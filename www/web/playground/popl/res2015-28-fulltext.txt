well programming up to congruence weirich university of pennsylvania pa usa popl consist complete easy to abstract this paper presents the design of a programming language that uses an adaptation of a congruence closure algorithm for proof and type inference this algorithm allows the type checker to automatically use equality assumptions from the context when reasoning about equality most languages automatically use equalities that follow from reduction during type checking however such reasoning is incompatible with congruence closure in contrast does not use automatic reduction because types may contain potentially terms therefore provides a unique to explore an alternative definition of equivalence in language design our work includes the specification of the language via a bidirectional type system which works and an algorithm for expressions in this language to an explicitly typed core language we prove that our elaboration algorithm is complete with respect to the source type system and always produces well typed terms in the core language this algorithm has been implemented in the language which includes general recursion irrelevant arguments heterogeneous equality and datatypes categories and subject descriptors d programming languages formal definitions and theory keywords dependent types congruence closure introduction the language aims to provide a smooth path from ordinary functional programming in a language like haskell to dependently typed programming in a language like agda however one significant difference between haskell and agda is that in the latter programmers must show that every function terminates such proofs often require reasoning especially when they must be done in conjunction with the function definition in contrast includes arbitrary nontermination relying on the type system to track whether an expression has been in the normalizing fragment of the language permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ copyright is held by the publication to acm acm prior work on has focused on the metatheory of the core safety for the entire language and consistency for the normalizing provides a foundation however it is not feasible to write programs directly in the core language because the terms get with type annotations and type conversion proofs this paper addresses the other half of the design a surface language which into the core the reason that elaboration is important in this context is that core has a weak definition of equivalence most languages define terms to be equal when they are at least however the presence of nontermination makes this definition to check whether two types are equivalent the type checker has to evaluate expressions inside them which becomes problematic if expressions may if the type checker gets stuck in an infinite loop existing languages fix an arbitrary global cut off for how many steps of evaluation the typechecker is to do or only reduce expressions that have passed a conservative termination test core somewhat automatic conversion completely instead equality is available only through explicit conversion because does not include automatic conversion it provides an to explore an alternative definition of equivalence in a surface language design congruence closure also known as the theory of equality with uninterpreted function symbols is a basic operation in automatic theorem provers for firstorder logic particularly smt solvers such as z given some context which contains assumptions of the form a b the congruence closure of is the set of equations which are by symmetry transitivity and changing subterms although efficient algorithms for congruence closure are wellknown this reasoning principle has seen little use in programming languages the problem is not lack of languages feature propositional equality written a b which is a type that asserts the equality of the two expressions programs that use propositional equality build members of this type using assumptions in the context and various lemmas and specify where and how they should be used congruence closure can with both of these tasks by the construction of these proofs and determining the for their elimination however the of this firstorder technique to the higherorder logics of languages is not straightforward the combination of congruence closure and full reduction makes the equality relation undecidable as a result most languages take the conservative approach of only congruence closure as a such as congruence tactic while this tactic can with the creation of equality proofs such proofs must still be explicitly eliminated proposals to use equations from the context automatically have done so in addition to reduction which makes it hard to characterize exactly which programs will typecheck and also leaves open the question of how expressive congruence closure is in isolation in this work we define the surface language to be fully up to congruence ie types which are by congruence closure can always be used and then show how the can implement this type system designing a language around an complicated piece of the of making the language hard to understand programmers could find it difficult to predict what core term a given surface term will elaborate to or they may have to think about the details of the elaboration algorithm in order to understand whether a program will successfully elaborate at all we avoid these problems using two strategies first the syntax of the surface and the core language differ only by annotations and the operational semantics ignores these annotations therefore the semantics of an expression is apparent just from looking at the source the only adds annotations that can not change its behavior second we define a declarative specification of the surface language and prove that the is complete for the specification as a result the programmer does not have to think about the concrete elaboration algorithm we make the following contributions · we demonstrate how congruence closure is useful when programming by comparing examples written in agda and explicitlytyped core language section · we define a dependently typed core language where the syntax contains annotations section · we define a typed version of the congruence closure relation that is compatible with our core language including features erasure and generalized assumption suitable for a dependent type system section · we specify the surface language using a bidirectional type system that uses this congruence closure relation as its definition of type equality section · we define an elaboration algorithm of the surface language to the core language section based on a novel algorithm for typed congruence closure section we prove that our elaboration algorithm is complete for the surface language and produces welltyped core language expressions our typed congruence closure algorithm both whether two terms are in the relation and also produces core language equality proofs · we have implemented these algorithms in extending the ideas of this paper to a language that includes datatypes and pattern matching a richer logical fragment and other features congruence closure works well in this setting in particular it significantly simplifies the typing rules for section our implementation is available for space reasons the full specification of the type systems described in this paper and the details of the proofs are only included in the extended version programming up to congruence consider this simple proof in agda which shows that zero is a right identity for addition n nat n n zero refl suc m suc m the proof follows by induction on natural numbers in the base case refl is a proof of in the next line translates a proof of m m from the recursive call to a proof of suc m this proof relies on the fact that propositional equality relation is reflexive and a congruence relation the former property holds by definition but the latter must be explicitly shown in other words the proof relies on the following lemma a b m n a f a b m n f m f n f refl refl now compare this proof to a similar result in the same reasoning is present the proof follows via natural number induction using the reduction behavior of addition in both cases n nat n n n case n eq of zero join suc m let m in join suc m suc m because does not provide automatic equivalence reduction must be made explicit above the term join explicitly introduces an equality based on reduction however in the successor case the type checker is able to infer exactly how the equalities should be put together for comparison the corresponding core language term includes a number of explicit type coercions n nat n n n nat case n eq of zero join join eq eq suc m let ih m in join suc m suc m join suc m suc ih join eq eq above an expression of the form a b converts the type of the expression a using the equality proof b equality proofs may be formed in two ways either via if a and a both reduce to some common term b then join a a is a proof of their equality or by congruence if a is a proof of bb then join is a proof of both sorts of equality proofs are constructed in the example in the base case the proof join follows from reduction and is converted to be a proof of n n by the congruence proof here eq is a proof that n an assumption derived from pattern matching congruence reasoning constructs a unify t t term unify t t unify leaf leaf match empty refl unify leaf branch t t unify branch t t leaf unify branch t t branch t t with unify t t match s p with unify ap s t ap s t match s q match compose s s trans branch t t trans t t branch ap s t t p q sym branch t t unify t var x with x is t no q match singleton x t trans singleton t x t q x t yes p with t var y match empty var sym p unify var x t with unify t var x match s p match s sym p prog unify t t term unify t t rec unify t t case t t of leaf leaf match empty leaf branch branch leaf branch t t branch t t case unify t t of match s p case unify ap s t ap s t of match s unfold ap s ap s t in unfold ap s ap s t in let s s t in let s s t in match compose s s var x case x t of no q let x t in let t x t q in match singleton x t yes case t of var y let x y p in match empty var x case unify t var x of match s p match s figure firstorder unification in agda left and in right proof that that n n the parts that differ on each side of the equality are marked by eq in the congruence proof the successor case uses congruence twice the equality derived from reduction is first by a congruence derived from the recursive call ih m m so that it has type suc m suc m this equality is then by a congruence derived from eq suc m n so that the result has type n n for a larger example consider unification of firstorder terms figure for this example the term language is the simplest possible consisting only of binary trees constructed by branch and leaf and possibly containing unification variables var represented as natural numbers we also use a type substitution of substitutions which are built by the functions singleton and compose and applied to terms by ap proving that unify terminates is difficult because the termination metric involves not just the structure of the terms but also the number of unification variables for example see to save development effort a programmer may to prove only a partial correctness property if the function terminates then the substitution it returns is a unifier in other words if the unify function returns it either says that the terms do not match or produces a substitution s and a proof that s them we write the data structure in as follows the agda version is similar data unify t term t term type where match of s substitution pf ap s t ap s t comparing the agda and implementations we can see the effect of programming instead of upto when the unifier returns match it needs to supply a proof of equality the agda version explicitly constructs the proof using equational reasoning which involves calling congruence lemmas sym trans and from the standard library the version leaves such proof arguments as just an meaning that it can be inferred from the equations in the context for that purpose it introduces equalities to the context with unfold for reductions see section and with calls to relevant lemmas figure demonstrates how congruence closure makes version of pattern matching ie smart case both simple and powerful the figure compares parts of inductive proofs in and agda of an inversion lemma about the operation which an element to the end of a list when both lists are nonempty the proof argument can be used to derive that x y using the of cons and the recursive call shows that xs ys congruence closure both puts these together in a proof of cons x xs cons y ys and the necessary proof for the recursive call in agda one is to prove the property by pattern matching on the equality between the lists this approach leads to a quite fun here the equivalence between x and y cannot be observed until xs z and xs z are named the socalled on trick provides the equalities p xs z s and q ys z s that are necessary to constructing the fourth argument for the recursive call by on agda log xs ys list a z a xs z ys z xs ys ind xs ys z pf case xs ys of cons x xs cons y ys let xs z cons x xs z in let ys z cons y ys z in let xs ord ys z in agda pattern matching based solution xs ys z xs z ys z xs ys x xs y ys z pf with xs z ys z xs z ys z y xs y ys z refl s s p q with xs ys z trans p sym q y ys y ys z refl s s p q refl refl alternative agda solution based on congruence and x xs y ys x xs y ys x y refl refl x xs y ys x xs y ys xs ys refl refl xs ys z xs z ys z xs ys x xs y ys z pf pf xs ys z pf figure pattern matching can be in agda x y f g h expression variables expressions a b c a b type x x a b rec fa x a a b a b rec fa a a a b join a b strategies p i j a b vx vj xj c b a a b i a values v type x x a b rec fa x a a b rec fa a a b join v b figure syntax although this development is not long it is not at all straightforward requiring advanced knowledge of agda idioms alternatively the reasoning used in the example is also available in agda as in the definition of however this version requires the use of functions to prove that cons is injective and congruent a cbv b rec f x a v cbv v x rec f x af a rec f · cbv rec f a a cbv a a b cbv a b a cbv a v a cbv v a a cbv a a · cbv a · figure callbyvalue operational semantics annotated core language we now turn to the theory of the system we begin by describing the target of the our annotated core language this language is a small variant of the callbyvalue language defined in prior work it corresponds to a portion of core language but to keep the proofs tractable we omit recursive datatypes and replace its terminating with syntactic value restrictions the syntax is shown in figure terms types and the sort type are into one syntactic category we use the notation ax b to denote the substitution of a for x in b as is standard in languages our notation for function types a b is syntactic sugar for function types x a b where the variable x is not free in b type annotations such as a in rec fa x a are optional and may be omitted from expressions annotations are in figure the a removes these annotations expressions that contain no typing annotations are called erased an expression that includes all annotations is called a core or annotated expression the core typing judgement written a a and described below requires that all annotations be present in this case the judgement is syntaxdirected and trivially decidable in contrast type checking for erased terms is undecidable the only role of annotations is to ensure decidable type checking they have no effect on the semantics in fact the operational semantics written a cbv b is defined only for erased terms and extended to terms with annotations via erasure this operational semantics is a smallstep callbyvalue evaluation relation shown in figure figure shows the typing rules of the core language typing judgement a a additionally the judgement from the figure states that each type in is wellformed recursive functions are defined using expressions rec f x a with the typing rule such expressions are values and applications step by the rule rec f x a v cbv v x rec f x af a if the function makes no recursive calls we also use the syntactic sugar x a when a function has a dependent type then its argument must be a value this restriction is common for languages with nontermination in addition to the normal function type the core language also include computationally irrelevant function types a b which are by irrelevant functions rec fa b and eliminated by irrelevant applications a many expressions in a dependently typed program are only used for type checking but do not affect the runtime behavior of the program and these can be marked irrelevant our treatment of follows because the treatment of irrelevant functions closely that of normal functions we omit the typing rules in this version of the paper we include this feature in the formalism to show that besides being generally useful works well with congruence closure given that we already handle annotations we can support full for free equality the typing rules at the bottom of figure deal with propositional equality a primitive type the formation rule states a b is a wellformed type whenever a and b are two welltyped expressions there is no requirement that they have the same type that is to say our equality type is heterogeneous propositional equality is eliminated by the rule given a proof v of an equation a b we can change the type of an expression from a to b since our equality is heterogeneous we need to check that b is in fact a type we require the proof to be a value in order to rule out divergence a language could use a more termination analysis indeed our implementation does so however the congruence proofs generated by our are syntactic values so for the purposes of this paper the simple value restriction is enough the proof term v in a type cast is an annotation with no operational so the typechecker considers equalities like a a v to be trivially true and the is free to insert coercions using congruence closure proofs anywhere the rest of the figure shows introduction rules for equality equality proofs do not carry any information at runtime so they all use the same term constructor join but with different annotations the rule introduces equations which are justified by the operational semantics source programs must use to explicitly indicate expressions that should be reduced the rule states that join is a proof of a a when the of a and a reduce to a common expression b using the parallel reduction relation this common expression b is not required to be a value note that without normalization we need a for how long to evaluate so programmers must specify the number of steps i j of reduction to allow in this to if these numbers are the rule states that equality is a congruence the simplest use of the rule is to change a single subexpression using a proof v the use of the proof is marked with a in the annotation for example if v y then we can prove the equality nat nat nat one can also eliminate several different equality proofs in one use of the rule the syntax of subst includes a type annotation b and the last premise of the rule checks that the type b matches what one gets after substituting the given equalities into the template c this annotation adds flexibility because the check is only upto erasure if needed the programmer can give the left and righthand side of b different annotations to make both sides welltyped finally the rules and state that the equality type and arrow type constructors are injective the figure similar rules for irrelevant arrow types making type constructors injective is for a dependent language it is incompatible with eg type theory which proves nat void bool void however in our language we need arrow to prove type preservation because type casts are erased and do not block reduction for example if a function by type cast steps via reduction we must use arrow to derive casts for the argument and result of the application we also add for the equality type constructor this is not required for type safety but it is justified by the metatheory so it is safe to add is important for the surface language design see section the core language satisfies the usual properties for type systems for the proofs in section we rely on the fact that it satisfies weakening substitution restricted to values and it also satisfies preservation progress and decidable type checking the proofs of these lemmas are in et al congruence closure the idea behind our surface language is that the programmer should never have to explicitly write a type cast a v if the proof v can be inferred by congruence closure in this section we exactly specify which proofs can be inferred by defining the typed congruence closure relation a b shown in figure like the usual congruence closure relation for firstorder terms the rules in figure specify that this relation is reflexive symmetric and transitive it also includes rules for using assumptions in the context and congruence by changing subterms however we make a few changes first we add typing premises in and to make sure that the relation only welltyped and core language terms in other words aa type type a type x a x a b type x a x a b type x a a type f x a a x a a a rec a x a x a a ba a x a b v a a v v x b aa bb a b type a a v a b b type a v b a i p b a j p b a a type join pi j aa a a b type k vk ak bk b ax aj xj c bx bj xj c vj xj cb b v a a b b i v ai bi v x a b x a b v a a v x a b x a b v a v v vx b vx b figure typing rules for the annotated core language aa aa ab ba ab bc ac a b a a b b ab x a a a b ab a b type k ak bk a b ax aj xj c bx bj xj c ab a a b b ak bk x a b x a b a a a b a b b b figure typed congruence closure relation if a b then a a and b b next we adapt the congruence rule so that it corresponds to the rule of the core language in particular the rule includes an explicit erasure step so that the two sides of the equality can differ in their portions furthermore we extend the relation in several ways we automatically use computational in the rule this makes sure that the programmer can ignore all annotations when reasoning about programs also we reason up to of datatype constructors in rules and as mentioned in section these rules are valid in the core language and we will see in section that there is good reason to make the congruence closure algorithm use them automatically note that we restrict rule so that it applies only to function types we explain this restriction in section systems based around congruence closure often their automatic theorem prover in some way eg and add reasoning about natural number equations and the coq congruence tactic automatically uses of data constructors finally the rule is a bit stronger than the classic rule from first order logic in the firstorder logic setting this rule is defined as just the closure over equations in the context x ab ab however in a dependently typed language we can have equations between equations in this setting the classic rule does not respect of contexts for example it would prove the first of the following two problem instances but not the second x nat y nat a type h x y a h x y x y x nat y nat a type h x y a h a xy therefore we replace the rule with the stronger version shown in the figure we were led to these rules by theoretical considerations when trying to show that our elaboration algorithm was complete with respect to the declarative specification see section once we implemented the current set of rules we found that they were useful in practice as well as in theory because they improved the elaboration of some examples in our test suite the stronger assumption rule is useful in situations where typelevel computation produces equality types for example when using custom induction principles surface language next we give a precise specification of the surface language which shows how type inference can use congruence closure to infer casts of the form a v note that this process involves determining both the location of such casts and the proof of equality v figure defines a bidirectional type system for a partially annotated language this type system is defined by two mutually defined judgements type synthesis written a a and type checking written a a here and a are always inputs but a is an output of the synthesizing judgement and an input of the checking judgement most rules of this type system are standard for bidirectional systems including the rules for inferring the types of variables the wellformedness of types and application and the mode switching rules and any term that has enough annotations to synthesize a type a also checks against that type conversely some terms eg functions require a known type to check against and so if the surrounding context does not specify one the programmer must add a type annotation the rules and in figure specify that checking and inference work at any point in the typing derivation the system can replace the inferred or checked type with something congruent the notation a b the congruence closure judgement from section to the partially annotated surface language these two rules contain premises to maintain wellformedness of types the invariant maintained by the type system is that in a wellformed context any synthesized type is guaranteed to be while it is the callers to ensure that any time the checking judgement is used the input type is the rule for checking functions is almost identical to the corresponding rule in the core language with just two changes first the programmer can omit the types a and a because in a bidirectional system they can be from the type the expression is checked against second the new premise slightly restricts the use of this rule the difficulty is that the congruence closure algorithm does not implement the full rule of the core language but injective reasoning is needed by the type checker therefore we rule out function types that do not support for their ranges in certain typing contexts this premise also appears in the rule for dependent application we return to this issue in section equations that are provable via congruence closure are available via the checking rule in this case the proof term is just join written as an in the concrete syntax because this is a checking rule the equation to be proved does not have to be written down directly if it can be inferred from the context the rule proves equations using the operational semantics we saw this rule used in the example written join in the concrete syntax note that the programmer must explicitly write down the terms that should be reduced the rule is a synthesizing rather than checking rule in order to ensure that the typing rules are effectively implementable although the type system works up to congruence the operational semantics do not so the expression itself needs to contain enough information to tell the typechecker which member of the equivalence class should be cannot get this information from the checking context in practice having to explicitly write this annotation can be the implementation includes a feature which can section it is also interesting to note the rules that do not appear in figure for example there is no rule or surface syntax corresponding to because this feature can be written as a function similarly the rather involved machinery for rewriting subterms and and erased terms rule can be entirely omitted since it is subsumed by the congruence closure relation the programmer only needs to introduce the equations into the context and they will be used automatically finally we note that the surface language does not satisfy some of the usual properties of type systems in particular it lacks a general weakening lemma because the relation cannot be similarly it does not satisfy a substitution lemma because that property fails for the congruence closure relation we might expect that x c a b and v c would imply v x a v x b but this fails if c is an equation and the proof v makes use of the operational semantics and it does not satisfy a strengthening lemma because even variables that do not occur in a term may be implicitly used as assumptions of congruence proofs the situations where weakening and substitution fail are we have never encountered one when writing example programs in and there are straightforward for programmers furthermore these properties do hold for fully annotated expressions so there are no restrictions on the output of elaboration however the typing rules for the declarative system must be formulated to avoid these issues which requires some extra premises the rule requires a type proving this from would need weakening requires b type proving this from a b type would need strengthening and requires f x a a x a a type proving this from x a a type would need weakening elaboration we implement the declarative system using an typechecker which translates a surface language expression if it is wellformed according to the bidirectional rules to an expression in the core language we formalize the algorithm that the uses as two inductively defined judgements written a a a and a are inputs and a a a a and a are inputs the variables with a and a are fully annotated expressions in the core language while a is the surface language term being the deals with each toplevel definition in the program separately and the context is an input containing the types of the previously definitions the job of the is to insert enough annotations in the term to create a welltyped core expression it should not otherwise change the term stated more formally theorem elaboration soundness if a a a then a a and a a if a type and a a a then a a and a a aa a a a b b type ab a type a a aa a aa bb a b type a a type a i p b a j p b join pi j aa a a type type x a a type x a a type x a b type x a b type ba b type a x a b v a x a b for v b type a v b aa a a a b b type ab aa a a ab join a b f x a a x a a a f x a a x a x a a for x f x a a x a a type rec f x a x a a ab a b a a b b ab a for v a b x a b x a b implies v x b v x b x a b for v figure bidirectional typing rules for surface language a for v v a x a b type a b x a b x a b implies v x b v v x b where x a b for v v a a figure core language restriction furthermore the should accept those terms specified by the declarative system if the type system of section accepts a program then the succeeds and produces an equivalent type in inference mode theorem elaboration completeness if a a and and a type a then a a a and a a if a a and and and a type a then a a a designing the elaboration rules follows the standard pattern of a declarative specification into an algorithm remove all rules that are not syntax directed in this case and and generalize the premises of the remaining rules to create a syntaxdirected system that accepts the same terms at the same time the uses of congruence closure relation a b must be replaced by appropriate calls to the congruence closure algorithm we specify this algorithm using the following partial functions a b v which checks a and b for equality and produces proof v a x b b v which checks whether a is equal to some function type and produces that type and proof v a b b v which is similar to above except for equality types for example consider the rule for function applications a a a a x a b v v a v x a b for v a v a v v v x b in the corresponding declarative rule the applied term a must have an arrow type but this can be by implicitly using to as type therefore in the algorithmic system the corresponding condition is that the type of a should be equal to an arrow type x a b modulo the congruence closure operationally the typechecker will infer some type a for a then run the congruence closure algorithm to construct the set of all expressions that are equal to a and check if the set contains some expression which is an arrow type the core term uses the produced proof of a x a b in a cast to change the type of a at this point there is a potential problem what if a is equal to more than one arrow type for example if a x a b x a b then the has to choose whether to check b against a or a a priori it is quite possible that only one of them will work for example the context may contain an inconsistent equation like nat nat bool nat we do not wish to introduce a backtracking search here because that could make type checking too slow this kind of in the domain type can be handled by extending the congruence closure algorithm note that things are fine if a a since then it does not matter if a or a is chosen so the issue only arises if x a b x a b and not a a fortunately type constructors are injective in the core language section including as part of the congruence closure judgement by the rule ensures that it does not matter which arrow type is we also have to about a in the codomain type ie the case when a x a b and a x a b for two different types at first it seems as if we could use the same solution after all the core language includes a rule for of the range of function types rule there is an important difference between this rule and however which is the handling of the bound variable x in the codomain b the rule says that this can be closed by substituting any value for it as a result we cannot match this rule in the congruence closure relation because the algorithm would have to guess that value as far as writing an goes maybe this is all we only want to apply the axiom to the particular value v from the function application a v however there does not seem to be any natural way to write a declarative specification what values v should be candidates instead we restrict the declarative language to this problematic case that is the programmer is not allowed to write a function application unless all possible return types for the function are equal note that in cases when an application is forbidden by this check the programmer can avoid the problem by proving the required equation manually and ensuring that it is available in the context in the core language we express this restriction with the rule in figure and then lift this operation to partially annotated terms by rule figure operationally the typechecker will search for all arrow types equal to a and check that the the with v substituted are equal in the congruence closure this takes advantage of the fact that equivalence classes under congruence closure can be efficiently the rule as written appears to quantify over potentially infinitely many function types the algorithm in section will represent these as a finite structure which can be effectively in the core language rule we need to insert a type coercion from a to a to make the righthand side well typed by the rule that equality is always provable so the typechecker will use the proof term v that the congruence closure algorithm produced on the checking side the rule now needs to prove that the synthesized and checked types are equal a a a a b a b a v v this rule corresponds to a direct call to the congruence closure al producing a proof term v note that the inputs are fully moving from the declarative to the algorithmic type system we replaced the undecidable condition a b with a decidable one finally the rule equality proofs written as in the concrete syntax a a b v a b join a v v v as in the rule for application the typechecker does a search through the equivalence class of the type a to see if it contains any equations if there is more than one equation it does not matter which one gets because the congruence relation includes of the equality type constructor in the term we need to prove a b a given a a b this can be done using for and and we abbreviate that proof term v implementing congruence closure algorithms for congruence closure in the firstorder setting are well studied and our work builds on them however in our type system the relation a b does more work than classic congruence closure we must also handle erasure terms with bound variables dependently typed terms the rules the assumption up to congruence rule and we must generate proof terms in the core language our implementation proves an equation a b in three steps first we erase all annotations from the input terms and explicitly mark places where the congruence rule can be applied using an operation called labelling then we use an adapted version of the congruence closure algorithm by and our version of their algorithm has been extended to also handle and assumption up to congruence but it ignores all the checks that the terms involved are welltyped finally we take the untyped proof of equality and process it into a proof that a and b are also related by the typed relation the implementation is in this way because the congruence rule does not necessarily preserve so the invariants of the algorithm are easier to maintain if we do not have to track at the same time labelling terms in a b the rule is stated in terms of substitution but existing algorithms expect congruence to be applied only to syntactic function applications from a b conclude f a f b to this gap we equations into erased labelled expressions a label f is an erased language expression with some designated holes written ­ in it and a labelled expression is a label applied to zero or more labelled expressions ie a term in the following grammar a f ai l a a lab l b a l a b l b a l a a x a l a ­ ­ a b lab k l ak bk l f ai f bi l f a f b f injective lab figure untyped congruence closure on labelled terms typically a label will represent just a single node of the abstract syntax tree for example a equation f x f y will be processed into ­ ­ f x ­ ­ f y where the label ­ ­ means this is an application however for syntactic forms involving bound variables it can be necessary to be more for example given a b our implementation can prove rec f x a x rec f x b x which involves using rec f x ­ x as a label in general to process an expression a into a labelled term the implementation will select the largest subexpressions that do not involve any bound variables applying the labelling step simplifies the congruence closure problems in several ways we show the simpler problem by defining the relation l a b defined in figure compared to figure we no longer need a rule for erasure congruence is only used on syntactic label applications all the different rules are handled and we do not ensure that the terms are welltyped in the appendix we formally define the label operation and prove that it is complete in the following sense lemma if a b then label l label a label b untyped congruence closure next we use an algorithm based on and to decide the l a b relation the algorithm first the problem by allocating constants ci ie fresh names for every subexpression in the input after this transformation every input equation has either the form c c or c f c c that is it is either an equation between two atomic constants or between a constant and a label f applied to constants then follows the main loop of the algorithm which is around three datastructures a queue of input equations a structure and a lookup table in each step of the loop we take off an equation from the queue and update the state accordingly when all the equations have been processed the structure represents the congruence closure the structure tracks which constants are known to be equal to each other when the algorithm an input equation c c it merges the corresponding classes this deals with the symmetry and transitivity rules the lookup table is used to handle the congruence rule it maps applications f c c to some canonical representative c if the algorithm an input equation c f c c then c is recorded as the representative if the table already had an entry c then we deduce a new equation c c which is added to the queue in order to adapt this algorithm to our setting we make three changes first we adapt the lookup tables to include the richer labels corresponding to the many syntactic categories of our core language and only use a single label meaning application of a unary function second we deal with rules in a way similar to the implementation of congruence tactic certain labels are considered injective and in each class we identify the set of terms that start with an injective label if we see an input equation c f c c and f is injective we record this in the class of c whenever we merge two classes we check for terms by the same f eg if we merge a class containing f c c with a class containing f c c we deduce new equations c c and c c and add those to the queue third our implementation of the extended assumption rule works much like with each class we record two new pieces of information whether any of the constants in the class which represent types of our language are known to be by a variable and whether any of the constants in the class represents an equality type whenever we merge two classes we check for new equations to be added to the queue the extended version of the paper contains a precise description of our algorithm and also gives a formal proof of its correctness lemma the algorithm described above is a decision procedure for the relation l a b typing restrictions and generating core language proofs along the pointers in the structure we also keep track of the evidence that showed that two expressions are equal the syntax of the evidence terms is given by the following grammar an evidence term p is either an assumption x with a proof p that xs type is an equation symmetry transitivity or an application of congruence annotated with a label a p q x p refl p p q p a p pi next we need to turn the evidence terms p into proof terms in the core calculus this is nontrivial because the algorithm does not track types not every equation which is derivable by untyped congruence closure is derivable in the typed theory for example if f bool bool then from the equation a nat b nat we can not conclude f a f b because f a is not a welltyped term worse still even if the conclusion is welltyped not every untyped proof is valid in the typed theory because it may involve illtyped intermediate terms for example let id a type a a be the polymorphic identity function and suppose we have some terms a a b b and know the equations x a b and y a b then x refl refl y is a valid untyped proof of id a a id b b but it is not a correct typed proof because it involves the illtyped term id b a x a b a a b b y a b id a a id b a id b id a a id b b a id b b trans notes this as an open problem of course the above proof is complicated the same equation can be proved by a single use of congruence furthermore the simpler p refl refl p p refl p q r p p p p p refl p p p q r refl refl p p p q q p a p pi a p pi p p a p pi a q qi a p q pi qi a p pi pk a p pi r pk r r a p pi r pk x p q p x r q pp x p x p assumption pp qq p q p q trans k pk pk a p pi a p pi pp p p inj figure simplification rules for evidence terms proof does not have any issues with typing every expression occurring in the derivation is either a subexpression of the goal or a subexpression of one of the equations from the context so we know they are welltyped our key observation is that this trick works in general the only time a congruence proof will involve expressions which were not already present in the context or goal is when transitivity is applied to two derivations ending in we simplify such situations using the following rule a p pi a q qi a p q pi qi this rule is valid in general and it does not make the proof larger we also need rules for simplifying evidence terms that combine transitivity with or such as a p pk and x p q rules for uses of symmetry past the other evidence constructors and rules for rewriting subterms the complete simplification relation is shown in figure any evidence term p can be simplified into a normalized evidence term p in the extended version of the paper we define an explicit grammar for fully simplified terms p and prove than any term can be simplified into that form and given p it is easy to produce a corresponding proof term in the core language the idea is that one can the middle expression in every use of transitivity p q because at least one of p and q will be specific enough to down exactly what equation it is proving formally we define the judgement l p a b by adding evidence terms to the rules in figure and then prove lemma if we have label l p label a label b and a b type then a b simplifying the evidence terms also solves another issue which arises because of the rule because the input terms are to delete annotations section an arbitrary evidence term will not uniquely specify the annotations again this issue only arises because of the pair simplifying the evidence term the issue because in a simplified term every intermediate expression is down putting together the labelling step the evidence simplification step and the proof term generation step we can relate typed and untyped congruence closure in the following theorem the relation a b is defined by similar rules as figure except that we omit the typing premises in and theorem suppose a b and a b type then a b furthermore v a b for some v the computational content of the proof is how the generates core language evidence for equalities so this shows the correctness of the implementation but it is also interesting as a theoretical result in its own right and an important part of the proof of completeness of elaboration section extensions the full implementation includes more features than the surface language described in section we omitted them from the formal system in order to simplify the proofs but they are important to make programming up to congruence work well smart case although we do not include datatypes in this paper they are a part of the implementation and an important component of any language the presence of congruence closure elaboration means that the core language can use a specification of pattern matching called smart case with smart case the rule for case analysis introduces a new equation into the context when checking each branch of a case expression for example the rule for an if expression type checks each branch under the assumption that the condition is true or false a bool x a true b a x a false b a if a then b else b a this rule is in contrast to specifications that use unification to communicate the information by pattern matching in those systems if the and the patterns are not in the fragment of higherorder unification supported by the type system then the case expression must be rejected furthermore the specification of the typing rule for the unification based systems is more complicated smart case by this information to propositional equality is both simpler and more expressive the to smart case has been that because this information is recorded as an assumption in the context it is more work for the programmer however with congruence closure the type system is immediately able to take advantage of these equalities in each branch thus the surface language has the convenience of the rule while the core language the simplicity of smart case reduction modulo congruence in the paper all reductions are introduced by expressions join a b but in practice some additional support from the typechecker for common patterns can make programming much more first one often wants to evaluate some expression a as far as it goes then making the programmer write both sides of the equation a b is instead we provide the syntax unfold a in body the implementation reduces a to normal form a cbv a cbv a cbv a if a does not terminate the programmer can specify a maximum number of steps and then introduces the corresponding equations into the context with fresh names that is it as let join a a in let join a a in let join a a in body second many proofs requires an interleaving of evaluation and equations from the context particularly in order to take advantage of equations introduced by smart case one example is in section the needs to return a proof of n n if we try to directly evaluate n we would reach the stuck expression case n of zero succ m succ m so instead we used an explicit type annotation in the zero branch to evaluate however the context contains the equation n zero which suggests that there should be another way to make progress to take advantage of such equations we add some extra intelligence to the way unfold handles contexts that is expressions of the form f a or case b of when such an expression it will first recursively unfold the function f the argument a or the b as with ordinary and add the resulting equations to the context however it will then examine the congruence equivalence class of these expressions to see if they contain any suitable value v is suitable for a a function value rec f x a for f and a value by a data constructor for then unfold the resulting expression rec f x a v if there are several suitable values one is selected arbitrarily this way unfolding can make progress where ordinary gets stuck using the same machinery we also provide a version of join which first both sides of the equation and then checks that the resulting expressions are this lets us omit the type annotations from n case n eq of zero suc m the unfold algorithm does not fully respect because it only converts into values for example suppose the context contains the equation f a v then unfold g f a will evaluate f a and add the corresponding equations to the context but unfold g v will not cause f a to be evaluated this gives the programmer more control over what expressions are run we have not studied the theory of the unfold algorithm and indeed it is not a complete decision procedure for our propositional equality if a subexpression of a does not terminate unfold will all its reduction budget on just that subexpression but this is ok because the programmer what expression a to unfold and if the context contains eg an equation between two function values unfold will arbitrarily choose one of them but it is hard to think of an example where this would happen we have found unfold very helpful when writing examples related work the annotated core language in this paper is a slight variation on previous work which in turn is a subset of the full language implemented by in this version in order to keep the formalism small we omit some features exceptions and general datatypes and replace the application rule with a slightly less expressive version however these are not significant the original system is still compatible with the up to congruence approach and is implemented in we also took the to simplify some typing rules and to emphasize the role of annotations propositional equality the idea of using congruence closure is not limited to the particular version of propositional equality used by our core language which has some nonstandard features we discussed the for them in below we discuss how those features interact with congruence closure and suggest how the algorithm could be adapted to other settings first our equality is very heterogeneous that is we can form and use equations between terms of different types this has and cons it can be convenient for the programmer to not about types and the metatheory is simple but it makes it hard to include typedirected rules however congruence closure will work just as well with a conventional equality second we use an nary congruence rule while most theories only allow eliminating one equation at a time for congruence closure to work equality must be a congruence eg given a a and b b we should be able to conclude f a b f a b our nary rule supports this in the most straightforward way possible an alternative used in some versions of would be to use separate nary congruence rules for each syntactic form systems that only allow rewriting by one equation at a time require some to avoid illtyped intermediate terms eg section finally in our system the elimination of propositional equality is erased so equations like a b a are considered trivially true this is similar to extensional type theory but unlike coq and agda having such equations available is important because the inserts casts automatically without detailed control by the programmer in coq that would be problematic because an inserted cast could prevent two terms from being equal however making the conversion is not the only possible approach for example in observational type theory the conversions are computationally relevant but the theory includes a b a as an axiom in that system one can imagine the would use the axiom to make the program typecheck stronger equational theories the theory of congruence closure is one among a number of related theories one can it in various ways by adding more reasoning rules in order to get a more expressive programming language however doing so may type inference or even the decidability of type checking one obvious question is whether we could extend the relation a b to do both congruence reasoning and reduction at the same time unfortunately this extension causes the relation to become undecidable this is clearly the case in our language which directly includes general recursive function definitions but even if we allowed only terminating functions the combination of equality assumption and can be used to encode general recursion for example reasoning in a context containing f nat nat h f x if even x then f n else f n is equivalent to having available a direct recursive definition f x if even x then f n else f n another natural generalization is to allow rewriting by axiom schemes ie instead of only using ground equations a b from the context also instantiate and use quantified formulas like b in general this generalization the word problem is also not decidable eg it is easy to write down an axiom scheme for the equational theory of however there are procedures such as completion which form the basis of many automated theorem provers even when preserving decidability one can still extend congruence closure to know about specific axioms schemes such as for natural numbers with successor and predecessor or lists or injective data constructors clearly one could design a programming language around a more theory than just congruence closure many languages such as and call out to an theorem prover in order to take advantage of all the theories that the prover implements one reason we focus on a simple theory is that it makes unification easier which seems to offer promising for future work on type inference unification modulo congruence closure is npcomplete this compares with unification modulo higherorder unification which is undecidable unification modulo other equational theories must be handled on a basis and it is not an operation exposed by most provers simplifying congruence proofs our simplification rule is quite natural and in fact the same rule has been studied before for a different reason for efficiency users of congruence closure want to make proofs as small as possible by taking advantage of simplifications like refl p p or p p refl however uses of can hide the for such simplifications de et al define the same rule and give the following example given assumptions h a b h b d h c b consider the proof term f h h f h h f a f d we can get of the assumption h by doing the rewrite f h h f h h f h h h h dependent programming with congruence closure aims to make definitional equality stronger by including additional equational theories such as presburger arithmetic so that for example the types vec and vec n × can be used the prototype implementation only looks at the types themselves but the metatheory also considers using assumptions from the context this is complicated because still wants to consider types modulo and in contexts with inconsistent assumptions like true false one could write nonterminating expressions therefore imposes restrictions on where an assumption can be used makes the definitional equality and as an example builds a stack combining congruence closure reduction and potentially other theorem proving neither or prove that their implementation is complete with respect to a declarative specification for example the application rule requires that the applied function has the type t t and then checks that t is equal to the type of the argument but there is no attempt to also handle declarative derivations which require definitional equality to create an arrow type the language includes a tactic similar to our and unfold however instead of using equations from the context the programmer has to write an explicit list of equations and unlike unfold it the given equations conclusion we consider this paper as an application of automatic theorem proving to language design of course in a higherorder logic we always expect that the programmer will have to supply some proofs manually the question is which ones intensional type theory that equivalence in a normalizing language is decidable so such equality proofs can be handled automatically as part of the definitional equality relation this paper considers a different decidable equational theory and proposes a language that is the dual of while conventional languages automatically use equalities that follow from reductions but do not automatically use assumptions from the context our language uses assumptions but does not automatically reduce expressions we look forward to exploring the of this design decision more in the context of a full programming language our implementation provides a good but we would like to add more automation in particular the addition of seems promising furthermore we would like to explore ways in which reduction and congruence closure can there is some way to achieve the benefits of each approach in the same context acknowledgments this material is based upon work supported by the national science foundation under grant and the implementation was developed with the of the team this paper was written with the help of the tool the authors would also like to thank the anonymous reviewers for their comments references t the case of the smart case how to implement conditional presentation at sept t c and w observational equality now in programming languages meets program verification pages ­ acm l ­ a language with dependent types in icfp international conference on functional programming pages ­ acm l n and d a completion without failure in a h and m editors resolution of equations in algebraic structures volume rewriting techniques pages ­ academic press b and b the implicit calculus of constructions as a programming language with dependent types in th international conference on foundations of software science and computational structures volume of lncs pages ­ springer y and p interactive theorem proving and program development calculus of inductive constructions springerverlag g m a d gordon c and d e semantic subtyping with an smt solver in icfp international conference on functional programming pages ­ e c programming meets full dependent types in programming languages meets program verification pages ­ acm isbn c v and s weirich combining proofs and programs in a dependently typed in popl st acm sigplansigact symposium on principles of programming languages p deciding equality in the constructor theory in t and c editors types for proofs and programs volume of lecture notes in computer science pages ­ springer berlin k crary typetheoretic methodology for practical programming languages phd thesis cornell university l de and n z an efficient smt solver in proceedings of the theory and practice of software th international conference on tools and algorithms for the construction and analysis of systems pages ­ berlin springerverlag l de h and n equality electronic notes in theoretical computer science ­ july p j r sethi and r e tarjan variations on the common subexpression problem j acm ­ oct j w p and d is npcomplete in proceedings of the third annual symposium on logic in computer science lics pages ­ l j a k j l j and s a programming language for and in icfp international conference on functional programming pages ­ k r m leino an automatic program verifier for functional correctness in proceedings of the th international conference on logic for programming artificial intelligence and reasoning pages ­ springerverlag c firstorder unification by structural recursion g nelson and d c fast decision procedures based on congruence closure j acm ­ r and a fast congruence closure and extensions inf comput ­ a and a deciding modulo ground equations in operational type theory in s and d editors proof search in type theories b c pierce and d n turner local type inference acm trans program lang syst ­ jan p sewell f s g t s sarkar and r effective tool support for the working j program ­ r e an algorithm for reasoning about equality acm ­ july v and s weirich programming up to congruence extended version technical report university of pennsylvania pa oct v c k y n h d iii p fu g t a and s weirich heterogeneous equality and callbyvalue dependent type systems in j and p b editors volume of pages ­ open association a and z shao static and proof checking in proceedings of the th annual acm sigplansigact symposium on principles of programming languages popl pages ­ new york ny usa acm py coq modulo theory in csl pages ­ a and ly the algebra of equality proofs in th international conference on rewriting techniques and applications pages ­ springer n j chen c fournet py k and j yang secure distributed programming with types in icfp international conference on functional programming pages ­ acm 