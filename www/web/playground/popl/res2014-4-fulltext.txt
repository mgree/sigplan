combining proofs and programs in a dependently typed language weirich university of pennsylvania abstract most programming languages either require that all expressions terminate eg coq agda and or allow infinite loops but are inconsistent when viewed as logics eg haskell here we combine these two approaches into a single core language the language is composed of two fragments that share a common syntax and overlapping semantics a logic that guarantees total correctness and a callbyvalue programming language that guarantees type safety but not termination the two fragments may interact logical expressions may be used as programs the logic may soundly reason about potentially nonterminating programs programs can require logical proofs as arguments and mobile program values including proofs computed at runtime may be used as evidence by the logic this language allows programmers to work with total and partial functions uniformly providing a smooth path from functional programming to programming categories and subject descriptors d programming languages formal definitions and theory keywords dependent types termination general recursion introduction dependently typed languages have developed along two different distinguished by their towards nonterminating programs on the one hand languages like and haskell treat programming as an extension of ordinary functional programming these languages ordinary functional programs defined by general recursion with more expressive types on the other hand languages like coq agda and treat dependently typed programming as a of constructive theorem proving these systems nontermination because an infinite loop can be given any type and would therefore make the logic inconsistent we would like balance between proving and programming with neither activity given treatment although we are to the ideal that all programs should be proven correct we permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ san diego ca usa copyright is held by the publication to acm acm understand that there are practical reasons not to do so instead we a language for heterogeneous verification allowing programmers to their verification budget to critical sections such a language must support general recursion as as a functional programming language yet at the same time must provide the expressive reasoning capabilities of a constructive logic proof assistant in support of this goal we propose a novel language that is composed of two fragments a logical fragment where every expression is known to terminate and a fragment that does not provide this the key idea of our work is to distinguish between these fragments by indexing the typing judgement with a consistency classifier that may be l logic or p program thus aa when is l the isomorphism applies and we may consider a a proof of the theorem a when is p the only interpretation of a is as a functional program making this distinction means that one language can both functional programming and constructive logic by embedding each in their respective fragments however these activities are not too far syntax and semantics of the two fragments overlap considerably because the distinction between them is made through typing in this paper we explore the consequences of this design in the context of a programming language focusing on the following mechanisms that foster interaction between the two fragments · first we define the logical language as a of the language so that all logical expressions can be used as programs of course the language includes forms that are not available to the logic including general recursion and the elimination of types · we allow uniform reasoning for logical and expressions through a equality type two expressions can be shown to be equal based on their evaluation which is the same for both fragments equality proofs can be used implicitly by the type system · we the labeled typing judgment as a new type form a this type can be used by either fragment to manipulate values belonging to the other · we identify a set of mobile whose values can freely move between the fragments to demonstrate the soundness and consistency of these mechanisms we define a core language called that supports these interactions see sections and in addition to the a type this language includes dependent functions products propositional equality natural numbers sums recursive functions and types we prove that this language is type safe and that the l fragment is normalizing and logically consistent section our normalization proof uses a combination of traditional and stepindexed logical relations all of our results have been completely using the coq proof assistant and are available online we also explore how our ideas interact with other programming language features we have implemented a prototype language based on the semantics of and discuss that implementation in section extends with features that are convenient for programming parametric polymorphism typelevel computation userdefined datatypes and implicit arguments we have developed a number of examples using the implementation is available online we are not the first to consider the combination of total and partial programming in the setting of languages partial types and the coinductive monad embed general recursive programs into constructive logic by modeling nontermination alternatively languages such as and f identify a restricted of pure total functions however neither of these approaches provide equal support for total and partial programming we compare them to our work in section combining proofs and programs before the semantics of we conclude this section with a number of examples to demonstrate the key ideas in declarations must indicate whether they belong to the logical or fragment of the language for example a boolean negation operation is trivially terminating so it is in the logical fragment as indicated by the tag log in its definition log not bool bool not b if b then false else true likewise addition for natural numbers can be shown terminating via natural number induction in the case expression below plus may be called on any subterm of its argument the argument is a proof that n is a subterm of n log plus nat nat nat ind plus n m case n of zero m succ n succ plus n m alternatively the following natural number division function diverges when m is so it must be tagged with prog the rec keyword indicates that this function is implemented using general recursion prog div nat nat nat rec div n m if lt n m then else plus div n m m subsumption all proofs can be used as programs in the above example even though the plus operation is logical we can use it and other logical operations such as lt and directly in a term and call it on an argument whose termination behavior is unknown thus the fact that we know that plus terminates does not restrict how it may be do not proofs available at implementation available at in the branch need to duplicate its definition for it to be available to both fragments proofs containing programs the type allows values to be embedded from one fragment into another for example the logical language can safely manipulate values as long as their types indicate with p that they are below consider the definition of a maybe datatype that could contain arbitrary programs data maybe a type where nothing just of a p as long as the component is treated carefully expressions in the logical fragment can work with this data structure this includes constructing values of the maybe type and pattern matching on the data structure log md maybe nat nat md just x div x log foo maybe nat nat nat nat p foo x case x of just y y nothing x x however if the component is ever used then the definition must be marked as as an embedded function could cause divergence prog bar maybe nat nat nat maybe nat bar x y case x of just f just f y nothing nothing prog maybe nat bar md proofs about programs having defined the function div we might wish to verify facts about it as a simple example we prove that div evaluates to we can state and prove these facts using the logical language even though the object of study may not terminate log div div div refl the proof above refl is valid when both sides of an equality proposition evaluate to the same result to avoid infinite loops the typechecker will give up and signal an error if the expression does not reach a normal form within steps if more evaluation is required the programmer can write eg refl in languages like or f this theorem cannot even be stated because expressions such as div cannot appear in types this example illustrates an important property of our language which we call freedom of although proofs cannot themselves use general recursion they are allowed to refer to arbitrary expressions as a more complicated example we might wish to prove that if the is not zero then the result is less than the in other words log eq m false le div n m n true above eq is an equality function for natural numbers and le m n determines whether m n we do not show proof of the above theorem here though it is available with our implementation the proof itself uses strong natural number induction to simultaneously show both that division terminates and that the property above holds for the result note that we can only show properties that are provable via finite reduction sequences for example we cannot show that division diverges when the is because that divergence is not finitely observable the logic does not have a general principle for reasoning about nonterminating programs such as fixedpoint induction we return to this issue in section programs that return proofs an alternative to writing separate proofs about nonterminating programs is to give the programs themselves more specific types that express their correctness for example consider writing a sat solver that we do not want to prove terminating a sat solver takes a formula of n variables and if the formula is satisfiable returns a satisfying assignment for some subset of those variables we can represent the result of a sat solver using the following datatype declaration the result for a given formula is either an assignment together with a proof that that assignment satisfies the formula or when the formula is unsatisfiable data ans n nat form formula n type where sat of assign vector maybe bool n proof satisfies assign form just true maybe bool the main loop of the solver itself takes a formula and the current assignment and returns whether that assignment can be extended to a satisfying one if the current assignment is known to be satisfying then that one is returned can automatically fill in the below with the proof that assign satisfies the formula if the assignment is known to the formula then the result is otherwise the algorithm must search for an extension to the assignment using techniques such as unit propagation pure literal assignment or merely trying both possibilities for an variable prog solver formula formula n vector maybe bool n ans n formula l solver n formula assign case satisfies assign formula of just true sat assign just false nothing since the solver is written in the fragment it may not terminate it also may fail to find an assignment even though the formula was satisfiable however the type of this function is more informative than if it had been written in ml or haskell the l in its type indicates that if it does return a proof of satisfiability then that value was type checked in the logical fragment when a program contains subexpressions from both fragments values can be handled more freely than expressions for example a logical expression cannot call solver directly because of the possibility of divergence however if the result of that call has already been bound to a variable then the logic has access to that result let prog f formula n in let log empty repeat nothing maybe bool n in let prog solver n f empty ans n f l in let log case of sat assignment pf use proof of satisfiability l p a b a b x a b a b nat a b x ab µx a a x x a rec f x a ind f x a a b refl inl a inr b a of inl x a inr y a a b a of x y b z s a a of z a s x a roll a a v ab x a b a b nat a b x ab µx a a x x a rec f x a ind f x a refl inl v inr v v v z s v roll v slam x a v v x a rec f x a v v x rec f x af a ind f x a v v x yz ind f x a yf a inl v of inl x a inr x a v x a inr v of inl x a inr x a v x a v v of x y a vx roll v v figure expressions values and operational semantics mobile types finally some types have the same meaning in both fragments so they do not benefit from being tagged with a consistency classifier for example a value of type nat can never cause divergence so it is safe to be used in logical expressions even when not marked as l similarly the ans type above is also mobile so the l annotation on the type of solver is actually unnecessary this observation simplifies programming as the only function arguments that must be annotated with their fragment are those that are not mobile the language we begin our technical development with an overview of the formal language this language is based on a callbyvalue cbv variant of lambda calculus its syntax is shown in figure for terms types and the single kind the type of types are drawn from the same syntactic category as in pure type systems the first two lines of the figure list the type forms the following lines list the terms by convention we use metavariables a b for expressions that are terms and metavariables a b for expressions that are types the values v and key rules of the operational semantics are also shown in figure the reduction relation a b defines a smallstep callbyvalue semantics the slightly beta rule for natural number induction is described in section to save space most rules have been omitted the full set of rules can be found in the companion technical report values include the standard components of functional programming recursive functions rec f x a nonrecursive functions x a natural numbers constructed by z and s a and eliminated by disjoint unions constructed by inl a and inr a and eliminated by dependently typed pairs constructed by a b and eliminated by and recursive data introduced by roll a and eliminated by a values also include all type forms a trivial equality proof refl and variables including variables is safe because cbv evaluation only values for variables and it is useful because it allows the type checker to reduce open terms we chose cbv because of its simple cost model but this choice also affects the interaction between the logical and fragments as shown in sections and the type system takes advantage of the fact that values cannot induce nontermination as a result some typing rules apply only to values note that expressions do not contain type annotations types describe terms but do not interfere with equality we do not want terms with the same runtime behavior to be considered just because they have different annotations due to the lack of annotations it is not possible to compute the type of a term this is not a problem because we do not intend programmers to write these terms directly instead our implementation uses an annotated surface language that the type checker into typing derivations see section the rest of this section describes the specific details of including its basic judgements section and treatment of equality section in the next section we introduce the novel features of our language that permit the interaction between the logical and fragments of the language terminating and nonterminating expressions the starting point for is a dependent type theory where the typing judgment a a is indexed by a consistency classifier the judgement is designed so that expressions that type check at l always terminate figure shows the typing rules for the basic building blocks of the functions and various data structures and their types because we work with a syntax we use the type system to identify which expressions are types a is a wellformed type if a contexts are lists of assumptions about the types of variables x a each variable in the context is tagged with to indicate its fragment and this tag is checked in the typing rule a context is valid written if each type a is valid in the corresponding fragment the rules and check types for for example checks a function type by checking the the domain and range we discuss the premise mobile a which asserts that a is a mobile type in section there are three ways to define functions in rule types nonrecursive expressions in the logical fragment whereas rule types general recursive and can only be used in the fragment additionally terminating recursion over natural numbers is provided in the logical fragment by rule when typechecking the body of a terminating recursive function ind f x b the recursive available from and as university of pennsylvania technical report · cnil x a x a aa x a x a a mobile a x a b x a b b x a b a a ax b b a ax b x l a l b b l x a b l x b x a b f p x a b x p a p b b p x a b p rec f x b x a b x l nat f l y nat z s y x b l b b l x nat b l ind f x b x nat b a b ab aa ab inl a a b bb ab inr b a b a a a b x a z l inl x a b b x a z l inr x a b b a of inl x b inr x b b a mobile a x a b x ab x ab aa b ax b ax b a b x ab a x aa b x a y a z l x y a b b a of x y b b a µx ax a x l l a µx a l µx a roll a µx a p a µx a p µx ax a p a µx ax a figure typing variables functions and datatypes rules for nat omitted call f takes an extra argument proving that it is being applied to the predecessor of the initial argument x this ensures termination when such an expression this argument is ignored by the function in an extra lambda rule from figure the rule for function application differs from the usual application rule in pure languages in the additional third premise ax b s which checks that the result type is wellformed some rules of the language such as reduction are sensitive to whether terms are values because values include variables substituting an expression a for a value x could cause b to no longer type check any dependently typed language that combines pure and effectful code will likely have to restrict the application rule in some way previous work uses a more restrictive typing for applications by splitting it into two rules one which permits only value dependency and requires the argument to be a value and one which allows a function to be applied to an arbitrary argument since substituting a value can never violate a value restriction in b our application rule subsumes the version likewise in the case of no dependency the premise can never fail because the substitution has no effect on b being able to call dependent functions with arguments is useful when writing explicit proofs for example a programmer may want to first prove a lemma about addition log plus n n and then instantiate the lemma to prove a theorem about a particular expression in the logical fragment f x plus f x f x the rules for sum types and provide dependent case analysis the term binds the logical variable z inside both branches of the case this variable provides an equality between the and the pattern of the branch so that type checking is flowsensitive at runtime this variable is replaced by refl because the must match the pattern for the branch to be taken the rules for dependent products allow the type of the second component of the pair to depend on the value of the first component as with function application the premise ax b ensures that substituting the expression a does not violate any assumptions made about the value x in the type of the second component analogously to sums the for pairs makes available a logical proof z that the to the pattern in the body of the match the availability of this equality means that the strong elimination forms projections for types are derivable finally the rules and deal with general recursive types these are the standard rules for types see eg but recursive types with negative is with the recursive variable appearing to the left of an arrow such as µx x a potential source of nontermination to ensure normalization it suffices to restrict the the elimination rule to be in p the introduction rule can be used in both fragments this reflects the fact that it is not to construct negative datatype values the potential nontermination comes from their elimination reasoning about equivalence a big benefit of combining with dependent types is that it is possible to write proofs about programs for example in the introduction we showed a proof that when the is not zero natural number division produces a result less than the aa lab a c b c a a b b l refl a b l b b b a bx a bx a a bx a figure typing equality our rules for propositional equality figure are designed to support such reasoning uniformly based only on the runtime behavior of the expressions being and independent of the fragment that they are defined in therefore the rule shows that the type a b is wellformed and in the logical fragment even when a and b can be type checked only this is freedom of proofs can refer to nonterminating programs the term refl is the primitive proof of equality rule says that refl is a proof of a b just when a and b reduce to a common expression the notion of reduction used in the rule is parallel reduction denoted a b this relation extends the ordinary evaluation a b by allowing reduction under binders eg x x even though x is already a value having this extra flexibility makes equality more expressive and simplifies the proof of preservation proven equalities are used to substitute expressions in types by the elimination rule the proof term is checked in l to ensure it is a valid proof we demand that the equality proof used in conversion type checks in the logical fragment for type safety all types are in the fragment so if we permitted the user to convert using a proof of say nat nat nat it would be easy to create a stuck term similar to we need to check that b does not violate any value restrictions so the last premise checks the wellformedness of the type given to the converted term rule is quite general and may be used to change some small part of a or the entire type by x for a this treatment of equality is a variant of et al however that setting did not include a logical instead it enforced soundness by requiring the proof term used in conversion to be a value uses of are not marked in the term because they are not relevant at runtime again types should describe terms without with equality we do not want terms with the same runtime behavior to be considered due to uses of conversion interactions between the fragments what is interesting about is how its two fragments interact in the introduction we discussed ways in which logical and terms work together below we discuss the technical machinery of the type system that supports this interaction subsumption every logical expression can be safely used we reflect this fact into the type system by the rule which says that if a term a type checks logically then it will also type check for example a logical term can always be supplied to a function a argument this rule is useful to avoid code duplication a function defined in the aa p a a v a a v a a l a a a a aa a p a a pv a pa l v ap figure typing subsumption and consistency classification logical fragment can be used without in the fragment subsumption also eliminates duplication in the design of the language for example we need only one type a b to talk about when two or two logical terms are equal in fact we can also logical and expressions consistency classification to provide a general mechanism for logical expressions to appear in programs and values to appear in proofs we introduce a type that the typing judgment written a nonterminating programs can take logical proofs as preconditions with functions of type x al b return them as postconditions with functions of type x a b l and store them in data structures with pairs of type x ab l at the same time logical lemmas can use to manipulate values from the fragment the rules for the a type appear in figure intuitively the judgment a a holds if the fragment may safely observe that a a this intuition is captured by the three introduction rules the fragment can any typing judgement but in the logical fragment and we sometimes need a restriction to ensure termination therefore rule only applies when the subject of the typing rule is a value the rule can introduce a for any since logical terms are also both introduction and elimination of is in the syntax so the reduction behavior of an expression is by whether the type system it to be provably terminating or not for example a recursive function f can require an argument to be a proof by marking it l eg al b forcing that argument to be checked in fragment l similarly a logical lemma g can be applied to a value by marking it p p f al b p a al pf ab pv a l g ap b l v ap b of course g can only be defined in the logical fragment if it is careful to not use its argument in unsafe ways for example using we can prove a lemma of type n nat f nat f plus n f n because reasoning about f does not require calling f at runtime mobile a mobile a mobile a b mobile a mobile b mobile x ab mobile nat mobile a mobile b mobile a b aa pv a la lv a mobile a a a a b x a z l inl x a b b x a z l inr x a b b a of inl x b inr x b b a x aa b x a y a z l x y a b b a of x y b b figure typing mobile types and case expressions there is no way to apply a logical lemma to a expression if an expression a may diverge then so may f a so we must not assign it a type in the logical fragment however we can work around this restriction by either first evaluating a to a value in the fragment or by the types are eliminated by the rule to preserve termination the rule is restricted to apply only to values recall the function solver of type prog solver n vector maybe bool n ans n fl in the introduction we that the following code type checks let prog solver n f empty ans n f l in let log case of sat a pf here pf is logical in this example the logical program cannot directly treat solver n f empty as a proof because it may diverge however once it has been evaluated to a value it can be safely used by the logical fragment above the let binding forces evaluation of the expression solver n f empty introducing a new variable ans n f l into the context because variables are values any logical context can freely use the variable through even though it was computed by the language mobile types the consistency classifier tracks which expressions are known to come from a normalizing language for some types of values however the rules described so far can be conservative for example while a expression of type nat may diverge a value of that type is just a number so we can treat it as if it were logical on the other hand we can not treat this is one of working in a strict rather than a lazy language if we know that f is nonstrict then this application is indeed safe a function value as logical since it might cause nontermination when applied the rule figure allows values to be moved from the to the logical fragment it relies on an auxiliary judgment mobile a intuitively a type is mobile if the same set of values the type when l and when p in particular these types do not include functions though any type may be made mobile by tagging its fragment with concretely the natural number type nat is mobile as is the primitive equality type which is by the single constructor refl as discussed in section any type is mobile since it a particular independent of the one on the typing judgment sum and pair types are mobile if their component types are even if a sum type is not mobile it is always safe to do one level of pattern matching on one of its values since such a value must start with a constructor we reflect that in the rule which generalizes from the previous section this rule allows a that type checks in one fragment to be eliminated in another fragment this lets the logical language reason by case analysis on values similarly is a more general version of the rule the two rules shown here are the ones actually included in our formalization the mobile rule lets the programmer write simpler types because mobile types never need to be tagged with logical for example without loss of generality we can give a function the type a b b instead of a bl b since when needed the body of the function can treat the argument as logical through similarly multiple s have no effect beyond the innermost in a type values of type can be used as if they had type ap in fact the arguments to functions must always have mobile types this restriction enforced by rule means that higherorder functions must use types to specify which fragment their arguments belong to for example the type nat nat a is not wellformed so the programmer must choose either nat a or nat a in either case programmers benefit from implicit for example checking wellformedness of a type like f nat f plus n f n implicitly uses but the equation still about the expression f n if we instead had to use explicit to eliminate the type as in unbox f n there would be no way to write a logical lemma proving the original equation by contrast mobile arguments do not need nor benefit from tagging the reason that function arguments must be mobile is to account for through subsumption we can introduce a function in the logical fragment and use it in the x l a l b b l x b x a b p x b x a b here the definition of b assumed x was logical yet when the function is called it can be given a argument for this derivation to be sound we need to know that a means the same thing in the two fragments which is exactly what mobile a checks metatheory we now describe the metatheory of we are interested in two properties first that the entire language is type safe including both the l and p fragments second that any closed term in the l fragment which implies logical consistency type safety is proven using standard progress and preservation theorems since the rules and allow stuck terms to type check given a contradiction the progress theorem depends on logical consistency for this reason we first prove preservation then normalization and consistency and finally progress the theorems in this paper have been checked in coq to prove certain facts about our logical relation we needed a standard axiom of functional this axiom is known to be consistent with logic preservation as usual the preservation proof relies on weakening substitution and inversion lemmas the weakening lemma is standard due to the value restrictions in the type system the substitution lemma is restricted to values lemma substitution if x b a a and v b then v x v x a v x a however our inversion lemmas are more complicated than usual because one of the design goals of is that typing rules without runtime effects should not require annotation in particular uses of and are not marked for example consider inversion for expressions usually it is the case that if xb a then a is with some arrow type x b b and x b b b in this is not true if there were a hypothesis x l nat nat nat the expression could also have been given type nat using restricting preservation to empty contexts would not help since at this point in the proving cannot rule out that this equality is provable alternatively if the box rules were used a may be an type taking this into account our inversion lemma reads lemma inversion for expressions if x b b then there is some p and x b b such that either l p b x b b and x b b b or there are some such that l p b x b b and x b b b with this and other similar inversion lemmas we can prove preservation theorem preservation if a a and a a a a then the proof of the preservation theorem requires the addition of type constructor and rules figure to the type system the rule eliminates equalities if we can prove a contradiction we must be in unreachable code so we allow giving any expression a any wellformed type b at any an equation b b counts as if the head forms of both sides are defined and the head form of a type is its outermost constructor for example the head form of x a b is and the head form of nat is nat the complete definition of appears in the companion technical report the rules equality proofs between type forms for example from a proof l p x a a x b b we can also derive l p a b similar typing rules are available for sum and pair types these are here for space but included in the technical report these rules are by the weak inversion lemmas consider eg the case when a function application beta reduces x b v v x b from the premises of the rule we know that x b x a a and v a and from aa a x a a x b b a b a a b a x a a x b b v a v x a v x b a v x a v x b l a b b aa a b ab figure typing and of type constructors rules for µ pair and omitted inversion we know either l p x a a x b b and x b b b or else x a a is provably equal to an type in the first case we apply the substitution lemma using to prove a b while in the second case we use normalization and progress our proof of normalization builds upon the standard method in a formulation the of this method is to define a type interpretation for each type a we define a set of values that check in fragment the additional inputs and k are discussed below the definition of the type interpretation figure is a logical relation and follows the structure of a our main theorem is that the interpretation is sound any closed logical expression a of type a reduces to a value in the rules and can move values from p to l so for the proof to go through we must generalize the soundness theorem to also characterize expressions in p for these values we prove a partial correctness property if a closed expression a of type a reduces to a value then the value is in these invariants are summarized by a computational type interpretation which identifies sets of expressions and is defined mutually with the type interpretation for expressions must ac count for recursive functions and recursive types which means that it cannot be defined by recursion on a instead we use step indexing the interpretation is indexed by a number k any value v in will be wellbehaved for at least k steps of execution the interpretation is defined by wellfounded recursion on the ordered triple k a i where i is one of c or v with v c however the usual formulation of a stepindexed type tation only itself to proving safety tells us that an expression will not do anything bad for the next k steps by con normalization is a liveness property every expression will eventually do something good namely reduce to a value in our definition we take a hybrid approach by only counting steps that happen in the p fragment the difference can be seen by comparing the definitions of vx a b lk and vx a b pk which say j k and j k respectively if all s in a tion are l then no inequalities are strict so the k never needs to decrease the input is a substitution mapping free variables of a to values we use when interpreting equality types the type a a is interpreted as the singleton set refl if a and a parallel reduce to a common expression and as the empty set otherwise we inductively define the judgment k which asserts that maps to values in the correct interpretation by · k k v a x a k x v intuitively k asserts that maps term variables to wellbehaved values because of the premise a it also asserts that does not contain any type variables this is true for the empty context and preserved by each case of the type interpretation in a normalization proof for system f or for cc the type interpretation would take an input which specifies the interpretation of type variables in a but not one which specifies the values of term variables since we do not have polymorphism in our language we do not need to account for type variables but unlike cc because of the primitive equality type we can not just ignore term variables in types our is similar to normalization proofs for systems that have large elimination of datatypes such as the soundness theorem relies on a few key lemmas about the interpretation the first is a standard downward closure property for stepindexed relations it says that requiring values to wellbehaved for a larger number of steps creates a more precise interpretation lemma for any a and if j k then the next two lemmas are specific to because they relate the l and p interpretations of a type they are used to handle the and rules respectively the first says that the set of logical values is a subset of the corresponding sets lemma for any a k and and the second says that for mobile types the reverse containment also holds for these types the interpretations contain the same values in both fragments lemma for any k and if mobile a then finally for the rule we need equal types to have the same interpretation lemma suppose b a and b a and b and b and k then a iff a we can now prove soundness by induction on a a normalization is an immediate corollary we also get a characterization of which terms can be proven equal in the empty context we need such a characterization to prove progress theorem soundness if a a and k then a corollary normalization if · l a a then there exists a value v such that a v corollary soundness of propositional equality if · l a a a then there exists some a such that a and a a a v k v · v v v is of the form sn z va k v · a and v vx a b lk x b · l x b x a b and j k if v then v x b lj ind f x b · l ind f x b x a b and j k if v then v x yz ind f x b yf b lj vx a b pk x b · p x b x a b and j k if v then v x b jp rec f x b · p rec f x b x a b and j k if v then v x rec f x bf b pj ind f x b · p ind f x b x a b and j k if v then v x ind f x bf b pj va b k inl v · a b and v inr v · a b and v vb k vx ab k v v · x ab and v and v k ak roll v · roll v µx a and j k v ax aj va ak refl · a a and a a and a a for some a otherwise a · p a a and j k if a j v then v a · l a a and a v figure type interpretation normalization holds only for closed terms this is a result of the fact that uses of the rule are in the syntax it is possible to assume a equality and use it to typecheck a nonterminating term in the logical fragment for example the following statement is derivable y l nat nat nat l x x x x x x nat this distinguishes from intensional type theories like coq and agda in those systems our rule arises as the patternmatching elimination form for a defined equality datatype uses of this would appear in the term above and their reduction would get stuck on the variable y since it does not reduce to the appropriate constructor the benefit of giving up normalization of open terms is a more equality since uses of conversion appear in terms in coq and agda they often get in the way of two terms which use such conversions equal in our system this can not happen the is that the typechecker can not automatically expressions since they may diverge so uses of refl must be explicit and annotated with a maximum step count however in a language with general recursion some explicit proofs are since checking a logical term can involve reducing a term that appears in its type since our language must accommodate such proofs in any case making conversion is the progress theorem relies on a canonical forms lemma in the and cases we need to know that there are no proofs of inconsistent equalities such as nat nat nat therefore this lemma relies on corollary the progress theorem is then an easy induction on · a a surface language elaboration annotated language zt derivations erasure core language zt figure implementation theorem progress if · a a then either a is a value or there exists a such that a a implementation we have implemented a prototype language called based on we have used this implementation to gain experience with the features described in this paper indeed all of the example code in this paper can be by our implementation these and other examples are available for our language includes several features which were left out of to keep the normalization proof simple instead of a single sort includes a full predicative hierarchy which allows both polymorphism and typelevel functions we also include a general form for parameterized recursive datatypes which subsumes nat a b x ab and µx a datatypes are always mobile and provides structural induction for all strictly positive datatypes not just nat following finally distinguishes between computationally relevant and irrelevant arguments and includes a conversion operator called adding these features to would the type interpretation increasing the complexity of our proof far beyond its current state in particular to add predicative polymorphism and typelevel computation we would have to our type interpretation as an induction over typing derivations which is very to do in coq however based on work in progress we are optimistic that the requirements of these additional features will have little interaction with the fundamental consistency mechanism proposed here the general structure of our implementation appears in figure the part of our implementation that most closely is the internal language zt this language defines the operational behavior of expressions however like type checking is not decidable for zt expressions therefore the implementation also includes an annotated version of zt that supports syntaxdirected type checking an approach we have explored in previous work annotated zt is a direct representation of zt typing derivations marking all uses of conversion subsumption and coercion to and from a types furthermore because reduction may not terminate annotations on refl control and limit the search for a common when proving that two terms are equal directly working with zt derivations a considerable annotation burden for programmers therefore the surface language makes these annotations optional we are currently with a number of elaboration strategies to infer these annotations these include using bidirectional type checking to propagate type information through terms unification to automatically infer some dependent arguments and congruence closure to automatically infer equality proofs used in conversions for example consider the projection functions fst and snd for dependent pairs shown below these functions pattern match their argument and return its first and second components respectively data ba type type where pair of xa y b x log fst ba type a b a fst a b p case p of pair x y x log snd ba type a b b fst p snd a b p case p of pair x y unfold fst p in y in the implementation of snd unification can infer the arguments a and b to fst which were marked by the the declaration of fst because not all expressions terminate the programmer must explicitly ask the type checker to unfold fst p by reduction which introduces the equation fst p x into the context that equation is then automatically used to convert the type of y from b x to b fst p the examples we have implemented fall into two categories the first includes the division and programs described in section these examples illustrate how one can write proofs about general recursive programs and how general recursive programs can return proofs second we have implemented functions for lists vectors finite sets represented as binary search trees and data compression using encoding together with proofs of their correctness since these functions use simple structural recursion they can be done entirely in the logical fragment they show that although our core language requires annotations on refl and the overhead of these annotations is related work in previous work we introduced the proof technique of hybrid logical relations but for a simplytyped language this paper extends the normalization proof to a more expressive type system with dependent function types an equality type and conversion it also improves the treatment of types by making them implicit this change the metatheory see lemma but makes the language more expressive and simplifies the application rule terminating there are other languages which allow general recursion but identify a of terminating expressions and f do this using the kind system expressions whose type has kind prop are checked for normalization types can contain values but not expressions so there is no way to write separate proofs about programs there also is no facility to treat values as proofs eg a logical case expression cannot a value from the nonterminating fragment and are languages where the logical and fragments are syntactically effect the rule one of the of this separation is that the logical language can be made even though the one is cbv avoiding the need for as discussed in section to do inductive reasoning the language adds an explicit terminates predicate is a dependently typed programming language that permits definitions internally it applies a syntactic test to check if function definitions are structurally decreasing and programmers may ask whether particular definitions have been total the type checker will only reduce expressions that have been proved terminating again separate equational reasoning about partial programs metatheory has not been studied formally monad monad uses coinductive types to embed general recursion into type theory this approach treats pure functions as the default and nontermination less nonterminating programs must be written using monadic combinators and are therefore never syntactically equal to pure programs the monad provides recursive function definitions but not general recursive types furthermore the coinductive approach requires a separate notion of equivalence to reason about partial programs in eg coq one would compare pure expressions according to the standard operational semantics but define a equivalence relation for partial terms that ignores the number of steps they take to equations like rec f x b v v x rec f x bf b do not hold with the usual coq equality because the step counts differ programming with equivalence relations like this which are not directly justified by the reduction behavior of expressions is an active area of research involving topics such as types and the axiom fixpoint semantics the work of and describes a way to embed general recursive functions into coq that does not use coinduction they define a datatype partial a that is isomorphic to the usual maybe a but is understood as representing a lifted cpo a and use classical logic axioms to provide a fixpoint combinator when defining a recursive function the user must prove continuity since recursive functions are defined they can not be reduced directly so instead one must reason about them using the fixpoint equation partial types has at its core an untyped lambda calculus capable of defining a general fixed point combinator for defining recursive computations in the core type theory all expressions must be proven terminating when used and smith integrated potentially nonterminating computations through the addition of a type a of partial terms of type a the fixpoint operator then has type a a a however to preserve the consistency of the logic the type a must be restricted to admissible types crary provides an expressive axiomatization of admissible types but these conditions lead to significant proof obligations especially when using types smith provides an example which shows that needs this restriction writing a for a terminates define a type t of functions which are not total and recursively define a p which t total f n n def n n f n t def f n f false p t def fix p g h g def x then else px here the is an proof which derives a contradiction using p and the hypothesis h that g is total on the other hand a separate induction shows that p is total it returns for all arguments this is a contradiction has almost all the for this instead of a recursively defined pair we can use a recursive function unit t and we can encode a as y aa y what us is that the proof in the second component of p uses the following reasoning principle if p terminates then p terminates in a is a primitive predicate and this inversion principle is built in but using our encoding a function p p would have to guess the second component of a pair knowing only the first component if we assume this function as an axiom we can encode the and derive inconsistency so our consistency proof shows that there is no way to write such a function hoare type theory is another embedding of general programs into a type theory like coq which goes beyond nontermination to also handle memory effects instead of a unary type constructor a it adds the indexed type p x aq representing an effectful computation returning a and with pre and postconditions p and q the assertions p and q can use all of coq so the type of a computation can specify its behavior precisely however computations can not be evaluated during type checking the fixpoint combinator and memory access primitives are implemented as coq axioms with types but no reduction rules fixpoint induction based provide two basic reasoning principles for proving properties about recursive functions unfolding a function definition and fixpoint induction the latter principle see eg states that to prove a property about a function one may assume it as an induction hypothesis for the recursive calls of the function for this to be valid the property must be admissible and it most hold for infinite loops an equivalent variant is to allow induction on the number of recursive steps an expression takes to currently provides no such principle if a theorem can not be proved just from unfolding there are two ways to proceed in order to prove in section we used strong induction for this strategy to work the programmer has to find a termination metric for the function in question so it only works for functions that are in fact terminating however it can still be convenient to give a direct recursive definition of the function for functions that do not terminate one can instead change them to return a type the property so that the property is automatically available for recursive calls this is what we did for solver in section and it is the only option in hoare type theory modal types for distributed computation modal logic reasons about statements whose truth in different possible worlds our type system is formally similar with the possible worlds being l and p modal logic has previously been used to design type systems for distributed computation in particular was inspired by ml in which the typing judgment is indexed by what world computer in a distributed system a program is running on and which includes a type a that judgment our rule is similar to the get rule in ml and our mobile a is similar to the judgment a mobile in ml on the other hand unlike ml does not require that the domain of an arrow type be mobile as we explained in section we make that restriction to accommodate our rule a rule which does not make sense in the context of distributed computation future work in future work we hope to extend the metatheory of to include more of zt we plan to allow polymorphic types and typelevel functions in both the l and p fragments extending our proof using ideas from normalization proofs for the calculus of constructions following the ideas of and and their language we also hope to add combinators to define recursive functions over recursive data to the logical language places no restriction on what sorts of datatypes can be defined or how they can be constructed instead it limits the analysis of data structures to ensure the soundness of the logic more generally we would like to extend our proofs to a general theory of datatype definitions maybe encoded via recursion sums and products as in one potential is that we assume for all type constructors which can be used to encode we hope to avoid inconsistency by impredicative polymorphism and datatypes with large indices adding these features will require substantial additional work in the normalization proof but we do not any changes to the novel typing rules that connect the l and p fragments reasoning about general recursive functions currently lightweight verification in order to turn it into a tool for full verification of potentially nonterminating programs we would add stronger reasoning principles first the value restrictions in can get in the way of equational reasoning if a is an expression in p there is no way to prove an equation like let x a in f x f a even though the two sides are in fact contextually equivalent to make it provable we could add case analysis on whether a expression evaluates to a value or diverges unfortunately this operator is so we would not want to allow proofs that use this reasoning to be used as programs one solution is to introduce a new consistency classifier o for in addition to l and p by not allowing o expressions to be used as programs we could control and track the use of termination case second we would like to investigate whether some perhaps form of fixpoint induction can be consistently added the experience with partial types in suggests that this may require a notion of admissible predicates conclusion this paper presents a framework for interacting logics and programming languages the consistency describe the set of typing rules that determine the properties of each welltyped expression at the same time many standard typing rules are polymorphic in this classifier leading to between the systems this judgment as a type and observing that some values can move freely allows the fragments to interact in nontrivial ways leading to an expressive foundation for programming acknowledgments this material is based upon work supported by the national science foundation under grant and the implementation was developed with the of the team and the ideas in this paper greatly from that this paper was written with the help of the tool the authors would also like to thank the anonymous reviewers for their considered and helpful comments references ahmed a stepindexed syntactic logical relations for recursive and quantified types in esop european symposium on programming lncs vol springer t a hierarchy of style recursion combinators inductive datatypes with negative occurrences in icfp international conference on functional programming pp ­ acm t m pitts am the programming language work in progress talk presented at the th symposium on implementation and application of functional languages t na a n dependent types without the sugar functional and logic programming pp ­ appel aw d an indexed model of recursive types for foundational proofcarrying code acm trans program lang syst ­ l ­ a language with dependent types in icfp international conference on functional programming pp ­ acm barendregt hp lambda calculi with types in abramsky s dm eds of logic in computer science pp ­ oxford university press g v o in type theory journal of functional programming ­ y v fixed point semantics and partial recursion in coq in principles and practice of declarative programming pp ­ acm ec programming meets full dependent types in programming languages meets program verification pp ­ acm v general recursion via coinductive types logical methods in computer science ­ c v weirich s stepindexed normalization for a language with general recursion in structured functional programming vol pp ­ chen c xi h combining programming with theorem proving in proceedings of the acm sigplan international conference on functional programming pp ­ icfp acm new york ny usa rl smith sf partial objects in constructive type theory in logic in computer science lics pp ­ ieee crary k type theoretic methodology for practical programming languages phd thesis cornell university h a short and flexible proof of strong normalization for the calculus of constructions in types lncs vol pp ­ girard jy et des de phd thesis paris vii l ja k j l j s a programming language for and in icfp international conference on functional programming pp ­ acm l walker d modal proofs as distributed programs extended abstract in esop european symposium on programming lncs vol pp ­ springer g a iii hd fu p t weirich s c v n equational reasoning about programs with general recursion and callbyvalue semantics in programming languages meets program verification acm dr harper r dependent types in programming languages meets program verification pp ­ acm z computation and reasoning a type theory for computer science oxford university press usa c j the view from the left j program ­ a the implicit calculus of constructions extending pure type systems with an intersection type binder and subtyping in of th international conference on typed lambda calculi and applications lncs vol pp ­ springer vii t crary k harper r typesafe distributed programming with ml in global computing a morrisett g a p birkedal l dependent types for imperative programs in icfp international conference on functional programming pp ­ acm r a fast congruence closure and extensions inf comput ­ u towards a practical programming language based on dependent type theory phd thesis university of technology s d weirich s g simple type inference for gadts in icfp international conference on functional programming pp ­ acm pierce bc types and programming languages mit press pierce bc turner dn local type inference in acm symposium on principles of programming languages popl san diego california sewell p f s g t sarkar s r effective tool support for the working j program ­ t n programming in in z r a v eds nd central european functional programming school lncs vol pp ­ springer v c n iii hd fu p g t a weirich s heterogeneous equality and callbyvalue dependent type systems in structured functional programming vol pp ­ smith sf partial objects in type theory phd thesis cornell university a m a t tw verified programming in in t td eds pp ­ acm k birkedal l a state and dependent types in typed lambda calculi and applications lncs vol pp ­ springer n chen j fournet c py k yang j secure distributed programming with types in icfp international conference on functional programming pp ­ acm ww intensional interpretations of of finite type i the journal of symbolic logic pp ­ the coq development team the coq proof assistant reference manual version inria the coq development team the coq proof assistant frequently questions inria the foundations program type theory foundations of mathematics b des constructions phd thesis paris g the formal semantics of programming languages an introduction mit press cambridge ma usa 