scheduling using polyhedra inria and inria and abstract polyhedral compilation has been successful in the design and implementation of complex loop nest and compilers the algorithmic complexity and scalability limitations remain one important we address it using of the systems of constraints resulting from affine scheduling problems we propose a scheduling technique using or utvpi polyhedra this technique relies on simple polynomial time algorithms to a general polyhedron into utvpi polyhedra we modify the compiler using our scheduling technique and show that for a of the kernels the above yield polyhedra that are nonempty solving the system leads to asymptotic in complexity and shows practically significant improvements when compared to a traditional lp solver we also verify that code generated by our parallelization prototype matches the performance of code when the underapproximation preserves feasibility categories and subject descriptors d programming languages optimization general terms approximations complexity scheduling optimization performance keywords approximation algorithms complexity theory compiler optimizations parallelism loop transformations affine scheduling optimization geometric algorithms motivation polyhedral compilation is well established as the most effective framework to reason with loop programs at its lie the representation of loop as polyhedra and the search for their loop transformations in general semantics preservation amounts to the feasibility of rational polyhedra while performance and are related to optimization on rational polyhedra this simplicity is both the strength as well as the of polyhedral compilation strength because polyhedral abstractions are extremely powerful to analyze loops encoding permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm of useful transformations with the ability to automatically and tile them on architectures being one of the main practical applications and because the of polyhedra itself becomes an due to the complexity of its core algorithms this latter issue creates a practical challenge when programs of nontrivial size are being compiled our view is that using approximations of polyhedra and provides a solution for this scalability challenge in a previous paper we proposed different directions for compilation where approximations of general convex polyhedra could be used so that the problems that are being solved by polyhedral compilers can be made scalable with worstcase polynomial time guarantee this was followed by the introduction of scheduling in where we proposed using utvpi to reduce the complexity of affine scheduling in the current paper we build from the above works and make progress towards polyhedral that are scalable in the program size our techniques rely on strongly polynomial algorithms ie whose time complexity is polynomial only in the number of integers in the input and not on the of the input encoding for example we are able to substitute linear programming with flow and shortest paths problems which are solvable using graph theoretic methods like the well known algorithm our method applies to and depth minimization approaches like algorithm as well as methods on loop tiling like et als polyhedral compilation affine scheduling now is a part and of many compilers which to compile for parallel architectures gcc llvm ibm xl the work of the of affine transformation methods building on the affine form of the lemma this approach has been refined extended and applied in many directions to only two recent at the two of the complexity the algorithm of et al extending the forward communication only principle of et al for parallelization and the complete convex characterization of and exploration heuristic of et al much progress has been made in the understanding of the theoretical and practical complexity of polyhedral compilation problems nevertheless when considering affine transformations none of these are strongly polynomial in the size of the program the lowest complexity heuristics such as are reducible to linear programming which is only weakly polynomial its traditional implementation being associated with large memory requirements and having a worstcase exponential complexity of a current scheduler time taken seconds vs number of dependences time taken seconds dependences figure for large loop programs in this section we show an example of of current methods in we have two typical kernels from and by a variable number of times so as to increase the number of dependences in the loop we have also the loops in two time loops the behavior of a scientific computing kernel the above transformations induce of dependences in the input program the compilation times are shown in figure with in blue and in red we checked that the compilation time trans time of increases in a roughly n complexity in the number of statements in the system the rest of the modules of particular dependence analysis and code generation took significantly less than the above it may seem that the above unrolling based method is an artificial way to induce with inlining being a better candidate for the same in real world benchmarks while unrolling is much simpler to simulate limitations of current do not provide a platform to study the asymptotic time complexity associated with code size increases associated with inlining hence the above examples could only be taken as of the problem but it should also be that when discussing the solution time with respect to the input code size increase the number of constraints in the overall lp problem is linear in the number of dependences in the input code so a method like the above which gives a representative sample to increase the size of the lp program is not a limitation further in current benchmarks for loop nest the range of dependences is in and it can be said that there exists no scalability problem like in the above artificial examples but polyhedral compilers will soon face such large problems arising from interprocedural optimization domainspecific program generation or simply as the applicability restrictions continue to be lifted in addition there could be a restriction of the time limit in compilers that would further the scalability problem such as applications of note that ibm xl llvm and have similar to in the following we aim for lower complexity feasibility and optimization algorithms with worstcase strongly polynomial bounds and closer to n time complexity for andor compilation applications contributions in this paper we make the following contributions · we show that parallelization and affine scheduling heuristics such as can be adapted to utvpi thereby reducing their algorithmic complexity · using elementary polyhedral concepts we present a simple and powerful framework an approximation scheme which can be used for designing underapproximation ua algorithms of general convex polyhedra the ua problem · we evaluate these methods by integrating them into we show that for a significant percentage of arising from a wide range of test cases from affine scheduling the proposed above are precise enough to preserve feasibility we show that our approximations when solved with a algorithm show considerable improvement in running time over a well established implementation further we show that preliminary integration of the above ua polyhedra into yields code in most cases that does not significant increase in execution time · we show how our framework is general enough to extend to various other problems in compiler scheduling either within the affine transformations or beyond the paper is structured as follows section introduces tvpi and utvpi section introduces polyhedral scheduling our method to with the scalability problem and the mathematical framework for the linearization of the underapproximation problem and for establishing its correctness section proposes simple algorithms that a general convex polyhedron into a utvpi polyhedron section discusses the theoretical and practical implications of the above algorithms in section we discuss the various methods for having better control of feasibility in the presence of multiple polyhedra in section we discuss the results of implementing these algorithms in in section we discuss extensions and related work and we conclude in section tvpi and utvpi in this section we briefly cover some of tvpi and utvpi approximations of polyhedra a more extensive discussion on these including other of as used by the static analysis community can be found in our earlier work for a polyhedron described in constraint form let m be the number of inequalities n be the number of variables and b the upper bound on the absolute value of the coefficients describing the system tvpi in tvpi polyhedra each constraint is of the form c a b c q tvpi are obviously closed under projection and hence many algorithms on geometric operations that are developed for polyhedra are directly applicable to general tvpi giving rise to simple algorithms with low complexity furthermore the dual of a tvpi program is a generalized flow problem which can be solved using graph algorithms so the linear programming community has been interested in tvpi polyhedra because it can be dealt with strongly polynomial time algorithms application of graph theory to linear programming using tvpi systems was by and showed the of the feasibility problem of by introducing a unique strongly polynomial time procedure that can be used to decide the range of a particular variable with respect to a given constant this latter procedure is a style propagation of values assigned to variables through inequalities in the system and is the of all subsequent algorithms in the tvpi literature the following result by is the best to date for the tvpi optimization problem lemma lp optimization on tvpi linear programming optimization on tvpi systems can be solved in log m log b worst case time it is well known that for general polyhedra the optimization and the feasibility problems have the same time but it is interesting to note that date they have different on tvpi systems the feasibility problem on tvpi systems has lower complexity than the above weakly polynomial time result by on the optimization problem network flow based combinatorial strongly polynomial time algorithms for the feasibility problem were given by and and showed that feasibility of tvpi polyhedra can be determined in strongly polynomial time lemma feasibility on tvpi feasibility of tvpi systems can be solved in log m worst case time the above nearly time algorithm by is surprisingly simple it the mentioned decision procedure of into a binary search along with a selected application of on a polyhedron it can be seen that the above result can as well be used to derive strongly polynomial time bounds for elimination and for projection of variables from tvpi systems tvpi systems have been used for various problems in abstract interpretation and verification utvpi have constraints of the form c a b ± c q and are called so because in dimensions their geometric shape is they are also referred to as unit two variables per inequality utvpi because of the nature of their constraints since utvpi tvpi the complexity bounds of tvpi polyhedra apply to utvpi polyhedra as well but as the dual of the lp formulation of problem has just difference constraints with the form xi xj c general utvpi systems can be solved with same quadratic complexity as giving the following lemma lemma feasibility on utvpi feasibility of utvpi can be solved in worst case time and in om n space the above decision algorithm can also return a feasibility certificate of the utvpi polyhedron utvpi polyhedra have successfully been used for various problems in abstract interpretation and program verification also they have well supported implementations in the analyzer and in the polyhedra library vs general convex polyhedra the use of by the static analysis community has different requirements than our proposed application to affine scheduling in the former they serve as abstract domains and provide operations like union intersection projection etc which are efficiently solved by utvpi polyhedra providing better worstcase complexity the objective functions in polyhedral scheduling are very simple with unit coefficients and our utvpi approximate solutions are based on the assumption that the objective function itself could be approximated and any valid feasibility certificate is usually enough in this aspect better than general convex polyhedra for which efficient algorithms are usually based on the widely used algorithm the worstcase complexity of lp is known to be weakly polynomial in time and the algorithm while taking exponential time on worstcase scenario inputs as shown by is known to run well in practice in practice we are more interested in the complexity of lp to evaluate the of our approximation methods let n be the complexity of lp using the algorithm with m constraints and n variables determining typical value of z is not an easy task as it is well known to depend on many details of the algorithm like relative ratio of m and n rule method of exploiting and even many implementation details in this paper however we will be using the following result which does not count the complexity on a typical input z om on average in the above empirical estimate we assume that the gaussian elimination steps of the are very fast exploiting and assuming a linear number om n of steps also the above estimate is practically very accurate for the lp programs we observe despite the recent of conjecture note that advanced algorithmic analyses using novel probabilistic techniques have even been proposed by and to establish the polynomial running time but these results go way beyond the empirical estimate we need to evaluate our algorithms polyhedral scheduling and approximations in this section we show how the above classes of could be used to help in the scalability challenge in affine scheduling polyhedral scheduling and lemma let us first recall some essential notations and results about polyhedral compilation the input to any polyhedral scheduling algorithm is a polyhedral dependence graph g which is a result of a dependence analysis and is defined to be a g v e where v is the set of statements and each particular dependence edge e e is annotated with a parametrized polyhedron de each of the constraints of de is affine and involves i n where vectors i and n are the iteration and parameter vectors respectively in algorithm these are converted into a edge polyhedron with being the that come from domain constraints and variables being the that come from dependence constraints this conversion is done by application of the affine form of the lemma corollary h given as lemma affine form of lemma let d be a nonempty polyhedron defined by p inequalities bk for any k p an affine form is nonnegative over d if and only if it is a nonnegative affine combination of the affine forms used to define d meaning p x bk k p k k the nonnegative values k are called in the polyhedron both of the newly created and µ variables are called the by putting together all the polyhedra one obtains an overall polyhedron p which is amenable to linear programming any rational point that satisfies p is considered a valid schedule the above application of the lemma results in all the constraints in the scheduler with some additional variables to model the satisfaction of dependences at a given dimension of the affine schedule in a different but conceptually similar method results in a of dependence constraints of the same form as it has been shown elsewhere that these methods result in an lp problem of size m × n d · e × d · v where d is the mean depth of the loop assuming a usual complexity has been in the previous solving systems with bounded d leads to a close to asymptotic complexity not counting the complexity and assuming e closely matching the in figure and leading to problems schedule space underapproximation in this paper we propose that p be ua to improve the scalability of the scheduling algorithm this means that instead of searching for an optimal feasible point in p we search in pa the above approximation is legal and only leads to a conservative approximation of schedules though it is well proven that p is highly redundant with respect to schedule points the overall process has to ensure that the approximation algorithm as well as the solution finding time be scalable algorithms we can restrict these requirements further and say that both of these algorithms should have worstcase strongly polynomial time running times matching the of utvpi polyhedra introduced in section the above approximation can also be done on a basis in this method the polyhedra pe are and the solution is found from the overall polyhedron obtained by putting together all the namely by doing pa if the above approximation leads to a nonempty polyhedron then we can find schedule using instead of p in the above we are exploiting the property that each of the individual of polyhedral compilation are guaranteed to be nonempty directly as a result of dependence analysis it also helps that each of the polyhedra pe are much smaller than the overall polyhedron in the rest of this section we define a simple and sound mathematical background to build utvpi approximations of polyhedra to the problem of finding approximations and to prove that the algorithms we construct in later sections return valid approximations for giving these conditions we take two approaches an intuitive and geometric explanation using in next section followed by a more direct way using the equivalent solution and approximations starting with a polyhedron given in constraint form as p b we show that simple approximations of p can be obtained by reasoning about of the dual associated with the matrix a bt to the above we introduce some basic lemmas about and then show how these geometric concepts help reasoning about and in a unified manner the reader may refer to standard for a complete coverage a more detailed presentation of this material can be found in and polarity in geometry can be done on polyhedra in in form or generator form the following definition is when p is in definition a let p p a b p b be a then its is a cone and is also a ab t cp it can be noted that if a is a m × m constraints and n variables and b is a then the constraint system c or is of size m × n note that the constants dimension has become an additional dimension in the n dimensional space we would be referring to this dimension as dimension and the other dimensions as dimensions though the is a rather trivial process involving special marking of the dimensions it however needs to be mentioned because this paper deals with utvpi constraints having at most two nonzero coefficients in the dimensions the following is the definition of of a polyhedron definition b polarity for c rn the set is defined by c c rn cx for all x c rn from the above definition k the cone corresponding to p can directly be constructed from in and whose generator vectors are columns of the following matrix k cone at bt in form k is of size n × m the of constraint matrix of and can also be written as the following k cone at b bj bm polarity utvpi and though a polyhedron can be represented in either of there is certain in describing the in for problems that occur in polyhedral compilation the can be built in linear time in as in but converting the to or the to is very costly it involves the algorithm which takes exponential time in the following lemma we will implicitly be using the above dual interpretation without making an actual call to lemma utvpi and for a the has vertices and generators which have not more than two nonzero components in the dimensions for a the has generators which have not more than two nonzero components each in the dimensions with them being from we define the of a utvpi constraint as or vector further we define the of a utvpi polyhedron as a polyhedron underapproximation and overapproximation the following lemma and its corollary are standard results lemma a polarity and for any two k and k k k k k corollary b between k the above corollary means that by taking the of a cone and taking the overapproximation oa one obtains a cone whose is an ua of the original cone by using it the problem of finding a ua of a polyhedron in is reduced to the problem of finding a oa of its cone in more specifically if we let pa respectively ka be the approximation of p respectively k we have the following ka k pa p so the objective in the space of finding the of cone k given in as in is equivalent to finding a cone ka such that k cone ka by this equation if each column of k as in can be written as a sum of the vectors in ka then the approximation remains a valid approximation if each vector in ka is a vector then the corresponding pa would be a utvpi approximation of p approximation scheme for in this section we formulate the sufficient conditions to prove that the we will construct in section are valid approximations in fact with the lemma in section and the equivalent intuition in section we do have all the necessary to construct an approximation scheme which allows us to built of general polyhedra are simple extensions of the material in this section in the rest of this section for ease of we assume that the polyhedron p is dimensional these are also called polyhedra generalization to n is straightforward let the jth column of k with j m be kj aj bj t aj aj aj bj t then we have aj tj tj kj aj aj cone tj bj pj tj pj tj tj j pj where the t constitute the elements of the unknown t matrix and are to be found out it can be that each column of the matrix t j is a vector and hence is a tvpi constraint in the space the above is what we call an approximation scheme in this scheme definition approximation scheme a constraint bj in the original system is replaced by the set of constraints x x pj pj pj in the above scheme every column vector of k which has more than two nonzero components is replaced by a set of vectors such that the original vector remains in the sum of the the combination of the replacement vectors would hence be an oa of the original vector kj satisfying the above scheme remains valid as long as the t p variables and the a b constants satisfy the requirement one way for ensuring the same is by making the t satisfy the following additional constraints which we would be referring to as it is also possible to reduce a general polyhedron into an equivalent one according to the transformation has been suggested by r tarjan it is similar to the reduction of an arbitrary boolean satisfiability sat problem to a sat problem this transformation is not an approximation which is the subject of this paper context constraints for reasons that will be exposed later tj tj aj tj tj aj tj tj aj pj pj pj bj if such a set of t matrices can be found for each vector of k then we have ka t t t m and the approximation would be k cone t t t m we have the following theorem theorem tvpi and ua pa is a valid of the original polyhedron p proof we employ the affine form of lemma with the premise of of p guaranteed because of the method for the ua to be proper the affine form corresponding to the original constraint bj should be expressible as a positive sum of the replacement tvpi vectors bj j j pj j pj pj where the satisfy j j j j pairwise matching for each of the yields aj j tj aj j tj aj j tj bj j pj j pj setting j j j yields the context constraints defined in proving the validity of the approximation except for the additional j in the setting j is safe and we will see later that it actually to the quality of the approximation the problem remains to find such a set of t p variables satisfying the above context constraints so that the approximation remains valid it can be seen that searching for the t p variables directly could lead to a nonlinear quadratic formulation even searching for tvariables that satisfy the above constraints turns out to be nonlinear but as they are existentially quantified the equations can be solved using advanced quantifier elimination techniques like which are well known to be beyond small inputs and certainly not polynomial the next section proposes some of the above mentioned approximation scheme so that the approximation algorithms remain scalable this is done first as a heuristic where both t are arbitrarily fixed then as a more careful method where only the tvariables are fixed while the are found by an lp formulation tvpi and utvpi ua algorithms in this section we use the framework developed in earlier section and develop worstcase polynomial time algorithms for obtaining utvpi of polyhedra the method for in this section we introduce a simple strongly polynomial heuristic using the framework developed in section the main idea of this approximation is saying that the original vector can be approximated by any set of the replacement vectors as long as the former remains in the cone of the latter definition method d case the inequality ax by cz can be approximated by the set of inequalities ax by ax cz by cz geometric intuition for the above derives from the observation of the space where the above approximation is the following a b c cone a b a c cb the intuition for the above approximation comes from the values of the tvariables and need to satisfy as explained earlier the tvariables have to be instantiated a priori to avoid solving a nonlinear problem the method in this section the p variables also in a heuristic manner by the available budget in the dimensions equally between the values in the dimensions of the replacement vectors we call it the method because the original vector is the of the replacement vectors in the space general nd case the above can be easily generalized to nd polyhedra let s be the of a polyhedron ie the number of nonzero variables outside the dimension for a specific constraint with s n let q s ss and let r s the set of vectors corresponding to the particular constraint are n dimensional with cardinality q the coefficients of the dimensions are divided by r while the dimension is uniformly divided by q in each of the cases it can be seen that the approximation being proposed is a approximation making its a tvpi ap it can also be verified using the construction given in the earlier sections and equations and that the ua proposed in each case is a valid approximation example let the input system be the d x y z x y z only the inequality x y z is not tvpi and is approximated by the set of in equalities xy xz yz it can be seen that the approximation is a nonempty tvpi system it is a utvpi system with vertices each of which are inside the vertices of the original system the above example is similar to the system induced in the compilation of the si a xi with reference to the choice of in theorem it can be seen that setting in the above exam ple has the advantage that the three replacement tvpi exactly on the original any other strictly positive choice for would mean that the point of tion would lie strictly inside the positive of the original and thus giving rise to an ua which is in a way less effective example let the input system be the mid x y z x y z only the in equality x y z is not tvpi and is by the set of inequalities x y x z y z it can be seen that the approximation is a nonempty tvpi system with vertices each of which are inside the vertices of the original system which are it can be seen that the method is simple and easy to implement but does not have any guarantee of ensuring that the approximation is nonempty in the next section we will generalize this method to formulate a parametrized approximation and formulate an lp problem to find the approximation parametrized tvpi approximation to ease the we will primarily deal with dimensional polyhedra again higher dimensional extensions are straightforward the method can easily be extended by defining the approximation as a on the values in the dimension entries as x bj x pj pj pj pj bj where the values of the dimensional are unknown and have to be found out in the above approximation it can be observed that the coefficients in the dimensions values have been fixed much similar to their choice in the method but the coefficients in the dimension values are unknown and have to be found out the context constraint pj pj pj pj bj is not arbitrary it is determined by the choice of the for the tvariables so that the kj vector is in the of t j as given in the system is pj x b bj x bj bj bm in the following discussion we show that the higher dimensional system pj can be interpreted in two ways a geometric and an algorithmic ways each having its own a parametrized approximation can be considered as a parametrized approximation with pj being the parametric vector and the context constraint pj bj considered as the parametric context when the values of the vector pj are known then the system sx pj pj is a lp problem which can be tested for feasibility in the usual since the context constraint pj bj is it follows from the proofs of earlier sections that sx is a proper approximation of sx if the value of the vector pj is not known sx can be considered as a parametrized approximation of sx note that the context constraint is only on the while the tvariables have been assigned a fixed value an lp formulation we can consider pj to be a lp system with unknown variables x pj such an interpretation is possible because there exist no nonlinear terms in the definition of sx pj and it is only the feasibility of the approximation that is interesting the system pj is solved for feasibility with the unknown variables vector as x pj and a valid assignment for the values of both as well as the is found then the system sx as given by can be considered an approximation of the system sx as long as the satisfy the constraint pj bj on the other hand pj is a higher dimensional system than sx and hence cannot be considered as an approximation of the latter it is an intermediate form useful for algorithmic purposes example here is a reduced example from sx y z x y z z x z y z x y z it is clearly not a tvpi system as the fourth constraint is the method applied to this constraint yields the system sx y z x y z z x z y z x y x z y z which turns out to be an empty system on the other hand the method in this section would lead to the following higher dimensional system y z p p p x y z p p pz xz yz x ppp where the variables p p p are additional context variables and the last constraint p p p is a context constraint when system is solved for a feasible point and the set of that are obtained as solution are substituted we obtain sx y z x y z z x z y z x y x z y z the reader can verify the satisfiability of the two approximations s and s the above method involves only one call to a standard lp solver the is that the system p has n aj n aj aj on aj dimensions where aj is the number of nonzero elements in the vector aj as the method involves a call to an lp solver its theoretical cost is not strongly polynomial time multiple constraint lp when there exist multiple constraints in sx each one of them has to approximated to find a tvpi approximation of the polyhedron let mk be the number of constraints in sx with mk m without loss of generality we can assume that the constraints have been ordered such that the constraints come first followed by the tvpi constraints this means that the constraints of sx are mk m with the constraints mk being constraints and the constraints mk m being tvpi constraints method a straightforward way in which one can find a tvpi tion of the above system sx is to construct a sys tem p in which all the constraints in sx are approximated using the scheme described in sec tion this system can be solved using an lp formulation in variables as x p an approximation of sx could be found as p p it can easily be shown that the latter system is a proper approximation as long as the context constraints p b are but finding the approximations of all the constraints simultaneously in the above fashion would lead to a large lp sys tem n p mk l al al could have up to n mk l dimensions which could be al as large as on with being the average number of nonzero coefficients in the constraints in sx iterative methods we can also iterate the above process described in section for each of the mk constraints in sx on an iterative basis clearly there could be choice in the methods in whether the original system is being updated with the approximation constraints of each constraint or not we refer to the case when the original system is immediately updated as the incremental method we refer to the case when the approximations of all constraints are found by constructing lp on the same lp system as the independent method it could be that each of the above methods involves multiple lp calls one for each constraint sx this means making upto om lp calls in total for building the approximation system but the dimension of each of the lp systems is in the or der of on which is much more reasonable than the previous formulation per constraint of tvpi let us sketch a simple algorithm that takes a tvpi constraint and returns its utvpi underapproximation from lemma a vector in the space needs to be and should have equal magnitude components in the non dimensions for the original to be utvpi so the intuition for this algorithm is similar to the namely that reasoning about the original vectors in the space and computing a set of vectors which oa the original vector resulting in an oa suppose the vector has components as a b p in the xi xj x dimension with x being the dimension then we can replace it with two vectors the re placement has to just take care of the fact that the new vectors are such that the original vector is in the sum of the as the case when a b means that the vec tor is already a vector the other cases can be handled in the following way ab ab b a p t a p t b b a p t p t in either of the above cases it can be that the first vector is a vector and the second is an interval vector the first case is illustrated in figure xj ab xi figure to approximation lemma validity of the above utvpi approximation given a tvpi constraint the above method returns a valid of the constraint proof the geometric proof derives from the observation that the sum of the corresponding replacement vectors is the original vector hence every vector in the space that is reachable by the original vector is reachable by these replacement vectors meaning that they give an oa in the space in the space the necessarily give an ua cor b example let p v with the h form of p being p h x y x y it can be seen that p is a tvpi system but not a utvpi system as the third constraint is a constraint the utvpi approximation by the above method is x y x y y which can be seen to be nonempty the cost of finding the ua is linear and the method is simple to implement just like the method mentioned in section just like that method this method does not have any guarantee that the approximated system is nonempty lp based parametrized utvpi approximation this approximation is similar to the parametrized tvpi approximation of section in the sense of searching for p variables instead of ts we are not covering it for lack of space metrics and discussion let us now study the size of the new system the complexity of the conversion the overall complexity of finding a solution and discuss some fundamental and limitations of our approach sizes let the original matrix be of size m × n m constraints and n variables with mk and mt being the number of and tvpi constraints respectively also let the overall factor of the system be s which means that for a constraint in the input system on average s variable elements are nonzero it will be seen in sections that for practical purposes s is a small constant little more than and relatively independent of n for a system described as above each of the methods given in sections and replace a constraint aj with the same number of aj aj aj tvpi constraints doing the above process for each of the mk constraints creates an approximated tvpi system of size ma × n where ma mt mk it can be assumed that the new system is approximately of the size sm × n in the case that s n which means that the constraint matrix does not have any zero entries then the size of the tvpi constraint system is which is of the order of n m × n for utvpi approximation given in section we have the same order of complexity of additional constraints as in the case though double in number constraint graph the algorithm constructs a constraint graph or matrix of nearly twice the size of the input utvpi system before solving it a input system results in n nodes and m n edges due to simple transformations of addition of positive and negative forms of each variable section and addition of a for the problem the former is a relaxation of utvpi into difference constraints and is exact for rational points though some odd integer points in the original are lost complexity of conversion both the method of tvpi approximation covered in section and the utvpi approximation covered in section are strongly polynomial time algorithms as they do not use any lp call when constructing the approximation the parametric approximation covered in section is a weakly polynomial time algorithm for it needs to solve an lp problem for finding the dimension values for the case of multiple constraints complexity of conversion is one lp call for the algorithm of section and one lp call per constraint for both incremental and independent algorithms each of the above numbers are weakly polynomial time but are worstcase times nonetheless complexity of finding a solution for the tvpi approximation as the worstcase complexity of is log m applying it to the approximated system would lead to log sm time with constraint s and log nm in the case when s on for the utvpi approximation as the theoretical worstcase complexity of solving utvpi systems is if we use the traditional algorithm on the difference constraints the corresponding would be and respectively we will see in section empirical evidence that tvpi constraints are always utvpi in practice making this method very it can be that our algorithms do not ask for removal of redundant inequalities which is as hard as determining if the input system is feasible polyhedra in compilation have lot of duplicate constraints which gets reflected in the approximations as well compilers like remove these by methods like textual matching which leads to a large decrease in the number of constraints a more advanced scheme to utvpi constraints would use a hashing or technique like in the utvpi constraint in a few integers exploiting the fact that the dimension values are from ± while the dimension values are always from a very small set it would bring the simplification complexity to linear time we thus believe that the problem of duplicate elimination is asymptotically the following example shows an inherent limitation of the process of itself example the polyhedron described using the constraints x y z x y z is not tvpi though it is unbounded in both directions the only tvpi approximations that are possible of the above polyhedron are bounded tvpi polyhedra which can be considered a failure of the ua approach the above kinds of polyhedra can be considered as cases and identified by a preprocessing step that removes the space from the input polyhedron further the polyhedra that arise in polyhedral scheduling are always pointed polyhedra and can never have nontrivial space integer scaling and tu polyhedra the parametric approximations of sections and can ensure that the resulting difference constraints are integer constraints of the type xi xj c where c z this would involve scaling up the variables changing the context constraints accordingly and solving an of the usual lp on a basis such a local transformation will not only induce integer schedules because matrices are a subclass of network matrices but also has the additional property that all vertices of the overall polyhedron are integral because such matrices are totally chapter we will show in section that this method would help in polynomial time approximations of npcomplete problems and feasibility control with many polyhedra the previous sections discuss algorithms for the under approximation of one single polyhedron so that the ua polyhedron can be solved as a means of expressiveness eg the ability to find good affine transformations for scalability in affine scheduling however the overall system p is an intersection of many polyhedra each of them arising from a as in the case of scheduler or the above along with some additional constraints as in the case of scheduler more specifically · scheduler to minimize pl where pe is the polyhedron a given dependence edge induces a weak satisfaction constraint in the system until it is strongly satisfied by outer dimensions of the affine schedule ie the sink of a dependence is scheduled at a strictly higher time step than the source · scheduler to expose loop tiling pf co ee pe vv hv vv nv where pe is similar to polyhedron enforcing weak dependence satisfaction only but at all dimensions of the affine schedule while hv collects the linear independence constraints and nv collects the or trivial solution constraints these two cases are different because thanks to the conditions in the polyhedron built by scheduler is known to be always feasible this condition however is not necessarily true for systems though the number of problematic additional constraints hv nv is small around v or less than when compared to constraints pe the overall polyhedron could be empty the ua procedure the feasibility preservation problem is to find a nonempty in each of the above cases without making any queries like an lp the overall system p in this section we discuss practical methods to increase the control on feasibility for the overall approximated system scheduler let us first discuss a technique for scheduler let us start by each of the pe by calling the algorithm discussed in section and construct the overall approximation by putting all the individual approximations together the overall approximation is the result of e calls to the procedure this will be because each of the are quite small algorithm always finds a rational affine schedule which guarantees that p is a feasible polyhedron the main question is whether feasibility will be preserved when the approximations it may sound as a that the answer is yes notice that he original schedule of the source program is always feasible the key idea is to the approximation of the pe polyhedra forcing this original schedule into the ua it simply amounts to substituting the values of the coefficients of the original schedule in the constraints and adding the resulting inequalities to the systems before applying the ua method this result is important because of the large number of affine scheduling heuristics deriving from algorithm parallelization method is already useful for loop our approach is directly applicable to parallelization heuristics as well we could stop there and declare success but more advanced methods combining tiling for locality and parallelism extraction require additional effort to preserve feasibility the next section studies the most successful of these heuristics us to the underapproximation method to feasibility preservation in presence of more complex affine constraints scheduling in in this section we discuss the approximation of p in the context of scheduler as implemented in here with the original schedule is not possible since the loops of the source program may not be directly we study a variety of constraint clustering techniques pd each pe is approximated alone and all the additional constraints are approximated together as in ee hv vv nv the overall approximation is the result of e applications of the method pd total each pe is augmented with all the additional constraints and this augmented polyhedron is approximated as in vv hv vv nv the overall approximation is the intersection of e and each element in hv and nv could be approximated pd selected each pe is augmented with its section of the additional constraints hu and nu for statements u on if such a query could be made then it could as well be used to solve for the objective function resulting in the schedule either side of dependence edge and the augmented polyhedron is approximated if e v v hv hv nv nv the overall approximation is the intersection of e approximations pd just each pe is approximated independently just like in scheduler while the additional constraints are away the overall approximation is the intersection of e approximations this method clearly does not give an ua it is meant to better characterize the source of the in the previous three methods indeed considering the intersection of of constraints we know that the are this tells us that the origin can be used as a to build a nonempty approximation experimental results we systematic experiments tiling and the with the polyhedral optimizer subsequent to our experiments later versions of x have been released and which have similar numbers systems are extracted from we compare the default linear programming calls to with the and then the algorithms the is further relaxed into a constraint graph or matrix which is to a custom implementation of the algorithm note that we still use for the much smaller linear programming problems arising from the feasibility heuristics also makes use of in parts with the scalability of affine scheduling problems the calls from from the functions satisfaction test ds get direction dir and find we focus on calls which correspond to affine scheduling problems there are a lot more calls of the ds and dir variety when compared to the calls optimization of the former pair of lp calls is entirely a different problem from the variety in many ways primarily the former need to be as otherwise it results in incorrect transformations the latter of course are the main topic of this paper and need to be leading to a conservative approximation and perhaps loss of useful schedules features of the polyhedra here we are referring to table a the initial three columns refer to the size of the loop nest l is the number of loops s the number of statements and d the number of dependences the next sets of columns indicate the polyhedral characteristics of the different of calls from as the ds and dir variety are similar types of calls they have been summarized together the remaining columns table b will be discussed in the next section the number of polyhedra of different types are indicated in the p columns pds and as written earlier there are lot more polyhedral calls of than when compared to but the former are smaller calls and are linearly dependent on the size of the loop nest for a particular benchmark and variety of polyhedra or n and m columns indicate the number of variables and average number of constraints in the particular lp formulation respectively m t column indicates the average number of tvpi constraints for that benchmark and variety of polyhedra as it can be expected most of the constraints in the polyhedra are tvpi constraints in these polyhedra there lu loop nest l s d pds p p n m m t p n m m t m a m u yy yn lp yy yn pd yy yn pd yy yn table a problem size polyhedral and characteristics b ua effectiveness is never more than constraint per polyhedron which is in all the cases whenever a constraint is tvpi it is always a utvpi constraint having the same absolute magnitude for the two coefficients when it has two entries in the variety it can be that the sizes of some of the polyhedra are small and comparable to the polyhedra this is either the result of a small problem size or because uses elimination along with a syntactic heuristic to reduce the duplicate constraints as it can be expected m t number of tvpi constraints in the original system is highly benchmark dependent but just like in polyhedra a tvpi constraint is always a utvpi constraint is the average number of nonzero coefficients in the constraints for that benchmark it can be seen that this number though again being benchmark dependent is a small constant when compared to the dimension size n m a is the number of constraints in the new approximated tvpi system as seen m a m mt mt the relative growth of the approximated system with respect to the original one is defined as the ratio between the sum of entries in the m a and m columns we found the average value of this to be meaning that the overall factor s is a little more than sometimes the growth of the approximated system is significant but it has to be that m a is the number of constraints without any simplification while m is obtained after systematic simplification and elimination of in for comparison purposes with m a we have added the m u column which is the average system size when the simplification techniques used in are turned off it can be observed that m u and m a are of comparable sizes our experience is that when the approximated system simplification and duplication removal techniques it leads to a much smaller system comparable to the one in m columns also asymptotically the size increase that only depends on does not matter much ua feasibility here we are referring to table b these numbers are for the results for are similar and are not being given because of space constraint these columns refer to the method discussed in section to the lp based independent method discussed in section and the methods discussed in section respectively all the columns except for the method refer to the methods only the method was implemented on the overall system one that is obtained after putting together all the individual systems and after simplification by the calls of the variety are for in the current table we discuss the feasibility results only the columns yy yn denote the feasibility y or n of the original and approximated systems respectively they have been accordingly since the system is used to find an optimization point in the overall system a yn entry would mean loss of parallelization it can be seen that the method yy and yn cases or out of problems performs much better than the method yy and yn cases or out of problems the latter performs not as as the simplicity of the approach would to we expect the incremental method to have much better performance than the current independent method the results of pd not shown better than the method the results of pd are close to yy and yn cases or out of loop advanced clustering strategy pd has not been implemented pd just gives feasibility preservation results yy and yn making it quite the next sections study the impact on compilation time and on the performance of the generated code scalability comparison vs time taken to solve system seconds vs number of dependences solve bf time taken to solve system seconds vs number of dependences solve bf time taken seconds time taken seconds dependences dependences figure vs bf figure shows the running times of the on the original system vs bf on a utvpi approximated system pd the former uses the quite well used implementation of similar to many lp solvers like called on a rational polyhedron for feasibility while the latter is our own implementation of a standard algorithm called for testing for presence of negative weight cycles the input programs and are the same as in figure and each call of trans of to find schedule has of calls of the above variety which explains the difference in prior to solving either of these the were eliminated using a syntactic matching like currently in even on the systems with the improvements were similar though being more it can be seen from the graphs that for their respective inputs bf worstcase is asymptotically as well as faster than observed om the scalability challenge the coefficients linear r for the above formulae are around the for bf appear linear because the counts the number of dependences which is practically though the memory improvements are not shown in the above graphs the linear memory of bf is considerably than the quadratic memory of the relatively and hence improvements of when compared to could be attributed to the fact that while the former has just uniform dependences which are easily amenable to the gaussian of the latter has more complex affine dependences and also induces many more variables ua generated code performance benchmark comparison seconds par cur par new cur new x x x x x x x x x x x x table ua code performance we are referring here to table limiting ourselves to a subset of the yy cases in the previous table that our current implementation could handle we will later consider all yy and yn cases with a more robust implementation in each case we replaced the original systems by the approximated tvpi ones obtained by the independent lp method the cost function was unchanged and the solution was found using it can be seen that performance closely match the default polyhedral method in despite the approximation taking place the impact of yn approximations on effectiveness is yet to be studied but we express some hope on loop distribution heuristic to break infeasible systems extensions and related work in this section we will first see how our framework can be applied to other scalability problems either in affine scheduling framework or beyond and then cover some related work applications to other loop transformation problems one important strength of our underapproximation framework is its ability to precision for scalability using utvpi approximations of polyhedra scalability arises from the worstcase of operations and the ability to largely implement the approximation as an independent optimization problem for each the latter property is another strength of our approach which happens to be general enough to be applied to other compilation problems related and to scheduling scheduling as the framework of which we build from is the most powerful among the class of algorithms that find affine schedules the lp formulation in scheduling can directly be approximated by our method d loops for pipelining and compaction to solve the cyclic scheduling decomposed software pipelining problem et al give an lp formulation whose constraint matrix is built from matrices of the original and a dependence graph and prove it to be a totally tu matrix as given the formulation is not a utvpi polyhedron having at most nonzero elements per row but it can benefit from our framework as the constraints are constructed on a basis and the constraint matrix elements belong to the set ± loop for compaction uses a very similar framework to the above paper where an lp formulation which is a variation of a flow problem is used and hence could as well benefit from a utvpi approximation resulting in a strongly polynomial time algorithm nd loop alignment for fusion show that external in the loop alignment problem is npcomplete they provide an formulation constructed on a basis with variables per constraint and general coefficients not just ± a possible heuristic for their formulation that builds on our techniques would be to each constraint and to solve the overall system using the algorithm this is correct because rational relaxation and subsequent ua may result in less integer points but no new ones the overall ua if nonempty can be solved in polynomial time further it can be made to directly result in an integer shift using the integer scaling discussed earlier in section in this method an problem is solved on a while solving a normal problem on the overall ua polyhedron resulting in an integer shift in this aspect utvpi polyhedra are very special and such a polynomial time algorithm will not be possible even with a as solving polyhedra is known to be npcomplete simpler code generated as seen earlier by the tu property a restriction of the dimensions to integers can ensure that all the vertices of the are integers using these in scheduling has the additional advantage of simpler code being generated even with affine schedules generated through rational linear programming uses integer linear programming by default rational schedule coefficients may indeed induce in loop bounds and conditional expressions of the generated code a completely eliminated with our approach related work scalable modular scheduling approach starts with gaussian elimination and suggests a decomposition generator representation of pe for projection we consider this approach as complementary to ours in the sense of methods but the use of generator representation makes it less likely to be scalable than ours approximations in loop optimization previous approaches to approximations in loop optimization concerned themselves with restricting the kinds of input programs or the kinds of transformations being for the most examples of the above are the dependence levels of allen and kennedy and direction vectors of and lam each of the above are less powerful than the affine scheduling model of our approach the scalability problem from within the affine scheduling model and is more powerful utvpi in loop optimization utvpi polyhedra have previously been used by and kennedy in task level loop parallelization and pipelining applications by data dependence analysis domain simplification and limited form of code generation their use is similar to the framework of classical dependence our use of utvpi is more powerful than because of our affine scheduling framework and ua algorithms further and et al also that utvpi polyhedra could be solved with better complexity and hence used in dependence analysis some statistics from parallelization benchmarks our statistics in table a could be seen as extensions of the above utvpi in static analysis general polyhedra are known to be considerably more expensive than utvpi polyhedra for abstract domain operations hence have been widely employed in abstract interpretation problems by the static analysis community as a means of precision for scalability a comparison of the use of along with their applicability to polyhedral compilation can be found in of the many classes of utvpi polyhedra have extensively been used with results such as in approximations to we are not aware of any previous algorithm for finding approximations of general polyhedra into other than finding the interval box polyhedral the literature is about polyhedral approximations and more so for the method of out the extra variables on a basis using method leads to an overapproximation with no bound on the complexity propose an algorithm to find the of a in vertex representation section the vertex method for finding the of a general polyhedron simon et al section propose an iterative algorithm for the of a general polyhedron using lp our algorithm for in section can be seen as complementary to the latter though our algorithm the lp problem by searching only for the in the dimension feasibility and optimization algorithms the state of the art in feasibility testing for tvpi systems is by and for optimization of tvpi systems by we are not aware of existing implementations of the above algorithms the state of the art for feasibility and optimization of utvpi systems is by the well understood algorithm which involves constructing a nearly m × n size constraint graph encoding the difference constraints and testing it for presence of negative weight cycles using the problem the latter has been extensively studied beginning from to most recently in efficient though closure based methods for the same are available in and more general forms than ours like boolean formulae involving utvpi constraints have been considered in constraint programming like by et al conclusions and future work we have presented scheduling using utvpi polyhedra we have proposed worstcase polynomial time algorithms to compute utvpi from a general convex polyhedron we have shown initial results of the above approximations as well as their integration in our experiments clearly indicate an asymptotic improvement in scalability the scalability challenge to within polynomial time care was taken to the underapproximation model avoiding the exponential vertex and construction associated with the algorithm the most difficult problem is the lack of a scalable way to preserve the of the underapproximation when the original polyhedron is nonempty the linear programming method offers this guarantee but not in strongly polynomial time we explore different heuristics relying on linear programs to complexity for feasibility we know this problem is difficult because a strongly polynomial method with this guarantee could directly lead to a solution of finding strongly polynomial feasibility test for general polyhedra the scalability experiments indicate an asymptotic improvement of over linear programming future experiments should include a fast duplicate elimination a complete evaluation of the performance impact of the approximation on all using an approximated objective function compatible with the algorithm and a complementary study of the memory complexity known to be in our an illustration of the power of our approximation scheme has been shown on important affine scheduling problems future work would involve applying the scheme to a range of compilation problems including or so that either heuristics with better complexity measures are obtained or the resulting approximations provide practical improvements on complex systems acknowledgments we are to paul for the helpful suggestions and insights we are also to and for their feedback at different stages our work also from framework and from the detailed comments from anonymous reviewers this work was supported by the project in with and by the european fp project id references r k t l and j b network flows theory algorithms and applications prenticehall inc nj usa r allen and k kennedy automatic translation of fortran programs to vector form acm trans program lang syst ­ oct a and s implementing j exp sept b and y a polynomial time algorithm for solving systems of linear inequalities with two variables per inequality siam j comput ­ r p m hill and e the polyhedra library toward a complete set of numerical abstractions for the analysis and verification of hardware and software systems science of computer programming r p m hill and e shapes for numeric abstractions improved algorithms and proofs of correctness formal methods in system design ­ v and k kennedy a technique for data access and its use in parallelism transformations in pldi pages ­ u loop transformations for compilers the foundations academic boston r on a routing problem of applied mathematics ­ ln a and c the polyhedral model is more widely applicable than you think in proceedings of the international conference on compiler construction cc number in lncs mar springerverlag r e solving realworld linear programs a and more of progress res ­ jan b p cousot r cousot j l a d and x a static analyzer for large software in pldi pages ­ acm u a j and p a practical automatic polyhedral and locality optimizer in pldi pages ­ py a and y robert circuit applied to decomposed software pipelining ieee trans parallel syst ­ jan b v l a v r e tarjan and r f feasibility algorithms an experimental evaluation j exp ­ jan e and n improved algorithms for linear inequalities with two variables per inequality siam j comput ­ december p cousot r cousot j l a and x why does scale up formal methods in system design ­ dec g b linear programming and extensions princeton university press princeton nj a and g loop for loop compaction int j parallel program ­ oct a and g complexity of loop alignment in proceedings of the th annual symposium on theoretical aspects of computer science pages ­ london uk uk springerverlag a y robert and f scheduling and automatic parallelization a and f optimal fine and parallelism detection in polyhedral reduced dependence graphs int j parallel program ­ december h g and e testing the condition for shortest and optimal factors in the theor comput sci ­ p parametric integer programming ­ p some efficient solutions to the affine scheduling problem i time ­ october p some efficient solutions to the affine scheduling problem part ii time int j parallel program ­ december p scalable and structured scheduling international journal of parallel programming ­ l r jr and d r flows in networks princeton university press m p and a forward communication only and their use for parallel program construction in w and cw editors volume of lecture notes in computer science pages ­ springer t h a a a and ln polyhedral optimization in llvm in impact in conjunction with france n d and l some ways to reduce the space dimension in polyhedra computations form methods syst des ­ july d s and j simple and fast algorithms for linear and integer programs with two variables per inequality siam j comput ­ j m j p j and r h c beyond finite domains in a editor volume of lecture notes in computer science pages ­ springer b and a a library of numerical abstract domains for static analysis in cav pages ­ j c the computational complexity of simultaneous approximation problems siam j comput ­ a w and m s lam parallelization via affine transformations in popl pages ­ paris france jan d e j l hennessy and m s lam efficient and exact data dependence analysis in proceedings of the acm sigplan conference on programming language design and implementation pldi pages ­ new york ny usa acm a the abstract domain higherorder and symbolic computation ­ ln u c a j p and n loop transformations pruning and optimization in popl pages ­ ln u et al the benchmarks v r pratt two easy theories whose combination is hard technical report massachusetts institute of technology cambridge mass w a practical algorithm for exact array dependence analysis acm ­ aug f a counterexample to the conjecture of mathematics ­ a theory of linear and integer programming john sons inc new york ny usa s a k and r e on solving boolean combinations of utvpi constraints journal on satisfiability boolean modeling and computation ­ r deciding linear inequalities by computing loop j acm ­ october a simon and a the two variable per inequality abstract domain higher order symbol comput ­ mar d a and sh analysis of algorithms why the algorithm usually takes polynomial time j acm ­ may a a decision method for elementary algebra and geometry univ of california press berkeley nd edition m j the many of linear programming mathematical programming ­ k a d f li t h r s pop j and r two years after first learned from realworld polyhedral compilation in gcc research opportunities workshop grow italy jan r scalability challenges in the polyhedral model an algorithmic approach using per inequality phd thesis france january r and a potential and challenges of compilation in first in workshop on polyhedral compilation techniques impact in conjunction with france r and a a case for strongly polynomial time scheduling using polyhedra in second international workshop on polyhedral compilation techniques impact in conjunction with paris france jan n scalable program optimization techniques in the polyhedral model phd thesis university sept f on the optimality of scheduling algorithm concurrency and computation practice and experience ­ f and n minimal enclosing in d comput theory ­ november k d a polynomial combinatorial algorithm for generalized minimum cost flow in proceedings of the annual acm symposium on theory of computing pages ­ new york ny usa acm m e and m s lam a loop transformation theory and an algorithm to parallelism ieee trans parallel syst ­ oct yang c and f minimal data dependence abstractions for loop transformations in k u d a and d a editors volume of lecture notes in computer science pages ­ springer g on in mathematics springer science 