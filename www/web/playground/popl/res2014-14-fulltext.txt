a verified informationflow architecture de david benjamin c pierce andrew university of pennsylvania portland state university inria university abstract safe is a design for a highly secure computer system with mechanisms for tracking and limiting information flows at the lowest level the safe hardware supports finegrained tags with efficient and flexible propagation and combination of tags as instructions are executed the operating system these generic facilities to present an informationflow abstract machine that allows user programs to label sensitive data with rich confidentiality policies we present a formal model of the key hardware and software mechanisms used to control information flow in safe and an proof of noninterference for this model categories and subject descriptors d security and protection information flow d software engineering verification keywords security design tagged architecture informationflow control formal verification refinement introduction the safe design is motivated by the that the of computer systems is due in large part to design decisions left over from an of hardware resources the time is for a complete of the entire system stack with security as the central focus in particular designers should be to more of the processing power available on to improve security a key feature of safe is that every piece of data down to the word level is annotated with a tag representing policies that its use while the tagging mechanism is very general one particularly interesting use of tags is for representing informationflow control ifc policies for example an individual record might be tagged this information should only be seen by principals alice or bob a function pointer might be tagged this code is trusted to work with or a string might be tagged this from the network and has not been yet such tags representing ifc policies can involve arbitrary sets of principals and principals themselves can be dynamically allocated to represent an unbounded number of entities within and outside the system at the level rich ifc policies have been extensively explored with many proposed designs for static permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work must be for all other uses the popl january ­ san diego ca usa copyright is held by the acm etc and dynamic etc enforcement mechanisms and a literature on their formal properties etc similarly operating systems with informationflow tracking have been a of the os literature for over a etc but progress at the hardware level has been more limited with most proposals on hardware acceleration for schemes etc safe extends the state of the art in two significant ways first the safe machine offers hardware support for sound and efficient tracking of both explicit and implicit flows ie information leaks through both data and control flow for arbitrary machine code just programs accepted by static analysis or produced by translation or transformation moreover rather than using just a few taint bits safe associates a tag to every word of data in the memory and registers in particular safe tags can be pointers to arbitrary data structures in memory the interpretation of these tags is left entirely to software the hardware just propagates tags from operands to results as each instruction is executed following rules second the safe design has been from the start by an effort to formalize critical properties of its key mechanisms and produce proofs in parallel with the design and implementation of its hardware and system software though some prior work in § shares some of these aims to the best of our knowledge no project has this combination of abstractly the tag propagation rules in safe can be viewed as a partial function from argument tuples of the form pc tag argument tag argument tag to result tuples of the form new pc tag result tag meaning if the next instruction to be executed is the current tag of the program counter pc is pc tag and the arguments expected by this are tagged argument tag etc then executing the instruction is allowed and in the new state of the machine the pc should be tagged new pc tag and any new data created by the instruction should be tagged result tag the individual pairs in this functions graph are called rule instances to distinguish them from the symbolic rules used at the software level in general the graph of this function in will be so concretely the hardware maintains a cache of rule instances on each instruction dispatch in parallel with the logic implementing the usual behavior of the addition the hardware forms an argument tuple as described above and looks it up in the rule cache if the lookup is successful the result tuple includes a new tag for the pc and a tag for the result of the instruction if any these are combined with the ordinary results of instruction execution to yield the next machine state otherwise if the lookup is the hardware invokes a cache fault trusted piece of system software with the job of checking whether the combination of tags corresponds to a policy violation or whether it should be allowed in the latter case an appropriate rule instance specifying tags for the instructions results is added to the cache and the instruction is thus the hardware is generic and the interpretation of policies eg ifc memory safety or control flow integrity is in software with the results in hardware for efficiency the first contribution of this paper is to explain and formalize in coq the key ideas in this design via a simplified model of the safe machine its tagging mechanisms in a form and focusing on enforcing ifc using these general mechanisms in § we outline the features of the full safe system and enumerate the most significant simplifications in our model to the most of the paper describes a version of the system to § the discussion of the more sophisticated memory model and ifc label representation that we have actually formalized in coq we begin by defining a very simple abstract ifc machine with a builtin purely dynamic ifc enforcement mechanism and an abstract lattice of ifc labels § we then show in three steps how this abstract machine can be implemented using the lowlevel mechanisms we propose the first step introduces a symbolic ifc rule machine that the semantics of the abstract machine splitting out the ifc enforcement mechanism into a separate judgment parameterized by a symbolic ifc rule table § the second step defines a generic concrete machine § that provides lowlevel support for efficiently implementing many different highlevel policies ifc and others with a combination of a hardware rule cache and a software fault handler the final step the concrete machine with a concrete fault handler enforcing ifc we do this using an ifc fault handler generator § which the symbolic ifc rule table into a sequence of machine instructions implementing the ifc enforcement judgment our second contribution is a proof that this simplified safe system is correct and secure in the sense that user code running on the concrete machine equipped with the ifc fault handler behaves the same way as on the abstract machine and the standard noninterference property that high inputs do not influence low outputs the of the concrete machine and fault handler is complex so some proof abstraction is essential in our proof architecture a first abstraction layer is based on refinement this allows us to reason in terms of a highlevel view of memory ignoring the concrete implementation of ifc labels while setting up the relation used in the noninterference proof a second layer of abstraction is required for reasoning about the correctness of the fault handler here we rely on a verified custom hoare logic that abstracts from lowlevel machine instructions into a set of verified structured code generators in § we prove that the ifc fault handler generator correctly a symbolic ifc rule table and a concrete representation of an abstract label lattice into an appropriate sequence of machine instructions we then introduce a standard notion of refinement § and show that the concrete machine running the generated ifc fault handler refines the abstract ifc machine and using the symbolic ifc rule machine as an intermediate refinement point in each direction of the proof § in our deterministic setting showing refinement in both directions guarantees that the concrete machine does not diverge or get stuck when handling a fault we next introduce a standard noninterference property § and show that it holds for the abstract machine since deterministic is preserved by refinement we conclude that the concrete machine running the generated ifc fault handler also satisfies finally we explain how to accommodate two important features that are handled by our coq development but from the sections dynamic memory allocation and tags representing sets of principals § we close with a survey of related work § and a discussion of future directions § we omit proofs and some parts of longer definitions a long version and a coq script formalizing the entire development are available at overview of safe to establish context we begin with a brief overview of the full safe system on its os and features more detailed descriptions can be found elsewhere system software performs process scheduling communication storage allocation and garbage collection and management of the lowlevel tagging hardware the focus of this paper the goal is to these services as a collection of mutually following the principle of least a os so that an attacker would need to multiple to gain complete control of the machine it is in a combination of assembly and a new lowlevel programming language the safe hardware a number of mechanisms for eliminating common and supporting higherlevel security primitives to begin with safe is dynamically typed at the hardware level each data word is marked as a number an instruction a pointer etc next the hardware is memory safe every pointer consists of a triple of base bounds and offset encoded into bits and every pointer operation includes a hardware bounds check finally the hardware associates each word in the registers and memory as well as the pc with a large bit tag the hardware rule cache enabling propagation of tags from operands to result on each machine step is implemented using a combination of multiple hash functions to approximate a cache an feature of the safe design is that formal modeling and verification of its core mechanisms have a central role in the design process since the beginning the goal formally specifying and verifying the entire set of critical runtime still some ways in the future but key properties of simplified models have been verified both at the level of a mostly functional dynamic language used for programming on safe and in the present work at the hardware and abstract machine level experiments are also to use random testing of properties like noninterference as a means to speed the design process our goal in this paper is to develop a clear precise and tractable model of one of the main in the safe design its scheme for efficiently supporting highlevel data use policies using a combination of hardware and lowlevel system software to make the model easy to work with we simplify away many important of the real safe system in particular i we focus only on ifc and noninterference although the tagging facilities of the safe machine are generic and can be applied to other policies we return to this point in § ii we ignore the and programming languages and concentrate on the hardware and runtime services iii we use a stack instead of registers and we the instruction set to just a of iv we drop finegrained separation in of a more conventional v we the rule cache to a single entry avoiding issues of replacement and and maintain it in kernel memory accessed by ordinary loads and stores rather than in specialized cache hardware vi we omit a large number of concepts dynamic principals downgrading public labels integrity etc vii we handle conditions including potential security violations by simply halting the whole machine and most importantly we ignore concurrency process scheduling and communication assuming instead that the whole machine has a single deterministic thread of control the absence basic instruction set add addition output output top of stack push n push integer constant load indirect load from data memory store indirect store to data memory jump indirect jump n conditional relative jump call indirect call ret return figure instruction set of concurrency is a particularly significant simplification given that we are about an operating system that offers ifc as a service however we conjecture that it may be possible to add concurrency to our formalization while maintaining a high degree of determinism by the approach used in the proof of noninterference for the sel we return to this point in § abstract ifc machine we begin the technical development by defining a very simple machine with dynamic ifc this machine the ifc mechanism we want to provide to higherlevel software and serves as a specification for the symbolic ifc rule machine § and for the concrete machine § running our ifc fault handler § the three machines share a instruction set fig designed to be a convenient target for compiling the symbolic ifc rule table the coq development formalizes several other instructions all three machines use a fixed instruction memory a partial function from addresses to instructions the machine integers ranged over by n m and p unlike the real safe machine we make no distinction between raw integers and pointers we this distinction in § each integer is protected by an individual ifc label ranged over by l we assume an arbitrary set of labels l equipped with a partial order a least upper bound operation and a bottom element for instance we might take l to be the set of levels with and we call a pair of an integer n and its label l an atom written nl and ranged over by a an abstract machine state µ pc consists of a data memory µ a stack and a program counter pc we sometimes drop the outer brackets the data memory µ is a partial function from integer addresses to atoms we write a for the memory that coincides with µ everywhere except at p where its value is a the stack is essentially a list of atoms but we distinguish stacks beginning with return addresses written pc from ones beginning with regular atoms written a the program counter pc pc is an atom whose label is used to track implicit flows as explained below the step relation of the abstract machine written µ pc µ pc is a partial function taking a machine state to a machine state plus an output action which can be either an atom or the action we generally omit from transitions because it is fixed throughout the paper we study other similar relations and consistently refer to actions as events ranged over by e the rules in fig adapt a standard purely dynamic ifc enforcement mechanism to a lowlevel machine following recent work by et al the rule for add joins the labels of the two operands to produce the label of the result which ensures that the result is at least as classified as each of the operands the rule for push labels the integer constant added to the stack as public the rule for jump uses join to raise the label n add µ nl nl µ n output µ ml µ n push m µ µ m n load ml µ pl µ n store k l µ l µ pl ml µ n jump µ n l µ n n k n nm k µ ml µ n n call µ n l a µ a n n ret µ n l µ n l figure semantics of ifc abstract machine of the pc by the label of the target address of the jump similarly raises the label of the pc by the label of the tested integer in both cases the value of the pc after the instruction depends on data that could be secret and we use the label of the pc to track the label of data that has control flow in order to prevent implicit flows leaks exploiting the control flow of the program the store rule joins the pc label with the original label of the written integer and with the label of the pointer through which the write happens additionally since the labels of memory locations are allowed to vary during execution we prevent information via labels using a check the precondition in the rule for store this check prevents memory locations labeled public from being when either the pc or the pointer through which the store happens have been by the output rule labels the integer with the join of its original label and the current pc label finally because of the structured control flow imposed by the stack discipline the rule for ret can soundly restore the pc label to whatever it was at the time of the call readers less familiar with the of dynamic ifc may find some of these side conditions a bit a longer explanation can be found in but the details are not critical for present purposes all data in the machines initial state are labelled as in all machine states and the simple machine labels to ensure noninterference as defined and proved in § there are no instructions that explicitly raise the label classification of an atom such an instruction is added to the machine in § we assume the of the events generated by output is constrained by the rules of information cannot freely look inside events in the real safe machine atoms being sent to the outside world need to be protected we are abstracting this away allow add true output true push true load true store lab jump true true call true ret true lab lab lab lab lab er lab lab bot lab lab lab lab lab figure rule table corresponding to abstract ifc machine symbolic ifc rule machine in the abstract machine described above ifc is integrated into the step relation in the form of side conditions on each instruction in contrast the concrete machine ie the hardware described in § is generic designed to support a wide range of policies ifc and other the machine introduced in this section serves as a between these two models it is closer to the abstract its machine states and the behavior of the step relation are identical the important difference lies in the definition of the step relation where all the aspects are out into a separate judgment while factoring out ifc enforcement into a separate reference monitor is our approach goes further we define a small for describing symbolic ifc rules and obtain actual monitors by interpreting this in this section and by compiling it into machine instructions using verified structured code generators in § and § more formally each rule of the new machine includes a uniform call to an ifc enforcement relation which itself is parameterized by a symbolic ifc rule table r given the labels of the values relevant to an instruction the ifc enforcement relation i checks whether the execution of that instruction is allowed in the current configuration and ii if so yields the labels to put on the resulting pc and on any resulting value this judgment has the form r lr where r is the rule table and is the kind of instruction currently executing for example the rule for add n add r l l add lr µ nl nl µ passes three inputs to the ifc enforcement judgment the label of the current pc and l and l the labels of the two operands at the top of the stack the fourth element of the input tuple is written as because it is not needed for add the ifc enforcement judgment produces two labels is used to label the next program counter n and lr is used to label the result value all the other rules follow a similar scheme the one for store uses all four input labels a symbolic ifc rule table r describes a particular ifc enforcement mechanism for instance the rule table corresponding to the ifc mechanism of the abstract machine is shown in fig in general a table r associates a symbolic ifc rule to each instruction formally r is a total function each of these rules is formed of three symbolic expressions i a boolean expression indicating whether the execution of the instruction is allowed or not ie whether it violates the ifc enforcement mechanism ii a expression for the label of the next pc and iii a expression for lr the label of the result value if there is one these symbolic expressions are written in a simple domainspecific language of operations over an ifc lattice the grammar of this includes label variables lab which correspond to the input labels l the constant bot and the lattice operators join and flows the ifc enforcement judgment looks up the corresponding symbolic ifc rule in the table and directly evaluates the symbolic expressions in terms of the corresponding lattice operations the definition of this interpreter is completely straightforward we omit it for brevity in contrast in § we compile this rule table into the ifc fault handler for the concrete machine concrete machine the concrete machine provides lowlevel support for efficiently implementing many different highlevel policies ifc and others with a combination of a hardware rule cache and a software cache fault handler in this section we focus on the concrete machines hardware which is completely generic while in § we describe a specific fault handler corresponding to the ifc rules of the symbolic rule machine the concrete machine has the same general structure as the more abstract ones but differs in several important respects one is that it data values with integer tags t rather than with labels l from an abstract lattice thus the concrete atoms a in the data memories and the stack have the form nt similarly a concrete action is either a concrete atom or the action using plain integers as tags allows us to their interpretation entirely to software in this paper we focus solely on using tags to implement ifc labels although they could also be used for enforcing other policies such as type and memory safety or controlflow integrity for instance to implement the abstract lattice with we could use to represent and to represent making the operations and easy to implement see § for richer abstract lattices a more complex concrete representation might be needed for example a label containing an arbitrary set of principals might be represented concretely by a pointer to an array data structure see § in places where a tag is needed but its value is irrelevant the concrete machine uses a specific but arbitrary default tag value eg which we write td a second important difference is that the concrete machine has two modes user mode u for executing the ordinary user program and kernel mode k for handling rule cache to support these two modes the concrete machines state contains a bit a separate kernel instruction memory and a separate kernel data memory in addition to the user instruction memory the user data memory µ the stack and the pc when the machine is operating in user mode u instructions are up using the pc as an index into and loads and stores use µ when in kernel mode k the pc is treated as an index into and loads and stores use as before since and are fixed we normally leave them implicit the concrete machine has the same instruction set as the previous ones allowing user programs to be run on all three machines unchanged but the semantics of instructions depends on the mode and in user mode the semantics further depends on the state of the rule cache in the real safe machine the rule cache may contain of entries and is implemented as a separate memory accessed by special instructions here for simplicity we use a cache with just one entry located at the start of kernel memory and use load and store instructions to manipulate it indeed until § it the of the rule cache holds a single rule instance represented like this t t t tr location holds an integer representing an location holds the pc tag locations to hold the tags of any other arguments needed by this particular location holds the tag that should go on the pc after this instruction executes and location holds the tag for the instructions result value if needed for example suppose the cache contains add note that we are showing just the part of these atoms by convention the tag part is always td and we do not display it if is the tag representing the label represents and is the default tag td this can be interpreted abstractly as follows if the next instruction is add the pc is labeled and the two relevant arguments are both labeled then the instruction should be allowed the label on the new pc should be and the label on the result of the operation is there are two sets of rules for the concrete machine in user mode which set applies depends on whether the current machine state matches the current contents of the rule cache in the cache case the instruction executes normally with the caches output determining the new pc tag and result tag if any in the cache miss case the relevant parts of the current state pc tag argument tags are stored into the input part of the single cache line and the machine simulates a call to the fault handler to see how this works in more detail consider the two rules for the add instruction n add add t t td tr u µ nt nt u µ n add i add t t td j u i o µ nt nt k j d µ u nt nt td in the first rule cache the side condition demands that the input part of the current cache contents have form add t t td where is the tag on the current pc t and t are the tags on the top two atoms on the stack and the fourth element is the default tag in this case the output part of the rule tr determines the tag on the pc and the tag tr on the new atom pushed onto the stack in the next machine state in the second rule cache miss the notation i o means let i be the input part of the current rule cache and o be the output part the side condition says that the current input part i does not have the desired form add t t td so the machine needs to enter the fault handler the next machine state is formed as follows i the input part of the cache is set to the desired form j and the output part is set to d td td ii a new return frame is pushed on top of the stack to remember the current pc and bit u iii the bit is set to k which will cause the next instruction to be read from the kernel instruction memory and iv the pc is set to the location in the kernel instruction memory where the fault handler routine begins what happens next is up to the fault handler code its job is to examine the contents of the first five kernel memory locations and either i write appropriate tags for the result and new pc into the and kernel memory locations and then perform a ret to go back to user mode and the instruction or ii stop the machine by to an invalid pc to signal that the combination of and argument tags is illegal this mechanism is general and can be used to implement many different highlevel policies ifc and others in kernel mode the treatment of tags is almost completely to avoid infinite the concrete machine does not the rule cache while in kernel mode for most instructions tags read from the current machine state are ignored indicated by and tags written to the new state are set to td this can be seen for instance in the step rule for addition n add k µ n n n k µ the only significant exception to this pattern is ret which takes both the bit and the new pc including its tag from the return frame at the top of the stack this is critical since a ret instruction is used to return from kernel to user mode when the fault handler has finished executing n ret k µ n t n µ n t a final point is that output is not permitted in kernel mode which guarantees that kernel actions are always the action fault handler for ifc now we the pieces a concrete ifc machine implementing the symbolic rule machine defined in § can be obtained by appropriate fault handler code in the kernel instruction memory of the concrete machine presented in § in essence this handler must how the symbolic rule machine looks up and evaluates the expressions in a given ifc rule table we choose to generate the handler code by compiling the lookup and evaluation relations directly into machine code an alternative would be to represent the rule table as abstract syntax in the kernel memory and write an interpreter in machine code for the but the compilation approach seems to lead to simpler code and proofs the handler compilation scheme is given in part in fig each gen function generates a list of concrete machine instructions the sequence generated by the toplevel is intended to be starting at location in the concrete machines kernel instruction memory the implicit addr parameters are symbolic names for the locations of the and various tags in the concrete machines rule cache as described in § the entire generator is parameterized by an arbitrary rule table r we make heavy use of the obvious encoding of booleans where false is represented by and true by any nonzero value we omit the straightforward definitions of some of the leaf generators the toplevel handler works in three phases the first phase does most of the work it consists of a large nested ifthenelse chain built using that compares the of the instruction against each possible and on a match executes the code generated for the corresponding symbolic ifc rule the code generated for each symbolic ifc rule by pushes its results onto the stack a flag indicating whether the instruction is allowed and if so the and tags this first phase never writes to memory or transfers control outside the handler this makes it fairly easy to prove correct the second phase reads the computed results off the stack and updates the rule cache appropriately if the result indicates that the instruction is allowed the result pc and value tags are written to the cache and true is pushed on the stack otherwise nothing is written to the cache and false is pushed on the stack the third and final phase of the toplevel handler tests the boolean just pushed onto the stack and either returns to user code instruction is allowed or jumps to address the code for symbolic rule compilation is built by straightforward recursive traversal of the rule syntax for expressions and expressions these functions are implicitly parameterized by generators and to implement these r r ret push jump r op push op allow er allow er bot le le le le true le le le le g where g nil g n ns n n g ns t f length f f t where f f t n n n n add output ret nil figure generation of fault handler from ifc rule table generators for a particular lattice we first need to choose how to represent abstract labels as integer tags and then determine a sequence of instructions that encodes each operation we call such an encoding scheme a concrete lattice for example the abstract labels in the lattice can be encoded like booleans representing by by non and instantiating and with code for computing false disjunction and implication respectively a simple concrete lattice like this can be formalized as a tuple cl tag lab where the encoding and functions lab and tag satisfy lab tag id to the we assume this form of concrete lattice for most of the paper the more realistic encoding in § will require a more complex treatment to raise the level of abstraction of the handler code we make heavy use of structured code generators this makes it easier both to understand the code and to prove it correct using a custom hoare logic that follows the structure of the generators see § for example the function takes two code sequences representing the then and else branches of a conditional and generates code to test the top of the stack and dispatch control appropriately the higherorder generator takes a list of integer indices eg and functions for generating guards and branch bodies from an index and generates code that will run the guards in order until one of them computes true at which point the corresponding branch body is run correctness of the fault handler generator we now turn our attention to verification beginning with the fault handler we must show that the generated fault handler the ifc enforcement judgment r lr of the symbolic rule machine the statement and proof of correctness are parametric over the symbolic ifc rule table r and con lattice and hence over correctness lemmas for the lattice operations correctness statement let r be an arbitrary rule table and r r be the corresponding generated fault handler we specify how r behaves as a a relation between initial state on entry and final state on the relation cs k cs defined as the reflexive transitive closure of the concrete step relation with the constraints that the fault handler code is and all intermediate states ie strictly preceding cs have bit k the correctness statement is captured by the following two lemmas intuitively if the symbolic ifc enforcement judgment allows some given user instruction then executing r stored at kernel mode location updates the cache to contain the tag encoding of the appropriate result labels and returns to otherwise r halts the machine pc lemma fault handler correctness allowed case suppose that r lr and i tag tag tag then r k i o µ pc u td k u i o µ pc with output cache o tag tag lr lemma fault handler correctness case suppose that r and i tag tag tag then for some final stack r k i o µ pc u td k k i o µ td proof methodology the fault handler is compiled by composing generators fig accordingly the proofs of these two lemmas reduce to correctness proofs for the generators we employ a custom hoare logic for specifying the generators themselves which makes the code generation proof simple and scalable this is where defining a for ifc rules and a structured compiler proves to be very useful approach eg compared to symbolic interpretation of code our logic two notions of hoare triple the generated code mostly consists of instruction sequences that terminate by off the that never return or jump outside themselves although they may contain internal jumps eg to implement conditionals the only exception is the final step of the handler third line of in fig we therefore define a standard hoare triple p c q suitable for reasoning about code and use it for the of the proof to specify the final handler step we define a nonstandard triple p c for reasoning about code hoare triples the triple p c q where p and q are predicates on × says that if the kernel instruction memory contains the code sequence c starting at the current pc and if the current memory and stack satisfy p then the machine will run in kernel mode until the pc points to the instruction immediately following the sequence c with a resulting memory and stack satisfying q note that the instruction memory is unconstrained outside of c so if c is not no triple about it will be provable thus these triples the usual composition laws also because the concrete machine is deterministic these triples express total rather than partial correctness which is essential for proving termination in lemmas and to aid automation of proofs about code sequences we give triples in style we build proofs by composing atomic specifications of individual instructions such as p n t n t nt nt q p add q with specifications for structured code generators such as p n t nt n p n p p c q p c q p c c q we emphasize that all such specifications are verified not as the inference rule notation might suggest the concrete implementations of the lattice operations are also specified using triples in this style p q tag td p q p l l tag tag l td q tag ll td p q p l l tag tag l td q if l l then else td p q for the lattice it is easy to prove that the implemented operators satisfy these specifications § describes an analogous result for a lattice of sets of principals hoare triples to be able to specify the entire code of the generated fault handler we also define a second form of triple p c which specifies mostly total code c that either makes exactly one jump outside of c or returns out of kernel mode more precisely if p and q are predicates on × and o is a function from × to outcomes the constants success and failure then p c holds if whenever the kernel instruction memory contains the sequence c starting at the current pc the current cache and stack satisfy p and · if o computes success then the machine runs in kernel mode until it returns to user code at pc and q is satisfied · if o computes failure then the machine runs in kernel mode until it halts pc in kernel mode and q is satisfied to compose code with code we prove two composition laws for these triples one for with specified code and another for with arbitrary unreachable code p c p p c p cc p c q p cc q we use these new triples to specify the ret and jump instructions which could not be given useful specifications using the triples eg p q pc u o success p ret q everything comes together in verifying the fault handler we use triples to specify everything except for ret jump and the final and then use the triple composition laws to connect the part of the fault handler to the final refinement we have two remaining verification goals first we want to show that the concrete machine of § running the fault handler of § compiled from proving this directly for the concrete machine would be complex so instead we show that the concrete machine is an implementation of the abstract machine for which noninterference will be much easier to prove § second since a trivial machine also has we want to show that the concrete machine is a faithful implementation of the abstract machine that all its behaviors we phrase these two results using the notion of machine refinement which we develop in this section and which we prove in § to be preserving in § we prove a refinement one direction for each goal between the abstract and concrete machines via the symbolic rule machine in both directions from here on we sometimes mention different machines abstract symbolic rule or concrete in the same statement eg when discussing refinement and sometimes talk about machines eg when defining for all our machines for these purposes it is useful to define a generic notion of machine definition a generic machine or just machine is a tuple m s e i · · init where s is a set of states ranged over by s e is a set of events ranged over by e · · s × e × s is a step relation and i is a set of input data ranged over by i that can be used to build initial states of the machine with the function init i s we call e the set of actions of m ranged over by conceptually a machines program is included in its input data and gets loaded by the function init which also the machine memory stack and pc the notion of generic machine abstracts all these details allowing uniform definitions of refinement and that apply to all three of our ifc machines to avoid stating it several times below we that when we instantiate definition to any of our ifc machines init must produce an initial stack with no return frames a generic step s e s or s s produces event e or is the closure of such steps steps written s t s produces lists t of events when the end state of a step starting in state s is not relevant we write s e and similarly s t for traces when relating executions of two different machines through a refinement we establish a correspondence between their traces this relation is usually derived from an elementary relation on events e × e which is lifted to actions and traces x y e e i xi yi definition and m refinement s e i · let m · init s e i · · init be two machines a refine ment of m into m is a pair of relations i e where i i × i and e e × e such that whenever i i i and init i t there exists a trace t such that init i t and t e t we also say that m refines m i init i t i i init i t e plain lines denote premises dashed ones conclusions in order to prove refinement we need a variant that considers executions starting at arbitrary related states definition refinement via states let m m be as above a state refinement of m into m is a pair of relations s e where s s × s and e e × e such that whenever s s s and s t there exists t such that s t and t e t if the relation on inputs is compatible with the one on states we can use state refinement to prove refinement lemma suppose i i i init i s init i for all i and i if s e is a state refinement then i e is a refinement refinements between concrete and abstract in this section we show that the concrete machine refines the symbolic rule machine and vice versa using we will be able to show in § that the concrete machine is from we know that the concrete machine implements the abstract one exactly its execution traces abstract and symbolic rule machines the symbolic rule machine with the rule table is a simple of the abstract machine their step relations are equal and started from the same input data they emit the same traces definition abstract and symbolic rule machines as generic machines for both abstract and symbolic rule machines input data is a tuple p args n l where p is a program args is a list of atoms the initial stack and n is the size of the memory initialized with n copies of l the initial pc is l lemma the symbolic rule machine instantiated with the rule table refines the abstract machine through concrete machine refines symbolic rule machine we prove this refinement using a fixed but arbitrary rule table r an abstract lattice of labels and a concrete lattice of tags the proof uses the correctness of the fault handler § so we assume that the fault handler of the concrete machine corresponds to the rule table of the symbolic rule machine r and that the encoding of abstract labels as integer tags is correct definition concrete machine as generic machine the input data of the concrete machine is a tuple p args n t where p is a program args is a list of concrete atoms the initial stack and the initial memory is n copies of t the initial pc is t the machine starts in user mode the cache is initialized with an illegal so that the first instruction always and the fault handler code the machine is in the initial instruction memory the input data and events of the symbolic rule and concrete machines are of different kinds they are matched using relations c i and c e respectively that values should be equal and that labels should correspond to tags modulo the function tag of the concrete lattice args map nl args p args n l c i p args n n l c e n theorem the concrete ifc machine refines the symbolic rule machine through c i ce we prove this theorem by a refinement via states lemma this in turn relies on two technical lemmas and the matching relation c s between the states of the concrete and symbolic rule machines is defined as r q c m q nl c s u c where the new notations are defined as follows the relation m demands that the memories be equal up to the conversion of labels to concrete tags the relation on stacks is similar but additionally requires that return frames in the concrete stack have their bit set to u the basic idea is to match in cs only concrete states that are in user mode we also need to track an extra invariant r which means that the cache is consistent with the table never lies more precisely the output part of represents the result of applying the symbolic rule judgment of r to the and labels represented in the input part of r i o l l l i lr r l l l lr o tag tag lr to prove refinement via states we must account for two tions first suppose the concrete machine can take a user step in this case we match that step with a single symbolic rule machine step we write cs to denote a concrete state cs whose bit is lemma refinement concrete step let be a concrete state and suppose that c let qs be a symbolic rule machine state with qs c s then there exist qs and a such that qs a qs with qs c s and a c e c since the concrete machine is able to make a user step the input part of the cache must match the and data of the current state but the invariant r says that the corresponding symbolic rule judgment holds hence the symbolic rule machine can also make a step from qs as required the second case is when the concrete machine into kernel mode and returns to user mode after some number of steps lemma refinement concrete step let be a con state and suppose that the concrete machine does a step to in kernel mode until and then exits kernel mode by to let qs be a state of the symbolic rule machine that matches then qs c s to prove this lemma we must consider two cases if the corresponding symbolic rule judgment holds then we apply lemma to conclude the machine exits kernel code into user mode otherwise we apply lemma and derive a contradiction that the fault handler ends in a failing state in kernel mode lemmas and can be summarized by qs qs a qs c c s c s c s c e s c k given two matching states of the concrete and symbolic rule machines and a concrete execution starting at that concrete state these two lemmas can be applied repeatedly to build a matching execution of the symbolic rule machine there is just one last case to consider namely when the execution ends with a fault into kernel mode and never returns to user mode however no output is produced in this case that the full trace is matched we thus derive the following refinement via states of which theorem is a corollary lemma the pair c s ce defines a refinement via states between the symbolic rule machine and the concrete machine concrete machine refines abstract machine by composing the refinement of lemma and the refinement of theorem in to the concrete machine running we can conclude that the concrete machine refines the abstract one abstract machine refines concrete machine the previous refine ment cs c e would also hold if the fault handler never returned when called so to ensure the concrete machine reflects the of the abstract machine we next prove an inverse refinement theorem the abstract ifc machine refines the concrete ifc machine via of c i i c and c e ec where c i and c e are the relational this guarantees that traces of the abstract machine are also by the concrete machine as above we use the symbolic rule machine as an intermediate step and show a state refinement of the concrete into the symbolic rule machine we rely on the following lemma where c s is the inverse of sc lemma forward refinement let qs and cs be two states with cs c s qs suppose that the symbolic rule machine takes a step qs a qs then there exist concrete state cs and action c such that cs c cs with cs c s qs and c c e a to prove this lemma we consider two cases if the cache input of cs matches the and data of cs then the concrete machine can take a step cs c cs moreover r in cs says the cache output is consistent with the symbolic rule judgment so the tags in c and cs are properly related to the labels in a and qs otherwise a cache fault occurs loading the cache input and calling the fault handler by lemma and the fact that qs a qs the cache output is computed to be consistent with r and this allows the concrete step as discussion the two toplevel refinement properties and share the same notion of matching relations but they have been proved independently in our coq development in the context of compiler verification another proof methodology has been a backward simulation proof can be obtained from a proof of forward simulation under the assumption that the machine is deterministic also requires a hypothesis that trivially holds in our context since our concrete machine is deterministic we could apply a similar technique however unlike in compiler verification where it is common to assume that the source program has a welldefined semantics ie it does not get stuck we would have to consider the possibility that the highlevel semantics the symbolic rule machine might block and prove that in this case either the ifc enforcement judgment is stuck and lemma applies or the current symbolic rule machine state and matching concrete state are both noninterference in this section we define for generic machines show that the abstract machine of § satisfies theorem that is preserved by refinement theorem and finally using the fact that the concrete ifc machine refines the abstract one theorem that the concrete machine satisfies theorem noninterference to define noninterference we need to talk about what can be observed about the output trace produced by a run of a machine definition observation a notion of observation for a generic machine is a tuple · · · · · is a set of ie different of power to observe ranged over by o for each o · o e is a predicate of of events for o and · o · i × i is a relation of of input data for o we write t o for the trace in which all events in t are out using · o we write t t to say that traces t and t are this the longer trace to the same length as the and then demands that the remaining elements be pairwise identical definition a machine s e i · · init with a notion of observation · · · · · satisfies if for any o pair of initial data i o i and pair of executions t and t we have t o t o since a machines program is part of its input data this definition of quantified over all and input data is conceptually quantified over all programs too because of the of traces the cannot detect the absence of output ie it cannot distinguish between successful termination failure with an error or entering an infinite loop with no observable output this property is standard for a machine with output for abstract machine definition observation for abstract machine let l be a lattice with partial order define of atoms a oa a by a ao a ¬ a o ¬ a o a oa a the notion of observation is l · · · where n l a o lo p args n l oa p args n l args ao args on the righthand side of the second equation ao is of atoms lifted to lists we prove for the abstract machine using a set of standard conditions for this we need to define on states and thus also of stacks this is where we one of stacks is defined pointwise when the label of the pc is observable o when the pc label is not observable however we only require that the stacks are pointwise related below the most recent call from an observable state this is necessary because the two machines run in lock step only when their pc labels are observable they can execute completely different instructions otherwise theorem the abstract ifc machine preserved by refinement theorem preservation suppose that generic machine m refines m by refinement i e and that each machine is equipped with a notion of observation suppose that for all ob servers o of m there exists an o of m such that the following compatibility conditions hold for all e e e all e e e and all i i i i e ee e o e o ii i o i io i i i i i i i iii e o e e e e e e e e o e then if m has m also has some of noninterference are subject to the refinement in which refinements of a system may violate noninterference we avoid this issue by a strong notion of noninterference that restricts the amount of nondeterminism in the system and is thus preserved by any refinement theorem since our abstract machine is deterministic it is easy to show this strong notion of noninterference for it in § we discuss a possible technique for generalizing to the concurrent setting while preserving a high degree of determinism it is called noninterference in a recent survey the recent noninterference proof for the sel works similarly see § alloc eq id pack dup n swap n extensions to instruction set allocate a new frame fetch frame size value equality system call extract pointer offset atom from and tag atom into and tag push cache address on stack duplicate atom on stack swap two data atoms on stack figure additional instructions for extensions n alloc alloc k a µ id µ µ int k l a µ ptr id l n length k µ ptr id ol µ int k l n µ ptr id ol µ int ol n eq µ vl vl µ int v n id t id k f f vl length k µ µ vl figure semantics of selected new abstract machine instructions for concrete machine with ifc fault handler it remains to define a notion of observation on the concrete machine instantiating the definition of for this machine this definition refers to a concrete lattice cl which must be a correct encoding of an abstract lattice l the lattice operators and must satisfy the specifications in § definition observation for the concrete machine let l be an abstract lattice and cl be correct with respect to l the observation for the concrete machine is l · c · · · where n t c o o p args n t co p args n t args oa args and map fun nl finally we prove that the backward refinement proved in § satisfies the compatibility constraints of theorem so we derive theorem the concrete ifc machine running the fault handler satisfies an extended system thus far we have described our model and proof results only for a simple machine architecture and ifc discipline our coq development actually works with a significantly more sophisticated model extending the basic machine architecture with a memory model supporting dynamic allocation and a system call mechanism for adding primitives building on these features we define an abstract ifc machine that uses sets of principals as its labels and a corresponding concrete machine implementation n alloc alloc k u a µ id µ alloc t td td tr u µ int k t a u µ ptr id tr n alloc alloc k k a µ id µ k µ int k a n k µ ptr id td n k µ n k µ ptr cache td n k µ vv n k µ n pack k µ v v n k µ vv n id t id k n length k u µ nt k µ nt u n td figure semantics of selected new concrete machine instructions where tags are pointers to dynamically allocated representations of these sets while still much less complex than the real safe system this extended model shows how our basic approach can be incrementally up to more realistic designs verifying these extensions requires no major changes to the proof architecture of the basic system as evidence of its fig shows the new instructions supported by the extended model instruction and pack are used only by the concrete machine for the compiled fault handler hence they only have a rule they simply get stuck if executed outside kernel mode or on an abstract machine we also add two instructions dup and swap to make programming the kernel routines more convenient it remains true that any program for the abstract machine makes sense to run on the abstract rule machine and the concrete machine for brevity we detail rules only for the extended abstract ifc machine fig and concrete machine fig corresponding extensions to the symbolic ifc rule machine are straightforward we also omit rules for dup and swap individual rules are explained below dynamic memory allocation highlevel programming languages usually assume a structured memory model in which independently allocated frames are disjoint by construction and programs cannot depend on the relative placement of frames in memory the safe hardware enforces this abstraction by explicit runtime types to all values distinguishing pointers from other data only data marked as pointers can be used to access memory to obtain a pointer one must either call the memory manager to allocate a fresh frame or else offset an existing pointer in particular it is not possible to a pointer from an integer each pointer also carries information about its base and bounds and the hardware prevents it from being used to access memory outside of its frame memory model in our extended system we model the view of memory system by adding a memory distinguished pointers so values the field of atoms and the tag field of concrete atoms can now either be an integer int n or a pointer ptr p and an allocation instruction to our basic machines we do this nearly uniformly at all levels of abstraction a pointer is a pair p id o of a frame identifier id and an offset o into that frame in the machine state the data memory µ is a partial function from pointers to individual storage cells that is undefined on pointers by of notation µ is also a partial function from frame identifiers to frames which are just lists of atoms the most important new rule of the extended abstract machine is alloc fig in this machine there is a separate memory region assumed infinite corresponding to each label the auxiliary function alloc in the rule for alloc takes a size k the label region at which to allocate and a default atom a it extends µ with a fresh frame of size k its contents to a it returns the id of the new frame and the extended memory µ ifc and memory allocation we require that the frame identifiers produced by allocation at one label not be affected by allocations at other labels eg alloc might allocate sequentially in each region thus of low atoms is just syntactic equality preserving definition from the simple abstract machine which is convenient for proving noninterference as we explain below we allow a program to observe frame sizes using a new instruction which requires the result of alloc with l the label of the size argument there are also new instructions eq for comparing two values including pointers for equality and for extracting the offset field of a pointer into an integer however frame ids are intuitively abstract the concrete representation of frame ids is not accessible and pointers cannot be or output the extended concrete machine rules for these new instructions are analogous to the abstract machine rules with the important exception of alloc which is discussed below a few small modifications to existing instructions in the basic machine fig are needed to handle pointers properly in particular i load and store require pointer arguments and get stuck if the pointers offset is out of range for its frame ii add takes either two integers or an integer and a pointer where int n int m int nm and ptr id o int o ptr id oo iii output works only on integers not pointers analogous modifications are needed in the concrete machine semantic rules concrete allocator the extended concrete machines semantics for alloc differ from those of the abstract machine in one key respect using one region per tag would not be a realistic strategy for a concrete implementation eg the number of different tags might be extremely large instead we use a single region for all allocations at the concrete level we also the separate user and kernel memories from the basic concrete machine into a single memory since we still want to be able to distinguish user and kernel frames we mark each frame with a mode ie we use two allocation regions fig shows the corresponding concrete rule for alloc for two cases user mode and kernel mode the concrete load and store rules prevent dereferencing kernel pointers in user mode the rule cache is now just a distinguished kernel frame cache to access it the fault handler uses the instruction proof by refinement as before we prove noninterference for the concrete machine by combining a proof of noninterference of the abstract machine with a proof that the concrete machine refines the abstract machine by using this approach we avoid some wellknown difficulties in proving noninterference directly for the concrete machine in particular when frames allocated in low and high contexts share the same region allocations in high contexts can cause variations in the precise pointer values returned for al it would be interesting to describe an implementation of the memory manager in a concrete machine with no builtin alloc instruction but we leave this as future work locations in low contexts and these variations must be taken into account when defining the relation for example and prove noninterference by their relation with a partial bijection that keeps track of memory addresses our approach by contrast defines pointer only at the abstract level where low pointers are identical this proof strategy still requires relating memory addresses when showing refinement but this relation does not appear in the noninterference proof at the abstract level the refinement proof itself uses a simplified form of memory the differences in the memory region structure of both machines are significant but to programs since no information about frame ids is to programs beyond what can be obtained by comparing pointers for equality this restriction allows the refinement proof to go through straightforwardly system calls to support the implementation of primitives on top of the concrete machine we provide a new system call instruction the id instruction is parameterized by a system call identifier the step relation of each machine is now parameterized by a table t that maps system call identifiers to their implementations in the abstract and symbolic rule machines a system call implementation is an arbitrary coq function that removes a list of atoms from the top of the stack and either puts a result on top of the stack or fails halting the machine the system call implementation is responsible for computing the label of the result and performing any checks that are needed to ensure noninterference in the concrete machine system calls are implemented by kernel routines and the call table contains the entry points of these routines in the kernel instruction memory executing a system call involves inserting the return address on the stack the call arguments and to the corresponding entry point the kernel code terminates either by returning a result to the user program or by halting the machine this feature has no major impact on the proofs of noninterference and refinement for noninterference we must show that all the abstract system calls preserve of abstract machine states for refinement we show that each concrete system call correctly implements the abstract one using the machinery of § labeling with sets of principals the full safe machine supports dynamic creation of security principals in the extended model we make a first step toward dynamic principal creation by taking principals to be integers and instantiating the parametric lattice of labels with the lattice of finite sets of integers in this lattice is is and is we our ifc model by adding a new classification primitive that adds a principal to an atoms label encoded using the system call mechanism described above the operation of is given by the following derived rule which is an instance of the rule from fig n µ vl int ml µ at the concrete level a tag is now a pointer to an array of principals integers stored in kernel memory to keep the fault handler code simple we do not maintain canonical representations of sets one set may be represented by different arrays and a given array may have duplicate elements as a consequence the mapping from abstract labels to tags is no longer a function we return this lattice is statically known but models dynamic creation by supporting unbounded labels and having no top element to this point below since the fault handler generator in the basic system is parametric in the underlying lattice it doesnt require any modification all we must do is provide concrete implementations for the appropriate lattice operations just allocates a fresh array and both argument arrays into it checks for array inclusion by through one array and testing whether each element appears in the other and allocates a new empty array finally we provide kernel code to implement which requires two new instructions pack and fig to manipulate the and tag fields of atoms otherwise the implementation is similar to that of a more realistic system would keep canonical representations of sets and avoid unnecessary allocation in order to improve its memory footprint and tag cache usage but even with the present approach both the code for the lattice operations and their proofs of correctness are significantly more elaborate than for the trivial lattice in particular we need an additional code generator to build counted loops eg for computing the join of two tags c dup push add where c c dup length c here c is a code sequence representing the loop body which is expected to preserve an index value on top of the stack the generator builds code to execute that body repeatedly the index each time until it reaches the corresponding specification is pn t nt inv qn t nt t inv n t n n pn c qn p n t n nt inv q t t inv p c q to avoid reasoning about memory updates as far as possible we code in a style where all local context is stored on the stack and manipulated using dup and swap although the resulting code is it is relatively easy to the corresponding proofs stateful encoding of labels changing the representation of tags from integers to pointers requires modifying one small part of the basic system proof recall that in § we described the encoding of labels into tags as a pure function lab to deal with the and representation of sets described above the extended system instead uses a relation between an abstract label a concrete tag that encodes it and a memory in which this tag should be interpreted if tags are pointers to data structures it is crucial that these data structures remain as long as the tags appear in the machine state we guarantee this by maintaining the very strong invariant that each execution of the fault handler only allocates new frames and never modifies the contents of existing ones except for the cache frame which tags never point into a more realistic implementation might use mutable kernel memory for other purposes and garbage collect unused tags this would require a more complicated memory invariant the formulation is similar in essence to the one in § but some arise for concrete output events since tags in events cannot be interpreted on their own we wish to i keep the semantics of the concrete machine independent of highlevel policies such as ifc and ii give a statement of noninterference that does not refer to pointers to achieve these aims we model an event of the concrete machine as a pair of a concrete atom plus the whole state of the kernel memory the resulting trace of concrete events is abstracted ie interpreted in terms of abstract labels only when stating and proving this is an of what happens in the real safe machine where communication of labeled data with the outside world involves cryptography modeling this is left as future work related work the safe design a number of research areas and a overview of related work would be we focus here on a small set of especially relevant points of comparison the long version discusses additional related work languagebased ifc static approaches to ifc have generally dominated languagebased security research etc however statically enforcing ifc at the lowest level of a real system is challenging soundly analyzing native with reasonable precision is hard even more so without the compilers eg for or proofcarrying code etc and typed assembly language etc have been used for enforcing ifc on lowlevel code without lowlevel analysis or adding the compiler to the in safe we follow a different approach enforcing noninterference using purely dynamic checks for arbitrary in a instruction set the mechanisms we use for this are similar to those found in recent work on purely dynamic ifc for highlevel languages etc however as far as we know we are the first to push these ideas to the lowest level sel et al recently demonstrated a noninterference proof for the implementation of the sel this proof is carried out by refinement and the specification and most of the existing functional correctness proof of sel like the property in this paper the variant of noninterference used by et al is preserved by refinement because it implies a high degree of determinism this organization of their proof was responsible for a significant in effort even when factoring in the additional work required to remove all observable nondeterminism from the sel specification beyond these safe and sel rely on completely different mechanisms to achieve different notions of noninterference whereas in safe each word of data has an ifc label and labels are propagated on each instruction the sel kernel maintains separation between several large partitions eg one partition can run an version of linux and ensures that information is between such partitions only in with a fixed access control policy in parallel work et al etc verified information flow security for a separation kernel running on and using a memory management unit for physical protection of memory regions belonging to different partitions the authors argue that noninterference is not well suited for systems in which components are to communicate with each other instead they use the bisimulation proof method to show trace equivalence between the real system and an ideal toplevel specification that is secure by construction as in sel the proof methodology an abstract treatment of scheduling but the authors this is to be expected when information flow is to be taken into account and the safe architecture a number of from earlier paper designs in particular the design first proposed the idea of a operating system and sketched a concrete architecture while the project proposed using a hardware rule cache to speed up informationflow tracking in and tags had a fixed set of fields and were of limited length whereas in safe tags are pointers to arbitrary data structures allowing them to represent complex ifc labels encoding sophisticated security policies moreover unlike and which made no formal soundness claims safe proposes a set of ifc rules at achieving noninterference the proof we present in this paper though for a simplified model provides evidence that this goal is within reach and other ifc systems enforces informationflow policies for x using binary rewriting static analysis and augmented hardware binary rewriting is used to make implicit flows explicit it relies on static analysis for the programs controlflow graph and performing and alias analysis the augmented hardware architecture associates labels with registers and memory and updates these labels on each instruction to track explicit flows additional security registers are used by the binary translation mechanism to help track implicit flows recently proved in coq that the main ideas in can be used to achieve noninterference for a simple while language unlike safe achieves noninterference purely dynamically and does not rely on binary rewriting or static analysis of moreover the safe hardware is generic simply caching instances of rules while many other information flow tracking systems based on binary rewriting have been proposed few are concerned with soundly handling implicit flows and even these do so only to the extent they can statically analyze since unlike and safe these systems use hardware the overhead for tracking implicit flows can be large to reduce this overhead recent systems track implicit flows or not at a reasonable tradeoff in settings such as analysis or attack detection where speed and precision are more important than soundness hardware taint tracking the last has seen significant progress in specialized hardware for taint tracking etc most commonly a single tag bit is associated with each word to specify if it is or not initially at lowlevel memory attacks by preventing the use of pointers and the execution of instructions etc taint tracking has also been used to prevent highlevel attacks such as sql injection and in contrast to safe these systems efficiency and overall over the soundness of the analysis a heuristic balance between false positives and false attacks as a consequence these systems ignore implicit flows and often dont even track all explicit flows while early systems supported a single taint propagation policy recent ones allow the policy to be defined in software and support monitoring policies that go beyond taint tracking etc for example provides a pair of caches that are quite similar to the safe rule cache possibly these could even be adapted to enforcing noninterference in which case we expect the proof methodology introduced here to apply verification of lowlevel code the challenge in verifying machine code is with control flow our approach using structured generators to build the fault handler is similar to the mechanisms used in system and by et al but there are several points of difference these systems each build macros on top of a powerful lowlevel program logic for machine code ni and xcap in the case of whereas we take a simpler adhoc approach building directly on our stack machines relatively highlevel semantics both these systems are based on separation logic which we can do without since at least in the present simplified model we have very few memory operations to reason about we have instead focused on developing a simple hoare logic specifically suited to verifying structured code eg we omit support for arbitrary code pointers but add support for reasoning about termination we use hoare triples similar to and gordon and weakest preconditions to guarantee progress not just safety for our handler code finally our level of automation is much more than though still adequate to most verification conditions on stack manipulation code and often automatically conclusions and future work we have presented a formal model of the key ifc mechanisms of the safe system propagating and checking tags to enforce security using a hardware cache for efficiency and a software fault handler for maximum flexibility to formalize and prove properties at such a low level including features such as dynamic memory allocation and labels represented by pointers to data structures we first construct a highlevel abstract specification of the system then refine it in two steps into a realistic concrete machine a bidirectional refinement methodology allows us to prove i that the concrete machine loaded with the right fault handler ie correctly implementing the ifc enforcement of the abstract specification satisfies a traditional notion of noninterference and ii that the concrete machine reflects all the behaviours of the abstract specification our formalization reflects the of the fault handling mechanism in that the fault handler code is compiled from a rule table written in a small we set up a custom hoare logic to specify and verify the corresponding machine code following the structure of a simple compiler for this the development in this paper concerns three deterministic machines and simplifies away concurrency while the lack of concurrency is a significant current limitation that we would like to remove as soon as possible by moving to a model we still want to maintain the abstraction layers of a architecture this requires some care so as not to run of the refinement since some standard notions of noninterference for example noninterference are not preserved by refinement in the presence of nondeterminism one promising path toward this objective is inspired by the recent noninterference proof for sel if we to share a common thread scheduler between the abstract and concrete machines we could still prove a strong double refinement property concrete refines abstract and vice versa and hence preserve a strong notion of noninterference such as the notion from this work or a variation although this paper focuses on ifc and noninterference the tagging facilities of the concrete machine are completely generic in current work we aim to show that the same hardware can be used to efficiently support completely different policies memory safety and controlflow integrity moreover although the rule cache fault handler design in the context of safe we believe that this mechanism can also be to more traditional architectures in the future we plan to reuse and extend the formal development in this paper both to a larger set of highlevel properties and to more conventional architectures for instance we expect the infrastructure for compiling to fault handler software using verified structured code generators to extend to components eg garbage collectors device drivers etc beyond ifc and safe acknowledgments we are to greg morrisett m smith and greg for useful discussions and helpful feedback on early we also thank the anonymous reviewers for their comments this material is based upon work supported by the crash program through the us force research laboratory under contract no the views expressed are those of the authors and do not reflect the policy or position of the department of or the us references a s a sabelfeld and d sands noninterference leaks more than just a bit a and a sabelfeld tight enforcement of policies for dynamic languages t h austin and c flanagan efficient information flow analysis a and d a access control and secure information flow ­ g d and t a certified lightweight noninterference java bytecode verifier esop l hybrid information flow control j and t f jr a trusted computing base for dynamically ensuring secure information flow technical report mit memo no s chen m t b p b t c v o m p and e flexible hardware acceleration for program monitoring a verification of lowlevel programs in computational separation logic pldi a the structured programming system combining generative and hoare logic in an extensible program verifier icfp j a clause w li and a a generic dynamic taint analysis framework m h and c a flexible information flow architecture for software security m r n h and o formal verification of information flow security for a simple separation kernel ccs to appear a b t f jr g b r g morrisett b c pierce r s o shivers j m smith and g preliminary design of the safe platform d y and g e parallel for flexible and efficient runtime monitoring u and a memories on in international symposium on gate arrays u a e c b c pierce j m smith a g g morrisett t f jr a t a d p s and g hardware support for safety and j a goguen and j and inference control ieee sp d and a sabelfeld a perspective on informationflow control school press d and a sabelfeld informationflow security for a core of javascript c m b b c pierce and g morrisett all your are belong to us ieee sp c j hughes b c pierce a d a de and l testing noninterference quickly icfp j on the derivation of secure components ieee sp j b n benton and a kennedy highlevel separation logic for lowlevel code popl m g s p and d dynamic taint analysis with controlflow propagation n o and m machine proof of instruction level isolation properties to appear g k g j d p d k r m t sewell h and s sel formal verification of an os kernel m n and e noninterference for a practical operating system ieee sp a u j m smith t f jr and a pointers compact encoding and efficient implementation of pointers for spatial safety and security ccs x leroy a formally verified compiler journal of automated reasoning ­ x leroy and s formal verification of a memory model and its uses for verifying program transformations ­ w a and d detecting and debugging information flows r a b and e a typed assembly language for noninterference b b c pierce and r a theory of informationflow labels t c d m p t s c lewis x and g sel from general purpose to a proof of information flow enforcement ieee sp t c d m p and g noninterference for operating system kernels m o and m j c gordon hoare logic for modelled machine code tacas z ni and z shao certified assembly programming with embedded code pointers popl a and a sabelfeld dynamic vs static flowsensitive security analysis a sabelfeld and a myers languagebased informationflow security ­ a sabelfeld and a from dynamic to static and back the of informationflow control research in conference j v vafeiadis f z s and p sewell concurrency and verified compilation popl h a and t f jr and architecture d a j c mitchell and d flexible dynamic information flow control in haskell haskell g e j w lee d and s secure program execution via dynamic information flow tracking n m j j r g j a g a m and d i august an framework for informationflow security g i y and m a for dynamic taint propagation s a programming languages for information security phd thesis cornell university 