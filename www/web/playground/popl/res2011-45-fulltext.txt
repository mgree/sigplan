loop transformations pruning and optimization the state university ibm tj watson research center university of inria j state university p the state university inc abstract highlevel loop transformations are a key in mapping computational kernels to effectively exploit resources in modern processor architectures however determining appropriate compositions of loop transformations to achieve this remains a significantly challenging task current compilers may achieve significantly lower performance than programs to address this fundamental challenge we first present a convex characterization of all distinct affine transformations we then bring together algebraic algorithmic and performance analysis results to design a tractable optimization algorithm over this highly expressive space the framework has been implemented and validated on a representative set of benchmarks run on platforms categories and subject descriptors d programming languages processor compilers optimization general terms algorithms performance keywords compilation compiler optimization parallelism loop transformations affine scheduling introduction loop nest optimization continues to much of the research in the fields of optimizing compilation highlevel hardware synthesis and adaptive library generation loop nest optimization attempts to map the proper of independent computation to a complex hierarchy of memory computing and resources despite four of research and development it remains a challenging task for compiler designers and a experience for programmers the performance gap between code for a given machine and that optimized and automatically by a compiler is widening with of hardware permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ austin texas usa copyright c acm one reason for this widening gap is due to the way loop nest attempt to decompose the global optimization problem into simpler recent results in optimization indicate that of this decomposition is largely responsible for the failure the polyhedral compiler framework provides a convenient and powerful abstraction to apply composite transformations in one step however the space of affine transformations is extremely large linear optimization in such a space raises complexity issues and its effectiveness is limited by the lack of accurate models this paper makes fundamental in the understanding of polyhedral loop nest optimization it is organized as follows section formalizes the optimization problem and a complete convex characterization of all distinct affine transformations focusing on one critical slice of the transformation space section proposes a general framework to reason about all distinct statement interleavings section presents a complete and tractable optimization algorithm driven by the iterative evaluation of these interleavings section presents experimental data related work is discussed in section problem statement and formalization the formal semantics of a language allows the definition of program transformations and equivalence criteria to validate these transformations denotational semantics can be used as an abstraction to decide on the functional equivalence of two programs but operational semantics is to express program transformations themselves especially in the case of transformations the detailed interaction with particular hardware program optimization amounts to searching for a particular point in a space of transformations when considering optimizing compilation as a whole the space has no particular property that makes it amenable to any formal characterization or optimization algorithm as a consequence compilers decompose the problem into that can be formally defined and for which complexity results and effective optimization algorithms can be derived the ability to a large set of program transformations into a single well understood optimization problem is the strongest of the polyhedral compilation model in the polyhedral model transformations are validated against dependence relations among dynamic instances of individual statements of a loop nest the dependence relation is the denotational abstraction that defines functional equivalence this dependence relation may not be statically computable but conservative abstractions may be finitely represented through systems of affine inequalities or unions of parametric polyhedra two of work in polyhedral compilation has demonstrated that the main loop nest transformations can be modeled and effectively constructed as affine schedules mapping dynamic instances of individual statements to sorted vectors of integers or rational numbers optimization in the polyhedral model amounts to selecting a good affine schedule for the program in this paper we make the following contributions · we take this well defined optimization problem and provide a complete convex formalization for it this convex set of distinct affine schedules the to more powerful linear optimization algorithms · we propose a decomposition of the general optimization problem over this convex polyhedron into of much lower complexity introducing the powerful concept the relation generalizes the conditions for loop fusion abstracting a large set of affine transformations · we demonstrate that exploring opportunities in a loop nest reduces to the enumeration of total and to the existence of pairwise compatible loop permutations we also study the transitivity of the relation · based on these results we design a affine scheduling algorithm at achieving portable high performance across modern processor architectures · our approach has been fully implemented in a compiler and validated on representative benchmarks loop optimization challenge let us illustrate the challenge of loop optimization from the of performance through a simple example shown in figure we the best combination of loop as a affine optimize a sequence of three for a given target platform for i i n i for j j n j for k k n k r for i i n i for j j n j for k k n k s for i i n i for j j n j for k k n k t figure c ab f de g cf we set n and computed different versions of using combinations of loop transformations including tiling we on two platforms e and using the intel compiler with optimization flags the framework developed in this paper enables us to by a factor × and × respectively for the intel and machines we observe that the best version found depends on the target machine for the intel system the best found loop fusion structure is shown in figure b on which further polyhedral tiling and parallelization were applied not shown in figure but on the machine all statements and tiling them performs best × better than b the efficient of a computation kernel on a modern architecture requires the operation of many hardware resources via the of parallelism the memory hierarchy including units different cache levels memory and and all available computational units including units because of the very complex between all these components it is currently infeasible to guarantee at compiletime which set of leads to maximal performance to performance one must carefully for the tradeoff between the different levels of parallelism and the usage of the local memory components this can be performed via loop fusion and distribution choices that the success of subsequent optimizations such as tiling or parallelization it is essential to adapt the fusion structure to the program and target machine however the provides only models of the impact of loop transformations on the actual execution to achieve performance across a wide variety of architectures empirical evaluation of several fusion choices is an alternative but requires the construction and traversal of a search space of all possible structures to make the problem sound and tractable we develop a complete framework to reason and optimize in the space of all combinations of loop structures background and notation the polyhedral model is a flexible and expressive representation for loop it captures the linear algebraic structure of statically control flow where loop bounds and conditionals are affine functions of the surrounding loop iterators and invariants parameters unknown at compilation time but it is not restricted to static control flow the set of all executed instances of each statement is called an iteration domain these sets are represented by affine inequalities involving the loop iterators and the global variables considering the example in figure the iteration domain of r is d r i j k z i n j n k n d r is a parametric integer polyhedron that is a subset of z the iteration vector xr is the vector of the surrounding loop iterators for r it is i j k and takes value in d r in this work a given loop nest optimization is defined by a affine schedule which is an affine form of the loop iterators and global parameters definition affine schedule given a statement s an affine schedule s of dimension m is an affine form on the d outer loop iterators xs and the p global parameters n s can be written as s xs d p xs n m the scheduling function s maps each point in d s with a timestamp of dimension m such that in the trans formed code the instances of s defined in d s will be executed fol the ordering of their associated timestamp timestamps can be seen as logical clocks the first dimension corresponds to most significant next one is less significant the third to and so on note that every static control program has a affine and that any composition of loop transformation can be represented in the polyhedral representation the full program optimization is a collection of affine schedules one for each program statement even nonlinear transformations like loop tiling blocking and unrolling can be modeled finally syntactic code is generated back from the polyhedral representation on which the optimization has been applied is the art algorithm and code generator to perform this task transformations a program transformation must preserve the semantics of the program the of affine loop nest transformations is defined at the level of dynamic statement instances as a starting point for transformation space pruning we build a convex polyhedral char of all affine schedules for a loop nest two statements instances are in dependence relation if they access the same memory cell and at least one of these accesses is a write given two statements r and s a dependence polyhedron d rs is a subset of the cartesian product of d r and d s d rs contains all pairs of instances xr xs such that xs depends on xr for a given array reference hence for a transformation to preserve the program semantics it must ensure that where denotes the ordering to capture all program dependences we build a set of polyhedra one for each pair of array references accessing the same array cell scalars being a particular case of array thus possibly building several dependence polyhedra per pair of statements the polyhedral dependence graph is a with one node per statement and an edge is labeled with a dependence polyhedron d rs for all dependence polyhedra the schedule constraints imposed by the precedence constraint are expressible as finding all nonnegative functions over the dependence polyhedra it is possible to express the set of affine nonnegative functions over d rs thanks to the affine form of the lemma lemma affine form of lemma let d be a nonempty polyhedron defined by the inequalities a x b then any affine function f x is nonnegative everywhere in d iff it is a positive affine combination f x t ax b with and t and t are called since it is a necessary and sufficient characterization the lemma offers a linearization of the constraints from the dependence polyhedron into direct constraints on the schedule coefficients for instance considering the first time dimension the first row of the scheduling matrices that is we set p in the following equation to preserve the precedence relation we have d rs xr xs d rs dp rs dp rs we to variable d rs to model the dependence satisfaction a dependence d rs can be either weakly satisfied when d rs for some instances in dependence or a an b bm iff there exists an integer i m st a ai b bi and ai bi strongly satisfied when d rs enforcing strict precedence at the first time dimension for all instances in dependence this model extends to schedules observing that once a dependence has been strongly satisfied it does not contribute to the semantics preservation constraints for the subsequent time dimensions furthermore for a schedule to preserve semantics it is sufficient for every dependence to be strongly satisfied at least once following these observations one may state a sufficient condition for semantics preservation adapted from formalization lemma affine schedules given a set of affine schedules r s of dimension m the program semantics is preserved if d rs p m dp rs j p dj rs j p xr xs d rs sj xs rj xr dj rs the proof directly derives from the of dependence satisfaction regarding the schedule m it is sufficient to pick m d to guarantee the existence of a legal schedule the maximum program loop depth is d obviously any schedule implementing the original execution order is a valid solution this formalization involves an oracle to select the dimension p at which each dependence should be strongly satisfied to avoid the combinatorial selection of this dimension we constraint on the schedules when the dependence was strongly satisfied at a previous dimension to the constraint we may always pick a lower bound lb for rk xr without any loss of generality we assume parametric loop bounds are nonnegative proposed a method to evaluate this lower bound when the coefficients of are bounded lb is greater or equal to the sum of the maximal values times the possibly parametric loop bounds we can always select a large enough k such that sk xs rk xr kn k note that this lower bound can also be into constraints on r s thanks to the lemma to obtain the schedule constraints we this lower bound in the previous formulation such that either the dependence has not been previously strongly satisfied and then the lower bound is or it has been and the lower bound is we thus derive the convex form of affine schedules of dimension m for a program as a corollary of lemma lemma convex form of affine schedules given a set of affine schedules r s of dimension m the pro gram semantics is preserved if the three following conditions hold i d rs p dp rs m ii d rs dp rs p iii d rs p m xr xs d rs p kd rs kn k dp rs k one can then build the set l m of all bounded legal affine schedules of dimension m by encoding the affine constraints given by lemma into a problem with m binary vari ables per dependence and m × variables per statement s for an efficient construction of the constraints for one should proceed dependence by dependence building the constraints of the form of is done for each dependence then the are eliminated for instance with a scalable projection technique the set of constraints obtained for each schedules are then and the process is replicated for all dimensions finding a schedule for the program we achieved completeness an integer linear program operating on l m can exhibit the best affine schedule according to a given objective function yet solving an arbitrary on l m is np complete given the high of this space on the larger loop our convex formalization induces a serious challenge to address this challenge and reduce the complexity effect of the problem we propose to the optimization into two the problem of selecting how statements are interleaved this is traditionally viewed as selecting a proper combination of loop fusion loop distribution and code motion the problem of selecting an affine schedule compatible with the statement interleaving selected at the previous step selecting a statement interleaving that a fusion criterion is still an npcomplete problem in general but its complexity is reduced from the linear optimization problem we focus our efforts on this simplified problem encoding statement interleaving fusion and of statements in the polyhedral model loop fusion is characterized by the interleaving of statement instances two statements are fully distributed if the range of the timestamps associated to their instances never overlap syntactically this results in distinct loops to traverse the domains one may define fusion as the negation of the distribution criterion for such a case we say that two statements r s are fused if there exists at least one pair of iterations for which r is scheduled before s and another pair of iterations for which s is scheduled before r this is stated in definition definition fusion of two statements consider two statements r s and their schedules r and s r and s are said to be fused at level p if k p there exists at least three distinct executed instances xr xr and xs such that we now propose an encoding of definition such that we can determine from the dependence graph if it is possible to find a schedule leading to the statements whatever additional transformations may be required to enable fusion this is called the purpose is to exhibit sufficient affine constraints that can be added to l to keep in the solution space only the schedules which correspond to the considered statements we rely on the fact that the first and last scheduled instances of r and s will to definition if the two statements are fused these specific instances belong to the set of vertices of d r and d s thus to determine whether r and s are or not it is sufficient to enumerate all vertices of d r and d s and for each possible combinations of vertices their actual value into eq leading to an affine constraint on the schedule coefficients and test for the existence of a solution in the space of all semantics preserving schedules l augmented with the new constraint as soon as there is a solution to one of the problems formed then the statements are this is stated in definition definition generalized check given vr resp vs the set of vertices of d r resp d s r and s are at level p if k p there exist two schedules rk and ks such that x x x vr × vs × vr rk x note that in practice the number of vertices of an iteration domain is often small from to hence the number of cases to be checked is limited we also present in section a specialization of this test to the case of nonnegative schedule coefficients which removes the need to enumerate the vertices statement interleaving thanks to lemma and definition we can determine if a set of statements can be fused at a given level while preserving semantics for our optimization problem we are interested in building a space representing all ways to the program statements to reason about statement interleaving one may associate a vector s of dimension d d being the maximal loop depth in the program to each statement s and order those vectors if some statement s is by less than d loops s is with figure gives an example of three possible optimizations for the example as defined by different configurations of the vectors note that to implement the interleaving specified by several loop permutations may be required there exist an analogy between s and a standard encoding of affine schedules where statement interleaving vectors are made explicit for each statement s one may constrain the rows of s to alternate between constant forms of a vector of dimension d usually denoted and affine forms of the iteration and global parameter vectors this d dimensional encoding does not any loss of expressiveness however in this paper we explicitly give important structural properties of the transformed loop nest if rk sk k p then the statements share at least p common loops if rp sp then the statements do not share any common loop starting at depth p we thus have rp sp kr ks k p m our objective to model all possible interleavings is to build a space containing all vectors for which there exists a affine transformation that implements the specified interleaving to guarantee that the solution space contains only useful points we need to address the problem that several choices of vectors represent the same statement interleaving intuitively the problem arises because there exists an infinite number of vectors which have the same ordering in particular the order is invariant to translation of all coefficients of at a given dimension or by multiplication of all its coefficients by a nonnegative constant to abstract away these equivalences we now formally define the concept of statement interleaving definition statement interleaving consider a set of statements s within at most d loops and their associated vectors r for a given k d the statement interleaving of s at dimension k defined by r is the partition of s according to the coefficients sk the statement interleaving of s at dimension k defined by r is the list of partitions at dimension k for t t n t for t t n t for t t n t r for t t n t for t t n t s for t t n t for t t n t t for t t n t for t t n t for t t n t s r for t t n t for t t n t for t t n t t for t t n t for t t n t for t t n t r for t t n t for t t n t for t t n t s t lr ls lt r s t lr ls lt r s t lr ls lt r s t a b figure three possible legal transformations for c ab f de g cf c the structural properties of statement interleaving indicate that equivalence classes at dimension k correspond to statements that share common loops at depth k in the transformed loop nest definition total preorder a total preorder on a set s is a relation which is reflexive transitive and such that for any pair of elements s s s either s s or s s or both an important result is that any preorder of a set s is isomorphic to a partial order of some equivalence classes of s applying this result to the structural properties of statement interleavings yields the following lemma lemma structure of statement interleavings each statement interleaving corresponds to a unique total preorder of the statements and statement interleavings we now propose a convex complete characterization of statement interleavings which serves as a basis to encode the space of valid vectors convex encoding of total we first present a solution for the problem of total of scalar elements that corresponds to interleavings case for a given set of n elements we define o as the set of all and distinct total of its n elements the key problem is to model o as a convex polyhedron to the best of our knowledge uniqueness of orderings cannot be modeled in a convex fashion on a set with a linear number of variables we propose to model the ordering of two elements i j with three binary decision variables defined as follows pi j iff i precedes j ei j iff i equals j and si j iff i succeeds j to model the entire set we introduce three binary variables for each ordered pair of elements ie all pairs i j such that i j n this models a set with × nn variables pi j ei j si j this problem is not a straight adaptation of standard order theory we look for the set of all distinct total of n elements in contrast to classical work defining counting functions of this set for instance the outermost interleaving r s t of figure b is represented by from there one may easily the corresponding total preorder r s t eg by computing the minimum of a system w of nonnegative variables that the ordering defined by all pi j ei j and si j the first issue is the consistency of the model an preorder would make w infeasible eg setting e and p the second issue is the totality of the relation these two conditions can be merged into the the following equality capturing both mutual exclusion and totality pi j ei j si j to simplify the system we immediately get of the si j variables thanks to we also relax to get pi j ei j mutually exclusive decision variables capture the consistency of the model for a single pair of elements however one needs to insert additional constraints to capture transitivity to enforce transitivity the following rule must hold true for all triples of statements i j k ei j e jk similarly we have ei j e jk these two rules set the basic transitivity of e variables since we are dealing with binary variables the implications can be easily modeled as affine constraints k j n ei j e jk ei j e jk slightly more complex transitivity patterns are also required for instance we also have transitivity conditions imposed by a connection between the value for some e coefficients and some p ones for instance i j and j k implies i k the general rules for those cases are ei j p jk ei j p jk ek j pi j these three rules set the complex transitivity between the p and e variables they can be modeled equivalently by following affine constraints k j n k i j ei j p jk ei j p jk ek j pi j generalizing this reasoning we collect all constraints to enforce the transitivity of the total preorder relation those constraints are in the following system for i j n defining the convex set of all distinct total of n elements o pi j variables are ei j binary pi j ei j relaxed mutual exclusion k j n ei j e jk basic transitivity ei j e jk on e k i j pk j pi j basic transitivity on p k j n ei j p jk complex ei j p jk transitivity k i j ek j pi j on p and e complex k j n ei j pi j p jk transitivity on s and p the following lemma is proved in appendix a lemma completeness and correctness of o the set o con one and only one element per distinct total preorder of n elements case o encodes all possible total or statement interleaving for a given loop level to extend to the interleaving case we first o for each di of the vectors however further constraints are needed to also achieve consistency and uniqueness of the characterization across dimensions intuitively if a statement is distributed at dimension k then for all remaining dimensions it will also be distributed this is modeled with the following equations l k j j j j the final expression of the set i of all distinct statement interleavings is k d constraints on o k total at level k j statement interleaving j j uniqueness it is worth noting that each o k contains numerous variables and constraints but when it is possible to determine thanks to the dependence graph for instance that a given ordering of two elements i and j is impossible some variables and constraints are eliminated our experiments indicate that these simplifications are quite effective improving the scalability of the approach significantly pruning for semantics preservation the set i contains all and only distinct statement inter a pruning step is needed to remove all interleavings that does not preserve the semantics the algorithm proceeds from the outermost to the innermost such a is possible because we have encoded interleaving constraints in i and that fusion at level k implies fusion at all pre levels in addition lemma and definition we can determine the of a set of statements at a given level by sufficient conditions for fusion on the schedules the general principle is to detect all the smallest possible sets of p statements at level k and for each of them to update i k by adding an affine constraint of the form p thus preventing them and any superset of them to be fused all to we note f the final set with all pruning constraints for f i a naive approach could be to enumerate all unordered subsets of the n statements of the program at level k and check for while avoiding to enumerate a superset of an set instead we the polyhedral dependence graph to reduce the test to a much smaller set of structures the first step of our algorithm is to build a graph g to facilitate the enumeration of sets of statements to test for with one node per statement sets of statements to test for will be represented as nodes connected by a path in that graph intuitively if g is a complete graph then we can enumerate all unordered subsets of the n statements all paths of length gives all pairs of statements by the nodes connected by a given path all paths of length gives all etc we aim at building a graph with less edges so that we lower the number of sets of statements to test for we first check the of all possible pairs of statements and add an edge between two nodes only if there is a dependence between them and either they must be fused together or they can be fused and distributed at that level when two statements must be fused they are merged to ensure all schedule constraints are considered when checking for the second step is to enumerate all paths of length in the graph given a path p the nodes in p represent a set of statements that has to be tested for each time they are detected to be not all paths with p as a are discarded from enumeration and f k is updated with an equation in the form of the complete algorithm is shown in figure procedure computes the space of legal schedules l according to lemma for the set of statements given in argument procedure tests for the emptiness of l when augmented with fusion conditions from definition up to level d if there is no solution in the augmented set of constraints then the statements cannot be fused at that level and hence must be distributed procedure checks if it is legal to the statements r and s the check is performed by inserting a splitter at level d this splitter is a constant schedule at level d to force the full distribution of statement instances at that level if there is no solution in this set of constraints then the statements cannot be distributed at that level and hence must be fused procedure tests if it is legal to r and s at level d and to execute s before r the latter is required to compute the legal values of the variables at that level the check is performed in a similar fashion as with except the splitter is made to make r execute after s finally procedure modifies the graph edges after the merging of two nodes r and s such that if for t there was an edge et r and not et s or et r is deleted and this is to remove of trivially sets compute f input pdg polyhedral dependence graph n number of statements maximum loop depth output f the space of distinct interleavings f i un f usable for d to do g forall pairs of dependent statements r s do l rs s pdg if rs d then f d f d rs d then f d f d else if ¬ rs d then f d f d end if r s end if end for forall pairs of statements r s such that do r s end for for l to n do forall paths p in g of length l such that there is no prefix of p in un f usable do l pdg if d then f d f d p in p l un f usable un f usable p end if end for end for end for figure pruning algorithm if there are edges between t and rs one of them is deleted and its label is added to the remaining one existing label the label of the edge is added to all remaining edges rs and is deleted applications the first motivation of building a separate search space of statement interleavings is to the selection of the interleaving from the selection of the transformation that enables this interleaving one can then focus on building search heuristics for the of statements only and through the framework presented in this paper compute a schedule that respects this interleaving additional schedule properties such as parallelism and can then be exploited without the outer level fusion scheme we present in the following a complete technique to optimize programs based on iterative interleaving selection leading to and transformed programs this technique is able to automatically adapt to the target framework and successfully the best performing fusion structure whatever the of the program compiler and architecture another motivation of building i is to enable the design of ob functions on fusion with the degree of applicability for instance one can fusion at outer level by i j ei j or similarly distribution by the same sum one can also assign a weight to the coefficients ei j to fusion for statements carrying more reuse for instance this formulation allows to further pruning algorithms to the optimization the most relevant choice of legal interleavings for a given target optimizing for locality and parallelism the previous sections define a general framework for statement interleaving we address now the problem of this framework to provide a complete optimization algorithm that tiling and parallelization along with the possibility to iteratively select different interleavings the optimization algorithm proceeds recursively from the outermost level to the innermost at each level of the recursion we select the associated schedule dimension by instantiating its values then we build the set of interleavings at that level pick one and proceed to the next level until a full schedule is instantiated we present in section additional conditions on the schedules to improve the performance of the generated transformation by integrating parallelism and as criteria then we define in section a new criterion for a better performance impact while restricting it to nonnegative schedule coefficients in section we show how to construct the set of legal interleaving without on testing the set of legal schedules for sets larger than a pair of statements finally we present the complete optimization algorithm in section additional constraints on the schedules tiling or blocking is a crucial loop transformation for parallelism and locality et al developed a technique to compute an affine schedule such that parallel loops are to the outer levels and loops with dependences are pushed inside at the same time the number of dimensions that can be are we extend and their technique into our framework of tiling tiling along a set of dimensions is legal if it is legal to proceed in fixed block sizes along those dimensions this requires dependences not to be backward along those dimensions thus avoiding a dependence path going out of and coming back into a tile this makes it legal to execute the tile atomically and showed that a sufficient condition for a schedule to be given r the dependence cone for the program is that r in other words this is equivalent to saying that all dependences must be weakly satisfied for each dimension k of the schedule such a property for the schedule is also known as forward communication only property returning to lemma it is possible to add an extra condition such that the p first dimensions of the schedules are a sufficient condition for the p first dimensions to be this translates into the following additional constraint on schedules to enforce of schedule dimensions definition condition given two statements r s given the conditions for as stated by lemma their schedule dimensions are up to dimension k if in addition d rs p k xr xs d rs dp rs to translate k into actual number of loops the k associated schedule dimensions must express schedules tiling selecting schedules such that each dimension is independent with respect to all others enables a more efficient tiling or close to blocks are achieved when possible avoiding complex loop bounds which may arise in the case of arbitrarily tiles we to the constraints with independence constraints hence to compute schedule dimension k we need instantiate first a schedule for all previous dimensions to k this comes from the fact that constraints are not linear or convex and cannot be modeled as affine constraints directly in its complete form adding constraints leads to a space and all cases have to be tried and the best among those kept when the number of statements is large this leads to a combinatorial explosion in such cases we restrict ourselves to the of the orthogonal space where all the constraints are nonnegative that is we restrict to have i j n by just considering a particular convex portion of the orthogonal we discard solutions that usually involve loop or combination of with other transformations however we believe this does not make a strong difference in practice for the rest of this paper we now assume i j n inner loops if it is not possible to express loops for the first level proposed to split the state ments into distinct blocks to increase the possibility to find outer loops since our technique already supports the selection of any possibility to split statements into blocks via the statement interleaving we propose instead to enable the construction of inner loops by choosing to the number of dependences solved at the first levels until we possibly find dimensions at the current level doing so increases the freedom for the schedule at inner di when it is not possible to express loops at the outer levels the number of dependences solved at a given level was introduced by and we use a similar form si max dk rs d rs this cost function replaces the condition when it is not possible to find a schedule for a given dimension k dependence distance minimization there are infinitely many schedules that may satisfy the criterion from definition as well as an approach that has proved to be simple practical and powerful has been to find those schedules that have the shortest dependence components along them for polyhedral code the distance between dependent iterations can always be bounded by an affine function of the global parameters represented as a vector n un w s xs r xr xr xs d rs u n in order to data locality one may include read dependences in the set of dependences d rs considered in the bounding function we showed in that there always exists a parametric form kn k for the lower bound of the schedule u and w can always be selected large enough for un w to be an on the schedule so considering dependences in the bounding function does not prevent from finding a legal schedule the and bounding function constraints are through the affine form of the lemma such that the only left are the coefficients of and those of the bounding function namely u w of the bounding function are then used as the minimization objective to obtain the unknown coefficients of minimize u w i the resulting transformation is a complex composition of loop fusion distribution and eventually tiling is applied on all and resulting tiles can be executed in parallel or at worse with a schedule tile sizes are computed such that data accessed by each tile roughly in the l cache check we presented in section a generalized check for which guarantees at least one instance of the iteration domains are fused but for fusion to have a stronger performance impact a better criterion is to guarantee that at most x instances are not interleaved in general computing the exact set of interleaved instances requires complex techniques a typical example is schedules generating a in the supporting lattice of the transformed iteration domain for such cases computing the exact number of instances could be achieved using the of the intersection of the image of iteration domains by the schedules however this refined precision is not required to determine if a schedule represents a potentially interesting fusion we allow for a lack of precision to present an easily computable test for based on an estimate of the number of instances that are not interleaved for the sake of simplicity we assume that loop bounds have been normalized such that is the first iteration of the domain when considering nonnegative coefficients the lowest timestamp assigned by a schedule rk is simply rk one can the corresponding timestamp by looking at the values of the coefficients attached to the parameters and the constant hence the timestamp interval c between the two first scheduled instances by rk and ks is simply the difference of the parametric constant parts of the schedules in addition to avoid the case where kr andor ks are parametric constant schedules we force the linear part of the schedule to be nonnull this is formalized in definition definition restricted to nonnegative coefficients given two statements r s such that r is by dr loops and s by ds loops they are at level p if k p there exist two schedules kr and ks such that i c kr ks c dr ds ii i i the constant c is an on the timestamp difference between the first scheduled instance of r and the first scheduled instance of s by the allowed size for this interval one can range from full aligned fusion c to full distribution with c greater than the schedule of r or s note that definition is independent from any composition of affine transformations that may be needed to enable the fusion of the statements the schedules that implement the fusion hence modeling also the sequence of transformations are simply solutions in the space of nonnegative schedules augmented with the constraints computation of the set of interleavings we have now restricted i j n a consequence is the design of a specialized version of our generic algorithm to compute the set of interleavings this specialized version new results on the transitivity of for the case of nonnegative schedule coefficients as shown below furthermore it does not require computing with l which significantly improves the overall complexity of the procedure is the capability to exhibit a schedule such that some of the instances are fused according to definition first let us remark that is not a transitive relation as an illustration consider the sequence of products x ab y bx z cy while it is possible to them by it is not possible to them all together when considering loops for x ab y bx one has to loops in y bx when considering loops for y bx z cy one has to keep loops in y bx as is we now present a sufficient condition to determine the transitivity of based on the existence of compatible pairwise permutations first we introduce a decomposition of schedules in two with the objective of loop permutation from the other transformations embedded in the schedule one can decompose a schedule rk with coefficients in n into two and r such that rk r n ir n without any loss of expressiveness such a decomposition is always possible because of the distributivity of the matrix multiplication over the matrix addition for our purpose we are interested in modeling schedules which are not constant schedules this is relevant as we do not want to consider building a schedule for fusion that would translate only into statement interleaving on the contrary we aim at building a schedule that performs the interleaving of statements instances hence the linear part of the schedule must be nonnull for r by d loops we enforce µ to be a linear form of the d loop iterators i id n t to model schedules we add the additional constraint di note that by µ to have only one set to this does not prevent to model any compositions of or these would be embedded in the part of the schedule as shown in the example below the µ part of the schedule models different cases of loop permutations for instance for statement r by loops in the example can take only three values i j k n t i i j k n t j i j k n t k while r can take arbitrary values for better illustration let us now build the decomposition of the schedule kr j k rk is the composition of a permutation a and a and can be decomposed as follows r j k one may note that another possible decomposition is k j in general when the schedule contains it is possible to embed either of the dimensions in the µ part of the schedule for the sake of we add an extra convention for the decomposition µ matches the first nonnull iterator of the schedule returning to the example j j k is thus the only valid decomposition of kr note that this decomposition prevents modeling of compositions of loop permutations in the part for to represent a loop permutation must have values in z as shown in the following example i j k n t i xr j which is not possible as we have constrained i n hence when considering arbitrary compositions of permutation parametric and the µ decomposition permutation embedded in the µ part of the schedule from the other transformations embedded in the part of the schedule we now show it is possible to determine if a set of statements are only by looking at the possible values for the µ part of their schedules considering three statements r s t that are while preserving the semantics at level k then there exist rk r ks s tk t leading to those statements considering now the of only r and s we build the set m rs of all possible values of for which there exist a r s leading to r and s obviously the value of leading to r s t are in m rs and are also in m st similarly are in m rt we derive a sufficient condition for based on pairwise loop permutations for fusion lemma pairwise sufficient condition for given three statements r s t such that they can be by fused and dis given m rs resp m rt resp m st the set of possible tuples resp resp leading to r and s resp r and t resp s and t such that the full program semantics is r s t are if there exists such that m rs m rt m st proof and t t such that they all preserve the full program semantics the as in r r ks s r is additional compositions of and which cannot make the dependence vec negative it cannot consist in performing a parametric shift r and s resulting in and kr is a a loop distribution rk schedule r and is t a schedule as kr is a schedule it leads to r and s generalizing this reasoning we can exhibit the following schedule leading to the fusion of r s t kr r r s s t t ks r r s s t t kt r r s s t t as all statements are fused by they are fused all together as the three statements can be distributed by there is no dependence cycle to the importance of lemma let us return to the example we can compute the pairwise permutations for fusion sets at the outermost level m rs i i i j i k j i j j j k k i k j k k m rt i i j k m st i k j j these sets are computed by iteratively testing against the set of constraints for augmented with fusion and constraints for the existence of solutions with a nonnull value for each of the coefficients associated with the statement iterators for only the two considered statements this is in contrast to the general algorithm which requires to consider the whole set of candidate statements for fusion here we can decide that r s t are as the solution j i k respects the conditions from lemma this solution is presented in figure a to improve further the we rely on two more standard properties on fusion given two statements r and s if r and s are not then any statement on which r depends on is not with s and any statement depending on s if r and s must be fused then any statement depending on r and on which s depends must also be fused with r and s these properties cut the number of tested sequences in particular in highly constrained programs such as kernels they are used at each step of the optimization algorithm optimization algorithm we now present our optimization algorithm the algorithm possible interleavings of dimension and generates a collection of program schedules each of them being a candidate for the optimization we use iterative compilation to select the best performing one for each candidate program schedule we generate back a syntactic c code compile it and run it on the target machine the structure and principle of the optimization algorithm shown in figure matches that of the pruning algorithm of figure as it also aims at computing a set of feasible interleavings at a given level it is in essence a specialization of the pruning algorithm for our optimization problem instance to decide the of a set of statements we put the problem in a form matching the applicability conditions of lemma we merge nodes that must be by fused to guarantee that we are checking for the set of valid µ values when considering procedure computes for a given pair of statements r s the set of nonnegative schedules augmented with and constraints as defined in the previous section given the previously computed rows of procedures operate in a similar fashion as in the general case procedure com m rs the set of all valid permutations leading to fusion to check if a given permutation is valid and leading for fusion at level d the set of constraints is tested for the existence of a solution where the schedule coefficients of row d corresponding to and is not this is sufficient to determine the existence of the associated part procedure collects the sets m of the pairs of statements connected by the path p and tests for the existence of µ values according to lemma if there is no compatible permutation then an additional constraint is added to f d such that it is not possible to the statements in p all together the constraint sets that the ei j variables for all pairs i j in the path p cannot be set to all together procedure instantiate a schedule row d that implements the interleaving i using only the scalar coefficients of the schedule procedure a schedule row d at the current interleaving dimension d for all statements the interleaving is given by i and for each group of statements to be fused under a common loop a schedule is computed to fusion and to enforce if possible to select the values we to the objective function finally procedure computes the possibly remaining schedule dimensions when is lower than the maximum program loop depth note that in this case maximal fu compute all optimizations input partial program optimization pdg polyhedral dependence graph d current level for the interleaving exploration n number of statements maximum level to explore for interleaving output complete program optimization g fd o un f usable forall pairs of dependent statements r s in pdg do s d pdg if d then f d f d else if d then f d f d end if f d f d m rs d r s m rs end if end for forall pairs of statements r s such that do r s end for for l to n do forall paths p in g of length l such that there is no prefix of p in un f usable do if ¬ then f d f d p in p l un f usable un f usable p end if end do end for forall i f d do d d i d pdg d i if d then pdg d n else pdg p output end if end for figure optimization algorithm sion is used to select the interleaving hence we do not need to build a set of interleavings for the remaining in practice this algorithm proved to be very fast and for instance computing the set f of all interleavings at the first dimension takes less than second for the benchmark pruning i from about structures to on an initial space with binary variables to model all total sub traversing f and computing a valid transformation for all interleavings takes an additional second experimental results studies performed on the performance impact of selecting schedules at various levels the higher impact of carefully selecting outer loops the selection of the statement interleaving at the outermost level captures the most significant difference in terms of locality and communication we can limit the recursive traversal of interleavings to the outer level only while obtaining significant performance improvement and a wide range of transformed codes nevertheless when the number of candidates in f is very small typically because of several dependences at the outer level it is relevant to build f and further benchmark loops o points f points time s s s s s s s s pb size xx x x x x xx x x × × × × × × × × × × × × × × × × table search space statistics and performance improvement note that in the experiments presented in this paper we traverse only f search space statistics several ei j and pi j variables are set ing the pruning of o so several consistency constraints are made useless and are not built significantly to reduce the size of the space to build table illustrates this by for our benchmarks considered the properties of the o in terms of the number of dimensions constraints and points points when compared to f the of possible interleavings for the first dimension only for each benchmark we list loops the number of loops the number of statements the number of array references as well as the time to build all candidate interleavings from the input source code that is including all analysis on an intel we also report the size we used for the benchmarks pb size performance evaluation the automatic optimization and parallelization approach has been implemented in the polyhedral compiler collection a complete polyhedral compiler based on available free software for polyhedral compilation the time to compute the space select a candidate and compute a full transformation is with respect to the compilation and execution time of the tested versions in our experiments the full process takes a few seconds for the smaller benchmarks and up to about for on an intel processor extensive performance characterization is beyond the scope of this paper the reader is referred to other for a more analysis of the performance issues that are successfully addressed by our iterative framework on various architectures nevertheless to illustrate the benefit of our approach we report in table the performance improvement obtained by our iterative process we used intel with fast parallel as the on the original code and also to compile all our optimized programs we report the performance improvement achieved over with automatic parallelization enabled on the original code under the column for a intel e running at with gb of memory hardware threads and for a running at hardware threads with gb of memory beyond absolute performance improvement another motivating factor for iterative selection of fusion structures is performance because of significant differences in design in particular in units performance and cache behavior a transformation has to be for a specific machine this leads to a significant variation in performance across tested frameworks to illustrate this we show in figure the relative performance normalized with respect to for for the and the version index is on the x axis represents maximal fusion is available at while corresponds to maximal distribution for the the best found version performs better than the best fusion configuration for the optimizing for the the best version performs better than the best fusion structure for the figure performance for the tradeoff between fusion and distribution is a relevant approach to a complete highlevel optimization framework the main motivation is the difficulty to design a portable heuristic to select the best interleaving as the best fusion structure is and even depends on the compiler used also as shown in figure the interleaving selection can impact the transformations required to implement the interleaving eg loop and subsequently the optimization process our technique is able to automatically adapt to the target framework and thanks to empirical search successfully the best fusion structure whatever the of the program compiler and architecture related work traditional approaches to loop fusion are limited in their ability to handle compositions of loop transformations this is mainly due to the lack of a powerful representation for dependences and transformations hence approaches typically study fusion in isolation from other transformations and sarkar presented a solution to the problem of loop fusion in parallel programs that performs fusion while preserving the parallelism in the input program we believe that several interesting solutions are not obtained when fusion is from parallelization in those frameworks where legal fusion choices are left out of the framework et al studied the combination of loop and fusion for parallelization in contrast to all of these works the search space explored in this paper includes fusion in the presence of all polyhedral transformations heuristics for loop fusion and tiling have been proposed in those heuristics have also been in the context of new architectures with mem hierarchies and heterogeneous computing resources the polyhedral model is complementary to these efforts opening many more opportunities for optimization in loop nest and compilers note that the polyhedral model is currently being integrated into production compilers including gcc ibm xl and a heuristic that loop fusion and tiling in the polyhedral model that subsumes a number of transformations such as and loop was presented in et al their work builds complex sequences of transformations that enable tiling of nested loops that generalizes the prior work on tiling loops and is helpful in identifying tradeoffs et al refined their static cost model for fusion by of hardware stream buffers loss of parallelism and constraints imposed by and code expansion however these techniques do not model a closed space of all and only distinct fusion structures instead they operate on the entire space of valid fusion structures and select a specific one that a static cost function across a broad range of machine architectures and compiler transformations iterative compilation has proven to be effective in deriving significant performance benefits nevertheless none of iterative compilation approaches achieved the expressiveness and the ability to apply complex sequences of transformations presented in this paper while focusing the search only on transformation candidates several powerful frameworks based on the polyhedral model have been proposed these frameworks are able to capture fusion structures but do not construct parallelization and tiling strategies using a heuristic is a compiler developed by inc is based on the polyhedral model and targets modern heterogeneous architectures including with caches systems with and distributed memory architectures that require explicit memory management and data movement the affine scheduler in builds on contributions from and sarkar and et al it introduced the concept of affine fusion to enable a single formulation for the joint optimization of cost functions representing tradeoffs between amount of parallelism and amount of locality at various in the loop nest hierarchy scheduling algorithms in search an optimization space that is either constructed on a basis as solutions are found or based on the convex space of all legal schedules as had been illustrated by allows direct optimization of the tradeoff function using integer linear programming solvers as well as iterative exploration of the search space redundant solutions in the search space are implicitly out by the combined tradeoff function as they exhibit the same overall cost in practice a solution to the optimization problem represents a whole class of equivalent scheduling functions with the same cost conclusions the selection of a composition of loop transformations is a hard combinatorial problem we proposed a complete characterization of affine transformations as a convex space we then this polyhedron focusing on statement interleavings corresponding to a generalized combination of loop fusion loop distribution and framework code motion we proposed a practical optimization algorithm to explore the polyhedron while building a affine enabling transformation this algorithm was applied to relevant benchmarks good scalability and strong performance improvements over architectures and compilers acknowledgments we are to paul for providing the foundations for affine scheduling and the simplification of original convex formulation of all schedules that we presented in this paper this work was supported in part by the us advanced research projects through contract the us national science foundation through and by the us through contract and by the european through the fp project id references f e j b g m f p j m and c k i using machine learning to focus iterative optimization in proc of the intl symposium on code generation and optimization pages ­ d and p array dataflow analysis journal of parallel and distributed computing ­ c code generation in the polyhedral model is easier than you think in ieee intl conf on parallel architectures and compilation techniques pages ­ france sept ln a and c the polyhedral model is more widely applicable than you think in intl conf on compiler construction cc lncs pages ­ mar f t p m w m f p and e iterative compilation in a nonlinear optimisation space in w on profile and feedback directed compilation paris oct u m s j a and p automatic transformations for parallelization and locality optimization in the polyhedral model in international conference on compiler construction cc u o s and l a model for fusion and code motion in an automatic compiler in proc of the th intl conf on parallel architectures and compilation techniques pages ­ u a j and p a practical automatic polyhedral program optimization system in acm sigplan conference on programming language design and implementation june c chen j and m hall a framework for composing highlevel loop transformations technical report u of california p counting solutions to linear and nonlinear constraints through polynomials applications to analyze and transform scientific programs in proc of the intl conf on pages ­ acm a s d m o and n the search for compositions of program transformations in acm international conference on pages ­ june a on the complexity of loop fusion parallel computing pages ­ a and g loop for loop parallelization technical report rr may a ga and f combining and scheduling techniques for loop parallelization and loop tiling parallel proc letters ­ p parametric integer programming ­ p dataflow analysis of scalar and array references intl j of parallel programming ­ p some efficient solutions to the affine scheduling problem part i one dimensional time intl j of parallel programming ­ oct p some efficient solutions to the affine scheduling problem part ii time intl j of parallel programming ­ dec f y and m formal loop merging for signal transforms in acm sigplan conf on programming language design and implementation pages ­ s n c a d m and o composition of loop transformations intl j of parallel programming ­ june m automatic parallelization of loop programs for distributed memory architectures thesis ac f p s and t hardware design methodology with the alpha language in france sept f and r partitioning in acm sigplan principles of programming languages pages ­ w optimization within a unified transformation framework phd thesis univ of k kennedy and k loop parallelism and improving data locality via loop fusion and distribution in languages and compilers for parallel computing pages ­ i n ahmed and k blocking in acm sigplan conf on programming language design and implementation pages ­ june m and s the execution of stream programs on platforms in acm sigplan conf on programming language design and implementation pldi pages ­ acm press r a b n d m a and k compiler in d editor of parallel computing springer st edition p in not available separately edition june k s s and cw improving data locality with loop transformations acm trans program lang syst ­ n and v sarkar optimal weighted loop fusion for parallel programs in symposium on parallel algorithms and architectures pages ­ a a compiler framework for algorithm ga in proc of the intl conf and on computing and pages ­ london uk springerverlag ln optimization in the polyhedral model phd thesis university of france jan ln c a and j iterative optimization in the polyhedral model part ii time in acm sigplan conf on programming language design and implementation pldi pages ­ acm press ln u c a j and p combined iterative and optimization in an automatic parallelization framework in conf on sc new la to appear a and k kennedy loop fusion and tiling using empirical search in proc of the th intl conf on pages ­ acm press j and p tiling iteration spaces for journal of parallel and distributed computing ­ m j y park m a aiken and w j a framework for memory hierarchies in intl conf on parallel architectures and compilation techniques pages ­ acm press l d s and m m parameterized loops for free sigplan notices proc of the pldi conf ­ a theory of linear and integer programming john sons s and k a parameterized loop fusion algorithm for improving parallelism and cache locality the computer journal ­ n j a sequence a the online of integer sequences m s m martin and meta optimization improving compiler heuristics with machine learning sigplan not ­ a c chen j m hall and j k a scalable framework for computer optimization in may n scalable program optimization techniques in the polyhedra model phd thesis university of s f m and g feasibility of incremental translation technical report cw department of computer science oct y f de and m computer generation of general size linear transform libraries in intl symp on code generation and optimization mar r c a and j j automated empirical optimization of software and the project parallel computing m d and dk chen combining loop transformations considering caches and scheduling in proceedings of the th annual international symposium on pages ­ m more iteration space tiling in proceedings of pages ­ m high performance compilers for parallel computing addisonwesley 