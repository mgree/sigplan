minimization of symbolic automata university of pennsylvania microsoft research abstract symbolic automata extend classical automata by using symbolic alphabets instead of finite ones most of the classical automata algorithms rely on the alphabet being finite and generalizing them to the symbolic setting is not a trivial task in this paper we study the problem of symbolic automata we formally define and prove the basic properties of in the symbolic setting and lift classical minimization algorithms and algorithms to symbolic automata while algorithm is the known algorithm for dfa minimization we show how in the presence of symbolic alphabets it can an exponential to address this issue we introduce a new algorithm that fully benefits from the symbolic representation of the alphabet and does not from the exponential we provide performance evaluation of all the algorithms over large benchmarks and against existing implementations the experiments show how the new symbolic algorithm is faster than previous implementations categories and subject descriptors f theory of computation automata over infinite objects regular languages keywords minimization symbolic automata introduction classical automata theory builds on two basic assumptions there is a finite state space and there is a finite alphabet the topic of this paper is along the line of work challenging the second assumption symbolic finite automata sfas are finite state automata in which the alphabet is given by a boolean algebra that may have an infinite domain and transitions are labeled with predicates over such algebra symbolic automata from the to support regular expressions in the context of static and dynamic program analysis they were also used for supporting regular expressions modulo label theories in the context of modern logical inference most classical automata algorithms view the size k of the alphabet as a constant and use specialized data structures that are optimized for this view therefore it is not clear if or how such algorithms would work when the alphabet is infinite understanding how operations over the finite alphabet lift to the symbolic setting permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than acm must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ san diego ca usa copyright c acm is a challenging task some classical automata constructions are extended to sfas in for example the product intersection of two symbolic automata m and m is computed by building product transitions of the form p p q q from transitions p q p q in m m where the guards and are composed using conjunction and when unsatisfiable the complexity of such constructions clearly depends on the complexity of checking satisfiability in the label theory in this particular case constructing the product has complexity of m where m is the number of transitions f l is the cost of checking satisfiability of predicates of size l in the label theory and is the size of the predicate in m and m this paper focuses on the problem of automata over symbolic alphabets and to the best of our knowledge it is the first paper that this problem deterministic finite automata is one of the fundamental concepts in automata theory it occurs in numerous areas such as programming languages text processing computational etc before looking for an algorithm for sfas we first need to answer a fundamental question what does it mean for an sfa to be minimal intuitively any two distinct states p and q of a minimal sfa must be where two states p and q are if there exists an input sequence s that starting from p leads to a final state and starting from q leads to a final state this notion is similar to dfa the original algorithms for were given by moore and hopcroft since all such algorithms use iterations over the finite alphabet they do not immediately extend to the symbolic setting in the following we briefly describe how we extended the classical algorithms to sfas and how we designed a new minimization algorithm that fully takes advantage of the symbolic representation of the alphabet our first algorithm is called and takes from a of algorithm described in the key idea from the algorithm in is the following if two states p and q are and there exists a character a and transitions a p p and a q q then p and q are this idea translates to the symbolic setting as if two states p and q are and there exist transitions p p and q q such that is satisfiable then p and q are starting with the fact that final and states are we can use a fixpoint computation for states into groups of states this procedure uses a number of iterations that is quadratic in the number of states moreover each iteration is linear in the number of transitions unfortunately does not scale in the case of a performance critical application described in section where sfas satisfiability checking predicate negation generation table summary of operations needed over a given label theory in the respective minimization algorithms end up having of states and the complexity of was not acceptable to this end we studied a generalization of algorithm called algorithm is based on a technique called partition refinement of states and with worst case complexity log n n number of states and k num of alphabet symbols it is the most efficient algorithm for min the main idea behind is to all the labels in the sfa into predicates called minterms such minterms can then be seen as atomic characters in the sense of classical allowing us to use the classical al over the finite set of minterms even though performs well in the application it from an other problem in the worst case the number of minterms can be exponential in the number of edges of the sfa moreover our ex showed that this factor can indeed be observed when considering more complex label theories such as the theory of pairs over string × int § this leads to our main algorithmic contribution in the paper we designed a new algorithm for sfa minimization which takes full advantage of the symbolic representation of the input alphabet is inspired by the idea of refining the partition of the state space used by algorithm but does not require the of minterms as in the key observation is that the set of relevant predicates can be computed locally rather than using all the transitions of the sfa to in terms of state complexity it while is similar does not from the exponential complexity related to the computation in fact in all our experiments by both and are table presents a summary of the minimization algorithms their dependency on operations over the label theory we compared the performance of the three algorithms using the benchmark of randomly generated presented in the sfas generated by common regular expressions taken from the web a set of sfas at showing the exponential explosion a randomly generated set of sfas over a complex al theory and the sfas generated during the transformation from monadic second order logic to in experiments and we also compared the performance of our implementation of against the implementation of algorithm in and in the library and we observed similar performance characteristics that validated our implementation in the fifth experiment we compared our results against the state of the art tool for deciding monadic second order logic contributions in summary our contributions are · a formal study of the notion of of sfas § · two algorithms for sfas based on classical dfa algorithms § and § · a completely new algorithm for sfas together with a proof of its correctness § · a evaluation of the algorithms using a variety of different benchmarks § and · a description of several concrete applications of such tion algorithms § effective boolean algebras and sfas we first formally define the notion of effective boolean algebra and symbolic finite automata next we develop a theory which explains what it means for a symbolic finite automata to be minimal an effective boolean algebra a has components d ¬ d is an re recursively enumerable set of domain elements is an re set of predicates closed under the boolean connectives and the denotation function d is re and is such that d for all and ¬ d for we write when and say that is satisfiable a is decidable if is decidable the intuition is that such an algebra is represented as an api with corresponding methods implementing the boolean operations and the denotation function we are primarily going to use the following two effective boolean algebras in the examples but the techniques in the paper are fully generic is the powerset algebra whose domain is the finite set for some k consisting of all nonnegative integers smaller than k or equivalently all a predicate is represented by a bdd of depth k the boolean operations correspond directly to the bdd operations is the bdd representing the empty set the denotation of a bdd is the set of all integers n such that a binary representation of n corresponds to a solution of smt is the decision procedure for a theory over some sort say integers such as the theory of integer linear arithmetic this algebra can be implemented through an interface to an smt solver contains in this case the set of all formulas x in that theory with one fixed free integer variable x for example a formula x mod k say div k denotes the set of all numbers by k then div div denotes the set of numbers by six we can now define symbolic finite automata intuitively a symbolic finite automaton is a finite automaton over a symbolic alphabet where edge labels are replaced by predicates in order to preserve the classical closure operations intersection complement etc the predicates must form an effective boolean algebra definition a symbolic finite automaton sfa m is a tuple a q q f where a is an effective boolean algebra called the alphabet q is a finite set of states q q is the initial state f q is the set of final states and q × a × q is a finite set of moves or transitions elements of da are called characters and finite sequences of characters elements of da are called words denotes the empty word a move p q is also denoted by p m q or p q when m is clear where p is the source state denoted src q is the target state denoted tgt and is the guard or predicate of the move denoted a move is feasible if its guard is satisfiable given a character a da an of m is a move p q such that a also denoted p a m q or p a q when m is clear in the following let m a q q f be an sfa definition a word w aa · · · ak da is accepted at state p of m denoted w if there exist pi ai m pi for i k such that p p and pk f the language accepted by m is lm def lq m the variable order of the bdd is the reverse bit order of the binary representation of a number in particular the most significant bit has the lowest given a state q q we use the following definitions for the set transitions from and to q q def src q q def tgt q the definitions are lifted to sets in the usual manner the following terminology is used to characterize various key properties of m a state p of m is called partial if there exists a character a for which there exist no with source state p · m is deterministic for all p q p q if then q q · m is complete there are no partial states · m is clean for all p q p is reachable from q and · m is normalized for all p q q there is at most one move from p to q · m is minimal m is deterministic complete clean normalized and for all p q q p q if and only if for the special case in which m is deterministic and complete we denote the transition function using the function m da × q q such that for all a da and p q m a p def q where q is the state such that p a m q observe that because of determinism if p m q p m q and a then q q moreover due to completeness there exists some q and such that p m q and a of sfas is always possible and is studied in completion is straightforward if m is not complete then add a new state q and the q q and for each par tial state q add the move q completion requires negation q observe that normalization is obvious if there exist states p and q and two distinct transitions p q and p q then replace these transitions with the single transition p q this does not affect for any p we always assume that m is clean amounts to running a standard forward reachability algorithm that keeps only reachable states and eliminates infeasible moves observe that in feasible moves p q do not add expressiveness and might cause unnecessary state space explosion it is important to show that of sfas is in fact welldefined in the sense that minimal sfas are unique up to renaming of states and equivalence of predicates to do so we use the following construction assume m a q q f to be deterministic and complete let a denote the firstorder language that contains the unary relation symbol and the unary function symbol for each a da we define the of m denoted by m to have the universe q and the interpretation function def f a p q def m a p also let m def q m w · a def m a m w for a da and w da in other words m w is the state reached in m for the word w da recall that two structures are isomorphic if there it is sometimes convenient to define over incomplete sfas in which case the state q q q and lq m is eliminated if it is present exists a mapping between their that preserves the meaning of all symbols in theorem if m and n are minimal sfas over the same alphabet a such that lm ln then m and n are isomorphic proof assume m and n to be minimal sfas over a such that lm ln we define i m n as follows w w def n w to show that i is welldefined as a function observe first that all states of m correspond to some w because m is clean second we prove that for all words v and w if m v m w then n v n w fix v w da such that m v m w then for all u da u by by m v v · u ln v · u lm u u w · u lm by w · u ln u so and thus n v n w by of n so i is welldefined as a function by switching the roles of m and n we also get the opposite direction thus v w v m w n v n w next we show that i is an isomorphism first we show that i is i is onto because n is clean ie each state of n corresponds to n w for some word w i is into because if m v m w then by im v n v n w im w finally we show that i is an embedding of m into n ie that i preserves all the functions and the relations for all p qm p ip and for all p qm and a da let p qm let w be any word such that p m w then p m w w lm w ln n w im w ip and for any a da w im a m w im w · a n w · a n a n w w w thus m and n are isomorphic the theorem implies that minimal sfas are unique up to renaming of states and up to equivalence of predicates due to normalization definition two states p q q are m equivalent p m q when we have that m is an equivalence relation if is an equivalence relation over q then for q q q denotes the equivalence class containing q for x q x denotes q q x and m denotes the sfa m def a q q f where def p q p q q p q pq observe that m is normalized by construction we need the following theorem that shows that minimization of sfas preserves their intended semantics theorem let m be a clean complete and deterministic sfa then mm is minimal and lm proof let be m clearly m is clean and complete because m is clean and complete to show determinism let p a m q and p a m q take p p p q q and q q such that p a m q and is deterministic thus p a m it follows ml q and q m q a da p qm m a p m a p of m follows from the definition next we show by induction over the length of w that w w for w we have that m qm m qm and qm qm for w v · a where a da and v da we have that m v · a m a m v by m a m v m a mv mv · a it follows that for all words w da w lm iff m w fm iff m w fm iff by fm iff w lm thus lm lm theorems and are classical theorems lifted to arbitrary possibly infinite alphabets theorem implies that sfas have equivalent minimal forms that by theorem are unique up to of states and modulo equivalence of predicates in a in particular since for all q and all equivalence relations e over q qe q each equivalent form has minimal number of states algorithm over symbolic alphabets minimization algorithm of also due to is commonly known as the standard algorithm even though the classical version of algorithm depends on the alphabet being finite the general idea can be lifted to sfas as follows given an sfa m initially let d be the binary relation f × f c f c × f where f c is q f compute the fixpoint of d as follows if p q d and there exist moves p p and q q where is satisfiable then add p q to d this process clearly terminates upon termination e q × q d is the equivalence relation m and the sfa me is therefore minimal we refer to this algorithm as observe that checks only satisfiability of conjunctions of conditions and does not depend on the full power of the alphabet algebra in particular it does not require the ability to complement predicates assuming the initial completion of m is viewed as a separate preprocessing step this is in contrast with the generalization of algorithm discussed in the next section complexity in the finite alphabet case algorithm can be implemented in n using the approach described in where n is the number of states of the dfa and k the number of characters in the input alphabet however such implementation relies on the alphabet being finite in a concrete implementation a dictionary can be used to maintain d similar to the case of section p p a r q a rc p figure the idea behind an a of a part p our implementation of the version of algorithm presented above has the following complexity given an sfa a let n be the number of states of a m the number of moves of a and the size of the largest guard appearing in a transition of a the predicate if the complexity of the alphabet theory for instances of size l is f l then has complexity which is assuming normalized a where m is on algorithm over symbolic alphabets algorithm for is based on a technique called partition refinement of states the symbolic version of algorithm is given in figure initially the set of states is partitioned into two sets final states and states ie p f q f here we assume that the sfa m is complete and nontrivial so that both f and q f are nonempty the partition p induces the equivalence relation p or when p is clear from the context over q such that q p at a high level p is refined as follows suppose there exist parts p r p and a character a da such that some from p goes into r and some from p goes into rc q r then the a of p is the set p p where p resp p is the set of all p p from which there is an into r resp rc p is then replaced in p by p and p see figure the a of p is welldefined by determinism and completeness of m the following invariant is maintained by splitting lemma after each refinement step of p for all p q q if p q then proof initially for p f the statement after step i step and i p fix p r pi and a to q f see that da such that p p is the a of p it is enough to show that for all p and p p a q p p since q lp m lp m consider p and q belong to distinct parts of pi a q by ih there exists a word w such moreover by determinism that of w m a iff w lq m m iff w m for j so a · w lp m iff a · w lp m and thus lp m lp m assuming a simple iterative refinement loop of p splitting is repeated until no further splits are possible ie until p is at which point the following property holds lemma upon termination of refinement of p for all p q q if p q then proof by way of contradiction suppose there exists a word x and states p p such that x lp m x lp m choose w to be a shortest such x since w cannot be because p p f or p p q f there are a and v such that a · v w and moves p q and p q such that a and a the choice of q and q is unique for given a by determinism so by v thus w m lq m v v lq m l qi m for i def tree new tree a null null foreach in ¯ return return the set of all the leaf predicates class tree predicate tree left tree right refine def if a a and a a ¬a if left null if the tree is a leaf then split into two parts left new tree a null null right new tree a null else refine subtrees recursively figure generation for ¯ a modulo a we now have the following contradiction there are two cases if q q say q r and q rc for some part r then p is not because we can split the part p p such that p p p using the a of p if q q then because v w and holds for x v and q q in place of p p it follows that w is not the shortest x such that holds in addition to the state partition refinement in the symbolic case we also use predicate refinement predicate refinement builds a set of minterms a is a minimal satisfiable boolean combinations of all guards that occur in the sfa the algorithm is shown in figure it uses a binary tree whose leaves define the partition initially the tree is the leaf each time a predicate is used to refine the tree it may cause splitting of its leaves into predicates the following example illustrates such generation example consider the alphabet algebra bv characters we use standard notation for character classes suppose that the following two guards occur in the given sfa w w and d d then the value of tree in w d in line in figure is either the first of the two trees below if w is selected first in the loop of line or else the second tree note that d w so d w d w d d w w the minterms are the leaves d w and next we analyze a property of the set of minterms given a predicate a and a state p q define p def tgt p p def src p p def p for p q pp let ing minterms proposition m def implies the are proposition let m be deterministic and complete for all and p q p we can therefore treat as a function from minterms to q and reduce minimization of the sfa to minimization of the dfa with alphabet minterms and transition function in particular we can m a q q f def p f q f initial partition w if f q f then f else q f compute the minterms while w iterate over parts r w w r foreach in iterate over all minterms s r all states leading into r for given while exists p in p where p s and p s p w p p s p s split p return mp split pw p p p def p w where p p p p p refine p w if p w then w p p p both parts else w if p p then p else p smaller part figure minimization algorithm lifted to deterministic sfas m is assumed to be clean complete and nontrivial f and q f use algorithm we refer to the resulting algorithm by such an algorithm is shown in figure lifting the transition relation to be over minterms is a powerful that can be used to adapt most classical automata algorithms to the symbolic setting however one of generation is that in the worst case the number of minterms of an sfa is exponential in the number of guards occurring in the sfa the following example illustrates a worst case scenario in which due to such a problem runs in exponential time example let the character domain be nonnegative integers k suppose ix is a predicate that is true for x iff the ith bit of the binary representation of x is eg is true and is false predicate can be defined as ¬x provided that besides equality the operator is a builtin function symbol of a eg consider the theory of an smt solver similarly we may also use the algebra where the size of the concrete bdd representation for i is linear in k it has one node that is labeled by i and whose left child case bit is is false and whose right child case bit is is true the point is that predicates are small essentially constant in size consider the following sfa mk with such an alphabet a q q q · · · qk k qk ¬ k p p · · · pk then minterms mk has k elements where n n for example suppose k then ¬ the minimal automaton is q q q · · · qk k qk the state q necessary for completion is implicit complexity in the finite alphabet case algorithm has complexity log n where n is the number of states of the dfa and k is the number of characters in the input alphabet assuming k is treated as a constant it is shown in that if k is on then the complexity of the algorithm presented in is m a q q f def p f q f initial partition w if f q f then f else q f while w main loop r w w r s src r all states leading into r p denotes the set of all characters leading from p s into r p p s p while exists p in p where p s and p s p w p p s p s while exists p in p where p s and exists p p in p where ¬p p a p p p p a p p w p p p p a return mp figure minimization of deterministic sfas m is assumed to be clean complete and nontrivial is defined in figure on but it is also shown that log n complexity can be maintained with a more careful implementation given an sfa let n be the number of states let m be the number of moves and let be the size of the largest label guard of a move in a normalized sfa there are at most n moves let be the number of minterms of the sfa is bounded by m each is of the form m where each i is a guard or a guard and thus minterms have size om the computation of minterms is m where f is the complexity to decide satisfiability of formulas of given size the rest of the algorithm after line can be seen as a standard implementation of algorithm where the sfa is first transformed into a dfa with an alphabet of identifiers where each sfa label has been replaced by identifiers of all relevant minterms then is viewed as a concrete alphabet of such identifiers in the final result the identifiers are mapped back to minterms and the resulting sfa is normalized the overall complexity is then m mn log n minimization without generation when the worst case complexity of the factor that stands out the most is the exponential caused by the predicate refinement generation in this section we investigate a new technique which is based on the symbolic representation of the alphabet and that avoids generation figure shows a new minimization algorithm that does not require predicate refinement the intuition behind is the following when splitting a partitions part it is not necessary to provide the exact witness that defines the split instead it is enough to check if some witness or witness set exists the main steps are the two inner while loops in figure they both refine the partition p with respect to r in the first loop lines ­ a part p is split into p s and p s without using a fixed witness see figure a where p p p p is a of p but it is neither an a nor a b of p the second loop lines ­ splits p if there exists some a that produces an a of p such an element a s p p p p p s p p p q q b a b a a b a b a a b q q r q q q r q b q a b a figure split cases of p in suppose da a b must distinguish at least two states p and p of p see figure b so that the split is indeed proper and guarantees progress the first loop lines ­ is an optimization that can be omitted without correctness provided that for p s we let p def the conditions p s and p s together imply that there exist p p s and p p s and thus p but p so ¬p p is satisfiable the concrete implementation is shown in figure it differs from the abstract algorithm in that it computes local minterms and does not compute any concrete witnesses the element a is not computed in the second loop in the concrete implementation it is important to keep the first loop for the following reasons one is efficiency the first loop is second is simplicity it is useful to work with as a dictionary or array whose index set is s and it is practical to assume that the invariant p s holds during the second loop next we formally prove the correctness of the proof provides more intuition on how the algorithm works we then provide more details on how the concrete implementation works theorem is minimal and m lm proof we show first that the invariant of lemma holds the invariant clearly holds initially we show that it is preserved by each split lines ­ and lines ­ first and let s consider the first splitting loop src r and in figure choose p fix r p p such that p p s and p p s fix p p and p p then there is a move p q for some q r let a since p s and m is complete for some q rc there exist a move p q such that a the situation is illustrated p that satisfy the loop condition all parts in p that with s must be subsets of s due to the first splitting loop so since m is clean p s p and the fa var fb new var new var blocks new block foreach var q in fb foreach var q in var w new if else while var r var g in figure var s var relevant blocks with s foreach var p in relevant lines in figure var p p s if of p foreach var p in p p if else if else bool iterate true while iterate lines in figure iterate false relevant blocks with s foreach var p in relevant var p new block var psi start with some element of p bool false while var q var if if psi psi else if psi psi refine the local true else psi implies if psi set p to q psi psi swap the local true else psi is equivalent to if a of p for some a iterate iterate foreach var p in p p if else if else construct the result using blocks and it figure concrete implementation of tion ¬p p means that either ¬p or ¬p assume the former case and choose a p ¬p by definition of we know that there is a move p q where q r such that a moreover since a p and p covers all the characters that lead from p to r there must be by completeness and determinism of m a move p q where q rc and a see we now show that lemma holds the proof is by way of contradiction assume there exists a word x a part p p and two states p p p such that x lp m x lp m let w be shortest such x since w cannot be there exist a and v such that w so there are by determinism and completeness of m unique q and q such that p a q and p a q it follows w lq m so q q or else v satisfies consider any fixed computation of it follows from the that the w is always update to w a subset of p and due if w ever contains a part containing a state q then w will keep containing a part that contains q until such a part is removed from w in line next we show that the following w invariant must hold at all times for all r w q r q r let suppose by way of contradiction that at some point in line a part r is chosen from w such that q r and q r so p s with s as in line we then have two following cases if p s then p and p are split apart in the first splitting loop this contradicts the fact that p p assume p s and consider the second splitting loop by choice of the character a above we know that there exist moves p q and p q where a and a it follows that a p because m is deterministic and q r while a p so a p p or in other words a p ¬p and therefore ¬p p holds consequently p and p end up in distinct parts upon termination of the second splitting loop this again contradicts the fact that p p so initially q f q f or else the initial part of w violates the invariant but now consider the point when the part containing both q and q is split into two parts containing q and q respectively but at this point at least one of those parts will be point we have shown that upon termination of p co with m it follows and accepts lm from theorem that mp is minimal implementation a simplified version of our concrete c implementation of is shown in figure parts of a state partition are represented by mutable sets called blocks ie objects of type block and states are represented by integers each block contains a of states the search frontier w is maintained as a stack of blocks and the partition p is an array of blocks called blocks that is indexed by states the first inner while loop lines ­ in figure is implemented by over all blocks p that with s the content of block p becomes p s while the content of block p is updated to p s observe that blocks are objects pointers thus if w contains p after the it will still contain p as well as the new block p the second inner while loop lines ­ in figure is implemented by en efficient encoding of the search for p and p in line of figure moreover no concrete witness a is computed instead a local called psi or in figure is computed using this avoids the use of model generation that is more expensive than satisfiability checking ie checking if there exists a model thus the implementation does not rely on model generation observe also that the second inner while loop relies on the fact that all remaining relevant blocks that with s must be contained in s due to the first inner loop the split of p although a is formally defined as a satisfiability checking is a more lightweight operation than actual model generation in particular in the context of smt solvers then happens with respect to which by construction is a member of minterms p p p so some member a of would have produced the same split relation to classical techniques implementation of algorithm is discussed in detail in in the classical setting the notions of blocks and a are standard the pair r a is called a splitter in classical algorithms where it plays a key role the idea of splitting a block into two and keeping only the smaller block in the waiting set w is a core classical feature in the case of partial the algorithms are similar except that w must be initialized with both f and f c in classical implementations the waiting set w consists of rather than blocks where characters have been the same is true for partial except that only those characters that are relevant for a given block are being used which is for with sparse transition graphs in the symbolic setting the character selection is indirect and achieved only through the satisfiability checks using local minterms during the second loop the alphabet algebra may be infinite in the case of sfas this is not possible in the classical setting as far as we know the idea behind the first inner loop of and the notion of recall figure say free r have not been studied in the classical setting complexity the complexity of depends on several factors most importantly on the representation of predicates and the concrete representation of the partition refinement data structure that is explained above first of all observe that each p has size at most on and the total size of is on since the split operator always adds to w only the smallest partition the outer loop is run at most log n times the two internal loops have different running times · the first loop is run at most n times with an internal complexity of on due to the split operation and · the second loop is run at most n times and if the complexity of the label theory for instances of size l is f l the complexity of each iteration is at most n this is due to the n internal iterations over the current part p we also notice that each iteration calls the solver on a predicate of size at most on we can conclude that has complexity n · f n as we will observe in the next section the quadratic behavior is not observed in practice evaluation we evaluate the performance of and with the following experiments we minimize the randomly generated from the mark presented in this experiment analyzes the performance in the presence of small finite alphabets and allows us to validate our implementation of against the results shown in we minimize the sfas generated by common regular expressions taken from the web this experiment measures performance in the case of typical character alphabets we minimize the sfas mk from example to show the worst case exponential behavior of in this experiment we also compare against the library a automata library that uses character ranges as a symbolic representations of finite alphabets figure running times on benchmark of randomly generated the corresponding sfas are over the theory of and each set of input symbols is represented as a predicate using a binary decision diagram bdd we minimize randomly generated sfas over the theory of pairs of integers and strings here we analyze the performance in the case in which the alphabet is infinite and we implemented the classical procedure for transforming monadic second order mso logic formulae into and measure how the running time of such transformation is affected by different minimization algorithms this last test aims at understanding the performance in the case of very large alphabets we also compare our implementation against the tool the state of the art library for deciding mso formulae all the experiments are run on a bits processor with gb of ram memory small randomly generated in the performance of several minimization algorithms are com against a set of randomly generated such benchmark contains with number of states ranging between and and alphabet sizes ranging between and the set of in is uniformly generated at random and therefore it offers good statistical coverage of the set of all possible with such number of states and alphabet sizes we run and on such set of figure shows the results for simplicity we only the results for with and states each contains the run time for each algorithm where the x axis represents the num of symbols in the alphabet in algorithm is not considered and we therefore able to validate the accuracy of our implementation of however we were able the behavior of algorithm shown using to on figure shows how the number of states affected by the number of input alphabets we can indeed see that already for states performs worse than in this experiment for most of the input the number of minterms was the same as the number of input symbols it is not and a indeed both be to both state space and alphabets moreover for no single input is slower than or figure running times on from both are in figure running times on the mk sfas of example the is in regular expressions next we compared the performance of different minimization algorithms over a sample set of sfas over the alphabet bv of characters constructed from typical taken from a public of popular figure shows the running in all cases the number of minterms turned out to be smaller by a factor between and than the total number of predicates and the exponential of minterms never occurred the size of the generated sfas ranged from states to states with an average of states after the minimization each sfa was smaller number of states than the original sfa the following is a typical from the sample set the generated sfa uses predicates such as d while there are only minterms such as for this the sfa has states and the sfa has states since the number of minterms does not is there a performance in using in this context the answer is yes since the total time used to minimize all sfas was seconds when using thus showing a and only x speedup seconds when using we also measured the performance of the minimization algo rithm implemented in the library version that uses symbolic integer ranges to represent char but does not implement them as a boolean algebra since ranges are not closed under complement and union we observed that the implementation of algorithms is to our the running at most to that of the implementation in the library we decided not to include the latter in the for the following reasons is implemented in java while our are all in c and in the code corresponding to the computation is not part of the minimization algorithm therefore the comparison would not be completely fair especially for big instances we use standard character class notation for character predicates alphabet corner cases the next experiment shows the importance of avoiding the generation used by we consider the sfas mk from example for values of k ranging between and over the alphabet bv of bit figure shows the running times for took sec less than with k ms for while time increased from ms to the time below ms for all the values of k similarly to the previous experiment we also compared the run time of the sample set against and algorithm in the library version for this experiment we decided to show the performance in order to how this particular example causes the num of ranges to grow exponentially causing algorithm to be very slow it is interesting to notice that the tation of algorithm is also slow this is again due to the alphabets caused by the ranges algebra complex theories we compare the performance of and over a sample set of randomly generated sfas over the theory of pairs over string × int the guards of each sfas are conjunctions of simple predicates over strings and integers in the theory of strings we only allow comparison against a constant string while for integers we generate unary predicates containing and integer constants the set of generated sfas is created as follows we first generated a set s of sfas with at most states for each sfa a s we also compute the complement and for every pair a b s we compute the union intersection and difference of a and b figure shows the running time of each algorithm for numbers of states we first observe how the performance of quickly when increasing the number of states this is mainly due to the large number of minterms since the pred are randomly generated many are possible and the number of minterms grows quickly next we can see how the per of is affected by the increasing number of states finally can quickly less than seconds this minimize sfas with up experiment shows how to states in is not affected by complex theories while and are both in this setting a b figure running times for sfas over the theory string × int with seconds timeout from monadic secondorder logic predicates to the relation between regular languages and logic has been extensively investigated in the past particularly every regular language can be expressed as a formula in monadic secondorder logic mso over strings and vice versa in the rest of the section we assume the alphabet to be a finite set say a b the following is an example of an mso formula where a is a unary relation symbol a string s is a model of iff there exists a position x in the string with label a transforming mso formulas to automata gives us an algorithm for deciding satisfiability of mso formulas the procedure for converting an mso formula into a dfa inductively transforms each into the corresponding dfa and then combines such using classical regular language operations the complexity arises from the presence of free variables that range over positions for example in the formula ax x occurs free in order to represent such a language the alphabet is extended with one extra bit to × the string a b a over the extended alphabet will then represent that the third position of the string is assigned to variable x following this intuition every is compiled into a dfa over the alphabet × n where n is the number of quantified variables around for each existential quantification a projection is performed which leads to a nondeterministic automaton that must be when a negation on it is performed this means that each quantifier alternation might therefore lead to an exponential and in general the procedure has complexity despite the complexity practical algorithms that can translate nontrivial mso formulas are presented in the tool implementing such algorithms is called the two of such algorithms are and the intermediate dfa at every step in the transformation and using bdds for representing the lifted alphabets we implemented the same transformation using the bdd solver in our library and compared the performance using different minimization algorithms figure shows the performance of the transformation for different mso formulas the running time for are also shown the four the running time for the mso to dfa transformation for the following formulas a x xk x xk for k between and b x xk x xk ax for k between and c d figure mso to dfa running times the are in c x xk x xk ax for k between and d x xk fk where f x x ax cx and for n fn fn xn xn for k between and all the values missing from the graphs are due to the algorithms running out of memory the figure shows the following behaviors · for all of the four classes of formulas the transformation based on is able to create the for higher values of k number of nested variables than those supported by · for small instances is faster than our implementation however for higher values of k our implementation is faster even when using or · while immediately shows an exponential behavior very we observe such in our implementation and · is faster than and and it is also less memory it runs out of memory for higher k even though such formulas are only a small benchmark they are quite representative of the kind of inputs that cause transformation to be we believe that the performance improvement of our implementation with respect to is primarily due to a better use of the bdd solver rather than due to the minimization algorithm applications the development of the theory of symbolic automata including use of minimization is motivated by several concrete practical problems here we discuss three such applications in each case we illustrate what kind of character theory we are working with the role of minimization and focus on the benefits of the symbolic representation processing practical applications of regular expressions or is practical differ from regular expressions in the following aspects · they support besides features that go beyond capabilities of finite state automata representations constructs such as bounded quantifiers and character classes that make them more more than their classical counterparts and · the size of the alphabet is due to the widely adopted standard of characters as a somewhat example the matches the set of in the socalled wide range of we let the alphabet algebra be bv let the bdd w represent all word characters as the set of character codes a z a z we write for the code a for sent the set of all the code etc let also and by using the boolean operations eg w represents the set of all upper and letters as a character class it is expressible as are used in many different contexts a common use of is as a constraint language over strings for checking ence or absence of different patterns eg for security validation of packet in network protocols another application is the use of for generating strings that match certain criteria eg for testing applications as another application consider the password generation problem based on constraints given in form of here is a concrete set of constraints adopted in pass word generation length is k and characters are in visible range there are at least two letters there is at least one d there is at least one character w the smallest feasible value for k is obviously consider sfas a a a and a for each case and let a be their product for k the version of a has states and a k with any of is increased or the number takes a few ms when of states increases to and using ms while or becomes takes respectively taking more than and sec x slower the minimal canonical form of a plays an important role here together with of the language accepted by a is used to guarantee a uniform distribution of the from a is achieved by using the canonical form of the state graph together with the canonical form of the guards while uniform sampling of a is not possible for arbitrary alphabet theories it is a wellknown feature of bdds sanitizer analysis sanitizers are string transformation routines special purpose that are extensively used in web applications in particular as the first line of against cross site attacks there are at least three semantically very different string sanitizers involved in a single web page and a large class of sanitizers including all the ones mentioned above can be described and analyzed using symbolic finite state transducers sfts sfas are used in that context for certain operations over sfts for example for checking domain equivalence of sfts since several basic operations are quadratic recall the standard convention a without the matches any prefix and a without the matches any suffix relevant values of k in the above scenario depend on the concrete context but range between and in the number of states product union minimization comes in as a tool for reducing the state space size in this setting we choose a different character theory we use integer linear modular arithmetic or arithmetic of an smt solver in our case z in place of bdds the main advantage of this choice is that it makes it possible to combine the guards over characters with expressions over yields ie the symbolic outputs of sft moves a concrete example of a yield is the following transformation that takes a character and encodes it as a sequence of five other characters f x x ÷ mod x mod in general a yield denotes a function from da to da or to db when the output alphabet b is different from the input alphabet a in the yield above for example f a is the sequence or the string given f as above a typical sft move looks like q q this specific rule happens to be an rule for encoding control characters in state q and remaining in that state what is the connection with sfas and the theory mentioned above for analyzing the idempotence of an with such rules the is sequentially composed with itself as a result this leads to an sft with more complex guards and outputs sfts are closed under composition when composing the move with itself ie roughly speaking the five output characters as its inputs again five times in a row the guard of the composed rule will have such as x ÷ mod which may involve nontrivial arithmetic operations in this particular case the guard of the composed move will be infeasible one of the operations performed during idempotence analysis is checking whether the original sft and the composed one have the same domain this reduces to language equivalence of sfas for which the guards involve arithmetic operations of the above kind that are not readily expressible using the earlier bdd based approach domain equivalence of two sfts checks that both the sfts the same input sequences maintaining the sfas minimal up the equivalence check and in general provides a better understanding of the structure of the domain language in general the alphabet theory may be a boolean combination of other decidable theories that are available for example in state smt solvers in the context of sanitizers and the alphabet theory is a combination of lists tuples bit vectors and integer linear arithmetic lists are used for example to represent composite characters or characters that represent head we demonstrated in the evaluation section that when the alphabet both theory is complex the algorithm and by several orders of magnitude enabling analysis of solving monadic second order logic we already in section how monadic second order mso logic predicates can be transformed into equivalent using a algorithm such algorithm also provides a decision procedure for mso we already discussed how several techniques have been introduced by the tool in order to make such transformation practical keeping the dfa minimal at any step in the transformation is one of the key techniques we gave experimental evidence of the fact that the new algorithm presented in this paper and in general the use of symbolic automata can further move the barrier of solvable mso formulas in terms of both formulas size number of nested quantifiers and running times related work dfa minimization the classical algorithms for dfa minimization have been studied and analyzed extensively in several different aspects in particular algorithm is studied in where it is shown that by a change of data structures its complexity can be reduced from to log n the bound log n has been shown to be tight for algorithm observed that a dfa can be by its transitions then then its transitions again and finally again however due to the steps this procedure is exponential and we decided not to consider it in this paper linear time algorithms have been studied for acyclic automata and automata containing only simple cycles the chapter provides an study of the techniques for automata minimization including the approaches mentioned above and several other ones watson also provides an elegant classification of the classical minimization algorithms based on their structural properties in the case of it whether the dfa to be is partial incomplete because it may be useful to avoid completion of with sparse transition graphs minimization of partial is studied in in this setting the complexity of the algorithm depends on the number of transitions rather than on the size of the alphabet however in the case of these two are generally related in contrast in a normalized sfa the number of transitions is independent of the alphabet size and it is at most n where n is the number of states one concrete difference between the minimization algorithms of complete versus partial is that the initial value of the waiting set w see figure for the partial case must contain both the sets f and f c we believe that similar modifications may be applied to even though we expect that in the case of sfas the benefit of using might not be as visible in fact a complete sfa has at most n transitions more than a partial one moreover in the case of sfas there are different ways for an sfa eg one can effectively restrict the alphabet to only those characters that are mentioned in the sfa sfa without states prior to completion different notions of minimization a notion of incremental minimization is investigated in an incremental minimization algorithm can be at any point and produce a partially minimal dfa which is equivalent to the starting dfa and has less or equal number of states if the algorithm runs completion a minimal dfa is computed in this paper we did not address incremental computation however it would be interesting to identify variants of the presented algorithms with such a property a similar idea based on intermediate computation results is used for a modular minimization algorithm in an algorithm for building a minimal dfa accepting a given finite set of strings is presented in the same paper the problem of maintaining a minimal dfa when applying modification such as node edge or string deletion and insertion to an already minimal dfa this class of problems is called dynamic minimization a parallel version of algorithm is presented in we are not aware of a parallel version of algorithm we leave as an open problem identifying parallel algorithms corresponding to and a variant of minimization called is investigated in given an input dfa a a dfa a is minimal with respect to a if it is the smallest dfa that differs from a only on a finite number of strings in the case of symbolic automata this definition doesnt extend naturally due to potentially infinite alphabet a less restrictive notion called is studied in given an input dfa a a dfa a is with respect to a if it is the smallest dfa that differs from a only on strings of length smaller or equal than k this second restriction naturally extends to symbolic automata a more general notion is that of minimization up to where given a regular language e the dfa a is allowed to differ from a on a set of strings l e extending the results of to symbolic automata is an interesting open research direction relationships between and selection of final states are studied in where uniform is defined as for any choice of final states automata with predicates the concept of automata with predicates instead of concrete symbols was first mentioned in and was first discussed in in the context of natural language processing a symbolic generalization of algorithm was first discussed in to the best of our knowledge no other minimization algorithms have been studied for sfas the implementation provides decision procedures for monadic secondorder logic and it relies on a representation for automata which has seen extensive engineering effort therefore the use of bdds in the context of automata is not new but is used here as an example of a boolean algebra that seems particularly well suited for working with alphabets minimization of other automata the problem of automata minimization has been investigated in several other settings a new approach for nondeterministic automata and nondeterministic bu¨chi automata has been studied in the problem of weighted automata automata computing functions from strings to a semiring is studied in classical minimization algorithms are used in this setting and we hope that the results shown in this paper can extend to such domain the minimization problem has also been studied for automata and register automata these models are able to represent infinite domains but not arbitrary theories an orthogonal direction is to extend the techniques presented in this paper to minimization of symbolic tree automata other applications the problem of learning of symbolic transducers has recently been studied in classical automata learning is based on algorithm which relies on dfa an almost topic is whether such learning techniques can be extended to sfas conclusions we presented three algorithms for symbolic finite automata sfas we first extended algorithm and algorithm to the symbolic setting we then show that while in the classical setting algorithm is the known minimization algorithm in the presence of symbolic alphabets it might in an exponential to address this issue we introduced a new minimization algorithm that fully benefits from the symbolic representation of the alphabet and does not from the exponential the new algorithm is a refinement of one in which splits are computed locally without having to consider the entire input alphabet the new algorithm can also be adopted in the classical setting finally we implemented all the algorithms and provided experimental evidence that the new minimization algorithm is the most efficient one in practice acknowledgments we thank for us accessing his benchmark of randomly generated was supported by the nsf in computing and this work was done as part of an at microsoft research we also thank the anonymous reviewers for their comments references finite state automata j and m description and analysis of a bottom up dfa minimization algorithm information processing letters ­ m n and r on the performance of automata minimization algorithms technical report dcc university of d learning regular sets from queries and counterexamples inf comput ­ mp and m incomplete automata in finitestate methods and natural language processing th international workshop pages ­ j l and o automaton minimization algorithm and words in pages ­ j l o and i minimization of automata to appear in of automata j and o on the complexity of state minimization algorithm in volume pages ­ n v r and m an format for sequences and regular expressions in p and a editors smt pages ­ n an n log n implementation of the standard method for finite automata information processing letters ­ m and s a characterization of languages in a k a pitts and r editors automata languages and programming volume of lncs pages ­ springer berlin m and d symbolic learning of inputoutput specifications in popl pages ­ new york ny usa acm j a canonical regular expressions and minimal state graphs for definite events in proc math theory of automata pages ­ new york d modular minimization of deterministic finitestate machines in in th international workshop on formal methods for critical systems pages ­ r c and m l incremental construction and of minimal finitestate automata comput ­ june s b f and b a canonical register automaton model for data domains with binary relations in s and m editors volume of lncs pages ­ springer l and m equivalence of extended symbolic finite transducers in n and h editors cav volume of lncs pages ­ springer l m b and d fast a language for tree manipulation technical report microsoft research november l de and n z an efficient smt solver in tacas lncs springer m w and h of weighted automata springer incorporated st edition p a and a on automata with errors in pages ­ berlin springer j j m n b t and a monadic secondorder logic in practice in tacas volume of lncs springer m and s from equivalence to and beyond ­ automata with errors in hc and o editors developments in language theory volume of lncs pages ­ springer m and a an algorithm for a deterministic automaton theor comput sci ­ p b d p and m fast and precise sanitizer analysis with bek in usenix security august p and m an evaluation of automata algorithms for string analysis in volume of lncs pages ­ springer j hopcroft an algorithm for states in a finite automaton in z editor theory of machines and computations proc pages ­ new york academic press j e hopcroft and j d ullman introduction to automata theory languages and computation d the synthesis of sequential switching circuits journal of the institute n a and m i implementation international journal of foundations of computer science ­ t an algorithm by hopcroft theor comput sci ­ s l algorithms for minimization of finite acyclic automata and pattern matching in terms ­ r and l advanced automata minimization in popl pages ­ e f moore on sequential machines automata studies of mathematics studies ­ a and r some remarks on automata in g and a editors volume of lncs pages ­ springer d of acyclic deterministic automata in linear time comput sci ­ a u and p gupta a parallel dfa minimization algorithm in volume of lncs pages ­ springer w thomas languages automata and logic in of formal languages pages ­ springer a fast brief practical dfa minimization information processing letters ­ a and p efficient minimization of with partial transition functions in s and p editors pages ­ g van and d finite state transducers with predicates and identities grammars ­ m n and l de symbolic automata constraint solving in c and a editors volume of pages ­ springer m p de and n symbolic regular expression in pages ­ ieee m p b d and n symbolic finite state transducers algorithms and applications in popl pages ­ b w watson a of finite automata minimization algorithms computing science report university of technology january b w watson implementing and using finite automata in extended finite state models of language pages ­ new york ny usa cambridge university press b w watson and j an efficient incremental dfa minimization algorithm nat lang ­ mar 