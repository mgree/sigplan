formalizing the llvm intermediate representation for verified program transformations m k martin computer and information science department university of pennsylvania abstract this paper presents verified llvm a framework for reasoning about programs expressed in intermediate representation and transformations that operate on it provides a mechanized formal semantics of intermediate representation its type system and properties of its ssa form the framework is built using the coq interactive theorem prover it includes multiple operational semantics and proves relations among them to facilitate different reasoning and proof techniques to validate design we extract an interpreter from the coq formal semantics that can execute programs from llvm test suite and thus be compared against llvm reference implementations to demonstrate we formalize and verify a previously proposed transformation that c programs against spatial memory safety violations tools allow us to extract a new verified implementation of the transformation pass that into the real llvm infrastructure its performance is with the adhoc original categories and subject descriptors d software engineering verification correctness proofs f logics and meanings of programs and verifying and reasoning about programs mechanical verification f logics and meanings of programs semantics of programming languages operational semantics general terms languages verification reliability keywords llvm coq memory safety introduction compilers perform their optimizations and transformations over an intermediate representation ir that details about the target execution platform proving properties about these ir transformations requires that the ir itself have a welldefined formal semantics unfortunately the used in production compilers generally do not to address this this this research was in part by the us the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the policies either expressed or implied of the us permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ pa usa copyright c acm c c haskell scheme scala optimizations transformations llvm ir program analysis code generator jit alpha arm x figure the llvm compiler infrastructure paper formalizes both the static and dynamic semantics of the ir that forms the of the llvm compiler infrastructure llvm lowlevel virtual machine uses a ir originally developed as a research tool for studying optimizations and modern compilation techniques the llvm project has since into a robust and compilation platform that with gcc in terms of compilation speed and performance of the generated code as a consequence it has been widely used in both and an compiler is structured as a translation from a highlevel source language to the llvm ir see figure the llvm tools provide a suite of ir to ir translations which provide optimizations program transformations and static analyses the resulting llvm ir code can then be to a variety of target architectures including x and arm either by static compilation or dynamic the llvm project focuses on c and c but many source languages including haskell scheme scala objective c and others have been to target the llvm ir this paper introduces verified framework that includes a formal semantics and associated tools for mechanized verification of llvm ir code ir to ir transformations and analyses the description of this framework in this paper is organized into two parts the first part formalizes the llvm ir it presents the llvm syntax and static properties section including a variety of wellformedness and structural properties about static single assignment ssa representation that are useful in proofs about llvm code and transformation passes memory model section is based on extended to handle arbitrary integers and alignment issues in developing the operational semantics section a significant challenge is capturing the nondeterminism that arises due to explicit undef value and its of certain erroneous behaviors such as reading from uninitialized memory this is needed to justify the correctness of optimizations therefore implements several related operational semantics including a nondeterministic semantics and several deterministic refinements to facilitate different proof techniques and reasoning the second part of the paper focuses on the utility of formalizing the llvm ir we describe implementation in coq and validate its llvm ir semantics by extracting an executable interpreter and comparing its behavior to that of the llvm reference interpreter and compiled code section the framework provides support for moving code between ir representation and its coq representation this infrastructure along with facility for extracting executable code from constructive proofs enables users to manipulate llvm ir code with high in the results for example using this framework we can extract verified llvm transformations that directly into the llvm compiler we demonstrate the effectiveness of this technique by using to implement a verified instance of an that c programs against buffer and other memory safety violations section to summarize this paper and the framework provide · a formalization of the llvm ir its static semantics memory model and several operational semantics · results preservation and progress theorems relating the static and dynamic semantics · coq infrastructure implementing the above along with tools for interacting with the llvm compiler · validation of the semantics in the form of an extracted llvm interpreter and · of applying this framework to extract a verified transformation pass for enforcing spatial static properties of the llvm ir the llvm ir is a typed static single assignment ssa language that is a suitable representation for expressing many compiler transformations and optimizations this section describes the syntax and basic static properties those features that are either unique to the llvm or have nontrivial implications for the formalization formalization is based on the llvm release version and the syntax and semantics are intended to model the behavior as described in the llvm language reference although we also used the llvm ir reference interpreter and the x to our design language syntax figure shows a fragment of the abstract syntax for the subset of the llvm ir formalized in the metavariable id ranges over llvm identifiers written x t a b etc which are used to name local types and temporary variables and a b main etc which name global values and functions each source file is a module mod that includes data layout information layout which defines sizes and for types see below named types and a list of that can be function declarations function definitions and global variables figure shows a small example of llvm syntax its meaning is described in more detail in section every llvm expression has a type which can easily be determined from type annotations that provide sufficient information to check an llvm program for type compatibility the llvm ir is not a typesafe language however because its type system allows arbitrary casts calling functions with incorrect signatures accessing invalid memory etc the llvm type system ensures only that the size of a runtime value in a wellformed program is compatible with the type of the wellformed program can still be stuck see section see st type i x i define st ptr entry p malloc st i r st p i i store i r as s st p i i i store i ptr s ret st p figure an example use of memory operations here p is a pointer to a array of structures of type st pointer r into the first component of the first element in the array and has type i as used by the subsequent store which writes the bit value pointer s has type i and points to the first element of the nested array in the same structure types typ include arbitrary integers i i i etc or more generally where sz is a natural number types also include float void pointers typ arrays sz × typ that have a size sz anonymous structure types j contain a list of types functions typ have a return type and a list of argument types here j denotes a list of typ components we use similar notation for other lists throughout the paper finally types can be named by identifiers id which is useful to define recursive types the sizes and for types and are defined in layout for example int sz that values with type are aligned when they are within an aggregate and when used as an argument and aligned when as a global operations in the llvm ir compute with values val which are either identifiers id naming temporaries or constants computed from data using the compiletime of the commands described below constants include base values ie integers or of a given bit width and of a given type as well as structures and arrays built from other constants to account for uninitialized variables and to allow for various program optimizations the llvm ir also supports a undef constant semantically undef stands for a set of possible bit patterns and llvm compilers are free to pick convenient values for each occurrence of undef to enable optimizations or program transformations as described in section the presence of undef makes the llvm operational semantics inherently nondeterministic all code in the llvm ir in toplevel functions whose bodies are composed of block bs as in classic compiler representations a basic block consists of a labeled entry point l a series of nodes a list of commands and a instruction as is usual in ssa representations the nodes join together values from a list of predecessor blocks of the controlflow node takes a list of value label pairs that indicates the value chosen when control transfers from a predecessor block with the associated label block br and ret branch to another block or return possibly with a value from the current function also include the unreachable marker indicating that control should never reach that point in the program the core of the llvm instruction set is its commands c which include the usual suite of binary arithmetic operations add etc memory load store heap operations malloc and free stack allocation conversion operations among integers and pointers and comparison over integers and select and calls call modules mod p layout prod layouts layout ptr sz int sz float sz sz stack sz products prod id global typ const define typ id declare typ id arg fp float double types typ fp void typ sz × typ j typ id values val id add sub and or float ops extension cast op op constants int fp float typ id typ null typ typ j j typ undef to typ to typ to typ select cond blocks b l c nodes j id typ lj br val l l br l ret typ val ret void unreachable commands c id int sz val val id fp val val id load store typ val val id malloc typ val free typ val id typ val id typ val to typ id typ val to typ id typ val to typ id cond typ val val id select val typ val val id fp val val option id call typ val param id typ val figure syntax for llvm note that this figure some syntax definitions eg cond the comparison operators for the sake of space they are of course present in implementation some other parts of the llvm have been omitted from the development these are discussed in section note that a call site is allowed to ignore the return value of a function call finally computes pointer offsets into structured datatypes based on their types it provides a way of performing array indexing struct field access and pointer arithmetic static semantics following the llvm ir specification requires that every llvm program satisfy certain invariants to be considered well formed every variable in a function is welltyped and assigned exactly once at a minimum any reasonable llvm transformation must preserve these invariants together they imply that the program is in ssa form all the components in the llvm ir are annotated with types so the typechecking algorithm is straightforward and determined only by local only is that types themselves must be well formed all except void and function types are considered to be first class meaning that values of these types can be passed as arguments to functions a set of firstclass type definitions is well formed if there are no cycles in their definitions ie every cycle through the definitions is broken by a pointer type this ensures that the physical sizes of such are positive finite and known statically the llvm ir has two syntactic global scope and a function does not have nested local in the global scope all named types global variables and functions have different names and are defined mutually in the scope of a function in module mod all the global identifiers in mod the names of arguments locally defined variables and block labels in the function must be unique which enforces the part of the ssa property the set of blocks making up a function constitute a controlflow graph with a welldefined entry point all instructions in the function must satisfy the ssa scoping invariant with respect to the controlflow graph the instruction defining an identifier must all the instructions that use it within a block dominates if appears before in a program order a block labeled l dominates a block labeled l if every execution path from the program entry to l must go through l the formalization provides an implementation of this dominator analysis using a standard dataflow fixpoint computation it also proves that the implementation is correct as stated in the following lemma which is needed to establish preservation of the wellformedness invariants by the operational semantics see section lemma dominator analysis correctness · the entry block of a function dominates itself · given a block b that is an immediate successor of b all the strict dominators of b also b these wellformedness constraints must hold only of blocks that are reachable from a functions entry code may contain illtyped and instructions a memory model for understanding the semantics of memory operations is crucial for reasoning about llvm programs llvm developers make many assumptions about the legal behaviors of such llvm code and they informally use those assumptions to justify the correctness of program transformations there are many properties expected of a reasonable implementation of the llvm memory operations especially in the absence of errors for example we can reasonably assume that the load instruction does not affect which memory addresses are allocated or that different calls to malloc do not reuse mem locations unfortunately the llvm language reference manual does not enumerate all such properties which should hold of any reasonable memory implementation on the other hand details about the particular memory management implementation can be observed in the behavior of llvm programs eg you can print a pointer after it to an integer for this reason and also to address error conditions the llvm specification leaves some behaviors undefined examples include loading from an address loading with alignment loading from properly allocated but uninitialized memory and loading from properly initialized memory but with an incompatible type because of the dependence on a concrete implementation of memory operations which can be platform specific there are many possible memory models for the llvm one of the challenges we encountered in formalizing the llvm was finding a point in the design space that accurately reflects the of the llvm documentation while still providing a useful basis for reasoning about llvm programs in this paper we adopt a memory model that is based on the one implemented for compcert this model allows to accurately implement the llvm ir and in particular detect the kind of errors mentioned above while simultaneously many of the reasonable assumptions that llvm programmers make the nondeterministic operational semantics presented in section takes advantage of this precision to account for much of the although design is intended to capture the llvm specification it is also motivated by building on existing memory model allowed us to reuse a significant amount of their coq infrastructure a benefit of this choice is that our memory model is compatible with memory model ie our memory model implements the compcert memory signature this memory model inherits some features from the compcert implementation it is single in this paper we consider only singlethreaded programs it assumes that pointers are bits wide and byte aligned and it assumes that the memory is infinite unlike compcert model must also deal with arbitrary integers and alignment constraints that are given by layout annotations in the llvm program as described next llvm memory commands the llvm supports several commands for working with data structures · malloc and allocate regions of memory they take a type parameter which determines layout and of the elements of the region and an integral size that specifies the number of elements they return a pointer to the newly allocated region · free the memory region associated with a given pointer which should have been created by malloc memory allocated by is implicitly upon return from the function in which was invoked · load and store respectively read and write llvm values to memory they take type parameters that the expected layout of the data being · into a structured data type by computing an offset pointer from another given pointer based on its type and a list of indices that describe a path into the datatype figure gives a small example program that uses these operations importantly the type annotations on these operations can allocated next block i i i x i valid invalid valid offset mb mb i offset i i valid valid invalid figure memory model this figure shows part of a memory state that might be reached by calling the function foo from figure blocks less than were allocated the next fresh block to allocate is block is deallocated and thus marked invalid to access fresh blocks are also invalid invalid memory blocks are gray and valid memory blocks that are accessible are white block contains data with structure type i x i but it might be read due to physical subtyping at the type i i this type is into two memory cells for the i field two uninitialized cells to alignment and four pointer memory cells for the first element of the array of bit i pointers here that pointer points to the th memory cell of block block contains an uninitialized i integer represented by four cells followed by a pointer that points to the nd memory cell of block be any firstclass type which includes arbitrary integers floating point values pointers and and structures the llvm ir semantics treats memory as though it is dynamically typed the sizes layout and alignment of a value read via a load instruction must be consistent with that of the data that was stored at that address otherwise the result is undefined this approach leads to a memory model structured in two parts a lowlevel representation that stores values of basic types along with enough information to indicate physical size alignment and whether or not the data is a pointer and an encoding that structured data with firstclass types into a sequence of basic values computing appropriate and alignment from the type the next two describe these two parts in turn the representation the representation is composed of blocks of memory cells each cell is a that describes the smallest chunk of contents that a memory operation can access cells come in several memory cells mc byte idx the memory cell byte represents a chunk of numeric data where the of the integer is given by sz and whose contents is byte for example an integer with is represented by four mb cells each with size parameter an integer with that is not by is encoded by the minimal number of bytes that can store the integer ie an integer with is encoded by two bytes each with size parameter see figure floating point values are encoded similarly memory addresses are represented as a block identifier and an offset within that block the cell idx is a chunk of such a pointer where idx is an index identifying which byte the chunk corresponds to because implementation assumes bit pointers four such cells are needed to encode one as shown in figure loading a pointer succeeds only if the bytes loaded are sequentially indexed from to the last kind of cell is which represents uninitialized memory layout and values that result from undefined computations such as might arise from an arithmetic overflow given this definition of memory cells a memory state m n b c includes the following components n is the next fresh block to allocate b maps a valid block identifier to the size of the block c maps a block identifier and an offset within the block to a memory cell if the location is valid initially n is b and c are empty figure gives a concrete example of such a memory state for the program in figure there are four basic operations over this memory state alloc and alloc allocates a fresh memory block n with a given size increments n the newly allocated memory cells with simply removes the deallocated block from b and its contents from c note that the memory model does not block identifiers deallocated by a operation because this model assumes that a memory is of infinite size the operation is responsible for basic values into chunks and updating the appropriate memory locations basic values are integers with their addresses and basic values bv int sz float pad sz basic types fp typ is a partial function that attempts to read a value from a memory location it is annotated by a basic type and ensures compatibility between memory cells at the address it reads from and the given type for example memory cells for an integer with sz cannot be accessed as an integer type with a different a sequence of bytes can be accessed as floating point values if they can be as a floating point value pointers stored in memory can only be accessed by pointer types if an access is type incompatible returns pad sz which is an error value representing an arbitrary bit pattern with the sz of the type being loaded is undefined in the case that the memory address is not part of a valid allocation block the llvm values and memory accesses structured data is to lists of basic values that indicate its physical representation values v bv bv v a constant is into a list of basic values according to it annotated type if the is already of basic type it into the singleton list values of array type sz × typ are first according to the representation given by typ and then by uninitialized values to match alignment requirements as determined by the modules layout descriptor the resulting list is then to obtain the appropriate value the case when a is a structure type is similar the llvm load instruction works by first its type annotation typ into a list of basic types and mapping across the list it then merges the returned basic values into the final llvm value storing an llvm value to memory works by first to a list of basic values and mapping over the result figure relations between different operational semantics each equivalence or inclusion is justified by a proof in this scheme induces a notion of physical subtyping it is permitted to read a structured value at a different type from the one at which it was written so long as the basic types they into agree for data types such as integers implementation is example reading an integer with bit width two from the second byte of a bit wide integer yields undef because the results are in general platform specific because of this physical subtyping casts can be treated as the identity similar ideas arise in other of lowlevel language semantics the llvm malloc and free operations are defined by alloc and in a straightforward manner as the llvm ir does not explicitly distinguish the heap and stack and function calls are the memory model defines the same semantics for stack allocation and heap allocation malloc both of them allocate memory blocks in memory however the operational semantics described next maintains a list of blocks allocated by for each function and it them on return operational semantics provides several related operational semantics for the llvm ir as summarized in figure the most general is a smallstep nondeterministic evaluation relation given by rules of the form s s see figure this section first the need for nondeterminism in understanding the llvm semantics and then illustrates by some of its rules next we introduce several equivalent deterministic refinements of and fn each of which has different uses as described in section all of these operational semantics must handle various error conditions which manifest as in the rules section describes these error conditions and relates them to the static semantics of section operational rules are specified as transitions between machine states s of the form m where m is the memory and is a stack of frames a frame keeps track of the current function and block label l as well as the continuation sequence of commands c to execute next ending with the block the map tracks bindings for the local variables which are not stored in m and the list keeps track of which memory blocks were created by the instruction so that they can be marked as invalid when the function call returns nondeterminism in the llvm operational semantics there are several sources of nondeterminism in the llvm semantics the undef value which stands for an arbitrary and bit pattern of a given type various memory errors such as reading from an uninitialized location unlike the errors which are modeled by stuck states see section we choose to model these behaviors nondeterministically because they correspond to choices that would be resolved by running the program with a concrete memory implementation moreover the llvm optimization passes use the flexibility granted by this to justify optimizations configurations fun tables v id g id v configurations mod g nondeterministic machine states value sets v v v frames l c id v call stacks program states s m s s g val v mod v define typ c b v v g arg param c option id call typ val param call mod g m l c c m l c l c c g val v c option id call typ val param m m ret mod g m l ret typ val l c c m l c id v g val v true v mod l g l l mod g m l br val l l m l c br true g val v v v c id malloc typ val malloc m typ v m mod g m l c c m l c id malloc g val v v v c id typ val malloc m typ v m mod g m l c c m l c id g val v g val v sz v v v mod g m l id int sz val val c m l c id v figure smallstep nondeterministic semantics of the llvm ir selected rules nondeterminism shows up in two ways in the semantics first stack frames bind local variables to sets of values v second the relation itself may relate one state to many possible successors the semantics apart these two kinds of nondeterminism because of the way that the undef value with memory operations as illustrated by the examples below from the llvm language reference manual undefined values indicate to the compiler that the program is well defined no matter what value is used giving the compiler more freedom to optimize semantically treats undef as the set of all values of a given type for some motivating examples consider the following code fragments a z i undef undef b x add i undef z i x x c z or i undef d br undef l l the value computed for z in example a is the set of all bit integers because each occurrence of undef could take on any bit pattern the set of possible results obtained by them still includes all bit integers perhaps surprisingly example b computes the same set of values for z one might reason that no matter which value is chosen for undef the result of x with itself would always be and therefore z should always be however while that answer is compatible with the llvm language reference and hence allowed by the nondeterministic semantics it is also safe to replace code fragment b with z undef the reason is that the llvm ir a substitution principle because x undef would be a replacement for first assignment in b it is allowed to substitute undef for x throughout which reduces the assignment to z to the same code as in a example c shows why the semantics needs arbitrary sets of values here z evaluates to the set of odd bit integers which is the result of with each element of the set this code could therefore not safely be replaced by z undef however it could be optimized to z or any other odd bit integer example d illustrates the interaction between the for local values and the nondeterminism of the relation the control state of the machine holds definite information so when a branch occurs there may be multiple successor states similarly we choose to model memory cells as holding definite values so when writing a set to memory there is one successor state for each possible value that could be written as an example of that interaction consider the following example program which was to the list that reads from an uninitialized memory location buf i val load i buf store i i buf ret val the llvm pass this program to program a below though according to the llvm semantics it would also be admissible to replace this program with option b perhaps to expose yet more optimizations a ret i b ret i undef nondeterministic operational semantics of the ssa form the semantics we have developed for and the others described below is parameterized by a configuration which is a triple of a module containing the code a partial map g that gives the values of global constants and a function pointer table that is a partial map from values to function identifiers see the top of figure the and function pointer maps are initialized from the module definition when the machine is started the rules relate machine states to machine states where a machine state takes the form of a memory m from section and a stack of evaluation frames the frames keep track of the sets of values bound to temporaries and which instructions are currently being evaluated figure shows a selection of evaluation rules from the development most of the commands of the llvm have straightforward interpretation the arithmetic logic and data manipulation instructions are all function computes a set of values from the global state the local state and an llvm val looking up the meanings of variables in the local state as needed similarly implements binary operations computing the result set by combining all possible pairs drawn from its input sets s malloc behaves as described in section while load uses the memory models ability to detect illtyped and uninitialized reads and in the case of such errors yields undef as the result function calls push a new stack frame whose initial local bindings are computed from the function parameters the component of the stack frame keeps track of which blocks of memory are created by the instruction see rule these are when the function returns rule ret there is one other in specifying the operational semantics when compared to a standard callbyvalue language all of the instructions for a block must be executed atomically and with respect to the old local value mapping due to possibility of self loops and dependencies among the nodes for example the wellformed code fragment below has a circular dependency between x and z x i z pred z i x pred b x z br b succ if control enters this block from pred x will map to and z to which causes the conditional branch to succeed back to the label the new values of x and z should be and and not and as might be computed if they were handled sequentially this update of the local state is handled by the function in the operational semantics as shown for example in rule br true preservation and progress throughout the rules the lift notation f x v indicates that a partial function f is defined on x with value v as seen by the uses of lifting both the nondeterministic and deterministic semantics are program may get stuck some of this is related to wellformedness of the ssa program for example g x is undefined if x is not bound in these kinds of errors are out by the static wellformedness constraints imposed by the llvm ir section in other cases we have chosen to use in the operational semantics to model certain failure modes for which the llvm specification says that the behavior of the program is undefined these include to free memory via a pointer not returned from malloc or that has already been deallocated allocating a negative amount of memory calling load or store on a pointer with bad alignment or a deallocated address trying to call a pointer or trying to execute the unreachable command we model these events by stuck states because they correspond to errors that will occur in any reasonable realization of the llvm ir by translation to a target platform each of these errors is precisely characterized by a predicate over the machine state eg s and the allowed stuck states are defined to be the disjunction of these predicates s s s s to see that the wellformedness properties of the static semantics rule out all but these known error configurations we prove the usual preservation and progress theorems for the semantics theorem preservation for if s is well formed and s s then s is well formed here wellformedness includes the static scoping typing properties and ssa invariants from section for the llvm code but also requires that the local mappings present in all frames of the call stack must be binding contains at least one value v and that each defined variable that dominates the current continuation is in s domain to show that the bindings are after the step we prove that values v are undefined values from constants typ undef contain all possible values of first class types typ undefined values from loading uninitialized memory or incompatible physical data contain at least indicating errors evaluation of nondeterministic values by returns nonempty sets of values given nonempty inputs the difficult part of showing that defined variables their uses in the current continuation is proving that maintain the dominance property if a program branches from a block b to b the first command in b can use either the variables from b which must be defined in by lemma or the variables updated by the s at the beginning of b this latter property requires a lemma showing that behaves as expected theorem progress for if the pair s is well formed then either s has terminated successfully or s or there exists s such that s s this theorem holds because in a wellformed machine state always returns a nonempty value set v moreover jump targets and internal functions are always present deterministic refinements although the semantics is useful for reasoning about the validity of llvm program transformations provides a a deterministic smallstep refinement along with two operational semantics and these different deterministic semantics are useful for several reasons they provide the basis for testing llvm programs with a concrete implementation of memory see the discussion about extracted interpreter in the next section proving that is an instance of the and relating the smallstep rules to the ones provides validation of all of the semantics ie we found bugs in by formalizing multiple semantics and trying to prove that they are related and the small and semantics have different applications when reasoning about llvm program transformations unlike the frames for these semantics map identifiers to single values not sets and the operational rules call deterministic variants of the nondeterministic counterparts eg eval instead of to resolve the nondeterminism from undef and memory operations these semantics fix a concrete interpretation as follows · undef is treated as a · reading uninitialized memory returns these choices yield behaviors compared to what one might expect from running a llvm program against a runtime system but the cases where this semantics differs correspond to unsafe programs there are still many programs namely those compiled to llvm from typesafe languages whose behaviors under this semantics should agree with their on target platforms despite these differences from also has the preservation and progress properties bigstep semantics also provides bigstep operational semantics which evaluates a function call as one large step and which evaluates each the code between two function one large step bigstep se are useful because compiler optimizations often transform multiple instructions or blocks within a function in one pass such transformations do not preserve the smallstep semantics making it hard to create simulations that establish correctness properties as a simple application of the semantics consider trying to prove the correctness of a transformation that program statements that do not depend on one another for example the following two programs result in the same states if we consider their execution as one bigstep although their intermediate states do not match in terms of the smallstep semantics a x add i a b b y load i p y load i p x add i a b the proof of this claim in uses the b rules to hide the details about the intermediate states to handle memory effects we use a simulation relation that uses symbolic evaluation to define the equivalence of two memory states the memory contents are defined abstractly in terms of the program operations by recording the sequence of writes using this technique we defined a simple translation validator to check whether the semantics of two programs are equivalent with respect to such reorderings execution for each pair of functions the validator ensures that their controlflow graphs match and that all corresponding are equivalent in terms of their symbolic evaluation this approach is similar to the translation validation used in prior work for verifying instruction scheduling optimizations although this is a simple application of semantics proving correctness of other program transformations such as dead expression elimination and constant propagation follow a similar difference is that rather than checking that two memories are syntactically equivalent according to the symbolic evaluation we must check them with respect to a more semantic notion of equivalence relationships among the semantics figure illustrates how these various operational semantics relate to one another provides proofs that simulates fn and that simulates in these proofs simulation is taken to mean that the machine states are syntactically identical at cor points during evaluation for example the state at a function call of a program running on the fn semantics matches the corresponding state at the function call reached in note that in the deterministic setting simulation implies bisimulation moreover is a refinement instance of the nondeterministic semantics these relations are useful because the semantics induce different proof than the smallstep semantics in particular the induction principles obtained from the large step semantics allow one to over details of the small step semantics infrastructure and validation this section briefly describes the coq implementation of and its related tools for interacting with the llvm infrastructure it also describes how we validate the semantics by extracting an executable interpreter and comparing its behavior to the llvm reference interpreter the coq development encodes the abstract syntax from section in an entirely straightforward way using inductive datatypes generated in a preprocessing step via the tool the implementation uses metatheory library which was originally designed for the locally representation to represent identifiers of the llvm and to reason about their freshness the coq representation from the full llvm language in only a few mostly minor ways in particular the coq representation requires that some type annotations be in normal form eg the type annotation on load must be a pointer which simplifies type checking at the ir level the tool that llvm into coq provides such normalization which simply expands definitions to reach the normal form in total the syntax and static semantics constitute about lines of coq definitions and proof scripts memory model implementation extends with approximately lines of code to support integers with arbitrary precision and an experimental treatment of casts that has not yet been needed for any of our proofs on top of this extended memory model all of the operational semantics and their metatheory have been proved in coq in total the development represents approximately lines of coq code checking the entire implementation using takes about on a intel core i processor with gb ram we expect that this could be significantly reduced in size by the proof structure and making it more modular the llvm distribution includes primitive ocaml bindings that are sufficient to generate llvm ir code in llvm from ocaml to convert between the llvm representation and the extracted ocaml representation we implemented a library consisting of about lines of bindings this library also supports of the this code was also useful in the extracted the interpreter omitted details this paper does not discuss all of the llvm ir features that the coq development supports most of these features are technically but necessary to support real llvm code the llvm ir provides aggregate data operations and for and updating the elements of structures and arrays the operational semantics supports external function calls by assuming that their behavior is specified by axioms the implementation applies these axioms to transition program states upon calling external functions the llvm switch instruction which is used to compile jump tables is to the normal branch instructions that supports by a preprocessing step features some features of llvm are not supported by first the llvm provides functions for extend ing llvm or to represent functions that have well known names and semantics and are required to follow certain example functions from standard c libraries handling variable argument functions etc second the llvm functions global variables and parameters can be with attributes that denote type calling conventions data representation etc which provide more information to compiler transformations than what the llvm type system provides does not statically check the wellformedness of these attributes though they should be by any valid program transformation third does not support the invoke and instructions which are used to implement exception handling nor does it support variable argument functions does not support vector types which allow for multiple primitive data values to be computed in parallel using a single instruction extracting an interpreter to test operational semantics for the llvm ir we used code extraction facilities to obtain an interpreter for executing the llvm distributions test suite extracting such an interpreter is one of the main for developing a deterministic semantics because the evaluation under the nondeterministic semantics cannot be directly compared against actual runs of llvm ir programs unfortunately the smallstep deterministic semantics is defined in the logical fragment of coq which is convenient for proofs but can not be used to extract code therefore provides yet another operational semantics which is a deterministic functional interpreter implemented in the computational fragment of coq is proved to be bisimilar to so we can port results between the two semantics although one could run this extracted interpreter directly doing so is not efficient first integers with arbitrary are inductively defined in coq this yields easy proof principles but does not give an efficient runtime representation floating point operations are defined to these problems at extraction we realize integer and floating point values by efficient c libraries that are a standard part of the llvm distribution second the memory model implementation of maintains memory blocks and their associated metadata as functional lists and it converts between and value representations at each memory access using the extracted datastructures directly performance overhead so we replaced the memory operations of the memory model with native implementations from the c standard library a value v in local mappings is boxed and it is represented by a reference to memory that stores its content our implementation runs out of the tests from the llvm suite that the llvm distribution interpreter can run the missing tests cover instructions like variable arguments that are not yet implemented in although replacing the coq datastructures by native ones the absolute correctness guarantees one would expect from an extracted interpreter this exercise is still valuable in the course of carrying out this experiment we found one bug in the semantics the br instruction the true and false branches verified is a previously proposed program transformation that c programs against spatial memory safety violations eg buffer array indexing errors and pointer arithmetic errors works by first compiling c programs into the llvm ir and then the program with instructions that propagate and check metadata maintains base and bound metadata with each pointer loads and stores of pointer with parallel loads and stores of their associated metadata this instrumentation ensures that each pointer is within bounds and aborts the program otherwise the original paper includes a mechanized proof that the correctness of this idea but it is not complete in particular the proof is based on a subset of a language with only commands and types while a real implementation needs to consider all of the llvm ir shown in figure the memory model and the operational semantics of the llvm also the original proof ensures the correctness only with respect to a specification that the instrumentation must implement but does not prove the correctness of the instrumentation pass itself moreover the specification requires that every temporary must contain metadata not just pointer temporaries using to verify this section describes how we use to formally verify the correctness of the instrumentation pass with respect to the llvm semantics that the spatial memory safety property is achieved moreover allows us to extract a verified ocaml implementation of the transformation from coq the end result is a compiler pass that is formally verified to transform a program in the llvm ir into a program augmented with sufficient checking code such that it will dynamically detect and prevent all spatial memory safety violations is a good test case for the framework it is a nontrivial translation pass that nevertheless only inserts code thereby making it easier to prove correct intended use is to prevent security so bugs in its implementation can potentially have consequences also the existing implementation already uses the llvm modifications to since the original paper as described in the original paper modifies function signatures to pass metadata associated with the pointer parameters or returned pointers to improve the of the tool we to an implementation that instead passes all pointer metadata on a stack this has two primary advantages the first is that this design simplifies the implementation while simultaneously better supporting indirect function calls via function pointers and more handling declared function the second is that it also simplifies the proofs formalizing for the llvm ir the correctness proof has the following highlevel structure we define a nonstandard operational semantics for the llvm ir this semantics builds in the safety properties that should be enforced by a correct implementation of it uses metalevel datastructures to implement the metadata and metalevel functions to define the semantics of the bounds checks we prove that an llvm program p when run on the semantics has no spatial safety violations we define a translation pass that the llvm code to propagate metadata we prove that a program if p then p when run on the simulates p running on the specification figure gives the program configurations and representative rules for the semantics behaves the same as the standard semantics except that it creates propagates and checks metadata of pointers in the appropriate instructions nondeterministic rules metadata md v v memory metadata mm s md frames l c µ call stacks local metadata µ id md program states s m mm mod g g val v v v c id malloc typ val malloc m typ v m µ typ × v m mm l c c µ m mm l c id µ sb malloc g val v v v c id load µ val md v md load m typ v v if typ then µ mm v else µ µ mod g m mm l c c µ m mm l c id v µ sb load g val v v v g val v v v c store typ val val µ val md v md store m typ v v m if typ then mm mm v md else mm mm mod g m mm l c c µ m mm l c µ sb store deterministic configurations frames l c µ call stacks program states s m mm figure the specification semantics for differences from the rules are a program state s is an extension of the standard program state s for maintaining metadata md which is a pair defining the start and end address for a pointers µ in each function frame maps temporaries of pointer type to their metadata mm is the heap that stores metadata for pointers in memory note that although the specification is nondeterministic the metadata is deterministic therefore a pointer loaded from uninitialized memory space can be undef but it cannot have arbitrary md which might not be valid is correct if a program p must either abort on detecting a spatial memory violation with respect to the or preserve the llvm semantics of the original program p and moreover p is not stuck by any spatial memory violation in the ie must catch all spatial violations definition spatial safety accessing a memory location at the offset of a block is safe if is less than the next fresh block n and is within the bounds of n size size the legal stuck states of s include all legal stuck states of recall section except the states that violate spatial safety the case when b does not map to some size indicates that is not valid and pointers into the are indicates a temporal safety error that is not by and therefore it is included in the set of legal stuck states because the program states of a program in the semantics are identical to the corresponding parts in the it is easy to relate them let s s mean that common parts of the state s and s are identical because memory instructions in the may abort without accessing memory the first part of correctness is by a straightforward simulation relation between states of the two semantics theorem simulates if the state s s and s s then there exists a state s such that s s and s s the second part of the correctness is proved by the following preservation and progress theorems theorem preservation for if s is well formed and s is well formed s s then here wellformedness the invariants for by requiring that if any id defined in is of pointer type then µ contains its metadata and a spatial safety invariant all bounds in of function frames and mm must be memory ranges within which all memory addresses are safe the interesting part is proving that the spatial safety invariant is preserved it holds initially because a programs initial frame stack is empty and we assume that mm is also empty the other cases depend on the rules in figure the rule sb malloc which allocates the number v of elements with typ at a memory block updates the metadata of id with the start address that is the beginning of and the end address that is at the offset typ × v in the same block memory model ensures that the range of memory is valid the rule sb load reads from a pointer val with runtime data v finds the md of the pointer and ensures that v is within the md via if the val is an identifier simply returns the identifiers metadata from µ which must be a spatial safe memory range if val is a constant of pointer type returns bounds as the following for global pointers returns bounds derived from their types because must be allocated before a program starts for pointers converted from some constant integers by it conservatively returns the bounds null null to indicate a potentially invalid memory range for a pointer derived from an other constant pointer by or returns the same bound of for note that v denotes conversion from a deterministic value to a nondeterministic value if the load reads a value v from memory the rule finds its metadata in mm and updates the local metadata mapping µ if mm does not contain any metadata indexed by mm m m mi allocated memory simulation p b e v p b e v where vi vi p b e v p b e v frame simulation figure simulation relations of the pass v that means the pointer being loaded was not stored with valid bounds so returns null null to ensure the spatial safety invariant similarly the rule sb store checks whether the address to be stored to is in bounds and if storing a pointer updates mm accordingly dereferencing a pointer that was converted from an even if that integer was originally obtained from a valid pointer following the same design choice returns null null for pointers cast from integers fails when a program accesses such pointers theorem progress for if s is wellformed then either s is a final state or s is a legal stuck state or there exists a s such that s s this theorem holds because all the bounds in a wellformed state give memory ranges that are safe if succeeds the memory access must be safe the correctness of the instrumentation given we designed an instrumentation pass in coq for each function of an original program the pass implements µ by generating two fresh temporaries for every temporary of pointer type to record its bounds for manipulating metadata stored in mm the pass a set of interfaces that a disjoint metadata space with specifications for their behaviors figure shows the simulation relations between an original program p in the semantics of and its transformed program p in the llvm semantics first because p needs additional memory space to store metadata we need a mapping mi that maps each allocated memory block in m to a memory block in m without overlap but allows m to have additional blocks for metadata as shown in dashed boxes note that we assume the two programs initialize second basic values are related in terms of the mapping between blocks pointers are related if they refer to corresponding memory locations other basic values are related if they are same two values are related if they are of the same length and the corresponding basic values are related using the value simulations defines a simulation for memory and stack frames given two related memory locations and their contents in m and m must be related if mm maps to the bound v v then the additional metadata space in m must store v and v that relate to v and v for the location for each pair of corresponding frames in the two stacks and must store related values for the same temporary if µ maps a temporary id to the bound v v then must store the related bound in the fresh temporaries for the id theorem given a state s of p with configuration and a state s of p with configuration if s s and s s then there exists a state s such that s s s s runtime overhead extracted c figure execution time overhead of the extracted and the c version of here s s is a deterministic that as in section is an instance of the nondeterministic the correctness of theorem is correct let p denote that the pass a wellformed program p to be p a instrumented program p either aborts on detecting spatial memory violations or preserves the llvm semantics of the original program p p is not stuck by any spatial memory violation extracted verified of the above formalism not only shows that the transformation enforces the safety properties but the framework allows us to extract a translator directly from the coq code resulting in a verified implementation of the transformation the extracted implementation uses the same underlying implementation and wrapped external functions as the transformation written in c the only aspect not handled by the extracted transformation is the metadata for pointers in the global segment that are nonnull initialized ie they point to another variable in the global segment without initialization valid programs can be rejected as erroneous thus we reuse the code from the c implementation of the to properly initialize these variables effectiveness to measure the effectiveness of the extracted implementation of versus the c implementation we tested both implementations on the same programs to test whether the implementations detect spatial memory safety violations we used test cases from the test suite of cc codes we chose the test cases which the buffer on both the heap and stack both implementations of correctly detected all the buffer without any false violations we also that both implementations properly detected the buffer overflow in the go spec benchmark finally the extracted implementation is robust enough to successfully transform and execute without false violations several applications selected from the spec spec and spec around k lines of c code in total performance overheads unlike the c implementation of that removes some obviously redundant checks the extracted implementation of performs no optimizations in both cases the same suite of standard llvm optimizations are applied to optimize the code to reduce the overhead of the instrumentation to determine the performance impact on the resulting program figure reports the execution time overheads lower is better of extracted leftmost bar of each benchmark and the c imple rightmost bar of each benchmark for various benchmarks from spec spec and spec because of the check elimination optimization performed by the c implementation the code is slightly faster but overall the extracted implementation provides similar performance bugs found in the original implementation in the course of formalizing the transformation we discovered two implementation bugs in the original c implementation of first when one of the incoming values of a node with pointer type is an undef undef was propagated as its base and bound subsequent compiler transformations may instantiate the undefined base and bound with defined values that allow the to succeed which would lead to memory violation second the base and bound of constant pointer typ null was set to be typ null and typ null typ allowing dereferences of null or pointers pointing to an offset from null either of these bugs could have in checking and thus expose the program to the spatial violations that was designed to prevent these bugs the importance of a formally verified and extracted implementation to avoid such bugs related work mechanized language semantics there is a large literature on formalizing language semantics and reasoning about the correctness of language implementations examples include foundational proof carrying code foundational typed assembly language standard ml and a substantial subset of java verified compilers compiler verification has a considerable history see the for a overview other research has also used coq for compiler verification tasks including much recent work on compiling functional source languages to assembly is closer in spirit to compcert which was the first compiler to generate compact and efficient assembly code for a large fragment of the c language compcert also uses coq it formalizes the operational semantics of compcert c several intermediate languages used in the compilation and assembly languages including arm and x the version of compcert also provides an executable reference interpreter for the semantics of compcert c based on the formalized semantics the compcert project fully proves that all compiler phases produce programs that preserve the semantics of the original program optimization passes include local value numbering constant propagation coalescing graph coloring register allocation and other transformations compcert has also certified some advanced compiler optimizations ­ using translation validation the project extends the compcert compiler by a generic translation validator based on smt solvers other efforts the verified software project that the proofs at the top of the hold in the machine language program typed assembly languages provide a platform for proving optimizations similarly the project also attempts to prove the correct functionality of systems in engineering and security technology guarantees control flow integrity for application code running on embedded processors the rhodium project uses a domain specific language to express optimizations via local rewrite rules and provides a soundness checker for optimizations llvm optimizations the project a methodology that existing program analysis techniques to the setting of translation validation and reports on a prototype tool that applies their methodology to verification of the llvm compiler the project llvm optimizations by symbolic evaluation the tool performs translation validation for the llvm compiler using a technique called equality saturation these applications are not fully certified conclusion although we do not consider it in this paper our intention is that the framework will serve as a first step toward a llvm compiler similar to that of leroy et als compcert our coq development extends some of libraries and our llvm memory model is based on memory model the focus of this paper is the llvm ir semantics itself the formalization of which is a necessary step toward a llvm compiler because much of the complexity of an compiler lies in the ir to ir transformation passes formalizing correctness properties at this level stands to yield a significant as demonstrated by our case study even without fully verifying a compiler acknowledgments this research was in part by the us the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the policies either expressed or implied of the us this research was in part by contract hr and n this material is based upon work supported by the national science foundation under grant no and any and conclusions or expressed in this material are those of the authors and do not necessarily reflect the views of the national science foundation references e and m a formal functional verification of device drivers in proceedings of the nd international conference on verified software theories tools experiments a w appel foundational proofcarrying code in lics proceedings of the th annual ieee symposium on logic in computer science a w appel verified software in esop proceedings of the th european conference on programming languages and systems b a b c pierce r and s weirich engineering formal metatheory in popl proceedings of the th annual acm sigplansigact symposium on principles of programming languages n benton and n compiling functional types to relational specifications for low level imperative code in proceedings of the th international workshop on types in language design and implementation s b and a w appel formal verification of coalescing register allocation in esop proceedings of the th european conference on programming languages and systems j chen d wu a w appel and h a provably sound tal for optimization in pldi proceedings of the acm sigplan conference on programming language design and implementation a a verified compiler for an impure functional language in popl proceedings of the th annual acm sigplansigact symposium on principles of programming languages a a certified typepreserving compiler from lambda calculus to assembly language in pldi proceedings of the acm sigplan conference on programming language design and implementation the coq proof assistant reference manual version pl the coq development team k crary toward a foundational typed assembly language in popl proceedings of the th acm sigplansigact symposium on principles of programming languages k crary and r harper mechanized of standard ml alpha release def r j ferrante b k rosen m n wegman and f k zadeck efficiently computing static single assignment form and the control dependence graph acm trans program lang syst ­ g a a unified approach to global program optimization in popl proceedings of the st annual acm symposium on principles of programming languages g t and t u a model for a language virtual machine and compiler acm trans program lang syst ­ c and v llvm a compilation framework for program analysis transformation in proceedings of the international symposium on code generation and optimization and runtime optimization s t e rice and c chambers automated soundness proofs for dataflow analyses and transformations via local rules in popl proceedings of the th acm sigplansigact symposium on principles of programming languages x leroy a formally verified compiler journal of automated reasoning ­ the llvm reference manual version the llvm development team v s n b r a t ar and l a ssa program representation for compiler optimization in popl proceedings of the th acm sigplansigact symposium on principles of programming languages s j m m k martin and s highly compatible and complete spatial memory safety for c in pldi proceedings of the acm sigplan conference on programming language design and implementation g c necula translation validation for an optimizing compiler in pldi proceedings of the acm sigplan conference on programming language design and implementation test suite for cc m and d automatic transformation of c code to support multiple equivalent data layouts in cc proceedings of the th international conference on compiler construction m d and c chambers a theory of lowlevel software in popl proceedings of the th annual acm sigplansigact symposium on principles of programming languages a pnueli m and e translation validation in tacas proceedings of the th international conference on tools and algorithms for construction and analysis of systems p sewell f s g t s sarkar and r effective tool support for the working in icfp proceedings of the th acm sigplan international conference on functional programming m r and s translation validator for llvm in cav proceedings of the rd international conference on computer aided verification z t and s proving optimizations correct using parameterized program equivalence in pldi proceedings of the acm sigplan conference on programming language design and implementation d reasoning with the formal definition of standard ml in hol in international workshop on higher order logic theorem proving and its applications z and s to verified compilers in pldi proceedings of the acm sigplan conference on programming language design and implementation and x leroy formal verification of translation a case study on instruction scheduling optimizations in popl proceedings of the th annual acm sigplansigact symposium on principles of programming languages and x leroy verified validation of lazy code motion in pldi proceedings of the acm sigplan conference on programming language design and implementation j b and x leroy a simple verified validator for software pipelining in popl proceedings of the th annual acm sigplansigact symposium on principles of programming languages p and g morrisett evaluating translation validation for llvm in pldi proceedings of the acm sigplan conference on programming language design and implementation a and a pnueli program analysis for compiler validation in proceedings of the th acm workshop on program analysis for software tools and engineering l g li b de and j fully verified software fault isolation in proceedings of the th acm international conference on embedded software 