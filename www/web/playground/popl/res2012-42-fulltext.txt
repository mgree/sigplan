and compiling cc concurrency from c to power mark scott sarkar university of cambridge inria peter sewell abstract the c and c revised standards add concurrency to the languages for the first time in the form of a subtle relaxed memory model the c model this aims to permit compiler optimisation and to accommodate the behaviours of combining simple semantics for most code with lowlevel atomics for concurrency libraries in this paper we first establish two simpler but provably equivalent models for c one for the full language and another for the subset without consume operations further to the fragment without lowlevel atomics we identify a arising from atomic and prove that under an additional condition the model is equivalent to sequential consistency for programs we then prove our main result the correctness of two proposed compilation schemes for the c load and store concurrency primitives to power assembly having noted that an earlier proposal was the main ideas apply also to arm which has a similar relaxed memory architecture this should the development of production compilers for c and cx what properties of the machine architecture are required and builds in the c and power semantics categories and subject descriptors c multiple data stream architectures parallel processors d concurrent programming parallel programming f specifying and verifying and reasoning about programs general terms languages reliability standardization theory verification keywords relaxed memory models semantics introduction most work on semantics and reasoning for concurrency has assumed a sequentially consistent sc memory lam in which a single shared memory is upon by interleaved threads in practice however x power arm provide weaker and more permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ pa usa copyright c acm subtle relaxed memory models to permit various hardware optimisations concurrent programming languages eg java c c also provide relaxed memory models although of rather different kinds both to permit compiler optimisations and so that they can be compiled to those processors without use of hardware memory barriers moreover for several of those and languages the actual memory model provided has long been specified and not well understood in recent years that situation has improved of particular here the c standards has introduced a memory model as outlined by boehm and ba into their revised standard c and it is expected that the of the c standard informally cx will adopt essentially the same model this standard is written in subject to the usual problems of ambiguity and not directly but in previous work we produced a formal semantics for c concurrency in discussion with members of the concurrency we identified various issues with earlier solutions that are now incorporated into the new c standard the result has a close correspondence between the formal semantics and the standard the c memory model is an axiomatic one a operational semantics that defines candidate executions consisting of the sets of memory read and write events for threads in isolation it defines when such a candidate is consistent and whether it has a race of some kind consistency is defined in terms of a happensbefore relation it is a model ah for a program that has no race in any consistent execution the semantics is the set of all such while other programs are undefined and implementations are unconstrained the design is stratified there is a with sequentially consistent atomic operations which is intended to have simple semantics for common use then additional and relaxed atomic operations less hardware synchronisation to implement for use in concurrency libraries and system code and finally atomics for maximum performance on architectures such as power and arm where dependencies provide useful ordering guarantees the whole is relatively complex for example to accommodate atomics it involves a happensbefore relation that is by design not necessarily transitive the first contribution of this paper is to simplify the c model proving that it is equivalent to a simpler model m without the technical concept of visible sequences of side effects the language to remove atomics gives a further simplification m with a transitive happensbefore relation still further to the fragment without lowlevel atomics one would like to know that that model is equivalent to a sequentially consistent model m in section we show that this holds for programs that are in m but that the m and m notions of race can differ with an example involving atomic we give additional conditions under which the two do coincide on the hardware side sarkar et al ssa have established a rigorous memory model for power based on extensive testing and discussion with ibm power has a more relaxed and more subtle model than tso or but it and arm are similar in this respect and preliminary testing and discussion with arm suggests that the same model with minor differences applies there is also quite relaxed but rather different this model is of a very different kind to that for c it deals with the power dependencies and barriers sync rather than the c atomic primitives it gives semantics to all programs not just programs and the presence of speculative execution is observable to the programmer on these machines accordingly this model is in an style rather than an axiomatic style it defines labelled transition systems for a thread semantics with explicit and for a storage subsystem abstracting from the cache hierarchy with interactions between the two between programming language and processor how can one compile a programming language with the c memory model to power or arm there are three main parts to this question one has to consider how each c atomic operation is compiled to assembly code perhaps with barriers andor preserved dependencies when conventional compiler optimisations are legal in this setting and what new optimisations are needed eg to remove redundant barriers in the setting all of these are sufficiently that it is hard to have any in correctness without proof we focus here on the first a naive compilation scheme would be to insert the power sync barrier between every c memory access even here it is not at all obvious that this would be a correct implementation indeed on inserting the mf barrier between every access is not sufficient to sc and for a realistic implementation with good performance it is essential not to introduce unnecessary synchronisation and have proposed a mapping of the core c atomic primitives to power assembly ms for the different of nonatomic and atomic loads and stores this is c operation nonatomic load load relaxed load consume load acquire load seq nonatomic store store relaxed store release store seq power implementation ld ld ld and preserve dependency ld bc sync ld bc st st st sync st this some c operations to normal power loads and stores some with a power lightweight synchronisation barrier or sync and in some cases uses just a combination of an artificial control dependency of a compare and conditional branch bc and an our second contribution is to prove the above mapping correct while the mapping involves only a few assembly instructions its correctness involves much of the behavioural of the c and power relaxed memory models and is far from obvious indeed the mapping above has been updated in the light of our comments following sarkar et al ssa an earlier proposal included an optimisation that we observed is not sound wrt the power we give two counterexamples here our proof relies on the simplified general c model m from the first part along the way we obtain results about the power architecture of independent interest eg showing that and why inserting a sync between all accesses does restore sc we also prove soundness of an alternative mapping with the sc atomics implemented as below the sync convention suggested in the arm context with in place of sync and by boehm c operation power implementation load seq ld sync store seq st sync depending on the relative of sc loads and store and on the costs of the different hardware barriers which may vary significantly from one architecture to another and also between implementations this may have better performance note that for code produced by different compilers to correctly they must all make the same choice of mapping which should be part of the we also show that both these mapping are local weakening any of the clauses eg replacing a sync by a yields an unsound scheme in the first contribution we covered the full c primitives as in but for these correctness results we focus just on the load and store operations in the tables above dynamic thread creation c and locks the first two are minor simplifications but the last two are substantial questions for future work as their power implementations involve the instructions for which we do not yet have a semantics to make this paper as as possible we give a brief introduction to our source and target starting points the c and power ssa models in sections and respectively section describes our simplifications of c and section the atomic issue section discusses the correctness of the above compilation schemes informally looking at specific examples and section discusses our correctness statement and proof that they are correct in general we discuss related work and conclude in sections and we focus throughout on the key ideas as it is not possible to include full details here the model definitions alone for c and power are around and pages of mathematics but our definitions and proofs are available online our definitions are expressed in lem a lightweight language of type function and relation definitions from which one can generate prover definitions in hol and in progress coq and executable ocaml code our proofs are a combination of interactive hol proof and rigorous hand proof with auxiliary definitions and lemma statements in lem this is a domain in which proved results are of direct interest to software development which typically relies almost entirely on testing for the nondeterminism of relaxed memory makes effective random testing challenging and the fact that the programming language and processor architecture specifications are than current implementations makes it even in principle compiler groups are now implementing c concurrency and we are in discussion with members of the red gcc and arm groups on how this should be done correctly based in part on the work we present here eg one implementation was found to put the sc store sync on the wrong side of the store background c concurrency this section gives a general introduction to the c concurrency primitives and their semantics we refer the reader to ba for a full discussion of many subtle points that we cannot cover here the language c concurrency primitives c is a language with explicit thread creation and implicit sharing any location might be read or written by any thread for which it is reachable from variables in scope it is the programmers to ensure that such accesses are for example in the following program the thread executing thread writes x while the main thread reads x without any synchronisation between the two these are nonatomic reads and writes and this a data race the fact that the program an include thread using void p p int main int x containing a race thread x makes the program un int r x defined according to the standard an return tation has freedom to behave arbitrarily in particular compilers can perform optimisations that are not sound for programs which means that common threadlocal optimisations can still be done without the compiler to determine which accesses might be shared the language provides several mechanisms for concurrent pro gramming without races first accesses to shared state can be pro using mutex locks of various kinds eg using and we then have various sequentially consistent atomic operations on objects of integral type bytes integer types etc atomic loads stores and various opera tions atomic operations do not race with each other by definition so changing the above to use sc atomic operations for x gives a welldefined program and the allowed behaviours are intended to be those one would expect in an sc semantics the tion is that locks and sc atomics will suffice for most program however making all accesses sequentially consistent is not always required and can a significant performance cost so c also provides several lowlevel atomic operations with different memory order parameters for use eg in concur libraries and other systems code for id in which one thread writes some perhaps data x and then a flag y while another to see that flag write before reading the data it suffices to make the flag write a release and the flag read an acquire atomic int x y sender thread t x receiver thread t while int r x the synchronisation between the release and acquire ensures that the write of x will be seen by the receiver ie that the read of x must be from the write x rather than from some value on with weak memory orders notably power and arm pairs are to implement than sc atomics but still significantly more expensive than plain stores and loads cf the preceding for the release and following bc for the acquire in section we return later to how these act however these architectures do guarantee that certain dependencies in an assembly program are and in many cases those suffice on the reader side this a variant of atomics for example suppose one thread writes some data again perhaps then writes the address of that data to a shared atomic pointer while the other thread reads the shared pointer dereferences it and reads the data int x p sender thread x receiver thread int xp int r xp here the combination of the pair and the dependency at the receiver from the read of p to the read of x suffices to ensure the intended behaviour finally in some cases one needs only very weak guarantees and here atomics can be used the language also includes explicit in acquire release and sc forms to ease of code semantics the c axiomatic memory model traditional operational semantics involves an explicit memory with interleaved transitions by threads reading and writing that memory that is sc and for a language such as c a quite different semantic style is needed we say a candidate execution ex of a c program a set of memory actions together with various relations over them the actions are of the form action xv xv xv xv al x au x nonatomic read nonatomic write atomic read atomic write atomic lock unlock here a is a unique id including a thread id x a location and v a value memory orders mo range over those mentioned earlier abbreviated thus sc rel con and ar the relations include four binary relations determined by a operational semantics sb additional with data dependency dd and control dependency cd together with three that determine an between memory actions of different threads rf relates a write to all the reads that read from it the sequential consistent order sc is a total order over all sc actions and modification order mo is the union of a total order over writes to each atomic location given a candidate execution the semantics defines various derived relations a variant of used in the semantics sw happensbefore hb and these are used to define when a candidate execution is consistent and whether it contains a race of some kind a data race race or read which we collect into a predicate race ex a data race is a pair of accesses to the same address at least one of which is a nonatomic write which are not happensbefore related the consistent reads from mapping check has as on the right below consistent execution consistent reads from mapping well formed threads consistent non atomic read values consistent locks consistent atomic read values consistent inter thread hb coherent memory use consistent sc order atomicity consistent modification order sc reads restricted well formed reads from mapping sc consistent reads from mapping for a program c prog for which all its consistent executions are with respect to all three kinds of race which we write as c prog the semantics is the set of all those con executions other programs are undefined for example the program above is and one of its consistent executions is shown below the ini write y to give some of the seman tics we describe why this execution is indeed consistent refer ring the reader to for the detailed definitions the well formed threads and well formed reads from mapping are straightforward conditions for this simple ex the and happensbefore relation hb coincide and are just the transitive closure of the union of sb and the sw edge created by the pair b c the con inter thread happens before predicate checks that this is acyclic the consistent locks and con sc order checks are as x there are no lock or sc atomic operations in this example the modification order mo is empty as there is only one y rf write to the atomic location so consistent modification order is for y consistent reads from mapping the main is x non atomic read values which checks that the nonatomic read of x takes the value of a visible side effect which in a program is unique and is the most re cent write in happensbefore then consistent atomic read values permits the atomic read of y to read from any element of a visible sequence of side effects which is a set of writes of y ordered by modification order by a visible side effect and terminated before any write that the read the coherent memory use does not contribute because the happens before condition already enforces coherence here the remaining three atomicity sc reads restricted sc are as there are no operations or sc atomics simplifying the c model in this section we establish two simplifications of the c model of the standard tries to give an intuitive definition of which values an atomic read might take using visible sequences of side effects as et al note taken alone they are too weak and additional coherence axioms now incorporated into the c standard are necessary to capture the intended semantics given those we can prove that the concept of visible sequences of side effects is unnecessary a much simpler definition of consistent atomic read values in a model m consistent atomic read values b actions is read b is at atomic location lk b if a a b then a b rf ¬ b a hb else ¬ a b rf theorem a c candidate execution is consistent in c iff it is consistent in m and the races are identical proof the happensbefore relations coincide in hol this has already been useful in automatic analysis as it removes the only use of an existentially quantified set of sets of actions in the semantics our second simplified model m removes the complications introduced by atomic consume operations included only for programmers on power and arm for the subset of the language without them the original c model and m have a complex definition of happensbefore from the standard let r sw sw sb in r sb r hb sb if we subset the language to remove atomic consume operations we can give an equivalent model m with a much simpler hb sb sw theorem a c candidate execution without consume operations is consistent in m iff it is consistent in m and the races are identical proof the two hb relations coincide hol atomic and sc semantics further to remove and relaxed operations leaving just and sc atomics one would like to prove a result along the lines of boehm and ba showing that for such programs the m semantics and hence m and standard c and an semantics are equivalent our third simplified model m has the obvious sc notion of consistent execution with a total order over all operations and requiring reads to read the most recent writes in that for defining data races it uses the same style of definition as c using a happensbefore relation but that from the total order to prove the result we would need to show that a program is in m iff it is in m and for any program the sets of consistent executions are the same unfortunately this is not true in general given a program which is in m we can show that it is in m and that it has the same consistent executions in both theorem c prog c prog ex c prog ex consistent ex ex consistent ex ex here we write c prog ex to mean that candidate execution ex is by the operational semantics for c program c prog this is an easy corollary of the following lemma lemma consistent ex ex consistent ex ex race ex consistent ex ex consistent ex ex race ex consistent ex ex c prog ex consistent ex ex ex consistent ex ex race ex c prog ex proof the first two are straightforward for the third we can identify a minimal race in the m total order and transfer that to a consistent execution in m however the other direction fails as the program below shows in the sc m semantics it is but in m it has a consistent execution that has races the example relies on the fact that in c there can be nonatomic writes to atomic locations the of atomic locations are nonatomic so that they can be implemented without x y if if in the sc m semantics both loads must read and so neither of the nonatomic atomic init writes can take place the program has no races and so has defined behaviour but in m there is a consistent execution in which both loads read this execution has races and so in m the programs behaviour is undefined this execution also has dynamic the program might also be considered undefined in m for that reason this issue can be eliminated by requiring atomics to be when constructed removing atomic init and requiring that atomics are accessed via a path through and corresponding to dataflow from their creation ie not by pointers under these additional restrictions we have proved the desired equivalence of m and m and hence that for this fragment c has semantics theorem a c candidate execution that uses only nonatomic operations operations and locks and that satisfies the conditions above is consistent in c iff it is consistent in m and the races are identical correctness of the mapping informally we now instantiate the first mapping of § for some key examples giving an introduction to the behaviour that power does and does not guarantee for them and hence informally why the mapping is correct in these specific cases we also show that both mappings are locally optimal in c synchronisation effects are associated to atomic loads and stores with particular memory order parameters but power assembly language has just plain loads and stores it provides the sync and instructions together with certain dependencies to constrain the otherwise highly relaxed memory model we introduce these constraints and the model by example here the key properties we depend on are in § applying the § mapping to the c example of § gives a power assembly program as follows y t t r rx ry rx ry a rr write x loop b from d rr read y c rr write y e r f loop g from h rr read x here is a store a load a and a conditional branch this is essentially the same as the example of ssa it has an between the two thread writes and an before the second thread read that follows a conditional branch that is via the compare on the first thread read we call the latter a relationship for this to be a correct implementation that power synchronisation must be strong enough to any outcomes that the c semantics in particular it must prevent the thread read of x from reading the initial state instead of from the thread write of x the and are both necessary and sufficient the keeps the two thread writes in or der as observed by any other thread otherwise as they are to different locations they might be in the storage hierarchy or even committed replacing the by an would still permit the former reordering as is observable on power and processors and just by typing it cannot be replaced by a as one cannot have a dependency from a write the relationship ensures that the read of x cannot be satisfied until the is committed which requires the branch to be committed which requires the read of y to be committed without the the power architecture permits a processor to satisfy the read of x before satisfying the reads of y despite the conditional branch it can thereby read from the initial state and this is observable in practice for a test that test is also it is essentially the result of applying the mapping to the example with the replaced by a the alone without the control dependency from the preceding read to a conditional branch also would not suffice in this case the could be committed first enabling read h to be satisfied and committed before anything else occurs we have not observed this outcome in practice on current power or power processors for test but it is permitted for the analogous arm test the outcome is observable now consider the example of § mapped to p t t r rx rp rp a rr write x d rr b from e rr c rr write px read p read xp the writing side has an as before but now the reading side has no it is correct nonetheless because the power architecture respects address dependencies between loads here the read e reads from an address in register r which takes its value from the read d in such a case the reads must be satisfied and indeed also committed in program order the above examples involve only two threads which turns out to be a very special case with three or more threads one can observe that on power a write does not necessarily become visible to the other threads atomically and indeed can be propagated to them in different orders or even never propagated to some threads any transitive reasoning across multiple threads relies on the of the power sync and barriers consider a version of the example with synchronisation between the first pair of threads and between the second pair int x y z t x t while t while r x the mapping introduces from the and from the as in the candidate power execution illustrated below thread thread thread a wx b wy c ry e rz rf rf d wz rf f rx here the effect of the thread is subsumed by the following eliminating the former is likely to be an important compiler optimisation that leaves the thread which acts just as in the first example and the two to rule out the execution shown we need to know that the writes a and d by different threads and to different locations are propagated to thread in that order by the threadlocal property of used above the thread ensures that a and b are propagated to thread in that order so a must have been propagated to thread before c reads from b and hence before the thread is committed this means that a is in the group a of that the set of writes that have been propagated to its thread already in turn the of power means that a must be propagated to any other thread eg thread before the is and hence before write d is now consider the classic example independent reads of independent writes here threads and write to two different locations the question is whether threads and can see those writes in opposite orders one reading x then y while the other reads y then x x y t t t t with atomics this is permitted in c this is clearly not a sequentially consistent outcome and so atomics do not guarantee sc and indeed applying the mapping gives essentially the power test which is permitted and observable in practice with sc atomics on the other hand this outcome is forbidden in c to it in the implementation requires a power sync between both pairs of reads not just an the sync is stronger in that its group a writes or some including any writes must be propagated to all threads before the sync completes and subsequent memory access instructions can begin a sync is also needed between the other three combinations of an sc atomic read or write as shown by our and r examples ssa for and and by the example below for the case all of which are permitted is also observable on current implementations whereas we have not observed the last two both of the latter can be explained by the fact that a power coherence edge does not add writes into the group a of a subsequent barrier is similar to r but with the initial write back along an rf edge they are counterexamples to the correctness of a previous version of the mapping which proposed an in place of the sync for sc stores in normal memory thread thread thread a wx b rx rf co d wy sync c wy rf test allowed e rx the first § mapping creates these by putting a sync before the load or store of an sc atomic one could equally well put them after as in the second mapping though in c sc atomics also have semantics so one then also needs a preceding for the sc atomic store in the first mapping the preceding sync does for both purposes using the above examples and some others we can show theorem both the § mappings are pointwise locally optimal proof for each possible weakening there is a c example with some forbidden behaviour which would map onto a power program for which that behaviour is allowed as checked by our and ssa tools using automatically generated executable versions of the models all these examples are collected in the material · the dependency cannot be removed c with power · the cannot be to just a control dependency or to just an · the sync whether before or after the load cannot be to an or to an · the in the original mapping cannot be to just control or to just · the cannot be to · the sync whether before or after the store cannot be to r or to an background the power memory model in preparation for the correctness proof in the next section we recall the overall structure of the power memory model ssa how the concepts we used informally in § eg of a write being propagated to a thread reflect the actual semantics as we saw there the fact that reads can be satisfied even a conditional branch is observable this pushes us towards an operational semantics expressed as a parallel composition of a thread model and a storage subsystem thread write request read request barrier request read response barrier thread storage subsystem at any one time a thread may have many instructions reads can be satisfied and instructions committed subject to constraints from barriers and dependencies and instructions are subject to or abort the storage subsystem abstracts from the cache and store hierarchy and does not involve it does not have an explicit memory but instead maintains the global constraints on the coherence order between writes to the same address that have been built up together with a list for each thread of the writes and barriers that have been propagated to that thread the thread and storage subsystem models are each labelled transition systems on labels as in the diagram above their composition gives another lts with labels label fetch tid ii commit write instruction tid ii w commit barrier instruction tid ii barrier commit read instruction tid ii rr commit reg or branch instruction tid ii write propagate to thread w tid barrier propagate to thread barrier tid satisfy read from storage subsystem tid ii w satisfy read by write forwarding tid ii w ii sync barrier partial coherence commit w w register read prev tid ii reg ii register read initial tid ii reg partial evaluate tid ii here tid ranges over thread ids ii over instruction instances w over write events rr over events barrier over sync or events and reg over power register names a power execution t is simply a trace of states and these labels we write machine executions power prog for the set of all such for a power program power prog power programs of type power program are essentially maps from addresses to assembly instructions together with the initial register state including pc for each thread key properties required for the proofs of § are derived from the preconditions and postconditions of the transitions as an example before a barrier sync or is propagated to a new thread by the barrier propagate to thread transition any writes propagated before it to its original thread the group a writes must first be propagated to that thread by a write propagate to thread transition for a sync the corresponding sync transition cannot until that sync is propagated to all threads and this implies that all its group a writes or coherence successors must have been propagated to all threads before that in the trace the combination of a conditional branch and an instruction stops reads being able to do their satisfy read transitions before the branch is resolved and committed to particular events of interest we let the following metavariables range over transition labels from a trace as follows metavariable wc rc bc mc memory xc transition labels ranged over commit write instruction commit read instruction commit barrier instruction commit write instruction commit read instruction commit write instruction commit barrier instruction correct compilation from c to power we now prove that the mappings of section are correct in general focusing on the first mapping and then discussing the changes required for the second correctness statement the usual form of correctness statement one might expect for a compiler is an inclusion between the observable behaviours of the compiled program and those of the source c prog c semantics c execution observations compilation power prog power semantics power execution observations here however we are proving correctness of compilation schemes for particular constructs the c atomic and nonatomic loads and stores not correctness of a specific compiler we therefore want to factor out as much as possible of the definition of the source language and of the rest of the compiler both to remove complexity that is irrelevant to the behaviour and to let us state a general result that should be in multiple later compiler correctness proofs we do so by the required properties of a c operational semantics and a good compiler for the source language we take a c program of type c program to be a parallel composition of singlethreaded programs from an abstract type c program thread with an arbitrary operational semantics for them that satisfies certain rather axioms an operational semantics is a relation between c programs and sets of c actions equipped with the three relevant relations of § ddc and into a record is empty in the absence of dynamic thread creation recall that this operational semantics should leave the values of memory reads unconstrained as that is handled by the c axiomatic memory model of § we return below to the axioms we need we take a strong intensional notion of observation given a power machine trace t we build read and write events from the commit read instruction and commit write instruction commit labels together with a relation the observation predicate obs eq t requires that there is an exact correspondence between these and the of a c execution with isomorphic relations and given a power trace t it is also straightforward to construct of the c relations over the constructed events for program order dependency and control dependency by the trace we can also identify the events from the same thread that are separated by sync or instructions in the trace constructing relations and a compiler comp is a function from c program to power program it satisfies good compiler if for any c program c prog and any power trace of comp c prog there is a set of c with associated ddc and relations such that the c data has the same observations as the trace obs eq t the c data is allowed by the c prog the c relations ddc and are subsets of the corresponding relations and built from the trace note that the c relation may not be total within a thread as evaluation order is sometimes unconstrained but the power program order is total within a thread and if one applies the mapping to the c actions the result is included in the and relations constructed from the power trace for example a c action x can be to arise from a source program instruction order release and so a good compiler following the mapping should have compiled it into a power preceding a store and any trace should contain a corresponding commit barrier instruction label followed perhaps not immediately by a commit write instruction finally we express correctness on a basis and can assume that the source program is otherwise c it as undefined and compilation is unconstrained that leads us to the following statement of our main theorem theorem correctness comp c prog good compiler comp c prog let power prog comp c prog in executions power prog scc obs eq t c prog consistent ex scc our proof follows this structure consider a power trace t of a power program power prog produced by a compiler from a c program c prog the good compiler assumption tells us that there are some corresponding up to obs eq c and for which the memory actions of each thread satisfy the operational semantics we now construct a c modification order and sequential consistent order scc and then have to either prove that the c execution all this data is consistent or to construct another consistent execution which contains a race thereby the assumption the construction of a c modification order is straightforward as like ddc and there is a direct analogue in the power trace the coherence constraints in the storage subsystem state increase along a trace so we can just take their union choose an arbitrary and restrict to the atomic locations construction of a c sc order scc is more involved as we see below in § note that in contrast to many compiler correctness proofs this is not a simulation argument the c definition of consistent execution is a predicate on complete candidate executions it is not generated by an operational semantics and does not involve any notions of a c state or transition analysis of a power trace wrt c the c definition of consistent execution conditions as listed in § almost all of which rely on the happensbefore relation which is the union of and a complex relation to establish those conditions we need to the power trace with the shape of the relation in mind making use of various ordering properties of the power semantics and the fact that the power program is obtained using the given mapping in broad terms if there is a c relation from a write to a read we need to show that the write has propagated to the reading thread before the read is satisfied for pairs we need to show that any write propagated to the thread of the first read before it is satisfied has propagated similarly for and pairs we need to ensure propagation before the commit of the final write in more detail we must also allow coherence successors of writes to be propagated in their place must consider propagation of barriers must refer to the last satisfy label of any read that reads from a different thread and must split the cases to capture all this we define a relation over memory and barrier commit labels for labels from different threads we say · bc rc iff the barrier has propagated to the reading thread before the read is finally satisfied ie if there is a barrier propagate label for bc the last satisfy read for rc · wc rc iff the write or some write has propagated to the reading thread before the read is finally satisfied and · wc wc iff the write of wc or some write has propagated to the thread of wc before the wc commit for labels from the same thread we say · xc rc iff xc is either a write commit label and is read by rc or it is rc is finally satisfied and · xc wc iff xc is wc consider now the c definition of happensbefore hb without relaxed or consume operations it only threads with a edge of a pair that with each other under the mapping this edge must be by or and followed by a with relaxed atomics the acquire might read from something in the release sequence of the release it with in power terms a release sequence is a series of edges if we covered operations these would not necessarily be on the same thread adding consume atomics synchronisation involves the relation which is similar to except that on the right hand side it only reaches to dependent operations not to all successors of the read in power terms in this case the is replaced by all this the definition of a machine analogue of refl refl where is the machine coherence order restricted to pairs of writes by the same thread and is the machine relation restricted to pairs on distinct threads lemma given two c memory actions m and m and the corresponding power commit events mc and mc if m m then mc mc proof by a series of lemmas about the c auxiliary relations unfolding the definitions with reasoning as above to prove the required propagation property corollary below we first consider the left part of this relation lemma propagation if wc rc then wc rc if rc rc then for any write commit wc rc we have wc rc proof by induction on the transitive closure of the relation in the base case by the large relation two intermediate write commit events appear wc and wc in the case where mc wc if mc is a write then it into the group a of the barrier if it is a read then any write propagated to its thread before it is satisfied into the group a of the barrier the relation is a subset of hence we also have mc wc hence using the property of the power machine and since we know that wc does propagate to the thread of rc before rc is last satisfied because it is read from the writes in the group a of the barrier or some coherence successors must have previously been propagated to that thread this establishes the desired relationship in the other case mc wc we just saw that wc does propagate to the thread of rc in time and it is here a of mc for the inductive case we use the same reasoning as for the first step to establish that the writes under consideration are first propagated to the thread of the intermediate read and then the induction hypothesis corollary propagation wrt if rc mc then for any write commit wc with wc rc we have wc mc if wc mc then wc mc proof and are subsets of po so without loss of generality we can all those edges except the last one wc rc mc lemma establishes propagation to the thread of rc then using either the or if mc is a read then it is satisfied after rc is committed and if mc is a write then it is committed after rc is committed several of the c conditions are properties either explicitly so eg the consistency of or requiring consistency between relations eg rf c and to establish these it is convenient to reduce them to the of trace order by the following lemma lemma trace order respects if mc mc then mc is before mc in the trace proof along the same lines as the reasoning above by induction on the transitive closure of analysis of a power trace to construct a c sc order c demands a single total order sc over all the sc atomic actions subject to some consistency conditions this order must be consistent with the relation with modification order and for each sc read rc if it reads from a sc write wc then wc must be the last sc write to that location before rc in the sc order while if it reads from a write wc then wc cannot be after in happensbefore any sc write to the same location which is itself after rc in the sc order in power terms the first two conditions are straightforward to express we need to construct a total order on sc actions which includes the of and and respectively that are restricted to sc actions however there is no obvious corresponding total order visible in the trace in particular recall from § that for write commit labels trace order is not necessarily consistent with the coherence order it is also not sufficient to use an arbitrary of though and are acyclic since that may introduce bad writes to the same location in between a pair of a write and a read that it consider then an sc read rc and the write wc not necessarily sc that it and recall that we have a coherence order for writes to that location we define two new derived relations on sc reads and writes defined as rc wc if wc wc ie rc a coherence predecessor of the sc wc and defined as wc rc if wc is the last sc write in coherence order equal to or before the wc that reads from relations have been used by various researchers alg and the latter reference proves that if the union of coherence and is acyclic then the execution is an sc execution by the traditional definition lam of a single global order over all events we use this in theorem below we will use as the sc order an arbitrary of we now show that this combination of relations is acyclic and hence can be consistently extended to a total order first note that if the above relation has a cycle there must be at least one mc mc edge in the cycle as otherwise it is straightforward to deduce that the coherence relation implied by the machine trace is itself cyclic under the mapping this means that mc and mc must be separated in the trace by a sync and its sync transition our main lemma for this lemma below says that for any mc with mc mc it must be in before that sync transition call this the s transition and this contradicts mc being after that transition we will prove lemma by induction on the length of the relation case the relation in the first step we have to the inductive hypothesis in two ways to make the proof go through for example consider the case where the first step is a rc wc edge we know inductively that wc is before s in the trace but this does not immediately help us know that the read rc is also before s what we need is the strong property of the sync recall § that before the for a sync in the trace preceding writes are not merely committed but also they or some coherence successors are propagated to all threads this suffices since if wc is propagated to the reading thread and it is not the read must already have been done for the second strengthening consider the case where the first step is a wc rc edge one kind of an edge is a edge as above we will have to inductively establish that the write wc have been propagated to all threads before the sync s the power machine guarantees this for any sync on the same thread as rc but not necessarily for on other threads to make the induction work we will find a new intermediate sync sn which is on the same thread as an event related to rc in the part of the relation since this involves only and edges these will be on the same location and wc will then be correctly related by coherence to a write that is known to be propagated everywhere before sn in the trace the final statement is then lemma main lemma for sc suppose mc mc and there is a sync s between mc and mc in the trace suppose mc then there is an and a sync sn such that is before sn in the trace and sn is before or equal to s in the trace if is a write then that write or a coherence successor has propagated to all threads before sn in the trace is before sn in the trace and sn are from the same thread and the of the relation be and is free proof by induction on the length of the chain mc in the base case mc and the required conditions are easily established by taking and sn s in the inductive case we case on the kind of relation in the first step for and we use the same intermediate event and sync as the inductive hypothesis making and sn sn then for example if the edge is wc wc we have inductively that wc is propagated to all threads as required before sn and thus a coherence successor of wc is as well we outlined the rc wc and wc rc cases in the description above in the remaining case we have two sc events separated in program order by the mapping there must be a sync between them in program order let sn be the transition for that sync and then the required conditions are easy to check notice in the proof that we use the sync between any two sc actions from the same thread this is crucial for the induction to go through indeed as shown in § for any pair of sc actions if we weaken the sync to anything else or weaker we have a counterexample to show a program with only sc actions in a consistent manner the proof is applicable in a setting than just for c the key fact we used to create the sc order is that every pair of sc actions on the same thread is separated in program order by a sync looking at the proof for the case that every memory access is a sc atomic action ie no other memory types or nonatomic accesses shows that such a program has only sequentially consistent behaviour an interesting fact in its own right about power assembly programs theorem between every pair of accesses restore sc suppose we have a power assembly program with every pair of memory accesses on the same thread separated in program order by a sync then the program has only sequential consistent behaviour proof given the premises the proof of lemma shows that is acyclic then by alg § the execution is verification of consistent execution we now have the tools to verify the satisfaction of all the conjuncts of the consistent execution predicate as listed in § and simplified by theorem of § the two well formed conjuncts hold by the obs eq and assumptions on eg that the relation only relates actions of the same thread the consistent locks conjunct is in the we consider in this section for the others we use the between c actions and relations and power trace events and relations we established in § and in § mostly using corollary and lemma first consistent inter thread happens before states the of using lemma we prove by contradiction that such a cycle implies a cycle in the trace order next we have four coherence conditions for pairs of a read and a write and which are part of consistent modification order and coherent memory use itself part of consistent reads from mapping these diagrams involve and edges relating two writes and some reads all at the same atomic location they require the writes to be correctly ordered in for example lemma given c actions w r and w all to the same location and an and edge as below the w w edge exists w r w proof to establish this we first show that the power write wc corresponding to w is propagated to the thread of the power write wc corresponding to w before wc is committed in more detail for the edge the inclusion from § gives us a power wc rc relation between the corresponding commit events from the trace for the edge by the definition of c happensbefore either case there is an edge in which case we use the inclusion from § to show rc wc and they are on the same thread or case an relationship in which case there is an rc wc edge we know because of the power rules involved in a relation and with a case split on whether wc and rc are on the same thread or not that wc propagates to the thread of rc before rc is finally satisfied hence wc is propagated to the thread of wc before the latter is committed either in case because the semantics of the commit transition guarantees that is by the trace order for events at a same location and using transitivity or in case by corollary finally by the semantics for commit write instruction when a write is committed it automatically becomes all the writes that have already been propagated to its thread so wc wc and by the construction of that gives w w the other three coherence properties are similar more complex two additionally use the fact that a power read can only be satisfied from the last write to the relevant address that has been propagated to its thread the consistent sc order predicate checks that sc is a strict total order over the sc actions the totality is by construction strictness is by it also requires that and restricted to sc atomics are included in scc the first is immediate from the construction of from subsets of the relations involved in the construction of scc the second makes use of a lemma stating the inclusion in of the relation from which we build the when restricted to pairs of writes at a same location and the construction of the consistent modification order predicate consists of dealt with above a totality condition that is immediate from the construction of as a and a check that it only relates writes at atomic locations which is also by construction now we have the of consistent reads from mapping two atomicity and sc are for the we consider we dealt with the coherence conditions of coherent memory use above the predicate sc reads restricted forces any sc read to read from the last write wc at the same location or some write that is not wc the proof is by constructing a for each forbidden situation which contradicts the results of § an interesting observation here is that through the application of the result of § we make use for the first time of the barriers placed by the mapping before the compilation of sc reads and in fact we do not rely anywhere else on these barriers as they play no part in the propagation property stated by lemma finally we get to the constraints on read values the consistent non atomic read values predicate says that a read r at a nonatomic location must read from a visible sideeffect ie a write w that happensbefore r such that there is no write w that w and r assuming the contrary there are three possible situations r reads from a write that it r reads from an write there exists a w that w and r or r reads from an write cases and are but in the same style as the reasoning for and showing that writes propagate appropriately case is quite different here we have a power read rc that reads from a write wc for which neither w r nor r w hold intuitively this is a race but this is not a consistent execution r cannot read from w in c unless w r in the next section we show that in this case the original program has some other candidate execution that is consistent and that has a race a data race or read the toplevel assumption that the program was a similar situation arises for the last consistent atomic read values formally we case split at the top level on the following rf in hb predicate capturing additional assumptions that ensure consistency rf in hb w r w r r is a nonatomic read w r w r r is an atomic read w is write w same location w w w r if rf in hb holds case is and consistent non atomic read values and consistent atomic read values can be established directly construction of a consistent execution in the situation where the rf in hb predicate of the previous section does not hold our strategy is to find a prefix of the trace for which rf in hb holds and build a consistent execution for it by applying the reasoning of section to that prefix add an or read to the consistent execution return any missing predecessor actions to the consistent execution extend the consistent execution until it is a complete execution of the original program for step we find the first read commit rc on the trace that causes a violation of rf in hb and build a consistent execution for part of the trace that precedes it our ability to use section for this relies on the fact that the commit labels on the trace respect and which are in turn consistent with ddc and steps ­ rely on the following axiom about the c operational semantics which we believe any reasonable operational semantics should satisfy c prog a new a c prog a new a all values a is read a a is downward closed under ddc new new let b a ¬ a ddc b in new aa new new a x y x y x new y new a c prog new a new new it states that if the operational semantics can perform a read at a certain point it can instead perform any read that is of the same kind and from the same location but that reads a potentially different value this reflects the fact that the operational semantics relies on the memory model to determine how memory reads are satisfied furthermore later actions that do not depend on the read via ddc are by the change of value read this reflects the fact that the operational semantics is required to correctly calculate the notions of control and data dependence we now return to the construction of the execution for step if there is a visible side effect w of r recall that r is the read that violated hb in rf we create a new read r according to the axiom and have r read from w this r then races with the write w that r read from originally if there is no visible side effect we have r read from nothing and the execution has an read we prove that this new execution is consistent by showing that the happens before relation is unchanged except for switching r to r step is necessary because the power can execute reads out of program order and so the prefix chosen in step might be missing actions that the c operational semantics requires in other words the trace ordering is not necessarily consistent with and hence the trace prefix might not be downward closed in the addition of such a missing read r in step follows the same reasoning as in step with the added observation that r cannot be atomic sequentially consistent or acquire because the power cannot past the dependency that would follow such a read the addition of missing writes is straightforward step is straightforward because there are no constraints on how the execution extended to completion it already contains the race and further application of axiom will not it this completes the proof of theorem alternate mapping as mentioned in § a modified mapping has been proposed that has a sync barrier as the last instruction in the mapping for all sc actions this keeps a sync barrier between any pair of sc actions from the same thread which ensures the results of § hold the rest of the proof with sc actions through the sc order so it can be carried over unchanged one additional is that sc stores are also release stores and sc loads in c are also acquire loads the first fact requires the before the store for sc stores as for release stores the second requires loads to be from being satisfied before the sc load is the sync suffices here related work the most closely related work is our correctness proof of a compilation scheme from c to x that covered in addition to loads and stores but was nonetheless simple as x has a strong semantics for section boehm and gave a definition ba of a memory model based on an earlier c working paper in the same style as the eventual draft standard and but in many details and with the semantics for lowlevel atomics only sketched they give a hand proof that in that model programs without lowlevel atomics have sc semantics some previous work proves correctness of compilers for concurrent languages rather than compilation schemes for particular primitives in a context s et al prove correctness of a compiler from a concurrent language with tso semantics to the x tso model building on singlethreaded compcert here the source and target share the same relatively simple memory model and the correctness proof is taking advantage of the fact that has a simple operational proves correctness of compilation from a of multithreaded java to a jvm loc but this assumes sc and does no optimisation s s ev proves the correctness or otherwise for various optimisations for languages though not specifically for c et al consider the correctness of transformations in relaxed models vafeiadis and verify elimination optimisations in the context of the compiler there is an extensive line of work inserting to restore sc starting with and ss et al do this in practice for sync on power machines but they appear to implicitly assume that writes are atomic discussing only threadlocal reordering which they are not on more recent power implementations et al alg am consider power insertion with respect to an axiomatic memory model the cav model that model was a to the model of sarkar et al ssa that we use in this paper as described there the cav model is stronger than the for the r test in this sense it is unsound wrt the architecture although not observed to be unsound wrt current implementations and it is weaker than the architecture and current implementations for cases such as the latter might be generated by the mapping for a c example so this model is too weak to prove the mapping correct produced a guide to implementing the java memory model on various written when the power was less clear considerably before ssa its suggested uses of are not correct wrt the architecture it also focuses on the synchronisation required between pairs of operations on the same thread without discussing the power properties that are essential for c and sc atomics conclusion we have proved the correctness of a realistic compilation scheme from the programming language memory model proposed for the c and c standards to a realistic memory model for power the c model was designed with implementation above the power and arm model in mind among others and this establishes that it is in fact implementable with what appears to be a reasonable mapping using hardware synchronisation mechanisms with the c semantics required moreover our development explains why the mapping is correct and also what properties of the power are actually required increasing understanding and in both models and providing a good basis for compiler developers compiling c and cx to power and arm we are discussing this with gcc and arm compiler groups there are many interesting directions for future work first the development should be extended to cover other c features and locks operations require first a semantics for the power instructions and one would also like to cover and dynamic thread creation second while a full compiler correctness proof for c or even c is still a long way off we would like to instantiate our proof to a concrete operational semantics and compiler for a small fragment third the proof suggests the construction of a more abstract axiomatic power model based on the derived properties we use in the proof we can see there exactly which machine trace events are relevant eg the last satisfy label for each committed read and certain write propagation events the more abstract model could deal just with those this would give a simpler foundation for developing analysis and reasoning techniques for power and arm concurrent software acknowledgements we thank boehm paul s and for discussions on this work and from grants and references a john and the power of processor consistency in proc ah s v and m d hill weak ordering a new definition in proc alg j a shared memory phd thesis paris and inria am j and l stability in weak memory models in proc cav j l s sarkar and p sewell in weak memory models in proc cav ba boehm and sv foundations of the c concurrency memory model in proc pldi p editor programming languages c a but recent version is available at m k s s sarkar and p sewell s m and v verifying local transformations on relaxed memory models in cc boehm atomic synchronization sequences list communication july th m s s sarkar p sewell and t c concurrency the model technical report n august m s s sarkar p sewell and t c concurrency in proc popl j c t m s and s sarkar c concurrency in proc x j lee and s p automatic insertion for shared memory in proc lam l lamport how to make a multiprocessor computer that correctly executes programs ieee trans comput d the for compiler writers http x leroy a formally verified compiler journal of automated reasoning ­ loc a verifying a compiler for java threads in proc esop ms p e and r example power implementation for cc memory model http s p f and p sewell lem a lightweight tool for semantics in proc lncs section s ev j s safe optimisations for concurrent programs in proc pldi ss d and m efficient and correct execution of parallel programs that share memory toplas ­ ssa s sarkar p sewell j l and d understanding power in pldi p sewell s sarkar s f and m o a rigorous and usable programmers model for x c acm ­ j s v vafeiadis f s and p sewell concurrency and verified compilation in proc popl v vafeiadis and f verifying elimination optimisations in proc sas 