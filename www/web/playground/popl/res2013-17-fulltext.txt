metatheory a la benjamin university of texas at austin c d s national university of abstract formalizing metatheory or proofs about programming languages in a proof assistant has many wellknown benefits unfortunately the considerable effort involved in proofs has it from standard practice this cost can be by as much of existing mechanized as possible when building a new language or extending an existing one one important challenge in achieving reuse is that the inductive definitions and proofs used in these are closed to extension this forces language designers to cut and existing definitions and proofs in an adhoc manner and to considerable effort to up the results the key contribution of this paper is the development of an induction technique for extensible church encodings using a novel of the universal property of folds these encodings provide the foundation for a framework formalized in coq which uses type classes to the composition of proofs from modular components this framework enables a more structured approach to the reuse of metatheory through the composition of modular inductive definitions and proofs several interesting language features including binders and general recursion illustrate the capabilities of our framework we reuse these features to build fully mechanized definitions and proofs for a number of languages including a version of miniml bounded induction enables proofs of properties for semantic functions and type classes enable proof adaptation for more languages categories and subject descriptors d programming languages formal definitions and keywords modular mechanized metatheory extensible church encodings coq introduction with their challenge et al identified representation of binders complex and reuse of components as key challenges in programming language metatheory while progress has been made for example on the representation of binders it is still difficult to reuse components including language definitions and proofs the current approach to reuse still involves copying an existing formalization and it manually to incorporate new permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm tures an extreme case of this approach can be found in three verified compiler project which consists of intermediate languages in addition to the source and target languages many of which are minor variations of each other due to the impact of new features the adaptation of existing features is moreover from a management perspective a of copies is obviously a typical present two important challenges to providing reuse conventional inductive definitions and proofs are closed to extension and cannot simply be imported and extended with new constructors and cases this is a of the wellknown expression problem ep modular reasoning reasoning with modular definitions requires reasoning about partial definitions and composing partial proofs to build a complete proof however conventional induction principles which are the fundamental reasoning techniques in most theorem provers only work for complete definitions the lack of reuse in is somewhat surprising because proof such as coq and agda have powerful modularity constructs including modules type classes and expressive forms of dependent types it is reasonable to whether these language constructs can help to achieve better reuse after all there has been a lot of progress in addressing issues in generalpurpose languages using advanced type system features ­ although not a lot of attention has been to modular reasoning this paper presents a framework for defining and reasoning about extensible inductive datatypes the framework is implemented as a coq library which enables modular mechanized metatheory by allowing language features to be defined as components using language developers can existing efforts to build new languages by developing new and interesting features and combining them with previously written components the solution to in was inspired by the popular data types a la technique however relies on a typelevel fixpoint definition for building modular data types which cannot be encoded in coq solves this problem by using extensible church encodings of data types these encodings allow modular data types to be defined in the restricted coq setting another difference between and is the use of folds and algebras instead of conventional folds to express modular definitions the advantage of folds and algebras is that they offer explicit control over the evaluation order which is important when modeling semantics of programming languages similar techniques to solve problems in proofs and inductively defined predicates solution to modular reasoning uses a novel of the universal property of folds because relies on folds the proof methods used in the initial algebra semantics of data types offer an alternative to structural induction with some care universal properties can be exploited to adapt these techniques to modular church encodings in addition to enabling modular reasoning about extensible inductive datatypes universal properties also overcome some theoretical issues related to church encodings in the calculus of inductive constructions also supports higherorder language features such as binders and general recursion binders are modeled with a parametric hoas representation a firstorder representation would be possible too because these features require general recursion they cannot be defined inductively using folds to support these features uses a variation of mixins mixins are closely related to folds but they allow uses of general recursion and can be modeled on top of church encodings using a bounded fixpoint combinator to illustrate the utility of we present a case study several orthogonal features of a variant of miniml the case study illustrates how various features and partial type soundness proofs can be developed and verified and later composed to complete languages and proofs contributions the main contribution of our work is a novel approach to defining and reasoning about extensible inductive datatypes is a coq framework for building components that implements this approach to modular mechanized metatheory more technically this paper makes the following contributions · techniques for the paper provides a solution to the ep and an approach to extensible of metatheory in the restricted typetheoretic setting of coq this solution offers precise control over the evaluation order by means of folds and algebras mixins are used to capture higherorder features like binders and general recursion · reasoning for church encodings the paper the universal property of folds to recover induction principles for church encodings this allows us to avoid the axioms used in earlier approaches and preserves strong normalization · modular reasoning the paper presents modular reasoning techniques for modular components it the induction principle from individual inductive features to compositions while induction over a bounded step count enables modular reasoning about higherorder features modeled with mixins is implemented in the coq proof assistant and the code is available at our implementation the users burden for adding new features by the with type classes and default tactics moreover the framework already provides modular components for miniml as a starting point for new language we also provide a haskell implementation of the computational subset of code used in this paper code and notational conventions while all the code underlying this paper has been developed in coq the paper a syntax for its code fragments for the computational parts this syntax exactly coincides with haskell syntax while it is an of haskell syntax for concepts the coq code requires the option extensible semantics in this section shows approach to extensible and modular semantic components in the restrictive setting of coq the approach is inspired by the solution to the expression problem in haskell in particular its composition mechanisms for extensible inductive definitions differs from in two important ways it uses church encodings to avoid the termination issues of generally recursive definitions secondly it uses folds instead of conventional folds to provide explicit control over evaluation order data types a la this subsection the core ideas of represents the shape of a particular data type as a functor that functor uses its type parameter a for inductive occurrences of the data type leaving the data type definition open is an example functor for a simple arithmetic expression language with literals and addition data a lit nat add a a the explicitly recursive definition fix f the open recursion of a functor f data fix f in f fix f applying fix to builds the data type for arithmetic expressions type fix functions over fix f are expressed as folds of f algebras type algebra f a f a a fold functor f algebra f a fix f a fold alg in fa alg fmap fold alg fa for example the evaluation algebra of is defined as data value i int b bool eval algebra value eval lit n i n eval add i v i v i v v note that the recursive occurrences in eval are of the same type as the result type value in essence folds process the recursive occurrences so that algebras only need to specify how to combine the values for example v and v resulting from evaluating the subterms finally the overall evaluation function is · fix value · fold eval add lit lit unfortunately two uses of general recursion are not permitted in coq coq does not accept the typelevel fixpoint combinator fix f because it is not strictly positive coq similarly the fold function because it is not structurally recursive church encodings encodes data types and folds with church encodings which are church encodings represent least fixpoints and folds as follows type fix f f a a fold algebra f a fix f a fold alg fa fa alg boolean values are not needed yet but they are used later in this section both definitions are nonrecursive and can be encoded in coq although we need to enable for certain definitions since church encodings represent data types as folds the definition of fold is trivial it applies the fix f data type to the algebra example church encodings of s literals and addition are given by the lit and add functions lit nat fix lit n alg alg lit n add fix fix fix add e e alg alg add fold alg e fold alg e the evaluation algebra and evaluation function are defined as in and expressions are evaluated in much the same way lack of control over evaluation folds are structurally recursive and therefore capture compositionality of definitions a desirable property of semantics a of the standard fold encoding is that it does not provide the of the algebra with explicit control of evaluation the fold encoding reduces all subterms the only freedom in the algebra is whether or not to use the result example modeling if expressions as a simple example that illustrates the issue of lack of control over evaluation consider modeling if expressions and their corresponding semantics the bigstep semantics of if expressions is e true e v if e e e v e false e v if e e e v using our framework of church encodings we could create a modular feature for boolean expressions such as if expressions and boolean literals as follows data a if a a a bool boolean functor eval logic algebra value eval logic if v v v if v b true then v else v eval logic b b b however an important difference with the bigstep semantics above is that eval logic cannot control where evaluation happens all it has in hand are the values v v and v that result from evaluation while this difference is not important for simple features like arithmetic expressions it does matter for if expressions semantics the development of implementations accordingly we believe that it is important that a semantic specification does not rely on a particular evaluation strategy such as laziness this definition of eval logic might be reasonable in a lazy metalanguage like haskell which is the language used by but it is when used as a basis for an implementation in a strict language like ml in a strict language eval logic is clearly not a desirable definition because it evaluates both branches of the if expression aside from the obvious performance this is the wrong thing to do if the object language features for example nontermination furthermore this approach can be quite in more complex object languages using folds and laziness can lead to subtle semantic issues church encodings to express semantics in a way that allows explicit control over evaluation and does not rely on the evaluation semantics of the metalanguage church encodings to use algebras and folds which make recursive calls explicit type f a r r a f r a a algebra differs from a traditional f algebra in that it takes an additional argument r a which corresponds to recursive calls to ensure that recursive calls can only be applied structurally the arguments that appear at recursive positions have a polymorphic type r the use of this polymorphic type r prevents case analysis or any other type of inspection on those arguments using f a folds and church encodings are defined as follows type fix m f f a a fold m f a fix m f a fold m alg fa fa alg folds allow algebras to state their recursive calls explicitly as an example the definition of the evaluation of if expressions in terms of a algebra is eval logic value eval logic · b b b eval logic · if e e e if e b true then e else e note that this definition allows explicit control over the evaluation order just like the bigstep semantics definition furthermore like the eval logic enforces compositionality because all the algebra can do to e e or e is to apply the recursive call · a compositional framework for algebras provides a convenient framework for composing conventional fold algebras provides a similar framework but for algebras instead of f algebras in order to write modular proofs its definitions with a number of laws modular functors individual features can be defined using functors like and functors are composed with the operator data f g a inl f a inr g a fix m represents a data type isomorphic to data exp lit nat add exp exp if exp exp exp bool modular algebras a type class is defined for every semantic function for example the evaluation function has the following class class eval f where f value in this class represents the evaluation algebra of a feature f algebras for composite functor are built from feature algebras instance eval f eval g eval f g where · inl · · inr · overall evaluation can then be defined as eval eval f fix m f value eval fold m in order to avoid the repeated of defining a new type class for every semantic function and corresponding instance for defines a single generic coq type class that is indexed by the name of the semantic function this class definition can be found in figure and subsumes all other algebra classes found in this paper the paper continues to use more specific classes to make a for the reader and projections of functors figure shows the type class this class provides a means to lift or inj f into larger compositions g and project them out again the inj and inj laws relate the class f g where inj f a g a g a maybe f a inj ga just fa ga inj fa inj inj just instance f g f g h where inj fa inl inj fa inl ga ga inr ha nothing instance f h f g h where inj fa inr inj fa inl ga nothing inr ha ha instance f f where inj fa fa fa just fa law law figure functor subtyping injection and projection methods in the class ensuring that the two are effectively the idea is to use the type class resolution mechanism to encode coercive subtyping between functors in coq this subtyping relation can be expressed because coq type classes perform a backtracking search for matching instances hence highly overlapping definitions like the first and second instances are allowed this is a difference to haskells type classes which do not support backtracking hence haskell solution has to provide a choice that does not accurately model the expected subtyping relationship the inf function builds a new term from the application of f to some subterms inf f fix m f fix m f inf alg alg fold m alg smart constructors are built using inf and inj as follows g f g fix m f fix m f inf inj lit f nat fix m f lit n lit n f bool fix m f b b cond f fix m f fix m f fix m f fix m f cond c e e if c e e expressions are built with the smart constructors and used by operations like evaluation exp fix m exp cond true lit lit eval exp the function the toplevel functor again functor f fix m f f fix m f exp fold m rec fr fmap inf rec fr exp we can pattern match on particular features using and project g f functor f fix m f maybe g fix m f project exp exp f functor f fix m f maybe nat exp case project exp of just lit n just n nothing nothing extensible semantic values in addition to modular language features it is also desirable to have modular result types for semantic functions for example it is much to separate natural number and boolean values along the same lines as the and features to easily achieve this we make use of the same sorts of extensional encodings as the expression language itself data f a i nat data f a b bool data stuck f a stuck vi f r nat fix m r vi n i n vb f r bool fix m r vb b b b stuck stuck f r fix m r stuck stuck besides constructors for integer vi and boolean vb values we also include a constructor denoting stuck evaluation stuck to allow for an extensible return type r for evaluation we need to the eval type class in r class eval f r where f fix m r projection is now essential for pattern matching on values instance stuck f r f r functor r eval r where · lit n vi n · add e e case project e project e of just i n just i n vi n n stuck this concludes support for extensible inductive data types and functions to to metatheory must also support reasoning about these modular definitions reasoning with church encodings while church encodings are the foundation of in coq does not provide induction principles for them it is an open problem to do so without to axioms solves this problem with a novel approach based on of two important aspects of folds discussed by the problem of church encodings and induction own original approach to inductive data types was based on church encodings it is wellknown that church encodings of inductive data types have problems expressing induction principles such as the induction principle for arithmetic expressions p prop hl np lit n ha a bp a p b p add a b ap a p hl ha e case e of lit n hl n add x y ha a b p hl ha x p hl ha y the original solution to this problem in coq involved axioms for induction which strong normalization of the calculus among other problems this was the primary motivation for the creation of the calculus of inductive constructions with builtin inductive data types why exactly are proofs problematic for church encodings where inductive functions are not after all a coq proof is essentially a function that builds a proof term by induction over a data type hence the church encoding should be able to express a proof as a fold with a proof algebra over the data type in the same way it represents other functions the problem is that this approach restricts the propositions that can be proven folds over church encodings are destructive so their result type cannot depend on the term being for example it is impossible to express the proof for type soundness because it performs induction over the expression e mentioned in the type soundness property e e t e t this restriction is a for the semantics setting of this paper as it rules out proofs for most if not all theorems of interest supporting reasoning about semantic functions requires a new approach that does not from this restriction type dependency with dependent products first aspect of fold s is that they become substantially more expressive with the help of tuples the dependent products in coq take this observation one step further while an f algebra cannot refer to the original term it can simultaneously build a copy e of the original term and a proof that the property p e holds for the new term as the latter depends on the former the result type of the algebra is a dependent product ep e a generic algebra can exploit this expressivity to build a induction principle eg for the functor p fix m prop hl np lit n ha a bp a p b p add a b algebra ep e p hl ha e case e of lit n lit n hl n add x y add x y ha x y x y provided with the necessary proof cases can build a specific proof algebra the corresponding proof is simply a fold over a church encoding using this proof algebra note that since a proof is not a computational object it makes more sense to use regular algebras than algebras fortunately regular algebras are compatible with church encodings as the following variant of fold m shows fold m functor f algebra f a fix m f a fold m alg fold m rec alg fmap rec term equality with the universal property of course the dependent product approach does not directly prove a property of the original term instead given a term it builds a new term and a proof that the property holds for the new term in order to draw conclusions about the original term from the result the original and new term must be equal clearly the equivalence does not hold for arbitrary terms that happen to match the type signatures fix m f for church encodings and algebra f ep e for proof algebras statically ensuring this equivalence requires additional wellformedness conditions on both these conditions formally capture our notion of church encodings and proofs algebras wellformed proof algebras the first requirement for algebras states that the new term produced by application of the algebra is equal to the original term alg algebra f ep e alg inf fmap this constraint is encoded in the for proof algebras it is easy to verify that satisfies this property other proof algebras over can be defined by instantiating with appropriate cases for hl and ha in general wellformedness needs to be proven only once for any data type and induction algebra wellformed church encodings wellformedness of proof algebras is not enough because a proof is not a single application of an algebra but rather a fold m of it so the fold m used to build a proof must be a proper fold m as the church encodings represent inductive data types as their folds this down to ensuring that the church encodings are wellformed second aspect of folds formally characterizes the definition of a fold using its universal property h fold m alg h inf alg h in an initial algebra representation of an inductive data type there is a single implementation of fold m that can be checked once and for all for the universal property in approach every term of type fix m f consists of a separate fold m implementation that must satisfy the universal property note that this definition of the universal property is for a fold m using a traditional algebra as the only concern is the behavior of proof algebras which are traditional algebras over church encodings this is a sufficient characterization of wellformedness uses the same characterization for deriving church fortunately the lefttoright implication follows trivially from the definitions of fold m and inf independent of the particular term of type fix m f thus the only hard wellformedness requirement for a term e is that it satisfies the implication of the universal property type up f e a alg f a h fix m f a e h inf e alg h e h e fold m alg e this property is easy to show for any given smart constructor actually goes one step further and its smart constructors in terms of a new inf that only builds terms with the universal property inf functor f f f e f e about terms built from these constructors as all of the nice properties of initial algebras hold for these terms and importantly these properties provide a handle on reasoning about these terms two known consequences of the universal property are the fusion law which describes the composition of a fold with another computation h alg alg fmap h h fold m alg fold m alg and the known reflection law fold m inf id soundness of folds with the two wellformedness properties we can prove the key theorem for building inductive proofs over church encodings theorem given a functor f property p and a wellformed p proof algebra alg for any f term e with the universal property we can conclude that p e holds proof given that fold m alg e has type e p e we have that fold m alg e is a proof for p fold m alg e from that the lemma is derived as follows p fold m alg e wellfounded algebra and fusion law p fold m inf e reflection law pe theorem enables the construction of a proof of correctness as an fold of a proof algebra this provides a means to achieve our true goal modular proofs for extensible church encodings modular proofs for extensible church encodings the aim of modularity in this setting is to first write a separate proof for every feature and then compose the individual proofs into an overall proof for the feature composition these proofs should be independent from one another so that they can be reused for different combinations of features fortunately since proofs are essentially folds of proof algebras all of the reuse tools developed in section apply here in particular composing proofs is a simple matter of combining proof algebras with nevertheless the transition to modular components does introduce several in the reasoning process algebra due to injection propositions range over the abstract f of the component composition the signature of for example becomes f f p fix m f prop hl np lit n ha a bp a p b p add a b algebra ep e consider building a proof of e just nat m e vi m using then the first proof obligation is typeof lit n just nat m lit n vi m while this appears to follow immediately from the definition of eval recall that eval is a fold of an abstract algebra over f and is thus opaque to proceed we need the additional property that this f algebra to the algebra as expected r rec r rec inj rec this behavior follows from our approach the intended structure of f is a composition of features and algebras are intended to to the feature algebras we can formally capture the behavior in a type class that serves as a precondition in our modular proofs class eval f eval g f g wf eval f g where wf eval alg r rec r nat e f r rec inj e g r rec e instance eval f eval g eval h wf eval f g wf eval f g h instance eval f eval g eval h wf eval f h wf eval f g h instance eval f wf eval f f figure wf eval instances provides the three instances of this class in figure one for each instance of allowing coq to automatically build a proof of wellformedness for every composite algebra composition a similar approach is used to automatically build the definitions and proofs of languages from pieces defined by individual features in addition to functor and algebra composition the framework derives several important reasoning principles as type class instances similarly to wf eval these include the class which ensures that from two different are distinct and the wf functor class that ensures that fmap through injection figure provides a summary of all the classes defined in noting whether the base instances of a particular class are provided by the user or inferred with a default instance importantly instances of all these classes for feature compositions are built automatically analogously to the instances in figure extensible inductive predicates many proofs to rules which define a predicate for an important property in coq these predicates are expressed as inductive data types of kind prop for instance a soundness proof makes use of a judgment about the of values data value type prop where i n b b when dealing with a predicate over extensible inductive data types the set of rules defining the predicate must be extensible as well of these rules is obtained in much the same way as that of inductive data types by means of church encodings the important difference is that logical relations are indexed data types eg is indexed by a value and a type this requires functors indexed by values x of type i for example v t is the corresponding indexed functor for the extensible variant of above data v t v t prop v t prop where f v functor v t functor t v t vi n this index is a pair v t of a value and a type as values and types are themselves extensible the corresponding metalanguage types v and t are parameters of the functor to manipulate extensible logical relations we need indexed algebras fixpoints and operations type i f i prop i prop a x if a x a x type i f i prop i prop x i a i f a a x as these indexed variants are meant to construct logical relations their parameters range over prop instead of set fortunately class definition description class functor f where fmap a b f a f b fmap id fmap id id fmap fusion g h fmap h fmap g fmap h g functors supplied by the user class f g where inj f a g a g a maybe f a inj ga just fa ga inj fa inj inj just functor subtyping inferred class functor f functor g f g wf functor f g where wf functor a b h a b fmap h inj inj fmap h functor inferred class functor h f h g h f g h where inj a fe f a ge g fe inj ge class name t a f where f algebra mixin t f a functor inferred function algebras supplied by the user class f g n t a f n t a g wf n t a f g where wf algebra rec fa f t f algebra rec inj fa f algebra rec fa algebra inferred class functor f functor g f g name f g a where p algebra algebra f a proj eq e p algebra e inf inj fmap e proof algebras supplied by the user figure type classes provided by this shift the need for universal properties for ed values it does not matter how a logical relation is built but simply that it exists to wf functor wf algebra and are similarly unnecessary case study soundness of an arithmetic language here we briefly illustrate modular reasoning with a case study proving soundness for the language the previously defined eval function captures the operational semantics of this language in a modular way and reduces an expression to a f f stuck f value its type system is similarly captured by a defined typechecking function typeof that maybe returns a f type representation data t data f t for this language soundness is formulated as theorem soundness e t env typeof e just t eval e env t the proof of this theorem is a fold of a proof algebra over the expression e which the different cases to separate proof algebras for the different features a summary of the most aspects of these proofs follows the modular setting requires every case analysis to be captured in a because the is abstract the cases are not known locally and must be handled in a distributed fashion hence modular lemmas built from proof algebras are not just an important tool for reuse in ­ they are the main method of constructing extensible proofs universal properties everywhere universal properties are key to reasoning and should thus be available throughout the framework has more infrastructure to support this as an example of their utility when constructing a proof we may wish to prove a property of the extensible return value of an extensible function consider the case of the soundness proof given that typeof if c e e some t we wish to show that eval if c e e t if c evaluates to false we need to show that e t since if c e e has type t the definition of typeof says that e has type t typeof alg rec if c e e case project rec c of just case rec e rec e of just t just t if t t then just t else nothing nothing nothing nothing in addition the type equality test function says that e and e have the same type t t true we need to make use of a showing that t t t t true t t as we have seen in order to do so the universal property must hold for typeof e this is easily accomplished by a proof of the universal property t in the typeof function using universal properties is so important to reasoning that this should be the default behavior even though it is computationally irrelevant becomes trivial with the use of constructors these constructors have the additional advantage over standard smart constructors of being injective lit j lit k j k an important property for proving inversion lemmas the proof of requires that the subterms of the functor have the universal property established by the use of inf to facilitate this we provide a type that can be used in of fix m in function signatures type up f f functor f f e furthermore the universal property should hold for any value subject to proof algebras so it is convenient to include the property in all proof algebras provides a predicate transformer up p that captures this and induction principles accordingly up p functor f p f e prop e fix m f ep e equality and universal properties while universal properties with terms enables reasoning it does equality of terms in particular two up f terms t and t may share the same underlying term ie t t while their universal property proof components are different this issue shows up in the definition of the typing judgment for values this judgment needs to range over up f fv values and up f ft types where fv and ft are the value and type functors because we need to exploit the of in our inversion lemmas however knowing v t and t t no longer necessarily implies v t because t and t may have distinct proof components to solve this we make use of two auxiliary lemmas w t vv and w t vt that establish the implication actually as proofs are opaque we cannot tell if they are equal theorem w t vv i v t v v v v t theorem w t vt i v t t t t v t similar lemmas are used for other logical relations features which introduce new rules need to also provide proofs showing that they respect this safe projection property higherorder features binders and general recursion are in programming languages so must support these sorts of higherorder features the untyped lambda calculus demonstrates the challenges of implementing both these features with extensible church encodings encoding binders to encode binders we use a parametric hoas representation allows binders to be expressed as functors while still preserving all the convenient properties of hoas is a functor for a feature with function application abstraction and variables the style requires to be parameterized in the type v of variables in addition to the usual type parameter r for recursive occurrences data v r var v app r r lam v r as before smart constructors build extensible expressions var v f v fix m f var v var v app v f fix m f fix m f fix m f app e e app e e lam v f v fix m f fix m f lam f lam f defining evaluation algebras defining an evaluation algebra for the feature presents additional challenges evaluation of the untyped lambdacalculus can produce a closure requiring a richer value type than before data value stuck i nat b bool value value unfortunately coq does not allow such a definition as the closure constructor is not strictly positive recursive occurrences of value occur both at positive and negative positions instead a closure is represented as an expression to be evaluated in the context of an environment of bindings the environment is a list of values indexed by variables represented as natural numbers nat type env v v the modular functor closure values into the framework of extensible values introduced in section data f a fix m f env a closure f r fix m f env fix m r fix m r closure mf e mf e a first attempt at defining evaluation is f r stuck f r functor r nat env fix m r fix m r · exp env case exp of var index env index lam f closure f length env env app e e case project e env of just e env e e env env stuck the function the type variable v of the v functor with a natural number nat representing an index in the environment the return type of the algebra is now a function that takes an environment as an argument in the variable case there is an index that denotes the position of the variable in the environment and simply looks up that index in the environment in the lambda case builds a closure using f and the environment finally in the application case the expression e is evaluated and analyzed if that expression evaluates to a closure then the expression e is evaluated and added to the closures environment env and the closures expression e is evaluated under this extended environment otherwise e does not evaluate to a closure and evaluation is stuck unfortunately this algebra is illtyped on two accounts the lambda binder function f does not have the required type nat fix m f instead its type is nat r where r is universally quantified in the definition of the algebra secondly and in the app case the closure expression e has type fix m f which does not to the type r expected by · for the recursive call both these have the same problem at their root the algebra enforces inductive structural recursion by hiding that the type of the subterms is fix m f using universal quantification over r yet this information is essential for evaluating the binder we need to give up structural recursion and use general recursion instead this is as an untyped lambda term can be nonterminating semantic functions mixin algebras refine algebras with a more type signature type mixin t f a t a f t a this algebra specifies the type t of subterms typically fix m f the overall expression type with this mixin algebra is now welltyped e v stuck f v mixin fix m e nat env fix m v fix m v mixin algebras have an analogous implementation to eval as type classes enabling all of previous composition techniques class f g r where mixin fix m f g env fix m r fix m r instance stuck f r f r functor r f nat r where although the code of still appears generally recursive it is actually not because the recursive calls are abstracted as a parameter like with algebras accordingly does not raise any issues with termination checker mixin algebras the open recursion style which is used to model inheritance and mixins in objectoriented languages still encodings only accept algebras so using mixin algebras with encodings requires a new form of fold in order to overcome the problem of general recursion the open recursion of the mixin algebra is replaced with a bounded inductive fixpoint combinator that returns a default value if the evaluation does not terminate after n recursion steps f f nat a mixin fix m f f a fix m f a n def alg e case n of def m alg m def alg e the argument e is a expression of type fix m f first uses to unfold the expression into a value of type f fix m f and then applies the algebra to that value recursively in essence can define generally recursive operations by case analysis since it can values of the recursive occurrences the use of the bound prevents nontermination bounded evaluation evaluation can now be defined as a bounded fixpoint of the mixin algebra the definition uses a distinguished bottom value that represents a computation which does not finish within the given bound data f a bot bot eval x functor f f r f f r nat fix m f env fix m r eval x n e env n e env backwards compatibility the higherorder feature has introduced a change to the algebras used by the evaluation function eval x uses mixin algebras instead of algebras eval x now expects algebras over a parameterized functor the first change is easily because algebras are compatible with mixin algebras if a feature defines evaluation in terms of a algebra it does not have to define a second mixin algebra to be used binder features the function automatically derives the required mixin algebra from the algebra f a mixin fix m g f a alg alg this conversion function can be used to adapt evaluation for the arithmetic feature to a mixin algebra instance eval f f r where · e env flip · env e the algebras of features can be similarly adapted to build an algebra over a parametric functor figure summarizes the hierarchy of algebra algebras are the most flexible because they can be adapted and reused with both mixin algebras and parametric they should be used by default only to mixin algebras when necessary reasoning with higherorder features the switch to a bounded evaluation function over parameterized church encodings requires a new statement of soundness theorem f ft env t n e fix m f maybe fix m ft e fix m f nat algebras parameterized algebras controlled evaluation algebras parameterized algebras general recursion mixin algebras parameterized mixin algebras binders figure hierarchy of algebra adaptation e e wf environment env typeof e just t eval x n e env t the proof of features two substantial changes to the proof of soundness from section proofs over parametric church encodings the statement of uses two instances of the same expression e v fix m f v the first e v with the appropriate type for the typing algebra while e v for the evaluation algebra in recursive applications of the connection between e and e is no longer apparent as they have different types coq considers them to be distinct so case analysis on one does not information about the other shows how the connection can be with the help of an auxiliary equivalence relation e e which uses the environment to keep track of the current variable bindings the toplevel application where the common origin of e and e is apparent can easily supply a proof of this relation by induction on this proof recursive applications of can then analyze e and e in figure shows the rules for determining equivalence of lambda expressions x x var x var x e e e e app e e app e e xx x x f x f x lam f lam f figure lambda equivalence rules proofs for semantics functions proofs for semantic functions that use proceed by induction on the bound hence the reasoning principle for mixin based bounded functions f is in general provided a base case e p f e and inductive case n e e p f n e e p f n e hold n e p f n e also holds in the base case of the bound has been reached and eval x returns the proof of this case relies on adding to the judgment the rule stating that every type is by t hence whenever evaluation returns soundness trivially holds the inductive case is handled by a proof algebra whose state ment includes the inductive hypothesis provided by the induction on the bound ih n e e p f n e p f n e the app e e case of the soundness theorem illustrates the reason for including ih in the statement of the proof algebra after using the induction hypothesis to show that eval x e env produces a wellformed closure e env we must then show that evaluating e under the eval x e env env environment is also wellformed however e is not a subterm of app e e so the conventional induction hypothesis for subterms does not apply because eval x e eval x e env env is run with a smaller bound the bounded induction hypothesis ih can be used of proof algebras in order to incorporate inductive features in the proof existing proof algebras for those features need to be adapted to to the four possible proof signatures of soundness one for each definition of · a naive approach requires four different proof algebras for an inductive feature this is not acceptable because reasoning about a features soundness should be independent of how a language its evaluation algebra hence allows features to define a single proof algebra and provides the means to adapt and reuse that proof algebra for the four variants these proof algebra rely on type class instances which automatically build an instance of the new proof algebra from the original proof algebra proofs to parametric functors a proof algebra over the expression functor to one over the indexed functor for the equivalence relation first requires a definition of equivalence for functors fortunately equivalence for any such functor can be defined ab a b states that the same constructor c of applied to equivalent subterms and produces equivalent expressions the type class proofs of propositions on two instances of the same expression like soundness to proof algebras over the parametric functor instance n p n p this instance requires a small proofs over have to be stated in terms of two expressions with distinct f and f rather than two occurrences of the same expression induction over these two expressions requires a variant of for pairs of fixpoints proofs to semantic functions to be usable regardless of whether fold m or is used to build the evaluation function an inductive features proof needs to reason over an abstract fixpoint operator and induction principle this is achieved by only considering a single step of the evaluation algebra and leaving the recursive call abstract type soundness e tp ev env e just t ev out t e env t type typeof alg mixin fix m f f maybe fix m t eval alg mixin fix m f f env fix m r fix m r e fix m f e up up e e soundness e typeof alg eval alg soundness e soundness e typeof alg eval alg introducing typelevel binders would further compound the situation with four possible signatures for the typeof algebra the hypothesis is used to relate calls of and to applications of eval alg and typeof alg a type class instance again a proof algebra with this signature to one that includes the induction hypothesis generated by induction on the bound of instance n p e n ih p e case study as a of the framework we have built a set of five language features and combined them into a miniml variant the study also builds five other languages from these features figure presents the syntax of the expressions values and types provided by the features each line is annotated with the feature that provides that set of definitions the coq files that implement these features average roughly loc and come with a typing and evaluation function in addition to soundness and continuity proofs each language needs on average only loc to build its semantic functions and soundness proofs from the files implementing its features the framework itself consists of about loc e n e e b if e then e else e case e of z e s n e lam x te e e x fix x te bool lambda recursion v n b bool closure e v lambda t nat bool bool t t lambda figure miniml expressions values and types the generic soundness proof reused by each language relies on a proof algebra to handle the case analysis of the main lemma each case is handled by a these have their own set of proof algebras for case analysis or induction over an abstract the whole set of dependencies of a toplevel proof algebra forms a proof interface that must be satisfied by any language which uses that algebra such proof interfaces introduce the problem of feature interactions wellknown from modular frameworks in essence a feature interaction is functionality eg a function or a proof that is only necessary when two features are combined an example from this study is the inversion lemma which states that values with type nat are natural numbers x nat x n the bool feature introduces a new typing judgment for boolean values any language which includes both these features must have an instance of this inversion for our modular approach supports feature interactions by capturing them in type classes a missing case like for can then be easily added as a new instance of that type class without or overriding existing code in the case study feature interactions consist almost exclusively of inversion principles for judgments and the projection principles of section their proofs are relatively straightforward and can be by tactics into the type class inference algorithm these tactics help minimize the number of interaction type class instances which could otherwise easily grow exponentially in the number of features also available at related work this section discusses related work modular reasoning there is little work on modular proofs for extensible components an important contribution of our work is how to use universal properties to provide modular reasoning techniques for encodings of inductive data types that are compatible with theorem provers like coq old versions of coq based on the calculus of constructions also use church encodings to model inductive data types however the inductive principles to reason about those encodings had to be which strong normalization of the calculus the calculus of inductive constructions has inductive data types builtin and was introduced to avoid the problems with church encodings returns to church encodings to allow but does not use standard closed induction principles it instead uses a reasoning framework based on universal properties which allow modular reasoning without axioms in coq our approach to combines and extends ideas from existing solutions to the expression problem the type class infrastructure for f algebras is inspired by however the typelevel fixpoints that are central to cannot be used in coq because of their use of general recursion to avoid general recursion encodes with church encodings church encodings have inspired other solutions to the expression problem especially in objectoriented languages ­ those solutions do not use f algebras instead they use an isomorphic representation called object algebras object algebras are a better fit for languages where records are the main structuring construct such as oo languages differs from previous approaches by using f algebras instead of conventional f algebras or object algebras unlike previous solutions to the expression problem which focus only on the aspects of implementations also deals with modular reasoning and inductively defined predicates mechanized metatheory and reuse several adhoc approaches provide reuse but none is based on a proof modularity features alone the project is a framework for specifying formal languages it was used to format the language variants used in types and programming languages and to compose traditional proofs the tool allows users to write definitions and theorem statements in an format designed to these are then automatically translated to definitions in either or a theorem prover and proofs and functions are then written using the generated definitions both and consider how to extend existing inductive definitions and reuse related proofs in the coq proof assistant both their techniques rely on external tools which are no longer available and have users write extensions with respect to an existing specification as such features cannot be checked independently or easily reused with new specifications in contrast our approach is fully implemented within coq and allows for independent development and verification of features et al applied techniques to mechanized metatheory proofs as a case study they built type safety proofs for a family of extensions to java from a common base of features importantly composition of these features was entirely manual as opposed to the automated composition developed here concurrently with our development of et al have been working on metatheory in agda while uses church encodings to encode extensible datatypes their approach achieves by using which can be lifted to the type level encodings and their associated proofs can be modified to derive new languages one of mechanized metatheory has been that it with adequacy ie users that the proven theorem is in fact the desired one certainly the use of can the of mechanized definitions the theorem for example uses a more complicated statement than the version because requires induction over the equivalence relation modular inductive datatypes have the potential for concerns as the encodings are distributed over different components combining a higherlevel notation provided by a tool like with the composition mechanisms of is an interesting direction for future work such a higherlevel notation could help with while composition mechanisms could help with generating modular code for specifications binding to minimize the work involved in modeling binders provides binder components the problem of modeling binders has previously received a lot of attention some proof and type theories address this problem with better support for names and abstract syntax in generalpurpose proof like coq however such support is not available a popular approach widely used in coq is to use firstorder representations of binders such as the locally approach this involves developing a number of straightforward but tedious infrastructure lemmas and definitions for each new language such tedious infrastructure can be automatically generated or reused from data definitions however this typically requires additional tool support a higherorder representation like avoids most infrastructure definitions while we have developed binders in it supports firstorder representations as well semantics and interpreters while the of semantics formalization approaches use inductively defined predicates we propose an approach based on interpreters of course supports standard approaches as well a particularly line of work based on interpreters is that of using monads to structure semantics moggi monads to model computation effects and structure denotation semantics et al introduced monad transformers to compose multiple monads and build modular interpreters et al used an approach similar to in combination with monads to provide modular implementation of mathematical operational semantics our work could benefit from using monads to model more complex language features however unlike previous work we also have to consider modular reasoning monads introduce important challenges in terms of modular reasoning only very recently have some modular proof techniques for reasoning about monads have been introduced while these are good starting points it remains to be seen whether these techniques are sufficient to reason about generalized modular statements like soundness of semantics clearly its own challenges yet it is highly relevant as it the high degree of in correctness directly on the executable rather than on an intermediate formulation based on inductively defined relations the only similar work in this direction developed concurrently to our own is that of he uses the monad which fairly similar to our bounded fixpoint to formalize semantic interpreters in agda he that this style is more easily understood and more obviously deterministic and computable than logical relations unlike us does not consider of definitions and proofs conclusion formalizing metatheory can be very tedious for larger programming languages the required amount of work can be we propose a new approach to formalizing metatheory that allows modular development of language by building on existing solutions to modularity problems in conventional programming languages allows modular definitions of language components furthermore supports modular reasoning about these components our approach enables reuse of modular inductive definitions and proofs that deal with standard language constructs allowing language designers to focus on the interesting constructs of a language this paper addresses many but obviously not all of the fundamental issues for providing a formal approach to modular semantics we will investigate further extensions of our approach by the formalization of larger and more complex languages on top of our modular miniml variant a particularly challenging issue we are currently considering of is the impact of new features on existing definitions and proofs we believe that existing work on modular monadic semantics is a good starting point to overcome this acknowledgements we would like to especially thank william cook for his help in structuring the presentation of this work further thanks to van and the reviewers for their comments and suggestions this work was supported by the national science foundation under grant references b e a b c pierce r and s weirich engineering formal metatheory in popl b e and s weirich tool support for locally representations unpublished manuscript be et al mechanized metatheory for the the challenge in p evaluation a la nonstrict evaluation via compositional data types in proceedings of the rd workshop on programming theory pages ­ d j and p feature interactions products and composition in c and a automatic synthesis of typed on term algebras theor comput sci o proof reuse with extended inductive types in theorem proving in higher order logics pages ­ a parametric higherorder abstract syntax for mechanized semantics in icfp d t g kahn and j a simple applicative language miniml in lfp w r cook a denotational semantics of inheritance phd thesis ri usa t coquand and huet the calculus of constructions technical report rr inria may n a operational semantics using the monad in icfp b w r cook and d product lines of theorems in oopsla l using subtypes and monad transformers for writing modular functional interpreters j and r just do it simple monadic equational reasoning in icfp j a goguen j w e g and j b wright initial algebra semantics and continuous algebras j acm jan g b a and d dreyer how to make ad hoc proof automation less ad hoc in icfp r church twice ­ g a on the and expressiveness of fold j program ­ m n and g modularity and implementation of mathematical operational semantics notes theor comput sci march g lee b c d s s and k yi a generic formal metatheory framework for firstorder representations in esop x leroy formal verification of a realistic compiler communications of the acm m y and b c pierce a language for with formal systems journal of functional programming march s and p hudak modular denotational semantics for compiler construction in esop s p hudak and m jones monad transformers and modular interpreters in popl d macqueen modules for standard ml in lfp g algebraic data types and program transformation phd thesis september e moggi notions of computation and monads inf comput july a proof in september b c d s modular components in ecoop b c d s and w r cook for the practical with object algebras in ecoop b c d s r and a extensible and modular for the in in functional programming b c d s t and w r cook advice with explicit effects in c inductive definitions in the system coq rules and properties in f pfenning and c inductively defined types in the calculus of constructions in v f pfenning and c system description a framework for deductive systems in b c pierce types and programming languages mit press a m pitts nominal logic a first order theory of names and binding inf comput ­ robert how to believe a proof in five years of constructive type theory christopher and g siek modular proofs using types abs peter sewell et al effective tool support for the working in icfp m and n firstclass type classes in w data types a la j program t and v coding recursion a la in pages ­ p wadler the expression problem email november discussion on the java list p wadler and s how to make adhoc polymorphism less ad hoc in popl pages ­ 