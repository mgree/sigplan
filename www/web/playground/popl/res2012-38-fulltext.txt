a simulation for verifying concurrent program transformations ming fu school of computer science and technology university of science and technology of abstract verifying program transformations usually requires proving that the resulting program the target refines or is equivalent to the original one the source however the refinement relation between individual sequential threads cannot be preserved in general with the presence of parallel compositions due to instruction reordering and the different of atomic operations at the source and the target on the other hand the refinement relation defined based on fully abstract semantics of concurrent programs assumes arbitrary parallel environments which is too strong and cannot be satisfied by many wellknown transformations in this paper we propose a simulation rgsim to verify concurrent program transformations the relation is parametrized with constraints of the environments that the source and the target programs may compose with it considers the interference between threads and their environments thus is less permissive than relations over sequential programs it is compositional wrt parallel compositions as long as the constraints are satisfied also rgsim does not require semantics preservation under all environments and can incorporate the assumptions about environments made by specific program transformations in the form of relyguarantee conditions we use rgsim to reason about optimizations and prove atomicity of concurrent objects we also propose a general garbage collector verification framework based on rgsim and verify the boehm et al concurrent gc categories and subject descriptors d software engineering verification ­ correctness proofs formal methods f logics and meanings of programs specifying and verifying and reasoning about programs general terms theory verification keywords concurrency program transformation relyguarantee reasoning simulation introduction many verification problems can be reduced to verifying program transformations ie proving the target program of the transformation has no more observable behaviors than the source below we give some typical examples in concurrent settings permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ pa usa copyright c acm · correctness of compilation and optimizations of concurrent programs in this most natural program transformation verification problem every compilation phase does a program transformation t which needs to preserve the semantics of the inputs · atomicity of concurrent objects a concurrent object or library provides a set of methods that allow clients to manipulate the shared data structure with abstract atomic behaviors their correctness can be reduced to the correctness of the transformation from abstract atomic operations to concrete and executable programs in a concurrent context · verifying implementations of software transactional memory stm many languages supporting stm provide a highlevel atomic block so that programmers can assume the atomicity of the execution of c atomic blocks are implemented using some stm protocol eg tl that allows very finegrained interleavings verifying that the finegrained program respects the semantics of atomic blocks gives us the correctness of the stm implementation · correctness of concurrent garbage collectors highlevel languages eg java allow programmers to work at an abstract level without knowledge of the underlying gc algorithm however the concrete and executable lowlevel program involves interactions between the mutators and the collector if we view the gc implementation as a transformation from highlevel mutators to lowlevel ones with a concrete gc thread the gc safety can be reduced naturally to the semantics preservation of the transformation to verify the correctness of a program transformation t we follow approach and define a refinement relation between the target and the source programs which says the target has no more observable behaviors than the source then we can formalize the correctness of the transformation as follows c c c tc c c that is for any source program c acceptable by t tc is a refinement of c when the source and the target are concurrent programs the refinement needs to satisfy the following requirements to support effective proof of · since the target tc may be in a different language from the source the refinement should be general and independent of the language details · to verify finegrained implementations of abstract operations the refinement should support different views of program states and different of state accesses at the source and the target levels · when t is syntaxdirected and it is usually the case for parallel compositions ie tc c tc tc a com refinement is of particular importance for modular verification of t however existing refinement or equivalence relations cannot satisfy all these requirements at the same time contextual equivalence the canonical notion for comparing program behaviors fails to handle different languages since the contexts of the source and the target will be different simulations and logical relations have been used to verify compilation but they are usually designed for sequential programs except which we will discuss in section since the refinement or equivalence relation between sequential threads cannot be preserved in general with parallel compositions we cannot simply adapt existing work on sequential programs to verify transformations of concurrent programs refinement relations based on fully abstract semantics of concurrent programs are compositional but they assume arbitrary program contexts which is too strong for many practical transformations we will explain the challenges in detail in section in this paper we propose a simulation rgsim for compositional verification of concurrent transformations by addressing the above problems we make the following contributions · rgsim the simulation between concurrent programs with relyguarantee conditions which specify the interactions between the programs and their environments this makes the corresponding refinement relation compositional wrt parallel compositions allowing us to decompose refinement proofs for multithreaded programs into proofs for individual threads on the other hand the relyguarantee conditions can incorporate the assumptions about environments made by specific program transformations so rgsim can be applied to verify many practical transformations · based on the simulation technique rgsim focuses on comparing observable behaviors eg io events only which gives us considerable in the implementations of related programs the relation is mostly independent of the language details it can be used to relate programs in different languages with different views of program states and different of atomic state accesses · rgsim makes relational reasoning about optimizations possible in parallel contexts we present a set of relational reasoning rules to characterize and justify common optimizations in a concurrent setting including loop invariants strength reduction and induction variable elimination dead code elimination redundancy introduction etc · rgsim gives us a proof method to verify finegrained implementations of abstract algorithms and concurrent objects we successfully apply rgsim to verify concurrent counters the concurrent algorithm nonblocking stack and the list · we reduce the problem of verifying concurrent garbage collectors to verifying transformations and present a general gc verification framework which combines unary verification with relational proofs based on rgsim · we verify the boehm et al concurrent garbage collection algorithm using our framework as far as we know it is the first time to formally prove the correctness of this algorithm in the rest of this paper we first analyze the challenges for compositional verification of concurrent program transformations and explain our approach informally in section then we give the basic technical settings in section and present the formal definition of rgsim in section we show the use of rgsim to reason about local r x r y if r then critical region local r y r x if r then critical region a mutual exclusion algorithm x x x x vs local r r x x r local r r x x r b different of atomic operations figure equivalence lost after parallel composition optimizations in section verify atomicity of concurrent objects in section and prove the correctness of concurrent in section finally we discuss related work and conclude in section challenges and our approach the major challenge we face is to have a compositional refinement relation between concurrent programs ie we should be able to know tc tc tc c c c if we have tc c and sequential refinement parallel compositionality observable behaviors of sequential imperative programs usually refer to their control effects eg termination and exceptions and final program states however refinement relations defined cannot be preserved after parallel compositions it has been a wellknown fact in the compiler community that sound optimizations for sequential programs may change the behaviors of multithreaded programs the algorithm shown in figure a has been widely used to demonstrate the problem reordering the first two statements of the thread on the left preserves its sequential behaviors but the whole program can no longer ensure exclusive access to the critical region in addition to instruction reordering the different of atomic operations between the source and the target programs can also break the compositionality of program equivalence in a concurrent setting in figure b the target program at the bottom behaves differently from the source at the top assuming each statement is executed atomically although the individual threads at the target and the source have the same behaviors assuming arbitrary environments is too strong the problem with the refinement for sequential programs is that it does not consider the effects of threads intermediate state accesses on their parallel environments people have given fully abstract semantics to concurrent programs eg the semantics of a program is modeled as a set of execution traces each trace is an interleaving of state transitions made by the program itself and arbitrary transitions made by the environment then the refinement between programs can be defined as the subset relation between the corresponding trace sets since it considers all possible environments the refinement relation has very nice compositionality but unfortunately is too strong to formulate the correctness of many wellknown transformations including the four classes of transformations mentioned before · many concurrent languages eg c do not give semantics to programs with data races like the examples shown in figure therefore the compilers only need to guarantee the semantics preservation of programs · when we prove that a finegrained implementation of a concurrent object is a refinement of an abstract atomic operation we can assume that all accesses to the object in the context of the target program use the same set of primitives · usually the implementation of stm eg tl ensures the atomicity of a transaction only when there are no data races therefore the correctness of the transformation from highlevel atomic blocks to finegrained concurrent code assumes in the source · many languages are typesafe and operations such as pointer therefore the garbage collector could make corresponding assumptions about the mutators that run in parallel in all these cases the transformations of individual threads are allowed to make various assumptions about the environments they do not have to ensure semantics preservation within all contexts languages at source and target may be different the use of different languages at the source and the target levels makes the formulation of the transformation correctness more difficult if the source and the target languages have different views of program states and different atomic primitives we cannot directly compare the state transitions made by the source and the target programs this is another reason that makes the subset relation between sets of program traces in fully abstract semantics infeasible for the same reason many existing techniques for proving refinement or equivalence of programs in the same language cannot be applied either different make different observations concurrency introduces between two kinds of human as external and the parallel program contexts external do not care about the implementation details of the source and the target programs for them intermediate state accesses such as memory reads and writes are steps and only external events such as io operations are observable on the other hand state accesses have effects on the parallel program contexts and are not to them if the refinement relation relates observable event traces only it cannot have parallel compositionality as we explained in section on the other hand relating all state accesses of programs is too strong any reordering of state accesses or change of atomicity would fail the refinement our approach in this paper we propose a simulation rgsim between the target and the source programs it establishes a weak simulation ensuring that for every observable event made by the target program there is a corresponding one in the source we choose to view intermediate state accesses as steps thus we can relate programs with different implementation details this also makes our simulation independent of language details to support parallel compositionality our relation takes into account explicitly the expected interference between threads and their parallel environments inspired by the relyguarantee rg verification method we specify the interference using relyguarantee conditions in relyguarantee reasoning the rely condition r of a thread specifies the permitted state transitions that its environment may have and its guarantee g specifies the possible transitions made by the thread itself to ensure parallel threads can we need to check the interference constraint ie the guarantee of each thread is permitted in the rely of every others then we can verify their parallel composition by separately verifying each thread showing its behaviors under the rely condition indeed satisfy its guarantee after parallel composition the threads should be executed under their common environment ie the intersection of their relies and guarantee all the possible transitions made by them ie the union of their guarantees parametrized with relyguarantee conditions for the two levels our relation c r g c r g about not only the target c and the source c but also the interference r and g between c and its environment and r and g between c and its environment at the source level informally c r g c r g says the executions of c under the environment r do not exhibit more observable behaviors than the executions of c under the environment r and the state transitions of c and c satisfy g and g respectively rgsim is now compositional as long as the threads are composed with wellbehaved environments only the parallel compositionality lemma is in the following form if we know c r g c r g and c r g c r g and also the interference constraints are satisfied ie g r g r g r and g r we could get c c r r g g c c r r g g the compositionality of rgsim gives us a proof theory for concurrent program transformations also different from fully abstract semantics for threads which assumes arbitrary behaviors of environments rgsim allows us to instantiate the interference r g r and g differently for different assumptions about environments therefore it can be used to verify the four classes of transformations for instance if we want to prove that a transformation preserves the behaviors of programs we can specify the in r and g then we are no longer concerned with the examples in figure both of which have data races basic technical settings in this section we present the source and the target programming languages then we define a basic refinement which naturally says the target has no more observable event traces than the source we use as an intuitive formulation of the correctness of transformations the languages following standard simulation techniques we model the semantics of target and source programs as labeled transition systems before showing the languages we first define events and labels in figure a we leave the set of events unspecified here it can be instantiated by program depending on their interest eg inputoutput events a label that will be associated with a state transition is either an event or which means the corresponding transition does not generate any event ie a step the target language which we also call the lowlevel language is shown in figure b we abstract away the forms of states expressions and primitive instructions in the language an arithmetic expression e is modeled as a function from states to integers lifted with an undefined value boolean expressions are modeled similarly an instruction is a partial function from states to sets of label and state pairs describing the state transitions and the events it generates we use p to denote the power set unsafe executions events e labels o e a events and transition labels e int b true false c × abort c skip c c c if b c else c while b c c c l × × labels × abort b the lowlevel language e int b true false c × abort c skip c c c if b then c else c while b do c c c l × × labels × abort c the highlevel language figure generic languages at target and source levels lead to abort note that the semantics of an instruction could be nondeterministic moreover it might be undefined on some states making it possible to model blocking operations such as a lock statements are either primitive instructions or compositions of them skip is a special statement used as a flag to show the end of executions a execution of statements is modeled as a labeled transition l which is a triple of an initial program configuration a pair of statement and state a label and a resulting configuration it is undefined when the initial statement is skip the step aborts if an unsafe instruction is executed the highlevel language source language is defined similarly in figure c but it is important to note that its states and primitive instructions may be different from those in the lowlevel language the compound statements are almost the same as their lowlevel counterparts c c and c c are sequential and parallel compositions of c and c respectively note that we choose to use the same set of compound statements in the two languages for simplicity only this is not required by our simulation relation although the analogous program constructs of the two languages eg parallel compositions c c and c c make it convenient for us to discuss the compositionality later figure shows part of the definition of h which gives the highlevel operational semantics of statements we often omit the subscript h or l in h or l and the label on top of the arrow when it is the semantics is mostly standard we only show the rules for primitive instructions and parallel compositions here note that when a primitive instruction c is blocked at state ie we let the program configuration reduce to itself for example the instruction would be blocked when l is not making it be repeated until l becomes whereas simply sets l to at any time and would never be blocked primitive instructions in the highlevel and low level languages are atomic in the interleaving semantics below we use for zero or transitions with no events generated and e for transitions with only one event e generated the event trace refinement now we can formally define the refinement relation that relates the set of observable event traces generated by the target and the source programs a trace is a sequence of events e and may end with a termination marker done or a fault marker abort e done abort e e definition event trace set represents a set of external event traces produced by c in n steps from the state · · e c c e c e c e e e e c abort e abort c skip e done we define as n we the notation and use for the highlevel language then we define an event trace refinement as the subset relation between event trace sets which is similar to refinement property definition event trace refinement we say c is an refinement of c ie c c if and only if the refinement is defined for program configurations instead of for code only because the initial states may affect the behaviors of programs in this case the transformation t should translate states as well as code we the notation and use t to represent the state transformation and use c t c for t c c then defined in formula can be as c c c tc c t c the rgsim relation the refinement is defined directly over the observable behaviors of programs it is intuitive and also abstract in that it is independent of language details however as we explained before it is not compositional wrt parallel compositions in this section we propose rgsim which can be viewed as a compositional proof technique that allows us to derive the simple refinement and then verify the corresponding transformation t the definition our defined rgsim relation is in the form of c r g c r g which is a simulation between program configurations c and c it is parametrized with the rely and guarantee conditions at the low level and the high level which are binary relations over states r g × r g × the simulation also takes two additional parameters the step invariant and the postcondition which are both relations between the lowlevel and the highlevel states × c c skip e c c e skip abort c c abort c c skip skip skip c e c c c e c c c c c c c c c c c c c c c e c c c e c c c abort or c abort c c abort figure operational semantics of the highlevel language rr a related transitions r rm r b the side condition of trans figure related transitions before we formally define rgsim in definition we first introduce the related transitions as follows definition related transitions r r r r r r represents a set of the related transitions in r and r putting together the corresponding transitions in r and r that can be related by as illustrated in figure a g g is defined in the same way definition rgsim whenever c r g c r g then and the following are true if c c then there exist c and such that c c g g and c r g c r g if c e c then there exist c and such that c e c g g and c r g c r g if c skip then there exists such that c skip g g and if c abort then c abort if r r then c r g c r g then c r g c r g iff for all and if then c r g c r g here the precondition is used to relate the initial states and informally c r g c r g says the lowlevel configuration c is simulated by the highlevel configuration c with behaviors g and g respectively no matter how their environments r and r interfere with them it requires the following hold for every execution of c · starting from related states each step of c corresponds to zero or multiple steps of c and the resulting states are related too if an external event is produced in the step of c c c c ge g e c c rr c c a program steps b environment steps figure simulation diagrams of rgsim c the same event should be produced by c we show the simulation diagram with events generated by the program steps in figure a where lines denote hypotheses and dashed lines denote conclusions following notations · the relation reflects the abstractions from the lowlevel machine model to the highlevel one and is preserved by the related transitions at the two levels so it is an invariant for instance when verifying a finegrained implementation of sets the relation may relate a concrete representation in memory eg a at the low level to the corresponding abstract mathematical set at the high level · the corresponding transitions of c and c need to be in g g that is for each step of c its state transition should satisfy the guarantee g and the corresponding transition made by the multiple steps of c should be in the transitive closure of g the guarantees are abstractions of the programs behaviors as we will show later in the par rule in figure they will serve as the rely conditions of the sibling threads at the time of parallel compositions note that we do not need each step of c to be in g although we could do so this is because we only care about the behaviors with of the source that are used to simulate the target we will explain more by the example in section · if c terminates then c terminates as well and the final states should be related by the postcondition we require ie the final state relation is not weaker than the step invariant · c is not safe only if c is not safe either this means the transformation should not make a safe highlevel program unsafe at the low level · whatever the lowlevel environment r and the highlevel one r do as long as the state transitions are related they should not affect the simulation between c and c as shown in figure b here a step in r may correspond to zero or multiple steps of r note that different from the program steps for the environment steps we do not require each step of r to correspond to zero or multiple steps of r on the other hand only requiring that r be simulated by r is not sufficient for parallel compositionality which we will explain later in section t b b b b b b b b id true rm r r r r r rm rm r figure auxiliary definitions for rgsim then based on the simulation we hide the states by the precondition and define the rgsim relation between programs only by the definition we know if c r g c r g ie the precondition needs to be no weaker than the step invariant rgsim is sound wrt the refinement definition that is c r g c r g ensures that c does not have more observable behaviors than c theorem soundness if there exist r g r g and such that c r g c r g then c c the soundness theorem can be proved by first strengthening the relies to the identity transitions and weakening the guarantees to the universal relations then we prove that the resulting simulation under identity environments implies the refinement for program transformations since the initial state for the target program is transformed from the initial state for the source we use defined in figure to say the transformation t over states ensures the binary precondition corollary if there exist r g r g and such that and c r g c r g then c t c compositionality rules rgsim is compositional wrt various program constructs including parallel compositions we present the compositionality rules in figure which gives us a relational proof method for concurrent program transformations as in the rg logic we require that the pre and postconditions be stable under the interference from the environments here we introduce the concept of stability of a relation wrt a set of transition pairs × × × definition stability sta holds iff for all and if and then usually we need sta r r which says whenever holds initially and r and r perform related actions the resulting states still satisfy by unfolding r r we could see that itself is stable wrt any related transitions ie sta r r another simple example is given below where both environments could increment x and the unary stable assertion x is lifted to the relation x x x x r x x r x x we can prove sta r r stability of the pre and postconditions under the environments interference is assumed as an implicit side condition at every proof rule in figure eg we assume sta r r in the skip rule we also require implicitly that the relies and guarantees are closed over identity transitions since stuttering steps will not affect observable event traces in figure the rules skip seq if and while reveal a high degree of similarity to the corresponding inference rules in hoare logic in the seq rule serves as the postcondition of c and c and the precondition of c and c at the same time the if rule requires the boolean conditions of both sides to be evaluated to the same value under the precondition we give the definitions of the sets b b and b b in figure the rule also requires the precondition to imply the step invariant in the while rule the relation is viewed as a loop invariant preserved at the loop entry point and needs to ensure b b parallel compositionality the par rule shows parallel compositionality of rgsim the interference constraints say that two threads can be composed in parallel if one threads guarantee implies the rely of the other after parallel composition they are expected to run in the common environment and their guaranteed behaviors contain each single threads behaviors note that although rgsim does not require every step of the highlevel program to be in its guarantee see the first two tions in definition this relaxation does not affect the parallel compositionality this is because the target could have less behaviors than the source to let c c simulate c c we only need a subset of the interleavings of c and c to simulate those of c and c thus the highlevel relies and guarantees need to ensure the existence of those interleavings only below we give a simple example to explain this subtle issue we can prove xx r g r g where the relies and the guarantees say x can be increased by and and relate x of the two sides r g x x r g x x x x note that the highlevel program is actually than its guarantee but to prove we only need the execution in which it goes two steps to the end without interference from its environment also we can prove r g r g then by the par rule we get xx r g r g which does not violate the natural meaning of refinements that is all the possible external events produced by the lowlevel side can also be produced by the highlevel side although the latter could have more external behaviors due to its another in the rgsim definition is with the fifth condition over the environments which is crucial for parallel compositionality one may think a more natural alternative to this condition is to require that r be simulated by r if r then there exists such that r and c r g c r g we refer to this modified simulation definition as unfortunately does not have parallel compositionality as a counterexample if the invariant says the x is not greater than the x and the precondition requires x of the two sides are equal ie x x x x skip skip r id skip r id c r g c r g c r g c r g seq c c r g c c r g c r g c r g c r g c r g b b b b ¬b ¬b if b c else c r g if b then c else c r g if c r g c r g b b b b ¬b ¬b while while b c r g while b do c r g c r g c r g g r g r c r g c r g g r g r c c r r g g c c r r g g par c r g c r g sta g g c r g c r g c r g c r g sta r r c r g c r g weaken c r g c r g r r c r g c r g r r gg gg c r g c r g r r r r sta g g r r c r r g g c r r g frame g c r g m rm gm m rm gm c r g rm r r trans c r g c r g figure compositionality rules for rgsim we could prove the following xx id true xx id true true id true id here we use id and true defined in figure for the sets of identity transitions and arbitrary transitions respectively and the notations at the low level to the high level however the following refinement does not hold after parallel composition xx id true xx id true this is because the rely r or r is an abstraction of all the permitted behaviors in the environment of a thread but a concrete sibling thread that runs in parallel may produce less transitions than r or r to obtain parallel compositionality we need to ensure that the simulation holds for all concrete sibling threads with our definition the refinement true id true id is not provable because after the environments related transitions the target may print a value smaller than the one by the source other rules we also develop some other useful rules about rgsim for example the rule allows us to replace the invariant by a stronger invariant we need to check that is indeed an invariant preserved by the related program steps ie sta g g holds the weaken rule requires to be preserved by environment steps related by the weaker invariant as usual the prepost conditions the relies and the guarantees can be or by the rule the frame rule allows us to use local specifications when verifying the simulation between c and c we need to only talk about the resource in and and the local relies and guarantees r g r and g then the proof can be reused in contexts where some extra resource is used and the accesses of it respect the invariant and r g r and g we give the auxiliary definitions in figure the disjoint union between states is lifted to state pairs an intuitionistic state relation is monotone wrt the extension of states the disjointness says that any state pair satisfying both and can be split into two disjoint state pairs satisfying and respectively for example let y y and x x then both and are intuitionistic and holds we also require to be stable under interference from the programs ie the programs do not change the extra resource and the extra environments we use as a shorthand for similar representations are used in this rule finally the transitivity rule trans allows us to verify a trans formation by using an intermediate level as a the intermediate environment rm should be chosen with so that the related transitions can be decomposed into related and related transitions as illustrated in figure b here defines the composition of two relations and defines the side con over the environments as shown in figure we use for a state soundness of all the rules in figure is proved in the technical report showing that for each rule the premises imply the conclusion the proofs are also mechanized in the coq proof assistant instantiations of relies and guarantees we can derive the sequential refinement and the refinement by instantiating the rely conditions in rgsim for example the refinement over closed programs assumes identity environments making the interference constraints in the par rule unsatisfiable this the observation in section that the sequential refinement parallel compositionality c id true c id true the refinement assumes arbitrary environments which makes the interference constraints in the par rule trivially true but this assumption is too strong usually cannot be satisfied in practice c true true c true true a simple example below we give a simple example to illustrate the use of rgsim and its parallel compositionality in verifying concurrent program transformations the highlevel program c c is transformed to c c using a lock l to the accesses of the shared variable x we aim to prove c c t c c that is although xx is implemented by two steps of x in c the parallel c will not print values here we view output events as observable behaviors x x x x x x x x to facilitate the proof we introduce an auxiliary shared variable x at the low level to record the value of x at the time when the lock it specifies the value of x outside every critical section thus should match the value of the highlevel x after every corresponding action here c means c is executed atomically by the soundness and compositionality of rgsim we only need to prove simulations over individual threads providing appropriate relies and guarantees we first define the invariant which only about the value of x when the lock is free x x l x x we let the pre and postconditions be as well the highlevel threads can be executed in arbitrary environments with arbitrary guarantees r g true the transformation uses the lock to protect every access of x thus the lowlevel relies and guarantees are not arbitrary r l x x x x l l g l l l x l l x every lowlevel thread guarantees that it updates x only when the lock is acquired its environment cannot update x or l if the current thread holds the lock here is the identifier of the current thread when acquired the lock holds the id of the owner thread following the definition we can prove c r g c r g and c r g c r g by applying the par rule and from the soundness of rgsim corollary we know c c t c c holds for any t that respects perhaps interestingly if we omit the lock and unlock operations in c then c c would have more observable behaviors than c c this does not indicate the of our par rule which is sound the reason is that x might have different values on the two levels after the environments related transitions so that we cannot have r g r g with the current definitions of r and g even though the code of the two sides are syntactically identical more discussions rgsim ensures that the target program preserves safety properties including the partial correctness of the source but allows a terminating source program to be transformed to a target having infinite steps in the above example this allows the lowlevel programs to be blocked forever eg at the time when the lock is held but never released by some other thread proving the preservation of the termination behavior would require liveness proofs in a concurrent setting eg proving the absence of deadlock which we leave as future work in the next three sections we show more serious examples to demonstrate the applicability of rgsim relational reasoning about optimizations as a general correctness notion of concurrent program transformations rgsim establishes a relational approach to justify compiler optimizations on concurrent programs below we adapt work on sequential optimizations to the concurrent setting optimization rules usually optimizations depend on particular contexts eg the assignment x e can be eliminated only in the context that the value of x is never used after the assignment in a concurrent setting we should also consider the parallel context for an optimization rgsim enables us to specify various sophisticated requirements for the parallel contexts by relyguarantee conditions based on rgsim we provide a set of inference rules to characterize and justify common optimizations eg dead code elimination with information of both the sequential and the parallel contexts due to the space limit we only present some interesting rules here and leave other rules in the technical report note in this section the target and the source programs are in the same language sequential skip law c r g c r g skip c r g c r g c r g c r g c r g skip c r g plus the variants with skip after the code c or c that is could be arbitrarily introduced and eliminated common branch b c r g c r g c r g c r g c r g if b c else c r g this rule says that when the can be evaluated and both branches can be optimized to the same code c we can transform the whole to c without introducing new behaviors dead while sta r r skip r id while bc r id we can eliminate the loop if the loop condition is false no matter how the environments update the states at the loop entry point dead code elimination skip id id c id g sta r r skip r id c r g intuitively skip id id c id g says that the code c can be eliminated in a sequential context where the initial and the final states satisfy and respectively if both and are stable wrt the interference from the environments r and r then the code c can be eliminated in such a parallel context as well redundancy introduction c id g skip id id sta r r c r g skip r id as we lifted sequential dead code elimination we can also lift sequential redundant code introduction to the concurrent setting so long as the pre and postconditions are stable wrt the environments note that here c is a single instruction because we should consider the interference from the environments at every intermediate state when introducing a sequence of redundant instructions an example of invariant with these rules we can prove the correctness of many traditional compiler optimizations performed on concurrent programs in appropriate contexts here we only give a small example of loop invariants more examples eg strength reduction and induction variable elimination can be found in the technical report target code c source code c local t local t t x n n t x i i t i i t when we do not care about the final value of t its not difficult to prove that the optimized code c preserves the sequential behaviors of the source c but in a concurrent setting safely the invariant code tx also requires that the environment should not update x nor t r x x t t the guarantee of the program can be specified as arbitrary transitions since we only care about the values of i n and x the invariant relation can be defined as i i n n x x we do not need special pre and postconditions thus the correctness of the optimization is formalized as follows c r true c r true we could prove directly by the rgsim definition and the operational semantics of the code but below we give a more convenient proof using the optimization rules and the compositionality rules instead we first prove the following by the and rules tx r true skip r true skip r true tx r true where and specify the states at the specific program points t x t x after adding to c and c to make them the same shape we can prove the simulation by the compositionality rules seq and while finally we remove all the and conclude ie the correctness of the optimization in appropriate contexts since the relies only updates of x and t we can execute c and c concurrently with other threads which update i and n or read x still ensuring semantics preservation proving atomicity of concurrent objects a concurrent object provides a set of methods which can be called in parallel by clients as the only way to access the object rgsim gives us a proof method to verify the atomicity atom s s e atom s s e a an abstract set local x head z u while u e x z z u if u e y new e z y local x head y v while v e x y y v if v e z z else b the set figure the set object of implementations of the object we can define abstract atomic operations in a highlevel language as specifications and prove the concrete finegrained implementations refine the corresponding atomic operations when executed in appropriate environments for instance in figure a we define two atomic set operations and figure b gives a concrete implementation of the set object using a list partial correctness and atomicity of the algorithm has been verified before here we show that its atomicity can also be verified using our rgsim by proving the lowlevel methods refine the corresponding abstract operations we will discuss the key difference between the previous proofs and ours in section we first take the generic languages in figure and instantiate the highlevel program states below ms ml loc × the state consists of shared memory ms where the object and a thread pool which is a mapping from thread identifiers t to their memory ml the lowlevel state is defined similarly we use ms ml and to represent the lowlevel shared memory threadlocal memory and the thread pool respectively to allow ownership transfer between the shared memory and threadlocal memory we use or c a at the low level to convert the shared memory to local and then execute c or c atomically following an abstract transition a or a is used to specify the effects of the atomic operation over the shared memory which allows us to split the resulting state back into shared and local when we exit the atomic block the atomic blocks are instantiations of the generic primitive operations c or c in figure their semantics is shown in the technical report we omit the annotations a and ms a shared ms local ml t t t gt t gt ms x null a ms ms x v y a v a ms a ms ms head x ms min val a max val ml ml ml x y z u v ms ms shared ms t dom local t ms ms x v y v y ms t v y ms ms x v y t v y ms v y t ml ms t ml ms x y z u v w t u z w ms t u y y v z ml y v z ml u v w t ml ms t ml ms x y z u v t u y t v z ms y t v z t u z ml ml y t v z v max val t ml ms t ml ms ml ml ms rt t t gt t ml ms t t ml ms t t ml ms t ml ms e ms ml ms e ms ml ms ml ml ms rt t t gt figure useful definitions for the list a in figure which are the same as the corresponding guarantees in figure as we will explain below in figure the abstract set is implemented by an ordered list pointed to by a shared variable head with two nodes at the two ends of the list containing the values min val and max val respectively each list node is associated with a lock traversing the list uses locking the lock on one node is not released until its successor is locked inserts a new node with value e in the appropriate position while holding the lock of its predecessor the predecessors pointer while both the node to be removed and its predecessor are locked we define the relation the guarantees and the relies in figure the predicate ms a represents a list in the shared memory ms at the location x whose values form the sequence a then the mapping shared map between the lowlevel and the highlevel shared memory is defined by only concerning about the value sequence on the list the concrete list should be sorted and its elements constitute the abstract set for a thread ts local memory of the two levels we require that the values of e are the same and enough local space is provided for and as defined in the mapping local map then relates the shared memory by shared map and the local memory of each thread t by local map the atomic actions of the algorithm are specified by and respectively which are all parameterized with a thread identifier t for example says that when holding the locks of the node y and its predecessor x we can transfer the node y from the shared memory to the threads local memory this corresponds to the action performed by the code of line in every thread t is executed in the environment that any other thread t can only perform those five actions as defined in rt similarly the highlevel gt and rt are defined according to the abstract and the relies and guarantees are almost the same as those in the proofs in we can prove that for any thread t the following hold rt gt rt gt rt gt rt gt we give the detailed proofs in the technical report which are done operationally based on the definition of rgsim by the compositionality and the soundness of rgsim we know that the finegrained operations under the parallel environment r are simulated by the corresponding atomic operations under the highlevel environment r while r and r say all accesses to the set must be done through the add and remove operations this gives us the atomicity of the concurrent implementation of the set object more examples in the technical report we also show the use of rgsim to prove the atomicity of other finegrained algorithms including the nonblocking concurrent counter stack algorithm and a concurrent algorithm calculating greatest common verifying concurrent garbage collectors in this section we explain in detail how to reduce the problem of verifying concurrent garbage collectors to transformation verification and use rgsim to develop a general gc verification framework we apply the framework to prove the correctness of the boehm et al concurrent gc algorithm correctness of concurrent a concurrent gc is executed by a thread and performs the collection work in parallel with user threads mutators which access the shared heap via read write and allocation operations to ensure that the gc and the mutators share a coherent view of the heap the heap operations from mutators may be instrumented with extra operations which provide an interaction mechanism to allow arbitrary mutators to with the gc these instrumented heap operations are called barriers eg read barriers write barriers and allocation barriers the gc thread and the barriers constitute a concurrent garbage collecting system which provides a higherlevel programming model for languages eg java in this highlevel model programmers feel they access the heap using regular memory operations and are from manually objects that are no longer in use they do not need to consider the implementation details of the gc and the existence of barriers we could verify the gc system by using a logic to prove that the gc thread and the barriers satisfy their specifications however we say this is an indirect approach because it is if the specified correct behaviors would indeed make the mutators and generate the abstract view for highlevel programmers usually this part is examined by and then trusted here we propose a more direct approach we view a concurrent garbage collecting system as a transformation t from a highlevel language to a lowlevel language a standard atomic memory operation at the source level is transformed into the corresponding barrier code at the target level in the source level we assume there is an abstract gc thread that turns unreachable objects into memory the abstract collector is transformed into the concrete gc code running concurrently with the target mutators that is tc where tc simply translates some memory access instructions in c into the corresponding barriers and leaves the rest unchanged then we reduce the correctness of the concurrent garbage collecting system to saying that any mutator program will not have behaviors when executed using this system a general framework the compositionality of rgsim allows us to develop a general framework to prove which cannot be done by monolithic proof methods by the parallel compositionality of rgsim the par rule in figure we can decompose the refinement proofs into proofs for the gc thread and each mutator thread verifying the gc the semantics of the abstract gc thread can be defined by a binary state predicate that is the abstract gc thread always makes to change the highlevel state we can choose different for different but usually guarantees not modifying reachable objects in the heap thus for the gc thread we need to show that is simulated by when executed in their environments this can be re to unary relyguarantee reasoning about by proving in a standard relyguarantee logic with proper and as long as is a concrete representation of the judgment says given an initial state satisfying the precondition if the environments behaviors satisfy then each step of satisfies and the postcondition holds at the end if terminates in general the collector never terminates thus we can let be false and should be provided by the verifier where needs to be general enough that can be satisfied by any possible lowlevel initial state encodes the possible behaviors of mutators which can be derived as we will show below verifying mutators for the mutator thread since t is syntaxdirected on c we can reduce the refinement problem for arbitrary mutators to the refinement on each primitive instruction only by the compositionality of rgsim the proof needs proper relyguarantee conditions let and denote the guarantees of the source instruction c and the target code tc respectively then we can define the general guarantees for a mutator thread t gt gt c c its relies should include all the possible guarantees made by other threads and the abstract and concrete behaviors respectively rt rt t t gt t t gt the used to verify the gc code can now be defined below t gt the refinement proof also needs definitions of binary and relations the invariant relates the lowlevel and the highlevel states and needs to be preserved by each lowlevel step in general a highlevel state can be mapped to a lowlevel state by giving a concrete local store for the gc thread adding additional structures in the heap to record information for collection renaming heap cells for copying etc for each mutator thread t the relations t and t need to hold at the beginning and the end of each basic transformation unit every highlevel primitive instruction in this case respectively we let t be the same as t to support sequential compositions we require see figure ie t holds over the initial states in addition the target and the source boolean expressions should be evaluated to the same value under related states as required in the if and while rules in figure t tb b theorem verifying concurrent garbage collecting systems if there exist rt rt t and such that and the following hold verification of the gc code correctness of t on mutator instructions c rt gt t t tc rt gt side conditions t then that is to verify a concurrent garbage collecting system we need to do the following · define the and t relations and prove the correctness of t on highlevel primitive instructions since t preserves the syntax on most instructions its often immediate to prove the target instructions are simulated by their sources but for instructions that are transformed to barriers we need to verify the barriers that they implement both the source instructions by rgsim and the interaction mechanism shown in their guarantees · find some proper and and verify the gc code by rg reasoning we require the guarantee should not contain more behaviors than the first side condition and can start its execution from any state transformed from a highlevel one the second side condition application boehm et al concurrent gc algorithm we illustrate the applications of the framework theorem by proving the correctness of a garbage collector proposed by boehm et al variants of the algorithm have been used in practice eg by ibm due to the space limit we only describe the proof sketch here details are presented in the technical report overview of the gc algorithm the toplevel code of the gc thread is shown in figure in each collection cycle after an collection local loop invariant while true initialize reach inv trace reach inv reach inv atomic reach stk x reach black sweep false figure outline of the gc code and proof sketch e id pt atomic e aux x atomic aux figure the write barrier for boehm et al gc initialization process the gc enters the concurrent line and traces the objects reachable from the roots ie the mutators local pointer variables that may contain references to the heap objects a mark stack is used to do a depthfirst tracing during the tracing the between objects might be changed by the mutators thus a write barrier is required to the collector of those modified objects by the objects tags called when the tracing is done the gc all the mutators and from the dirty objects that have been marked called line and the phase is implemented by finally all the reachable objects are marked and the gc performs the concurrent line in which objects are usually in practice there is also a concurrent phase line before the to reduce the time the full gc code is given in the technical report the write barrier is shown in figure where the dirty field is set after modifying the objects pointer field here we use a auxiliary variable aux for each mutator thread to record the current object that the mutator is updating we add aux only for the purpose of verification so that we can easily specify the finegrained property of the write barrier in the guarantees that immediately after updating the pointer field the thread would do nothing else except setting the corresponding dirty field the gc does not use read barriers nor allocation barriers we first present the highlevel and lowlevel program state models in figure the behaviors of the highlevel abstract gc thread are defined as follows h h l h hl h l saying that the mutator stores and the reachable objects in the heap are here h means the object at the location l is reachable in h from the roots in s h loc × s h m × figure highlevel and lowlevel state models the transformation the transformation t is defined as follows for code the highlevel abstract gc thread is transformed to the gc thread shown in figure each instruction e in mutators is transformed to the write barrier where id is a pointer field of x other instructions and the program structures of mutators are unchanged the following transformations are made over initial states · first we require the highlevel initial state to be wellformed h l h l domh that is reachable locations cannot be dangling pointers · highlevel locations are transformed to integers by a function loc m satisfying · variables are transformed to the low level using an extra bit to preserve the highlevel type information for and for pointers · highlevel objects are transformed to the low level by adding the color and dirty fields with initial values white and respectively other addresses in the lowlevel heap domain m are filled out using objects whose are blue and all the other fields are initialized by here we use black and white for marked and objects respectively and blue for memory · the concrete gc thread is given an initial store the formal definition of t is included in the technical report to prove in our framework we apply theorem prove the refinement between lowlevel and highlevel mutators and verify the gc code using a unary logic refinement proofs for mutator instructions we first define the and t relations h h t dom store t heap h h in the relation between lowlevel and highlevel stores and heaps are enforced by store map and heap map respectively their definitions reflect the state transformations we describe above ignoring the values of those structures it also requires the wellformedness of highlevel states for each mutator thread t the t relation enforced at the beginning and the end of each transformation unit each highlevel instruction is stronger than it requires that the value of the auxiliary variable aux see figure be a null pointer p t h h p the refinement between the write barrier at the low level and the pointer update instruction at the high level is formulated as e rt barrier t t e rt pt where barrier and pt are the guarantees of the write barrier and the highlevel atomic write operation respectively since the transformation of other highlevel instructions is identity the corresponding refinement proofs are simple relyguarantee reasoning about the gc code the unary program logic we use to verify the gc thread is a standard relyguarantee logic adapted to the target language we describe states using separation logic assertions as shown below p q b e p q following parkinson et al we treat program variables as resource and use and for the thread ts of pointers and respectively we omit the thread identifiers if these predicates hold for the current thread we first give the precondition and the guarantee of the gc the gc starts its executions from a lowlevel wellformed state ie just corresponding to the highlevel definition the lowlevel predicate says none of the reachable objects are blue we define as follows s h s h n h hn h n blue h blue the gc guarantees not modifying the mutator stores for any object the gc does not update its fields coming from the highlevel mutator nor does it the object here a lowlevel object to a new one that contains mutator data only the proof sketch is given in figure one of the key invariants used in the proof is reach inv which says any white reachable object can either be traced from a root object in a path on which every object is white or be reachable from a black object whose pointer field was updated and dirty bit was set to since the proof is done in the unary logic the details here are orthogonal to our proof but it is rgsim that allows us to derive theorem which then links proofs in the unary logic with relational proofs we give the complete proofs in the technical report related work and conclusion there is a large body of work on refinements and verification of program transformations here we only focus on the work most closely related to the typical applications discussed in this paper verifying compilation and optimizations of concurrent programs compiler verification for concurrent programming languages can date back to work by wand and et al which is about functional languages using mechanisms recently presents a verified compiler for java threads and prove semantics preservation by a weak bisimulation he views every heap update as an observable move thus does not allow the target and the source to have different of atomic updates to achieve parallel compositionality he requires the relation to be preserved by any transitions of shared states ie the environments are assumed arbitrary as we explained in section this is a too strong requirement in general for many transformations including the examples in this paper et al present a proof method for verifying concurrent program transformations on relaxed memory models the method relies on a compositional denotational semantics where the values of shared variables are always considered arbitrary at any program point in other words they also assume arbitrary environments following compcert project s et al verify compilation from a concurrent language to x by simulations they focus on correctness of a particular compiler and there are two phases in their compiler whose proofs are not compositional here we provide a general compositional proof technique to verify concurrent transformations we apply rgsim to justify concurrent optimizations following benton who presents a declarative set of rules for sequential optimizations also the proof rules of rgsim for sequential compositions conditional statements and loops coincide with those in relational hoare logic and relational separation logic proving linearizability or atomicity of concurrent objects et al show linearizability can be characterized in terms of an observational refinement where the latter is defined similarly to our there is no proof method given to verify the linearizability of finegrained object implementations and wand propose a proof method to verify concurrent objects they first propose a simple refinement based on fully abstract trace semantics which is compositional but cannot handle complex algorithms as discussed in section their refinement then uses rely conditions to filter out illegal environment transitions the basic idea is similar to ours and the refinement can also be used to verify stack algorithm however it is not a congruence for parallel composition in their settings both the concrete finegrained and the abstract atomic versions of object operations need to be expressed in the same language they also require that the finegrained implementation should have only one update action over the shared state to correspond to the highlevel atomic operation these requirements and the lack of parallel compositionality limit the applicability of their method it is if the method can be used for general verification of transformations such as concurrent et al prove linearizability by incrementally rewriting the finegrained implementation to the atomic abstract specification their behavioral simulation used to characterize linearizability is an subset relation with requirements on the orders of method invocations and returns their rules rely on ie operations that can commute over any operation of other threads and always rewrite programs to instructions thus are designed specifically for atomicity verification in his thesis vafeiadis proves linearizability of concurrent objects in logic by introducing abstract objects and abstract atomic operations as auxiliary variables and code the refinement between the concrete implementation and the abstract operation is implicitly in the unary verification process but is not out formally in the metatheory eg the soundness verifying concurrent et al define transformations to generate concurrent from an abstract collector et al present refinements to derive concrete concurrent from specifications these methods focus on describing the behaviors of variants or instantiations of a correct abstract collector or a specification in a single framework assuming all the mutator operations are atomic by comparison we provide a general correctness notion and a proof method for verifying concurrent and the interactions with mutators where the barriers could be finegrained furthermore the correctness of their transformations or refinements is expressed in a way eg the target gc should mark no less objects than the source which cannot be used to justify other transformations et al verify gc using concurrent separation logic to validate the gc specifications they also verify a representative mutator in the same system in contrast we reduce the problem of verifying a concurrent gc to verifying a transformation ensuring semantics preservation for all mutators our gc verification framework is inspired by et al who propose a framework for separate verification of and incremental and their mutators but their framework does not handle concurrency conclusion and future work we propose rgsim to verify concurrent program transformations by describing explicitly the interference with environments rgsim is compositional and can support many transformations we have applied rgsim to reason about optimizations prove atomicity of finegrained concurrent algorithms and verify concurrent garbage collectors in the future we would like to further test its applicability with more applications such as verifying stm implementations and compilers it is also interesting to explore the possibility of building tools to the verification process acknowledgments we would like to thank matthew parkinson and anonymous for their suggestions and comments on earlier versions of this paper this work is supported in part by grants from national natural science foundation of under grant no and is also supported in part by under grant no by program for new in and by the fundamental research for the central references m abadi and g plotkin a model of threads in proc th acm symp on principles of prog lang popl pages ­ acm press january k o i e k v y a and e a parallel incremental mostly concurrent garbage collector for servers acm trans program lang syst ­ n benton simple relational correctness proofs for static analyses and program transformations in proc th acm symp on principles of prog lang popl pages ­ acm press january n benton and ck and compiler correctness in proc th acm intl conf on functional prog icfp pages ­ acm press september boehm threads cannot be implemented as a library in proc acm conf on prog lang design and pldi pages ­ acm press june boehm and s v foundations of the c concurrency memory model in proc acm conf on prog lang design and pldi pages ­ acm press june boehm a j demers and s mostly parallel garbage collection in proc acm conf on prog lang design and pldi pages ­ acm press june s d full abstraction for a parallel language inf comput ­ s m and v verifying local transformations on relaxed memory models in proc th intl conf on compiler construction cc volume of lecture notes in computer science pages ­ springer march coq development team the coq proof assistant reference manual the coq release v october d o and n transactional locking ii in proc th intl symp on distributed computing volume of lecture notes in computer science pages ­ springer september t s qadeer a o and s simplifying linearizability proofs with reduction and abstraction in proc th intl conf on tools and algorithms for the construction and analysis of systems tacas volume of lecture notes in computer science pages ­ springer march i p ohearn n and h yang abstraction for concurrent objects in proc th european symp on prog esop volume of lecture notes in computer science pages ­ springer march d s and m wand compiler correctness for concurrent languages in proc st intl conf on coordination languages and models coordination volume of lecture notes in computer science pages ­ springer april m and n the art of multiprocessor programming morgan april ck and d dreyer a kripke logical relation between ml and assembly in proc th acm symp on principles of prog lang popl pages ­ acm press january c b jones steps toward a development method for programs acm trans program lang syst ­ k k and u finegrained concurrency with separation logic j logic ­ x leroy a formally verified compiler j reason ­ december h x and m fu a simulation for verifying concurrent program transformations technical report with coq implementation university of science and technology of october a verifying a compiler for java threads in proc th european symp on prog esop volume of lecture notes in computer science pages ­ springer march a z shao c lin and l li a general framework for garbage collectors and their mutators in proc acm conf on prog lang design and pldi pages ­ acm press june m parkinson r and c calcagno variables as resource in hoare logics in proc th ieee symp on logic in computer science lics pages ­ ieee computer society august d p and d r smith formal derivation of concurrent garbage collectors in proc th intl conf on mathematics of program construction volume of lecture notes in computer science pages ­ springer june j s v vafeiadis f z s and p sewell concurrency and verified compilation in proc th acm symp on principles of prog lang popl pages ­ acm press january r k system programming with parallelism technical report rj ibm research center a and m wand a separation logic for refining concurrent objects in proc th acm symp on principles of prog lang popl pages ­ acm press january v vafeiadis modular finegrained concurrency verification technical report university of cambridge computer laboratory july v vafeiadis and m j parkinson a of relyguarantee and separation logic in proc th intl conf on concurrency theory concur volume pages ­ springer m t e and d f derivation of concurrent garbage collection algorithms in proc acm conf on prog lang design and pldi pages ­ acm press june m wand compiler correctness for parallel languages in proc conf on functional prog lang and computer architecture pages ­ acm press june h yang relational separation logic theoretical computer science ­ 