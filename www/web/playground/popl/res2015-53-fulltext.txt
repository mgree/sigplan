program program synthesis via robert a university of north david microsoft research university of pennsylvania benjamin microsoft research microsoft research abstract in this paper we investigate an approach to program synthesis that is based on with the help of we aim to capture the of the to find good if not perfect solutions to inherently programming tasks which even developers and lack an specification we propose an approach we call program which involves solutions to a difficult programming problem from developers and then these programs together in a way that improves their correctness we implement this approach in a system called and show in our experiments that interesting and highly nontrivial tasks such as writing regular expressions for or email addresses can be effectively we demonstrate that carefully the results together consistently produces a yielding results that are better than any of the starting programs our experiments on program pairs show consistent in accuracy and demonstrate that program can be performed at a relatively cost categories and subject descriptors f theory of computation formal languages h information systems computing d programming techniques automatic programming keywords program synthesis symbolic automata regular expressions introduction programming involves solving numerous small but necessary tasks some of these tasks are fairly routine others are surprisingly challenging examples of challenging tasks include coming up with a regular expression to recognize email addresses or an input string to avoid sql injection attacks both of these tasks are easy to describe to most developers yet both are surprisingly difficult to get right permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than acm must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ copyright © acm ie to implement while properly addressing all the corner cases furthermore there is of room for ambiguity in both tasks for example even developers can as to whether or are valid email addresses or whether removing all characters outside of the a za z set is a valid sanitization strategy for preventing sql injection attacks these tasks are there may not be absolute consensus on what solution is correct moreover different people may get different parts of the solution wrong what if we could pose these programming tasks as a challenge we would be able to describe the task in question in a very form of specification with all its inherent and corner cases we would subsequently use the of the to arrive at a solution without having a precise specification a priori but perhaps with some positive and negative examples giving us a partial specification this paper this simple idea and expands on previous into the use of to help with technically challenging programming problems our implementation shares some of the highlevel goals with systems such as and in search of perfect url validation in december a web from set up a page to collect possible regular expressions for matching url matching turns out to be a surprisingly challenging problem while may define formal grammars for it is nontrivial to construct a regular expression that can be used in practice from these specifications to help with testing the regular expressions a collection of both positive and examples that is strings that should be accepted as proper or rejected while some example are as simple as others are considerably more complex and require the knowledge of allowed protocols should be rejected or the range of numbers in ip addresses which is why http should be rejected this challenge to his on soon a total of responses were collected as summarized in figure note that the of responses were incorrect at least in part while all regular expressions correctly captured simple such as they often would on some of the more subtle inputs only one participant with a handle of to get all the answers right user close getting all positive inputs right but missing some of the negative inputs notably this experiment performed by was a specific form of program key observations while a detailed analysis of this experiment is available at http a few things are clear · the problem by is surprisingly complex moreover it is a problem where it is easy to get started and get to a certain level or accuracy but getting to perfect precision on the example set is very difficult · potential answers provided by developers range in length ­ and accuracy ­ a great deal as measured on a set of examples note that the most accurate answer provided by is in this case not the longest · developers get different portions of the answer wrong while a particular may the url scheme but remember to include optional port numbers that follow the host name another may do exactly the opposite · combining or partially incorrect answers may yield a correct one inspired by these observations program is a technique that combines programs using the technique of programming to yield a solution of higher quality a way of combining individual to improve the accuracy is referred to as classifier in machine learning hence of our choice of the term program this technique is especially helpful for problems that a precise specification other domains for program the experimental results in this paper focus on the regular expression domain regular expressions represent a limited but very important class of programming tasks which maintain decidability of many important properties unlike programs written in generalpurpose languages like c or java however we feel that a wide range of problems are captured by the model outlined above just like with other general techniques we cannot really all domains in which may be valuable but we give several examples below security sanitizers security sanitizers are short routines that are crucial in preventing attacks in web applications yet programming these sanitizers is to be a difficult task sanitizers written in domain specific languages have properties that allow for automated manipulation and reasoning about program behavior but human is still required when a specification is not precise reasoning about sanitizers amounts to reasoning about transducers we feel that algorithms similar to those presented in this paper can be developed for transducers as well program can incorporate powerful new techniques for program analysis with the efforts of both and human insight merging code we the application of program in other domains as well for example while it would be difficult to mix the code from several java program directly we can imagine how the space of possible combinations of code written by different developers could be explored to find an optimal result as by the the full from can be obtained from the address source true true overall length positive negative accuracy v figure representative regular expressions for obtained from for every possible solution we show its length true and false positive and the overall accuracy the last row is the combining static analysis checkers the precision of static analysis checkers or bug finding tools can be improved via them together one scheme could be to have multiple checkers for null dereferences on a particular potential violation another would be to machine learning and program analysis by training a decision tree which determines which checker to apply in response to a range of local static features web site layout in web site design ab testing is often used to measure design changes and their observable influence on behavior building on the idea that the is always right program could be used to construct a layout engine that results which are most to the user the key thread linking these application areas together is that a problem exists where the overall specification and how it should be implemented are difficult to down but it is easy to indicate whether a given solution is correctly operating on a single input defining effective operations for each of these domains remains a separate research challenge which we only address for regular expressions contributions our paper makes these contributions · we propose a technique we program program is a program generation or synthesis technique that uses a set of initial programs and combines or them to provide a better result according to a function · we show how to implement program for regular expressions we propose a programming technique with and mutation operations we propose a new programming paradigm in which the function is along with the candidate programs · we implement our program technique in a tool to generate complex regular expressions we represent regular expressions using symbolic finite automata sfas which enable representation while supporting large alphabets we adapt classic algorithms such as edit distance to the symbolic setting to the best of our knowledge ours is also the first work that uses programming on automata over complex alphabets such as · we evaluate program techniques on four case studies in our experiments on a set of pairs of regular expression programs we observe an average in accuracy of which is a significant improvement on already input programs examples function mutation function µ example generator function budget output program function µ while do until perfect or no new examples for this generation for all i j do for all i j do i and j generate new examples add this candidate to end for end for for all i do for all do i generate new examples add this candidate to end for end for get consensus on these new examples via f and update budget add the newly acquired examples update candidates end while return return program with best end function figure program implemented as an iterative programming algorithm given a set of initial programs the program algorithm proceeds in in the context of our number example these initial programs may be the two initial regular expressions at every generation it performs a combination of and mutation operations in our example this may individual parts of the regular expression to handle number like and as a form of refinement new examples are added to the training set as an example in our regular expression implementation the goal of refinement is to state coverage by considering cases such as or as either valid or invalid numbers to be added to the training set finally the candidates with the are chosen to continue to the next generation initial programs and continuous refinement of the training set are key of program and more standard programming program algorithm figure shows our program algorithm as let be the set of all programs and be the set of all inputs in every generation we update the set of currently considered programs and the set of current examples note that the algorithm is iterative in nature the process of proceeds in similar to the way programming is typically implemented the overall goal is to find a program with the best in at each generation new examples in are produced and sent to the to obtain consensus the algorithm is parametrized as follows · is the initial set of programs · is the initial set of positive and negative examples · × is the function that takes two programs and produces a set of possible · µ is the mutation function that given a program produces a set of possible programs · × given a program and a set of examples generates a new set of training examples · n is the function · n is the budget for mechanical later we show how to implement operations that correspond to functions µ and for regular expressions using sfas note that in practice in the interest of faster we usually limit the number of iterations to a set limit such as our implementation benefits greatly from parallelism in particular we make the two loops on lines and of the algorithm parallel while we need to be careful in our implementation to avoid shared state this relatively simple change ultimately leads to on a machine with or unfortunately our to the on line to get the consensus are inline this does lead to an in practice as tend to have a associated with finding and starting new tasks even if their is quite high in the future we a slightly more architecture where allowing speculative exploration of the space of programs may allow us to invoke calls regular expressions in this section we instantiate the different parts of the program algorithm for the regular expression domain we first describe symbolic finite automata and show how they are used to represent regular expressions in our implementation next we present algorithms for mutation and example generation used by the algorithm in figure symbolic finite automata while regular expressions are and relatively easy to understand they are not easy to manipulate in particular there is algorithm for or them directly we therefore opt for finite automata classic deterministic finite automata many closure properties and however each dfa transition can only carry one character causing the number of transitions in the dfa to be proportional to the size of the alphabet when the alphabet is large has elements this representation becomes symbolic finite automata sfas extend classic automata with symbolic alphabets in an sfa each edge is labeled with a predicate rather than a single input character and this allows the automaton to represent multiple concrete transitions for example in the sfa of figure the transition from state to state is labeled with the predicate s because of the size of the set this transition in classic automata would be represented by of concrete transitions before defining sfas we first need to introduce several preliminary concepts since the guards of sfa transitions are predicates operations such as automata intersection need to manipulate such predicates lets consider the problem of two in classic automata intersection if the two respectively have transitions p a p and q a q the dfa also called the product will have a transition p q a p q now if we want to two sfas this simple synchronization would not work if two sfas respectively have transitions p p and q q where and are predicates the sfa will need to the two transitions only on the values that are both in and therefore the new transition will be p q p q where the guard is the conjunction of the two predicates and moreover if the predicate defines an empty set of characters this transition should be removed this example shows how the set of predicates used in the sfa should at least be closed under conjunction and the underlying theory should be decidable we can check for satisfiability it can be shown that in general in order to achieve the classic closure properties of regular language the set of predicates must also be closed under negation lp la ln figure computation for an sfa a the dashed regions represent the strings on which a is correct definition a boolean algebra b has components db pb f ¬ db is a set of domain elements and pb is a set of predicates closed under boolean connectives ¬ and pb the denotation function f pb db is such that f db f f f f and f ¬ db f for pb we write when f and say that is satisfiable we say that b is decidable if is decidable we can now define symbolic finite automata definition a symbolic finite automaton sfa a is a tuple b q q f where b is a decidable boolean algebra called the alphabet q is a finite set of states q q is the initial state f q is the set of final states and q × pb × q is a finite set of moves or transitions in the following definitions we refer to a generic sfa a we say that a is deterministic if for every state q q there do not exist two distinct transitions q q and q q in such that we say that a is complete if for every state q q and every symbol a db there exists a transition q q such that a f in this paper we only consider deterministic and complete sfas and for this class of sfas we can then define the closure of as q q and for all a d and s d q as q s if q q such that a f the language accepted by a is la s q s f bdd algebra we describe the boolean algebra of binary decision diagrams bdds which is used in this paper to model sets of characters that are used in regular expressions a bdd algebra is the powerset algebra whose domain is the finite set for some k consisting of all nonnegative integers less than k or equivalently all a predicate is represented by a bdd of depth k the variable order of the bdd is the reverse bit order of the binary representation of a number in particular the most significant bit has the lowest the boolean operations correspond directly to the bdd operations is the bdd representing the empty set the denotation f of a bdd is the set of all integers n such that a binary representation of n corresponds to a solution of for example in the case of over the alphabet we use the bdd algebra bv to naturally represent sets of characters we consider the sfa and bdd implementations from the symbolic automata computation recall that as part of the programming approach employed in program we need to be able to the of a particular program for regular expressions this amounts to calculating the accuracy on a training set the process of calculation can by itself be quite this is because running a large set of examples and counting how many of them are accepted correctly by each produced sfa is a process that quite when we consider of sfas and of examples instead we construct sfas p and n which represent the languages of all positive and all negative ex input sfas a q q f a q q f output all of a and a function a c c for all c c do c c c a c for all t p p exit a do for all c c do for all i entry a do c c c a c for all c c do for all t q q exit a do for all c c do for all i entry a do t p i t q i new t t t t yield return q q q f f new end function function exit a return p q a p c q c end function function entry a return q qa p q ap c q c q qa end function figure algorithm respectively for any sfa a we then compute the cardinality of the intersection sets la lp and ln la see dashed regions in figure both of which can be computed fast using sfa operations the accuracy can be then computed as la p ln n and will range from to a challenge inherent with our refinement technique is that our example set can greatly from the initial set while we still want to treat the set as a more reliable source of truth to this end we use to give the set a higher weight in the overall calculation in our experimental evaluation we get good results if we set weights to a operation two sfas into a single sfa that combines their behaviors an ex of this operation is illustrated in figure given two sfas a and b the algorithm creates a new sfa by two transitions one from a to b and one from b to a the goal of such an operation is that of using a w w component of b inside a the algorithm is shown in figure in all of the following algorithms we assume the sfas to be minimal v v an sfa can have many transitions and trying all the possible figure can be concretely if a has n states and m transitions and b has n states and m transitions there will be possible and checking for this many sfas would not scale we several heuristics that try to such by limiting the number of possible the first technique we use is to guarantee that if we leave a by a transition q q to b and come back to a from b with a transition that reaches a state q in a then q is reachable from q but different from it we write q q and if we reach b in a state p and leave it by a transition p p then p is reachable from p we write p p following these rules we only generate automata for which there always exists an accepted string that traverses both the transitions the next heuristics limit the number of interesting edges and states to be used in the algorithm by multiple states into single component and only considering those edges that from one component to another one in the algorithm in figure the reachability relation is naturally extended to components set of states the function components returns the set of state components computed using one or more of the heuristics described below components our first strategy states that belong to a single strongly connected component are easy to compute and often capture interesting blocks of the sfa in several cases do not enough states consider the sfa in figure in this example the only scc with more than one state is the set ­ moreover most of the number are represented by acyclic sfas causing the to be completely to address this limitation we introduce a strategy for a is a maximal connected acyclic subgraph where every node has degree smaller or equal than in the sfa in figure and are components even using the is often consider again the sfa in figure the set of nodes looks like it should be treated as a single component since it has a single entry point and a single exit point however it is not a this component clearly captures an independent part of the which accepts the correct protocols of a url such a component is characterized by the following features it is a connected direct acyclic subgraph it has a single entry and exit point it does not start or end with a and it is maximal it is not con in a component with properties ­ such components can be com figure identifying components in linear time by using a variation of depthfirst search start ing in each node with smaller or equal than the requirement is achieved by consider ing the nodes in topological sort since are already the induced graph is acyclic since this technique is generally more effective than we use it before the in the sfa in figure the final components will then be and finally if a has c components and t transitions between different components and b has c components and t transitions between different components then there will be pos input sfa a q q f and string w output set of new training strings function w c q while c do q remove a sfa q s w c c states a yield return s end while end function language of all strings in a passing through state q function sfa q return q q q q f end function figure example generation in practice this number is much smaller than one way are a variant of those described above in which we one edge from a to b but we do not come back to a on any edge if a has t transitions between different components and b has c components then there will be oct possible mutation in its classic definition a mutation operator one or more values of the input program and produces a one sfas have too many values to be every transition can carry elements and a approach would produce too many instead we consider a approach in which take as input an sfa a and a counterexample s such that s is classified by a s is a positive example but it doesnt belong to la or s is a negative example but it belongs to la using this extra bit of information we a only in those ways that will cause s to be correctly classified the intuition behind such operations is to perform a minimal syntactic change in order to correctly classify the counterexample given a negative example and an sfa a such that s la generate an sfa a such that la la and s la given a string s a an that is accepted by a the algorithm finds a transition q q that is traversed using the input character ai for some i when reading s and either removes the whole transition or simply the guard to the symbol ai given a string of length k this mutation can generate at most k sfas given the state q f such that q s q we also output the sfa a q q f q in which the input sfa is by removing a final state given a positive example and an sfa a such that s la generate an sfa a such that la la and s la given a string s a an that is not accepted by a the algorithm finds a state q such that for some i q a ai q and a state q such that for some j i q aj an f next it adds a path from q to q on the string ai aj this is done by adding extra states it is easy to show that the string s is now accepted by the sfa a given a string of length k and an sfa a with n states this mutation can generate at most nk sfas when there exists a state q such that q s q we also output the sfa a q q f q in which the input sfa is by adding a new final state example generation generating one string is often not enough to characterize the language of an sfa in generating examples we aim to follow a examples generated randomly b examples generated with the edit distance approach starting with the string figure two approaches to examples generation compared the following invariant we full state coverage for the sfas we allow to proceed to the next generation for each sfa a q q f we generate a set of strings s la such that for every state q q there exists a string a an s such that for some i q a ai q the example generation algorithm is described in figure given an sfa with k state it terminates in at most k iterations the algorithm simply generates a new string at every iteration which is forced to cover at least one state which yet been covered unfortunately this approach to generate strings that look random causing to be conservative by all of the generated strings as negative examples even when they are not for example we have observed a strong towards strings that use characters in the case of we often get strings containing upper elements such as characters which look to we would like to generate strings that look as close to normal as possible edit distance we solve this problem by using the knowledge encoded in our training set of inputs we choose to look for strings in a that are close to some example string e in the training set we can formalize this notion of by using the classic metric of string edit distance the edit distance between two strings s and s eds s is the minimum number of edits insertion deletion and character replacement that transforms s into s given an sfa a and a string s la we want to find a string s a such that eds s is minimal in the case of there exists an algorithm that given a string s and a dfa a computes the metric ss la representing the minimum edit distance between s and all the strings in la we symbolically extend the algorithm in to compute the minimum edit distance for sfas and we modify it to actually generate the witness string the algorithm has complexity where n is the number of states in the sfa as an illustration figure a shows some examples of randomly generated strings and figure b several strings generated using the edit distance technique clearly the second set looks less random and less to an average mechanical experimental evaluation to evaluate our implementation of program we face a fundamental challenge there is no easy definition of correctness because the problems we are to solve do not have a clearly defined specification recall that our framework is designed to a notion of correctness as the provides the algorithm in actually has a in the base case of the dynamic program when computing the value of v t s c in page the otherwise case does not take into account the case in which t s and t has a self loop on character c we fix the definition in our implementation task numbers specification examples ­ figure specifications provided to the last two columns capture the number of positive and negative examples a subset of the set given to in the task specifications time pm solution pm updated solution pm pm pm pm solution updated solution updated solution pm pm updated solution pm pm am am am pm left comment pm updated solution pm left comment pm pm pm solution question question updated solution solution solution left comment left comment updated solution solution figure the experience of initial for at more feedback which is then incorporated into the solution therefore our goal in this section is to describe the experiments on four different regular expression tasks and demonstrate that our technique can both refine an initial specification and construct a solution that performs well on the both and initial specification before we describe our experiments we first outline our in addition to regular expressions from an online library of and other sources etc we the creation of initial regular expressions using a service that allows users to post a coding task or technical question to the site along with a starting at as little as typical on are ­ we four separate character length sfa state count max max numbers figure summarized size and complexity of the candidate in our case studies other url figure of candidate regular expressions evaluated on set set task initial no initial no numbers figure in each task category results are shown via values measured on either the set or the set for three separate initial no and figure shows the distribution of initial accuracy values by source somewhat surprisingly the initial values obtained through are higher than those obtained from a library of regular expression specifically designed to be reused by a variety of developers overall initial values between and with none of the being either too good or too bad of course starting with initial regular expressions creates less room for growth results our experiments center around pairwise for the four chosen tasks numbers we test the quality of the regular expressions obtained through by the accuracy on both positive and negative examples our measurements are performed both the set and the set we consider the measurements on the set to be more representative because the set is entirely under our control and could be manipulated by adding and removing examples to influence accuracy measurements the set on the other hand naturally through refinement and obtained mechanical consensus figure captures our highlevel results obtained from the process we display the the mean values for the task generated strings consensus max max max numbers figure characterizing the process the generated strings column demonstrates that the size of the set for each experiment pair depending on the number of strings created to cover the generated on each task we show results as measured both on the set of examples and the expanded set we see that our process consistently results in across the significant improvements can be observed by comparing columns and the average across all the tasks is it is worth pointing out that having a stable technique that produces consistent for a range of programs is both very difficult and important to make our approach note also that on the larger set the advantage of having a columns and is more than on the smaller set process figure characterizes the process in three dimensions the number of the number of generated strings and the measured consensus for classification tasks for each of these dimensions we provide and max numbers in of a histogram note that we limit the number of to however about half the pairs for the task finish in only for there are always required none of the results converge the number of generated strings is relatively at for this suggests that the total costs for mechanical should not be very high the classification consensus is very high overall this is largely due to the our candidate string generation technique by making strings look nice it prevents a wide of figure provides additional statistics for the and mutation process across the tasks in the and max format used before across the the number of produced during is in of yet only a very small percentage of them succeed ie to the next generation this is because for the the is too small to keeping them around the number of is smaller only in single and their rate is somewhat higher this can be explained by the fact that are relatively local transformations and are not nearly as as the overall experience is not in algorithms running times figure a shows the overall running time for pairwise for each task the means vary from about per pair and per pair numbers completes than note that for the times are relatively low this well with the low number of generated strings in figure making the process run faster may involve having mechanical on and is the subject of future work costs figure b shows the costs of performing program across the range of four tasks the overall costs are quite ranging between ¢ and per pair we do see on the high end about some pairs do not require mechanical at all resulting in zero cost task numbers max successful max max figure successful propagation of candidates successful max time per pair date email url date email url a running times for each task b costs for mechanical figure running times and costs discussion we see the following main challenges with the program approach in this paper we aim to provide solutions to only some of these challenges addressing all of them in a manner will require much subsequent research low quality of responses just like with other tasks our approach from response quality challenges both because the participant is mechanical think that characters are not allowed within or because they are trying to game the system by providing an answer that is either random or obviously too broad such as for regular expression tasks makes the same if every gets the same corner case incorrect and approaches are not going to be very helpful will for the same outcome raising our in the wrong solution analysis of security sanitizers in illustrates that sometimes that may be the case on the training data just like with any other learning tasks the answer model to the data is a potential problem one way to this is to force generalization either explicitly or through limiting the size length or number of states or another similar metric of the selected program for instance we could smaller regular expressions in our selection program complexity is too high while it is possible to programs together to achieve good results on training and testing data it is desirable to produce resulting programs that are too complex to be understood in some cases since these programs will be used as black boxes this is fine in others this is not the case knowing when to stop in the context of knowing when to stop answers is difficult even if you have absolute agreement among existing it is not clear that more questions may not eventually yield about a corner case the current approach in this paper does not use a more flexible approach to getting the desired level of although several techniques have been proposed and it is not clear how to properly the whose programming efforts become into the there are property issues to with there is the question of whether the should be beyond their initial as the software to which they have becomes successful the time it takes to solutions from the is a major issue in getting program results faster in the future it may be possible to have a set of on with faster response times another option is to design a more asynchronous approach that would explore the program space because we are the training set it is possible that in earlier we programs that in later would appear to be more fit one way to for this kind of is to either the evaluation once the set has been or to some of the previously rejected programs from past into the mix at later stages related work recent work has investigated the of human computation into programming systems several platforms have been proposed to abstract the details of services away for the programmer making the issues of quality control and cost easier to and take different approaches to the problem of making programming easier the former enabling usage of to solve tasks well suited for and the latter enabling between programmers another approach to using is to break large programming tasks into small independent our work progress towards the goal of solving difficult programming problems by a of mixed levels and using formal methods to combine efforts from these multiple algorithms in general algorithms alter structures that represent members of a population to produce a result that is better according to or optimality conditions early work finite state machines to predict symbol sequences others have extended these techniques to build modular systems that incorporate independent to solve and grid exploration problems or to predict note sequences in compositions in software engineering algorithms have been applied to software bugs and software optimization programming is a of algorithms focused on programs an approach has also been applied to design where iteratively improved and design of a and clocks our work introduces a novel use of to both initial programs and to automatically refine the training set and the function through program analysis and synthesis in the theory of abstract interpretation widening operators are used to compute a valid abstraction for some function our use of the mutation and operations to refine or sfas follows the spirit of this ap and may be one path towards applying program to domains where abstract interpretation has seen much success eg static analysis recent work has investigated automatic synthesis of program fragments from formal and example based specifications a specification which defines program behavior can be viewed as a search problem for which constraint solvers or strategies can be applied these approaches use formal methods to aid in the construction of the lowlevel implementation of a specification in our technique the initial specification may be open to interpretation or not fully defined we take advantage of the to refine our specification and improve the correctness of a collection of implementations learning regular expressions automatic generation of regular expressions from examples has been explored in the literature for information extraction in the context of analysis events can be extracted from sequences by learning simple regular expressions that the relevant strings others use transformations on regular expressions themselves rather than a dfa representation in contrast our approach uses the power of symbolic automata to manipulate complex expressions containing large alphabets we are not aware of traditional learning approaches suitable for learning regular expressions that contain due to the large alphabet size learning inference is the study of learning a grammar by observing examples of an unknown language it has been shown that a learning algorithm can produce a new grammar that can generate all of the examples seen so far in polynomial time many variants of this problem have been studied including different language classes and different learning models relevant to this paper is the study of producing a regular language from labeled strings where the learning algorithm is given a set of positive and negative examples this problem has been shown to be hard in the worst case but many techniques have been demonstrated to be practical in the average case the algorithm can infer a accepting dfa but assumes that the target language is known and that grammars can be checked for equivalence with the target language recent results extend to large alphabets but still require strong assumptions about the oracle state merging algorithms relax the requirement for a minimal output and work by building a for the training examples and then merge states together that map to the same a number of extensions to this technique have been proposed approaches to learning a dfa from positive and negative examples have also been proposed conclusions this paper presents a novel approach to program synthesis called program our focus is difficult programming tasks which even the most of developers have with our insight is that the of the can be to bear on these challenging tasks in this paper we show how to use two a of developers and a of computer to successfully produce solutions to complex tasks that involve regular expressions we have implemented program in a tool called and have tested it on four complex tasks we have regular expressions from and several other sources and performed pairwise on them we find that our program technique is stable it produces consistent in accuracy when tested on pairs of programs even when starting with initial programs of high quality from qualified developers we are consistently able to achieve in accuracy references d learning regular sets from queries and counterexamples information and computation w p r e and f d programming an introduction d w c e d and a a platform for integrating and digital computation in proceedings of the conference on objectoriented programming systems languages and applications d f d and m automatic web data extraction based on algorithms and regular expressions in data and integration k and d a preliminary investigation into modular finite state machines in proceedings of the on computation b and s programming for software optimisation in proceedings of the conference on and computation p cousot and r cousot formal language grammar and program analysis by abstract interpretation in proceedings of the conference on functional programming languages and computer architecture l and m minimization of symbolic automata in proceedings of the symposium on principles of programming languages l j a j and m j artificial intelligence through simulated evolution s t w and c l a programming approach to automated software repair in proceedings of the conference on and computation u and a learning regular expressions from sequences in proceedings of the symposium on abstraction and approximation e m language identification in the limit information and control m g little and r c coding in the browser in proceedings of the workshop on and human aspects of software engineering a and d analysis of approaches to regular expression induction in proceedings of the on computation s gulwani string processing in using inputoutput examples in proceedings of the symposium on principles of programming languages t v and r interactive synthesis of code in proceedings of the on computer aided verification p b d p and m fast and precise sanitizer analysis with bek in proceedings of the usenix security symposium y on synchronized evolution of the network of automata ieee transactions on computation m and l cryptographic limitations on learning boolean formulae and finite automata journal of the acm r r d and r m controlled experiments on the web survey and practical guide data and knowledge discovery j r programming on the programming of computers by means of natural selection b c and p dfa induction algorithms with merge constraints in proceedings of the international on inference k j lang random can be approximately learned from sparse uniform examples in proceedings of workshop on computational learning theory k j lang b a and r price results of the one dfa learning and a new state merging algorithm in proceedings of the international on inference t d w b c m and a van der programming building software with a in proceedings of the symposium on user interface software and technology y li r s s and h v regular expression learning for information extraction in proceedings of the conference on empirical methods in natural language processing g little l b m and r c tools for iterative tasks on mechanical in proceedings of the workshop on human computation s m and t j reynolds learning dfa evolution versus evidence driven state merging in proceedings of the on computation s m and t j reynolds learning deterministic finite automata with a smart state labeling algorithm ieee transactions on pattern analysis and machine intelligence o and i e learning regular languages over large alphabets in tools and algorithms for the construction and analysis of systems j v y and l structures for the of design in workshop on and human computation j and p identifying regular languages in polynomial time in advances in structural and syntactic pattern recognition series in machine and artificial intelligence a g h park h n and j declarative in proceedings of the conference on information and knowledge management l and m k the minimum consistent dfa problem cannot be approximated within any polynomial journal of the acm r w b and n f a field guide to programming a j b b t and j lin integrating machine learning with mechanical for flexibility technical report university of college park r e the approach to machine learning an overview a program ­ s s gulwani and j s foster from program verification to program synthesis in proceedings of the symposium on principles of programming languages t e and m e ordered binary decision diagrams and the procedure in proceedings of the conference on constraints in computational m and n symbolic automata the in proceedings of the conference on tools and algorithms for the construction and analysis of systems r a correction for regular languages communications of the acm a appendix to provide intuition on the type of results produced by our technique we present two examples these are not necessarily the the results some of these are after several the complexity of the results is due to two factors the regular expressions are obtained using the classical transformation from automata which in general produces large results and the have to take into account many corner cases task email result z task numbers result xx x xx x xx x xx x xx x x xx x x xx xx x x xx xx x xx x xx x xx xx x 