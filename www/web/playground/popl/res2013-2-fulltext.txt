the sequential semantics of producer effect systems cornell university abstract effects are fundamental to programming languages even the lambda calculus has effects and consequently the two evaluation strategies produce different semantics as such much research has been done to improve our understanding of effects since moggi introduced monads for his computational lambda calculus further have been designed to formalize complex computational effects such as indexed monads followed by layered monads followed by parameterized monads this us to determine the most general formalization possible in searching for this formalization we across many such as the of arrows as well as many insights such as the importance of considering an effect as a small component of a whole system rather than just an isolated feature in this paper we present our semantic formalization for producer effect systems which we call a and prove its maximal generality by focusing on only sequential composition of effectful computations consequently that the existing monadic techniques are of categories and subject descriptors d programming languages formal definitions and general terms languages theory keywords effects monads thunks introduction effects have been around since the beginning of programming languages after all even programs written in the lambda calculus have effects some programs diverge and some programs their inputs how these effects interact determines the semantics of a program leading to strict or lazy evaluation depending on what choices are made yet despite their effects and their behavior remain fairly especially when one considers how data and types have been formalized we view effects and types as complementary systems so by improving our understanding of effects to match that of types we hope to the perspective of programming languages as a whole before we go any further we should define what we mean by an effect since this term has come to have different meanings in different for some an effect is a classification of a computation determined by some analysis ­ permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm for others an effect is with a monad indeed wadler and illustrated the connection between the former perspective and the latter perspective which we will refine within this paper what we mean by an effect is a classification of a computation independent of the values of its inputs and outputs for example writes to the heap is an effect but writes to the heap only if the input integer is nonzero is not thus whereas types classify the inputs and outputs of computations effects classify the of computations forming complementary classification systems more specifically we are avoiding the complexity of dependent classification systems in addition to the complexity of reasoning about effects in a manner this informal definition is much than what many might consider an effect for example its input satisfies our definition though it the input to the computation the meaning of this classification does not depend on the actual value of that input similarly uses variable x satisfies our definition these effects correspond to the use of context they are often since many consider freely accessible persistent contexts to be a basic part of programming languages even though such contexts are not necessarily present in or languages when we realized this assumption we had to our own notion of effect what we found is that effects like uses its input multiple times can be formalized as consumer effects because they reason about how a computation its inputs in fact many fundamental of behaviors of programming languages reflect these consumer effects unfortunately in order to keep this paper focused we must consider consumer effects to be outside of the scope at hand instead we will focus on the much more familiar dual notion that we call producer effects a producer effect reasons about how a computation produces its outputs for example may throw an exception instead of producing its output or may examine and alter the heap before producing its output are familiar producer effects here is where most existing work on effects lies and so likewise here is where we focus our attention the reason that producer effects are so common is that they are to the notion of computations meaning computations which have been delayed so that they can be treated as values indeed we will define an effect as a producer effect if all computations with that effect can be as pure computations for a domainspecific notion of purity from this basic property we will prove that the sequential semantics of all producer effects can be formalized by our framework as a result monads for his computational lambda calculus indexed monads layered monads and parameterized monads are subsumed by our framework and we will illustrate how these various arise from simple assumptions on the producer effects at hand as well as how those assumptions restrict the kind of information that the effect system can track as an example we present an effect system for ensuring shared memory is accessed only in critical regions the semantics of which is guaranteed to be by these existing systems because it violates their assumptions however we show how the semantics can easily be formalized with our framework to prove that the effect system prevents race conditions just as we restrict our scope to producer effects we also restrict it to sequential composition of computations there are many other forms of composition such as multiplicative composition for parallelism and for adjacent subexpressions additive composition for branching and coinductive composition for recursion and for loops we choose sequential composition because that is where existing research has focused its efforts we focus on just the one form of composition so that we may address its challenges in full we believe many of the insights and techniques in this paper can be adapted to other forms of composition though there is still of interesting work to be done there with our semantic framework which we call we provide a powerful solution to the problem of formalizing the sequential semantics of producer effects this solution is not to common assumptions such as freely accessible persistent contexts or higherorder functions enabling us to into more interesting semantic domains as well as narrow down the fundamental aspects of programming languages because it is so general not only does our framework provide a means for specifying the semantics of programming languages or first steps towards improving the of programming languages it also provides a metalanguage for discussing effects and their properties we will demonstrate how such a metalanguage the constructs in existing languages particularly in prior of effects this paper begins by first providing an example of an effect system greatly simplified for sake of section then we present monads and how they formalize the semantics of an effect in a slightly different light than prior such section we adapt this approach to our example effect system showing where and why monads need to be generalized section that concludes our portion of the paper we then move on to formalizing effect systems as and section we follow that by formalizing their semantics as and section with these established we illustrate how a variety of existing semantic frameworks are special cases of arising from extra assumptions on the structure of the effect system at hand section we then show what basic properties of a language with effects guarantee all its effects are producer effects and so using section finally we remark on higherlevel insights opportunities to expand existing semantic techniques and further directions to take our research in order to meet our goal of providing an abstract language for discussing and formalizing programming languages section effects for locking effects are a classification of computations independent of the explicit inputs and outputs of those computations sometimes effects are on top of an existing language in order to identify optimization opportunities or potential bugs other times effects are integrated into the type system for example java has checked exceptions and haskell uses monads in order to combine laziness and side effects in this paper we will demonstrate how patterns in applications of effects lead to patterns in the semantics of effects to demonstrate that these are just patterns and not necessarily inherent to effects we present a language that breaks from all of these patterns our language shown in figure has explicit synchronization and shared memory limited for simplicity in that there is only one lock and one shared integer clearly this is just a subset of a more realistic language with branches functions and actual par x z y z z x y z z e acquire locking release x get x z critical x z setx critical p prop ¯ p ¯ p sub p p p seq p p figure a language with effects e locking critical e critical e locking critical e locking critical e locking critical locking critical locking critical locking critical figure the effect system for as well as a much richer type system however our is just to address sequential composition so we strip down the language to sequential composition nonetheless even the semantics of this very simple language cannot be formalized using existing frameworks at least not in a way that allows the semantics to prove the desired properties of the effect system in particular the effect system for this language is intended to prove that whenever a lock is acquired it is subsequently released without being acquired again and every use of shared memory occurs within such a critical region before we get into the effect system let us explain at a high level the judgement p indicates that the program p context as its input produces context as its output and has overall effect note that is linear every value created is used exactly once there is one exception an integer stored to the shared state via set can be read multiple times via multiple gets we can do this because it is possible to implement a function z z in linear type theory one could make nonlinear by restricting its types to ones which have such a function we chose not to because it is orthogonal to the concerns of sequential composition and would make the denotational semantics of complex next consider the five primitive statements of and their effect we give addition the effect e which we call the basic effect and which more generally can be used for all effects not related to locking such as nondeterminism or memory allocation the statement acquire has the effect locking because overall it changes the state of the lock from free to release has the effect because overall it changes the state of the lock from to free get and set have the effect critical because they must occur inside a critical region finally consider the three generalpurpose rules prop allows unused context to propagate through a program without the effect while this is not necessary and indeed is not possible for all effect systems eg lowlevel effect systems we will show how this relates to the notion of strength used in existing semantic frameworks sub the notion of analogous to subtyping seq specifies how effects sequence statically these rules can easily be used for other languages so we give their separately in figure note that figure has an additional effect used to indicate code that enters and leaves a critical section possibly multiple times so though the code the state of the lock it first needs the lock to be free in order to execute this effect system has a number of attributes first the effects do not form a lattice in particular e is not a of every effect second not all effects can be not even necessarily with themselves this means that effects can influence the typability of a program third the order of the effects locking before is considered but the reverse is not allowed at all all these attributes have important consequences on the denotational semantics of and on the of existing frameworks but before we discuss those we should present the of denotational techniques for effects monads in standard constructions which known as triples which known as monads in moggi the concept of monads from the community to the semantics community in wadler carried this concept over to the community and in these concepts were realized as monadic programming and added to haskell to make io more convenient and to imperative functional programming the line between imperative programming and pure programming this has made monads the most well known technique for formalizing the semantics of effects here we show how a monad formalizes an effect but in a way that opportunities for generalization propagating an effect consider the expression ÷ x using integer division focus on the problem that expects its first argument to be an integer but the ÷ in the first argument may fail to produce one because ÷ is a partial operation in other words ÷ has the partial effect we might represent this by saying that ÷ has type z × z partial z we want to formalize what it means to have the partial effect moggi observed that we can do so by modifying the return type of ÷ in particular we can view ÷ as a function that returns an integer or a failure code we can define an algebraic data type to represent these two cases success failure then we can formalize ÷ as a pure operation z × z when a failure occurs any subsequent computations need to propagate this failure in particular if fails then should fail as well thus ÷ x also has the partial effect we can do this by making the pure computation vv from z to z instead take a and return a this is achieved with a map operation px case px x failure failure thus map turns a pure computation into one which takes an effect argument and propagates the effect in this case indicates that if a failure code is present then all computation should be and the failure propagated using map we can formalize the semantics of ÷ x as ÷ x we map the computation after the effectful operation so that it can take an effectful argument then pass the effectful result to this mapped computation which propagates the effect thus if ÷ x fails so does the entire expression this pair of a type constructor p type type and a function on computations map p p is called an on the category of types provided it satisfies a few additional equalities which we do not repeat here and this is just one part of a monad in the setting of effects the type constructor p indicates how a production of the effect can be described as data so that effectful computations can be represented as pure computations with a modified return value and the function map defines how to propagate the effect through pure computations sequencing effectful computations now consider a slightly more complex example ÷ x ÷ y here we are sequencing two effectful computations we can use the functor representation of the partial effect in order to formalize this expression ÷ y ÷ x the type of this formalization though is since the computation we mapped namely vv ÷ y also has the partial effect although having a partial value allows us to determine which ÷ failed in this case we are only concerned with whether any ÷ failed that is we want the effect of ÷ x ÷ y to be partial rather than conceptually partial we can this by using a monadic join operation to turn partial values into partial values case failure failure failure note that in this example there is only one effect in the whole system and this is why we can use a single monad some semantic frameworks generalize from one effect to multiple effects by using multiple monads but our semantic framework provides a more general system in which these approaches are special cases making pure computations effectful with the above structures we can sequence a nonempty list of effectful computations with pure computations together into a single effectful computation monads have one more component that enables an empty list of effectful computations from a type to itself to be turned into a single effectful computation this structure also enables pure computations to be turned into effectful computations it is known as the unit of the monad in this case pure values into partial values unit partial unit while it is important to be able to treat pure computations as effectful computations in order to handle computations uniformly a system with many effects need only have one effect with a unit in order to this this is important since it allows effects to express significantly more concepts as we will demonstrate later the operations for monads have a variety of equalities which must hold known as the identity and associativity laws we do not repeat those laws here rather we their consider the expression ÷ x ÷ y ÷ z this is essentially five computations together vv ÷ x vv ÷ y vv ÷ z and vv using the structures above we can sequence these computations maintaining order in a variety of ways depending on how we combine consecutive pairs and whether we turn pure computations into effectful computations or simply use structure to propagate effects through them but the result should be the same no matter which way is used we call this concept semantic and the monad laws are necessary and sufficient to ensure this for sequential composition semantics for locking with monadic techniques in mind let us consider how we might define a denotational semantics for first we need to choose a semantic domain on which to define all of our operations choosing a good semantic domain can enable the semantics to automatically ensure useful properties in this case we want to ensure that acquires match up with and gets and sets happen only inside critical regions selecting a semantic domain to this end we opt for linear type theory as our semantic domain since linear type theory already has a notion of counting built into it we use an abstract type l to denote a free lock and an abstract type c to denote the capability to access shared memory an abstract operation acquire converts a free lock l to a capability c and an abstract operation release does the reverse an abstract operation get the value of the shared state provided a capability c is present and an abstract operation set replaces the value of the shared state provided a capability c is present of course l and c actually stand for z but by hiding that information and ensuring every primitive operation and produces one l or c we are guaranteed that every acquire matches up with a release and all gets and sets occur in between these abstract constants and their types are summarized below l type acquire l c get c c z c type release c set c z l c representing effectful values next we must specify how to represent productions of each effect as data while we could define pe as simply we want to emphasize that e represents all effects not related to locking for example e could be nondeterminism in which case pe would be t as such we simply assume pe is some monad with operations and along with an operation of type pe pe which we will explain later as for the impure effects their semantics all have the form s transforms the state from s to s in particular the impure effects transform between l and c thus a computation with the locking effect must have access to a necessarily unique free lock l do some computation with effect e and complete with a necessarily unique capability to access shared memory c still available formalizing primitive operations once we have determined how to represent an effect we can give semantics to the primitive effectful computations the strategy formalizes the semantics of a judgement s as a term in linear type theory with the type p with this in mind we define the semantics of the primitive effectful computations in figure note that the semantic domain guarantees that only one portion of code can hold the lock at a time thus just the fact that these primitives can be expressed in that semantic domain ensures that they preserve that property this helps a language designer determine how they can safely extend the language since now they need only check that any potential new constructs are expressible in this domain propagating effects next we have to define how effects propagate through pure computations since the impure effects have the same shape they also use approximately the same map operation s x s f x gs x z y z z x y z z e m n n acquire locking release x get x z critical x z setx critical n figure semantics of the primitive effectful computations of sequencing effectful computations the most challenging semantic component is sequencing effectful components here is where we have to from monads after all not all of these effects are monads for example there is no join operation for locking to see why recall that a locking computation needs a free lock to be available and then removes that free lock it into a capability thus immediately after a locking computation there is no free lock available so there cannot be another locking computation that needs a free lock fortunately our effect system is designed to address precisely this problem in figure locking locking is undefined so that such programs are and we do not have to about sequencing two locking computations this suggests how we might generalize monads for sequencing computation suppose we had functions p a pb and p b p c representing effectful with different effects furthermore suppose were defined as then we should be able to combine p and p into a function of type a p c representing a computation from a to c with effect so far we can use map to get the following function pa a pp c this function essentially produces a effectful value like with monads but this time with two different effects so like with monads we need some way to turn this effectful value into a effectful value with just effect thus whenever is defined as we need the following operation to sequence the two effectful computations join pp p for there are four major categories of such basic followed by basic impure followed by basic basic followed by impure and impure followed by impure the first is simply assumed to be defined as discussed before the second is fairly simple to define e s note that this is simply the result of sequencing the linear function f s pe viewed as a computation with effect e with s pe also viewed as a computation with effect e what is doing is the context of the state s produced by f into the effectful value pe so that it can be accessed by subsequent computations unlike in haskell does not exist for all monads in linear type theory one exception is the error monad this is why languages with both errors and locks have to have special constructs for handling the case when an error is by a thread holding a lock similarly this is why many languages have constructs for data in the face of errors such as cs using construct for objects also we were careful to define nondeterminism using rather than which corresponds to the nonempty list monad used by parsers since the former has linear strength whereas the latter does not moving on the third is only slightly more complex to define sf f s f here we have an s and f is an value containing a function an s so once again we have to use and to give the contained function f access to the state s this results in a value so we use the fourth case is the most interesting regarding this paper ts s s g gs f s note that it is only defined when the intermediate state s for both effectful computations in which case it results in a effectful computation in fact when we consider just the impure effects we get an instance of parameterized monads a connection we will discuss in section with these components we can define the semantics of seq p f p f join p p f g effectful computations has another feature namely that we could not with monads since there was only one effect like subtypes the intuition for is that there is a way to coerce computations to the into ones to the as such whenever holds we need an operation with the following form coerce p p with we can define such coercions from the basic effect to an impure effect whenever the input and output states match up namely for critical and x using these coercions we can define the semantics of sub p f coerce p f g propagating context there is only one rule left to handle for prop is in a sense orthogonal to the concerns of sequential composition yet it is so common in languages that we include it for sake of discussion suppose we have some function f p denoting the semantics of p we want to extend f so that it propagates the values of an additional context ¯ through the computation it is easy to define the following function that does at least part of the job ¯ f ¯ ¯ p so the issue is that we need to the ¯ inside the p so that we have the necessary p ¯ this issue should look familiar since when sequencing the impure effects we needed some way to state inside of pe and so we use the same technique we used there in particular we need every effect to have a strength operation strength p p we already assumed such an operation has been defined for e so we need only define it for the impure effects again the strength operations for the impure effects all have the same form x f f s swap x s y s x y note that this strength need only be defined for types that can occur in a context so if one were to extend to be p n pn n n n seq p pn n figure assumed typing rule for effect systems nonlinear and ensure all types had an operation then the effects could use a nonlinear strength this way effect system could be extended with exceptions so long as one were to carefully track and define the interaction of exceptions with locking however since we already need the basic effect to have linear strength we make no such restriction on the types occurring in here we mentioned that prop is not necessary for sequential composition it comes from the notion that the context is freely accessible in lowlevel languages effectful operations may be required for even just accessing the context sometimes the context can be extended but only if the effect is as well for example in a lowlevel language it is the of the exception handler to the stack that at the point the exception was such a language might have an effect of the form where is the state of the stack at the point the exception was the effect may be represented as should the stack be extended prior to the exception then this must be encoded in the effect as such this language might have a rule like the following p ¯ p ¯ thus this effect has no need for strength we emphasize this example both to illustrate the origin of strength present in many existing and to illustrate the wide variety of languages our framework is capable of handling while so far we have been focusing on our example language the of this work is to apply to nearly all effect systems in this section we introduce to formalize effect systems as they to typing sequential composition of programs in the next section we then present our semantic framework for following that we show how existing semantic frameworks fit within our own finally we show what common properties of a language and its effect system guarantee that the semantics can be formalized with our framework for the sake of formalizing effect systems we assume the unknown language at hand admits the rule seq in figure the language may and should admit many other rules as well we simply need to know that it admits at least seq the symbol is a relationship from lists of effects to effects so that n indicates that is the overall effect of sequencing computations with effects through n in that order seq us that the effects of computations are independent of their specific inputs and outputs the modularity one would expect from an effect system thus we do not concern ourselves with some form of dependent effects note that we intend seq to include when n is corresponding to typing the empty program the following short may further the meaning of e means means means seq may not seem like much to work with but it actually provides some very useful structure in particular it is important to realize that given a sequence of computations say p p p the syntax p p p could be parsed as a whole or as p p p or as p p p or even as p p p with the empty program as such one can show that should and hold then we can assert that also holds without changing the effects of programs in light of this we formalize effect systems as follows definition a set along with a relation between and satisfying the following two properties identity associativity i n n n the identity rule says that sequencing an effectful computation with no other computations should have at least the same effect the associativity rule says that should one partition a list of effectful computations and sequence each partition together and then sequence each of those results together sequencing the original list all together should have at least the same overall effect this formalization may seem rather with respect to existing work on effects however when an is meaning the associativity implication is actually an there is an equivalent definition more to prior work theorem a can equivalently be defined as an a set along with a unary relation e a binary relation and a relation satisfying e r e r r ¯ ¯ ¯ reflexive congruence associativity identity e e proof the proof can be found in the technical report are common because compositional type systems are common conceptually if seq is actually an then the for the language is note that e does not necessarily imply is an identity in the usual sense for monoids it simply means that pure computations particularly the empty program can be given the effect we call such effects effects the effect system for is defined as a partial monoid this works because partial monoids are equivalent to a is one where for every list of effects such that holds for some effect there exists a minimal such with respect to are common for the same reasons type systems are common such as simplifying type checking and type inference note that not all are especially ones used in analyses for example an analysis may say that x p has the read effect and that p x has the write effect but then give x p p x the e effect even though generally those effects would combine into the readwrite effect the analysis is using information not contained in the descriptions read and write namely that the same value and pointer is used in both heap uses to reason that the programs semantics factor through the operation pure into readwrite computations and so can be treated as pure in general such typically arise when an analysis uses more detailed reasoning but reasoning thus while are extremely common the generality of is necessary to capture existing effect systems at last we present our semantic framework for sequential tion of effectful computations which we call a our goal is to give a denotational semantics to seq in such a way that all the many possible of p pn are guaranteed to produce the same semantics our fundamental assumption is that the semantics of the judgement p can be represented as a morphism p for some p definition for an a category sem with p map and natural transformations join n p ··· pn p n such that join is always the identity transformation and the following diagram whenever all terms are defined join join p · · · p join p · · · p join p n n nn n n notice the similarity between the commutativity requirements for and the requirements for the idea is to ensure that the many ways that a sequence of programs may be typed all correspond to the same semantics in other words the specific proof used to type check a program should be irrelevant to its semantics in the technical report we ensure precisely that for the following denotational semantics of seq p f n pn n n fn n p pn n f map fn one might why we about parsing ambiguity after all a language could always parse sequential composition like haskell does the reason is that by addressing ambiguity concerns we also address the kind of program transformations one would intuitively expect from sequential composition for example should f be defined as p p p g as the empty program and h as p then one would expect f g h to have the same semantics as p p p p this is precisely what our commutative diagrams ensure we have proven that when the is there is an equivalent definition of that may appear more familiar for those with existing semantic frameworks theorem a for an e can equivalently be defined as a a category sem with end p map along with natural transformations unit sem pe and coerce p p and join p p p such that coerce is always the identity morphism and the following diagrams commute whenever all terms are defined p p p unit coerce join p map unit join rr p p r p join ¯ p p p p map join join p p unit p coerce id p unit join p coerce p p p join proof the proof can be found in the technical report the requirements of an is essential to the above theorem using a for a meaning an not necessarily satisfying the relevant implications can indeed result in ambiguous semantics figure provides a example of such the intuition behind this example is that pure represents no effect err represents a possible error and indicates an error handler has been specified more precisely the must be a natural transformation ­ note that sometimes there can be many of such as error messages or even null in objectoriented domains a primitive operation error an error and a primitive operation sets the handler the definition of indicates that if the handler is set twice in a row the second handler should be used in place of the first one the interaction of handlers and exceptions is defined solely by the operation in particular this definition indicates that should an exception be then the previously set handler should be used to handle the exception and proceed with normal execution the result is that a computation has effect pure only if a handler has been set every place an exception might be one can check that these operations do indeed satisfy the requirements of our definition in theorem however h and h are handlers the following program still has two possible semantics error error in particular the program can result in h or h the program results in h if gets matched up with the first error via sequencing into a computation so that then can be matched up with the second error via sequencing into a computation resulting in h the program results in h if via and the two errors are combined via so that then can be matched up with error error sequencing into a computation resulting in h thus the specific proof used to show the program has effect pure actually the programs semantics semantic pure err pure pure err err err err pure × identity x h h x h px h case px x failure h figure a semantically and this was designed by a that violates our associativity requirement for for example and err pure hold but there is no such that err and pure hold as such one cannot transform either proof into the other using the required equivalences on the so they can produce different semantics this illustrates the of semantic for effect systems addressed by our framework because the does not satisfy the appropriate requirements the does not extend to a although not immediately apparent in general a actually has more equational requirements than a in order to maintain semantic it just happens to be that the requirements of an imposes enough structure on its to ensure they satisfy those additional equational requirements in general additional structure on the at hand imposes structure on its this will be a common during our discussion of existing semantic frameworks for effects existing frameworks while the components and requirements of a can be described the highlevel nature of this description can be as such it is helpful to see how existing semantic frameworks for effects can be seen as special classes of we start with the simplest such framework monads monads a monad m map unit join is a for the with one effect and with always holding m is simply p map is map unit is join and join is join the equational requirements for a monad are precisely those re by our definition of more generally for any with an effect such that e and hold called a idempotent effect any representation of is necessarily a monad monad morphisms a monad morphism coerce from a monad m map unit join to another monad m map unit join is a natural transformation from m to m such that the following diagrams commute m m unit m coerce coerce sem unit m join join m coerce m these equational requirements ensure that implicit coercions for effectful computations do not affect the semantics of the program in the same spirit as reynolds requirements for implicit coercions for data types as we mentioned monads correspond to idempotent effects furthermore given two such effects and with the additional property that is a of then the equational requirements for guarantee precisely that the corresponding natural transformation coerce join from p to p is a monad morphism thus both the concepts of monads and monad morphisms are special cases of indexed monads program analysis is one of the most common applications of effect systems such analyses typically use what is known as a system which code with a collection of atomic effects for example and taint code with how it accesses various heap regions and abadi showed that the dependency core calculus essentially takes this approach as well abstractly these effect systems form a join semilattice and the combined effect of a sequence of computations is the join of the effects of the individual computations with pure and empty computations being given the effect wadler and showed that one of and effect systems can be formalized by what has become known as an indexed monad an indexed monad is a join semilattice of monads connected by monad morphisms the semantics of sequencing effectful computations was defined by both computations to the least common and then using the join of that monad they did this for a single effect system but with our framework it is easy to determine that join semilattice are connected to indexed monads and in these cases the semantics of sequential composition are guaranteed to be defined with this strategy to see why consider the following properties of an where sequential composition of effects coincides with a operation they are guaranteed to be meaning all their effects are effects they are guaranteed to be idempotent meaning all their effects are idempotent they are guaranteed to be increasing meaning whenever holds then all elements of are of the first two properties already guarantee that a represents all effects as monads and furthermore all coercions between such effects must be monad morphisms thus a for any idempotent must be a network of monads and monad morphisms like an indexed monad all we have left to do is show why sequential composition must take the strategy theorem any increasing idempotent is for any of an increasing idempotent join is determined by coerce coerce and join proof first suppose n holds since the is increasing all effects in each i must be of since the is and idempotent holds for all these and the definition of imply that i holds thus since also holds the is second suppose holds since the is increasing i holds so must exist since the is idempotent holds so join must exist then by definition of since equals join must equal join join join which is the form of coerce coerce join in the other direction let us consider what kind of indexed monads can handle suppose an is represented by an indexed monad then that can be extended so that it is a idempotent increasing and furthermore commutative meaning if holds then holds for all permutations of this tells us three things the cannot guarantee properties that depend on an effectful computation occurring the cannot guarantee properties that depend on the order of effectful computations and the cannot guarantee properties that depend on the frequency of effectful computations first we know that an represented by an indexed monad cannot have effects that guarantee an effectful computation occurs since all effects are in it is important to distinguish computations that must lock from those that might lock in order to ensure accesses occur in critical regions in particular the must not a pure or empty computation for one that definitely locks so that whatever effect used to identify definite locking cannot satisfy e and so cannot be as such indexed monads cannot be used for that guarantee locking or guarantee eg a server always producing a response for each request second we know that an represented by an indexed monad cannot guarantee properties dependent on the order of operations since the is commutative in it is important to distinguish accessing shared memory after a lock from accessing shared memory before a lock yet if the were commutative then locking critical would necessarily equal critical locking so such computations would be in the as such indexed monads cannot be used for that need order sensitivity third we know that an represented by an indexed monad cannot guarantee properties dependent on the frequency of operations since each effect is idempotent in it is important to distinguish a lock once from a lock multiple times since prevents code however if locking were idempotent then locking locking would have to equal locking so that multiple would appear the same as a single acquisition as such indexed monads cannot be used for that want to track the of effectful operations these limitations of indexed monads were part of why we to find a more general framework the discussion here illustrates that not only are there advantages to having a more general semantic framework but our provide a useful language for discussing another reason why we our it also some importance for effect analyses since our indicate that have some limitations in what they can determine about a program we hope these insights will into new techniques and new semantic techniques layered monads introduced the semantic technique of layered monads a of a monad m map unit join over another monad m map unit join is a natural transformation layer m m m satisfying certain equational properties layer looks very much like our join operation for effects and should hold indeed equational requirements for are simply our equivalent requirements for of an increasing idempotent and uses the layer operation to sequence a computation followed by a computation as our framework would do with the corresponding join operation in more recent work allows users to build a tree of monadic with nontermination at the root of the tree so that programmers could build their own effect system any effect system designed in such a way is guaranteed to be an increasing idempotent and so has many of the key limitations that we discussed for indexed monads however there is one significant difference indexed monads necessarily correspond to total whereas tree of may not be total an is total if for every list of effects there is some effect such that holds this is not necessarily a limitation of approach though it has the advantage that it can express user effects that are incompatible with each other this is an important property for a modular language where users should be able to design their effects without about what other effects may be present elsewhere in the system should they never meet each other parameterized monads made the observation that many effect systems have to do with from one state to another indeed most of the effects in are used to indicate the required incoming state of the lock and the guaranteed outgoing state of the lock as such designed a parameterized monad to address this common case and showed how parameterized monads can formalize a variety of concepts such as composable continuations a parameterized monad is equivalently · a category s of states and primitive operations · a functor t map × s sem sem · an transformation unit s id t s s · an transformation join s s s t s s t s s t s s satisfying equational requirements we do not repeat here this should look slightly familiar in fact the cor to just the impure effects of is a parameterized monad the category s is just the discrete category with objects free and the conditions hold automatically since the category is discrete now it is important to note that a parameterized monad does two things simultaneously it specifies how to sequence computations and it specifies the semantics of primitive operations for example our semantics for acquire and release could be adapted into a parameterized monad for the free category generated by the graph with two objects and a morphism between them in each direction however the of our framework is only to formalize sequential composition of computations so we focus on a restricted subset of in particular we focus on parameterized monads where s is meaning there is at most one morphism between any two states such an s is actually a preorder and so represents states with a relation given such a set of states s and a preorder define an e s as follows · is s × s so that the effect s s represents computations that transition from state s to state s · e s s holds iff s s holds · s s s s holds iff s s and s s hold · s s s s s s holds iff s s s s and s s hold due to their definition all by parameterized monads are of this form theorem given a set of states s and a preorder there is a correspondence between parameterized monads for the category s and for the e s proof given a parameterized monad t map unit join for s define the for e s as follows · p ss map ss t s s · unit ss id units t s s t s s · coerce ss ss maps s s s · join ss ss ss t s s t s s maps s s s maps s s s t s s t s s join t s s the necessary equivalences hold due to the equational requirements of parameterized monads given a p map unit coerce join for e s define the parameterized monad for s as follows · t s s p ss map ss · maps s s s coerce ss ss · unit s unit ss · join ss s join ss s s ss the necessary equivalences hold to due to the equational requirements of these two processes are clearly of each other now that we have seen how parameterized monads fit within our framework let us consider the expressiveness of parameterized monads first a parameterized monad is not a family of monads while t s s forms a monad since the input and output are the same this is not the case for t s s whenever s and s are not equivalent to each other this is because e s s holds only when s is a of s and s s s s s s holds only when s is a of s so the e s is neither idempotent nor increasing in general thus the very notion of distinct states is by indexed monads and layered monads indicating how powerful parameterized monads are parameterized monads have their limitations though for example informationflow effect systems and contextual effects do not meet the requirements of theorem and so cannot be formalized using parameterized monads interestingly though should we allow for e s to be just a subset of s × s rather than all pairs of states then we can represent informationflow effect systems and contextual effects for example in the states are levels of secrecy so contains only those pairs s s where s is a lower level of secrecy than s since inputs can be propagated to outputs thus theorem suggests such effect systems must be by something very similar to a parameterized monad even such are still too restrictive for some for example the full for including the basic effect e cannot be formalized by a parameterized monad the issue is that ignoring since they are orthogonal to the following concerns a parameterized monad can only have one effect between any two states however both e and critical computations are permitted when the lock is acquired and finish with the lock acquired if we to prevent race conditions then we would want to distinguish e and critical computations since we should allow critical computations be ran in parallel with e computations but not with other critical computations furthermore if we to track other effectful attributes that are state such as nondeterminism then we would need multiple effects between any two states even just an indexed monad can be viewed as having many effects between a single state showing why indexed monads cannot be formalized by parameterized monads thus while parameterized monads are expressive there are still useful even by generalized parameterized monads but still expressible by our framework arrows and freyd categories arrows another generalization of monads are a little difficult to discuss because they are simultaneously too general and too restrictive first they have three components which we describe informally · a way to sequentially compose arrows · a way to turn a pure computation into an arrow · a way to propagate additional context through an arrow these three components must satisfy equalities which essentially indicate that the arrows form a category the pure computations form a pure and a pure computation can be executed an arrow without the overall effect of the arrow in fact the above intuition behind the equational properties has been formalized and proved that arrows are equivalent to freyd categories an attempt to formalize arbitrary effectful computations informally a freyd category is a premonoidal category a category with a notion of extending morphisms to propagate context with a wide cartesian monoidal of pure morphisms that can be executed other morphisms without their overall effect note that an important aspect of the above descriptions is the notion of extending and propagating context lies our primary of arrows and freyd categories what we determined is that nearly all of their structure has to do with extending and propagating context if one removes the components that are present to serve those roles ie anything using what remains is just a category of effectful computations with a wide of pure computations that is arrows and freyd categories say nothing about sequencing effectful computations besides the fact that sequencing pure computations results in a pure computation not to mention they only handle one effect so while arrows generalize strong monads they do so at the cost of most of the useful structure to work with it is for this reason that we focused on producer effects our suggest that being as general as possible means not providing any structure beyond a category with a distinguished generality the of this work is not to generalize prior semantic frameworks for effects but to design the most general such framework possible however as we just mentioned while discussing arrows the most general framework possible is not very useful as such we focused on producer effects and defined for formalizing producer effect systems here we show how a few language properties guarantee that the semantics of sequential composition forms a figure extends the language assumptions made in figure again while we assume these rules can be imposed upon the language at hand we expect the language will have a different syntax and more rules in addition to those we assume figure introduces two new judgements the judgement p indicates that p is a pure program with input and output for some notion of purity in prior work this separation usually is as values versus computations for example ocaml restricts type generalization to values rather than arbitrary computations however not all notions of purity may be restricted to values for example haskells notion of purity includes exceptions and nontermination here we let the designer determine their own notion of purity then we will show how effectful computations can be expressed by a on pure computations for whatever notion of purity the designer decided upon the other new judgement p p indicates that p and p viewed as effectful computations from to are semantically equivalent when is absent then they are semantically equivalent p seq n pn n p pn n p p p p p p p thunk p p eq p exec p exec eq exec p p exec p figure typing and semantic rules that guarantee when viewed as pure computations while not explicitly stated in figure we assume semantic equivalence is congruent with respect to sequential composition implicit coercion of pure computation into effectful computation and figure also introduces three new the operation maps an effectful program to a pure version of that program delaying its execution and treating it as a value in ocaml given an expression e e e would be fun e effectively delaying the evaluation of e by it into a function waiting for an input namely the operation maps a context to the context representing a effectful computation that would produce whenever it is executed ie the output of a computation p in ocaml e would be unit the operation exec is the program that finally executes a effectful computation in ocaml would be ie the program finally passing to the computation of the form fun e note that while our ocaml example defines the operations by the relevant program or context other examples may be done by a more translation for example if a language has sum types then an program can be done by recursively translating the entire program to left or right instead of an exception and to use pattern matching to explicitly propagate the exception thus a language does not have to be higher order in order to satisfy the requirements of figure the rules in figure formalize a number of language properties some of which are obvious and some of which are fundamental to the notion of producer effects seq indicates that pure computations are closed under sequential composition note in particular that the empty computation is pure indicates that sequential composition of effectful computations with pure computation preserves the effect of a computation this formalizes the idea that the effect of a computation is not dependent on the values of its inputs or outputs note that these rules combined with using the empty computation for seq admit the following p e p thunk and exec formally evidence the notion of producer effects first any effectful computation can be into a pure computation by modifying only the output in a uniform manner second there is a similarly effectful computation that executes a computation eq and eq essentially correspond to and equivalence for these constructs note that these are not the only rules of the language they are simply properties that may be upon a language in particular there can be and typically are many rules that operate on contexts of form so that exec is not the only operation that can be performed on a computation nonetheless regardless of what additional rules the language at hand may have so long as it admits at least the rules in figures and then it is guaranteed to be an instance of our framework with these we can finally present our fundamental theorem theorem if a language with an admits at least the rules in figures and then there is a map join using pure computations modulo semantic equivalence as sem such that the language admits the following p n pn n n n p pn n p map pn n proof define the as follows · p is already defined as · exec p · exec in the technical report using eq eq and congruence here we prove only the desired semantic property of sequential using approximately the same proof strategy first there is an important lemma given pure programs p and p from to if p exec is semantically equivalent to p exec then p and p are semantically equivalent the lemma assumptions and congruence imply that p exec is semantically equivalent to p exec eq then tells us that the former is semantically equivalent to p and the latter to p thus by transitivity p and p are semantically equivalent now to prove that p pn is semantically equivalent to p map pn n due to our lemma we can instead prove p pn exec is semantically equivalent to p map pn n exec so p pn exec is semantically equivalent to p pn by eq from eq and the definition of join exec is semantically equivalent to exec from eq and the definition of map p is semantically equivalent to p using that fact and eq we know that pi i pn n is equivalent to pi pi i pn n via induction p map pn n exec is equivalent to p pn taking advantage of congruence then p map pn n is also equivalent to p pn therefore the desired semantic property holds example our language does not actually satisfy the requirements of figure this illustrates that figure is sufficient but not necessary for our framework that our framework is useful even for formalizing languages without a notion of thunks nonetheless for sake of illustration we show how we might extend so that it models figure a sufficient extension of is shown in figure semantically we assume the usual and equivalences the first extension is a singleton type unit the second and more important extension is effectful function types in particular represents an effectful function accepting a as input and during execution assigning values of the appropriate types to the variables in thus this extension is like the computational lambda calculus with multiple effects mixed with a language with this language we can define the required judgements and operations in figure as follows p p e p t u u p t unit exec u t u that is a pure computation is one with the basic effect e works by the computation into a function waiting for a u x p u unit e f xp f e u unit u e f x f x figure extended with effectful functions unit value eliminating that unit value and then finally running the computation that function is stored into variable t so that results in an output context of the form t unit executing a computation then simply involves storing the unique value of unit into a variable and then calling the thunk with that variable as the argument thus causing the body of the function to finally execute these definitions clearly satisfy the requirements of figure thus our fundamental theorem implies that the semantics of extended can be formalized with a defined on just the extended computations with the basic effect e furthermore the theorem shows how to construct this closed freyd categories now we would like to existing frameworks to see what insights the assumptions in figure can offer as we discussed while freyd categories offer a lot of useful structure for working with contexts they provide little structure regarding sequential composition however power and recognized that strong monads arise for closed freyd categories this is no given our theorem since the structures that makes a freyd category closed are essentially the assumptions in figure similarly defined a notion of parameterized freyd categories and observed that closed parameterized freyd categories gave rise to parameterized monads again the additional structure for a closed parameterized freyd category corresponds to the assumptions in figure so this result is no given our theorem conclusion we have presented a semantic framework for sequential composition of computations with producer effects a concept we were able to formalize abstractly in particular we showed why the notion of makes producer effects so common in our discussions of existing frameworks we argued why it is important to restrict our attention to producer effects we illustrated how monadic frameworks fit within and used our framework to illustrate how properties of the effect system at hand give rise to various semantic structures in all this discussion we have the higher categorical connections for example can be viewed as functors from the to the category of categories this higher perspective suggests some ways to adapt the framework to more specialized forms of computation for example by changing the target category to that of premonoidal categories ie categories with a notion of propagating context one at that can propagate context such as a strong monad or by using the category of categories and partial functors one can drop the implicit assumption of theorem that is defined for all contexts even if there is no effectful computation with as its output in another direction while we chose to present along the line of lax algebras in rel they can equivalently be described as it would be interesting to investigate how the concepts for translate to and for example a representable multicategory is equivalently a total equivalent to a monoid our preliminary into the dual concept of consumer effects and have been very the traditional notion of context seems to be well described as a strength appears to be as an of this consumer effect with the producer effects similarly nonlinear uses of inputs also seem best described as a after all an intuitionistic implication p q translates to linear implication p q with a modification on the input rather than the output the modality is a which is a special class of just like monads are a special class of furthermore it seems that strictness and laziness arise as two dual ways to make such a interact with producer effects finally while we have discussed what the semantic framework for producer effects should look like we have not investigated how to actually build with monads there have been a variety of techniques for composing monads though interestingly many of these such as distributive laws arise as special cases of our framework building monads from monad transformers or combining algebraic monads with and sums we would like to see how these concepts extend to for example the of two monads is relatively simple to define but at first thought it is not clear whether the of two and respective would be simpler or more complex also transformers such as for exceptions rely on the presence of a unit operation so one if they are restricted to just by these techniques in this new light we expect to acquire a better understanding of their fundamental structure with this framework we aim to new for the foundations of programming languages of course there are still many more forms of composition to formalize the semantics of but we have already the strategy taken here to those settings and found some results in the end we expect to have composable frameworks for formalizing the many roles effects have in programming languages we hope this work will provide a new means to abstractly formalize expand and communicate programming languages acknowledgements in addition to our anonymous reviewers we thank john c thomas ball daniel jeffrey s foster michael daniel andrew myers michael and for their valuable feedback on the research its context and our writing references abadi access control in a core calculus of dependency in icfp robert notions of computation ­ july benton john hughes and moggi monads and effects in international school on applied semantics danvy and a functional abstraction of typed contexts technical report university of copenhagen representing layered monads in popl monads in action in popl et des john hughes monads to arrows science of computer programming ­ may martin gordon plotkin and john power combining effects sum and tensor theoretical computer science ­ and categorical semantics for arrows ­ mark p jones and composing monads technical report yale university new ct usa december simon peyton jones and philip wadler imperative functional programming in popl richard b effects with monadic typing in icfp david j and philip wadler combining monads in higher higher categories cambridge university press paul hudak and mark jones monad transformers and modular interpreters in popl john m and david k polymorphic effect systems in popl and composing monads using acm sigplan notices ­ daniel and a generic system in moggi computational lambdacalculus and monads in lics michael jeffrey s foster and contextual effects for dynamic software updating and safe concurrent programming in popl nielson and nielson type and effect systems in acm computing nielson nielson and polymorphic subtyping for effect analysis the static semantics in gordon plotkin and john power notions of computation determine monads in john power and premonoidal categories and notions of computation mathematical structures in computer science ­ october john power and environments continuation semantics and indexed categories in john power and closed freyd and categories in john c reynolds using category theory to design implicit conversions and generic operators lncs ­ and michael lightweight monadic programming in ml technical report microsoft research theoretical and practical aspects of type and effect inference phd thesis des de paris and university paris vi paris france and polymorphic type region and effect inference ­ and the type and effect discipline information and computation ­ the sequential semantics of producer effect systems technical report cornell university andrew p optimizing ml using a hierarchy of monadic types in types in compilation philip wadler monads in lisp and functional programming philip wadler the essence of functional programming in popl philip wadler monads and composable continuations lisp and symbolic computation ­ january philip wadler and peter the of effects and monads transactions on computational logic ­ andrew k wright simple imperative polymorphism lisp and symbolic computation ­ 