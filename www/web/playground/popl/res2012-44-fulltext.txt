an executable formal semantics of c with applications u university of illinois abstract this paper describes an executable formal semantics of c being executable the semantics has been tested against the gcc test suite and successfully passes of test programs it is the most complete and tested formal definition of c to date the semantics yields an interpreter debugger state space search tool and model checker for free the semantics is shown capable of automatically finding program errors both statically and at runtime it is also used to enumerate nondeterministic behavior categories and subject descriptors d programming languages formal definitions and general terms languages standardization verification introduction c provides just enough abstraction above assembly language for programmers to get their work done without having to about the details of the machines on which the programs run despite this abstraction c is also known for the ease in which it allows programmers to write programs with no runtime checks and little static checking in c the programmer is to be trusted entirely despite the abstraction the language is still lowlevel enough that programmers can take advantage of assumptions about the underlying architecture trust in the programmer and the ability to write code are actually two of the design principles under which the c standard was written these ideas often work in to yield bugs the potential of c bugs makes it an candidate for formalization as subtle bugs can often be only by more rigorous means in this paper we present a formal semantics of c that can be used for finding bugs rather than being an on paper semantics it is executable machine readable and has been tested against the gcc tests see section the semantics describes the features of the c standard but we often the text from the proposed cx standard we use the cx text because it will eventually the c standard and because it offers and more explicit descriptions of certain kinds of behavior our semantics can be considered a implementation of c the standard defines a implementation as supported in part by contract hc and by contract no permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ pa usa copyright © acm a version of c that includes every language feature except for complex and types and that includes only a subset of the standard library our semantics is the first complete dynamic semantics of c see section above all else our semantics has been motivated by the to develop formal yet practical tools our semantics was developed in such a way that the single definition could be used immediately for interpreting debugging or analysis described in section at the same time this does not mean that our definition is not formal being written in a subset of rewriting logic rl it comes with a complete proof system and initial model semantics briefly a rewrite system is a set of rules over terms constructed from a signature the rewrite rules match and apply everywhere making rl a simple uniform and general formal computational paradigm this is explained in greater detail in section our c semantics defines c syntactic operators the definitions of these operators are given by semantic rules over source lines of code however it takes only of those rules to cover the behavior of statements and another for expressions there are rules for dealing with declarations and types rules for memory and technical rules defining operators finally there are rules for the core of our standard library the semantics itself is described in more detail in section and is available in its at contributions the specific contributions of this paper include · a detailed comparison of other c · the most formal semantics of c to date which is executable and has been tested · as to its utility in discovering program · constructive evidence that semantics scale features our semantics captures every feature required by the c standard we include a partial list here to give an idea of the completeness and explain any in section all aspects related to the below features are included and are given a direct semantics not by a translation to other features · expressions and dereferencing casts array indexing ai structure members and arithmetic and logical operators increment and assignments sequencing conditional · statements for while if switch goto break continue return · types and declarations unions static storage variable length arrays · values regular scalar values arithmetic and pointer types unions compound literals · standard library basic io · conversions implicit argument and parameter and arithmetic conversion and explicit casts comparison with existing formal c semantics there have already been a number of formal semantics written for c one might ask why yet another we claim that the definitions so far have either made enough simplifying assumptions that for many purposes they are not c or have any way to use them other than on paper while paper semantics are useful for and understanding the language we believe that without a mechanized definition it is difficult to gain in a definitions for any other purpose below we the most definitions and explain their and in comparison with our work and one of the formal descriptions of c is given by and using abstract state machines then known as algebras their semantics describes c using four precise layers each formal and their semantics covers all the highlevel constructs of the language and uses external to capture the inherent in the definition of c their semantics was written without access to a standard and so is based on and however many behavioral details of the features of c are now partially including details of arithmetic type representation and evaluation strategies the latter has been investigated in the context of but none are present in the original definition based on our own experience the details involving the features of c are complex see section but we see no reason why the technique could not be used to specify them their semantics was never converted into an executable tool nor has it been used in applications however their purpose and context was different from ours as pointed out elsewhere p their semantics was constructed without the benefit of any according to their purpose was to discover the structure of c at a time when c was far beyond the reach of denotational semantics algebraic specifications etc cook and soon after the previous definition cook et al describe a denotational semantics of c using a temporal logic for the express purpose of proving properties about c programs like us they give semantics for particular behaviors in order to have a more concrete definition these choices are then partitioned off so that one could in theory choose different values and behaviors they have given at least a basic semantics to most c constructs we say at least without malicious their work was promising they moved on to other projects before developing a version of their semantics and without doing any concrete evaluation additionally no proofs were done using this semantics cook and the related work of cook and is a semantics for a restricted subset of c based on the semantics above this semantics is embedded in the theorem prover a to acl they were successful in verifying at least two functions one that takes two pointers and the values at each and one that computes the factorial they were also able to prove properties about the c definition itself for example they prove that the execution of p an puts the address of the nth element of the array a into p p their semantics is at its roots an uses a similar technique to that described by and leroy to an interpreter from recursive there is no description in their work of any reference programs they were capable of executing as above it appears the work was terminated before it was able to personal communication the next major semantics was provided by who gives both static and dynamic formal semantics inside the hol theorem proving system for the purpose of verifying c programs later extended to c his semantics is in the structural operational semantics style using smallstep for expressions and bigstep for statements one of the focuses of his work is to present a precise description of the evaluation orders of expressions his semantics still stands as a precise representation of evaluation in c in section we demonstrate how our definition captures the same behaviors working inside hol provides an elegant solution to the of the can state facts given by the standard as to maintain we chose instead to our definition for those choices in that respect our definitions conceptually complement each is better for formal proofs about c while ours is better for searching for behaviors in programs see section proofs of program correctness as well as proofs have already been demonstrated in the framework used by our semantics but we have not yet applied these techniques to c uses his definition to prove some properties about c itself as well as to verify some strong properties of simple line programs but was unable to apply his work to larger programs his semantics is not executable so it has not been tested against actual programs however the proofs done within the hol system help to the definition a denotational semantics for c is described by using a monadic approach to domain construction the definition includes static typing and dynamic semantics which enables not only to represent the behavior of executing programs but also check for errors like of an identifier in the same scope and cook et al each give a typing semantics in addition to the dynamic semantics while we and and leroy below give only dynamic semantics represents his semantics in haskell yielding a tool capable of searching for program behaviors this was the only semantics for which we were able to obtain a working interpreter and we were able to run it on a few examples having modeled expression nondeterminism and being denotational his semantics evaluates a program into a set of possible return values however we found his interpreter to be of limited capability in practice for example using his definition we were unable to compute the factorial of six or the fourth number and leroy a bigstep operational semantics for a subset of c called clight is given by and leroy while they do not claim to have given semantics for the of c their semantics does cover most of the major features of the language and has been used in a number of proofs including the verification of the optimizing compiler compcert to help validate their semantics they have done manual of the definition as well as proved properties of the semantics such as determinism of evaluation they additionally have verified transformations from their language into simpler languages which are easier to develop in their semantics is not directly executable but they describe a mechanism by which they could create an equivalent recursive function that would act as an interpreter this work has not yet been completed clight does not handle nondeterminism or subexpressions with side effects however since publication they have added a new frontend smallstep definition called compcert c that does handle these features and is also being used to handle goto personal communication personal communication feature definition gh ccr cr no pa bl er string literal struct as value arithmetic casts functions exp side effects goto switch malloc feature gh ccr cr no pa bl er fully described partially described not described gh represents and ccr is cook et al cr is cook and no is pa is bl is and leroy and er is our work figure dynamic semantics features we our study of related works in figure for interested this may be however we believe that it is useful both for developers of formal semantics of c and for users of them to give a broad though incomplete overview of the state of the art of the formal semantics of c also it may serve as an of the complexity involved in the c language although not all features are equally difficult we did our best to give the authors the benefit of the with features they explicitly mentioned but the other features were based on our reading of their semantics we have also discussed our views with the authors where possible to try and establish a consensus obviously the categories are broad but our intention is to give an overview of some of the more difficult features of c we left off any feature that all definitions had fully defined finally there are a number of other features such as arrays that are difficult to correctness through simple inspection of the formal semantics ie without testing or verifying it it is also difficult to determine if feature pairs work example does a definition allow inside of unions we decided to leave most of these features out of the because they are simply too hard to determine if the semantics were complete enough for them to work properly background in this section we give a little background on the c standard including some important definitions we additionally explain the rewriting formalism we use to give our semantics of c c standard information the c standard uses the idea of undefined and partially defined behaviors in order to avoid placing difficult requirements on implementations it the particular behaviors of any c implementation that are not fully defined into four categories unspecified undefined and behavior for the purposes of this paper we focus on three of these § unspecified behavior use of an unspecified value or other behavior with two or more possibilities and no further requirements on which is chosen in any instance unspecified behavior where each implementation documents how the choice is made undefined behavior behavior upon use of a or erroneous program construct or data with no requirements an example of unspecified behavior is the order in which the arguments to a function are evaluated an example of implementation defined behavior is the size of an int an example of undefined behavior is referring to an object outside of its lifetime to put these definitions in perspective for a c program to be portable it shall not produce output dependent on any unspecified undefined or behavior § this is called strictly however programmers use c for many inherently tasks such as writing device drivers the standard offers another level of called where the program may rely on or even unspecified but never undefined behavior based on this our definition is parametric in behaviors and uses symbolic computation to describe unspecified behaviors as much as possible this behavior is kept separate from the semantics underlying the highlevel defined for all implementations aspects of the language more details about our are described in section and about our use of symbolic values in section why details matter it is to over the details of cs arithmetic and other lowlevel features when giving it a formal semantics however c is designed to be to machine languages where arithmetic is handled by any number of machine instructions the effects of this overloading are easily at the size boundaries of the types it is a common source of confusion among programmers and so a common source of bugs here we give a few examples that reveal even simple c programs can involve complex semantics for the purposes of these examples assume that ints are bytes capable of representing the values to and long ints are bytes to also unless specified in c a type is assumed to be signed in the following program what value does c receive q int a b long int c a b one is to say but that misses an important detail the two operands of the multiplication are ints so the multiplication is done at the int level it therefore which according to the c standard makes the expression undefined what if we make the types of a and b unsigned to unsigned int a b long int c a b here the arithmetic is again performed at the level of the operands but overflow on unsigned types is completely defined in c the result is computed by simply reducing the value modulo one more than the max value § mod gives us one last are one byte in c to what does c receive signed char a b int c a b except and whose is bytes are only required to be at least bits long since the are signed then based on the first example above the result would seem undefined however this is not the case in c types smaller than ints are to ints before doing arithmetic there are essentially implicit casts on the two operands int c thus the result is actually while the above examples might seem like a game the conclusion we draw is that it is critical when defining the semantics of c to handle all of the details the semantics at the higher level of functions and statements is actually much easier than at the level of expressions and arithmetic these issues are subtle enough that they are very difficult to catch just by manually the code and so need to be represented in the semantics if one wants to find bugs in real programs even though errors related to the above details continue to be found in real compilers previous semantics for c either did not give semantics at this level of detail or were not suitable for identifying programs that these features this is one of our primary reasons for an executable semantics we give some of the rules associated to binary arithmetic in section rewriting logic and k to give our semantics we use a semantic framework called k inspired by rl in particular our semantics is written using the tool which takes k rewrite rules and translates them into is a engine that provides facilities for the execution and analysis of theories rl term rewriting modulo equations namely associativity commutativity and identity as a logic with a complete proof system and initial model semantics the central idea behind using rl as a formalism for the semantics of languages is that the evolution of a program can be clearly described using rewrite rules a rewriting theory consists essentially of a signature describing terms and a set of rewrite rules that describe steps of computation given some term allowed by signature eg a program together with input deduction consists of the application of the rules to that term this yields a transition system for any program a single path of rewrites describes the behavior of an interpreter while searching all paths would yield all possible answers in a nondeterministic program for the purposes of this paper the k formalism can be regarded as a frontend to rl designed specifically for defining languages in k parts of the state are represented as labeled nested multisets as seen in figure these collections contain pieces of the program state like a computation stack or continuation eg k environments eg env types stacks eg etc as this is all best understood through an example let us consider a typical rule for a simple imperative language see section for the equivalent rule in c for finding the address of a variable x ··· k ··· x l ··· env l we see here two cells k and env the k cell represents a list or stack of computations waiting to be performed the leftmost ie top element of the stack is the next item to be computed the env cell is simply a map of variables to their locations the rule above says that if the next thing to be evaluated which here we call a redex is the application of the operator to a variable x then one should match x in the environment to find its location l in memory with this information one should transform the redex into that location in memory l this example a number of features of k first rules only need to mention those cells again see figure relevant to the rule the rest of the cell infrastructure can be inferred making the rules robust under most extensions to the language second to omit a part of a cell we write ··· for example in the above k cell we are only interested in the current redex x but not the rest of the context finally we draw a line parts of the state that we wish to the above case we only want to evaluate part of the computation but neither the context nor the environment change this notation is actually quite useful the above rule would be written out as a traditional rewrite rule like this x k x l env l k x l env items in the k cell are separated with which can now be seen the and take the place of the ··· above the most important thing to notice is that nearly the entire rule is duplicated on the righthand side rhs duplication in a definition requires that changes be made in in multiple places if this duplication is not kept in sync it leads to subtle semantic errors in a complex language like c the configuration structure is much more complicated and would require actually including additional cells like control and local figure these cells are automatically inferred in k which keeps the rules more modular going back to k we use · to represent the unit element of any algebraic lists or sets including the list we also use to stand for a term that we do not care to name finally in order to get the redexes to the top of the k cell ie in order to identify which positions in the syntax tree can be reduced next the grammar of c is annotated with additional strictness annotations for example for addition we say that exp exp exp strict meaning that either argument of the addition operator can be taken out for evaluation nondeterministically in contrast the if construct looks like this stmt if exp stmt strict indicating that only the first argument can be taken out for evaluation the two annotations above cause the following six rules to be automatically generated e e ··· k e e e e ··· k e e if e s ··· k e if s v e ··· k v e v e ··· k e v v if s ··· k if v s here e e and e represent expressions and v represents an evaluated expression ie a value while these are the rules generated by in the theory of k they can apply anywhere not just at the top of the k cell there are additional annotations for specifying more particular evaluation strategies and can be found in documentation on k we also give names to certain contexts that are evaluated differently for example the left hand side lhs of an assignment is evaluated differently than the rhs the use of this is described in section the semantics of c in k in this section we describe the different components of our definition and give a number of example rules from the semantics syntax we use the parser with additions made and included in an c parser and transformation tool itself only c c but extended it with syntax for c we use only the parser here and none of the transformations of we give semantics directly to the abstract syntax tree generated by the parser the parser with c extensions is used by a number of other tools including compcert and configuration program state the configuration of a running program is represented by nested multisets of labeled cells and figure shows the most important cells used in our semantics while this figure only shows cells k k map env map types map list bag k control list local map map map map mem map map t figure subset of the c configuration we use over in the full semantics the outer t cell contains the cells used during program evaluation at the top a k cell contains the current computation itself and a local cell holds a number of cells related to control flow and below there are a number of cells dealing with global information in the local cell there is a used for calling and returning from functions and a control cell which gets pushed onto the call stack inside the control cell there is a local variable environment env a local type environment types local aggregate definitions a loop stack a record of the locations that have been written to since the last sequence point section and the name of the current function the cells inside the control cell were separated in this manner because these are the cells that get pushed onto the call stack when making a function call outside the local cell are a number of global mappings such as the global variable environment the global type environment global aggregate definitions the heap mem the dynamic allocation map and a map from pairs to continuations for use by goto and switch memory layout our memory is essentially a map from locations to blocks of bytes it is based on the memory model of both and leroy and u et al in the sense that the actual locations themselves are symbolic numbers however it is more like the former in that the actual blocks of bytes are really maps from offsets to bytes below we see a of a memory cell holding four bytes ··· obj ··· mem this says that at symbolic location there is an object whose size is bytes those bytes are and all objects are broken into individual bytes including aggregate types like arrays or as well as base types like integers our pointers are actually pairs which we write as o where b corresponds to the base address of an object itself while the o represents the offset of a particular byte in the object we wrap the base using sym because it is symbolic despite representing a location it is not appropriate to eg directly compare b b section it is better to think of the above as representing object as opposed to location when up the bytes are interpreted depending on the type of the construct used to give the address the simplest example possible is dereferencing a pointer sym of type unsigned char which would simply yield the value of type unsigned char looking up data using different pointer types requires taking into account a number of details such as the use of signed magnitude ones or complement representation or the order of bytes these choices are made parametric in the semantics and can be depending on which implementation a user is interested in working with section when new objects ints arrays etc get allocated each is created as a new block and is mapped from a new symbolic number the block is allowed to contain as many bytes as in the object and accesses relative to that object must be contained in the block we represent information smaller than the byte ie by using offsets within the bytes themselves while it might seem that it would be more consistent to treat memory as mappings from bit locations to individual bits themselves are not in c so we decided on this hybrid approach semantics we now give the of our semantics by examining a few of the rules for the rules below recall that in k what is above the line is considered the lhs of the rule while what is below the line is considered the rhs parts of a rule without a line at all are considered to be on both sides of the rule lookup and assignment we first consider one of the most basic identifier according to the standard an identifier is a primary expression an object in which case it is an lvalue or a function in which case it is a function § although in informal language an lvalue is an expression that appears on the lhs of an assignment this is not the case according to the c standard an lvalue can be more accurately thought of as any expression that a place in memory a in the standard suggests it might better be called a value § we denote lvalues with brackets an lvalue that points to location l which is of type t is denoted by l t with this in mind here then is our lookup rule x ··· k ··· x l ··· env ··· x t ··· type l t this rule is actually very similar to the example rule we gave in section it says that when the next thing to evaluate is the program variable x both its location l and its type t should be up in the env and type cells and the variable should be replaced by an lvalue containing those two pieces of information we distinguish between objects and functions based on type in almost all contexts this lvalue will actually get converted to the value at that location except when it is the operand of the operator the unary operator the operator the operator or the left operand of the operator or an assignment operator an lvalue that does not have array type is converted to the value stored in the designated object and is no longer an lvalue § we call these contexts for right evaluation here is the rule for simplifying lvalues in the right value context t t where the rule for read then does the actual read from memory its evaluation involves a series of rules whose job is to determine the size of the type the right bytes from memory and to piece them together in the right order to the value there are over highly technical rules defining read just for integer types alone this process results in a normal value instead of an lvalue which we represent simply as v t reference and dereference we can now take a look at the rule for the operator l t ··· k l this rule says that when the next computation to be performed is taking the address of an lvalue it should simply be converted into a true value holding the same address but whose type is a pointer type to the original type we can expect to find an lvalue as the argument because the context does not include the arguments of the address operator the rule for dereference is similarly simple l ··· k l t where t void this will first make sure that the location l is allowed to be eg it is valid memory and will then evaluate to an lvalue of the same location as with lookup no memory is read by default notice that is blocking the top of the k cell as long as it there no rules that match other constructs on the top of k can apply if succeeds it will simply evaluate to the unit of the construct and this is called our rule for is o ··· k ··· b ··· mem · where o len here we match the constituent parts of a location b and o or base and offset as explained in section we then match the base part of the pointer in the memory cell giving us an object and check that the offset is within the bounds of the object if this is the case we the task structure members the standard says a expression followed by the operator and an identifier a member of a structure or union object the value is that of the named member and is an lvalue if the first expression is an lvalue § here is the rule for when the first expression is an lvalue l ··· k ··· s f offset t ··· l offset t this rule finds the offset offset and type t of the field f in struct s and simply adds the offset to the base address l of the struct to evaluate the expression the result is another lvalue of the type of the field in contrast the rule for when the first expression is not an lvalue cannot simply work with pointers v ··· k ··· s f sd ··· sd s f one situation in which this arises is when a function returns a struct and the programmer uses the function call to access a particular field as in the expression the call to fun will result in a struct value represented in the rule above by v the function will look at the bytes of the struct represented by v and read a value of the appropriate type sd contains the offset and type of the field there are many rules shared by the and read since both have to piece together bytes in orders to make new values the semantics for the arrow operator pf is identical to that of the dot operator above after dereferencing the first subexpression e f ef there are similar rules as above for union where all offsets of a unions fields are multiplication and related conversions as mentioned in section the rules for arithmetic in c are nontrivial to show this in more detail here we give many of the rules related to integer multiplication here is the core multiplication rule i t i t i int i where this rule matches when values with identical types more on it then uses a operator to convert the resulting product into a proper value i where i i it i where i int int i i where i int int i the first rule creates a value as long as the product is the range of the type the next two rules unsigned products into range § by not giving rules to signed types we catch signed overflow here with the above rules defined the question becomes how to and convert the types of the operands so that the core multiplication rule can take effect first all arithmetic in c takes place at or above the size of ints this means smaller types need to be into int or unsigned int t ··· k where the above rule and its commutative cause multiplication operands to be of the actual the standard says if an int can represent all values of the original type the value is converted to an int otherwise it is converted to an unsigned int § int unsigned int where where finally in order to perform the multiplication the types of the operands have to be identical if the types are not identical an implicit conversion takes place to convert the different types to a common type there are rules for this given in the standard to give an idea of their we give a few of the rules for integer conversions here first the rule to enable conversion i t i t ··· k where t t cast i t cast i t t the standard says if both operands have signed integer types or both have unsigned integer types the operand with the type of integer conversion rank is converted to the type of the operand with greater rank § t where t t rank is a partial ordering on integer types based on their ranges and eg int additionally the of unsigned integer types equal the of the corresponding signed integer types § with the conversion rules otherwise if the operand that has unsigned integer type has rank greater or equal to the rank of the type of the other operand then the operand with signed integer type is converted to the type of the operand with unsigned integer type § t ··· k where t and similarly for the commutative case the above equations use a number of operators in the side definitions for min and max are given in section the other operators are defined as expected malloc and free here we show our semantics of malloc and free these are functions from the standard c library that perform dynamic memory allocation and deallocation the declarations of these functions are void size void ptr where is an unsigned integer type that is implementation defined when a programmer calls malloc an implementation can return a new pointer pointing to a new block of memory the size specified by the programmer or it can return null eg if there is no memory available here is the rule for a successful call to malloc ··· k ··· · ··· n l ln where l is fresh if the user requests n bytes the semantics will schedule that many bytes to be allocated at a new location and record that this memory was dynamically allocated in the cell here is the related rule for a failed called to malloc malloc ··· k this rule is usually only useful when searching the state space a call to free is meant to space allocated by malloc its rule is also straightforward ··· k ··· l n ··· ··· l ··· mem ·· · when the user wants to free a pointer l it is removed from both the and mem cells by matching these cells the rule ensures that the pointer has not already been and once applied ensures no other rules that use that address can match into the memory and finally we show our semantics of and these are functions from the standard c library that perform complex control flow they are of callcc and are often used as a kind of exception handling mechanism in c the declarations of these functions are int env void env int val where is an array type suitable for holding the information needed to restore a calling environment a call to its calling environment for later use by the function additionally the call to evaluates to zero § here is our rule for c k int k c local because is an array type it will evaluate to an address l in the rule above we match the remaining computation similar to a continuation as well as the local execution environment c this includes cells like the call stack and the map from variables to locations which we also call the environment the rule then causes this information to be written at the location of the a call to the environment saved by the most recent invocation of with the corresponding argument § when the user calls this address is read to find that previous context l t ··· k t and it is then k i int if i then else i fi int k local c this function returns the val that the user passes unless this is a in which case it returns it should be clear that these rules operate on the configuration itself treating it as a firstclass term of the formalism the fact that k allows one to the continuation as a term is what makes the semantics of these constructs so easy to define this is in to semantic like where the context is a derivation tree and not directly accessible as an object inside a definition parametric behavior we chose to make our definition parametric in the behaviors and are not the first to do so thus one can the definition based on the architecture or compiler one is interested in using and then proceed to use the formalism to explore behaviors this allows the definition to be out and made executable for a simple example of how the definition is parametric our module starts with these settings are then used to define a number of operators where int here we use a side condition to check when a type is not a finally the above rules are used to define how an integer i of type t is cast to an unsigned integer type t i t i int int t where i here we use predicates in our side conditions to make sure this rule only applies when from integer types to unsigned integer types there are similar equations used to define other cases expression evaluation strategy and undefined behavior the c standard allows compilers freedom in optimizing code which includes allowing them to choose their own expression evaluation order this includes allowing them to · delay side effects eg allowing the write to memory required by x or x to be made separately from its evaluation or use · evaluation eg a b c can be evaluated in the order b a c at the same time the programmer must be able to write programs whose behaviors are and only allow nondeterminism in a controlled way therefore the standard makes undefined certain situations where reordering creates a race condition the treatment of this restriction is given by the cx standard if a side effect on a scalar object is relative to either a different side effect on the same scalar object or a value computation using the value of the same scalar object the behavior is undefined if there are multiple orderings the behavior is undefined if such an side effect occurs in any of the orderings § this means that if there are two writes or a write and a read to the same object that are ie either is allowed to happen before the other then the expression is undefined examples of expressions made undefined by this clause include xx and xx and xx and px for int x and int px this relation is related to the concept of sequence points also defined by the standard sequence points cause the expressions they fall between to be the most common example of a sequence point is the ie the end of an all previous evaluations and side effects must be complete before sequence points a read of the standard may indicate that detecting this kind of undefined behavior is an easy problem that can be checked statically in fact it is undecidable statically moreover one needs to use the entire semantics in order to check it dynamically consider the following example int x y p y int if guard p x return int return x p f the of this program is based on what happens in the call to f if f is called before the other subexpressions in main are evaluated and if the guard expression which could be arbitrarily complex is true then the remaining expression effectively becomes x x which is undefined the possible complexity of the guard is a witness to the static undecidability of this problem the evaluation of the guard may make arbitrary use of the entire c language so the entire semantics is needed in order to determine whether this program is undefined based on this note that when two expressions are it means that evaluation can happen in any order thus it is natural to map behavior into nondeterministic behavior this way we can use state space exploration as a single mechanism to find behavior to identify this kind of undefined behavior can be computationally expensive some optimizations are necessary to make this feasible we offer two such optimizations below first with a little case analysis of the definition of the sequencing relation it is clear that there can be no write before a read of the same object with no sequence point this means that if in searching the semantic state space we find an execution in which the write of a scalar object happens before a write or read of the same object with no sequence point then we can conclude that this or pair is whenever a write is made its location is recorded in the cell which is whenever a sequence point is this cell is first checked whenever a read or write is made to ensure that there is no conflict this strategy has the added benefit that some undefined behaviors of this kind can be detected even during interpretation where only a single path through the state space is explored it is similar to the strategy used by second it turns out that a large subset of allowed orderings do not need to be considered in order to detect undefined behavior or possible nondeterministic behaviors because we are looking for writes before other events we can take the of applying side effects immediately instead of delaying them what would it mean for there to exist an expression whose on whether or not a side effect a write occurs later instead of earlier there must be three parts to the expression a subexpression e generating a side effect x and for sake further subexpressions e and e the particular evaluation where we do side effects immediately would look like e x e e because this is always a possible execution and we assume it does not show a problem we can conclude neither e nor e reads or writes to x if there is a problem only when we delay the side effect it can be seen in a path like e e x e for this to be different than applying the changes to x immediately it means there must be some use of x in the evaluation of e but this contradicts the previous assumption this the state space while at the same time not missing any undefined behavior our semantics does capture the appropriate state space as seen in section using a simple frontend that the behavior of gcc c programs are parsed and translated into a term then reduced using the rules of our formal semantics for defined programs this process produces behavior from the same c program run as native code we call this interpreter obtained automatically from our formal semantics as we will show in section is significantly more than an addition to simple interpretation it is also capable of debugging undefined behaviors state space search and model checking once is on a system compilation of c programs generates a single executable file an containing the semantics of c together with a parsed representation of the program and a call to the output is captured by a script and presented so that for working programs the output and behavior is identical to that of a real c compiler to emphasize the here is a simple world while it may seem like a it our testing and debugging for example we could run the definition using the same test gcc uses for its testing see section it also means people with no formal background can get use out of our semantics simply by using it as they would a compiler testing the semantics no matter what the intended use is for a formal semantics its actual use is limited if one cannot generate in its correctness to this aim we that our formal semantics executable and computationally practical gcc tests as discussed in the previous section our semantics is inside a replacement for gcc which we call this enables us to test the semantics as one would test a compiler we were then able to run our semantics against the gcc and compare its behavior to that of gcc as well as the intel c compiler and r c compiler for llvm we ran all compilers with optimizations turned off we use the test for gcc specifically those tests inside the directory we chose these tests because they focus particularly on portable machine independent executable tests the for the tests says the tests are meant to be generic tests that can run on any target we found that generally this is the case although there are also tests that include features which had to be from our evaluation there were originally tests of which we tests because they used extensions or they used the complex data type or certain library functions which are not required of a implementation of c or they were machine dependent this left us with tests further manual inspection an additional tests that were according to the standard mostly signed overflow or reading from uninitialized memory us to a total of tests in order to avoid our semantics to the tests we randomly extracted about of the tests and developed our semantics using only this small subset and other programs discussed in section after we were with the quality of our semantics when running this subset we ran the remaining tests out of previously programs we successfully ran after this initial test we to use all of the tests to help develop our semantics we now pass of the tests compiler gcc tests run of count the tests represent about or correctness analysis our executable formal semantics performed nearly as well as the best compiler we tested and better than the others we incorporated the passing tests into our suite that gets run every time we commit a change this way upon adding features or our accuracy can only increase three of the six failed tests rely on floating point accuracy problems two more rely on evaluating expressions inside of function as in int i int return i which we are not handling properly the last is a problem with the lifetime of variable length arrays coverage analysis in order to have some measure of the effectiveness of our testing we recorded the application of every semantic rule for all of the tests out of core rules operator the gcc tests in addition to getting a coverage measure this process suggests an interesting application for example in the gcc tests at above a rule that deals with large values to unsigned int was never applied by looking at such rules we can create new tests to trigger them these tests would improve both in the semantics as well as the test suite itself testing we have also tested our semantics on programs from around the web including programs of our own design and from open source compilers not counting the gcc tests we include over in our tests that are run when making changes to the semantics these tests include a number of programs from the and compcert compilers we also execute the c reference manual tests also known as which go through and and test each feature described in about when these tests are added to the gcc tests described above it our to rules we can successfully execute device an switch statement where the cases are inside of a loop inside of the switch statement itself as well as programs whose output are precisely their source code and a number of programs from the c code all of these test programs as well as our semantics are available from our project semantics is useful here we describe applications of our formal semantics which are in addition to the interpreter already mentioned these tools are automatically derived from the made to the semantics immediately affect the tools we are permitted this because we take advantage of general purpose tools available to rl theories of which our semantics is one contrast this to the nearly universal strategy of writing analysis tools independently of semantics instead of developing a different model for each tool a of tools can be created around a single semantic definition these tools are essentially wrappers or views of the semantics debugging by introducing a special function that acts as a breakpoint we can turn the debugger into a simple debugger for c programs this provides the ability to step through interesting parts of execution to find out what rules of semantics are invoked in giving meaning to a program in the semantics we handle this function by giving a labeled rule that causes it to evaluate to a void value it is essentially equivalent we have been unable to determine the author or origin of this test suite us with any information to void i if this function is called during execution it starts a debugger that allows the user to the current state of the program one can step through more rules from there or simply note the information and proceed if the call is inside a loop the user will see a each time it reaches the expression for example int for int i i i we can run or the program above as follows run the program normally done or run it in the debugger where int ··· k ··· i l ··· env · · · resume int ··· k ··· i l ··· env · · · the user can use this to see what the value of the argument is each time through the loop as well as the entire state of the program when the breakpoint was reached the state presented to the user includes all of the cells of the language figure this state is represented by the above in addition to the where and resume commands there is also a step command to step through the application of a single semantic rule § runtime verification there are two main through which we can catch and identify runtime problems with a program undefined behavior and symbolic execution undefined behavior the first mechanism is based around the idea that when something lacks semantics ie when its behavior is undefined according to the standard then the evaluation of the program will simply stop when it reaches that point in the program we use this mechanism to catch errors like signed overflow or array in this small program the programmer to leave space for a string the call to will read off the end of the array int char src src gcc will execute this and depending on the state of memory even do what one would expect it is still undefined and our semantics will detect trying to read past the end of the array because this program has no meaning our semantics gets stuck when exploring its behavior it is through this simple mechanism that we can identify undefined programs and report them to the user by default when a program gets stuck we report the state of the configuration a concrete instance of that shown in figure and what exactly the semantics was trying to do at the time of the problem we have also to add explicit error messages for common is the output from our tool for this code error encountered while executing this program description reading outside the bounds of an object function line here and elsewhere in this section we take the to slightly simplify the output to make it fit in less vertical space symbolic execution through the use of symbolic execution we can further the above idea by expanding the behaviors that we consider undefined while maintaining the good behaviors symbolic execution is straightforward to achieve using a semantics whether a term is concrete or abstract makes no difference to the theory rules designed to work with concrete terms do not need to be changed in order to work with symbolic terms as we explained in section we treat pointers not as concrete integers but as symbolic values these values then have certain behavior defined on them such as comparison difference etc this technique is based on the idea of strong memory safety which had previously been explored with a simple language in this context it takes advantage of the fact that addresses of local variables and memory returned from allocation functions like malloc are unspecified § however there are a number of restrictions on many addresses such as the elements of an array being completely and the fields in a struct being ordered though not necessarily for example take the following program int int a b if a b if we gave objects concrete numerical addresses then they would always be comparable however this piece of code is actually undefined according to the standard § symbolic locations that are actually pairs allow us to detect this program as problematic we only give semantics to relational pointer comparisons where the two addresses share a common base thus evaluation gets stuck on the program above error encountered while executing this program description cannot apply to different base objects function main line of course sometimes locations are comparable if we take the following code instead int struct int a int b s if sa sb the addresses of a and b are guaranteed to be in order § and in fact our semantics finds the comparison to be true because the pointers share a common base another example can be seen when copying a struct one byte at a time as in a c implementation of every byte needs to be copied even uninitialized fields or and no error should occur because of this our semantics must give it meaning using concrete values here would mean missing some incorrect programs so we use symbolic values that allow reading and copying to take place as long as the program never uses those uninitialized values in undefined ways state space search we can also use our semantics to do both state search and explicit state modelchecking with linear temporal logic ltl the basic examples below show how our semantics captures the appropriate expression evaluation semantics precisely exploring evaluation order to show our semantics captures the evaluation orders of c expressions allowed by the specification we examine some examples from related works the results given below are not just theoretical results from our semantics but are actual results obtained from executing the tools provided by our semantic framework to start with a simple example from and we take a look at xx in an environment where x is this expression is undefined because the read of x the x is with respect to the write of x the assignment using our semantics to do a search of the behaviors of this expression finds this readwrite pair and reports an error offers the simple addition expression x x which in many languages would be valid however in c it is again a technically undefined expression due to the assignments to x our semantics reports an error for this expression as well another example in the literature is given by which shows how c can exhibit nondeterministic behavior while the expression is the addition of two function calls in c function evaluation is not allowed to so the behavior of this program is determined solely on which call happens last int r int f int x return r x int f f return r if f is called with the argument last then the result will be and similarly for searching with our semantics gives the behaviors r and r which are indeed the two possible results as a last example we look at a more complex expression of our own cd except for f each function call out its name and returns the function f however out its name and then returns a function pointer to a function that e the function represented by this function pointer will be passed results of a we the actual function bodies because the behavior is more easily understood by this tree bc d this tree or diagram describes the sequencing relation for this expression that is it must be the case that d happens before c that b and c happen before a and that f and a happen before e running this example through our search tool gives precisely the behaviors allowed by the standard search solutions found model checking in addition to the simple state search we showed above one can also use our semantics for ltl model checking for example consider the following program red state state state red int switch return red return if red return int while this program is meant to represent two orthogonal traffic and at the same intersection it provides an implementation of an algorithm to change the state of the from to to red and back we the nearly identical function the program takes advantage of the unspecified order of evaluation of addition in the expression to nondeterministically choose the order in which the are changed there are a number of properties one might like to prove about this program including safety and liveness properties one safety property is that it should always be the case that at least one of the is red or red red we have added a special allowing the programmer to write and name ltl formulae if we call the above formula safety then we can invoke the model checker as follows result bool true similarly it is important that the always make progress ie that it is always the case the will eventually become if we try to check we find that it does not hold of the above program result counterexample the reason this property is not verified is that the algorithm is wrong because the calls to and can occur in any order it is possible for either of the to get stuck on red the program starts with consider the following execution by alternating evaluation orders the program can change the ns light without ever changing the ew light this evaluation order is highly in most c compilers but the semantics allows it if we fix an evaluation order by changing to then the property holds result bool true limitations and future work here we the limitations of our definition and explain their causes and effects there are two main ways in which semantics can be incomplete and typically when one of incompleteness one of failure to give meaning to correct programs however because we want to be able to identify incorrect or programs the semantics must be balanced appropriately between defining too much or too little it is equally important not to give semantics to programs that should be undefined in the first case we are not missing any have given semantics to every feature required of a implementation of c with this said our semantics is not perfect for example we still are not passing of our test cases see section also our semantics of floating point numbers is particularly weak during execution or analysis we simply rely on an ieee implementation of floating point arithmetic provided to us by our definitional framework k this is fine for interpretation and explicit state model checking but not for deductive reasoning in the second case although our semantics can catch many bad behaviors other tools cannot eg we have not found any other tool that the undefined programs in sections or a way to add behavior to c there is still room for improvement for one our semantics all types to boundaries this means we cannot catch undefined behavior related to alignment restrictions note that others have on formalizing alignment requirements but it has never been incorporated into a full semantics for c we also do not handle type qualifiers like const or we simply ignore them this is safe to do when interpreting correct programs but it means we are not detecting problems related to those features in incorrect programs it also means that we are missing possible behaviors when searching programs that use we have not yet used our c definition for doing language or program level proofs even though the k framework supports both program level and semantics level proofs to do so we need to extend our semantics with support for formal annotations eg assume assert invariant and connect it to a theorem prover this is already being done for a subset of the c language and we intend to apply those techniques to actual c in the future we still do not cover all of the standard library so far we have added library functions by need in order to run example programs which is why we have semantics for library functions like malloc parts of functions and over others we intend on covering more libraries in the future but for now one could what we provide by using implementations of libraries written in c in our current semantics only some of the behaviors are most common ones by making the semantics parametric we hope others can add or change rules to their needs finally we should mention the speed of our system while it is not nearly as fast as c compiled it is usable of the gcc test programs described listed in section our semantics ran over of these programs in under seconds each an additional completed in in and further in under in comparison it takes gcc about s for each test the reader should keep in mind that this is an interpreter obtained for free from a formal semantics in addition the search and model checking tools the same state explosion problems inherent in all model checking conclusion it is a that despite the best efforts of over years of research in formal programming languages most language designers still consider the difficulties of defining formal semantics to the benefits formal semantics and are not typically considered together when c was being the standards explored using formal semantics but in the end decided to use simple because anything more was considered to be likely to delay the standard and to make it less accessible to its § this is a common in the programming language community indeed few real languages have ever been completely formalized and even fewer were designed with formal specification in mind based on our experience with our semantics the development of a formal semantics for c could have taken place the development of the standard within roughly we had a working version of our semantics that covered more of the standard than any previous semantics the version presented in this paper is the result of of work to put this in perspective one member of the standards that it took roughly to produce the c standard we are not that we have done the same job in a fraction of the time obviously writing a semantics based on the standard is quite different than writing the standard itself we are simply saying that the effort it takes to develop a semantics is quite small compared to the effort it took to develop the standard the of the language community towards formal methods has not been without is not always clear that having a formal semantics the designer anything for her effort commonly mentioned benefits like improving the understanding of the language or providing a model in which sound arguments about the language can be made are relatively to be accepted by the general language community semantics needs to be shown to have concrete value beyond that of the time has come to start building analysis tools directly on formal models instead of building analysis tools for different languages and different versions of each language the analysis infrastructure surrounding the semantics could be maintained independently so that one could derive tools for multiple languages simply by out the semantic rules we offer our work as one small step in this direction we are not alone and there are other tools including analysis architectures like and formal tools like compcert that share part of this our semantics and its automatically generated tools have already found one serious application is a c program test generator that generates random programs from a large expressive subset of the c language these tests are then used to perform differential testing among c compilers to find compilation bugs to date the team has found more than bugs in common compilers like gcc and the programs generates are almost always too large many between and to as bug reports and need to be reduced the reduction process is but is with the possibility of introducing undefined behavior until now these tests would have to be carefully examined by hand for undefined behavior because any such behavior would the tests invalid our semantic tools are being used by the team to detect this undefined behavior and have allowed them to more completely the process and reduce the tests more references s and x leroy mechanized semantics for the clight subset of the c language j automated reasoning ­ r s and j s moore a computational logic academic press second edition m f s j p n and c all about a logical framework volume of lncs springer j v cook and s a formal semantics for c in technical report d trusted information systems november j v cook e l and t s a formal denotational semantics for c technical report d trusted information systems september p j p r g l b v and a experience report ocaml for an static analysis framework sigplan not ­ august t on device url msg to the group c t f s and g u a rewriting logic approach to type inference in th intl on algebraic development techniques volume of lncs pages ­ compiler collection url c language version url y and j k the semantics of the c programming language in computer science logic volume of lncs pages ­ d r and c w fraser a c compiler design and implementation addisonwesley sc programming technical report n intl organization for standardization december sc for international standard programming technical report intl organization for standardization april sc x programming technical report n intl organization for standardization august d m jones the new c standard an and december url b w and d m the c programming language prentice hall second edition j conditional rewriting logic as a unified model of concurrency theoretical computer science ­ g c necula s s p and w intermediate language and tools for analysis and transformation of c programs in intl conf on compiler construction pages ­ m d and c chambers a theory of lowlevel software in th acm symposium on principles of programming languages popl l c s cooper p and l a the international c code url m c in hol technical report university of cambridge december m a formal semantics for c technical report url n s a formal semantics for the c programming language phd thesis technical university of n s denotational semantics of c computer standards and interfaces ­ n s and d a study of evaluation order semantics in expressions with side effects j functional programming ­ g d plotkin the of structural operational semantics j logic and algebraic programming ­ g u and t f s an overview of the k semantic framework j logic and algebraic programming ­ g u and a s matching logic a new program verification approach track in th intl conf on software engineering pages ­ g u w and t f s runtime verification of c memory safety in runtime verification rv volume of lncs pages ­ g u c and w matching logic an alternative to logic in th intl conf on algebraic methodology and software technology volume of lncs pages ­ t f s and g u a rewriting based tool for semantics of programming languages in th intl on rewriting logic and its applications volume of lncs pages ­ s and j v cook mechanical verification of c programs in acm on formal methods in software practice january s c programming frequently questions url x yang y chen e and j finding and understanding bugs in c compilers in nd conf on programming language design and implementation pldi pages ­ w and a a framework for modeling the semantics of expression evaluation with abstract state machines in abstract state machines volume of lncs pages ­ 