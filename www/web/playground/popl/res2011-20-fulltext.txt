a separation logic for refining concurrent objects mitchell wand university abstract finegrained concurrent data structures are crucial for performance from but their design is a subtle art recent literature has made large in verifying these data structures using either atomicity refinement or separation logic with relyguarantee reasoning in this paper we show how the ownership discipline of separation logic can be used to enable atomicity refinement and we develop a new relyguarantee method that is to the definition of a data structure we present the first semantics of separation logic that is sensitive to atomicity and show how to control this sensitivity through ownership the result is a logic that enables compositional reasoning about atomicity and interference even for programs that use finegrained synchronization and dynamic memory allocation categories and subject descriptors d software engineering verification f logics and meanings of programs specifying and verifying and reasoning about programs general terms algorithms verification introduction the goal this paper is about the semantic relationship between ownership atomicity and interference we begin with a very simple data structure the counter counters permit a single operation inc int c int tmp c c tmp return tmp of course this implementation only works in a sequential setting if multiple threads use it concurrently an interleaving can lead to several threads the same value from the counter the usual reaction to this problem is to use mutual exclusion the operation with lock instructions but as and put it with this we prevent the bad interleavings by preventing all interleavings finegrained concurrent objects permit as many good interleavings as possible without allowing any bad ones the code supported by a grant from microsoft research permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ austin texas usa copyright c acm do tmp c until tmp tmp implements inc using an optimistic approach it takes a of the counter without a lock computes the new value of the counter and uses cas to safely the new value the key is that cas compares c with the value of tmp atomically updating c with tmp and returning true if they are the same and just returning false otherwise even for this simple data structure the finegrained implementation significantly the implementation likewise even for this simple example we would prefer to think of the counter in a more abstract way when reasoning about its clients giving it the following specification ret x c x c x ret x this specification says that for any value x inc atomically transforms a heap in which c points to x into one where c points to x moreover ensuring that the value of ret an is x we express both implementations and specifications in a single specification language and say that refines implements if for every context c each behavior of c is a possible behavior of c that is no client can detect that it is interacting with rather than even if the client invokes s operations concurrently this paper presents a logic for proving such refinements based on separation logic the key idea is to use a notion of ownership expressed through separation logic to reason about both atomicity and interference the key contributions are the semantics refinement and proof rules enabling this reasoning we will be able to easily verify the counter given above § as well as more complex nonblocking data structures eg a nonblocking stack § the approach since this paper is focused on verification rather than development we will take the perspective of abstraction which is converse to refinement refines iff abstracts the of abstraction is that to prove something about the behaviors of c for a particular client c it suffices to consider the behaviors of c is usually much simpler than for verifying data structures in a sequential setting one is primarily interested in data abstraction where abstracts away representation details from in a concurrent setting we want simplicity in another respect as well atomicity abstraction where appears to perform an operation in one atomic step even though takes many steps refinement on the power of the context c what can it observe and with what can it interfere the more powerful the context the less freedom we have in implementing a specification concurrency changes not what but when in a firstorder language a sequential context can only interact with the state before or after we take the perspective advanced by et al that linearizability is a proof technique for we choose not to use it see § for more discussion running the program fragment in its hole a concurrent context might do so at any time in his classic paper protection in programming languages morris argued that a programmer should be able to prove that his programs do not solely on the basis of what he can see from his private that paper and its showed how to enable such reasoning by weakening the context eg by hiding data through lexical scoping data by dynamic sealing or by giving it an opaque existential type a basic message of this paper is that these and other hiding techniques serve just as well to reasoning in a concurrent setting we present an approach for proving of concurrent objects using an ownership discipline to enforce hiding as in any separation logic the ownership discipline is dynamic what is owned can vary over time and is often determined by runtime values in the heap we derive two major benefits from our ownership discipline first it enables us to perform atomicity abstraction under the basic principle that if you dont own it you cant see it thus an atomic step modifying only private data can be into an adjacent atomic step to form a single atomic step claim by making both atomicity and ownership explicit we can and exploit their relationship observed atomicity is relative to ownership atomicity abstraction from the notion of private data the other benefit of ownership is to do with object instances which are shared among methods claim because ownership limits possible interference we can exploit it to give a modular and dynamic account of relyguarantee reasoning relyguarantee reasoning is a wellknown technique for reasoning about interference you prove that each thread guarantees certain behavior as long as it can rely on other threads to interfere in a limited way traditionally the rely constraint must be carried through the whole verification even if it is only relevant to a small portion using ownership we relyguarantee reasoning to the definition of a concurrent object since we know all interference must from the methods making up its definition in our approach relyguarantee reasoning is done with respect to a object instance at runtime there may be zero one or many such instances each in its own region of the heap a similar form of relyguarantee reasoning appeared in very recent work by et al we compare the approaches in § to support our claims we make the following contributions · we present a new specification language in the of refinement calculi but to separation reasoning § we give it an operational semantics which determines the meaning of refinement our notion of refinement captures safety properties only but we expect most of our results to easily transfer to a model liveness · we adapt transition trace model to handle dynamic memory allocation and use it to give our specification language a simple denotational semantics § the semantics is adequate for the operational model so it can be used to justify refinements to our knowledge this is the first model of separation logic that captures atomicity explicitly · on the strength of the denotational model we are able to give many basic refinement laws § and we show how these laws can be used to verify a simple nonblocking counter § they domains x y z var loc v val var o val loc val variables locations values environments heaps outcomes syntax specifications x x x let f f in f e x p q p procedures f f x configurations o predicates p q r true false emp e e ee pq pq pq p q xp xp expressions e x n e e e e figure are not strong enough however to handle more complex data that we need reasoning · in § we introduce our ownership discipline formally captured by the notion of refinement the semantics of refinement is a hybrid between trace semantics and inputoutput relations traces for shared state io for private state we give laws of refinement that justify our two claims above finally we give a law data relating and standard refinement which allows us to employ refinement in correctness proofs we sketch the soundness proof for this law in § · we present a case verification of a nonblocking demonstrate refinement § this paper on several ideas from recent work especially that of vafeiadis et al and et al we refer the reader to § for a detailed discussion of prior work specifications the standard view of refinement calculus is as follows we are interested in specifications the most concrete of which are programs thus we have an expressive language of specifications so it is easy to say what behavior is and a of programs that say how to produce such behavior it will be possible for instance to write a specification that solves the halting problem but this will not correspond to any program the distinction between programs and general specifications is not important for our purposes here suffice it to say that the implementations we will verify are clearly executable on a machine the language of specifications figure includes traditional programming constructs like sequential composition and parallel composition of firstorder procedures and recursion x in addition there are logical constructs like disjunction and quantification x these latter can be read operationally as nondeterminism either behaves like or behaves like and x behaves like for some choice of x the remaining specification constructs in gray will be explained in § in the semantics given below a specification with a heap a configuration of the abstract machine is typically a pair of the remaining specification to execute and the current heap in addition there are two terminal configurations called outcomes either successful termination with heap or else a fault will be explained in § the important point at the moment is that termination propagates up through sequential and parallel composition operational semantics of specifications v val x vx x xx let f f in ff xe e x o q x p q o p true p p true p a few other points of note · variables x y z are immutable only the heap is mutable · the domain of values val is unspecified but at least includes locations integers and pairs · we assume a denotational semantics e val for expressions e which is straightforward we write e for e · a composition steps to exactly when terminates · the first rule for makes it symmetric · we abbreviate let f x in by let f x in heap predicates to describe the remaining forms of specifications in gray we first need to define heap predicates p these are the usual predicates of separation logic they make assertions about both program variables eg x and the heap eg x as such the entailment relation p holds when p is true both of the heap and the environment which gives the values of program variables predicate semantics p emp iff e e iff e e e e iff e e p q iff p q p q iff p or q xp iff v x v p the predicates emp e e and p q come from separation logic the predicate emp asserts that the heap is empty while e e asserts that the heap contains a single location e which contains the value e thus x is satisfied when takes x to the only location in and maps that location to the separating conjunction pq is satisfied by any heap into one satisfying p and one satisfying q thus x y asserts that the heap contains exactly two locations containing and in particular it implies that the locations x y we write p for p actions assertions and assumptions in separation logic a hoare triple for a command c asserts that if p then c running on · will not fault by say following a dangling pointer and · if it terminates will do so with a heap such that q note that p and q may be quite specific about the shape of the heap for example that it consists of a single cell a key idea of separation logic is that commands are local what they do on a large heap is determined by what they do on smaller heaps this idea leads to the frame rule allowing r to be inferred from in our specification language we basic commands in of a single construct the action x p q an action describes an atomic step of computation in terms of the strongest partial correctness assertion it satisfies cf specification state ments in other words it permits every behavior that satisfies the triple p q the variables x are in scope for both p and q and are used to link them together as in inc above to understand the behavior of a simple action p q it is helpful to think in terms of a specific starting heap first suppose that p true meaning that no of satisfies p in this case the behavior is unconstrained and in particular the action is permitted to fault hence arise when preconditions are not satisfied on the other hand if can be decomposed into such that p then the action must take a step to some heap such that q it must establish the postcondition without modifying the frame and cannot fault the semantics of actions is in essence that of calcagno et al action semantics q × o q iff if and p then o and q many familiar commands can be expressed as actions the following are used in our examples and provide some intuition for the semantics of actions abort skip ret x ret old new ret x a x false true true false emp emp emp ret x a a x x a x a x x ret x old ret a x x old ret a new where the predicate a is shorthand for za z the abort action can always fault as its precondition is never satisfied on the other hand never but it also never takes any steps as its postcondition is never satisfied from the of the operational semantics neither nor successfully terminates from a partial correctness it satisfies every specification the skip action cannot fault because any heap has a that satisfies emp likewise new cannot fault and it furthermore ensures that ret is distinct from any address allocated in the frame finally put get and cas fault if a is notice that get and cas both quantify over a variable x in order to connect an observation made in the precondition to a constraint in the postcondition one common in these examples is the use of postconditions to filter possible behaviors being the most extreme case for procedures like get the postcondition is used to constrain the ret where one might write let x in as a program we write x as a specification executions where x took on the wrong value simply neither terminating nor one use of postcondition is so common that we introduce shorthand for it an assumption p stands for the action emp emp p because its precondition is emp an assumption cannot fault and because its postcondition implies emp as well it cannot alter the heap it is a refinement of skip since it is with emp the predicate p cannot further constrain the heap it is used only to constrain the value of variables assumptions are used for control flow the specification if p then else is sugar for p ¬p finally assertions p simply test a predicate if some satisfies p then the heap is left unchanged and otherwise the tion assertions provide a way to introduce a claim during verification while its justification cf we can write the finegrained concurrent version of inc in our specification language as follows inc c ret x t t t b if b then ret t else x refinement model theory we have seen what specifications are how they behave and how they express common programming constructs but the point of working with specifications is to compare them we want to say when a relatively concrete specification implements a more ab one informally a specification implements if no client can observe that it is interacting with instead of ie every be of is a possible behavior of formally this situation is expressed as refinement refinement op op iff c if c then c if c then c or c where iff and iff where c is a specification context a specification with a hole closing and the op stands for operational semantics in this definition we the possible outcomes of a c to three cases nontermination successful termination and termination if the specification can fault in a given context then is of any obligations for that context in this way behavior is treated as unspecified behavior and as we will soon see it follows that abort is the most permissive specification op abort for all ultimately our goal is to give useful axioms and inference rules for proving such refinements however as usual the quantification over all contexts in the definition of refinement makes it difficult to work with directly as a in this section we give a denotational semantics for specifications which will give us a sound but not complete denotational version of refinement readers primarily interested in the proof rules can read § first taking the soundness of the rules on the denotational model is based on transition trace model which gave a fully abstract semantics for a parallel while language we this model to deal with pointers and the heap as well as the challenge in giving a denotational model for concurrency is the semantics of parallel composition to define in terms of and we must leave room for interference from in the meaning of and with transition traces we give meaning to and in terms of discrete of execution between which we allow for arbitrary interference to calculate the meaning of we need only these in detail we model the behavior of each specification as a set of transition traces a transition trace is a finite sequence of moves each move represents one of execution which may correspond to zero one or some finite number of steps in the operational semantics a trace of like arises from an execution where first then some unknown specification in the environment changed the heap from to then a trace can be terminated by a fault either on the part of the specification as in or on the part of its environment as in domains move fault trace × × move fault s t u trace s t u trace the transition traces of a specification can be read directly from the operational semantics observed traces to o o o o t o t o the inference rules say respectively the environment might fault at any time a terminating whether successful or results in a singleton trace a nonterminating allows the specification to resume later under a heap an important insight in model is that the transition traces of a specification are closed under stuttering addition of a step and merging of two steps with a common closure under stuttering means that the context of a specification cannot observe in which it does not change the heap this that skip is a unit for sequential composition closure under implies that for example p r op p q q r the scheduler might give the latter specification a long enough to execute both actions so that the behavior of the former is a possible behavior of the latter our denotational semantics gives an alternative definition of o that is compositional in the structure of in giving the denotational semantics we must explicitly apply stuttering and closure which we do via the closure operator a that together observationally trace sets closure t t tt st t s ot t t t s t t s ot t t t t t u t the rules for appeared in original paper to them we add two rules concerning the first captures the fact denotational semantics of specifications trace x let f f in v xv f f f e f e x t t t xt t x x x p q q p p true p true procedures f f x v xv figure that the environment of a specification might cause a fault at any time the second reflects that on the part of a specification is permissive so a specification that after some interactions t can be implemented by one that continues without after t the reason steps are important is to handle cases like xx abort without the steps o xx would be empty but the semantics of the composition is nonempty the effect of including in the closure is that every finite prefix of the behavior of a specification is included in its set of traces but with the marker at the end that the specification was terminated early by a fault on the part of the environment with those out of the way the denotational semantics is straightforward sequential composition is concatenation and parallel composition is nondeterministic interleaving one when traces a fault on the left out everything on the right since causes early termination to u to this rule applies to both sequential and parallel composition recursion is defined using the point over closed sets of traces the order on trace sets is set inclusion disjunction and existential quantification are given by least upper bounds according to that ordering here environments map variables x to values v specification variables x to closed sets of traces t and procedure variables f to functions val trace environments are ordered pointwise over the subset order on closed sets of traces leading to the following lemma lemma for each the function from environments to trace sets is monotonic we connect the denotational semantics to refinement in two steps first we show that the denotational semantics gives the trace sets as the operational semantics modulo closure lemma if is a closed specification then o this lemma is proved separately in each direction the direction goes by induction on the rules defining o while goes by induction on the structure of we define a denotational version of refinement and prove that it soundly approximates the operational version adequacy definition iff for all closing theorem adequacy if then op some laws of refinement abort ex x skip skip str x x str x y p q y p xq x p q x p r q r ext x p p xp p exact p p p xp x p q x p q x p q r x p q r r pure ind x x x p p x p q x q q x p q qp p q nb syntax appearing both in and outside a binder for x in a refinement as in x cannot mention x figure proof suppose let c be a specification context that and by the monotonicity of the semantics one can show that c c by lemma o c o c it follows that if c then c and that if c then either c or c refinement proof theory with the denotational semantics in hand it is easy to prove a number of basic refinement laws these laws will be powerful enough to verify a basic nonblocking counter § but to more advanced examples we will need to employ reasoning the subject of § we write for axiomatic refinement which is justified in terms of and we write when the refinement goes in both directions the benefit of the in the previous two sections is that axiomatic refinement is a is what enables us to verify implementations in a compositional manner many of the rules in figure are familiar the top group comes from firstorder and hoare logic we leave those rules and use them freely the two dst rules giving the interaction between nondeterminism and sequencing are standard for a process calculus ind is standard fixpoint induction is the frame rule from separation logic capturing the locality of actions is the consequence rule of hoare logic the less familiar rules are still largely straightforward ext provides an important case where actions and assertions are equivalent on exact predicates which are satisfied by exactly one heap and hence are deterministic as postconditions the str rules allow us to manipulate quantifier structure in a way of scope in the calculus like the dst rules they express that the semantics is to when a nondeterministic choice is made the rules express the idempotence of assertions recall that the precondition of an action acts as a kind of assertion allows us to move a guard into or out of a postcondition when that guard is pure does not use emp or tells us that assertions are which follows from the permissive nature of theorem the laws are sound if then op proof we prove soundness using the denotational semantics we show that implies which by theorem adequacy implies op most laws are very easy to show this way the only nontrivial case ind uses the fixpoint the in the standard way as a simple illustration of the proof rules we have lemma ret definition x a x a x x ret x a x a x ext a this lemma shows that we can abstract away the constraint that get places on its allowing it to vary freely but we cannot that ret when a is example a nonblocking counter we now return to the example of an atomic counter ret inc c ret x c x c x ret x x t t t b if b then ret t else x to show inc inc we first prove some useful lemmas about optimistic concurrency lemma t e b b def x a x x t b a x x t b a e x a x x t b a x x t b a e x a x a e x t lemma t e b b a b b proof similar corollary t t e b if b then else x t x a x a x proof expand if apply and use lemmas lemma t t e b if b then else x t t x a x a e x t where is shorthand for x notice too that the scope of quantifiers continues over line breaks the specification on the left captures a typical optimistic nonblocking algorithm take a of a cell a do some work and update a if it has not changed otherwise loop the specification on the right characterizes the partial correctness effect of the algorithm it performs some number of loops and then updates a proof apply corollary at a high level the result follows by induction using to remove assertions a applying lemma to inc letting be skip which we drop we have inc c ret t t x c x c x x t ret t tc tc x c x c x x t ret t tc x c x c x x t ret t t x c x c x x t ret t t x c x c x ret x x c x c x ret x step is the application of lemma in step we abstract away the gets the using lemma in we remove the first existential the remaining existential str and apply inductively to the assertions applies to remove the remaining assertion applies and removes the remaining existential the abstraction of get in step is of abstraction and it illustrates that the are not necessary for the safety of the algorithm though essential for liveness notice that we do not give and did not use any rules for reasoning about parallel composition we certainly could give such rules eg an expansion law but that would be the point our aim is to reason about concurrent objects which are defined by sequential methods that clients may choose to execute in parallel having proved the refinement we can conclude that even for a concurrent client c we have ownership in the previous section we were able to reason about the nonblocking counter because it a very helpful property it works correctly regardless of interference no matter what concurrent reads and writes occur to the counter the inc method will only modify the counter by atomically it such an implementation is possible because a counter can be represented in a single cell of memory and so cas can be used to operate on the entire data structure at once for more complex data structures such as the stack we will study in § this will not be the case such data structures cannot with arbitrary interference in this section we will develop an ownership discipline that will enable reasoning about lack of interference we will the denotational semantics to give a meaning to and find the consequences of the ownership discipline the resulting laws give to the key claims of the paper atomicity is relative to ownership and interference is by ownership the discipline the ownership discipline we have in mind is to the notion of a concurrent object which is given by a collection of methods one of which is a constructor for example imagine a counter that supported both and let new ret in let inc ret · · · in let dec ret · · · in intuitively the representation of a counter can be described by a simple predicate x notice that this predicate is specific to a counter located at address and with value x a client that called twice would expect to be left with a satisfying a b more complex data structures are described by more complex predicates consider the specification of a stack let new ret in let push x h h h h h x h in let pop ret h h x h h x h h h x h ret x in in this representation an instance of a stack consists of at least a memory cell s which points to the head of the stack if the stack is empty the contents of the stack is given by a linked list which can be described by the following recursive predicate list list x · xs x list xs the second parameter to list is a sequence of list items this sequence is abstract in the sense that it exists only at the level of the logic not as a value in a program a stack located at with abstract contents x is described by the predicate a a x in general the memory belonging to an instance of a concurrent object is described by a predicate p x with free variables and x the variable gives the location of the object while x gives its abstract value the predicate xp x then describes a heap that contains an object instance at with unknown contents we call this latter predicate the representation invariant for a concurrent object and use the metavariable i to such predicates we introduce a new metavariable not just as a but also because we restrict representation invariants to be precise a predicate is precise if for every heap there is at most one way to split such that satisfies the predicate thus precise predicates serve to pick out precisely the region of memory relevant to an object instance for example the invariant i ax a x in some sense the linked list associated with a stack whatever its contents may be our ownership discipline works as follows a concurrent object is given in the logic a representation invariant i parameterized by location an object instance at consists of the described by i clients may not access these directly but must invoke methods of the object instead each method is parameterized by a location of the object to operate on and is given access only to the described by i since multiple methods may be invoked on the same instance concurrently this memory is shared between invocations but because the objects methods are the only code with access to this memory we may assume that any concurrent interference is due to one of these methods when a method begins executing its view of the heap consists solely of some object instance i as it executes the method may in addition allocate private memory which is initially free from interference if however the private memory is made reachable from the object instance so that it into the region described by i it at that point becomes shared and subject to interference an implementation of push for example will first allocate a private linked list node and only later actually link it into the list conversely memory from the object instance becomes private to the method refinement now for the our ownership discipline enables reasoning about method bodies through refinement i as above i describes a specific object instance we leave the location implicit refinement says that refines under the assumption that all memory is either part of the shared instance described by i or private moreover interference on the shared memory is bounded by the specification the rely here are the key rules some laws of refinement i inv i i skip lift i i x p q x q p r i xp x p p r x q q i x p q xq x p q inv expresses that the representation invariant i always holds so it will always succeed we check that the method itself maintains the invariant elsewhere in the data rule lift reflects the fact that refinement is more permissive than standard refinement in refinement any data that is not part of the data structure instance by i is private and hence can be about sequentially suppose that at some point we know that i p that is our view of the heap includes both a shared object instance described by i and some other memory described by p by our ownership discipline we know that p is private in this case the execution of an action like p q will not be visible to other threads because it is operating on private memory the seq rules permit atomicity abstraction two atomic actions can be combined if one of them only operates on private data we give one rule which combines two actions when the first the left is notice that introduces the assertion i xp as a verification condition for showing that the data on by the first action really is private we omit the similar rule finally allows as assertion q to be removed if it is satisfied after an action that is the predicate q must be established by an action and once established must be maintained under any interference in addition to those rules refinement is also nearly a congruence if i then i c c for any context c that does not contain parallel composition it is not a congruence for parallel composition because of the sequential reasoning it permits on private data since we use refinement only to reason about the method bodies implementing a concurrent we assume to be is all we need to give a semantics for refinement we want to ignore certain aspects of the denotational semantics in some cases we throw away traces for example traces where the environment does not the rely should be discarded a deeper issue is the distinction between private and shared memory because private memory cannot be observed or with by concurrent threads we do not model it with a trace instead we view private memory in terms of inputoutput behavior recording its value only at the beginning and end of a computation as a consequence sequential reasoning eg is valid for steps involving only private memory in short the semantics of method bodies is a hybrid between trace semantics and inputoutput relations we thus define × trace × a trace contains three components the initial state of private memory a trace involving only the shared memory and the final state of private memory suppose is a fragment of a method body we calculate its traces as follows projection i i where t t u u seq t rely i t o ot o o o o ot u u seq o o seq o seq rely i i t rely i t t rely i t i o i rely i ot the functions and return the first and last heaps or outcomes that appear in a trace u projection each trace of into a part t dealing with the shared state and a part u dealing with the rest of the heap which is to be we do this by lifting to traces notice that t and u have the same length and represent the same moves of we are just splitting the heap involved in each move into a shared part and a private part the rely operator performs several tasks at once first it filters the traces t to include only those where the environment maintains the invariant i and the rely at the same time it checks that the specification maintains the invariant as well inserting when it does not one effect is that the resulting trace t satisfies i which means that is captures precisely the shared state this shared state is unambiguous due to the precision of i it follows that the trace u which carries the remaining state contains exactly the private state we therefore require u to be sequential meaning that we filter any traces where the private data appears to have been with at all projection gives us the traces of a specification refinement just compares these traces semantics of refinement i i iff closing i i theorem the laws of refinement are sound if i then i proof the semantics of refinement was designed to make this theorem straightforward each law corresponds to one of the basic assumptions of projection inv that the invariant is satisfied that the rely is that the private traces are sequential the lift rule expresses that projection is monotonic enforcing ownership hiding so far refinement is just a we have no way to deduce standard refinements from refinements to do so we have to justify the assumptions made in projection the ownership discipline described in § is the desired policy now we turn to the mechanism for carrying it out consider the following specification let f ret emp ret in xf x here we have a simple concurrent object with a constructor f and no methods its client however violates our ownership discipline by directly modifying an object instance using put if the tions of refinement are to be met such clients must be out our solution is to introduce an abstraction barrier we extend the language of specifications to include abs which binds the abstraction variable in and we likewise extend heaps to include abstract cells e each location in the heap is either concrete or abstract so the predicate is unsatisfiable the purpose of abstract cells is to clients access to concurrent objects the client above we could instead write abs let f ret emp ret in xf x in this case the client will fault when the put because put operates on concrete cells but f allocates an abstract cell in general the concrete representation of an object may involve multiple memory cells when we introduce an abstraction variable we also have an to switch to a more abstract representation as in the following rule applicable when r is precise data let fi x y pi r ei qi r ei in abs let fi x y pi ei qi ei in as before the predicate r z is meant to describe an object instance located at with abstract contents z notice that the client is unconstrained except for the implicit constraint that cannot appear free in it the idea is that in applying this abstraction rule we swap a concrete version of a concurrent object for an abstract one cases where the client might have accessed a concrete object instance directly will in the context of the abstract object result in a fault since a specification is permissive § this means that behaviors where the client performed such an access are irrelevant for this refinement they are masked out by the fault on the other hand to ultimately verify that say abs p q it will be necessary to show that the client is wellbehaved as long as the precondition p is satisfied in short when we introduce hiding we can assume the client is wellbehaved when we verify a full program we must check this assumption we define abs as follows abs s s t t seq the notation s t denotes s t but is only defined when no heap in s contains cells and every heap in t consists only of cells so it is not commutative thus as in refinement we are in trace t the contents of the heap specific to an abstract variable the operator works by away the abstract resources making them any external environment in addition it only includes those traces where no interference on those resources took place since such interference is impossible due to the projection while abs abstract resources we also need a way to realize an abstract data structure by a concrete one we do this by extending the closure operator as follows s t t seq s t t s s t t seq s t t the first rule says that an implementation may always allocate more memory than its specification requires the constraint that requires the memory is allocated notice that the rule also requires the allocated memory to be free from external interference t seq why is the memory free from external interference the key insight here is that the memory is not present in data r precise pi pure let f emp r e let gi x i in r i i i i y r y r ei pi in abs let f emp e in let gi x y y ei pi in figure relyguarantee reasoning one possible behavior s of the specification t therefore the environment cannot assume the memory will be present and indeed if it tries to read or modify the memory and is interleaved with s rather than s t it will fault although we know that the environment will fault if it attempts to interfere the structure of transition trace semantics is such that arbitrary interference is always considered possible thus we include a second new closure rule that says in the presence of interference by the environment which will ultimately result in a fault the implementation is allowed to do anything and in particular may itself immediately fault of course we cannot extend we must ensure that adequacy still holds we sketch the proof that it does in § the net effect of these definitions is to protect abstracted data from its client and environment while allowing it to be implemented in a concrete way as we mentioned above when we introduce an abstraction through a rule like data we cause an client to fault where it would have accessed concrete data ultimately when we verify a whole the show it free from by showing that it refines some atomic action like p to do this we must eventually apply abstraction elimination abs which by convention requires that not appear in refinements from refinements data finally we have the data rule in figure which allows us to derive standard refinements from refinements ensuring that the assumed ownership discipline is actually followed ownership is in the of the in data we are working with a concurrent object with constructor f and methods gi the predicate r y describes a concrete object instance at location with abstract contents y as in data the abstracted version of the object works on abstract cells y instead we introduce i as a between i and the specification y r y r ei pi because we want to keep the rely i as simple as possible in particular methods usually operate on small portions of the object while r y refers to the entire object instance the definition of abs ensures that the client or environment of an object cannot interfere with it but refinement also assumes that methods do not violate the invariant r and methods do not violate the rely i · the invariant is maintained because each method body i is a refinement y r y r ei pi which clearly maintains the invariant · the rely is never violated because each method body i is a refinement of i and the rely permits the behavior of any of the is a key feature of data is its for modular and dynamic relyguarantee reasoning it is modular because we have isolated the memory involved to r and the code involved each do not constrain the clients nor the contexts in which the data refinement holds it is dynamic because it arbitrary allocation of new data structure get relyguarantee reasoning for each individual instance even though we do not know how many instances the client will allocate as given data only applies to methods whose action on the shared state is given in a single atomic step the rule can easily be extended to allow methods which also take an arbitrary number of steps refining y r y r y which make internal to the object instance often known as but look like skip to the client we will not need this for our case study below but it is necessary for related data structures such as queues the soundness proof for data is sketched in § case study nonblocking stack using refinement we will be able to verify a version of nonblocking stack new ret push x n x t t t n b if b then x pop ret x t t n t n b if b then x else ret the specifications and operate on the ith component of pairs eg x y a y a y x we have simplified pop so that it asserts that the stack is nonempty stacks provide two new challenges compared to counters first the loop in push modifies the heap every time it executes by calling put rather than just at a successful cas this makes atomicity nontrivial to show second pop has a potential problem it assumes that if the head pointer is unchanged ie equal to t at the cas then the tail of that cell is unchanged ie equal to n at the cas intuitively this assumption is justified because stack cells are never changed or deallocated once they are introduced we must make such an argument within the logic first we introduce the following procedures ret x x x ret x t n x x n x t t n x x n x t we apply lemma to push and pop push x n t t t t t n we assume garbage collection here but we can also verify a stack that its own memory using pointers technically for pop we need a slight variant of the lemma allowing the existential n to scope over the cas pop ret t t n t t n t n ret notice that pop after recording a pointer t to the current head node and checking that it is nonnull attempts to read the tail of that node using get in a sequential setting this would be in our concurrent setting we must about interference what if between taking the t and getting its tail the node t was from the stack or worse deallocated clearly the push and pop methods will give no such interference but we must find an appropriate representation invariant i and interference description to explain that to the logic it turns out to be slightly to formulate an appropriate representation invariant because part of what we want to assert that cells even when are neither nor deallocated can involve memory that is no longer reachable from the head of the stack in order to state the invariant we need some way of the addresses of cells which used to be part of the stack but no longer are to do this we will introduce an internal abstract value which a ghost parameter a using data ret t n t n x a x a x a x a x a ret x x a n a x t x a n x · a x t in order to apply data we have used the predicate p x a x notice that the parameter a does not appear in the concrete predicate the idea is that the abstract a is a sequence of addresses of cells while the concrete representation of a is simply nothing we can now give a representation invariant i for stacks along with a bound on interference i na n a x cells emp · a x x a x a n n a n x x x x a x a x x x x x · a x x x notice that describes interference only in terms of the effect on the head of the stack implicitly by this means that the rest of the stack described by the heap cells given by invariant under interference proving push we verify push using the refinements in figure which are by i and step just what we have done already in step we abstract into the assertion as in § and then apply inv to abstract these assertions to skip because they are implied by the invariant in steps and we use to merge the calls to new and put into a single atomic action new this introduces an assertion i emp again implied by the invariant step is just str step again applies again producing a trivial assertion which we remove with inv step applies str and step is by push x n t t t t t n n t t t n n t t n n t t n t n t n nt z a z a n a n x t z t z a z a nt n a n x t z t z a z a n n a n x z figure highlevel proof of push proving pop we do not give the full proof of pop but instead we show one important step in very careful detail figure recall that in pop we take two every time we loop one of the address of the current head node and one of its tail we will show that although these take place at distinct points in time they may as well have in a single atomic step the justification is that no interference could change the tail between the two steps we have labeled each step with the rule it applies except for the step which applies the derived rule x p q x p r q r for r pure this rule follows from the frame rule and because for pure r we have pr the proof mostly consists of structural steps which we give for purposes in practice one would reason with more powerful derived rules these steps serve to introduce enough names and frame to actually say what we want to say about the the step the precondition of the second by that it has a fixed value t the step actually demonstrates that the tail of t has a stable value strictly speaking it requires a use of to the assertion so that it matches the postcondition soundness of data abstraction the closure operator the operator acts as a homomorphism on the space of trace sets if t u then t u but not conversely to ensure that adequacy is preserved we must show that this homomorphism acts properly as a it suffices to show that has two properties in addition to being a closure operator lemma strength for each semantic operator we have t u t u lemma preservation of observation t iff t t iff t applying induction strength says that if we apply to each clause of our denotational semantics the result will be no larger than had we calculated the semantics without and only applied it at the top level we then use preservation of observation to tell us that t n t x a x a x a t x n y y t y y t y y y n t x x x a p p t x n y y t y y t y y y n t x x x a p p t x x x n y y t y y t y y y n tt x x x a p p t x t x n y y t y y t y y y n tt x x x a p p t x t x n y y t y y y t t y y y n y t tt x x x a p p t x t x n y y t y y y t t y y y t t n tt x x x a p p t x t x n y y t y y y t t y y y t t n ext tt x x x a p p t x t x nt t t n str x x x a p p t x t x t t t n x x x a p p t x t x t n x x x a p p t x t x t n x x x a p p t x n x tn x x x a p p t x n x where p x a x x x figure detailed atomicity abstraction for pop applying the toplevel to a closed specification in context does not change the basic we are concerned with § normal termination and termination data as with the other refinement laws we prove data by means of the denotational model however unlike the other laws this proof is nontrivial in order to prove the law we first show that if the hypotheses of the law hold then let f emp r e in let gi x i in simulates let f emp e in let gi x y y ei pi in simulation relates the concrete traces of the first specification to the abstract traces of the second it is a generalization of refinement instead of dealing with a single object instance we must track the arbitrary instances that may arise as a specification executes for each object instance we assume that the environment the rely we prove the simulation result by induction on the structure of the client the cases include method calls which interact with the concrete objects in known ways and client actions which cannot interact with the concrete objects for the latter we use the fact that in the second specification the concrete objects do not exist at are held abstract thus if the client which does not mention attempts to interact with them it will fault which as usual is permissive for inductive cases we are inductively that the client itself never breaks the rely this simulation tells us that neither the methods nor the client can break the rely condition to prove data we introduce abs which further guarantees that the environment will not interfere at all an important lemma for showing simulation is locality definition t is local if whenever t · and t u t or · t t u t either lemma locality for every the set is local assuming we take the fixpoint over only local trace sets locality captures the idea that if at some point a specification is given fewer resources to execute with it will either fault or it did not need those resources so they are part of the frame for that step we use this lemma when reasoning about steps that the client takes we know that if we remove the concrete object instances either the client would fault and hence was or else did not modify those instances the details of this and other proofs can be found online at evaluation and related work in the last several years there has been progress in the formal verification of finegrained concurrent data structures giving logics appropriate for hand verification as well as automated verification we have in this work to and this for us being the connection between ownership atomicity and interference our main contribution lies in making this connection formalizing it with a new semantics for separation logic and proof rules based on the idea while the logic resulting from our work offers some significant new features more experience using it is required before its or applicability can be compared to other approaches the most closely related work is concurrent abstract predicates cap a recent paper that also to reasoning about interference by using ownership and separation logic cap takes a different approach toward atomicity rather than proving linearizability or refinement in cap one always uses predicates which are invariant under internal atomicity issues entirely by contrast we have focused on the semantic issues related to both atomicity and interference and have shown both in terms of semantics and proof rules how these issues interact it should be possible to apply our semantic insights to explain cap in terms of contextual refinement as we have done separation logic has also been used to relyguarantee reasoning in work from which we the terminology however it does not appear possible to use that technique to both reasoning about interference to a group of methods and also let clients make use of the methods the abstract predicates in cap are related to and work data abstraction in a sequential separation logic setting in particular and parkinson use abstract predicates whose definition is known to the data structure implementation but opaque to the form of secondorder existential quantification there is clearly a close relationship to our abstract resources but we do not define abs in terms of secondorder quantification because we need the ability to introduce and require the connections between these approaches certainly further investigation the basic form of our calculus clearly to et als calculus of atomic actions the key idea in that work is to combine technique of reduction for the of atomicity with abstraction eg weakening a hoare triple on atomic actions the authors demonstrate that the combination of techniques is extremely powerful they were able to their logic and use it to verify a significant number of data structures and other programs a significant difference between their calculus and ours is what refinement entails semantically for them refinement is ultimately about the inputoutput relation of a program where for us it is about the reactive semantics the distinction comes down to this is refinement a congruence for parallel composition for us it is and this means that our system as a whole is compositional we also demonstrate that reduction is not necessary for atomicity refinement at least for the class of examples we have considered we instead use reasoning finally aside from these points we have shown how to incorporate separation logic into a calculus of atomic actions enabling reasoning about the heap a significant in our work is that we have with linearizability which is usually taken as the basic correctness condition for the data structures we are studying here we are by et al who point out that programmers expect that the behavior of their program does not change whether they use data structures or but data structures the authors go on to show that if we take refinement as our basic goal we can view linearizability as a sound and sometimes complete proof technique but implicit in their proof of indeed in the definition of the assumption that the heap data associated with data structures is never with by clients in a setting where clients are given pointers into those data structures this is an assumption that should be checked in contrast we are able to give a model including both data structures and their clients and make explicit assumptions about ownership our use of separation logic and relyguarantee clearly derives from vafeiadis et als work especially thesis in that line of work it was shown how to combine separation logic and relyguarantee reasoning which provided a basis for verifying finegrained concurrent data structures while their logic for proving hoare triples was proved sound no formal connection to linearizability or refinement was made there is only an implicit methodology for proving certain hoare triples about data structures and that those data structures are linearizable we show how to make that methodology explicit and moreover compositional by it to data abstraction as a we get a account of relyguarantee we also eliminate any need for explicit linearization points which sometimes require variables or annotations separating shared from private resources finally it should be noted that our semantics a both to and to calcagno et al acknowledgements thanks to and for feedback and discussions the first author was supported by a grant from microsoft research references r j back and j von wright refinement calculus a systematic introduction springer s full abstraction for a shared variable parallel language information and computation ­ c calcagno p w ohearn and h yang local action and abstract separation logic in lics pages ­ ieee computer society t m p m parkinson and v vafeiadis concurrent abstract predicates in ecoop june t s qadeer and s a calculus of atomic actions in popl pages ­ acm t s qadeer a o and s simplifying linearizability proofs with reduction and abstraction in tacas pages ­ springer x local relyguarantee reasoning in popl pages ­ acm i p ohearn n and h yang abstraction for concurrent objects in esop pages ­ springer l reasoning about nonblocking concurrency ­ m and n the art of multiprocessor programming morgan m p and j m linearizability a correctness condition for concurrent objects toplas ­ c b jones steps toward a development method for programs toplas ­ a strong functors and monoidal monads der ­ r j reduction a method of proving properties of parallel programs acm ­ b liskov and s programming with abstract data types in symposium on very high level languages pages ­ acm m m michael pointers safe memory for lockfree objects ieee transactions on parallel and distributed systems ­ m m michael and m l scott nonblocking algorithms and locking on shared memory j parallel comput ­ r milner a calculus of communicating systems springerverlag new york inc j c mitchell and g d plotkin abstract types have existential type toplas ­ m and n concurrent data structures in of data structures and applications d and s editors pages and press c morgan and t on the refinement calculus springer j h morris jr protection in programming languages cacm ­ p w ohearn resources concurrency and local reasoning theor comput sci ­ m parkinson and g separation logic and abstraction popl ­ d sangiorgi and d walker picalculus a theory of mobile processes cambridge university press r k systems programming with parallelism technical report research center v vafeiadis modular finegrained concurrency verification phd thesis university of cambridge v vafeiadis and m parkinson a of relyguarantee and separation logic in concur pages ­ springer r j van the linear time branching time in concur pages ­ springer 