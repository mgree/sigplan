cakeml a verified implementation of ml o michael computer laboratory university of cambridge uk research lab school of computing university of uk scott abstract we have developed and mechanically verified an ml system called cakeml which supports a substantial subset of standard ml cakeml is implemented as an interactive loop repl in x machine code our correctness theorem ensures that this repl implementation only those results permitted by the semantics of cakeml our verification effort on a of topics including parsing type checking incremental and dynamic compilation garbage collection arithmetic and compiler our contributions are the first is simply in building a system that is verified that each piece of such a verification effort can in practice be composed with the others and ensuring that none of the pieces rely on any assumptions the second is developing novel approaches to some of the more challenging aspects of the verification in particular our formally verified compiler can itself we apply the verified compiler to itself to produce a verified implementation of the compiler additionally our compiler proof handles input programs with a lightweight approach based on logical timeout exceptions the entire development was carried out in the hol theorem prover categories and subject descriptors d software engineering proofs formal methods f logics and meanings of programs specifying and verifying and reasoning about verification specification techniques invariants keywords compiler verification compiler ml machine code verification loop verified parsing verified type checking verified garbage collection supported by the cambridge trust supported by the society uk is by the through the department of communications and the research through the centre of program permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ san diego ca usa copyright is held by the publication to acm acm introduction the last has seen a strong interest in verified compilation and there have been significant results many based on the compcert compiler for c this interest is easy to justify in the context of program verification an unverified compiler forms a large and complex part of the trusted computing base however to our knowledge none of the existing work on verified compilers for generalpurpose languages has addressed all aspects of a compiler along two dimensions one the compilation algorithm for converting a program from a source string to a list of numbers representing machine code and two the execution of that algorithm as implemented in machine code our purpose in this paper is to explain how we have verified a compiler along the full scope of both of these dimensions for a practical generalpurpose programming language our language is called cakeml and it is a strongly typed impure strict functional language based on standard ml and ocaml by verified we mean that the cakeml system is ultimately x machine code a mechanically checked theorem in higherorder logic saying that running that machine code causes an input program to yield output or diverge as specified by the semantics of cakeml we did not write the cakeml compiler and platform directly in machine code instead we write it in higherorder logic and cakeml from that using our previous technique which puts the compiler on equal with other cakeml programs we then apply the compiler to itself ie we it this avoids a tedious manual refinement proof relating the compilation algorithm to its implementation as well as providing a large example program more specifically · we write and can run the compiler as a function in the logic and we a cakeml implementation of the compiler inside the logic · we the compiler to get a implementation inside the logic and · the compiler correctness theorem thereby applies to the implementation of the compiler another consequence of is that we can include the compiler implementation as part of the runtime system to form an interactive loop repl a verified repl enables applications that provide an important feature for interactive theorem provers in the which were the original motivation for ml contributions · semantics that are carefully designed to be simultaneously suitable for proving language properties and for supporting a verified implementation section · an extension of a synthesis originally from logic to ml now to machine code via verified compilation sections ­ · a lightweight method for proving using a clock and timeout exceptions these only appear in the proof not in the implementation it allows us to do all of our compiler proofs by induction and in the direction of compilation section · to the best of our knowledge this is the first of a formally verified compiler the is done within the logic so that the compiler correctness theorem can be instantiated to apply directly to the compilers output section result the result of this work is an verified repl implementation in bit x including parsing type inference compilation garbage collection and integer arithmetic the entire formal development was carried out in the hol theorem prover all of our definitions and proofs are available at approach the cakeml system and verification into three layers repl semantics implements interactive proof repl as function in hol implements mostly repl in x at the top is the semantic specification of the repl at the bottom is machine code implementing the repl in between is an implementation of the repl as a function in logic we describe the components of each layer in more detail below then give an overview of the proof that each layer implements the one above it the repl specification the semantics for the cakeml repl is given by a relation bool list string repl result bool between a string representing the read input and a repl result which is a list of strings representing the output ending in a nil value that indicates whether the repl has terminated or the bool list argument indicates which input declarations have type errors needed because we have not yet verified completeness for the type see section the input string is treated as a series of declarations separated by each declaration might yield an output string describing a result value or a parse or type error or it might diverge in the definition of we apply an executable specification to the entire input string and split the resulting list of tokens at toplevel yielding a list of possibly invalid declarations for each declaration we pick a valid parse tree according to the cakeml grammar if one exists if none exists the result for that declaration is a parse error we then translate away some syntactic sugar and resolve the scoping of types and datatype constructors cakeml has a declarative typing relation in the standard style if the declaration has a type we move on to the operational semantics if it does not have a type then the semantics gets stuck or signals a type error depending on the corresponding value in the bool list we use an executable specification instead of a regular one because ml comments are not expressible with regular expressions the operational semantics is given as a bigstep relation on which our compiler correctness proofs can all proceed by induction since both the compiler and bigstep semantics are defined inductively over cakeml abstract syntax to precisely define divergence and to support a syntactic proof we also give a smallstep semantics for expressions as a machine and prove that it is equivalent to the bigstep relation if the declaration diverges relates it to the repl result value if it terminates normally or with an exception or if a parse or type error occurred updates its state converts the result to a string and it to the result of evaluating the rest of the input the repl implementation the specification is implemented by a hol function string repl result from an input string to a list of result strings ending in either termination or divergence as above the function is total however it is not computable since it correctly ends the output list with divergence when necessary being a function in the logic it is able to ask whether there exist a number of steps in which execution of code for the next declaration would terminate we define as a loop that the input string while transforming the state of a lowlevel virtual machine for cakeml bytecode section and results the loop is split into three parts step read and compile the first part reads and the input until the next the resulting tokens performs type inference on the resulting syntax and then it to produce bytecode evaluate the second part returns the result if it exists of executing the bytecode on the bytecode or else signals divergence print and loop if the terminates the last part continues the loop with the new machine state after the results from the new state if the diverges or if all input has been read the loop ends if any step fails the loop continues after the error message the repl in the bottom layer is a implementation of the repl created mostly by specifically we translate the hol function step the main part of into cakeml declarations using synthesis we then evaluate the compiler in the logic on those declarations to produce a verified bytecode implementation of step this bytecode is mapped via a verified translation into x machine code to implement the other parts of we separately a small amount of x machine code to jump to the code produced by the compiler and to tie the loop together we also verified machine code for the garbage collector and integer package which complete the verified implementation correctness and verification the correctness of the x implementation of the cakeml repl is stated with respect to our machine model for x the theorem which appears in more detail as theorem can informally be read as follows theorem if the machine is loaded with the cakeml repl code and started with accessible memory for the data and code heaps and provided with a finite input character stream i then one of the following happens · the machine terminates successfully with an output stream output and there exist l and o such that l i o holds o ends with termination and out o output here out converts a repl result to a string by joining the results · the machine diverges after producing a finite output stream output and there exist l and o such that l i o holds o ends with divergence and out o output · the machine terminates with an error the output stream is terminated with an error message we prove the correctness theorem using two methods interactive proof to establish a connection between and and to put the final result together and a combination of interactive proof and synthesis including to construct verified machine code that implements the main lemma proved is that for every input there is an l such that l input input holds we prove this section by composing proofs that relate each of the components of to the corresponding component of since reads its input one character at a time whereas splits the whole input string up front we first prove for the that the resulting list of declarations is the same either way we then prove our parser sound and complete with respect to grammar section which means the results of parsing in match the choice of valid parse tree made by we prove soundness for the type inference algorithm if a type is inferred the type system allows that type we verify the rest of the loop in under the assumption that type inference and hence the operational semantics does not a type error internally is defined by inductive relations by an environment and store we maintain an invariant between these semantic objects the state of the compiler and the bytecode machine state our first compiler correctness theorem section is for when says the declaration yields a new environment and output string we carry our invariant around an iteration of the loop with this theorem which says running the compiled code for the declaration leads the virtual machine to produce the same output string and to terminate in a state that satisfies the invariant updated with the new environment in the case of divergence we have a second compiler correctness theorem section that says that if says a declaration diverges then a run of the compiled code for that declaration also diverges causing the entire repl to diverge the x implementation is constructed using forward proof most of which is automated the of the verified machine code ie that implementing step is produced via compiler we start by translating the hol function step into cakeml abstract syntax a list of cakeml declarations ml repl step the translation is automatic and it proves that the generated cakeml declarations implement the hol functions once we have the step in cakeml abstract syntax we evaluate the verified compiler on this abstract syntax the evaluation happens inside the logic and proves a theorem compile init ml repl step bytecode by the compiler correctness theorems we prove that the generated code ie bytecode accurately implements the cakeml declarations produced in the previous step in order to construct verified and executable machine code from bytecode we apply a verified translation from bytecode instructions to x machine code the steps outlined above produced verified x code for part of namely step we construct the machine code for all id x cn m cn t int bool unit id t id t t t t t ref t l i true false p x l p ref p pp p p p p e l id e ee e e e raise e e handle p e p e fn x e e e e e e e op e if e then e else e case e of p e p e let ld in e e end ld val x e fun x y e and x y e ref op div mod before c cn cn of t c c x x x d datatype and val p e fun x y e and x y e exception c sig sig sl end sl val x t type datatype and top structure mn sig struct d end d e where x and y range over identifiers must not start with a letter over type variables eg a cn over constructor names must start with a letter mn over module names and i over integers figure cakeml source grammar other parts including garbage collector and library using a different form of synthesis of machine code the toplevel theorem is proved by together theorems describing the behaviour of the components the specification of cakeml cakeml figure is a subset of standard ml sml including datatypes and patternmatching higherorder functions references exceptions polymorphism and modules and signatures cakeml integers are arbitrary precision the main features not included are records inputoutput and functors all cakeml programs should run on an sml implementation with the same result however we have not proved that fact with respect to the definition of standard ml thus any formal reasoning about cakeml programs must be carried out with respect to the cakeml semantics rather than we chose to be faithful to sml so that potential cakeml users do not have to learn a new programming language from but our main focus is not on sml per se but rather on a callbyvalue impure strongly typed functional language we choose sml over ocaml for technical reasons section on our subset the difference is mostly in the syntax section the specification as a contextfree grammar type system and bigstep operational semantics wrapped in a repl most of these are typical so here we focus on their properties and on our design decisions concrete syntax is specified by a contextfree grammar similar to figure s but that encodes the various parsing and the dangling case ambiguity the transformation to abstract syntax removes syntactic sugar cakeml does not enforce equality types so an sml implementation will statically reject some programs that cakeml accepts our implementation of equality raises an exception if one of its arguments contains a closure for example a let expression with multiple val bindings is into nested lets each with one binding our abstract syntax uses a firstorder representation of binding where variables constructors etc are represented as strings this straightforward representation well with our semantics which uses closures rather than substitutions and it also enables because the ast closely corresponds to a cakeml datatype cakeml does not support strings but they become lists of integers during synthesis the the ast and replaces uses of types and constructors in patterns and expressions with fully qualified names ie with the full module path to the constructor thus each constructor is named and the type system and operational semantics do not have to generate unique stamps at datatype declarations in order for a type preservation lemma to hold a key design principle for the operational semantics is for it to raise a distinguished exception error whenever something goes wrong instead of getting stuck or on by raising error instead of getting stuck the bigstep semantics has a precise correspondence between divergence and failure of an expression to relate to a result this is a key part of our technique for verifying the compiler for input programs section the error behaviour of the semantics forms the interface between the type soundness proof and the compiler proof as the compiler proof assumes that programs do not raise error and type soundness theorem guarantees this even though these choices only affect programs that do not type check they are how the compiler proof can use the fact that these situations do not arise for example when evaluating a pattern match the values constructor might be from a different type than the first patterns as in case true of none true the semantics could just move on to the next pattern since the values and constructors are not equal instead the semantics detects this case and raises error the semantics relies on the following definitions of values v environments for variables constructors and modules stores s and results r the constructor environment records the arity of the constructor and what type of values it constructs v loc l v closure e x e e fun x y e and x y e x loc num e x v list c list m id e list s loc list r s c m e s c ex s c error the type system relies on typing contexts for variables te constructors tc modules tm and stores ts we then have relations for evaluation divergence and typing for toplevel declarations evaluate top m c s e top r bool top diverges m c s e top bool type top tm tc te top tm tc te bool we use closures for function values rather than performing substitutions at function applications to keep a close connection between the semantics of functions and their implementation strategy the repl repeatedly calls evaluate top and must update its state between each call new bindings using the new store etc after a module declaration the repl updates the type systems state with the modules bindings according to its signature since future declarations must not refer to hidden bindings or constructors however the operational semantics state must be updated because references to the hidden constructors will generally be reachable from the environment or from the store the last remaining lies in module declarations that raise an exception through when any declaration raises an exception its bindings do not take effect and so the type environments are not updated however the operational semantics might need its constructor information updated since the module might have placed a locally defined constructor in the store first before raising the exception we have two either updating the constructor environment with just the constructors seen or with all of the constructors from the module body both are sound and neither affect the programmer since they are not in the type environments we choose the latter to match how the compiler implements modules metatheory theorem determinism if evaluate top m c s e top r and evaluate top m c s e top r then r r proof sketch by induction on the bigstep relation theorem totality r evaluate top m c s e top r iff diverges m c s e top proof sketch first we establish by induction along a small step trace that the smallstep semantics cannot get stuck then we use the equivalence theorem to transfer the result to the bigstep semantics the invariant of the type soundness theorem existentially constructor and module type environments that represent the declarations that are hidden by module signatures the update type sound inv function updates the state depending on whether the result is an exception or not following the discussion above type sound tc te m c e s ts tm no sig tc no sig the environments are wellformed and consistent with each other map fst tm no sig map fst tm tm no sig tm tc no sig tc and the constructors in tc no sig but not tc are all in modules in the domain of tm theorem type soundness let state tm tc te m c e s be given for all top if type sound inv state and type top tm tc te top tm tc te then either top diverges m c s e top or there exists s c and r such that r error evaluate top m c s e top s c r and type sound inv update type sound inv top state tm tc te s c r proof sketch we prove the usual preservation and progress lemmas along a smallstep trace then we use the equivalence theorem to transfer the result to the bigstep semantics we then reason about declarations entirely with the bigstep semantics this no problem because declarations cannot diverge apart from their subexpressions the preservation and progress lemmas were proved directly on our smallstep semantics which uses closures and a context stack to our knowledge no such proof appears in the literature the main impact on the proof is to out its structure eg no substitution lemma and instead to require an invariant that types the continuation stack the usual about type substitution and weakening were unchanged we use de bruijn indices for type variables part ii verification and implementation we now turn to the implementation and verification of each part of the compiler we include a highlevel discussion of design and section parsing we implement the first phase of parsing with a parsing expression grammar peg following and in coq we have a general inductive relation peg eval which takes a grammar an input sequence of tokens a peg expression and returns a of either failure or success with a returned value and the remaining input we prove the results from and that the peg eval relation always has a value when the peg is wellformed and that it is deterministic thus on wellformed pegs we prove the cakeml peg is one such peg eval specifies a function peg expressions are by semantic actions that can transform the values associated with into a combined return value our semantic actions in hol cannot be dependently typed as can be done in coq where it is to have of different nonterminals return values of different types instead all our have semantic actions that simply return lists of in this way the first phase of parsing on a linear sequence of tokens into a tree later phases map different parts of these trees into different types even though peg eval specifies a function its definition is not to computation rather we define a general peg interpreter peg exec that is written in a continuationpassing style whenever its peg argument is wellformed we prove the interpreter has a welldefined result and one that is equal to the result by the peg eval relation it is this definition that is compiled into the bytecode that is eventually executed theorem parser soundness whenever the peg successfully a nonterminal n its result is a single cfg with n at its head and whose of tokens corresponds to the input consumed by the execution of the peg proof sketch induction on the combination of the length of the input given to peg eval and the rank of the nonterminal each nonterminal is given a natural number rank such that if executing the peg on nonterminal n can result in to execute nonterminal m without having consumed any input then n s rank is greater than m s the fact that this ranking is possible from the same argument that gives the wellformedness of the peg theorem parser completeness if a parse tree exists for a given input then the peg implementation will find it proof sketch induction on the combination of the length of the parse trees and the rank of the trees head nonterminal as peg execution is deterministic this also implies that our cfg is unambiguous type inference type inference is based on milners algorithm j and hence w we represent unification variables as numbers and increment a counter to generate fresh variables since the is written in higherorder logic in a monad we cannot use the common technique of doing substitutions by updating pointers in the types instead we reuse our previous from the hol examples directory of tions which are not idempotent but are instead designed to maintain sharing for greater efficiency in a pure functional setting theorem type soundness if infer top tm tc te top state tc te state and tm tc te contain no unification variables then type top tm tc te top tm tc te proof sketch the soundness proof is long and tedious but not particularly surprising a large part of the proof is to establishing invariants on the usage of type variables in the various environments and state components of the algorithm there are two ways in which our verification short of what could be seen as an ideal for sml but neither directly affects our correctness theorem first the types of variables are not generalised restricting polymorphism to toplevel and declarations and second we have not verified completeness of the in both cases the potential for the cakeml system to behave is limited to a type error on a declaration that the programmer expected to pass type checking in particular there is no possibility for the programmer to be by the system appearing to returning an erroneous result of executing the definition we gave proving completeness low priority because in practice we find the does not fail on the programs we expect to have types if it did a completeness theorem would tell us that the bug is in declarative type system rather than possibly also in the compilation we now turn to translation from abstract syntax to cakeml bytecode our assembly language for a virtual stack machine which is the final language before translation to x machine code we describe the bytecode in detail in section but first take a highlevel look at the compiler and its verification the main function is compile top which takes a toplevel declaration and the compilers state including environments mapping variables to bytecode stack offsets and returns code and two new compiler states one is used if the code runs successfully and the other if it raises an exception for the verification we define a relation compiler inv s rs z rd bs between the semantic context the module constructor and value environments and the store the compilers state rs the bytecode machine state bs and additional context indicating the size z of the stack before the last complete declaration and information about references and closures in rd we explain the compiler along with its verification beginning with the statement of the correctness theorem for terminating programs for programs see section theorem compiler correctness if top is welltyped evaluate top m c s e top res compile top rs top code and compiler inv m c s e rs rd bs then a run of bs with code terminates with a new state bs satisfying the following condition depending on res if res is a successful result with new environments m c and e and new store s then there exists rd such that bs has reached the end of code no next instruction compiler inv m c s e bs stack rd bs and bs has the result of the new bindings in its output et al section provide evidence that for let expressions is used in practice otherwise if res is an exception with a new store s then there exists rd and bv such that the next instruction for bs is stop bs stack bv bv is a refinement of and compiler inv m c s e rd bs where bs is bs with bv the and of bv is done by the main repl loop after the stop instruction is reached proof sketch the compile top function is implemented using functions for compiling declarations and expressions the structure of the bigstep semantics the proof for each layer is by induction on the appropriate bigstep relation our compilation strategy has three phases translation to an intermediate language analysis for the purpose of compiling functions and finally translation to bytecode we proceed with a description of the implementation and verification of each phase translation to intermediate language the intermediate language il simplifies the source language in the following ways · patternmatching is replaced by conditional expressions and equality tests · named variables are replaced by de bruijn indices constructor names are replaced by numeric tags · all functions are syntactically recursive and may have zero or more arguments · the set of primitive operations is smaller eg no only the translation to il expressions is a straightforward recursion on the abstract syntax of cakeml we also define a translation from cakeml values to il values which makes use of the expression translation since closures are the values verification we give a bigstep operational semantics for the intermediate language similar to the one for the source language the correctness theorem for the translation to il says whenever the cakeml semantics gives a program p a result r the il semantics gives the translated program p a result r that is related to r the proof is by induction on the cakeml bigstep evaluation relation we cannot prove identity between the translated cakeml result and the result produced by the il semantics because closure environments may differ the translation to il sometimes introduces fresh variables that will appear in an il closures environment but not in the translation of the source closures we need a relation on il closures allowing their environments to differ for this purpose we define a relation on il expressions values and environments the relation v z e z e relates an il expression together with the size of its environment to another such pair it is by a relation v vv indicating variables that are assumed to be bound to equivalent values to relate values the relation v v needs no sizes or parameters since closures carry their environments so the size can be computed we have proved reflexive and transitive symmetry fails as explained in the next section and the following two theorems theorem if the il semantics says e evaluates in environment env to a result r whenever v v v holds does also and v env e env e then there is a result r to which e evaluates in env and r r proof sketch by induction on the il evaluation relation the main purpose of the relation is to enable closure environments to be manipulated the second theorem supports the of variables that is required in a closures body when its environment is changed theorem let e be the result of variables in e and suppose v relates indices under the same scheme then v e e proof sketch by induction on syntaxdirected we use these theorems for verifying the translation to il including the removal of pattern matching we also use to relate il function bodies to annotated il closure bodies described below intermediate language closure annotation for every function body we compute how to compile each occurrence of a variable and how to build the closure environment we use flat closure environments that only have bindings for variables that actually occur free in the functions body as an example consider the following il expression written in concrete syntax with named variables but recall that the il actually uses de bruijn indices let val a e val b e val c e fun f h x if x then h else g x f x a and g x f fn y x y b a c in e end analysis of the bodies records this about the free variables for f x arg h arg g rec f self a env cl env for g f rec b env a env c env cl env for x env y arg b env cl env the env annotation gives an index into the closure environment which is itself a list of indices into the enclosing environment so in the anonymous functions closure environment refers to gs argument and refers to the first element of gs environment since would refer to g itself we update the variables in function bodies so that they refer to the closure environment instead of the enclosing environment for example in the body of f the de bruijn index for a is twice because the variables in the enclosing environment are omitted in the closure environment operational semantics also uses closures making the proof of correspondence conceptually straightforward but closures in the semantics contain the whole enclosing environment we generate for each function body a unique label that is used section as a code pointer to bytecode implementing the body verification we store the closure environment information as annotations on the function bodies within the expression the il semantics uses the closure rather than enclosing environment to evaluate a call when such an annotation exists similarly the relation v u z bs z bs allows the bodies in bs and bs to be annotated and uses the closure environment rather than v and z as appropriate the relation is directed hence not symmetric if a body in bs is annotated then the corresponding body in bs must have the same annotation however an body in bs may be related to an annotated body in bs theorem if e is the result of annotating e and e is and has free variables all less than z then z e z e and e is fully annotated with environments that cover the free variables of its bodies proof sketch by induction on syntaxdirected annotation bc inst bc stack op loc n bc value bc state stack bc stack op return call loc loc jump loc loc ref deref update print char label n tick stop pop n shift n n int cons n n el n n n load n store n n equal less add sub div mod lab n addr n num number int n block n bc value n n stack bc value n bc value code bc inst pc n handler n output string names n string clock n figure cakeml bytecode syntax values and machine state cakeml bytecode the target language of the compiler is cakeml bytecode figure a lowlevel assembly language for a virtual machine with a single stack cakeml bytecode was designed with three separate goals to be i abstract as a target for the compiler and its proofs and ii easy to map into reasonably efficient machine code that is iii possible to reason about and verify wrt an operational semantics for x machine code to support i the bytecode has no notion of pointers to the heap and provides structured data cons multiple bytecode values into a block on the stack instead also the bytecode number values are mathematical integers the x implementation includes a library to implement the arithmetic instructions for ii we ensure that most bytecode instructions map to one or two x machine instructions and for iii the bytecode essentially only operates over a single stack the x stack which we access using the normal stack and base pointers and registers see section for the implementation of the bytecode in x the bytecode semantics is a deterministic state transition system the relation bs bs from code the instruction indicated by pc and executes it to produce the next machine state we give some example clauses in figure our data refinement relation l r cv bv says bv is a bytecode value representing the il value cv it is by two functions l to translate labels to bytecode addresses and r providing extra information about code pointers for closures the refinement of closures is most interesting there are two components to a closure its body expression and its environment which may refer to other closures in mutual recursion we use a correspondence of labels to link a code pointer to an annotated il body and for the environment we assume the il annotations correctly specify the closure environment in the il a closure looks like env defs n where env is the enclosing environment and the body is the nth element of the of recursive definitions defs we say l r env defs n block c a block e holds c and e are tags indicating closure and environment blocks when most operations work on the top of the stack but load n and store n readwrite the cell n places below the top and takes an index from the bottom annotations on build the closure environment from env stack cons t n vs xs vs n bs block t rev vs xs return x ptr xs bs x xs pc ptr x ptr xs bs x xs pc ptr xs bs bs bs bs stack xs handler xs ys x xs h ys bs x ys handler h figure cakeml bytecode semantics selection the function fetch the next instruction using the pc and code and updates the pc to the next instruction · has label lab and annotations ann a and ann · for every variable x with an env annotation in ann the corresponding bytecode value bv in satisfies l r env x bv and · for every variable with a rec i annotation in ann the corresponding bytecode value in is p for some p and there are env defs and j such that rp env defs j and env defs i env defs j thus for a function in mutual recursion we assume it is behind the indirection of a the function r acts as an oracle indicating the closure that should be pointed to to tie the the inductive hypothesis in our compilation proof says whenever rp env defs j the bytecode machine binds p to a value bv satisfying l r env defs j bv translation to bytecode the main compilation algorithm takes an il expression as input and produces bytecode instructions additional context for the compiler includes an environment binding il variables to stack offsets and a return context indicating the number of variables that need to be discarded before a jump if the expression is in tail position the correctness theorem for this phase is similar to theorem whose proof uses this one as a lemma assuming evaluation in the il semantics rather than the source semantics in particular we have a relation called il inv that captures an invariant between the il environment and store the compiler state the bytecode machine state and proof information like the l and r functions this relation is used in the definition of compiler inv which the three languages cakeml il bytecode the theorem below depends only on the il and the bytecode theorem if the il semantics says evaluates in environment and store cs to a new store cs and result and all the values in the context are fully annotated then for all bytecode machine states bs satisfying il inv with and cs and proof information including l and r then · if is a value cv then running bs with code from compiling in position leads the bytecode machine to terminate in a new state bs such that il inv holds of cs and bs and bs stack bv with l r cv bv and assuming ret args st running bs with code from compiling in tail position ready to discard and args leads the machine to a state bs satisfying the invariant as above and also bs pc ret and bs stack bv st with l r cv bv · otherwise if is an exception value cx and if vs h st and st then running bs with code for compiling in either call context leads the machine to a state bs satisfying the invariant and with bs pc bs stack bv st l r cx bv and bs handler h · finally if is a timeout exception then a run of bs on code for causes the machine to time out see section for details proof sketch by induction on the bigstep semantics for the il the invariant includes a condition on it must already contain code resulting from compiling all the function bodies appearing in and for closures in cs and this assumption is justified by the compilation of function bodies described below function bodies before compiling the main expression we compile the functions for each body the compilation environment is the closure environment and the return context is tail position ready to discard just the arguments to the function but no local variables we the resulting of bytecode in sequence each by the label annotating the closures body closure creation as we saw in the definition of l r cv bv we represent a closure using a cons block containing a code pointer and an environment block which is built following the annotations on the closure body for mutually recursive closures the rec annotation we build the closure environment using references and update them with the appropriate closures once all the closures are created thereby ensuring mutually recursive functions appear as in the closure environment function calls and proper tail calls the generated code for a function call depends on whether it is tail position or not in both cases we first evaluate the closure and its arguments and extract the code pointer from the closure for a call we use the instruction which generates a return pointer and jumps for a tail call since we are assuming a return pointer is already on the stack we the stack the local variables and arguments then use the return instruction to make the call the key lemma enabling our proof by induction for the function call case says that if ret block c p and l r env defs n block c p then we can establish il inv for bs with the closure environment made from env and the annotations on thus we can use the inductive hypothesis on the closure body even though it is not a subexpression of the original in the theorem statement declarations so far we have at the compilation of il expressions a cakeml program however is a sequence of declarations of types values or structures our il does not have declarations so to compile a value declaration val p e we construct the cakeml expression case e of p vs where vs is a tuple of the variables appearing in p translate this expression to the il and compile it and generate a bit of additional code to extract the new bindings from the tuple for type declarations we need not generate any code at all and simply update the compilers state component mapping constructor names to bytecode block tags modules structure declarations are from the compilers perspective just a sequence of type and value declarations but they must be treated as a single unit so there is a if any of the within a structure raises an exception the bindings for the whole structure need to be discarded therefore we must set up an exception handler around the whole sequence of declarations enabling of the stack before to the next toplevel declaration if the sequence of declarations successfully we pop the exception handler and hence need to shift the stack offsets for the new bindings in the compilers environment we reuse this machinery and its proof for toplevel declarations treating them as structures with one declaration programs so far we have seen our compilation algorithm and how we prove that if a source declaration terminates then the bytecode terminates with the same result by assuming termination we might appear to admit a compiler that causes programs that should diverge to do anything at all including returning a wrong result here we show how to establish that our compiler in fact preserves divergence the proofs of the previous section are all performed in the direction of compilation by induction on the bigstep semantics we would like to handle programs in the same way to avoid establishing a simulation from a smallstep bytecode trace to a smallstep source trace against the direction of compilation and to avoid introducing a coinductive bigstep semantics because the bytecode semantics is deterministic all we have to do is show that the compiler maps source expressions to bytecode expressions first we add optional clocks to the source bigstep semantics and to the bytecode machine state in the bigstep semantics the clock is by on each function call and a timeout exception is raised if a function is called when the clock is in the bytecode the tick instruction the clock and the semantics gets stuck if the clock is the compiler a tick instruction for each source function call and we prove that if a program times out in the semantics with a certain clock then the compiled version times out in the bytecode with the same clock this is the core of the compiler proof for divergence and it follows the same inductive approach as the rest of the compiler proof the conclusion of theorem handles the case of a timeout exception and thereby supports an analogue of theorem for programs it remains to show how to establish our main divergence result when the source semantics ignores the clock and the tick instruction is implemented as a and thus produces no x instructions we sketch the proofs here with a simplified notation we will write c e v for convergence in the source language with clock c to a value or exception and c e for a timeout exception we use a clock of to indicate the version that ignores the clock lemma bigstep totality for all clocks c and expressions e either c e or v c e v proof sketch by wellfounded induction on the ordering of the clock and size of the expression in all but one case the applicable bigstep rules have inductive premises that have the same or smaller clocks because the clock is and smaller subexpressions thus by induction the results for the subexpressions combine to give a result for the expression it is important here that all primitives evaluate to an result the only case where the expression might be is function application but it the clock first lemma bigstep c e v implies e v and e v implies c c e v proof sketch straightforward induction the operational semantics is smallstep so we define an evaluation relation in the standard way c bs bc bs c bs bs bs we say the machine has out if it evaluates to a state with clock and next instruction tick a bytecode machine state diverges if it can always take another step lemma bytecode c bs bc bs implies bs clock and bs bc bs implies c c bs bc bs clock proof sketch straightforward induction lemma bytecode determinism c bs bc bs and c bs bc bs implies bs bs proof sketch the smallstep relation is deterministic by inspection of the rules the main result follows by induction on theorem evaluation of e diverges in the semantics iff the compilation of e loaded into a bytecode state bs diverges in the bytecode semantics proof for the direction we have c e for all clocks c by the source languages determinism and the totality and lemmas therefore by the compiler correctness result we know for all clocks c there is a bs such that c bs bc bs and bs is out now we must show that diverges suppose for a contradiction there is some bs with bs bc bs let c be one more than the number of tick instructions on the trace from bs to bs which is unique by determinism this contradicts the existence of a bs above if evaluation stops before reaching bs it will not have passed enough to the clock and if it reaches bs it stops without timing out the backwards direction follows easily from theorem and the lemmas loop to interact with our compiler we build a repl we define this first as a logic function that implements in later sections we describe how we produce an x machine code implementation of the repl loop bs b input case until toplevel input of none terminate some tokens rest of input case s of failure error msg result error msg loop bs s rest of input success code s let bs code code bs in case bc eval bs of none diverge some bs let s if success bs then s else in result loop bs s rest of input input loop initial state input on each iteration of its main loop part of the input string up until the first toplevel it then calls the step function which performs parsing elaboration type inference and then compilation to bytecode once the input has been turned into code it the code into a bytecode state and starts execution bc eval of the new bytecode state if the generated code terminates then it loops back to the top and starts again here bc eval is a function which describes the smallstep execution of the bytecode semantics this function is total and returns none if the bytecode fails to terminate otherwise it returns the resulting state inside some theorem correct for all inputs i and outputs o if i o then get type error mask o i o where is the repl semantics described in section and get type error mask out the inputs that output type error to let the repl semantics know where the type system should fail proof sketch by induction on the length of i this theorem together the parser soundness and completeness theorems the inference soundness theorem the type soundness theorem and the compiler correctness theorem most of the proof is to showing that the various invariants required by the theorems are maintained across the iterations of loop the verified function is well suited for simulating the implementation in the theorem prover we can evaluate using the hol provers eval mechanism for example eval fun f x x f automatically derives a theorem fun f x x f result val f fn result val it terminate note that this evaluation of inside the logic by inference does not terminate if the bc eval fails to terminate ie this evaluation return diverge most of the complexity in the definition of is contained within the definition of step a function that combines parsing elaboration type inference and compilation to bytecode the next section describes how we construct a verified x implementation of and therefore of in order to make the construction of x for an easier task we use the verified compiler to compile step to bytecode the step function contains the compiler itself which means that this application of compilation amounts to the compiler this section explains the method the next section explains how we use the result our starting point is step we want to have bytecode which is proved to implement the step function the step is defined in logic hol where functions are specified using equations eg it is easy to define a hol constant that is by the equations n n × n in order to apply the verified compiler to functions defined in hol we need these equations to exists as cakeml abstract syntax for function definitions ie we need cakeml declarations defining step a previously developed tool implements exactly this kind of translation given a constant from hol with equations that look sufficiently mllike the tool generates cakeml abstract syntax and proves that the generated cakeml implements the constant described by equations in hol when applied to step this translation produces a long list of bc eval is the bc relation from section cakeml declarations ml repl step datatype datatype fun fun fun repl step x the tool also proves two relevant theorems theorem evaluating ml repl step evaluation of the declaration list succeeds and produces a semantic environment ie a mapping from names to values we will refer to this environment as ml repl step env theorem evaluating repl step the value associated with the name repl step in ml repl step env is a closure which implements step wrt refinement invariants input and output relations between abstract values and cakeml semantic values in the notation of and eval ml repl step env repl step input output step proof sketch by algorithm from and the compiler is then applied to the declaration list the result is a theorem produced by evaluation theorem compiling ml repl step given an initial compiler state init and the declaration list the compiler produces bytecode and a new compiler state compile init ml repl step bytecode proof sketch by evaluation in the logic eval from above next we instantiate the compiler correctness theorem the compile version of theorem for use with theorems and two further theorems are outlined below we omit the definition of run inv theorem running bytecode executing the compiler generated bytecode terminates in some state bs such that this state contains ml repl step env and run inv bs v is true for some v proof sketch by instantiation of a lemma supporting theorem theorem calling repl step for any bytecode state bs semantics value v and x such that run inv bs v and input x v running a of bytecode which calls the code for repl step terminates in a new bytecode state bs and v such that run inv bs v and output step x v in other words calling the code for repl step computes step proof sketch by instantiation of theorem and other lemmas supporting theorem implementation in x the verified x implementation is constructed so that it exactly implements the function from above thanks to the large parts of namely step exist in the form of verified bytecode in other words much of the effort involved in constructing the x implementation of down to producing an implementation of the bytecode that the compiler targets in order to verify the x code we need a semantics a programming logic and proof automation for x machine code for these we build on previous work semantics of x we use a conventional smallstep operational semantics for x machine code this semantics in a definition for bit x that sarkar et al validated against real hardware the semantics was extended in to handle code and used in our previous work on a verified implementation of a repl for lisp the current semantics has a small coverage of the x instruction set however it tries to be as accurate as possible for the subset it describes programming logic for most proofs manual and automatic we use the hoare logic for our previous work on code however for the current work we had to define a new more expressive programming logic in order to state and prove the toplevel theorem the toplevel theorem must be able to specify that the machine code diverges our previously developed hoare logic is only able to specify that a state satisfying the postcondition is eventually reached termination the new programming logic also embedded in hol makes statements using temporal logic about the sequence of all possible executions of the underlying x machine this new programming logic makes judgements of the form temporal code it is strictly more expressive than the hoare triple theorem hoare triple instance of temporal the hoare triple p code q is an instance of temporal p code q temporal code now p now q proof sketch follows immediately from the definitions we define temporal now etc as follows the definitions below take a few concepts from in particular x seq s t is true if t is a valid x trace starting from state s and p s is true if p holds for a copy of a state s with a less precise instruction cache for most purposes simply read p s as p s temporal code s t r x seq s t p s p code code r s t now p assert t assert p t assert t k assert p n t n k assert t k assert p n t n k later assert t k assert p n t n k assert t assert t assert t assert t assert t assert t using these we can specify divergence of a program for example from initial configuration p code will always at some some later point reach a state satisfying q in other words q will be true infinitely many times temporal code now p now q in our theorems we instantiate q to say that the compiled bytecode is still running divergence means that the program runs bytecode forever bytecode heap invariant central to our proofs is the invariant which specifies how bytecode states are concretely represented in the x machine state this invariant is as a state assertion bc heap bs aux s which relates bytecode state bs and auxiliary state aux to part of machine state s the formal definition of bc heap is not shown due to its length however informally this invariant states that · memory is split into two data heaps of which only one is in use at any point in time enabling garbage collection a code heap the normal x stack and a separate global state record · registers hold bytecode values ­ in the case of a block a large number or a this means they contain a pointer into the data heap · the top of the bytecode stack is stored in register · the rest of the bytecode stack is kept in the x stack ie all values in the x stack are roots for the garbage collector · the stack is accessed through the normal stack and base pointers registers and · other registers and state keep track of temporary values the state of the allocator and system configuration · output is produced via calls to a special code pointer for which we have an assumption that each call to this code pointer puts a character onto some external stream in practice we link to cs routine input is handled similarly using · memory contains code for supporting routines the verified garbage collector arithmetic library etc the garbage collector updates the heap and the stack ie the roots for the heap both of which can contain code pointers and stack pointers in order for the garbage collector to distinguish between data pointers and pointers all pointers must have zero as the least significant bit ie appear to be small integers we ensure that all code pointers end with zero as the least significant bit by making sure that each bytecode instruction is mapped into x machine code that is of even length implementation of cakeml bytecode having the representation of bytecode states we define a function that maps cakeml bytecode instructions into concrete x machine instructions ie lists of bytes here i is the index of the instruction that is to be translated i is used for the translation of branch instructions such as jump x i stack pop x x x i stack add x entire bytecode programs are translated by x code x code i x code i x xs let c x i x in c x code i length c xs we prove a few key lemmas about the execution of the generated x machine code theorem x code implements bytecode steps the code generated by x code is faithful to the execution of each of the cakeml bytecode instructions each instruction executes at least one x instruction hence later note that execution must either reach the target state or to an error out of memory error bs bs temporal base x code now bc heap bs base aux later now bc heap bs base aux now out of memory error aux proof sketch for simple cases of the bytecode step relation the proof was manual using the programming logic from more complex instruction such as the supporting routines were produced using a combination of manual proof and synthesis eg theorem x code implements terminating bytecode executions same as the theorem above but with bc instead of proof sketch induction on the number of steps theorem x implementation of step executing the x code for the result of the ie bytecode and the bytecode that calls repl step has the desired effect wrt bc heap proof sketch follows from theorems and the only source of possible divergence in our x implementation of is the execution performed by bc eval when the logic function bc eval returns none we want to know that the underlying machine gets stuck in an infinite loop and that the output the same only the toplevel loop is able to print output repl out aux now bs bc heap bs aux out theorem x divergence for any bs such that bc eval bs none we have bs bs bs bs output temporal base x code now bc heap bs base aux later repl aux now out of memory error aux proof sketch theorem and temporal logic toplevel correctness theorem the toplevel theorem for the entire x implementation is stated as follows theorem x implementation of if the state starts from a good initial state init then execution behaves according to l for some list l of type inference failures temporal entire machine code implementation now init inp aux later l res repl returns out res aux l inp res terminates res l res repl out res aux l inp res res now out of memory error aux here repl returns states that control is returned to the return pointer of aux and out and terminates are defined as follows out terminate out diverge out result str rest str out rest terminates terminate true terminates diverge false terminates result str rest terminates rest proof sketch the execution of bytecode is verified as sketched above the other parts of the x implementation the code the and the code that together the toplevel loop was verified again using a combination of manual hoare logic reasoning and synthesis theorem was used to replace by the toplevel specification small benchmarks to run the verified x machine code we inline the code into a line c program which essentially just allocates memory with execute permissions enabled then runs it passing in function pointers for and the result of running a few benchmarks is shown below execution times are compared with interpreted ocaml cakeml runs the example times faster than interpreted ocaml quicksort queue binary tree compiled ocaml cakeml the benchmark computes the st number using the recursive definition the second benchmark applies quicksort to a list of length the queue benchmark performs times on a purely functional implementation of queues the last benchmark constructs a element binary tree and then it we used ocaml version and design and context our overall goal for cakeml is to provide the most secure system possible for running verified software and other programs that require a platform thus our primary focus has been on reducing the trusted computing base rather than on compiler optimisations or language features trusted computing base our correctness theorem relies on a machine code semantics for x and on a semantics for cakeml if the machine code semantics does not soundly reflect actual processor behaviour then the program might not behave as verified having a machine code semantics in the trusted computing base is to the problem the only alternative is to restrict execution to a verified processor limiting the of the verified compiler compared to one that targets hardware however the target machine code semantics only needs to cover and be tested on the instructions that the compiler actually generates which in our case is significantly smaller than the entire x if a programmer wants to understand what their cakeml program does they currently have two strategies one is to reason about it relative to the cakeml semantics and the other is to verified cakeml from higherorder logic eg using the same technique that we use for in the latter case the cakeml semantics is not part of the trusted computing base because the cakeml is verified with respect to the cakeml semantics in this sense the cakeml semantics is just the interface between the compiler and the users chosen verification approach in the future we hope to implement further verified ways to verify cakeml code in the spirit of the princeton verified software which takes the same viewpoint but for a source language we also trust a small amount of code to set up the initial execution environment with functions to get a character from standard input and to write a character to standard output because our machine model does not include these features a theorem prover or checker is also part of the trusted computing base in practice our proofs can only be checked by automated means too much of their content is in the details furthermore the and machine code synthesis steps use verified computation in the prover itself to create the verified code the proofs generated here are not human readable one could apply a separate proof checking tool eg or simply trust hol which follows the approach and relies for its own soundness only on a small lines trusted kernel we note that we do not rely on the correctness of another compiler in our trusted computing base except perhaps as part of the proof checker or theorem prover other targets other sources cakeml currently translates from an language to x machine code however neither of those choices are by our approach in the future we hope to extend cakeml to generate arm machine code as well because cakeml to a lowlevel machine independent bytecode and then to machine code it only requires introducing a new bytecode to machine code level this means that the amount of effort required to get a verified compiler for a second platform is much smaller than the effort required to build the system in the first place even though going through a bytecode can potentially limit the compilers ability to generate optimal code we consider it well worth it in this context it would take more effort to adapt cakeml to new source languages any of the parser type checker and compilation to intermediate language or even bytecode if the source language is different enough might have to change however this work would not be of a different character ­ it would just be in proofs of different algorithms following the strategy out here in particular the use of clocks section to handle divergence and maintaining equivalent smallstep and bigstep semantics will be helpful in building a verified compiler for any similar language what about ocaml for the features that cakeml supports sml and ocaml are very similar and cakeml follows ocaml in several ways including the restrictions on variables and constructors and our lack of equality types and overloading however ocaml lacks two things that are important to our development deterministic evaluation order and an equality function that always terminates follows reference cells into their contents instead of just comparing them for identity thus in order to be a semantic subset of an existing language sml is our only choice however cakeml to an syntax with these small differences would just be a matter of providing a new and parser related work the verified lisp implementation has a similar goal of verification about the compiler running as machine code however the source language of is simpler than ours with much simpler parsing no type system no modules no exceptions no pattern matching and no higherorder functions thus cakeml demonstrates a substantial of the kind of language that can be supported in a very high setting furthermore does not itself and its toplevel correctness theorem assumes that every input program terminates the compcert compiler and projects based on it including and the princeton verified software focus on a source language in contrast to our mllike language the is on optimisations concurrency and program logics whereas our is on correctness and a very small trusted computing base the project which produced a ­ not formally ­ verified implementation of scheme verification and did their scheme compiler to produce a verified implementation of their compiler is the most closely related work on verification of compiling impure functional programs with higherorder functions compiler has simpler source and target languages and its proofs do not address divergence he the use of parametric higherorder abstract syntax instead of the more conventional substitution semantics for cakeml we made the closure environments explicit in order to keep things simple to the front end there has been significant focus on metatheory for language researchers eg but it has not typically on into the overall context of a verified compiler for type inference and verify algorithm w for a basic typed calculus plus let expressions our overall approach is similar to but they verify completeness and nested lets whereas we have a much richer language our approach to type soundness is similar to ocaml light which also uses a concrete tion for ordinary variables and de bruijn indices for type variables the languages supported are also similar except that they support type abbreviations whereas we support a module system they also use a semantics two other of ml metatheory by lee at al and by focus on sophisticated type system features functors and structural polymorphism respectively verified parsing has been a area recently our work distinguishes itself in its combination of soundness completeness guaranteed termination and relative efficiency et al validate lr automata generated from a cfg proving soundness and completeness however they have to provide a parameter in order to ensure that the execution terminates verifies a sound complete and terminating parsing algorithm for arbitrary cfgs as the input grammars may be ambiguous algorithm returns a list of it is also rather inefficient potentially on earlier still work by and achieves soundness and completeness but is again missing termination the big difference between these approaches and our own is that our approach is not generic as are our peg was and its proofs of soundness and completeness with respect to the cfg were done manually conclusion the primary aim of cakeml is to provide an implementation of a practical programming language running on hardware with the of security and we hope that it will be used as a platform for the development and of programs where their correctness is the most important concern thus the tradeoffs we have made in the design of the project differ from other efforts along the same lines in particular our focus has been on the trusted computing base not on optimisation or on of source language features in this sense we believe that cakeml the verification efforts based around compcert which are on optimisation and programming languages however the design of cakeml does not rule out source or optimisations such as good support for multiple argument functions inlining constant propagation and lambda lifting the interesting question will be how to integrate them into the existing verification without requiring effort furthermore it does not appear difficult to add lower level optimisations with only changes to cakeml bytecode for example the addition of registers and some form of register allocation a verified compiler is most important in the context of verified applications to run on it we are already working toward one example a theorem prover using cakeml as its execution environment and hope that others will join in with applications drawn from a variety of domains references a w appel verified software talk in esop volume of lncs b e a m j n foster b c pierce p sewell d g s weirich and s mechanized metatheory for the the challenge in volume of lncs a and m verified executable parsing in esop volume of lncs a a verified compiler for an impure functional language in popl m felleisen r b findler and m semantics engineering with plt redex mit press j a certified implementation of ml with structural polymorphism in volume of lncs j j and m wand a verified implementation of scheme lisp and symbolic computation ­ hol j the standard theory library in formal methods volume of lncs f pottier and x leroy lr parsers in esop volume of lncs a and h a formally verified parser interpreter logical methods in computer science r and m nominal unification by recursive descent with substitutions in volume of lncs d k lee k crary and r harper towards a mechanized metatheory of standard ml in popl x leroy formal verification of a realistic compiler acm x leroy and h coinductive bigstep operational semantics inf comput a t and a p a certified framework for compiling and executing languages in icfp r milner a theory of type polymorphism in programming j comput syst sci r milner m tofte r harper and d macqueen the definition of standard ml revised mit press m o verified compiler on x in popl m o and g proof a verified implementation in x machine code in volume of lncs m o and j a verified runtime for a verified theorem prover in volume of lncs m o and s synthesis of ml from higherorder logic in icfp m o k and m j c gordon extensible compilation in cc volume of lncs m o s and r steps towards verified implementations of hol light in volume of lncs w and t type inference verified algorithm w in j reasoning s a sound semantics for ocaml light in esop volume of lncs t simple functional sound and complete parsing for all contextfree grammars in volume of lncs s sarkar p sewell f s t t m o and j the semantics of multiprocessor machine code in popl j s v vafeiadis f s and p sewell concurrency and verified compilation in popl d s l peyton jones t and m modular type inference with local assumptions j program a k wright and m felleisen a syntactic approach to type soundness inf comput 