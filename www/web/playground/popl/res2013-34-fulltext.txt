a pattern for bayesian reasoning andrew d gordon microsoft research and university of edinburgh open university university microsoft research microsoft research v microsoft research k rajamani microsoft research microsoft research abstract a bayesian model is based on a pair of probability distributions known as the prior and sampling distributions a wide range of fundamental machine learning tasks including classification clustering and many others can all be seen as bayesian models we propose a new probabilistic programming abstraction a typed bayesian model based on a pair of probabilistic expressions for the prior and sampling distributions a for a model is an algorithm to compute data from its sampling distribution while a learner for a model is an algorithm for probabilistic inference on the model models and form a generic programming pattern for inference they support the uniform expression of common tasks including model testing and generic compositions such as models model and of a formal semantics supports reasoning about model equivalence and implementation correctness by developing a series of examples and three learner implementations based on exact inference factor graphs and markov chain we demonstrate the broad applicability of this new programming pattern categories and subject descriptors d programming languages language constructs and keywords bayesian reasoning machine learning pattern probabilistic programming introduction background bayesian models and inference we give the simple general structure of a bayesian model see for instance many examples follow later in the paper let y be the output of the model such as the object to be or observed and let x be any input information on which to condition such as the feature vector in classification or let w be the parameters of the model and let h be the the key of a bayesian model are the two conditional probability distributions · the prior distribution over the parameters · the sampling distribution w over the output permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm the parameters w the sampling distribution over the output while the h the prior distribution over the parameters given training data d x y we obtain by rule expressions for computing the following distributions · the posterior distribution h · the posterior predictive distribution py x d h assuming that x y are independent from and distributed as x y this fundamental bayesian model represents a wide variety of machine learning tasks there are also a great many machine learning algorithms for probabilistic inference that is for computing exactly or approximately the posterior h and for using py x d h to make background probabilistic programming for inference probabilistic programming language systems allow automatic generation of algorithms such systems include et al et al bugs et al church et al and et al fun et al and iii probabilistic cc gupta et al and and probabilistic scheme others the user writes a short probabilistic program often embedded within a larger conventional program and the system produces an algorithm for learning distributions given by the probabilistic program hence probabilistic programming development costs compared to the alternative of writing the inference algorithm from probabilistic programming is more flexible than the alternative of relying on a fixed algorithm for a particular task as one can easily compose and write variations of models on the other hand for some tasks a fixed algorithm may be more efficient but much progress is being made on inference for probabilistic programs still the current practice of probabilistic programming is lowlevel and probabilistic programs represent bayesian models but simply the code for defining parameters outputs observing data and so on the absence of such structure is a for example in our own experience with fun we have over a samples but very little code reuse even though each sample performs similar tasks such as training parameter learning and prediction we also duplicate code for the task of testing a model by sampling parameters generating data from the predictive distribution and then comparing with the outcome of learning the parameters from the data moreover there is of common probabilistic patterns such as constructing models other probabilistic programming systems share these problems our proposal the pattern the central idea of the paper is to add structure and code reuse to probabilistic programming by representing a bayesian model by a generic type a value of this type is a record containing a together with probabilistic expressions for the prior and sampling distributions the type parameters correspond to the of a bayesian model h th parameters w tw inputs x tx and outputs y ty the aim of the pattern is to make construction use and reuse of models easier rather than to make inference more efficient we are aware of no probabilistic system that writing bayesian models in a generic format common patterns of constructing bayesian models can be written as functions on these typed models given any model we can derive a object which has general methods to draw samples from the prior and sampling distributions for test purposes given any model and a suitable algorithm we can derive a learner object which has general methods to on data and to compute the posterior distribution and posterior predictive distributions fun we evaluate the pattern by developing the idea in detail using fun et al a probabilistic language embedded within f a of ml for net the pattern can be developed in other probabilistic languages too with or without types but fun has both a precise formal semantics and an efficient implementation as background section the syntax type system and informal semantics of fun pattern and a reference learner section describes our notions of models and using fun independently of any particular implementation of probabilistic inference theorem asserts that the reference learner does indeed compute the posterior and posterior predictive distributions based on exact inference and factor graphs we present in section a learner for discrete models that uses algebraic decision diagrams adds as a compact representation of joint distributions theorem shows correctness of the add we show by example that bayesian networks can be presented as models and solved using adds with performance comparable to other systems section describes inference using probabilistic graphical models in et al we describe our typed api for inferring distributions using theory we the previous semantics of fun the original version of fun and its semantics et al did not include sums or observations on composite types did not describe a semantics of fun in the probability monad and did not consider how to compute a density function for a probabilistic expression in section we recall the semantics of fun from previous work et al we extend fun and the semantics with sum types and give an inductive definition for observations on composite types we identify a normal form with a single outermost observation theorem enabling a semantics for many fun expressions using the standard probability monad these results provide a foundation for our semantics of the pattern generic section shows how generic compositions such as models model and of can be seen as model combinators that is f functions for producing models from models fun itself is firstorder in the sense that functions are not values but our combinators are higherorder functions in the host language f theorem shows that we can compute the evidence for a model a measure of how well the model the observed data using a simple enabling a simple definition of these combinators and setting us apart from many other probabilistic languages third learner via markov chain in section we develop the theory and implementation of a learner based on markov chain techniques this learner is built on and a generic system given training data d x y bayesian computations explore different values for parameter w and for each w require us to compute the density of the posterior function that is h hence to implement a learner we need to compute the density of a probabilistic expression we present a algorithm based on the direct symbolic evaluation of a probabilistic expression with only deterministic let bindings verify its correctness as theorem and report our implementation with our method the user provides only a model and our system automatically computes the density of the posterior hence we save the user effort compared to existing practice with and other systems where the user provides code for both the sampling distribution and the density calculation table of model types table at the end of the paper summarizes our collection of typed models our examples demonstrate that a wide range of tasks including classification topic modelling all fit the pattern all our example models have been tested via at least one of our three learner our learner generates code of the same form as one would execute directly so there is no performance our initial learner used an function which was much less efficient than typical functions written in c our current implementation now uses runtime code generation to compile the function yielding performance with the further may be achieved by runtime specialization of this function to the data at hand our practical examples are evidence that a wide range of machine learning tasks are executable using the pattern with no loss in performance in principle but with the advantage of automatic synthesis of test data from the model and in the case of systems such as the automatic construction of the density function section discusses related work and section concludes contributions of the paper the new conceptual insight is that machine learning can be structured around typed bayesian models which are records containing a together with probabilistic expressions for prior and sampling distributions our specific technical contributions · definition of a type of bayesian models with combinators for constructing models and operations to derive and from an arbitrary model · many bayesian examples expressed as such executable models · a formal semantics for models learning and prediction in terms of fun and its semantics using measure transformers and the probability monad · based on algebraic decision diagrams on factor graphs and our generic format for models and generic learner and interfaces have several advantages over conventional probabilistic programming an may new models from models and combinators without writing models from our api is accessible from other languages such as c it is easy to add a new inference algorithm as a new learner finally we enable generic programming for code reuse most of the in the paper are directly imported from our f code and are a of probabilistic fun code and deterministic functions in full f a full version with additional details and proofs is available gordon et al fun probabilistic expressions review we recall the core calculus fun et al here with sum types to support the normal form of section fun is a firstorder functional language without recursion our implementation efficiently supports a richer language with arrays and array and vector and matrix types whose semantics can be seen as for constructs in this core we let c range over constant data of base and unit type n over integers and r over real numbers we write t to mean that constant c has type t values and types of fun uv x c vv inl v inr v a b int real t u unit t t t t value base type compound type let bool unit unit we let vt be the set of closed values of type t real numbers integers and so on semantically we consider real to be the reals but our implementation uses we assume a collection of deterministic functions on these types including arithmetic and logical operators and fst and snd projections on pairs each function f of arity n has a signature of the form val f t · · · tn tn we assume standard families of primitive probability distributions of type t such as the following distributions dist x t · · · xn tn t real bool beta a real b real real gaussian mean real real real shape real scale real real a distribution is a flip the lies in the unit interval and is the probability of true a beta distribution often used as a prior distribution on the of a distribution is a distribution on the unit interval when a and b it is the uniform distribution on the unit interval a gaussian distribution is parameterized by its mean and precision the standard follows from the identity a distribution often used as a prior distribution on the precision of a gaussian distribution is a distribution on the positive reals the expressions of fun are in a syntax to normal form with for sequential composition expressions of fun m n v f v vn let x m in n match v with inl x m inr y n observe f v vn fail expression value deterministic application let scope of x is n matching scope of x is m scope of y is n primitive distribution observation failure we rely on several standard syntactic conventions we write if v then m else n for match v with inl m inr n we write m n for let x m in n when x is not free in n although formally fun uses normal form we often allow arbitrary expressions m in places where values v are expected assuming the insertion of suitable we allow arbitrary length tuples formed by multiple we make use of records and arrays and array where the size of each array is known statically we consider operations on records and on arrays to be reducible to operations on tuples observation and failure expressions represent we usually write observations in the form observe f v where v is short for v vn such an observation expresses on the event that the function f v yields a zero defined as a closed value where every instance of c is the primitive fail represents an impossible event it has the same meaning as an observation such as observe whose function cannot yield zero note that observe is a on bool since any boolean is a zero according to the above definition we write observe x v for observe x v when v c cn and x v is the difference we write m t to mean that in type environment x t xn tn xi distinct the expression m has type t we write for the empty type environment apart from the following the typing rules are standard selected typing rules m t fun observe f v t observe f v unit fun random dist x t · · · xn tn t v t · · · tn t fun is designed as a subset of f so we represent fun expressions using fs features for reflection evaluation and we represent a closed term m of type t by the f m of f type more generally if x t xn tn m t we represent m by the f fun x xn m suppose e is a evaluates e to its value and inside a the symbol denotes expression e the expression e within the the semantics of fun is detailed in section as usual for precision concerning of discrete and continuous probabilities we turn to measure theory formally the semantics of a closed fun expression m is a finite measure m m over its return type a is that the semantics may or may not be a probability distribution that is one whose total measure is still until section we think simply of all fun expressions as defining probability distributions implicitly the measure and use conventional mathematical notations for probability as in the start of section we assume some with basic concepts such as joint distributions and let an inference engine be an algorithm that given a of a closed fun expression m of type t returns a possibly approximate representation of the distribution m m we can represent an inference engine as a function where is the type of the representation models and this section explains the central idea of the paper that the prior and sampling distributions a bayesian model may be represented by a pair of typed fun expressions we introduce the distributions using conventional mathematical notations our formal notation using fun expressions we begin by the idea for a specific example and then generalize a specific bayesian model linear in fun as outlined in the introduction a bayesian model consists of a prior distribution over parameter w given h together with a sampling distribution w over output y given input information x and parameter w viewed as a function of the parameters w with y fixed the sampling distribution is also known as the function the prior distribution represents our about the parameters given h the sampling distribution represents our view of how output y is produced from input x given parameter w we consider the problem of linear that is of finding the best line given a set of points our input data are d x y where x x xn and y y yn are arrays of intuitively we fit a line yi b to the data where the is drawn from a gaussian distribution with mean and precision the expression prior h below expresses our initial uncertainty about the parameters a b and of the line where h provides parameters for these distributions a standard alternative to a constant is to consider a prior over the known as the we discuss in the full version the probabilistic expression x defines how to generate each yi from xi and parameters w in the fun code below we use record and array notations which are eventually treated as operations on tuples the prior and sampling distributions let prior h a random b random random let gen wx for xi in x wa xi these expressions formalize the prior and sampling distributions the prior distribution is the density of m prior h at w while the sampling distribution w is the density of m x at y we the two components of our model in the function predictive below to obtain the prior predictive distribution h the density of m x at y the prior predictive distribution let predictive hx let w prior h in the semantics of the is obtained by forming the joint distribution of m prior h and m x and with respect to m x formally the semantics is obtained as the following integral h we may sample from the prior predictive distribution by choosing h and input x as shown by the following f output val h shape scale val x we first sample w from the prior distribution w prior h and then the output y x val w a b val y we express the posterior and posterior predictive distributions as fun expressions using observe to condition on the data x y the posterior and posterior predictive distributions let posterior let w prior h in observe w let posterior let w posterior in given observed data d x y via rule we obtain a posterior distribution that is the prior in light of the data h the normalization constant is known as the evidence or we also obtain the posterior predictive distribution py x d h py x using a particular inference engine for fun we may obtain concrete representations of the normalized distributions in the case of our running example we try to infer the parameters used to generate our sample data y by running our implementation of fun to compute the distribution x y we obtain the following approximations a gaussian actual a b gaussian actual b mean actual moreover suppose we have new input x by running our implementation of fun to compute the distribution posterior x y x we obtain the following gaussian gaussian gaussian gaussian to summarize we modelled a line by distributions written as the fun expressions prior h and x we ran these expressions to draw samples from the predictive distribution so as to create a d x y we fun expressions for the posterior and posterior predictive distributions and ran an inference engine to learn the posterior and to make given fresh data these tasks are the essence of bayesian reasoning the remainder of this section proposes generic types and interfaces for these tasks typed bayesian models in general in general let a typed bayesian model be a value of the record type where the type parameters correspond to the different data of a bayesian model h th parameters w tw inputs x tx and outputs y ty typed bayesian model type th prior tw gen tx ty given a model m the fun expression h is the the fun expression h is the prior distribution and the fun expression x is the sampling distribution w we treat f expressions such as h as being closed fun expressions although strictly speaking they are f expressions that evaluate via and function application to closed fun expressions the following module packages our linear code as a typed model m we use f to treat the bodies of prior and gen above as fun expressions linear model module type th real real type type tx real type ty real let m h prior fun h prior h gen fun wx sampling parameters and data given any model m with h we construct a new s by sampling w from and providing the methods · tw is w from the prior · ty samples the sampling distribution w the interface type interface abstract parameters tw abstract sample ty end hence a from the prior predictive distribution we omit our code which uses eval to evaluate learning parameters and making given any model m with h and an inference engine we may construct a new learner l with the following interface the learner interface type interface abstract unit abstract posterior unit abstract predict end the type represents distributions over parameter tw while the type represents distributions over output ty different may use different representations our add learner exactly represents distributions over booleans using an add data structure while our learner yields approximate parameters of the distributions of each dimension of the distribution and our learner represents a distribution as an of samples we can think of a fun as an exact representation of a conditional distribution on its return type independent of any inference engine using this idea we present below our reference learner which captures the intended exact semantics of our api by suitable the mutable variable d takes as values fun expressions that represent the current parameter distribution initially the posterior each call to updates d by with the training data calls to posterior and predict return suitable for the posterior and posterior predictive distributions compare with the posterior and posterior predictive functions in section reference learner l for model m let h let d ref h new with member d let w d in wx w member d member let w d in wx theorem after n calls to with arguments d xi · represents the posterior distribution h · represents the predictive distribution py x d h our reference learner code is in fact the basis of our exact learner based on adds our other use numeric representations of intermediate distributions rather than a for example a generic usage of our and is to test whether an inference algorithm can recover known parameters from data consider a learner l constructed from a model m h and some inference engine given some input x we may test the effectiveness of l by constructing a new s for m and h and running the following let w tw fixed parameters on data let inferred distribution on w test how w is according to we abstract this pattern as a function in section generic combinator for models if we assume that the data is a collection d xi of and independently distributed observations then the sampling distribution according to n w w i hence we arrive at our first model combinator given a model that sends tx to ty builds a new model with the same prior but which sends tx to ty learning with any model built from this combinator is an instance of learning where multiple data items are processed simultaneously in the code below we use an f of a to represent a fun expression with two free variables w and xs as described in section combinator to lift model to act on arrays module let prior gen fun for x in xs for example m below is linear on a single x y point and m obtained by our combinator is equivalent to our original model m models in the style of m are useful because we may them with other combinators before applying as shown in section linear again and again let m h prior fun h prior h as before gen wa x let m generic testing a common method to test the effectiveness of a learner on a particular model is to generate sample data for different xi for a fixed w and then evaluate the posterior distribution for w obtained by training on that data we here give a generic procedure for such a test functions for testing let test tw let l let s let y do let l m xs test l xs since the details of evaluating the inferred posterior depend on its representation test simply returns the parameters and posterior distribution to the caller notice how is constructed by a simple application of the model combinator here is an application of to our running example linear using the learner we describe below testing of linear let m let m on one test run we obtained w a b a gaussian e b gaussian mean here the learner has inferred close approximations to a b and with very high precision especially for a a learner using exact inference the exact learner uses symbolic evaluation of boolean functions representing discrete distributions in order to give an answer that is either an exact of each variable or the exact joint distribution let fun be the finite fragment of fun where the only sum type is bool unit unit the only matches are conditionals there are no instances of observe and every random expression takes the form random for some real c the semantics of a closed fun program is a distribution over its discrete return type that is a measure that may sum to less than inference by symbolic evaluation of programs the procedure post symbolically evaluates a fun expression m and computes the posterior over the result of m given a valuation of its free variables the algorithm relies on the following notations we write let x t n in m for the corresponding untyped when n t we write vf for the conditional statement that returns vt when v u and vf otherwise a valuation is a finite map from variables to closed values a valuation is a finite map x v xn vn where each vi we let denote the empty valuation and write s for the set of valuations if v t and is a valuation v is the closed value resulting from substituting x for x in v for all x dom given an open expression m where m t post is a function from valuations s to discrete distributions over vt by uncurrying the semantics of m can also be expressed as a function from s × vt to the algorithm post m computes this function by structural recursion on m the post function is a forward analysis that computes the posterior distribution and is named by analogy with the standard postcondition computation in program analysis post calculation post m s × vt real when m t v post f v vn f v vn true r r v then n else n true · v false · v x t n in n u · x u v the post computation uses four different types of operations on functions pointwise product pointwise sum ifthenelse over a variable or existential quantification the operations and are used for example in the case for if operation is used in the cases for values deterministic functions and and operation is used in the let case each of these operations is directly supported by add packages such as and takes time proportional to the product of the sizes of the arguments in the worst case theorem let m be a fun program with m t for all values v vt v m m v the add learner builds on the reference learner calling the post algorithm on the fun expression returned from its posterior and predict methods an add learner has the following type where is the type of a decision diagram that maps values of type t to probabilities tx ty in our experiments the performance of the add learner is with algorithms implemented in et al report performance in detail for symbolic evaluation of a related imperative probabilistic language example net for the model is a classical example of a net and in our variant the model describes the conditional probabilities of having and the having been on given that the is observed to be in detail given prior distributions for and and the view that has a of the an and some other cause a what is the posterior distribution for and given that the is we perform inference using the add learner described above yielding an exact posterior model module type th real real type b b type tx a unit type type ty bool let prior fun h gen fun wx random random random given an add learner l for this model here is the outcome of true false false true false false true true true a learner based on factor graph inference is a probabilistic programming system which generates efficient scalable inference algorithms based on on factor graphs we compile a fun expression to the input format of and perform inference et al since the original description of fun we have made a series of which make the present paper possible these include the api described next support for arrays and a compiler based on multiple transformations of the fun expression learner for algorithms in we describe our interface for creating based on but omit the details of the implementation which rely on the existing translation from fun to computes posterior distributions from joint distributions involving observed and variables for example given a probabilistic program defining a joint distribution on pairs of type bool × real computes the of the first projection as a value d say of the distribution type and computes the approximate of the second projection as a value d say of type gaussian and gaussian are types representing the distribution as a record of its parameters uses the distribution families of the on these projections as approximate distribution types for the let a type g be a nesting of tuples records and arrays over distribution types such as and gaussian let be g with each occurrence of an type replaced with its range for instance bool and real we perform inference using using the following function where is a dynamically typed value representing the composite of the distributions core inference for fun val tb ta next we describe use of automatic coercions to achieve better static typing than with a compound distribution for g is a value of representing a value of type g a is a function g that a compound distribution for g to the corresponding value to create a learner for m we ask the user to supply f types gw and gy such that tw and ty plus a which is a pair of a and a we have functions to construct these coercions but we omit the details the resulting learner does approximate inference on the model m after each call to we run inference and record the result at type gw calling posterior returns the current distribution calling predict runs inference and we return the result at type gy constructing an learner type gw gy val learner th example gaussian here is the model for the gaussian the parameters are its mean and precision their are a gaussian and a in turn the consists of the parameters for the the sampling distribution simply from the gaussian ignoring the input of type tx unit a model that ignores its input is said to be gaussian model module type shape ta scale tb type type th gaussian let m prior fun h mean let m let p sh let sc gen fun wx let mp we obtain a learner of the following type the subject of the type for y gaussian is real while the subject of the type for w is we make tw generic so it can express both these types after inference we can the parameters of the inferred gaussian and distributions to learn the inferred mean and variance of the data and the remaining uncertainty is a standard binary classifier built from a gaussian its model shares the same prior and its output is a probabilistic boolean dependent on its input we use this model in section model let prior gen fun wx x we have a range of other models including multivariate linear the point machine classifier the latent allocation topic modelling et al and et al but we omit the details semantics of models measures and monads in this section we review the semantics of fun et al and extend it with sum types and observations on composite types based on our experience with fun models their structure often includes a single outermost observe statement here we show that given a certain compatibility constraint on its semantics any fun expression can be transformed to one with a single outermost observe preserving the semantics as part of the proof we show that the semantics of fun models is closely related to their semantics when considered as programs of the stochastic lambdacalculus of ramsey and this the relationship between our semantics and the probability monad in particular for programs with none or only a single outermost observation measure transformer semantics for fun expressions in this section we recall the used in et al and augment these with operations on sum types and failure we also give an inductive definition of the semantics of observations on composite types and recall the compositional denotational semantics of a fun expression as a measure transformer augmented with sum types for more and see et al we conclude by introducing the notion of compatible measure and show that it is sufficient but not necessary for all observations to be welldefined we define the measurable sets of type t written mt as the subsets of vt which in particular contains all closed sets we write f t u to mean that f is a measurable function from type t to type u that is that f a mt for all a mu let m t be the set of finite measures on t that is additive functions from mt to the nonnegative real numbers let the distributions s t be the finite measures whose range is contained in let t u be the set of measure transformers from t to u defined as the partial functions m t m u if x t xn tn we let range t · · · tn we make use of the following constructions on measures · the measure is v a if v a otherwise · given a function f t u and a measure µ m t there is a measure µ f m u given by µ f b µ f b we can add two measures on the same set as µ the disjoint sum µ µ of two measures is defined as µ b · given a measure µ on t a measurable set a mt and a function f t real we write a f or equivalently a f x for standard integration this integration is always welldefined if µ is finite and f is bounded · given a measure µ on t a function d µ t real is a density for µ iff ad µ d for all a where is the completion of the standard measure on t which is built by taking products and disjoint sums of the counting measure on int and the interval measure on real the semantics of a fun program is given in terms of the following measure transformers which standard theorems in finite measure theory measure transformer combinators pure t u t u t t t t t t extend t s u t t u observe t real t t t u t u t t u fail t t to lift a pure measurable function to a measure transformer we use the combinator pure given f t u we let pure f µ a µ f a where µ m t and a is a measurable set from u to sequentially compose two measure transformers we use standard function composition defining t u u t the combinator extend extends the domain of a measure using a function yielding distributions we let extend m µ ab vt x y ab the combinator observe computes the conditional density of a measure µ over t on the event that an function p of type t real is zero note that this is we consider the family of events px r where r ranges over r we let br be the closed ball of around r that is x r and define µ ap r r the at p r of a by conditional density µ ap r µ ap r br d if the limit exists we define observe p µ a µ ap as an example if t u real p x yy c and µ has continuous density d µ then observe p µ a d µx c d x and r µ ap x d x notice that observe p µ a is greater than if the density at p is greater than so we cannot consider only transforming distributions support for sum types new to add support for sum types we introduce a new measure transformer we let t t µ a tx µx a tx µ xa we also let fail µ a observations on composite types new the fun language of et al permits observations only on atomic types to achieve a normal form theorem we here extend observations to composite types we write obs f u if f t u then the measure transformer obs f has type t t below we let b unit tu t u and tu t we write split p pure ps then inl s else inr s observations on composite types obs f u obs f real observe f obs f int split s f s pure id fail obs f unit pure id obs f u u obs snd f u obs fst f u obs f u u split f obs either id u f u obs either u id f u observation at real type is primitive it is trivial at unit type at int we fail unless f returns for products we observe each component in turn for sum types we split the set of states depending on the branch of the sum by f and run the observation in each branch note that observations on discrete types yield a series of splits where some branches fail and that obs int fail measure transformer semantics we can then give a compositional semantics of a fun program as a measure transformer taking a measure over assignments to its free variables and returning a joint measure over variable assignments and return value to bind the values of a valuation to the corresponding variables we use pat and x x as patterns and in return values below we define the measure transformer semantics of a program as a where xs are the free variables in the program we use an auxiliary definition a for the semantics of the program m in the scope of y for closed terms m we obtain m m by transforming the trivial probability measure each signature val f t · · · tn tn means that f is a total function with f if dist t u and v vt there is a corresponding measure on vu this measure is a probability measure for legal values of v and otherwise such as in it is the zero measure to apply below we need to lift a sum to the top level of a type we do this with lift t u u t u t u defined as x y with inl z z inr z z measure transformer semantics of fun m m a µ m m a a m × a a a pure y z a v xs pure a f v pure f v a match v with inl x m inr y a v xs pure lift a a a let x m in a a a xs extend a observe f v xs obs f v a xs a fail a xs note that a observe xs a indeed fail suffices to implement all observations on discrete types by inlining obs implementing split using if proposition static adequacy if m t then a range range × t as seen above observe p µ might be undefined if its defining limit does not exist we here give a sufficient condition for the limit to exist we inductively define compatibility of a measure with respect to all the observations in a composition of measure transformer combinators as follows we write µ t for µ is compatible with respect to t compatibility µ t t t u and µ m t µ pure f µ extend m µ fail µ µ t t µ t u iff µ t and µ t iff µ t and t µ u µ observe p iff p is an affine function and and there is p is not proposition if µ t then t µ is defined compatibility is not necessary for t µ to be defined hybrid measure let hybrid if then else let hybrid the measure µ m hybrid is the average of a gaussian distribution and a line mass at y here µ observe x yy but we do not have µ observe x yx because the line x the line mass at y where the density fails to exist however by of observe we get observe x yx m hybrid r · · m hybrid where is the probability density of the standard normal distribution at note that as the precision r above grows the weight of the resulting distribution grows with no upper bound monadic semantics for fun with fail if m does not contain any occurrence of observe or fail then m is a term in the language of ramsey and which has a semantics using the probability monad to treat fail we work in the monad where the set of admissible distributions µ also admits µ cf the semantics of et al the valuation maps the free variables of m to closed values monadic semantics of fun with fail pm µ f a f xa return v a if v a else zero a monadic bind monadic return monadic zero pv return v p f v vn return f v vn v with inl x m inr y n pv either x v y v x m in n pm x v zero proposition if x t xn tn m t and xs x xn and all observations in m are fail then a extend v x v xn vn in particular if m t we have m m pm a normal form for fun expressions observation translation om o does not appear in n f v f v x m in n let x o om in let y o on in y o o v with inl x m inr y m match v with inl x let r o om in r inl o inr y let r o om in r inr o om m otherwise proposition if m t then there is u such that om t u theorem if m t and n let ro om in observe or and µ a then a µ a µ corollary normal form for closed terms if m t and n is as above and a n then m m m n the program m observe fst hybrid does not satisfy the compatibility precondition of the normal form theorem this can be checked using static analyses et al a that can determine if m om is continuous and thus admits a density a more sensitive analysis could additionally determine the of the density function in many cases allowing to check compatibility statically the results of this section imply that models that is generative ones and models with discrete observations only have semantics that correspond to their monadic semantics so we can use the latter for its simplicity generic probabilistic conditionals perhaps surprisingly the if expression gives rise to three useful and interesting ways of composing bayesian models models model and a of we also show how to use the if expression as a general means for computing model evidence and evidence bayesian models given a number of models mk with k k with the same types of inputs xi and data yi we can create a of these models by introducing an variable zi independent given w for each sample yi that indicates which component mk it was generated by this composition is helpful when the data can be generated by one of several known models below we write wk and hk for the parameters and the associated with model k and w for w wk the sampling distribution is then given by nk w w mk wk i k we here give a generic combinator for creating a of two models given a prior over the probability of choosing the first distribution model combinator let m real prior fun h h gen fun if then wx else wx the call to is a for the avoids the of learning symmetric solutions we can create a of two gaussian models where we have no prior knowledge of the probability of each model being used of two gaussian models let m such a model is useful for a scalar property of two of unknown sizes model evidence by a conditional an important concept in bayesian machine learning is the notion of model evidence which intuitively is the of the model given a particular set of observations it is for instance used to choose between different models of the same data model selection ch and as an objective function to in certain inference techniques if m is a closed term we define e m m m that is the total measure of the semantics m m note that e m may be different from if m contains instances of observe or fail as discussed in section more generally if m t we let e m µ a µ when choosing between two or more different models m and n for the same data we typically want to choose the model that has the given the observations of the data the presence of arbitrary in the language allows to compute the evidence of a model in a uniform way more generally the ratio of the evidence of two models also known as the factor can be computed as the ratio between the probabilities of the two possible outcomes of a boolean variable compare and by inferring the posterior probability of an a priori selector variable being true evidence ratio by e m n e m n let x in if x then m else n x lemma if m t and n u and µ m range then e m µ a e m µ s true s e n µ a e m µ s false s proof by expanding a e m given lemma we can compute the evidence of a model m from its evidence ratio to the trivial model which has evidence theorem if m t we have e m · m e m true for open terms if m t and µ m range then e m µ · a e m dom µ s true s for this way of computing model evidence to work it is critical that observe denotes it does not generalize to languages such as church et al where observations queries correspond to a distribution in such a language m e m n true for all admissible m n the technique also does not work in languages where the probability distribution of a program is the limit of its successive approximations such as probabilistic cc gupta et al in such a language m e m true for all m frameworks based on sampling such as bugs also fail since containing random variables require a facility for computing the evidence of a which sampling does not provide and model in section we were combining models mk by choosing a model for each data point another standard notion of composition is model et al where we have some prior about how likely each model mk is to have generated all of the data that is then updated based on the evidence of each model given the data that we here assume to be kn w w pz kw mk wk k i we show below a combinator for the case k the parameter of the combined model includes a random bool switch which is to generate each output yi from the model combinator for model let m prior fun h h gen fun if switch then wx else wx the posterior distribution over the gives us the evidence ratio between the two models m and m cf lemma with the prior pz pz d h d h h h pz pz h h of a powerful counterpart to the models discussed in is the of model et al and its hierarchical variants and and the idea is to use a socalled model w to decide for each input xi which model to use for generating the corresponding output yi we consider a of k models with conditional sampling distributions mk wk and a model w with prior resulting in the combined sampling distribution nk w w pz mk wk i k as before we here implement the binary case with two data models mk with k t f with independent given their parameters pw wf wt h ht hf ht hf combinator for of let prior fun hc h h gen fun if then wx else wx the hierarchical of model and and can easily be obtained by a tree of calls to the above combinator it is also straightforward to build an nary version of this combinator from the above construction or a variation that operates on arrays of models with identical type parameters some examples of hierarchical of let m let n the model m a line to the data the model m above attempts to fit two different lines l and l and to find a point x where the data shifts from being to l for x x and being to l for x x the model n attempts to fit four lines with three separating points and operates on arrays of data a learner based on inference markov chain methods are an important class of inference algorithms for bayesian models because they make it possible to obtain samples from the posterior for a wide variety of models even if that posterior is not in a simple family of parametric probability distributions or the idea of is to construct a markov chain in the parameter space of the model whose distribution is the posterior distribution over model parameters provides an review of methods as an example implementation we consider and an implementation of an adaptive based on the algorithm et al all that is required to apply an algorithm to a particular model is the ability to calculate posterior probabilities for a given set of parameters the algorithm then generates an of samples from the posterior this serves as a representation of the posterior or to calculate desired distributions of individual parameters or other under the posterior distribution direct calculation of et al a report an algorithm but not an implementation for computing the of the distribution computed by a probabilistic program and a type system that guarantees their existence their algorithm uses integration at every we here implement a simplified version without but instead limited to deterministic variables only this pattern is common in the realworld models we have studied for greater efficiency and simplicity in unpublished work et al b implement a more general algorithm for calculating of fun programs we describe a recursive function pre which is an effective partial algorithm for calculating the for the parameters of a generative model written in fun it is standard to compute to avoid when dealing with very small probabilities the pre function is a backward analysis that computes the density function and is named by analogy with the standard precondition computation in program analysis calculation prev m r prev u log if u v else log prev f v vn log if f v vn v log otherwise prev prev match u with inl x m inr y n prev x u m if u inl u prev y u n if u inr u prev let x m in n prev x u n if m is deterministic and m evaluates to u otherwise prev fail log prev observe f v when defined that is not the prev m function computes the density of the parameters in given the data v theorem if m t and is a valuation and v vt and prev m then prev m pm v the of the parameters vw is then obtained by adding the of the prior at vw which is obtained by calling h vh prior where vh is the to the density w vw m here is the actual function we pass to from our learner space more detail let let fun w for x in xs wx let tw real fun w w pre ys h p here is the observed data from training and m is the original model though not shown here the learner represents distributions simply as an an array of samples example as a typical example we present a simplified model of growth adapted from a example given an array of deterministic data the model generates the mass of a on x assuming that x the parameter of the model is a record of numbers the initial mass growth rate alpha for growth sensitivity and the of some each field is given a gaussian prior the mass is calculated by a growth function the argument of below on the initial mass this deterministic computation is finally by some drawn from a gaussian of unknown precision obtained from model prior omitted due to lack of space fun wx first grow let let mass compute the mass after x compute next mass in a time series fun mass i i let r mass i mass i exp rr x finally add to perform inference on this model a user must also provide a function computing the of the models parameters given some observed data here pairs of and it is this function that algorithm attempts to over the parameter space moreover the user typically also needs to write an explicit generative model for producing based either on the mean of the obtained posterior parameter distribution or better yet by error propagation using an of parameters drawn from this posterior instead we use the pre algorithm described above to automatically compute the function from the generative model adaptation of our learner to related methods such as the computation of either the maximum or the maximum a probability map estimate appears straightforward but is beyond the scope of the paper related work formal semantics of probabilistic languages there is a long history of formal semantics for probabilistic languages with sampling primitives often with recursive computation one of the first semantics is for probabilistic which the core functional language with weighted binary choice for discrete distributions kozen a probabilistic semantics for with random assignment he two equivalent semantics one more operational and the other denotational and morgan develop a theory of abstraction and refinement for probabilistic while programs with variables based on weakest preconditions jones and plotkin investigate the probability monad and apply it to languages with discrete probabilistic choice ramsey and give a stochastic calculus with a semantics in the probability monad and provide an embedding within haskell they also do not consider observations several languages such as and and et al and the informal sampling semantics of et al have boolean assertions or fail statements that give rise to such languages support the operations and evidence of section for discrete observations only the concurrent constraint programming language of gupta et al allows describing continuous probability distributions using independent sampling and constraints however their semantics of constraints is different than that of fun observations this makes less suitable for compositional bayesian modelling since computation of model evidence using an if statement theorem does not work the program choose x from in if x then b p yields probability at most of b being true in contrast the semantics of fun allows computing e m for models with continuous observations using the if statement of theorem as do the direct factor graph semantics of et al using and probabilistic languages for machine learning previous programming models for machine learning mainly represent particular implementation strategies rather than general bayesian models an exception is church et al which represents probability distributions over lisp terms as lisp programs and uses various inference techniques however since every admissible term denotes a probability distribution e m always yields true with probability early work includes that of et al where a probabilistic model is represented as a functional program with probabilistic choice et al is a library for constructing factor graphs bugs et al uses sampling for bayesian inference on bayesian networks represented as imperative probabilistic programs bayesian parameter and utility but only works with discrete datatypes et al represents markov logic networks which are inherently discrete park et al also define a probabilistic functional language where as in church terms always denote probability distributions et al is an xml format for representing instances of a range of models including association rules networks decision trees support vector machines etc does not represent arbitrary graphical or generative models in our terms a model corresponds roughly to a learner we have not developed any format for a format based on may be suitable example learner a a two in a a gaussian in gaussian mix in gaussian mix f f in lin reg in mv gaussian in th bool int int unit tw bool list list bool list list r r real n gaussian beta r vector m w generalizes to multiple dimensions n multivariate gaussian distribution r r r r tb tb a unit type r r heads tb heads tb a unit type gaussian tx ty bool bool bool list list int int int bool list list int int int bool unit real n unit real n unit real r int real r bool n real real n w unit r n players int g p ta p int r r r r shape r scale r table rows show types for l for m inference using adds the idea of using adds for probabilistic inference has been explored before and define affine algebraic decision diagrams to perform inference over bayesian networks and markov decision processes et al have used a variants of adds to perform probabilistic model checking in the project and have used adds to symbolically simulate markov chains and use adds to represent factors in a bayesian network and thereby perform efficient inference via variable elimination in contrast the add described in this paper avoids factor graphs and uses adds to represent symbolic program states which are distributions at every program point much like a dataflow analysis or an abstract interpreter cousot and cousot et al develop an approximate representation for discrete distributions based on abstract interpretations with application to security policies conclusions we proposed typed programming abstractions models and for composing and training and with bayesian models we are aware of no prior generic abstractions for bayesian models future work includes adding functions over recursive types and general recursion to the fun language we will also investigate the possibility of the condition of compatibility of a measure with respect to a model acknowledgements about this work with john robert matthew smith and john were and on a draft references g b f and s probabilistic relational reasoning for differential privacy in j field and m editors popl pages ­ acm s a r w and a g gray a type theory for probability density functions in j field and m editors popl pages ­ acm a s j a d gordon and c deriving probability density functions from probabilistic functional programs draft paper b c m and m bayesian hierarchical of in c and u editors uncertainty in artificial intelligence pages ­ morgan d m a y ng and m i latent allocation journal of machine learning research ­ j a d gordon m j and j van measure transformer semantics for bayesian machine learning in european symposium on programming esop volume of lncs pages ­ springer available at http m and o on the representation of probabilities over structured domains in computer aided verification cav pages ­ m and a compiling bayesian networks using variable elimination in international joint conference on on artificial intelligence pages ­ g s k rajamani a v a d gordon and j bayesian inference for probabilistic programs via symbolic execution technical report microsoft research p cousot and r cousot abstract interpretation a unified lattice model for the static analysis of programs by construction or approximation of fixpoints in popl pages ­ a modeling and reasoning with bayesian networks h iii hierarchical compiler available at p s d h m and p markov logic in l de p k and s editors probabilistic inductive logic programming pages ­ springerverlag berlin m and s functional probabilistic functional programming in haskell j program ­ w r a thomas and d j a language and program for complex bayesian modelling the ­ m a categorical approach to probability theory in b editor categorical aspects of topology and analysis volume of lecture notes in mathematics pages ­ springer berlin n v k d m k and j b church a language for generative models in uncertainty in artificial intelligence pages ­ press a d gordon m j g t a s rajamani and c a pattern for bayesian reasoning technical report microsoft research a m w chen and g an open standard for sharing models the r journal may v gupta r and p stochastic processes as concurrent constraint programs in popl pages ­ w k sampling methods using markov chains and their applications ­ r t and t a bayesian system in advances in information processing systems pages ­ j a d a e and c t bayesian model a statistical science ­ r a m i s j and g e adaptive of local computation ­ c jones and g d plotkin a probabilistic powerdomain of evaluations in logic in computer science lics pages ­ ieee computer society m i and r a hierarchical of and the em algorithm computation ­ o and c probabilistic programming using generalized in uncertainty in artificial intelligence d d a and a effective bayesian inference for stochastic programs in pages ­ d kozen semantics of probabilistic programs journal of computer and system sciences ­ m z g and d quantitative analysis with the probabilistic model checker in quantitative aspects of programming languages volume of pages ­ d j c information theory inference and learning algorithms p s m and m dynamic enforcement of security policies in computer security foundations symposium pages ­ a k and s probabilistic programming via defined factor graphs in advances in information processing systems pages ­ a and c morgan abstraction refinement and proof for probabilistic systems in computer science springer n a w m n a h and e equation of state by fast computing machines journal of ­ t a family of algorithms for approximate bayesian inference phd thesis mit t and j m in advances in information processing systems pages ­ mit press t j j and a software available from r m probabilistic inference using markov chain methods technical report dept of computer science university of september s park f pfenning and s a probabilistic language based upon sampling functions in popl pages ­ acm j and g probabilistic reasoning in systems networks of inference p the category of markov kernels electronic notes in theoretical computer science ­ a a probabilistic rational programming language in b editor international joint conference on artificial intelligence pages ­ morgan a the design and implementation of a generalpurpose probabilistic language in l and b editors introduction to statistical relational learning mit press a practical probabilistic programming in p and f a editors inductive logic programming volume of lecture notes in computer science pages ­ springer d and v user guide available at a report on the probabilistic language scheme in proceedings of the symposium on dynamic languages pages ­ acm n ramsey and a stochastic lambda calculus and monads of probability distributions in popl pages ­ n probabilistic in mathematical foundations of computer science volume of lncs pages ­ springer s and d a affine algebraic decision diagrams and their application to structured probabilistic inference in international joint conference on on artificial intelligence pages ­ j t e w and b fischer program synthesis system users manual technical report research center f cu decision diagram package release software available from d net components from f integrated queries and heterogeneous execution in a kennedy and f pottier editors ml workshop pages ­ acm j and t probabilistic programming with machine learning school lecture notes available at http 