a parallel approach to compilation laboratory introduction design of programs to run on computers with vector processing capability requires ment of many long established programming tech these vector oriented solutions are not limited to those few computers with special vector hardware current experiments indicate that the performance of a scalar computer with a high speed instruction cache and overlap such as the can be significantly improved when a program consists of a series of loops in the programming problems languages area work in has included of vector extensions into languages and also the recognition of fortran which can be into vector instructions another area for attention is vector the compiler itself this project was in by the lan guage group at laboratory the apl compiler project must actually be considered experimental in several different but related aspects this paper will concentrate on the compilation of a program using vector instructions but the other aspects of the project also enter into the discussion and a brief introduction the high level of the tion set a real challenge of providing a high level language which can offer a al to programming directly in machine lan guage the similarity of apl and the star instruction set made apl a natural candidate however the dynamic nature of apl requiring a great deal of runtime overhead was considered instead of designing a new language the choice was made to eliminate those aspects of apl which required the runtime overhead this required limiting the domain of the operations to vector and scalar operands and adding a set of declarations to bind the scope type and maximum size of the variables in a program there are really two problems first to compile any language with the star as a target machine and second to compile an apl subset regardless of the target machine care was taken in selecting the apl subset to ensure that the resulting language was compatible with the apl interpreter so that the interpreter could be used to develop apl star programs since the compiler was intended to run on the star the next question to be was what language to use to develop the compiler again apl like the best choice because of the availability of the interpreter the compiler is written in so that an even to the star would be possible the choice of apl yet another question which was explored suitable as the project is apl a language for a large problem such as compiler writing returning to the question of the definition of a compiler the general problem is to find successive transformations which can be applied to large portions of the input program translating and reducing it step by step to a machine code representation compilation is no longer the proc of an occurrence of a condition in a given state and taking some appropriate action instead the compiler needs to recognize all occur of some condition in a given state and take the appropriate action this approach to compiling was quite success for lexical analysis and symbol table tion the problems involved in parsing and code generation met with varying of success and these problems are much more dependent on the structure of itself so the characteristics which or solution efforts do not necessarily apply to other languages or machines the remaining sections of this paper describe in order the lexical analysis the syntactic analysis of both declarations and executable statements and code generation code generation which is dependent on the star instruction format is discussed only briefly lexical analysis lexical analysis is the part of a com to as a sequence of transformations the steps listed below characterize the process for most languages most of these steps consist of the beginning and end of all the items in some lexical class forming a bit mask to extract the elements and marking their places with single representative are placed tokens in a separate the extracted buffer where elements they can be further processed in a manner figure follows the steps through as they occur in a segment of an program a description of the process for fortran is given in lexical analysis transformations change the source from physical records to logical records this includes removing compressed restrictions marks ii sequencing and other information input format mask out program comments extract any other input elements which are not subject to syntactic analysis such as text strings or format specifications a single descriptor is left to mark each position and extract constants from the source converted values are stored in a separate vector a pointer to the value is left in the source string tokens are identified these may include syntactic words of the program as well as identifiers these tokens are moved to another buffer for identification and a single marker holds each place all are removed from the source at this point the size of the input has been greatly reduced one characteristic of this re form is that there are no remaining variable length tokens each string identifier constant and operator has been reduced to a ie entry this is an important detail when looking for the patterns of tokens which can be identified as syn tactic elements of the language one further source reduction which may be classified as lexical is the identification of the tokens the list of identifiers and syntactic elements is reduced to a list where each name occurs exactly once tokens which may appear as either syntactic occur first in the symbols or identifiers list so that syntactic symbols have a known index of figure an algorithm in the list see step similar to an memory is used to find all of the different tokens during this process additional information about the positions of a token relative to all other occurrences of the same token might be recorded such information could be useful in later tion passes of the compiler source representation of program segment step sequencing information is removed and separate lines are into one long source string step comments are located by finding o not followed by and forming a mask from that point to an end of line marker step character strings are masked and put into a special buffer out step constants are located converted and replaced pointer to their value extracted by a step all tokens are extracted replaced by a marker and stored for further processing step are compressed out step finally matched keywords unique source the buffer is against the list of known and itself to come up with to replace in the syntactic analysis lexical r half comment x begin line end o half buffer char x begin line end q ii half buffer begin line q x r strings begin n half buffer char l s line s constants q x n half buffer buffer s line s z d q c x p half buffer char line z b q strings begin end constants discarded word list bit char half full ext global buffer line figure the process of parsing a program involves a syntactic replacing it by a representative symbol and invoking the appropriate semantic action one approach to parallel parsing might be informally described as all occurrences or as many as pos of a given syntactic construct this is done by detecting special a unique construct or context which signal for adhoc parsers this proc is very much dependent on characteristics of the source language in fortran for example there are no words so the presence of a keyword at the beginning statement used to classify statement types the keyword well be a variable name the problem is further if are not significant the lexical analysis may have recorded a of keywords and identifiers as a single alpha numeric token block structuring the parsing the context of a construct can of lines of source program classification of statement types in algol provides an extreme of this sort lem a can begin a closed serial clause a conditional clause a case clause or a clause the correct classification cannot be made until the other con period or vertical bar of the clause is located if all of the pairs of the program have been correctly matched this is not a difficult decision the problem becomes a serial however if the pairs of the source program contain errors matching block open and close symbols is not the only kind of problem encountered in a block structured language the nesting of declarations also presents a context problem it is not difficult to find all of the and applied occurrences of a given identifier but the problem of matching the applied occurrences with the correct defining occurrences without re sorting to serial processing is nontrivial is not free of these problems there is no to about but the parentheses and square brackets must still be correctly balanced on a statement by statement basis the keywords used in the declarations are not so additional care must be taken to separate them from variables since the tions do not share any significant amount of syntax with the executable statements they are handled separately as described below all declarations start with a special symbol pair which appears to be a comment to the interpreter so the unique context necessary to split the declarations from the remainder of the program is immediately able parsing of the executable statements is discussed later analysis of declarations and symbol table organization specific details of parsing tions are for the most part unique to the syntax however the analysis of the tions is of the processing of recursively defined lists of notions which occur in many lan guages e g real x y z from algol and fortran and also of the factoring of attributes very similar to that of pl pl declare a fixed b float static c controlled external a so char c global the steps below describe how the declared names are identified and the attributes are col with the analysis of the declaration syntax complete the information is organized symbol table form for use in processing into a the ex statements figure illustrates these steps for a small example analysis of declarative syntax step lexical is complete and tions have been separated from executable statements all of the separate statements are put together as one long statement by replacing the declaration with step is to make sure that they are properly matched this is very important for all of the following steps step the declared identifiers are located by finding the first non past each these identifiers are removed and form the basis for the symbol table step constant expressions must be removed because they may contain identifier names which conflict with attribute names there are no keywords the expres sions also may contain struc ture which should be removed before the steps these expressions are stored in a separate vector for later proc and the positions are marked by a exactly has the form declaration declarations identifiers once each are required declarative to be list declaration declaration i declaration list declaration identifier declaration attributes list i attributes where attributes is a possible empty list defining type size and scope of the identifier types are bit character bits bits and bits constant value or function the size attribute specifies either scalar or vector constant express ion the scope attributes specify local global known to other functions or external known to all programs which are resolved by the additional attributes allow the user to exercise control over the memory allocation of his variables since it may be im that some variables do not cross page boundaries the default attributes are local scalar source form of declarative token representation after statement lexical step location of declared names step names are removed and expressions are located step expressions and program are removed profile is built step par information step the attributes are located and their profile numbers recorded step start and stop vectors describing attributes are built attributes start stop el e a char a half global attributes recorded in symbol and resolved table n a b char c half global constants unique word list bit char half full ext global a b c t t t declared names a a a a b and c in unique word list f t expressions c ax c running sum of depth profile numbers of right parentheses count left parentheses of corresponding attribute locations match profile numbers tl from step attributes compared to right parentheses stop attribute stops start x p starts starts identifiers bit char half full ext global local vector scalar unique word constants expressions list a a sizes el e bit char half full ext global a b c ca x c analysis of declaration figure syntax step profile numbers are created for the remain ing tokens these numbers are a composite number built from the running sum of the count and the depth count of each item step the structure is recorded two vectors are built is a vector of the profile numbers of all the right parentheses is a vector of the count numbers of the left parentheses this vector is so that the entries correspond to the entries in r par en i e the open parentheses are matched with the closed parentheses step the attributes in the declarative string are located all of the tokens remaining in the string are attributes there are also a few special symbols such as which mark the of attributes the vector is a vector of the profile numbers of these attributes a vector of counts for the attributes is also needed for step but this is easily found by taking the integer part of the vector step an attribute is if and only if its profile number matches the profile number of a closing if the attribute is not then its count tells which entry it applies to if the attribute is the count of the open which corresponds to the matched closing tells where the factoring starts the count of the attribute or the closing tells where the factoring stops using the vectors constructed in steps and the following apl state ly ments produce the desired values yields the index of the first occurrence of each element of the x vector in the y vector if the element does not occur the corresponding element of the re is one greater than the length of the y vector lx x to integer px yields the length of the vector x match pr stop start match attributes attributes at this point all of the useful information in the declarative statements has been recorded and the symbol table can be constructed using the start and stop vectors bit vectors are built for each attribute default attributes can be recorded by the bit vectors for the declared attributes e g local global sim conflicting attributes can be detected by in bit vectors which should be unique e g char a bit in addition to the declared attribute tion the symbol tables must provide addressing information the constant expressions extracted in step above are evaluated so that the size of the vectors is known the relative addresses of all the local variables can then easily be assigned syntactic analysis of executable statements best results can be expected from parallel processing when the data can be processed in a uniform manner on the surface the executable statements of an program fit this re there are no keywords to process and no special statement types to each statement is an expression to be eval from right to left with no operator precedence involved despite these advantages there are still many details to be resolved before analysis for code generation can begin the infix state ments are revised and until they consist entirely of operands and operators this infix is then transformed into form x op y becomes yx op before further semantic analysis precedes the steps involved in reordering the infix are listed below followed by comments on the analysis source representation to be processed of two statements step brackets are replaced script operator by sub step null operands a are inserted for monadic operators step depth for each operator is found and then parentheses are b yz l l l x b c d oe l ry xl y z l step operands and operators are separated operand operator list list x preparation of infix form figure a kk use operand list and operator list from step above generation steps consider and zl a move a move b consider b consider d and o cl and y x a move b consider b and a a move b consider c push both operator r and o stacks p a move b consider x and w o c push second operator a move b drop both stack pointers is complete generated e l z ed l f y l o ll l o l o l l l l l o pl t ui w l ap w l generation serial adaptation figure b x k z k k x k x z kx k k x kk k kk kk preparation of infix form a descriptor marking their length step the statements have been through the analysis and all of the identifiers have been matched with symbol table entries labels are eliminated from the source and all references to labels are replaced by constants representing the line numbers where they were defined step constant vectors are extracted from the source and placed in the constant list with step subscript brackets may be considered as a operator which has higher priority than the surrounding operators this is handled by inserting parentheses to force the proper order of evaluation eg becomes x sub i operators are handled in a similar fashion step it is not always possible to determine from context whether a function is monadic or operand list and operator list from figure a step select in the operator list and move them to with their corresponding operands z step select all of the operators level o on step find lower priority the right and operand operator to in l step insert pairs the locations order selected in into found in in reverse step select all of operators on level step find lower priority operator the right and operand in to step insert pairs selected in into locations found in in reverse order step select all of operators on level step find level and operators to right operand in step insert the pairs places into the selected yj e d cl to i xl ll z y xl apl w ll ol j j z o jc y x a pi o x can be parsed either way since functions are declared specifying the number and type of the arguments and result parentheses can be placed around the func tion name and the proper number of ments to resolve this question step all monadic operators are made to look by inserting a null operand on their left step the pairs which specify order of evaluation are removed from the infix by introducing precedence to the operators based on their depth the are considered to be operators of the lowest priority step the infix form now consists operands and operators these are split into two vectors for subsequent reordering during analysis two different approaches for generating are presented the first described in an tion of the serial method of generation the algorithm is carefully set up so that sequences for all statements are processed from right to left in a synchronized fashion which loops through the generation process as many times as there are operators in the longest statement the second approach outlined later loops only as many times as the set of parentheses in the source program on each pass all of the operators on that parentheses level are handled adaptation of serial generation the created for each statement will have the same length as the infix representation while the form is built up at the left end of each statement the right end can be used as the operator stack for the statement the two stacks meet and fill the statement exactly when the for that statement is complete an example of the process is followed in figure b step i start by considering each marker in the operator list produced by step above recall these are the low priority operators step repeat the following steps until there are no more entries to be considered a move the considered operators to the of the corresponding operator stacks move the corresponding operands to the of the stacks b the pointers in the operator list by one drop any of the pointers if the new operator considered the for that is an marker statement is completed c compare the precedence of the considered operators with those on the of the cor operator stacks move any operators from the operator stacks to the whose are less than or equal to that of the considered operators generation by level the required for the statements can be built up by moving all of the operands and operators which are not inside pa to the in order the algorithm loops through each successive thesis level selecting all operators and their corresponding operands on that level and insert ing them into the correct position in the minor variations in the scheme will produce regular as well as prefix forms the algorithm works off the operator and operand lists produced after processing the infix as de above so the successive levels are represented by the precedence numbers of the operators figure c illustrates the work ing of the steps step select all of the in the operator list copy the corresponding operand followed by the marker to form the basis recall that the are represented as the lowest priority operators step if all of the operators have been processed the is otherwise select all of the operators in the operator list of the next higher precedence level step for each selected operator find the first operator of lower priority to the right the current position in the of the operand associated with this lower priority operator this is the lo cation for the selected operator step insert the operands corresponding to each selected operator followed by the selected operators into the in the chosen lo if more than one pair of operand operators is to move to the same location they are copied in the reverse order of their the in the operator list go to step z for the reversal in step comes from the fact that the apl statement is being turned around so that it can be processed from left to right hence the this reversal could be eliminated from the loop if the preprocessing effort were made to re all the operands and operators within state ments the parallel scheme described to exploit the parallel processing does more than the serial scheme but at the time of this writing ii has not been coded in apl so it is not known if a simple apl representation can be found to perform the rather complex operations described semantic analysis and code generation the operator set and the star in set are both very complex requiring an process to find the correct star repre for an operator this process is only outlined briefly here a set of code are defined which map the tion set into actual star instructions before these are applied constant expressions are and evaluated and special operator pairs such as are located and replaced by single operators finally the operand types of each operator are analyzed so that the correct code skeletons can be applied the expression is analyzed for all operators for which the required operands are available this defines a level of the expression tree the tion precedes iteratively through tree levels at each level the operators which have their operands available are selected by comparing the positions of all operators with the positions of the previous operators where there are two or more operands between operators the right operator can be processed figure gives a simple example of this selection the triples selected from the are reduced to single entries with the re result types and the process is repeated for the next level of the tree position c operator positions previous positions left by operator shift one distance between operators only the st two have operands available the operator selection figure with the large number of operators in apl and the variety of data types in it is not feasible to provide code skeletons for every possible combination of operand types with every operator about code skeletons in total are defined appropriate coercion operators are se where necessary to make the operand types match defined code skeletons where possible the replacement and operators are com with other operators to avoid unnecessary temporary results the actual structure of the code skeletons is complex and will not be defined in detail in this paper the star instruction formats are not simple for some vector operations there are fields in addition to the op code to be in the code skeletons some of which describe many star instructions are organized such that these star instructions fields can all be treated uniformly at the same time the entries for each field are coded to indicate what operand is to be used whether the registers involved are or pairs the entries are further coded to indicate any of the following possibilities a issue code to fetch a variable of descriptor described by a given symbol table entry b issue code to load a given constant value into a register c allocate a result register d allocate result space for a temporary vec tor result and the descriptor into a register e use a value directly in the instruction field e g the f copy the entry from a previously defined field necessary to match up registers for temporary results figure shows the encoding for a simple single instruction skeleton after all of the instruction fields have been processed the resulting code is into the instruction format and put into the correct order for output tc the ba w is code use registers issue fetch code allocate result register code generated e x address of a e base x value e x address of b e base x value sum of a to register of b to register to register code skeleton figure conclusions it is difficult to give a final of the success of the compilation experiment final judgment will have to wait for actual imple on the star there are however a few comments that can be made about the overall approach use of vectors for compilation a traditional compiler handles the source of the program one symbol at a time per forming a wide range of compilation functions to completely process the symbol the process described in this paper is completely opposite in nature a wide window of the input source is examined while the code execution is held to a narrow locality there are tradeoffs to be con in these two approaches the speedup expected with vector instructions on the star is unknown but expected to be on the order of to over register instructions assuming the vectors are sufficiently long specific timing are dependent on the operator types of the operands and memory conflicts encountered this speed up comes at a definite cost some of the tokens are accessed many more times than would be the case in serial compilation it is difficult to know where the break point between a complex parallel algorithm and a looping serial algorithm occurs the actual length of the vectors used in the compiler will be a critical factor in the of the compiler it is clear that the com cannot expect to handle the entire source of all programs submitted to it so it is designed to break the program into pieces if necessary if these pieces are too small many of the vectors may be too short especially those which process semantic and error checking with such vectors the overhead to set up the descriptors and the time of the vector instruction may any advantage by handling the elements in parallel on the other hand if the program pieces are large the vectors may be come too long creating another set of problems the storage required for temporary vector results may become costly if bit vectors are used to extract elements from a vector the entire vector passes through the stream unit from memory even if only a few elements are selected additional care must be taken with long vectors to ensure that they do not cause repeated page which would completely the efficiency of the compiler the best size of pieces to handle will have to be determined apl and compilation the facilities of the apl interpreter provided an tool for development and debugging of the compiler however as the project problems with apl as a compiler writing tool and as a natural language for the star more apparent and bit fields is a common compiler operation which is very costly in apl the only way to shift a number is to divide or multiply by of two apl maintains com control over the data types of the variables this lead to some debugging when a carefully constructed bit pattern would be converted to an floating point repre during a simple shift division operation as the code skeletons for the operators were developed it also apparent that maintaining compatibility with the apl inter would be more costly than expected corn code sequences had to be developed to handle all of the special cases of some operators which had very simple counterparts in the star tion set the take operator is a good example of this if the left operand is positive the elements are selected from the beginning of the right and if negative vector is used the end of the right in addition the result operand vector must be extended with if the magnitude of the left operand is greater than the length of the vector on the right the star instruction sequences for the different cases are simple but the code skeleton for the take operator must emit all four different possibilities as well as the runtime check to select the right one in this case it would be ad to define for the different operators cases especially in other cases it was discovered that apl had no operator to describe very powerful star in apl provides the operator to extract selected elements from a vector under control of a bit vector but there is no in for this operation in order to store a sequence of elements into positions selected by a bit vector an important star instruction a com apl sequence is required a p a c would be a more effective tool for the star if the interpreter compatibility require ment were or alternatively could be modified to reflect if the star in parallel processing algorithms a number of unique algorithms for processing a program in parallel were developed for the apl star compiler some of which have been described others have been omitted because of the complexity of an example these algo can be improved and many new variations can be many of these algorithms have been developed in an adhoc fashion there is much work to be done in formalizing such tech especially parsing and register allocation and proving that the formalized technique is the best or even proving that it works in all cases the features of language design e g words significant minimal recursive syn tactic constructs which facilitate vector processing and minimize semantic end cases should be char the vector approach to compilation also offers interesting new possibilities for global optimization algorithms acknowledgments the design and implementation effort of the compiler is the work of john martin c a and project richard in addition to the author this work was performed under the of the states atomic energy references f h l j g a long a vector function library of for the oo to be published laboratory university of california ca r g apl language specification and compiler progress uc id laboratory ca university of california control data star computer system publication number oo control data corporation k e a programming language john sons inc new york r g et uc id university of california al apl interpreter laboratory c a et al preliminary users manual for the laboratory university of california more ca n parallel programming for compilers sigplan notices no oct techniques vol 