profiling for laziness plt at university boston ma matthias felleisen abstract while many programmers the benefits of lazy programming at an abstract level determining which parts of a concrete program to evaluate a significant challenge for most of them over the past years have published numerous papers on the problem but developing this level of requires a significant amount of experience we present a technique that captures and this for the insertion of laziness annotations into strict programs to make this idea precise we show how to a formal semantics with a metric that measures in an evaluation then we explain how to implement this metric as a dynamic profiling tool that suggests where to insert laziness into a program finally we present evidence that our suggestions either match or improve on an use of laziness in a range of realworld applications categories and subject descriptors d programming languages formal definitions and theory general terms laziness profiling code where to be lazy have the benefits of laziness for now as hughes explained lazy programming languages enable programmers to design code in a modular way even earlier and argued that programs in strict languages can profit from laziness programmers have learned however that the key to laziness is because laziness reasoning about a programs resource consumption approaches to laziness come from two different directions from one direction lazy language researchers have strategies for determining when to safely remove laziness because these methods still tend to leave too much laziness behind lazy programmers frequently annotate their programs with strictness annotations such as haskells seq from the other direction strict programmers add laziness via constructs such as delay and force for example to large data structures delay possibly tasks or other lazy design patterns though the strict approach is since most programs need only a small amount of laziness finding exactly where to add the laziness can be problematic permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ san diego ca usa copyright is held by the publication to acm acm consider a programmer who to insert laziness annotations into a finite strict program in order to improve its performance the problem is that laziness is a global property of programs inserting an annotation in one place to require additional annotations at other points in the program even one of these annotations can result in the complete loss of the desired benefits in short the difficulty in placing laziness in strict programs is a recently the problem with a static tool this static analysis assumes that a programmer has partially annotated a program based on these annotations and a controlflow analysis it suggests additional delay annotations because the tool considers only static information it merely approximates where laziness is needed and often produces spurious suggestions the requirement for some initial annotations additional finally reports that he has to run his tool more than once to find placement but offers no on this issue in this paper we present a dynamic solution that information from an execution to determine which parts of the program to evaluate our solution consists of three concrete contributions first we show how to a callbyvalue calculus semantics with a metric for each expressions laziness potential roughly laziness potential represents the amount of computation performed by the evaluation of an expression it thus the degree to which a programs performance benefits from delaying that expression second we explain how to implement this metric as a dynamic profiler for an untyped language after profiling a program on a typical input the tool suggests where to add laziness annotations third we present evidence that our profiler generates advice comparable to that of in the literature for most of the programs we examined our profiler requests the insertion of delays at the same places as human in a few instances the suggestions achieve the same performance benefits with fewer laziness annotations the next section presents some motivating examples and section formally describes the notion of laziness potential section presents our prototype profiler implementation while section demonstrates its effectiveness finally the remaining sections conclude with related and future work laziness potential the intuition in some instances it is easy for a programmer to identify where laziness is other times trying to find these in a program is challenging in this section we explain our method for finding such with a series of examples these languages tend to support laziness annotations or with libraries and should benefit most from our work our work applies to typed languages as well see section criteria for laziness if an expressions result is not used we should delay its evaluation informally a value is used if it reaches a position that requires a specific kind of value to continue the evaluation process examples of such positions are the operands to primitive functions the test in a conditional and the function position in an application in contrast positions such as arguments to a programmers functions and data constructors do not use their values thus the argument in the following expression should be delayed x our initial laziness criterion does not cover the case where a program evaluates an expression more than once eg via recursion producing multiple values we could extend our criterion to delay expressions where none of its values are used but obviously this binary classification is useless for practical cases consider the following which represents a function definition and its use in a typical strict functional language def n m if n m then nil else n n m let lst in second lst third lst a call to n m produces the list of integers in n m in this example the recursive call to is evaluated multiple times and produces multiple values although second and third use two of these values the program is likely to benefit from delaying the expression because most of the list is unused the example suggests a quantitative criterion for the injection of laziness into strict programs specifically it that the ratio of the number of used results to the total number of results per expression might expressions in the example the recursive call to is evaluated m n times and two of the values are used giving it a ratio of profiling this example with our tool reports the following n m ln values used an expression with such a low ratio seems like a promising candidate for laziness but as the following boxed changes to the example show this first quantitative criterion is still def f n m if n m then nil else f n f n m let lst add in second lst third lst here is some data returned by our profiler f n ln values used f n m ln values used the expressions f n and f n m have equal indicating that the program benefits equally from delaying each a programmer immediately however that this is because delaying the call to would prevent most calls to f to combine these factors we focus only on the unused values and additionally weight them by the number of created during the creation of an unused value essentially this weight is to the size of the dynamic tree whose root is the unused value the weight of an expression then which we its laziness potential is roughly the average of the weights of all its unused values our profiler reports this information too f n m ln values used delaying unused avoids f n ln values used delaying unused avoids a higher weight indicates a greater benefit from laziness the exact calculation of laziness potential is discussed in section but the important here is that the profiler now considers delaying the call to more than delaying the call to f which with a programmers intuition laziness potential seems promising as a criterion but the following generate and filter example demonstrates another problem def f n m if n m then nil else f n f n m def filter p lst if nil lst then nil else let x first lst in if p x then x filter p rest lst else filter p rest lst let lst filter even add in second lst third lst profiling this example reports the following initial data filter p rest lst ln used delaying unused avoids meaning the profiler proposes delaying only a call to filter intuitively the recursive call to should be delayed as well but it does not appear in the results because filter uses the entire list in response our profiler iteratively simulates delaying the expression with the laziness potential and then to possibly more unused values with this refinement the profiler reports profiling summary round filter p rest lst ln values used delaying unused avoids profiling summary round f n m ln values used delaying unused avoids f n ln values used delaying unused avoids after round the analysis simulates a delay of the call to filter and then all unused values from the call to in round this process until there are no more unused expressions the profiler then reports that delaying both the calls to filter and would benefit program performance a complete example this subsection shows how a programmer can use our profiler to solve the problem we compare our result to who describes the problem like this the problem makes an for lazy programming an lazy solution to such a may consist of just two parts a part that places n at arbitrary positions on an n by n and a part for deciding whether a particular placement is a solution to the thus the program into two independent components and defines one function to compute a solution def n first filter all where let all foldl process row nil n def process row r so far qs new map cr c qs n new nil so far while all generates a stream of all possible checks whether a placement is valid according to the rules of the solution then these functions via filter and first as explains the approach two distinct concerns all ignores the rules of the while enforces them if the components were large two different programmers could them in parallel all they would have to agree on is the representation of for which we choose a list of r c accordingly running all n yields a list of lists of positions nn n each line represents one possible placement in a strict language computing all generates all possible adding laziness preserves the elegant solution and makes it efficient because it prevents unnecessary evaluation the question is which parts should be delayed as reports switching all lists to lazy lists does not improve program performance then presents a static tool to aid programmers with the task of inserting additional laziness for with lazy lists as the initial source of laziness the static analysis makes the key of adding laziness to which results in a significant speedup without any such initial our profiler suggests laziness at the same place in and also suggests laziness in filter filter p rest lst ln values used delaying unused avoids f base rest lst ln used delaying unused avoids figure summarizes the running times for the program implemented in and varying of laziness the figure reports that the strict version is slow and that adding the suggestions from static tool produces roughly a speedup however adding laziness annotations as suggested by our profiler produces a program that is roughly times faster than the strict version is due to the laziness required by the static analysis in order for the static tool to compute its suggestions first converting lists to lazy lists as strict programmers looking to add laziness commonly do it turns out however that this inserts too much laziness as evident from our only filter needs additional laziness the other lists should be evaluated implementation description no laziness static suggestions from suggestions time ms figure running times for an program laziness potential the definition as our informal presentation suggests we consider laziness potential the key to determining where to insert effective laziness annotations in strict programs this section formally defines the notion in two stages using a small model calculus our model starts from a labeled version of the untyped calculus e exp x v e e e · e v w w val xe x var the syntax two kinds of labels static labels in name a syntactic expression in the source program dynamic labels plain name a value during evaluation ie the result of one runtime execution of an expression with a particular set of bindings for its free variables define a program to be a closed expression e with only static labels as the grammar indicates static labels are optional during evaluation a statically labeled expression may be with a dynamic label at the upper left evaluation may also tag values with any number of dynamic labels all at the upper right and denoted with we use w when we wish to refer to a value without labels a program may evaluate an expression multiple times eg via recursion so a statically labeled expression may be associated with a set of dynamic labels representing the values that this expression produces further we wish to compute usage of these values which requires tracking value flow so values themselves may multiple labels to enable identification of the values source expressions in the example xx zz yy yy is the result of evaluating both expressions and thus must have two dynamic labels evaluation contexts specify the order of evaluation in our labeled calculus they are the standard evaluation contexts plus an additional labeled context e e e v e · e these contexts that reductions take place within a labeled expression only if it comes with a static and a dynamic label the reduction relation specifies one step of evaluation it is generated from three basic notions of reduction v and two additional reductions that introduce and manipulate value labels v v e e e · e e e v e · w ew the semantics satisfies a conventional theorem theorem a program e either reduces to a value v or starts an infinitely long chain of reductions proof sketch the relation satisfies unique decomposition so e is a value or can be partitioned uniquely into an evaluation context and a redex using a approach we can then show that this property is preserved for all reductions from an extensional perspective the labeled calculus reduces programs just like the calculus theorem says that the labeled calculus produces the same result modulo labels as the semantics generated by v the v relation is the standard reduction and v is its reflexive transitive closure the function labels from programs theorem label noninterference for any labeled program e if e e then e v e proof sketch show by cases on that if e e then either e v e or e e from an intensional perspective labels play a critical role expressions may be labeled in three different ways and the two reductions specify transitions between suppose a redex is statically labeled with before it is evaluated a unique dynamic label is generated and placed on the as indicated by the reduction when such a labeled subexpression is reduced to a value a reduction shifts the value label from the lefthand side to the righthand side and the static label labeling a program the labeled calculus does not specify which expressions in a program to label statically hence the calculus is applicable in a variety of scenarios depending on the specific labeling strategy for the purposes of finding candidates for lazy evaluation we employ a function l that maps expressions to expressions with labels on arguments that are not already values lx x l exp exp le e le large x large e le large the l function labels only applications because delaying values or variables is furthermore only applications in an argument position receive a label again it is not to delay applications in a usage context because the created is immediately forced we also do not label function bodies we prefer to delay its application to avoid the proper implementation of tail calls for the execution of annotated programs usage contexts to determine whether a particular value is used during evaluation we define usage contexts u u e u eu intuitively a context is a usage context if creating a redex requires a specific kind of value placed in the hole in our core calculus the function position of an application is the only usage context because it requires a value in addition the toplevel context is a usage context and thus a program result is considered used extending the model by design our model generalizes to constructs found in practical languages almost any reduction semantics can easily be extended to an appropriate labeled reduction system the only requirements are to extend the usage contexts and labeling strategy we extend our model with typical features specifically we add constants let conditionals primitive arithmetic and boolean operations lists and list operations and delay and force laziness constructs see figures and the reductions are conventional e n b let x e in e if e then e else e o e e and e e or e e not e cons e e first e rest e nil nil e delay e force e o n n b t f w n b cons v v nil delay e e let x e in e if e then e else e o e e o v e and e e and v e v f or e e or f e not e cons e e cons v e first e rest e nil e force e figure syntax for an extended language x v in e v let f then e else e ee iff v then e else e ee v f eo v v e v v v e ev v f f v ev f e ef v v ev v f f et v ef v f cons v v ev fst cons v v ev nil et nil v ef v nil nil delay e e v ev v delay e figure semantics for an extended language · the true and false boolean literals are t and f the semantics treats all values as true as is standard in untyped and some typed languages · the and and or primitives are meaning that the second argument is only evaluated if necessary this behavior is reflected in the evaluation contexts for and and or · the force form is recursive specified by the rule meaning that applying a single force to a returns the underlying value no matter how many delays it is wrapped in · untyped force is idempotent as seen in the rule applying force to a value returns that value here is the extended set of usage contexts u if e e o e o v and e and v v f or e or f not first rest nil force finally we extend our labeling function to mark expressions of interest maintaining the goal of finding expressions to delay in addition to arguments in a function application we label the bound expression in a let and the arguments to cons the traverse all other expressions in a manner le e le large x e in e let x large in le e e cons large large x lv large le if e x or v calculating laziness potential we calculate laziness potential via functions that extract information from the propagation of labels in reduction sequences let red be the set of finite reduction sequences in the following definitions a series of expressions represents an element of red ie a trace we also use t e to denote es complete trace the v function takes a reduction sequence and a static label and returns a set of dynamic labels representing the values generated by the labeled expression over the course of reduction v red × v e v e e e · e e v e v e e v e if e e e intuitively v all steps in the last example from section call it program p if the recursive call to filter has static label then a new dynamic label is created every time filter p rest lst is a redex and v t p the u function counts how many times a specified value is used in a given reduction sequence as by usage contexts u red × n u w if u e if e v or e w but u u w e u e if u e e u e if e u v or e u w but an labeled value is unused in t e if u t e the unused function relies on u and v to compute the labels of all the unused values produced by a particular expression in e unused exp × unused e v t e u t e for sample program p if second and third are to and then two created values reach a first or rest usage context so for i u t p i for two values of i and is otherwise thus unused p the c function returns the labels of all the that are generated during the creation of a given labeled value c red × c e c e · e e c e e c e c e if e e · e c red × c e c ew e c e e e · e e c e c e e c e if e e e when the creation of the specified value begins the c function to c when this function a reduction that creates another value label it adds it to its results when evaluation of the specified value completes or the reduction sequence ends the function stops collecting labels the created function uses c to compute the labels of all generated during the creation of all the unused values of a given labeled expression in e created exp × created e c t e unused e in our running example created p the additional values created while evaluating each of about finally the lp function computes the laziness potential of an labeled expression in program e roughly the function computes the average number of generated during the creation of an unused value of expression if unused e lp exp × r lp e unused e unused e created e created e the function uses unused to compute the labels of the unused values created by the specified labeled expression and created to compute the labels of the together these two sets represent the total number of values for which expression is responsible the of the calculation uses the union of the two sets to avoid values for example when expression is a recursive call to compute the desired ratio lp the total value count by the number of unused values produced by expression the of the calculation additionally those unused values that are of other unused values this appropriately gives higher weight to recursive calls which matches a programmers intuition in the running example all but one of the unused values are induced by the first recursive call to filter thus the in the laziness potential for is one and lp p the lp function computes the laziness potential of one particular expression in a program delaying the expression with the laziness potential should generate the largest possible benefit but doing so may reveal additional opportunities for laziness hence we iteratively define the following series of lp functions lp e lp e e max max where e c and max arg max e e an function first delays the subexpression with according to maximal laziness potential and adds appropriate forcing for the used values of that subexpression it then uses on this transformed program to determine the next for laziness injection in the definition max labels the expression with the most laziness potential and c is its context since some values produced by may still be used is c augmented with forces around those usage contexts that require values though it is sufficient to simply force every usage context in c a flow analysis like may compute a more a precise placement of forces in our running example assume lp determines that the labeled filter expression has the laziness potential then lp first delays and inserts forces at its use points lp then the augmented program and laziness potential for other expressions assume that both arguments to cons in also have static labels as mentioned in section the lp computations would find that the call to both and f create unused values but that only the unused values of subsequently induce many more values and thus has higher laziness potential a an reader may whether we can relate the laziness potential of an expression to a formal cost model it would show that the suggestions are guaranteed to improve a programs performance unfortunately the predictive capability of a model depends on how laziness is implemented meaning the desired theorem may hold only for semantic cost models close to one specific implementation a laziness profiler an implementation of a laziness profiler cannot use the definition of as a because it is highly to a modified program for every i instead our profiler creates a value dependence graph in an online fashion during a single execution and uses this graph to perform laziness potential usage information table describes the collected information it also lists the analogous mathematical function from section the i function a labeled calculus program to collect this information ix x i exp exp ie e u ie i relies on two additional functions a and u to argument and usage positions respectively we defined i only for core calculus expressions so far but in general the application of a exactly follows the labeling strategy from the previous section in other words a subexpression in a program is only instrumented as an argument if it has a static label in addition a subexpression is instrumented with u if it in a usage context here are a and u which imperative code fragments that perform the required during program execution information collected during evaluation math function set of labels representing all values created during evaluation v maps an expression label to a set of value labels representing the values created by that expression during evaluation c maps a value label to a value label hi such that the set of values created while evaluating is the exclusive interval hi ie the rooted subtree in the tree uses n u the number of times a value is used during evaluation n maps a value label to another map of value labels to counts representing the value usage while evaluating only to avoid uses a value with label used is considered used while evaluating value only if is the immediate ancestor in the programs tree for example if value is created while evaluating another value with label parent then used is considered used while evaluating but not while evaluating parent table information collected by the profiler a e let new in new new new let w e in new return w new u e let in let w e in for uses return w in these definitions let w e is a patternmatching notation that means evaluate e bind the resulting value to w and bind any resulting value labels to the vector the a and code generates unique dynamic labels from a counter and it tracks which value is being evaluated via a value stack the interfaces for the counter and the stack are described in table counter stack returns the current count returns then increments current count adds a value label to the top of the stack removes top label from the context stack returns top label but does not pop it table auxiliary functions for functions analysis before we show the loop that computes we introduce functions that use the collected information from table unused uses sub sub sub created unused lp unused unused created created for program e the main processing loop then looks like this while unused e arg max lp for unused erase the loop performs another iteration as long as some expression in the program has an unused value if all values are used ie the program cannot benefit from laziness then the profiler does not report any suggestions at the start of each iteration the analysis selects an expression with the currently greatest laziness potential identified with label above the analysis then simulates delaying this expression by its unused values via erase erase for sub erase sub for used n uses used n the erase function a value by its usage of values from the total usage counts marking the value as erased by removing it from so it is not considered in subsequent and recursively all that were created while evaluating the parameter value finally at the end of each iteration the analysis records the delayed expression via so it can present a summary to the programmer after the terminate the main loop always terminates since each iteration of the loop at least one unused value theorem the profiler implements the labeled calculus model proof sketch the interesting part is showing that our analysis implements the functions from section specifically the ith iteration of the main loop in this section corresponds to the function in an iteration both the model and implementation first compute the expression with laziness potential the implementation then information to this expression and loops while the math model inserts delays and forces and the program thus the correctness of the implementation on a correspondence between the erase function and the delay and force transformation in delaying an expression and then forcing the needed thunks eliminates the unused values produced by that expression the while producing those unused values and all of those values and their similarly an iteration of the main loop in the implementation calls erase to eliminate all unused values of the potential expression by removing them from the set of all values produced during execution the by those unused values as recorded in from the total usage counts in uses and recursively calls erase for each remaining as recorded in note that the theorem does not hold once sideeffects as simple as exception handling are added to the language although our empirical evidence suggests that this is not an issue in practice implementation we have implemented a prototype of the profiler described in this section for most of the language the profiler supports all the language constructs from section as well as several other frequently used forms such as pattern matching match named records struct sequence iterations and for additional binding forms define let etc much of the object system and a large part of the syntax system we use syntax system to modify the compiler so that it implements and using this compiler api greatly simplifies the implementation of our profiler a note on performance preliminary measurements indicate roughly a two to three when profiling certain programs this kind of is not for highlevel because programmers are expected to test their code with small representative inputs programs requiring laziness are especially suited for this style of testing because they generate of unused data but so long as the ratio of unused to used data remains the same it does not matter to the profiler whether the absolute amount of data is large or small evaluation to demonstrate the of the laziness potential metric we present the results of profiling a range of realworld examples known to benefit from laziness some of purely functional data structures monadic parser combinators and ai game players we show that in most cases the profiler the knowledge of when our results differ from the we turn to measurements to further evaluate our output general profiling issues in general produce meaningful results only when given representative programs for example it is impossible to demonstrate the effectiveness of a memory profiler using programs without memory leaks similarly we wish to demonstrate our effectiveness at inserting laziness into strict programs for performance reasons thus we choose wellknown uses of laziness rather than arbitrary programs and use inputs designed to force our test applications to rely on laziness our experiments as follows we implemented one of the examples as a strict program we then this strict version in a representative context and finally we delays according to the suggestions we inserted appropriate forces by hand but one could in principle derive the positions automatically we all experiments in an untyped language we all implementations as we found them except for a few points out page that laziness in a typed language requires extra annotations to make the types work out for example typed languages must delay an empty stream tail while in an untyped language this annotation is since the empty stream is a value in general laziness in typed languages requires a pairing of delays and forces while untyped languages are more flexible due to the recursive and idempotent nature of untyped force data structure queue heap pairing heap queue realtime queue realtime queue list implicit queue implicit tree description basic data structures canonical functional queue with streams like the queue but allows inserting and deleting from both ends stores ordered elements in a series of trees analogous to the representation of binary numbers supports constant time insert and log merge delete min and min operations stores ordered elements as a tree where each node consists of a heap element and a list of supports constant worstcase time insert merge and min operations and log time delete min operation data structures canonical functional queue with a stream front list an eager front list cache and a delayed list converted queue with an incrementally list with the goal of achieving worst case rather than bounds version of realtime queue improves on queue by eliminating redundancy in append operation lists that support constant time append achieves constant operations via implicit recursive version of implicit queue other functional data structures and general purpose data structure related to implicit queues p implementation implementation profiler suggests the same lazy annotations as implementation mixed results result p p p p p table comparison of lazy data structures with analogous data structures purely functional data structures purely functional data structures make up a wellknown library of algorithms that benefit from some degree of laziness in the data representation at the same time these data structures do not assume that the underlying language is lazy hence they are a nearly ideal test for checking the of our profiler the of our comparisons depends on the design of a particular data structure we therefore classify lazy data structures into two categories the first kind of lazy data structure is derived from an existing strict data structure added laziness to improve performance without making any other changes the second kind of data structure is either designed with laziness in mind or is converted from an existing strict data structure with changes more significant than simply adding laziness the first kind of data structure basic is ideal for evaluating our profiler because a straightforward comparison of the laziness annotations is appropriate for the second kind of data structure which we refer to as the laziness is possibly integral to its design and removing the laziness may not yield a realistic strict data structure hence any results concerning structures may be less general than basic ones but nonetheless table describes several data structures of each kind and presents the results of our comparisons for most examples our profiler suggests laziness identical to version in some cases however our profiler suggests what appears to be a better use of laziness and we present these latter cases in detail queue our queue and implementations improve on versions to help readers understand the differences and how they come about we present the queue experiment in more detail def enq x q f r f x r def f r if then q f r else q f rev r nil rotation def hd q nil error hd q x f r x def tl q nil error tl q x f r f r def nil lst lst x xs lst x xs lst def rev lst lst nil def nil acc acc x xs acc xs x acc figure functional queue implementation without laziness the canonical functional queue is implemented with two eager lists a list onto which elements are added to the queue and a front list from which elements are removed a record data definition q front represents these queues where q is the constructor and front and are field names the front and lists are front and respectively and and are the number of elements in each list figure presents this strict queue implementation in function definitions in the figure use a patternmatching syntax to decompose lists and queues where is the wildcard pattern the enq function adds an element to a queue hd returns the def enq x q f r f x r def f r if then q f r else q f rev r nil def hd q nil error hd q x f r x def tl q nil error tl q x f r f r def nil lst lst x xs lst x xs lst def rev lst lst nil def nil acc acc x xs acc xs x acc figure lazy queue element without removing it and tl removes the front element and returns the remaining elements as a new queue the figure also includes infix list append and list reverse rev when elements are added to or removed from front a queue maintains the invariant that the size of front must be equal to or greater than the size of when is larger than front a rotation is performed figure box ie is and to the end of front and is reset to empty the function checks the queue invariant and performs as needed though a list takes time proportional to the size of the list for any given set of inserted elements the list containing those elements is only once thus a functional queue supports constant time enq hd and tl operations are expensive but since the elements are added to the end of front and are not needed immediately laziness might improve the strict queue implementation also the constant time bounds of the strict queue do not hold when the queue is used to illustrate this problem consider a queue with enough elements such that calling tl a rotation calling tl repeatedly on this queue a rotation each time while the cost of the first rotation is over all the elements the subsequent require more than constant time because the are already spent by the first one to address these issues adds laziness to the strict queue implementation the new queue the queue replaces the eager lists with lazy streams and is shown in figure we adopt syntax for laziness where an expression delays that expression while in a pattern means to force the argument before trying to match the pattern since the queue merely adds laziness to the strict queue it into the basic kind of lazy data structure described earlier to see what laziness annotations our profiler suggests we need a representative benchmark that uses the strict queue def build sum size sum build size def build n n def n n q nil nil m n enq m m n def sum q n q n def q n n q m n hd q tl q m n uses the method to determine the queues complexity def enq x q f r f x r def f if then q f r else q f rev r nil def hd q nil error hd q x f r x def tl q nil error tl q x f r f r def nil lst lst x xs lst x xs lst def rev lst lst nil def nil acc acc x xs acc xs x acc figure version of lazy queue the build function builds a queue of the specified size while sum adds up the specified number of elements from the front of the given queue the build sum function combines build and sum our representative benchmark should benefit from laziness if we sum only the first few elements of the queue leaving most of the queue unused hence profiling this benchmark should reveal the places where it is to insert laziness annotations specifically profiling build sum produces the following laziness suggestions rev r ln values used delaying unused avoids xs lst ln values used delaying unused avoids figure shows a lazy queue that implements these suggestions our lazy queue has fewer and different laziness annotations than specifically the profiler does not inserting laziness in enq and rev boxes leaving as an eager list this is justified because rev is monolithic ie it always traverses its entire argument regardless of whether it is an eager list or a lazy stream instead our profiler suggests a single delay around the call to rev in box the profiler also differs in its to delay the tail of the list returned by append box while delays the entire list since the first list element is already a value this difference is trivial since our profiler uses of laziness different from we further compare the queue implementations with empirical experiments we several calls to build sum varying the number of elements for each run we used a fixed queue of size for i time build sum i the graph in figure shows that using an eager list in the lazy queue improves performance over queue which has to build a for each element a problem is that the benchmark does not test because the queue is used in a singlethreaded manner to expose issues a representative benchmark must in a that the list could be left as an eager list but because of his preference of theoretical simplicity over practical optimizations he presents the version in figure figure elements of a queue lower is better implementation strict strict test name strict strict time time time time time time time ms table testing with in the queue construct a queue such that a tl operation on the queue the suggested by the in the graph of figure for the lazy queues the rotation operation is delayed so we must remove a sufficient number of elements before the rotation is forced specifically we build a queue of size n right after a delayed rotation is to the end of front and then remove n elements from the queue removing the next element of the queue forces the rotation this benchmark uses a drop function which removes some number of elements from a list we again use n in the benchmark let q drop build in time time tl q time time tl q table presents for the benchmarks for reference we additionally include times for a strict queue which requires the same time on each access because it the rotation each time in contrast the lazy queue times verify that both implementations offer constant operations with the queue queue though our laziness potential model does not explicitly account for the memoization that enables constant operations for used queues our profiler is still able to suggest laziness annotations that satisfy the desired behavior which is a this suggests that reasoning with laziness potential possibly suffices to account for both the delaying and the memoization benefits of laziness which makes intuitive sense because programmers typically do not use laziness for memoization only this observation further investigation in future work queue queue differs from the queue in three ways first it a plain list for the list instead of a stream second the front list is a delayed plain list instead of a stream third the content of the front list is into a separate plain list before a rotation up hd accesses thus the queue requires an extra field in def enq x qp f f r f f x r def f f r if then f f r else let f force f in f f rev r nil def nil f r qp force f f r f f r qp f f r def hd qp nil error hd qp x f f r x def tl qp nil error tl qp x f f r f rest force f r def nil lst lst x xs lst x xs lst def rev lst lst nil def nil acc acc x xs acc xs x acc figure lazy queue def enq x qp f f r f f x r def f f r if then f f r else f f rev r nil def nil f r qp f f r f f r qp f f r def hd qp nil error hd qp x f f r x def tl qp nil error tl qp x f y f r f f r def nil lst lst x xs lst x xs lst def rev lst lst nil def nil acc acc x xs acc xs x acc figure lazy queue its data definition qp front figure shows the implementation for queue deriving the queue from the strict queue in figure involves more than just adding lazy annotations so it belongs in the category of data structure nevertheless we follow the previously described steps to develop the alternative implementation in figure it turns out that laziness potential cannot caching strategy and the profiler suggests front and into duplicate lazy streams the other profiler suggestions are identical to the queue the list remains an eager list and is delayed with a single delay in figure queue elements lower is better figure shows queue for the benchmark with its caching queue is faster than the implementation until half the queue is used after that point the benefits of caching in the queue are because the entire front list must be forced also forcing this last part of front takes much longer due to all the extra created by tl which as a large in the graph essentially our queue forces a little of front with each tl call while version delays all the until the second half of the queue is consumed deciding which queue implementation is better depends on the expected use cases implicit queues implicit queue and data structures pose challenging for both designers and and trees are a related data structure and pose the same problems this section presents details concerning queues the cases for and trees are similar see table implicit queues rely on implicit recursive ch a technique inspired by functional representations of thus implicit queues are also an kind of data structure like explicit queues implicit queues offer constant time hd tl and enq operations essentially the queue maintains some front elements and some elements in two structures with the remaining elements in a delayed middle queue here are the record definitions for implicit queues a is a zero or one x or two x y a queue is a shallow or deep a is either a zero one or two structure and an implicit queue itself is represented with either a shallow or a deep structure a shallow queue is of a single while a deep queue has two plus a delayed middle queue of element pairs figure presents enq tl and hd for implicit queues the enq function shows the of a queues internal state as more elements are added with the from zero to two and the queue itself from shallow to deep these transitions are in tl finally the hd function returns the front element by a queue in a straightforward manner while the design of this data structure laziness to support constant operations it also the overhead of laziness because every operation must not only the queue but many fields of the queue as well these numerous operations result in a high rate of creation and forcing in fact profiling the benchmark only finds expressions with low laziness potential even for queues where most or all of the elements are unused that the def enq shallow zero x shallow one x enq shallow one x y deep two x y nil zero enq deep f m zero x deep f m one x enq deep f m one x y deep f enq force m x y zero def hd shallow zero error hd shallow one x x hd deep one x m r x hd deep two x y m r x def tl shallow zero error tl shallow one x shallow zero tl deep one x shallow zero r shallow r tl deep one x m r let y z hd m in deep two y z tl m r tl deep two x y m r deep one y m r figure implicit queue operations figure elements of a implicit queue lower is better data structure should not use any laziness this makes intuitive sense since each operation effectively uses the entire queue to investigate this figure presents timing information for a strict queue compared to queue the shows that the high rate of creation and forcing any benefits that laziness might provide no matter how much of the queue is used obviously the laziness overhead is implementation dependent we implemented with a lambda and a mutable box although direct compiler support for would likely improve performance of the lazy queue and decrease the gap the is large enough that an should consider laziness while does not use the queue the worstcase expensive operation for implicit queues is only in the size of the queue as opposed to the linear of the queue thus even when we tested the queues with benchmarks the strict version still the lazy one in conclusion this experiment further supports laziness from an implicit queue implementation even if it may its theoretical properties monadic parser combinators our second suite of benchmarks concerns a monadic parser combinator library and point to one in the monadic bind operator where laziness is key calling it essential for efficient behavior since the library is a higherorder program we instantiated it for five different scenarios to apply our profiler a parser a url query parser a parser and an http request parser in every case the profiler suggested adding laziness at the exact identified by the paper manipulating game trees our final benchmark is an ai game algorithm from of lisp which introduces programmers to functional lisp via a series of games one of these games of is a strategy game similar to after several a is with a game complete with graphical interface and ai players an ai player generates a game tree of all possible moves to help it determine the next move and laziness to the tree without laziness the ai player analyzes only a small version of the game laziness however the ai player to a game the game implementation some lines of code a benchmark for our profiler not only because it requires laziness but also because it uses many additional language features such as mutable state list and libraries our profiler is able to the game and collects data as the game is returning suggestions when the game concludes it suggests enough laziness so that the full game is possible but with fewer annotations than the of lisp version related work strictness analysis a concept related to use is the denotational notion of strictness which is defined via a function f is strict if f in a lazy language a strict functions argument does not need to be delayed in the strict world however there is no analogous like value that indicates when to delay an expression we must instead consider intensional value flows which is precisely what use captures data structures xu et al present a tool that uses an object analysis to help programmers find inefficient parts of java programs while they analyze imperative objectoriented programs instead of functional ones they have goals similar to ours however a key difference lies in their somewhat indirect approach their goal is to find problematic in the program source but they compute costs at the level of memory accesses and bytecode instructions thus requiring an extra final step to interpret the results in terms of the source it is not clear how the paper achieves this last step which becomes even more complicated for a higherorder language our approach computes laziness potential directly in terms of a highlevel semantics from which the problem in a program become apparent conclusion and future work we introduce the notion of laziness potential a metric that which program expressions benefit from lazy evaluation our profiler implements these and programmers with the insertion of laziness annotations an evaluation of our profiler automatically and in some cases improves on the laziness in a range of realworld applications the potential of our approach though we presented laziness potential for a calculus and implemented our profiler for a matching language the idea should be applicable to any language that supports both strict and lazy evaluation specifically our insights may transfer we followed real world haskell for to a lazy language with strictness annotations such as haskell while the of haskells strictness analysis already programmers with the task of eliminating unnecessary laziness the approach is limited by its static approximate nature hence for realworld programmers suggest the insertion of strictness annotations to help the compiler we conjecture that a dynamic profiler based on the notion of laziness potential would these programmers with the difficult task of appropriate positions for these annotations acknowledgments we thank greg morrisett for initial and j johnson for reading and the reviewers for their suggestions this work has been supported by nsf infrastructure grant references h g j and j structure and interpretation of computer programs mit press c of lisp no press s laziness by need in proc nd esop pages ­ c and s l peyton jones strictness analysis a practical approach in proc nd pages ­ r and s peyton jones optimistic evaluation an adaptive evaluation strategy for nonstrict programs in proc th icfp pages ­ speculative evaluation in a lazy functional language in proc th icfp pages ­ m felleisen r b findler and m semantics engineering with plt redex mit press r b findler s and a lazy contract checking for immutable data structures in proc th pages ­ m and plt reference technical report plt inc r and r trees a simple generalpurpose data structure in j program pages ­ p hudak j hughes s p jones and p wadler a history of haskell being lazy with class in proc rd pages j hughes why functional programming comp j ­ d and e direct style monadic parser combinators for the real world tr university eager haskell execution yields efficient iteration in proc haskell workshop pages ­ f b hill l and j evaluating the design of the r language in proc th ecoop pages ­ a abstract interpretation and transformations for applicative programs phd thesis university of edinburgh c purely functional data structures cambridge university press b d and j real world haskell g d plotkin callbyname callbyvalue and the calculus theor comput sci ­ k e and s c how much do programs require in proc th pages ­ p wadler how to replace failure by a list of in proc nd pages ­ g xu n mitchell m a e and g finding data structures in proc st pldi pages ­ 