manifest contracts michael princeton university abstract the standard algorithm for higherorder contract checking can lead to unbounded space consumption and can tail recursion a programs asymptotic space complexity while space efficiency for gradual untyped and typed well studied sound space efficiency for manifest that check stronger properties than simple types eg is a natural instead of is an an open problem we show how to achieve sound space efficiency for manifest contracts with strong predicate contracts the essential trick is the contract checking down into coercions structured lists of checks by carefully preventing duplicate coercions from appearing we can restore space efficiency while keeping the same observable behavior categories and subject descriptors d software programming constructs and features keywords contracts pre and postconditions function coercions space efficiency introduction types are an extremely successful form of lightweight specification programmers can state their plus is a function that takes two numbers and returns another then type checkers can ensure that a program to the programmers types can only go so far though division is like addition a function that takes two numbers and returns another number so long as the second number zero conventional type systems do a good job of many kinds of errors but most type systems cannot protect partial operations like division and array indexing advanced and dependent types for cover many of these cases allowing programmers to use types like nonzero number or index within bounds to specify the domains on which partial operations are safe such techniques are they can be difficult to understand they force certain programming idioms and they place heavy constraints on the programming language requiring purity or even strong normalization permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ copyright is held by the publication to acm acm contracts are a popular programmers write contracts of the form int x int x int where the predicates x are written in code these specifications can then be checked at runtime models of contract calculi have taken two forms latent and manifest we take the manifest approach here which means checking contracts with casts written tt l e checking a predicate contract also called a refinement type though that term is overloaded like x int x on a number n involves running the predicate x with n for x casts from one predicate contract to another x b ex b e l take a constant k and check to see that ek x true its hard to know what to do with function casts at runtime in l e we know that e is a tt but what does that tell us about treating e as a tt findler and insight is that we must defer checking waiting until the cast value e gets an argument these deferred checks are recorded on the value by means of a function ie l e is a value when e is a value applying a function it we check the domain contract t on e run the original function f on the result and then check that result against the codomain contract t l e e tt l e tt l e findler and felleisen designed a system for contract checking in a higherorder world but there is a problem contract checking is space inefficient contract space can be up as follows function break tail calls calls to an function from a tail position can be optimized to not allocate stack frames functions however will to have codomain tail calls we discuss other sources of space below but tail calls is the most consider factorial written in passing style the may believe that the following can be compiled to use tail calls fact x int x x int x x int x x x int true true if x then y else fact x x y a cast insertion algorithm might produce the following recursive function fact x int int true x int x y z int x x x int true true if x then y else x int x x int true fact optimization is essential for usable functional languages space has been one of two significant for use of higherorder contract checking the other is state which we do not treat here in this work we show how to achieve space efficiency for contract checking our approach is inspired by work on gradual typing a form of manifest contracts designed to dynamic and simple is gradual typing a allows the dynamic type and b restricts the predicates in contracts to checks on type tags et al developed the first typed system using coercions siek and wadler a related system supporting blame the essence of the solution is to allow casts to merge given two adjacent casts tt l tt l e we must combine them into a single cast siek and wadler annotate their casts with an intermediate type representing the greatest lower bound of the types encountered such a trick doesnt work in our more general setting simple types plus dynamic form a straightforward lattice using type precision as the ordering but its less clear what to do when we have arbitrary predicate contracts we define two modes of a single calculus h the classic mode is just the conventional inefficient semantics the mode casts with refinement lists and function new form of coercion inspired by the coercions keep track of checking so well that the type indices and blame labels on casts are unnecessary tc t · tc t · e e · e these coercions form a lattice refinement lists have ordering constraints that break commutativity h is space efficient and observationally equivalent to the classic mode h is the first manifest contract calculus that is both sound and space efficient with respect to the classic result contrary to who that such a result is impossible we believe that space efficiency is a critical step towards the implementation of practical languages with manifest contracts we do not prove a blame theorem since we lack the clear separation of dynamic and static typing found in gradual typing we conjecture that such a theorem could be proved our model has two limits worth we do not handle dependency a common and powerful feature in manifest systems and our bounds for space efficiency are establish that contracts consume constant space but do nothing to reduce that constant our contribution is showing that sound space efficiency is possible where it was to be impossible we leave evidence that it is for future work our proofs are available in the extended version readers who are very familiar with this topic can read figures and and then skip directly to section readers who understand the space of contracts but particularly familiar with manifest contracts can skip section and proceed to section function space inefficient contract checking breaks tail problem for realistic implementations of contract use contract system the most widely used higherorder contract system takes a macro approach to contracts contracts typically appear only on module interfaces and checked within a module their approach comes out of a of invariants inside modules but not out of them but also out of a need to retain tail recursion within modules space has the way their contract system has developed they do not use our approach annotations and casts the code tail recursion aside there is another important source of space the unbounded number of function hierarchies of libraries are a typical example consider a list library and a set library built using sorted lists we might have null bool true head x list not null x empty setx bool true null min x set not empty x head our code reuse comes with a price even though the precondition on min is effectively the same as that on head we must have two function and the of the list representing the set is checked twice first by checking empty and again by checking null which is the same function blame systems like those in modules to declare contracts to avoid being which can result in redundant checking like the above when libraries requirements imply requirements or consider a library of primitives based around functions of type an underlying library offers basic functions for manipulating and functions over eg is a transformer of type the generated a wrapper library may add derived functions while the underlying functions with refinement types specifying a square dimensions where x p l l p the wrapper library only accepts with appropriately refined types but must strip away these refinements before calling the underlying demands the wrapper library then has to cast these modified functions back to the refined types calling p yields l l l l p that is we first cast p to a plain and return a new p we then cast p into and then immediately out of the refined type before on to flip p all the while we are many function beyond the done by the underlying implementation of redundant can become quite extreme especially for continuationpassing programs function are the essential problem nothing bounds their unfolding many function creates stacks of many breaks tail calls a scheme for manifest contracts bounds the number of function that can classic manifest contracts the standard manifest contract calculus h is originally due to flanagan we give the syntax for the fragment in figure we have in the four syntactic forms relevant to contract checking this paper paper discusses two modes of h classic h mode h mode e each of these languages uses the syntax of figure while the typing rules modes m c e classic h section h section types b bool t x b e tt terms e x k x t e e e en ta t l e x b e e k l l x b e s r k e · annotations type set coercions and refinement lists a · c c r c c r nil x b el r s locations l · l figure syntax of h and operational semantics are indexed by the mode m the proofs and metatheory are also in an extended version of this work we develop two additional modes with slightly different properties from h out a framework for manifest contracts we omit the other two modes here to save space for h which is the only mode that is sound with respect to classic h the metavariable b is used for base types of which at least bool must be present there are two kinds of types first predicate contracts x b e also called refinements of base types or just refinement types denotes constants k of base type b such that ek x is such that ek x m true for any mode m function types tt are standard the terms of h are largely those of the simplytyped lambda calculus variables constants k abstractions applications and operations should all be familiar the first distinguishing feature of hs terms is the cast written ta t l e here e is a term of type t the cast checks whether e can be treated as a e doesnt cut it the cast will use its label l to raise the exception l read blame l our casts also have annotations a classic doesnt need write · and say none h uses coercions c based on coercions in we explain coercions in greater detail in section but they amount to lists of refinement types r and function coercions the three remaining checks blame and coercion occur as the program evaluates casts between refinement types are checked by active checks x b e e k l the first term is the type being for the typing rule the second term is the current status of the check it is an invariant that ek x m e the final term is the constant being checked which is returned if the check succeeds when checks fail the program raises blame an exception written l a coercion stack x b e s r k e · represents the state of checking a coercion we only use it in h so we discussing it until section core operational semantics our operational semantics for our manifest calculi three relations e identifies terms that are values in mode m or e identifies and e m e is the smallstep reduction relation for mode m figure defines the core rules the rules for classic h m c are in the shared rules are in to save space we pass over standard rules the value rules are straightforward constants are always values v const as are v abs each mode defines its own value rule for function v the classic rule v says that a function tt l e is a when e is a that is function can wrap lambda abstractions and other function h only allows lambda abstractions to be all of the calculi in the literature take our approach where a function cast applied to a value is a value some space inefficient ones do too in other of h in the literature function are implemented by introducing a new lambda as a wrapper a la findler and wrap operator such an expansion semantics is convenient since then applications only ever reduce by reduction but it our purposes at all space efficiency demands that we combine function we can also imagine a third semantics that looks into closures rather than having explicit function results dont depend on the mode are always r val blame is always a result too r blame e beta applies lambda abstractions via substitution using a callbyvalue rule note that reduction in mode m requires that the argument is an the reduction rule for operations e op to operations denotations op since these may be partial eg division we assign types to operations that guarantee totality see section that is partial operations are a potential source of and the types assigned to operations must guarantee the absence of robin milner stated that well typed expressions dont go wrong his programs could go wrong by a applying a boolean like a function or b on a function like a boolean systems with more base types can go wrong in more ways some of which are hard to capture in standard type systems contracts allow us to that gap letting operations get stuck is a contracts expand the notion of wrong e applies function to values in the domain and in the codomain we also split up each casts annotation using and mode is discussed in its respective section e turns a cast between refinement types into an active check with the same blame label we discard the source already know that k is a x b substitute the into the target type ek x as the current state of checking we must also hold onto the in case the check succeeds we are careful to not apply this rule in h which must generate annotations before running checks active checks evaluate by the congruence rule e until one of three results the predicate returns true so the whole active check returns the e the predicate returns false so the whole active check raises blame using the label on the e or blame was raised during checking and we propagate it via e checks in h use slightly different forms described in section the core semantics includes several other congruence rules e e and e since space bounds rely not only on limiting the number of function but also on of casts on the stack the core semantics doesnt include a cast congruence rule the congruence rule for casts in classic h e allows for free use of congruence in the calculus the use of congruence is instead limited by the rules e and e cast arguments only take congruent steps when they casts themselves a cast ap values and results v const k e e v abs x t e e tt l e v e e r val r blame l shared operational semantics e m e e e beta x t e e m e en e op en m op e en tt l e e tt l e e m t t l e t t l e e · c c · c c x b x b e l k c x b e ek x k l e x b e true k l m k e x b e false k l m l e e m e e e e m e e e e m e e e m e e e e ei ei m ei e ei ei en m ei ei en e c e t l e c t l e e e m e x b e e k l m x b e e k l e e e e e ta t l e ta t l e e ta t l e e l e m l e c c tc t l tc t l e e tc t l e e e e e l m l e ts t l l m l e ei e ei l en m l x b e l k l m l e figure core operational semantics of h classic h rules are rules are to another cast merges using the join function each calculus uses a different annotation scheme so each one has a different merge function we are careful to define join only over coercions so e apply on the empty annotation · read none we have e arbitrarily retain the label of the outer cast this choice is ultimately irrelevant since h need to keep track of blame labels on casts themselves section in addition to congruence rules there are blame propagation rules which are universal e e e e these rules propagate the exception l while callbyvalue rules type system all modes share a type system given in figure all judgments are universal and simply thread the mode for annotation well m a t t which is mode specific and a single rule given in figure the type system several relations context well m and type well m t type compatibility t t a comparison of the skeleton of two types annotation well m a t t and term typing m e t context well is entirely straightforward type well requires some care to get base types off the ground we establish as an axiom that the raw type x b true is well formed for every base type b wf base we then use raw types to check that refinements are well formed x b e is well formed in mode m if e is well typed as a boolean in mode m when x is a value of type b wf refine without wf base wf refine have a well formed context function types are well formed in mode m when their domains and are well formed in mode m unlike many recent our functions are not leave dependency as future work type compatibility t t identifies types which can be cast to each other the types must have the same skeleton it is reasonable to try to cast a nonzero integer x int x to a positive integer x int x but it is to cast it to a boolean x bool true or to a function type tt every cast must be between compatible types at their core h programs are simply typed lambda calculus programs type compatibility context and type well m mt wf empty m wf base m x b true x x b true m e x bool true m x b e m mt m x t wf refine wf extend m t m t m tt wf fun type compatibility and annotation well s refine x b e x b e t t m a t t t t t t tt tt s fun t t m t m t m · t t a none expression typing m et m x t m x t t var m t x t m e t m x t e tt t abs m mt m l t t blame m m x b e b ek x m true t const m k x b e t tn t m ei ti m en t t op m e tt m e t m e e t t app m a t t m e t m ta t l e t t cast m m x b e b m e x bool true ek x m e m x b e e k l x b e t check figure universal typing rules of h is reflexive symmetric and transitive ie it is an equivalence relation our family of calculi use different annotations all source programs defined below begin without write the empty annotation · read none the universal annotation well rule just to type compatibility a none it is an invariant that m a t t implies t t as for term typing the t var t abs t op and t app rules are entirely conventional t blame types blame at any well formed type a constant k can be typed by t const at any type x b e in mode m if a k is a b ie b b the type in question is well formed in m and c if ek x m true as an immediate consequence we can derive the following rule typing constants at their raw type since true m true in all modes and raw types are well formed in all modes wf base m b m k x b true this approach to typing constants in a manifest calculus is novel it offers a great deal of with typing while avoiding the subtyping of some and the extra rule of others we assume that bool iff k true false we require in t op that only produces well formed firstorder types ie types of the form m x b e x bn en we require that the type is consistent with the operations denotation op k kn is defined iff ei ki x m true for all m for this evaluation to hold for every system we consider the types assigned to operations cant involve casts that both a stack and b can fail we believe this is not so a requirement the types for operations to be simple eg x real y z real true and casts only arise in terms due to function in general it is interesting to ask what refinement types to assign to constants as assignments can lead to circular checking eg if division has a codomain cast checking its work with multiplication and vice versa the typing rule for casts t cast relies on the annotation well rule ta t l e is well formed in mode m when m a t t and e is a t allowing any cast between compatible base types is conservative a cast from x int x to x int x always fails earlier work has used smt solvers to try to statically reject certain casts and eliminate those that are guaranteed to succeed we omit these checks as we view them as static analysis and optimization and not the essence of the system the final rule t check is used for checking active checks which should only occur at runtime in fact they should only ever be applied to closed terms the rule allows for any well formed context as a technical device for weakening active checks x b e e k l arise as the result of casts between refined base types as in the following classic h evaluation of a successful cast x b x b e l k c x b e e k x k l c x b e true k l c k if we are going to prove type soundness via syntactic methods we must have enough information to type k at x b e for this reason t check requires that ek x m e this way we know that e k x m true at the end of the previous derivation which is enough to apply t const the other premises of t check ensure that the types all match up that the target refinement type is well formed that k has the base type in question and that e the current state of the active check is also well formed to say that our languages share a syntax and a type system we a subset of type derivations as source program type derivations we show that source programs well typed in one mode are well typed in the all modes definition source program a source program type derivation the following rules ­ t const only ever assigns the type x true variations in each modes evaluation reflected in the source program type system we could soundly relax this requirement to allow x e such that ek x m true for any mode m ­ casts have empty annotations a · casts also have blame labels and not empty blame also written · ­ t check t stack section and t blame are not are for runtime only note that source programs dont use any of the typing rules that defer to the evaluation relation t check and t stack so we can maintain a clear phase distinction between type checking programs and running them metatheory one distinct advantage of having a single syntax with parameterized semantics is that some of the metatheory can be done once for all modes each mode proves its own canonical forms each mode has a unique notion of its own progress and preservation lemmas for syntactic type soundness but other standard machinery weakening substitution and be proved for all modes at once see section a to wit we prove syntactic type soundness in appendix a for classic h in just three lemmas canonical forms progress and preservation in every theorem statement we include a reference to the lemma number where it is proved in the appendix in pdf versions this reference is lemma classic canonical forms a if c e t and e then ­ if t x b e then e k and b and e ex c true ­ if t tt then either e x t e or e tt l e lemma classic progress a if c e t then either e ie e l or e or there exists an e such that e c e lemma classic preservation a if c e t and e c e then c e t space efficiency h uses coercions coercions do two critical things they retain check order and they track blame our coercions are ultimately inspired by those of we discuss the relationship between our coercions and his in related work section recall the syntax of coercions from figure c r c c r nil x b el r coercions come in two refinement lists r zero or more refinement types each annotated with a blame function coercions c c we write them as separated lists the empty refinement list nil when the refinement list is nonempty we define the coercion well rules an additional typing rule and reduction rules for h in figure to ease the our explanation doesnt the rule in the figure as a general intuition coercions are for checking they contain precisely those types to be checked refinement lists are well formed for casts between x b e and x b e when a every type in the list is a well formed refinement of b ie all the types are of the form x b el and are therefore similar to the indices b there are no duplicated types in the list and c the target type x b e is implied by some other type in the list note that the input type for all refinement lists can be any well formed corresponds to the intuition that base types have no negative parts ie casts between refinements ignore the type on the left finally we simply write no in r it is an invariant during the evaluation of source programs function coercions on the other hand have a straightforward contravariant well rule the e coerce rule translates casts to coercions t l is a coercion representing exactly the checking done by the cast t l all of the refinement types in t l are annotated with the blame label l since the label that would be if the cast failed at that type since a coercion is a complete plan for checking a coercion annotation the need for type indices and blame labels to this end e coerce the blame label from the cast replacing it with an empty label we keep the type indices so that we can reuse e from the universal semantics and also as a technical device in the preservation proof the actual checking of coercions on the treatment of refinement lists function coercions are expanded as functions are applied by e so they dont need much special treatment beyond a definition for dom and h uses coercion stacks x b e s r k e · to evaluate refinement lists coercion stacks are type checked by t stack in figure we explain the operational semantics before the typing rule coercion stacks are entities five parts a target type a status a pending refinement list a constant and a checking term we keep the target type of the coercion for sake the status bit s is either or when the status is we are currently checking or have already checked the target type x b e when it is we the pending refinement list r holds those checks not yet done when s the target type is still in r the k is the constant were checking the checking term e is either the k itself or it is an active check on k the evaluation of a coercion stack proceeds as follows first e starts a coercion stack when a cast between refinements meets a constant recording the target type setting the status to and setting the checking term to k then e starts an active check on the first type in the refinement list using its blame label on the active updating the status if the type being from the list is the target type the active check runs by the congruence rule e eventually returning k itself or blame in the latter case e propagates the blame if not then the is k once more and e can again eventually the refinement list is and e returns k now we can explain t stacks many it must a refine but not eventually the target type will be checked and no longer appear in r the status s what our requirement is when s the target type is in r when s we either know that k the target type or that we are currently checking the target type ie an active check of the target type at some blame label reduces to our current checking term finally we need to define how to merge casts we use the join operator which is very nearly concatenation on refinement lists and a contravariant homomorphism on function coercions its not coercion implication predicate axioms x b e x b e if e x b e then x b e x b e transitivity if x b e x b e and x b e x b e then x b e x b e adequacy if x b e x b e then k kb ek x e true implies ek x e true decidability for all e x b e and e x b e it is decidable whether x b e x b e coercion well and term typing m c t t m et e x b e e x b e x b e r e x b e no in r x b e r x b e x b e e r x b e x b e a refine e c t t e c t t e c c tt tt a fun e e x b e b e e x b e x b e r e x b e s implies ek x e true x b e l x b e x b e x b e ek x k l e e s implies x b e r x b e x b e e x b e s r k e · x b e t stack values and operational semantics e e e e · x t e v e coerce t l e e t t l t · e x b er x b e · k e x b e r k k · e x b e s x b e l r k k · e x b e s e e r k x b e e k x k l · e e e e x b e s r k e · e x b e s r k e · e x b e s r k l · e l e x b e nil k k · e k e cast translation and coercion operations c c c c b e x b e l x b el tt l t l t l b el nil x b el b el r x b el drop r x b e r r b el r r b el r c c c c c drop nil x b e nil drop x b el r x b e drop r x b e x b e x b e x b el drop r x b e x b e x b e e e e e e e otherwise figure typing rules and operational semantics for h concatenation because it uses an implication predicate the preorder to eliminate because is reflexive and hide subsumed types because is adequate we read x b e x b e as x b e implies x b e when eliminating types join always chooses the leftmost blame label means that c takes leftmost labels in positive positions and rightmost labels in negative ones the coerce and join operator work together to make sure that the refinement lists are correctly ordered as we show below correctly ordered means the positive parts take labels and negative parts take ones e is slightly never merge casts with · as an annotation because such merges defined in figure we only give the axioms for it must be an adequate decidable preorder syntactic type equality is the simplest implementation of the predicate but the reflexive transitive closure of any adequate decidable relation would work by way of example consider a cast from t x int x x int x to t x int int x for brevity we refer to the domains as ti and the as ti we find that t l v v steps in classic h to x int x · x int x l v x int x int x l v e x int x mod · x int x l x int x · x int x mod l x int x int x l e coerce e x int x mod x l x int x l x int x · x int x mod l x int x int x l e coerce e x int x mod x l x int x l x int x x mod l x int x mod l x int x int x l e e x int x r x int x l x int x int x l where r x int x mod l x int x l e coerce e x int x r x int x l x int l x int x l e x int x int x l where r x int x l r e e x int x r · e x int x r x int x l · e l e e figure example of h note that ts domain is checked but its codomain the reverse is true for t when looking at a cast we can read off which refinements are checked by looking at the positive parts of the target type and the negative parts of the source type the relationship between casts and polarity is not a new one unlike casts coercions directly express the sequence of checks to be performed consider the coercion generated from the cast above that ti and ti are the domains and of t and t e e e t l v v tc t · v v where c x int x l x int x l tt · v v tx l t · v tx l t · v in this example there is only a single blame label l tracking blame labels is critical for exactly matching classic hs behavior the examples rely on being reflexive first we return to our example from before in figure throughout the merging each refinement type its own original blame label allowing h to behave just like classic h we offer a final pair of examples showing how coercions with redundant types are merged the intuition here is that positive positions are checked innermost cast first while negative positions are checked out cast first consider the classic h term t x int ex int e t x int ex int e t x int ex int e e t l t l v note that the casts run from old to new in the positive position but they run from the new to old in the negative position e v c x int x int e l x int x int e l v x int x int e l x int x int e l v the key observation for eliminating redundant checks is that only the check run first can no point in checking a predicate contract twice on the same value so h merges like so e e e tx intel t · tx intel t · v tc t · v where c int el x int el int el x int el x int el x int el x int el the coercion merge operator eliminates the redundant codomain check choosing to keep the one with blame label l choosing l makes sense here because the codomain is a positive position and l is the innermost cast we construct a similar example for merges in negative positions t x int ex int e t x int ex int e t x int ex int e e t l t l v again the unfolding runs the positive parts and the negative parts when applied to a value v x int x int e l x int x int e l v x int x int e l x int x int e l v running the example in h we reduce the redundant checks in the domain e e tx intel t · tx intel t · v e tc t · v where c int el x int el int el x int el x int el x int el x int el following the rule for negative positions we keep the blame label l from the outermost cast metatheory the proof of type soundness is a standard syntactic proof relying on a few small lemmas concerning refinement list well and the generic metatheory described in section the full proofs are in appendix a lemma canonical forms a if e e t and e then ­ if t x b e then e k and b and e ex e true ­ if t tt then either e x t e or e · x t e lemma progress a if e e t then either e ie e l or e or there exists an e such that e e e lemma preservation a if e e t and e e e then e e t h shares source programs definition with classic h we can therefore say that classic and h are really just modes of a single language lemma source program typing for h a source programs are well typed in c iff they are well typed in e ie ­ c e t as a source program iff e e t as a source program ­ c t as a source program iff e t as a source program ­ c as a source program iff e as a source program soundness for space efficiency we want space efficiency to be sound it would be space efficient to never check anything classic h is the more a mode behaves like classic h the it is a single property summarizes how a calculus behaves with respect to classic h cast congruence in classic h if e c e then t l e and t l e behave this cast congruence principle is easy to see because e applies freely in h however e can only apply when e doesnt merged casts may not behave the same as running the two casts separately h a complete cast congruence just like classic h has e t l e e e t l e e e e the proof is in appendix b but it is worth observing here that h needs a proof of to justify the way it uses to eliminate redundant coercions checking a property once is as good as checking it twice naturally this property only holds without state our proofs relating classic h and h are by logical relations found in figure in the extended version the soundness proofs for all three different modes use a single logical relation here we give its restriction to h as far as alternative techniques go an induction over evaluation derivations give us enough information about evaluations that return lambda abstractions other contextual equivalence techniques eg bisimulation would probably work too value rules e e e t k e k x b e b ek x e true e e e tt e e e e e t e e e e e t term rules e e e t e e ce l l e e e t e e ce e e e e e e e t type rules t e t x b e e x b e e e e x b true e x bool true tt e tt t e t t e t closing substitutions and open terms e e e t e e x dom x e x x e e e t e e e e t figure symmetric logical relation between classic h and h mode classic m c m e cast size wh l pending casts e table space efficiency of h lemma similar casts are logically related b if t e t and t e t and e e e t then t l e e t l e t lemma relating classic and source programs b if c e t as a source program then e e e t if c t as a source program then t e t bounds for space efficiency we have that h is space efficient what do we mean what sort of space efficiency have we achieved we summarize the results in table proofs are in appendix c from a high level there are only a finite number of types that appear in our programs and this set of types can only reduce as the program runs we can effectively code each type in the program as an integer allowing us to efficiently run the predicate suppose that a type of height h can be represented in wh bits and a label in l bits type heights are defined in figure in appendix c casts in classic h each take up wh l bits two types and a blame label coercions in h have a different form the only types recorded are those of height ie refinements of base types each of these may appear at every position in a function coercion c c we use s to indicate the size of a function type ie the number of positions it has as a first pass a set of refinements and blame labels take up lw space but in fact these coercions must all be between refinements of the same base type leading to space per coercion where is the number of refinements of any single base type we now have our worstcase space complexity a more precise bound might track which refinements appear in which parts of a function type but in the worst refinement appears in every to the bound we give here classic h can have an infinite number of pending and function a program h can have no more than one pending cast per term node abstractions are limited to a single function and e merges adjacent pending casts the text of a program e is finite so the set of types appearing in the program is also finite since reduction doesnt introduce types we can bound the number of types in a program and therefore the size of casts we can therefore fix a numerical coding for types at runtime where we can encode a type in w bits in a given cast w how many types can appear the source target and annotation must all be compatible which means they must also be of the same height we can therefore represent the types in casts with fewer bits wh t h in the worst case we to the original bound all types in the program are of height even so there are never casts between different base types b and b so b e hs coercions never hold types greater than height the types on its casts are once the coercions are generated because coercions the checking representation choices the bounds we find here are having established that contracts are space efficient making an implementation practically space efficient is a different involving careful choices of representations and calling conventions hs space bounds rely only on the of the predicate since we leave it abstract we have identified one situation where the relation allows us to find better space bounds mutual implication if x b e x b e and x b e x b e then these two types are equivalent and only one ever need be checked which to check could be determined by a compiler with a cost model note that our proofs dont entirely justify this optimization by default our join operator will take of x b e and x b e was meant to be checked first join to always choose one based on some preference relation would not be particularly hard and we believe the proofs adapt easily other analyses of the relation seem promising at first but in fact do not allow more compact representations suppose we have a program where x b e x b e but not vice versa and that b is our worst case type that is because there are different refinements of b and fewer refinements of other base types the worstcase representation for a refinement list is bits with bit bi indicating whether ei is present in the list can we do any better than bits since e can stand in for e could we represent the two types as just bit we cannot when a there are constants that pass one type but not the other and b when refinement lists are in the reverse order of implication suppose there is some k such that ek x e true and ek x e false now we consider a concatenation of refinement lists in the reverse ordering b el x b el we must retain both checks since different failures lead to different blame the k that passes e but not e should raise l but other k that fail for both types should raise l one bit enough to capture the situation of having the coercion x b el x b el finally what is the right representation for a function when calling a function do we need to run coercions or not siek suggested a smart closure which holds the logic for branching inside its own code this may support better branch prediction than an indirect jump or branching at call sites related work some earlier work uses firstclass casts whereas our casts are always applied to a term it is of course possible to expand a cast with an abstraction so no expressiveness is lost leaving casts fully applied us from the rules how casts work on other casts in semantics like tt l t l f t l previous approaches to have focused on gradual typing this work uses coercions casts casts annotated with intermediate types or some combination of all three recent work relates all three frameworks making particular use of coercions our type structure differs from that of gradual types so our space bounds come in a somewhat novel form gradual types without the more complicated checking that comes with predicate contracts allow for simpler designs siek and wadler can define a simple recursive operator on labeled types with a strong relationship to subtyping the fundamental property of casts we been able to discover a connection in our setting instead we ignore the type structure of functions and focus our attention on labels in lists of firstorder predicate contracts in the gradual world only et al take a similar approach recursively higherorder types down to their firstorder parts when they compute the closure of flows into and out of type variables gradual types have simpler proofs too eg by induction on evaluation even when strong reasoning principles are needed the presence of dynamic types leads them to use bisimulation we use logical relations because hs type structure is readily available and because they allow us to easily reason about how checks evaluate our coercions are inspired by coercions for modeling injection to and projection from the dynamic type primitive coercions tag and untag values while ours represent checks to be performed on base types both our formulation and use structural function coercions the most closely related work offers a coercion language combining the dynamic types of original work with predicate contracts his efficient language does not quite achieve sound space rather it is casts he blame though he that blame for coercions reads left to right as it does in siek and our h verifies this conjecture while languages offer dynamic simple and refined types our types here are entirely refined his coercions use and syntax for injection and projection while our coercions lack such a distinction in our refinement lists each coercion simultaneously projects from one refinement type and into another possibly producing blame we reduce notation by the et al introduce option contracts which offer a way of off contract checking as well as a controlled way to pass the off contracts from component to component option contracts address time efficiency not space efficiency findler et al studied space and time efficiency for datatype contracts as did and contracts have a form of space efficiency the predicate checks for exact duplicate contracts and blame at tail positions the redundancy it detects seems from to rely on pointer equality since contracts are a macro contracts and b first class this optimization is somewhat limited compared with our calculus which can handle contracts and blame labels conclusion and future work space efficiency for manifest contracts is the of state as the final barrier to practical utility we established that h behaves exactly like its classic counterpart without space usage we believe it would be easy to design a latent version of h following the translations in et al in our simple ie not dependent case our refinement types close over a single variable of base type space efficiency for a dependent calculus remains open the first step towards dependent types would be extending with a context and a source of closing substitutions a serious issue in a dependent setting the definition of what it means to compare closures at all clear closures environments may contain functions and closures over equivalent functions may not be equal a more nominal approach to contract comparison may resolve some of the issues here comparisons might be more straightforward when contracts are explicitly declared and referenced by name similarly a dependent predicate might be more easily defined over some explicit structured family of types like a lattice findler et al has made some progress in this direction finally a host of practical issues remain beyond representation choices having expensive checks makes it important to predict when checks happen the predicate compares closures and will have interactions with optimizations acknowledgments comments from greg morrisett weirich wadler and improved a previous version of this work done at the university of pennsylvania some comments from benjamin pierce led me to realize that a cast formulation was straightforward discussions with findler and greatly improved the quality of the wadler me to return to coercions to understand the formulation the popl reviewers had many suggestions and findler once more with angelic de the paper this work was supported in part by the nsf under grants tc and and by the crash program through the states force research laboratory under contract no the views expressed are the authors and do not reflect the policy or position of the department of or the us references j f m a and b c pierce polymorphic contracts in european symposium on programming esop g m a d gordon c and d semantic subtyping with an smt solver in international conference on functional programming icfp c r findler and m felleisen option contracts in oopsla pages ­ r b findler contracts as pairs of projections in symposium on logic programming r b findler and m felleisen contracts for higherorder functions in international conference on functional programming icfp r b findler sy and a lazy contract checking for immutable data structures in implementation and application of functional languages pages ­ c flanagan hybrid type checking in principles of programming languages popl r calculating with blame in international conference on functional programming icfp m manifest contracts phd thesis university of pennsylvania november m manifest contracts url http technical report m b c pierce and s weirich contracts made manifest in principles of programming languages popl m b c pierce and s weirich contracts made manifest journal of functional programming ­ may j and c flanagan unifying hybrid types and contracts in in functional programming f dynamic typing syntax and proof theory sci comput program ­ d a and c flanagan gradual typing in in functional programming pages ­ d a and c flanagan gradual typing higher order symbol comput ­ june k and c flanagan hybrid type checking acm trans prog lang syst ­ k a j s n and c flanagan hybrid checking for flexible specifications in scheme and functional programming workshop e and v checking data structure properties orders of magnitude faster in runtime verification pages ­ r october url r milner a theory of type polymorphism in programming journal of computer and system sciences ­ aug plt contract system url a a and b the ins and of gradual type inference in principles of programming languages popl j siek r and w exploring the design space of higherorder casts in programming languages and systems volume of lncs pages ­ j siek p and p wadler blame coercion and together again for the first time draft url j g siek and r interpretations of the lambda calculus in scheme and functional programming j g siek and w gradual typing for functional languages in scheme and functional programming workshop september j g siek and p wadler with and without blame in principles of programming languages popl pages ­ n m and g m a theory of typed coercions and its applications in international conference on functional programming icfp pages ­ isbn s and m felleisen migration from scripts to programs in oopsla p wadler and r b findler welltyped programs cant be in european symposium on programming esop a k wright and m felleisen a syntactic approach to type soundness information and computation ­ a proofs of type soundness this appendix includes the proofs of type soundness for all four modes of h we first prove some universally applicable properties a generic metatheory a lemma weakening if m e t and m t and x is fresh then m x t and x t m e t a lemma substitution if x t m e t and m e t then m ee x t and m a lemma if m e t then m and m t a lemma similarity is reflexive if t t proof by induction on t t x b e by s refine t tt by s fun and the a lemma similarity is symmetric if t t t proof by induction on the similarity derivation s refine by s refine s fun by s fun and the t then a lemma similarity is transitive if t t and t t then t t proof by induction on the derivation of t t s refine the other derivation must also be by s refine by s refine s fun the other derivation must also be by s fun by s fun and the a lemma well formed type sets have similar indices if m s t t then t t proof immediate by inversion a lemma type set well is symmetric m a t t iff m a t t for all m e proof we immediately have m t and m t and t t iff t t by lemma a if m c or m f then by a none and symmetry of similarity lemma a if m h then let t s be given the h t premises hold immediately we are then done by transitivity lemma a and symmetry lemma a of similarity t t iff t t when t t a lemma type set well is transitive if t t and m a t t and m t and m e then m a t t proof we immediately have m t and m t we have t t by transitivity of similarity lemma a if m c or m f we are done immediately by a none if on the other hand m h let t s be given we know that h t and t t by symmetry lemma a and transitivity lemma a of similarity we are done by a a classic type soundness a lemma classic determinism if e c e and e c e then e e proof by induction on the first evaluation derivation a lemma classic canonical forms if c e t and e then ­ if t x b e then e k and b and e ex c true ­ if t tt then either e x t e or e tt l e a lemma classic progress if c e t then either e ie e l or e or there exists an e such that e c e proof by induction on the typing derivation a lemma classic preservation if c e t and e c e then c e t proof by induction on the typing derivation a type soundness a lemma determinism of h if e e e and e e e then e e proof by induction on the first evaluation derivation in every case only a single step can be taken a lemma canonical forms if e e t and e then ­ if t x b e then e k and b and e ex e true ­ if t tt then either e x t e or e · x t e a lemma progress if e e t then either e ie e l or e or there exists an e such that e e e proof by induction on the typing derivation a lemma extended refinement lists are well formed if e x b e and e r x b e x b e then e b el r x b e x b e proof by cases on the rule used a refine all of the premises are immediately except in one case when x b e x b e where x b e r is the only type x b e then drop r x b e well formed on its own but adding x b el makes it so by transitivity if not then we know that drop r x b e is well formed and so is its extensions by assumption we know that there are no by of a fun a lemma merged coercions are well formed if e c t t and e c t t then e c t t proof by induction on cs typing derivation a refine by the ih lemma a and a refine a fun by the and a fun a lemma coerce generates well formed coercions if t t then e t l t t proof by induction on the similarity derivation s refine by a refine with b e x b e l x b el s fun by a fun and the a lemma preservation if e e t and e e e then e e t proof by induction on the typing derivation a lemma source program typing for h source programs are well typed in c iff they are well typed in e ie ­ c e t as a source program iff e e t as a source program ­ c t as a source program iff e t as a source program ­ c as a source program iff e as a source program proof by mutual induction on e t and b proofs of soundness b lemma idempotence of coercions if e k x b e and e r x b e x b e then for all e we have x b b e · k e e iff x b b e · k e e proof by induction on their evaluation derivations the only difference is that the latter derivation performs some extra checks that are implied by ek x e we already know to hold as before cast congruence is the key lemma in our proof in this case the strongest property we have reduction to identical results b lemma cast congruence single step if ­ e e t and e c t t and so tc t · e t ­ e e e and so e e t e then for all e we have tc t · e e e iff tc t · e e e proof by cases on the step taken to find e e e our proof strategy is as follows we show that the casts between related types are applicative and then we show that well typed source programs in classic h are logically related to their translation our definitions are in figure our logical relation is like our proofs relating and h to classic h we use the semantics in the refinement case and use type indices b lemma similar casts are logically related if t e t and t e t and e e e t then t l e e t l e t proof by induction on the invariant relation using coercion congruence in the function case when e is a function b lemma relating classic and source programs if c e t as a source program then e e e t term type extraction pt t e types ta t l e e en in types x b e e k l b e types x b e s r k e · b e type type set and coercion type extraction pt b e x b e tt pt b el r x b e c type height b e figure type extraction and type height if c t as a source program then t e t proof by mutual induction on the typing derivations c proofs of bounds for this section contains our definitions for collecting types in a program and the corresponding proof of bounded space consumption for all modes at once we define a function collecting all of the distinct types that appear in a program in figure if the type t x int x y appears in the program e then includes the type t itself along with its x int x and y c lemma x proof by induction on e c lemma proof this property is trivial when a · immediate when a c c c lemma proof similar to lemma c c lemma types doesnt introduce types t l proof by induction on t and t when they are refinements we have the coercion just being x b el when they are functions by the ih c lemma types doesnt introduce types r x b e proof by induction on r r nil the two sides are immediately equal r x b e l r if x b e x b e then the two are identical if not then we have by the ih c lemma coercion merges dont introduce types r proof by induction on r r nil the two sides are immediately equal r x b el r using lemma c we find r x b e drop r x b e x b e r x b e x b e c lemma reduction doesnt introduce types if e e then proof by induction on the step taken m 