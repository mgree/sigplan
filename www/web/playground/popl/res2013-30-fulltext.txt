linear dependent types for differential privacy benjamin c pierce university of pennsylvania di focus abstract differential privacy offers a way to answer queries about sensitive information while providing strong provable privacy guarantees ensuring that the presence or absence of a single individual in the database has a statistical effect on the result proving that a given query has this property involves establishing a bound on the much its result can change when a single record is added or removed a variety of tools have been developed for that a given query is differentially private in one approach and pierce proposed a functional programming language for writing differentially private queries uses linear types to track sensitivity and a probability monad to express randomized computation it guarantees that any program with a certain type is differentially private can successfully verify many useful queries however it fails when the sensitivity analysis depends on values that are not known statically we present dfuzz an extension of with a combination of linear indexed types and lightweight dependent types this combination allows a richer sensitivity analysis that is able to a larger class of queries as differentially private including ones whose sensitivity depends on runtime information as in the differential privacy guarantee follows directly from the soundness theorem of the type system we demonstrate the expressivity of dfuzz by differential privacy for a broad class of iterative algorithms that could not be typed previously categories and subject descriptors d programming languages language application languages f theory of computation studies of program structure general terms design languages theory keywords differential privacy type systems linear logic dependent types introduction an amount of data in databases every records location data etc this information could potentially be very valuable eg for scientific and permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm research but much of it cannot be safely released due to privacy concerns moreover and are not sufficient to privacy recent experience with the for example has shown how easy it is to leak sensitive information even when the data is carefully before it is released differential privacy is a promising approach to this problem it offers strong statistical privacy guarantees for certain types of queries even in worstcase scenarios intuitively this is accomplished by a only queries whose result does not depend too much on the data of any single individual and b adding some random to the result of each query thus if we pick any individual i and remove all of is data from the database before a query the probability that the result is any given value v remains almost the same this limits the amount of information that can be learned about a single individual by observing the result of the query many specific queries have been shown to be differentially private including machine learning algorithms such as empirical minimization and combinatorial optimization algorithms such as vertex cover and and many others but checking that a given query is differentially private can be both tedious and rather subtle the key challenge is to prove an upper bound on the sensitivity ie the maximum change in the output that can result from changing the data of a single individual briefly queries require more to maintain privacy since most data are not in differential privacy they cannot benefit from its strong guarantees unless they have access to suitable tools the approach we focus on is to provide with a programming language for differentially private queries the can formulate queries in this language and then them to a special compiler which determines their privacy cost and them if this cost a budget that has been specified by the this approach is because differential privacy is compositional for instance the privacy cost of a sequence of differentially private computations is simply the sum of the individual costs thus we can reason about large complex queries by manually a few simple primitives and then composing the analysis results of larger and larger this is the basis of previous systems like which provides a language which implements a framework and a higherorder functional language the analysis in is based on a type system that queries as differentially private via two components numeric annotations at the type level to describe the sensitivity of functions and a probability monad to represent probabilistic computations can many useful queries but it fails for other important kinds of queries including some fairly simple ones for instance iterative algorithms such as can only be analyzed when the number of iterations is a constant and there are other instances such as a program that computes a distribution function for an arbitrary list of where even the type of the program cannot be expressed in fails for these programs because their overall are not simply a static composition of the of rather they depend on some input data such as the number of iterations or the list of numeric numeric sensitivity annotations are not sufficient to express such dependencies between input data and sensitivity however as we show in this paper these dependencies can be expressed with dependent types dependent types enable static reasoning about information that will be available to a program only at runtime but we must make a choice at the regarding the complexity of the dependencies we wish to support richer dependencies would expand the range of queries that can be certified as differentially private but systems with rich dependent types tend to require extensive program annotations which would make dfuzz more difficult to use by at the extreme end of this would be a system like which can a broad range of differentially private queries but requires the programmer to supply most of the proof to preserve our goal of by we instead work the other end choosing a lightweight form of dependent types that requires few annotations but still yields a powerful analysis we introduce a language called combines a rich form of typelevel sensitivity annotations with lightweight dependent types the sensitivity annotations we consider are arithmetic expressions over real numbers our dependent types are a simple form of indexed types where indices describe the size of data types and provide the programmer with dependent pattern matching in the style of dependent ml sensitivity annotations and dependent types combine well and the resulting language strong properties most importantly our type system like that of captures the concept of differential privacy since dfuzz an extension of the metric preservation property of to demonstrate the capabilities of dfuzz we show that it can several examples from the differential privacy literature quite naturally including iterative database construction and the distribution function in summary we offer the following contributions · dfuzz a core calculus for differential privacy that combines the earlier sensitivity analysis of and pierce with lightweight dependent types inspired by dependent ml section · the fundamental metatheory for dfuzz including an adaptation of the usual basic preservation and well as a generalization of the metric preservation theorem from sections and and · four example programs that express algorithms from the differential privacy literature and can be successfully certified by dfuzz section we discuss related work in section and future research directions in section background and overview differential privacy we begin by some basic definitions suppose the private data is collected in a database that contains rows of the same type and each data is in a single row let db be the type of such databases and assume for the mo ment that we are interested in queries then the key definition of differential privacy based on is definition a randomized function f db r is differentially private if for all possible sets of outputs s r and for any two databases b b that differ in only one row b s e · b s intuitively this means that the presence or absence of one data has only a small effect on the distribution of f s randomized outputs here is a privacy parameter the larger is the more information about is potentially by the result for small the factor e can be thought of as we will often refer to as the privacy cost of running f we can extend the definition to data types other than db and r if we assign to each data type a metric that measures the distance between values we write v r v to indicate that two values v and v of type are at most r apart thus we obtain definition a randomized function q is differentially private if for all sets s of closed values of type and for all v v such that v r v we have p s e rp s to determine whether a given query has this property the following definition is useful definition a function f is for c r if for all v v with v r v we have f v f v in other words a function changes in its inputs by at most a factor of c when a function q is not for any c r in the sense of the above definition we will refer to it as sensitive functions with limited sensitivity can be converted into differentially private queries using the mechanism introduced in here we write l to denote the distribution with scaling parameter proposition let f db r be a function and let q db r be the randomized function q b f b n where n is a random variable distributed according to lc then q is differentially private in other words the mechanism converts f into a randomized function q by adding from the distribution note that the parameter of the magnitude of the on both c and the stronger the privacy requirement smaller and the higher the sensitivity of f larger c the more must be added to f s result to preserve privacy linear types for differential privacy the key idea behind static type systems for differential privacy is to provide a compositional analysis that tracks both the privacy cost and the sensitivity c of a function for context we sketch the analysis in on which our work is based has a linear type system functions can have types of the form r where the modality r is annotated with a numeric upper bound r on the functions sensitivity for instance the term x · x can be given the type r r to express the fact that f x · x is sensitive in its argument x checks these types with standard typing judgments of the form e where the type environment additionally contains hypotheses about sensitivity for instance a typing judgment x c e means that e can be given type if e is at most in the free variable x in the symbol appears both in types as here and in terms to help guide typechecking algorithms here for simplicity we uses in terms as an illustration consider the slightly more complex program z · z · x it is easy to see that x r · x r and z · z r r and thus uses the typing rule e r g r e g to infer x r z · z · x r this reflects the fact that · · x · x is sensitive in x to turn this deterministic program into a randomized differentially private one introduces a probability monad and assigns monadic types to randomized computations accordingly the concept of sensitivity is generalized so that the privacy cost of a differentially private function is interpreted as its sensitivity specifically the type system guarantees that any program that can be given a type db r is differentially private with privacy cost the full type system is described in which also show how several practical programs can be successfully type checked one of these is clustering a machine learning algorithm that takes a list of points and computes around which the points cluster however as mentioned above a key tation of is that its sensitivity annotations are purely numeric in the case of clustering this is a major the sensitivity depends on the number of iterations of the algorithm but types cannot express the fact that a functions sensitivity in one parameter may depend on the value of only way out is to the number of iterations for instance in a program performing two iterations can be typed as lr r r lr r this type says that is a program that when provided with an initial list of of type lr r produces a differentially private algorithm that maps a to a new list of a program that performs a different number of iterations would have a different type worse in section we will see several examples of practical algorithms whose types cannot be expressed in eg the algorithm in which the desired sensitivity is itself a parameter this means that we cannot even add such operations to as primitives in dfuzz we overcome this limitation by adding dependent types in particular we add a lightweight form of dependent types that allow us to give the following type to a general algorithm for i lr rk i r lr rk this type gives more precise information about the behavior of it says that is a program that when provided with a natural number i specifying the number of iterations the sensitivity annotation is since this parameter does not need to be kept private and a list of k produces a i differentially private algorithm that maps the to a list of k in the next section we describe dependent types in more detail dfuzz the main of dfuzz is the way it combines a lightweight form of dependent types a la dependent ml with a sensitivity analysis inspired by the one in this combination requires several which are formally defined in figure type grammar figure program syntax figure in a fixed value of was into the metric on distributions in contrast we use the convention from where the privacy parameter is not fixed and is made explicit in the type annotation kinds z ns l s rr ps precise types r db basic types a i i quantified types a z a types a r modal types s i s size terms r k r s r r r · r sensitivity terms s s i assumptions c s s r r constraints i kind environments x a type environments figure dfuzz types p r rn probabilities e g x xe e e f fix xe expressions s e nil e e of e xi e e of nil e x e ie ei i as i e as x i in e p return e e e en let x e in e v xe f fix xe s v nil v ie i as i p return v v e en values s do e p s sn states f do return v p f fn figure dfuzz syntax final states rules figure subtyping rules figures typing rules and figure selected operational semantics rules we describe each of these components below some details for brevity in particular we some linear data types like and a full description is available in sizes and the special feature of dfuzz types figure is that they can contain size or sensitivity information this information is described by means of terms in a small language at the type level a size term written s is a term that to the grammar s i s where i is a size variable size terms are simple expressions over natural numbers they are used to describe the size of data types a sensitivity term denoted r is a term that to the grammar r k r s r r r · r where k is a sensitivity variable and r is a nonnegative real constant ie r r sensitivity terms are simple expressions that consist of positive real numbers and the symbol they are used to describe program sensitivity an annotation of means that k k r r k r r i i r r r kr r r r · r figure rules s s k s k s str st i i st i i r r st r r i i st i i s s ns ns s s stl ls l s figure subtyping rules ax x x x e · fix xe fix e e r e e l x r e i xe r e r r · e g g e figure core typing rules e ns s s e ns n nil l e g ls c g ls n e ns s g i s i x g r · e of g xi g e l s s g i s i x rl i y r r · e of nil g xi g g i e i ie i i e ii i i i as i i e i i ei ii e e i i x r g i r e r · e as x i in g imply f ext f r figure data types and polymorphism typing rules e return e i e x g e let x e in g e pn ei i e p pn si i s e e en p s sn p r rn pn e do do e figure probability layer typing rules there is no guaranteed bound on the sensitivity the binary operators and · are the symbolic counterparts on of sum and product on values their precise meaning is described below we will use the metavariable i to range over sizes and any size term is also a sensitivity term this is important for expressing dependencies between sizes for example number of iterations and for example privacy cost to ensure the correct behavior of size and sensitivity terms and to prevent substitutions we consider size and sensitivity terms to be typed as well to avoid confusion we refer to the types for size and sensitivity terms as kinds dfuzz uses two kinds for size annotations and for sensitivity annotations kinds are assigned to terms via kind judgments of the form i where is a kind environment ie a set of kind assignments to size and sensitivity variables the rules for deriving the judgment i are presented in figure notice that we have a relation on terms that is induced by the rule k this relation allows us to consider size terms as sensitivity terms for notational convenience we will write sizes and terms without making explicit their kind we can interpret size terms over the domain n of natural numbers and sensitivity terms over the domain r of nonnegative extended real numbers to interpret expressions with free variables we need as usual a notion of is a mapping from size variables to elements of n and from sensitivity variables to elements of r we write dom for the domain of this is a set of mappings of the shape i where each variable i appears at most once given a term i and an assignment such that dom we inductively define the interpretation i · · i i · s s · r r · r r r r · r · r r · r · where and · are the usual sum and product extended to r r · r r · for every r r for every r and · · note that this definition implicitly size real numbers as needed the of the interpretation is by the following lemma lemma let i and dom then · if then i n · if then i r proof by induction on the derivation proving s data types and dependent pattern matching our syntax of types offers just two representative algebraic data types natural numbers ns and lists ls with elements of type see figure we could have further and included general algebraic datatype declarations and pattern matching but this would add to the complexity of the notation without we believe raising new conceptual issues we leave this generalization to future work intuitively the size of a natural number corresponds to its value we consider a unary encoding of the natural numbers and we assume the natural number to be of size and the size of a list corresponds to the number of elements in it we assume nil to be of size types like ns and ls are only by terms whose evaluation produces a value of size s if it terminates the approach is of singleton types to illustrate why size terms are helpful for expressiveness let us consider the list data type in more detail values of the list type are built through the constructors nil and g see figure where cons carries the size s of the expression g as additional information this information is used to support a simple form of dependent pattern matching the destructor can in addition to the usual pattern matching also perform typelevel pattern matching this is described by the following reduction rule see figure e of nil g x g in which the size s is propagated to the term g in a similar way in the reduction rule in figure for dependent pattern matching on ns the information n is propagated to the term g the data type elimination rules in figure are crucial to making this technique work for instance the elimination rule for the list data type e l s s g i s i x rl i y r g r · e of nil g x g adds assumptions explained in detail below to the contexts used to typecheck the two branches of the case construct information by the case about the size s of the test value e in the first branch it is assumed that s this extra piece of information enables us to remember at the typing judgment level that e has been matched to nil conversely in the second branch it is assumed that s i giving us a name i for the size of the tail of the list e which appears in the type assumed for the pattern variable x a similar mechanism is used in the elimination rule for the ns data type assumptions and constraints more formally a judgment e contains besides the usual environment for term variables and the kind environment an extra parameter that records the assumptions under which the typing is obtained intuitively the expression e can be assigned the type for any value of its free size variables satisfying since assumptions record the size constraints generated by the pattern matching rules we consider assumptions that to the following grammar s s i an assumption is well defined when it is associated with a kind environment that determines the kinds of the free size variables in we write in this case given an assumption and an assignment such that dom the interpretation is defined inductively as follows · true · s s · s i s i · where is equality on natural numbers the use of assumptions is crucial for the subtyping relation figure indeed subtyping judgments involve judgments of the shape c where c is a constraint of the form r r or s s the meaning of a constraint c also follows directly from the interpretation of the size and sensitivity terms it contains given an assignment for the size and sensitivity variables appearing in c the interpretation c is defined inductively as · r r r r · s s s s where is the expected extension of to cover the judgment c asserts that the constraint c is a logical consequences of the assumption ie for every such that true we have c true analogously we will also use the notation to denote the fact that the assumption is a logical consequence of the assumption we will see how these judgments are used later when we present the subtyping rules in detail generalized and the scaling modality sensitivity terms are the key in the sensitivity analysis they appear as of the scaling modality r the scaling modality is used to define types with the shape r which are used in turn in function types and in term environments suppose that a given expression e can be assigned the function type r e r then we know that e is a function that maps elements of type to elements of type as long as is satisfied and that in this case r is an upper bound on the functions sensitivity two points further explanation first a static analysis cannot always describe the exact sensitivity of a program we are always dealing with conservative upper bounds second we say that r describes this upper bound because it is not necessarily a number it can depend on size or sensitivity variables from which can themselves be involved in assumptions from this dependency is central to the expressivity of dfuzz modal types also appear in type environments a typing judgment of the form x r xn rn n e says that the expression e is a function whose sensitivity in the ith argument is described by the sensitivity term ri notice that this means that every function type comes with a sensitivity term associated to its input type indeed we are implicitly using the standard linear logic decomposition of the intuitionistic implication and the observation that it suffices to have modal types appearing in negative position for convenience we will similarly use the notation as a shorthand for functions ie functions of a type r where r modal types can be combined by arithmetic operations r t rt and t · r t and these operations are lifted to type environments the sum of two contexts is defined inductively as · · x a x b x a b · x a x a x a if x dom the product of a type environment with a sensitivity term t is · t · · t · x a t · x t · a it is worth that the sum of two type environments and is defined only in the case that for each x the type ab is defined where x a and x b this in turn requires that there is a type such that a r and b r in all the binary rules in figure we implicitly assume this condition a sensitivity term can also appear as the annotation of a precise type rr this class of types is close in spirit to the data types ns and ls since it terms whose value is described by r however we have no destructor operation for this kind of type we will see in section that these types can be used to dynamically specify the sensitivity of certain operations subtyping and quantifiers the assumptions introduced by pattern matching play a crucial role in the subtyping relation which is defined by the rules in figure a subtyping judgment has the shape where is a kind environment and is an assumption intuitively the subtyping relation says that and are equal up to their with size and sensitivity terms and the of is more permissive than the of under the assumption one main purpose of the subtyping relation is to capture the fact that an function is also r sensitive for r r this is by the rule for the scaling modality r r st r r indeed the combination of this rule and the rule for function types st which as usual is contravariant in its first argument ensures that r r iff r r in other words if we can prove that r r under assumption then every expression that can be given the type r can also be given the type r subtyping is also needed for putting the dependent pattern matching mechanism to work to unify the contexts and the types in the two branches of a case rule this is obtained by using subtyping judgments on data types for instance for natural numbers we have a rule s s ns ns that allows us to obtain the type ns from the type ns if we have s s subtyping can be applied by using the rule r in figure moreover it can be extended to type environments the judgment holds if for every x a we have x b and b a note that the type environment can contain variable assignments for variables that do not appear in thus the rule l in figure can also be seen as a kind of weakening in order to be able to express the size and sensitivity dependencies in a uniform way we additionally the type language with a universal quantifier and an existential quantifier over size and sensitivity variables figure for instance the type i ni ir r can be assigned to a program that given a value of type ns returns an function of type sr r for any size term s similarly the type i ni k jr r abstracts the sensitivity of the function that is returned when a term of this type is provided with a value of type ns finally the type i ni is the type of the ordinary natural numbers the probability layer to ensure differential privacy we need to be able to write probabilistic computations this is achieved in dfuzz by considering a grammar of programs with two layers figure we have an expression layer that contains the constructors and destructors for each data type and an additional probability state layer that contains the program constructions for describing probabilities over expressions and values to between the two layers we use a monadic type similar to the one found in ramsey and stochastic lambda calculus in order to describe probabilistic states we need to have probability vectors p ie lists of real numbers from the interval that sum up to probability vectors can be typed by means of a precise type of the shape ps where the size term s describes the length of the vector though s can range over variables the typing rules for vectors only use types pn indexed by a constant natural number n a probabilistic state s then is either an object of the shape p s sn where p is a probabilistic vector or an object of the shape do e intuitively the former associates a discrete probability distribution described by p to a list of probabilistic states s sn whereas the latter turns an expression into a probabilistic state probabilistic states represent probabilistic computations in the sense that their evaluation results in final states that assign probabilities to values for an example the state do return do return do return is a final state in which the value is returned with probability and the values and are each returned with probability · we use three monadic expression forms to ensure that only expressions representing probabilistic computations can be turned into probabilistic states the expression return e can be seen as representing the distribution that yields e the monadic sequencing let x e in e can be seen as a program that a sample x from the probabilistic computation e and then continues with the computation e and the explicit probability construction e e en associates an expression e representing a probability vector with a list of random computations e en the typing rules figure ensure that we consider only wellformed expressions in particular the rule e pn ei i e e e en ensures that e represents a probability vector and every ei is a probabilistic computation notice also that this rule is responsible for the wellformedness of the probabilistic states it ensures that we associate lists of expressions of length n only with probability vectors of the same length this is the reason for introducing the precise type pn as a last remark notice that the different components of a state represent independent computations so even though evaluation of expressions is defined sequentially we define evaluation on states in parallel sensitivity and primitive operations one last component that is necessary to make the framework practical is a way to add trusted primitive operations ie operations that are known to preserve the properties of the type system this is intuitively the meaning of the following typing rule from figure imply f ext f r which says that we can add to dfuzz any primitive operation f of type r as long as we know that this operation represents a mathematical function f that maps values in the type to values in the type and that is under the assumption at the operational level the evaluation rules for the primitive operation f must respect the behavior of the function f this is obtained by means of the two following rules figure e e fe fe f v f v we can also extend dfuzz with additional primitive types as long as they are equipped with a metric that respects the properties we describe in section basic metatheory in this section we develop fundamental properties of dfuzz in order to show the usual properties one would expect from our programming preservation and additionally need to prove some properties that are particular to our use of size and sensitivity annotations these will also be useful to prove the metric preservation theorem in the next section we give just proof full proofs are in properties of sizes and as we saw earlier typing judgments in dfuzz have the form e ie they are indexed by a set of kind assignments to index variables and an assumption intuitively the fact that the subtyping can prove statements using the assumptions in is what makes the dependent pattern matching work it enables us to recover the same type from the different branches here we prove some properties of the typing with respect to the assumption the first says that strengthening the assumption preserves the typing lemma assumption strengthening suppose that then we have if c then c if then if e then e if s then s proof follows directly from the transitivity of the logical implication follows by induction on the derivation proving using point when needed follows by induction on the derivation proving e using point when needed follows by induction on the derivation proving s using point when needed the environment can contain free size and sensitivity variables these can be thought of as for any size or sensitivity index term and they can be instantiated with a concrete index term when necessary this is captured by the next lemma lemma instantiation if i c then for every ii if i then for every ii ii ii i we have i we have of e xi e e s n of e xi e ee e of nil e y e e of nil e y e e e fe fe nil of nil e yi e e f v f v w of e fix fix ee e as x i in g e as x i in g ee i as i i as i op i as i as x i in e ee return e return e ee e e en e e en ee op tr let x e in e let x e in e op let x return v in e e vx op let x p in e p let x ei in e in do p p do e e do e do e i n si si sj sj fj i i j i p p figure selected evaluation rules if i e then for every ii ii ii if i s then for every ii ii ii i we have i we have proof follows directly from the definition of constraint satisfiability follows by induction on the derivation proving i using point when needed follows by induction on the derivation proving i e using point when needed follows by induction on the derivation proving i s using point when needed type soundness and type preservation using the properties on size and annotations detailed in the previous section we are now ready to prove the usual properties we want a programming language to substitution type preservation and progress theorem substitution if x r e and g then r · proof by induction on the derivation proving x r e the proof of the substitution lemma is straightforward except for the management of the term variable environments the proof of type preservation however is not as straightforward because it requires the constraints and the size and sensitivity annotations in various places theorem type preservation if e and e e then e if s and s s then s proof part proceeds by induction on the derivation proving e and case analysis on the possible derivations for e e using the substitution lemma lemmas and are needed when the step taken comes from a dependent pattern matching rule part now follows by induction on the derivation proving s and case analysis on the possible derivations for s s using point when needed we can also prove progress as usual theorem progress if e then either e e or e is a value if s then either s s or s is final proof both parts proceed by induction on the given derivation using part as needed in part metric preservation and differential privacy the design of the dfuzz type system is related to the metric relation we present in this section this connection is captured by the metric preservation theorem which states that the evaluations of two well typed expressions at a given distance result in two values at the same distance or less metric relations to formalize the notion of sensitivity we need a metric relation on programs and states that captures an appropriate notion of information distance for each type for this purpose we first introduce a metric relation r on values and final states and then extend it to a metric relation r on expressions and states through substitutions of related values concretely we begin with metric judgments on values and final states v r v f r f respectively that values v v and final states f f are related at type and that they are no more than r apart where r r using these metric judgments we can also relate substitutions of values for variables in an environment first we need some notation let be the environment obtained from as follows xi i xi ri i suppose that is a vector of positive reals indexed by variables in dom ie x r xn rn then we also define a metric judgment with shape this asserts that the substitutions and of values for the variables in dom are related at the types described by and that they are no more than apart that is for every value vi xi and vi xi we have vi xi vi finally we have judgments for expressions and states e r e s r s these assert that the expressions e e and states s s are related at the type and that they are no more then r apart in the type environment given an environment x r xn rn n and a vector of positive reals x r xn rn we define as n i ri · ri by can assume values in r in what follows we will be particularly interested in the cases where is finite all these metric judgments are defined inductively by the rules in figure where b b is the size of the symmetric difference between the two databases b and b it is worth noting that the metric on expressions considers only expressions that are typable with no constraints and no free size variables this ensures that the index r in the relations r and r is actually a value r r the metric presented here like the one used in differs significantly from the one presented in in its treatment of non value expressions and states in particular we do not require the relation on expressions to be closed under reduction this makes the proof of metric preservation easier and as we will see it is sufficient to ensure differential privacy metric preservation the metric preservation theorem which we present at the end of this section can be seen as an extension of the type preservation theorem we can read it as that the evaluation of expressions and states preserves not only their types but also the between related input values up to a constant factor given by the metric relation the proof of the metric preservation theorem involves five major steps the goal of these steps is to ensure that the different metric relations respect the properties of the type system the first step is to show that the metric on expressions and states a sort of weakening lemma if e r e and r p then e p e if s r s and r p then s p s proof the proof of is by inversion on the rule proving e r e using the fact that if v r v and r p then v p v the base case of follows from the inductive case follows directly by induction hypothesis the second step is to show that the metric relation is well with respect to the subtyping relation this is formalized by the following lemma lemma subtyping on metrics if e r e and then e r e if s r s and then s r s proof by induction on the derivation proving e r e by induction on the derivation proving s r s the third technical lemma is an intermediate step to show that the two metric relations r and r coincide on expressions and states that happen to be values and final states respectively lemma suppose e if and e is a value then e must also be a value and e e suppose s if and s is final then s must also be final and s s corollary v r v iff v r v f r f iff f r f the last important property that the metric inherits from the dfuzz type system is a substitution property on the judgments involving the relation r lemma substitution into the following rule is admissible e r e x r e r e r · r r r combining these four results we can prove the main lemma lemma metric compatibility suppose such that r then if e and e g then g e g and g g if s and s sf then sf s sf and sf sf proof by induction on the typing derivation proving e and f respectively with further case analysis on the evaluation step taken and using corollary and the substitution lemma the metric compatibility lemma is the main we need to prove that welltyped programs map related input values to related output values theorem metric preservation if e r e and e ef then ef e ef r ef if s r s and s sf then sf s sf r sf ef and sf and proof by inversion on the rule proving the judgment e r e using the metric compatibility lemma by induction on the derivation proving the judgment s r s again using lemma we can then make a corresponding statement about the complete evaluation of two expressions or two states where is the reflexive transitive closure of the step relation theorem bigstep metric preservation if e r e and e v then there exists v such that e v and v r v if s r s and s f then there exists f such that e f and f r f v f n ns r rr nil l v v f f n n ns r r rr nil nil l v r v v r v ls v rr v ls v r v r r v r v r r r r r r r b b r b r b db x r e r e xe r xe r x e r e fix xe r fix xe v r v ii i as i r i as i i r r v ri ri s i iv r iv i r rn s r rn pn p r p pn fi s fi i p r p pn ei s ei i p f fn rs p f fn p e en rs p e en p r p pn si s si i p s sn rs p s sn e r e do e r do e e e e vi ri vi i i vx · · · vx · · · x xn n figure metric rules welltyped programs are differentially private the bigstep metric preservation theorem ensures that programs map related inputs to related outputs combined with the properties of the probability layer this allow us to show that welltyped programs are differentially private to formalize this we need to define the probability v that a final state f yields a value v we recursively define return v v if v v otherwise n pi v i note that by the typing rule for probabilistic states s the tuples p pn f fn must have the same length the metric on probability distributions is carefully chosen so that the metric on final states corresponds to the relation on probability distributions needed in the definition of differential privacy lemma let f and f be two closed final states such that f r f for some r r then for every value v v v thus we can show that the type system can verify that a program is differentially private theorem differential privacy the execution of any closed program e such that e is an differentially private function from to that is for all closed values v v such that v r v and all closed values w if v f and v f then w er w proof by using the fact that vx xr v x x we have that r xv x so by the bigstep metric preservation theorem we obtain f r f we conclude by corollary and lemma the above theorem shows that in order to ensure that the execution of a program e corresponds to an differentially private randomized function from values in to values in it is sufficient to check that the program e has a type of this form e primitive operations for privacy as outlined in section one important property of dfuzz is that it can be extended by means of primitive operations in particular we are interested in adding two basic building blocks allowing us to build more involved differentially private examples the first operation we add is the mechanism proposition with the following signature add r r r note that unlike the version presented in this primitive allows the level of and thus the level of privacy to be specified by the user another primitive operation that well in our framework is the exponential mechanism exp s rs bag r r db where bag is a primitive type representing a multiset of objects of type the exponential mechanism takes a set of possible outputs a quality score that assigns to each element in the range a number depending on the database and the database itself the quality score is at most in the database and here we allow this sensitivity to be passed in as a parameter the algorithm outputs an element of the range that approximately the quality score case studies to illustrate how dependent types expand the range of programs that can be certified as differentially private we now present four examples of practical algorithms that can be implemented in dfuzz but not in each algorithm is taken from a different paper from the differential privacy literature specifically the first three algorithms rely on the following new feature that is enabled by dependent types iterative privacy the ability to express a dependency between the total privacy cost of a function and a parameter that is chosen at runtime such as a number of iterations the last example illustrates how allowing slightly more complex sensitivity annotations can increase the expressivity and it also shows another important use for dependent types tradeoff the ability of a function to control its own privacy cost eg by scaling the precision of an iterated operation to make the total cost independent of the number of iterations we are with a prototype implementation of dfuzz and we present the examples in the actual syntax used by the prototype an extension of that closely follows the concrete syntax from figure for instance we write sample xe e to denote let x e in e we only omit instantiations of terms for brevity the examples also use some additional constructs such as ab for tensor products of types a and b with associated primitive operations details of these extensions are available in iterative privacy our first example figure is clustering an algorithm from data that groups a set of data points into k clusters given a set of points and an initial guess for the k cluster the algorithm iteratively refines the clusters by first associating each point with the center and then moving each center to the middle of its associated points the differentially private version ensures privacy by adding some to the refined the algorithm can be implemented in dfuzz as follows here iterate is a procedure performing function db i e bag iterate bag oe case of return n sample n db iterate iterate db figure in dfuzz an update of the details omitted for brevity note that the sensitivity of in the database db depends on two other parameters the number of iterations i and the privacy cost per iteration e that the is to this is enabled by the dependent types in dfuzz in contrast is only able to typecheck a simplified version of in which both parameters are iterative database construction our second example figure is an algorithm that can efficiently answer exponentially many queries with good accuracy this is done by first constructing a public approximation of the private database which can then be used to answer queries without further privacy cost builds the approximation iteratively given an initial guess it uses a private pa to find a query that would be on the current approximation and then applies a database update algorithm to refine the approximation pa and are parameters of the algorithm and the sensitivity of an instance depends on the of its pa this can be expressed in dfuzz as follows several choices for pa and have been proposed in the function iter db i e qs query bag pa query bag oe query query num query o num case iter of return n sample n db qs pa sample q pa qs db sample actual q db return q actual figure iterative database function in dfuzz literature some can be written directly in dfuzz eg the exponential from and others can be added as trusted primitives eg the sparse from by contrast a parametric cannot be written in plain because there is no way to express the dependency between the sensitivity of the and the sensitivity of the overall algorithm distribution function our third example figure is an algorithm that computes the function given a database of numeric records and a list of defined by values it computes the number of records in each bucket presents three variants of this algorithm with different tradeoffs only one of which was previously supported in to understand why consider the following version implemented in dfuzz note that the sensitivity in this version depends function db i e num bag case of return x y let fun n nx db sample count lt sample y gt return count figure distribution function in dfuzz on the number of values or since cannot capture such a dependency this variant is not just impossible to write in cannot even be added as a trusted primitive since there is no way to express its type signature in contrast dfuzz can directly support this program and it could also support the last version in with a small extension that we discuss in section tradeoff our fourth and most complex example shows how dfuzz enables programmers to write functions that control their own privacy cost and it also illustrates how small extensions to the language for annotations can further increase expressivity the extension we use here introduces a new operation r r on sensitivity terms r and r that provides a limited form of division the in is extended accordingly as follows r r r s r r if r r r s r s if r r r r otherwise the behavior of the operator is different from that of the ordinary division operator does not the usual properties of division with respect to multiplication and addition ie it is not the inverse of multiplication and it does not the usual distributivity laws however it does have two key properties first lemma still holds for the system that includes if the usual division ÷ were added instead the interpretation would no longer be total because r ÷ and ÷ are in general undefined when ÷ is the inverse of · and the usual distributivity laws the choice of ensures the preservation of the results of sections and second the interpretation of satisfies the following inequality the need for which will become apparent for every r r · r r in terms of we can add a safe division primitive to the language for terms div i j ri rj ri j note that the div operation is simply a restriction of the usual division to positive real numbers that we make total by restricting the domain of the to reals greater than or equal to with this extension we can implement our fourth example figure an algorithm for a classic problem in combinatorial optimization given a database v of locations with between locations a desired number k of say to build and a private demand set d v the goal is to select a set f v of k locations to minimize the cost defined to be the sum of the from each demand point to the in the program the are given implicitly via the cost function which maps sets of locations to costs the algorithm starts with an initial random choice f of k locations and runs several iterations each time using the exponential mechanism equation in section to find the best location to swap for a location in the candidate set of after building up a collection of candidate sets the mechanism uses the exponential mechanism once more to choose the best configuration the function runs the main loop which repeatedly tries to improve the cost of a set of locations by replacing a location from the set with one that is not in the set the outer function simply chooses an initial random set of locations and sets up the privacy and iteration constants the program uses several primitive functions for manipulating checks the membership in builds the cartesian product of two adds an element to a bag two element in a bag and chooses subset of a given size from a bag uniformly at random the function score measures how much a swap can improve the cost of a set of locations it can also be written in dfuzz see the key challenge in implementing is that it the privacy level of the exponential mechanism to achieve a con function iter f loc bag cost loc bag loc bag os num v loc bag d e s i loc bag loc bag loc bag bag case iter of return f bag f x sample pair x f cost v d let fi fs pair let fun l v l fi fi sample best score cost fi d let a b best a b fi return fs function t v loc bag cost loc bag loc bag os num d e loc bag k loc bag sample f k v sample result t f cost v d let fs result fs cost d figure in dfuzz overall privacy cost independent of the number of iterations to derive the correct type for dfuzz must prove that in the call to the auxiliary function the sensitivity of d is at most this involves checking a subtyping application that requires the following inequality between sensitivity terms e i · s · · s · i e this inequality follows from two applications of equation thus with the additional operator algorithms that scale their privacy cost depending on the number of iterations can be expressed and verified in dfuzz using dependent types related work differential privacy our system provides differential privacy one of the strongest privacy guarantees that has been proposed to date alternatives include and which are generally less restrictive but can be to certain attacks on privacy differential privacy offers a provable bound on the amount of information an attacker can learn about any individual even with access to auxiliary information is an differentially private query language embedded in c is a solution using a modified java vm both and check privacy at runtime while dfuzz uses a static check the other previous work in this area is on which dfuzz is based dfuzz has a richer type system while uses linear types to track sensitivity dfuzz uses a combination of linear indexed types and lightweight dependent types which substantially expands the set of differentially private queries that can be certified successfully another recent languagebased solution is this is a on top of the coq proof reasoning about differential privacy from first principles can even more queries than dfuzz including queries that do not rely on standard building blocks such as the it can be used to prove the correctness of the mechanism itself however this comes at the cost of much higher complexity and less automation making more suitable for who are expanding the boundaries of differential privacy in contrast certification is automatic allowing it to target a class of potential users other work in this area include xu who considered differential privacy in a distributed setting using a process calculus and et al who introduce a platform for private data analysis that error for certain queries linear dependent types linear types inspired by linear logic have as key tools to support fine reasoning about resource management in this context the idea of using indexed modalities p for counting multiple uses of the same resource as we do early on bounded linear logic introduced modalities indexed by polynomial expressions those are similar to our sensitivity annotations with the essential difference that they are polynomials over natural numbers while we consider polynomials over the reals augmented with this approach has been extended in by constrained universal and existential quantifiers providing mechanisms for polymorphism and abstraction over polynomial expressions similar to the ones made available by our quantifiers over size and sensitivity variables different forms of lightweight dependent types form the basis for programming languages such as dependent ml and moreover they have also started to be incorporated in more standard programming languages such as haskell in all these approaches the types can express richer properties of the program that can then be automatically by type checking is a language that combines linear and dependent types its type system is with a notion of resources that is a typelevel representation of memory locations the management of location resources uses a linear discipline this aspect makes useful for reasoning about properties of memory and pointers however linear types as used in are not enough to reason about the sensitivity of programs linear indexed types and lightweight dependent types have also been combined in with the aim of providing a general framework for implicit complexity the approach in is similar in spirit to the one developed in the current paper however it considers only typelevel terms that represent natural numbers and its typing judgments are parametric in an equational program providing for the semantics of the typelevel language moreover allows a further dependency between different modal operators that is not needed for our analysis more recently et al proposed a language that combines linear types with dependent types in order to provide program modules with a refined control of their state related notions of privacy and sensitivity the study of database privacy and statistical databases has a long history recent work includes and study of probabilistic database management systems and et als comparison of different notions of privacy with respect to realworld data quantitative information flow is concerned with how much one piece of a program can affect another but measures this in terms of how many bits of entropy leak during one execution while differential privacy and quantitative information flow are clearly related concepts the question of establishing formal relations between them has been only recently provenance analysis in databases tracks the input data actually used to compute a output and is also capable of detecting that the same piece of data was used multiple times to produce a given answer and recently proposed a approach to compute the sensitivity of relational algebra queries their analysis is able in particular to compute the exact sensitivity for a wide range of queries in contrast the goal of our approach is to provide an upper bound on the sensitivity not only of relational queries but also for higher order functional programs et al in study automatic program analyses that establish sensitivity which they call of numerical programs their approach can also used to ensure differential privacy although they do not study this application in depth our approach differs in that we ensure differential privacy through a logically motivated type system rather than a program analysis conclusions and future work we have presented a new core language dfuzz for differentially private queries like its predecessor dfuzz has a type system with strong properties which guarantee that all queries of a certain type are differentially private the key in dfuzz is a lightweight form of linear dependent types that track size and sensitivity information this considerably expands the range of programs that can be certified as differentially private we have demonstrated the expressivity of dfuzz using four example algorithms from the differential privacy literature that can be implemented in only in greatly simplified form or not at all prototype we are currently working on an algorithmic version of dfuzz and a prototype implementation the key implementation challenge is related to checking the subtype relation a natural approach to this problem is to generate numeric and logical constraints that would have to be satisfied in order to type the program and to then pass these constraints to an external solver in the case of dfuzz some of the constraints are over real numbers but they are of a form that is supported by the z solver since additional constructs and annotations are at runtime a prototype can share a with and is thus able to take advantage of against side channels possible extensions the languages for size and sensitivity annotations we have used in this paper are fairly restrictive but this is merely a design choice and not an inherent limitation of the approach as we have shown in the example allowing more complex size and sensitivity annotations can increase the expressivity though it may also make the generated constraints harder to solve there are other simple increments to the annotation languages that would increase expressivity for example provides a algorithm for the distribution function that uses a approach the resulting sensitivity is proportional to the of the number of if of sizes were added to the annotation language it would become possible to implement this algorithm of course this addition would again come at the cost of increasing the difficulty of constraint solving another possible direction would be to include more general data types as in in addition to the precise types ls and ns we have focused on for instance the private facility location algorithm as presented in is similar to but instead of a fixed number of to build we are given a fixed cost per and the goal is to minimize the total cost this algorithm requires recursion over generalized trees which we could be implemented in dfuzz if support for versions of these data types were added limitations and future work we designed dfuzz to algorithms for which the differential privacy property can essentially be proven with a rich compositional sensitivity analysis to show that the is drawn from an appropriate distribution however in the differential privacy literature there are algorithms whose analysis requires more involved reasoning one example is the private version of the vertex cover algorithm that was presented in one way to handle the analysis for this algorithm would be to use the probabilistic relational reasoning that is the basis of the framework the ability to reason about relations between different programs and data ie about closely databases seems crucial to this approach however by using the framework one the ability to reason about differential privacy in an automated way one natural way to preserve the automatic approach and to nevertheless expand the scope of the analysis would be to combine the approach of dfuzz with a limited form of relational reasoning acknowledgments we thank for many valuable comments on the final version of this work we thank s and the anonymous reviewers for their helpful comments this research was supported by grants n and n and nsf grant was supported by the european framework fp under grant agreement n references m s m e k and c on the relation between differential privacy and quantitative information flow in proc icalp g and b bounds for differentially private mechanisms in proc g b f and s probabilistic relational reasoning for differential privacy in proc popl a c f and k practical privacy the framework in proc k c and a d differentially private empirical minimization j learn res ­ july s s gulwani r and s proving programs robust in proc c chen and h xi combining programming with theorem proving in proc icfp pages ­ u and m linear dependent types and relative completeness in ieee lics pages ­ u and m hofmann bounded linear logic in volume of lncs pages ­ springer n c and d probabilistic databases in the acm ­ l de and n z an efficient smt solver in proc tacas c differential privacy in proc icalp c f k and a smith to sensitivity in private data analysis in proc m a j a and b c pierce linear dependent types for differential privacy extended version j girard linear logic theor comp sci ­ j girard a and p scott bounded linear logic theoretical computer science ­ t j g and v provenance in proc a gupta k f a and k differentially private combinatorial optimization in proc a gupta a and j ullman iterative constructions and private data release in proc a b c pierce and a differential privacy under in proc usenix security s singleton union and intersection types for program extraction in proc volume of lncs pages ­ springer berlin s p h k lee k s and a smith what can we learn in proc oct n r a d dreyer and d types in proc icfp n li t li and s privacy beyond and in proc a d j j and l privacy theory meets practice on the map in proc f privacy integrated queries an extensible platform for data analysis in proc f and r network trace analysis in proc f and k mechanism design via differential privacy in proc p a e d and d privacy preserving data analysis made easy in proc a and v robust of large sparse in proc ieee sp c and m differential privacy for relational algebra improving the sensitivity bounds via constraint systems in proc volume of pages ­ n ramsey and a stochastic lambda calculus and monads of probability distributions in proc popl j m and b c pierce distance makes the types grow stronger a calculus for differential privacy extended version j and b c pierce distance makes the types grow stronger a calculus for differential privacy in proc icfp sept a and t the mechanism interactive and efficient privacy with multiple queries in proc i s t v a v and e security and privacy for in proc d walker advanced topics in types and programming languages chapter type systems the mit press h xi and f pfenning dependent types in practical programming in proc popl l xu modular reasoning about differential privacy in a probabilistic process calculus manuscript b a s weirich j s peyton jones d and j p m es giving haskell a in proc 