programs david benjamin microsoft research abstract programs are an important class of programs with applications in detection input sanitization for web security and html processing this paper extends prior work on bek an expressive domainspecific language for writing programs with algorithmic insights that make bek both and by we mean that unlike most general purpose programming languages many algebraic properties of a bek program are decidable ie one can check whether two programs commute or compute the inverse of a program by we mean that a bek program can compute on arbitrary of its input in parallel thus exploiting parallel hardware this latter requirement is particularly important for programs which operate on large data without data parallelism a programmer cannot hide the of reading data from various storage ie reading a of data from a modern hard takes about with a approach the system can split data across multiple and thus hide the of reading the data a bek program is expressive a programmer can use conditionals switch statements and local order to implement common programs unfortunately this expressivity induces data dependencies which are an to parallelism the key contribution of this paper is an algorithm which automatically removes these data dependencies by mapping a bek program into a intermediate format consisting of symbolic transducers which extend classical transducers with symbolic predicates and symbolic assignments we present a novel algorithm that we call exploration which performs symbolic loop unrolling of these transducers to obtain simplified versions of the original program we show how these simplified versions can then be lifted to a form and from there compiled to hardware to evaluate the of our approach we demonstrate up to x for a number of realworld bek programs eg html and on hardware to the best of our knowledge these are the first data parallel implementation of these programs to validate that our approach is correct we use an automatic testing technique to compare our generated code to the original implementations and find no semantic permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than acm must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ copyright c acm categories and subject descriptors d formal definitions and theory semantics d language specialized application languages f models of computation automata f formal languages decision problems keywords symbolic automaton symbolic satisfiability modulo theories state space exploration introduction bek is a popular for programs because of its expressiveness and we have chosen to use it for our experiments while much of our results can be applied to symbolic finitestate transducers our focus is on providing correct and implementations of symbolic finitestate transducers bek gives us a platform for doing so the reader can some bek programs online at or read the bek to build his or her intuition typical bek programs are string and security sanitizers etc why bek the advantage of a domainspecific language is that unlike most generalpurpose languages many algebraic properties are decidable for basic bek bek programs that do not use registers in particular one can check whether such bek programs commute or are idempotent one can compute the inverse of a bek program and given an output compute all inputs that lead to it while previous work has focused on algorithms for reasoning about basic bek programs they did not provide a clear strategy for either running bek on a variety of platforms thus its adoption or providing algorithms that first transform bek programs to their basic form these are important problems as bek programs are useful tools that developers use to secure both web and scale web services the goal of this paper is to demonstrate how to compile a bek program to their basic form then as a concrete application we show how to compile bek programs into scalable code previous work has shown that special state variables called registers in bek are often needed to express common functionality section unfortunately registers introduce data dependencies that are to parallelism and also make many forms of bek analysis undecidable manually removing registers requires developers to reason about complex state which is and exploration a key contribution of this work is a novel exploration algorithm that is a form of loop unrolling combined with symbolic function composition loops are symbolically while data dependencies exist between consecutive iterations such unrolling is achieved by introducing new states for finite projections of registers in this process several characters may be together into tokens by folding some part of a register symbolically into labels while another part is into concrete states intuitively changes the of what is to be considered as a single input element for example if we take a program such as a then would create tokens that correspond to between and bytes while for a base it would create of fixed length while the algorithm is not guaranteed to work in all cases because it is undecidable eg it is easy to encode reachability of two counter machines which is undecidable when it does work it produces a transducer that is equivalent to the original up to of the input sequence but without register variables we have not found any typical bek programs such as sanitizers or for which the technique would fail to terminate a case when it does not work is a loop that for example counts the number of elements in the input or in general has arbitrarily long dependencies between input elements data parallelism there are two key benefits to a bek program after exploration first registers induce data dependencies which limit parallelism and thus exploration is a necessary first step in exploiting parallelism second after exploration by construction a bek program has little intermediate state eg complexity of a program is pushed to the edges rather than encoded as states the overhead of our data parallel implementation of a bek program is linearly related to the size of the bek programs intermediate state and thus exploration enables the automatic transformation from an expressive bek program with registers into a data parallel one this ultimately the programmer from the burden of explicitly describing parallelism in a bek program an and difficult task contributions this paper makes the following contributions · previous work on bek introduced an extension to symbolic transducers with registers use of registers is essential for modeling real sanitizers but makes their analysis difficult in this paper we present a novel exploration algorithm that is a form of loop unrolling that works modulo arbitrary decidable background theories the algorithm terminates for a class of that only need a bounded lookahead and the algorithm outputs a new transducer that is equivalent to the input transducer but does not need registers · we integrated the exploration algorithm into a bek to symbolic finite transducer sft compiler it has several interesting features first it uses an smt solver as an oracle during the exploration algorithm both for satisfiability checking and for model witness generation second it combines exploration with third it uses the simplification mechanism present in modern smt solvers for code generation of conditions and update functions · we demonstrate how exploration enables data parallelism in particular we show how to encode a bek program with infinite alphabets and registers into one with a finite set of equivalence classes and no registers further we demonstrate a data parallel implementation of this intermediate form based on recent work in parallel finite state machines to the best of our knowledge this is the first parallelization of code that combines advanced automata theory with smt technology to produce a parallel implementation · we have with a number of bek programs we frequently observed exponential reductions in the number of assuming standard text processing where code points are limited to in which case bytes are enough otherwise longer encodings up to bytes are possible private s t a t i c string string t i f t n u l l return n u l l i f t length return s t r i n g empty new s t r i n g b u i l d e r t length foreach char c in t i f c c c c c c c c c c c b u i l d e r append c else b u i l d e r append int c return figure code for version states due to the application of our exploration algorithm to validate the correctness of our translation we used random testing of of strings observing no semantic differences when compared to independent c serial implementations for the range of hardware configurations we have with we observe a as significant as x the background theories that were relevant for us during this work were theories over linear arithmetic tuples and lists these theories were used to represent characters tokens and strings however there were no dependencies on these particular theories for example one could also consider reals and arrays speaking any theory or combination of theories that is supported by an smt solver works background and motivation programs much of the practical motivation for analyzing routines comes from the need to analyze security sanitizers such as the one shown in figure these are key in against cross site attacks which web applications these attacks happen because the applications take data from untrusted users and then this data to other users of the application because web pages mix and javascript this data may be interpreted as code by a browser leading to arbitrary code execution with the of the the first line of against is the practice of sanitization where untrusted data is passed through a sanitizer a function that escapes or removes potentially strings multiple widely used web frameworks offer sanitizer functions in libraries and developers often add additional custom sanitizers due to performance or functionality constraints sanitizers are typically a small amount of code perhaps of lines furthermore application developers know when they are writing a new custom sanitizer or set of sanitizers experience has shown that if developers are to a little more time on sanitizers they can obtain fast and precise analyses of sanitizer behavior along with actual sanitizer code ready to be integrated into both server and applications our approach here is bek a language for modeling string transformations the language is designed to be a sufficiently expressive to model realworld code and b sufficiently restricted to allow fast precise analysis without to approximate the behavior of the code unfortunately implementing sanitizers correctly is surprisingly difficult in of code performed across various just about any sanitizer was with respect to security for example shows in sanitizers used by ten web applications incorrect sanitization may be worse than no sanitization by enabling rather than javascript execution the problem becomes even more complicated when considering that a web application may compose multiple sanitizers in the course of creating a web page in a recent empirical analysis it has been found that a large web application often applied the same sanitizers twice despite these sanitizers not being idempotent this analysis also found that the order of applying different sanitizers could vary leading to questions about whether composition of sanitizers is commutative bek has been previously used to perform analyses of sanitizers for example one can use bek to determine whether there exists an input to a sanitizer that yields any member of a available database of strings known to result in cross site attacks our analysis is fast in practice for example we take two seconds to check the commutativity of the entire set of filters and less than seconds to check an implementation of the sanitization function against target strings from the beyond strings bek has been demonstrated as being useful for applications beyond security sanitization other uses have been proposed as as image and privacy which fall outside the scope of this paper the interested reader can see for more details performance to realize why performance is a concern in this context consider distributed data processing in the encoding is in web applications especially with large of data or web for example store files from of users caused by data sanitization has been discovered in these before to avoid these services must encode all user files before them on the web symbolic transducers the semantics of bek programs are given by symbolic transducers the goal of this section is to the bek language in section in section we develop a formal treatment required to precisely express these semantics readers may wish to save section for later reading intuition we briefly describe the bek domainspecific language for writing string transformations such as shown in figure an example bek program is in figure as introduced in the core construct in bek is iteration over each character in an input string programs can then have case statements that describe different behavior for different input characters typically the program will perform some local computation then yield or output a new character a new string is built up based on the characters of the input string registers programs can also have register variables that keep state during the iteration figure shows a sample bek program that checks each character and then updates a register variable r depending on input character the program may then output the contents of the register or it may simply pass through the the reader may these links for examples function ex i t e xx i t e xx i t e xx i t e x program be i n p u t return iter x in input s r c a s e r a i s e error c a s e s y i e l d e r x e s r c a s e t r u e y i e l d e i t e s x r x r i t e s s s end case s yield e r end case s yield e r end case true y i e l d may be o m i t t e d figure bek program for base encoding x yx y ey x yx y y x x yx y q yy y yy ey yy ey figure st of the program be in figure character unchanged an end case statement takes care of any remaining final output suffix after the end of the input has been reached for more details on bek we refer to previous work or to the online bek evaluator while the language is limited it still is expressive enough to capture a wide range of functions including many of the functions commonly used in web sanitization and functions used in processing st representation the semantics of the program in figure is captured by a symbolic transducer in figure symbolic transducers are a generalization of classic finite transducers which allow arbitrary underlying label theories exploration and the register variables in bek are important for making it easy to translate functions written in c or other languages to bek because existing functions typically keep state through an iteration these variables are also convenient for writing functions in bek directly unfortunately these register variables are of because they introduce control flow that depends on the registers and not on the individual character formalism we now formally define symbolic transducers or sts and give examples of how sts capture behavior of programs we assume a background structure that has an effectively enumerable background universe u and is equipped with a language of function and relation symbols with fixed interpretations definitions below are given with u as an implicit parameter we assume closure under boolean operations and equality operations that are specific to u do not affect the results we use expressions for dealing with anonymous functions that we call terms in general we use firstorder logic and follow the notational conventions that are consistent with the universe is with denoting the of elements of type we make use of the empty tuple type t such that t we use a variant of the definition of sts where the control state component of sts is explicit we write for the set of predicates we write for terms f that denote functions f we write for k k in other words for any term f the length of the output sequence may not depend of the input but must be fixed definition a symbolic transducer or st with input type output type and register type is a tuple a q q r r where q is a finite set of states q q is the initial state r is the initial register value r is a finite set of rules r f where q × × × × × × is a set of transitions and f q × × is a set of finalizers a transition q o u p is also written q p where q is the start state the guard o the output u the update and p the end state a q o is also written q o with q as the state as the guard o as the output finalizers generalize final states example let be unsigned or natural numbers n and let be the type n × n the operation is is is is the st in figure has the above types and is the direct mapping of the bek program in figure where s y and r y q q r and the st has two transitions and three finalizers it computes base encoding of byte sequences base is a standard encoding that is used to transfer binary data over textual the semantics of a is given by the following concrete transition relation let q p q r a then q r a p ua r denotes that there exists a transition q p such that a r holds similarly q r or a denotes that there exists a q o such that r holds now the reachability relation p a p for and p p q × is defined through the closure under the following conditions where · is concatenation of sequences note that · x¯ x¯ · x¯ · if p a p then p a p · if p a p p then p p definition function from the to of a denoted ta is the following def qa ra a a is singlevalued when for all and a is deterministic when for all p p p if p a p and p a p then and p p we write for finalizers can be omitted at the of allowing nondeterminism however nondeterminism is because of sts is in general not possible and analysis of or even code generation from nondeterministic sts is very difficult it is easy to show that determinism implies deterministic sts form a practically important subclass of sts and in the examples and case studies we only consider deterministic sts for the translation explained in section the sts are required to be deterministic that is naturally the case for the kinds of string transformations we have in mind with this approach example let a be the st in figure let y and x a so x and y we have ex e e q and x so there is a concrete transition q aq q if we do one more step from configuration q with input b we get the concrete transition q bu q suppose that the input sequence ends here then we use the last that gives us the concrete transition q i by using the derived reachability relation we have q thus compilation of sts to sfts we assume that an st is given the st may for example be the result of a translation from a bek program sample bek program and corresponding st are illustrated in figure and figure our goal is to compile the st into an sft if possible where an sft is an st without registers or formally whose register type is t in the sft we may group some characters into combined characters or tokens so that if the input type of the st is then the input type of the sft is k for some k sequences over of length l l k in our compilation we maintain the following equivalence between the given st and the resulting sft we use where ui has type k to denote the sequence u · u · · · un in definition st and sft are equivalent modulo if in other words the outputs of st and sft must be equal for some of the input characters in sft the compiler uses two phases and exploration the phases are interleaved into a single algorithm but intuitively they serve two distinct purposes the idea is as follows two consecutive transitions p q q can be lifted into a single transition that reads more inputs in one atomic step x yx y x ux y x y · o x ux y x x ux y p q where xi reads the ith element from x suppose first element has index thereby the state q becomes eliminated if this is the only occurrence of q the lifted transition may also become unsatisfiable in which case it is eliminated the input character of the new transition is a pair of the original characters exploration exploration starts from the initial configuration q r where q is the initial state and r is the initial register value of the st if an update to a register is a fixed value r that is independent of the input values in a given target state q of the st then the configuration q r is treated as a state algo py from z import z solver c l a s s st e n c a p s u l a t e s a s y m b o l i c t r a n s d u c e r def i n i t s e l f q r t f x y ax s e l f q q initial state self r r initial register self t t transitions s e l f f f finalizers s e l f x x label variable s e l f y y register variable s e l f ax ax background axioms d e f d e l t a s e l f q transitions from q f o r t i n s e l f t i f t q y i e l d t d e f f i n s e l f q f i n a l i z e r s from q f o r f i n s e l f f i f f q y i e l d f d e f i s s a t f z p u s h z add f r e s z c h e c k z pop r e t u r n r e s u n s a t d e f choose f t z p u s h z add f z c h e c k v z model e v a l u a t e t t r u e z pop r e t u r n v d e f g e t u n i q u e v a l u e s t p h i t k x lambda i c o n s t i s t x s o r t z lambda i c o n s t zd i s t x s o r t t h e t a x i z i f o r i i n range k t s u b s t i t u t e t t h e t a p h i s u b s t i t u t e p h i t h e t a i f i s s a t and p h i p h i t t r e t u r n none e l s e r e t u r n choose p h i t d e f group s t q r k p h i o u t f o r qs g o u qe i n s t d e l t a q xk c o n s t k s t x s o r t t h e t a s t x xk s t y r c and p h i s u b s t i t u t e g t h e t a i f i s s a t c o s u b s t i t u t e o t h e t a f o r o i n o r s u b s t i t u t e u t h e t a v g e t u n i q u e v a l u e s t c r k i f v none y i e l d c o u t o k qe v e l s e f o r t r i n group s t qe r k c o u t o y i e l d t r f o r qf g o i n s t f i n q cf and p h i s u b s t i t u t e g s t y r i f i s s a t cf of s u b s t i t u t e o s t y r f o r o i n o y i e l d cf o u t of k none none d e f e x p l o r e s t e x p l o r a t i o n a l g o r i t h m z add s t ax add t h e a x i o m s t o t h e s o l v e r w s f t n e x t s t a t e i d s t a t e m a p s t q s t r s t a t e i d m a p s t q s t r s t r w h i l e l e n w qs w pop q r s t a t e m a p qs t t b o o l v a l t r u e f o r g o k q r i n group s t q r t t qe none i f q none i f q s t r r i n s t a t e i d m a p qe s t a t e i d m a p q s t r r e l s e qe n e x t s t a t e i d n e x t s t a t e i d s t a t e m a p qe q r s t a t e i d m a p q s t r r qe w add qe s f t a p p e n d qs g o k qe r e t u r n s f t figure st exploration algorithm in z python of the explored sft and the configuration if new is pushed to the search stack for exploration if an update does not have a fixed value then is invoked in an attempt to the use of the register update the overall effect is that registers which are used to encode local dependencies between consecutive characters are redundant and thus can be eliminated we refer to the full algorithm also as exploration when it is clear from the context that the combined algorithm is meant the complete algorithm is given by the executable python script in figure although the algorithm is given in a concrete executable form in python using the z module it is identical to an abstract mathematical formulation and we have therefore decided to present only the concrete version although it requires a bit of extra effort to get used to the notational differences compared to the formalism above we illustrate the exploration algorithm in example where for purposes and exploration are presented as two separate phases the function called on line shows how z is used to decide if the register is going to have a concrete value ie if the term r representing the value is constant with respect to the constraint c if not then is invoked recursively example take the st in figure project into n as the first element y of y and n as the second element y of y this projection happens automatically in the combined exploration algorithm exploration will now partially evaluate all the rules by using depth first search and integrate y into the states in x rx ex x q q r x rx x rx q figure st after exploration of st in figure such a way that a rule q q is replaced by one or more rules of the form qa qb where a b and the register z has type the main technical insight is that it is possible to compute such b and ab for the given a through finite case analysis over x even though and may be infinite if we apply exploration to the st in figure we get the st in figure we can now apply to this st to illustrate consider the path q f q g q h q of transitions first apply to q f q g q to obtain q fg q and then we apply to q fg q h q to obtain p p at this point the composed label f g h be xx x x x ex ex · x ex · x ex xx x p ex ex p xx x x ex ex · x ex p figure sft after of st in figure denotes extraction of bits from m to n from y y · z denotes comes independent of the register r because r is only used to glue f with g and g with h a similar step is applied to transitions followed by finalizers to get composed transitions that lead from p to sink states p and p states without outgoing transitions and with trivial finalizers that yield empty outputs finally all resulting rules are independent of the register and so the register can be eliminated and we have constructed an sft illustrated in figure an important point is that the construction of the sft would not be possible by only using or only using naive exploration the new combined exploration algorithm is needed the first point we address next is the reason we are interested in sfts the second point is when does the exploration algorithm terminate the third point is does the algorithm meet our needs for parallelization as it turns out the third question needs more work ­ because except for some special cases when the lookahead is fixed the assumption that the input is up front is not fully realistic in a parallel setting because then there is no way to calculate where the next token starts without having processed the previous tokens figure compares the sizes of the state machines needed to achieve the different encoding and tasks size sft sft figure exploration sizes in total nr of transitions sft is naive exploration sft is exploration is creation of after sft the table indicates the advantages of using the exploration algorithm without this reduction in the size of the sft we would not be able to compile the sft to exploit data parallel finite state machines presented below where the approach requires that the number of states in the transducer is small which our compilation scheme provides while the label theory may potentially allow infinite character domains in particular it is shown in figure a that in html the number of states in the sft grows exponentially in the length of k for supporting of patterns k that makes naive exploration to sfts in this case this exponential is avoided with the new exploration algorithm the final column in the table shows the size of the obtained after the final phase of the algorithm discussed below definition a has a finite state space q and has transitions p f q where p q q is a predicate and f mn is a term for some fixed m and n we assume that the is deterministic meaning that if there are two transitions p f q and p f q such that is satisfiable then f f and q q a has also finalizers of the form q f with f as above and where to maintain determinism there is at most one for each state q the case m means that there is no input dependence so f is a fixed output sequence the semantics of a transition p f q is that is applied in state p to the current character in the input sequence c¯ say ci there is an implicit criterion that if the state is p and ci is true then i m where m is the arity of f if ci holds then f is applied to ci ci to produce the next subsequence of the output for finalizers the semantics is that f is applied to cl cl to produce the suffix of the output where cl is the last character termination and limitations the exploration algorithm does not terminate if there are unbounded dependencies between successive characters in the input in other words if the register is needed to remember some input element for arbitrarily many following input elements for example if the register is used to sum all seen in the input then the exploration algorithm does not terminate an of a nonempty sequence over is a sequence over m whose form equals for example the sequence is a of the sequence definition st a has the bounded lookahead property if there is a finite subset p q × p q r p and there exists m such that for all input sequences over accepted by a there exists an of such that pi ui pi for some pi p for i n and pn theorem exploration algorithm terminates iff the st has the bounded lookahead property the output sft is equivalent modulo to the input st we write sft for the intermediate result that the exploration algorithm produces namely sft stands for the sft whose input characters have been ie whose character type is m for some m where is the character type of the input sft there is a class of sts for which the exploration algorithm does not terminate although an equivalent exists roughly speaking this situation arises when bounded cannot be turned into bounded lookahead thus even if the st could in principle be compiled into an equivalent there exists no intermediate sft over characters the following example illustrates such a case example consider standard over full an input to the is a encoded string an input is if it contains a bad b · b is a high in range h def x x that is not immediately followed by a low in range l def x x or · b is a low that is not immediately by a high some use the following rule as a feature rather than strings eg in in net framework the replacement character is used to replace bad so that the string is not such a phase can be described by the st in figure a say rep for efficiency x x x x x x y q q x x x x x x x xx a using an st h h q lx xx x q x l xx b using a sft figure replacing bad with existing integrate rep into the logic for the but here we think of it as a separate preprocessing step over the input in some versions of the replacement character itself is also encoded in others it is not the difficulty with rep is that there is no fixed length lookahead window to decide if the last character in the window is the last high however the sft in is equivalent to rep and is with the approach described below the variable x refers to the previous character in the input while x refers to the current character so the window size for determining the output is to be completely accurate the exploration algorithm does terminate for the rep st in figure a because there are a finite number of high but this is not the point the point is that the exploration creates a state space that is large moreover if h x and lx were defined as x mod and x mod then the algorithm would not terminate because rep would not have the bounded lookahead property suppose there exists m and p as in definition and consider the input for some c such that h c holds then q c p but there are infinitely many such c that p is finite it is an open problem how to decide such cases the particular case of rep in figure a seems easy to detect but consider the small variant of rep where the is replaced by q hx q ie the intermediate high are ignored then there exists no fixed k for the symbol xk in the corresponding transition from q to q in the k sft in figure b the way we deal with this problem is by using composition the sts we consider are defined under the assumption that the input string is valid ie it has no bad the exploration algorithm is used to produce a sft that is then transformed into an equivalent say m finally m is composed with rep the sft in figure b to produce m xm although are in general not closed under in this particular case they are so the actual input to parallelization is m not only is this easier to program but it is also less error because the corner cases of what to do with bad are completely avoided moreover there is no loss in efficiency because the two transformations are automatically composed into one essentially eliminating the intermediate string as a form of deforestation example illustrates a case when it is not possible to construct sft from st because there is no bound although an equivalent exists another difficulty is that it is not always possible to turn an sft into a that is required for parallelization unless all groups have a fixed length as discussed below such a transformation requires monadic decomposition of predicates in order to decompose nary relations used as guards in the sft into boolean combinations of monadic relations that will guard the transitions in the in general this is not possible eg if the predicate is x y moreover the problem of deciding if such a decomposition exists is in general undecidable even when assuming as we do that the theory over labels is decidable the latter undecidability follows from a result in proposition b the exploration algorithm presented above transforms an st into an sft at the of several input characters into one token thus formally the input language of the sft is a nested sequence where the inner sequences or character groups are tokens if all tokens have the same length k as in base where k then it is possible to process the original input in parallel by reading the input tokens from offsets km for m in general as for example with html encoding or encoding the tokens have variable length and this simple solution does not work also storing inputs in registers breaks and takes us back to square one instead we transform the sft into a with building on the idea of introduced in the algorithm that we use does not introduce registers and maintains the property that transition guards only reference the current character but output functions may refer back to k prior input characters the resulting is a special kind of a the main benefit is that the transition graph of the domain of a is an sfa over the original characters this enables the parallelization approach presented in section and the output computation still works because the is bounded and can be applied in parallel we illustrate the algorithm below using an example the input to the algorithm is an sft over tokens or of characters this sft is first decomposed so that all transitions are split into predicates over singleton characters to achieve this the algorithm uses monadic decomposition of predicates from then the split transitions are merged back together into a deterministic finally the is compiled into c code that is used by the subsequent parallelization step example we consider here a cut down version of a to illustrate construction suppose that the sft produced by exploration has a single state q and three transitions q xx q q f q and q g q where · reads one byte and checks that it is in the range and the character is output as is · reads two bytes and checks that they form a valid byte encoding f computes the code point from the two bytes · reads three bytes and checks that they form a valid byte encoding g computes the code point from the three bytes the first transition is kept as is the second and the third transitions are split into transitions that read one character at a time and the output calculation is delayed to the last transition in order to do so the predicates are first decomposed by using monadic decomposition the decomposed forms of the predicates are as follows using notation for numbers and interval notations x bf e x x bf x ed x f x bf x x bf x bf the construction algorithm introduces intermediate states for each transition after reading each symbol considering one disjunct at a time in the dnf it then merges the transitions into a single deterministic in this case the result is a sft shown in figure there would be additional states for the case of byte x x x xf x x q q q e q ed q f q bf figure sft constructed from a that up to three byte encodings encodings resulting in a sft and more states and larger if even longer encodings up to bytes were allowed translation in the prior sections we demonstrated how to remove registers from st and turn them into in this section we describe how to run on hardware in particular we demonstrate an end to end compilation of to a data parallel version capable of exploiting multiple via threads here we frame the evaluation of finite state transducers as associative operations over vectors and matrices because these operations are associative they can take advantage of hardware the number of states in the sft must be small for efficiency our key insight that allows us to combine sts with the approach is that we first transform the st into a using the pipeline of algorithms discussed above in effect st to compilation pushes the complexity of the st into the edges which in turn allows us to efficiently target hardware in the sections that follow we demonstrate an automatic approach that a bek program into a sft and then down into the data parallel formulation that runs on hardware operators to aid our discussion we introduce two higherorder primitives first takes a binary function and maps that function over two sequences of equal length for example to pairwise add the numbers in two sequences we could use second scan applies a binary associative function over every prefix of a sequence ie given a sequence x x xn xn and an identity element i such that i x x scan produces i x x x x x x x · · · xn for purposes we use a related function that takes a function q × q a value q q a sequence s sn sn and produces the sequence q q s q s s q s s · · · sn in q of length n finally we use the function split to split a given sequence s according to a sequence m of offsets as follows into a sequence of tuples or we next show how to define sfts in terms of these primitives describing sfts with higherorder functions recall that a m is a tuple q q r where q is the initial state and r f is a finite set of rules consisting of transitions and finalizers f here we require m to be deterministic moreover for ease of presentation and without loss of generality we assume that all finalizers of m are trivial in the sense that they produce the empty output and are thus treated as final states in the classical sense for example the sft in figure b is deterministic we assume that we work with an extended alphabet where there is an symbol and all valid input sequences end with so that finalizers are not needed for each transition p f q we refer to the arity of f as the of the transition that is denoted by p a where a we represent normal characters by their code points as nonnegative integers has code we refer to f by p a ie p a takes p a arguments thus the rules define a transition function from a given input and state to an output and a new state let q a be the state function implicitly defined by the rule set r which takes as arguments a state q and an input a and produces a new state to an input sequence s m starts in state q q and sequentially reads the symbols of s when m reads the ith symbol si from s in state qi first symbol being s it enters state qi qi si and calls the output function qi u where u si si si which maps to a finite possibly empty sequence of symbols in the output alphabet we call the algorithm to a string by m it takes as input m and a sequence s and produces the output sequence s let q q s in let m q s in q splits m where is defined in section example consider the sft rep in figure b we first extend rep so that it has the final state q and we assume that all valid inputs end with we write h for h we write for xx and we write for we also add a fourth state q that corresponds to an error state in practice this state may often be omitted but we include it here for clarity let def f def lx then else x and let g def x lx then x else x the extended sft is depicted in figure let a dd and b so ha holds and lb thus also b holds take the input f h q h q q q figure sft rep extended with the state q is the final state meaning that it has the trivial q sequence s b a a b a we get that s b a a b a q s q q q q q q q q s m splits m u b a b q u v a b and so is the valid string a b that would be displayed similar to where a b is the pair encoding of the code point fa that is a in the alphabet the prior section formalized in terms of higherorder data parallel primitives if the function on which these primitives operate are not associative they must execute sequentially if the bek code contains registers then in general it is not possible to directly write the resulting with associative generalization of fortunately as we saw in the previous section our compilation algorithm can remove registers in many cases we compile into an associative operation on matrices because matrix multiplication is an associative operation that encodes graph traversals this representation is amenable to data parallelism the main idea is to lift above to its associative counterpart scan by representing both states and symbols as matrices so that we can talk about associativity to begin with we build on known techniques from graph traversals with matrix multiplication a convenient way to view is as a graph where nodes in the graph are states and there exists an edge from state i to state j on symbol s if i s j a graph is simple to represent as an matrix the set of allowed transitions for each symbol s in our input alphabet can be described by ms a n × n matrix where n is the number of states such that if state i transitions to state j on symbol s and otherwise in other words an matrix is a symbolic representation of how a symbol from the input alphabet transitions every state in a in order to deal with a potentially infinite alphabet we first divide the input alphabet into a finite set of equivalence classes such that the state transitions are invariant under thus we end up with one matrix mc per equivalence class c we write a for the equivalence class containing the symbol a but how do we actually compute the equivalence relation let all the guards of the be m the equivalence relation can be effectively obtained by constructing all the satisfiable boolean combinations over for this we use the algorithm from see example consider the sft rep in figure rep uses four guards the minterms are h because they are all pairwise disjoint and their union equals the sfa corresponding to rep looks exactly the same as rep but with output functions omitted since there are three equivalence classes say a h b and c we have three matrices ma mb and mc that describe how every state in the sfa transitions when reading symbols a a b b and c c respectively ma mb mc given a and b as in example we have a a and b b given this formulation we use matrix multiplication · as a mechanism for graph traversal assume the identity matrix i encodes the initial state of the sfa then matrix that encodes the state of the sfa after reading the first symbol a in an input sequence s is i · ma further the matrix that encodes the state of the sfa after reading the second symbol b of s is i · ma · mb etc from to matrices to transform a to operations on vectors and matrices we define the following two functions and project generates the matrix ma for each symbol a project extracts from matrix the state of the underlying sfa where is obtained after reading the input sequence w starting from state q v · · vf where v is an row vector v and vf is an column vector n so v · extracts the first row say x of where x has exactly one element j that is while all the other elements are because the sfa is deterministic where j is the state reached from q after reading w thus x · vf equals that state j given this formulation we implement an associative version of the transition function that uses symbols instead of actual symbols thus instead of using the actual alphabet the uses the alphabet ma a and the input sequence is mapped to the alphabet through the initial of the input sequence s m ma def m · ma where m is a matrix that encodes the state of the sfa and ma is the symbol a thus the function is associative by associativity of matrix multiplication and enables us to implement a data parallel version of as s def let s s in let q scan s in let m q s in q splits m an important point to note is that must be applied to the original sequence s because the output functions of the rules of the sft depend on the actual input while both and are lifted to work directly on the equivalence classes an efficient matrix representation while matrix multiplication is associative it unfortunately has a high overhead even an optimized implementation requires a significant amount of computation and multiplication runs in om where m is the number of states in a finite state automaton and requires m memory to reduce this overhead such that it is linear in the number of states both time and space we exploit the fact that all of our matrices are square binary matrices with exactly one in each row and elsewhere we follow recent work and represent this type of matrix as an array where the value of the array at index i from is equal to the index of the column that contains a for row i this is possible because each row contains exactly one in other words the matrix is encoded as a array indexed by states for example the matrices ma and mb from the prior section represented as arrays are and respectively with this representation matrix multiplication of ma with mb with replacement the elements of mb according to ma ma · mb to implement this efficient form of matrix multiplication is simple we the elements of one array by the elements of another v o i d m u l t i p l y char char char k f o r i n t i i k i i i because two matrices of this form produces another matrix of this form we always represent matrices as linear arrays indexed by state which requires only m memory locations and a running time of om translating to and to summarize we produce the following pipeline first a programmer writes string manipulating functions in bek next we compile from bek into an st and then compile the st into a finally we compile from the to c functions which encode and these functions can then be applied as part of our computation as an integrated part of the pipeline we also need a constraint solver eg an smt solver to construct the finite equivalence relation and to construct a classifier that membership of actual inputs in the equivalence classes example consider again the sft in figure recall the matrices ma mb and mc from example let s be as in example so s s mb ma ma mb ma mc and scan s i mb mb · ma mb · ma · ma q q q q q q the rest of the output computation is the same as illustrated in example the actual code generation to c is discussed below the code template for the generated c is shown in figure the field corresponds to the field corresponds to lifted to symbols and the field output corresponds to the semantics of is the implementation of the implementation of uses predicates that have been generated by z and then mapped to c expressions to decide which symbol a concrete character maps to the symbols are unique identifiers for the equivalence classes of as discussed above evaluation this section demonstrates the of our algorithms by their correctness and performance section explains the of the evaluation experiment section demonstrates that our generated programs produce consistent outputs compared to those available in existing system libraries section provides a performance comparison of our generated programs with existing library functions in the sequential case that our generated programs are comparable in performance finally section demonstrates on a variety of realworld string transformation programs we use three and pairs in the following experiments and and and finally and each pair performs the logical inverse of the other ie the output of an is the input to the corresponding we also use sanitizers from the library in our sequential comparison all system that we use are listed in figure there are several variations of some of them and they routine library figure used for comparison all are from net framework differ for example in is different than both the one in and the one in in particular the latter two do not encode control characters or the replacement character while the former does however the latter two encode all characters such as while the former does not encode all of them in total the latter two encode characters out of all of the extended characters while the former encodes only since we have no in selecting one before the other we compare against all of them in our experiments the concrete input to each individual experiment is the intermediate representation of the bek program under consideration it is an st as an instance of the st python class in figure for example the bek intermediate representation of is shown in figure it corresponds to the st shown in figure it has a single state q a register that is a pair of numbers two transitions r r and three finalizers f f f the initial register value is the pair notice that the function e is defined as a z axiom such axioms are either or used to define corresponding methods during code generation the python function in figure is the entry point that generates the final c code first it invokes explore as defined in figure to construct the equivalent modulo sft it then the transitions of the sft by introducing and constructs a deterministic in the case of whose input is assumed to be a valid string the resulting is composed with the sft rep as shown in figure b to lift the input strings to arbitrary sequences of characters as opposed to valid strings only recall the discussion at the end py from s t c s import def q c lambda c ord c register datatype register r e g i s t e r d e c l a r e pair fst snd register register create p r e g i s t e r p a i r f r e g i s t e r f s t s r e g i s t e r snd e d e f lambda x i f x x i f x x i f x x i f x c c e function encode v const v axiom forall v e v v patterns e v x var input character variable y var register r e g i s t e r variable transitions r q and x f y i f f y e x e s y x p f y i f f y q r q and x f y e s y x e p q finalizers f q and f y f y f q fy c c f q fy c s t st q p r r f f f x y axiom return st figure intermediate representation of section the generated c is for the subsequent parallelization step consistency to demonstrate that our synthesized are correct we checked the consistency of the output against independent implementations with the same functionality we generate a set of mb strings and evaluate both the independent output and the bek generated code on each input the strings are chosen randomly we used implementations listed in figure for comparison in each case we implemented a corresponding equivalent bek program and automatically generated the code as explained above for each individual input we compared that the output of the bek generated program is equal to the output returned by the corresponding system we found no the system listed in figure from net core libraries and the library sequential bek the generic code template for the generated sequential c code for a given bek is shown in figure it the same interface of the that is used by the parallel implementation the method implements the sequential routine concrete characters x are mapped to a finite set of symbols through each symbol identifies the equivalence class in which the input behaves similarly recall the discussion from section the maximal is k the initial state is given a state q and a symbol s is the next state output is computed from a given state q and symbol s by invoking xm where x xm is the subsequence of m previous characters m note that m k we have not optimized for the case when the input size experiments public static class public const int public const int public const int k public static int public static int p u b l i c s t a t i c n t i n t o u t p u t public s t a t i c int int x public s t a t i c string apply string s int l s length s t r i n g b u i l d e r sb new s t r i n g b u i l d e r var xs new i n t k int state for int i i l i var x s i var symbol x int n output s t a t e symbol length if n var m s t a t e symbol for int j j m j xs j s i m j for int j j n j sb append char output s t a t e symbol j xs s t a t e s t a t e symbol var m end s t a t e for int j j m end j xs j s l m end j var n end output s t a t e length for int j j n end j sb append char output s t a t e j xs return sb figure code template for generated c is fixed as with but iterate one character at a time over the input for each of the string to string in figure the top rows we compared the running time with the corresponding bek generated over randomly generated strings over extended to get significant results we ran each experiment times and report the mean m and the standard error e of the running time as for we use a different version of bek in the case of to match the semantics while we use another bek for the other two libraries for we used the same bek in all three instances as input to the we used the output from the corresponding ie from the random inputs we generate inputs to the using the corresponding inputs for in are generated with in inputs for in are generated with in etc the html in bek supports up to encodings which is why we restricted this experiment to extended we see no reason why supporting longer encodings would affect the sequential running time in any significant manner the experiments were carried out on a x with intel i processor having gb of ram and running bit windows the results are shown in figure the sequential performance of our generated are on par with existing codes our code is sometimes faster and sometimes slower than routine library ± ± ± ± ± ± ± ± ± sec ± ± ± ± ± ± ± ± ± t figure sequential comparison over strings these standard libraries consider bek is significantly faster than the as this has many corner cases which makes it difficult to and thus points to the benefits of an automated compiler however consider where bek is almost x slower this is because all encodings have the form xy and use the loop over function calls in output in figure to append and four s to sb one at a time we could this overhead through simple optimizations ie inlining function calls instead of indirectly calling them through a table however because this paper is about extracting data parallelism from bek codes with registers we left this simple optimization for future work the producing inputs for in the experiment encodes less data than in the other two experiments as was explained above which explains the bek time difference of almost second in those experiments to summarize the geometric mean of all speedup experiments is and at the interval ranges from to so our approach is neither faster nor slower than these data parallel bek in this section we demonstrate performance improvements over sequential by multiple threads on hardware it is worth noting our approach is not limited to multiple as it is data parallel and thus it can target many forms of data parallel hardware eg or clusters platform we all experiments on an intel e with gb of ram and logical processors with physical inputs for both the html and pair we encode and then a gb subset of html while for the base pair we encode and then a mb sql server executable we measured the time it takes to execute a bek program after reading the input from disk many of our performance numbers are faster than a disk and thus we did not want our experiments to be io bound to compute numbers we measure both bytes read and bytes written as both numbers are required to understand a bek programs performance to get significant results we ran each experiment times and reported the mean and interval of the mean our bek programs exploit parallel hardware and are fast as shown in figure with logical threads our and are able to process data at of anywhere from to in contrast the serial are anywhere from to secondly even with small input data ie base only encodes mb we still see significant this implies that the cost to threads threads threads threads threads threads encode threads threads threads threads threads threads a html encode threads threads threads threads threads threads b base encode c figure of various bek shown in on the y axis as function of threads create and threads does not the computation our singlethreaded implementation is slower than the this result is our implementation requires each thread do two passes over the input and with a our implementation does twice as much work as the sequential a real user of our system would never run with a single thread speedup our bek programs provide nearly linear for up to physical and after that up through figure details the speedup of x processors over a single processor with threads our implementation is just of x speedup across the various and our approach at physical threads because the of reading data from shared caches and ram becomes a because our approach is data parallel we could this by using more physical machines such that each machine more effectively both caches and ram to summarize these improvements and across a wide range of bek programs are significant and enable data parallel processing of large amounts of data encode speedup over thread number of threads a html encode speedup over thread number of threads b base encode speedup over thread number of threads c figure speedup of various bek relative to a sequential as a function of threads related work symbolic finite transducers sfts and bek were originally introduced in with a focus on security analysis of sanitizers the formal foundations and the theoretical analysis of the underlying sft algorithms in particular an algorithm for deciding equivalence of singlevalued sfts modulo a decidable background theory is studied in where symbolic transducers sts are also introduced as an extension of sfts with registers but exploration of sts and code generation are not studied in in contrast the focus of this paper and its motivation is efficient transformation from sts to sfts and with the particular application of code generation that supports efficient parallel execution another recent extension of sfts extended sfts is sfts with lookahead where the primary motivation is to allow lookahead without introducing registers unlike sfts are not closed under composition the idea was originally exploited in where it is used as a heuristic for lifting to sfts but it is not integrated with exploration a model similar to is are introduced in and use instead of lookahead and unlike step one symbol at a time our model of can be seen as a special class of a key property that we use here is of the predicates which is needed for a to be into a the general case of deciding if a predicate is monadic is undecidable which follows from proposition b in recent years there has been considerable interest in automata over infinite languages finite words over an infinite alphabet are often called data words in the literature other related automata models are pebble automata and data automata several of logics with respect to different models of data word automata are studied in this line of work focuses on fundamental questions about decidability complexity and expressiveness on classes of automata on one hand and fragments of logic on the other hand a different line of work on automata with infinite alphabets introduces lattice automata that are finite state automata whose transitions are labeled by elements of an atomic lattice with motivation coming from verification of symbolic communicating machines streaming transducers is another recent symbolic extension of finite transducers we do not know of prior work that has investigated the use of symbolic extensions of transducers for code generation in our implementation we use the smt solver z for incrementally solving label constraints that arise during the exploration algorithm similar applications of smt techniques have been introduced in the context of symbolic execution of programs by using path conditions to represent under and over approximations of reachable states the distinguishing feature of our exploration algorithm is that it computes a transformation that is equivalent to the original st with respect to the semantics which is important for correct code generation finite state transducers have been used for dynamic and static analysis to validate sanitization functions in web applications in other types of security analyses use string analysis show how multiple automata can be composed to model looping code our work is complementary to previous efforts in using smt solvers to solve problems related to list transformations and extend the solver to handle equations over strings and equations with multiple variables we are not aware of previous work the use of finite state transducers for efficient code generation one explanation for this is that classical finite state transducers are not directly suited for this purpose because sfts can be exponentially more with respect to the alphabet size parallel algorithms for finite state machines to the one presented in this work have been known for a long time like this paper and fischer build a parallel implementation by finite state machine computation as matrix multiplication their approach targets applications with small finite state machines and thus they ignore the resulting in the number of states overhead and steele describe an improved algorithm based on parallel prefix sum which reduces this overhead to linear in the number of states to the best of our knowledge none of these approaches allow infinite alphabets neither were implemented on real hardware nor are they used with a larger framework for this paper builds on these theoretical insights into a larger compilation framework which lets programmers use an expressive language to write and and then evaluates those programs on large scale parallel machines finally stream processing is a programming model which programs by independent filters that communicate over data channels programmers need not think about parallelism as it is implicit in the programming model a streaming program is the successive composition of independent filters and the runtime maps these independent computations to hardware parallelism unlike the programming model in this paper streaming based programming models are not nor do they break data dependencies to expose data parallelism like we do in this work in particular streaming languages can only run as fast as hardware can expose a stream thus it is not clear how they can hide io from reading large files from multiple conclusions this paper demonstrates how to compile an expressive domainspecific language bek to produce consistent and fast and sanitizers we use symbolic transducers as an intermediate formalism and then introduce a novel algorithm which performs a symbolic partial exploration of these transducers to obtain simplified versions of the original bek program we then show how to compile the resulting transducers to hardware our compilation results indicate significant runtime improvements our compilation are up to x faster compared to a sequential implementation when run on a node references r and p streaming transducers for algorithmic verification of programs in proceedings of the th annual acm sigplansigact symposium on principles of programming languages popl acm d m v n e c and g composing static and dynamic analysis to validate sanitization in web applications in ieee security and privacy c and c satisfiability modulo theories in e clarke t henzinger and h editors of model checking springer to appear d a and c regular expressions considered in filters in proceedings of the th international conference on world wide web acm m c and g automata vs logics on data words in proceedings of the th international annual conference on computer science logic volume of lncs pages ­ springer m a t l and c david logic on words with data in proceedings of the st annual ieee symposium on logic in computer science lics pages ­ ieee m and d symbolic learning of inputoutput specifications in proceedings of the th annual acm sigplansigact symposium on principles of programming languages popl pages ­ acm l and m static analysis of string and in th international conference on verification model checking and abstract interpretation volume of lncs pages ­ springer l and m minimization of symbolic automata in proceedings of the st acm sigplansigact symposium on principles of programming languages popl pages ­ acm l de and n z an efficient smt solver in c and j editors tools and algorithms for the construction and analysis of systems volume of lncs springer l de and n satisfiability modulo theories introduction and applications acm ­ t l and b lattice automata a representation for languages on infinite alphabets and some applications to verification in sas volume of lncs pages ­ p compositional dynamic test generation in proceedings of the th annual acm sigplansigact symposium on principles of programming languages popl pages ­ w d and g l steele data parallel algorithms in acm volume pages ­ dec p b d p and m fast and precise sanitizer analysis with bek in usenix security august j e hopcroft and j d ullman introduction to automata theory languages and computation m and n automata in st annual ieee symposium on foundations of computer science volume of pages ­ ieee a v p j p and m d a solver for string constraints in international symposium on software testing and analysis r e and m j fischer parallel prefix computation journal of the acm ­ l variable independence for firstorder definable constraints acm transactions on computational logic ­ d and e v universal via filters in black site library microsoft corporation bek guide microsoft research y static approximation of dynamically generated web pages in pages ­ t m and w finitestate machines in proceedings of the th international conference on support for programming languages and operating systems pages ­ new york acm f t and v finite state machines for strings over infinite alphabets acm trans cl ­ filter p d s s f and d a symbolic execution framework for javascript in ieee security and privacy p d and b preventing script injection attacks in web applications with automatic sanitization technical report microsoft research august l automata and logics for words and trees over an infinite alphabet in z editor annual conference on logic in computer science csl volume of lncs pages ­ w m and s p a language for streaming applications in proceedings of the th international conference on compiler construction volume of lncs pages ­ springer m p b d and n symbolic finite state transducers algorithms and applications in proceedings of the th annual acm sigplansigact symposium on principles of programming languages popl acm m n l and s monadic decomposition in international conference on computer aided verification volume of lncs pages ­ springer p wadler deforestation transforming programs to eliminate trees in proceedings of the second european symposium on programming pages ­ g d a d h and z su dynamic test input generation for web applications in international symposium on software testing and analysis f t and o h relational string verification using automata in conference on implementation and application of automata pages ­ d q j li r and s a lightweight streaming layer for execution comput ­ may 