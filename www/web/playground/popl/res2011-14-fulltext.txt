calling context abstraction with shapes inria university of abstract interprocedural program analysis is often performed by computing procedure summaries while possible computing adequate summaries is difficult particularly in the presence of recursive procedures in this paper we propose a complementary framework for interprocedural analysis based on a direct abstraction of the calling context specifically our approach exploits the inductive structure of a calling context by treating it directly as a stack of activation records we then build an abstraction based on separation logic with inductive definitions a key element of this abstract domain is the use of parameters to refine the meaning of such call stack summaries and thus express relations across activation records and with the heap in essence we define an abstract analysis framework for recursive programs that permits a per call site abstraction of the call like how shape enable a per program point abstraction of the heap categories and subject descriptors d software engineering verification f logics and meanings of programs specifying and verifying and reasoning about programs f logics and meanings of programs semantics of programming analysis general terms languages verification keywords interprocedural analysis calling context shape analysis inductive definitions separation logic symbolic abstract domain introduction it seems there are few things if any more fundamental in programming than procedural abstraction hence without interprocedural analysis is simply something that static program need to do well yet precise interprocedural static analysis in presence of recursion is need to simultaneously abstract unbounded executions unbounded calling context and unbounded heap structures speaking there are two main approaches to interprocedural analysis with different and the first approach is to compute procedure summaries eg abstraction shared with and paris permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ austin texas usa copyright c acm these summaries are then used to interpret function calls ie derivatives of the functional approach this approach is common as modularity is important if not a for scalability unfortunately computing effective summaries is not easy for all families of properties intuitively it is more complex to abstract relations between pairs of states than to abstract sets of states the former is the essence of what needs to be done to compute procedure summaries while the latter is what is more typical in program analysis the second approach is to perform whole program analysis that at least conceptually completely ignores procedural abstraction by inlining function calls therefore the analysis only needs to abstract sets of states instead of relations on pairs of states while this kind of analysis yields without the of deriving procedure summaries it is clear that the exponential makes scaling significantly more difficult this then negative on the choice in precision of the state abstraction certainly these approaches are not entirely disjoint and overlap to some extent however in both situations the typical result is a rather abstraction of calling contexts in the modular analysis situation procedure summaries capture precisely what is by the function in question but assume the context to be arbitrary for whole program analysis the values of in the call stack above the current call are typically completely abstract calling context abstraction makes it difficult to for example recursive procedures where there are critical relations between successive activation records in this paper we propose abstracting calling contexts precisely by directly modeling the call stack of activation records that is we explicitly push the call stack into the state on which we abstract to do so we exploit the fact that the call stack has a regular inductive structure so that shape analysis techniques apply under the we use separation logic formulas with inductive definitions in order to elaborate precise and concise stack descriptions we formalize our call stack abstraction inside the shape analysis framework as we this abstract domain which is parametrized by inductive definitions while in practice there has been prior work on directly abstracting the call stack in the framework this approach requires careful choice of a set of predicates for the modeling of stack summaries instead the natural inductive structure of the call stack and a framework built around inductive definitions we to lower the configuration effort in particular we show that the inductive definitions for the summarization of the call stack can be derived automatically overall our motivation is to define global program analyses for programs with recursive functions that make use of a precise characterization of the calling context including the status of the pending call returns while we apply a shape domain to the abstraction of the call stack our focus is not shape analysis certainly heap shapes continue to fit naturally into the framework but there is void main dll l l is a list maybe not doublylinked l null dll c dll p dll ret if c null p c if ret else ret c else ret null return ret void n if null if null a the recursive function fix main l p fix c ret p fix c ret p fix c ret b after two recursive calls to fix and just about to make another recursive call at main l p fix c ret p fix c ret p fix c ret c before return from the second recursive call to fix at figure an recursive program shown with diagrams both the call stack and the heap at two points in its execution independent interest for numerical domains in particular the procedure summary approach has not been adapted to large classes of numerical domains so the technique proposed in this paper takes steps towards a or product extension of base domains to precise interprocedural analysis if heap shapes are of interest we assume our abstract domain has been instantiated with the appropriate inductive definitions describing them eg they come from the user in the form of an inductive checker corresponding to structural consistency checking code that is while we automatically derive a inductive definition to summarize call stacks we do not try to infer inductive definitions for recursive heap structures from a technical point of view we exploit the fact that the call stack has a fixed recursive contrast to userdefined recursive structures in the heap which do not have a set shape from a perspective the stack of records is a lowlevel implementation mechanism for procedural abstraction and thus such inductive definitions would be problematic to expect from the contrast to heap shapes which are finally we that we do not necessarily a precise call stack abstraction in all situations rather our technique a gap in the analysis of programs with recursive procedures in this paper we make the following contributions · we define an abstract domain that models the call stack directly in an exact manner section and with summarization section the novel aspect of our approach is to the inductive structure of the call stack by using a parametric shape domain based on separation logic and inductive definitions · we give an algorithm for automatically deriving inductive cases for call stack summarization section that is the inductive definition stack used to summarize the call stack is defined on the in a manner · we describe an analysis for programs with recursive procedures using this call stack abstraction section · we provide evidence through a case study that our call stack abstraction can be used to overcome precision issues in the modular approach section that is a less precise base domain with the call stack abstraction is sufficient for certain examples where a more precise one is needed with the modular approach overview in this section we illustrate the main challenges in designing a precise abstraction of the calling context by following an example execution of the recursive function fix shown in figure a then through this discussion we our abstraction technique consider the recursive function fix shown in figure a this function takes as input a pointer c to a dll structure a dll structure has three fields next prev and data used to represent a doublylinked list of integers the function fix does two things it takes as input a list ie the prev links are unused or potentially invalid and sets the prev field of each node to create a valid doublylinked list and it implements a operation where all nodes whose data field satisfies the check function are removed it implements this functionality by a recursive using the c pointer on each call the p pointer points to the previous node where should be set in particular during the downward sequence of recursive calls it updates to set up the doublylinked list invariant then on the upward sequence of returns it removes all nodes whose data field satisfies check to simplify our presentation function fix also uses a local variable ret so that there is only one return site it is certainly possible to perform the along the downward path of calls instead of upward path of returns which in fact would likely make analysis easier however in this case the has chosen to do the removal along the upward sequence perhaps because she wants to call the library function remove the remove function expects a doublylinked list node but the doublylinked list invariant is not established until the downward sequence is complete while this example is it in a small fragment many of the key challenges in analyzing recursive imperative programs state changes on both the downward call path and upward return path incomplete or temporary of data structure invariants along the recursive paths and interactions with heap state conceptually belonging to callers to illustrate the analysis challenges let us consider the concrete program state at two points in an example execution figure b shows the concrete state right after two recursive calls to fix ie main has called fix which has called itself twice and is at the program point marked with to fix a convention we say that the first call to fix from main is not recursive figure c the concrete state just before the return of this same call and where the current node pointed to by c has just been removed shown out in other words check evaluated to true and the state is at the program point marked with we can also see that between these two states there have been two for the last two nodes in the list where their prev fields have been set appropriately but neither node was removed in addition to the list allocated in the heap shown in the right part of figures b and c we show the call stack in the left part in our picture the call stack consists of sequence of activation records where each field is a local variable eg p c and ret for activation records of fix our approach to interprocedural analysis is essentially to abstract the notion of state depicted in figures b and c traditional shape analysis focuses on precise summarization of the heap that is the right part in the concrete state diagrams while the call stack is or abstracted in this paper we define a precise abstraction of the call left part in the diagrams to build up to our technique let us consider an intuitive abstraction of the state shown in figure b with only heap summarization prev prev next next next main · l · c · c · c · p · p here the nodes represent heap addresses the edges denote fields of a dll node ie the edges labeled with next and prev and the edge labeled represents a list of dll nodes of length the next and prev edges correspond to those fields of the first three nodes of the input list l the data fields have been as well as the prev field of the first node the call stack is in a sense by fully variables with a call string essentially converting local variables into for instance the l variable of activation record c of the activation record for the first call to fix and p of the activation record for the second call to fix all point to the first node our first observation is that this kind of exact modeling of the call stack in the separation abstraction shown above depicted as a separating shape graph if we make the following simple extensions introduce a node for the base address of each activation record view local variables as fields of an activation record and link the activation records in a call stack together with a conceptual frame pointer field note that this representation does abstract lowlevel details much like the diagram in figure b eg we do not capture of activation records or lowlevel fields like the return address of each activation this abstraction with heap summaries but an exact stack is formalized in section at this point we have an abstraction suitable for interprocedural analysis on nonrecursive programs but capable of precise reasoning with recursive data structures however for precise static analysis in the presence of recursive procedures as we propose it is clear that we need to summarize the call stack to prevent our representation from growing unbounded in particular we need to abstract the concrete states both along the downward sequence of recursive calls and the upward sequence of returns in our example during the downward recursive call sequence the structure of the activation records is actually quite regular the local variable p contains the same pointer value as in each activation record even in the initial call where it is null and the next and prev fields of the already visited nodes ie directly pointed to by the c variables in the call stack define a valid doublylinked list segment it is not entirely a doublylinked list as in the most recent activation record is not null while the upward return sequence mostly preserves this pattern there are in particular in this case where a node is removed from the list the next field of the previous element has been updated in other words the next field of the c of the second most recent activation record has been updated ie · c is updated when is still active therefore a suitable call stack abstraction must be able to precisely capture the following properties we must be able to track the fragments of the structure where the prev fields have been fixed this property is needed so that we know that we obtain the doublylinked list in the end we also need this property to validate the call to remove eg the prev field of the node to be removed is not dangling we must be able to track relations between the fields of each activation record and heap structures in particular we need to propagate invariants during the upward return sequence these properties can be expressed using an inductive statement since the structure of the call stack is itself inductive successive activation records must be disjoint regions of memory separate from each other and the heap thus our second key observation is that a shape domain built on separation logic formulas with inductive definitions such as the one described in our prior work seems not only for abstracting recursive heap structures precisely but also for abstracting call stacks in other words a novel aspect of our approach is that we propose to use separation logic formulas to describe not only heap data structures but also the concrete call stack of activation records observe that the concrete states shown in figures b and c are lower level than descriptions in many language semantics and most analyses while a shape domain based on inductive definitions seems adequate for abstracting the call stack it is informally speaking necessary as well recall that in our example the upward sequence of returns mostly preserves the pattern along the downward sequence of calls but not entirely this observation indicates that the call stack abstraction must be in the sense that there is a need for variation for example along the downward call sequence versus the upward return sequence a similar kind of is obtained in shape analysis for heap abstraction with we observe that the classical summarization and operations in shape analysis is exactly what we need at function call and function return to obtain this · at a function call site the call stack grows by one activation record we summarize ie fold the rest of call stack the new active activation record in shape analysis folding is done through either widening or operations folding allows us to continue the analysis with a bounded and precise description of the call stack moreover the ability to create partial summaries is critical for addressing challenge above · at a function return site the compact description of the activation records ie the call stack the most recent activation record should be to expose the activation record of the caller in shape analysis corresponds to unfolding or focus operations is essential for addressing challenge above therefore the fundamental concepts in shape analysis provide the essential for the precise call stack abstraction that we in section we describe our combined state abstraction that makes use of an inductive predicate stack to precisely summarize recursive call stacks the stack predicate is more complex than inductive predicates describing typical recursive data structures in general shape domains require some level of to describe the structures or summaries of interest for example uses instrumentation predicates while separation analyzes rely on inductive definitions either supplied by the analysis designer or the analysis user while the user to provide descriptions of userdefined structures seems quite natural the user to describe the call stack does not the call stack is not even a structure to which the user has direct access in any highlevel language however at the same time the inductive ie a stack structure is fixed here in section we describe a algorithm to automatically derive definitions of the stack predicate because the is fixed the challenge is in inferring the node type of activation records this task is similar in spirit to berdine et al in inferring the node type for a polymorphic doublylinked list predicate exact call stack abstraction before we describe our approach for call contexts see section we first formalize an exact abstraction of call stacks based on separation logic formulas concrete machine states to begin we describe the concrete machine states on which we abstract see figure a a concrete state describes the status of a program at some point of its execution an environment describes the set of program variables along with their machine addresses defined at a point in the execution of a program it includes the global variables and the variables defined in each activation record in the call stack the environment is given by the grammar in figure a an environment a stack of pairs made of a function name and a local variable to address binding before ending with a global variable binding we write x for a generic variable drawn from x and use l and g to refer to local and global variable names respectively for any environment we define a few functions to simplify our presentation let denote the call string defined by ie pn · · · pp similarly let vars be the set of variables of environment finally let vars v be the function that gives the address of any variable in the environment these functions can be defined by induction over the environment a program state s is a tuple made of an environment and a memory state a memory state is a finite mapping from addresses to values where the set of addresses is included in the set of values addresses that do not correspond to the address of any variable are heap locations whereas addresses that correspond to the address of a variable defined in an activation record are stack locations abstraction the core of the abstraction is a spatial formula in separation logic describing the shape of memory spatial formulas can be seen equivalently as graphs nodes which are given symbolic names eg abstract sets of values and edges describe memory cells subject to certain constraints such as cell of address contains value ie a graph g is the separating con of the memory regions represented by each of its s program states s e environments x global variables p x new activation record m v memories x · x x a variable to address bindings x l g x program variables p p procedure names a v values including addresses a the concrete state g pointsto edge pointsto edge of a field · c inductive edge · c · c segment edge emp g g graphs n d num numerical constraints in a base domain a g n analysis state ie abstract program state ¯ g v symbolic names ie nodes f g fp l f field names ie offsets b the abstract state figure defining the concrete machine and abstract analysis states edges as shown in figure b the empty graph is written emp a pointsto edge describes a memory cell with abstract address and contains the value abstracted by if we the lefthand side of pointsto with a field as in · f we represent a memory cell whose address is plus the offset of field f and whose content is we assume offsets are symbolic fields and thus use a relatively highlevel model a memory model could be mixed in without much difficulty by following our prior work an inductive edge · c is an instance of inductive predicate c with a distinguished traversal parameter while a segment edge · c · c is a partial tion of an inductive predicate c these edges summarize some set of memory cells as described by an inductive predicate allowing us to represent a potentially unbounded memory section discusses these notions in greater depth concrete program states are then abstracted by an analysis state a consisting of a graph g and a numerical constraint n a numerical constraint describes relations symbolic names and is drawn from some base domain that is the abstract domain described is parametrized by a standard sort of numerical domain if we instantiate this abstraction with inductive definitions describing recursive heap data structures supplied by the user we essentially obtain the shape domains in our prior work to abstract the call stack in a concrete state s we observe that the environment plays a significant role here at the abstract level we build it directly into the graph as follows · the address of each global is represented by a node thus the set of global variable names are included in the set of symbolic names v · we introduce a node to represent the base address of each activation record for the sake of clarity we distinguish nodes representing activation record addresses by using a bar over the symbolic names as in ¯ and by them with a dotted in diagrams we also annotate them with the function to which they correspond ie indicating the type of the activation record · each local variable can be viewed as a field of its activation record the set of field names f therefore includes local vari able names this representation is key in allowing to be summarized as part of the call stack see section · we make explicit a frame pointer fp which is simply a field of all activation records like in the physical memory at run time the frame pointer fp points to the previous activation record in the call stack to distinguish them clearly in the diagrams frame pointer edges are drawn as dotted lines and usually the fp label is omitted thus with the above observations we encode the structure of the call stack in our shape domain in a faithful manner essentially and without any significant modifications as an example an abstraction of the concrete state from fig stack heap b is shown the ¯ nodes represent the base address of the activation records and main ¯ l their outgoing pointsto edges fp p null prev correspond to the call stack observe that the edges fix ¯ c between the ¯ nodes and the fp nodes are the stack cells for p next prev local variables the fix ¯ c fp links connect the ¯ nodes to capture the actual stack struc fp p next prev ture the heap is represented by fix ¯ the edges in the rightmost col c the vertical edges are the next next and prev fields for the first three nodes and · summarizes an arbitrary list note that this portion of the graph is the only part of the mem state that is captured by traditional shape analyses we have a few edges from this figure specifically the ret variable edges in the stack and the data fields in the heap concretization like for concrete states we define functions that compute the call string and the set of variables it defines given a graph g these functions follow the chain of frame pointers to compute the desired result we also define a function g v × f that maps each variable to the pointsto edge representing its cell ie an abstract mapping to define the of graph graph domain a graph we need a mapping be numerical domain symbolic d d d graph × num shape domain names and con values such mappings v v are called valuations and allow us to abstract irrelevant details like concrete physical addresses we first summarize the types of the the names of the various domains are given in the graph num d pm × v v pv v pe × m the concretization of a graph g yields a set of pairs consisting of a concrete memory and a valuation while a numerical domain element n should give a set of valuations together the concretization of the combined domain produces a set of pairs of a concrete environment and a concrete memory to a graph we take the concretization of each edge def · v v g def and we write for the separating conjunction of concrete memories ie the union of two memory maps with disjoint domains and · for an empty concrete memory the frame pointer fp fields are model fields so they have no concrete correspondence but otherwise the concretization of a pointsto edge is a single memory cell written a a v · fp ¯ def · v · f def f v def where f gives the base address plus the offset of field f we defining the concretization of summary edges ie inductive and segment edges to section overall the concretization of an analysis state a are the pairs given by the graph and consistent with the numerical constraint g n iff for some and vars and and and gx for all x vars valuations connect the various components capturing relations across disjoint memory regions and with the numerical constraint inductive summarization and as to in section we summarize a potentially unbounded memory using edges built on inductive definitions at a highlevel an inductive definition consists of a set of unfolding rules or cases that specify how a memory region can be recognized through a recursive traversal as stated earlier our inductive edges come in two forms an inductive edge · c describes a memory region that satisfies inductive definition c from and a segment edge · c · c describes an incomplete structure in particular a memory region that can be derived by unfolding · c a certain number of times up to a missing · c relations among pointers or numerical values between successive of an inductive edge are captured by definitions with additional parameters for instance the relation between prev and next pointers in a doublylinked list can be captured by the following inductive definition written as a separation logic formula l · def emp l n d l · prev p l · next n l · data d n · l unfolding an inductive definition gives rise to a natural syn tactic unfolding operation unfolding an inductive edge · c or a segment edge · c · c with one in case of cs definition and where all variables are replaced with fresh nodes for inductive edges base cases correspond to a rule with no new inductive edge upon un folding for segment edges the base case is unfolding to the empty segment ie when and c c we write g unfold g for an unfolding step from graph g to g as well as unfold for the closure of unfold because the unfolding operation is so closely to the inductive definition we often present an inductive definition by the that it induces dll unfold dll next unfold prev data dll figure unfolding operation induced by the dll definition for instance in figure we present the doublylinked list definition dll in this style the concretization of graphs containing inductive or segment edges is based on the concretization without them in particular the concretization of a graph g containing is simply the join of the of all the graphs that can be derived from it by successive unfolding g graph g unfold g unfolding and analyzing updates unfolding is the key operation for abstractly interpreting writes to reflect an update e e we traverse the graph to find the pointsto edges ie the memory cells that correspond to the addressing expressions e and e if the pointsto edges of interest already exist in the graph then the update is simply a matter of an edge because a graph is a separating conjunction of edges this modification is a strong destructive update however if the desired edges are not present then we try to them with the unfolding operation unfold unfolding to expose cells in a userdefined heap structure is necessarily heuristic but the distinguished traversal parameter in our inductive predicates ie in · c provide also see our prior work for ways to make unfolding more robust more we describe the abstract interpretation of an update with the following inference rule a statement a a e a · f a e a · f a e e a g ga · f the abstract interpretation judgment a statement a says that in abstract state a evaluating statement statement produces a resulting state a as in a standard structured concrete operational semantics this judgment is defined in terms of an auxiliary judgment a e a · f that evaluates an addressing expression e to a pointsto edge in a which may yield a modified state a as the result of unfolding to reflect the update we write ga for looking up the graph component of a ag g for replacing the graph component of a with g and g · f for updating the edge with source · f in g to point to towards analyzing calls and returns our analysis is based on an abstract tion of the programs interprocedural controlflow graph we a sound analysis which means at each step the analysis ap transfer functions they cannot omit any pos concrete behavior with just the abstraction described in this section we can define an analysis for nonrecursive programs al a potentially computationally expensive one at a function call site in the concrete execution a new activation record is pushed onto the call main ¯ l null stack at the ab fp level we push a new ab p activation record we create a new node representing the base address of the new activation fix ¯ c ret record and we set the content of its fields ie the formal parameters and local variables by assigning formal parameters to the actual arguments and by pointing local variables to fresh nodes for example consider again the code from figure a at the call to fix from main ie null during the analysis we push a new abstract activation record with base address ¯ with fields for parameters c and p and local variable ret as shown in the the ¯ · fp field is set to point to ¯ the base address of the activation record for main while ¯ · c is made to point to as ¯ · l and ¯ · p gets null for the ¯ · ret field it is set to fresh node which indicates it contains an arbitrary value the · inductive edge states that is the head of a list of dll nodes which before the call now if we continue analyzing the body of fix we see that · would be along the path where null ie c null before at a recursive call to fix it is clear that if we continue analyzing in the manner described above we will keep on creating new activation records and never terminate thus in order to ensure the termination of the analysis in the presence of recursive functions we must apply a widening that is capable of the call stack as to earlier the key observation is that the call stack is itself an inductive structure specifically it is a list of activation records where the frame pointer fp fields form the based on this observation we use a special inductive predicate stack to summarize recursive segments of the call stack eg the sequence of fix main this inductive predicate stack is necessarily more complex than usual predicates for recursive heap structures and is described in detail in section furthermore the stack predicate must be because it depends on the programs interprocedural controlflow thus its definition cannot be known before beginning the analysis in section we detail an algorithm for deriving a definition of stack on the during the analysis finally at a function return site the analysis proceeds like in a concrete execution by off the most recent activation for instance in the example above on return from fix to main we drop the node ¯ and its outgoing edges for fp c p and ret just like the of heap cells as an invariant of the analysis we make sure the activation record is always exposed ie never summarized in a stack predicate this invariant ensures that all program variables in scope and are directly accessible as part of the transfer function for return we need to make sure that the activation record of the caller function becomes exposed after the return as now it is the one in the presence of call stack summarization that includes the caller we need to unfold the stack predicate to expose the callers activation the unfold operation with stack as such stack segments always go from to callers that is in the direction of the fp links call stacks inductively as to earlier we summarize call stacks from recursive programs using an inductive predicate stack exploiting their inherent inductive structure the definition of stack is particularly interesting because it depends on the interprocedural control flow of the program being analyzed to build intuition for a definition of stack we first explore a number of examples that illustrate requirements for it we consider analyzing simple recursive functions requiring no relations between successive recursive procedures requiring simultaneous summarization of the stack and heap nested recursion and mutual recursion our algorithm for automatically deriving a stack definition on the during analysis is then described in section recursion without heap relations between con the simple program shown in a that constructs a list of random length using a recursive function f for each call to function f a new uninitialized list node is allocated on the heap before the next recursive call for simplicity in presentation a list node has just one field next void main list x f list f list y if return null else y for linking note that we f the argument to malloc return y treating it as a highlevel tor with types the next point are assigned during the se a list allocation of returns b shows a graph with no summarization main ¯ x that describes the state of the program at the entry of the first recursive call to f ie with the call string while c shows the state at the second re f ¯ y next f ¯ y call ie b after one recursive call the repeated pattern is clear from these diagrams all pending of f have a local variable main ¯ x y that point to a list node whose next field is arbitrary this f ¯ y next pattern suggests the unfolding rule or case for the definition of f ¯ y next stack shown in d inductive edges of stack are y f ¯ labeled with a regular expression to the set of call strings c after two recursive calls to which the rule can be applied here the regular expression on this rule indicates ¯ stack unfold that it can be applied only to a call stack where the activation record corresponds to an f record while the calling con ¯ f ¯ ctx stack y next text ctx may be arbitrary these constraints on the calling context d an unfolding rule can be expressed as an additional parameter to stack so the labels are simply a shorthand in other words the first additional parameter to stack is a set of possible call strings expressed as a main f ¯ ¯ stack stack x f ¯ y expression in the case of rule e summary for entry to f definition the label is a check for that regular expression pattern eg on the lefthand side of the example unfold for an instance of the stack predicate it gives an abstraction of the call string as an example using this rule we can all the possible states at the entry to function f after any number of recursive calls with the graph shown in e the f label indicates that there are zero or more f between ¯ and ¯ intuitively these labels approximate the sequence of frame pointer links and the types of activation records along that sequence recursion with mixed call stack and heap summaries in figure we present a slightly more involved example where an existing heap data structure is traversed recursively function f a recursive of a list ie a list consisting of list nodes before the first call to f the memory state is abstracted by the graph shown in figure a after the first call void main list l make l · list fl void x if x null return else main ¯ l list a before the first call to f main ¯ l f ¯ x list b after the first call to f main ¯ f ¯ f ¯ l x next x list c after one recursive call main ¯ l f ¯ x next f ¯ x next f ¯ x list d after two recursive calls ¯ stack unfold ctx ¯ stack f ¯ x next e an unfolding rule ¯ stack main f ¯ stack l f ¯ x list f summary for the entry point to f ¯ stack main f ¯ stack l f ¯ x next f ¯ x list g nonempty unfolding of the stack segment in f figure the memory states for recursive list traversal to f but before any recursive call we have the graph shown in b in c we show the graph after the first recursive call at the entry point to f while d shows the graph at the same point after two recursive calls just like in the previous example there is a clear pattern consisting of both stack and heap edges for each activation however unlike the previous example there is an important relation between successive activation records through the heap of an activation record aliases x of the subsequent activation eg ¯ · x · next ¯ · x such a relation can be captured with an additional parameter to the stack predicate and thus we get the unfolding rule shown in figure e the key difference between the unfolding rule here and the rule from the previous example is the parameter shown in the figure that says the next field from the value of ¯ · x ie points to an existing node given by parameter using this inductive definition we can summarize the possible states at the entry to function f using a stack segment edge shown in figure f in the graph shown in figure f the stack segment not only summarizes a portion of the call stack but also a fragment of the heap specifically the list segment between and it also maintains the relation between the x pointers to elements in this inductive definition of stack is quite powerful here to get a better sense of this aspect consider unfolding the stack segment in the summary shown in figure f there are two cases · the segment is empty this base case says there are no cells summarized by the segment and the ends are equal that is ¯ ¯ and this state is exactly the one at the entry point after the first call to f ie with call string shown in figure b · the segment is nonempty one step of unfolding yields the graph shown in figure g notice that one step of unfolding the previous activation record with the desired relation between the previous x and current x overall this inductive case summarizes the state after successive recursive calls eg states shown in figures c and d for instance replacing the stack segment in g with the empty segment ie unfold it to empty we get the state after one recursive call c where ¯ ¯ and in both examples thus far in this section we never defined a base case for the stack inductive definition at the same time it is not particularly meaningful to provide one as the first function called in the program is main which must be the activation record for our analysis this absence of a base case for stack is actually never a problem as the stack predicate is always used as a segment edge for any segment the base case is the empty segment nested recursion the program below illustrates a nested recursion main calls function f which calls itself recursively a certain number of times until it calls g which then also calls itself recursively a certain number of times there is no call to f from g void main t x fx void ft x if fx else gx void gt x if gx g ¯ stack stack ¯ x g main f ¯ ¯ stack stack ¯ x f x after a number of recursive calls the layout of the call stack at the entry point to function g can be summarized by the above graph where the stack segments correspond to the sequence of recursive calls in g and to the sequence of recursive calls in f respectively mutual recursion in the program below functions f and g are mutually recursive so the call strings at the entry point to g are of the form main void main t x fx void ft x if gx void gt x if fx as the cycles are of the form gf · · · the call stack of the above program at the entry point to g is summarized using the following rule ¯ stack unfold ctx ¯ stack f ¯ x g ¯ x the cycles can be more complex for example for call stacks where the call strings are of the form gf g main the inductive stack rule for the f g cycle would unfold into a call stack fragment which would contain a summary for the inner f cycle ie another stack segment over the f call string defining stack we can now state precisely the notion of an inductive definition suitable for abstracting the call stack · a stack segment is a segment edge this edge is labeled with with a regular expression denoting a superset of the call strings that it describes · a stack inductive definition is an inductive definition stack such that each case a sequence of one or more activation records according to a call string as stack segments are simply segment edges of the stack definition the concretization of graphs with stack segments follows from the definitions in section notably given the ability to inductive definitions by simple regular expressions the meaning of stack summaries directly from the notion of inductive segments inferring call stack summarization rules in section we illustrated how the call stack corresponding to various forms of recursion is summarized by an inductive stack predicate however we also need to be able to derive a suitable definition for stack to obtain a terminating analysis we require a widening operator capable of the call stack to do so it must fold fragments into stack segments yet before beginning the analysis the definition of stack cannot be known as the interprocedural control flow of the program is still to be explored this circularity means that the definition of stack must be derived on the during the analysis when recursive calls are found in this section we describe such an algorithm for defining a stack predicate on the widening in recursive cycles in this section we consider a recursive function f which directly calls itself the technique we propose also applies to more complex cycles eg mutual recursion in general when a function call is recursive the interprocedural controlflow graph contains two cycles one at the function entry from the recursive call site and one at the function exit to the recursive return site thus to ensure termination of the analysis in the presence of recursion widening is applied at the entry and exit points of a recursive function we first describe at a highlevel the steps that the analysis takes to compute an invariant at such a recursive widening point the key operations are the widening on program states given some stack definition see section and a shape to generate inductive rules of the stack predicate described later in this section intuitively deriving rules for stack comes from finding the difference between successive abstract program states at for example fs entry point after some number of recursive calls specifically the analysis takes the following steps at fs entry point compute a few abstract states by over the recursive call cycle in practice unrolling a few iterations of a cycle is main ¯ l p fix ¯ c ret p fix ¯ c ret null prev data next a the abstract state at iteration a main ¯ l p fix ¯ ret c null prev data next p prev fix ¯ ret c p data next fix ¯ ret c b the abstract state at iteration a ¯ p fix ¯ ret c prev data next c the result of shape ¯ stack unfold ctx ¯ stack p fix ¯ c ret prev data next d an inferred rule for stack figure inferring a stack rule from abstract states computed at the entry point to fix while analyzing the example in figure a often to get to stable behavior suppose we obtain three states a a and a from the first iterations and we wish to from a and a we derive an inductive rule for stack from a and a using the shape algorithm we weaken a into a weaker a using the rule derived in step to perform this weakening step we apply the widening operator over program states to a and a to produce a the net result is that a summarizes both a and a with a stack segment for the difference between them we perform widening iteration over the cycle until convergence to an invariant a the definition of the widening operator over program states guarantees convergence note that the algorithm for inferring new inductive rules for stack in step widening in obtaining quality invariants it does not need to be sound or complete in fact it is possible to complicated examples where discovering a pattern would be arbitrarily difficult instead the goal should be that it is effective at discovering adequate rules in realistic situations creating stack rules by shape at a highlevel we find the difference in the graphs between two successive state a g n and a g n using shape this difference gives the exposed or fragment in a new stack rule in the following suppose a corresponds to call string and a to the first step is to derive the graph part of the new rule to do so we want to the edges that appear in g but not in g in other words we want to partition g into two sets of edges and g such that informally speaking g g and g the above is informal because we must take care of matching symbolic node names which correspond logically to existential variables we illustrate the description of the algorithm by following the example from section ie figure figure a shows the abstract state at the entry point to fix obtained from one tion over the recursive call cycle ie after executing one recursive call figure b shows the abstract state after one more recursive call ie after two recursive calls the graph shown in figure c shows the g computed from the states in a and b in essence shape works by performing a traversal over a node g and naming g to identify relation matching structure ie v × v serves to track the correspondence between the nodes in g and those in g as well as to define the frontier of the traversal to start the process the node naming relation is initialized with root nodes of memory regions that we want to be in in particular we pair the following for the initial nodes representing ad of global variables base addresses of activation records in the context ctx eg ¯ ¯ and ¯ ¯ for ing the example in figure the base address of the activation record eg ¯ ¯ this initialization states that is any portion of memory reachable from the activation records of the context and the tion what remains g is the state difference between g and g that we wish to summarize with a stack segment in the example the only activation record node that does not appear in is the one for the second activation in g ie ¯ in figure b observe that this node is exactly the base address of the activation that we wish to summarize at this point the algorithm is rather straightforward we collect together edges of the same kind whose the source nodes are in the node naming relation whenever two edges are matched the target nodes and any additional checker parameters are added to the matched edges are discarded from g and g and added to up to node renaming for example in figure the edges corresponding to field l of ¯ can be matched and consumed right after initialization then the pair is added to and the prev edges from in both graphs can be consumed next we iterate this match and consume traversal until g is empty in which case g has become g it is possible that g fails to become empty that is we are unable to find a common fragment this algorithm is much like the graph join algorithm in that the result depends on the traversal order matching and certain edge pairs too early may cause the algorithm to fail to produce an empty g when another traversal order would have fortunately in our experience a simple strategy suffices first we match fields from the activation record which are not pointed to by other activation records directly eg from ¯ ¯ then we do the same for the fields from the context eg from ¯ ¯ and ¯ ¯ nodes directly pointed to by the activation being summarized are considered last the graph result of shape g gives the edges for a stack unfolding rule that is the portion of memory that could be summarized by a stack segment of length such a rule does not express all the properties that are needed to describe the call stack precisely in the figure example we need to express aliasing relations between successive cf the difference between the list allocation and the list traversal examples in section these relations are captured by parameters on the stack definition the parameters are given by the nodes at the boundary between the activation and the being summarized in this case nodes and are this boundary and become parameters in the definition of the stack rule as shown in figure d finally any relevant numerical constraints in the base domain is also captured in defining a stack rule once g has been computed we simply take the projection of the numerical invariant n onto the set of symbolic node names in g shape on the graph portion can be seen as a restriction on frame inference here we are looking for an exact match as opposed to an entailment between two configurations in spirit the above algorithm potentially could be applied to derive other kinds of inductive definitions besides stack cf however we make critical use of understanding the inductive structure of a call stack to get good results for example this background knowledge is used in the node naming relation we that having some knowledge on the kind of inductive of interest is key to getting definitions applying call stack summaries in analysis with the mechanism for deriving stack rules during analysis we have all the pieces for analyzing recursive procedures with call stack summarization by following the outline in section in particular sound transfer functions from intraprocedural inductive shape analysis for basic program statements like assignment cf section guard conditions for branching loops and memory carry over in a straightforward manner a slight difference is that instead of a fixed set of variables as in the intraprocedural case we have both global and local variables local variables are fields of activation records in our graph but all program variables in scope are easily accessible as we ensure that the activation is never summarized there are two remaining pieces to our interprocedural analysis first we want to see how widening with derived stack rules applies at the function entry and exit points in recursive call cycles section second the soundness and termination of extensible inductive shape analysis relies on the assumption that all inductive definitions are fixed before the analysis starts in this paper where the definition of stack is extended on the we need to justify soundness and termination in the presence of such inductive rule generation section we conclude this section with a summary of the reasons for termination and soundness for the overall analysis as well as some empirical experience section main ¯ l null p ¯ fix ¯ c stack stack ret fix p ret fix ¯ c list a inferred invariant a prev data next main ¯ l null p ¯ fix ¯ c stack stack ret fix p ret prev fix ¯ c p data next fix ¯ c list ret prev data next b next iteration which the inferred invariant a figure widening at the entry point to fix in figure a widening with call stack summaries after an appropriate inductive rule for stack has been derived see section widening at function entry and exit points in a recursive call cycle is not particularly different than at loop heads that is the join and on graphs and program states essentially carries over we do not these algorithms but we discuss their main features here by following our example introduced in section the join on separating shape graphs is so the only difference between join and is the operator applied to elements of the numerical base domain at a highlevel the join on graphs is actually quite similar to the algorithm described in section they both work by a simultaneous match and consume traversal over two graphs from root nodes using a node naming relation ie roughly speaking the main difference is that join applies weakening to memory regions by the traversal for example it folds fragments consisting of pointsto edges eg · next into an instance of an inductive definition eg · list folding is in essence applying an unfolding rule in reverse following the outline in section at the entry point to fix we first obtain abstract states a and a from figures a and b respectively is applied to them to get the stack rule in figure d with this rule widening on abstract states is applied to a and a to produce the state a shown in figure a which summarizes both a and a beginning at the entry point to fix with a we analyze until the next recursive call and returning to the entry point we get the abstract state a shown main ¯ l null p ¯ fix ¯ c stack stack ret fix p prev fix ¯ c data ret next prev data next dll figure an invariant just before returning from a recursive call to fix in figure b observe that ¯ is the activation record that can be into the stack segment using the figure d rule thus computing aa yields a which that a is an invariant that summarizes the set of all concrete states that can be observed at the entry to function fix after one or more recursive calls the control point after the function exit before the return site of a recursive call is also on a cycle in the interprocedural control flow graph so we perform widening iterations there we perform widening at the point just before the abstract activation record is discarded in figure we show an abstract element concrete states that can be observed just before returning from a recursive call to fix and where this call along the path where c was not null and node c was not removed note that during the sequence of returns from recursive calls the new dll edge appears as upon function return the tail of the structure has prev pointers set correctly so as to define a dll introducing inductive rules on the as noted above a source of complexity in the call stack with the stack predicate is that new inductive rules are gen on the to reason about this aspect we extend our frame work with rule set extension when the analysis starts the set r is empty whenever a new recursive call site is discovered a new rule is added to r therefore we consider r an element of a separate lattice specifically the powerset of the set of rules each invariant is with respect to a set of rules r which determines the instance of the graph domain in use thus our analysis state is actually an r g n tuple in the abstract domain d defined below for ity we annotate with the set of inductive definition of stack as follows rules r allowed for the r and similarly with graph r we also define r g n as we did g n except we now use graph r in place of graph and similarly for the order r on states g n d d r g n g graph r and n num r g n def s s r g n r g n r g n iff r r and g n r g n the above ordering is sound as r r implies that graph r g graph r g all transfer functions are as before except for widening at the head of recursive functions which also adds a new rule most importantly as shown in that has similar a construction this widening if the benchmark list traversal list get nth element list insertion nth element list remove nth element list deletion memory free list append list reverse recursive ms iterative ms table comparing analysis times for recursive and iterative versions of the same operation process of adding rules is itself bounded one possible bound is to allow at most one rule per call site the above construction also suggests applying more complex forms of widening to the set of rules r while preserving sound ness in the ordering r g n r g n defined above we stated that it must the case that r r however we could use a more sophisticated ordering on sets of rules in par if we have two rules r and r where r is weaker than r then we could replace r with r in our set of rules while main soundness in terms of the analysis this observation means that inductive rules for stack may be during the course of the analysis surprisingly we can use this process to improve what can be summarized suppose the analysis a stack rule r to summarize the call stack at the entry of some function f however widening at the next iteration fails ie is due to rule r being too specific we are allowed to weaken r to a rule r that may allow this widening step to succeed this technique is potentially useful when the shape part of the rules is stable but when the numeric contents of cells need to be computed by a nontrivial widening sequence as can be seen in section to guarantee termination of the analysis with this process the rule weakening step must be shown to stop in some way termination soundness and empirical experience to ensure termination the analysis algorithm applies widening to at least one point in each cycle in the set of abstract flow equations in the case of interprocedural analyses the following is one set of such widening points loop heads for intraprocedural loops and at the entry and at the exit of functions when analyzing a recursive call at the end of the analysis each program point is mapped to a finite set of abstract elements as all transfer functions are sound and there is at least one widening point on each cycle in the interprocedural controlflow graph the analysis terminates and is sound soundness if concrete state s can be reached at program point l and if the set of abstract elements computed for point l is rl gl nl then s nil for some i n preliminary empirical experience we have implemented shape and stack rule inference described in section in it the appropriate stack rules for all of the examples given in sections and in each case the stack rule inference time is we also have implemented a prototype analyzer and ran it on a series of that compares the analysis time of some recursive functions against their iterative counterparts table the tests were performed on a pro with gb of ram and under a linux virtual machine in all these cases the memory usage is not significant at most mb while the analysis times on these are we do see that analyzing the recursive versions take about two to three times more time than their iterative counterparts this is expected since the analysis of a recursive function involves not only the inference of a suitable stack definition but also two fixedpoint computations one over the call sites and one over the return sites in contrast the analysis of a single imperative loop requires only one fixed point computation note that in the case of list reverse the imperative version is quite trivial eg does not even require a segment summary in the loop invariant while the stack inductive definition for the recursive version is just as complex as the other examples case study precision and modularity in this section we look more closely at numerical properties which are combined with shape properties in the presence of recursion figure a shows an example program that implements a filter equation over a doublylinked list here we replaced the integer data field with two floating point fields x and y it through the structure and the nodes where the x field is not in range m m in the same pass it a filter equation by reading from the x fields and writing the result to the y fields this computation is performed only for the nodes that are not deleted let us first consider the purely numeric part of the code ie the digital filter and imagine that it is implemented using a instead of recursion on this version of the program the analyzer can infer rather precise invariants using either the domain of or simply the interval domain with threshold widening for instance if we let m a and p is initially set to then computes the range as an approximation for the terms of the sequence after iterations using only the interval domain with threshold widening on the iterative purely numeric version even though does not support recursion the basic techniques are applicable to the purely numeric part of the program shown in figure a on the other hand using a modular approach to interprocedural analysis to reason precisely about the numeric part is quite challenging as we must capture relations between the inputs and outputs in the abstract domain for instance to obtain the same properties as using the interval domain in the iterative version we must use a complex domain like polyhedra for nonlinear filters like those handled by even polyhedra would not be sufficient to achieve the same level of precision with the modular approach in essence relational abstract domains are sometimes required to achieve the same level of precision using the modular approach as domains on an iterative counterpart we now consider analyzing the program shown in figure a using our call stack abstraction and by instantiating the base domain with intervals that is with a simple domain when applied to this program our analysis must infer inductive rules for stack at two call sites as there are two recursive call sites we consider only the second call site as the other one is very similar though slightly more complicated with respect to shape figure b the abstract state after two recursive calls before summarization of the call stack is performed nodes that denote floating point values are annotated with an interval in particular we have that i i m m i a m a m and so on the values account for errors to obtain an invariant we first derive a stack rule shown in figure c this rule allows us to fold the call stack at the first recursive call site interestingly this rule does not work at the next iteration because the interval constraints over the floating point nodes have not yet instead we weaken the stack as discussed in section in essence this process amounts to the same series of widening steps on the numerical domain elements as void l float p if l null if lx m lx m dll n p else ly a p lx ly a recursive implementation of a digital filter main ¯ l null filter ¯ p filter ¯ p filter ¯ p prev l x y i l prev next x y next i i i l dll b an abstract state after two recursive calls ctx ¯ stack filter ctx ¯ stack unfold p ¯ filter prev i l x y next i c an inferred rule for stack i figure obtaining numerical properties on a recursive program with the call stack abstraction in the analysis of the iterative program by except they are applied when generating the stack summarization rule thus it will lead to the computation of the same numerical invariants recall that we are not an of modular interprocedural analysis as noted in section modularity is often the basis for scalability when functions should be analyzed out of context eg library api functions then the modular approach seems ideal instead we present interprocedural analysis by call stack summarization as an alternative that can be more effective in certain situations a potentially hybrid approach could be to apply modular analysis except were call stack summarization is required for example call stack summarization is applied for a few internal functions as part of a modular analysis of the program discussion interprocedural shape analysis in this section we consider known challenges in the context of interprocedural analysis of heap manipulating programs and comment on tradeoffs cutpoints modular shape analyses typically infer an abstraction of the effect of a procedure on a portion of the heap to make this effect abstraction precise the analysis needs to carefully extract the fragment of the heap that may be modified during a call so that the rest of the heap is a frame such an analysis must also abstract cutpoints carefully to obtain precise results cutpoints are the locations at the of the reachable heap that is any node that is reachable from the parameters though not directly by them and reachable from a pending activation or a global without following links inside the reachable heap it is important to track cutpoints precisely in a modular analysis as they are used to reflect the effect of the callee in the callers state on function return doing so can be challenging as an unbounded number of cutpoints may arise either due to unbounded recursion or due to the traversal of unbounded heap structures while there is no general solution for cutpoints several partial solutions have been proposed for example they focus on their effect by proving or by proving that cutpoints are not live or they reason up to a bounded number of them our analysis based on call stack summarization also needs to with cutpoints so that the widening iteration reaches a precise fixed point in the following we consider how cutpoints impact our analysis in particular situations cutpoints cutpoints often arise when a field of a callers activation record point into the heap space that may be modified by the callee or a subsequent this situation arises in the example in section figure such cutpoints may be unbounded as each recursive call defines a set of local cutpoints and the number of recursive calls may be unbounded however they can be summarized as part of the call stack and when recursive calls return observe that such cutpoints appear among the parameters in inductive rules for stack therefore our approach can deal with an unbounded number of cutpoints by folding them as part of the call stack with finitely many parameters case splitting from cutpoints another case is when the cutpoints from the global variables or from sections of the call stack that are not summarized eg as the activation record of main such cutpoints cause in the call stack as in the example from et al in that example a list is built by two linked lists while keeping a pointer to the element in the middle then a destructive reverse function is applied to the whole structure the state before the list reverse can be summarized as follows l main ¯ l list list list now our analysis needs to through the segment between and using the segment unfolding and a stack rule for the call stack the generated rule is actually very similar to the one derived from the list traversal example of section figure e it is essentially the same except for the direction of next pointers which are by the reverse function as we might predict special care must be taken for the case where the reverse reaches node applying widening here would cause the property that l points inside the list to be lost a solution is to case split and not perform widening on that iteration the trick here is a variation on a classical one when a new behavior is observed eg reaching widening to the next iteration cf to summarize cutpoints induce a somewhat different set of issues compared with modular shape analyses as our analysis ab only states and not effects these issues can be using standard techniques to some extent heap partitioning and cutpoints sharing can introduce more problems as the example void l shown demonstrates in this if code function f takes as input a else doublylinked list and performs a nondeterministic over it at each step depending on a random test it either one step forward and calls itself recursively or it one step backwards and calls itself recursively the difficulty here is that this function may traverse several times the same elements of the doublylinked list thus at any time in a concrete execution an element that has been visited in the past may be visited again in the future this prevents the heap structure from being partitioned into by successive recursive calls this problem would also occur in the case of analyses that infer the footprint of procedures so as to compute their effect this sort of problem can arise even without procedures so we consider this issue orthogonal to the problem cutpoints aim at describing the in the heap partition used to abstract successive calls whereas the issue of this example is that no simple and good partitioning exists related work the most closely related work to ours is and sagiv they designed an analysis based on threevalued logic where the call stack is abstracted together with the heap some earlier work had similar views eg and sagiv s concrete model is quite similar to ours however the abstraction is different as we use separation logic and inductive definitions in particular we found that these tools are natural for abstracting the call stack first the call stack can be defined inductively and second there are builtin separation constraints between the call stack and the heap as well as between successive activation records moreover we found that the operations like function call function return and widening encode well in this abstraction most interprocedural shape analyses take advantage of functions in order to achieve modularity for instance et al abstracts inputoutput relations in the framework using threevalued structures with two occurrences of each element of the universe one for the input state and one for the output state the analysis of et al is based on the of pairs of inputoutput threevalued structures in et al cutpoints are used in order to segment the abstract states and restrict the analysis to a precise approximation of the footprint of procedures similarly separation modular analyses such as et al calcagno et al or et al the footprint of procedures and compute the effect on the local heap though in different as we noted in section modularity in shape analysis has many advantages especially when analyzing libraries or for scalability reasons our approach a gap to a family of analysis problems such as the combined analysis example of section where whole program analysis appears more suitable another area of static analysis related to our work is that of contextsensitive analyses the term context sensitive is used in many ways and may cover very different levels of abstraction ranging from approaches that use to describe contexts or an abstraction of the control flow history to techniques where the call stack content is abstracted our technique uses a rather abstraction of the call string and of the control flow history so its precision can be further improved by applying those techniques the analysis of and features a abstraction of the call stack in the sense that it the order of the activation records conclusion in this paper we have explored a approach to interprocedural analysis over recursive programs in particular we have shown how to apply a shape analysis abstraction based on separation logic and inductive definitions to directly summarize call stacks along with heap structures to automatically derive rules for call stack summarization we exploited its builtin inductive structure the framework turned out to be both expressive and robust in abstracting a very concrete model of calling contexts acknowledgments we would like to thank berdine and yang for interesting discussions on interprocedural shape analysis and on the issues related to cutpoints we also thank the anonymous reviewers for their helpful suggestions including comments on the versus modular approach references berdine calcagno and peter w ohearn symbolic execution with separation logic in symposium on programming languages and systems pages ­ berdine calcagno cook peter w ohearn thomas and yang shape analysis for composite data structures in verification cav pages ­ cousot cousot david and a static analyzer for large software in programming language design and implementation pldi pages ­ calcagno peter w ohearn and yang compositional shape analysis by means of in principles of programming languages popl pages ­ and relational inductive shape analysis in principles of programming languages popl pages ­ and c necula shape analysis with structural invariant checkers in static analysis sas pages ­ cousot and cousot abstract interpretation a unified lattice model for static analysis of programs by construction or approximation of fixpoints in principles of programming languages popl pages ­ cousot and automatic discovery of linear among variables of a program in principles of programming languages popl pages ­ on determining lifetime and aliasing of dynamically allocated data in higherorder functional specifications in principles of programming languages popl pages ­ peter w ohearn and yang a local shape analysis based on separation logic in tools and algorithms for the construction and analysis of systems tacas pages ­ static analysis of digital filters in european symposium on programming esop pages ­ berdine and cook interprocedural shape analysis with separated heap abstractions in static analysis sas pages ­ s and v bottomup shape analysis in static analysis sas pages ­ and david i august shape analysis with inductive recursion synthesis in programming language design and implementation pldi pages ­ and abstracting for interprocedural verification of imperative programs in algebraic methodology and software technology pages ­ thomas reps and sagiv a relational approach to interprocedural shape analysis acm trans program lang syst thomas reps sagiv and interprocedural shape analysis for effectively programs technical report university of london and separating shape graphs in european symposium on programming esop pages ­ mark v and efficient contextsensitive shape analysis with graph based heap models in compiler construction cc pages ­ thomas reps horwitz and sagiv precise interprocedural dataflow analysis via graph reachability in principles of programming languages popl pages ­ john c reynolds separation logic a logic for shared mutable data structures in logic in computer science lics pages ­ and sagiv interprocedural shape analysis for recursive programs in compiler construction cc pages ­ thomas reps sagiv and a semantics for procedure local heaps and its abstractions in principles of programming languages popl pages ­ sagiv and interprocedural shape analysis for programs in static analysis sas pages ­ and the trace partitioning abstract domain acm trans program lang syst sagiv thomas reps and solving problems in languages with destructive updating acm trans program lang syst ­ sagiv thomas reps and parametric shape analysis via valued logic acm trans program lang syst ­ and pnueli two approaches to interprocedural data flow analysis in s muchnick and d jones editors program flow analysis theory and applications chapter pages ­ prenticehall abstract domains application to the alias analysis of untyped programs in static analysis sas pages ­ 