code generation for expressions with common subexpressions extended ct a v aho and s c johnson bell hill new j d ullman princeton university princeton new introduction easy as the task may seem many compilers generate rather inefficient code some of the difficulty of generating good code may arise from the lack of realistic models for programming language and machine semantics in this paper we show that the computational complexity of generating efficient code in realistic situations may also be a major cause of difficulty in the design of good compilers we consider the problem of generating optimal code for a set of expressions if the set of expressions has no common subexpressions then a number of efficient optimal code generation algorithms are known for wide classes of machines su aj bl in the presence of common subexpressions however and sethi have shown that the problem of producing optimal code for a set of expressions is npcomplete even on a single register machine bs s however and proof of uses rather complex expressions so it leaves some hope of being able to find efficient algorithms for generating optimal code for restricted classes of expressions with common subexpressions unfortunately we show in this paper that the problem of optimal code generation work partially supported by nsf grant remains npcomplete even for expressions in which no shared term is a subexpression of any other shared term we also show that the optimal code generation problem is npcomplete for these expressions on machines even when the number of registers is with these negative results we consider both heuristic and exact solutions for generating code first we investigate the worst case performance of a collection of fast heuristics for single and machines one reasonable heuristic is shown to produce code that is in the worst case three times as long as optimal other heuristics are given which have a worst case of for machines then we present for the single register machine an algorithm which generates optimal code and whose time complexity is linear in the size of an expression and exponential only in the amount of sharing since the number of common subexpressions in expressions to be limited in practical situations this approach appears finally after discussing code generation for commutative machines we conclude with a list of open problems background and definitions dags for the purposes of this paper we can assume we have a compiler of the form f r o n t dag code end i m a generator u c d ub u u a u u u u u u u basic block the front end translates a source program into a sequence of intermediate code segments called basic blocks along with information that identifies the flow of control among basic blocks within a basic block the flow of control is sequential each basic block consists of a sequence of assignment statements of the form where a b and c are distinct variables and op is any binary operator for which there exists a corresponding machine operation since we shall concentrate on generating code for basic blocks in this paper the flow of control information will not be mentioned further the dag transforms the basic blocks into a directed acyclic graph dag for short that represents the computations of the expressions in the block see au or cs for algorithms to construct a dag from a basic block we shall not consider the use of algebraic identities to transform dags to make them easier to compute this has been discussed in fa fig shows a basic block and its corresponding dag we call node a right child of node and a left child of node for symmetry we call node a right parent of node and node a e f t parent of node we say node x uses a node y if y is either a left or right child of x we say x left uses resp right uses y if y is a left resp right child of x dag fig basic block and its dag a node with no children is called a leaf a node with no parents is called a root nodes that are not leaves are often referred to as interior nodes we assume for simplicity that all operations are binary we ignore constraints that may be introduced into the dag because of side effects for example suppose two nodes of a dag represent the operation of indirect assignment through a pointer if the two pointers could point to the same datum and the source code specified an order for the two assignments then an edge in the dag connecting the two nodes in the proper order must be introduced the machine model we assume the code generator is to produce code for a machine the instructions of the machine are of the form r ri op ri ri op m r r ri m register copy load m store here ri and § are any of n registers and m is any memory location op stands for any machine operation when a machine has only one register ie n then there are only type type and type instructions a machine program is a sequence of instructions the length of a program is the number of instructions it contains definition the optimal code generation problem is to produce from a dag a shortest machine program that evaluates and stores all roots of the dag when discussing single and machines we assume the leaves of the dag are labeled by memory locations and the interior nodes by machine operations we also assume for convenience that a dag has no root that is a leaf example the dag of figure can be evaluated on a machine and stored in memory location m by the sequence of instructions r c ri r d r b r r r t r rt a ri r r r r t ri r r m q evaluate node load b evaluate store load a evaluate evaluate evaluate store root in section we shall discuss code generation for commutative machines ie machines in which for every type and above is also an instruction of the form rj op ri ri m op ri even for machines is a very difficult problem the next section discusses why why is hard and sethi have shown that is npcomplete even for machines their proof technique was to transform the satisfiability prob lem with three literals per clause see eg to their technique however in rather complex dags we begin by showing that is npcomplete for machines even on a rather simple class of dags a node both of whose children are leaves is called a node a shared node in a dag is a node with more than one parent a dag is a dag in which every shared node is a node a is a dag in which every shared node is a leaf c several code generation algorithms for machines make use of the notion of a left chain that is a sequence of interior nodes nt n nk such that ni is the left child of hi for i k for example in the dag of figure and are the only nontrivial left chains the first lowest node on a left chain is called its tail and the last node its head definition the feedback node set problem is given a directed graph g find a smallest set of nodes f a feedback node set such that removing f from g eliminates all cycles is a wellknown problem see eg theorem for dags on a machine is npcomplete proof we show how to transform an instance of to let g be the directed graph in the feedback node set problem from g construct a dag d as follows for each node n in g of d create a corresponding left chain of d interior nodes n ni nd in d n o is the tail and nd the head of the chain make no a node by giving it left and right children labeled by memory locations the remaining edges of d are determined as follows suppose the of n are directed to nodes mi m md in g make the o f the left chains corresponding to mi m m d right children of tl i i respectively in d fig a shows a directed graph g and fig b the dag resulting from g using the construction above a directed graph g b resulting dag d fig graph and corresponding dag we must now show that we can construct a minimal feedback node set f for g from an optimal program p for d and conversely it can be shown that an optimal program for a machine does not store and load any uniquely interior nodes of a dag interior nodes with exactly one left use and no right uses thus except for the loads of leaves the only loads in p are loads of some nodes it can be seen that these nodes identify a feedback node set f in g conversely given a minimal feedback node set f of g we can construct an optimal program for d by first evaluating and storing the in d of the left chains corresponding to the nodes in f for example d is a minimal feedback node set for the directed graph g of fig a the optimal program p corresponding to this feedback node set first computes node do of d in fig b then p evaluates c ci b b i b a o a i di to evaluate d p needs to load do this is the only node loaded by p to the difficulty of generating optimal code for dags let us assume we are generating code for an infinite register machine a machine in which the number of registers is unbounded to eliminate the problem of deciding what to store or load let us further assume the leaves of the dag are labeled by register names rather than by memory locations similarly let us assume we need not store the roots the relevant instructions of the infinite register machine then become ri ri op ri ri fi even in this highly simplified environment the optimal code generation problem is npcomplete theorem for leaf dags on an infinite register machine is npcomplete similar to that of t h e o r e m thus even if the problems of code selection and storage of intermediate values are made trivial just finding an optimal evaluation order for the nodes of a dag is an npcomplete problem on the other hand if we the infinite register machine architecture by arbitrary instructions of the form ri rj op rk then we can generate optimal code for arbitrary dags in linear time we simply evaluate the dag bottom up level by level assigning a distinct register to each node the three main problems in code generation are what instructions to use in what order to do the computations and what values to keep in registers the results of this section indicate that for machines just deciding the order in which instructions are to be executed is an npcomplete problem heuristic techniques since even simple versions of the optimal code generation problem are npcomplete it is not surprising that in the past code generation algorithms for dags usually have made several restricting assumptions one approach has been to ignore sharing by representing a set of expressions as a forest of trees for this case a number of optimal code generation algorithms have been developed su aj bl was another approach has been to avoid the problem of finding an optimal evaluation order by taking some fixed order for the nodes of a dag and then on optimal of registers fr eg optimal code cannot be guaranteed however without considering sharing and the freedom to code that is inherent in the source program when with an npcomplete problem there are two standard approaches develop and analyze heuristics and look for useful special cases that have polynomial time algorithms we shall consider both approaches here for the analysis of heuristics we use the worst case measure a way of the of a heuristic which may be applied to various of data for our purposes we define the worst case of an algorithm to be the over all dags of the ratio of the length of the code produced by that algorithm to the length of the optimal code for the dag two methods of for costs there is a usual way of the interior nodes of a dag for the cost of their evaluation a node one unit of cost for each of performing its operation storing its value and loading its left child or copying its left child from another register we call a program if it performs no useless instructions ie instructions which can be deleted without changing the value of the program it never moves via loads or transfers a value into a register without subsequently left using that value and it never stores the same value more than once it is easy to check that a program will have each of its instructions assigned to some one node by the above scheme formally we may show the following theorem let p be an optimal program for some dag d and let p be any program for d then the ratio of the length of p to that of p is at most proof using the above scheme every interior node of d is assigned at least one instruction but never more than three instructions a load an operation and a store obviously there are an infinite number of programs to evaluate any dag we shall restrict ourselves to programs doing so serves only to rule out programs there is little loss of generality since we can construct from any program p an equivalent program in time proportional to the length of p there is a second cost scheme which we find quite useful this scheme gives the same overall cost as the scheme above but the cost units are differently the nodes we now each node for every instruction that affects its value i e for the operation that computes its value a n d any loads stores or copies of that value we call this cost scheme the if n is a node of a dag let i n and rn be the number of times n is used as a left and right child respectively of some other node in the dag of figure for example and r z also r lemma the following costs are upper and lower bounds on the of a node n with respect to any program on a machine case n is a leaf n is not a leaf and n n n and rn and rn lower n nl upper n n let us consider case as an example an evaluating n is necessary since n is used more than once and there is only one register one store instruction is also necessary every time n is left used its value in the register is and it must be the next time it is left used thus n load instructions are necessary and in load instructions are sufficient by condition in the definition of therefore a total of n or n instructions is needed lemma for a machine lemma holds with the lower bound set to in cases and and in case omitted we observe from l e m m a that it is only interior nodes with one left parent and no right parent that could give us a worst case ratio of for the machine interestingly it is quite easy to handle such cases if node n is uniquely we can to have n evaluated immediately before its parent thus it is unnecessary to load or store n and it achieves a of therefore we can state the following theorem any algorithm for a machine which generates programs that avoid storing uniquely nodes has a worst case no greater than note that theorem fails to hold in the case since n rn is another case that can yield a worst case ratio of and s o m e other cases yield a ratio of we must also point out that the use cost can in some cases the cost of an optimal program on a machine by a factor of fig for example shows a dag whose lower bound is p this lower bound however is not since any program evaluating this dag must store and subsequently load each of the nodes the cost of an optimal program for the dag is p p nodes fig dag thus if we found an algorithm with a worst case ratio less than the proof of that worst case bound must use a more sophisticated cost analysis than the above heuristics for one register machines an evaluation order for a dag is any to sort of the interior nodes of the dag for a machine from an evaluation order we can easily construct a program that is as short as any other which computes the dag in that order thus an algorithm that produces an evaluation order for a dag is in effect a code generation algorithm for a single register machine in this section we analyze the performance of some simple heuristics for creating evaluation orders for single register machines definition t h e bottomup greedy algorithm bug creates an evaluation order for a dag by repeatedly listing the nodes of a longest left chain that can be currently evaluated to evaluate a node both its children must have been previously evaluated note that it is for the right child of a node in a chain to be an node which is lower on the same chain example r e t u r n to the dag of figure the only left chain that be listed initially is t h e n the chain can be listed and finally the chain giving an evaluation order of in this case the code is ri c r ri d t r r b ri r t u r r i r i t v r ri a ri ri u ri r i v m ri by l e m m a this program is optimal theorem b u g has a worst case ratio o f proof figure shows how the worst case o f can be arbitrarily closely at the right we s h o w p nodes c c cp called whose initial evaluation is necessary for optimal code if we evaluate the first and store them at a cost of p we can go up each of the p left chains with a cost of p per chain for a total of p p h o w e v e r b u g select c then the bottom node of each chain then c then the next node of each chain then c and so on using three instructions per interior node the worst case ratio for this example p p fig bug definition the topdown greedy algorithm au p see also works by listing left chains in the reverse order of their evaluation repeatedly select a node n all of whose parents if any have already been listed then list n and as many nodes of the left chain with head n as may be listed note that a node may be listed only if all of its parents have already been listed as we are generating the evaluation sequence in reverse also once an node is encountered we do not proceed further down the chain after sequencing all interior nodes reverse the list to get the evaluation order example in the dag o f figure we would select the root first and find we may list it and its left child t h e n we could select since its parent has already been listed we could proceed to the left child of since its parents namely and have been listed finally we list r e v e r s i n g the list gives again so the same code as for bug is produced in this case and bug however are quite different in their worst case performance produces optimal code for fig for which bug produced the worst case code theorem has a worst case ratio of proof to see that it is no worse than note that if n is uniquely by m then n must be listed immediately after m and therefore n is evaluated immediately before m thus case of lemma is always handled correctly the lower bound of one instruction to n is all other cases in lemma have a ratio of or less for the proof that can be from below consider the grid of figure the optimal sequence of evaluation goes up the left chains starting at the bottom right storing each value with the exception of those on the leftmost chain roughly two instructions per node are used in this evaluation sequence on the other hand could list nodes row by row from the right taking three instructions per node fig grid it is also worth noting that always handles the case rn o in correctly since n will be listed immediately after the last of its left parents to be listed thus the generated code will have only in loads of n in truth there is no magic about top down vs bottom up algorithms by care in the selection of chains it is easy to construct a modification of bug that has the same performance as another worst case algorithm can be obtained using depth first search definition the depthfirst search algorithm dfs performs a depthfirst search see eg of the to move to the right child rather than the left when there is a choice nodes are then evaluated in order of last visit theorem the worst case ratio for dfs is heuristics for machines the topdown greedy algorithm can be generalized to the case of an n register machine for a machine however it is no longer sufficient to specify only an evaluation order we must also specify in which register a computation is to be done the following procedure lists the interior nodes of a dag in reverse evaluation order t h e register assigned to a node is the register in which that node is to be computed stores and loads of registers are performed as needed procedure k n is a node k is the number of registers available if k and n is an interior node all of whose parents have been listed then begin list n and assign it register k child of n k child of n k end main program while not all interior nodes have been listed do select an interior node n all of whose parents have been listed and perform n although performs well in many cases the worst case performance of approaches as large theorem the worst case ratio for the algorithm with n registers is no less than nn the grid of figure provides the essence of the proof demers d has considered a generalization of dfs to machines in which a depthfirst search is used to obtain an ordering of the nodes and then algorithm is used to allocate registers an optimal algorithm for the one register machine we define sn the sharing of a node n in a dag to be sn n sn sn and rn otherwise the sharing s for a dag is the sum of the sn over all interior nodes n in the dag we shall now present an algorithm for the one register case that is optimal and is of time complexity o p s where p is the number of nodes in the dag and s is the amount of sharing to introduce this algorithm we note that any dag can be partitioned in various ways into left chains given a program for a dag we can create a partition by looking for maximal sequences of one or more consecutive operations by loads each such consecutive sequence forms a left chain and the set of left chains so formed partitions the interior nodes of a dag we can obtain a partial converse of the above we say that a partition of the interior vertices of a dag d is legal if the following holds form a graph g whose nodes correspond to the left chains of d and with an edge from ci to c w h e n e v e r there is a path in d from some node of cl to some node of c t h e n there must be no cycles in g we may thus state the following lemma there is an evaluation order producing a given partition of a dag into left chains if and only if that partition is legal more importantly we can relate the cost of evaluation sequences to the costs of the heads of the left chains theorem let d be a dag then there is a constant co with the following property suppose p is any program evaluating d let the partition induced by p have k i chains whose heads are left used at least once let k of these be uniquely then the length of p is cd k k conversely if there is a program for d of cost c then we can find a legal partition into left chains with parameters k i and k such that c cd k k cd is the sum over all interior nodes of d of the lower bound on cost given in l e m m a k accounts for loads of nodes that is the th load of a node left used times note that a node will be loaded rather than times if and only if it is the head o f a c h a i n k accounts for stores of uniquely nodes we intend to reduce the problem of finding an optimal program to that of finding a set of heads of chains clearly any node with n must be the head of a chain a node with rn and n can always be attached to its left parent in a chain as in the following lemma l e m m a if is a legal partition of dag d and there is a uniquely node n which heads a chain then the partition formed from by removing n from its current chain and it to the chain of its parent is also legal if there is a path to n in d it must go through the unique parent of n we thus see that the question of whether or not a node is the head of a chain in an optimal program is only for those interior nodes with more than one parent at least one of which is a left parent we may thus try all subsets of these nodes selecting those which are not the head of a chain for each selected node with more than one left parent we must also select the left parent to whose chain it is attached the number of these can be shown not to s where s is the sharing we may thus test each selection in order of lowest cost until we find one that is legal the test for is seen to be op on a p node dag thus t h e o r e m there is an o p s algorithm for obtaining an optimal program for a dag commutative machines a c o m m u t a t i v e m a c h i n e is o n e in which for each instruction of the form ri ri op r or ri ri o p m there is also an instruction of the form ri ri op ri or ri m op rr that is the register used to hold the result can be the same as as either the left or the right register operand this allows us to think of the order of the children of any node as being as far as code generation is concerned although the operator itself may not be commutative for commutative machines the of a is a a is any path in a dag the leaves we define a partition of a dag d into to be legal if the graph whose nodes are the of d with an edge from wi to w if and only if some node of w has a path in d t o s o m e node of w is acyclic the following is an to t h e o r e m t h e o r e m let d be a dag t h e n there is a constant cd with the following property suppose d has a legal partition into such that there are k i whose heads are used either left or k of which are uniquely used then there is a program for d on a commutative machine of cost cd k i k conversely if there is a program for d with cost c then we can find a legal partition with parameters k i and k as above such that c cd k k we can generalize the topdown greedy algorithm to commutative machines by listing in reverse evaluation order if we always list a uniquely used child immediately after its parent then we can show that is a worst case ratio for this algorithm for the commutative machine we can also produce an of the optimal algorithm of section which is polynomial in the size of the dag and exponential only in the sharing the follow ing lemma is needed it is not as strong a result as could be proved about partitions lemma let w be a legal partition of a dag suppose node ni is the head of a w nl n n k in which n n nk are all uniquely used then there is another partition w of d with a of which n n n k is a proper tail that is the new includes at least the parent of n such that the cost of the program induced by w is no greater than the cost of the program induced by w fig shows a fragment of a dag in which node m is on some perhaps n ms other child is on the same fig construction remove edge m n from that if it is there and add the edge mn i this may make node n a head but ni will no longer be a head it is easy to show that the cost of the partition is not increased and the fact that n n n k are uniquely used makes a proof of for the new partition easy t h e o r e m t h e r e is an o n s algorithm for finding an optimal program on a commutative machine for an dag with sharing s the first step is to take the dag d and divide it into trees an idea discussed by for each root or shared node n we do the following find the maximal subtree with n as root which includes no other shared nodes except as leaves an example is shown in fig a dag b trees fig division of a trees note that each node appears as a leaf in at most one tree per use if it is used by two nodes t h e same tree divide the shared node into as many leaves as necessary so that no leaf is used more than once note also that no node appears in more than one tree the algorithm begins by determining which edges of tile various trees belong to later we shall combine the trees to allow to cross tree boundaries imagine upward from all leaves in a given subtree the fact that do not actually reach the leaves can be for later by removing edges from at the bottom at each interior node n we must decide which if any of the reaching children of n include the node n if either or both of the children of n are part of that begin at tree leaves of d or interior nodes of d that are not shared recall some leaves of a tree here may actually be shared nodes of d then lemma us that we may allow any such to continue up to n the only uncertainty occurs when both reaching the children of n at shared nodes of d then we must try all three possibilities that either or neither n in the last case n begins a new a situation which could be necessary to achieve a legal partition we see from the above that the only where there is uncertainty regarding how far up to proceed are those which al shared nodes of d if tree ti has k i leaves which are shared nodes of d then there are at most ki outcomes for the regarding which proceeds moreover for each shared node n that is a leaf of ti ns in t may or may not connect with that which includes n in the tree of which n is the root recall the edges from leaves to their parents are not really parts of thus we may either include or the edges from node n to its parent in ti from the set of edges of d thus for tree t there are at most ki subsets of edges which could possibly be the edges used in an optimal partition of d not all subsets of edges need be consistent for example some node could be connected to two or more of its parents by selected edges the number of possible sets of selected edges is no more than k which is no greater than s where s is the total sharing of d each s u c h s e t of selected edges can be checked for consistency and in on time where n is the number of nodes of d if legal the cost of the partition can easily be computed in on time by the heads we can therefore run through all the candidate partitions in on s time and select that one with the least cost summary and open questions we have analyzed several simple heuristics for generating code for a machine showing them to have a worst case of or in one case we have also shown for the machine both in the commutative and cases that there are optimal code generation algorithms which are linear in the size of the dag and exponential only in the sharing additionally we have shown that even some very simple code generation problems are npcomplete we feel that this work only the surface of what can be learned about the important area of code generation algorithms we therefore propose the following questions as potentially areas for future research is there an optimal algorithm for machines which is polynomial in the number of nodes and registers and exponential only in the amount of sharing how closely can the optimal code generation problem be approximated by a polynomial time heuristic on a single register b and c infinite register machines in particular can we for all e develop polynomial time algorithms with a worst case ratio of e what about the same problems for commutative machines on some machines certain operations such as multiplication require an register pair how do machine such as these affect the computational complexity of code generation is optimal code generation polynomial even for trees how difficult is it to generate code for a tree in which some of the leaves are registers rather than memory o the leaves whose values are in registers cause a register to be when they are used sethi has shown that we can without loss of generality evaluate any subtree containing a leaf in a register provided we can do so with no stores replacing that subtree by a leaf in a register the problem of what to do when no such reductions are possible appears npcomplete is it acknowledgements the authors wish to thank and for their helpful comments on the manuscript references a v aho j e hopcroft and j d ullman the design and analysis of computer algorithms aj a v aho and s c johnson optimal code generation for expression trees proc annual acm symposium on theory of computing may pp au a v aho and j d ullman the theory of parsing translation and compiling vol ii compiling prentice hall j c a register assignment algorithm for generation of highly object code ibm j res january l a a study of replacement algorithms for virtual storage computers j br m a generation of optimal code for expressions via comm acm june bl j l and t the generation of optimal code for stack machines j acm july bs j l and r sethi register allocation for a machine tr computer science dept state univ university park pa oct c s chen on the algo port bell n j may cs j and j t schwartz languages and their compilers second edition institute new york d a demers private communication fa r j optimal code for serial and parallel computation comm acm december fr r a register allocation via usage counts comm acm november l p r m r e and s index register allocation j acm january si r sethi complete register allocation problems siam j september r sethi private communication su r sethi and j d ullman the generation of optimal code for arithmetic expressions j acm october w m optimization in compiler construction an advanced course f l and j eds springerverlag pp was s g a compiler writing system with optimization capabilities for complex order structures phd thesis univ ill w a r k c b s o and c m the design of an optimizing compiler 