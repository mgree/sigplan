characterization and elimination of redundancy in recursive programs h university abstract many wellknown functions by interpretations of the recursion are computed schema procedure q px then else fx return return ax some of these interpretations computations because they lead on f with identical argument define redundant to multiple calls values the existence properties and nature of the redundancy depend on of the functions ci we explore four sets of assumptions about these functions we analyze directed acyclic graphs formed by the nodes of the computation tree for fx which are known to be equal for each set of assumptions in each case there is a transformed program which computes fx without redundancy provided that certain additional assumptions about p a and the ci are satisfied the transformed programs avoid redundancy by exactly those intermediate results which will be needed again later in the computation recursive these programs are all procedures which leave intermediate and final results in specified global locations in each case recursion can be eliminated of a stack we compare the storage without use requirements of the transformed programs discuss the ability program of these improvement transformations to an automatic system and present a general criterion redundancy for establishing the existence of however many of these definitions are inefficient because they lead to redundant computation that is they cause f to be called recursively several times with identical arguments for instance by letting px x cx x the following negative integer series if we interpret the schema j ax and yz we obtain function which given a non x returns the element of the u fx xo or x else return fx fx the resulting computation for f is in figure note that f is computed two times and f is computed are calls three times on f with in all there only six distinct argument values for certain interpretations of n transformations which when applied to the procedure f yield a program which is partially equivalent to f the applicability introduction functions often definitions which recursion schema gn have elegant are interpretations defined by recursive of the pn p u px else fx return ax return x research supported by and by us under electronic contract an ibm department systems research of the command figure a tree representation of the computation of f under the interpretation call on f of and is each labelled node represents a with the argument value for that call the sons of a node represent recursive cal s arising directly from the call represented by that node of these transformations depends on the of two conditions a descent condition relating the functions ci to each other and a frontier condition relating the to the predicate p and the function a for t interpretation such a transformation would yield the following program fx fx s procedure fx then begin q else begin fx back back the variables and back are global to f the recursive procedure fx is executed for the sideeffect of placing the value of fx in it also the value of fx in and the value o fx in back for xi we present four transformations applicable under a weaker descent condition the previous one in sections through these transformations in terms schema defined by procedure fx q px then return else return ax each than we of the for c simplicity we explore we use c and d in place of c and the constraints which each condition places on the domain and present a program which given the validity of an appropriate frontier condition exploits these constants to compute f without redundancy in section we sketch the generalization of these transformations to n for n we are interested both in exploring the mathematical nature of redundant programs and in the automatic improvement of redundant programs after we consider the mathematical implications of each descent condition and present a transformed program the full generality of the schema we discuss the applicability of more specialized improvements which result in simpler and more efficient programs to programming as in k aho hopcroft and unman redundant computation is avoided by results which may be needed many times the approach in some ways the method of presented by b however we use knowledge about the interpretation to reuse storage for results which will not be needed again in many but not all cases a fixed amount of storage can be shown to be sufficient for all inputs in general there are interpretations of whose computations inherently require unbounded amounts of storage and strong we show in section that among these interpretations are some for which f is redundant sophisticated knowledge about the interpretation allows us to produce a program which makes recursive calls only when such calls are necessary and references stored previous results at all other times traditional approaches to dynamic programming determine when to make recursive calls by checking whether the storage location identified with a particular argument value has been written into since we intend to reuse storage locations for many argument values we will have to be more general the transformed program f uses global variables to store these previous results when called with argument x the program first checks whether px is true if not it calls itself recursively with some new value x this has the effect of leaving the value of fx as well as any other values which may be needed later on in specified global locations using these values and taking advantage of the descent condition the program computes the value of fx this and any other values which might be needed by invocations of f which called itself recursively with argument x are placed in appropriate global locations and f returns in the case where px is true we simply initialize the global locations with the value ax and any other values by the caller of f needed as we assume that all these results can be computed without further recursion the frontier condition is a formal statement of this assumption we conjecture that it is valid for most naturally arising cases the transformed programs in sections through are recursive procedures which do not return a value but have the side effect of leaving their results in a designated location these programs are in a form which at the of clarity can easily be made iterative methods for eliminating the recursion are discussed in section in each case this can be done without use of a stack in the example the result of eliminating the recursion would be essentially this program fx i until back back q return x iq back descent conditions we partition the domain of f into two subsets and consists of the base cases those values in the domain of f for which p is true consists of the recursive cases those values in the domain of f for which p is false we shall refer to c and d as the descent functions of in general ci is a descent function of yn for a requirement that certain among the descent functions a descent condition relationships on in section is hold we consider the very strong descent for all x in in require the existence of a function condition that section we g and integers m and n such that and for all x in and condition iz the notation means otherwise this weaker implies that on in section our x if io descent and descent condition asserts that and on f for some m and n but we do not on the existence of g the descent condition for section is the relatively weak requirement that that c and d commute on not on we say surprisingly as we consider weaker descent conditions our transformations become more the frontier condition the purpose of the frontier condition is to that there is a boundary between and and that the descent functions map values toward cases formally let s be a set of functions typically these functions will be compositions of descent functions the frontier condition for s is the requirement that for all x in and all h in s and thus hx is defined and if is defined then this is always the case for instance when h maps into ie when px implies for all h in s this condition us that whenever we are for the value of where h is in s and x is in we may supply the answer and be sure that we have supplied the wrong answer only if we were for an undefined value descent trees and compressed descent a descent tree will be a tree representing the computation of fx for some x each node will correspond to a call on f the root will correspond to the original call and each node will have children corresponding to the calls arising from the call on f represented by that node sometimes we will identify nodes with the argument values of the corresponding calls and sometimes we will identify them with the result values of the corresponding calls in the former case we will often abbreviate an argument value by indicating only a sequence of descent functions which must be applied to x to obtain that value each of these the tree the computation function conventions is in figure is of f where depicted a descent f is the in figure tree for if we make certain assumptions about c and d then we may the descent tree into a directed acyclic graph dag by merging nodes which correspond to calls with the same argument value any two such nodes are roots of identical subtrees subtrees compressed and we merge the resulting descent l the nodes by merging those graph will figure be called shows a a compressed descent dag for the descent tree of figure a bx b ada c c d cc dc cd d figure descent trees for the computation of of fx tree argument values a has nodes tree b with labelled result with values under the assumption that p is true for every value in the third value of tree a and false for every value in the first and second levels of that tree tree c is a convenient for tree a abbreviation a i figure computation function a compressed of f since each descent where f of the dag is the nodes for the has a different value this is the minimal compressed descent dag for that computation when we have merged all the nodes of a descent tree which can be shown to have the same value under the resulting a given graph set of assumptions the minimal compressed we call descent dag for that set of assumptions formally if there is an interpretation a given set of assumptions for which no two nodes of a compressed descent dag have the same value the compressed descent descent dag is minimal the minimal dag of a computation is uniquely compressed defined assumptions it will be assumed throughout that evaluating a descent function a b or p entails no sideeffects lie guarantee that the transformed function returns the same value as f throughout the domain of f but we do not attempt to characterize the behavior of the transformed function on those values for which f is not defined the parameter x may be regarded either as a scalar or as a tuple in the latter case the descent functions will be explicit redundancy definition of an interpretation of j redundancy if for all x in consider for example the domain of lisp lists let px be the predicate let ax be the constant function whose value is the list whose only element is nil let let cx dx is a function taking an atom and a list of lists and returning the result of the atom onto each for example bc d is to the list aa ba c d this interpretation leads to the following explicitly redundant definition mapping sets represented as lists to their fx then return else return solution to explicit we can transform f into a recursive fx which does not return a result leaves the value of x in a global variable follows procedure but always t as procedure fx u px t ax t the function f is then simply procedure fx this transformation is valid of a frontier condition require functions that the frontier in the empty condition set of used in place of c in the transformed it is to do so without the formally we hold for all course d may be program if explicit redundancy need not arise from programming it is likely to be found in programs or in programs written to clarity rather than efficiency the program above could have been a mechanical translation from pure lisp in which there is no notion of assignment to an algollike language the original lisp programmer could have introduced an auxiliary function lambda xy append y car x y and called it with arguments x and f to avoid the redundant computation since f cdr x would be evaluated once and bound to y the resulting program would have been less clear however it is quite reasonable and in fact desirable for a programmer to write clear but inefficient programs if he has software tools at his to improve those programs mechanically definition of common generator suppose that for a given interpretation of there exist a function g and positive integers m and n such that and for al x in e we shall call g a common generator of c and d and say that the interpretation common generator we assume without loss of n generality that m if this is not and and n are relatively the case we consider in place of g m and n respectively value of gm or gn figure without the shows the structure of the descent this section we tree under these assumptions present a transformation in which a x mx g x x figure redundancy nodes but descent tree the kth level at most k distinct for common of the tree values generator has pk eliminates that the functions common generator frontier condition redundancy holds for the set of the program discussed in section provides an example of common generator redundancy recall that under that interpretation cx x and dx x if we define gx x then and for m nl and x in the frontier condition requires that for each function h in su and each x in is either undefined or equal to the possible values of hx are o and the function a is a constant function equal to at all these points since and f and f are undefined the frontier condition is satisfied implications of common generator the set of expressions occurring in the descent tree of figure is i since m and n are relatively prime almost every natural number can be expressed in the form specifically it is shown in the appendix that all but of the natural numbers can be so expressed the cannot be is mn number which typically m and n will be small numbers thus the tree contains expressions equivalent to almost every expression of the form kj this makes it reasonable to compute fx by computing in turn each of the values for some appropriate k we shall write a procedure fx which calls itself recursively on gx then using previous results the value of fx the resulting descent tree for f is a simple chain as shown in figure this tree is also a minimum compressed descent dag x gx x x i figure the minimal dag for a computation of fx call the chain based on a recursive continues until for some k is true suppose we want to find the value of f node in the chain say that corresponding at a to value and is false if we look computed m nodes down the chain at the we will find the value of similarly the value nodes down the chain is the value of computed n using these we can compute we employ a global to remember values which array may be needed later and transform procedure fx which f into a recursive does not return a value the side effect in is undefined for some of leaving the j an arbitrary if value value of is left in when px is true the frontier condition us that either or simply range is undefined set to if px is so we may for each i in this false we call to place into shift up to and then place fx in the program is procedure fx fx a procedure fx s u px l i begin x gx return ax q ti i q l note that behaves as a queue newly calculated values are placed in at the low end of the array and towards the high end of the array as we from the recursion the values are referenced and nth positions as they pass through in order to calculate the a new value to be placed at the beginning of it is possible that a will be calculated and placed in but never far enough to be referenced or that it will be referenced only to compute results which themselves never far enough to be referenced etc however if the depth of the recursion every value of the form which we calculate is in fact needed thus the nature of more than us that useless for any x no values are computed any value placed in such that is undefined be one of these useless values must turn out to redundancy the solution to common generator the efficiency improved at the and n are constants practice be small of this program can be of clarity recall that m whose values will in thus the loops above may be into a sequence of assignments since array references constant subscripts scalar in these assignments we may replace variables if there will have by is a form which will evaluate to in an amount of time independent p by of ax the i we may replace x gx equivalent of the sequence in the first periodic redundancy consider the following shortest path problem which we shall call the problem there are two parallel into a and k at which a may switch from one to the other the time involved in switching is but all exit from the left and enter into the right since it takes time to cross several of traffic safely we do not permit consecutive the to switch at two that is if a switches at i he may not do so again until i the problem is to determine the minimum amount of time in which the can reach the given the amount of time it takes to between each pair of consecutive on each suppose we represent the by the integers and so that if we are on h the other is h and we initialize the array l so that time needed to between is the i and i on h and for io and the numbers are assumed to be in order as we approach the and kl is the final destination then the following recursive program computes the solution to the problem ik return else return h the value of is the minimum time to reach the if we are now i on h if ik then we are at the last and we can simply select takes us from k to kl ie the destination time required to do this most quickly is the if we are already at the destination so that the time required is h o otherwise we take the smaller of the minimum time to the if we minimum time to the if h the first of these the second on h and the we switch to values is is since the is constrained to on h until at least the ith the row of delay allows the base cases to be handled uniformly the row of delay allows us to assume without loss of generality that the out at o on so that we may solve fol the problem by calling function f is of course an instance of with x corresponding to the pair ih then px ax u xz cx xx computation and dx of f is redundant as x xy u descent tree for fol with k in figure this is not surprising when we observe that cx dx u xx and u xx definition of periodic in general we say that an interpretation of l periodic whenever there exist integers i and j such that for all x in and for all x in this is the case when the interpretation common generator redundancy if c and d have a common generator g such that and on a then and on however c and d in the solution to the problem have no common generator thus periodic redundancy is a strict generalization of common redundancy lie present a transformation for programs periodic redundancy which is valid whenever the frontier condition holds for the set of functions figure descent tree for the call fol where f is the program computing the solution to the problem for k each node is labelled with a pair ih representing the argument values at that call implications of periodic redundancy let e ci dj on since c and d commute all values in the minimal compressed descent dag of fx are of the form where m and n are nonnegative integers but m can be expressed as where r and s are nonnegative integers and si and n can be expressed as where then t and j are nonnegative integers and uj thus each value in the compressed descent dag of fx has a unique representation of the form where si and uj consider descent dag the subgraph of the consisting of the values compressed for a given k this subgraph is depicted in figure notice that this subgraph forms an i by j rectangle we can a comparable i by j rectangle whose upper righthand side lies adjacent to the lower righthand side of this one and a third i by j rectangle whose upper lefthand righthand side side lies of adjacent the original to the rectangle lower in fact the entire descent dag may be compressed into a network of as shown in figure given result values corresponding to the upper sides of for instance d and e it is possible to compute the result values corresponding to rectangle b let us assume that the rectangle labeled a represents the subgraph shown in figure the node in the corner of b is the one just below and to the left of the node in a corresponding to thus it corresponds to the node in the corner of c occurs just below and to the right of the node in a corresponding to thus it corresponds to u however ci dj e on thus that is the nodes in the cf b and c correspond to the same value these would not be part of the descent dag if and respectively were not in it follows that all the nodes in b correspond to the same values as their counterparts in c in other words in the compressed descent dag b and c are similarly d e and f are mutually thus the descent dag may be further compressed into the form shown in figure this compression preserves between ie if there is an edge between a certain node in rectangle x and a certain node in rectangle y in figure there is a connection between the corresponding nodes in the of x and y in figure figure an abstraction each rectangle represents the configuration of figure of the descent ij nodes dag in figure the subgraph of a compressed dag consisting of the nodes descent figure the result dag by merging identical of the descent observe that each rectangle in figure has an corner corresponding to a value of the form for some k every other node in that rectangle where corresponds to a value of the s and u are uniquely determined form by the position of the node within the rectangle there is a linear ordering among the in the descent dag of figure corresponding to the various values for k it follows that the compressed descent dag of figure is minimal solution to periodic these observations lead us to the following method for computing the value of fx without redundancy we will procedure f with the maintain we will property a global transform that a array f into a call on fx will leave the value of in oi if px can be done immediately according condition by setting is true this to the frontier to otherwise result we call f recursively which has the effect to the values appropriate on ex of for the next lower rectangle in given these values appropriate values the compressed we can set for the current descent result rectangle dag to the as where i and represent mod i and mod j addition m o until i l u then x else n until j n j l until o m n l of course of i and j the roles of c and d are simply by the roles the solution to periodic redundancy a slightly less clear version of this program uses ij locations to store intermediate results instead of the that the only important either ij locations in locations in at the beginning result observe result which are or the end of the second m loop are those in row zero and column zero of result we will introduce global vectors to represent column zero of result and to represent each row of result in the loop iteration turn below row it just before the will of result will represent mk iteration of represent the just after that the kth row of result in the improved version of the algorithm the second m loop is rewritten as follows a until el j m in addition each m and n if the value be expressed of can for in an explicit form which can be evaluated in an amount of time independent of m and n we may eliminate the array argument we omit the first m loop and modify the second by replacing assignments of the form u by t explicit form for at bt when this improvement is possible result takes on the following form the final fx return procedure fx m u px then begin mo until il ti form for n o until j return m form for lq t explicit form for pt at t explicit form for u pt at q again primarily replaced variables form for sequence the use of a notational loops and convenience by a sequence of assignments and we may have a different arrays is loops can be to scalar explicit each value occurring n commutative redundancy definition of commutative finally we consider interpretations for which the only descent condition is that u for all x in this generalization of periodic redundancy will be called figure la shows the minimal compressed condition descent dag our transformation under this descent for eliminating commutative redundancy will be valid whenever the frontier condition holds for the set of functions ie whenever this is the case the dag for the entire computation takes on the shape shown in figure lb where the dag has been turned on its side for clarity ie the frontier between and upward and from point i to point ii formally i and i x for all x in j an following no and example of commutative redundancy is the recursive definition of the of n and k defined for o b dx cx y figure the minimal for commutative redundancy in b the a has been o dag dag of to illustrate the structure of the frontier whenever the frontier condition holds procedure ko ql kn then return else return this is an instance of f with x in in establish xx ax since c and d commute u and on for i yz and j the frontier we show that to for all i and j in if x or xx the of and xj is either or undefined if x then either equal to in which case the is in the legal range and undefined is if otherwise or then in which case it is undefined if xx either in which case is either or undefined the or in which case it is undefined implications of commutative and showed that for each n there exist interpretations for the schema g for which the function f cannot be computed using fewer than n storage locations for partial results an adaptation of their proof shows that this is true even if the interpretations are restricted to be redundant consequently if we are to eliminate commutative redundancy by using global locations to store needed temporary results we will in general have to allocate that storage dynamically the adapted proof differs from only in that it replaces a descent the original tree with the corresponding minimal compressed descent dag for each n we consider the is free except for whenever interpretation the assumptions px is false which that and that is true if and only constant xo the value of descent trees and minimal compressed is displayed in figure for if in for along with the descent dags interpretations and ce a xj bd dx xo cd xo cd xj figure the value interpretations j and minimal compressed each interpretation of under each of l he descent dag are shown the tree for we will show that the computation of under storage interpretation locations n requires at least nl each step of the computation involves either placing the value corresponding to a leaf of the dag in a storage location or taking the values corresponding to children of a given interior node from two storage locations ing the value corresponding to that interior node and placing that value in a storage location we call the dag open if there is a path from the root to a leaf consisting only of nodes whose cor values are not currently held in any storage location otherwise the dag is closed the computation begins with the dag open and concludes with the dag closed with the value corresponding to the root in a storage location thus it suffices to show that n storage locations are required at the moment an open dag like the minimal compressed descent dag for n becomes closed we do this by observing that the computation of under o trivially location and proving that requires computation one storage of under n requires at least one storage location more than isomorphic under mapping from consider a subgraph the following of the dag for n to the dag for the ith node on the kth level of the dag for n is mapped to the node on the intuitively level of the dag for n this mapping creates a graph the same shape as the dag for nl by off the nodes on the upper lefthand edge of the dag for en sequence of see figure operations which now consider a the dag for n leaving the possible storage locations in use at the moment the dag is closed we can map this sequence to a sequence of operations closing the dag for nl by deleting operations involving the node on any level of the dag for n and applying the node described to all other operations mapping however just for the dag for n to be closed at least one value corresponding to the first node on some level of the dag must be in a storage location otherwise the leftmost path in the dag would be open since this node plays no role in the sequence of operations we have created to close the dag for there become closed the moment is a way for the dag for nl using one storage location less of closure than the minimum number to at of storage closure required locations required by n at that is the minimum number by n at the moment the the moment of of locations dag becomes n closed is at least one more than the minimum for n thus we have established that there exist interpretations for for which there is no way to calculate f using a fixed amount of storage even though these interpretations exhibit commutative redundancy solution to commutative define the of x to natural number n such that clearly has a value defined this value can always program be the smallest is true whenever fx is be computed by the i o while not px q x return i dx i il or depending on the interpretation of p and d it may be computable directly for instance if dx x px is xo and x our solution to commutative redundancy will use a global array of locations to compute fx we will use the function without specifying how that function is to be computed the solution is to think of the dag as drawn in figure lb and let the global array represent the result values in a row of that dag another global array argument will hold the argument values in that row we transform f into a procedure which leaves the value of in when is o ie px simply by placing the frontier condition is true this in guarantees that is done is valid otherwise we call f recursively with arguments cx and which places in we then set the array argument so that place and execute the p in i xl o i figure a mapping from the dag for n to the dag for nl the ith node on the kth level first dag is mapped to the node on the level of the second dag of the which leaves in oi at the beginning of the ik through the loop k and ok since k px is false so x thus after the ik through the loop holds the entire program looks like this procedure fx d return procedure m u px w w ax x q return d dx i from o until n x x dx i from m until n until the solution to commutative as before this program can be improved in many cases if can be computed in an amount of time independent of i eg when then argument can be eliminated if neither nor can be computed directly then time would be saved by combining the initialization of argument with the tion of however this would be expensive in terms of space since we would then have to make argument local to save it across recursive calls on f of course the roles of if appropriate throughout the program would be replaced by c and d can be changes are made for instance would become and such changes would result in a more program is usually smaller than if if the value of ax is the same for all x in then be initialized element equal to that constant value with every then the two loops which set elements of to ax for some x can be eliminated this is because the array elements which are set by these loops are not referenced by the program before the loops are encountered conclusions we have presented a recursion schema defining a function f together with various sets of assumptions under which the definition of f calls for redundant computation for each set of assumptions we have investigated the nature of the redundancy and presented a recursive program using the predicate and function of j which computes f without redundant recursive calls as expected we found that weaker assumptions require more computations we also found that weaker sets of assumptions required greater amounts of global storage the use of global variables is only one of a number of implementations which could have been used an obvious alternative would be to rewrite f to return a tuple consisting of those results which will be needed later instead of leaving those results be an obvious in global variables there would correspondence between elements of the tuple and elements of the global arrays this approach seems than the use of global variables but it was that the use of global variables would be more familiar to most readers being more consistent with programming languages such as and algol the each of the versions is of the general of f presented earlier u px else fx ax begin bx where x may be a tuple in which case h maps tuples to tuples and a and b are procedures executed for their side effects on global variables references to the global variables may occur free in a or b the version of f developed for commutative redundancy is not quite in this form but this is easily by moving the assignment to m to just after the recursive call at the cost of computing twice using the direct method of recursion removal described by a we can rewrite f by using a stack s to maintain an of values on which b must still be executed the resulting version of f preserves the order of the calls on a and b procedure fx stack s s while not px do qs ax x x while not hx xs q bx this program may be improved as suggested by and burstall recursion can be eliminated without the use of a stack if there is a single recursive call whose descent function is invertible the resulting program can be made even more efficient when there is a unique base case when h has an inverse x may be set to directly instead of by a stack as above the resulting program fx y x while not py ay a yx wy a y hy by this assumes that neither ay nor by modifies y if this is not the case we can replace ay by z y or by iz y as necessary if there is a unique base case x such that px is true if and only if the initial assignment and may be replaced by the single assignment y xo even if h eliminate the follows has no inverse stack by using we can always a counter as fx fl y x n o while not py y ay hy n nl e o yx c j from until i y hy by although this increases the number of calls on h from some value n to nn it is a reasonable approach if h can be computed very that most of the time is still so spent in the computation of a and b in particular if there is a way to compute the value of in an amount of time independent of i the body of the outer loop can be replaced by the equivalent of even if none of these conditions holds we can compute f with a fixed amount of storage in time proportional to where k is an arbitrary integer using the construction of the amount of space required is ok in any case we have established that the recursive versions of f do not their space complexity in the stack the number of global locations used by each program is a fair measure of these space requirements inter of q explicit common or periodic redundancy can be computed using a fixed amount of storage commutative redundancy really has a higher space complexity generalization to n the methods we present for eliminating redundancy in can easily be extended to yn n in general we will require that the descent conditions functions simultaneously hold for all of the descent redundancy can be eliminated for pn in exactly the same way as for provided that all of the ci are equal on if the ci can be partitioned into kn groups such that all members of any one group are equal on then a similar solution exists using k global variables common generator be eliminated for n in exactly redundancy can the same way as for provided that there is a function which is a common generator of all the ci a general solution to periodic exists provided that there exist c i on descent dag would il in a the minimal consist of such that compressed a chain of the values corresponding to one such stored in a il x i x x in array or by applying an improvement similar to that presented in section by n arrays each of n dimensions and representing of the a the solution for commutative redundancy for p can also be extended to n we require that all the descent functions be pairwise commutative on l and we use an array back whose length in the ith dimension is set to i the procedure f takes on the following for procedure yn u q px then begin set in to ac return d set in to all i in such that qe jc m for for all i in such that in an order which guarantees that ll is always earlier than ij set for each of the four kinds frontier condition for an obvious way of redundancy can be generalized the in we have not addressed the question of what we can do when a particular form of redundancy exists among certain subsets of the descent functions in pn but not among all of them simultaneously additional problems arise when we consider the possibility of different subsets of the descent functions sharing different forms of redundancy or the possibility that only a proper subset of the descent functions are in any way neither have we discussed the more general situation not an instance of n for any n where the number of recursive calls invoked by call fx depends on x the dynamic programming examples of aho hopcroft and unman are of this form the program transformations presented here can be applied to actual more importantly they can be incorporated in automatic program transformation systems one such system is described by burstall and that system uses heuristic methods to a series of simple but powerful to recursively defined functions one of the most effective transformations however the definition of new functions in terms of old ones has not yet been automated among the examples of definition presented by burstall and is the definition of a function which returns a tuple consisting of the nth elements of the series by calling itself recursively to obtain the values of the and nth elements of the series but that is exactly the program that would result by our transformation for common generator redundancy to the usual recursive program provided that we used return values instead of global variables the methods presented in this paper provide both a way to recognize a particular situation in which a definition would be useful and a way to formulate the definition itself effective procedures exist to find true descent conditions given of straight line code which compute descent functions let ul and vi vr be blocks represent the block obtained by executing let block bl and then using its output as input values to block b and let for nl with lewis proves that it is possible to compute values ul of it computes the jl jr for which same function as a general definition of redundancy each form of redundancy we have discussed has involved descent functions calls arise because repeated applications of which commute arguments are the same two just or n descent orders functions in fact in but irrelevant each minimal compressed descent dag we have discussed is a compression of the minimal compressed descent dag for commutative redundancy this is not meant to imply that the descent functions must commute in order for an interpretation program or n to to the contrary whenever the maximum number by k applications define a redundant redundancy exists of distinct values of the descent functions to some value is less than nk for all sufficiently high k clearly whenever this condition holds there is going to be a duplication of argument values on the kth level of the descent tree in fact a sufficient condition for redundancy is that the number of values by k gr fewer applications of the n descent functions is less than for sufficiently high k this guarantees that there is a duplication of argument values in the first k levels of the descent tree one example of redundancy commutativity is a recursive program the solution to the of string the program is not due to which returns problem as a procedure no then else return return ii this is an instance of with x px u xo y ax cx u e u and dx observe that c and d do not commute if they did this would be an example of periodic redundancy since cx dx u on each level of the descent tree n is constant and there are only six possible permutations of from to and using so there can be no more than six distinct values at each level of the descent tree in fact there are at most three distinct values at each level of the tree since three of the permutations can only result from an odd number of applications of c and d and the other three only from an even number the descent tree and minimal compressed descent dag for a typical computation of are shown in figure bc c d dc d c d b c cd c ob cd a cb c d c d c d l d io bc c d cd c s o cb figure the descent tree and minimal compressed descent dag for the call in the tree left sons represent applications of c and right sons represent applications of d in the dag edges are labelled according to the descent functions they represent edges coming in from the right edge of the page are continuations of edges leaving the leftmost node of the previous level and versa the dag does not get any after the third level as this example demonstrates our of is characterization far of other from complete forms of redundancy the and the formulation applicable to of program those forms of transformations redundancy are topics for future research it may be possible to formulate a general theory of redundancy which all these forms tion of redundancy in terms the the number of distinct values by k or fewer applications of the descent functions typical component of such a theory would be a appendix the set relatively prime m and n we will prove the following results about the set u m and n are positive integers prime the largest natural in is mn number not included in all there are natural numbers not included exactly in mn note that if m and n are relatively prime all integers are expressible in the form where a and b are integers is the subset of the integers obtained by restricting a and b to be nonnegative proof of the first result it wellknown that the set lm s contains exactly one representative of each congruence class mod n in fact each of the n numbers in that set is the smallest member of its congruence class which is in sm n once a congruence class is introduced into by one of these n numbers all larger numbers in that congruence class may be generated by adding appropriate any number generated of n by adding a multiple clearly of n to a member of is itself a member of the number is the last number in sm n which introduces a new congruence follows that all numbers greater than class it are in furthermore the n integers immediately preceding belong to congruence classes introduced into and therefore belong to themselves the number preceding these nl integers however belongs to the mod n congruence class which is not introduced until so it cannot be a member of sm n this number is therefore establishing the number not in the first result a similar sm n of this result appears in a different context in proof of the second result in place of our original proof of the result we present a much and more proof by the proof use of the following lemma second elegant makes lemma let m and n be relatively prime positive integers any x in not expressible in the form ae is expressible either as with an and bo or as with and ao proof by algorithm any integer can be expressed in at least one of the four forms by hypothesis x cannot be expressed in the first form since xo x is in and not zero since x be expressed in the fourth form is expressible either as or assume and let then x u since a mod n since x cannot be expressed in the form must be negative ie if we assume that the proof is analogous lx let k mn we have shown that k is the the form as then then k integer not expressible in suppose i is expressible ki cannot be for if expressed conversely as suppose that i cannot be by the lemma i can be expressed either as with bm and ao and in the with an and bo or as in the first case ki where na second case ki where and mb thus for i is expressible in the form if and only if ki is not furthermore whenever this establishes a correspondence between those members of k which are in sm n and those which are not it follows these integers that half or kl are in since k is of the integer not in sm n there exist in all kl of which are not in acknowledgements the author is to thomas lewis and for their careful reading of the manuscript and many helpful suggestions references aho hopcroft and iii the design and algorithms addisonwesley massachusetts unman jd of computer reading rs elimination al notes on recursion no june pp rs b improving introduction of recursion november pp programs by the cacm no burstall rm transformation recursive january and system programs pp j for developing no a ak linear record efficient compilation of recursive programs conference th annual g automata pp j and burstall rm a system which automatically improves programs informatica no pp lewis hr a new decidable problem with applications proceedings qq foundations ieee th a science pp ms and ce record of conference concurrent parallel pp jl the equivalence problem for regular expressions over one letter is elementary conference record ti annual switching and pp strong hr translating equations into flow june pp recursion in the solution the sequence to commutative x x dx q i from m until n should be replaced by i from o until l x dx x q i om until without this correction a problem arises for some x in invocation of f with arguments cx m will be set to nl and the of the second loop will not be executed once consequently the first time that the of the loop when the and body even body i m m until o is executed undefined one element base rule in the correction is each invocation initialized of f will be that at least using the 