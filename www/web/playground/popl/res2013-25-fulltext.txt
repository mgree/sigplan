highlevel separation logic for lowlevel code b it university of copenhagen benton andrew kennedy microsoft research cambridge abstract separation logic is a powerful tool for reasoning about structured imperative programs that manipulate pointers however its application to languages such as assembly language or machine code remains challenging in this paper we describe a separation logic for this purpose that we have applied to x programs the logic is built from an assertion logic on machine states over which we construct a specification logic that uses of frames and step indexing the traditional notion of hoare triple is not applicable directly to machine code where code and data are mixed together and programs do not in general run to completion so instead we adopt a continuationpassing style of specification with preconditions alone nevertheless the range of primitives provided by the specification logic which include a higherorder frame connective a novel readonly frame connective and a later modality support the definition of derived forms to support reasoning for common cases in which standard rules for hoare triples are derived as lemmas furthermore our encoding of labels lets us give definitions and proof rules for powerful macros such as while loops conditionals and procedures we have applied the framework to a model of sequential x machine code built entirely within the coq proof assistant including tactic support based on computational reflection categories and subject descriptors f logics and meanings of programs specifying and verifying and reasoning about invariants logics of programs mechanical verification pre and postconditions specification techniques d programming languages language macro and assembly languages d software engineering software program proofs formal methods general terms languages theory verification keywords separation logic machine code proof introduction formal verification is one of the most important techniques for building reliable computer systems research in software permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm tion typically and quite reasonably concerns reasoning about the highlevel programming languages with which most programmers work but to build systems one really needs to verify the machine code that actually runs whether it be or the output of a compiler this is particularly important for establishing security properties since failures of abstraction between the high and lowlevel models often lead to and because machine code is often found in places such as kernels a further motivation for verifying lowlevel code is that real systems are composed of components written in many different languages machine code is the only universal by which we can reason about properties of such compositions finally experience shows that lowlevel programs are simply much harder to get right than higherlevel ones increasing the gap between formal and informal verifying lowlevel programs and compilers that produce them both have a long history and since such are like lowlevel programs themselves extremely and some form of mechanical is crucial this often takes the form of automated decision procedures for firstorder logic and various more specialized theories combined by an smt solver here however our focus is on deductive verification of programs using an interactive proof assistant in our case coq this requires more manual effort on the part of the user but allows one to work with much richer mathematical models and specifications which are particularly important for modularity both approaches to also have considerable history with much work applying interactive provers to lowlevel code having been done with the prover in the s recently however an confluence of advances in foundational theory program logics most notably separation logic and the technology of proof together with increased interest in formal certification have led to an explosion of work on mechanized verification of real or at least realistic software including compilers and operating systems although many of these do involve reasoning about machine code or assembly language programs program logics for lowlevel code are generally much less satisfactory and more ad hoc than those for highlevel languages the design of a highlevel program logic to follow closely the structure and abstractions provided by the language commands in a for example may be modelled as partial functions from stores to stores which are only combined in certain very restricted ways the classical hoare triple relating a predicate on inputs to a predicate on outputs is a natural indeed and generally satisfactory form of specification for such functions furthermore the structured form of programs leads to particularly elegant syntaxdirected program logic rules for composing machine code by contrast has almost nothing in the way of inherent structure or abstractions to guide one supports patterns of programming and also involves a host of the include large instruction sets with encodings the need to work with operations and arithmetic mod alignment a of flags registers addressing modes and so on these cause some but are just the sort of thing proof are good at checking precisely and with a formalization removing some of the from there is of course complexity of a quite different order associated at both high and lowlevel with concurrency ­ especially relaxed memory models on ­ which we do not address at all in this paper even in the sequential case however the lack of inherent structure in lowlevel code is a fundamental problem machine code features control flow a block of instructions potentially has many entry points and many exits with the added that the same bytes may differently according to the entry point machine code is almost entirely untyped and higherorder with no runtime tagging any word in memory or a register may be treated as a scalar value a pointer or a code pointer and common coding patterns do make use of this flexibility bits in pointers storing metadata at offsets from code pointers computing branches and so on finally code and data live in the same heap allowing code generation code and code for example for interpreting instructions the most basic abstractions such as memory allocation or function calling are not built in but are conventions that must be specified followed and verified at appropriate points furthermore code that implements even the simplest of these abstractions such as firstorder function calls uses features of machine code whose highlevel higherorder dynamically allocated local state are challenging to reason about ­ and a subject of active research ­ even in very highlevel languages such as ml some logics type systems and analyses for machine code deal with these by structure and restrictions on the code they deal with for example one can enforce a traditional basic block structure memory allocation as a special or treat calling and a such techniques can work well for verifying code that looks like it from a c compiler but we would like something more generally applicable able to verify higherorder code systems code such as and and code that uses representation in previous work for example on compiling a functional language to a rather assembly language one of us has proved useful results in coq using a shallow embedding of stepindexed separated predicates and relations a notion of for code pointers explicit secondorder quantification for and a ad hoc collection of lemmas for instructions quantifier manipulation and entailment given sufficient effort such an approach can be pushed through but the proofs and specifications are very although some of the connectives have properties there is certainly no sense that one is working in a program logic with a wellbehaved proof theory applying such a naive approach in the context of real machine code with the and in which we would clearly need to build numerous higherlevel proof abstractions to work well separation logics for higherlevel languages by contrast do have a good proof theory in particular work on higherorder frame rules allows local reasoning about higherorder programs allowing invariants to be onto commands in context by logics for highlevel languages often ignore arithmetic even when that is what is provided by real implementations them through the specifications of parameters a major goal of the work described here is to bring the power and of higherorder frame rules to reasoning about programs at first it may seem how to incorporate even the firstorder frame rule p c q p r c q r into a system for reasoning about machine code the frame rule is typically justified using a global property of commands with respect to a semantics defined over partial heaps if a command executes without in some heap then it does so in any extension of that heap and moreover if it terminates it preserves the extension partial heaps in the semantics model a builtin allocator but as in our previous work in lowlevel code we do not wish to define the ground semantics with respect to which we interpret specifications using partial heaps whatever memory is in the machine is there all the time and the allocator is just another piece of code to be specified and verified in our framework secondly the postcondition of a triple corresponds to the single exit point of a firstorder command machine code fragments do not have single exits or even a natural local notion of terminating execution we are ultimately concerned with the observable behaviour of whole programs and do not wish to restrict ourselves to a form of specification that relies on the intensional property of reaching a particular intermediate program counter value we thus take our basic form of safety specifications to be one that only involves a precondition execution from a given address in a state satisfying the precondition is safe as it is not obvious how to a frame soundly to such a specification we address these problems by going beyond a shallow embedding of specifications of individual program points to an embedding of a specification logic making the context within which code fragments are proved explicit and with a semantics that captures but a surface notation which the way in which frames are preserved the specification logic allows one to work with subtle patterns of invariant preservation but does not impose particular forms of specification rather it provides building blocks from which more complex patterns including hoare triples may be built the rich wellbehaved theory of the core logic allows derived rules for new forms of specification to be expressed and proved we have formalized our specification logic in the coq proof assistant and instantiated it for the particular case of a model for sequential x machine code our formalization also includes a range of reflective tactics for solving separation and performing specification logic proofs at a high level of abstraction this paper mainly discusses the logic in a way but we use the x instantiation for examples and motivation in summary the contributions of this work include a separation logic for machine code that supports both first and higherorder frame rules accounts of connectives including a readonly frame a later modality and a full range of intuitionistic connectives all with good logical properties examples of higherlevel patterns such as hoare triples and associated proof rules being defined within the logic an certified supporting convenient macro definitions with internal label generation and natural derived proof rules with examples including constructs and procedure calling a semantics involving no or other modifications to the underlying machine model memory can be total and and auxiliary variables happen only in the logic all this is formalized in coq with an instantiation for x machine code and tactic support for highlevel proving the formalization is available via the authors web pages machine model our separation logic is not to any particular machine architecture but in order to illustrate its application we will be presenting examples from bit x the architecture for which we have built a model in coq in this section we present enough concrete detail of this model to support subsequent sections we have modelled a subset of the bit x instruction set considering sequential execution only but treating memory registers and flags in sufficient detail to obtain accurate specification of its behaviour machine words and arithmetic we model machine words simply as tuples of boolean values an indexed type in coq for the purpose the x architecture makes various use of bit byte bit word bit and bit values and so types in coq are a to specification logical and arithmetic operations are defined directly in terms of bits although to prove useful properties of arithmetic it proved to map words into arithmetic modulo n making use of the library for algebraic identities machine state the state of the machine is described by a triple of registers flags and memory state s reg × flag true false undef × byte register state is a straightforward mapping from the xs core registers eax and to bit values the instruction pointer register is the xs program counter and points to the next instruction to be by the processor rather than model the special as a monolithic register we split it up into flags the undef value represents the undefined state in which many instructions leave flags any dependence of execution on an undefined state such as in a conditional branch instruction is then treated as unspecified behaviour memory is modelled straightforwardly as bytes with the possibility that any byte might be missing or for now we are not interested in such as readonly or though it would be a simple matter to incorporate these notions it is however important to note that the of memory has nothing to do with the partial states of separation logic indeed we could choose to model and fully specify the x support for fault handling using the very same logic instructions any machine model must of course include a datatype of instructions the x instruction set is large and but by careful and factoring our datatype is made reasonably concise figure presents the instruction datatype with only some names changed for the purposes of this paper instruction the x instruction format is also complex being variable in length and not canonical a single instruction can sometimes be encoded in many ways we have implemented an there is no particular reason for choosing x over x or arm typeof d if d then else byte scale s s s s reg × option × scale × d d src d rr rm mr ri d mi d add and or sub inc dec not pop bt count condition o b z be s p l le d d false test d d mov d d dir bool push pop call jmp ret figure instruction datatype instruction as a partial function × byte × such that if m j then memory m from address i up to but not including address j is defined and to instruction the reads memory incrementally returning an undefined value if memory is or out of range or if the contents do not describe an instruction in our chosen subset there is no need to specify explicitly a maximum instruction length lifting to machine states and the updating of the register through yields a partial function in s s × instruction execution instruction execution is given by a partial function on states s × s which when composed with instruction gives rise to a smallstep transition function on machine states step s s when this function is undefined it means that either a fault occurred such as the of an illegal instruction or an access to memory or behaviour is simply unspecified such as branching on an undefined flag assertion logic partial states assertions in separation logic describe a subset or footprint of the machine state for highlevel imperative programs with dynamic allocation this footprint consists of a subset of the heap indeed a common idiom is to prove that some code starts or with an empty heap here there is no such thing we have the whole machine at our and we must out our own abstractions such as heaps or stacks so the footprint is simply that part of the state that we care about right now we also find it useful to use separation in describing the manipulation of registers and flags and so define partial states as follows noting the to the definition of total states in section reg × flag true false undef × byte there is a partial binary operation on elements of defined when its operands have disjoint domains on all three tuple components and yielding a tuple with the union of each of the maps this makes a separation algebra ie a partial commutative monoid assertion logic an assertion is a predicate on partial states p since is a separation algebra its powerset forms a complete boolean bi algebra ie a model of the assertion language of classical separation logic where the connectives are defined in the standard way x t p x xt p x x t p x xt p x p q p q emp p q p q p q p q the propositional connectives and are just binary and special cases of and respectively as usual entailment is defined as p q p q and we write p for p and p q whenever p q and q p there is a notion of pointsto for registers and for flags r v r v f b f b the meaning of the pointsto assertion for memory ij v depends on the type of v this is done using a type class in our coq implementation for byte and types pointsto means that memory from address i to j contains that value in these cases j is uniquely determined to be i or i respectively for syntactic assembly instructions it means that the memory at ij to in other words m j where m is the memory component of the state instruction encoding is not unique so more than one byte sequence in memory may to the same we write i v to mean j ij v discussion another option would have been to let the registers and flags behave like the stack in traditional separation logic and not split them over this is the approach taken by shao et al and but it leads to the side condition on the frame rules that the program may not modify any registers mentioned by the frame in a setting where programs have multiple entry and exit points and may be it is not even clear what that side condition means or how to check it so we instead make registers and flags split across following et al specification logic safety we extend the partial function step s s to a function run n × s s where s is the state that results from successful execution of k instructions starting from state s unlike the highlevel languages typically modelled with hoare logics a cpu has no natural notion of a computation it will run forever until it either or power this means that we cannot apply the standard approach of describing a computation by a precondition and a postcondition since there is no meaningful time to check the postcondition instead specifications around safety we the safe machine configurations as the set of pairs k p n × such that the machine will run for at least k steps without if started from a state in p safe k p p s s s s s the relation s states that all the mappings in are also found in s this is how we connect the partial states found in assertions to the total states executed by the machine example it is safe to in a tight loop forever that is k i k i i jmp i safe the register is the instruction pointer and jmp i is an jump to address i the proof goes by induction on k the number k plays the role of a step index we are ultimately always interested in proving computations safe for an arbitrary number of steps but an intermediate step index gives us a value on which we can do induction as a running example we will attempt to specify the jump instruction we can show that for all i a k r k q r safe k p r safe p i i jmp a q a i jmp a where and in words if you need to show that p r is a safe configuration for k steps it suffices to show that q r is safe for k steps when a specification follows this pattern we can think of p as a precondition q as a postcondition and r as a frame the specification does not say that q r will ever hold rather it requires that if q r does hold then we are in a safe configuration this can be seen as a cps version of hoare logic which is appropriate for machine code since nothing ever returns or at this level we will refine this specification in later examples as we develop constructions at higher levels of abstraction specification logic reasoning directly about membership of safe is since the step index and frame are explicit and visible even though their use always follows the same pattern the solution is to instead consider safe as a formula in a specification logic we define a specification to be a set of of k p pairs that is closed under decreasing k and under arbitrary assertions onto p spec s k p s k k r k p r s even when it it will typically and so keep running but this behaviour is outside of our model intuitively a specification s spec describes how many steps the machine has to execute before it no longer holds and what frames the execution will preserve this idea comes from the work of birkedal and yang on higherorder frame rules and spec is essentially a stepindexed version of specification logic model the definition of spec is such that safe spec furthermore spec is a complete algebra and thus a model of intuitionistic logic this gives us a notion of entailment and the logical connectives with the expected rules the definitions of the connectives follow a standard kripke model x t sx xt sx x t sx xt sx s s k p k k r k p r s k p r s again the propositional connectives and are just binary and special cases of and respectively notice how the semantics of requires arbitrary frames to be preserved across the implication this was not a choice we made ­ it is the only definition that makes be the right adjoint of and it out of giving standard kripke semantics we also get two new connectives the later connective and the frame connective we will define and discuss these in the next two they will enable us to state the specification of the jmp instruction from section more a a we can even factor out the duplicated part of the assertion and just write safe a safe i i jmp a or informally reading from right to left given that i points to instruction jmp a it is safe to execute with the instruction pointer set to i if it is later safe to execute with the instruction pointer set to a frame connective following the literature on higherorder frame rules we define the frame connective spec × spec as s r k p k p r s this is also known as the invariant extension connective because an intuitive reading of s r is that the computation described by s is allowed to additionally depend on and maintain the invariant r note that by the definitions safe p iff k r k p r safe relating judgements in the specification logic with the safety of executions since we defined spec such that any s can be extended by any invariant we can immediately prove the higherorder frame rule s s r frame the frame connective over all other connectives including and itself that means for example that s s r s r s r it also with emp and as follows s emp s emp s r r s r r example we can now start to see why frame should be thought of as a frame rule assume we have proved for some p and q that safe q safe p then by frame and we can derive safe q r safe p r this looks like the standard frame rule and it performs the same function to extend both pre and postcondition by an invariant the formula s r is covariant in s with respect to entailment meaning that ss sr s r the variance in r is more complicated and will be discussed in section example to illustrate informally how frame the standard firstorder frame rule consider a program in a highlevel functional programming language f unit unit unit whose specification is for some particular p q and r g p r g q r p r fg q r that is f the specification of g most likely f simply applies its argument to the unit value but assume that it has been verified separately and we should not see its implementation if we have g with specification p g q we cannot immediately apply fg since the specification does not match what f requires however we can apply the ordinary frame rule to deduce that g also has the specification p r g q r and then we can call fg if we are in a state satisfying p r now instead consider an f with the specification g p g q p fg q and a g with specification p r g q r it is impossible with just the standard frame rule to call fg since the specification of g cannot be refined to match what is assumed by f but with the higherorder frame rule we can instead refine the specification of f to be g p g q p fg q r g p g q r p fg q r g p r g q r p r fg q r it is now compatible with our g without the higherorder frame rule we would have had to either the implementation of f or the original specification of f to explicitly quantify over all possible frames that may be through the latter option is essentially what the definition of spec does but this is and implicit using to give concise and modular specifications to higherorder functions is as important here as in any other separation logic but that is not our main reason for including we do it because it allows our logic to have a frame rule despite the program being and lowlevel uses explicit secondorder quantification in place of a frame rule shao et al have a frame rule that only applies to judgements in a very restrictive specification logic in particular it does not apply directly to specifications of function pointers later connective just as we hide the explicit frames using we hide the step using the later connective this is a trick by that exploits the fact that we are never interested in the absolute number of steps but only that they are the same or differ by exactly one between two specification formulas we define s k p k k k p s because any s spec is closed under decreasing steps an equivalent definition is that p s for all p and k p s iff k p s the closure under decreasing steps is expressed logically as the rule weaken ss as mentioned in section the purpose of step is to serve as a handle for induction we can phrase the induction principle on natural numbers using the following rule which is named for its similarity to a corresponding rule in logic ss s b the rule is a of the strong induction principle for natural numbers if k k p k p k for all k then p n holds for any n it is a powerful rule in that it almost allows assuming the formula one wants to prove except that the assumption may only be used after taking one step of computation example recall the specification of a tight loop from example we can now express and prove that inside the specification logic in just two steps safe safe safe i i jmp i i i jmp i i i jmp i b the connective over every other connective we have mentioned except for and existential quantification over empty types discussion like we saw in the rule for jmp equation every step of computation allows us to relax our remaining proof obligation by adding a for example we could prove that nop where nop is the instruction there are two s on the postcondition of because it takes two steps of computation to get there it turns out however that it is never useful to have more than one applied to a specification since the purpose of step is to do induction and induction will always give us the necessary assumptions on the immediate predecessor of the number of interest furthermore we have found that is not necessary in code that only moves forward induction only makes sense when verifying loops and a loop requires some form of backward jump unless we consider code therefore in practice we would state without any connective at all readonly frame the instruction rules we have discussed so far are too weak for some purposes recall the rule for jmp safe a safe i i jmp a because the meaning of i jmp a is only that the memory starting at i to jmp a the rule would be satisfied in a semantics where the jmp instruction not only performed the jump but also replaced its own machine code in memory with a different byte sequence that also to jmp a this would be a problem for programs whose code needs to eg to verify that the of the code remains the same our solution is to make this specification more precise by the readonly frame connective defined as s r r s a more precise specification for jmp is then safe a safe i i jmp a intuitively s r requires s not only to preserve the truth of r but to leave the underlying state fragment that made r true the state may be changed just as r might be broken as long as it is at the end of the computation described by s like for there is a frame rule s s r the connective does not over every other connective like does but it does over it only in one direction over and a sa r a sa r s s r s r s r the formula s r is covariant in s and contravariant in r with respect to entailment meaning that ss rr s rs r another convenient property is that existential quantifiers can be moved in and out of the frame s x rx x s rx these last two properties of about variance and with do not generally hold for the cases where they hold are discussed in sections and we explore further properties of in section discussion this connective is of fractional permissions but more and lightweight we mention connections to other notions of weak ownership in section our definition of may not be the only good one but we have examined three other candidate definitions and found that the one given above had the most convenient properties for our purposes the candidates relate to each other as follows r r s r r r s r r s r s highlevel assembly code basic blocks using safe and the connectives discussed so far we can specify code with multiple entry points and exit points jumps to code pointers and so on in practice though most code is much simpler for code that behaves like a basic block with control flow always coming in at the top and going out at the bottom we can describe its behaviour with a hoare triple defined in the specification logic as p c q i j safe j q safe i p ij c example the instruction mov r v move literal v to register r can be specified as r mov r v r v where r is shorthand for v r v this is much more compact and readable than writing the specification in terms of safe this triple satisfies the structural rules we expect from a hoare triple in separation logic p p s p c q q q s p c q s x p x c q s p c q s x p x c q s p r c q r the frame rule for the triple follows from frame and the fact that into the triple p c q r p r c q r triple there is no rule of conjunction for the triple since this would be unsound in the presence of frame discussion this kind of triple is certainly not the only useful one one could also adapt the triples of and gordon to this setting allowing use of the triple in specifying code with multiple entry and exit points it would be a matter of whether this more convenient to work with than reasoning directly in terms of safe the triple defined here can be thought of as encoding a very simple calling convention inlining ie concatenation of code we defining triples for other conventions as needed and proving similar properties about them see section for another example it is a valid question to ask why there is no on the postcondition part of the triple so it would read safe j q it would give stronger specifications for single instructions like in example but as discussed in section it would also be unnecessary since control flow always moves forward in a triple we will also see in section that there are useful values of c that take no computation steps rules for x instructions with a variety of logical building blocks in place we can give simple rules for x instructions these split into instructions that do not touch the instruction pointer for which we can use the form and control flow instructions for which we describe their effect on the instruction pointer explicitly example the following rule for add register indirect with offset is a typical instance here d is a literal offset and addition of two bit values produces a pair c v where v is the bit result and c is the carry into bit r v of sf zf cf pf add r r d r v of v v v sf v zf v cf c pf r w w d v where v v c v v the ¬ and operators are boolean negation and respectively the instruction affects flags of sf zf cf and pf whose values initially are arbitrary f is shorthand for f f f where f may be undef notice the of invariant registers and memory example for the instruction we specify two postconditions the first for when the branch is taken and the second for when it safe b a zf b safe ¬b j zf b safe i zf b ij a note the use of the later connective when the possibly backwards branch is taken our approach is to give a very general specification to each instruction and then on top of that provide convenience definitions for common cases in a sense our rules are therefore just a logical of the operational semantics which may seem a bit but turns out to be a strong platform on which to build higherlevel layers of abstraction instruction encoding and assembly language we have implemented an for syntactic instructions and it has the property that ij ij that is if the memory at ij contains the sequence of bytes then that memory will to the instruction the instruction referred to here is the same one that is part of the operational semantics for the machine the encode function takes i as parameter because the encoding of x instructions is not generally this is the main in our a certified and executable coq function that takes a program as input and produces a list of bytes as output a program is a value in the following inductive definition p skip p p l local l p that is a program is essentially a list of instructions with label l a label l may be declared local to program p with the local l p construction a label is simply a memory address ie a bit word and it can therefore be used as an argument to jump instructions the following is a closed program that loops forever local l l jmp l the local constructor in our coq implementation has type program program so writing local l p is just syntactic sugar for pl the benefit of modelling label with function spaces is that coq handles all aspects of label naming including the necessary and conversion the is that it is not to statically rule out programs such as programs that place the same label more than once the function is partial and maps an address and a program to a sequence of bytes it is undefined if the program is where defined it has the correctness property that ij p ij p here ij p is defined recursively as follows ij ij skip ij p p ij local l p ij l ij i j emp i ii p i j p l ij pl i j l emp recall that the definition of triples p c q in section did not require c to have a particular type the definition and its rules are valid for any c that can occur on the right of a pointsto thus we can put a program p in a triple and it turns out that the following rules hold p skip p s p p q s q p r s p p p r s p q s p q s l p pl q s p local l p q there is no useful rule for the case of l in a triple example we cannot specify jmp with a triple in any useful way but we can specify the special case of a tight loop shown above emp local l l jmp l the proof is by first applying the triple rule for local then unfolding the definition of the triple and applying the result of example assembly macros a useful assembly language has not only labels but also macros ie definitions that expand to instruction sequences when invoked we get macros almost for free since assembly programs are written and parsed inside coq and can be with all the features of its term language this includes fixpoint computations custom syntax coercions overloading and other features of a modern programming language an example of a very useful macro is the following definition of t b p where p is a loop test p is a loop body t encodes the combination of processor flags to be on and b is a boolean that indicates whether the test should be t b p local l l jmp l l p l p t b l the instruction is the general conditional jump on x we see here how local lets us declare labels that will be fresh for every invocation of the while macro realworld macro also have that functionality although the scope is usually to the named macro or global label our coq notations for assembly syntax including local are chosen to be compatible with the microsoft macros such as while give us the usual convenience of not having to write similar code many times but even better it lets us avoid writing similar proofs many times if the body and test can be specified in terms of a triple then the loop as a whole also has a triple specification s p p b ib b s ib b p p s p t b p ¬b while here b translates t of type condition from figure to an assertion that tests the relevant flags for example b zf b where zf is the zero flag there are two loop invariants p and i representing the state before and after executing the test p since this may have side effects the proof of the while rule involves operators and the b rule but these do not leak out into the rule statement with if and while macros and the sequence operator on programs we have the building blocks to easily write and verify programs with structured control flow these constructs also facilitate using our assembly language as the target of a verified compiler from a structured language which is something we hope to investigate more in future work procedure calls the triple p c q encodes and abstracts the programming pattern of structured control flow another crucial pattern to capture is procedure calls we will here show the theory of a very simple calling convention store the return address in register and jump to the procedure entry point the following macro calls the procedure whose code is at address f call f local mov jmp f the calling convention does not specify how to pass arguments or return values this is instead part of individual procedure specifications a more realistic calling convention would maintain a stack of arguments and return addresses to allow deep call hierarchies and but this would our examples with arithmetic side conditions because the stack has to be finite the following definition describes the behaviour of a procedure starting at f with precondition p and postcondition q f p q safe q safe f p recall that is shorthand for v v this definition satisfies the usual rules for a formula including f p q r f p rq r proc in contrast with the triple defined in section this definition of a procedure specification does not mention the code stored at f the code should be mentioned separately from its behaviour such that the footprint of the code covers both the caller and the callee the rule for calling a procedure looks fairly standard f p q p call f q call it reveals that is as part of the calling convention the modality on the premise together with b permits sion example this is the first of three examples to illustrate independent verification of caller and callee consider the following definition of a program that calls some procedure at f twice call f call f if the intention with this program is to compose it with a procedure that satisfies a f eax a then we can specify the caller as eax a eax a we can prove this specification directly from the program sequencing rule and call no connective is put on the assumption since no recursion is intended if a procedure body p is structured and returns at its very end we can prove its specification through the following rule s p p q s f p q f p jmp body in words this means that calling f behaves as p q when in memory where the program p jmp is at address f assuming we can prove the given triple which is allowed to access as long as it its value in the end example the following program almost satisfies as defined in example inc eax inc eax jmp we say almost because the inc instruction affects the status flags of the cpu as a side effect the caller is not interested in the flags but they have to be in the specification of since they do get affected let flags be the assertion that all flags are of some existential value then we can prove flags f the proof is by applying body whose conclusion matches the above specification after rewriting by proc the next example demonstrates how to compose a caller and a callee even if the callee has a larger footprint than what the caller assumes this shows how to execute the informal reasoning from example in our logic example we can now compose the implementations of the caller from example and the callee from example to obtain the following closed program we arbitrarily choose to place the callee in memory before the caller local f f entry we can give the following specification to this program which says that the code between entry and j will increment eax by and step on and the flags safe j eax a safe entry eax a flags ij the crucial step in proving this specification is to satisfy the callers assumption with the callee specification which is essentially flags the former entails the latter but here we would need the entailment to go the other way instead we exploit that frame is a higherorder frame rule and lets us frame an assertion on to the left and right side of an entailment simultaneously this is allowed by the rules and from sections and a eax a eax a we can derive flags flags ex flags f flags f we know from example that flags f so by transitivity of we conclude flags f from this it is straightforward to derive our desired specification for the preceding example showed how to use frame as a secondorder or frame rule the procedure involved was firstorder at runtime though the following example involves a proper higherorder procedure ie a procedure that takes a pointer to another procedure as argument example the simplest example of a higherorder procedure is apply which in a functional programming language would be defined as x gx in our an apply procedure that takes its g argument in register is implemented simply as jmp its specification reflects how it the behaviour p q of g gp f p f practical verification we have used our coq development not only to build a machine model and to validate the logic developed in this paper it is also an environment for building and verifying actual programs in this section we describe the coq tactic support that we have developed for making machine code verification and present a slightly larger example of assembly language instructions in order to give a of the coq proof of its correctness example memory allocation we illustrate the use of the logic rules and coq tactics with a slightly more challenging example the specification of a memory allocator and its simplest possible the of a pointer and checking it against a limit its specification is as follows parameterized by the number of bytes n to be allocated and an address fail to jump to on failure fail inv code i j safe fail safe j a an a an safe i flags inv ij code the specification is by an assertion that register is used as storage flags are updated arbitrarily and an internal invariant inv is maintained the latter might be the wellformedness of some representation of free lists or in our trivial allocator simply a pair of pointers the calling convention is inline in other words the allocator is just a macro consisting of assembly in code in section we will wrap a slightly less trivial calling convention around it control either through if successful or branches to address fail if memory cannot be allocated on success the allocator leaves an address a in that is just beyond the n bytes of memory that were allocated on failure is perhaps surprisingly even a implementation consists of instructions n fail mov mov add n jc fail jc fail mov the implementation invariant inv is the following base limit base limit base limit in other words at address there is a pair of pointers base and limit that bound a piece of mapped memory applying instruction rules during a proof we typically keep the goal in the form s safe p r the specifications discussed in this paper are easy to put into that form by applying distributivity rules for and nested implications and we have implemented a tactic to do this automatically typically r describes the code to be executed and p describes the instruction pointer and the remaining state that will go into proving the precondition of the next instruction we may use the full range of rules on this goal but eventually we will want to apply the lemma appropriate for the code that is pointing to in p we assume that the lemma has the same form as the goal and apply a lemma through the following rule s ctx s ctx p r s ctx s ctx s safe p r s ctx p rp r s s rp r s safe p r the top premise is the lemma to be applied and the bottom premise is the remaining proof obligation that describes the symbolic state after having applied the lemma if the lemma is an instruction rule the three middle premises correspond to satisfying its preconditions at the level of specifications data memory and code memory respectively the latter two can be dealt with by our entailment checker described in the next subsection assertion entailment solving much of the activity in a formal separation logic proof is proving entailment between assertions this happens every time a precondition needs to be and if it is not automated the proofs will in the details of manual context manipulation and rewriting modulo associativity and commutativity typically we are given a description of the current state p and a precondition p and we must show p p r for our own choice of frame r which represents all the state that was not consumed by the precondition and can therefore be out our approach to this automation is similar to other tools if p and p consist only of emp and atomic assertions we iterate through the conjuncts of p to unify each with a conjunct found in p and let the two out typically p is full of holes corresponding to variables that have yet to be instantiated the holes are represented in coq as unification variables which are identifiers that will receive a value upon being unified with a from p several of p may unify but typically only one choice will permit the entailment as a whole to be solved for example we may be proving eax i j i eax u u u where u and u are unification variables of type if our algorithm should attempt to unify the atom u u with the atom j it will succeed but the remaining proof obligation will be eax i i eax j the algorithm succeeds even if it did not solve the goal entirely leaving the rest to be proved but in this case there is no solution for the remaining part of the goal rather than try to support backtracking which does not combine well with interactive proof we make the algorithm greedy but of p are unified from left to right in our current example this would first fix the choice of u to be i and the second conjunct of p would therefore become i u which rules out the bad unification choice from before there is of course no guarantee that this always works but we have found that it always works in practice as long as preconditions are written with this lefttoright order in mind this happens naturally since it is also more readable for who read from left to right if the algorithm should still fail it remains possible to manually instantiate the unification variables the entailment solving algorithm is implemented with a hybrid approach where the unification is done by builtin higherorder unification engine while the of identical terms is done with proof by reflection which has good performance if an entailment has existential quantifiers on the lefthand side we can apply the rule x cp x q cx p x q where c is formula with a hole that contains only connectives in the path from the root to the hole this lets us effectively move the quantified variable into the coq variable context if an entailment has existential quantifiers on the righthand side we will eventually need to instantiate them with witnesses this can be done with the rule x p p cx qx we immediately apply the rule but we instantiate x with a unification variable which in practice instantiation until a unification forces it to happen as described above we have extended the tactic for moving quantifiers into the context so it also works on for example given the goal s x s safe x p x x x rx the extended tactic will introduce x x and x into the coq variable context and leave the new goal s s safe p x x rx the rules allowing x and x to be out are given in sections and respectively proving the allocator correctness consists of proving the following for any n fail fail n fail here is a fragment of the coq proof script that deals with the second instruction in the implementation we make use of extensions to standard coq tactic notation mov rewrite inv base limit by for this instruction almost everything is handled automatically the initial rewrite simply the invariant inv to expose the existential quantifiers the custom tactic the variables from deep within the goal to introduce them into the coq context the tactic l will first both the goal and lemma l to have the form required by the rule from section it will then invoke with l as the first premise in this case l is the rule for instructions of the form mov r r the second and fourth premises are trivial leaving only the precondition of the mov rule as a this can be by our tactic which implements entailment checking as described in section in fact none of the instructions needs more than four lines of proof and we hope to reduce this further through the use of additional lemma and tactic support once we have more experience with proving the allocator having verified a component such as the allocator it is reasonably straightforward to use to the logic to verify higherlevel abstractions in a modular way as an example we show the of the allocator in a procedure for onto a list we start with the inductive list segment assertion of separation logic originally due to burstall e vs q p v p p e emp q e vs if vs v vs otherwise here vs is a list of and the assertion says that memory contains a linked list starting at p and ending at e with elements given by vs a possible specification for our cons function is r i j code h t e vs i r h r t e vs r r e vs q q e h vs flags ij code specifying a procedure that is passed a value h in r and a pointer to a list starting at t in r on return is either zero and the original linked list is preserved or points to a linked list segment ending at e with h added as the new head element an implementation is given by r local fail local succeed fail sub mov r mov r jmp succeed fail mov succeed jmp the proof that for any r r i and j r i j r is entirely modular relying on the body rule and the previous result that meets properties of the frame connectives we now return to the frame connective defined in section in previous literature on higherorder frame rules ­ the r in s r to be and does not interact with its environment until it has distributed across all connectives and has been merged into the pre and postconditions of a triple only at that point will the rule of consequence and the existential rule for triples be used to interact with r since we only see triples in certain special cases as described in section we are interested in of the consequence and existential rules just as frame is a of the frame rule for triples the use of these generalised rules in practice is similar to their counterparts in ordinary hoare logic rule of consequence the standard hoare rule of consequence states that p c q is contravariant in p and covariant in q with respect to entailment analogously the we present here describes the variance of s r in r it turns out that s r is not always covariant nor always contravariant in r it can be either depending on s we encode this as two predicates on s frames p q p q s p s q frames p q p q s q s p these definitions directly give rise to our two rules of consequence frames p q sp sq frames p q sq sp all we did so far was to switch the problem to proving frames or frames for particular s but it turns out that there is a very set of rules for this writing f v vn v to mean s sn s sn f s sn we can the rules for various connectives safe and and and and notice that all the logical connectives preserve either or of their operands modulo the flip that happens for implication but there is no way to combine the example for all p and p frame example for all p p there are no definitions analogous to frames and frames for the readonly frame connective since s r is always contravariant in r but as we will see in section the frame family of predicates plays an important role for too it is no that these rules for variance have not been studied in the previous literature there is no rule for frame or frame on hoare triples and in a logic where the only atomic specifications are the triple and then any s that satisfies frames or frames is equivalent to either or existential rule the existential rule in hoare logic allows moving an existential quantifier from the precondition of a hoare triple out into the logical variable context just as we have generalised the frame and consequence rules we can the existential rule to work with other specifications than triples using the same approach as in section we define frames p x s p x s x p x we can then state the existential rule as frames s x s p x s s x p x the following rules using the notation introduced in section let us prove frame safe the natural converse of frames with the entailment in the other direction is equivalent to frames this gives an intuitive justification of the rule for implication above example for all p c q we have c q this is seen by unfolding the definition of the triple and applying the above rules further properties of readonly frame connective the readonly frame and the frame connectives are in certain cases for singleton frames s s if frames then s r s r if frames then s r s r whereas two adjacent frame connectives can always be merged and split by the rule this is not always possible for the readonly frame connective if frames then s r r s r r s r r s r r related work this paper builds on previous work on higherorder frame rules verification and guarded recursion separation logic for assembly code our work shares many goals with the work of et al they have built a separation logic for subsets of arm and x in the hol proof assistant their logic total correctness but since programs do not terminate total correctness does not mean guaranteed termination as it usually would instead a postcondition q means that execution will eventually reach a machine state in q this makes specifications much more intensional than in our case preventing for example and or interpreting code in memory in an way unless this has been explicitly allowed by the specification the logic of et al lacks labels in assembly programs relying instead on explicit instruction address arithmetic their entire specification logic takes place in a generalised hoare triple with multiple pre and postconditions and offset transformer functions this is general enough to support jumps function calls and code but it remains a triple and is thus restricted to what can be expressed with preconditions postconditions and code blocks the cap family of logics from shao et al are also hoare logics for lowlevel code all verified in coq the family includes xcap and unfortunately neither of them is a of any of the others so each has its and all except and have highlevel heap manipulation commands such as allocation or function calls built into the machine semantics all except have the program in a map from labels to instruction sequences which is a high level of abstraction and cannot support treating code as data as and this paper have shown it is not difficult to treat code as data and support function pointers if the logic is set up for it in contrast supports it with some by to impose the abstraction on top of what is actually in the machine et al have formalized in coq a separation logic for firstorder assembly code extending a simpler logic due to and and applied it to verifying provable security of implementations of cryptographic primitives project is also a coq framework for verifying lowlevel code with separation logic like our framework has while and if macros and associated proof principles for common patterns of structured code automated verification and the program logic is therefore not very expressive there is no frame rule so frames are instead passed around explicitly in procedure specifications explains the problem with defining a frame rule for programs with jumps here we have demonstrated how this may be solved none of the logics discussed above feature a higherorder frame rule higherorder frame rules the frame rule was extended by ohearn et al to the frame rule which allowed invariants onto a context of procedure specifications in addition to the triple under consideration this allowed greater modularity in separate verification of caller and callee but it still required programs to have structured control flow the higherorder frame rule was proposed by birkedal et al and used in a type system for a programming language with higherorder functions and ground store ­ it has later been extended to languages with higherorder store and used by and by pottier in all cases it has been for highlevel functional programming languages whereas we have applied it to machine code we believe we are the first to complement the higherorder frame rule with a higherorder rule of consequence and a higherorder existential rule sections and typed assembly language the work of appel et al on typed assembly language and foundational proofcarrying code has demonstrated that step indexing is a technique for describing the behaviour of lowlevel programs the very modal model paper later operator which we also use here and demonstrated its applicability to assembly code the work on typed assembly language focuses on safety of reference types coming from highlevel languages and does not attempt to verify code for full functional correctness as we do future work the logic described in this paper will form the foundation for research on languagebased security in verified systems software although the focus of this paper is on the general design of a separation logic for machine code and is thus largely parametric in the underlying machine model ones in the real world validity of in the logic is limited by ones in the accuracy of that model our x model was from reading the intel and although small programs extracted from coq seem to run as expected on real hardware has not been subject to any systematic testing or verification indeed there is one aspect of the intel specification that we do not currently model namely the presence of a code cache instructions written to memory are on processors not guaranteed to be up by subsequent execution until a jump or other instruction has occurred we plan to treat the code cache following the approach of which we expect to be more generally however we would like to work with a more machine model these have previously been obtained by extensive testing and extraction from the text of reference an important feature currently missing from our machine model is io by adding this we would incorporate observations beyond the simple notion of safe execution but we believe that our framework is generic enough that the safe specification can be generalized to safety properties involving observable input and output transitions we have not so far given any serious thought to how one might also prove liveness properties in a extensional way though that is clearly an interesting subject for future work it would also be useful to extend our logic to deal with binary relations rather than unary predicates on machine states such an extension would allow us to verify information flow and abstraction properties we have already to experiment with verified compilation building a imperative language its compiler program logic and proof of correctness all within coq it is straightforward to mix machine code with higherlevel languages as our logic provides a common framework for specifying their interaction at a high level we plan to develop a number of domainspecific little languages within the same framework lowlevel code often makes sophisticated use of lowlevel data structures whose ownership properties cannot easily be captured by the default model of separation described here we might instead employ separation logic it is interesting to note that even our use of partial states to describe the machine state s in a more finegrained way is of separation acknowledgements we would like to thank birkedal and for many discussions on higherorder frame rules and their applications references r d and k assembly with formal security proofs the case of sci comput prog a w appel and d an indexed model of recursive types for foundational proofcarrying code acm trans program lang syst a w appel pa c d and j a very modal model of a modern major general type system in proceedings of popl j j b and l birkedal ­ a framework for higherorder separation logic in coq in proc of n benton a typed compositional logic for a abstract machine in volume of lncs n benton abstracting allocation the new new thing in computer science logic csl volume of lncs n benton and n compiling functional types to relational specifications for low level imperative code in l birkedal n and h yang semantics of typing and higherorder frame rules in proc of lics l birkedal n and h yang semantics of typing and higherorder frame rules for algollike languages logical methods in computer science l birkedal and h yang relational parametricity and separation logic logical methods in computer science f c v and x designing a cpu model from a document to fast code in rd workshop on simulation and performance evaluation methods and tools r c calcagno p w ohearn and m j parkinson permission in separation logic in proceedings of popl r m burstall some techniques for proving correctness of programs which alter data structures machine intelligence h z shao and a certified code in proc of pldi c calcagno p w ohearn and h yang local action and abstract separation logic in proc of lics a verification of lowlevel programs in computational separation logic in proc of pldi a certified programming with dependent types mit press to appear r w assigning meanings to programs in j t schwartz editor mathematical aspects of computer science volume of proc of in applied mathematics island a c j and m o a monadic formalization of the instruction set architecture in st international conference on interactive theorem proving volume of lncs g a and e a small scale reflection extension for the coq system technical report inria c and e automated verification of practical garbage collectors in popl j b and l birkedal separation logic in proc of esop volume of lncs springer n r verifying higherorder imperative programs with higherorder separation logic phd thesis carnegie mellon university j and j correctness of a compiler for arithmetic expressions in mathematical aspects of computer science volume of proc of in applied mathematics j moore a mechanically verified language implementation journal of automated reasoning g morrisett g j and e better faster stronger for the x in rd acm sigplan conference on programming language design and implementation pldi acm g morrisett d walker k crary and n from system f to typed assembly language acm transactions on programming languages and systems m o verified compiler on x in proc of popl m o and m j c gordon hoare logic for modelled machine code in proc of tacas h a modality for recursion in proc of lics z ni and z shao certified assembly programming with embedded code pointers in proc of popl p w ohearn h yang and j c reynolds separation and information hiding in proc of popl f pottier hiding local state in direct style a higherorder rule in proc of lics j c reynolds an introduction to specification logic in logics of programs j c reynolds separation logic a logic for shared mutable data structures in proc of lics a and t a compositional natural semantics and hoare logic for lowlevel languages theor comput sci m and n firstclass type classes in proc of g and a w appel a compositional logic for control flow in th international conference on verification model checking and abstract interpretation a m turing checking a large routine in report of a conference on high speed automatic calculating machines x w wang z shao and y a simple model for assembly programs with firstclass function pointers in proc of w d a mechanically verified code generator journal of automated reasoning 