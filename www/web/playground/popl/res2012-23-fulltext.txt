static and proof checking shao department of computer science yale university new ct usa abstract despite recent proof development within proof remains an art that is extremely we argue that this can be attributed to two in the architecture of modern proof the first is that proofs need to include a large amount of detail this is due to the of the proof checking process which cannot be extended with domainspecific knowledge in order to avoid these details we rely on developing and using tactics specialized procedures that produce proofs unfortunately tactics are both hard to write and hard to use the second of modern proof this is because there is no static knowledge about their expected use and behavior as has recently been demonstrated languages that allow typesafe manipulation of proofs like and can be used to this second issue by assigning rich types to tactics still the issues remain in this paper we build on this existing work and demonstrate two novel ideas an extensible conversion rule and support for static proof scripts together these ideas enable us to support both proof checking and sophisticated static checking of tactics leading to a new point in the design space of future proof both ideas are based on the between a lightweight staging construct and the rich type information available categories and subject descriptors d programming languages formal definitions and theory general terms languages verification introduction there have been various recent in using proof to construct foundational proofs of large software like a c compiler leroy and an os et al as well as complicated mathematical proofs despite this success the process of proof development using the foundational approach remains a complicated that requires significant manual effort and is by various issues the big benefit of using a foundational proof assistant is that the proofs involved can be checked for validity using a very small proof checking procedure the is that these proofs are permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ pa usa copyright c acm very large since proof checking is fixed there is no way to add domainspecific knowledge to the proof checker which would enable proofs that out less details there is good reason for this too if we allowed arbitrary extensions of the proof checker we could very easily permit it to accept invalid proofs because of this lack of in the proof checker users rely on tactics procedures that produce proofs users are free to write their own tactics that can create domainspecific proofs in fact developing domainspecific tactics is considered to be good engineering when doing large developments leading to significantly overall effort ­ as shown eg in still using and developing tactics is tactics are essentially untyped functions that manipulate logical terms and thus tactic programming is untyped this means that common errors like passing the wrong argument or the wrong result are not statically this proofs contained within tactics are not checked statically when the tactic is defined therefore even if the tactic is used correctly it could contain serious bugs that manifest only under some conditions with the recent of programming languages that support strongly typed manipulation of logical terms such as and and and and shao this situation can be somewhat it has been shown in and shao that we can specify what kinds of arguments a tactic expects and what kind of proof it produces leading to a typesafe programming style still this does not address the fundamental problem of proof checking being fixed ­ users still have to rely on using tactics furthermore the proofs contained within the typesafe tactics are in fact programs which need to be evaluated upon invocation of the tactic therefore proofs within tactics are not checked statically and they can still cause the tactics to fail upon invocation in this paper we build on the past work on these languages to solve both of these issues regarding the architecture of modern proof we introduce two novel ideas support for an extensible conversion rule and static proof scripts inside tactics the former technique enables proof checking to become while maintaining the guarantee that only logically sound proofs are the latter technique allows for statically checking the proofs contained within tactics leading to increased guarantees about their runtime behavior both techniques are based on the same mechanism which consists of a lightweight staging construct there is also a deep between them allowing us to use the one to the benefit of the other our main contributions are the following · first we present what we believe is the first technique for having an extensible conversion rule which combines the following characteristics it is safe meaning that it preserves logical soundness it is using a familiar generic pro a hol approach proof script call eval tactic call tactic call user tactic static dynamic execute × invalid b coq approach proof script eval steps implicit call tactic call user tactic c our approach typed proof script eval steps implicit steps implicit user steps implicit proof checker eval tactic execute × invalid × invalid invalid × type checker smaller proof execute × invalid × invalid figure checking proof scripts in various proof gramming model and it does not require additions to the logic but can be used to simplify the logic instead · second building on existing work for typed tactic development we introduce static checking of the proof scripts contained within tactics this significantly reduces the development effort required allowing us to write tactics that benefit from existing tactics and from the rich type information available · third we show how typed proof scripts can be seen as an alternative form of proof witness which between a proof object and a proof script of the certificate are able to decide on the tradeoff between the level of trust they show and the amount of resources needed to check its validity in terms of technical contributions we present a number of technical advances in the metatheory of the programming languages these include a simple staging construct that is crucial to our development and a new technique for variable representation we also show a condition under which static checking of proof scripts inside tactics is possible last we have extended an existing prototype implementation with a significant number of features enabling it to support our claims while also its use as a proof assistant more practical informal presentation of terms we will start off by introducing some concepts that will be used throughout the paper the first fundamental concept we will consider is the notion of a proof object given a derivation of a proposition inside a formal logic a proof object is a term representation of this derivation a proof checker is a program that can decide whether a given proof object is a valid derivation of a specific proposition or not proof objects are extremely and are thus hard to write by hand for this reason we use tactics functions that produce proof objects by combining tactics together we create programs which we call proof scripts if a proof script is evaluated and the evaluation completes successfully the resulting proof object can be checked using the original proof checker in this way the trusted base of the system is kept at the absolute minimum the language environment where proof scripts and tactics are written and evaluated is called a proof assistant it needs to include a proof checker checking proof objects in order to keep the size of proof objects many of the logics used for mechanized proof checking include a conversion rule this rule is used implicitly by the proof checker to decide whether any two propositions are equivalent if it determines that they are indeed so the proof of their equivalence can be omitted we can thus think of it as a special tactic that is embedded within the proof checker and used implicitly the more sophisticated the relation supported by the conversion rule is the simpler are proof objects to write since more details can be omitted on the other hand the proof checker becomes more complicated as does the metatheory proof showing the soundness of the associated logic the choice in coq et al one of the most widely used proof with respect to this tradeoff is to have a conversion rule that identifies propositions up to evaluation nevertheless extended notions of conversion are desirable leading to proposals like where equivalence up to firstorder theories is supported in both cases the conversion rule is fixed and extending it requires significant amounts of work it is thus not possible for users to extend it using their own domainspecific tactics and proof objects are thus bound to get large this is why we have to to writing proof scripts checking proof scripts as mentioned earlier in order to validate a proof script we need to evaluate it see fig a this is the in proof of the hol family and therefore it is easy to extend the checking procedure for proof scripts by writing a new tactic and calling it as part of a script the price that this comes to is that there is no way to have any sort of static guarantee about the validity of the script as proof scripts are completely untyped this can be somewhat in coq by the static checking that it already supports the proof checker and especially the conversion rule it contains see fig b we can employ proof objects in our scripts this is especially useful when the proof objects are trivial to write but trigger complex conversion checks this is the essential idea behind techniques like which lead to more robust proof scripts in previous work and shao we introduced a language that enables programming tactics and proof scripts in a manner using a generalpurpose programming model combining typed tactics leads to typed proof scripts these are still programs producing proof objects but the proposition they prove is carried within their type information about the current proof state the set of hypotheses and goals is also available statically at every intermediate point of the proof script in this way the static about proof scripts are significantly increased and many potential sources of type errors are removed on the other hand the proof objects contained within the scripts are still checked using a fixed proof checker this ultimately means that the set of possible static guarantees is still fixed extensible conversion rule in this paper we build on our earlier work on in order to further increase the amount of static checking of proof scripts that is possible within this language we propose the notion of an extensible conversion rule see fig c it enables users to write their own domainspecific conversion checks program static tactic calls type checker × stage eval proof object values × static dynamic figure staging in l that get included in the conversion rule this leads to simpler proof scripts as more parts of the proof can be inferred by the conversion rule and can therefore be omitted also it leads to increased static guarantees for proof scripts since the conversion checks happen before the rest of the proof script is evaluated the way we achieve this is by programming the conversion checks as typesafe tactics within and then evaluating them statically using a simple staging mechanism see fig the type of the conversion tactics requires that they produce a proof object which proves the equivalence of the propositions in this way type safety of guarantees that soundness is maintained at the same time users are free to extend the conversion rule with their own conversion tactics written in a familiar programming model without requiring any additions or termination proofs such proofs are only necessary if decidability of the extra conversion checks is desired furthermore this approach allows for reductions as the original conversion rule can be within the language thus it can be removed from the logic and replaced by the simpler notion of explicit equalities leading to both simpler metatheory and a smaller trusted base checking tactics the above approach addresses the issue of being able to extend the amount of static checking possible for proof scripts but what about tactics our existing work on shows how the increased type information addresses some of the issues of tactic development using current proof where tactics are in a completely untyped manner still if we consider the case of tactics more closely we will see that there is a limitation to the amount of checking that is done statically even using this language when programming a new tactic we would like to reuse existing tactics to produce the required proofs therefore rather than writing proof objects by hand inside the code of a tactic we would rather use proof scripts the issue is that in order to check whether the contained proof scripts are valid they need to be evaluated ­ but this only happens when an invocation of the tactic reaches the point where the proof script is used therefore the static guarantees that this approach provides are limited by the fact that the proof scripts inside the tactics cannot be checked statically when the tactic is defined static proof scripts this is the second fundamental issue we address in this paper we show that the same staging construct for introducing the extensible conversion rule can be to perform static proof checking for tactics the crucial point of our approach is the proof of existence of a transformation between proof objects which suggests that under reasonable conditions a proof script contained within a tactic can be transformed into a static proof script this static script can then be evaluated at tactic definition time to be checked for validity last we will show that this approach itself well to writing extensions of the conversion rule we show that we can create a of conversion rules using a basic conversion rule as a starting point we can it inside static proof scripts to implicitly prove the required obligations of a more advanced version and so on this the required user effort for writing new conversion rules and enables modular proof checking t proof object constructors propositions natural numbers lists etc sorts and types x · x t t t · x t · x t main judgement t t type of a logical term figure assumptions about the logic language our in this section we will present the essential that are needed for the rest of our development the main requirement is a language that supports typesafe manipulation of terms of a particular logic as well as a generalpurpose programming model that includes general recursion and other operations two recently proposed languages for manipulating lf terms and and and fit this requirement as does and shao which is a language used to write typesafe tactics our discussion is focused on the latter as it supports a richer calculus compared to the others something useful for our purposes still our results apply to all three we will now briefly describe the constructs that these languages support as well as some new extensions that we propose the interested reader can read more about these constructs in sec and in our technical report and shao a formal logic the computational language we are presenting is around manipulation of terms of a specific formal logic we will see more details about this logic in sec for the time being it will suffice to present a set of assumptions about the syntactic classes and typing judgements of this logic shown in fig logical terms are represented by the syntactic class t and include proof objects propositions terms corresponding to the domain of eg natural numbers and the needed sorts and type constructors to classify such terms their variables are assigned types through an ordered context a package of a logical term t together with the variables context it is called a contextual term and denoted as t t our computational language works over contextual terms for reasons that will be evident later the logic such terms by allowing them to get substituted for metavariables x using the constructor x when a term t t gets substituted for x we go from the context to the current context using the substitution logical terms are classified using other logical terms based on the normal variables environment and also an environment that types metavariables thus leading to the t t judgement for example a term t representing a closed proposition will be typed as · · t prop while a proof object proving that proposition will satisfy the judgement · · t functional programming we move on to the computational language as its main core we assume an functional language supporting general recursion algebraic data types and mutable references see fig terms of this fragment are typed under a computational variables environment and a store typing environment mapping mutable locations to types typing judgements are entirely standard leading to a e judgement for typing expressions programming over logical terms as shown in fig the first important additions to the ml computational core are constructs for dependent functions and products over contextual terms t abstraction over contextual terms is denoted as x te it has the dependent function type x t the type is dependent since the introduced logical term might be used as the type of k k k unit int bool × µ k k array k · · · e n e e e e true false if e then e x e e e e e e e xe xe fold e unfold e ke e fix x e e ee ee e l error · · · · x k · l array figure syntax for the computational language ml fragment · · · x t x t × ctx e · · · x te e t e t e let x x e in e t return of t e · · · tn en return of e · · · n en figure syntax for the computational language logical term constructs another term an example would be a function that receives a proposition plus a proof object for that proposition with type p prop x p dependent products that package a contextual logical term with an expression are introduced through the t e construct and eliminated using let x x e in e their type is denoted as x t × especially for packages of proof objects with the unit type we introduce the syntax last in order to be able to support functions that work over terms in any context we introduce context polymorphism through a similarly dependent function type over contexts with these in mind we can define a simple tactic that gets a proof of a universally quantified formula and an instantiation term and returns a proof of the instantiated formula as follows instantiate ctx t type p x t prop a t lt x t p lt pid a instantiate t p a pf let h pf in h a from here on we will omit details about contexts and substitutions in the interest of presentation pattern matching over terms the most important new construct that supports is a pattern matching construct over logical terms denoted as this construct is used for dependent matching of a logical term against a set of patterns the return clause specifies its return type we omit it when it is easy to infer patterns are normal terms that include unification variables which can be present under binders this is the essential reason why contextual terms are needed pattern matching over environments for the purposes of our development it is very useful to support one more pattern matching construct matching over logical variable contexts when trying to construct a certain proof the logical environment represents what the current proof context is what the current logical hypotheses at hand are what types of terms have been quantified over etc by being able to pattern match over the environment we can look up things in our current set of hypotheses in order to prove further propositions we can thus view the current environment as representing a simple form of the current proof state the pattern matching construct enables us to manipulate it in a typesafe manner one example is an assumption tactic that tries to prove a proposition by searching for a matching hypotheses in the context assumption ctx p prop option assumption p of h p return h assumption p proof object erasure semantics new feature the only construct that can influence the evaluation of a program based on the structure of a logical term is the pattern matching construct for our purposes pattern matching on proof objects is not necessary ­ we never look into the structure of a completed proof thus we can have the typing rules of the pattern matching construct specifically matching on proof objects in that case we can define an alternate operational semantics for our language where all proof objects are erased before using the original smallstep reduction rules because of type safety these semantics are guaranteed to yield equivalent results even if no proof objects are generated they are still bound to exist implicit arguments let us consider again the instantiate function defined earlier this function expects five arguments from its type alone it is evident that only the last two arguments are strictly necessary the last argument corresponding to a proof expression for the proposition x t p can be used to exactly the arguments t and p furthermore if we know what the resulting type of a call to the function needs to be we can choose even the instantiation argument a appropriately we employ a simple mechanism so that such arguments are omitted from our programs this feature is also crucial in our development in order to implicitly maintain and the current proof state within our proof scripts minimal staging support new feature using the language we have seen so far we are able to write powerful tactics using a generalpurpose programming model but what if inside our programs we have calls to tactics where all of their arguments are constant those tactic calls could be evaluated to proof objects prior to tactic invocation we could think of this as a form of generalized constant folding which has one benefit we can tell statically whether the tactic calls succeed or not this paper is exactly about exploring this possibility towards this effect we introduce a staging construct in our computational language this takes the form of a construct which binds a static expression to a variable the static expression is evaluated during stage one see fig and can only depend on other static expressions details of this construct are presented in fig d and also in sec after this addition expressions in our language have a lifetime that are also shown in fig typechecking where the wellformedness of expressions according to the rules of the language is checked and inference of implicit arguments is performed static evaluation where expressions inside are reduced to values yielding a residual expression runtime where the residual expression is evaluated extensible conversion rule with these tools at hand let us now return to the first issue that us the fact that proof checking is and cannot be extended with userdefined procedures as we have said in our introduction many modern proof are based on logics that include a conversion rule this rule essentially identifies sorts s type type kinds k prop nat k k p p p x kp x true false p p · · · d zero succ d p · · · proof objects x x p x k d ··· hol terms t s k p d selected rules intro x p p x p p p p p p p figure syntax and selected rules of the logic language hol conversion c p p n p c p d n d x kd d n dd x dz ds zero n dz dz ds succ d n ds d dz ds d d n d is the compatible reflexive symmetric and transitive closure of d n d figure extending hol with the conversion rule tions up to some equivalence relation usually this is equivalence up to partial evaluation of the functions contained within propositions the supported relation is decided when the logic is designed any extension to this relation requires a significant amount of work both in terms of implementation and in terms of proof required this is by projects that extend the conversion rule in coq such as et al and even if user extensions are supported those only take the form of firstorder theories can we do better than this enabling arbitrarily complex user extensions written with the full power of ml yet maintaining soundness it turns out that we can this is the subject of this section the key idea is to recognize that the conversion rule is essentially a tactic embedded within the type checker of the logic calls to this tactic are made implicitly as part of checking a given proof object for validity so how can we support a flexible extensible alternative instead of a conversion tactic within the logic type checker we can program a typesafe version of the same tactic within with the requirement that it provides proof of the equivalence instead of calling the conversion tactic as part of proof checking we use staging to call the tactic statically ­ after type checking but before runtime execution this can be viewed as a second potentially nonterminating proof checking stage users are now free to write their own conversion tactics extending the static checking available for proof objects and proof scripts still soundness is maintained since full proof objects in the original logic can always be constructed as an example we have extended the conversion rule that we use by a congruence closure procedure which makes use of mutable data structures and by an arithmetic simplification procedure introducing the conversion rule first let us present what the conversion rule really is in more detail we will base our discussion on a simple typetheoretic higherorder e d k c d k e d d prop e d k e refl d d d x k e p prop e d k e e d d e x kp x k e d d e x k x kd x kd x k e d d e d prop e x k x kd x kd x k e d k e d k e x kd d x kd d dd x axioms assumed fz fz fs zero fz fz fz fs succ n fs n fz fs n figure extending hol with explicit equality hole logic based on the hol logic as described in barendregt and and used in our original work on and shao we can think of such a logic composed by the following broad classes the objects of the domain of d which are the objects that the logic reasons about such as natural numbers and lists their the kinds k classified in turn by sorts s the propositions p and the derivations which prove that a certain proposition is true we can represent derivations in a linear form as terms in a typed lambdacalculus we call such terms proof objects and their types represent propositions in the logic checking whether a derivation is a valid proof of a certain proposition amounts to typechecking its corresponding proof object some details of this logic are presented in fig the interested reader can find more information about it in the above references and in our technical report and shao in fig we show what the conversion rule looks like for this logic it is a typing judgement that effectively identifies propositions up to an equivalence relation with respect to checking proof objects we call this version of the logic and use c to denote its entailment relation the equivalence relation we consider in the conversion rule is evaluation up to reductions and uses of primitive recursion of natural numbers denoted as in this way trivial arguments based on this notion of computation alone need not be as for example is the fact that succ x y succ x y ­ when the addition function is defined by primitive recursion on the first argument of course this is only a very basic use of the conversion rule it is possible to omit larger proofs through much more sophisticated uses this leads to simpler proofs and smaller proof objects still when using this approach the choice of what relation is supported by the conversion rule needs to be made during the definition of the logic this choice all aspects of the metatheory of the logic it is easy to see why even with the fragment of logic we have introduced most typing rules for proof objects in the logic are similar to the rules intro and they are syntaxdirected this means that upon the associated proof object constructor like x p in the case of intro we can directly tell that it applies if all rules were syntax directed it would ctx t tt t option t t t t t t t t of ta t t tb tc td do pf t t ta tc pf t tb td return · · · proof of ta tb tc td · · · ta tb tc td do pf prop ta tc pf prop tb td return · · · proof of ta tb tc td · · · x tt x tt do pf x t prop t t return · · · proof of x tt x tt · · · tt do return · · · proof of t t · · · tt none ctx t tt t t t t t match t t t with some x x none error figure tactic for checking equality up to conversion be entirely simple to prove that the logic is sound by an inductive argument essentially since no proof constructor for false exists there is no valid derivation for false in this logic the only rule that is not syntax directed is exactly the conversion rule therefore in order to prove the soundness of the logic we have to show that the conversion rule does not introduce a proof of false this means that proving the soundness of the logic passes essentially through the specific relation we have chosen for the conversion rule therefore this approach is limited from supporting user extensions since any new extension would require a new result in order to make sure that it does not violate logical soundness conversion away since having a fixed conversion rule is bound to fail if we want it to be extensible what choice are we left with but to throw it away this approach is what we will do here we can replace the conversion rule by an explicit notion of equality and provide explicit proof witnesses for rewriting based on that equality essentially all the points where the conversion rule was to and proofs were omitted need now be replaced by proof objects the equivalence some details for the additions required to the base hol logic are shown in fig yielding the hole logic there are good reasons for choosing this version first the proof checker is as simple as possible and does not need to include the conversion checking routine we could view this routine as performing proof search over the replacement rules so it necessarily is more complicated especially since it needs to be relatively efficient also the metatheory of the logic itself can be simplified even when the conversion rule is supported the metatheory for the associated logic is proved through the explicit equality approach this is because model construction for a logic benefits from using explicit equality and still this approach has a big the proof objects soon become extremely large since they include detailed proofs for even the simplest of equivalences this their use as independently proof certificates that can be sent to a third party it is possible that this is one of the reasons why systems based on logics with explicit equalities such as hol ctx t t t t × t t t t of t t t t t let t p f t t t in t of x t t f t fz fs n t f · · · t t · · · let n p f nat n in n of zero fz · · · succ n fs n fz fs n · · · n fz fs n · · · t t ··· figure tactic for rewriting to weak form and and et al do not generate proof objects by default getting conversion back we will now see how it is possible to the explicit equality based approach with the conversion rule we will gain the conversion rule back it will remain completely outside the logic therefore we will be free to extend it all the while without introducing in the logic since the logic remains fixed hole as presented above we do this by the view of the conversion rule as a special trusted tactic through the tools presented in the previous section first instead of a conversion tactic in the type checker we program a typesafe conversion tactic the features of based on typing alone we require that it returns a valid proof of the equivalences ctx t type t t t t option t second we evaluate this tactic under proof erasure semantics this means that no proof objects are produced leading to the same space as the original conversion rule third we use the staging construct in order to check conversion statically details we now present our approach in more detail first in fig we show a sketch of the code behind the typesafe conversion check tactic it works by first rewriting its input terms into weak form via the function in fig and then recursively checking their subterms for equality in the equivalence checking function more cases are needed to deal with quantification while in the rewriting procedure a recursive call is missing which would our presentation here we also define a version of the tactic that raises an error instead of returning an option type if we fail to prove the terms equal which we call the full details can be found in our implementation the code of the tactic is in fact entirely similar to the code one would write for the conversion check routine inside a logic type checker save for the extra types and proof objects it therefore follows trivially that everything that holds for the standard implementation of the conversion check also holds for this code eg it corresponds exactly to the n relation as defined in the logic it is bound to terminate because of the strong normalization theorem for this relation and its version is at least as as the standard implementation furthermore given this code we can produce a form of typed proof scripts inside that correspond exactly to proof objects in the logic with the conversion rule both in terms of their actual code and in terms of the steps required to validate them this is done by constructing a proof script in by induction on the derivation of the proof object in replacing each proof object constructor by an equivalent tactic as follows constructor x p x k d c conversion to tactic assume e apply e e intro e inst e a lift c conversion of type lt h p p p p lt x t p t p t p a t a h p p here we have omitted the current logical environment it is maintained through syntactic means as discussed in sec and through type inference the only subtle case is conversion given the transformed proof e for the proof object contained within a use of the conversion rule we call the conversion tactic as follows pf p p in conversion e pf the arguments to can be easily inferred making crucial use of the rich type information available conversion could also be used implicitly in the other tactics thus the resulting expression looks entirely identical to the original proof object correspondence with original proof object in order to the correspondence between the resulting proof script expression and the original proof object it is to view the proof script as a proof certificate sent to a third party the steps required to check whether it a valid proof are the following first the whole expression is checked using the type checker of the computational language then the calls to the function are evaluated during stage one using proof erasure semantics we expect them to be successful just as we would expect the conversion rule to be applicable when it is used last the rest of the tactics are evaluated by a simple argument based on the fact that they do not use pattern matching or sideeffects they are guaranteed to terminate and produce a proof object in hole this validity check is entirely equivalent to the behavior of typechecking the proof object save for all conversion checks towards the end extending conversion at will in our treatment of the conversion rule we have so far focused on the n conversion in our framework still there is nothing us to supporting this conversion check only as long as we can program a conversion tactic in that has the right type it can safely be made part of our conversion rule for example we have written an function which checks terms for equivalence based on the equality with uninterpreted functions decision procedure it is adapted from our previous work on and shao this equivalence checking tactic hypotheses of the form d d from the current context using the context matching support then it constructs a data structure in order to form equivalence classes of terms based on this structure and using code similar to recursive calls on subterms we can decide whether two terms are equal up to simple uses of the equality hypotheses at hand we have combined this tactic with the original tactic making the implicit equivalence supported similar to the one in the calculus of congruent constructions et al this demonstrates the flexibility of this approach equivalence checking is extended with a sophisticated decision procedure which is using its original imperative formulation we have both the rewriting procedure and the equality checking procedure in an extensible manner so that we can globally register further extensions typed proof scripts as certificates earlier we discussed how we can validate the proof scripts resulting from the conversion rule into explicit tactic calls this discussion shows an interesting aspect of typed proof scripts they can be viewed as a proof witness that is a flexible between untyped proof scripts and proof objects when a typed proof script consists only of static calls to conversion tactics and uses of total tactics it can be thought of as a proof object in a logic with the corresponding conversion rule when it also contains other tactics that perform potentially expensive proof search it corresponds more closely to an untyped proof script since it needs to be fully evaluated still we are allowed to validate parts of it statically this is especially useful when developing the proof script because we can avoid the evaluation of expensive tactic calls while we focus on getting the skeleton of the proof correct using proof erasure for evaluating is only one of the choices the receiver of such a proof certificate can make another choice would be to have the function return an actual proof object which we can check using the hole type checker in that case the interpreter does not need to become part of the trusted base of the system last the possible choice would be to avoid doing any evaluation of the function and ask the proof certificate to do the evaluation of themselves in that case no evaluation of computational code would need to happen at the proof certificate side this any concerns one might have for code execution as part of proof validity checking and guarantees that the small hole type checker is the trusted base in its also the receiver can decide on the above choices for different conversion tactics ­ eg use proof erasure for but not for leading to a trusted base identical to the case this means that the choice of the conversion rule with the proof certificate receiver and not with the designer of the logic thus the proof certificate receiver can choose the level of trust they require at will static proof scripts in the previous section we have demonstrated how proof checking for typed proof scripts can be made through a new treatment of the conversion rule it makes use of userdefined typesafe tactics which are evaluated statically the question that remains is what happens with respect to proofs within tactics if a proof script is found within a tactic must we wait until that evaluation point is reached to know whether the proof script is correct or not or is there a way to check this statically as soon as the tactic is defined in this section we show how this is possible to do in using the staging construct we have introduced still in this case are not as simple as evaluating certain expressions statically rather than dynamically the reason is that proof scripts contained within tactics mention metavariables and thus cannot be evaluated through staging we resolve this by showing the existence of a transformation which logical terms from an arbitrary metavariables context into the empty one we will focus on the case of developing conversion routines similar to the ones we saw earlier the ideas we present are generally applicable when writing other types of tactics as well we focus on conversion routines in order to demonstrate that the two main ideas we present in this paper can work in a for plus we will consider the case of writing a to for simplifying expressions of the form x y depending on the second argument the addition function is defined by induction on the first argument as follows y r x in order for to be able to use existing as well as future to perform their recursive calls we write them in the open recursion style ­ they receive a function of the same type that corresponds to the current the code looks as follows ctx t t t t × t recursive t t t with xy let y recursive y in let t y return t x y t of x · · · proof of x x · · · succ y y · · · proof of x succ y succ x y · · · y x y · · · proof of x y x y · · · in t · · · proof of x y t · · · t t · · · proof of t t · · · while developing such a tactic we can the type checker to know the types of missing proofs but how do we fill them in for the interesting cases of x x and x succ y succ x y we would certainly need to prove the corresponding lemmas but for the rest of the cases the corresponding lemmas would be and tedious to state such as the following for the x y t case lemma x y y t y y x y t x y t stating and proving such lemmas soon becomes a when writing tactics an alternative is to use the congruence closure conversion rule to solve this trivial obligation for us directly at the point where it is required our first attempt would be proof of x y t let pf h y y h x y t x y t in the benefit of this approach is evident when implicit arguments since most of the details can be inferred and therefore omitted here we had to alter the environment passed to which includes several extra hypotheses once the resulting proof has been computed the hypotheses are substituted by the actual proofs that we have the problem with this approach is first the call to the tactic is every time we reach that point of our function for such a simple tactic call this does not impact the runtime significantly still if we could avoid it we would be able use more sophisticated and expensive tactics the second problem is that if for some reason the is not able to prove what it is to we will not know until we actually reach that point in the function moving to static proofs this is where using the construct becomes essential we can evaluate the call to statically during stage one interpretation thus we will know at the time that is defined whether the call also it will be replaced by a concrete value so it will not affect the runtime behavior of each invocation of to do that we need to avoid any of the metavariables that are bound during runtime like x y and t this is done by specifying an appropriate environment in the call to similarly to the way we incorporated the extra knowledge above and substituted it later using this approach we have proof of x y t pf let x y y t nat h y y h x y t in x y t in y id id id what we are essentially doing here is replacing the metavariables by normal logical variables which our tactics can deal with the metavariable context is into a normal context proofs are constructed using tactics in this environment last the resulting proofs are back into the desired context by substituting metavariables for variables we have explicitly stated the substitutions in order to distinguish between normal logical variables and metavariables the reason why this transformation needs to be done is that functions in our computational language can only manipulate logical terms that are open with respect to a normal variables context not logical terms that are open with respect to the metavariables context too a much more complicated but also more flexible alternative to using this trick would be to support within our computational language directly overall this approach is entirely similar to proving the auxiliary lemma mentioned above prior to the tactic definition the benefit is that by the type information together with type inference we can avoid stating such lemmas explicitly while the same runtime behavior we thus end up with very concise proof expressions that are statically validated we introduce syntactic sugar for binding a static proof script to a variable and then performing a substitution to bring it into the current context since this is a common operation e static pf e in pf · · · based on these the trivial proofs in the above tactic can be filled in using a simple static call for the other two we use instantiate x static after we define we can register it with the global equivalence checking procedure thus all later calls to will benefit from this simplification it is then simple to prove commutativity for addition yx y y x based on this proof we can write a that takes commutativity into account and uses the hash values of logical terms to avoid infinite loops we have on an arithmetic simplification that is built by such together using previous ones to aid us in constructing the proofs required in later ones it works by converting expressions into a list of sorting the list based on the hash values of the variables and then factoring on the same variable also the procedure mentioned earlier has all of its associated proofs automated through static proof scripts using a naive potentially nonterminating equality is always possible a natural question to ask is whether the metavariables context into a normal context is always possible in order to cast this as a more formal question we notice that the essential step is replacing a proof object of type t typed under the metavariables environment by a proof object of type t typed under the empty metavariables environment there needs to be a substitution so that gets back to the environment and has the appropriate type syntax of the logic terms t s c fi bi tt t t tt t t refl t t t t t t t t sorts s prop type type var context · t substitutions · t example of representation a nat x plus a a x nat plus f b plus f b t n m fi bn bi n nm fi fm bi when i n tt n t n t n t t t t bind t n m fm fi n m n m bi tt t t bn fi when i m bi t n t n t t a hybrid indices representation technique syntax t · · · fi xi · t i · t indices i n i i k t ctx extension context · k t t ext subst · t t t sample i t fi t t tt t t t t t · i t xi t · t k t t t t wf ctx wf sample b extension variables metavariables and context variables wf i ctx i wf subst application t · c · c fi · i bi · bi tt · t · t · t t · t · t · ext subst application sample i i · i · when i · · xi · t · · when i t i · · when i · · t t · t t i ctx i i selected t k · t k subst lemmas t t t · t · · c substitutions over logical variables and extension variables t k t · k · syntax · x x s k e · · · x e in e · limit ctx x s x static x t static static e part · static e x s e x e in e x s x evaluation v pack t return with v x ed v v v fold v l s x · in e x s in e ks x s ed xs xs xe xs ks fix x s unify t return with t s es es t pack t return with es es xe es e ed es es e ed es es es xe xe fold es unfold es ref es es e ed es es es ed all of e except x e in e e exactly as es with es e and e ed stage µ ed µ ed µ s µ µ x v in e s µ µ x v in e s µ d computational language staging support figure main definitions in metatheory we have proved that this is possible under certain restrictions the types of the metavariables in the current context need to depend on the same free variables context max or prefixes of that context also the substitutions they are used with need to be prefixes of the identity substitution for max such terms are characterized as we have proved that terms can be replaced using terms that do not make use of metavariables more details can be found in sec and in the technical report and shao this restriction corresponds very well to the treatment of variable contexts in the language this language assumes an ambient context of logical variables instead of full contextual modal terms constructs to extend this context and substitute a specific variable exist if this last feature is not used the ambient context grows and the mentioned restriction holds trivially in our tests this restriction has not turned out to be limiting metatheory we have completed an extensive of the metatheory of in order to incorporate the features that we have presented in this paper our new metatheory includes a number of technical advances compared to our earlier work and shao we will present a technical overview of our metatheory in this section full details can be found in our technical report and shao variable representation technique though our metatheory is done on paper we have found that using a concrete variable representation technique some aspects of how different kinds of substitutions work in our language compared to having normal named variables for example instantiating a context variable with a concrete context a set of potentially complicated which a concrete representation makes explicit we use a hybrid technique representing bound variables as indices and free variables as levels our technique is a small from the named approach requiring fewer extra annotations and lemmas than normal indices also it identifies terms not only up to equivalence but also up to extension of the context with new variables this is why it is also used within the two fundamental operations of this technique are and binding which are shown in fig a extension variables we extend the logic with support for metavariables and context variables ­ we refer to both these sorts of variables as extension variables a metavariable xi stands for a contextual term t t which packages a term together with the context it context variables i stand for a context and are used to weaken parametric contexts in specific positions both kinds of variables are needed to support manipulation of open logical terms details of their definition and typing are shown in fig b we use the same hybrid approach as above for representing these variables a somewhat subtle aspect of this extension is that we generalize the levels i used to index free variables in order to deal effectively with parametric contexts substitutions the hybrid representation technique we use for variables simultaneous substitutions for all variables in scope as the most natural choice in fig c we show some example rules of how to apply a full simultaneous substitution to a term t denoted as t · similarly we define full simultaneous substitutions for extension contexts defining their application has a very natural description because of our variable representation technique we prove a number of substitution lemmas which have simple statements as shown in fig c the proofs of these lemmas the main effort required in proving the of a computational language such as the one we support as they represent the point where computation specific to logical term manipulation takes place computational language we define an computational language that supports dependent functions and dependent pairs over contextual terms t as well as pattern matching over them lack of space us from including details here full details can be found in the technical report and shao a fairly complete ml calculus is supported with mutable references and recursive types type safety is proved using standard techniques its central point is extending the logic substitution lemmas to expressions and using them to prove progress and preservation of dependent functions and dependent pairs this proof is modular with respect to the logic and other logics can easily be supported pattern matching our metatheory includes many extensions in the pattern matching that is supported as well as a new approach for dealing with typing patterns we include support for pattern matching over contexts eg to pick out hypotheses from the context and for nonlinear patterns the allowed patterns are checked through a restriction of the usual typing rules p t k the essential idea behind our approach to pattern matching is to identify what the relevant variables in a typing derivation are since contexts are ordered removing variables amounts to replacing their definitions in the context with holes which leads us to partial contexts the corresponding notion of partial substitutions is denoted as our main theorem about pattern matching can then be stated as theorem decidability of pattern matching if p t k · p t k and relevant t k then either there exists a unique partial substitution such that · and t · t or no such substitution exists staging our development in this paper depends on the construct we presented earlier it can be seen as a dual of the traditional box construct of and pfenning details of its typing and semantics are shown in fig d we define a notion of static evaluation contexts s which a hole of the form x · in e they include normal evaluation contexts as well as evaluation contexts under binding structures we evaluate expressions e that include staging constructs using the s relation internally this uses the normal evaluation rules that are used in the second stage as well for evaluating expressions which do not include other staging constructs if evaluation is successful we are left with a residual dynamic configuration µ ed which is then evaluated normally we prove for evaluation its statement follows theorem type safety if · · e then either e is a dynamic expression ed or for every store µ such that µ we have either µ e s error or there exists an e a new store typing and a new store µ such that µ e µ e µ and · · e extension variables last we have proved the fact that under the conditions described in sec it is possible to a term t into a term t which is typed under the empty extension variables context a substitution with which we can the original term t exists this suggests that whenever a proof object t for a specific proposition is required an equivalent proof object that does not mention extension variables exists therefore we can write an equivalent proof script producing the proof object instead and evaluate that script statically the statement of this theorem is the following theorem if t tt and t tt then there exist t tt and such that · wf · t tt t · t and tt · tt the main idea behind the proof is to maintain a number of substitutions and their one to go from a general extension context into an equivalent context which includes only definitions of the form t for a constant context that uses no extension variables then another substitution and its inverse are maintained to go from that extension variables context into the empty one this is simpler since terms typed under are already essentially free of metavariables the computational content within the proof amounts to a procedure for transforming proof scripts inside tactics into static proof scripts implementation we have completed a prototype implementation of the language as described in this paper that supports all of our claims we have built on our existing prototype and shao and have added an extensive set of new features and improvements the prototype is written in ocaml and is about k lines of code using the prototype we have implemented a number of examples that are about k lines of code readers are to and try the prototype from new features we have implemented the new features we have described so far context matching nonlinear patterns semantics staging and for logical and computational terms semantics are only if by a flag enabling us to trust tactics the staging construct we support is more to the · static form described as syntactic sugar in sec and it is able to infer the substitutions that are needed following the approach used in our metatheory changes we have also changed quite a number of things in the prototype and improved many of its aspects a central change by our new treatment of the conversion rule was to modify the used logic in order to use the explicit equality approach the existing prototype used the logic we also the variable representation to the hybrid indices technique we described which enabled us to implement subtyping based on context subsumption also we have adapted the typing rules of the pattern matching construct in order to support refining the environment based on the current branch examples implemented we have implemented a number of examples to support our claims first we have written the typesafe conversion check routine for n and extended it to support congruence closure based on equalities in the context proofs of this latter tactic are constructed automatically through static proof scripts using a naive that is nonterminating in the general case we have also completed proofs for theorems of arithmetic for the properties of addition and multiplication and used them to write an arithmetic simplification tactic all of the theorems are proved by making essential use of existing conversion rules and are immediately added into new conversion rules leading to a compact and clean development style the resulting code does not need to make use of translation validation or proof by reflection which are typically used to implement similar tactics in existing proof towards a practical proof assistant in order to facilitate practical proof and program construction in we introduced some features to support surface syntax enabling users to omit most details about the environments of contextual terms and the substitutions used with metavariables this syntax follows the style of assuming an ambient logical variable environment which is extended through a construct denoted as x te still the full power of contextual modal type theory is available which is crucial in order to change what the current ambient environment is used as we saw earlier for static calls to tactics in general the surface syntax leads to much more concise and readable code last we introduced syntax support for calls to tactics enabling users to write proof expressions that look very similar to proof scripts in current proof we developed a mode for that enables us to call the typechecker and interpreter for parts of source files by adding holes to our sources we can be by the type inference mechanism about their expected types those types correspond to what the current proof state is at that point therefore a possible workflow for developing tactics or proofs is writing the known parts inserting holes in missing points to know what remains to be proved and calling the typechecker to get the proof state information this workflow corresponds closely to the interactive proof development support in proof like coq and but generalizes it to the case of tactics as well related work there is a large body of work that is related to the ideas we have presented here techniques for robust proof development there have been multiple proposals for making proof development inside existing proof more robust a wellknown technique is writing total and certified decision procedures within the functional language contained in a logic like a recently introduced technique is automation through canonical structures et al the resolution mechanism for finding instances of canonical structures a generalization of type classes is in order to program automation procedures for specific classes of propositions we view both approaches as somewhat similar as both are based in exploiting static interpreters that are available in a modern proof assistant the partial evaluator within the conversion rule in the former case the unification algorithm within instance discovery in the latter case our approach can thus be seen as similar but also as a generalization of these approaches since a generalpurpose programming model is supported therefore users do not have to adapt to a specific programming style for writing automation code but can rather use a familiar functional language could perhaps be used to support the same kind of extensions to the conversion rule still this would require a large part of the logic in itself through a complicated encoding both techniques are applicable to our setting as well and could be used to provide benefits to large developments within our language the style in and elsewhere suggests that proper proof engineering entails developing sophisticated automation tactics in a modular style and extending their power by adding proved lemmas as we are largely inspired by this approach and believe that our introduction of the extensible conversion rule and static checking of tactics can significantly benefit it we demonstrate similar ideas in conversion tactics traditional proof there are many of our work with the family of proof like hol and and which have as first the foundational logic that we use is similar also our use of a mllike programming language to program tactics and proof scripts is similar to the approach taken by hol and last the fact that no proof objects need to be generated is shared still checking a proof script in hol requires evaluating it fully using our approach we can evaluate parts of proof scripts we focus on tactics but we are not limited to those this is only possible because our proof scripts carry proof state information within their types similarly proof scripts contained within tactics cannot be evaluated statically so it is impossible to establish their validity upon tactic definition it is possible to do a transformation similar to ours manually lifting proof scripts into auxiliary lemmas that are proved prior to the tactic but the lack of type information means that many more details need to be provided the coq proof assistant et al is another obvious point of reference for our work we will focus on the conversion rule that its logic supports ­ the same problems with respect to proof scripts and tactics that we described in the case also apply for coq the conversion rule which identifies computationally equivalent propositions coupled with the rich type universe available up many possibilities for constructing small and efficiently proof objects the implementation of the conversion rule needs to be part of the trusted base of the proof assistant also the fact that the conversion check is builtin to the proof assistant makes the supported equivalence and by frequently used decision procedures there is a large body of work that aims to extend the conversion rule to arbitrary confluent rewrite systems eg et al and to include decision procedures these approaches assume some small or larger addition to the trusted base and extend the already complex metatheory of coq furthermore the proof assistant et al is based on extensional type theory which includes an extensional conversion rule this enables complex decision procedures to be part of conversion but it results in a very large trusted base we show how for a subset of these type theories the conversion check can be outside the trusted base it can be extended with arbitrarily complex new tactics written in a familiar programming style without any additions and without the soundness of the logic the question of whether these type theories can be supported in full remains as future work but as far as we know there is no limitation to our approach programming the large body of work on languages has close to our work out of the of proposals we consider the russell framework as the current because of its high expressivity and automation in proof obligations in our setting we can view programming as a specific case of tactics producing complex data types that include proof objects static proof scripts can be to support expressivity similar to the russell framework furthermore our approach up a new possibility programs whose obligations are statically and automatically through code written within the same language last we have been largely inspired by the work on languages like and and and and build on our previous work on and shao we investigate how to typesafe tactics as well as a number of new constructs we introduce so as to offer an extensible notion of proof checking also we address the issue of statically checking the proof scripts contained within tactics written in as far as we know our development is the first time languages such as these have been demonstrated to provide a workflow similar to interactive proof acknowledgments we thank anonymous for their suggestions and comments on an earlier version of this paper this research is based on work supported in part by crash grant fa and nsf grants and any and conclusions contained in this document are those of the authors and do not reflect the views of these references hp barendregt and h using dependent type systems in a and a editors of automated reasoning sci bv b s c j y d d de jc e h et al the coq proof assistant reference manual version f jp and m the calculus of algebraic constructions in rewriting techniques and applications pages ­ springer f jp and py a calculus of congruent constructions unpublished draft s using reflection to build efficient and certified decision procedures lecture notes in computer science ­ a verification of lowlevel programs in computational separation logic in proceedings of the acm sigplan conference on programming language design and implementation acm rl sf allen hm wr rw harper dj tb np p et al implementing mathematics with the proof development system prenticehall nj r and f pfenning a modal analysis of staged computation in proceedings of the rd acm sigplansigact symposium on principles of programming languages pages ­ acm g formal theorem notices of the ­ g b a and d dreyer how to make ad hoc proof automation less ad hoc in of the th acm sigplan international conference on functional programming pages ­ acm j hol light a introduction lecture notes in computer science pages ­ g k g j d p d k r m et al sel formal verification of an os kernel in proceedings of the acm nd symposium on operating systems principles pages ­ acm x leroy formal verification of a realistic compiler communications of the acm ­ t lc and m a proof assistant for higherorder logic volume of lncs b and j programming with proofs and explicit contexts in proceedings of the th international acm sigplan conference on principles and practice of declarative programming pages ­ acm new york ny usa a and c practical programming with higherorder encodings and dependent types lecture notes in computer science v and h equality is typable in pure type systems in th annual ieee symposium on logic in computer science pages ­ ieee k and m a brief overview of hol theorem proving in higher order logics pages ­ m subset coercions in coq in proceedings of the international conference on types for proofs and programs pages ­ springerverlag a and z shao typed computation of logical terms inside a language with effects in proceedings of the th acm sigplan international conference on functional programming pages ­ acm a and z shao static and proof checking extended version available in the acm digital library py coq modulo theory in proceedings of the th international conference on computer science logic pages ­ springerverlag 