runtime enforcement of security policies on black box reactive programs university of italy frank abstract security enforcement mechanisms like execution monitors are used to make sure that some untrusted program with a policy different enforcement mechanisms have different and and hence it is important to understand the of various enforcement mechanisms this paper studies runtime enforcement mechanisms for reactive programs we study the impact of two important constraints that many practical enforcement mechanisms satisfy the enforcement mechanism must handle each inputoutput event in finite time and on occurrence of the event as opposed to for instance edit automata that have the power to buffer events for an arbitrary amount of time and the enforcement mechanism treats the untrusted program as a black box it can monitor andor edit the inputoutput events that the program on execution and it can explore alternative executions of the program by running additional copies of the program and providing these different inputs it can not the source or machine code of the untrusted program such enforcement mechanisms are important in practice they include for instance many execution monitors virtual machine monitors and secure or executions we establish upper and lower bounds for the class of policies that are by such black box mechanisms and we propose a generic enforcement mechanism that works for a wide range of policies we also show how our generic enforcement mechanism can be instantiated to enforce specific classes of policies at the same time showing that many existing enforcement mechanisms are optimized instances of our construction categories and subject descriptors d operating systems security and protection general terms security keywords runtime enforcement policy black box mechanism reactive program permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than acm must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ copyright c acm introduction an enforcement mechanism is a mechanism to ensure that some untrusted program will with an independently specified security policy for that program an interesting question that has received a considerable amount of attention over the past is for what classes of policies do there exist secure and precise enforcement mechanisms roughly speaking an enforcement mechanism is secure if it ensures that any program running under the enforcement mechanism with the policy it is precise if it does not change the behavior of secure programs in any significant way ie secure programs are not affected by the enforcement mechanism for purely static enforcement mechanisms ie mechanisms that should accept or reject the program after some finite amount of analysis possibly including verification of the code of the program model checking of the program or the execution of a finite number of test runs it is known that they can enforce exactly the recursively decidable properties of programs ie the class of the arithmetic hierarchy for dynamic runtime enforcement mechanisms the picture is more complicated at least in part this is the case because it is less clear what exactly runtime mechanisms are allowed to do can they only monitor the program and halt it on an observed policy violation or are they also allowed to change the program andor its executions and if so under what constraints obviously the enforcement mechanism should not be allowed to make arbitrary changes if it is to be precise it should preserve in some sense the behavior of secure programs for the important mechanism of execution monitoring the mechanism can only observe executions of the program and terminate them ie prevent any further actions as soon as they are observed not to with the policy the enforcement power of this mechanism was first studied by and results were later refined by et al and et al roughly speaking execution monitors can enforce the computable safety properties but the details depend on the power of the monitor if there are certain that the monitor can not prevent from such as the passing of time this the set of properties edit automata are a generalization of execution monitors where the monitor can also insert or change actions that the program performs they were shown to be strictly more powerful than execution monitors edit automata can enforce the socalled infinite properties a class of properties that also includes some liveness properties yet this is only possible at the of assuming that the monitor can buffer inputoutput events for an arbitrary amount of time for reactive programs it would be desirable if the enforcement mechanism handles each inputoutput event on occurrence of the event an inputoutput event will often further progress of the reactive program events happen in response to earlier events the main objective of this paper is to come to a better understanding of the enforcement power of dynamic enforcement mechanisms for deterministic reactive programs that satisfy two constraints that are important in practice first we require the enforcement mechanism to handle each input event in finite time and before processing the next input event no second the enforcement mechanism does not analyze the code or runtime state of the program it treats the program as a black box the enforcement mechanism can inputoutput events and possibly modify them it can also run multiple copies of the program as in secure or executions in summary this paper makes the following contributions · we define the class of black box policies a class of policies that is by only considering the io behaviour of a program and hence without any analysis of the source or binary code of the program · we establish upper and lower bounds for this class · we develop a generic black box enforcement mechanism and prove that it is secure and precise · we show how this generic enforcement mechanism can be instantiated to interesting policies the remainder of this paper is structured as follows in sections and we define reactive programs and security policies in section we define and study the notion of black box policies and construct a generic black box enforcement mechanism in section we show specific useful and interesting instances of the generic construction and we discuss some of the implications of our result in section finally sections and discuss related work and conclude a model of reactive programs and observations we model reactive programs as states in a labeled transition system with a total computable deterministic transition relation programs are black boxes in the sense that the only observation one can do on a program is it input and observing the corresponding output this section formalizes these concepts programs let i resp o be enumerable sets of input resp output values the metavariable i resp o ranges over i resp o a stream of inputs i resp stream of outputs o is defined from the empty stream and the observation i i resp o o of a value i and a tail stream i the set of finite and infinite streams over i resp o is denoted i resp o the set of finite streams over i resp o is denoted i resp o we notation and denote by i i the operation of value i to the finite stream i for simplicity we will abbreviate i in as i in for n definition a labelled transition system lts is a tuple c i o where c is the set of states and c × i × o × c is a transition relation we denote a transition as c io c an lts is if for all c c and i i there exist c c and o o such that c io c an lts is deterministic if for all c c and for all i i if c io c and c io c then o o and c c for this paper program states c are elements of the state set c of some and deterministic lts c i o we assume throughout the paper that the function mapping any c i to o c such that c io c holds is total and computable the intuition is that if c io c holds then program state c will process input i produce output o in finite time and transition to the new program state c we will often refer to states c as programs rather than program states each program c an input stream i into an output stream o this process defines a relation c io c by the rules specified below nil c c c io c c io c cons c c this relation defines a function on finite input streams that maps any c i to some o c since the function that processes an individual input is total and computable also the function over streams is total and computable for finite input streams i therefore we write ci o if there is some program c such that c io c and say that program c on input i produces output o programs run for ever in this model every program state is ready to accept more inputs but termination of a program can be modeled by producing a special output value ad for every input value et als model of reactive systems allows divergence on a single input value we impose the constraint that a program can not diverge on a single input value because we want to impose that same constraint on enforcement mechanisms the consequences of this choice are significant and further discussed in section listing shows an example program specified as a function on an input value and on program state stored in a state variable listing a sum program state var sum sum i this program maps for instance input stream on output stream and the infinite input stream on the infinite output stream finite observations on programs a primitive observation is a pair i o where i i and o o are finite and of equal length a program c has the primitive observation i o iff ci o an observation m is a finite set of primitive observations ie a partial mapping of finite input streams to finite output streams a program c has the observation m denoted by m c iff it has all the primitive observations in m the prefix of a primitive observation i i o o is i o an observation m is if for each i i o o m it is also the case that i o m the prefix closure of m denoted as m is the smallest set that includes m and is it is straightforward to prove that if m c then m c we write for the set i i o m given a finite set is of finite input streams we define is i o i is ci o it is easy to see that m c iff m we say an observation m is possible if there exists a program c that has the observation m for instance is possible because it is an observation on the sum program above but the observation is not possible any program that has primitive observation must also have the primitive observation and hence by determinism of programs it can not have observation proposition an observation is possible if and only if its is deterministic ie i o m and i o m implies that o o in the sequel we only consider possible observations we write obs for the set of all possible observations and use the metavariable m obs to range over them definition two programs c and c are observationally equivalent denoted by c c iff they have the same primitive observations it follows that if two programs c and c are not observationally equivalent there is some finite input i such that ci c i policies a policy p can be defined very generally as the set of programs allowed by the policy membership of the policy is required to be compatible with observational equivalence if c p then all programs observationally equivalent with c must also be in p hence one can also think of a policy as a set of sets of primitive observations a program satisfies the policy iff the set of primitive observations of the program is an element of the policy for black box dynamic enforcement mechanisms such as the ones in this paper we are interested in the subset of policies for which violation of the policy can be detected by means of a finite observation and for which the test of violation is decidable policies the policies for which violation can be detected by a finite observation were formalized by and as the policies if c is not in the policy then c has a finite observation that only programs by the policy have definition a policy p is a policy iff c p obs c c c c p if there is a bound k on the cardinality of these bad observations the policy is a policy definition a policy p is a policy iff c p obs c k c c c p policies can be specified by defining a set m of bad or observations the corresponding policy p is then defined as c p if and only if c has one of the specified bad observations m however for a given policy m need not be unique for example one may choose m to be the set containing any one for every c p example suppose there are two distinguished output values the program is sending something over the network and the program a read action on the file system the safety policy can be specified by the following set of bad observations i o where o is a boolean function defined as f o o o o where the boolean function o is true if the value o occurs in finite stream o is safety since every specified bad observation is a singleton containing primitive observation example noninterference ni the policy that low l outputs do not depend on high h inputs is a safety policy and can be specified by defining a set of observations as follows let be a function that assigns h or l to input and output values given a finite stream i let il be the resulting stream after out the input values i with h and similarly for ol then a program c is or c iff i i i il i l ol o l where ci o and ci o a set of bad observations that specifies is i o i o il i l ol o l a program c that has an observation in this set is not ni if c does not have any such observation then it is ni ni is a safety since the bad observations in the set above all have cardinality here is an example of a policy for arbitrary k example let oi be the act of the ith share of a secret for i k the policy that no observation on the program will ever reveal all k shares can be specified by defining the following set of bad observations i o ik ok o ok policies to enforce a policy it should be decidable whether an observation made on the program is allowed or not by the policy for policies specified by a set of bad observations m this seems to imply we want membership of m to be decidable however a policy can be specified by different sets of bad observations and membership can be decidable for some of these sets and not for others a canonical set of bad observations for a given policy is the maximal set definition for a policy p we define mp the maximal set of bad observations as mp c c c p an observation m is allowed by a policy p iff m mp it is maximal in the sense that any other set m that specifies the same policy p is a subset of mp for any policy p the maximal set mp always exists yet it is possible that p can be specified by a computable set of observations even if mp is not computable example let o be the set of closed terms t of the untyped calculus consider the policy that specifies that programs can only output valid reduction sequences in some deterministic reduction relation for any input the next term on the output is a valid reduction of the previous term on the output stream a program can therefore only emit a valid reduction of the term until it reaches normal form and then no valid output is possible recall from section that programs have to keep producing output possibly stuttering on a specific output value to model termination hence the only programs satisfying the policy are the programs that output sequences starting with a term whose reduction does not terminate and ad output further reductions of this term we define two predicates o which holds iff o is a valid reduction sequence and o which holds iff o is a valid reduction sequence that ends in a term that is not normalizing and hence can be further reduced long true t true t t o t reduces to t t o o o not normalizing we can use the following set of bad observations m i o m o membership in this set is computable and correctly captures the policy any bad program will eventually have one of these bad observations yet it is not maximal for the policy it specifies we can have observations eg a program a normalizing term that are themselves not in the specified set of bad observations but any program that has the observation is bound to eventually violate the policy once a program has output a normalizing term it will eventually have to stop valid reductions it can reduce until it reaches normal form but then the next element in the output cannot be obtained by a reduction of the former element and the policy is violated the maximal set corresponding to this policy is m i o m t any observation that is bound to eventually fail is in this set as soon as a program outputs a term that will always terminate ie is normalizing the program is rejected however membership in this maximal set is not computable as this would require deciding termination of terms definition a policy p is iff membership in mp is decidable for the construction of enforcement mechanisms we limit our attention to policies such policies can be specified by giving a total computable boolean function that for an observation m returns true iff m mp it is nontrivial to check whether a set of bad observations specified by a reject function is actually maximal for example the set of bad observations that we specified in example for ni is not maximal it does not contain observations that have violated the policy in the past but where things have as the execution as shown in the following example example suppose that i o and that l whereas h consider the following observation this observation is possible and it satisfies the simple test presented in example because the outputs are equivalent l l however no program that satisfies the ni policy can generate this observation because it will have to first generate the observation which would violate the policy fortunately the maximal set for ni is still decidable example ni a safety for the ni policy discussed in example a reject predicate can be constructed as follows true false i o i o m st il i l and ol o l otherwise it is straightforward to check that this is a total computable function we show that it specifies the maximal set of bad observations by contradiction suppose that there is an observation m such that false and m mp by construction of the reject function we have that false since mp is maximal m mp by definition of mp all programs c such that m c must not belong to the policy consider now one of such programs such that for all i o m o and otherwise it always outputs a value o with h this program satisfies the policy contradiction example the policy in example is an example of a policy that is not incrementally constructing observations allowed by a policy an enforcement mechanism must not only decide whether or not an observation is rejected by the policy it must also correct programs that turn out to have observations that are not allowed for instance by terminating the program or more generally by modifying the outputs of the program given an observation m of the untrusted program that is still allowed so far when we find for the next input i that the corresponding output will lead to a violation of the policy we need to find another output that will not lead to a violation of the policy definition given a set of bad observations m that specifies a policy a function i i is an extension function for m iff for any observation m m where i o m it returns an o o such that m i i o o m any extension function can be used for outputs think of i as the input processed so far i as the new input to be processed and m as the set of observations made on the program so far possibly including primitive observations on alternative input streams if the new output o observed of the program makes m i i o o a bad observation then i i can be used to replace this output one of the reasons why it is useful to work with the maximal set of bad observations to specify a policy is that for the maximal set an extension function always exists proposition for any policy p there exists an extension function for the maximal set of bad observations mp proof if the policy p is empty then all observations are bad observations in mp and therefore the precondition for the applicability of the extension function is false and we are done if the policy is not empty consider an observation m that is allowed by mp by definition of maximal set of bad observations there must be a program such that m and p if none m would have been in mp let i be an arbitrary input stream such that i o m and i an arbitrary input value by definition of observation on a program it must be o since programs are input total i has the form o o for some o o pick this o as the return value for m i i suppose now m i i o o mp since m i i o o by definition of maximal set of bad observation it should be p contradiction therefore the set m i i o o is also allowed by mp for a given policy p we write m i i as an abbreviation for some function m i i that is guaranteed to exist by the proposition above interestingly for policies there is always a total computable extension function proposition let p be a policy then there exists a total computable extension function for mp proof let m be an observation i be an arbitrary input stream in and i be an arbitrary input value the total computable extension function is constructed as follows if the first argument m already belongs to mp then the function returns an arbitrary output value in this case the precondition for the extension function is not satisfied and we can return any value otherwise the function all output values o and each observation m i i o o to the total computable membership test for mp until the reject function returns false since by proposition an exists such that m i i o is not in mp this procedure terminates the function constructed in the proof of this proposition is not very efficient many policies admit much more efficient ways of extending allowed observations example for the policy m i i can be defined to always return to an allowed output stream is always allowed example for the ni policy we can define m i i as follows let oh be an arbitrary output value with h if i i o o is in m then return o else if h then return oh else if l a if there exists i i o o in m st i l il then return o b otherwise return oh we show that this is a correct extension function by contradiction suppose there exists an input stream i an input value i and an output stream o such that i o m false and i i o o true where the reject predicate is specified as in example and o m i i is the result of the above algorithm by construction of the reject function we also have for all m let m m i i o o then by hypothesis and the properties of the reject predicate we have that true further since i o m we have that m m i i o o · if i i o o is in m then m m thus true contradiction · if h then o oh hence h since true there exists ib ob in m st i il and obl o ol because h it follows that i il il and o ol ol but then il and obl ol thus true contradiction · if l and there exists i i o o in m st i l il then o is o since true there exists ib ob in m st i il and obl o ol but i il i il and o o l o ol and since both ib ob and i i o o are in m it follows that true contradiction · if l and there is no i i o o in m st i l il then o oh since true there must exist ib in st i il let ib be the prefix of ib that removes all elements with level h at the end of ib then ib is in and it must have the form ib i and it must have ib l il contradiction black box enforcement mechanisms definition we model enforcement mechanisms as total computable functions from programs to programs they turn a program that possibly does not satisfy the policy into a program that definitely with the policy the security property moreover they do not have any observable impact on untrusted programs that do happen to satisfy the policy the precision property finally they should be black box ie only depend on the observable behaviour of their input program definition a black box enforcement mechanism for a policy p is a total computable function ep from programs to programs which satisfies the following properties · security for all programs c ep c p · precision if c p then c ep c · black box if c c then ep c ep c a policy p is black box iff there exists a secure and precise black box enforcement mechanism for p because enforcement mechanisms produce programs in our program model they have to to any input event in finite time with an appropriate output event without inputs or outputs in this section we derive upper and lower bounds on the set of black box policies upper bounds on black box policies first any policy that is black box is a policy theorem if an enforcement mechanism ep exists for a policy p then p is a policy proof suppose c p we have to construct an such that c and c c c p if c p then by security of the enforcement mechanism ep c is not observationally equivalent to c hence there must be some finite input stream i such that ci ep ci take as the set of all primitive observations that ep has done on c during the execution of ep ci and add the primitive observation i ci this set is necessarily finite as ep ci must process the finite input i in finite time it is clear that holds as is constructed only using primitive observations on c in order to prove suppose a program c has this same observation then c i ci because includes i ci but also ep c i ep ci as c will exactly as c to all the observations that ep does while processing the input stream i and ep is a deterministic program hence c i ep c i by hypothesis the enforcement mechanism is precise and therefore c p obviously the converse is not true there are many policies that are not for instance the policy in example is not if the program outputs a first term the enforcement mechanism should output this term iff it is nonterminating obviously it cannot decide this in finite time this upper bound can be substantially we say a policy is if membership in mp is enumerable ie we can enumerate all the observations that are allowed by the policy theorem let p be a policy if an enforcement mechanism ep exists for p then p is proof we have to provide an algorithm for the reject function that will return false for any observation m that is not in mp and will return true or diverge for any observation m that is in mp given an observation m the algorithm all possible programs in some complete programming language for writing reactive programs for each program it applies the enforcement mechanism to and then tries to observe m it returns false if it can observe m and otherwise continues with the next program if m mp then ­ by the security property of the enforcement mechanism ­ m will never be observed and the algorithm diverges if m mp then ­ by the of mp there exists some program that has m and satisfies p by precision the enforcement mechanism applied to will be observationally equivalent to and hence will have observation m hence if m mp we will eventually enumerate and the algorithm for the reject function will terminate with return value false a lower bound on black box policies for safety policies it is obvious that as defined in definition is a sufficient condition for if membership of an observation in the maximal set of bad observations is decidable then it is obviously possible to decide whether primitive observation i o is a bad observation therefore one can simply use the reject function as a security automaton in the sense of at the point where the primitive observation corresponding to the current execution is about to violate the policy one can use the extension function to correct the execution considers only termination as a measure in the terminology of this paper he assumes that is never by any policy and hence one can use the constant function on as an extension function in cases where policies can talk about termination too one can use another extension function only in the case where the policy is empty and hence the maximal set of bad observations contains all observations a safety policy is not black box surprisingly is also a sufficient condition for black box for general policies we show that in this section by constructing a secure and precise enforcement mechanism for any policy we need to address two challenges testing a sufficient number of alternative executions and doing in a consistent way generating sufficient test inputs for policies with k it is not obvious that is a sufficient condition for for such policies the enforcement mechanism should not only look at the inputoutput streams i o of the current execution for it should also make sure that other primitive observations that the policy defines to be incompatible with the current execution do not exist and in general there will be infinitely many alternate input streams that can possibly lead to incompatible observations example for the ni policy for a given primitive observation i o the set of all other primitive observations that are incompatible with i o is i o il i l o l ol this set contains an infinite number of input streams i so the enforcement mechanism can not query the program c with all of them in finite time fortunately it is not necessary to check the behavior of the program on all input streams that might be potentially conflicting with the current input stream we introduce the notion of test generator a function that computes a finite and sufficient set of alternative input streams to check definition a test generator for a policy p is a function g i finite i st for all c c and all mp i mp c in other words if a program c has a bad observation then there is at least one input stream i for which gi is a sufficiently large set of input streams such that testing the program c on these input streams in addition to the actual input stream i will detect a policy violation lemma if for every i gi i mp then c p proof suppose c p by definition there is a bad observation mp such that c from the property of generators in definition it follows that there exists an i such that gi i mp but this contradicts the condition of the lemma example for safety policies gi is a test generator since a safety policy defines a predicate on primitive tions any contains at least one i o that violates the predicate hence if c then at least one of the i ci will be in mp example for the ni policy from example with reject in example gi il is a test generator let this means there must exist i o i o with il i l and ol o l now suppose c ie ci o and ci o we show that c has a bad observation either on inputs i and il or on inputs i and i l consider the output o of c on il i l since ol o l we must have either that o ol or o o l · if o i l · if o i l ol then c has a bad observation on inputs i and o l then c has a bad observation on inputs i and this implies that g is a generator we can further reduce the size of the generator let us define g as follows g i if il i then else il since for all i gi i g i i it follows easily from definition that g is a generator if g is a generator consistently executions a second challenge that needs to be addressed is how to correct executions while processing an input stream i the enforcement mechanism will explore other input streams in order to check that there are no bad observations so the output for input stream i will be computed in different while ep c is actually processing i as well as while the mechanisms actual input is another stream i and the stream i is only considered as a potential candidate with i for membership in a bad set the enforcement mechanism should compute the same output for i in any of these example assume that i o i i is defined for i and i of equal length as a pairwise of i and i where and similarly we define o o let resp denote a stream consisting of only values resp values a program c satisfies a policy iff i i i i o o the reject function that is as follows true i o i o m st i i and o o false otherwise we define gi i i i obviously given an i such i is unique it is easy to show that it actually is a test generator now consider a naive construction of an enforcement mechanism that on execution of a program c on input stream i checks the behavior of c also on gi i if the enforcement mechanism finds that ci ci it the output for ci to make it with the policy for instance let c be the program that just outputs for any input value ie ci for any i if c is executed on the enforcement mechanism would see that c and that c and it would decide to correct the output for to it is easy to see that is not a secure enforcement mechanism because if c is executed on it would see that c and that c and it would decide to correct the output for to essentially c will be a program that always outputs on every input and it violates the policy as as c does this is an example of inconsistent on execution of c on we are considering the alternate execution but we are not taking into account that the alternate execution might as well be if it were ever executed consistency of is challenging one idea is to use recursive invocations of the enforcement mechanism while checking alternative inputs example for the example above if c is executed on the enforcement mechanism would see that c and then it should not check this against c but against c unfortunately for the given generator this would lead to divergence as c will again recursively call c we address the issue of divergence by means of the notion of wellfounded test generator a generator is wellfounded if there exists a wellfounded partial order on the set of finite input streams such that · i ii · i gi i i now we can recursively call the enforcement mechanism on alternative input streams generated by the generator and this will make sure that are done consistently example consider again the policy we now propose the following generator gi and gi i i i this is a wellfounded generator the partial order can be defined as the transitive closure of i i i and i i now consider again an enforcement mechanism that on execution of an untrusted program c on input stream i checks the behaviour of c also on gi now the enforcement mechanism will let any program c do its original output on s and it will correct the output on s so that the policy is satisfied for instance let c again be the program that just outputs for any input value if c is executed on the enforcement mechanism would output if c is executed on our algorithm would see that c and that c and it would decide to correct the output for to essentially c will now be a program that inputs on outputs and hence it is a secure program the recursive calls to c always terminate thanks to the wellfounded generator lemma every nonempty policy has a wellfounded generator proof construct an enumeration of i the set of finite streams of input values that has the property that i is before i i for all i i the constructed enumeration defines a total order on i say i i if i is before i define the generator gi i i i it is easy to check that this is a generator for any let i be the maximal element in the set then gi i since c is deterministic and gi i if c then gi i and hence gi i mp from the property of maximal set of bad observations a generic enforcement mechanism we now have all the necessary to construct a secure and precise enforcement mechanism for any policy this construction will be useful in two ways we will use it in section to construct enforcement mechanisms for interesting policies by constructing efficient wellfounded generators for these policies we will also use it to show a lower bound on policies theorem definition let p be a policy specified as a total computable predicate with a total computable wellfounded generator gi and a total computable extension function m i i we define a function ep from programs to programs as follows a state of ep c is a tuple i c c o where c is the original program c is the current state of the program after input i and o is a good output of the enforcement mechanism on i or ep ci o the initial state of ep c is a tuple c c the transition relation of ep c is defined by the following rules m c gi i c io c i i o o false ok io i c c o i i c c o o m c gi i i i o o true c io c o m i o i i io i c c o i i c c o o the first rule says that if the observation obtained by combining the recursive application of ep to gi i and the new observation that c is producing are allowed by the policy then we just release the output of c the second rule says that if the obtained observation is not allowed we will correct the execution we correct it by selecting a new output using the consistent extension function the successor state for the program can be an arbitrary program c as the program being is definitely not with the policy we do no longer have to care about precision c could for instance be a state that terminates ie the output while c can be chosen arbitrarily the enforcement mechanism should choose it based only on its current state and input in order to make ep c a deterministic program notice that in the antecedent of our rules we do not check the output of the program c on the additional inputs from the generator but the output of ep c this avoids inconsistency of as we had in example we have to show that the rules ok and are a proper definition for a program lemma for every state i c c o of the enforcement mechanism and for every input i the transition relation is total computable and deterministic proof we show both properties by total induction on the wellfounded order on i so suppose both properties and hold for all states i c c o and input i with i i i i the transition from i c c o on input i is total computable because a the transition relation on c is total computable b the reject and extension functions are total computable and c the computation of the map of ep c only needs a finite number of transitions on states i c c o and inputs i such that i i i i this follows from the fact that g is wellfounded and hence all i gi i i i hence by the induction hypothesis all these transitions are total computable the transition from i c c o on input i is deterministic because a the transition relation on c is deterministic b the computation of the map of ep c only needs transitions on states i c c o and inputs i such that i i i i hence by the induction hypothesis all these transitions are deterministic now reject returns either true or false for the false case we are done for the true case since the extension function is indeed a function and its parameters are determined by the input state and input value this function returns an o finally the state c in the output state is chosen arbitrarily but based on current state and input value now that we have established that ep is a total computable function from programs to programs we can prove its properties theorem security let p be a and nonempty policy then ep c p for any c proof let us say that a program c is secure if it does not have any bad observation with for all i i i we first show the following property for all i i ep c is secure we prove this by complete induction on the order so suppose the property holds for all inputs i i we prove it holds for i for the case where i is empty since the empty list is a minimal element under the relation we just have to show that the primitive observation is not in mp this follows from the fact that p is nonempty there is a program c p and every c has the observation for the case where i has the form i i we show that c gi i i i mp · for the where the last output on this input was derived by the ok rule this follows from the fact that i i o o false for m c gi i · for the where the last output on this input was derived by the rule we can use the induction hypothesis all the input streams in gi i i are i i hence the first argument to the extend function is an allowed observation by the property of the extend function we then also get for this that c gi i i i mp now we can show that ep c is secure suppose there is an with all elements of i then we can easily see that for all i it holds that c mp for i i this follows from the induction hypothesis and the fact that g is wellfounded for i i we have just shown it but then the definition of test generator tells us that mp finally using this fact that ep c is secure for all i we can apply lemma and we get that ep c p theorem ep c is precise proof we have to show that c and ep c have exactly the same primitive observations when c p we show this by complete induction on the wellfounded partial order on i assume that c and ep c have the same primitive observations i o for all i i i we have to show that ep ci i ci i from the induction hypothesis it follows that the derivation of the last step of ep c processing input i i was done by the ok rule ep c is applied only on i i i hence the induction hypothesis applies and ep c has the same outputs as c on gi i hence c gi i i i o o is actually an observation on c and since c p it follows that c gi i i i o o mp and hence the call to reject must return false as a consequence the primitive observation of ep c on i i is the same as the primitive observation of c on i i theorem ep c is black box proof by the same induction technique as in lemma one can show that c gi i is equal to c gi i if c c a lower bound finally we can establish an interesting lower bound for the set of black box policies theorem every nonempty policy is black box proof for any nonempty policy · the reject predicate is total computable by definition of · proposition gives us a total computable extension function · lemma gives us a wellfounded generator hence we can construct an enforcement mechanism as in definition and theorems and tell us that this enforcement mechanism is secure precise and black box obviously this construction is very inefficient but from a theoretical point of view this lower bound on the class of black box policies is interesting in the next section we turn to constructing concrete enforcement mechanisms instances given a policy p the steps that need to be taken to enforce the policy using our generic enforcement mechanism are specify a total computable reject function that membership in mp prove that the set of observations for which reject returns true is indeed maximal in the sense of definition specify a total computable test generator function and prove it satisfies the property required of a test generator as in definition specify a total computable extension function and prove that it has the property required of such a function as specified in definition since our enforcement mechanism only applies extend to observations m with of the form gi i i it is sufficient to define extend for such input parameters in this section we construct interesting instances and relate them to existing enforcement mechanisms we also discuss some optimizations to improve the performance of the generic enforcement mechanism safety policies the simplest instantiation of our mechanism is the case where p is a safety policy the generator g maps every i on example the reject function can be simplified to just a boolean predicate on primitive observations ensures that any primitive observation that is not rejected can be further extended in a way acceptable to the policy hence reject is a in the sense of et al the extend function just takes a primitive observation i o and a new input i and returns a valid output o since g always returns the empty set no recursive calls of the enforcement mechanism are needed processing an inputoutput event just requires one call to reject and one call to extend even this simplest instantiation admits interesting examples example for the policy reject was specified in example the generator always returns the empty set and an extend function was defined in example example consider the policy that any primitive observation of length than also counting the output values this policy is empty no program and hence not the reject function for this policy is the constant function that returns true suppose the policy requires termination after at most steps this policy is the reject function is o o drop o the extend function always returns the termination event o i if a program fails to terminate before its th step the enforcement mechanism will force it to terminate for instance the sum program from listing will process the input stream to the output stream when executed under this enforcement mechanism noninterference with two levels let pr be a total idempotent function from finite input streams to finite input streams that is for all i i we think of pr as a projection that removes information from the input stream a program c is wrt pr iff i i i ol o l where ci o and ci o the projection pr can be instantiated in many ways and our enforcement mechanism can handle all these instantiations · where is the resulting stream after replacing the h input values in i with default values this is a variation of ni where content of input events is secret but the occurrence of the input event is not with the optimizations in section our generic enforcement mechanism reduces to standard secure · il models standard ni as in example our generic enforcement mechanism defines a reactive variant of secure as in · pr can more generally project to values that depend on all previous values in the input stream this can model for instance ni with stateful declassification policies our generic enforcement mechanism even improves on the mechanism in as it does not require annotations for precision since in a operator is just a indicating that a particular value is computed by the release function construction of the reject predicate and the test generator for this policy is similar to example and example for this more general case the following definitions work true false i o i o m st and ol o l otherwise gi i the well order for the generator is the smallest ordering such that for all i and i i i i and if i then i a sufficient condition is that has smaller or equal length as i and this is satisfied in all instances for pr mentioned above since extend is only called for m i o i i o o where i i i this function is as below where oh is an arbitrary value such that h m i i oh o if h where h if l noninterference for multiple levels it is relatively to extend all the variants of ni above to multiple confidentiality levels we illustrate this for standard ni let l be a complete lattice of security levels with a top level and a bottom level and let be a function from i o to l a program c is with respect to iff i i i il i l ol o l where ci o and ci o and il filters out all i with i l and similarly for ol true false i o i o m st il i l and ol o l for some l otherwise gi il l l i o if where m i i o if taking into account that extend is only called for m i o i i o o i i gi i and i i o o is in m where i i i i optimizations and extensions the construction in definition is designed to minimize the state of the enforcement mechanism thus making the security and precision proofs relatively simple however it is very in terms of execution time the recursive calls to the enforcement mechanism will often observations on ep c over and over many times a standard optimization for such cases is memoization cache the results of calls to ep c in some data structure and reuse them from the cache instead of them a data structure that is particularly well suited for optimization of our enforcement mechanism is an array of entries ij cj oj where for each j it holds that ij c cj oj is the state reached by the enforcement mechanism after processing input stream ij this data structure caches all the output streams that ep c produces on any of the ij or prefixes of ij and it is efficient to update the data structure for growing ij essentially such a data structure maintains a set of alternative executions of c taking into account to the execution where necessary in a way that is very close to secure proving the correctness of this optimization for an arbitrary policy and relating it to secure is an interesting for future work finally our generic construction also constructs secure and precise enforcement mechanism for many other policies however it is not always obvious that efficient test generators exist for example the policy from example is but we have not been able to come up with an efficient generator for this policy another interesting line of future work is to look for efficient generators for other policies discussion many enforcement mechanisms used in practice make no or very limited use of analysis of the code of the programs they are monitoring operating system kernels virtual machine monitors and application treat the programs they are as black boxes hence it is interesting to understand what exactly can be enforced under this black box constraint figure summarizes our results on upper and lower bounds for the class of black box policies the region corresponds to the class of policies that are black box as defined in definition first in theorem we have shown that any policy that is black box must be more importantly in theorem we have shown that such policies must be policies based on this theorem the policy in example is not black box finally in theorem we have shown that every nonempty policy is black box the empty policy is not since there is no program in this policy and the mechanism is just a program an interesting question is how tight the bounds we establish for black box policies are there is a gap between the sufficient condition ie that the policy is and the necessary condition ie that the policy is clearly the upper bound is not tight an example safety policy that is but not is the policy that requires programs to only output terminating terms the complement of the maximal set of bad observations is recursively enumerable hence the policy is however an enforcement mechanism would have to decide termination the question now is whether the subset marked with on figure is empty for the and ni not nonterminating reduction sequence ex but no em example output valid reduction sequences of terms output terminating terms black box ni empty policy figure lower and upper bounds of black box policies lower bound we believe it might actually be tight but we have not been able to prove this yet one important aspect of our results is the fact that they hold for our specific model of reactive programs where programs can not diverge on a single input value on the one hand this is a positive aspect as many programs satisfy this constraint and under this program model enforcement mechanisms can be guaranteed not to diverge while still being allowed to execute programs until the next observable output divergence of a program could perhaps be modeled by having the program with a special output value to any input value while but this does impact the policies that are as output values such as become observable and hence policies have to take them into account on the other hand this constraint on programs makes enforcement easier and some of our results will clearly not hold for programs that do diverge on some inputs an important question for future work is to explore the impact of variations of the program model on our results another interesting question to ask is what is the relation between policies by program rewriting and the black box policies under our model of programs clearly the black box policies are also by rewriting but seem to have additional power as they can and transform the code of the program at will however we have not been able to find policies that are by rewriting but not black box it seems that the power to edit inputoutput events and explore alternative runs is very close to the power to rewrite and code ­ at least if one operates under the constraints that the resulting enforcement mechanism must be secure and precise and programs must not diverge on single inputs besides the bounds on this article also introduces a general enforcement mechanism that can be used to build practical enforcement mechanisms this was demonstrated in section where we have seen that several different of enforcement mechanisms for ni are particular instances of our techniques with efficient test generators we believe that the existence of efficient test generators is the key to practical in fact one can prove that the existence of an efficient enforcement mechanism implies the existence of an efficient test generator one can take as gi all the input streams i that the efficient enforcement mechanism to the untrusted program while processing input i it is not too hard to see that this defines a test generator hence we believe one of the interesting conclusions of this work is that the key to developing a black box enforcement mechanism for a policy is to come up with an efficient test generator related work enforcement power of enforcement mechanisms and the investigation of dynamic enforcement of security policies via execution monitoring em demonstrated that for a security policy to be by em the policy has to be a safety property on execution traces he also introduced a class of monitors called security automata that can be used as for safety properties such an automaton is capable of observing system actions violations and terminating the observed system called the target when it is about to perform a violation a target system is allowed to perform a computation step if and only if the respective security automaton can transition to some next state by performing the same step our proposed mechanisms can be seen as a generalization of security policies as they can be instantiated on nonempty safety policies work was refined by who showed that a property has to be decidable in order to be formally argued that the class of dynamically policies with em is actually equivalent to the class of enumerable core properties also known as the class of the arithmetic hierarchy however it was later shown by et al that core is actually an upper bound on the class of em properties the reason is that some policies in core are not because the monitor might not have enough power to for instance it is impossible to enforce a policy that all the available to the em analyzed the impact of on the enforcement mechanisms he introduced shallow history automata which only store information about the occurrence of past events and not about their order despite this limitation many interesting properties were shown to remain et al extended work by introducing bounded history automata combining features of security and edit automata and having bounded memory in addition they proposed an algorithm that whether there exists a bounded history automaton for a policy in a language from a subclass of the regular languages called the locally languages et al investigated the properties that are by different automata models with a finite set of control states and enforcement operations in terms of the hierarchy in addition they presented a systematic technique to synthesize monitors from an automaton some safety guarantee obligation or response properties et al defined the class of security policies by program rewriting rw and called it rw however they did not provide a precise characterization of this class and even argued that a characterization in complexity theoretic terms might not exist finally et al explored the problem of policy enforcement wrt a trace universe they showed that a enforcement mechanism is more powerful if it only considers the possible traces and not all traces in the trace universe they also presented an algorithm that takes as an input a finite state automaton ie the policy and a finite state transition system ie the target system and checks if the policy is additionally if the policy is found to be the algorithm returns a version of the target system et al introduced edit automata capable of enforcing a class of including purely liveness policies called infinite properties they argued that infinite properties the computable safety properties edit automata are a black box enforcement mechanism capable of inserting and deleting system actions as well as terminating a target system in the case of a policy violation the authors also showed how to construct an enforcement mechanism that provably enforces any reasonable infinite property edit automata are similar to our approach in that they offer a black box mechanism capable of monitoring andor editing the inputoutput behavior of programs however to enforce infinite properties they have to buffer program actions ­ something that is for reactive programs also edit automata are not capable of exploring alternative executions unlike edit automata automata have an interface to interact with a target system they get requests from the system and send outputs back to the system but do not enforce policies that are more expressive than those investigated by et al and his work and proposed to distinguish between actions that are under the control of the enforcement mechanism and actions that are merely observable for instance the passing of time ie the mechanism cannot prevent their execution for this refinement of the problem the authors presented necessary and sufficient conditions to characterize when a policy is em based on their generalized notion of safety in addition they studied the problem of whether a policy is for several specification languages they also showed how to synthesize an enforcement mechanism for a given policy and gave complexity results and were the first to propose sets of trace properties as a model for security policies they generalized safety and liveness to and and proposed a static verification approach for verifying with a property the fact that so well with black box is additional evidence that their classification of security policies as or is a useful of policies existing black box enforcement mechanisms for noninterference besides the general purpose black box enforcement mechanisms such as the different variants of execution monitors and edit automata discussed above a considerable amount of research has been done on dynamic enforcement of noninterference some of it assuming only black box access to programs le phd thesis presents an extensive survey of the state of the art in dynamic information flow control the major more recent results are presented next there have been several proposals for information flow runtime monitors sabelfeld et al proposed such monitors for structures dynamic code evaluation and austin and presented alternative techniques that have the potential of being more permissive all these monitors are useful and relatively efficient however a common problem is that they are not precise ie they the problem and as a result sometimes block secure executions a secure and precise dynamic enforcement technique is secure developed independently by several researchers et al proposed a technique called data which partitions the program into two programs at level and then uses system call to control the output channels in a article et al partitioning instead they proposed to run two processes for the public and secret levels respectively and as a result provide strong confidentiality guarantees and independently proposed the related technique that they called the overall idea of is to keep a program secure by separating computations at different security levels to that end the original program is executed multiple times once for each security level and giving inputs and outputs special treatment this technique guarantees security and precision austin and flanagan developed a more efficient implementation of based on evaluation and sabelfeld the technique to distinguish between presence and content of secret messages on a channel to perform declassification and to make precise for having access to more than one level et al proposed combining with execution monitoring the idea is at each step to compare the current execution with what would produce in order to detect and report actions that the policy similarly to and sabelfeld they use a scheduling strategy that preserves the interleaving of events from different security levels thus increasing the precision of et al proposed an technique for enforcing information flow policies with support for stateful declassification for programs they used a projection function to specify what information about an event can be and a stateful release function to specify aggregate information about secret events seen so far that can be it is clear that the mechanisms presented in this work are a generalization and at the same time go beyond a number of of for instance the one with levels the one with and with stateful declassification conclusion we have studied security policy enforcement mechanisms for deterministic reactive programs that to input events in finite time with an observable output event our enforcement mechanisms are black box the enforcement mechanism only needs to be able to and edit the inputoutput events of the untrusted program and run multiple isolated copies of the untrusted program in order to test the behaviour of the program on alternative inputs the enforcement mechanism can not do or more does not need to do analysis on the source or machine code of the program we have given a constructive proof that under these assumptions any policy is if it is decidable whether an observation can not be produced by any program in the policy then the policy is black box by a generic enforcement mechanism the construction in the proof is inefficient but one can construct more efficient enforcement mechanisms by providing a reject function an efficient test generator and an extension function as inputs to the general construction we have also shown an upper bound on black box policies any policy is a policy ie the observations that are possible for some program in the policy are enumerable while these lower and upper bounds are of theoretical interest we have also shown that our generic enforcement mechanism is of practical interest by instantiating it to concrete enforcement mechanisms for a number of relevant policies acknowledgments the authors are to for this paper and numerous improvements this research is partially by the research by the research foundation by the project n and by the project references a and a sabelfeld tight enforcement of policies for dynamic languages in pages ­ t h austin and c flanagan permissive dynamic information flow analysis in pages ­ t h austin and c flanagan multiple for dynamic information flow in popl pages ­ d v f and e security policies ­ june n d f and f reactive noninterference for a browser model in th international conference on network and system security pages ­ a b c pierce v s weirich and s reactive noninterference in ccs pages ­ r a v n and a p preventing information leaks through executions in pages ­ h r and n extending the enforcement power of monitors using static analysis computers security ­ june e y z manna and a pnueli characterization of temporal property classes in icalp pages ­ m r and f b ­ september d and f noninterference through secure in ieee sp pages ­ u and f b enforcement of security policies a in workshop on new security pages ­ y l jc and jl runtime enforcement monitors composition synthesis and enforcement formal methods in system design ­ p w l access control by tracking shallow execution history in ieee sp pages ­ k w g morrisett and f b classes for enforcement mechanisms toplas ­ t r and v n data a technique for enforcing confidentiality policies in pages ­ g le confidentiality enforcement using dynamic information flow analyses phd thesis state university j l and d walker edit automata enforcement mechanisms for runtime security policies int j of inf sec ­ ­ february j l and d walker runtime enforcement of policies ­ j and s a theory of runtime enforcement with results in pages ­ r and s a automata mit research no the mit press w and a sabelfeld secure finegrained and transparent in pages ­ a and a sabelfeld timeout instructions in web applications in pages ­ a a sabelfeld and a tracking information flow in dynamic tree structures in pages ­ f security policies ­ c n and m execution monitoring enforcement under constraints inf comput ­ m w de d f and t stateful declassification policies for programs in m foundations for the runtime analysis of software systems phd thesis university of pennsylvania a r b and l p keeping applications from the in th usenix conference on systems design implementation pages ­ d m and a precise enforcement of confidentiality for reactive systems in pages ­ 