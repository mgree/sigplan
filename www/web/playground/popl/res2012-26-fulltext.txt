synchronization inference by abduction university of cambridge university of cambridge university abstract we present an analysis which takes as its input a sequential program augmented with annotations indicating potential parallelization opportunities and a sequential proof written in separation logic and produces a program and proof of that program unlike previous work ours is not an independence analysis we insert synchronization constructs to preserve relevant dependencies found in the sequential program that may otherwise be violated by a translation separation logic allows us to finegrained patterns of moving beyond straightforward pointsto analysis our analysis works by using the sequential proof to discover dependencies between different parts of the program it these discovered dependencies to guide the insertion of synchronization primitives into the program and to ensure that the resulting program satisfies the same specification as the original sequential program and the same sequential behaviour our analysis is built using frame inference and abduction two techniques supported by an increasing number of separation logic tools categories and subject descriptors d software engineering program proofs d programming languages language constructs and programming structures general terms languages theory verification keywords separation logic abduction frame inference deterministic parallelism introduction automatically verifying the safety properties of concurrent programs remains a challenging problem to be useful in practice proof tools must a explore a potentially large number of interleavings and b construct precise flow and abstractions of a shared heap just as significantly verification complexity is often at with the straightforward of the programmer lowlevel concurrency control abstractions such as locks higherlevel notions such as atomicity and linearizability likely to be exploited by the programmer when writing programs while attempts to incorporate these notions directly into programs have met permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ pa usa copyright c acm with some example in software transactional memory there remains a substantial burden on the programmer to ensure programs can be partitioned into atomic and threadlocal sections automated proof used to verify program correctness must also this knowledge to ensure on relevant behaviour eg serializability and irrelevant details eg threadlocal state the alternative expressing such in specifications is too often to be acceptable in practice in any case the inherent complexity of dealing with concurrency both for the programmer and for the verifier unfortunately remains in many cases concurrency is an optimization rather than to the behaviour of the program that is a concurrent programs is often intended to achieve the same effect of a simpler sequential counterpart consequently an alternative to constructing a concurrent programming is to automatically one in this approach the programmer writes a sequential program the program is automatically transformed into a concurrent one the same behaviour ­ in this context the verification problem becomes significantly more tractable understanding and verifying the concurrent program reduces to first verifying the sequential program and second verifying the transformation we propose a program analysis and transformation that yields a program by a safety proof of the original sequential program to guide the transformation we assume that the programmer points in the sequential program where concurrency can be exploited without any additional concurrency control or synchronization the result of the transformation is a concurrent program with corresponding behaviour and a safety proof for the concurrent program in this sense programs are verified by construction while our analysis is driven by a safety proof parallelization all behaviours not just those specified in the proof thus we can apply our approach to complex algorithms without to verify total functional correctness our transformation ensures that behaviour is preserved by requiring that the concurrent program respects sequential in other words the way threads access and modify shared resources never results in behaviour that would not be possible under sequential evaluation to enforce these dependencies the transformation barriers operations that when threads are allowed to read or write shared state these barriers can be viewed as resource transfer operations which acquire and access to shared resources such as data structures and regions when necessary our analysis is built on separation logic by tracking how resources are and consumed within a separation logic this approach is commonly known as deterministic parallelism although our approach does not in fact require that the input sequential program is deterministic proof we can synthesize barriers to precisely control access to these resources our approach relies on frame inference and abduction two techniques that generate finegrained information on when resources are necessary and when they are redundant this information enables optimizations that depend on deep structural properties of the example we can split a linked list into segments and transmit portions between threads our analysis thus enforces sequential order over visible behaviours while allowing parallelization where it has no effect on behaviour as our technique safely transforms a sequential program into a concurrent one it can also be viewed as a kind of compiler optimization notably our transformation is not based on an independence focus is not to identify when two potentially concurrent code regions do not interfere instead our analysis sufficient synchronization to ensure relevant sequential dependencies are preserved even when regions share state and thus potentially interfere contributions we present an automated technique to synthesize a parallel program given a sequential program augmented with annotations indicating computations that are candidates for parallelization the provided specifications are used to define relevant loop invariants we abduction and frame inference to define a contextsensitive program analysis capable of identifying per resources that are both are resources that would no longer be used by the thread executing this computation and are resources that would be required by any thread that executes this computation but which is not known to have been released at this point we use information from the above analysis to grant and allowed barriers into the original program their semantics enable resource transfer from redundant to needed resource points the analysis also constructs a safety proof in separation logic which the correctness of the barrier we prove that our transformation is the program is guaranteed to satisfy the same specification as the sequential program moreover for terminating programs that do not memory we also show that the transformed program preserves the behaviour of the original complete proofs and other supporting material can be found in an associated technical report paper structure an overview of the approach and motivating examples are given in § issues that arise in dealing with loops and recursive datatypes such as lists are discussed in § the analysis and transformation are formalized in § and § behaviour preservation results are discussed in § observations about the between analysis precision and the predicates available in defining specifications are given in § § discusses related work overview the objective of our analysis is to take a sequential program with annotations indicating where concurrency may be exploited and to produce a program that to the same specification to do this we insert synchronization barriers enforcing those sequential dependencies that can affect the observable behaviour of the program our analysis uses separation logic to capture and manipulate these dependencies the programmer must provide a proof of safety for the sequential program this proof is used to the parallelization process allowing our analysis to calculate precisely global x y void main local i n n x alloc y alloc fi void fi local vx if vi gy v else gx void gp v p v figure a simple parallel program that operates over shared locations x and y the number of concurrent iterations performed is chosen nondeterministically to represent the act of receiving values from some unknown process or user interaction which resources can be accessed in parallel and which must be accessed sequentially in order to preserve sequential dependencies parallelization and we assume that the portions of a program that can be will be written as loops the intended semantics of a loop is that every iteration will run in parallel but that the behaviour will be identical to running them in sequence this semantics provides a simple but useful form of data parallelism in which concurrently executing computations may nonetheless have access to shared state for example consider the program shown in fig how can we this program without introducing any new behaviours ie behaviours not possible under sequential execution we might simply run every iteration of the in parallel without synchronization that is f f in some cases this parallelization is good and introduces no new observable behaviours eg if v is greater than n but under others the second call to f may write to a memory location that is subsequently read by the first call to f intended sequential ordering for example consider the case when v is initially and n is sequential execution would produce a final result in which the locations pointed to by x and y resp are and while executing the second iteration before the first would yield a result in which the location pointed to by y remains undefined to be sure that no new observable behaviour is introduced we must ensure that · no iteration can read from a location that was already written to by a later iteration · no iteration can write to a location that was already read from or written to by a later iteration in order to enforce this behaviour we must introduce a mechanism to force later iterations to wait for earlier ones note that later iterations need not always wait for earlier is only needed when reads and writes to a particular memory location could result in behaviour we want to enforce dependencies while allowing concurrency barriers our analysis inserts barriers into the program requiring logically later iterations to wait for earlier ones we introduce grant a barrier that signals to subsequent iterations that a resource can safely be accessed and wait a barrier that blocks until the associated resource becomes available from preceding iterations fi local vx if vi v else gap v pv v pv fi local vx if vi v else gap v pv v pv figure parallelization of f only synchronization barriers between the first and second iterations are shown how can we use these barriers to enforce sequential dependencies in the example program the exact pattern of parallelization depends on the of our parallelization analysis in the best case there are no dependencies between iterations eg each iteration operates on a different portion of a data structure in this case we need no barriers and all iterations run independently however our example program shares the locations x and y meaning barriers are required in the worst case each iteration of the begins with a call to wait and ends with a call to would enforce sequential ordering on the iterations a better although still relatively simple parallelization is shown in fig to simplify the presentation we only show the synchronization barriers between the first and second iterations of we write f for the first iteration and f for the second our full analysis generates a single version of f with sufficient barriers to run an arbitrary number of iterations in parallel see § for a description two channels wx and wy are used to signal between f and resp wy is used to signal that the later thread can read and write to the heap location referred to by x resp y the function g has different resource requirements depending on its calling context consequently we have specialized it to embed appropriate barriers depending on its context our analysis inserts barriers so that an iteration of the only calls grant on a signal when the associated resource will no longer be accessed similarly it ensures that an iteration calls wait to acquire the resource before the resource is accessed how does our analysis generate these synchronization barriers the example we have given here is simple but in general our analysis must with complex resources such as linked lists it must deal with the partial ownership for example and with manipulating portions of a dynamic structure for example just the head of a linked list we therefore need a means to express complex dynamic patterns of resource management and transfer to achieve this our analysis assumes a sequential proof written in separation logic rather than just an program this proof need not capture full functional is sufficient just to prove we exploit the dependencies expressed within this proof to determine the resources that are needed at a program point and when they can be released our analysis inserts barriers to enforce the sequential represented in this proof as our proof system is sound these dependencies represent those in the original sequential program resources separation and dependency at the of our analysis is automated reasoning using concurrent separation logic separation logic is a program logic for reasoning about mutable resources a separation logic proof of a program c establishes a specification p c q this can be be read as saying the program c if run in a resource satisfying p will not fault and will give a resource satisfying q if it terminates in general a resource can be anything for which ownership can be partitioned separated between different threads in practice resources are most often structures such as lists trees locks etc where separation corresponds to disjointness between underlying heap addresses an essential feature of separation logic is that specifications are tight this means that all of the resources accessed by a program c must be described in its precondition p or acquired through explicit resource transfer no other resources will be accessed or affected by c when executed from a resource satisfying p the tight interpretation is essential for our analysis suppose we prove a specification for a program or portion resources outside of the precondition cannot affect the programs behaviour and consequently can be safely to other threads one result of this tight interpretation is the frame rule which allows a small specification to be embedded into a larger context p c q p f c q f frame here is the separating conjunction an assertion p f is satisfied if p and f hold and the portions of the state they denote do not overlap the concurrent counterpart of the frame rule is the parallel rule this allows two threads that access resources to run in parallel without each others behaviour p c q p p c p c q c q q parallel the parallel rule enforces the absence of between c and c the two threads can consequently only affect each others behaviour by communicating through synchronization mechanisms such as locks or barriers automatic inference automated reasoning in separation logic around two kinds of inference questions the first frame inference the portion of a formula s which is left over once another formula p has been satisfied we call this remainder f the frame and write the inference question as follows s p f throughout the paper we use square brackets to indicate the portion of the entailment that is to be computed the second kind of inference question abduction the missing formula that must be combined with a formula s in order to satisfy some other formula p we call this formula a the and write the inference question as follows s a p frame inference and abduction form the basis of symbolic execution in separation logic intuitively frame inference lets us reason while abduction lets us reason backwards frame inference can work out which portions of the state will and will not be affected by the command while abduction can work out what extra resources are necessary to execute the command safely suppose we have a symbolic state represented by an assertion s and a command c with specification p c q if we calculate the frame in s p f the symbolic state after executing c must be q f the tight interpretation of triples is necessary for this kind of reasoning because a specification must describe all the resources affected by a thread any resources in the frame must be conversely if we calculate the s a p it must be the case that before executing c we must first acquire the additional resource a as well as s redundant and needed resources the tight interpretation means that a proof in separation logic expresses all resources modified by each individual command because separation logic ensures behaviour a proof also expresses all the resources that can affect the observable behaviour of each individual command in the program our parallelization analysis uses this to calculate resources that are redundant and those that are needed during the execution of the program we use frame inference to determine redundant resources resources that will not be accessed in a particular portion of the program and which can thus be safely to other threads conversely we use abduction to determine needed resources resources that must be held for a particular portion of the program to complete and which must thus be acquired before the program can proceed safely in our analysis we generally calculate the redundant resource from the current program point to the start of the subsequent iteration this resource can be to the subsequent iteration using a grant barrier we generally calculate the needed resource from the end of the previous iteration to the current program point this resource must be acquired from the previous iteration using a wait barrier before execution can proceed further note that these two resources need not be disjoint a resource may be used early in an iteration in which case it will be both needed from the previous iteration to the current point and redundant from the current point up to the next iteration note also that redundant and needed resources need not cover the entire state some resource described in the proof may never be accessed or modified by the program algorithm overview the user a sequential program which makes use of the construct as well as a sequential proof written in separation logic establishing the of the program the highlevel structure of our algorithm is then as follows the resource usage analysis phase uses abduction and frame inference to discover redundant and needed resources for different portions of the program the transformation phase consists of two parts a the resource matching phase matches redundant resources in one iteration of the with needed resources in the subsequent iteration b the barrier insertion phase converts the sequential program into a concurrent program and inserts grant and wait barriers consistent with the discovered the result is a program and its separation logic proof resource usage analysis the resource usage analysis takes as its input the program and a separation logic proof for the program for some specification consider once again the functions f and g which we introduced at the start of this section let us assume the programmer proves the following specification x x y y fi x i x x y x x y y fig shows an outline proof of this specification for each program point the resource usage analysis computes a pair of assertions the needed resource and the redundant resource xx yy p vv void fi xx yy void gp v p vv local v x vx xx yy if v i p v pv vx vi xx yy gy v else vx vi xx yy gx x i x x y x x y y figure proofs of functions f and g see fig the needed resource is the portion of the sequential precondition required to reach the program point without the redundant resource is the portion of the resource held in the sequential proof that is unnecessary for reaching the end of the function in other words needed assertions at program point p denote resources that are needed from the beginning of the function up to but not including p redundant assertions denote resources that are not required from p to the end of the function for example the redundant resource established within the false branch of the conditional in f asserts that a thread executing this function will no longer require access to y at this point whenever v i the needed resource here asserts that the thread reaching this point still requires access to x provided v i generalizing to n threads our analysis can handle an unbounded number of loop iterations running in parallel fig shows the final parallelization of our example generalized to deal with an arbitrary number of iterations a is translated to a sequential for loop in which each iteration a new copy of the loop body resources are between the threads in order of that is the nth iteration of the acquires resources from the n th iteration and resources to the logically n th iteration this ordering is implemented through shared thread shares with its predecessor a set of channels for receiving resources and with its successor a set of channels for sending resources the number of so the required number of potentially decided at runtime consequently channels are dynamically allocated in the main using the operation each iteration creates a set of new channels and passes the prior and new set to the thread the version of f fig now takes four channel arguments a pair of each for x and y the prior channels are used for resource transfer with the thread here wx wy and the new channels are used to communicate resource transfer with the thread here wx wy our analysis generates two versions of function g specialized to the two contexts in which it is invoked function ga executes when v i here the executing thread needs write access to y which it acquires by calling function gb needs write access to x but it runs in a context where the resource x has already been acquired consequently it need not call wait both versions release a resource to the following thread using grant before returning void fi n emp r xi yy local v x n x x r x i x x x i y y if v i n x i x x r xi xx gy v void gp v n x i x x r xi xx p v n x i x x y y r xx yy else n x i x x r xi yy gx void gp v n x i x x r xi yy p v n x i x x r xx yy n x i x x y y x i x x r xx yy figure redundant and needed resources in the function f function g is as its resource usage depends on the calling context loops and recursive data structures up to this point we have dealt with channels single heap locations injected into code our analysis can in fact handle more complicated datastructures such as linked lists and controlflow constructs such as loops to illustrate consider the example program shown and verified in fig sums the values stored in the first n elements of the list then the rest of the list an important feature of our approach is that the input safety proof need not specify all the relevant sequential properties all sequential dependencies are enforced thus we can see as representative of the class of algorithms that traverse the head of a list then the tail with minor modifications the same proof pattern would cover insertion of a node into a list or sorting the tail of the list consider two calls to this function within a void main as above for the sake of we specialize the first and second iterations of the loop calling them and our analysis generalizes to n iterations exactly as described in § the barriers injected into must enforce the following properties · must not write to a list node until has finished both writing to and reading from it consequently if n void main local i n x alloc y alloc chan wx wy chan wx chan wy for i i i n wx wy wx wy wx wy wx wx wy wy fi wx wy local v x if v i v wy else wx gap v wy p v v wx p v figure parallelization of our running example generalized to deal with n threads channels are used to signal availability of resources from one thread to another n must wait for to finish the values stored in the first n nodes before writing to them · must not read from a list node until has finished writing to them consequently must wait for to finish the value stored in a node before reading from the node this example is substantially more subtle than our earlier one requiring more than a simple pointsto analysis because the list is not divided into reachable segments in the worst case a wait at the start of and a grant at the end of enforces sequential order however by reasoning about the structure of the manipulated list using the safety proof given in fig our approach can do considerably better the parallelization synthesized by our analysis is shown in fig the general version is given in the technical report this parallelization the list into two segments consisting of the portions read and written to by sum head a shared stores the starting address of the portion written by the thread uses to control when to access the second segment of the list we discuss how the analysis below handling dynamic structures means dealing with allocation and fortunately separation logic handles both straightforwardly updates to the datastructure and object allocation are by assumption reflected in the invariants of the original sequential proof thus updates and allocations are also reflected in the invariants which our analysis constructs to represent the contents of channels however introducing allocation and affects the result discussed in § this result ensures for simplicity here we write sum head with wait controlled by conditionals the actual transformation performs syntactic to avoid the need to modify the loop invariant details are given in § hd hd h nil local i sum x int i int sum x hd hd x nil entailment on predicate hd h x nil in hd h x v y v y nil sum i x hd h x nil hd h x v y v y nil x hd h nil figure separation logic proof of a program whose automated parallelization requires reasoning over complex assertions and predicates i sum x hd in i x x x i sum x hd in sum i x x figure parallelization of for two threads the program behaviour is by the translation ie the translation enforces deterministic parallelism reasoning about list segments we assume that our separation logic domain includes the predicate t which asserts that a segment of a linked list exists with head x and t we define as the least separation logic predicate satisfying the following recursive equation t x t emp v y v y t we assume that the programmer proves the following specification for the sequential version of hd nil hd nil our analysis depends strongly on the choice of these basic predicates see § for a discussion of alternatives to this specification is trivial all it says is that executing beginning with a list segment results in a list segment fig shows a proof of this specification we run our analysis over the program to determine redundant and needed resources consider the following loop from the end of x our analysis reveals that only the resource defined by nil is needed from the start of this loop to the end of the iteration comparing this resource to the corresponding invariant in the sequential proof reveals that the resource h hd x is redundant at this point this assertion represents the segment of the list that has already been traversed from the head of the list to x and barrier injection notice that the assertions generated by our analysis are expressed in terms of the local variable x which may change during execution in order to safely transfer these assertions to subsequent iterations of the we need them to be globally accessible and invariant to satisfy this goal we could simply existentially quantify the variable x giving a redundant invariant h y hd h y however such a weakening important information in particular the relationship between the necessary resource the list segment from x and the tail of the list to retain such dependency relationships our analysis the current value of x into a location shared between and an assignment is injected into at the start of the second loop x after the assignment to the redundant state can now be described as follows h y hd h y y here we use fractional permissions in the style of to allow a location to be shared between threads the assertion y represents fractional readonly permission on the shared location this helps in binding together the head of the list and the remainder of the list when they are when traversing the list compares its current position with if it reaches the pointer stored in it must wait to receive the second remainder segment of the list from technical background programming language and representation we assume the following language e x nil expressions b true false e e e e booleans a atomic commands c c c skip a x return e c else c c p global local y¯ c to avoid introducing an extra construct we define c bc as c c void i int v x if v i gy v else gx void p int v p v fs x x y y x x y y v x x x y y v x v i x x y y v x v i x x y y fe x i x x y x x i x y y gs p v v p v v ge p v figure left labels for commands in f and g right associated assertions in the sequential proof to simplify the slightly we assume a fixed input program p of the following form c b work our parallelization approach generates a new program that allows safe execution of a transformed version of work in separate threads we denote by func main work the set of functions declared in a program p labelling of commands every command c cmd in the program is indexed by a unique label label function identifiers are also treated as labels we identify a particular command by its label and when needed denote by cmd the command at the label the set of all labels occurring in c is given by the left hand side of fig shows a labelling of the functions f and g commands within a block function or while form a sequence identified by the sequence of the corresponding labels functions pred succ label label return the label of the the next resp command in the sequence for corresponding to a function name a function call or a while loop the of the first command and successor of the last command in the block are denoted by s and e respectively for corresponding to t s et and f s f e are labels of the predecessor of the first the successor of the last commands in the if and else branches respectively given labels and within the same block we say that if n such that let and denote the smallest resp largest label in the block containing let denote the sequence of labels between and exclusively and let p stand for the corresponding program fragment analogously we define and p program representation a program is represented via a control flow graph with label as the set of nodes and as the set of edges all such that corresponds to a label of a function call and s e or corresponds to and t s t e f s f e a path is a finite sequence of nodes in the control flow graph intuitively a path represents the sequence of function calls and conditionals that need to be traversed in order to reach a particular assertion due to the structure of our analysis we are only interested in the set of path in the function work denoted by ap we often want to manipulate and compare path for n ap we write i to denote i ij to denote i j and to denote the length n for path and denotes their longest common prefix ie for k we have j k j j and if k then k k we define a partial order on ap as follows we say that iff and or for k we have k and k k we say that iff or lemma ap is a lattice with the least element works and the greatest element for fin ap we define max as max ¬ we define min analogously assertion language and theorem prover assertions in our approach are expressed using a class of separation logic formulae called symbolic heaps a symbolic heap is a formula of the form x¯ where the pure part and the spatial part are defined by true e e e e pe emp x e e se here x¯ are logical variables e ranges over expressions pe is a family of pure firstorder predicates such as eg arithmetic inequalities etc and se a family of other spatial predicates such as eg doublylinked lists trees etc besides pointsto and predicates previously discussed we refer to the pure and the spatial part of as and we denote set of all quantifierfree firstorder formulae built in the same way as but also allowing the connective by during our analysis we often need to substitute variables for example when an assertion into a different calling context if x¯ is a mapping from variables in x¯ to then by we denote the formula obtained by simultaneously substituting every occurrence of xi in with the corresponding ei we denote by the inverse variable mapping if is injective the set of all symbolic heaps is denoted by sh we represent a disjunction of symbolic heaps as a set and use the and operators the set of all disjunctive symbolic heaps is we the and operators in a natural way for i i i i we define i i i and i i i operators and over thus we allow these operations on disjunctive heaps just as if they were on symbolic heaps and furthermore use the same notation to refer to both symbolic and disjunctive symbolic heaps we assume a sufficiently powerful automated prover for separation logic that can deal with three types of inference queries · f frame inference given and find the frame f such that f holds · a abduction given and find the missing assumption a such that a holds · a f given and find a and f such that a f holds as before square brackets denote the portion of the entailment that should be computed we sometimes write for a computed assertion that is existentially quantified and will not be reused none of these queries has a unique answer in general however for our analysis any answer is acceptable though some will give rise to a better parallelization than the others existing separation logic tools generally provide only one answer in our framework substitutions are always guaranteed to be injective because the variables being substituted correspond to heap locations and channel resources whose denotations are guaranteed to be distinct if the substitution involves values then they must be implicitly existentially quantified and can therefore be assumed to be distinct sequential proof we assume a separation logic proof of the program p represented as a map p label intuitively assertions in the proof have the property that for any label executing the program from a state satisfying p up to some subsequent label will result in a state satisfying p and will not fault more formally we assume functions pre post label associating labels of atomic commands and function calls with their pre and postcondition respectively and a function inv label associating while labels with loop invariants we also assume a mapping from labels to variable substitutions such that l x¯ x¯ maps formal variables x¯ in the specification assertion to actual variables x¯ in the proof assertion finally we assume a function f label giving the portion of the state we write l to represent the heap constructed by applying the substitutions defined by l to the assertion then at each label we have p pre f and post f if is a while label then pre and post are replaced by inv this structure means that the proof is modular ie each atomic command function and loop is given a specification in isolation without a reference to the particular context in which the specification is being used the righthand side of fig shows a proof for the functions f and g which is in this form our approach is to the method by which the proof p is created it can be discovered automatically eg by a tool such as by a proof assistant or written manually proof assertions inlining the proof p assumes use of a modular specification for each function however our analysis needs to refer to the assertions in the local function with respect to the variables of the caller all the way up to the work function we therefore define a process for lifting local assertions with respect to their global contexts for ap such that m and n are the labels corresponding to the function calls in the order of occurrence as in we define the lifted proof assertion p as f f f n pm n n intuitively the assertion p represents the global proof state at including the portions in terms of works variables finally let pc ap represent the path constraint associated with each path the path constraint at the pure part of p corresponding to the assumptions from the conditionals encountered on the way from works to the path constraint may be extracted directly from the proof or computed by some other means parallelization algorithm we now formally define our parallelization algorithm the goal of our approach is to construct a version of the input program p in particular our approach generates a new function work in invoking possibly transformed such that initial channel creation c b channel creation channel finalization has the same behaviour as the original algorithm computing locally needed resources using backward symbolic execution function label × label while do pred if cmd matches c else c then p t s t e sf f e if cmd matches c then inv a p inv a else post a p pre a return resource usage analysis our approach to parallelization traverses the program by referring to a finite prefix and closed subset of path p fin ap this subset reflects the portions of the program that are path and contextsensitive targets of parallelization the set p provides precise control over which functions the analysis should address but how this set is chosen is not considered here function invocations whose successors are not in p are treated as a single operation with effects defined by their specification the goal of resource usage analysis is to compute the maps redundant p × p needed p × p for p q p such that p q q gives the resources that are guaranteed to not be accessed by the program between p and q in parallelization these are resources that can safely be to other parallel threads for p q q gives the resources that might be accessed during execution from p to q in parallelization these are the resources that must be acquired before execution of the current thread can proceed the function alg uses backward symbolic execution to compute needed resources between pairs of path in the same function block it uses the pure parts of the sequential proof to guide the inference since we already have function summaries and loop invariants in the sequential proof gives a symbolic heap sufficient to execute the fragment p lemma is a sufficient precondition for p proof follows from the disjunctive version of the frame rule p c ii qi jj ja p kk jj aj c and rule of composition the function s alg to the contextsensitive interprocedural level given two assertion points represented as path s and e s works by backwards an assertion from e to s the algorithm operates in two phases in phase a it steps backwards from e towards the outermost calling context in the hierarchy this context represented as the longest common prefix of s and e is the dominator of the two algorithm computing needed resources function p e p k e pe while k s e do ek ek k k if is function call then ek sk sk while k s do if is function call then sk k k sk sk return a b algorithm computing redundant resources function p e p ps e r return r functions in which s and e are found in the function call graph phase b of the algorithm keeps backwards but proceeds into the hierarchy towards s both phases of the algorithm use alg to compute the needed resources function call boundaries in phase a we establish the needed assertions from the point to e and in phase b from s to the point since the invariants of the input proof are written in terms of the outermost calling context comparing specifications with these invariants requires the local specifications to be in terms of the outer context in the first line of phase a we construct a variable substitution that the assertion in terms of the calling context at the start of e the second line constructs the running state in terms of es starting context this is typically the context defined by the work function used in a command constructs a new needed state up to the start of the current block finally the resulting state back into the current context when a function call is reached we the variable substitution by one call since we now have moved from the context to a callers operations in phase b are similar the results computed by needed are as follows if ps e then e ps e otherwise e ps lemma e is a sufficient precondition to execute p from s to e in order to be able to use the needed map further in the algorithm we must ensure that it grows ie that p such that we have needed needed if the underlying theorem prover behaves consistently with respect to failing and precision this property always holds however we can also make an additional check and insert assertions from the sequential proof as needed the redundant resource between two path is the portion of the in p that is not required by the needed map in alg we calculate this by frame inference ge ge fe xi yy v x v i x x v x v i y y vx vi xx vx vi xx yy vx vi yy vx vi xx yy figure redundant map with respect to fe lemma if ps e then is a sufficient precondition to execute p from s to e consider the functions f and g from § fig shows the labels and sequential proof for these functions the map obtained by needed is shown in fig fig shows the map computed by redundant with respect to path fe transformation we now describe a transformation based on our analysis the construction proceeds in two phases first we compute an resource transfer between threads then we grant and wait barriers to this resource transfer the resource transfer mechanism transfers a resource from one invocation of the work function to another this transformation can be viewed as just one application of the analysis more optimized transformations are certainly possible our overall goal is to describe a framework for a analysis conditions on released and acquired resources in the first phase we determine resources that should be released and acquired at particular points in the program released resources cannot be ie each released resource should be included in the redundant map from the point of the release to the end of the work way we know the resource will not be needed further acquired resources are held by the executing thread until released resources that are acquired along a sequence of path should contain what is by the needed map between each of the path we represent the result of this phase of the algorithm via the following maps · resource denoting resource identifiers that identify released and acquired resources · released p × subst representing resources that are going to be released at a path together with the variable substitution applied at that point · acquired p representing resources that are going to be acquired at a path we require the following wellformedness properties released r redundant p acquired r needed acquired r released the first property states we can release only resources that are not needed between the given path and any subsequent one the second property states that the resources needed at a ge ge ge xx xi xx xi xx yy xi xx ge xi xx vx vi vx vi yy vx vi vx vi xx vx vi yy vx vi xx figure needed map some entries omitted fe x i x x y y x i x x v x v i y y v x v i x x vx vi yy vx vi vx vi xx vx vi algorithm computing released and acquired resources n needed r redundant c max p n works emp while c do r n choose c p x¯ x¯ where x¯ fresh r r cr min p r r c if cr pc true then r fresh resource id r for all cr do released r for all st do r r r for all c do acquired r for all st do n r n c max c n emp path must have already been acquired the third property states that only the resources that have been previously acquired can be released in general there are many solutions satisfying properties ­ for instance there is always a trivial solution that acquires before the first command and it after the last causing each invocation of work to be blocked until the preceding invocation the last command of course some solutions are better than others computing released and acquired maps algorithm constructs released acquired and resource maps satisfying properties ­ each iteration of the algorithm a needed resource and then iteratively searches for matching redundant resource along all paths the algorithm maintains a set c of all path up to which no more resources are needed it terminates once no needed resources remain line at the start of the main loop line the algorithm a resource between a path in c and some further path the of the needed resource is by a we could relax the third requirement if we extended our barriers to support the ability to release a resource without first it allows a resource to skip iterations giving limited we believe it would be straightforward to fold such techniques into the analysis although such extensions are outside the focus of this paper heuristic function choose for which we make no assumption the choose function serves as a for external knowledge about likely points for parallelization the key step of the algorithm is performed on line cr min p r r c here r is the redundant resource from to the end of the work function and r is the candidate resource that we want to acquire the constructed set cr is a set of path along which we can satisfy the candidate needed resource in line the algorithm checks that cr covers all paths by checking the conjunction of path constraints is resources stored in needed contain path constraints and other conditions on local variables embedded in the pure part of the symbolic heap since we can transfer resources between different path we only take the spatial part of the resource into consideration when entailment questions this is denoted by a moreover since the acquired resource is being sent to a different function invocation we substitute a fresh set of variables line the remainder of the algorithm is to constructing the new resource line and with updating released lines ­ acquired lines ­ and c line lemma maps resource released and acquired computed by algorithm satisfy properties ­ consider our running example if choose in the first iteration and ge in the second iteration then the end result of alg is resource r x x r y y released r ge r ge r r and acquired r r r inserting grant and wait barriers in this phase we transform the sequential program p into a parallel program by inserting grant and wait barriers the inserted barriers resource transfer defined by the maps released and acquired we generate the parallel function work env in as follows to each r we assign a unique channel name ir denote by the corresponding channel of the previous thread in the sequence let env be an associative array that for each channel maps local variable names to values let be such map from the previous thread in the sequence env and are used for for each n let k km be the labels in corresponding to function calls then for each j kj we create in an identical copy f of the function f called at kj and replace the call to f with the call to f let us denote by tr the path in corresponding to after this transformation has been applied for all for each such that acquired r we insert a wait barrier between path and tr for each such that released r between path and tr we insert a sequence of assignments of the form y for every local variable y followed by a grant barrier each invocation of work creates a fresh set of local variables that are bound to the scope of the function however some resources must be expressed in terms of variables parallelization must take account of this if the structure of a resource depends on local variables from a previous invocation this must be encoded explicitly by the variables of the previous invocation the main function in first creates the set of dummy channels then in the while loop repeatedly creates a set of new channels for the current iteration a new thread with work taking the channels from the previous iteration as and from the current iteration as and at the end of the loop body assigns the new channels to the previous channels and after the while loop completes on the channels in the last set we generate the parallel proof from the sequential proof p using the following specifications from emp i r r r r emp r r each variable r in associated with channel ir is instantiated with the corresponding resource the predicates req and track the ownership of the input and output ends of the channel to reason about threads we use the standard separation logic rules for disjoint concurrency eg as in theorem is a proof of the parallel program and defines the same specification for as p does for the approach presented so far treats a loop as a single command with a specification derived from its invariant or resources within a loop is subtle as it changes the sequential loop invariant it is not clear how to handle this in full generality so we take a pragmatic approach that performs heuristic the example in § uses two channels to transfer the segment of the list traversed after the first and the second while loop respectively the resource released via channel i in fig is hd h in the following iteration the needed resource for the whole loop is hd h x if we try to match released against needed the entailment r r in algorithm will fail this is because the value of x is unknown at the start of the loop meaning we cannot establish whether the released resource will cover the needed resource one way to resolve this would be to acquire the entire list before the first loop but this would result in a very parallelization instead we modify the structure of the loop to expose the point at which the second list segment becomes necessary we split the spatial portion of the resource needed by the whole loop into a dead already traversed and a live still to be traversed part in our example hd h x would be the dead and nil the live part this kind of splitting is specific to some classes of programs eg linked list programs that do not traverse a node twice we match the resource against the dead part of the loop invariant and infer the condition under which the two resources i i i remainder else figure loop splitting for the example are the same in our example the entailment between the two resources holds if x this condition can be inferred by a question r c r with the pure fact c now we can syntactically split the loop against the inferred condition c x and obtain a transformed version that ensures that after entering the true branch of the if statement the condition c holds the transformation of our example is shown in fig formally we define splitting of a command possibly multiple loops against a condition c as follows to simplify we assume here that every command ends with skip function cmd c match c with c c c c c c c else c c c c c skip skip the condition c is obtained from c by replacing a reference to every variable y by a reference to where ir is the channel name associated to the resource it is not difficult to see that the proof of c can be split in a proof preserving way against c this transformation can either be applied to p between the analysis and parallelization or embedded within alg implementation we have validated our parallelization algorithm by a prototype implementation on top of the existing separation logic tool while our implementation is not intended to provide full automated translation it is capable of the algorithms on the examples given in the paper and automatically the underlying theorem proving queries our parallelization algorithm does not assume a shape invariant generator except possibly to help construct the sequential proof soundness is independent of the of the invariants the analysis will always give a correct result in the worst case to sequential behaviour our examples in have been validated using invariants other efforts indicate that works well with invariants produced by shape analysis even over very large code bases behaviour preservation a property of our parallelization analysis is that it enforces sequential in the program even if the safety proof does not explicitly reason about such dependencies the result is that our analysis preserves the sequential behaviour of the program any behaviour by the program is also a behaviour that could have occurred in the original sequential program however there are important relating to termination and allocation termination if the original sequential program does not terminate our analysis may introduce new behaviours simply by of running segments of the program that would be unreachable under a sequential schedule to see this suppose we have a such that the first iteration of the loop will never terminate sequentially the second iteration of the loop will never execute however our parallelization analysis will execute all iterations of the loop in parallel this permits behaviours from the second and subsequent iterations these behaviours were latent in the original program and become visible only as a result of parallelization allocation and if the program both allocates and memory the program may exhibit aliasing that could not occur in the original program to see this consider the following sequential program for simplicity we have avoided the program to use data parallelism via example could easily be encoded as such however parallelization might give us the following program this version of the program is and the required sequential ordering on data depending upon the implementation of the underlying memory allocator however x and y may be aliased if the operation was interleaved between the two allocations such aliasing could not happen in the original version either kind of new behaviour might result in further new example we might have an conditional on xy in the second example above these are common to our analysis and others based on separation example see the similar discussion in proving behaviour preservation we now sketch a behaviour preservation result a detailed proof is given in the theorem defines preservation in terms of an interleaved operational semantics for a core language similar to the one described in § additionally equipped with threads and operations on channels such as grant and wait are interpreted as in this semantics we prove our result for a sequential thread t possibly executing concurrently with other sequential into the purely sequential case when there are no other threads because t is sequential it does not call fork we also assume that it is guaranteed to terminate and that it never memory based on the discussed above theorem let t be a sequential thread and let a corresponding version equipped with thread creation operations and synchronization actions that enforce sequential dependencies among the child threads it creates let be a terminating ie free trace of an execution of there exists a corresponding trace k derived by substituting corresponding operations in t for such that k and begin in the same state for every thread t t in k k and exhibit identical threadlocal behaviour and the terminal state of thread t in is a of the corresponding state in k proof sketch we show that under the assumption that child threads never wait for channels granted by their parent or child threads any terminating trace can be into a trace with the same thread local behaviour by we mean that children must execute to completion before their parents can be scheduled we establish a simulation invariant between executions of with arbitrary calls to wait grant and fork and executions of identical to except with all such constructs erased the invariant establishes that every trace of simulates some trace k of we tie this result to our analysis by observing that tion only inserts the four constructs wait grant and fork leaving aside issues of and as a result t we also show that the way we insert signals ensures that they are ordered with respect to thread creation as assumed in the previous step this establishes a result for traces but parallelization might introduce however programs are verified using separation logic meaning we can assume that they do not fault when executed in a state satisfy ing the precondition this completes the proof one property is that this proof does not place any explicit requirements on the of is sufficient that we can provide a proof for the on memory in the way we establish our simulation invariant which necessarily assumes newly allocated data is always fresh and thus does not alias with any accessible structure the on termination is necessary to ensure we can threads to yield a trace in addition to inserting barriers our analysis the program by threadlocal variables and splitting loops both of these can be performed as on the initial sequential program and neither affect visible behaviour is straightforwardly while variables are only used to control barrier calls theorem guarantees that does not introduce deadlocks otherwise the simulation relation would not exist the ordering on barriers ensures that termination in the sequential program is preserved in the resulting parallel program refining the predicate domain the structure of the sequential proof affects the success of parallelization in two ways first the loop invariants may allow the analysis to verify a program when it would otherwise have failed second the choice of predicate domain how much information about is available to the analysis intuitively the domain may permit a splitting of resources allowing redundant resources to be identified earlier or missing resources later to see how the choice of abstract domain precision and effectiveness of the analysis consider the example discussed in § there we using the list segment predicate an alternative predicate is t n i which extends with a parameter n z recording the length of the list segment and with a parameter i recording the permission on the list segment if i the thread has readwrite access otherwise it has read access only we define as the least predicate satisfying the following equation t n i x t n emp v y i v i y t n i the equivalence t n t n would allow the analysis to exploit this predicate even if the sequential proof is written using the predicate n i sum x hd in sum i x x x i sum x hd in sum i x x figure improved parallelization of function only writes to the list after traversing n nodes consequently it needs only readonly access to the first n nodes or the entire list if the list is than n nodes long we can extend our resource usage analysis to deal with this richer predicate such that it identifies the following as a sufficient precondition for the entire function hd j h t t n i nil n nil n i n n without the predicate this precondition could not be expressed the availability of would also allow the analysis to discover that this resource is redundant at the start of h i j hd j h t n i n nil n i n n when is called in a the subsequent call to can immediately read from the first n nodes of the list applying our analysis using the predicate yields the the parallelization shown in fig i signals that the first n nodes can be read by the subsequent iteration of similar to the transformation discussed in § grant calls can be inserted on i to signal that the subsequent iteration can write to the first n nodes and on i to signal that the entire list can be written to because this parallelization calls grant earlier than the parallelization discussed earlier it can consequently extract more parallelism from the original sequential program as this discussion reveals our analysis is generic in the choice of abstract domain any separation logic predicate could be used in place of for example however the success of automated parallelization is highly dependent on the power of the entailment prover in the chosen domain the domain is one of the in separation logic and consequently automated parallelization is feasible using tools such as other domains such as trees are far less developed related work inference by abduction we have defined an interprocedural analysis capable of determining the resource that will and will not be accessed between particular points in the program at its core our analysis uses reasoning to discover is state used earlier in the program that will not be accessed subsequent to the current program point using abduction in this way was first proposed in where it is used to discover memory leaks without conditionals procedures loops or code specialization in abduction is used to infer resource invariants for synchronization using a process of refinement our approach similarly infers resource invariants but using a very different technique invariants are derived from a sequential proof and we also infer synchronization points and the program to reveal synchronization opportunities parallelization we expect our analysis can be used in other optimizations but in this paper we have used it as the basis for a transformation this transformation is in the style of deterministic parallelism ­ although our approach does not in fact require of the source program in this our transformation ensures that every behaviour of the program is a behaviour of the source sequential program modulo the about allocation and termination discussed in § previous approaches to deterministic parallelism operate without the benefit of a highlevel specification this places a substantial burden on the analysis and runtime to safely extract information on resource usage and that is readily available in a proof as a result these analyses tend to be much more conservative in their treatment of mutable data our technique gives us a general approach to splitting mutable resources for example by allowing the analysis to perform adhoc list splitting as we do with our approach transforms a sequential by running all the iterations in parallel and between them this idea has been proposed previously for example in numerical computation the in our approach lies in inferring synchronization over portions of complex mutable datastructures alternatively we could have used a more concurrency annotation for example safe futures or an unordered as in the galois system in the former case our analysis would be mostly unchanged but our program would construct a set of threads rather than a pipeline of identical threads removing ordering between iterations as in the latter case would mean replacing ordered pairs with conventional locks and would introduce an obligation to show that locks were always acquired together as a set parallelization a insight central to our approach is that a separation logic proof expresses data dependencies for parts of a program as well as for the whole program these internal dependencies can be used to safe parallelism this insight is due to and both of which propose parallelization analyses based on separation logic the analyses proposed in these papers are much more conservative than ours in that they discover independence which already exists between commands of the program they do not insert synchronization constructs and consequently cannot enforce sequential dependencies among concurrent computations that share and modify state indeed does not consider any program transformations since the goal of that work is to identify memory separation of different commands while expresses optimizations as reordering rewrites on proof trees bell et al construct a proof of an multithreaded program by the transformation this approach assumes a specific pattern of linear dependencies in the consistent with a specific pattern of sequential proof and a fixed number of threads in our example the outermost loop contains two successive inner loops while the example in fig illustrates how the technique can deal with interprocedural and controlflow sensitive dependencies in both cases the resulting parallelization is specialized to synchronization primitives to enforce sequential de we believe examples like these do not fall within the scope of either or the proof techniques supported by outside separation logic et al propose an analysis which a sequential library with synchronization this approach takes as input a sequential proof expressing the correctness criteria for the library and generates synchronization ensuring this proof is preserved if methods run concurrently a basic assumption is that the sequential proof represents all the properties that must be preserved in contrast we also preserve sequential order on access to resources consequently et al permit that we would and can introduce new behaviours into the program another difference is that derives a linearizable implementation given a sequential specification in the form of inputoutput assertions because they do not consider specialization of multiple instances of the library running concurrently it is how their approach would deal with transformations of the kind we use for separation logic and concurrency separation logic is essential to our approach it allows us to the behaviour of a program fragment to precisely the resources it accesses our proofs are written using concurrent separation logic csl has been extended to deal with locks locks and primitive channels sequential tools for separation logic have achieved example has verified a large of the linux kernel our work can be seen as an attempt to the success of such sequential tools our experiments are built on a proof tool for separation logic the parallelization phase of our analysis makes use of the specifications for parallelization barriers proposed in that paper defined highlevel specifications representing the abstract behaviour of barriers and verified those specifications against the barriers lowlevel implementations however it assumed that barriers were already placed in the program and made no attempt to infer barrier positions in contrast we assume the highlevel specification and define an analysis to insert barriers the semantics of barriers used in that paper and here was initially proposed in acknowledgments this work was supported by the trust by grant and by nsf grant thanks to matthew parkinson john and the anonymous reviewers for comments and suggestions references c j bell a appel and d walker concurrent separation logic for parallelization in sas pages ­ j berdine c calcagno and p w ohearn modular automatic assertion checking with separation logic in pages ­ t o j l and d a compiler and runtime system for deterministic multithreaded execution sigplan not ­ e d t yang t and g safe multithreaded programming for cc in oopsla pages ­ r l jr v s d s v s r j p h and m a type and effect system for deterministic parallel java in oopsla pages ­ r c calcagno p ohearn and m parkinson permission in separation logic in popl pages ­ m d m r and m parkinson the core of in pages ­ m m and s synchronization inference by abduction technical report university of cambridge computer laboratory j and k and checking determinism for multithreaded programs acm ­ june c calcagno p w ohearn and h yang local action and abstract separation logic in lics pages ­ c calcagno d p ohearn and h yang compositional shape analysis by means of in popl pages ­ c calcagno d and v vafeiadis resource invariant synthesis in pages ­ b cook s m j and s making fast hardware with separation logic unpublished j v g v p and k logical concurrency control from sequential proofs in esop pages ­ d and i memory leaks detection in java by inference in pages ­ d and m j parkinson j towards practical verification for java in oopsla pages ­ m s and m j parkinson modular reasoning for deterministic parallelism in popl pages ­ t s qadeer and s a calculus of atomic actions in popl pages ­ a j berdine b cook n and m sagiv local reasoning for locks and threads in pages ­ c m and c reasoning about locks in pages ­ t j and r transactional memory nd edition c a r hoare and p w ohearn separation logic semantics for communicating processes ­ a a w appel and f oracle semantics for concurrent separation logic in esop c automatic parallelization and optimization of programs by proof rewriting in sas pages ­ b and f modular full functional specification and verification of lockfree data structures technical report cw dept of computer science k r m leino p and j channels and locks in esop pages ­ a x and s quasistatic scheduling for safe futures in pages ­ acm p w ohearn resources concurrency and local reasoning ­ g r a and d i august automatic thread extraction with software pipelining in pages ­ k d m m m a r th lee a r m d and x the of parallelism in algorithms in pldi pages ­ m c calcagno and p automatic parallelization with separation logic in esop pages ­ j c reynolds separation logic a logic for shared mutable data structures in lics pages ­ p p j n and j n reducing data communication overhead for loop in international conference on pages ­ j and c calcagno tracking heaps that with in tacas pages ­ 