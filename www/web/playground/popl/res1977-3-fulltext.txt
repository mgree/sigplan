a new strategy for code generation ­ the general purpose optimizing compiler william ibm thomas j watson research center heights new york abstract this paper presents a systematic approach to the problem of generating good code with a compiler that is easy to construct a compiler structure is proposed which relies on interprocedural data flow analysis global optimization and an intermediate language schema to simplify the task of writing the code generating portions of a compiler without code quality this structure is with a more conventional structure to explore the reasons why the new structure solves several problems inherent in the conventional structure further advantages which from the new structure are also presented overview considerable effort has been spent over the last producing a systematic strategy for the syntax processing component of compilers during this time however no adequate framework has for struc turing the remaining components of an optimizing compiler recent in program analysis have the way to a new compiling strategy which may provide such a framework this strategy is the general purpose optimizing compiler compiler which is being developed by the experimental compiling system group at the ibm research laboratory heights the compiler strategy has from the synthesis of four fundamental ideas the development of a schema for intermediate languages the expression of language semantics through defining procedures which take the place of code generators code macros and library source code the application of global data flow analysis to the defining procedures and source programs and the repeated application of machine independent optimizations the role of each of these is discussed in turn intermediate language schema most compilers perform the translation from source to target in a series of stages using a different representation of the known information at each stage these represent which include both text and symbol table tion are often referred to as intermediate languages in order to facilitate the application of global flow analysis and optimization at any stage it is imperative that a compiler a representation into which all intermediate languages from source to target may be embedded this representation called the il schema meets several important objectives it supports languages such as pl algol cobol and fortran it makes the execution of a procedure integrated at compiletime equivalent to invocation of the procedure at runtime so that the compiler is free to chose whether or not to integrate any procedure into any particular invocation it introduces no into control and data flow analysis that were not characteristic of the source lan guage so that the quality of the code resulting from a source language will not from its translation through the schema finally it contains a minimal number of language constructs with builtin semantics so that the largest number of constructs are available for analysis and optimization several broad of this il schema can be made it contains no dictionary holding particular information about the data types bounds or other attributes of variables such information is expected to be held as the values of ordinary variables the instruction format uniformly represents the invocation of procedures whether they are primitives or source language no expressions may appear as operands since the call by reference interpretation of these expressions at runtime may differ from the call by name tion imposed by procedure integration at compiletime there are no builtin constructs for exception handling nor are there even arithmetic or branching instructions the language is somewhat higher than a conventional machine language in that details of storage mapping and address computation are in addition the il schema provides for a naming convention which allows the variables containing type information to be associated with the variable they describe it also includes for describing the occurrence of block structure in a program for describing possible storage relations among variables for indicating the occurrence of indirect addressing or its inverse and for denoting program points as labels or entries the following sample procedure for generic addition of fixed or floating point numbers illustrates the use of this naming convention add do case eq fixed float end end defining procedures in order to relate the semantics of a source language to the semantics of a target machine it is necessary for a compiler designer to specify at least one most general code sequence which implements each source language operation this is the same specification which would be used for an interpreter of the operation however such a general definition ignores many possibilities for tion these possibilities arise because the context in which an operation is actually used may make the information needed to interpret some parts of the operation sequence available at compile time for example the most general code for an array element in would include of subscript range the range checking itself and the formation of a sum of products of the and subscripts in a compiler the semantics of a source level operation is expressed as a conventional procedure whose invocation at runtime would always produce the correct result these procedures called defining procedures may be viewed as the code for an interpreter or as macros whose expansion produces the code desired from a compiler by using procedure integration the defining procedure for an operation can be incorporated into a calling procedure this involves performing substitution for parameters and renaming of local the integration of defining procedures merely eliminates the overhead of procedure call in traditional compilers for large languages like the macro or generally the ability to execute tests at compile time in order to the code sequences to the of their invocation for example the code generator for in a compiler would usually test the of at compiletime since the of conditions is known statically in a compiler the function of such an selection mechanism is performed by global data flow analysis and optimization such analysis and optimization is independent of the particular of the language being compiled for example in a compiler the types of data are always known at compiletime thus at any invocation of the previously described add procedure the value of would have been established by the sequence of assignments to attributes of x made by the declare statement for x data flow analysis relates the assignment to to its use in add allowing the compiler to determine which case applies at a particular invocation of add although the same add procedure might be employed in an compiler for a language the lack of declarations might cause the testing of to be deferred until execution time global data flow analysis global data flow analysis is the process of ing how information is generated and used in a program r is then possible to base various optimizations on locally available information derived from the global analysis for example data flow analysis can be used to derive a relation between those operations which set the value of a variable and those operations which use that value this makes it possible for the optimization called constant propagation to carry forward the results of interpreting an operation at compiletime by those results directly to the operations which use them the technology for performing such an analysis of a program is well however because the semantics of all operations are expressed as procedures it is necessary that the analysis of a program take of some summary of preceding analyses of the procedures the program invokes recent has also techniques for such interprocedural analysis by using interprocedural analysis summary tion which is for the most primitive operations encountered in the compiling process can be mechanically constructed for the defining procedures built from them global optimization in the development of a compiler a collection of optimization forms the basis which replaces the manual analysis applied to determine special code generation cases certain optimizations such as constant propagation and dead code are necessary in a compiler other optimizations such as redundant expression elimination range analysis variable propagation and strength reduction may be part of any optimizing compiler they assume greater importance in a compiler since the code resulting from integrated procedures many operations these operations would have been avoided by a human programmer presented with the task of writing the original program entirely in a lowlevel language it has been demonstrated that the application of such optimization to a procedural description of concatenation would in a typical case produce a code sequence in which instructions are executed as compared to the instructions required by an available optimizing compiler or the instructions required by an interpreter structure of the compiler as can be seen from figure a compiler has three major components first the source language translator converts the input form into its il language the operators correspond closely to the source language operations next the resulting program is to repeated control and data flow analysis optimization and procedure the procedure integration component and the analysis component are directed by heavy lines a library containing the defining procedures and their data flow summaries this transformation results in an program ie one completely in terms of operations although the choice of this tive level is somewhat arbitrary it is intended to be a version of the machine operations the program result may be entered into the library as a new defining procedure finally the storage mapping is performed the is transformed to a machine oriented variant of called rl and register allocation and final assembly take place rl preserves the program but and summaries analysis i optimization integration summaries t storage mapping and il to rl conversion instruction scheduling register allocation and final assembly machine and code summary figure general structure of a compiler the operands of the program with whatever addressing information is needed register allocation is then performed followed by final assembly a small example will give some insight into the interaction of optimizations with defining procedures to produce code for this example we will consider the translation of two lines of a program to the ibm system the two statements are declare i fixed binary ao fixed binary boo fixed binary q ail since the in this example will be on the operation the data type issues which would actually arise in will be ignored t his is reasonable since it is clear that constant propagation of the fixed binary attribute eliminates any sions the translation of these two statements into could then be as shown in table the subscript operation is a general sub procedure which computes a pointer to the array element whether the array is based controlled or parameter or whether the bounds are known or unknown consider the integration of the subscript procedure into the above program as shown in table of the optimization of the code resulting from statement shows that in fact optimal code can be derived from the general procedure constant propagation will all of the bounds and information from the declaration in statement into the operands of the code for statement furthermore when constants are propagated to all input arguments of an operation the result can be computed and propagated further by keeping the data flow information up to date dead code elimination proceeds simultaneously table shows the results of constant propagation with dead code marked by a it should also be noted after constant propagation all code resulting from has become dead several other optimizing transformations can be interleaved with constant propagation these are range analysis redundant expression elimination and operation simplification operation simplification includes ii collection of operator dependent transformations which are made when various operand criteria are met for example y x is an operation tion table shows the result of applying these a new data flow analysis pass is made to form the information needed for the variable propagation these transformations are applied opening the way for another round of optimization in the case under consideration however optimization of the program is complete table shows the final program corresponding to the sample input program the process of integration and optimization has reduced the original program to an il program containing only primitives these primitives are selected to reflect the semantics of the target machines operators without the complex operand accessing structure present in most machines this accessing structure which generally includes address formation indexing and indirection is instead exposed as instructions in the code stream this allows the transformations to ignore special addressing of the target machine in a compiler storage mapping completes this process of all computations by entering into the instruction stream all instructions needed for address calculation in the example under discussion this adds the instructions through in table these move move move move move move move move move move move move subscript subscript move a b a b a b a b a b a b t ail indirect table version of source program e sub sub code after integration t t a t t a t add t tt add t sub b t b o sub t t b t add add t move sub i i sub i code after constant propagation t t i t t t ot i sub l t i o tt unchanged i unchanged table result of constant propagation i q i q i i i i i i i i i i code after constant propagation sub add add sub add add move t t t ot t t tt t code after redundant expression elimination operation simplification and q unchanged unchanged move t t unchanged t q t is t q move tt unchanged unchanged table result of redundant expression elimination and operation simplification instructions have the form add ti or t this transformation occurs in two steps operation simplification changes the add to a move and expression elimination with t add t where the off are the the offsets in the automatic or static storage assigned to variable i any references to in the program are changed to t the process of converting the primitive il program to the corresponding rl program is code after redundant expression elimination and operation simplification final code after sub unchanged t t unchanged move t t unchanged add t add t move tt unchanged add t address add t t move indirect unchanged q q q table code after optimization code after storage mapping add t add t add t add t add tg add add t sub add t t t tt add t tt move sub move rl code q q q q q q q q l q tl l table result of conversion accomplished by together those operations which can be into the operand semantics of the machine for example in addressing a single operand of an instruction an ibm system can perform the equivalent of the code sequence add for k add f xt reference indirect t the conversion of il to rl is performed by the matching of such patterns in the data flow graph when applied to the sample code described above this process results in the the instruction sequence of rl code displayed in table register allocation will convert this rl code into a sequence of at most machine instructions comparison with conventional compilers the structure of a compiler may be compared with that of a conventional compiler l schema in the compiler strategy the il schema replaces the collection of levels of intermediate language present in a conventional compiler this single representation provides for flexible support of multiple source or target languages in addition its use for the representation of input output and intermediate stages of compilation as well as for the defining procedures themselves makes it possible to write a single collection of analysis and optimization algorithms as an additional benefit of this flexibility a compiler is free to perform various analyses and optimizations at more than one stage in the compiling process making it unnecessary to find a single best time for optimization defining procedures the compiler strategy a library which contains in addition to the bodies of the defining proce a summary of their characteristics the summary information is a uniform description of the data flow and other characteristics of all operations primitive and thus the analysis and optimization are totally independent of the precise semantics of the operations the fact that operations are merely procedures in the same il framework makes it possible for most of the summary characteristics to be produced mechanically by the same data flow analysis which later uses them those summary items which like are difficult to will be supplied by assertions about the defining procedures compiling past the machine interface a conventional compiler often performs which detect the occurrence of certain code patterns which are subject to improvement in a compiler a similar pattern matching process takes place to convert the primitive il program to its rl form the pattern match in this case is not limited to small sections of control flow but rather is applied in the context of the more general data flow graph this matching and substitution process is per formed to operations back together into machine primitives the of operations often results from the of addressing in the code however such a will also produce optimizations of any code which was by the programmer before being input to the compiler elimination of special in the compiler strategy the code generation phase of the conventional compiler has been replaced by a procedure defining procedures in a compiler contain only those instructions needed to express the semantics of the individual operation which they implement it has been that code generators should provide for elaborate special special compilers require major and when language changes are made in fact the cost of a revised compiler often approaches that of the original this requirement for major when language changes are introduced seems to be inherent in the approach to optimization this is caused by the fact that the conceptual model used for the design and specification of each language operation does not match the representation of operation semantics used by the compiler designer in particular the compiler designer has distributed the semantics of each operation into the description of all others with which it may interact to produce special cases this combinatorial effect means that although the compiler designer may correctly incorporate a language change into uses of the feature specifically changed it is difficult for to all cases where the semantics of the changed operation has been into the case analysis of other operations what generally happens is that bugs develop in the compiler from case analyses these bugs are fixed by removing the special case and over time the quality of the compiler code the compiler strategy of implementing only the general case operations and allowing the optimizations to derive the special case code systematically the of additional advantages in addition to reducing the problems of cost com reliability and code quality associated with existing compiler the with it numerous additional advantages varying of optimization it becomes possible to use the same body of program ming to implement varying of optimization for example execution is achieved by totally or avoiding the integration of defining proce in the limiting case all instructions in the form of a program are merely converted into subroutine calls to some interpreter library on tbe other hand a quick and dirty compilation is achieved by performing constant of the data type attributes simple of the summary tion of the defining procedures will indicate that no definitions of the value of these attributes occurs so the constant propagation can be performed without extensive analysis the cost of the alternating sequences of proce integration and elimination which would result may be reduced to produce a quick and dirty compiler this cost reduction can be realized by applying a of the defining procedures into one another with an like that which has been suggested for conventional optimization and is also useful to the fully optimizing compiler because the alternative represent library routines from which a selection can be made according to proofs of compiler correctness the compiling strategy of using defining procedures in proving the correctness of an imple the correctness of various optimizations may be demonstrated on an overall basis and then a particular language implementation must only demonstrate using some accepted technique iz that the defining procedures are faithful to the language improved programming style use of a compiler also to the use of improved programming style by allowing a program to be constructed from many small without the overhead associated with numerous proce calls or with general procedures furthermore the advantages of an abstract data definition can be realized without the optimizations made possible by exploiting its underlying representation program in fact the compiling strategy can a significant role in an overall programming support system the same summary information and integration techniques applied to the library of defining procedures can be applied to a library of user programs the compiler can verify that summaries of program behavior fit within their specified behavior optimization of the compiler strategy the way to the optimization of large programming entities such as compilers data or operating systems by compiling those components of a system which are totally internal knowledge about all can be used to eliminate to optimization which arise from not knowing aliasing information about and acknowledgements the experimental compiling system is being built upon a by allen john and recognition should be given to j paul david robert and mark wegman for their contributions to this project my thanks are due to these people and especially to for their helpful suggestions in of this manuscript references allen fe interprocedural data flow analysis proc ifip north holland co amsterdam allen f e and j a of optimizing transformations qe m of compilers r ed prenticehall n j jeffrey m interprocedural data flow analysis based on transitive closure report university of california at berkeley september jl a case study of a new code generation technique for compilers communications to be published of the acm m and st code generation technique for large language compilers ibm systems journal vol no william compiler analysis of the value ranges of variables ibm research report rc tj watson research laboratory heights ny july william formal semantics of a intermediate language ibm research report rc tj watson research laboratory heights ny november s david v a survey of optimization techniques in compilers national information service development center september liskov b h sn specification techniques for data abstractions ieee transactions on software engineering vol no march fi david the effects of call point information on called procedure optimization inter october d b data flow analysis in the presence of procedure calls ibm research report rc tj watson research laboratory heights ny november jones cb formal definition in compiler develop ment technical report tr ibm laboratory february rosen k flow analysis for procedural languages ibm research report rc tj watson research laboratory heights ny april rosen b k data flow analysis for recursive programs ibm research report rc tj watson research laboratory heights n y january tc side effects in a optimizing compiler proc ifip i north holland co amsterdam unman j d data flow analysis second computer conference g complete redundant expression tion in flow diagrams ibm research report rc tj watson research laboratory heights ny august 