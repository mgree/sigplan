concurrency and verified compilation s vafeiadis peter sewell university of cambridge inria university work done while on at cambridge to the memory of robin milner abstract in this paper we consider the semantic design and verified compilation of a programming language for concurrent computation above x the design of such a language is made surprisingly subtle by several factors the behaviour of the hardware the effects of compiler optimisation on concurrent code the need to support concurrent algorithms and the for a reasonably simple programming model in turn this complexity makes verified or verifying compilation both essential and challenging we define a concurrent semantics for clighttso an extension of clight in which the processors memory model is exposed for code we discuss a strategy for verifying compilation from clighttso to x which we validate with correctness proofs building on compcert for the most interesting compiler phases categories and subject descriptors c multiple data stream architectures parallel processors d concurrent programming parallel programming f specifying and verifying and reasoning about programs general terms reliability theory verification keywords relaxed memory models verifying compilation semantics introduction context are now with hardware support for concurrent computation over data structures but building programming languages with welldefined semantics to exploit them is challenging for several reasons at the hardware level most multiprocessor families eg x power and arm provide only relaxed abstractions substantially weaker than sequentially consistent sc memory lam some of the hardware optimisations they rely on while to sequential code can affect the behaviour of concurrent programs moreover while for some it has long been clear what the programmer can rely on eg the total store ordering tso model for others it has been hard to interpret the architecture specifications for x we recently proposed as a rigorous and usable semantics we review this in § permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ austin texas usa copyright c acm compilers also rely on optimisations for performance and again many common optimisations eg common subexpression elimination and so on preserve the behaviour of sequential code but can change the behaviour of concurrent programs hence when designing a concurrent programming language where one must choose what memory semantics to provide there is a difficult to resolve a strong model such as sequential consistency will be relatively easy for programmers to understand but hard to implement efficiently because compiler optimisations will not always be sound and because expensive memory or other synchronisation instructions will be needed to enforce ordering in the target hardware another alternative is to programs containing races and give sc semantics to the rest ag relying on synchronisation from the implementations of lock and unlock precisely defining a programming language model is a technical challenge in itself as by the in establishing a java memory model that admits all the intended optimisations sa and the work on cx however when it comes to concurrent systems code and concurrent data structure libraries for example as used in an os kernel and in it seems that a weak model is essential compiler optimisations are not the main issue here these lowlevel algorithms often have little scope for optimisation and their accesses should be implemented exactly as expressed by the programmer but for good performance it is essential that no unnecessary memory are introduced and for understanding and reasoning about these subtle algorithms it is essential that the language has a clear semantics moreover such algorithms are such code is a small fraction of that in a large system but may have a effect on performance this is illustrated by an improvement to a linux where a change to a primitive gave a performance gain lin this both java and cx aim to provide a strong model for most programming but with lowlevel primitives for use in the face of all this semantic of source language target language compilation between them and the soundness of optimisations it is essential to take a rigorous and approach to concurrency to give semantics for source and target languages and to consider verified or verifying compilation between them in the sequential setting verifying compilation has recently been shown to be feasible by leroy et als compcert a verifying compiler from a sequential language clight to assembly language com bl in this paper we consider verifying compilation in the setting of concurrent programs with a realistic relaxed memory model contributions our first contribution is the design and definition of clighttso § clighttso is not intended to be a generalpurpose programming language but rather a language in which concurrent algorithms can be expressed precisely and more as a test case for reasoning about computation it essentially the x or hardware load and store operations and synchronisation primitives to the programmer so clighttso loads and stores inherit the hardware tso behaviour but can be implemented without memory or atomic instructions as we discuss in § in a full language one would expect to augment these with threadlocal accesses that the compiler is permitted to away for sequential code but that is not our focus here the semantic design of clighttso turns out to involve a surprisingly between the relaxed memory model the behaviour of block allocation and free and the behaviour of pointer equality our second contribution is one of semantic engineering § relaxed memory models are complex in themselves and a verifying compiler such as compcert is complex even in the sequential case to make verifying compilation for a concurrent language feasible we have to pay great attention to structuring the semantics of the source and target languages and the compiler and any correctness proof to separate concerns and reuse as much as possible we factor out the tso memory from each language and build smallstep semantics allowing most of the proof to be done by simulation arguments a key question for each compiler phase is the extent to which it changes the memory accesses of the program for most of our phases of the memory accesses of source and target are in exact correspondence moreover for four phases the memory accesses are identical except that some values that are undefined in the source take particular values in the target and one phase register allocation has no effect on memory accesses except that it removes memory loads to dead variables for all these the correctness of the phase is to the tso nature of our memory that leaves two phases that change memory accesses substantially and whose proofs must really involve the whole system of all threads and the tso memory we present evidence that our approach is effective § we have implemented a compiler from clighttso to x taking compcert as a starting point and have proved correctness in coq coq for key phases in addition we have successfully run the compiler on a number of sequential and concurrent benchmarks including an implementation of a nontrivial lockfree algorithm by fraser finally we reflect on the process and on the tools we used § discuss related work and conclude the proof effort for each compiler phase was with its conceptual difficulty some have essentially no effect on memory behaviour and needed only of work a few were much more substantial really changing the intensional behaviour of the source and with proofs that involve the tso semantics in essential ways thread thread write buffer write buffer lock shared memory figure block diagram background we begin by the behaviour of our target language x multiprocessor assembly programs as captured by our model the classic example showing behaviour in a tso model is the store buffer sb assembly language program below given two distinct memory locations x and y initially holding if two hardware threads or processors respectively write to x and y and then read from y and x into register eax on thread and on thread it is possible for both to read in the same execution it is easy to check that this result cannot arise from any sc interleaving of the reads and writes of the two threads but it is observable on modern intel or x sb thread thread mov x mov y mov mov allowed final state thread eax thread one can view this behaviour as a visible consequence of store each hardware thread effectively has a fifo buffer of pending memory writes avoiding the need to block while a write completes so the reads from y and x can occur before the writes have propagated from the buffers to main memory in addition it is important to note that many x instructions involve multiple memory accesses eg an increment inc x by default these are not guaranteed atomic so two parallel increments of an initially location might result in it holding but there are variants of them lock inc x atomically performs a read a write of the value and a of the local write buffer instructions are atomic in the same way and memory simply the local write buffer the model makes this behaviour precise in two equivalent ways an abstract machine with an operational semantics illustrated in fig and an of legal executions in the style of app k the model covers the normal case of aligned accesses to memory it does not cover other memory types code and so on for the relationship between the model and the documentation and with empirical testing we refer to our previous work clighttso clighttso is a language imperative with pointers and pointer arithmetic and with storage that is dynamically allocated and but not subject to garbage collection gc we choose this level of abstraction for several reasons first it is what is typically used for concurrent systems programming for example in an os kernel where garbage collection may be infeasible and many concurrent algorithms are expressed in second it is an starting point for research in pl semantics and compilation because c accesses will often map onto target accesses without the complexity and cost of accesses required for gc last but not least the work of leroy et al on compcert gives us a verifying compiler for sequential programs so by using that as a starting point we can focus on the issues involved in concurrency syntactically clighttso is a straightforward extension of the compcert clight language bl adding thread creation and currently this is storage for function local variables but our development is structured so that adding explicit malloc and free should be straightforward type ty void int float pointer ty array function struct id union id comp ty nil id ty unary operation op binary operation op expr e expr a n f id e e op e e op e ee ee ty opt lhs atomic statement as cas atomic inc statement s skip ee opt lhs e e ss if e then s else s while e do s do s while e for break continue return opt e switch l s goto l thread opt lhs labeled statements ls default s case internal ty id s program main id figure clighttso abstract syntax some atomic primitives that are directly implementable by x instructions an of the abstract syntax is given in fig where one can see that programs consist of a list of global variable declarations a list of function declarations and the name of a main function function bodies are taken from a fairly rich language of statements and expressions semantically though the addition of concurrency has consequences tso most obviously the clighttso load and store operations must have tso semantics to make them directly implementable above x so we cannot model memory as say a function from locations to values instead we use a derivative of the tso machine in fig the abstract machine style is more intuitive and technically more convenient here than the axiomatic model pointer equality c implementations are typically not one can use pointer arithmetic to state including that introduced by compilation but in order to specify an implementable language c standards rule out many programs from consideration giving them undefined behaviour for example the draft cx standard states if an object is referred to outside of its lifetime the behavior is undefined the value of a pointer becomes when the object it points to reaches the end of its lifetime cx p in clight the memory state records what is allocated with equality testing of pointers giving the undefined value if they do not refer to currently allocated blocks however in a setting any to global time should be treated with great and the concept of currently allocated is no longer simple different threads might have different views not only of the values in memory but also of what is allocated for example in one thread might free and use some memory while another thread compares against a pointer to it with the writes of the first thread remaining within its buffer until after the comparison one could make pointer comparison effectful the abstract machine to see whether a pointer is valid wrt a particular thread whenever it is used but this would lead to a complex and semantics moreover comparing potentially dangling pointers for equality is useful in practice eg in algorithms to free cyclic data structures accordingly for clighttso we take pointer comparison to always be defined block reuse in turn this means that the clighttso semantics must permit reuse of pointers again with clight in which allocations are always fresh otherwise it would not be sound wrt the behaviour of reasonable implementations for example in the program below h must be allowed to return or as an implementation might or might not reuse the stack frame of f for g int f int a return a int g int a return a int h return f g memory errors and of allocations and a read or write of a pointer that is dangling wrt that thread must still be a semantic error so that a correct compiler is not to preserve the behaviour of such programs now implementations of memory allocation and free do not necessarily involve a memory or other buffer at the assembly language level stack allocation and free are simply register operations while heap malloc and free might often be wrt some threadlocal storage to test whether pointers are valid therefore we treat allocations and analogously to writes adding them to the buffers of the tso machine this is a convenient common abstraction of stack and heap allocation for the former it essentially models the stack pointer an allocation must immediately return a block address to the calling thread but they should not when they are when they the main memory of the tso machine so they must return blocks that are fresh taking into account pending allocations and from all threads it is technically convenient if and writes also fail immediately when they are added to the tso machine buffer so we also take all possible sequences of the pending allocations and into account when them otherwise one would have latent failures eg if two threads free a block and those are both held in buffers finite memory a final of clighttso not directly related to concurrency is that we support finite memory in which allocation can fail and in which pointer values in the running implementation can be equal to their values in the semantics the latter is convenient for our correctness proofs simplifying the simulations it also means that pointer arithmetic works properly mod and may be helpful in the future for a semantic understanding of errors the memory usage of a compiled program and its source may be different as the compiler may be able to local variables to registers but will need extra storage for stack frames and temporaries but analogous to verifying rather than verified compilation it would be reasonably straightforward to make the compiler emit and check for each function bounds on those one could then reason about real space usage in terms of a source semantics annotated with these bounds smallstep semantics clighttso is a concurrent language in which execution of an expression or a statement may involve multiple memory reads and hence multiple potential interaction points with other threads we therefore need a smallstep operational semantics for both expressions and statements conceptually this is routine but it requires significant described in § of definitions and proofs wrt compcert where clight had a bigstep semantics for expressions we use a style with thread states that can be an executing expression with an continuation or an executing statement with a continuation expr cont e op · e e · s v · s stmt cont s stop s · s state e · e s · s here is a threadlocal environment mapping identifiers to their locations in allocated blocks the semantics is also by an global environment of global variables and functions and additional machinery is needed to deal with lvalues loops and function calls which we return to in § we also fix a lefttoright evaluation order examples we give a of the language with some very small examples of clighttso source programs sb the x behaviour can now be seen at the clighttso level eg if the following threads are created in parallel then both could print in the same execution int x int y void tid x dn y return void tid y dn x return using cas more an efficient can be implemented directly in clighttso using cas any integer variable can be used to represent the state of the with lock and unlock as follows void mutex while while mutex void mutex mutex the generated the implementation of linux mentioned in section as shown by the memory update performed by unlock does not need to be on a publication idiom the memory model supports the common publication idiom below double channel int flag sender channel flag receiver while flag fn channel since the store buffers are fifo when the receiver thread the update to flag the contents of the channel variable must have been propagated into main memory and as such must be visible to all other threads that do not themselves have a pending write to channel for contrast in cx which also targets machines flag must be accessed with sequentially consistent atomics implemented with costly x instructions or or with atomics implemented with normal stores and loads but with a much more involved semantics verifying compiler strategy having discussed our x target language in § and the design and of our clighttso source language in § we now consider the semantics and proof structure required to make a verifying compiler for a concurrent language feasible correctness statement the first question is the form of the correctness theorems that we would like the compiler to generate we our attention to the behaviour of whole programs leaving a compositional understanding of compiler correctness for concurrency eg as in the work of benton and for sequential programs bh as a problem for future work we take the observable behaviour of both clighttso and programs to be labelled transition systems lts with visible actions for call and return of external functions eg os io primitives program exit semantic failure and an error together with internal actions event ev call id vs return typ v exit n fail we split external io into call and return transitions so that blocking os calls can be correctly modelled now how should the source and target lts be related as usual for implementations of concurrent languages we cannot expect them to be in some sense equivalent as the implementation may resolve some of the nondeterminism cf for example in our implementation stack frames will be and the pointers in the example above will always be equal hence the most we should expect is that if the compiled program has some observable behaviour then that behaviour is by the source semantics some kind of backward simulation result this must be refined further compiled behaviour that arises from an erroneous source program need not be in the source semantics eg if a program a return address on its stack or tries to apply a we have to distinguish between such semantic errors modelled with fail and allocation errors modelled by so that we can correctly blame the source program in the former case moreover the compiled program should only diverge indicated by an infinite trace of labels if the source program can we express all this with the following notion of backward simulation between a source lts s and a compiled target lts t definition a family of relations ri × indexed by elements i of a wellfounded order is a measured backward simulation if whenever s ri t and t ev t for ev then either s s s fail s can reach a semantic error or s j s ev s s rj t s can do a matching step or j ev i j s rj t t with a decreasing measure given a measured backward simulation relating s and t one can easily see that if s has no semantic failures then any finite or infinite completed trace of t that does not include an error is a trace of s the compcert proof strategy clighttso is an extension of sequential clight and its compiler has to deal with everything that a clight compiler does except for any optimisations that become unsound in the concurrent setting we therefore our semantic definitions and proof structure to reuse as much as possible of the compcert development for sequential clight the parts where concurrency plays a key role compcert is around k lines of coq into compiler phases each of which builds a semantic preservation proof between semantically defined intermediate languages the terminology in compcert forward and backward refer to the direction of the simulation with respect to the compiler phases not to the direction of transitions of compilation as a forward simulation means that source behaviours can be matched by the target overall strategy is to build some kind of forward simulation for each phase these can be composed together and combined with for the target language or arm assembly to give a backward simulation for a complete compilation forward simulations are generally easier to establish than backward simulations because compiler phases tend to introduce intermediate states a forward simulation proof does not have to and relate these as we shall see this strategy cannot be used directly for compilation of concurrent clighttso to x but much can be adapted the proof by compiler phases our compiler is divided into similar but not identical phases to compcert the above notion of backward simulation also serves as the correctness criterion for each of our phases theorem the composition of two measured backward tions is a measured backward simulation coq proof and proof in our concurrent setting the languages are not deterministic so the compcert approach to building backward simulations is not applicable however for most of the phases we can reuse the compcert proof adapted to give forward simulation results for the behaviour of a single thread in isolation and we can make our semantics deterministic for such we therefore the semantics for each level source target and each intermediate language instead of defining transitions s s over configurations that combine a singlethreaded program state s and an sc memory as most sequential language semantics including compcert do we define the semantics of a single thread split apart from the memory as a transition system s te s together with extra structure for thread creation where a thread event te is either an external event as above an interaction with memory me an internal action or the start or exit of the thread thread event te ext ev mem me start opt tid p vs exit the semantics of each level is a parallel composition roughly of the form s sn of the thread states si and a tso machine the threads interact with the tso machine by on various events reads or writes of a pointer p with a value v of a specified memory chunk size allocations and of a memory block at a pointer p various error cases and thread creation these transitions are in the style of the early transition system for ccs a thread doing a memory read will have a transition for each possible value of the right type for example here is the clighttso rule for dereferencing a pointer access mode ty by value c typ type of chunk c type v typ p · ty · e mem v · e external events of the threads and of the tso machine are exposed directly as the behaviour this conceptually simple change concerns compiler phases that do not substantially affect the memory accesses of the program can be proved correct as described in § and those results lifted to the whole system by a general result below leaving only the two remaining phases that require proofs that really involve the tso machine the tso machine our tso machine is based on the abstract machine with a main memory and buffers but with several differences the tso machine must handle memory allocations and which are and various memory errors the main memory records allocation as in compcert we use the tso semantics for software threads not hardware threads which is sound provided that the scheduler the buffer during task switching we use the same tso machine for all the intermediate languages and we uniformly lift to the parallel composition with the tso machine lifting forward simulations to backward simulations we convert forward simulations to backward simulations in two steps first we observe that a forward simulation from a language to a determinate language implies the existence of backward simulation we say that two labels are of the same kind written te te if they only differ in input values in our case te te if i te and te are reads from the same memory location but not necessarily with the same value or ii te and te are external returns or iii te te definition a thread lts is if s te t and te implies t s te t te definition a thread lts is determinate if s te t and s te t implies te te and moreover if te te then t t definition a relation r between the states of two thread s and t is a forward simulation if there is a wellfounded order on the states of s such that if given any s s s t t and label te whenever s te s and s r t then either te fail or t t te t s r t or te s r t s s definition a relation r is a backward simulation if there is a wellfounded order on t such that whenever t te t and s r t then either s s te s s r t or s s fail s or te s r t t t moreover if t t is stuck and s r t then s or s s fail s note the subtle in handling errors if a source state does an error or gets stuck both the backward simulation and forward simulation hold in contrast the target states errors must be reflected in the source to make the backward simulation hold this is necessary to allow compilers to eliminate errors but not to introduce them theorem if r is a forward simulation from s to t s is and t is determinate then there is a backward simulation that contains r coq proof details of and assumptions on global environments we have theorem a backward simulation can be lifted to a measured backward simulation for the composition of the threads with the tso machine coq proof to establish correctness of compiler phases that remove dead variable loads and undefined values we have also proved variants of theorems and for modified definitions and the two proofs in clighttso as in clight local variables are all in allocated blocks but an early phase of the compiler identifies the variables whose addresses are not taken by any use of the operator and keeps them in threadlocal environments changing loads and stores into action environment accesses moreover individual stack allocations on function entry are merged into one large allocation of the entire stack frame conversely a later phase does activation record layout and threadlocal state manipulation actions is compiled into memory accesses to the threadlocal part of activation records in both cases the thread has different views of memory in source and target and these views involve the of loads stores allocations and we return to this which is the of our proof in § and § finite memory to be faithful to a real machine semantics our x semantics uses finite memory and performs memory allocations only when threads are initialized the stack of the thread is allocated in clight however small memory allocations happen whenever a variable is declared as a result the memory should be unbounded because the compiler can local variables to registers and thus a clight program can have a footprint that would not fit in the x memory in our intermediate languages we switch from infinite to finite memory in the csharpminor to cstacked phase § where we move local variables whose address is not taken to local environments and perform one allocation for the remaining local variables per function call since our pointer type needs to accommodate both the finite and infinite nature of addresses our pointers are composed of two parts an unbounded block identifier and machine integer offset within the block the language semantics uses only the finite memory in block the memory to allocate any other block the higher level languages can allocate in any block note that one memory block can contain more than one memory object a later phase to phase § away the allocations per function call a threads stack when it is created the final phase x we target x because gives us a relatively simple and relaxed memory model for a common multiprocessor compcert targets sequential and arm assembly language but these have much more concurrent behaviour which is still not fully understood though cf we therefore need an x described in § parts of the new x of compcert following the strategy above we have built a working compiler from clighttso to x assembly language with semantics and have proved correctness of the most interesting phases this shows a how we can reason about concurrent tso behaviour in the phases where that plays a key role and b how our overall strategy enables relatively straightforward adaptation of the existing sequential proof in the phases where concurrent memory accesses do not have a big impact our development all in coq is available online the structure of our compiler and of its proof is shown in fig the into phases between intermediate languages follows compcert as far as possible with our major changes being · the source and target languages are clighttso and concurrent x assembly not clight and or arm assembly infinite memory finite memory clighttso source parsing typechecking simplification clighttso simplification § typebased overloading resolution csharpminor § stack allocation of cstacked compilation of switch statements undefined values can become defined cminor instruction selection construction of the cfg address code generation rtl recognition of tail calls undefined values can become defined rtl constant propagation rtl cse for arithmetic expressions only rtl register allocation unnecessary loads removed § ltl branch ltl of the cfg calling conventions undefined values can become defined linear out the activation records part i § out the activation records part ii § of x assembly code undefined values can become defined x of x ast assembly and linking machine code x at calls stack allocations stack allocations at thread creation our proof structure is indicated by single arrows for forward simulations and straight double arrows for direct proofs of backward simulations arrows are if the proof is completed and dotted otherwise the completed composite backward simulations lifted with theorems and and composed with theorem are shown with double arrows clighttso and csharpminor perform a stack allocation for each individual variable in the program and assume an infinite memory whereas the languages below have only finite memory from cstacked to a stack allocation occurs for each nonempty stack frame that is almost every function call whereas in and only when a thread is created figure phases · the semantics is expressed with a tso machine which is common to all phases · we need a stack of abstractions for the intermediate languages while named after those of compcert their semantics are all adapted to tso semantics · the simulation from clighttso to the first intermediate language csharpminor is a new proof above our smallstep semantics · the compcert phase that does stack allocation of some local variables those whose address is taken by from csharpminor to cminor is divided into two via a new intermediate language cstacked cstacked has the same syntax as csharpminor and compilation to it is the identity on terms but a memory semantics more like cminor the proof of the phase is a new direct backward simulation argument dealing with the very different patterns of memory accesses in the two languages and how they interact with the tso machine · the proofs of the middle phases of the compiler from rtl to with various optimisations are relatively straightforward of the compcert proofs to our semantics and then lifted by the general results of the previous section · our phase generates x rather than or arm assembly the rest of this section discusses these in more detail our main results are as follows theorem given a clighttso program p and its compilation to a cminor program p there is a measured backward simulation between the of p and p coq proof theorem if an rtl program p has been successfully com to a program p by the following phases tail call recognition constant propagation restricted cse register cation branch and activation record layout then there is a measured backward simulation be the of p and p coq proof proof outline first we construct forward simulations from clighttso to csharpminor from cstacked to cminor and between each of the phases from rtl to more precisely for the tail call recognition and phases we establish a forward simulation with and for the register allocation phase a forward simulation with unnecessary load removal then we turn these forward simulations to backward simulations by theorem and by the analogous theorems for the forward simulation with and for the forward simulation with unnecessary load removal then by theorem we turn the backward simulations into measured backward simulations in § we also establish a measured backward simulation from cstacked to csharpminor finally by composing these measured backward simulations according to theorem we get the overall measured backward simulations at the time of writing the remaining proofs required for a complete verifying compiler include our phase which involves memory very similar to those of and the forward simulations for compilation from cminor to rtl which should be relatively straightforward from compcert these have been sketched out in detail in coq and we believe that the main challenges have all been addressed though of course one can never be certain until the proof is complete clighttso csharpminor v · v · e v · n · v · e v · e v · v · e v · e here int int and ptr pointer int the type annotation in the multiplication context is omitted figure part of the simulation relating clighttso and csharpminor evaluation for addition of an int and a pointer clighttso csharpminor id ty ty ty · e id · e deref id ty ty · ty · e addr id ty · ty · e id p · ty · e eval var ref id p c mem read p c v var has type v type of chunk c mem read p c v v · e v · e figure clighttso compilation can sometimes eliminate transitions clighttso to csharpminor clighttso is compiled into csharpminor a highlevel intermediate representation that has a simpler form of expressions and statements most notably the translation various looping constructs found in the source away casts translates union and into primitive indexed memory accesses and makes variable lvalue and explicit highlevel type information found in clighttso is compiled to a memory representation for these differences in the simulation is complicated by the relatively large size of the two languages definition has rules while csharpminor has because expression evaluation is defined by a smallstep semantics the forward simulation proofs directly from compcert which uses a bigstep expression evaluation semantics was not feasible and much of the proof along with the simulation change had to be written from as a result since the two languages are relatively close however the revised simulation could sometimes simply map clighttso transitions directly to the corresponding csharpminor ones evaluation of constants unary operations and certain components of function call and return are such examples however as we mentioned earlier compilation often results in a clighttso term translated to a sequence of simpler csharpminor terms to illustrate the diagram shown in fig shows the evaluation of a binary addition of an integer and a pointer for clighttso the multiplication of the integer operand by the representation size of the pointer type is performed implicitly subsumed within the definition of addition in csharpminor an explicit binary multiplication operation is introduced notice that the continuations in the subsequent matching states are structurally quite different from each other as a result the simulation relation must explicitly account for these differences perhaps a more surprising consequence of using a smallstep semantics is that the simulation relation may sometimes be required to match multiple clighttso transitions to a single csharpminor one for example compilation from clighttso to csharpminor eliminates various states defined in clighttso to deal with addressing and dereferencing consider the evaluation of an identifier that appears in an context in clighttso the identifier is first translated into a pointer and a separate step returns either the contents of the pointer in case it references a scalar type or the pointer itself in case of eg arrays or compilation to csharpminor removes this intermediate step generating the appropriate access instruction directly since the pointer type is statically known this simplification generalizes to sequences of and dereferencing operations we the sequence of steps necessary to compute a variables address and then dereference it if it is a scalar in fig the relation eval var ref states that variable id in the context of local environment evaluates to pointer p that references an object with memory representation c the value v read must have a type consistent with c as defined by relation has type notice that clighttso requires four steps to perform this operation while compilation to csharpminor requires only one to account for such differences the simulation relation forces csharpminor transitions to a measure on clighttso expressions and continuations that allows matching of several intermediate clighttso states to a single csharpminor one indeed such a measure adapted must be defined for most other compiler phases besides memory read and write operations the clighttso semantics also generates events for function argument and local variable allocation as part of the function calling sequence the smallstep semantics requires these operations be performed in stages after all argument expressions and the function pointer have been evaluated memory is allocated for each formal parameter as well all local variables in turn each distinct allocation is represented as a separate labelled transition after allocation the values of the are written to the formals on function exit allocated storage is the corresponding csharpminor transitions are similar with a change in the underlying type representation used to guide memory allocation and writes changing memory accesses csharpminor to cstacked languages and compilation the csharpminor to cstacked phase the semantic gap to the next intermediate language cminor by introducing a new semantics of the csharpminor syntax that is the program transformation from csharpminor to cstacked is an identity function however the cstacked memory semantics closely follows that of cminor which differs from csharpminor to understand the motivation for introducing cstacked we the main features of the following compilation phase cstacked to cminor local variable reads and writes are turned into explicit memory accesses or local state reads and updates note that in csharpminor as in c it is legal to take the address of a local variable and even to pass it to another thread so long as it is not accessed outside its lifetime variables whose address is never taken however are guaranteed to be threadlocal and the compiler such variables from memory to local state the remaining variables are kept in memory individual local variable allocations are replaced with single allocation statements are compiled to statements without the intermediate cstacked phase the first two steps change memory semantics step replaces memory accesses to local variables with local state manipulation that does not touch memory and step replaces the individual variable with a single deallocation in cminor to separate concerns the cstacked semantics only captures the memory effects of the transformation ie its transitions simulate the compilation steps and cstacked and csharpminor only differ in handling local variables the change is most evident in the types of local environments which are part of the local state of threads in csharpminor a local environment is a map from names to pointers and type information that essentially describes the size of a local variable in memory var kind vk scalar memory chunk array size env nil id p vk in cstacked a local environment consists of a stack frame pointer and a map that assigns to each name a value or an offset within the st kind sk local v stack scalar memory chunk stack array size items nil id sk env p note that cstacked can keep values of local variables in the local environment when the corresponding st kind is local this with csharpminor which stores the values of all local variables in memory the difference in the environment all the other changes from csharpminor to cstacked we the rules for assignment the write of a functions return value local variable reads function entry and function exit to handle local variables and variables separately the most significant change is in function entry where we scan the function body for the operator and compute the size of its stack frame together with offsets for local variables we illustrate the difference between the memory semantics of csharpminor and cstacked on the environment construction and parameter binding in function entry consider the following function int i int j k gi j k return jk fig shows the environment construction and argument binding transitions following an invocation of f with parameter the states have the following meaning the state call l f follows the evaluation of actual parameters l in the invocation of f alloc l v e is an intermediate state for allocation of local variables v where e is an for the environment and l is the list of values to be bound to the functions formal parameters bind l p e is a state for binding parameter names p to values l in environment e the alloc to bind transition the parameter names from the states continuation which we omit in this example for brevity note that csharpminor cstacked call f call f i i alloc j i k i alloc ai stack alloc » j k i i ­ i ai i alloc aj stack alloc k i » j i aj i ai i ­ alloc as stack alloc ak stack k ak i alloc j aj i i ai i k ak i bind i j aj i i ai i k si bind i as j si a i write ai int k ak i bind j aj i i ai i k si bind as j si a i l where i stands for scalar int for local si for stack scalar int and l for local figure function entry transitions in csharpminor and cstacked the states do not refer to memory directly instead the transitions expose the memory interaction in the labels in csharpminor the semantics of function entry allocates three different byte blocks one for parameter i and two for variables j and k in cstacked and in all languages between cminor and the function entry semantics allocates a single byte stack frame for variables j and k no memory is for variable i because is value is kept in the threadlocal local environment the binding transitions are also different csharpminor writes the value of parameter i to memory but cstacked simply stores the value in the environment indeed note the difference in the environment entry for i in the last bind states at the bottom of the figure the csharpminor entry only contains a pointer to memory whereas the cstacked entry contains the value of the variable simulating cstacked in csharpminor remember that the phase switches from infinite memory to finite memory this is necessary to be able to simulate the creation of the cstacked local environments by fresh memory allocation in csharpminor so that the memory cannot be allocated even by future cstacked allocations we call the finite space used by cstacked the machine space the remaining infinite part of the csharpminor memory space in other blocks is called space our representation of pointers is of the form b where b is an integer block identifier and is an offset in our semantics the machine space pointers have block b the pointers with nonzero b are space pointers we simulate cstacked transitions so that we preserve equality of pointer values in the states and the values in the machine memory · we simulate cstacked stack frame allocation by allocations of individual variables at the same machine memory location as they have in cstacked moreover we allocate space for cstacked local environments in globally fresh blocks in the memory · cstacked memory are simulated by the same in csharpminor · cstacked local environment accesses which are events in cstacked are simulated by memory accesses to the corresponding csharpminor memory · we simulate cstacked stack frame deallocation by the individual variables including the ones in memory in csharpminor the simulation relation on the states of the parallel composition of threads and the tso machine consists of three main components a thread state relation a tso buffer relation and a memory relation relating thread states the main source of difficulty is relating the local environments of cstacked and csharpminor because the values of the local environments in cstacked correspond to the memory contents of csharpminor therefore the thread state simulation must relate cstacked thread state with csharpminor thread state and memory in our tso semantics a threads view of memory may differ from the real contents of the memory and from other threads views of memory because of possibly pending writes allocations and in store buffers of this and other threads we consider local environments related for thread t if the values in the local environments in the cstacked state are the same as the ones in the memory of tso machine with ts buffer applied moreover we consider stack environments related if for each cstacked environment item of the stack kind with offset the corresponding csharpminor items pointer equals the sum of cstacked stack frame pointer and since cstacked and csharpminor only differ in their environments the thread state simulation relation is a natural lifting of the environment relation all thread transitions preserve such a relation because they can only affect the threads buffer however the simulation of applying other threads buffers to the main memory requires a stronger relation in particular the state relation does not prevent in one thread from with another threads state relation to get noninterference for we keep track of memory partitioning among threads this is also necessary to make sure that threads do not free each others stack frames by the state relation with the partitions they own in memory relating buffers the buffer relation requires that a cstacked allocation corresponds to individual disjoint csharpminor allocations of individual variables that must be in the cstacked writes correspond to the same writes in csharpminor buffer in cstacked buffer correspond to of in csharpminor to relate we must know the sizes of objects in memory because a free label does not contain a size hence we the buffer relation by the threads partition it is worth noting that the csharpminor buffer may contain extra memory labels for the local environment manipulation which are labels in cstacked and thus do not appear in the cstacked buffer we only require the operations in the labels to be valid in the threads partition csharpminor write int free stack free stack free stack write int alloc stack alloc stack alloc stack cstacked write int free stack alloc stack figure buffer relation fig illustrates the buffer relation assuming that the tso machine inserts labels to the top of the buffer and applies the labels to memory from the bottom the buffer contents might be generated by the function f from the beginning of this section where the allocations correspond to the transitions from fig the dotted part of the buffer is generated by the function g the correspond to local variable at function exit and the write label is by writing the return value to the callers stack frame the grey labels are the memory manipulation removed by the compiler or more precisely they are the labels introduced by the backward simulation note that they act on memory in the simulation proof the buffer relation says how to simulate cstacked buffer application in csharpminor while preserving the simulation relation for example if we are to simulate cstacked buffer application of the alloc label we apply the three corresponding allocations followed by the write from the csharpminor buffer relating tso states the simulation relation states that there are cstacked and csharpminor ie maps from thread ids to partitions such that · the csharpminor resp cstacked partitioning corresponds to the ranges allocated in the csharpminor resp cstacked tso machines memory moreover the must be pairwise disjoint and for each thread the csharpminor machine partitions must contain of cstacked partitions this is necessary to guarantee that any cstacked allocation can be successfully simulated in csharpminor · the values in the machine memory are the same in cstacked and in csharpminor we need this property to establish that reads of the same address give the same value in cstacked and in csharpminor · each threads cstacked and csharpminor buffers are related · for each thread t the states of t in csharpminor and cstacked are related in the partitions and memory updated by ts buffers the relation also imposes several consistency invariants to guarantee that cstacked writes do not csharpminor memory we require pointers only appear as pointers in csharpminor environments with these the relation on the tso states is a backward simulation relation a simulation of successful allocation is an interesting and exercise because one must show that in csharpminor no possible partial application of other threads buffers conflicts with the simulated allocations the partial buffer applications create states that do not directly correspond to any cstacked state eg partially allocated environments forcing us to a new simulation relation for this purpose changing memory accesses to in many respects the simulation from to is similar to the simulation and are again two different semantics for the same programs in the threadlocal state consists of the current function being executed the program counter the stack pointer the register file the current stack frame and a sequence of the stack frames for the functions callers instructions that manipulate local stack variables perform a step which accesses only the threadlocal stack frames in contrast allocates the stack frames in global memory so the three instructions generate read or write events for communicating with the tso machine the proof is by measured backward simulation which keeps track of which regions of memory are local for a given thread corresponding to the threadlocal parts of the stack frames and which regions correspond to the possibly shared parts of each threads stack frames for the threadlocal parts memory is related to the corresponding threads frames only after the threads updates have been applied whereas for the shared parts memory is immediately related to memory ie before any buffers have been applied in addition the and the buffers for each thread are related in an manner if we ignore the threadlocal writes from the buffers as they do not correspond to any memory writes in of course deciding whether a write is threadlocal depends on its position inside the buffer since preceding allocations and can affect whether an address is local or shared the full simulation relation also relates the states of each thread in the two semantics and contains several properties such as that the various threadlocal and shared stack allocation ranges are pairwise disjoint and that stack frames are aligned to byte boundaries a distinguishing aspect of this simulation is that we compile away and in each nonempty stack frame is allocated with a fresh address at function entry and deallocated at function return concretely however no memory allocation takes place the stack pointer is simply or accordingly therefore in each thread is allocated a stack when created and the stack pointer is simply at function entry and at function return x stacks grow if the stack pointer the allocated stack range the semantics raises an out of memory error in concrete x executions this would correspond to a segmentation fault due to stack overflow compiling away and makes the simulation relation slightly more as the relations between buffers and between memories over the appropriate ranges are of equality on values the values are less defined than the corresponding ones this is because a newly allocated stack frame in will initially contain everywhere whereas in the corresponding block after the stack pointer will contain whatever values to be there the easy phases including optimisations we have enabled all the compcert optimisations that are sound under the tso semantics these are constant propagation partial evaluation a restricted version of cse common subexpression elimination that eliminates only common arithmetic expressions but does not eliminate common memory loads redundant load removal as part of register allocation branch and tail call optimisation the only compcert optimisation we do not perform is cse for memory reads because this is unsound under the tso memory model as demonstrated by the following example adapted from int x x void f int p int a x b p c x x a b c fx cse would replace the assignment c x with c a allowing the second thread to print a behaviour that is not allowed by the tso semantics definitions of rtl ltl linear and and establishing that they are determinate and so that they can be composed with the tso machine was straightforward because the compcert definitions of these languages were already fully smallstep forward simulation proofs to forward simulation proofs and lifting them to measured backward simulations using theorems and was equally straightforward in the early of the project one phase took approximately two but by the end were sufficient to port constant propagation and lift it to a measured backward simulation elimination of redundant loads required a small adaptation of the simulation infrastructure moreover the tail call optimisation and the phases may change some of the undefined values in the source semantics to particular values in the target semantics requiring us to prove another slightly more general version of theorems and the x we adapted the x from compcert compcert supported and arm only with several differences in the semantics and proofs our x semantics is based on a hol of part of the x instruction set section the structure of our instruction ast is closer to that of general x instructions with their various combinations of immediate register and arguments than that of compcert which is a ast supporting just the combinations used by the compiler it does some additional complexity in the proof however we replaced individual allocations with stack space allocation at the start of the thread and direct stack pointer arithmetic we detect stack overflow by checking that the stack pointer register inside the threads stack space if not the semantics issues an explicit event using the more realistic single stack space gives us the added benefit of direct access to function arguments and the return address this with compcert that accesses arguments through an indirect link to parent and models the return address with a virtual register similarly to real link register the direct access to arguments us a slight performance advantage over compcert while the direct return address access enables a more modelling of x several parts of the x semantics are less realistic than we would wish the most abstraction in the semantics is modelling register and memory contents by the highlevel value datatype as in compcert which is a union of pointers integers and undefined value instead of the more appropriate representation running despite not making any attempt at the generated code results on simple sequential and concurrent benchmarks mostly drawn from com show that our generated code runs at about of the performance of gcc o as a more representative example we have also successfully compiled lockfree algorithm we are roughly of the performance of gcc o on this benchmark required only three changes all to inline assembly macros two of which were replacing macros for cas and by the clighttso constructs discussion we reflect briefly on the impact of the tool chain and proof style that we employed to ease development of our compiler the main tool was coq here we found the proof style by gm to be helpful in ensuring proof but to retain backward compatibility with compcert we employed it we used tactics to some of the more tedious proofs such as the and of all the languages to give the reader a for the effort involved in the development we list the number of lines of proof and specifications definitions and statements of lemmas for some of the important and fully proven phases of our compiler phases tso machine memory simulations § clighttso definition § § § § proofs of those the phases are of existing code phases in total as is the compiler part of the rest is largely new for comparison compcert has roughly k lines of specifications and k lines of proofs for all the phases the project has taken approximately the semantics of clighttso is given as an inductively defined relation as usual and following clight to make it easier to check the integrity of the definition we also implemented a functional of the transition relation and proved that the two definitions are equivalent by extracting the functional version into an ocaml program as an interpreter we were able to test the semantics on sample clighttso programs this a number of subtle errors in our original definitions it would also be worth testing our x semantics against processor behaviour as we did for a hol x semantics in previous work with a theorem is only useful if its statement can be understood and for the overall correctness theorem involves the clighttso and x semantics we defined clighttso using a tool that generates coq and definitions from a single source it also in enforcing naming conventions the clighttso grammar and semantic rules and the terms in examples are all parsed and automatically related work research on verified compilation of sequential languages has a long history recent work includes compcert which we have already discussed in detail compiler from a small impure functional language to an assembly language on coq proof automation jit compiler from a bytecode to x and benton and compilation bh from a simply typed functional language to a lowlevel machine this last differs from most other work in giving a compositional understanding of compiler correctness rather than just a relationship between the behaviours of source and target verified compilation of concurrent languages has received much less attention perhaps the most example is the work of loc extending a compiler from sequential java to jvm verified in to concurrency as here to a smallstep semantics required nontrivial proof effort but the memory accesses in source and target are very closely related so issues of behaviour memory layout finite memory and so on seem to have no role to the best of our knowledge there is no prior work addressing verified compilation for a concurrent language an alternative approach to extending compcert with concurrency has been suggested by et al they define a concurrent version of cminor equipped with a concurrent separation logic the idea is to do verifying compilation for programs that have been proved correct in such a logic and their oracle semantics for concurrent cminor rather differently to ours is intended to make that possible without extensive of the compcert proofs that is in some sense complementary to our work we focus on concurrent algorithms whereas programs proved correct in that logic are known to be race free as most application code is expected to be however we conjecture that an oracle semantics could be defined directly above the semantics that we use clighttso is not intended as a proposal for a complete language its load and store operations are analogous to the cx atomics and java and it has no distinguished class of memory operations which are to be threadlocal and hence which a compiler is to between synchronisation points it is closer to the or that is commonly used for concurrent algorithms and the clighttso operations can be implemented efficiently with simple x loads and stores and cx sc atomics need implementations though cx also has lowlevel atomics with weaker semantics that are to implement java and cx also have more complex semantics not specific to tso processors essentially x and conclusion the shift to processors has recently made concurrent computation but semantics and verification in this setting is a problem as lamport in lam for some applications achieving sequential consistency may not be worth the price of down the processors in this case one must be aware that conventional methods for designing algorithms cannot be upon to produce correctly executing programs protocols for the processors must be designed at the lowest level of the machine instruction code and verifying their correctness becomes a task this paper is a step towards putting them on a rigorous foundation both for programming and verification acknowledgements we thank leroy for discussions and for making compcert available we from grants and and grant references ag s v and k shared memory consistency models a ieee computer ­ j l s sarkar and p sewell in weak memory models in proc cav p editor programming languages c final draft sc n bh n benton and ck and compiler correctness in proc icfp bl and leroy mechanized semantics for the clight subset of the c language journal of automated reasoning ­ boehm threads cannot be implemented as a library in proc pldi pages ­ m s s sarkar p sewell and t c concurrency in proc popl cx programming languages ­ c draft n x a a verified compiler for an impure functional language in proc popl p a and e the java memory model operationally in proc esop com the compcert verified compiler v august coq the coq proof assistant fraser practical lock freedom phd thesis also available as tech report gm g and a a small scale reflection extension for the coq system technical report a a w appel and f oracle semantics for concurrent separation logic in proc esop lam l lamport how to make a multiprocessor computer that correctly executes programs ieee trans comput d concurrent programming in java second edition design principles and patterns leroy formal verification of a realistic compiler communications of the acm ­ leroy a formally verified compiler journal of automated reasoning ­ lin linux kernel list thread unlock messages th accessed loc a verifying a compiler for java threads in proc esop r milner communication and concurrency prentice hall international j w and sv the java memory model in proc popl m o verified compiler on x in proc popl s s sarkar and p sewell a better x memory model in proc s reasoning about the implementation of concurrency abstractions on in proc ecoop w the java memory model is concurrency practice and experience sa j s and d on validity of program transformations in the java memory model in ecoop p sewell on implementations and semantics of a concurrent programming language in proc concur july the architecture manual v the architecture manual v international inc p sewell s sarkar s f and m o a rigorous and usable programmers model for x c acm ­ s sarkar p sewell f s t t m and j the semantics of multiprocessor machine code in proc popl p sewell f s g t s sarkar and r effective tool support for the working j program ­ e m and j checking axiomatic specifications of memory models in pldi 