university abstract techniques have been widely used in the past in the construction of parsers however the restrictions imposed by them on the grammars were hard to meet thus of the rules of the grammar was necessary in order to make them acceptable to the parser we have shown that by keeping track of the possible set of rules that could be applied at any one time one can the class of grammars considered the possible set of rules to be considered is obtained directly from the information given by a set of precedence relations thus the parsers are easily obtained compared to the precedence parsers this new method gives a considerable increase in the class of grammars as well as an improvement in error detection an interesting consequence of this approach is a new decomposition technique for lr parsers introduction among the large variety of techniques used for parsing one can distinguish the bottomup parsers as those which attempt to make reductions on a given string so as to eventually get to the starting symbol of the grammar these parsers can be thought of operating in two modes or phases on the detection phase the parser attempts to determine the portion of a right hand side of the string which is being considered once this boundary is detected the parser goes into a reduction phase consisting of selecting a production which is a handle at the determined position if we classify different types of bottomup parsers according to the amount of information they carry while in the detection phase we can distinguish two on one hand we have the precedence parsers which are characterized by the fact that they carry no information while for the righthand side of a phrase and by making its decisions in the reduction phase by using local context only the parsers obtained are relatively simple but the classes of grammars they can parse is restricted by the of local by varying the amount of context examined one can define different families of precedence grammars among the most popular ones we have the precedence the simple weak precedence and the mixed strategy precedence on the other side of the lie the lrk parsers while in the detection phase they carry enough information so that the decision to reduce can be made immediately after a right hand side is detected the number of states an lrk parser has can become part of this high number of states is due to the fact that different information that is carried has to be further for the same local context an intermediate situation is obtained if one what is to be considered information which has to be carried forward and information that can be obtained from local context a parser thus constructed will consist of two machines a forward machine j and a decision machine d the parser will work as follows initially the control is given to the machine while on t the parser behaves like a precedence parser but every time it shifts an input it stores in the stack the input symbol together with a symbol denoting the state it is currently in the decision to shift which is by a transition to a new state is done by examining local context the t can also acceptance an error condition or a call on the d machine for a decision the d machine determines whether a shift or a reduce has to be performed by examining local context together with the state information that exists on the pushdown a shift is performed like the t if a reduce is called for the right hand side of the production used is removed from the the t machine is initialized to the state denoted by the symbol and the left hand side of the production used is given as input to it this is like an lrk parser a parser of this type is given in example example j let g be given by s a ada b a g is not a member of any of the classes of precedence grammars mentioned above an or an lr parser for g has states we can see that we really need states to carry information forward ie whether a c or a b was first seen the rest of the information can be determined from local context a diagram for the machine could be the d machine would check the contents of the stack to match a right hand side of a subset of the productions determined by the state of t from which it was called and it would give a decision on which reduction to make a diagram for d can be given as a forest called from reduce s ca reduce a aa reduce reduce s bb reduce b ab reduce bad in this paper we examine parsers built using this approach different classes of grammars can be obtained by applying different for the construction of the t and machines we will see that any class of precedence grammars can be extended this way without a significant of the parsers and the advantage of not having to accommodate the rules of the grammar to satisfy the requirements of the particular precedence method used although the of this study was to extend precedence parsers we get as a side effect a decomposition method for lrk parsers this approach is a matter of further study labeled precedence parsing in this section we examine the construction of different parsers and the classes of grammars they can parse we assume the reader is familiar with the terminology for context free grammars since our original attempt was in the direction of extending precedence techniques all the grammars considered here will be proper extensions to non grammars can be studied along the same lines definition a context grammar g is a reduced context free grammar v denotes the vocabulary vt is the set of terminals vn is the set of we assume the productions in p are indexed the set i of indices will consist of symbols of the form ak where a vn an index ia i will denote the kth production whose left hand side is a if this production is a we will write i a s or ak a if there is only one production for nonterminal a we will use a instead of al as its index there will be an index to denote an augmented production of the form s s s v this is just a convenience to make definitions simpler except where otherwise noted the following conventions apply throughout the paper vn vt jc v xyz c v we will now define certain relations between pairs of symbols in v these relations will be defined in a similar way as was done in but there will be a label attached to them the labels will provide information about the way the relation between the symbols was obtained definition let xy v let al az a al s l then x is less than y ml az x y if al az which we will write as vi al such that ia i and b cm j cy t x is equal than y ax a which we will write as x greater y m ai which we will write x y i i a and j c tx notice that ignoring the labeling the relations are as in example shows a grammar together with a matrix of relations let g be defined by the productions sl s a s s s s y y ag the precedence relations can be displayed in matrix form s s y z x a l b cg ss s s y z s s x ys c r s s sx za s s we have listed the elements of the sets a instead of using the usual set notation the matrix of precedence relations will be denoted by m note that for two symbols x and y there may be more than one of labels al a such that we will later perform reductions on this matrix these will amount to merging some indices into one we can think of the set of labels as coming from a set l and having a mapping l the is defined with l i and y in general though we will have a precedence matrix m with labels from a set l given a matrix of precedence relations we now define a parser for the grammar the forward states of the parser will be subsets of l informally the parser can be defined as follows define a directed graph whose nodes are the members of v plus two other nodes denoted by one of them will be the unique source node the other the unique sink node in the graph an arc exists between nodes x and y if the xy entry of the m matrix is not empty the initial state will be the set consisting of the label for production and we will say it is to the source node now we perform the following operation at every node let state s be to node x and let there be an arc from x into y let y and there may be more than one label of the form aa for the relation we then define a state t to node y as s l a together with the set of all indices of productions in az such that s al the state t will be referred to as the successor of state s when no new states are created the process stops note that the computation of the states is done using only boolean operations on sets and that checking if a state has already been created is straightforward the whole process can be viewed as a parallel operation at all nodes the set of states so created the set qf of states of the if machine the underlying will be called the the parsing of a word proceeds as follows initially the t machine is in the initial state so to node there is a stack which will have two channels subsequently referred as wi and y u initially let for some for be the contents of the stack at some point in the computation thus the t machine is in state s to node x let y be the next input symbol normally this is the next symbol in the input string let ux y if a shift is performed this consists in changing state to the successor state t of s and in the stack the symbols y on the first channel and t on the second if sta we say that a potential conflict occurs the set of all productions whose indices are in for all al is made available to the d machine which will give a unique decision of what to do the d machine will either determine a shift by examining productions in or a reduce to one of the productions in if a shift is determined control is to the state of s in the machine if a reduce is determined the right hand side of the production being reduced is up from the stack control is to the state now appearing on channel and the input symbol to machine t is the left hand side of the production used the parser accepts if the input symbol is t is in its final state and we will now define the machine t is a finite state machine where qf is a subset of the set of all subsets of l is the input alphabet the initial and final state is the set containing and f is defined as follows let s the xy entry of m contains labels aa there may be many labels of type aa in the range of r is interpreted as a call to machine d the empty state is interpreted as an error the transition function for the unrestricted t machine is sf u u a the d machine can be defined in different ways giving rise to different classes of grammars we will give some definitions here for simplicity we will restrict to local contexts of one symbol but these constructions can be extended to other contexts we will need some definitions which we now give definition let sw we denote by ft an operator such that is the longest prefix of of length k we denote by fk an operator such that fk fk pi p we define lk for suffix strings let zs be an interior symbol of a channel stack the stack is and for some n j let ia s be the production whose index is i if al a z we say that distinguished occurrence of z w production if nl occurrence of z leads into distinguished occurrence of s production and the distinguished production i then the is a d if or then we will say that we will write and for x z some ti y state s if ia and we will sometimes write a similar convention holds for the other labels now we can give a definition machine is specified as follows for the d machine the d a i i ax leads into i then reduce i and z b u u a and z leads into i y when d is called the parser has y as input and this d machine works as follows for each production ia s in it checks that s appears as a valid expansion of i if so machine d outputs reduce i it my output a state consisting of the set of all labels of productions such that y sx y and such that x appears as a valid expansion of i thus the d machine could produce more than one output we are interested in deterministic behavior so we will say that a parser is well defined if the d machine has at most one output an empty output from d is an of error the class of grammars which have deterministic parsers whose d machine are defined as above and whose y machines have n states will be called the class of precedence w independent la right context grammars let us compute the machines and d for the grammar in example xy a t machine states ss s s us w y s s lb ss lc s bz s br ls cr ry rx ra gl y xl s s s y s s xz dy dz dx ds y whenever a call to the d machine is given the set of all i such that is given the d machine can be represented as a forest where the root of each tree is by an element i of l and the corresponding tree represents all right hand sides of productions i such that il in this case l i and f is so there is one tree for each production reduce s reduce s reduce reduce y reduce z reduce x the parsers constructed as above will be such that their t machines usually have more states than it is necessary we can get minimal machines t as follows assume we have a definition for the class of machines we then define an relation on the set of productions i we will say that two productions ii iz are incompatible if when a call to occurs with state d will produce more than one output once we have all incompatible pairs of productions we will define a new set l and a new function y such that if il and iz are incompatible then il ji in other words we are defining an relation on i note that a call to d occurs whenever there is an entry in the matrix m containing a relation the are defined below let denote between productions if xy such that a i and al for some or ua and w such that a ck d if there are productions a j there is v such that and and i gw for some or and w such that a given the set of incompatible we can define a partition n on the set of productions such that if are incompatible productions they belong to different classes for each class we define a symbol let l be the set of all these symbols and define the natural map l such that ij if i and j belong to the same class of n we can now define the t and d machines as before for some partitions rt it may happen that z will not be well defined but if the parser defined on the identity partition was well defined there exist a partition for which the parser is well defined and for which the number of states of the machine t is minimal this number gives an on the amount of information that has to be carried forward in order to successfully parse the of the language generated by the grammar it is clear that for each n we can define grammars for which the t machine will have at least n states so this gives a measure of the complexity of the grammar as the following result shows even the simple class of grammars of states in this hierarchy ie those for which the number of the t machine is is an extension of the largest class of grammars defined using precedence relations over ie the class of simple mixed strategy precedence theorem j the class of grammars is contained in the class of grammars let g be a grammar assume there are two productions a i a b b let and since or we cannot have in particular we cannot have ai if we cannot have x or x b so in particular there is no index ck such that ck x y so no of type can occur if there are two productions a bj yz then again if ua there can be no such that bj if va then a and bj have identical right hand sides so there is no v such that u and v b u in particular there are no ck dm such that and thus no of type occur thus we can define t with one state it is easy to see the d is deterministic the class left and right under another of state context has been name as indicated grammars with independent presented in the literature by the following result theorem the class of state grammars with independent left and right context coincides with the class of overlap or grammars w the reader of or grammars a deterministic behavior is referred to for the definition case analysis shows that d has a iff every conflict is left or right thus we get the following conjecture of which answers a j the class of or languages coincides with the class of deterministic languages proof follows from the fact that every deterministic an grammar example presented a grammar which failed to be or there are two entries in m which can cause namely and for the latter we have that productions y and s are not of the form in case or for the definition of for the former we do have that thus at least states are required for the machine it turns out that states are sufficient to get a parser for this grammar because we checks left and following result have right defined context the d machine as one which independently we have the theorem for any n the class of grammars with independent left and right context is properly included in the class of grammars w given the set qo of sets of lr items for a grammar and the set qf of states of the unrestricted t machine we can define a mapping h from q to qf as follows let s be a set of lr items for each symbol we can partition si in sets u si u s u s u sis s z s s if then ys q i xy where s is the transition function of the unrestricted t machine and ss ys j is the set of lr items obtained as the y see for undefined terms now we make the following claim if s is a set of lr above then hs contains the indices u s us partitioned of all productions as in the claim is certainly true for so because ss now the claim holds for s i we note that i y is obtained by taking all productions in s u s with the dot over the symbol y which becomes the set s u s u s and applying a closure operator to get the set s j u s js but for every index i of a production in s i j we have and for every index j of a production in s d there is an index i of a production in s i ij s such that thus all indices of productions in u s u sj appear in state and the claim holds it is now straightforward to verify that if g is not ie if there are two conflicting items in some set s i of lr items then the corresponding state of the t machine will produce a call of the d machine which will in turn give more than one output thus the parser will not be a deterministic one and the grammar will not be an n state grammar we note that to generate the t machine we do not distinguish positions within a production as an parser does thus we are able to get the t machine faster but we restrict the class of grammars which can be parsed those which have productions in which a repeated occurrence of a symbol may cause problems as suggested by the following example example let g have productions bd i since and and a we have that the t the machine when in state ab and reading symbol dl the machine gives as output both reduce a and reduce b this behavior will occur even if the d machine checks the left and right context simultaneously as is done later on the other hand it is easily seen that g is an grammar example leads us to the following definition definition let be a production we will say that this production is free of for if for all we have ij implies x x ie there is no repeated occurrence of a symbol among the first n symbols a grammar will be free of for if all of its rules are for for grammars and for productions occur very often any grammar in normal form is a for grammar and every cf language can be given a trivial for grammar among the grammars used in programming languages a quick at some reveals that pl as defined in pages is for defined in pages has only one non for rule algol as defined in has only one non for rule which happens to be a production for the for list element as defined in pages is for if we are dealing with for grammars the result of theorem we can theorem if g is for and i then it is proof define the machine if g is for the claim theorem becomes the following using the stated in identity map the proof of cm productions if s i is a set of lr hs i coincides with the in u si u si items partitioned set of indices of as all to prove the claim it suffices to show that there are no indices of productions in hs which are not in s j s i u s this follows from the fact that if or y then since g is for there is only one occurrence of x in the production whose index is i since an lr item is identified by this symbol the map h is i it is easy to see that the parser constructed parser is isomorphic to the thus if we restrict our attention to for grammars both classes coincide moreover the parser can be obtained very easily from the t machine so that a fast procedure for constructing parsers is obtained as mentioned above for productions and grammars occur frequently in programming languages thus we should take advantage of this fact when constructing parsers for them we will now modify the definition of the d so as to make it check for simultaneous left and right context we need to introduce the following definition definition a symbol id within the context of q production qj if either c xy and either or or and for some production dk let a a be a production and a we say that a a valid reduction es within symbols x and and state s if for some cs such that y is adjacent within the context of production to symbols x and z c note that we can check the condition of valid reduction by the matrix m as the following shows we get information about possible simultaneous left and right context in which a nonterminal may appear let c with but for some such that py then is a valid reduction for s within x and z and some state s such that m we know c there are two cases or since fy in the first case also either or ca and then either c yz or if then such that c with pa then so c d xy and d yz in either case y is adjacent to symbols x and z within the context of cj since ya we have c j a i x fl where a a js thus we have that conditions and of definition are satisfied we are now in parsers by changing affect the instruction to a position to specify another class of the d machine the change will only label led a this instruction is changed a ai i ax into i and a is a valid reduction y and state s where s v next to z reduce i z leads for ix within symbols z and ie the state which appears we will now construct machine d a parser for a grammar using this example let g be sl s the matrix m is s s s a ac b s s a a s s ba s s ab s s b s s c dl ss ab ss ss the machine t is s s w s s s g a lb lc d sl aa ab s ba s eb s ca x a b cb da s s dc ab al xs ds bl ds ds the s t forest for s t machine d is as follows s s t ab al ab bf ri dd reduce s reduce s reduce s b reduce a a reduce b when is called with ab it knows its lookahead symbol assume it is an a then it checks that the stack contains c and looks at the left context if it is a d ss it checks to see if a or b are valid reductions of c within d and a and state ss from the matrix m we see that b is valid while a is not thus the output reduce b is given we could proceed as before and give a criteria for incompatible productions we will not do this here but k clear we again get a hierarchy depending on the number of states the machine has in the above example we really need the states in the t machine in order to decide the output for the d machine thus we could have built a parser with state in the t machine actually we have theorem the class of state precedence grammars with simultaneous left and right context is properly included in the class of if the grammars are restricted to be for these classes coincide m because the d machine can check for context of at most one to both left and right of the right hand side of a production we have that we are within the the following grammar is but not in the class of precedence grammars considered ad bd it thus remain to be shown that any for grammar which is is in this class this follows from the fact that for a for grammar the converse of lemma holds ie if a is a valid reduction for within x and z then is a substring of some form thus if the d machine more than one output it means that knowledge of the left and right context of a handle of a form does not uniquely determines it thus g is not l decomposition lr parsers so far we have considered parsers which operate as precedence parsers in the sense that once a reduction could occur as determined by the machine we would check the contents of the stack to either determine the production to use in the reduction or to continue the forward scan this of actions is clearly not necessary since the d machine when called only a bounded amount of tape not more than one plus the length of the longest right hand side of any production we can construct a definite machine which can operate in parallel with the t machine and which performs the checking that d does we will also refer to this new machine as the t machine in this way the decisions are already taken when the t machine requests them now the parser is exactly as an lr parser but since we have separated the functions in the y and d machines the total number of states is reduced as an example of these ideas consider the following grammar s d al az ab ac bc b bd cl c ce from the m matrix we can determine the we find there are none thus one state is sufficient for the t machine in fact g is an or not an the y machine is obtained directly from the matrix of precedence relations it has only one state which by a denoted by d input action input action input action s a ld a la a s a db a db a dc a dd a ac u ae a ad a aa a bl d bd d ba d cd d ca cl d dl d ca d cb d cc d cd d ce a ea eb d ec d ed d ee d to obtain d we reduce using standard techniques of finite machines the machine which checks all productions since there is only one state in t the only information j has to determine its output is the input from which it is called from t the following is the transition table for it has states notice that the input to d is taken as the second component of the input to t ie the new input symbol not the one already on top of the stack the output depends on both next state under new symbol stat abc i x da output bs ba db cd x x l a dont care entry is shown as an error entry is shown as x the following example shows a sequence of configuration taken by the parser when given an input string since t has state we do not show it on the stack the state of appears as a second component stack input action of machine td shift la shift d reduce c t reduce d ld shift d reduce al shift ld aa shift cal d reduce cz c cal d reduce d cal shift al d reduce az ld ada x al error had the last symbol a not been there the last two configurations would have been changed to d reduce b d reduce s s it is interesting state parser to note that this grammar has an constructed a la knuth a state parser detection using parser as method and a state by allowing the parser to error the one above does aho and unman constructed a state parser we have shown that using decomposition techniques one can get a parser for this grammar because of the simple way the t and d machines are determined this decomposition technique appears quite useful we should point out here that although not explicitly mentioned a similar decomposition technique appears in conclusions keeping track of the possible productions which can be in use at any one time during the operation of a precedence parser can significantly the class of grammars to which it applies we have shown how to obtain such parsers and given some ideas about their relative power an additional feature over conventional precedence parsers is the improved error detection capability the fact that we have more than one state during the detection phase allows the parser to discover errors before they are detected by conventional precedence parsers in fact these parsers very much like lr parsers but and they are considerably smaller than these by the machine which which reduction to perform we were able to get parsers which are equivalent to lr parsers obtained using error techniques but again at a substantial in the number of states more work is needed concerning this method of lr decomposition references generalization and comm n and of algol acm h and its formal definition parts and a j d and s p a technique for generating almost optimal productions for precedence grammars comm acm aho and a v p j and j d mixed strategy precedence languages knuth from d e on the translation of left to right information and control d s algorithm applied to generalized overlap grammars proc third annual acm on theory of f l comm acm simple lrk grammars aho a v and j d the theory translation compiling prenticehall s mathematical theory of contextfree new york n pl a programming language for the computers p cd revised report on the algorithmic language algol comm acm constructing lrk a j a practical method for processors comm acm m a and m on the parsing of deterministic languages to be published 