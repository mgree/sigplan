a shape analysis for optimizing parallel graph programs s dept of computer science the university of texas at austin texas usa institute for computational engineering and sciences the university of texas at austin texas usa abstract computations on graphs are challenging to because dependences in the underlying algorithms are usually complex functions of runtime data values static parallelization one promising generalpurpose parallelization strategy for these algorithms is optimistic parallelization this paper identifies the optimization of graph programs as a new application area and the first shape analysis for addressing this problem our shape analysis identifies points in the program after which the execution is guaranteed not to abort and copies of modified data are not needed additionally the analysis can be used to eliminate redundant conflict checking it uses two key ideas a novel topdown heap abstraction that state space explosion and a strategy for predicate discovery that exploits common patterns of data structure usage we implemented the shape analysis in and used it to optimize benchmarks from the suite the optimized programs were executed on the galois system the analysis was successful in eliminating all costs related to rollback for our benchmarks additionally it reduced the number of lock by a factor ranging from × to × depending on the application and the number of threads these optimizations were effective in reducing the running times of the benchmarks by factors of × to × categories and subject descriptors d programming techniques concurrent programming d programming techniques objectoriented programming f logics and meanings of programs program analysis general terms algorithms languages performance verification keywords abstract interpretation compiler optimization concurrency parallelism shape analysis static analysis programs optimistic parallelization synchronization overheads operators this work was supported by nsf grants and as well as grants from the ibm and intel permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ austin texas usa copyright c acm introduction computations on large graphs are in many problem domains such as computational machine learning and data they are difficult to because most dependences between computations in these algorithms are functions of values known only at runtime such as the structure of the possibly graph therefore it is impossible to these algorithms statically using techniques such as shape analysis and pointsto analysis one generalpurpose solution to graph computations is optimistic parallelization computations are performed in parallel but the runtime system monitors conflicts between concurrent computations and back computations as needed there are many implementations of this highlevel idea such as transactional memory and the galois system for our results are presented in the context of the galois system but they are applicable to other systems as well in the galois system applications programmers write algorithms in sequential java augmented with a construct called the galois iterator this iterator iterates in some unspecified order over a set of active nodes which are nodes in the graph where computations need to be performed the body of the iterator is considered to be an operator that is applied to the active node to perform the relevant computation known as an activity an activity may touch other nodes and edges in the graph and these are known as the for that activity these nodes and edges must be accessed by invoking methods from graph classes provided in the galois library ab d e cg f figure in algorithm we illustrate these concepts using minimal spanning tree algorithm the running example in this paper the starts as a forest with each node in its own component the algorithm iteratively contracts the graph by nondeterministically choosing a graph node examining all edges on that node to find the weight edge and that edge which is the galois system also supports iterators but we do not consider these in this paper added to the the algorithm terminates when the graph has been to a single node figure shows an graph for active node e the of the corresponding activity consists of nodes d e and f and the edges between these nodes since these are the edges that must be examined to find and contract the weight edge connected to e in most algorithms each is a small portion of the overall graph so it is possible to work on many active nodes concurrently provided the corresponding do not overlap for example in figure the for the activity at node c is disjoint from the for the activity at node e so these activities can be performed in parallel however the activity at node b cannot be performed concurrently with the activity at e since the overlap in the galois system this concurrency is exploited by adding all graph nodes to the and executing iterations of the galois in parallel all concurrency control is performed within the library graph classes conceptually an exclusive lock called an abstract lock is associated with each graph element and this lock is acquired by an activity when it that element by invoking a graph api method if the lock has already been acquired by another activity a conflict is reported to the runtime system which back activities to permit rollback methods that modify the state of the graph also record actions that are executed on rollback the idea of handling conflicts at the abstract data type level rather than at the memory level is also used in tm systems the galois system has been used to complex graph algorithms in the benchmark suite compared to static parallelization optimistic parallelization has several overheads work from aborted activities because conflicts between activities are detected online an activity may be back after it has performed a lot of computation conflict checking abstract locks must be acquired and released by activities and this is an overhead even if no activities are ever aborted actions these must be for every graph api call that might the graph in this paper we present a novel shape analysis that can be to reduce the overheads of conflict checking and actions reducing the number of aborted activities is mainly a scheduling problem and is dealt with elsewhere our main contributions are the following · shape analysis we develop a novel shape analysis for programs with set and graph data structures which infers properties for optimizing speculative parallel graph programs we the structure of stores arising in our programs to design a hierarchy summarization abstraction which uses a finite set of reachability relations relative to a given property the property to abstract stores into shape graphs our abstraction assigns unary predicates only to root objects capturing reachability facts from root objects to objects deeper in the heap thus the size of an abstracted store is linear in the number of variables and the number of abstracted stores at a program point depends on the number of explored sets which to be constant in our programs therefore the number of abstract states explored by our analysis in practice is linear in the size of the program the explosion that is the of existing shape analyses · predicate discovery we develop a simple yet effective technique for discovering predicates relevant for inferring the set objects that are always locked at each program location from data structure specifications and of data structure method specifications · evaluation of effectiveness we implement our shape analysis in the framework and use a frontend to analyze several benchmarks from the benchmark suite a collection of realworld applications that exhibit behavior our analysis takes at most seconds on each benchmark and infers all available optimizations these optimizations result in substantial improvements in running time ranging from × to × several existing heap abstractions including canonical abstraction boolean heaps indexed predicate abstraction and generalized abstract the heap by recording a set of unary predicates for every object and the heap by equivalence classes of objects with the same set of predicate values such abstractions achieve high precision as they express every boolean combination of intersection and union of objects satisfying those predicates however the size of a summarized heap can be exponential in the number of predicates and the summarization of a set of stores can be we call these bottomup abstractions since they typically express reachability facts for objects in the depth of the heap relative to heap roots our experience with bottomup abstraction shows that heaps are partitioned very leading to state space explosion as we discuss in section our topdown abstraction runs several orders of magnitude faster than an implementation of the bottomup abstraction approach when analyzing our benchmarks the rest of the paper is organized as follows section provides an overview of our optimizations and shape analysis on example section presents our shape analysis via hierarchy summarization and predicate discovery section describes the static analysis implementation and gives experimental results that demonstrate the effectiveness of the approach presented in this paper section discusses related work overview this section introduces the programming model the performance optimizations and our shape analysis informally using algorithm as the running example algorithm for the algorithm is shown in figure the galois iterator on line iterates over the graph nodes in some nondeterministic order performing edge contractions in lines we examine the neighbors of the active node a and identify the lt which is connected to a by a weight edge in lines we contract the two components by removing lt from the graph and updating all of lts neighbors to become neighbors of a this is done by the loop in lines if a n of lt is already connected to a we update the data value of the edge connecting them lines otherwise we add an edge connecting the two nodes lines in algorithm the of an active node a consists of the immediate neighbors of a and lt and their related edges and data in more complex examples like mesh refinement the of an activity can be an unbounded subgraph speculative execution in galois the graph data structure is parameterized by data objects referenced by nodes and edges respectively the work list of active nodes is stored in a set the weight ob class rep static locks abstract locks flag static int lock acquire locks log static int log static int lock acquire locks static int none no locks and no class weight static weight max weight int v we record the of the edge that holds the weight in the input graph final int other class void main g read from file wl new none new galois iterator foreach node a wl in any order l lock find to edge weight weight node lt null l for node n iterator edge e n none weight w none if w lt n if lt null no neighbors continue contract edge a lt l lock avoids in l l lt none l none l for node n iterator edge e lt n none weight w none edge an n none if an null merge edges weight none if w use minimal weight l w none else new for a l n w none l none l none l none put node back on worklist figure simplified implementation of algorithm which record the weights of the edges and their nodes in the original graph are stored in another collection which only allows addition operations in a concurrent context the last argument to a data structure method is a flag that tells the runtime system whether the method should attempt to acquire abstract locks and whether it should log an inverse method call the default value lock is always a safe choice ensuring correctness of speculative execution the galois system userdefined data types such as weight using a readwrite lock allowing concurrent read syntactic categories types pointer fields set fields field all fields pointer variables boolean variables variables var all variables stmt expr path data types class rep static rep static set var expr expr path path path path path path in path path path new var figure grammar for specified data structures the notation x means that x is optional but at most one write operation and maintaining copies of such objects iterations of the galois set iterator are executed in parallel and this execution has transactional semantics an iteration either completes and commits or is back and data structure specifications figure shows the syntax for a lightweight specification of abstract data types for all clients defining their abstract state abstract locks acquired by each method and operational semantics of each method in terms of abstract fields the set of variables includes method parameters the special ret parameter for returning values static variables and temporary variables used to define the semantics of methods the formal semantics of this language can be found in the report our analysis operates in terms of these specifications ignoring the internal details of library we assume the correctness of the specifications approaches such as can be used for their verification figure shows a graph type built from the node and edge types and the parametric types nd and ed used to store userdefined data on the graph nodes and edges in our example nodes do not store any data objects and thus their nd fields are null figure shows a bag a set and an iterator type specifying abstract data types the rep annotations in figure define the abstract state of a data structure in terms of ie fields whose values are sets of objects for example the abstract state of graph is given by a pair of sets ns and es representing the set of graph nodes and edges respectively we represent an edge by a single edge directed arbitrarily contains a static ie global locks set representing the set of abstract locks acquired by an iteration example figure shows an abstract store representing the input graph of figure where a references the active node a and lt references c the node connected to a by the edge discovered on the second iteration after over b the full specification includes additional firstorder constraints galois implements a lock scheme by maintaining a single set of abstract locks shared among all data structure instances c l a s s ed u n d i r e c t e d b o o s t e d g r a p h rep s e t node ns g r a p h n o d e s rep s e t edge e s g r a p h e d g e s locks n rev src dst n rev dst src op n r e v s r c d s t n r e v d s t s r c r e t new o n t s e g e t n e i g h b o r s n i n t o p t locks f rev src dst t t rev src dst f op f r e v s r c e f t d s t t t r e v s r c e t f d s t f ret choose g e t e d g e f t i n t o p t locks f t f rev src dst t t rev src dst f op f r e v s r c e f t d s t t t r e v s r c e t f d s t f ret in es ne new s r c f d s t t e s ne b o o l e a n f t ed d int opt locks n rev src dst n rev dst src op r e t n i n ns ns n e s n r e v s r c n r e v d s t b o o l e a n n i n t o p t locks f rev src dst t t rev src dst f op f r e v s r c e f t d s t t t r e v s r c e t f d s t f r e t e t f e f t i n es e s e t f e f t b o o l e a n f t i n t o p t locks n op r e t n nd nd g e t n o d e d a t a n i n t o p t locks e e src e dst op r e t e ed ed g e t e d g e d a t a e i n t o p t locks e e src e dst op e ed d v o i d s e t e d g e d a t a e ed d i n t o p t c l a s s nd nd d a t a o b j e c t c l a s s node s r c edge node d s t edge ed ed data origin destination object figure graph specification samples the figure does not show objects used by the internal concrete representation of specified data types instead it uses the rep set fields to indicate that an object is contained in a set field of a data structure filled locks denote objects in locks denote objects for which our analysis infers that lock protection is not required path language we use a language of access path expressions access paths for short to denote the set of objects that can be obtained by following variables and fields in a store a variable x denotes the object it references a pointer field ef denotes an object obtained by traversing the field f forward from an object denoted by the prefix expression e a set field denotes any object stored in the set stored in a given object a reverse field written or f denotes objects obtained by traversing field f backwards we formalize path expressions in section c l a s s b o o s t e d s e t rep s e t e g c o n t s e t c o n t e n t s locks e op r e t e i n g c o n t boolean contains e e locks e op r e t e n o t i n g c o n t e boolean add e e c l a s s b o o s t e d bag f o r r e d u c t i o n o p e r a t i o n s rep s e t e b c o n t bag c o n t e n t s locks no l o c k s r e q u i r e d op b c o n t e void add e e op r e t new c o n t s e te t o s e t u s e d o n l y i n s e q u e n t i a l c o d e i n t e r f a c e s e te s e q u e n t i a l s e t f r o m j a v a u t i l rep s e t e c o n t s e t c o n t e n t s i n t e r f a c e i t e r a t o r e i t e r a t o r f r o m j a v a u t i l rep a l l underlying set rep s e t e p a s t p a s t i t e r a t i o n e l e m e n t s rep e a t element at current iteration rep s e t e f u t u r e f u t u r e i t e r a t i o n e l e m e n t s figure set bag and iterator specification samples we use the notation x inside a path expression to denote a set of intermediate objects during an access path traversal we write and for set union and difference respectively example the following paths are derived from the abstract store in figure · represents the outgoing edges of a · represents the incoming edges of a · represents all of the graph nodes adjacent to a b c · sets the temporary variable x to the edge from a to lt x is not on a path from a to lt specifying abstract locks a locks annotation defines the set of abstract locks a method should acquire by a set of path expressions to keep specifications access paths expressions in locks stand for all of their prefixes eg stands for n and we call a node referenced by n along with its edges and adjacent nodes the immediate of n we specify the set of locks for such a by example commutativity via abstract locks the method specifies locks for the immediate of the node being removed a call to clock attempts to lock the node object c the edge objects c via the src field or the dst field the edges to c and the node objects that are neighbors of c this ensures the concurrent method calls clock and will not cause their respective iterations to abort since the immediate of c and e do not overlap specifying method semantics an op annotation defines the semantics of a method by a simple imperative language the language allows a sequence of statements using set expressions over method parameters static fields and temporary variables expressions of the form a in b a b and test whether a is contained in b a is not contained in b and whether a is an empty past at future all cont ab cd ef g a nd nd lt nd nd nd nd nd ns g es null null null null src dst ed src dst ed src dst ed src dst ed null null l src dst ed src dst ed v v v v v v figure an abstract store arising at l using as input the graph from figure object are shown by by their fields are used to name objects locks show objects contained in the global set we label node objects by the same labels used in figure and other objects by a running index a g ns es past at future all a a nd src dst nd ed v cont nd c lt lt wl figure a shape graph obtained by applying hierarchy summarization abstraction to the store in figure grey boxes represent sets of locked objects v indicates that the numeric value of v has been abstracted away set respectively we these expressions to treat reference variables as singleton sets statements of the form a exp and a exp are shorthand for a a exp and a a exp respectively nondeterministically chooses an object from a set denoted by exp optimization opportunities our static analysis enables the following optimizations eliminating usage of concurrent data structures the following conditions allow replacing a concurrent implementation of a data structure by a sequential implementation the data structure is iteration private or the data structure is never modified we use a purity analysis to discover objects that are never modified inside an iteration such as weight in the running example reducing rollback inverse method calls for iterations that commit represents work as the log is when the iteration commits and the method calls are never used our static analysis finds a minimal set of points program locations in the client program such that an iteration reaching them cannot abort the analysis computes an underapproximation of the set of objects that are always locked at a program location if the set of locks computed for a location l subsumes the set of locks computed for all locations reachable from l then l is a point an iteration reaching a point will never fail to acquire a lock and therefore cannot abort we eliminate inverse actions for method calls appearing after a point if no method call before a point modifies shared data structures rollback is not needed anywhere in the iteration algorithms with this property are called algorithms eliminating redundant locking our analysis can also be used to find method calls for which all locks have already been acquired by preceding method calls lock can be eliminated for these calls furthermore our analysis finds userdefined objects dominated by other locked objects ie objects that can only be accessed after a unique abstract lock is acquired we eliminate lock operations for such objects as well optimizing the running example by static analysis we develop a sound static analysis to automatically infer available optimizations of the kind discussed above the input to our analysis is a java program with a single parallel loop given by the foreach construct operating over a library of specified data structures the output of our analysis is an assignment of option flags to each adt method call and a list of userdefined types that do not need transactional protection the core component of our analysis is a shape analysis that the set of objects that are always locked at a program point intuitively our analysis abstracts stores into shape graphs by all objects not referenced by variables together and recording for each root object a set of path expressions denoting the set of locked objects figure shows a shape graph obtained by applying our abstraction to the store in figure the object labeled by a shows the set of objects the grey box pointing to a expresses the fact that the immediate of a is locked along with the weight objects referenced by its edges this shape graph represents an intermediate invariant inferred by our analysis at l the full invariant is given by a set of the shape graphs at that point at the fixpoint below we provide sample invariants that our analysis infers for figure and the corresponding path expressions denoting sets of objects all of which are locked inv at l the immediate of a is locked a inv at ll the immediate of a and lt are locked a lt inv at l and l all graph nodes accessible by the iterator past present and future iterations are locked inv at and the edges referenced by e and an and the nodes they reference are locked e an inv is part of the invariant needed to prove that l is a point before executing the statement inv needs to be maintained from l and on it is also used to eliminate locking in lines inv helps establish l as a point since all accesses to nodes and edges in the second loop are to objects known to be locked also it helps eliminate redundant locking at l inv helps establish the point at l by the fact that the node referenced by n is locked at and and eliminate locking at finally inv establishes that the calls to and in lines and do not lock new objects additionally our analysis infers that weight objects are readonly which enables eliminating all lock operations and copy for them points l l l l are after the point and do not require storing inverse actions at l the calls to the add method of bag do not require locks and trivially commute we apply these optimizations to the code of figure by setting the lock option at l and l which eliminates rollback and setting the none option in all other calls eliminating both abstract locking and rollback this implementation of algorithm is our analysis infers that the point is l and that no modifications are made to the graph between l and l if we remove the statement at l the point is at l which requires an inverse method call for lt a shape analysis for graph programs this section presents our static analysis for enabling the optimizations described in previous sections our analysis considers only sequential executions but the inferred properties apply to concurrent executions as well we use a result by et al and the fact that our concurrent executions are strictly to formally justify this the core component of the analysis is a shape analysis that the set of objects that are always locked at each program location this section is organized as follows we discuss the class of programs and stores that our shape analysis addresses we define canonical abstraction and partial join in our setting we define hierarchy summarization abstraction we present a technique for discovering predicates relevant to our analysis we explain how the results of the shape analysis are used we contrast our abstraction with backward reachability abstraction a commonly used form of shape abstraction we discuss how our analysis can aid the programmer by providing counterexamples and finally we discuss limitations of our analysis a class of programs and stores we analyze java programs recursive procedures where the implementation of specified data structures is replaced by the abstract fields in the rep annotations and the semantics of methods is given by the op annotations figure defines stores in terms of pointer fields and fields defined by the rep annotations we define the meaning of path expressions recursively which denote sets of objects reachable from a variable by following fields in specified directions and going through specified variables the last definition in figure provides the meaning of variables assigned to intermediate objects along path expressions such as hierarchical stores we define the set of types reachable from an object o by forward paths to be the set of types of all objects in op for all path expressions p this paper focuses on the class of hierarchical stores stores where the set of types reachable from of is a proper subset of the set of types reachable from o for every object o and field f such stores are acyclic the length of any l and l makes the code once again but breaks sequential correctness since in the galois library it is illegal to remove an edge while over the neighbors of a node to it path ie a path where all fields are either forward or reverse is linearly bounded by the number of program types canonical abstraction and partial join we implement our shape analysis using the system which allows defining stores by firstorder predicates program statements by firstorder transition formulae formulae relating the values of predicates after a statement to those before and abstract states by firstorder abstraction predicates the system automatically generates sound abstract operations and transformers yielding a sound abstract interpretation for a given program uses canonical abstraction which abstracts stores into valued logical structures to focus our presentation on the important details of our analysis we simplify our description of abstraction and use shape graphs for abstract states instead of valued structures definition shape graph let p ap be a set of predicates consisting of two disjoint sets of unary predicates called abstraction predicates ap and predicates a shape graph g is a tuple n g p g eg where n g is a set of abstract objects p g n g p assigns predicates to objects and eg n g × n g is a set of for each field we denote the set of shape graphs over p by we call the set of abstraction predicates assigned to an abstract node v n g its canonical name def p gv ap a shape graph g is bounded if no two abstract nodes have the same canonical name this means that the number of abstract nodes in a bounded shape graph is exponentially bounded by the number of abstraction predicates we define the abstraction function p store which maps a store s h into a bounded shape graph g as follows we use the function p to p which evaluates the predicates in p for each object and to n g which maps store objects having an equal canonical name to an abstract node representing their equivalence class in g the predicate assignment function assigns to abstract nodes the predicates common to all objects they represent and a field edge exists between two abstract nodes if there exist two objects represented by the abstract nodes that are related by that field p o ap p o ap p gn p o o st n n o o n n o hf o f o hf o f we say that a shape graph g subsumes a shape graph g written g g if there exists an onto function n g n g such that p gn p g n for all n n g and n n implies that n n eg f for all n n n g f the meaning of a shape graph g is given by the function p store defined as p g p g we say that two shape graphs g and g are congruent if there exists a bijection between their sets of abstract nodes n g n g which preserves the abstraction predicates p gn ap p g n ap for all n n g two congruent shape graphs g and g can be subsumed by a congruent shape graph g g g by corresponding predicate values and taking the union of corresponding edges using the stores to stack to to t f heap to × to to × to store stack × heap s h objects stacks heaps stores store notation semantics of path expressions path store to base case variables x sx x sx x inductive case p path p is known and e is a field or variable p e e ho e o p pe ho e op e e o to ho f p e f o to ho f p e f for an object o to and path p path we define op let y be fresh sy o h in meaning of intermediate variables the expression assigns to v the set of objects that are both on a path from x to q and in xp for x var v p q path v xp o to figure stores and semantics of path expressions g n g n g and g n g n g ng ng p g n p gn p g g n n n eg f gn gn or g n g n eg f we use partial join operator which merges congruent shape graphs into a single shape graph and keeps shape graphs in a set predicates meaning abstraction predicates xv x var x references v predicates pv hierarchy summarization x var p predicates table p predicates for hierarchy summarization abstraction g g def g g g and g are congruent g g else the abstraction of a set of stores p store is defined as p p hierarchy summarization abstraction our abstraction is defined relative to a set of abstraction paths denoted by which represent possible paths from variables to locked objects the next subsection discusses a technique to discover a set of useful abstraction paths for a set of data structures let s h be a store for a pointer variable x and an abstraction path p we define a unary predicate expressing the fact that v is a root object referenced by x and all objects reachable from it by the path p are locked pv def x v xp locks we encode hierarchy summarization abstraction via shape graphs and the set of predicates p shown in table and the ab paths in table since a pointer variable points to at most one node the number of abstract nodes in a bounded shape graph g is equal to at most the number of heap roots in the case where there exist objects the canonical names in such a shape graph are the sets of aliased pointer vari ables we call such sets aliasing configurations in practice the average number of different aliasing configurations discovered by our analysis is a small constant which means that the set of bounded shape graphs our analysis is linear in the number of program locations figure shows the result of applying p to the store in figure and the predicates in table heap roots are labeled with path expressions that denote the sets of objects that are reachable type graph node edge weight set iterator abstraction paths a lt nd all past at future table abstraction paths for the running example we omit java parameters when no confusion is likely from them and are definitely locked at l we would expect that node a its neighbors and the edges connecting a are locked this is specified by the path expressions labeling node a for example refer to all the neighbors of a additionally the current element that we are over is node c which is the of a this node has its single incoming edge and edge data locked all other nodes edges and weight objects are by our abstraction predicate discovery we now describe heuristics for generating the set of abstraction paths from the data structures in a program and show how it finds paths expressing the invariants described in section our technique constructs paths in three phases a building the type dependence graph b discovering paths in method specifications and c combining paths and all forward paths in the type dependence graph definition type dependence graph a type dependence graph for a program contains a type node nt for each program type t labeled by the set of program variables of that type and a field edge from type node nt to type node nt labeled by a field of type t or set t declared in type t figure shows the type dependence graph for figure for the rest of this section we fix the set of variables and fields and define the set of wellformed path expressions definition wellformed path expressions define the type node pair of a path expression element as follows nt nt for a variable x of type t nt nt for a field f of type t or set t declared in a type t and f nt nt for a field expression f if nt nt let p be a path expression ee ek and let the corresponding sequence of pairs be n n nk nk we say that p is wellformed if the sequence of n n nk nk is an path in the type dependence graph we define the pair of p to be n nk example whereas for and not is wellformed in the sequel we consider only wellformed path expressions we say that a path expression p contains a cycle if the corresponding path in the type dependence graph contains a cycle a forward path is a well formed path expression that contains no field subexpressions definition forward closure the forward closure of a path expression p written is the set of all path expressions of the form pp where p is a forward path not containing program variables pp is wellformed and p does not introduce cycles other than ones already contained in p the forward closure of a type t is the set of all forward paths starting from type t not containing program variables path closures of sets of path expressions and types are obtained by taking the union of the closures of all set members nd the forward closure of the types in the type dependence graph represent data access patterns where a sequence of method calls is used to obtain an object of type t from an object of a type t higher in the hierarchy for example in lines of figure a sequence of method calls is used to obtain an edge from the graph and a weight from an edge in particular the forward closure gives us the paths needed to express inv and inv however these paths ignore the effect of methods which create more paths such as the ones needed for inv and inv those are discovered by method specifications as explained next wl g iterator all node past at future set node cont node weight graph ns es a lt n node nd void edge src dst ed weight e an w figure type dependence graph for figure src edge dst n node node src cont set node dst edge ret figure footprint graph for a lock is shown next to each node labeled by locks discovering paths in method we now explain how to find paths which represent possible paths between objects referenced by the method parameters and returned value and objects accessed by the locks specification after the op specification executes to find these paths we construct a footprint graph for each method intuitively this graph represents the set of objects accessed by the method sometimes referred to as the footprint of the method the idea of footprint analysis was defined by calcagno et al to infer method preconditions and postconditions we put this idea to use for a different purpose we create a footprint graph by the following steps handling statements we interpret the statements in op in the order they appear for each statement we create a graph representing every path expression on the righthand side of an assignment this is done by creating a new node for each position in the expression connecting them by the respective fields and labeling nodes by the variables along the expression if the lefthand side of the assignment is a pointer or set variable locks we use it to label the last node of each path graph if it is a field of the type containing the method we create a node of that type labeled by this and connect an edge field from that node to the last node of every path graph created for the righthand side expression creating locks paths we create path graphs for all path expressions in locks that do not already appear in op merging we merge nodes labeled by a common pointer or set variable setting locks we label every node matching a path expression in locks by locks example figure shows the footprint graph for the method of graph the top node represents the outgoing edges of n the lower node represents the incoming edges type graph node edge weight paths src dst table paths for the running example denotes an arbitrary variable to an object of type t of n both are connected to some of n the node on the right represents the returned set containing the neighbors of n we use this graph to obtain paths expressing that has the effect of locking the immediate of n we define the function associating a set of paths with each program type we create a set of paths for every type node from all footprint graphs as follows for each footprint graph we take all the acyclic nonempty paths from a node labeled by a method parameter including this and the return parameter ret to any node labeled by locks we associate these paths with the type node corresponding to the type of the parameter we denote the set of paths of type t by table shows the paths that we get for the running example these paths enable us to express inv and inv we combine the sets of paths defined earlier to obtain the set of abstraction paths def here expressions of the form appearing in are substituted by the set of paths x var x is of type t putting it all together our overall static analysis consists of the following stages preprocessing we use a lightweight purity analysis to detect objects that do not require concurrency control and fields that are never used inside the parallel loop eg the and fields of weight the remainder of the analysis does not consider path expressions in locks containing unused fields and sets the opt flags of readonly objects to none shape analysis we execute a forward shape analysis using hierarchy summarization abstraction and abstract transformers the fixpoint is a set of bounded shape graphs at every program location finding redundant locks we use abstract operations in to conservatively check whether every shape graph at a program location represents stores that lock all objects defined by a locks specification of a method executing at that location if so we set the opt argument of that method call to if it was not already set to none finding points we perform a backward traversal over the cfg control flow graph to find program locations where all following method calls are labeled by none or meaning they do not acquire locks these program locations are the program points we set the predicates meaning abstraction predicates xv x var x references v pv x var p predicates table predicates for abstraction tion argument of all method calls dominated by points to none backward reachability abstraction a common abstraction idiom for shape abstraction uses coloring which records a set of unary with every object in the store these predicates are used to partition the set of objects into equivalence classes examples are canonical abstraction boolean heaps indexed predicate abstraction and generalized these abstractions typically employ backward reachability predicates that use paths in the heap to relate objects to variables for example most analyses and analyses using boolean heaps distinguish between disjoint data structure regions eg list segments and subtrees by using transitive reachability from pointer variables indexed predicate abstraction uses predicates that assert that cache clients are contained in one of two lists list and list lam et al use set containment predicates as the generalized typestate of an object we call such abstractions bottomup since they record properties of objects deep in the heap with respect to shallow root objects these abstractions achieve high precision as they express every boolean combination of intersection and union of objects satisfying the unary predicates however the size of an abstracted store can be exponential in the number of predicates which might lead to state space explosion in cases where objects satisfy many different subsets of predicates we define backward reachability abstraction by using the set of abstraction paths presented earlier to define backward reachability predicates for a pointer variable x and an abstraction path p we define a unary predicate expressing the fact that v is a locked object reachable from x by the path p pv def v locks xp we obtain a backward reachability abstraction p from the predicates shown in table is strictly more precise than however it can be very expensive the number of abstract nodes in a shape graph obtained by p can be exponential in the number of predicates state space explosion when stores create between different interacting sets set fields which is often the case in our programs applying p to the store in figure will all objects not locked and not referenced by a program variable compared to figure edge objects and for example will remain distinguished situations such as over the neighbors of a node exploring multiple simultaneously or sharing objects between multiple collections cause the number of useless to increase producing counterexamples when the code of a parallel loop body is not our analysis can sometimes provide a counterexample to demonstrate the violation of the property at appropriate program points to find such counterexamples we assume the small scope conjecture which says that counterexamples usually manifest in small graphs a nd lt nd nd ns g es src dst ed src dst ed cont figure a counterexample at location l for the implementation of a graph with three nodes and two edges is sufficient to provide us with a counterexample for the case of as shown in figure the region of the graph where the violation happens is this is the smallest counterexample found by our analysis taking about seconds to produce limitations we recognize the following limitations of our analysis hierarchy as discussed at the beginning of this section we assume a class of stores where a hierarchy property exists this allows us to ensure a bound on the number of hierarchy summarization paths used to define our abstraction this us from handling benchmarks where data structures such as lists and trees are explicitly manipulated and cannot be abstracted away by a rep specification generalizing our analysis to handle recursive data structures may be done by considering abstraction paths with regular expressions over the pointer fields of the data structure temporary violation of invariants our abstraction is to infer invariants of the form po where ro expresses a heap region by abstraction paths and po is a property we wish to summarize for the objects in the region ro the property in our analysis when the property p is violated for the objects in ro and then our analysis is not able to restore the invariant for example assume an invariant po holds at program point then a point a single object in ro referenced by a pointer variable x is made to have and at point it is removed from ro in order to the invariant po at point we may need to refine our abstraction in order to express an invariant such as po experimental evaluation the shape analysis described in section was implemented in and used to optimize four benchmarks from the suite these benchmarks were chosen because they exhibit very behavior we describe them below · algorithm this benchmark adds and removes nodes and edges from a graph · mesh refinement this benchmark uses iterative refinement to produce a quality mesh in each iteration a of a bad called the of that is removed from the mesh and replaced with new uses a large number of collections with patterns of data sharing so it is a test for the analysis · sp survey propagation a heuristic sat solver most iterations only update node labels but once in a while an iteration removes a node corresponding to a frozen variable and its edges prog sp ir size graph calls set calls field acc optimal table program characteristics and static analysis results xy measures analysis total abs nodes sp cfg location time sec table performance shape graph · algorithm this algorithm only updates labels of nodes and edges and does not modify the graph structure static analysis evaluation table reports the results of static analysis of our benchmarks we measure the size of benchmarks by the number of intermediate language instructions in the client program the code implementing the data structures by a specification columns to show the number of static optimization opportunities that our analysis enables galois objects eg the in using a variant of stm which can also benefit from our optimizations column refers to those objects in all cases our analysis was precise enough to identify the maximum number of sites that were for optimization and it discovered the minimal set of points the optimal result that we compare against was determined manually since our analysis is sound we need to consider only the relatively few calls where the analysis does not suggest conflict detection or rollback optimizations comparing analyses vs in table we compare our analysis using hierarchy summarization abstraction with an analysis using backward reachability abstraction the first column reports the total number of shape graphs sg explored by the analysis which is a measure for the amount of work performed we also report the average size of a shape graph the average number of per cfg location our analysis uses roughly cfg locations for a instruction at the fixed point and the running time of the analysis as expected generates a constant number of at each program location whereas in the number of increases as the benchmarks become more complex from for to for the benefits of are more as the complexity of the benchmark increases for generates roughly times more than per cfg location for in which the number of collections increases produces times more structures additionally we observe that in we have more refined and consequently larger for all benchmarks the average sg size in is roughly times larger than in these facts lead to a significant state space explosion which translates to increased work performed by for we see a fold increase in the number of generated and to increased running times thus is as precise as but more efficient experimental evaluation of optimizations this section provides detailed performance results for each benchmark to evaluate the performance obtained by different levels of of the analysis we considered the following variants for each benchmark · o version accesses within parallel loops to all objects are protected · o objects are not protected · o o dominated shared objects are not protected · o o duplicate lock and unnecessary operations are eliminated even in the version we do not protect object accesses made outside of parallel loops since the analysis required to enable this is trivial at level o objects are identified and accesses to them are not protected this optimization by itself can be accomplished by a combination of flowinsensitive pointsto and escape analysis optimization levels o and o target shared data for these levels a shape analysis similar to ours is necessary we performed our experiments using the galois runtime system and a sun x server running linux version the system contains two intel processors which share gb of main memory we used the sun bit server jvm version each variant was executed times in the same instance of the jvm we drop the first two iterations to account for the overheads of jit compilation and report results for the run with the running time because of the nondeterminism of iterators different executions of the same combination may perform different numbers of iterations since our optimizations focus on reducing the overhead of each iteration and not on controlling the total number of iterations we focus on a performance metric called which is the number of committed iterations per for completeness we also present other measurements such as the total running time the number of committed iterations the abort ratio etc table shows detailed results for all benchmarks algorithm we do not provide results for level o since the number of iteration private objects is the number of committed iterations is exactly the same across all thread counts this is a natural property of the algorithm since each committed iteration adds one edge to the the analysis is successful in reducing the number of locks per iteration and it correctly infers that the operator implementation is the algorithm takes roughly seconds to run if we use thread and optimization level o and seconds if we use threads and optimization level o at optimization level o no are and the number of acquired locks in each iteration is substantially reduced however overall speedup is limited by the high abort ratio for example for threads the abort ratio is between and for all levels of optimization the abort ratio decreases as the optimization level increases because if the time to execute an iteration is reduced the iteration holds its locks for a smaller amount of time reducing the of conflicts this high abort ratio is to the algorithm the is built bottomup so towards the end of the execution only the top few levels of the tree remain to be built and there is not much parallel work a implementation as we discussed in section removing the call to at l results in iterations our analysis successfully infers that the point along this program path moves from l to l the only difference in the inferred method flags is in l where the call to requires the flag instead of none this example shows the utility of our analysis for optimizing programs in which the operator implementation is not mesh refinement the number of committed iterations for this application is fairly stable across thread counts and optimization levels lock drop in going from o to o the analysis correctly that the operator implementation is which is why the number of per iteration to zero at optimization level o the number of per iteration is stable in going from o to o because the is constructed in private storage and then stored into the shared graph the abort ratio is very small even for threads the reductions in the average number of acquired locks and per iteration are reflected directly in the running time takes sec to run if we use thread and optimization level o and only sec if we use threads and optimization level o this is roughly a factor of improvement in the running time of which a factor of roughly comes from optimizations and a scaling factor of roughly comes from increasing the number of threads since the number of committed iterations is fairly stable across all optimization levels and thread counts the same improvement factors can also be seen in survey propagation the number of committed iterations is fairly stable for this benchmark the analysis is successful in reducing the number of locks per iteration the number of per iteration is fairly small even at optimization level o because the graph is only when a variable is frozen which happens in very few iterations the analysis correctly infers that the operator implementation is the sp algorithm takes roughly seconds to run if we use thread and optimization level o and seconds if we use threads and optimization level o most of this benefit comes from the optimizations at optimization level o we observe a speedup of roughly on threads we see a × improvement in for threads when the optimization level goes from o to o and by from o to o maximal flow a characteristic of is its schedule sensitivity because of nondeterminism different schedules can perform very different amounts of work this can be seen in the thread numbers at optimization level o the program executes twice as many iterations on threads as it does on a single thread the number of per iteration is for o since the graph structure is not by the algorithm the algorithm takes roughly seconds to run if we use thread and optimization level o and the best parallel time is seconds if we use threads and optimization level o this is a fold improvement of which roughly fold im th o o o sp o o o o o o o o o o o o lock committed iterations abort ratio running time sec table performance metrics input is a random graph of nodes and neighbors per node input is a random mesh with total bad sp input is a sat formula with variables and clauses input is a random graph of nodes and in the range comes from the optimizations and an improvement of roughly fold comes from exploiting parallelism summary of results our analysis eliminates all costs related to rollback for our benchmarks and reduces the number of lock by a factor ranging from × to × depending on the application and the number of threads these improvements translate to a improvement ranging from × up to × in the running time which is consistent across different thread counts and robust against of eg high abort ratio related work prior work on shape analysis has focused mostly on analyzing data structure implementations to infer heap structure in contrast we use data structure specifications to abstract away data structure representations and we focus on graphs the system verifies that a data structure implementation meets its specification and it uses the abstract state to simplify the verification of data structure clients our analysis assumes that a given specification is correct checking that the implementation and specification of the method semantics match and that the locks specification ensures that only methods can execute concurrently is an interesting challenge et al use specialized predicates to model sharing patterns between objects stored in data structures and use this information to statically benchmarks from the suite and benchmarks our benchmarks operate on graphs and are not amenable to static parallelization we exploit the fact that our execution model is speculative to avoid tracking between different data structures which increases the cost of the analysis considerably in the current galois system the optimizations described here are performed manually our shape analysis these optimizations reducing the burden on the programmer and ensuring correctness of optimized code points extend the notion of operators our running example shows that code too can be optimized by conflict detection and rollback off for a subset of the calls obtaining performance improvement similar to the version additionally in the system locking only after the point in contrast to our analysis which locking regardless of whether an operator is et al use value to reduce the critical path length in ordered algorithms their static analysis focuses mainly on array programs value is orthogonal to our approach and the benchmarks discussed in this paper do not benefit from value furthermore our heap abstractions are very different because we need to handle complex such as graphs et al et al and et al use compiler optimizations to reduce the overheads of transactional memory they also handle immutable and transaction local objects additionally they describe extending traditional compiler optimizations such as common subexpression elimination cse to reduce the overheads of although cse helps to reduce repeated for a single object its effectiveness for our benchmarks is limited by the extensive use of collections their approaches cannot capture global properties such as points other optimizations they propose are complementary to ours et al et al and et al describe analyses that infer locks for atomic sections these techniques are conservative for our benchmarks since they would always infer that an iteration might touch the whole graph acknowledgments we would like to thank the anonymous and berdine for their helpful comments references a b t lewis v b r b and t compiler and runtime support for efficient software transactional memory in pldi acm a m and r survey propagation an algorithm for satisfiability random structures and algorithms ­ c calcagno d p w ohearn and h yang footprint analysis a shape analysis that preconditions in sas s t and s gulwani inferring locks for atomic sections in pldi acm t c r and c editors introduction to algorithms mit press a y ni and a optimizing transactions for captured memory in d spanning trees and pages ­ i p w ohearn n and h yang abstraction for concurrent objects in esop t and k fraser language support for lightweight transactions in oopsla t l m a and d optimizing memory transactions in pldi acm m and e transactional a methodology for transactional objects in acm m and j b transactional memory support for lockfree data structures in m j s foster and p lock inference for atomic sections in june d software abstractions logic language and analysis the mit press m m c and k a suite of parallel programs in m p k g b k and l p scheduling strategies for optimistic parallel execution of programs in m k b g k and l p optimistic parallelism requires abstractions in pldi acm v and m c rinard decision procedures for fields notes theor comput sci v and m c rinard an overview of the analysis system project goals and current status in s k and r e predicate abstraction with indexed predicates acm trans comput log p lam v and m c rinard generalized typestate checking using set interfaces and analyses sigplan notices t and m sagiv a framework for implementing static analyses in sas r s sagiv g and j field partially disjunctive heap abstraction in sas m d d and m v identification of data dependence via explicit store heap models in pages ­ b f d and e autolocker synchronization inference for atomic sections in popl acm m d d x m a m m and k optimizations for programs in acm k m d m m d x and z in algorithms regular tech report tr the university of texas at austin a podelski and t boolean heaps in sas p g and k safe speculative parallelism in pldi d r k and k s a shape analysis for optimizing parallel graph programs technical report tr ut austin l and d a the test speculative runtime parallelization of loops with and reduction parallelization ieee trans parallel syst ­ m sagiv t reps and r parametric shape analysis via valued logic acm trans program lang syst a and m c rinard purity and side effect analysis for java programs in k v and m rinard full functional verification of linked data structures in acm 