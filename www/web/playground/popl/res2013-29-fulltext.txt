logical relations for finegrained concurrency university it university of copenhagen ahmed university birkedal it university of copenhagen dreyer germany abstract finegrained concurrent data structures or reduce the of critical sections in both time and space thus making it possible for clients to access different parts of a mutable data structure in parallel however the tradeoff is that the implementations of are very subtle and to reason about directly consequently they are carefully designed to be contextual refinements of their counterparts meaning that their clients can reason about them as if all access to them were in this paper we propose a new semantic model based on kripke logical relations that supports direct proofs of contextual refinement in the setting of a typesafe highlevel language the key idea behind our model is to provide a simple way of expressing the local life of individual pieces of an hidden state by means of protocols that the threads concurrently accessing that state must follow by these protocols with a simple yet powerful transition structure as well as the ability to assert invariants on both heap states and specification code we are able to support clean and intuitive refinement proofs for the most sophisticated types of such as conditional categories and subject descriptors d programming languages formal definitions and theory f logics and meanings of programs specifying and verifying and reasoning about programs keywords refinement finegrained concurrency linearizability separation logic logical relations data abstraction local state introduction suppose you want to take a sequential mutable data structure and adapt it to a concurrent setting so that multiple threads can safely access it in parallel the simplest way to do it is to treat all of the operations on the data structure as critical sections by a common lock this approach to concurrency is easy for clients to reason about since it essentially all access to the data structure but by the same token it also any speedup one might hope to gain from parallelism in contrast finegrained concurrent data structures or reduce the of critical sections in both time and space often down to a single primitive atomic instruction like cas so that clients can exploit parallelism by having different threads manipulate different parts of the data structure simultaneously permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm as are very to reason about directly they are carefully designed to be contextual refinements of their counterparts this means essentially that performance aside no client can tell they are working with the finegrained version of a data structure instead of the version put another way the is a faithful implementation of its specification thus clients can safely reason about the as if all access to it were while at the same time the efficiency benefits of parallelism contextual refinement is clearly an essential property that clients of an expect to hold the question is how to prove it in this paper we propose a new semantic model that supports direct proofs of contextual refinement in the setting of a typesafe highlevel language the key idea behind our model is to provide a simple way of expressing the protocols that the hidden state of an and that the threads concurrently accessing it must follow by these protocols with a simple yet powerful transition structure as well as the ability to assert invariants on both heap states and specification code we are able to support intuitive refinement proofs for the most sophisticated types of we now examine these points in more detail direct rather than prove contextual refinement directly most prior approaches have focused on proving a related property on traces called linearizability linearizability is often viewed as being with contextual refinement but in fact this has only recently been shown by et al to be the case and only for a particular class of languages as et al argue refinement is the property that clients of an actually want and linearizability is one technique for proving it we instead provide a direct proof technique for contextual refinement which any discussion of linearizability highlevel language most prior work has only considered coded in firstorder languages however one of the most libraries is written in a typesafe highlevel language java and indeed depends on the abstraction facilities of java to ensure that the private state of its is hidden from clients our approach is the first to prove contextual refinement for in the setting of a higherorder language with abstract types recursive types and general mutable references thus establishing the correctness of these when linked with unknown welltyped client code how to achieve these first two aims we employ a stepindexed kripke logical relations model have been developed in recent years as an effective tool for reasoning about representation independence for higherorder stateful and thus provide a foundation for reasoning about contextual refinement of concurrent objects in a realistic highlevel setting to adapt to reasoning about we follow the approach of recent work by birkedal et al and employ a model which accounts properly for the possibility that threads are after every step of computation birkedal et als model however is limited in its ability to reason about interference between threads which is in we therefore generalize their model with support for protocols protocols to understand how an works it helps to think of each piece of the data structure eg each node of a linked list as being subject to a protocol that tells its life how it to be allocated how its contents over time and how it eventually by being or deleted from the data structure this protocol describes the rules by which all threads must play as they access the shared state of the a number of additionally require their protocols to support is a mechanism by which different threads in the protocol can dynamically acquire certain roles these roles may enable them to make certain transitions that other threads cannot a simple example of this is a locking protocol under which the thread that acquires the lock the unique role of and thus knows that no other thread has the ability to release the lock how following recent work by dreyer et al in the setting of our model supports a direct encoding of protocols as state transition systems of a certain kind in comparison to dreyer et als work we at a much and use them to tell local life about individual nodes of a data structure of course there are also global constraints connecting up the life of the individual nodes but to a large extent we are able to reason about at the level of these local life and their local interactions with one another in order to account for we our with a notion of tokens intuitively the idea is that while the sts defines the basic for the possible changes to the state of the some of the on that map are that may only be traversed by threads certain tokens this idea is highly of recent work on concurrent abstract predicates but we believe our approach is simpler and more direct the most sophisticated types of in proving refinement for each operation of an a key step is identifying its linearization point the point during its execution at which the operation can be considered to have committed ie the point at which its spec can be viewed as having executed atomically what sets the most sophisticated apart from the pack and makes them so challenging to verify is that their linearization points are hard to identify in a threadlocal and way for example the elimination stack provides side channels by which a push and pop operation can mutually decide to each other out without the stack itself this works by having one operation say push use the side channel to offer its argument to be pushed if a thread running the pop operation this offer it can commit both the push and pop at once although it is very kind of the pop thread to with the push thread by it complete its operation in this way it also means that the linearization point for push occurs during the execution of pop thus making threadlocal verification difficult in other algorithms like the nondeterminism induced by concurrency has the effect that it is impossible to determine where the linearization point has occurred until after the finegrained operation has completed its execution this in turn makes it challenging to reason about refinement in a way ie showing that each step of the algorithm considered in isolation the protocol how the whole point of is to provide a way of describing local knowledge about the hidden resources of an abstract data type but in prior work those hidden resources have been with local variables or a private piece of the heap to support reasoning about thread and nondeterminism we make two orthogonal to the notion of resources first to model we extend resources to also include specification code this extension makes it possible for the right to commit an operation eg push in the example above to be treated as a resource which one thread may pass to other threads to run on its second to model nondeterminism we extend resources to include sets of specification states this extension makes it possible to about all the possible specification states that our implementation could be viewed as refining so that we can wait until the implementation has finished executing to decide which one we want to choose both of these extensions are formally and conceptually simple especially in comparison to prior approaches relying on ghost and variables and we will demonstrate their utility on both examples sections and and a more realistic example toward the end of the paper section the main ideas the language we study within a variant of the polymorphic lambda calculus extended with tagged sums general mutable references higherorder state types cas and fork these features suffice for modeling the kinds of used within which a are polymorphic b use recursive linked data structures and c rely on the abstraction facilities of the language for data hiding figure presents the syntax of the language together with of the static and dynamic semantics in examples we will employ a few other features that trivially extend the language defined here eg immutable pairs and records while the language is essentially standard there are a few aspects that help keep our treatment of concise terms are not annotated with types but polymorphism is nevertheless introduced and eliminated by explicit type abstraction e and application e reference and tuple types are combined into the type ref useful for constructing objects with many mutable fields the term ei reads and projects the ith component from a tuple reference e while ei e assigns a new value to that component when e is a reference we will usually write e e instead of e e finally the type ref of option references provides an union of the unit and reference types with explicit coercions null and because reading and writing operations work on references and not option references which must be separately eliminated by cases there are no errors the net effect of these types is fewer layers of indirection which simplifies verification the type system imposes two important restrictions first recursive types µ are required to be meaning that all free occurrences of in must appear under a type constructor more subtle is the restriction on cas which can only be used on components of comparable type this constraint is needed because cas performs an equality comparison of values at the hardware level it is only reasonable to apply it at types whose representation allows such a comparison ie base types and locations tagged sums are allocated on the heap and hence represented using locations making them comparable as well figure presents the nonstandard typing rules the remaining rules are standard see appendix note that we use u to denote values that can be stored in the heap a t is a finite map from thread identifiers to expressions a program configuration h t pairs a heap with a thread pool we define a smallstep callbyvalue operational semantics as a re we will use closures as our primary means of hiding local state b n ref ref µ b n ref ref µ e true false if e then e else e n e e x e e e e rec f xe new e ei ei e e e fork e null null e e e inj x e inj y e v rec f xe e n true false x u v v · x · k null e e k · · · t n fin exp h heap loc fin type rules e e ref i eo en e eo en b fork e e ref ref e e e e primitive reductions h e h e h i h vi when h v h cas i vo vn h i vn true when h i vo h cas i vo vn h false when h i vo h case null e e h e h case null e e h e x h new v h v h null h h v h v h e h e h some h program reduction h t h t h e h e h t i ke h t i ke h t i e h t i k j e figure our language f µ with fork and cas between program configurations allowing the creation of new threads and the nondeterministic interleaving of existing ones we use evaluation contexts k to specify a lefttoright evaluation order within each thread a look at the of a concurrent data structure is a measure of the locality of synchronization between threads accessing it data structures provide exclusive global access for the of a critical section a thread holding the lock can access as much of the data structure as needed secure in the knowledge that it will a consistent frozen representation by contrast finegrained data structures or eliminate synchronization forcing threads to do their work on the basis of limited knowledge about its as little as what the contents of a single word are at a single moment the local nature of is best understood by example in figure we give a variant of michael and lockfree queue the queue maintains a reference head to a nonempty linked list the first node of the list is considered a whose data does not contribute to the queue nodes are from the front of the list so we examine the code first if the queue is logically nonempty it contains at least two nodes the physical head and its successor logical we use the shorthand e e e head intuitively the operation should atomically update the head reference from the to its successor after doing so the old logical head becomes the new and the next node if any becomes the new logical head because there is no lock head however a concurrent operation could update it at any time thus optimistic concurrency after access to the by dereferencing head it does some additional work finding the logical assuming that head has not changed behind its back in the end meets through cas which performs an atomic update only when head is unchanged if its was must start from after all the queues state may have entirely changed in the the key thing to notice is just how little knowledge has as it executes immediately after reading head the most that can be said is that the resulting node was once the physical head of the queue the power of cas is that it head is now head becomes n the of cas is that this applies only to a single word of memory for this is in the lack of knowledge cas has about the new value n which should still be the successor to the physical head n at the instant of the cas because cas cannot check this fact it must be established ie guaranteed to be true on the basis of the queues internal protocol we will see in a moment how to formulate such a protocol but first we examine the more subtle enq in a queue implementation one would expect to have both head and tail pointers and indeed the full queue includes a tail pointer however because cas operates on only one word at a time it is impossible to use a single cas operation to both link in a new node and update a tail pointer the classic algorithm allows the tail pointer to behind the true tail by at most one node while the implementation in allows these choices affect performance of course but from a correctness one needs to make essentially the same argument whether one has a tail or simply traverses from head as we do in all of these cases it is necessary to find the actual tail of the list whose successor is null by doing some amount of traversal clearly this requires at least that the actual tail be reachable from the starting point of the traversal the loop invariant of the traversal is then that the tail is reachable from the current node but in our environment we must account for the fact that the data structure is changing under even as we traverse it the node that was the tail of the list when we the traversal might not even be in the data structure by the time we finish the of a node we want ultimately to prove that refines its specification the latter uses a lock to protect its internal state e is a simple derived form that of the e around the code e the proof would proceed in the same way ones intuitive reasoning does ie by considering the execution of a single function by a single thread one line at a time reasoning about what is known at each program point to achieve this goal we must solve two problems we must characterize the possible interference from concurrent threads and we must characterize the knowledge that our thread can gain we solve both of these problems by introducing a notion of protocol based on the abstract state transition systems of dreyer et al but with an important we apply these transition systems at the level of individual nodes rather than as a description the definition of sync is given in the appendix enq ref let head new new null null in rec try let n head in case n of if n n then n else try null null queue is empty enq x let n x null in let rec case c of null if null n then else in let head new null lock new false in case head of head n n null null enq x protocol logically in queue v null null reachable global interpretation is i i v vi vs heads s vs lock s false vs sl s i i i vi i when s vi sl i i null emp link i s i vi s v vs vs v v vs vi i v i i vi vi s i vs vs vs s figure a variant of michael and queue of the entire data structure these transition systems describe what we call the local life of each piece of an the diagram in figure is just such a every heap location can be seen as a potential node in the queue but all but finitely many are state after nodes go through a of life changes some changes are the transition from null to for example occurs when the successor field of the node is updated to link in a new node other changes reflect relationships the transition from live to for example does not represent an internal change to the node but rather a change in the nodes position in the data structure finally a node when it becomes unreachable the benefit of these life is that they account for knowledge and interference together in a local and abstract way knowledge is expressed by that a given node is at least at a certain point in its life this kind of knowledge is inherently stable under interference because all code must to the protocol and is therefore constrained to a forward march through the sts the life together in one place all the knowledge and interference that is relevant to a given node even knowledge like reachability which is a global property this allows us to draw global conclusions from local information which is precisely what is needed when reasoning about for example notice that no node can with a null successor field a successful cas on the successor field from null to some the one performed in that the successor field was null local information which by the protocol means the node was reachable global information which entails that the cas makes a new node reachable similarly the protocol makes it immediately clear that the queue is free from any problems because nodes cannot be and their fields once nonnull never change to formalize this reasoning we must connect the abstract account of knowledge and interference provided by the protocol to concrete constraints on the queues representation we do this by giving a invariant i for the data structure where state refers to abstract sts states for the queue we have the following set of states for each nodes local sts s v v v val v v v val v val loc along with the transition relation given in the diagram where the annotated edges denote branches for choosing particular concrete v and values the data structure as a whole is by a product sts with states s loc fin s where fin indicates that all but finitely many locations are in the state in their local sts the transition relation for the product sts is just the pointwise lifting of the one for each nodes sts s s iff s s thus at the abstract level the product sts is simply a collection of independent local at the concrete level of the invariant i however we record the constraints that tie one nodes life to see figure the invariant is essentially a relational version of the recursive list predicate from separation logic the relational nature is apparent in the fact that the invariant makes assertions about both the implementation i and specification s heap out the portion of each corresponding to an instance of and respectively it is thus a kind of linking invariant or refinement map as one would expect to find in any refinement proof at a high level the invariant says the state of the product sts must decompose into exactly one node at location a collection of live nodes sl and a collection of dead nodes at locations i the notation represents a list the link assertion recursively asserts that each live node in the implementation corresponds to some node in the specification and that a node is live iff it is reachable from the since the queue is parametric over the type of its data the data stored in each live implementation node must refine the data stored in the specification node at type written v v v see section the invariant also accounts for two representation differences between and first the node data in the implementation is stored in a ref while the specification stores the data directly second the specification has a lock the invariant requires that the lock is always free false because as we show that refines we always run entire critical sections of at once going from state to state these big steps of the correspond to the linearization points of the nodes must have nonnull successor pointers whose locations are in a non state this property is the key for giving a simple local loop invariant for enq namely that the current node c is at least in a live state it follows that if the successor pointer of c is not null it must be another node at least in the live state if on the other hand the successor node of c is null we know that c is both not dead and at least live which means that c must be at that instant reachable from the implementations head pointer the proof for and the other examples in this section are given in the appendix and tokens although michael and queue is already to verify there is a specific sense in which its protocol in figure is simple it treats all threads equally all threads see a level field with a single notion of legal transition and any thread is free to make any legal transition according to the protocol many however require more refined protocols in which different threads can play different them the to make different sets of in which threads can acquire and release these roles dynamically as they execute in fact one need not look to complex for instances of this dynamic simple lock used in the spec of the queue is a perfect and canonical example in a protocol a single lock eg lock in there are two states and locked starting from the state all threads should be able to acquire the lock and transition to the locked state but not vice versa once a thread has acquired the lock and moved to the locked state it has adopted the role of and should know that it is the only thread with the right to release the lock and return to to support this kind of we with a notion of tokens which are used to grant authority over certain types of actions in a protocol each sts may employ its own appropriately chosen set of tokens and each thread may own some subset of these tokens the idea then is that certain transitions are only legal for the thread that certain tokens formally speaking this is achieved by associating with each state in the sts a set of tokens that are currently free ie not owned by any thread we then the law of of tokens for a thread to transition from state s to state s the disjoint union of its private tokens and the free tokens must be the same in s and in s for instance in the locking protocol there is just a single it in the state the sts asserts that must belong to the free tokens and thus that no thread it whereas in the locked state the sts asserts that does not belong to the free tokens and thus that some thread it · denotes that is in the free tokens and denotes that it is not · locked when a thread acquires the physical lock and transitions to the locked state it must add to its private tokens in order to satisfy of tokens no other thread may transition back to because doing so requires putting back into the free tokens of the sts which is something only the private owner of can do usually the invariant for the state all of the hidden state for the data structure while the locked invariant nothing thus a thread taking the lock also acquires the resources it but must return these resources on lock release in the style of csl as this simple example suggests tokens induce very natural notions of rely and guarantee relations on states of an sts for any thread i the total tokens a of an sts must equal the disjoint union of is private tokens ai the free tokens in the current state s and the frame tokens ie the combined private tokens of all other threads but i the guarantee relation says which future states thread i may transition to namely those that are accessible by a series of transitions that i can pay for using its private tokens ai the rely relation says which future states other threads may transition to namely those that are accessible by another perspective is that the free tokens are owned by the sts itself as opposed to the threads in the protocol cf csl let flag new true chan new in flip rec try if then else if true false then else if false true then else if then if then try else chan else try read flag let flag new true lock new false in flip flag not flag read flag j k k empty · k q x b i x flags s x lock s false i empty q chan i k q chan i j s k q chan i j s k figure red flags versus blue flags a series of transitions that can be for without using is private tokens ai ie only using the tokens in these two relations play a central role in our model section and as explained in the introduction some use side channels separate from the main data structure to enable threads executing different operations to to illustrate this we use a specifically by elimination stacks that the essential challenge of reasoning about the of a real data structure figure shows the example in which is a lockfree implementation of the latter is a very simple data structure which maintains a hidden boolean flag and provides operations to flip it and read it one obvious lockfree implementation of flip would be to keep running true false and false true repeatedly until one of them succeeds however to demonstrate does something more in addition to maintaining flag it also maintains a side channel chan which it uses to enable two flip operations to each other out without ever modifying flag at all more specifically chan to the following protocol which is in figure ignore the ks for now if chan i it means the side channel is not currently being used it is in the empty state if chan i it means that some thread j has to perform a flip using the side channel and moved it into the state if chan i it means that another thread has accepted thread js offer and to thus performing both at once since they that thread j has not yet that its offer was accepted like the locking example this protocol uses a single it is free in state empty but which thread j moves into its private tokens when it transitions to the state after that transition due to its ownership of offer thread j is the only thread that has the right to that offer by setting chan back to and returning to empty on the other hand any thread may transition from to since the two states have identical free tokens namely none once in the state though thread j is again the only thread able to empty the channel the implementation of flip in then works as follows first we use cas to check if another thread has to flip ie if chan i and if so we accept the offer by setting chan to we then immediately return having implicitly committed both right then and there without ever accessing flag if that fails we give up on the and instead try to perform a flip by doing true false and false true as suggested above if that fails as well then we attempt to make an offer on the side channel by changing chan from to if our attempt succeeds then we rather try to immediately the offer and loop back to the beginning if another thread has us at this point and accepted our offer ie if fails that another thread has updated chan to then that other thread must have already committed our flip on our so we simply set chan back to thus making the side channel free for other threads to use and return finally if all else fails we loop again as far as the refinement proof is concerned there are essentially two interesting points here the first concerns the step as we observed already the failure of this cas implies that chan must be why because of the way our protocol uses tokens after the previous we that we had successfully to the state and thus that our thread j now the offer token our ownership of offer tells us that other threads can only transition to a limited set of states via the rely ordering ie without offer they can either leave the state where it is or they can transition to thus when we observe that chan is not we know it must be the second more interesting point concerns the semantics of if we make an offer on chan which is accepted by another thread it should imply that the other thread performed our flip for us so we dont have to at least the intuition but how is that intuition enforced by the protocol that is when we observe that our offer has been accepted we do so merely by the current value of chan but how do we know that the other thread that updated chan from to actually performed our flip for us for example as as this what is to prevent from performing chan as part of its implementation of read our key to enforcing that the semantics of is is to treat specification code as a kind of resource we introduce a new assertion j s e which describes the knowledge that thread j on the spec side is to run the term e this knowledge is kept private to thread j itself but in a protocol the whole idea is that j should be able to pass control over its spec code e to other threads so that they may execute some steps of e on its specifically this assertion is used to give semantic meaning to the k and k states in our protocol see the interpretation of f in figure in the former state we know that j s which tells us that thread j has its spec code to be run by another thread whereas in the latter state we know that j s k which tells us that js flip has been executed the k is present here only because we do not want to place any restrictions on the evaluation context of the flip operation these interpretations demand that whatever thread accepts the offer by from k to k must take the not only of updating chan to but also of executing only js when j subsequently moves back to the empty state it at this point in a real implementation it would make sense to wait a while for other threads to accept our offer but we that detail since it is irrelevant for reasoning about correctness rand let y new false in fork y true y x x rand x let r rand in x r xi v xs j s xi xi v xs j s j s rand ret ret true ret false j s j s ret j s figure late choice versus early choice private control over its specification code so that other threads may no longer execute it nondeterminism and another aspect of reasoning about like the conditional cas example we consider in section is dealing with nondeterminism the problem is that when proving that an refines some spec we want to reason in a using something to a simulation argument by which the behavior of each step of code is matched against zero or more steps of spec nondeterminism it would seem this plan to see why consider the late choice example in figure this example is really simple it does not maintain any hidden state hence no protocol and is not in fact an at all but it nevertheless illustrates the core difficulty with nondeterminism we want to show that refines both functions flip a ie use rand to nondeterministically choose a boolean value and set a given variable x to but they do so in opposite orders intuitively though the order matter there is no way to observe the flip until the functions return however if we try to reason about the refinement using a simulation argument we run into a problem the first step of is the setting of x to to simulate this step in we need to match the assignment of x to as well since the update is an observable effect but to do that we must first flip while we have the freedom to choose the outcome of the flip the is that we dont know what the outcome should be flip has yet to be executed the solution is simple that is if you dont know which spec states to step to in order to match an implementation step then keep your open and maintain a speculative set of specification states that are reachable from the initial spec state and consistent with any observable effects of the implementation step in the case of this means that we can simulate the first step of the setting of x to by executing the entire function twice in both speculative states x is set to but in one the flip returns true and in the other it returns false this reasoning is captured in the proof outline given in figure the precondition j s instance of the assertions on specification code introduced in the previous that initially the spec side is to execute after we execute x in we that the flip on the spec side could result in either returning true or returning false this is represented by the speculative assertion j s j s appearing in the postcondition of this first step in which the operator provides a speculative choice between two characterizing possible spec states in the subsequent step its for every implementation execution we must construct some specification execution yielding a return value ret of either true or false we can then refine the speculative set of specification states to one either j s or j s matches ret and simply drop the other state from consideration in the end what is that we are left with at least one spec state that has been produced by a sequence of steps matching the observable behavior of the implementations steps the idea of is not new it is implicit in and notion of simulation what is new here is that we capture without using variables which allows us to compose without for example we can use speculative reasoning in a private threadlocal way as in the choice example while separately using it within the protocol some shared state as in the example section we give a more detailed comparison to related work in section the formal model in this section we develop the syntax and semantics of a logic for concurrent programs in our higherorder polymorphic language we leave a proof theory for future work and instead work in the model semantically when verifying examples overview proving refinement via hiding and protocols our logic is ultimately used to prove contextual refinements so it is important to first make clear what that entails both formally and practically to define contextual refinement we first introduce a standard typing judgment for contexts c so that whenever e we have ce then if ei and es we say ei contextually refines es written ei es if for every i j and c n we have i h i n ti ts j h j n ts refinement formalizes observable behavior as anything a client of an expression could test a context c captures the notion of an unknown but welltyped client which can interact arbitrarily with the two expressions if ei behaves in a way that its spec es does not it should be possible to find a context c whose main thread returns a number with ei that with es it does not the only practical way to prove refinement is to find some other more structured way of characterizing observable that does not require detailed reasoning about particular contexts in a highlevel language hide their internal state within the functions they export their methods thereby greatly limiting the scope of interaction they have with their clients in particular a client context can neither observe nor alter the internal state directly all interactions are by the methods from the perspective of an then the behavior of a client can be reduced to a collection of method invocations and from the perspective of a client the behavior of an can be reduced to the answers it returns from those invocations how can we prove that an arbitrary collection of concurrent method calls to an will yield the same answers as its spec protocols are the key they capture the effect methods can have on the internal thereby the effect they have on each other abstractly ie without reference to code protocols enable us to reason locally about one method invocation at a time instead of considering an arbitrary sequence of prior method invocations we simply start from an arbitrary protocol state and instead of considering arbitrary concurrent invocations we simply force our local reasoning to arbitrary rely moves in a protocol p v v emp v i u v s u i s e p p p p p p p p xp xp p p p t m x p p e x q v v v e e e i s a where i s assert s s a a af s s a f where s a sets s × s f s a m i none figure syntax of assertions assertions in program logics for firstorder languages there is a strict separation between assertions about data eg heap assertions and assertions about code eg hoare triples but the distinction makes less sense for higherorder languages where code is data and hence claims about data must include claims about code our logic is therefore built around a single notion of assertion p shown in figure that plays several roles assertions are best understood one role at a time the first role they play is similar to that of heap assertions in separation logic they capture knowledge about a part of the implementations heap eg x i and support the composition of such knowledge eg x i y i in this assertions make claims on the current state which may be in a later state on the other hand some assertions are pure meaning that if they hold in a given state they will hold in any possible future state the syntactic subclass of code assertions all have this property and they include hoare triples p e x q the hoare triple says for any future state satisfying p if the implementation expression e is executed until it terminates with a result the final state will satisfy q where x is the value e returned so for example emp new x x i is a valid assertion ie it holds in any state more generally the usual rules of separation logic apply including the frame rule the rule of sequencing the sequencing rule works even in our concurrent setting because heap assertions describe a portion of heap that is owned by the expression in the hoare triple in particular that portion of the heap is guaranteed to be neither observed nor by threads concurrent with the expression the next role assertions play is expressing knowledge about shared resources all shared resources are by a protocol for hidden state the protocol can be chosen freely modulo proving that exported methods actually follow it for visible state however eg a reference that is returned directly to the context the protocol is forced to be a trivial one that allows the state to take on any welltyped value at any time for the arbitrary interference an unknown context could cause see section claims about shared resources are made through island assertions inspired by which first of all assert the existence of said resources we call each shared collection of resources an island because each collection is disjoint from the others and is by an independent protocol an island assertion gives the protocol its resources · the component s a f formalizes the sts for the protocol where s is its set of states a is its set of possible tokens is its transition relation and f is a function which tokens are free at each state we will use dot notation like s to project named components from compound objects · the component i tells how each state of the sts is interpreted as an assertion characterizing the concrete hidden resources that are actually owned by the island in that state domains resource heap × finite nonempty heap × j s a w k sts s s a a af s j s resource k n n fin u u u v val × val island and world operations j s a j s k k ii frame j s a j s a f s a k j s a k k sis s a k i i k interp j s a js composition state sets resources h h islands j s a j s a worlds k k h h t t hi ti i when all compositions are defined h h j s a a when s s j j k ii i when k k dom dom protocol s a s a j s a j s a s s f s a f s a j j s a s a k k rely ww k k i dom i k i world satisfaction w wk i i i w figure semantic structures and operations on them in addition island assertions express knowledge about the state of the protocol the component s and any tokens the component a this last bit of knowledge gives a lower bound on the actual state of the protocol which may in fact by in any state of s ie any state that can be reached from s by the environment without using the tokens a finally assertions play two roles the first is to express refinement itself either between two closed values vi v vs or between open expressions ei e es the syntactic counterpart to semantic refinement section until this point we have avoided saying anything about spec terms but in order to prove refinement we need to show that the observable behavior of an implementation can be by its spec this us to an essential idea ei e es roughly j j s es ei xi xs xi v xs j s xs by treating spec code as a resource we can reduce refinement reasoning to reasoning thus the final role assertions play is to express knowledge ownership resources which include portions both of the heap eg x s and of the eg j s es these resources can be shared and hence by protocols just as resources can when proving refinement for an we will prove something like the above hoare triple for an arbitrary application of each of its in the scope of an island assertion giving the protocol for its shared hidden state for each method invocation we start from an arbitrary state of that protocol and are given ownership of the spec code corresponding to the invocation which we may choose to transfer to the protocol to support as explained in section but in the end when the implementations invocation has finished and returned a value xi we must have exclusive control over its spec which must have it by producing a value xs that xi refines the remaining forms of assertions include standard logical connectives and two more technical forms of assertions p and t m x p which we explain in the section semantic structures the semantics of assertions is given using two judgments one for general assertions w p and the other for code assertions u where p and contain no free term variables but may contain free type variables bound by to explain these judgments we begin with the semantic structures of worlds w resources and environments together with operations on them needed to interpret defined in figure resources the resources h that assertions claim knowledge about and ownership of include both implementation heaps h and speculative sets of spec configurations recall that a configuration h t consists of a heap and a resources can be combined at every level which is necessary for interpreting the operator on assertions for heaps and composition is done via the usual disjoint union the composition of state sets is just the set of state it is only defined when all such state compositions are defined so that speculative sets have a single footprint consisting of all the existing in any speculative state to ensure that this footprint is finite we require that is itself finite finally composition of resources is the composition of their parts islands and possible worlds all assertions are interpreted in the context of some possible world w which contains a collection of is the kripke in kripke logical relations semantic islands look very much like syntactic island assertions the only difference is that sts states are interpreted semantically via j rather than syntactically via i unfortunately this creates a circularity j is meant to interpret its syntactic counterpart i and since assertions are interpreted in the contexts of worlds the interpretation must be relative to the current we are in the middle of defining worlds the step index k in worlds is used to away in the definition of worlds and the logical relation it and its operators and k are completely standard and so for space reasons we direct the interested reader to earlier work for a detailed explanation the less interested reader should simply ignore step indices from here on there is one additional however it is crucial that all participants in a protocol agree on the protocols interpretation of a state which must therefore be to which tokens a particular participant we guarantee this by giving the interpretation j access to only the part of a participants world w which has been of any tokens see the constraint on the type of j to determine the meaning of assertions like we must allow islands to be composed semantic island composition is defined only when the islands agree on all aspects of the protocol including its state their owned tokens are then combined note however that because island assertions are an assertion like does not require and to assert the same state it merely requires that there is some state that is in both of their worlds are composable only when they define the same islands and those islands are composable environments type variables are interpreted by an environment that maps them to relations v this interpretation of types captures the usual relational parametricity in which the interpretation of an abstract type may relate values of potentially different types on the the implementation and specification sides protocol the judgment s a s a the law of of tokens section for a single step we use this judgment in defining a guarantee relation the changes an expression can make to an islands state given the tokens it an expression can likewise rely on its environment to only change the island according to the tokens that the environment ie the tokens owned by frame the rely and guarantee views of a protocol give rise to two notions of future worlds in both cases the world may grow to include new islands but any existing islands are constrained by their rely and guarantee relations respectively the guarantee relation on islands may include changes to both the state of the sts and the tokens the rely relation only allows the state to change since only the implicit participant making the move may gain or lose tokens island interpretations j are required to be monotone with respect to the rely relation on worlds written which ensures that making a rely move in one island cannot possibly the interpretation of another world satisfaction worlds describe shared state abstractly in terms of protocol states expressions on the other hand are executed against some concrete resources the world satisfaction relation w defines when a given collection of concrete resources satisfies a world meaning that it breaks into a disjoint portion for each island with each portion satisfying its islands current interpretation the parameter represents additional resources that are private and therefore disjoint from those by the world which is convenient for defining the semantics of assertions below semantics the semantics of assertions given in figure satisfies a fundamental rely property if w p and w w then w p all assertions are therefore stable under arbitrary interference from other threads this should not be a assertions are either statements about private resources for which interference is impossible or about shared islands for which interference is assumed eg we are careful to only assert lower bounds on the state of an island the only is in the semantics of implication which must be explicitly to ensure stability the semantics of the basic assertions about private resources and we use the more readable notation s s in place of s s islands are entirely straightforward as are those for the basic logical connectives we omit and the value refinement assertion v v v requires that any observations a context can make of v at type can also be made of v those readers familiar with kripke logical relations will recognize it as essentially the standard definition of logical approximation between values base type values must be identical for function types we check that the bodies of the functions are related when given related arguments which due to the semantics of implication might happen in a world for recursive types we check that the values are related at the type which is wellfounded due to the requirement on recursive types and our uses of in type constructors values that are exposed to the context at and sum types are forced to be by a trivial island allowing all typesafe updates in the case of and no updates in the case of sums hidden state on the other hand is by definition state that does not escape directly to the context and so we need say nothing about it for value refinement the fact that refinement is a pure assertion to the state of private resources or the ownership of private tokens is essential for soundness for a simple reason once a value has reached the context it can be copied and used concurrently we therefore cannot claim that any one copy of the value some resources note that if p is impure we use u p as shorthand for u p for expression refinement e e e we first close off any term or type variables bound by with the appropriate universal quantification closed expression refinement is defined in terms of a hoare triple almost in the way we suggested in section the main difference in the actual definition is that we additionally quantify over the unknown evaluation context k in which a specification is running this appears to be necessary for proving that refinement is a hoare triples are defined via the simulation assertion t m x p which is the engine that our model simulation accounts for the fact that an expression can fork threads as it executes but that we care about the return value only from the initial thread m to satisfy t m x p at some w and the threads in t must first of all the protocols of w given private ownership of that is every atomic step taken by a thread must transform its shared resources in a way that corresponds to a guarantee move in the protocol and it must preserve as a frame any private resources of its environment but it may change private resources in any way it in between each such atomic step the context might get a to run which we model by over an arbitrary world if at any point the main thread m terminates it must do so in a state satisfying p where x is bound to the value the main thread returned any threads are still required to the protocol that simulation is in fact a simulation is due to its use of the speculative relation which requires any changes to the spec state to represent feasible execution steps every new state must be reachable from some old state but we are free to introduce multiple new states in the same old state and we are free to drop irrelevant old states on the as a result of how simulation is defined such changes to the spec state can only be made to those pieces that are under the control either as part of its private resources allowing arbitrary feasible updates or its shared ones allowing only updates soundness for refinement our key theorem is theorem soundness if u e e e for all u then e e private and assertions w r iff r emp v i u v s u i se p q p q xp p p p p p i s a requirements w w w v u v u i e w p and w q rely w w w p w q v w p vx wk w p w w w wi i pi w h i pi rely i w wk i i s a where i su u is value refinement u v v v iff b µ ref ref requirements v v vi b for b b n v v u vi rec f u x e vi ei u e e e u v v v µ u v v v v v v ref u y x v y v i x v s y i u x y x v y i i x v s y expression refinement u e e e iff · x requirements k j u j s ke e x y x v y j s v v u v v v e v u v e e e hoare triples u p e x q i u p i ei x q invariant protocols spec p simulation rely w t m x q w w f if wk and h w f then if h t h t then w w h w f w k wk if t t m v then w w h w f w k wk w t m x q w x tt figure the semantics of assertions the proof of this theorem given in the appendix is built on novel lemmas expressing key properties for the simulation assertion the most important being lemma if w tm x q and w tm x q with m none or m then w w t tm x q these lemmas allow us to prove that refinement assertions are congruent ie they compose which is the difficult part of soundness we can also derive the following inference rules for valid pure assertions true at every world p e x p x p e y p p let x e in e y p p e x q p r e x q r p p p e x q q q p p p e x q p the first three of these inference rules are the expected ones for a separation logic our assertions also model intuitionistic bi the last rule is the rule which allows us to reason about recursive functions by assuming their specification holds one step later in giving proof in the next section we make implicit use of these rules and also drop the variable binding in the postcondition when it is irrelevant case study conditional cas with the details of our model in hand we are now in a position to in detail a rather complex et als conditional cas which performs a on one word of memory but only succeeds when some other word the control flag is nonzero at the same instant this data structure is the that enables et al to build their lockfree cas from cas as with the queue we have down conditional cas to its essence its key verification challenges while removing detail thus we study lockfree conditional increment on a counter with a fixed control flag per instance of the counter see the specification counters in figure these simplifications eliminate the need to track information about the operation we are trying to perform but do not change the algorithm itself so our proof of conditional increment to full is a straightforward exercise the protocol to explain our implementation we begin with its representation and the protocol that it the control flag f is represented using a simple boolean reference all of the action is in the counter c which has type n a value inj n represents an counter with logical value n a value inj n in contrast means that the counter is a conditional increment and had the logical value n when the increment because inj n records the original value a concurrent thread another operation on the data structure can help finish the increment this is actually not so really one thread is just another thread get out of its way the question is how to perform a conditional increment without using any locks the algorithm simply reads the flag f and a separate the counter c with a cas see the complete function it is possible therefore for one thread performing a conditional increment to read f as true at which point another thread sets f to false the original thread then proceeds with the counter even though the control flag is false proving that refines counters despite this race counters let c new f new false lock new false let f b let get c let c c if f then else in get let c new inj f new false let f b let n if f then x inj n else x inj n let rec get let x c in case x of inj n n inj n n get let rec let x c in case x of inj n let y inj n in if x y then n else inj n n in get · d · n · dead · d n j k b a loc s loc fin s s b dead is b b fi i b fs s b lock s false c s const upd c n j k b s c j k b c n s c s i inj n j s k s i inj s dead i inj c n ci i c c i inj n cs s n c n j k b ci i c c i inj n cs s n j s cs s n j s k if b cs s n j s k if b figure conditional increment a simplification of condition will require all the features of our model working in an initial idea is that when the physical value of the counter is inj n its logical value is ambiguous it is either n or n this idea will only work if we can associate such logical values with feasible executions of the code since logical value really means the value the difficulty is in choosing when to take spec steps if we wait to execute the spec code until a successful cas in complete we may be too late as the interleaving above shows the flag may have changed by then but we cannot execute the spec when we read the flag either the cas that follows it may fail in which case some other thread must have executed the spec the way out of this is for threads to interact via a speculative protocol shown in figure recall that into sum types are so every value c takes on has let n x j k if f then x j k x inj n x j k else x j k x inj n x j k let rec let x c in j s i j s x const x upd case x of inj n let y inj n in if x y then n else j s x j s x y inj n x y · j k y · j k y · j k ret ret j s k y ret ret j s k j s i ret ret j s k inj n j s x n j s x j s i ret ret j s k figure proof outline for conditional increment an identity its location the protocol gives the life for every possible location in the heap as a potential value of c with the usual constraint that all but finitely many locations are in the state the first step of the protocol reflects the choice latent in the sum type either this location is a inj n represented initially by or an active increment operation inj n represented initially by the logical descriptor d gives the old value n of the counter together with the thread id j and specification evaluation context of the thread the increment the latter information is necessary because thread j its spec to the protocol threads to execute the spec on its following the pattern out in section in return for its spec thread j receives a it will later permit it and only it to recover its spec as usual we the token with a the life for a inj n is quite either it is the current value pointed to by c or it is dead an active cell inj n leads a much more life in the first phase of life b the cell records which branches b of the complete code have been entered by a thread initially no thread has executed complete so the set is empty if a thread subsequently reads that f true in the first step of executing complete it moves to the set since it is now committed to the branch that adds to the initial value n this step coincides with a speculative run of the specification the spec is also in case some other thread commits to the branch the process continues until some thread perhaps not the original of the increment actually succeeds in performing its cas in complete at that point the increment is done and its inj n cell is effectively dead but not yet in the end the thread that the original increment its spec whose execution is guaranteed to be finished the proof we now formally justify that refines counters by giving a concrete interpretation to the protocol and providing a proof outline for complete and the outline for get is then a straightforward exercise to formalize the protocol we first give the set of states s for an individual life see figure the states s for the data structure are then a product of individual sts states indexed by location with all but finitely many locations required to be in state the set of tokens a for the product sts is just the set of locations ie there is one token per location and hence per individual life the transition relation on the product sts the one for individual life s s s s s s if f is the function for an individual sts we can then define the product sts as follows s a s fs attempt the interpretation i for states of the product sts given in figure is fairly straightforward the implementation and specification flag values must always match there must exist a unique location c c in a live state of const or upd this unique live location will be the one currently pointed to by c in the upd state it also speculative spec resources according to the branch set b finally done nodes retain a finished spec while dead and nodes are simply garbage inj and inj nodes respectively to show the refinement e counters where n × b × it suffices to show the following hoare triple for every j k j s zi zs zi v zs j s the execution of is short and simple it allocates the hidden state of the data structure and then immediately returns three procedures for manipulating that state in the proof of the triple after the hidden state is allocated we construct an island to it and add the island to the world a guarantee extension the new island is described by the assertion i const which says that it follows the conditional increment protocol and i is in some state of const in which every location other than is and currently no tokens adding this island requires us to show that the initial values of the hidden state in the implementation and specification satisfy the invariant at this state which they clearly do we must then show in the context of this extended world that each of the implementation procedures refines the corresponding specification procedure we give the detailed proof for ie j s i ret ret j s k in the precondition we weaken our knowledge about the island to simply saying that it is in a state of where every location maps to since this is all we need to know the locality of the local life is in our ability to make isolated abstract assertions about a particular location by the data structure because every location is in some state of we can focus on a location x of interest by that the product sts is in a state of x s where s s for readability we employ the following shorthand for making such local assertions about the island x s i x s x · s i x s x thus we can some additional insight about the algorithm that the complete function satisfies the triple x j k n ret x j k in reading this triple it is crucial to remember that assertions are closed under rely x j k means that the location x was once a live update the interesting thing about the triple is that regardless of the exact initial state of x on exit we know that x is at least no going back the proof outline for complete at the top of figure states that after reading the value of the flag the location x is in an appropriately speculative state to prove that fact we must consider the states of j k and show that for each such state we can reach via a guarantee move a state of j k or j k depending on the value read for example if the initial state is s and we read that the flag is true we take a guarantee move to s as follows if s is then s is if s is then s is if the initial state already included the needed or was done or there is nothing to show otherwise changing the state requires speculative execution of the spec we perform a similar case analysis at the cas step but there we start with the knowledge that the appropriate has already been is exactly what we need if the cas succeeds if on the other hand the cas fails it must be the case that x is at least done if it were still in an upd state the cas would have with complete out of the way the proof of is relatively easy see the bottom of figure when entering the procedure all that is known is that the island exists and that the specification is owned the thread first c to see if the counter is which is the interesting case if the subsequent cas succeeds in an active descriptor inj n that descriptor is the new live node in state j k and the thread being responsible for this transition ownership of the descriptors token the resulting assertion y · j k is equivalent to y j k y · j k which means that we can use y · j k as a frame in an application of the frame rule to the triple for n this gives us the postcondition y j k y · j k which is equivalent to y · j k since our thread still the token we know the state is exactly j k and in the next step where we return the unit value we the token in return for our some thread has executed discussion and related work we have presented a model for a highlevel language with concurrency that enables direct refinement proofs for sophisticated via a notion of local protocol that the fundamental of and nondeterminism in this section we survey the most closely related work along each of these highlevel language birkedal et al recently developed the first model for a higherorder concurrent language similar to the one we consider here their aim was to show the soundness of a sophisticated system and in particular to prove the soundness of a parallelization theorem for disjoint concurrency expressed by the effect system when the conditions are satisfied the worlds used in the logical relation capture the approach to interference implied by the system as a result the model has rather limited support for reasoning about it can only prove correctness of algorithms that can arbitrary interference we are of any other proof methods that handle higherorder languages concurrency and local state direct refinement proofs and notion of linearizability has long been the standard of correctness for but as et al argue what clients of an really want is a contextual refinement property et al go on the steps labeled with indicate uses of the rule of consequence to show that under certain strong assumptions about a programming language linearizability implies contextual refinement for that language more recently and yang generalized both linearizability and this result the socalled abstraction theorem to include potential ownership transfer of memory between and their clients while it is possible to compose this abstraction theorem with a proof of linearizability to prove refinement there are several advantages to our approach of proving refinement directly first of all it allows us to treat refinement as an assertion in our logic which means that we can compose proofs of refinement when reasoning about compound and do so while working within a single logic second it allows us to recent work for reasoning about refinement and hidden state eg dreyer et als logical relations third it allows us to reason about that use higherorder features eg the universal construction given in which would otherwise require extending the definition of linearizability to the higherorder case finally it allows us to combine reasoning about finegrained concurrency with other kinds of reasoning eg relational parametricity and wand developed the first logic for reasoning directly about contextual refinement for their model is based on ideas from relyguarantee and separation logic and was developed for a simple firstorder language using an extension of denotational semantics while it is capable of proving refinement for simple such as stack it does not easily scale to more sophisticated algorithms more recently et al proposed rgsim a compositional simulation relation based on relyguarantee for verifying program transformations in a concurrent setting et al also use their method to prove that some simple but realistic are simulated by their spec while the original paper on rgsim did not relate simulation to refinement or linearizability new currently unpublished work has done so local protocols ohearn et als work on linearizability with clearly the need for local protocols in reasoning about and demonstrates how a certain of local and global constraints leads to proofs about lockfree traversals at the of the work is the lemma which conclusions about reachability in the past based on information in the present since ohearn et al are focused on providing proofs for a particular class of algorithms they do not formalize a general notion of protocol but instead focus on a collection of invariants specific to the traversals they study we have focused in contrast on giving a simple but general account of local protocols that suffices for reasoning about a range of it remains to be seen however whether our techniques yield a satisfying correctness proof for the kinds of traversals ohearn et al study or whether as ohearn et al argue these traversals are best understood the notion of protocol most closely related to ours is et als concurrent abstract predicates cap cap extends separation logic with shared hidden regions similar to our islands these regions are by a set of abstract predicates which can be used to make assertions about the state of the region in addition cap provides a notion of named actions which characterize the possible changes to the region actions are treated as a kind of resource which can be lost or split up in a fractional permissions style and executing an action can result in a change to the available actions it is upon users of the logic to show that their abstract predicates and actions by showing that every abstract predicate is remains true after any available action is executed while notion of protocol is very expressive it is also somewhat lowlevel compared to our protocols which would require a somewhat encoding to express in cap in addition our protocols make a clear separation between knowledge bounding the state of the protocol treated as a assertion and to change the state treated as a linear resource tokens which are mixed in cap another major difference is that cap the internal protocol of a data structure as part of the specification seen by a means that the spec for a given often depends on how the client is to use it additional and additional correctness proofs may be necessary for other clients by contrast we take a data structure as an spec if clients then want to use that data structure according to some sophisticated internal protocol they are free to do so finally our protocols support and spec code as a resource neither of which are supported in cap the classic treatment of in concurrency is relyguarantee reasoning in which threads guarantee to make only certain updates so long as they can rely on their environment to make only certain possibly different updates more recent work has combined relyguarantee and separation logic and in some cases even supporting a frame rule over the rely and guarantee constraints this line of work in et als reasoning the to was designed to facilitate a more dynamic form of relyguarantee to account for thread in the framework actions are classified into those that both a thread and its environment can perform those that neither can perform and those that only one or the other can perform the classification of an action is in terms of fractional permissions the dimensions being and guarantee which can be split and combined dynamically our express dynamic evolution of roles in an more direct and way through tokens thesis set a mark in verification of the most sophisticated such as building on his logic vafeiadis established an informal methodology for proving linearizability by several kinds of ghost state including variables and resources the latter representing linearization points by storing and communicating this ghost state to another thread one can perform threadlocal verification and yet account for the other thread the single of the ghost resource while this account of seems intuitively reasonable it lacks any formal metatheory its use in linearizability or refinement proofs our computational resources generalize ghost state since they can and do run computations for an arbitrary number of steps and we have justified their use in refinement in fact that the technique of logical relations can be expressed in a unary hoare logic style by using these computational resources concurrently with our work and have extended their rgsim framework to account for the new simulation method is parameterized by a pending thread inference map which plays a role somewhat to our worlds for us worlds impose a relation between the current protocol state the current implementation heap and the current speculative spec resources by contrast imposes a relation between the current implementation heap and the current spec thread pool to recover something like our protocols one instead introduces ghost state into the implementation heap much as vafeiadis does as a result can be used to do threadlocal reasoning about however there are several important differences from our approach first there is no notion of composition on thread inference maps which take the perspective of the global implementation heap and global pool of spec threads thus thread inference maps do not work as resources that can be owned split up and second the assertions that are used in pre and postconditions cannot talk directly about the thread inference map they must control it indirectly via ghost state third the simulation approach does not support or highlevel language features like higherorder functions or polymorphism finally it requires encoding protocols via traditional ghost state and relyguarantee rather than through protocols and propose a different approach for dealing with based on method of reduction reduction in a sense the effects of concurrency by showing that interleaved actions commute with one another much like linearizability and are able to derive an elimination stack from its spec by a series of transformations each by considering possible interleavings and proving very roughly that the relevant actions commute et al also developed a method for proving linearizability using reduction and abstraction and while they do not study explicitly it is likely that their method can with it too nondeterminism forward simulation is wellknown to be sensitive to differences in the timing of nondeterminism also known as the branching structure of a transition system on the other hand forward simulation is local since it considers only one step of a program at a time as opposed to eg trace semantics to retain reasoning but permit differences in nondeterminism as in the choice example it suffices to use a combination of forward and backward simulation or equivalently history and variables and showed that there are also of forward and backward simulations which relate a single state in one system to a set of states in the like our our technique goes further though in combining this form of reasoning with threadlocal reasoning hybrid simulations work at the level of complete systems whereas our simulations can be composed into larger simulations allows us to combine uses of with shared uses of in protocols moreover it is crucial in showing soundness for contextual refinement references m abadi and l lamport the existence of refinement mappings theoretical computer science ­ a ahmed stepindexed syntactic logical relations for recursive and quantified types in esop a ahmed d dreyer and a representation independence in popl l birkedal b j k j and h yang stepindexed kripke models over recursive worlds in popl l birkedal f and j a concurrent logical relation in csl sept s full abstraction for a shared variable parallel language information and computation ­ t m p m parkinson and v vafeiadis concurrent abstract predicates in ecoop june m x m parkinson and v vafeiadis reasoning in esop d dreyer g and l birkedal the impact of higherorder state and control effects on local relational reasoning in icfp d dreyer g a and l birkedal a relational modal logic for higherorder stateful in popl t s qadeer a o and s simplifying linearizability proofs with reduction and abstraction in tacas x local relyguarantee reasoning in popl pages ­ acm x r and z shao on the relationship between concurrent separation logic and reasoning in esop i p ohearn n and h yang abstraction for concurrent objects theoretical computer science k fraser and t concurrent programming without locks acm trans comput syst a and h yang linearizability with ownership transfer in concur l and r derivation of a scalable lockfree stack algorithm form comput ­ t k fraser and i pratt a practical operation in d n and l a scalable lockfree stack algorithm in m and n the art of multiprocessor programming morgan m p and j m linearizability a correctness condition for concurrent objects toplas ­ c a r hoare proof of correctness of data representations informatica ­ c b jones steps toward a development method for programs toplas ­ h and x modular verification of linearizability with linearization points manuscript july h x and m fu a simulation for verifying concurrent program transformations in popl r j reduction a method of proving properties of parallel programs acm ­ j and d polymorphic effect systems in popl n and f forward and backward simulations i systems inf comput ­ m m michael and m l scott nonblocking algorithms and locking on shared memory j parallel comput ­ p ohearn n m e and g verifying linearizability with in p w ohearn resources concurrency and local reasoning theor comput sci ­ j c reynolds types abstraction and parametric polymorphism in information processing j c reynolds separation logic a logic for shared mutable data structures in lics r systems programming with parallelism technical report research center a j a ahmed l birkedal and d dreyer logical relations for finegrained concurrency technical appendix url a and m wand a separation logic for refining concurrent objects in popl v vafeiadis modular finegrained concurrency verification phd thesis university of cambridge v vafeiadis and m parkinson a of relyguarantee and separation logic in concur r j van the linear time branching time in concur 