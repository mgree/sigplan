the in programming preliminary report r pratt massachusetts institute of technology cambridge mass abstract we consider the problem of some of the of programmers we take as our point of the claim that data management has been automated to the point where the programmer concerned only about the correctness as opposed to the efficiency of his program need not involve in any aspect of the storage allocation problem we focus on what we feel is a sensible next step the problem of aspects of control to this we propose a definition of control based on a a variation of ys the formalizes an idea with and developed by and others it allows one to operate arbitrarily on the control component of a program without the programs correctness which is entirely the of the fact component the immediate objectives of our research are to learn how to program keeping fact and control separate and to identify those aspects of control amenable to automation to the computer one might characterize the difference between a tool and a or assistant to avoid solely in terms of communication a user commands his tool in the simple language of the tool a commands his assistant in the rich language of the putting a heavy demand on the intelligence the modern computer as a tool for calculating table a reasonable objective of artificial intelligence is to make it an assistant in this paper we outline a step in this direction as an example of progress to date we may consider storage allocation the problem of finding a place in memory to store a datum the machine language programmer must specify an absolute address for an array the symbolic assembly language programmer may simply request a given amount of storage at assembly time leaving the choice of base address up to the the fortran programmer can store data in arrays this research was supported by the advanced research of the department of under of research contract without to choose or even be aware of a correspondence between integers and pairs of integers for mapping two dimensions into one the algol programmer can have multiple simultaneous of the same procedure namely when that procedure calls itself directly or indirectly ie recursively without having to allocate storage in advance for each such activation the lisp programmer can create complex objects eg by lists without having to declare them in advance to the storage allocator and without even having to think up names for them we observe in this a gradual shift of for storage management from the programmer to the computer every such the computer can assume means that much less work for the programmer and more importantly in our that much less for on the part of the programmer one might take the position that such progress while of value to programmers is not a step towards an assistant but merely an application of techniques from the theory of algorithms we that position how is to the computer whether via algorithms or magic is when it has been our objective is to continue this transfer without having to to magic in this paper we will focus not on data management but on control our objective is to some of the control decisions currently made by the programmer in the following we outline a of control in terms of interpreters and programs present an approach to separating issues from control or heuristic issues performance in programs and discuss approaches to the latter a of control we adopt the viewpoint that an operating computer consists of an interpreter and a program being interpreted and that the program the interpreter in its choice of operations in much the same way as a grammar a readers with this viewpoint might consider the regular expression a grammar of sorts where the assignments and tests are terminals is concatenation and y is kleene this grammar generates the set of execution sequences associated with one way of computing x out of context a grammar does not specify which of the in its language the should use any more than does a program specify which execution sequence to use in the absence of an environment given an environment whether a interpreter can choose an appropriate execution sequence depends on the nature of the program in the factorial example the interpreter can work from left to right in the regular expression the tests xo and xo to decide whether to execute again or to end it all by executing xo using the environment in carrying out the rule never execute a test whose value is false with this rule the interpreters are so limited by this program that almost no intelligence is needed to choose the right sequence in that the interpreter need not be a large program and need not other data bases beyond the immediate environments this viewpoint of the program as guide is not constrained to execution sequences of assignments and tests the formulae f and fn can be regarded as advice on what to do with say f one obvious possibility being to rewrite it repeatedly using the above formulae and other facts of arithmetic to end up with f xf xf xf x again a simple interpreter will suffice to discover this sequence say by trying to unify the last term generated with the left hand side of one of the above two identities where the unifier has enough intelligence to unify and nl in the above examples the interpreter next to nothing in the between program and interpreter this was about the extent of the power of machine languages on all early computers one might be to justify this on the basis of the theoretical observation of turing that small universal interpreters exist that is that in the division of between program and interpreter all but a small fixed amount of the can be allocated to the program however it has always been understood by language designers whether or that the in hardware possible using a minimal interpreter are more than offset by the resulting of execution and to the programmer so that even the simplest machines use machine languages considerably more sophisticated than that implied by choice of representation of programs to be executed by his universal machine with the decreasing ratio of hardware to programmer costs and with the development of services provided by operating systems as a powerful extension of the basic machine language this division of has been with the interpreter assuming more in the decision making process the primary of this in the division of is the programmer in his as writer of his own programs and as of both his own programs and those of others the more the interpreter the less advice the programmer need supply to enable the interpreter to a given task it is natural to assume that less advice leads to less effort but we prefer to this potential benefit and instead the of the programmer in comparison to the computer less advice means less for error if this results in a substantial decrease in debugging time some increase in programming time may be however the greatest in the end may be the programs user for the cost of a bug in the program may often amount to more than the cost of the program even if he is the of that program and has the full programming costs fact and heuristic we focus on the notions of or fact or and performance or heuristic which supply a dimension for programs that has received relatively little attention to date this dimension with who argued the of the to theoretical the idea has implicitly been applied to computer science in various ways which we discuss later the of a deterministic program is that in the program that to its partial correctness soundness and nondeterministic termination completeness the performance to the determinism of the program in this section we shall be concerned simply with making the separation being content to leave the automation of the heuristic component later this is a little so let us consider some examples the simplest domain in which to study the is that of function definitions where one combines identities with information as to when each identity is relevant this can be observed in the following definition of the factorial function fx if xo then else we find here two kinds of information one is the definition asserts that fi and that if xo then the other is procedural the interpreter in what order to do thing the advice given here is to begin with the fact fl treating it as fd asymmetric and if it is to proceed to the other fact with no for advice if the second fact is eg if the hardware is broken if we were to rewrite this definition separating the from the performance we might write base f ind performance the component the two facts appropriately the performance component says that if you want the expression fx transformed into an integer then apply the lefttoright transformation rule to fx using the identity base and failing that try the same with the identity ind this use of labels is whether we write factorial as above or as i is not important so long as we can distinguish the two components in this case by putting the elements of the component in with further syntactic one might be able to get the definition to look almost the same as the original one however there is an aspect of not yet discussed that makes it likely that labels would be widely used and that is the that much of a programs component will consist of generally useful facts to by more than one program a trivial instance of this is the example below now that we have seen an example of the idea let us return to definitions we referred in the beginning to soundness and completeness as though the were an axiom system indeed we shall think of it as just that without the usual attached in axiom systems to axioms that is we shall not object in the least to the presence of axioms that follow from other axioms the advantage of having a set of logically independent facts in the component is that it helps to keep that component small the is that it shifts to the interpreter and the performance component the burden of coming up with the relevant theorems we feel that this task is more appropriate for establishes the correctness component in this way we keep separate the functions of generating the proof of the programs correctness and executing the program our notion of soundness is here one of to the properties of the problem domain thus no fact in the component should be inconsistent with what we know about the domain being able to prove such facts is a sure guarantee of this the two facts used in the factorial example if not axiomatic can at least be proved from whatever definition of factorial one has in mind our notion of completeness is a bit more subtle the basic idea is to make sure that there are enough facts around our objective is to make it possible for the interpreter and the performance component to run using at most the resources specified by the programmer who may say simply the program should halt on all inputs or more it should not take time greater than the component we gave for factorial is complete with respect to the first of these but not the second unless the interpreter does some theorem proving some more facts are needed such as nz where px together with enough facts or a library procedure to allow one to evaluate the degree n polynomial p at n points in time on the following example illustrates issues absent from the simple factorial example define if xo then y else mod x x define if xo then y else case of if xy then else j separating out the components we have base x sym e add corn ty mod xx note that there is no point in keeping separate components for separate programs performance algorithm algorithm note the use of also note the use of the test which causes l to to fail when y is not even tests in the performance component do not any of the advantages of the separation in contrast if we were to allow assignments whether explicitly in the form of assignments to variables or implicitly by naming values to be returned as the answer we would then be able to the correctness of the component combined useful when is not known in advance to be applicable eg when availability of mod is unknown in this example we have more facts in the component than we need for either one of the two algorithms by itself conventional programming necessary and sufficient programming where you write down just enough cases to get the job done in the style since the use of each fact is unspecified there the same to be necessary and one free to include any relevant facts at the same time one runs the of not sufficient facts the ifthenelse style forces one to for every case whereas an empty component will at least be sound if not complete impact of this on verification methods thanks primarily to the work of we now understand the relationship between proving theorems in mathematics and proving that a program is correct namely that correctness can be expressed in terms of theorems about programs and that such theorems can be proved using inference rules analogous to rules used in conventional mathematics hoare has made the connection even by developing an axiom system modelled on systems developed by and manna has shown that such systems are no stronger than conventional oriented secondorder logic and cook has in effect this by showing that even when the symbols of the underlying language are interpreted as arithmetic operations such systems are no more powerful than firstorder arithmetic although his goal was actually to establish completeness of method in the style of programming all of the above results become redundant correctness of a program reduces to correctness of the facts making up its component the above results are now implicit in the interpreter in which is the for to the facts thus all that is needed to prove the program correct is to prove the individual facts in the component in the example of a program verifying the facts becomes even simpler than proving mathematical theorems it becomes a matter of having an check that the facts are in with his understanding of the laws and related issues this observation is in with a of ours that truth proof that is that the question of whether a formula is true arises independently of the existence of any axiom system in which it can be proved proofs are just computations for machines limited by thesis of the truth of propositions correctness of a program is defined in terms of whether its facts are true not whether they are provable in this way we can factor out from our theory any on the notion of proof procedural not all components need involve static facts sometimes a procedural idea is required where the of the idea can be explained in terms of a small fixed number of steps of a procedure the appropriate control structure for application of the idea is still an appropriate task for the interpreter in this case the programmer need only apply a small fragment of what we know about proving programs correct just enough to verify that a of instructions have the desired the interpreter can then be on to use the idea correctly the components in the following examples refer to programs in the following symbols not taking arguments are considered universally quantified all other symbols take on whatever value is assigned to them by the particular world in which they are evaluated p preserves q is an abbreviation for p and q implies next q next is a unary modal logical connective the only procedural concept present whose meaning is after executing one arm operation eg opening the hand moving the hand so that b is meaning that b is between the of the hand without the hand necessarily being closed moving the hand to meaning that the hand is just over b not not and implies and implies cd and implies xy implies next not preserves not implies next implies implies next or preserves not preserves not preserves not the reader familiar with interpreters of theorems as in should not find it hard to see how to interpret these facts as a program the problem of is the canonical example of this three of the predicate symbols at and open have the appropriate effects on the arm note the application of the first two facts discussed in the next we have not yet out a suitable heuristic component for this example or the next we are at present trying to it from an already existing deterministic ie conventional lisp program that essentially these facts an important decision to make in deciding just what a component is is whether to treat the facts exactly as in logic where the soundness of the whole system can be reduced to the soundness of the individual facts or whether one is to let some facts others for example a program to operate a robot arm needs to know that a block cannot be placed on itself this will prevent it from to a command such as put b on b an obvious approach to this information is to supply the fact but if the correctness of the whole component reduces to the correctness of its facts and if it is correct with the fact it must also be correct without the fact it follows that any contribution made by this fact to the correctness of the whole cannot be considered in isolation from the we must have lost what we will call monotonicity the ability to add facts without increasing the correctness of the program or conversely to select any subset of facts from a correct library knowing that the subset will also be correct in the following system we eliminate and also replace a single modality next with a separate modality for every elementary arm operation represented for convenience here as assignments to the three arm predicates at and open is interpreted to mean after making the formula true while means the dual notion a close analogue is vx interpreted as after setting x to a random value and its dual x vx thus says that no matter what happens as a result direct or indirect of doing s p will hold sp that it is possible for p to hold as a result of s terminating when p is just t true this asserts that s terminates s implies c and implies not and not or implies not and implies not and implies implies not implies not implies implies not the reader can verify for that every assertion in this system is valid given a reasonable interpretation of how the blocks world behaves by itself unlike the preceding system where in the absence of such pessimistic facts as it would be possible to deduce a computation that put b on b it is worth noting that in neither of the above systems is the notion of state referred to explicitly this is in contrast to and see for a rigorous account of how to do this while keeping the semantics these two examples suggested two ways in which procedural information might be incorporated into facts this leads one to ask whether there is any limit to how much procedural information can be put in facts this depends on what programs one is to allow in modalities the equivalences u e s show that union ie nondeterministic choice and sequencing does not affect what we can say leading us to include them without any additional concern only when we add iteration need we again question whether our fact language has become too rich obviously one can then simply implement an interpreter that executes b when the fact component consists of just bp p when it terminates along with the current values of those variables affected by b this is the of the richer the language the more complex the ideas expressible in it in a weaker language it is up to the interpreter with the help of the heuristic component to figure out the complex idea the fact component can only contribute relatively simple ideas other work though we are of any published work in computer science that explicitly attention to the distinction between and performance the idea is implicit in a number of places the most familiar application of the idea is in the use of grammars in parsing systems a grammar whether for algol or can be thought of as a collection of facts about a language the con tf rule abc may be read as the fact an a may be a b with a c from such facts one may infer an s may be a the with a with a the objective of a parser is to recover the of reasoning leading up to such an inference for programming language grammars the performance component is essentially empty and the interpreter ie parser all the performance until system the same held for natural language parsers where the entire grammar in the contextfree component and the parser nothing about the special properties of the particular grammar it was to work with augmented his contextfree grammars represented as transition networks to facilitate this with a performance component that the parser decide what to do when all major contextfree based systems for natural language being on whether or not represented as transition networks now have a substantial performance component predictive analyzer ill which has an empty performance component is maintained at ibm heights but it is not being developed or used an early of explicit representation of heuristics in addition to facts was however was on the fact component and neither that early work nor more recent work a proportional amount of attention to heuristics however this was made up for in the programs of the late s notably qa system and system the former on a theorem prover as its interpreter and had an empty performance this into the of fully automated heuristics proved however its component consisting of raw facts precisely matches our own ideals for a component was more performance oriented however enough of the performance was mixed in with the eg by distinguishing antecedent theorems from theorems when these were both merely implications and by identifying the notion of negation with the performance notion of that we would not wish to class as a of the method we successors and and have become sophisticated performance oriented systems with no and performance components as we them what distinguishes from is more immediate to an interpreter though this intelligence does not extend significantly beyond implementing some good algorithms for handling environments more recently has developed a more interpreter supported by a small theorem prover however the performance component remains with the j notion of programs u programs consisting of a of fragments captures one aspect of components namely their thesis is that any program has such a program as its the programmer begins by the program then proceeds to optimize it in the process the into a structured unit and at the same time converting operations on sets into operations on their elements via the appropriate generalization of reduction in strength schwartz proposes to this optimization in this schwartz comes as close as any to sharing our objectives two major differences are with reducing the of naive set manipulation and his more goals concerning automation of control we ignore optimization possible by reduction in strength formal because the examples we work with cannot benefit from this idea and we expect to see many more examples in that category we have relatively goals for control because it appears to us that complete automation is at present difficult partial automation seems sensible but the question of what part at present our understanding of control structures does not permit us to them up and them between the programmer and the computer which is why we propose to work out our in more detail to try to a better understanding of the heuristic component another place in which the idea can be found is in the most recent attempts to implement logic as a programming language notably those of and io these come as close as any work to our own objectives for separating and performance both of them have the advantage of a welldefined semantics from logic as did qa providing that proofs of correctness will not be just optimistic symbol manipulation but will be supported by a definition of truth for which to our knowledge no substitute has ever been out more attention to the development of a performance component than does who to rely on the interpreter which he implements using has implemented a version of system that the missing performance component and propose applying a version of the to computation the top two levels our fact and heuristic levels respectively with their other two levels corresponding respectively to functions and their implementation with digital hardware discussions with suggest however that their top level is really a set of independent axioms cf our inclusion of theorems in the fact component while their next level is a hybrid of our fact and heuristic components approaches to automation as we have little experience to date in separating fact from control we are not in a position to predict what approaches we will take to control the only idea we have had to date concerns the style of programming by our blocks world example as this idea is interesting we sketch it here it was suggested by a technique used in r firstorder logic proof checker we view each fact as a collection of and to do this we each fact slightly all logical connective ignoring modalities for the moment and assuming that only unary and binary logical connective exist are replaced by a v and eg and then the s are moved down to the atomic formulae via de laws we think of formulae as trees with vertices with symbols and having the root at the top the result is a monotone expression containing only as and vs whose leaves are atomic formulae the monotonicity plays an essential role as we shall see note that this does not result in the substantial increase of size generally associated with conversion to conjunctive or disjunctive normal form unless s or occur for example is not by our transformation but is expanded to if converted to conjunctive normal form in fact our transformation does no to the basic structure of the expression in the absence of and only the names of some of the binary logical connective and some if p is an atomic formula we take p as usual however if p is q for some atomic formula q we take to be q in this way we can say that for any literal p p is an for p and the literal p is a for p given a fact consisting of the single literal p any attempt to make p true must meet with instant success since the existence of p as a fact means that p is always true thus if p occurs as a goal the fact p is an for that goal conversely tp is a for that goal if it occurs as a fact saying that p can never be achieved given a fact of the form the occurrence of p in this fact still acts as an for a goal p and as a for p because all the operators above p in the formula namely v are monotone and do not reverse the sense of p thus if p is set as a goal nothing pessimistic about it but is optimistic in the sense that if q were false then p would be forced to be true we call of this if the goal is p then only pessimistic and says that q had better be true or p will not be we call of this if the fact is then this is as optimistic as the fact p for the goal p and as pessimistic as the fact p for the goal p and say that there are no these ideas generalize to arbitrary formulae in the normal form described above because of the monotonicity given a goal p if an p occurs in a fact then the set of for that are the of the in each of the vs encountered going from the occurrence of the to the root of the expression for example if the goal is d and the fact is then the of the d are in the order encountered going up the expression ye f and similarly if the goal is d then the of the d are e f and this leads to an algorithm for achieving a goal p when p is a literal first determine the truth of p if true we are done now satisfy some of every for p this may recursively setting as if for some it proves impossible to satisfy any then the attempt to satisfy p otherwise find an every one of whose can be satisfied success or failure here translates into success or failure in satisfying p we implemented an interpreter based on this idea and tried it out on the blocks world fact component with an empty performance component the absence of other facts that might throw the system off the allowed our interpreter to proceed reasonably quickly to satisfy such goals as in simple situations unfortunately the presence of modalities such as next this approach and the heuristics we added to the interpreter to deal with the modalities did not seem satisfactory our next project is to give some thought as to how best to deal with next the above method may be generalized to deal with which avoids having to expand it out and the original expression structure though this need at worst square the expression size roughly by treating occurrences of a literal below as both a positive and a negative occurrence any segment of a path from that occurrence to the root with the segment between consecutive s may be forced to take on either with the at the two ss determining how that value with the rest of the path we leave the details to the reader acknowledgments david provided some argument richard gave me the idea for section references u aho a v j e hopcroft and jd unman the design and analysis of computer algorithms addisonwesley reading mass n some aspects of the theory of syntax mit press cambridge mass cook sa axiomatic and semantics for an algol fragment tr rw assigning meanings to programs in mathematical aspects of computer science cd schwartz c the application of theorem proving systems stanford university computer science department report cs to j computation and deduction proc symp math found of comp sci of sciences ce description and theoretical analysis using of a language for proving theorems and manipulating models in a robot mit ai lab tr p and r a universal modular actor formalism for intelligence p proc hoare c a i an axiomatic basis for computer programming cacm r predicate logic as programming language university of edinburgh department of computational logic memo s the predictive analyzer and a path elimination technique cacm j programs with common sense in semantic information processing cd ml mit press cambridge mass d and gj the reference manual mit ai lab memo a flexibility program for designing and efficiency in a computer circuits phd thesis mit ai lab sept manna z secondorder mathematical theory of computation proc nd ann acm symp on theory of computation may dc and tg from understanding computation to understanding mit ai memo may pratt vr effect of basis on the size of boolean expressions proc th ann ieee symp on foundations comp sci of pratt vr considerations on logic proc th ann ieee symp on foundations of comp sci schwartz j a view of program and its implications for future programming languages in new directions in algorithmic languages cd sa an interpreter for the programming language predicate logic proc p turing am on computable numbers with an application to the e proc london math w a augmented transition networks for natural language analysis report no cs to the nsf aiken computation laboratory university cambridge massachusetts 