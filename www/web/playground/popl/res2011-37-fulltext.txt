dynamic inference of static types for ruby david an jeffrey s foster michael systems corporation advanced technology systems university of college park abstract there have been several efforts to bring static type inference to objectoriented dynamic languages such as ruby python and in our experience however such type inference systems are extremely difficult to develop because dynamic languages are typically complex specified and include features such as eval and reflection that are hard to analyze in this paper we introduce dynamic type inference a technique that infers static types based on dynamic program executions in our approach we wrap each runtime value to associate it with a type variable and the wrapper generates constraints on this type variable when the wrapped value is used this technique avoids many of the often conservative approximations of static tools as constraints are generated based on how values are used during actual program runs using wrappers is also easy to implement since we need only write a constraint resolution algorithm and a transformation to introduce the wrappers the best part is that we can our too our algorithm will infer sound types as long as it every path through each method that the number of such paths may be smaller than the number of paths through the program as a whole we have developed an implementation of our algorithm for ruby takes advantage of dynamic features to implement wrappers as a language library we applied to a number of small programs and found it to be both easy to use and useful discovered real type error and all other inferred types were correct and readable categories and subject descriptors f logics and meaning of programs semantics of programming analysis f logics and meaning of programs studies of program structure general terms languages theory verification keywords dynamic type inference static types ruby dynamic languages introduction over the years there have been several efforts to bring static type inference to objectoriented dynamic languages such as ruby python and ­ static type inference has the potential to provide the benefits of static typing permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ austin texas usa copyright c acm welltyped programs dont go wrong without the annotation burden of pure type checking however based on our own experience developing a static type inference system for a dynamic language is extremely difficult most dynamic languages have complex syntax and semantics that must be carefully before any static analysis is possible dynamic languages are usually specified only with a canonical implementation and tend to have many corner cases that make the reverse engineering process tedious and moreover dynamic language programmers often employ programming idioms that precise yet sound static analysis for example programmers often give variables flowsensitive types that differ along different paths or add or remove methods from classes at runtime using dynamic features such as reflection and eval combined these challenges make developing and maintaining a static type inference tool for a dynamic language a to address these problems this paper introduces dynamic type inference a technique to infer static types using information from dynamic runs more precisely at run time we introduce type variables for each position whose type we want to fields method arguments and return values as values are passed to those positions we wrap them in a object that records the associated type variable the user may also supply trusted type annotations for methods when wrapped values are used as or passed to methods we generate subtyping constraints on those variables at the end of the run we solve the constraints to find a valid typing if one exists we have implemented this technique for ruby as a tool called where stands for dynamic of static types unlike standard static type systems only type information at method boundaries where type variables constraints from different calls and not within a method as such supports flowsensitive treatment of local variables allowing them to be assigned values having different types since only actual runs of the program it is naturally and supports use of many dynamic features finally can be implemented as a library by common features to method calls there is no need to any subtle parsing or elaboration rules and to build a separate analysis infrastructure in sum is more precise than standard static type inference and many of the engineering difficulties of building a static analysis tool suite although is based purely on dynamic runs we can still prove a soundness theorem we formalized our algorithm on a core subset of ruby and we prove that if the training runs on which types are inferred cover every path in the controlflow graph cfg of every method of a class then the inferred types for that fields and methods are sound for all possible runs in our formalism all looping occurs through recursion and so the number of required paths is at most exponential in the size of the largest method body in a program notice that this can be smaller than the number of paths through the program as whole clearly in practice it is potentially an issue that we need test cases that cover all method paths for fully sound types however there are several factors that this potential · almost all software projects include test cases and those test cases can be used for training in fact the ruby community development which that tests be written before writing program tests will likely be available for training right from the start · while loops within methods could yield an unbounded number of paths in our experimental benchmarks we observed that most loop bodies use objects in a manner within each path within the loop body hence typically observing all paths within a loop body rather that observing all possible iterations of a loop suffices to find correct types we discuss this more in section · even incomplete tests may produce useful types in particular the inferred types will be sound for any execution that takes within a method paths that were covered in training we could potentially add instrumentation to identify when the program executes a path not covered by training and then blame the lack of coverage if an error arises as a result types are also useful as documentation currently the ruby documentation includes informal type signatures for standard library methods but those types could become out of sync with the code we have found cases of this previously using we could generate type annotations automatically from code using its test suite and thus keep the type documentation with the tested program behaviors our implementation of is a ruby library that takes advantage of rich features no special tools or compilers are needed each object o at runtime with a object that associates o with a type variable that corresponds to os position in the program a field argument or method calls on o the generation of constraints eg if the program invokes then we generate a constraint indicating that must have a method m whose argument type is a supertype of the type of x also trusted type annotations on methods this is important for giving types to builtin standard library which is written in c rather than ruby and hence is not subject to our type inference algorithm we evaluated by applying it to several small programs the largest of which was roughly loc and used their test to infer types we found one real type error which is particularly interesting because the error was by solving constraints from a passing test run all other programs were found to be type correct with readable and correct types the overhead of running is currently quite high but we believe it can be reduced with various optimizations that we intend to implement in the future in general we found the performance acceptable and the tool itself quite easy to use in summary our contributions are as follows · we introduce a novel algorithm to infer types at runtime by dynamically associating fields and method arguments and results with type variables and generating subtyping constraints as those entities are used section · we formalize our algorithm and prove that if training runs cover all syntactic paths through each method of a class then the inferred type for that class is sound section · we describe a practical implementation of our algorithm that uses rich features since on the standard ruby interpreter we can caller where g u constrain a x b mx c g wrap h v i u g where g u callee wrap def mx e end d v x where f w e w f run e v constrain f g f where f w figure dynamic instrumentation for a call handle all of rather complex syntax and semantics without effort section · we evaluate on a small set of benchmarks and find it to be useful section we believe that is a practical effective method for inferring useful static types in ruby and that the ideas of can be applied to other dynamic languages overview before presenting our dynamic type inference algorithm formally we describe the algorithm by example and illustrate some of its key features our examples below are written in ruby which is a dynamically typed objectoriented language inspired by smalltalk and in our discussion we will try to point out any syntax or language features we use more complete information about ruby can be found elsewhere method call and return in our algorithm there are two kinds of classes annotated classes which have trusted type signatures and classes whose types we wish to infer we assign a type variable to each field method argument and method return value in every class at run time values that these positions are associated with the corresponding type variable we call this association since we implement it by the value with some metadata when a wrapped value is used eg as a receiver of a method call or as an argument to a method with a trusted type signature we generate a subtyping constraint on the associated variable at the end of the training runs we solve the generated constraints to find solutions for those type variables which yield field and method types for classes or we report an error if no solution exists note that since all instances of a class share the same type variables use of any instance to inferring a single type for its class before working through a full example we consider the operation of our algorithm on a single call to an method figure summarizes the five steps in analyzing a call to a method defined as def mx e end where x is the formal argument and e is the method body in this case we create two type variables x to represent xs type and m ret to represent ms return type in step the caller looks up the dynamic class of the receiver to find the type of the called method in this case method m has type x m ret the caller then generates two constraints the constraint labeled a ensures the type of the actual argument is a subtype of the formal argument type here is the type of an object either its actual type for an object or the type variable stored in the wrapper in the constraint b the type m is the type of an object with a method m with the numeric numeric numeric class a foo w × u foo ret def w b w u u w y u y numeric u numeric return ret bar ret w x end bar ret foo ret bar x bar ret def x b x x return numeric bar ret end end returns a new object b b w numeric u ret foo ret figure basic method call and return example given type hence by constraint b specifies that o has at least an m method with the appropriate type we generate this constraint to ensure os static type is consistent with the type for m we found via dynamic lookup for now ignore the constraint c and the other constraints e g and i involving fields f and g we will discuss these in section in step of analyzing the call the callee its arguments with the appropriate type variables immediately upon entry in this case we set x to be v x which is our notation for the value v wrapped with type x then in step we execute the body of the method doing so will result in calls to other methods which will the same process moreover as v x may be used in some of these calls we will generate constraints on x ie x that we saw in step in particular if v x is used as a receiver we will constrain x to have the called method if v x is used as an argument we will constrain it to be a subtype of the target methods formal argument type at a highlevel steps and maintain two critical invariants · prior to leaving method n to enter another method m we generate constraints to capture the flow of values from n to m constraints a and b · prior to entering a method m all values that could affect the type of m are wrapped indicated by d roughly speaking something with a type records how it was used in the past and something with a type how it is used in the future returning from methods should maintain the same invariants as above but in the reverse direction from callee to caller thus in step we generate constraint f in the callee that the type of the returned value is a subtype of the return type and in step when we return to the caller we immediately wrap the returned value with the called methods return type variable complete example now that we have seen the core algorithm we can work through a complete example consider the code in figure which defines a class a with two methods foo and bar and then calls foo on a fresh instance of a on line this code uses numeric class which is one of the builtin classes for integers because numeric is builtin we make it an annotated class and supply trusted type signatures for all of its methods a portion of the signature is shown on line which indicates numeric has a method of type as in the previous subsection we introduce type variables for method arguments and returns in this case w u and foo ret for foo and x and bar ret for bar then we begin through the calls at the call on line we pass in actual arguments b the object created by the call to on the same line and thus we constrain the formal argument types in the caller lines and and wrap the in the callee line next on line we use a wrapped object so we generate a constraint here we require the associated type variable w contains a method for simplicity we show the return type as though as it is unused it could be arbitrary on line we call u the receiver object is which has actual class is numeric an annotated class thus we do the normal handling in the caller the box in figure but omit the steps in the callee since the annotation is trusted here we generate a constraint u numeric between the actual and formal argument types we also generate a constraint not shown in the figure type but as type numeric this constraint is immediately satisfiable in general we need to generate such constraints to correctly handle cases where the receiver is not a constant finally we wrap the return value from the caller with its annotated type numeric next we call method bar as expected we constrain the and formals line wrap the argument inside the callee line and generate constraints during execution of the body line at the return from bar we constrain the return type line and wrap in the caller yielding the wrapped value bar ret on line as that value is immediately returned by foo we constrain the return type of foo with it line and wrap in the caller line after this run we can solve the generated constraints to infer types the constraints from the example as a directed graph where an edge from x to y corresponds to the constraint x y we have b w numeric x numeric u numeric here we duplicated numeric for clarity in practice it is typically represented by a single node in the graph as is standard we wish to find the least solution equivalent to a most general type for each method since arguments are contravariant and returns are covariant this corresponds to finding upper bounds transitive successors in the constraint graph for arguments and lower bounds transitive predecessors for returns intuitively this is equivalent to inferring argument types based on how arguments are used within a method and computing return types based on what types flow to return positions for our example the final solution is w x u numeric bar ret foo ret numeric notice that w must have bar and methods but x only needs a method for return types both bar and foo always return numeric local variables and fields in the previous example our algorithm generated roughly the same constraints that a static type inference system might generate how in ruby the syntax e e is shorthand for e e ie calling the method on e with argument e class c def z x z z return z end end class d def f x end def y f end def f foo end def f end end figure example with local variables and fields ever because our algorithm only dynamic runs in many cases it can be more precise than static type inference consider class c in figure on entry to foo we wrap the actual argument v as v x where x is formal argument type at the assignment on line we do nothing allow the language interpreter to copy a reference to v x into z at the call to we generate the expected constraint x more interestingly on line we z to contain and so at the call to zs method we do not generate any constraints on x thus our analysis is flowsensitive with respect to local variables meaning it respects the order of operations within a method to see why this treatment of local variable assignment is safe it helps to think in terms of compiler optimization we are essentially performing inference over a series of execution traces we can view each trace as a program consider the execution trace of foo which is the same as the body of the function in this case if we apply copy propagation of x and to the trace we get zx z return since z is a local variable outside of the scope of foo it is dead at the end of the method too so we can apply dead code elimination to reduce the trace to return the constraints we would generate from this trace are equivalent to those we would generate with our approach instance fields in ruby are not visible outside an object but they are shared across all methods of an object thus we need to treat them differently than to see why consider the class d in figure which uses the instance variable f all instance variables begin with in ruby suppose that we treated fields the same way as local variables ie we did nothing special at assignments to them now consider inferring types for d with the run bar during the call bar we would generate the constraint numeric x the type variable for x and store x in f then during we would generate the constraint x numeric and the call to would generate no constraints thus we could solve the constraints to get x numeric and we would think this class has type bar numeric but this result is clearly wrong as the welltyped sequence produces a type error to solve this problem we need to introduce a type variable f for the field and then generate constraints and wrap values accordingly it would be natural to do this at writes to fields but that turns out to be impossible with a dynamic solution as there is no dynamic mechanism for field writes fortunately we can still handle fields safely by applying the same recall we wish to avoid using static techniques including program rewriting because they require complex that understand program semantics for example even ordering of assignment operations in ruby can be in some cases class e def p if p then else end end def if p then y else y end if p then y else y length end end end a paths and class f def return if x then else end end def z return if y then else foo z end end end f b path coverage figure additional examples principles we saw in figure for method arguments and returns there we needed two invariants when we switch from method m to method n we need to capture the flow of values from m to n and when we enter a method n we need to wrap all values that could affect the type of n translating this idea to fields we need to ensure · when we switch from m to n we record all field writes performed by m since they might be read by n this is captured by constraints c and g in figure · when we enter n we need to wrap all fields n may use so that subsequent field reads will see the wrapped values this is captured by constraints e and i in figure adding these extra constraints and operations solves the problem we saw above at the call bar we generate the constraint numeric x as before however at the end of bar we now generate a constraint x f to capture the write at the beginning of we wrap f so that the body of will now generate the constraints f numeric then generates the constraint string f we can immediately see the constraints string f numeric are unsatisfiable and hence we would correctly report a type error notice that this design also allows a small amount of for fields a field may contain a value of a different type as long as it is before calling another method or returning we do not expect that this yields much additional precision in practice however our implementation handles class variables similarly to instance variables note that we assume singlethreaded execution if accesses of such variables by other threads are interleaved the inferred constraints may be unsound path and path coverage as our algorithm dynamic runs to infer sound types we need to observe all possible paths through branching code sequences for example we can infer types for the foo method in figure a if we see an execution such as true false in this case we will generate x from the first call and x from the second one benefit of observing actual dynamic runs is that we never model program executions for example consider the bar method in figure a in a call line assigns a numeric to y and in a call bar false it assigns a string to y typical static type inference would these possibilities and determine that y could be either a numeric or string on line and hence would signal a potential error for both the calls to and to length in contrast in our approach we do not assign any type to local y and we observe each path separately thus we do not report a type error for this code our soundness theorem section holds if we observe all possible paths within each method body to see why this is sufficient rather than to observe all possible program paths consider the code in figure b assuming bar is the entry point there are four paths through this class given by all possible truth value combinations for y and z however to observe all possible types we only need to explore two paths if we call f true and f bar false true we will generate the following constraints true boolean y boolean z z x numeric foo ret foo ret bar ret true boolean y boolean z boolean x string foo ret foo ret bar ret thus we can deduce that bar may return a numeric or a string note that our system supports union types so we can express this return type as string numeric the reason we only needed two paths is that type variables on method arguments and returns act as join points the possible types of all paths within a method in our example both branches of the conditional in bar have the same type foo ret thus the other possible calls f false and f bar false false do not affect what types bar could return dynamic features another benefit of our dynamic type inference algorithm is that we can easily handle dynamic features that are very challenging for static type inference for example consider the following code which occurred in one of our experimental benchmarks def initialize args args keys each do self args end end this constructor takes a hash args as an argument and then for each pair k v uses reflective method invocation via send to call a method named after k with the argument v or consider the following code attributes do code def end eval code end for each element of the string array attributes this code uses eval to define a new method named after the element note that an if generates no constraints on its guard as any object may be supplied false and nil are false and any other object is true also here and in our implementation we treat true and false as having type boolean though in ruby they are actually instances of and respectively expressions e nil self x f x e f e e e if e then e else e methods d def mx e classes c class a d programs p c e types af am am a m am am x local variables f field names m method names a class names labels figure syntax of source language we encountered both of these code in earlier work in which we proposed using runtime profiling to concrete uses of send eval and other highly dynamic constructs and then analyzing the profile data statically in the dynamic analysis we propose in the current paper no separate profiling pass is needed we simply let the language interpreter execute this code and observe the results during type inference method invocation via send is no harder than normal dynamic dispatch we just do the usual constraint generation and which as mentioned earlier is actually performed inside the callee in our implementation method creation via eval is also easy since we add instrumentation by dynamically through the defined methods of classes it makes no difference how those methods were created as long as it happens before instrumentation formal development in this section we describe our dynamic type inference technique on a core source language the syntax is shown in figure expressions include nil self variables x fields f variable assignments x e field assignments f e object method calls sequences e e and conditionals if e then e else e conditionals carry labels to allow us to reason about path coverage conceptually labels may be thought of as logical of the form and ¬ represent a branch taken or not taken respectively at run time we assume that all labels are distinct the form def mx e defines a method m with formal argument x and body e classes c are named collections of methods a program consists of a set of classes and a single expression that serves as a test typically we run a test on a collection of classes to the infer in our proofs run other tests to monitor the show that the inferred types are sound in the formalism we use only a single test e to the system but we can always represent a set of tests by sequencing them together into a single expression the syntax of types requires some explanation type variables are tagged to avoid generating and for fresh variables thus af is a type variable that denotes the type of the field f of objects of class a similarly am and am are type variables that denote the argument and result types of the method m of class a in addition we have nominal types a for objects of class a and structural types m am am for objects with method m whose argument and result types can be viewed as am and am finally we have the bottom type the top type union types and intersection types values v l nil wrapped values v field maps f f method maps m m xe class maps c a m heaps h l a f environments e x self l a literals p ¬ paths p constraints figure auxiliary syntax training semantics we now define a semantics for training the semantics extends a standard semantics with some instrumentation the instrumentation does not affect the runtime behavior of programs it merely records runtime information that later allows us to infer types and argue about their soundness to define the semantics we need some auxiliary syntax to describe internal data structures shown in figure let l denote heap locations values include heap locations and nil such values are wrapped with types for training a field map associates field names with wrapped values a method map associates method names with abstractions a class map associates class names with method maps a heap maps locations to objects a f which denote objects of class a with field map f an environment maps variables to wrapped values and self to a location wrapped with its runtime type formally the runtime type of a value under a heap is defined by a if hl a f and a path is a list of label literals or ¬ denoted by p that mark conditionals encountered in a run constraints include standard subtyping constraints and coverage constraints meaning that the path is traversed during some call in the run the rules shown in figure derive bigstep reduction judgments of the form h e e c h e meaning that given class map c expression e under heap h and environment e reduces to wrapped value covering path generating constraints and returning heap h and environment e we define the following operations on wrapped values if v then val v type and · v in the rules we use an in any position where an arbitrary is allowed and we write empty set as to avoid confusion with by the type assigned to nil is which means that nil may have any type is straightforward in the notation a nil indicates an instance of a with all possible fields mapped to nil as in ruby fields need not be explicitly initialized before use and are nil by default and are standard and generate no constraint nor perform any as discussed in section as explained in section we permit some for field types thus field and field are like var and var in that they generate no constraint and perform no is straightforward by either or ¬ is recorded in the current path depending on the branch traversed for the conditional with label note that and ¬ can never appear in the same path looping in the formal language occurs only via recursive calls and callee paths are not included in caller paths that said the conditional itself may be visited on many during the training run so that both and ¬ may eventually appear in coverage constraints h e nil c h e nil l a h e self c h e l a l fresh h hl a nil h e c h e l a ex h e x c h e h e e c h e e e x h e x e c h e l val hl f ff h e f c h e h e e c h e e self l val h l a f h h l a f f h e f e c h e h e e c h e h e e c h e h e e e c h e h e e c h e p ep e if val nil p ¬ ep e if val nil h e ep c h e h e if e then e else e c h e p h e e c h e type h e e c h e type l e self l val h l a ca m mm xe m am am am h e self · a x · am h e e c h type am h · am h e e me c h e figure training semantics performs the actions introduced in figure first the type of the receiver is constrained to be a subtype of m am am and the type of the argument is constrained to be a subtype of am the argument type of the callee we evaluate the body e with argument x mapped to · am which is the argument wrapped with method arguments type variable the type of the result is constrained to be a subtype of the result type am and returned wrapped with that type furthermore relates the current path to the set of paths stored as coverage constraints in particular while records the current path traversed in the caller the path traversed by the callee is recorded as a coverage constraint in in addition involves and generation of subtyping constraints for fields of the caller and the callee objects let hl a f we define · hl a f f f · type af f f as discussed in section we constrain the fields of the caller object and wrap the fields of the callee object before the method call and constrain the fields of the callee object and wrap the fields of the caller object after the method call finally the following rule describes training with programs c e c c e coverage where we define a class a d c m xe def mx e d coverage we assume that solves the subtyping constraints in to obtain a mapping t from type variables to concrete types possibly involving and and unions and intersections of nominal types and structural types we discuss the solving algorithm we use in our implementation in section however our technique is to the choice of algorithm or even to the language of solved types the crucial soundness measure for the inferred types is coverage which collects all the coverage constraints in the run the key soundness theorem states that any run whose paths are a subset of must use types that are consistent with as a corollary we show that if all possible paths are covered during inference then all runs are type safe monitoring semantics to argue about the soundness of inferred types next we define a monitoring semantics this semantics slightly extends a standard semantics with monitoring of calls at the top level and monitoring of conditionals this affects the runtime behavior of programs we enforce a contract between the runtime type of the argument and the inferred argument type for any call at the top level and require that the monitoring run only traverses paths that have already been traversed by the training run a toplevel call is simply one that calls into any of the classes for which we have inferred types from outside a call from within a typed class either to its own method or to one of other typed class is considered internal to define the monitoring semantics we modify the syntax of expressions field maps class maps and environments as follows expressions e e me class maps c a m t field maps f f v environments e x v self l expressions of the form e me denote method calls at the top level class maps additionally carry the solution t of the subtyping constraints collected during training and the coverage of the training run field maps and environments no longer map to types the rules shown in figure derive bigstep reduction judgments of the form h e e c h e v where is the path to be traversed and is the suffix of that remains nil h e nil c h e nil self l new h e self c h e l l fresh h hl a nil var h e c h e l ex v h e x c h e v var h e e c h e v e e x v h e x e c h e v field l hl f ff v h e f c h e v field h e e c h e v e self l h l a f h h l a f f v h e f e c h e v seq h e e c h e h e e c h e v h e e e c h e v call h e e c h e v h e e c h e l h l a ca m mm xe c h self l x v e c h v h e e me c h e v h e e c h e v p p ep e if v nil p ¬ ep e if v nil h e ep c h e v h e if e then e else e c h e v h e e c h e v h e e c h e l h l a ca m mm xe v c h self l x v e c h v h e e me c h e v figure monitoring semantics nil self new var field var field and seq are derived from the corresponding rules for training simply by types paths and constraints call is similar but in addition it nondeterministically a path from the coverage of the training run which is carried by c and that the call should traverse that path by including it in the environment under which that call is run by a particular branch p of a conditional may be traversed only if the path that branch ie it begins with p the branch is then run under a residual path by a top level call requires that the runtime type of the argument v is a subtype of the argument type of the method as by the solution carried by c which we write as the following rule describes monitoring of programs run c t c c e where is e but with any method call of course reduction may be stuck in several ways so we do not expect to derive such a judgment for every program in particular we do not care when reduction is stuck due to calls on nil violations of argument type contracts for toplevel calls and violation of coverage contracts for conditionals these correspond to a failed null check a program and an program respectively however we do care about method not found errors since they would reveal that our inferred types even for paths we have are unsound the following rule along with other versions of the monitoring rules augmented with error propagation not shown derives error judgments of the form h e e c error h e e c h e v h e e c h e l h l a ca m m h e e me c finally the following rule defines program error judgments of the form t c e monitor c t t c ce soundness we prove the following key soundness theorem theorem soundness suppose that c e t for some e then there cannot be e such that t c e informally if we infer types t with a test that covers paths then as long as we run other tests that only traverse paths in and satisfy the type contracts in t we cannot have errors in particular this implies the following corollary corollary if we infer types with a test that covers all possible paths then our types are always sound we sketch our proof below our monitoring semantics execution to follow only paths traversed in the training guarantees that if some expression in the methods of c is visited in the monitoring run then it must be visited by the training run our proof is by simulation of the executions of such expressions between these runs we define the following simulation relation between heaps and environments of the training run marked by subscript · and those of the monitoring run marked by subscript · definition simulation h e simulates h e under types t denoted by h e t h e iff the following hold · e t e ie ex if and only if ex v such that v t type and l a if and only if l a · a f such that ff if and only if a f such that ff v and v t type · whenever hl a f such that ff and l we have type af and whenever hl a f such that ff v and l we have v t informally let us say that a value v in the monitoring run with a type associated in the training run if the runtime type of v is a subtype of the solution of then we say that a training state heap and environment simulates a monitoring state heap and environment if the values of variables in the monitoring environment agree with their types in the training environment the self objects in both environments have the same class the fields of objects in the monitoring heap agree with their types in the training heap and for all objects other than self the fields of those objects in the training heap are of the form af this last requirement essentially says that while self fields may have flowsensitive types all other fields must be with their flowinsensitive types we define this notion of stability for training and monitoring heaps below definition training heap stability h is iff whenever hl a f such that ff we have type definition monitoring heap stability h is iff whenever hl a f such that ff v we have v t monitoring and training heaps can be by the operations of and respectively as shown by the lemmas below recall that these operations happen upon entry and exit of method calls thus we can ensure that the of field types does not leak across method calls this is crucial for our proof as shown later lemma suppose that h e t h e suppose that whenever we have t t then h is lemma suppose that h e t h e then is we now have a way of establishing that a training state simulates a monitoring state if both heaps are say by and and furthermore if the environments themselves satisfy the requirements for simulation then the states are related by simulation lemma proof technique for simulation suppose that h is h is and e t e then h e t h e this proof technique is used to show the following main lemma if we run the same expression in both runs and the initial training heap simulates the initial monitoring heap then we cannot have errors in the monitoring run the result of the monitoring run with its type in the training run and the final training heap simulates the final monitoring heap lemma preservation suppose that t in particular deriving h e e c h e let c c t let h and e be such that h e t h e then · we cannot have h e e c · if h e e c h e v with e and e for some then v c and h e t h e proof the proof is by induction on the monitoring run the only difficult case is for method calls which we sketch below note that these method calls are internal not toplevel since only environments for which self is defined can appear in the simulation by the induction hypothesis we cannot have errors in the evaluation of the argument and the receiver let us say they evaluate to v and l furthermore the simulation relation must hold for resulting states say h e and h e and v and l must agree with the types and associated with the argument and receiver in the training run respectively since is a subtype of a structural type with method m we cannot have a error here the main now is that the method in the training run may not be the same as that in the monitoring run although the latter method should be at some point in the training run thus to apply our induction hypothesis for the method call we need to show that the initial state for that method call in the monitoring run is simulated by the possibly initial state with which that method was called in the training run however at this point we can apply lemmas and to relate those states since we constrain the initial state of the caller and wrap the initial state of the callee thus now by induction hypothesis the method expression evaluates to say v such that the simulation relation must hold for resulting states say h e and h e and v must agree with the type associated with the result in the training run finally as above we apply lemmas and to show that the final state for the method call in the training run simulates the final state for the method call in the monitoring run since we constrain the final state of the callee and wrap the final state of the caller now using lemma we can show that the following weaker state invariant is preserved at the top level of a monitoring run definition at the top level e holds iff · whenever hl a f such that f f v we have v · is undefined lemma suppose that c t with c let c c t let h and e be such that e then · we cannot have h e c · if h e c h e v then we must have e theorem follows by lemma perhaps the most interesting thing about this theorem is that it proves we do not need to on all iterations of a loop here formalized as recursive calls to a function but rather just all paths within the loop body here is an example to provide some intuition as to why suppose a recursive method over an array and calls on each element eg def i return if i alength a i i end recall that a i is actually a method call to the method ie a i is really a i if is the arrays contents type variable ie the array has type array this call generates a constraint this constraint generated from a single call to foo affects all elements of a because when the array was created we added constraints that each of its element types are compatible with eg etc where the i are the element types thus the solution to will contain class a infer types a is an class def foo end def bar end end class string string is an annotated class insert numeric string string to s string string end class include def test end test cases called by def test end end figure using we can also prove the following completeness theorem theorem completeness if there are n methods and a maximum of k labels in each method and each label is reachable then a program of size on · k is sufficient to ensure that the inferred types are sound over all runs proof for any method m there can be at most k paths with the labels in m and there can be at most n such methods in practice the completeness bound n · k is likely quite of course a bound could be obtained by considering the actual number of labels k in each method furthermore a method with k labels may induce far less paths than k indeed we are the number of nodes in a branching tree of height k which may even be k if the tree is as a list as is the case for switch statements implementation in this section we describe an implementation of our dynamic type inference algorithm for ruby roughly lines of code and is written purely in standard ruby using is straightforward as illustrated with the example in figure to use a program with the programmer simply runs the program as ruby program the ruby script in turn sets up the ruby environment before running the target program program for each class whose types should be inferred the programmer adds a call to infer types method during the class definition line note that in ruby class definitions are executed to create the class and hence methods can be invoked as classes are defined for classes with annotated types the programmer calls method with a string for each type to be declared for example on line we declare that string insert takes a numeric and string and returns a string as another example on line we declare that string takes a argument that has a to s method and returns a string we support the full type annotation language from including intersection types and discussed below finally the programmer also needs to define several test cases which are run when the program is executed by after runs the test cases it solves the generated constraints and outputs the inferred types examples in section next we briefly discuss details of the instrumentation process constraint resolution and some limitations of our implementation classes wrapped objects v are implemented as instances of a class that has three fields the object that is being wrapped its type and the owner of the which is the instance that was active when the was created when a method is invoked on a the objects method missing method will be called in ruby if such a method is defined it receives calls to any undefined methods here method missing does a little work and the call to the wrapped object to implement the with and constraint generation operations we use ruby to the class in particular we rename the current methods of each class and then add method missing to perform work before and after to the method we need to classes to our algorithm as the program code were tracking creates ordinary ruby objects whose method invocations we need to on entry to and exit from a method we perform all of the constraint generation and according to figure note that we perform both the caller and the actions in the method missing this is convenient because it allows us rely on builtin dynamic dispatch to find the right callee method whereas if we did work in the caller we would need to dynamic dispatch algorithm moreover it means we can naturally handle via send which performs reflective method invocation since we are working in the callee we need to do a little extra work to access the caller object inside of each class we add an extra field that points to the object that most recently a call to this object we set the field whenever a is used to invoke a method also recall that each has an owner field which was set to self at the time the was created since we wrap arguments and fields whenever we enter a method this means all objects accessible from the current method are always owned by self thus on entry to a callee we can find the caller object by immediately getting its dispatching and then finding the owner of that finally notice that the above discussion suggests we sometimes need to access the fields of an object from a different object this is when trying to read and write fields normally but there is an escape we can access field f of o from anywhere by calling o instance eval f in our formalism we assumed fields were only accessible from within the enclosing object thus we may be unsound for ruby code that uses instance eval to break the normal access rules for fields as we do annotated classes as with classes we annotated classes to calls to them and we perform constraint generation and for the caller side only as in figure we also fully any arguments to the method before to the original method we do this to support annotations on core library methods which are actually implemented as native code and expect regular rather than objects the actual method annotations for classes are stored in the class object and can thus be from the method by self class for some methods the calls to the original method all the arguments for example we forward calls to and hash so wrapped objects will be treated correctly within collections includes support for polymorphic class and method types if a class has a polymorphic type signature eg at we instantiate its type parameters with fresh type variables whenever an instance is created we store the instantiated parameters in the instance so that we can substitute them in when we look up a method signature for methods that are polymorphic we instantiate their type parameters with fresh type variables at the call we also support intersection types for methods which are common in the ruby core library if we invoke and om has signature a b c d we use the runtime type of x to determine which branch of the intersection applies recall we trust type annotations so if the branches overlap then either branch is valid if both apply constraint solving and type reconstruction we a program by running it under a test suite and generating subtyping constraints which are stored in at run time at the end we check the consistency of the subtyping constraints and solve them to types for methods the type language for reconstruction is simple as outlined in section we do not try to polymorphic or intersection types for methods consequently the algorithms we use are fairly standard we begin by computing the transitive closure of the subtyping constraints to put them in a solved form then we can essentially read off the solution for each type variable first we set method return type variables to be the union of their immediate lower bounds then we set method argument type variables to be the intersection of their immediate upper bounds these steps correspond to finding the least type for each method then we set the remaining type variables to be either the union of their or intersection of their depending on which is available finally we check that our solved constraints in which type variables are replaced by their solutions are consistent limitations there are several limitations of our current implementation beyond what has been mentioned so far first for we allow calls to methods whose classes are neither marked with infer types nor provided with annotations we do nothing special to support this case and it is up to the programmer to ensure the resulting program behavior will be reasonable second we do not wrap false and nil because those two values are treated as false by conditionals whereas wrapped versions of them would be true thus we may miss some typing constraints however this is to be a problem because the methods of false and nil are invoked for consistency we also do not wrap true third has no way to the creation of array and hash literals and thus initially treats such a literal as having elements of type the first time a method is invoked on an array or hash literal iterates through the container elements to infer a more precise type thus if an array or hash literal is returned before one of its methods is invoked will use the less precise for the element type for the constraint on the return variable this limitation is an we will address soon fourth for soundness we would need to treat global variables similarly to instance and class fields we but do not current implement this fifth ruby includes looping constructs and hence there are potentially an infinite number of paths through a method body with a loop however as the foo example at the end of section illustrates if types of the state are invariant the number of loop iterations is as long as all internal paths are covered we manually the code in our benchmarks section and found that types are in fact invariant across loops note that looping constructs in ruby actually take a code block essentially a firstclass the loop body if we could assign type variables to all the inputs and outputs of such blocks we could eliminate the potential at loops however ruby does not currently provide any mechanism to code block creation or to the behavior of a code block we currently do not support annotations on some lowlevel classes such as io thread exception proc and class also if methods are defined during the execution of a test case will not currently them we expect to add handling of these cases in the future style tc test cases p paths loc tc e p e manual edits line coverage method coverage total of methods path coverage ot original running time rt running time figure results finally in infer types is a annotation either all methods in a class have inferred types or none do however it is fairly common for ruby programs to existing classes or inherit from annotated classes in these cases we would like to infer method signatures for just the newly added methods we plan to add support for doing so in the future experiments we ran on small programs obtained from and ruby we ran on a mac pro with two core processors with gb of memory running mac os x version figure our results the column are defined at the bottom of the figure the first group of columns shows the program size in terms of lines of code via the number of test cases distributed with the benchmark and the number of manual edits made which includes rewriting array and hash literals and inserting calls to infer types for the benchmark two of the edits ensure the test code is called only once across all tests without this change the constraint solver does not complete in a reasonable amount of time for all benchmarks when calculating the lines of code number of methods and manual edits made we testing code for style we also did not count about lines of the source file that occur after end tag which tells the interpreter to ignore anything below that line in this case those lines contain static data that the program loads at runtime by reading its own source file the next group of columns gives the line coverage from the test cases computed by the method coverage the sum of the number paths in covered methods and the percentage of these paths covered by the test cases as does not compute path coverage we determined the last two metrics by each method we inserted print statements on every branch of the program to record which branches were taken at run time we then manually analyzed this information to determine path coverage when considering paths we tried to infeasible paths eg conditionals with overlapping guards and paths that only errors the path coverage is generally high with the exception of and style which have long methods with sequences of conditionals that create an exponential number of paths we manually the source code of the benchmark programs and we determined that for the methods that were covered the type annotations inferred by are correct it is interesting that the annotations are correct even for the two programs with low path coverage this suggests that for these programs reasonable line coverage is sufficient to infer sound types also found one type error which we discuss below performance the last group of columns in figure reports running time which we split into the time to and run the instrumented program and the time to solve the generated constraints as we can see the overhead of running under even solving time is quite high compared to running the original program part of the reason is that we have not optimized our implementation and our heavy use of wrappers likely fast paths in the ruby interpreter for example values of primitive types like numbers are not really implemented as objects but we wrap them with objects nevertheless we believe that some overhead is acceptable because inference need not be performed every time the program is run the solving time is high but that is likely because our solver is written in ruby which is known to be slow this is being addressed in versions of ruby we expect this solving time would decrease if we exported the constraints to a solver written in a different language inferred types we now describe the benchmark programs and show some example inferred types as output by generates simple statistical information on numerical data sets as an example inferred type consider the method which computes a from a list of numbers sort size numeric numeric numeric numeric the method takes an object that has sort size and methods and returns a numeric thus one possible argument would be an array of numeric however this method could be used with other arguments that have those three because ruby is dynamically typed programmers are required to pass in objects of exactly a particular type as long as the objects have the right methods this is referred to as typing in the ruby community another mathematical library provides basic operations on elements in a finite field as an example type consider the inverse method which a matrix inverse numeric boolean numeric numeric numeric numeric numeric numeric numeric numeric numeric as above we can see exactly which methods are required of the argument one concrete class that has all these methods is numeric encodes and data following format there are only two methods in this program both of which are covered by the test cases issues an error during the constraint solving that boolean is not a subtype of to i numeric the parts of the code are shown below module def self wrap lines if wrap lines then return end wrap lines to i end end the author of the library uses wrap lines as an optional argument with a default value of in one test case the author passes in false hence wrap lines may be a boolean but as boolean does not have a to i method invoking wrap lines to i is a type error for example passing true as the second argument will cause the program to crash it is whether the author to allow true as a second argument but clearly wrap lines can potentially be an arbitrary since its to i method is invoked which would not be necessary for an integer is a solution for the a search problem it includes a class tile to represent a position on a map infers that two of the methods to tile have types y numeric x numeric the map class uses tile which we can see from the inferred types for two of maps methods adjacent y numeric x numeric find push y numeric x numeric include y numeric x numeric boolean pop y numeric x numeric to the adjacent method computes a set of adjacent locations represented as an given an input tile the find method returns an array of tile which is an instance of the slightly more precise structural type infers here the structural type is actually the type of a field returned by find is a program that converts to and vice versa one method type we inferred is numeric numeric boolean this method determines whether the year is a year this signature is interesting because the argument only needs a single method which returns a numeric this is the only requirement because subsequent operations are on the return value of rather than on the original method argument is a solver as this program did not come with a test suite we constructed a test case ourselves one of the four edits we made to the program some of the inferred types are shown below initialize we can see that the and initialize methods return a representation of the as an style is a analysis tool for the program has several methods that determine characteristics of text some sample inferred types are string boolean passive each boolean string boolean abbreviation string boolean string boolean string boolean string string here most of the methods first their argument and then use the resulting string the passive method takes an array of strings representing a sentence and iterates through the array to determine whether the sentence is in the passive finally is a tool that us address into different as an example the parse class method takes a string and returns an instance of the class which is depicted in the following output class define a class method parse string end notes we encountered all of limitations in these benchmark were tests that called out to and classes that use false and nil that use global variables and that use lowlevel classes like io however as already mentioned the types inferred were correct and so these limitations did not affect the results we also encountered the use of reflective method invocation via send described in section we did not uses of other dynamic features for classes whose types are inferred though they do occur internally in the standard library related work there has been significant interest in the research community in static type systems to dynamic languages much recent research has developed ways to mix typed and untyped code eg via quasistatic typing occurrence typing gradual typing and hybrid typing in these systems types are supplied by the user in contrast our work focuses on type inference which is complementary we could potentially use our dynamic type inference algorithm to infer type annotations for future checking several researchers have explored type inference for objectoriented dynamic languages including ruby python and javascript among others as discussed in the introduction these languages are complex and have subtle semantics typically only defined by the language implementation this makes it a major challenge to implement and maintain a static type inference system for these languages we this in our development of a static type inference system for ruby there has also been work on type inference for scheme a dynamic language with a very compact syntax and semantics however these inference systems do not support objects dynamic type inference has been explored previously in several contexts et al describe a dynamic type inference algorithm for smalltalk that takes advantage of features of that language however their algorithm is not very clearly explained and seems to infer types for variables based on what types are stored in that variable in contrast we infer more general types based on usage constraints for example back in figure we discovered argument x must have a method whereas we believe the approach of et al would instead infer x has type b which is correct but less general et al dynamically infer abstract types in x and java bytecode et al propose a combined static and dynamic inference algorithm in both of these systems the inferred types have no the former system abstract types are essentially tags that group together values that are related by the program and in the latter system parameters and fields are either mutable or not in contrast our goal is to infer more standard structural or nominal types in addition to inferring types dynamic analysis has been proposed to discover many other program properties to three ex likely program invariants from dynamic runs uses symbolic execution to infer invariants and temporal properties of programs in these systems there is no notion of sufficient coverage to guarantee sound results in contrast we showed we can soundly infer types by covering all paths through each method there are several dynamic inference systems that while they have no theorems about sufficient coverage do use a subsequent checking phase to test whether the inferred information is sound et al and and dynamically infer types that protect against races after inference the program is annotated and passed to a type checker to verify that the types are sound similarly and use to infer invariants that are then checked by we could follow a similar approach to these systems and apply to our inferred types when coverage is known to be incomplete we leave this as future work finally our soundness theorem soundness for mix a static analysis system that type checking and symbolic execution in mix blocks are introduced to which code should be analyzed with symbolic execution and which should be analyzed with type checking at a highlevel we could model our dynamic inference algorithm in mix by analyzing method bodies with symbolic execution and method calls and field reads and writes with type checking however there are several important differences we use concrete test runs where mix uses symbolic execution we operate on an objectoriented language where mix applies to a conventional imperative language and we can model the heap more precisely than mix because in our formal language fields are only accessible from within their containing objects conclusion in this paper we presented a new technique dynamic type inference that infers types based on dynamic executions of the program we have proved that this technique infers sound types as long as all possible paths through each method are traversed during inference we have developed an implementation of our technique for ruby and have applied it to a number of small ruby programs to find a real error and to accurately infer types in other cases we expect that further engineering of our tool will improve its performance we also leave the inference of more advanced types including polymorphic and intersection types to future work acknowledgments we would like to thank mark t for his work on the type annotation parser most of this work was performed while the first and second authors were at the university of college park this work was supported in part by nsf and references and scott d type inference for parameterized java in o j palsberg and mi type inference of self ecoop david an and jeffrey s foster static typing for ruby on in and dynamically and statically typed oo languages in christopher and towards type inference for javascript in ecoop david and michael d combined static and dynamic analysis in john type inference in international python conference and dynamic symbolic execution for invariant inference in michael d h philip j matthew s and chen the system for dynamic detection of likely invariants sci comput program michael david an and jeffrey s foster static typing for dynamic languages in oopsla michael david an jeffrey s foster and michael the ruby intermediate language in dynamic language symposium michael david an jeffrey s foster and michael static type inference for ruby in track j k a sn and c flanagan hybrid checking for flexible specifications scheme and functional programming philip j h and michael d dynamic inference of abstract types in and jeffrey s foster type checking and symbolic execution in pldi ­ type inference for ruby using the cartesian product algorithm thesis university robin milner a theory of type polymorphism in programming journal of computer and system sciences type inference in ruby of code project w and michael d invariant inference for static checking an empirical evaluation in pascal and dynamic type inference to support objectoriented in smalltalk in ecoop code coverage for ruby james and michael dynamic inference of polymorphic lock types sci comput program ruby michael a static type and compiler for python thesis mit g siek and gradual typing for functional languages in scheme and functional programming workshop quasistatic typing in popl peter towards a type system for analyzing javascript programs in esop thomas and programming ruby the pragmatic programmers guide pragmatic and matthias felleisen the design and implementation of typed scheme in popl david a august ak wright and r cartwright a practical soft type system for scheme acm toplas yang david and temporal api rules from traces in 