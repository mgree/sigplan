on characterizing the data access complexity of programs the state university j state university inria the state university p the state university abstract technology will cause data movement to account for the of energy and execution time on computers therefore computational complexity will no longer be a sufficient metric for comparing algorithms and a fundamental characterization of data access complexity will be important the problem of developing lower bounds for data access complexity has been modeled using the formalism of pebble game for computational directed acyclic graphs however previously developed approaches to lower bounds analysis for the pebble game are very limited in effectiveness when applied to of real programs with computations of multiple with dag structure we address this problem by developing an approach for effectively composing lower bounds based on graph decomposition we also develop a static analysis algorithm to derive the asymptotic lower bounds of programs as a function of the problem size and cache size categories and subject descriptors f analysis of algorithms and problem complexity general d software metrics complexity measures general terms algorithms theory keywords data access complexity io lower bounds pebble game static analysis introduction advances in technology over the last few have significantly different of improvement in the computational performance of processors relative to the speed of memory access because of the significant between computational and when compared to main memory and the use of hierarchical memory systems and the of significant data reuse in the faster ie higher levels of the memory hierarchy is critical for high performance with future sys permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ copyright is held by the publication to acm acm the cost of data movement through the memory hierarchy is expected to become even more relative to the cost of performing arithmetic operations both in terms of time and energy it is therefore of critical importance to limit the volume of data movement memory by data reuse in registers and higher levels of the cache thus the characterization of the inherent data access complexity of computations is extremely important i n i j n j ai j ai j ai j a code for it it n it t for n t it i min it t n i j min t n j ai j ai j ai j b equivalent code c cdag figure code let us consider the code shown in fig a its computational complexity can be simply stated as n arithmetic operations fig b shows a equivalent form of the same computation after a tiling transformation the form too has exactly the same computational complexity of n arithmetic operations next let us consider the data access cost for execution of these two code forms on a processor with a single level of cache if the problem size n is larger than cache the number of cache misses would be higher for the version fig a than the version fig b but if the cache size were sufficiently large the version would not offer any benefits in reducing cache misses thus unlike the computational complexity of an algorithm which unchanged for different valid orders of execution of its operations and also independent of machine parameters like cache size the data access cost depends both on the cache and the order of execution of the operations of the algorithm a fundamental question therefore is given a computation and the amount of storage at different levels of the hierarchy what is the minimum possible number of data transfers at the different levels among all valid schedules that perform the operations in order to model the range of valid scheduling orders for the operations of an algorithm it is common to use the abstraction of the computational directed acyclic graph cdag with a vertex for each instance of each computational operation and edges from producer instances to consumer instances fig c shows the cdag for the codes in fig a and fig b for n although the relative order of operations is different between the and versions the set of computation instances and the relationships for the flow of data are exactly the same special input vertices in the cdag represent values of elements of a that are read before they are written in the nested loop while in general it is to precisely answer the above fundamental question on the absolute minimum number of data transfers between main memory and among all valid execution schedules of a cdag it is feasible to develop lower bounds on the optimal number of data transfers an approach to developing a lower bound on the minimal data movement for a computation in a twolevel memory hierarchy was addressed in the work of by using the model of the pebble game on a computational directed acyclic graph cdag while the approach has been used to develop io lower bounds for a small number of computational kernels as later it challenges for effective analysis of full applications that are of a number of parts with cdag structure in this paper we address the problem of analysis of affine loop programs to develop lower bounds on their data movement complexity the work presented in this paper makes the following contributions · enabling composition in analysis of data access lower bounds it the pebble game model on and the associated model of under a restriction that thereby enabling effective composition of io lower bounds for composite from lower bounds for component · static analysis of programs for lower bounds characterization it an approach for asymptotic parametric analysis of lower bounds for arbitrary affine loop programs as a function of cache size and problem size this is done by analyzing linearly independent families of dependence chains background computational model we are interested in modeling the inherent data access complexity of a computation defined as the minimum number of data elements to be moved between local memory with limited but fast access by the processor and main memory much slower access but among all valid execution orders for the operations making up the computation while the key developments in this paper can be naturally extended to address memory hierarchies and parallel execution using an approach like the multiprocessor memory hierarchy game model of we restrict the treatment in this paper to the case of only two levels of memory hierarchy and sequential execution the model of computation we use is a computational directed acyclic graph cdag where computational operations are represented as graph vertices and the flow of values between operations is captured by graph edges fig shows an example of a cdag corresponding to a simple loop program two important characteristics of this abstract form of representing a computation are that there is no specification of a particular order of execution of the operations although the program executes the operations in a specific sequential order the cdag abstracts the schedule of operations by only specifying partial ordering constraints as edges in the graph there is no association of memory locations with the source operands or result of any operation labels in fig are only shown for explanation they are not part of the formal description of a cdag for i i i s ai ai s a a a a figure example of a cdag input vertices are represented in black output vertices in grey we use the notation of to formally describe the cdag model used by definition a computational directed acyclic graph cdag is a tuple c iv e o of finite sets such that i v is the input set and all its vertices have no incoming edges e v × v is the set of edges g v e is a directed acyclic graph v i is called the operation set and all its vertices have one or more incoming edges o v is called the output set the pebble game used this computational model in their work the inherent io complexity of a cdag is the minimal number of io operations needed while the pebble game this game uses two kinds of pebbles a fixed number of red pebbles that represent the small fast local memory could represent cache registers etc and an arbitrarily large number of blue pebbles that represent the large slow main memory definition pebble game let c iv e o be a cdag such that any vertex with no incoming resp outgoing edge is an element of i resp o given s red pebbles and an arbitrary number of blue pebbles with an initial blue pebble on each input vertex a complete calculation is any sequence of steps using the following rules that results in a final configuration with blue pebbles on all output vertices r input a red pebble may be placed on any vertex that has a blue pebble load from slow to fast memory r output a blue pebble may be placed on any vertex that has a red pebble store from fast to slow memory r compute if all immediate predecessors of a vertex v v i have red pebbles a red pebble may be placed on or moved to v execution or of operation the original pebble game in does not allow a red pebble from a predecessor vertex to a successor we chose to allow it since it reflects real instruction set architectures others have also considered a similar modification but all our proofs hold for both the variants figure example of schedule for a complete calculation on cdag in fig the vertex numbers represent the order of execution r delete a red pebble may be removed from any vertex reuse storage the number of io operations for any complete calculation is the total number of moves using rules r or r ie the total number of data between the fast and slow memories the inherent io complexity of a cdag is the smallest number of such io operations that can be achieved among all complete for that cdag an optimal calculation is a complete calculation achieving the minimum number of io operations fig shows an example schedule for the cdag in fig given s red pebbles and blue pebbles goal of the game is to begin with blue pebbles on all input vertices and finish with blue pebbles on all output vertices by following the rules in definition without using more than s red pebbles considering the case with three red pebbles s one possible complete calculation for the cdag in fig is r r r r r r r r r r r r r r r r r r r r the io cost of this complete calculation is which corresponds to the number of moves using rules r and r a different complete calculation for the same cdag with io cost of is given by r r r r r r r r r r r r r r r r r r r r r r r r the io complexity of the cdag is the minimum io cost of all such complete lower bounds on io complexity via while the pebble game provides an operational definition for the io complexity problem it is generally not feasible to determine an optimal calculation on a cdag developed a novel approach for deriving io lower bounds for by relating the pebble game to a graph partitioning problem defined as follows definition of a cdag let c iv e o be a cdag an of c is a collection of h subsets of v such that p i j vi vj and h i vi v p there is no cyclic dependence between subsets p i d such that d s p i s where a dominator set of vi d is a set of vertices such that any path from i to a vertex in vi contains some vertex in d the minimum set of vi is the set of vertices in vi that have all its successors outside of vi and for a set a a is the cardinality of the set a showed a construction for a of a cdag corresponding to any complete calculation on that cdag using s red pebbles with a tight relationship between the number of vertex sets h in the and the number of io moves q in the complete calculation as shown in theorem the tight association between any complete calculation and a corresponding provides the key lemma that serves as the basis for approach for deriving lower bounds on the io complexity of typically by reasoning on the maximal number of vertices that could belong to any in a valid theorem pebble game io and any complete calculation of the pebble game on a cdag using at most s red pebbles is associated with a of the cdag such that s h q s h where q is the number of io moves in the complete calculation and h is the number of subsets in the lemma lower bound on io let h be the minimal number of vertex sets for any valid of a given cdag such that any vertex with no incoming ­ resp outgoing ­ edge is an element of i ­ resp o then the minimal number q of io operations for any complete calculation on the cdag is bounded by q s × h this key lemma has been useful in proving io lower bounds for several by reasoning about the maximal number of vertices that could belong to any in a valid challenges in composing io lower bounds from partitioned application codes are typically constructed from a number of using the fundamental composition mechanisms of sequencing iteration and recursion as explained in sec in contrast to analysis of computational complexity of such composite application codes io complexity analysis challenges with computational complexity the operation counts of can simply be added however using the pebble game model of as below it is problematic to analyze the io complexity of and simply combine them by addition in the next section we develop an approach to overcome the problem the decomposition problem the pebble game model places blue pebbles on all cdag vertices without predecessors since such vertices are considered to hold inputs to the computation and therefore assumed to start off in slow memory similarly all vertices without successors are considered to be outputs of the computation and must have blue pebbles at the end of a complete calculation if the vertices of a cdag corresponding to a composite application are partitioned into the analysis of each will require the initial placement of blue pebbles on all vertices without predecessors in the and final placement of blue pebbles on all vertices without successors in the so an optimal calculation for each will require at least one load r operation for each input and a store r operation for each output but in a complete calculation on the full composite cdag clearly it may be possible to pass values in a red pebble between vertices in different so that the io complexity could be less than the sum of the io costs for optimal on each this is illustrated by the following example fig b shows the cdag for the computation in fig a fig c shows the cdag partitioned into two where the first contains vertices of s and s and the input vertices corresponding to ai and bi and the second contains vertices of s and s considering the full cdag with just two red pebbles it can be computed at an io cost of io just for the initial loads of inputs ai and bi and the final stores for outputs fi in contrast with the partitioned the first will additional output stores i i ci ai bi s i i di ci ci s i i ei ci di s i i fi di ei s a original code a b a b a b a b ci di ei fi b full cdag a b a b a b a b ci di ei fi c cdag partitioning with s and s only with s and s only figure example limitation of model regarding composition of lower bounds from of cdag for the vertices si and the second will input loads for vertices si thus the sum of optimal pebble game io costs for the two amounts to moves ie it the optimal io cost for the full cdag the above example illustrates a fundamental problem with the pebble game model a simple combining of io lower bounds for of a cdag cannot be used to generate an io lower bound for the composite cdag but the ability to perform complexity analysis by combining analyses of component is important for the analysis of real applications such decomposition of complexity analysis can be enabled by making a change to the pebble game model as discussed next flexible inputoutput vertex labeling to enable composition of lower bounds with the model all vertices without predecessors must be input vertices and all vertices without successors must be output vertices by this constraint we show that composition of lower bounds from is valid with such a modification vertices without predecessors will not be required to be input vertices and such vertices do not have an initial blue pebble placed on them however such vertices are allowed to using rule r at any time since they do not have any predecessor nodes without red pebbles vertices without successors are similarly not required to be output vertices and those not designated as outputs do not need a blue pebble on them at the end of the game however all compute vertices ie vertices in v i in cdag are required to have for any complete calculation using the modified model of the pebble game with flexible inputoutput vertex labeling it is feasible to compose io lower bounds by adding lower bounds for partitioned of a cdag the following theorem formalizes it theorem decomposition let c iv e o be a cdag let vv vp be an arbitrary not necessarily acyclic disjoint partitioning of v p i vi and p i vi v and cc cp be the induced partitioning of c ii i vi ei c proof consider an optimal calculation p for c with cost q we define the cost of p restricted to vi denoted as as the number of q r or r transitions ip we will in p show that that involve a vertex of we can build from vi p clearly a valid complete qi for ci of cost qi ip q this will prove that is built from p as follows for any transition in p that involves a vertex v vi apply this transition in delete all other transitions in p conditions for transitions r r and r are trivially satisfied whenever a transition r on a vertex v is performed in p all the predecessors of v must have a red pebble on them since all transitions of p on the vertices of vi are maintained in when v is executed in all its predecessor vertices must have red pebbles enabling transition r with this modified model of the pebble game that permits vertices to be vertices complex can be decomposed and lower bounds for the composite cdag can be obtained by composition of the bounds from the however that have no true input and output vertices in them will have trivial io lower bounds of zero ­ the entire set of vertices in the can fit in a single vertex set for a valid for any value of s since conditions pp are trivially satisfied in the next section we present a solution to the problem the main idea is to impose restrictions on the pebble game to or multiple of any vertex using rule r we show that by such a restriction we can develop an inputoutput tagging strategy for that enables stronger lower bounds to be generated by cdag decomposition when is with the pebble game model of the compute rule r could be applied multiple times in a complete calculation this is useful in modeling algorithms that perform of multiply used values rather than the overhead of storing and loading it however the of practically used algorithms do not perform any redundant hence several efforts ­ have modeled io complexity under a more restrictive model that primarily because it or enables analysis with some lower bounding techniques in this section we consider the issue of composing bounds via cdag decomposition under a model that ie we develop a modified definition of that is adapted to enable io lower bounds to be developed for the restricted pebble game this provides two significant benefits it enables nontrivial io lower bound contributions to be ac from of a cdag even when the do not have any true inputs this is achieved via inputoutput strategies we develop in this section it enables static analysis of programs to develop parametric expressions for asymptotic lower bounds as a function of cache and problem size parameters this is described in the following sections a pebble game model that does not allow can be formalized by changing rule r of the pebble game to nr denotes or and the definition of a complete calculation as follows definition pebble game let c iv e o be a cdag given s red pebbles and arbitrary number of blue pebbles with an initial blue pebble on each input vertex a complete calculation is any sequence of steps using the following rules that causes each vertex in v i to be once using rule and results in a final configuration with blue pebbles on all output vertices r input a red pebble may be placed on any vertex that has a blue pebble load from slow to fast memory r output a blue pebble may be placed on any vertex that has a red pebble store from fast to slow memory compute if all immediate predecessors of a vertex v v i have red pebbles on them and a red pebble has not previously been placed on v a red pebble may be placed on v r delete a red pebble may be removed from any vertex reuse storage we next present an adaptation of and that will enable us to develop larger lower bounds for the restricted pebble game model that definition of cdag given a cdag c an of c is a collection of h subsets of v i such that p i j vi vj and h i vi v i p there is no cyclic dependence between subsets p i s p i s where the input set of vi is the set of vertices of v vi that have at least one successor in vi the output set of vi is the set of vertices of vi that are also part of the output set o or that have at least one successor outside of vi theorem restricted pebble game io and any complete calculation of the pebble game without on a cdag using at most s red pebbles is associated with a of the cdag such that s × h q s × h where q is the number of io moves in the game and h is the number of subsets in the proof consider a complete calculation p that corresponds to some scheduling ie execution of the vertices of the graph g v e that follows the rules of the restricted pebble game we view this calculation as a string that has recorded all the transitions ap of pebble game rules suppose that p contains exactly q transitions of type r or r let p p ph correspond to a partitioning of the transitions of p into h qs consecutive such that each pi p ph contains exactly s transitions of type r or r the cdag contains no node isolated from the output nodes and any vertex of v i is computed exactly once in p let vi be the set of vertices computed transition in the pi property p is trivially as transition on a vertex v is possible only if its predecessor vertices have red pebbles on them those predecessors are necessarily executed in some p j j i and are thus part of a vj j i this proves property p to prove p for a given vi we consider two sets vr is the set of vertices that had a red pebble on them just before the execution of pi is the set of vertices on which a red pebble is placed according to rule r input during pi we have vr thus vr as there only s red pebbles vr s also by construction of pi s this proves that s property p property p is proved in a similar way vr is the set of vertices that have a red pebble on them just after the execution of pi is the set of vertices of vi during pi according to rule r thus vr s also by vr construction on which a blue pebble is placed we have that vr as there are only s red pebbles of pi s this proves that s property p lemma io lower bound for restricted pebble game let be the minimal number of vertex sets for any valid of a given cdag then the minimal number q of io operations for any complete calculation on the cdag without any is bounded by q s × the above theorem and lemma establish the relationship between complete of the restricted pebble game and partitions the critical difference between the standard of and the partition is the validity condition to incoming edges into a vertex set in the partition for the former the size of dominator sets is constrained to be no more than s while for the latter the number of external vertices with edges into the vertex set is constrained by s when a cdag is decomposed into very often some of the get isolated from the input and output vertices this will lead to trivial ie zero lower bounds for such component for the restricted pebble game below we develop an approach to obtain lower bounds for component that have become isolated from inputs and outputs of the full cdag the key idea is to allow any vertex without predecessors resp successors to simulate an input resp output vertex by tagging it so and then the obtained lower bound to account for a access cost for loading resp storing such a tagged input resp output the vertices of a cdag remain unchanged but the labeling tag of some vertices as in the cdag is changed theorem inputoutput ­ restricted pebble game let c and c be two of the same dag g v e c iv e o c i div e o do where di v and do v if q is the io complexity for c and q is the io complexity for c then q can be bounded by q as follows tagging q di do q q can be bounded by q as follows q q proof consider an optimal calculation p for c of cost q we will build a valid complete calculation p for c of cost no more than q di do this will prove that q q di do we build p from p as follows for any input vertex v di the only transition r involving v in p is replaced in p by a transition r for any output vertex v do the only transition r involving v in p is by an r transition any other transition in p is reported as is in p consider now an optimal calculation p for c of cost q we will build a valid complete calculation p for c of cost no more than q this will prove that q q we build p from p as follows for any input vertex v di the first transition r involving v in p is replaced in p by a transition r followed by a transition r any other transition in p is reported as is in p we note that such a construction is only possible for the restricted pebble game where is it enables lower bounds to be developed via cdag decomposition in the next section we use partitioning and the theorem in developing a static analysis approach to characterizing lower bounds of loop programs parametric lower bounds via static analysis of programs in this section we develop a static analysis approach to derive asymptotic parametric io lower bounds as a function of cache size and problem size for affine computations affine computations can be modeled using union of convex sets of integer points and union of relations between these sets the motivation is first there exists an important class of affine computations whose control and data flow can be modeled exactly at compiletime using only affine forms of the loop iterators surrounding the computation statements and program parameters constants whose values are unknown at compiletime many linear algebra computations image processing algorithms finite difference methods etc belong to this class of programs second there exist readily available tools to perform complex geometric operations on such sets and relations we use the integer set library for our analysis in subsection we provide a description of the program representation for affine programs in subsection we detail the geometric reasoning that is the basis for the developed io lower bounds approach subsection describes the io lower bound computation using examples background and program representation in the following we use terminology and syntax to describe sets and relations we now recall some key concepts to represent program features iteration domain a computation vertex in a cdag represents a dynamic instance of some operation in the input program for example given a statement s ai bi by one loop i n i the operation will be executed n times and each such dynamic instance of the statement corresponds to a vertex in the cdag for affine programs this set of dynamic instances can be represented as a union of ie a set of integer points bounded by affine in equalities with an affine integer lattice using notation the iteration domain of statement s ds is denoted the lefthand side of n in the example is the list of all parameters needed to define the set si models a set with one dimension i named i and the set space is named s presburger formulae are used on the righthand side of to model the points belonging to the set in these sets are of conjunctions of presburger formulae thereby modeling unions of convex and integer sets the dimension of a set s is denoted as in the example above the cardinality of set s is denoted as s s n for the example standard operations on sets such as union intersection projection along certain dimensions are available in addition key operations for analysis such as building counting polynomials for the set ie polynomials of the program parameters that model how many integer points are contained in a set n in our example and parametric integer linear programming are possible on such sets these operations are available in we remark that although our analysis relies on integer sets and their associated operations it is not limited to programs that can be exactly captured using such sets eg purely affine programs since we are interested in computing lower bounds on io an underapproximation of the statement domain andor the set of dependences is acceptable since an io lower bound for the approximated system is a valid lower bound for the actual system for instance if the iteration domain ds of a statement s is not described exactly using presburger formulae we can this set by taking the largest convex polyhedron ds ds such a polyhedron can be obtained for instance by first computing the convex hull ds ds and then its until they are strictly included in ds we also remark that such sets can be extracted from an arbitrary cdag again using approximations by means of trace analysis and especially trace compression techniques for vertices modeling the same computation relations in the graph g v e of a cdag c iv e o vertices are connected by edges capturing the data flow between operations similar to iteration domains affine forms are used to model the relations between the points in two sets such relations capture which data is accessed by a dynamic instance of a statement as in classical dataflow analysis in the example above elements of array b are read in statement s and the relation r describing this access is bi in this relation models a single edge between each element of set s and an element of set b described by the relationship i i several operations on relations such as which computes the domain eg input set of the relation n i in computing the image eg range or output set of r n i in the composition of two relations r r their union intersection difference and the transitive closure r of a relation are available all these operations are supported by relations can also be used to directly capture the connections between computation vertices for instance given two statements s and s with a relationship the edges connecting each dynamic instance of s and s in a cdag can be expressed using relations for example models a relation between a d statement and a d statement each point in s is connected to several points in s along the we note that in a similar manner to iteration domains for vertices relations can also be extracted from programs via convex underapproximation or from the cdag via trace analysis again care must be taken to always properly the relations capturing data dependences it is safe to ignore a dependence it can only lead to underapproximation of the data flow and therefore the io requirement and therefore we only consider in our analysis framework geometric reasoning for io lower bounds by given a cdag lemma establishes a relation between a lower bound on its data movement complexity for execution with s fast storage elements and the minimal possible number of vertex sets among all valid of the cdag the minimum possible number of vertex sets in a is related to the largest possible size of any vertex set for a valid a geometric reasoning based on the inequality and its generalization has been used to establish io lower bounds for a number of linear algebra algorithms a novel approach to determining io lower bounds for affine computations in nested loops has been recently developed using similar geometric reasoning the approach developed in this paper is inspired by that work and also uses a similar geometric reasoning but improves on the prior work in two significant ways generality it can be applied to a class of computations handling multiple statements and nested loops bounds for computations with that are not oriented along one of the iteration space dimensions it provides io lower bounds as illustrated by the example in the next section before presenting the details of the static analysis for lower bounds characterization of affine computations we use a simple example to illustrate the geometric approach based on the inequality and its that have been used to develop io lower bounds for and other linear algebra computations consider the code an force calculation in fig a we have a d iteration space with n points the net force on each of n from the other is computed using the function f which uses the mass and position of a pair of to compute the force between them the total number of input data elements for the computation is n if s n it will be necessary to bring in at least some of the input data elements more than once from slow to fast memory a geometric reasoning for a lower bound on the amount of io fast memory proceeds as follows consider an arbitrary vertex set from any valid let the set of points p in the iteration space illustrated by a in fig b denote the vertex set the projections of each of the points onto the two iteration space are shown let pi and p j respectively denote the number of distinct points on the i and j pi represents the number of distinct elements of input arrays pos and mass that are accessed in the computation for references and similarly p j corresponds to the number of distinct elements accessed via the references and for any vertex set from a valid the size of the input set cannot s hence × pi s and × p j s for this d example the inequality asserts that the number of points in p cannot pi × p j combining the two inequalities we can conclude that s is an upper bound on the size of the vertex set thus the minimum number of vertex sets in a valid h ns by lemma a lower bound on io is h × s ie ns i ni j nj if i j force i a code for force calculation b geometric projection figure illustration of geometric reasoning for io lower bounds more generally for a iteration space given some bounds on the number of elements on some projections of p a bound on p can be derived using a powerful approach developed by et al et al theorem extended the discrete case of the inequality theorem to obtain these bounds since our goal here is to develop asymptotic parametric bounds the extension of the continuous inequality stated below in the restricted case of orthogonal projections and using the measure for is sufficient for our analysis we use the notation h rd to denote that h is a linear of rd theorem let j rd be an orthogonal projection for j m such that y where y x then for s sm m m h rd s j j m e rd e j since the linear transformations j are orthogonal projections the following theorem enables us to limit the number of of eq required for theorem to hold only one inequality per hi defined as the linear span of the canonical vector ei is required ei represents the by the vector with a nonzero only in the ith coordinate theorem let j rd be an orthogonal projection for j m such that y where y x then for s sm m m h rd s j j m hi ei j j where i j the proof of theorem directly corresponds to the proof of theorem and is omitted see also prop it shows that if s s sm m are such that hi mj j then the volume of any measurable set e rd can be bounded by us mj in order to obtain as tight an asymptotic bound as possible we s such that us is as small as possible since we have s this corresponds to finding s j such that mj is or equivalently sj is in other words mj s j has to be for this purpose if i j st i j we solve mm minimize s j st i s ji j j j we can instead solve the following dual problem whose solution gives an of the shape of the optimal dd xi st j j i i we use an example i ni j nj fork k nk consider the following three projections we explain how the projection directions are obtained later in this section i j k i j i j k i k i j k k let h h and h denote the three by the canonical bases of r consider for example the linear map we have for any h h for any h h and for any h h thus we obtain the constraint x x x or x x similarly we obtain the remaining two constraints for the projections and this results in the following linear programming problem x x x st x x x x x solving eq provides the solution x x x ie x x x the solution corresponds to considering a of asymptotic dimensions × s × s and volume xj os as the largest this provides an io lower bound of ns when the problem size n is sufficiently large automated io lower bound computation we present a static analysis algorithm for automated derivation of expressions for parametric asymptotic io lower bounds for programs we use two examples to explain the various steps in the algorithm before providing detailed for the algorithm example consider the following example of d computation parameters n t inputs in outputs an for i i n i s ai ii for t t t t for i i n i s bi ai ai ai for i i n i s ai bi i e s e e e e e s e e e e s figure dataflow graph for d fig shows the static dataflow graph gf vf ef for d gf contains a vertex for each statement in the code the input array i is also explicitly represented in gf by node i in black in fig each vertex has an associated domain as shown below · di · ds · ds and in · ds and in the edges represent the true data dependences between the statements each edge has an associated affine dependence relation as shown below · edge e this edge corresponds to the dependence due to copying the inputs i to array a at statement s and has the following relation · edges e e and e the use of array elements ai ai and ai at statement s are captured by edges e e and e respectively · edges e and e multiple uses of the boundary elements i and in by at and respectively for tt are represented by the following relations · edge e the use of array b in statement s corresponds to edge e with the following relation and in · edges e e and e the uses of array a in statement s from s are represented by these edges with the following relations and in and in and in given a path p e el with associated edge relations r rl the relation associated with p can be computed by composing the relations of its edges ie rl · · · r for instance the relation for the path e e in the example obtained through the composition re re is given by rp tn further the domain and image of a composition are restricted to the points for which the composition can apply ie j ri j and j ri r j hence tn tt and in and tn tt and in two kinds of paths namely injective circuit and broadcast path defined below are of specific importance to the analysis definition injective edge and circuit an injective edge a is an edge of a dataflow graph whose associated relation ra is both affine and injective ie ra ax b where a is an invertible matrix an injective circuit is a circuit e of a dataflow graph such that every edge e e is an injective edge definition broadcast edge and path a broadcast edge b is an edge of a dataflow graph whose associated relation rb is affine and a broadcast path is a path e en of a dataflow graph such that e is a broadcast edge and are injective edges injective circuits and broadcast paths in a dataflow graph essentially indicate multiple uses of same data and therefore are good candidates for lower bound analysis hence only paths of these two kinds are considered in the analysis the current example of d computation illustrates the use of injective circuits to derive io lower bounds while the use of broadcast paths for lower bound analysis is explained in another example that follows injective circuits in the example we have three circuits to vertex s through s the relation for each circuit is computed by composing the relations of its edges as explained earlier the relations and the dependence vectors they represent are listed below · circuit c e e rc tn tt and t i figure original iteration domain space for d blue integer points of domain ds black arrows relation rc of circuit e e red frontier f gray box subset e and corresponding in black projection of the points inside gray box along the direction of black arrows onto the frontier in b t · circuit c e e rc tn tt and in b t · circuit c e e rc tn tt and in b t fig shows the domain ds and the relation rc as a for t n definition frontier the frontier f of a relation r with domain d is the set of points with no incoming edges in the corresponding f can be calculated using the set operation f d rd the frontiers f f and f for the three relations rc rc and rc respectively are listed below · f · f · f in fig points of frontier f are shown as red points due to the correspondence between a and a refer to sec each point in a frontier represents a source vertex ie vertex with no incoming edges of the it could be seen that there are fi i disjoint paths pi i as a consequence of the injective property of the relations in the c iv e o corresponding to the instances of statements s and s each with a distinct source vertex that corresponds to a point in fi these source vertices are tagged as inputs for the lower bounds analysis and their count fi is later from the final io lower bound using theorem let v be a of a valid of c there are a set of points e in the eg the set of points inside the gray colored box in fig corresponding to the set of points outside e with an edge to a point in e corresponds to in eg points marked with in fig since there is no cyclic dependence between the of the s partition and the paths are disjoint by starting from the vertices of in and tracing backwards along the paths in any pi i we should reach in s distinct source vertices this process corresponds to the set e along each of the directions bi i onto the frontier fi i hence we have s here denotes e along the direction bi the points of the frontier obtained by projection are shown as black over red in fig we ensure that e this allows us to apply the geometric reasoning discussed in sec to restrict the size of the set e as shown below since it is sufficient to consider any two linearly independent directions theorem applies only for projections along the orthogonal directions in case projection vectors are a sim ple change of basis operation is used to transform the space to a new space where the projection directions are the canonical bases in the example if we consider vectors bb and bb as the projection directions in the original space then the linear map bb bb will transform the to a new space where the projection directions are the canonical bases in the example after such transformation the projection vectors are t and t and hence we have the following two projections i j i i j j from eq we obtain the following inequalities for the dual problem refer x x in addition we also need to include constraints for the cases where the problem size considered may be small relative to the cache size s hence we have the following additional constraints for the example ex n t ex n t or after taking log with base s x t x t since s we have hence we obtain the constraints x t and x t thus we solve the following following parametric linear programming problem x x st x x x t x t solving eq using provides the following solution if t then x x else x x t this specifies that when n t s os and hence q nt s n t here n t is from the lower bound to account for io tagging otherwise o n t and q nt n t in the example since the vectors bb and bb are already the change of basis transformation that we per formed earlier is but in general this need not be the case since we focus only on asymptotic parametric bounds any constant multiplicative factors that arise due to the transformation are ignored example the following example is composed of a and a computation within an outer iteration loop parameters w n t inputs ann outputs ann iterative loop with followed by for it it w it split out into a sequence of and vector scaling ops for each row i ni j nj fork k nk s j nj s j nj s t tt for i i n i for j j n j s the decomposition theorem theorem allows us to split this code into individual components analyze each subprogram separately and obtain the io lower bounds for the whole program through simple of the individual bounds hence given the cdag c of the above example the analysis proceeds with the following steps · the cdag c and thus the underlying program is decomposed as follows each iteration of the outer loop with w is split into w each of this subprogram is further decomposed by separating the consisting of statements s s and s and operations consisting of statement s into individual · the vertices corresponding to the input arrays of the and computations are tagged as inputs in their · the with cm em om and the computation with cs es os are separately analyzed for their io lower bounds · if lm and ls are the io lower bounds obtained in the previous step for and computation respectively theorem and theorem provides us an io lower bound of w × lm im ls is for the whole program the analysis of the computation is similar to the analysis of the d computation detailed in the previous example hence we skip n s and the analysis and t s then provide qs the following result if nt n nt else s qs where qs is the io complexity for the computation now we consider the analysis of the the data flow graph gf consists of six vertices vertices a c and temp correspond to the input arrays a c and temp respectively s s and s correspond to the statements s s and s respectively the domain corresponding to each vertex in the or der a c temp s s and s is listed below · da and jn · dc and jn · and jn · ds and jn and kn · ds and jn · ds and jn the relations corresponding to various edges are listed below · a s re n ai j in and jn and jn · a s re n in and in and jn · c s re n in and jn · temp s re n in and jn · s s re n in and jn and kn · s s re n in and jn · s s re n in and jn broadcast paths the paths p e and p e are of type broadcast as p and p are composed of a single edge their relations rp and rp respectively are the same as their edge thus rp re and rp re we are specifically interested in the broadcast paths whose eg rp can be expressed as affine maps in our example the two rp and rp can be expressed as affine maps as shown below rp i j j rp i j i further we have an injective circuit p e with rp re whose direction vector b t we next calculate the frontiers f f and f of the relations rp rp and rp respectively by taking the of their domain and image eg f dp rp dp where dp the three frontiers are shown using the notation below · f n in and jn · f n in and jn · f n in and jn in the case an injective circuit with associated relation say ra we chose the direction of projection to be the vector representing ra here in case of a broadcast path with associated relation say rb ax b we choose the kernel of the matrix a to be the projection direction the intuition behind choosing this direction is that the kernel represents the of reuse and hence the set of points obtained by a set e along the kernel directions represents the in general the kernel can be of dimension higher than one but has to be at least one due to the definition of a broadcast path the kernels k and k of the of the paths p and p are k t and k t respectively by choosing k k and b as the projection directions we obtain i j k i k i j k j k i j k i j this provides us the following inequalities x x x x x x further to handle the cases we have the additional constraints that specify that the size of the projections onto the i j and k should not n and the size of the projections onto the i j j k and i k should not n hence we obtain the following parametric linear programming problem x x x st x x x x x x x x x x x x x x x solving eq using provides the following solution if x then hence x when x n x s qm else x x n n s otherwise qm finally by applying theorem we obtain the io lower bound for the full program q qm qs w × n nt n nt ss when n and t are sufficiently large putting it all together algorithm provides a for our algorithm because the number of possible paths in a graph is highly combinatorial several choices are made to limit the overall practical complexity of the algorithm first only edges of interest ie those that correspond to relations whose image is representative of the iteration domain are kept second paths are considered in the order of decreasing expected one criterion detailed here corresponds to injective circuits over broadcast paths with kernel to reduce the potential span and then broadcast paths with decreasing kernel dimension the higher the kernel the more the reuse the lower the constraint for a given vertex v once the directions associated with the set of paths chosen so far span the complete space of the domain of v no more paths are considered the role of the function try on lines and in algorithm amounts to finding a set of paths that are linearly independent compatible ie a base can be associated to them and representative the try is shown in algorithm the function shown in algorithm selects a set of paths for a vertex v and computes the associated complexity the function solve shown in algorithm writes the linear program and returns the io lower bound with cases for a domain d and a set of compatible various operations used in the are detailed below · given a relation r and return the domain and image of r respectively · for an edge e the operation provides its associated relation if re has acceptable number of then the edge can be split into multiple edges with count equal to the number of otherwise a convex underapproximation can be done · for a given path p e e el with associated relations re re rel we can compute the associated relation for p by composing the relations of its edges ie computes rel · · · re re note that the domain of the composition of two relations is restricted to the points for which the composition can apply ie r j rj j and r j j · for a given domain d returns its dimension if the cardinality of d ie number of points in d is represented in terms of the program parameters its dimension can be obtained by setting the values of the parameters to a fixed big value say b and computing and the result to the integer for example if d cn m nm n setting b we get round cb b · if a relation r is injective and can be expressed as an affine map of the form ax b then the operation computes b otherwise returns · for a relation r if its inverse can be expressed as an affine relation ax b computes the kernel of the matrix a and returns otherwise · for a set of vectors b b bl provides the linear by those vectors · for a set of linear k k kl gives a set of linearly independent vectors b b bd such that for any ki there exists bi b st ki if such a set could not be computed it returns · for a path p returns its set of vertices · given an expression x the operation simplifies the expression by eliminating the lower order terms for example n n t returns nt n gf vf ef fi fb foreach e u v ef do r if then next if r is invertible then fi f e if then fb fb e end if then e end end foreach v vf do d foreach circuit p from v to v in fi do r if b then next p if d then next p if p then next v end foreach path p to v in do r if k then next p if d then next p if k p then next v end foreach path p to v in do r if k then next p if d then next p if k p then next v end end algorithm for each vertex v in a dataflow graph gf finds a set of paths and computes the corresponding complexity function v let k k d t with maximum value of solved k t q solved k q algorithm for a vertex v selects a set of paths and computes the associated complexity function v k path p is a set of k k d t where k is a k is a set of d is a domain t is a set of vertices is an asymptotic complexity with cases if k then return false k foreach k k d t do if k and k then d d if d or then t t k k k k k k d t if k then q solved k q return true end end end end return false algorithm for a vertex v try to add path p to some other paths return true if a good bound is found function d set of k b lp i foreach k k do lp i foreach b b do db d lp i end f kk d u s q ds u f return q algorithm for a domain d and a set of compatible writes the linear program and returns the io lower bound with cases related work provided the first formalization of the io complexity problem for a twolevel memory hierarchy using the pebble game on a cdag and the equivalence to of the cdag we perform an adaptation of to constrain the size of the input set of each vertex set rather than a dominator set which is suitable for bounding the minimum io for a cdag with the restricted pebble game where is this adaptation enables effective composition of lower bounds of to form io lower bounds for composite a similar adaptation has previously been used by modifying the pebble game through addition of a third kind of pebble the composition of lower bounds for sequences of linear algebra operations has previously been addressed by the work of et al by use of imposed reads and writes in between segments of operations adding the lower bounds on data access for each of the segments and the number of imposed reads and writes our use of tagged inputs and outputs in conjunction with application of the decomposition theorem to the use of imposed reads and writes by et al but is applicable to the more general model of that model data dependences among operations et al proposed an approach to obtain lower bounds on the access complexity of a dag in terms of space lower bounds that apply to disjoint components of the dag when is not allowed the approach was later extended to the case when is allowed by means of the notion of space complexity et al used a geometric reasoning with the inequality to present an alternate proof to and for io lower bounds on standard matrix tion more recently group at uc berkeley has lower bounds as well as optimal algorithms for several linear algebra computations including qr and lu decomposition and the shortest paths problem extending the scope of the model to more com memory hierarchies has also been the subject of research age provided an extension together with results for some classes of computations that were considered by providing op lower bounds for io with memory hierarchies proposed a hierarchical computational model that offers the possibility to reason in an arbitrarily complex parametrized mem hierarchy model while we use a memory model in this paper the work can be extended in a straight forward manner to model memory hierarchies unlike original model several models have been proposed that do not allow of values also re to as no ­ developed results for using no and explore the possibility of coding a given algorithm so that it is efficiently portable across machines with different memory systems without the use of et al assume no in deriving lower bounds for linear algebra computations et al develop better bounds than for using a specialized technique adapted for computations on memory hierarchies ran jan et al derive lower bounds for pebbling under the assumption that there is no as discussed we also use a model that of values but our focus in this regard is different from previous efforts ­ we formalize an adaptation of the the model of that effective composition of lower bounds from of a composite cdag i ni j nj i ni fork k nk j nj fork k nk a matrix multiplication code b code with same array accesses as figure example difference between cdag model and computational model used by et al the previously described efforts on io lower bounds have involved manual analysis of algorithms to derive the bounds in contrast in this paper we develop an approach to the analysis of io lower bounds for programs the only other such effort to our knowledge is the recent work of et al indeed the approach we have develop in this paper was inspired by their work but differs in a number of significant ways the models of computation are different our work is based on the cdag and pebbling formalism of while the lower bound results of et al are based on a abstraction of an loop body of affine state ments within a nested loop for example under that model the lower bounds for codes in fig a standard ma and the fig b would be exactly the same ­ analysis is based only on the array ac in the computation in contrast with the pebble game model the for the two codes are very different with the code in fig a representing a connected cdag while the code in fig b represents has a cdag with three parts corresponding to the three statements and computation has a much lower io complexity of on the work of et al does not model data dependencies between statement instances and can therefore produce weak lower bounds in contrast the approach developed in this paper is based on using precise data dependence information as the basis for geometric reasoning in the iteration space to derive the io lower bounds for example with the example discussed earlier the lower bound obtained by the approach of in this paper this work addresses a more general model of programs while the work of et al only models nested loop computations the algorithms presented in this paper handle sequences of nested loop computations discussion we conclude by raising some issues and open questions some of which are being addressed in work of lower bounds a very important question is whether a lower bound is tight ­ clearly zero is a valid but weak and useless io lower bound for any cdag the primary means of of lower bounds is by comparison with upper bounds from algorithm implementations that have been optimized for data locality for example tiling or blocking is a commonly used approach to data locality of nested loop computations an open question is whether any automatic tool can be designed to systematically explore the space of valid schedules to generate good parametric upper bounds based on models andor heuristics that minimize data movement cost lower bounds when is allowed the of existing application codes do not perform any redundant of any operations but with data movement costs over operation execution costs both in terms of energy and performance there is significant interest in implementations of algorithms where redundant of values may be used to off additional operations for a reduction in expensive data memory it is therefore of interest to develop automated techniques for io lower bounds under the original model of that permits of cdag vertices having lower bounds under both models can offer a mechanism to identify which algorithms have a potential for a tradeoff between extra computations for reduced data movement and which do not if the cdag representing a computation has matching and tight io lower bounds under both the general model and the restricted model the algorithm does not have potential for such a tradeoff on the other hand if a lower bound under the restricted model that is higher than a tight lower bound under the general model the computation has potential for off extra computations for a reduction in volume of data movement this raises an interesting question is it possible to develop necessary andor sufficient conditions on properties of the computation for example on the nature of the data dependencies which will guarantee matching or lower bounds under the models relating io lower bounds to machine parameters io lower bounds can be used to determine whether an algorithm will be inherently limited to performance far below a processors because of data movement the between main memory and the last level cache in processors in on current systems is over an order of magnitude lower than the aggregate computational performance of the processor in floatingpoint operations per second this ratio is a critical machine balance parameter by comparing this machine balance parameter to the ratio of the io lower bound calculated for s set to the of the last level cache to the total number of arithmetic operations in the computation we can determine if the algorithm will be inherently limited by data movement overheads however such an analysis will also require tight of the constants for the leading terms in the asymptotic expressions of the order complexity for io lower bounds this is not addressed by the approach presented in this paper modeling associative operators reductions using associative operators like addition occur frequently in computations with the cdag model some fixed order of execution is enforced for such computations resulting in an linear chain of dependencies between the vertices corresponding to instances of an associative operator some previously developed geometric approaches to modeling io lower bounds have developed io lower bounds for a family of algorithms that differ in the order of execution of associative operations it would be of interest to extend the automated lower bounding approach of this paper to also model lower bounds among a family of corresponding to associative reordering of the operations finding good the second example in sec demonstrated the benefit of to obtain good lower bounds by combining bounds for via the decomposition theorem however if the decomposition is performed the result will be a very weak lower bound in the same example if the computation within the second level i loop had also been used to further decompose the cdag we would have a sequence of with order complexity on from which the tagged io nodes of the same order of complexity must be out resulting in a weak lower bound of zero conversely if the computation within the outer it loop were not decomposed into it would again have in weak lower bounds the question of automatically finding effective of to enable tight lower bounds is an open problem conclusion characterizing the io complexity of a program is a problem that is particularly important with current and architectures where data movement costs are the energy previous approaches to modeling the io complexity of computations have several limitations that this paper has addressed first by modifying the pebble game model used for characterizing io complexity analysis of large composite computational dags is enabled by decomposition into smaller a key requirement to allow the analysis of complex programs second a static analysis approach has been developed to compute io lower bounds by generating asymptotic parametric lower bounds for programs as a function of cache size and problem size we thank the anonymous for the feedback and many suggestions that us significantly in improving the presentation of the work we thank and for discussions on many aspects of lower bounds modeling and their suggestions for improving the paper this work was supported in part by the us national science foundation through and by the us department of energy through and by state university references g j o and o schwartz communication in numerical linear algebra siam j matrix analysis applications ­ g j o b and o schwartz brief strong scaling of matrix multiplication algorithms and communication lower bounds in proc pages ­ g j o and o schwartz graph expansion and communication costs of fast matrix multiplication j acm a computing the polynomial of a convex lattice discrete and computational geometry ­ j a m and t finite bounds for inequalities mathematical research letters ­ k s et al computing study technology challenges in achieving systems tech rep g and e a characterization of temporal locality and its across memory hierarchies automata languages and programming pages ­ g and f p processor time tradeoffs under message propagation part ii lower bounds theory comput syst ­ g a and p on the space and access complexity of computation dags in concepts in computer science volume of lncs pages ­ g m and f a lower bound technique for communication on with application to the in pages ­ m j n t and k communication lower bounds and optimal algorithms for programs that reference arrays part technical report uc berkeley may s a cook an observation on off j comput syst sci ­ j l m and j parallel and sequential qr and lu siam j scientific computing v f ln j and p data access complexity the pebble game technical report sept v f l j and p on characterizing the data movement complexity of computational dags for parallel execution in th acm symposium on parallelism in algorithms and architectures pages ­ p parametric integer programming ­ s h and l i the future of computing performance game over or next level the national press s n c a d m and o composition of loop transformations for deep parallelism and memory hierarchies intl j of parallel programming g gupta and s the model in acm sigplan symposium on principles and practice of parallel programming pages ­ acm and h t io complexity the pebble game in proc of the th annual acm on theory of computing pages ­ acm d s and a communication lower bounds for matrix multiplication j parallel comput ­ a and p profiling to parallelization framework scope and optimization in pages ­ l and h an inequality related to the inequality am math ­ d and m vertex parameter of a computation graph int j found comput sci ­ d j and m strong io lower bounds for and computation graphs in computing and volume of lncs pages ­ springer d j e and m upper and lower io bounds for pebbling j discrete algorithms ­ j extending the model to memory hierarchies in computing and volume of lncs pages ­ j e models of computation addisonwesley j e and m a unified model for architectures in proceedings of the st international on page acm j e and m algorithms for option acm trans math m and f communication lower bounds for computations abs j s and j computing technology challenges high performance computing for computational pages ­ e a and j communication in shortest paths in s i the polyhedron can j math ­ l g a model for computing j comput syst sci ­ jan s an integer set library for the polyhedral model in mathematical pages ­ springer 