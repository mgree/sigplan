on specifying v r pratt m i t the goal of automatic program verification is to prove programs correct formally we argue that the existing notions of formal proof are and as such too bound up with of computation we propose a more semantic notion of formal proof which nevertheless due respect to the problem of effectiveness in proof checking such a notion a more practical basis for the specification of do approaches in particular the problem of constructing according to our approach is reduced to routine development and implementation of decision methods while proofs and yet remaining easy to develop proofs wit h quote an nsf automatic verification of programs is either impossible or useless a recent text on software engineering included a chapter on verification nd that did not even mention the notion of formal proof at a session of the ieee symposium cm specifications for reliable software april a was able to a round of by expressing his about the value of formal verification a highly of computer have written a on programs be proved correct in the way theorems arc proved the contents of are summarized the end of this paper a computer on verification this author last his to know why verification research continue this research was supported by contract no permission to copy without fee all or part of tor or ut are copies to to prior a machinery to copy requires a fee and or specific permission so acm to be supported in the of in a recent issue of the of the acm to of which supported the position these are not just the of a art verification has been taken by many since at a comparable age the art of bj comparison in is there any hope for verification to become as useful and as compilation the here is that the of verification is not properly formulated the purpose of this paper is to supply an we do this by ab with a that should be as a objective we then a notion of those aspects of we to proofs in we the notion of proof from the notion of computation in a way intended to reduce the to the development of the outcome to a specification for ideas for our were presented in this paper those ideas further introducing a more treatment of soundness and and identifying better where the of our contribution of any sufficiently product whether a a a or o is almost certain to have of one kind or another in its some of the may be attributed to or product specification some to the to in the face of inconsistent specifications and putting it some to designer the first of these much outside the scope of the design process the second is a complicated of the design process involving much in the reduction effects but the third derives from plain human and it is here that one an for improving the quality of designs even if careful analysis were to reveal that the of the in designs from specifications it would remain the case that designers make often very costly ones the development of methods for those is a computers being better suited than to computation it would seem that designing could be made more accurate through by involving the computer more in the design process elimination of would reduce errors arising from and limitations of memory and computation speed yet the design process requires a substantial element of and it seems that such could be supplied entirely by machines in the automatic programming and automatic design in general are goals research of course continue in this are as the of success will be however its will need to be more than those supporting less projects there do exist places for accurate but in computer aided design has been a popular topic for many years and its successful application in has left little of the potential for computers to help in the design process the verification of designs by computer represents a more role for computers in design the computer is still not being to the magic of but it does need to know more the objectives of the design than does a typical one can form a better idea of the role of the computer here by considering the verification function of the question of how a might perform that function n the design of software such verification is carried out in practice with sometimes in what is the the programmer his program the design to who serve as his job is to the his does what he it does the are not called on for merely for accurate checking of this is not to say that the might not supply indeed ri very so far as to detect in the specifications by of his insight into the of the however the function of the is to errors in the of the designer and a and accurate presentation by the programmer turn out to be a experience for any without in his family tree this view of the is to suggest a division in the while and more generally designing with its demands on is better left to the human the accuracy by suggests that machines should take over the job viewed in this way verification cannot be is useless the question then arises is automatic impossible purpose of how maybe a that no about he than previous approaches for the possibility of using we make no as to the eventual feasibility of our approach however we assert with considerable that if our approach to verification cannot be at reasonably useful then neither can any of the other that have been out in the literature to the of when a discusses his program with the in a the the behavior of his program along with facts relevant to the data and control of the in the discussions would center on whatever objects were being designed whether or whatever in to any of the it would necessary to in the relevant areas viewed in this light automatic verification would seem to pose a to artificial the kind of approach we describe below stands in the middle between artificial intelligence ind logic it defines the problem more in terms of the topic being discussed with the verifier and less in of and rules of inference a would characterize this as being model theoretic in yet it involves formal of proof proof step ind making it sound very like i classical proof theoretic account of verification in fact this paper is a notion of proof that is much sensitive to the issue of the topic of discussion and less io the classical notions of axiom and inference rule which we shall argue can be with in of a more or semantic notion of rigorous argument let us now consider the essential attributes of the sort of explanation a verifier is to with we identify three problems here what is an appropriate for giving an explanation to a computer how is its meaning to be defined and how does one a computer of the truth of claims in that language given the capabilities of computers the natural used in will need to be replaced by something more formal for the automatic verifier this immediately presents an to the programmer who must now present his is this an consider the language used by the programmer to to the computer whether fortran cobol pl lisp or whatever the programming language is certainly formal yet the programmer has not only to learn it but to produce large amounts of software with it thus alone is not an to we feel that neither should it be an to the sort of formal language we have in mind is exactly that used by mathematical to within details of syntax an assertion such as for x there exists y x such that y is prime is a this would be considered a syntactic variant of a we would assume that a sophisticated verifier would make for such variations in in the syntax of formal languages much as some lisp systems offer the alternatives of notation or an algollike notation in each case with the same underlying semantics another assertion within the scope of what we have in is if x then after setting y to x and then setting x to y x this is not a statement normally encountered in ordinary logic but has been for by recent developments in formal of programs see eg j on the other hand we would probably stop short of such as saying x does not help here or this sentence is false the one criterion we would to in determining the language would be whether each construct was sufficiently precisely defined as to determine the correctness of each assertion in the language exactly what correctness is left undefined here however the reader will not be led by reading valid for while the can assume that the notion coincides with his about the correctness of assertions about welldefined models of any given domain in the sequel correctness is the only property of the language we shall make use of the definitions of the language constructs would in general be in terms of the models about which the language there would be models whose domain was the natural numbers models consisting of states for to between and for propositions to be true or false of this being one possible model for precisely what programs do models consisting of abstract representations of continuous functions for when these arise in an explanation snd so on for all of these models the meanings of the language constructs would be either standard or at least out for the benefit of the user there is much in the and the artificial intelligence literature about how to model from the point of view of our application for models there are two key properties one should look for in a model the first property is simplicity of definition this enables the model to be to the verifier designer the person that specifies the program for reasoning about the model the one who defines the proof that we talk about below it also the user of the verifier to the model to his own private model of whatever he is about the second property is sufficient precision of definition to determine the correctness of every assertion the computer will be called on to deal with this permits the verifier designer to what an acceptable argument and to specify algorithms for following such arguments whether the model is a firstorder relational structure or contains a type hierarchy or claims to have no relation to any structure thus far by philosophers or is not as important as whether it meets the above objectives it is easy but not very to get carried away with questions of of any given class of models the important thing is to have models beyond the model itself there is the question of the language used for about that model for example do you want to use ranging over in the model do you want to be able to form the disjunction of any set of assertions in the language or the negation of an assertion can you quantify over a variable do you want way to refer to subsets of the domain or to functions or even functional or would you prefer to all those concepts into the model itself thereby them with mathematical existence and reducing the language perhaps to no more c than equations between terms involving free variables as is done in the various approaches to algebraic logic all the above language considerations make sense a powerful verification system would be able to for a wide range of such approaches to language just as a hm to be to with the different modes of explanation of his various such power need not be developed all at a verifier should be just as useful as its available models and languages permit it to be researchers in search of the one true language will find our position on the choice of language something of a the problem of language design is a good one for research but there is as yet no real consensus in any research community that a universally useful language has been found this authors would go to an extreme algebraic logic approach which seems to offer unit y wit power however this is not a widely held position even in of logic despite its support from such visible as and more recently not to mention computer sciences own group under the the let a seems appropriate but further developments in the area could still our position depending on the model and the language permitted for about that model there may be fast slow or no algorithms for deciding correctness of all assertions about the model the approach we adopt to specifying addresses this problem later in the paper thus we have taken care of the language ind its meaning leaving the problem of how to a computer that rr given assertion is correct the nature of proof we begin by defining a notion of proof at a level abstract enough it could serve as a starting point for development of either a treatment of formal proof or an account of informal reasoning the notion is independent checking of the question of effectiveness in proof account does however assume that a fixed standard of correctness is applied uniformly to all the assertions of a proof this makes it a or account of proofs rather than a one deduction permits variations in the of correctness in a proof under the control of hypotheses that may be assumed locally and later usually for the purposes of exploring cases or for ad arguments the connections between the two are easily made and present no serious computational essentially what happens is that the hypotheses can be incorporated into each of the within their scope st little cost our arguments can therefore be applied equally well to a framework an exercise we do not carry out in this paper this is not to say that the exercise should not be performed a practical verifier should certainly permit natural deduction proof correctness a proof is a set of assertions a proof is correct when all of its are correct a basic rule of is that ones proofs be correct the reader in any as to whether this applies to informal should try to imagine a programmer getting away with incorrect claims about his program in the course of it any enough to such an will regardless of whether the incorrect logically from other claims if it does then one of those other claims is also incorrect another basic is that it should be possible to follow a proof we put correctness of proofs of this requirement one could call this the principle for proofs in this context there is a on page of attributed to in advice to the newly of a island there is no difficulty in deciding a case only both sides then consider what you think requires and accordingly but never give your reasons for your judgement will probably be right but your reasons will be wrong in other words it is easier to be right than to people that you me right it should be pointed out that advice assumes the to be a in applying the principle we shall assume that the programmer or designer doing the has sufficient to be right about his program or design when discussing it even if he has his correct assertions together to form a proof proof it is of course in the nature of assertions that they are sometimes difficult to test for correctness and this is where proofs help the essence of a proof is in its structure in the way some of its assertions help in the correctness of other assertions the classic account of the structure of a proof and the one assigns to every assertion q in a proof those assertions of the proof which are the premises of q which intuitively are those assertions that are intended to help directly in the correctness of q assertions without any premises are usually out as axioms but this serves no essential technical purpose and is not done here for those that find formalism helpful we may make this precise by binary relation the relation on the assertions of the proof means that p is a premise of q every assertion q of a proof is associated with a of the proof having conclusion q and premises the premises of q formally a the pair one pair for each q in the proof we define a to be one with either a correct conclusion or an incorrect premise a one with only sound steps as a practical matter we shall assume that proofs are always finite a proof is when the proof has no cycles in its relation ie m the transitive closure of r is the following proposition is intuitively obvious though not often stated explicitly proposition is correct an acyclic proof is sound if and only if it for correctness clearly implies soundness conversely suppose we have a but incorrect proof then some assertion is incorrect so the step of which it is the conclusion has an incorrect premise and so cm yielding an infinite series of incorrect assertions since the proof is acyclic the of the proof those who care about such things will of course be aware that of the proof is not needed to prove this result it suffices that be in the direction much work in proof theory depends on this observation our account is meant to be applied directly to realworld proofs so we lose nothing by requiring all proofs to be finite we assume from here on that proofs are acyclic the reader should not however assume that is an essential feature of proofs the author has been involved recently in work on cyclic proofs where the above proposition holds as a alternative to the use of the induction principle proof systems a proof is a set of steps infinite in practice a proof has only sound steps a proof is in a proof when it is a subset of the system thus if a is in a sound proof system it is sound and so correct by the above proposition a system is when every correct assertion is the conclusion of some step of some proof in the system the function of a proof is to provide a standard of proof given a proof system a job is to test whether the proof is in the system is one include the ideal proof that contains all all system from the users viewpoint sound steps however this would steps with correct conclusions to proofs of the form its obvious for all correct assertions for any model and language whose set of correct assertions is not easily tested for membership a practical proof system will have to for less than all sound steps a proof is one whose set of steps is a set that is one for which there is an algorithm to tell whether a given step is in the proof system clearly a for a recursive proof system can always be implemented a less precise but more useful notion is that of a proof system in which steps can not only be tested for membership but can be so in a amount of time say a few seconds is not only because of uncertainty about the exact time limit but because of the dependency of the complexity of such tests on the choice of computer on which the tests are implemented there still remains inherent complexity do not know how even when these factors are on the difficulty of determining the of a given set for example we still quickly propositional can be recognized the best algorithms worst case but for all we know that does the job take time gn in the there is an on algorithm h the other hand although the boundary of may be it is nevertheless possible for a proof system to lie well within that boundary for example if membership in the system is decidable in a second on a computer this author at least would not to call such a system tractable yet the potential for a system as tractable as this to reduce the of proof is very high as we shall see later the classical kind of proof system is tractable it consists essentially of the substitution instances of a finite set of with restrictions on the possible substitutions we do not distinguish this from a system which makes substitution explicit inference rule for example the axioms and pq pr together with from infer q constitute a proof system every step of which has either no premises an instance of one of the axioms or two premises an instance of an such a proof system is very tractable because steps can be tested in since only and efficient pattern matching need be applied in time independent of the size of the assertions if careful attention is to their representation the problem with this patternmatching approach is that where a substantial amount of computation is required to verify the truth of a claim there is no alternative but to have the proof of the claim explicitly contain all the steps of the computation in effect the author and the checker of the proof have to go through the entire computation together step by step putting this the other way around if the assertion to be proved has a short proof then that proof a short computation the assertions truth when the inference rules look m much like the atomic steps of some abstract computer as do the rules of classical proof systems it is reasonable to view a proof as a completely out computation such a formal proof has no more use than does the complete trace of execution of the involved in say computing the inverse of a matrix our first step towards a more usable proof system then is to propose the adoption of larger systems than the classical ones but not as yet still tractable enough to be usable and therefore still a proper subset of the set of all sound steps by larger we mean containing many steps not in the classical system in this way we may hope for the of many proofs as well as the introduction of new proofs where a correct assertion had no proof in the old system as can happen with incomplete systems in the end a verification system or on whether it can be used in practice the in our proposal lies primarily in its treatment of the proof system permit proofs but brevity in proofs is not everything the user should also know what the is or proof development will become a proposition where the user produces a step and then tests whether it is in the system such tests require computer help when tractable permits machine computations of steps this is all very because the has no basis for efficiently development of his proof the classical systems the user to tell fairly easily whether a given step is in the system which is very helpful in developing the proof classical systems without preserving this property is a in the approach we describe below we play it safe and improve this property at the same time as we substantially the system decision methods for of logic supply precisely the we need to address this issue typical decidable fragments of logic classical inference rules to the extent that they tend to be easily characterized for example one may talk about the fragment whose language is restricted to propositional connective variables and correctness to mean validity such a characterization is in fact simpler in character than the sort of characterization of a typical inference rule dealing purely with the choice of vocabulary and not with matching patterns it is about the simplest sort of syntactic characterization one could have on the other hand differ from inference rules by not soundness but by defining a domain in which soundness is decidable by decidable fragment we shall mean that step soundness is decidable in that fragment so just being in ii fragment would not seem to be a good criterion for a step to belong to a proof after all the step may be unsound and if it is going to take a computation to test soundness then the user is no better off than before these let us take for a proof system the set of all sound steps each of which is in some tractable fragment of logic that is an easily decidable fragment now we have already on the principle and that it is easier to to the truth than to connect together to form a coherent proof if the user to to the truth in his proof and so produce only correct proofs then such proofs will contain only sound steps as was pointed out if in the user keeps each step in one of the for by the proof system it is then guaranteed that the proof is in the system this is the key to our approach the user now has two things to about correctness and instead of one as in the classical approach namely just matching some rule however we maintain that each of these is easier for the user to deal with than pattern matching correctness is handled by so to that is the user whatever it is that makes so sure of his facts without any reference to the methods used by the verifier is a little more difficult involving constraints that must be just as n programming language must be however these constraints can be to be less than the artificial constraints of a classical proof system the use of decision methods in verification is by no means novel indeed the formal verifier on the existence of decision methods for certain fragments of programming logic however the use described here uses a new and still principle and should not be with these other use note that unlike soundness is a concept dependent on the of decision methods as such it be considered an of the state of the art deciding soundness together with the state of the art of computer as we learn more more domains will become tractable but no amount of learning will which steps are sound and for as long as computer continues to out thesis the set of theorems of an implementable proof system will always be recursively enumerable the converse holds also if a computer is built that thesis we can expect to see some effectively systems with e theories point is obvious to recursion but seems to be a block for some less oriented who have a time getting straight the applicability of incompleteness theorem the advantages of our approach are a much larger proof systems m measured by the number of steps of a given length are possible with this approach than with either the classical approach or with any method based on a library of theorems and rules of inference even if one uses decision methods exponential time and on answers within a few seconds a single decision method can the effect of of inference rules for if a method takes n being the of words in the step then in seconds the method can handle steps of size up to n with say an word dictionary for the domain in question this means possible steps of which perhaps e are wellformed are sound and of those perhaps l that a and fixed fraction of wellformed steps must be sound follows from the existence of short sound steps together with the possibility of those steps with or as they are sometimes called for if p is correct so is and if xy is correct so is xy the proof system would then be characterized as including just those sound in the given fragment of length at most the length constraint is not for the user to take into account a decision method time n is less satisfactory giving n as the largest step size it can this steps of which such a number would be and sound that one might as just write them all down and perhaps add a few ones to the algorithm if was the worstcase time but there were many of size m more could be handled in a amount of time one might feel more towards such an algorithm unfortunately we would no longer have a good characterization of the system which of those steps longer does one just those that are with in under seconds say is no better than the we at the since then the user has no way to develop his proof but to try out steps on the computer thus there is a threshold between one and two exponential in the worstcase analysis beyond which algorithms have nothing to offer that a classical system cannot offer b the verifier specifications build it it suffices to implement methods are well defined to the necessary decision c the user need not track of the carried out by the verifier in fact the user need not even have a general for computing soundness in any of the domains known about by the proof system it suffices for to keep his correct with whatever methods he would use in keeping his assertions correct in the course of a with and to keep each step it should be clear that these two that ail steps of his proof in the proof system how people to the truth during an explanation to within is a that we do not feel to we just observe that seems to between steps tractable is another issue here we rely on being an recognized property of steps what exist to begin with of inference rather such are defined in a and the artificial way so that every step in the domain is sound still they are very tractable there are a number of decidable logical theories already in existence that meet all our criteria the domains they each treat are recognized the basis of the vocabulary used and their are at most one exponential or a little more these are more than the classical axioms and rules is easier to yet they for more steps the work done by nelson and on combining decision is extremely useful in this context they show that methods for quantifierfree theories can be combined to with the deductive of the union of those theories in time the maximum of the method and bl the bell number n being the length of the problem the author has the problem of extending this result to with program it had been this work could have presented at this conference but the paper into the of the conference consider the usual constructs of procedure calls with call parameters ifthenelse even nondeterministic choice along with the constructs of programming logics for partial correctness for and ab for include with these everything covered by the theory then the entire resulting logic is still of complexity at most bn the following is a valid formula of this logic as the reader may wish to verify halts xy a zx do begin ax b b halts yx a yz v do az fl of course we have left out something from program logic since otherwise the would be quite undecidable what we have omitted the three main kinds of binding mechanisms assignment and definition an one of these would make the fragment quantification would give ii of first order logic would make termination of a single program undecidable and procedure definition would permit recursion which would introduce through wellknown undecidability results about testing inclusion between contextfree languages thus this logic is for ii decidable fragment of what one consider sequential program logic that such a fragment is so tractable bn is opposed to or worse is perhaps surprising this fragment would be one of many such in which other concepts and integer were for to deal with one develop fragments of logic that covered all existing rules for firstorder predicate to begin with there the fragments studied by and and analyzed for their complexity by lewis j these provide examples of fragments are not defined purely but have simple structural constraints the number of of in various ways these be extended by say ii fragment one variable x step with many occurrences of vx ind x for that variable x in the step together with s operators with vx and x and the role of quantifiers the identity of whose had been except for the that they were ill different from x we that this or something very close to it is in time we also conjecture that the proof system it defines is complete for first order predictive logic all theorems of that logic can be proved in system other approaches here are some other approaches that have been proposed for a direct checking a verifier checks that a complete formal proof uses only legal axioms and rules this has the that the specifications for the verifier are well defined that the verifier is fast the is that proofs are in the extreme to b proof here one fragments of a proof find lets the verifier the rest this approach avoids the of approach i by letting the do more of the work often with the help of decision methods for of logic however it is what the specifications for a verifier should be c derived of inference this is a of ii the is to permit the user to derive of beyond those by the proof system as a means of formal proofs with this well specified d proof under control here the user writes a program to produce a proof this is the proposed by for his logic of computable functions as described by milner the users program amounts to heuristic control of proof discovery strategies a certain of is required in order to get the proof right and no convenient way is provided for the outcome of a particular program other than by trying it to see what happens topdown proof development our basic notion of proof says nothing about how a proof might be developed and any order of development to the same be equally satisfactory still it is worth pointing out that there is a particularly natural way of developing a proof recursively we may consider a proof to be a of one of its assertions one not as a premise in any step of the proof from some subset of the assertions of the proof in fact what is being proved has itself the form of a step then the proof can be considered the of intermediate assertions possibly including some additional assertions the user his proof by selecting any step that is not in the proof system and trying to explain it the assertions of the explanation are added to the proof along with the appropriate edges the process is then repeated for step not yet in the system one that was just introduced when all steps are in the system the proof is complete this approach development technique one to use in practice can be considered a topdown proof it us as a very natural system manual the system manual that goes with an implementation of our approach takes the place of the traditional axiom system it should contain the following a definition of the language and its semantics thus defining correctness and so soundness and an algorithm for membership in some fragment that the user can perform in his head in a matter of seconds its user verifies that the language and its semantics agree with his intuition and then proceeds to use the algorithm for in the course of developing proofs in general will be decomposed into a union of predicates analogously to the way classical proof systems have a finite set of axioms and inference rules implementation implementation of a system requires little more than the implementation of a set of decision methods together with a procedure for detecting cycles in proofs this permits to be as a completely set of modules and allows for their growth by new methods m be added without the existing methods must be in this section we arises in connection with our semantically of view issue that oriented point it is often assumed that a verifier with bugs is no better than no verifier at all however if this were true there would be no point in having since are whether as programmers or yet are not useless io this as they do to bugs the a verifier is of a compiler it does a large amount of tedious computation automatically reducing the number of errors one may expect in such when performed by in the case of the compiler the computation involves translating and optimizing code in the case of the verifier it involves checking the correctness of in both cases a lot of work is involved also in both cases it is possible for errors in the compiler or verifier to completely the outcome experience has shown that compilers can be effective without being entirely reliable and we see no reason why the should not be true of in fact we would expect to a in period in the same way a compiler does during which time from users with or bugs results in eliminating those bugs that cause problems leaving behind just those that very take an user one may think of this process as the gradual of a compiler or a verifier from this point of view there always remains the possibility of a bug in a verified program or other design however when the probability has been driven below a level the probability of error from other sources must start to such as incorrect specifications machine errors in the case of programs in material and in the case of production of physical objects such as and so on beyond this point further in the reliability of the verifier is not worth the effort any more than it is the effort of the provers of the theorem to prove correct the compiler they used as part of the overall proof the recently de and a paper on difficulties verification we x out of it but were by the and both for and which we all to a or two of being by nature we were to review the paper in the same spirit in which it was in a weak moment we to there are main made in i that we could they are as follows real proofs are and only with time and experience theorems should be simple long formal proofs arc real software is specified there is no evidence small program changes will require only small proof changes theorems have long proofs is an impossible we too are for ind and all of these statements except now why dont these people trust long computations one before we the result of five and a half of computation in connection with a computer search for using probabilistic prime were not just from lewis it really was before the computer had been left running if the the results of computation they should have expressed their about the recent proof of the theorem which involved more than of computation about a points and leave us with a that might be to what feel when they see their up all those to see all this in mathematics and software to an end the parents tell them that counts who the status in mathematical is what we should all be for in this is probably one of those we keep reading about on one reads those little notices how to kill ideas and as we always did it that way we point in our there is no evidence for file which is full of dead on and other that the must have been them not collecting evidence seems to us the perfect academic alternative to testing point us somewhat e have for the stronger remark half a that some theorems have no proofs the authors are off by trying to make a point with one hand behind their their attention to decidable theories but they dont let on that this is what up to why they would want to restrict point to decidable theories is a total to us the writing style was very and we were looking forward to further light reading from this team maybe something a little more their reply to the bit their closing reads as follows finally of the letters is the sense that if only we did things this way or that way or if we our activities then program proving would work perhaps but we are by of any that requires new there has not been a more statement in any research journal in this right there in black and white it says it dont get involved in areas that seem to need new methods out when the nsf to for its light reading de and be our le would they we are by people who tell us they are and by conclusions we have tried to show how decision methods can take over the role generally for axiom systems in automatic verification technology it is clear that the technology has moving in this direction for some tim even the early verifier of j under the influence of r a strong on efficient decision methods and the of and make heavy use of decision methods as opposed to the more heuristic methods that are employed in many other yet no framework has to date within which it is just how decision methods can replace more rules of inference while preserving the precision with which a traditional proof system is specified indeed many people working in verification methodology are still to the that some mathematical logic do much to while they use of the decision methods the approach we described such a framework in which a proof system could be defined entirely by identifying tractable fragments of logic yet in a way that permitted proofs to be developed without help from the computer to avoid ending on too optimistic a note we point out some we have already observed the inherent in any attempt to formalize the namely may the style of the his program one might take as an objective of natural language research the of such formal environments to improve which we regard as a but very difficult problem an issue here is the extent to which the replacement of traditional rules by decision methods improves the rate of convergence to a tractable proof we are to as the reader will have but a fair amount of will have to be done in order to this another problem is to do for the user who wants to refer to a function for which no decision method eg or factorial a view would be that eventually decision methods will be developed for fragments all the more familiar functions a more and quite approach is to let the user proceed m he would have in a traditional axiom system as the permitted steps the substitution instances of those axioms that are appropriate for those functions q de r a rj and aj processes and proofs of theorems programs comm acm may r w assigning meanings to programs of science ed schwartz in hoare c a r an axiomatic basis for computer programming cacm j c a program proc ifip northholland amsterdam s also phd thesis university pittsburgh pa lewis h complexity of solvable cases of the decision problem for the predicate calculus th annual symposium on foundations of computer science ann oct g and dc a simplifier on efficient decision algorithms th ann acm symp on principles of programming j r the and ny simon a g et al letters to the acm section on comm acm not to mention of letters to software engineering notes sigplan notices etc even dijkstra in pratt v r axioms or algorithms proceedings of the symposium on mathematical foundations of computer science sept the nice thing about axioms is that they implicitly define a procedure namely the one that attempts to match an axiom an instance of its use thus even though the system is built out of decision the user need not he a programmer to add to the systems capabilities all he needs is to be able to write axioms the advantage that the system programmer has is that he can augment the system in much more powerful ways by adding more decision methods thus an axiom can be viewed as the decision method rl and m a logic press cook s a and ra the relative efficiency of propositional proof systems j symbolic logic march 