after writing parallel programming with university r university of r university abstract parallel programming models offer the advantages of parallel speedup while avoiding the nondeterministic bugs that fully concurrent code a approach to parallel programming with shared state is by shared memory locations whose semantics are defined in terms of an lattice writes to an lvar take the least upper bound of the old and new values with respect to the lattice while reads from an lvar can observe only that its contents have a specified threshold in the lattice although it guarantees determinism this interface is quite limited we extend in two ways first we add the ability to and then read the contents of an lvar directly second we add the ability to event handlers to an lvar a callback when the value changes together handlers and enable an expressive and useful style of parallel programming we prove that in a language where communication takes place through these extended programs are at worst on every run they either produce the same answer or raise an error we demonstrate the of our approach by implementing a library for haskell supporting a variety of data structures together with a case study that illustrates the programming model and yields promising parallel speedup categories and subject descriptors d language constructs and features concurrent programming structures d concurrent programming parallel programming d formal definitions and theory semantics d language concurrent distributed and parallel languages keywords deterministic parallelism lattices introduction flexible parallelism requires tasks to be scheduled dynamically in response to the of an execution but if the resulting schedule nondeterminism is observable within a program it becomes permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ san diego ca usa copyright is held by the publication to acm acm much more difficult for programmers to discover and correct bugs by testing let alone to reason about their code in the first place while much work has focused on identifying methods of deterministic parallel programming guaranteed determinism in real parallel programs remains a and achieved goal it places constraints on the programming model concurrent tasks must communicate in restricted ways that prevent them from observing the effects of scheduling a restriction that must be enforced at the language or runtime level the simplest strategy is to allow no communication forcing concurrent tasks to produce values independently pure languages follow this strategy as do languages that force references to be either or immutable but some algorithms are more naturally or efficiently written using shared state or message passing a variety of models allow limited communication along these lines but they tend to be narrow in scope and permit communication through only a single data structure for instance fifo queues in kahn process networks and or shared tables in intel concurrent collections deterministic parallelism our goal is to create a generalpurpose programming environment to increase the and applicability of the method we an approach that is not to a particular data structure and that supports familiar idioms from both functional and imperative programming our starting point is the idea of monotonic data structures in which information can only be added never removed and the order in which information is added is not observable a example is a set that supports insertion but not removal but there are many others our recently proposed programming model makes an initial into programming with monotonic data structures in this model which we review in section all shared data structures called are monotonic and the states that an lvar can take on form a lattice writes to an lvar must correspond to a join least upper bound in the lattice which means that they increase the information in the lvar and that they commute with one another but writes are not enough to guarantee determinism if a read can observe whether or not a concurrent write has then it can observe differences in scheduling so in the model the answer to the question has a write occurred ie is the lvar above a certain lattice value is always yes the reading thread will block until the contents reach a desired threshold in a monotonic data structure the absence of information is thread could add that information at any the presence of information is forever the model guarantees determinism supports an variety of data structures anything as a lattice and provides a familiar api so it already achieves several of our goals unfortunately it is not as generalpurpose as one might hope consider an unordered graph traversal a typical implementation involves a growing set of seen nodes neighbors of seen nodes are back into the set until it reaches a fixed point such fixpoint computations are and would seem to be a perfect match for the model due to their use of monotonicity but they are not expressible using the threshold read and write operations described above the problem is that these computations rely on negative information about a monotonic data structure ie on the absence of certain writes to the data structure in a graph traversal for example nodes should only be explored if the current node is not yet in the set a fixpoint is reached only if no new neighbors are found and of course at the end of the computation it must be possible to learn exactly which nodes were reachable which entails learning that certain nodes were not but in the model whether a node is in a set means waiting until the node is in the set and it is not clear how to lift this restriction while determinism monotonic data structures that can say no in this paper we propose two additions to the model that significantly extend its reach first we add event handlers a mechanism for a callback function to an lvar that runs whenever events arrive in the form of monotonic updates to the lvar ordinary lvar reads a synchronous model of programming in which threads ask specific questions of an lvar potentially blocking until the answer is yes handlers by contrast support an asynchronous push model of programming it is possible to check for of a handler discovering that no callbacks are currently negative property since means that there are no further changes to to it can be used to tell that a fixpoint has been reached second we add a primitive for an lvar which comes with the following tradeoff once an lvar is frozen any further writes that would change its value instead throw an exception on the other hand it becomes possible to discover the exact value of the lvar learning both positive and negative information about it without blocking putting these features together we can write a parallel graph traversal algorithm in the following simple fashion traverse graph par set traverse g do seen seen let handle node seen g node seen handle this code written using our haskell implementation described in section in parallel the set of nodes in a graph g reachable from a given node and is guaranteed to produce a deterministic result it works by creating a fresh set lvar corresponding to a lattice whose elements are sets with set union as least upper bound and it with the starting node the function combines the constructs proposed above first it the callback handle as a handler for the seen set which will put the neighbors of each visited node into the set possibly further callbacks recursively sec our original work on included a brief sketch of a similar proposal for a consume operation on but did not study it in detail here we include in our model prove for it and show how to program with it in conjunction with our other proposal handlers the par type constructor is the monad in which lvar computations live when no further callbacks are ready to when the seen set has reached a will the set and return its exact value unfortunately does not commute with writes that change an lvar if a is interleaved before such a write the write will raise an exception if it is interleaved the program will proceed normally it would appear that the price of negative information is the loss of determinism fortunately the loss is not total although lvar programs with are not guaranteed to be deterministic they do satisfy a related property that we call all executions that produce a final value produce the same final value to put it another way a program can be trusted to never change its answer due to nondeterminism at worst it might raise an exception on some runs in our proposed model this exception can in principle the exact pair of and write operations that are greatly debugging our general observation is that towards general monotonic data structures leads to with nondeterminism perhaps the best way of ultimately getting deterministic outcomes is to a small distance into nondeterminism and make our way back the identification of programs as a useful intermediate class is a contribution of this paper that said in many cases our construct is only used as the very final step of a computation after a global barrier is used to extract an answer in this common case we can guarantee determinism since no writes can subsequently occur contributions the technical contributions of this paper are · we introduce lvish a parallel programming model that extends to incorporate and event handlers section in addition to our highlevel design we present a core calculus for lvish section formalizing its semantics and include a version implemented in plt redex section for interactive · we give a proof of for the lvish calculus section the key lemma independence gives a kind of frame property for lvish computations very roughly if a computation takes an lvar from state p to p then it would take the same lvar from the state p pf to p pf the independence lemma captures the commutative effects of lvish computations · we describe a haskell library for practical parallel programming based on lvish section our library comes with a number of monotonic data structures including sets maps counters and variables further it can be extended with new data structures all of which can be used within the same program adding a new data structure typically involves an existing scalable eg lockfree data structure to haskell then it to expose a lvar interface our library a monad that is indexed by a determinism level fully deterministic or thus the static type of an lvish computation reflects its guarantee and in particular the idiom allows to be used safely with a index · in section we evaluate our library with a case study control flow analysis the case study begins with an existing implementation of written in a purely functional style we show how this code can easily and safely be by it to the lvish adaptation that the same is true for detection see section yields promising parallel speedup and also turns out to have benefits even in the sequential case background the model are a wellknown mechanism for deterministic parallel programming an is a variable with a blocking read semantics an attempt to read an empty will block until the has been filled with a value we recently proposed as a generalization of unlike which can only be written to once allow multiple writes so long as those writes are increasing with respect to an lattice of states consider a program in which two parallel computations write to an lvar lv with one thread writing the value and the other writing let par put lv put lv in get lv example here put and get are operations that write and read respectively and the expression let par x e x e in body has semantics it concurrent e e whose executions arbitrarily but must all complete before body runs the put operation is defined in terms of the lattice of lvar states it updates the lvar to the least upper bound of its current state and the new state being written if lv s lattice is the ordering on positive integers as shown in figure a then lv s state will always be max by the time get lv runs since the least upper bound of two positive integers n and n is n therefore example will evaluate to regardless of the order in which the two put operations occurred on the other hand if lv s lattice is that shown in figure b in which the least upper bound of any two distinct positive integers is then example will raise an exception indicating that conflicting writes to lv have occurred this exception is analogous to the multiple put error raised upon multiple writes to an unlike with a traditional though multiple writes of the same value say put lv and put lv will not raise an exception because the least upper bound of any positive integer and itself is that to the fact that multiple writes of the same value do not allow any nondeterminism to be observed threshold reads however merely ensuring that writes to an lvar are increasing is not enough to ensure that programs behave consider again the lattice of figure a for lv but suppose we change example to allow the get operation to be interleaved with the two puts let par put lv put lv x get lv in x example since the two puts and the get can be scheduled in any order example is nondeterministic x might be either or depending on the order in which the lvar effects occur therefore to maintain determinism put an extra restriction on the get operation rather than allowing get to observe the exact value of the lvar it can only observe that the lvar has reached one of a specified set of lower bound states this set of lower bounds which we provide as an extra argument to get is called a threshold set because the a b c figure example lvar lattices a positive integers ordered by b containing a positive integer c pair of annotated with example threshold sets that would correspond to a blocking read of the first or second element of the pair any state transition the for causes it to and return a result values in it form a threshold that the state of the lvar must cross before the call to get is allowed to and return when the threshold has been reached get and returns not the exact value of the lvar but instead the unique element of the threshold set that has been reached or we can make example behave by passing a threshold set argument to get for instance suppose we choose the singleton set as the threshold set since lv s value can only increase with time we know that once it is at least it will remain at or above forever therefore the program will evaluate to had we chosen as the threshold set the program would evaluate to had we chosen it would block forever as long as we only access with put and get we can arbitrarily share them between threads without introducing nondeterminism that is the put and get operations in a given program can happen in any order without changing the value to which the program evaluates of threshold sets while the lvar interface just described is deterministic it is only useful for synchronization not for communicating data we must specify in advance the single answer we expect to be returned from the call to get in general though threshold sets do not have to be singleton sets for example consider an lvar lv whose states form a lattice of pairs of that is lv is a pair m n where m and n both start as and may each be updated once with a non value which must be some natural number this lattice is shown in figure c we can then define and operations for reading from the first and second entries of lv p get p m m n p get p n n n this allows us to write programs like the following let par put lv put lv x lv in x example in the call lv the threshold set is an infinite set there is no of nondeterminism because the elements of the threshold set are pairwise incompatible with respect to lv s lattice informally since the second entry of lv can only be written once no more than one state from the set can ever be reached we formalize this requirement in section in the case of example lv may and return any time after the second entry of lv has been written regardless of whether the first entry has been written yet it is therefore possible to use to safely read parts of an incomplete data an object that is in the process of being initialized by a constructor the model versus the use of explicit threshold sets in the above model should be understood as a mathematical modeling technique not an implementation approach or practical api our library discussed in section provides an unsafe operation to the authors of lvar data structure libraries who can then make operations like and available as a safe interface for application writers implicitly in the particular threshold sets that make sense for a given data structure without ever explicitly constructing them to put it another way operations on a data structure exposed as an lvar must have the semantic effect of a least upper bound for writes or a threshold for reads but none of this need be visible to clients or even written explicitly in the code any data structure api that provides such a semantics is guaranteed to provide deterministic concurrent communication lvish informally as we explained in section while offer a deterministic programming model that allows communication through a wide variety of data structures they are not powerful enough to express common algorithmic patterns like fixpoint computations that require both positive and negative queries in this section we explain our extensions to the lvar model at a high level section then formalizes them while section shows how to implement them through event handlers our first extension to is the ability to do asynchronous programming through event handlers an event for an lvar can be represented by a lattice element the event occurs when the current value reaches a point at or above that lattice element an event handler together an lvar with a callback function that is invoked whenever some events of interest occur for example if lv is an lvar whose lattice is that of figure a the expression lv x put lv x example registers a handler for lv that executes the callback function x put lv x for each odd number that lv is at or above when example is finished evaluating lv will contain the smallest even number that is at or above what its original value was for instance if lv originally contains the callback function will be invoked twice once with as its argument and once with these calls will respectively write and into lv since both writes are lv will remain on the other hand if lv originally contains then the callback will run three times with and as its respective arguments and with the latter of these calls writing into lv leaving lv as in general the second argument to is an arbitrary subset q of the lattice specifying which events should be handled like threshold sets these event sets are a mathematical modeling tool only they have no explicit existence in the implementation event handlers in lvish are somewhat in that they invoke their callback for all events in their event set q that have taken place ie all values in q less than or equal to the current lvar value even if those events occurred prior to the handler being to see why this semantics is necessary consider the following more subtle example let par put lv put lv lv x if x then put lv in get lv example can example ever block if a callback only executed for events that after its handler was or only for the largest event in its handler set that had occurred then the example would be nondeterministic it would block or not depending on how the handler was interleaved with the puts by instead executing a handlers callback once for each and every element in its event set below or at the value we guarantee for example guarantee the result of the power of event handlers is most evident for lattices that model collections such as sets for example if we are working with lattices of sets of natural numbers ordered by subset inclusion then we can write the following function foreach lv f lv f unlike the usual foreach function found in functional programming languages this function sets up a asynchronous flow of data from lv into the callback f functions like foreach can be used to set up complex cyclic dataflow networks as we will see in section in writing foreach we consider only the singleton sets to be events of interest which means that if the value of lv is some set like then f will be executed once for each singleton subset that is once for each element in section we will see that this kind of handler set can be specified in a way and in section we will see that it corresponds closely to our implementation strategy through handler because event handlers are asynchronous we need a separate mechanism to determine when they have reached a state ie when all callbacks for the events that have occurred have finished running as we discussed in section detecting is crucial for implementing fixpoint computations to build flexible dataflow networks it is also helpful to be able to detect of multiple handlers simultaneously thus our design includes handler which are groups of event handlers whose can be tested the simplest way to use a handler pool is the following let h in h lv q f h where lv is an lvar q is an event set and f is a callback handler are created with the function and handlers are with a variant of that takes a handler pool as an additional argument finally blocks until a pool of handlers has reached a state of course whether or not a handler is is a property we can move in and out of as more puts to an lvar occur and even if all states at or below the current state have been handled there is no way to know that more puts will not arrive to increase the state and trigger more callbacks there is no to however because does not yield any information about which events have been such questions must be through lvar functions like get in practice is almost always used together with which we explain next and the pattern our final addition to the lvar model is the ability to an lvar which further changes to it but in return allows its exact value to be read we expose through the function which takes an lvar as its argument and returns the exact value of the lvar as its result as we explained in section puts that would change the value of a frozen lvar instead raise an exception and it is the potential for races between such puts and that makes lvish rather than fully deterministic putting all the above pieces together we arrive at a particularly common pattern of programming in lvish lv q f let h in h lv q f h lv in this pattern an event handler is for an lvar subsequently and then the lvar is frozen and its exact value is returned a variant of this pattern was used in the graph traversal example in section lvish formally in this section we present a core calculus for particular a parallel callbyvalue calculus extended with a store containing it extends the original lvar formalism to support event handlers and in comparison to the informal description given in the last two sections we make two simplifications to keep the model lightweight · we the definition of the lvish calculus by a single lattice representing the set of states that in the calculus can take on therefore lvish is really a family of calculi varying by choice of lattice multiple lattices can in principle be encoded using a sum construction so this modeling choice is just to keep the presentation simple in any case our haskell implementation supports multiple lattices · rather than modeling the full of event handlers handler and as separate primitives we instead formalize the combined as a primitive this greatly simplifies the calculus while still capturing the essence of our programming model in this section we cover the most important aspects of the lvish core calculus complete details including the proof of lemma are given in the companion technical report lattices the lattice is given as a tuple d where d is a set is a partial order on the elements of d is the least element of d according to and is the greatest the element represents the initial empty state of every lvar while represents the error state that would result from conflicting updates to an lvar the partial order represents the order in which an lvar may take on states it induces a binary least upper bound lub operation on the elements of d we require that every two elements of d have a least upper bound in d intuitively the existence of a lub for every two elements of d means that it is possible for two to independently update an lvar and then merge the results by taking the lub of the resulting two states formally this makes d a bounded with a designated greatest element for brevity we use the term lattice as shorthand for bounded with a designated greatest element in the rest of this paper we also use d as a shorthand for the entire tuple d when its meaning is clear from the context to model we need to generalize the notion of the state of an lvar to include information about whether it is frozen or not thus in our model an state is a pair d where d is an element of the set d and is a status bit of either true or false we can define an ordering p on lvar states d in terms of the ordering on elements of d every element of d is except informally · two states are ordered according to the that is d false p d false exactly when d d · two frozen states do not have an order unless they are equal d true p d true exactly when d d · an state d false is less than or equal to a frozen state d true exactly when d d · the only situation in which a frozen state is less than an state is if the state is that is d true p d false exactly when d the addition of status bits to the lattice results in a new lattice dp p p p and we write p for the least upper bound operation that p induces definition and lemma formalize this notion definition lattice suppose d is a lattice we define an operation dp p p p as follows dp is a set defined as follows dp d d d true false false p × dp is a binary relation defined as follows d false d true d false d true p d false p d true p d true p d false dd dd dd d p false p false lemma lattice structure if d is a lattice then is as well stores during the evaluation of lvish programs a store s keeps track of the states of each lvar is represented by a binding from a location l drawn from a set loc to its state which is some pair d from the set dp definition a store is either a finite partial mapping s loc fin dp p or the distinguished element s we use the notation sl d to denote extending s with a binding from l to d if l doms then sl d denotes an update to the existing binding for l rather than an extension we can also denote a store by explicitly writing out all its bindings using the notation l d l d it is straightforward to lift the p operations defined on elements of dp to the level of stores given a lattice d with elements d d configurations s e error expressions e x v e e get e e put e e new e e after e with e l after q with x e e h stores s l p ln pn s values v d p l p q x e eval contexts e e e e e get e e get e e put e e put e e e e after e with e e after e with e e after e with e v after v with v e e e h handled sets h d dn threshold sets p p p event sets q d d states p d status bits true false figure syntax for lvish definition a store s is less than or equal to a store s written s s s iff · s s or · doms doms and for all l doms sl p s l stores ordered by s also form a lattice with bottom element and top element s we write s for the induced lub operation concretely defined in if for example d p d p then l d s l d s a store containing a binding l can never arise during the execution of an lvish program because as we will see in section an put that would take the value of l to will raise an error the lvish calculus the syntax and operational semantics of the lvish calculus appear in figures and respectively as we have noted both the syntax and semantics are parameterized by the lattice d the reduction relation is defined on configurations s e a store and an expression the error configuration written error is a unique element added to the set of configurations but we consider s e to be equal to error for all expressions e the metavariable ranges over configurations lvish uses a reduction semantics based on evaluation contexts the rule is a standard context rule allowing us to apply reductions within a context the choice of context determines where evaluation can occur in lvish the order of evaluation is nondeterministic that is a given expression can generally reduce in various ways and so it is generally not the case that an expression has a unique decomposition into redex and context for example in an application e e either e or e might reduce first the nondeterminism in choice of evaluation context reflects the nondeterminism of scheduling between concurrent threads and in lvish the arguments to get put and application expressions are implicitly evaluated concurrently arguments must be fully evaluated however before function application reduction modeled by the rule can occur we can exploit this property to define let par as syntactic sugar let par x e y e in e x y e e e this is in contrast to the original formalism given in which models parallelism with explicitly simultaneous reductions because we do not reduce under terms we can sequentially compose e before e by writing let e in e which to e e sequential composition is useful for instance when allocating a new lvar before beginning a set of operations on it semantics of new put and get in lvish the new put and get operations respectively create write to and read from in the store · new implemented by the rule extends the store with a binding for a new lvar whose initial state is false and returns the location l of that lvar ie a pointer to the lvar · put implemented by the and rules takes a pointer to an lvar and a new lattice element d and updates the state to the least upper bound of the current state and d false potentially the state of the lvar upward in the lattice any update that would take the state of an lvar to p results in the program immediately to error · get implemented by the rule performs a blocking threshold read it takes a pointer to an lvar and a threshold set p which is a nonempty set of lvar states that must be pairwise incompatible expressed by the premise a threshold set p is pairwise incompatible iff the lub of any two distinct elements in p is p if the state p in the lattice is at or above some p p the get operation and returns p note that p is a unique element of p for if there is another p p in the threshold set such that p p p it would follow that p p p p p which contradicts the requirement that p be pairwise incompatible is the get operation deterministic consider two lattice elements p and p that have no ordering and have p as their lub and suppose that puts of p and p and a get with p p as its threshold set all race for access to an lvar lv eventually the program is guaranteed to fault because p p p p but in the get lv p p could return either p or p therefore get can behave this behavior is not observable in the final answer of the program which is guaranteed to subsequently fault the after with primitive the lvish calculus includes a simple form of that immediately an lvar see more interesting is the after with primitive which models the pattern described in section the expression after with has the following semantics · it the callback to the lvar the expression must evaluate to a event set q the callback will be executed once for each lattice element in q that the state reaches or the callback is a function that takes a lattice element as its argument its return value is ignored so it runs solely for effect for instance a callback might itself do a put to the lvar to which it is attached yet more callbacks · if the handler reaches a state the lvar is frozen and its exact state is returned rather than an underapproximation of the state as with get we that although is given as a premise of the reduction rule that it is checked at runtime in our real implementation threshold sets are not written explicitly and it is the data structure authors to ensure that any provided read operations have threshold semantics see section given a lattice d with elements d d p p p p p p p p p s e s e s ee s e e s x e v s ex v l doms s new sl false l sl p p p p d false p p s put l d sl p sl p p p d false p s put l d error sl p p p s get l p s p p p p s l after q with x e s l after q with x e sl d d d d h d q s l after q with x e e h s l after q with x e ex d e d h sl d d d d d q d h s l after q with v v h sl d true d sl d s l sl d true d figure an operational semantics for lvish to keep track of the running callbacks lvish includes an auxiliary form l after q with x e e h where · the value l is the lvar being · the set q a subset of the lattice d is the event set · the value x e is the callback function · the set of expressions e are the running callbacks and · the set h a subset of the lattice d represents those values in q for which callbacks have already been due to our use of evaluation contexts any running callback can execute at any time as if each is running in its own thread the rule a new callback thread any time the current value is at or above some element in q that has not already been handled this step can be taken nondeterministically at any time after the relevant put has been performed the rule detects by checking that two properties hold first every event of interest lattice element in q that has occurred is bounded by the current lvar state must be handled be in h second all existing callback threads must have terminated with a value in other words every enabled callback has completed when such a state is detected the state like the rule can at any time nondeterministically that the handler appears property but after being frozen any further puts that would have enabled additional callbacks will instead fault raising error by way of the rule therefore is a way of that once a collection of callbacks have completed no further puts that change the value will occur for a given run of a program either all puts to an lvar arrive before it has been frozen in which case the value returned by after with is the lub of those values or some put after the lvar has been frozen in which case the program will fault and thus we have at a program will always either evaluate to the same answer or it will fault to ensure that we will our we need to guarantee that is a state rather than a is we need to perform all puts either prior to after with or by the callback function within it as will be the case for fixpoint computations in practice is usually the very last step of an algorithm its result to be extracted our implementation provides a special function that does so and thereby guarantees full determinism modeling lattice in redex we have developed a version of the lvish calculus using the plt redex semantics engineering in the redex of it is not possible to directly a language definition by a lattice instead taking advantage of syntactic abstraction capabilities we define a macro that a template implementing the semantics of figure and takes the following arguments · a name which becomes the passed to form · a operation a procedure that takes a lattice element and returns the finite set of all lattice elements that are below that element this operation is used to implement the semantics of after with in particular to determine when the rule can · a lub operation a procedure that takes two lattice elements and returns a lattice element and · a possibly infinite set of lattice elements represented as redex patterns given these arguments generates a redex model specialized to the lattice in available at see discussion at tion for instance to instantiate a model called nat where the lattice is the natural numbers with max as the least upper bound one writes nat max natural where is separately defined here and max are procedures natural is a redex pattern that has no meaning to proper but because is a macro natural is not evaluated until it is in the context of redex for lvish our proof of for lvish formalizes the claim we make in section that for a given program although some executions may raise exceptions all executions that produce a final result will produce the same final result in this section we give the statements of the main theorem and the two most important supporting lemmas the statements of the remaining lemmas and proofs of all our theorems and lemmas are included in the companion technical report and our main result theorem says that if two executions starting from a configuration terminate in configurations and then and are the same configuration or one of them is error theorem if and and neither nor can take a step then either up to a permutation on locations or error or error theorem follows from a series of lemmas the most important of these strong local lemma says that if a configuration steps to two different configurations then either there exists a single third configuration to which they both step in at most one step or one of them steps to error additional lemmas generalize lemma s result to multiple steps by induction on the number of steps eventually building up to theorem lemma strong local if s e a and b then either there exist i j and c such that a i c and b j c and i and j or a error or b error independence in order to show lemma we need a frame property for lvish that captures the idea that independent effects commute with each other lemma the independence lemma establishes this property consider an expression e that runs starting in store s and steps to e updating the store to s the independence lemma allows us to make a guarantee about what will happen if we run e starting from a larger store s s s first it will update the store to s s s second it will step to e as it did before here s s s is the least upper bound of the original s and some other store s that is on to s intuitively s is the store resulting from some other computation lemma independence if s e s e where s e error then we have that s s s e s s s e where s is any store the following conditions · s is with s e s e · s s s s and · s s s s lemma requires as a precondition that the stores s s s and s are equal in for all the locations shared between them the status bits of those locations agree this assumption rules out interference from finally the store s must be with the original transition from s e to s e meaning that locations in s cannot share names with locations newly allocated during the transition this rules out location name conflicts caused by allocation definition two stores s and s are equal in status written s s iff for all l doms doms if sl d and s l d then definition a store s is with the transition s e s e iff doms doms doms implementation we have constructed a prototype implementation of lvish as a monadic library in haskell which is available at our library the basic approach of the par monad enabling us to employ our own notion of lightweight threads with a custom scheduler it supports the programming model out in section in full including explicit handler it differs from our formal model in following haskells evaluation strategy which also means that concurrency in the library is explicitly marked either through uses of a fork function or through asynchronous callbacks which run in their own lightweight thread implementing lvish as a haskell library makes it possible to provide compiletime guarantees about determinism and because programs written using our library run in our par monad and can therefore only perform side effects we take advantage of this fact by indexing par computations with a type that indicates their determinism level data determinism the par type constructor has the following kind par determinism together with the following suite of run functions par a a par a io a a par a a the public library api ensures that if code uses it is marked as thus code that types as is guaranteed to be fully deterministic while lvish code with an arbitrary determinism level can be executed in the io monad using only code can be executed as if it were pure since it is guaranteed to be free of visible side effects of nondeterminism in the common case that is only needed at the end of an computation runs the computation to completion and then the returned lvar returning its exact value and is guaranteed to be deterministic we are here using the extension to haskell to treat determinism as a kind in the full implementation we include a second type parameter to ensure that cannot be used in multiple runs of the par monad in a manner analogous to how the st monad prevents an from being returned from the is used to perform of nested producing values of frozen type as given by the type function the big picture we two interacting with our library first there are data structure authors who use the library directly to implement a specific monotonic data structure eg a growing finite map second there are application writers who are clients of these data structures only the application writers receive a guarantee an author of a data structure is responsible for ensuring that the states their data structure can take on correspond to the elements of a lattice and that the exposed interface to it corresponds to some use of put get and event handlers thus our library is focused primarily on infrastructure the par monad itself a thread scheduler support for blocking and threads handler and event handlers since this infrastructure is unsafe does not guarantee only data structure authors should import it subsequently a limited interface specific to their data structure for finite maps for instance this interface might include insertion lookup event handlers and and with higherlevel abstractions built on top of these for this approach to scale well with available parallel resources it is essential that the data structures themselves support efficient parallel access a finite map that was simply protected by a global lock would force all parallel threads to their access thus we expect data structure authors to draw from the extensive literature on scalable parallel data structures techniques like finegrained locking and lockfree data structures data structures that fit into the lvish model have a special advantage because all updates must commute it may be possible to avoid the expensive synchronization which must be used for operations and in any case monotonic data structures are usually much simpler to represent and implement than general ones two key ideas atoms monotonic data structures acquire pieces of information over time in a lattice the smallest such pieces are called the atoms of the lattice they are elements not equal to but for which the only smaller element is lattices for which every element is the lub of some set of atoms are called and in practice most lattices used by lvish programs have this those whose elements represent collections in general the lvish primitives allow arbitrarily large queries and updates to an lvar but for an lattice the corresponding data structure usually operations that work at the atom level semantically limiting puts to atoms gets to threshold sets of atoms and event sets to sets of atoms for example the lattice of finite maps is with atoms consisting of all singleton maps ie all pairs the interface to a finite map usually works at the atom level allowing addition of a new pair of a single key or traversals which we model as handlers that over one pair at a time our implementation is designed to facilitate good performance for lattices by associating with a set of changes as well as a lattice for lattices the are essentially just the a set lattice a is an element for a map a pair provide a compact way to represent a change to the lattice allowing us to easily and efficiently communicate such changes between puts and idempotence while we have the commutativity of least upper bounds they also provide another important property idempotence meaning that d d d for any element d in lvish terms repeated puts or have no effect and since these are the only way to modify the store the result is that e e behaves the same as e for any lvish expression e idempotence has already been recognized as a useful property for scheduling if the scheduler is allowed to duplicate work it is possible to substantially save on synchronization costs since lvish computations are guaranteed to be idempotent we could use such a scheduler for now we use the standard but idempotence also helps us deal with races between put and as we explain below representation choices our library uses the following generic representation for data lvar a d lvar state a status status d where the type parameter a is the mutable data structure representing the lattice and d is the type of for the lattice the status field is a mutable reference that represents the status bit data status d frozen active d the status bit of an lvar is together with a bag of waiting which include blocked gets and handlers once the lvar is frozen there can be no further events to for the bag module imported as b supports atomic insertion and removal and concurrent traversal put bag a a io token a remove token a io foreach bag a a token a io io removal of elements is done via abstract tokens which are acquired by insertion or traversal updates may occur concurrently with a traversal but are not guaranteed to be visible to it a for an lvar is a pair of callbacks one called when the lattice value changes and the other when the lvar is frozen data d d token d io token d io the is given access to its own token in the bag which it can use to from future events useful for a get whose threshold has been passed it is also given access to the scheduler queue which it can use to spawn threads the core implementation internally the par monad represents computations in continuationpassing style in terms of their interpretation in the io monad type io type a a a par a the type represents par computations which are given direct access to the scheduler queue rather than returning a final result a completed computation must call the scheduler on the queue a par computation on the other hand completes by passing its intended result to its a computation figure gives the implementation for three core functions and which we explain next threshold reading the function data structure authors in writing operations with get semantics in addition to an lvar it takes two threshold functions one for global state and one for the global threshold is used to initially check whether the lvar is above some lattice values by global inspection the extra boolean argument gives the frozen status of the lvar the threshold checks whether a particular update for lattices we take a and d to be the same type in particular with one atomic update of the flag we both mark the lvar as frozen and allow the bag to be lvar a d a bool io maybe b d io maybe b par b status k q let d d state true q do b do q k b in do status case of frozen do no further can arrive state true case of just b exec k b q nothing q active ls do ls status must after state case of just b do remove the execute our continuation nothing q lvar a d a io maybe d par status k q do q our to modify the lvar state possibly modify lvar status read while q is marked q our d do case of frozen error attempt to change a frozen lvar active d q k q lvar a d par lvar status k q do q status s case of frozen return active q k q figure implementation of key functions takes the state of the lvar above some lattice states both functions return just r if the threshold has been passed where r is the result of the read to continue our running example of finite maps with pair we can use internally to build the following function that is exposed to application writers wait for the map to contain a key return its value key where m frozen lookup key m kv k key return just v otherwise return nothing where lookup looks up a key in the underlying map the challenge in implementing is the possibility that a concurrent put will push the lvar over the threshold to with such races a somewhat pessimistic strategy before doing anything else it a on the lvar that will be on any subsequent updates if an update passes the threshold the is removed and the continuation of the get is invoked with the result in a new lightweight thread after the checks the global threshold in case the lvar is already above the threshold if it is the is removed and the continuation is immediately otherwise invokes the scheduler effectively treating its continuation as a blocked thread by doing the global check only after a is sure not to miss any updates it does not need to between the and global if the threshold is passed just as runs it might the continuation twice once via the global check once via but by idempotence this does no this is a performance tradeoff we avoid extra synchronization on all uses of at the cost of some duplicated work in a case we can easily provide a second version of that makes the alternative tradeoff but as we will see below idempotence plays an essential role in the analogous situation for handlers putting and on the other hand we have the function used to build operations with put semantics it takes an lvar and an update function that performs the put on the underlying data structure returning a if the put actually changed the data structure if there is such a subsequently invokes all on it the implementation of is complicated by another race this time with if the put is nontrivial ie it changes the value of the lvar the race can be resolved in two ways either the takes effect first in which case the put must fault or else the put takes effect first in which case both succeed unfortunately we have no means to both check the frozen status and attempt an update in a single atomic step our basic approach is to ask rather than permission we perform the put and only check whether the lvar is frozen intuitively this is allowed because if the lvar is frozen the par computation is going to terminate with an the effect of the put cannot be observed unfortunately it is not enough to just check the status bit for for a rather subtle reason suppose the put is executing concurrently with a get which it causes to and that the getting thread subsequently the lvar in this case we must treat the as if it after the put because the could not have occurred had it not been for the put but by the time reads the status bit it may already be set which would cause to fault to guarantee that such confusion cannot occur we add a marked bit to each cpu scheduler state the bit is set using prior to a put being performed and using only after has subsequently checked the frozen status on the other hand until it has observed a clear mark bit on every cpu using before actually the lvar this guarantees that any puts that caused the to take place check the frozen status before the takes place additional puts that arrive concurrently may of course set a mark bit again after has observed a clear status the proposed approach requires no barriers or synchronization instructions assuming that the put on the underlying data structure acts as a memory barrier since the mark bits are flags they can generally be held in a cache line in exclusive that marking and them is extremely while we could require the underlying data structure to support such transactions doing so would the use of existing lockfree data structures which tend to use a operation to perform atomic updates lockfree data structures data structures the only time that the flags can create communication is during which should only occur once per lvar computation one final point unlike and which are polymorphic in their determinism level is statically handlers and given the above infrastructure the implementation of handlers is relatively straightforward we represent handler as follows data counter blocked where counter is a simple counter supporting atomic increment and checks for equality with zero we use the counter to track the number of callbacks which we can use to implement a handler pool also keeps a bag of threads that are blocked waiting for the pool to reach a state we create a pool using of type par and implement testing as follows par cnt bag k q do bag k cnt if then do k q else q where the function indicates whether cnt is zero note that we are following the same strategy as in but with blocked as the bag of finally has the following interface maybe pool to in lvar a d lvar to to a io maybe par global callback d io maybe par callback par as with handlers are specified using both global and threshold functions rather than returning results however these threshold functions return computations to run in a fresh lightweight thread if the threshold has been passed each time a callback is the callback count is when it is finished the count is and if zero all threads blocked on its are the implementation of is very similar to but there is one important difference handler callbacks must be invoked for all events of interest not just a single threshold thus the par computation returned by the global threshold function should execute its callback on eg all available atoms likewise we do not remove a handler from the bag of when a single threshold is passed handlers to an lvar until it is frozen we might for example expose the following foreach function for a finite map foreach cb lv where kv return just cb k v mp traverse mp kv cb k v mp here idempotence really off without it we would have to to ensure that no callbacks are duplicated between the global threshold which may or may not see concurrent additions to the map and the threshold which will catch all concurrent additions we expect such to be since they can one can use a scalable nonzero to implement counter but we have not yet done so only arise when a handler is added concurrently with updates to an lvar evaluation case study we now evaluate the expressiveness and performance of our haskell lvish implementation we expect lvish to particularly for complicated algorithms on structured data that pose challenges for other deterministic and composing stages of computation each of which may be internally in this section we focus on a case study that this controlflow analysis we discuss the process of a sequential implementation of to a parallel implementation using lvish in the companion technical report we also give results for lvish implementations of two search and maximal independent set the analyses provide a hierarchy of precise methods to compute the flow of values to expressions in a higherorder language for this case study we with a simple sequential implementation of translated to haskell from a version by might the algorithm processes expressions written in a calculus it a nondeterministic abstract interpreter in which stores map addresses to sets of abstract values and function application entails a cartesian product between the operator and operand sets further an address models not just a static variable but includes a fixed window of the calling history to get to that point the k in taken together the current redex environment store and call history make up the abstract state of the program and the goal is to explore a graph of these abstract states this phase is followed by a second summarization phase that combines all the information discovered into one store phase exploration the following function from the original sequential version of the algorithm expresses the of the search process explore set state state set state explore seen seen explore seen todo seen explore seen otherwise explore insert todo seen next todo this code uses haskell data types like and lists however it presents a with respect to parallelism consider to explore using purely functional parallelism with instance using the strategies library an attempt to compute the next states in parallel would seem to be by the the main thread forcing each new state to perform the check todo seen there is no way for independent threads to keep going further into the graph rather they check in with seen after one step we this prediction by adding a parallelism annotation next todo the ghc runtime reported that of created futures were that is the main thread forced them before any thread could changing to exposed a small amount that said it is possible to avoid all duplication by adding further synchronization and in research we are exploring various locking and timestamp schemes to do just that haskell port by max of parallelism futures were successfully executed in no actual speedup phase summarization the first phase of the algorithm produces a large set of states with stores that need to be together in the summarization phase when one phase of a computation produces a large data structure that is immediately processed by the next phase lazy languages can often achieve a form of pipelining for free this outcome is most obvious with lists where the head element can be consumed before the tail is computed benefits unfortunately when processing a pure set or map in haskell such pipelining is not possible since the data structure is internally represented by a balanced tree whose structure is not known until all elements are present thus phase and phase cannot overlap in the purely functional they will in the lvish version as we will see in fact in lvish we will be able to achieve partial deforestation in addition to pipelining full deforestation in this application is impossible because the sets in the implementation serve a memoization purpose they prevent repeated computations as we traverse the graph of states to the lvish library our first step was a port to lvish we changed the original purely functional program to allocate a new lvar for each new set or map value in the original code this was done simply by changing two types set and map to their monotonic lvar counterparts and in particular a store maps a program location with context onto a set of abstract values import as im import as is type store s addr s s value next we replaced allocations of containers and operations over them with the analogous operations on their lvar counterparts the explore function above was replaced by the simple graph traversal function from section these changes to the program were mechanical including converting pure to monadic code indeed the key insight in doing the port to lvish was to consume as if they were pure values ignoring the fact that an contents are out over space and time and are modified through effects in some places the style of the code is functional while in others it is imperative for example the summarize function uses nested foreach invocations to data into a store map summarize s state s par d s store s summarize states do states state store store key key return while this code can be read in terms of traditional parallel nested loops it in fact creates a network of handlers that incremental updates from one lvar to another in the style of dataflow networks that means in particular that computations in a pipeline can immediately begin reading results from containers eg long before their contents are final the lvish version of contains occurrences of foreach as well as a few operations the cartesian products serve to apply functions to combinations of all possible values that arguments may take on greatly increasing the number of handler events in moreover chains of handlers with foreach result in of events through six or more handlers the runtime behavior of these would be difficult to reason about fortunately the programmer can largely ignore the temporal behavior of their program since all lvish effects explore summarize states stores seen figure simplified handler network for exploration and summarization processes are driven by the same lvar the foreach calls in summarize become a chain of three handlers like the way in which a lazy functional programmer typically need not think about the order in which thunks are forced at runtime finally there is an optimization benefit to using handlers normally to a nested data structure such as int in a functional language we would need to one layer at a time and allocate a series of temporary structures the lvish version avoids this for example in the code for summarize above three foreach invocations are used to traverse a structure and yet the side effect in the innermost handler directly updates the final the switch the port uses copying them repeatedly and them without modification this effect the benefits of partial deforestation and pipelining and the lvish port has a small performance overhead relative to the original but not for long the most clearly unnecessary operation in the port is in the next function like the pure code it creates a fresh store to extend with new bindings as we take each step through the state space graph store store of course a copy for an lvar is persistent it is just a handler that forces the copy to receive everything the original does but in lvish it is also trivial to the parallel branches of the search allowing them to share information about bindings simply by not creating a copy let store store this change up execution by up to × on a single thread and the asynchronous parallelism enables subsequent parallel speedup as well up to × total improvement over the purely functional version figure shows performance data for the benchmark drawn from a recent paper on we use k for the benchmarks in this section in general it proved difficult to generate example inputs to that took long enough to be candidates for parallel speedup we were however able to scale up the benchmark by the code n times one into the continuation argument for the next figure also shows the results for one benchmark that to the benefits of our sharing approach which is simply a long chain of not functions using a cps conversion of the church encoding for booleans it has a small state space of large states with many variables states and variables the role of lockfree data structures as part of our library we provide lockfree implementations of finite maps and sets based on concurrent skip lists we also provide reference implementations that use a inside a mutable container in fact this project is the first to incorporate any lockfree data structures in haskell which required solving some unique problems parallel speedup linear speedup threads figure parallel speedup for the and benchmarks speedup is normalized to the sequential times for the lockfree versions s and s respectively the normalized are consistent for the lockfree version between the two benchmarks but the relationship to the original purely functional version is quite different at the lockfree lvish version of is × faster than the original while is only × faster not anything from sharing rather than copying stores due to a lack of in the state graph our scalable implementation is not yet carefully optimized and at one and two our lockfree is to slower than the reference implementation on the benchmark but the effect of scalable data structures is quite visible on a core machine without them replicated × stops scaling and begins down slightly after four even at four variance is high in the reference implementation s s over runs with lockfree structures by contrast performance improves to a speedup of × on s at gc part of the benefit of lvish is to allow purely functional programs to make use of lockfree structures in much the same way that the st monad allows access to efficient array computations related work monotonic data structures traditional approaches lvish builds on two long of work on parallel programming models based on shared data structures · in kahn process networks as well as in the more restricted synchronous data flow systems a network of processes communicate with each other through blocking fifo channels with channel histories each process computes a sequential monotonic function from the history of its inputs to the history of its outputs enabling pipeline parallelism are the basis for deterministic languages such as · in parallel languages bits are associated with heap locations so that they may be written to at most once locations with blocking read is have appeared in concurrent ml as in the intel concurrent collections system in languages and libraries for computing such as and the library and have even to haskells laziness and the ghc compilers assumptions regarding but we lack the space to detail these improvements intel full machine details available at been implemented in hardware in machines although most of these uses incorporate into programming environments haskells par monad on which our lvish implementation is based uses in a setting allowing threads to communicate through without requiring io so that such communication can occur anywhere inside pure programs are general enough to both and a lattice of channel histories with a prefix ordering allows to represent fifo channels that implement a kahn process network whereas an lvar with empty and full states where empty full behaves like an as we described in section hence provide a framework for generalizing and unifying these two existing approaches to deterministic parallelism deterministic parallel java is a deterministic language consisting of a system of annotations for java code a sophisticated type system ensures that a mutable region of the heap is essentially passed linearly to an exclusive writer thereby ensuring that the state accessed by concurrent threads is disjoint does however provide a way to assert that operations commute with one another using the form to enable concurrent mutation lvish differs from in that it allows overlapping shared state between threads as the default moreover since lvar effects are already commutative we avoid the need for annotations finally it is worth noting that while in commutativity annotations have to appear in code in lvish only the datastructure author needs to write trusted code the application programmer can run untrusted code that still a guarantee because only programs can be expressed as lvish par computations more recently et al proposed a type and effect system that allows for the of nondeterministic sections of code in the goal here is different from ours while they aim to support nondeterministic computations such as those arising from optimization problems like search arises as a result of schedule nondeterminism et al recently proposed a data structure with an api closely related to ideas in lvish a is a bag that allows concurrent but a operation that further updates and combinators like foreach that invoke callbacks as data in the pool to retain determinism the operation requires explicitly passing the expected bag size as an argument and the program will raise an exception if the bag goes over the expected size while this interface has a similar to lvish it lacks the ability to detect which is crucial for supporting examples like graph traversal and the operation is to use when the structure of data is not known in advance by contrast our operation is more expressive and convenient but moves the model into the of another important difference is the fact that lvish is data both our formalism and our library support an collection of data structures whereas are specialized to nevertheless represent a in the deterministic parallel design space by allowing handlers but not general they retain determinism while improving on the expressivity of the original model we claim that with our addition of handlers lvish generalizes to add support for arbitrary data structures concurrent the concurrent cr programming model uses isolation types to distinguish regions of the heap shared by multiple mutators rather than enforcing exclusive access cr a copy of the state for each mutator using a deterministic merge function for conflicts in local copies at join points unlike writes cr merge functions are not necessarily commutative the default cr merge function is still turn up in the metatheory of cr in particular and show that for any two vertices in a cr diagram there exists a greatest common ancestor state which can be used to determine what changes each side has interesting duality with our model in which any two lvar states have a lub while cr could be used to model similar types of data structures to variables used least upper bound as their merge function for would only become visible at the end of parallel regions rather than asynchronous communication within parallel regions this the use of traditional lockfree data structures as a representation replicated data types in the distributed systems literature eventually consistent systems based on replicated data types lattice properties to guarantee that in a distributed database eventually agree unlike allow intermediate states to be observed if two are updated independently reads of those may until a merge operation takes place various techniques can ensure that updates such as removal of elements from a set are not lost the language for distributed database programming combines with monotonic logic resulting in a confluent language that is a close relative of lvish a monotonicity analysis pass rules out programs that would perform operations on distributed data collections whereas in lvish monotonicity is enforced by the lvar api future work will further explore the relationship between and in one direction we will investigate data structures inspired by that support operations in the other direction we will investigate the feasibility and of lvar threshold reads in a distributed setting acknowledgments and work on this paper was by nsf grant references r s and k k data structures for parallel computing acm trans program lang syst october h r d p m m michael and m laws of order expensive synchronization in concurrent algorithms cannot be eliminated in popl d a and k designing multithreaded algorithms for search and on the in r l jr v s s v and m parallel programming must be deterministic by default in r l jr v s d s v s r j p h and m a type and effect system for deterministic parallel java in oopsla r l jr et al safe nondeterminism in a parallel language in popl z m v k g r j palsberg d v sarkar f and s concurrent collections sci program august s and d semantics of concurrent in esop b l d and h p parallel and the language international journal of high performance computing applications d and y dynamic circular in n w p j m and d logic and lattices for distributed programming in c i m might and d van horn pushdown analysis of higherorder programs in icfp f y v and m scalable nonzero in m felleisen r b findler and m semantics engineering with plt redex the mit press st edition k fraser practical phd thesis m i gordon w m j lin a s c a a j h d z and s a stream compiler for architectures in m and n the art of multiprocessor programming morgan g kahn the semantics of a simple language for parallel programming in j l editor information processing north holland amsterdam aug l and r r data structures for deterministic parallelism in l a n r and r r after writing parallel programming with technical report tr university november url e lee and d synchronous data flow proceedings of the ieee ­ d m and s concurrency purely functional concurrent in haskell s p m k and p seq no more better strategies for parallel haskell in haskell s r and s peyton jones a monad for deterministic parallelism in haskell m m michael m t and v a idempotent work in m might determining types andor control flow in languages like python java and scheme r s id language reference manual s l peyton jones r g and m m t the nested data parallelism in haskell in a h t p and m odersky a lockfree deterministic concurrent dataflow abstraction in j h concurrent programming in ml cambridge university press cambridge m shapiro n c and m replicated data types in l g and h j a language design for concurrent processes in k b r c and d an api for programming with of lightweight threads 