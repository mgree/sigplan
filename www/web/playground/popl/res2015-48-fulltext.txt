from network interface to multithreaded web applications a case study in modular program verification mit popl consist complete well easy to abstract many of realistic software systems are monolithic in the sense that they define single global invariants over complete system state more modular proof techniques to support reuse of component proofs and even reduce the effort required to verify one concrete system just as modularity simplifies standard software development this paper reports on one case study applying modular proof techniques in the coq proof assistant to our knowledge it is the first modular verification a system that combines infrastructure with an application of interest to end users we assume a nonblocking api for tcp streams and on top of that we work our way up to multithreaded web applications key verified components include a library and an implementation of a domainspecific language for xml processing we have our system on mobile where it interfaces with components for and control categories and subject descriptors f logics and meanings of programs specifying and verifying and reasoning about programs mechanical verification d software engineering verification correctness proofs keywords modular program verification proof thread libraries servers domainspecific languages introduction program verification for realistic systems is very the proof all of the usual challenges of the software and then some typically a proof of program correctness requires more human effort than implementing the software system in the first place modularity is an essential part of the programmers in complexity and we might ask for the same in verification we want a programs proof to its natural decomposition into components each component should be proved to respect a formal interface and we reason about the component only through its interface not only does this style allow us to reuse component proofs permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ copyright is held by the publication to acm acm in of different full systems but it also frequently the effort to verify just one system for the same reason the author of a program with a data structure may choose to that data structure in its own class or module even with no expectation for future reuse in other programs the most recent system are not modular the and projects have both verified kernels with different proof tools their proofs are structured around global invariants relating all state of all system components both in the kernel and in relevant parts of applications when one part of a kernel changes the global invariant must often be modified and the proofs of all other components must be proof automation is able to use annotations and proof scripts to the new proofs but in practice the proof is often required to old proof details of system modules the one he has changed such between proof pieces is and we feel that it should be for certain kinds of changes like applying an optimization that does not affect a components behavior a variety of results have also been published for modular verification systems modular program logics have been demonstrated for a variety of features of lowlevel code including dynamic thread creation function pointers control operators code garbage collection and interrupts however these past projects never applied modular verification at scale a full system of interest to end users in theory the frameworks were set up to allow linking of proofs about systems infrastructure and applications to produce proofs but the is in the details this paper is about those details we present the first realistic case study in modular mechanized program verification establishing properties of a application what exactly we mean by realistic we will out below one key element is separate proof of an application and systems infrastructure in our case the application is a dynamic web application and the infrastructure is a library one subtle source of difficulty is supporting infrastructure that itself needs to play with other modules of infrastructure some of which may not even have been written or specified yet contrast that with the and proofs which show correctness of os kernels assumed to have exclusive control over all elements of machine state or the proof of the compcert c compiler which assumes that no other compiler will be used to produce code in the final program other elements of have produced further challenges which we needed to solve on the way to an application with real users who are not what properties would we expect to see of modular in a future world where such activities are standard at least for code of particular importance · not all verified components will have theorems at the same level of detail the reason is the classic that a word processor does not have an obvious specification worth proving also different parts of a system may be of varying importance where the proof wants to more effort in more important components via more precise theorems · not all software in the final system will be verified it is necessary to have some kind of function interface to connect to conventional components · there will be further modular structure within infrastructure components and this structure must be designed to facilitate effective reasoning in client code for instance in the components of a thread library we need to think carefully about which interfaces to assign to the data structures used to implement the scheduler where we feel to make the interfaces as weak as possible to minimize proof effort however we are building these modules so that they may eventually be linked with client code where we feel to make the infrastructure interfaces as strong as possible to give the client flexibility · some components will be implemented in domainspecific languages but we do not want to have to trust anything about those languages or their implementations our case study uses a for declarative xml processing and access to a relational database · most proof details should be automated it is to require detailed manual proof for each line of program code · most importantly we must actually link our proofs of infrastructure components with proofs of applications to form theorems a proof of infrastructure is only as good as the sorts of proof composition it enables to the best of our knowledge no past work in modular verification has produced a case study any of the above principles whereas ours involves all of them our verification was done in the coq proof assistant using the library whose basic functionality we review in more detail is a platform for producing verified assembly code by programming proving and compiling entirely within coq our application is a replacement for the socalled server of the popular robot operating system is a platform for implementation of software systems are structured as networks of nodes processes that communicate only via mostly with tcp messages are largely via a architecture among other services the server processes node requests to or to particular named topics it must maintain an database mapping node names to ip addresses and ports mapping topics to their and and so on the server the protocol and runs as a web server our version of it has been on several and used to coordinate the interaction of nodes for and control algorithms the system infrastructure we have verified is a library as unverified primitives we assume functions for opening tcp and sending and receiving byte streams over them furthermore we require system calls for efficient to determine which have new data to pro all the assumed primitives are nonblocking on top of them we implement a library that supports the standard abstraction of threads blocking during calls to io functions without forcing programmers to their code into continuationpassing style we prove a deep functional correctness theorem for the thread library where bugs can lead to particularly where one thread the private state of another to demonstrate the possibility to mix proofs at different in one verification we verify the application at the level of datastructure shape invariants mostly to the relational database we link the module proofs together into a proof the unifying specification style applied to the final program is various points in the assembly code eg entry labels of crucial functions are labeled with invariants in higherorder logic formalizing properties of machine state that should always hold upon reaching those points we prove that starting from an initial program location whose invariant is satisfied execution will proceed safely forever never reaching a program point whose invariant is false regardless of what nondeterministic results system calls return these invariants can be at many different levels of invariants within our thread library encode detailed requirements for functional correctness while invariants in our application code focus more on shape invariants of data structures like the relational database all invariants throughout the program must formalize enough of essential isolation properties to guarantee lack of of other modules data structures section gives a more detailed outline of what we have proved and section the relevant aspects of the framework the next few sections present our main contributions · section explains how to extend with a treatment of system calls to model interaction with conventional unverified libraries · section introduces three verification design patterns that we found essential to meet our standard of proof modularity and automation we present a new style of definition for recursive predicates that are higherorder and stateful a new formal interface style for components of thread libraries or others working with firstclass code pointers and a new take on classic rules that is compatible with verifying the building blocks of domainspecific languages · the next two sections present particular modular verification architectures that we found work well for our components section presents the architecture of our library and section the architecture of our verified compiler for a for xml processing and relational database operations · finally one contribution that we want to most is that our proofs apply to real code that has been outside a context section gives some empirical analysis of our proofs and executable code which we do not believe has been done before for verified systems the complete source code of this project for both proofs and generating executable linux programs is available on the project web site system architecture summary before to technical details we take a moment to sketch the full layered architecture that we have verified different levels of this architecture have separately proofs and we combine all the proofs treated as black boxes into one final theorem about a particular linked assembly program to summarize our results the unifying verification formalism is based on invariant checking programs contain assertions written in higherorder logic that is they may express much more properties than in executable assertions each module contains code with assertions plus assumptions on other modules plus proofs that the assumptions imply that no assertions are violated while we are running code from this module our final program is a large assembly source file about lines where each basic block begins with an assertion but we produce this code by verified compilation from higherlevel languages with their own notions of where assertions again in higherorder logic not just executable code are allowed the final theorem is that the assembly code runs without assertion violations the platform is singlethreaded at its lowest level we verify assembly programs with respect to a operational semantics we do not take advantage of parallelism as a performance optimization but rather we use concurrency as a convenient idiom with multiple threads running and in different io interactions the thread model is where threads yield control of the processor explicitly by calling particular library functions we prove functional partial correctness of our thread library by giving it very expressive assertions sufficient to enable easy verification of similar functional correctness of simple applications eg proving that a factorial program really computes factorial despite context switches to other threads in the middle of its computation application assertions that we prove are about datastructure shape invariants for instance we have an relational database involving nontrivial use of arrays with index arithmetic at runtime and linked lists in future work we would hope to establish stronger properties but we also consider it to demonstrate that modular verification is not all or nothing rather different parts of a system may be verified at different while still allowing fully rigorous linking into useful results our proof is structured into several software layers we expand on each layer in later sections but here is a quick summary device abstraction api we begin from a layer providing a set of system calls for basic nonblocking access to a network and stack without our proofs this layer could just as well be a simple communication mechanism as the details of are orthogonal to the properties we verify data structures algorithms our first verified layer considers core data structures such as the free list of a malloc implementation and the fifo queue at the of a thread scheduler challenges here have to do with reasoning about data structures pointer aliasing and their connection to higherlevel interfaces like finite multiset to be exported to higher layers thread context management next we provide an abstraction of queues of suspended threads verification challenges center on the relationship between memory and firstclass code pointers ie saved instruction pointers of threads each thread must be considered to own some private memory but also to access some shared memory containing data structures that other threads access as well functions at this level must break basic abstractions of code implementing a coroutine style by storing function return pointers in heap data structures rather than just returning to them as usual the interface for this level should hide such details so that higher layers may that a normal discipline is being followed blocking io abstraction the next challenge is to provide a simple interface that enables easy overlapping of io and computation while the lowest layer of our system nonblocking io functions we combine them with thread queues to implement blocking io plus dynamic thread creation and destruction the interface of this level should make blocking io calls appear very similar to the nonblocking calls hiding the fact that threads may themselves into queues while waiting for io events to be enabled data structures algorithms we implement a simple relational database with standard data structures for representing table state domainspecific language our application must both access the database and do parsing and generation of xml since it provides an web service we implemented a domainspecific language called the web service language which more or less allows us to execute intuitive for such operations our language has a verified compiler so programmers do not need to do any manual proof to generate a theorem corresponding to a compiled application showing that it maintains the invariants of the database does not interfere with other threads etc application logic finally we implement the service as a program in about lines of code calling library tactics to its proof layers through would be considered as a thread library in unix they implement functionality similar to what has been treated in projects like those projects have generally given operational specifications to kernels via nondeterministic programs expressing how the kernel should to hardware and events in the modular verification style we adopt here we instead specify all layers of the system in terms of invariants that are and with preconditions and postconditions of functions the two approaches can be related to each other formally and the invariant style to make for easier verification of properties of course one can always ask for more specific theorems about programs and it is hard to come up with a formal characterization of full functional correctness for a full system for instance most theorems assume correctness of hardware at some level and our proof goes even further in considering a stack to be outside the scope of what we verify however we do not assume any other services traditionally provided by an operating system we need no virtual memory no process interrupts and so on the program style is set up to be compatible with execution in future work we start with our specifications as this case study is at learning pragmatic about modular program proofs from first principles review of our verification is done using a coq library that provides formal definitions proof procedures and syntax macros which together enable implementing specifying verifying and compiling lowlevel programs within coq at the core of is the il a kind of assembly language in the end every program we verify is compiled to the il and our correctness theorems are stated in terms of this language and its semantics every assembly basic block begins with an invariant and we prove that each invariant holds each time it is visited we compile il to bit or bit x assembly code for vars coq propositions p prop machine words w w machine states s coq terms v propx p w x x v figure syntax of the xcap assertion logic execution in linux that final translation is currently unverified but it works in a particularly simple way essentially each il into a sequence of in the target language though the core features deal with an assembly language provides infrastructure for combined verification and compilation of an extensible language the structured programming system and our explanation in this paper begins at that abstraction layer we will write code that looks like c it is important to note that these programs appear within coq source files that also contain theorem statements and proofs takes advantage of extensible parser to embed syntax of other languages we make further use of the same facility to embed our new web service language whose verified compiler is also built on top of to avoid redundant proofs about lowlevel code generation we refer readers to past for details of the lower abstraction levels that we for the rest of this paper implements the xcap program logic and inherits the sorts of final program correctness theorems that xcap supports xcap is designed for modular verification of programs that manipulate code pointers as data in such a setting it is not obvious what is an appropriate notion of specification for functions one might try defining a domain of specifications like p w p s prop that is a specification is a predicate over both machine states s and mappings from program counters w to the specifications of the associated code blocks some sort of ability for specifications to refer to specifications or code of other blocks is essential for verifying higherorder programs unfortunately the recursive equation has no solution as a simple cardinality argument shows several more involved notions of specification have been studied many are based on step indexing where otherwise recursive definitions are made wellfounded by adding extra parameters counting steps of program execution that remain xcap and thus our work in this paper is based on an alternative approach a specification language is defined with a deep embedding or an explicit definition of syntax trees in coq xcap uses the propx language shown in figure propx is a secondorder assertion language that includes most of the usual connectives features include p for lifting a normal coq proposition into propx and w a kind of hoare double for that the precondition of the code block pointed to by w is the function from il machine states to propx formulas introducing this connective solves the problem with specifications that reference other specifications just as a classic static type system allows eg a map function to constrain its argument using a syntactic function type xcap allows eg an map function to constrain its argument using a syntactic hoare double nested within maps precondition the soundness of either reasoning pattern is justified by considering that at each point in program execution we are run standard tcp operations port int void buf int int void buf int void io event rest bool rest figure list of system calls some code fragment that has been proved to meet a syntactic specification which accurately describes the current state usually one wants a more semantic notion w of a hoare double saying not that the given specification is attached to code block w but rather that the given specification implies ws specification semantically both this notation and the hoare triple of separation logic are defined by macro expansion to uses of · · and other connectives also crucial to the expressiveness of propx is the inclusion of secondorder quantification over predicate variables for instance in our thread library verification we use this feature to quantify over invariants describing the private state of individual threads the semantics of propx formulas is given by a set of rules where the secondorder quantifiers receive the treatment of being given introduction rules but no elimination rules as a result reasoning may only be done at the meta level in normal logic reasoning about the syntactic definition of propx deduction here is where we run into the that seems always to sound specification for higherorder stateful programs as the soundness proof for the propx deduction system cannot be adapted naturally to cover elimination rules for these quantifiers in the rest of this paper we often adopt convenient like lifting brackets · in propx formulas that we are instead working in a more conventional higherorder logic earlier we sketched the basic idea of a verified module a unit of code annotated with invariant assertions plus assumptions about which invariants eg as pairs are associated with code labels in other modules plus proof that our own code never assertion violations if our assumptions are accurate xcap this style to the case of assembly code modules sets of basic blocks and a linking theorem combining the basic blocks of two modules when their assumptions are consistent linking module a with b may remove as assumptions about b and vice versa eventually we link enough modules to empty out the assumptions and we have a closed program the final theorem about a verified closed program is that it never violations of its invariant assertions we also get a standard memory safety property where code never accesses memory addresses or jumps to program labels once again however in this paper we take the details for granted hiding below the abstractions that provides we think in terms of verified modules invariants linking etc for modules of code system calls the last section existing tools that we rely on and we now turn to new contributions the next few sections discuss elements of modular verification that only show up when scaling to more buf len buf buf len r sp a a buf buf len m a ma m read r m r figure rule for read system call though it is convenient to state our final theorems in terms of this relatively simple operational semantics reasoning about this style of specification directly is so we it in the higherlevel notation that provides and we prove that each implies the original for a concrete example consider this hoare triple that we prove for the read function buf buf len realistic systems we begin here with the question how do we support integration with unverified support code we extended the il with new system calls trusted primitives outside the scope of our verification upon which we depend to provide an efficient interface to the outside world since we focus on servers our system calls all relate to tcp network connections and io these system calls expose only nonblocking operations with no on sharing resources eg the network across different software components instead we implement such in and verify our implementations figure shows c for our trusted system calls the first group of functions provides a simplified version of the standard api we write fd t for the type of file descriptors here for open connections again we emphasize that all of these operations are nonblocking for example any call to read will return immediately with an error code if no bytes are available to read on top of this interface we built a verified implementation of the standard abstraction with blocking io to enable efficient of the kind needed to implement blocking io we use two additional system calls in the style of a function declare is called to register to read or write a particular producing a value called a later when the program makes a wait system call the result is a whose associated io operation is now ready to execute a call to wait itself may either be blocking if the program has no other useful work to do without further io opportunities or nonblocking if there is further work to do while waiting for io conceptually in the former case the system blocks until one of the io events becomes enabled at which point that id is returned we have extended the il semantics to include these system calls as primitive operations explained via one new rule per system call figure gives an example rule for read the semantics is smallstep operating on states of the form m pc r where m is memory pc the program counter and r values of registers two registers in particular matter here to formalize the calling convention that read expects the stack pointer sp and the return pointer rp which stores a code address to return to after the call the first few premises in figure formalize the precondition of read in order we have that the stack pointer indicates a valid memory segment at least bytes containing the values of passed parameters two particular stack slots contain the values of parameters buf and len and the memory region by those parameters is valid the remaining premises constrain the result state of this step we say that the stack pointer sp is guaranteed to be and that only memory addresses within the passed buffer may be modified note that the rule is quite nondeterministic we give a conservative characterization of the unverified code that we link against in particular rather than formalizing the effect of the function we just describe which parts of state it may change the notation a n asserts that memory address a is the beginning of an accessible memory region of n bytes the read specification is not fully precise for instance the file descriptor is not mentioned at all we do not model the detailed semantics of network access instead conservatively modeling reading from the network as nondeterministic our concern is more with verifying the correct management of resources internal to a single server so specifications focus on memory layout and transfers of control we implemented the system calls mostly in c with some assembly code to between the calling convention and the native conventions of target platforms three verification design patterns the last section discussed the operational semantics that we use to state our final theorem recall that programs at any level of are annotated with invariant assertions and we prove that assertions always hold whenever we reach them we now describe three design patterns we developed in the course of choosing good invariants and good ways of proving that they always hold defining higherorder recursive predicates a challenging question arising in many verification tasks is how should we define recursive stateful higherorder predicates that is we need logical predicates that constrain both mutable state and firstclass code pointers small changes in the formalism may bring large consequences for the ease of proof automation past work on verifying a thread library in xcap this challenge by extending xcap with a new recursive µ connective that specification style turns out to make automation especially challenging for reasons that we explain the natural use of recursive predicates in our setting is for queues of suspended threads the associated data representation predicate must be higherorder because it deals with code pointers for suspended threads and recursive because the preconditions of those pointers must mention the same predicate we are defining the last condition follows because we expect threads to be able to call into the thread library whose methods will naturally be specified in terms of the same thread queue predicate in this section we discuss sound encodings of such predicates using a simpler motivating example that of a function memo table structure that stores both a function and an optional return value for it we would like to expose our memo table as an abstract data type with an abstraction relation that implementation details the code module implementing memo tables should expose methods for allocating new tables setting the function stored in a table and the return value of a current function for simplicity we consider only stored functions with no arguments and no private state satisfying deterministic specifications since we model simple pure functions a number n serves as a specification for such a function giving the result that it must always return so it makes sense to define the invariant of memo tables as a predicate n over the pointer p to the table and the function specification n here is a first cut at the cache precondition of code figure sketch of a recursive higherorder specification for a simple memo table predicate definition in style which makes intuitive sense but has a formal that we come to n f c p f c c c n nf n result n we write that a memo table is a record in memory indicated by the pointsto operator in particular p points to a record containing some values f a function pointer and c a cache of the current functions result or to indicate that the cache is invalid the next clause of the definition enforces cache validity where any nonzero c value must match the expected function return value the final clause a specification to f via a hoare triple it must be legal to call in any state where the memo table itself remains present with the same parameters and if it terminates it must return the expected result n while preserving a memo table in memory figure this predicate definition we introduce a convention followed throughout this paper of indicating encapsulation boundaries with dashed in this example the only component is the memo table module we indicate the recursive reference within the predicate definition with a dashed line connecting the overall predicate name to a smaller copy of the predicates box elsewhere here the smaller copy appears within a thought indicating a specification to a code pointer this programming pattern is associated with the idea of where a program without explicit recursion may nonetheless become recursive by firstclass function values in a mutable store application to abstract data types in separation logic has been studied before not just for the xcap thread library project that we build on but also in a variety of other recent work eg with impredicative concurrent abstract predicates our solution here also uses impredicative quantification which is built into propx language in an essential way a predicate like this one can be used in an abstract specification to a method such as the following ones for the function stored in a memo table and the current function result respectively the latter case to be implemented by and updating the cache as appropriate so that the stored function only needs to be called once n n f n result n f n n n result n unfortunately it is not obvious that the recursion in our definition of is wellfounded certainly treated like a recursive function in a programming language this definition does not terminate since one call invokes itself with the same arguments we might try to phrase it as an inductive definition as in coq and other proof expressed as the least relation satisfying a set of inference rules here we are still out of as proof must generally impose a restriction where an inference rule for a predicate p may not contain a premise like p x with an implication from the same predicate being defined it is hard to see how to encode preconditions such that the formulas inside them do not show up in just that kind of negative position this sort of is not a consequence of our choice of assertion logic related challenges appear in all work on semantics for higherorder programs with state one popular solution uses stepindexed relations to break in recursive definitions we instead use the syntactic features of xcap to make our definition legal past work on verifying a thread library in xcap extended the xcap assertion logic with a new µ connective for anonymous recursive predicates of course to retain soundness this connective cannot be given the obvious rules establishing µ p p µ p since then we would the usual logical of systems supporting definitions like p ¬p so this past work dealt with the of a restricted set of proof rules for µ in particular µ gets an introduction rule but no elimination rule forcing reasoning to take place only in the meta logic coq in terms of explicit syntactic statements about formula in our work we apply a new approach to recursive predicate definitions in xcap that imposes fewer restrictions on reasoning patterns which is especially helpful for the simpler proof automation that it enables rather than applying the analogue of anonymous recursive types from programming we instead apply an analogue of named recursive types we derive a connective name p for looking up the predicate associated with a textual name name and we allow program modules to include such definitions of named predicates which the connective will n f c p f c c c n p p p p nf p p n result n note that this definition is not explicitly recursive the predicate name does not appear in its own definition instead we see the referring to a label within an xcap code module our actual implementation gives each module its own separate label so there is no of across modules we note that this approach to recursive definition can be seen as an analogue to the wellknown recursion through the store at the level of specifications an interesting implementation detail is how we can derive the new connective from the original xcap connectives first a recursive definition of predicate name as p in a module is encoded as a code block labeled name whose specification is x p x embedding p into an xcap assertion in an arbitrary way next we define name p as x p x name using the syntactic hoare double to look up the specification associated with the right code block and assert it equal to a template built from p one subtle point here is that we want to allow any module to include predicates over any coq types the quantifiers in the templates above are implicitly annotated with the predicate type and at some point in a related proof we need to reason from the equality of two such formulas to the equality of their embedded predicates that reasoning step turns out to require the named axiom k which is the only coq axiom used anywhere in our development an important benefit of this new encoding compared to past work on a µ connective for xcap shows up in the definition of above the higherorder quantification over p appears front back pc sp pc sp global invariant and seen by all threads precondition of code stack gi state stack other threadlocal state figure in on invariant only in one conjunct of the definition of so only when reasoning about that conjunct do we need to deal with the incompleteness of rules for higherorder quantification only lines of code in the memo table implementation that actually call the function f will need to into that conjunct so straightforward proof automation can help us verify the rest of the code automatically applying the usual to the connectives this pattern into our verification of thread queues where manual human proving effort is only necessary for lines of code that resume suspended threads specifying layers of abstractions in verifying a thread library and its client code we benefit from several dimensions of modularity most obviously it should be possible to verify client code without knowing library implementation details however we also want to take advantage of proof modularity within the library raising the question which specification idioms apply effectively to modules within a thread library where each layer of the library suspended threads in some form past work with xcap on and thread libraries this question by not to verify any actual application code against the libraries let alone focus on human effort to verify a new client program creating a client experience requires widening the library specifications and in turn that widening reveals the benefits of the somewhat proofs across modules with state take as an example our component that suspended threads providing a fifo queue of thread entries our definition is very close to that from a prior xcap library but the key difference is in modeling parts of memory shared across threads that past work forced threads to operate only on their own private memory partitions modulo the ability to allocate and free memory blocks realistic applications need to share some state for instance in our final application the database is shared across threads consider the presentation of most of datastructure invariant in figure we maintain a queue as a linked list of saved instruction pointer pairs each saved stack pointer points to some memory region that is private to the associated thread and there is also a shared memory region described by the global invariant the appears in deciding which requirements to assert for the saved code pointers we face the challenges in recursive predicate definition from the prior subsection plus additional associated with state both threadlocal and shared figure gives the formal definition that we on which we will explain in pieces though many singlethreaded data structures have obvious notions of correctness a concurrent structure like the raises questions of how we specify the rules for sharing of state across threads many are possible and we adopted one simple choice here our specifications would be quite if we took the idea of a global invariant or a fixed property that must always hold of shared memory invariants may over time for instance in the overall thread scheduler we want the invariant to change as the set of open files expands since the invariant to enforce that certain pointers only go to valid open files we formalize a more general using the idea of state a client programmer of is allowed to choose a set of worlds w such as sets of open file pointers furthermore an evolution relation must be provided to characterize how the world is allowed to change over time this relation must be reflexive and transitive but no further restrictions are enforced monotonic evolution of state is not sufficient for stating all of the invariants one might care about like that there are no dangling references to closed file records but it provides a useful starting point for logical interfaces to expose to applications in higher layers of our stack we the need to rule out dangling file references by file records in a free list and keeping dummy data in any free records the global invariant may now be given as a predicate over w and the root pointer of the concretely the module in coq is a functor in the sense of ml module systems its parameters are w and the global invariant predicate plus some logical axioms that must be proved about them eg transitivity this use of worlds and an evolution relation is inspired by the various semantic techniques based on kripke structures such as kripke logical relations for compiler verification binary relations for concurrent program verification have a long history including in relyguarantee proof methods which have been used both for proofs and in with refinement types and in the object invariants of as an example of one of the proved specifications for methods here is the specification for yield w w q q malloc w w w w q q malloc the specification is in the style of separation logic which uses the operator to indicate by p q that memory can be split into two disjoint regions one satisfying p and the other satisfying q we write tq for the invariant sketched in figure for the global invariant predicate and malloc for the datastructure invariant of our malloc library universal quantification over w captures the abstract global state at the point where yield is called while in the postcondition existential quantification over w introduces the new possibly world that characterizes state when the yielding thread is finally note that this specification an important complexity yield does not behave as a normal function but rather the function return pointer and stores it in a heap data structure nonetheless the specification looks like one for a normal function and we successfully the details of manipulation within the correctness proof for verification of methods like yield depends on giving a proper definition of tq on the recursive definition approach from section first we define what is a valid of a thread in figure via a predicate q p s over world at time of w thread queue pointer q saved program counter p and saved stack pointer s the definition starts by using section s trick to obtain in local predicate variable p a reference to tq next we quantify existentially and q p s m p p i im sp s w w w i p w q q malloc p q t q s q q s q q p s figure the thread queue predicate and an auxiliary definition over another predicate variable i capturing the suspended threads local memory invariant we assert that this invariant does indeed describe m the partial memory that is the implicit parameter to a predicate like the final part of the definition is a semantic hoare double a precondition to the saved program counter where is the il state at the point where the thread is we require first that the stack pointer of has been to the saved value s next we require that the world w has to some w a assertion applied to breaks memory into four pieces satisfying the local invariant i the thread queue invariant tq referenced via its local name p the global invariant in the new world and the malloc library invariant figure also gives the final definition of the tq predicate for parameters current world w and queue pointer q we quantify over a bag or multiset t of suspended threads represented as pairs of saved program counters and stack pointers as well as over two values q and s that q points to the pointer q is to a more primitive queue structure while s points to the stack used while the current thread in exit multisets form the interface with queues via the queue predicate the most interesting part of the specification is its last conjunct which uses as a notation for iterated separating conjunction over some index bag here we generate one conjunct per suspended thread in t all the quantifiers appearing directly in definition are firstorder since their domains do not involve specifications as a result this definition within the fragment of xcap assertions that support simple proof automation using connectives that have both introduction and elimination rules in contrast uses secondorder quantification so less clean proofs are required to reason about indirect jumps to suspended threads fortunately only four such jumps appear in the implementation and we are able to apply proof automation for the other some lines of executable code past work on verifying a similar library with xcap used a new µ recursive predicate connective that also lacks an elimination rule and perhaps as a result their proofs were highly manual using about times more lines of proof to establish a weaker interface for a library with fewer features more instances of the same pattern not only does the specification style facilitate flexible use of shared state in applications it also in layers within a thread library to demonstrate we discuss verifying two further components on top of which multiple queues corresponding to multiple possible io events and scheduler which standard blocking io operations on tcp to our knowledge ours is the first work to consider a certified implementation of blocking io in a modular verification framework first consider which abstracts over a dynamically growing set of thread queues it provides our first to take advantage of the generality of handling of global invariants specifically the programmer to choose w and like before though now is a predicate over w and of queues where the latter component was just a single queue for for any such choices by the programmer for the parameters of we must come up with appropriate parameters to use internally for concretely both of these modules are functors and the functor with derived parameters based on its own parameters the main idea is to define a world to contain not just a world but also the set of all queues that have been allocated so far to formalize this notion for given w and here is how we derive the parameters where pq stands for the set of sets of queue pointers w q s q s q s q pq × w q q s s s s q q qq we focus on the definition which formalizes what a particular thread queue expects to see in the remainder of memory the definition above says a thread queue the global invariant plus all of the other thread queues the other part is encoded via the operator in the index bag of this sort of explicit capture of all library state may seem compared to approaches like rules and dynamic locks with invariants for separation logic an advantage of our approach here is that it may be developed as a specification design pattern on top of simple hoare logic with no requirement to build supporting features into the trusted base while approaches seem to require such support for the application programmer these details are inside the correctness proof in the end we export method specifications that refer to an abstract predicate whose arguments are a world value and a set of available queues here is the revised specification for yield at the level for a thread into while a thread to resume from w w q pq q q q q malloc w w q pq w w q q q q malloc we come finally to scheduler which along with other state to provide both thread management and blocking tcp io scheduler is parameterized over a choice of a simple global invariant whose only argument is f a set of available file record pointers we thus instantiate with w as the set of sets of file pointers as the subset relation and as the invariant that we sketch later in figure our choice of this particular interface prevents the final clients of scheduler from choosing global invariants that depend on custom world concepts the proof architecture would support a stronger interface preserving such freedom but we decided to flexibility in of more straightforward proof automation now we arrive at a specification for the final of yield where f is the set of file record pointers f pf malloc yield f pf f f malloc the final interface all details of manipulation using just an abstract predicate to capture the state of the scheduler library the four layers scheduler and application are modular where proofs in each layer treat only the next lower layer only through hoare triples for methods specified with abstract predicates we may each layer without to proofs for others so long as we maintain its formal interface for instance the specifications of the components are general enough to allow us to the data structures of the scheduler without modifying any other module or its proofs the reader may have an apparent in our approach to specifying global invariants when multiple applications are sharing a scheduler instance they must coordinate to choose a mutually satisfactory global invariant however it is fairly straightforward to build a little that still allows each application to be proved when global state of each application can be kept in a distinct region that other applications may not touch each application with proof is implemented as a functor over the part of the global invariant by other applications and the overall global invariant is denoted as the conjunction of the part known locally and the part passed as functor parameter a single global invariant may be seen through a different lens of this kind for each application variants of this approach may also support different modes of between applications the point is that the scheduler specification allows these modularity disciplines to be constructed on top with implementation and proof remaining a black box one last note may be about the malloc predicate used throughout our example specifications why does this predicate not take some kind of argument too which we are forced to propagate through the spec of scheduler for instance one might expect to see malloc parameterized over a description of which memory blocks have been allocated so far so that we can require that any block being really did come from a past allocation our malloc library this by allowing any block of memory disjoint from the current malloc state to be via deallocation even if it previously had nothing to do with malloc patterns for implementation many verification tasks are practical to carry out over code in lowlevel languages like c but in scaling to larger systems we may realize large improvements by coding in and reasoning about higherlevel languages we raise the abstraction level while keeping our final theorems at the level of assembly code the relevant question is what is the right way to incorporate a verified implementation within a modular proof in particular we focus on how the implementation and proof may themselves be into modules we developed our the web services language at the level of language constructs supports the mostly orthogonal features of relational database access and xml processing each of these factors is further decomposed into constructs like database vs modification and xml patternmatching vs generation each construct is implemented with a separately proof we hope these building blocks are suitable to in different ways to build different but we also found that modularity off even just for the construction of this one the structured programming system already provides a notion of certified lowlevel macro where we package a code generator with a proof rule and a proof that the two are compatible thus it was natural for us to implement our building blocks as macros se offset sec s offset output if pos offset len offset c offset else output figure definition of a code generator for string equality the module formalism does not currently support statically allocated data such as for string literals extracted from source code no a more practical evolution of the framework would add such a feature but we can take advantage of the to an example macro for checking whether a byte array matches a string literal in other words we effectively represent static character arrays by inlining appropriate loops into assembly code includes basic combinators for eg sequencing conditionals and loops merely composing these combinators and their proof rules leads to a derived proof rule that may expose too much code detail we often want to wrap a macro applying an equivalent of the rule of consequence to assign a more abstract proof rule the design includes a basic combinator which a view of programs at the level of il controlflow graphs with no concept of local variables we found that interface to be too for the more abstract macros that interest us in this project so we built a higherlevel combinator that allows the preconditions and postconditions of chunks to mention the set v of declared local variables to illustrate consider our example of a macro to check whether some substring of a string equals a constant let us fix four program variable names str for a pointer to the string we should check len a variable holding its length pos indicating the first index of the substring to check and output a variable where we write either or to indicate the boolean result of the test in figure a simple recursive definition of a function se suffices to generate the code on top of more primitive macros we implement definitions like this one in functional programming language the syntax indicates some computed code pieces within syntax we define the overall macro via automatically builds a sound proof rule for any concrete application of however the rule reveals the exact lowlevel code structure when we would prefer a more abstract presentation details like checking array bounds here is the rule we derive with our expanded combinator we will step through it in stages we make the four variable names eg str into explicit parameters of the macro eg str so that client code may choose appropriate concrete names for its context i p p str i len pos len str len pos output v len pos output s output pos len pos output s p str i len pos len most of the precondition and postcondition are facts combined with the only parts of the predicates are p some frame predicate and str indicating that the variable str points to a byte array whose contents are i these parts repeat before and after indicating that the macro may only produce code that has no heap effects or fails to terminate most of the parts of the precondition are side conditions of the sort familiar to users of separation logic we require that the variable parameters are all members of the set v of declared local variables and we also require that no variable name is duplicated as the value of multiple parameters the last precondition conjunct imposes a condition on the free variables of the frame predicate p which is inspired by conditions in the classic frame rule that rule assumes p cq and concludes p f cq f for an arbitrary f that does not mention variables that command c could modify the classic rule is able to c syntactically to determine which variables it may write but in the macro setting we want to hide code details through encapsulation thus we expose a formal interface for that in effect not to change any variable outside the set output pos by only allowing useful postconditions with p that does not depend on those variables this technique generalizes to macros that take blocks of code as arguments for instance consider some macro len k implementing a foreach loop over all cells of a buffer indicated by variable buf and length variable len running some body code k for each where v is some set of program variables that the macro needs to use in generated code we might assign this proof rule i p buf i len k p buf i len i p buf i len buf len v v v len k p buf let us read the conclusion first we assert a particular hoare triple for the macro for arbitrary choices of buffer contents i which should remain unchanged by execution as before two pieces of state appear in precondition and postcondition a frame predicate p and the buffer itself via the array predicate we require that variable len hold an accurate array length that all variables we need are included in the available variables v and that the frame predicate p does not depend on any of the variables v that may be modified the premise formalizes for the body code block k we require that a hoare triple is valid for k again for any buffer contents i specifically k must preserve a statement about p buf and len technically k might change the values of these variables but at least the new versions must still satisfy the invariant that buf points to an array whose length is len note that p may be chosen to include any state known only to k and not to the iterate macro we want to emphasize one key element of rules like this one the body k may be instantiated with arbitrary assembly code that can be proved semantically to satisfy the hoare triple that is in coding and verifying our building blocks we need not commit to the design in advance subsets of our building blocks to be usable to construct different verified implementations though so far we have only them into the of section a component stack this section our concrete architecture for a verified thread library that a rich interface to client code sections and presented the two key novel design patterns that enabled this architecture and we show the details in figure malloc head free list local state of current thread global invariant scheduler file record free list ready free wait file records fd io queues queue pc sp queue stack front back pc sp stack figure architecture we follow conventions introduced in figure mixed dotted and dashed group elements of state within a single encapsulation boundary to aid understanding arrows indicate pointers which terminate at precise memory elements when they do not span encapsulation boundaries or terminate at the edges of dashed boxes when pointing to abstract objects provided by other modules basically this picture shows how to take a of memory in a running system and divide it into pieces within separately verified modules the of the diagram state of the scheduler which provides functions for thread creation and destruction tcp connection management and blocking io these functions are built on top of the nonblocking io system calls from figure the scheduler is implemented via a number of data structures including three more components sketched in section but an abstract interface is exported for use by client code the scheduler both threads and open files a scheduler instance is rooted in a struct containing ready a pointer to a queue of suspended threads ready to be free a pointer to a pool of available to use in representing open files wait a pointer to a table to be in interpreting the results of via the wait system call and the length of the wait array the scheduler maintains a pool of file records which are after previous open files are closed each file record includes an underlying file descriptor and pointers to two queues of suspended threads one for threads waiting to read from the file and the other for threads waiting to write in any blocking io call associated with one of these file records a pointer to the appropriate one of the two queues is saved in the wait array at an offset equal to the assigned to this request by the declare system call thus when a wait system call returns its return value may be treated as an index into wait determining which thread is up to handle the new io event since the trusted of declare and wait are simple and nondeterministic we do dynamic checking of returned by wait to make sure they are for the wait array we also check that the accepted n sn handlers call fs r r fs fs buf call fs r r r r v fs fs accepted call fs r r fs v buf v buf v buf v fs fs n call buf fs v accepted fs v buf v buf v buf v fs fs sn n call fs v buf v buf v buf v fs fs v sn v n call fs v buf v buf v buf fs v sn v n call fs fs v sn v n call fs fs v sn v n exit end t try solve unfold post evaluate try theorem ok m proof abstract t qed figure an example client program of the thread library corresponding array cell has been initialized with a nonnull queue pointer failure of either check signals a toplevel runtime program error the concept of threads in scheduler is than in most thread libraries there is no persistent data structure in the library for a thread instead we think of each queue as storing continuations allocated as threads decide to block the notations in our specification style so far have been hiding details of representation effectively we require each thread to have a valid stack at the point where it calls any library function but it is legal for thread code to grow and its stack through manual between blocking operations when such an operation is the associated stack is into the idea of local state for the continuation that we save figure shows an example of a client program verified against the thread library we refer the reader to the paper for more detail on the programming language used here at a high level the code between executable statements and invariants in square brackets the former are mostly assignments and function calls we prove that every invariant holds every time it is reached this program accepts a tcp connection on a port reads some bytes from that connection and then in a local variable a value one greater than the number of bytes read after a few more calls into the thread library that saved value is invariants ensure that the proper value is in the end modulo the non conventional library code generator notations http base notations notations figure architecture of verified implementation determinism of our for the underlying io operations for instance the later invariants include clauses v sn v n that the value of local variable sn equals the value of variable n plus one in the domain of bit machine words other interesting conjuncts appearing throughout the function include fs representing the state of the scheduler with set fs and v accepted fs indicating that local variable accepted holds a file pointer belonging to that set figure shows an from a real coq source file ending in the full code to prove that invariants are never violated the proof is almost entirely automated to the proof procedures that provides this level of automation in of more client code and it represents a improvement to the ease of building on verified systems libraries compared to past work a library of verified compiler features we summarize our architecture for modular verification of a implementation for database access and xml processing section introduced the basic design patterns we use for splitting a language implementation into a set of certified macros whose definitions and proofs are independent of the full language that they will be used to implement recall that we decided to verify our thread library at the level of functional correctness and verify client applications mostly at the level of datastructure shape invariants figure shows how we decomposed the verification effort at that level for the implementation of our the web service language arrows indicate dependencies between modules the two core sets of features are relational database access and xml processing we decompose the former into macros for adding and removing database rows and the latter into macros for xml patternmatching and generation all of the above are combined into a macro whose parameter is a syntactic program in an ast type we are able to write the equivalent of a typechecker as a functional program over these the final theorem for our main macro establishes that any program is compiled to assembly code that maintains the invariants of the database and does not interfere with the state of other components figure shows an example function definition from our server any such function is over http following the protocol this particular function a pair in the configuration store that the maintains one is that nodes are allowed to to updates on particular keys and we must further string key any value do delete where key key insert key value from where key key do callback command string key value response success message parameter set body ignore end end theorem wf wf ts pr proof wf qed figure example function with proof http callbacks to all interested in order the body commands of this function delete any old mapping for the key insert the new mapping loop over callbacks to all nodes to updates and return a response document to the calling node the code here uses special coq notations to hide the details of xml parsing and generation but we use macros for those functions under the we show the complete correctness proof at the end of the figure this proof actually applies to the full set of methods in the it works by calling a library tactic wf for program wellformedness obligations automatically we only need that sort of shallow fact to instantiate the generic correctness proof of the implementation yielding an result that can be composed with the main theorem about our thread library the generated main function a set of threads http requests empirical results the premise of this paper is that some about modular verification can only be learned by building and systems at realistic our server application has both an coq proof and real users without in this section we summarize the human cost of carrying out our case study the runtime performance of our application and its developing the proofs overall we spent about implementing and verifying the thread library and then another doing the same for the implementation the server itself is trivial to code and verify with that infrastructure in place the thread library includes about lines of implementation code and about additional lines to state and prove theorems making for a ratio of verification code to implementation of about the implementation includes about lines for actual executable code generation plus about lines for verification for a ratio of about we the higher overhead in the latter case to the greater of a compiler where the code has a higher density of interesting operations these in general compare reasonably to related projects like with a ratio of in a project over with proofs and past work in modular verification of thread libraries achieving on the order of number of concurrent requests threads thread figure of our web server static content ing just on developing libraries without them formally with realistic verified applications our general workflow is to verify each component fully before testing it we have been that not a single bug has been found in the systems components through testing verification every we have found so far testing has about bugs in the components for which we prove only the sorts of invariant annotations from figure in each case we the implementation and found that our automation the proofs without any need to edit proof code manually the current practical to our verification methodology is the performance of the proof automation taking several to check our whole stack which we hope to in the future by running proof search in parallel on compute clusters running the code we have not to build a web server but we to make sure that we had not simplified our program code too much during verification in a way that led to performance too to support any real use therefore we ran a basic load test experiment between two servers in the same data center our benchmark input is the full set of static files from a recent of a conference web site there are about different files with one at size about mb and the rest each smaller than mb with several html files of only a few kb each our experiment compares our verified server against the server from with default configuration we each server by on one of the two machines a set of concurrent processes to send repeated requests to a server running on the other machine figure shows the results of our experiment comparing the of and our verified server running either thread or as expected the singlethreaded server fails to scale well with increased request concurrency in contrast our thread verified server keeps up with here the network link and the underlying linux implementation are the real limiting factors our experimental results show just that we and sufficient performance to that if anything the results are in of which runs multiple hardware threads while the model is inherently we can serve real web sites at that will not users where to our knowledge previous mechanized of applications had not any such practical results the real test of our program is the of its real users the who us with our test pay little attention to verification details and are much more interested in how our server performs in practice in the nodes split across the two computers robot and control terminal include those associated with a and including and where the traditional python server leads to a second process for the robot to enable it with the our server requires seconds which our users in a context programs should have an inherent performance advantage over interpreted python thanks to specialized generation of assembly code doing manual memory management however our very elementary database implementation which does not use any kind of index structures should bring an asymptotic performance compared to the standard dictionaries used to store corresponding data in the python server we also to make proofs more straightforward simplified some aspects of our code in ways that performance like always allocating certain buffers at a fixed size and them out in full per request even when network inputs do not take up the full space and making copies of buffers before sending them to deal with a library specification that we explain in the next we believe that the performance differential from these coding patterns in the process of building and the application we a few in the formal interface for instance the blocking write function is assigned a specification like buf buf len we realized late that this specification sending from string buffers that logically belong within the global invariant such as strings for column values within the database to we copy column values into temporary buffers before sending them additional overhead our server does successfully against a security attack that works on the python server a carefully xml input leads the python server to loop allocating an effectively unbounded amount of memory in contrast our final theorem establishes a static bound on how much memory our server can allocate by defining the set demonstrated in figure to be small enough related work several recent projects have verified systems infrastructure mechanically is the project in this space based on an proof that a refines a specification of system calls and so given by a functional program there has been preliminary work on using the proof to establish theorems about applications running on the kernel but we are not aware of results with applications on the scale of those reported here with our web service the project establishes type safety but not functional correctness of net programs running on a platform that includes a verified garbage collector the project has also produced kernel correctness proofs using a decomposition of the proof effort via several abstract machines from hardware to theorems have been proved for kernel composed with embedded applications following a simple communication model without dynamic thread creation or calls to io operations past work has designed verification frameworks to support modular reasoning for instance the cap project has demonstrated several verification frameworks for programs including the xcap logic that we use here one project used xcap to verify a thread library that inspired our new work our library follows roughly to the level of where their work ends they also assign their version of this module a weaker specification that does not support sharing of memory across threads in ways and they did not report on experience verifying applications against the library a project applied a compositional program logic for hardware interrupts to code for process scheduling without dynamic process creation plus code imple synchronization primitives here the focus was on a convenient interface for systems library work rather than for applications of interest to end users and no such applications were verified even in the proofs of code that rely on abstract interfaces exported by modules the verification overhead is about times greater than in our new work though it is hard to make a direct comparison since our library is based on scheduling rather than and yang presented a framework for modular correctness proofs of process they designed a domainspecific separation logic to enable proofs of this kind for a variety of that are more realistic than those in other verification work including ours no proof approach is suggested for linking of theorems and none of their proofs are mechanized so far so it is hard to predict what human cost they would impose on authors of or applications ours is not the first project to implement a verified compiler for a higherlevel language on top of the project has verified semantics preservation for a language with builtin support for data abstraction that compiler theorem is stronger than ours for which only establishes preservation of datastructure shape invariants but it also applies to a programming language at a lower abstraction level requiring more proof work by programmers to establish basic properties of source code the project has verified an implementation of a domainspecific language for they compile to the language rather than generalpurpose assembly establishing in coq rich semantic correctness properties of network without the sort of decomposition we introduce in this paper other projects have verified elements of web applications the project produced proofs for a application and a relational database engine that work established more semantic properties than in this paper for a more realistic database system but in the setting of interpretation in a highlevel functional language rather than compilation to optimized assembly and they require new manual proof about each program using the database library several programming languages have been developed to help programmers reason about xml manipulation including and these languages use features like regular expression types to bring static typing features like checking from the world of ml and haskell to xml processing this sort of static type system would be a complementary addition to conclusion we have described the first modular mechanized verification of a software system combining proofs about systems infrastructure primarily a thread library and an application an web service by a relational database our summary of the project focuses on that are difficult to learn when not applying modular verification at scale where formal interfaces must be flexible at the same time as proofs are kept automated short and we sketch one decomposition that we found effective into about separately pieces which we hope can provide a model for future in this style acknowledgments we thank our at and for their help getting our verified server running on real and the reviewers for their helpful comments on an earlier version of this paper this work has been supported in part by nsf grant and by under agreement number fa the us is to and for purposes any copyright notation the views and conclusions contained are those of the authors and should not be interpreted as necessarily representing the policies or either expressed or implied of or the us references e w j paul a and a verification of an os inline assembly memory consumption concurrent devices in proc pages ­ springerverlag a w appel and d an indexed model of recursive types for foundational proofcarrying code toplas ­ sept h z shao and a certified code in proc pldi pages ­ acm a verification of lowlevel programs in computational separation logic in proc pldi pages ­ acm a the structured programming system combining generative and hoare logic in an extensible program verifier in proc icfp pages ­ acm a g g morrisett a and r effective interactive proofs for higherorder imperative programs in proc icfp pages ­ acm e m m d m t w and s a practical system for verifying concurrent c in proc pages ­ springerverlag m n w and m from correctness to verified applications in proc pages ­ springerverlag x and z shao modular verification of concurrent assembly code with dynamic thread creation and termination in proc icfp pages ­ acm x z shao y and y lowlevel programs with hardware interrupts and threads in proc pldi pages ­ acm x z shao y and y combining domainspecific and foundational logics to verify complete software systems in proc pages ­ springerverlag x z shao a s and z ni modular verification of assembly code with control abstractions in proc pldi pages ­ acm v m y b c pierce and a the experience in proc university of pennsylvania technical report oct c s gordon m d and d relyguarantee references for refinement types over aliased mutable data in proc pldi acm a j berdine b cook n and m sagiv local reasoning for locks and threads in proc pages ­ springerverlag a and h yang modular verification of os kernels in proc icfp pages ­ acm a m and n foster network in proc pldi pages ­ acm h and b c pierce a statically typed xml processing language acm transactions on technology ­ may ck and d dreyer a kripke logical relation between ml and assembly in proc popl pages ­ acm c b jones steps toward a development method for programs acm trans program lang syst ­ oct g from a verified kernel towards verified systems in proc pages ­ springerverlag g k g j d p d k r m t sewell h and s sel formal verification of an os kernel in proc pages ­ acm x leroy formal certification of a compiler or programming a compiler with a proof assistant in proc popl pages ­ acm d macqueen modules for standard ml in proc lfp pages ­ acm g a and t compositional computational reflection in proc pages ­ springerverlag g g morrisett a and r toward a verified relational database management system in proc popl pages ­ acm g g morrisett and r verification of imperative programs with io j comput ­ a z shao c lin and l li a general framework for garbage collectors and their mutators in proc pldi pages ­ acm z ni and z shao certified assembly programming with embedded code pointers in proc popl pages ­ acm z ni d and z shao using xcap to realistic systems code machine context management in proc pages ­ springerverlag f pottier hiding local state in direct style a higherorder rule in proc lics pages ­ ieee computer society m b k j t j e r and a ng an robot operating system workshop on open source software j c reynolds separation logic a logic for shared mutable data structures in proc lics pages ­ ieee computer society t into intensional type theory thesis k and l birkedal impredicative concurrent abstract predicates in proc esop pages ­ springerverlag p wang s and a compiler verification meets linking via data abstraction in proc oopsla pages ­ acm j yang and c safe to the last instruction automated verification of a typesafe operating system in proc pldi pages ­ acm 