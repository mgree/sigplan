fair reactive programming andrew francisco school of computer science university abstract functional reactive programming models reactive systems with events and signals which have previously been observed to correspond to the eventually and always modalities of linear temporal logic ltl in this paper we define a constructive variant of ltl with least fixed point and greatest fixed point operators in the spirit of the modal and give it a interpretation as a foundational calculus for reactive programs previous work the part of the correspondence between ltl and here we emphasize the part by structural proof theory we show that the type system is expressive enough to enforce liveness properties such as the fairness of and the eventual of results we illustrate programming in this calculus using operators we prove type preservation of our operational semantics which guarantees that our programs are we give also a proof of strong normalization which provides justification that our programs are and that they satisfy liveness properties derived from their types categories and subject descriptors d programming techniques applicative functional programming keywords temporal logic functional reactive programming liveness introduction reactive programming to model systems which and to input such as games print and web servers or user interfaces functional reactive programming was introduced by and hudak to raise the level of abstraction for writing reactive programs particularly higherorder functions has several implementations ­ many allow one to write functions where the present output depends on future input and space leaks are all too common recently there has been a lot of interest in typetheoretic foundations for functional reactive programming ­ with the intention of these in particular permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ san diego ca usa copyright is held by the publication to acm acm and have recently observed that linear temporal logic ltl can act as a type system for in this paper we present a novel logical foundation for discrete time with operators which exploits the expressiveness by the proof theory ie the universal properties for least and greatest fixed points in the spirit of the modal µcalculus the always eventually and until modalities of ltl arise simply as special cases we do this while still remaining relatively conservative over ltl moreover we demonstrate that distinguishing between and interleaving of least and greatest fixed points is key to statically guarantee liveness properties ie something will eventually happen by type checking to illustrate the power and of this idea we describe the type of a fair scheduler ­ any program of this type is guaranteed to be fair in the sense that each participant is guaranteed that his requests will eventually be notably this example requires the expressive power of interleaving least fixed points and greatest fixed points a construction due to park which is unique to our system our approach of distinguishing between least and greatest fixed points and allowing for iteration and is in contrast to prior work in this area work for example only supports less expressive combinators instead of the primitive our system and only particular instances of our recursive types et al employ a more expressive notion of recursion which entails unique guarded fixed points ­ this implies that their type systems are of expressing liveness properties in to our work describes denotational settings for some of which are capable of expressing liveness guarantees however the theory of fixed points is largely in his setting our technical contributions are as follows · a type system which in addition to enforcing causality as in previous systems also enables one to enforce liveness properties fairness being a particularly example moreover our type system acts as a sound proof system for ltl while previous work the component of the correspondence between ltl and the present work additionally the part of the correspondence through the lens of structural proof theory · a novel operational semantics which provides a reactive of our programs one can evaluate the result of a program for the first n time steps and in the next time step resume evaluation for the n st result it allows one to evaluate programs one time step at a time moreover we prove type preservation of our operational semantics as a consequence our foundation is future inputs do not affect present results · a strong normalization proof using method of saturated sets which that our programs are total functions it also demonstrates that our programs satisfy liveness properties derived from their types notably our proof the generality of interleaving fixed points and offers a novel treatment of the paper is organized as follows to illustrate the main idea limitations and power of our foundation we give several examples in sec in particular we elaborate the implementation of two fair where our foundation statically guarantees that each request will eventually be we then introduce the syntax sec of our calculus which features operators and explicit delay operators together with typing rules sec in sec we describe the operational semantics and prove type preservation in sec we outline the proof of strong normalization in sec we discuss consequences of strong normalization and type preservation namely causality liveness and we conclude with related work examples to illustrate the expressive power of our calculus we first present several motivating examples using an informal ml or syntax for better readability we use general recursion in our examples although our foundation only provides operators however all the examples can be translated into our foundation straightforwardly and we subsequently illustrate the elaboration in sec on the type level we employ a type constructor corresponding to the next modality of ltl to describe data available in the next time step on the term level we use the corresponding introduction form · and elimination form let · x e in e where x is bound to the value of the expression e in the next time step the always modality our first example app produces a stream of elements of type b given a stream fs of functions of type a b and a stream xs of elements of type a by applying the nth function in fs to the nth value in xs such streams are thought of as values which vary in time here we use the type of ltl to describe temporal streams where the nth value is available at the nth time step a can be defined in terms of the modality as follows using a standard definition as a greatest fixed point a coinductive datatype a of a × a a has one constructor which is declared as an infix operator and takes an a now and recursively a a in the next time step the functions hd and tl can then be defined the only being that the type of tl expresses that the result is only available in the next time step hd a a tl a a finally we can implement the app function as follows app a b a b app fs xs let · fs tl fs · xs tl xs in hd fs hd xs · app fs xs we use the elimination form let · to bind the variables fs and xs to values of the remaining streams in the next time step our typing rules will guarantee that fs and xs are only usable a · which we will explain further in the following examples such a program is interpreted as a process which at each time step receives a function a b and a value a and produces a value b more generally given n functions a b and n values a it can compute n values b the eventually modality a key feature of our calculus is the distinction between least fixed points and greatest fixed points in other words the distinction between data and this allows us to make a distinction between events that may eventually occur and events that must eventually occur this is a feature not present in the line of work by and his benton and ­ ­ they have unique guarded fixed points which intuitively correspond to our greatest fixed points to illustrate the benefits of having both least and greatest fixed points we present here the definition of operator read eventually as a data type corresponding to a type of events in reactive programming data a now of a later of a the function below receives an event of type a and a stream of functions a b it produces an event of type b operationally for the a to arrive applies the function available at that time and the resulting b event immediately a a b b ea fs case ea of now x now hd fs x later ea let · ea ea · fs tl fs in later · ea fs this is not the only choice of implementation for this type such functions could opt to produce a b event before the a or even long after if b is something concrete such as bool however all functions with this type in our system have the property that given that an a is eventually provided it must eventually produce a b although perhaps not at the same time this is our first example of a liveness property guaranteed by a type this is in contrast to the weak eventually modality present in other work which does not guarantee the production of an event it is interesting to note that this program and all the other programs we write can be considered proofs of their corresponding statements in ltl abstract server here we illustrate an abstract example of a server whose type guarantees responses to requests this example is inspired by a corresponding example in recent work we wish to write a server which to two kinds of requests get and put with possible responses ok and error we represent these data req get put data resp ok error at each time step a server specifies how to behave in the future if it did not receive a request and furthermore if it receives a request it specifies how to and also how to behave in the future this is the informal explanation for the following server type expressed as here we use coinductive record syntax server server some req resp × server now we can write the server program which to get with ok and put with error server server server · server some r if r then ok · server else error · server above we say that if no request is made we behave the same in the next time step if some request is made we check if it is a get request and appropriately in either case in the next time step we continue to behave the same way more generally we could opt to behave differently in the next time step by eg passing along a counter or some memory of previous requests it is clear that this type guarantees that every request must immediately result in a response which jeffrey calls a liveness guarantee in our setting we the term liveness guarantee for something which has the traditional of eventually something good happens that is they are properties which cannot be after any finite amount of time because the event may still happen the present property of immediately providing a response does not have this it can be by a single request which does not immediately receive a response in our setting liveness properties arise strictly from uses of inductive types ie data or µ types combined with the temporal modality which requires something to happen arbitrarily but finitely far into the future and other bad programs we wish to programs such as the following which has the effect of data from the future into the present it violates a interpretation of such programs moreover its type is certainly not a theorem of ltl for arbitrary a a a x let · x x in x does not typecheck our typing rules this program roughly by restricting variables bound under a · to only be usable under a · in much the same way as similarly the type a b expresses that either an a or a b is available in the next time step but it is not known yet which one it will be hence we programs such as the following by case analysis on something only available in the future a b a b x let · x x in case x of does not typecheck inl a inl · a inr a inr · b such a program would tell us now whether we will receive an a or a b in the future again this violates causality due to this interpretation there is no uniform of this type despite being a theorem of classical ltl similarly is in our system one cannot get out of doing work by the end of the world although it would be from the perspective of causality we also the following import a a import x · x does not typecheck this is on the that it is not uniformly a theorem of ltl and benton allow it in but it later in to space usage syntactically this is accomplished by removing from scope all variables not bound under a · when moving under a · however some concrete instances of this type are for example the following program which natural numbers into the future import nat nat import zero · zero import succ n let · n import n in n our calculus does not have guarded recursion fix a a a because it creates for us of certain inductive types such inductive types into coinductive types for example the following would be an of a in which the a is never never a never fix x later x finally the following program which attempts to build a constant stream cannot be into the foundational calculus while it is guarded we must remove all local variables from scope in the bodies of recursive definitions so the occurrence of x is out of scope repeat a a repeat x xs where xs x x out of scope this is ­ the above type is not uniformly a theorem of ltl so one should not expect it to be as et al illustrate this is precisely the kind of program which leads to space leaks fair scheduling here we define a type expressing the fair interleavings of two streams and provide examples of fair this type ­ this is the central example the unique power of the presented system this is enabled by our systems ability to properly distinguish between and least and greatest fixed points ie data and other systems in the same typically least fixed points into greatest fixed points or simply lack the expressiveness of recursive types first we require the standard until modality of ltl written a u b this is a sequence of as terminated with a b in the setting of reactive programming calls programs of this type processes ­ they behave as signals which eventually terminate with a value data a u b same of a × a u b switch of b notably since this is an inductive type the b must eventually occur the coinductive variant is weak until the b might never happen in which case the as continue forever we remark that without temporal modalities a u b is isomorphic to list a × b but because of the it when the b happens we define also a slightly stronger version of until which requires at least one a which we write a u b type a u b a × a u b we characterize the type of fair interleavings of a stream of a s and bs as some number of as until some number of bs at least one until an a and the process this is fair in the sense that it guarantees infinitely many as and infinitely many bs as a coinductive type fair a b in of a u b u a × fair a b qa qb start q a figure scheduler automaton the reader may find it helpful to compare this type to the corresponding bu¨chi automaton in figure briefly discusses essentially the same type here we have the tools necessary to write programs with this type that is to say we can write examples of fair which take a stream of as and a stream of bs and select from them fairly here is the simplest fair scheduler which simply selecting an a and b a b fair a b as bs let · as tl as · bs tl bs in in switch hd bs · switch hd as let · as tl as · bs tl bs in · as bs the reader may notice that this scheduler the as at odd position and the bs at even position this could be overcome if one has import for the corresponding stream types but at the cost of a space leak as a a a a a a a a a a a a a a bs b b b b b b b b b b b b b b however this behaviour could be viewed in a reactive setting the source of the a requests could have the option to the same request or even modify the previous request after observing that the scheduler decided to serve a b request instead next we illustrate a more elaborate implementation of a fair scheduler which serves more as each time before a b again the type requires us to eventually serve a b as a a a a a a a a a a a a a a bs b b b b b b b b b b b b b b we will need a special notion of natural numbers to implement the in the succ case the predecessor is only available in the next time step data zero succ we can write a function which import the scheduler is implemented in figure it involves two mutually recursive functions cnt is structurally decreasing on a counting down how many as to produce while the recursive call to is guarded by the necessary switches to guarantee and increments the number of as the next time off the process starting with zero as mutual cnt a b a u b u a × fair a b cnt n m as bs let · m import m · as tl as · bs tl bs in case n of zero switch hd bs · switch hd as let · m import m · as tl as · bs tl bs in · succ import m as bs succ p let · n p in same hd as · cnt n m as bs and a b fair a b n as bs in cnt n n as bs main function a b fair a b as bs zero as bs figure fair scheduler to understand why type is necessary we note cnt is structurally decreasing on its first argument this requires the immediate subterm n to be available in the next step not the current the important remark here is that these can be seen to be fair simply by of typechecking and checking more precisely this is seen by the program to use the operators available in the formal language which we illustrate in the next section syntax the formal syntax for our calculus figure includes conventional types such as product types sum types and function types additionally the system has the a modality for values which will have the type a in the next step and least and greatest fixed points µ and types our convention is to write the letters a b c for closed types and f g for types which may contain free type variables types a b f g f × g f g a f f xf x terms m n x m n fst m snd m inl m inr m case m of inl x n inr y n xm m n let · x m in n inj m xm n out m xm n map f m contexts · x a kind contexts · x type substitutions · fx morphisms · xm x figure ltl syntax our term language is mostly standard and we only discuss the terms related to modality and the fixed points µ and describes a term m which is available in the next time step let · x m in n allows us to use the value of m which is available in the next time step in the body n our typing rules will guarantee that the variable only occurs under a · our calculus also includes iteration operator xm n and operator xm n intuitively the first argument xm corresponds to the inductive invariant while n specifies how many times to the fixed point the introduction form for µ types is inj m up a term m the elimination form for types is out m unrolling m we note that the xf annotations on iter and play a key role during runtime since the operational semantics of map are defined using the structure of f see sec we do not annotate abstractions with their type because we are primarily interested in the operational behaviour of our language and not eg unique typing the term map f n witnesses that f is a functor and is explained in more detail in the next sections our type language with least and greatest fixed points is expressive enough that we can define the always and eventual modality eg a xa × x a x the definition of a expresses that when we unfold a a we obtain a value of type a the head of the stream and another stream in the next time step the definition of a expresses that in each time step we either have a value of type a now or a for a value of type a the use of the least fixed point operator guarantees that the value is only a finite number of times using a greatest fixed point would permit always and never providing a value of type a we can also express the fact that a value of type a occurs infinitely often by using both great and least fixed points traditionally one expresses this by combining the always and eventually modalities ie a however there is another way to express this namely inf a x y in this definition at each step we have the choice of making progress by providing an a or until later the least fixed point implies that one can only a finite number of times the two definitions are logically equivalent but have different constructive content ­ they are not isomorphic as types intuitively a provides at each time step a handle on an a to be at some point in the future it can potentially several values of type a in the same time step and the order of the handles may not correspond to the order they are in on the other hand can provide at most one value of type a at each time step this demonstrates that the inclusion of general µ and operators in the language in of a of modalities offers more finegrained than it does we show here also the encoding of server a u b a u b and fair a b which we used in the examples in sec server x x × req resp × x a u b a × x a u b a × a u b fair a b xa u b u a × x finally to illustrate the relationship between our formal language which features operators and the example programs which were written using general we show here the program app in our foundation here we need to use the pair of f s and xs as the coinduction invariant wellformedness of types f f g f g f f g · a f x f x f af xf f x f x figure wellformed types typing rules for × x a m b m a b n a xm a b m n b xa x a m a n b m n a × b m a × b fst m a m a × b snd m b m a n b inl m a b inr n a b m a b x a n c y b n c case m of inl x n inr y n c rules for modality and least and greatest fixed points · m a a m a x a n c let · x m in n c m · x m c n inj m xm n c · x c m n c m xf xm n xf out m f m f map f m f typing rules for morphisms · x a m b ax xm x bx · · · figure typing rules app a b a b app f s xs x x let · f s tl fst x in let · xs tl snd x in hd fst x hd snd x s xs f s xs type system we define wellformed types in fig in particular we note that free type variables cannot occur to the left of a that is to say we employ a strict restriction in contrast to condition we give a type assignment system for our calculus in fig where we distinguish between the context which provides types for variables which will become available in the next time step ie when going under a · and the context which provides types for the variables available at the current time the main typing judgment m a asserts that m has type a given the context and in general our type system is similar to that of and while in their work the validity of assumptions at a given time step is indicated either by annotating types with a time or by using different judgments ie now later stable we separate assumptions which are valid currently from the assumptions which are valid in the next time step via two different contexts much more importantly our foundation differs in the treatment of recursive types and recursion most rules are standard when traversing xm the variable is added to the context describing the fact that x is available in the current time step similarly variables in each of the branches of the are added to the interesting rules are the ones for modality and fixed points µ and in the rule i the introduction rule for with corresponding constructor · provides a term to be evaluated in the next time step it is then permitted to use the variables in the next time step so the assumptions in move to the available position while the assumptions in are no longer available in fact the variables in remain until going under a · ­ this is how causality is enforced our motivation for about current assumptions and not allowing them to is that we wish to obtain a type system which is sound for ltl allowing to would make the unsound a a easily derivable in the work of et al about current assumptions plays a key role in space usage the corresponding elimination form let · x m in n simply adds xa the type of values by m to the context and we continue to check the body n allowing it to refer to x under a · the elimination form for µ is an iteration operator iter examining an instantiation of this rule for nat µx x may help to this rule · x c m c n µx x xm n c the term m contains the base case and the step case m will typically be a case analysis on x while n specifies how many times to iterate the step case of m starting at the base case of m for example we illustrate here the function on natural numbers written using this iteration operator we write for the term inj inl and suc m for the term inj inr m db x of inl y inr w w double x we note that and in the first premise is essential intuitively the bodies of recursive definitions need to be used at arbitrary times while and are only available for the current and next time steps respectively this is to see for the rule where keeping allows a straightforward derivation of a a repeat which is unsound for ltl and easily produces space leaks similarly keeping in the iter rule allows one to derive the unsound a b a u b which says that if a holds now and b eventually holds then a in fact holds until b holds unsound a b a u b unsound a eb x y case y of inl b inj inl b inr u inj inr a u ­ a out of scope eb the typing rules for µ and come directly from the universal properties of initial algebras and terminal coalgebras the reader may find it to compare these rules to the universal properties depicted here f f µf f c c f inj µf iter f f c f out f f c f f the primitive recursion operator below can be derived from our iteration operator so we do not lose expressiveness by providing only iteration of course in practice rec is necessary to write efficient programs · x c × m c n xm n c the term map f m witnesses that f is a functor it has the effect of applying the transformations specified by at the positions in m specified by f it is a generic program defined on the structure of f while this term is definable at the metalevel using the other terms in the language we opt to include it in our syntax because doing so significantly simplifies the operational semantics and proof of normalization in this term binds the free variables of f it is to consider the case where f y list y µx y × x if y a m b and n list a then map y list y y m y n list b in this case map implements the standard notion of map on lists we will sometimes not write the when the intention is clear we define two notions of substitution substitution for a current variable written and substitution for a next variable written the key case in their definition is the case for for current substitution in terms x cannot occur in m so we define for next substitution in the body of m x becomes a current variable so we can defer to current substitution defining these definitions are motivated by the to obtain tight bounds on how substitution with the operational semantics without having to keep typing information to know that terms are these substitutions satisfy the following typing lemma lemma substitution typing if xa m b and n a then b if xa m b and · n a then b operational semantics next we define a smallstep operational semantics using evaluation contexts since we allow full reductions a redex can be under a binder and in particular may occur under a modality we define evaluation contexts in fig we index an evaluation context ek by a depth k which indicates how many modalities we traverse intuitively the depth k tells us how far we have in time or to put it differently at our current time we know that we have ek ek ek n m ek fst ek snd ek ek m m ek case ek of inl x n inr y n inl ek case m of inl x ek inr y n inr ek case m of inl x n inr y ek let · x ek in n let · x m in ek inj ek xm ek xm ek out ek map f ek e figure evaluation contexts xm n n m n n case inl m of inl x n inr y n case inr m of inl x n inr y n let · x in n xm inj n map xf y xm yx n xm out xm n map xf y xm yx figure operational semantics taken k time steps and therefore terms under k modalities are available to us now single step reduction is defined on evaluation contexts at a time ie either n or and states that we can step to where m is a redex occurring at depth k where k and m reduces to n more precisely the reduction rule takes the following form m n if k if then we are evaluating all redexes now and do not evaluate terms under a modality if we advance to we in addition can contract all redexes at depth ie terms occurring under one · and so on at we are all redexes under any number of · we have reached a normal form at time if for all k all redexes at depth k have been reduced and no further reduction is possible the contraction rules for redexes see fig are mostly straightforward the only exceptions are the iteration and rules if we make an observation about a value by out xm n then we need to compute one observation of the resulting object using m and explain how to make more observations at the recursive positions specified by f if we an iteration xm inj n we need to continue performing the iteration at the recursive positions of n the positions are specified by f and reduce the result using m performing an operation at the positions specified by f is ac with map which witnesses that f is a functor the op semantics of map are presented in fig they are driven by the type f most cases are straightforward and more or less forced by the typing rules the key cases and the reason for putting map in the syntax in the first place are those for µ and for µ we reduce n until it is of the form inj n at which point we can continue applying inside n where now at the recursive positions specified by y we need to continue recursively applying map the case for is similar except it is when we demand an ob with out we remark that we do not perform reductions inside the bodies of iter and map see fig as these are in some sense terms they will be used at multiple points in time and it is not clear how our notion of operational semantics could interact with these we the issue by reductions inside these bodies to illustrate the operational semantics and the use of map we consider an example of a simple recursive program a natural number example we here the program double which a given natural number by two given in the previous section recall the following abbreviations for natural numbers inj inl suc w inj inr w suc etc let us first compute double double db inj inl case m of inl y inr w suc suc w where m map x yx inl case inl of inl v inl inr u u case inl of inl y inr w suc suc w we now compute double double db inj inr case m of inl y inr w suc suc w where m map x yx inr case inr of inl v inl inr u u case of inl y inr w suc suc w case inr of inl y inr w suc suc w suc suc we have the following type soundness result for our operational semantics theorem type preservation for any if m n and m a then n a observe that after evaluating m n n where n is in normal form one can then resume evaluation n n n to obtain the result available at the next time step one may view this as the computation to compute the result up to n but with the results up to time n memoized in practical implementations one is typically only concerned with see sec however considering the general gives us the tools to analyze programs from a more global viewpoint which is important for liveness guarantees our definition of substitution is so that we can prove the following bounds on how substitution with which are important in our proof of strong normalization notice that these are independent of any typing assumptions proposition if n if m if n if n if m n then n xm m then n n then n then m then n n n our central result is a proof of strong normalization for our calculus which we prove in the next section map x n if x xm map n map f × g n map f fst n map g snd n map f g n case n of inl y f y inr z g z map a f n f n y map f n let · y n in · map f y map inj n inj map y f x map xy n out map yf n map y f x map yf xy out n figure operational semantics of map strong normalization in this section we give a proof of strong normalization for our calculus using the method in our setting this means we prove that for any every reduction sequence m is finite for welltyped terms m this means that one can compute the approximate value of m up to time in fact this result actually gives us more our programs are using normalization at and the type of a program gives rise to a liveness property which it satisfies using normalization at our logical relation is in fact a form of kripke logical relation as we index it by an to keep track of how many time steps we are normalizing it is in that the partial order we use on is discrete ie precisely when it is not stepindexed because our strict condition on µ and allows us to interpret them without the aid of step indexing this proof is made challenging by the presence of interleaving µ and types and operators this has been treated before by as well as and others have considered cases or with other forms of recursion such as and and to our knowledge ours is the first such proof which treats map as primitive syntax with reduction rules instead of a derivable operation which we find simplifies the proof substantially as it allows us to consider map independently of iter and in the proof we use a standard inductive characterization of strongly normalizing terms definition strongly normalizing we define sn as the inductive closure of m m m m sn m sn we say m is strongly normalizing at if m sn it is immediate from this definition that if m sn and m m then m sn since this is an inductive definition it us a corresponding induction principle to show that a property p holds of a term m sn one is allowed to assume that p holds for all m such that m m one can easily verify by induction that if m sn then there are no infinite reduction sequences rooted at m for our proof we use saturated sets instead of candidates as this allows us to perform the syntactic analysis of redexes separate from the more semantic parts of the proof this technique has been used by and in the following we will of indexed sets by which we mean a subset of terms for each ie a where we write tm for the set of all terms we the notation and to mean pointwise inclusion intersection and union that is if a and b are indexed sets we will write a b to mean a b for all definition we define the following next step operator on indexed sets a a tm am am a a the motivation for this is that it explains what happens when we go under a · ­ we are now interested in under one fewer · below we define a notion of normalizing weak head reduction we write m m for a contraction and m n for a contraction under a weak head context this is a weak head reduction where every term which may be lost along the way eg by a substitution is required to be strongly normalizing this is a characteristic of the saturated set method it is designed this way so as to backward preserve strong normalization the intuition is that weak head redexes are ­ reducing other redexes can only a weak head reduction not eliminate it we define below weak head reduction contexts and normalizing weak head reduction we show only the lambda case the full definition can be found in the long version of the paper h fst h snd h hn xm h map h out h let · x h in n case h of inl x n inr y n m m hm hm n sn xm n lemma sn is backward closed under normalizing weak head reduction if m sn and m m then m sn we note that in all of our proofs the subscript plays little to no role except of course in the cases to the next step operator for this reason we typically the cases of the proofs we define the indexed set of terms strongly normalizing neutral which are strongly normalizing but are stuck with a variable in place of a weak head redex definition we define hx sn we can now define saturated sets as subsets of strongly normalizing terms the rest of the proof proceeds by showing that our types can be interpreted as saturated sets welltyped terms saturated sets and hence are strongly normalizing definition saturated sets an indexed set a is saturated if a sn for any m m if m m and m a then m a backward closure under normalizing weak head reduction a it is immediate from lemma that sn is saturated definition for an indexed set a we define a as its closure under conditions and ie a m m m m m a m to interpret least and greatest fixed points we construct a complete lattice structure on saturated sets lemma saturated sets form a complete lattice under with greatest lower bounds and least upper bounds given by s s sn s s for we with sn so that the lower bound is sn and hence saturated for nonempty s we have s s as a consequence by an instance of the fixed point theorem we have the following corollary given f which takes predicates to predicates we define µf c saturated f c c f c saturated c f c if f is monotone and takes saturated sets to saturated sets then µf resp f is a least resp greatest fixed point of f in the lattice of saturated sets the following operator definitions are convenient as they allow us to reason at a high level of abstraction without having to introduce at several places in the proof definition we define a f m f m a a f f m m a we will often use these notations for partially applied syntactic forms eg a inj we are now in a position to define the operators on saturated sets which correspond to the operators in our type language definition we define the following operations on saturated sets a × b sn a fst b snd a b a inl b inr a b m n am n b a a · µf µx f x inj f x f x out notice that µf is defined regardless of whether f is monotone although we only know that µf is actually a least fixed point when f is monotone we remark also that our definition does not the definition one might expect that is to say we are using the discrete partial order on we do not need the monotonicity that the standard ordering would grant us since our type system does not in general allow carrying data into the future lemma the operators defined in definition take saturated sets to saturated sets we are now ready to interpret wellformed types as saturated sets the definition is given the operators defined previously definition given an environment mapping the free variables of f to saturated sets we define the interpretation f of an open type as a saturated set as follows x x f × g f × g f g f g a f a · f f f µx f x x xf x f x x observe that by lemma every f is saturated if ny and mx are simultaneous substitutions we write m to mean substituting the ni with next substitution and the mi with the current substitution we may write this explicitly as follows mx if mx and x a xm am then we write to mean mi ai for all i and similarly for definition semantic typing we write m c where the free variables of m are bound by and if for any and any substitutions and we have m c next we show that the term constructors of our language corresponding semantic typing lemmas we prove the easier cases first ie constructors other than map iter and as their results are used in the next lemma to map we state only the nonstandard cases for the full statement see the long version lemma interpretation of term constructors the following hold where we assume a b and c are saturated if · m a then a if m a and xa n b then let · x m in n b if f is a monotone function from saturated sets to saturated sets and m f µf then inj m µf if f is a monotone function from saturated sets to saturated sets and m f then out m f f proof we show only the case for · the rest are straightforward or standard we are given · m a ie for any and that · m a suppose we are given and and case then a tm so · m a case m then am am and m by our assumption taking m we have · m am case then a a and by our assumption · m a in any case we have · m a then ·· m a · hence a as required with this lemma it remains only to handle map iter and below we show the semantic typing lemma for map we write where and ax and bx and the ai and bi are saturated to mean x ai mi bi for each i notably because we define map independently of iter and we can prove this directly before iter and a simplification of known proofs for interleaving µ for readability we write f instead of f lemma semantic typing for map if x f map f x f then proof notice by unrolling the definitions this is equivalent to showing f f map f the proof proceeds by induction on f we show only the case for µ the case for is analogous the rest are straightforward using lemma and backward closure we present the proof in more detail in the long version case this proceeds primarily using the least fixed point property and closure let c µx f x inj let d c let n map f map d is saturated x d map x c by definition of d x f d map f map x f c by ih f d f c map f map by definition of f c inj inj n f c inj inj n by of c inj n by fixed point c f map by def c map inj by closure c map inj d inj by def f d inj d by f d inj d by d by lfp property y map y by definitions of d c the only term constructors remaining to consider are iter and these are the subject of the next two lemmas which are proven similarly to the µ and cases of the map lemma namely they proceed primarily by using the least greatest fixed point properties and backward closure under to the map lemma the proofs can be found in the long version of the paper lemma if x f cx m c where c is saturated we have y xm y c lemma if x c m f cx where c is saturated we have y c xm y xf by now we have shown that all of the term constructors can be interpreted and hence the fundamental theorem is simply an induction on the typing derivation to the previous lemmas theorem fundamental theorem if m a then we have m a corollary if m a then for any m is strongly normalizing at causality and liveness we discuss here some of the consequences of type soundness and strong normalization and explain how our operational semantics enables one to execute programs we call a term m a value if it cannot step further at time we may write this m we obtain as a consequence of strong normalization that there is no closed of the type which we define as since there is no closed value of this type perhaps surprisingly we can also show there is no closed of for if there was some f we could evaluate x · f at to obtain a value x · v which by inspection of the possible values cannot exist similarly we can demonstrate an interesting property of the type b µx x first there is no closed term of type b for if there was some f b we could x b · f inj b at time to obtain a value x b · v which cannot exist moreover there is no closed term of type b since there is no closed value of type b that is b is neither nor provably inside the logic to show how our operational semantics and strong normalization give rise to a reactive interpretation of programs as well as an explanation of the liveness properties guaranteed by the types we illustrate here the reactive execution of an example program x p m q such a program can be thought of as waiting for a p event from its environment and at some point a q event for simplicity we assume that p and q are pure types such as bool or n we consider sequences of interaction which begin as follows where we write now p for inj inl p and later · t for inj later · later · later · m later · m each such step of an interaction corresponds to the environment the program that it does not yet have the p event in that time step and the program saying that it has not yet produced a q event essentially at each stage we leave a hole xi for input not yet known at this stage which we will refine further in the next time step the resulting mi acts as a continuation specifying what to compute in the next time step we note that each mi q by type preservation such a sequence may not end if the environment providing a p forever however it may end one of two ways the first is if eventually the environment a closed value p of type p now v in this case now q by type preservation and strong normalization we can evaluate this completely to v q by an inspection of the closed values v must be of the form · · · now q that is a q is eventually in this case the second way such an interaction sequence may end is if the program produces a result before the environment has supplied a p later · now q we remark that type preservation of provides an explanation of causality since xi p · later · q if evaluating the term later · with produces a value v then xi p · v q and by an inspection of the values of this type we see that v must be of the form later · mi or now p ­ since the variable xi is in the next context it cannot interfere with the part of the value in the present which means the present component cannot be stuck on xi that is xi could only possibly occur in mi this illustrates that future inputs do not affect present output ­ this is precisely what we mean by causality we also remark that strong normalization of guarantees reactive that is the evaluation of later · is guaranteed to terminate at some value v by strong normalization as an aside we note that if we were to use a type system such as that of and benton one could generalize this kind of argument to reduction at n and terms using n to obtain where x can only occur at time step n this gives a more global perspective of reactive execution however we use our form of the type system because we find it corresponds better in practice to how one about reactive programs one step at a time finally strong normalization of provides an explanation of liveness when evaluating a closed term m q at we arrive at a closed value v q by inspection of the normal forms such a value must provide a result after only finitely many delays this is to say that when running programs the environment may choose not to satisfy the liveness requirement eg it may never supply a p event in which case the output of the program cannot reasonably be expected to guarantee its liveness property since it may be waiting for an input event which never comes however we have the conditional result that if the environment satisfies its liveness requirement eg eventually it a p event then the result of the interaction satisfies its liveness property eg eventually the program will a q event related work most closely related to our work is the line of work by and his ­ our type systems are similar in particular our treatment of the modality and causality the key distinction lies in the treatment of recursion and fixed points et al employ a guarded recursion rule which allows some programs to be written more than with our operators however their recursion rule has the effect of least fixed points into greatest fixed points both type systems can be seen as interpretations of temporal logics ours has the advantage that it is capable of expressing liveness guarantees and hence it a relationship to ltl in their recent work they obtain also promising results about space usage which we have so far ignored in our foundation in his most recent work describes an operational semantics with better sharing behaviour than ours another key distinction between the two lines of work is that where we restrict to fixed points of strictly positive functors restricts to guarded fixed points ­ type variables always occur under even negative occurrences are permitted in contrast our approach allows a unified treatment of typical pure recursive datatypes eg list and temporal types eg a as well as more mixed types such as xx x that allowing negative guarded occurrences enables the definition of guarded recursion as a consequence this a of guarded µ and so negative occurrences appear incompatible with our goals also related is the work of jeffrey and who first observed that ltl propositions correspond to types both consider also continuous time while we focus on discrete time here we provide a missing piece of this correspondence the component jeffrey writes programs with a set of combinators in contrast to our mllike foundation his systems lack general datatypes and as a result one cannot write practical programs which enforce some liveness properties such as fairness as we do here in his recent work he illustrates what he calls a liveness guarantee the key distinction is that our liveness guarantees talk about some point in the future while jeffrey only illustrates guarantees about specific points in time we illustrated in sec that our type system can also provide similar guarantees we claim that our notion of liveness a correspondence to the concept of liveness as it is defined in the temporal logic world studies denotational settings for reactive programming some of which are capable of expressing liveness guarantees he obtains the result that his concrete process categories can express liveness when the underlying time domain has a greatest element he does not describe a language for programming in and hence it is not clear how to write programs which enforce liveness properties in unlike our work he discusses also least and greatest fixed points but does not mention the interleaving case in generality nor does he treat their existence or metatheory as we do here his may provide a promising denotational semantics for our calculus the classical linear µcalculus often called t l forms the for our calculus the study of classical t l proof systems goes back at least to our work offers a constructive typetheoretic view on t l and also investigate proof systems for a constructive variant of ltl with many of the same properties as ours eg the of they do not investigate fixed points or modalities other than synchronous dataflow languages such as esterel and are also related our work to a logical understanding of synchronous dataflow and in particular our work could possibly be seen as providing a type system for such languages birkedal et al also use a logical relation indexed by an larger than in particular to model countable nondeterminism which arises when modeling fairness in concurrent settings our is a much smaller than they require to the fact that we are not concerned with nondeterminism in the present work and de prove normalization results for pure type systems augmented with a later modality their systems have style guarded recursion and streams as their only instance of coinductive types for this reason the connection with liveness is absent from their work conclusion we have presented a typetheoretic foundation for reactive programming inspired by a constructive interpretation of linear temporal logic extended with least and greatest fixed point type constructors in the spirit of the modal µcalculus the distinction of least and greatest fixed points allows us to distinguish between events which may eventually occur or must eventually occur our type system acts as a sound proof system for ltl and hence expands on the interpretation of ltl we prove also strong normalization which together with type soundness guarantees causality and liveness of our programs future work our work provides a foundational basis for exploring expressive temporal logics as type systems for from a practical however our calculus is a few key features for example the import functions we in section traverse the entire term from a foundational perspective it is interesting to notice that they can be implemented at all however in practice one would like to employ a device such as stability to allow import for such types we believe that our system can provide a foundation for exploring such features in the presence of liveness guarantees it would also be useful to explore more general forms of recursion with syntactic or typing restrictions such as types to guarantee and which would allow our examples to typecheck as they are instead of by manual elaboration into this in the presence of interleaving µ and is challenging this is one motivation for using guarded recursion a promising direction is to explore the introduction of guarded recursion at socalled complete types in our type system by analogy with the complete spaces of ­ roughly types where occurrences of µ are restricted this would be a step in the direction of unifying the two approaches we are in the process of developing a denotational semantics for this calculus in the category of on inspired by the work of birkedal et al who study the on as well as who studies more general eg continuous time domains the idea is that the extra point at expresses the global behaviour ­ it expresses our liveness guarantees which can only be observed from a global perspective on time the challenge in our setting lies in constructing interleaving fixed points it is expected that such a denotational semantics will provide a explanation of our liveness guarantees references a and t a predicative strong proof for a lambdacalculus with interleaving inductive types in types pages ­ t constructions inductive types and strong normalization phd thesis university of edinburgh november g and l the esterel synchronous programming language and its mathematical semantics in on concurrency university pages ­ london uk uk springerverlag isbn l birkedal r e j and k first steps in guarded domain theory in the of trees in proceedings of the th annual ieee symposium on logic in computer science lics pages ­ ieee computer society l birkedal a and j stepindexed relational reasoning for countable nondeterminism submitted journal version of csl paper p d n and j a a declarative language for realtime programming in proceedings of the th acm symposium on principles of programming languages popl pages ­ acm g h cooper and s embedding dynamic dataflow in a callbyvalue language in proceedings of the th european conference on programming languages and systems esop pages ­ springerverlag a functional reactive programming in java in proceedings of the third international symposium on practical aspects of declarative languages pages ­ springerverlag j functional reactive programming in ocaml url c and p hudak functional reactive in proceedings of the second acm sigplan international conference on functional programming pages ­ acm j y girard et elimination des de these de paris jy girard y and p proofs and types cambridge university press h a modality for recursion in proceedings of the th annual ieee symposium on logic in computer science pages ­ ieee computer society a jeffrey ltl types temporal logic propositions as types proofs as functional reactive programs in proceedings of the workshop on programming languages meets program verification pages ­ acm a jeffrey causality for free parametricity implies causality for functional reactive programs in proceedings of the workshop on programming languages meets program verification pages ­ acm a jeffrey functional reactive programming with liveness guarantees in th international on functional programming acm w towards a common categorical semantics for temporal logic and functional reactive programming electronic notes in theoretical computer science ­ w temporal logic with until functional reactive programming with processes and concrete process categories in proceedings of the workshop on programming languages meets program verification pages ­ acm jp and m abstract data type systems theoretical computer science ­ k and a constructive temporal logic proof systems and kripke semantics information and computation ­ modal logic and applications d kozen results on the propositional µcalculus theoretical computer science ­ n r higherorder functional reactive programming without leaks in th international on functional programming acm n r and n benton semantics of reactive programs in proceedings of the ieee th annual symposium on logic in computer science pages ­ ieee computer society n r n benton and j higherorder functional reactive programming in bounded space in proceedings of the th annual acm sigplansigact symposium on principles of programming languages pages ­ acm o decidability completeness and extensions of linear time temporal logic phd thesis the institute of science z an extended calculus of constructions phd thesis university of edinburgh r extensions of system f by iteration and primitive recursion on monotone inductive types phd thesis university of n p inductive definition in type theory phd thesis cornell university h a and j functional reactive programming in proceedings of the acm sigplan workshop on haskell pages ­ acm d m r park concurrency and automata on infinite sequences in p editor theoretical computer science proceedings of the th lecture notes in computer science lncs pages ­ springer a pnueli the temporal logic of programs in proceedings of the th annual symposium on foundations of computer science pages ­ ieee computer society m version and reference manual april p g and fj j de pure type systems with on streams from finite to sigplan not ­ sept w w intensional interpretations of of finite type i the journal of symbolic logic pp ­ 