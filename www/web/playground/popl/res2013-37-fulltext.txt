symbolic learning of inputoutput specifications university of cambridge inc abstract we present a novel technique for learning symbolic models of software behavior addresses the challenge of synthesizing models of software by using symbolic and abstraction by combining dynamic symbolic execution to discover symbolic inputoutput steps of the programs and counterexample abstraction refinement to program behavior transforms arbitrary source representation of programs into faithful inputoutput models we define a class of stream that process streams of data which to a complete model if abstraction refinement eventually builds up a sufficiently strong abstraction in other words is complete relative to abstraction to represent inferred symbolic models we use a variant of symbolic transducers that can be effectively composed and equivalence checked thus enables fully automatic analysis of behavioral properties such as commutativity and idempotence which is useful for web sanitizer verification and stream programs compiler optimizations as we show we also show how models inferred by can performance of stream programs by code generation categories and subject descriptors d software engineering software methods d programming languages general terms languages theory verification keywords inductive learning specification synthesis behavioral properties equivalence checking stream programs compiler optimization parallelization introduction modern software systems often process large amounts of data in a fashion by streams we mean sequences of data items processed in some order such stream processing is inherent to many domains such as digital signal processing embedded applications network event processing applications web applications and even to common software likewise services running on a often process streams of moving data and of past data this work was done while the second author was with uc berkeley permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm we focus on a simple notion of programs that applies to many of these systems called a filter filters are typically small fragments of code but they facilitate large scale a filter iteratively reads a bounded number of items from an input stream at once performs some computation on those items and writes the results to an output stream filters exchange data via streams with other parts of the program and can also be together into more complex structures unfortunately reasoning about even these relatively programs is difficult as their lowlevel implementation details often the highlevel inputoutput behavior that we want to reason about our aim is to provide ways for automated analysis of the inputoutput behavior of programs such as stream filters although the internal implementation of such programs may be rather many of their properties rely solely on their inputoutput behavior to a of such properties let us consider simple filters p and p coming from say two of the code or from two different that implement a difference used in eg compression while true p in state while true p state in p and p are syntactically different and have different operational semantics but they exhibit the same inputoutput behavior behavioral equivalence of p and p ensures that the two implementations can be used instance a equivalent or with few states implementation might be over a stateful or with many states one as the former can be made amenable to execution by a simple replication for another property consider a filter q that looks like p but instead of the difference the sum of the two consecutive values if we connect p s output stream to qs input stream in a pipeline then the resulting composition will have the same behavior as if we were to connect qs output to p s input knowing that p and q are commutative with respect to each other we can them eg for performance reasons without the behavior of the pipeline in this paper we present a technique called that enables automated analyses of inputoutput properties of programs by learning uses dynamic symbolic execution to discover symbolic inputoutput steps of a program and counterexample abstraction refinement to program behavior and combines the two techniques into a sound and complete relative to abstraction symbolic learning algorithm works on the controlflow graph without assuming any specific in these code function out writes a data item to the output stream returns the item at the given offset in the input stream without it and in and returns the current item from the input stream figure the design of arrows indicate the data flow syntactic structure of the program and by learning a faithful symbolic model of program behavior it represents the models using a variant of symbolic transducers sts which generalize classical finitestate machines by allowing transitions labeled with arbitrary predicates as input guards and terms as output assuming formulae from a decidable theory sts can be effectively composed and enabling analysis of various behavioral properties such as commutativity and idempotence targets applications beyond just verification as we show enables domainspecific compiler optimizations eg filter fusion and reordering for a class of stream programs than currently possible also sts inferred by themselves to implementation eg by instructions gpu architecture or gate arrays and execution eg by replication or using speculative techniques such as overview of in a can be seen as an extension of l algorithm to learning models of programs l designed to learn regular languages in a manner is not applicable to the general software setting for two reasons l requires a priori knowledge of the concrete alphabet of the language while that certain scenarios such as inference of component interfaces where the alphabet corresponds to the set of components methods the exact alphabet of software including for instance all values that arise during the execution is hard to specify in advance even if known such alphabets are typically large or practically infinite so treating them concretely as in l scalability secondly l merely the inferred model and to check the conjecture relies upon an oracle a that can answer equivalence queries an oracle for equivalence checking against software is however computationally therefore is built around two key ideas uses dynamic symbolic execution to discover constraints on input values path predicates and terms generating output values and builds symbolic alphabet out of these by using symbolic alphabets to represent equivalence classes of inputoutput steps enables discovery of complete inputoutput behavior independently of the concrete alphabet size instead of equivalence checking against the program builds an abstraction that is a finitestate symbolic overapproximation of program behavior that we wish to learn checking equivalence of deterministic symbolic and such possibly nondeterministic can be done implements an algorithm that either generates a separating sequence counterexample showing how the conjecture and abstraction differ or proves they are equivalent starting with the trivial symbolic conjecture and the abstraction iteratively refines the conjecture or the abstraction until the two become equivalent see figure if the counterexample returned by the equivalence checking algorithm is spurious ie the program does not produce the same sequence of outputs as the abstraction we refine the abstraction otherwise the counterexample represents a behavior that the conjecture failed to capture and we refine the conjecture upon termination the final conjecture is in a certain sense minimal equivalent model of the program the symbolic conjecture maintained by is a variant of symbolic finitestate transducers that we call symbolic transducers to generate outputs use a window over a bounded number of past inputs can also be augmented with lookahead to allow of incoming inputs along with we also synthesize of program behavior in the form of we use predicate abstraction to abstract away the internal control flow of a program however in doing so we keep the inputoutput data flow we then transform the obtained abstraction into an equivalent nondeterministic to check equivalence of the conjecture and the overapproximation we use our algorithm for equivalence checking of a deterministic and nondeterministic the main technical result of the paper is that is relatively complete with respect to the abstraction assuming that the program behavior can be represented with an terminates with an equivalent to the program if the overapproximation scheme eventually produces an inductive invariant the programs inputoutput relation since synthesis of the is by abstraction refinement relative completeness of is by completeness of the predicate selection method in refinement of the predicate abstraction other classes of program behavior could be learned by varying the type of symbolic for programs whose behavior cannot be represented within the given class of symbolic models will end up more refined models ad however if is before convergence the conjecture is guaranteed to be correct up to the explored depth applications to demonstrate practical utility of we report three experimental studies with our implementation · web sanitizers verification we analyzed sanitizers from web sanitization framework and found out that of them out of can be represented as successfully inferred all sanitizers fully automatically enabling their further analysis with systems such as bek · stream filter optimization we applied to infer filters from various stream processing applications we show how enables optimizations such as reordering and fusion that are not possible with the current · parallelization we show how models of filters enable automated parallelization from a variety of we generated implementations using intel and gpu implementations using and obtained of up to against the most optimized gcc code contributions we claim the following contributions · symbolic learning framework we present an automated learning framework for learning symbolic models of inputoutput behavior the key insight behind besides use of symbolic alphabets to represent program steps is use of overapproximation to detect convergence · symbolic transducers we introduce a carefully limited variant of symbolic transducers that is amenable to learning prev cur i while true cur if i else if cur prev prev else prev prev in i figure code for the running example in § true true true a c b c true true true true true c a true true d a figure and abstractions for the example in figure and develop an equivalence checking algorithm we show that are useful in practice through three case studies two of which demonstrate novel use of transducers · synthesis of we show how to transform predicate abstraction of a program into an the program behavior and how to refine it the key step of the synthesis is of the components of states that correspond to the inputoutput flow · relative completeness our main technical result is that to a sound and complete model of programs as long as the abstraction refinement eventually builds a strong enough set of predicates effectively this result reduces the completeness of learning to the completeness of abstraction illustrated by example we begin by showing how works on the example given in figure the program reads input in an infinite loop using commands and in reads the current input symbol and leaves it in the input stream while in reads the current input symbol and moves onto the next one both commands halt if there is no more input to read in the first two iterations the program the last read symbol using command out and in every subsequent iteration it outputs the sum or difference of the last two symbols depending on their relative ordering we represent learned and synthesized abstractions in the example as with each transition is labeled by a symbolic pair of the form pt the transition is taken when the predicate p evaluates to true for a given sequence of concrete input symbols the term t describes the computed output predicates and terms are expressions over input symbols and constants we use to denote the current symbol and i to denote symbols read i transitions before with k are allowed to read only the current and the last k symbols we use dynamic symbolic execution to sequences of predicates and output terms occurring along the paths in the program execution for instance given an input of length four a possible execution might take twice the then branch of the first if then the else branch of the second if and finally the then branch of the second if for that execution we would obtain a predicate sequence the path condition p true · true · cur prev · cur prev and an output sequence t cur · cur · cur prev · cur prev in sequences such as p and t we use · to denote the concatenation operator to obtain predicates and output terms formulated with regard to the input we all references of variables in p and t so that they become expressed with respect to the current position in the input stream for instance the version of p would be the sequence true · true · · and of t the sequence · · · as for the variable j in each element pi of the sequences above corresponds to the input symbol j positions before the current position i in the input stream thus eg in the third and fourth element of the sequences correspond to the last two symbols read by the program to generate a concrete input from path conditions we need to them and pass the formula to an smt solver in the case above the solver might return a concrete sequence · · · satisfying the path condition begins processing the example by learning the first conjecture c figure a and compares it against predicate abstraction a of the program with respect to an empty set of predicates figure c note that unlike in the classic predicate abstraction we keep the inputoutput data flow equivalence checking of c and a produces the first symbolic counterexample say a p true and output t which is a behavior captured by the abstraction but not the conjecture any concrete sequence satisfying those two formulae is a concrete counterexample for example take input the program will produce output for that input without reading showing that pt is spurious because symbolic outputs do not match we refine the abstraction with respect to a new set of predicates obtained by some predicate selection method eg by taking atomic predicates in the weakest precondition computed along the path suppose such method returns i i at this instance the refined abstraction a is shown in figure d equivalence checking of a and c produces the second symbolic counterexample say p and t · · any sequence of three symbols will satisfy p and it turns out that counterexample is not spurious thus we have to refine the conjecture after processing the counterexample conjecture c shown in figure b c is correct but does not know that yet because equivalence checking of c and a returns the third counterexample say p true · true · and t · · the third counterexample is not spurious either thus once again we need to refine the abstraction using the same method for refinement as above we extend the set of predicates with predicate abstraction computes a which is equivalent to c and the process terminates inferring the programs inputoutput relation ie the specification of programs inputoutput behavior for the following example with nested loops terminates inferring a with shown on the right while true x in while x a x in a a a a programs we now turn to the formal development of in this section we formalize the syntax and semantics of programs that transform an input stream into an output stream of symbols behavior of certain such programs can be represented by § we also formally define concepts associated with the dynamic symbolic execution which we use in development of § and learning § to simplify we assume programs working with streams of integers let z be the set of integers n i z i the set of and b false true the set of booleans for a set d we denote by d the free monoid generated by d with concatenation as the operation and the empty word as identity we refer to words in d as sequences sequences of predicates resp terms we denote by p p · · · pm resp t t · · · tn for sequences of sequences of terms we write t we denote the length of p by p the ith element of p by pi and the subsequence pi · · · by for f d c and d d we write f d to denote the restriction of f on d for a and b such that n a b we write f a b to denote the function f such that for all i n f ai bi and for all x a an f x f x we use tx y to denote the term obtained from t by simultaneously replacing all free occurrences of x with y denotes the set of all free variables in t syntactic representation we first define syntactic representation of programs let v be the set of program variables expressions terms predicates and atomic commands cmd v over v are given by e k x fe b false true ¬b b b b b e e e e re c x e x x in cmd v where k z x v while f and r are constructors for terms and predicates as long as the quantifierfree theory of with equality and satisfiability of are decidable particular details of the grammar are not important the command x reads a data item at offset k from the current symbol in the input stream and stores the item to x if the input is available otherwise it causes the program to halt the in command works like but in addition the item from the input stream and moves onto the next input symbol the command writes the value of e to the output stream we represent programs using controlflow automata over the language of atomic commands the controlflow automaton is determined by a set of control nodes n containing a distinguished node sn n representing the starting point of the program and a function succ n × cmd v n representing labeled edges all nodes either have a single successor or have all outgoing edges labeled with a label of the form in the latter case we k k x x x if x v if x vi undefined otherwise fe f e en figure symbolic evaluation of expressions n i n i n i n i n i xe n i n x e i n x i n x ini i n out e i figure symbolic semantics of commands assume that all corresponding predicates b are mutually exclusive and that their disjunction is a symbolic semantics given a program p we now define its symbolic semantics we formalize the contents of the input and the output stream with sets of variables vi in in and vo out out respectively on a particular run of p all except finitely many of these variables are undefined and for those which are defined ini corresponds to the ith element of the input stream and out to the th element of the output stream by in we refer to the sequence of and we use in to denote the length of the data sequence in the input stream we evaluate expressions on a memory mem v as indicated in figure we execute commands on states of the form state n × mem × × n × n the third component vo represents the symbols in the output stream the last two components of the state the and the store indices of the current element in the input stream and the output stream respectively we denote the components of a state s state by sn s s si and s respectively the initial state is s sn we represent the symbolic semantics of p by a labeled transition system lts t state c with state as the set of states c cmd v as the finite set of labels and as the labeled transition relation the relation state × c × state is defined by the rules given in figure showing the effect of each command on a state in each rule we have n c we write s c s to denote the transition s c s dynamic symbolic traces path predicates and outputs the lts t encodes the symbolic semantics of p with respect to any input given a concrete input a z we can construct a sequence of states in t representing the dynamic symbolic trace of p driven by a as in we start with the initial state s and at each step we follow the transition si c si such that if c is of the form then b is true in a we stop if we ever reach a state sf which we call ending such that the in index sf i equals in or sf has an outgoing transition with k such that sf i k in we define the symbolic trace of p on input a denoted p a as the finite sequence ss sf if an ending state is reached or as the infinite sequence ss otherwise we refer to a state si as if si s si sf or the incoming transition reads an input symbol ie si in si let ss sn be the sequence of from p a we define bigstep transition as a transition between two successive states in for i n let pi be the conjunction of predicates b of the form encountered on all transitions between si and si in case no assume transitions exist between si and si we set pi to true furthermore for i n let ti be the sequence of symbolic outputs as written to by out transitions between si and si if no output is generated we set ti to we define path predicates of p on input a as the sequence p a p · · · pn analogously we define the symbolic output of p on a by p a t · · · tn the concrete output of p on a is defined by p a p ain a and programs in order to be able to learn program behavior we have to make some assumptions about programs when considering the inputoutput behavior of a program no path in a program should end up in a loop without reading an input ie we will not allow in finite of during which the program would not read any input this first assumption will allow us to extend incomplete of program behavior with new bigstep transitions sec we will assume that programs produce uniformly bounded number of output symbols per each bigstep transition this second assumption is inherent to symbolic transducers on which we base § the model of program behaviour used in more formally let t be the lts of p and any symbolic trace in t starting with s and ending with an let us denote in by in the number of transitions in and by out the number of out transitions in we say that p is if there are no infinite symbolic traces in t with only finitely many and there exists m n such that for every as above we have out m · in as a consequence if p is then for every input a p a is finite and p a p a m · a besides we impose an additional require ment that is specific to the type of transducers that we use to represent program behavior in but that could be relaxed if we would use more expressive models such as eg with registers this additional requirement that programs produce outputs from a bounded number of inputs in the past more formally we say that p is if p is and for every as above each in depends only on previous k inputs ie if s s then vars e s in § and § we focus on a class of programs whose behavior can be represented with input in development of § and the learning algorithm § we will need to symbolic expressions to program states so that they use the offset from the current position in the input stream rather than from the beginning we show how to these expressions so that the offset becomes relative to the current let v be an infinite set of variables indexed by a relative offset we use variables so that stands for the current symbol in the input stream i for the symbol i positions back and i for the symbol i positions let in i denote a variable substitution that maps each in to variable i we define of a state s n i by s n in i in i intuitively s symbolic expressions in s with respect to the current for general programs expressions in and components of s may use many variables as the expressions can refer to inputs from arbitrary far in the past however programs use only up to k variables with negative index namely k symbolic transducers with in the last section we formalized the syntax and semantics of programs in this section we introduce symbolic transducers with a constructive equivalence checking algorithm we use to represent synthesized § and symbolic in the learning algorithm § background finitestate transducers are an extension of classic finitestate automata obtained by allowing output on transitions see symbolic finitestate transducers extend finitestate transducers by symbolic transitions which are defined using predicates for input guards and symbolic terms for output our notion of extends symbolic finitestate transducers with a window over input which allows a transducer to generate outputs based on a bounded number of inputs from the past definitions we now formally define symbolic finitestate transducers with we specialize our for the case when the alphabet of input and output symbols is z but generalization is easy we omit k when it is not important instead of reading a single symbol from the input tape at a time the tape head of a is effectively a window of size k reading the current and the last k symbols equivalently such a transducer can be seen as a transducer with k registers updated in a fifo manner on each newly read symbol is inserted while the is removed from the queue rather than using registers we use the set of variables vk k so that is the current symbol and i is the symbol i positions back definition a symbolic finite transducer with k is a tuple a q q where q is a finite set of states q q is the initial state and q × × q × is a finite transition relation in other words is a variant of a symbolic sequential ie realtime transducer having only final states and in general can be nondeterministic and does not have to be we say that a is deterministic if for every two transitions q t r and q t r if is satisfiable then r r and t t is valid that are inferred by the s learning algorithm will always be deterministic and even more transitions from every state will have mutually disjoint guards we next formally define how produce output before defining a run of an we introduce some convenient notation it is how to learn transducers with states as such transducers allow inherent ambiguity in where the output is produced indeed existing algorithms for learning concrete transducers eg require all states to be final for brevity we refer to the sequence k as to process the input it with k dummy symbols z any operation with yields and every comparison with except is false for a sequence a let us denote a k · a a run of a q q on a zn is a finite sequence of states q qn such that there exists a sequence of transitions q t q t q · · · qn qn where n and t tn such that for all i n satisfies i we say that a on the input a produces the output o z and write a a o if for all i n oi ti where oi oi if a is deterministic the run is uniquely determined by the input sequence for a deterministic a and a z let us denote by aa aa and aa the corresponding sequences · · · n t · · · tn and o · · · on respectively we define the of a possibly nondeterministic a as a function ta z z defined by o a a o we say that a is singlevalued if for all a composition of are closed under composition given a a and a b their composition is a k a b such that o the composition of can be constructed similarly as the composition of symbolic finitestate transducers equivalence checking unfortunately general equivalence checking of is undecidable as it is already undecidable to check equivalence of concrete nondeterministic free finitestate transducers while the technique of et al could be adapted to to decide the singlevalued case that would not suffice in our case as of programs § need not to be fortunately our learning are always deterministic so in fact we only need to check equivalence between a deterministic and a possibly nondeterministic we present an efficient algorithm for equivalence checking between deterministic and nondeterministic which is a symbolic adaptation of the algorithm from demers et al for deciding of finitestate transducers to check whether a deterministic and nondeterministic are equivalent it suffices to check whether their union which is a nondeterministic is singlevalued checking whether a nondeterministic a q q is singlevalued is efficiently decidable in time by checking whether a linear grammar generated from a generates a language of let n t p s be a linear contextfree grammar with a finite set of nonterminals resp terminals n resp t a finite set of productions p of the form n t n t and the start symbol s n from a a generate a grammar g p q q where p is defined as s s ts s t such that si i ti si i i is satisfiable and ti by our learning algorithm denotes outputs on transitions that are either infeasible because of the constraints on the path condition or subsumed by other predicates a is singlevalued iff g generates a set of checking whether the outputs match under the guards reduces to checking the validity of formula i i t t which can be done with calls to the prover if a is not single valued then we construct a witness for between the deterministic and the nondeterministic called separating sequence by finding the shortest path from the start symbol to the first reachable rule that does not generate a extension with lookahead can be straightforwardly extended to incorporate lookahead in our model of the window begins at the current input tape head position and covers k last symbols such window can also be made to cover symbols of the current head position by using additional variables l such that i stands for the symbol i positions a with a lookahead l can be reduced to a k so equivalence checking of with lookahead can be reduced to equivalence checking of synthesis of we now show how to synthesize sound program for a class of programs with finite are computed in two steps in the first step we construct an overapproximation of the program that is based on predicate abstraction in the second step we transform the obtained abstraction to an equivalent nondeterministic we refine such an by the set of predicates in predicate abstraction abstraction of programs the goal of the abstraction is to abstract away the internal computation of the program but in doing so to keep all of its original inputoutput behavior let us consider the lts t state c of a program p as defined in § we our abstraction by a set of predicates over program variables interpreted over v z let us denote by pred the set of boolean combinations over predicates from ie all minterms we define the abstraction of t as the lts t state c constructed as follows the set of abstract states state is given by state n × pred × vd × × n × n where the valuations of program variables are mapped to predicates in pred satisfied by the valuation while the data variables vd v that are live ie for which there exists data flow to output terms are kept along with other components of the state using the approximate post operator on pred computed with predicate abstraction we obtain the transition relation on abstract states we rely on the soundness of the predicate abstraction to obtain the following proposition for every input a if p a s sn is a trace in t then there exists a trace p a s sn in t such that for every i n sin sin si si si si si and si satisfies si consequently the output p a corresponding to the trace p a is equal to p a translation to we now translate the abstract lts t state c into an equivalent possibly nondeterministic we define an equivalence relation on state as follows for s s state we let s s iff for s n j and s n j we have n n and relation can have infinitely many equivalence classes in general however we focus on programs having as we can represent such programs with and learn with definition we say that p is if for any choice of the corresponding relation is of finite index programs necessary have a bounded let us define t as the set of all sequences of states between s and t such that there is a single input transition we extend the definition of to s n i state by s n in i in i in i between states on the path from s to t for t let us denote by the conjunction of assumed predicates on transitions in and let be the produced symbolic output we need the following lemma for our translation to an to be welldefined lemma if s s and t t then for every path t there exists an equivalent path t such that and we define a to be the q q with q s s is as the set of states q s as the initial state and as the transition relation such that s t s iff there exist s such that and t intuitively a represents all isomorphism classes of bigstep transitions between the abstracted lemma if p is then a is an we can now show that a captures exactly the behavior of t thus a soundly the behavior of p proposition for all a p a o iff a a o corollary for all a if p a o then a a o refinement suppose that a strictly the behavior of an p on some input a ie there exist o and o o o such that p a o and a a o then we need to refine the abstraction a we do so by adding enough predicates to to evidence of the spurious run in a that generates o our approach to finding a new set of predicates for refining a is based on standard counterexample feasibility analysis with weakest preconditions the basic idea is to build a predicate from the spurious trace in a generating o so that is unsatisfiable if and only if the given trace is infeasible in p starting with false is obtained by applying the weakest precondition of commands in p along the trace until the beginning of the trace to maintain the syntactic form of collected along the trace we keep all substitutions in explicitly the set of all atomic predicates in is then used to augment although more involved methods eg based on craig interpolation are possible our empirical evaluation shows that this heuristic works well in practice for our target classes of programs completeness of the predicate selection method since our abstraction is based on predicate abstraction and fully precise isomorphic representation of other components of the state a in fact defines the strongest inductive invariant containing the reachable set of states of p that is expressible as a boolean combination of the given set of predicates while preserving the inputoutput relation in the form if there exists a quantifierfree inductive invariant which can be built using some set of predicates such that uniquely identifies the reachable states of p then the construction of abstraction would converge assuming a complete decision procedure for the underlying theory and a predicate selection method that would eventually build such by the relative completeness of predicate abstraction we could generate an invariant as strong as although it is not clear how to construct such directly from p we can construct it if the number of states n of an ap that is equivalent to p is known a explicitly encoding a checking sequence that distinguishes ap from all in some examples we employ additional heuristic that uses templates built from syntactic predicates in the code other transducers up to n states to abstract away the complexity of such construction we assume existence of a predicate selection method that eventually yields a set resulting in an abstraction a equivalent to p we will say that a predicate selection method is complete if it is guaranteed to eventually generate a sufficient set of predicates to construct a equivalent to p our main result expresses completeness of our learning algorithm relative to existence of such a complete predicate selection method however we emphasize that the predicate selection mechanism does not affect the soundness of nor the quality of inferred models only the eventual convergence learning in this section we describe s learning algorithm and prove its main properties our algorithm iteratively builds similarly as l to make the presentation reasonably we first give a brief overview of l § we then define the representation of § followed by the detailed presentation of the learning algorithm § and its properties § background overview of l here we give an informal overview of the classic l see the paper of for a more detailed description or and for the machines version of l the goal of l is to learn an unknown regular language d by generating a deterministic finite automaton dfa that accepts d l starts by a who knows d membership queries over a known concrete alphabet to check whether certain words are in d the results of these queries are recorded in a socalled observation table membership queries are iteratively until certain technical conditions are met upon which l an automaton l the an equivalence query to check if the language is equivalent to d the either the equivalence or returns a counterexample which is a word that distinguishes d from the conjecture l uses the counterexample to new membership queries refining the conjecture this procedure is repeated until the conjecture becomes equivalent to d if d is indeed a regular language then l is guaranteed to find a minimal dfa for d after at most a polynomial number of membership and equivalence queries in we answer the membership queries by using a combination of concrete and symbolic execution and the equivalence queries by equivalence checking learned and refined abstractions using the equivalence checking algorithm for § definitions we proceed by giving notational used in the section and defining s representation of the observation table we first define a function for path predicates and symbolic outputs by s sn sin n where in i is the variable substitution defined in § and s is either a path predicate or symbolic output if s is a symbolic output t the same function is applied to each individual term in the subsequence ie if t t tm then i i i we next define witness as a function that takes a sequence of predicates them by applying the inverse of the substitution computes a conjunction of predicates ip p i passes the conjunction to an smt solver and returns a concrete sequence of input symbols of length p satisfying the conjunction or if the conjunction is infeasible finally we point out that all equality resp inequality checks resp over predicates and terms in this section are syntactic equality resp inequality checks constructs symbolic observation table similarly as l but table entries are path predicates and symbolic outputs § rather than concrete words the finished table can be easily translated into an representing a conjecture as in l such conjecture will always be deterministic definition symbolic observation table is a r s e t × where r s represents a set of identified states s resp e is a prefix resp suffix closed set of path predicates and t is a map indexed by pp s ps e containing the suffix of the symbolic output generated when processing ps immediately after pp ie if a · ps and t p a then t pp ps ts where ts is a suffix of t such that ts ps for p s we define a in the observation table as an set denoted we denote outputs generated by infeasible transitions in the table by intuitively r represents a set of shortest paths leading to discovered states s r contains exactly path predicates from r and additionally all the sequences that extend sequences from r by exactly one bigstep transition the role of s is to exercise all the transitions in the inferred finally e is the set of distinguishing tests that distinguish different states the classic l makes a conjecture when the table is closed which means that every sequence in s has a representative in r ie p s r r we define in the same way as l from a closed table we can easily construct a complete for all states and input symbols all transitions are defined using standard techniques eg see the learning algorithm we begin by describing the algorithm that computes the missing entries of the observation table continue with the algorithm that the successor states of all states discovered at certain step and end with the s learning algorithm algorithm computes the missing entries in the observation table if the entry is missing for some prefix pp s and suffix ps e we first try to compute a concrete witness a by together the prefix and the suffix line while the sets s and r contain path predicates that are collected along prefixes of some feasible paths in p starting from the initial state the set e contains of feasible paths naturally when we arbitrarily prefixes and of different paths the resulting formula might be infeasible if feasible we execute a on p using execution line and collect the predicates r and output terms t from bigstep transitions note that the collected predicates might differ from pp · ps but at least the prefix corresponding to pp will always match the outputs corresponding to at the cost of more complex we could use semantic equality and check that output terms are equal under the guard restrictions such an approach might allow us to learn more compact in l one also defines the consistency property which would in our setting say that if two sequences p p from r are equivalent then both states reached by p and p must produce the same output in the next bigstep transition given the same input symbol we maintain the consistency of our symbolic observation table by always that each state has only one representative in the r set input and output observation table ot forall the pp s ps e such that t pp ps is undefined do a · ps if a then r t p a p a t ts forall the i t do if i pp then if pp · psi ri then ts ts · ti else ts ts · else ri t pp ps ts else t pp ps close the table forall the p s st r do r r p new state return ot algorithm the algorithm predicates and infeasible path conditions are marked lines ­ replace the output terms at positions where the pp · ps and r sequences differ syntactically finally lines ­ close the table algorithm takes a state representative r ie a path predicate that holds on the shortest path to the identified state and finds all the outgoing bigstep transitions from that state adding the predicates from those transitions to e and the entire sequence r extended by one transition to s the only interesting part of the algorithm is the discovery of new transitions and the corresponding predicates in the first iteration line extends the representative sequence r with predicate true effectively allowing the solver to produce an arbitrary value for the last element of the concrete input sequence executing the obtained concrete sequence and collecting predicates along the path we identify the first bigstep transition guard predicate rs in every following iteration we a disjunction of the predicates discovered so far until the disjunction becomes valid test at line all infeasible traces lead to a ghost state that has one transition labeled true the algorithm creates such a state automatically if needed by the corresponding row with as even the prefix to the ghost state is infeasible finally algorithm infers a symbolic transducer lines ­ discover all the bigstep transitions from the initial state and the corresponding predicates all the discovered predicates are added to the set e in the next three lines we extend and close the table producing the first ac conjecture and the first abstraction a of p the loop beginning on line checks the equivalence between the conjecture and abstraction if they are equivalent the algorithm terminates returning the exact transducer implemented by p otherwise the counterexample is checked against p if it is spurious we refine the abstraction otherwise we refine the conjecture we use and technique for processing the counterexamples adapted for our symbolic setting first we collect the predicates from p along the path determined by the counterexample and discard the longest prefix that is already in s we denote the remaining suffix by ps we add all of ps to e line to that e remains suffix closed properties first we state the main properties of and then proceed with the proof of relative completeness and a discussion of computational complexity input and output observation table ot forall the r r do extend all sequences from r if e ps r · ps s then s false while s true do rs a · if a then rs s true else p p a r rs pr s s rs e e rs s s r · rs ot return ot algorithm the algorithm init r s e t i s false result ac repeat fill st row if s false then a randomly generated array of type z else a p p a st pred from path predicate e e p t p p a s s p until s true r s e t s e t compute ac from r s e t compute initial a of p while true do let a o be a separating sequence between ac and a if a then return ac if p a o then spurious counterexample refine a of p on a o else p p a let pp be the longest prefix of p st pp s let ps be st p pp · ps e e suffix ps r s e t s e t compute ac from r s e t algorithm the s learning algorithm lemma let t r s e t be a symbolic observation table then preserves the following invariants r and s resp e are always prefix resp suffix closed for every p s there is a unique r r such that for every r r there are rs such that n i true and for all i it holds that r · s the conjecture ac is closed at the end of each step correctness r represents the part of the symbolic execution tree of p on which the conjecture represents the behavior of p which is stated with the following proposition proposition bounded correctness after each step for all r r and a such that a p a ac a holds one can bounded correctness as a guarantee given by in case is before reaching a convergence in other words we can consider as performing bounded model checking of the program with a exploration strategy by the learned model completeness the following lemma ensures that a progress is made after each conjecture refinement lemma if at some step of a o is a separating sequence such that p a o then at the end of the step for all a such that a a ac a p a holds we state the completeness of relative to the completeness of the predicate selection method theorem relative completeness if p is and the predicate selection method for refinement is complete then terminates with ac being equivalent to p proof first note that when a is singlevalued then by the soundness of abstraction a is in fact equivalent to p as the predicate selection method is assumed to be complete we will eventually obtain a singlevalued a the equivalence check of a and ac always returns the shortest separating sequence if one exists there can be only finitely many shortest separating sequences of a given length and at each step such a sequence is used either to refine the conjecture or to refine the abstraction therefore the number of conjecture refinements must also be finite computational complexity next we analyze the complexity of let n be the number of states of the inferred k the maximal number of outgoing bigstep transitions from any state m the maximal length of any counterexample and c the number of counterexamples there can be at most n counterexamples as each counterexample distinguishes at least one state since we initialize e with k predicates e can grow to at most the size of s is at most n · k thus the table can contain at most n · k · k m · n m on · k m · n · k entries the k factor is likely to be small in practice and our equivalence checking algorithm finds the minimal counterexample the smt solver is called once per each state ie representative in r and for each outgoing transition for each equivalence check we might need to call the solver n times thus the total worstcase number of calls to the solver is on · k n not including the number of calls required for abstraction refinement which depends on the abstraction technique used applications in this section we demonstrate practical utility of by applying it in three different application domains and experimental results obtained with our prototype implementation we built our implementation on top of with and we to generate symbolic traces and answer membership queries for the learning algorithm § and used in the equivalence checking algorithm § we used for counterexampleguided predicate abstraction refinement § all experiments were run on a machine with intel core cpu and gpu with benchmark learned int bits states l l l l transitions · l l l l l ac refinements l l l l a refinements l l l l l l l l table experimental results the benchmarks that successfully learned are denoted by the last benchmark could be learned if were extended to handle transducers int bits is the size of the internal control and data state in bits states the number of states in the final transitions the number of transitions in the final ac refinements the number of refinements of the conjecture a refinements the number of refinements of the abstraction and the size of the set of predicates in the final abstraction in each of the four benchmarks whose rows contain symbolic expressions dependent on l the particular l denotes the bound on the size of the buffer internally used by the benchmark the value of l depends on the characteristics of the input language of the benchmark and is a priori fixed in our four benchmarks eg for it is bounded by the maximal length of tag names attribute names and special symbols each the learning algorithm inferred all benchmarks described below in less than three seconds web sanitizers verification to make web applications more secure sanitization is used to remove possibly malicious elements from users input although small in numbers of lines of code sanitizers in realworld applications are surprisingly difficult to implement correctly often because lowlevel implementation are the intended inputoutput behavior by automatically inferring inputoutput models of sanitizers we can automatically check their properties such as commutativity and idempotence using tool such as bek we evaluated on the sanitizers from ga web sanitization framework the same benchmarks used by et al we the sanitizer as it is effectively just a wrapper for calling other sanitizers in addition to ga sanitizers we added to our benchmark suite the sanitizers and we found out that of ga sanitizers out of along with and are and were successfully learned by table in comparison the authors of had to several of a human time into manual synthesis of each transducer from the source code only two sanitizers could not be inferred by is effectively a but it is implemented by calling the function in guards which could only be represented by nondeterminism as return value could be arbitrarily far from the start of the input string generates output from a set of symbols only at the end of the input but it could be learned if were extended to transducers by generalizing algorithm to the symbolic setting stream filter optimization stream programs often consist of many interacting filters that have to be optimized against various goals eg speed two filter optimizations are reordering and fusion for instance reordering might be when it would place a filter that is selective ie some data before a costly filter that does some processing however we must ensure that the benchmark kernel complex filter filter filter in in fm in internal parser in in linear table properties of filters inferred by first four filters are linear and can be optimized with existing techniques enables fusion and reordering optimizations for all filters by we mean transducers two filters are commutative in order for reordering to be safe filter fusion is used when it would be to pipeline parallelism for lower communication cost we a set of experiments to explore ability of to enable stream filter optimizations such as reordering and fusion table shows filters inferred by indicating their two key properties whether they encode a linear or nonlinear output function and whether they are ie have a single state or stateful ie have more then one state first four filters can be optimized with existing techniques for optimizing linear filters to our knowledge no optimization techniques used in existing stream program compilers can optimize the remaining filters in table on the other hand enables fusion and reordering optimizations for all filters parallelization finally we show how models of filters enable automated parallelization we consider two approaches to improving of hardware concurrency by mapping filters to multiple and instructions filters are inherently and themselves naturally to both and implementations by simple replication stateful filters normally cannot be this way as their next invocation depends on the previous invocation however filters have usually small a known number of states so we can run each replica of an filter from each state in parallel and merge suitable outputs to provide some insight into possible practical we generated implementations using intel and gpu implementations using of from table from table and and one inferred by original source code representations of all are stateful and some of them are with loop for the we obtained in the range of to for the versions and to for the versions for the state the speedup of the version was versions were run using threads resp threads in blocks for the resp we established the by running the sequential version of compiled with gcc with all optimizations o and flags turned on discussion predicate abstraction to obtain complete models relies on convergence of the abstraction one could ask why we need the whole learning machinery of as we the abstraction eventually equivalent although in a possibly nondeterministic form to the behavioral model our program is deterministic so as long as the abstraction is not singlevalued it must contain infeasible behavior therefore we could consider a procedure that just iteratively refines the abstraction until the abstraction becomes singlevalued setting aside how to efficiently refine abstractions alone an approach from a fundamental limitation models generated by the abstraction can be larger than the ones learned by for instance consider the program from figure in which is considered as an example on which predicate abstraction does not work well let us adapt the example by adding reading an input and writing some output in the loop and enclosing it with an outer to become a program then infers a while by using predicate abstraction alone we would obtain an with states limitations along with the dependency on the abstraction ability of to infer complete models of program behavior is limited by the expressive power of symbolic we have restricted so as to be able to represent interesting realworld examples while still being able to learn and equivalence check them efficiently however there are still other interesting classes of programs that are not at the cost of additional complexity we believe it would be possible to extend to work with symbolic versions of more expressive transducers such as and streaming transducers and in this way enable learning of larger classes of programs incomplete models while the main concern of this paper is learning of exact behavioral models incomplete models inferred by could also be useful eg for automated testing based on dynamic symbolic execution the learning component of can be seen as systematically exploring all paths in the execution tree of a program but in addition the behavior of not yet explored branches could be used to guide the exploration strategy similarly as in which showed how concrete transducer enable more effective testing of protocol implementations other related work learning of symbolic transducers previous work on learning some notion of symbolic transducers focuses on variations that a priori fix the shape of predicates and generate concrete values learning algorithms for these transducers existence of an equivalence checking oracle and work over concrete alphabets relying on the shape restrictions to translate the concrete transducer to a symbolic one as software feature predicates that are unknown prior to the analysis if techniques were to be applied in the software setting they would need to enumerate predicates whose set is unbounded learning in verification techniques for learning various types of automata have been applied in a wide variety of verification settings inference of interface invariants execution compositional verification and regular model checking in those settings except for learning is performed using concrete alphabets in a manner even though source code is usually available independently to us et al have recently developed a technique for learning component interfaces that combines l with symbolic execution to discover method input guards however their approach treats method invocations as a single input step with no output and unlike assumes that each method has a finite number of paths under this later constraint equivalence checking can be done by merely executing a sufficiently large number of membership queries and c approach to synthesis of interface specifications with also uses predicate abstraction as however predicate abstraction in is used to check whether the synthesized interfaces are safe for a given safety property in general such interfaces are approximate and may incorporate infeasible behavior in addition the paper does not demonstrate that the technique can be fully automated in contrast is fully automated and infers faithful models upon termination property checking although the goal of is different it some ideas used in property checking most closely related collecting predicates on conditional statements as in automated testing has been previously combined with predicate abstraction in the algorithm while uses a combination of must and may analyses to check safety properties faster uses must learning and may abstraction to infer a more compact inputoutput relation optimizations of filters the work to our application of for stream compiler optimizations is on optimizations of linear filters and slightly more general linear state space systems in in another line of work fusion of filters for has been developed using an affine model et al developed a proof calculus that allows analysis of nonlinear filters but they can perform reordering optimizations only if filters are in contrast allows fusion and reordering of stateful filters with nonlinear inputoutput relations approaches for numerical static analysis of linear filters eg do not relate directly to ours as their goal is to obtain deep numerical properties of filters such as numerical bounds for applications automated parallelization et al extract pipeline partitions from streaming applications written in c by relying on annotations indicating pipeline boundaries in contrast our approach does not require any annotations for synchronous dataflow streaming applications parallelism has been exploited either by filters or by using affine partitioning of loop in contrast enables parallelization of nonlinear stateful filters with loop bounds there is a amount of work on general iteration dependence scheduling eg see is at such advanced techniques by enabling par of simple loop that are not necessary polyhedral disjoint or with a clear pipeline structure acknowledgments this work was supported by the trust the national lab grant b and by the pdf thanks to matthew parkinson john and the anonymous reviewers for comments and suggestions references f b and j generating models of communication protocols using regular inference with abstraction in proc of the nd ifip int conf on testing software and systems pages ­ s w and s p optimizing stream programs using linear state space analysis in proc of the int conf on compilers architecture and synthesis for embedded systems pages ­ r and p c streaming transducers for algorithmic verification of programs in proc of the th acm sigplansigact symp on principles of programming languages pages ­ r p c p and w synthesis of interface specifications for java classes in proc of the nd acm sigplansigact symp on principles of programming languages pages ­ d learning regular sets from queries and counterexamples information and computation ­ t ball formalizing refinement with weakest preconditions in engineering theories of software systems volume of science series pages ­ t ball r majumdar t and s rajamani automatic predicate abstraction of c programs in proc of the acm sigplan conference on programming language design and implementation pages ­ t ball a podelski and s k rajamani boolean and cartesian abstraction for model checking c programs in proc of the th int conf on tools and algorithms for the construction and analysis of systems pages ­ t ball a podelski and s k rajamani relative completeness of abstraction refinement for software model checking in proc of the th int conf on tools and algorithms for the construction and analysis of systems pages ­ d m v n e c and g composing static and dynamic analysis to validate sanitization in web applications in ieee symposium on security and privacy pages ­ m m n u j a and p dynamic scheduling for effective parallelization of loop on processors in proc of the th acm sigplan symp on principles and practice of parallel programming pages ­ t b and h regular inference for state machines using domains with equality tests in proc of the theory and practice of software th int conf on fundamental approaches to software engineering pages ­ d and m e a tool for software verification in proc of the rd int conf on computer aided verification pages ­ n p b d and m symbolic finite state transducers algorithms and applications in the th acm sigplansigact symp on principles of programming languages i t d r horn j k m and p for stream computing on hardware acm trans graph ­ c and d r execution generated test cases how to make systems code crash itself in proc of the th int workshop on model checking software pages ­ c d and d and automatic generation of tests for complex systems programs in proc of the th usenix symp on operating systems design and implementation pages ­ m k chen xf li r j h lin l t and r achieving high performance from compiled network applications while enabling ease of programming in proc of the acm sigplan conference on programming language design and implementation pages ­ c y d p k z chen e x wu and d exploration for protocol and discovery in usenix security symposium e m clarke o s y lu and h counterexampleguided abstraction refinement in proc of the th int conf on computer aided verification pages ­ j m d and c s learning assumptions for compositional verification in proc of the th int conf on tools and algorithms for the construction and analysis of systems volume pages ­ a j demers c and b on some decidable properties of finite state translations informatica ­ m h r m and s p in a stream programming language in proc of the th international parallel and distributed processing symposium j static analysis of digital filters in programming languages and systems th european symposium on programming pages ­ v and d l a decision procedure for and arrays in proc of the th int conf on computer aided verification pages ­ b h kl wu p s and m the system s declarative stream processing engine in conference pages ­ d z and v symbolic learning of component interfaces in th int symp on static analysis pages ­ p n and k dart directed automated random testing in proc of the acm sigplan conf on programming language design and implementation pages ­ m i gordon w and s p exploiting task data and pipeline parallelism in stream programs in proc of the th int conf on support for programming languages and operating systems pages ­ s and h construction of abstract state graphs with in proc of the th int conf on computer aided verification pages ­ b s t a henzinger y a v and s k rajamani a new algorithm for property checking in proc of the th acm int symp on foundations of software engineering pages ­ j j y turner and m programming generalpurpose processors using streams in proc of the th int conf on support for programming languages and operating systems pages ­ m r j s d t m austin t and r b a free representative embedded benchmark suite in proc of the characterization ieee int workshop pages ­ p and t regular model checking using inference of regular languages notes theor comput sci ­ a wf d f and r m a computing folding streams in in proc of the th design automation conference pages ­ t a henzinger r jhala r majumdar and g lazy abstraction in proc of the th acm sigplansigact symp on principles of programming languages pages ­ p b d p and m fast and precise sanitizer analysis with bek in usenix security symposium j e hopcroft on the equivalence and containment problems for contextfree languages theory of computing systems ­ a m s a d f and r m efficient realization of streaming applications on in proc of the int conf on compilers architecture and synthesis for embedded systems pages ­ f b b and s inferring canonical register automata in proc of the th int conf on verification model checking and abstract interpretation pages ­ o h the of the equivalence problem for free with unary input output alphabet and applications in proc of the th annual symp on foundations of computer science pages ­ r jhala and k l a practical and complete approach to predicate refinement in proc of the th int conf on tools and algorithms for the construction and analysis of systems pages ­ u j w j s j d and b the imagine stream processor in proc of the th int conf on computer design vlsi in computers and processors pages ­ m and s a the execution of stream programs on platforms in proc of the acm sigplan conference on programming language design and implementation pages ­ a a w and s p linear analysis and optimization of stream programs in proc of the acm sigplan conference on programming language design and implementation pages ­ d lee and m principles and methods of testing finite state survey in proc of the ieee volume pages ­ sw z du g wu and gy data and computation transformations for streaming applications on in proc of the th int symp on code generation and optimization pages ­ p g and k safe speculative parallelism in proc of the acm sigplan conf on programming language design and implementation pages ­ k d and g a unit testing engine for c in proc of the th european software engineering conf held with th acm int symp on foundations of software engineering pages ­ m and r inferring machines in proc of the nd world on formal methods pages ­ r d and c s learning component interfaces with may and must abstractions in proc of the nd int conf on computer aided verification pages ­ r m r b h v and kl wu a universal calculus for stream processing languages in programming languages and systems th european symposium on programming pages ­ w and s p an empirical characterization of stream programs and its implications for language and compiler design in proc of the th international conference on parallel architecture and compilation techniques pages ­ w m and s p a language for streaming applications in proc of the th international conference on compiler construction pages ­ w v and s p a practical approach to exploiting pipeline parallelism in c programs in th annual int symp on pages ­ a r and m j software execution of stream programs on in proc of the th int symp on code generation and optimization pages ­ m d b and l generating fast string manipulating code through transducer exploration and integration technical report microsoft research j m query learning of transducers in proc of the rd int colloquium on inference learning syntax from pages ­ 