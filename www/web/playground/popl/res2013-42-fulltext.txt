parsing for languages rule michael d portland state university abstract several popular languages such as haskell python and f use the indentation and layout of code as part of their syntax because contextfree grammars cannot express the rules of indentation parsers for these languages currently use ad hoc techniques to handle layout these techniques tend to be lowlevel and operational in nature and the advantages of more declarative specifications like contextfree grammars for example they are often coded by hand instead of being generated by a parser generator this paper presents a simple extension to contextfree grammars that can express these layout rules and derives and lrk algorithms for parsing these grammars these grammars are easy to write and can be parsed efficiently examples for several languages are presented as are benchmarks showing the practical efficiency of these algorithms categories and subject descriptors d programming languages formal definitions and d programming languages f mathematical logic and formal languages grammars and other rewriting general terms algorithms languages keywords parsing indentation rule introduction languages such as haskell ed and python python use the indentation of code to various forms in haskell the contents of a let where do or case expression can be relative to the surrounding code instead of being explicitly delimited by in python the body of a function or compound statement must be relative to the surrounding code there is no alternative syntax for example in haskell one may write f loop where loop acc acc x xs where acc x f acc x acc xs loop acc xs loop acc acc permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm the indentation of the bindings after each where keyword determines the parse structure of this code for example the indentation of the last line determines that it is part of the bindings introduced by the first where instead of the second where likewise in python one may write def result for i in range x result result i return result print factorial here the indentation determines that the for loop ends before the return and the factorial function ends after the return while haskell and python are well known for being languages quite a few other languages also use indentation introduced the concept of the rule for indentation which requires that all tokens in an expression be at least as far as the first token of the expression variations on this rule are used by haskell turner limited wadler curry ed and project f is indentation sensitive when its lightweight syntax is enabled et al § the block in the et al data language are indentation sensitive as are many forms in the and languages even scheme has an syntax in the form of though it is not often used sensitivity may be but regardless of whether it is a good idea from a language design perspective it is important that the grammars of languages be precisely specified unfortunately many language specifications are informal in their description of layout or use that are not amenable to practical implementation the task of parsing layout is thus often left to ad hoc code the lack of a standard formalism for expressing these layout rules and of parser generators for such a formalism increases the complexity of writing parsers for these languages often practical parsers for these languages have significant structural differences from the language specification for example the layout rule for haskell is specified in terms of an extra pass between the and the parser that inserts explicit this extra pass uses information about whether the parsing that occurs later in the pipeline will succeed or fail on particular inputs due to the resulting cyclic dependency haskell implementations do not actually structure their parsers this way as a result the structural differences between the implementation and the specification make it difficult to determine if one accurately reflects the other this paper aims to resolve this situation by a grammar formalism for expressing layout rules this formalism is both sound and practical to implement grammars are easy and convenient to write and fast and efficient parsers can be implemented for them the primary contributions of this paper are ­ a grammar formalism for expressing languages which is informally described in section and formally defined later in section ­ a in section of the expressivity of these grammars by showing how to express the layout rules of haskell and python in terms of these grammars ­ a development in section of and lrk parsing algorithms for these grammars which is possible by a careful factoring of item sets into state and indentation sets and ­ a in section of the practical performance of these parsing techniques relative to existing ad hoc techniques section of this paper related work section concludes note that section of this paper assumes a fair amount of with standard parsing techniques and in particular the work by knuth on lrk parsing other than section however this paper assumes only a basic knowledge of contextfree grammars the basic idea in order to support parsing we use a modification of traditional contextfree grammars we parse over a sequence of terminals where every terminal is annotated with the column at which it occurs in the source code we call this its indentation during parsing we also annotate each nonterminal with an indentation the grammar specifies a numerical relation that the indentation of each nonterminal must have with the indentation of its immediate children these relations are usually chosen so the indentation of a nonterminal is the minimum column at which any token in the nonterminal is allowed to occur thus the indentation of a nonterminal usually coincides with the intuitive notion of how far a block of code is formally however the indentation of a nonterminal has no meaning other than that it must appropriately relate to the indentation of the nonterminals children we call these grammars contextfree grammars to contrast them with traditional contextfree grammars section gives examples of for real world languages and section formally defines this class of grammars as a simple example we may write a a to mean that and must be at the same indentation as the a on the left of the production arrow but the a on the right must be at a greater indentation we may also write a a to mean the same except that and must be at a greater or equal indentation than the a on the left of the production arrow in addition we may write a aa to mean that the indentation of both occurrences of a on the right of the production must be at equal to that of the a on the left of the production combined with the production a these form a grammar of nested parentheses and square brackets in that grammar matching parentheses must and things in parentheses must be more than the parentheses are things in square brackets merely must be more than the surrounding code figure shows examples of parse trees for this grammar on the words and where we write xi to mean that i is the indentation of x in these parse trees take particular note of how the of the nonterminals a a a a a a a a a a a a a a figure example parse trees for and respectively and terminals relate according to the indentation relations specified in the grammar in general we write a production as a x x · · · where · · · n are relations between to mean that the indentation of a relates to the of each x x · · · xn according to · · · n that is to say this production requires j i j i · · · jn n i if i is the in of a and j j · · · jn are the respective of x x · · · xn while in principle any set of indentation relations can be used we restrict ourselves to the relations and the and relations have their usual meanings the relation is i j i j n and effectively the indentation of a child from that of its parent languages typically have forms that re the first token of a subexpression to be at the same tation as the subexpression itself even though the nonterminal for that subexpression does not normally require this thus for every nonterminal or terminal x we introduce the nonterminal x that is identical to x except that its indentation is always equal to the indentation of its first token this is merely syntactic sugar as we can introduce the production a a for each terminal a and the production a xm x m m · · · for each production a x x · · · where n and each m n such that x x · · · xm are all for example with the above grammar a would have the productions a a and a a from the first two productions for a it would also have a a a and a a from the third production for a by replacing m with the first symbol of each production is forced to have the same indentation as the non terminal on the left of the production by transitivity this is the in of the first token in the nonterminal this is a mechanical transformation requiring no input from the user languages despite this systems simplicity it can express a wide array of layout rules this section demonstrates this by presenting the layout rules of several languages in terms of where possible we use the nonterminal names from the original grammar of each language though not shown here for other languages have been constructed for curry and the additional indentation relation i i i n is required by as it has forms that require increasing indentation by exactly and with introduced several still used in programming languages among these is the use of indentation to indicate program structure defines an rule that specifies that the that just contains the phrases first symbol must contain the entire phrase except possibly for this rule requires that all the tokens in a particular nonterminal be at a column that is at least as far right ie in the as the column of the first token the for is similar to the for that ignores the rule except that we annotate each production of the with appropriate indentation relations as an example consider the productions in figure where we have applied the rule to only the righthand side of where clauses note that the productions for expr are created automatically from the productions for expr as specified in section we do likewise for the terminals using this grammar to parse the expression x v where x y z w results in the parse tree in figure for productions that do not involve the rule such as the productions for addition and negation we annotate the nonterminals with and the terminals with this means that these productions do not change the current indentation and terminals are allowed at any column greater than or equal to the current indentation for example the expressions for x v y z and all the variable references are all at the same indentation as their respective parents for those expressions no special indentation rule is in effect and we simply use to propagate the indentation from parent to child the terminals use so they can be at that or any greater indentation if a nonterminal is too far left eg if w was at column then the constraint is violated and the code would be rejected this is a common pattern that we will see in other grammars as well next consider forms that involve the rule a nonterminal a should trigger the rule we simply use a instead of a an example is the righthand side of a where clause where we use expr instead of expr because we use instead of the righthand side is allowed to be at a greater indentation than its parent we see this in the example parse tree where the righthand side of the where clause has an indentation of while its parent has an indentation of if the toplevel expr were at indentation however such a parse with a righthand side at indentation would be rejected we also use expr instead of expr so that the first token of the righthand side of the where clause has the same indentation as the entire righthand side as a consequence in the example parse tree the on the path from the righthand side of the where to the are all exactly finally since expressions are from the indentation constraints of the surrounding code the production for expressions uses expr instead of expr this it as both and we adopt the consistent with the rule from is not clear about whether his rule applies to all syntactic forms his examples imply that it does not for the sake of example we also simplify where and omit the multiple bindings case that case uses the same techniques as haskells statement blocks of course the productions generated for the terminals and where are unreachable from the rest of the grammar and can be omitted productions written by the user expr expr where id expr expr expr expr expr expr expr expr expr id productions added by expr expr where id expr expr expr expr expr expr expr expr expr id where where id id figure productions for expr expr where idx expr expr expr expr expr idx expr expr expr expr figure parse tree for the indentation of the expression inside the parentheses from any indentation constraints coming from the context of the expression this is used in the example parse tree where the y z expression has an indentation of even though the y z expression has an indentation of uses of the rule inside the parentheses still have effect of course the language uses the same rule as except for two differences the first is that expressions inside parentheses are subject to indentation constraints imposed by the context outside the parentheses the production for expressions thus uses instead of and is simply expr expr the second difference is that the language specification the notational convention that for any nonterminal x x means that x is followed by an optional and is subject to the rule so that every token of x must lie below or to the right of the first provided the layout makes it clear where x terminates the may be omitted turner § this notation is easily handled by introducing for each nonterminal a the nonterminal a and the two productions a a and a a l l ts if m n l ms if n m l ms l ts ms l l ts if n m l l ts n if n l ms l ms l ts ms l ts ms l ts ms l ts ms l ts ms l t ts l ms if m and l t ts ms t l ts ms l l l ms if m figure haskells l function ed § haskell language haskell uses a more sophisticated rule than does blocks eg the bodies of do case or where expressions are made up of one or more statements or clauses that not only are relative to the surrounding code but also are to the same column as each other thus lines that are more than the block continue the current clause lines that are at the same indentation as the block start a new clause and lines that are less than the block are not part of the block in addition and and can explicitly separate clauses and blocks respectively explicitly delimited blocks are from indentation restrictions arising from the surrounding code while the indentation rules of haskell are intuitive to use in practice the way that they are formally expressed in the haskell language specification ed § is not nearly so intuitive the indentation rules are specified in terms of both the and an extra pass between the and the parser roughly speaking the inserts special n tokens where a new block might start and special n tokens where a new clause within a block might start the extra pass then translates these tokens into explicit and the special tokens are inserted according to the following rules ­ if a let where do or of keyword is not followed by the the token n is inserted after the keyword where n is the indentation of the next if there is one or if the end of file has been reached ­ if the first of a module is not or module then it is by n where n is the indentation of the ­ where the start of a is only by white space on the same line this is by n where n is the indentation of the provided that it is not as a consequence of the first two rules by n ed § between the and the parser an indentation resolution pass converts the stream into a stream that uses explicit and to clauses and blocks the stream of tokens from this pass is defined to be l tokens where tokens is the stream of tokens from the and l is the function in figure thus the contextfree grammar has to deal with only and it does not deal with layout this l function is fairly but the key clauses are the ones dealing with n and n after a let where do or of keyword the inserts a n token if n is a greater indentation than the current indentation then the first clause for n executes case case exp of explicitly delimited blocks blocks clause sequences figure productions for case an open is inserted and the indentation n is pushed on the second argument to l ie the stack of if a line starts at the same indentation as the top of the stack then the first clause for n executes and a is inserted to start a new clause if it starts at a smaller indentation then the second clause for n executes and a close is inserted to close the block started by the inserted open finally if the line is at a greater indentation then the third clause executes no extra token is inserted and the line is a continuation of the current clause the effect of all this is that and tokens are inserted layout indicates that blocks start new clauses begin or blocks end respectively the other clauses in l handle a variety of other edge cases and scenarios note that l uses to signal a parse error but uses as an oracle that the future behavior of the parser that runs after l specifically if the tokens generated so far by l together with the next token t represent an invalid prefix of the haskell grammar and the tokens generated so far by l followed by the token represent a valid prefix of the haskell grammar then is true ed § this handles code such as let x do f g in x where the block starting after the do needs to be terminated before the in this requires knowledge about the parse structure in order to be handled properly and thus is used to query the parser for this information in addition to the operational nature of this definition the use of the predicate means that l cannot run as an independent pass its execution must interact with the parser in fact the haskell implementations ghc ghc and jones do not use a separate pass for l instead the and parser share state consisting of a stack of the parser accounts for the behavior of by making close optional in the grammar and appropriately the indentation stack when are omitted the protocol relies on some complicated interactions between the and parser jones and is to use while the parser in section we found that even minor changes to the error propagation of the parser affected whether syntactically correct programs were accepted by this style of parser while we may believe the correctness of these parsers based on their many years of use and testing the significant and fundamental structural differences between their implementation and the language specification are grammar haskells layout rule is more complicated than those of and but is also easily specified as an by using an there is no need for an intermediate l function and the and parser can be separated into passes the functionality of is simply implicit in the structure of the grammar figure shows example productions for case expressions for productions that do not change the indentation we annotate nonterminals with a default indentation relation of and terminals with a default indentation relation of we use instead of because haskell distinguishes tokens that are at an indentation equal to the current indentation from tokens that are at a strictly greater indentation the former start a new clause while the latter continue the current clause in haskell a block can be delimited by either explicit or use of the layout rule in figure this is reflected by the two different productions for if expands to then the relation allows to not respect the indentation constraints from the surrounding code since haskells layout rule allows closing to occur at any column we use instead of the usual on on the other hand if expands to then the relation increases the indentation in the productions for the use of instead of ensures that the first tokens of the all to the same column note that within an each must be separated by a thus because refers to instead of each instance of can be separated using either layout or a when using to explicitly a block must always be used other forms that use the layout rule follow the same general pattern as case with only minor variation to account for base cases eg let uses decl in place of and structures eg a do block is a sequence of stmt ending in an exp a of haskells layout rule is that tokens on the same line as but after a closing may not have to respect the current indentation this is because the l function considers the indentation of only the first token of a line ie where n is inserted and tokens after a let where do or of keyword ie where n is inserted one might view this as an of how the language specification uses l to define layout but this aspect of haskells layout rule is still expressible by having the annotate tokens whose indentation is to be ignored with an indentation of since terminals have an indentation relation of the infinite indentation of these tokens will always match we have the handle this instead of the parser because it is the linear order of tokens instead of the structure of the syntax that what tokens are indentation sensitive for example the token after the do keyword is indentation sensitive regardless of the structure of the expression following the do this requires the to maintain a bit of extra state indicating whether we are at the start of a line or after a let where do or of keyword but this is a fairly light requirement as the is already tracking state to determine the column of each token finally ghc also supports an alternative indentation rule that is enabled by the extension it allows opening to be at any column regardless of the current indentation ghc § this is easily implemented by changing the first production for to be this assumes no tokens are at column which we for this purpose of course column information for error should still use the actual position of the token python language python represents a different approach to specifying indentation sensitivity it is explicitly line oriented and features in its grammar as a terminal that statements the grammar uses and tokens to forms an token is by the whenever the start of a line is at a strictly greater indentation than the previous line matching tokens are when a line starts at a indentation in python indentation is used only to statements and there are no forms for expressions this combined with the simple layout rules would seem to make parsing python much simpler than for haskell but python has line joining rules that normally each new line of python code starts a new statement if however the preceding line ends in a then the current line is with the preceding line and is a continuation of the preceding line in addition tokens on this line are treated as if they had the same indentation as the itself explicit line joining rule is simple enough to implement directly in the but python also has an implicit line joining rule specifically expressions in parentheses square brackets or can be split over more than one physical line without using the indentation of the continuation lines is not important python § this means that and tokens must not be by the between for example the second line of the following code should not emit an and the indentation of the third line should be compared to the indentation of the first line instead of the second line x y z thus while the simplicity of indentation rules is they contain hidden complexity that requires interleaving the execution of the and parser grammar though specification presents its indentation rules quite differently from haskells specification once we translate it to an it shares many with that of haskell the still needs to produce tokens but it does not produce or tokens as with haskell we start with a grammar where the nonterminals and terminals are annotated with indentation relations of and respectively in python the only form that changes indentation is the suite nonterminal which represents a block of statements contained inside a compound statement for example one of the productions for while is while test suite a suite has two forms the first is for a statement and is the same as with the standard python grammar the second is for statements the following productions handle both of these two cases suite suite block block block statement block statement when a suite is of the form ie using the second production the initial token ensures that the suite is on a separate line from the preceding header the block inside a suite must then be at some indentation greater than the current indentation such a block is a sequence of statement forms that all start with their first token at the same column in grammar the productions for statement already include a terminating so is not needed in the productions for block for implicit line joining we employ the same trick as for expressions in and in haskell for any production that contains parentheses square brackets or we annotate the part contained in the with the indentation relation since the final is also allowed to appear at any column we annotate it with for example one of the productions for list construction becomes atom there remain a few with line joining rules that we must address first as with haskell tokens after a closing can appear at any column for example the following code is according to rules while true x to handle this we use the same trick as for haskell and annotate tokens that are not at the start of a line with an infinite indentation second while a based on regular expressions can detect the start of a line and thus produce finite for the first token of a line but infinite for other tokens it cannot detect matching parentheses to determine that tokens should be omitted inside delimited forms thus nonterminals that occur inside delimited forms need to allow the insertion of tokens at arbitrary locations this may mean there have to be two forms of a nonterminal ie for expressions inside versus outside a delimited form but this is a fairly mechanical transformation that can be automated by the use of syntactic sugar similar to the syntactic sugar for a alternatively it may be possible to use a grammar that does not use tokens at all and instead like for haskell uses vertical alignment to statements finally as with the standard python parser the still handles the explicit line joining that is by a line ending in a it gives the tokens of an explicitly line the same indentation as the itself and the is not as a token conventions and syntactic sugar in an every symbol in every production must be annotated with an indentation relation in many languages however productions often allow terminals to appear at any indentation greater than the current indentation but do not themselves change the current indentation thus we can simplify the job of writing an by the convention that if a symbol on the righthand side of a production is not explicitly annotated with an indentation relation then it implicitly to if it is a nonterminal and if it is a terminal for example with this convention the only productions in figure that need explicit annotations are those for all other productions simply use the using this convention most productions in a grammar do not have to be annotated with indentation relations they thus look like ordinary productions and only the forms that explicitly deal with indentation must be explicitly annotated in addition just as often allow the use of alternation or kleene to simplify writing grammars it is often convenient to allow symbols on the righthand side of a production to be annotated with a composition of indentation relations thus we might write a c instead of the more a b b c these conventions are merely notational and do not affect the fundamental theory grammars the formalism for that this paper proposes is an extension of thus to review the standard definition of recall that a grammar is a g n s where n is a finite set of nonterminal symbols is a finite set of terminal symbols is a finite production relation and s n is the start symbol the relation is a subset of n × n and we write a xx · · · xn for a tuple a xx · · · xn that is an element of as a notational convention let a b c be elements of n let a b c be elements of and let x y z be elements of n let u v w be elements of n and u v w be elements of we define a rewrite relation n such that u av u xx · · · iff a xx · · · xn we define as the reflexive transitive closure of the language recognized by a grammar is then defined as l g w s w and is the set of words reachable by the rewrite relation from the start symbol an is also a g n s except that and s account for s is an element of n × n and records the indentation of the initial nonterminal the production relation is an element of n × n × i where i is the domain of indentation relations and each indentation relation is a subset of n × n in principle these indentation relations can be any subset of n × n but for our purposes we restrict i to the relations and here and in the remainder of this paper we restrict ourselves to finite but everything generalizes straightforwardly to languages with infinite as a notational convention let i j and l be and be an indentation relation for the sake of we adopt the notations xi and x respectively for a pair of x and either an indentation i or an indentation relation thus we write a x x · · · for a tuple a x x · · · xn n that is an element of as with we define a rewrite relation n × n × n × n where u u xj xj · · · v iff a x x · · · and j i j i · · · jn n i the relation the language l g derivations and parse trees are all defined as with except that they are in terms of this new rewrite relation note that every is as an by translating every production a xx · · · xn to a xx · · · xn and every word aa · · · am to ai ai · · · with arbitrary i i · · · im n conversely the and indentation relations in an results in an note that translating from an to an will not introduce but translating from an to an might parsing of course a grammar is not practically useful if we cannot effectively parse with it in this section we show how to modify traditional parsing techniques for to handle we show this for both and lrk parsing this can also be done for and but we do not present those here as they are straightforward once the techniques for lrk parsing are understood in order to derive and lrk parsing algorithms we first prove a number of basic properties about indentation relations and section then we model by using infinite section next we consider traditional rewrite systems section and parsing algorithms section applied to this infinite finally we factor out the parts of these constructions representing so that these algorithms can be expressed finitely sections and and discuss some practical efficiency considerations section the key insights here are first expressing the semantics of an in terms of an infinite and second factoring the representation of item sets into a finite representation basic properties there are a few technical definitions and properties that we will use in our parsing algorithms we present these without discussion definition a nonterminal a is if ai for all i lemma composition of indentation relations every finite sequence of compositions of elements from i is one of n or n for some n proof is a left and right identity under composition is a left under composition the compositions of with and with are both lemma closure of indentation relations the closure of i under finite sequences of composition and either finite or infinite sets of unions is the set of unions of one or more of n and m for some n m where each of these is in the union only once we call this closure and as a notational convention let ¯ be an element of proof by lemma every finite composition is of the form n or m since nn if n n and mm if m m at most one occurrence of n and one occurrence of m needs to be in the union lemma of unique if ai w then the set of all i such that ai w using the same sequence of productions is either the set n a singleton or the upper bounded set i i n for some n n furthermore if it is a singleton or upper bounded set then the maximum indentation is limited to be at most the maximum indentation in w proof consider the derivation as a parse tree each edge can be annotated with the indentation relation between parent and child nodes the relation between the indentation of the root ai and each leaf aj is then a composition of the edges in the path from ai to aj the possible values of i are the values compatible with every leaf indentation and the roots relation to them by lemma every such relation is one of p or q and for a particular leaf the compatible root are thus are either n a singleton or i i m for some m n the intersection of these over all the leaves in the parse tree is thus either the set n a singleton or i i n for some n n lemma of ambiguous if ai w then the set of all i such that ai w using any sequence of productions is either the set n or a finite subset of n moreover the finite subsets of n are bounded by the maximum indentation in w proof by lemma and the union over all translating to infinite the first step of our approach is to model the by an infinite of course we do not actually compute with this infinite grammar but it provides a mathematical model from which we derive a computable parsing algorithm given an g n s this is g n s where n n × n × n ai xj xj · · · a x x · · · i j j · · · jn n j i j i · · · jn n i s s this grammar has an infinite number of nonterminals terminals and productions per nonterminal but we still limit derivations to finite lengths note that traditional parsing algorithms on this grammar may not terminate due to the infinite size of g so we formally model g as the limit of successive approximations where each approximation bounds the maximum indentation in any nonterminal terminal or production to greater values we over this detail in the remainder of this paper lemma equivalence s w for g iff s w for g proof by induction on the number of reductions and the fact that for all w and w w w in g iff w w in g rewrite system in this subsection we consider lrk parsing in terms of a rewrite system that specifies what it means for a parser to be lrk in later we derive more conventional parsing algorithms in this development we closely follow the original presentation of lrk parsing by knuth with only minor changes to use current notational conventions recall that an lrk parser is one that always produces a rightmost derivation and a rightmost derivation is one in which the rightmost nonterminal is always expanded before any other nonterminals the symbols resulting from such an expansion step are called the handle for example if s u xj v u yl · · · v w is a rightmost derivation then a handle of u yl · · · v is yl · · · note that in order for this to be a rightmost derivation v necessarily contains only elements of though u and yl · · · may contain elements of both and n since an lrk parser works from the result of a rightmost derivation back to the start symbol lrk parsing can be accomplished by iteratively searching for the handle of a string and performing the appropriate reduction again following knuth given the infinite g n s we construct the and thus regular grammar g n n s for prefixes that end in a handle here the nonterminals are n ai aj aj · · · ai n aj aj · · · and represent the part of the string that contains the handle the aj aj · · · track the k terminals expected after the handle and are the lookahead for each ai xj · · · x jm m · · · in and each u al al · · · we include the following in ai u xj · · · u ai u xj · · · x jm m v for each v hk · · · u here u and v are the expected by the parser hk w computes such by computing the prefixes of l w and is defined as hk w al al · · · w al al · · · u where the reduction relation is for g the intuition here is that the first production expands to the handle along with a lookahead string and the second production expands to an intermediate nonterminal that in turn eventually expands to the handle since this grammar is regular it can be implemented by a state machine which leads to the following rewrite based algorithm for parsing algorithm given input string w if s w then stop and accept the string otherwise find all prefixes of w that match the regular language l g if there are no such matches then reject the string otherwise nondeterministically choose one of the matches and let the last production of the match be ai u xj xj · · · u replace this occurrence of xj xj · · · in w with ai as it is a handle of w and repeat this algorithm with the new value of w note that this algorithm is nondeterministic and accepts the word if any path through the algorithm accepts the word we allow this because productions in g eg a b and a c may produce multiple productions when translated to g eg all ai bj and ai ck such that k i these may introduce in g even when there are no in g once we convert to a finite version of the parsing algorithm we will eliminate this nondeterminism parsing with stacks of course rewriting the entire string and the automaton from the start as done in algorithm is inefficient instead we can save a trace of the states visited when a handle is reduced we to the state just before the first symbol of the handle and proceed from there this is the essential idea behind the traditional lrk parser development by knuth we apply this idea to our infinite to obtain the following construction we begin with the notion of an item we denote an item by ai xj · · · · x jm m · · · u where ai xj · · · is a production in g and u k is the lookahead the algorithm maintains a stack of sets of items ss · · · sn where sn is the top element of the stack we use the notation ss · · · sn aa · · · to denote that ss · · · sn is the current stack and aa · · · is the input remaining to be consumed by the parser to parse a word w we start with the configuration s w i i · · · ki where s s · · · k we let s be a fresh nonterminal and · · · k be fresh terminals that pad the string to have at least k tokens of lookahead we then run the following parsing algorithm algorithm given configuration ss · · · sn ai ai · · · w if s u sn and ai ai · · · w i i · · · ik then accept otherwise compute the closure s of sn where s is the least set of items satisfying the recurrence s sn x jm m · · · v ai xj · · · · x jm m · · · u sn x jm m yl · · · v hk x jm m · · · u compute the acceptable lookahead set k where k v ai xj · · · · x jm m · · · u s v hk x jm m · · · u for each production ai xj · · · in compute the acceptable lookahead set k ai xj · · · where k ai xj · · · u ai xj · · · · u s let o s zl ai xj · · · x jm m · x jm m · · · v ai xj · · · · x jm m m · · · u s x jm m zl and nondeterministically choose one of the following a if ai ai · · · k then do a shift action by looping back to the start of the algorithm with the new configuration ss · · · o sn ai ai · · · w b if ai ai · · · k ai xj · · · for some production ai xj · · · then do a reduce action by looping back to the start of the algorithm with the new con ss · · · o ai ai ai · · · w finite representations of stacks algorithm contains both nondeterminism and infinite sets here we from knuth in order to eliminate these up to this point our parser is simply a standard lrk parser on an infinite and we rely on the correctness of the standard lrk parsing algorithm for our correctness from here forward we ensure correctness by ensuring that our modified version of the algorithm models the same item sets as algorithm using a more efficient representation as a first step consider the sets of items that form the stack each item is of the form ai xj · · · · x jm m · · · u where ai n × n xj · · · n × n and u × nk observe that the to the left of the j · · · jm do not effect the parsing process and multiple items that differ only in the values of j · · · jm can therefore be represented by a single item this reduces the state space slightly but we can go further and also factor out jm · · · jn by observing that the algorithm preserves the following completeness property for item sets definition completeness we say that an item set s is complete if for every a x · · · ai xj · ·· · x jm m ··· u s implies that s ai xj · · · · x jm m · · · u jm · · · jn n jm m i · · · jn n i this property is preserved by each loop through algorithm as stated in the following lemma lemma if every item set on the stack is complete at the start of a loop through algorithm then every item set on the new stack at the start of the next loop is also complete proof for every production xm y · · · if the sure step adds the item x jm m · · · v then by con it adds all items of the form x jm m · · · v where l jm · · · lp jm thus this step of the algorithm preserves completeness the o operation filters the set of items by requiring that x jm m zl but x jm m is moved to the left of the and is therefore no longer relevant to the completeness of the item set since jm is related to jm · · · jn only indirectly through i the remaining jm · · · jn are complete given the i that remain in the item set since the item sets in the stack are all complete we no longer need to represent the individual j · · · jn the only we need to record are i the indentation of the nonterminal on the lefthand side of the production and the in u the expected lookahead thus we can represent items that differ only in the values of j · · · jn with a x · · · · x m m · ·· l where a x · · · and l n × × nk we call l the set each element of l is a pair of i the indentation for a and u the lookahead word with this factoring we can implement a parser by letting k and translating algorithm to use this representation of item sets since k the lookahead is always the empty string and l is simply a set of by examining the algorithm we can further determine that this set will always be either the set n a finite subset of n or the union of a finite subset of n with the set of all elements of n greater than j for some j n these sets are all finitely representable and thus computable finally the standard technique of the possible item sets and the transitions between them can be used to construct a state machine for a pushdown automaton that g during this elaboration we keep the set of l abstract this ensures that there are only finitely many item sets to be at runtime both the current state and the stack elements then simply store a reference to one of these item sets along with a concrete indentation set any nondeterminism remaining in the algorithm is handled using the standard stack representation used by parsers parsing lrk grammars after having the representation of the item sets this far we eliminate the nondeterminism in the algorithm by restricting the algorithm to only lrk grammars recall that an lrk grammar is defined to have a unique rightmost derivation for any given word thus there is always a unique handle at each parsing step and thus in the nondeterministic choice at the end of algorithm there is never more than one allowed choice otherwise we have a or a conflict and the grammar is not an lrk grammar with the original representation of item sets we did not apply this criterion because there might be multiple reductions that differ only in their for example if we have a b in g then both a b and a b are in g these could lead to spurious conflicts however now that items are identified in terms of productions from eg a b instead of productions from eg a b these conflicts no longer occur any remaining or conflicts reflect a conflict in the original grammar g and are not of the translation to g the last remaining source of ambiguity is the set l which can grow infinitely to resolve this we change the representation of l from being a subset of × nk to being a subset of n along with an element of × × k × we write such an item as a x · · · · x m m · · · i ¯ ¯ a · · · ak this represents the item a x · · · · x m m ··· l where s bi and l i aj · · · i i i ¯ l l ¯ l · · · lk lk j ¯ l j ¯ l · · · jk lk lk i the intuition behind this representation is best understood in terms of the sort of parse tree that could lead to the item that is trying to parse an a with of a · · · ak this situation is depicted in figure note that there are no terminals between any of a or a a · · · ak and in the general case we consider a node to be an ancestor of itself so some of cl cl · · · or bi may actually be the same node the lookahead token aj is in the lookahead only because a shares with it the ancestor c at indentation l the ¯ and ¯ relations record the possible indentation relations between c and respectively a and aj the second lookahead token aj is in the lookahead only because c the common ancestor of the item and the first lookahead token also shares with a the common ancestor c at indentation l the ¯ and ¯ relations record the possible indentation relations between c and respectively c and a and so on until we reach the final ancestor ck at indentation lk this ancestor has a minimum indentation at which it can occur so we use to record the indentation relation between ck and b the start terminal the lookahead computation hk that is defined in section must of course be modified to account for this representation we omit this because while conceptually simple its formal definition is fairly bi cl cl aj ai aj figure the structure of lookahead tokens in a parse tree with this representation the lookahead set is finitely represented so the only potentially infinite part remaining is the indentation set however as before we can show that these sets are always either the set n a finite subset of n or the union of a finite subset of n with the set of all elements of n greater than j for some j n indentation sets are thus finitely representable and we have completely reduced the parsing algorithm to a finite representation we can now construct an lrk parser just as we constructed the parser at the end of section as before to do this we translate algorithm to use the new item set representation keep the indentation sets abstract while we elaborate the possible item sets to form the states of the pushdown automaton and at runtime augment the automaton states and stack entries with concrete indentation sets correctness of item set representation we must consider carefully the correctness of the parsing algorithm based on the representation given in section at first the representation looks like it could lead to matching when they should not indeed the following grammar of variable references ie id and do blocks with aligned statements shows how this can arise expr id expr do expr expr for example consider the parse of the word do do id id which may come from the code do do x y note that y does not with either the second do or the x and thus this code should be rejected put another way the valid when looking at the id for y but before reducing x to expr are id id do and do the string should thus be rejected since id the token for y is not in that set but the lr lookahead set using the new representation is id do since the current indentation is and there exist l such that l l and l the string will not be immediately rejected this representation thus appears to over approximate the set of for a particular lookahead this means that in the non deterministic choice at the end of algorithm there could be more reductions possible than there should be however as we restrict ourselves to lrk grammars this turns out to not be a problem this is because there are only four cases where these spurious reductions occur case there should be no reductions or shifts possible but the approximation makes one extra reduction possible in this case the parser should reject the program but will instead reduce and continue parsing however this case happens only when some other item set further up the stack also checks the lookahead tokens though the string is not rejected immediately it will be rejected once we reach that point in the stack in our example once x reduces to expr and then do x reduces to an expr that finally reduces to the lookahead set will be id do since the indentation at that point is but the next token is id the parser will reject the program the program might not be rejected as soon as we expect but it is eventually rejected this case may arise even when the grammar is lrk case there should be no shifts or reductions possible but the approximation makes two or more extra reductions possible the representation for in section is designed so that every lookahead word that it represents comes from a valid parse thus if this representation generates multiple possible reductions then there is some string that would also generate those multiple possible reductions with the original representation in algorithm in that case the grammar is not lrk and the grammar should be rejected by the parser generator case there should be one reduction or shift possible but the approximation makes one or more extra reductions possible the same reasoning applies as in the preceding case case there should be two or more reductions or shifts possible then the original grammar is not lrk and the grammar should be rejected by the parser generator this means that the representation in section is valid for any grammar that is lrk and furthermore we can detect when a grammar is not lrk by using this representation an efficiency consideration note that each item in an item set may have a different set of for example we may have an item set containing both of the following two items a i u a i u even if they start with the same indentation set i after reading an a the indentation sets for these items will be different from each other for the first item the indentation set will be restricted to strictly greater than the indentation for a for the second item the will be restricted to equal to that of a thus different items can have different indentation sets and a naive factoring eg sharing i between items in an item set is this does not the possibility of a like the one done with the lookahead sets but we have been unable to find such a factoring that works in all cases nevertheless as a practical matter the following techniques seem to work well observe that we need to keep only the indentation sets for items before the closure is taken items generated by the closure operation can be annotated with the ¯ that can lead to them and this value can be incorporated into the lookahead check in addition when we can determine that some set of items will always have the same indentation set we can represent them using a common parsing time relative to the parser number of nodes in the ast figure benchmark results indentation set these techniques reduce the number of indentation sets that must be passed from one state to another and based on the experience implementing the haskell parser in section the resulting number of such sets is usually one implementation in order to verify the realworld of this parsing technique we modified the parser generator and to support the parsing techniques presented in this paper the parser is instead of lrk but the techniques shown in section generalize straightforwardly to note that this implementation is only a prototype and is only intended for testing the practical feasibility of parsing with in particular no significant effort was put into optimizing the performance of the generated parser the haskell parser from the package et al uses techniques for implementing layout similar to those used by ghc however it is as a parser and this makes it easy to for purposes this parser was modified to use an instead of using shared state between the and parser both the modified and versions were then run on the source files from the base package two modules and could not be due to missing header files of the remaining haskell modules cannot be parsed by the parser due to syntactic extensions such as rank types that are not supported by this left source files that are by the parser all of these files parsed and produced the same parse tree when parsed using the based parser figure shows the parsing times of the modified parser relative to the parser when run on these files these benchmarks were compiled using ghc version with the o and flags and were run on a bit running with gb of ram timing measurements were collected using criterion version with samples per benchmark note that the parser is designed to run both the and the parser simultaneously so they can share information about it is difficult to separate the execution of the parser from the execution of the so the time is included in the times for both that parser and the based one as expected the based parser runs in approximately linear time it is on average times slower than the parser there is a slight upward in the factor by which the based parser is slower than the parser this is primarily due to the fact that we are the ratio between the performance of the modified and parsers and the parser has performance overheads that are more significant on small inputs given that this is a prototype implementation with little optimization the fact that the version is only one to three times slower than the standard parser is promising this overhead is likely due to the manipulation of the indentation sets as the representation of indentation sets is naive since in practice only certain sorts of sets are common eg and the set n an improved version could optimize for these sorts of sets in addition we could take advantage of the tokens with an indentation of by adding a fast path through the parser that short circuits the indentation computations related work the parser library and the and extensions to the and parser library provide support for parsing to the best of our knowledge there is no published formal theory for the sort of indentation that these parsers implement they are all topdown parsers and use some variation of state through a parser monad to track the current indentation describes an approach to parsing languages that is based on the token stream this idea is further developed by and in both cases the layout combinator searches the token stream for appropriately tokens and passes only those tokens to the combinator for the expression to which the layout rule applies as each use of layout the remaining tokens in the input this can lead to quadratic running time given that the layout combinator filters tokens before parsing occurs this technique also cannot support subexpressions such as expressions in python that are from layout constraints thus this approach is of expressing many realworld languages including haskell and python et al propose a method of parsing languages by effectively the parse trees generated by a parser the parser generates all possible parse trees of layout indentation constraints on each parse node then remove the trees that violate the layout rules for performance reasons this is interleaved with the execution of the parser when possible aside from the fact that they require a parser and thus generate parse trees that might not be used a critical difference between their system and the one presented in this paper is that their indentation constraints are in terms of the set of tokens under a nonterminal whereas the system in this paper uses constraints between nonterminals and their immediate children thus the two approaches look at the problem from different et al do not consider the question of an lrk parser and take a unique approach to specifying the aspects of a language they use a grammar that uses individual characters as tokens and has nonterminals that take an integer counter as parameter this integer is through the grammar and eventually specifies the number of spaces that must occur within certain productions the grammar encodes the indentation rules of the language by carefully how this parameter is through the grammar and thus how many characters should occur at each point in the grammar while encoding indentation sensitivity this way is formally precise it comes at a cost the specification et al uses the approach proposed by and and as a result has about a and a half different nonterminals for various sorts of and comments with this encoding the grammar cannot use a separate and must be each possible occurrence of must be explicit in the grammar and the grammar must carefully track which nonterminals produce or expect what sorts of the authors of the grammar establish naming conventions for nonterminals that help this but the result is still a grammar that is difficult to and even more difficult to modify while this approach some similarity to the technique proposed in this paper a key difference is that their method uses the parameters of nonterminals to generate explicit characters and thus a significant overhead in the design of the grammar on the other hand the system presented in this paper operates at a higher level using the parameter to indicate the column or indentation at which nonterminals and terminals should occur this is a subtle distinction but it has a impact as shown in section layout rules are simple to encode this way and as shown in section this formalism is amenable to traditional parsing techniques such as lrk parsing note that none of the systems above present an lrk parsing algorithm they use either topdown parsers or in the case of et al a parser conclusion this paper presents a formalism for languages it is both expressive and easy to use we derive provably correct and lrk parsers for this formalism though not shown here and parsers can also be constructed by appropriately using the key technique of factoring item sets experiments on a haskell parser using this formalism show that the parser runs between one and three times slower than a parser using traditional ad hoc techniques for handling indentation sensitivity improvements in the handling of indentation sets may reduce this overhead using these techniques the layout rules of a wide variety of languages can be expressed easily and parsed effectively acknowledgments feedback from andrew r tim mark p jones and the anonymous improve the presentation of this paper references base version june url version may url http and net language version rd edition october url http and indentation sensitive languages unpublished manuscript july url a derivatives of regular expressions journal of the acm jacm ­ october doi and generalized parsing in software language engineering lecture notes in computer science springer berlin url to appear the glasgow haskell compilation system users guide version the ghc team august url david specification january url john syntax url on june michael ed curry an integrated functional logic language version technical report march url project the programming language the revised preliminary report november url graham higherorder functions for parsing journal of functional programming ­ july doi s graham and monadic parser combinators technical report department of computer science university of limited programming manual prenticehall international series in computer science prenticehall international isbn mark p jones the implementation of the functional programming system research report yale university new usa may e knuth on the translation of languages from left to right information and control ­ december doi s p version january url http p j the next programming languages communications of the acm ­ march doi and version june url simon and user guide url http for version simon and version november url simon ed haskell language report april url syntax may url python the python language reference url on june s version august url http et al the f language specification microsoft corporation april url updated april efficient parsing for natural language a fast algorithm for practical systems international series in engineering and computer science academic isbn d a turner system manual research software limited url philip wadler an introduction to technical report programming research group at oxford university 