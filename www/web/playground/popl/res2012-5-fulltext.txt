higherorder functional reactive programming in bounded space r benton microsoft research jan yale university abstract functional reactive programming is an elegant and successful approach to programming reactive systems the high levels of abstraction and expressivity that make as a programming model do however often lead to programs whose resource usage is and hard to predict in this paper we address the problem of space leaks in functional reactive programs we present a functional reactive programming language that statically bounds the size of the dataflow graph a reactive program creates while still use of higherorder functions and streams such as streams of streams we achieve this with a novel linear type theory that both allocation and ensures that all recursive definitions are wellfounded we also give a denotational semantics for our language by combining recent work on metric spaces for the interpretation of higherorder functions with models of computation the resulting category is closed and hence forms a model of the logic of implications categories and subject descriptors d dataflow languages general terms languages design theory keywords functional reactive programming dataflow computation linear logic implications introduction reactive systems in an interaction with their environment input events and producing corresponding output events examples of such systems range from embedded and networks up to complex graphical user interfaces web applications games and simulations programming reactive systems in a generalpurpose imperative language can be as different parts of the program interact not by structured control flow but by dynamically callback functions with one another the complexity of writing and reasoning about programs written in such a higherorder imperative style as well as the critical nature and resource requirements of many reactive systems has inspired extensive re permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ pa usa copyright c acm search into domainspecific languages libraries and analysis techniques for reactive programming synchronous dataflow languages such as esterel and implement a domainspecific computational model deriving from kahn networks a program corresponds to a fixed network of nodes that communicate with one another each and producing a number of primitive values at every clock tick synchronous languages have precise semantics provide strong guarantees about bounded usage of space and time and are widely used in applications such as hardware synthesis and embedded control software functional reactive programming as introduced by and hudak also works with values rather than mutable state as a primitive abstraction but provides a much richer model than the synchronous languages signals behaviours can vary as well as values can be higherorder including both firstclass functions and signals and the overall structure of the system can change dynamically has been applied in problem domains including games web applications and however the expressivity and simple semantics of the classic model come at a price the intuitively idea of modelling signals as elements of the stream type a or in the continuous case ar and reactive systems as stream functions input output does not rule out systems that violate causality the output can depend upon the input or feedback can lead to undefined behaviour secondly as the model is highly expressive and abstracts entirely from resource usage the time and space behaviour of programs is hard to predict and even with sophisticated implementation techniques can often be it is all too easy to write programs with significant space leaks caused by for example the entire history of a signal subsequent research has to reduce and performance problems by restrictions on the classic model the yale haskell groups for example is an embedded for that constructs signal processing networks using arrow abstraction signals are no longer firstclass and functions must be built from wellbehaved primitives by combinators allows signals to carry complex values but is essentially firstorder there is no exponential at the level of signal functions though certain forms of are allowed via built in switching combinators does not enforce closely related are time leaks which occur when sampling a value can invoke an arbitrarily computation to catch up with the current time ity or provide resource guarantees but at least makes certain kinds of leaks less likely and benton recently described a semantic model for higherorder functional reactive programs based on spaces identifying functions with maps and interpreting wellfounded feedback via fixpoint theorem they gave an associated language a temporal modality for wellfounded recursion and showed the correctness of an implementation using an dataflow graph this implementation is much more efficient than directly running the functional semantics but nothing prevents the dataflow graph from growing as a program executes leading to space leaks in this paper we solve the problem of such leaks by extending the approach to with resources that represent the permission to perform following the pattern of work on computation we give a denotational model for bounded higherorder reactive programming in terms of complete length spaces which carry both an distance measure and a size function maps between such spaces must be and intuitively the metric is used to enforce good temporal behaviour causality and of recursive definitions the size measure enforces good spatial behaviour bounding the number of cells in the dataflow graph the category of complete length spaces is forming a model of the logic of implications and a perhaps surprising connection between the type theory of stream programming and separation logic we define a term language with a rather novel type theory that corresponds to our model and allows us to write bounded reactive programs judgements are all with the successor operation on times in a modality terms are typed in three contexts one carrying linear actually affine resources of type giving permission to allocate one binding pure variables and one binding potentially variables is via a a modality in the style of linear logic we give the language an interesting staged operational semantics which the normalizing reduction that takes place within each time step from the transitions that take place when the clock advances and show that this is soundly modelled in the denotational semantics the operational semantics uses terms of the language itself to encode the heap context within which evaluation takes place we also give a number of examples in our language that illustrate properties of the model and the applicability of our approach showing that one can work with higherorder functions and streams in a natural way while still ensuring causality and bounded space usage to improve readability we the logical order of presentation section gives an informal account of the language that suffices for presenting some of the motivating examples section formally defines the language and the type system we then in section define the operational semantics and in section and present the details of the denotational model finally in section we discuss our work and relate it to existing research programming language the language is essentially a simplytyped calculus with a type constructor s for infinite streams extended with three nonstandard notions delay types resource types and pure types we treat streams as much as possible as mathematical sequences but want to ensure that we can also interpret them as the successive values of signals generated by implementable systems thus a definition in a generic functional syntax for now t t t t t figure memory usage of streams n sn n n denotes a infinite stream but can also be understood as a stateful process out successive natural numbers as time advances it is necessary to restrict recursive definitions to ensure that signals are welldefined at all times the recursion above is clearly guarded the recursive call to only occurs a cons constructor so unfolding the stream at each clock tick is that is we always discover at least one new cons constructor which we can examine to find the head and the tail of the stream at the current time however simple syntactic checks used by languages as as agda and coq do not integrate well with higherorder for example one might want a stream functional that abstracts over the constructor higher order f v fv higher order f v the of higher order now depends on the definition of f which is an unknown parameter as in our earlier work we instead use a modality to track the times at which values are available in their types a value of type is a computation that will yield a value of type a when executed on the next clock tick the tail function has type tail sa expressing that the tail of a stream only becomes available in the future similarly the type of cons is refined to cons a × sa capturing that streams are constructed from a value and a stream by giving the fixed point combinator the type fix a a we ensure that all recursive definitions are wellfounded without restricting their syntactic form if we care about space usage however this use of types to track still admits too many programs the problem is to limit the amount of data that must be to carry it from one time tick to the next in the case of above it is clear that the current state of the counting process can always be held in a single natural number but consider a similar definition at a higher type leak sa ssa leak xs leak xs the call leak xs yields a stream of streams which is xs this is a wellfounded functional definition but as a stateful process requires the whole history of xs to be so it can be pushed forward on each time step figure shows the evolution of a stream as time passes the gray nodes denote the nodes already produced the nodes show the current value of the head of the stream and the white nodes mark the elements yet to be produced at each time step one node moves into the past becomes gray and the current head advances one step into the stream as leak xs a reference to its argument it needs to buffer all of the gray nodes to correctly enumerate the elements of the streams to be produced in future running leak xs for n time steps thus requires on space which is to see this more clearly consider the following function f sa ssa n n sa f xs n m let x xs head xs tail xs in let ys head tail in if n then f head m m else f xs n m sa sa xs f xs leak xs now yields the prefixes of as each prefix appears infinitely often the whole history of the initial stream must be saved as the program executes there are definitions with the same type as leak that can be implemented in constant space sa ssa xs tail xs since returns the successive of its stream argument we do not need to remember gray nodes see figure and hence can implement the function without any substituting for leak turns into the identity to account for the memory usage associated with creating and stream data we adapt a variant of the linear affine resource types of the type represents a permission to create one new stream the tensor product r s is the permission to do both r and s and the linear function space r a builds an a the resources in r we further refine the construction of streams of type sa to take three arguments using the syntactic form e u e the term u is a permission to allocate a cons cell and the term e a is the head of the stream the tail e is defined in scope of the variable u which the allocation permission that will be up on the next time step we still permit sharing of stream values without restriction since dataflow programs gain efficiency precisely from the ability to share therefore we also support a context of unrestricted variables and an intuitionistic function space a b original language a strictly linear type discipline function closures can also need if they capture streams in their environment so it is useful to introduce the type constructor a which those that need no and may be freely carried forward in time examples our language makes the intuition of bounded resource consumption explicit while remaining close to standard functional programming style we begin with the definition of two classic stream functions and fib in our language n sn fix loop n sn x u let n x in n u loop n u n n sn fix loop n n sn x y u let n x in let m y in n u loop m nm u we do not decompose the intuitionistic function space as a b the function differs from the standard definition in two ways first we include an extra resource argument of type which contains a permission used as the extra argument to the cons operator furthermore we require the argument of the function to be of the modal type n since the variable n is used in both the head and the tail of the we need to know that n can be used at different times without requiring additional space usage this is exactly what the type a allows an expression let a a in binds the modal value a to a variable a which can be used at any current or future time the introduction form e for a constructs a value of type a which may only mention variables the definition of the function is similar similarly we give the definition of the constant function which returns a constant stream of values constant a sa constant fix loop a sa a u let a a in a v loop a v the modal type a in the typing of constant prevents one defining leak in terms of constant since stream values are never as include a resource argument however we can still define functions constructing higherorder streams so long as space usage is bounded in this we improve upon much previous work on efficient implementations of an example is the function that we described earlier in our language this is as follows sa ssa fix sa ssa xs u let xs tail xs in xs u xs u higher type streams also let us define many of the switching combinators of libraries without having to build them in as primitive operations for example switch ssa sa switch let loop fix loop ssa sa sa bs current u let tail in let bs tail bs in if then let zs tail head in u loop bs zs u else let zs tail current in u loop bs zs u in bs u loop bs head u the function switch takes a stream of boolean events and a stream of streams it then yields the elements of the head of the stream of streams until the boolean stream yields true at which point it starts generating the elements of the current stream from the stream of streams in this way it is easy to go beyond simple static dataflow programs without having to programs to fit a fixed set of combinators however with the full resources of a higherorder programming language available it is often convenient to define programs in terms of familiar stream such as map map a b sa sb map h let f h in fix loop sa sb xs u let ys tail xs in f head xs u loop ys u this function illustrates a common pattern of higherorder programming in our language we often wish to use functional arguments at many different times in this case we want to apply the argument to each element of the input stream therefore the functional arguments in higherorder functions often need to be under the modality a b the unfold function provides another nice example of higherorder programming unfold x a × x unfold h let f h in fix loop x sa x u let a d fx in let d in a v loop x v sa using unfold one can directly translate deterministic state machines into stream programs passing in the state transformer function and the initial state as the arguments this function is also the first example with the delay modality our state transformer takes a state and returns a value and the state to use on the next the elimination form let e in takes an expression of type and binds it to a variable y of type a one tick in the future this lets us use it in the third argument to cons since the tail of a stream is also an expression one tick in the future next we illustrate the importance of being able to use streams even as we track resources linearly sa × sb sa × b fix sa × sb sa × b xs ys u let xs tail xs in let ys tail ys in head xs head ys v xs ys v sum sn × sn sn xs ys u v map xs ys u v double sn sn double ns u v ns u v we first define the function which takes two streams and returns a stream of pairs and the function sum which takes two streams of natural numbers and pointwise sums their elements these two functions are then used to define double which takes a stream of numbers and returns a new stream of elements each of which is twice the size of the input note that double works by passing the sum function the same stream in both arguments linearity the map and functions together with which we do not define here witness that is a cartesian functor we can also define maps other semantic properties of streams sa b sa sb g let f g in fix loop sa sb xs u let ys tail xs in f xs u loop ys u flip · sa flip fix flip · sa xs let in let xs tail xs in · let flip xs in u x u f u fix xs u let xs in u let ys tail ys in · ys u the function a function from streams sa to a type b to a function from streams of a to streams of b giving a structure to the functor the flip and functions define an isomorphism between streams of delayed val and delayed streams of values these operations make use of the ability to explicitly delay expressions e until the next tick with the introduction form for in our earlier work we had general delay operators a a which values of any type forward one tick into the fu ture however a given piece of data may represent different val as time passes and so we do not want delay maps of type a sa since this type does not capture the additional storage needed to move the argument forward one step in the future however it is possible in our system to define delay operators with types such as sn which explicitly represent the in the type buffer n sn sn buffer b xs u let y in let head of y be usable later let ys tail xs in ys at time b v buffer y ys v now call buffer at time the buffer function a number to the front of a stream and can be used to construct a delay operator sn xs u let y in let ys tail xs in · buffer y ys u let head of y be usable later tail ys is at time now call buffer at time with y ys this gives a delay operator for streams but additionally for a resource with which to construct the delayed stream the definition illustrates our design that expensive operations should be explicitly we conclude with a traditional example of stream programming the of n bool sn s option n p xs u let n head xs in let ns tail xs in let pred p in if pred n then let q j pred j j mod n in some n v q ns v else none v p ns v sn uv is odd u v the function incrementally constructs a filter predicate that tests each element of the stream for by all the seen so far since the number of is infinite the size of the predicates grows without bound but is nevertheless accepted by our languages type system by design we allow all ordinary callbyvalue functional programs which have reasonable compositional cost semantics and only use typing to track the memory leaks of hence our types only track the size of the dataflow graph ie the number of live cons cells syntax and typing we give the types and syntax of the programming language in figure the types include base types p stream types sa the modality ordinary functions a b the purity modality a and the linear function space r a resources r include the allocation permission and the tensor product r s for space reasons we do not include products a × b or sums a b here since we require to define switching combinators we that this is purely for space reasons there are no technical complications associated with sum types the typing rules are defined in figure the two type judgements of our type theory are t i r and e i a both judgements are in the sense that the type system a term to have a type at a particular time i furthermore each hypothesis in each context is indexed by the time at which they can be used as usual we take contexts to be unordered and implicitly assume to ensure that all variables are distinct the judgement t i r states that in the context of affine resource variables the term t has resource type r at time i the resource terms are built from affine pairs of the ground type and are permissions to allocate one or more cons cells the judgement e i a has three contexts the affine resource context contains again permissions to allocate cons cells the intuitionistic context contains pure hypotheses ie variables in bind values and the intuitionistic context binds arbitrary value types and permits unrestricted sharing and reuse of variables under these three contexts we a term e to be an expression of type a at time i there are only two rules for the affine resource term calculus in figure the rule allows a resource to be used at any time after the context says it is available the tensor rule ri lets one form an affine pair t t the resources in the context between the two components observe that these rules allow weakening but not contraction the rule lets us use a pure hypothesis at any time after the time index in the variable context in contrast the rule only permits using a variable x at exactly its time index in this difference is one of the keys to accurately tracking space usage we may substitute values which require for variables in and by implicit of values across time we ensure that the programmer uses explicit whenever needed the rules i and e introduce and eliminate intuitionistic functions the introduction rule does not permit the body to use any resources since we can call functions multiple times the presence of in the conclusion of i and the other value forms builds in weakening so that we do not have to give a separate structural rule the elimination rule does allow expressions to use resources since we will use a callbyvalue evaluation strategy that will evaluate the two terms using up their resource permissions before substituting a value into a the rules i and e introduce and eliminate linear functions the introduction rule only permits the body to use the resources it receives in the argument since we need to ensure that the function can be safely called multiple times as a result our typing rules do not permit of linear functions r s a r s a even though our underlying semantic model does permit it if our type theory had the contexts of the logic of implications then linear functions would be syntactically expressible however type checking for calculi is still a difficult problem and so in this work we restrict our attention to a linear fragment the rules si and are the introduction and elimination rules for streams the syntactic form const e u e takes three arguments the expression t is a permission to create a cons cell the expression e is the head of the stream and e is the tail of the stream the tail subterm e occurs a binder for the resource variable u the intuition is that each stream takes up one unit of space at each successive time step and u names the permission t after one time step has this lets us pass the permission to use t to functions on subsequent time steps in the body of e the rule is straightforward given a stream of type sa we get a value of type a at the same time the rule uses the form let x in e to bind the tail of e to the variable x in e the tail of a stream at time i at time i and we choose a binding elimination form to maintain the invariant that no term of time i contains any subterms at any earlier time the rules and introduce and eliminate delay terms the rule says that if e is a term of type a at time i then is a term of type at time i like the other value introduction forms it prevents e from using any resources so that e can be substituted freely the rule gives a binding elimination let e in e for the modality we use a binding elimination for the same reason as in the rule we do not want terms of time i to contain subterms of time i the rule i introduces a term of pure type a it does so by typing the body of a term a at type a with an empty resource and shared context since e can only refer to hypotheses in which are pure it follows that e itself must be pure the rule e types the elimination form let x e in e which binds the value e to the variable x in the pure context the rule e is the elimination form for the tensor given a term t of type r s the expression let u v t in e binds the components to the variables u and v for the scope of e the rule let introduces local the introduced binding x e must be at the same time i as the overall expression the rule fix types fixed points fix x a e the body e is typed at time i with the recursive hypothesis x i a one tick later the delay ensures the of recursive definitions furthermore the typing of the expression e is derived under an empty resource context and with an empty shared context since e may unfold multiple times giving e resources would violate linearity furthermore the can happen at different times which means that using any variables in the shared context might require we now state the structural and substitution principles lemma of weakening and contraction if t i r then t i r if e i a then e i a if x i a y i a e i b then x i a i a if x i a y j a e i b and i j then x i a i a theorem substitution we have that if t i r and u i r t j r then j r if t i r and u i r e j a then j a if · · e i a and x j a e k b and i j then k b if · e i a and x i a e j b then j b lemma and theorem can be proved by structural on the type derivations in the respective premises types general a p a a sa · a a r a resource r r r terms general e resource t values v x x a e e e u r e e t const e u e let x in e let e in e e let x e in e let u v t in e fix x a e let x e in e u t t x a e u r e v · e x contexts general · x i a pure · x i a resource · u i r evaluation contexts c let x in c let x v u e in c figure syntax operational semantics theorem the substitution principles so that a general expression e that replaces a variables has to be typed without resource variables that is the substitution is only sound if the substituted term e uses no resource variables on the other hand the typing rule for cons cells demands the use of a resource raising the question what is the operational semantics of cons cells a purely operational semantics cannot be correct because it does not account for the sharing of cons cells consider the following expression that is welltyped in our system let xs in u is the linear allocation permission sum xs xs v here we construct xs once but use it twice in the call to sum we cannot simply substitute the cons into the body of the let in our system as that would duplicate the linear variable u one approach for permissions is to introduce a heap for cons cells and refer to streams indirectly by reference however adding a heap moves us away from our functional and makes it more difficult to connect to our denotational model instead we retain the idea of referring to streams by reference but use variables for the indirect reference by defining evaluation to put terms into form such as let xs e v e in let ys e v e in let xs tail xs in let zs e v e in let ys tail ys in v now the nested act as our heap the value v may contain many references to individual streams such as xs but since each stream is bound only once we can respect the linearity constraint on the allocation permissions ui taking the tail of streams as in the definition xs and ys also needs to be in form since we cannot cut out the tail of a cons cell until t i r e i a u i r i j u j r t i r t i r ri t t i r r x i a i j x j a x i a x i a · x i a x a e i b e i a b i e i a b e i a e e e i b u i r e i a i u r e i r a e i r a t i r e e t i a t i e i a u i e i sa si const e u e i sa e i sa i a e i sa y i sa e i b let y in e i b · e i a i e i x i a e i b let e in e i b · · e i a i e i a e i a x i a e i b e let x e in e i b t i r s u i r v i s e i c e let u v t in e i c · x i a · e i a fix fix x a e i a e i a x i a e i b let let x e in e i b figure typing rules the next tick using bindings to represent sharing will make it easier to continue using our denotational model to interpret the resulting terms the scoping rules for also restrict us to a dag dependency structure an invariant that imperative reactive programming implementations based on dependency graphs must go to some lengths to implement and maintain cons cells has a second benefit we can advance the global clock by taking the of each cons cell in the context let xs in let ys in let xs xs in let zs in let ys ys in v since we know where all of the cons cells are we can rewrite them to model the of time the clock for tail expressions simply the tail intuitively they a tail stream and after the step the binding they refer to contains that tail stream our operational semantics has two phases the operational semantics which puts an expression into form and the step semantics which advances the clock by one tick by rewriting the cons cells to be their operational semantics the syntax of values and evaluation contexts is given in figure and the typing and operations are given in figure we define the reduction relation in figure in bigstep style we write i i c i for the typing judgement the context is a resource context that consists only of hypotheses similar the contexts i are restricted forms of general contexts consisting only of stream variables at time i or i both are defined in figure the judgement i i c i reads as the evaluation context c creates the bindings in i uses the resources in to do so and may refer to the bindings in i the operation c c two evaluation contexts c and c it is defined in figure and satisfies the following properties lemma context concatenation we have that · is associative with unit · if i i c i and i i i c i then i c c i i · if i i c c i then there exist and i i such that and i i i and i i c i and i i i c i these properties all follow from routine in figure we give the context semantics evaluating an expres sion in a context into a value in a larger context note that the value forms for streams are variables since we need to preserve sharing for them and we can use variable names as pointers into the evaluation context for most expression forms the context semantics works as expected it evaluates each subexpression in context building a value in a larger context the rule is one of the two rules that extend the context it evaluates a cons cell creates a binding to a fresh variable and returns the fresh variable as the value for that stream the other rule that extends the context is it adds a binding to the context naming the tail it constructs the rule on the other hand uses the cx v relation that is defined in figure to find the head of the cons cell bound to the variable x the rule looks entirely conventional we simply unfold the fixed point and continue we are nevertheless able to prove a normalization result for the operational semantics since the fixed point for a variable at a future time we begin the metatheory with a type preservation proof theorem type preservation if we have that i · c i · i e i a and ce c v then there is an i and c such that c c c i i c i and · · i i v i a this theorem follows from a routine structural induction to show soundness we will prove termination via a kripke logical relations argument since we evaluate terms e in contexts c and return a value v in some larger context c we take our kripke worlds to be the closed contexts that is worlds are those c such that i · c i we define the ordering c c on worlds so that there should be some c such that c c c thus a future world is one in which more bindings are available in figure we define the logical relation by induction on types there is one clause for each type a defining a subset of the welltyped expressions of type a closed save for the variables bound by c the expression relation ea c consists of the expressions that use resources in and evaluate to a value in in the context c the definition of the logical relation for streams states that a variable x is in if x binds a cons cell with v in its head and v is in the as expected the relation for functions consists of such that in any future world applying a value in the should result in a term in the expression relation at type b in the case of the delay modality we allow any welltyped value since the evaluation relation does not evaluate any terms at time i and the body of a delay is at time i the a relation consists of values v such that v is in the in the empty world since we want values of type a to not depend on the stream values c binds last the relation at r a consists of those u r e such that for any resource t of type r in context the expression is in the expression relation for a with resources to prove the fundamental property we define some predicates in figure the predicate good i out those contexts in which all of the bindings in i at time i contain true streams according to the stream relation the vi c and vi sets extend the value relation to substitutions rather than single values and defines linear substitutions the notations i and i mean contexts where every variable is at time i or later in these substitutions we only require for variables at time i to lie in the logical relation and require only for other variables since evaluation only affects the current tick theorem fundamental property of logical relations suppose i i i e i a furthermore suppose that c good and and vi and vi c then e ea c as is usual for logical relations this theorem follows from a structural induction on the derivation of e a the fundamental property suffices to prove normalization once we observe that typing derivations satisfy the following history independence property lemma history independence · if x i a · if x i a e j b · if u i r e j b e j b and i j then e j b e j b and i j then x j a e j b and i j then u j r parameter of the logical relation i base contexts · u i · i x i sa i x i sa va i · c i v · · i v i a ea i · c i e · i e i a x v cx v v x a e c v c c c i · c i · · i i v v va vr ac u r e c t t i r ea c c ea c e a c v ce c c v v c good i c x i sa i x c · v x i a c vx v c v v x ji a i · c i ex v c · · i e j a · v x i a vx v v va v x ji a ex v · · · e j a · ·· t i r tu u i r figure logical relation for termination these properties are all proved by structural induction the syntax ensures expressions at time j i do not depend on a variable of time i as a result we only need to consider contexts in which and contain variables no than the current time normalization immediately follows corollary normalization suppose · · e i a then e cv finally note that we are considering normalization of open terms since we have no constants of type the of such constants is of course what ensures that the language respects space bounds theorem space bounded evaluation suppose · · e i a and e cv then the size of c the number of cons cells it binds is bounded by the size of given type preservation this theorem is straightforward each cons cell in the context needs a distinct resource variable so the number of cons cells in c is clearly bounded by the size of operational semantics recall that when we advance time we want to replace the of stream variables with just the variable we define the necessary operations in figure to tick the clock we define the relation cx e which takes a stream in context cx and constructs a new expression e by the of the streams in c and sending each tail expressions in c to y this models the effect of time by one tick so that all the streams in the expression context become their and all references to become references to the updated stream variable to show the of this operation we introduce the operation which tells us how the typing changes it sends all streams at time i to time i and leaves streams at time i alone now we can prove the following type soundness theorem theorem the clock if · i cx i sa and cx e then · e i sa this theorem follows from a routine structural induction and establishes that our semantics is since is the same before and after the tick from cx e it follows that evaluating e will never construct more streams than permits together with the type preservation property our theorem gives a purely syntactic proof of the of our language however while our definition of the clock is intuitively and even makes proving memory safety easy it is still in what sense it is correct to illustrate the issues involved observe that our language contains which may contain free variable references and that the tick operator essentially updates stream values it is important to prove that the clock cannot change the meaning of a in a way which violates the purely functional character of functional reactive programming to show this we will first give a denotational semantics of stream programs then we will show that if cx e then the meaning of e does in fact equal the tail of the denotational meaning of cx showing that the clock really does advance the clock in the way we expect this is a standard adequacy proof applied to an operational semantics semantic causality and spaces the intuition reactive programming is the stream transformer a function which takes a stream of inputs and generates a stream of outputs but not all functions on streams are implementable reactive programs in order to be implementable at all reactive programs must respect the causality condition that is the first n outputs of a stream function may depend on at most its first n inputs writing xs n for the prefix of the stream xs we formalize causality as follows definition causality a stream function f a b is when for all n and all streams as and as we have that if as n as n then f as n f as n furthermore reactive programs often define streams by feedback if a stream transformer can produce the first value of its output without looking at its input then we can constructing a fixed point via feedback taking the nth output and it as the input at time n so as long as we can generate more than n outputs from the first n inputs we can find a fixed point formalizing this gives us a definition of for defining fixed points definition a function f a b is guarded when there exists k such that for all n and all streams as and as if as n as n then f as nk f as nk i i c i i i i · · i v i a u i · i e i sa i i x i sa c i u i i i let x v u e in c i x i sa y i sa i i i x i sa c i i i let x in c i x i sa c c c c let x in c c let x in c c let x v u e in c c let x v u e in c c cx v c c let y in cx v c x v c c let y v u e in c x v cx v c c let x v u e in cx v figure context typing and operations however these definitions apply only to stream functions and real programs need more types than just the stream type so we need of causality which work at other types such as streams of streams and higherorder functions to generalize these definitions we follow our earlier work by moving to a category of metric spaces a complete bounded space a which we will simply call space is a pair a d where a is a set and d a × a is a distance function satisfying the following properties dx y iff x y dx y dy x dx z y dy z dx y or n for some n all sequences have limits we take the morphisms between spaces to be the maps f a b these are the settheoretic functions f a b such that for all a a a we have a f a a that is a morphism between a and b is a function f such that it takes any two points in a to two points in b that are at least as close it is a function ce c v cv cv ce c x a e c e c v c c v ce e c v ce c u r e c c v ce t c v x fresh ce c v c c let x const v u e in e u e c x ce c x c x const v u e c v ce c y c let x in e c v x in e c v ce c c c v e in e c v x a c v x a e c v ce c v c c v x e in e c v c v e u v t t in e c v ce c v i ce c v ce c v c c v e x e in e c v figure operational semantics the category of spaces is useful for two reasons first the stream functions are exactly the maps between spaces of streams with the metric ie the distance between two streams is n where n is the first position at which they since the category of bounded complete spaces is cartesian closed we have our of causality one which would be very difficult to find from purely operational considerations second nonempty metric spaces satisfy theorem which lets us define fixed points at arbitrary types proposition contraction map theorem if a is a nonempty complete metric space and f a a is a strictly contractive function then f has a unique fixed point modeling space bounds with length spaces as noted earlier simple still allows functions requiring a stream function to depend only on its history does not prevent it from depending on its whole history cz e z x cz e let x in cz let x y in e cz e let x v u e in cz let x uu e in e · x i sa x i sa x i sa x i sa ii vs tail vs vs vs figure the next step operator to deal with this issue we adapt the length spaces of hofmann which give a model of computation the idea behind this model is to start with a partially ordered resource monoid r representing space resources n in the original work one then constructs the category of length spaces as follows a length space a is a pair a a a r consisting of a set of elements a and a size function which assigns a size aa to each element a a a morphism of length spaces f a b is a function that is it is a settheoretic function f a b with the property that a a bf a aa the programming language intuition is that a morphism a b is a term of type b with a free variable in a and so a term cannot use more memory than it receives from its environment to model the permission to allocate we can define a length space of type the space is computationally its set only has the unit in it but it a permission to allocate with it so we can model computations which do allocation by giving them permission elements thereby controlling the allocation performed the denotational semantics the resource model in the synchronous dataflow model there is a global ambient notion of time furthermore higherorder reactive programs can create a dataflow graph dynamically by waiting for an event before choosing to build cons cells to do some computation so we need a resource structure capable of modelling space usage over time therefore we take resources to be the monoidal lattice r time space max min where time n and space n the vertical natural numbers with a element intuitively time is discrete and measured in space counts the number of cons cells used in the program and may be infinite obviously we cannot implement such programs we define the lattice operations as follows k k k d k dk d k dk c d k ck dk c d iff k time we have ck dk essentially we lift the lattice structure of the vertical natural numbers pointwise across time with as the monoidal structure so that a resource c r describes the number of cons cells that are used at each time step we then turn r into an space by it with the metric d n where n min k time ck dk the category of complete length spaces a complete bounded length space a which we will as metric length space is a tuple a d where a d is a complete bounded space and a a r is a size function giving each element of a a size drawn from r furthermore the size function a r must be a map between a d and r dr ensures that we cannot tell if the memory usage requirements of two elements of a differs until we know that the elements themselves differ in addition to being intuitively reasonable this requirement ensures that limits of sequences will be wellbehaved with respect to size which we need to ensure the completeness of the size of a that we use to interpret a the morphisms of this category are the maps f a b which are the settheoretic functions f a b such that · for all a a a we have a f a a · for all a a we have bf a aa that is the morphisms we consider are the functions which are both and categorical structure metric length spaces and maps form a category that we use to interpret our programming language first it forms an intuitionistic bi category which is a category with both cartesian and monoidal closed structure as well as supporting structure second this category also models the resource types of hofmann as well as a modality a which is in the usual fashion of linear logic third it supports a version of the delay modality of our earlier work which lets us interpret guarded recursion via fixed point theorem we give the definitions of all of these objects below in figure we define the distance and size functions and in figure we give the natural transformations associated with the objects · d · a b a b ab · a × b a × b · a b a b ab · a b a b ab · a b a × b da b a b · a b a b da b a b · a · sa a sa · a a a aa a · d · d the construction of cartesian and monoidal products closely follows that of hofmann the cartesian product is a sharing product in which the associated resources are available to both components this explains the use of max and the monoidal product is a disjoint product in which the resources are divided between the two components the use of in the size function the best intuition for the closed structure comes from implementing firstclass functions as closures the monoidal exponential a b takes an argument which does not share with the captured environment and the cartesian exponential a b which does a difference between our work and earlier work on length spaces is our heavy use of the cartesian closed structure indeed and hofmann use a realizability model to remove the cartesian closed structure from their semantics they to prevent duplicated variables in from enabling large increases in the size of a under reduction since this makes establishing strict resource bounds more difficult as we only want to track the allocation of cells but wish to allow free sharing otherwise the structure takes on a central role in our model our metric is the same as in and benton but the size function which shifts all sizes into the future relative to a means that b this breaks with and benton and significantly changing the elimination rules as mentioned earlier this limitation is we do not want delay operators at types for which delay would be expensive our semantics rules out such maps with the size function for streams plus the requirement that morphisms are the size function for streams gives a size for the stream as to account for the size of the stream itself plus the maximum space usage of all the values the stream takes on intuitively a stream can seen as taking the space for an cartesian product a × × × plus a constant for the stream cell itself this is the only place where we increment the size of a value relative to its components which the idea that sizes measure the number of cons cells since delaying a stream shifts its time usage by one step we have no a priori reason to expect that a delay map will exist at all types however for types such as n a and there do exist maps a which is why time subsumption is justified for the linear and pure contexts furthermore all types whose values are all of size zero have maps a a as a result we can introduce constants corresponding to such maps for these types allowing types such as numbers and booleans be to the pure fragment in fact our implementation applies these coercions implicitly providing a slightly syntax than presented here our semantic model contains a space to interpret the resource type which gives unit of space at every time tick our model uses the additional metric length space which gives unit of space at time and no units of space at any other time this lets us give a nice type to cons a × sa note that the type a × lacks the space to form a stream we need unit of space at time which neither the a nor the provide ai a × b a a × b b f g a b × c where f a b g a c f abc where f a × b c eval a b × a b f g a bc d where f a c g b d a b c a b c a b c a b c a bb a a ia a i a f a b c where f a b c eval a b a b a a f a b where f a b f a b where f a b a where f a b · a head sa a tail sa cons a × sa split · split · fix a a × × b × b × b b a b a b a × b a b a b a × b a a b a a b b a f a g a a b f a b f a f a a b f a g b a b c a b c a b c a b c a b b a a a a a a b f a b f a f a a a a f a a f a a a a f a a a a a x · xs x x · xs xs x xs x · xs f µf a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b figure categorical combinators denotational interpretation we give the interpretation of types and contexts in figure the interpretation of types offers no but the interpretation of contexts is relative to the current time the interpretations of and keeps hypotheses at times earlier than the current time but simply all earlier hypotheses this corresponds to the difference between the type rules and on the one hand and the rule on the other in all three cases future hypotheses are interpreted with the delay modality in figure we give a interpretation function for expressions e i ai which has the type i i i a the interpretation of makes use of the of to interpret the body of the delay in the future and then bring it back to the past with the necessary action on contexts defined in figure the other rules are as expected with the resource context in a singlethreaded way and the other contexts duplicated freely we can then show that this semantics is sound with respect to substitution x if v inl x v inl x v v y if v inr y v inr y otherwise d a b a b a b da b a b a b a b f g max a g a a a da b f g max a g a a a a a a xs ys max a n · n n da a a a d d theorem soundness of semantics let · · ce i a and ce c v then · · ce i a equals · · c v i a finally we can show that the clock has the expected semantics theorem soundness of the clock let · i cx i sa and i and ii and suppose cx e then we have that tail · i cx i sa is equal to · · e i sa where and this theorem the operation of the heap with ab v aa if v inl a bb if v inr b the denotational interpretation each time we advance the clock each stream in a closed context c will become its tail so the clock the elements of the stream a b bb a b a b aa bb ab f min k r a a bf a aa discussion a b f min k r a a b f a k aa sa xs k max i time k k if k then else a a in this paper we have introduced an expressive type system for writing stream programs and given an operational semantics the claims of the type system our semantic model is one of the primary contributions of this paper since it lets us reason about space usage without the view of also our model contains many operations · a k if k then else ak which are not currently expressible in our language for example in the future we might want richer types in the affine context and figure the distance and size functions function space so that operations like map can be typed a b sa sb our language contains an explicit delay modality as in cal of and an operational semantics the reader may find it surprising that al theorem semantic substitution suppose i i i and i then though our operational semantics does make use of a form of mutable higherorder store the logical relation we give is not stepindexed the reason this is possible is essentially that is a syn if t i r and u i r t j r then j r is equal to model of computation in which all the updates happen in a separate phase from ordinary functional evaluation this explains u i r t j r t i r why we were able to present a semantics and since no if t i r and u i r e j a then heap modifications take place during there is no need for step j a equals indexing u i r e j a t i r et al introduced realtime a restricted subset if · · e i a and x j a e k b and i j of sharing many of the same design choices of synchronous then dataflow languages it is essentially firstorder streams can carry k b equals general values of the host language but these values can not them x j a e k b · · e i a refer to streams and makes use of a novel continuation typ if · e i a and x i a e j b then j b equals x i a e j b · e i a ing to ensure that all recursive signals are as a result the language requires only and reductions is similar but timing constraints by the global clock these theorems follow from structural induction on the typing derivation of the term being substituted into figure gives the interpretation of contexts using the expression semantics to define the meaning of each stream bound by the context this interpretation is sound with respect to the of terms in contexts none of our examples using higherorder functions or nested streams can be in realtime which is carefully to avoid a firstclass behaviour type and so cannot express higherorder operations on streams all realtime programs can be written in our language since we can define all of realtime stream operators switching delays recursion as ordinary programs theorem context soundness if i i c i and · i i e i a and i and i and ii then · i ce i a is equal to · i i e i a i i c i et als commutative arrows are another attempt to control the memory and space usage of reactive programs this work takes advantage of the fact that pure ie without switching builds fixed dataflow graphs allowing programs to be optimized into code via a transformation now we can show that the operational semantics is cent of the theorem our language does not seem sound with respect to the denotational model to support such an elegant normal form because of the presence a b a b sa sa a a r a r a r s r s i i i i obj i x n ri i x n ri i r when n i when n i i obj i x n ai i × when n i x n ai i × a when n i i x n ai x n ai obj i i × i when n i when n i i i i r r if n i r r if n i v v if n i v v if n i v v v if n i if n i figure interpretation of types and contexts of higherorder streams and functions but it would nonetheless be interesting to investigate related optimizations in our setting and work on safe functional programming uses types to ensure by having dependent types track whether signal processors have delays before feedback our modality is simpler but less flexible since it cannot depend on the values a signal produces however the advantage of our modality is that it works at higherorder cooper and described the system which into the plt scheme now implementation one between and our work is that switching does not come from special primitives but from ordinary conditionals and case statements unlike our denotational model operational semantics the imperative in which is modelled explicitly as t i ri i r e i ai i i i a u j ri u t t j r si t t x j ai x if x i a x i ai x if x i a x a e i a bi v · x i a e i bi v e e i bi let f e a bi in let v e ai in eval f v e i ai · · e i ai let x e in e i bi e i ei const e u e i let d r in let h ei in let t i r in h t i ai head e i let x in e i bi let vs in x i sa e i bi tail vs i ·· e i ai let e in e i bi let v e i in x i a e i bi v u r e i r ai r u i r e i a r e t i ai eval e t let u v t in e i ai let r s t i r s in u i r v i s e i a r s fix x a e i ai let f v let v in · x i a · e i ai fix f in let x e in e i bi let v e i ai in x i a e i bi v figure denotational semantics of terms i i c i i i i p d n and j a declarative language for realtime programming in popl g cooper integrating dataflow evaluation into a practical higher i i · order callbyvalue language phd thesis university i i let y in c y i sa i let v tail x in let i i y i sa c i v in v g cooper and s embedding dynamic dataflow in a callbyvalue language programming languages and systems pages ­ d dreyer a ahmed and l birkedal logical stepindexed logical i i let x v u e in c i x i sa relations in lics pages ­ ieee c and p hudak functional reactive in icfp let r d u i in let h · · i v i a in let d in let next i in let t · u i · i e i sa let vs h t in in m hofmann a type system for bounded space and functional update journal of computing m hofmann linear types and polynomial time computation information and computation p hudak a h and j arrows and functional reactive programming in advanced functional pro let i i x i sa c i vs in vs gramming volume of lncs springer j hughes generalizing monads to arrows sci comput program figure interpretation of contexts n and n benton semantics of reactive programs in lics ieee a kind of heap update in the operational semantics we think the operational semantics in this paper which is in is close enough to both a denotational model and semantics that it makes sense to study how to the pure and the imperative of and benton have also presented a language for writing reactive programs this language also makes use of linear types but in this case they are used to track the allocation of new it is not yet clear to us how one might combine with this kind of we may need to add a dynamic allocation monad to our model to integrate the two lines of work supporting other dynamic data structures not necessarily streams suggests looking at the work of acar et al who have studied adding to selfadjusting computation which shares many implementation issues with conversely it will be worth whether our denotational semantics can be adapted to provide a useful categorical cost semantics for selfadjusting computation n and n benton a semantic model of graphical user interfaces in icfp u d and m hofmann realizability models and implicit complexity theor comput sci ­ r u a acar and m a cost semantics for selfadjusting computation in z shao and b c pierce editors popl pages ­ acm isbn h e and p hudak commutative arrows and their optimization in icfp h a modality for recursion in lics pages ­ h a and j functional reactive programming in acm haskell workshop pages ­ acm p w ohearn and d j the logic of implications of symbolic logic m version and reference manual n and h safe functional reactive programming through dependent types in icfp references u a acar g e r k and d data types for selfadjusting computation in pldi pages ­ a w appel pa c d and j a very modal model of a modern major general type system in m hofmann and m felleisen editors popl pages ­ acm isbn g and l the esterel synchronous programming language and its mathematical semantics in on concurrency pages ­ springer d g e r harper and p b space profiling for parallel functional programs in j and p editors icfp pages ­ acm isbn t and v the essence of dataflow programming in k yi editor volume of lecture notes in computer science pages ­ springer isbn z w and p hudak realtime in icfp pages ­ z w and p hudak in pages ­ 