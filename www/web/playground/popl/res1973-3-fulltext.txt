top down operator precedence r pratt massachusetts institute of technology survey of the problem domain there is little agreement on the extent to which syntax should be a consideration in the design and implementation of program ming languages at one extreme it is con and one may go to any lengths van to provide adequate syntactic capabilities the other extreme is the of a need for a rich syntax in between we find some language to incorporate as much syntax as possible provided they do not have to work hard at it in this paper we present what should be a satisfactory for a large language designers and we have in mind particularly i those who want to write and interpreters soft or for new or languages without having to acquire a large system to reduce the and ii those who need a convenient yet efficient language extension mechanism accessible to the language user the approach described below is very simple to understand trivial to implement easy to use extremely efficient in if not in theory yet flexible enough to meet most reasonable syntactic needs of users in both categories i and ii above what is reasonable is addressed in more detail below more over it deals with error tion one may why such an approach has not been generally adopted already i the root cause of this kind of is our universal with grammars and their various indexed aho type macro fischer lrk knuth and lewis grammars to name a few of the more ones together with their related automata and a large body of theorems i am person of automata theory per se but i am not with the extent to which it has so far been successfully applied to the writing of compilers or interpreters promising nor do i see a particularly future in this direction rather i see automata theory as holding back the development of ideas valuable to language design that are not in the domain of automata theory users of grammars when to the con goals of practical simultaneously with generality symbol tables data types and their of ambiguity demands by the user topdown semantics etc and theoretical efficiency the guarantee that any translator using a given technique will run in linear time and reasonable regardless of the particular grammar space used grammars alone do not deal with either of these issues and so they are in some directions to increase generality and in others to improve efficiency both of these operations tend to increase the size of the implementation system that is the soft needed to grammars and to translator the execution of the resulting this makes these methods less accessible and less to use also the operation is done dealing only with those issues that have work reported was supported in part at stanford by the national science foundation under grant no gj and the of research under grant number nr by ibm under a at stanford by the ibm tj watson research center heights ny and by project by the advanced research projects department mac an mit research program of under of research contract number and the national science foundation under contract number in whole or in part is permitted for any purpose of the states been ed needs leaving no room for i am here particularly of the work of lewis and and their on grammars table grammars and translations their approach while the precision characteristic of the mathematical sciences which is in what is really a and problem is with a sensitivity to the needs of tor writers that makes it perhaps the most promising of the approaches to demonstrate its they have their theory in an efficient algol compiler a number of not addressed which we propose in the approach below they issues are by their system to make up are as follows i from the point of view of the lan guage designer or writing an grammar and keeping it after extending it seems to be a black art whose main feature is that the system can at least the problems with a given grammar it would seem where possible to make it easier for the user to write acceptable grammars on the first try a property of the approach to be presented here ii there is no escape clause for dealing with nonstandard syntactic prob eg statements the procedural approach of this paper makes it possible for the user to deal with difficult problems in the same language he uses for routine tasks iii the system must be up running and on the users ter before he can start to take advantage of the technique this may take more effort than is for applications lie suggest an approach that requires only a few lines of code for supporting soft it lewis and consider only in the context of their system it remains to be determined how effectively they can deal with interpreters the approach below is suited for interpreters whether written in software or hardware three syntactic issues to with syntactic needs we adopt the simple of allowing the language to write arbitrary programs by itself this would represent a long step backwards instead we offer in place of the structure of a metalanguage a of supporting software and a set of guide lines on how to write modular efficient compact and and interpreters while preserving the that one is really writing a grammar rather than a program the are based on some ele assumptions about the primary syn tactic needs of the average programmer first the programmer already under stands the semantics of both the problem and the solution domains so that it would seem appropriate to the syntax to fit the semantics current practice entails the reverse second it is convenient if the pro can avoid having to make up a special name for every object his program computes the usual way to do this is to let the computation itself name the result eg the object which is the second ment of in the computation abc is the result of the computation bc we may regard the relation is an argument of as defining a class of trees over tions the program then contains such trees which need conventions for express ing linearly third semantic objects may require varying annotation at each cation depending on how far the particular invocation differs in from the norm eg for loops that dont start from or by the programmer needs to be able to formulate these annotations within the programming language there are clearly many more issues than these in the design of programming languages however these seem to be the ones that have a significant impact on the syntax aspects let us now draw from the above assumptions lexical semantics semantic versus the traditional mechanism for assign ing meanings to programs is to associate semantic rules with rules or equivalently with classes of phrases this is inconsistent with the following reasonable model of a programmer the programmer has in mind a set of semantic objects his natural is to talk about them by assigning them names or tokens he then makes up pro grams using these tokens together with other tokens useful for program control and some purely syntactic tokens no boundary these classes this suggests that it is more natural to associate semantics with tokens classes of phrases this argument whether we specify is independent of program control as in algollike languages or implicitly as in languages in either case the programmer wants to express his instructions or tions concerning certain objects when a given class of phrases is character by the of a token the effect is the same but this is not always the case in a semantic specification and i conjecture that the difficulty of learning and using a given of language rules not specified in with a to the num by a single token the existence of an operator grammar for algol provides a ble account of why people succeed in learn ing algol a process known not to be strongly with whether they have seen the of algol are two advantages of separating semantics from syntax in this way first rules interact more strong ly than individual tokens because rules can share nonterminals whereas tokens have nothing to share so our assignment of semantics to tokens has a much better of being modular than an assignment to rules thus one can the language to ones needs by selecting from a library or writing the semantics of just those objects that one needs for the task in hand without having to about interactions between two semantic objects at the syntactic level second the lan guage designer is free to develop the syntax of his language without concern for how it will affect the semantics instead the semantics will affect decisions about the syntax the next two issues linear trees and annotating tokens illustrate this point well thus syntax is the of semantics an relationship since the of the message is with the semantics variations in syntax being an added on the idea of lexical semantics is implicit in the usual approach to macro generation although the point usually goes i many people find syntax macros for reasons related to the above discussion conventions for trees we argued at the beginning of section that in order to on names the programmer to the use of trees the is a long history of use of the same trick in natural language of for channels the trees are mapped into strings for trans and at the other end we are concerned with computer engineering both the human and aspects of the coding we may as look like apply int j y i j xy eg that is every node is labelled token whose arguments if any trees without further adopt the following conventions ing trees as strings with a are its sub we shall for i the string contains of the tokens in the tree the semantic tokens items such as if some additional syntactic necessary every occurrence which we include together with tokens where ii subtrees map to strings containing no semantic side that subtree out iii the order of arguments in the tree is preserved naturally these are ed trees in general iv a given semantic token in the lang together with any related syntactic tokens always appear in the same place within the arguments eg if we for we may not use ab as well this convention is not as strongly as i iii without it however we must be restrictive in other areas more important than this one if we that every semantic token take a fixed number of arguments and that it always all of its arguments prefix notation we may re cover the tree from the string and similarly for as is well known for a variable number cf arguments the lisp solution of tokens parentheses at the beginning and end of a subtrees string will suffice many people find neither particularly ab cd ii ab easy to read sin ab c d solution they prefer to sin ab p or to a b c d sin a b although they will for cd in of the first if necessary but i have recently encountered some lisp users the reverse so i may be an unambiguous is to require parentheses but move the tokens as in ab this a quite if but it tell if the parentheses balance and it nearly the number of symbols s we seem forced into having to solve the problem that operator precedence was designed for namely the association problem given a substring where a takes a right argument b a left and e is an expression does e associate with a or b a simple convention would be to say e always associates to the left however in print a b it is clear that a is meant to associate with not print the reason is that print a b does not make any conventional sense print being a procedure not normally returning an arithmetic value the choice of print a b was made by taking into account the data types of right argument s left argument and the types returned by each thus the association is a function of these four types call them for the argument and result respectively of and b that also takes into account the legal coercions implicit type conversions of course sometimes both make sometimes neither also a or r may depend on the type of e further one way to resolve the issue is simply to the outcome in advance for each pair a and b the choices on some reasonable heuristics suggested this approach called operator precedence the outcome was stored in a table also suggested a way of en coding this table that would work in a small number of cases namely that a number should be associated with each argument position by means of precedence functions over tokens these numbers are sometimes called binding then e is associated with the argument position having the higher number need never occur if the numbers are assigned care fully alternatively may be broken by associating to the left say showed that algol could be so treated a the idea is to assign data types to classes and then to totally order the classes an example might be in order outcomes eg the of print booleans graphs eg trees lists strings algebraic eg complex arrays and references as on the left side of an assignment we write strings c references etc we now that the class of the type at any argument that might in an association problem not be less than the class of the data type of the result of the function taking that argument this rule applies to coercions as well s we may use since its argument types algebraic are each greater than its result type boolean we may not write length xi where x is a string or a graph since the argument type is less than the result type however lx would be an acceptable substitute for x as its argument cannot in an tion problem finally we adopt the convention that when all four data types in an association are in the same class the association is to the left these restrictions on the language while slightly are certainly not as as the lisp restriction that every expression have parentheses around it thus the following theorem should be a little surprising since it implies that the programmer never need learn any theorem given the above restrictions every association problem has at most one solution consistent with the data types of the associated operators proof and b let be such a problem e may associate with both a hence because e associates with a aa ra ab rb type x is in since coercion is type class of the result of ae greater than r by an obvious proof also fo e with b ab and the is not inductive rb aa ra similarly thus one to this approach is that there seems to be little guarantee that one will always be able to find a set of numbers consistent with ones needs another is that the programmer has to learn as many numbers as there are argument positions which for a language may be the order of a lie present an approach to language design which simultaneously solves both these problems without yet allows restricting normal usage us to retain the numeric approach to operator precedence and that four are in the same class but the convention case is that e must associate our assumption associate with b as well in this with a that e could a this theorem implies that the program need not even think about association except in the case all four types in the same class and then he just the rule more simply the rule is always associate to the left unless it doesnt make sense what he does have to remember is how to write expressions containing a given token eg he must know that one writes x not length x and which coercions are allowed these sorts of facts are quite modular being contained in the description of the token itself independently of the properties of any other token and should certainly be easier to remember than numbers associated with each argument given all of the above the obvious way to parse strings ie recover their trees is for each association problem to associate to the left unless this yields semantic unfortunately testing requires looking up the types ra and a and verifying the existence of a from r to a for translation this is not but for interpretation it might slow things down significantly fortunately there is an efficient solution that uses operator precedence functions theorem given the above restrictions on a language there exists an assignment of integers to the argument positions of each token in the language such that the correct association if any is always in the tion of the argument position with the larger number with being broken to the left proof first assign even integers to make room for the to the data type classes then to each argument position assign an integer strictly where possible between the integers corresponding to the classes of the argument and result types to see that this assign ment has the desired property consider the and cases in the problem ae as before in the case all four types are in the same class and so the two numbers must be equal resulting in left association as desired if two of the data types are in different classes then one of the inequalities in assuming e associates with a must be strict if it is the first or third inequality then as number must be strictly greater than bs because of the strictness condition for between different argument and result type class numbers if it is the second inequality then as number is greater than bs because result type class number is greater than bs argument one a similar argument holds if e associates with b the proof u thus theorem takes care of what the programmer needs to know and theorem what the computer needs to know in the former case we are relying on the programmers with the syntax of each of his tokens in lhe latter on the computers with numbers theorem establishes that the two methods are equivalent exceptions to the left association rule for the case may be made for classes as a whole without theorem this can be done by by the numbers for argument positions to the right of all semantic tokens in that class that is the right binding then the programmer must remember the classes for which the exception holds applying this trick to some tokens in a class but not to others gives results and so does not seem worth the extra effort required to remember the affected tokens the about and motivated con and f may be implemented the appropriate classes here the booleans and algebraic into eg terms factors as in the for algol then is defined over terms over factors and over with coercions allowed from to factors to terms to be consistent with algol the should be a right associative class while these remarks are not essential to the basic approach they do provide a sense in which operator precedence is more than just an ad hoc solution to the tion problem even if the language designers find these too restrictive it would not the fact that operator precedence is in practice a quite solution and we shall use it in the approach below regardless of whether the theoretical justification is reasonable nevertheless we would be interested to see a less restrictive set of conventions that offer a degree of modularity comparable with the above while the use of precedence functions the approach of the precedence functions for every operator after one change to the grammar is not modular and does not allow flexible access to individual items in a library of semantic tokens an alternative to precedence functions would be to of the ordering and rely purely on the data types and legal coercions to resolve cases which did not have a unique answer would be referred back to the programmer which would be acceptable in an online environment but in mode our concern about efficiency for interpreters could be dealt with by having the outcome of each tion problem marked at its occurrence to speed things up on subsequent pending such developments operator precedence seems to offer the best overall in terms of modularity ease of use and and efficiency the theorems of this section may be interpreted as theorems about grammars with the nonterminals the role of data type classes however this is really a of the nonterminals one to try to say everything with just context free rules which on the difficulties mentioned objects abstraction in section it would seem to refer to the semantic directly rather than to their in an language annotation when a token has more than two ments we lose the property of infix tion that the arguments are delimited this is a nice property to retain for readability be cause complications arise it is to be used as both eg if an infix and a prefix operator also has this property as an infix it denotes tion as a prefix a accordingly we require that all arguments be de limited by at least one token such a grammar calls an operator grammar provided the number of ments remains fixed it should be clear that no done by the extra arguments to theorems and p since the string of tokens and arguments including the two arguments at each end plays the same syntactic role as the single semantic token in the two argument case we shall call the seman tic tokens associated with a its parents an obvious choice of is however this is as valuable as a syntactic token that documents the role of the argument following it for example if a then b else c is more readable by a human then if a b c other examples are print x format f for i from s to f by d while c do b log x base b solve e using m x between y and zt etc sometimes arguments may be used constants eg for i from to n by while true do b if an argument is uniquely identified by its preceding an obvious trick is to permit the of that argument and its token to denote that a default value should be used thus we may abbreviate the previous example to i to n do b as in extended algol other obvious are log x for log x base if x then yl far if x then y else nil and sa on note that various arguments in now may be involved depending on which ones are absent another situation is that of the variable length parameter list eg clear at b cf d are more appropriate here need more although again we may as in on a qn b off g on m off p off t in which the switches or bits are left as they are all of these examples show that we want to be able to handle quite a variety of situations with default and parameter lists no claim is made that the above examples the possibilities so our language design should make not only for the above but for the as well this is one reason for a procedural embedding of semantics we can write arbitrary code to find all the arguments when the language designer the need to things implementation in the for lexical and a arguments to practice preceding semantics variety tn this section we argued operator of ways of reduce this to combine lexical semantics with a procedural approach we assign to each semantic token a program called its semantic code which contains almost all the information about the token to translate or interpret a string of tokens execute the code of each token in turn from left to right many tokens will expect arguments which may occur before or after the token if the argument always comes with unary t we may parse operators expressions following parser before as such as using the run code this parser is initially at the of the input it runs the code of the current token the result in a variable called left advances the input and the pro if the input is then by default the parser halts and returns the value of left the variable may be by the code of the next which will use the value of left as either the translation or value of the lefthand argument depending on whether it is translating or alternatively all arguments may appear on the right as with unary pre fix such as log and sin in this case the code of a prefix can get its argument by calling the code of the following token will continue recursively this a token is encountered eg a variable or a constant that does not require an argument the code of this token returns the appropriate does the code in the reverse were called translation and then so of each of the other tokens of the order in which they clearly we want to be able to deal with a of these two types of tokens together with tokens having both kinds of arguments operators this is where the problem of association arises for which we operator precedence we add a state to the parser bo c code advance i left run c ql starting in state qo the parser inter a token after past that token and then enters state ql if a certain returns condition is satisfied the parser to qo to process the next token otherwise it halts and returns the value of left by default we shall also change our strategy when for a righthand argument making a recursive call of the parser it self rather than of the code of the next token in making this call we supply the binding power associated with the desired argument which we call the right fixed binding as this power value remains of the parser runs the left binding power is a property of the current token in the input stream and in general will change each time state q is entered left binding ts of the token not in its semantic code to return to q we require ig this test fail then by default the parser returns the last value of left to called it which corresponds to a getting e in if a had called the parser read e if the test succeeds the parser enters state qo in which case b gets e instead because of the possibility of there being several recursive calls of the parser running simultaneously a stack of return addresses and right binding must be used this stack plays essentially the same role as the stacks described explicitly in other parsing schemes lie can the parser a little by having the edge leaving ql return to a rather w than since qo this may appear we have to repeat the q ql code on the q q edge as well this allows us to take advantage of the distinction between c and ql namely that left in state q and defined is that is some expression precedes token interpreted during the q q transition but not a token during the q q transition we will call th denoted by a token with without a expression its left the advance lq advance ill or by split trans and using a c stack instead c led of variables the state advance the variable run on the stack c left it now makes sense to denote two different for a token codes for example the of denotes unary and its led binary we may do the same for in conversion as fn algol versus division syntactic as in versus applications of variables or constants whose value is a function as in yf etc and e the empty versus the membership a possibly more important role for and is in tion if a token only has a and is given a left argument or only has a led and is not given a left argument or has neither semantic code is invoked which can be to result n the calling of an error routine far we have assumed that semantic code calls the parser once and then the appropriate one is at to have more elaborate code however when the code can read the input but it request and use arbitrary amounts of storage and carry out arbitrary computations in whatever language is available for which an ideal choice is the language being defined these give the the of a turing machine to be used and by the language as he fit while one may object to all this power on the ground that language descriptions can then be written for practical purposes the same holds for grammars of which some quite yet brief examples exist in fact the argument really runs the other way the language can use the extra power to produce more implementations as we shall see in section one use for this procedural capability is for the semantic code to read the and the arguments following them if any clearly any that might come directly after an argument should have a left binding power no greater than the binding power for that argument for example the of if when encountered in the context if a then b else c may call the parser for a verify that then is present advance call the parser for b test if else is pre sent and if so then advance and call the parser a third time this the dangling else in the usual way the of will call the parser and then sent and of course simply check that advance the input may have multiple is pre parents and even semantic code such as which might have a absolute value of as in ix two parents it self and is shorthand for if a then b else c the ease with which and optional are dealt with one of the advantages of the approach over the conventional methods for implementing operator precedence the parsers operation may perhaps be better understood consider the example if a b o then print a else we may exhibit the tree by the parser from this expression as in the diagram below the tokens encountered during one of the parser are in a dotted and are connected via links while calls on the parser are connected to their caller by links label the links of the expression they if any the is included although it is not really a semantic object the major difference between the approach described here and the usual operator precedence scheme is that we have modified the to work topdown implementing precedence parser the stack by means of recursion a technique known as recursive descent this would appear to be of no value if it is necessary to imple ment a stack in order to deal with the recursion however the crucial pro of recursive descent is that the stack entries are no longer just operators or operands but the environments of the pro grams that called the parser recursively when the programs are very simple and only call the parser once gives us no more information this environment than if we had semantic tokens themselves on the stack when we consider more complicated sorts of constructions such as operators with various default parameters the technique becomes more interesting while the above account of the al should be more or less it may be worth while the properties of the algorithm a little more an expression is a string s such that there exists a token t and an environment e in which if the parser is started with the input at the beginning of st it will stop with the input at t and return to e the interpretation of s relative properties i when the semantic code of a token t is run it begins with the input just to the right of that token and it returns the interpretation of an expression ending just the final position of the input and starting either at t if t is a or if t is a led then at the beginning of the expression of which left was the interpretation when the code of t started ii when the parser returns the tation of an expression s relative to en e s is immediately followed by a token with in e iii the led of a token is called only if it immediately follows an expression whose interpretation the parser has assigned to left iv the of a token whose led has just been called is greater than the of the current environment v every expression is either returned by the parser or given to the following ld via left vi a token used need a left binding only as a power does these are the ones that make the algorithm useful they are all straight forward to verify property i says that a semantic token pushes the input pointer off the right end of the expression whose tree it is the root properties ii iv and v together completely account for the two possible of the of left property iii guarantees that when the code of a led runs it has its left hand argument interpreted for it in left there is no guarantee that a is never an expression instead property v guards against an expression by calling a which does not know the expres sion is there property vi says that binding are only relevant when an argument is involved ii forms the by boolean combination of strings x and y where m is a string of four bits that specifies the combination in the obvious way q or if one string s before continues from the beginning of the string until both strings are simultaneously is not defined for strings of other than os and s we shall assume that led ar the functions and to call the parser and simultaneously establish a value for in the environment of the parser we write parse passing as a parameter when a led runs its left hand arguments interpretation is the value of the variable left which is local to the parser that led tokens without assumed to have for the variable also the self will have whose code is missing an explicit their and for variable as value when the are the value of their led the token error occurs in the language used for the semantic code we use a b to define the value of expression a to be the value of expression b not b itself also the value of a b is that of b the value of an expression is itself unless it has been defined ex by assignment or implicitly by procedure definition eg the value of is of we write a to mean the expression a whose value is a itself as distinct from the value of a eg be evaluated twice to yield iii x a predicate that when x is a string of all ones holds only we shall use these primitives to write a which will read a order parse it determine the truth table column for each subtree in the parse and print theorem is encountered or when at the end of the tion depending on whether the whole tree returns all ones the theorem prover evaluating the following is defined expression by led if null then generate else print self print has no argument if left then print else print parse theorem parse o o check a string x is written x this differs from x only in that x is now assumed to be a token so that the value of is the token which does not evaluate to in general to evaluate a then b re the value of b write ab if the value of a is instead write these are for sideeffects we write check x for if token advance else print missing print x halt every thing else should be since this language is the one implemented in the second example it will not to see it defined and used during the first led i left parse left parse left parse parse o to run the theorem kl parse o prover evaluate we give specifications using this approach of an online theorem prover and a fragment of a small generalpurpose programming language the theorem prover is to demonstrate that this approach is useful for other applications than just programming languages the translator demonstrates the flexibility of the approach for example exchange we might have the following a theorem theorem until we turn the machine off for the theorem assume that we have available provers semantics we the following primitives i generate and also this returns the bit string k assumed initially the first definition of the program deals with new variables without a prior meaning which is anything that needs a the first new variable will get the constant for its next then etc next is defined to work as a it to the value of its left argument the column for the whole proposition processes the next proposition by calling the parser and returns the result to the next level parser this parser then passes it to the next as its left argument and the process without building up a stack since is left associative of next is defined to interpret and return an expression the follow ing the remaining definitions should be the reader interested in how this approach to works is on his own as we mainly concerned here with the way in which the definitions specify the syntax and semantics of the language the overhead of this approach is almost the parser possibly four machine cycles or so per token not counting lexical analysis and the semantics can be seen to do almost nothing only when the strings get longer than a computer word need we expect any significant time to be spent by the logical operations for this particular interpreter this efficiency is irrelevant however for a generalpurpose the program interpreter if we so that the lexical items become pointers into a symbol table then the efficiency of interpreting the resulting string would be no worse than interpreting a tree using a algorithm as in lisp interpreters for translator above to internal an ideal compilers the next example we describe a from the language used in the trees whose format is that of the representation of lisp intermediate language for most in this example we focus on the the procedural approach gives us and the power to improve the tive of the metalanguage that we get from some of the of the theorem prover can be done away with in this way we present a subset of the definitions of tokens of the language l all of them are defined in l although in practice one would begin with a host language h say the target language here lisp and write as many definitions in h as are sufficient to define the rest in l we do not give definitions of prefix infix or here however they perform assignments to the appropriate objects eg a b performs prefix a b c sets before performing infix a b c does the same as prefix a b c except that the led is defined instead and also is done and is like infix except that replaces the variable bp is available for use for calling the parser when reading c also x does the function a b a list as parsing and it returns of expressions delimited by each one by calling parse b a lisp list of the results the object is to translate for example ab into plus a b ab into prog a b ab into prog nil a b a into a za into lambda x y z a etc these target objects are lisp lists so we will use to build them ab c translates into list a b c prefix infix prefix prefix prefix j prefix infix prefix prefix infix prefix prefix infix prefix infix infix infix prefix prefix prefix infix infix infix infix infix a fragment right is if then else advance check x i a e of the definition of l parse bp prog left right prog nil left right list right left parse bp print eval left right token g advance quote right check list check l bp o right g check s left f token then get nil is o check cond right check then right if token else then advance right advance check right left lambda g check right right is plus right is difference is times is is is log o abs g check l is append is cons car right cdr right is member is is is and so on the reader may find some of a little let consider the definitions of right the former is equivalent to parse bp the and the latter is equivalent parse and led plus left because when the of encountered while reading of it is evaluated an environment where bp by to parse right is the definitions by the parser is assigned in it is worth noting how effectively we made use of the capability in defining is which saved a considerable amount of typing with more work one could define even more facilities a useful one would be the ability to describe the argument structure of operators using regular expressions the is facility is more declarative than imperative in even though it is a program this is an instance of the boundary between declarative and there do not appear to be any reliable ways of distinguishing the two in general conclusions we argued that approaches to the writing of and interpreters were not the success one might wish for we lexical semantics operator precedence and a flexible approach to dealing with arguments we presented a trivial parsing algorithm for this approach and gave examples of an theorem prover and a trans based on this approach it is clear how this approach can be used by translator writers the modularity of the approach also makes it ideal for implementing extensible languages the of the parser makes it easy to implement either in software or hardware and efficient to operate attention was to some aspects of error detection and it is clear that type checking and the like though not in the above can be handled in the semantic code and there is no that the procedural approach will allow us to do anything any other system could do although not always as the system has so far found two practical applications one is as the frontend for the system and at ibm heights the implementation was carried out by the other application is the syntactic component of project system at mit where this approach added to extension facilities not possible with the previous precedence parser used in the was michael of acknowledgments i am to a large number of people who have discussed some of the ideas in this paper with me in particular i must thank michael fischer for many valuable ideas relevant to the implementation and for much programming help in defining and implementing a language initially and improve the system used to break in but which we hope to develop programming further in the future language for a large as a desirable number of classes of users references aho av indexed grammars jacm n on certain formal properties of grammar information and control fischer mj macros with grammar like productions ph d t university rw syntactic analysis and operator precedence jacm knuth de on the of from left to right ad control bn macros and extended translation cacm lewis pm and re syntax directed jj and db a compiler generator prenticehall inc nj ml form and content in science turing lecture jacm van a bj and on the algorithmic language alg amsterdam mr n the programming language pascal acts informatica 