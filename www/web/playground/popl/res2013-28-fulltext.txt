plan b a memory model for java david jan university inria abstract recent advances in verification have made it possible to trusted implementations of realworld languages java with its and fully specified semantics would appear to be an ideal candidate yet the complexity of the translation steps used in production virtual machines have made it a challenging target for verifying compiler technology one of key its memory model significant to such an the java memory model is an attempt at specifying the behavior of multithreaded programs in a portable hardware way while have an intuitive of the properties that the model should the specification is complex and not for integration within a verifying compiler infrastructure moreover the specification is given in an axiomatic style that is from the intuitive traditionally used to justify or rule out behaviors and ill suited to the kind of operational reasoning one would expect to employ in a compiler this paper takes a step back and introduces a memory model bmm for java we choose a pragmatic point in the design space generality in of a model that is fully characterized in terms of the reorderings it allows amenable to formal reasoning and which can be efficiently applied to a specific hardware family namely x although the bmm restricts the reorderings compilers are allowed to perform it serves as the key enabling device to achieving a verification from bytecode to machine instructions despite its restrictions we show that it is backwards compatible with the java memory model and that it does not performance on tso architectures categories and subject descriptors d programming languages formal definitions and theory f specifying and verifying and reasoning about programs keywords concurrency java memory model verified compilation introduction formally verified systems are a recent have shown that it is possible to construct reasonably efficient compilers along with a proof of correctness building on our experience with the realtime virtual machine and verified compilation for relaxed memory architectures we have on a project to produce a verified platform for a variant of the java language that by the safety critical specification for java to build a verifying compiler requires starting from a formal semantics of the source language and simultaneously developing and proving the permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright © acm x y z rz if r x else y rx y ry x if r r z figure jmm x y and z are shared memory variables ri are local in the jmm no execution yields r r r however manually reordering the writes to x and y so that they are performed in the same order in both branches allows the compiler to eliminate the conditional and the assignments above the store to r thus making such an execution alternative definitions of the jmm allow this execution but the justification is complex involving subtle notions of and nonlocal reasoning over execution traces correctness of optimizations and transformations with an associated formal operational semantics developed for each of the compilers intermediate representations all the way through to the target although we expected java to be a challenge because of the complexity of the transformations used in virtual machines like the java memory model also the task of a tractable formal semantics for the source and intermediate representations the java memory model jmm was designed to specify the behavior of concurrent programs across all modern architectures and compiler optimizations currently in use in production virtual machines the complexity underlying the jmm from the need to give a semantics to all programs even ones and the to be portable this degree of generality comes at the price of complexity when the semantics of programs key jmm notions such as the definition of a legal execution this issue remains the subject of much active research consider fig which shows a program where according to no execution can yield r r r but if the programmer were to manually the instructions in the a this result would be allowed such behavior is from the verifying compiler writers point of view the situation is not much better ­ it is an open problem to write correctness proofs for a compiler with respect to the current definition especially if the target platform enforces its own relaxed or weak memory semantics indeed even in the absence of formal proofs existing java compilers are not jmm and in the process of writing this paper we discovered that our own virtual machine was not jmm often the jmm is informally discussed in terms of allowed instruction reorderings combined with sequentially consistent sc interleavings to illustrate assume for a moment that reordering of independent statements was allowed then we could admit r r as the value of the program on the left x y rx ry y x speculative loads x y y x rx ry this would be true because after reordering the result is an sc execution with this approach reasoning would be easy ­ determining the validity of an execution would down to considering combinations of permitted reorderings unfortunately the jmm reorderings are complex and reasoning about transformations is intuitive to rule an execution illegal requires showing that it is not an sc execution if the program is free or that it includes an read formalizing these notions leads to a complex definition involving sequences this is a level of complexity that is challenging for most programmers to in four test cases from et al were found to be but a later paper using an automatic verification tool this interpretation on two of the examples such a lack of clarity for programs less than instructions long does not well for the of the model the complexity of the jmm arises in large part by its to be portable across all platforms and thus hardware but this is a challenging goal given the different relaxed memory found on modern architectures and the range of optimizations modern compilers perform many of which are often for example operational definitions of the power architecture are substantially different from those defined for x the former supports unbounded speculative executions and subtle notions of partial coherence while the latter is expressed in terms of more intuitive store buffers and limited memory reorderings it is how one might define a tractable formal language memory model that can be effectively to both neither is there a clear specification of the optimizations that to be supported of course we could greatly simplify the problem by limiting the behaviors by java with an easily understood more restrictive model such as sequential consistency valid program executions would be limited to those that can be expressed purely in terms of a sequential interleaving of thread actions but under sc reordering of reads and writes is while simple to state and easy to understand we choose to not follow this approach because sc would likely performance of java programs on all modern due to the large number of needed to enforce sc on relaxed hardware this would be especially true for programs implementing sophisticated lockfree algorithms of the kind found for example in optimized libraries such as instead we propose an alternative memory model that has a tractable semantics and designed to be mapped to x that support a total store ordering relaxed memory semantics we introduce the memory model bmm a memory model for java that can be fully characterized in terms of the memory reorderings it allows on top of sequentially consistent executions the bmm comes in two forms the first is an axiomatic specification that can be used to relate it to the jmm and which provides an intuitive method to describe valid and invalid program executions the second form is a fully operational abstract machine with write buffers attached to each thread this semantics can be readily used by a verifying compiler infrastructure like bmm is backwards compatible existing software that has been written against the jmm can be run directly since the jmm is a superset of the bmm ie every legal bmm execution is legal under the jmm this ensures that software that has been validated and tested with the jmm in mind will remain correct the contributions of this paper are thus as follows · an axiomatic definition of the bmm an alternative memory model for java programs fully characterized in term of memory event reorderings and a proof with the jmm · a formalization of bmmo an operational definition of the semantics of java programs equipped with a simple mapping to the total store order tso memory model enabling it easily be used with the x family of multiprocessor architectures and with verified compilers like such platforms · a proof that bmm and bmmo are equivalent we prove the data race freedom theorem for bmm and the of reordering optimizations under the bmm · an upper bound on the cost of preserving bmm semantics on a production virtual machine running on a tso hardware benchmark results the cost and overhead of bmm enforcement compared to implementations and an illustration of the subtle performance implications of the memory model with a case study on the implementation of locking we note that the design for the bmm is very much by our goal of constructing a verifying compiler for java as a result bmm is not intended to be generalpurpose and does not apply directly to all architectures and compiler optimizations instead we view it as a starting point for further research on verified compilation and memory models the bmm the statements of results and key lemmas are expressed in coq our proofs are rigorous but the details are available online along with the version of and llvm used in our benchmarks related work language memory models languages like java and c have sophisticated memory models to answer questions related to data visibility and updates for concurrent programs the jmm does this using that make it subtle complex and unsound and petri proved its guarantee they the of related to memory initialization by adding hypotheses and s proposed an alternative definition of the jmm that does not from these issues they restrict their definition to the finite case as we do here recently extended the formalization by including infinite executions and dynamic allocations this work proves for correctly synchronized programs such a mechanized proof is a de force since it covers a large fragment of java however the proof structure is quite different from the simulation proof we need to perform within the scope of a verified optimizing compiler there has also been recent work on memory models for c boehm and provide a semantics for free c programs including a semantics for lowlevel atomics in java it is to also give welldefined semantics to programs to avoid security weak memory model work in this area has primarily on characterizing hardware memory models early studies outlined a range of hardware memory models and to formalize the et al defined a general framework for formalizing hardware models using partial orders operational have been examined in et al define an expressive denotational framework where a memory model is a set of dynamic reorderings or splitting rewriting rules tso down to a reordering and a rule the bmm follows this line of work by providing provably equivalent axiomatic and operational models that make it intuitive and suitable to verification proofs verified compilation and weak memory models defining multithreaded semantics in terms of reordering is also the approach taken by the semantics of multithreaded c programs is defined as the interleavings of the programs possibly obtained by the syntactic transformations defining the memory model from a certified compiler perspective an operational definition of the jmm is desirable there are several attempts to provide such a semantics but none of them has been used in a proof assistant our operational semantics is inspired by the tso memory model proposed in which has been formalized in coq s identifies some trace transformations that are valid under the jmm transformations are however defined semantically this gap is filled in where the program transformations are proved to be correct but this is done under a assumption also identifies the need for characterizing memory models in terms of the transformations they permit and this is the goal of the axiomatic formalization of bmm bmm two models for the price of one while the bmm covers the whole of java the most challenging parts of reasoning about concurrent programs are those that manipulate shared memory in a potentially way following the design we separate operations that are purely threadlocal from those that deal with shared memory the bmm is parametrized by an abstract notion of semantics to deal with the former we mention a few of the highlevel concepts and our design choices before focusing on the memory model proper more details about this part of our model is in the online coq development java values the jvm operates on two kinds of values primitives and references primitives include long and double values that are bits wide updates to these variables is not guaranteed to be atomic on a bit machine our semantics captures this the treatment of references is several instruction like require reading the class of an object pointed to by a reference these operations are not relevant to the memory model because they refer to immutable metadata we explicitly avoid reading from shared memory in those cases since that would directly reasoning about the memory model instead our semantics type information to references in the spirit of of the bytecode verifier as a consequence the type of an object can be conceptually read without going to shared memory we also give to each thread its own allocation pool this matches the notion of field initialization that is in the jmm we do not need to initialize objects with a default value when we allocate them because each memory address has a welltyped initial value from the very beginning of the program execution final fields the jmm provides complex rules for fields annotated final compilers are allowed to perform optimizations on reads the surprising thing is that final fields may change between reads this occurs if the programmer leaks an object during its construction the result is a very semantics which stands more as a for the programmer who does not follow a safe publication pattern than a real semantics our position is to unsafe which happens to be a restriction imposed by safety critical java as well this allows us to keep an intuitive semantics for final fields and let compilers optimize them class initialization lazy class loading is an important mechanism for concurrent programming see for example the initialization on demand idiom our semantic supports this by tracking the current initialization status of each class synchronization actions their treatment in the paper is slightly simplified our formal semantics needs to handle more synchronization actions than those explained here for example when a thread an exception can occur if the thread has already been started it means that for a given execution and a given thread there can be only one successful spawn event but several other failed spawn events a socalled jmm edge must exist between the successful spawn and all failed spawn events a memory model we propose a memory model that can be fully characterized by reorderings over sc executions and that has a simple specification in the bmm all sc executions are allowed and any execution from which an sc execution can be derived by reordering a read action with a write action is allowed both actions must operate over disjoint memory locations and the actions can be separated by a sequence of reads that see the write action thus for instance in the following program x y x y ry rx r r is allowed it suffices to one of the threads for the result to be under an sc execution fig gives some executions thanks to this definition all three examples are easily seen to be illegal since no reordering is applicable and no sc execution can exhibit such behaviors x y x ry y rx r r is illegal x y x rx ry y rx r r r is illegal x y x rx y ry ry rx r r r r is illegal figure bmm executions a operational memory model while more intuitive for the programmer the definition of bmm lacks an operational form what we with an operational model is a companion proof technique to provide a formal correspondence proof between the different layers of a verified compiler operational semantics have been long as a within which to such proofs by the use of simulation diagrams thanks to their inductive form they can be used to reason about global program behavior in terms of elementary single steps axiomatic models generally do not the same kind of proof technique in to prove validity of some program transformations the authors had to reason on whole prefixes of traces this situation comes from the fact that in the jmm a trace of n execution steps is not easily defined in term of its n first steps at the hardware level operational semantics have been provided in it is not surprising to see that no proof the jmm with any of these operational models thus our second memory model called bmmo introduces a store buffer each hardware thread effectively has a fifo buffer of pending memory writes so that reads performed on different processors can occur before writes have propagated to main memory the two models while the axiomatic form of bmm has an intuitive definition and supports a subset of the executions permitted by the jmm its operational variant has been specified to fit within the store sc c jmm bmm theorem reordering memory accesses redundant memory accesses operational semantics semantics for all programs programmer can understand the semantics of programs sound with respect to jmm does not break java lock optimizations × × × × × × table expressivity and properties of memory models if a property holds × if it does not and if there are restrictions the models differ in the reordering they permit how they are formalized the programs they consider and their support for code bmm is weaker than the jmm in terms of allowed reorderings but its operational semantics is useful for verifying compiler optimizations and its simpler axiomatic version is easier for programmers to understand reordering memory accesses is illegal under original jmm but legal under the alternative version of operations provided by relaxed memory hardware the two models are with an equivalence proof for this purpose the bmm reorderings have been carefully chosen to with the behaviors permitted under bmmo these two semantics have different uses in sec we use the reordering view to prove the jmm compatibility in sec we use the operational semantics to study the validity of program transformations gives an overview of the properties of the bmm background on the java memory model we introduce key notions from the jmm a language memory model formally specifies what values can be read by each thread depending upon the writes performed by this thread or others these interactions are using actions actions the shared memory of a program is split into a set of disjoint addresses which are instance fields static fields or array positions but not local variables for each address x x we can determine if it is or not with the function x bool in the literature external actions are distinguished from other memory actions in this work we model external actions using writes that can be identified with the function external x bool we assume a set t of threads a set l of locks and a set v of values the set of actions is given below where i denotes the unique identifier of memory actions a v thread t writes value v to address x thread t reads from address x thread t acquires a lock on monitor l thread t a lock on monitor l thread t creates a new thread t bt thread t starts thread t detects t has terminated et thread t ends wx default write action to address x x x v v l l t t t i n eg a call by a thread t to a function f with arguments args that returns value v is modeled as a write to the abstract location we require that x action wx address x it has no thread thread start bt and end et can happen only once and thus do not require identifiers for any action a that is not a default write action we write t a the thread of this action for any write action w we write v w the value written by that action initialization actions write a default value according to the type of the related address we use some notations for sets of actions ar t t x x reads aw v wx t t x x v v writes ad wx x x ab bt t t begins as v t t x x t t l l bt et t t t ax v t t external actions the jmm is based on a happensbefore model an execution is described in terms of partial orders between memory actions the same external behavior may be associated with many different interleavings of thread actions an interleaving can be seen as a total order on actions this action occurs before that one according to global time such an interleaving is in fact a consistent extension of a partial order called happens before that precisely relates dependencies between actions for example the program fig a may exhibit an interleaving of bt bt wt x rt y wt y rt x but there is no dependency between the read performed in t and the one performed in t fig b relation behind such a linear presentation each gray region is to the actions owned by a same thread b so so t so t x x y y wt po x ry rx po rt y a code of threads t t po wt y po rt x wx wy b so so t so t po wt x po wt y po rt y po rt x wx wy b so so t so t po wt x po wt y po rt y po rt x b causality relation c axiomatic execution figure execution with and without arrows b so so so t so bt two kinds of same thread arrows po so reflects the synchronization relation between events in more complex unlike we to the jmm every address is given a default value at the start of the program even if the corresponding location is not allocated yet examples it may relate an unlock of a monitor with its subsequent lock or the write of a address with a subsequent read dotted arrows indicate which write was seen by each read action these arrows form what we call an axiomatic execution the write seen must satisfy some minimal constraints that we will make clear with the notion of wellformed execution notations when a partial order is total we write it directly as a sequence of elements that uniquely characterizes it when a partial order o is a disjoint union indexed by t of orders we write its restriction on thread t as o t a list of elements can be thought of as a total order we write a tr b when elements a b are ordered with to a list tr we call any transitive relation an order two such relations r and r are said to be consistent when they satisfy x y x we write tr a for the sequence tr to the elements of the set a definition axiomatic execution an execution e is described by a tuple e p a po so w where · p is a program and a a ad is a set of actions · po a × a is the program order a disjoint union of total orders on actions of each thread · so a ad × a ad is the synchronization order the union of a total order on a as of all synchronization actions in a and the cartesian product ad × a as · w ar aw is a function that maps each read action r from a to a write action w of a ad r and w must operate on the same address we now explain how to extract the happensbefore relation from the program order and the synchronization order of an execution definition relation an action a an action b written a sw b in an execution e p a po so w if b and a b satisfy one of the following conditions · a ad and b a ab default writes starts · a is a spawn of a thread t and b is the start of the thread t · a is a write to a address x and b is a read from x · a is an unlock on monitor l and b is a lock on monitor l · a is the end of the thread t and b is a join action on t definition happensbefore order the happensbefore order of an execution is the transitive closure of the union of its relation and its program order hb sw po semantics our formalization requires an abstract notion of semantic state and an labeled transition relation × × given to each thread t t transition labels are in the set a ar ar × v a thread can either take an action step or a step with label that is memory irrelevant for a read action step the value read is with the action in the label the requirements on the semantics are · only relates states of the same thread · there is an initial state ready no transition leads to it and a thread t steps from it if and only if it the bt action · labels are tagged with the thread · there is a final state done a step of a thread t leads to it if and only if its last transition is labeled by et definition let tr a · · · an be a sequence of actions in set a and let w be a function on a given a thread t t in program p tr is an of t if there exist s s sm m n and l l · · · lm such that · for all a a an t a t · s is the initial state ready · for all i m si li si · the projection b · · · bn of l to labels is such that bi ai v w ai if ai is a read action or bi ai otherwise we write p t for the set of such pairs tr w for p definition wellformed execution an execution p a po so w is wellformed if · a is finite · so is consistent with po · locking is proper for all lock actions a and all threads t different from the thread t the number of lock actions on l by t before in so is the same as the number of unlock actions on l by t before in so and each unlock action a occurs after a matching lock action t t l l l l · po is consistent for all thread t t po t w p t · so is consistent with w for every read r of a address x we have w r and for any write w to x different from w r either w r or w w · hb is consistent with w for all reads r of x r hb w r does not hold and there is no write w to x ie such that w r hb w hb r a distinguished of wellformed executions is the set of sequentially consistent axiomatic executions definition sequentially consistent sc execution a wellformed execution e p a po so w is sc if there exists a total order to on a such that · to is consistent with po and so · for each read action r a accessing address x w r is the last write on x before r in to the set of wellformed executions of a program forms the happensbefore memory model it is relatively easy to manipulate but it is not a satisfactory memory model because it allows values and does not the theorem the jmm considers a subset of this model these are known as legal executions the exact definition of legal executions is subtle in a a wellformed execution e is legal if there exists a sequence e e en e of wellformed executions such that in e each read a write that it does not race with then each execution ei allows some reads through data races but in a wellfounded order until the execution e itself is reached thanks to this definition one obtains almost directly that in a program all reads see writes that them and each execution is sequentially consistent and no value can be read by the causality order on races whereas the guarantee of the jmm is easily achieved the complex definition of the sequence makes it hard to justify whether a given reordering is allowed or not our approach is to define the bmm with explicit reorderings introduced in the next section bmm an axiomatic memory model we now formally define the axiomatic view of our memory model the semantics is built on top of two simple notions sequential consistency and reordering of actions the transformations of executions are expressed with the notion of local reordering definition local reordering given an execution e p a po so w e p a po so w is a local reordering of e from an action list l to a list l in thread t if · po t · l · and · l · · po t for all threads t t · for all tr w p t where tr is of the form · l · there exists · l · w p t · p t p t for all thread t t · l and l contain the same set of actions · no element of l or l is a synchronization action such a reordering is written e e intuitively we the trace po t by transforming l into l bmm two reorderings to the programmer the first one is a reordering which a read before a previous adjacent write to a different address here is a simple example x ry wr ry x definition reordering a reordering e wr e of an execution e p a po so w with respect to actions w and r in t is a local reordering e such that e e where w and r operate on different addresses fig illustrates the use of the reordering on a classical test program to understand the bmm semantics a key observation must be made the execution on the left is not sequentially consistent but after two wr reorderings we obtain a sequentially consistent execution it is then to ask if a bmm execution is any execution that can be transformed into an sc execution after x y x y wr x y r y y wr x y r y r x r y r x x r x x y wx wy wx wy wx wy b so so t po wt x so t po wt y wr b so so t po rt y so t po wt y wr b so so t so t po rt y po rt x po rt y po rt x wt po x po rt x wt po x wt po y figure reordering example some wr reorderings unfortunately such a definition would not allow us to capture executions by so we need to work a bit harder the program on the part of fig illustrates this issue in this program the configuration r r r r r is reachable under a tso architecture but it is not a sc execution and no wr reordering can be applied to this program we introduce a second category of reorderings that is allowed in bmm that permits such executions x y x y y r x x r x r x x r y r y wr r y r y r y r y r x r y wx wy wx wy so so bt po wt y po rt y so so bt so bt so so bt po rt x wt po x wr r po rt x po rt y po rt y so so bt so bt po rt x wt po x po rt y figure reordering example definition reordering a reordering of e p a po so w wrt a tuple of action w r r of a is a local reordering e such that e e reads in r r rn have w as and r and w target different addresses such a reordering is written e e in fig we apply this transformations to the previous program this time a reordering is possible and leads to an sc execution note that wr r is a generalization of the previous wr reordering we prove in sec that this new reordering exactly captures a tso operational semantics formally a bmm execution is any execution that can be transformed using wr r reorderings until reaching an sc execution definition bmm executions bmm executions are bmm n e e e ro e o and e is sc with ro we write for the set of executions of a program p the bmm observable behaviors of a program p is then defined as the set of sequences of external actions ax p a po so w o the definition of bmm is a least every time we must prove that bmm is included in some set of wellformed executions we can rely on the following characterization lemma bmm least bmm is the least set s of wellformed executions such that · all sc executions are in s · s is by bmm reorderings for any wellformed executions e e such that e ro e if e s then e s proof first bmm satisfies the two above properties now let s be a set of wellformed executions satisfying both properties we show that bmm s let e bmm if e is sc then e s otherwise there exists an sc execution e such that e ro e but e is in s so e is in s too we use this lemma to show that bmm is a subset of the jmm executions and to show the equivalence between bmm and bmmo bmm is a subset of jmm the current java memory model defines the set of legal executions as a subset of all wellformed executions that are using a sequence of intermediate in order to connect our model with the jmm rather than unfolding the details of this formal definition we rely on the following jmm properties · jmm accepts all sequentially consistent executions · jmm allows reordering of memory accesses different locations theorem let jmm be the set of all legal executions permitted by the jmm then bmm jmm proof we use here lemma we first know that jmm contains all sc executions then suppose that e ro e with e jmm in the jmm reordering non memory accesses different addresses is allowed we use this property to e into e hence e is also in jmm meaning that jmm is by wr r guarantee we establish that bmm the important property that any reasonable memory model should have namely a guarantee free programs have sc executions only we first define the standard notions of concurrent conflicting memory action and programs definition conflicting actions two actions a b ar aw are conflicting if they target the same address and t a t b and at least one of them is a write definition let p a po so w be a bmm sc execution two conflicting actions a b form a if they are not ordered by hb definition a program p is free written p if all of its sc executions are free of theorem guarantee for all p if p then for all execution e e is sc proof let p be such that p and e by theorem e but jmm satisfies the guarantee so e is sequentially consistent bmmo an operational memory model in this section we provide an operational view of the bmm the reorderings allowed in its axiomatic version can be implemented by a bmmo machine that a to each running thread the bmmo semantics is also parametrized by an semantics hence we need to consider an extra set of actions the s ts b m t s b m ts t s w m x read ts b m s b m s write ts b m s bt v bt m bt l · v ts b m ts bt l mx v ts m synch ts m bt synch ts b m ts b m figure bmmo machine labelled transition system actions in that are either the ba of a write action a aw ad by thread t a or a step t by thread t ba t the idea behind bmmo is to provide a generative operational machine that executes an input operational execution modifying a memory state made of thread buffers and a shared memory the input of the bmmo machine is an operational execution made of a program and a trace of operational actions an operational action a is either an action in a ad ar or a pair in ar × aw for each read action we record the write action that it and refer to it as its or a action in definition operational execution an operational execution is a pair p tr where p is a program and tr is finite and such that no action appear more than once in tr the bmmo machine is then defined by a transition system parametrized by an semantics we now describe its states and transitions a bmmo state state is a record ts t state of threads b t ad one buffer per thread m x aw one write action per address the state first keeps track of each state in each thread is given a write buffer all write actions are first written to this buffer when these writes are committed to the shared memory m that maps addresses to write actions given a memory state buffers b and memory m the bmmo machine specifies the write action a thread t can read when accessing the address x w if w is the first write to x in bt m x mx if there is no write to x in bt if a pending write to this address appears in the buffer of t we take the most recent in the execution ie the first in the buffer otherwise we the memory if no write has been performed yet at this address we will the default value for this address the bmmo machine is defined as a labeled transition system where steps are labeled by operational actions the semantic rules are given fig in all rules except the bmmo machine makes a step that the semantics can match rule corresponds to a step when eg the thread operates on registers the bmmo memory state does not change in this case on a read read the value is obtained from s w mx ts m s m s ts m synch s mx v bt s begin ts m bt synch s m s t spawn ts m st ready m s lock ts m synch s m et s ts m et synch ts t s end m done s join ts m s m s unlock ts m synch s m figure bmmo machine synchronization actions the memory state using the rd function for this action the event is a pair v composed of a read and a value the semantics accepts any value here but the purpose of the rule is to constrain it using threadlocal buffers and shared memory on a write write the write action is put onto the threads buffer a write action can be at any time in which case the write is committed into shared memory all actions are by threads whose buffers are empty they are under the synch rule whose definition relying on a relation · synch is in fig reads from and writes to locations directly access the memory so that all threads have a consistent view and when a thread ends end its state is kept in the bmmo state enabling other threads to join it join and preventing it to from being spawn we then define a bmmo execution as a constrained operational execution that is accepted by the bmmo machine the input trace is properly locked and can be executed by the machine with the intended meaning that the input execution is consistent definition bmmo execution an operational execution p tr is in if there exists states s s sn in state satisfying the following · tr is properly locked see definition using tr instead of po and so · s is an initial state the memory maps every address to the corresponding default write x mx wx buffers are empty and sts is defined for exactly one thread mapping it to the ready state · tr a · · · an · for all i n si ai si the bmmo behaviors of program p are external action traces obtained by all executions of p accepted by the bmmo machine on ax tr ax p tr equivalence of bmm and bmmo we show that bmm and bmmo are equivalent relaxed memory models they allow the exact same set of behaviors for any program theorem for all program p the proof relies on an operator that the gap between bmm and bmmo by building axiomatic executions from operational ones definition operator let eo p tr be an execution is defined as eo p a po so w where · a is the set of actions in tr · for all a b a b iff t a t b and a tr b · for all a b a b iff a b as and a tr b · for all pairs w in tr w w we show that bmmo bmm each inclusion is proved and theorem follows from the following lemma lemma let eo p tr be an operational execution and p a po so w eo then tr ax so ax proof by definition of we know that for all a b a b iff a b as and a tr b we define auxiliary notions needed for the proof an operational execution eo is wellformed if eo is wellformed and it is sc if eo is sc similarly we define operational reorderings relying on an execution eo is an operational reordering of eo if eo eo we notations and write it eo eo and lift this notion to trace reorderings ro to the notations in this section we keep implicit the unique identifier of actions and write for v the value written is omitted when considering operational actions in a trace we generally omit the write action w attached to a read action bmmo bmm we prove that every bmmo execution trace can be into a sc trace the proof relies on a reordering scheme explained in the following lemma lemma let eo p tr with tr · an execution such that we write · wt y x write actions belonging to thread t · rt · · y x read actions a write performed by t in · · wt rt the remaining actions in then there exist p such that eo p tr eo ro eo and tr · · · where · · contains the elements of wt rt · · matches the pattern · · n n · for all p tr · then p tr · before going into the detail of the proof we give an intuition on how we use it this lemma is applied to a part of an execution in which a write action performed by t in its buffer this is illustrated in the following figure where the grey regions denote of actions whose thread is not t the action is the write action that remains in ts buffer until the end of tr we will use this action as a pivot on all the actions performed in the rest of tr so that the resulting trace tr is as illustrated a all grey actions are before the pivot remaining in the same relative order by changing the interleaving b actions of thread t are handled with the wr r reordering rule because write actions of t cannot be moved they are kept to the right of the pivot tr tr handling read actions of t is more involved either they see a write that occurred necessarily in thread t after the pivot in tr and they are in a pattern · · n n or they see a write that occurs before the pivot and wr r is applied repeatedly on this pattern until they are before proof let eo p tr with tr · · and the · can be decomposed as · p · t with p we take the shortest t we now proceed by induction on the length of t · base case t is empty we dont need any reordering transformation to reach the expected pattern · inductive case we proceed by case analysis on the first element of t a t and show that a can be either i integrated inside the pattern p or ii be moved before this pattern if a when k is one of the addresses of p here we integrate in p by applying an wr r as many times as needed to make it part of the right pattern such that p p · · p note wr r can be applied because the pattern only concerns thread t and the visibility conditions required by wr r are the rightmost such pattern before a ie such that there is no in p is the only one that can ensure the of a to be preserved according to bmmo thus the resulting trace p · p · a · p · is bmmo if a when k is not any of the addresses of p we apply the same reasoning as in the previous case rewriting the trace with wr r but in this case this simply amounts to put a before because wr r will be applied on the whole p and the is trivially kept valid if a ba then a because there is no action in p this could have been done just before this does not modify the visibility constraints of the new trace as it cannot any of the write actions in p for any trace if p · p · a · t · then the trace p · a · p · t · is also in bmmo p any read in that a in the first trace can still see it in the second trace because no write action in p is before for all other cases a where t t a with t t and a as we can just change the interleaving to move a before p and conclude easily for each resulting trace we show that we are under the induction hypothesis premises hence we conclude by induction this reordering scheme is extensively used for proving lemma stating that the reordering interpretation of bmm can be simulated in the operational world lemma let eo p tr then there exist p tr such that eo ro p tr with p tr is sc in order to prove the lemma by induction we need to prove a stronger result that includes an additional property on the shape of the two operational traces tr and tr this socalled property is formally defined as follows definition let tr and tr two sequences of actions the property holds on tr tr if for any write actions w w to the same address · if w tr w and w tr w write actions have been then the trace tr is of the form tr · w · · w · and bw · if w tr w and w tr w write actions have not been then if bw occurs before w in tr it is also the case in tr proof we prove lemma by strong induction on the size of the execution tr n assume the property holds for any integer k n let eo p tr an execution of size n we assume n the case n holds trivially so tr is of the form tr tr · a by induction on tr we get p and tr such that p tr ro p tr with eo p tr sc plus a on tr tr we extend eo to p tr · a if action a is not a read action we can conclude directly otherwise a the extended trace is in and the property holds it remains to show that it is sc if it is not we proceed by case analysis case there is a thread t t whose buffer is not empty at the end of tr formally there is a write action in tr such that tr tr a is of the form · · · applying lemma on we get p and tr such that p tr a ro p tr with eo p tr and tr · · · · with · matching the pattern by induction on · · we get p and tr such that p · · ´ ro p tr with eo p tr sc plus a property on the traces we the suffix · to extend tr to an execution in the sequential consistency holds thanks to the pattern of · the is preserved by the concatenation case all threads distinct from t have their buffer empty at the end of tr formally for every write action tr such that t t tr let be the write seen by · if tr it means that t t the trace tr a is of the form · · · we apply lemma on the trace · · · we obtain is in bmmo and by the shape of and it is sc we must show is now the most recent write to x in but any other write there would be from thread t and could thus not see · if tr then the trace tr a is of the form · · · · · no more recent than can appear in either it is in and it would or it is not but then t t and could not be seen by no can either appear in since it would by lemma on and we get a trace tr such that tr in this trace the most recent write to x is now the · · is sc because · was it remains to show that all reads in still see the most recent writes by induction on tr · · an sc execution is that keeps the same finally we obtain the first inclusion as a corollary of lemma corollary bmmo bmm proof let eo p tr by lemma we have eo ro eo with eo p tr is sc by definition eo ro eo and eo is sc hence eo bmm bmmo we use here the characterization of bmm lemma we first show that bmmo contains all sc axiomatic executions let e p a po so w bmm be an sc execution then there exists a total order to on a compatible with po and so such that all read actions in a see the last write to their address wrt to we claim that eo p tr can be build with tr and that eo actions are inserted in to so that each write action is immediately and that tr is consistent ­ an equivalent condition was required for e finally eo e we also show that bmmo is by wr r let e and e two wellformed axiomatic executions such that e bmmo and e e e bmmo so there exists eo bmmo such that e eo wr r is a valid transformation under bmmo see sec meaning that there exists eo bmmo such that eo e hence e bmmo validity of transformations one of the objectives of any memory model is to take into account the reorderings performed by the hardware and to allow compilers to perform some program transformations that deal directly with memory accesses or locks gives standard transformations and their validity under various memory models for a proof of validity we rely on the operational model we consider a bmmo trace of a transformed program and show there exists a valid bmmo trace of the original program with the same behavior for a proof of we provide a counterexample and use the intuitive reordering memory model of bmm given a program p and a transformed program p we show that there exists an execution that is valid for p but invalid for p both under bmm this table demonstrate that despite its restricted set of reorderings bmm allows useful transformations validity of wr and wr r among the set of transformations the validity of the local reordering wr r is crucial for the memory model inclusion definition valid reordering a local reordering between axiomatic executions is said to be valid with respect to bmmo if for all axiomatic execution e and all operational execution eo e eo and eo bmmo implies that there exists eo bmmo such that e eo we can show that both wr and wr r are valid transformation trace preserving transformation reordering normal memory accesses redundant read after read elimination redundant read after write elimination irrelevant read elimination irrelevant read introduction redundant write before write elimination redundant write after read elimination reordering sc jmm bmm × × × × we write for a valid transformation and × when it is generally wrong for limited applicability only wr r applies to normal memory accesses a read can be delayed past a lock and a write can take over an unlock table validity of transformations in memory models lemma wr is valid proof let e p a po so w be an axiomatic execution and eo p tr an operational execution with e wr eo and eo bmmo by hypothesis we know that tr · · · v · and does not contain any action owned by t except some actions the write action v can be performed just after since the in are independent of it and no read action in can see v it is still in its buffer hence the trace · · v · · is still in bmmo for the same and information after a swap we obtain a trace tr · v · · · that belongs to by definition of wr and p tr e lemma is valid proof let e p a po so w be an axiomatic execution and let eo p tr be an operational execution such that e eo and eo bmmo by hypothesis the traces tr is of the form tr y · · · each n does not contain any action owned by t except some actions as in the previous proof the action v can be performed just after all read actions y y see the write v in tr and can thus also be performed earlier the trace y · · · · · · is still in for the same and the moved reads see v directly from ts buffer we then conclude with a swap the trace tr · v · y · · · y · x · · · · · n · belongs to and p tr e other valid transformations given e p tr for each transformation we observe the shape of tr and provide a corresponding bmmo trace of an program we assume that the semantics accepts the transformation all read and write actions are redundant read after read elimination tr · · trace · · · is in bmmo and see the same write redundant read after write elimination tr · v · trace · v · · is in bmmo v in its buffer irrelevant read elimination tr · trace · · is in bmmo the first write to x in the buffer or pick the current write attached to x in memory irrelevant read introduction tr · · trace · is in bmmo the visibility of the other actions is preserved redundant write before write elimination tr · v · we distinguish two cases if · v · the trace · v · y v · · v · y v · is in bmmo adding the preserves the visibility of v since v is never seen otherwise v the trace tr · v · v · is in bmmo v is never seen reordering a read before a lock can be no action by the thread t in tr · · · x · we assume tr is properly locked so no synchronization action on l is in hence the following interleaving is a valid trace of the transformed program · · · · then the trace · · x · · is in bmmo reordering a write after an unlock can be since the buffer must be empty the transformed trace has the following shape where v is the last non action of thread t tr · v · · v · · l · there is no action by thread t in except some no action in by the other threads can see the write v then changing the scheduling we can obtain the following bmmo traces · · v · v · · l · by hypothesis there is no action by the thread t in besides there is no action on l in therefore changing the scheduling again can lead to the following bmmo properly locked trace · · v · v · · · finally the following trace is a bmmo execution of the program · · l · v · v · · invalid transformations the bmm helps understand why some transformations are invalid redundant write after read elimination here v is x y x y rx y xr rx x v ry write after read rx y rx x v ry r r r invalid r r r valid on the left we see why the execution is not valid it sc and no reordering is possible after the redundant write elimination the execution becomes valid because the read rx can be with the write y to give a sc execution this transformation thus introduced new behaviors reordering reordering reads and is not allowed here the reads cannot both see the default writes whereas they could if one of them was into the critical section and with the write reordering reordering writes and locks is not allowed the reads cannot both see the default writes whereas they could if one of the writes was into the critical section and with the next read x lock l x unlock l ry x x lock l ry unlock l y lock l y unlock l rx y y lock l rx unlock l empirical evaluation of the bmm we have shown that bmm is more restrictive than the jmm it is therefore natural to ask how these restrictions are in practice ie what is the performance impact imposed by bmm when incorporated within a production virtual machine running on a tso architecture in this section we present results from a preliminary study that provides a approximation of the overheads by bmm our experiment is as follows starting with a production virtual machine we switch the from a optimizing compiler to one that preserves tso semantics then we modify any optimizations performed by the vm to be bmm we expect that the performance results are going to be an upper bound on the costs of bmm since we limited the optimizations performed by the vm and that they precisely respect the reorderings allowed by bmm this enforcement is realized through the injection of memory operations that effectively the contents of store buffers we make no attempt to optimize or verify the placement of such specifically we start with the realtime vm we selected because it has performance we understand the optimizations it performs well and it is representative of a realworld system the compiler takes bytecode as input and in the configuration we use here transforms it into c code which is to gcc the compiler includes a variety of classic optimizations as well as techniques to achieve bmm in the we replace gcc with an llvm branch with optimizations either modified or to preserve with the tso memory model this is a close approximation of what we would write to support bmm in the within we carefully examined all optimization passes to ensure with bmm redundant code elimination is the only optimization for which could not be guaranteed is performed over local operations as well as heap loads as a result the optimization permits or operations to be bmm semantics we modified the optimization to processing any heap loads we evaluated the modified system on a variety of benchmarks including and a subset of mr release and release the whole benchmark suite is a mix of concurrent and sequential programs which we think are well suited to exhibit the overheads of optimization opportunities and the concurrent programs we consider are and the experiments were run on an core processors and gb memory machine with linux kernel was executed for iterations with the first iterations being we report the mean of the last iterations the standard was the and benchmarks were all executed with their default configurations except that the bmm db figure vm execution time normalized to jmm configuration see for configurations name jmm bmm jmm bl bmm bl llvm regular tso regular tso regular modified regular modified off off on with no on with table evaluation configurations was set to the maximum possible and that the number of for and the number of threads for were set to to exercise the maximum concurrency we evaluate how bmm performance by examining performance relative to a system that uses an version of and llvm in this configuration there are no optimizations that are either modified or within either or llvm specifically the implementation allows to perform transformations and llvm to perform reorderings the results are shown in fig with column bmm the numbers are normalized with respect to this first observe that adding tso support to llvm and has almost no impact on performance on most of benchmarks with the exception of and for the former bmm is faster while slower for the latter the average is in general these results provide evidence that bmm is essentially performance neutral on more relaxed architectures the is of course likely to be different locking while the code of the vm we upon an interesting optimization has several implementations of the java concurrency control primitives one optimization that is supported is called locking locking is an implementation of locking operations that is efficient when one thread repeatedly acquires and the same monitor a pattern that is in java roughly a monitor can be to one thread that can then acquire and release it without any synchronization however when a thread needs a lock that is to another thread that needs to be using instructions as shown in fig under column on locking in results in a maximum speed up of roughly and an average of this optimization thus appears to be important to performance locking is implemented without any cas or although we believe this is what most of modern java vm do its correctness is given the current formal definition of jmm locking implies a reordering and this kind of reordering has been shown to be invalid by according to the and other locking is permitted under jmm but to the best of our knowledge there is no formal proof on the number of required to ensure correctness the bmm requires two as we will prove next one at the lock and one at the unlock with two the benefits of locking is at best and on average validity of locking we explain how to reason about locking under bmm since the implementation of the locking mechanism cannot be described with java constructs only we introduce two actions available only at a language in the compilation chain a memory ft and a unlock the memory can be by a thread if and only if its buffer is empty the effect of the action is to ensure the buffer is empty prior to any subsequent action being performed ft s ts m ft synch s m the unlock models the revocation this action is taken into account as a regular unlock in what makes a trace properly locked however it imposes no restrictions on the state of buffers s ts b m s b m at this level of abstraction we do not describe how the locking is to be implemented but the intuition is that the conjunction of a and a unlock corresponds to an unlock the general case of a thread the same lock can be seen as a trace transformation there is no ltl in and no ltl nor in · · · l · · l · bl · · · ft · · ft · this transformation is indeed valid consider a bmmo execution p tr with tr · · · ft · · ft · if the semantics allows to replace the first by an action l and the second one by an action then the trace tr · · · l · · l · is also bmmo the rule ensures that when the ft action is the buffer of thread t is empty so the rules can be applied moreover the trace tr is properly locked the revocation of a lock corresponds to the following trace transformation · · · l · · bl · · · ft · · l · since there is no lock on monitor l in if the transformed trace is properly locked then so is the initial one the action ft ensures ts buffer is empty after the unlock rule can thus be applied conclusions this work presents bmm a memory model that has been designed as part of a to build a verifying compiler for multithreaded java the key characteristics required for such a memory model are both for programmers and compiler writers and a practical realization within a compiler framework that does not impose restrictions on important program optimizations we believe bmm is a promising step in this direction its axiomatic definition is expressed using intuitive and simple memory reordering notions making it suitable for reasoning about program transformations while its operational view can serve as a basis for a verifying compiler infrastructure its backward compatibility with jmm entails that we can use bmm on code it thus provides a key missing piece for a verified infrastructure for java on the x processor family the question of how to obtain a more relaxed model one that would allow efficient implementations on architectures such as power and arm while at the same time remaining amenable to within verified compilers remains a subject for future research although these more relaxed platforms still guarantee coherence all threads must respect a single linear order of writes they allow other behaviors such as writes speculative execution etc as well as having a substantially more complex notion of dependence these make formalization and axiomatic reasoning challenging we believe that more experience with bmm with respect to both applications and optimizations is necessary before we can the underlying our development here to these other environments acknowledgments we would like to thank boehm petri s and peter sewell for their useful feedback on this work we thank for his help with references s v and k shared memory consistency models a computer s v and m hill a unified formalization of four models par and systems ieee transactions on j l s sarkar and p sewell in weak memory models in proc of cav d and j s java memory model examples good bad and in proc of d and j s data race free guarantee in proc of boehm and s v foundations of the c concurrency memory model sigplan not g and g petri relaxed memory models an operational approach in proc of popl g and g petri a theory of speculative computation in proc of esop s m and v verifying local transformations on relaxed memory models in proc of cc p a and e the java memory model operationally in proc of esop b t j j d and d java concurrency in practice addisonwesley t j d k m and j java for applications in l j and n defining and comparing memory consistency models in proc of l t v and d enforcing secure object initialization in java in proc of m and g petri the java memory model a formal explanation in proc of r c and j generative operational semantics for relaxed memory models in proc of esop k a and t lock java locks can mostly do without atomic operations in proc of oopsla g and t a model for a language virtual machine and compiler acm trans program lang syst l lamport time clocks and the ordering of events in a distributed system acm x leroy a formally verified compiler j reasoning a java and the java memory model ­ a unified in proc of esop j w and s v the java memory model in proc of popl d a t d m and s a case for an compiler in proc of pldi a static analysis of runtime errors in embedded critical parallel c programs in proc of esop s s sarkar and p sewell a better x memory model in proc of f l e p and j highlevel programming of embedded hard realtime devices in proc of w the initialization on demand idiom w causality test cases for the java memory model k russell and d eliminating atomic operations with locking and in proc of oopsla s sarkar p sewell f z s t t m o and j the semantics of multiprocessor machine code in proc of popl s sarkar p sewell j l and d understanding power in proc of pldi j s program transformations in weak memory models phd thesis the university of edinburgh j s safe optimisations for concurrent programs in proc of pldi j s and d on validity of program transformations in the java memory model in proc of ecoop j s v vafeiadis f z s and p sewell concurrency and verified compilation in proc of popl p sewell s sarkar s f z and m o a rigorous and usable programmers model for x acm e m and j checking axiomatic specifications of memory models in proc of pldi v vafeiadis and f z verifying elimination optimisations in proc of sas 