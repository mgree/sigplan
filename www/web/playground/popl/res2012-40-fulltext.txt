the ins and of gradual type inference university advanced technology systems abstract gradual typing lets programmers their dynamically typed programs by adding explicit type annotations which benefits like improved performance and fewer runtime failures however we argue that such evolution often requires a and that type inference can offer a crucial missing step if omitted type annotations are interpreted as unknown types rather than the dynamic type then static types can often be inferred thereby removing unnecessary assumptions of the dynamic type the remaining assumptions of the dynamic type may then be removed by either reasoning outside the static type system or the code we present a type inference algorithm that can improve the performance of existing typed programs without introducing any new runtime failures to account for dynamic typing types that flow in to an unknown type are treated in a different manner than types that flow out furthermore in the of an escape analysis is to decide which types are safe to infer we have implemented our algorithm for and evaluated it on the and v benchmark we demonstrate that our algorithm can improve the performance of programs as well as recover most of the type annotations in annotated programs categories and subject descriptors d programming languages f logics and meaning of programs semantics of programming analysis f logics and meaning of programs studies of program structure general terms algorithms languages performance theory keywords gradual typing type inference introduction gradual typing and programming gradual typing aims to combine the benefits of static typing and dynamic typing in a language in a typed program dynamically typed code can be mixed with statically typed code while the dynamically typed fragments are not constrained to follow the structure enforced by a static type system the statically typed fragments not only some static safety guarantees welltyped programs cannot be blame theorem but also permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ pa usa copyright c acm admit performance optimizations that the dynamically typed fragments do not gradual typing a style of programming where dynamically typed programs can be into statically typed programs by off in code structure for of safety and performance although there has been much recent progress on the of gradual typing a key has been largely inference the only previous work on type inference for typed languages is based on unification which is for use in objectoriented languages with subtyping unfortunately as we argue below the lack of type inference may be the most significant towards the style of programming by gradual typing the key missing type inference in a typed language a program may be partially annotated with types any missing types are uniformly assumed to be the dynamic type this means that the fragments of the program that have missing type annotations do not any of the benefits of static typing in particular their performance is by dynamic casts even if they implicitly satisfy the constraints of static typing ie even if the dynamic casts never fail to improve performance the missing types have to be declared however in our experience with a typed language the task of dynamically typed programs to statically typed programs by missing types can be quite the annotation burden is often in the limit types must be declared for every variable in the fragment and the programmer may need to several annotations to satisfy the constraints of the static type system furthermore the programmer may eventually be forced to declare dynamic types for some variables it may not be possible to satisfy the constraints of the static type system without the code this is because the programmer may be relying on an invariant that cannot be expressed via static types in the language ie the proof of safety may rely on a form of reasoning typically that is outside the scope of the static type system unfortunately due to these difficulties typed programs often continue to miss out on important benefits of static typing such as performance optimizations consequently programming remains a the of the problem is that a missing type is as the dynamic type whereas the intended interpretation is that of an unknown type often an unknown type can be inferred to be a static type in contrast the dynamic type is a to encode a variable must be of the dynamic type when the set of values that the variable may denote cannot be expressed as a static type in the language thereby forcing in the type abstraction therefore we an iterative process for evolution of dynamically typed programs to statically typed programs that between two states in one state type inference removes un infer types annotate figure iterative evolution of scripts to programs necessary assumptions of the dynamic type so that elimination of any remaining dynamic types in the code requires either reasoning outside the static type system or the code in the other state the programmer either introduces further type annotations or parts of the program to to the static type discipline furthermore at any state the programmer may decide to the evolution process the program and take advantage of the improved precision of static types that have already replaced dynamic types in the program at a later point the programmer should be free to resume the evolution process this process is depicted in figure since the programmer may choose to an existing program type inference must ensure that the program remains it should have exactly the same runtime behavior after type inference as it would have before type inference in particular if the program was safe did not fail at run time then it should continue to be safe and any other programs that ran safely with the program should continue to run safely type inference on typed programs in this paper we study the problem of type inference in an existing typed language the practical motivation for our work is to improve the performance of existing programs under the our aim is to let existing programs the benefits of typedirected performance optimizations as much as possible while remaining on the other hand our aim is not to eliminate runtime failures in existing programs indeed any runtime failures need to be preserved as well thus the static types we infer may not satisfy some static safety guarantees such as the blame theorem nevertheless the static types we infer can improve performance since they soundly approximate precise sets of runtime values thus we prefer to infer static types where possible rather than back on the dynamic type of course it remains possible to recover static safety guarantees by some opportunities for can fall back on the dynamic type whenever the inferred static type may be cast to an incompatible type design challenges the aim of our type inference algorithm is to reduce the associated with dynamic types so that programs with missing type annotations can benefit from various performance optimizations we try to infer for each variable a precise type abstraction of the set of values that flow into it the setting of a typed language and the requirement of present several unique challenges as outlined next in a purely static type system the definitions of a variable determine a lower bound on its type since the type must admit every value into the variable the uses of a variable determine an upper bound on its type since the type must admit only those values that are by the type of every context to which the variable flows out thus for a type that satisfies both sets of constraints it is possible to prove statically that every use of the variable is safe for every definition of that variable in contrast in a gradual type system every use of a variable need not be safe for every definition of that variable instead runtime failures may be avoided if each use is safe for some definition thus the type of a variable must be inferred by considering only its definitions type checks on its uses until run time furthermore the type of a variable may only be inferred if it is local ie if all of its definitions are visible during compilation in the absence of this guarantee we cannot the possibility that values of an type may flow into the variable at run time for example consider a parameter of a global function which can be defined by arbitrary arguments through calls that are not visible during compilation in such cases replacing the variables assumed dynamic type with an inferred static type may break the program in some unknown runtime environment based on these observations we infer types of only those variables for which we can infer the types of all values in ie their and we derive the solutions by computing the least upper bounds of those types without checking that the solutions satisfy the greatest lower bounds of the types of the contexts to which they flow out ie their higherorder values such as functions and objects present some interesting there is an immediate problem if we take the standard least upper bounds of their higherorder types since we will then be taking the greatest lower bounds of the input negative parts of these violates the principle we motivated above giving us safe types rather than precise types for the input parts of the higherorder solution another possibility might be to take the least upper bounds of both input and output parts following subtyping however this also is not quite right since we are still to observe the types of the actual inputs eg the types of arguments in calls to a function rather as with standard subtyping we are still considering the types of values that such a function considers safe to input ie the functions parameter types the key insight is that if we are to the principle of solving based on alone we must recursively higherorder types down to their firstorder parts solve for those based on eg the of arguments to the parameter of a variable and then the higherorder parts in such a way as to preserve the desired we an elegant way of inferring such higherorder solutions via a notion of kinds this requires us to treat higherorder in a different manner than higherorder section another arises when local functions and objects escape in this case we cannot infer the parts of their types in negative input positions since values may then flow into them from some code that cannot be analyzed at compile time therefore it seems that we need some kind of escape analysis to figure out if some local function or object escapes perhaps surprisingly the escape analysis we require is carried out for free by our algorithm it suffices to assume that in the enclosing programs type the parts in negative positions are either explicitly annotated or are the dynamic type section guarantees our main guarantee is that the type inference algorithm is sound if a program fails at run time with our inferred types it would have failed at exactly the same point with the dynamic type the soundness guarantee is compositional in the sense that it holds even when the program is placed in an arbitrary runtime environment furthermore we show how to recover solutions from our inferred types that satisfy the blame theorem we also prove that the time complexity of our type inference algorithm is quadratic in the size of the input program implementation and evaluation we have implemented our algorithm for and evaluated it on the and v benchmark overall we are able to subtyping is covariant in both negative and positive positions unlike standard subtyping which is contravariant in negative positions achieve x performance improvement on average over partially typed benchmarks with type annotations only on required parts of the interfaces with a maximum performance improvement of x section contributions to summarize we make the following main contributions in this paper · we argue that the evolution of typed programs is essentially an iterative process with type inference being a key missing component · we design a type inference algorithm for typed languages with the goal of improving the performance of programs as much as possible while preserving the runtime behaviors of programs our design involves new ideas that are specific to the setting of a gradual type system and the requirement of such as the need to treat definitions and uses and the need for escape analysis to decide what types are safe to infer · we formalize our type inference algorithm in a core calculus of functions and objects and prove soundness and complexity theorems for the algorithm technical in our algorithm include a notion of kinds to compute precise higherorder solutions and the encoding of escape analysis as a syntactic condition on the programs type · we implement our algorithm for a typed language and evaluate its effectiveness with results overall we believe that the techniques and insights developed in this paper will the of type inference for typed languages and further research in this area overview algorithm while existing compilers for typed languages such as consider missing type annotations to be the dynamic type our aim is to infer precise static types where possible and fall back on the dynamic type only where necessary as usual our type inference algorithm begins by replacing missing type annotations in the program with fresh type variables then we compile the program using type annotations to generate coercions between types a coercion is of the form s t where s and t are types such a coercion witnesses the flow of a term of type s into a context of type t in particular coercions involving type variables are interpreted as flows for those type variables for example if x is a type variable then t x is an for x whereas x t where t is not a type an for x starting from the original set of coercions collected during compilation we now iterate generating new coercions from existing ones using carefully designed rules which treat the implications of and differently at each step new coercions represent flows that are implied by but are not directly expressed by coercions iteration continues until our rules can produce no new coercions at which point we have a closure of the flows implied by the type annotations in the program for each type variable x we can now derive a solution namely the least upper bound of all types t that can flow into expressed by coercions of the form t x a formal treatment of the algorithm is presented in section we now demonstrate the fine points of the algorithm viz the computation of closures and the derivation of solutions using examples in is an extension of javascript with a gradual type system and is the programming language underlying applications we show type variables as part of programs below although they are not part of in actual programs these type variables are just missing annotations we follow the convention that type variables in have similar names as corresponding variables with the first letter for example the type variable for an variable foo in the program is written as foo if foo is an function foo represents the type variable for the parameter type of foo and foo represents the type variable for the return type of foo the dynamic type is denoted by number and boolean are base types we also use to denote the bottom type although it is not part of for the purpose of our examples operators are typed as follows number number number number number boolean local variables having base types we start with a simple example to show how our algorithm infers primitive types for local variables in a function and how it improves performance function var var index n index index sum sum index return sum in the absence of type inference index and sum will be given type since the operator has type number number number evaluation of index and sum index will cause in runtime conversions number for index and sum to store the results back to index and sum further runtime conversions number will happen as we show later in our experiments such runtime conversions can the performance of programs we now show how our inference algorithm works after adding type variables for missing types as shown we compile the program and collect coercions the of index and sum on lines and generate number index and index sum the operations index n index index and sum sum index on lines and generate index number number index sum number index number and number sum to solve these flows we note that the only type into index is number so we infer index number next we see that types into sum are number and index therefore the solution for sum is the union of number and index which is number and finally the only type into foo is sum so foo number as well annotating index and sum with number rather than improves runtime performance by eliminating unnecessary runtime conversions between number and in the loop body note that we also generated sum number and index number but did not use them for inference a typical type checker will check that the solutions of sum and index satisfy these but we skip this step we say more about why we do so in section local variables having function types unions of function types are problematic when a base type like number or boolean flows into a type variable the solution of the type variable is simply that type and if several base types flow in the solution is the union of those base types unfortunately the obvious ways of generalizing this approach to higherorder types like function types do not work for example consider the following program var xx x on line we generate number x thus we may infer the solution of x to be the type into it number however a more precise solution is number number based on the fact that the only values into the parameter of the function stored in x are of type number line furthermore when several function types flow into a type variable we cannot combine those by taking the union of all such types consider the following example var xx x x else x we generate number number x from line and boolean number x from line since the union of two function types is a type s t where s is the intersection of their parameter types and t is the union of their return types we would infer x to be number using the standard approach this would mean that in the running program any application of x to a number or a boolean value would result in an error this is clearly unsound as the programmer applies x to a number at line and to a boolean at line both of which are safe kinds as higherorder solutions to deal with higherorder types we introduce a notion of kinds a kind can be thought of as a view of a type variable it describes a structure and introduces type variables for the types of parts within that structure coercions between type variables and kinds are generated during compilation and closure computation in either direction a coercion from a type variable t to a kind k witnesses the flow of t typed values into a context whose higherorder type is by k conversely a coercion from k to t witnesses the flow of higherorder values of kind k into a t typed context for example on line the function call x induces a view of x as a function type to realize this view we generate the coercion x x x where x x is a kind for x corresponding to function types this witnesses values of type x to a context in which they are used as functions we also generate number x which witnesses the flow of arguments of type number into the parameters of those functions combining number x and x x x we get number x x this flow using for the parameter type and for the return type we get x and number x intuitively these coercions witness the flows into and out of the concrete function value assigned to x on line resulting from the call to x on line solving these flows we obtain x number and x number but what should xs solution be we claim it should be xs function kind ie x x which after substituting for x and x becomes number number our closure rules introduce the necessary intermediate step the coercion x x x as a consequence of the assignment on line thus a kind not only gives a view of a type variable as a higherorder type but also encodes the corresponding higherorder solution of the type variable in other programs there may be no to generate a coercion from a type variable x to a kind at all due to an absence of contexts in which values are used in a syntactically higherorder way such as the function application term x in the previous example consider the following variation var xx function y fx we generate number x and x number number on lines and respectively here we dont need the view of x as a function type since x is not applied directly but we still need to represent the solution for x this is accomplished by the coercions introduced by our closure rules as a result of the assignment on line namely number x x and x x x combining x x x and x number number gives us x x number number solving the flows gives us x number and x number as before since only function types flow into x its solution is its function kind x x which after substituting for x and x gives us number number finally decomposition using kinds enables us to take unions of kinds not types giving us types inferred from alone for example the decomposition of x into x x lets us capture the flow of argument types to x in the calls to x on lines and yielding number x and boolean x respectively these firstorder flows may then be combined by taking the least upper bound in the usual way after which reconstruction of x proceeds as described above function parameters functions by existing code are problematic since we cannot assume that all existing programs will be available for our analysis a key goal of our algorithm is to ensure that our inferred types are programs compiled using inferred types are able to with programs compiled under the assumption that missing type annotations are the dynamic type without introducing any new runtime failures we now show an example in which we try to extend our algorithm to infer the parameter type of a function that can be called by other programs that are not available for analysis function return x else return foo the function call foo on line generates number foo furthermore as before we generate foo number and number foo on line solving for type variables we get foo number and foo number as before we do not use foo number for inference suppose that the function foo is part of the interface of some library and clients of foo have been compiled under the assumption that foo and foo are then the solution for foo is sound because it can be used in any context of type in particular it will not throw an error unless it flows to a context whose type is incompatible with number in which case it would already throw an error without type inference unfortunately the solution for foo is not sound for example suppose a caller sets the global variable b false and then calls foo with x true in the absence of type inference the true argument will be successfully converted at run time from type boolean to type after which it will go unused since b false avoiding a runtime error in contrast if we add the annotation after type inference this will have the effect of requiring a runtime conversion of the true argument from boolean to number at the point of the call to foo and this conversion will always fail thus inferring foo number can break existing programs in general we conclude that we cannot safely infer the parameter types of functions that are part of the interface of the program with existing code because our analysis cannot be guaranteed to include every call to such functions local functions on the other hand it is safe to infer the parameter types of local functions defined within other functions and all their calls are available for analysis consider the local function foo in the following example function function return x else return return as before we get the solutions foo number and foo number here we also get bar number since foo is a local function that does not escape bar we know it cannot be called from outside bar meaning that all calls to foo are available for analysis in this case it is safe to infer foo number even if the function bar is by existing code local functions that escape are problematic however if a local function by being returned as a higherorder value from a function that is by existing it becomes available to callers in the this again makes it unsafe to infer the local functions parameter type since not every call to the function is available for analysis function function return x else return return foo in this example inferring foo number based on function call on line would again be unsound assuming the function bar is by existing code since foo is returned by bar clients can set b false and call foo with any x value thus as in section annotating x as number could introduce runtime errors in existing programs what types are safe to infer to summarize the examples above illustrate that while it may be safe to infer the types of local variables in a function the return types of functions and the parameter types of local functions that do not escape it is definitely not safe to infer parameter types of functions that are by existing code and those of local functions that do escape furthermore if values from such parameters flow into other variables then inferring the types of those variables is clearly also unsafe so what is the principle that lets us decide which types are safe to infer all is necessary we observe that in a typed language we must see the types of all the values that may flow into a variable before we can infer the variables type suppose that at compile time we see only a proper subset of the types of values that may flow into a variable some of the types of values that may flow into x are unknown at compile time because they flow into x from a runtime environment that cannot be analyzed during compilation next suppose that the compiled program is executed in such a runtime environment in the absence of type inference x has type which means that the runtime environment could write any type of value into x furthermore the programmer could reason outside the type system to ensure that once such a value reaches x it is then used correctly under appropriate conditions thus if the inferred type of x is based only on the subset of types that are seen then we could end up the program in this runtime environment by causing a runtime error to be upon the write to x not only would this error not have occurred in the absence of type inference but as described in the previous it is quite possible that no error would have occurred at all flows encode escape analysis for a function that is by existing code we require the programmer to explicitly annotate the parts of the functions type that have negative polarity in particular the parameter type if those parts have static types in the absence of annotations we must assume they have the dynamic type for a local function our ability to infer the parts of its type with negative polarity depends on whether the function escapes into an unknown runtime environment there are many ways a local function can escape it can be returned as a value it can be assigned to a global variable it can be assigned to some object property and that object could be returned and so on at first it seems that either we need a sophisticated escape analysis to figure out if a local function escapes or we need the programmer to annotate parameter types for local functions as well fortunately we observe that the flows already encode an escape analysis if we require that types with negative in the interface of the program with existing code be explicitly annotated if if we assume that they are the dynamic type when our closure computation ensures that escape information is properly propagated to all type variables let us consider the example from section with different possibilities for bar first suppose that the programmer has annotated the return type of bar as number number in this case the programmer has annotated the types with negative polarity in bar explicitly now its safe to infer foo number since the programmer has us that foo will always be called with x as number otherwise there will be a runtime error on the other hand if the programmer had not explicitly annotated the return type of bar we would have assumed it to be some type variable bar as before we generate foo foo bar from return foo on line we introduce function kind section for bar and add foo foo bar bar and bar bar bar now we observe that bar has negative polarity since the function bar is by existing code we assign bar thus we have foo foo bar the flow we get foo and finally we infer foo which is always safe in this way escape analysis is through our closure computation thus we require explicit type annotations only for types that have negative in the interface of the program with existing code all the remaining types we can infer so far we have maintained that we are looking at of the form t x to solve for type variable x but we have not said anything about of the form x t where t is not a type variable such correspond to dynamic consistency checks need not contribute to solutions we observe that of the form x t need not contribute to the solution for in general such do play a role in propagating flows between parts of higherorder types as we have seen in section if we can analyze all writes to x we know precisely the types of all values that x will need to hold at run time and so by just looking at of the form t x we can infer a more precise solution for x need not be validated statically we also do not need to validate the at compile time as the runtime does it as we show in the following example if we try to validate statically we could end up being too conservative and infer less precise types than we could function return else return else first we note that this program is safe if foo which is the case when there is no type inference when b is false foo doesnt use its argument and returns in our inference algorithm we generate the flows boolean number foo foo line number number foo foo line and boolean foo from function call on line the first two flows gives us foo boolean foo number and number foo therefore we infer foo boolean and foo number and our solution is foo boolean number with these inferred types the program is still safe there is no change in the runtime semantics of the program but note that our solution foo boolean turns the foo number to the dynamic consistency check boolean number which will fail if executed at run time so if we were to validate statically we would have foo to which means we would have inferred a less precise type that we could in this example the programmer encodes path sensitive reasoning about correctness of his program and ensures that the dynamic consistency check boolean number never happens at run time when the function in line is passed to foo foo doesnt invoke it since it is not possible to statically determine whether dynamic consistency checks will at run time we do not validate but we maintain that our inference doesnt introduce any new runtime errors our soundness theorem proves that if a program fails at run time with our inferred types it would have failed even if those types were and vice versa for blame guarantees traditionally type inference algorithms in statically typed languages ensure that the solution of x is a subtype of the greatest lower bound of all the types t that flow out of x this implies that all dynamic consistency checks always succeed in our system we do not validate because this may constrain our inferred types as we saw in the previous example but this comes with a tradeoff type inference for statically typed languages guarantees that inferred types will not generate any runtime type errors while we clearly cannot hope for such guarantees typed languages often provide weaker blame guarantees the statically typed parts of a program cannot be for any runtime type errors on the other hand by default we do not give any such guarantee dynamic consistency checks may throw errors at run time instead our inferred types can be thought of as to a runtime to optimize memory runtime conversions property and so on we only guarantee that they do not introduce any new runtime errors in the program if on the other hand the programmer wants some blame guarantees from our system we can run an additional step we validate if some may cause an error we either the type variable that may cause the error to the type or if there is no type variable involved fail the compilation in the example of previous section once we find that inferring foo boolean will fail the consistency check foo number we can the type variable foo and recover blame guarantees for our system objects the treatment of objects in our system follows that of functions in that we use to model object properties with various access for example private properties of objects have no polarity so we infer types of private properties readonly properties like public functions have positive polarity and so we infer positive parts of the types of those functions and we require programmers to annotate the negative parts on the other hand public variables in an object are readwrite so they have both negative and positive and we require programmers to annotate the types of public variables as before we do not need escape analysis to figure out if some private function escapes the scope of an object or if a private object escapes the scope of a function escape analysis is in the closure computation we show an example in where object templates are defined using classes class a private var bb true private function return x else return public function return foo in this example our solution will be b boolean foo foo number bar number note that as before we infer foo because it is returned from a public function bar summary our key observations can be summarized as follows unlike type inference in statically typed languages we treat which represent definitions in a different manner than which represent uses the for a type variable determine its solution the for a type variable represent dynamic consistency checks that happen at the runtime when the for a type variable involve higherorder types its solution is encoded by a kind which the the type variable into parts recursively solves for those parts and the solutions to determine the solution of the type variable in particular the negative parts of such a solution are determined by the negative parts of higherorder types in the for the type variable we need to see all the types of all values into a variable before we can infer its type this means that we can only infer positive parts of the type that serves as the programs interface with existing code the negative parts of that interface can be defined by some unknown runtime environment so we either need the programmer to annotate those parts explicitly or we assume them to be the dynamic type we do not need a separate escape analysis to find which types escape their scope once we have put sufficient type annotations in the interface of the program with existing code our flows encode the escape analysis our framework extends naturally to objects and classes we use to model object properties with various access private readonly and public computation of closure derivation of solutions compilation type inference blame recovery figure overall architecture for type inference formal development in this section we formally develop our type inference algorithm for a core typed calculus of functions and objects unknown types are modeled as type variables in the language we formalize the static semantics of the language by a compilation judgment that translates a program annotated with types to a program with coercions section we then describe a type inference algorithm that analyzes the coercions to compute a flow relation over types and derives a solution map for the type variables based on this flow relation section we also describe how the solution map may be to recover standard blame guarantees section figure the overall architecture for type inference we prove complexity theorems for the type inference algorithm section next we formalize the dynamic semantics of the language by an evaluation judgment that under a solution map for the type variables reduces programs with coercions to values section based on this dynamic semantics we prove soundness theorems for the type inference algorithm by comparing the behaviors of programs under the solution map inferred by our algorithm with those under the default solution map that every type variable as the dynamic type section syntax the syntax of the language is shown below we model function parameters and object properties as variables x in contrast to standard object calculi we distinguish readability and of object properties we model access capabilities for object properties as subsets of where denotes readability and denotes we express objects and their types as indexed collections of object properties and their types for any nonnegative integer m the notation m means the set of indices m and for any syntactic entity the notation means the collection m indexed by m term t null fun x t t t xi i ti tt tx tx t t t t if t then t else t type variable x x x xx type t t t xi i x terms include functions of the form fun x t t t objects of the form xi i ti and the null value null as well as applications of functions of the form tt reads and writes of object properties of the form tx and tx t and null checks of the form if t then t else t they also include reads and writes of variables of the form x and x t furthermore they include coercions between types of the form t t coercions may be interpreted syntactically as flows and semantically as operations we assume that in source code there are no coercions types include function types of the form t t objects types of the form the null type and the dynamic type furthermore they include type variables x some type variables may be derived by others xx denotes the type of the property x of objects of type x while x and x denote the type of the input and output of functions of type x we assume that in source code type variables are distinct and are of the form recursive functions self references and loops can be readily encoded in the language so can blocks with local variables thus we do not include those constructs in the language furthermore we do not model classes their treatment is similar to that of objects and we discuss them further in section compilation we now describe the compilation semantics of our language the goal of compilation is to compute types and embed coercions in source programs thereby them for type inference section and evaluation section compilation proceeds under a type environment a type environment is a finite map from variables to types compilation judgments are of the form t t t meaning that t to t of type t under figure lists the rules for deriving compilation judgments the compilation rules are fairly straightforward the type of a term is computed in a syntaxdirected manner and whenever a term of type t appears in a context that is annotated with type t the coercion t t is attached to the term we elaborate on the rules for functions and objects namely for function applications and and for object property accesses they rely on a partial relation between types defined below intuitively this relation captures the condition under which a term of a certain type can be by the type either as the type of a function that can be applied or as the type of an object for which a property can be read or written definition view a type t can be viewed as a type t if t t can be derived by any of the following rules · x x x · · t t t t · x x xx for or · x for or · xi i xj tj such that j m and j for or compilation may fail due to the of the view relation essentially whenever a term of some type is in a context that is annotated with an incompatible type in particular a function cannot be viewed as an object an object cannot be viewed as a function and an object without a particular access capability for a property cannot be viewed as an object with that access capability for that property further restrictions can be imposed statically in particular a standard gradual type system would detect other unsafe coercions by interpreting all type variables as the dynamic type and ensuring that coercions are between statically consistent types cf consistency and static consistency is defined in section where we discuss how to carry over blame guarantees by such systems to our setting how compilation judgment t t t null null x t t t t t t t t fun x t t t fun x t t t t t x t xm tm i m ti ti ti ti ti ti ti ti ti ti im t t t t t xj tj xj tj t xj tj t t t t xj tj tj tj tj tj tj tj tj tj t xj tj t xj tj tj t t t t t t t t t t t t t t t t t t t t t x t x x t x t t t t x t x t t t t fresh t t t i ti ti ti ti ti ti if t then t else t if t then t else t figure compilation ever we emphasize that we do not require those restrictions for our soundness theorem we can existing runtime failures as long as we do not introduce any new runtime failures type inference following compilation the coercions embedded in a program say what types of terms appear in what types of contexts other coercions are implicit in the type of the compiled program which serves as the interface with existing code these are coercions between the dynamic type and type variables in the type of the compiled program which continue to be interpreted as the dynamic type by existing code based on this set of coercions we type inference as follows we apply some carefully designed closure rules on this set of coercions to compute a flow relation between types section the flow relation the set of all possible flows of terms to contexts at run time we then derive a solution map for type variables based on that flow relation section in particular if some context is flow judgment t t t t is a coercion in the compiled program tt c x t is the type of the compiled program x is positive in t x x is negative in t c tx kx x xy kx y t x kx c c t kx kx x kx x xt kx t kx t t t t t xi i xi i im t t t t xi i xi i im t t t t c t t t c t j n xi i xi i ti in n m i n i i c tj tj j tj tj j c figure computation of closure annotated by a type variable the solution for that type variable is an overapproximation of the types of terms that may flow to that context at run time computation of closure given a compiled program and its type we compute a flow relation between types by and growing a set of coercions until fixpoint flow judgments are of the form t t meaning that flows from type t to type t are possible ie terms of type t may flow to contexts annotated with type t at run time figure lists the rules for deriving flow judgments those rules are explained below unlike usual flow relations for statically typed languages with subtyping our flow relation is not merely a transitive closure of the coercions in a compiled program interpreted as subtyping constraints instead it is designed carefully to account for gradual typing and is for efficiency rules and generate the initial facts in particular relies on a standard notion of polarity for type variables defined below to ensure that any type variable that appears in the type of the compiled program is or becomes by other rules with the dynamic type in the contravariant parts definition polarity of a type variable in a type the set of positive variables and the set of negative variables in a type t are pt and pt respectively defined as follows let s range over let s be when s is and when s is · px x px · ps ps · t · i ti im i m i i m i for example if the interface of the compiled program with existing code is x x then reflects the following assumptions · we assume that there is a flow from to x · we also assume that there is a flow from x to so that if say there is a local function that escapes through x then by other rules we can derive a flow from to the parameter type of the function similar considerations apply if the interface is an object type if a property is annotated with a type variable there is a flow from to that type variable and if a readable property is annotated with a type variable there is a flow from that type variable to if a property is both we assume both flows if a property is neither we assume neither other rules namely and rely on a notion of for type variables defined below intuitively a type variable has for every type constructor that may form a solution for the type variable a kind that encodes that solution definition kinds for a type variable kinds for a type variable x ranged over by kx are types of the form x x xi i or eventually the solution of a type variable is derived by the kinds that flow into it either directly or indirectly through other type variables thus the rule any kind on the left of a type variable to any other type variable on its right the rule factors a coercion from a type to a type variable into intermediate coercions through a corresponding kind for that type variable computed as shown below this factoring ensures that flows from types to a type variable are appropriately captured in solutions for that type variable definition kind of a type for a type variable the kind t x of a type t where t is not a type variable for a type variable x is defined as follows · x · x · t t x x x · xi i x xi i the rule limits transitive flows through a type variable in two ways it only considers a kind on the left and it only considers a type on the right such that the kind on the left is dynamically consistent with the type on its right dynamic consistency is a partial relation between types that are not type variables defined as follows it models coercions that never fail at run time definition dynamic consistency a type t is dynamically consistent with another type t if t and t are not type variables and t t can be derived by any of the following rules · t t · t t t t · xi i ti in if n m and for all i n we have i i in combination with the rule ensures that flows from types on the left of a type variable to types on the right of the type variable are taken into account without computing a standard transitive closure in section we discuss why computing a standard transitive closure is the remaining rules are fairly straightforward and expand on the left or right of a higherorder type to the appropriate shape finally and split flows between higherorder types into flows between their parts and note that since we distinguish access capabilities for reading and writing object properties the types of object properties are not necessarily invariant they may be covariant readonly contravariant invariant readwrite or even abstract no access derivation of solutions based on the flow judgment we derive a solution map i that associates each type variable x to a type without type variables we also extend i to a function i from types to types without type variables such that it is the type obtained by substituting each type variable x in type t by ix to solve for x let tx be the set of types t such that t is not a type variable and t x we compute the least upper bound of the kinds of types for x in tx as defined below definition least upper bound of kinds the least upper bound kx kx of two kinds kx and kx for x is defined as follows · kx kx kx kx · kx kx · x x x x x x · jn where yj jn and for all i m j n and k p if xi yj then k i j · x x · x x the solution ix for x is then defined as i t tx t x such solutions are always wellfounded since kinds do not have cyclic dependencies blame recovery standard gradual type systems enforce that the coercions in a compiled program satisfy static consistency which is a partial relation between types that are not type variables defined as follows definition static consistency a type t is statically consistent with another type t if t and t are not type variables and t t can be derived by any of the following rules · t t · t t t t if t t and t t · ti in if n m and for all i n we have i i and if i then ti ti if i then ti ti this static consistency relation extends similar relations defined separately for a typed language of functions and for a typed language of objects we conjecture that programs in our language satisfy the blame theorem whenever they compile to programs whose coercions satisfy the static consistency relation following similar results for existing languages however the solution map i derived above does not guarantee static consistency this means that blame guarantees by standard gradual type systems do not carry over with type inference fortunately it is possible to weaken i to recover those blame guarantees as follows for any type variable x let tx be the set of types t such that t is not a type variable and x t if there is any t tx such that ix t then ix is to be we can then prove the following theorem theorem blame recovery suppose that for every coercion t t in the compiled program we have t t where is the solution map that associates every type variable with then for every flow judgment t t we have it it algorithmic complexity although computation of closure may be performed by applying the flow rules in arbitrary order until fixpoint an effective algorithm would apply them systematically as described below we can then reason about its efficiency definition flow computation the computation of flow judgments proceeds in the following steps until fixpoint initially rules and are applied until saturation next rules and are applied until saturation next rules are applied until saturation next rule and is applied until saturation finally control returns to step where if no new flow judgments are derived the algorithm terminates we prove that our algorithm terminates and is efficient theorem termination flow computation terminates proof recall that all type variables in the system are distinct so they have unique let d be the maximum depth of types in the system after step steps and introduce types of depth d in the system step introduces types of depth d finally in step types of depth d and type variables of depth can be away this means that maximum depth of types in the system after step is d thus flow computation must terminate in d iterations theorem time complexity the time complexity of flow computation is quadratic in the size of the program proof let k be the number of type variables n be the number of types other than type variables and d be the maximum depth of types after step step takes ok time step takes time and increases the number of types by some factor w that denotes the maximum width of types step takes on time and increases the number of types by the same factor w thus before step the total time taken is ok n and after step we have wk variables and wn types other than type variables since the algorithm terminates in d iterations the total time complexity is n typically w and d are small constants so the time complexity is almost quadratic in the number of types k n in general if the size of the program is n then on thus the total time complexity is on evaluation we now describe the evaluation semantics of our language which enables us to prove that our type inference algorithm is sound let range over locations a stack s is a sequence of locations the syntax of values is as follows value v · · · t null t t · · · t sx t · · · t a value of the form t t u is abbreviated as u t furthermore we use the notation t · · · t t · · · t u to denote t · · · t · · · t u unlike previous work that focuses on implementations of typed languages our dynamic semantics admits unbounded chains of coercions to simplify the specification and proof of soundness essentially we keep coercions in symbolic form and check that they along the way a record is a map from variables to values a heap h is a map from locations to records we rely on the following operations for variables on the stack through the heap hx vs h h x v if x domh hx vs if x domh h x if x domh if x domh the evaluation judgment is s h t h v where is a solution map which associates type variables to types without type variables figure lists the rules for deriving evaluation judgments the rules are fairly standard except that the coercions on values are symbolic the type variables in those coercions are not substituted by their solutions but instead the solutions are up when normalizing the coercions this is convenient for our soundness proof normalization is defined as follows definition normalization the chain of coercions t · · · tn under if for all j n t tj furthermore a value v under written v if it is of the form t · · · tn u and t · · · tn under the rules for functions and objects namely and rely on the following standard splitting rules for higherorder coercions i n ti xj ti t tn xj uj · xj t tn i n ti xj ti t tn xj uj · xj tn t evaluation judgment s h t h v s h null h null s h fun x t t t h sx t t t is fresh h h x null xn null i m s hi ti hi vi vis hi s h xi i ti hm xi i s h t h c c · xj cj h r vj cj vj s h h cj vj s h t h c c · xj cj s h tj vj cj vj r h cj vj s h tj h cj vj s h t h c s xt c · c c s h t h v c v is fresh h h x c v s h t h v c v s h t t h c v s v s h x h v h t h v h x vs h s h x t h v s s h t h v t t v h t t t h t t v s h t h v v null i v null i s h ti h v s h if t then t else t h v figure evaluation i n ti ti ti t tn u u · tn t t tn soundness since we infer more precise types where there were less precise types the interesting direction for soundness is to establish as above that we do not introduce any runtime errors the other direction is trivial and can be established by reasoning about positive and negative see section we prove the following soundness theorem for our type inference algorithm which says that if a compiled program evaluates to a value with dynamic types for type variables then it evaluates to the same value with inferred types for type variables recall that the dynamic semantics is symbolic in type variables but ensures that any coercions in values theorem soundness let t t t let i be the inferred solution map for t t and let be the solution map that associates every type variable with if t h v then t i h v soundness follows as a corollary of our main lemma term correspondence lemma see below which states not only i there a correspondence between reductions in the original program and reductions in the program with inferred types but also ii any coercions that may be generated at run time have already been generated at compile time via closure computation of course ii is a crucial invariant to show i since it means that the solutions we compute at compile time behave as expected at run time definition knowledge of coercions the chain of coercions t · · · tn is known if for all j n tj tj definition compatibility of type environment with stack and heap the type environment is compatible with the stack s under heap h written h s if whenever x tn we have t · · · tn v and t · · · tn is known lemma term correspondence let t t t and h s if s h t h t · · · tn v then · s h t i h t · · · tn v · t · · · tn is known the proof of term correspondence requires value correspondence lemma see below and two other lemmas on knowledge of coercions function flow and object flow which are used in the cases of function application and object property access lemma value correspondence if t · · · tn is known and under then it under i lemma function flow if t t t · · · tn is known and ti ti ti for all i n then tn t t is known and t t tn is known lemma object flow if t · · · tn is known and ti x ti for all i n then tn t t is known if and t t tn is known if the proofs of these lemmas in turn require the closure rules and the following two basic lemmas on dynamic consistency lemma kind ordering if t t t t then for all t t we have t t lemma monotonicity if x y then ix furthermore we can prove the following soundness theorem that says that our type inference is compositional theorem compositional soundness suppose that t t t let i be the inferred solution map for t t and be the solution map that associates every type variable with let t be a program without type variables such that t t t t let t t t t then t t h v implies t t i h v proof the new coercion is t t however by we already know coercions of the form x for positive type variables x and x for negative type variables x in t so by term correspondence the composition is sound finally in section we discuss the adequacy of our inferred types and conjecture that our algorithm is relatively complete ie the solution maps it infers are optimal in a restricted family of possible solution maps unfortunately we cannot with manual reasoning we are working in a setting that admits reasoning outside the static type system via discussion feature extensions base types base types in our language can be modeled as kinds kinds correspond to type constructors and the base types are type constructors of arity by definition any base type is a kind for any x and by definition the kind of a base type for a type variable as that base type itself finally in definition the least upper bounds over base types takes into account partial subtyping relations between base types in the obvious manner classes and nominal subtyping we do not model classes in our formal language but could do so by closely following the treatment of objects in particular instance methods are modeled as readonly properties and instance fields are modeled as readwrite properties private properties are also modeled our algorithm and its guarantees carry over to a language with nominal subtyping if the compiler ensures that nominal subtyping implies structural subtyping for example in nominal subtyping of objects is available via the compiler ensures that when class b is a subclass of class a the structural type of is a subtype of the structural type of by checking that the properties in a that are in b are related by subtyping taking into account readwrite limited transitivity previous type inference algorithms for objectoriented languages with subtyping involve taking full transitive closure of subtyping constraints which makes them on where n is the size of the program in contrast we have designed our closure rules for flows so that transitivity is limited which not only makes our algorithm on but also allows for more precise type inference for example consider this sequence of flows number x y boolean our core algorithm infers x number and y number now if we want our solutions to satisfy the blame theorem we fall back to y since y number is inconsistent with y boolean however we do not need to fall back to x in contrast full transitivity would have lost the information that there is no immediate dynamic consistency check between x and boolean performance optimizations as we will see in our experiments adding more precise types improves runtime performance in most cases but more precise types can also runtime performance by introducing new runtime conversions it does not matter whether these precise types are added by type inference or effect is the same for example consider the following program function return x function var var y max sum sum return sum the function foo could be part of some external library which we cannot modify without any type annotation variable y in bar will be assigned type so the function call will not involve any runtime conversions for y since the parameter type for foo is also but if we annotate y with number either using our type inference algorithm or manually function call will result in a runtime conversion from number to for y we observe that the fix for this problem lies in the runtime rather than our inference algorithm our type inference algorithm tries to infer more precise types for variables the runtime should use these precise types to optimize the program in particular it can do type specialization for foo ie it can create a copy of foo which takes a number argument and the function call in bar to this new copy type specialization already happens in for numeric operations the resulting program will be more optimized than the version adequacy of inferred types we now analyze how precise our inferred types are our closure algorithm ensures that if there exists some flow from a concrete type t to a type variable x via other type variables we consider t when computing the solution for x we do this to make sure that we do not introduce any new runtime errors by missing out some types that could flow into x we the solution for x to when two different kinds flow into x or flows into x explicitly one could give more precise types than our algorithm by reasoning outside the type system for example consider the following program var xx yy x else x false y x else y we generate number x and boolean x on line and x y and number y on line when we do closure we add boolean y also and we infer x and y whereas with reasoning outside the type system the programmer can argue that y need not be it can be number blame recovery may also reduce the precision of our solutions for example if the generated flows are number x x y and y boolean we infer x number and y number when we do blame recovery we see that the coercion y boolean is not satisfied and so we y to whereas the programmer could get away by annotating y as number and making sure that y boolean does not happen at run time again by reasoning outside the type system however we expect that if reasoning outside the type system is then our algorithm indeed infers optimal solutions formally we can define a subset of the static consistency relation that forces the use of purely static reasoning standard subtyping for we then conjecture that there are no other solutions that are subtypes of the solutions we infer upon blame recovery and that satisfy the above relation experiments we have implemented our type inference algorithm for our implementation takes an existing program as input and returns the same program with inferred types added to the source as output the output program can then be compiled and run using the compiler and vm and compared with the input program methodology we use the and v benchmarks to evaluate our type inference algorithm these are standard benchmarks used to measure the performance of javascript implementations we use the version of these benchmarks which are part of the test suite of the vm figure comparison of our algorithm with partially typed code in their original form these benchmarks are fully typed ie their source code has complete type information we remove all type annotations except in those parts of the interface that are required by our algorithm to be explicitly annotated we then run our algorithm on these partially typed benchmarks with performance of the fully typed benchmarks as the we compare the performance of partially typed benchmarks with and without types added by our inference algorithm we also compare the results of our algorithm on partially typed benchmarks with the results of et al who have recently implemented a much simpler type inference algorithm that only infers types for a subset of local variables along with several other highlevel optimizations for at bytecode level and report performance increases due to the added type information results comparison with partially typed code figure compares the performance of partially typed benchmarks with and without types added by our inference algorithm overall our algorithm gives an average x performance improvement over partially typed benchmarks with a maximum improvement of x we are able to recover performance ie the performance of fully typed benchmarks in out of the benchmarks for our performance is higher than the fully typed version there are some private class variables in the benchmark which are typed as in the fully typed version whereas our algorithm is able to infer more precise types for them resulting in an increased performance in the fully typed version of an object is from an array and implicitly cast to an integer via an explicit int annotation since arrays are untyped in our inference algorithm infers the type of object as this one annotation is the reason that we could reach only performance as compared to the fully typed benchmark similar explicit type annotations for properties accessed from the type object which are also untyped in our performance in for and we infer some variables as number whereas in the fully typed benchmarks they are typed figure comparison of our algorithm with et al as int in int represents bit integers whereas number has size bits and can represent integers unsigned integers and floatingpoint numbers at run time operations involving int are much faster than those involving number since we do not implement a range analysis we conservatively infer all numeric types to be number this the performance in the above benchmarks our algorithm can be augmented with a simple range analysis to this problem comparison with et al figure compares the performance of partially typed benchmarks with types added by our inference algorithm and with types added by inference algorithm of et al in out of the benchmarks our numbers are better than them in out of the the numbers are almost equal for they report that the higher performance is because of a different intermediate code representation they implement in the jit compiler this effect is independent of the type inference algorithm performance after type inference in figure we see that for the performance after adding precise type information to the partially typed code this general issue was also found by where the effect is even worse and is already discussed in section related work gradual type inference the only previous work on gradual type inference is the technique of which is not suitable for an objectoriented language with subtyping soft typing overall our goal is the same as that of soft typing to improve runtime performance by eliminating runtime type checks where ever possible however to our knowledge all the soft type inference systems proposed to date are based on unification which is for objectoriented languages with subtyping since we do not aim to infer polymorphic types in we are interested in algorithms with polynomial complexity furthermore treating uses and definitions enables us to infer more precise types than soft type inference finally existing soft type inference systems have not considered problems of soundness in the presence of partial compilation whereas our algorithm type inference on existing programs under the assumption that complete source code may not be available for analysis this restriction of preserving semantics of code outside the compilation unit implies that we must infer types for only those parts of the program that we can see all the writes to ie those parts of the program that do not escape the compilation unit blame our algorithm seems to share deep connections with the blame calculus and other coercion calculi exploring these connections should be interesting future work in particular the blame calculus defines three new subtyping relations positive subtyping negative subtyping and n subtyping such that s n t denotes that s is more precise than t and holds if and only if s t and t s in particular we have s and t the main result in is that if s t then a runtime cast error from s to t cannot be on the term to which the cast is attached and if s t then a runtime cast error from s to t cannot be on the context in which the cast appears the solutions of our algorithm are related to the default types by n so we can say that our solutions are more precise than the default types in a context that previously expected the default type we now effectively introduce a cast from a more precise type this means that any blame for a runtime cast error must lie with the context so there is nothing to prove about the program on the other hand we infer a more precise type for a context we effectively introduce a cast from the default type this means that any blame for a runtime cast error must lie with the program ie we must prove that a program that executed successfully before type inference continues to execute successfully after type we do in this paper combining static typing and dynamic typing there has been a lot of interest in exploring ways to mix typed and untyped code eg via occurrence typing gradual typing hybrid typing and like typing in these systems types are supplied by the user in contrast our work focuses on type inference which is complementary static type inference static type inference has been explored for dynamic languages including self ruby python javascript and scheme there is also a long history of work on type inference for languages with subtyping dynamic type inference our type system infers some static types but is still bound by the limitations of static analysis on programs that use dynamic types as such we believe that dynamic type inference would be useful to improve the precision of those dynamic types which we cannot eliminate in a program recent work has explored dynamic techniques for type inference and type specialization for dynamic languages as future work we plan to explore such combinations in the jit compiler underlying the vm conclusion in this paper we design a type inference algorithm that can improve the performance of existing typed programs without introducing any new runtime failures the distinguishing features of the algorithm lie in its asymmetric treatment of and and its encoding of an escape analysis to preserve we prove that our algorithm is sound and efficient and demonstrate its applicability on a typed language acknowledgments we would like to thank and several anonymous reviewers for their helpful comments and suggestions this work was done while the first author was an at advanced technology systems references o j palsberg and mi type inference of self ecoop a aiken e l and t k soft typing with conditional types in popl pages ­ j d an a j s foster and m dynamic inference of static types for ruby in popl pages ­ acm d m a and n dynamically and statically typed oo languages in acm c p and s towards type inference for javascript in ecoop r cartwright and m soft typing in pldi pages ­ m b e smith a a m c and m the impact of optional type information on jit compilation of dynamically typed languages in acm c flanagan hybrid type checking in popl pages ­ acm m j d an j s foster and m static typing for dynamic languages in oopsla a b m d d m r b kaplan g hoare b j j e w smith r m m and m type specialization for dynamic languages in pldi pages ­ acm f dynamic typing syntax and proof theory science of computer programming ­ d a and c flanagan gradual typing in functional programming c essential j palsberg efficient inference of object types in lics pages ­ ieee f pottier a framework for type inference with subtyping in icfp pages ­ acm j siek and w gradual typing for objects in ecoop pages ­ springerverlag j g siek and w gradual typing for functional languages in scheme and functional programming workshop j g siek and m gradual typing with inference in pages ­ acm j g siek and p wadler with and without blame in popl pages ­ acm benchmarks p towards a type system for analyzing javascript programs in esop s and m felleisen the design and implementation of typed scheme in popl v benchmarks p wadler and r b findler welltyped programs cant be in esop pages ­ springerverlag a k wright and r cartwright a practical soft type system for scheme acm toplas t f z s j and j integrating typed and untyped code in a language in popl pages ­ acm 