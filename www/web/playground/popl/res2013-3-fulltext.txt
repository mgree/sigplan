copatterns programming infinite structures by observations department of computer science germany david school of computer science university computer science university uk abstract inductive datatypes provide mechanisms to define finite data such as finite lists and trees via constructors and allow programmers to analyze and manipulate finite data via pattern matching in this paper we develop a dual approach for working with infinite data structures such as streams infinite data coinductive datatypes which denote greatest fixpoints unlike finite data which is defined by constructors we define infinite data by observations dual to pattern matching a tool for analyzing finite data we develop the concept of matching which allows us to synthesize infinite data this leads to a symmetric language design where pattern matching on finite and infinite data can be mixed we present a core language for programming with infinite structures by observations together with its operational semantics based on matching and describe coverage of copatterns our language naturally supports both callbyname and callbyvalue interpretations and can be integrated into existing languages like haskell and ml we prove type soundness for our language and sketch how copatterns open new directions for solving problems in the interaction of coinductive and dependent types categories and subject descriptors d programming languages language constructs and types and structures patterns recursion f logics and meanings of programs studies of program and recursion schemes type structure general terms languages theory keywords coinduction functional programming introduction vs elimination message passing pattern matching david support by the ­ of the and by the research of the natural sciences and engineering research of has been supported by grant theory and applications of part of the work was done while the author was a of the institute cambridge permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page to copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission andor a fee popl january ­ italy copyright c acm introduction representing and reasoning about infinite computation plays a crucial role in our for designing and implementing safe software systems since we often want to establish behavioral properties about our programs reason about io interaction and processes and establish liveness properties that eventually something good will happen while finite structures such as natural numbers or finite lists are modelled by inductive types infinite structures such as streams or processes are characterized by coinductive types inductive types are now very well understood and supported by functional languages and proof whereas the theoretical foundations and practical tools for coinductive types behind for example in the calculus of coinductive constructions the core theory underlying coq inria coinduction is broken since computation does not preserve types in agda a dependently typed proof and programming environment based on martin type theory inductive and coinductive types cannot be mixed in a compositional way for instance one can encode the property infinitely often from temporal logic but not its dual eventually forever and over the past there has been growing consensus that one should distinguish between finite inductive data defined by constructors and infinite coinductive data which is better described by observations this view was by who modeled finite objects via initial algebras and infinite objects via final coalgebras in category theory his development in the design of a version of ml where one can declare via a list of their destructors for example the of streams is defined via the destructors head and tail which describe the observations we can make about streams and took up his work and designed a language where one programs directly with the morphisms of category theory but while was later extended with pattern matching on initial data types no corresponding dual concept was developed for called final data types in in this paper we take a first step towards building a typetheoretic foundation for programming with infinite structures via observations dual to pattern matching for analyzing finite data we introduce matching for manipulating infinite data and describe coverage for copatterns in order to focus on the main concepts and avoid the additional that come with dependent types for instance the need to guarantee termination or we ourselves to simple types in this article our theoretical treatment of patterns and copatterns takes from the growing body of work which relates classical and linear logic to programming language theory via the more precisely we build on the duality between finite values as righthand side proof terms and continuations or evaluation contexts as lefthand side terms of sequent calculus curien and wadler and following b deep analysis of focused proofs in linear sequent calculus and its relationship to pattern matching and evaluation order in programming languages we distinguish between positive types which characterize finite data and negative types which describe infinite data while values are matched against patterns evaluation contexts are matched against copatterns our notion of copatterns extends previous work by and harper to treat least as positive types and greatest fixedpoint as negative types and we recognize copatterns as a definition scheme for infinite objects more precisely we regard copatterns as experiments on infinite objects such as functions streams and processes infinite objects can be defined by a finite covering set of observations which are pairs of experiment together with its outcome defining term we take the distinction between the finite initial positive and the infinite final negative serious and give introduction rules and patterns for the former and elimination rules and copatterns for the latter this leads to a core functional language based on natural deduction instead of the sequent calculus formulation explored in by b et al et al our contributions are the following we show how copatterns complement the syntax of existing functional languages and enable a style of programming with infinite objects by observations section there is no need to move to a different programming paradigm such as classical logic curien and wadler or the morphisms of category theory we describe a nondeterministic algorithm for checking coverage and prove that welltyped and complete programs do not go wrong section the construction of a covering set of copatterns corresponds to the interactive construction of a program as in agda and section we explain how copatterns can be a paradigm in rewriting and dependent type theory in rewriting definition by observations lead naturally to strongly normalizing rewrite rules and a semantics without rewriting and de section in dependent type theory they overcome the subject reduction problem of the calculus of coinductive constructions section the remainder of this article is structured as follows we informally describe copatterns in section and explain in detail their benefits in programming rewriting and type theory in section we define formally our core language with copatterns and its static semantics we then describe its operational semantics together with matching in section coverage of copatterns together with the type safety proof is presented in section we briefly describe a prototype implementation of copatterns for agda in section before we conclude with a discussion of related work section and an to further work section copatterns and their applications in this section we explain copatterns section and out the arguments started in the introduction we illustrate how copatterns impact functional programming section rewriting section and dependent type theory section from function definition to copatterns we introduce copatterns in the scenario of interactive program construction by refining the left hand side of a function definition step by step as we will see copatterns arise naturally as the generalization of definition by pattern matching as an example we construct the infinite stream n n n n of natural numbers via an auxiliary function nat stream nat such that n n n n n before we begin let us define stream nat as a recursive record type containing the possible observations we can make about streams these observations are also referred to as destructors since they allow us to take apart streams record stream a head a tail stream a now we will construct similar to the interactive editing in agda and and the starting point is the template nat stream nat since a function is an infinite object we define it by observation rather than giving its value a abstraction directly however we cannot give a value of n for every natural number n instead we apply to a generic natural number the pattern variable x x application to x which we write as · x is our first instance of a an applicative it is in this case a generic experiment on the observation of its outcome determines we are left with the task of constructing a stream of natural numbers we can make two principal experiments on a stream we can observe its head and its tail and the outcome of these two experiments determines the stream these experiments give us two new copatterns head · and tail · called destructor copatterns and lead to the next refinement of our definition of head x tail x the observed head of x is just x to determine the tail we need to split on the pattern variable x head x x tail tail x this generalizes the applicative form · x to · p where p is a pattern as usual a term built from constructors literals and uniquely occurring variables only we finally can fill the remaining two holes and complete our definition of head x x tail n tail x x the infinite object a function yielding streams is defined via the complete set of copatterns head · x tail · tail · x where · the hole is a for the function it is determined by the following set of observations i e experiments mapped to their results head · x x tail · n tail · x x copatterns in functional programming a missing symmetry destructor copatterns are a useful addition to functional languages even if no coinduction is involved in the following we an implementation of the state monad typical for haskell to demonstrate why the absence of general copatterns breaks symmetry and how copatterns restore it a first implementation defines the type state s a of a stateful computation with result a just as a for s a × s the monadic operations return and bind are given in an applicative style state s a s a × s return a state s a return a s a s state s a a state s b state s b m k s let a s m s in k a s returning a in state s yields the pair a s of result and unchanged state and executing the sequence m k in state s first executes m state s a in state s resulting in a value a a and a new state s in which we run the continuation k applied to a the code explains itself if the application to s is read as in state s there are reasons to move away from type state s a to a bijection between the monadic type state s a and its implementation as s a × s for instance in haskell type interact with based overloading and instead state s a is implemented as a record type with projection and constructor state record state s a s a × s state state s a s a × s s a × s state s a as we update our implementation of the monad operations we are in for an we can only partially keep up the applicative style more precisely only on the right hand side of the expression side here we only have to prefix the monadic values m and k a with the projection but on the left hand side the pattern side we cannot do the same change since projections are not allowed there instead we have to turn the lhs application to s to a rhs abstraction over s and prefix it with constructor state return a state s a return a state s a s state s a a state s b state s b m k state s let a s m s in k a s the projection bits are still nice to read e g m s reads as run m in state s however the definition of m k as the stateful computation that if you pass it state s is a bit the symmetry is broken copatterns which allow projections also on the lhs restore the symmetry and allow a smooth definition of the monad operations again return a state s a return a s a s m state s a a state s b state s b k s let a s m s in k a s it reads if you run return a in state s you get a s and to run m k in state s run m in s obtaining a value a and a new state s in which you run k a deep copatterns in rewriting strong normalization for definitions in the following we argue that copatterns help to integrate infinite objects into term rewriting without having to change the standard reduction semantics a popular example of programming with infinite objects is the creation of the stream of numbers it is defined as fib cons cons fib tail fib cons is the stream constructor head and tail the projection and yields a stream by applying addition pointwise to a pair of streams here fib and tail fib clearly reading this equation as a rewrite rule the computation of fib does not terminate under the standard semantics which is rewrite when the left hand side matches using rewriting and de fib to the stream cons cons cons cons cons cons however we are interested in the strong normalization of a term rewriting system since this yields a decision procedure for equality which then implies decidability for checking dependent types we can to a nonstandard rewriting semantics label the definition of fib as and only unfold it when its value is e g by a projection this solution for instance taken in coq does not help with our particular definition of fib either since tail fib appears in its own unfolding leading to infinite reduction a exists we could introduce a mutually defined auxiliary stream fib which denotes the tail of fib but copatterns provide a and scalable solution mechanically transforming the definition of fib into copatterns yields head fib head tail fib tail tail fib fib tail fib these equations are actually by our first equation for fib but now we take them as definition of fib the rewrite system is terminating neither fib nor tail fib can be reduced by itself because none of the three defining copatterns matches our syntax allows us to delay unfolding of until the whole is matched copatterns in particular deep copatterns such as nested projections tail tail · give us greater flexibility for definitions than nonstandard semantics copatterns in dependent type theory subject reduction following the lead of the functional programming language haskell the dependently typed language coq introduces both finite and infinite trees via constructors however this leads to fundamental problems for example the calculus of coinductive constructions the core theory underlying coq inria lacks subject reduction this issue is already described in section of thesis it back to the attention of the community a detailed analysis has been given by let us counterexample to subject reduction as in fig given a coinductive type u with constructor in that takes just an argument of type u the u of u can be constructed as the fixed point of in the definitions force and eq seem p u in u u a type its only u u u in an of u infinite of ins force u u force x case x of in y in y an identity eq x u x force x eq x case x of in y refl u in u eq u figure counterexample but are in fact a major tool in coq proofs about definitions such as u since they wrap a around a that reduction while unrestricted reduction of f to f f would diverge immediately the following two rewrite equations for matching coinductive data maintain strong normalization case in s of in y t case f of in y t case f f of in y t now the closed term eq u simplifies via eq u case u of in y refl case in of in y refl case in in of in y refl refl to the single constructor refl of propositional equality which means that u and in u must be equal yet they are not since u does not reduce to in u unless under a case distinction subject reduction is lost as notes subject reduction holds only modulo an undecidable equality on types that allows unrestricted fixedpoint unfolding but this is not what can be implemented in proof for intensional type theory with decidable type checking the is that the rule for dependent matching is also available for coinductive data i e in case of u we have the rule u u y u t y case u of in y t cu the rule a constructed term in y for term u in type c which may trigger reduction of case expressions in c that are not possible without the substitution for instance force in y reduces to in y while force x does not reduce to x this is exploited in the typing of eq which leads to the loss of subject reduction in the end the deeper reason for this is that coinduction is just understood as constructing infinite trees coinductive structures are just data structures in coq however even in dependent type theory infinite objects are better understood through their elimination rules i e observations looking at example it seems wrong to regard in as a constructor rather it should be defined in terms of the only since refl in y force in y by dependent pattern matching case x of in y refl x force x thus eq x x force x observation out u u same for the infinite structure u u in u u out in y y uu out u u the equations we have written are now exactly the reduction rules no restricted unfolding of has to be taken into consideration this makes definitional equality and thus type checking more for the user it is a equational theory dependent pattern matching on coinductive types u is no longer available and subject reduction is the like force and eq necessary to deal with edges of dependent pattern matching are also while we do not develop a dependently typed language with copatterns in this article we have illustrated the of uniformly modeling finite and infinite data via constructors and the potential of copatterns in the dependently typed setting a core functional language with copatterns in this section we introduce a core language with recursive data types for modeling finite data and recursive record types for modeling infinite data the term language is which allows for a complete bidirectional type checking algorithm we then proceed to define patterns and copatterns which allow us to define functions records and can be by an extension of the algorithm function definitions will be modeled as sets of rewrite rules types we distinguish between positive types a × b and and negative types a b and xr this polarity assignment is inspired by focusing proofs in intuitionistic linear logic benton et al our types × and µ correspond to the positive connectives and a combination of and least fixed point resp and they classify finite data the types and correspond to the negative and a combination of and greatest fixed point resp and classify infinite data linearity will show up in the typing rules for patterns and copatterns even though ordinary terms need not be linear in terms of categorical languages and positive types are left objects or initial datatypes and negative types are right objects or final datatypes a b c x p n type variable positive type negative type p unit type cartesian product data type n a b xr function type record type d c a · · · cn an variant labeled sum r d a dn an record labeled product figure types figure introduces positive types p negative types n and types a which can be either positive or negative variants d serve our terminology should not be with recursive records in objectoriented language foundations e g by abadi and cardelli to construct possibly recursive data types and records r list the fields di of a possibly recursive record type xr in our calculus type variables x only serve to construct recursive data types and recursive record types as usual xr resp binds type variable x in d r resp substitution of type c for variable x in type a is denoted by the set of free type variables of a type expression a is defined in the standard way a type is wellformed if it has no free type variables in the following we assume that all types are wellformed datatypes datatypes c for d c a · · · cn an are recursive variant types they could be called algebraic types we write for ai the constructor ci of c takes an arguments of type i e cx nonrecursive data types can be represented by a void like in sml a con that requires no argument formally takes an argument of the unit type examples list a µx nil cons a × x nat µx zero suc x maybe a µ nothing just a µ positive empty type record types record types c xr with r d a dn an are recursive labeled products they could be called types the destructor di if applied to a record of type c returns the ith field which has type or with a rd notation cx the destructors are applied in notation to a term t as as for data nonrecursive record types are encoded by a void abstraction r examples stream a a tail x a µ nil cons a × x vector a length nat list a negative unit type both d and r can be seen as finite maps from a set of labels constructors and destructors resp to types with application written dc and rd we write c d and d r to express that a label is in the domain of the corresponding finite map in this article both and xr are just recursive types rather than inductive and coinductive types resp since d and r are not checked for and programs are not checked for termination or resp there are no conditions that ensure to be a least fixedpoint only by finite data and xr to be a greatest fixedpoint that hosts infinite objects which are however we keep the notational distinction to to the intended interpretation as least and greatest in a total setting terms and typing next we describe terms which constitute the targets of our rewrite rules terms are given by the following grammar e t u f x t t ct t t td defined symbol eg function variable unit empty tuple pair constructor application application destructor application terms can be identifiers variable x defined symbol f tuple t t constructed term c t of positive types a × b or application t t projection td of negative types a b xr constructor applications choose a variant and fold the recursive type destructor applications unfold the recursive type and select a component of the record missing by intention are for positive types like tuple projections and case these are replaced by pattern matching we omit for negative types such as abstractions and record values instead we have definitions by matching see t a in context term t can be assigned type a x a x a f f t c t t xr td t a a t t a t a t a t a t t a × a figure typing rules for terms typing contexts and denote finite maps from term variables to wellformed types to ensure linearity in pattern typing we write for the disjoint union of finite maps and i e dom dom we write · or simply nothing for a finite map with empty domain and we usually drop the when giving a context explicitly as set of pairs x a xn an we assume a global signature which maps defined symbols f to their type the rules for the typing judgement t a are given in figure note that since we have no binder on the term level no in particular remains fixed in all the rules assumptions in describe the type of pattern variables occurring on the left hand side of a rule and are synthesized when analyzing copatterns for each term constructor there is exactly one typing rule so we trivially obtain the usual inversion in the following whenever we have a judgement j eg a typing judgement we write d j to indicate that d is a derivation of j using the rules for j usually our proof proceeds by induction on a derivation of our judgement and we write in this case by induction on d some of our judgements are algorithmic i e partial functional relations unless stated otherwise all arguments to these relations are inputs bidirectional type checking our language naturally supports overloading of constructors and destructors when a bidirectional type checking algorithm pierce and turner supporting overloading is convenient in practice and leads to elegant compact and readable code with bidirectional checking overloading comes for free since a constructor c gets its meaning in the context of a data type check a constructed term c t we push its type in a destructor d only has a meaning in the context of a record type xr which is inferred from head t in the projection term td overloading projections is standard in objectoriented programming here projections correspond to method calls and has to the success of the oo paradigm constructor overloading is also e g in the dependently typed languages agda and and given a typing context we infer the type a of identifiers and judgement t a while we check against a given type a judgement t a the t a in context the type of term t is inferred as a f f x a x a t a a t t a t a t xr td t a in context term t checks against type a ta ac tc t c t t a t a t t a × a figure typechecking rules for terms rules are given in figure type checking is trivially sound but it is also complete without the need for any additional type annotations theorem soundness of type checking if d t a then t a if d t a then t a proof simultaneously by induction on the derivation d for simplytyped lambdacalculus bidirectional type checking is not complete and typically requires type annotations it fails for redexes xt u since the type of a is not inferred in our case since for a type we have either introduction or elimination we lack the usual redexes thus bidirectional type checking is actually complete theorem completeness of type checking if d t a then t a and if a is a negative type then t a proof by induction on d note that a proof of t a is sufficient since this trivially implies t a by patterns and copatterns the force behind computation in our language is pattern and matching pattern matching allows us to for the missing for positive types while matching for the missing for negative types in the following we present copatterns and their typing patterns p x p p cp variable pattern unit pattern pair pattern constructor pattern copatterns q · qp qd hole application destructor the application of a projection d in qd corresponds to the prefix application d q we used in the introduction to with haskell and agda syntax note that in contrast to convention in the ml projection does not bind stronger than application i e f x d is to be read f our style parentheses when writing nested copatterns pattern typing is defined in figure it computes a context containing all the variables in the pattern a p or q must be linear that is each variable in appears exactly once in p or q resp again there are two modes for pattern typing the checking mode denoted by p a works on patterns p and follows the checking mode for regular typing the inference mode denoted by a q c works on copatterns q and additionally computes its type c from the given type a of the hole p a pattern p checks against type a yielding x a x a p c p p a p a p p a × a a qc q eliminates given type a into inferred type c yielding context a q xr · a · a a qd a q b c p b a q p c figure type checking for patterns and rewrite rules again there is a connection between pattern constructors and pattern typing rules a standard inversion lemma holds for all rules in figure programs a program p rules consists of a signature mapping defined symbols f to their types and a collection rules of rewrite rules for each symbol f defined in the signature gives the rewrite rules for f as a set of pairs q e called observations which define the behavior of f we require a symbol main called the entry point that determines the value of a program execution of a program means rewriting main with the rules until no more rewriting is possible the informal syntax used in the introduction can be mechanically transformed into programs of form p for instance the definition fib of the stream of numbers corresponds to the following entries in and rules fib zero suc y tail x · head zero · tail head suc zero · tail tail fib fib tail a complete program needs also entries for and and a symbol main the type of main should be positive otherwise the result of the program is an infinite object here main could be a function listing the first elements of the leave the details to the of the reader a program p is welltyped if p as given in figure which in essence says that any rule q u for any defined symbol f must be welltyped a first result proven in the next section is that during the execution of a welltyped program we never a term which is illtyped evaluation and type preservation in this section we define program evaluation in terms of a smallstep reduction relation to decide whether a rewrite rule can qf u check rewrite rule f q c u c qf u p check program main f q u rules qf u figure welltyped rules and programs we match evaluation contexts against copatterns we prove that reduction preserves types evaluation contexts evaluation contexts e are elimination terms with a hole in head position they generalize copatterns q in that they allow arbitrary terms e instead of just patterns p in argument positions e · ee ed hole application projection the hole · can be considered as a special variable we write et as shorthand for typing a e c for evaluation context e is defined in figure this judgement holds iff x a ex c for a fresh variable x welltyped evaluation contexts compose lemma composition of contexts if d a e b and e b e c then a c a ec in context evaluation context e eliminates type a into type c a e xr a · a a ed a eb a figure typing rules for evaluation context pattern matching matching a term t against a pattern p if successful yields a substitution such that p t pattern matching is defined in terms of a judgement t p whose rules appear in figure a substitution is a finite map from variables to terms we write · for the empty map tx for the singleton mapping x to t and for the disjoint union of two maps and substitution typing simply means that for all x we have x x while matching patterns p is standard matching copatterns q is straightforward as well the hole · serves as and in an implementation it seems to match i e start at the hole and proceed reduction and type preservation the only source of computation in our language is a defined function symbol f in an evaluation context e that matches the t p term t matches with pattern p under substitution t x tx t p c t c p · t p t t p t p p e q evaluation context e matches q returning substitution · · · e q ed qd e q t p e t q p figure rules for pattern matching q of one of the rules q u such an e ef is a redex which can be to another expression e written e e the precise rule for contraction is e q q u ef u one step reduction e e is defined as the compatible closure of contraction i e e reduces to e if e results from contraction of one redex in e we omit the standard inductive definition of e e our first major result is that reduction preserves types we assume a welltyped program i e all rewrite rules are welltyped theorem subject reduction if e a and e e then e a subject reduction is a consequence of the following statements substitution preserves types matching yields a welltyped substitution and contraction preserves types lemma substitution if d u c and e then f u c for some f proof by induction on d lemma adequacy of pattern matching if d p a and e e a and f e p then proof by induction on f lemma adequacy of matching if d a q c and e a f e q then c b and e b and proof by induction on f lemma correctness of contraction if f e c and qf u and e q then u c proof by assumption we have d d d f q b u b qf u since it is the only rule that could have been used by lemma using d and both assumptions we have that c b and then by substitution lemma and d we conclude that u c finally the subject reduction theorem follows proof of theorem by induction on the reduction relation with contraction being the only interesting case e q ef b and q u ef u by qf u we obtain from lemma that u b coverage and progress a fundamental property of strongly typed languages is type soundness in the words of milner welltyped programs do not go wrong this means that welltyped programs either produce a value or run forever but never get stuck by an invalid operation like adding a function to a string or calling a number as one would call a function for our language there are three reasons why a program is stuck i e no reduction step is possible yet we have not reached a value missing rule we might have defined a function f nat a but only given a rewrite rule f zero in this case f suc n is stuck in this section we give rules for coverage that ensure no rewrite rules are illtyped term the term f nil is stuck even if we have given a complete implementation of f nat a however illtyped terms like f nil are already by type checking and the type preservation theorem infinite object the term f does not evaluate by itself it is an function however just as the typical interpreter we consider terms of negative types as values as a consequence our notion of value is not syntactic but as main technical result of this section and the article we prove type soundness syntactically wright and felleisen by showing the progress theorem for a callbyvalue strategy values and evaluation contexts values are defined using a new judgment v e a to mean that the expression e is a value of type a under the context we also use v to denote an expression which acts as a value whether an expression is considered a value or not depends also on its type in particular each expression of negative type n is considered a rules are given in figure v e a in context e is a value of type a xa v xa v v v c v v v v a v v a v v v a × a en v en figure rules for values lemma inversion for values the following hold for v x if v v then v if v v a × a then v v v v v a and v v a if v v then v c v for some c d and v we the notion of value for terms to evaluation contexts introducing a judgement a v e c see figure it accepts those welltyped evaluation contexts e that have values in all argument positions the idea is that if e is long enough i e if c is a positive type then ef is a redex because one of the defining copatterns for f has to match e this would not necessary be the case if the arguments in e were not values a v e c e is an evaluation context with only values in application arguments a v e xr a v · a a v ed a a v vb figure rules for value evaluation contexts the following two propositions enable us to analyze nonempty value evaluation contexts from the inside out they will be used in theorem lemma splitting a function evaluation context if d b c v e a and e · then e e · v with v v b and c v e a proof by induction on d lemma splitting a record evaluation context if d xr v e a and e · then e e with v e a proof by induction on d coverage figure defines a judgment to indicate that a list of copatterns covers all of a given type a the judgment is a q c or more generally a q where q i qi is a set of copatterns qi with their type ci and context i each satisfying i a qi ci the rules to construct a covering set of copatterns are not syntaxdirected to check whether a given set of copatterns q for a type a is complete we nondeterministically guess the derivation of a q if it exists although this is not the best we can do we are that we can adopt existing efficient coverage algorithms for our language the initial covering is given by the axiom we can refine a covering q by focusing on one q and either split the result of negative type or split one of its variables of positive type result splitting at function type b c applies the q to a fresh variable x b at record type xr we take all projections splitting a variable x replaces it by unit a pair x x or all possible constructors c x cd in with the type a × a or of the variable let us the example of the function from the introduction and through the rules for coverage with the following for types nat µx zero suc x nat tail x a q typed copatterns q cover elimination of type a result splitting a q q b c a · · a a q x b q x c a q q xr a q qd variable splitting a q x q c a q qx c a q x a × a q c a q x a x a qx xx c a q x q c a q x qc x x figure rules for coverage the signature entries for are the following nat head x · zero tail n · suc x tail x to check coverage we start with the trivial covering and apply the rules until we obtain the copatterns of since a nat fixed throughout the derivation we omit it and just write the list q we start with · · nat we apply x to the hole by x nat · x then we split the result by x nat · x head nat x nat · x tail in the second we split x via the variable name x x nat · x head nat x · zero x tail x nat · suc x tail finally we apply replacing x by x nat · x head nat · · zero tail x nat · suc x tail the lists of copatterns q for type a generated by the splitting rules is complete in the sense that every closed value context e eliminating a into a positive type p actually matches one of the copatterns qi theorem matching with a covering if d · a v e p and e a i qi then there are e e such that e e qi some i · a v e ci and · ci v e p to prove this theorem we use the following statements for lemma splitting a pattern variable let d x a b q c and e b v e c and f e q assume a a × a and let q qx xx then x a x a b q c and e q with x x x assume a and let q qc x x for some c d then x q c and e q x c x with assume a and let q qx then q c and e q with x proof first prove an adaptation of these statements for patterns p and values v instead of copatterns q and evaluation contexts e then prove this lemma by induction on f proof of theorem the theorem is proved by induction on the coverage derivation e the variable splitting cases and follow from lemma we consider the rules for result splitting case e a q q b c a q x b q x by induction hypothesis the statement holds for one of the patterns in q q b c if the pattern has been chosen from q we are done thus without loss of generality e and · a v e b c and · b c v e p and e q if e · then p b c which is a contradiction since p is a positive type if e · then e v with · v v b and · c v e p by lemma thus let e e v and · a v e c by and e q x vx by case e a q q xr a q qd analogously using lemma progress we are ready to show that evaluation of a welltyped program does not get stuck provided that all definitions come with a complete set of observations first we note that closed terms are either values or of a defined symbols such an elimination is either a value evaluation context or contains a closed lemma decomposition if · e a then either e a e e e a a × a e c e a e e where · f v e b c and · c e a and v e b for some f some evaluation contexts e e some term e and some types b c e ef for some f e with · f v e a proof by induction on e we only show the cases e e e and e e d the other cases are trivial case e e a then by inversion e b a and e b by induction hypothesis e ef with · f v e b a for some f e or e e for some f e e and e where · f v e b c · c e b a and v e b as the other cases are impossible in the former case if v e b we can obtain case by letting e · e e and e e this gives us e e e if v e b then by · f v ef e a and e e e in the latter case we have e e e by setting e e e case ed a then by inversion e xr for some r by induction hypothesis e ef and · f v e xr or e e where e is not a value in the former case ed ef d e f and · f v ed by otherwise ed e d e finally we prove progress under the assumption that every definition f is complete written f theorem progress if d e a then either v e a or e e for some e proof the proof is done by induction on e by lemma we have five possible cases since the four first cases follow by a simple induction argument we only present the last case here e ef and · f v e a if a is negative then e is already considered a value and we are done otherwise since by assumption f we can apply theorem and obtain e e such that e e qi for some qi plus · f e ci and · ci v e a thus by our reduction rules ef ui where qi ui and so ef ui we conclude that extensions and implementations our core language misses introduction rules for functions and objects thus we do not have lambda abstractions or record expressions however we can embed sets of behaviors q u into the expression syntax and obtain anonymous objects that abstractions anonymous functions defined by pattern matching and record expressions xt · x t fn nil false cons x xs true · nil false ff · cons x xs true t snd t t ff t of course bidirectional type checking is no longer complete since anonymous objects can only be checked against a given type but can appear in elimination position copatterns have been added to the development version of agda agda team currently projection copatterns are not part of the core of agda they are parsed but then translated into record expressions this does not give the full flexibility of copatterns but allows us to experiment with them full copatterns in the core would allow us to exploit the benefits of deep projection copatterns and mixed copatterns but for that coverage checker has to be extended to copatterns to this further research is required because dependent pattern matching is a far from trivial coquand and pfenning goguen et al and another implementation of copatterns exists in in one can termination and using types hughes et al et al copatterns provide the right syntax to definitions with size variables that witness available from the related work our work builds on the insight that finite datatypes correspond to initial algebras and infinite datatypes correspond to final coalgebras this was first observed by and was the basis of categorical programming languages such as and and categorical programming languages typically support programming with the morphisms of category theory while they do provide iteration they do not support general recursion and pattern matching in support for pattern matching on data types was added but it lacks support for matching our type theoretic development of copatterns exploits the duality of positive and negative types which is well known in focused proofs previously focusing has been applied to pattern matching a and evaluation order curien and to our work from a theoretical point of view is the work by and harper where a language based on the sequent calculus is described which supports lf types with types the weak function space of lf is classified as a positive connective and admits pattern matching using constructor patterns the strong computation level function space is classified as negative connective which is defined by destructor patterns the technical report also describes briefly how to add formulas to the proposed system however in their work matching happens at the meta level this is like replacing induction by an rule our work provides an syntax for copatterns and an algorithm for coverage and extend dual calculus to inductive and coinductive types treating the constructor for inductive data as value constructor and the destructor for coinductive data as continuation constructor however they do not introduce recursive values or recursive continuations nor pattern and matching but allow only iteration over finite data and into infinite data agda in its currently released version already avoids subject reduction problem infinite objects are created via delay and analyzed via force the corresponding operation on types is lifting in spirit this approach the standard trick in callbyvalue languages such as ml and scheme to encode lazy values by i e functions over the unit type the dependent pattern matching on infinite objects is out since one cannot match on functions coinduction is informally described by and but it lacks theoretical indeed compositionality is lost because any data type that uses lifting is coinductive and for instance a data type of trees with infinite branching realized via streams host automatically infinitely deep trees even if that is not expressed by the data type definition our work lifting as the generation of a mutual recursive record type that the coinductive part to the data type forcing is interpreted as destructor and delaying as a mutual definition by destructor pattern this way we provide a standard semantics for coinduction in agda and recover compositional construction of data types conclusion in this paper we have presented a typesafe foundation for programming with infinite structures via observations we model finite data using variant types and infinite data via record types pattern matching of finite data is extended with its dual notion of matching on infinite data while we do not consider termination and in this paper we guarantee that the functions are covering ie they are defined on all possible inputs copatterns a foundation for finitary rewriting with infinite objects they are also an candidate for representing definitions in typetheoretic proof such as coq and dependently typed languages like agda in the future we plan to extend the presented work to full dependent types there are two main theoretical issues we need to first extension of coverage to dependent types and secondly checking termination and of functions to guarantee strong normalization a candidate for the latter task are types hughes et al et al as already implemented in further we aim at developing a denotational model for languages with copatterns it seems that semantics based on and provides a good starting point for this investigation from a practical point of view we plan to fully integrate copatterns into agda for a and robust foundation of coinduction acknowledgments the first author thanks coquand and for email exchange about copatterns and the regular participants of the agda from on for discussions on copatterns and the best way to integrate coinduction into agda during an to university by the second author much of the theory of copatterns was already out he is also towards and james for an to the institute for in in november during that visit the implementation of copatterns for agda we also thank and the anonymous for suggestions to improve this paper references m abadi and l cardelli a theory of primitive objects untyped and firstorder systems in m and j mitchell editors theoretical aspects of computer software volume of notes in comput sci pages ­ springer a mixed types and strong normalization in z shao editor proc of the th symp on programming languages and systems volume of notes in comput sci pages ­ springer isbn a typebased termination and mixed types proc in theor comp sci ­ proceedings of agda team the agda t and n a termination checking in the presence of nested inductive and coinductive types short note supporting a talk given at par workshop on and recursion in interactive theorem provers jm logic programming with focusing proofs in linear logic journal of logic and computation ­ g m j e l and t typebased termination of recursive definitions math struct in comput sci ­ n benton g m v de and m a term calculus for intuitionistic linear logic in m and j f editors proc of the st int conf on typed lambda calculi and applications volume of notes in comput sci pages ­ springer isbn a certified programming with dependent types mit press june unpublished draft r and t about technical report department of computer science the university of june series report no t coquand pattern matching with dependent types in b k and g plotkin editors types for proofs and programs types pages ­ t coquand infinite objects in type theory in h barendregt and t editors types for proofs and programs types volume of notes in comput sci pages ­ springer pl curien and h the duality of computation in proc of the th acm sigplan int conf on functional programming icfp sigplan notices pages ­ acm press isbn n a and t subtyping in c j and b editors proc of the th int conf on mathematics of program construction volume of notes in comput sci pages ­ springer isbn j and b case analysis of higherorder data notes in theor comp sci ­ e un de constructions et son application a la de phd thesis de dec h goguen c and j eliminating dependent pattern matching in k jp and j editors algebra meaning and computation to a goguen on the of his th volume of notes in comput sci pages ­ springer isbn x j reference and computation in intuitionistic type theory phd thesis mathematical logic university t a typed lambda calculus with categorical type constructors in d h a and d e editors category theory and computer science volume of notes in comput sci pages ­ springer t in ml j logic ­ j hughes l and a proving the correctness of reactive systems using types in proc of the rd acm symp on principles of programming languages popl pages ­ inria the coq proof assistant reference manual inria version edition j and f de rewriting volume of cambridge in theoretical computer science chapter chapter in term rewriting systems pages ­ cambridge university press d and m dual calculus with inductive and coinductive types in r editor rewriting techniques and applications volume of notes in comput sci pages ­ springer isbn n r focusing on pattern matching in z shao and b c pierce editors proc of the th acm symp on principles of programming languages popl pages ­ acm press isbn d r n and r harper focusing on binding and computation in f pfenning editor proc of the nd ieee symp on logic in computer science lics pages ­ ieee computer press isbn long version available as technical report c lets see how things unfold the infinite with the intensional in a m and a editors rd int conf on algebra and coalgebra in computer science volume of notes in comput sci pages ­ springer isbn c and j the view from the left j func program ­ r milner a theory of type polymorphism in programming j comput syst sci ­ aug u towards a practical programming language based on dependent type theory phd thesis dept of comput sci and sept n coinductive types and type preservation message on the list june m proofs of strong normalization for second order classical natural deduction j logic ­ b c pierce and d n turner local type inference in proc of the th acm symp on principles of programming languages popl san diego california c and f pfenning a coverage checking algorithm for lf in d and b editors proceedings of the th international conference on theorem proving in higher order logics volume of notes in comput sci pages ­ italy september springer a coalgebras as types determined by their elimination rules in p s e and g editors versus on the foundations of mathematics in of per springer to appear c pattern matching in thesis the university of july j and pa semantic types a fresh look at the ideal model for types in n d jones and x leroy editors proc of the st acm symp on principles of programming languages popl pages ­ acm press isbn x p wadler callbyvalue is dual to callbyname in c and o shivers editors proc of the th acm sigplan int conf on functional programming icfp pages ­ acm press isbn p wadler callbyvalue is dual to callbyname in j editor rewriting techniques and applications volume of notes in comput sci pages ­ springer isbn a k wright and m felleisen a syntactic approach to type soundness information and computation ­ n focusing and higherorder abstract syntax in g c necula and p wadler editors proc of the th acm symp on principles of programming languages popl pages ­ acm press a isbn n on the of duality ann pure logic ­ b n the logical basis of evaluation order and patternmatching phd thesis carnegie mellon university a agda examples the development version of agda has experimental support for copatterns which can be turned on by option copatterns in the following we present a few examples for copatterns in agda syntax have a coinductive type with an embedded variant type in agda this is represented as mutual recursion between a coinductive record type and a data type mutual data a set set where a x a xs a a record a set set where coinductive field out a open our first function lets us append a to a list it is defined by recursion on the list open import using list map append a set list a a a out append ys out ys out append x xs ys x append xs ys note the overloading of constructor for lists and we can also define a function for defined as a pair of mutually recursive functions one is on the other on mutual a b c set a b c a b c out f xs ys f out xs out ys a b c set a b c a b c f ys f x xs f x xs y ys f x y f xs ys another example is an unfold function suppose we have a set of states s and a set of values a corresponding to the observation we do at some particular state then given a function taking a current state and a new state and its value or no state at all if it is a terminal state and given an initial state we can build a of values of all states visited open import using maybe nothing just open import using × mutual unfold a s set s maybe a × s s a out unfold f s f f s a s set s maybe a × s maybe a × s a f just a s a unfold f s f nothing traversal of tree finitely branching but potentially infinite deep trees can be represented by a coinductive record with two fields a label and a list of subtrees record tree a set set where coinductive field label a list tree a open tree if we have a forest list tree a we can extract the labels in a manner by first taking all the roots then all the subtrees and to ensure we distinguish the empty forest from the nonempty forest bf a set list tree a a out bf out bf t ts label t append map label ts bf t ts bf is since it is coquand it directly outputs either the empty or the nonempty and since append xs ys only adds elements in front of ys the latter is not yet tracked by termination and checker thus the termination checker this code checking using types as realized in does work for bf and it is our goal to bring coinduction in agda to the same level of expressiveness as in 