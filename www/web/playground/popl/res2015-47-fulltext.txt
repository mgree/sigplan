deep specifications and certified abstraction layers shao wu yale university university of science and technology of complete popl consist well easy to abstract modern computer systems consist of a of abstraction layers eg os kernels device drivers network protocols each of which defines an interface that the implementation details of a particular set of functionality client programs built on top of each layer can be understood solely based on the interface independent of the layer implementation despite their obvious importance abstraction layers have mostly been treated as a system concept they have almost never been formally specified or verified this makes it difficult to establish strong correctness properties and to scale program verification across multiple layers in this paper we present a novel languagebased account of abstraction layers and show that they correspond to a strong form of abstraction over a particularly rich class of specifications which we call deep specifications just as data abstraction in typed functional languages leads to the important representation independence property abstraction over deep specification is characterized by an important implementation independence property any two implementations of the same deep specification must have contextually equivalent behaviors we present a new layer calculus showing how to formally specify program verify and compose abstraction layers we show how to instantiate the layer calculus in realistic programming languages such as c and assembly and how to adapt the compcert verified compiler to compile certified c layers such that they can be linked with assembly layers using these new languages and tools we have successfully developed multiple certified os kernels in the coq proof assistant the most realistic of which consists of abstraction layers took less than one person year to develop and can a version of linux as a categories and subject descriptors d software engineering proofs formal methods d programming languages languages constructs and features d programming languages processors compilers d operating systems d operating systems organization and design f logics and meanings of programs specifying and verifying and reasoning about programs keywords abstraction layer modularity deep specification program verification certified os kernels certified compilers permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page for components of this work owned by others than the authors must be abstracting with credit is permitted to copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission andor a fee request permissions from popl january ­ copyright is held by the publication to acm acm introduction modern hardware and software systems are constructed using a series of abstraction layers eg circuits architecture device drivers os kernels network protocols web servers and application each defining an interface that the implementation details of a particular set of functionality client programs built on top of each layer can be understood solely based on the interface independent of the layer implementation two layer implementations of the same interface should behave in the same way in the context of any client code the power of abstraction layers lies in their use of a very rich class of specifications which we will call deep specifications in this paper a deep specification in theory is to capture the precise functionality of the underlying implementation as well as the assumptions which the implementation might have about its client contexts in practice abstraction layers are almost never formally specified or verified their interfaces are often only in natural languages and thus cannot be checked or enforced nevertheless even such informal instances of abstraction over deep specifications have already us benefits and attributed such use of abstraction modularity and as the key factor that the computer toward levels of and growth because complex products can be built from smaller that can be designed independently yet function together as a whole abstraction and modularity have also been studied in the programming language community the focus there is on abstraction over shallow specifications a module interface in existing languages cannot describe the full functionality of its underlying implementation instead it only describes type specifications augmented sometimes with simple invariants abstraction over shallow specifications is highly desirable but client programs cannot be understood from the interface makes modular verification of correctness properties impossible verification of client programs must look beyond the interface and examine its underlying implementation thus the modularity given the obvious importance formalizing and verifying abstraction layers are highly desirable but they pose many challenges · lack of a languagebased model it is how to model abstraction layers in a languagebased setting and how they differ from regular software modules or components each layer seems to be defining a new abstract machine it may take an existing set of mechanisms eg states and functions at the layer below and expose a different view of the same mechanisms for example a virtual memory management on top of a physical memory layer would expose to clients a different view of the memory now accessed through virtual addresses · lack of good language support programming an abstraction layer formally by its very nature would require two languages one for writing the layer implementation which given the low level nature of many layers often means a language like c or assembly another for writing the formal layer specification which given the need to precisely specify full functionality often means a rich formal logic it is how to fit these two different languages into a single setting indeed many existing formal specification languages are capable of building accurate models with rich specifications but they are not concerned with connecting to the actual running code · lack of compiler and linking support abstraction layers are often in binary or assembly even if we can verify a layer implementation written in c it is how to compile it into assembly and link it with other assembly layers the compcert verified compiler can only prove the correctness of compilation for whole programs not individual modules or layers linking c with assembly adds a new challenge since they may have different memory layouts and calling conventions in this paper we present a formal study of abstraction layers that all these challenges we define a certified abstraction layer as a triple pl m lq plus a mechanized proof object showing that the layer implementation m built on top of the interface l the indeed implements the desirable interface l above the here the implements relation is often defined as some simulation relation a certified layer can be viewed as a parameterized module from interfaces l to l a la an sml functor but it enforces a stronger contextual correctness property a correct layer is like a certified compiler capable of converting any safe client program running on top of l into one that has the same behavior but runs on top of l eg by compiling abstract primitives in l into their implementation in m a regular software module m built on top of l with interface l may not such a property because its client may invoke another module m which shares some states with m but imposes different state invariants from those assumed by l an abstraction layer does not allow such a client instead such m must be either built on top of l thus the invariants in l or below l in which case l itself must be changed our paper makes the following new contributions · we present the first languagebased account of certified abstraction layers and show how they correspond to a rigorous form of abstraction over deep specifications used widely in the system community a certified layer interface describes not only the precise functionality of any underlying implementation but also clear assumptions about its client contexts abstraction over deep specifications leads to the powerful implementation independence property see sec any two implementations of the same layer interface have contextually equivalent behaviors · we present a new layer calculus showing how to formally specify program verify and compose certified abstraction layers see sec such a layer language plays a similar role as the module language in sml but its interface checking is not just typechecking or signature matching instead it requires formal verification of the implements relation in a proof assistant · we have instantiated the layer calculus on top of two core languages see sec and a variant of the compcert clight language and lasm an x assembly language both and lasm can be used to program certified abstraction layers we use the coq logic to develop all the layer interfaces each or lasm layer is parameterized over its interface implemented using external call mechanisms we developed new tools and tactic libraries to help the verification of the implements relation · we have also modified compcert to build a new verified compiler that can compile abstraction layers into lasm layers see sec is novel because it can prove a stronger correctness theorem for compiling individual functions in each a theorem requires reasoning about memory injection between the memory states of the source and target languages to support linking between and lasm layers we show how to design the implements relation so that it is stable over memory injection · using these new languages and tools we have successfully constructed several certified os kernels in coq see sec a certified kernel k is a verified lasm implementation k built on top of lx and it implements the set of system calls as specified in the correctness of the kernel guarantees that if a user program p runs safely on top of running the version of p linked with the kernel k on lx will produce the same behavior all our certified kernels are built by composing a collection of smaller layers the most realistic kernel consists of layers took less than one person year to develop and can a version of linux as a the popl evaluation the full of our entire effort including and lasm the compiler and the implementation of all certified kernels with coq proofs the reviewers stated that our implementation their additional details about our work can be found in the companion technical report why abstraction layers in this section we describe the main ideas behind deep specifications and show why they work more naturally with abstraction layers than with regular software modules shallow vs deep specifications we introduce shallow and deep specifications to describe different classes of requirements on software and hardware components type information and program contracts are examples of shallow specifications typebased module interfaces eg ml signatures are introduced to support compositional static type checking and separate compilation a module m can be based on its import interface l without looking at ls implementation and shown to have types specified in its export interface l to support compositional verification of strong functional correctness properties on a large system we would hope that all of its components are given deep specifications a module m will be verified based on its import interface l without looking at ls implementation and shown to implement its export interface l to achieve true modularity we would like to reason about the behaviors of m solely based on its import interface l and we would also like its export interface l to describe the full functionality of m while the implementation details more formally a deep specification captures everything we want to know about any of its must satisfy the following important implementation independence property implementation independence any two implementations eg m and m of the same deep specification eg l should have contextually equivalent behaviors different languages may define such contextual equivalence relation differently but regardless we want that given any client p built on top of l running p m ie p linked with m should lead to the same observable result as running p m without implementation independence running p m and p m may yield different observable results so we can prove a specific property that holds on p m but not on p property cannot be proved based on the program p and the specification l alone struct struct prev next struct struct head tail and struct struct struct q struct struct null return pid else head q head if head null return pid else pid head next head next null q head null q tail null else next prev null q head next return pid inductive inductive prev next z inductive head tail z record function a i match i with none h t if h then some a else match h with none n if n then let in some a i q h else match n with none s n let n t in let a i q in let s n in some a n b h end end end figure concrete in c vs abstract in coq thread queues definition definition list z record function a i match i with h q a i q h nil none end figure a more abstract queue in coq partial correctness specifications are deep specifications since they fail to satisfy implementation independence given two implementations of a partial correctness specification for a factorial function one can return the correct factorial number and another can just go into infinite loop a program built on top of such specification may not be about based on the specification alone instead we have to into the actual implementation in order to prove certain properties eg termination in the rest of this paper following compcert we will focus on languages whose semantics are deterministic relative to external events formally these languages are defined as both and determinate and they support external nondeterminism such as io and concurrency by making events explicit in the execution traces likewise we only consider interfaces whose primitives have deterministic specifications if l is a deterministic interface and both m and m implement l then p m and p m should have identical behaviors since they both follow the semantics of running p over l which is deterministic deterministic specifications are thus also deep specifications deep specifications can of course also be nondeterministic they may contain resource bounds numerical client program p l with abs r module m l with abs r module m interface l with abstract state abs rr module m with concrete state mem figure client code with conflicting abstract states etc such nondeterminism should be in the semantics of a whole program allowing implementation independence to still hold we leave the investigation of nondeterministic deep specifications as future work layers vs modules when a module or a software component implements an interface with a shallow specification we often hide its private memory state completely from its client code in doing so we can guarantee that the client cannot possibly break any invariants imposed on the private state in the module implementation if a module implements an interface with a deep specification we would still hide the private memory state from its client but we also need to introduce an abstract state to specify the full functionality of each primitive in the interface for example fig shows the implementation of a concrete thread queue module in c and its interface with a deep specification in coq the local state of the c implementation consists of thread queues and thread control blocks each thread control block consists of the thread state and a pair of pointers prev and next indicating which queue it belongs to the function takes a pointer to a queue it returns the head block if the queue is not empty or null if the queue is empty in the coq specification fig right we omitted some invariants to make it more readable we introduce an abstract state of type abs where we represent each c array as a coq finite map and each pointer as an integer index z to the or array the primitive is a mathematical function of type abs Ñ z Ñ option abs z when the function returns none it means that the abstract primitive this specification is made very similar to the c function so we can easily show that the c module indeed implements the specification we define that a module implements a specification if there is a forward simulation from the module implementation to its specification in the context of determinate and languages if the specification is also deterministic it is sufficient to find a forward simulation from the specification to its implementation this is often easier to prove in practice in the rest of this paper following compcert we often call the forward simulation from the implementation to its specification as upward forward simulation and the one from the specification to its implementation as downward forward simulation fig shows a more abstract specification of the same queue implementation where the new abstract state abs the prev and next links in and treats each queue simply as a coq list the specification d is now even simpler which makes it easier to reason about its client but it is now harder to prove that the c module implements this more abstract specification this explains why we often introduce less abstract specifications eg the one in fig as intermediate steps so a complex abstraction can be decomposed into several more tractable abstraction steps deep specification out an interesting new challenge shown in fig what if a program p attempts to call primitives defined in two different interfaces l and l which may export two conflicting views ie abstract states abs and abs of the same abstract state abs thus also the same concrete memory state mem here we assume that modules m m m implement interfaces l l l via some simulation relations r r r lines marked with a dot on one end respectively clearly calling primitives in l may violate the invariants imposed in l and vice versa so l and l are each others abstraction when we run p in fact even without m and l if we allow p to directly call primitives in l similar violation of l invariants can also occur this means that we must client programs such as p above and each deep specification must state the clear assumptions about its valid client contexts each interface should come with a single abstract state abs used by its primitives and its client can only access the same abs throughout its execution this is what abstraction layers are designed for and why they are more compositional with respect to deep specification than regular modules layers are introduced to limit interaction among different modules only modules with identical state views ie r r and abs abs must be identical can be composed a layer interface seems to be defining a new abstract machine because it only supports client programs with a particular view of the memory state the correctness of a certified layer implementation allows us to transfer formal reasoning of client programs on one abstract machine the to another the programming with certified abstraction layers enables a way of composing a large number of components in a complex system without using layers we may have to consider arbitrary module interaction or dependencies an invariant held in one function can be easily broken when it calls a function defined in another module a layered approach aims to sort and all components based on a carefully designed set of abstraction levels so we can reason about one small abstraction step at a time and eliminate most interaction and dependencies a calculus of abstraction layers motivation a user of an abstraction layer pl m lq wants to know that its implementation m on top of the interface l can be used to run any program p written against the interface l if we consider l l as abstract machines and m as a program transformation which transforms a program p into m pp q then for some notion of refinement this property can be stated as p m pp ql p l meaning that the behavior of m pp q executing on top of the specification l refines that of the program p executing on top of the specification l this view of abstraction layers captures a wide variety of situations furthermore two layers pl m lq and pl n lq can be composed as pl m n lq and the correctness of the layer implementation m n follows from that of m and n however the layer interfaces are often not arbitrary abstract machines but simply instances of a base language specialized to provide primitives and abstract state the implementation is not an arbitrary transformation but instead consists of some library code to be linked with the client program in order to prove this transformation correct we will verify the implementation of each primitive separately and then use these proofs in conjunction with a general template for the instrumented language abstract machines and program transformations are too general to capture this redundant structure the layer calculus presented in this section provides finegrained notions of layer interfaces and implementations it allows us to describe what from one layer to the next and to such layers in a generic way to keep the formalism general and simple we initially take the syntax and behavior of the programs under consideration to be abstract parameters specifically in the remainder of this section we will assume that the following are given · a set of identifiers i p i which will be used to name variables functions and primitives eg and in fig · sets of function definitions p k and variable definitions p t as specified by the language eg and in fig · a set of behaviors p for the individual primitives of layers and the individual functions of programs eg the step relation derived from the coq function in fig more examples can be found in sec we also need to define how the behaviors refine one another this is particularly important because our layer interfaces primitive specifications and because a relation between layer interfaces is defined pointwise over these primitives ultimately we wish to use these finegrained layers and refinements to build complete abstract machines and simulations this can only be done if the refinements of individual primitives are consistent for example if they are given in terms of the same simulation relation hence we index behavior refinement by the elements of a partial monoid pr we will refer to the elements r p r of this monoid as simulation relations however note that at this stage the elements of r are entirely abstract and we require only that the composition operator and identity element id satisfy the monoid laws r ps t q pr sq t and r id id r r finally we need to interpret these abstract simulation relations as refinement relations between behaviors that is for each r p r we require a relation r on for instance if the behaviors p are taken to be step relations over some sets of states r may be interpreted as the following simulation diagram s s rr s s that is whenever two states s s are related by r in some sense and takes s to s in one step then there exists s such that takes s to s in zero or more steps and s and s are also related by r the relations ´ should respect the monoid structure of r so that for any p we have id and so that whenever r s p r and p such that r and s it should be the case that sr layer interfaces and modules the syntax of the calculus is defined as follows l i ÑÞ i ÞÑ l l m i ÑÞ i ÑÞ m m the layer interfaces l and modules m are essentially finite maps constructions of the form i ÞÑ are elementary objects and computes the union of two layers or modules this is illustrated by the interpretation given in the companion technical report for example the thread queue module shown in fig can be defined as queue ÑÞ ÞÑ ÑÞ while the interface can be defined as queue ÑÞ the rules are presented in fig the inclusion preorder defined on modules corresponds to the intuition that when m n any definition present in m must be present in n as well the composition operator behaves like a join operator however while m n is an upper bound of m and n we do not require it to be the least upper bound the order on layer interfaces extends the m m m m m m m pm mq m m pm mq m m m m m m m m m m m ñ m m m m m m ñ m m m m l r l l id l r l l id l pl lq l id l pl lq l l id l l l id l l l l id l l r l l s l ñ l sr l l r l l r l ñ l l r l l r ñ i ÞÑ r i ÑÞ l r m l empty l id l var l id i ÞÑ i ÞÑ l r m l l s n l l rs m n l l r m l l r n l l r m n l l l r l l s m l l m l l t l figure the finegrained layer calculus underlying simulation preorder r on behaviors compared to it should satisfy the additional property the judgment l r m l is to a typing judgment for modules it asserts that using the simulation relation r the module m running on top of implements l because modules consist of code ultimately intended to be linked with a client program the empty module acts as a unit and can implement any layer interface l empty moreover first n then m to a client program is to m n in one step these rules correspond to the identity and composition properties already present in the framework of abstract machines and program transformations however the finegrained calculus also provides a way to split refinements when two different layer interfaces are implemented in a compatible way by two different modules on top of a common interface then the union of the two modules implements the union of the two interfaces this allows us to break down the problem of verifying a layer implementation in smaller pieces but ultimately we need to handle individual functions and primitives the consequence rule can be used to tie our notion of behavior refinement into the calculus however to make the introduction of certified code possible we need a semantics of the underlying language language semantics assume that layers and modules are interpreted in the respective sets l and m the semantics of a module can be understood as the effect of its code has on the interface as specified by a function ´ m Ñ pl Ñ lq i ÞÑ id i ÞÑ l m pl n lq id m n l m m l r l ñ m l r m l figure semantics of modules ´ m Ñ l Ñ l given such a function we can interpret the typing judgment as l r m l l r l m l then the properties in fig are sufficient to ensure the soundness of the typing rules with respect to this interpretation here surprisingly we require that the specification refine the implementation this is because our proof technique involves such a downward simulation into the converse upward simulation as detailed in sec theorem and sec also we included l on the righthand side of r to support of primitives in the l into the l the property can be understood intuitively as follows in m pl n lq the code of m is able to use the functions defined in n in addition to the primitives of the interface l but conversely the code of n cannot access the functions of m however in m n l the functions of m and n can call each other freely and therefore the result should be more defined the property states that making the module and larger should also result in a more defined semantics once a language semantics is given we introduce a rule to prove the correctness of individual functions q fun l id i ÑÞ i ÑÞ where the predicate q asserts that the function body implements the primitive behavior on top of l this rule can be combined with the rules of the calculus to build up complete certified layer implementations similarly given a concrete language semantics we will want to tie the calculus back into the framework of abstract machines and program transformations for a layer interface l we will define a corresponding abstract machine meant to execute programs written in a version of the language augmented with the primitives specified in l the program transformation associated with a module m will simply the code of m to the client program then for a particular notion of refinement we will want to prove that the typing judgments the contextual refinement property l r m l p pp m ql p l informally if m implements l on top of l then invocations in p of a primitive i with behavior in l can be satisfied by calling the corresponding function in m indeed in sec and sec the primitive specifications in m l based on step relations are defined to reflect the possible executions of the function definitions in m therefore l r l m l implies that for any primitive implementation in m the corresponding deep specification in l refines the execution of that function definition hence the execution of program p with l refines that of p m with l the properties in fig hold for a similar reason properties of the language ie being determinate and can then be used to reverse this refinement into the desired pp m ql p l layered programming in in this section we provide an instantiation of our framework for a language this instantiation serves two purposes it illustrates a common use case for our framework showing its and and it shows that our framework can add and proof infrastructure to existing language subsets at minimal cost our starting point compcert clight clight is a subset of c and is formalized in coq as part of the compcert project its formal semantics relies on a memory model that is not only realistic enough to specify c pointer operations but also designed to simplify reasoning about of different variables from the programmers point of view clight avoids most and of c such as nondeterminism in expressions with side effects on the other hand clight allows for pointer arithmetic and is a true subset of c such simplicity and turn clight into a choice for certified programming however clight provides little support for abstraction and proving properties about a clight program requires reasoning about data structures this issue is addressed by our layer infrastructure abstract state primitives and layer interfaces we enable abstraction in clight and other compcert languages by the memory states used by their semantics with an abstract state component this abstract state can be manipulated using primitives which are made available through external function mechanism we call the resulting language abstract state and external functions the abstract state is not just a ghost state for reasoning it does influence the outcome of executions however we to minimize its impact on the existing proof infrastructure for program and compiler verification we do not modify the semantics of the basic operations of clight or the type of values it uses instead the abstract state is accessed exclusively through external function mechanism primitives and layer interfaces compcert offers a notion of external functions which are useful in modeling interaction with the environment such as inputoutput indeed compcert models compiler correctness through traces of events which can be generated only by external functions compcert the behaviors of external functions without specifying them and only assumes they do not behave in a manner that violates compiler correctness we use the external function mechanism to extend clight with our primitive operations and supply their specifications to make the semantics of external functions more precise definition primitive specification let mem denote the type of memory state and let val denote the type of concrete values a primitive specification over the abstract state type a is a predicate on mem aq pval mem aq when m a res m aq holds we say that the primitive takes arguments args memory state m and abstract state a and returns a result res a memory state m and an abstract state a the type of abstract state and the set of available primitives will constitute our notion of layer interface definition layer interface a layer interface l is a tuple l pa p q where a is the type of abstract state and p is the set of primitives as a finite map from identifiers to primitive specifications over the abstract state a the parametric language syntax the syntax of parameterized over a layer interface l is identical to that of clight it features global variables including function pointers local variables and temporary variables t expressions have no side effects in particular they cannot contain any function call they include pointer comparison offset arrays e n x t constant variable temporary e e e op e statements include assignment to a memory location or a temporary function call and return and structured control loops etc s e e assignment to a memory location t e assignment to a temporary variable t Ð q function call function return s s s else s s function calls may refer to internal functions defined as part of a module or to primitives defined in the l however these two cases are not distinguished syntactically in fact the layer calculus allows for replacing primitive specifications with actual code implementation with no changes to the callers code definition functions modules a function is a tuple sq where is the list of temporaries to receive the arguments is the list of local variables with their sizes and s is a statement the function body a module m is a finite map from identifiers to functions semantics compared with clight the semantics of adds a notion of abstract state and permits calls to the primitives of l we will write m a res m aq to denote the semantics of the primitive associated with identifier i in l we present the semantics of under the form of a bigstep semantics we fix an injective mapping from global variables to memory block identifiers we write e pl mq for the evaluation of expression e under local variables l temporaries and memory state m we write l m l s p m aq Ó m aq for the semantics of statements from the local environment l the temporary environment the memory state m and the abstract state a execution of s terminates and yields result res or ¨ if no result temporary environment memory state m and abstract state a for instance the rule for return statements is e pl mq res l m l p m aq Ó m aq we write l m f m aq m aq to say that a function f defined either as an internal function in the module m or as a primitive in the layer interface l called with list of arguments args from memory state m and abstract state a returns result res memory m and abstract state a for internal function calls we first initialize the temporary environment with the arguments and allocate the local variables of the callee denotes the next available block identifier in memory m not yet allocated then we execute the body finally we the variables of the callee m pf q sz q sz sq m ¨ ¨ ¨ l Ð Ð k ´ s Ð vs Ð l m l s p m aq Ó m aq m sz q ¨ ¨ ¨ k ´ sz l m f pv vn m aq m aq for primitive calls we simply query the layer interface l m a res m aq l m f m aq m aq using the function judgment we can state the rule for function call statements as i ei pl mq vi e pl mq pb q pf q b l m f pv vn m aq m aq rt Ð l m l t Ð enq p m aq Ó m aq i i r i i l id i ÞÑ i i ÞÑ i i i ÑÞ i r i ÞÑ i l id m l l r l l r m l where l is the the module m À i i ÞÑ i the intermediate layer l À i i ÑÞ i and the l À i i ÑÞ i figure building a certified layer m m a a figure layer simulation relation the full semantics of is given in the companion tr definition semantics of a module let m be a module and l be a layer interface let be a mapping from global variables to memory blocks the semantics of a module m in written m l is the layer interface defined as follows · the type of abstract state is the same as in l · the semantics of primitives are defined by the following rule f p q l m f m aq m aq p m m a res m aq layered programming and verification to construct a certified abstraction layer pl m lq we need to find a simulation r such that l r m l holds fig gives an overview of this process we write m À i i ÞÑ i where i ranges over the function identifiers defined in module m and i is the corresponding implementation global variables in m should not be accessible from the layers above their permissions are removed in the interface l the interface l also includes a specification i for each function i defined in m we the task of code verification from that of data structure abstraction we introduce an intermediate layer interface l À i i ÞÑ i with its specifications i expressed in terms of the states we first prove that l id m l holds for each function i in m we show that its implementation i is a downward simulation of its specification i that is l id i ÞÑ i i ÑÞ i we apply the rule to compose all the simulation statements note the simulation relations here are all id meaning there is no abstraction of data structures in these steps we then prove l r l which means that each specification i in l is an abstraction of the intermediate specification i via a simulation relation r from i ÑÞ i r i ÞÑ i we apply the monotonicity rule to get l r l finally we apply the rule to deduce l r m l verifying functions l and l share the same views of both concrete and abstract states so no simulation relation is involved during this step of verification the fun rule in sec using language we have developed a proof automation engine that can handle most of the functional correctness proofs of programs it contains two main parts a interpreter that generates the verification conditions by rules of bigstep semantics and an automated theorem prover that the generated verification conditions struct t u struct at notation notation notation norm inductive t z u z record abs at figure concrete c vs abstract coq memory allocation table at get i allocated allocated if allocated allocated return allocated at set void i b b function at get a i match i with some some none end function at set a i b match i with t some a i t b none end figure concrete vs abstract functions for at inductive at set m m a v n at v m n n at set m a m a inductive at set m a a n v at set a n v some a n at set m a m a figure high level and low level specification for at set on the the automated theorem prover is a first order prover extended with different theory solvers such as the theory of integer arithmetic and the theory of compcert style partial maps the entire automation engine is developed in language data abstraction since primitives in l and l are atomic we prove the downward simulation between l and l only at the specification level the simulation proof for the abstraction can be made language independent the simulation relation r captures the relation between the state concrete memory and abstract state and the state and can be decomposed as and see fig the relation ensures that the concrete memory states m and m contain the same values while making sure the memory permissions for the part to be abstracted are erased in the memory m the component relates the abstract state a with the full state pm aq through this decomposition we achieve the following two objectives the client program can directly manipulate the abstract state without about its underlying concrete implementation which is hidden via and the abstract state in the is actually implementable by the concrete memory and abstract state in the via common patterns we have developed two common design patterns to further ease the task of verification the pattern establishes memory abstraction by introducing new abstract states and the corresponding memory permissions for the the only adds the get and set primitives which are implemented using simple memory operations at the the pattern implements key but does not introduce new abstract state its implementation on does not touch concrete memory state instead it only accesses the states i u i u if u i i if return definition a n v fst v n fst v snd v x x fst v x x x n x function a match a with exist i t a i t i a end figure concrete in c vs abstract in coq function inductive spec m a a n a a n m a n m a definition figure high level and low level specification for function that have already been abstracted and it only does so using the primitives provided by the interface show how we use the two patterns to implement and verify a simplified physical memory allocator which allocates and returns the first free entry in the physical memory allocation table fig shows how we follow the pattern to abstract the allocation table into a new abstract state as shown in fig we first turn the concrete c memory allocation table implementation into an abstract coq data type then we implement the and functions for the memory allocation table both in c and coq see fig the coq functions at get and at set are just intermediate specifications that are used later in the specifications the actual and specifications of the function at set are shown in fig we then prove l id at set ÞÑ at set at set ÑÞ at set and also at set ÞÑ at set r at set ÞÑ at set the code verification first part is easy for this pattern because the memory load and store operations in the match the source code closely the proof can be by our automation tactic the main task of this pattern is to prove refinement second part we design a simulation relation r relating the memory storing the global variable at with its corresponding abstract data at the component ensures that there is no permission for allocation table at in memory state m while the component is defined as follows · i p r q enforces the permission on at memory state m and requires i at to be · except for at requires all other abstract data in and to be the same the refinement proof for l r l involves the efforts to prove that this relation r between memory and abstract state is preserved by all the atomic primitives in both l and l after we abstract the memory and operations we implement on top of l following the pattern the previous now becomes the new l fig shows both the implementation of in and the abstract function in coq as before we separately show that l id ÞÑ ÑÞ p alloc and ÞÑ r ÑÞ p alloc holds for the pattern the refinement proof is easy since we do not introduce any new abstract states in this pattern the implementation only the abstract states through the primitive calls of the thus as shown in fig the corresponding and specifications are exactly the same so the relation r here is the identity id and the proof of refinement is trivial the main task for the pattern is to verify the code which is done using our automation tactic the above examples show that for the pattern the primary task is to prove data abstraction while for the pattern the main task is to do simple program verification these two tasks are well understood and so the via these two patterns makes the layer construction much easier layered programming in lasm in this section we describe lasm the layered assembly language and the extended machine model which lasm is based on the reason we are interested in assembly code and behavior is first of all even though we provide to write most code we are still interested in the actual assembly code running on the actual machine in section we will provide a verified compiler to all proofs of code written in to assembly secondly there are parts of software that have to be manually written in assembly for various reasons for example the standard implementation of kernel context switch modifies the stack pointer register which does not satisfy the c calling convention and has to be verified in assembly a will be defined in section to link them with compiled c code last but not least we are interested not only in the behavior of our code but also in the behavior of the context that will call functions defined in our code to be as general as possible we allow the context to include all valid assembly code sequences to this end it is necessary to refinement proofs to a contextual refinement proof the lasm assembly language we start from the bit x assembly subset specified in compcert compcert x assembly is modeled as a state machine with a register set and a memory state the register set consists of bit generalpurpose registers and registers designated as scalar floatingpoint operands the memory state is same as the one in clight in particular each function executes with its stack frame modeled in its own memory block so that the stack is not a piece of memory another regarding function calls in compcert x assembly is that the return address is stored in ra instead of being pushed onto the stack so that the callee must allocate its own stack frame and store the return address similarly to we extend the machine state with an abstract state which will be modified by primitives this yields lasm whose syntax is the same as that of compcert x assembly except that the semantics will be parameterized over the type of abstract states and the specifications of primitives most notably primitive calls are syntactically from normal function calls yet depend on the specifications semantically moreover in our coq formalization the semantics of lasm is also equipped with memory for address translation in order to handle both kernel memory linear mapping and user space virtual memory however for the sake of presentation we are going to describe a simplified version of lasm where memory accesses only use the kernel memory we define the semantics of lasm in smallstep form the machine state is p m aq where contains the values of registers m is the concrete memory state and a is the abstract state let m be an lasm module which is a finite map from identifiers to arrays of lasm instructions we write l m p m aq Ñ p m aq a transition step in the lasm machine the full syntax and formal semantics of lasm is described in the companion technical report assembly layer interfaces the semantics of lasm is parameterized over a layer interface different from primitives see def which are defined using argument list and return value primitives implemented in lasm often their full control over the register set and are not restricted to a particular calling convention eg context switch therefore it is necessary to extend the structure of layer interfaces to allow primitives modifying the register set definition primitive an specification p over the abstract state type a is a predicate on Ñ mem aq Ñ mem aq pp m a m aq says that the primitive p takes register set memory state m and abstract state a as arguments and returns register set memory state m and abstract state a as result by style we mean the calling convention not the language in which they are actually implemented primitives may very well be implemented as assembly code at we can then define assembly layer interfaces by replacing the primitive specification with our one in def but to make reasoning simpler when defining assembly layer interfaces we distinguish from primitives first primitives can be refined by other primitives second and most importantly it becomes possible to instantiate the semantics of with an assembly layer interface by just considering primitives and ignoring primitives which might not follow the c calling convention in this way code is only allowed to call primitives whereas lasm can actually call both kinds of primitives definition assembly layer interface an assembly layer interface l is a tuple l pa where · pa is a c layer interface see def · is a finite map from identifiers to primitive specifications over the abstract state a the domains of and shall be disjoint semantics and contextual refinement based on the relational transition system which we just defined for lasm we can define the semantics including not only the code that we by hand or that we compile but also the context code that shall call our functions to this end it suffices to the semantics with a notion of initial and final state in a way similar to the compcert x assembly semantics in compcert the initial state consists of an empty register set with only instruction pointer register pointing to the main function of the module and the memory state is constructed by allocating a memory block for each global variable of the program we follow the same approach for lasm except that we also need an initial abstract state provided by the layer interface so we need to extend its definition definition layer interface a layer interface l is a tuple l pa aq where · pa is an assembly layer interface · a a is the initial abstract state definition initial state the lasm initial state for layer interface l and module m is the lasm state p m aq defined as follows q if r · if r ra k otherwise · m is constructed from the global variables of l m · a is the initial state specified in l definition final state a lasm state p m aq is final with return code n if and only if n and where eax is the register notice that contains the integer which is also the initial return address and is not a valid pointer this ensures that executions do not go beyond a final state following the compcert x semantics main has returned to its caller which does not exist thus the final state is uniquely determined there can be no other possible behavior once such a state is reached so the semantics is deterministic once the primitives are definition behavior let be a mapping of global variables to memory blocks then we say that · l m q diverges if there is an infinite execution sequence from the initial state for l · l m q terminates with return code n if there is a finite execution sequence from the initial state for l to a final state with return code n · l m q goes wrong if there is a finite execution sequence from the initial state for l to a state that can take no step then we are interested in refinement between whole machines definition refinement let be two assembly layer interfaces and be two lasm modules then we say that refines and write if and only if for any such that y y y and does not go wrong then does not go wrong if terminates with return code n then so does if diverges so does in our coq implementation we actually formalized the semantics of lasm with a richer notion of observable behaviors involving events such as io thus we define the behaviors and refinement using event traces a la compcert if the higher machine does not go wrong then every valid behavior of the lower machine is a valid behavior of the higher finally we can define contextual refinement between layer interfaces through a module m definition contextual refinement we say a module m implements an on top of an and write m if and only if for any module context m disjoint from m we have pm m m semantics as for we can also specify the semantics of an lasm module as a layer interface however a major difference between and lasm is that it is not possible to uniquely characterize the final state at which function execution should stop indeed as in lasm there is no control stack when considering the semantics of a function f it is not possible to distinguish f and returning control to its caller from a callee g returning to f thus even though both the step relation of the lasm semantics and the primitive specifications of a layer interface are deterministic the semantics of a function could still be nondeterministic definition let l pa q be an assembly layer interface and m be an lasm module the module semantics m l is then the assembly layer interface m l pa h p q where the primitive specification p is defined for each f p q using the smallstep semantics of lasm as follows p pf qp m a m aq pf q b pb q l m p m aq Ñ p m aq soundness of refinement in this paper we aim at showing that the layer calculus given in section is a powerful device to prove contextual refinement instead of proving the contextual refinement directly we only need to prove the downward simulation relations about individual modules as r m and apply the soundness theorem to get the contextual refinement properties at the level lemma downward simulation diagram let m be a certified layer such that r m then for any module m we have the following downward simulation diagram r r slow m slow theorem soundness let m be a certified layer if the primitive specifications of are deterministic and if r m then m proof since the whole machine mq is deterministic we can flip the downward simulation given by lemma to an upward one hence the refinement since the semantics is nondeterministic due to its final state not being uniquely defined we can only flip the downward simulation to contextual refinement at the level certified compilation and linking we would like to write most parts of our kernel in rather than in lasm for easier verification this means that for each layer interface l we have to compile our source code to the corresponding assembly language in such a way that all proofs at the level are preserved at the lasm level this section describes how we have modified the compcert compiler to compile certified c layers into certified assembly layers it also about how we link compiled certified c layers with other certified assembly layers the verified compiler to the proofs at down to lasm we adapt the compcert verified compiler to all its intermediate languages over the layer interface l similarly to how we defined including the assembly language this gives rise to for compcert extended where external functions are instantiated with layer interface l goes from to the similarly parameterized and then to lasm we retain all features and optimizations of compcert including function inlining dead code elimination common subexpression elimination and tail call recognition compiler correctness for because compcert only proves semantics preservation for whole programs the major challenge is to adapt the semantics preservation statements of all compilation passes from clight to assembly to semantics the operational semantics of all compcert languages are given through smallstep transition relations equipped with sets of initial and final states so we have to those states to setting for the initial state whereas compcert constructs an initial memory and calls main with no arguments we take the function pointer to call the initial memory and the list of arguments as parameters for the final state we take not only the return value but also the memory state when we exit the function consequently the compiler correctness proofs have to change currently compcert uses a downward simulation diagram for each pass from clight then thanks to the fact that the compcert assembly language is deterministic up to input values given by the environment compcert all of them together before them to a single upward simulation which actually entails that the compiled code refines the source code in this work we follow a similar approach for each individual pass we prove semantics preservation in a downward simulation we do not however turn it into an upward simulation because the whole layer refinement proof is based on downward simulation which is in turn turned into an upward simulation at contextual refinement thanks to the determinism up to the environment of memory state during compilation the main difference between compcert and lies in the memory given at the beginning of a function call in the setting the initial state is the same across all languages because it is uniquely determined by the global variables which are preserved by compilation on the other hand in the middle of the execution when entering an arbitrary function the memory in clight is different from its assembly counterpart because compcert introduces memory transformations such as memory or extensions to the stack frames this is actually for compilation of handling arguments and the return address for within the module being compiled the same memory state also exists at module entry however we cannot assume much about the memory state because it is given as a parameter to the semantics of each function in the module in fact this memory state is determined by the caller so it may very well come from code eg arbitrary assembly user code thus we have to take the same memory as initial state across all the languages of it follows then that the arguments of the function already have to be present in the memory following the calling convention imposed by the assembly language even though does not read the arguments from memory another difference between compcert and is the treatment of final memory states in compcert only the return value of a program is observable at the end the final memory state is not by contrast in the final memory state is passed back to the caller hence observable thus it is necessary to account for memory transformations when relating the final states in the simulation diagrams compilation refinement relation finally the compiler correctness statement of can be roughly summarized as this commutative diagram and formally defined below v m a l m a jj l « m a definition let lc be a c layer interface and lasm be an assembly layer interface we say that lc is simulated by lasm by compilation written lc comp lasm if and only if for any and for any execution lc pf m a v m aq of a primitive f of lc for some list l of arguments and some return value v from memory state m and abstract state a to m and a and for any register map such that the following requirements hold the memory m contains the arguments l in the stack pointed to by points to the function f being called q q then there is a primitive execution qp m a m aq and a memory injection j from m to m preserving the addresses of m such that the following holds · the values of registers in are preserved in · points to return address · the return value contained in for or for is related to v by j theorem let l be an assembly layer interface with all primitives preserving memory transformations then for any m m l comp q l more details can be found in the companion technical report linking compiled code with assembly code contrary to traditional separate compilation we target compiling functions that may be called by lasm assembly code since the caller may be arbitrary lasm code not necessarily wellbehaved code written in or compiled from we have to assume that the memory we are given follows lasm layout when reasoning about memory states that involve compiled code we then have to accommodate memory introduced by the compiler during a refinement proof the two memory states of the and the are related with a simulation relation r however consider when the higher lasm code calls an primitive that in the is compiled from because during the simulation proofs we ignored the effects of the compiler the memory injection introduced by the compiler may become a source of that is why we in r a memory injection between the higher memory state and the lower memory state this injection is identity until the lower state calls a compiled function then at every such call the layer simulation relation r can compilation refinement on its righthand side lemma if l and lc are c and lasm is an assembly with l r lc and lc comp lasm then l r lasm proof if r a memory injection j and compilation introduces a memory injection j then the simulation relation r will still hold with the composed memory injection j j summary of the refinement proof with compilation and linking finally the outline of proving layer refinement l m l where m is the union of a compiled module and an lasm module is summarized in the following steps also shown in fig split the l into two layer interfaces lc and lasm where lc is a c layer interface containing primitive specifications to be implemented by code necessarily and lasm is an assembly layer interface containing all other primitives implemented in lasm so that l lc lasm for each such part of the design an intermediate layer interface lc and lasm with the same abstract state type as l see section and prove lc r l c and lasm r l independently of the implementation for both intermediate layer interfaces prove that they are implemented by modules mc and on top of l respectively ie l c id mc l and lasm id l then compile mc mc l comp l lc À lasm r l c r lasm id mc l comp l À id l m l id lo l r figure proof steps of layer refinement l r m l using and to combine and we have lc lasm r l c l id mc l l on the c side left of lemma shows that r comp by lc lasm r l l from the soundness of proof in tr and because m we have l l id m l finally by combining and we have lc lasm r m l since l lc lasm by using and we have l r m l id m l l id l m l thus we get l r m l case study certified os kernels to demonstrate the power of our new languages and tools we have applied our new layered approach to specify and verify four variants of kernels in the coq proof assistant this section describes these kernels and the benefits of the approach the base kernel is a simplified version of the kernel designed for the bit x architecture it provides a environment for applications using separate virtual address space where the communications between different applications are established by message passing the kernel built on top of the base kernel is a realistic kernel that can recent versions of linux operating systems and the kernel extends the supporting ring processes safe services and application programs inside the kernel address space finally we strip the last kernel down to the kernel removing virtual memory and interrupt handling this results in a minimal operating system suitable for embedded environments the layer structures of these kernels are shown in the top half of fig each block in the top half represents a collection of shown in the bottom half as we in on the layered approach is the key to our success in fully a kernel in sec we have shown how to define and for abstract data types like those in fig allowing higher layers to manipulate abstract states furthermore is also crucial to certification of thread queues as discussed in sec instead of directly proving that a c implements a functional list we insert an intermediate layer as shown in fig to divide the difficult task into two steps these may look like proof techniques for enabling abstract states or reducing proof effort but they the following which makes our certification more efficient and scalable base trap proc vm mm trap proc vm mm rz trap proc vm mm proc mm figure various layer structures layer trap interrupt handling proc process management thread management vm virtual memory mm physical memory management abstract in minimal steps specify full behavior and hide all underlying details this is also how we prove the overall contextual correctness guarantees for all system calls and interrupt handlers fig shows the call graph of the page fault handler including all functions called both directly and indirectly indicate functions arrows mean primitive invocations and dashed lines are primitives that are translated by all the layers they pass through defined in layer interface the page fault handler makes use of proc exit and proc start both defined in layer interface since the invocations of them are separated by other primitive calls one may expect that the invariants need to be or the effects of the calls fortunately as our suggests when the layers translate the two primitives to layer interface the behaviors of them are fully specified in terms of abstract states and the invariants of layer interface are considered the underlying details and have all been hidden this is especially important for calls like proc exit to set which span over layers with the abstract states so different that direct translation is not feasible finally kernel initialization is another difficult task that has been missing from other kernel verification projects the traditional kernel initialization process is not compatible with specify full behavior and hide all underlying details for example start kernel in linux kernel makes a sequence of calls to module initialization see its call graph in fig is a chain of calls to layer this pattern with the that one layer should hide the detail about the lower layers without the specifications of all functions will be with initialization flags for each module they depend on this makes encapsulation harder and could also lead to a quadratic in size and proving effort the kernel provides core primitives to build by supporting one of the two popular hardware ­ the primitives include the operations for manipulating the virtual machine status handling starting or a virtual machine etc the details of eg the virtual machine control block and the nested page table are hidden from the applications the are implemented in layers and then inserted in between process management and interrupt handling layers the layered approach allows us to do so while only modeling structures when needed primitives in the layer interface by systematic lifting and adding new primitives including a new initialization function guaranteed not to interfere with existing primitives figure call graph of the page fault handler figure call graph of the kernel a different of adding intermediate layers we augmented a few existing layers in with support of ring processes the main modification is at where an additional kind of threads is defined however all the layers between and also need to be extended to expose the functionality as system calls since all the new primitives are already described in deep specifications lifting them to system calls only requires equality reasoning in coq the kernel features down to a minimum it does not switch to user mode hence does not require memory protection and does not provide system call interfaces this requires removing features instead of adding them since the layered structure by eliminating unnecessary dependencies and code the removal process was relatively easy and straightforward moreover removing the top layers requires no additional specifications for those now toplevel specifications are suitable for both internal and external descriptions thread and process management layers now directly on top of physical memory management virtual memory is never enabled the layers remain largely the same the removal of primitives page tables evaluation and limitations the and development of took person plus person on linking and code extraction with the infrastructure in place only took person to finish and and take half a person each the kernels are written layer by layer in lasm and abstract along with driver functions specifying how to compose link them all of those are in coq for the proofs to refer to we code extraction to get an ocaml program which contains the abstract syntax trees of the kernels and the driver functions which invoke on pieces of code and generate the full assembly file the output of the ocaml program is then to an to produce the kernel executable with the device drivers running as user processes and a scheduler most of the benchmarks in are under x running in well within expected over head ring processes not used in the above experiment can easily lower the number as we measured one to two orders of magnitude reduction in the number of cycles needed to serve system calls because the proof was originally developed directly in terms of abstract machines and program transformations the current code base does not yet reflect the calculus presented in sec in its notably vertical composition is done at the level of the contextual refinements obtained by applying the soundness theorem to each individual abstraction layer outside our verified kernels consists of about lines of c and assembly there are lines of c and lines of x assembly code that are not verified yet the procedure the used by user process creation and functions such as which currently cannot be verified because of a limitation arising from the compcert memory model device drivers are not verified because lasm lacks device models for expressing the correctness statement finally the compcert for converting lasm into machine code remains unverified related work program verification hoare logic and its modern variants were introduced to prove strong partial or total correctness properties of programs annotated with postconditions a hoare triple rp often means a refinement between the implementation c and the specification rp qs given any state s if the precondition p holds then the command c can run safely and terminate with a state that satisfies q though not often done it is also possible to introduce states to serve as abstract states and prove that a program implements a specification via a simulation our layer language can be viewed as a novel way of a module system over program verification we on using interfaces with deep specifications and we address the conflicting abstract states problem mentioned in sec traditional program verification does not always use deep specification for postconditions so the module interfaces eg rp qs may allow some safe but behaviors such gap is fine if the goal is to just prove safety as in static typechecking but if we want to prove the strong contextual correctness property across module boundaries it is important that each interface accurately describes the functionality and scope of the underlying implementation in addition to the obvious benefits on compositionality our layered approach also enables a new powerful way of combining programming and specification languages in a single setting each layer interface enables a new programming language at a specific abstraction level which is then used to implement layers at even higher levels as we move up the layer hierarchy our programming language gets closer and closer to the specification can call primitives at higher abstraction levels but it still supports generalpurpose programming eg in interestingly we did not need to introduce any program logic to verify our os kernel code instead we verify it directly using the or lasm language semantics which is already parameterized over a layer interface in fact unlike hoare logic which shows that a program eg c refines a specification eg rp qs we instead show there is a downward simulation from the specification to the program as in compcert we found this easier to prove and we can do this because both our specification and language semantics are deterministic relative to external events program refinement dijkstra proposed to realize a complex program by it into a hierarchy of linearly ordered abstract machines based on this idea the team at developed the hierarchical development methodology and applied to design and specify an os using organized modules was difficult to be applied in practice probably because of the lack of powerful specification and proof tools in this paper we advance the paradigm by using a new formal layer language to connect multiple layers and by implementing all certified layers and proofs in a modern proof assistant we also decomposition more since it made our verification task much easier refinement calculus is a formalized approach to refinement using this calculus a highlevel specification can be refined through a series of transformations and eventually turned into an efficient executable our work imposes a new layer language to compositional reasoning we use or lasm and the coq logic as our refinement language and use a certified layer with deep specification to represent each such transformation all our and lasm instances have executable semantics and can be compiled and linked using our new compiler separate compilation for compcert compositional compiler correctness is an extremely challenging problem especially when it involves an open compiler with multiple languages in the context of compcert a recent proposal aims to the full clight language but it has not been fully implemented in the compcert compiler while our compiler proves a stronger correctness theorem for each layer the language is different from the original clight language within each layer all locally allocated memory blocks eg stack frames cannot be updated by functions defined in another layer this means that does not support the same general data structures as in clight this is fine for our os kernels since they do not allocate any data structures on stack but it means that can not be regarded as a full separate compiler for compcert os kernel verification the sel team were the first to build a proof of functional correctness for a realistic the sel work is in that all the proofs were done inside a modern mechanized proof assistant they have shown that the behaviors of lines of their c code always follow an abstract specification of their kernel to make verification easier they introduced an intermediate executable specification to hide c both their abstract and executable specifications are monolithic as they are not divided into layers to support abstraction among different kernel modules these kernel led to more complex invariants which may explain why their effort took person years the initial sel effort was done completely at the c level so it does not support many assembly level features such as address translation this also made verification of assembly code and kernel initialization difficult lines of c and lines of assembly are still unverified it is also how to use their verified kernel to reason about programs since they would be running in a different address space our certified kernels on the other hand directly model machines that support all and programs memory access to a address space must go through a page table and memory access in a virtual machine must go through a nested page table we thus had no problem verifying our kernel initialization or assembly code modular verification of lowlevel code and shao also used a layered approach to verify a small virtual memory manager their layers are not linearly ordered instead their abstract machines form a dag with potential ie calls from a lower layer to upper ones as a result their initialization function an was much harder to verify their refinement proofs between layers are to termination from which they can only prove partial correctness but not the strong contextual correctness property which we prove in our current work et al developed an open framework for linking components verified in different domainspecific program logics they verified a thread library with hardware interrupts and using a variant of concurrent separation logic they decomposed the thread implementation into a sequential layer with interrupts and a concurrent layer with interrupts enabled developed an automated coq library to support verified lowlevel programming all these systems to prove partial correctness only so they are quite different from the layered simulation proofs given in this paper conclusions abstraction layers are key techniques used in building computer software and hardware in this paper we have presented a novel languagebased account of abstraction layers and shown that they are particularly suitable for supporting abstraction over deep specifications which is essential for compositional verification of strong correctness properties we have designed a new layer language and imposed it on two different core languages and lasm we have also built a verified compiler from to lasm by each complex abstraction into smaller abstraction steps we have successfully developed several certified os kernels that prove deeper properties contextual correctness contain smaller trusted computing bases all code verified at the assembly level require significantly less effort lines of c and assembly code proved in less than person year and demonstrate strong support for layers are reused in different certified kernels we expect that both deep specifications and certified abstraction layers will become critical and important building blocks for developing certified system in the future acknowledgments we thank david jan peter david members of the team at yale and anonymous for helpful comments and suggestions that improved this paper and the implemented tools this research is based on work supported in part by grants fa and fa nsf grants and and grant n it is also supported in part by and national natural science foundation of grants and any and conclusions contained in this document are those of the authors and do not reflect the views of these references c y and k b design rules volume the power of modularity mit press march m by e r b and k r m leino a modular verifier for objectoriented programs in proc th symp on formal methods for components and objects n benton and ck and compiler correctness in icfp pages ­ l g r and a w appel verified compilation for c in esop pages ­ s and x leroy mechanized semantics for the clight subset of the c language j automated reasoning ­ q j t and z shao verification of bounds for c programs in pldi s s gulwani and r continuity analysis of programs in popl pages ­ a verification of lowlevel programs in computational separation logic in pldi pages ­ e w dijkstra notes on structured programming in structured programming pages ­ academic press x z shao y and y lowlevel programs with hardware interrupts and threads in pldi pages ­ june x z shao y and y combining domainspecific and foundational logics to verify complete software systems in pages ­ l a b z shao and d a certified kernel for secure computing in r j t z shao x wu sc h and y deep specifications and certified abstraction layers yale univ technical report http oct c a r hoare an axiomatic basis for computer programming communications of the acm ­ oct ck d dreyer g and v vafeiadis the of bisimulations and kripke logical relations in popl pages ­ d software abstractions logic languages and analysis the mit press g k g j d p d k et al sel formal verification of an os kernel in pages ­ october l lamport the temporal logic of actions acm transactions on programming languages and systems may x leroy the compcert verified compiler ­ x leroy a formally verified compiler journal of automated reasoning ­ x leroy and s formal verification of a memory model and its uses for verifying program transformation j automated reasoning ­ n a and f w forward and backward simulations i systems inf comput ­ r milner m tofte r harper and d macqueen the definition of standard ml revised mit press cambridge massachusetts j c mitchell representation independence and data abstraction in popl pages ­ january c c morgan programming from specifications nd edition prenticehall a g morrisett and l birkedal polymorphism and separation in hoare type theory in icfp pages ­ sept p g r s r j k n and l a provably secure operating system its system its applications and proofs technical report csl may p w ohearn resources concurrency and local reasoning in concur pages ­ j t and a ahmed verifying an open compiler using semantics in esop pages ­ b c pierce types and programming languages the mit press j c reynolds theories of programming languages cambridge university press j c reynolds separation logic a logic for shared mutable data structures in lics pages ­ j v vafeiadis f z s and p sewell a verified compiler for concurrency j acm m the z notation a reference manual prentice hall the coq development team the coq proof assistant ­ a and z shao compositional verification of a virtual memory manager in pages ­ dec 