{"article_publication_date": "09-12-2005", "fulltext": "\n A Language-based Approach to Functionally Correct Imperative Programming Edwin Westbrook, Aaron Stump, \nIan Wehrman Computer Science and Engineering, Washington University in Saint Louis {ewestbro,stump,iwehrman}@cse.wustl.edu, \nhttp://cl.cse.wustl.edu Abstract In this paper a language-based approach to functionally correct im\u00adperative \nprogramming is proposed. The approach is based on a programming language called RSP1, which combines \ndependent types, general recursion, and imperative features in a type-safe way, while preserving decidability \nof type checking. The methodology used is that of internal veri.cation, where programs manipulate programmer-supplied \nproofs explicitly as data. The fundamental technical idea of RSP1 is to identify problematic operations \nas im\u00adpure, and keep them out of dependent types. The resulting lan\u00adguage is powerful enough to verify \nstatically non-trivial proper\u00adties of imperative and functional programs. The paper presents the ideas \nthrough the examples of statically veri.ed merge sort, stati\u00adcally veri.ed imperative binary search trees, \nand statically veri.ed directed acyclic graphs. Categories and Subject Descriptors D.3 [Software]: Program\u00adming \nLanguages General Terms Languages, Veri.cation Keywords Dependent Types, Program Veri.cation, RSP, RSP1 \n1. Introduction Impressive progress in veri.cation and analysis of imperative pro\u00adgrams continues to \nbe made in several research communities. In static analysis, techniques like shape analysis have been \nused to verify properties of the reference graph (e.g., [18, 27, 14]). The\u00adorem proving techniques in \nhigher-order logics have also been ap\u00adplied (e.g., [17]). Rapid development continues based on separation \nlogic [26], a substructural logic that has proved convenient for stat\u00ading properties of the reference \ngraph. In the present work, we develop an alternative, language-based approach to functionally correct \nimperative programming, based on the idea of internal veri.cation [1, 2]. In internal veri.cation, proofs \nare data in a dependently typed programming language. Functions are written to require proofs of their \npreconditions as ad\u00additional arguments, and return proofs of their postconditions. Type checking ensures \nthat proofs are manipulated soundly, guarantee\u00ading partial correctness: If the program terminates and \nencounters no run-time errors, then the speci.ed properties will hold. Depen- Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 05 September 26 28, 2005, Tallinn, Estonia. \nCopyright c . 2005 ACM 1-59593-064-7/05/0009. . . $5.00. dent types are used for two reasons. First, \nthe judgments-as-types principle allows speci.cations to be represented as types, with their proofs represented \nas objects of those types. Second, dependency allows a type checker to connect proofs and the data the \nproofs prove something about. Dependent types are supported by a number of languages [22, 3, 16, 9, 7, \n15, 6]. Including support for general recursion and im\u00adperative features while retaining desirable meta-theoretic \nproperties like decidability of type checking is technically challenging. Twelf is the only system the \nauthors know where this has been achieved, but the solution there depends heavily on the fact that logic \npro\u00adgramming is taken as the programming paradigm (more on this in Section 7). The technical challenges \narise due to the fact that if ar\u00adbitrary objects can index types, then unrestricted recursion in types \ncan cause type checking to be undecidable (as some objects that in\u00addex types might not terminate); and \nreads of mutable state in types are unsound, since the mutable state, and thus the types, can change \nover time. The goal of this paper is to present a type-safe language, RSP1, that allows programming with \nproofs in the presence of unre\u00adstricted recursion and imperative features, while retaining decid\u00adable \ntype checking. The key insight enabling this is purity: only objects which are considered pure are allowed \nto index types. Un\u00adrestricted recursion and imperative reads and writes are considered impure, and are \nbanned from types. This concept could potentially be extended to other features that do not mix well \nwith dependent types. The paper presents several examples of (imperative) pro\u00adgramming with proofs in \nRSP1 (Section 3), including binary search trees where the binary search tree property is statically veri.ed, \nand directed graphs which are statically veri.ed to be acyclic. A pure functional example is also included, \nstatically veri.ed merge sort. Technically, RSP1 is .rst-order (thus the 1 in its name): it does not \nallow functions or function application in its types. Lambda-abstractions are replaced by a more powerful \npattern\u00admatching facility, which is considered impure. This prevents the direct use of of Higher-Order \nAbstract Syntax [21] in the language, as it cannot appear in types. Despite the lack of this feature, \nmany useful properties of algorithms and imperative data structures can be veri.ed in the .rst-order \nsetting of RSP1. Omitting lambdas from types also has the advantage that there is no need to consider \n\u00df-or .-equivalence in type-checking. This greatly simpli.es the proof of the decidability of type-checking, \nwhich is notoriously hard to prove in systems with \u00df-and .-equivalence [12, 10]. This also makes it straightforward \nto compile RSP1 to machine code to OCaml, for which compilers to native code exist. The rest of this \ndocument is organized as follows. Section 2 gives an overview of the language RSP1. Section 3 discusses \nhow programming with proofs interacts with the purity and .rst-order restrictions, and presents the examples. \nSection 4 brie.y describes our approach to compiling RSP1. Section 5 gives an in-depth ac\u00ad Objects M \n::= xIcIM1M2 IM :: T I let rec D in M IR IM.l I .Inull IM.c IM1.c := M2 a ITM I.{r,c,a} Types T ::= x: \nT1.T2 IRT Kinds K ::= type I.r x: T.K Pattern .::= E Ix\\M1\\G .M2 |. Abstractions Records R ::= [] I[l \n= M,x.R] I[l = M,R] Variable Def- D ::= d1 : T1 = M1,...,dn : Tn = Mn initions Record Types RT ::= {}I{l \n: T,x.RT} Signatures S ::= \u00b7IS,a: K IS,c : T Contexts G ::= \u00b7IG,x : T Figure 1. RSP1 Syntax count of \nthe static semantics of the language. Section 6 describes the operational semantics of the language. \nSection 7 discussed re\u00adlated work. Finally, Section 8 concludes and gives directions for future work. \nThe proofs of lemmas given in the text are given in the expanded, tech report version of this article. \n[30] 2. Language Overview In this Section, we give an overview of RSP1 through its syntax. The .rst \nhalf of the section describes the constructs of the language and how they are used. We then go on to \nde.ne some other impor\u00adtant syntactic concepts of the language, such as purity, representa\u00adtional objects, \nwhat counts as .rst-order types, and patterns as they are allowed in pattern-matching. The syntax of \nRSP1 is given in Figure 1. Each category of term is given an abbreviation, such as M for terms or T for \ntypes. Throughout this document, we will refer to the various categories of terms in the Figure by the \nletter(s) or symbol(s) given with them, possibly with numeric subscripts or primes, as in M1 or Ml. Other, \nnon-numeric subscripts will be used for special restrictions of these categories, like the pure or representational \nobjects, which are given below. We will also use x, y, and z for variables, c for object\u00adlevel constants, \na for type-level constants, l for record labels, and dfor de.nition variables (discussed below), again \nwith possible subscripts or primes on any of these. Note that, since some of the constructs given are \ncannot be written in ASCII text (e.g. .r), there are a few instances where RSP1 code differs from this \n.gure. These will be discussed where appropriate. The central concepts in Figure 1 are the objects, the \ntypes, the kinds, the signatures, and the contexts, as in LF [11]. The objects level terms are the programs \nof RSP1. The well-formed programs of RSP1 have types, and the well-formed types have kinds. Signatures \nare used to type user-de.ned type-and term\u00adconstructors, while contexts are used to type variables. Starting \nat the top of this hierarchy are the standard kinds of LF: type, which classi.es all the types that may \nbe had by objects, such as record types and some user-de.ned types; and .r x : T.K, the kind of types \nindexed by objects of type T. (In LF, kind-level abstractions are normally written .x: T.K, but we add \nthe rsuperscript, which stands for representational, to distinguish from two other sorts of abstraction \nin RSP1.) The construct .r x : T.K appears in RSP1 code as x:T =>K. At the type level are: type constants, \na; type applications, TM1 ...Mn, indicating a type of family T indexed by objects M1 through Mn; representational \nabstraction types, .r x : T1.T2, for typing functions in the LF fragment (which, as RSP1 has no lamb\u00addas, \nare an application of a constant to less than its required num\u00adber of arguments); computational abstraction \ntypes, .c x : T1.T2, for typing pattern abstractions, the computational element of the language; attribute \nabstraction types, .a , for typing attributes (see below); and dependent record types, {l1 : T1,x1.{...{ln \n: Tn,xn.{}}...}}(the right-associating dependent record types of [25]), in which the types of later .elds \nmay be indexed by the names of earlier ones. The abstraction types, .r x : T1.T2, .c x : T1.T2, and .a \nx : T1.T2, are written x:T1 => T2, x:T1 =c> T2, and x:T1 =a> T2, respectively. Note that the type constants, \ntype ap\u00adplications, and representational abstractions are exactly the type constructs of LF. The objects, \nbeing the programs of RSP1, have more constructs. The .rst three constructs of the objects given in Figure \n1, variables, constants, and application, are standard, though in RSP1, applica\u00adtion is written the same \nfor the LF fragment and for applying pat\u00adtern abstractions. The next two constructs, type ascription \n(written M :: T) and let rec, are also standard (see e.g. [23]). Type as\u00adcription allows the user to \nascribe a type to a term, and is useful because the type inferencing algorithm for RSP1 is not complete. \nThe let rec construct, similar to that found in ML, allows general recursion. It is slightly nonstandard \nin that it requires the special d variables, which are just like normal variables, except they are im\u00adpure. \nThis is because they represent recursive terms, so evaluation of them may not terminate. Records in RSP1 \nare of two sorts: dependent records and in\u00addependent, dependently typed records. The latter are the right\u00adassociating \nrecords of [25], and are written [l1 = M1,[...[ln = Mn,[]] ...]] in RSP1, where the li are the record \nlabels and the Mi are the .elds of the record. Dependent records allow later .elds of a record to refer \nto previous .elds. These are written [l1 = M1,x1.[...[ln = Mn,xn.[]] ...]], where the xi variables can \nbe used in later .elds to refer to earlier ones. These two styles can be freely intermixed. To increase \nreadability, the user can omit the variables and all but the outermost brackets, which is syntactic sugar \nfor dependent records with variables named the same as their .elds. For example, the code [l1 =c, l2 \n=f(d l1)] makes a dependent record wherein the second l1 (in the l2 .eld) refers back to the value of \nthe .rst .eld. Record selection, written M.l, is then used to extract elements of records. The pattern \nabstractions, abbriviated ., are the central computa\u00adtional element of the language. These are written \nx1\\M1\\G1 . M1l|...|xn\\Mn\\Gn . Mnl|E. When applied to an argument, a pattern abstraction matches each \nMi (the patterns) against the argument, starting from the .rst, until one matches, i.e. until it .nds \nsome substitution for the variables in Gi (the pattern vari\u00adables) to make the pattern equal to the term. \nIf, say, pattern Mi matches the argument, then the whole argument is substituted for xi into Mil(the \nbody), while the subterms of the argument that matched the pattern variables are substituted for them \ninto body as well. The resulting term is then evaluated. For instance, the iden\u00adtity function on type \nT could be written x\\ y\\y:T -> x or x\\ y\\ y:T ->y as anything matches the single pattern vari\u00adable y. \nNote that we elide the empty pattern, E, in code. As a second example, if we create the type nat of natural \nnumbers, with con\u00adstructors zero and succ (so e.g. 3 would be represented by succ succ succ zero), then \nthe pattern function x\\ zero \\-> zero | x\\succ y\\ y:nat -> y would be the standard predecessor function \n(taking the predecessor of0tobe0). Rep. Object Mrep ::= x Ic IMrep Mrep Pure Object Mpure ::= Mrep IMpure.l \nI [l = Mpure,x.Mpure] I [l = Mpure,Mpure] I[] Pure Pattern Mppat ::= Mrep I[l = Mppat,Mppat] I[] Pattern \nMpat ::= Mppat Inull Zero-Order Rep. Type TZRep ::= a ITZRep Mrep Zero-Order Type TZ ::= TZRep I{l : \nTZ,x.TZ}I{} Rep. Type Trep ::= TZRep I.r x : TZRep.Trep Figure 2. Other Syntactic Concepts of RSP1 If \nno pattern in a pattern abstraction matches, then it returns the special term null. null is considered \na run-time error in RSP1, and behaves like an exception: records that contain null as a .eld, as well \nas applications that contain null as either the function or the argument, evaluate to null themselves \n(except that pattern abstractions can match a null argument by having null as a pattern). Thus no value, \nother than pattern abstractions, will have null as a proper subterm. This means that run-time errors \ntrickle up to the top of a term, and can immediately be detected by checking against null. Finally, the \nattribute operations, M.c and M.c := Ml, consti\u00adtute the imperative feature of RSP1. An attribute is \na user-de.ned constant of type .a x : T1.T2. These act like hashtables: if c is an attribute, then M.c \nlooks up the value associated with M in c s hashtable and M.c := Ml updates this value to be Ml. Attributes \nare slightly different than references, the standard imperative fea\u00adture, but experience with RSP1 has \nshown attributes to be a useful mechanism for capturing dependencies: the fact that attributes have product \ntypes (as suggested by the .) means that the type of M.c can be indexed by M. In addition to these constructs, \nwe shall .nd two pieces of syn\u00adtactic sugar very useful. The .rst, let x= M1in M2, does local variable \nbinding. This stands for for (x \\y\\ y:T ->M2) M1, where T is the type of M1, and y is a fresh variable. \nThe second, if M1 then M2 else M3, tests M1 against null. This form stands for (x \\null \\ -> M3 | x\\y \n\\y:T -> M2) M1, where T is the type of M1 and x and y are new variables. We shall also de.ne some other \nimportant concepts in RSP1 in terms of syntax. These de.nitions are given in Figure 2. The repre\u00adsentational \nobjects and types are the LF fragment of the objects and types, respectively. Note the zero-order restriction \non the argument type of .r-abstractions. The pure objects include the representa\u00adtional objects plus \nrecords and record selects. These will be the only objects allowed to index types. The patterns, made \nof records and representational objects or a single null, are the only patterns allowed in pattern abstractions. \nThus a pattern abstraction cannot match on the form of another pattern abstraction. Finally, the zero\u00adorder \ntypes, which omit the abstraction types, will be the only ar\u00adgument types allowed for computational and \nattribute abstractions types. The concept of purity, as mentioned above, is important in ensuring type \nsoundness and decidability. The only computation allowed in types is record selects from pure records, \nas these will always terminate and their value is not dependent on the store. We ban attribute operations \nand let rec from the pure objects, since, as discussed above, these cannot be allowed to index types. \nWe ban null, since it is not data that we wish to prove properties about. We also ban pattern abstractions, \nboth so we do not have to consider problems like \u00df-and .-equivalence, and because it is unclear how to \napply pattern abstractions to the variables that can appear in types. Purity will be important in the \nprogramming methodology in Section 3, since the programmer must take care not to apply dependently typed \nfunctions to impure objects. It will also be important in formalizing the metatheory of the language, \nas there will have to be two different substitution lemmas, one for pure and one for impure objects. \n 3. Programming with Proofs In this section, we discuss programming with proofs in RSP1. We begin by \ndiscussing a methodology for programming with proofs in RSP1, which both solves the technical problems \nposed by the con\u00adcept of purity and offers some conveniences not necessarily found in other methodologies. \nThis will be illustrated by a simple list ex\u00adample. Then, in the subsections, we give examples of more \ncom\u00adplicated examples which illustrate the kinds of properties of data structures we can prove in RSP1. \nThe purpose of this section will be to see both how purity affects programming with proofs, and how useful \nproperties of data structures and code can be represented in a .rst-order language like RSP1. Consider \nthe example of lists of some arbitrary data (here given the type data) where it is important to prove \nproperties about the sizes of the lists. These can be represented with the following type and term constructors: \n nat :: type. Natural numbers in unary, with the usual con\u00adstructors zero and succ.  list :: n:nat => \ntype. Lists of nats of length n. The term constructors are:  nil :: list zero;; cons :: n:nat => data \n=> list n => list (succ n);; plus :: nat => nat => nat => type. The type (plus xy z) is intended to \nbe inhabited iff x + y = z. Its term con\u00adstructors, embodying the usual recursive de.nition of addition, \nare: plus_zero :: x:nat => plus zero x x;; plus_succ :: x:nat => y:nat => z:nat => plus yx z=> plus (succ \ny) x (succ z);; Next, consider the operation of appending two lists. We wish to write an append function \nthat returns, along with the concatenation of two lists, a proof that the length of this result is the \nsum of the lengths of the two inputs. The code for this append is given in Figure 3. append is de.ned \nto be a recursive function. (The rec keyword means append is a top-level, recursive de.nition, and is \nequivalent to let rec append:T = M in M, where T is replaced by the type declared for append and M is \nreplaced by the outer pattern abstraction in the Figure.) append takes in two records, l1 and l2, each \nof which contain a list and its length, in the l and n .elds, respectively. The length must come .rst, \nas the type of the list is indexed by it. Also, note that it is more convenient in this case to take \nthe second list .rst, as we wish the inner case to discriminate against whether the .rst list is empty \nor not. append returns a record with a list, its length, and a proof that this length is the sum of the \nlengths of l1 and l2. Its type illustrates the .rst point of our methodology, that terms should generally \nbe bundled in a record with the terms that index their types. Bundling terms with the indices of their \ntypes makes it easy for the user to see, in the type of the function, the dependencies between the arguments \nand rec append :: l2:{n:nat, l:list n} =c> l1:{n:nat, l:list n} =c> {n:nat, l:list n, deriv:plus l2.n \nl1.n n} = l2 \\ dummy_var \\ dummy_var:{n:nat, l:list n} -> ( l1 \\ [n=zero, l = nil] \\ -> [n=l2.n, l=l2.l, \nderiv=plus_zero l2.n] | l1 \\ [n=succ tail1_len, l = cons n1 data1 list1_tail] \\ tail1_len:nat,data1:data,list1_tail \n-> let res = append l2 [n=tail1_len, l = list1_tail] in [n=succ res.n, l = cons res.n data1 res.l, deriv \n= plus_succ l2.n tail1_len res.n res.deriv]);; Figure 3. Append for lists with length their types, as \nwell as the speci.cation of the function. This could be done without dependently typed records, but it \nwould require declaring a new type family and constructor for each input and output bundle, which quickly \nbecomes tedious, and separates the speci.cation of the function over multiple locations. The body of \nthe function works like a normal append function: if the second argument is the empty list (matched by \nthe .rst l1 clause, which matches n against zero and l against nil), the function simply returns the \nsecond list; otherwise, it recursively calls append on the tail of the list (the appearance of append \non the third-to-last line), and prepends the .rst element of l1 to the resulting list (the cons on the \nsecond-to-last line). The main difference is that we also construct the deriv .eld in the returned record, \nwhich is the proof that the length of the returned list is the sum of the lengths of the input lists. \nSince the recursive call to append is recursive, it is not pure. The length of the result, res.n, needs \nto index two types, the type of the cons expression and the type of the plus expression. The reason this \nexample still type checks is because of the let. Inside the body of the let, the res variable is pure, \nas it is a normal variable. Thus it is ok that the types of some expressions are indexed by it. The type \nof the whole body, however, is not indexed by res, as the individual types of the .elds of the returned \nrecord are swallowed up by the dependent record type. Thus, the type of the whole let expression need \nnot be indexed by the impure recursive call. This is the other key to our methodology, using let to locally \nshadow the values of impure terms and then bundling them in dependently typed records to hide the impurity \nfrom the return type. A .nal consideration is null. null can inhabit any type, so is a vacuous proof \nof any property. Since null trickles up in any term, however, there cannot be proofs that are erroneous \nbecause they contain null as a proper subterm. Also, since our methodology involves the bundling of data \nwith its proofs in records, if any of the proofs a function returns contain null, the whole record will \nevaluate to null, and the function will not return any data. Instead, this is interpreted as a run-time \nerror. So our desired property of functional correctness can be made precise: if a function that programs \nwith proofs, according to our methodology, returns a non\u00adnull value, then the proofs it returns are guaranteed \nto be well\u00adformed. Note that this motivates the use of null in our methodology. If a program wishes to \nprove some properties of data which could potentially fail to hold, for instance if it is input incorrectly, \nthe program can simply return null in cases where it ascertains that the property fails. In the following \nsubsections, we consider the following three examples of programming with proofs in RSP1. The .rst is \na ver\u00adsion of mergesort which returns, in addition to the sorted output list, a proof that that list \nis sorted and has exactly the same ele\u00adments as the input list. The third example is an implementation \nof imperative binary search trees where we statically verify that the binary search tree property is \nmaintained. This example does not verify the structural property that the reference graph starting from \nany node is really a tree (we verify the binary search tree prop\u00aderty even without this structural property). \nIn the fourth example, we give an example of statically verifying a structural property of the reference \ngraph, namely that of being acyclic. Other examples in progress but not discussed here include a proof-producing \nau\u00adtomated reasoning tool, where propositional proofs are encoded as a term-indexed datatype [13]; and \nmesh-manipulating algorithms from computer graphics, where a mesh is encoded as a datatype indexed by \nits Euler characteristic [5]. 3.1 Merge Sort The implementation of proof-producing merge sort in RSP1 \nis based on the following term-indexed datatypes: nat :: type. Natural numbers in unary, as for the \nappend example.  list :: type. Lists of nats. We elect here not to index the type of lists by a length, \nfor simplicity. The term constructors are nil and cons, of the usual types.  lte :: nat => nat => type. \nNatural number less-than. This type has these term constructors:  lte_start :: x:nat => lte x x;; lte_next \n:: x:nat => y:nat => lte x y => lte x (succ y);; sorted :: list => type. The property on lists of being \nsorted. We rely on the following three term constructors for this type. The third one, for example, can \nbe read as saying that for all nats n and m, and for all lists l;if n is less than m and (cons ml) is \nsorted, then so is (cons n (cons m l)). sorted_nil :: sorted nil;; sorted_cons1 :: n:nat => sorted (cons \nn nil);; sorted_cons2 :: n:nat => m:nat => l:list => lte n m=> sorted (cons m l) => sorted (cons n (cons \nm l));; occurs :: nat => list => list => type;; The intend\u00aded meaning of (occurs n l1 l2) is that n occurs \nin l1, and l2 is the result of removing one occurrence of x from l1.We omit the (simple) term constructors \nhere. multiset union :: list => list => list => type;; The intended meaning of multiset union l l1 l2 \nis that the multiset of elements in l is equal to the multiset union of the multiset of elements in l1 \nwith the multiset of elements in l2. The term constructors for this type are: mu_nil :: multiset_union \nnil nil nil;; mu_cons1 :: n:nat => l:list => l1:list => l1p:list => l2:list => occurs n l1 l1p => multiset_union \nl l1p l2 => multiset_union (cons n l) l1 l2;; mu_cons2 :: n:nat => l:list => l1:list => l2:list => l2p:list \n=> occurs n l2 l2p => multiset_union l l1 l2p => multiset_union (cons n l) l1 l2;;  With these types, \nwe can state the types of the three critical recur\u00adsive functions needed for mergesort: split :: l:list \n=c> {a:list, b:list, MU:multiset_union l a b};; merge :: q:{l1:list, D1:sorted l1, l2:list, D2:sorted \nl2} =c> {l:list, D:sorted l, MU:multiset_union l q.l1 q.l2};; mergesort :: l1:list =c> {l:list, D:sorted \nl, MU:multiset_union l1 l nil};; The split function is responsible for splitting an input list l into \ntwo output lists a and b of roughly equal size (note that this latter property is not speci.ed here and \nhence not statically checked). It additionally produces a proof that l is the multiset union of a and \nb. The merge function takes in lists l1 and l2, together with proofs that those lists are sorted, and \nproduces the merged output list l, together with a proof that l is sorted and the multiset union of l1 \nand l2. Finally, mergesort takes in a list l1, and returns an output list l, together with a proof that \nl is sorted and the multiset union of l1 and nil. This last condition is, of course, suf.cient to guarantee \nthat l and l1 have exactly the same elements. Space reasons prohibit giving all the code (87 lines) for \nthis ex\u00adample, but we consider a representative piece from merge, shown in Figure 4. This is the case \nwhere the two input lists are both non\u00adempty (as shown in the pattern which makes up the .rst line of \nthe Figure; note that the types of the pattern variables are omitted for space reasons). The body of \nthis case begins by calling a helper function nat comp to compare the heads n and m of the two lists. \nIf n is smaller, nat comp returns a term of type (lte n m). Oth\u00aderwise, it returns null. Depending on \nwhich of these two cases occurs, one or the other recursive call to merge is made (in either the then-part \nor the else-part of the if-then-else). The two recur\u00adsive calls to merge both rely on a helper lemma \nsublist sorted, which takes in a non-empty sorted list and returns a proof that its immediate sublist \nis sorted. Both branches of the if-then-else then build a record with .elds l for the merged list, D \nfor the proof that l is sorted, and MU for the proof that l is the multiset union of the input lists. \nLemmas extend sorted1 and extend sorted2 are also used. The lemma extend sorted1 takes in the proofs \nthat the input lists are sorted, as well as the proof that the result of the recur\u00adsive call is sorted \nand is the multiset union of the second list and the immediate sublist of the .rst list. The lemma returns \na proof that consing n onto the list obtained from the recursive call is sorted. We note here that the \nimplementation of mergesort relies on 250 lines of proofs of lemmas like extend sorted1. A few lemmas \nconcerning multiset union remain to be proved. These are currently just expressed as additional axioms \n(via declarations of additional term constructors). 3.2 Imperative Binary Search Trees We consider implementing \nimperative binary search trees in such a way that the binary search tree property is ensured statically \nby RSP1 s type checking. The binary search trees are imperative in the sense that the left and right \nsubtrees of a particular tree are reached by following mutable pointers from the node at the top of the \ntree. Trees can, of course, be implemented as an inductive datatype in a language with user-declared \ndatatypes (like RSP1 or ML). But imperative trees have the advantage that subtrees can be modi.ed in \nplace, without requiring the entire tree to be rebuilt (as would be the case with a datatype of trees). \nFor simplicity, the data in our binary search tree will just be natural numbers in unary (as de.ned above). \n     |q \\[l1 = cons nl1, D1 =D1, l2 = cons ml2, D2 =D2] \\ D1,l1,m,n,l2,D2 -> let C = nat_comp n m \nin if C then let R = merge [l1 = l1, D1 = sublist_sorted [n =n, l =l1, D =D1], l2= q.l2, D2 =D2] in [l \n= cons n R.l, D = extend_sorted1 n m l2 D2 C [l1 = l1,D1 = D1, l = R.l, D = R.D, MU = R.MU], MU = mu_cons1 \nn R.l (cons n l1) l1 q.l2 (occurs_start n l1) R.MU] else let R = merge [l1 = q.l1, D1 = D1, l2= l2, D2 \n= sublist_sorted [n =m, l =l2, D =D2]] in [l = cons m R.l, D = extend_sorted2 n l1 m D1 (nat_comp m n) \n[l2 = l2,D2 = D2, l = R.l, D = R.D, MU = R.MU], MU = mu_cons2 m R.l q.l1 (cons m l2) l2 (occurs_start \nm l2) R.MU] Figure 4. Recursive case of merge The binary search tree property we would like to verify \nstati\u00adcally is that every piece of data stored in the left subtree of a tree whose top node stores data \nd must be less than or equal to d; and every piece of data stored in the right subtree must be greater \nthan or equal to d. Note that allowing data equal to d to appear in either subtree makes the development \nsimpler. Note also that we will not actually try to enforce the structural property of being a tree, \nas op\u00adposed to a proper graph (although see Section 8). To express our binary search tree property as \nan RSP1 type, we cannot rely on be\u00ading able to speak directly about the reference graph, as is often \ndone in static analysis (e.g., [18, 27, 14]). RSP1 s types may not contain attribute reads or any other \nimpure expressions, and hence cannot refer directly to the reference graph. The approach we follow in\u00adstead \nis to express local invariants which imply the binary search tree property. The local invariants are \nstatically enforced. The fact that they imply the binary search tree property is not (in any ob\u00advious \nway) expressible in RSP1. Hence, we cannot prove in RSP1 that the local invariants indeed imply the global \nproperty, and must argue that outside the system. The basic plan is to build our binary search tree out \nof nodes, connected by bst left and bst right attributes. We associate (in a way explained shortly) two \nnumbers l and u with each node n. These are intended to be a lower bound and upper bound, re\u00adspectively, \non all the data stored in the subtree rooted at n. Then we enforce the following local invariants on \nthe pointers from node n to another node n , storing data d and having associated lower and upper bounds \nl and u : If n is the left child of n, then l = l and u = d. That is, the left subtree s lower bound \nmust be the same or tighter than the current tree s lower bound, and the left subtree s upper bound must \nbe less than or equal to the data at the top of the current tree.  If n is the right child of n, then \nu = u and d = l . That is, the right subtree s upper bound must be the same or tighter, and the right \nsubtree s lower bound must be greater than or equal to the data at the top of the current tree. We take \nthe following term-indexed datatype for the type of binary search tree nodes: node :: l:nat => d:nat \n=> u:nat => type;; The type (node l du) is the type for nodes with associated lower bound l and upper \nbound u, and data d stored in the node. We include d as an index to the type so we can refer to it when \nwe express the local invariants. To construct nodes, we use the following term constructor, which requires \nproofs that l = d = u, as well as a unique id (to ensure the graph is not cyclic, although as mentioned, \nwe do not statically check that property): mknode :: l:nat => d:nat => u:nat => id:nat => lte l d=> lte \ndu =>node l du;; Now we may express the local invariants with the following attribute declarations: bst_left \n:: parent:{l:nat, d:nat, u:nat, n:node l d u} =a> {l:nat, d:nat, u:nat, n:node l d u, p1:lte parent.l \nl, p2:lte u parent.d};; bst_right :: parent:{l:nat, d:nat, u:nat, n:node l d u} =a> {l:nat, d:nat, u:nat, \nn:node l d u, p1:lte u parent.u, p2:lte parent.d l};; These declarations state that bst left and bst \nright are at\u00adtributes of dependent records containing the indices l,d, and u, as well as the node itself. \nWe cannot make them attributes just of nodes, due to the presence of the indices. The declarations state \nthat proofs of the local invariants discussed above are included as mem\u00adbers of the records stored in \nthe attributes. This means that when\u00adever an attribute is written, the proofs of the local invariants \nmust be supplied. And similarly, those proofs are available whenever an attribute is read. By the soundness \nof our encoding of judgments of natural number less-than as the term-indexed datatype lte, the ex\u00adistence \nof these proofs for every edge in the reference graph shows that the local invariants always hold. To \nshow that the local invariants imply the binary search tree property (which we must do outside RSP1), \nit suf.ces to show that the putative lower and upper bounds on the data reachable from each node really \nhold. The argument cannot proceed by induction on the structure of trees, since, as mentioned above, \nwe are not en\u00adforcing the structural property of being a tree. Nothing prevents the pointers from being \nincorrectly set to create cycles or reconvergent paths. Nevertheless, the binary search tree property \nstill holds. We prove that for every length k, for every node n, and for every node n reachable by a \nsimple path of length k from n, the data stored at n is within the bounds associated with n. The proof \nis by induction on k. The data stored at n itself is within the bounds, since mknode requires proofs \nof those containments. For the inductive case, sup\u00adpose n is reachable from n with a simple path of length \nk +1. This must be by following either bst left or bst right to reach a node n . The node n is thus reachable \nfrom n using a simple path of length k. Then by the induction hypothesis, we know the data stored at \nn is within the bounds associated with n . But by the enforcement of the local invariants and transitivity \nof =, this implies that the data is within the bounds associated with n.   Based on our data structure, \nwe can implement insertion into a binary search tree: rec bst_insert :: x:nat =c> q:{l:nat, d:nat, u:nat, \nn:node l d u} =c> bst_insert_ret_t q.l q.d q.u x = ... The return type of bst insert uses a new term-indexed \ndatatype, introduced to return information about how the insertion pro\u00adceeded. The information is needed \nto construct suitable proofs when recursive calls to bst insert return. The term constructors for bst \ninsert ret t correspond to three possible scenarios that could occur when doing the insertion: 1. l \n= x = u, and the input node to the recursive call remains the root of the updated tree. 2. x = l, and \nthe input node is no longer the root of the updated tree (since the lower bound must now be x). The node \nwhich has everything the same as the input node except that the lower bound is x is the new root. 3. \nu = x, and the input node is again no longer the root of the updated tree (since the upper bound must \nnow be x). The node which has everything the same as the input node except that the upper bound is x \nis the new root.  When bst insert makes a recursive call, it uses the information returned as follows. \nIf the input node is no longer the root of the updated tree, the bst left or bst right (as appropriate) \nattribute of the node currently being processed must be reset to point to the node which is the new root. \nThen the current call to bst insert must itself return the appropriate instance of bst insert ret t. \nThis instance is readily determined. For example, if the recursive call was made in order to insert x \ninto the right subtree of the current node, and if that recursive call returned an instance cor\u00adresponding \nto case 1 or case 2 above, then the current call returns an instance corresponding to case 1: in either \ncase, the data x is still within the current node s bounds. Note that we are not checking, and cannot \nin any obvious way check, that bst insert actually inserts the data into the tree. This might be considered \nsomething like a liveness property: the reference graph is actually modi.ed in a certain way. But we \nare enforcing what might be considered a safety property: the reference graph is guaranteed always to \nhave a certain property, however it may be modi.ed. 3.3 Statically Enforcing a Structural Property The \npreceding example showed how to enforce statically a non\u00adstructural property of the reference graph in \nRSP1. Here, we give a simple example where a structural property is statically enforced. The property \nis that a reference graph determined by two attributes, dag left and dag right, is acyclic. As in the \npreceding Section, we must devise local invariants that imply this global property of the reference graph. \nWe rely on the simple fact that a .nite directed graph is acyclic (a dag) if its edge relation is contained \nin some well-founded ordering. For the implementation in RSP1, we take natural number less-than as our \nwell-founded ordering. More complex (computable) orderings could be supported in a similar way. We will \nassociate with each of our dag nodes a natural number. The well-founded ordering on dag nodes is then \nthe ordering of those nodes by the associated natural number. In RSP1, as for the example in the preceding \nSection, we index the type of dag nodes by the associated natural number. We will enforce statically \nthe local invariant that all dag nodes reachable in one or more type nat = Null_nat | Zero | Succ of \nnat type list = Null_list | Nil | Cons of nat * list type lte = Null_lte | Lte_start of nat | Lte_next \nof nat * nat * lte type sorted = Null_sorted | Sorted_nil | Sorted_cons1 of nat | Sorted_cons2 of nat \n* nat * list * lte * sorted type mu = Null_mu | Mu_nil | Mu_cons1 of nat * list * list * list * list \n* occurs * mu | Mu_cons2 of nat * list * list * list * list * occurs * mu let record = let _num = Succ \nZero in let _data = Cons _num Nil in let _order = Lte_start _num in [num = _num; data = _data; order \n= _order] in record.data;; Figure 5. Intermediate compiled representation of types and records in OCaml \nsteps from a given dag node have a smaller associated number. Hence, each dag node s number will be a \nstrict upper bound on the numbers associated with dag nodes reachable in one or more steps. For concreteness, \nwe implement dags where each dag node stores a natural number (unrelated to the bound associated with \nthe dag node). The term-indexed datatype we need, with its term constructor, is: dag :: b:nat => type;; \nmkdag :: b:nat => data:nat => dag b;; We then specify our local invariant in these attribute declarations, \nwhich use a term-indexed datatype lt for strict natural-number less-than (we omit its simple declarations): \ndag_left :: parent:{b:nat, d:dag b} =a> {b:nat, d:dag b, p:lt b parent.b};; dag_right :: parent:{b:nat, \nd:dag b} =a> {b:nat, d:dag b, p:lt b parent.b};; Using these de.nitions, it is straightforward to implement \ncon\u00adversion from (functional) trees to dags with maximal sharing. We declare an inductive datatype of \ntrees in the usual way, and then implement: rec dagify :: x:tree =c> {b:nat, d:dag b} = ... As in the \npreceding Section, we do not here statically check the liveness property that the dag returned is suitably \nrelated to the input tree. But we do enforce the safety property that the reference graph starting from \nany node created by this method is contained within the natural number less-than relation (and hence \nreally a dag, although that implication must again be veri.ed outside the system).  4. Compilation We \ntranslate well-typed RSP1 programs into Objective Caml (OCaml) and leverage the OCaml compiler to generate \nnative exe\u00adcutables. OCaml was chosen as an intermediate language primarily because many of its syntactic \nand operational aspects closely mirror those of RSP1. Furthermore, OCaml s strong type system allows \nthe intermediate representation to use much of the original type in\u00adformation to ensure correctness of \nthe translation and the compiler itself. OCaml s type system does not support dependent types. So, RSP1 \ntypes are compiled into OCaml types in which the index\u00ading terms are elided (see Fig. 5). Most features \nin RSP1 translate with little adjustment to their natural analogues in OCaml. Com\u00adputational functions \nare represented by the OCaml function con\u00adstruct. The let and let rec constructs are identical. RSP1 \npat\u00adterns are similar to those in OCaml, but, unlike in RSP1, all vari\u00adables in OCaml patterns are treated \nas pattern variables. The trans\u00adlation from RSP1 patterns must therefore include a pattern guard (a when \nclause) to constrain the values of pattern variables with corresponding local variables already in the \ncontext. Terms are cre\u00adated by data constructor application in a manner that is essentially identical \nin both languages. Other RSP constructs are more .exible than their OCaml coun\u00adterparts or simply do \nnot map directly to any high-level OCaml feature. For example, RSP attribute declarations are compiled \ninto a pair of functions that manage reads and writes to a hash table for the attribute. Records in RSP \nallow intra-record prior .eld lookups, unlike in OCaml. In the intermediate representation, .eld contents \nare compiled into a series of let-de.ned OCaml expressions cul\u00adminating in an OCaml record that gathers \nthe de.nitions and allows for later access in the typical fashion (see Fig. 5). The constant null may \nadopt any type in an RSP program, but since the OCaml type system disallows polymorphic constants, a \nspecial Null constructor is added to the signature for each data type. More complex types are .-expanded \ninto null objects at compile-time null records become records of the appropriate type with null .elds \nand null functions become functions that return a null object of the appropriate type regardless of the \narguments it is applied to. Testing for null in an if-then-else RSP1 expression is translated into a \ntest for the appropriate null object in OCaml. 1 5. Static Semantics To formalize the static semantics \nof RSP1, we must .rst de.ne the valid signatures and contexts. Rules for these judgments are given in \nFigure 6. Note that any constant in a valid signature must either have representational type or be an \nattribute. This is the only place we shall mention these judgments explicitly: all typing rules in the \nsequel implicitly require that all signatures and contexts involved are valid. We also assume that all \nvariables in a context are always distinct; it will always be possible to assure this with alpha-conversion. \nfS sig S; \u00b7fK :kind f\u00b7sig fS,a : K sig fS sig S; \u00b7fTrep :type fS,c : Trep sig fS sig S; \u00b7f.a x: T1.T2 \n:type fS,c:.a x: T1.T2 sig fS sig S fG ctxt S; G fT :type S f\u00b7ctxt S fG,x : T ctxt Figure 6. Valid RSP1 \nSignatures and Contexts The rules for typing types and kinds are given in Figure 7. As mentioned above, \nonly .-abstractions with zero-order argument types are allowed. Also, .r-abstractions require representational \n1 Compiled RSP does not yet support the correct behavior of propagating nulls. types for argument and \nresult types, to keep them inside the rep\u00adresentational fragment. Finally, note that, as promised above, \nonly types indexed by pure objects will be considered well-formed. t-type-kind S; G ftype : kind S; G \nfTZRep :type S; G,x : TZRep fK :kind t-pi-kind S; G f.r x : TZRep.K :kind a : K .S t-const-type S; G \nfa : K t-empty-rec-type S; G f{}:type S; G fTZRep :type S; G,x : TZRep fTrep :type t-r-pi-type S; G f.r \nx : TZRep.Trep :type S; G fTZ :type S; G,x : TZ fT :type t-{c,a}-pi-type .c,a S; G fx : TZ.T :type S; \nG fT :.r x : TZRep.K S; G fMpure : TZRep t-type-app S; G fTMpure :[Mpure/x]K S; G fT :type S; G,x : T \nfRT :type t-rec-type S; G f{l : T, x.RT }:type Figure 7. RSP1 Type-and Kind-Level Typing In order to \nde.ne object-level typing, we need two more judg\u00adments. The .rst is type equivalence, written fT1 = T2. \nThe rules for type equivalence are given in Figure 8. Most of these corre\u00adspond directly to structural \nequivalence of the two types. Note that record types are considered equivalent up to a-conversion on \nthe variables they bind. The interesting case is for type application, which requires the argument objects \nto be equivalent. This is a sep\u00adarate judgment, written fM1 = M2, and has only one rule, eq-obj. This \nrule requires the two objects to evaluate to the same object: . is the single-step evaluation relation, \ngiven in Section 6, and . * is the re.exive-transitive closure of this relation. This evaluation is also \nin the empty store, as object equivalence should not depend on values in the store. For more on the evaluation \nrelation, see Section 6. Note that only pure objects can be considered equivalent, which will be suf.cient \nfor our purposes, as only pure objects can enter into types. The use of evaluation to the same normal \nform as the basis for object equivalence is justi.ed, because this coincides with the cus\u00adtomary, more \ndeclaratively de.ned equivalence relation. We could de.ne object equivalence as the set of equational \nconsequences of the equational versions of the rules e-rec-sel1 and e-rec-sel2 (Fig\u00adure 14). But if we \norient those equations as in the Figure, the re\u00adsulting rewrite system is terminating and clearly locally \ncon.uent. Hence, it is convergent by Newman s Lemma, and equivalent to the equational theory by Birkhoff \ns Theorem [4]. Then any strat\u00adegy for applying the oriented equations, including the call-by-value strategy \nof our evaluation relation, is sound and complete for the equational theory. Note that our notion of \nequivalence does not de\u00adpend on typing. This is one instance where the .rst-order nature of RSP1 greatly \nsimpli.es the type theory. In standard LF with \u00df-and .-equivalence, con.uence does not hold for ill-typed \nterms. Thus ** f\u00b7; Mpure-1 .\u00b7; M \u00b7; Mpure-2 .\u00b7; M eq-obj fMpure-1 = Mpure-2 eq-const eq-empty-rec fa \n= a f{}= {} fT1 = T2 fM1 = M2 eq-app fT1M1 = T2M2 fT11 = T21 fT12 = T22 eq-{r,c,a}-pi .{r,c,a}T11.T12 \n=.{r,c,a} fT21.T22 fT1 = T2 fRT1 = RT2 eq-rec-type f{l : T1,x.RT1}= {l : T2,x.RT2} Figure 8. RSP1 Equivalence \nproving con.uence requires notions of typing, and is much more complicated. The second judgment we require \nis record type selection, the rules for which are given in Figure 9. This judgment, written f RTSell \nMRT T , is meant to indicate that selecting label l from object M with type RT will result in an object \nof type T .If l is the .rst label in RT , then the required type is the .rst type in RT ,as suggested \nby the rule rtsel-base. If, however, l is not the .rst label in RT , then, since RT is a dependent record \ntype, the .rst element of M must be substituted for the .rst variable in RT into the second and later \n.eld types in RT . Since we require only pure objects to appear in types, then either M should be pure, \nor it should not be substituted into the record type. Thus we get the pure and impure rules in the Figure. \nTo ensure coherence of the two rules, we use the question of whether the variable x is free in RT to \ndistinguish which rule is applicable. rtsel-base fRTSell M {l : T, x.RT }T x .FV (RT ) l1= l2 fRTSell1 \nMpure ([Mpure/x]RT ) T1 rtsel-pure fRTSell1 Mpure {l2 : T2,x.RT }T1 fRTSell1 MRT T1 FV (RT ) l1 x.= l2 \nrtsel-impure fRTSell1 M {l2 : T2,x.RT }T1 Figure 9. RSP1 Record Type Selection The object-level typing \nrules for RSP1 are given in Figure 10. These include standard rules for constants, variables, ascriptions, \nand conversions, and a rule typing null at any type. Pattern ab\u00adstractions are only well-typed when all \npatterns follow the syntac\u00adtic restrictions of Figure 2. Note that the requirement that E only be typed \nby valid .c-types ensures inductively that the .c-type of any pattern abstraction is a valid type in \njust the context G. In par\u00adticular, this ensures that none of the variables in Gl, for any part of a \npattern abstraction, appear in the resulting type of the abstrac\u00adtion. Following these are pure and impure \nrules for applications and attribute reads, similar to the pure and impure rules for RTSel discussed \nabove. The Figure gives rules for dependent and inde\u00adpendent records, the latter being equivalent to \nthat given in [25] and the former being a straightforward adaptation to dependent records. Record selects \nare typed using RTSel, which, as discussed above, substitutes record selects of earlier labels of M into \nthe types of later labels. Finally, the Figure gives straightforward rules for at\u00adtribute writes, empty \nrecords, and let rec. x : T . G c : T . S S; G f x : T t-var S; G f c : T t-const S; G f T :type S; \nG f M : T t-null t-asc S; G f null : T S; G f (M :: T): T S; G f M : T S; G f Tl :type f T = Tl t-conv \nS; G f M : Tl S; G f . :.c x : TZ .T S; G, Gl f [Mpat/x]M :[Mpat/x]T S; G, Gl f Mpat : TZ FV (Mpat)=Vars(Gl) \n t-rho S; G f x\\Mpat\\Gl . M | . :.c x : TZ .T S; G f .c x : Tz.T :type t-epsilon S; G f E :.c x : Tz.T \nS; G f M :.r,cx : T1.T2 S; G f Mpure : T1 x . FV (T2) t-{r,c}-pure-app S; G f MMpure :[Mpure/x]T2 S; \nG f M1 :.r,cx : T1.T2 S; G f M2 : T1 x . FV (T2) t-{r,c}-impure-app S; G f M1 M2 : T2 S; G f c :.a x \n: TZ .T S; G f Mpure : TZ x . FV (T2) t-attr-read-pure S; G f Mpure.c :[Mpure/x]T S; G f c :.a x : TZ \n.T S; G f M : TZ x . FV (T) t-attr-read-impure S; G f M.c : T S; G f M1.c : T S; G f M2 : T t-attr-write \nS; G f M1.c := M2 : T t-empty-rec S; G f [] : {} S; G f M : RT f RTSell MRT T t-rec-select S; G f M.l \n: T S; G f [M/x]R :[M/y]RT S; G f M : T S; G,y : T f RT :type t-record S; G f [l = M, x.R]: {l : T,y.RT} \nS; G f R :[M/y]RT S; G f M : T S; G,y : T f RT :type t-indep-record S; G f [l = M, R]: {l : T,y.RT} S; \nG,d1 : T1,...,dn : Tn . M : T S; G,d1 : T1,...,dn : Tn . Mi : Ti t-let-rec S; G . let rec d1 : T1 = \nM1,..., dn : Tn = Mn in M : T Figure 10. RSP1 Object-Level Typing Many standard structural properties \nof dependent type systems hold for RSP1, such as weakening and validity. Substitution, how\u00adever, is nonstandard, \nbecause impure objects cannot enter into types. In RSP1, we in fact have two Substitution Lemmas, for \npure and impure objects: LEMMA 5.1. (Pure Substitution) If S; G f M : T, x . FV (G), M is pure, and S; \nG,x : T f Ml : Tl, then S; G f [M/x]Ml :[M/x]Tl . LEMMA 5.2. (Impure Substitution) If S; G f M : T, x \n. FV (G), D is a derivation of S; G,x : T f Ml : Tl, and x is not free in any type in D, then S; G f \n[M/x]Ml : Tl . The pure form of substitution is similar to the pure typing rules, in that M can only \nbe substituted into a type if it is pure. The impure form requires a much stronger condition: not only \ncan x not occur in Tl if M is impure, but it cannot occur free in any type in the deduction D. This is \nbecause the argument type of an abstraction typing could contain x, even though Tl does not, since these \nargument types disappear below the line of their respective elimination rules (i.e. the typing rules \nfor applications and attribute reads). Type and object equivalence are also decidable, the .rst follow\u00ading \nfrom the second, and the second following from the fact that the evaluation relation is deterministic, \nso easily Church-Rosser, and terminating on the pure objects. LEMMA 5.3. (Decidability of Equivalence) \nFor any T1, T2 and M1, M2, it is decidable whether f T1 = T2 and whether f M1 = M2. Given the decidability \nof equivalence, it is straightforward to implement a sound, but not complete, type inferencing procedure, \nusing local type inference [24]. The problem with completeness lies in the t-record and t-indep-record \nrules of Figure 10: the substitutions below the line make it impossible to know, from just structural \ninformation, what instances of M in R should be replaced by x in RT. The basic idea of the local type \ninference algorithm we use is that when typing applications, the type of the functional term is synthesized, \nand its domain type is used to guide type checking of the argument. This means that in the common case \nwhere records are passed as arguments to recursively de.ned functions, we check that the supplied record \ncan indeed have the domain type of the function. Our procedure, which incorporates a few further ideas, \nworks well in practice, and the code that has been written in RSP1 so far rarely needs to make use of \nascriptions. Further details of the lo\u00adcal type inference algorithm are beyond the scope of this paper. \nNote that the algorithm currently does not compute omitted types for bound variables; those must still \nbe supplied by the program\u00admer. We conjecture that a complete type inference algorithm for RSP1 should \nbe achievable, since the number of distinct types a dependent record can have in RSP1 is .nite. Indeed, \nthis observa\u00adtion shows that the non-determinism of the present typing rules is bounded, and hence type \nchecking is decidable. In more general settings, there can be in.nitely many incomparable types (an ex\u00adample \nis given in [28]). 6. Operational Semantics To de.ne the operation semantics of RSP1, we .rst de.ne \nthe values and the stores, given in Figure 11. The values, as in all languages, represent the possible \n.nal results of a computation. In RSP1, these include records, pattern abstractions, representational \nobjects, and null, though note that, as mentioned above, null cannot be a proper subterm of a value. \nThe stores are necessary because of the attributes. They associate attribute expressions with their values. \nWhenever an attribute is read, it is retrieved from the current store, and whenever it is written, the \ncurrent store is updated. Record Values Representational Values RV ::= Vrep ::= [] I[l = Vpure,RV ] c \nIVrep Vrep Pure Values Values Stores Vpure ::= V ::= \u00b5 ::= Vrep IRV Vpure I. Inull \u00b7I\u00b5, V1.c ..V2 Figure \n11. RSP1 Operational Syntax  Stores also need to be well-typed. The rules for typing stores are given \nin Figure 12. The interesting rule, opt-store-add, simply ensures that the referenced value, V2, has \nthe same type as the corresponding attribute read expression, V1.c, has. Note that we do not need a pure \nand an impure version of this rule, because values are always pure. opt-store-empty S f\u00b7 S f\u00b5c :.a x: \nTz.T .S S; \u00b7fV1 : Tz S; \u00b7fV2 :[V1/x]T opt-store-add S f\u00b5, V1.c . .V2 Figure 12. RSP1 Operational Typing \nThe operational semantics of RSP1 are given in Figures 13 and 14 in terms of a small-step semantics. \nThe small-step evaluation judgment, \u00b5; M . \u00b5 l; Ml, describes the evaluation of an object M in the context \nof \u00b5, the current store, which, as discussed above, gives the current values of the attributes. The rules \nin Figure 13 describe the congruences, and are thus straightforward. An interesting case is e-rec-congr3, \nwhich evalu\u00adates dependent records to independent records. Also note that these rules de.ne a deterministic \nevaluation order. The rules in Figure 14 describe the action of each of the object\u00adlevel constructs of \nRSP1. Most of these are as expected: record selects retrieve the value for the particular label, ascriptions \nare removed, attribute reads retrieve the necessary value from the store, attribute writes update the \nstore, and let rec operates as usual. null is returned whenever no other value is appropriate, including \nwhen null or E are applied to a value, when a record select acts on null,or when an attribute is read \nthat does not have a corresponding value. Applying a non-empty pattern abstraction requires testing whether \nthe argument matches the outer pattern. This is the mean\u00ading of the match function; match(V1, G,V2) is \nthe substitution for the variables in G that, when applied to V1, obtains V2. If such a match exists \nfor a pattern and an argument, [V2/x, s] is applied to the body, where s is the given substitution. Otherwise, \nif no such substitution exists, written match(V1, G,V2) ., then the outer pat\u00adtern is stripped from the \npattern abstraction, so that the next pattern can be tried. Note that, as a special case, only the pattern \nnull can match null, i.e. a pattern variable cannot match null. This is be\u00adcause null is impure, but \nthe output type of a pattern abstraction might depend on its argument, and substituting null in as the \nargu\u00adment would put it into a type. If we think of null as an exception, this means the pattern null \nis really a catch statement. Our pure and impure rules, along with our .rst-order syntactic restrictions, \nensure that our static semantics is sound with respect to our operational semantics. This is proved in \nthe full tech report ver\u00ad \u00b5; M1 .\u00b5 l; M1 l le-app-congr1 \u00b5; M1M2 .\u00b5 ; M1l M2 l; Ml \u00b5; M2 .\u00b5 2 le-app-congr2 \n; V1Ml \u00b5; V1M2 .\u00b5 2 \u00b5; M .\u00b5 l; Ml le-rec-sel-congr \u00b5; M.l .\u00b5 ; Ml.l \u00b5; M .\u00b5 l; Ml e-attr-read-congr \nl; Ml \u00b5; M.c .\u00b5 .c l; Ml \u00b5; M1 .\u00b5 1 e-attr-write-congr1 l; Ml \u00b5; M1.c := M2 .\u00b5 1.c := M2 \u00b5; M .\u00b5 l; \nMl e-attr-write-congr2 \u00b5; V.c := M .\u00b5 l; V.c := M \u00b5; M .\u00b5 l; Ml e-rec-congr1 \u00b5;[l = M, x.R] .\u00b5 l;[l \n= Ml,x.R] \u00b5; M .\u00b5 l; Ml le-rec-congr2 \u00b5;[l = M, R] .\u00b5 ;[l = Ml,R] e-rec-congr3 \u00b5;[l = V, x.R] .\u00b5;[l \n= V,[V/x]R] \u00b5; R .\u00b5 l; Rl e-rec-congr4 \u00b5;[l = V, R] .\u00b5 l;[l = V, Rl] e-rec-null1 \u00b5;[l =null,RV ] .\u00b5;null \ne-rec-null2 \u00b5;[l = Vpure, null] .\u00b5;null Figure 13. RSP Operational Semantics Part 1 (Congruence) sion \nof this article [30] via the standard Preservation and Progress Lemmas. LEMMA 6.1. (Preservation) If \nS f\u00b5, S; G fM : T, and \u00b5; M .\u00b5 l; Ml, then S f\u00b5 l and S; G fMl : T. LEMMA 6.2. (Progress) If S f \u00b5 and \nS; \u00b7f M : T, then either M is a value, or \u00b5; M .\u00b5 l; Ml, for some \u00b5 l and Ml . THEOREM 6.1. (Type Safety) \nIf S; G f M : T, S; G f \u00b5, and \u00b5; M . * \u00b5 l; Ml, then Ml is either a value or can evaluate another step. \n 7. Related Work There has been much research in dependently typed languages and in verifying programs \nwith them. For discussion of the latter, see, for example, [1, 2]. As for the former, many of these (for \ninstance, [16, 9, 15, 8, 19]) are strongly normalizing. This is an important property in showing them \ncorrect. None of these languages support any sort of effects or mutable state, which is not surprising, \nas many of them are intended more as proof assistants than as programming languages. The Cayenne language \n[3], on the other hand, is not strongly normalizing. Unfortunately, this percolates up to its types, \ncausing type-checking and type equivalence to be undecidable. e-null-app \u00b5;nullV . \u00b5;null e-epsilon-app \n\u00b5;EV . \u00b5;null e-rep-null-app \u00b5;Mrep null. \u00b5;null match(V1, G,V2)=s e-rho-app1 \u00b5;(x\\V1\\G . M | .)V2 . \n\u00b5;[V2/x, s]M match(V1, G,V2). e-rho-app2 \u00b5;(x\\V1\\G . M | .)V2 . \u00b5;.V2 e-ascription \u00b5;M :: T . \u00b5;M e-rec-sel-null \n\u00b5;null.l . \u00b5;null e-rec-sel1 \u00b5;[l =V, RV ].l . \u00b5;V l1 =l2 e-rec-sel2 \u00b5;[l1 =V, RV ].l2 . \u00b5;RV.l2 V1.c \n. . V2 . \u00b5 e-attr-read \u00b5;V1.c . \u00b5;V2 V1.c . Dom(\u00b5) e-attr-read-null \u00b5;V1.c . \u00b5;null e-attr-write \u00b5;V1.c \n:= V2 . \u00b5[V1.c . . V2];V2 D = x1 : T1 =M1,...,xn : Tn =Mn e-let-rec \u00b5;let rec D in M . \u00b5;[..., let rec \nD in Mi/xi,...]M Figure 14. RSP Operational Semantics Part 2 (without Congru\u00adence) Cayenne is also the \nonly other language the authors know of that has a construct similar to null, namely ., which inhabits \nall types. A different approach to dependent types is Dependent ML [31]. Dependent ML restricts the terms \nallowed to index types to con\u00adstraint domains: the paper uses arithmetic over the integers as an example. \nThe type system of Dependent ML can then express con\u00adstraints over these domains, such as one integer \nbeing greater than another, and can solve for properties of these constraints, which end up proving properties \nof the code. This is different from the goals of RSP1, which involve letting the user prove arbitrary \nproperties of the data she manipulates. Yet another approach we consider here is Twelf [22], a logic \nprogramming language built on LF. Twelf supports unrestricted re\u00adcursion, but has a decidable type-checking \nproblem. This is pos\u00adsible without the notion of purity because logic programs cannot be explicitly called \nin types. Twelf also supports a form of muta\u00adble state, through dynamically added clauses. The main difference \nbetween RSP1 and Twelf is thus the difference of paradigm: func\u00adtional programming with reference-like \nfeatures versus logic pro\u00adgramming with dynamic clauses. A .nal approach that is similar to RSP1 is ATS \n[6]. ATS is a pattern-matching language for programming with proofs which supports unrestricted recursion \nbut has a decidable type-checking problem. This is achieved by separating the terms into the proof terms \nwhich encode proofs and the dynamic terms which allow for more powerful computation such as recursion. \nATS also sup\u00adports pointers, and can reason about them using stateful views (see [32]). ATS allows types \nto mention the reference graph explic\u00aditly, leading to greater expressivity than is possible in RSP1. \nThe price for this is a more complex type system. The goal with RSP1 is to .nd a sweet spot balancing \nexpressivity and complexity. 8. Conclusion and Future Work We have seen a language, RSP1, which combines \ndependent types with imperative and computational features. Using this language, we can implement examples \nwhere properties of data and even lo\u00adcal properties of the reference graph can be enforced statically. \nThis makes it relatively straightforward to implement examples like stat\u00adically veri.ed merge sort and \nbinary search trees where the binary search tree property is statically veri.ed. The type theory for \nthis language has two important features. First, it is .rst-order, mean\u00ading that it does not contain \nlambda-expressions and does not al\u00adlow abstraction types in argument positions. The latter is achieved \nwith syntactic restrictions on the forms of the argument types of abstraction types. Second, only pure \nobjects, which contain no use of the computational or imperative features of the language, are al\u00adlowed \ninto types. This is achieved with pure and impure versions of rules that need to substitute objects into \ntypes. These developments greatly simplify the type theory; the .rst-order restriction means there is \nno .-reduction, allowing for an untyped evaluation rela\u00adtion and an easy proof of the Church-Rosser property. \nWhen com\u00adbined with the restriction of only allowing pure objects into types, this makes the proof of \nthe decidability of equivalence checking straightforward. Only allowing pure objects into types also \nensures soundness of the type system in the face of imperative features. For future work, we would like \nto establish a sound and com\u00adplete type inferencing procedure for RSP1. Such an inference pro\u00adcedure \nwould need to handle the special case of a pattern abstrac\u00adtion with record patterns applied to a record. \nPreliminary results indicate that this would require second-order matching, to discover the dependencies \nin record and computational abstraction types. Also, we intend to add coverage checking and simple termi\u00adnation \nchecking [29] and support for proof irrelevance [20]. This would allow the use of RSP1 pattern abstractions \nas proofs of meta\u00adtheoretic properties of an object logic, which would not need to be executed at run-time. \nThey do not need to be executed if we can determine that they would always succeed (using coverage and \nter\u00admination checking) and that their results are never analyzed by any code other than more proof-irrelevant \ncode. This piece of future work is practically quite important, to avoid having to execute lem\u00admas at \nrun-time. Finally, we would like to do more examples of verifying safety properties of imperative data \nstructures. For example, it should be possible to enforce, through local invariants, the safety property \nthat the reference graph from any node is a tree. One way to do this would be to associate an id with \neach node (in addition to the node s data). Then the same idea as for the local invariants of the binary \nsearch tree can be used, except that we require the id at a node to be strictly greater than all ids \nreachable by going left and strictly less than all ids reachable by going right. Proof irrelevance is \nlikely to be important here, since inserting a new node into the tree would generally require updating \nthe ids at many (if not all) nodes. Naturally, we would need to slice away such code after type checking \nto get an ef.cient implementation. Acknowledgments: Thanks to Joel Brandt, Robert Klapper, and Li-Yang \nTan for many discussions about RSP1. Thanks also to Erran Li for discussion of the binary search tree \nand dag examples.  References [1] T. Altenkirch. Integrated veri.cation in Type Theory. Lecture notes \nfor a course at ESSLLI 96, Prague, 1996. available from the author s website. [2] A. Appel and A. Felty. \nDependent Types Ensure Partial Correctness of Theorem Provers. Journal of Functional Programming, 14(1):3 \n19, Jan. 2004. [3] L. Augustsson. Cayenne a language with dependent types. In Proceedings of the third \nACM SIGPLAN International Conference on Functional Programming, pages 239 250. ACM Press, 1998. [4] F. \nBaader and T. Nipkow. Term Rewriting and All That. Cambridge University Press, 1998. [5] J. Brandt. What \na Mesh: Dependent Data Types for Correct Mesh Manipulation Algorithms. Master s thesis, Washington University \nin Saint Louis, 2005. In preparation. [6] C. Chen and H. Xi. Combining Programming with Theorem Proving. \nIn Proceedings of the 10th International Conference on Functional Programming (ICFP05), Tallinn, Estonia, \nSeptember 2005. [7] R. Constable and the PRL group. Implementing mathematics with the Nuprl proof development \nsystem. Prentice-Hall, 1986. [8] T. Coquand and G. Huet. The Calculus of Constructions. Information and \nComputation, 76(2-3):95 120, 1988. [9] G. Dowek, A. Felty, H. Herbelin, and G. Huet. The Coq proof assistant \nuser s guide. Technical Report 154, Inria-Rocquencourt, France, 1993. [10] H. Goguen. A syntactic approach \nto eta equality in type theory. In Principles of Programming Languages (POPL), pages 75 84, 2005. [11] \nR. Harper, F. Honsell, and G. Plotkin. A Framework for De.ning Logics. Journal of the Association for \nComputing Machinery, 40(1):143 184, Jan. 1993. [12] R. Harper and F. Pfenning. On equivalence and canonical \nforms in the LF type theory. Transactions on Computational Logic, 6:61 101, Jan. 2005. [13] R. Klapper \nand A. Stump. Validated Proof-Producing Decision Procedures. In C. Tinelli and S. Ranise, editors, 2nd \nInternational Workshop on Pragmatics of Decision Procedures in Automated Reasoning, 2004. [14] N. Klarlund \nand M. Schwartzbach. Graph types. In Principles of Programming Languages, pages 196 205. ACM Press, 1993. \n[15] Z. Luo and R. Pollack. LEGO Proof Development System: User s Manual. Technical Report ECS-LFCS-92-211, \nEdinburgh LFCS, 1992. [16] C. McBride and J. McKinna. The View from the Left. Journal of Functional Programming, \n14(1), 2004. [17] F. Mehta and T. Nipkow. Proving Pointer Programs in Higher-Order Logic. In F. Baader, \neditor, 19th International Conference on Automated Deduction, volume 2741 of LNCS, pages 121 135. Springer-Verlag, \n2003. [18] A. M\u00f8ller and M. Schwartzbach. The pointer assertion logic engine. In M. Soffa, editor, ACM \nSIGPLAN Conference on Programming Language Design and Implementation, 2001. [19] B. Nordstr\u00a8om, K. Petersson, \nand J. Smith. Programming in Martin\u00adL\u00a8of s Type Theory. Oxford University Press, 1990. [20] F. Pfenning. \nIntensionality, Extensionality, and Proof Irrelevance in Modal Type Theory. In J. Halpern, editor, Proceedings \nof the Sixteenth Annual IEEE Symp. on Logic in Computer Science, LICS 2001. IEEE Computer Society Press, \n2001. [21] F. Pfenning and C. Elliott. Higher-order abstract syntax. In ACM SIGPLAN Symposium on Language \nDesign and Implementation, 1988. [22] F. Pfenning and C. Sch\u00a8urmann. System Description: Twelf A Meta-Logical \nFramework for Deductive Systems. In 16th International Conference on Automated Deduction, 1999. [23] \nB. Pierce. Types and Programming Languages. The MIT Press, 2002. [24] B. C. Pierce and D. N. Turner. \nLocal type inference. In 25TH ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages \n252 265, 1998. [25] R. Pollack. Dependently typed records in type theory. Formal Aspects of Computing, \n13:386 402, 2002. [26] J. Reynolds. Separation Logic: a Logic for Shared Mutable Data Structures. In \nIEEE Symposium on Logic in Computer Science, 2002. [27] S. Sagiv, T. Reps, and R. Wilhelm. Parametric \nShape Analysis via 3-Valued Logic. In Symposium on Principles of Programming Languages, pages 105 118, \n1999. [28] J. Sarnat. LF-Sigma: The Metatheory of LF with Sigma types. Technical Report 1268, Yale CS \ndepartment, 2004. [29] C. Sch\u00a8urmann and F. Pfenning. A Coverage Checking Algorithm for LF. In D. Basin \nand B. Wolff, editors, Proceedings of the 16th International Conference on Theorem Proving in Higher \nOrder Logics, volume 2758 of LNCS, pages 120 135. Springer-Verlag, 2003. [30] E. Westbrook, A. Stump, \nand I. Wehrman. A Language-based Ap\u00adproach to Functionally Correct Imperative Programming. Technical \nReport WUCSE-2005-32, Washington University in Saint Louis, July 2005. [31] H. Xi. Facilitating Program \nVeri.cation with Dependent Types. In Proceedings of the International Conference on Software Engineering \nand Formal Methods, pages 72 81, 2003. [32] D. Zhu and H. Xi. Safe Programming with Pointers through \nStateful Views. In Proceedings of the 7th International Symposium on Practical Aspects of Declarative \nLanguages, pages 83 97, Long Beach, CA, January 2005. Springer-Verlag LNCS vol. 3350.  \n\t\t\t", "proc_id": "1086365", "abstract": "In this paper a language-based approach to functionally correct imperative programming is proposed. The approach is based on a programming language called RSP1, which combines dependent types, general recursion, and imperative features in a type-safe way, while preserving decidability of type checking. The methodology used is that of internal verification, where programs manipulate programmer-supplied proofs explicitly as data. The fundamental technical idea of RSP1 is to identify problematic operations as impure, and keep them out of dependent types. The resulting language is powerful enough to verify statically non-trivial properties of imperative and functional programs. The paper presents the ideas through the examples of statically verified merge sort, statically verified imperative binary search trees, and statically verified directed acyclic graphs.", "authors": [{"name": "Edwin Westbrook", "author_profile_id": "81100094090", "affiliation": "Washington University in Saint Louis", "person_id": "P745793", "email_address": "", "orcid_id": ""}, {"name": "Aaron Stump", "author_profile_id": "81100151789", "affiliation": "Washington University in Saint Louis", "person_id": "PP18000552", "email_address": "", "orcid_id": ""}, {"name": "Ian Wehrman", "author_profile_id": "81430618845", "affiliation": "Washington University in Saint Louis", "person_id": "P745796", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1086365.1086400", "year": "2005", "article_id": "1086400", "conference": "ICFP", "title": "A language-based approach to functionally correct imperative programming", "url": "http://dl.acm.org/citation.cfm?id=1086400"}