{"article_publication_date": "09-12-2005", "fulltext": "\n Backtracking, Interleaving, and Terminating Monad Transformers (Functional Pearl) Oleg Kiselyov Chung-chieh \nShan Daniel P. Friedman FNMOC Harvard University Indiana University oleg@pobox.com ccshan@post.harvard.edu \ndfried@indiana.edu Amr Sabry Indiana University sabry@indiana.edu Abstract We design and implement \na library for adding backtracking com\u00adputations to any Haskell monad. Inspired by logic programming, \nour library provides, in addition to the operations required by the MonadPlus interface, constructs for \nfair disjunctions, fair conjunc\u00adtions, conditionals, pruning, and an expressive top-level interface. \nImplementing these additional constructs is easy in models of backtracking based on streams, but not \nknown to be possible in continuation-based models. We show that all these additional con\u00adstructs can \nbe generically and monadically realized using a single primitive msplit. We present two implementations \nof the library: one using success and failure continuations; and the other using control operators for \nmanipulating delimited continuations. Categories and Subject Descriptors D.1.1 [Programming Tech\u00adniques]: \nApplicative (Functional) Programming; D.1.6 [Program\u00adming Techniques]: Logic Programming; D.3.3 [Programming \nLanguages]: Language Constructs and Features Control struc\u00adtures; F.3.3 [Logics and Meanings of Programs]: \nStudies of Pro\u00adgram Constructs Control primitives General Terms Languages Keywords continuations, control \ndelimiters, Haskell, logic pro\u00adgramming, Prolog, streams.  1. Introduction One of the bene.ts of monadic \nprogramming is that it gener\u00adalises over all computational side e.ects or notions of computa\u00adtion [16, \n17], thus supporting custom evaluation modes like non\u00addeterminism and backtracking [29, 30]. Using monads \nto express non-determinism and backtracking is far from a theoretical curios\u00adity. Haskell s MonadPlus \ntype class, which de.nes a backtracking Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 05 September 26 28, 2005, Tallinn, Estonia. Copyright .c2005 ACM \n1-59593-064-7/05/0009. . . $5.00. monad interface, has found many practical applications [20], rang\u00ading \nfrom those envisioned for McCarthy s amb operator [15] and its descendents [25], to transactions [28], \npattern combinators [27], and failure handling [21]. In a functional pearl [11], Hinze describes backtracking \nmonad transformers that support non-deterministic choice and a Prolog\u00adlike cut with delimited extent. \nHinze aimed to systematically de\u00adrive his monad transformers in two ways, yielding a term imple\u00admentation \nand a (more e.cient) context-passing implementation. The most basic backtracking operations, failure \nand non-determin\u00adistic choice, are indeed systematically derived from their speci.\u00adcations. But when \nit came to cut, creative insight was still needed. Furthermore, the resulting term implementation is \nno longer based on a free term algebra, and the corresponding context-passing im\u00adplementation performs \npattern-matching on the context. As Hinze notes [11], this context-passing implementation di.ers from \na tra\u00additional continuation-passing-style (CPS) implementation that han\u00addles continuations abstractly. \nIn other words, the implementation is not directly amenable to a direct-style implementation using con\u00adtrol \noperators. Most existing backtracking monad transformers, including the ones presented by Hinze, su.er \nfrom three de.ciencies in practical use: unfairness, confounding negation with pruning, and a limited \nability to collect and operate on the .nal answers of a non-deter\u00administic computation. First, the straightforward \ndepth-.rst search performed by most implementations of MonadPlus is not fair: a non-deterministic choice \nbetween two alternatives tries every solu\u00adtion from the .rst alternative before any solution from the \nsecond alternative. When the .rst alternative o.ers an in.nite number of solutions, the second alternative \nis never tried, making the search incomplete. Indeed, as our examples in Section 3 show, fair back\u00adtracking \nhelps more logic programs terminate. Naturally, the im\u00adportance of fairness has been recognised before \n(e.g., by Seres and Spivey [23, 26], who also present a simple term implementation based on streams). \nOur contribution in this regard is to implement fair disjunctions and conjunctions in monad transformers \nand using control operators and continuations. The second de.ciency in many existing backtracking monads \nis the adoption of Prolog s cut, which confounds negation with pruning. Theoretically speaking, each \nof negation and pruning in\u00addependently makes logic programming languages more expres\u00adsive [9, 18]. Pruning \nalso allows an implementation to reclaim stor\u00adage and thus run some logic programs in constant space \n[18]. But negation does not necessarily imply pruning. In fact, Naish [18] points out that Prolog s cut \nis best understood as a combination of two operators: a logical if-then-else (also known as soft-cut, \nor negation as failure) and don t-care non-determinism (also known as once). Thus we separate the implementation \nand expressive power of these two operators and eschew the overloaded cut in our library. The third practical \nde.ciency is the often-forgotten top-level in\u00adterface: how to run and interact with a computation that \nmay re\u00adturn an in.nite number of answers? The most common solution is to provide a stream that can be \nconsumed or processed at the top\u00adlevel as desired. But in the case of monad transformers, this solution \nonly works if the base monad is non-strict (such as Haskell s lazy list monad and LazyST). In the case \nwhere the base monad is strict, the evaluation may diverge by forcing the evaluation of the entire stream, \neven if we only desire one answer. A less common solu\u00adtion is to explicitly include in the top-level \nrequest the maximum number of answers to return. Such an interface is trivial to imple\u00adment if the backtracking \ne.ect is internally realized using streams, but apparently impossible if the e.ect is internally realized \nusing continuations or control operators. Indeed, no existing system that uses continuations seems to \nprovide such an interface. We however show how to uniformly implement this interface in our model. To \nsummarise our contributions, we implement a backtracking monad transformer with fair disjunctions, fair \nconjunctions, soft\u00adcut, once, and an expressive top-level interface. In addition to discussing the standard \nstream-based implementation, we show two technically-challenging implementations, one based on CPS and \nthe other based on a control channel : 1. The CPS implementation uses a success continuation alongside \na failure continuation. It is e.cient in two ways: (a) It does not pattern-match on these continuations \nbut only invokes them. (b) It is the result of CPS-transforming a direct-style imple\u00admentation that \nruns deterministic code at full speed that is, without any interpretive overhead insofar as the base \nmonad to which the monad transformer is applied runs at full speed with mutable state and delimited control. \n 2. Underscoring this last point, the control-channel implementa\u00adtion uses fully-polymorphic multiprompt \ndelimited continua\u00adtions [7]. Thus our monad transformer factors through delim\u00adited control. This implementation \ncan be extended with more sophisticated search strategies that handle left recursion with\u00adout tabling, \nand that avoid pitfalls that make depth-.rst search incomplete and breadth-.rst search impractical. We \nomit such extensions here and refer the interested reader to the Kanren project [10]. We achieve fair \ndisjunctions and conjunctions, negation, prun\u00ading, and an expressive top-level interface across these \ntwo imple\u00admentations by requiring of them a single operation beyond the MonadPlus interface, called msplit. \nRoughly, msplit means to look ahead for one solution. It has the signature: msplit :: (Monad m, LogicT \nt, MonadPlus (tm)) . tma . tm (Maybe (a, tma)) where m is the underlying monad that provides arbitrary \ne.ects, and t is the monad transformer designed and implemented in this paper. Intuitively, msplit computes \nthe .rst solution (if any) and suspends the rest of the computation. Although it seems that msplit simply \nde-constructs a list or stream, it is not so easy to implement when tma is not a stream (indeed, not \neven a recursive type), as is the case for our CPS and control-channel implementations. The msplit operation \ndoes however let us treat the transformed monad as a stream, even when it is not. In particular, we can \nobserve not just the .rst solution from a backtracking computation but an arbitrary number of solutions, \neven using an implementation not based on streams. This paper is a literate Haskell 98 program, except \nthat we need the commonly implemented extension of rank-2 polymor\u00adphism [19] for the control operators \nof Section 5.2. All the code described in the paper is available at http://pobox.com/~oleg/ ftp/packages/LogicT.tar.gz \nunder the MIT License. 2. Basic Backtracking Computations: MonadPlus The MonadPlus interface provides \ntwo primitives, mzero and mplus, for expressing backtracking computations. The command mplus introduces \na choice junction, and mzero denotes failure: class Monad m . MonadPlus m where mzero :: ma mplus :: \nma . ma . ma The precise set of laws that a MonadPlus implementation should satisfy is not agreed upon \n[1], but there is reasonable agreement on the following laws [11]. (We discuss what kind of equivalence \nmeans in Section 3.4.) Definition 2.1 (Laws for MonadPlus). mplus a mzero a mplus mzero a a mplus a (mplus \nb c) mplus (mplus a b) c mzero >>= k mzero (mplus a b) >>= k mplus (a >>= k)(b >>= k) The intuition behind \nthese laws is that mplus is a disjunction of goals and >>= is a conjunction of goals. The conjunction \nevaluates the goals from left-to-right and is not symmetric. Using these operations, we may write some \nsimple examples: t1, t2, t3 :: MonadPlus m . m Int t1 = mzero t2 = return 10 mplus return 20 mplus return \n30 t3 = msum (map return [10, 20, 30]) The .rst example represents a choice that leads to failure. The \nsecond and third examples are identical, using a library de.nition of msum: they both represent a computation \nwith three choices, each succeeding with a di.erent integer. For simple examples like these, the built-in \nlist monad is an adequate implementation of the MonadPlus interface. The empty list denotes failure; \na singleton list denotes a deterministic com\u00adputation; and a list with more than one element denotes \nmultiple successful results returned by multiple choices. To run such exam\u00adples, we can trivially convert \nthe answers generated by the multiple choices into a stream of answers: runList :: [a] . [a] runList \n= id Indeed, runList t1 returns the empty list, and runList t2 and runList t3 both return the list [10, \n20, 30]. The list monad imposes an interpretive overhead on even deter\u00administic computations, because \nit constructs and destructs single\u00adton lists over and over again. Moreover, it takes quadratic time to \nenumerate all the solutions of a program like [11]: ( ... (return 1 mplus return 2) mplus ... return \nn) Other, more e.cient implementations of backtracking have been proposed using the two-continuation \nmodel [8] and delimited con\u00adtrol operators [5]. We revisit the various implementations of back\u00adtracking \nafter we enrich the interface of MonadPlus with additional operators that are considered useful for realistic \nprogramming ap\u00adplications. 3. A More Expressive Interface In this section, we extend the bare-bones \nMonadPlus interface with four combinators, for fair disjunctions, fair conjunctions, condi\u00adtionals, and \npruning. But .rst, let us generalise the runList function to monads other than the list monad. 3.1 Running \nComputations To run commands in a backtracking monad, we use a function runL, which is discussed in detail \nin Section 6. For now it su.ces to think of runL as having the following type: runL :: Maybe Int . La \n. [a] where L is the backtracking monad in question. When the .rst argument to runL is Nothing, all answers \nare produced. But when the .rst argument to runL is Just n, at most n answers are produced. 3.2 Interleaving \n(Fair Disjunction) Many realistic logic programs make a potentially in.nite number of non-deterministic \nchoices. For example, the computation: odds :: MonadPlus m . m Int odds = (return 1) mplus (odds >>= \n.a . return (2 + a)) succeeds an in.nite number of times. Running runL (Just 5) odds produces the list \n[1, 3, 5, 7, 9]. Computations that succeed an in.nite number of times can\u00adnot be combined na\u00efvely with \nother computations. For example, odds mplus t3 never considers t3 and thus the execution of the pro\u00adgram:1 \nrunL (Just 1) (do x . odds mplus t3 if even x then return x else mzero) diverges without ever succeeding. \nIn this case, however, the three answers 10, 20, and 30 that could be returned by t3 if it were executed \nare all even. In other words, the entire computation could diverge due to the in.nite number of successes \nwith odd numbers generated by odds. More abstractly, in addition to the laws in De.nition 2.1, mplus \nsatis.es an extra law: m1 mplus mm1 whenever m1 is a computation that can backtrack arbitrarily many \ntimes. This law is undesirable as it compromises completeness. This undesirable property is a direct \nconsequence of the associa\u00adtivity of mplus: it holds up to .nite observations in any implemen\u00adtation \nof MonadPlus which satis.es the laws in De.nition 2.1 (in\u00adcluding the speci.c List monad). It would thus \nbe useful to have a new primitive interleave such that: runL (Just 10) (odds interleave t3) would produce \n[1, 10, 3, 20, 5, 30, 7, 9, 11, 13]. This would allow: runL (Just 1) (do x . odds interleave t3 if even \nx then return x else mzero) to succeed with the answer 10. 1 For the code examples in this section, \nit is tempting to write ... $ do ..., but that would not work with our control-channel implementation \nof back\u00adtracking in Section 5.2, because the type of the computation passed to that runL must be polymorphic, \nwhich the predicative rank-2 polymorphism in Haskell [19] does not allow in an argument to $. 3.3 Fair \nConjunction The distributivity law from De.nition 2.1 states that: (mplus a b) >>= k mplus (a >>= k)(b \n>>= k) If a>>=k is a computation that can backtrack arbitrarily many times, then mplus never considers \nb >>= k, which means that in this case the following two expressions become equivalent: (mplus a b) >>= \nka >>= k Thus the unfairness of disjunction (mplus) causes the unfairness of conjunction (>>=). For example, \nthe program: let oddsPlus n = odds >>= .a . return (a + n) in runL (Just 1) (do x . (return 0 mplus return \n1) >>= oddsPlus if even x then return x else mzero) diverges, even though there exists an in.nite number \nof answers from return 1 >>= oddsPlus. Therefore, in addition to a fair mplus we need a fair >>=, which \nwe denote with >>-. Using such a combinator, the program: let oddsPlus n = odds >>= .a . return (a + \nn) in runL (Just 1) (do x . (return 0 mplus return 1) >>- oddsPlus if even x then return x else mzero) \nsucceeds with the answer 2. 3.4 Laws of interleave and >>- By design, interleave and >>- are fair analogues \nof mplus and >>=. In order to state the analogues for the laws in De.nition 2.1, it is helpful to realize \nthat every non-deterministic computation can be represented as either mzero or return a mplus mr for \nsome a and mr. Definition 3.1 (Laws for Fair MonadPlus). interleave mzero m interleave (return a mplus \nm1) m2 return a mplus (interleave m2 m1) mzero >>- k (mplus (return a) m) >>- k interleave (k a) (m >>- \nk) m mzero There are no explicit laws for computations of the form: interleave m mzero but we can reason \nabout such computations as follows. Either m is mzero and hence the entire expression is equivalent to \nmzero, or m can be represented as return a mplus mr and then: interleave m mzero interleave (return a \nmplus mr) mzero return a mplus (interleave mzero mr) return a mplus mr m The main use of interleave and \n>>- is in avoiding divergence when composing computations with a possibly in.nite number of answers. \nIn .nitary cases, interleave and >>- are observationally equivalent to mplus and >>= if the notion of \nobservation does not include the order of elements in the .nal list of answers. More precisely, Hinze \n[11] interprets an equivalence ab between monadic computations a and b to mean that runL Nothing a and \nrunL Nothing b produce identical streams of answers (where the order of the answers is signi.cant). In \nthis paper, we always in\u00adterpret the equivalence the same way. This is important when we later consider \nnon-deterministic computations layered over arbi\u00adtrary monadic computations. In such cases the order \nof the non\u00addeterministic answers must indeed be assumed to be observable. We should however mention in \npassing a di.erent approach, which asserts that the order of answers should not be part of the observational \nsemantics of non-deterministic computations. In that case, runL Nothing a and runL Nothing b need only \nreturn the same multiset of answers. Using this weaker, less deterministic and more liberal notion of \nequivalence based on multisets the laws of De.nition 3.1 become an instance of the simpler laws of De.nition \n2.1. 3.5 Soft cut (Conditional) In Haskell, one can use ordinary conditionals within a sequence of commands. \nWhile these constructs are quite useful, a logical condi\u00adtional is still wanting. The conventional conditional \nconstructs can easily express the situation when one computation depends on the success of another. For \nexample, the non-deterministic computa\u00adtion odds, which produces an odd number, can be restricted to \nonly succeed when the odd number is divisible by another number: iota n = msum (map return [1 .. n]) \ntest_oc = runL (Just 10) (do n . odds guard (n > 1) d . iota (n - 1) guard (d > 1 . n mod d = 0) return \nn) The result is [9, 15, 15, 21, 21, 25, 27, 27, 33, 33]. We use guard from the standard Monad library \nto .lter out only those numbers generated by odds that are evenly divisible by some number d between \n1 and n exclusive. (The presence of duplicates in the result will be discussed in the next section.) \nThe existing constructs are of no help however if we want to restrict the computation odds by .ltering \nthose odd numbers that are not divisible by any d in the given range, i.e., to produce odd prime numbers. \nFor this case, we need the common paradigm in logic programming of negation as .nite failure , which \nperforms a logical computation when some other computation fails. What is needed in this case is a special \nlogical conditional operator that we call ifte. The operation iftet thel should evaluate as follows. \nFirst the computation t is executed. If it succeeds with at least one result, the entire ifte computation \nis equivalent to t >>= th. Otherwise, the entire computation becomes equivalent to el. The construct \nifte is equivalent to Prolog s soft-cut (*->) and Mercury s if-then-else construct. A similar construct \nhas been pro\u00adposed for a Haskell logic monad [3]. The behaviour of this con\u00ad struct is given by the following \nlaws. Definition 3.2 (Laws for ifte). ifte (return a) th el th a ifte mzero th el el ifte (return a mplus \nm) th el th a mplus (m >>= th) The .rst two equivalences formalise the basic intuition of the con\u00adstruct. \nThe third equivalence is more interesting: as soon as the test command succeeds once, the th branch is \nimmediately executed and the el branch can never be tried. Thus: ifte (m1 mplus m2) th el * (ifte m1 \nth el) mplus (ifte m2 th el) In other words, the context ifte [] th el interacts in an unusual way with \nmplus. Because the el branch is only attempted when the test fails on the initial (rather than on a backtracking) \ntry, ifte is particularly useful [4] for explaining failure. For example, the el branch may contain a \ncomputation that records (e.g., prints) the fact and circumstances of failure of that particular test, \nand thus helps avoid uninformative, silent failures. Another common application of soft-cut, mentioned \nby Andrew Bromage [4], is committing to a heuristic (expressed as the test of ifte) if the heuristics \napplies. Section 7 illustrates with such an application. Example 3.1. With ifte we can now modify the \nexample at the be\u00adginning of the section to generate the odd prime numbers: test_op = runL (Just 10) \n(do n . odds guard (n > 1) ifte (do d . iota (n - 1) guard (d > 1 . n mod d = 0)) (const mzero) (return \nn)) The result is [3, 5, 7, 11, 13, 17, 19, 23, 29, 31]. 3.6 Pruning (Once) The operator ifte is in \nsome sense a pruning primitive. Another important pruning primitive is once, which selects, generally \nnon\u00addeterministically, one solution out of possibly many. The operator once greatly improves e.ciency \nas it can be used to avoid useless backtracking and therefore to dispose of data structures that hold \ninformation needed for backtracking (e.g., choice points). The once primitive is also important for expressiveness, \nas it expresses don t care non-determinism. For example, without it, non-deterministic polynomial-time \nDatalog queries are inexpressible [9]. Naish [18] suggests a simple example that motivates the use of \nonce. The example is based on the following code, which shows how to sort a list by generating all permutations \nand testing them: bogosort l = do p . permute l if sorted p then return p else mzero sorted (e1: e2: \nr) = e1 . e2 . sorted (e2: r) sorted = True permute [] = return [] permute (h : t) = do {tl. permute \nt; insert h tl} insert e [] = return [e] insert e l@(h : t) = return (e : l) mplus do {tl. insert e t; \nreturn (h : tl)} Despite being a bit contrived, this example is characteristic of logic programming: \ngenerate candidate solutions and then test them. The function bogosort can have more than one answer \nin case the list to sort has duplicates. For example: runL Nothing (bogosort [5, 0, 3, 4, 0, 1]) produces \ntwo answers that di.er in the order of the .rst two el\u00adements: [[0, 0, 1, 3, 4, 5], [0, 0, 1, 3, 4, 5]]. \nClearly this order is not observable, and we only need any one of the answers, which we can express by \nchanging the de.nition of bogosort to be: bogosortl l = once (do p . permute l if sorted p then return \np else mzero) The change does not constrain the use of bogosort in a larger program which itself uses \nbacktracking. It is just that bogosortl avoids backtracking during the sorting itself because it is useless \nand wasteful. In more general situations, di.erent solutions may not be equiv\u00adalent, and yet we may be \nsatis.ed with any of them for the purposes of a particular application. For example, in model checking \nwe are usually satis.ed with the .rst counterexample. As another example, our test_op in Example 3.1, \nwhich computes odd prime numbers, calculates all the factors of a composite number, which is wasteful \nfor primality testing. If any factor is found, the number is not prime, and there is no need to look \nfor more factorisations. In other words, test_op could be modi.ed as follows: test_opl = runL (Just 10) \n(do n . odds guard (n > 1) ifte (once (do d . iota (n - 1) guard (d > 1 . n mod d = 0))) (const mzero) \n(return n)) The use of ifte and once implements negation as failure. As Andrew Bromage explains [4], \nthis pattern can be abstracted into the following construct: gnot :: (Monad m, LogicT t, MonadPlus (tm)) \n. tma . tm () gnot m = ifte (once m)(const mzero)(return ()) Clearly, if m succeeds then gnot m fails, \nand if m fails then gnot m succeeds. Moreover, after the .rst time gnot m fails, there is no reason to \nbacktrack into m; any more results it might produce will just be ignored.  4. Splitting Computations \nRemarkably, the additional primitives in the more expressive in\u00adterface presented in the previous section \ncan all be implemented using one basic new abstraction msplit. We begin by formalising the extended interface \nas a Haskell type class that can be instanti\u00adated with one method: msplit. We give all the remaining \noperators default de.nitions. 4.1 The Monad LogicM The class LogicM in Figure 1 formalises the interface \ndiscussed in the previous section. It includes the functions used there: interleave, >>-, ifte, and once, \nwith default implementations us\u00ading the function msplit. Conspicuously absent from the LogicM class is \na function runL. It turns out that it can also be easily ex\u00adpressed using msplit. We discuss that implementation \nfor a more general case of a monad transformer LogicT in Section 6. Intuitively msplit takes a computation \nand determines if that computation fails or succeeds at least once. Operationally, we think of msplit \nas running its input computation looking for the .rst successful choice, providing a sort of lookahead \nof size one. The behaviour of msplit can be formalised using the following two laws. Definition 4.1 (Laws \nfor msplit). msplit mzero return Nothing msplit (return a mplus m) return (Just (a, m)) The .rst law \nformalises that a computation that fails cannot be split. The second law states that a computation that \nsucceeds at least once can be split into the .rst result and the rest of the computation. Using the default \nimplementations in LogicM we can verify the axioms for our primitives assuming msplit satis.es its axioms. \nFor example, we can verify: ifte (return a) th el do r . msplit (return a) case r of Nothing . el Just \n(sg1, sg2) . (th sg1) mplus (sg2 >>= th) class MonadPlus m . LogicM m where msplit :: ma . m (Maybe (a, \nma)) interleave :: ma . ma . ma interleave sg1 sg2 = do r . msplit sg1  case r of Nothing . sg2 Just \n(sg11, sg12) . (return sg11) mplus (interleave sg2 sg12) (>>-) :: ma . (a . mb) . mb sg >>- g = do r \n. msplit sg  case r of Nothing . mzero Just (sg1, sg2) . interleave (g sg1) (sg2 >>- g) ifte :: ma . \n(a . mb) . mb . mb ifte t th el = do r . msplit t case r of Nothing . el Just (sg1, sg2) . (th sg1) \nmplus (sg2 >>= th) once :: ma . ma once m = do r . msplit m  case r of Nothing . mzero Just (sg1, ) \n. return sg1 Figure 1. The class LogicM do r . msplit (return a mplus mzero) case r of Nothing . el \nJust (sg1, sg2) . (th sg1) mplus (sg2 >>= th) do r . return (Just (a, mzero)) case r of Nothing . el \nJust (sg1, sg2) . (th sg1) mplus (sg2 >>= th) case Just (a, mzero) of Nothing . el Just (sg1, sg2) . \n(th sg1) mplus (sg2 >>= th) (th a) mplus (mzero >>= th) th a 4.2 Implementing msplit Using Lists The \nmain technical challenge addressed in the paper is in imple\u00admenting msplit in monads that use continuations. \nThe implementa\u00adtion of msplit in the case of the list monad is straightforward and provides some helpful \nintuition. newtype SSG a = Stream [a] unSSG (Stream str) = str instance Monad SSG where return e = Stream \n[e] (Stream es) >>= f = Stream (concat (map (unSSG . f ) es)) instance MonadPlus SSG where mzero = Stream \n[] (Stream es1) mplus (Stream es2) = Stream (es1 ++ es2) class MonadTrans t . LogicT t where msplit :: \n(Monad m, MonadPlus (tm)) . tma . tm (Maybe (a, tma)) interleave :: (Monad m, MonadPlus (tm)) . t m a \n. t m a . t m a (>>-) :: (Monad m, MonadPlus (t m)) . t m a . (a . t m b) . t m b ifte :: (Monad m, MonadPlus \n(t m)) . t m a . (a . t m b) . t m b . t m b once :: (Monad m, MonadPlus (t m)) . t m a . t m a Figure \n2. The class LogicT instance LogicM SSG where msplit (Stream [ ]) = return Nothing msplit (Stream (h \n: t)) = return (Just (h, Stream t)) The implementation is essentially the List monad that is already \npresent in Haskell. As argued earlier, the reliance on the list monad has several drawbacks, many of \nwhich are discussed by Hinze [11]. In addition, the above implementation cannot be easily modi.ed to \nbecome a monad transformer since List as a transformer can only be applied to commutative monads [12]. \n 4.3 The Monad Transformer LogicT Instead of working with the .xed monad LogicM, we would like to uniformly \nadd msplit to other monads, thus augmenting arbitrary computations with our backtracking facilities. \nIn Haskell, this can be achieved by using monad transformers. A monad transformer t is de.ned using a \nclass: class MonadTrans t where lift :: Monad m . ma . tma Intuitively computations in a base monad \nm are lifted to computa\u00adtions in a transformed monad tm. The lifting satis.es the following laws: lift \n. return return lift (m >>= k) lift m >>= lift . k The speci.cation of LogicM can be turned into a monad \ntrans\u00adformer by simply copying the functions and giving them the re\u00adquired generalised types. Indeed \nthe interface to the class LogicT in Figure 2 is essentially identical to the one of LogicM; for brevity \nwe have not repeated the default implementations of the meth\u00adods. The precise relationship between the \ntwo .gures is that the class LogicM can be recovered by applying the monad transformer LogicT to the \nidentity monad. By inheriting from the library class MonadTrans, the class LogicT also includes the method \nlift that injects computations of the underlying monad of type ma into backtracking computations of type \ntma. For example, lift (putStrLn \"text\") >> mzero is a backtracking computation which performs a side-e.ect \nin the IO monad and then fails. The laws of msplit postulated in De.nition 4.1 should be gen\u00aderalised \nto handle the additional lifted e.ects from the under\u00adlying monad [14]. In the .rst law, instead of considering \na com\u00adputation mzero, we should consider more generally a computation lift m >> mzero which might perform \ncomputational e.ects in the underlying monad before failing. Similarly in the second law, in\u00adstead of \nconsidering a computation return a mplus tm1, we should consider more generally a computation lift m \nmplus tm1 which re\u00adturns the .rst result after performing some arbitrary e.ects in the underlying monad. \nThese generalisations are minimal and only de\u00adscribe the morphisms that lift trivially. In some cases, \na morphism m in the underlying monad may not be trivially lifted as lift m but rather as a new morphism \ntm that combines the backtracking ef\u00adfects and underlying e.ects in non-trivial ways. This is similar \nto what happens when lifting callcc through the state monad trans\u00adformer for example [14]. We motivate \nthe new form of the laws by considering the gener\u00adalised left-hand side of the second law: msplit (lift \nm mplus tm1). The computation tm1 has type tma whereas the result of msplit has the type tm (Maybe (a, \ntma)), which makes relating these values inconvenient. Therefore, we de.ne: re.ect :: (Monad m, LogicT \nt, MonadPlus (tm)) . Maybe (a, tma) . tma re.ect r = case r of Nothing . mzero Just (a, tmr) . return \na mplus tmr rr tm = msplit tm >>= re.ect Now, rr tm has the same type as tm and hence the two can be \nmore directly related. Direct inspection of the code of re.ect shows that it introduces no e.ects at \nthe source monad level and it does not a.ect the values of the monadic computation the latter fact is \nobvious from the type, which is polymorphic over any a and any source monad m. We can now state the generalised \nlaws. Definition 4.2 (Generalised Laws for msplit). rr (lift m >> mzero) lift m >> mzero rr (lift m mplus \ntma) lift m mplus (rr tma)  5. Implementations of LogicT We now focus our attention on the main technical \nchallenge of the paper: the implementation of the LogicT monad transformer. We provide two implementations \nthat manipulate continuations, either explicitly or implicitly using control operators. 5.1 CPS Implementation \nThe CPS-based implementation introduces the type constructor SFKT for functions accepting success and \nfailure continuations. The answer type is fully polymorphic: newtype SFKT ma = SFKT (. ans. SK (m ans) \na . FK (m ans) . m ans) unSFKT (SFKT a) = a type FK ans = ans type SK ansa = a . FK ans . ans The concrete \ntype of monadic actions is SFKT ma, where m is the source monad to be transformed. The following instance \ndeclarations specify that SFKT m is a Monad and MonadPlus, and that SFKT is a monad transformer. These \ninstance declarations are quite straightforward, and match the implementation of the monad transformer \n(without cut) given by Hinze [11]. instance Monad m . Monad (SFKT m) where return e = SFKT (.sk fk . \nsk e fk) m >>= f = SFKT (.sk . unSFKT m (.a . unSFKT (fa) sk)) instance Monad m . MonadPlus (SFKT m) \nwhere mzero = SFKT (. fk . fk) m1 mplus m2 = SFKT (.sk fk . unSFKT m1 sk (unSFKT m2 sk fk)) instance \nMonadTrans SFKT where lift m = SFKT (.sk fk . m >>= (.a . sk a fk)) As Hinze explains, this context-passing \nimplementation im\u00adproves on the na\u00efve term implementation by removing an interpre\u00adtive layer. But in \norder to augment the above implementation with control over backtracking (e.g., cut), Hinze changes the \nrepresen\u00adtation of contexts in order to pattern-match against them, restor\u00ading an interpretive layer. \nWe show however that this is not neces\u00adsary: we can maintain the abstract representation of continuations \nand support msplit. But indeed, contrary to the situation in Sec\u00adtion 4.2 where we implement msplit using \nlists, the implementa\u00adtion of msplit for the two-continuation monad transformer SFKT is more challenging: \ninstance LogicT SFKT where msplit tma = lift (unSFKT tma ssk (return Nothing)) where ssk a fk = return \n(Just (a, (lift fk >>= re.ect))) Intuitively, to split a computation tma, we supply it with two custom \nsuccess and failure continuations. If the failure continuation is immediately invoked, we get lift (return \nNothing) which is essen\u00adtially another way of expressing mzero in the transformed monad. If we encounter \nseveral non-deterministic choices and the success continuation is invoked in one of the cases with an \nanswer a, we return this answer a and a suspension that can be used to continue the exploration of the \nother choices. This is reminiscent of the list implementation but works even if tma for arbitrary m is \ngenerally not a recursive data type. Since the correctness of msplit is not so obvious, we outline a \nproof in the remainder of the section. The .rst law of msplit: rr (lift m >> mzero) lift m >> mzero follows \nfrom the monadic laws, the de.nition of re.ect and the observation: msplit (lift m >> mzero) lift m >> \n(return Nothing), which can be derived from the code of the above instance declara\u00adtions. To prove the \nsecond law of msplit: rr (lift m mplus tma) lift m mplus (rr tma) we observe that: lift m mplus tma SFKT \n(.sk fk . (.sk fk . m >>= (.a . sk a fk)) sk (unSFKT tma sk fk)) SFKT (.sk fk . m >>= (.a . sk a (unSFKT \ntma sk fk))) Thus we have: msplit (lift m mplus tma) lift m >>= (.a . return (Just (a, rr tma))) The \ndesired result follows from the de.nition of rr and monadic laws in the ma and tma monads. Furthermore, \nif we de.ne gf vtm = unSFKT (rr tm) fv we can easily obtain, from the de.nition of rr, that: gf vmzero \nv gf v (lift m mplus tm1) m >>= (.a . fa (gf vtm1)) that is, g is essentially fold, which clari.es the \nmeaning of the function rr. 5.2 Implementation Using Delimited Control The implementation based on control \noperators uses an exten\u00adsion of the fully answer-type-polymorphic delimited continuation framework developed \nby Dybvig et. al. [7]. The framework pro\u00advides two type constructors of interest: CC for computations \nthat manipulate delimited continuations and Prompt for control delim\u00aditers. We .rst extend the implementation \nto make CC a monad transformer and, using this extension, de.ne the following small library of control \noperators: promptP :: Monad m . (Prompt r a . CC r m a) . CC r m a abortP :: Monad m . Prompt r a . \nCC r m a . CC r m b shiftP :: Monad m . Prompt r b . ((CC r m a . CC r m b) . CC r m b) . CC r m a \nThe constructors Prompt and CC are parametrized by a type parameter r that refers to the control region \nassociated with the computation. Intuitively a delimiter of type Prompt r a was created in a control \nregion indexed by type r and its uses cannot escape from that control region. The type parameter r allows \ncomputations in the monad to be encapsulated using a construct of the following type: runCC :: Monad \nm . (. r. CC r m a) . ma The control operators we implement above have the following in\u00adtuitive explanation. \nThe operator promptP creates a new delimiter, pushes it on the stack, and invokes its argument with access \nto the newly-pushed delimiter. The execution of the argument can later abort up to this occurrence of \nthe prompt using abortP, or capture the continuation up to this occurrence of the prompt using shiftP. \nFor example, in the following expression: runIdentity (runCC (promptP $ .p . do x . shiftP p (.k . k \n(k (return 2))) return (x + 1))) the evaluation proceeds by .rst creating a new prompt and pushing it \non the stack. The evaluation of the do-expression then pushes the context do {x . [ ]; return (x + 1)} \non the stack before evaluating the shiftP expression. This expression captures the continuation up to \nthe prompt p, rei.es it as a function, and applies it twice to the argument 2. This instance of LogicT \nuses the CC library to de.ne the type constructor SR as follows: newtype SR r m a = SR (. ans. ReaderT \n(Prompt r (Tree r m ans)) (CC r m) a) unSR (SR f ) = f data Tree r m a = HZero | HOne a | HChoice a (CC \nr m (Tree r m a)) At the core of the de.nition of the type SRr ma is a computa\u00adtion of type CC rma that \nmanipulates continuations using con\u00adtrol operators instead of having an explicit success and failure \ncon\u00adtinuation as in the previous section. The computation executes in the context of an environment implemented \nusing ReaderT. The environment holds the most recently-pushed control delimiter, to which the computation \nshould abort if it fails. Computations in the ReaderT monad transformer are executed using the library \nfunction runReaderT, and access the environment using the library function ask, which in our case has \nthe type: ReaderT (Prompt r (Tree r m ans)) (CC r m) (Prompt r (Tree r m ans)). The SR r m monad is \nessentially the direct-style version of the two-continuation implementation in the previous section. \nPre\u00adviously, non-determinism was realized with the help of success and failure continuations. The success \ncontinuation receives not only the produced value but also a (failure) continuation to invoke if that \nvalue was not good enough (failure when processing that value). Here, the success continuation is represented \nby an implicit stack of pending computations with control delimiters marking the choice junctions. A \nnon-deterministic choice is then represented by capturing the delimited continuation up to the closest \ndelimiter and trying each of the branches using that continuation; failure is rep\u00adresented by aborting \nthe current delimited continuation. In the two-continuation model, there was no special way to represent \ndeterministic computations, which produce exactly one value. In the current model, we .nd it useful to \ndistinguish deter\u00administic results from non-deterministic results by using the data type Tree r m a. \nA deterministic result is marked by tagging it with HOne. A failure is represented by HZero and a choice \nis represented by HChoice a r. The latter value describes both the result a of the performed computation \nand the not-yet-executed computation that represents the other part of the choice. It is possible to \nrepresent deterministic computations as HChoice a (return HZero) at the expense of obscuring the de.nitions \nand losing some performance. The following de.nition shows that the type SR r m is an instance of Monad: \ninstance Monad m . Monad (SR r m) where return e = SR (return e) (SR m) >>= f = SR (m >>= (unSR . f )) \n The de.nition shows that deterministic computations are executed normally that is, as if they were in \nthe base monad m. And since SR is a newtype, tagging with SR and untagging with unSR do not take any \nrun time. We then show that SR r m is an instance of MonadPlus: instance Monad m . MonadPlus (SR r m) \nwhere mzero = SR (ask >>= .pr . lift (abortP pr (return HZero))) m1 mplus m2 = SR (ask >>= .pr . lift \n$ shiftP pr $ .sk . do f1 . sk (runReaderT (unSR m1) pr) let f2 = sk (runReaderT (unSR m2) pr) compose_trees \nf1 f2) compose_trees :: Monad m . Tree r m a . CC r m (Tree r m a) . CC r m (Tree r m a) compose_trees \nHZero r = r compose_trees (HOne a) r = return $ HChoice a r compose_trees (HChoice a rl) r = return $ \nHChoice a $ rl >>= (.v . compose_trees v r) A failing computation mzero simply aborts to the current \ndelim\u00aditer with the result HZero. A non-deterministic choice is slightly more complicated: we capture \nthe continuation sk up to the current delimiter. The .rst alternative m1 is immediately executed in that \ncontinuation; the second alternative m2 is suspended. The function compose_trees builds a new Tree combining \nthe results obtained from the .rst branch with the suspension from the second branch. Before discussing \nthe implementation of msplit we discuss a necessary function used to implement msplit. This function \nreify represents the computational e.ect of backtracking in an algebraic data type as described in two \nrecent papers [24, 13]: reify :: Monad m . SR r m a . CC r m (Tree r m a) reify m = promptP (.pr . runReaderT \n(unSR m) pr >>= (return . HOne)) As the code shows, the function reify m creates a new prompt, sets it, \nexecutes the computation, and tags the result with HOne. If the computation m executes deterministically, \nwe get the result HOne a where a is the resulting value. If the computation m fails, then the continuation \n(return . HOne) is aborted and we instead get HZero as the resulting value. Finally, let us illustrate \nthe case where the computation m is about to execute mplus m1 m2 using the following example: reify (m0 \n>>= (.x . k1 x mplus k2 x) >>= k3) where m0 is deterministic. This example is equivalent to: do HOne \nx . reify m0 f1val . reify (k1 x >>= k3) let f2comp = reify (k2 x >>= k3) compose_trees f1val f2comp \n Here f1val is the result (rei.ed into the Tree data type) of the .rst choice of mplus, and f2comp is \nthe computation that corresponds to the second choice. If f1val is HZero that is, the .rst choice even\u00adtually \nfails (either in k1 or in k3), then compose_trees will run the computation f2comp and the (rei.ed) result \nof the latter shall be the result of the original computation. In other words, if the .rst choice fails, \nwe execute the other one. If the .rst choice .nishes deter\u00administically, i.e., if f1val is HOne a, then \ncompose_trees represents the available choice by creating a result HChoice a f2comp, which suspends the \ncomputation f2comp to be later explored if needed as a possible alternative solution. Finally, if f1val \nis itself the choice Choice a rl that is, the execution k1 x >>= k3 has (unexplored) al\u00adternative branches \n(represented by rl), the function compose_trees essentially composes the unexplored choices rl with the \nunexplored choice f2comp. One may think of that composition as a rotation of a binary decision tree, \nor joining a branch f2comp to a binary node (a, rl). It helps to contrast our way of handling non-determinism \nwith the regular Prolog approach, epitomized in the Warren Abstract Machine (WAM). The WAM includes a \nstack, which contains both environments and choice points [22]. The stack of the WAM is represented by \nthe regular execution stack of the Haskell system. In the above example, f2comp (or more generally the \ncomputation sk (runReaderT (unSR m2) pr) in the implementation of mplus) represents the choice point. \nThe function compose_trees essentially handles the top-most choice point (the CP register of the WAM). \nOur function compose_trees opens up more .exible policies of handling the choice points. For example, \nonce compose_trees de\u00adtermines that f1val is HZero (that is, represents failure), it may not run f2comp. \nRather, it may tag f2comp with a special tag like Incomplete and return that. When one mplus is nested \nin an\u00adother, the outer instances of compose_trees, having received the Incomplete f2comp, may then decide, \neither to run that f2comp, or to try other choices, if any. Thus we can implement alterna\u00adtive evaluation \npolicies that avoid divergence in situations like (odds >> mzero) mplus m, that is, when disjoining (on \nthe left) a computation that diverges on backtracking. Finally we implement msplit for the monad transformer \nSR r: instance MonadTrans (SR r) where lift m = SR (lift (lift m))  instance LogicT (SR r) where msplit \nm = SR (lift (reify m >>= (return . re.ect_sr))) where re.ect_sr HZero = Nothing re.ect_sr (HOne a) = \nJust (a, mzero) re.ect_sr (HChoice a r1) = Just (a, SR (lift r1) >>= (return . re.ect_sr) >>= re.ect) \nThis implementation of msplit is more complicated than the CPS-based one because it must maintain the \nproper polymorphism of the answer type by not letting the type variable ans escape. Given the computation \nm, we .rst reify it. This will tell us if the computation fails, completes deterministically, or completes \nwith one answer and the choice of an alternative solution. This is precisely the information that we \nneed to know for msplit. The problem with the msplit implementation is that r1 in HChoice a r1 has the \ntype CC r m (Tree r m a) (of the rei.ed computation), whereas msplit must produce SR r m a. Thus we must \nbe able to go from the rei.ed computation Tree r m a back to the computation ma. The recursion in the \nimplementation of msplit accomplishes that goal: of re.ecting a value HChoice a r back into the computation \nreturn a mplus r. The recursion of re.ect_sr is a consequence of the fact that Tree r m a is a recursive \ndata type (although SR r m a is generally not, depending on m). Note that msplit invokes reify, which \nsets the prompt, overriding the prompt set by the top-level reify. This dynamic scoping inherent in delimited \ncontrol [2] is essential for msplit. In summary, we have implemented the LogicT interface to sup\u00adport \ndirect-style programming with a rich combination of several computational e.ects: of the base monad m, \nthe computational of the CC monad, and of the Reader monad. Although the present SRr ma implementation \nmay have a large cost because of the layering of several e.ects and because of the inherent cost of the \nCC monad, it is still worth using, at least for prototyping. Often direct-style implementations are clearer \nand lend themselves to deeper insights. Even though the SFKT monad seems more e.\u00adcient (and we would \nrecommend using it in production, because all its costs are quanti.able and not large), SR r m a seems \nto be better suited for prototyping of various choice-point selection poli\u00adcies and other advanced implementations \n(suspensions, constraint\u00adpropagation, etc.) of logical programming systems.  6. Running Computations \nWe now implement runL, to run the backtracking monad and ob\u00adserve its results as a list of answers. The \nsimplest solution is to de.ne the function solve for a particular monad, e.g., SFKT: solve :: (Monad \nm) . SFKT ma . m [a] solve (SFKT m) = m (.a fk . fk >>= (return . (a:))) (return [ ]) which is identical \nto the one provided by Hinze [11]. This function runs the backtracking computation of type SFKT ma and \ncollects all the answers in a list (to be observed in the source m monad). One may think that this function \nis su.cient: to observe at most n answers, we need to examine the pre.x of the resulting list of at most \nthat size. The rest of the answers will not be produced. However, the latter is only true if the source \nmonad m is non-strict. If however m is strict (e.g., IO), it is clear from the de.nition of solve that \nall the answers of SFKT ma will be produced and collected into the list, even if we need only a few of \nthem. This also means that applying solve to a computation SFKT IO a that has an in.nite number of answers \n(such as odds) will diverge. Thus we need a more general function runL, to which we can pass the maximum \nnumber of answers we wish to observe. That function will run the backtracking computation to the extent \nneeded to observe that many answers, no more. Therefore, runL can be safely used with non-deterministic \ncomputations with an in.nite number of answers over a strict monad. Implementing runL for the SFKT monad \nhowever appears to be all but impossible. To run a computation, we need to pass it a success and failure \ncontinuation. The success continuation receives one answer and a computation fk to run to get more answers. \nWe can easily disregard the failure computation after the .rst answer: observe :: Monad m . SFKT ma . \nma observe (SFKT m) = m (.a fk . return a)(fail \"no answer\") Or we can run that fk computation after \nthe .rst answer, as in solve, which gives us all answers. There does not seem to be a way to run fk only \na certain number of times, as the interface of SFKT does not let us pass any counter from one invocation \nof the success continuation to the next. Here again msplit helps. It turns out that we can implement \nrunL moreover, we can implement a more general operation bagofN and even unfold. Furthermore, we can \nimplement bagofN in a way that does not depend on the implementation of the back\u00adtracking monad transformer. \nThe operation bagofN is similar to Prolog s bagof iterator. The latter collects all answers of a given \ngoal in a list. Our bagofN is more general, as it lets the user spec\u00adify the maximum number of answers \nwanted. This more general bagofN is not expressible in Prolog using bagof or other prim\u00aditives, without \nresorting to destructive operations on the Prolog database: bagofN :: (Monad m, LogicT t, MonadPlus (tm)) \n. Maybe Int . tma . tm [a] bagofN (Just n) | n 0 = return [] bagofN n m = msplit m >>= bagofNl where \nbagofNl Nothing = return [] bagofNl (Just (a, ml)) = bagofN (fmap pred n) ml >>= (return . (a:)) If the \n.rst argument to bagofN is Just n, it selects at most n answers. Again, the operation msplit let us treat \nthe backtracking monad as if it were a stream, regardless of its actual implemen\u00adtation. The partially-applied \nbagofN Nothing is equivalent to the function sols of Hinze [11]. But there is no equivalent there of \nthe more challenging and more expressive bagofN (Just n). The result type of bagofN is tm [a]: we are \nstill in the trans\u00adformed monad. To get back to the source monad m, we need to observe [11] the produced \nlist value. The observation function is necessarily speci.c to the backtracking implementation.2 For \nthe SFKT monad, it is given above. For the SR monad, it is as follows: observesr :: Monad m . (. r. SR \nr m a) . ma observesr m = runCC (reify m >>= pick1) where pick1 HZero = fail \"no answer\" pick1 (HOne \na) = return a pick1 (HChoice a r) = return a Here, we reify the computation m into Treer m a, then pick \nthe .rst answer from the Tree, disregarding any other choices. With the help of observe we can now write \nthe function runL that we have used to run our examples: type La = . r. SR r Identity a runL :: Maybe \nInt . La . [a] runL n m = runIdentity (observesr (bagofN n m)) We also reveal the type of the backtracking \nmonad L that we introduced in 3.1. For our examples, the type is the transformer SR r over the identity \nmonad. The examples also run with the SFKT transformer. As an example of using the backtracking transformer \nover a non-trivial (and strict!) monad, we modify Example 3.1 to print all the factors that are produced: \n2 Ideally, the function observe should be part of the LogicT class, but this is not possible because \nof the universally quanti.ed type variable r in the last implementation. test_opio = print =<< observe \n(bagofN (Just 10) (do n . odds guard (n > 1) ifte (do d . iota (n - 1) guard (d > 1 . n mod d = 0) liftIO \n(print d)) (const mzero) (return n))) The source IO monad lets us print out the intermediate results. \nThis approach is far more robust than using Debug.Trace, as the output of the latter is hard to predict. \nThe comparison with Example 3.1 demonstrates the advantage of having a monad transformer: the bulk of \nthe code of Example 3.1 remains the same. We merely add liftIO (print d) and the printing of the .nal \nresult. 7. A Larger Example: Tic Tac Toe Tic Tac Toe, Reversi and many other strategic boardgames are \ngood examples of heuristic search. The Tic Tac Toe code, suggested by Andrew Bromage on the Haskell mailing \nlist [4], illustrates many features of our monad transformer LogicT in conducting basic minimax search \ncoupled with two heuristics. The present code is a generalisation of that by Andrew Bromage: It solves \ninstances of the problem with boards of size n \u00d7 n and where m consecutive marks are required for a win \n(such as Gomoku). We also added explicit limits on the depth and breadth of the search. Without the limits, \nthe program is too slow for interactive play on boards larger than 3\u00d73. The code accompanying the article \nincludes the complete program. We begin by declaring the basic types for representing the board and the \nmarks: data Mark = X | O deriving (Ord, Eq, Show) type Loc = (Int, Int) type Board = FiniteMap Loc Mark \ndata Game = Game{winner :: Maybe (Loc, Mark), moves :: [Loc], board :: Board} The type Loc describes \n(row, column) coordinates of one board cell, as a pair of integers within [0 .. n - 1]. A .nite map Board \nmaps the coordinates of marked locations to their marks. We use type Mark to identify players as well. \nThe current state of the game is a record of the current board position, the list of available moves \n(i.e., unmarked cells) and the indicator of the winner. The function newlgame :: Game initialises the \nboard. The function takelmove :: Mark . Loc . Game . Game takelmove p loc g = Game{ moves = delete loc \n(moves g), board = boardl , winner = let (n, l) = maxlcluster boardl p loc in if n . m then Just (l, \np) else Nothing} where boardl = addToFM (board g) loc p accounts for a move (i.e., the placement of a \nmark on a previ\u00adously empty cell) and generates the new game state. The function maxlcluster :: Board \n. Mark . Loc . (Int, Loc) computes the number of consecutive marks of the same sort around a given loca\u00adtion, \nmaximized over all possible directions. Let us de.ne the player procedure that takes the player s mark, \nthe game state, and, non-deterministically, makes a move and re\u00adturns the new game state together with \nan estimate of the game score for the player. type PlayerProc t (m :: *.*) = Mark . Game . tm (Int, Game) \n The main game function can then be de.ned: game :: (MonadPlus (tm), LogicT t, Monad m, MonadIO (tm)) \n. (Mark, PlayerProc t m) . (Mark, PlayerProc t m) . tm () game player1 player2 = gamel player1 player2 \nnewlgame where gamel player@(p, proc) otherlplayer g | Game{winner = Just k}. g = liftIO (putStrLn ((show \nk) ++ \" wins!\")) | Game{moves = []}. g = liftIO (putStrLn \"Draw!\") | otherwise = do ( , gl) . once (proc \np g) liftIO (putStrLn $ showlboard (board gl)) gamel otherlplayer player gl The expression once (proc \np g) means that once the player has made the move, the move is committed and cannot be un-played. Our \nplaying strategy is the basic minimax search. We .rst check if we reached the terminal, goal state. ail \n:: (MonadPlus (tm), Monad m, LogicT t) . PlayerProc t m ail pg = aillim m 6 pg where aillim dlim blim \np g | Game{winner = Just }. g = return (estimatelstate p g, g) | Game{moves = []}. g = return (estimatelstate \np g, g) | otherwise = minmax aillim dlim blim p g If not, we pick such a successor state that minimizes \nthe score for our opponent assuming the opponent always makes its best move: minmax :: (MonadPlus (tm), \nMonad m, LogicT t) . (Int . Int . PlayerProc t m) . (Int . Int . PlayerProc t m) minmax self dlim blim \np g = do wbs . bagofN (Just blim) (do m . choose (moves g) let gl = takelmove p m g if dlim 0 then return \n(estimatelstate p gl , gl) else do (w, ) . self (dlim - 1) blim (otherlplayer p) gl return (-w, gl)) \nreturn (maximumBy (.(x, )(y, ) . compare x y) wbs) The number dlim limits the depth of the search and \nthe number blim limits the number of moves considered at each step. The function choose non-deterministically \nchooses one move out of all available, and the function estimatelstate :: Mark . Game . Int estimates \nthe game score for the given player, as a signed integer in [-scorelwin .. scorelwin]. The larger the \ninteger, the better the position. We see the application of bagofN operation of LogicT. Unfortunately, \nthis code is too slow. Even for such a simple game on a 3\u00d73 board, the search space is noticeably large. \nAndrew Bromage has pointed out two safe heuristics. They are based on the following function, which determines \nif there is a move that immediately leads to victory for the player p: .rstlmovelwins p g = do m . choose \n(moves g) let gl = takelmove p m g guard (maybe False (.( , pl) . pl= p)(winner gl)) return (m, (scorelwin, \ngl)) We can change our play function as follows: ail :: (MonadPlus (tm), Monad m, LogicT t) . PlayerProc \nt m ail pg = aillim m 6 pg where aillim dlim blim p g | Game{winner = Just }. g = return (estimatelstate \np g, g) | Game{moves = []}. g = return (estimatelstate p g, g) | otherwise = ifte (once (.rstlmovelwins \np g)) (return . snd) (ifte (once (.rstlmovelwins (otherlplayer p) g)) (.(m, ) . do let gl = takelmove \np m g (w, ) . aillim dlim blim (otherlplayer p) gl return (-w, gl)) (minmax aillim dlim blim p g)) If \nthere is a winning move, we take it, without further ado. We are only interested in one such move, hence \nonce. If we cannot immediately win but our opponent can on the next move, we block that move. The ifte \nforms signify the commitment to a heuristic once it applies. If, and only if, none applies, we do the \nminimax search. To let the computer play against itself, we run the following computation: a12a1 :: IO \n() = observe $ game (X, ail)(O, ail) The complete code also includes a function for a human player, so \none can play against the computer. Although currently the choice and scoring functions are simplistic, \nand the search limits are low, the play is good enough to be entertaining. 8. Related Work Seres and \nSpivey [23] explored fair conjunction, but their imple\u00admentation relied exclusively on streams, instead \nof being purely monadic with operators >>- and interleave. Our solution not only handles the stream representation \nbut at least two other represen\u00adtations, Federhen s two-continuation model [8] and the control channel. \nWand and Vaillancourt [31] formally related the stream and two-continuation semantics of backtracking, \nbut they did not consider more general monadic streams or splitting of the back\u00adtracking computation. \nHinze [11] described backtracking transformers that support non-deterministic choice, and limited-extent \nProlog-like cut. His .nal, e.cient context-passing implementation was explicitly not continuation-passing \nbecause it required pattern-matching on the context. In addition, he ignored the problem of managing \ntermina\u00adtion, which we address with interleave and >>-. Furthermore, we added the ability to select any \ngiven number of answers. This is of course easy using streams, but di.cult in the two-continuation and \ncontrol-channel solutions; we believe that we are the .rst to im\u00adplement these monadically. One weakness \nof our approach as com\u00adpared to Hinze s is that he shows how to derive the transformers, with the promise \nof mechanization. That promise is not completely ful.lled however when cut is involved. Our approach \nis akin to the one he contrasts with in his introduction: Because it works. CPS-based implementations \nof Prolog with cut were discussed by de Bruin and de Vink [6], who used three continuations, for success, \nfailure, and cut. In this paper, we have shown a CPS-based system with negation and Prolog-like pruning \nthat uses only two continuations. 9. Conclusion We have introduced a backtracking monad transformer, \nwhich, in addition to the MonadPlus interface, provides fair conjunctions and disjunctions, logical conditional \nand pruning (don t-care non\u00addeterminism), and selecting an arbitrary number of answers. We have described \ntwo implementations of the transformer, a CPS one with two continuations, and a direct-style one based \non a Haskell library of delimited continuations [7]. All additional backtracking operations are implemented \ngenerically, in terms of one operation msplit. Our msplit operation lets us treat the backtracking transformed \nmonad as if it were a stream even when the monad is not a stream and not even of a recursive type (which \nis the case for both our implementations). We can therefore observe not just the .rst solution from a \nbacktracking computation but an arbitrary number of solutions. In future research, we plan on using our \ndirect-style implemen\u00adtation to implement sophisticated backtracking policies that can handle, for example, \nleft recursion without tabling. Acknowledgments We would like to thank the anonymous reviewers for their \ncorrec\u00adtions and suggestions. We also thank Andrew Bromage for helpful suggestions. References [1] MonadPlus. \nhttp://www.haskell.org/hawiki/MonadPlus, 2005. [2] Ariola, Z. M., Herbelin, H., and Sabry, A. A type-theoretic \nfoundation of continuations and prompts. In ACM SIGPLAN International Conference on Functional Programming \n(2004), ACM Press, New York, pp. 40 53. [3] Bromage, A. Initial (term) algebra for a state monad. http:// \nwww.haskell.org/pipermail/haskell-cafe/2005-January/ 008259.html, Jan. 2005. [4] Bromage, A. A MonadPlusT \nwith fair operations and pruning. http://www.haskell.org/pipermail/haskell/2005-June/ 016037.html, June \n2005. [5] Danvy, O., and Filinski, A. Abstracting control. In Proceedings of the 1990 ACM Conference \non LISP and Functional Programming, Nice (1990), ACM Press, New York, pp. 151 160. [6] de Bruin, A., \nand de Vink, E. P. Continuation semantics for PROLOG with cut. In TAPSOFT, Vol.1 (1989), J. D\u00edaz and \nF. Orejas, Eds., vol. 351 of Lecture Notes in Computer Science, Springer, pp. 178 192. [7] Dybvig, R. \nK., Peyton Jones, S. L., and Sabry, A. A monadic frame\u00adwork for delimited continuations. Tech. Rep. TR615, \nDepartment of Computer Science, Indiana University, June 2005. [8] Federhen, S. A mathematical semantics \nfor PLANNER. Master s thesis, University of Maryland, 1980. [9] Fosca Giannotti, D. P., and Zaniolo, \nC. Semantics and expressive power of nondeterministic constructs in deductive databases. Journal of Computer \nand System Sciences 62, 1 (2001), 15 42. [10] Friedman, D. P., and Kiselyov, O. A declarative applicative \nlogic programming system. http://kanren.sourceforge.net/, 2005. [11] Hinze, R. Deriving backtracking \nmonad transformers. In ICFP 00: Proceedings of the 5th ACM SIGPLAN International Conference on Functional \nProgramming (2000), ACM Press, pp. 186 197. [12] Jones, M. P., and Duponcheel, L. Composing monads. Tech. \nRep. YALEU/DCS/RR-1004, Department of Computer Science, Yale University, New Haven, 1993. [13] Kiselyov, \nO. How to remove a dynamic prompt: static and dynamic delimited continuation operators are equally expressible. \nTech. Rep. TR611, Department of Computer Science, Indiana University, 2005. [14] Liang, S., Hudak, P., \nand Jones, M. Monad transformers and modular interpreters. In POPL 95: Proceedings of the 22nd ACM SIGPLAN-SIGACT \nsymposium on Principles of programming languages (New York, NY, USA, 1995), ACM Press, pp. 333 343. [15] \nMcCarthy, J. A Basis for a Mathematical Theory of Computation. In Computer Programming and Formal Systems \n(1963), P. Bra.ort and D. Hirschberg, Eds., North-Holland, Amsterdam, pp. 33 70. [16] Moggi, E. An abstract \nview of programming languages. Tech. Rep. ECS-LFCS-90-113, Laboratory for Foundations of Computer Science, \nDepartment of Computer Science, University of Edinburgh, 1990. [17] Moggi, E. Notions of computation \nand monads. Information and Computation 93, 1 (1991), 55 92. [18] Naish, L. Pruning in logic programming. \nTech. Rep. 95/16, Depart\u00adment of Computer Science, University of Melbourne, Melbourne, Australia, June \n1995. [19] Peyton Jones, S. L., and Shields, M. B. Practical type inference for arbitrary-rank types. \nhttp://research.microsoft.com/ ~simonpj/papers/putting/, Apr. 2004. [20] Pierce, B. C., et al. What is \nMonadPlus good for? http://www. haskell.org/pipermail/haskell-cafe/2005-February/ 009072.html, Feb. 2005. \n[21] Roundy, D. What is MonadPlus good for? http://www.haskell. org/pipermail/haskell-cafe/2005-February/009081.html, \nFeb. 2005. [22] Roy, P. V. 1983 1993: The wonder years of sequential Prolog implementation. Journal of \nLogic Programming 19 20 (1994), 385 441. [23] Seres, S., Spivey, J. M., and Hoare, C. A. R. Algebra of \nLogic Programming. In ICLP (1999), pp. 184 199. [24] Shan, C. Shift to control. In Proceedings of the \n5th workshop on Scheme and Functional Programming (2004), O. Shivers and O. Waddell, Eds., pp. 99 107. \nTechnical report, Computer Science Department, Indiana University, 2004. [25] Siskind, J. M., and McAllester, \nD. A. Nondeterministic Lisp as a substrate for constraint logic programming. In AAAI-93: Proceedings \nof the 11th National Conference on Arti.cial Intelligence (11 15 July 1993), AAAI Press, pp. 133 138. \n[26] Spivey, J. M. Combinators for breadth-.rst search. Journal of Functional Programming 10, 4 (2000), \n397 408. [27] Tullsen, M. First class patterns. In Practical Aspects of Declarative Languages, 2nd International \nWorkshop (2000), E. Pontelli and V. S. Costa, Eds., vol. 1753 of Lecture Notes in Computer Science, Springer-Verlag, \npp. 1 15. [28] Turk, R. What is MonadPlus good for? http://www.haskell. org/pipermail/haskell-cafe/2005-February/009086.html, \nFeb. 2005. [29] Wadler, P. L. Comprehending monads. Mathematical Structures in Computer Science 2, 4 \n(1992), 461 493. [30] Wadler, P. L. The essence of functional programming. In POPL 92: Proceedings of \nthe 19th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (1992), ACM Press, pp. 1 \n14. [31] Wand, M., and Vaillancourt, D. Relating models of backtracking. In ACM SIGPLAN International \nConference on Functional Program\u00adming (2004), pp. 54 65.  \n\t\t\t", "proc_id": "1086365", "abstract": "We design and implement a library for adding backtracking computations to any Haskell monad. Inspired by logic programming, our library provides, in addition to the operations required by the <i>MonadPlus</i> interface, constructs for fair disjunctions, fair conjunctions, conditionals, pruning, and an expressive top-level interface. Implementing these additional constructs is easy in models of backtracking based on streams, but not known to be possible in continuation-based models. We show that all these additional constructs can be <i>generically</i> and monadically realized using a single primitive <i>msplit</i>. We present two implementations of the library: one using success and failure continuations; and the other using control operators for manipulating delimited continuations.", "authors": [{"name": "Oleg Kiselyov", "author_profile_id": "81100177557", "affiliation": "FNMOC", "person_id": "PP37024734", "email_address": "", "orcid_id": ""}, {"name": "Chung-chieh Shan", "author_profile_id": "81100400956", "affiliation": "Harvard University", "person_id": "PP33025858", "email_address": "", "orcid_id": ""}, {"name": "Daniel P. Friedman", "author_profile_id": "81100636522", "affiliation": "Indiana University", "person_id": "PP39051860", "email_address": "", "orcid_id": ""}, {"name": "Amr Sabry", "author_profile_id": "81100016804", "affiliation": "Indiana University", "person_id": "P16266", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1086365.1086390", "year": "2005", "article_id": "1086390", "conference": "ICFP", "title": "Backtracking, interleaving, and terminating monad transformers: (functional pearl)", "url": "http://dl.acm.org/citation.cfm?id=1086390"}