{"article_publication_date": "09-12-2005", "fulltext": "\n A Logical Analysis of Aliasing in Imperative Higher-Order Functions Martin Berger Kohei Honda Nobuko \nYoshida Queen Mary, University of London Imperial College London Abstract We present a compositional \nprogram logic for call-by-value imper\u00adative higher-order functions with general forms of aliasing, which \ncan arise from the use of reference names as function parameters, return values, content of references \nand parts of data structures. The program logic extends our earlier logic for alias-free impera\u00adtive \nhigher-order functions with new modal operators which serve as building blocks for clean structural reasoning \nabout programs and data structures in the presence of aliasing. This has been an open issue since the \npioneering work by Cartwright-Oppen and Morris twenty-.ve years ago. We illustrate usage of the logic \nfor description and reasoning through concrete examples including a higher-order polymorphic Quicksort. \nThe logical status of the new operators is clari.ed by translating them into (in)equalities of refer\u00adence \nnames. The logic is observationally complete in the sense that two programs are observationally indistinguishable \niff they satisfy the same set of assertions. Categories and Subject Descriptors F.3.1 [Specifying and \nVeri\u00adfying and Reasoning about Programs]: Assertions, logics of pro\u00adgrams, speci.cation techniques General \nTerms Languages, Reliability, Security, Theory, Veri.\u00ad cation Keywords Hoare-Logics, Modalities, Aliasing, \nPointers, Typing, Functional Programming, p-Calculus 1. Introduction In high-level programming languages \nnames can be used to indicate either stateless entities like procedures, or stateful constructs such \nas imperative variables. Aliasing, where distinct names refer to the same entity, has no observable effects \nfor the former, but strongly affects the latter. This is because if state changes, that change should \naffect all names referring to that entity. Consider def P = x := 1; y :=!z ;!y := 2, where, following \nML notation, !x stands for the content of an imperative variable or reference x. If z stores a reference \nname x initially, then the content of x after P runs is 2; if z stores something else, the .nal content \nof x is 1. But if it is unclear what z stores, we cannot know if !y is aliased to x or not, which makes \nreasoning Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP \n05 September 26 28, 2005, Tallinn, Estonia. Copyright c &#38;#169; 2005 ACM 1-59593-064-7/05/0009. . \n. $5.00. dif.cult. Or consider a program def Q = .y.(x := 1; y := 2). If Q is invoked with an argument \nx, the content of x ends up as 2, otherwise it stays 1. In these examples, what have been syntac\u00adtically \ndistinct reference names in the program text may be coa\u00adlesced during execution, making it dif.cult to \njudge which name refers to which store from the program text alone. The situation gets further complicated \nwith higher-order functions because pro\u00adgrams with side effects can be passed to procedures and stored \nin references. For example let: def R = .(f xy). ( let z =!x in !x := 1; !y := 2; f (x,y) ; z := 3 ) \nwhere a = Ref (Ref (Nat)). R receives a function f and two ref\u00aderences x and y. Its behaviour is different \ndepending on what it receives as f (for simplicity let s assume x and y store distinct ref\u00aderences). \nIf we pass a function .xy.() as f , then, after execution, !x stores 3 and !y stores 2. But if the standard \nswapping function def swap = .ab.let c = !b in (b :=!a; a := c) is passed, the content of x and y is \nswapped and !x now stores 2 while !y stores 3. Such interplay between higher-order procedures and aliasing \nis common in many non-trivial programs in ML, C and more recent typed and untyped low-level languages \n[1, 17, 38]. Hoare logic [20], developed on the basis of Floyd s assertion method [14], has been studied \nextensively as a veri.cation method for .rst-order imperative programs with diverse applications. How\u00adever \nHoare s original proof system is sound only when aliasing is absent [4, 11]: while various extensions \nhave been studied, a gen\u00aderal solution which extends the original method to treat aliasing, retaining \nits semantic basis [15, 21] and tractability, has not been known, not to speak of its combination with \narbitrary imperative higher-order functions (our earlier work [24] extends Hoare logic with a treatment \nfor a general class of higher-order imperative func\u00adtions including stored procedures, but does not treat \naliasing). Resuming studies by Cartwright-Oppen and Morris from 25 years ago [9, 10, 33], the present \npaper introduces a simple and tractable compositional program logic for general aliasing and im\u00adperative \nhigher-order functions. A central observation in [9, 10, 33] is that (in)equations over names, simple \nas they may seem, are ex\u00adpressive enough to describe general aliasing in .rst-order proce\u00addural languages, \nprovided we distinguish between reference names (which we write x) and the corresponding content (which \nwe write !x) in assertions. In particular, their work has shown that alias ro\u00adbust substitution, written \nC{|e/!x|} in our notation, de.ned by: M |=C{|e/!x|} iff M [x .[[e]]M] |= C (1) (i.e. an update of a store \nat a memory cell referred to by x with value e), can be translated into (in)equations of names through \ninductive decomposition of C, albeit at the expense of an increase in formula size. This gives us the \nfollowing semantic version of Hoare s assignment axiom: {C{|e/!x|}}x := e {C} (2) where the pre-condition \nin fact stands for the translated form men\u00adtioned above. The rule subsumes the original axiom but is \nnow alias-robust. As clear evidence of descriptive power of this ap\u00adproach, Cartwright and Oppen showed \nthat the use of (2) leads to a sound and (relatively) complete logic for a programming lan\u00adguage with \n.rst-order procedures and full aliasing [9, 10]: Mor\u00adris showed many non-trivial reasoning examples for \ndata structures with destructive update, including the reasoning for Schorr-Waite algorithm [33]. The \nworks by Cartwright-Oppen and Morris, remarkable as they are, still beg the question how to reason about \nprograms with alias\u00ading in a tractable way. The .rst issue is calculation of validity in assertions involving \nsemantic substitutions. This is hardly practi\u00adcal because inductive decomposition of {|e/!x|} into (in)equations \nhas been the only syntactic tool available. As demonstrated through many examples by Morris [33] and, \nmore recently, Bornat [7], this decomposition should be distributed to every part of a given for\u00admula \neven if that part is irrelevant to the state change under consid\u00aderation, making reasoning extremely \ncumbersome. As one typical example, if we use the decomposition method for calculating the logical equivalence \nC{|c/!x|}{|e/!x|} = C{|c/!x|} for general C, with c being a constant, we need either meta-logical reasoning, \ninduction on C, or an appeal to semantic means. Be\u00adcause such logical calculation is a key part of program \nproving (cf. [20]), practical usability of this approach becomes unclear. The second problem is the lack \nof structured reasoning principles for deriving precise description of extensional program behaviour \nwith aliasing. This makes reasoning hard, because properties of com\u00adplex programs often depend crucially \non how sub-programs inter\u00adact through shared, possibly aliased references. Finally, the logics in [9, \n10, 33] and their successors do not offer a general treatment of higher-order procedures as well as mutable \ndata structures which may store such procedures. We address these technical issues by augmenting the \nlogic for imperative higher-order functions introduced in [24] with a pair of mutually dual logical primitives \ncalled content quanti.ers. They of\u00adfer an effective middle layer with clear logical status for reasoning \nabout aliasing. The existential part of the primitives, written (!x)C, is de.ned by the following equivalence: \ndef M |= (!x)C =.V.(M [x .V ] |= C) (3) The de.ning clause says: for some possible content of a reference \nnamed x, M satis.es C (which may not be about the current state, but about a possible state, hence the \nnotation). Syntactically (!x)C does not bind free occurrences of x in C. Its universal counterpart is \nwritten [!x]C, with the obvious semantics. We mention a couple of notable aspects of these operators. \nFirst, introduction of these operators gives us a tractable method for logically calculating assertions \nwith semantic update, solving a central issue posed by Cartwright-Oppen and Morris 25 years ago. We start \nfrom the following syntactic representation of semantic update using the well-known decomposition: C{|e/!x|} \n= .m.((!x)(C .!x= m) . m= e). (4) From (3) and (4), the logical equivalence (1) is immediate, recov\u00adering \n(2) as a syntactic axiom. Not only does C{|e/!x|} now have concrete syntactic shape without needs of \nglobal distribution of up\u00addate operations, but also these operators offer a rich set of logical laws \ncoming from standard quanti.ers and modal operators, en\u00adabling ef.cient and tractable calculation of \nvalidity while subsum\u00ading Cartwright-Oppen/Morris s methods. Intuitively this is because logical calculation \ncan now focus on those parts which do get af\u00adfected by state change: just like lazy evaluation, we do \nnot have to calculate those parts which are not immediately needed. In later sections we shall demonstrate \nthis point through examples. Closely related with its use in logical calculation is a powerful descriptive/reasoning \nframework enabled by content quanti.cation, in conjunction with standard logical primitives. By allowing \nhypo\u00adthetical statements about the content of references separate from reference names themselves (which \nis the central logical feature of these operators), complex aliasing situations are given clean, suc\u00adcinct \ndescription, combined with effective compositional reason\u00ading principles. This is particularly visible \nwhen we describe and reason about disjointness and sharing of mutable data structures (in this sense \nit expands the central merits of separating connec\u00adtives [34, 37], as we shall discuss in later sections). \nThe primi\u00adtives work seamlessly with the logical machinery for capturing pure and imperative higher-order \nbehaviour studied in [22, 23, 24], en\u00adabling precise description and ef.cient reasoning for a large class \nof higher-order behaviour and data structures. The descriptive power of the logic is formally clari.ed \nin Section 4 by showing the as\u00adsertion language is observationally complete in the sense that two programs \nare contextually indistinguishable exactly when they sat\u00adisfy the same set of assertions. Third, and \nsomewhat paradoxically, these merits of content quanti.cation come without any additional expressive \npower: any formula which contains content quanti.cation can be translated, up to logical equivalence, \ninto one without. While establishing this result, we shall also show that content quanti.cation and semantic \nupdate are mutually de.nable. Thus name (in)equations, content quanti.cation and semantic update are \nall equivalent in sheer ex\u00adpressive power: the laws of content quanti.cation are reducible to the standard \naxioms for the predicate calculus with equality, which in turn are equivalent to semantic update through \nits axioms for decomposition. This does not however diminish the signi.cance of content quanti.cation: \nwithout identifying it as a proper logi\u00adcal primitive with associated axioms, it is hard to consider \nits use in reasoning, both in logical calculation and in its applications to structured reasoning for \nprograms and data structures in the pres\u00adence of general aliasing. To our knowledge [2, \u00a710], neither \nthe calculation method nor the reasoning principle proposed in the present paper is discussed in the \nforegoing work. In the remainder, Section 2 introduces the programming/asser\u00adtion languages. Section \n3 presents axioms and proof rules. Section 4 records key technical results on the logic. Section 5 illustrates \nthe use of the logic through concrete reasoning examples including a higher-order, polymorphic Quicksort. \nSection 6 discusses related work (including earlier logics for sublanguages of Algol and more recent \nones such as Separation Logic) and concludes with further issues. A full version [2] contains detailed \nproofs, further examples and an extensive historical survey. 2. Assertions and their Semantics 2.1 Programming \nLanguage. As a target programming language, we use call-by-value PCF with unit, sums and products, augmented \nwith imperative constructs [35]. Let x,y,... range over an in.nite set of names. Then types, values and \nprograms are given by the following grammar. a ::= Unit | Bool | Nat | a.\u00df | a \u00d7 \u00df | a + \u00df | Ref (a) \naa V ::= c | x | .x.M | \u00b5f a.\u00df ..y.M |(V,W )| ini(V ) M ::= V | MN | M := N | !M | op(M ) | pi(M) |(M,N)| \nini(M) ai | if M then M1 else M2 | case M of {ini(xi ).Mi}i.{1,2} We use standard boolean/arithmetic \nconstants and operations, resp. ranged over by c and op. Types can carry reference types: hence procedures, \nreferences and data structures may pass/return/store reference names, leading to general forms of aliasing \nas discussed in the Introduction. We freely use obvious shorthands like M; N and let x = M in N. A basis \nG; . is a pair of .nite maps one from names to non\u00adreference types (G,..., called environment basis) \nand the other from names to reference types (.,..., called reference basis). T,T',... combine two kinds \nof bases. The typing rules are standard and omitted [35]. We write G;. f M : a when M has type a under \nG;.. A program is semi-closed if its environment basis is empty, written . f M : a.A store (s,...) is \na .nite map from reference names to semi-closed values, to which the typing extends in the obvious way. \nUsing con.gurations of the form (M, s) with semi\u00adclosed M and store s typable under a common basis, the \ncall-by\u00advalue, one step reduction, written (M, s) -. (M', s'), is de.ned in the standard way [18, 35]. \nWe write (M,s) . if .V,s'. (M,s) -. * (V,s') -. . Henceforth we only consider well-typed programs and \ncon.gura\u00adtions. 2.2 Models. We introduce a class of models which concisely represent compu\u00adtational \nsituations of interest. We follow our previous work [24] except for the additional use of distinctions \nto describe aliasing, an innovation coming from the p-calculus [32]. Our models are im\u00admediately faithful \nto the observable behaviour of programs, which is important for our logic s observational completeness, \nestablished later. A distinction over . (D,...) is a type-respecting equivalence relation over dom(.). \nThe equivalence classes of a distinction are called its identicals (i,j,...). The point of using distinctions \nis to have a modular way of specifying in the model which references are aliased (those in the same identical) \nand which are not. Let . f M : a and let D be a distinction over .. Regarding identicals of D as names, \nwe can substitute a D-identical i for each name x . i in M, which we write MD. Intuitively, MD is a program \nwhose names are coalesced following D. MD is typed by .D, which is de.ned def similarly. For example, \ngiven M = if x = y then 0 else 1, if D only equates x and y then we have MD def = if i = i then 0 else \n1 = {x, y}), (assuming i def Note MD reduces as (MD, s) -. (0, s) which is quite different from M itself, \nshowing that distinctions affect observable behaviour of programs. A typed context C[ \u00b7 ]G;.;a is a context \nwith a hole typed with a under G;.. A typed context is semi-closing if it does not .-abstract any reference \nname in the hole and the resulting program is semi\u00adclosed. . is complete if, whenever Ref (a) occurs \nin a type in . s range, there is a name of that type in .. Let . be complete and D be a distinction over \n. and assume G;. f M1,2: a. Then we write ~ G; . f M1 =D M2: a iff ((C[M1D],s) . iff (C[M2D],s) .) for \nall semi-closing C[ \u00b7 ]G;.;a and well-typed stores s. The stan\u00addard contextual congruence [35], which \nwe denote by ~ =, coincides with the closure of ~ =D under arbitrary distinctions. An abstract value \nof type (D;.;a) is a ~ =D-congruence class of semi-closed values which are typed as a under .. We let \nv, w,... range over abstract values. In short, abstract values are semi\u00adclosed values taken modulo the \ntyped congruence relative to a given distinction. Since reference names are values, identicals are also \nabstract values (of appropriate types). We write [V ]D;.;a for an abstract value whose representative \nis V , and [[a]]. D for the set of all abstract values of type (D; .;a). We can now de.ne a model. De.nition \n1 A model of type G;., written M G;. , is a triple (D,.,s) where D is a distinction on .;  ., called \nenvironment, is a .nite map from dom(G,.) to ab\u00adstract values which is type-respecting in the sense that \neach x . dom(G,.) is mapped to an abstract value of type D; .;G(x);  s, called (abstract) store, is \na .nite map from the identicals of D to abstract values which is type-respecting in the sense that each \ni . D is mapped to an abstract value of type D;.;a assuming (.D)(i)= Ref (a).  2.3 Syntax of Assertions. \nThe logical language is standard .rst-order logic with equality [31, \u00a7 2.8], extended with assertions \nfor evaluation with side effects [24] and quanti.cations over store content. Let * . {.,.,.} and Q . \n{., .}. We highlight changes from [24]. a+\u00df e ::= xa | () | n | b | op(e ) |(e,e') | pi(e) | inj(e) | \n!e i ' C ::= e = e'|\u00acC | C *C'| Q x.C |{C} e e= x {C'} | [!e]C |(!e)C ' The .rst set of expressions \n(ranged over by e, e,...) are terms while the second set are formulae (ranged over by A, B,C,C' ...). \nThe constants include unit, numerals and booleans, while op(e ) ranges over .rst-order operations, both \ncoming from the underlying pro\u00adgramming language. We also have pairing, projection and injection, again \ncorresponding to those in the target programming language. The .nal term !e dereferences e. Unlike in \n[24], quanti.cation can abstract variables of all types including references. We also use truth T (de.nable \nas 1 = 1) and falsity F (which is \u00acT). Finally, x = y stands for \u00ac(x = y). ' The formula {C} e e= x \n{C'} is called evaluation formula [24], where the name x binds its free occurrences in C'. Intuitively, \n' {C} e e= x {C'} asserts on the evaluation of an application with pre/post conditions, and can be read: \nan invocation of e with an argument e' under hypothetical initial state C (pre-condition) terminates \nwith a .nal state and a resulting value, the latter named x, both described by C' (post-condition). The \npre/post conditions are about hypothetical state since we often need to describe imperative behaviour \nindependent from a current state. For example, !x = 1 ..i.. j.{!x = i} f j = z {z = !x = i + j} asserts \nthat (1) the current content of x is 1; and (2) if, hypothet\u00adically, the content of x is i and f is invoked \nwith j, then the re\u00adturn value and the resulting content of x are both i + j. Note that ' e e' = x in \n{C} e e= x {C'} is asymmetric and is not commu\u00adtative. 1 Content quanti.cations (!e) and [!e] are illustrated \nthrough examples later. fv(C) denotes the set of free variables in C. C-x in\u00addicates fv(C) n{ x } = 0/. \nBinding in formulae is induced only by standard quanti.ers, ., ., and by evaluation formulae. In particu\u00adlar, \nfv((!e)C)= fv([!e]C)= fv(e) . fv(C). Formulae are taken up to a-convertibility (some care is needed to \navoid name capture, as illustrated in [2, \u00a75.2], though all concrete examples in this paper can be read \nwithout this concern). Starting from variables, each term can be typed inductively. Using typed terms \nis not strictly necessary but contributes to clarity ' 1 In [24], we wrote {C} e e'. x {C'} instead \nof {C} e e= x {C'}. and understandability. We write T f e : a when e has type a under T. We also write \nT f C when terms in C are well-typed under T. Henceforth we only treat well-typed terms and formulae. \nType annotations for variables are often omitted in examples. Logical substitution plays an important \nrole in the present logic. We de.ne, with m fresh: def C{|e2/!e1|} = .m.((!e1)(C . !e1 = m) . m = e2). \nIntuitively C{|e2/!e1|} describes the situation where a model satis\u00adfying C is updated at a memory cell \nreferred to by e1 (of a reference type) with a value e2 (of its content type), with e1,2 interpreted \nin the current model. Through the help of axioms discussed later, log\u00adical substitution interacts with \ncontent quanti.cation just as syntac\u00adtic substitution does with conventional quanti.cation. For example, \n[!x]C . C{|e/!x|} for any x, e and C, which corresponds to the fa\u00admiliar .x.C . C[e/x]. C{|e/!x|} . (!x)C \nalso holds, corresponding to the standard entailment C[e/x] ..x.C. Convention Logical connectives are \nused with standard prece\u00addence/association, with content quanti.cation given the same precedence as standard \nquanti.cation (i.e. they associate stronger than binary connectives). For example, \u00acA .B ..x.C .(!e)D \n. E is a shorthand for ((\u00acA) . B) . (((.x.C) . ((!e)D)) . E). C1 = C2 stands for (C1 . C2) . (C2 . C1). \nSimilarly, {C}e e '{C '} stands for {C}e e ' = x{x = () . C '} with x . fv(C '); and ' {C}e e = e \n''{C '} for {C}e e ' = x{x = e '' . C '} with x . '' fv(C ') . fv(e '') and e not a variable. Formulae \nare often called assertions. 2.4 Semantics of Assertions. The interpretation of terms, written [[e]]M \n, is straightforward and omitted. The de.ning clauses for the satisfaction relation is stan\u00addard [31] \n(e1 = e2 is interpreted by the identity; connectives are in\u00ad ' terpreted classically [23, 22, 24]), except: \nM |= {C}e e = x{C '}is given following [24] (to wit: if the given environment and any hypothetical state \ntogether satisfy C, then the application of [[e]]M to [[e ']]M converges to a value (named x) and a state \nwhich together satisfy C ); whereas standard and content quanti.cations are inter\u00adpreted as: a '' M \n|= .x.C if M '|= C for each M such that M =x:a M . a '  M |= .x.C if M '|= C for some model M such \nthat M =x:a '  M . M |=[!eRef (a)].C if [[e]]M = [[x]]M and for each V . [[a]]. D we have M [x . V ] \n|= C. M |= (!eRef (a)).C if [[e]]M = [[x]]M and some V . [[a]]. M exists with M [x . V ] |= C. '' Above \nM =x:a M means that M is exactly like M , except that the former has an additional entry for x (in detail: \none new entry for x is added to the environment; if x has a reference type, it may either be adjoined \nto an existing identical or form a new identical for which a new entry is added to the store). M [x . \nV ], with x a reference name in M , is exactly like M except that it stores [V ] at the identical containing \nx. 2.5 Examples of Assertions We illustrate usage of our assertion language through simple exam\u00adples. \nThroughout we assume x,y,z are typed as Ref (Nat), while i, j are typed as Nat, unless otherwise stated. \n1. (dereference) The assertion x = 2 with x typed as Nat, says that a (functional) variable has the value \n2. The assertion !x = 2 says the content of a reference named x is 2. Finally the assertion !!x = 2 with \nx typed as Ref (Ref (Nat)), says that the content of a reference which is itself the content of a reference, \nthe last one named x, is 2. 2. (content quanti.cation, 1) A simple formula using existential content \nquanti.cation is (!x)!x = 3. It is equivalent to T because all it says is that x can possibly store 3, \nwhich is surely true regardless of its current value (just as .i.i = 3 is always true). Dually [!x]!x \n= 3 is equivalent to F since it claims that x stores 3 whatever value x may store, which is impossible \nregardless of the current content of x (just as .i.i = 3 is a contradictory statement). 3. (content \nquanti.cation, 2) Consider (!x)!y = 3. Since if x and y are equal the content of both references are \nhidden, and because !y = 3 is equivalent to (x = y.!x = 3).(x = y.!y = 3), the assertion (!x)!y = 3 is \nequivalent to x = y . (x = y.!y = 3) hence to x = y .!y = 3. Next consider [!x]!y = 3. It says whatever \nnatural number a reference named x may store, the number stored in y is 3. For this to hold, it is suf.cient \nand necessary that x and y name distinct memory cells and that the content of y is 3. Thus the assertion \nis logically equivalent to x = y . !y = 3. In general, the assertion (!e)C claims C holds for the content \nof a reference quali.ed in C if that reference is distinct from e; whereas [!e]C claims C holds and any \nreference whose content is discussed in C is distinct from e.  def 4. (swap, 1) Recall swap = .(x, y).let \nz = !x in (x :=!y; y := z) from the Introduction. The behaviour of this program, named u, can be described \nby the following assertion. .xyi j.{!x = i.!y = j}u (x,y){!x = j.!y = i} (5) Above and henceforth we \nuse an evaluation formula with mul\u00adtiple arguments for readability. 5. (swap, 2) swap above in fact works \nfor a pair of references of an arbitrary type, and is indeed typable as such in polymorphic programming \nlanguages like ML and Haskell. Following [23], we can capture its polymorphic behaviour by adding .X.C \n(and dually .X.C) to the assertion language, with the grammar of types extended with type variables (X, \nY,...) and quanti.ers (.X.a and .X.a). With this extension, we can re.ne (5). Ref (X)Ref (X) .X..x..y..iX \n.. jX . {!x = i.!y = j}u (x,y){!x = j.!y = i} (6) The assertion should be readable naturally. Types \nin assertions are interpreted syntactically, incorporating a map from type variables to closed types \nto the environment part of models [23]. 6. (swap 3) The assertions (5) and (6) may not fully capture \nthe behaviour of swap in that they do not say swap only modi.es the content of references it receives \nas arguments (which can be crucial if we are to use swap as part of a larger program). To capture this \nproperty, we may assert, re.ning (5): Ref (Y) .Y..z..hY ..xyi j. (z=xy . {!x =i . !y = j . !z = h} u \n (x,y) {!x= j . !y = i . !z = h}) (7) Above z = xy stands for z = x.z = y , similarly henceforth. z, \nj are polymorphically typed since we wish to say any refer\u00ad ence of any type except xy are left unmodi.ed. \nThe assertion (7) now captures the whole observable behaviour of (monomor\u00adphic) swap in the sense that \nany program satisfying the asser\u00adtion is observationally congruent to swap under arbitrary dis\u00adtinctions. \nSince (7) is slightly verbose, we may wish to use a shorthand, writing: .xyi j. {!x = i.!y = j}u (x, \ny){!x = j.!y = i} @ xy (8) which formally stands for (7) (note the translation is mechani\u00adcal). The general \nform of this construction is: ' {C}e e = x{C '} @ {e0,e1,..., en-1} (9) where {e0, e1,...,en-1} (usually \nwritten as a sequence, as in (8)) is a .nite set of terms of reference types, called write set, in which \ndereferences should not occur as subterms. The short\u00adhanded form (9) is called located assertion and \nused extensively from now on. 7. (double) Let double? def = .(x,y).(x :=!x+!x ; y :=!y+!y). Obvi\u00adously \ndouble? will double the content of each of its two argu\u00adment only if x and y are distinct. We give a \nlocated assertion for double?, named u. .xyih. {!x = i. !y = j . x = y} u (x, y) {!x = 2 \u00b7 i. !y = 2 \n\u00b7 j} @ xy. (10) This speci.cation doesn t talk about the case x = y. A full def speci.cation of double? \nis given as, with A = !x = i. !y = j: .xyi j. {A}u (x,y){(x = y.!x = 4i) . (x = y.!x = 2i.!y = 2 j)}@xy \n (11) Speci.cation (11) suggests how we may re.ne this program so that it becomes robust w.r.t aliasing. \nLet: def double! = .(x, y).if x = y then x :=!x+!x else x :=!x+!x ; y :=!y+!y. The program now meets \nthe expected speci.cation obtained by deleting x = y from the precondition of (10). The relation\u00adship \nbetween semantics of a program and its speci.cation is clari.ed by observational completeness discussed \nin Section 4.  3. Proof Rules and Axioms 3.1 Judgement and its Validity. A judgement consists of a program \nand a pair of formulae following Hoare [20], augmented with a fresh name called anchor [23, 22, 24], \nwritten {C} MG;.;a :u {C '}. This sequent is used for both validity and provability. If we wish to be \nspeci.c, we pre.x it with either f (for provability) or |= (for validity). In {C} MG;.;a :u {C '}: u \nis the anchor of the judgement, which should not be in dom(G,.) . fv(C); and  C is the pre-condition \nand C ' is the post-condition.  An anchor is used to name the value resulting from M, and spec\u00adi.es \nits behaviour. As in Hoare logic, the distinction between pri\u00admary and auxiliary names plays an important \nrole in our logic. In {C} MG;.;a :u {C '}, the primary names are dom(G, .) .{u}, while the auxiliary \nnames are those free names in C and C ' which are not primary. Henceforth we assume judgements are always \nwell-typed, in the sense that, in {C} MG;.;a :u {C '}, G,., T f C and G,u : a,., T f C ' such that dom(T) \nn (dom(G,.) .{u})= 0/. As a convenient notation, when a = Unit, we write {C}MG;.;a{C '}for {C}MG;.;a \n:u {C '} with u . fv(C '), recovering a Hoare triple [20]. Validity of judgement is given by the following \nclause. De.nition 2 (validity of judgement) We say {C} MG;. :m {C '} is valid, written |= {C} MG;. :m \n{C '}, if, whenever (D, ., s)G' ;.'|= C, we have (M.,s) . (v,s') such that (D,.\u00b7m : v,s') |= C ' , for \neach G' and .' which respectively extend (i.e. are supersets of) G and .. [Var] - [Const] - {C[x/u]} \nx :u {C}{C[c/u]} c :u {C} [In1] {C} M :v {C '[in1(v)/u]} [Proj1] {C} M :m {C '[p1(m)/u]} {C} in1(M) :u \n{C '} {C} p1(M) :u {C '} x x x} M :m {C0 -}{C0[ini(xi)/m]} Mi :u {C ' -} [Case] {C \u00ad {C} case M of {ini(xi).Mi}i.{1,2} \n:u {C '} {C}M1:m1 {C0}{C0}M2:m2 {C '[m1 + m2/u]} [Add] {C}M1 + M2:u {C '} {C . A -x} M :m {C '} [Abs] \n{A} .x.M :u {{C}u x = m {C '}} {C} M :m {C0}{C0} N :n { C1 .{C1} m n = u {C'}} [App] {C} MN :u {C '} \n[If ] {C} M :b {C0}{C0[t/b]} M1:u {C '} {C0[f/b]} M2:u {C '} {C} if M then M1 else M2:u {C '} {C} M1:m1 \n{C0}{C0} M2:m2 {C'[(m1,m2)/u]} [Pair] {C}(M1,M2) :u {C '} [Deref ] {C} M :m {C '[!m/u]} {C} !M :u {C \n'} [Assign] {C} M :m {C0}{C0} N :n {C '{|n/ !m|}} {C} M := N {C '} [Rec] {A -xi .. j .i.B( j)[x/u]} .y.M \n:u {B(i)-x} {A} \u00b5x..y.M :u {.i.B(i)} Figure 1. Main proof rules. The difference from the rules in [24] \nis highlighted. Thus a valid judgement demands termination. By using arbitrary models under arbitrary \nextensions of bases, the validity is robust with respect to arbitrary aliasing and weakening. Total correctness \nwas chosen to facilitate comparison with [24]. It is straightforward to obtain partial correctness: only \nthe recursion rule changes. 3.2 Main Proof Rules. Figure 1 presents the main compositional proof rules. \nThere is one rule for each language construct following its typing. In addition, there are structural \nrules which simply manipulate formulae. Some of the main structure rules are listed in Figure 2. For \neach rule we stipulate: Free i, j,... range over auxiliary names. Further no primary names in the premise(s) \noccur as auxiliary names in the con\u00adclusion (this may be considered as a variant of the bound name convention). \n A,A ' ,B,B ' ,... range over stateless formulae, i.e. those formulae which do not contain active dereferences \n(a dereference !e is active if it does not occur in pre/post conditions of evaluation formulae nor under \nthe scope of content quanti.cation of !e: for example, !x is active in !x = 2 but neither in (!x)(C.!x \n= 2) nor in {!x = 0}u (){!x = 1} ).  Despite the added complexity of models due to aliasing, the only \nessential textual change in the proof rules from the logic for alias\u00adfree imperative higher-order functions \nin [24], is the replacement of syntactic with logical substitution in [Assign] (highlighted), demonstrating \nclean, rigorous strati.cation of logics. Below we discuss two rules for imperative constructs, using \nsimple inferences for illustration. {C0} M :u {C0'} 0 . C ' [Consequence] C . C0 C ' {C} M :u {C '} {A} \nV :u {B} [.-.] {C . A}V :u {C '} [Promote] {A .C} V :u {B .C}{C}V :u {A . C '} [.-.] {C}M :u {A . C '} \n[.-Pre] {C1}M :u {C}{C2}M :u {C} {C . A}M :u {C '} {C1 .C2}M :u {C} [.-Post] {C}M :u {C1}{C}M :u {C2} \n[Aux.] {C -i} M :u {C '} {C}M :u {C1 .C2}{C} M :u {.i.C '} }{C} MG;.;a :m {C '} [Aux.] {C} M :u {C ' \n-i[Invariance] {.i.C} M :u {C '} {C . A} M :m {C '. A} Figure 2. Structural rules. [Deref] infers the \nproperty of !M for an arbitrary program M of a reference type, saying: If we wish to have C ' as a result \nof dereference !M named u starting from the initial state C, we should assume the same thing about M \n(to be evaluated into a reference) named x, substituting !x foruinC. A simple example of using [Deref] \nfollows. {T} x :z {z = x} (Var, Conseq) {T} .x.x :m {.x.{T}m x = z{z = x}} (Abs, Aux.) {.x.{T}m x = \nz{z = x}} y :n {n = y .{T}m n = z{z = y}} {T} (.x.x)y :z {!z =!y} (App, Conseq) {T} !((.x.x)y) :u {u \n=!y} (Deref)  In the second line we use a structural rule [Aux.]. The third and fourth lines use standard \nequality laws (e.g. z=y .!z=!y). The rule [Assign] treats assignment of an arbitrary expression (of type \na) to an arbitrary expression (of type Ref (a)), both possi\u00adbly inducing side effects. It reads: If the \nresult after executing M := N should satisfy C ' starting from C, then, starting from the same state \nC, M named m should terminate to reach some C0, and, in turn, N named n evaluates from C0 to reach C \n' , with its occurrences of n substituted for !m. Note the rule assumes the left-right evaluation order \n(the rule which assumes the right-left evaluation order, or no order at all, can be easily formulated). \nThe next example starts from Line 4 in the previous inference. 1. {T} (.x.x)y :m {m = y} above 2. {m \n= y . 1 = 1} 1:n {m = y . n = 1} (Const) 3. (m = y . n = 1) . (!y = 1){|n/!m|} (*) 4. {m = y . 1 = 1} \n1:n {(!y = 1){|n/!m|}} (2, 3, Conseq) 5. {T} (.x.x)y := 1{!y = 1} (1, 4, Assign)  Line 3, which involves \nsemantic update, is derived later. The case with side effects can be reasoned similarly. [Assign] treats \nthe most general form of assignment. From this rule, we can derive specialised assignment rules which \noffer more ef.cient reasoning. For example, if both sides of the assignment are simultaneously both logical \nterms and programs, we have the following simpli.ed rule. [AssignS] {C{|e2/!e1|}} e1:= e2 {C} {C . A \n-x} M :m {C '}@ e [Abs] {A} .x.M :u {{C}u x= m{C '}@ e}@0/ [App] {C}M :m {C0}@ e {C0}N :n {C1 .{C1}m \n n = u{C '}@ e2}@ e1 {C} MN :u {C '}@ ee 1e 2 e [Deref ] {C} M :m {C '[!m/u]}@ {C} !M :u {C '}@ e ' e1 \n{C0} N :n {C '{|n/!m|}}@ e2 C0 . m = e[Assign] {C} M :m {C0}@ ' {C} M := N {C '}@ e1e 2e eC0 ! e-free \ne [Invariance] {C} M :u {C '}@ [Weak] {C} M :m {C '}@ ' {C . C0} M :u {C '.C0}@ e {C} M :m {C '}@ ee \n{C1} M {C1'}@ e1 {C2} N {C2'}@ e2 [SeqI] {C1 . [! e1]C2} M; N {(! e2)C1 '. C2'}@ e1e 2 ' '' = i} M :m \n{C '.!e = i}@ ee i fresh [Thinning] {C.!e {C} M :m {C '}@ e Figure 3. Derived proof rules for located \nassertions (other rules directly follow Fig.1 and 2). The rule is directly derivable from [Assign] and \n{C[e/u]}e :u {C}(which is also derivable). 3.3 Structured Reasoning for Programs with Aliasing. One \nof the central problems in large-scale software development is to prevent inadvertent interference between \nprograms through shared variables, especially in the presence of aliasing. The located assertions in \n\u00a72.5 address this concern by delineating part of the store a program may affect. Below we extend this \nidea to judge\u00adments. def {C}M :u {C '}@ e ={C .y = e .!y = i}M :u {C '. y = e .!y = i} where y and i \nare fresh and distinct (to be precise, y and i are respectively typed as Ref (X) andXforafreshX)and e \nis a write set as for located assertions, cf. \u00a72.5 (6). For example {!x = i} x := !x +1 {!x = i +1}@x \nsays the command increments the content of x and does nothing else. Valid located judgements are derivable \nby the proof rules for non-located judgements by translating located judgements to non\u00adlocated ones. \nA more ef.cient method is to use compositional proof rules which are derivable in the original system \nbut which are tailored for located judgements, the main ones of which are listed in Figure 3. The initial \nfour rules should be naturally read (note [Assign] demands the assigned reference to be among a write \neffect, while [Deref] does not have such a condition). In [Invariance], we say C is !e-free when [!e]C \n= C. Since !e-freedom of C is (up to =) equivalent to C having the shape [!e]C ' or (!e)C ' for some \nC ', the rule is in fact equipotent to each one of the following rules: {C} M :u {C '}@ e [InvUniv] {C \n. [! e]C0} M :u {C '. [! e]C0}@ e {C} M :u {C '}@ e [InvExist] {C .(! e)C0} M :u {C '.(! e)C0}@ e [Invariance] \nand its variants improve the standard invariance rules in Hoare logics in that they need no extra-logical \nside condition (which says M does not modify variables in C0 ). The next rule [SeqI] ( I for independent) \nis directly derivable from [InvUniv], [InvExist] and the standard sequencing rule. The rule looks lop\u00adsided, \nbut its meaning is operationally transparent: Assume (1) {C1}M1{C1'}@ e1 and (2) {C2}M2{C2'}@ e2. Suppose \nC1 and C2 initially hold, the latter regardless of the content of e 1. Let .rst M1 run: then by (1), \nC 1 ' holds. Since M1 only modi.es e 1,C2 still holds, so that if M2 runs next, we reach C 2 ' by (2). \nThis next run only modi.es e 2, hence if C1 ' does not talk about e 2, then it should continue to hold \nin the .nal state. The rule directly infers a judgement for a sequenced pair of pro\u00adgrams from independent \njudgements for the component programs. Here we show a very simple usage of this rule. 1 {T} x := 2 {!x \n= 2}@x (AssignS) 2 {T} y :=!z {!y = !z}@y (AssignS) 3 {T} x := 2; y :=!z {(!y)!x = 2 . !y =!z}@xy (SeqI) \nNote (!y)!x = 2 is equivalent to x = y .!x = 2. We used the following located version of (AssignS): [AssignS] \n{C{|e2/!e1|}} e1:= e2 {C}@ e (C . e1 . e ) Finally, [Weakening] is easily understood, while [Thinning] \nrecov\u00aders extensionality (for example the judgement {T} x :=!x {T}@0/ becomes derivable). 3.4 Laws of \nContent Quanti.cation Content quanti.cation is introduced because aliasing cuts off the unique bond between \na reference name and its content. Hence (hypothetical) properties of content need to be described indepen\u00addently \nfrom names. For veri.cation, content quanti.cation offers tractable reasoning on aliased references through \nsuccinct logical laws. These laws are deduced starting from axioms and applying in\u00adference rules in the \nstandard way [31]. The axiom system includes the standard axioms and rules of .rst-order logic with equality \n[31, \u00a72.8], formal number theory, as well as axioms for evaluation for\u00admulae, data types and content \nquanti.cation. Here we focus on con\u00adtent quanti.cation (other proper axioms follow our previous work \n[24], as detailed in [2, \u00a76.3/6.4]). Axioms for [!x] and (!x) may be given following either those of \nstandard quanti.ers [31, \u00a72.3] or those of modal operators [6]. Here we take the former approach, which \nis more concise. First we regard (!x)C as standing for \u00ac[!x](\u00acC). Then there are three axioms. (CA1) \n[!x](C-!x . C2) . (C1 . [!x]C2) 1 (CA2) [!x]C . C (CA3) [!x](!x = m . C) =(!x)(C.!x = m) In (CA1), C-!x \nindicates C is syntactically !x-free. We generate the set of syntactically !x-free formulae, S-!x by: \n(1) [!x]C . S-!x; and V (2) C . i ei = x . S-!x where {ei} exhaust all active dereferences (cf.\u00a73.2) \nin C; (3) the result of applying any logical connective (including negation) or standard/content quanti.er \nexcept .x, .x -!x to formulae in S-!x is again in S. (CA1) corresponds to familiar .x.(C1 .C2) . (C1 \n..x.C2) with x . fv(C1). (CA2) is a degenerate form of .x.C . C[e/x]. (CA3) says two ways to represent \nlogical substitutions coincide, which is important to recover all properties of semantic update as studied \nin [7, 9, 10, 33], as discussed in the next section. Finally, to the rules of inference, we add the following \nanalogue of standard generalisation. (CGen) C . [!x]C In a deduction with non-trivial assumptions, we \ndemand assump\u00adtions to be syntactically !x-free if the deduction uses (CGen) for !x. By the standard \nargument, we obtain the deduction theorem [31, \u00a72.4]. Let us list some of the useful laws (focussing \non existentials for our later convenience), all deducible from the axiom system. (L1) C .(!x)C (L2) (!x)(!x)C \n.(!x)C (L3) (!x)!x = e (L4) .m.(!x)C =(!x).m.C (m = x) (L5) (!x)(C1 .C2) =(!x)C1 .(!x)C2 (L6) [!x]C1 \n.(!x)C2 .(!x)(C1 .C2) (L7) (!x)(C1 .C2) = C1 .(!x)C2(C1!x-free) (L8) if C = C-!x then C is x-free. 0 \nAll are analogues of the well-known laws for existential quan\u00adti.ers and the May modality. (L7) implies \n(C1 . C2){|e/!x|} = C1 . (C2{|e/!x|}) when C1 is!x-free, suggesting the use of content quanti.cation \nfor realising the following locality principle which has been missing so far (a similar point is observed \nby Bornat [7], after his extensive exploration of logical calculations involving se\u00admantic update using \nMorris s method): If part of a formula does not concern the content of x, then an update (substitution) \nat x by some value should not affect that part. As a simple application of these laws, we derive C{|c/!x|}{|e/!x|} \n= defC{|c/!x|} mentioned in the Introduction. Let C ' = C{|c/!x|} and m be fresh. Writing (fol) indicates \nthe use of .rst-order logic with equality [31, \u00a72.8]. .m.((!x)(C '.!x = m) . m = e) =.m.(C '.(!x)(!x \n= m) . m = e) (L8, L7) = C '..m.(!x)(!x = m . m = e) (fol, L8) = C '.(!x).m.(!x = m . m = e) (L4) = C \n'.(!x)!x = e (fol) = C ' (L3, fol) Note the inference never touches C ' (as it should not). As another \nexample, we infer (*), Line 3, from the inference in Page 9. (m =y . n=1) = [!m](m= y . n =1) (L8) = \n[!m](m= y . n =1) .(!m)!m= n (L3) .(!m)(m=y . n= 1.!m=n) (L6) . (!y = 1){|n/!m|}. (fol) As noted in the \nIntroduction, the proposed framework effectively subsumes the known calculation methods based on semantic \nup\u00addate, which are often useful. Below we list simple ones (all are easily justi.able by the laws given \nabove). Some others are also discussed in the next section. Below, in (S1-a) (resp. (S1-b)), we ' assume \ne1 (resp. e) and e do not contain dereferences. (S0) C{|e ' /!e|} = C, assuming C is !e-free. ' = !e2)) \nor, as its special instance: (S1-a) (e ' =!e1){|e '' /!e2|} = ((e1 = e2 . e ' = e '') . (e1 = e2 . e \n'' (S1-b) (e ' =!e){|e '' /!e|} = e ' = e .  4. Technical Results This section records key theoretical \nproperties of the logic, starting with soundness. Theorem 1 (soundness for the proof rules) If f{C} M \n:u {C '} then we have |= {C} M :u {C '}. PROOF: We show [Deref ,Assign]. Write (M.,s) .m (.\u00b7m : v,s') \nfor (M., s) . (v,s'). For [Deref ]: (., s) |= C . (M., s) .m (.\u00b7m:i, s') |= C'[!m/u] . ((!M)., s) .u \n(.\u00b7u:s'(i), s') |= C' For [Assign] we reason, with .0 = . \u00b7 m : i: (., s) |= C . (M., s) .m (.\u00b7m:i, s0) \n|= C0 . (N.0, s0) .n (.0 \u00b7n: w, s') |= C'{|n/!m|} . ((M := N)., s) .u (.0 \u00b7u: (), s'[i . w]) |= C' The \nlast line is by the logical equivalence between M |=C '{|n/!m|} and M [ [[m]]M . [[n]]M ] |= C ', which \nis immediate. See [24, \u00a75.5] and [2, \u00a78.1] for other cases. D Proposition 1 (soundness of the axioms) \n(1) (CA1 3) in \u00a7 3.4 are valid. (2) (CGen) is sound in the sense that if C is valid then so is [!x]C. \nFor the proofs, see [2, \u00a78.1]. Since proof rules in Figure 3 are derivable by those in Figures 1 and \n2 (as well as Kleymann s strengthened consequence rule for (Thinning) [27]), we also know: Corollary \n1 If f{C} M :u {C '} @ e by the rules in Figure 3, then |= {C} M :u {C '} @ e. 4.1 Elimination of Content \nQuanti.cation. We show any formula containing content quanti.cation can be transformed into a formula \nwithout them, up to logical equivalence. This is closely related with the decomposition result in [10]. \nIn the course of the proof, we also establish mutual representability between content quanti.cation and \nCartwright-Oppen/Morris s se\u00admantic update. Proposition 2 1. We have [!e]C =.m.C{|m/!e|} with m be fresh. \nDually, (!e)C =.m.C{|m/!e|}. 2. (following [10]) Let * . {.,., .}, Q . {.,.} and z .{x,y}. (C1 *C2){|y/!x|} \n= C1{|y/!x|} *C2{|y/!x|} (\u00acC){|y/!x|} = \u00ac(C{|y/!x|}) (Q z.C){|y/!x|} = Q z.(C{|y/!x|}) C-!x C-!x{|y/!x|} \n= {C}e e ' = x{C '}{|y/!x|} = .uv.({C}u v = w{C '}. (u = e . v = e '){|y/!x|}) 3. If C has no content \nquanti.cation we can rewrite C up to = as .r r has no active c.((.ici =!ri) .C '), where c are fresh \nand C ' dereference. PROOF: Mechanical using the axioms, see [2, \u00a75.4]. D Proposition 2 (1, 2), which \ndepend on (CA3) in \u00a73.4, establish a direct connection between content quanti.cation and semantic up\u00addate, \nallowing us to restore the latter s reasoning methods from [10, 9, 33]. Now transform (!u = z){|m/!x|} \ninto: (!x)(!u = z.!x = m) (with m fresh) which is equivalent to (x = u.m = z).(x = u.!u = z). Write [[(!u \n= z){|m/!x|}]] for the formula on the right. Using Proposition 2, (!x)C =.m.(.r c .((.i[[(!ri = ci){|m/!x|}]]) \n.C ')) with C ' without content quanti.cation and m etc. fresh. Performing this transformation repeatedly, \nwe obtain: Theorem 2 (elimination) For each C, there exists C ' s.t. C = C ' and no content quanti.cation \noccurs in C ' . 4.2 Observational Completeness A central property of our logic is its precise correspondence \nwith the observational congruence, in the sense that two programs are contextually equivalent iff they \nsatisfy the same set of assertions. This offers foundations of modular software engineering, where re\u00adplacement \nof one module with another with the same speci.cation does not violate the observable behaviour of the \nwhole software, up to the latter s global speci.cation. For the proof we extend the method we used in \n[24], which we now outline. We .rst de.ne a subset of programs which represent a limited class of behaviours, \ncalled .nite canonical forms (FCFs, ' ranged over by F,F ,...), whose construction comes from game semantics \n[3]. Now let us say (C,C ') is a characteristic assertion pair (or a CAP) of F at u when F is the least \nbehaviour w.r.t. c s.t. |= {C}M :u {C '}, where c is the preorder counterpart of ~ =. We then derive \nCAPs for FCFs by introducing tailored proof rules which re.ne those in [24] with located judgements (cf. \nFigure 3). For writing down CAPs and constructing proof rules, we need a small extension of terms in \nour assertion language which stands for vectors of variable. Once we know there are CAPs for all FCFs, \nwe can translate discernibility of .nite contexts, hence FCFs, into the latter s CAPs, hence we know \nany discerning .nite contexts can be represented by logical assertions, concluding the proof. Following \n[24] we work with total correctness assertions (TCAs) which rep\u00adresent properties closed upwards w.r.t. \nc, which is enough (see [2, \u00a78.3] for details). Writing fchar {C} F :u {C '} when {C} F :u {C '}is provable \nwith the derived rules, we obtain: Proposition 3 If fchar {C} F :u {C '}, then (C,C ') isaCAPofF at u. \nSuch (C,C ') gives the most general formula for total correctness in the sense of [4], so that we observe: \nCorollary 2 (relative completeness for FCFs) If |= {C}F :u {C '}such that (C,C ') are TCAs, then f{C}F \n:u {C '}. We conjecture that Corollary 2 extends to general programs by ~ a similar argument. Now write \nG;. f M1 =L M2: a whenever: |= {C}MG;.;a :u {C '} iff |= {C}MG;.;a :u {C '}. We conclude: 1 2 ~ Theorem \n3 (observational completeness) G; . f M1 = M2: a iff ~ G;. f M1 =L M2: a. PROOF: Only if is direct from \nthe de.nitions. For if suppose ~~ M1 =L M2 but M1 = M2. By abstraction, we assume M1,2 are semi\u00adclosed. \nBy construction there is semi-closed FCF F and F ' such that (FM1,r . F ') . and (FM2,r . F ') .. By \nProposition 3, there are assertions which characterise F and F '. Let such formula for F def ' at f be \nwritten [[F]]( f ). With A = [[F]]( f ) . (.i[[Fi ]](!ri)) we now reason: ' (FM1, r . F ') .. f :[F]\u00b7m \n:[M1] |= {.i[[Fi ]](!ri)} f m = z {T} . |= {T} M1:m {. f .{A} f m = z {T}}~ But |= {T} M2:m {. f .{A} \nf m = z{T}}, that is M1 =L M2. D  5. Reasoning Examples This section illustrates the use of our logic \nfor verifying correctness of programs, starting from simple examples and .nishing with highlights from \nthe derivation for a higher-order generic Quicksort [26], extracted from the full derivation in [2, \u00a79]. \nAlong the way we also show how easily our logic can accommodate generalisations in type structures. Throughout \nwe use the rules for the located assertions from Figure 3. 5.1 Double and Swap Double We begin with reasoning \nabout double? from \u00a7 2.5 (6), which exhibits different behaviour under different distinctions. We derive \nthe speci.cation (10). The key point is a use of [SeqI] in Figure 3 for a short inference, focussing \non the extensional property def of each part, setting A = x =y . !x =i . !y= j. {!x =i} x :=!x+!x {!x=2i}@x \n{!y= j} y := !y+!y {!y=2 j}@y {!x =i . [!x]!y = j} x := !x+!x ; y := !y+!y {(!y)!x =2i . !y=2 j}@xy {A} \nx := !x+!x ; y := !y+!y {x=y . (!x =2i. !y = 2 j)}@xy {A} x := !x+!x ; y := !y+!y {!x =2i . !y=2 j}@xy \n {T}double?:u {.x, y. {A}u (x,y){!x=2i.!x=2 j}@ xy }@0/ where the .rst two lines are instantly derivable \nby (S1-b) in \u00a73.4 and (AssignS), the third uses (SeqI), the next (Consequence), then (.-.) and the last \n(Abs, Aux.). Swap: Located Reasoning The swap procedure is a classical example for reasoning about aliased \nprograms [10, 9, 12]. We can either use [SeqI] as done for double? above, or use the traditional decomposition \nmethod via our result in \u00a74.1. Next we verify that swap satis.es (8), \u00a7 2.5. We start with extensional \nreasoning for def the two assignments and combine them using [SeqI]. Let A = x = y . i = j. {!y = j} \nx :=!y {!x = j}@x (AssignS) {z = i} y := z {!y = i}@y (AssignS) {!y = j . [!x]z = i} x :=!y ; y := z \n{(!y)!x = j . !y = i}@xy (SeqI) {!x = i.!y = j . z = i} x :=!y ; y := z (Conseq) {(x = y .!x = j) . !y \n= i}@xy {A.!x = i.!y = j . z = i} x :=!y ; y := z (Invariance) {A . (x = y .!x = j) . !y = i}@xy {!x \n= i.!y = j . z = i} x :=!y ; y := z {x = j . y = i}@xy (Conseq) {!x = i.!y = j} !x :z {!x = i.!y = j \n. z = i}@0/ (Deref) {!x = i.!y = j}let z =!x in (x :=!y ; y := z) (Let) {!x = j.!y = i}@xy {T} swap :u \n{Swapu}@0/ (Abs) In the .fth line, A is stateless. In the sixth line, we used !x = i.!y = j entails A. \nThe rest is immediate. We can further universally abstract the program, using [TAbst] (which appears \nat the end of \u00a75.3). Swap: Reasoning by Traditional Method For comparison, we now show reasoning based \non the traditional method. {(!x = j.!y = i){|z/!y|}{|!y/!x|}} x :=!y (AssignS) {(!x = j.!y = i){|z/!y|}}@x \n{(!x = j.!y = i){|z/!y|}} y := z {!x = j.!y = i}@y (AssignS) {(!x = j.!y = i){|z/!y|}{|!y/!x|}} x :=!y \n; y := z (Seq) {!x = j.!y = i}@xy (!x = i.!y = j . z = i) . (!x = j.!y = i){|z/!y|}{|!y/!x|} (***) {!x \n= i.!y = j . z = i} x :=!y ; y := z {!x = j.!y = i}@ xy (Conseq) {!x = i.!y = j} !x :z {!x = i.!y = j \n. z = i}@0/ (Deref) {!x = i.!y = j}let z =!x in (x :=!y ; y := z) (Let) {!x = j.!y = i}@xy {T} swap :u \n{Swapu} (Abs) In the sixth line we used the following derived rule, using the def encoding let x = M \nin N =(.x.N)M. {C} M :x {C0}@ e {C0} N :u {C '}@e ' [Let] {C} let x = M in N :u {C '}@ ee ' Except for \nthe fourth line, all inferences are direct from the proof rules. Below we derive (***), starting from \nthe consequence and reaching the antecedent. (!x = j.!y = i){|z/!y|}{|!y/!x|} = (!x = j){|z/!y|}{|!y/!x|}. \n(!y = i){|z/!y|}{|!y/!x|} (Pro.2 (2)) = ((x = y . z = j) . (x = y .!x = j)){|!y/!x|} . (z = i){|!y/!x|} \n(S1) = (x = y . z = j){|!y/!x|} . (x = y .!x = j){|!y/!x|} . (z = i){|!y/!x|} (Pro.2 (2)) = (x = y . \nz = j) . (x = y . (!x = j{|!y/!x|})) . z = i (L7) = (x = y . z = j) . (x = y .!y = j) . z = i (S1) . \n!x = i . !y = j . z = i (fol) While the traditional reasoning gives a shorter compositional rea\u00adsoning, \nit involves non-trivial inferences at the assertion level. This is because the traditional method (or \nthe separation-based method a la Burstall) cannot exploit semantic independence between two assignments, \nwhich [SeqI] can capture. 5.2 Circular References Next we consider x :=!!x, an example of a circular \ndata structure. Typing this program requires recursive types, which we outline .rst. Taking the equi-isomorphic \napproach [35] where recursively de.ned types are equated iff their representation as regular trees are \nisomorphic, the grammar of types is extended as follows, for both the programming language and for the \nassertion language. a ::= ... | X | \u00b5X.a The typing rules do not change except for taking types up to \ntree isomorphism. Accordingly no change is needed in the axioms and proof rules. We wish to prove the \nfollowing judgement. {!x = y.!y = x} x :=!!x {!x = x}@ x For the proof we start by converting the pre-condition \ninto a form that is usable by [AssignS]. (!x = y . !y = x) .!!x = x = (!x = x)[!!x/!x] = (!x = x){|!!x/!x|} \n(**) Given (**), the inference is immediate: 1. {(!x = x){|!!x/!x|}} x :=!!x {!x = x} (AssignS) 2. {!x \n= y. !y = x} x :=!!x {!x = x} (1, (**), Conseq) Similarly we can easily derive {!y = x} x :=(1,inr(!y)) \n{!x =(1,inr(x))} @ x where x is typed with \u00b5X.Ref ((Nat \u00d7 (Unit + X))), the type of a mutable list of \nnatural numbers (one may also use the null pointer as a terminator of a list). The assertion !x =(1,inr(x)) \nsays x stores a pair of 1 and the right injection of a reference to itself, precisely capturing graphical \nstructure of the datum. We can also assert and reason about stored procedures including programs with \nLandin s recursion (e.g. x := .z.if z = 0 then 1 else z \u00d7 (!x)(z - 1), after whose run (!x)n computes \nn s factorial), see [24] for details. 5.3 A Polymorphic, Higher-Order Procedure: Quicksort Hoare s Quicksort \nis an ef.cient algorithm for sorting arrays using recursion. Apart from recursive calls to itself, Quicksort \ncalls Parti\u00adtion, a procedure which permutes elements of an array so that they are divided into two contiguous \nparts, the left containing elements less than a pivot value pv and the right those greater than pv. The \npivot value pv is one of the array elements which may ideally be their mean value. In the following we \nspecify and derive a full speci.cation of one instance of the algorithm, directly taken from its well-known \nC version [26, \u00a75.1.1]. First we present the code, assuming a generic swapping procedure from \u00a72.5 (4-6). \nWe use indentation for scoping. def def quicksort = par = \u00b5q. .(a,c, l,r). .(a,c, l,r) if l < r then \nlet pv =!a[r] in ' let p = par(a,c,l,r) in p := l;i := l; q(a,c,l, p '- 1); while !i < r q(a,c, p ' \n+ 1,r) if c(!a[!i], pv) then swap(a[!p],a[!i]); p :=!p + 1; i :=!i + 1; swap(a[r],a[!p]);!p In these \nprograms we omit type annotations for variables, the main ones of which (for both programs) are: a :X[], \nc : (X \u00d7 X) .Bool, l,r : Nat X[] is the type of a generic array, see below. Quicksort itself has the \nfunction type from the product of these types to Unit. Partition is the same except that it return type \nis Nat. This program exhibits several features which are interesting from the viewpoint of capturing \nand verifying behavioural prop\u00aderties using the present logic. Its correctness crucially relies on the \nextensional behaviour of each part: when recursively calling itself twice in the last two lines of the \nQuicksort code, it is essential that each call modi.es only the local subarray it is working with, without \nany overlap. We shall show how this aspect is transparently re.ected in the structures of assertions \nand reasoning, realising what O Hearn and Reynolds called local reasoning [34, 37] through the use of \nlogical primitives of general nature rather than those introduced for that speci.c purpose.  The program \nmakes essential use of a higher-order procedure, receiving as its argument a comparison procedure which \nis used for permuting elements.  The program is fully polymorphic, in the sense that it can sort an \narray of any type (as far as a proper comparison procedure is provided).  In the following we shall \ndiscuss how these aspects can be treated in the present logic. Even including a recent formal veri.cation \nof Quicksort in Coq [13], we believe a rigorous veri.cation of Quicksort s extensional behaviour with \nhigher-order procedures and polymorphism is given here for the .rst time. Preparation: Arrays We .rst \nintroduce arrays, both for pro\u00adgrams and assertions. The presentation may offer basic ideas on how a \nnew data type can be systematically incorporated in the pre\u00adsented logic. We add: G f M : a[] G f N : \nNat (types) a ::= ... | a[] [Array] G f M[N] : Ref (a) (programs) M ::= ... | M[N] (Terms) e ::= ... \n| e[e '] | size(e) An array consists of a sequence of references: selecting an entry will return the \ncorresponding reference which can then be derefer\u00adenced (we can equally treat less analytical presentation). \nIn models an array is regarded as a .nite partial injection from Nat to refer\u00adences. Any data type is \nequipped with axioms characterising its be\u00adhaviour. The main ones for arrays are: Each array of size \nn is made up of n distinct references: .i, j. ( 0 = i, j .size(x) . i = j . x[i]= x[ j]) Two arrays are \nequal iff their size and component references coin\u00adcide. (size(x)= size(y) ..i. ( 0 = i < size(x) - 1 \n. x[i]= y[i] )) . x = y Two distinct arrays never overlap (not applicable in some lan\u00adguages). x = y \n..i, j. ( 0 = i < size(x) - 1 . 0 = j < size(y) - 1 . x[i]= y[ j]) We also need proof rules for arrays, \none introduction rule for array identi.ers and one elimination rule for indexing. Since the former is \ncommon to all variables, we only add the latter. {C}M :m {C0}@ e {C0}N :n {C'[m[n]/u]}@e ' C '[m[n]/u] \n. 0=n < size(m)[Array] {C} M[N] :u {C '} @ ee ' The rightmost premise prevents out-of-bound errors (treatment \nof errors is further discussed in [2]). Speci.cation We now present a full speci.cation of Quicksort \n(For simplicity, par and swap are assumed inlined: treating them as external procedures is straightforward). \n{T} qsort :u {.X.Qsortu}@0/ . where we set, omitting types, Qsortu is the predicate (12) .abclr. . .{Equal(ablr).Order(c)}u \n (a,c,l,r) {Perm(ablr).Sorted(aclr)}@a[l...r]ip . . (13) Here a[l...r]ip is short for a[l],...,a[r],i, \np. The variable b is auxil\u00adiary and is of the same array type as a, denoting the initial copy of a, so \nthat we can specify the change of a in the post-condition is only in the ordering of its elements. Each \npredicate used in (13) has the following meaning. For the precondition: Equal(ablr) says: distinct arrays \na and b coincide in their content in the range from l to r (with l and r being in the array bound). In \naddition, it also stipulates freshness and distinctness of variables p and i.  Order(c) says: c calculates \na total order without side effects. Formally, it is the conjunction of:  1. .xy. (c (x,y)= T . c (x, \ny)= F). In this assertion c (x,y)=e stands for {T}c (x,y)= z{z = e}@0/ ( the comparison terminates and \nhas no side effects ); 2. .xy.(x = y . (c (x,y)= T.c (y,x)= T)) ( two distinct elements are always ordered \n); and 3. (c (x, y)= T.c (y,z)= T) . c (x,z)= T ( the ordering is transitive ).  The use of this predicate \ninstead of (say) a boolean condition embodies the higher-order nature of Quicksort. For the post-condition: \n Perm(ablr) says: entries of a and b in the range from l to r are permutations of each other in content. \nIt also stipulates the same distinctness condition as Equal(ablr).  Sorted(alrc) says: the content of \na in the range from l to r  are sorted w.r.t. the total order implemented by c. Formally: def Sorted(aclr) \n=.i, j.(l = i < j = r . c (!a[i],!a[ j]) = T). So Qsortu in (13) as a whole says: Initially we assume \ntwo distinct arrays, a and b, of the same content from l to r (Equal(ablr)), together with a procedure \nwhich realises a total order (Order(c)). After the program runs, one array remains unchanged (because \nthe assertion says it touches only a), and this changed array is such that it is the permutation of the \noriginal one (Perm(ablr)) and that it is well-sorted w.r.t. c (Sorted(aclr)). Located assertions play \na fundamental role in this speci.cation: for example, it is crucial to be able to assert c has no unwanted \nside effects. In the rest of this section, we present highlights from a full derivation of the judgement \n(12) recorded in [2, \u00a79]. Reasoning (1): Sorting Disjoint Subarrays First we focus on the last two lines \nof quicksort which sort subarrays by recur\u00adsive calls. The reasoning demonstrate how the use of our re.ned \ninvariance rule offers quick inference by combining two local, ex\u00adtensional speci.cations. Concretely \nour aim is to establish: {C1} q(a,c,l, p '- 1) ; q(a,c, p ' + 1,r) {C1'}@a[l...r]ip (14) where def Perm(ablr) \n. Parted(aclrp') . Order(c) . C1 = . j < k.QsortBounded(qj) . r - l =k def C ' = Perm(ablr) . Sorted(aclr). \n1 Two newly introduced predicates are illustrated below. QsortBounded(qj) with j of Nat type is used \nas an inductive hypothesis for recursion. It is the same as Qsortq, given in (13), Page 10, except that \nit only works for a range no more than j and that it replaces Equal(ablr) in the precondition of (13) \nwith Perm(ablr) , which is necessary for the induction to go through. Parted(aclrk) says the subarray \nof a from l to r is partitioned at an intermediate index k w.r.t. the order de.ned by c. Formally it \nis given as: l =k =r .. j.(l = j =k . c (!a[ j],!a[k]) = T) .. j.(k = j =r . c (!a[k], !a[ j])=T) A \nkey feature of these two recursive calls is that neither modi\u00ad.es/depends on subarrays written by the \nother. As mentioned al\u00adready, this feature allows us to localise reasoning: the speci.ca\u00adtion and deduction \nof each part has only to mention local informa\u00adtion it is concerned with. Joining the resulting two speci.cations \nis then transparent through the invariance rule and basic laws of con\u00ad def def tent quanti.cation. Let \ne2 = a[l..p '- 1]pi and e3 = a[p ' + 1..r]pi (which are the parts touched by the .rst/second calls, respectively). \nWe now derive: R.1. {C2} q(l, p '- 1) {C2'} @ e2 R.2. {C3} q(p ' + 1,r) {C3'} @ e3 R.3. {C2 . [! e2]C3} \nq(l,p '- 1) ; q(p ' + 1,r) {(! e3)C'. C3'}@ e2e 3 2 R.4. C1 ..b ' .(([! e3]C2 . C2 . [! e2e 3](C2 ' \n.(! e2)C '. C1' ))) 3 R.5. {C1} q(l, p '- 1) ; q(p ' + 1,r) {C1'}@ e2e 3 (Conseq-Aux) Line (R.3) uses \n(R.1-2, SeqI), the .rst two (AppS). The derivation uses the following abbreviations. def C2 = Equal(ab \n' l(p '- 1)) . Order(c) .. j <k.QsortBounded(qj) . p '- 1 - l < k def C2 ' = Perm(ab ' l(p '- 1)) . Sorted(acl(p \n'- 1)) def ' C3 = Equal(ab '(p +1)r) . Order(c) .. j <k.QsortBounded(qj) . ' r-(p +1) < k def C ' = Perm(ab \n'(p ' + 1)r) . Sorted(ac(p ' + 1)r) 3 Note each of C2/C2 ' and C3/C3 ' mentions only the local subarray \neach call works with. The auxiliary variable b ' serves as a fresh copy of a immediately before these \ncalls (we cannot use b since, e.g. Perm(abl(p '- 1)) does not hold). (R.1 3) are asserted and reasoned \nusing b ', which (R.4) mediates into the judgement on b, so that (R.5) only mentions b. The inference \nuses the following derived rules (the .rst one is due to Kleymann). 0}@ eC .. j .(C0[ j /i ] . [! e](C0' \n[ j /i ] . C ')) [Conseq-Aux] {C0} M :u {C ' {C} M :u {C '}@ e =u{C '}@ e[AppS] C .{C}e (e1..en) {C} \ne(e1...en) :u {C '}@ e Using these rules and [SeqI], (R.1/2/3/5) are immediate. The re\u00admaining step is \nthe derivation of (R.4), the condition for [Conseq-Aux]. For this, the .rst step is to see: (Dist . !a[p \n']=!b '[p '] . Perm(bb ' lr) . Parted(bclrp ')) . ((C2 '. C3' ) . C1' ) (15) is valid, which is elementary \n(Dist says a and b ' are distinct and do not overlap with p and i). Then by (CGen) (cf. \u00a73.4) we can \nuniver\u00adsally content quantify ! e2e 3 over (15). By Dist, the antecedent of (15) is ! e2e 3-robust, hence \nwe can apply (CA1) (cf. \u00a73.4) to reach (R.4). Reasoning (2): Using Comparison Next we focus on the use \nof a comparison procedure in the while loop in Partition, which is originally passed to Partition as \nan argument. We start with the loop invariant. .. Cpre def . l =!p, !i = r . Leq(acl(!p - 1)pv) part \n.. Invar =. Geq(ac(!p0)(!i - 1)pv) . (!p <!i . c (!a[!p], pv)= T) Leq(aclrv) (resp. Geq(aclrv)) says \nthe entries from l to r in a are smaller (resp. bigger) than v. When inside the loop, the values of p \nand i differ from the invariant slightly, so that we also make use def of: Cinloop = Invar.!i < r . r-!i \n= j. The following assertions specify two cases of the conditional branch. def def Cthen = Cinloop .c \n(!a[!i], pv)= T C\u00acthen = Cinloop .c (!a[!i], pv)= F. We now present the derivation for the if sentence \nof the loop, where the comparison procedure received as an an argument is used at the conditional branch. \nBelow we assume the conditional body ( ifbody ) has been veri.ed already and let j to be a freshly chosen \nvariable of Nat-type. .. {Invar . r-!i >0} (Invar . r-!i > 0) . .c (!a[!i], pv)= z . {c (!a[!i], pv)= \nz . Invar . r-!i>0}@0/ {Invar . r-!i > 0} c(!a[!i], pv) :z (AppSimple) {c (!a[!i], pv)= z . Invar . \nr-!i > 0}@0/ {Cthen} ifbody {Invar{|!i + 1/!i|}. r-!i = j)}@a[l...r - 1]ip (omitted) C\u00acthen . (Invar{|!i \n+ 1/!i|}. r-!i = j) {Cinloop}if c(!a[!i], pv) then ifbody (IfThen) {Invar{|!i + 1/!i|}. r-!i = j)}@a[l...r \n- 1]pi Thus reasoning about a conditional branch which involves a call to a received procedure is no \nmore dif.cult than treating .rst-order expressions. Above we used the following simpli.cation of [If \n]. {C} M :m {C0}@ e {C0[T/m]} N {C '}@e ' C0[F/m] . C ' [IfThen] {C} if M then N {C '}@ ee ' The rest \nof the veri.cation for Partition is mechanical, so that we reach the following natural judgement: {Perm(ablr) \n. Order(c)}par(a, c,l,r) :p ' . {Parted(aclrp ') . Perm(ablr) . Order(c)}@a[l..r]pi Reasoning (3): Polymorphism \nWe are now ready to derive the whole speci.cation of Quicksort (12). As noted, the algorithm is generic \nin the type of data being sorted, so we conclude with deriv\u00ading its polymorphic speci.cation. We need \none additional rule for type abstraction (for further details of treatment of polymorphism, see [23]). \nWe also list the rule for let which is easily derivable from [Abs] and [App] through the standard encoding. \nBelow, ftv(T) indicates the type variables in T, similarly for ftv(C). X . ftv(G,.) . ftv(C) [TAbs] {C} \nV G;.;a :m {C '} {C} V G,.;.X.a :u {.X.C '} [Let] {C} M :x {C0}@ e {C0} N :u {C '}@e ' {C} let x = M \nin N :u {C '}@ ee ' We now present the derivation. For brevity we use the following ab\u00addef def breviations: \nC* = Perm(ablr).Sorted(aclr), B ' = Perm(ablr). def Order(c) .. j < k.QsortBounded(qj) . r - l = k, and \nB = ' B '. l < r. We also write qsort for qsort in Page 9 without the .rst line (i.e. without \u00b5/.-abstractions), \nM for q(a, c,l, p '- 1) ; q(a,c, p ' + 1,r) and N for q(l, p '- 1) ; q(p ' + 1, r). {B} par(a,c,l,r) \n:p '{Parted(aclrp') . B}@a[l..r]pi (Invariance) {Parted(aclrp') . B} M {C*}@a[l...r]ip (R.5) {B} let \np ' = par(a, l,r,c) in N {C*}@a[l...r]ip (Let) ' {B'} qsort {C*}@a[l...r]ip (IfThen) {. j < k.QsortBounded(qj)} \n' .(a,c,l,r).qsort :m (Abs) {QsortBounded(mk)}@0/ {T} qsort :u {Qsortu}@0/ (Rec, Consequence) {T} qsort \n:u {.X.Qsortu}@0/ (TAbs)  This concludes the derivation of a full speci.cation for polymor\u00adphic Quicksort. \n  6. Conclusion This paper introduced a program logic for imperative higher-order functions with general \nforms of aliasing, presented its basic the\u00adory, and explored its use for speci.cation and veri.cation \nthrough simple but non-trivial examples. Distinguishing features of the proposed program logic include \na general treatment of impera\u00adtive higher-order functions and aliasing; its precise correspondence with \nobservational semantics [15, 19]; provision of structured as\u00adsertion and reasoning methods for higher-order \nbehaviour with shared data in the presence of aliasing; and clean extensibility to data structures. We \nexpect that compositional program logics which can fully capture behaviours of higher-order programs \nwill have applications not only in speci.cation and veri.cation of individual programs but also in combination \nwith other engineering activities for safety guarantee of programs. The logic is built on our earlier \nwork [24], where we introduced a logic for imperative higher-order functions without aliasing. In [24], \na reference type in both the programming and assertion lan\u00adguages, is never carried in another type, \nwhich leads to the lack of aliasing: operationally, a procedure never receives or returns (and a reference \nnever stores) references, while logically, equating two distinct reference names is contradictory. In \nthe present work we have taken off this restriction. This leads to substantially richer and more complex \nprogram behaviour, which is met by a minimal but powerful enrichment in the logic, both in semantics \n(through intro\u00adduction of distinctions) and in syntax (by content quanti.cation). The added machinery \nallows us to reason about a general form of assignment, M := N, to treat a large class of mutable data \nstruc\u00adtures, and to reason about many programs of practical signi.cance such as Quicksort, all of which \nhave not been possible in the logic in [24]. In the following we conclude the paper with discussions \non remaining topics and related work. Local References. Apart from aliasing and higher-order behaviours, \none of the fo\u00adcal points in reasoning about (imperative) higher-order functions is new name generation \nor local references, as studied by Pitts and Stark [36]. Its clean logical treatment is possible through \na rigorous strati.cation on top of the present logic. At the level of program\u00adming language, the grammar \nis extended by new x := M in N with x . fv(M). For its logical treatment, there are two layers. In one, \nlocal references are never allowed to go out of the original scope (hence they are freshly created and \nused at each run of a program or a procedure body, to be thrown away after termination or return). In \nthis case, we do not have to change the assertion language but have only to add what corresponds to the \nstandard proof rule for locally declared variables. Below we present a simpler case when name comparison \nis not allowed in the target programming language. {C -x}N :n {C0}{([!x]C0)[!x/n]}MG;.\u00b7x:Ref (a);\u00df :m \n{C '-x} {C} new x := N in MG;.;\u00df :u {C '} (16) which says that, when inferring for M, we can safely assume \nthat the newly generated x is distinct from existing reference names, and that the description of the \nresulting state and value, C ' , should not mention this new reference (for further illustration, see \n[2, \u00a710]). It is notable that this rule and its re.nement for the restricted form of local references \nallow us to treat the standard parameter passing mechanism in procedural languages such as C and Java \nthrough the following simple translation: a procedure de.nition f(x,y) {...} is transformed into ' '' \n.(x , y ').new x := x in new y := y in .... Since x and y are freshly generated, they are never aliased \nwith each other nor with existing reference names. This aspect is logically captured by (16). Thus the \n(lack of) aliasing in stack variables can be analysed as a special case of aliasing in general references, \nallowing uniform understanding. In the fully general form of local references, a newly gener\u00adated reference \ncan be exported to the outside of its original scope (reminiscent of scope extrusion in the p-calculus \n[32]) and can live longer than the generating procedure. A procedure can now have local state, possibly \nchanging behaviour each time it runs, re.ect\u00ading not only a given argument and global state but also \nits local state, the latter invisible to the environment. This leads to greater complexity in behaviour, \ndemanding a further enrichment in logics. Among others we need to treat a newly generated reference which \nis exported to the outside, which means, in the context of (16), that C ' should now be able to talk \nabout the freshly generated reference. How this can be done with a clean and minimal extension to the \npresent logic will be discussed in a forthcoming exposition. Related Work. A detailed historical survey \nof the program logics and reasoning methods which treat aliasing, is given in [2, \u00a710], where the main \nefforts in this genre in the last three decades are discussed. Below we focus on some of the directly \nrelated Hoare-like program logics which treat aliasing. Janssen and van Emde Boas [25] .rst intro\u00adduce \ndistinctions between reference names and their content in the assertion method. The assignment rule based \non semantic substitu\u00adtion is discussed by Cartwright and Oppen [10], Morris [33] and Trakhtenbrot, Halpern \nand Meyer [39]. The work by Cartwright and Oppen [10] presented a (relative) completeness result for \na lan\u00adguage with aliasing and procedures. Morris [33] gives extensive reasoning examples. Bornat [7] \nfurther explored Morris s reason\u00ading method. Trakhtenbrot et al. [39] also presents an invariance rule \nreminiscent of ours, as well as using the dereference notation in the assertion language for the .rst \ntime. As arrays and other mutable data structures introduce aliasing between elements, studies of their \nproof rules such as [16, 29, 4] contain logical analyses of aliasing (which goes back to [30]). More \nrecently Kulczycki et al. [12] study possible ways to reason about aliasing induced by call-by-reference \nprocedure calls. A different approach to the logical treatment of aliasing, based on Burstall s early \nwork, is Separation Logic by Reynolds, O Hearn and others [37, 34]. They introduce a novel conjunction \n* that also stipulates disjointness of memory regions. Separation Logic uses the semantics and rules \nof Hoare logic for alias-free stack-allocated variables while introducing alias-sensitive rules for variables \non heaps. We discuss their work in some detail since it exhibits an interesting contrast with our approach, \nboth philosophically and technically. Their logic starts from a resource-aware assignment ' ' rule [37]: \n{e . -} [e] := e {e . e '} where e and e do not include dereference of heap variables and x .- stands \nfor .i.(x . i) . The rule demands that a memory cell is available at address e, demonstrating the resource-oriented \nnature of the logic (motivated from reasoning for low-level code such as assemblers). Consequently, {T} \n[e] :=[e] {T} is unsound in their logic. This command corresponds to x := !x in our notation. {T} x :=!x \n{T} is trivially sound in original Hoare logic [20] and ours. On the basis of these resource-oriented \nproof rules, [37, 34] propose a variant of the invariance rule. {C} P {C '} fv(C0) n modify(P)= 0/ (17) \n{C *C0} P {C '*C0} The second premise is the standard side condition (modify(P) is the set of all stack-allocated \nvariables which P may write to). Apart from this side condition, soundness of this rule hinges on the \nre\u00adsource-oriented assignment/dereference rules described above, by which all the variables (addresses) \nin the heap which P may write to are explicitly mentioned in C. Like the standard invariance rule, this \nrule is intended to serve as an aid for modular veri.cation of program correctness. Separation Logic \ns ability to reason about aliased references crucially depends on its resource-oriented nature, the separating \nconjunction * and a special predicate . to represent content of memory cells. In contrast, the present \nwork aims at a precise log\u00adical articulation of observational meaning of programs in the tra\u00additions \nof both Hennessy-Milner logic and Hoare logic, as exem\u00adpli.ed by Theorem 3. Another difference is that \nour logic aims to make the best of the standard logical apparatus of .rst-order logic with equality to \nrepresent general aliasing situations. These differ\u00adences come to life for example in the [Invariance] \nrule of \u00a73, which plays a role similar to (17). Our rule relies on purely compositional reasoning about \nobservable behaviour, which, as examples in the previous section may suggest, contributes to tractability \nin reason\u00ading. Concrete examples will serve to elucidate the difference. The following shows a possible \ninference for x := 2; y :=!z through a direct application of (17, Assign, Inv, Seq, Consequence). {x \n. -} x := 2 {x . 2} {y .- . z . i} y :=!z {y . i . z . i} {x .- * (y .- . z .-)}x := 2; y :=!z {x . 2 \n*.i.(y . i . z . i)} For the same program, a direct application of our invariance rule gives: 1 {T} x \n:= 2 {!x = 2}@x (Assign) 2 {T} y :=!z {!y = !z}@y (Assign) 3 {T} x := 2;y :=!z {(!y)!x = 2 . !y =!z}@xy \n(SeqI) Re.ecting observational nature, the pre-condition simply stays empty. Note also that (!y)!x = \n2 . !y =!z is equivalent to (x = y . !x = 2) . !y =!z, which is more general than x . 2 *.i.(y . i . \nz . i). Intuitively this is because the content quanti.cation (here (!y)) offers a more re.ned form of \nprotection from sharing/aliasing. These examples suggest a gain in generality in using the pro\u00adposed \nlogical framework for representation of sharing and disjoint\u00adness of data structures. While C1 *C2 is \npractically embeddable as [! e2]C1 . [! e1]C2 where ei exhausts active dereferences of Ci, the examples \nsuggest the use of write sets in located judgements/asser\u00adtions offers a more precise description and \nsmooth reasoning. On its observational basis, the present logic may incorporate resource\u00adsensitive aspects \nthrough separate predicates (for example a pred\u00adicate allocated(e) may say e of a reference type is allocated). \nBe\u00adcause of differences in orientation, we also expect a fruitful inter\u00adplay between ideas from Separation \nLogic and those from the pro\u00adposed logic and its rami.cations. As one such instance, our long version \n[2, \u00a710] reports a generalisation of a re.ned version of (17) studied by O Hearn, Yang and Reynolds [34]. \nWe also note elimination procedures similar to our Theorem 2 are studied by Lozes [28] and Calcagno et \nal. [8]. Acknowledgements We thank the anonymous referees for their useful comments. This work was partially \nsupported by EPSRC grants GR/R03075/01, GR/T04236/01, GR/S55538/01, GR/T04724/01 and GR/T03208/01.  \n References [1] C home page. http://www.cminusminus.org. [2] A full version of the present paper. Available \nfor download at www.dcs.qmul.ac.uk/ kohei/logics. [3] Samson Abramsky, Kohei Honda, and Guy McCusker. \nA fully abstract game semantics for general references. In LICS 98, pages 334 344, 1998. [4] K R. Apt. \nTen Years of Hoare Logic: a survey. TOPLAS, 3:431 483, 1981. [5] Friedrich L. Bauer, Edsger W. Dijkstra, \nand Tony Hoare, editors. Theoretical Foundations of Programming Methodology, Lecture Notes of an International \nSummer School. Reidel, 1982. [6] Patrick Blackburn, Maarten de Rijke, and Yde Venema. Modal Logic. Cambridge \nUniversity Press, 2001. [7] Richard Bornat. Proving pointer programs in hoare logic. In Conf. on Mathematics \nof Program Construction, LNCS. Springer-Verlag, 2000. [8] Cristiano Calcagno, Philippa Gardner, and Matthew \nHague. From separation logic to .rst-order logic. In Proc. FoSSaCs 05, LNCS. Springer-Verlag. [9] Robert \nCartwright and Derek C. Oppen. Unrestricted procedure calls in Hoare s logic. In POPL, pages 131 140, \n1978. [10] Robert Cartwright and Derek C. Oppen. The logic of aliasing. Acta Inf., 15:365 384, 1981. \n[11] Patrick Cousot. Methods and logics for proving programs. In Handbook of Theoretical Computer Science, \nvolume B, pages 843 993. Elsevier, 1999. [12] G. W. Kulczycki et al. Reasoning about procedure calls \nwith repeated arguments and the reference-value distinction. Technical Report TR .02-13a, Dept. of Comp. \nSci., Iowa State Univ., December 2003. [13] Jean-Christophe Filli atre and Nicolas Magaud. Certi.cation \nof sorting algorithms in the system Coq. In Theorem Proving in Higher Order Logics: Emerging Trends, \n1999. [14] Robert W. Floyd. Assigning meaning to programs. In Symp. in Applied Mathematics, volume 19, \n1967. [15] Irene Greif and Albert R. Meyer. Specifying the Semantics of while Programs: A Tutorial and \nCritique of a Paper by Hoare and Lauer. ACM Trans. Program. Lang. Syst., 3(4), 1981. [16] David Gries \nand Gary Levin. Assignment and procedure call proof rules. ACM Trans. Program. Lang. Syst., 2(4):564 \n579, 1980. [17] Dan Grossman, Greg Morrisett, Trevor Jim, Michael Hicks, Yanling Wang, and James Cheney. \nRegion-based memory management in cyclone. In PLDI 02. ACM, 2002. [18] Carl A. Gunter. Semantics of Programming \nLanguages. MIT Press, 1995. [19] Matthew Hennessy and Robin Milner. Algebraic Laws for Non-Determinism \nand Concurrency. JACM, 32(1), 1985. [20] Tony Hoare. An axiomatic basis of computer programming. CACM, \n12, 1969. [21] Tony Hoare and He Jifeng. Unifying Theories of Programming. Prentice-Hall International, \n1998. [22] Kohei Honda. From process logic to program logic. In ICFP 04, pages 163 174. ACM Press, 2004. \n[23] Kohei Honda and Nobuko Yoshida. A compositional logic for polymorphic higher-order functions. In \nPPDP 04, pages 191 202. ACM Press, 2004. [24] Kohei Honda, Nobuko Yoshida, and Martin Berger. An observation\u00adally \ncomplete program logic for imperative higher-order functions. In Proc. LICS 05, pages 270 279. IEEE, \n2005. [25] T. M. V. Janssen and Peter van Emde Boas. On the proper treatment of referencing, dereferencing \nand assignment. In Proc. ICALP, pages 282 300, 1977. [26] Brian W. Kernighan and Dennis M. Ritchie. The \nC Programming Language, Second Edition. Prentice-Hall, Englewood Cliffs, New Jersey, 1988. [27] Thomas \nKleymann. Hoare logic and auxiliary variables. Technical report, University of Edinburgh, LFCS ECS-LFCS-98-399, \nOctober 1998. [28] Etienne Lozes. Elimination of spatial connectives in static spatial logics. TCS, to \nappear. [29] David C. Luckham and Norihisa Suzuki. Veri.cation of array, record, and pointer operations \nin pascal. ACM Trans. Program. Lang. Syst., 1(2):226 244, 1979. [30] John L. McCarthy. Towards a mathematical \nscience of computation. In IFIP Congress, pages 21 28, 1962. [31] Elliot Mendelson. Introduction to Mathematical \nLogic. Wadsworth Inc., 1987. [32] Robin Milner, Joachim Parrow, and David Walker. A calculus of mobile \nprocesses, parts I and II. Info. &#38; Comp., 100(1):1 77, 1992. [33] Joseph M. Morris. A general axiom \nof assignment/ assignment and linked data structures/ a proof of the Schorr-Wait algorithm. In [5], pages \n25 52. Reidel, 1982. [34] Peter O Hearn, Hongseok Yang, and John C. Reynolds. Separation and information \nhiding. In POPL 04, 2004. [35] Benjamin C. Pierce. Types and Programming Languages. MIT Press, 2002. \n[36] Andrew Pitts and Ian Stark. Operational reasoning for functions with local state. In HOOTS 98, CUP, \npages 227 273, 1998. [37] John C. Reynolds. Separation logic: a logic for shared mutable data structures. \nIn LICS 02, 2002. [38] Zhong Shao. An overview of the FLINT/ML compiler. In 1997 ACM SIGPLAN Workshop \non Types in Compilation (TIC 97), Amsterdam, The Netherlands, June 1997. [39] Boris Trakhtenbrot, Joseph \nHalpern, and Albert Meyer. From Denotational to Operational and Axiomatic Semantics for ALGOL\u00adlike languages: \nan overview. In Logic of Programs, volume 164 of LNCS, pages 474 500, 1984.  \n\t\t\t", "proc_id": "1086365", "abstract": "We present a compositional program logic for call-by-value imperative higher-order functions with general forms of aliasing, which can arise from the use of reference names as function parameters, return values, content of references and parts of data structures. The program logic extends our earlier logic for alias-free imperative higher-order functions with new modal operators which serve as building blocks for clean structural reasoning about programs and data structures in the presence of aliasing. This has been an open issue since the pioneering work by Cartwright-Oppen and Morris twenty-five years ago. We illustrate usage of the logic for description and reasoning through concrete examples including a higher-order polymorphic Quicksort. The logical status of the new operators is clarified by translating them into (in)equalities of reference names. The logic is observationally complete in the sense that two programs are observationally indistinguishable if they satisfy the same set of assertions.", "authors": [{"name": "Martin Berger", "author_profile_id": "81100228866", "affiliation": "Queen Mary, University of London", "person_id": "PP14089313", "email_address": "", "orcid_id": ""}, {"name": "Kohei Honda", "author_profile_id": "81100624236", "affiliation": "Queen Mary, University of London", "person_id": "PP31050384", "email_address": "", "orcid_id": ""}, {"name": "Nobuko Yoshida", "author_profile_id": "81100632656", "affiliation": "Imperial College, London", "person_id": "PP39051644", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1086365.1086401", "year": "2005", "article_id": "1086401", "conference": "ICFP", "title": "A logical analysis of aliasing in imperative higher-order functions", "url": "http://dl.acm.org/citation.cfm?id=1086401"}