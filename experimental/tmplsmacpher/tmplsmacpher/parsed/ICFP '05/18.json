{"article_publication_date": "09-12-2005", "fulltext": "\n Scrap Your Boilerplate With Class: Extensible Generic Functions Ralf L\u00a8ammel Simon Peyton Jones Microsoft \nCorp. Microsoft Research ral.a@microsoft.com simonpj@microsoft.com Abstract The Scrap your boilerplate \napproach to generic programming al\u00adlows the programmer to write generic functions that can traverse arbitrary \ndata structures, and yet have type-speci.c cases. How\u00adever, the original approach required all the type-speci.c \ncases to be supplied at once, when the recursive knot of generic function def\u00adinition is tied. Hence, \ngeneric functions were closed. In contrast, Haskell s type classes support open, or extensible, functions \nthat can be extended with new type-speci.c cases as new data types are de.ned. In this paper, we extend \nthe Scrap your boilerplate ap\u00adproach to support this open style. On the way, we demonstrate the desirability \nof abstraction over type classes, and the usefulness of recursive dictionaries. Categories and Subject \nDescriptors D.1.m [Programming Tech\u00adniques]: Generic Programming; D.3.3 [Programming Languages]: Language \nConstructs and Features; D.2.13 [Software Engineer\u00ading]: Reusable Software General Terms Design, Languages \nKeywords Generic programming, type classes, extensibility, type\u00adcase, recursive dictionaries 1. Introduction \nIn the so-called scrap your boilerplate approach to generic pro\u00adgramming, we exploit Haskell s rich type \nsystem to allow pro\u00adgrammers to write generic functions [LP03, LP04]. The approach works very well for \nconstructing closed generic functions; that is, ones whose special cases are all known in advance. However, \nuntil now, the approach did not work well for open, or extensible, generic functions. We consider a generic \nprogramming example to illustrate the open/closed dichotomy. The QuickCheck library [CH00] involves the \nfollowing function: shrink :: Shrink a => a -> [a] Shrinking a data structure returns a list of smaller \ndata structures of the same type. QuickCheck runs the user s function on randomly Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 05 September 26 28, \n2005, Tallinn, Estonia. Copyright c . 2005 ACM 1-59593-064-7/05/0009. . . $5.00. chosen inputs. When \nit .nds a value that fails a test, it repeatedly uses shrink to try to .nd a smaller example that also \nfails. Shrinking is clearly a generic programming problem. For many data structures, a boilerplate de.nition \nwill do, e.g., return the largest (immediate or deeply nested) subterms of the same type as the failing \nterm. But some data structures require special treatment. For example, we must not shrink a syntax tree \nrepresenting a program in such a way that variables become unbound. Each user of the QuickCheck library \nde.nes new data types. So QuickCheck cannot de.ne, once and for all, all the types for which shrink behaves \nspecially; shrink absolutely must be extensible. That is not possible using the existing scrap your boilerplate \napproach, as Koen Claessen carefully explained to us1. In general terms, lack of open, generic functions \neffectively bans generic programming from use in libraries. Thus motivated, this paper describes a variant \nof scrap your boilerplate (henceforth SYB) that directly supports open, generic functions. We make the \nfollowing contributions: We describe how to program extensible generic functions in Haskell (Section \n3). It was entirely non-obvious (at least to us) that SYB could be enhanced in a such a manner.  Our \ninitial presentation assumes that Haskell allows abstraction over type classes in addition to normal \nabstraction over types. In particular, we need to parameterise a class by its superclass a feature somewhat \nreminiscent of mixins. In Section 4 we build on work by Hughes to show that this extension is not necessary \n[Hug99]. However, we argue that abstraction over type classes is a natural and desirable extension after \nall, Haskell lets you abstract over practically anything else.  While our new approach builds on Haskell \ns type-class sys\u00adtem hence the title it requires one fundamental extension, which we deliver in this \npaper: the ability to construct recur\u00adsive dictionaries (Section 5). This extension is both principled \nand independently useful. It has been requested many times by (hard-core) Haskell users, and was already \npart of GHC before we began work on this paper.  We give a case study of the approach applied to QuickCheck \nin Section 6, and discuss related work in Section 8. Everything we describe has been implemented, as \nHaskell code that runs in GHC, and is available at http://www.cs.vu.nl/boilerplate/. The extended SYB \nis .nding its way into new applications of generic programming such as Foster s HAIFA ( Haskell Application \nInter\u00adoperation Framework Architecture ) [Fos05]. 1 Personal communication, October 2004. 2. The problem \nwe tackle Let s consider a very simple generic function that computes the size of a data structure: gsize \n:: Data a => a -> Int gsize t = 1 + sum (gmapQ gsize t) Here we use the SYB combinator gmapQ, a method \nof the Data class, de.ned thus: class Typeable a => Data a where gmapQ :: (forall b. Data b => b -> r) \n-> a-> [r] The idea is that (gmapQ gsize t) applies gsize to each of the immediate children of t, and \nreturns a list of these sizes; then sum adds up this list, and we conclude by adding 1 (for the root \nnode) to the total. Instances of the Data class can be derived automatically, but we give two sample \ninstances as an illustration: instance Data Char where gmapQ f c= [] --no immediate subterms to be queried \n instance Data a => Data [a] where gmapQ f[] =[] --no immediate subterms to be queried gmapQ f (x:xs) \n= [f x, f xs] --head and tail are queried The Data class has several other methods, but for much of \nthis pa\u00adper we will pretend that it has just one method, gmapQ. Everything we say extends to generic \nfunction types other than just queries (c.f. Q in gmapQ). 2.1 Classic customisation Almost always, however, \none wants to de.ne special cases of a generic function at speci.c types. For example, suppose that the \ndatum t contained nodes of type Name: data Name = N String deriving( Typeable ) Then we might want to \ncount just 1 for a Name node, rather than count up the size of the string inside it. As another example, \nwhat would you expect the call (gsize [4,1]) to return? In fact it returns 5, one for each cons cell, \none for the nil at the end of the list, and one for each Int; but we might prefer to give gsize list\u00adspeci.c \nbehaviour, so that it returned (say) the length of the list. The original SYB paper [LP03] described \nhow to achieve type\u00adspeci.c behaviour, using type-safe cast and operations de.ned on top of it. The main \nfunction, gsize, is obtained by combin\u00ading a generic function gsize_default with a type-speci.c case, \nname_size, written by the programmer: gsize :: Data a => a -> Int gsize t = gsize_default extQ name_size \nextQ phone_size gsize_default :: Data a => a -> Int gsize_default t = 1 + sum (gmapQ gsize t) name_size \n:: Name -> Int name_size (N _) = 1 phone_size :: PhoneNumber -> Int --Another special case The type \nof the combinator extQ2 is the following: 2 ext hints at generic function extension another term for \ncustomisa\u00adtion. extQ :: (Typeable a, Typeable b) => (a->r) -> (b->r) -> (a->r) Here, Typeable is a superclass \nof Data. In the call (extQ fg t), extQ attempts a cast to decide whether to apply g to t, or to use the \ngeneric method f. Since extQ is left-associative, one can compose together a whole string of calls to \nextQ to give the function many type-speci.c cases. 2.2 The shortcomings of extQ However, this way of \nspecialising, or customising, a generic func\u00adtion suffers from several shortcomings: The cast operation \nof extQ boils down to a run-time type test. When a customised generic function is applied to a datum, \nthen type tests are performed in linear sequence for the type-speci.c cases, at every node of a traversed \ndata structure. These type tests can outweigh other computations by a factor.  There is no static check \nfor overlap; in a long sequence of extQ calls one could mistakenly add two cases for Name, one of which \nwould silently override the other.  The use of cast operations becomes .ddly when we want to specialise \nthe generic function for type constructors as well as types [LP04]. A good example is when we want to \nspecialise gsize for polymorphic lists, as suggested above.  But these problems pale into insigni.cance \nbeside the main one: Once the knot is tied, via the mutual recursion between gsize and gsize default, \none can no longer add type\u00adspeci.c cases to gsize. Notice the way that gsize contains a list of all its \ntype-speci.c cases. In short, the technique is fundamentally non-modular. Suppose a programmer adds a \nnew type Boo, and wants to extend gsize to handle it. The only way to do so is to tie the knot afresh: \nmy_gsize :: Data a => a -> Int my_gsize t = gsize_default extQ name_size extQ phone_size extQ boo_size \n gsize_default :: Data a => a -> Int gsize_default t = 1 + sum (gmapQ my_gsize t) boo_size :: Boo -> \nInt ... The amount of new code can be reduced in obvious ways for example, pass the recursive function \nto gsize_default as an argument, rather than calling it by name but it still forces the programmer to \nexplicitly gather together all the type-speci.c cases, and then tie the knot. 2.3 What we want What \nmakes the situation particularly tantalising is the contrast with type classes. In Haskell, if we declare \na new type Name, we can extend equality to work over Name simply by giving an instance declaration: instance \nEq Name where (N s1) == (N s2) = s1==s2 The type system checks that there is only one instance for Eq \nName. There is no run-time type test; instead, the correct instance is auto\u00admatically selected based \non static type information. If a function is polymorphic in a type with equality, then the correct instance \ncan\u00adnot be selected statically, so it is passed as a run-time parameter instead. For example: isRev :: \nEq a => [a] -> [a] -> Bool isRev xs ys = (xs == reverse ys) We know statically that the equality test \nis performed on two lists, but the element type of the lists is not known statically hence the (Eq a) \nconstraint in the type. At run-time, isRev is passed a dictionary that gives the equality method for \nvalues of type a, and from which it can construct the equality method for lists of type [a] (again by \nplain dictionary passing). Most importantly, though, the programmer never has to gather together all \nthe instances and de.ne a recursive == that takes all these instances into account. The result is modular: \neach time you de.ne a new type, you also de.ne its overloaded operations. Unfortunately, overloaded operations \n(in the Haskell sense) are not generic; you have to de.ne an instance for every type. We want the best \nof both worlds: generic functions (in the scrap-your\u00adboilerplate sense) together with modular customisation \nas new data types are added.  3. The idea Our goal is to combine SYB with the modular extension offered \nby type classes. The pattern we hope to use is this: Each time we need a new generic function, such \nas gsize, we de.ne a new type class, Size, with gsize as a method.  At the same time, we provide a generic \nimplementation of gsize, in the form of an instance for (Size t). (Section 3.5 discusses an alternative.) \n When we later introduce a new data type, such as Name in the example above, we can also add an instance \ndeclaration for Size that gives the type-speci.c behaviour of gsize for that type. If we omit such as \nspeci.c instance, we simply inherit the generic behaviour.  It is helpful to identify three separate \nprotagonists. The SYB au\u00adthors (i.e., ourselves) write SYB library code, including the de.ni\u00adtion of \nthe Data class and its supporting libraries. The generic func\u00adtion author writes another library that \ngives the class and generic de.nitions; in the case of gsize, this means the class Size and the generic \nde.nition of gsize. Finally the client imports this li\u00adbrary, de.nes new types, and perhaps adds instance \ndeclarations that make gsize behave differently on these new types. 3.1 A failed attempt Here is a .rst \nattempt: class Size a where gsize :: a -> Int instance Size Name where gsize (N _) =1 instance Size \nt where gsize t = 1 + sum (gmapQ gsize t) The idea is that the Size Name instance gives the Name-speci.c \nbehaviour while the Size t instance gives the default, generic be\u00adhaviour on all types that do not match \nName. The reader will no\u00adtice right away that this assumes that the compiler accepts overlap\u00adping instances, \na non-standard extension to Haskell. Overlapping instances are very convenient here, but they are not \nabsolutely nec\u00adessary, as we discuss in Section 3.5. For now, however, let us as\u00adsume that overlapping \ninstances are allowed. Overlap is not the big problem here. The problem is that the Size t instance does \nnot type-check! Recall the type of gmapQ: gmapQ :: Data a => (forall b. Data b => b -> r) -> a-> [r] \n There are two issues. First, the call to gmapQ in the Size t instance leads to a Data t constraint. \nSo we must add Data t to the context of the instance declaration: instance Data t => Size t where gsize \nt = 1 + sum (gmapQ gsize t) The second issue is not so easily solved. In any call (gmapQ f t), the function \nf has access to the operations of the Data class (and its superclasses), but no more just look at the \ntype of gmapQ. Sadly, in the Size t instance declaration we pass gsize to gmapQ, and gsize now has this \ntype: gsize :: Size a => a -> Int The only obvious way out of this dif.culty is to arrange that Size \nis a superclass of Data: class (Typeable a, Size a) => Data a where ... We have thus de.ned a single, \nextensible generic function3. 3.2 Abstraction over a class Problem solved? By no means. The Data class \nis de.ned in the SYB library, and we cannot extend it with a new superclass every time we want a new \ngeneric function! That would be a new (and even more pernicious) form of non-modularity. However, it \nleads us in an interesting new direction. Since we do not know what class should be a superclass of Data, \nlet us parameterise over that class: --Pseudo-code class (Typeable a, cxt a) => Data cxt a where gmapQ \n:: (forall b. Data cxt b => b -> r) -> a-> [r] instance Data Size t => Size t where gsize t = 1 + sum \n(gmapQ gsize t) Here the variable cxt ranges over type classes, not over types. In the class declaration \nfor Data, the superclass is not .xed, but rather is speci.ed by cxt. In the generic instance declaration \nfor Size t we specify which particular superclass we want, namely Size. We note that Haskell does not \noffer variables that range over type classes, but we will assume for now that it does. In Section 4.1 \nwe will show how class parameters can be encoded straightfor\u00adwardly in standard Haskell. We are nearly \nhome, but not quite. Let us recall again the types for gmapQ and gsize, which we write with fully-explicit \nquanti.cation: gmapQ :: forall cxt, a. Data cxt a => (forall b. Data cxt b => b -> r) -> a -> [r] gsize \n:: forall a. Size a => a -> Int So in the call (gmapQ gsize t), the function f can use any operations \naccessible from Data cxt b. In this case we want cxt to be Size, but there is no way to say so. The universally\u00adquanti.ed \ncxt type parameter in gmapQ s type is mentioned only in constraints: it is ambiguous. However, if we \ncould specify the type arguments to use, we would be .ne: --Pseudo-code instance Data Size t => Size \nt where gsize x = 1 + sum (gmapQ {|Size,t|} gsize x) 3 This solution suffers from a dif.culty discussed \nand solved in Section 5, but we pass lightly on since this is a failed attempt anyway. Here, we imagine \nanother non-standard extension to Haskell, namely the ability to specify the types at which a polymorphic \nfunc\u00adtion is called. The notation gmapQ {|Size,t|} means gmapQ called with cxt = Size and a = t (refer \nto the type of gmapQ given immediately above). We pass two type arguments, because gmapQ is quanti.ed \nover two type parameters, but only the .rst is really interesting. Again, we will discuss how to encode \nthis exten\u00adsion in standard Haskell, in Section 4.2, but the essential intent is simply to .x the type \narguments for gmapQ. 3.3 The Data instances As in our earlier work, every data type must be made an \ninstance of class Data, either manually or with compiler support. For example, here are the instance \ndeclarations for integers and lists: instance (cxt Int) => Data cxt Int where gmapQ f n= [] instance \n(cxt [a], Data cxt a) => Data cxt [a] where gmapQ f[] =[] gmapQ f (x:xs) = [f x, f xs] Compared to \nour earlier work, the only change is an extra context for each instance declaration (cxt Int) and (cxt \n[a]) re\u00adspectively to provide the necessary superclass. Here, we need an instance declaration context \nthat contains structured types (e.g., (cxt [a])), so one might worry about the termination of con\u00adstraint \nsolving, a point we return to in Section 5. 3.4 Using the new customisation In the type-class framework, \nnew instances can be added (by the client of the gsize library) in an extremely straightforward manner. \nFor example: instance Size Name where gsize n =1 instance Size a => Size [a] where gsize [] =0 gsize \n(x:xs) = gsize x + gsize xs The .rst instance declaration says that a Name always has size 1, regardless \nof the size of the String inside it (c.f. Section 2.1). The second instance de.nes the size of a list \nto be the sum of the sizes of its components, without counting the cons cells themselves, the [] at the \nend. (Both would be counted by the generic de.nition.) One can make new generic functions by combining \nexisting ones, just as you always can with type classes. For example, sup\u00adpose we have a generic depth-.nding \nfunction gdepth, de.ned similarly to gsize. Then we can combine them to .nd the den\u00adsity of a data structure: \ndensity :: (Size a, Depth a) => a -> Int density t = gsize t / gdepth t Notice that the context is \nexplicit about all the generic functions that are called in the body. Again, this is just standard type-class \nbehaviour, and we could easily have a single class combining both gsize and gdepth. 3.5 Overlapping \ninstances and default methods So far we have given the generic de.nition of gsize the one to use if \nnot overridden using an instance declaration thus: instance Data Size t => Size t where gsize x = 1 \n+ sum (gmapQ {|Size,t|} gsize x) Notice the => Size t , which makes this instance overlap with every \nother instance of Size. Hence, this approach relies on over\u00adlapping instances, a non-Haskell 98 feature. \nWe can avoid overlapping instances, using Haskell 98 s default method declarations instead. We brie.y \nreview default methods, using a trivial example: class Num a where (+), (-) :: a -> a-> a negate :: a \n-> a (-) xy =x+ negate y The de.nition of (-) in the class declaration is the default method for (-); \nif an instance declaration de.nes only (+) and negate, the method for (-) is .lled in from the default \nmethod in the class declaration. A default method has the same use this unless overridden .avour as do \nour generic functions. Consider our class Size: class Size a where gsize :: a -> Int gsize x = ???? \nThe default method for gsize can assume absolutely nothing about the type a, so it is hard for it to \ndo anything useful. The obvious way to .x this is to add Data as a superclass of Size, thus: class Data \nSize a => Size a where gsize :: a -> Int gsize x = 1 + sum (gmapQ {|Size,a|} gsize x) Now, for every \ntype for which we want to use the generic de.nition, we must add a boilerplate instance declaration. \nFor instance: instance Size a => Size [a] instance (Size a, Size b) => Size (a,b) These instances omit \nthe code for gsize, so that it is .lled in by the default-method code from the class declaration. Type-speci.c \ninstances, such as that for Size Name, are written just as before, with explicit type-speci.c code for \ngsize. Compared to the previous approach, using the default method has the the advantage that it does \nnot require overlapping instances. There seem to be two disadvantages. First, since Data isnow a su\u00adperclass \nof Size, every type that is an instance of Size must also be an instance of Data, even though the methods \nof Data may be en\u00adtirely unused for that type; this seems inelegant. Second, one must give an explicit \n(albeit brief) Size instance declaration for every type for which gsize is to be callable, including \nones for which the generic behaviour is wanted (e.g., lists and pairs above). However, in some applications \nthis disadvantage might be considered an advantage, because it forces the library client to make a conscious \ndecision about whether to use a type-speci.c implementation for gsize (by supplying code in the instance \ndeclaration), or to use the generic method (by omitting the code). 3.6 Intermediate summary We have \nnow concluded our overview of the key new idea in this paper: if we can abstract over type classes, then \nwe can arrange for modular customisation of generic functions, the challenge we posed in Section 2. Apart \nfrom modular extensibility, the approach has several other bene.ts, compared to the cast-based technique \nof our earlier work: There are no run-time type tests. Instead, execution proceeds using the existing \nHaskell type-class mechanism: the overload\u00ading is resolved either statically, or by dictionary passing. \n There is no danger of accidentally extending a generic function in incompatible ways for the same data \ntype. Any attempt to do so will be reported as an overlapping-instance error.  No extra complexity is \nassociated with customising the generic function at type constructors for example, see the instance \nfor Size on pairs in the previous sub-section. By contrast, in our earlier work [LP04], it required distinct \ngeneric function combinators for each new kind of type constructor. We have assumed a number of extensions \nto Haskell 98: Multi-parameter type classes, a very well-established extension.  Overlapping instance \ndeclarations are required in one formula\u00adtion, but are entirely avoidable (Section 3.5).  The ability \nto abstract over type classes. This extension can be encoded in ordinary Haskell (Section 4.1).  Explicit \ntype application; again this is readily encoded in ordi\u00adnary Haskell (Section 4.2).  The ability to \ndeclare an instance for (Size t), where t is a type variable; and the possibility of non-type-variable \ncon\u00adstraints in the context of an instance declaration. Both these ex\u00adtensions are used in the instance \ndeclaration for (Size t) in Section 3.2, for example. They are both illegal in Haskell 98, in order to \nguarantee decidability of type inference.  Of these, the last is the only extension that is both unavoidable \nand not already widely available. Decidability of type inference is indeed threatened. In Section 5, \nwe describe a corresponding Haskell extension that is based on building recursive dictionaries.  4. \nEncoding in Haskell In this section we show how to encode the technique discussed in Section 3 in Haskell \nwith common extensions. 4.1 Encoding abstraction over classes The biggest apparent dif.culty is the \nquestion of abstraction over type classes. John Hughes encountered a very similar problem six years ago, \nin the context of a language concept for algebraic data types with attached restrictions, and he described \na way to encode abstraction over type classes without extending Haskell [Hug99]. We can adopt Hughes \ntechniques for our purposes. We begin by de.ning, once and for all, a class Sat, with a single method, \ndict4: class Sat a where dict :: a This class becomes a superclass of Data, thus: class (Typeable a, \nSat (cxt a)) => Data cxt a where gmapQ :: (forall b. Data cxt b => b -> r) -> a-> [r] Now, whenever \na generic-library author de.nes a new class for a generic function, such as Size, she additionally de.nes \na new record type SizeD, which corresponds to the dictionary type for the envisaged class. The .elds \nof the record type correspond one\u00adto-one to the methods of the class: data SizeD a = Size { gsizeD :: \na -> Int } This type automatically gives us a record selector with the follow\u00ading parametrically polymorphic \ntype: gsizeD :: SizeD a -> a -> Int It happens in this case that there is only one method, but the encoding \nworks equally well when there are many. Along with the new record type, we also give a new instance declaration \nfor Sat: 4 Short for Satis.es and class dictionary , respectively. instance Size t => Sat (SizeD t) where \ndict = SizeD { gsizeD = gsize } As you can see, both the record type and the instance declaration are \ntrivially derived from the class declaration of Size. Now the library author can give the generic de.nition \nfor gsize, via an instance declaration for Size t, just as in Section 3.2: instance Data SizeD t => Size \nt where gsize t = 1 + sum (gmapQ {|SizeD,t|} (gsizeD dict) t) Here comes the crucial point: the recursive \ncall to gsize is made by calling (gsizeD dict), instead of gsize, because the function passed to gmapQ \nonly has access to Data SizeD t, and hence to Sat (SizeD t), but not to Size t. Accidentally calling \ngsize instead of (gsizeD dict) would yield a type error. It is only when one wants to call gsize inside \nan argument passed to a rank-2 polymorphic SYB combinator (such as gmapQ) that one has to call gsizeD \ndict. Type-speci.c code never has to do this. For example, the instances given in Section 3.4 work unchanged; \nno encoding is needed: instance Size Name where gsize n =1 instance Size a => Size [a] where gsize [] \n=0 gsize (x:xs) = gsize x + gsize xs In practise this means that the encoding effort for type-class \nab\u00adstraction is limited to generic function libraries; clients of such li\u00adbraries will not be concerned \nwith the encoding.  4.2 Explicit type application In Section 3.2 we found that we needed to specify \nthe type ar\u00adguments for a call to gmapQ, which we did using the notation gmapQ {|Size,t|}. There is a \nstandard way to treat this dif.culty in standard Haskell, by using a type-proxy parameter. Suppose that \nwe give gmapQ the following type: gmapQ :: forall cxt, a. Data cxt a => Proxy cxt -> (forall b. Data \ncxt b => b -> r) -> a -> [r] The function gmap gets a new formal parameter, of type Proxy cxt, so that \nthe type of an actual parameter will .x the type cxt. The type Proxy does not need to de.ne any constructor, \nas it is used for carrying around type information only: data Proxy (cxt :: * -> *) The actual type-proxy \nparameter for the Size context is con\u00adstructed as follows: sizeProxy :: Proxy Size sizeProxy = error \n\"urk\" As a result, we can now call (gmapQ sizeProxy) to .x the cxt type argument of gmapQ to be Size: \ninstance Data SizeD t => Size t where gsize t = 1 + sum (gmapQ sizeProxy (gsizeD dict) t) We de.ne sizeProxy \nto be error \"urk\", to emphasise that it is only used as a type proxy; its value is never examined. The \nde.ni\u00adtions of gmapQ, in instance declarations for Data simply ignore the type-proxy argument. For example \n(notice the underbars): instance (Sat (cxt [a]), Data cxt a) => Data cxt [a] where gmapQ _f[] =[] gmapQ \n_ (x:xs) = [f x, f xs] In de.ning the type Proxy above, we took advantage of two GHC extensions. First, \nwe omitted all the constructors, since we never build a concrete value of this type. Second, the type \nparameter cxt of Proxy has kind (* -> *), which we indicated with a kind signature. If we wanted to stick \nto vanilla Haskell 98, we could instead write: data Proxy cxt = P (cxt Int) --Any type other than Int \nwould also be fine The constructor P will never be used, but it speci.es the kind of cxt via its use \nin the component (cxt Int). Although we describe type-proxy arguments as an encoding of proper type arguments, \nthey are in some ways superior. In the hypothetical extension of Section 3.2, allowing type arguments, \nwe had to pass two type arguments {|Size,t|}, even though only one was of interest. With type proxies \nwe can identify exactly which type arguments must be passed. Furthermore, omitting an explicit type-proxy \nargument will lead to a somewhat-comprehensible error message, whereas omitting a genuine type argument \nmight lead to a less-comprehensible ambiguity error. 4.3 Intermediate summary The encoding we describe \nis not heavy. The Sat class and Proxy types are de.ned in the SYB library, along with Data, Typeable \nand much else; and the derivation of Data and Typeable instances is automated in GHC5. In addition to \nde.ning a class for the generic function, the author of a generic library must also de.ne a corresponding \n(a) record type, (b) Sat instance, and (c) type proxy. These de.nitions are pure boilerplate, and take \nonly a line or two each. One could employ Template Haskell [SP02] to eliminate the need to de.ne (a) \n(c) explicitly. The only tricky points arise in writing the generic code for the function: the provision \nof type-proxy parameters, and the necessity of calling (gizeD dict) instead of gsize in SYB combinator \nar\u00adguments. The client of a generic library sees no encoding whatso\u00adever. However, like any encoding, \ntype errors are likely to be less perspicuous than if type-class abstraction were directly supported. \nFor completeness, Figure 1 gives a small but complete example, which executes in GHC. It is partitioned \ninto the code that has to be written by the three protagonists. module Example where import Data.Typeable \n---------SYB library code ----------\u00addata Proxy (a :: * -> *) class Sat a where { dict :: a } class (Typeable \na, Sat (ctx a)) => Data ctx a where gmapQ :: Proxy ctx -> (forall b. Data ctx b => b -> r) -> a -> [r] \ninstance Sat (cxt Char) => Data cxt Char where gmapQ _f n =[] instance (Sat (cxt [a]), Data cxt a) => \nData cxt [a] where gmapQ _f[] =[] gmapQ _ f (x:xs) = [f x, f xs] ---------gsize library code ----------\u00adclass \nSize a where gsize :: a -> Int data SizeD a = SizeD { gsizeD :: a -> Int } sizeProxy :: Proxy SizeD sizeProxy \n= error \"urk\" instance Size t => Sat (SizeD t) where dict = SizeD { gsizeD = gsize } instance Data SizeD \nt => Size t where gsize t = 1 + sum (gmapQ sizeProxy (gsizeD dict) t) ---------gsize client code ----------\u00ad \ninstance Size a => Size [a] where gsize [] =0 gsize (x:xs) = gsize x + gsize xs test = (gsize [ a , b \n], gsize x ) --Result = (2,1) 4.4 Related work Hughes encountered the need for abstraction over type \nclasses in the context of restricting type parameters of abstract data type constructors [Hug99]. For \ninstance, an operation for a membership test could be of potentially different types, depending on the \nactual data type constructors: --An Eq constraint would be fine --for a simple set data type member \n:: Eq a => a -> PlainSet a -> Bool --An Ord constraint would be more efficient --for binary trees \nmember :: Ord a => a -> BinTree a -> Bool Hence, the type could not be de.ned once and for all in a \ntype class. Hughes therefore proposed to enable restricted algebraic data types, where PlainSet and BinTree \nwill be constrained, and these constraints are implied by any use of the restricted data types 5 As of \nwriting this paper, compiler support is limited to the previous form of Data instances, but the source \ndistribution for this paper includes templates (in the sense of Template Haskell) for the new form of \nData instances. Figure 1. Self-contained sample code for generic size in type signatures or otherwise. \nHughes proposed abstraction over type classes as an aid for the simulation of restricted data types. \nFor instance, a collection class would be parameterised as follows: class Collection c cxt where member \n:: cxt a=> a-> c a-> Bool Hughes made the point that restricted data types should receive ex\u00adtra language \nsupport, since the simulation based on classes pa\u00adrameterised in classes would require that the programmer \nantici\u00adpates extra parameters for constraints when designing classes such as Collection. In our case, \nthe parametrisation in a superclass of Data is intuitive, which makes classes parameterised in classes \nan appropriate technique for SYB. Hughes encoding of abstraction over type classes comprised the Sat \nclass, but the assumption was made that existing classes should readily serve as parameters of other \nclasses. In the SYB context, we need abstraction over type classes for the provision of new classes that \nimplement generic functions. In fact, the default instance of such a new class (or the default method \nof the class) is the one and only client of the explicit dictionary.  5. Recursive dictionaries Suppose \nwe try to evaluate the expression (gsize x ) for the program of Figure 1. The call to gsize gives rise \nto the constraint Size Char, which the type checker must discharge. Let us see how the constraint can \nbe satis.ed: Size Char . Data SizeD Char Instance head Size t . Sat (SizeD Char) Instance head Data \ncxt Char . Size Char Instance head Sat (SizeD t) ... etc. ...  To satisfy the constraint Size Char \nwe select the generic instance with the head Size t (because there is no Size instance that is speci.c \nto Char). Using that instance declaration means that we must now satisfy Data SizeD Char. We use the \ninstance dec\u00adlaration for (Data cxt Char), also given in Figure 1, which in turn means that we must satisfy \nSat (SizeD Char). Using the in\u00adstance declaration for Sat (SizeD t) means that we need to sat\u00adisfy Size \nChar but this is the very constraint from which we started dictionary construction. There is a danger \nthat constraint solving will fail to terminate. Indeed, the instance declaration for (Data cxt Char) \nis not legal Haskell 98: instance Sat (cxt Char) => Data cxt Char where gmapQ _ fn =[] The instance \nis illegal because the context (before the => ) does not consist of simple constraints; that is, constraints \nof the form C a1 ...an , where the ai are just type variables. Haskell 98 imposes this restriction on \ninstance constraints precisely in order to ensure that constraint-solving always terminates. GHC requires \nthe .ag -fallow-undecidable-instances to accept the instance decla\u00adration, to highlight the danger of \nnon-termination. (Hugs also sup\u00adports such a .ag.) Incidentally, this problem is not caused by the Sat \nencoding; it would arise, in the same way, if parameterisation over type classes were directly supported. \n(The problem arises even for a hard-coded superclass, as discussed in Section 3.1.) 5.1 Cycle-aware constraint \nresolution For the present scenario, however, there is a simple solution to the non-termination problem: \nbuild a recursive dictionary. To this end, a Haskell type checker must detect and discharge cycles in \nconstraint resolution. We will now specify and assess the approach taken in GHC. We presume that constraint \nresolution is modelled by a function solve(S,C) that solves a constraint C, by deducing it from a set \nof given constraints S. Recursive dictionaries require the following behaviour: solve(S,C) = succeed, \nif C . S = solve(S . C,(D1 ,.. .,Dn )) if there is a unique instance declaration that can be instantiated \nto the form (D1 ,...,Dn ) => C = fail, otherwise The key point is that in the recursive call to solve, \nwe add C to the given constraints S before trying to solve the sub-problems (D1 ,...,Dn ). Dictionary \nconstruction is merely an elaboration of this scheme for constraint resolution. In each step, the algorithm \nneeds to construct a dictionary to witness the solution, and the effect of adding C to S before the recursive \ncall is to build a recursive dictionary. This technique does not guarantee that solve will terminate, \nof course. Consider the following declaration: instance Foo [[a]] => Foo [a] where ... Using this declaration \nto satisfy constraint Foo [Char], say, sim\u00adply yields a more complicated constraint Foo [[Char]], and \nso on. Adding C to S before the recursive call does not solve the halt\u00ading problem! It just makes solve \nterminate more often. This technique does not guarantee either that the recursively dictionary is useful. \nConsider the following declaration: instance Foo [a] => Foo [a] where ... The type checker will terminate \nall right, but only by building a dictionary that is de.ned to be equal to itself; any attempt to use \nmethods from the dictionary will loop at run-time. One might be able to impose useful restrictions on \nthe form of instance heads so that well-founded recursion is enforced. This re.nement is likely to require \na global analysis of the program in question. We leave this as a topic for future work. 5.2 Related \nwork The general idea of adding a goal to the set of known facts before attempting to prove its sub-goals \nis, of course, far from new it amounts to a co-inductive proof rather than an inductive one. In the \nprogramming-language area it crops up when one attempts to decide the subtyping relation on recursive \ntypes [Car86, BH97, Pie02, LS04]. Our application is unusual in that we derive a re\u00adcursive proof term \nfrom the co-inductive proof, namely a recursive de.nition of the dictionary we seek. Our approach also \nshares sim\u00adilarities with tabling and other attempts in logic programming that improve the termination \nbehaviour of depth-.rst search and SLD resolution [SSW00]. Hughes s paper [Hug99] also mentioned the \ndesirability of de\u00adtecting loops in context reduction, but for a different reason, and with a different \n(and less satisfying solution). His problem con\u00adcerned instance declarations that looked like instance \nSat (EqD a) => Eq a instance Eq a => Sat (EqD a) His proposal was that when an in.nite loop like this \nwas detected, the context-reduction search should back-track, and seek an alter\u00adnative way to satisfy \nthe constraints. Our proposal is quite different. Looping context reductions suc\u00adceed, and build a recursive \ndictionary, rather than failing as Hughes suggests. This extension to Haskell s context-reduction mechanism \nhas been suggested several times. Here is a recent example. A pro\u00adgrammer wanted to de.ne and use the \nFix data type: data Fix f = In (f (Fix f)) data List ax= Nil | Cons a x instance (Eq a, Eq x) => Eq \n(List a x) where Nil == Nil = True (Cons a b) == (Cons c d) = a== c&#38;&#38; b == d other1 == other2 \n= False Subject to an instance for Fix, we would like to test for equality of lists like the following: \ntest1, test2 :: Fix (List Char) test1 = In Nil test2 = In (Cons x (In Nil)) The expression (test1 \n== test2) should evaluate to False! Equality on such lists ought to work because data structures are \n.nite, and so are the types. But how can we give the equality instance for Fix? Here is the obvious attempt; \nthe instance head paraphrases the data type declaration for Fix: instance Eq (f (Fix f)) => Eq (Fix f) \nwhere (In a) == (In b) = a== b Now, the expression (test1 == test2) gives rise to the constraint Eq \n(Fix (List Char)), whose simpli.cation resembles unfold\u00ading steps of a recursive data type constructor: \nEq (Fix (List Char)) . Eq (List (Fix (List Char))) Instance Eq (Fix f) . Eq (Fix (List Char)) Instance \nEq (List a x) . Eq (List (Fix (List Char))) ... etc. ...  In this case, too, building a recursive dictionary \nis precisely the right thing to do. Of course we need a recursive function, if we are to compute equality \non a recursive type, and Fix (List Char) is indeed a recursive type, albeit indirectly.  6. Case study: \nQuickCheck As a real-life illustration of the ideas of this paper, we now describe the shrink function \nfrom the QuickCheck library, referred to in the Introduction. For the sake of a concise notation, we \nwill pretend that Haskell supports abstraction over classes, but everything in this section is readily \nencoded using Section 4; the actual code is in the source distribution that comes with the paper. The \nHaskell library QuickCheck makes it easy to test functions. It generates random data of the appropriate \ntype, feeds it to the function, and checks that the result satis.es a programmer-supplied criterion. \nQuickCheck is described by a fascinating series of papers [CH00, CH02b], but we concentrate here on a \nmore recent devel\u00adopment: its ability to re.ne failing cases. When QuickCheck .nds inputs that make the \nfunction under test fail, these inputs are of\u00adten not the smallest ones that make it fail. So it makes \nsense to successively shrink the failing input, until it no longer fails. This technique turns out to \nwork surprisingly well in practise. What is needed, then, is an overloaded function shrink that takes \na value and returns a list of values of the same type, that have been shrunk by one step : class Shrink \na where shrink :: a -> [a] shrinkProxy :: Proxy Shrink shrinkProxy = error \"urk\" We return a list, \nbecause there is often more than one way to shrink a value, and there may be none (e.g., an integer cannot \nbe shrunk). A step is the smallest shrinkage we can do to the value; by applying shrink many times, we \ncan shrink a value by more than one step. There are two obvious generic strategies for shrinking a value \nv: 1. Choose one of v s sub-components, where that sub-component is of the same type as v. For example, \none way to shrink a list (x:xs) is to return just xs, because xs has the same type as (x:xs). 2. Shrink \none (and only one) of v s (immediate) sub-components by one step. For example, to shrink a pair (a,b) \nwe can either shrink a or shrink b.  These strategies suggest the following generic Shrink instance: \ninstance Data Shrink a => Shrink a where shrink t = children t ++ shrinkOne t In the next two sections, \nwe will write the helper functions children and shrinkOne. Meanwhile, whenever the user intro\u00adduces a \nnew data type Foo, she can either do nothing (and get the generic instance above), or give an explicit \ninstance declaration to override it. The user may want to provide a data type-speci.c in\u00adstance in order \nto ensure invariants during shrinking. For example: data ListWithLength a = LWL [a] Int --Invariant: \n--the Int is the length of the list instance Data Shrink a => Shrink (ListWithLength a) where shrink \n(LWL [] n) = [] shrink (LWL (x:xs) n) = LWL xs (n-1) : [ LWL xs n | xs <-shrinkOne xs] 6.1 Finding \ncompatibly-typed children Let s write children .rst. It is a generic function with the following type: \n children :: Data Shrink a => a -> [a] Its business is to look at each of the sub-components of its \nargu\u00adment, and return the largest subcomponents that have the same type as the argument. (For simplicity, \nwe will limit ourselves to im\u00admediate subcomponents here.) The de.nition of children makes use of the \ntype-safe cast operation: children :: Data Shrink a => a -> [a] children t = [c | Just c <-gmapQ shrinkProxy \ncast t] Recall the type of cast: cast :: (Typeable a, Typeable b) => a -> Maybe b where Typeable is \na superclass of Data. The call (cast x) re\u00adturns Just x if the context needs a value of the same type \nas x (that is, a=b), and Nothing otherwise. The generic map function, gmapQ applies cast to each of t \ns immediate children, in a context that requires the result to have the type Maybe t, where t has type \nt, so all we need do is to collect the Just members of this list. Note that we pass shrinkProxy to gmapQ, \neven though cast does no shrinking; it needs only Typeable. We need to choose some proxy to comply with \ngmapQ s type, and we have a (Data Shrink a) dictionary to hand. 6.2 Shrinking sub-components Writing \nshrinkOne generically is a little harder. Recall that (shrinkOne t) should apply shrink to all the immediate \nsub\u00adcomponents of t, and construct shrunken versions of t from the result. For example, suppose that: \nshrinkOne x = [x1] shrinkOne y = [y1,y2] then the result of shrinking the pair (x,y) is this: shrinkOne \n(x,y) = [(x1,y), (x,y1), (x,y2)] Notice that each result has just one shrunken component. Before thinking \nabout implementing a generic shrinkOne, let us write a particular case. Here is shrinkOne for pairs: \nshrinkOnePr :: (Shrink a, Shrink b) => (a,b) -> [(a,b)] shrinkOnePr (x,y) = [(x ,y) | x <-shrink x] ++ \n[(x,y ) | y <-shrink y] The more components, the more similar-looking list compre\u00adhensions we have to \nwrite. It would be nicer and we are antici\u00adpating our needs for generic programming to use do-notation: \nshrinkOnePr :: (Shrink a, Shrink b) => (a,b) -> [(a,b)] shrinkOnePr (x,y) = do { x <-shrink x ; y \n<-shrink y ; return (x , y ) } This would not work, partly because the list monad forms all combinations \nof the results as opposed to combinations with one shrunk position only, and partly because there are \nno combinations that include the original x and y. We can solve both problems with a single blow, by \nusing a different monad, like this: data Sa =Sa [a] shrinkS :: Shrink a => a -> S a shrinkS t = S t \n(shrink t) The idea is that (shrinkS t) returns a pair (S tts), con\u00adtaining the original argument t \nand a list of one-step shrunken ver\u00adsions of t. Then we give an instance declaration that makes S into \na monad, in a different way to lists, with a more selective way of combining its components. For example: \ndo { x <-Sx [x1] ; y <-S y [y1,y2] ; return (x ,y ) } returns the list [(x1,y), (x,y1), (x,y2)]. Furthermore, \nthe same pattern works no matter how many components are involved. Here is how we make S into a monad: \ninstance Monad S where return x=S x[] (S xxs) >>= k = S r (rs1 ++ rs2) where S rrs1 =k x rs2 = [r \n| x<-xs, let Sr_ =k x] The case for return is easy. Now recall that (>>=) has type: (>>=) :: Monad m=> \nma -> (a -> mb) -> mb The un-shrunk result r is obtained by passing the un-shrunk part x of the .rst \nargument (S xxs) to the rest of the computation k, and taking the un-shrunk part of the result. The shrunk \nparts of (k x), namely rs1 are useful too, because they are shrunk by one step, and so form part of the \nresult. The other one-step shrunken results, rs2, are obtained by taking the shrunken parts xs of the \n.rst argument, passing them to the rest of the computation k, and taking the un-shrunken part of its \nresult. Now we can indeed write shrinkOnePr with do-notation, us\u00ading S as its result type: shrinkOnePr \n:: (Shrink a, Shrink b) => (a,b) -> S (a,b) shrinkOnePr (x,y) = do { x <-shrinkS x ; y <-shrinkS y \n ; return (x , y ) } All that remains is to do this generically. Since we want to combine results monadically, \nthe combinator we need is the monadic map gmapM, a cousin of gmapQ [LP03]: gmapM :: (Monad m, Data cxt \na) => Proxy cxt -> (forall b. Data cxt b => b -> m b) -> a-> ma Although gmapM is, in reality, de.ned \nusing the yet-more-general combinator gfoldl, it can best be understood through its instances. For example, \nhere is the instance for pairs: instance (cxt (a,b), Data cxt a, Data cxt b) => Data cxt (a,b) where \n gmapM _ f (x,y) = do {x <-f x ;y <-f y ; return (x ,y ) } Comparing this de.nition of gmapM for \npairs with shrinkOnePr above, it should be clear that the generic code for shrinkOne is simply this: \nshrinkOne :: Data Shrink a => a -> [a] shrinkOne t = ts where S _ ts = gmapM shrinkProxy shrinkS t  \n6.3 Summary This example shows nicely how important it is to have extensible generic functions. QuickCheck \nis a library and cannot, of course, anticipate all the data types that its clients will de.ne. Furthermore, \nthe clients must be able to override the generic de.nition of shrink at will, because the generic method \nof shrinking might break invari\u00adants of the data structure. Shrinking is just one example of the need \nfor extensible generic functions, but QuickCheck has many others. For example the over\u00adloaded function \narbitrary supports the generation of random data; just like shrink, there is a sensible generic de.nition, \nbut the client must be able to override it. Incidentally, our choice of shrink happens to illustrate \nthe continuing usefulness of the type\u00adsafe cast function.  7. Discussion and variations In this section \nwe discuss various alternative design choices, and contrast the approach described here with our earlier \nwork. 7.1 Run-time type tests Does this paper render obsolete our earlier work on scrap your boilerplate \n[LP03, LP04], which relied on run-time type tests? No, it does not, for several reasons. First, run-time \ntype tests remain extremely useful, as we saw in the Shrink example in Section 6. In Section 7.2, we \nwill also employ cast to model twin traversal. Second, the extra clutter of the context parameters (in \nboth types and terms) is a real disadvantage, especially when generic functions are used in a .rst-class \nway, as we will illustrate in Section 7.3. Third, one sometimes positively wants to enumerate type\u00adspeci.c \ncases explicitly! This issue arises with Haskell s type classes today. Sometimes you have a list of (.rst-name, \nlast-name) pairs: you might want to sort it lexicographically by last name, then by .rst name. But the \nbuilt-in Ord instance for pairs works the other way round, and Haskell gives no way to use different \ninstances at different places in the program [WB89]. This often prompts programmers to de.ne new data \ntypes, but that does not work when you want to sort a single type in more than one way. Indeed, Haskell \ns Prelude has a function sortBy that takes an ex\u00adplicit function to use as the ordering. In short, the \nwhole approach of using instance declarations to incrementally extend functions (whether generic or not) \nis rather global ; if you want more local behaviour then the classic SYB approach might be better. Lastly, \njust as dynamic types support run-time composition of values that cannot be statically type-checked, \nso extQ and friends allow the special cases of a generic function to be composed dy\u00adnamically. 7.2 Twin \ntraversal We may wonder about the generality of the new SYB style. Can we rephrase all classical generic \nprogramming examples as listed in [LP03, LP04] so that the generic functions are open rather than closed? \nThere is one challenge: multi-parameter traversal in particular, twin traversal as in generic equality. \nIn old style, we had proposed the following de.nition of generic equality [LP04]: geq :: Data a => a \n-> a -> Bool geq x y= geq xy where geq :: forall a b. (Data a,Data b) => a-> b-> Bool geq x y = (toConstr \nx == toConstr y) &#38;&#38; and (gzipWithQ geq x y) Here gzipWithQ is a generic variation on the standard \nzipWith operation. It zips two lists of immediate subterms ( kids ). When recursing into kids with gzipWithQ, \nwe use an independently polymorphic generic equality; c.f. forall a b in the type of geq . Clearly, if \nwe wanted to rephrase this approach directly to the new style with class , we will naturally end up requiring \ntype\u00adclass parameterisation for classes with two parameters. Alas, our parameterisation of Data is restricted \nto classes with a single type parameter. Why do we need independent polymorphism? The recursion into \nkids, (gzipWithQ geq x y) uses curried generic maps such that one generic map processes the kids of x \nto compute a list of partial applications of geq that are used in an accumulator position when processing \nthe kids of y with another generic (and accumulating) map. In order to model the list of partial applications \nas a normal homogeneous list, each partial application must be a generic function. (That is, we cannot \nrecord the types of the kids of x in the types of the partial applications.) This forced genericity of \npartial applications implies independent polymorphism. Existential quanti.cation combined with cast comes \nto our res\u00adcue. We can eliminate the heterogeneity of kid types, and thereby use a dependently polymorphic \ngeq in recursive calls. This new technique works equally well for both old and new SYB style. We start \nwith an envelope that wraps castable values. The only way to access such an envelope is indeed by casting: \ndata Pack = forall x. Typeable x => Pack x unpack :: Typeable a => Pack -> Maybe a unpack (Pack x) \n= cast x Processing the kids of x and y is organised as an accumulating generic map over the kids of \ny, where the kids of x contribute the initial accumulator value in the form of a list of Packed kids. \ngeq :: Data a => a -> a -> Bool geq x y = let ([], bools) = gmapAccumQ geq x y in and ((toConstr x \n== toConstr y) : bools) where x = gmapQ Pack x geq :: Data y => [Pack] -> y -> ([Pack],Bool) geq \n(x:xs) y = (xs, maybe False (geq y) (unpack x)) Note that the single-type-parametric polymorphic operation \ngeq is used for the recursive calls that compare pairs of kids. Hence, we can readily move geq to a generic-function \nclass with a single type parameter. (This is not demonstrated here.) It is a nuisance that we need to \nperform casts for the kids of x. One can easily see that the casts will succeed for the case that x and \ny use the same outermost term constructor. Alas, the type system cannot infer this fact. 7.3 First class \ngeneric functions An attractive feature of our earlier paper [LP03] is that generic functions are .rst \nclass: in particular, they can be passed as ar\u00adguments to other Haskell functions, and they can be returned \nas results. Our new scheme shares this advantage, but the additional static checks make it somewhat less \nconvenient, as we discuss in the rest of this section. A potent application of .rst-class status is the \nability to modu\u00adlarise algorithms into tree traversal and node processing. For exam\u00adple, here is the \nde.nition of everywhere, taken from the original SYB paper: --Old type everywhere :: Data a => (forall \nb. Data b => b -> b) -> a -> a The call (everywhere f t) takes a generic function f and a data structure \nt, and applies f to every node in t. Indeed, by writing a type synonym we can make the type even more \nperspicuous: type GenericT = forall a. Data a => a -> a everywhere :: GenericT -> GenericT A generic \ntransformer GenericT has type a->a, for any type a that is traversable (lies in class Data). The everywhere \ncombinator takes a generic transformer that works on individual nodes, and returns a transformer that \nworks on the entire tree. Matters are not so easy now that Data has an extra parameter. To begin with, \neverywhere s type must look more like this: type GenericT cxt = forall b. Data cxt b => b -> b everywhere \n:: GenericT cxt -> GenericT cxt In addition, everywhere needs a proxy type parameter, just like gmapQ \nand its cousins (Section 4.2). So everywhere s type is actually this one: everywhere :: Proxy cxt -> \nGenericT cxt -> GenericT cxt (For the record, we can eliminate some proxy arguments in nested compositions \nof generic functions by means of implicit parame\u00adters [LLMS00].) Now suppose we want to make an actual \ntraver\u00adsal (everywhere pickyCtx pickyInc t) where the node\u00adprocessing function pickyInc is de.ned like \nthis: pickyInc :: ( Data IncEligible t , Data IncSalary t )=> t -> t pickyInc t | incEligible t = \nincSalary t | otherwise = t The details of this restricted function for salary increase do not matter; \nwhat is important is that pickyInc s context has two con\u00adstraints. Alas, that makes it incompatible with \neverywhere, which passes exactly one dictionary to its argument (see everywere s type above). Hence, \nthere is no straightforward way to provide the needed type-proxy argument pickyCtx. Assuming that Haskell \nprovides proper abstraction over type classes, one option is to combine IncEligible and IncSalary into \na single class, thus: class (IncEligible a, IncSalary a) => PickyInc a --no methods needed We instantiate \nthis class as follows: instance (IncEligible a, IncSalary a) => PickyInc a Clearly, we prefer a (non-Haskell \n98) generic instance here because we do not want to re-enumerate all types covered by IncEligible and \nIncSalary. The adapted de.nition of pickyInc is constrained by the new helper class: pickyInc :: Data \nPickyInc t => t -> t pickyInc = ... as before ... One could imagine a more sophisticated form of abstraction \nover classes, that automates this clutter, so that a single ctx pa\u00adrameter may transport several constraints \ninstead of just one. This is a topic for future work. When we consider the encoding for abstraction over \ntype classes, as de.ned in Section 4.1, we may avoid the de.nition of a helper class, but we must provide \na composed dictionary type a product of the dictionary types for IncEligible and IncSalary: data PickyIncD \na = PickyIncD { dictE :: IncEligibleD a, dictI :: IncSalaryD a } The corresponding Sat instance will \nsimply construct a pair of dictionaries taking advantage of preexisting Sat instances for IncEligibleD \nand IncSalaryD. Now, to call incSalary we need to extract it from two layers of wrapping: incSalary :: \nData PickyIncD a => a -> Int incSalary = incSalaryD (dictI dict) This proliferation of different versions \nof the same generic function is tiresome.  8. More related work The overall Scrap your boilerplate approach \nhas been compared to other work on generic programming in detail in [LP03, LP04]. Likewise, we discussed \nwork related to type-class parameterisation and recursive dictionaries in the respective sections. Therefore, \nwe are going to focus here on the new enhancement: open, generic functions. 8.1 Derivable type classes \nThe derivable type classes approach to generic programming [HP00] is closely related to the work we describe \nhere. Both ap\u00adproaches assume that a generic function is de.ned as a method of a type class, and that \nthe programmer writes type-speci.c cases sim\u00adply by giving an ordinary instance declaration. The big \ndifference is that in the derivable-type-class approach, the class de.nition spec\u00adi.es a kind of template \nthat can be used to generate the boilerplate; for example: class Size a where gsize :: a -> Int --Code \nnot correct gsize {| Unit |} Unit = 1 gsize {| a:*: b|} (a :*: b) = gsize a +gsize b gsize {| a :+: b \n|} (Inl a) = gsize a gsize {| a :+: b |} (Inr b) = gsize b instance Size [a] instance Size (a,b) The \nde.nition of gsize in the class declaration is a kind of generalised default method. The argument in \nthe funny brackets {|..|} is a type argument, and the function is de.ned by induction over the structure \nof the type. For each instance declaration that does not give an explicit method de.nition, such as the \nones for lists and pairs here, the compiler generates a method from the template, by converting the instance \ntype to a sum-of-products form, and passing it to the generic code. It can be tricky to get the generic \ncode right; in this case, there is a bug in gsize because it counts 1 only for nullary constructors! \nFixing this requires a second method in the class, which is quite annoying. Derivable type classes require \nconsiderable compiler support. The mechanism we propose here requires much less, and what we do need \nis useful for other purposes. 8.2 Generic Haskell speci.cally In more recent versions of Generic Haskell \n[CL03, LCJ03], generic function de.nitions can involve some sort of default cases. This allows the programmer \nto fabricate customised generic functions while reusing fully generic functions as a kind of default. \nThis is a major improvement over earlier polytypic programming prac\u00adtise, where types-speci.c cases (if \nany) had to form an integral part of the polytypic function declaration. Generic Haskell s de\u00adfault cases \nproperly support capture of recursion. That is, recursive occurrences of the reused generic function \nare properly redirected to the reusing (i.e., customised) generic function. Our development shows that \nHaskell s existing type-class mech\u00adanism can be readily leveraged for open, generic functions with appropriate \ncapture of recursion. Generic Haskell (including its support for customisation) requires very considerable \ncompiler support, in fact, a new compiler. 8.3 Generics for the masses Hinze s recent generics for the \nmasses approach [Hin04] is sim\u00adilarly lightweight as Scrap your boilerplate . The distinguishing feature \nof Hinze s new proposal is that it captures essential idioms of Generic Haskell in a Haskell 98-based \nmodel, which requires absolutely no extensions. The generics for the masses approach exhibits an important \nlimitation in the view of generic function customisation. That is, the class for generics would need \nto be adapted for each new type or type constructor that requires a speci.c case. This is a pernicious \nform of non-modularity. Hinze has identi.ed this issue and its consequences: the approach is not useful \nfor a generic programming library. 8.4 Intensional type analysis Intensional type analysis [HM95] has \nmade major contributions to the notions typecase and induction on type structure. The earlier work favours \nstructural type equivalence, where the notion of a nominal branch in a typecase does not occur. An exception \nis the re\u00adcent lambda calculus .L [VWW05], where the typecase construct can involve branches for user-de.ned \ntypes. This calculus also ad\u00addresses another limitation of early work on intensional type anal\u00adysis: \nit allows one to compute the branches in a typecase expres\u00adsion by a join operation. So one can parameterise \nin branches. Pa\u00adrameterisation in classic SYB functions is similar in effect. Hence, .L does not yet \nsupport modular customisation. Likewise, all other techniques that aim at enabling type-safe cast as \nan operation in a functional language, e.g., [Wei00, BS02, CH02a], do not support modular customisation. \n 9. Conclusions and further work We have used type-class abstraction and recursive type-class dic\u00adtionaries \nto support open, generic functions in an enhanced Scrap your boilerplate approach (aka SYB). This makes \nSYB useful for a new range of generic programming applications, namely ones that require generic functions \nthat can later be customised as new data types are added. QuickCheck is a good example, but other include: \nprovision of system-wide generic equality, read, show, and friends; serialisation libraries in the XML \ncontext; extensible language im\u00adplementation frameworks; and re.nement of generic functions even on .xed \ndata types. The .rst SYB paper focused on traversal problems ( generic consumers ) for complex data structures, \nsuch as those correspond\u00ading to data models or language syntaxes. The second paper added support for \ngeneric builders (the opposite of generic consumers or traversals), and it described a number of speci.c \ntechniques such as type case for type constructors and multi-parameter traversal. The present, third \npaper complements cast-based customisation by type-class-based customisation, which we had until recently \nbe\u00adlieved to be impossible. There is plenty left to do. The new proposed extensions for re\u00adcursive dictionaries \nand type-class abstraction deserve dedicated study of their own: termination conditions for generalised \ninstance heads, well-foundedness conditions for the constructed recursive dictionaries, type system formalisation \nfor type-class parameterisa\u00adtion and context composition. In addition, some correspondence re\u00adsults for \ndifferent styles of generic programming need to be discov\u00adered. For instance, can we encode all of derivable \ntype classes? Fi\u00adnally, new application domains of generic programming are ready to be explored: we have \nargued that .rst-class generic functions fa\u00adcilitate computation of generic functions. This calls for \nresearch on generic function memoisation and adaptive generic algorithms.  Acknowledgements We thank \nKoen Claessen and Simon Foster for their thoughtful critique of our early SYB approaches leading to the \ninsight that extensible generic functions are urgently needed. Many thanks to James Cheney, Simon Mar\u00adlow \nand Fermin Reig for helpful feedback on drafts of this paper. We also acknowledge the opportunity to \npresent this work at a Generic Haskell meeting in January 2005. Ulf Norell, Sean Seefried and Simon Foster \ncon\u00adtributed Template Haskell code for the derivation of instances of the Data class. We are grateful \nfor helpful comments by the ICFP referees. References [BH97] Michael Brandt and Fritz Henglein. Coinductive \naxiomatization of recursive type equality and subtyping. In Proc 3rd International Conference on Typed \nLambda Calculi and Appliactions (TLCA 97), Nancy, France, volume 1210 of Lecture Notes in Computer Science, \npages 63 81. Springer Verlag, 1997. [BS02] A.I. Baars and S.D. Swierstra. Typing dynamic typing. In Proceedings \nof the ACM SIGPLAN International Conference on Functional Programming (ICFP 2002), pages 157 166. ACM \nPress, 2002. [Car86] L Cardelli. Amber. In G Cousineau, PL Curien, and B Robinet, editors, Combinators \nand functional programming languages. LNCS 242, Springer Verlag, 1986. [CH00] Koen Claessen and John \nHughes. QuickCheck: a lightweight tool for random testing of Haskell programs. In ACM SIG-PLAN International \nConference on Functional Programming (ICFP 00), pages 268 279, Montreal, September 2000. ACM. [CH02a] \nJ. Cheney and R. Hinze. A lightweight implementation of generics and dynamics. In Proceedings of the \nACM SIGPLAN Workshop on Haskell, pages 90 104. ACM Press, 2002. [CH02b] Koen Claessen and John Hughes. \nTesting monadic code with QuickCheck. In Manuel Chakravarty, editor, Proceedings of the 2002 Haskell \nWorkshop, Pittsburgh, October 2002. [CL03] Dave Clarke and Andres L\u00a8oh. Generic Haskell, Speci.cally. \nIn Proceedings of the IFIP TC2/WG2.1 Working Conference on Generic Programming, pages 21 47. Kluwer, \nB.V., 2003. [Fos05] Simon D. Foster. HAIFA: The Haskell Application Inter\u00adoperation Framework Architecture \n; web site, 2004 2005. http://www.repton-world.org.uk/mediawiki/index. php/HAIFA_Wiki. [Hin04] Ralf Hinze. \nGenerics for the masses. In Proceedings of the ACM SIGPLAN International Conference on Functional Programming \n(ICFP 2004), pages 236 243. ACM Press, 2004. [HM95] Robert Harper and Greg Morrisett. Compiling polymorphism \nusing intensional type analysis. In Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles \nOf Programming Languages (POPL 1995), pages 130 141. ACM Press, 1995. [HP00] Ralf Hinze and Simon Peyton \nJones. Derivable type classes. In Graham Hutton, editor, Proceedings of the 2000 Haskell Workshop, Montreal, \nnumber NOTTCS-TR-00-1 in Technical Reports, September 2000. [Hug99] RJM Hughes. Restricted data types \nin haskell. In Erik Meijer, editor, Proceedings of the 1999 Haskell Work\u00adshop, number UU-CS-1999-28 in \nTechnical Reports, 1999. ftp://ftp.cs.uu.nl/pub/RUU/CS/techreps/CS-1999/1999-28.pdf. [LCJ03] Andres L\u00a8oh, \nDave Clarke, and Johan Jeuring. Dependency\u00adstyle Generic Haskell. In Proceedings of the ACM SIGPLAN International \nConference on Functional Programming (ICFP 2003), pages 141 152. ACM Press, August 25 29 2003. [LLMS00] \nJeffrey R. Lewis, John Launchbury, Erik Meijer, and Mark B. Shields. Implicit parameters: dynamic scoping \nwith static types. In Proceedings of the 27th ACM SIGPLAN-SIGACT Symposium on Principles Of Programming \nLanguages (POPL 2000), pages 108 118. ACM Press, 2000. [LP03] Ralf L\u00a8ammel and Simon Peyton Jones. Scrap \nyour boilerplate: a practical approach to generic programming. In ACM SIGPLAN International Workshop \non Types in Language Design and Implementation (TLDI 03), pages 26 37, New Orleans, January 2003. ACM. \n[LP04] Ralf L\u00a8ammel and Simon Peyton Jones. Scrap more boilerplate: re.ection, zips, and generalised \ncasts. In ACM SIGPLAN Inter\u00adnational Conference on Functional Programming (ICFP 04), pages 244 255, Snowbird, \nUtah, September 2004. ACM. [LS04] K Zhuo Ming Lu and M Sulzmann. An implementation of subtyping among \nregular expression types. In Proc Asian Programming Languages Symposium (APLAS 04), volume 3302 of Lecture \nNotes in Computer Science, pages 57 73. Springer Verlag, 2004. [Pie02] Benjamin Pierce. Types and programming \nlanguages. MIT Press, 2002. [SP02] T Sheard and SL Peyton Jones. Template meta-programming for Haskell. \nIn Manuel Chakravarty, editor, Proceedings of the 2002 Haskell Workshop, Pittsburgh, October 2002. [SSW00] \nKonstantinos F. Sagonas, Terrance Swift, and David Scott Warren. An abstract machine for ef.ciently computing \nqueries to well-founded models. J. Log. Program., 45(1-3):1 41, 2000. [VWW05] Dimitrios Vytiniotis, Geoffrey \nWashburn, and Stephanie Weirich. An Open and Shut Typecase. In Proceedings of the ACM SIGPLAN Workshop \non Types in Language Design and Implementation (TLDI 2005). ACM Press, January 2005. [WB89] PL Wadler \nand S Blott. How to make ad-hoc polymorphism less ad hoc. In Proc 16th ACM Symposium on Principles of \nProgramming Languages, Austin, Texas. ACM, January 1989. [Wei00] S. Weirich. Type-safe cast: (functional \npearl). In Proceedings of the ACM SIGPLAN International Conference on Functional Programming (ICFP 2000), \npages 58 67. ACM Press, 2000.  \n\t\t\t", "proc_id": "1086365", "abstract": "The 'Scrap your boilerplate' approach to generic programming allows the programmer to write generic functions that can traverse arbitrary data structures, and yet have type-specific cases. However, the original approach required all the type-specific cases to be supplied at once, when the recursive knot of generic function definition is tied. Hence, generic functions were <i>closed</i>. In contrast, Haskell's type classes support <i>open</i>, or extensible, functions that can be extended with new type-specific cases as new data types are defined. In this paper, we extend the 'Scrap your boilerplate' approach to support this open style. On the way, we demonstrate the desirability of abstraction over type classes, and the usefulness of recursive dictionarie.", "authors": [{"name": "Ralf L&#228;mmel", "author_profile_id": "81100095823", "affiliation": "Microsoft Corp.", "person_id": "PP18000329", "email_address": "", "orcid_id": ""}, {"name": "Simon Peyton Jones", "author_profile_id": "81100271851", "affiliation": "Microsoft Research", "person_id": "PP43121273", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1086365.1086391", "year": "2005", "article_id": "1086391", "conference": "ICFP", "title": "Scrap your boilerplate with class: extensible generic functions", "url": "http://dl.acm.org/citation.cfm?id=1086391"}