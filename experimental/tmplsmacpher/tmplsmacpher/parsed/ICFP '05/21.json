{"article_publication_date": "09-12-2005", "fulltext": "\n Invited Talk Mechanizing the Meta-theory of Programming Languages Robert Harper Carnegie Mellon University \nPittsburgh, PA 15217 rwh@cs.cmu.edu Abstract What does it mean for a programming language to exist? \nUsually languages are defined by an informal description augmented by a reference compiler whose behavior \nis regarded as normative. This approach works well so long as the one true implementation suffices, but \nas soon as we wish to have multiple compilers for the same language, we must agree on what the language \nis independently of its implementations. Most often this is accomplished through social processes such \nas standardization committees for building consensus. These processes have served us well, and will continue \nto be important for language design. But they are not sufficient to support the level of rigor required \nto prove theorems about languages and programs written in them. For that we need a semantics, which provides \nan objective foundation for such analyses, typically in the form of a type system and an operational \nsemantics. But merely having such a rigorous definition for a language is not enough --- it must be validated \nby a body of meta-theory that establishes its coherence and its consistency with expectations. But how \nare we to develop and maintain this body of theory? For full-scale languages the task is so onerous as \nto inhibit innovation and foster stagnation. The way forward is to take advantage of the recent advances \nin mechanized reasoning. By representing a language definition within a logical framework we may subject \nit to formal analysis, much as we use types to express and enforce crucial invariants in our programs. \nI will describe our use of the Twelf implementation of the LF logical framework, and discuss our successes \nand difficulties in using it as a tool for mechanizing the meta-theory of programming languages. Bio \nRobert Harper is a professor in the Computer Science Department at Carnegie Mellon University, where \nhe has been a faculty member since 1988. He received his Ph.D. in Computer Science from Cornell University \nin 1985, and was a post-doctoral research fellow at the Laboratory for Foundations of Computer Science \nat Edinburgh University from 1985-1988. He is best known for his work on the design, definition, and \nimplementation of Standard ML; the design and application of the LF logical framework; the type-theoretic \nfoundations of modularity in programming languages; the use of typed intermediate languages for certified \ncompilation; the co-invention of self-adjusting computation for dynamic algorithms; and the application \nof fundamental theory to practical systems. His current interests include the development of a trust-free \nframework for grid computing, enriching the type structure of programming languages, and the application \nof type theory to the description and analysis of hybrid systems. His web site is http://www.cs.cmu.edu/~rwh. \nCopyright is held by the author/owner(s). ICFP 05, September 26 28, 2005, Tallinn, Estonia. ACM 1-59593-064-7/05/0009. \n \n\t\t\t", "proc_id": "1086365", "abstract": "What does it mean for a programming language to exist? Usually languages are defined by an informal description augmented by a reference compiler whose behavior is regarded as normative. This approach works well so long as the one true implementation suffices, but as soon as we wish to have multiple compilers for the same language, we must agree on what the language is independently of its implementations. Most often this is accomplished through social processes such as standardization committees for building consensus.These processes have served us well, and will continue to be important for language design. But they are not sufficient to support the level of rigor required to prove theorems about languages and programs written in them. For that we need a semantics, which provides an objective foundation for such analyses, typically in the form of a type system and an operational semantics. But merely having such a rigorous definition for a language is not enough &#8212; it must be validated by a body of meta-theory that establishes its coherence and its consistency with expectations.But how are we to develop and maintain this body of theory? For full-scale languages the task is so onerous as to inhibit innovation and foster stagnation. The way forward is to take advantage of the recent advances in mechanized reasoning. By representing a language definition within a logical framework we may subject it to formal analysis, much as we use types to express and enforce crucial invariants in our programs. I will describe our use of the Twelf implementation of the LF logical framework, and discuss our successes and difficulties in using it as a tool for mechanizing the meta-theory of programming languages.", "authors": [{"name": "Robert Harper", "author_profile_id": "81100140064", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP39029370", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1086365.1086396", "year": "2005", "article_id": "1086396", "conference": "ICFP", "title": "Mechanizing the meta-theory of programming languages", "url": "http://dl.acm.org/citation.cfm?id=1086396"}