{"article_publication_date": "09-12-2005", "fulltext": "\n Monadic Augment and Generalised Short Cut Fusion Neil Ghani Patricia Johann * Tarmo Uustalu Varmo \nVene University of Leicester Rutgers University Inst. of Cybernetics Univ. of Tartu Leicester LE1 7RH, \nUK Camden, NJ 08102, USA EE-12618 Tallinn, Estonia EE-50409 Tartu, Estonia ng13@mcs.le.ac.uk pjohann@crab.rutgers.edu \ntarmo@cs.ioc.ee varmo@cs.ut.ee Abstract Monads are commonplace programming devices that are used to \nuniformly structure computations with effects such as state, excep\u00adtions, and I/O. This paper further \ndevelops the monadic program\u00adming paradigm by investigating the extent to which monadic com\u00adputations \ncan be optimised by using generalisations of short cut fu\u00adsion to eliminate monadic structures whose \nsole purpose is to glue together monadic program components. We make several contributions. First, we \nshow that every in\u00adductive type has an associated build combinator and an associ\u00adated short cut fusion \nrule. Second, we introduce the notion of an inductive monad to describe those monads that give rise to \nin\u00adductive types, and we give examples of such monads which are widely used in functional programming. \nThird, we generalise the standard augment combinators and cata/augment fusion rules for algebraic data \ntypes to types induced by inductive monads. This allows us to give the .rst cata/augment rules for some \ncommon data types, such as rose trees. Fourth, we demonstrate the practi\u00adcal applicability of our generalisations \nby providing Haskell imple\u00admentations for all concepts and examples in the paper. Finally, we offer deep \ntheoretical insights by showing that the augment com\u00adbinators are monadic in nature, and thus that our \ncata/build and cata/augment rules are arguably the best generally applicable fu\u00adsion rules obtainable. \nCategories and Subject Descriptors D.3.2 [Programming Lan\u00adguages]: Language Classi.cations Applicative \n(functional) lan\u00adguages; F.3.2 [Logics and Meanings of Programs]: Semantics of Programming Languages \nDenotational semantics; F.3.3 [Logics and Meanings of Programs]: Studies of Program Constructs Functional \nconstructs, program and recursion schemes General Terms design, languages, theory Keywords short cut \nfusion, build, augment, monads, bind * Supported in part by National Science Foundation grant CCF-0429072. \nSupported in part by Estonian Science Foundation grant 5567. Supported in part by Estonian Science Foundation \ngrant 5567. Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP \n05 September 26 28, 2005, Tallinn, Estonia. Copyright c . 2005 ACM 1-59593-064-7/05/0009. . . $5.00. \n1. Introduction As originally conceived by Moggi, monads form a useful compu\u00adtational abstraction which \nmodels diverse effects such as stateful computations, exceptions, and I/O in a modular, uniform, and \nprin\u00adcipled manner [13]. Wadler [24] led the call to turn Moggi s theory of effectful computation into \na practical programming methodol\u00adogy, and showed how to use monads to structure such computa\u00adtions. Monads \nare now .rmly established as part of Haskell [16], supported by speci.c language features and used in \na wide range of applications. The essential idea behind monads is the type-safe sep\u00adaration of values \nfrom effectful computations that return those val\u00adues.1 Because monads abstract the nature of effectful \ncomputations, and in particular the mechanism for composing them, monadic pro\u00adgrams are often more highly \nstructured than non-monadic ones which perform the same computational tasks. Monadic programs thus boast \nthe usual bene.ts of structured code, namely being eas\u00adier to read, write, modify, and reason about than \ntheir non-monadic counterparts. However, compositionally constructed monadic pro\u00adgrams also tend to be \nless ef.cient than monolithic ones. In par\u00adticular, a component in such a program will often construct \nan in\u00adtermediate monadic structure i.e., an intermediate structure of type mt where m is a monad and \nt is a type only to have it immediately consumed by the next component in the composition. Given the \nwidespread use of monadic computations, it is natu\u00adral to try to apply automatable program transformation \ntechniques to improve the ef.ciency of modularly constructed monadic pro\u00adgrams. Fusion is one technique \nwhich has been used to improve modularly constructed functional programs, and a number of fu\u00adsion transformations \nappropriate to the non-monadic setting have been developed in recent years [1, 6, 7, 8, 9, 19, 20, 21, \n23]. Perhaps the best known of these is short cut fusion [6], a local transformation based upon two combinators \n build, which pro\u00adduces lists in a uniform manner, and foldr, which uniformly con\u00adsumes them and a single, \noriented replacement rule known as the foldr/build rule. (See Section 3.) The foldr/build rule re\u00adplaces \ncalls to build which are immediately followed by calls to foldr with equivalent computations that do \nnot construct the inter\u00admediate lists introduced by build and consumed by foldr. Elim\u00adinating such lists \nvia short cut fusion can signi.cantly improve the ef.ciency of programs. Unfortunately, there are common \nlist producers such as the append function that build cannot express in a manner suit\u00adable for short \ncut fusion. This led Gill to introduce a list producer, called augment, which generalises build, together \nwith an ac\u00adcompanying foldr/augment fusion rule for lists [5]. This rule has 1 Monads, such as the expression \nmonad in Example 1, which correspond to ordinary algebraic data types can be thought of as having an \neffect of storing data in a data structure. subsequently been generalised to give cata/augment rules \nwhich fuse producers and consumers of arbitrary non-list algebraic data types [8].2 Fusion rules which \nare dual to the foldr/build rule (in a precise category-theoretic sense) [20, 21], and rules which elimi\u00adnate \nlist-manipulating operations other than data constructors [23], have also been developed. This paper \nfurther generalises short cut fusion to rules which eliminate intermediate monadic structures. In order \nto write con\u00adsumers of expressions of type mt in terms of catas we restrict attention to types mt which \nare inductive types in a uniform man\u00adner. We call a monad m with the property that mt is an inductive \ndata type for every type t an inductive monad. Our .rst observation is that build combinators and cata/build \nfusion rules can be de.ned for all inductive types. As we demon\u00adstrate, this opens the way for a generic \ntheory of fusion. Next, we ask whether augment combinators and cata/augment rules can similarly be generically \nde.ned. We show that there are in\u00adductive types which do not support augment combinators (see Section \n4.2), but that a large class of inductive monads do. To de\u00adscribe these monads, we introduce the notion \nof a parameterised monad, and use the observation that the least .xed point of every parameterised monad \nis an inductive monad [22] to de.ne generic augment combinators and cata/augment rules for all such .xed \npoints. We illustrate our results with expression languages, rose trees, interactive input/output monads, \nand hyperfunctions, all of which are commonly used monads arising as least .xed points of parameterised \nmonads. When applied to types for which augment combinators are already known, our results yield more \nexpres\u00adsive augment combinators. On the other hand, the examples in\u00advolving rose trees and interactive \ninput/output monads show that there are well-known and widely used monads for which neither augment combinators \nnor cata/augment fusion rules were previ\u00adously known, but for which we can derive both. Since, as we \nshow in Section 4.3, the bind operations for monads which are least .xed points of parameterised monads \ncan be written in terms of our augment combinators, our cata/augment fusion rules can be applied whenever \nan application of bind is followed by a cata. This is expected to be often, since the bind operation \nis the fun\u00addamental operation in monadic computation. We thus expect our cata/augment fusion rules to \nbe widely applicable. The results detailed in this paper are of practical interest since the cata/augment \nfusion rules we develop have the potential to improve the ef.ciency of modularly constructed programs \nusing a variety of different monads. Our results are of theoretical im\u00adportance as well: they clearly \nestablish the monadic nature of our augment combinators by showing that they are interde.nable with the \nmonadic bind operations. The fact that our results make it possible to de.ne cata/build rules for all \nfunctors, as well as cata/augment rules for all least .xed points of parameterised monads, suggests that \nthey are close to the best achievable. We expect, therefore, that our results will appeal to a variety \nof differ\u00adent audiences. Those who work with monads will be interested in parameterised monads and their \napplications, and those in the pro\u00adgram transformation community will be interested in seeing their ideas \nfor optimising computations successfully deployed in the monadic setting. We hope that, as with the best \ncross-fertilisations of ideas, ours will enable experts in each of these communities to gain greater \nunderstanding of, and facility with, the ideas and mo\u00adtivations of the other. The concrete contributions \nof this paper are as follows: 2 As is standard in Haskell, we use foldr to denote the standard catamor\u00adphism \nfor lists. Catamorphisms for other inductive data types are written as cata. In Section 3 we derive \na build combinator for the least .xed point of any functor, and show how this opens the way for an algebra \nof fusion.  In Section 4 we de.ne the notion of a parameterised monad and show that the least .xed point \nof any parameterised monad is a monad. We use this observation to generalise the standard augment combinators \nfor algebraic data types to give augment combinators for all monads arising as least .xed points of pa\u00adrameterised \nmonads. Finally, we argue that our augment com\u00adbinators are inherently monadic in nature by showing that \nthe augment combinator for each parameterised monad is interde\u00ad.nable with the bind operation for the \nmonad which is its least .xed point via the elegant equality  augment g k = build g >>= k A more general \ndevelopment of augment combinators for a larger class of data types is hard to envisage. In Section \n5 we generalise the standard cata/augment fusion rules for algebraic data types to give cata/augment \nrules for all monads arising as least .xed points of parameterised monads.  We support this development \nwith a variety of running exam\u00adples and a Haskell implementation. The latter can be down\u00adloaded from \nhttp://www.mcs.le.ac.uk/~ng13.  We discuss related work in Section 6 and conclude in Section 7. Throughout \nthe paper we assume as little background of the reader as possible. In particular, no knowledge of category \ntheory is as\u00adsumed or required and, in order to make this paper accessible to as wide an audience as \npossible, the correctness of the fusion rules presented here is given in a separate paper [4]. On the \nother hand, this paper is addressed to the functional programming community and, aside from using the \nsame combinators, is disjoint from [4]. 2. Why monads? Functional programming was recognised early on \nas providing a clean programming environment in which programs are easy to read, write, and prove correct. \nBut the problem of performing ef\u00adfectful computations in a purely functional language without com\u00adpromising \nthe advantages of the functional paradigm proved dif\u00ad.cult to solve. Moggi s very nice solution was to \ntag types with .ags which indicate that effects are associated with values of those types. For example, \nif t is a type and m .ags a particular computational effect, then mt is a new computational type whose \ninhabitants can be thought of as performing effectful computations described by m and (possibly) returning \nresults of type t. For exam\u00adple, the type Int contains integer values, while the computational type State \nEnv Int contains functions which transform the cur\u00adrent state (given by an element of type Env) into \nan integer value and a new state. (See Example 3 below.) In order to program with computational types \nwe need two op\u00aderations. The .rst, called return, lifts any value of the underly\u00ading type to the trivial \ncomputation which returns that value. The second, called bind and written >>=, composes two computations \nwhich have the same type of effect. A .ag m together with its two operations forms a monad. Monads are \nrepresented in Haskell via the type class class Monad m where return :: a-> ma >>= ::ma-> (a -> mb)->mb \nFrom a semantic perspective, return and bind are expected to sat\u00adisfy the three monad laws [13]. These \ncan be thought of as requir\u00ading that the composition of effectful computations be associative and that \nvalues act as left and right units for it. Satisfaction of the monad laws is, however, not enforced by \nthe compiler. Instead, it is the programmer s responsibility to ensure that the return and bind operations \nfor any instance of Haskell s monad class behave appropriately. EXAMPLE 1. The algebraic data type Expr \na represents simple arithmetic expressions. data Ops = Add| Sub |Mul | Div data Expr a =Var a |Lit Int \n| Op Ops (Expr a) (Expr a) instance Monad Expr where return = Var Varx >>=k= kx Liti >>=k= Liti Op op \ne1 e2>>= k = Op op(e1 >>= k) (e2 >>= k) EXAMPLE 2. The type Maybe a consists of values of type a and \na distinguished error value. data Maybe a = Nothing | Just a instance Monad Maybe where return = Just \nNothing >>= k = Nothing Justx >>=k=kx EXAMPLE 3. The type State s a represents computations that can \nchange states of type s while computing results of type a. newtype State s a = State {runState :: s -> \n(a,s)} instance Monad (State s) where return x = State (\\s -> (x,s)) State g >>= k = State (\\s -> let \n(y,t) = g s in runState (k y) t) We conclude this section by demonstrating how monads sys\u00adtematise, simplify, \nand highlight the structure of effectful programs by allowing us to structure them as though they were \nnon-effectful. Suppose we want to write an evaluator eval :: Expr Int -> Int for (closed) expressions \nover the type a. In a non-monadic setting we might have the clause eval (Op Div e1 e2) = (eval e1) div \n(eval e2) together with similar clauses for expressions involving the other arithmetic operators. To \nbetter accommodate exceptions arising, for example, from attempting to divide by 0 we could instead \nuse a monadic evaluator eval :: Expr Int -> Maybe Int and write eval (Op Div e1 e2) = liftM2 div (eval \ne1) (eval e2) Here, liftM2 is a built-in Haskell function which lifts functions over types to functions \nover their corresponding monadic types. Note how the essential structure of the computation remains faith\u00adfully \nrepresented in the de.nition of eval while all error han\u00addling is abstracted and hidden in the use of \nthe monadic operation liftM2. 3. Short cut fusion As already noted, modularly constructed programs tend \nto be less ef.cient than their non-modular counterparts. A major dif.culty is that the direct implementation \nof compositional programs literally constructs, traverses, and discards intermediate data structures \n although they play no essential role in a computation. Even in lazy foldr :: (a ->b -> b) -> b-> [a] \n->b foldrcnxs=casexsof[] ->n z:zs -> cz(foldr cn zs) build :: (forall b. (a -> b -> b) -> b -> b) -> \n[a] build g =g (:)[] augment :: (forall b. (a -> b -> b) -> b -> b) -> [a] -> [a] augment g xs = g (:) \nxs sum :: [Int] -> Int sum xs = foldr (+) 0 xs map ::(a -> b)-> [a] -> [b] map fxs =build (\\c n-> foldr \n(c .f) n xs) Figure 1. Combinators and functions for lists languages like Haskell this is expensive, \nboth slowing execution time and increasing heap requirements. 3.1 Short cut fusion for algebraic data \ntypes Fortunately, fusion rules often make it possible to avoid the creation and manipulation of intermediate \ndata structures. The foldr/build rule [6], for example, capitalises on the uniform production of lists \nvia build and the uniform consumption of lists via foldr to optimise list-manipulating programs. Intuitively, \nfoldr c nxs produces a value by replacing all occurrences of (:) in xs by c and the single occurrence \nof [] in xs by n.For instance, foldr (+) 0 xs sums the (numeric) elements of the list xs. The function \nbuild, on the other hand, takes as input a function g providing a type-independent template for construct\u00ading \nabstract lists, and produces a corresponding concrete list. For example, build (\\cn -> c3 (c 7 n)) produces \nthe list [3,7]. The Haskell de.nitions of foldr and build, as well as those of other list-processing \nfunctions used in this paper, are given in Figure 1. The recursive combinator foldr is standard in the \nHaskell prelude. The foldr/build rule serves as the basis for short cut fusion. It states that, for every \nclosed type t and every closed function g:: forall b.(t -> b-> b) -> b -> b, foldr cn (build g) =g cn \n(1) Here, type instantiation is performed silently, as in Haskell. When this law, considered as a replacement \nrule oriented from left to right, is applied to a program, it yields a new program which avoids constructing \nthe intermediate list produced by build g and immediately consumed by foldr c n in the original. Thus, \nif sum and map are de.ned as in Figure 1, and if sqrx= x*x, then sumSqs :: [Int] -> Int sumSqs xs = sum \n(map sqr xs) = foldr (+) 0 (build (\\c n -> foldr (c . sqr) n xs)) = (\\c n -> foldr (c . sqr) n xs) (+) \n0 = foldr ((+) . sqr) 0 xs No intermediate lists are produced by this version of sumSqs. Transformations \nsuch as the above can be generalised to other data structures. It is well-known that every algebraic \ndata type D whose de.nition appears in, e.g., [8] has an associated cata combinator and an associated \nbuild combinator. Operationally, the cata combinator for an algebraic data type D takes as input appro\u00adpriately \ntyped replacement functions for each of D s constructors cata-E :: (a -> b) -> (Int -> b) -> (Ops -> \nb-> b-> b) ->Expr a -> b cata-E vl oe= case eof Var x-> vx Lit i-> li Op ope1 e2 ->o op (cata-E v lo \ne1) (cata-E v l o e2) build-E :: (forall b. (a -> b) -> (Int -> b) -> (Ops -> b-> b -> b) -> b) -> Expr \na build-E g = g Var Lit Op augment-E :: (forall b. (a -> b) -> (Int -> b) -> (Ops ->b -> b -> b)-> b) \n-> (a -> Expr c) -> Expr c augment-E g v= gv LitOp Figure 2. Combinators for expressions and a data element \nd of D. It replaces all (fully applied) occurrences of D s constructors in d by corresponding applications \nof their re\u00adplacement functions. The build combinator for an algebraic data type D takes as input a function \ng providing a type-independent template for constructing abstract data structures from values. It instantiates \nall (fully applied) occurrences of the abstract construc\u00adtors which appear in g with corresponding applications \nof the con\u00adcrete constructors of D. Versions of these combinators and related functions for the arithmetic \nexpression data type of Example 1 ap\u00adpear in Figures 2 and 3. As we will see, the types of augment-E \nand subst are more general than those in [8] a bene.t arising from our monadic perspective. Compositions \nof data structure-consuming and -producing functions de.ned using the cata and build combinators for \nan algebraic data type D can be fused via a cata/build rule for D.For example, the rule for the data \ntype Expr t states that, for every closed type t and every closed function g :: forall b. (t -> b) ->(Int \n->b) -> (Ops ->b -> b-> b)-> b, cata-E vl o(build-E g) = gvl o (2) EXAMPLE 4. Let env ::a -> b be a renaming \nenvironment and e be an expression. The function renameAccum :: (a -> b) -> Expr a -> [b] which accumulates \nvariables of renamings of expressions, can be de.ned modularly as renameAccum env e = accum (map-E env \ne) Using rule (2) and the de.nitions in Figure 3 we can derive the following optimised version of renameAccum: \nrenameAccum env e = cata-E (\\x -> [x]) (\\i -> []) (\\op -> (++)) (build-E (\\v l o -> cata-E (v . env) \nl o e)) =(\\v l o-> cata-E (v. env) lo e) (\\x -> [x]) (\\i -> []) (\\op -> (++)) = cata-E ((\\x -> [x]) . \nenv) (\\i -> []) (\\op -> (++)) e Unlike the original expression accum (map-E env e), the opti\u00admised version \nof renameAccum does not construct the renamed expression but instead accumulates variables on the .y \nwhile renaming. 3.2 Short cut fusion for functors In this section we show that the least .xed point \nof every func\u00adtor has an associated cata/build rule and provide clean Haskell accum :: Expr a -> [a] \naccum = cata-E (\\x -> [x]) (\\i -> []) (\\op -> (++)) map-E :: (a -> b) -> Expr a -> Expr b map-E env \ne = build-E (\\v l o-> cata-E (v .env) loe) subst = (a -> Expr b) -> Expr a -> Expr b subst env e = augment-E \n(\\v l o-> cata-E v lo e) env Figure 3. Functions for expressions implementations of these rules. This \nopens the way for an alge\u00adbra of fusion, which allows us to de.ne generic fusion rules which are applicable \nto any data type, rather than only speci.c rules for speci.c data types. Haskell s Functor class, which \nrepresents type constructors supporting map functions, is given by class Functor f where fmap :: (a ->b) \n-> fa ->f b The function fmap is expected to satisfy two semantic functor laws stating that fmap preserves \nidentities and composition. Like the monad laws, they are enforced by the programmer rather than by the \ncompiler. Given an arbitrary functor f we can implement its least .xed point and cata and build combinators \nas follows: newtype M f = Inn {unInn :: f (M f)} cata-f :: Functor f=> (f a-> a) ->M f-> a cata-f h (Inn \nk) = h (fmap (cata-f h) k) build-f :: Functor f => (forall b.(f b -> b) -> b) -> Mf build-f g = g Inn \nThe de.nition of the type Mf represents in Haskell the standard categorical formulation of the initial \nalgebra/least .xed point of f, while cata-f represents the unique mediating map from the initial algebra \nof f to any other f-algebra. For a categorical semantics of build and the other combinators introduced \nin this paper see [3]. By contrast with the various build combinators that have previ\u00adously been de.ned \nfor speci.c data types, the build combinators de.ned above are entirely generic. Moreover, all previously \nknown de.nitions of build for speci.c types are instances of these. We call a type of the form Mf for \nan instance f of the Functor class an inductive data type, and we call an element of an inductive data \ntype an inductive data structure. By de.nition, every algebraic data type is an inductive data type. \nEXAMPLE 5. The algebraic data type Expr a in Example 1 is M(E a) for the functor Ea de.ned by data Ea \nb= Var a| LitInt | Op Opsb b EXAMPLE 6. An interactive input/output computation [18] is ei\u00adther i) a \nvalue of type a, ii) an input action, which for every input token of type i results in a new interactive \ninput/output compu\u00adtation, or iii) an output of an output token of type o and a new interactive input/output \ncomputation. The algebraic data type data IntIO i oa =Val a| Inp (i ->IntIO ioa) | Outp (o, IntIO i o \na) of such computations is the least .xed point of the functor Kioa where data K io ab= Va |I (i-> b) \n|O (o,b) We can derive a build combinator for Kioa by instantiating our generic de.nition of build. 3 \nWriting f for Kioa gives cata-f ::(a -> b)-> ((i -> b)-> b) -> ((o,b) -> b) ->IntIO io a-> b cata-f vp \nqk= case kof Valx -> vx Inph -> p(cata-fvpq.h) Outp (y,z) -> q (y, cata-f v p q z) build-f :: (forall \nb. (a -> b) -> ((i -> b) -> b) -> ((o,b) -> b) ->b) -> IntIO io a build-f g = g Val Inp Outp Pleasingly, \nour generic cata and build combinators for any functor f can be used to eliminate inductive data structures \nof type Mf from computations. For every functor f, and for every closed function g of closed type forall \nb. (f b-> b) -> b,wecan generalise rules (1) and (2) to the following cata/build rule for f: cata-f h \n(build-f g) = g h (3) In Section 3.1 we saw how the foldr/build rule can be used to eliminate from sumSqs \nthe intermediate list produced by map and consumed by sum. In Example 4, we saw how the cata/build rule \nfor expressions can be used to eliminate from renameAccum the intermediate expression produced by map-E \nand consumed by accum. Since modularly constructed programs often use catas to consume data structures \nproduced by maps, it is convenient to derive a generic cata/map fusion rule that can be instantiated \nat different types, rather than having to invent a new such rule for each data type. We now show that \nour build combinators make this possible. A bifunctor is a functor in two variables. In Haskell, we have \nclass BiFunctor f where bmap ::(a -> b)-> (c ->d) -> fa c-> fb d If f is a bifunctor then, for every \ntype a, fa is a functor, and the type M(fa) is sensible. If we de.ne the type constructor Mu f by Mu \nfa =M (f a) then, by inlining the de.nition of M in that of Mu f, we see that Mu f is a functor and its \ncata and build combinators can be represented in Haskell as newtype Mu fa= In {unIn :: fa (Muf a)} cata-f \n::BiFunctor f=> (f a c-> c) -> Mu fa -> c cata-f h (In k) = h (bmap id (cata-f h) k) build-f :: (forall \nc. (f ac ->c) -> c)-> Mu fa build-f g = g In Here, we have written cata-f and build-f rather than cata-(f \na) and build-(f a), respectively. Suppressing reference to the type a is reasonable because the de.nitions \nof the build and cata combinators for fa are uniform in a. The function fmap :: (a ->b) -> ha-> h b for \na functor h can be de.ned in terms of cata-f provided ha is uniformly a least .xed point. This is certainly \nthe case when h is of the form Mu f for some bifunctor f, and we have instance BiFunctor f => Functor \n(Mu f) where 3 Here, and at several places below, we must appropriately unbundle type isomorphisms to \nobtain the desired instantiation. So rather than cata-f for f = Kioa having type (K io ab -> b) -> IntIO \ni oa -> b, we take it to have the type given above. Unbundling is done without comment henceforth. fmap \nf xs = build-f (\\k -> cata-f (k . bmap f id) xs) EXAMPLE 7. If f is the bifunctor E from Example 5 then \nthe above instance declaration gives the function map-E from Figure 3. Using this de.nition of fmap we \nhave, for every bifunctor f, the cata/map fusion rules cata-f k (fmap f xs) = cata-f k (build-f (\\k -> \ncata-f (k . bmap f id) xs)) = cata-f (k . bmap f id) xs fmap f (build g) = build-f (\\h-> g (h . bmap \nfid)) The .rst expression in the .rst rule above constructs an interme\u00addiate data structure via fmap \nand then immediately consumes it with a call to cata-f. The optimised .nal expression avoids this. In \nthe second fusion rule, the right-hand side expression is a call to build, making further fusions possible. \nDeveloping an algebra of fusion incorporating generic rules such as these is an exciting possibility. \n 4. Augment The instance of build-E used in map-E in Figure 3 can be thought of as constructing particularly \nsimple substitution instances of ex\u00adpressions. It replaces data associated with the non-recursive con\u00adstructor \nVar by new data, but not with arbitrary expressions. As demonstrated above, the process of mapping over \nan expression in this way and then accumulating variables in the resulting expres\u00adsion is well-suited \nfor optimisation via the cata/build rule for expressions. Although it is possible to use build-E to construct \nmore gen\u00aderal substitution instances of expressions which replace data with arbitrary expressions and, \nindeed, to use build-f to construct general substitution instances of structures of any inductive data \ntype Mf the build representations of these more robust substi\u00adtution instances are inef.cient. The problem \nis that extra consump\u00adtions must be introduced to process the subexpressions introduced by the substitution. \nUnfortunately, subsequent removal of such con\u00adsumptions via fusion cannot be guaranteed [5]. Suppose, \nfor example, that we want to write a substitution function for expressions of type Expr a in terms of \nbuild-E and cata-E. It is tempting to write badSub :: (a -> Expr a) -> Expr a -> Expr a badSub env e \n= build-E (\\v l o -> cata-E env l o e) but the expression on the right hand side is ill-typed: env has \ntype a -> Expr a, while build-E requires cata-E s replacement for Var to be of the more general type \na-> b for some type variable b. The dif.culty here is that the constructors in the expressions introduced \nby env are part of the result of badSub, but they are not properly abstracted by build-E. More generally, \nthe argument g to build-E must abstract all of the concrete constructors that appear in the data structure \nit produces, not just the top-level ones contributed by g itself. To achieve this, extra consumptions \nusing cata-E are required: goodSub env e = build-E (\\v l o-> cata-E ((cata-E v lo) .env) loe) In the \nliterature, eliminating such extra consumptions has been ad\u00addressed by the introduction of more general \naugment combinators. The augment combinator for lists was introduced in [5] and ap\u00adpears in Figure 1. \nAnalogues for arbitrary algebraic data types are given in [8]; the augment combinator given in [8] for \nthe Expr data type, for example, is aug-E :: (forall b. (a -> b) -> (Int -> b) -> (Op-> b -> b ->b) -> \nb)-> (a -> Expr a) -> Expr a aug-E g v= gv Lit Op Note that the type of aug-E is more restrictive than \nthat of the augment combinator augment-E developed in this paper, which appears in Figure 2. Using aug-E \nwe can express subst as subst env e = aug-E (\\vl o-> cata-E vl oe) env The aug-E combinator offers more \nthan a nice means of ex\u00adpressing substitution, however. When expression-producing func\u00adtions are written \nin terms of aug-E and are composed with expression-consuming functions written in terms of cata-E,a cata/augment \nrule generalising the cata/build rule for expres\u00adsions can eliminate the intermediate data structure \nproduced by aug-E. This fusion rule asserts that, for every closed type t and ev\u00adery closed function \ng :: forall b. (t -> b) -> (Int -> b) -> (Ops -> b-> b-> b)-> b, cata-E v l o (aug-E g f) (4) = g(cata-E \nvl o. f) lo EXAMPLE 8. First inlining the aug-E form of subst above and the cata-E form of accum from \nFigure 3, and then applying the above rule, eliminates the intermediate expression in substAccum :: (a \n-> Expr b) -> Expr a -> [b] substAccum env e = accum (subst env e) to give substAccum env e = cata-E \n(accum . env) (\\i -> []) (\\op -> (++)) e This example generalises Example 4 since renaming is a special \ncase of substitution. Note that augment combinators are derived only for algebraic data types in [8]. \nIn Section 5 we generalise the combinators of [8] to give augment combinators, and analogues of the cata/augment \nrule (4), for non-algebraic inductive data types as well. The precise relationship between our combinators \nand those of [8] is discussed in Section 4.5 below, where we show how, for algebraic data types, the \nlatter can be derived from the former. 4.1 Introducing monadic augment We have seen that a build combinator \ncan be de.ned for any functor. A natural question raised by the discussion in the previous section is \nthus: For how general a range of functors can augment combinators be de.ned? The essence of augment is \nto extend build by allowing data structure-producing functions to take as input additional replace\u00adment \nfunctions. In [5], the append function is the motivating ex\u00adample, and the replacement function argument \nto the augment combinator for lists replaces the empty list occurring at the end of append s .rst input \nlist with append s second input list. Sim\u00adilar combinators are de.ned for arbitrary algebraic types in \n[8]. There, each constructor of an algebraic data type is designated ei\u00adther recursive or non-recursive, \nand the augment combinator for each algebraic data type allows the replacement of data stored at the \nnon-recursive constructors with arbitrary elements of that data type. (See Section 4.5.) We take a different \napproach in this paper. We, too, start from the observations that i) each augment combinator extends \nthe corresponding build combinator with a function which re\u00adplaces data/values by structures/computations, \nand ii) the essence of monadic computation is precisely a well-behaved notion of such replacement. But \nwe see these as evidence that the augment com\u00adbinators are inherently monadic in nature. Moreover, as \ndiscussed at the end of Section 4.3, the augment combinators bear relation\u00adships to their corresponding \nbuild combinators similar to those that the bind operations bear to their corresponding fmaps. That is, \nboth build and fmap support the replacement of data by data, while augment and bind allow the replacement \nof data by struc\u00adtures. Of course, augment and bind are de.ned for monads, while build and fmap are de.ned \nfor functors. This theoretical insight offers practical dividends. As we demon\u00adstrate below, it allows \nus to de.ne more expressive augment combinators, and more general cata/augment rules, than those known \nbefore. It also allows us to de.ne augment combinators and cata/augment rules for types for which these \nwere not previously known to exist. We brie.y illustrate our results before proceeding with the formal \ndevelopment of the monadic augment combinators and their associated fusion rules in the next section. \nEXAMPLE 9. The data type data Rose a = Node a [Rose a] of rose trees has no non-recursive constructors. \nThe associated augment combinator of [8] therefore does not allow the replace\u00adment of data of type a \nwith rose trees. But we will see in Section 4.3 that Rose is a monad, and thus that the augment combinator \nfor Rose de.ned in this paper does allow such replacements. In fact, it allows replacements of data of \ntype a with structures of type Rose b for any b. EXAMPLE 10. The inductive data type data Tree a b = \nNode (Tree a b) a (Tree a b) | Leaf b has one non-recursive constructor storing data of type b. The associated \naugment combinator of [8] thus supports replacement functions of type b -> Tree ab. But since Tree a \nis also a monad, the augment combinator de.ned in this paper supports replacement functions of the more \ngeneral type b-> Treeac. 4.2 Parameterised monads We have argued above that the essence of an augment \ncombina\u00adtor is to extend its corresponding build combinator with replace\u00adment functions mapping data/values \nto structures/computations. The types of the structures produced by the augment combinators must therefore \nbe of the form ma for some monad m. But if we want to be able to consume with catas the monadic structures \npro\u00adduced by augment combinators then we must restrict our attention to those monads m for which cata \ncombinators can be de.ned. This is possible provided m is an inductive monad. One way to specify inductive \nmonads uniformly is to focus on monads of the form ma=Mu f a for a bifunctor f.As we have seen, Mu f \nis a functor. But it is clear that Mu f is not, in general, a monad. Indeed, the data type Tree a b from \nEx\u00adample 10 can be written as Tree ab =Mu (T b) a where data Tb ac =N ca c|L b,but Tree ab is not a monad \nin a, i.e., does not admit a substitution function Treeab-> (a ->Tree cb) -> Tree cb. De.ning such a \nfunction would entail constructing new trees from old ones by replacing each in\u00adternal node in a given \ntree by a new tree. Since there is no way to do this, we see that Tree a b is an example of a common \ninduc\u00adtive type which does not support an augment combinator. In light of this observation, it is quite \nsatisfying to .nd weak and elegant conditions on f which guarantee that Mu f is indeed a monad. To de.ne \nthese conditions we introduce the notion of a pa\u00adrameterised monad [22]. Parameterised monads are represented \nin Haskell via the following type class: class PMonad f where preturn :: a-> f ac (>>!) ::fac-> (a -> \nfbc) -> fbc pmap ::(c->d)->fac-> fad The operations preturn, >>=, and pmap are expected to satisfy the \nfollowing .ve parameterised monad laws: >>! preturn = id (>>! g) . preturn = g >>! ((>>! g) . j) = (>>! \nj) . (>>! j) pmap g . preturn = preturn pmap g. (>>! j) =(>>! (pmap g.j)) . pmap g Thus a parameterised \nmonad is just a type-indexed family of mon\u00adads. That is, for each type c, the map f c sending a type \na to fac is the monad whose return operation is given by preturn, and whose bind operation is given by \n>>!. Note how the .rst three parameterised monad laws ensure this. Moreover, the fact that f c is a monad \nuniformly in c is expressed by requiring the opera\u00adtion pmap to be such that every map g:: c-> d lifts \nto a map pmap g between the monads f c and f d. This is ensured by the last two parameterised monad laws. \nIntuitively, we think of >>! as replacing, according to its second argument, the non-recursive data of \ntype a in structures of type fac, and of pmap as modifying, according to its .rst argument, the recursively \nde.ned substructures of structures of type fac to give corresponding structures of type fad. As for the \nmonad and functor laws, the compiler does not check that the operations of a parameterised monad satisfy \nthe re\u00adquired semantic conditions. Note that a parameterised monad is a special form of bifunctor with \npmap, >>!, and preturn implement\u00ading the required bmap operation: instance PMonad m => BiFunctor m where \nbmap f g xs = (pmap g xs) >>! (preturn . f) There are many parameterised monads commonly occurring in \nfunctional programming. To illustrate, we .rst show that the ex\u00adpression language Expr a is generated \nby a parameterised monad. We then give three different mechanisms for constructing parame\u00adterised monads \nand, for each such mechanism, give a widely used example of a parameterised monad constructed using that \nmecha\u00adnism. EXAMPLE 11. We can derive expression monads from parame\u00adterised monads as follows. If data \nE ab =Var a| Lit Int |Op Ops bb as in Example 5, then E is a parameterised monad with operations given \nas follows, and Expr a= MuE a. instance PMonad E where preturn = Var Varx>>!h =hx Liti>>!h =Liti Opope1e2>>!h \n=Opope1e2 pmapg(Varx) =Varx pmapg(Liti) =Liti pmap g(Op op e1e2) = Op op (g e1) (ge2) EXAMPLE 12. If \nh is any functor, then the following de.nes a parameterised monad: data SumFunc ha b= Val a| Con (hb) \ninstance Functor h => PMonad (SumFunc h) where preturn = Val Valx>>!h =hx Cony>>!h =Cony pmap g (Val \nx) =Val x pmap g (Con y) = Con (fmap g y) The name SumFunc re.ects the fact that SumFunc h a is the sum \nof the functor h and the constantly a-valued functor. The data type Expr a from Example 1 is (essentially, \ni.e., ignoring terms induced by the extra lifting implicit in the data declaration for hb) Mu (SumFunc \nh) a for data hb =Lit Int | Op Ops b b The data type IntIO i oa of interactive input/output compu\u00adtations \nfrom Example 6 is (essentially) Mu (SumFunc h) a for h=kio and data k io b= I(i ->b) | O(o,b). A parameterised \nmonad of the form SumFunc h constructs monads with a tree-like structure in which data is stored at the \nleaves. We can instead consider monads with a tree-like struc\u00adture in which data is stored at the nodes, \ni.e., in the recursive constructors. These are induced by parameterised monads of the form ProdFunc ha \nb= Node a(h b). Because the >>! op\u00aderation of a parameterised monad must replace (internal) tree nodes \nwith other trees, the branching structure of such trees must form a monoid. We therefore restrict attention \nto structure functors h such that, for each type t, the type ht forms a monoid. This re\u00adstriction is \ncaptured in the following Haskell type class de.nition: class Functor h => FunctorPlus h where zero :: \nh a plus :: h a-> ha ->h a The programmer is expected to verify that the operations zero and plus form \na monoid on ha. EXAMPLE 13. If h is an instance of the FunctorPlus class, then the following de.nes a \nparameterised monad: newtype ProdFunc h a b = Node a (h b) instance FunctorPlus h => PMonad (ProdFunc \nh) where preturn x = Node x zero Nodext>>!k =letNodeys=kx in Node y (plus t s) pmap g (Node x t) = Node \nx (fmap g t) A commonly occurring data type which is the least .xed point of a parameterised monad of \nthe form ProdFunc h is the data type of rose trees from Example 9. Indeed, the data type Rose is Mu (ProdFunc \n[]) where [] is the list functor and instance FunctorPlus [] where zero = [] plus = (++) Our .nal example \nof a general mechanism for generating parameterised monads concerns a generalisation of hyperfunc\u00adtions \n[10]. Here, we start with a contravariant structure functor , i.e., with a functor in the class class \nContraFunctor f where cfmap :: (a-> b) ->f b-> fa EXAMPLE 14. If h is a contravariant functor, then the \nfollowing de.nes a parameterised monad: newtype Hh ab= H{unH :: h b-> a} instance ContraFunctor h => \nPMonad (H h) where preturn x = H (\\f -> x) Hh>>!k =H(\\f->unH(k(hf))f) pmap g(H h) =H (\\f-> h (cfmap g \nf)) An example of a data type which arises as the least .xed point of a parameterised monad of the form \nHh is the data type of hyperfunctions with argument type e and result type a: newtype Hyp e a = Hyp {unHyp \n:: (Hyp e a -> e) -> a} Indeed, Hyp e is Mu (Hh) for the contravariant functor hb= b-> e. This example \nshows that the data types induced by param\u00adeterised monads go well beyond those induced by polynomial \nfunc\u00adtors, and include exotic and sophisticated examples which arise in functional programming. We now \nturn our attention to showing that every parame\u00adterised monad has an augment combinator and an associated \ncata/augment fusion rule. This will allow us to show that every least .xed point of a parameterised monad \nis a monad by writing the required bind operation for the least .xed point in terms of the augment combinator \nfor the parameterised monad whose least .xed point it is. That this can be done is very important and \nwe will return to it in the next section. We will also show there that we can write the augment combinators \nin terms of their corresponding binds, and thus that the augment combinators really are gmonadic in nature. \n 4.3 Augment for parameterised monads The central contribution of this paper is the de.nition, for each \npa\u00adrameterised monad f,of an augment combinator and cata/augment fusion rule for the monad Mu f. Our \nde.nition is entirely generic, and extends the de.nition of the augment combinators from [8] to accommodate \nnon-algebraic inductive data types. If f is a parameterised monad then we can de.ne an augment combinator \nfor it by augment-f :: PMonad f => (forall c. (f a c-> c)-> c) ->(a -> Muf b) -> Mu fb augment-f g k \n= g (In . ( >>! (unIn . k))) Here, >>! (unIn . k) is the application of the in.x operator >>! to its \nsecond argument. We can now see clearly that the de.nition of augment is the same as that of build, except \nthat it allows an extra input of type a->Muf b which is used to replace data of type a in the structure \ngenerated by g with structures of type Mu fb. Note that a->Muf b is the type of a Kleisli arrow for what \nwe will see is the monad Mu f.Itis the augment combinators ability to consume Kleisli arrows mirroring \nthe bind operations ability to do so that precisely locates augment as a monadic concept. Indeed, as \nwe now show, the bind operation for Mu f can be written in terms of the augment combinator for f. We \nhave already observed that if f is a bifunctor then Mu f is a functor. But if f satis.es the stronger \ncriteria on bifunctors neces\u00adsary to ensure that it is a parameterised monad, then Mu f is actu\u00adally \nan inductive monad. The relationship between a parameterised monad f and the induced monad Mu f is captured \nin the Haskell instance declaration instance PMonad f => Monad (Mu f) where return x = In (preturn x) \nx >>= k = augment-f g k where g h = cata-f h x Although not stated explicitly, this instance declaration \nentails that if f satis.es the semantic laws for a parameterised monad, then Mu f is guaranteed to satisfy \nthe semantic laws for monads. More\u00adover, while Mu f may support more than one choice of monadic return \nand bind operations, this declaration uniquely determines a choice of monadic operations for Mu f which \nrespect the struc\u00adture of the underlying parameterised monad f. By analogy with the situation for inductive \ndata types, we call a type of the form Muf a which is induced by a parameterised monad in this way a \nparameterised monadic data type. Further, we call an element of a parameterised monadic data type a parameterised \nmonadic data structure. We now consider the relationship between augment, build, and bind. We have seen \nabove that the bind operation for the least .xed point of a parameterised monad can be de.ned in terms \nof the associated augment combinator. It is also known that the build combinators for speci.c data types \ncan be de.ned as spe\u00adcialisations of the augment combinators for those types, e.g., build g = augment \ng []. Our generic de.nitions allow us to show that this holds in general. We have, for every parameterised \nmonad f: build-f g >>= k = augment-f g k (5) Setting k = return and using the monad laws, we see that \nbuild-f is de.nable from augment-f. Together with the obser\u00advation that fmap k = >>= (return . k) the \nequality (5) shows that the implementation of build in terms of augment is similar to that of fmap in \nterms of bind. But (5) also shows how augment combinators can be de.ned in terms of bind operations. \nThe equality (5) is very elegant indeed! In addition, it provides support for our assertion that the \naugment combinators are monadic by demonstrating that they are interde.nable with, and hence are essentially \noptimisable forms of, the bind operations for their associated monads. 4.4 Examples Examples of the \nmonads and augment combinators derived from the parameterised monads E, SumFunc (k i o), ProdFunc [], \nand Hh for hb=b-> e from Examples 11 through 14 appear below. In the interest of completeness we give \nthe correspondence between the generic combinators derived from the de.nition based on parameterised \nmonads and the speci.c combinators given earlier for the expression language in Example 1. The monadic \ninterpre\u00adtation of our augment combinators makes it possible to generalise those of [8], which allow \nreplacement only of data stored in the non-recursive constructors of data types, to allow replacement \nof data stored in recursive constructors of data types as well. (See Ex\u00adample 17.) It also makes it possible \nto go well beyond algebraic data types, as is illustrated in Example 18. EXAMPLE 15. If E is the parameterised \nmonad from Example 11, then the data type induced by E is the expression monad Expr a from Example 1, \nwhose return and bind operations are de.ned below. Instantiating the generic derivations of the cata, \nbuild, and augment combinators for E and then simplifying the results gives the cata, build, and augment \ncombinators in Figure 2. return x = In (preturn x) = In (Var x) = Var x e >>= k = augment-E g k where \ng hl o= cata-E h lo e =g kLit Op where g hl o= cata-E h lo e = cata-E k Lit Op e = case e of Varx -> \nkx Liti -> Liti Opop e1 e2-> Op op (cata-E k Lit Op e1) (cata-E k Lit Op e2) EXAMPLE 16. If f = SumFunc \n(k i o) is the parameterised monad from Example 12, then the data type induced by f is (es\u00adsentially) \nthat of interactive input/output computations from Ex\u00adample 6. Instantiating the generic derivations \nof the cata, build, and augment combinators for the parameterised monad f yields the de.nitions for cata-f \nand build-f from Example 6 and augment-f :: (forall b. (a -> b) -> ((i -> b) -> b) -> ((o,b) -> b) -> \nb) -> (a ->IntIO io c)-> IntIO i oc augment-f g k = g k Inp Outp Using the above de.nitions, we can also \ninstantiate the generic derivation of the monad operations for IntIO i o from the op\u00aderations for the \nunderlying parameterised monad f. This gives return x = Val x intio >>= k = cata-f k Inp Outp intio EXAMPLE \n17. If f = ProdFunc [] is the parameterised monad from Example 13, then the data type induced by f is \nthat of rose trees from Example 9. Instantiating the generic derivations of the cata, build, and augment \ncombinators for the parameterised monad f gives cata-f ::(a -> [b] ->b) -> Rose a-> b cata-f n (Node \nx tas) = n x (map (cata-f n) tas) build-f :: (forall b. (a -> [b] -> b) -> b) -> Rose a build-f g = g \nNode augment-f :: (forall b. (a -> [b] -> b) -> b) ->(a -> Rose c) ->Rose c augment-f g k= g(\\x t-> let \nNode y s= kx in Node y(t ++ s)) The de.nitions of cata-f and build-f coincide with those in [15]. Using \nthe above de.nitions, we can also instantiate the generic derivation of the monad operations for Rose \na from the operations for the underlying parameterised monad f. This gives return x = Node x [] t>>=k \n=cata-f(\\xts->letNodeys=kx in Node y (ts ++s)) t EXAMPLE 18. If f=Hh with hb =b-> e is the parame\u00adterised \nmonad from Example 14, then the data type induced by f is the monad of hyperfunctions given there. Instantiating \nthe generic derivations of the cata, build, and augment combinators for the parameterised monad f gives \ncata-f ::((b -> e) ->a) -> b)-> Hyp ea ->a cata-f h (Hyp k) = h (\\g -> k (g . cata-f h)) build-f :: (forall \nb. (((b -> e) -> a) -> b) -> b) -> Hyp ea build-f g = g Hyp augment-f :: (forall b. (((b -> e) -> a) \n-> b) -> b) ->(a -> Hyp ec) -> Hyp e c augment-f g k = g (\\u -> Hyp (\\f -> unHyp (k (u f)) f)) Using \nthe above de.nitions, we can also instantiate the generic derivation of the monad operations for Hyp \nea from the opera\u00adtions for the underlying parameterised monad f. This gives return x = Hyp (\\k -> x) \n(Hyp h) >>= k = Hyp (\\f -> unHyp (k (h (f . (>>= k)))) f) 4.5 Representing algebraic augment In addition \nto providing new augment combinators for rose trees, as well as augment combinators for other types which \nwere not previously known to have them, our results also generalise the augment combinators of [8]. At \n.rst glance this does not appear to be the case, however, since the augment combinators from [8] are \nderived for all algebraic data types, while the ones in this paper are derived for types of the form \nMu fa where f is a parameterised monad. Surely, one thinks, there are more algebraic types than inductive \nmonads arising as least .xed points of parameterised monads. Put differently, it seems that one can distinguish \nbetween recursive and non-recursive constructors, as Johann does, more often than one can distinguish \nbetween values and computations, as we do. The key to resolving this apparent conundrum is the observa\u00adtion \nthat, for each algebraic data type, we can form a parameterised monad by bundling all the non-recursive \nconstructors of the alge\u00adbraic type together and treating them as values. The augment com\u00adbinator derived \nfrom this parameterised monad will allow replace\u00adment of all of these values, thereby achieving the expressiveness \nof Johann s augment combinators for the original algebraic data type. Lack of space prevents a full treatment \nof this observation, but we illustrate with two examples, namely Gill s augment combinator for lists \nand Johann s augment combinator for expressions. The list monad is not of the form Mu L for any parameterised \nmonad L. However, if we de.ne data La eb =Var e |Cons a b then, for each type a, the type La is a parameterised \nmonad. The data type Lt ae =Mu (La) e can be thought of as rep\u00adresenting lists of elements of type a \nthat end with elements of type e, rather than with the empty list. We therefore have that [a] =Lt a(), \nwhere () is the one element type. The augment combinator for this parameterised monad can take as input \na re\u00adplacement function of type ()-> Lt a(), i.e., can take as input another list of type a. This gives \nprecisely the functionality of Gill s augment combinator for lists. Note the key step of generalising \nthe non-recursive constructor [] of lists to variables. Johann s augment combinator for expressions allows \nthe re\u00adplacement of both variables and literals with other expressions. By contrast, our augment combinator \nfor the expression data type allows only the replacement of variables with other expres\u00adsions. However, \nthe same approach we used to derive the standard augment combinator for lists works here as well. If \nwe de.ne the parameterised monad data Ex ab =Op op b b| Var a then the type Expr a is Mu Ex (Plus a) \nwhere data Plus a = Left a | Right Int Here, any occurrences of the constructor Left can be thought of \nas the true variables of Expr a, while any occurrences of the constructor Right can be thought of as \nits literals. The augment combinator for Ex can take as input replacement functions of type Plus t -> \nMu Ex (Plus u), which replace both the literals and true variables with expressions of type Expr u. This \naugment combinator is actually more general than the one in [8], which forces the type of the variables \nbeing replaced to be the same as that of the variables occurring in the replacement ex\u00adpressions. This \nextra generality, while appearing small, is actually very useful in practice, e.g., in implementing map \nfunctions using augment. Once again, the key step in the derivation here is the treat\u00adment of the non-recursive \nconstructors as variables in the parame\u00adterised monad. Although Johann s augment combinators can be derived \nfrom our monadic ones, the distinction between recursive/non-recursive constructors may be more intuitive \nfor many programmers than the monadic distinction between values and computations. Of course, when augment \ncombinators based on both distinctions are available, the programmer is free to choose between them. \nBut a monadic augment may be available even if an algebraic one is not.  5. Generalised short cut fusion \nWe have seen that parameterised monads are particularly well\u00adbehaved, in the sense that their least .xed \npoints are inductive monads which support cata, build, and augment combinators. In this section we give \na generic cata/augment fusion rule which can be specialised for each parameterised monad. The rule we \ngive generalises the cata/augment rules for lists and expressions discussed in Section 4, as well as \nthe ones in [8]. The rule says that, for each parameterised monad f, cata-f h (augment-f g k) (6) = g \n(h . (>>! (pmap (cata-f h)) . unIn . k)) The correctness, and indeed the derivation, of this rule is \nbased on a categorical interpretation of the augment combinators which reduces correctness to parametricity; \nsee [4] for details. As with the generic cata/build rule (3) from Section 3.2, the right-hand side of \nthis rule is an application of the abstract template g, but now the extra replacement function k must \nbe blended into the algebra h. As we have seen in Section 4.3, the bind operation of the least .xed point \nof a parameterised monad f can be de.ned in terms of the associated augment combinator. The possibility \nof cata/bind fusion for Mu f is therefore hardwired into the very de.nition of parameterised monadic \ntypes. Moreover, since bind is the most fundamental of monadic operations, and since data structures \nuni\u00adformly constructed via binds are often uniformly consumed by catas, we expect to see many applications \nof binds followed by catas in monadic code. The intermediate data structures con\u00adstructed by such binds \nand consumed by such catas are eligible for elimination via (6) and, because the augment representation \nof each bind is based on a cata, the fused optimisation of a bind followed by a cata will itself be a \ncata. This has the important consequence that not just a single bind followed by a cata, but in fact \na whole sequence of binds followed by a cata, can be opti\u00admised by a series of cata/augment fusions, \neach (except the .rst) enabled by the one that came before. These will ripple backward, allowing monadic \ncode to intermingle and intermediate data struc\u00adtures to be eliminated from computations. We now illustrate \nfusion using the generic rule (6). The ex\u00adamples below are natural generalisations of the optimisation \nof sumSqs in Section 3.1, which is typical of the applications found in the literature. EXAMPLE 19. To \ncompute the list of free variables appearing in any expression, we can .rst substitute for each variable \nnode in the expression a new variable node consisting of the singleton list containing the variable name, \nand then accumulate the contents of these lists by recursively appending them. We have free-vars :: Expr \na -> [a] free-vars e = cata-E id (\\i -> []) (\\op -> (++)) (subst (\\x -> Var [x]) e) The instantiation \nof the generic cata/augment rule for E is cata-E v l o (augment-E g k) =g (cata-E vl o. k)l o where cata-E \nand augment-E are as in Figure 2. Using this, together with the augment representation of subst from \nFigure 3, we can derive an equivalent version of free-vars in which the intermediate expression produced \nby subst has been eliminated from the modular computation: free-vars e = cata-E id (\\i -> []) (\\op -> \n(++)) (augment-E (\\v l o-> cata-E v lo e) (\\x-> Var [x])) =(\\v l o-> cata-E v lo e) (\\x -> [x]) (\\i -> \n[]) (\\op -> (++)) = cata-E (\\x -> [x]) (\\i -> []) (\\op -> (++)) e Note that whereas the intermediate \nexpressions in Examples 4 and 8 are of type Expr a, the one in free-vars has a type of the more general \nform Expr c, where c is taken to be [a]. EXAMPLE 20. Consider again the monad of interactive input/output \ncomputations from Examples 12 and 16. The function down plays the game in which the user chooses an integer \nn and tries to incre\u00admentally decrease this number to 0 by inputting a number, record\u00ading that number \nas an output, decreasing n by the input, and play\u00ading the game from the result. Let f = SumFunc (k i \no) as in Example 16. Then down :: Int -> IntIO Int Int Int down n = augment-f (\\v in out -> let loop \nx = ifx <= 0 then vx else in (\\k -> out (k, loop (x-k))) in loop n) Val We can represent such a game \nas a tree with nodes labelled by the last input and the remaining distance to go to zero. The exception \nis the root node, representing the start of the game, which does not have a preceding input. For example, \nignoring the branches which fail by becoming negative, down 3 could be represented by 3 (1, 2) (2, 1) \n(3, 0) (1, 1) (2, 0) (1, 0) (1, 0) The function results takes as input a number n and an interac\u00adtive \ninput/output computation, and returns the list of values in the leaves of that computation. The user \ns inputs are assumed to be integers between 1 and n. results :: Int -> IntIO Int o a -> [a] results n \n= cata-f v in out where vx =[x] ing =concat[gx|x<-[1 .. n]] out (o, p)= p The instantiation of the generic \ncata/augment rule for f = SumFunc (ki o) is cata-f v in out (augment-f g k) = g (cata-f v in out . k) \nin out We can optimise the function which returns the list of values in the leaves of the game tree rooted \nat n. Since vx= [x], ing =concat [g x| x<-[1 .. n]], and out (o,p) =p, we have the following equivalent \ncomputation from which the intermediate tree of type IntIO Int Int Int has been elim\u00adinated: results \nn (down n) = cata-f v in out (augment-f (\\v in out -> let loop x =if x<= 0then vxelse in (\\k -> out (k, \nloop (x-k))) in loop n) Val) = (\\v in out -> let loop x= if x<= 0then v xelse in (\\k -> out (k, loop \n(x-k))) in loop n) (cata-f v in out . Val) in out =let loop x=if x <= 0 then (cata-f v in out . Val) \nx else in (\\k -> out (k, loop (x-k))) in loop n = let loop x = if x <= 0 then [x] else in (\\k -> loop \n(x-k)) in loop n = let loop x = if x <= 0 then [x] else concat [loop (x-z) | z <-[1 .. n]] in loop n \nEXAMPLE 21. Consider again the monad of rose trees from Exam\u00adples 13 and 17. The function down takes \na non-negative integer n as input and produces a rose tree whose root is labelled n and in which each \nnode has one child for each non-negative integer smaller than its label. For example, down 3 produces \n3 012 0 01 0 Letting f = ProdFunc [] as in Example 17 we have return :: a -> Rose a return x = Node \nx [] down :: Int -> Rose Int down n = augment-f (\\h -> let loop x = h x (map loop [0 .. x-1]) in loop \nn) return The function results returns the pre.x list of data elements in a rose tree: results :: Rose \na -> [a] results = cata-f (\\x ys -> x : concat ys)  The instantiation of the generic cata/augment rule \nfor f = ProdFunc [] is cata-f no (augment g k) =g (\\x t-> let Node ys =k x in no y (t ++ map (cata-f \nno) s)) Using this we can optimise the function which returns the pre.x list of data elements in the \nrose tree produced by down n. Letting no xys =x :concat ys gh =let loop y =h y(map loop [0.. y-1]) in \nloop n we have the following equivalent computation from which the inter\u00admediate rose tree of integers \nproduced by down n has been elimi\u00adnated: results (down n) = cata-f no (augment-f g return) =g (\\x t-> \nlet Node ys =return x in no y (t ++ map (cata-f no) s)) =g (\\x t-> nox) t) = let loop y = (\\x t-> no \nx t)y (map loop [0 .. y-1]) in loop n = let loop y = no y (map loop [0 .. y-1]) in loop n = let loop \ny = y : concat (map loop [0 .. y-1]) in loop n EXAMPLE 22. Rather than give another example in the same \nvein as previously, we add some variety by establishing the potential for the optimisation of programs \nwhich manipulate hyperfunctions by reimplementing the interface for hyperfunctions given in [10]. The \noriginal interface was based upon the following operations: run ::Hyp o o-> o run (Hyp k) =krun base \n:: o-> Hyp io base a= Hyp (\\x ->a) (<<) :: (i-> o) ->Hyp i o-> Hyp io f << fs = Hyp (\\k -> f (k (fs))) \nWe can now reimplement this library using the combinators given in Example 18: run = cata (\\c -> c id) \nbase a = build (\\h -> h (\\x -> a)) f << fs = build (\\h -> h (\\k -> f (k (cata h fs)))) Correctness of \nthe implementation of run is proved as follows: run (Hyp k) = cata (\\c -> c id) (Hyp k) = (\\c -> c id) \n(\\g -> k (g . cata (\\c -> c id))) = (\\g -> k (g . cata (\\c -> c id))) id = k (id . cata (\\c -> c id)) \n= k (cata (\\c -> c id)) = k run Similar proofs exist for the other combinators. Code written using this \ninterface can now potentially be optimised. As a .nal observation, we note that, in the instance declaration \nfor parameterised monadic data types, we could have written the bind operation of the monad Mu f as x \n>>= k = cata-f (In . ( >>! (unIn . k))) x rather than in terms of augment-f. There are, however, two \nreasons to not do this. First, this de.nition of bind is signi.cantly less clear than the one involving \naugment-f, and it goes against the practice of abstracting away from programming details via high\u00adlevel \ncombinators. The second, bigger problem for the purpose of optimisation is that, if a bind is followed \nby a consuming cata, then it might not be possible to fuse the cata implementing the bind with this cata \nsince not all compositions of catas can be fused. To get around this dif.culty we would be led to devise \nsome kind of strategy for marking those compositions which can be so fused, which would be tantamount \nto inventing the augment combinators.  6. Related work In addition to the literature on monads and program \ntransformation cited above, there are some additional papers relating to the inter\u00adaction of these subjects. \n Our work on generic build and augment combinators con\u00adtributes to the fruitful line of research into \ngeneric recursion combinators. Research in this area has led, for example, to the generalisation of fold \nfor lists to arbitrary mixed variance data types [2, 11].  Like us, Pardo [14] sought to understand \nfusion in the con\u00adtext of monadic computation, but his goal was different from ours. Pardo investigated \nconditions under which an expression of type M(\u00b5F ), for M a monad and F a functor with least .xed point \n\u00b5F , can be fused with a function foldf : \u00b5F . X to produce an expression of type M(X). The crucial difference \nwith our work is that Pardo considered the monad M an ambi\u00adent structure which was not to be eliminated \nby the fusion rule. Our goal, on the other hand, is to eliminate the construction of precisely such monadic \nstructures.  In a similar vein, [12] develops a variety of fusion laws in the monadic setting, including \na short cut deforestation law for eliminating intermediate structures of the form M(List X). However, \nas with [14], the aim is not to eliminate the monad, but rather the list inside the monad.  J\u00a8urgensen \n[9] de.ned a fusion combinator based on the unique\u00adness of the map from a free monad to any other monad. \nThus, his technique is really a different form of fusion from ours and, in particular, isn t based upon \nwriting consumers in terms of catamorphisms. Since catamorphisms appear in the literature far more frequently \nthan monad morphisms, it is natural to want as well-developed a theory of catamorphism-based fusion as \npossible, irrespective of other possibilities such as J\u00a8urgensen s.  Correctness proofs for the fusion \nrules presented in this pa\u00adper rely on sophisticated categorical concepts in particular, strong dinaturality, \nwhich, it has been suggested, is unsuitable for a general functional programming and programming trans\u00adformation \naudience. Since our aim is to reach precisely such an audience, the correctness proofs of our fusion \nrules are given in a separate paper [4] which extends the categorical account of cata/build fusion given \nin [3].  7. Conclusion and future work We have de.ned build combinators for all inductive types. In \nad\u00addition, we have demonstrated that augment is inherently an induc\u00adtive and monadic construction, and \nde.ned augment combinators for inductive monads arising as least .xed points of parameterised monads. \nWe believe it will be dif.cult to .nd a more general mech\u00adanism for de.ning inductive monads, and thus \nthat these results are about as general as can be hoped for. The categorical semantics of [4] reduces \ncorrectness of the fu\u00adsion rules given here to the problem of constructing parametric models which respect \nthe categorical semantics given there. An al\u00adternative approach to correctness is taken in [8], where \nthe opera\u00adtional semantics-based parametric model of [17] is used to validate the fusion rules for algebraic \ndata types introduced in that paper. Extending these techniques to tie the correctness of our monadic \nfusion rules into an operational semantics of the underlying func\u00adtional language is ongoing work. Benchmarking \nthe rules and de\u00adveloping a preprocessor for automatically converting monadically structured functions \ninto cata/augment form are additional direc\u00adtions for future work.  Acknowledgments We thank Graham \nHutton and the anonymous reviewers for their comments. References [1] O. Chitil. Type inference builds \na short cut to deforestation. In International Conference on Functional Programming, Proceedings, pages \n249 260, 1999. [2] L. Fegaras and T. Sheard. Revisiting catamorphisms over datatypes with embedded functions. \nIn Principles of Programming Languages, Proceedings, pages 284 194, 1996. [3] N. Ghani, T. Uustalu, and \nV. Vene. Build, augment and destroy. Universally. In Asian Symposium on Programming Languages, Proceedings, \npages 327 347. 2004. [4] N. Ghani, T. Uustalu, and V. Vene. Generalizing the AUGMENT combinator. In \nTrends in Functional Programming 5, 2005. To appear. [5] A. Gill. Cheap Deforestation for Non-strict \nFunctional Languages. PhD thesis, Univ. of Glasgow, 1996. [6] A. Gill, J. Launchbury, and S. L. Peyton \nJones. A short cut to deforestation. In Functional Programming Languages and Computer Architecture, Proceedings, \npages 223 232, 1993. [7] Z. Hu, H. Iwasaki, and M. Takeichi. Deriving structural hylomor\u00adphisms from \nrecursive de.nitions. In International Conference on Functional Programming, Proceedings, pages 73 82. \n1996. [8] P. Johann. A generalization of short-cut fusion and its correctness proof. Higher-Order and \nSymbolic Computation, 15:273 300, 2002. [9] C. Juergensen. Using monads to fuse recursive programs (extended \nabstract). citeseer.ist.psu.edu/543861.html. [10] J. Launchbury, S. Krstic, and T. Sauerwein. Zip fusion \nwith hyper\u00adfunctions. citeseer.ist.psu.edu/launchbury00zip.html. [11] E. Meijer and G. Hutton. Bananas \nin space: Extending folds and unfolds to exponential types. In Functional Programming and Computer Architecture, \nProceedings, pages 324 333, 1995. [12] E. Meijer and J. Jeuring. Merging monads and folds for functional \nprogramming. In Advanced Functional Programming, Proceedings, pages 228 266, 1995. [13] E. Moggi. Notions \nof computation and monads. Information and Computation, 93(1):55 92, 1991. [14] A. Pardo. Fusion of recursive \nprograms with computational effects. Theoretical Computer Science, 260(1-2):165 207, 2001. [15] S. Peyton \nJones, A. Tolmach, and T. Hoare. Playing by the rules: Rewriting as an optimization technique in GHC. \nIn Haskell Workshop, Proceedings, pages 203 233, 2001. [16] S. L. Peyton Jones, editor. Haskell 98 Language \nand Libraries: The Revised Report. Cambridge University Press, 2003. [17] A. Pitts. Parametric polymorphism \nand operational equivalence. Mathematical Structures in Computer Science, 10:1 397, 2000. [18] G. Plotkin \nand J. Power. Notions of computation determine monads. In Foundations of Software Science and Computation \nStructure, Proceedings, pages 342 356, 2002. [19] T. Sheard and L. Fegaras. A fold for all seasons. In \nFunctional Programming Languages and Computer Architecture, Proceedings, pages 233 242. 1993. [20] J. \nSvenningsson. Shortcut fusion for accumulating parameters and zip-like functions. In International Conference \non Functional Programming, Proceedings, pages 124 132, 2002. [21] A. Takano and E. Meijer. Shortcut deforestation \nin calculational form. In Functional Programming Languages and Computer Architecture, Proceedings, pages \n306 313, 1995. [22] T. Uustalu. Generalizing substitution. Theoretical Informatics and Applications, \n37(4):315 336, 2003. [23] J. Voigtl\u00a8ander. Concatenate, reverse and map vanish for free. In International \nConference on Functional Programming, Proceedings, pages 14 25, 2002. [24] P. Wadler. The essence of \nfunctional programming. In Principles of Programming Languages, Proceedings, pages 1 14, 1992.  \n\t\t\t", "proc_id": "1086365", "abstract": "Monads are commonplace programming devices that are used to uniformly structure computations with effects such as state, exceptions, and I/O. This paper further develops the monadic programming paradigm by investigating the extent to which monadic computations can be optimised by using generalisations of short cut fusion to eliminate monadic structures whose sole purpose is to \"glue together\" monadic program components.We make several contributions. First, we show that <i>every</i> inductive type has an associated build combinator and an associated short cut fusion rule. Second, we introduce the notion of an <i>inductive monad</i> to describe those monads that give rise to inductive types, and we give examples of such monads which are widely used in functional programming. Third, we generalise the standard augment combinators and cata/augment fusion rules for algebraic data types to types induced by inductive monads. This allows us to give the first cata/augment rules for some common data types, such as rose trees. Fourth, we demonstrate the practical applicability of our generalisations by providing Haskell implementations for all concepts and examples in the paper. Finally, we offer deep theoretical insights by showing that the augment combinators are monadic in nature, and thus that our cata/build and cata/augment rules are arguably the best generally applicable fusion rules obtainable.", "authors": [{"name": "Neil Ghani", "author_profile_id": "81100427276", "affiliation": "University of Leicester, Leicester, UK", "person_id": "PP43120510", "email_address": "", "orcid_id": ""}, {"name": "Patricia Johann", "author_profile_id": "81100058482", "affiliation": "Rutgers University, Camden, NJ", "person_id": "P220019", "email_address": "", "orcid_id": ""}, {"name": "Tarmo Uustalu", "author_profile_id": "81100651156", "affiliation": "Inst. of Cybernetics, Tallinn, Estonia", "person_id": "PP40029488", "email_address": "", "orcid_id": ""}, {"name": "Varmo Vene", "author_profile_id": "81100442892", "affiliation": "Univ. of Tartu, Tartu, Estonia", "person_id": "PP25003684", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1086365.1086403", "year": "2005", "article_id": "1086403", "conference": "ICFP", "title": "Monadic augment and generalised short cut fusion", "url": "http://dl.acm.org/citation.cfm?id=1086403"}