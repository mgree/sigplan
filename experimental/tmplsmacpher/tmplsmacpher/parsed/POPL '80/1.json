{"article_publication_date": "01-28-1980", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1980 ACM 0-89791-011-7 $5.00 treat data types as values, in complete analogy with procedure and function \nvalues in conventional languages. The treatment of data typea as values leads to a pleasing uniformity \nin the parameterization mechanism of Russell. The Russell semantica gives a meaning for the value of \nany identifier or expression, including types and variables (vari\u00adables are treated essentially as reference \nvalues). Thus, any construction in the language may be parameterized with respect to any of its free \nidentifiers (even type identifiers) using a straightforward call-by-value semantics. ( The benefits of \nthis type completeness as a language design principle are discussed in the other paper in this proceedings \nby the authors [Demers80a]; here we are concerned solely with its implications for type-checking.) In \naddition, following Landints rPrinciple of Correepondence~ [Landin66], we treat declaration and parameterization \nas semantically equivalent. Thus, the language has only a single, straightforward semantic mechanism \n(call-by-value parameter passing) for the intro\u00adduction of new names. In particular, it is not necessary \nto treat type declarations and type parameters as special casea, aa must be done done in Euclid, Alphard \nand CLU. Finally, we note that every value in a Russell program either is treated as an operation (i.e. \na procedure, function or type) or else is interpreted by the operations of some type. thus , the set \nof primitive combining forms in Russell is extremely small, consisting of those forms needed to interpret \noperation values: selection of a com\u00adponent of a type, and S%P-Plicat ion of a procedure or function \nto a list of argument values. The purpose ascribed to type-checking depends on onels view of what a data \ntype is. If types are viewed a&#38; sete of values (as in Pascal) or as sets of values and operations \n(as in [Morris73]. or the Wrnany-sorted algebras!? of [Goguen76]), an attempt to apply an operation to \na value of the wrong type produces an erroneous result (i.e., a Prun-time errort~). Thus, type-checking \nis con\u00adsidered an essentially redundant way of predicting at compile-time that a program will produce \nan error when executed. In our view of data types, however, all types share a single universal value \nspace. Any value may be interpreted as belonging to any type, or even as being a type. Thus, a type-erroneous \napplication does not necessarily generate an error; it simply produces a spurious result by misinterpretingn \nits argument. Note that this view reflects the situation in a typical language implementation on a vonNeumann \nmachine --values are represented as (untyped) sequences of bits, and can be partitioned into clisjoint \nsets only by introducing explicit tagn fields, with the asso\u00adciated overhead in time and apace. In this \nframe\u00adwork, static type-checking takes on a more essen\u00adtial role: it is pecessary in order to guarantee \nthat values produced by one type will not be misinterpreted by operations of another type. In practice \nthere is not much difference between these points of view for simple languages. When static type-checking \nis sufficient to guaran\u00ad attempted, the representations of values of dis\u00ad tinct types need not be distinct \n--e.g., most Pascal implementations will represent both @ and integer values in a single word. However, \nour view of types suggeste that, no matter how ela\u00adborate the type etructure of a language becomes, it \nmust still be possible to do all type-checking statically, since no additional information will be available \nat run time to facilitate it. 4. Yroble ms .in ~ TVX Checking M~ ds In a programming language that provides \nonly a finite set of builtin typee, the type-checking rules can be specified exhaustively. Frequently \nthese rules are laden with &#38; ~ coercion rules and run-time consistency checks. (The PL/I arith\u00admetic \nrules are an outstanding example.) Flexible type definition and parametrized type mechanisms, however, \nmake it essential that a programming language design be based on a clear understanding of the meaning \nof data types and type-checking. The use of data type definitions meane that the set of types with which \nthe type-checker must deal is no longer finite; thus, the type-checking rules cannot be an exhaustive \nlist of special cases. Instead, the rules must show how the result of any type constructor in the language \nbehaves with respect to existing (builtin or user-defined) types. That this is not straightforward is \nseen in the inconsistencies between the type-checking rules of Algol-liket! languages, in the complexity \nof the rules, and in the difficulty of providing semantic justifications for them. Below we describe \nseveral aspects of type\u00adchecking in which this problem is apparent. TWO basic problems arise: (a) types \nthat are obvi-Ouslyir semantically equivalent but have distinct denotations. and (b) type denotations \nwhose mean\u00ading depends on (run-time) argument values. The treatment of types as values and the Principle \nof Correspondence suggest a solution to (a) which aPPears in [Demers78] and will be discussed only briefly \nhere. Problem (b) greatly influenced our syntactic treatment of type-checking; it also motivated the \nscope and import rules of Russell, described and justified later in this paper. Consider a program like \nthe following in which a new type is declared to be ~~identical~t to an existing type: JQ T {Qgze . . \n. ] == Integer T! {~ . .. } == Integer in let x {wT} == ... y {wT } == ... ~ ... x :=y ... (In Russell \nsyntax, braces enclose ?signatures,t~ or syntactic types; thus T and Tr are types, x is a variable of \ntype T, and y is a variable of type T?.) Whether this program is considered legal depends on whether \ntypes T and T~ with identical definitions are considered equivalent by the type-checking rules. Alphard \nand Euclid give dif\u00adferent answers to this question, while the Pascal report says nothing at all. By \nthe Principle of Correspondence, the above program in Russell is equivalent to one in which the type \ndeclarations are replaced by parameters: ill ... x :=Y *** h P[ Integer, Integer 1 A type-checking system \nbased on %acro-expansionn semantica (as used in Alphard) may or may not declare the above program correct. \nHowever, if the call P [ Integer, Real ] is added, then the program as a whole must be con\u00adsidered type-incorrect, \nthough it is unclear whether it is the body of P or the call which is invalid. Our desire to treat type \nparameters uni\u00adformly with other kinds of parameters leads us to conclude that the body of P is invalid. \nSince we can type-check and give the meaning of an ordinary procedure independent of any calls of the \npro\u00adcedure, we must be able to do the same for a polymorphic procedure. This requirement precludes a \nmacro-expansion interpretation of polymorphism and leada to a set of type-checking rules in which distinct \ntype names are never treated as equivalent. Parameterized types introduce a second kind of problem in \nwhich textually identical type expressions may denote different types because of a change in the value \nof some variable, The usual interpretation of equivalence for two applications of a parameterized type \nlike ~ is that corresponding argument valules must be equal. Thus, the assignment x := y, where the types \nof and y are &#38;E?&#38;%y E1..nal 4 intezer and ~ [l..nb] tiinte~er is legal only when na and nb have \nthe same value. For arbitrary expressions, it is clearly undecid\u00ad able whether this will always (or ever) \nbe the case; thus, asking that the run-time values of type arguments be equal makes static type-checking \nof such an assignment impossible. Further compli\u00adcations arise if, as in Russell, the programmer can \nredefine the meaning of equality for any type. Conventional approaches to this problem either insist \nthat arguments to parametrized types be manifest constants or defer type-checking to run time in such \ncases. Each app:roach has its draw\u00adbacks. Limiting type arguments to manifest con\u00adstants severely restricts \nthe programs that can be written (this ia a major problem in Pascal). How\u00adever, as was argued in Section \n3, our view of types precludes run-time type-checking. Thus, we have been led to devise language restrictions \n(in the form of scope and import rules, described below) to ensure that identical type expressions denote \nequivalent types without insisting that all type argumenta be manifest constants. In this section we \npresent. the type-checking rules of Russell. To escape the undecidability problems described above, tlhe \nRussell type\u00ad checking rules avoid the use of run-time values of expressions, without demanding that \nall type argu\u00adare applied to uninterpreted type expressions as composition rules described below. In \nparticular, purely syntactic forms. Each identifier in a the TypeDenotation may contain free identifiers, \nRussell program ie given a pi~naturq (similar to a subject to the import rule described below. For nsyntactic \ntypen of [Reynolds78].) The signatures example, of expressions are determined from the signatures w Stack[ \nN+M, Integer ] of their components by a set of purely syntactic and composition rules. Finally, each \nprocedure or Y&#38;Z Stack[ M+N, Integer 1 function application is checked to ensure that are valid (and \ndistinct) signatures. corresponding argument and parameter signatures are equivalent under a simple \ncalculus of signa-The signature of a procedure or function ture transformation rules described below. \ngives an identifier and signature for each parame\u00ad ter, plus a signature for the result, if there is \nTo justify the claim that our type-checking one. (In Russell, functions may produce results rules are \nsufficient to prevent misinterpretation having any signature, including variables, func\u00ad of values, the \nsyntactic transformations of the tions or data types.) Since we view a type as a signature calculus must \nbe provably set of operations, the signature of a type is sim\u00ad interpretation-preserving .W Also , the \nlanguage ply a collection of operation signatures, with an must be constrained to guarantee that syntacti\u00ad \nidentifier naming each component operation, and a cally identical type expressions in the same scope \nMlocal name!t), which the com\u00adbound identifier (or (which would be equivalent under the signature ponents \nmay use as a type denotation meaning the calculus) are semantically equivalent. In type in which the \ncomponent appears.vt Russell, a simple import rule (discussed below) is sufficient to guarantee that \nidentical type OperationSignature ::= expressions are equivalent. @ Id{Signature} ;1 I fund Id{Signature} \n~ 1 Signature  2.1. Simaturea ! &#38;YQ&#38; Id( Id{OperationSignature] ;) In Russell, each identifier \nand expression in The need for an identifier associated with a program is given a syntactic type or signa\u00ad \neach parameter of a procedure or function arises ture.n A signature may describe a variable, a because \na parameter name may appear free in the value, or an operation --procedure, function or signature of \nother parameters or the result. For type. example, a polymorphic function might have signa- Signature \n::= w ~peDenotation ture I JQ @peDenotation I OperationSignature In this context a TypeDenotation ie \nany expression that has ~ signature according to the signature T{~t( ...)); x{ YQT} ]y&#38;l T where \nthe type of the second parameter and of the result depend on the first argument. A similar technique \nis used in the polymorphic lambda cal\u00adculus of [Reynolds74], where a mCurriedn version of the above signature \nwould be written ( AT. T+T ) ..  5.2. Siznature ComDosltloa The rules for composing signatures of compo\u00adsite \nexpressions are completely natural if one bears in mind that they deal with signatures as syntactic objects, \nand not as values. As men\u00adtioned above, there are two primitive forms of composition in Russell: selectlon \nof a component of a type. and ~lication, of a function to a list of argument values. 5.2.1. Sele c t \nions Consider selection of the fn component of a type T, where T is some (arbitrarily complex) type denotation \nwith signature QJ!Qt (... f {sig } ... ) The signature of the selection T $ f is obtained by textual \nsubstitution of the type denotation T for the local name t in the signature of the f component: IT s \nig / It For example, if Integer has signature -1(... + {-[ X,Y{YQ 1] 1 @ I) ... ) then Integer$+ has \nsignature J5WI X,Y{YQ Integer] 1 W Integer Selection illustrates the importance of local names in type \nsignatures: if another type T has the -signature as Integer, the signature of T$+ is .&#38;dx.YkLLT] \nIMQT This allows operations selected from T to be applled to T values rather than to Integers.  2.2.2. \n@DlicatiOns The composition rule for function application also involves textual substitution of denotations \nfor bound identifiers. Consider an application F(al, . . ..ak). where F is an (arbitrarily complex) \ndenotation with signature XuQG[ Pl{viigl); ..(. pk{w%k} ] rsig The result signature is obtained by textual \nsub\u00adstitution of argument clenotations for the corresponding parameter identifiers in the result part \nof the signature of F: I al, .... ak I rsig I \\ PI, . ..s Pk Thus, an application of the form f[Integer,lO] \nwhere f has signature checkingn is involved here; the result signature of a type-erroneous application \nis a perfectly well-defined syntactic object (which may itself contain type-erroneous applications, of \ncourse). Xi. Xi&#38;e-Ghec king a ADDli cations: XJx2S.i.mature Calculus To type-check a Russell program, \nwe must guarantee that the signatures of the arguments and parameters match in function or procedure \napplica\u00adtions. Every parameter in a Russell program has an explicit signature; and every argument can \nbe given a signature using the composition rules described above. Thus, the Russell type-checking rules \noperate by transforming and comparing signa\u00adtures. Note that since types themselves have values and signatures, \ntype parameters require no special treatment. Type-checking an application proceeds in two steps: ex~ \nansion of parameter signatures by argu\u00adment denotations, and ~atc-of argument and parameter signatures. \nThe application ie legal iff each argument signature matches the corresponding expanded parameter signature. \nConsider an application P[al, . ..s ak], where P has signature =[ pl~psigl}; --; pk{psigk} ] and the \narguments have signatures asigl , .... asigk First the parameter signatures are expanded by textual substitution \nof arguments for the thcorresponding parameter identifiers; thus, the i expanded parameter eignature \nis I al, .... ak I psigi I 1 , PI, . ..s Pk Signature expansion is used so that the parameter signatures \nmay be modified to reflect the interre\u00adlationships among the arguments of a particular call of an operation. \nFor example, if g has sig\u00ad nature -[ n{yal Integer]; x{= T[n]} 1 then the expanded parameter signatures \nused in matching the call g[a+b,y] would be Q Integer and ~ T[a+b] h argument and parameter are said \nto IL@&#38;-&#38; iff the argument signature can be transformed to the parameter signature using a small \nset of syn\u00adtactic transformations, the simature calculus. The signature calculus rules are: a) Re n m \ning. The local name on a type signa\u00adture, or the parameter names in a procedure or function signature, \nmay be uniformly replaced by any new identifier. Thus , for example, the signature ~ [x,y{sigl]] sig2 \nmatches the signature Ia,b Ia,b I }1 sig2\\ - b~si% I Ix,y Ix,y The substitutions are necessary because \nx and y may appear free in the signatures sigl and sig2. b) ~ ord in . TWO type signatures match if \nthe signatures include all the same component names and identically-named components have matching signatures. \nFor example, the signa\u00adture 3YET ( al{sigl]; a2{sig2] ) matches LYM T ( a2{8ig2 l; al[sigl l ) if sig \nmatches sig t and sig matches sig ~. 1 12 2 c) .Rw etting. An argument type signature may be simplified \nby eliminating (nforgettingl?) some of its operations. Thus, the argument signature LYUT (al{sigl}: a2{sig2} \n) can be reduced by ~forgettingm a+ to L &#38;yIET (al{sigl} ) This rule is the sole means of encapsulat\u00adingn \ndata type definitions required in Russell. All the above rules are straightforward, easily explained \nand can obviously be shown to be interpretation-preserving. It is important to note the absence of any \ntransformation rule for variable or value signatures --to match, two variable or value signatures must \nbe textually identical. There are no 4 &#38; transformations based on knowledge of the behavior of particular \ntypes. This rule has the advantage of simplicity, especially when contrasted with the type compati\u00adbilitytt \nrules of Euclid [Lampson77, pp. 31-32] or the type subsumption, syntactic satisfaction and implicit bindingn \nrules of Alphard [Wulf78, PP. 11-131. 2.4. SQuKiiwdlw!Qxt MdSS Above we described_ an approach to static \ntype-checking based on the manipulation of type expressions as syntactic objects. Clearly, such an approach \ncan only work if language constraints exist to ensure that te~tually identical type expressions always \ndenote semantically equivalent type values. At the same time, these constraints must not be so restrictive \nas to prevent e.g. the computation of arguments to parameterized types. A formal definition of semantically \nequivalent type values requires a fo:~al semantics for the language; this is currently in preparation \n[Demers 80b] . However, we can ensure the correctness of our type checking rules in a way that is largely \nindependent of the details (of the formal semantics by insisting that the meanings of Russell programs \nbe invariant under certain syntactic transforma\u00adtions. Our approach to thifl is described below. The \nscope and import rules of Russell have been designed to guarantee that denotations have the subst itu \ndescribed as follows. tion ~. Let D be any denotation appearing in a legal Russell program, and let D \nbe yariabk -a (i.e.. neither D nor any of the free identifiers of D has w signature). Define the m of \nD to be the smallest enclosing scope in which all free iden\u00adtifiers of D are bound; this has the form \nkc c. ill P The substitution property demands that an equivalent program results if all occurrences of \nD are replaced by a new identifier bound to the value of D: ID Informally, this rule requires that evaluations \nof identical variable-free denotations must produce semantically identical values and must be free of \nobservable side-effects. Note that a consequence of this rule is that variable-free Russell pro\u00adgrams, \nlike the lambda calculus, have the Church-Rosser property; in particular, terminating pro\u00adgrams cannot \ndistinguish between call-by-value and call-by-name semantice. In Russell, the substitution property is \nachieved by enforcing the following rules. 1. The builtin types have the substitution property. This \nconstraint affects the signatures as well as the meanings of certain builtin types, For example, the \n~tobvious~t signature for the dere\u00adferencing operation Ref[Integer]$t is ~ [{ti Ref[lnteg=l}l = Integer \nThis signature would be unacceptable, as it can easily be used to write variable-free denotations that \ndo not have substitution property (using any plausible semantics); for example: . . . ValueOf[ p+ 1 ... \np+ := ValueOf[ p+ 1 + 1 ... ValueOf[ p+ 1 ... The remedy in this case is to introduce a type Heap, analogous \nto an untyped Euclid collection, and require a Heap variable as the first argument of a dereferencing \noperation. With this change, Ref[Integer]$+ has signature tic {~Heap}; {~ Integer} 1 W Integer and cannot \nbe embedded in a variable-free denota\u00adtion as was done in the example above. 2. No identifier may be \nredeclared in a scope in which it is accessible. This %nique visibil\u00aditytr rule is necessary to avoid \ncapture of free identifiers of the signature of an argument when that argument is passed to an operation \ndeclared in an outer scope. For example, it prohibits such (clearly incorrect) programs as m ~== ... \n P == @x{ysML T}] . . . iJlle.&#38; T== ... y {y&#38;ET} == . . . Q= . . . PIYI... which without the \nunique visibility rule would be considered legal. 3. No free identifier in an operation (i.e., procedure, \nfunction or type) denotation may have YCLK signature. This rule simply ensures that all operation denotations \nare variable-free. This is the most restrictive of the three rules, as it prevents procedures from inspecting \nor modifying global variables and prohibits applications like Array [ 1, N, Integer ] where N is a variable. \nThe rule does not, how\u00adever, prevent obtaining the effect of the above application; it is simply necessary \nto introduce a new identifier and bind it to the current value of N: M VN == ValueOf[ N ] h ..* Array[ \n1, VN, Integer ] . . . In our discussion of type-checking we have made a careful distinction between \nsignatures and data types. Data types are sets of operations, and have values; signatures are purely \n~vntactic constructs used by the type-checker, and do not have values. In particular, an operation signa\u00ad \nture like .@=[kdT}] @T is not a type; thus, Y&#38;z.i3Lu[klTllw.L f is not a legal signature, and there \nare no operation-valued variables. It is difficult to see how operation-valued variables could be introduced \ndirectly into the Russell type-checking framework. For example, suppose we somehow managed to produce \na type F that interpreted values as T-to-T functions. The operation of !Itaking the value of an F variable \n would have signature Z!md{w F}] ti{L@T]ltiT tiny nontrivial application of this function would be an \noperation denotation (since the result ia a function) that imported a variable (the argument), and thus \nwould violate the import rule. It is possible to add operation-valued vari\u00adablee to Russell using the \n_ constructor. Let sig be any operation signature; then *( sig) is a type with signature ~1( New{HI ~ \nI} :={ A{wI], {YQI}] ] ValueOf{ ti{y~ 1}1 Y&#38;l. I 1 In{ fic~{sig}l W I } Out{ -{A 1)] sig ] ) For \nexample, the type  Ff == imzs-diwd{YJLLT)]YALT ) is similar to the type F shown above to violate the \nimport rule. The key difference is that the ValueOf operation of Fr yields a A F? rather than a function; \nto obtain a function value it is neceseary to apply the Out function. Direct conversion of an F! variable \nto a function by conv position of ValueOf and Out, e.g. F $Out[ F $ValueOf[ x ] 1 still violates the \nimport rule; however, in most cases the same effect can be achieved by first binding the value of the \nvariable to a new iden\u00adtifier and then applying the Out function: -k Vx == Ft$ValueOf[ x ] h . . . Ft$Out[ \nVX 1 ... Since vx haa signature JQ Ft. the import rule is satiafied and type-checking is unaffected. \nThe _ constructor allows self-application in Russell programs. For example, the (recursive) cient to \nprevent any combination of language type declaration T = = x( ti{~T}] AT ) is perfectly well-behaved. \nAn example of an expression of this type is the following T-to-T identity function: f == T$In [ = x{d) \nT] YA.LT Le&#38;QIJixd 1 Clearly f can be applied to itself in a type\u00adcorrect way, e.g. ( T$Out[f] )[ \nf 1 From this example we can conclude that, with our view of data types, type-correctness and eelf\u00adaPPlication \nare unrelated; the fundamental goal of typechecking --to prevent misinterpretation of values --can be \nachieved even if self-application is allowed. 6. Conclusiw The ability to define new data types and to \nproduce objects of arbitrarily complex kinds by parameterization greatly increase the difficulty of type-checking. \nIn this paper we investigate the problems of type-checking in the presence of these features, and present \nan approach that allows static type-checking in the presence of completely general type definition and \nparametriz\u00ad ation mechanisms. The type-checking rules we present are simple and, most importantly, are \nbased on the firm ground of a semantic characteri\u00adzation of data types. Thus, a basic test of the correctness \nof the Russell design has been to guarantee that the type-checking rules are suffi\u00adfeatures from being \nused to misinterpretn a value. The obligation to prove this property of the language makes it advantageous \nto look for a few general mechanisms rather than a large number of unrelated features. z. References \n[Demers78] Demers, A., J. Donahue and G. Skinner. Data Types as Values: Polymorphism, Type-Checking, \nEncapsulation. Proceedings rZi&#38;tll AaILKLL ?r inCiD Ies A Proyramin% ~an~ua!es X h, 1978, pp. 23-30. \n [Demers79] Demers, A. and J. Donahue. Revised Report on Russell. Report TR79-389, Computer Science Department, \nCornell University, September 1979. [Demers80a] Demers, A. and J. Donahue. Type-Completeness as a Language \nPrinciple. Pro ceedinzs Seventh ~ Pr inCiDl es d Pr osrammin% Lanzuazes .@uo s iu m, 1980. [Demers80b] \nDemers, A. and J. Donahue. A Formal Seman\u00ad tics for Russell. (in preparation) [Goguen76] Goguen, J.A., \nJ.W. Thatcher and E.G. Wagner. An Initial Algebra Approach to the Specifica\u00adtion, Correctness and Implementation \nof Abetract Data Types. Report RC6487. IBM Tho\u00ad mas J. Watson Research Center, Yorktown Heights, N.Y., \n1976. [Landin66] Landin, P.J. The Next 700 Programming Languages. &#38;mQ. ~ 9:3 (1966). [Liskov77] \nLiskov, Barbara, Alan Snyder, Russell Atkin\u00adson and Craig Scaffert. Abstraction Mechan\u00adisms in CLU. h. \nw 20:8 (August 1977). [Morris73] Morris, James H. Types are Not Sets. lro ceedin~s m Annual Principles \nti ~ .nn ar~~s ua~ s ~VmD 0 s ium 1973, pp. 120\u00ad 12;. [Reynolds74] Reynolds, John. Towards a Theory \nof Type Structure. Colloquium Q pro~ramming, Paris, 1974. [Reynolcle781 Reynolde, John. Syntactic Control \nof Interference. Pr oceedin~s Fifth Annual Prin\u00ad -d Pro~rammin~ Lan uazes .SvmDosium, 1978, pp. 39-46. \n [Wulf78] Wulf, W. A. (cd. ) An Informal Definition of Alphard. CMU-CS-78-105, Department of Com\u00adputer \nScience, Carnegie-Mellon University, 1978. \n\t\t\t", "proc_id": "567446", "abstract": "In statically typed programming languages, each variable and expression in a program is assigned a unique \"type\" and the program is checked to ensure that the arguments in each application are \"type-compatible\" with the corresponding parameters. The rules by which this \"type-checking\" is performed must be carefully considered for modern languages that allow the programmer to define his own data types and allow parameterized types or types as parameters. (Such languages include Alphard [Wulf78], CLU [Liskov77], Euclid [Lampson77] and Russell [Demers79].) These features increase the expressive power of the languages, but also increase the difficulty of type-checking them.In this paper, we describe a treatment of type-checking that makes it possible to do completely static checking with a general parameterization mechanism allowing parameterized types, types as parameters, and even a disciplined form of self-application. Our method defines a calculus of \"signatures,\" where signatures are similar to the \"program types\" of [Reynolds78]. Each identifier and expression is given a signature, and applications are type-correct when argument and parameter signatures are equivalent under a simple set of signature transformation rules. Below we present the signature calculus of Russell; we also present a semantic justification of this calculus and specify the language constraints necessary for us to justify our purely static approach to type-checking.", "authors": [{"name": "Alan J. Demers", "author_profile_id": "81100529925", "affiliation": "Cornell University, Ithaca, New York", "person_id": "P12362", "email_address": "", "orcid_id": ""}, {"name": "James E. Donahue", "author_profile_id": "81100145919", "affiliation": "Cornell University, Ithaca, New York", "person_id": "PP42049977", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567446.567448", "year": "1980", "article_id": "567448", "conference": "POPL", "title": "Data types, parameters and type checking", "url": "http://dl.acm.org/citation.cfm?id=567448"}