{"article_publication_date": "01-28-1980", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1980 ACM 0-89791-011-7 $5.00 Our primary (but not exclusive) concern in the present report is the analysis \nof the class L of simple programs, mainly because nontrivial questions about the behavior of programs \nin Ln, for n .4 2, are recursively undecidable. And in order to go beyond the work of Tsichritzis [2], \nour LOOP Pro9r~s will use more general instructions then those mentioned earlier in this section. II. \nDIFFERENT BASES OF PRIMITIVE STATEMENTS We consider therefore extending the language of loop programs \nin the following way. We leave their itera\u00adtive structure unchanged, but we allow other types of assignment \nstatements in addition to the three men\u00adtioned above. Primitive assignment statements in loop programs \nwill now be of the following types--listed alongside equivalent arithmetic operations, each of which \nbeing later used to abbreviate the corresponding type of assignment: (1) X+o O (the conatent zero) (2) \nX+Y id (the identity operator) (3) X+succ(x) Succ (4) X +pred(X) pred (5) X+succy(x) SUCCY (the Y-th \nsuccessor) (6) X +predy(X) predy (the Y-th predecessor) (7) X+max(YrZ) max (8) X +min(Y, Z) min (9) \nX+Y+Z i\u00ad (10) X+-Y:Z :  where X, Y, andyZ, may be replaced by the names of any variables. Note how \nthe operators SUCC, pred, Succy, and pred , are used; e.g., a statement of the form X + SUCC(Y) will \nnot be primitive (as opposed to macro ) if X and Y are distinct variables. We shall require that if a \nstatement of the form X + SUCCY(X) or X * predy(X) appears inside a LOOP-END pair, then variable Y cannot \nbe mentioned on the left-hand side of any assignment statement inside the LOOP-END pair in qUeStlOn. \n(Without this restriction assignment type (5) is equivalent to type (9), and type (6) equivalent to type \n(10).) Other possible primitive statements will be conditional statements, taken in the followin9 fOrm-\u00adalongside \nits abbreviation: (11) IF X=O THEN Al ELSE A2 IF-THEN-ELSE where X is any variable, and Al and A2 are \nfinite blocks of already defined statements. A base 8 over which loop programs may be written ie then \ndefined to be any subset of the primitive statements just listed. The corresponding class of loop programs \nwith loop-nestings of depth S n is de\u00adnoted by L (~), and the class of functions they compute by 8 (~). \nThus if ~= {O, id, SUCC}I which is the setnof assignment statements over which loop programs w&#38;e \noriginally considered by Meyer and Ritchie, we then have that &#38;n(w) $ &#38;n+l (8) for all n, and \n#2(fi) is the class of elementary functions. Moreover, the equivalence problem of L..(a) for n 2 2 is \nundecidable, whereas the equivalence problems for LO(8) ~d L1(6-) are decidable. n - We mainly consider \nhere the claeses LL(3) of simple programs over different bases % of primitive statements. One of our \naims is to study how changes in B affect the analysis of programs in L1(~)--in particular, we examine: \n(1) the equivalence problems of the classes L1(W), for different S s, and the difficulty of the decision \nprocedure involved;  (2) questions of translatability between different classes Ll(~), for different \nD s, and the dif\u00adficulty of the txanslatic.ns involved.  In pursuing these objective, we aleo discover \nthat for come of these classes Ll(w), the run tike Of any program can be bounded above from its syntax, \nand/or mathematical expressions can be uniformly assigned to programs in a natural manner. By considering \nloop programs over different bases of primitive statements, as explained above, some of the issues raised \nhere will be similar to those raised by Constable and Borodin in [3]--except that they were dealing with \nsubrecursive programming languages in general, whereas our particular focus is on classes of programs \ncomputing subelementary functions, for which many of the decieion problems are decid\u00adable (and sometimes \neasily so). III. TRANSLATABILITY RESULTS Let L and L be classes of programe, and ~andg thecorresponding \nclasses ofnumber-theoretic func\u00ad tions they compute. We say that L is (effectively) translatable into \nL if for every program P e L there is (a constructive way to obtain) a program P G L! such that P and \nP~ compute the same function. If there is a translation from L to L , we shall use the notation: L-L \n. And if the translation ,,*,, may be replaced by C , t I P , r is in addition effective, we shall write: \nL ~ L , where the e , according to whether the translation is the (trivial) inclueion map or produces \na program P E L which is of length at most linear , polynomial , or exponentialtt , in the length of \nthe original P E L. A few comments are in order about the complexities involved: (1) Whenever one of \nour translation procedures is Q , or p , or e , it also happens that it will take at meet linear, or \npolynomial, or exponential time, respectively --but not more--as a function of the size of the source \nprogram P. (Of course, the time complexity of a translation procedure cannot be of order less than that \nof the etring, i.e. the object program P , it writes out.) (2) Although we do not have optimality proofs \nfor our translation procedures, it seems that there is no room for improvement on their complexities: \nfrom exponential to polynomial, and from polynomial to linear. In particular, the nature of the programming \nlanguages considered in Theorem 3 below suggests that the translations labeled e cannot be replaced by \nequivalent polynomial translations. This question will be pursued in a subsequent report. (3) ?+n important \nquestion, which we have not investigated, is to also compare the run times (in ad\u00addition to the sizes) \nof an original program 1? c L and its translated version P e L .  Clearly the aesertion L ~ L is equivalent \nto the assertion &#38;c ~. But while L &#38; L necessarily implies <~< , the opposite implication is \nnot always tr~e. Some translatability results are trivial; e.g., if n < n and ~~ ~ then Ln(&#38;) ~Ln, \n(~ ). Others are by no means obvious, and we list some of them next. 1. THEOREM . Let B be any subset \nof {id,pred,succy,predy,max,min,+,: ,IF-THEN-ELSE}. Then for all n 2 3, c Ln(O,succ) ~ Ln(O,SUCC,ti) \n, where the degree of the polynomial translation depends on ~ and never exceeds 2. That is, for loop-nestings \nof depth 3 or more, the computational power of 100p progrms becomes in\u00adsensitive to the addition of primitive \nstatements other than X * O and X +-SUCC(X). It is important to keep in mind the kind of additional primitive \nstatements we allow here; e.g., using Theorem 4.3 in [3], we can easily show that if ~ were allowed to \ninclude assignment instructions of the fern X + Y X Z, then the ebove theorem would no longer be true- \nThe situation is quite different for loop-nestings of depth < 2. 2. THEOlU3M . Let Ml and ti2 be non-empty \nsubsets of {id,pred,succyrpredy,maxrmin,+,: ,IF-THEN-ELSE]. Then L2(0,succ) ~ L2(0,succ, W1) ~ L2(0,succ,Y32) \n,T where the degrees of the polynomial translations depend on ~1 and ~2, but never exceed 2. 3. THEOP.EM \n. Let )331 and ~2 be subsets of {id,pred,IF-THEN-ELSE}. All possible translations from L1(O,succ, ~l) \nto L1(0,succ,X32) can be read off the following diagram: L1(O,succ,pred) / \\ L1(O,SUCC)<L(O,~uccrzd) \n>L~:ISUCCIPTedIid) P Ll(O,succ,pred ,IF-THEN-ELSE )1 e n i1 [P L1(O,SUCC,IF-THEN-ELSE) L1(O,succ,pred,id, \nIF-THEN-ELSE) [ (4n L1(O,SUCC,IF-THEN-ELSE, id) If an omitted arrow in the above diagram cannot be obtained \nby composition from the arrows already drawn, then it is a case of non-translatability, which also requires \nsome proof. One conclusion of the preceding theorem is that in the presence of loops, id and IF-THEN-ELSE \nare equivalent proqranuning features, in that they add the same computational power to programe. This \nie not the case in-the absence of loops, where id does not add to the computational power of programs \nwhile IF-THEN-ELSE does, as seen from the next result. 4. THEOREM .  /:0 -::\\ Lo (O,succ) Lo(O,succ,pred \n,IF-THEN-ELSE) !t Lo 1 n (O,succ,id) Q o t~ in Lo(Orsucc,pred,id, IF-THEN-ELSE) \\ / LO(O,SUCC,IF-THEN-ELSE) \nin ti Lo(O,succ,id, IF-THEN-ELSE) Again here, if an omitted arrow is not obtainable by composition from \nthe arrows in the diagram, then it is a case of non-translatability. IV. CHARACTERIZATIONS OF SOME SUBELEMENTARY \nCLASSES Let fl, f2, . . . . be number-theoretic functions. The class of all functions obtained through \ncomposition from fl, f2, . . . . will be denoted by: [f1,f2,. ..l. For the next theorem we need to define \nspecial functions on, u:, L./k], and W: On(xlr. ..,xn) = o; U;(X ,...,xn) =xi, withl<i <n: 1 Cx\\k] = \ninteger division of x by constant k; xl, ifx=O 2 W% X2) = o { , ifx *O. 2 1. THEORFM . We have the following \nalgebraic characterizations: (I) %l(o,succ) = [On,U:,SUCC,W,+l ; (2) #l(O,succ,pred) = [on,u~,succ,w,+,:l \n; (3) <l(O,succ,Pred,IF-THEN-ELSE) = [on,u~,succ,w,+,s,[.fil 1 .  Proving tha c the sets on the right-hand \nside are included in the corresponding sets on the left-hand side is an easy programming exercise; proving \nthe opposite inclusions is the difficult part of the theorem, which consists in finding for every loop \nprogram of the kind under consideration a function it computes from the set on the right-hand side. By \nTheorem 111.3, <l(O,succ,pred, IF-THEN-ELSE) in (3) above may be replaced by~l(O,succ,pred, id) or by \nxl(O,succ,pred,id,IF-THEN-ELSE) . Also, these three characterizations should be compared with the characterization \nobtained by Tsichritzis [2] in proving the decidsbility of L1(O,succ,id) , which can be expressed as: \n~l(o,succ,id) = [on,u~,succ,w,+,pred,[./k],[.,k] 1 , where Cx,kl = remainder upon dividing x by constant \nk. For part (3) of the next theorem we need to make the following restriction. All assignment statements \nincluded in a base w as primitive statements can each be executed in one time unit; all other statements \nare macros, and the time cost of each is the time required to execute a macro definition for it in terms \nof the primitives. Furthermore, if conditionals IF X=O THEN A, ELSE A. are also primitive then the time \nre\u00ad quired to execute each one of them = 1 (the cost for X=O ?*) + the cost of Al or A2--depending on \nwhich of the two branchee is executed. Let us say that f: ~k + ~ is linear (respec. , a.e. linear) in \nxi, 1< i s k, if for all sets of con\u00adstants a ,...,a, ,ai+l,.. .r ~ c q , the function f(alt-. .,xi,~). \n,~) is linear (respect. , a-e. linear). 1 l-l 2. THEOREM . We have the following alternative characterizations: \n(1) ~l(O,succ,pred) = {flf is a.e. linear in each of its variables]; (2) ~l(O,succ,pred,IF-THEN-ELSE) \n= {all functions computable in linear time}.  (<l(O,SUCC) is not equal to the set of all functions f \nsuch that f is linear in each of its variables, but properly includes it.) For the next reeult, the restriction \nintroduced for the preceding theorem may be lifted. That is, the result holds even if we do not assign \na uniform cost of one time unit to every primitive statement; in particular, instructions of the form \nX + SUCCY(X) may be assigned arbitrary costs of polynomial order. 3. THEOREM . Let ~ be a subset of {O,id,succ,pred,succy,predy,max,min,IF-THEN-ELSE}. \nThen ~l(O,s.ccy,TF-THEN-ELSE, %3) ={ functions computable inpolynomial time], where the time complexity \nof function may be measured on any other model of computation which is poly\u00adnomially related to loop \nprograms over the primitives under consideration. v. DECISION PROCEDURES Using Theorems 111.1 and 111.2, \nand the fact that KLeenels predicate T(n,xry) is elementary (i.e. its characteristic function is elementary) \n, the following result is immediate. 1. THEOP.EM. Let ~ be any subset of {O,id,succ,pred,succy,predy,max,min,+,~,IF-THEN-ELSE]. \nThen for all n > 2, the equivalence problem of Ln(O,succ,~) is recursively unsolvable. 2. THEOREM . \nLet P, P c L1(O,SUCC), and IPI and 1P*I be the respective lengths of P and P . Then whether  P is equivalent \nto P is solvable in time proportional to IP[ + lPt 1; that is, the equivalence problem of L1(O,SUCC) \nis solvable in linear time. 3. THEOREM. The equivalence problem of Ll(O,succ,pred) is solvable in exponential \ntime. (Proved by reduction to a problem of establishing the positivity of linear forms over %.) In light \nof the next result, it does not seem that we can cut the time complexity of the decision procedure in \nthe preceding theorem down to polynomial order. 4. THEOREM. The inequivalence problem of L1(O,succ,pred) \nis NP-hard. (Proved by reducing the Satisfiability Problem to the inequivalence problem considered here.) \n 5. THEOREM . The equivalence problem of Ll(O,succ,pred,id) --and thus, by Theorem 111.3, that of  L1(O,succ,pred,IF-THEN-ELSE) \nand that of L1(O,succ,pred,id,IF-THEN-ELSE) too--are each solvable in time exponential in the time required \nby the decision procedure for Presburger arithmetic. (Proved by reduction to Preeburger arithmetic.) \nUeing the best known bound for a decision procedure of Presburger arithmetic, the time complexity of \nthe procedure in Theorem 5 is: C(IF I+IP 1) 22 0(22 ). Although this complexity makes the decision procedure \nimpractical, it improves by one exponential level a similar result in Cherniavsky [5]. The next result \nshows that, if this bound can be improved further, then it cannot be improved by more than one additional \nexponential level. 6. THEOREM . The problem of deciding the truth of Presburger formulas is polynomially \nreducible to the equivalence problem of Ll(O,succ,pred,id). (Proved by using the characterization of \npart (3) in Theorem IV.1.) 1. Meyer and Ritchie, The complexity of Loop p rograms, Proc. 22nd Nat. Conference \nACM, 1967. 2. Tsichritzis, The equivalence problem of simple programs, JACM, 17 (1.970), PP. 729-738. \n 3. Constable and Borodin, Subrecursive programming languages, Part 1: Efficiency and p rogram structure, \nJACM, 19 (1972), pp. 526-568. 4. Jones and Muchnick, Even simple programs are hard to analyze, JACM, \n24 (1977), PP. 338-350 (also 2nd ACM SIGACT-SIGPLAN Symposium record, p. 106). 5. Cherniavsky, Simple \nprograms realize exactly Presburger formulas, SIAM J. Comp., 5 (Dec. 1976), no. 4.  \n\t\t\t", "proc_id": "567446", "abstract": "It is well known that most questions of interest about the behavior of programs--such as equivalence, halting, optimization, and other problems--are undecidable. On the other hand, it is possible to make some or all of these questions decidable by introducing appropriate restrictions on the programming language under consideration. And once such restrictions are made, the next step is to ask how hard it is to solve these problems for programming languages for which they are decidable.This analysis of programming languages has been undertaken by others, in particular by Jones and Muchnick [4], who choose to restrict their programs to operate over finite memory. Our approach starts from the language of loop-programs, as defined by Meyer and Ritchie [1], in which we in fact allow more general arithmetical operations. Unlike Jones and Muchnick, we do not place any restriction on memory here; instead, we (primarily) restrict our attention to loop-programs without nested loops.", "authors": [{"name": "A. J. Kfoury", "author_profile_id": "81332508516", "affiliation": "Boston University, Boston, MA", "person_id": "PP43126515", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567446.567452", "year": "1980", "article_id": "567452", "conference": "POPL", "title": "Analysis of simple programs over different sets of primitives", "url": "http://dl.acm.org/citation.cfm?id=567452"}