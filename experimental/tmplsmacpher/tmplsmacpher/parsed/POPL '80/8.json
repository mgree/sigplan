{"article_publication_date": "01-28-1980", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1980 ACM 0-89791-011-7 $5.00 are used when analyzing invoking procedures, avoiding the problems mentioned \nabove. The methods proposed by Barth and Banning have a number of advantages over that proposed by Allen, \nincluding greater speed, fewer passes required over the code, and the handling of recursion. Rosen s \nmethod, though slower than the others mentioned here, can produce more precise information. Unfortunately \nthese methods are not sufficiently general to be used for many languages. Specifically, all of these \nmethods require a call graph. However, if procedure variables are included in the language, the call \ngraph cannot be obtained through a simple scan of the text of the program being compiled. Further complications \noccur when aliasing [12] among variables in the program is possible. This can result from mechanisms \nsuch as pointers and call-by-reference parameter passing. These two mechanisms are the ones considered \nin this paper. As an example of the problems which aliasing can cause, a call on a procedure variable \nusing call-by-reference could have the effect, depending on the value of the procedure variable at the \ntime of the call, of assigning a procedure value to one of the parameters of the call. This fact must \nbe taken into account in constructing the call graph, for if procedure A contains a call on procedure \nvariable X, the call graph must contain arcs from the node for procedure A to the nodes for each procedure \nwhich X can have as its value. Another language feature which complicates the situation is the use of \nlabel variables. Such a feature prevents the construction of a control flow graph until the possible \nvalues of all label variables in the program have been determined. Since a control flow graph is required \nfor standard data flow analysis, it is necessary for some part of the analysis phase of the compiler \nto compute this range information for label variables before standard data flow analysis is performed. \n2. RELATED WORK Very little work has been done on the problem of handling procedure variables and pointers \nin performing interprocedural data flow analysis. Spillman [12] is the only one who addresses the problems \nassociated with these language features. However, there are a number of limiting aspects to Spillman \ns work. First, the algorithm requires iteration in the presence of recursion. This can lead to large \ntime requirements. Second, the algorithm is presented at a low level, making it difficult both to understand \nand to verify. Finally, the algorithm as presented is specific to certain features of PL/1. This, combined \nwith the low level of presentation, makes it difficult to adapt the algorithm for use in compiling other \nlanguages. Ryder [11] presents an algorithm which determines the call graph for a program with procedure \nparameters. The algorithm is designed to be used with Fortran and is meant to be portable across a wide \nrange of machines. The portability constraint leads to limitations on the use of in-core storage; these \nlimitations influenced the design of the algorithm. The intent to use the algorithm for Fortran leads \nto the assumption that there is no aliasing and no recursion. These factors all limit the general applicability \nof the algorithm. The methods proposed by Allen, Barth, Banning, and Rosen solve the problems associated \nwith procedure variables and pointers to varying degrees, usually by placing restrictions on the use \nof these features in the programs to be compiled. In the extreme case these features are not allowed \nat all. 3. PROPOSED SOLUTION We propose to deal with the problems introduced byp,ointers, procedure \nvariables, and label variables by first computing range information (i.e., lists of possible values) \nfor procedure variables, thus providing a call graph, and then using one of the known methods, such as \nBarth s, for generating summaries. It is necessary to compute aliasing patterns as well as range information \nfor pointers while computing range information for procedure variables, simply because procedure variables \ncan acquire values as a result of aliasing with other variables. All of this information will be computed \nwithout taking control flow information into account. It will subsequently be used to compute range information \nfor label variables and to generate summaries for procedures, prior to generating a control flow graph. \nThe context in which this work has been done is that of the Experimental Compiling System (ECS) project \nof the Computer Sciences Department at IBM s Watson Research Center. An overview of this project is given \nin [5]. Briefly, the goal of the project is to build a general purpose optimizing compiler which, given \nthe appropriate source language definition and target machine description, can compile programs for that \nsource language into code for that target machine, Clearly it will not be possible to compile all languages \nfor all machines. However, it is hoped that it will be possible to compile a large class of languages \nfor a large class of machines. For this reason the analysis and optimization phases should be formulated \nin a manner which is as independent as possible of language and machine. The ECS compiler attempts to \ntreat primitives of the intermediate language and previously analyzed procedures as uniformly as possible, \nat least as far as analyzing a program which uses them. This is accomplished by associating with each \nprimitive and each analyzed procedure a summary of its effects. Information contained in such a summary \nincludes lists of variables which are used, modified, and preserved, as well as an indication of the \ncopies which may be performed when the primitive or procedure is invoked. For example, the summary for \na primitive which moves data from its second argument to its first argument would specify that the primitive \nuses and preserves its second argument, modifies its first argument, and performs a copy of its second \nargument into its first argument. The information about copies is used in propagating procedure, label, \nand pointer values. Thk means that in order to analyze a program, we need either the code or a summary \nfor every procedure which it calls. This might seem to force a compilation order for separately compiled \nprograms, and to achieve reasonable optimization of the programs, it does. However, it is desirable to \nbe able to compile programs separately, and to allow this to be done in any order. This creates two problems \nin analyzing a procedure. First, the effects of the caller, such as aliasing of parameters, may be unknown. \nSecond, there may be calls on procedures for which no summary exists. In either case, the worst case \nmust be assumed. In ECS the second case is treated by creating a summary for the unknown procedure, and \nensuring that this summary specifies all of the possible effects of the procedure. The first case is \nsomewhat more complicated; in effect, the program is treated as if there were a call on the procedure \nwhich causes all possible parameter aliasing, including with external variables. If any of the parameters \nare procedure variables the problems are compounded. This is because a call on the parameter could be \na call to a procedure which was passed as an actual parameter, and the effects of this procedure are \nunknown. We omit the details of the handling of such situations. We assume that we are given a collection \nof procedures, each of which consists of a set of instructions. Each instruction consists of an opcode, \nwhich indicates a call on either a primitive, a previously analyzed procedure, a procedure in the collection, \nor a variable, and a list of operands, each of which is either a variable or a constant. Expressions \nare not allowed as operands; rather, we assume that the computation of expressions has been expanded \ninto sequences of instructions. Operands are assumed to be passed by reference. For each opcode which \nis a ,primitive or a previously analyzed procedure we assume that there exists a summary for that opcode. \nThis summary must specify all of the possible copies among parameters and globals in which a call on \nthe opcode could result. We make no assumptions about the possible flow of control between instructions \nin a single procedure. Given such a collection of procedures, the problem is to compute sets of possible \nvalues for procedure variables, sets of possible values for label variables, sets of variables which \nmay be addressable through pointer variables, and sets of possible aliases for all variables. In the \nnext section we show that this problem is inherently very difficult. In succeeding sections we present \nour solution in stages, demonstrating its correctness and evaluating its precision and time requirements. \nFollowing this we discuss briefly some characteristics of the alias relationships as computed by our \nmethod, and then summarize our results. 4. COMPLEXITY In this section we show that the problem of determining \npossible values for procedure variables is P-space hard. We assume some familiarity with the term P-space \nhard . A definition of this term and a discussion of its significance can be found in [1]. In fact, we \nprove the following theorem, which makes a stronger statement. T%eorem: Determining possible values for \nprocedure parameters for programs in which there is no aliasing among variables, no nesting of procedure \ndeclarations, and no significant flow of control, and in which every procedure is formally reachable, \nis a P-space hard problem. This theorem is significant for a number of reasons. First, it indicates that \nit is extremely unlikely that there is any efficient method for computing possible values for procedure \nvariables. Second, and perhaps more important, it shows that even when assignment statements, aliasing, \nand nesting of procedure declarations are not allowed, it is still unlikely that an efficient method \nexists. Furthermore, this is still true when there is no significant control flow in the program being \nexamined, other than that implied by the call graph. These results lead one to search for solutions to \nthe problem which are approximate and reasonably efficient, such as the one presented in this paper. \nThese solutions may not produce exact information, but they must produce safe information; i.e., information \nwhich is conservative in that the possible values determined should be a superset of the exact possible \nvalues. We make the restriction that all procedures be formally reachable since this is an assumption \nwhich is often made in compilers. Proof We make use of a theorem proved by Winklmann [16], in which he \nshows that deciding the property of formal reachability in programs without nested procedure declarations \nis a P-space hard problem. Formal reachability is defined in terms of a formal execution tree, which \nis a tree of calls where the nodes of the tree are pairs consisting of procedures and their environments. \n(This is not the same as reachability defined in terms of a call graph as it is usually used in compilers.) \nWinklmann shows this by constructing a program P for a given Turing machine M, polynomial s, and input \nw, such that a procedure HALT in P is formally reachable if and only if M, when started in its initial \nstate with w written on its tape and its head scanning the leftmost symbol of w, halts without its head \never moving outside the s(n) squares to the right of, and including, the tape square scanned at the start, \nwhere n is the length of w. P satisfies all of the requirements given in the statement of the theorem \nexcept for the restriction that all procedures be formally reachable, and can be constructed in polynomial \ntime from a description of the Turing machine M, the input w, and the polynomial s. In addition, P has \nthe property that there is a procedure Qf such that Qf is formally reachable in P if and only if M, when \nexecuted with input w, enters its final state without its head ever leaving the boundaries stated above, \nQf contains a single call to the procedure HALT. Deciding whether HALT is formally reachable is therefore \nas difficult as deciding whether M halts in the required manner. Furthermore, HALT is formally reachable \nif and only if Qf is formally reachable. Since the first parameter of Qf has no possible values if Qf \nis not formally reachable, and has exactly one possible value if Qf is formally reachable, it follows \nthat determining whether a given procedure parameter has a non-empty set of possible values is a P-space \nhard problem. This problem can be easily solved given the set of possible values for the procedure parameter, \nso determining sets of possible values for procedure parameters must also be P-space hard. We have not \nyet proved the theorem, since P does not satisfy the restriction given in the statement of the theorem \nthat all procedures in P must be formally reachable. However, it is possible to transform P into a program \nP in which all procedures are formally reachable, and about which we can ask the same kind of question \nwhich we asked about P. Furthermore, the construction of P ! from P can be done in time linear in the \nlength of P. Details of this construction can be found in [15]. The basic idea in constructing P t is \nto introduce calls to every procedure in P, but to do so in such a way that it is still possible to talk \nabout the formal execution of P simulating the execution of the Turing machine M on input w. Since it \nwill then be the case that Qf is always called at least once, the question which we will ask about P \nis whether the first parameter to Qf has more than one possible value. This will be true if and only \nif Qf is called more than once, which will be true if and only if M, when executed on input w, halts \nin the prescribed manner. Therefore, answering this question is P-space hard, and since this question \ncan be easily answered given sets of possible values for procedure parameters, the theorem f Ollows. \n5. THE METHOD As stated earlier, we will present the method in stages. We begin with the simplest case, \na single procedure with no aliasing, and gradually allow more complexity in the program being analyzed \nuntil we have included reference parameters, pointers, and calls on procedure variables. 5.1. NO ALIASING \nWe will first consider propagating values within a single procedure. Given that there is a summary for \nevery instruction in the procedure, create a relation named PVAL and initialize it to all pairs (A,B) \nsuch that B is copied into A. B may be an constant or a variable; A must be a variable. A pair (X,A) \nin PVAL means that X has possible value A. PVAL ranges over the variables in the program for which we \nwish to determine values and over the values which we are interested in propagating. We determine which \ncopies are possible by examining the instructions in the procedure. For each instruction, consider each \ncopy in the summary for the opcode of the instruction. If one of the elements of the copy is a formal \nparameter of the opcode, substitute the corresponding operand of the instruction. The resulting copy \ngives a pair which should be placed in PVAL. To propagate values, replace PVAL by its transitive closure \nPVAL+. For variable X and constant A, the resulting relation gives an answer to the question of whether \nA is a possible value of X. We claim that propagating values in this manner, for this limited case, is \nboth correct and as precise as possible. To show that it is correct, suppose that a variable X has value \nA at some point during the execution of the program. For X to have value A, the execution of the program \nmust include a sequence of assignments Xi+ 1 : = Xi, with X. being A and X, being X. If this is the case, \nthen each of these assignments must appear as a copy in the summary of some instruction in the program. \nTherefore each appears as a pair in the initial PVAL relation. From this it follows that the transitive \nclosure of PVAL must include the pair (X, A). Therefore the information computed is correct. To show \nthat it is as precise as possible, suppose that there is a pair (X,A) in the transitive closure of PVAL. \nThere must exist a sequence of pairs (Xi+l ,Xi) in the initial PVAL relation, with XO being A and Xn \nbeing X. Each of these pairs corresponds to a copy specified by the summary for some instruction in the \nprocedure. Since we are making no assumptions about the possible flow of control between instructions \nin the program, any sequence of instructions must be considered possible. In particular, the sequence \nof instructions which corresponds to the given sequence of copies must be considered possible. This means \nthat, ignoring control flow information, X may have A as value. Therefore the information computed is \nprecise. The complexity of this algorithm is bounded by the complexity of computing the non-reflexive \ntransitive closure of an n x n matrix, with n being the total number of variables and values involved \nin the propagation. Under the assumptions made up to this point, this is asymptotically the best possible \nalgorithm for computing this information. We can show this by demonstrating that computing this information \nis of the same complexity as computing the transitive closure of a matrix. We consider a single procedure \nand assume that we have no control flow information. If P(n) is the time to propagate values for a program \ncontaining n variables and constants, and T(n) is the time to compute the transitive closure of an n \nx n matrix, we must show that there exists a constant c such that T(n) < cP(n). Suppose that we have \nan n Xn binary matrix M and we wish to compute its transitive closure. We first create variables Xi and \nconstants Ai, for 1 s i s n. For each Xi we create an instruction whose summary indicates a copy to Xi \nfrom Ai. For each 1 in the matrix, say at position (i,j), we create an instruction whose summary indicates \na copy to Xi from Xj. These instructions constitute the procedure for which we wish to propagate values. \nWe claim that Xi has possible value Aj if and only if there is a 1 in position (i,j ) in the transitive \nclosure of M. This implies that T(n) s P(2n). Since P(n) is bounded by the time to compute transitive \nclosure, and this is 0(n3), we can assume that P(2n) s 8P(n). From this we conclude that T(n) < 8P(n). \nNow consider the situation in which the program to be analyzed consists of multiple procedures, and in \nwhich instructions may be calls on primitives, previously analyzed procedures, or procedures in the given \ncollection. Operands to primitives and previously analyzed procedures are passed by reference while operands \nto procedures in the collection are passed by value. Propagating values in this situation is almost identical \nto propagating values in the case of a single procedure. The only difference is that we must account \nfor the transmission of values from actual parameters to formal parameters. This can be done in initializing \nthe relation PVAL. For each call on a procedure P in the collection, where P is declared with formal \nparameters Xi, and the call has corresponding operands Yi, add the pairs (Xi,Yi) to PVAL. For each other \ninstruction initialize PVAL as before. Then form the transitive closure PVAL+. We claim that, as in the \ncase of a single procedure, this computes correct and completely precise information, and does so asymptotically \nas quickly as possible. The proof is quite similar to the previous proof; we omit the details. 5.2. \nCALL BY RE.TERENCE We now wish to allow parameters to procedures in the collection to be passed by reference. \nThis means that when a value Y is copied into a variable X, there is an implied copy of Y into each alias \nof X. There are now two different effects to consider. The first is the modification of a variable by \nassignment to it. The second is the association of a formal parameter with an actual parameter by a call \nto the procedure which owns the formal. To keep track of this information, we create two relations called \nMODVAL and AFFECT. A pair (X,A) in MODVAL means that X is assigned value A. A pair (X,A) in AFFECT means \nthat X may be aliased to A and to every other variable which may be aliased to A. However, it can be \nthe case that there is some variable which may be aliased to X but not to A. The characterization of \nparameter aliasing with AFFECT was first suggested by Barth [7]. MODVAL is initialized to all copies \nwhich are specified in the summaries of instructions in the program. AFFECT is initialized to all formal-actual \nparameter pairs which result from calls to procedures in the collection. Assume for the moment that constants \nare never used as actual parameters for calls to procedures in the collection. We will relax this restriction \nin the final version of the algorithm and will explain the reason for it at that time. Barth shows that \nthe ALIAS relation, which indicates the possible aliasing relationships among variables, may be computed \nby the expression AFFECT* o (AFFECT* ) T. We claim that the following computation results in PVAL specifying \ncorrect possible values: PVAL := (AFFECT V ( (AFFECT*) T oMODVAL)) , where R* denotes the reflexive \ntransitive closure of the relation R, RT denotes the transpose of R, and R+ denotes the non-reflexive \ntransitive closure of R. We first note a theorem by Barth [7], which states that a modification of a \nvariable can affect any actual parameters, including the variable itself, which correspond to the variable, \nas well as any formal parameters which correspond to any of those actuals. Observe that if the variable \nis not a formal parameter then the set of corresponding actuals will include only the variable itself. \nFurthermore, a modification of a variable can affect only these variables. He then goes on to show that \nAFFECT* gives, for each formal parameter, all of the possible corresponding actuals. Now suppose that \nvariable X can have possible value A at some point in the execution of the program. There must be a sequence \nof calls and assignments which resulted in the assignment of A to X. For each call in the sequence which \nmatches formal Y with actual Z, the pair (Y,Z) is in AFFECT and therefore in PVAL. For each assignment \nof Z to Y in the sequence, the pair (Y,Z) is in MODVAL and therefore in PVAL. Furthermore, if W is aliased \nto Y, there exists a U such that W AFFECT* U and Y AFFECT* U, as shown by Barth. The pair (U,Z) is therefore \nin PVAL, since we know that U (AFFECT*) T o MODVAL Z. The pair (W,U) is also in PVAL, since each pair \nin AFFECT is in PVAL. Since PVAL is closed, the pair (W,Z) must be in PVAL. Therefore, each pair corresponding \nto the values transmitted by each action in the execution sequence of the program is in PVAL. This implies \neach pair corresponding to the values transmitted by the sequence as a whole must be in PVAL. In particular, \nthe pair (X,A) is in PVAL. Therefore the information computed is correct. Since the complexity of boolean \nmatrix multiplication is the same as that of transitive closure, the complexity of this algorithm is, \nlike the previous versions of the algorithm, bounded by the time to compute the transitive closure of \nan n x n matrix. Furthermore, since this algorithm computes the same information for a single procedure \nas the previous algorithm, it can be argued that this algorithm is asymptotically the fastest possible \nalgorithm for computing the information which it produces. This algorithm does not compute completely \nprecise information. The imprecision stems from the use of AFFECT to characterize parameter aliasing, \nand is discussed by Barth in [7]. As a simple example of the imprecision, consider the skeleton program \nin figure 1. In this example, A should be assigned Q by the first call on P, and B should be assigned \nR by the second call on P. However, the method determines procedure P(S,T); .. . S:=T; . .. ; procedure \nQ; procedure R; procedure variable A,B; P(A,Q); P(B,R); Figure 1 that both A and B have possible values \nQ and R. This results from the fact that, based on the assignment of T to S, we propagate all values \nof T to S and then to all actual parameters for S. The basic reason for this is that separate calls on \na procedure are not treated separately.  5.3. POINTER VARIABLES We now introduce pointer variables into \nthe programs being analyzed. We do so in two steps, first considering a single procedure and then allowing \nmultiple procedures with parameters passed by reference. As mentioned earlier, it is necessary to augment \nthe summary information kept for primitives and previously analyzed procedures to give some information \nabout indirect accesses through variables. To simplify the summaries no information will be kept about \nthe number of levels of indirection involved in accessing storage through a pointer, e.g., in accessing \nan element of a list. Instead, a distinction is made only between a direct access of a variable and an \naccess of storage via some positive number of indirection on a variable. The summaries must now distinguish \nbetween four types of copies. Letting P and Q denote variables and *P and *Q denote storage accessible \nthrough the variables, these four types are as follows: l) P:=Q 2) P:= *Q 3) *P :=Q 4) *P :=*Q Two other \ntypes of copies are also allowed. These involve the assignment of the address of a variable to another \nvariable or to storage accessible through another variable. These are as follows: 5) P := addr(Q) 6) \n*P : = addr(Q) We will utilize the relations AFFECT and MODVAL. Previously these relations dealt with \nthe variables and values which were interesting in terms of propagating values. To handle pointers and \nthe transmission of values via assignments to storage accessible through pointers, we introduce dummy \nvariables for each pointer variable. For a pointer variable P this dummy variable is meant to represent \nthe storage accessible through P and will be denoted by *P. To propagate aliasing information correctly \nbased on the assignment of the address of a variable to another variable, we introduce dummy literals \nfor each variable whose address is copied. For a variable Q whose address is copied (cases 5 and 6 above), \nthis literal will be denoted by AQ and represents the address of Q. l) P:=Q Add Add the the pair pair \n(P,Q) to (* P,*Q) MODVAL. to AFFECT, 2) P := Add Add *Q the the pair pair (P,*Q) to MODVAL. (* P,*Q) \nto AFFECT. 3) *P := Add Add Q the the pair pair (*P,Q) (* P,*Q) to MODVAL. to AFFECT. 4) *P := Add Add \n*Q the the pair pair (* P,*Q) (* P,*Q) to MODVAL. to AFFECT. 5) P := Add Add Add addr(Q) the pair the \npair the pair (P,AQ) (*P,Q) (* P,*Q) to MODVAL. to AFFECT. to AFFECT. 6) *P := Add Add Add addr(Q) the \npair the pair the pair (*P,AQ) (*P,Q) (* P,*Q) to MODVAL. to AFFECT. to AFFECT. Figure 2 Figure 2 describes \nthe initialization of AFFECT and MODVAL for each type of copy. If one element of a copy, say X, is not \na pointe~ variable, then all pairs involving *X should be ignored. TO give some intuition about the \nreasons for initializing the relations in this manner, consider the simple assignment P : = Q. If P and \nQ are pointer variables, this has two effects. First, it results in P (and any alias of P) acquiring \nthe value contained in Q. It also causes any storage accessible through Q to be accessible through P, \nfrom which it follows that every alias of *Q is an alias of *P, There are many similarities between the \neffects which occur due to parameter aliasing and those occuring due to the use of pointers. If there \nare several assignments to a pointer P, say from Q and R, then *P is aliased to both *Q and *R, but *Q \nand *R are not necessarily aliased. On the other hand, if p is assigned to several pointers, say Q and \nR, then *Q and *R are both aliased to *P and, since Q and R may be assigned the same value, *Q and *R \nare aliased to each other. These two situations are very similar to two situations which can occur with \nreference parameters, the first being when two different actual parameters are passed to the same formal \nparameter, and the second being when a single actual is passed to two formals, In fact, parameter aliasing \nbehaves much like pointer aliasing, something which makes more sense when we consider the fact that a \ncall binds the formal parameters to the locations occupied by the corresponding actual parameters for \nthe duration of the call. In effect, for formal X and actual Y, there is an assignment of the form addr(X) \n: = addr(Y). Taking addr(X) to be a variable, so that the storage accessible through it is simply X, \nwe see that the initialization for such a copy is exactly that used in initializing the relations for \na call using call-by-reference; i.e., add the pair (X,Y) to AFFECT. However, the algorithm which we \nused to propagate values for reference parameters is not sufficiently general to handle pointers. Although \nthe effects are very similar in the two cases, there is one crucial difference. We mentioned that the \nbinding of a formal parameter to an actual parameter is in effect an assignment of the address of the \nactual to the address of the formal. Considering these two addresses to be variables, this almost models \nthe situation which occurs with pointers. The difference with pointers is that the variables which contain \naddresses can be aliased as well, and so assignments to a pointer variable must be propagated to all \nof the aliases of the variable. This includes assignments of the address of a variable (cases 5 and 6). \nFurthermore, for any variable which is assigned the address of another variable, it is necessary to ensure \nthat the appropriate aliasing is computed between the second variable and the storage accessible through \nthe first variable. The method which we choose to solve this problem is to iterate. For each modification \nto a variable which we discover, we will add the aliasing relationships implied by that modification \nand then iterate to see if this produces any more modifications. This produces the algorithm in figure \n3. The function ind returns the object which denotes storage accessible via one level of indirection \non X. If X is of the form AY, Y is returned. If X is of the form Y and Y is a pointer variable, *Y is \nreturned; if Y is not a pointer variable then the pair should be ignored. Finally, if X is of the form \n*Y, *Y itself is returned. For each modification X := Y, this explicitly propagates the implied aliasing \ninformation to all Z such that X AFFECT* Z. The propagation to other aliases of X, e.g., to those Z such \nthat Z AFFECT* X, is already done by virtue of the fact that whenever we have Z AFFECT* X we also have \ninitialize AFFECT and MODVAL as indicated above. repeat M : = (AFFECT*) T o MODVAL for each (X,Y) in \nM Add (ind(X),ind(Y)) to AFFECT Add (ind2(X),ind2(Y)) to AFFECT until there is no change in AFFECT PVAL \n: = (AFFECT v ((AFFECT*) T o MODVAL))+ Figure 3 *Z AFFECT* *X. Adding (* X,*Y) to AFFECT and then recomputing \nthe closure of AFFECT will give *Z AFFECT* *Y, as desired. The key to demonstrating the correctness of \nthis algorithm lies in the definition of AFFECT. Remember that a pair (X,Y) in AFFECT means that every \nalias of Y is also an alias of X. Now suppose that variable X has value A at some point in the execution \nof the program. There must be a sequence of assignments which results in the assignment of A to x. Assume \nthat for the ith assignment in the sequence, all of the possible aliasing which can result from previous \nassignments is embodied in AFFECT. We will show that the same is true for the aliasing which results \nfrom the ith assignment. The proof of the correctness of the computation of PVAL is then identical to \nthe proof used for reference parameters. We first note that for each possible assignment which appears \nin the program, AFFECT is initialized such that if an assignment is the first in the sequence, the aliasing \ncomputed from AFFECT is correct after considering that assignment. The ith assignment in the sequence, \nhowever, could assign a value not just to the explicit target of the assignment, but also to any aliases \nof that target. Assuming that AFFECT contains at least the aliasing information resulting from the previous \ni-1 assignments, and that the target of the ith assignment is W, the computation of M finds all possible \nmodifications of those Y such that W AFFECT* Y. The aliasing implied by these modifications is then entered \ninto AFFECT. We must show that forming the closure of AFFECT computes all aliasing which could result \nfrom the ith assignment. Since W may alias any Z for which there exists a Y such that W AFFECT* Y and \nZ AFFECT* Y, we must show that the pairs entered in AFFECT by the loop over the pairs in M cause the \naliasing for each such Z to be correct. We have shown that this is true for each Y such that W AFFECT* \nY. Since, as may be easily verified, *Z AFFECT* *Y is true if Z AFFECT* Y is true, the aliasing which \nwas entered for Y is transferred to Z when the closure of AFFECT is recomputed. This means that the aliasing \nis correct after considering the ith assignment, from which we can deduce that the aliasing is correct \nafter considering the sequence of assignments. Therefore the computation of PVAL is correct, and so A \nis determined as a possible value for X. We claim that this algorithm is precise as well as correct, \ngiven the assumption that no information about control flow is available. Observe that a pair (X,Y) in \nAFFECT means that every alias of Y, as computed by the expression AFFECT* o (AFFECT* ) T, is also an \nalias of X. Now observe that this is actually the case for every pair which is placed into AFFECT because \nof a modification. From this it follows that the aliasing is precise, which implies that the computation \nof PVAL produces precise information. The reason why the aliasing information computed is precise for \npointers but not for reference parameters is that the call structure of the program contains information \nabout the relative lifetimes of the alias relationships for parameters. Unless control flow information \nis considered, no such information is available for aliasing due to pointers within a single procedure. \nAllowing multiple procedures in the collection with parameters passed by reference requires a change \nonly in the initialization of AFFECT. No change in the propagation algorithm itself is required. For \neach call with operands Yi to a procedure with formal parameters Xi, the pairs (Xi>Yi) and (* Xi, *Yi) \nshould be added to AFFECT. The initialization for all other statements is as above. We omit the details \nof the proof of correctness for this version of the algorithm. The algorithm has the same imprecision \nas it did for programs with reference parameters and without pointers. Before discussing the time requirements \nof this algorithm, we make an observation about the algorithm itself. This is that it is not necessary \nto recompute the transitive closure of AFFECT each time through the loop, nor is it necessary to consider \nthe effects on M of a pair in AFFECT whose effects have already been considered. In other words, we can \npropagate the effects of modifications incrementally. This leads to the equivalent version of the algorithm \ngiven in figure 4. In this algorithm, we keep track of all recently discovered aliasing relationships \nand determine any modifications implied by these relationships. We then compute the aliasing relationships \nimplied by these Initialize AFFECT and MODVAL as indicated above. AFFECT : = AFFECT+ NEWA : = AFFECT \ndo while NEWA * @ M : = NEWAT o MODVAL NEWA := qJ for each (X,Y) in M Add (ind(X),ind(Y)) to NEWA Add \n(ind2(X),ind2(Y)) to NEWA Remove those pairs from NEWA that are already in AFFECT. Add each pair in NEWA \nto AFFECT and reform the closure of AFFECT. Let NEWA be all those pairs which were added to AFFECT by \nthe previous statement, end F VAL :. (AFFECT V ((AFFECT*) T o MODVAL))+ Figure 4 modifications, and \ncontinue this process until no new aliasing is discovered. Let n be the size of the domain of the relations. \nLet e be the total number of pairs in AFFECT* when the algorithm finishes. The initial closure of AFFECT \ncan be done in time T(n). The computation of the contribution of a single pair in NEWA to M can be done \nin time n. Every pair in AFFECT appears in NEWA at this point in the program at most once. Therefore \nthe total time spent in the computation of M for all iterations of the outermost loop is at most ne. \nThe loop over the elements of M can be done as M is computed, and so the total time spent in this loop \nis at most ne. The time spent deleting those pairs in NEWA which are already in AFFECT is proportional \nto the number of such pairs. There are at most 2ne such pairs for all iterations of the outermost loop, \nsince the total number of pairs placed in M for all iterations of the outermost loop is at most ne. Finally, \nthe forming of the closure of AFFECT can be done in time at most n for each pair which is added to AFFECT, \nwhether it is in NEWA or is added in forming the closure after adding a pair in NEWA. There are at most \ne such pairs, so the total time spent forming the closure of AFFECT for new pairs is at most ne. The \ncomputation of PVAL can be done in time O(T(n)). The total time for the algorithm as a whole is therefore \nO(T(n) +-ne).  5.4. CALLS ON PROCEDURE VARIABLES The final step is to consider propagating values through \ncalls on procedure variables. The basic problem with a call on a procedure variable is that at the time \nthe call is encountered in scanning the program, the possible values for the variable, and hence the \nactual procedures which might be called by the statement, are unknown. Therefore it is not possible to \nimmediately associate the actual parameters of the call with the formal parameters of the procedure being \ncalled. To avoid rescanning the program several times, we need a mechanism to keep track of the actual \nparameters of calls on procedures variables. When a value is determined for a procedure variable, we \ncan then associate the actual parameters of the calls on the variable with the formal parameters of the \nvalue. keeps track of the number of actual parameters passed to each procedure variable. If the source \nlanguage requires complete type specifications of procedure variables, i.e., that the types of the parameters \nbe specified as well, then the number of dummy formal parameters which are needed for each procedure \nvariable can be determined from the declaration of the variable. Also, entries *XFi only need to be created \nfor those parameter positions which have pointer types. Having created dummy formal parameters for each \nprocedure variable, the initialization required for a call on a procedure variable is exactly that for \na call cfi G procedure in the collection. If the call has actual parameters Yi and is to procedure variable \nX with dummy formal parameters XFi, the pairs (XFi,Yi) and (*xFi,*Yi) should be added to AFFECT. If we \nconsider a procedure variable X to be a procedure with formal parameters XFi which contains a single \nstatement, that statement being a call on the current value of X with actual parameters XFi, it should \nbe clear that each time a value A is determined for X we should associate the formal parameters of A \nwith the dummy formal parameters of X as formal-actual pairs. One way in which this can be done, as suggested \nby Kenneth Walter [13], is to create relations FPARMi, one for each parameter position. A pair (X,Y) \nin FPARMi means that X has ith formal parameter Y. For each procedure A in the collection with formal \nparameters Yi, the pair (A,Yi) is placed in FPARMi for each parameter position i. For each procedure \nvariable X with dummy formal parameters XFi, the pair (X,XFi) is placed in FPARMi for each parameter \nposition i. Now suppose that A is determined as a possible value for X. If Yi is the ith formal parameter \nof A, and A is a possible value for X, and X has ith formal parameter XFi, then the pairs (Yi,XFi) and \n(* Yi,*XFi) should be added to AFFECT. The expression FPARMi T o PVALT o FPARMi computes the pair (Yi$XFi). \nThis leads to the algorithm in figure 5. This algorithm, like the one developed for pointers, Initialize \nAFFECT and MODVAL as indicated above. repeat M : = (AFFECT*) T oMODVAL for each (X,Y) in M Add (ind(X),ind(Y)) \nto AFFECT Add (ind2(X),ind2(Y)) to AFFECT  The mechanism which we choose to accomplish this is to create, \nfor each procedure variable, dummy formal parameters. For a given procedure variable X which is called \nwith m actual parameters, we create m dummy formal parameters XFij for 1 sism. We also create dummy variables \n*XFi for each dummy formal parameter, representing the storage accessible through the dummy formal. The \nnumber of dummy formal parameters which need to be created can be determined by an initial scan of the \nprogram which PVAL : = (AFFECT v ((AFFECT*) T 0 MODVAL))+ for each parameter position i P : = FPARMiT \no F VAL~ o FPARMi for each (X,Y) in P Add (X,Y) to AFFECT Add (ind(X),ind(Y)) to AFFECT  until there \nis no change in AFFECT PVAL : = (AFFECT v ((AFFECT*) T o MODVAL)) + Figure 5 can be transformed into \nan equivalent algorithm which propagates information incrementally. A similar time bound can also be \nderived for it. Its correctness should be fairly clear given the correctness of the algorithm for programs \nwithout calls on procedure variables, and we omit the proof. We mentioned earlier that actual parameters \nto calls on procedures in the collection or on procedure variables should be restricted to be variables \nand not constants. The reason for this was to avoid unnecessarily complicating the discussion of aliasing, \nsince constants are passed by value under call. by-ref erence. The solution to this is to initialize \nPVAL with all pairs (X,A) such that there is a call to a procedure (or procedure variable) with formal \nparameter X and corresponding actual parameter A. No entry is made in AFFECT for such pairs. The computation \nof pvAL :. (AFFECT v ((AFFECT*) oMODVAL) ) + is then changed to assign (pVAL v AFFECT v ((AFFECT*) .MODVAL))+ \nto PVAL. In this way constant actual parameters are propagated but no values may be attributed to them \ndue to modification of the corresponding formals. 6. THE ALIAS RELATION The ALIAS relation, as mentioned \nearlier, can be computed by the expression (AFFEcT*) o (AFFEcT*)T [71. This relation gives an answer \nto the question Is it possible at some point in the program for variable A to be aliased with variable \nB? The obvious ways to store this relation, e.g., as a boolean matrix, or as a list for each variable \nof the variables to which it might be aliased, take space which is roughly proportional to the square \nof the number of variables. In many situations, however, it is the case that there are sets of variables \nwhich are equivalent under this relation. We define equivalence of two variables to mean that they may \nbe aliased to each other and that the sets of variables to which they may be aliased are identical. Each \nsuch class could potentially be stored in space linearly proportional to the number of variables in it, \nrather than to the square of that number, The amount of storage required for the ALIAS relation is then \nC2 rather than V2, where c is the number of classes (which may be of unit size) and v is the number of \nvariables. This is especially useful in ECS because of the large number of temporaries which are generated \nfor constructs such as array indexing, and which fall into fairly large classes of equivalent variables. \nWe prove the following theorem, which gives a necessary and sufficient condition for two variables to \nbe equivalent as defined above. Theorem: Given the relation AFFECT, consider it as a graph and find its \nmaximal strongly connected components. Replace each such component with a new node identified with the \ncomponent. This leaves a directed acyclic graph (DAG). Define a sink in the DAG to be a node which has \nno edges coming out of it. A node X in the original graph is a sink if the node identified with the strongly \nconnected component containing X is a sink in the DAG. We say that node A reaches node B if there is \na path, possibly of length zero, in the graph from A to B. Two nodes in the original graph are equivalent \nif and only if they reach the same set of sinks [8]. Proofi We will consider AFFECT and ALIAS as graphs, \nderived in the obvious way from the relations previously discussed, and will give the proof in terms \nof nodes and edges of these graphs. AFFECT is a directed graph, while ALIAS may be considered as an undirected \ngraph, since the ALIAS relation is symmetric. This is easily seen from the definition of ALIAS. When \nwe speak of an edge in ALIAS, we henceforth mean an undirected edge. Also, when we speak of a node X \nreaching a node Y, we mean that there is a path from X to Y in AFFECT, unless stated otherwise. A path \nis defined as a possibly empty sequence of edges. We note that there is an edge between node X and node \nY in ALIAS if and only if there exists a node Z such that X reaches Z and Y reaches Z. This follows immediately \nfrom the definition of ALIAS in terms of AFFECT. Two nodes X and Y are equivalent if and only if the \nfollowing three conditions hold: there is an edge between X and Y in ALIAS; for each edge between X and \nsome node Z in ALIAS there is an edge between Y and Z; for each edge between Y and some node Z in ALIAS \nthere is an edge between X and Z. In other words, two nodes are equivalent if and only if they alias \neach other and the sets of nodes which they alias are identical. Lemma: X ALIAS Y is true if and only \nif there exists a sink Z such that X reaches Z and Y reaches Z. Proof of Lemma: From the definition of \nALIAS, it is clear that X ALIAS Y is true if and only if there exists a node W such that X reaches W \nand Y reaches W. Therefore, if there exists a sink Z such that X reaches Z and Y reaches Z, it follows \nthat X ALIAS Y is true. We now show that such a Z exists if X ALIAS Y is true. Let W be such that X reaches \nW and Y reaches W. Consider the DAG derived from AFFECT in the statement of the theorem. Let U be the \nnode in the DAG which is identified with the strongly connected component containing W. U must reach \nsome sink V in the DAG. Let Z be a node in the strongly connected component identified with V. Since \nU reaches V in the DAG, it follows that W reaches Z. This means that X reaches Z and Y reaches Z. V is \na sink, implying that Z is a sink, and so Z is the desired node. We now prove the theorem, first showing \nthat if X and Y reach the same set of sinks they are equivalent, and then showing that if they reach \ncliff erent sets of sinks, they are not equivalent. Suppose that X and Y reach the same set of sinks. \nSince this set is necessarily non-empty, they are aliased to each other. Suppose that X ALIAS W is true. \nLet Z be a sink such that X reaches Z and W reaches Z, as in the lemma. Since X reaches Z, it follows \nby hypothesis that Y also reaches Z. By the lemma, it follows that Y ALIAS W must be true. Similarly, \nif Y ALIAS W is true it follows that X ALIAS W is true. Therefore X and Y are equivalent. Now suppose \nthat X and Y are equivalent. Furthermore, suppose that there exists a sink Z which one of them, say X, \nreaches, and which the other one, say Y, does not reach. By the lemma, it follows that X ALIAS Z is true, \nsince a sink reaches itself. Furthermore, there is no W such that Y reaches W and Z reaches W, since \nZ reaches only itself, being a sink, and Y does not reach Z. Therefore Y ALIAS Z is not true. This gives \na contradiction, since we have found a node Z such that X ALIAS Z is true and Y ALIAS Z is not true, \nimplying that X and Y are not equivalent. This completes the proof of the theorem. This theorem leads \nnaturally to a reasonably efficient method for computing the sets of equivalent variables. These sets \ncan then be used for storing the ALIAS relation. Strongly connected components can be computed in time \nO (max(n,e) ), where n is the number of nodes in AFFECT and e is the number of edges [1]. Deciding which \nnodes are sinks can be done by first forming the reflexive transitive closure of AFFECT, and then checking \neach strongly connected component to see if there is an edge from any node in the component to a node \nin another component. If there is no such edge then the component, and each node in it, is a sink. A \ntechnique described by Wegman and Carter [14] can then be used to partition the nodes into classes based \non the sets of sinks which they reach. This technique involves hashing the sinks which a given node reaches, \nexclusive-oring the results of the hash together to get a new representation of the set. Having found \nthe new representation of the set of sinks reached by each node, the nodes can be partitioned very quickly \nbased on the equality of these representations by using a hash table. For those nodes whose sets of sinks \nhave the same such representation, the actual sets should be compared. This is because the representation \nis guaranteed to be unique only within a specified probability [14]. 7. SUMMARY In this paper we have \npresented an approach to interprocedural data flow analysis for programs which use pointers, label variables, \nand procedure variables. We have stated as the major obstacle to such analysis the problems of determining \nthe call graph, the control flow graph, and the alias relationships in the program, and have presented \nan algorithm for determining these program characteristics. Subject to the basic assumption that information \nabout control flow is not available, we have shown that the algorithm is precise for programs containing \nsimple assignments and multiple procedures, with parameters passed by value. Assuming that information \nabout the number of levels of indirection involved in accessing storage through a pointer is not available, \nwe have shown that the algorithm is precise for programs containing pointer variables, as long as the \nprogram consists of a single procedure. The algorithm is in fact precise for programs containing multiple \nprocedures and pointer variables as long as pointers are not passed as parameters. When pointers may \nbe passed as parameters, or parameters are passed by reference, the information produced by the algorithm \nis no longer as precise as possible. Similarly, when the program may contain calls to procedure variables \nthe information produced lacks some precision. We have also shown that the problem of determining possible \nvalues for procedure variables is P-space hard. This fact makes it unlikely that a method exists which \nis both precise and reasonably efficient. In certain cases we have shown that the algorithm is asymptotically \nas efficient as possible. We have also discussed some characteristics of the aliasing information which \nis produced, and have shown how these characteristics can be used to store the information more efficiently. \nIt is still an open question whether it is possible to produce better information without any loss of \nefficiency. It is also open as to whether iteration is required in cases involving aliasing and calls \non procedure variables. It may be that the information produced can be computed in time bounded by the \ntime to compute the transitive closure of an n x n matrix. It is also possible that certain restrictions \non the use of procedure variables and reference parameters may make it possible to compute the desired \ninformation both precisely and efficiently. 8. ACKNOWLEDGEMENTS The author would like to thank Bill Harrison \nfor suggesting this work. He, Louise Trevillyan, and Larry Carter deserve thanks for the many helpful \nsuggestions which they made as these algorithms were being developed. Steve Ward also provided many suggestions \non the work. Jeanne Ferrante, Janet Fabri, Fran Allen, John Guttag, and the others mentioned above also \ndeserve thanks for their comments on previous drafts of this manuscript which greatly improved the presentation. \nMark Wegman provided some key insights in analyzing the time requirements of the algorithm. Finally, \nIBM itself should be thanked for providing the opportunity to do this work through the MIT VI-A cooperative \nprogram. 9. REFERENCES 1. Aho, A. V., Hopcroft, J. E., and Unman, J.D. Design and Analysis of Computer \nAlgorithms, Addison-Wesley, 1974, 2. Aho, A.V. and Unman, J.D. Principles of Compiler Design, Addison-Wesley, \n1977. 3. Allen, F.E. Interprocedural Data Flow Analysis. Proceedings IFIP Congress 74, North Holland \nPublishing Company, Amsterdam, 398-402.  4. Allen, F.E. and Cocke, J. A Program Data Flow  Analysis \nProcedure. CACA4 19, 3 (March 1976), 137-147. 5. Allen, F. E., et. al. The Experimental Compiling Systems \nProject. IBM Research Report RC67 18, T.J. Watson Research Center, Yorktown Heights, N.Y. September 1977. \n6. Banning, J.P. A Method for Determining the Side Effects of Procedure Calls. Ph.D. Thesis, Stanford \nUniversity. Linear Accelerator Report No. Center (August 213, Stanford 197 8). 7. Barth, J. Interprocedural \nData Flow Analysis Based on Transitive Closure. Univ. of California at Berkeley, Computer Science Dept., \nTech. Rep. UCB-CS-76-44, September 1976. 8. Carter, J.L. Private Communication. 9. Graham, Usually Analysis. \nS.L. and Wegman, M. A Fast and Linear Algorithm for Global Flow JA CM 23, 1 (January 1976), 172-202. \n10. Rosen, B.K. Languages. Data JACA4 Flow 26, 2 Analysis for (April 1979), Procedural 322-344. 11. Ryder, \nB.G. Program. Engineering Constructing the Call Graph IEEE Transact ions on Soft SE-5, 3 (May 1979), \n216-226. of a ware 12. Spillman, Optimizing Conference Company, T.C. Exposing Side-Effects in a PL/I \nCompiler. Proceedings IFIP 1971, North Holland Publishing Amsterdam, 376-381. 13, Walter, K.G. Optimization. \n514-516. Recursion Analysis for CACM 19, 9 (September Compiler 1976), 14. Wegman, M. N., and Carter, \nJ.L. New Classes and Applications of Hash Functions. Proceedings 2 Oth Annual Symposium on Foundations \nof Computer Science (October 1979), 175-182. 15 Weihl, W .E. Interprocedural Data Flow Analysis in the \nPresence of Pointers, Procedure Variables, and Label Variables. S. M. Thesis, Massachusetts Institute \nof Technology (to be published). 16 Winklmann, K.A. A Theoretical Study of Aspects of Parameter Passing \nin ALGOL60 in Similar Programming Languages. Thesis, Purdue University (August 1977). Some and Ph.D. \n \n\t\t\t", "proc_id": "567446", "abstract": "Interprocedural data flow analysis is complicated by the use of procedure and label variables in programs and by the presence of aliasing among variables. In this paper we present an algorithm for computing possible values for procedure and label variables, thus providing a call graph and a control flow graph. The algorithm also computes the possible aliasing relationships in the program being analyzed.We assume that control flow information is not available to the algorithm; hence, this type of analysis may be termed \"flow-free analysis.\" Given this assumption, we demonstrate the correctness of the algorithm, in the sense that the information it produces is conservative, and show that it is as precise as possible in certain cases. We also show that the problem of determining possible values for procedure variables is P-space hard. This fact indicates that any algorithm which is precise in all cases must also run very slowly for some programs.", "authors": [{"name": "William E. Weihl", "author_profile_id": "81100231697", "affiliation": "IBM Thomas J. Watson Research Center, Yorktown Heights, New York", "person_id": "P300237", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567446.567455", "year": "1980", "article_id": "567455", "conference": "POPL", "title": "Interprocedural data flow analysis in the presence of pointers, procedure variables, and label variables", "url": "http://dl.acm.org/citation.cfm?id=567455"}