{"article_publication_date": "01-28-1980", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. &#38;#169; \n1980 ACM 0-89791-011-7 $5.00 tural analysis and extraction of data flow information 2. Definitions sacrificing \nsome power and generality. The published results concerning the worst case com\u00adplexity of prime subprogram \nparsing are, to our nkowledge, the following. Kas janov [KAI has given a O (nm ) worst case algorithm \nto parse a restricted class of control flow graphs. Gannon and Hecht [GH] give a O (rr3) algorithm for \na different restricted class of graphs, which Fredrickson [FR] later improved to run in O (ma (m ,n )) \non a more general class of inputs. We show how to obtain a prime subprogram parse tree in O (m+n ) for \na class of control flow graphs more general than those considered by the authors mentioned above. Additionally, \nwe show that any algorithm that produces a prime subprogram parse tree for a sufficiently general class \nof programs, can be transformed into an algorithm to decompose a biconected Multigraph into triconnected \npieces with the same worst case as the parsing algorithm. Therefore any algorithm which is simpler than \nthe method suggested here, and performs the same task will produce a simpler triconnected components \nalgorithm than that of Hopcroft and Tarjan. This fact seems, in our opinion, to dim the hopes for a genera/ \nlinear time prime subprogram parsing algorithm which is truly simple, although finding such algorithms \nfor special cases of graphs having practical interesl may not be too difficult. 1.2. Automatic structuring \nof programs The maintenance of large programs written in older programming languages (such as FORTRAN) \nlacking in control structures presents, in many cases, serious prob\u00adlems. These programs usually contain \nlarge number of unstructured control transfers (goro s) which tend to make the code hard to understand, \nand consequently, hard to modify and maintain. A possible way to alleviate this problem, suggested by \nBaker [BAI, consists of automatically translating the pro\u00adgram into an equivalent program that uses more \ncontrol statements and in which as few as possible of the control transfers occur through the use of \ngoro s. One could, rea\u00adsonably expect the resulting equivalent program to be easier to understand and \nmaintain. Baker designed and implemented an algorithm to translate FORTRAN programs into RATFOR (a FOR-TRAN \npreprocessor with a full complement of modern control structures) which was quite succesfull at this \ntask. Baker s concern was focused on the translation task, and as a result this algorithm, although quite \nefficient, was far from optimal. The flow graphs obtained from programs that do not contain goro s can \nbe nicely characterized using the con\u00adcepts employed by our parsing algorithm, as we shall dis\u00adcuss later. \nMore importantly, in an arbitrary flow graph, our parsing algorithm will identify the sections containing \nunstructured control transfers and give enough informa\u00adtion about the other program sections so they \ncan be easily structured. This section provides the definitions of the non stan\u00addard terms used later \non, and a short comparison between some of our definitions and those used by other authors that consider \nsimilar problems. Some standard graph theoretical terms will be used throughout without being defined; \ntheir definitions can be found in [HA] or any other graph theory textbook. A program is a directed graph \nwith two distinguished vertices s and t (called respectively the start and jirrisld and such that for \nany vertex v of the graph there is a path from s to t that includes v. A subprogram is a connected subgraph \nof a program. Let v be a vertex of a program P=-< V, E>. We will use the following notation for the set \nof predecessors and succesors of v: Suc(v)==(x I(V,X)6E) pre(v)={xl(x, v)6E) Let S be a subprogram of \nP. A vertex v of S is a boundary vertex if the set suc (v) U pre (v) includes at least one vertex of \nP-S, A boundary vertex v is an enrry of S if pre (v ) includes only vertices of P S or if suc ( v ) includes \nonly vertices of S. Similarly, v is an exit of S if suc (v ) contains vertices of P-S exclusively or \nif pre (v) contains only vertices of S. Examples of these concepts are shown in fig. 1. By convention \nwe will consider s an entry and r and exit of the program as a whole. A subprogram is proper if it has \nexactly two boundary vertices, one an entry and the other an exit. Clearly a proper subprogram considered \nindependently must be a program with its entry as the start and its exit as the finish. A proper subprogram \nis nontrivial (opp. trivial) if it includes at least two edges. A nontrivial proper subpro\u00adgram is prime \nif all proper subprograms totally contained in it are trivial. These concepts are illustrated in fig. \n2. A prime subprogram (PS) parse of a program P is a pro\u00adcess that reduces P by repeatedly replacing \na prime subpro\u00adgram by an edge from its entry to its exit. An example of such a process is shown in fig. \n3. It is a simple conse\u00adquence of our definitions that any program either consists of a single edge, \nor contains no prime subprograms, or can be parsed into a program that satisfies one of the first two \nconditions. This fact should not be missinterpreted: even though all programs will have a prime subprogram \nparse it does not follow that the same amount of structural information can be obtained from all of them. \nThere will be some cases in which the information obtainable with our parsing method will be very minimal, \nand other cases in which a great deal of information is produced. Some extreme examples are considered \nin the next section. Because at a given point more than one prime subpro\u00adgram of the program being parsed \nmay be replaceable, there will be in general more than one way to perform the PS parsing of a program. \nThis situation (common in pars\u00ading problems) is normally overcome by the use of a parse tree to represent \nconcisely all possible parses. We will use a PS parse tree to represent in a concise fmn all the possible \nPS parses of a program. As an exam\u00adple, the PS parse tree for the program of fig. 3 is shown in fig. \n6. We are not quite ready however to discuss exactly how this tree is constructed; therefore the fact \nthat it represents all the PS parses of the program should be taken on faith until some further explanation \nis given. The motivation behind this parsing method should be clear. We hope that the data flow problems \nwill be easy to solve on the prime subprograms (since normally they will have a simple structure), and \nthat the effects of the com\u00adputation performed inside them on the rest of the program should be easy \nto account for, due to the single entry and single exit restrictions. Thus, we hope that the data flow \nproblems in the total program can be solved by integrating the solutions of the problems in the prime \nsubprograms using the information that tells how these prime subpro\u00adgrams fit together to form the program. \nThe application of the PS parsing process to the automatic structuring of programs rests on the same \nbasic principles. Our approach will be to structure the total pro\u00adgram by structuring its prime subprograms, \nand then integrating the structured subprograms using structured control statements, The prime subprogram \nparse of a flow graph is therefore used to provide the decomposition of the control flow graph necessary \nfor this approach. Let us end this section by discussing the rationale behind some of our definitions \nand comparing them with the alternatives in the literature. The definitions of entry and exit try to \ncapture the intuitive idea of having every transfer of control into a proper subprogram occur through \nits entry vertex and every transfer of control out of it occur through its exit vertex. Our definitions \nare the closest we could find to the intuitive notion described above that still retain a /oca/ character. \nThis means that it can be tested whether a ver\u00adtex v is an entry or exit of a subprogram S by inspecting \non(y the edges incident to v, and knowing about each of them on~ whether it belongs to S. The use of \nlocal definitions (in this sense) is justified because in most appli\u00adcations you want to obtain global \ninformation about flow of control from local control flow information, and therefore it does not make \nmuch sense to define the parsing process in terms of the information that one wishes to obtain. Our work \nis independent of the actual definitions we use in that any others that have this local character can \nbe substituted for them without affecting our results, In par\u00adticular, the definitions discussed in the \nnext paragraph are all special cases of our definitions. Kas janov [KA] requires entries to have all \ntheir SUC- cessors (and exits all their predecessors) inside the subpro\u00adgram, and that no edge join the \nentry and the exit of a subprogram. Gannon and Hecht [GH] make a more res\u00adtrictive assumption: the degree \nof all the vertices of a pro\u00adgram is assumed to be either two or three. Under this res\u00adtriction, which \nis reasonable in many circumstances, every boundary vertex of a subprogram is either an entry or an exit \naccording to our definitions. Fredrickson [FR] requires that a single edge originating outside the subpro\u00adgram \nterminate at the entry and that a single edge originat\u00ading at the exit terminate outside the subprogram. \nThis is a slight generalization of the definitions of Gannon and Hecht, and a particular case of our \ndefinitions. 3. Prime subprogram parsing and triconnected decomposition Let P=< V,E> be a program with \nstart vertex s and finish vertex t and let U(P) denote the undirected graph obtained by adding an edge \n(t,s) to P and then disregard\u00ading the directions of all the edges. We call U(P) the undirected version \nof P. For any vertex v of P there is a path from s to r that includes v, according to our definition \nof program. If we assume that such a simple (i.e., itdoes not intersect itself) path exists for all vertices \nof P, it follows trivially that U(P) must be biconnected. The significance of this asumption will be \ndiscussed briefly later on, we use it to simplify the description of the PS parsing. Lemma 1: Let P be \na program and S a nontrivial proper subprogram of P with entry u and exit v, and such that P-S is not \nempty. The vertices rJ and v are a separa\u00adtion pair of U(P). Proof: Removal of u and v clearly disconnects \nthe edges in S from those of P S. Furthermore, according to our definitions, S will have at least two \nedges since it is non trivial, and because P S is not empty, d(P)-S will also contain at least two edges. \nThis implies that u. v are a separation pair of U(P) according to the definition of [HTI. o Theorem 1: \nThe PS parse tree of a program P can be computed in linear time from the triconnecled pieces of u(P). \no Instead of a precise algorithm and a formal proof of this fact we offer a detailed example of such \na computation and an informal discussion of some of the problems involved in this task which are not \nillustrated by the exam\u00adple. The example begins with a brief description of the output of the triconnected \ncomponents algorithm which we need for our discussion. (For a complete description see [HTI). Figure \n4 shows a biconnected graph U (P, ) and its unigue triconnected pieces. In general, these pieces are \ngraphs of three types: polygons, bonds and triconnected graphs with at least four vertices. The graphs \nlabelled B, A and C in fig,4 are examples (respectively) of these three classes of graphs. Each triconnected \npiece is made up of edges of two types: edges of the original graph (drawn as continuous lines in fig. \n4) and virtual edges, (represented by dotted lines iri fig. 4) which are introduced during the decomposi\u00adtion \nprocess. Virtual edges are always introduced in pairs, the two members of a pair never belonging to the \nsame tri\u00adconnected component. In fig. 4 virtual edges have been assigned labels so the pair of edges \nintroduced together have the same labeI. Note that the endpoints of each virtual edge are a separa\u00adtion \npair and that the original graph can be reconstructed from the pieces by gluing them along virtual edges \nwith the same label, and then eliminating the virtual edges. Note also that not every separation pair \nof the graph will be joined by a virtual edge (for example, two non adjacent vertices of a polygon like \nD in fig.4). The graph U (Pl) shown in fig.4 is the undirected ver\u00adsion of the program parsed in ftg.3. \nWe will use this graph as an example to describe the construction of the PS parse tree of a program from \nthe triconnected pieces of its undirected version and to illustrate in what sense the PS parse tree represents \nall PS parses of a program. Figure 5 depicts a rooted tree, Tl, obtained by representing each triconnected \npiece of U (Pl ) by a vertex and joining by an edge the vertices that represent two tri\u00adconnected pieces \nthat include the members of a pair of vir\u00adtual edges. As the root of this tree we choose the com\u00adponeni \nthat includes the edge ((,s) which is included in U(PI) but not in P,. Figure 6 shows the PS parse tree \nof P,, obtained by adding to TI a leaf for each edge e of P]. The leaf corresponding to e has been a~tached \nto the vertex of T, representing the triconnected component of U(P, ) that includes e. The children of \nnodes representing bonds or triconnected graphs in such a tree may appear in any order, but the children \nof a node that corresponds to a polygon must be listed in the order in which the edges of the polygon \nare encoun~ered as one circles the polygon (clock\u00adwise or counterclockwise, it does not matter). All \nthese operations can be trivially performed in linear time given a suitable representation components \nalgorithm. of the output of the triconnected Figure subgraphs 7 of illustrates a program a conwith venient \nsubtrees way of its of PS associating parse tree which will help us to show how a great deal of structural \ninformation about the program is cptured by its PS parse tree in a hierarchical fashion. For example, \nfrom the fact that the root of T} is a bond and has two children, we can infer (aided by a brief consideration \nof the directions of the edges incident to the entry of the subprogram represented by the root of that \ncomponent) that globally F l is a branch, with the two alternatives being the subprograms defined by \nthe two sub\u00adtrees of the root of T,. Performing this analysis recur\u00adsively on the subtrees of the root \nwill provide exactly the kind of information needed to perform the structuring of the program. In particular, \nwhen we get to the subprogram represented by the triconnected graph C, we can conclude that it is an \ninherently ill structured section, since the con\u00adtroi flow graph that one obtains from a program that \nuses only structured control transfer statements (if, whi/e ,... ) will decompose into polygons and bonds \nexclusively. The information needed to generate PS parses is also available from the PS parse tree, as \nthe example of fig. 8 shows. The figure displays some of the programs obtained as intermediate stages \nduring the PS parse of PI shown in fig.3, side by side with their respective PS parse trees. In this \nexample, each parsing step can be interpreted as the application to the parse tree of one of the simple \ntransfor\u00admations shown in fig.9. It seems therefore as if the PS parse of a program can be defined in \nterms of simple transformations of its PS parse tree. However the image painted by figs. 8 and 9 of how \nthe PS parse tree encodes the PS parsing information is some\u00adwhat simplistic. The program has a nice \ndecomposition into prime subprogram, and the decomposition reflects quite well what we perceive as the \ncontrol structure of the program. A truly general case wiIl present some difficulties, some of which \nare discussed below, that were carefully eliminated from our example in order to make the basic ideas \nmore accesible. The example given is not general in that every separa\u00adtion pair of U(P1) is an entry-exit \npair of P,. That this is not always the case is shown by the (admittedly contrived) examples of fig.10, \nIf rule (a) of fig.9 is applied to these two PS parse trees, we obtain the PS parse trees shown in fig. \n11 side by side with their corresponding programs. In either case rule (a) corresponds to the replacement \nby a single edge of a subprogram which was not proper (and therefore not prime). Thus, the complete correspondence \nbetween the operations of fig.9 and the PS parsing process has disap\u00adpeared. It would seem that this \ncorrespondence can be restored without much trouble by testing which virtual edges have endpoints that \nare entry-exit pairs and allowing rule (a) [o be applied only when it is safe. However, new problems \narise immediately. For instance, if we take the cross marks on the edges of the PS parse trees in fig. \n11 to indi\u00adcate that rule (a) may not be applied to the vertices below those edges, no transformation \nfrom our set may be applied to the second program of that figure, even though it has a PS parse! Although \nit is possible to specify a complete set of PS tree transformations so that even in the general case \nthe PS parsing process can be described in terms of them, they are complex enough so we prefer not to \ndiscuss them: the interested reader can find an early version of this material discussed in detail in \n[VA]. Instead we wanl to point out that the one-to-one correspondence between separation pairs and entry-exit \npairs that makes our parsing very sim\u00adple, is likely to be the rule rather than the exception, when dealing \nwith reasonable control flow graphs (as opposed to artificial examples like those of fig. 11). After \nthis long description of how to obtain the PS parse tree and of some of its applications, let us present \na esult that ties the concept of PS parsing to the concept of 5. References reconnected decomposition \ntightly. Theorem 2: A PS parsing algorithm with worst case [AL] 2 (f (n, m)) can be modified to produce \nthe triconnected Decomposition of a biconnected graph in O (f (n, m)) steps n the worst case. [BA] Proof: \nEven and Tarjan [ET] describe a way to number 1 linear the vertices of an undirected biconnected graph \nG [co]/ith n vertices from 1 to n in linear time so that: a) Given any edge (s, r) of G, s gets number \n1 and t gets number n. [ET] b) Every vertex except s and t is adjacent both to a lower-numbered and to \na higher-numbered vertex. If we remove the edge (s,/) and direct the edges of G [FRI om lower to higher \nnumbered vertices, condition (b) uarantees (by an easy induction) that we obtain a pro\u00adram PG with start \ns and finish f. Furthermore, every [GHI}paration pair of G must be a entry-exit pair for some roper subprogram \nof PG since PG cannot have any cycles. herefore in PC, we will have a one-to-one relationship ?tween \nentry-exit pairs and separation pairs. Because per\u00ad [GWI )rming the PS parsing of a program requires \nknowledge of 1 the entry-exit pairs of the program, a PS parse tree for ~ will give a concise description \nof the separation pairs of [HAI from which the triconnected pieces can be easily Xained. Since the computation \nof the s-t numbering [HEIkes linear time, the worst case of the triconnected >composition method just \ndescribed will be no worse than al of the parsing algorithm. o [HT] [HU] Final Comments [KAl ,rsed are \nbiconnected. Although it is possible to have ograms that do not satisfy this condition, they hardly ok \nrealistic. Nevertheless one can apply our technique to [RO] ese programs as well by eliminating articulation \npoints y node splitting for instance) before using the tricon\u00ad:cted components algorithm. Obviously the \ntransforma-We have assumed throughout that the programs being ITAI ms performed during the elimination \nof the articulation Iints will have to be taken into consideration during the Iution of the data flow \nproblems. [VA]We consider the following the main main contributions our work: Providing an efficient \nalgorithm for the prime subpro\u00adgram pa~sing of control flow graphs. Exhibiting the close relationship \nbetween prime sub\u00adprogram parsing of a control flow graph and the tricon\u00adnected decomposition of a biconnected \ngraph. The idea of using the triconnected decomposition as a means of structuring programs. F. E. Allen, \nControl Flow Analysis, ACM SIG-PLAN Notices (Newsletter) 5, 7 (July 1970), 1\u00ad 19. B. Baker, An A Igorithm \nfor Structuring Flowgraphs, JACM 24, 1, (January 1977), 98-120. J. Cocke, Global Common Subexpression \nElimination, ACM SIGPLAN Notices (Newsletter) 5, 7 (July 1970), 20-24. S. Even and R. T. Tarjan, Computing \nan s-t number\u00ading, Theoretical Computer Science 2, (1976), 334-344. G. N. Fredrickson, Fast Algorithms \nfor Parsing Fiowgraphs Using a Prime Subgraph Grammar, (Manuscript). J. D. Gannon and M. S. Hecht, An \nO (n3) A/go\u00adrithm for Parsing a Proper Program into its Prime Subprograms, (Manuscript). S. L. Graham \nand M. Wegman, A Faw and Usual@ Linear Algorithm for Global Flow Analysis, JACM 22, 1 (January 1976), \n172-202. F. Harary, Graph Theory, AddisonI-Wesley, Read\u00ading, Mass., 1977. M. S. Hecht, Flow Analysis \nof Computer Pro\u00adgrams, Elsevier North-Holland, 1977. J. E. Hopcroft and R. E. Tarjan, Dividing a Grap/~ \ninto Triconnected Components, SIAM J. Comput. 2, 3 (September 1973), 135-158, M. S. Hecht and J. D. Unman, \nF/ow Grap/~ Reduci\u00adbiliv, SIAM J. Comput. 1, 2 (june 1972), 188\u00ad 202. V-N. Kas janov, Distinguishing \nHammocks 1)1 a Directed Graph, Soviet Math. Dokl. 16, 2 (1975), 448-450. B. K. Rosen, High Level Dara \nFlow Analysis, Com\u00admunications ACM 20, 10 (October 1977), 712\u00ad 724. R. E. Tarjan, Tesring Flow Graph \nReducibility, Jour\u00adnal of Comp. and Systems Sciences 9, 3 (December 1974), 52-53, J. Valdes, Parsing \nFlowc}larts and Series-Parallel Graphs, (Ph. D. thesis) Computer Science Depart\u00adment Tech. Rep, STAN-CS-682 \n(December 1978) Stanford University, * Ca Id - m (9 u J2 1.1 . s  (1* -+ 101 . ,2? 0 \\ 103 3 u 1 \n 104 f+. LLnL%iii 0---= --+ =- VI .\u00ad .5 a 0, +  \n\t\t\t", "proc_id": "567446", "abstract": "A parsing method based on the triconnected decomposition of a biconnected graph is presented. The parsing algorithm runs in linear time and handles a large class of flow graphs. The applications of this algorithm to flow analysis and to the automatic structuring of programs are discussed.", "authors": [{"name": "Robert E. Tarjan", "author_profile_id": "81100645220", "affiliation": "Stanford University", "person_id": "PP14221119", "email_address": "", "orcid_id": ""}, {"name": "Jacobo Valdes", "author_profile_id": "81100435239", "affiliation": "Princeton University", "person_id": "PP31042152", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/567446.567456", "year": "1980", "article_id": "567456", "conference": "POPL", "title": "Prime subprogram parsing of a program", "url": "http://dl.acm.org/citation.cfm?id=567456"}