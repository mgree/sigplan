{"article_publication_date": "01-01-1999", "fulltext": "\n A Core Calculus of Dependency Martin Abadi Anindya Banerjee Nevin Heintze Jon G. Riecke Systems Research \nCenter Stevens Institute of Technology Bell Laboratories Bell Laboratories Compaq ab@cs.stevens-tech.edu \nnch@bell-labs.com rieckeabell-labs.com ma@pa.dec.com Abstract Notions of program dependency arise in \nmany settings: security, partial evaluation, program slicing, and call-tracking. We argue that there \nis a central notion of dependency common to these set- tings that can be captured within a single calculus, \nthe Dependency Core Calculus (DCC), a small extension of Moggi s computational lambda calculus. To establish \nthis thesis, we translate typed cal- culi for secure information flow, binding-time analysis, slicing, \nand call-tracking into DCC. The translations help clarify aspects of the source calculi. We also define \na semantic model for DCC and use it to give simple proofs of noninterference results for each case. 1 \nIntroduction Systems that incorporate aspects of program dependency arise in many different contexts. \nFor example, type systems for secure in- formation flow trace dependencies between outputs and inputs \nof a computation. These type systems are meant to guarantee secrecy and integrity. In the Secure Lambda \n(SLam) Calculus [13] and the while-program languages of Volpano et al. [31, 381, data may be labelled \nas high security or low security , and the type sys- tem ensures that all computations that depend on \nhigh-security in- puts yield high-security outputs, and conversely, that low-security outputs do not \ndepend on high-security inputs. This independence property is often called the noninterference property \n[8, 9, 171 in the security literature: high-security data does not interfere with the calculation of \nlow-security outputs. Fragments of the trust cal- culus [27] and JFlow [22,23] also appear to satisfy \nthe noninterfer- ence property (although this is not proved). Program analyses such as slicing, call-tracking, \nand binding- time analysis are also based on dependency: the goal of these analy- ses is to compute a \nconservative approximation of the parts of a pro- gram that may contribute to the program s final result \n(and, more generally, its intermediate results). Correctness of these analyses is often expressed using \nproperties analogous to noninterference. For instance, in slicing [36, 401, the aim is to determine those \nparts of a program that may contribute to the output; those parts that do not Permission to make digital \nor hard copies ofall or part of this work for personal or classroom use is granted without fee provided \nthat copies arc not made or distributed for prolit or commercial advantage and !hat copies bear this \nnotice and the full citation on the first page. To copy otherwise. to republish, to post on swvers or \nto redistribute to lists, requires prior specific permission and/or a fee. POPL 99 San Antonio Texas \nUSA Copyright ACM 1999 l-581 13-0953/99/01...$5.00 contribute can be replaced by any expression of the \nsame type. In call-tracking [33,34], we wish to determine the functions that may be called during evaluation; \nfunctions that are not called can be re- placed by any function of the same type without affecting the \nfinal value. In binding-time analysis [5, 251, we wish to separate static from dynamic computations; \ndynamic values can be replaced by any expression of the same type without affecting the static results. \nThe similarity between secure information flow and other pro- gram analyses is striking, and raises a \nquestion: do these analyses share some common substrate? This paper provides one answer by constructing \na general framework for type-based dependency anal- yses in higher-order programs. The framework is a \ncalculus called the Dependency Core Calculus (DCC). We give a denotational se-mantics for DCC that formalizes \nthe notion of noninterference. We then show how to translate a variety of calculi for security, slicing, \nbinding-time analysis, and call-tracking into DCC in such a way that the noninterference results for \nthe respective calculi are imme- diate corollaries of the generic results for DCC. There are three advantages \nto this foundational approach. First, DCC gives us a way to compare dependency analyses. This idea relates \nback to Strachey s conception of denotational semantics as a tool for comparing languages [32]. Second, \nthe translations themselves yield a check on type systems for dependency analysis. They help confirm \nsome seemingly ad hoc decisions in some cal- culi and have uncovered some problems and incompletenesses \nin others. Third, general results about DCC yield simple noninterfer- ence proofs for the individual \ndependency analyses. DCC is a simple extension of Moggi s computational lambda calculus [20]. Typically \nthe computational lambda calculus has a single type constructor that is semantically associated with \na monad. In DCC, this notion is extended to incorporate multiple monads, one for every level of a predetermined \ninformation lattice. The use of the computational lambda calculus in describing dependency is somewhat \nsurprising. Usually, the computational lambda calculus describes languages with side effects [20], or \nforms the basis of adding side effects like I/O to pure functional languages [15]. Dependency analyses, \nin contrast, do not funda- mentally change the values being computed. Nevertheless, there is one common \nidea underlying both uses of the computational lambda calculus. In the case of Haskell, there is no way \nto com- pute a value using the I/O type constructor and pass that value to an expression of non-I/O type. \nSimilarly, in information-flow systems, the test of a high-security boolean in an if-then-else requires \nthat the branches of the conditional return high-security values. In both cases, the type rules of the \ncomputational lambda calculus enforce the necessary restriction. The rest of the paper describes DCC, \na semantic model of DCC, and six translations from type-based dependency analyses into DCC. Certain aspects \nof dependency analysis cannot be mod- elled in DCC; we discuss this further in the concluding discussion. \n2 Commonality among Dependency Analyses Before presenting the syntax and semantics of the core language \nDCC, we give two examples of dependency analyses: the SLam calculus and a slicing calculus. 2.1 Why the \nSLam Calculus is a Dependency Analysis The SLam calculus [ 131 is a typed lambda calculus extended with \nsecurity annotations for access control and information flow. To simplify the setting, we consider only \nthe functional facet of the calculus with information flow, which corresponds to a fragment of the trust \ncalculus of @rbzk and Palsberg [27]. A types is a pair consisting of a structural part, f, and a security \nannotation, K,denoting information flow and ranging over elements in a security lattice L, with least \nelement L and greatest element H. For example, the type (bool,L) denotes low-security booleans; similarly, \n(bool, H) denotes high-security booleans. The type ((bool,H) -+ (bool,L),L) denotes a low-security function \nthat accepts a high-security integer and returns a low-security result. The terms and type rules of the \nlanguage are given in Section 4.1. A simple example of a well-typed SLam term of type ((bool, H) -+ (bool,L),L) \nis the constant function (hx: (bool,H). trueL)L. Note that all constructors in SLam are labelled with \nsecurity anno-tations. Since low-security computations should not depend on high-security data, the evaluation \nof an expression such as if trueH then trueL else falseL must not produce the low-security boolean trueL, \nsince otherwise information about the high-security boolean is leaked to the low- security world. The \nremedy is simple: whenever a constructor is destructed, we make the security annotation of the constructor \nflow to the an-notation of the result. Specifically, the annotation of the result is the least upper \nbound of its original annotation and that of the construc- tor. This propagation of annotations is captured \nby the following dependency-calculus principle: At every elimination rule, properties (e.g., security \nlevel, binding-time information, dependency annotation) of the destructed constructor are transferred \nto the result type of the expression. This principle is fundamental to the design of the dependency \ncal-culus and to the rest of the paper. In the example, then, the result of if trueH then trueL else \nfalser. is the high-security boolean, trueg. The noninterference property is vacuously sat-isfied, since \nthe result is a high-security boolean. More generally, if in the context (X : (t, H)) expression e has \ntype (bool,L), then noninterference says that e must not depend on the high-security variable x, and \nhence must be constant with respect to X. 2.2 Why the Slicing Calculus is a Dependency Analysis In program \nslicing [36, 401, we seek the dependencies of a program--&#38;z, those subterms of the program that may \ncontribute to its output. For example, the slice of the application ((hr. 3) 2) should contain only the \nfunction hr. 3 and the constant 3, since the argument 2 does not contribute to the final result. To identify \nsuch subterms, we follow Abadi ef al. [2] and use a labelled lambda calculus. We give a conservative \napproximation of the labelled op-erational semantics using a type system, whereas previous work by Biswas \n[3] employs set-based analysis. The type system for slicing is similar to that of the SLam cal-culus. \nA type s is a pair consisting of a structural part, t, and a set of labels, K,denoting slicing information. \nNote that the powerset of labels forms a complete lattice with empty set as least element and the set \nof all labels as greatest element. We give the complete type system in Section 4.2. A typing judgement \nr k e : (t, K) means that, under the assumptions r, the expression e has type t and possi- ble dependency \nK. For instance, consider the example from above, where the constructors are all labelled: It is easy \nto see that the type of the function part of the applica- tion is ((int,{nz}) -+ (int,{nl}),{nu}), so \nthat the type of the whole term is (int,{nu,nt}). Thus the result of evaluating the term cannot depend \non 12. Noninterference also holds in the slicing calculus: if under the assumption (x : (t, Kl)),the \nexpression e has type (int, Kz),where K1 g K2 in the powerset lattice, then e must not depend on x. 3 \nDependency Core Calculus DCC is a minor extension of Moggi s computational lambda cal-culus [20]. Three \nfeatures distinguish it from the computational lambda calculus. First, the calculus contains sum types \nand lifted types, as well as term recursion. Lifting allows us to model call-by-value calculi. Second, \ninstead of having one type constructor T semantically associated with a monad, the calculus incorporates \nmultiple type constructors Te, one for every element fJ E L of a pre- determined lattice L. This idea \nwas also considered by Wadler [39]. The lattice represents different grades of information. In the secu-rity \nsetting, the least element usually stands for low security. Type constructors q change the level of a \ntype. For instance TH(boo1) describes high-security booleans. Third, the monad bind opera-tion has a \nspecial typing rule that is explained later. 3.1 Syntax The types of DCC are given by the grammar: where \nC ranges over elements of a predetermined lattice L. The lift- ing operation on types, denoted so in \nthe syntax of types, induces a subset of types called the pointed types: . sI is a pointed type; . ifs \nand t are pointed types, then (s x t) and Te(s) are pointed types; and . if t is a pointed type, then \n(s + t) is a pointed type. For a recent account of pointed types, see the paper by Howard 1141 or Mitchell \ns text [181. Similarly, the Te operation on types induces a subset of types called the types protected \nat level C: Table 1: Typing Rules for DCC. Wk r,x:.~,r~-x:.~ [Unit] [Lam1 l-,x : s, t e : S2 rt (hr: \n~.e) : (s, + .v) [APPI [Puir] TIeI :s, r t e2 : ~1 r t (el,e2) : (.v x ~2) PM1 PWI r t e : si r t (injje) \n: (~1 +SZ) [Case] [UnitM] Tte:s r t (9~ e) : W4 [BindM] rte:.v [WI rt(lifte):.yi [se4 [Ret] T,f :.vt-e:s \nr t (p,f : S. e) : s s is pointed . If e E L? , then Tel (s) is protected at level l?; . if s and t \nare protected at level C, then (S x t) and Tel(t) are protected at level e; and . if t is protected at \nlevel 1, then (S t t) are protected at level e. The typing rules for DCC appear in Table 1. In all of \nthe typing judgements in this paper, a typing environment r denotes a list of distinct variables with \ntypes. The rules for unit, function, product, and sum types are all standard, as is the rule for the \nmonadic unit operation. The rule for monadic bind is nonstandard, using the concept of protected at level \nP for the body; usually, the body must have type G(x ) for some 3 . The model of the next section gives \nsome justification for this rule. Finally, the rules [Lift] and [Seq] are just special cases of the monadic \nunit and bind operations for lifted types, and recursion is permitted only over pointed types. The operational \nsemantics for DCC is a call-by-name seman-tics. In particular, the term (qe e) reduces to e, and (bind \nx = e in e ) reduces to e [e/x], where e[e /x] denotes the capture-free substitution of e for x in e. \nThe rest of the operational semantics is standard and hence omitted. 3.2 Semantics The model of DCC draws \non ideas from other noninterference proofs [ 13, 191 which use Reynolds s concept of parametricity [28]. \nThe method is easiest to explain with an example with high-and low-security booleans. A high-security \ncomputation can depend on a high-security input, but a low-security computation cannot. Our model explains \nthe difference using views of the high-security booleans, where each view is captured by a binary relation \nand where computations must respect the relations. In this simple ex-ample, the high-security view is \nthe diagonal relation (i.e., x and y are related iff x = y), so that high-security computations can dis-tinguish \nbetween the booleans. The low-security view, in contrast, is the everywhere true relation--that is, x \nis related to y for all x and y. Low-security computations can therefore not take advantage of the distinctions \nbetween the high-security booleans. Sabelfeld and Sands develop these ideas in a recent manuscript [30]; \nsimilar constructions appear in Nielson s work on strictness analysis [24]. rt():unit rte:(s, +.Q) rtd:.vl \nr t (e d) : .y2 rte:(s, xs2) r t (pro ji e) : sj r t- e : (s, +.y2) r,x : .yi t ej : s rt (case e of \ninj ,(x). el ) injz(x). e2) : s rt-e:T&#38;) r,x:ste :r t is protected at level I rtbindx=eine :t rte:sl \nr,x:ste :t t is pointed rtseqx=eine :t We formalize these ideas via a category. Recall that a complete \npartial order (cpo) is a poset that contains least upper bounds for ev- ery directed subset; a cpo may \nor may not have a least element [ 181. Recall also that a directed-complete relation is a relation that \npre- serves least upper bounds of directed sets. Define the category 8C (for dependency category) to \nbe the category with . OBJECTS An object A is a cpo IAl and a family of directed- complete relations \nRA,e on A for every C E L. . MORPHISMS A morphism f :A + B is a continuous function such that for any \n(x,~) E R&#38;e, (f(x),f(u)) E R&#38;e. We use Hom(A, B) to denote the set of morphisms from A to B. \nThe condition on morphisms is crucial. Consider, for instance, the lattice with two points L 5 H, let \nB = {true, false} with the trivial ordering, and define the objects boolH = (B, RL,RH) boolL = (B,R;,RL) \nwhere RL,RH,R~,RL are relations on B. The relation RL corre-sponds to a low-security viewer of a high-security \nboolean; such a viewer cannot distinguish between the booleans. Hence we choose RL to be the everywhere \ntrue relation, i? x B. The rela-tion RH, in contrast, corresponds to a high-security viewer of a high-security \nboolean; such a viewer can distinguish between the booleans. Hence we choose RH to be the diagonal relation \non B. In a similar manner, we can choose both Ri and Rk to be the di- agonal relation on B. Now, if f \n: boolH + book5 is a morphism, it must send arguments related by RL to results related by RL. Since RL \nis the everywhere true relation, for any x,y E B, the pair (x,y) is in RL. Thus, (f(x),f(y)) E R ,. In \nother words, f(x) = f(y) for all x,y E B. Therefore, a function mapping high-security booleans to low-security \nbooleans must be a constant function. However, a relation need not be either the diagonal relation or \nthe everywhere true relation. The key property we need of BC is that it is a model of DCC (and therefore \nof the typed lambda calculus with products and CO- products). To establish this, we adapt standard results \nfrom cat-egorical semantics [16] to show that 2X is Cartesian closed, has coproducts, and has a monad \nfor each e E L. (These results are necessary to justify the constructions in this paper; however, the \nreader unfamiliar with category theory can safely skip them.) More concretely, if A, B, C, D are objects \nand f :A + B, g : C + D: . The unit object unit is defined by the poset {T} and the iden- tity relations. \n. Coproducts are given by ]A+B] = ]A]+]R] RA+B,~ = {(ida,idb) 1 (a,b) 6 RA,~}U {(inrqinrb) 1 (a,b) \nERBJ} inZ(f(y)) if x = inl(y) (f+g)(x) = inr(g(y)) if x = k(y) . Products are given by IA xBI = IAl x \n\\BI RAxB,e = {(klb)i@,b )) I (a,~ ) E h,e, c&#38;b ) E RB,~) (f x d(X,Y) = (f(47dY)) . Exponentiation \nis given by l;A;fj = ~4lAl~I~I) = {(f,s) I v(a,a ) E h,e, (f(a),f(a )) E he) (f* i)(h : ffMf4C))(x: A) \n= dh(fb))) . Lifting is given by IAd = {@ >a) I a E IAIIU{(l,~) RAd = {((0,x), (0,~)) I for all (x,Y) \nE h,e)u ) = where ((0,~) ( a E [AI} is ordered as in IAl, and (1,1) is or- dered below all other elements. \n. The monads are given by IMA)I = IPI ifeEl RA,e~Rfi(A),el = IAl x IAl otherwise Q(f:A+B) = f We also \ndefine the maps r(e[A] : A --t c(A) and pl[A] : WMA)) -+ WA) rle[Al(x) = x ve[Al(x) = .X That is, both \nmaps are based on the identity function. How-ever, these morphisms are not the identities in the category, \nsince they do not have the same domain and codomain. The first four of these definitions are not surprising; \nMitchell s text [ 181 gives a history of these definitions. This structure gives us all the machinery \nneeded to interpret the types and terms of DCC. We use [[sl] for the meaning of a type s in the category, \nand 1x1 : ~1,. . . ,x,, : sn t- e : s] : [[sl x . x s,,D -+ [[sl for the meaning of a typing judgement. \nWe omit the definitions of the meanings of terms since they are standard. Using induction on the definition \nof pointed , we can show that: Proposition 3.1 Ifs is pointed, then 1 I[f] I has a least element. Hence \nrecursion can be interpreted via least-fixed points. The monads Te give a way to change the level of \na type, e.g., as in TH(boolL) = boolH. The operator Te changes the relations not above e to the everywhere \ntrue relation. More generally, when a type is protected at level e, views of that type at a level e p \ne are the everywhere true relation. Proposition 3.2 lft is a type protected at level e, and e p I, then \nR~t~,e~ = lU4ll x IDllI. 4 Applications I: A Strong Version of Noninterference In languages with recursion \nand some notion of dependency, there are often two ways to state the notion of noninterference. The first \nsays that if a program terminates with an input and produces a re- sult, then changing the input to a \nrelated input still causes the program to terminate and the result is related to the original result. \nThis is a strong notion of noninterference. Some calculi, however, do not satisfy the strong property \nbut do satisfy a weaker property: if two related inputs cause the program to terminate, the outputs are \nrelated. Under this property, related inputs may yield different convergence behavior. In this section \nwe study calculi with the strong version of nonin- terference. These include calculi based on call-by-name \nsemantics, and they turn out to be easier to translate into DCC. In the next section, we study calculi \nthat satisfy the weaker version of nonin- terference. 4.1 Call-by-name Functional SLam Calculus Our \nfirst source calculus is the call-by-name, purely functional ver-sion of the SLam calculus; this calculus \nis essentially the trust cal-culus of @rbrek and Palsberg [27] without the coercion from high to low \nsecurity. Let L denote a join semilattice of security levels and let K range over the levels of _L. The \ntypes are .._ t ..-unit I (s+s) I (sxs) I(s-+s) .._ s ..- (t,K) and the typing rules appear in Table \n2. In the typing rules, the operation (t,K)*d = (t,KUd) is used to increase the security level of a \ntype. The symbol 5 de-notes the subtyping relation. The restriction of recursion to func- tion types \nis not essential in a call-by-name context; the restriction here merely allows us to use the same type \nsystem for a call-by- value version below. The operational semantics of this calculus deviates from the \noriginal operational semantics of the SLam calculus [ 131 in that arguments are passed by name rather \nthan by value. Evaluation contexts are defined in the style of Felleisen [lo] by the grammar E ::= [.]](Ee) \nI (projiE)](caseEof injt(x).et I injz(x).ez) and the local operational rules are ((J~:s.e)~e ) -+ e[e \n/x] (Proji(el,e2),) -+ G, i= 1,2 W : s. e) -+ 4bf : s. e)lfl (protect,e) -+ e (case(injie)Kof injt(x).el \nI inj2(x).e2)-+ei[e/X]i=1,2  Table 2: Typing Rules for the Functional SLam Calculus. 1-,x:s,rtx:s r \nt e : s s 5 s l- t- e : s l-,x : s, t e : s2 [Lam1 rt(hw:S,.e),:(s, +S~,K) r-t-e] :S, r F e2 : s2 [Pair] \nrk (~~4~: h xs2,4 r F e: Si r-l-(injie),:(Sl+Ss,K) [Protect] [SubUnit] [Uflit] kc] KJPI [Proj] [Case] \n[SubTrans] [Sub&#38;m] [Sub&#38;n] rk ()K:(unit,K) r,f:SFe:s sis a function type r I- (p.f : S. e) : \ns rke:(sl +S2,K) r+e':Sl rl-(ee'):s2*~ rEe:(S, x.72,~) rk(projje):q*K rt-e:(SI+S2,K) r,X:Sjkei:S rF(caseeofinjI(X).eI \n1inj2(x).e2):s*K We write e .lJ v when e rewrites to v and v cannot be rewritten. The translation of \nthe SLam calculus into DCC is straightfor- ward. Types are translated into DCC by the following recursive \ndefinition, where t maps from types t (without a security level) into DCC types, and * maps from types \ns (with a security level) into DCC types. unit+ = unit1 (Sl +Q)+ = (s;+s;)J_ (St x sz)+ = (xi x s;) (q \n--f sz)+ = (s;t --k s;) (t,K)* = &#38;(t+) A SLam typing derivation of I- I- e : s is translated to \na valid DCC derivation of r* I- e* : S* by the rules in Table 7. It is easy to check that every SLam \ntyping derivation yields a DCC typing derivation by the translation. We can also prove the following \ncorrectness properties of the translation: Theorem 4.1 (Adequacy) Ij according to Table 7, 0k.e: (unit,K) \n*0ke*: (unit,@* then e u v ifS[e*jj # 1. Theorem 4.2 (Noninterference) Let K1 and K2 be any two ele-ments \nof L. Suppose KI g K2 and x: (t,Kl) t-e: ((unit,K2)+(unit,Kz),K2) is derivable in the SL.am type system. \nThen (e[e /x]) u v ifs (e[e /4) U v. Proof: The proof follows directly from the structure of !DC. We \nsketch the argument for the case where L = {L,H} . Suppose x: (t,H) t-e: ((unit,L)+(unit,L),L) is derivable \nin the SLam type system. Applying the typing rule 1-1, 01- (lx: (t,H).e)L: ((t,H) t ((unit,L)+(unit,L),L),L) \nNow, translating to DCC, we have 0l-(hx: (t,H).e)L:TL(TH(t+)dTL((TL(unitl)+TL(unitl))l)) Let f = [( hr \n: (t,H) . e)tl. Since L is the least element of L, f E [[TH(~+) + (unit1 +unitl)ll Let D = ITH( and E \n= [( unitl+unitl)l]. By the I)C condition on morphisms, for all 1 E .G and for all x,y E D, ~RD,I Y implies \n(fx) RE,I WY). In the case 1 is L, RQL is the everywhere true relation, and RE,L is the diagonal relation. \nHence, for all x,y E D, (f x) = (f y).Thus, [(e[e /x])*I] = U((hx: (r,H).e)L e )*ll = [((hx: (t,H).e)L \ne )*n = U&#38;+ /4*ll and so by adequacy, (e[e /x]) J.l v iff (e[e /x]) .lJ v. . This noninterference \ntheorem is stated over one specific type only for readability; it extends to types not involving function \ntypes. 4.2 Slicing Calculus The slicing calculus, introduced in Section 2, attempts to calculate which \nportions of a program may contribute to the final answer, and which definitely do not. To study slicing, \nwe formulate a type- based slicing analysis. The types of the language are exactly the same as in the \nSLam calculus, except that K ranges over sets of labels. The typing rules appear in Table 3. These rules \nresemble the SLam calculus rules, although the rules for value constructors are different. Types are \ntranslated into DCC exactly as in the call-by-name, functional SLam calculus, and a typing judgement \nr E e : s istrans-lated to a judgement of the form r* k e* : s* by the rules in Ta- ble 8. The correctness \nproperties are also the same as for the call- by-name, functional SLam calculus. Table 3: Typing Rules \nfor the Slicing Calculus (where subtyping is analogous to subtyping in the SLam calculus). r,x:.~,r~x:s \nWrl I-i-e:s sls WI r t- e : .d r,x : S, t-e : .v2 km1 r~((hx:.~,.e),:(s,-tS2,{n}) TFel :SI rkel:.yp \n[Puir] rk (el,e2h : (SI X~2,{n)) rke:si Pjl rk (injje), : (~1 +.v,{n}) [Unit] rk On : (unit,(n)) 1-,f \n:st-e:s [Ret] s is a function type rI-(Pf:s.e):.v rt-ee:(.yI+S2,K) rke :.T, PPPI r t- (e e ) : ~2 0 K \nrt-e: (S1XS2,K)  [Proj] I- !-(projje) :si*K Ti-e:(.7,+.72,K) T,x:sit-e;:s [Case] rt-(caseeof inj,(x).el \n1inj2(x).e2):soK Table 4: Typing Rules for the Binding-time Calculus. [VW PubI 1~6 [Pair] [hl r,x:s,r \nt~:.y rt-e:(unit,sta) r 1 e : (unit,dyn) r,x : .q I- e : s2 rI-(hr:.~l.e)p:(.~l~.~2,P) l-t-eel :SI r \nt e2 : .72 rk (el,ez)p : (.u X.v2,P) rFe:.yj rk (inj;e)p: (SI +.yz,P) [Unit] Fe4 LAPPI [Projl [Case] \nr I- ()p : (unit,P) r,f:.yt-e:.7 r I- (uf : S. e) : s sis a function type Tke:(q +s~,P) rke :s[ rt-(ee \n):.v2 rke:(s, xsz,p) rt-(proj;e):s; rl-e : (s, +s2,p) r,x: .yit- ei : s rt-(caseeof injI(x).el 1 inj2(x).ez):s*P \n 4.3 Binding-Time Calculus The goal of binding-time analysis is to annotate a program with binding times \nand specialization directives [ 121. The binding times specify when data is available. For instance, \nif there are only two binding times, static and dynamic, then static denotes known at specialization-time \nand dynamic denotes known at run-time . Binding times are used to specify specialization directives: \nif an expression has static binding time, then it is eliminable, i.e., can be reduced at compile time. \nIf an expression has dynamic binding time, then it is residual, i.e., it cannot be reduced at compile \ntime. Hatcliff and Danvy define one binding-time type system, fo-cused on the computational lambda calculus \n[ 121. Under their sys-tem, if in a dynamic context l-d an expression e of type int is mapped by the \nanalysis to an annotated term w with annotation sta (for static), then w and e must be identical and \nmust be equiv- alent to some integer constant it [ 12, Lemma 21. This property is exactly noninterference: \nstatic data cannot rely on dynamic data. Implicit in the Hatcliff-Danvy type system is a restriction \non the structure of types. This restriction can be made ex-plicit by defining a notion of well-formedness \nof types [26, 351. For example, if dyn denotes dynamic binding-time with sta 5 dyn, the types ((int,sta) \n--f (int,sta),dyn) and ((int,sta) x (int,sta),dyn) are ill-formed, whereas ((int,dyn) + (int,dyn),sta) \nis well-formed. Using DCC,we can give a more generic account of this system. Specifically, we can show \nthat the noninterference property is independent of the notion of well-formedness employed. The specific \nnotion of well- formedness is motivated by engineering constraints varying from specializer to specializer. \nIn summary, binding-time analysis can be viewed as a dependency calculus (a la DCC) in conjunction with \na notion of well-formed types. The dependency captures a generic notion of whether or not a computation \ndepends on dynamic inputs, and the well-formedness condition captures constraints imposed by the specializer. \nWe formalize these ideas in a source language similar to SLam, where the types are annotated with binding \ntimes s ta 2 dyn. Types in the binding-time calculus are therefore t ::= unit~(s+s)~(~xs)~(s-+s) S ::= \n(t,P) p ::= staldyn The well-formed types [35] are a subset of the types defined as follows: . (unit,P) \nand (~1 +s2,p) are well-formed. . ((tl , PI) OP (h Pd, PI is well-formed iff (tl, I%) and (t2, P2) are \nwell-formed and p < pi, where op = x , +. The typing rules are given in Figure 4. The judgement I- k \ne : s means that under assumptions I-, expression e has the well-formed type s. Note that the well-formedness \nrestriction on types obviates the need for . in the elimination rules App and Proj, since (t, p) . p \n= (t,P) when p 5 p. The binding-time calculus can be translated into DCC. Types are translated into DCC \nin the same way as in the call-by-name, functional SLam calculus. A typing judgement I-k e : s is translated \nTable 5: Typing Rules for the Smith-Volpano Calculus over Booleans. rH;rLtskip:Tcmd r,;r,te:z xErr rH;rLt(x:= \ne):zcmd rH;rLte:T rH;rLtci:rcmd rH;rLtifethenclelsec2:zcmd to a judgement of the form I-* k e* : S* \nby the rules in Table 9. The correctness properties are the same as for the call-by-name, functional \nSLam calculus. 4.4 Smith-Volpano Calculus The Smith-Volpano calculus [31] is a simple language of while- \nprograms, modified so that the types keep track of the security levels of variables and commands. Just \nas in the SLam calculus, the type system prevents high-security inputs from influencing low-security \noutputs. The translation of the Smith-Volpano calculus to DCC, however, looks very different from translations \nof SLam, the slicing calculus, and the binding-time calculus. Part of this differ- ence arises from the \ndifference between imperative and functional languages, On a deeper level, some of the subtleties of \npointed types in DCC are useful in the translation. Types in the Smith-Volpano calculus are divided into \ndata types z and phrase types p: r ::= LIH p ::= z(zcmd When L or H is used in a phrase type, it is the \ntype of storage cells that hold values of type L or H. The subtyping relation, used in the typing rules, \nis based on the primitive relations L 2 H and H cmd 5 L cmd. The typing rules for the calculus appear \nin Table 5. In order to keep the translation to DCC simple, we modify the original type rules [31] in \ntwo ways. First, variables have types L or H; variables of command type, possible in the original Smith-Volpano \ncalculus, appear to have no use. Typing contexts are consequently split into two parts, r~ and r~, containing \nthe sets of high and low variables respectively; the type contexts are just lists of variables because \nof this split. Second, the implicit data type is boolean instead of in- teger. In other words, L is the \ntype of low-security booleans and H is the type of high-security booleans. We make this simplifica- tion \nonly for expository purposes, because there is no direct way of encoding the integer type in DCC. To \nextend the encoding to the original calculus, we could either directly add an integer type to DCC, whose \nsemantic domain would be the flat integers, or add recursive types to DCC so that one could represent \nthe integers as a type expression. Both changes would complicate DCC, and essen-tially no new difficulties \narise with integers. The operational semantics of the language uses a state, i.e., a map B from variables \nto {true, false}. There are two forms of judgement in the operational semantics. A judgement of the form \n(c,o) --t cr , where c is a command, denotes a computation that [Cm?] i- ,q;TLl-k:r k=trueorfalse rH;rLte:7cmd \nrH;rLte':rcmd [Se4 rH;rLt(e;e'):rcmd rw;rLbe:L rn;rLtC:LCmd [While] rH;rLtwhileedoc:Lcmd terminates \nin state d. A judgement of the form (c,o) -+ (c ,~ ) denotes a computation that has not halted yet; the \ncommand to be run next is c . The following rules define the operational semantics: (skip,o) -+ (T (ecr) \n= v (ec) = false (x:=e,0)-_,cr[x++v] (whileedoc,(3)td (Cl,@ -+ (C;r@ (Cl,(J)-+o ((ClX2),4 + ((4X2)7~') \n((ClX2),(J) -+ (c27(3') (eo)=false (ifethenq elsec2,6)t(c2,0) (e 0) = true (if e thenct elsec2,(3) \n--t (ct,G) (e 0) = true (whileedoc,o)-+((c;whileedoc),(T) We use +* for the reflexive, transitive closure \nof -+. Two observations about the calculus are in order. First, phrases of type (H cmd)never modify variables \nof type L. Thus, a phrase of type (H cmd) is a function from a state to the portion of the state representing \nhigh variables. Low commands, in contrast, can mod-ify high and low variables. Second, while loops may \ninclude only low expressions and low commands. Without this restriction, the type system does not satisfy \nthe strong noninterference property. Indeed, concurrency can be used to leak information [31]. From the \nrestriction on while loops, it follows that only low commands may diverge. The translation of the Smith-Volpano \ncalculus into DCC de-pends on these two observations. We define the type boo1 to be the DCC type (unit \n+ uni t), and let  SV(L) = boo1 S (H) = TH(bool) WZl , . . At) = y(T) x , x SV(z! sv(rH,rL,q = svH(rH) \nxsvL(rL)+ b00l sv(rH,rL,H) = svH(rH)x svL(rL) + TH(bOOi) sv(rH,rL,Hcmd) = SvH(rH) x svL(rL) -+ svH(rH) \nsv(rH,rL,Lcmd) = svH(rH)x svL(rL) -+ (wrd x svL(rLh The translations of judgements are closed expressions \nin DCC, with the form rH;rLbe:p+e* :sv(r,,r,,p) where e ranges over expressions and commands, and e \ndenotes the result of the translation of e. The complete translation is given in Table 10. For example, \nsuppose the last rule used in the typing derivation is [a. The judgement r~; rt I- if e then cl else \nc2 : L cmd is translated as ho. if (e* O) then (CT CT) else (cz (T) where if e then er else e2 is shorthand \nfor (case e of inj 1 (x). el 1injz(x). e2) for a fresh variable x. In contrast, the judgement r~;r~ k \nif e then cl else c2 : H cmd is translated to ho. bind v = (e* CI) in if v then (CT 0) else (cz (3) \nNotice the use of the bind in the last rule-the value of the expres- sion e is a high-security boolean, \nand hence must be decomposed. Since both arms of the conditional are protected at level H, this part \nof the translation is well typed. Suppose rL is a set of variables; define (T wt-, B if for all x E \nrL, (T(X) = G (X). We can prove the following theorems from the translation: Theorem 4.3 (Adequacy) Suppose \n(xl,. . . ,x,,); (~1,. . . ,yk) k c : L cmd. Then (c, 0) +* 0 ifs uc*n 2 uGJl)7(u~(YI)ll~~~~    (ob(xl)ll7~~~ \n>U~(Yk)ll))# -L Theorem 4.4 (Noninterference) Suppose TH; rL F c : L cmd is derivable in the Smith-Volpano \ncalculus, and o -r, 0 . lf(c, O) -+* 00. then (c, 0 ) +* oh and 00 -r, oh. Dually, if(c,(T ) -+* do, \nthen (C,(T) +* CJOand 00 -r, oh. The proof of the noninterference theorem uses the semantic model of \nDCC, whereas the original operational proof uses a more de- tailed operational analysis [31]. Applications \nII: A Weaker Version of Noninterference Not all calculi that track dependency satisfy the strong version \nof noninterference. For example, the original functional SLam calcu- lus uses a call-by-value semantics \nrather than a call-by-name se-mantics. In this calculus, high-security inputs may affect the ter- mination \nbehavior-but not the outputs-of a low-security compu- tation. An earlier version of the Smith-Volpano \ncalculus, due to Volpano, Smith, and Irvine [38], also satisfies this weaker notion of noninterference; \nthe strong version of noninterference seems to require the restriction of while-loops to low commands. \nUnfortunately, it seems difficult to use DCC directly to model these languages. We must alter the syntax \nand semantics of DCC slightly. The main problem lies in the semantics of lifting. Con-sider, for instance, \nthe meaning of the DCC type TH(boo1) _$ booll where boo1 = (unit + unit) as before and L 2 H. A function \nof this type must either map all elements to _L or all elements to a constant element of type bool, in \nessence obeying the strong version of noninterference. For the weaker version, we want the relation at \nboo11 to relate I to any element of bool, not just to I; the relation on non-l elements should continue \nto be the diagonal relation. To model the weaker notion, we use the same underlying cat-egory, and change \nthe semantics of the lifting operator to have the relations RAI,L=RA,~U{(I,I)}~{(X,I),(I,X) IxE IAt3 \nand change the definition of protected to include the clause . If t is protected at level C, then tl \nis protected at level e. We call the new language vDCC, since it is tuned to call-by-value (even though \nthe operational semantics is still call-by-name). The meaning of fi(tl) is now isomorphic to (c(t))l, \nvia the terms f = hr:fi(tl).bindy=xinseqz=yin(lift (rtez)) g = hx:(4(t))l.seqy=xinbindz=yin(~(liftz)) \nThe terms are well typed because of the change in the definition of protected. We now describe two calculi \nsatisfying the weak version of noninterference and translations of them into vDCC. 5.1 Call-by-value \nFunctional SLam Calculus The first application of vDCC is the call-by-value version of the functional \nSLam calculus in Section 4.1. The syntax and type- checking rules of the language are exactly the same \nas in the call- by-name setting, except that we require in recursion (&#38; : s. e) that s has the form \n(st + ~2, K) where q = s2 . K. The main change is in the operational semantics, where the evaluation \ncontexts become V ::= () 1 (l2:s.e) 1(injiv) 1 (V,V) E ::= [.I I (E 4 I (vE) I (inji E) I (ET4 I by,@ \nI (proji E) I (caseE of injI(x). e I inj2(x). e )  and rewrite rules become ((hr : s. e)K v) + +/4 (proj \ni (~1, ~2)~) + Vi (protect,v) -+ v (case(injiv)rof inj*(x).el 1inj2(x).e2) -+ei[v/x] (pf : s. e) -+ \ne[(hr : s1. (pj : s. e) ,~)~/f] s = (s, -+ S2,K)  Types are translated into vDCC as follows: unit+ = \nunit (Sl +s2)+ = (s;+s;) (q x s2)+ = (ST x.71) (s1 -_) s2) + = (sf -($)l) (t,K)* = &#38;(t+) Unlike in \nthe call-by-name case, not every type is translated to a pointed type; function types, though, are guaranteed \nto be pointed. A typing judgement r b e : s is translated to a judgement of the form r* k e* : (s*)l \nby the rules in Table 11. Theorem 5.1 (Adequacy) lj according to Table 11, 8t_e:(unit,K)=S@)_e*:(unit,K)* \n then e 4 v ifs [e*jj # 1. Theorem 5.2 (Noninterference) Let K1 and K2 be any two ele- ments of L. Suppose \nK1 g K2 and x: (t,Kl) be: ((unit,K2)+(unit,K2),K2)  is derivable in the SLum type system. Then (e[e \n/x]) Jj v ifs (+ /xl) U v. Table 6: Typing Rules for the Call-tracking Calculus. W-1 l-,x : s,r i-n \n: s,L [Chit] rt-c?:Sl,K SI 5 S2 WI Wcl KEICI rl-e:S2,d r,x:Sl te:S2,K @ml L@Jl rk(hw:S,.e) n :(S,{kF2). \n>L rkf?] :SI,K~ rte2 ~~2~1~2 [Puir] [ Proj] rf- (el,e2): ($1xS2),K1 UK2 rke:S;,K [@I [Case] rt-(injje):(sl+s2),K \n5.2 Call-tracking Calculus Typesin the call-tracking calculus [33, 341 are given by the gram- mar s::=unit \n1 (s+s) 1 (sxs) 1 (s--%s). where K ranges over sets of labels. (These labels occur only on lambdas.) \nThe typing rules appear in Table 6. A term is assigned with a type and an effect (a set of labels of \nlambdas that may be called). We use L to denote the least element of the lattice of sets of labels. The \nsubtyping rule for function types is The other subtyping rules are obvious and omitted. Qpes are translated \ninto vDCC as follows: unit+ = unit (Sl +s2)* = (S;+S;) (Sl x4* = (ST x $1 (SI +S2)* = (ST -+ (TK(S;))l) \nA typing judgement P + e : s, K is translated to a judgement of the form I-* I- e : (TK(s*))l by the \nrules in Table 12.  Theorem 5.3 (Adequacy) M according to Table 12, 0 I- e : unit,K=% 0 k e* : (T,(unit))l \nfhen e J.l v ifl[[e*l] # 1.  Theorem 5.4 (Noninterference) Let K be an element of L, and n $! K. SuppOSe \nst-e[(hx:s.e ),/f] :unit+unit,K 8 b e[(hr:s.e\"),/f: unit+unit,K are derivable in the call-tracking type \nsystem. Then (e[(hx : s. 4,/f]) U v $f(e[(hx : s. e Mf) U v. This theorem formalizes the intuition expression \ne does not call- ing function f as the property function f can be replace by an arbitrary function (of \nappropriate type) without changing the result of evaluating of e . r/-O: unit,l r,f:St-e:S,K S= (S, --% \nS2) ri-(p,!f:S,e):S,K rl-e:(.q --%S~),K, rFe':s],~~ rk(ee'):S2,KuKIuK2 r!-e:(.u XS~),K l-l-(projie):si,K \n rFe:(.q+s2),~ r,x:Sikei:S,d rt-(caseeofinj~(x).el Iinj2(x).e2):S,KUd 6 Discussion We have shown how \nmany dependency analyses can be cast in DCC. As Section 4 shows, we can compare and contrast various \ndependency analyses in a single framework, For example, the call- by-name functional SLam calculus, the \nslicing calculus, and the binding-time calculus share a common translation of types into DCC and a set \nof common correctness properties; small differences occur only in the translations of terms, Larger differences \nbetween these calculi and the Smith-Volpano calculus can also be described. Another advantage of the \ntranslations is their utility in the de- sign of dependency analyses. For instance, we have found a certain \nincompleteness in the functional SLam calculus; it would make se- mantic sense to add a rule r,x:(t,K)te:(t \n,d) Kcd  T,x: (t,ti) t-e : (t ,d) - (since it is easily modelled in DCC), but the original SLam cal- \nculus does not have the rule. DCC can also be used to point out apparent design inconsistencies in some \nof the existing calculi. We are currently redesigning the Imperative SLam Calculus [13] us- ing a translation \ninto DCC as a guide for the type system, and as a vehicle for proving noninterference. The model underlying \nDCC simplifies proofs of noninterfer- ence. The model was also invaluable in developing DCC itself. For \ninstance, the pattern seqx = e in (bind y = e in e ) occurs frequently in the translations; the type \nof e must be both pointed and protected in order for the translation to work. With- out the concepts \nof pointed and protected , the obvious path might be to adopt an ever increasingly complex set of type \ncon- versions and equations. The model was also helpful in developing the weaker notion of noninterference, \nand extending the notion of protected types to lifted types by changing the semantics of lift- ing. It \nwould have been difficult to make this change in the syntax of DCC alone (other than, perhaps, by directly \nimposing the equa- tion T&#38;l) = (Te(s))l). Not all aspects of dependency can be translated into DCC. \nFor example, the binding-time analyses of Davies and Pfenning 17, 61 cannot be directly translated into \nDCC because DCC cannot model the coercion from run-time objects to compile-time objects. A rather different \nsemantics due to Moggi [21] has been developed for such binding-time analyses, using the concept of a \nfibration to model dependency. A similar comment applies to the trust oper-ator that maps from untrusted \nto trusted in (Zlrbaek and Palsberg s work [27]. Other possible extensions of DCC include accounting \nfor the spawning of concurrent threads [ 131 and modelling cryptographic operations in such a way that \nencrypting a high-security datum could produce a low-security ciphertext [l]. The relationship of DCC \nto semantic dependency in the context of optimizing com-pilers [4, 111 and to region systems for memory \nmanagement [37] should also be explored. Acknowledgements Thanks to Eugenio Moggi for discussions and \nto the anonymous referees for their comments. Anindya Banerjee is a member of the Church Project and \nis supported in part by NSF grant EIA-9806835. 6 November 1998 References 111 M. Abadi. Secrecy by typing \nin security protocols. In The- oretical Aspects of Computer Software: Third International Symposium, \nvolume 1281 of Lect. Notes in Computer Sci. Springer-Verlag, 1997. PI M. Abadi, B. Lampson, and J.-J. \nL&#38;y. Analysis and caching of dependencies. In Proceedings.of the 1996 ACMSIGPLAN International Conference \non Functional Programming, pages 83-91. ACM, 1996. [31 S. K. Biswas. Dynamic Slicing in Higher-Order \nProgram-ming Languages. PhD thesis, University of Pennsylvania, 1997. [41 R. Cartwright and M. Felleisen. \nThe semantics of program dependence. In Proceedings of the 1989 ACMSIGPLAN Con-ference on Programming \nLanguage Design and Implementa- tion, pages 13-27. ACM, 1989. r51 C. Consel. Binding time analysis for \nhigher order untyped functional languages. In Proceedings of the 1990 ACM Con-ference on Lisp and Functional \nProgramming, pages 264- 272. ACM, 1990. [61 R. Davies. A temporal-logic approach to binding-time anal-ysis. \nIn Proceedings, Eleventh Annual IEEE Symposium on Logic in Computer Science, pages 184-195, 1996. [71 \nR. Davies and F. Pfenning. A modal analysis of staged com-putation. In Conference Record of the Twenty-Third \nAnnual ACM Symposium on Principles of Programming Languages, pages 258-270. ACM, 1996. PI D. Denning. \nA lattice model of secure information flow. Com-mun. ACM, 19(5):236-242, 1976. [91 D. Denning and P. \nDenning. Certification of programs for se- cure information flow. Commun. ACM, 20(7):504-5 13, 1977. \n1101 M. Felleisen. The theory and practice of first-class prompts. In Conference Record of the Fifteenth \nAnnual ACM Sympo-sium on Principles of Programming Languages, pages 180- 190. ACM, 1988. [ill J. Ferrante, \nK. J. Ottenstein, and J. D. Warren. The program dependence graph and its use in optimization. ACM Trans. \nProgramming Languages and Systems, 9(3):3 19-349, 1987. WI J. Hatcliff and 0. Danvy. A computational \nformalization for partial evaluation. Mathematical Structures in Computer Sci-ence, 7:507-541, 1997. \nSpecial issue containing selected pa-pers presented at the 1995 Workshop on Logic, Domains, and Programming \nLanguages, Darmstadt, Germany. v31 N. Heintze and J. G. Riecke. The SLam calculus: program-ming with \nsecrecy and integrity. In Conference Record of the Twenty-Fifth Annual ACM Symposium on Principles of \nPro- gramming Languages, pages 365-377. ACM, 1998. [I41 B. T. Howard. Inductive, coinductive, and pointed \ntypes. In Proceedings of the 1996 ACM SIGPLAN International Con-ference on Functional Programming, pages \n102-109. ACM, 1996. [I51 P. Hudak, S. L. Peyton Jones, P. L. Wadler, Arvind, B. Boutel, J. Fairbairn, \nJ. Fasel, M. Guzman, K. Hammond, J. Hughes, T. Johnsson, R. Kieburtz, R. S. Nikhil, W. Partain, and J. \nPe- terson. Report on the functional programming language Haskell, Version 1.2. ACM SIGPLAN Notices, \nMay 1992. [I61 J. Lambek and P. Scott. Introduction to higher order cate-gorical logic. Cambridge studies \nin advanced mathematics. Cambridge University Press, 1986. [I71 J. McLean. Security models. In J. Marciniak, \neditor, Ency-clopedia of Software Engineering. Wiley Press, 1994. [181 J. C. Mitchell. Foundations for \nProgramming Languages. MIT Press, 1996. [I91 M. Mizuno and D. A. Schmidt. A security flow control algo-rithm \nand its denotational semantics correctness proof. For-mal Aspects of Computing, 41727-754, 1992. rw E. \nMoggi. Notions of computation and monads. Information and Control, 93:55-92, 1991. WI E. Moggi. A categorical \naccount of two-level languages. In Proceedings, Mathematical Foundations of Programming Semantics, Thirteenth \nAnnual Conference, Electronic Notes in Theoretical Computer Science. Elsevier, 1997. Available fromhttp://www.elsevier.nl/locate/entcs/. \nw-1 A. C. Myers and B. Liskov. A decentralized model for infor- mation flow control. In Proceedings of \nthe Sixteenth ACM Symposium on Operating Systems Principles. ACM Press, 1997. ~31 A. C. Myers. Practical \nmostly-static information flow con-trol. In Conference Record of the Twenty-sixth Annual ACM Symposium \non Principles of Programming Languages. ACM, 1999. v41 F. Nielson. Strictness analysis and denotational \nabstract in-terpretation. In Conference Record of the Fourteenth Annual ACM Symposium on Principles of \nProgramming Languages, pages 120-131. ACM, 1987. WI H. R. Nielson and E Nielson. Automatic binding time \nanaly- sis for a typed h calculus. Science of Computer Programming, 10:139-176, 1988. [26] H. R. Nielson \nand F. Nielson. Two-Level Functional Lan-guages, volume 34 of Cambridge Tracts in Theoretical Com-puter \nScience. Cambridge University Press, 1992. [27] P. 0rbaek and J. Palsberg. Trust in the h-calculus. Journal \nof Functional Programming, 7(6):_557-591, November 1997. [28] J. C. Reynolds. Types, abstraction and \nparametric polymor-phism. In R. E. A. Mason, editor, Inform&#38;ion Processing 83, pages 513-523. North \nHolland, Amsterdam, 1983. [29] J. G. Riecke and R. Viswanathan. Isolating side effects in sequential \nlanguages. In Conference Record of the Twenty-Second Annual ACM Symposium on Principles of Program- ming \nLanguages, pages I-12. ACM, 1995. [30] A. Sabelfeld and David Sands. A Per model of secure infor-mation \nflow in sequential programs. Unpublished manuscript, 1998. [31] G. Smith and D. Volpano. Secure information \nflow in a multi- threaded imperative language. In Conference Record of the Twenty-Fifth Annual ACM Symposium \non Principles of Pro- gramming Languages. ACM, 1998. [32] C. Strachey. The varieties of programming language. \nIn Pro-ceedings of the lnrernational Computing Symposium, pages 222-233. Cini Foundation, Venice, 1972. \nReprinted in Pe- ter O Hearn and Robert Tennent, eds., Algol-like Languages. Birkhhser, 1997. [33] Y.-M. \nTang. Systkmes d effet et interpktation abstraite pour l analyse de jot de con&#38;le. PhD thesis, Ecole \nNationale SupCriere des Mines de Paris, 1994. [34] Y.-M. Tang and P. Jouvelot. Effect systems with subtyping. \nIn ACM Conference on Partial Evaluation and Program Ma-nipulation, June 1995. [35] P. Thiemann. A unified \nframework for binding-time analy-sis. In M. Bidoit, editor, Colloquium on Formal Approaches in Software \nEngineering (FASE 97), volume 1214 of Lect. Notes in Computer Sci., pages 742-756. Springer-Verlag, April \n1997. [36] F. Tip. A survey of program slicing techniques. Journal of Programming Languages, 3(3): 121-189, \nSeptember 1995. [37] M. Tofte and J.-P. Talpin. Region-based memory manage-ment. Information and Computation, \n132(2):109-176, 1997. [38] D. Volpano, G. Smith, and C. Irvine. A sound type system for secure flow analysis. \nJournal of Computer Security, 4(3): l-21, 1996. [39] P. Wadler. The marriage of effects and monads. In \nProceed-ings of the 1998 ACM SIGPLAN International Conference on Functional Programming, pages 63-74. \nACM, 1998. [40] M. Weiser. Program slicing. IEEE Trans. Software Engineer-ing, 10(4):352-357, July 1984. \n A Translations into DCC The translations of the various source calculi into DCC are given in Tables \n7-12 below. To make the translations more readable, most of the cases of sums and products are left out. \nWe also use the DCC combinator and abbreviation  dot : TK(TK (t)) + Tati dot =hr: T,(T~(t)).bindy=xinbindz=yin(~,u~ \nz) (seqbindf =eine ) = (seqv=e inbindf =v ine ) where v is a fresh variable. Most of the translations \nalso re-quire a coercion combinator for interpreting subsumption, but these combinators-and a few others-need \nto be defined specially for each system. These definitions are found in each translation. Table 7: Translation \nof the Call-by-name Functional SLam Calculus into DCC (excerpts). coerw, 1s2 : s; --f s; = k~:T~(unit~).bindy=xin(~~y) \n COerce(,it,k),(unit,~)  = kc: T,(s~~uf).bindy=nin~lc (~z:~~.coerce~,,,,(y(coerce,~,,.~,z))) =oe~ce(.s2+U, \n,w),(s,+U2,~) = hx: T,(s; xuT).bindy=xin~~~~ (coerce,Y,,s2(proj1 y),coerce,,,,,(proj2y)) coerce(.~,,,,,K),(.~,xu,,~) \n = hr:T,((s~+u~)~).bindy=.~in~~~ (seqz=yin casezcoeYCe(,~,+u,,IC),(SZ+UZ,K ) of injI(w). lift (injl (coerce,T,,,T, \nw)) 1inj2(w).lift (inj2 (coerce,,,,, w))) w4 [Unit] rk(),:(unit,K)* r* I- llK(lift()):TK(unitJ Tl-e:sl \nr* t- e* : S; SliS2 kbl rkees2 * r* t- (coerce,y,,,T, e*) : s; r*,f:s*  r,f :ske:s be*:s* [JW rk(pf:s.e):s \n* r*l-(pf:s*.e*):s* be*:~; v-4 rk(h:sl.e)K:(~l * r* k (qK (LX : s;. e*)) : T,(s; -+ s;) r,x: sl I-e : \n~2 r*,x:s; -+sz,K) l-t-e: (s, --+s~,K) rFel :sl r* k e* : TK(s; --t s;) r* k e; :s; LAPPI rk(eel):s20K \n* r*t-dot(bindf=e*in(qr(fe;))):(s2*K)* jisfresh rt-ei:Si r* I-e: : ST [Pair] rk(el,e2)K:(sl Xs2,K) * \nr* +(r(,(e;,e$)): G(sT Xsb) rte:(Sl Xs2,K) r* l-e* : T,(s; xs;) [WI rk(projie):si*K * I-'* (bindx= e* \nin(TIK (projix))) :(SiOK)* k dot xis fresh TFe:si r* t e* :s; [WI rt(injie)h-:(sl fs2,K) * (qK(lift (injie*))) \n+$)I) r* I- : T,((s; r* k e* : T,( (s; + s;)~) r*,x:sfke;:s* r*t-dot( bindy=e* T+~:(s,+s~,K) r,x:siFei:s \nin (TIK( seqv=yin y fresh   [Case] =+ casev of injI(x).e; 1inj2(x). ez))) : (S*K)* rE(caseeofinjI(x).el \nIinj2(x).e2):s*K rt-e:s r* f e* :s* [Protect] rt-(protect,e):s*K * r*I-ddot(qre*):(s*K)* Table 8: Translation \nof the Slicing Calculus into DCC (excerpts). W-1 r,x:s,rfkx:s+r*,x:s*,(r')*k~:~* [Unit] rt On : (unit,{n}) \n=+ r*I-r({,)(lift0) :T{,)(unit~) [km1 r,x:sI k e: g r t- (Ix:s~.~),: (s, -+s2,{n}) * r* t- (q{,,) r*,X:Sfke*:s; \n(Lx: sT.e*)) : T{,,)(si -+ ss) Tke: (s, +s~,K) rFel:sl r* t-e* : TK(s; -+ s;) r* t-e; :s; VPPI rt(eel):s20~ \n* r* I- dot (bindf= e* in (Q (fer))) : (s2oK)* fis fresh Table 9: Translation of the Binding-time Calculus \ninto DCC (excerpts). r,x:s,r~x:sJr*,x:s*,(r )*~.:s* WI [Unit] rt ()p: (unit,@ *r* I- (qp (lift 0)) : \nTj(unitl) r-,x: s1 k e : ~2 r*,x:s;t-e*:~;km1 rk(hr:sl.e)p:(s~ -+s2,P) * r* I- (Q (IX :s;.e*)) :Tp(s; \n-+ sz) rte: (~1 +s2,/3) r t- el : s1 j r* k e* : Tg(s; -+ s;) r* ~ T ; f is fresh L%wl rk(eel):s2 \nTable 10: Translation true = (if e thene, elsfz; = = proj, = c0ercet.p = c0erceL.H= c~~erceHcmd.Lcmd \n= r*l-(bindf=e*in(fe;)):s; of the Smith-Volpano Calculus into DCC. (inj 1 0) (inj;! 0) (caseeof injl(x).el \n 1inj*(n).ez),n is fresh theprojection statetothe x oftbe variable hf..f , e = L, H, (L cmd),or (H cmd) \nhf.hs:S\"f,(rH)XS\"L(rL).~H (,fS) hf'.h~:SVff(r~)xSV~(T~).lift (,f's,proj2s)  W4 rH;r~tX:~=+(hO.proj,O):sv(rH,rL,z) \nifxErT [ TrueH] rH;rL k true :H * (ho.qH true) :sv(rH,rL,H) [FalseHj rH;rL t false:H + (ho.T)H,fdse) \n:sv(rH,rL,H) [True-L] rH;rLI-true: L* (hatrue) :sv(rH,rL,q [FalseL] r,&#38;rL.t false : L + (ho.,fahe) \n: s\"(rH,rL,L) P@Hl rH;rLk skip:H cmd+(ha,proj,O):sv(r,,r,,H cmd) [Sk&#38;L] rH;rLbskip:Lcmd+(ho.lift \nCJ):SV(TH,TL,LC~~) WI rH; rL t e : .w .w ISI rH;rLbe:21 * e* : sv(rH,rL,SO) (COerCeSople*) : s\"(rH,rL,SI) \n[Assigns] r&#38;rLke: H rH =(~l,...r&#38;) rH;rL!F((xi:=e):Hcmd j e*:sv(rH,rL,H) (h~.(proj,(proj, @,...,(e* \n(~),...,)):Sv(r~,r~,Hcmd) [AssignL] rH;rLte:L rL=h,...,4 rH;rLl-(q:=e):Lcmd * e : sv(rH,rL,L) (ho.lift \n((proj1Q),(proj,(proj*(T),...,(e*cT),...,))):sv(rH,rL,Lcmd) rH;rLkCI:Hcmd rHH;rLb-c2:Hcmd j CT:SV(rH,rL,Hcmd) \nc;:SV(rH,rL,Hcmd) PeNI rH;rL k (cI;c2): H cmd (h0.c;(cl Q,proj2O)):SV(rH,rL,Hcmd) rH;rL+cC1:Lcmd rH;rLkC2:Lcmd \nj Ci :S\"(rH,rL,L cmd) C;:s\"(rH,rL,L cmd) rH;rLk(Cl;C2):Lcmd (ho.seqal =(Ci6) in(c~a~)):S\"(TH,TL,Lcmd) \nWI r&#38;rLke: H rH;rL k Ci :H cmd rH;rLtifethenclelsec;?:H cmd * e*:SV(rH,rL,H) (lcr.bindv= (e* O) c; \n:SV(l-H,r-L,HCrnd) v is fresh inifvthen(Ci cr)else(c;o)):SV(rH,rL,Hcmd) WI rH;rLte:L rH;rLtci:Hcmd rH;rLt-ifethenclelsec2:Lcmd \ne*:sv(rH,rL,L) of:sv(rH,rL,Lcmd) * (ho.if (e* CJ) then{ci o)else (cz o)) :SV(r~,rL,Lcmd) [While] rH;rLte:L \nrH;rLtc:Lcmd j lYH;rLFwhileedOc:Lcmd e*:s\"(rH,rL,L) C* :s\"(rH,rL,L cmd) (~,?f..ho.if(e*a)thenseqd=(c*(T)in(fd)else(lifto)):SV(r~,rL,Lcmd) \n Table 11: Translation of the Call-by-value Functional SLam Calculus into vDCC (excerpts). ifs=(sl+.v~,K)and(s:!or)=s~ \nc\"erce(,,it,r).(unit,~) fi = p,!f.hg:s*+(s*)~.g(~,(hx:s~.seqbindh=(f'g)in(hx))) = k:T,(unit).bindy=nin(~y) \nc~'erce(.,z+u,.r)~(.~,~uz,n') (hz :si.seqv (y (c~erce,~,.,,~ z)) = hr : T,(s; + (Ui)l).bindy=.XinIld \n= in lift (coerce,,,,2 v)) seqV=e; inseqr=(,f'~)inlift(dot(Tj~r)):(.Q.~); Prl r,n:s,I+ I-(liftx):(s*)~k-x:s* \nr*,x:s*,(r')* [Unit] rt-(),:(unit,K)*r*t-(lift(Ij,())):(T,(unit))~ Pbl rte:.q s, 5 r I- e: s2 92 * r*te*:(s;)I \nr* t- seqw= e* inlift(c0erce,v,,,s2 w) : (.$)I w fresh [Reel r, .f : s I- e : s S = ($1 --f .Q,K) r t- \n(p..f : s : 3.e) (S1.K) = s* * r*,f: S* t e* : (s*)~ r*kji.x(k,f :~*.e*) :(s*)~ [Lam1 r,x: 3, t- e : \n.q r~(hr:.Vl,e)K:(sl -+S2,K) * r*,n: Si t-e* : ($)I r* k lift(?jK(hY:.7i.e*)):(TK(si -+ (S;)I))I PPPI \nrte:(s, --Fs~,K) rte, rI_ (eel) :S~OK :s, a r* k e\" : (Tx(Si --f (s;)~))~ r* I- seqbind,f =e*in r* k \nei : (s;)~ ,f',v,r fresh rte:s r* t-e* : (s*)~ r-t-(protect,e) * r*Fseqm=e*inlift(dot(Ijrm)):(s*K); \nmfresh :SIK Table 12: Translation of the Call-tracking Calculus into vDCC (excerpts). ifs= (~1-% ~2) \n fir = p,f.hg:~*+(T~(s*))~.g(hr:s~.seqbindh=(f'g)in(h~)) r,x:s,r~x:s,L~r*,n:s*,(r)*~lift(~~x):(T (~*))~ \nrt-() :unit,L* r* k lift (ljr. 0) :(T~(unit))~ : S* I- e : (TK(~*))L Fe4 rt-: s.e) * r*~~((hf :.~*.e*):(T,(.~*))l \nr,.f : s t e : S,K s = (SI -r, .q) r*,f' (p.!f' : s r,x:S, I-e :s~,K r*,n: Si I- e* : (T,(.$))L k4 r-F- \n(hr :.q.e), : (s, q s2),L * I? k (lift(IjL (k:si.seqr=e*in lift (dot (qt,) r))))) : (TL(si -+ (Ti,),,(s;))l))l \nrfresh r* F e* :(T&#38;(si --f (T,(s;))~))~ r* t ei : (T,,(si))l rke:(Sl&#38;S2),Kl r!-el:Slr~2 j r*t-seqbindf'=e*in \n,f ,y,v fresh MPPI  rt (eel):S2,KuKl UK2 seqbindy=eiin seqbindv= (.t'~) inlift(%uK,uK2 ~):(TMJ~,u~~(s;))~ \n   \n\t\t\t", "proc_id": "292540", "abstract": "", "authors": [{"name": "Mart&#237;n Abadi", "author_profile_id": "81100547147", "affiliation": "Systems Research Center, Compaq", "person_id": "PP39047996", "email_address": "", "orcid_id": ""}, {"name": "Anindya Banerjee", "author_profile_id": "81100144615", "affiliation": "Stevens Institute of Technology", "person_id": "PP14060901", "email_address": "", "orcid_id": ""}, {"name": "Nevin Heintze", "author_profile_id": "81100251839", "affiliation": "Bell Laboratories", "person_id": "P208265", "email_address": "", "orcid_id": ""}, {"name": "Jon G. Riecke", "author_profile_id": "81339524439", "affiliation": "Bell Laboratories", "person_id": "PP39077809", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/292540.292555", "year": "1999", "article_id": "292555", "conference": "POPL", "title": "A core calculus of dependency", "url": "http://dl.acm.org/citation.cfm?id=292555"}