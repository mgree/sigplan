{"article_publication_date": "01-01-1999", "fulltext": "\n Typed Memory Management in a Calculus of Capabilities* Karl Crary David Walker Greg Morrisett Carnegie \nMellon University Cornell University Cornell University Abstract An increasing number of systems rely \non programming lan-guage technology to ensure safety and security of low-level code. Unfortunately, these \nsystems typically rely on a com- plex, trusted garbage collector. Region-based type systems provide an \nalternative to garbage collection by making mem- ory management explicit but verifiably safe. However, \nit has not been clear how to use regions in low-level, type-safe code. We present a compiler intermediate \nlanguage, called the Capability Calculus, that supports region-based memory management, enjoys a provably \nsafe type system, and is straightforward to compile to a typed assembly language. Source languages may \nbe compiled to our language using known region inference algorithms. Furthermore, region life- times \nneed not be lexically scoped in our language, yet the language may be checked for safety without complex \nanal-yses. Finally, our soundness proof is relatively simple, em-ploying only standard techniques. The \ncentral novelty is the use of static capabilities to specify the permissibility of various operations, \nsuch as memory access and deallocation. In order to ensure ca-pabilities are relinquished properly, the \ntype system tracks aliasing information using a form of bounded quantification. 1 Motivation and Background \nA current trend in systems software is to allow untrusted ex-tensions to be installed in protected services, \nrelying upon language technology to protect the integrity of the service instead of hardware-based protection \nmechanisms [19, 39, 2, 25,24,17,14]. For example, the SPIN project [2] relies upon the Modula-3 type \nsystem to protect an operating system kernel from erroneous extensions. Similarly, web browsers rely \nupon the Java Virtual Machine byte-code verifier [19] to protect users from malicious applets. In both \nsituations, the goal is to eliminate expensive communications or boundary *This research was performed \nwhile the first author was at Cornell University. This material is based on work supported in part by \nthe AFOSR grant F49620-97-1-0013 and ARPA/RADC grant F30602-96-l-0317. Any opinions, findings, and conclusions \nor recommendations expressed in this publication are those of the authors and do not reflect the views \nof these agencies. Permission to make digital or hard copies ofall or part of this work for personal \nor classroom use is grmted without fee probided that copies are not wade or distributed for prolit or \ncommercial advantage and that topics bear this notice and the fillcitation on the first page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission \nand!or a fee. POPL 99 San Antonio Texas LJSA Copyright ACM 1999 I-581 13-095-3/99/01...$5.00 crossings \nby allowing extensions to directly access the re-sources they require. Recently, Necula and Lee 126, \n251 have proposed Proof-Carrying Code (PCC) and Morrisett et al. [24] have sug- gested Typed Assembly \nLanguage (TAL) as language tech- nologies that provide the security advantages of high-level languages, \nbut without the overheads of interpretation or just-in-time compilation. In both systems, low-level ma-chine \ncode can be heavily optimized, by hand or by com-piler, and yet be automatically verified through proof-or \ntype-checking. However, in all of these systems (SPIN, JVM, TAL, and Touchstone [27], a compiler that \ngenerates PCC), there is one aspect over which programmers and optimizing compil-ers have little or no \ncontrol: memory management. In par- ticular, their soundness depends on memory being reclaimed by a trusted \ngarbage collector. Hence, applets or kernel extensions may not perform their own optimized memory management. \nFurthermore, as garbage collectors tend to be large, complicated pieces of unverified software, the degree \nof trust in language-based protection mechanisms is dimin- ished. The goal of this work is to provide \na high degree of con- trol over memory management for programmers and com-pilers, but as in the PCC and \nTAL frameworks, make veri- fication of the safety of programs a straightforward task. 1.1 Regions Tofte \nand Talpin [35, 361 suggest a type and effects system for verifying the soundness of region-based memory \nman-agement. In later work, Tofte and others show how to infer region types and lifetimes and how to \nimplement their the- ory [34, 3, 41. There are several advantages to region-based memory management; \nfrom our point of view, the two most important are: 1. Deallocation is explicit but provably safe. 2. \nThe run-time routines necessary for region-based mem-ory management are relatively simple constant-time \noperations and, in principle, could be formally verified.  The Tofte-Talpin calculus uses a lexically \nscoped expres-sion (letregion r in e end) to delimit the lifetime of a re- gion r. Memory for the region \nis allocated when control en-ters the scope of the letregion construct and is deallocated when control \nleaves the scope. This mechanism results in a strictly LIFO (last-in, first-out) ordering of region lifetimes. \n Both Birkedal et al. [4] and Aiken et al. [l] observed that a completely LIFO (de)allocation of regions \nwould make poor use of memory in many cases. They proposed a series of optimizations that often alleviate \nefficiency concerns and even improve upon traditional tracing garbage collection in some cases. Although \ntheir optimizations are safe, there is no simple proof- or type-checker that an untrusting client can \nuse to check the output code. Similarly, even the most straightforward code-generation requires that \nwe stray from the Tofte-Talpin framework and allow arbitrary separation of allocation and deallocation \npoints. Therefore, while re-gion inference brings us half way to our goal, in order to construct a strongly-typed \nregion-based assembly language we must re-examine the fundamental question: When can we free an object \nx? One solution is to free x when you can guarantee that it will no longer be accessed. Operating systems \nsuch as Hydra [41] have solved the access control problem before by associating an unforgeable key or \ncapability with every object and requiring that the user present this capability to gain access to the \nobject. Furthermore, when the need arises, these systems revoke capabilities, thereby preventing future \naccess. 1.2 Overview of Contributions In the rest of this paper, we describe a strongly typed lan-guage \ncalled the Capability Calculus. Our language s type system provides an efficient way to check the safety \nof ex-plicit, arbitrarily ordered region allocation and deallocation instructions using a notion of capability. \nAs in traditional capability systems, our type system keeps track of capability copies carefully in order \nto determine when a capability has truly been revoked. Unlike traditional capability systems, our calculus \nsupports only voluntary revocation. However, the capabilities in our calculus are a purely static concept \nand thus their implementation requires no run-time over-head. We have a purely syntactic argument, based \non Subject Reduction and Progress lemmas in the style of Felleisen and Wright [40], that the type system \nof the Capability Calcu-lus is sound. In contrast, Tofte and Talpin formulate the soundness of their \nsystem using a more complicated great-est fixed point argument [36], and the soundness of Aiken et aI. \ns optimizations [l] depend upon this argument. Part of the reason for the extra complexity is that Tofte \nand Talpin simultaneously show that region inference translates lambda calculus terms into operationally \nequivalent region calculus terms, a stronger property than we prove. However, when system security is \nthe main concern, soundness is the critical property. The simplicity of our argument demonstrates the \nbenefits of separating type soundness from type inference or optimization correctness. We have a formal \ntranslation of a variant of the Tofte- Talpin language into our calculus. We describe the transla- tion \nin this paper by example; the full details appear in the companion technical report [5]. We also illustrate \nhow some region-based optimizations may be coded in our language, taking advantage of our extra freedom \nto place allocation and deallocation points. We have adapted the type system for the Capability Cal-culus \nto the setting of Typed Assembly Language, providing for the first time the ability for applets to explicitly \ncon-trol their memory management without sacrificing memory- or type-safety. As the typing constructs \nat the intermediate and assembly levels are so similar, we discuss here only the intermediate language \nand refer the interested reader to the companion technical report [5] for details on the assembly level. \n 2 A Calculus of Capabilities The central technical contribution of this paper is the Ca- pability Calculus, \na statically typed intermediate language that supports the explicit allocation, freeing and accessing \nof memory regions. Programs in the Capability Calculus are written in continuation-passing style (CPS) \n[29]. That is, functions do not return values; instead, functions finish by calling a continuation function \nthat is typically provided as an argu- ment. The fact that there is only one means of transferring control \nin CPS-rather than the two means (call and re-turn) in direct style-simplifies the tracking of capabilities \nin our type system. A direct style formulation is possible, but the complications involved obscure the \ncentral issues. In the remainder of this paper, we assume familiarity with CPS. The syntax of the Capability \nCalculus appears in Fig- ure 1. In the following sections, we explain and motivate the main constructs \nand typing rules of the language one by one. The complete static and operational semantics are specified \nin Appendix A. 2.1 Preliminaries We specify the operational behavior of the Capability Calcu-lus using \nan allocation semantics [22, 23, 241, which makes the allocation of data in memory explicit. The semantics \nis given by a deterministic rewriting system P I-+ P' map-ping machine states to new machine states. \nA machine state consists of a pair (M, e) of a memory and a term being ex-ecuted. A memory is a finite \nmapping of region names (v) to regions where a region is a block of memory that holds a collection of \nheap-allocated objects. Regions are created at run time by the declaration neurgnp, z, which allocates \na new region in the heap, binds p to the name of that region, and binds z to the handle (handle(v))for \nthat region. Region names and handles are distinguished in order to maintain a phase distinction between \ncompile-time and run- time expressions. Region names are significant at compile time: The type-checker \nidentifies which region an object inhabits via a region name (see below). However, region names, like \nother type constructors, have no run-time sig-nificance and may be erased from executable code. In con- \ntrast, region handles hold the run-time data necessary to manipulate regions. In addition to accounting \nfor a phase distinction, the separation of region names and handles also allows us to refine the contexts \nin which region handles are needed. Handles are needed when allocating objects within a region and when \nfreeing a region, but are not needed when reading data from a region. Regions are freed by the declaration \nfreergnv, where v is the handle for the region to be freed. Objects h large enough to require heap allocation \n(i.e., functions and tu-ples), called heap vaZues, are allocated by the declaration z = h at v, where \nv is the handle for the region in which h is to be allocated. Data is read from a region in two ways: \nfunctions are read by a function call, and tuples are read by the declaration z = r;(v), which binds \nx to the data re-siding in the ith field of the object at address v. Each of kinds constructor vars constructors \ntype8 region8 capabilities multiplicities constructor context8 value context8 region type8 memory type8 \nword values heap values arithmetic ops declarations term8 memory region8 memories machine states ::=K \n%P?E C ::= 7 .._ 21 ..-.*_   I= cp ..- A ..- ..-r ::= -I-..- ..-9 .._ ..-  ; ;;I ..- P ..- d ..- \n...  e ..- R ::= M ..- ..- ..- P ..- TYPO I %n I Cap alTlrlC a 1int I r handle IV[A].(C, 71,.. .,T \n) -+ o at r 1(n, .. . , TV) at T .I A,crx ( A,e 5 C . I r,x:r 2.1i I v.L I handle(v) I w[c] f+yf[f](C,x~:n,. \n. . ,2dn).e I (VI,. . . ,vn) X x=v~x=v1pv2~x=hatvIx=nivInewrgnp,z letd ine 1ifOvtheneselsees I v(vI,...,v~) \nI halt I freergn V v {el+-+-,l,...,e,~~h,) {~1++R1,...,vn++Rn} (M, e) Figure 1: Capability Syntax these \noperations may be performed only when the region in question has not already been freed. Enforcing this \nrestric- tion is the purpose of the capability mechanism discussed in Section 2.2. A region maps locations \n(e) to heap values. Thus, an address is given by a pair v.e of a region name and a loca-tion. In the \ncourse of execution, word-sized values (v) will be substituted for value variables and type constructors \nfor constructor variables, but heap values (h) are always allo-cated in memory and referred to indirectly \nby an address. Thus, when executing the declaration z = h at r (where r is handle(v), the handle for \nregion v), h is allocated in region v (say at a) and the address v.e is substituted for x in the following \ncode. A term in the Capability Calculus consists of a series of declarations ending in either a branch \nor a function call (or a halt). The class of declarations includes those constructs discussed above, \nplus two standard constructs, x = v for binding variables to values and x = vi p 212 (where p ranges \nover +, -and x) for arithmetic. Types The types of the Capability Calculus include type constructor variables \nand integers, a type of region handles, as well as tuple and function types. If r is a region, then r \nhandle is the type of r s region handle. The tuple type (Tl , . . . , TV) at r contains the usual n field \ntuples, but also specifies that such tuples are allocated in region r, where r is either a region name \nv or, more frequently, a region variable P. The function type V[].(C, 71,. . . ,T~) + 0 at r contains \nfunctions taking n arguments (with types 71 through rn) that may be called when capability C is satisfied \n(see the next section). The 0 return type is intended to suggest the fact that CPS functions invoke their \ncontinuations rather than returning as a direct-style function does. The suffix at r , like the corresponding \nsuffix for tuple types, indicates the region in which the function is allocated. Functions may be made \npolymorphic over types, regions or capabilities by adding a constructor context A to the function type. \nFor convenience, types, regions and capabili-ties are combined into a single syntactic class of construc-tors \nand are distinguished by kinds. Thus, a type is a con-structor with kind Type, a region is a constructor \nwith kind Rgn, and a capability is a constructor with kind Cap. We use the metavariable c to range over \nconstructors, but use the metavariables 7, r and C when those constructors are types, regions and capabilities, \nrespectively. We also use the metavariables p and c for constructor variables of kind Rgn and Cap, and \nuse the metavariable (Yfor type variables and generic constructor variables. When A is empty, we abbre-viate \nthe function type V[A].(C, 1) -+Oatr by (C, ?) +Oat r. For example, a polymorphic identity function that \nis al-located in region r, but whose continuation function may be in any region, may be given type V[a:Type, \np:Rgn].(C, cy, (C, a) + 0 at p) + 0 at r for some appropriate C. Let f be such a function, let w be its \nargument with type r, and let g be its continuation with type (C, 7) -+ 0 at r. Then f is called by f[T][r](v, \ng). The typing rules also make use of region types (T), which assign a type to every location allocated \nin a region, and memory types (@), which assign a region type to every re-gion allocated in memory. \n2.2 Capabilities The central problem is how to ensure statically that no re-gion is used after it is \nfreed. The typing rules enforce this with a system of capabilities that specify what operations are permitted. \nThe main typing judgement is *;A;I ;C!-e which states that (when memory has type X!?, free construc- \ntor variables have kinds given by A and free value variables have types given by I ) it is legal to execute \nthe term e, pro-vided that the capability C is held. A related typing judge- ment is which states that \nif the capability C is held, it is legal to execute the declaration d, which results in new constructor \ncontext A , new value context I and new capability C . Capabilities indicate the set of regions that \nare presently valid to access, that is, those regions that have not been freed. Capabilities are formed \nby joining together a collec- tion of singleton capabilities {r} that provide access to only one region, \nand capability variables E that provide access to an unspecified set of regions. Capability joins, written \nCr @ Cz, are associative and commutative, but are not al-ways idempotent; in Section 2.3 we will see \nexamples where C @ C is not equivalent to C. The empty capability, which provides access to no regions, \nis denoted by 8. We will often abbreviate the capability {ri} $ . . . @ {T,,} by {PI,. . . , T,,}. In \norder to read a field from a tuple in region r, it is necessary to hold the capability to access r, as \nin the rule: A I- C = C @ {r} : Cap *;A;l?t-~:(ri,...,r~)atr (z G Dam(r)) 9; A; l?; C I- z = A;(W) + \nA; l?{z:ri}; C The first subgoal indicates that the capability held (C) is equivalent to some capability \nthat includes {r}. A similar rule is used to allocate an object in a region. Since the type of a heap \nvalue reflects the region in which it is allocated, the heap value typing judgement (the second subgoal \nbelow) must be provided with that region. A l- C = C @ {r} : Cap \\k;A;I t-hatr:r P;A;I fv:r handle (z \n@ oom(r)) ~;A;r;Ct-~==atv~A;r{z:r};C Functions Functions are defined by the form fixf[A](C,zi:rr ,..., \nz,,:r,,).e, where f stands for the function itself and may appear free in the body, A spec-ifies the \nfunction s constructor arguments, and C is the function s capability precondition. When A is empty and \nf does not appear free in the function body we abbreviate the fix form by X(C,zi:ri,. . . ,z :r,,).e. \nIn order to call a function residing in region r, it is again necessary to hold the capability to access \nr, and also to hold a capability equivalent to the function s capability precon-dition: A k C = C @ {r} \n: Cap A I- C = C : Cap *;A;lYt-v:(C ,ri,...,r,)+Oatr O;A;I t-wi:ri The body of a function may then assume \nthe function s capa-bility precondition is satisfied, as indicated by the capability C in the premise \nof the rule: *; A; I {zi:ri, . . . , G:T,,}; C I- e (xi $ oom(r)) 9; A; r E X(C, zl:rl,. . . , z,,:r,).e \nThis rule specializes the full rule for fiz to the case where the function is neither polymorphic nor \nrecursive. Often, we will extend the required capability for a func-tion with a quantified capability \nvariable (similar to a row variable). This variable may be instantiated with whatever capabilities are \nleftover after satisfying the required capabil- ity. Consequently, the function may be used in a variety \nof contexts. For example, functions with type V[e:Cap].({r} @ 6,. . .) -+ 0 at r may be called with any \ncapability that extends {r}. Allocation and Deallocatiw The most delicate issue is the typing of region \nallocation and deallocation. Intuitively, the typing rules for the newrgn and freergn declarations should \nadd and remove capabilities for the appropriate re-gion. Naive typing rules could be: (wrong) Q;A;I ;C~newrgnp,x* \nA{p:Rgn}; I {z:p handle}; C cB {p} Q; A; l? !- v : r handle C = C \\ {v} (wrong) 9; A; l?; C E f reergn \nv + A; I ; C We will be able to use something much like the first rule for allocation, but the naive \nrule for freeing regions is fundamen- tally flawed. For example, consider the following function: fixf[pr:Rgn,pz:Rgn]({pl,pz},z:pl \nhandle, y:(int) at pz). let f reergn 2 in let z = 7rs y in . . . This function is well-formed according \nto the naive typing rule: The function begins with the capability {pi,pz} and pi is removed by the freergn \ndeclaration, leaving {pz}. The tuple y is allocated in pz, so the projection is legal. However, this \ncode is operationally incorrect if pi and pz are instanti- ated by the same region r. In that case, the \nfirst declaration frees r and the second attempts to read from r. This problem is a familiar one. To \nfree a region safely it is necessary to delete all copies of the capability. However, instantiating region \nvariables can create aliases, making it impossible to tell by inspection whether any copies exist.  \n2.3 Alias Control We desire a system for alias control that can easily be en-forced by the type system, \nwithout expensive and complex program analyses. One possibility is a linear type system [12, 37, 381. \nIn a linear type system, aliasing would be triv- ially controlled; any use of a region name would consume \nthat name, ensuring that it could not be used elsewhere. Thus, in a linear type system, the naive rules \nfor allocating and deallocating regions would be sound. Unfortunately, a linear type system is too restrictive \nto permit many useful programs. For example, suppose f has type V[pl:Rgn, pz:Rgn]. ({p~,pz}, (int) at \npl, (int) at ~2,. . .) + 0 at d and vi and w2 are integer tuples allocated in the same region r. Then \nf could not be called with vi and 2)~ as arguments, because that would require instantiating pl and pa \nwith the same region. More generally, one could not type any func- tion that takes two arguments that \nmight or might not be allocated in the same region. Approaches based on syntactic control of interference \n[30, 311 are more permissive than a linear type system, but are still too restrictive for our purposes; \nit is still impossible to instantiate multiple arguments with the same region. Uniqueness Our approach, \ninstead of trying to prevent aliasing, is to use the type system to track aliasing. More precisely, we \ntrack non-aliasing, that is, uniqueness. We do this by tagging regions with one of two multiplicities \nwhen forming a capability. The first form, {r+}, is the capability to access region r as it has been \nunderstood heretofore. The second form, {ri}, also permits accessing region P, but adds the additional \ninformation that P is unique; that is, r repre- sents a different region from any other region appearing \nin a capability formed using {r }. For example, the capability {r , , ri} not only indicates that it \nis permissible to access ri and rz, but also indicates that ri and ~2 represent distinct regions. Since \n{r } guarantees that r does not appear anywhere else in a capability formed using it, it is the capability, \nnot just to access r, but also to free r. Thus we may type region deallocation with the rule: A;I bv:r \nhandle Al-C=C @{r }:Cap !P ; A; r; C l- f reergn v =+ A; l?; C Allocation of a region accordingly adds \nthe new capability as unique: (D 6 Dom(A),x 4 Dom(I )) Q;A;l?;Ct-newrgnp,x* A{p:Rgn}; I {s:p handle}; \nC G3 {pi> Note that joining capabilities is only idempotent when the capabilities in question contain \nno unique multiplicities. For instance, the capabilities {r+} and {r+, r+} are equivalent, but the capabilities \n{r } and {r ,r } are not; the latter capability ({r , r }) asserts that r is distinct from itself and \nconsequently that latter capability can never be satisfied. The rules for capability equivalence appear \nin Appendix A. When C is equivalent to C@C, we say that C is duplicat- able. Note that capability variables \nare unduplicatable, since they can stand for any capability, including unduplicatable ones. Occasionally \nthis prevents the typingof desired pro- grams, so we provide a stripping operator C that replaces all \n1 multiplicities in C with + multiplicities. For example, {r:,rz} = {rt,r, }. For any capability C, the \ncapability c is duplicatable. When programs need an unknown but duplicatable capability, they may use \na stripped variable 7. Subcapabilities The capabilities {r } and {r+} are not the same, but the former \nshould provide all the privileges of the latter. We therefore say that the former is a subcapability \nof the latter and write {r } 5 {r+}. In the complete system, the various rules from Section 2.2 are modified \nto account for subcapabilities. For example, the function call rule becomes: \\E;A;rbv:(C ,7i,...,rn)+0atr \nA t- C 5 C EJ {r+} A !- C <_ C *;A;l?kW; :7i q ; A; l?; C t- v(vr, . . . , a) The subcapability relation \naccounts only for the forget- ting of uniqueness information. Intuitively there could be a second source \nof subcapabilities, those generated by for- getting an entire capability. For example, {rt,r$} seems \nto provide all the privileges of {rt}, so it is reasonable to suppose {r; ,r, } to be subcapability of \n{r; }. Indeed, one can construct a sound Capability Calculus incorporating this axiom, but we omit it \nbecause doing so allows us to specify memory management obligations and to prove a stronger property \nabout space usage. One may write a function that can be called with extra capabilities using a capability \nvari-able, as discussed in Section 2.2. By omitting the axiom Cl @ C2 5 Ci, our type system may formally \nspecify who has responsibility for freeing a region. Failure to follow informal conventions is a common \nsource of bugs in languages (such as C) that use manual memory management. Our type system rules out \nsuch bugs. For example, consider the type: V[p:Rgn, c:Cap]. ({pi} @ e, p handle, (E) -+ 0 at r ) + 0 \nat r In our system e @ {p } f E. Consequently, before any func- tion with this type can return (i.e., \ncall the continuation of type (E) + 0 at r ), it must take action to satisfy the capability E, that is, \nit must free p. In general, our type system prevents region leaks : pro-grams must return all memory \nresources to the operating system before they terminate (Theorem 2.4). The operat-ing system does not \nhave to clean up after a program halts. The typing rule for halt states that no capabilities may be held, \nand since capabilities may not be forgotten, this means that all regions must have been freed. @ ;A;I \nl-v:int Al-C=@:Cap rk;A;l?;C l- halt v Bounded Quantification The system presented to this point is \nsound, but it is not yet sufficient for compiling real source languages. We need to be able to recover \nuniqueness after a region name is duplicated. To see why, suppose we hold the capability {r ) and f has \ntype: V[pi :Rgn, pz :Rgn]. (Id, Pa, * * * 9 ({pt,pt}, . . .) + 0 at r ) + 0 at r We would like to be \nable to instantiate pl and p2 with r (which we may do, since {r } 5 {r+,r+}), and then free r when f \ncalls the continuation in its final argument. Un-foryftel? the continuation only poss;sses the capability \n{r ,r } -{r+}, not the capability {r } necessary to free r. It does not help to strengthen the capability \nof the con- tinuation to (for example) {pi}, because then f may not call it. We may recover uniqueness \ninformation by quantifying a capability variable. Suppose we again hold capability {r } and g has type: \nSuppose f has typeV[pi:Rgn,p2:Rgn].({pt,pt}, . . .)-+Oatr . If we hold capability {r+}, we may call f \nb instanti-P ating pi and p2 with r, since {r+} = {r+,r }. Using the subcapability relation, we may also \ncall f when we hold {rl}, again by instantiating pi and p2 with r, since {r } 5 {r+} = {P+,r+}. V[pi:Rgn, \npz:Rgn, e:Cap].(e, . . . , (E, . . .) + 0 at T ) + 0 at r We may instantiate e with {r } and then the \ncontinuation will possess that same capability, allowing it to free r. Un-fortunately, the body of function \ng no longer has the capa- bility to access pl and ~2, since its type draws no connection between them \nand E. We solve this problem by using bounded quantification to relate pi, pr and e. Suppose h has type: \nV[~l:~,Ggn,c 5 {P:,P;)]. E,. . . , (E,. . .) + 0 at r ) + 0 at r If we hold capability {r }, we may call \nh by instantiating pi and pz with r and instantiating c with r }. This instan-tiation is permissible \nbecause {r } 5 {r i,r+J. As with g, the continuation will possess the capability {r }, allowing it to \nfree r, but the body of h (like that of f) will have the capability to access pi and pa, since e 5 {pt,pt}. \nBounded quantification solves the problem by revealing some information about a capability e, while still \nrequir- ing the function to be parametric over E. Hence, when the function calls its continuation we \nregain the stronger capa- bility (to free r), although that capability was temporarily hidden in order \nto duplicate T. More generally, bounded quantification allows us to hide some privileges when calling \na function, and regain those privileges in its continuation. Thus, we support statically checkable attenuation \nand am-plification of capabilities. 2.4 Formal Properties of the Calculus The most important properties \nof the Capability Calculus are Type Soundness and Complete Collection. Each can be proven from the formal \nsemantics in Appendix A. Type Soundness states that we will never enter a stuck state during the execution \nof a well-typed program. A state (M,e) is stuck if there does not exist (M , e ) such that (M,e) e (M \n,e ) and e is not halt i. For example, a state that tries to project a value from a tuple that does not \nappear in memory is stuck. Theorem 1 (Type Soundness) If I- (M,e) and (M,e) W* (M ,e ) then (M ,e ) \nis not stuck. The proof of soundness is straightforward, making use of the standard Subject Reduction \nand Progress lemmas. Progress states that well-typed states are not stuck, and Subject Reduction states \nthat evaluation steps preserve well- typedness. Lemma 2 (Subject Reduction) Ift-(M,e) and (M,e) w (M \n,e ) then F (M ,e ) Lemma 3 (Progress) Ift-(M,e) then either: 1. There exists (M ,e ) such that (M,e) \nc-) (M ,e ), or 2. e = halt i  The Complete Collection property guarantees that well- typed terminating \nprograms return all of their memory re-sources to the system before they halt. Theorem 4 (Complete Collection) \nI !-(M,e) then ei-ther (M,e) diverges or (M,e) H* ({ }, halt i). By Subject Reduction and Progress, terminating \npro-grams end in well-formed machine states (M, halt i). The typing rule for the halt expression requires \nthat the capa- bility C be empty. Using this fact, we can infer that the memory M contains no regions. \n3 Expressiveness Our work provides a type system in which to check region- annotated programs for safety, \nbut we do not provide any new techniques for determining those annotations. Instead, we rely on existing \nregion inference strategies [34, l] to infer appropriate region annotations. In this section we illustrate \nhow a variant of the Tofte-Talpin region language can be translated into the Capability Calculus. The \ntranslation is formalized in the companion technical report [5]. By com-posing Tofte and Birkedal s region \ninference algorithm [34] with this translation, we have a way to compile high-level languages into the \nCapability Calculus. Our example considers a function count that counts down to zero. In order to have \ninteresting allocation be-havior the integers involved in the count are boxed, and hence are allocated \nin a region. %xX count in a Tofte-Talpin calculus variant letregion pi, zpl in letregion ps,xpZ in letrec \ncount [p] (zP : p handle, x : (int) at p) at zpl = 7, count : % V[p]. (p handle, (int) at p) ~cce66 ~~ \n;; P unit let n = ze(x) in . if0 n then 0 else count [p] (zp, (n -1) at zp) % (2) end in count 1~21 (~2, \n(10) at +J end % letrec end % region pz scope and deallocate end % region pl scope and deallocate The \ncount function is stored in region pl and takes two arguments, a handle for region p and a boxed integer \nx al-located in region p. If x is nonzero, count decrements it, storing the result again in p, and recurses. \nThe function has two effects: a read on pl, resulting from the recursive call, and a read/write effect \non p, resulting from line l s read and line 2 s store. Therefore, we give the function count the effect \n(acce88 (PI), access (pz)}. Operationally, the letregion command serves a purpose similar to a pair of \nnewrgn and freergn declarations. A new region is allocated at the beginning of the letregion block and \nis automatically deallocated at the end of the block, resulting in a stack-like (LIFO) allocation pattern. \nHence, the code above allocates two regions (pl and pz), stores count in pl, stores a boxed integer in \npz, calls count, and then deallocates pl and pa. The translation of this program into the Capability \nCal-culus rewrites it in continuation-passing style, and converts effects information into capability \nrequirements. One of the main tasks of the translation is the compilation of letregion blocks into nevrgn \nand freergn declarations. The resulting program appears below. In the interest of clarity, we have simplified \nthe actual output of the formal translation in a few ways. X%X count in the Capability Calculus let \nnewrgn pr, xP1 in let newrgn pz,xPz in let newrgn ps,xPg in % capability held is {p:,pi,p:} let count \n= (fix count [p:Rgn, p cant :Rgn,c I {p~,p+,p~,fll (E, xP:p handle, x:(int) at p, k:(e) + 0 at peoni) \n. % capability held is E 5 {pr, p+,pznt} let n = zoo(x) in % p ok if0 n then k() % pcont ok else let \nn =n-lin let x = (n ) at xP in % p ok count [p,pcont,c] % pl (xp,x',k) ok > at xpl in let ten = (10) \nat xpz in let cant = C+ (bbbm . % capability held is {pt,p:,pi} let freergn xPl in % pr unique let freergn \nxPZ in i! pz unique let freergn xP3 in % ps unique halt 0 1 at xpg in count [PZ, pa, {pi, pi, ~91 (xpzj \nten, cant) The translated program begins by allocating regions pi and ps, and also allocates a third \nregion ps to hold count s continuation. The count function requires a capability E at least as good as \nthe capability {p~,p+,p~,t} needed to ac- cess itself, its argument, and its continuation; and it passes \non that same capability E to its continuation. The contin-uation requires the capability {p:,p:,p:} in \norder to free the three regions. Hence E is instantiated with the stronger capability needed by the continuation. \nThe power of bounded quantification comes into play when a function is called with several regions, some \nof which may or may not be the same. For example, the above exam-ple could be rewritten to have ten and \ncant share a region, without changing the code of count in any way: %%% count vith ten and cant sharing \nps let newrgn pr,xP1 in let neurgn p2,xPz in % capability held is {p:,pi} let count = . . . as before \n. . . let ten = (10) at xP2 in let cant = 0 (G,P:}) . . .I at xp2 in count IPZ, ~2~ ipi, piI1 (xp2, ten, \ncant) In this example, pcont is instantiated with ,os and E is instantiated with {pt, pt} (which is again \nthe capability required by cant). However, count proceeds exactly as before because c is still as good \nas {pf,p+,pL,t) (since tp:, P:) 5 {PL P, > = MY Pzs, Pz+D In the examples above, even though count is \ntail-recursive, we allocate a new cell each time around the loop and we do not deallocate any of the \ncells until the count is complete. However, since p never contains any live values other than the current \nargument, it is safe to reduce the program s space usage by deallocating the argument s re-gion each \ntime around the loop, as shown below. Note that this optimization is not possible when region lifetimes \nmust be lexically scoped. XVI count with efficient memory usage let newrgn pi,xPl in let newrgn pz, xP2 \nin let newrgn ps,xP3 in % capability held is {p:,p:,p:} let count = (fix count [p:Rgn,pcont:Rgn, c I \n{P; , phd (E @ {p }, xp:p handle, x:(int) at p, M(E) + 0 at peont) . 1 capability held is E C3 {p } let \nn = 7re(x) in % p ok let freergn xP in % p unique % capability held is c if0 n then k() %p cant ok else \n let n' = n -1 in let newrgn p ,xPf in % capability held is E S3 {p } let 2 = (n ) at xPf in % p ok count \n[p , pd, E] (xp ,z , k) % PI ok ) at xpI in let ten = (10) at xp2 in let cant = (A ({PL P:)) * % capability \nheld is {p:,pi} let freergn xP1 in % pl unique let freergn xP3 in % ps unique halt 0 > at xP3 in count \n[pz, ~3, {pi, pill (xP2, ten, cant) In order to deallocate its argument, the revised count re-quires \na unique capability for its argument s region p. Note that if the program were again rewritten so that \nten and cant shared a region (which would lead to a run-time er-ror, since ten is deallocated early), \nthe program would no longer typecheck, since {pi, pi} g {p; ,p$, pi}. However, the program rewritten \nso that count and cant share a re- gion does not fail at run time, and does typecheck, since {P:> PiI \nI {P; , PL PiI. 4 Discussion We believe the general framework of our capability system is quite robust. \nThere are several ways to extend the language and a number of directions for future research. 4.1 Language \nExtensions The primary goal of this work was the development of a low-level, type-safe language that \ngives compilers and pro- grammers control over the allocation and deallocation of data. The language \nthat we have described so far is rel- atively high-level as it includes abstract closures and high- \nlevel operations such as the atomic allocation and initializa- tion of data. In the companion technical \nreport [5], we show that the capability constructs interact benignly with the pro- cess of type-preserving \ncompilation described by Morrisett et al. [24] and we use the techniques described in this paper to modify \ntheir typed assembly language to allow explicit deallocation of data structures. In this paper, we have \nconcentrated on using the Capa-bility Calculus to implement safe deallocation of memory, but with a few \nchanges, we believe our capability appara-tus may be used in a variety of other settings as well. One \npotential application involves reducing the overhead of com- munication across the user-kernel address \nspace boundary in traditional operating systems. Typically, in such systems, when data in user space \nis presented to the kernel, the ker- nel must copy that data to ensure its integrity is preserved. However, \nif a user process hands-off a unique capability for a region to the kernel, the kernel does not have \nto copy that region s data; without the capability, the user can no longer read or modify the contents \nof that region. Capabilities can also be used to ensure mutually exclu-sive access to shared mutable \ndata in a multi-threaded en-vironment, by viewing locks as analogous to regions. If we associate each \npiece of sensitive data with a lock, we can statically check that every client to sensitive data obtains \nthe corresponding lock and its associated capability before accessing that data. When the code releases \nthe lock, we revoke the capability on the data, just as we revoke a capa- bility when we free a region. \nIn general, whenever a system wishes statically to restrict access to some data, and/or to ensure a certain \nsequence of operations are performed, it may consider using capabilities to check that the appropriate \ninvariants are maintained. 4.2 Related Work The Capability Calculus derives its lineage from the work \nof Gifford and Lucassen on type and effect systems [ll, 201 and the subsequent study by many others [16, \n33, 36, 341. The relationship between effects and capabilities is quite close. A necessary prerequisite \nfor the use of either system is type in- ference, performed by a programmer or compiler, and much of \nthe research into effects systems has concentrated on this difficult task. Because of the focus on inference, \neffect sys-tems are usually formulated as a bottom-up synthesis of ef- fects. Our work may viewed as \nproducing verifiable evidence of the correctness of an inference. Hence, while effect sys-tems typically \nwork bottom-up, specifying the effects that might occur, we take a top-down approach, specifying by capabilities \nthe effects that are permitted to occur. The addition of aliasing information to our capabilities also \nseparates them from earlier work on effects systems. However, capabilities only express the simplest \naliasing re-lationships: a region is either completely unaliased or it may alias any other region. Our \ncapabilities reveal very little of the structure of the store. A number of other re-searchers [lo, 7, \n321 have studied static analyses that infer the shapes of data structures and the aliasing relationships \nbetween them. We plan to investigate how to use these finer- grained memory models to increase the flexibility \nof our type system. A connection can also be drawn between capabilities and monadic type systems. Work \nrelating effects to monads [21, 28, 18, 81 has viewed effectful functions as pure func-tions that return \nstate transformers. This might be called an ex post view: the effect takes place after the function s \nexecution. In contrast, we take an ex ante view in which the capability to perform the relevant effect \nmust be satis- fied before the function s execution. Nevertheless, there is considerable similarity between \nthe views; just as the monad laws ensure that the store is single-threaded through a com- putation, our \ntyping rules thread a capability (which sum-marizes aspects of the store) along the execution path of \na program. The experience of Birkedal et al. [4] with the ML Kit re-gion compiler shows that there are \nmany refinements to the basic system that will be necessary to make our Capability Calculus a practical \nintermediate language. In particular, Birkedal found that allocation often occurs in two diierent contexts: \none context in which no live object remains in the region and a second context in which there may be \nlive objects remaining in the region. In order to avoid code du- plication and yet ensure efficient space \nusage, they check at run time to find out which situation has occurred. In the for- mer case, they reset \nthe region (deallocate and reallocate in our formalism) and in the latter case, they do not reset but \ncontinue allocating at the top of the region. The type sys-tem we present here is not powerful enough \nto encode these storage-mode polymorphic operations. In fact, it must be refined in two ways. First, \nthis optimization demands finer-grained aliasing specifications that declare a region p does not alias \nsome particular region p but may alias other re-gions. Second, after we dynamically check which of the \ntwo contexts above we are in, we must refine the type of our capability. Harper and Morrisett s typecase \n[13] mechanism developed for the TIL compiler and further refined by Crary et al. [6] allows the sort \nof type refinement required here. Aiken et al. [l] have also studied how to optimize the initial Tofte-Talpin \nregion framework and they also allow regions to be independently deallocated. Furthermore, their system \nseparates the naming of a region from its allocation. Our language, as presented, does not make such \na distinc-tion, but it is straightforward to add one. With such a mech- anism in place, we conjecture, \nbased on the soundness proof for Aiken et al. s analyses, that those analyses may be used to produce \ntype correct code in the Capability Calculus. Gay and Aiken [9] have developed a safe region imple-mentation \nthat gives programmers control over region al-location and deallocation. They use reference counting \nto ensure safety. Hawblitzel and von Eicken [15] have also used the notion of a region in their language \nPassport to support sharing and revocation between multiple protection domains. Both of these groups \nuse run-time checking to en-sure safety and it would be interesting to investigate hybrid systems that \ncombine features of our static type system with more dynamic systems. 5 Conclusions We have presented \na new strongly typed language that ad-mits operations for explicit allocation and deallocation of data \nstructures. Furthermore, this language is expressive enough to serve as a target for region inference \nand can be compiled to a typed assembly language. We believe that the notion of capabilities that support \nstatically checkable atten-uation, amplification, and revocation is an effective new tool for language \ndesigners. Acknowledgements WI Jean-Yves Girard. Linear logic. Theoretical Computer We would like to \nthank Lam Birkedal, Martin Elsman, Dan Grossman, Chris Hawblitzel, Fred Smith, Stephanie Weirich, Steve \nZdancewic, and the anonymous reviewers for their comments and suggestions. References Alexander Aiken, \nManuel Fghndrich, and Raph Levien. PI Better static memory management: Improving region-based analysis \nof higher-order languages. In A CM SIG- PLAN Conference on Programming Language Design and Implementation, \npages 174-185, La Jolla, Califor-nia, 1995. Brain Bershad, Stefan Savage, Przemyslaw Pardyak, PI Emin \nSirer, Marc Fiuczynski, David Becker, Craig Chambers, and Susan Eggers. Extensibility, safety and performance \nin the SPIN operating system. In Fif-teenth ACM Symposium on Opemting Systems Princi-ples, pages 267-284, \nCopper Mountain, December 1995. [31 Lam Birkedal, Nick Rothwell, Mads Tofte, and David N. Turner. The \nML Kit (version 1). Techni-cal Report 93/14, Department of Computer Science, University of Copenhagen, \n1993. Lam Birkedal, Mads Tofte, and Magnus Vejlstrup. I41 From region inference to von Neumann machines \nvia region representation inference. In Twenty-Third ACM Symposium on Principle8 of Programming Languages, \npages 171-183, St. Petersburg, January 1996. Karl Crary, David Walker, and Greg Morrisett. Typed [51 \nmemory management in a calculus of capabilities. Tech- nical report, Cornell University, 1999. Karl Crary, \nStephanie Weirich, and Greg Mor- PI risett. Intensional polymorphism in type-erasure se-mantics. In ACM \nSIGPLAN International Conference on Functional Programming, pages 301-312, Baltimore, September 1998. \nAlain Deutsch. Interprocedural may-alias analysis for pointers: Beyond k-limiting. In ACM SIGPLAN Con-ference \non Programming Language Design and Imple-mentation, pages 230-241, Orlando, June 1994. I71 Andrzej Filinski. \nControlling Effects. PhD thesis, Carnegie Mellon University, School of Computer Sci-ence, Pittsburgh, \nPennsylvania, May 1996. 181 David Gay and Alex Aiken. Memory management with PI explicit regions. In \nACM SIGPLAN Conference on Pro-gramming Language Design and Implementation, pages 313 -323, Montreal, \nJune 1998. Rakesh Ghiya and Laurie J. Hendren. Is it a tree, a DAG, or a cyclic graph? A shape analysis \nfor heap-directed pointers in C. In Twenty-Third ACM Sympo-sium on Principle8 of Programming Languages, \npages 1-15, St. Petersburg Beach, Florida, January 1996. PO1 D. K. Gifford and J. M. Lucassen. Integrating \nfunc-tional and imperative programming. In ACM Confer-ence on Lisp and Functional Programming, Cambridge, \nMassachusetts, August 1986. WI Science, 50:1-102, 1987. Robert Harper and Greg Morrisett. Compiling poly- \nP31 morphism using intensional type analysis. In Twenty-Second ACM Symposium on Principles of Program-ming \nLanguages, pages 130-141, San Francisco, Jan-uary 1995. Chris Hawblitzel, Chi-Chao Chang, Grzegorz Cza-jkowski, \nDeyu Hu, and Thorsten von Eicken. Imple-menting multiple protection domains in Java. In 1998 USENIX Annual \nTechnical Conference, New Orleans, June 1998. P41 Chris Hawblitzel and Thorsten von Eicken. Shar- P51 \ning and revocation in a safe language. Unpublished manuscript., 1998. Pierre Jouvelot and D. K. Gifford. \nAlgebraic recon- WI struction of types and effects. In Eighteenth ACM Sym-posium on Principle8 of Programming \nLanguages, pages 303-310, January 1991. Dexter Kozen. Efficient code certification. Technical P71 Report \n98-1661, Cornell University, January 1998. PI John Launchbury and Simon L. Peyton Jones. State in Haskell. \nLISP and Symbolic Computation, 8(4):293-341, December 1995. Tim Lindholm and Frank Yellin. The Java Virtual \nMa- WI chine Specification. Addison-Wesley, 1996. John M. Lucassen. Types and Eflects-Towards the In- \nPO1 tegration of Functional and Imperative Programming. PhD thesis, MIT Laboratory for Computer Science, \n1987. Eugenio Moggi. Notions of computation and monads. PI Information and Computation, 93:55-92, 1991. \nWI Greg Morrisett, Matthias Felleisen, and Robert Harper. Abstract models of memory management. In ACM \nConference on Functional Programming and Computer Architecture, pages 66-77, La Jolla, June 1995. Greg \nMorrisett and Robert Harper. Semantics of mem- P31 ory management for polymorphic languages. In A.D. \nGordon and A.M. Pitts, editors, Higher Order Oper-ational Techniques in Semantics, Publications of the \nNewton Institute. Cambridge University Press, 1997. Greg Morrisett, David Walker, Karl Crary, and Neal \nGlew. From System F to Typed Assembly Language. In Twenty-Fifth ACM Symposium on Principles of Pro-gramming \nLanguages, San Diego, January 1998. v41 George Necula. Proof-carrying code. In Twenty-Fourth ACM Symposium \non Principles of Programming Lan-guages, pages 106-119, Paris, 1997. 1251 PI George Necula and Peter \nLee. Safe kernel extensions without run-time checking. In Proceedings of Operat-ing System Design and \nImplementation, pages 229-243, Seattle, October 1996. George Necula and Peter Lee. The design and imple- \nP71 mentation of a certifying compiler. In ACM SIGPLAN Conference on Programming Language Design and \nIm- plementation, pages 333 -344, Montreal, June 1998. Simon L. Peyton Jones and Philip Wadler. Imper- \nP81 ative functional programming. In Twentieth ACM Symposium on Principle3 of Programming Languages, \nCharleston, South Carolina, January 1993. John C. Reynolds. Definitional interpreters for higher- PI \n order programming languages. In Conference Record of the 25th National ACM Conference, pages 717-740, \nBoston, August 1972. John C. Reynolds. Syntactic control of interference. In [301 Fifth ACM Symposium \non Principles of Programming Languages, pages 39-46, Tucson, Arizona, 1978. John C. Reynolds. Syntactic \ncontrol of interference, 1311 part 2. In Sixteenth International Colloquium on Au-tomata, Languages, \nand Programming, July 1989. M. Sagiv, T. Reps, and R. Wilhelm. Solving shape- [321 analysis problems \nin languages with destructive updat- ing. ACM Zbansactions on Programming Languages and Systems, 20(1):1-50, \nJanuary 1996. J.-P. Talpin and P. Jouvelot. Polymorphic type, region, and effect inference. Journal of \nFbactional Progmm-ming, 2(3):245-271, July 1992. [331 Mads Tofte and Lars Birkedal. A region inference \nal- 1341 gorithm. l+ansactions on Progmmming Languages and Systems, November 1998. To appear. Mads Tofte \nand Jean-Pierre Talpin. Implementation of 1351 the typed call-by-value X-calculus using a stack of re- \ngions. In Twenty-First ACM Symposium on Principles of Programming Languages, pages 188-201, Portland, \nOregon, January 1994. Mads Tofte and Jean-Pierre Talpin. Region-based [361 memory management. Information \nand Computation, 132(2):109-176, 1997. Philip Wadler. Linear types can change the world! In [371 M. \nBroy and C. Jones, editors, Programming Concepts and Methods, Sea of Galilee, Israel, April 1990. North \nHolland. IFIP TC 2 Working Conference. Philip Wadler. A taste of linear logic. In Mathemat- [331 ical \nFoundations of Computer Science, volume 711 of LNCS, Gdansk, Poland, August 1993. Springer-Verlag. Robert \nWahbe, Steven Lucco, Thomas Anderson, and Susan Graham. Efficient software-based fault isolation. In \nFourteenth ACM Symposium on Operating Systems Principles, pages 203-216, Asheville, December 1993. 1391 \nAndrew K. Wright and Matthias Felleisen. A syntactic WI approach to type soundness. Information and \nCompu- tation, 115(1):38-94, 1994. W. A. Wulf, R. Levin, and S. P. Harbison. Hy-dra/C.mmp: An Experimental \nComputer System. [411 McGraw-Hill, New York, NY, 1981. A Formal Semantics of the Capability Calculus \n We use the followina notational conventions: Alpha-equivaleit expressions are considered identical. \nMemories, memory regions, memory types, and region types that differ only in the order of their fields \nare considered identical. The expression E[E /X] denotes the capture-avoiding substitution of E for X \nin E. Updates of finite maps M are denoted by M{XeE} or M{X:E}. Juxtaposition of two maps M and MN a,s \nin MN de-notes an update of the first with the elements of the second. The notation M\\X excludes X from \nthe domain of map M. We abbreviate M(v)(e) by M(v.L). We abbreviate M{v I+ M(v){e I+ E}} by M{v.!! C) \nE]. (M,e) t-b P Ife= then P = letx = vine (M, e [v/x]) letx=ipjine (M, e [(i p j)/x]) let x = h at \n(handle(v)) in e (M{v.~ I-) h}, e [v.I?/x]) and v E Dom(M) where !? $ Dom(M(v)) let 2 = Ai (V.e) in \ne (M, e [Vi/X]) and v E Dom(M) and I E Dom(M(v)) where M(y.-!) = (vo,. . . , v,-I) (0 2 i < n) let neurgn \np, x in e (M{vc,{}} [ e v, handle(v)/p,x]) where u # 1M and Y # e I let freergn (handle(v)) in e W\\v, \ne 1 and v E Dam(M) if0 0 then ez else ea (M, ez) if 0 i then e2 else ee (M, ea) and i # 0 v Vl,...,V \n (M,e[cr ,..., cm,u.e,vI ,..., vn/ar ,..., ch,f,xl,..., 34) where v = v.&#38;, . . . , cm] and M(v.~) \n= fix f[A](C,xr:rr,. . . ,snrn).e and Dom(A)=crr,...,cr, Figure 2: Capability Operational Semantics Figure \n3: Capability Static Semantics: Judgements A,_ozK (*(a)=~) Abee:cap ((elc)EA) A I- int : Type A I- r \n: Rgn A I- r handle : Type A I- ri : Type (for 1 5 i 5 n) A I- (71 ,...,r,,)atr:Type A I- r : Rgn A k \nA AA t- ri : Type (for 1 < i 5 n) AA !- C : Cap A I- r : Rgn A I- V[A ].(C, 71,. . . , T,,) + 0 at r \n: Type A I- C : Cap A !- r : Rgn A I- Cl : Cap A I- C s : Cap A I- Y : Rgn A I- 0 : Cap A k {P} : Cap \nAkC~%jCs:Cap A I- c : Cap k Ti (for 1 5 I- {VI : Tl,...,l+ i 5 n) : T,} * I- Ti : Type (for i- {l, : \nTl,...,l, 1 5 i 5 : Tn} n) At_.=. A I- A, A I- AI,o:tc = = A, Az,cw:n AkAa,=A2 A I- A~,E AAll-C,=Ca:Cap \n5 CI = A2,e I c2 A~c~=c~:Ic (except congruence rules) 1 A!-C:K A!-c=c:tc A~c~=c~:K Al-c~=Q:K. AkcC1=c2:~ \nA!-ca=ca:~ Al-c1=cs:n A I- C : Cap Al-0@C=C:Cap A I- CI : Cap A t A~Cl~C2=C2@C1:CaP Ca : Cap A I- C; \n: Cap (for 1 5 Al-(CI~C~)~Cs=C~~(C~~Cs):Cap i < 3) A I- C : Cap Al-c=C@C:Cap Akg=0:Cap AI-r:Rgn Al-(r \n)={r+}:Cap Al-r:Rgn A I- {r+} = {r+} : Cap A I- C : Cap A/-E=c:Cap A I- C1 : Cap A k C2 A~c,@c,=~cBr2:CaP \n: Cap -1 A k CI = C s : Cap A I-Cl I C2 A I- 171 5 C2 A A I- CI I f- C2 C3 5 C3 * k E < - C (cc I C) \nE A) Figure 4: Capability Static Semantics: Type and Context Formation 273 QI;A;l?!-hatr:r A t- A AA \nl- C : Cap AA k r; : Type (for 1 5 i 5 TZ) A I- r : Rgn G; AA ; r{f:rf, x1:71,. . . ,zn:r,,}; C I- e \n xx; V[A ].(C, rl, . . . , rn) + 0 at r Q; A; r k fix f[A ](C, zl:rl, . . . , z,:r,).e at P : rf I..., \nz?a @ oom(r) 4Y;A;J?kvi:r; (forl<i<n) Al-r:Rgn q;A;I khatr:r A t- r = r : Type Q!;A;rt-(v, ,..., vn)atr:(rl \n,..., rn)atr iI!;A;l?l-hatr:r *;A;rt-x:r (r(z)=r) 9;A;I ki:int A I- @I,..., rn) at v : Type (v e Dam(q)) \nA I- V[A ].(C, 71,. . . , TV) -+ 0 at v : Type (v sr Dam(*)) 9;A;rt-v.e:(71,...,r~)atv 9; A; r I- v.e \n: V[A ].(C, 71,. , . , rn) + o at v 9; A; I I- v.e : r @+ * ) = r) Q ; A; I t- handle(v) : v handle \n* ; A; r I- v : V[CY:K, A ].(C, rl,. . . , T,,) --t o at r A~C:IG *; A; I? t- v[c] : (V[A'].(C,. . , \nTV) + at r 71,. O)[C/CX] QTA; r b v : V[c I C\",A ].(C , 71,. . . , TV) + o at r A k C 5 C Q;A;rl-u[C]: \n(V[A ].(C ,r~,...,r~)+~)[~/c]atr 9;A;I kv:r AI-r =r:Type *;A;rkv:T Figure 5: Capability Static Semantics: \nHeap and Word Values s;A;lT;Ctd*A ;l+;C !P;A;l?t-v:: q;A;I t-vr:int q;A;I kvz:int (z # Dam(r)) (Z e \nDom(f9) \\E;A;r;c!-z=w*Aa;r{z:7};C q A; I?; C I- z = w p u2 =P A; J?{z:int}; C 'P;A;rt-v:: handle 9;A;rkhatr:T \nA k C I C @ {r+l cz e Dom~r~~ ~;A;r;C~-==atvjA;r{2:7};C Q;A;l?t-v:(ri3,...,rn-r)atr A ccc @{r+] (zgDom(r)Ao~i<73) \nT! ; A; r; C I- z = xiv + A; l?{z:ri}; C (P @ Dom(A),s 6 oom(r)) Q?;A; r; C k newrgn p, z + A{p:hgn}; \nr{z:p handle}; C 63 {p } Q:A:I !-v:r handle A!-C=Cc @{rl}:Cap q ; A; r; C I- freergn v + A; I?; C !P;A;l- \n;Cl-d+A ;r ;C qA ;r ;c l-e q;A;rt-v:int q;A;l?;Ckez !P;A;r;Ckes Q;A;l?;Ct-letdine \\Ir; A; r; C I- if \n0 v then e2 else es !P;A;l?t-~:V[].(C ,rr,...,r~)-+Oatr 9;A;I kvi:ri (forl<i<n) A I- C 2 C @ {r+} AI-Ccc \nq;A;f l-v:int Al-C=@:Cap Q?; A; I?; C I- v(vr, . . . , v,) !P;A;J?;Ct-halt w Figure 6: Capability Static \nSemantics: Declarations and Expressions * i-C sat *I-Ratu:T t-M:\\k WI .I-C={V~l,...,V~ }:Cap (Vi#Vjforl<i,jInandi#j) \n{VI : Ti,. . . , v, : T,) k C sat !P; .;. k hi at V : 7i (for 1 5 i 5 ?I) *I-{&#38;++_,I,..., e,~~h,}atv:{L1:71,...,L,:7,} \nkM: P *I-Csat Q;.;.;Cke I-Of, e) Figure 7: Capability Static Semantics: Memory    \n\t\t\t", "proc_id": "292540", "abstract": "", "authors": [{"name": "Karl Crary", "author_profile_id": "81100253026", "affiliation": "Carnegie Mellon University", "person_id": "P157139", "email_address": "", "orcid_id": ""}, {"name": "David Walker", "author_profile_id": "81100426485", "affiliation": "Cornell University", "person_id": "PP18001632", "email_address": "", "orcid_id": ""}, {"name": "Greg Morrisett", "author_profile_id": "81339518683", "affiliation": "Cornell University", "person_id": "PP43136279", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/292540.292564", "year": "1999", "article_id": "292564", "conference": "POPL", "title": "Typed memory management in a calculus of capabilities", "url": "http://dl.acm.org/citation.cfm?id=292564"}