{"article_publication_date": "01-01-1999", "fulltext": "\n Representing Layered Monads Andrzej Filinski BRIGS* Department of Computer Science University of Aarhus \nNy Munkegade, DK-8000 Aarhus C, Denmark andrzejQbrics.dk Abstract There has already been considerable \nresearch on construct- ing modular, monad-based specifications of computational effects (state, exceptions, \nnondeterminism, etc.) in program- ming languages. We present a simple framework in this tra- dition, \nbased on a Church-style effect-typing system for an ML-like language. The semantics of this language \nis for- mally defined by a series of monadic translations, each one expanding away a layer of effects. \nSuch a layered specifica- tion is easy to reason about, but its direct implementation (whether by parameterized \ninterpretation or by actual trans- lation) is often prohibitively inefficient. By exploiting deeper semantic \nproperties of monads, how- ever, it is also possible to derive a vastly more efficient im- plementation: \nwe show that each layer of effects can be uni- formly simulated by continuation-passing, and further \nthat multiple such layers can themselves be simulated by a stan- dard semantics for call/cc and mutable \nstate. Thus, even multi-effect programs can be executed in Scheme or SML/NJ at full native speed, generalizing \nan earlier single-effect re- sult. As an example, we show how a simple resumption- based semantics of \nconcurrency allows us to directly simulate a shared-state program across all possible dynamic interleav- \nings of execution threads.  Introduction By now, monads are firmly established as an key concept in \nfunctional programming, both as a semantic framework for ML-like languages [Mog89], and as a structuring \ntechnique for purely functional programs with computational effects [Wad92]. But the situation is less \nclear for the prospect of using monads to structure multiple, potentially intertwined effects: although \na number of frameworks for this have been proposed [MogSO, Ste94, CF94, LHJ95, Esp95], none seem to have \ngained overwhelming acceptance. This is perhaps not surprising, since a truly modular characterization \nof computational effects is probably an ill- *Basic Research in Computer Science (http://www.brics.dk), \nCentre of the Danish National Research Foundation. Permission to make digital or hard copies ofall or \npart of this work for personal or classroom use is granted without fee provided that copies arc not made \nor distrihutcd fbr prolit or commercial advantage and that topics bear this notice and the full citation \non the first page. TO cop) otherwise. to republish, to post on sewers or to redistribute to lists, requires \nprior specific prrmssion and!or a fee. POPL 99 San Antonio Texas USA Copyright ACM 1999 l-581 13-095-3/99/01...$5.00 \nspecified problem, with no unique solution. Nevertheless, most monad-based formalisms tend to leave at \nleast two ar- eas with definite room for improvement: Conceptual overhead. It is usually clear how a \nsin-gle monad in isolation represents a particular notion of computational effect (such as mutable state \nor ex-ceptions), and how individual effect-operations (such as reading and writing of the state, or raising \nand handling of exceptions) are expressed in terms of the monadic structure. But with multiple effects, \nthe initial cost is higher: each notion of effect must now be specified in an integrable form, and the \nspecification of the opera-tions must likewise be further parameterized. In some cases, operations for \none effect are even fundamentally incompatible with the monadic structure of another, significantly complicating \nthe semantics of the result-ing language. Practical overhead. A distinct problem with monad-based executable \nspecifications of interacting effects is computational efficiency. Although explicit, purely functional \ndefinitions of effects make it easier to reason about programs, in practice key monads (such as state) \nare usually implemented imperatively by the compiler [LPJ95]. The efficiency problems are compounded \nfor multi-level effects: in a naive implementation, the cost of each computational step is generally \ndirectly pro-portional to the total number of effects being modeled; and built-in monads are generally \nnot integrable in a multi-effect framework with the same flexibility as user-specified ones. Although \nthe present paper is hardly the final word on either subject, it does present a framework for monadic \nef-fects addressing both problems in a novel way: conceptually, it offers a simple declarative specification \nbased on nested translations, and practically, an efficient imperative imple-mentation in terms of low-level \ncontrol and state primitives. In more detail, each notion of effect is specified inde-pendently by a \nformal monadic translation (state-passing, exception-passing, etc.), which also defines two proto-operations, \nmonadic reflection and reification. These estab-lish a (trivial) bijection between opaque and transparent \nrep-resentations of an effect-computation, allowing us to define the usual effect-operations in terms \nof the transparent rep-resentation, and then write general programs using only the abstract, opaque form. \nThis specification is purely local, and can be written independently for each effect. Secondly, we show \nthat each such monadic translation can be simulated by a continuation-passing translation, which re- \n I?(x) = 7 C(c) = t/z 7-l?,x:rl t E: r2 /e I kEi:(rr-%r2)/n l?l-E2:ri/n rl-x:7/n r I- cp : 7[??/G]/n \nrkXx .E:(ri%r2)/n rl-ElE2:rz/e rkE:Qln I t-Ei:ri/n rkE2:r2/n l?i-E:rl xr2,/n rl-E:rlxr2/n rkVE:r/e r+():l/n \nl?t(E1,E2):r~xr2/n rt-rlE:rl/n rt-2r2E:r2/n rkE:ri/n rl-E:r2/n I l-E:~l+~2/n l?,xl:rl t-E1 : r/e I ,x2:r2 \nI-E2 : r/e l?k inlE:r1+r2/n rt-inrE:ri+rz/n l? t- case(E,xl.El,xz.Ez) : 7/e rtE:r/n rl-E1:rl/e l?,x:rl \nI- E2 :5/e r I- El : 7l / el r,x:rl k E2 : r2 /e2 el + e2 I t vale E : r / e l? l- let? x + El in E2 \n: r2 / e l?~lete* e2x~E1inE2:r2/e2 el 5e e 4 e2 4 L 71 e 5 e Q-2 I 72 71 I 4 72 I 7: (L=a,bJ,O) (0=x,+)ede \nel 5 e2 L<L Tl 4 -i-25 7; G r; Tl 0 72 < 7-i 0 r; r t El : 71 / el l?,x:T1 i- E2 : r2 /e2 el 5 e2 I kE:r/e \n7 5 r e 5 e I? t- lete1~ 2 x + El in E2 : 72 / e2 rtE:r /e Figure 1: Effect-typing and subtyping rules \ntains the original transparent representation of effects, but substitutes a different opaque one. We \nuse this result to show correctness of a direct implementation of the proto-operations in terms of the \ncontrol operators sh$ and reset. As previously shown [Fi194, Fi196], these operators can them- selves \nbe implemented by Scheme-style primitives call/cc and state, but this uses up the call/cc operation of \nthe host language. Here we show how, in addition to defining shift and reset, we can regenerate a call/cc \nthat can be used to implement other effects without interference. Thus, a whole monadic tower can be \nembedded in a language with Scheme-like primitive effects. Accordingly, the paper is structured as follows: \nin Sec- tion 2, we present the translation-based specification of monadic effects. In Section 3, we show \ncorrectness of the continuation-based implementation using logical relations; we also present a concrete \nrealization of the construction in SML/NJ. Section 4 contains a few practical examples, in-cluding a \nsimulation of shared-state concurrency. Finally, Section 5 compares the present results with related \nwork on monad layering and control operators, and Section 6 presents some conclusions and outlines future \nwork. 2 Specifying layered effects In this section, we introduce a simple functional language with a \ntype system for keeping track of effect-behavior of terms, and show how this language can be systematically \nextended by new, programmer-defined effects. 2.1 A multi-effect language For the purpose of the formal \nresults, it will be convenient to work with a syntax in which all computational steps are ex-plicitly \nsequenced. That is, the results of all non-trivial oper-ations must be explicitly named, as in A-normal \nor monadic normal forms [FSDFSS, HD94]. (Ultimately, however, we will still be able to write concrete \nprograms in ML notation, with implicit call-by-value sequencing.) We further refine this language with \na type system for keeping track of effects, very similar to Tolmach s and (to a lesser degree) Wadler \ns intermediate languages for ML [Tol98, Wad98]. However, we will use effect-types prescrip- tively, to \ndefine a new language, rather than descriptively, to analyze an already given one. The raw syntax is \nthus as follows: r::=cu~b~71-e+~2~1~171X72~0~71+72 E ::= x I cq....,rn I Xx . E 1 El Ez I () I VE 1 (El, \nEz) 1x1 E I7r2E I id E I inrE I case(E,xl.El,xa.Ez) I vale E I let x + El in E2 ( letel~ez x ti El in \nE2 e ::= n I p I ..* Here e ranges over a set of effect names, which classify the range of effects of \nan expression: the typing judgment I l- E : r / e states that under typing assumptions l? (mapping variables \nto types), E has type r, and possible effects e. In particular, the effect n (none) means that evaluation \nof E has no effects, and that E therefore behaves as a value for the purpose of equational reasoning. \nAnother distinguished effect is p (partiality), which indicates that evaluation of E may diverge, but \nhas no other effects. The typing rules are displayed in Figure 1. They are pa-rameterized by an effect-layering \nrelation <, with ei < e2 expressing that e2 is layered immediately above ei , in a sense to be made precise \nin the next section. (Typically it means that e2 was defined by a formal translation into a language \nwith ei-effects.) 3 is the reflexive, transitive closure of -&#38; We sometimes use pattern-matching \nbinding syntax in-stead of projections; and in particular, we write X(). E for Xx . E. We also often \nwrite ri % ~2 simply as ri + 72, and rkE:r/nasrt-E:r. A complete program is a closed term of base type. \nFor simplicity, we may also put restrictions on the potentially escaping effects of such programs, in \npreference to compli- cating the top-level semantics. (For example, we may require that a complete program \nhandles all exceptions it may raise, using a catch-all exception wrapper.) The language is also parameterized \nby a signature C as-signing (potentially polymorphic) types to the basic con-stants in the language. \nThese would typically include the standard arithmetic functions, and in particular a family of CBV fixed-point \noperators, fixEl,az : ((cy14a2)_)cy1~$2)-_)(Y1~~2 (P 5 e) (Note that all recursively defined functions \nwill thus have at least the effect of partiality.) Although complete programs will be monomorphic, we \nneed the extra generality of type schemas in order to define monad components as polymor-phic terms in \nSection 2.3. The l&#38;&#38; two lines of Figure 1 add implicit subeffecting and subtyping to the language. \n(But note that the only subtyp-ing relations introduced are changes of effect-annotations.) We can expand \nall occurrences of the general let-construct into the two primitive ones as follows:  leteSe x e El \nin Ez = lete x -+ El in E2 letelse x e El in E2 = e+z 2 (E (lep5e let z e El in vale x) in E2 Similarly, \nwell-typed terms in the system with subsumption can be expanded into the system without, by replacing \nall instances of the last rule by appropriate coercion terms: letede XX= E in vale x <~ (x) a Xa. x 72/e~r~le \n(f(XT;~71(a))) Tl<T; s2<r; (x -(Tl P), x -(7QP)) case(s,x1. inl (x l ;(xl)) x2. inr (xT2 21Tl (x2))) \nAs always with subtyping systems, there is a potential coher-ence problem: the semantics must ensure \nthat different, ways of inserting coercions in a program give the same result. We will see that for our \napplication, this is automatically en-sured (see the note following Theorem 11).  2.2 Layered monads \nand effect-semantics For concreteness, we present a denotational semantics of our language in the setting \nof CPOs (chain-complete poset,s, not necessarily containing least elements) and continuous func-tions. \nThis specific choice is not essential, however. We start with a standard concept: Definition 1 A monad \n7 consists of a triple (T, q,*), where T maps every CPO A to a CPO of A-computations; rl is a family \nof value-inclusion functions VA : A + TA; and * (normally written infix) is a family of binding functions \n*A,B : TA x (A+ TB) +TB; such that for any f : A+TB and g : B + TC, 77a*f =fa, t*v=t, and (t*f)*g=t*(Xa.fa*g) \n(We generally omit the type subscripts on v and * when they are clear from the context.) When f : A + \nB, we also define Tf = Xt.t*(qo f) : TA+TB; and when f : A+TB, f =Xt.t*f :TA+TB. Intuitively, elements \nof TA represent effectful computa-tions yielding values in A. qa represents the trivial (effect-free) \ncomputation of a, while t*f represents the computation consisting of evaluating t to a value a (possibly \nwith some effects), followed by evaluating f a (again possibly with ef-fects). The monad laws ensure \nthat the sequencing of effects is well-behaved. A very simple monad is the identity monad, with IA = \nA, r]A a = a, and t*f = ft. An important non-trivial example is the lifting monad, where the computation-type \nconstructor is domain-theoretic lifting, LA = AJ_; unit is the inclusion, qa = [a]; and binding is strict \nextension, I * f = _L and [a] * f = fa. We now introduce a concept useful for stacking monads: _Defin&#38;ion \n2 A layering of a monad 7 over an_other monad ? -= (T, Q, 4) consists of a function family <A : T(TA) \n+TA, such that each (TA,CA) is a T-algebra [n/rL71, VI.21, i.e., CA 0 ETA = idTA and CA o id&#38;,,) \n= <A o T<,J and such that every f* is a T-algebra morphism, i.e., f*o<A=<BoTf*:T(TA)-+TB The definition \nof layering is 2 bit more technical, but cap-tures the requirement that a T-computation can be mean-ingfully \ninterpreted as a more general 7-Emputation. When T is explicitly constructed in terms of T, we can generally \nobtain a suitable C directly from the shape of T, as shown in Section 2.3. And the additional condition \non f* is usu- ally immediate to verify -informally it expresses that the T-computation represented by \nt * f performs any latent T-effects in t first . Any monad 7 can be layered over_itself by id; A : T(TA) \n+ TA. And, if T is layered over 7 by C, and 7 over 7 by 1, then 7 is also layered over 5 by CA o <TA \no T~TA : T(TA) --t TA. When 7 is layered over 7, we can also define a computation-inclusion or l$t;fting[LHJ95, \nTo1981 function family iA = <A o TV.4 : !?A + TA. This is easily checked to be a monad morphism [MogSO], \ni.e., to satisfy the equa- tions iA(ijAa)=~Aa and i,(t &#38;f)=iAt k(Xa.iB(fa)) Conversely, given a \nmonad morphism i : T -+ T, we can obtain a layering by <A = id; A o i.4. Both formula_tions allow us \nto define a mixed binding operation %A,B : TA x (A-+TB) -+TB by: t zA.13 f = (iA t ) *Ad3 f = [B (t sA,TB \n(h fjTB (f a))) Defining layering in terms of inclusions may seem more nat- ural, but it turns out, that \ntaking C as the primitive notion leads to a more direct implementation of monadic effects in Section \n3. Any monad can be trivially layered over identity by taking [At = t. It can be layered over lifting \nwhen each TA is a pointed CPO (i.e., has a least element _!_TA, allowing C_L = ITA and [[t] = t) and \nf is always strict (that is, if the original computation t has a divergence-effect, then so will t* f). \nConversely, if 7 is layered over lifting, TA is necessarily pointed (because for any t E TA, <I E [[t] \n= t), and f* is strict (because f*(CI) = ((Lf l) = <I), We can now define a semantics of our language. \nThis will be done in the style of Church, i.e., we only give meanings to well-typed terms: Definition \n3 (effect-semantics) A semantics t of an effect-language L assigns first to every base type b, a CPO \nB(b); and to every eflect e, a monad&#38;(e) = (Te, $, ke), such that if e 4 e then E(e) is layered over \n&#38;(e ) by C . This US-signment induces a semantics of general L-type phrases as follows. Let Q be \nan assignment of CPOs to type variables in 6. Then for any type r over G, we define a CPO 13irlp, as \nfollows: &#38;I, = @Q l1bBe = B(b) This also extends straightforwardly to a semantics of type assignments, \nFurther, C must assign to every constant c of L a family of elements C(c)i E L[C(C)~~,,A~. Then we define \nfor every well-typed term r t-3 E : r/e, its meaning C[E], : CII ]lp + TeC[r], (omitting the subscript \nQ on all semantic brackets): L:CxIp = Px L[c,,,...,, IP = W.cM.4M L[Xx .E]lp = Aa 171.L[E]p[x*a] L[El \nEzD P = L[&#38;] P (L[Ez] P) L[vale E] p = qe (LIE] p) L[lete x -c= El in Ezlp = C[ElBp ke (Xa.C[Ez~p[x \nI+ a]) C[letelVe2 ze=,?&#38;inEz]p = ~yt[~~n~*el (xu.~~* (qEz~p[x~u~))) (together with straightforward \nclauses for sums and prod- ucts). Finally, 13 must include a collection of result interpreta-tion functions \n<be: Tef3(b) + PI from meanings of complete programs to observations, where P is some countable set of \nfinal outputs, such as character strings. For a complete pro-gram, I-E : b/e, we can then define In the \nstandard semantics of the language, we take E(n) as the identity monad and E(p) as lifting. (An implementa- \ntion semantics, however, may use a different interpretation: for example, we can give a continuation-based \nsemantics of partiality; the result interpretation function must then be adjusted appropriately.) We \nwill also always use the stan-dard interpretation of fix, (A1-.TeA~)- A1-+TeA~ C(fiXe)Al,A2 = xf .uic, \nfi( Xa. &#38;A,) where TeAz is pointed because e is layered above partiality. We can reason about terms \nin the language by means of a formal equational theory, including in particular the equations (Xz.El) \nEz = El[Ez/z] Xx.Ex = E (ZBFV(E)) val E = E  letelde2 z -+ vale El in Ez = Ez[El/x] lete x e E in vale \nx = E  letezse3 x2 + (letelde2 $1 -&#38;El in Ez) in Es = letelse x1 X= El in lete25e3 x2 -c= E2 in \nE3 (~l~FV(&#38;)) (together with the usual ones for products and sums). Note that the strong &#38;-rules \nfor functions are only valid because we restrict the terms in an application to have no effects. 2.3 \nAdding a new effect Of course, we can always enrich the language by adding a new effect at the level \nof the semantics. But a wide variety of effects can also be defined purely syntactically: Definition \n4 A formal monad T over effect Z in L consists of a type constructor and three polymorphic terms, T-: \nType -+ Type glue, : (1% TLY) -+ Tcu unit, : a-+ Ta! bind,, ,o12 : Toll x (al + TCQ) + Tcx2 Such a T \ndenotes an (actual) monad C[Tn = (T,Q,*,<) layered over &#38;(I?) in a semantics C of L if C[Tc$,,A] \n= TA, C[gk-&#38; ++A] 0 = xt.CA(t()), L[IJfJit&#38;++A]0 = VA, and LBbih, ,azl[al ++ A1 ,a2 H AZ]0 = \n(*A, ,A*). Note that we do not require that T denote a monad for all interpretations of the effect E. \nFor example, the formal list monad (used to give a semantics of nondeterminism in Section 4.2) can only \nbe properly layered over a commutative monad [KW93], such as partiality. The component glue can usually \nbe constructed system-atically from just the form of T, as follows: Tcu 1 glue: : (1% TLY) + TCY F Q \n4 Gcu At. Au. let f + t () in f a Fa % T a At. Xu.g/ue,f (A(). let f + t () in val f a) Tlcu x Tza At. \n(glue? (A(). let p + t () in val' ~1 p), g/ue, z (A(). let p * t () in val ~2 p)) (In fact, in most \ncases, the first rule alone suffices.) It is easy to check that such a glueT satisfies the T-algebra \ncon-ditions of Definition 2; and the verification of the additional property of bind is usually straightforward. \nGiven T we construct an extension LT of L, with a new effect t and new proto-operations, monadic reflection \nand reification [Fi194]: reflect: : Tcu &#38; cr reify: : (1 % CY) -+ Ta When E : Tr/n, we often write \np (E) : r/t for reflect) E; and conversely, when E : r/t, [El : Tr/n for reify (A(). E). Informally, \nevaluating p(E) performs the action represented by the datum E, while [El returns a datum representing \nthe action that would result from evaluating E. Note that LT is a proper extension of L: any L-program \nis still a valid LT program with the same meaning. This means that we can define the semantics of LT \nby a formal monadic translation 1-1~ back into L, expanding out only the new type and term constructors \ninto their L-definitions. First, the translation of an effect e is an effect-type con-structor lel T: \nltlcv = TcL/n le[Q = cr/e (e # t) For types, only function spaces have a non-trivial trans-lation: 171 \n% 721 = 1~11 4 ri where rile = lellr~l And finally, we define a translation 1-1~ of terms: if l? t E \n: ~/e then [FIT !- \\E[T : lelTjT1T. Again, the only non-trivial clauses are: Ival El = unitl,l IEJ  \nIlet 2 * El in Ezl = bindl,,l,lrzl(IEI~,Ad . 1321) Ilet x-+El inEzl = g/uel,l (A().let z += IElI in \nvale IEzl) /reflectSI = Xtq7 .t [reify:1 = XPq .t() This syntactic translation agrees with the denotational \nsemantics: Lemma 5 13[l-I~] = ,Cr[-] luhere C7 is the semantics of LJ determined by extending C with \nE(t) = 7 = fZCITlm, C(reflect)A = XtTA. t, and C(reify)A = kl+TA. t (). For example, given some base \ntype exn of exception names, the formal monad Ex of exceptions is defined by: TCY= 1% (a + exrr) gluea \n= XtlSTa. A(). let r -+ t () in T()  unit, = Xa . A(). id a ~ VX(~l-+ ~~(). bind ollP2 - X(k f) let \nr + t () in case (T,a.fa (), x.vaP inr x) This does in fact denote a monad for any monadic interpreta-tion \nof E. Calling the new effect 9, we can define operations in LJ with types raise, : exn % cy handle, \n: (1% cy) -_) (exn 14 (.y)14 cz in terms of the proto-operations: raisea = XxeX .pu (X().valBinrz) handle, \n= Xt S .Ah ~ .let ~ ~ T* [t()I () in case (r, a.vaP a, x.hx) That is, raise constructs an exception-computation \nthat im-mediately returns with a right-tagged x, and reflects that as an Q-effect. Conversely handle \nreifies t into a &#38;computation of a sum-typed value, performs that computation, and ei-ther returns \nthe result or passes the exception name to the handler h. It is easy to check that the semantics of these \nop-erations capture the usual behavior ,of ML-style exceptions, even in the presence of state as an Z-effect. \nNote that we can often reason about LJ-programs directly, without either expanding them into L-programs, \nor comput-ing their denotational meanings. In particular, we have the following sound equations for well-typed \nterms: p(CEl) = E C,u(E)I = E [val*El = unit E [let x -c=El in Ezl = bind (CEil, AZ. [Ed) [let?< x X=El \nin E23 = glue (A(). le&#38; x + El in val [Ez]) (e<a<t) From these, and the equations at the end of Section \n2.2, it is easy to derive laws about the particular operations, such as  let r X=raisex in E = raisex \nhand/e(X().val a)h = val l a hand/e(X(). raisex) h = hx 2.4 Effect-ordering and monadic reflection \nThe hierarchical organization among the effects is crucial to the translation-based definition. Although \nbeing able to in-tegrate effects flatly (i.e., with no mutual ordering) might seem a desirable goal, \noften different orderings correspond to different intended semantics, as illustrated below. An important \nconsequence of the layering is that some source terms are meaningless, even if their effect-erasures \nare simply-typable. Specifically, attempting to apply the reifi-cation operator of a lower-level effect \nto a higher-level com-putation has no counterpart in a program written with ex-plicit effect-passing, \nand thus cannot be given a well-defined meaning by the translation. Where appropriate, the desired meaning \nof such a construct must instead be expressed ex-plicitly. As a simple example, let us analyze this issue \nin the context of mutable state and exceptions. We saw the definitions of raise and handle in Section \n2.3. Similarly, using the formal state monad St, with type con-structor STCY = state % (a x state) \nfor some base type state, we can define a new effect st, with operations get : 1 *state set : state \nrl, 1 withst, : state x (1% CY)-% (Y as follows:  get = X().,J (Xs.val (s,s)) set = Xn.$ (Xs.val ((),n)) \nwithst, = X(s, t). let (a, s ) G [t ()l s in val a But how do these operations interact with those for \nexcep-tions? First, consider the ML-like layering of exceptions above state above partiality, p -Xst \n4 er, with the state persistent across exceptions. The composite translation, defining away first exceptions \nand then state, corresponds to the following effect type: Ila/qlEXlS~ = 11%a+ eXnlST = 1 + state % (a \n+ exn) x state  That is, when started in some initial state from state, a computation may diverge; or \nit may result in a new state together with either an o-value or raised exception from exn. The proto-operators \nhave types: reify:* : (1% cr) + state 4 a! x state reflect:* : (state 4 cr x state) *a reify: : (1% \n(Y)+ 11 (c~+ exn) reflect: : (1 % (cy+ em)) % (Y In this setting, we can always coerce a st-computation \ninto an er-computation (and with the subtyping system, this CO-ercion can be left implicit). This means \nthat the previous definition of handle, based on g-reification, works without changes even when the expression \nbeing guarded has only state-effects (which includes partiality-effects). But if we want to extend withst \nto computations which may raise exceptions, we must explicitly account for those. For example, we can \ndefine a more general operation where the state threading is made explicit before er-reification. withst \n, : state x (1% o) 14 (Y withst a = X(s,t).leter (T,s ) X= [Ct()leF ()15 9 in per(X().valsf r) Here \nwe first explicitly e,r-reify the original computation of cr into a &#38;computation of a! + exn, perform \nthe original withst-operation, and finally ey-reflect back the result, which may have the effect of raising \nan exception. Note that when withst , is applied to a computation that provably does not have exception-effects, \nits behavior also provably coincides with the original withst. That is, we can show  withst (s, X().let? \nz + E in vales z) = letP5 z es: withst (s, A(). E) in valer x  using the equations from the end of \nSection 2.3. In a gen- eral optimizer for higher-order programs, however, it seems preferable to maintain \nexplicit effect-types everywhere, as advocated by Tolmach [TolSb]. Note also that the behavior of withst \ndiffers from that of a more naive definition, withst , = X(s, t). let? ~ ~ 0 X= get () in letst~rg () \n-+ sets in let r X= t () in let ~ r () * set0 in valCF r Here, an unhandled exception raised in t () \ndoes modify the global state, which makes an observable difference if the ex- ception is eventually handled \nsomewhere. Yet both versions behave the same on programs that never actually raise exceptions. Thus, \nit is not sufficient to merely require that programs in the original language (partiality and state) \nshould retain their meaning in the extended lan-guage (partiality, state, and exceptions); the interactions \nof effects need to be considered explicitly in each case. On the other hand, suppose we want a transactional \nse-mantics with transient state layered atop exceptions, corre-sponding to effect-type ]]o/st]Sr]sx = \n]stdte % o x StdtelEX = state -+ 1 -Q (o x state) + exn  Here the type already shows that the state \nmust be discarded if a computation aborts with an exception. When p 4 q 4 st, the monad reflection operators \nhave types reify:*: (1 % cr) + state 14 Q x state reflect: : (state Zr, Q x state) % (Y reify: : (1 ZE, \nC-Y) + 14 (CY+ exn) reflect: : (1 4 (cr + exe)) 14 o Thus, s&#38;reification of any computation is well-defined, \nbut we need to explicitly define the meaning of er-reifying a com- putation which may have state effects, \nas when handling ex-ceptions. In this case, a natural revised definition of handle is handle , = AtlnA* \n.Xhe S f. $*(Xs. let r T e Cl3()I\"' de6 () in case(r, (a, s ).valCr (a, s ), z.Chxl s)) It is worth \nreiterating that these considerations typically only arise when we want to assign well-defined meanings \nto al2 terms in a language without an effect-typing system, but with effect-delimiting operations such \nas hand/e or withst. If we are only using reflection and reification as a more concise notation for programs \nwritten with explicit effect-passing, such conflicts have by definition already been resolved in the \noriginal program.  3 Implementing layered effects The previous section describes a framework for adding \nprogrammer-defined effects to an ML-like language. How-ever, a direct implementation of this semantics \nwould be problematic for several reasons: In the context of a full programming language, it re-quires \nus to effectively write a full language processor, including parser, type checker, module system, stan-dard \nlibrary, etc.; or, at the very least, perform major surgery on an existing implementation. Each level \nof translation imposes a potentially substan-tial execution-time overhead -especially for programs which \nonly rarely use any particular effect, but must still provide the infrastructure for connecting such \nscat- tered uses. Perhaps most significantly, the semantics is given by in- duction on explicitly sequenced, \nfully effect-annotated terms. Although this verbosity is essentially equiva-lent to writing a program \nin explicit monadic style, it imposes an uncomfortably heavy burden on the pro-grammer accustomed to \nML s anonymous (and, given a guarantee of left-to-right call-by-value evaluation, of-ten completely implicit) \nsequencing of computations. In this section we show how all of these problems can be solved. In doing \nso, we demonstrate that the monad equa-tions and the layering conditions are not merely arbitrary category-theoretic \noverhead, or a mere convenience for man- ual or automated reasoning about programs, but are in fact the \nkey to a vastly more efficient implementation of the spec- ification. The result falls in two parts: \n(1) that each individ-ual monadic translation can be uniformly simulated by a layer of continuation-passing, \nand (2) that any tower of continuation-passing layers can be simulated by a single no- tion of effect \ncomprising Scheme-style first-class continua-tions and mutable state. We phrase these simulations in \nterms of realizations of one language in another, where a realization of an effect-language L > L replaces \n(not necessarily injectively) every new effect of L with an effect of L, and every new constant of L \nby a term of L, such that the meanings of complete L/-programs are preserved. 3.1 Relating monadic effects \nto continuation-passing It is a fairly simple observation that continuation-passing can simulate monadic \nstyle [PW93], but actually showing that the translations are equivalent is surprisingly complicated. \nThis was sketched in [Fi194] for a single effect in an other- wise completely pure language; unfortunately \nthe retraction- based approach [MW85] used there does not seem to gen- eralize well to more general settings, \nsuch as unrestricted recursion. In [Fi196], the proof was redone with admissible relations in the style \nof [Rey74], and extended to a base lan- guage with arbitrary pre-existing effects; and that approach \ndoes generalize to the multi-effect language of the previous section, as sketched in the following. One \nmajor complication is that to obtain a proper simu- lation, we must pick the answer type for the CPS \ntransform large enough . In particular, this means that we cannot use a simple base type, but will need \na recursively defined type of answers in the implementation language L, (the specifi- cation language \nL C L, remains simply typed). Let E be some effect of L, &#38; (gothic k ) a new effect name, and w some \nfixed t pe with effects from L extended with l?. We then define L KYas L extended with E 4 e, and two \nnew constants shift and reset, with types shift, : ((a 4 w) 4 w) % a reset : (14 w) 4 w We write S,k. \nE ins syntactic sugar for shift, (Xk. E), and #E for reset (A(). E). (Conversely, we have shift, = Ah. \nS,k. hk and reset = Xt. #(t ()).) Informally, Sk. E evaluates E with k bound to a functional representation \nof the current evaluation context, but with E itself evaluated in an empty context. Conversely, #E evaluates \nE in an empty evaluation context, and returns the result to the current context. For example, writing \nout all the sequencing explicitly, letE r e #(let n + (Sk. let x + k3 in kz) in vale 2 x n) in val 1 \n+ T = vale 1 + 2 x (2 x 3) = val 13  Much like for general effects, we give the formal semantics of \nLK by a continuation-passing translation into L,. For any type x, we define first a parameterized translation \nof the effect e as an effect-type constructor: I%(,)~ = ((a q x) 4 x)/n Let G = /.Lx. IwI~(~), with isomorphisms \n$ : IwIK(S) -)G and 11,: &#38;I+ IwIK(~) (Note that if w does not contain any &#38;effects, so that \nIwIK(~) does not actually depend on x, we can simply take G = w and the isomorphisms as identities.) \nWe can then define the formal monad K of &#38;continuations by TOcY=Ka! = (,%i)%G g/uee t = Xk. let T \n+ t () in r k unitea = Xk.ka binde (t, f) = Xk. t (xa. fa k) It is easy to check that this determines \nan actual monad K: = C[Kl for any interpretation of I?. We use the formal monad to define the syntactic \ntrans-lation l-11<, extended with the clauses for the specialized control operators: (I&#38;+Jl)+(lWp+s)50~ \nxk l . (shift,1 = Ah h(X~ .letPa~kIcinval ~a) (Xr . vale C$ r) l-t(lwlls)%,o  lresetl= At let a + t \n() (Ad .val 4 r) in val II, a (We could also have these operators explicitly in terms of pe(-), C-l \n, r$ and +; the result of the translation would be the same.) Note that shift and reset are the only \noperations that ac-tually depend on the choice of G as the answer type. As usual for a continuation-passing \ntranslation, everything else is parametric in the answer type. Further, let d be a sufficiently large \ntype to embed any LT-type at which we want to reify. (For any particular program, this can always be \nchosen as a finite sum; and if we only need to reify at outermost level, e.g., for state, it can even \nbe a base type.) More precisely, let N be a (finite or infinite) set of types, with functions in,:r%d \nand out,:d&#38;r for every T in N, such that outr (in, a) = valp a for any T- value a. For the actual \nsimulation, we now take w = Td, allowing us to define a realization (P: of LT in LK by cP(t) = e, and \n @(reflect:) E XtT .SakD15rd.vale bhd,,d(t, Xaa.g/ue,j(X().ka))  O( reify:) G Xt I. .g/ueol (A(). let \nr (2 #(let a + t() in vale un/td(in,a)) in val bindd,, (r, Add. letP z -4= out0 d in unit, x)) We want \nto show that for every LT-program I- E : b/p, the two translations give the same result. More precisely, \nwe will show that given a specification semantics C, and implemen- tation semantics Ci of L, such that \nfor complete L-programs, E, E,[E] = Ei[E], then also &#38;[lEl~] = fZi~lE{@~}IK] for complete LT-programs \nE. But we cannot show this state-ment (or any simple variation of it) directly by induction on E: the \nproblem is that at higher types, there is no di-rect equational characterization of the relationship \nbetween lEl~ and IEIK. Instead, we use a more general relational invariant, that will give us the original \nequation as a special case. We say that a relation R C A x A between two CPOs A and A is admissible if \nit ?s chain-complete, i.e., if the least upper bounds of pointwise R-related chains are also R-related. \nWe write ARel(A, A ) for the set of all admissible relations between A and A . Definition 6 A logical \nrelation R between C, and Li of an effect-language L assigns to every base type b a relation B (b) E \nARel(B,(b), Bi(b)) between their interpretations; and to every eaect e, a relational action E (e), mapping \nany re- lation R E ARel(A, A ) to &#38; (e)R E ARel(T, A,TFA). Let Q and e map type variables from Lu \nto CPOs, and for each a let 19cu E ARel(ecu, e cr). For any type T ower cl?, we then define a relation \nR[T]~ E ARel(&#38;[T]1,, /!Zi[Tlp ) by: R[cr]s = ea Rl[b], = B (b) R[TI x ~21~ = {((m,a2), (a:,&#38;)) \nI  (al,ai) E R[TI], A (a2,ab) E 7+2B0) RBn + ~21~ = {((ha), CL&#38;)) I (al,&#38;) E R[n]e) U (((2, \na2), Rak)) I (a2,4) E W2B8) R[n + ~21~ = {(f, f ) I J(a, a ) E MnBe. (f a, f 4 E ~ (eD%d9)1  It is easy \nto check that these relations are all admissible. Moreover, the relations must respect interpretations \nof ef- fects and constants: for every e of L we require that, 1. if ;r;;Rand (t, t ) E E (a)(&#38; (e)R) \nthen (<:A t, <:A t ) 2. If (a, a ) E R then ($A a, $A! a ) E P(e)R. 3. If (t, t ) E &#38; (e)Rl and \nfor evenJ (~,a ) E RI, (fa, f u ) E &#38; (e)Rz then (t$ f,t *; f ) E E (e)Rz.  And for c : \\d&#38; \nr in CL, and any relation-environment 0 with Bai E ARel(Ai, A:) for each CG, (Cs(c)xj G(C),) E R[T], \n Finally, we require that related meanings of complete pro- grams are interpreted as the same observation, \ni.e., if (p,p ) E Er(e)Br(b) then &#38;g p = tit p . For our purposes it suffices to take the relation \nat base types to be simple equality, i.e., B (b) = {(n, 4 I n E WI) When Ci also interprets p as the \nlifting monad, we can define the relational action of p by: &#38; (p)R = ((4 1)) U {([a], @I) I ha ) \nE RI (Note that then &#38; (p)B (b) becomes simply the equality rela- tion on B(b)l.) In other cases, \nwe must explicitly construct a suitable action, as in the proof of Theorem 11 later. We can now state \nthe usual logical-relations lemma, straightforwardly extended to effects and polymorphic terms: Lemma \n7 (Logical relations lemma) Let there be given a logical relation between Cc, and Ci. Let G! be a list \nof type variables, Q and Q type environments, and 0 a relation envi- ronment, such that for each cy, \necu E ARel@, e (r). Let I be a type assignment over cu , and let p and p be environments such that for \nevery x E dome?, pa: E .Cs[$, p a: E &#38;[r],l, and (pz,p z) E R[l?(~)]s. Then for every well-typed \nterm I? k-3 E : r/e, Proof. Straightforward induction on E. . Note that the standard interpretations \nof fix are always re- lated. This is easily seen by fixed-point induction, using the fact that R[T~ 4 \n~21~ is admissible and contains (I, I) when p 5 e (follows from Definition 6(1-3)). Much as we previously \ninterpreted a type construc-tor as a CPO constructor, we can define for any type constructor T its relational \naction, T : ARel(A,A ) + ARel(&#38;[T&#38;++A], Li[Ta][attA]) b T R = RlT~l[,,q. Suppose now we have \na logical relation between semantics L, and Li of language L, and we want to extend it to LT, where we \ntake E,(t) = 7 and Ei(t) = K: in the extended semantics. We then need to define E (t). Intuitively, we \nare representing a T-computation t by the K-computation u = Xk. k t. So we want something like (t, U) \nE &#38; (t)R _ (Xk. t * k, u) E K R where K is the natural choice: two K-computations u and u are related \nby K R if for all continuations k and k map-ping R-related values to T O-related results, vk is T O-related \nto u k , for some suitable relation 0 on u. But how to pick O? A suitable answer is to take 0 as the \nintersec-tion (always admissible) of all the relational interpretations we will actually need. Formally: \nLemma 8 The relational action E (t) oft defined by &#38; (t)R = {(t,u) E TA x KA 1 VT E N.VO E ARel(C,I[TB, \nLi[dl). Vk : A + Cc,[TT], k : A + Ci[Td]. ( +,a ) E R. (ku,C($(k u ))) E T O) * (t * k, C (II,(uk ))) \nE T O) extends the logical relation between semantics Ls and ti of L to one between 136 and L o +f;e \nof LT. Proof. Relatively direct verification for both the new ef-fect t and the new constants reflect \nand reify [Fi196]. For the latter two, we use the fact that (by Lemma 7) the inter- pretations of the \nterm components of T are related, even if T does not actually define a monad in Li. W Theorem 9 (T-K \nsimulation) Let Cs and Ci be related semantics of L, and let E be a complete LT-program, i.e., I-E : \nb / p. Then ,&#38;[lEl~] = .&#38;l[lE{@y}IK]. Proof. By Lemmas 7 and 8, (Cs[lEITIO,CialE{~:P,,K]S) E \n&#38; (p)B (b), from which the result follows by the assumption on&#38; andci. H 3.2 Relating continuation-passing \nto primitive ef-fects Let us now consider an implementation language essentially like Scheme or SML/NJ, \ni.e., containing first-class continu-ations and state as primitive effects. To keep things simple, we \nconsider all state to be allocated before program execu-tion proper begins. That is, for a state-assignment \nA mapping ref-cell names v to types, the language L,, contains the basic syntax from Section 2 (products, \nsums, functions), a single effect E, and constants escape, : ((a % 0) % 0) % a get : 1% A(v) set : A(v) \n% 1 escape is a simple variation on cull/cc, interdefinable with both Scheme s and SML/NJ s operators. \nWe usually write !v for get 0 and v := E for setl) E. The formal semantics of this language is also Scheme-like \n[KCR98]: we interpret cs as the continuation-state monad, Tc9A = A+Sa+P I 7i4u = XK.XU.K,UU t*-f = X&#38;Xa.t(Xu.Xa \n. fUK(T )(T where Sa = nvEdoma C[A(v)l. (Note that, since the types in A may themselves contain m-annotations, \n5 ~ is a recur- sively defined CPO. We elide the associated isomorphisms for conciseness.) Then the interpretations \nof the operations are given by Theorem 10 (K-CS simulation) Let E be a complete programof GA, FE:b/G. \nThen C(escape)A = Xf.k.b. f (XUA.X~ .X~ .~a~ )(Xzo.VZ)cr &#38;, ]lEl~] = J%,, [E{@ %}]C(get ) = X().Xlc.Xcr.~.(uv)u \nC(set ) = Aa. XIG X0. K () (o[v ti a]) whereA =(A,v:w%O) forv$domA. We also define Ef t = t (Xa. Au . \n[printb a]) (TO, where the ini-tial store (TO is some fixed element of SA. We add a new effect e over \ncs and shift/reset to this lan-guage as described in Section 3.1, to obtain L&#38;. Much as before, we \nnow view the continuation-passing transform as the specification of the new language, and define a different \nimplementation. To see how to obtain such an implementation, consider the interpretation of a e-effect: \nThat is, the composite semantics is also a continuation-state semantics, only with a larger state. This \nsuggests that we can implement L&#38; by a simple embedding into LcsA,, where A extends A with a new \ncell to hold the metacontinuation [DF90, Fi196] of the original computation. Formally, we define the \nrealization @>$ by a(e) = +(cs) = cs (thus conflating two previously distinct layers of effects), and \n@(reset) = At ,escape, (XIC ~~~. letc4 m -4= !v in (v := (Xa .v := m; ka); letc4 T -4= t () in letC \n772 -k !v in mr)) @(shift,) = Xh  *escape, (Xk O_ letC* r -+ h(Av .@(reset)(A().letC8 z+kv in Vz)) \nin letCS m + !v in mr) @(escape,) = Xh(~C~OF~o~escape, (Ak O. let m e !v in (v := err; h(Xa . (v := \nm; ka)))) where (El; Ez) G letcs () X= El in Es, w is a new cell with A (w) = w % 0, and err : w % 0 \nis an error continuation that will never actually be invoked in an effect-type-correct program. The realization \nensures that the newly exported escap: respects the meta-continuation used by shift and reset. But the \nmore significant aspect of the construction is that it eliminates an entire layer of effects (technically, \nit con-flates two layers of state-passing into a single layer with a larger state), making &#38; vs. \ncs-annotation on vals and lets unnecessary. Formally, we have the following result: lThis redefinition \ncan also be seen as a more principled justi-fication for the practice of redefining the call/cc made \navailable to the programmer in order to accommodate an implementation of dynamic-wind in Scheme [Ree92, \nKCR98], and for the implicit adaptation of the callcc/throw primitives in SML/NJ to also save and restore \nexception handlers [BCL+98]. Proof. (Sketched.) The proof is based on a logical relation between semantics \nL, ,, and L,,h o 9 of LEp. For this, we define the relational actions of two effects in the source language, \n&#38; (e)R = {(t,t ) I V&#38;K . (V(a,a ) E R.ka x da ) *tkXt /C } E (c5)R = {(t, t ) I Vk, IC . (V(a,a \n) E R. ka x ~ a ) =S X/c.t(Xa.kaK) x t d} using auxiliary relations on intermediate answers, (x) E ARel((C]w] \n4 SA + PI) + SA + PI, Sal + PI): uxv u vlE,u,u .(IE,u)Qu *uIEu=vu on metacontinuation-state pairs, (4) \nE ARel((L]w] + SA -_) PI) x SA,~A~): (/c,U)QU' e (a,(~') E R]A] A V(r,r ) E R]w],(ur,u;) E R[A],~.nru; \n= u v~ ~~u; and on state, R[A] E ARef(SA, SA, ,): R[A] = {(a, u ) 1Vu E A. (uw, u v) E R[A(v)],} Note \nthat these relations are mutually recursively defined. Thus, their existence is not automatic, but can \nbe estab-lished fairly easily using Pitts s techniques [Pit96, FilSG]. We can then check directly that \nthe interpretations of all con-stants in the two semantics are related by the corresponding relations, \nso the result follows by Lemma 7. . Putting all the pieces together, we finally obtain our main result: \n Theorem 11 (T*-CS simulation) For formal any monad T, define the composite realization of LT in L,, \nby Cc4= 92tqTdO@+T Let LO be the basic language with no PT effects other than n and p, with the standard \nsemantics LO, and let ipprcs be the realization a(p) = ~5. Let Tl,. . . T, denote a sequence of monads, \neach layered over the previous one (and T1 over p). Then there exists a store-typing A, such that for \nany complete L2*...ST -program F E : b/p, *..lT,] =~,,~E{~p c }{~~~}~~~{~,:~}~ ~dl~-IEl~, Proof. For \nthe base case, we need to relate the standard lifting semantics of p to the continuation-based one: when \nR E Rel(A, A ), we take E (p)R = {(t, t ) E Al X ((A 3 SA -+ PI) -_) SA -+ PI) 1 VIE, h , uo. (V(a, a \n) E R, u. rca = K O U) *t*PIE=t duo} The general theorem then follows by induction on n, using Lemma \n5 and Theorems 9 and 10 in each step. H Writing 0 for the composite realization, we also note that for \nall effects er 5 ez, L,,[(lete1~e2 z -+=El in E2){9}] = C,, [letCD x X= El { @} in E2{+}], and thus for \nall coercions C,,[x(E){@}j = C,,[EJ. That is, the effect-annotations do not actually matter for the purpose \nof program evaluation, and in particular, we can write our source programs in ML s implicit-sequencing \nsyntax, with the standard elaboration into single-effect monadic normal forms. abstyp void= VOID of \nvoid with fun coerce (VOID v) = coerce v endi signature ESCAPE = sig val escape : (('a -> void) -> void) \n-> 'a end; structure Escape0: ESCAPE= stnlct fun escape h = SMLofNJ.Cont.callcc(in k => coerce (h (fn \nx => SMLofNJ.Cont.throw k x))) end; signature CTRL= sig type ans val shift : (('a -> ans) -> am) \n-> 'a val reset include RSIAjnit -> ans) -> am  d; functor RepCPS (type am structure E : ESCAPE): \nCTRL where type ans = am =  stlnct type am = am fun initmk a = raise Fail \"Unexpected control effect\" \nval mk = ref (initmk : ans -> void) fun abort v = !mk v fun reset t = E.escape (fn k => letvalm= !mk \nin n&#38; := (fn a => (mk := m; k a)); abort (t 0) end) fun shift h = E.escape (in k => abort (h (fn \nv => reset (in 0 => coerce (k v))))) fun escape h = E.escape (fn k => let valm= !mk in mk := initmk; \nh (in a => (mk := m; k a)) end) end; Figure 2: Representing continuation-passing with escapes and state \n3.3 Representation in SML/NJ As suggested by the development, the construction applies directly to a \nlanguage with first-class continuations and state, such as Scheme or SML/NJ. We show it here for the \nlatter (in SML 97 syntax), using parameterized modules to represent syntactic realizations. Figure 2 \nis a straightforward encoding of the control-operator construction from Section 3.2. Figure 3 shows a \nsimple implementation of the universal type required for the answer-embedding in Lemma 8; an alternative \nimplementa-tion in terms of SML s extensible datatype exn of exception names is also possible. Finally, \nFigure 4 shows the imple- mentation of monadic proto-operations using control opera-tors from Section \n3.1. (The monad component show and the signature DYNAMIC = sig exception Dynamic type dyn val newdyn \n: unit -> ('a -> dyn) * (dyn -> 'a) end; structure Dynamic :> DYNAMIC = struct exception Dynamic datatype \ndyn = DYN of unit -> unit fun newdyn 0 = let val r = ref NONE in (fn a => DYN (fn 0 => r := SOME a), \nfn (DYN d) => (r := NONE; d 0; case !r of SOME a => a I NONE => raise Dynamic)) end d: Figure 3: A universal \ntype, with a state-based implementa-tion  4 Examples and applications In this section, we show two examples \nof programming with effects in direct style. The first simply explores further the ordering of exceptions \nand state. The second, more sub-stantial, shows how we to use layered monads to simulate nondeterministic \nbehavior in a shared-state concurrent pro-gram. 4.1 Exceptions and state Using the definitions of the \nexception and state monads from Figure 5, we can represent a language with exceptions lay-ered over state, \nas familiar from ML: structure E = EffO; structure E = Represent (stmcture M =I Exceptions structure \nE = E); structure Rex = E structure ExcOps = R Rex); ExceptionOps(stracture=  structure E = Represent \n(structure M = State StNCtWX E = E) StNCtl,,X Rst = E structure StateOps= R Rst); StateOps(strnctnre= \n valtl= E.run (fn 0 => (StateOps.set 3; \"ok\")); (* val tf = \"Wt. 3>ok\" * string *) val t2 = E.run &#38;n \n0 =>' (StateOps.set4; ExcOps.fraise \"err\"; \"ok\")); (* val t2 = \"<St: 4Xexn: err>\" : string *) val t3 \n= E.run(fn 0 => (StateOps.set 5; ExcOps.fhandle  (fn 0 => (StateOps.set 8; ExcOps.fraise \"err\"; \"ok\")) \n(fn x => x ^ 'I, ^ Int.toString (StateOps.get 0)))) (* val t3 = \"<St: b>err, 8\" : string *) Let us now \nswitch the order of the two effect-definition blocks in the prologue, putting the state-block first. \nThen running the same three examples gives: corresponding operation run are not formally part of the \nval tl = E.run (in (1 => (StateOps.set 3; ok ));construction, but are useful for visualization of the \neffect (* val tl'= \"<St: 3>ok\" : string *) layering.) vel t2' = E.run (fn 0 => signature MONAD = sig \n type'at val unit : 'a -> 'a t val bind : 'a t * ('a -> 'b t) -> 'b t val glue : (unit -> 'a t> -> \n'a t val show : string t -> string end; signature RMONAD = sig structure M : MONAD val reflect : 'a \nM.t -> a val reify : (unit -> a) -> a M.t end; signature WFREP = sig include ESCAPE val run : (unit \n-> string) -> string end; structure EffO : EFFREP= stract open Escape0 fun run t = t () end; fun&#38;or \nRepresent (structure M : MONAD structure E : EFFREP): sig include RMONAD include EFFREP end = strllct \nstructure C = RepCPS (type ans = Dynamic.dyn M.t structure E = E) structure M = M fun reflect m = \nC.shift (fn k => M.bind (m, in a => M.glue (fn 0 => k a))) fun reify t = let val (in-d, out-d) = Dynamic.newdyn0 \n in M.glue (fn 0 => M.bind (C.reset (in 0 => M.unit (in-d (t O))), M.unit o out-d)) end val escape \n= C.escape fun run t = M.show (reify (fn 0 => E.run t)) end; Figure 4: Representing monadic effects \nwith continuation- passing (StateOps.set4; ExcOps.fraise \"err\"; \"ok\")); (* val t2'= \"<exn: err>\" : string \n*) vsl t3' = E.run (in 0 => (StateOps.set5; ExcOps.fhandle (in (1 => (StateOps.set 8; Exb,ps.fraise \n\"err\"; \"ok\")) (in x => x - fi, u - Int.toString (StateOps.get 0)))) (* uncaught exception Fail: Unexpected \ncontrol effect raised at: ctrl.sml:29.25-29.57 *) Here, the computation of t2 shows that a raised excep- \ntion simply discards the current state. t3 shows what hap- pens when we attempt to execute an effect-ill-typed \npro-gram: the state-effect in the first argument to fhandle is meaningless in this ordering of effects. \nConsequently, the translation-based specification says nothing about the mean- ing of the program, and \nthe simulation theorem does not constrain the behavior of the implementation. structure Exceptions (*: \nMONAD*) = struct datatype 'a res = OK of 'a I EXN of string 'a t = unit -> 'a res unglue t = fn 0 => \nt 0 0 fun unit a = fn (1 => OK a fun bind (t, f) = fn 0 => case t 0 of OK a => f a (1 I EXN s => EXN \ns fun show t = case t () of OK s => s I EXN x => \"<exn: II ^ x ^ \">\" end; functor ExceptionOps (structure \nR : RMONAD where M = Exceptions): sig val fraise : string -> 'a val fhandle : (unit -> 'a) -> (string \n-> 'a) -> 'a and =  stnlct open Exceptions fun fraise s = R.reflect (in 0 => EXN s) fun fhandle t h \n= case R.reify t 0 of OK a => a I EXN s => h s end; structure State : MONAD= stnlct type state= int \ntype 'a t = state -> 'a * state fun glue t = fn s => t 0 s fun unit a = fn s => (a,s) fun bind (t, f) \n= fn s => let val (a,s') = t s in f a s' end fun show t = let val (a,s) = t 0 in if s = 0 then a else \n\"tst: \" ^ Int.toStrings ^ 11>11a  ^ end end; functor StateOps (structure R : RMONAD where M = State) \n: sig val get : unit -> int val set : int -> unit end =  stract fun get (1 = R.reflect (fn s => (s, \ns)) fun set n = R.reflect (in s => (0, n)) end; structure ListMonad : MONAD= stnlct type 'a t = unit \n-> 'a list fun glue t = fn 0 => t 0 0 fun unit a = in 0 => [al fun mapcan f [I = Cl I mapcan f (h::t) \n= f h Q mapcan f t fun bind (t, f) = in () => mapcan (fn a => f a 0) (t 0) fun disp [] = \"<fail>\" I \ndisp [xl = x 1 disp (h::t) = h ^ I' <or> ' -disp t  fun show t = disp (t 0) end; Figure 5: Some simple \nmonads and their operations 4.2 Shared-state concurrency As a larger example, we will consider the monadic \napproach *to modeling concurrency, as sketched in [MogSO], based on the semantic concept of resumptions \n[Sch86]. (Strictly speaking, this example goes beyond the language outlined in Section 2.1 by using a \n(positive) recursively defined type in the monad specifications. The relevant theorem extends easily \nto this case, however.) The monad of &#38;resumptions is given by with straightforward unit and extension \noperations. That is, a resumption-computation of Q is a &#38;computation that yields either an a-value \n(representing the final result), or an- other resumption-computation (representing the remaining computation). \nThe ML representation of the monad and its associated operations can be found in Figure 6. As long as \nall resumption-computations suspend periodi- cally (e.g., by calling yield()), this setup can directly \nsimu-late the parallel-or operation [Plo77], which returns true if either of of its arguments evaluates \nto true, false if both evaluate to false, and diverges in all other cases. Not that, because por constructs \nanother resumption-computation, the branches of a parallel-or can themselves contain parallel subcomputations. \nMore generally, we can model a concurrent system as a collection of resumption-computations, corresponding \nto the runnable processes. A scheduler flattens this collection into a single computation by repeatedly \npicking out an element of the collection, running it for a single step, and (if it has not yet terminated) \nputting it back into the collection. In-dividual processes can communicate by e.g., a shared store if \nz contains state-effects. Alternatively, we can use a more refined monad, To = j@. 14 (cy + req x (rsp \n+ 0)) Here, a computation that suspends now produces a request of type req, and must be resumed with \nresponse of type rsp. With this setup, and a suitable structure on requests and responses, it is simple \nto write an scheduler matching up senders and receivers in purely functional style. And while similar \nin efficiency to a traditional call/cc-based thread package [Wan80], such a system also achieves a direct \nre-lationship to the usual denotational specification. We will instead pursue another important aspect \nof con- currency: instead of making the scheduler pick runnable processes in a strict round-robin fashion, \nwe can make it choose non-deterministically which process to run at each step. That is, we can layer \nthe entire construction atop a nondeterminism monad: structure E = EffO; structure E = Represent (structure \nE = E structure M = Resumptions) structure Rrs = E structure ParOps = ParallelOps (structure Fl = Rrs) \n structure E = Represent (structure E = E structure M = State) structure Rst = E structure Cell = StateOps \n(structure R = Rst); stractlue E = Represent (structure E = E structure M = ListMonad) structure Rls \n= E structure Cone = ConcurOps (structure RR = Rrs structure RL= Rls);  structure Shared = stnlct \n fun store n = (ParOps.yield 0; Cell.set n)  fun fetch 0 = (ParOps.yield 0; Cell.get 0) end; structure \nResumptions (* : MONAD *) = strnct datatype 'a res = DONE of 'a I SlJSP of 'a t withtype 'a t = unit \n-> 'a res fun glue t = fn 0 => t 0 0 fun unit a = fn 0 => DONE a fan step (DONE a, f) =faO I step (SUSP \nt, f) = SUSP (bind (t, f)) and bind (t, f) = fn 0 => step (t 0, f)  fun disp (DONE a) =a I disp (SUSP \nt) = shov t and show t = disp (t 0) end; functor ParallelOps (structure R : RMONAD vhere M = Resumptions) \n: sig val yield : unit -> unit val por : (unit -> bool) * (unit -> bool) -> boo1 end =  struct open \nResumptions fun yield () = R.reflect (fn 0 => SUSP (unit 0)) fun por (tl, t2) = let fun step (DONE true, \n_) = DONE true I step (DONE false, p) = p () I step (SUSP t1, t2) = SUSP (rpor (t2, tl)) end rpor (tl, \nt2) () = step (tl 0. t2) in R.reflect (rpor (R.reify ti. R.reify t2)) end end; functor ConcurOps (structure \nRR : RMONAD where M = Resumptions structure RL : RMONAD where M = ListMonad) : sig val par : (unit -> \n'a) * (unit -> 'b) -> 'a * 'b val atomically : (unit -> 'a) -> 'a end =  stract open Resumptions fun \natomically t = let fun step (DONE a, y) = if y then SUSP (unit a) else DONE a I step (SUSP t, y) = step \n(t 0, true) and atom t 0 = step (t 0, false) in RR.reflect (atom @R.reify t)) end full par (tl, t2) = \nlet fun step (DONE a, DONE b) = DONE (a,b) I step (DONE a, susp tb) = SUSP (bind (tb, fn b => unit (a,b))) \nI step (SUSP ta, DONE b) = SUSP (bind (ta, in a => unit (a,b))) I step (SUSP ta, SUSP tb) = SUSP (rpar \n(ta, tb)) and rpar (tl, t2) 0 = if RL.reflect (in ()=>[true, false]) then step (tl 0, SUSP t2) else step \n(SUSP tl, t2 0)  in RR.reflect (rpar GtR.reify tl, RFt.reify t2)) end =d; Figure 6: Resumption monad \nand associated operations val tl = E.run (fn 0 => (Conc.par (fn 0 => Shared.store 3, fn 0 => Shared.store \n(Shared.fetch 0 + 1)); Int.toString (Shared.fetch 0))) 0 val tl = \"<st: 04 <or> <St: 4>4 <or> <St: 1>1 \n<or> <St: 3>3 \\ \\<or> <St: 4>4 <or> <St: I>1 <or> <St: 3>3 <or> ist: l>f \\ \\<or> <St: 3>3 <or> <St: 3>3\" \n*) val t2 = E.run (fn 0 => (Conc.par (fn 0 => Shared.store 3, fn () => Conc.atomically (in 0 => Shared.store \n(Shared.fetch (1 + 1))) Int.toString (Shared.fetch 0))) (* val t2 = \"<St: 4>4 <or> <St: 3>3 <or> <St: \n3>3 <or> <St: 3>3 \\ \\<or> <St: 3>3 <or> <St: 3>3\" *) Here, we see that bracketing a part of the concurrent \ncom-putation as an atomic section reduces the set of possible changes to the store. While the number \nof possible interleav-ings easily gets astronomical in any substantial concurrent program, the simulation \nis perfectly usable for exhaustively testing individual fragments, such as mutual-exclusion pro-tocols. \nFurther refinements are possible. For example, by lay- ering a data monad (To = int % (Y) above resumptions, \nwe can model thread-specific data, where a running compu-tation can perform a the equivalent of a getpid() \ncall to obtain its own thread s unique identifier. We can provide thread-local exceptions, or global \nones for aborting the en-tire concurrent system. We can add an output monad for tracing, but inspect \nit only for nondeterministic paths in which an exception is raised, and so on.  Related work There are \nalready a large number of proposals for layering effects, both for structuring denotational semantics \n[MogSO, Esp95] and functional programs [KW93, Ste94, LHJ95]. Generally, however, these approaches pursue \nmodularity in a flat multi-effect language, without an explicit effect-typing system. Accordingly, a \ncentral problem in such frameworks concerns defining the various effect-operations in such a way that \nthey lift through other effects that may be present. For specific effects, more or less ad hoc solutions \ndo exist, but operations that involve reification-like behavior (such as exception handling) do not seem \nto admit any general solu-tion. The approach presented in this paper is less ambitious: the basic translation-derived \nframework exposes the layer-ing explicitly in the effect-types of the proto-operations. Thus, those conflicts \nthat are not automatically resolvable by effect-subsumption must either be exposed to the pro-grammer \nas typing restrictions that go beyond simple typa- bility (akin to, e.g., keeping track of a function \ns exception-effects in Java), or the desired semantics must be explicitly encoded in the definitions \nof the programmer-visible opera-tions. Of course, existing results about lifting specific oper-ations \nthrough particular monads can be used for that. A further difference is that most executable specifications \nbased on monad constructors actually construct and use the full compound monad -explicitly or implicitly \n-during ac-tual evaluation of programs, usually at a substantial cost. Here, we make a strong distinction \nbetween the simple but inefficient specification, and the efficient but (especially for multiple layers) \nnot easily analyzable implementation, tak-ing care only that they agree on the meanings of complete programs. \nA second line of related work concerns implementation of various computational paradigms using control \noperators directly, without involving monads at all. Examples include uses of basic call/cc for thread \npackages [WanSO] and im-perative backtracking [HDM93]; simple composable-control [FWFD88, DF92] for nondeterminism \nand other basic ef-fects, and a number of proposals for hierarchical control [DF90, SF90, GRR95] to represent \ngeneral layered effects. Most of these are based on operational definitions of the control operators \nin terms of their actions on evaluation con-texts (although many also include sample implementations \nin terms of Scheme primitives). Again, we take a more minimalist approach here: we view control operators \nnot as an explicitly exposed programming abstraction in its own right, but only as a means to the end \nof implementing a monadic specification. (Of course, sometimes -although surprisingly rarely -the most \nnatural description of a computational effect is in fact in terms of continuations; the monadic framework \nencompasses this as simply another instance.) This frees us from the constraint of defining a general-purpose \ncontrol mechanism with intu-itive operational behavior, and allows us to provide instead a lean and mean \nimplementation, which can be formally analyzed without too much work.  6 Conclusions To be practically \ncompelling, a monad-based framework for effects needs to minimize overhead, both conceptual and computational. \nWe address the former concern by basing the specification on the intuitively familiar concept of def- \ninitional translation ( explaining away an effect ), and the latter by an efficient implementation that \nkeeps execution cost at roughly native levels, as long as the effect-invoking and effect-delimiting operations \nare comparatively rare -as is indeed the case in most functional programs. In other words, we aim to \nsteer clear of two extremes: on the one hand the specification is the implementation , re-sulting from \nexecuting a monad-based specification (of, e.g., exceptions) literally; and on the other hand, the implemen- \ntation is the specification , resulting from taking a particu- lar imperative implementation (e.g., a \nthread package) as a guide to specifying interactions with other effects. Instead, we propose a paradigm \n-monadic reflection -to uniformly relate a layered declarative specification of an effect tower to its \nultimate imperative implementation in terms of low-level primitives. Although the implementation presented \nhere is nominally complete in an operational sense, it should still be viewed as a proof-of-concept prototype, \nrather than a final solution. That is, the construction establishes that -beyond avail-ability of call/cc \nand references -no further support from the compiler or runtime system is needed to efficiently im-plement \nlayered effects. But this does not mean that such support would be undesirable. In particular, a type \nsystem for actually enforcing the effect-restrictions statically would be a big help in constructing \nlarge programs. To be practi- cal, this would probably need to be largely reconstruction-based, with \nonly minimal explicit annotations; it should also include support for some notion of effect-polymorphism. \nOn the semantic side, further refinements are also possi-ble. In particular, it should be possible to \nextend the formal simulation result to effect-recursive monads , in which the new effect being defined \nis implicitly used in its own spec-ification (e.g., for a higher-order state, we can store proce-dures \nthat themselves have state-effects). This would also allow for a more uniform treatment of continuation \nmonads with non-base answer types. It would also be worth inves-tigating whether the present results \nfor simulating a linear s-hierarchy can be extended to more general orders. Acknowledgments Programming \nLanguages, pages 333-343, San Francisco, Cali-fornia, January 1995. The author is sincerely indebted \nto Olivier Danvy for a num- ber of perceptive comments, as well as to the POPL review- ers and everyone \nwho influenced earlier versions of this work. References [BCL+98] Edoardo Biagioni, Ken Cline, Peter \nLee, Chris Okssaki, and Chris Stone. Safe-for-space threads in Standard ML. Higher-Order and Symbolic \nComputation, 11(2), 1998. [CF94] Robert Cartwright and Matthias Felleisen. Extensible denotational language \nspecifications. In Masami Hagiya and John C. Mitchell, editors, Symposium on Theoretical Aspects of Computer \nSoftware, number 789 in Lecture Notes in Com-puter Science, pages 244-272, Sendai, Japan, April 1994. \n[DFSO] Olivier Danvy and Andrzej Filinski. Abstracting control. In Proceedings of the 1990 A CM Conference \non Lisp and Func-tional Programming, pages 151-160, Nice, France, June 1990. [DF92] Olivier Danvy and \nAndrzej Filinski. Representing control: A study of the CPS transformation. Mathematical Structures in \nComputer Science, 2(4):361-391, December 1992. [Esp95] David A. Espinosa. Semantic Lego. PhD thesis, \nGrad-uate School of Arts and Sciences, Columbia University, May 1995. [Fi194] Andrzej Filinski. Representing \nmonads. In Proceedings of the 21st ACM SZGPLAN-SZGACT Symposium on Principles of Progmmming Languages, \npages 446-457, Portland, Oregon, January 1994. [Fi196] Andrzej Filinski. Controlling Effects. PhD thesis, \nSchool of Computer Science, Carnegie Mellon University, May 1996. Technical Report CMU-CS-96-119. [FSDF93] \nCormac Flanagan, Amr Sabry, Bruce F. Duba, and Matthias Felleisen. The essence of compiling with continu-ations. \nIn Proceedings of the SZGPLAN 93 Conference on Programming Language Design and Implementation, 1993. \n[FWFD88] Matthias Felleisen, Mitchell Wand, Daniel P. Fried-man, and Bruce F. Duba. Abstract continuations: \nA mathe-matical semantics for handling full functional jumps. In Pro-ceedings of the 1988 ACM Conference \non Lisp and Functional Programming, pages 52-62, Snowbird, Utah, July 1988. [GRR95] Carl A. Gunter, Didier \nRemy, and Jon G. Riecke. A generalization of exceptions and control in ML-like languages. In Functional \nProgramming and Computer Architecture, pages 12-23, 1995. [HD94] John Hatcliff and Olivier Danvy. A generic \naccount of continuation-passing styles. In Proceedings of the 21st ACM SZGPLAN-SZGA CT Symposium on Principles \nof Progmm-ming Languages, pages 458-471, Portland, Oregon, January 1994. [HDM93] Robert Harper, Bruce \nF. Duba, and David MacQueen. Typing first-class continuations in ML. Journal of Functional Programming, \n3(4):465-484, October 1993. (A preliminary ver-sion appeared in Proceedings of the 1991 Symposium on \nPrin-ciples of Programming Languages). [KCR98] Richard Kelsey, William Clinger, and Jonathan Rees, editors. \nRevised5 report on the algorithmic language Scheme. Higher-Order and Symbolic Computation, 11(3):7-105, \n1998. Also appears in ACM SIGPLAN Notices 33(9), September 1998. [KW93] David J. King and Philip Wadler. \nCombining monads. In J. Launchbury and P. M. Sansom, editors, Z%nctional Pro-gramming, Glasgow 1992, \npages 134-143, Ayr, Scotland, 1993. Springer-Verlag. [LHJ95] Sheng Liang, Paul Hudak, and Mark Jones. \nMonad transformers and modular interpreters. In Proceedings of the 22nd ACM SZGPLAN-SZGACT Symposium \non Principles of [LPJ95] John Launchbury and Simon L. Peyton Jones. State in Haskell. Lisp and Symbolic \nComputation, 8(4):293-341, De-cember 1995. [ML711 Saunders Mac Lane. Categories for the Working Math-ematician, \nvolume 5 of Graduate Texts in Mathematics. Springer-Verlag, 1971. [Mog89] Eugenio Moggi. Computational \nlambda-calculus and monads. In Proceedings of the Fourth Annual Symposium on Logic in Computer Science, \npages 14-23, Pacific Grove, Cali-fornia, June 1989. IEEE. [MogSO] Eugenio Moggi. An abstract view of \nprogramming lan-guages. Technical Report ECS-LFCS-90-113, Laboratory for Foundations of Computer Science, \nUniversity of Edinburgh, Edinburgh, Scotland, April 1990. [MW85] Albert R. Meyer and Mitchell Wand. Continuation \nse-mantics in typed lambda-calculi (summary). In Rohit Parikh, editor, Logic3 of Programs -Proceedings, \nnumber 193 in Lec- ture Notes in Computer Science, pages 219-224, Brooklyn, June 1985. [Pit961 Andrew \nM. Pitts. Relational properties of domains. Zn-formation and Computation, 127(2):66-90, June 1996. [Plo77] \nGordon D. Plotkin. LCF considered as a programming language. Theoretical Computer Science, 5(3):223-255, \nDe-cember 1977. [PW93] Simon L. Peyton Jones and Philip Wadler. Impera-tive functional programming. In \nProceedings of the Twenti-eth Annual ACM Symposium on Principles of Programming Languages, pages 71-84, \nCharleston, South Carolina, January 1993. [Ree92] Jonathan Rees. The Scheme of things: The June 1992 \nmeeting. Lisp Pointers, 5(4):40-45, 1992. [Rey74] John C. Reynolds. On the relation between direct and \ncontinuation semantics. In Jacques Loeckx, editor, 2nd Col-loquium on Automata, Languages and Programming, \nnum-ber 14 in Lecture Notes in Computer Science, pages 141-156, Saarbriicken, West Germany, July 1974. \n[Sch86] David A. Schmidt. Denotational Semantics: A Method-ology for Language Development. Allyn and \nBacon, Inc., 1986. [SF901 D orai Sitaram and Matthias Felleisen. Control delimiters and their hierarchies. \nLisp and Symbolic Computation, 3(1):67-99, January 1990. [Ste94] Guy L. Steele, Jr. Building interpreters \nby composing monads. In Proceedings of the 2lst ACM SZGPLAN-SZGACT Symposium on Principles of Programming \nLanguages, pages 472-492, Portland, Oregon, January 1994. [To1981 Andrew Tolmach. Optimizing ML using \na hierarchy of monadic types. In Xavier Leroy and Atsushi Ohori, editors, Types in Compilation, Second \nInternational Workshop, num-ber 1473 in Lecture Notes in Computer Science, pages 97-115, Kyoto, Japan, \nMarch 1998. [Wad921 Philip Wadler. The essence of functional programming (invited talk). In Proceedings \nof the Nineteenth Annual ACM Symposium on Principles of Programming Languages, pages 1-14, Albuquerque, \nNew Mexico, January 1992. [Wad981 Philip Wadler. The marriage of effects and monads. In International \nConference on Functional Programming, 1998. [Wan801 Mitchell Wand. Continuation-baaed multiprocessing. \nIn Conference Record of the 1980 LISP Conference, pages 19-28, Stanford, California, August 1980. \n\t\t\t", "proc_id": "292540", "abstract": "", "authors": [{"name": "Andrzej Filinski", "author_profile_id": "81100252096", "affiliation": "BRICS, Department of Computer Science, University of Aarhus, Ny Munkegade, DK-8000 Aarhus C, Denmark", "person_id": "PP39034562", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/292540.292557", "year": "1999", "article_id": "292557", "conference": "POPL", "title": "Representing layered monads", "url": "http://dl.acm.org/citation.cfm?id=292557"}