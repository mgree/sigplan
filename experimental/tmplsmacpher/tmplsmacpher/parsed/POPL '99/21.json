{"article_publication_date": "01-01-1999", "fulltext": "\n Type-based analysis of uncaught exceptions FranCois Pessaux Xavier Leroy INRIA Rocquencourt* Abstract \nThis paper presents a program analysis to estimate un-caught exceptions in ML programs. This analysis \nrelies on unification-based type inference in a non-standard type system, using rows to approximate both \nthe flow of escaping exceptions (a la effect systems) and the flow of result values (a la control-flow \nanalyses). The resulting analysis is efficient and precise; in particular, arguments carried by exceptions \nare accurately handled. 1 Introduction Many modern programming languages such as Ada, Modula-3, ML and \nJava provide built-in support for exceptions: raising an exception at some program point transfers control \nto the nearest handler for that exception found in the dynamic call stack. Exceptions provide safe and \nflexible error handling in applications: if an exception is not explicitly handled in a function by the \nprogrammer, it is automatically propagated upwards in the call graph until a function that knows how \nto deal with the exception is found. If no handler is provided for the exception, program execution is \nimmediately aborted, thus pinpointing the unexpected condition during testing. This stands in sharp contrast \nwith the traditional C-style reporting of error conditions as impossible return values (such as null \npointers or the integer -1): in this approach, the programmer must write significant amount of code to \npropagate error conditions upwards; moreover, it is very easy to ignore an error condition altogether, \noften causing the program to crash much later, or even complete but produce incorrect results. The downside \nof using exceptions for error reporting and as a general non-local control structure is that it is very \neasy to forget to catch an exception at the right place, i.e. to han- dle an error condition. ML compilers \ngenerate no errors or warnings in this case, and the programming mistake will only show up during testing. \nExhaustive testing of appli- cations is difficult, and even more so in the case of error conditions that, \nare infrequent or hard to reproduce. Our experience with large ML applications is that uncaught ex-ceptions \nare the most frequent mode of failure. *Authors address: INRIA Rocquencourt, projet Cristal, B.P. 105, \n78153 Le Chesnay, France. E-mail: Francois.PessauxOinria.fr, Xavier.LeroyOinria.fr. This work has been \npartially supported by CNET, France TBlBcom. Permission to make digital or hard copies ofall or part \nofthis work for personal or classroom use is granted without fez provided that copies arc not made or \ndistributed for protit or commercial advantage and that copies bear this notice and the full citation \non the first page. TO copy otherwise. to republish. to post on swws or to redistribute to lists, requires \nprior specific permission and/or a fee. POPL 99 San Antonio Tesas USA Copyright ACM 1999 l-58113-095-3/99/01 \n. ..$5.00 To address this issue, languages such as Modula-3 and Java require the programmer to declare, \nfor each function or method, the set of exceptions that may escape out of it. Those declarations are \nthen checked statically during type-checking by a simple intraprocedural analysis. This forces programmers \nto be conscious of the flow of exceptions through their programs. Declaring escaping exceptions in functions \nand method signatures works well in first-order, monomorphic programs, but is not adequate for the kind \nof higher-order, polymor-phic programming that ML promotes. Consider the map it- erator on lists. In \nModula-3 or Java, the programmer must declare a set E of exceptions that the function argument to map \nmay raise; map, then, may raise the same exceptions E. But E is fixed arbitrarily, thus preventing map \nfrom being applied to functions that raise exceptions not in E. The genericity of map can be restored \nby taking for E the set of all possible exceptions, but then the precision of the ex- ception analysis \nis dramatically decreased: all invocations of map are then considered as potentially raising any exception. \n(Similar problems arise in highly object-oriented Java pro- grams using e.g. container classes and iterators \nintensively.) To deal properly with higher-order functions, a very rich language for exception declarations \nis required, including at least exception polymorphism (variables ranging over sets of exceptions) and \narbitrary unions of exception sets. (See section 2 for a more detailed discussion.) We believe that such \na complex language for declaring escaping exceptions is beyond what programmers are willing to put up \nwith. The alternative that we follow in this paper is to infer escaping exceptions from unannotated ML \nsource code. In other terms, we view the problem of detecting potentially uncaught exceptions as a static \ndebugging problem, where static analyses are applied to the programs not to make them faster via better \ncode generation, but to make them safer by pinpointing possible run-time failures. This approach has \nseveral advantages with respect to the Modula-S/Java ap-proach: it blends better with ML s type inference; \nit does not change the language and supports the static debugging of legacy applications; it allows the \nuse of complex approx- imations of exception sets, as those need not be written by the programmer (within \nreason -the results of the analysis must still be understandable to the programmer). Finally, the exception \ninference needs not be fully compatible with the ML module system: a whole program analysis can be considered \n(again within reason -analysis time should re-main practical). Several exception analyses for ML have \nbeen proposed [8, 35, 36, 3, 41, some based on effect systems, some on control-flow analyses, some on \ncombinations of both (see section 6 for a detailed discussion). The analysis presented in this paper \nattempts to combine the efficiency of effect sys- tems with the precision of flow analyses. It is based \non unifi- cation and non-standard type inference algorithms that have excellent running time and we hope \nshould scale well to large any exception can be raised by applying a function retrieved applications. \nAt the same time, our analysis is still fairly precise; in particular, it approximates not only the names \nof the escaping exceptions, but also the arguments they carry -a feature that is essential to analyze \nprecisely many existing ML programs. This constitutes the main technical contribu-tion of this paper: \nintegrate in the same unification-based framework both approximation of exception effects in the style \nof effect systems [28], and approximation of sets of val- ues computed at each program point in the style \nof flow analyses and soft typing [26, 331. Finally, our analysis has been implemented to cover the whole \nObjective Cam1 lan-guage -not only core ML, but also datatypes, objects, and the module system. We present \nsome preliminary experi-mental results obtained with our implementation. The remainder of this paper \nis organized as follows. Sec-tion 2 lists the main requirements for an ML exception anal-ysis. Section \n3 presents the non-standard type system we use for exception analysis. Extension to the full Objective \nCam1 language is discussed in section 4; experimental results ob-tained with our implementation, in section \n5; and related work, in section 6. Concluding remarks can be found in section 7. 2 Design requirements \nIn this section, we list the main requirements for an ef-fective exception analysis for ML, and show \nthat they go much beyond what can be expressed by exception declara-tions in Modula-3 or Java. Existing \nexception analyses have addressed some of these requirements, but none addresses all. 2.1 Handling higher-order \nfunctions precisely The exception behavior of higher-order functions depends on the exceptions that can \nbe raised by their functional ar-guments. A form of polymorphism over escaping exceptions is thus needed \nto analyze higher-order functions precisely. Consider the map iterator over lists mentioned in introduc- \ntion. An application map f 1 may raise whatever exception the f argument may raise. Writing 7 3 7 for \nthe anno-tated type of functions from type T to type 7 whose set of potentially escaping exception is \ncp, the behavior of map is captured by the following annotated type scheme: map : Vcu,p,cp. (CX 4 p) \n-% (r.~ list -% /3 list) where cx, p range over types and cp ranges over sets of excep- tions. In general, \nthe escaping exceptions for a higher-order function are combinations (~1 U. . . U (Pi U {Cl; . . . ; \nCn} where the (pi are variables representing the escaping exceptions for functional arguments and the \nCj are exception constants. For instance, we have the following annotated type for func-tion composition \nXf.Xg.Xx.f(g(Z)): Given the frequent use of higher-order functions in ML pro-grams, an exception analysis \nfor ML must handle them with precision similar to what the annotated types above suggest. Similar issues \narise when functions are stored into data structures such as lists or hash tables (as in callback tables \nfor instance). The exception analysis should keep track of the union of the exceptions that can be raised \nby functions contained in the structure. It is not acceptable to say that from the structure. 2.2 Handling \nexceptions as first-class values In ML and Java, exceptions are first-class values: exception values \ncan be built in advance and passed through functions before being raised. Consider for instance the following \ncon-trived example: let test = Xexn. try raise(exn) with E + 0 The exception behavior of this function \nis that test exn raises the exception coatained in the argument exn, except when exn is actually the \nexception E, in which case no ex-ception escapes out of test. We seek exception analyses precise enough \nto capture this behavior. It is true that the first-class character of exception val-ues is rarely, if \never, used in actual ML programs. However, there is one important idiom where an exception value ap-pears: \nfinalization. Consider: let f = Xx. try g(x) with E -+ 0 I exn -+ finali.~ation code; raisecexn) Assuming \ng can raise exceptions E and E' , the exception analyzer should recognize that the exn exception variable \ncan only take the value E , thus the raise(exn) that re-raises the exception after finalization can only \nraise E , and so does the function f itself. 2.3 Keeping track of exception arguments ML exceptions \ncan optionally carry arguments, just like all other data type constructors. This argument can be tested \nin the with part of an exception handler, using pattern-matching on the exception value, so that only \ncertain ex-ceptions with certain arguments are caught. Consider the following example: exception Failure \nof string let f = Xx. if . . . then . . . else raise(Failure f 1 let g = Xx. try f(x) with Failure f \n-+ 0 An exception analysis that only keeps track of the exception head constructors (i.e. Failure above) \nbut not of their argu-ments (i.e. the string \"f above) fails to analyze this example with sufficient \nprecision: the analysis records that function f may raise the Failure exception, hence it considers that \nthe application f(x) in g may raise Failure with any argu-ment. Since the exception handler traps only \nFailure f I, the analyzer concludes that g may raise Failure, while in reality no exception can escape \ng. This lack of precision can be brushed aside as unimpor-tant and bad programming style anyway . Indeed, \nthe programmer should have declared a specific constant excep-tion Failure-f to report the error in f, \nrather than rely on the general-purpose Failure exception. However, code fragments similar to the example \nabove appear in legacy Cam1 applications that we would like to analyze. More im-portantly, there are \nalso legitimate uses of exceptions with parameters. For instance, the Cam1 interface to Unix sys-tem \ncalls uses the following scheme to report Unix error conditions: type unix_error = EACCES I ENOENT I \nENOSPC 1 . . . (* enumerated type with 67 constructors representing Unix error codes *> exception Unix-error \nof unix_error This allows user code to trap all Unix errors at once (try . . . with Unix-error(_) -> \n. . .), and also to trap particular errors (try . . . with Unix_error(ENOENT) -> . . .). Replacing Unix-error \nby 67 distinct exceptions, one for each error code, would make the former very painful. It is desirable \nthat the exception analysis be able to show that certain Unix-error exceptions with arguments representing \ncommon errors (e.g. Unix-error (ENOENT), no such file ) are handled in the program and thus do not escape, \nwhile we can accept that other Unix-error exceptions representing rare errors are not handled in the \nprogram and may escape. The problem with exception arguments is made worse by the availability (in the \nCam1 standard library at least) of predefined functions to raise general-purpose exceptions such as Failure \nabove. Indeed, the example with Failure above is more likely to appear under the following form: exception \nFailure of string let failwith = Xmsg. raise(Failure msg) let f = Xx. if . . . then . . . else failwith( \nf ) let g = Xx. try f(x) with Failure f -+ 0 Precise exception analysis in this example requires tracking \nthe string constant f I not only when it appears as imme- diate argument to the Failure exception constructor, \nbut also when it is passed to the function failwith. Hence the exception analysis must also include some \namount of data flow analysis, not limited to exception values.  2.4 Running faster than control-flow \nanalyses All the requirements we have listed so far point towards control-flow analyses in the style \nof Shiver s k-CFA [26] or Heintze s SBA [9]. Control-flow analyses provide an approx- imation of the \nset of values that can flow to each program point. It is entirely straightforward to extend them to ap- \nproximate also the set of escaping exceptions at each pro- gram point at the same time as they approximate \nthe set of result values. Alternatively, the exception analysis can be run as a second pass of dataflow \nanalysis exploiting the results of control-flow analysis [36], although this results in some loss of \nprecision, as the control flow can be determined more accurately if exception information is available. \nThis exception analysis benefits from the relatively precise ap-proximation of values provided by the \ncontrol-flow analysis, especially as far as exception arguments are concerned. Our first implementation \nof an exception analyzer for Objective Cam1 was indeed based on control-flow analysis: 0-CFA initially, \nthen Jagannathan and Wright s polymor-phic splitting [12]. Our practical experience with this ap- proach \nwas mixed: the precision of the exception analysis was satisfactory (at least with polymorphic splitting), \nbut the speed of the analysis left a lot to be desired. In partic- ular, we observed quadratic behavior \non several examples, indicating that the analysis would not scale easily to large programsl. Although \nsophisticated techniques have been developed to speed up program analyses based of set inclu- sion constraints \nsuch as CFA and SBA [2, 6, 5, 191, it is still an open problem whether those analyses can scale to lOO,OOO-line \nprograms. The complexity of 0-CFA alone is 0(n3), where n is the size of the whole program. We did not \nobserve cubic behavior on our tests, how-ever. Quadratic behavior arises in the following not uncommon \ncase: assume that a group of functions of size k = O(n) recurses over a list of m = O(n) elements given \nin extension in the program source. At least m iteration of the analysis is required before fixpoint \nis reached on the parameters and results of the functions. Since each iteration takes time proportional \nto k, the time of the analysis is O(n ). For these reasons, we decided to abandon analyses based on CFA \nor more generally set inclusion constraints, and set- tled for less precise but faster analyses based \non equality constraints and unification. 3 A type system for exception analysis In the style of effect \nsystems [16, 281, our exception anal-ysis is presented as a type inference algorithm for a non-standard \ntype system. The type system uses unified mecha- nisms based on row variables both to keep track of the \neffects (sets of escaping exceptions) of expressions and to refine the usual ML types by more precise \ninformation about the pos- sible values of expressions. In this section, we present first the typing \nrules for our type system (that is, the specifica- tions for the exception analysis), then type inference \nissues (the actual analysis). 3.1 The source language The source language we consider in this paper is \na simple subset of ML with integers and exceptions as the only data types, the ability to raise and handle \nexceptions, and sim- plified pattern-matching. Terms: a ::= 2 identifier i integer constant Xx. a application \nai(a2) abstraction let x = al in a2 the let binding match ai with p -+ as ] x -+ as pattern-matching \nexception constr. C I D(a) try al with x + a2 exception handler Patterns: p ::= 2 variable pattern constant \npatterns IilC constructed pattern I D(P) The match ai with p --+ a2 1 x -+ as performs pattern- matching \non the value of al; if it matches the pattern p, the branch as is evaluated; otherwise, as is evaluated. \nMulti-case pattern matchings can be expressed by cascading match expressions. The try ar with x + a2 \nconstruct evalu-ates al; if an exception is raised, its value is bound to x and as is evaluated. There \nis no syntactic form for rais- ing an exception; instead, we assume predefined a raise function in the \nenvironment. The try construct catches all exceptions; catching only a given exception C is performed \nby: try al with x + match z with C + a2 I y + raise(y) The dynamic semantics for this language is given \nby the reduction rules in figure 1, in the style of [34]. Values, eval- uation contexts, and evaluation \nresults are defined as: Values: 21 ::= i ) C 1 D(v) I Xx.a I raise Evaluation contexts: P ::= [] 1 l?(a) \nI w(r) I D(r) I let z = r in a I match I with p --+ a2 1 x + a3 I try P with x -+ a (Ax.a)(v) * a{x \n+- v} let x = 2) in a * a(a: +- v} match v with p --) az 1 cc + a3 j o(u2) if (T = M(v,p) is defined \nmatch v with p + az ( z -+ a3 + as{x + v} if M(v,p) is undefined try v with x + as =+ v (raise v)(u) \n* raise v (Xz.a)(raise v) * raise v D(raise w) + raise v let x = raise v in a * raise v match raise v \nwith p -+ u2 1 IC -+ u3 * raise v try raise v with 2 --t a2 + az(z +-- v} IJa] * r[a ] if a * a Ihe pattern-matching \nfunction M(v,p):  M(V,Z) = {x +- v} IM(i,i) = id M(C, C) = id WD(v), D(P)) = WV,P) Figure 1: Reduction \nrules Evaluation results: r ::= v ( raise v A result of v indicates normal termination with return value \nv; a result of raise v indicates an uncaught excep-tion v. 3.2 The type algebra The type system uses \nthe following type algebra: Type expressions: 7 ::= (Y type variable I Wf4 integer type exception type \nI -Iv1 I Tl 2 72 function type Type schemes: U ::= Voi,pj,6k.r Rows: $0 ::= p row variable all possible \nelements iI, the element E plus whatever is in p Row elements: E ::=i:7r integer constant constant exception \n) Yz;=, parameterized exception Presence annotations: T ::= Pre element is present presence variable \nAs in effect systems, our function types rr -% 72 are an- notated by the latent effect cp of the function, \nthat is, the set of exceptions that may be raised during application of the function. In addition, the \nbase types exn[ p] and int[cp] are also annotated by sets of exceptions and integers re-spectively. Those \nsets refine the ML types exn and int by restricting the values that an expression of type exn[cp] or \nint[cp] can have. Sets of exceptions or integers are represented by rows similar to those used for typing \nextensible records (31, 21, 231. A row is either T, meaning that all values of the type are possible \n(we do not have any more precise information), or a sequence of row elements ~1 . . . E,, terminated \nby a row variable p. We impose the following equational theory on rows to express that the order of elements \nin a row does not matter (equation l), and that T is absorbing (equation 2): El; E2; p = E2; El; cp (1) \n i:Pre; T = T (2) The absorption equation 2 applies only to integer row ele- ments because we intend \nT to be used only in rows anno-tating the int type. (The kinding rules below enforce this invariant.) \nA T symbol is required for base types such as int, which have an infinite (or at least very large) signature. \nIt is not required for datatypes such as exn, which have a finite signature: a row enumerating all possible \nconstructors can be used instead (this is discussed in section 4.1.4 below). Moreover, combining T and \nrows containing parameterized constructors raises technical problems2; we prefer to avoid the difficulty \nby restricting T to rows containing only integer elements. Rows and row variables support both polymorphism \nover sets and a form of set union in a unification framework. For instance, the two rows ~1; pr and ~2; \npz, which informally represent the sets (~1) and {sz} respectively, unify into the row ~1; ~2; p representing \nthe set (~1; ~2) via the substitution {Pi + (E2;P); P2 + (EliP)). A row element E is either an integer \nconstant i, a con- stant exception constructor C, or a parameterized exception constructor D(T) carrying \nthe annotated type r of its argu- ment. To maintain crucial kinding invariants (see below), The obvious \nabsorption equation D(T); T = T is unsound, as it allows deductions such as D(a);T = T = D(P);T, which \nlead to inconsistent typings. If ML had subtyping and a supertype T of all types, a correct equation \nwould be D(T); T = T. This equation allows T to absorb any D(Tj (because D(7); T <: D(T); T = T), but \nonly allows expansion of T into D(T); T, meaning correctly that no information is available on the argument \nof D. (Xz.a)(v) =+ a{z +- v} let 2 = 0 in a j a{z +-v} match u with p + a2 1 z + a3 + c(u2) if g = M(v,p) \nis defined match v with p + a2 1 z + a3 j a3{z + v} if M(u,p) is undefined try v with z + CL~ + IJ (raise \nv)(a) j raise v (Xz.a)(raise v) * raise v D(raise v) j raise v let z = raise u in a * raise u match raise \nv with p + a2 1 z + a3 * raise v try raise v with z + a2 + az{z t v} l?[a] * r[a ] if a * a The pattern-matching \nfunction M(v,p):  M(v,z) = {Z + v} M(i, i) = id M(C, C) = id M(Wv), D(P)) = M(V,P) Figure 1: Reduction \nrules Evaluation results: T ::= v raise v A result of v indicates normal termination with return value \nV; a result of raise v indicates an uncaught excep-tion v. 3.2 The type algebra The type system uses \nthe following type algebra: Type expressions: 7- ::= ff type variable I int[cpl integer type I =4cp1 \nexception type I71 3 n function type Type schemes: a ::= Va,,p,,tik.r Rows: p ::= p row variable all \npossible elements the element E plus whatever is in cp 1:9 Row elements: E ::=i:n integer constant IC:7r \nconstant exception I L (r) parameterized exception Presence annotations: 7r ::= Pre element is present \npresence variable 16 As in effect systems, our function types 71 s rz are an-notated by the latent effect \ncp of the function, that is, the set of exceptions that may be raised during application of the function. \nIn addition, the base types exn[cp] and int[cp] are also annotated by sets of exceptions and integers \nre-spectively. Those sets refine the ML types exn and int by restricting the values that an expression \nof type exn[cp] or int[cp] can have. Sets of exceptions or integers are represented by rows similar to \nthose used for typing extensible records [31, 21, 231. A row is either T, meaning that all values of \nthe type are possible (we do not have any more precise information), or a sequence of row elements ~1 \n. Ed terminated by a row variable p. We impose the following equational theory on rows to express that \nthe order of elements in a row does not matter (equation l), and that T is absorbing (equation 2): El; \n&#38;a; cp = E2; El; P (1) i:Pre; T = T (2) The absorption equation 2 applies only to integer row ele-ments \nbecause we intend T to be used only in rows anno-tating the int type. (The kinding rules below enforce \nthis invariant.) A T symbol is required for base types such as int, which have an infinite (or at least \nvery large) signature. It is not required for datatypes such as exn, which have a finite signature: a \nrow enumerating all possible constructors can be used instead (this is discussed in section 4.1.4 below). \nMoreover, combining T and rows containing parameterized constructors raises technical problems2; we prefer \nto avoid the difficulty by restricting T to rows containing only integer elements. Rows and row variables \nsupport both polymorphism over sets and a form of set union in a unification framework. For instance, \nthe two rows ~1; p1 and ~2; pz, which informally represent the sets (~1) and (~2) respectively, unify \ninto the row ~1; ~2; p representing the set (~1; ~2) via the substitution {Pl + (EZ; P); PZ + (El; P)>. \nA row element E is either an integer constant i, a con-stant exception constructor C, or a parameterized \nexception constructor D(r) carrying the annotated type T of its argu-ment. To maintain crucial kinding \ninvariants (see below), The obvious absorption equation D(r); T = T is unsound, as it allows deductions \nsuch as D(e); T = T = D(p); T, which lead to inconsistent typings. If ML had subtyping and a supertype \nT of all types, a correct equation would be D(T); T = T. This equation allows T to absorb any D(T) (because \nD(r); T <: D(T); T = T), but only allows expansion of T into D(T); T, meaning correctly that no information \nis available on the argument of D. I- p :: K(p) b T :: INT(S) i$S k cp :: INT(S U {i}) k- (i:~; 9):: \nINT(S) C@S F~J::EXN(SU{C}) k (C:ir; cp) ::EXN(S) D#S I- cp :: EXN(S U {D}) t- 7- wf F (D(T); cp) :: EXN(S) \nI- cp :: INT(0) t-cp::EXN@) I-71 wf k cp :: EXN(@) k 72 wf I-int[cp] wf F exn[cp] wf I- Tl % T2 wf Figure \n2: Kinding rules the constant row elements (i and C) also carry a presence annotation, written A. A presence \nannotation can be either Pre, meaning that the element is present in the set denoted by the row expression; \nor a presence variable 6 meaning that the element is actually not present in the set denoted by the row \nexpression, but may be considered as present in order to satisfy unification constraints. Examples: The \ntype int[T] denotes all integer values. The type of integer addition is VP,, ~2, ~3, ~4. inth] 2 int[p3] \n2 int[T] (no effects, no information known on the return value). The type scheme Vp. int [I: Pre; 2 \n:Pre; p] stands for the set (1; 2) and is the type of integer expressions that can only evaluate to 1 \nor to 2. A universally quantified row variable p that occurs only positively in a type should be read \nas denoting the empty set of elements, for the same reasons that Vcr.(~ denotes an empty set of values. \nThe type scheme Vp, 6. int [l : 6; 2 : Pre; p] stands for the set (2). Although 1 is mentioned in the \nrow, it should not be considered present in the set, since its presence annotation 6 is universally quantified \nand occurs only positively. The type scheme VP, p . exn[D(int[3 : Pre; 4 : Pre; p]); p ] stands for the \nset of exceptions {D(3); D(4)}. The raise predefined function has the following type scheme: Va, p. exn[p] \n2 CL It expresses that an application of raise never returns and raises exactly the exceptions that it \nreceives as argument. Kinding of rows: To simplify the formulation of the typing rules and to ensure \nthe existence of principal unifiers and principal typings, we require the following four structural invariants \non rows: 1. A given integer constant or exception constructor should occur at most once in a row (for \ninstance, (D(T); D(T ); cp) is not well-formed). 2. A row variable p is preceded by the same set of \ninteger constants and exception constructors in all row expres- sions where it occurs (for instance, \nwe cannot have both (1 :Pre; p) and (2 :Pre; p) in the same deriva-tion). 3. A row cp annotating an \ninteger type int[cp] can only contain integer elements i.  4. A row p annotating an exception type exn[cp] \nor a func- tion type 71 -% ~2 can only contain constant or param- eterized constructors C, D and must \nnot end with T. Invariants (I) and (2) are well known from earlier work on record types [23]. Invariants \n(3) and (4) are more unusual. They ensure a clear separation between annotations of int types (composed \nof integer elements and possibly T) and annotations of the exn types (composed of constructors and no \nT). Since T absorbs only integer elements (equation 2), we do not want it to occur in rows containing \nexception constructors C, D. Following 123, 181, we use kinds to enforce the invariants above. Our kinds \nrc. are composed of a tag (either INTor EXN) and a set of constants and constructors: K.::= INT((i1 ,..., \ni,})IEXN({G ,..., C,,Dl,... ,D,}) The constants and constructors appearing in the set part of a kind \nare those constants and constructors that must not appear in rows of that kind (because they already \nappear in elements concatenated before those rows). We assume given a global mapping K assigning kinds \nto row variables, and such that for each n there are infinitely many variables of that kind (i.e. K-~(K) \nis infinite). The kinding rules are shown in figure 2. They define the two judgements k p :: K (row cp \nhas kind K) and k T wf (type T is well-formed). 3.3 The typing rules Figure 3 shows the typing rules \nfor our system. They define the judgement E F a : r/q, where E is the typing environ- ment, a the term \nto type, 7 the type of values that a may evaluate to, and cp the set of exceptions that may escape dur- \ning the evaluation of a. All types appearing in the rules are assumed to be well-kinded. We assume that \ntyping starts in the initial environment Eo = {raise : Va, p. exn[p] 3 a}. The rules for variables and \nlet bindings (rules 1 and 5) are standard, except that we generalize over all three kinds of type variables. \nFor variables as well as other language constructs that never raise exceptions (rules 1, 2, 3, 7), the \ncp component of the result is unconstrained and can be chosen as needed to satisfy equality constraints \nin the remainder of the typing derivation. The rules for function abstraction and application (rules \n3 and 4) are the usual rules for effect systems. For abstraction, the effect of the function body becomes \nthe latent effect of the function type. For application al(az), we require that the same set cp of exceptions \noccurs as effect of al, latent effect of the function denoted by al, and effect of a2. This corresponds \nin our unification setting to taking the union of those three effects. I yping of expressions: k q wf \nE $ {cc : ~1) k a : TZ/ P b cp::EXN(@) k cp :: INT({i}) t-cp::EXN(@)(2) ; frJ (1) (3)  E k i : int[i:~re; \ncp']/cp Et-XZ.~:(T&#38;~)/(P E b al : (7 2 T)/(p E I-az : T / P (4) E b al : ~~/cp E @ {z : Gen(ri, E, \ncp)} t- a2 : ~/cp (5) E klet x=ai in a2 : ~/cp Ek m(m) :T/'P  E k al : ~l/cp t-p : 71 + E k 71 -j.J \nI, 72 E$E /-az:T/cp E${x~T2}ka3:T/(P (6) E k-match al with p + a2 1 x + a3 : ~fcp k 9 :: EXN({C}) k cp \n::EXN(k?) 7 5 %eAv(Q E k a : T/(P !-cp :: EXN({D}) k cp ::EXN(o) (8) (7)  Ek C :exn[C:Pre;cp']/cp Et-D(a) \n: exn[D(r); cp ]/cp E k- al : T/(P E $ {x : exn[cp ]} k a2 : ~/cp (9) E k try al with x + a2 : ~/cp \n ryping of patterns: t- 2 : T + {X : T} (lo) t i: int[i:Pre;cp] * {} (11) t C : exn[C : Pre; p] =+ {} \n(12) r < QpeArg(@ t P : 7 * E (13) t D(p) + E : exn[D(T);cp]  ?attern subtraction: t T Wf t int[i:Pre;cp] \n-i-vt int[i:x;cp] (15) t exn[C : Pre; p] - C w exn[C : T; p] (16) (14)ET-X-T t-T--p-T (17) t exn[D(T); \n-u exn[D(r ); p] 'p] D(p)  nstantiation and generalization: . 5 VcUipj6h.T iff there exists Ti, Cpj, \nrk such that 7 = T{C&#38; + Ti, pj + pj, 6k + ??k} and t Ti Wf and t pj :: K(pj). len(T, E, cp) is Vaipj6k. \nT where {oi, pj, 6k, } = FV(T) \\ (FV(E) U FV((p)). Figure 3: The typing rules For integer constants and \nexception constructors (rules 2, 7 and 8), we record the actual value of the expression in the approximation \npart of the type int or exn. For instance, the type of i must be of the form int[i : Pre; cp], forcing \ni : Pre to appear in the type of the expression. In rules 8 and 13, we write TypeArg(D) for the type \nscheme of the argument of constructor D, e.g. TypeArg(D) = Vp. int[p] for an integer- valued exception \nD. For an exception handler try al with x + uz (rule 9), the effect (pi of al is injected in the type \nexn[cpr] assumed for 2 in az. The most interesting rule is rule 6 for the match con-struct. This rule \nis crucial to the precision of our exception analysis. When typing match al with p -+ a2 1 x + as, we \nwant to reflect the fact that the second alternative (Z + aa) is selected only when the first alternative \n(p + a~) does not match the value of al. In other terms, the type of values that can flow to x in the \nsecond alternative is not the type of the matched value al, but the type of ai from which we have excluded \nall values matching the pattern p in the first alternative. To achieve this, rules 14-17 define the pattern \nsubtrac-tion predicate t T -p ?rt T , meaning that T is a correct type for the values of type T that \ndo not match pattern p. For a variable pattern p = x (rule 14), all values match the pattern, so it is \ncorrect to assume any T for the type of the non-matched values. For an integer pattern p = i (rule 15), \nwe force T to unify with int [i : Pre; 91, thus exposing in cp the set of all possible values of type \nT that are different from i. Then, we take T = int [i : K; p] for a suitable K. In particular, if that \nrr is unconstrained in the remainder of the derivation, we can take x to be a fresh presence variable \n6, thus reflecting that i is not among the possible values of type T . The rules for exception patterns \n(rules 16 and 17) are similar. If the exception has an argument, instead of changing a presence annotation, \nwe recursively subtract in the type of the argument of the exception. It is easy to see that the typing \nrules preserve the kinding invariants: if E is well-kinded and E b a : T/P, then k T wf and t cp :: EXN(0). \n3.4 Examples of typings We now show some typings derivable in our system. These are principal typings \nidentical to those found by our ex-ception analyzer. Consider first a simple handler for one exception \nC: try raise(C) with x -, match x with C -, 1 1 y ---t raise y The effect of raise(C) is C : Pre; p. \nHence, the type of x is exn[C :Pre; p]. Subtracting the pattern C from this type, we obtain the type \nexn[C : 6; p] for y. Hence the effect of the whole match expression, and also of the whole try expres-sion, \nis C : 6; p. The type is int[l:Pre; p ]. Since 6, p and p are generalizable and occur only positively, \nwe have estab- lished that no exception escapes the expression, and that it can only evaluate to the \ninteger 1. We now extend the previous example along the lines of the f ailwith example of section 2.3: \nlet failwith = Xn. raise(l)(n) > in try f ailwith(42) with x -+ match x with D(42) -, 0 1 y -+ raise \ny We obtain the following intermediate typings: Wintlmlh failwith : Va,m,pz.int[pl]-a x : exn[D(int[42 \n:Pre; ps]); ~4) : exn[D(int[42 : 6; ps]); p4] Y Thus we conclude as before that no exception escapes \nthis expression. For a representative example of higher-order functions, consider function composition: \nlet compose = Xf. Xg. Xx. f(g(x)) in compose (Xy. 0) (X2. raise(C)) 1 The type scheme for compose is \nVcu, ,R, y, p, pi, ps. (o 3 P1 p) -+ (y 2 a) 2 y -% p. The three occurrences of p express the union of \nthe effects of f and g. The application of compose above has effect C:Pre; ps. Concerning exceptions \nas first-class values, the first ex- ample from section 2.2 becomes: let test = Xexn. try raise (exn) \nwith x -+ match x with C -+ 1 1 y + raise(y) in test(C) c:s;p The type scheme for test is Vp,p , 6. exn[C \n:Pre; p] -+ int[l : Pre; p ], expressing that the function raises whatever exception it receives as argument, \nexcept C. The application test(C) has thus type int[l : Pre; pi] and effect C: 62; pz. Hence no exception \nescapes. The application test C, where C, is another exception distinct from C would have effect C: 63; \nC :Pre; ~3, thus showing that C may escape. Finally, here is an (anecdotal) example that is ill-typed \nin ML, but well-typed in our type system due to the refined typing of pattern-matching: match 1 with \nx -> x 1 e -> raise e Since the first case of the matching is a catch-all, rule 6 lets us assign the \ntype exn[/] for a fresh p to the variable e bound by the second case, even though the matched value is \nan integer. Hence the expression is well-typed, and more- over we obtain that it has type int [l : Pre; \np] and raises no exceptions (its effect is p for any p ). 3.5 Type soundness and correctness of the exception \nanalysis We now establish the correctness of our exception analysis: all uncaught exceptions are predicted \nby our effect system. This property is closely connected to the type soundness of our system. Theorem \n1 (Subject reduction) Reduction preserves typing: if Eo I- a : r/9 and a =+ a , then Eo F a : r/p The \nproof of subject reduction is mostly standard and follows [34] closely. Detailed proofs of the statements \nin this paper can be found in the technical report [14]. A key lemma is the following property of pattern \nsubtraction: Lemma 2 (Correctness of subtraction) If Eo F v : r/9 and M(v,p) is undefined (v does not \nmatch pattern p) andI-r-purl, thenEol-vv:r jp. The correctness of our exception analysis (all uncaught \nexceptions are detected) is a simple corollary of subject re-duction: Theorem 3 (Correctness of exception \nanalysis) Let a be a complete program. Assume Eo t a : r/cp and a $ raise v. Then, either v = C and cp \n= C :Pre; p for some C and cp , or v = D(v ) and 9 = D(r );9 and Eo F v : ~ 19 for some D, v ,r , (p \n. In either case, the uncaught exception v is correctly predicted in the effect 9. Type soundness for \nour non-standard type system fol-lows from the subject reduction property and the following lemma showing \nthat well-typed expressions either reduce to a value or to an uncaught exception, or loop, but never \nget stuck . Lemma 4 (Progress) If Eo F a : r/9, then either a is a value v, or a is an uncaught exception \nraise v, or there exists a such that a + a .  3.6 Principal types and inference of types and exceptions \nJust like the ML type system, our type system admits prin- cipal types, which can be computed by a simple \nextension of Milner s algorithm W, thus implementing the exception analysis. Theorem 5 (Principal unifiers) \nThe set of well-kinded types module equations (I) and (2) admits principal uni-fiers. More precisely, \nthere exists an algorithm mgu that, for all system Q of well-kinded equations between types, either returns \na substitution t.~ that is a principal solution of Q, or fails, meaning that Q has no solution. Moreover, \nthe sub-stitution t.~ preserves kinds in the following sense: for all cr, F ,~(a) wf and for all p, t \ng(p) :: K(p). In the theorem above, systems of well-kinded equations are sets Q = {ri = r,!; 9j = 9$;7rr \n= ?ri} of equations be-tween types, rows, row elements, and presence annotations such that for all i, \nt ri wf and t r,! wf, and for all j, there exists a kind K+ such that (p3 :: ~j and 95 :: Kj. The existence \nof principal unifiers follows from the fact that our equational theory is syntactic and regular [22]. \nThe algorithm mgu is given in appendix A. Theorem 6 (Principal types) There exists a type infer-ence \nalgorithm W satisfying the following conditions: (Correctness) If E is well-kinded and (r,cp, 0) = W(E,a) \nis defined, then O(E) F a : rfcp. (Completeness) If E is well-kinded and there exists a kind-preserving \nsubstitution 8 and types r ,(p such that O (E) I- a : 8/p , then (T, (o, 0) = W(E, a) is de-fined and \nthere exists a substitution $ such that r = q(7) and cp = G(q) and e (v) = $(0(u)) for all type, row \nor presence variable v not used as a fresh variable by algorithm W. The algorithm W is shown in appendix \nB. 4 Extension to the full Objective Cam1 language In this section, we discuss the main issues in extending \nthe analysis presented in section 3 to deal with the whole Ob-jective Cam1 language [15]. 4.1 Datatypes \nUser-defined datatypes (sum types) can be approximated in several different ways, depending on the desired \ntrade-off between precision and speed of the analysis. We have con- sidered the four approaches listed \nbelow (from most precise to least precise). 4.1.1 Full approximation of datatypes The first approach \napplies to datatypes the same treatments as for exceptions: we annotate the type by a row p approx- imating \nthe possible values of that type, as constant con-structors with presence annotations, and unary constructors \nwith types of arguments. Consider the source-level datatype definition type d t = Cl 1 . . . 1 C, 1 D1 \nof ~1 1 . . . 1 D, of pLm. where the p1 are unannotated ML types. The propagation of approximations \nis captured by the following type schemes assigned to the constructors Ci and Di: Ci : VZ, p . CT! t[Ci \n: Pre; p ] Di : V6!,p ,~ ,p . pi c Z t[Di(Ti); p ] where Ti is the annotated type obtained from pi by \nadding distinct fresh row variables taken from jTon every type con-structor that carries a row annotation. \nFor instance, given the declaration type intlist = Nil I Cons of int * intlist we assign Nil and Cons \nthe type schemes Nil : Vp. intlist[Nil : Pre; p] Cons : V~1,~2,~3,~4.int[pl] x intlist[pz] 4 intlist[Cons(int[pl] \nx intlist[pz]);p4] Recursive datatypes such as intlist above naturally lead to recursive type expressions. \nConsider: let tail = xx. match x with Cons(hd,tl) + tl I 1 ---f 1 During inference, tl and 1 receive \ntypes intlist[pl] and intlist [Cons(int [pz] X intlist [PI]); ps] respectively. If only finite type expressions \nare allowed, those two types have no unifier and the program is rejected by the analysis. This is not \nacceptable, so we extend our type system with recursive (infinite, regular) type expressions. On the \nex-ample above, we obtain pea. intlist[Cons(int[pz] x cy); ~31. The extension of our type system with \nrecursive type expressions involves replacing term unification by graph unification in the type inference \nalgorithm, but this causes no technical difficulties. 4.1.2 Looped approximations for recursive datatypes \nThe approximation scheme described above has the unde- sirable side-effect of recording in the type approximation \nthe whole structure of a data structure given in exten-sion. If the data types involved are recursive, \nwe may end up with very large type approximations. Continu-ing the intlist example above, consider the \nexpression !, = Cons(il, Cons(i2,. , Cons(i,,Nil).. .)). With the type of Cons given above, this expression \nis given an annotated type that is of depth n and records not only the fact that the list contains the \nintegers il.. .i, (an information that might be useful to analyze exceptions), but also the fact that \nthe list has length n and that its first element is il, the second ia, etc. The latter piece of information \nis, on practical examples, useless for analyzing exceptions. Moreover, such large approximations slow \ndown the analysis. A solution to this problem comes from the following re-mark: as soon as one of those \nbig data structures given in extension is passed to a sufficiently complex function, its big, unfolded \nannotated type is going to be unified with a recursive type, forcing all the information in the big type \nto be folded back into a smaller recursive type. For instance, if we pass the list e, to the tail function \nshown above, the type of the list will be unified into 7n = P(Y. intlist[Cons(int[il : Pre; . . ; i, \n: Pre; p1] X a); Nil : Pre; pz] The idea, then, is to force this folding into a recursive type when \nthe data structure is created, by giving recursive, pre- folded types to the data type constructors. \nThis is easily achieved by unifying, in the type of the constructors, all occurrences of the recursively-defined \ntype in argument po- sition with the occurrence of the recursively-defined type in result position. For \ninstance, in the case of the Cons con- structor of type intlist, we start with the type int[pl] x intlist[pz] \n4 intlist [Cons(int [pl] X intlist [pz]); p4] as in the previous section, then unify the two under- \nlined intlist types, then generalize the free variables, obtaining Cons : Vp1,ps,p4. int[pl] x T 2 T \nwhere T is pcu.intlist[Cons(int[pl] x a); ~41. With this type for Cons, the list e, is given the reasonably \ncompact type TV shown above. This technique of looping the types of constructors also works for parameterized \ndatatypes, as long as they are reg- ular (the data type constructor is used with the same pa-rameters \nin the argument types of the constructors). For non-regular datatypes such as a nreg = Leaf of a 1 Node \nof a list nreg type the unification of the occurrences of t in the type of Node would render that constructor \nessentially useless. Fortu-nately, such non-regular data types are extremely rare in actual programs, \nso we can use full approximations for them without impacting performance. 4.1.3 Adding row parameters \nto datatypes An alternative to annotating datatype constructors with rows is to add row parameters to \nthe type constructor re-flecting the row annotations on exn, int and function types contained within \nthe datatype. This technique is used by Fahndrich et al [4]. For instance, the ML datatype defini-tion \n= A of int I B of exn I C of t 1 D of t type t is turned into type (pl,pz) t = A of int[pl] I B of exn[pz] \n1 C of (p1,p2> t 1 D of (p~,pz> t Two parameters pr and pz were added in order to reflect in the type \nt the possible values of types int and exn contained in that type. The type t itself is not annotated \nby a row recording which constructors A, B, C and D are present in values of that type. The net effect \nis to forget the structure of terms of type t, while correctly remembering the integers and exception \nvalues contained in the structure. In practice, this solution appears to be slightly less pre- cise and \nslightly more efficient than full approximations of non-recursive datatypes and looped approximations \nof re-cursive datatypes: type expressions are smaller, but in the case oft above, looped approximations \ncan express the fact that a value of type t lack one of the constructors C or D, while this is not captured \nin the solution based on extra row parameters. On datatypes that are not annotated by a row, we can no \nlonger perform type subtraction during pattern-matching, since we have no approximation on the structure \nof values of that type. Hence, we simply consider that subtraction is the identity relation on those \ndatatypes. 4.1.4 Datatypes without any approximations For maximal speed and minimal precision, we can \nput no annotations at all on a datatype (neither a row approxima- tion nor extra row parameters). This \nway, we forget not only the structure of values of that type, but also the excep- tions, functions and \nbase values contained in that type. Of course, this forces us to make very pessimistic assumptions on \nvalues extracted from a datatype without approximation. For instance, if we extract an integer by pattern-matching \non such a datatype, we must give it type int[T] since it can really be any integer. This is reflected \nin the types of con- structors by putting T annotations on all annotated types in the constructor argument. \nIn the intlist example above, if we choose not to annotate intlist at all, we must give its constructors \nthe following types: Nil : intlist Cons : Vpl. int[T] x intlist 2 intlist This approach assumes that \nwe have T annotations for all types, while the type system from section 3 only has T for type int. However, \nwe can allow T to annotate other base types such as float and string. For exceptions and other datatypes, \nsince there are finitely many constructors, we can use a (potentially recursive) row enumerating all \ncon- structors of the datatype instead of a built-in constant T. In the case of lists, for instance, \nwe can use the following top row Trist(o, p): Tri.t(o, p) = @cup .Nil : Pre; Cons(o. X cy list[p ]); \np The annotated type 7 list[Tli.t(r, p)] correctly represents any list of elements of type 7. The no \napproximation approach described in this para- graph may look excessively coarse, but is actually quite \nef- fective for datatypes that introduce no base types, exception types, nor function types. Prominent \nexamples are the built- in ML types LY list and a array, where the CY parameter already records all the \ninformation we need about list and array elements. For instance, a list of functions from inte- gers \nto booleans has type (int[pr] 4 bool[cpa]) list, where pz denotes the union of the effects of all functions \npresent in the list. A function extracted from that list and applied has effect cpz, and not any exception \nas one might naively expect.  4.1.5 Choosing a datatype approximation The choice between the four datatype \nanalysis strategies described above can be done on a per-datatype basis, depending on the shape of the \ndatatype definition. We have considered several simple heuristics to perform this choice. Our first prototype \nused full approximations for non-parameterized datatypes, and no approximations for parameterized datatypes. \nOur current prototype uses full approximations for non-recursive or non-regular datatypes, looped approximations \nfor recursive datatypes, and no approximations for built-in types without interesting structure (arrays \nand floating-point numbers, for instance). Another factor that we plan to integrate in the heuristic \nis whether the datatype introduces any exception type, function type, or base type likely to be an exception \nargument (string and int, essentially); if not, we could favor the no approximation approach.  4.2 Tuples \nand records Tuple types are not approximated specially: each com-ponent of the tuple type carries its \nown annotation. For instance, intIl:Pre; 2:Pre; p] X int[3:Pre; 4:Pre; p ] stands for the set of four \npairs {1;2} x {3;4}. Pattern subtraction on tuple types is not pointwise subtraction, which would lead \nto incorrect results. Consider the type int[l : Pre; p] x int[2 : Pre; 3 : Pre; $1. Subtracting pointwise \nthe pattern (1,2) from this type would lead to type int[l : 6; p] x int[2 : 6 ; 3 : Pre; p ], which is \nincorrect since the value (1,3) is no longer in the set. Therefore, the current implementation perform \nno subtraction on tuples: we take b (71 x ~22) -(pl,pz) d TI x ~2. For a more refined behavior, we could \nperform subtraction on one of the components if all other components are matched against catch-all patterns. \nFor instance, we could take l-(71 x 72) -(Pl,ZZ) ~~;Xr2iift-rr-pr~~~. Unlike in SML, records in Cam1 \nare declared and matched by name. We analyze them like datatypes, by annotating the name of the record \ntype by a row of a partic-ular form. The row contains exactly one element recording the annotated type \nof every field. Pattern subtraction for record types behaves as in the case of tuples. To summarize, \nthe extended type algebra for datatypes, tuples and records is as foIlows: Type expressions: 7::=... \napproximated type constructor l?t non-approximated type constructor 1 71 x . . . X r, tuple type Row \nelements: E ::= . . . 1 {Zbll : T-~;. . . ; Zbl, : 7-n} I 7 tbl  4.3 Mutable data structures Mutable \ndata structures (references, arrays, records with mutable fields) are triviallv handled: it suffices \nto introduce the standard value restr&#38;ion on let-generalization [32]. This results in a precise approximation \nof mutable data. For instance, an array of functions has type (ri 3 rs) array, where cp is the union \nof the latent effects of all functions stored in the array. In contrast, control-flow analyses would \nlose track of which functions are stored in the array, and thus also of the exceptions they may raise, \nunless supplemented by a region (aliasing) analysis. 4.4 Objects and classes Because our system already \nuses recursive types, OCaml-style objects do not add significant complexity to our frame- work. We just \nneed to extend the type algebra with object types, that is, polymorphic records of methods [24]. The \ntype of each method is annotated by its latent effect. No extension to rows and row elements are needed. \nSince there are no object patterns in pattern-matching, pattern subtrac- tion needs not be modified. \nThe OCaml class language interferes very little with the exception analysis. No significant modifications \nto the class type-checker are needed. 4.5 Modules and functors Structures are assigned annotated signatures \ncontaining an-notated types for the value components. Type abbrevia-tions are currently handled by systematic \nexpansion of their definitions3. For matching a structure S against a signature C, there are two possible \nsemantics. The opaque semantics says that the only things known about the restriction (S : C) is what \nC publicizes. In our case, since user-provided signatures C contain no annotations, this amounts to forgetting \nthe result of the analysis of S and assume T annotation on all value components of the restricted structure. \nThe transparent se-mantics simply check that S matches C, but the restriction (S : C) retains all information \nknown about S. We imple- mented the transparent semantics, as the opaque semantics results in too much \ninformation loss. (The opaque semantics also precludes choosing datatype annotations based on the definition \nof the datatype.) Similar problems arise with functors. All is known about the parameter of a functor \nis its syntactic signature. Hence, a naive analysis would assume T annotation on all compo- nents of \nthe functor argument. For better precision, one could use techniques based on conjunctive types such \nas [25]. Other issues with functors are still unclear, such as 3This might cause performance problems \nin conjunction with OCaml objects, which relies intensively on type abbreviations to make type expressions \nmore manageable [24]. If this turns out to be a prob- the generativity of exception declaration in functor \nbodies, and the impact of the exception polymorphism offered by functors (a functor can take one or several \nexceptions as arguments, and have a different exception behavior depend- ing on whether those arguments \nare instantiated later with identical or different exceptions). For simplicity, we chose not to analyze \nfunctors when they are defined, but instead expand the functor body at each application and re-analyze \nthe P-reduced body. Al-though this transformation increases the size of the analyzed source, the Cam1 \nprograms we are interested in do not use functors intensively and this simple approach to analyzing functors \nworks well in practice. 4.6 Separate analysis Transparent signature matching precludes true separate \nanalysis (where any module can be analyzed separately knowing only the syntactic signatures of the modules \nit imports). We can still do bottom-up separate analysis, however: a module can be analyzed separately \nprovided the implementations of its imports have been analyzed already, and their annotated signatures \ninferred. Since annotated signature for a module may contain free row variables (e.g. if the module defines \nmutable structures), separately analyzing several clients of that module may re- sult in independent \ninstantiations of those free variables. Those instantiations are recorded in the result of the anal- \nysis of each module, and reconciled in a final linking pass before displaying the results of the analysis. \n 4.7 Polymorphic recursion Polymorphic recursion as introduced by Mycroft [17] is not needed to type-check \nthe source OCaml language, but is de- sirable to enhance the precision of our exception analyzer. With \nML-style monomorphic recursion, we obtain false pos- itives on functions that recursively call themselves \ninside a try.. .with. Consider: let ret f = Xx. try f(x) with C -+ 0 I y -+ raise y The latent effect \ninferred for f is C; p because the effect of f(x) is unified with the type of the pattern C at a time \nwhere the type off is not yet generalized. With polymorphic recursion, we can assign f the type scheme \nVa, p. a z unit both outside and inside the recursion; it is a fresh instance of that type scheme that \ngets unified with the type of C, thus not polluting the type scheme of f. Although type inference with \npolymorphic recursion is undecidable [13], there exists incomplete inference algo-rithms that work very \nwell in practice. We experimented with Henglein s algorithm [ll] and with a home-grown al-gorithm based \non restricted fixpoint iteration and obtained good results. 5 Experimental results In this section, we \npresent some experimental results obtained with our implementation. Currently, our analyzer implements \nall extensions described in section 4 except objects4. The analyzer is compiled with the OCaml 2.00 native-code \ncompiler and runs on a Pentium II 333 Mhz workstation under Linux. lem, we could also handle abbreviations \nby adding extra row parame- 4The analysis of objects and classes was prototyped separately and ters to \nthe type constructors, as described in [4] and in section 4.1.3. remains to be merged in our main implementation. \nTest program 1. Huffman compression 2. Knuth-Bendix 3. Docteur (Eliza clone) 4. Lexer generator 5. \nNucleic 6. OCaml standard library 7. Analyzer of .h files 8. Our exception analyzer 9. The OCaml \nbvtecode compiler  Size (lines) 233 441 556 1169 2919 3082 3088 12235 17439 T Analysis time 0.07/0.08 \ns 0.14/0.16 s 0.81/0.83 s 0.2710.32 s 1.90/1.88 s 2.5212.52 s 0.5410.58 s 10.3/16.1 s 12.6122.9 s 1 Analysis \nspeed (lines per sec.) 3300/2900 l/s 3200/2800 l/s 6801670 l/s 4300/3700 l/s 1530/1550 l/s 1200/1200 \nl/s 5700/5300 l/s 1200/760 l/s 1400/760 l/s OCaml type-checking time  0.08 s 0.14 s 0.10 s  0.20 \ns 0.62 s 1.89 s  0.27 s 3.86 s 4.00 s  Figure 4: Experimental results (without polymorphic recursion/with \npolymorphic recursion) Analysis speed: Figure 4 gives timings for the analysis of various small to medium-sized \nOCaml programs. We give timings both without and with polymorphic recursion. For comparison, we also \ngive the time OCaml takes to parse and type-check those programs. (The timings given include parsing \nand pre-processing as well as analysis time.) The overall performances are quite good, in the order of \n1000-2000 lines of source per second. Programs that contain large data structures given in extension \n(Nucleic, Docteur) take longer to analyze due to the large size of the rows an- notating the types of \nthose data structures. On average, the exception analysis takes twice as much time as OCaml type inference; \nthe ratio ranges between 1 (on simple pro-grams) and 8 (on Docteur, because of the large constant data \nstructures). Polymorphic recursion slows down the analysis somewhat on the largest benchmarks, but the \nslowdown re-mains acceptable compared with the increase in precision. Precision of the analysis: We have \nmanually inspected the output of the analyzer on our benchmark programs. Pro-grams 1, 3, 4, 5 and 7 have \na relatively simple exception behavior, and our analysis reports exact results for those programs: there \nare no false positives except run-time errors such as division by zero or array index out of bounds , \nwhich require extra analyses (or even general program proof) to show that they cannot occur. For Knuth-Bendix, \nwhich has a quite complicated excep-tion structure, 8 exceptions (Failure with 8 different string arguments) \nappearing in the source are correctly reported as non-escaping; 7 exceptions (one Invalid_argument and \n6 Failure) are reported as potentially escaping, and can actually occur in some circumstances. Without \npolymor-phic recursion, the analysis reports two false positives (one Not-found and one Failure), which \ncorrespond to recur-sive functions containing try . . . with around recursive calls. Adding polymorphic \nrecursion as discussed in section 4.7 removes one of those false positives. The other one is still there, \nbecause our incomplete inference algorithm for poly- morphic recursion fails to give a type polymorphic \nenough to one of the functions. A more precise algorithm such as Hen- glein s [ll] would probably eliminate \nthe other false positive as well. The larger examples 8 and 9 exhibit another source of false positives: \nmutable data structures (references and ar-rays) containing functions. As mentioned in section 4.3, the \nrow variables appearing in approximations of mutable data structures are not generalized, hence collect \nall exceptions at their use sites. For instance: let r = refotx. . ..> in typing f, the effect of raise \nC is unified with that of ! r y, hence p becomes C : Pre; p and the application ! r 0 appears to raise \nC. let f = xy. if in !r 0 cond then !r y else raise C r has type int -% int where p is not generalized. \nWhen 6 Related work 6.1 Exception analyses for ML Several exception analyses for ML are described in \nthe lit- erature. Guzmdn and Sukez [8] develop a simple type and effect system to keep track of escaping \nexceptions. Their system does not handle exceptions as first-class values, nor exceptions carrying arguments. \nThe first exception analysis proposed by Yi [35] is based on general abstract interpreta-tion techniques, \nand runs too slowly to be usable in practice. Later, Yi and Ryu [36] developed a more efficient analysis \nroughly equivalent to a conventional control-flow analysis to approximate the call graph and the values \nof exceptions, followed by a data-flow analysis to estimate uncaught ex-ceptions. Fahndrich and Aiken \n[3, 41 have applied their BANE toolkit for constraint-based program analyses to the prob- lem of analyzing \nuncaught exceptions in SML. Their system uses a combination of inclusion constraints (as in control- \nflow analyses) to approximate the control flow, and equality constraints (unification) between annotated \ntypes to keep track of exception values. To compare performances between [36], [3] and our ana- lyzer, \nwe used two of our benchmarks for which we have a faithful SML translation: Knuth-Bendix and Nucleic. \nThe times reported below are of the form tr/tz, where tl is the time spent in exception analysis only, \nand t2 is the total program analysis time, including parsing and type-checking in addition to exception \nanalysis. Test program Yi-Ryu BANE Knuth-Bendix 1.2/1.5 s 1.612.2 s Nucleic 3.817.8 s 3.317.6 s From \nthese figures, our exception analysis us 0.06/0.14 s 1.4511.86 s seems notably faster. However, there \nare many external factors that influ- ence the total running times of the analyses (such as the Yi- Ryu \nand BANE analyses being compiled by SML/NJ while ours is compiled by Objective Caml), so the figures \nabove are not conclusive. The main difference between the analyses of [36, 31 and ours is the approximation \nof arguments carried by excep- tions: they approximate only exception and function values carried by \nexceptions, but our analysis is the only one that also approximates exception arguments that are strings, \nin- tegers, or datatypes. As explained in section 2.3, approxi- mating all arguments of exceptions is \ncrucial to obtain pre- cise analysis of many real applications. In theory, our unification-baaed analysis \nshould be less precise than analyses based on inclusion constraints such as [36, 31: the bidirectional \npropagation of information per-formed by unification causes exception effects to leak in types where \nthose exceptions cannot actually occur. It is easy to construct artificial examples of such leaks, e.g. \nby re- placing let-bound identifiers by X-bound identifiers. How-ever, those examples do not seem to \noccur in actual pro-grams. The only leaks we observed in actual programs were related either to deficiencies \nof our incomplete algorithm for typing polymorphic recursion, or to functions contained in-side mutable \ndata structures. On those two cases, [3] obtains more precise results than our analysis. 6.2 Other related \nwork Our use of rows with row variables and presence annotations to approximate values of base types \nand sum types is essen- tially identical to R&#38;my s typing of extensible variants [21]. Another application \nof R&#38;my s encoding is the soft typing system for Scheme of [33]. There is a natural connection between \nexception anal-ysis and type inference for extensible variants: using the well-known functional encoding \nof exceptions (where each subexpression is transformed to return a value of a variant type, either an \nexception tag or NormalResult where v is the value of the subexpression), estimating uncaught excep- \ntions is equivalent to inferring precise variant types. Pottier (201 outlines an exception analysis thus \nderived from a type inferencer for ML with subtyping. Refinement types [7] also introduce annotations \non types to characterize subsets of ML s data types. Our approach is less ambitious than refinement types, \nin that it does not try to capture deep structural invariants of recursive data structures; on the other \nhand, type inference is much easier. The principles of effect systems were studied extensively in the \nearly 90s [16, 281, but few practical applications have been developed since. An impressive application \nis the re-gion analysis of Tofte et al. [30, 291. Like ours, its precision is improved by typing recursion \npolymorphically. Several program analyses based on unification and run-ning in quasi-linear time have \nbeen proposed as faster alter- natives to more conventional dataflow analyses. Two well-known examples \nare Henglein s tagging analysis [lo] and Steensgaard s aliasing analysis 127). Baker [l] suggests other \nexamples of unification-based analyses. 7 Conclusions and future work It is often said that unification-based \nprogram analyses are faster, but less precise than more general constraint-based analyses such as CFA \nor SBA. For exception analysis, our experience indicates that a-combination of unification, let-polymorphism, \nand polymorphic recursion is in practice al-most as precise as analyses based on inclusion constraints. \n(The only case where our analysis is noticeably less precise than inclusion constraints is when references \nto functions are used intensively.) The running times of our algorithm seem excellent (although its theoretical \ncomplexity is at least as high as that of ML type inference). In turn, this good ef-ficiency of our analysis \nallows us to keep more information on exception arguments than the other exception analyses, increasing \ngreatly the precision of the analysis on certain ML programs. Thus, we see an interesting case of less \nis more , where an a priori imprecise technology (unification) allows to improve eventually the precision \nof the analysis. Some engineering issues remain to be solved before our analysis can be applied to large \nML applications. The main practical issue is displaying the results of the analysis in a readable way. \nThe volume of information contained in annotated type expressions can be overwhelming. The pro- grammer \nshould be able to select different levels of display abstracting some of that information. Acknowledgements \nThe inference algorithm for polymorphic recursion used in our implementation was designed in collaboration \nwith Pierre Weis. We thank Francois Pottier and Didier Remy for interesting discussions. References H. \nG. Baker. Unify and conquer (garbage, updating, PI aliasing, . . . ) in functional languages. In Lisp \nand Func-tional Programming 1990. ACM Press, 1990. M. Fahndrich and A. Aiken. Making set-constraint PI \nbased program analyses scale. Technical Report 96-917, University of California at Berkeley, Computer \nScience Division, 1996. M. Fahndrich and A. Aiken. Program analysis using 131 mixed term and set constraints. \nIn Static Analysis Symposium 97, number 1302 in LNCS, pages 114-126. Springer-Verlag, 1997. M. Fahndrich, \nJ. S. Foster, A. Aiken, and J. Cu. Track- 141 ing down exceptions in Standard ML programs. Tech-nical \nreport, University of California at Berkeley, Com- puter Science Division, 1998. M. Fahndrich, J. S. \nFoster, Z. Su, and A. Aiken. Partial PI online cycle elimination in inclusion constraint graphs. In Prog. \nLang. Design and Impl. 1998, pages 85-96. ACM Press, 1998. C. Flanagan and M. Felleisen. Componential \nset-based I61 analysis. In Prog. Lang. Design and Impl. 1997. ACM Press, 1997. T. Freeman and F. Pfenning. \nRefinement types for ML. PI In Prog. Lang. Design and Impl. 1991, pages 268-277. ACM Press, 1991. J. \nC. Guzmdn and A. Suirez. A type system for ex- 181 ceptions. In Proc. 1994 workshop on ML and its appli-cations, \npages 127-135. Research report 2265, INRIA, 1994. N. Heintze. Set-based analysis of ML programs. In Lisp \nPI and Functional Programming 94, pages 306-317. ACM Press, 1994. [lOI F. Henglein. Global tagging optimization \nby type infer- ence. In Lisp and Functional Programming 199.2. ACM Press, 1992. WI Nl [I31 [I41 1151 \n1161 [I71 Ml WI 1201 1211 [221 I231 [241 I251 1261 [271 I281 F. Henglein. Type inference with polymorphic \nrecur-sion. ACM Trans. Prog. Lang. Syst., 15(2):253-289, 1993. S. Jagannathan and A. Wright. Polymorphic \nsplitting: An effective polyvariant flow analysis. ACM Trans. Prog. Lang. Syst., 20(1):166-207, 1998. \nA. J. Kfoury, J. Tiuryn, and P. Urzyczyn. Type re-construction in the presence of polymorphic recursion. \nACM Truns. Prog. Lang. Syst., 15(2):290-311, 1993. X. Leroy and F. Pessaux. Type-based analysis of un-caught \nexceptions. Research report 3541, INRIA, Nov. 1998. Extended version of this paper. X. Leroy, J. Vouillon, \nD. Doligez, et al. The Objective Cam1 system. Software and documentation available on theWeb,http://caml.inria.fr/ocaml/, \n1996. J. M. Lucassen and D. K. Gifford. fect systems. In 15th symp. Principles pages 47-57. ACM Press, \n1988. Poof lymorphic Progr. Lang., ef- A. Mycroft. Polymorphic type schemes and recursive definitions. \nIn International Symposium on Program-ming, number 167 in LNCS, pages 217-228. Springer-Verlag, 1984. \nA. Ohori. A polymorphic record calculus and its com- pilation. ACM Trans. Prog. Lang. Syst., 17(6):844-895, \n1995. F. Pottier. A framework for type inference with sub- typing. In Int. Conf. on Functional Progr. \n1998, pages 228-238. ACM Press, 1996. F. Pottier. Type inference in the presence of subtyping: from theory \nto practice. Research report 3483, INRIA, Sept. 1998. D. Rkmy. Records and variants as a natural extension \nof ML. In 16th symp. Principles of Progr. Lang., pages 77-88. ACM Press, 1989. D. RBmy. Syntactic theories \nand the algebra of record terms. Research report 1869, INRIA, 1993. D. RCmy. Type inference for records \nin a natural ex-tension of ML. In C. A. Gunter and J. C. Mitchell, ed-itors, Theoretical Aspects of Object-Oriented \nProgram-ming. MIT Press, 1993. D. R&#38;my and J. Vouillon. Objective ML: A simple object-oriented extension \nof ML. In 244th symp. Princi-ples of Progr. Lang., pages 40-53. ACM Press, 1997. Z. Shao and A. Appel. \nSmartest recompilation. In 20th symp. Principles of Progr. Lang., pages 439-450. ACM Press, 1993. 0. \nShivers. Control-Flow Analysis of Higher-Order Languages. PhD thesis CMU-CS-91-145, Carnegie Mel- lon \nUniversity, May 1991. B. Steensgaard. Points-to analysis in almost linear time. In %%d symp. Principles \nof Progr. Lang., pages 32-41. ACM Press, 1996. J.-P. Talpin and P. Jouvelot. The type and effect dis- \ncipline. Inf. and Comp., 111(2):245-296, 1994. M. Tofte and L. Birkedal. A region inference algorithm. \nACM Trans. Prog. Lang. Syst., 1998. To appear. 1291 M. Tofte and J.-P. Talpin. Region-based memory man- \n I301 agement. Inf. and Comp., 132(2):109-176, 1997. / M. Wand. Complete type inference for simple objects. \nIn Logic in Computer Science 1987, pages 37-44. IEEE Computer Society Press, 1987. [311 A. K. Wright. \nSimple imperative polymorphism. Lisp and Symbolic Computation, 8(4):343-356, 1995. 1321 A. K. Wright \nand R. Cartwright. A practical soft type system for Scheme. ACM Trans. Prog. Lang. Syst., 19(1):87-152, \n1997. [331 A. K. Wright and M. Felleisen. A syntactic approach 1341 to type soundness. Inf. and Comp., \n115(1):38-94, 1994. K. Yi. An abstract interpretation for estimating un- 1351 caught exceptions in Standard \nML programs. Sci. Com-put. Programming, 31(1):147-173, 1998. K. Yi and S. Ryu. Towards a cost-effective \nestimation [361 of uncaught exceptions in SML programs. In Static Analysis Symposium 97, number 1302 \nin LNCS, pages 98-113. Springer-Verlag, 1997. A The unification algorithm In this appendix, we give \nthe unification algorithm for our type algebra modulo the two equations (1) and (2). We de- fine the \nhead constructor H(E) of a row element e as follows: H(i:r) = i H(C:r) = c H(D(T)) = D The algorithm \nhandles the left commutativity axiom (equa- tion (1)) like in [23]. mgu(0) = id Unification between \ntypes: mgu({a = a) Q) = wu(Q) mgu({a = 7) u Q) = mgu(Q{a +- 71) 0 {a + ~1 if (Y $ FV(7) mgu({~ = cx} \nQ) = mgu(Q{a +-- T)) 0 {a + 71 if QI 4 FV(T) mgu({int[cpl] = int[cpz]} U Q) = mgu({cpl = cpz) u &#38;I \nmgu({exn[cpl] = exn[w]} u Q) = mw({w = ml Q) mgu({T1 3 7; = 7z 4 T;} u Q) = mgu((71 = 722; (~1 = PZ; \nT; = 7:) u Q) Unification between rows: mgu({~ = ~1 &#38;I = mw(Q) mgu(b = ~1 &#38;I = mgu(Qb + ~1) \n0 {P + ~1 if P $ FV(cp) mgu(tio = P) &#38;I = wu(Qb + ~1) 0 {P + ~1  if P $ FV(v) mgu({T= T) u Q) = \nw(Q) mgu({(i:qcp) = T} U Q) = mgu({~ = h-e; cp = T} u Q) mgu({T = (i : n; cp)} u Q) = mgu({x = h-e; \ncp = T} u Q) mgu({(sl;w) = (~2; CPZ)) U &#38;I = mgu({a = a) u Q) if H(E~) = H(Ez) mgu({(El; cpl) = \n(~2; cpz)) u &#38;I = md{cpl = (~2; ~1; (~2 = (~1; P)) U &#38;I if H(Q) # H(a) and p is not free in the \n1.h.s. and has kind t(S U {H(Q), H(Q)}) where t(S) is the kind of ~1; cp1 and ~2; 402 Unification between \nrow elements: mgu(((i : ~1) = (i : 7r2)) u Q) = mgu({sl = m} U Q) mgu({(C:xl) = (C:nz)}UQ) = mgu({nl \n= ~2) U Q) mgu({D(n) = D(n)} U Q) = mgu((71 = 72) u Q)  Unification between presence annotations: mgu({b \n= 6) U Q) = m@(Q) mgu({S = r} u Q) = mgu(Q{6t~})o{6t~}if~#6 mgu({n = 6) u Q) = mgu(Q(6 t 7r)) o (6 +-r} \nif r # 6 mgu({Pre = Pre} U Q) = mgu(Q) If none of the cases above is applicable, mgu(Q) is undefined. \nB The type inference algorithm The result of the algorithm W(E,a) is the triple (~,cp,O) defined by induction \non a as follows: If a is 2 (with z E Dam(E)): let p be a fresh variable of kind EXN(@) take T = Inst(E(z)) \nand cp = p and 8 = id. If a is i: let p be a fresh variable of kind INT({i}) let p be a fresh variable \nof kind EXN(P)) take -r = int[i : Pre; p] and cp = p and 0 = id. If a is Xz.al: let Q be a fresh variable \nlet (~~,(~l,&#38;) = W(E@ {z : a},~) let p be a fresh variable of kind EXN(0) take 7 = O,(a) 2 71 and \ncp = p and 0 = 81. If a is al(a2): let (71,cp1,6) = W(JSal) let (TV, p2, 0,) = w(e@), a2) let cy be a \nfresh variable let p = mgu{02(T1) = 72 2 or, e2(pl) = cp2} take r = p(a) and cp = 4(p2) and 0 = ~1 o \nO2 o t$ If a is let z = al in a2: let (71,(p1,el) = W(E,al) let (72,972, e2) = we,(E) e+ {Z : Gen(n, \ne,(E), cpd}, u2) let CL = mgu{e2(+4 = (p2} taker=p(r2)andcp=p(cp2)andB=po020B1. If a is match al with \np -+ a2 1 z + a3: let (71,r(Pl,el) = W(E,al) let (J??, 7 , $) = Patsubtr(p, 71) let (72, (Pi, e2) = w(+(e,(E)) \na3 E , u2) let p3, p3, e3) = w(e,(+(e,(fq)) a3 (2 : e,(+)), a31 let CL =mgu{e3(72) = 5, e3(p2) = p3, \ne3(e2(~(d)) = (p3} take 7 = ~(7~3) and 1p = ~(93~) and 0 = p o O3 o O2 o $ o &#38;. If a is C: let p \nbe a fresh variable of kind EXN({C}) let p be a fresh variable of kind EXN(!?l) take 7 = exn[C : Pre; \np] and cp = p and 19 = id. If a is D(al): let (~l,pl,el) = W(E,al) let 72 = Inst( TypeArg(D)) let p = \nmgu(T2 = 71) let p be a fresh variable of kind EXN({D}) let p be a fresh variable of kind EXN(0) take \nT = exn[D(p(Tl)); p] and cp = p and 8 = p o &#38;. Ifaistry al with z+az: let (TI,(pl,el) = W(E,m) let \n(72,(p2,e2) = w(e,(-q a? {~::xn[cp~]}, a2) let p = mgu{02(71) = 72} take 7 = ~(7~) and cp = ~(93~) and \n8 = p o O2 o 64. The auxiliary function Inst(a) (trivial instance): Inst(Vcq,P,,&#38;.7) is ~{cy( + \ncui,pj +-pi,&#38; c 6;) where cr:, pi, 6; are fresh variables such that pj and pj have the same kind \nfor all j. The auxiliary function Patsubtr (typing of patterns and pattern subtraction): Patsubtr(p, \nT) is the triple (E, T , 0) defined by induction on p as follows: If p is 2: let (Y be a fresh variable \ntake E = {x : r} and r = cy and t9 = id. If p is i: let p be a fresh variable of kind INT({i}) let p \n= mgu{T = int[i : Pre; p]} let 6 be a fresh presence variable take E = 0 and 7 = int[i : 6; p(p)] and \nB = ~1. If p is C: let p be a fresh variable of kind EXN( { C}) let p = mgu{T = exn[C : Pre; p]} let \nS be a fresh presence variable take E = 0 and 7 = exn[C : 6;p(p)] and 6 = CL. If p is D(pl): let ~1 = \nInst( TypeArg(D)) let (&#38;, 7:, &#38;) = Patsubtr(pl, ~~) let p be a fresh variable of kind EXN({D}) \nlet p = mgu(7 = exn[o(O,(-r,)); p]} take E = p(E1) and 7 = exn[O(p(T;));&#38;)] and 8 = PO&#38;.   \n\t\t\t", "proc_id": "292540", "abstract": "", "authors": [{"name": "Fran&#231;ois Pessaux", "author_profile_id": "81100082929", "affiliation": "INRIA Rocquencourt, projet Cristal, B.P. 105, 78153 Le Chesnay, France", "person_id": "P84951", "email_address": "", "orcid_id": ""}, {"name": "Xavier Leroy", "author_profile_id": "81100078576", "affiliation": "INRIA Rocquencourt, projet Cristal, B.P. 105, 78153 Le Chesnay, France", "person_id": "PP39026141", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/292540.292565", "year": "1999", "article_id": "292565", "conference": "POPL", "title": "Type-based analysis of uncaught exceptions", "url": "http://dl.acm.org/citation.cfm?id=292565"}