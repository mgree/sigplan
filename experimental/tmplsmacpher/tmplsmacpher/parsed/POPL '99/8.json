{"article_publication_date": "01-01-1999", "fulltext": "\n Parametric Shape Analysis via 3-Valued Logic Mooly Sagiv* Thomas Reps+ Reinhard Wilhelm* Tel-Aviv Univ. \nUniv. of Wisconsin Univ. des Saarlandes Abstract We present a family of abstract-interpretation algorithms \nthat are capable of determining shape invariants of programs that perform destructive updating on dynamically \nallocated storage. The main idea is to represent the stores that can pas-sibly arise during execution \nusing three-valued logical struc- tures. Questions about properties of stores can be answered by evaluating \npredicate-logic formulae using Kleene s semantics of three-valued logic: . If a formula evaluates to \ntrue, then the formula holds in every store represented by the three-valued structure. . If a formula \nevaluates to false, then the formula does not hold in any store represented by the three-valued structure. \n. If a formula evaluates to unknown, then we do not know if this formula always holds, never holds, or \nsometimes holds and sometimes does not hold in the stores repre- sented by the three-valued structure. \nThree-valued logical structures are thus a conservative repre-sentation of memory stores. The approach \ndescribed is a parametric framework: It pro- vides the basis for generating a family of shape-analysis \nal-gorithms by varying the vocabulary used in the three-valued logic. 1 Introduction Data structures \nbuilt using pointers can be characterized by invariants describing their shape at stable states, i.e., \nin be- tween operations on them. These invariants are usually not preserved by the execution of individual \nprogram statements, and it is challenging to prove that invariants are reestab-lished once a sequence \nof operations is finished [9]. In the past two decades, many shape-analysis algorithms have been developed \nthat can automatically identify shape invari- ants in some programs that manipulate heap-allocated stor-age \n[ll, 12, 15, 10, 2, 21, 1, 16, 22, 191. A common feature of these algorithms is that they represent heap \ncells by shape- nodes and sets of indistinguishable run-time locations by a single shape-node, often \ncalled a summary-node [2]. One *Supported in part by the U.S.-Israel BSF under grant 96-00337. Address: \nDept. of Camp. Sci.; Tel-Aviv Univ.; Tel-Aviv 69978; Israel. E-mail: sagivOmath.tau.ac.il. Supported \nin part by the NSF under grants CCR-9625667 and CCR- 9619219, by the U.S.-Israel BSF under grant 96-00337, \nby grants from Rockwell and IBM. and bv a Vilas Associate Award from the Univ. of Wisconsin. Address: \nC&#38;p. Sci. Dept.; Univ. of Wisconsin; 1210 W. Daytod St.; Madison, WI 53706; USA. E-mail: repsQcs.wisc.edu. \n*Supported in part by a DAAD-NSF Collaborative Research Grant. Address: Fachbereich 14 Informatik; Univ. \ndes Saarlandes; 66123 Saarbriicken; Germany. E-mail: wilhelmQcs.uni-sb.de. Permission to make digital \nor hard copies ofall or parl ufthis work for personal or classroom me is granted withwt fee procided \nthat copies are not made or distrihutcd for profit or cnrnmercinl advantage IIKI that copies bear this \nnotice and the full citation on the first page. To copy otherwise. to republid~, to post on sewers or \nto redistribute tn lists, requires prior specific permission anJ!or a fee. POPL 99 San Antonio TexasUSA \n Copyright ACM 1999 l-581 13-095-3/99/01...$5.00 way of looking at these algorithms is that shape graphs \nare indirect representations of store invariants.   1.1 Main Results This paper presents a parametric \nframework for shape analy- sis. Different instantiations of the framework allow the usage patterns of \ndifferent kinds of data structures in a program to be observed, or allow the usage patterns of data structures \nto be observed with different levels of precision and efficiency. The ideal is to have a fully automatic \nmethod-a yacc for shape analysis, so to speak. The designer of a shape-analysis algorithm would supply \nonly the specification, and the shape- analysis algorithm would be created automatically from this specification. \nThis can be achieved by means of the methods presented in this paper. Moreover, the framework allows \nus to create algorithms that are more precise than the above-cited algorithms. In particular, by tracking \nwhich run-time locations are reachable from which program variables, it is often possible to deter-mine \nprecise shape information for programs that manipulate several (possibly cyclic) data structures. Other \nstatic-analysis techniques (including ones that are not based on shape graphs [14, 6, 8, 4, 51) yield \nvery imprecise information on these pro- grams. 1.1.1The Use of Logic for Shape Analysis In our shape-analysis \nframework, predicate-logic formulae play many roles: expressing both the concrete and abstract seman- \ntics of the programming language, expressing properties of store elements (e.g., may-aliases, must-aliases), \nand express- ing properties of stores (e.g., data-structure invariants). For instance, the predicate \nZ(V) expresses whether pointer variable x points to heap cell u; the binary predicate n(ui, vz) express \nwhether the n-component of heap cell ~1 points to heap cell uz; to specify the effect of the statement \nx = x->n on variable x (part of the concrete semantics), we write the formula z (v) = 3?Ji : Z(Vl) A \nn(w1, v). (1) This indicates that after this statement, variable x points to a heap cell that was formerly \npointed to by x->n. To express the property program variables x and y are not may-aliases , we write \nthe formula vu : +r( u) A y(v)). (2) 1.1.2 Shape Analysis via Three-Valued Logic We use Kleene s three-valued \nlogic [13] (which has a third truth value that signifies unknown ) to create a shape-analysis algorithm \nautomatically from a specification. Kleene s logic is useful for shape analysis because we only have-partial \ninfor-mation about summary nodes: For these nodes, predicates may have the value unknown. One of the \nnice properties of Kleene s three-valued logic is that the interpretations of for- mulae in two-valued \nand three-valued logic coincide on true and false. This comes in handy for shape analysis, where we wish \nto relate the concrete (two-valued) world and the ab-stract (three-valued) world: The advantage of using \nlogic is that it allows us to make a statement about both the concrete and abstract worlds via the same \nformula-the same syntac- tic expression can be interpreted either as statement about the two-valued world \nor the three-valued world. In this paper, shape graphs are represented as three-valued logical structures \nthat provide truth values for every formula. Therefore, by evaluating formulae, one obtains simple algo- \nrithms for: (i) executing statements abstractly, and (ii) (con- servatively) extracting store properties \nfrom a shape graph. For example, formula (2) evaluates to true for an abstract store in which x and y \ndo not point to the same shape-node. In this case, we know that z and y cannot be aliases. For-mula (2) \nevaluates to false for an abstract store in which z and y point to the same non-summary node. In this \ncase, we know that x and y are aliases. However, the formula can evaluate to unknown when both x and \ny point to a summary- node. In this case, the analysis does not know if x and y can be aliases. In Sections \n2 and 4, we show how these mechanisms can be exploited to create a parametric framework for shape-analysis. \nThis technique suffices to explain the algorithms of [ll, 10, 2, 211. 1.1.3 Materialization of New Nodes \nfrom Summary Nodes One of the magical aspects of [19] is materialization , in which a transfer function \nsplits a summary-node into two sep- arate nodes. (This operation is also discussed in [2, 161.) This \nturns out to be important for maintaining accuracy in the analysis of loops that advance pointers through \ndata struc-tures. The parametric framework provides insight into the workings of materialization. It \nshows that the essence of ma- terialization involves a step (called focus, discussed in Sec- tion 5.1) \nthat forces the values of certain formulae from un-known to true or false. This has the effect of converting \na shape graph into one with finer distinctions. In [19], it was observed that node materialization is \ncom- plicated because various kinds of shape-graph properties are interdependent. For instance, the connections \nbetween heap cells constrain the sets of potential aliases, and vice versa. In this paper, we introduce \na mechanism for expressing (three-valued) constraints on shape graphs, which we use to capture such dependences \nbetween properties. 1.2 Limitations The results reported in the paper are limited in the following ways: \n. The framework creates intraprocedural shape-analysis algorithms, not interprocedural ones. Methods \nfor han- dling procedures are presented in [2, 1, 191. Because these are instances of the framework, \ntheir methods for handling procedures should generalize to the parametric case. . The number of possible \nshape-nodes that may arise dur- ing abstract interpretation is potentially exponential in the size of \nthe specification. We do not know how severe this problem is in practice. However, it is possible to \nde- fine a widening operator that converts a shape graph into a more compact, but possibly less precise, \nshape graph by collapsing more nodes into summary nodes. This can be used to make a shape-analysis algorithm \npolynomial, at the cost of making the results less accurate. . The number of shape graphs may be quite \nlarge (as in [ll, lo]). This problem was avoided in [15, 2, 16, 191 by keeping a single merged shape \ngraph at every point. /* reverse.c */ #include 1ist.h List reversetlist x> { List y, t; assert (acyclic-list \n(x1 > ;/* 1ist.h */ y=NuLL;typedef struct node { while (x != NULL) { struct node *n; t = y;int data; \ny = x;} *List; x = x->n; y-h = t; 1 return y; 1 (a) (b) Figure 1: (a) Declaration of a linked-list data \ntype in C. (b) A C function that uses destructive updating to reverse the list pointed to by parameter \nx. This measure has not been employed in this paper in order to simplify the presentation.  1.3 Organization \nof the Paper We explain our work by presenting two versions of the shape- analysis framework. The first \nversion is used to introduce many of the key ideas, but in a simplified setting: Section 2 provides an \noverview of the simplified version and presents an example of it in action; Section 4 gives the technical \ndetails. Section 3 presents technical details of how three-valued logic is used to define abstractions \nof concrete stores (which is needed for Section 4 and subsequent sections). Section 5 defines the more \nelaborate version of the shape-analysis framework. Due to space constraints, some aspects of the abstract \nsemantics are omitted (see [18]). Section 6 contains a short account of related work. 2 An Overview of \nthe Parametric Framework Figure l(a) shows the declaration of a linked-list data type in C, and Figure \nl(b) shows a C program that reverses a list via destructive updating. The analysis of the shapes of the \ndata structures that arise at the different points in the reverse program will serve as the subject of \nthe examples given in the remainder of the paper. The reverse program allows us to demonstrate many aspects \nof the shape-analysis framework in a nontrivial, but still relatively digestible, fashion. 2.1 Representing \nStores via Three-Valued Structures In Section 1, we couched the discussion in terms of shape- graphs \nfor the convenience of readers who are familiar with previous work. Formally, we do not work with shape-graphs; \ninstead, the abstractions of stores will be what logicians call three-valued logical structures, denoted \nby (U, L). There is a vocabulary of predicate symbols (with given arities); each log- ical structure \nhas a universe of individuals U, and L maps each possible tuple ~(2~1, . . . , uk) of an arity-k predicate \nsymbol p, where ui E U, to the value 0, 1, or l/2, (i.e., false, true, and unknown, respectively). Logical \nstructures are used to pro-vide a uniform representation of stores: Individuals represent abstractions \nof memory locations; pointers from the stack into the heap are represented by unary pointed-to-by-variable-x \npredicates; and pointer-valued fields of data structures are rep- resented by binary pointer-component-points-to \npredicates. S Structure Graphical Representation unary predicates: indiv. x y t sm is so binary predicates: \n. unary predicates: binary predicates: unary predicates: Figure 2: The three-valued logical structures \nthat describe all possible acyclic inputs to reverse. Assuming that reverse is invoked on acyclic lists, \nthe three-valued structures that describe all possible inputs to reverse are shown in Figure 2. The following \ngraphical no-tation is used for three-valued logical structures: Individuals of the universe are represented \nby circles with names inside. Summary nodes (i.e., nodes for which the value of predicate sm is l/2) \nare represented by double circles. Other unary predicates with value 1 (l/2) and binary pointer-component- \npoints-to predicates are represented by solid (dotted) arrows. Thus, in structure S2, pointer variable \nx points to element ~1, whose n field may point to a location represented by element u. u is a summary \nnode, i.e., it may represent more than one location. Possibly there is an n field in one of these locations \nthat points to another location represented by u. S2 corresponds to stores in which program variable \nx points to an acyclic list of two or more elements: . The abstract element u1 represents the head of \nthe list, and u represents all the tail elements. a The unary predicates x, y, and t are used to characterize \nthe list elements pointed to by program variables x, y, and t, respectively. . The unary predicate sm \nindicates whether abstract el-ements are - summary elements , i.e., represent more than one concrete \nlist element in a given store. Thus, sm(ul) = 0 because u1 represents a unique list element, the list \nhead. In contrast, sm(u) = l/2, because u repre- sents a single list element when the input list has \nexactly two elements, and more than one list element when the input list is of length three or more. \nThe unaxy predicate is is explained in Section 2.2. The binary predicate n represents the n fields of \nlist el- ements. The value of n(u1, u) is l/2 because there are list elements represented by u that are \nnot immediate n-successors of 741. The structures SO and S1 represent the simpler cases of lists of \nlength zero and one, respectively. 2.2 Conservative Extraction of Store Properties Three-valued structures \noffer a systematic way to answer ques- tions about properties of stores: Observation 2.1 [Property-Extraction \nPrinciple]. Ques- tions about properties of stores can be answered by evaluating formulae using Kleene \ns semantics of three-valued logic: . If a formula evaluates to 1, then the formula holds in every store \nrepresented by the three-valued structure. . If a formula evaluates to 0, then the formula never holds \nin any store represented by the three-valued structure. . If a formula evaluates to l/2, then we do not \nknow if this formula always holds, never holds, or sometimes holds and sometimes does not hold. In Section \n3.3, we give the Embedding Theorem (Theo-rem 3.7), which states that the three-valued Kleene interpre- \ntation in S of every formula is consistent with the formula s two-valued interpretation in every concrete \nstore that S rep- resents. Now consider the formula p(v) def 3vl,v2 : n(vl,v) A n(v2,v) A 211 # v2, \n(3) which expresses the property Do two or more different cells point to v. 7 Formula q(v) evaluates \nto l/2 in 5% for v c+ u, v1 t+ u, and 212 C) ~1, because n(u, u) A n(u,, u) A u # UI = l/2 A l/2 A 1, \nwhich equals l/2. The intuition is that because the values of n(u,u) and n(u1,u) are unknown, we do not \nknow whether or not two different cells point to u. This uncertainty implies that the tail of the list \npointed to by x might be shared (and the list could be cyclic, as well). In fact, neither of these conditions \never holds in the concrete stores that arise in the reverse program. To avoid this imprecision, our abstract \nstructures have an extra instrumentation predicate , is(v), that represents the truth values of formula \n(3) for the elements of concrete struc-tures that v represents. In particular, is(u) = 0 in SZ. This \nfact implies that S2 can only represent acyclic, unshared lists even though formula (3) evaluates to \nl/2 on u. The preceding discussion illustrates the following principle: Observation 2.2 [Instrumentation \nPrinciple]. Suppose S is a three-valued structure that represents concrete store Sb . By explicitly storing \nin S the values that a formula cp has in 9, we can maintain finer distinctions in S than can be obtained \nby evaluating cp in S. 0 2.3 Simple Abstract Interpretation of Program Statements Our main tool for \nexpressing the semantics of program state- ments is based on the Property-Extraction Principle: Observation \n2.3 [Expressing Semantics of Statements via Logical Formulae]. Suppose a structure S represents a set \nof stores that arise before statement st. A structure that represents the corresponding set of stores \nthat arise after st can be obtained by extmcting a suitable collection of properties from S (i.e., by \nevaluating a suitable collection of formulae that capture the semantics of st). 0 Figure 3 illustrates \nthe first two iterations of an abstract interpretation of reverse on the structure S2 from Figure 2. \nThe value of a predicate p(v) after a statement executes is obtained by evaluating a predicate-update \nformula p (v). The appropriate predicate-update formulae for each statement are shown in the second column \nof Figure 3. Figure 3 lists a predicate-update formula p (v) only if predicate p is affected statement \n1formula structure that arises just after statement _. . . st1: y = NULL; y (v) = 0  st2: t = y; t \n(v)= Y(V) stg: y = x; Y (V) = 4u) st4: x = x->n; z (v) = 3Vl : Z(Q) A n(w1, v) 12 (Ol,212) = (n(v1,vz) \nA -y(w)) v (Y(W) A t(v2)) Ul # 212 An(v1,v) A7qv2,v) sts: y-al = t; is(v) A 3Vl,D2 : is (w) = A -y(w) \nA -y(vz) > V (t(v) A 3~1 : n(w , v) A y(w )) :..-. 4 :; stz: t = y; t (v)= Y(V) @. x s* ,_. ._, st3: \ny = x; Y (V) = dV> st4: x = x->n; z (v) = 3Vl : z(q) A n(v1, v) I n v1,v2 ) = (?z(Vl, v2) A -y(v1)) \nv (y(w) A t(v2)) VI #aAn(vl,v)An(w,v) sts: y-al = t; is(v) A 3~1,212 : is (v) = A-y(w) A -7y(v2)  ( \n> V (t(v) A 31 : n(w,~) A -y(w)) st2: t = y; t (v) = Y(V) st3: y = x; Y (V) = 4V) st4: x = x->n; z (w) \n= 3Vl : 2?(Q) A n(m, tJ) n (m, ~2) = (n(vl, ~2) A my) V (y(w) A t(w)) ~1 # ~2 An(w,v) An(vz,v) st5: \ny-h = t; is(v) A 3~1, v2 : is (v) = A ly(m) A T&#38;Z) ( > V (t(v) A 3~1 : n(w,v) A l!/(w)) iS I igure \n3: The first three iterations of the abstract interpretation of reverse (7viaI the simplified framework \ndescribed in Section 4). In this example, reverse is applied to structure Sz from Figure 2, which represents \nlists of length two or more. by the execution of the statement. The shape-analysis al-are traversed. \nAs we will see, this allows us to determine the gorithm illustrated in Figure 3 is essentially that of \nChase et correct shape descriptors for the data structures used in the al. [2]. reverse program. Unfortunately, \nthere is also bad news: The method de-scribed above and illustrated in Figure 3 can be very impre- 3 \nThree-Valued Logic and Embedding cise. For instance, statement st4 sets x to x->n; i.e., it makes x point \nto the next element in the list. In the abstract inter- This section defines a three-valued first-order \nlogic with equal- pretation, the following things occur: ity and transitive closure. . In the first \nabstract execution of st4, z'(u) is set to l/2 We say that the values 0 and 1 are definite values and \nthat because z(ui) A n(ul,u) = 1 A l/2 = l/2. In other l/2 is an indefinite value, and define a partial \norder C on truth words, x may point to one of the cells represented by the values to reflect information \ncontent: Ii &#38; 1s denotes that Ii summary node u (see the structure Ss). has more definite information \nthan 12: . This eventually leads to the situation that occurs after Definition 3.1 For 11,12 E {0,1/2, \nl}, we define the infor-the third abstract execution of st5,which produces struc-mation order on truth \nvalues as follows: 11 C 12 if 11 = 12 or ture Sis. Structure $5 indicates that x, y, and t may 12 = I/2. \nThe symbol U denotes the least-upper bound opera-all point to the same (possibly shared) list . tion \nwith respect to 5. El In Section 5, we show how it is possible to go beyond the Kleene s semantics of \nthree-valued logic is monotonic in the simplified approach described above by materializing new information \norder (see Definition 3.4). non-summary nodes from summary nodes as data structures Cl Does pointer variable \nx point to element v? Does element v represent more than one Table 1: The core predicates that correspond \nto the List data-type declaration from Figure l(a). 3.1 First-Order Formulae with Transitive Closure \nLet P = {pi,... ,p,} be a finite set of predicate symbols. We write first-order formulae over P using \nthe logical con-nectives A, V, 1, and the quantifiers V and 3. The sym-bol = denotes the equality predicate. \nThe operator TC denotes transitive closure on formulae. We also use several shorthand notations: For \na binary predicate p, P+(v~,v~) is a shorthand for (TC VI, us : p(v1,va))(vs, ~4); cpl =S 92 is a shorthand \nfor (-cpr V ~2); and (pi * ps is a shorthand for (91 * 92) A ($72 * cpl). Formally, the syntax of first-order \nformulae with equality and transitive closure is defined as follows: Definition 3.2 A formula offer \na vocabulary P= {Pl,... ,Pn} is defined inductively, as follows: Atomic Formulae The logical-literals \n0, 1, and l/2 are atomic formulae with no free variables. For every predicate symbol p E P of arity k, \np(vl, . . . , vk) is an atomic formula with free variables ~1, . . . , vk . The formula (~1 = va) is \nan atomic formula with free variables v1 and vs. Logical Connectives If (~1 and cp2 are formulae whose \nsets of free variables are VI and Vz, respectively, then (cpl A (p2), (cpl Vqa), and (-rrpi) are formulae \nwith free variables VI U Va, VI U Va, and VI, respectively. Quantiflers If cp is a formula with free \nvariables VI, ~2,. . . , vk, then (3vl : cp) and (Vvi : cp) are both formulae with free variables us, \nvs, . . . , vk. Transitive Closure If cp is a formula with free variables V such that VI, va E V and \nus, 214 # V, then (TC VI, v2 : (P)(Q, ~4) is a formula with free variables (V-{VI, v2))U (213,214). A \nformula is closed when it has no free variables. I In our application, the set of predicates P is partitioned \ninto two disjoint sets: the core-predicates , C, and the Ynstrumentation-predicates , Z. The core-predicates \nare part of the programming-language semantics. In contrast, the in- strumentation predicates are introduced \nin order to improve the precision of the analysis (as described by Observation 2.2). Example 3.3 Table \n1 contains the core-predicates for the List data-type declaration from Figure l(a) and the reverse program \nof Figure l(b). 0 Table 2 lists some interesting instrumentation predicates, and Table 3 lists their \ndefining formulae. . The sharing predicate is was introduced in [2] and also used in [19] to capture \nlist and tree data structures. . The reachability-from-x predicate rr was mentioned in [19, p.381. It \ndrastically improves the precision of shape anal- ysis, even for programs that manipulate simple list \nand tree data structures, since it keeps separate the abstract representations of data structures that \nare disjoint in the concrete world. 1 Pred. I Intended Meaning I Puruose I Ref.] qq-- Do two or more \nfields of lists *and heap elements point to v? trees TX(v) Is v (transitively) reachable from separating \ndisjoint data WI pointer variable x? structures Is v reachable from some compile-time pointer variable \n(i.e., is v garbage a non-garbage element)? collection 44 Is v on a directed cycle? ref. counting [ll] \nCf.6(v> Does a field-f dereference from v, followed by a field-b dereference, yield v? doubly-linked \nlists [7], [I61 Cb.f(v) Does a field-b dereference from v, followed by a field-f dereference, yield v? \ndoubly-linked lists [7], [16] Table 2: Examples of instrumentation predicates. def @J(V) = 3v1,v2 : \nn(v1,v)An(v2,v) Au1 # v2 (4) def cp,,(v) = z(v)V% : Z(Q) An+(vl,v) (5) (p,(v) dzf // (z(v) V 3vi : z(w) \nA n+(vl,v)) (6) xEPVor cpc(v) tsf n+(z), v) (7) def (~c~,~ (v) = VW, v2 : f (v, ~1) A b(vl, 212) =S v2 \n= 2, (8) (pcb.f (v> ef VW, 212 : b(v, VI) A f (VI, v2) * ~2 = 2, (9) Table 3: Formulae that define the \nmeaning of the instrumen- tation predicates listed in Table 2. . The reachability predicate r identifies \nnon-garbage cells. This is useful for determining when compile-time garbage collection can be performed. \n. The cyclicity predicate c was introduced by Jones and Muchnick [ll] to aid in determining when reference \ncount- ing would be sufficient. . The special cyclic&#38;y predicates cf.b and c&#38;f are used to capture \ndoubly-linked lists, in which forward and back- ward field dereferences cancel each other. This idea \nwas introduced in [7] and also used in (161. 3.2 Kleene s Three-Valued Semantics In this section, we \ndefine Kleene s three-valued semantics for first-order formulae with transitive closure. Definition 3.4 \nA three-valued interpretation of the Zan-guage of formulae over P is a three-valued logical struc-ture \nS = (U ,L ), where Us is a set of individuals and L maps each predicate symbol p of arity k to a truth-valued \nfunction: LS: P -+ (US) -+ (0, 1,1/2}. An assignment Z is a function that maps free variables to individuals \n(i.e., an assignment has the functionality 2: {v1,v2,...} + Us). An assignment that is defined on all \nfree variables of a formula cp is called complete for cp. In the sequel, we assume that euery assignment \n2 that arises in connection with the discussion of some formula cp is complete for cp. The meaning of \na formula cp, denoted by [&#38;(Z), yields a truth value in (0,1,1/2}. The meaning of cp is defined in-ductively \nas follows: Atomic For a logical-literal 1 E {O,l, l/2}, [l]:(Z) = I (where 1 E (0,&#38;l/2}). For an \natomic foTTHLla p(vl, . . . , a), [p(Vl,... ,vk)]@) = ~% )(% I), . . . > z(d) For an atomic formula (WI \n= vz), 0 Z(w) # Z(v2) Z(w) = Z(v2) [Vl = vz];(z) = 1 A qm)(z(v,)) = 0 l/2 otherwise Logical Connectives \nFor logical formulae pl and ~2 ha A (~2lt(z) = min(8vlI~(~h h&#38;(~)) BP1 v cp21m = mMcpll~(~), Ff213sW) \n8%13s(~) = 1 - Mm Quantifiers If cp is a logical formula, pw : &#38;(Z) = p$. I&#38;qw I-t UI) pw : &#38;(a \n= mys [&#38;(GJ1 e 4 Transitive Closure For (TC 211,212: (p)(vs, v4), [(TC 211,212 : (P)(w4)p:(z) = We \nsay that S and Z potentially satisfy cp(denoted by S, 2 k cp) if [q]:(Z) = l/2 or [&#38;(Z) = 1. Finally, \nwe write S + cp if for every 2: S, 2 k cp. 0 The only nonstandard part of Definition 3.4 is the meaning \nof equality (denoted by the symbol = ). The predicate = is defined in terms of the sm predicate and the \nidentically-equal relation on individuals (denoted by the symbol = ): . Non-identical individuals ui \nand u2 are unequal (i.e., if ui # uz then ui # uz ). . A non-summary individual must be equal to itself \n(i.e., if sm(u) = 0, then u = u). . In all other cases, we throw up our hands and return l/2. Three-valued \nlogic retains a number of properties that are familiar from two-valued logic, such as commutativity and \nas- sociativity of A and V, distributivity of A over V and vice versa, De Morgan laws, etc. 3.3 The Embedding \nTheorem In this section, we formulate the Embedding Theorem, which gives us a tool to relate two- and \nthree-valued interpretations. We define the embedding ordering on structures as follows: Definition 3.5 \nLet S = (U ,L ) and S = (Us , ) be two structures. Let f: Us -+ Us be surjectiwe. We say that f embeds \nS in S (denoted by S Cf S ) if(i) for every predicate symbol p of an ty k and all ~1,. . . , u&#38; E \nUs, &#38;)(ul, . . . . , ilk) &#38; b%)(f (u1), . . . , f (uk)) (10) Note the typographical distinction \nbetween the syntactic symbol for equality, namely = , and the symbol for the identically-equal relation \non individuals, namely I= . and (ii) for all u E Us , (Ku I f(u) = u }I > 1) E ts (sm)(u ) (11) We say \nthat S can be embedded in S (denoted by S 5 5 ) if there exists a function f such that S cf S . I Note \nthat inequality (10) applies to the summary predi-cate, sm, as well. A special kind of embedding is a \ntight embedding, in which information loss is minimized when multiple individuals of S are mapped to \nthe same individual in S : Definition 3.6 A structure S = (U ,L ) is a tight em- bedding of S = (Us, \nts) if there exists a surjectiwe function t-embed: Us + Us such that, for every p E P -{sm} of arity \n1, s (p)@:, . . . ) u;> = &#38;)(%,... ,uk)(12) I-J t_embed(Ui)=~i,l<i<k and for every u E Us , LS,(sm)( \n,) = (I{4t-embed($ = ~ 11 > W u L (smN4 (13) u t_embed(u)=u Because t-embed is surjective, equations \n(12) and (13) uniquely determine S (up to isomorphism); therefore, we say that S = t-embed(S). I It is \nimmediately apparent from Definition 3.6 that the tight embedding of a structure S by a function t-embed \npos-sessing properties (12) and (13) embeds S in t-embed(S), i.e., S Pmbed t-embed(S). If f:US + us is \na function and 2: Var + Us is an assignment, f o Z denotes the assignment f o 2: Var + Us such that (f \no Z)(v) = f(.Z(v)). We are now ready to state the embedding theorem. Intu-itively, it says: If S cf S \n, then every piece of information ex-tracted from S via a formula q is a conservative approximation of \nthe information extracted from S via cp. Theorem 3.7 [Embedding Theorem]. Let S = (Us,ts) and S = (Us \n, I? ) be two structures and f: Us + Us such that S cf S . Then, for every formula cp and complete assign- \nment 2 for 9, M3s(z) 5 Mf (f o 2). 0 3.4 Compatible Structures We use 3-STRUCT[P] to denote the set of \ngeneral three-valued structures over vocabulary P, and 2-STRUCT[P] to denote the normal two-valued structures \nover P. (Note that 2-STRUCT[? ] C 3-STRUCT[P].) Suppose that P is a C program that operates on the List \ndata-type of Figure l(a), and that Sb E 2-STRUCT[P] is a two-valued structure over the appropriate vocabulary. \nAs de- scribed in Table 1, our intention is that Sh capture a List- valued store in the following manner: \nEach cell in hyhp-allocated storage corresponds to an individual in U . For every individual u, ~~~(z)(u) \n= 1 if and only if the heap cell that u represents is pointed to by program vari- able x. For every pair \nof individuals ui and 112, L Sb (n)(u1, u2) = 1 if and only if the n field of ui points to UP. for each \nx E PVar,Vvi,v2 : Z(Q) AZ(~) =S WI = ~2 (14) v111,212: (3tJ3 : n(w3,211) A n(vs,vz)) * 211 = 212 (15) \n vv: (32)1,v2 : WI # 212An(th,v) A n(v2,v)) * is(w) (16) tlv : -+h,w2 : ~1 # v2 An(m,v) An(wz,v)) =S \n-+8(v) (17) v212,2,: (AI, : -vis u A VI # 212 An v1,v)) =k- -n(vz,v)(18) V/2)1,2): (3~2: +5(v) Avl # \n212 An(vz,w)) + -Vz(v1,v) (19) tj211,va :(3~ : -k?(v) An(vl,v) A n(v2,v)) + 111= 212 (20) Table 4: Compatibility \nformulae F for structures that repre- sent a store of the reverse program, which operates on the List \ndata-type declaration from Figure l(a). The rules below the line are logical consequences of the rules \nabove the line, and are generated systematically from the rules above the line, as explained in Section \n5.2.1. (Similar statements hold for the instrumentation predicates, as indicated in Table 2.) However, \nnot all structures Sb E 2-STRUCT[P] represent stores that are compatible with the semantics of C. For \nexam- ple, stores have the property that each pointer variable points to at most one element in heap-allocated \nstorage. Conse-quently, we are not interested in all structures in 2-STRUCT[P], but only in ones compatible \nwith the semantics of C. Table 4 lists a set of compatibility formulae F (or hygiene condi-tions ) that \nmust be satisfied for a structure to represent a store of a C program that operates on the List data-type \nfrom Figure l(a). Formula (14) captures the fact that every pro- gram variable points to at most one \nlist element. Formula (15) captures a similar invariant on the n fields of List structures: Whenever \nthe n field of a list element is non-NULL, it points to at most one list element. In addition, for every \ninstrumentation predicate p E Z de-fined by a formula pp (vi , . . . , ZIP), we generate a compatibility \nformula of the following form: vu1 ,... ,?.Jk : (pp(211 ,... ,vk) w$p(vl,... ,vk) (21) This is then broken \ninto two formulae of the form: vu l,... , vk : f&#38;,(2)1,. . . , uk) * p(vl,. . . ,vk) vu 1,. . . ,Vk \n: -&#38; p(Vl,. . . ,2)k) =i - p(vl,. . . ,vk) For instance, for the instrumentation predicate is, we \nuse formula (4) for (Pia to generate compatibility formulae (16) and (17). In the remainder of the paper, \n2-CSTRUCT[P, F] denotes the set of two-valued structures that satisfy a set of compati- bility formulae \nF. Compatibility constraints for three-valued structures are discussed in Section 5.2.1. A Simple Abstract \nSemantics In this section, we formally work out the abstract-interpretation algorithm that was sketched \nin Section 2.3. In Section 4.1, we define how (a potentially infinite number of) concrete struc-tures \ncan be represented conservatively using a single three- valued structure. In Section 4.2, the meaning \nfunctions of the program statements are defined. To guarantee that the analy- sis of a program containing \na loop terminates, we require that the number of potential structures for a given program be fi- nite. \nFor this reason, in Section 4.3 we introduce the set of bounded structures, and show how every three-valued \nstruc-ture can be mapped into a bounded structure. Section 4.4 states the abstract interpretation in \nterms of a least fixed point of a set of equations. 4.1 The Concrete Stores Represented by a Three-Valued \nStructure Deflnition 4.1 (Concretization of Three-Valued Struc-tures) For a structure S E 3-STRUCqP], \nwe denote by y(S) the set of two-valued structures that S represents, i.e., y(S) = {Sb 1 Sh c S, Sb E \n%CSTRUC~P, F]} (22) Cl Example 4.2 The structure S2 shown in Figure 2 represents lists of length two \nor more. 0 4.2 The Meaning of Program Statements In this subsection, we present a simple algorithm that, \ngiven a program, computes for every point in the program a conserva- tive approximation of the set of \nconcrete structures that arise at that point during execution. (This algorithm is refined in Section \n5 to obtain a more precise solution.) We now formalize the abstract semantics that was dis-cussed in \nSection 2.3. The main idea is that for every state- ment st, the new values of every predicate p are \ndefined via a predicate-update formula cp; (referred to as p in Section 2.3). Definition 4.3 Let st be \na program statement, and for every a&#38;y-k predicate p in vocabulary P, let pit be the formula over \nfree variables vi,. . . , vk that defines the new value of p after st. Then the P transformer associated \nwith st, denoted by [St], is defined as follows: ]stl(S) = . . . ,t&#38;.[$$];([th +b 111,. . . ,Wk ti \nt&#38;l)) ( y;;,,, 0 Example 4.4 Table 5 lists the predicate-update formulae that define the abstract \nsemantics of the five kinds of statements that manipulate data structures defined by the List data type \ngiven in Figure l(a). (For the moment, ignore the case for statements of the form x = malloc 0 .) Cl \nDefinition 4.3 does not handle statements of the form x = malloc0 because the universe of S does not \nchange. Instead, for statements of this form, we use the modified definition of ]st](S) given in Definition \n4.5, which first allocates a new individual unew , and then invokes predicate-update formulae in a manner \nsimilar to Definition 4.3. Definition 4.5 Let st E x =malloc() and let new $2 P be a unary predicate. \nFor every p E P, let pGt be a predicate-update formula overvocabulary PU{new}. Then the P trans-former \nassociated with st E x = malloc(), denoted by [z = malloc()], is defined as follows: [x = malloc()](S) \n= let U = Us U {unew}, where unew is an individual not in Us xp.xul,. . . ,uk. 1 p=new Au1 =unew 0 p=newAul#unew \nand L'= p#new A V ui =unew l/2 l<i<k I LS(p)(Ul,... , uk) otherwise U , in ( xp.xu1, . . * , dbf p St \n( + )([Vl 13 k-b ul, . . . , Vk +b Uk]) > Cl In Definition 4.5, L is created from L as follows: (i) new(unew) \nis set to 1, (ii) new(ui) is set to 0 for all other individuals 111 # uncut, and (iii) all predicates \nare set to l/2 when any st P; x = NULL &#38; (w) def 0 (Pan def zj:J, for each z E (PVar -{x}) cpz (211, \nv2) = n(211,212) &#38;(w) def m(w) x=t f&#38; (w) deft(w) p: (w) def z(w), for each z E (PVar -{x)) cpzLt(wI,w2) \ndgf n(w1,w2) y&#38;(w) def m(w) x = t->n &#38;(w) def 3Wl : t(w1) A 7z(Wl, w) p: (w) def z(w), for each \nz E (PVur -{x}) def f&#38;(w , w2) = n(w1,w2) g&#38;(w) def m(w) x->n = t &#38;(w) def Z(W), for each \nz E PVar def (n(w, 112) A ~~(211)) d(wl,w2) = v (z(w1) A t(w2)) cp::, (w) dsf m(w) x = malloc() p: (w) \ndef new(w) def Z(W) A -new(w), cp (w) = for eac;lu: z2jpVar -{x}) def cp , (Wl,W2) = A -w&#38;(w,) A \nTnew(w2) p::(w) ef sm(w) A -new(w) Table 5: Predicate-update formulae for the core predicates for List \nand reverse. argument is uneW. The predicate-update operation in Defi- nition 4.5 is very similar to \nthe one in Definition 4.3 after L has been set. (Note that the p in L = Xp.. . . ranges over P U {new}, \nwhereas the p in Xp.. . . appearing in the last line of Definition 4.5 ranges over P.) The Embedding \nTheorem immediately implies that the three-valued interpretation is conservative with respect to ev- \nery store that can possibly occur at run-time. The above two definitions are not the complete story. \nIn the case of the instrumentation predicates, the statements need to maintain %orrect instrumentation \n. This is formally defined as follows: Definition 4.6 A predicate-update formula cpg maintains a correct \ninstrumentation for predicate p E Z if for all Sb E 2-CSTRUCqP, F] and for all Z, [p;*]$(Z) = [ pp]yqZ). \nEl Example 4.7 Table 6 gives the definitions of the predicate- update formulae for the instrumentation \npredicate is. It is not hard to see that, for each kind of assignment statement, equation (23) holds. \n0 Henceforth, when discussing the general case (i.e., the para- metric framework), we assume that all \npredicate-update for-mulae maintain correct instrumentations. 4.3 Bounded Structures To guarantee that \nshape analysis terminates for a program that contains a loop, we require that the number of potential \nTable 6: Predicate-update formulae for the instrumentation st st(Pis j x = NULL I&#38;w) def is(w) x=t \n(cp$w)defis(w) x = t->n &#38;w) def is(w) is(w) A 3~1,212 : 01 # w2 x->n = t l&#38;(w) def A n(wl, A \n+wl) w) A 4~2, A -4~2) v) V (t(w) A 3~1 : n(w~, w) A x(w~)) x = malloc() cp~~(w) gf is(w) A -mew(w) \npredicate is. structures for a given program be finite. Toward this end, we make the following definition: \nDefinition 4.8 A bounded structure ozler vocabulary P is a structure S = (U ,L ) such that for every \nUI,UZ E Us, where u1 # 112, there etists a unary predicate symbol p E P such that (i) I # l/2, (ii) L \n(~)(W) # l/2, and (iii) LS(P)(U1) # rS(p)(u2>. In the sequel, B-STRlJCljP] denotes the set of such struc-tures. \n13 There are two consequences of Definition 4.8: . For every fixed set of predicate symbols P containing \nunary predicate symbols A C P, there is an upper bound on the size of structures S E B-STRUCT[P], i.e., \nIUs < 21-4 . . The embedding of any structure into a bounded struc-ture S is unique. Example 4.9 Consider \nthe class of bounded structures asso-ciated with the List data-type declaration from Figure l(a). Here \nthe predicate symbols are C = {sm, n) U {z ( x E PVar) and Z = {is}. For the reverse program from Figure \nl(b), the program variables are x, y, and t, yielding unary core predicates G, y, and t; the other unary \npredicates are is and sm. Therefore, the maximum number of individuals in a structure is 25 = 32; however, \na consequence of equation (13) is that sm cannot have the value 1, and thus the maximum number of individuals \nin a structure is really only 16. On the other hand, Figure 3 shows that each structure that arises in \nthe analysis of reverse has at most two individuals. 0 One way to obtain a bounded structure is to map \nindivid- uals into abstract individuals named by the definite values of the unary predicate symbols. \nThat is, to embed unbounded-size structures into bounded-size ones, we exploit the following abstraction \nprinciple, in which the mapping is controlled by a fixed set of unary abstraction predicates -the unary \npredicates of the vocabulary: Individuals are partitioned into equivalence classes according to their \nsets of unary-predicate values. Every structure Sb is then represented (conserva-tively) by a condensed \nstructure in which each in- dividual of S represents an equivalence class of Sb. This is formalized in \nthe following definition: *The predicate sm has a slightly different status than the other core predicates. \nIt captures the essence of summary-nodes , and thus has has a fixed meaning in all concrete structures, \nnamely, sm(u) = 0 for all u E Us. Including sm in the concrete structures allows us to work with the \nsame vocabularies at the concrete and abstract levels. Deflnition 4.10 The canonical abstraction of \na structure S, denoted by t-embed,(S), is the tight embedding induced by the following mapping: t-embed,(u) \n= \"{pod-{~n}l ~(p)(~)=l),(pEA-Iam)JrS(p)(~)=O}. Cl Note that t-embed, can be applied to any three-valued \nstructure, not just two-valued structures, and that t-embed, is idempotent (i.e., t_embed,(t_embed,(S)) \n= t-embed,(S)). The name '\"{p~d-{dm}l s(p)(u)=l),{ ~d-{.m}~~S(p)(u)=O}n is known as the canonical name \nof m Jividual u. Example 4.11 In structure Sr from Figure 2, the canonical name of individual ui is u{xl,{r,t,ial, \nand the canonical name of 11 is \"0,{z,y,t,is}*In structure Ss, which arises after the first abstract \nmterpretation of statement sts in Figure 3, the canonical name of ui is ~I~,~l,{~,i~l, and the canonical \nname of u is ~0,{,,~.t,i~j. 0 It is straightforward to generalize Definition 4.10 to use just a subset \nof the unary predicate symbols, rather than all of the unary predicate symbols A c P. This alternative \nyields bounded structures that have a smaller number of individu- als, but may decrease the precision \nof the shape-analysis al-gorithm. For instance, Definition 4.10 is a generalization of the abstraction \nfunction used in [19].3 The only abstraction predicates used in [19] are the pointed-to-by-x predicates; \nthe predicate is is used only as an instrumentation predicate in [19], but not as an abstraction predicate \n(i.e., is does not contribute to the canonical name of an individual in [19]). Consequently, the algorithm \nfrom [19] loses precision for stores that contain both shared and unshared heap cells that are not directly \npointed to by any variable. Adopting is as an addi- tional abstraction predicate improves the accuracy \nof shape analysis: In this case, shared heap cells and unshared heap cells are represented by abstract \nindividuals that have differ- ent canonical names. 4.4 The Shape-Analysis Algorithm In this section, \nwe define the actual shape-analysis algorithm. Deflnition 4.12 For structure sets XS1, XS1 c 3-STRZJCqP], \nwe define: XSI E XSa e VSi E XSz : 3Sz E XSz : Si g .I$. cl The shape-analysis algorithm itself is an \niterative proce-dure that computes a set of structures, StructSet[v], for each vertex 2) of control-flow \ngraph G, as a least fixed point of the following system of equations over the variables StructSet[v]: \nU {t_embed,[st(w)](S) ] S E StructSet[w]} if u # start {(8,&#38;h,... ,uk.1/2)} if v = start The iteration \nstarts from the initial assignment StructSet[v] = 0 for each control-flow-graph vertex v. Because of \nthe t-embed, operation, it is possible to check efficiently if two structures are isomorphic. 5 Improved \nAbstract Semantics In this section, we formulate the improved abstract interpre-tation referred to in \nSection 2. This analysis recovers precise shape information for many list-manipulation programs, in-cluding \nones that manipulate cyclic lists. The shape-analysis algorithm presented in [19] is described in terms \nof Storage Shape Graphs (SSGs), not bounded structures. Our compar- ison is couched in terms of the terminology \nof the present paper. II {S51 1Wl {s6} 2 {sS,OtsS,l, s6.2) \\COerrF {'95,0,0,'95,o,lrS5,o,2) Figure 4: \nOne- vs. three-stage abstract semantics of statement sts. The operation [st] was already defined in Section \n4. The focus and the coerce operations are introduced in Sections 5.1 and 5.2, respectively. (This example \nwill be discussed in fur- ther detail in Sections 5.1 and 5.2.) In contrast to the abstract meaning function \nfor a state- ment st given in Definition 4.3, in this section we decompose the transformer for st into \na composition of three functions, as depicted in Figure 4 and explained below: The operation focus, defined \nin Section 5.1, refines three- valued structures such that the formulae that define the meaning of st \nevaluate to definite values. The focus op-eration thus brings these formulae into focus . The transformer \n[St], defined in Section 4, is then ap- plied (see Definitions 4.3 and 4.5). The operation coerce, defined \nin Section 5.2, converts a three-valued structure into a more precise three-valued structure by removing \nincompatibilities. In contrast to the other two operations, coerce does not depend on the particular \nstatement st; it can be applied at any step (e.g., right after focus and before [St]) and may improve \nprecision. It is worthwhile noting that both focus and coerce are semantic-reduction operations (originally \ndefined in [3]). That is, they convert a set of three-valued structures into a more precise set of structures \nthat describe the same set of stores. This property, together with the correctness of the structure transformer \n[St], guarantees that the overall three-stage se-mantics is correct. 5.1 Bringing Formulae Into Focus \nTo improve the precision of the simple abstract semantics of Section 4 we define an operation, called \nfocus, that forces a given formula cp to a definite value. 5.1.1 The Focus Operation First, we define \nan auxiliary operation, mazimal, that returns the set of maximal structures in a given set of structures: \nDefinition 5.1 For a set of structures XS C 3-STRUCT[P], mazimal(XS) def XS-{XEXSI~X EXS:X[I:X ~~~X ~X} \nCl Definition 5.2 Given a formula cp, the operation focus, yields the (potentially infinite) set of structures \nin which cp evaluates to a definite value, i.e., focus,(S) = maximal for all 2 : [&#38; (2) # l/2 }I \n0 Example 5.3 The upper part of Figure 5 illustrates the ap- plication of focus to the formula &#38;(u) \nand the structure Ss that we have in reverse between the first application of state- ment sts: y = x \nand the first application of statement st4: x = x->n in Figure 3. This results in three structures: The \nstructure S~J,C,, in which pit4(w) evaluates to 0 for all individuals. This structure represents a situation \nin which the concrete list that x and y point to has only one element, but the store also contains garbage \ncells, represented by summary node U. The structure &#38;JJ, in which [ pzt4 (v)]? ~*~ ([v I+ u]) equals \n1. This covers the case where the list that x and y point to is a list of exactly two elements: In all \nof the concrete cells that summary node 1~ represents, cpz (v) must evaluate to 1, and so u must represent \njust a single list node. The structure &#38;,,f,2, in which [cpzt4 (v)]~. . ([v * u.01) equals 0 and \n[&#38; 4(~)]~*f~2([w C) u.l]) equals 1. This covers the case where the list that x and y point to is \na list of three or more elements: In all of the concrete cells that u.0 represents, cp: (v) must evaluate \nto 0, and in all of the cells that 21.1 represents, cpzt4 (w) must evaluate to 1. This case captures \nthe essence of node materialization as described in [19]: individual 1~ is bifurcated into two individuals. \nNotice how foc~~~~t~ CV) is effectively constructed from SS by considering the reasons why [&#38; 4(~)]~(Z) \nevaluates to l/2 for a possible assignment 2: [&#38;4(v)]? ([v H ul]) equals 0, and therefore cpit4(v) \nis already in focus at ~1; in contrast, [ pzt4 (v)]? ([v e u]) equals l/2. There are three (maximal) \nstructures in which [(pit4 (v)]s([~ t+ u]) has a definite value: . &#38;,,J,o, in which ~(uI,u) was forced \nto 0, and thus [$&#38; (v)]?J*O ([v I+ u]) equals 0. . SSJJ, in which n(ul, U) was forced to 1, and thus \n[ p$4 (?&#38;JJ ([v c) u]) equals 1. . &#38;,f,z, in which u was bifurcated into two different in-dividuals, \nu.0 and 21.1. In &#38;,,f,z, n(u1,u.O) was set to 0, and thus [cp; (~)],S6,~*~ ([v r-) u.01) equals 0, \nwhereas n(z(;;;; ) was set to 1, and thus [&#38;(~)],s * * ([v I+ ~.l]) Of course, there are other structures \nthat can be embedded into S5 that would assign a definite value to pjZt4 (v), but these are not maximal \n(according to Definition 5.1) because each of them can be embedded into one of &#38;,f,o, Ss,f,l, or \n&#38;,f,2. 0 In this paper, we simplify the analysis algorithm by only applying focus with respect to \nspit formulae, which ensures that the number of resulting structures is finite: Lemma 5.4 For every program \nvariable x E PVar, statement st, and structure S, If0cu.9,:~ (S)l 5 31U I. . 5.1.2 An Algorithm for Focus \nIn this section, we present an algorithm that implements focusVlt ( ) by generating structures in which \ncp;2 (v) has a definite value. A key aspect of the algorithm is the ability to identify the maximal structures \nin which cpzt (v) has a definite value. Recall that the Hoare order on sets of structures is only a pre-partial \norder (see Definition 4.12). The following definition provides a way to compute a least upper bound and \na greatest lower bound on sets of structures sharing the same universe U. Definition 5.5 Let XSI, XS2 \ns 3-STRUCqP] such that for all S E XS1 U X&#38;, Us = U. We define the following opera-tions on XSI and \nXS2: XSl U XS2 def maximal(XS1 U XS2) xs 1 l-l xs 2 dsf (u,~p.xUl,. . . Uk.LS1(P)(Ulr.. . ,Uk) n L (P)(Ul,. \n. . ,uk)) I S1 E XSI and Sz E XS2 and comparable(S1, SZ) > { where: comparable(S1, SZ) = forallpEP,forallu~,... \n,uk EU: Pqp)(UI,... ,uk) bS2@)( 111,... ,uk) or bs2 (p)(u~, . . . , Uk) c Lsl (p)(Ul, . . . , ilk) cl \nWe are now ready to define the operations z and o that assure that a given formula evaluates to 0 and \n1, respectively, in a given assignment. Definition 5.6 Let S = (U, L) E 3-STRUCljP] be a three- valued \nstructure. Let &#38;(u~, . . . , uk) t l] denote the map ob- tained from L by updating ~(p)(u~, . . . \n, uk) to have the value 1. For a formula cp and assignment 2, we define z(cp)(S,Z) E 23~STRUCT~p1and \no(cp)(S, 2) E 23-sTRucT[p1 inductively, as follows: M(S,Z) = {(&#38;h (z(d,-.. , z(vk)) + 01) Z(P( ul,... \n, d)(s, 2) = if 0 E b@(z(vl), . . . , z(vk)) 0 otherwise ,491 A (P2)(% 2) = 4cpl)(S, Z) u 4cpz)(S, 2) \n4~1 v cp2)(8 2) = 4cpd(s, 2) n 4f72)(s, 2) 4-v)(f% 2) = o(cp)(S, 2) WJ : rp)(S, 2) = u 4cp)(S, Z[v I+ \n4 UEU -43v : cpw, 2) = fl 4cpm,GJ * 4 UEU o(Z)(S, 2) = z(sm(vl))(S, 2) if Z(~I) = Z(v2) o(v1 = u2)(S,Z) \n= otherwise {(~,h (~( ul),-.. ,z(vk)) 4-11)) O(P(V1, . . . tvk))(S, 2) = if 1 c L(I)(z(vl), . . . , \nz(vk))) 0 otherwise 4cpl A cpz)(S, 2) = O(cpl)(S, 2) n o(cpz)(S, 2) O(cpl v (P2)(% 2) = O(cpl)(S, 2) \nu o(cp2)(% 2) o(-cp)(S, 2) = 4v)(S, 2) o(Vv : cp)(S, 2) = /-j o(cp)(S, -qJ ++ 4) UEU o@v : cpp, 2) = \nu 4cpK% Zb -4 UEU cI Example 5.7 For the formula cpct4(w), structure S5 from Fig- . . 4 ; input struct. \ns5 a focus {$+(2)) = 31 : 2(w) A n(tJ1, v), &#38;qv) = y(v), cp; yv> = t(v)} formulae focused struct. \n%f,O &#38;4(u) = 0 %f,l pg4 (u) = 1 S&#38;f,2 cp:t (u) = 1 &#38; (21) = 0 ..m. x,,_@ 4d x,y_@_R x,y_o~~-_:::::::::~.~ \nt t t t t update pct4 (v) PO;4(v) $4 4(v) (PL4 (v) cp:4 (v) cp; 4 (211, v2) formulae 31 : 2(Vl) A n(v1, \nv)ly(v) It(v) lis(v) m(v) jTz(v1, v2) output ss,o,o SS,o,l X X struct . s5,0,2 . ..?a... ..*.. 4 .: \n y+@ j&#38; y-u1 n @ Y - 111 n, u.1 ,:;:;,::r. 21.0 0-A i ). 0 (I 0 ... .. . b ,: coerced struct. St?,0 \n&#38;,l X se,2 n y+@ 4&#38; Y-Ul U y-o-Q . . ?L@ 0-A Figure 5: The first application of the improved \ntransformer for statement st4: x = x->n in reverse. ure 5, and individual u E lJs5, we have: function \nFocus(S : 3-STRUCT[P], 9$(v): Formula) 4&#38; )(~5, bJ -+ ul) returns 2s-CsTnrJCW~s(FN = Z(3Vl : z(w) \nA n(v1, v))(S5, [v --) U]) begin = n Z(Z(Vl) A n(v1, v))(S5, [v + U, Vl + 21 1) if there exists u E Us \ns.t. [&#38; ]z([v C) u]) = l/2 then u E{u,u1) +(m) A n(vl, v))(s5, [v -+ U, VI + U]) let u.0 and u.l \nbe individuals not in Us = I-I .+(vl) A n(w, v)>(s5, [v + U, VI + UI]) and S = o(cp: (v))(z(cp:t(v))(Expand(S, \nq~0,u.l) 42(Vl)(S5, [v -+ U, VI + U]) [v +) 4>, = ( > [v c) u.11) u z(n(v1, v))(S5, [v + U, Vl + U])) \n I-I z(z(w) A ~(vI, v))(ss, [v + U, VI + ~11) z($u))(S, [v H 4) = ({Ss) u ({U, Ul), +[n(U, 4 * 01)) \nand XS ; $ = (u))(S, [u I+ 4 = n r+(w) A n(w, v))(Ss, [v + u, VI + UI]) = {Ss} n z(~(vr) A n(v1, v))(Ss, \n[v + u, vi + ~11) in return u Focus(S) , cp$ (v)) (z(z(vl))(ss [v + U 211 --) Ul]) S EXS = {ss] I-I \n(u *(n(vr, v),(&#38;, [v + L, vr + u1])) > else return {S} end = (Ss} l-l +qVl, 4)(S5, [v --) U, Vl \n+ w]) = {Ss} n ({U, Ul}, +(Ul, U) I-+ 01) function Expand(S : 3-STRUCT[P], u, ~0, u.1: elements) = {({U,%}, \n+[n(Ul,U) I+ 01)) returns 3-STRUCT[P] = {%f,Ol if u = 21.0 V u = u.1 Similarly, 0((0:~~)(S5, [v + ~1) \n= {&#38;,f,l}. Cl let m = Xu . :I otherwise in {Remark. In Definition 5.6 we have ignored the case of \nfor- (VS -{?J}) u (u.0, 1L.l) return mulae that include the transitive-closure operator. This was xp.xui,. \n. . 7m.LSb)(m(Ul), . . . Tm(Uk)) done both for notational simplicity, and because such formu-> lae are \nnot useful in the various predicate-update formulae cpi Figure 6: An algorithm for ~ocus~:~(,). employed \nby the abstract semantics. It is possible to handle such formulae by enumerating structures in which \nformulae which individual u is bifurcated into two individuals; this cap- evaluate to definite values. \n0 tures the essence of shape-node materialization (cf. [19]). The algorithm for focus, called Focus, \nis shown in Figure 6. When all of structure S s individuals have definite values for Example 5.8 Consider \nthe application of Focus to the struc-I&#38;(V), Focus returns {S}; when S has an individual u that has \nture S5 from Figure 5 and the formula pzt4. By Example 5.7, an indefinite value for cp: (v), Focus applies \nz and o to gener- z(cpgt4)(Ss, 2) yields the singleton set {Ss,f,o} and o(&#38; ~)(SS, 2) ate structures \nin which the indefiniteness is removed, and then yields the singleton set {Ss,f,i}. By a similar derivation, \nrecursively applies Focus to each of the structures generated. o(pzt4 (v))(z((p:t4(v))(Expand(S, 21, \nu.0, u.l), [v I+ u.O]), [v I+ The call on auxiliary function Expand creates a structure in u.11) yields \nthe singleton set {Ss,f,2}. Thus, the result of Focus(Sa, cp$ ) is the set {Ss,f,o,Ss,f,l,S5,f,2}. 0 \n5.2 Coercing into More Precise Structures After focus, we apply the simple transformer [st]l that was \ndefined in Definitions 4.3 and 4.5. In the example discussed in Section 5.1, we apply [sty] to the structures \n&#38;J,o, SSJJ, and S5,f,2. We see that S+,o is obtained from S,~J,O, &#38;,+,,l from SSJJ, and sS,o,Z \nfrom S5,f,2. Applying focus and then [st] can produce structures that are not as precise as we would \nlike. The intuitive reason for this state of affairs is that there can be interdependences be-tween different \nproperties stored in a structure, and these in- terdependences are not necessarily incorporated in the \ndefini- tions of the predicate-update formulae. This is demonstrated in the following example: Example \n5.9 Consider structure S5+,,2 from Figure 5. In this structure, the n field of u.0 can point to u.l, \nwhich sug-gests that x may be pointing to a cyclic data structure. How-ever, this is incompatible with \nthe fact that is(u.1) = 0-i.e., u.1 cannot represent a heap-shared cell-and the fact that n(u1,u.l) = \n1-i.e., it is known that u.l definitely has an incoming selector edge from a cell other than u.0. 0 In \nthis subsection, we show that in many cases we can sharpen the structures by removing indefinite values \nthat vi- olate certain compatibility rules. In particular, it allows us to remedy the imprecision illustrated \nin Example 5.9. Further-more, the shape-analysis actually yields precise information in the analysis \nof reverse. 5.2.1 Compatibility Constraints We can, in many cases, sharpen some of the stored predicate \nvalues of three-valued structures: Example 5.10 Consider a two-valued structure Sb that can be embedded \nin a three-valued structure 5 . By the Property- Extraction Principle (Observation 2.1), we know that \nif the formula cpis for inferring whether an individual u is shared evaluates to, e.g., 1 in S, then \nin Sk, is(&#38;) must be 1 for any individual 1~~ that maps to u. The definition of embedding (Definition \n3.5) would allow the value of is(u) in S to be l/2; however, in this case a tighter embedding-in the \nsense of Definition 3.6-is also possible, in which is(u) has the value 1. In other words, it is needlessly \nimprecise to let is(u) retain the value l/2: The stored property is should be at least as precise as \nits inferred value. Thus, in some cases, the fact that cpis evaluates to 1 in a three-valued structure \nallows us to sharpen the stored predicate is. Similar reasoning allows us to determine, in some cases, \nthat a structure is inconsistent. For instance, if 9;s evaluates to 1 for an individual u and is(u) is \n0, then S is a three-valued structure that does not represent any concrete structures at all! When this \nsituation arises, the structure can be eliminated from further consideration by the abstract-interpretation \nal-gorithm. This reasoning applies to all instrumentation predicates, not just is, and to both of the \ndefinite values, 0 and 1. 0 The reasoning used in Example 5.10 can be summarized as the following principle: \nObservation 5.11 [The Sharpening Principle]. In any structure S, the valued stored for p(ul, . . . , \nuk) should be at least as precise as the value of p s defining formula, pp, evalu-atedatul,... ,Uk (i.e., \n[(pp]~([Vl I+ Ul,... ,Vk I-b Uk])). fir- thermore, ifp(ul,... ,uk) has a definite value and pp evalu- \nates to an incomparable definite value, then S is a three-valued structure that does not represent any \nconcrete structures at all. cl for each x E PVar, ~(211) A z(v2) D vl = 212 (27) (3213: n(v3,w) A n(v3,vz)) \nD vl = 212 (28) (h,v2 : VI # 212An(Vl,v)A n(V2,V)) D is(v) (29) $3vl,2)2 : WI # 212A n(v1, v) A n(v2, \nv)) D lia(v) (30) (Au1 : via v) A v1 # 212 A n(w1, w)) D Tn(v2, v) (31) (3~12 : -is(v) A ~1 # 212 A n(v2, \nw)) D %(2)1, v) (32) (3~ : -is(v) A n(v1, w) A n(v2, v)) D v1 = 212 (33) Table 7: The compatibility \nconstraints R( clzre(F)) gener-ated using Definition 5.13 from the formulae F given above the line in \nTable 4. The constraints below the line come from applying r to the formulae listed below the line in \nTable 4. This observation motivates the subject of the remainder of this subsection-an investigation \nof compatibility constraints expressed in terms of a new logical connective, D . Definition 5.12 Let \nC be a finite set of compatibility con-straints of the form cpl D cpz, where cpl is an arbitrary three-valued \nformula, and cpz is either an atomic formula or a nega- tion of an atomic formula. We say that a structure \nS satisfies C (denoted by S k C) if for every constraint pl D (~2 in C, and for every assignment 2 such \nthat [(pl]t(Z) = 1, we have [qJ2]3s(Z)= 1. 0 For a two-valued structure, D has the same meaning as +. \nHowever, for a three-valued structure D is stronger than 3: if pl evaluates to 1 and (~2 evaluates to \nl/2, the constraint pl D p2 is not satisfied. More precisely, suppose that [pl]i(Z) = 1 and [(p&#38;(Z) \n= l/2; the implication pl + (~2 is satisfied (i.e., S, 2 b pl * cpz), but the constraint pl D p2 is not \nsatisfied (i.e., S, 2 p ~1 D ~2). The constraint that captures the reasoning used in Exam- ple 5.10 is \nCpis(V) D is(v). That is, when cpi8 evaluates to 1 at u, then is must evaluate to 1 at u. Such constraints \nformalize the Sharpening Principle. They will be used to improve the precision of the shape-analysis \nalgorithm by (i) sharpening the values of stored predicates, and (ii) eliminating structures that violate \nthe constraints. The following definition converts formulae into constraints in a natural way: Definition \n5.13 For formula p and atomic formula a, define r((p) as follows. r(Vvl,... Uk: ( p =s a)) def cp D a \n(24) r(Vvl,... vk : ( p * -a)) def $7 D -a (25) r(Vvl,... Vk : $7) dsf Cp D 9 (26) For a set of formulae \nF, we define R(F) to be the set of con-straints obtained by applying r to each of the formulae in F. \n0 Rule (26) was added to enable an arbitrary formula to be converted to a constraint. Example 5.14 The \nconstraints generated for the formulae that appear above the line in Table 4 are listed above the line \nin Table 7. c7 In [18], we define a closure operator cl&#38;&#38;e(F) that gen-erates certain logical \nconsequences of a set F of compatibility formulae. For instance, the three formulae below the line in \nTable 4 are generated by cE&#38;%e(F), where F is the set of for- mulae given above the line in Table \n4. The corresponding com- patibility constraints that are obtained from R(cl&#38;&#38;e(F)) are listed \nbelow the line in Table 7. Example 5.15 As we will see in Section 5.2.3, compatibil-ity constraints play \na crucial role in the shape-analysis algo-rithm. Without them the algorithm would often be unable to \ndetermine that the data structure being manipulated by a list-manipulation program is actually a list. \nIn particular, constraint (31) allows us to do a more accurate job of ma-terialization: When is(u) evaluates \nto 0 and one incoming n edge is 1, to satisfy constraint (31) a second incoming n edge cannot have the \nvalue l/2-it must have the value 0, i.e., no such edge exists (cf. Examples 5.9 and 5.19). This allows \nedges to be removed (safely) that a more naive materi- alization process would retain (cf. Sh@AIreS .t&#38;,,2 \nand S6,2 in Figure 5), and permits the improved shape-analysis algorithm to generate more precise structures \nfor reverse than the ones generated by the simple shape-analysis algorithm described in Sections 2.3 \nand 4. . Henceforth, we assume that c&#38;&#38; has been applied to all sets of hygiene conditions. Definition \n5.16 (Compatible Three-Valued Structures). The set of compatible three-valued structures 3-CSTRlJCqP,R(F)] \nE 3-STRUCqP] is defined by S E 3-CSTRUCqP,R(F)] i_@S b R(F). I 5.2.2 The Coerce Operation We are now \nready to show how the coerce operation works. Example 5.17 Consider structure S&#38;o,2 from Figure 5 \nagain. The structure S5+,,2 violates constraint (32) under the assign- ment [v I-) u.l,vl I+ ul,v2 C) \nu.01. Because ~(Is)(u.l) = 0, ~1 # u.0, and b(n)(ul, 21.1)= 1, yet, ~(n)(u.O, u.1) = l/2, con-straint \n(31) is not, satisfied: The left-hand side evaluates to 1, whereas the right-hand side evaluates to l/2. \n0 This example motivates the following definition: Definition 5.18 The operation coerce: 3-STRlJCqP] \n-+ 3-CSTRUCqP, R(F)] U {I} is defined as follows: coerce(S) def the maximal S such that S c s, US = US, \nand S E 3-CSTRUCflP, R(F)], or I if no such S exists. 0 Example 5.19 The application of coerce to the \nstructures S+.,O, S+,l, and SS,~,Z is shown in the bottom block of Fig- ure 5. It yields Ss,O, S&#38;l, \nand S6,2, respectively. There are important differences between the structures S&#38;O, Ss,l, and S&#38;2 \nthat reSUk from the improved k_tnSfOrIrXT for statement st4 : x = x->n, and the structure Ss that is \nthe result of the simple version of the transformer (see the fourth entry of Figure 3): x points to a \nsummary node in Ss, whereas in none of Ss,O, S&#38;l, and Se,2 does 2 point to a summary node. 1 5.2.3 \nThe Coerce Algorithm In this subsection, we describe an algorithm, Coerce, that im- plements the operation \ncoerce defined in Section 5.2. This algorithm actually finds a maximal solution to a system of constraints \nof the form defined in Definition 5.12. It is conve- nient to partition these constraints into the following \ntypes: (P(v~,vz,... ,v/c) D b (34) (p(vl,V2,... ,vk) b (vl =V2) (35) (P(Vl,VZ,... , vk) D pb(vl,v2,... \n,vk) (36) where b E (0, 1,1/2}and the superscript notation means the following: ppl 3 cp and p E ycp. \nWe say that constraints in function Coerce(S: 3-STRUCT[P], R(F): Constraint set) retuns 3-CSTRUCT[P, \nR(F)] u {I} s := s while there exists a constraint c G pl D ~72 E R(F) and an assignment 2: freeVars(c) \n--t Us such that S , 2 p c do switch p2 case cp2 z b /* Type I */ return I case p2 E (211 = ~2)~ /* Type \nII */ if b = 1 and Z(v,) = Z(v2) and ~~ (sm)(Z(vl)) = l/2 then ~~ (sm)(Z(vl)) := 0 else return I case \n(~2 E pb(vl, . . . , vk) /* Type III */ if ~ (p)(Z(v1), . . . , z(Vk)) = l/2 then ~~ (p)(.i?(v&#38;. \n. . , z(vk)) := b else return _L end switch od return S end Figure 7: An iterative algorithm for solving \nthree-valued con-straints. the forms (34), (35), and (36) are Qpe I, Qpe II, and Type III constraints, \nrespectively. The algorithm for coerce is shown in Figure 7. The input is a three-valued structure S \nE 3-STRUCT[P] and a set of constraints R(F). It initializes S to the input structure S and then repeatedly \nrefines 5 by lowering predicate values in L from l/2 into a definite value, until either: (i) a constraint \nis irreparably violated, i.e., the left-hand and the right-hand side have different definite values, \nin which case the algorithm returns I, or (ii) no constraint is violated, in which case the algorithm \nsuccessfully returns S . The main loop is a case switch on the type of the constraint considered: . A \nviolation of a Type I constraint is irreparable since the right-hand side is a literal. . A violation \nof a Type II constraint can be fixed only when the right-hand side is an equality (as opposed to a negated \nequality) that evaluates to l/2. This can happen when there is an individual u that is a summary node: \n[VI = V&#38; ([Vl I+ u, v2 c) ?J]) = lS (Sm)(a) = l/2. In this case, ~~ (srn)(u) is set, to 0. . A violation \nof a Type III constraint can be fixed when the predicate entry is indefinite. The correctness of algorithm \nCoerce stems from the fol- lowing lemma: Lemma 5.20 For every S, S1 E 3-STRUCljP], such that S1 C S and \nSI /= R(F), and for every structure S during each e teration of Coerce, S1 E S . Proof: By induction \non the number of iterations. Coerce must terminate after at most n steps, where n is the number of definite \nvalues in S , which is bounded by &#38;p lulQr+(p). 6 Related Work The following previous shape-analysis \nalgorithms, which all make use of some kind of shape-graph formalism, can be viewed as instances of \nour framework: . The algorithm of [ll], which collapses individuals that are not reachable from a pointer \nvariable in k or fewer steps, for some fixed k. This algorithm can be captured in our framework by using \ninstrumentation predicates of the form reachable-from-x-via-access-path-c? , for ]a! 5 k. . The algorithms \nof [12,2], which can be incorporated into the framework by introducing unary core predicates that record \nthe allocation sites of heap cells. . The algorithm of [16], which can be captured in the framework using \nthe predicates cf.b(u) and c&#38;f(v) (see Tables 2 and 3). . The algorithms of [22, 191. These map unbounded-size \nstores into bounded-size abstractions by collapsing con-crete cells that are not directly pointed to \nby program variables into one abstract cell, whereas concrete cells that are pointed to by different \nsets of variables are kept apart in different abstract cells. (See also the discussion in Section 4.3.) \n Throughout this paper, we have focused on precision and ignored efficiency. The above-cited algorithms \nare more ef-ficient than the one presented in this paper; however, Sec-tion 1.2 discusses reasons why \nit should be possible to incor-porate well-known techniques for improving efficiency into our approach. \nIn addition, the techniques presented in this paper may also provide a new basis for improving the efficiency \nof shape-analysis algorithms. In particular, the machinery we have introduced provides a way both to \ncollapse individuals of 3-valued structures, via embedding, as well as to materialize them when necessary, \nvia focus. Roughly speaking, the chief alternative to the use of shape graphs involves representing may-aliases \nbetween pointer-access paths [8, 14, 4, 5, 201. Compared with shape graphs, these methods have certain \ndrawbacks. In particular, shape graphs represent the topological properties of the store directly, which \nallows certain operations, such as destructive updates, to be tracked more precisely. In addition., shape \ngraphs are a more intuitive mechanism for reporting Information back to a hu-man, and thus may be more \nuseful in program-understanding tools. On the other hand, representations of may-aliases can be more \ncompact than shape graphs, and some may-alias al-gorithms are capable of representing information that \ngoes beyond the capabilities of bounded structures [4, 51. Acknowledgements We are grateful for the helpful \ncomments of A. Avron, T. Ball, M. Benedikt, N. Dor, M. Gitik, K. Kunen, V. Lifschitz, H.R. Nielson, M. \nO Donnell, A. Rabinovich, and K. Sieber. We thank K.H. Rose for the Xy-pit I&#38;QXpackage. [I] U. Assmann \nand M. Weinhardt. Interprocedural heap anal- ysis for parallelizing imperative programs. In W. K. Giloi, \nS. Jghnichen, and B. D. Shriver, editors, Pmgmmming Models For Massively Pamllel Computers, pages 74-82, \nWashington, DC, September 1993. IEEE Press. [2] D.R. Chase, M. Wegman, and F. Zadeck. Analysis of pointers \nand structures. In SIGPLAN Conf. on Prog. Lang. Design and Impl., pages 296-310, New York, NY, 1990. \nACM Press. [3] P. Cousot and R. Cousot. Systematic design of program anal-ysis frameworks. In Symp. on \nPrint. of Prog. Lang., pages 269-282, New York, NY, 1979. ACM Press. [4] A. Deutsch. A storeless model \nfor aliasing and its abstractions using finite representations of right-regular equivalence rela-tions. \nIn IEEE International Conference on Computer Lan-guages, pages 2-13, Washington, DC, 1992. IEEE Press. \n[5] A. Deutsch. Interprocedural may-alias analysis for pointers: Beyond k-limiting. In SIGPLAN Conf. \non Prog. Lang. Design and Zmpl., pages 230-241, New York, NY, 1994. ACM Press. [6] L. Hendren. Pamllelizing \nPrograms with Recursive Data Struc-tures. PhD thesis, Cornell Univ., Ithaca, NY, Jan 1990. [7] L. Hendren, \nJ. Hummel, and A. Nicolau. Abstractions for re-cursive pointer data structures: Improving the analysis \nand the transformation of imperative programs. In SIGPLAN Conf. on Prog. Lang. Design and Impl., pages \n249-260, New York, NY, June 1992. ACM Press. [8] L. Hendren and A. Nicolau. Parallelizing programs with \nre-cursive data structures. IEEE Trans. on Par. and Dist. Syst., l( 1):35-47, January 1990. [9] C.A.R. \nHoare. Recursive data structures. Int. J. of Comp. and Znf. Sci., 4(2):105-132, 1975. [lo] S. Horwitz, \nP. Pfeiffer, and T. Reps. Dependence analysis for pointer variables. In SIGPLAN Conf. on Prog. Lang. \nDesign and Impl., pages 28-40, New York, NY, 1989. ACM Press. [ll] N.D. Jones and S.S. Muchnick. Flow \nanalysis and optimiza-tion of Lisp-like structures. In S.S. Muchnick and N.D. Jones, editors, Program \nFlow Analysis: Theory and Applications, chapter 4, pages 102-131. Prentice-Hall, Englewood Cliffs, NJ, \n1981. [12] N.D. Jones and S.S. Muchnick. A flexible approach to inter-procedural data flow analysis and \nprograms with recursive data structures. In Symp. on Print. of Prag. Lang., pages 66-74, New York, NY, \n1982. ACM Press. [13] S.C. Kleene. Introduction to Metamathematics. North-Holland, second edition, 1987. \n[14] W. Landi and B.G. Ryder. Pointer induced aliasing: A problem classification. In Symp. on Print. \nof Prog. Lang., pages 93-103, New York, NY, January 1991. ACM Press. [15] J.R. Larus and P.N. Hilfinger. \nDetecting conflicts between structure accesses. In SIGPLAN Conf. on Prog. Lang. Design and Impl., pages \n21-34, New York, NY, 1988. ACM Press. [16] J. Plevyak, A.A. Chien, and V. Karamcheti. Analysis of dy- \nnamic structures for efficient parallel execution. In U. Baner- jee, D. Gelernter, A. Nicolau, and D. \nPadua, editors, Lan-guages and Compilers for Parallel Computing, volume 768 of Let. Notes in Comp. Sci., \npages 37-57, Portland, OR, August 1993. Springer-Verlag. [17] M. Sagiv, T. Reps, and R. Wilhelm. Solving \nshape-analysis problems in languages with destructive updating. In Symp. on Print. of Prvg. Lang., New \nYork, NY, January 1996. ACM Press. [18] M. Sagiv, T. Reps, and R. Wilhelm. Parametric shape analysis \nvia J-valued logic. Tech. Rep. TR-1383, Comp. Sci. Dept., Univ. of Wisconsin, Madison, WI, July 1998. \nAvailable at Lhttp://www.cs.wisc.edu/wpis/papers/parametric.ps . [19] M. Sagiv, T. Reps, and R. Wilhelm. \nSolving shape-analysis problems in languages with destructive updating. tins. on Prag. Lang. and Syst., \n20(1):1-50, January 1998. [20] S. Sagiv, N. Francez, M. Rodeh, and R. Wilhelm. A logic-based approach \nto data flow analysis problems. Acta In., 35(6):457-504, June 1998. [21] J. Stransky. A lattice for abstract \ninterpretation of dynamic (Lisp-like) structures. Raf. and Comp., 101(1):70-102, Nov. 1992. [22] E. Y.-B. \nWang. Analysis of Recursive Types in an Imperative Language. PhD thesis, Univ. of Calif., Berkeley, CA, \n1994.   \n\t\t\t", "proc_id": "292540", "abstract": "", "authors": [{"name": "Mooly Sagiv", "author_profile_id": "81100150928", "affiliation": "Dept. of Comp. Sci., Tel-Aviv Univ., Tel-Aviv 69978, Israel", "person_id": "PP39029858", "email_address": "", "orcid_id": ""}, {"name": "Thomas Reps", "author_profile_id": "81100117392", "affiliation": "Comp. Sci. Dept., Univ. of Wisconsin, 1210 W. Dayton St., Madison, WI", "person_id": "PP40023877", "email_address": "", "orcid_id": ""}, {"name": "Reinhard Wilhelm", "author_profile_id": "81100325916", "affiliation": "Fachbereich 14 Informatik, Univ. des Saarlandes, 66123 Saarbr&#252;cken; Germany", "person_id": "PP39037801", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/292540.292552", "year": "1999", "article_id": "292552", "conference": "POPL", "title": "Parametric shape analysis via 3-valued logic", "url": "http://dl.acm.org/citation.cfm?id=292552"}