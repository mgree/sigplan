{"article_publication_date": "06-09-2004", "fulltext": "\n Prefetch Injection Based on Hardware Monitoring and Object Metadata Ali-Reza Adl-Tabatabai, Richard \nL. Hudson, Mauricio J. Serrano, Sreenivas Subramoney Programming Systems Laboratory Microprocessor Technology \nLaboratory Intel Corporation Santa Clara, California USA {Ali-Reza.Adl-Tabatabai | Rick.Hudson | Mauricio.J.Serrano \n| Sreenivas.Subramoney}@Intel.com ABSTRACT Cache miss stalls hurt performance because of the large gap \nbetween memory and processor speeds for example, the popular server benchmark SPEC JBB2000 spends 45% \nof its cycles stalled waiting for memory requests on the Itanium\u00ae 2 processor. Traversing linked data \nstructures causes a large portion of these stalls. Prefetching for linked data structures remains a major \nchallenge because serial data dependencies between elements in a linked data structure preclude the timely \nmaterialization of prefetch addresses. This paper presents Mississippi Delta (MS Delta), a novel technique \nfor prefetching linked data structures that closely integrates the hardware performance monitor (HPM), \nthe garbage collector s global view of heap and object layout, the type-level metadata inherent in type-safe \nprograms, and JIT compiler analysis. The garbage collector uses the HPM s data cache miss information \nto identify cache miss intensive traversal paths through linked data structures, and then discovers regular \ndistances (deltas) between these linked objects. JIT compiler analysis injects prefetch instructions \nusing deltas to materialize Algorithms, Measurement, Performance, Design, Experimentation, Languages. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, \nto post on servers or to redistribute to lists, requires prior specific permission and/or a fee. PLDI \n04, June 9 11, 2004, Washington, DC, USA. Copyright 2004 ACM 1-58113-807-5/04/0006 $5.00. Keywords Prefetching, \ncompiler optimization, garbage collection, cache misses, profile-guided optimization, virtual machines. \n1. INTRODUCTION Memory systems performance remains one of the biggest bottlenecks in processor performance. \nFigure 1 illustrates this problem, showing the percentage of execution cycles attributed to data cache \nstalls running the SPEC JBB2000 and SPEC JVM98 benchmarks [29] on the Itanium\u00ae 2 processor. For memory\u00adintensive \nprograms such as SPEC JBB2000 and db the processor spends up to 45% of its execution cycles stalled \nwaiting for memory. This problem will only worsen as processor speed continues to outpace memory speed, \nand as the demand on the memory subsystem increases due to chip-level multiprocessing. 50% % of execution \ncycles prefetch addresses. We have implemented MS Delta in a fully dynamic profile-guided optimization \nsystem: the StarJIT dynamic compiler [1] and the ORP Java virtual machine [9]. We demonstrate a 28-29% \nreduction in stall cycles attributable to the high-latency cache misses targeted by MS Delta and a speedup \nof 11-14% on the cache miss intensive SPEC JBB2000 benchmark. 40% 30% 20% 10% 0% Categories and Subject \nDescriptors D.3.3 [Programming Languages]: Language Contructs and Features Dynamic storage management; \nClasses and objects. General Terms Figure 1. Percentage of execution cycles stalled due to data cache \nmisses. Prefetching tackles the memory latency problem by fetching data into processor caches in advance \nof their use. To prefetch in a timely fashion, the processor must materialize the prefetch address early \nenough to overlap the prefetch latency with other computations or latencies. For both hardware and software-based \nstrategies, prefetching for linked data structures remains a major challenge because serial data dependencies \nbetween elements in a linked data structure preclude the timely materialization of prefetch addresses. \nFigure 2 illustrates the challenge of prefetching for linked data structures. This figure shows three \nlinked objects. Assume that traversal of this linked structure causes all three objects to miss in the \ncache. The processor cannot load the String object until it has loaded the brandInfo field of Item. Similarly, \nit cannot load the Char Array object until it has loaded the value field of String. Thus data dependences \nserialize cache misses during traversal, as illustrated by the chart. Char Array brandInfo value Memory \nAccess into delinquent paths representing linked data structure traversals that cause high- latency cache \nmisses. Taking advantage of object placement, the GC determines regular deltas between objects along \nthe paths. Knowing the deltas and the paths simplifies the JIT compiler analysis needed to schedule prefetches \nalong a traversal path: The JIT combines the address of the first object in the path with the deltas \nto materialize prefetch targets. This means that the miss latency experienced by the first object in \na traversal path hides the miss latency of subsequent objects along the path. Raw Time Figure 2. Serial \ndata dependences in linked data structures. This paper presents Mississippi Delta (MS Delta), a novel \ntechnique for prefetching linked data structures that starts with information from the hardware performance \nmonitor (HPM), and uses the garbage collector (GC) to discover cache miss intensive paths through linked \ndata structures and regular distances (deltas) between objects in these structures. The JIT compiler \nsubsequently uses the deltas to materialize prefetch addresses in a timely fashion. Figure 3 shows how \nMS Delta uses deltas to predict prefetch addresses, thus avoiding data dependences and permitting timely \nprefetches. The GC discovers a regular delta between Item and String, as well as Item and Char Array. \nThe JIT compiler uses this delta to inject prefetches of String and Char Array such that the prefetch \nlatency overlaps the miss latency of Item, as illustrated by the chart. Delta to Char Array  Char Array \nbrandInfo value Memory Access Tim e Figure 3. Prefetching using deltas. Figure 4 shows the high-level \nMS Delta algorithm as it abstracts from raw HPM samples up to prefetches. The HPM provides samples of \nhigh-latency cache misses. Each sample includes the instruction pointer address (IP) and the referent \neffective address (EA) of the memory access. MS Delta abstracts these raw samples first into the delinquent \nobjects that caused the misses and then into a high level metadata graph, whose nodes represent object \ntypes, and whose edges represent relations induced by fields and array elements containing references. \nDuring heap traversal, the GC uses the delinquent objects to discover edges in the metadata graph that \napproximate the high\u00adlatency traversals between linked data. It then composes these edges HPM Metadata \nGraph Paths Deltas Prefetches Abstract  Figure 4. High-level MS Delta algorithm. This paper makes \nthe following novel contributions. First, MS Delta uses dynamic hardware-based data cache miss profiling \ninstead of software-based memory access profiling to greatly reduce the cost of profiling and to concentrate \nanalysis on loads that actually cause cache misses instead of loads that fall along frequently executed \nyet cache resident paths. Second, MS Delta leverages the GC s heap traversal to infer object layout properties \n(in the form of deltas between linked objects) useful for generating prefetch addresses in linked data \nstructures. By using deltas to materialize prefetch addresses, MS Delta avoids the inherent serial dependences \nthat make prefetching for linked data structures difficult. Third, MS Delta uses the GC s object placement \nability to maintain the deltas used for prefetching. Fourth, MS Delta abstracts the raw cache miss data \nup to the type and type connectivity level instead of tracking individual addresses and objects. By abstracting \nthe voluminous miss address information up to type\u00adlevel metadata, MS Delta concisely models cache miss \nbehavior, eliminating the need to maintain potentially large historic address specific structures. In \nsummary, MS Delta couples hardware data cache profiles and global heap properties with metadata to enhance \nand guide dynamic JIT compiler analysis, recompilation, and prefetch injection decisions. The rest of \nthis paper is organized as follows. The next section describes our experimental framework. Section 3 \ndescribes the algorithm for building the metadata graph using the HPM samples. Sections 4 and 5 describe \nhow the GC builds delinquent paths and discovers deltas between objects, respectively. Section 6 describes \nthe JIT algorithm for injecting prefetches and Section 7 presents experimental results on SPEC JVM98 \nand SPEC JBB2000. Section 8 discusses related work. 2. EXPERIMENTAL FRAMEWORK We have implemented MS \nDelta in the context of the StarJIT dynamic compiler [1] and the ORP JVM [9] running on the Itanium\u00ae \n2 platform [19]. The ORP JVM supports dynamic profile-guided feedback to the JIT compiler, and contains \na GC tool kit capable of supporting multiple collection algorithms [24] (e.g., generational, sliding \ncompaction, parallel, concurrent). To improve memory performance, ORP and StarJIT can compress pointers \nfrom 64 bits to 32 bits [2]. We have optimized the GC to take advantage of the Itanium\u00ae 2 processor features \n[16]. StarJIT features an SSA-based intermediate representation and performs aggressive profile-guided \nglobal optimizations such as devirtualization, inlining, bounds-check elimination, and others. StarJIT \nalso includes aggressive profile-guided code generator optimizations such as trace scheduling, speculation, \ncode layout, and others. StarJIT and ORP currently support two profiling strategies: control-flow edge \nprofiling using software instrumentation and hardware cache miss sampling. The Itanium\u00ae processor supports \nsampling of hardware cache misses via an HPM called the Performance Monitoring Unit (PMU). All measurements \nreported in this paper were gathered by running the SPEC JVM98 and SPEC JBB2000 benchmarks on a commercially \navailable 4 processor 1.5 GHz Itanium\u00ae 2 machine with 16 gigabytes of memory and 6 megabytes of 3rd-level \ncache (with 128-byte cache lines) running Microsoft s Windows 2003 Enterprise Edition. Figure 5 compares \nthe performance of StarJIT and ORP with a leading edge commercial JVM for the Itanium\u00ae processor (BEA \nWebLogic JRockit 1.4.1 SDK Developer Release). On these benchmarks, our baseline system performs 5-59% \nfaster than the commercial JVM. 1.7 1.6 1.5 1.4 1.3 1.2 1.1 1.0 Relative performance Figure 5. Performance \nof ORP relative to a commercial JVM. 3. BUILDING THE METADATA GRAPH MS Delta represents cache miss information \nin terms of types and their relationships using a concise metadata graph. This section describes how \nMS Delta abstracts HPM samples first into objects, then into types and related loads, and finally into \nthe edges needed to build this graph. 3.1 Delinquent Objects Each PMU sample forms a tuple comprising \nthe load instruction pointer (IP), target effective address (EA), and latency of the load causing the \nmiss. MS Delta programs the PMU to sample only high-latency cache misses so that it can concentrate on \nloads that access off-chip memory. MS Delta further eliminates samples whose EA do not fall within the \ncontiguous garbage collected heap. Each sample refers to an object that caused a cache miss; we call \nsuch objects delinquent objects. Each object starts with a header containing a virtual function table \npointer (vtable) that identifies the type of the object. MS Delta abstracts a sample into a delinquent \nobject by scanning backwards in memory starting from the EA of the sample, looking for a word that looks \nlike a valid vtable. To improve accuracy, the search probes a hash table containing valid vtables recorded \nby the class loader. The search ensures constant time by bounding the number of 8-byte words it visits \nto 100. If the search fails to locate a valid vtable it simply discards the sample. Of course a random \nsequence of bits can masquerade as a vtable (rare in practice) we discuss later how to deal with this \ninaccuracy. After abstracting the effective addresses up into delinquent objects, MS Delta constructs \nthe delinquent object set from the delinquent objects and their respective samples. Limiting the vtable \nsearch to at most 100 captures 97% of the interesting types in all of the SPEC JVM98 and SPEC JBB2000 \nbenchmarks except for compress, which exhibits misses in large arrays. MS Delta focuses on misses in \nlinked data structures, which usually consist of relatively small objects instead of large arrays. Standard \nloop prefetching techniques can typically address misses to large arrays (see [30] for an overview). \n3.2 Delinquent Types and Loads Experimental data shows that only a few types and a few loads cause the \nmajority of cache misses [27]. We refer to these types and loads as delinquent types and delinquent loads \n[10], respectively. The set of delinquent types and loads concisely characterizes an application s cache \nmisses. After identifying delinquent objects, MS Delta further abstracts the HPM data by rolling up the \ninformation contained in the delinquent object set to the set of delinquent types. To compute delinquent \ntypes the algorithm iterates through the delinquent object set accumulating the total miss latency for \neach type encountered. It then sorts these types by their latency and retains the topmost types whose \ncumulative latency contributes to most of the overall latency (types contribute to 90% of the latency \nin SPEC JBB2000, 5 delinquent types contribute to 99% of the latency in db, and 9 delinquent types contribute \n96% in mtrt. Similarly, 88 loads contribute 88% of the latency in SPEC JBB2000, and 24 loads contribute \n90% of the latency in db. A delinquent load can access more than one delinquent type because of subtyping. \nWe observed that in our benchmarks, each delinquent load accesses a dominant delinquent type. To filter \nout errors from misidentifying the correct vtable in a sample, MS Delta discards samples whose loads \naccess non\u00addelinquent types. for example, 98%). These types form the set of delinquent types. A similar \nalgorithm computes the set of delinquent loads, looking at sample IPs instead of types. Figure 6 and \n7 show the cumulative cache miss latency contributed by the top sorted delinquent loads and types, respectively. \nThese figures show that the set of delinquent loads and delinquent types is tractable. For example, 10 \ndelinquent to that particular field. At the end of the heap traversal the matrix concisely characterizes \nthe dynamic connectivity between each of the delinquent types. Note, that both the DMT and the metadata \ngraph are small data structures; for example, SPEC JBB2000 contains only 10 delinquent types and thus \nproduces a sparse 10 X 10 matrix. Furthermore, even though the object identification technique discussed \nin Section 3.1 occasionally misidentifies objects, the GC only encounters valid objects, thus making \nmisidentification benign. Figure 8 shows a portion of the metadata graph for SPEC JBB2000. Type Item \npoints to type String via fields name and brandInfo. Type String points to type Char Array, via field \nvalue. % total latency 100 90 80 70 60 50 40 30 20 10 0  compress jess db javac mtrt jack \nspecjbb Figure 6. Cumulative contribution of delinquent loads to total cache miss latency. 100 90  \n name 80 com press 70 jess  db Item 60   value Char Array % total latency  value Char Array 50 \n javac 40  mtrt brandInfo 30 jack 20 specjbb   Figure 8. Portion of SPEC JBB2000 metadata graph. \n10 0 1 3 5 7 9 11 13 15 17 19 num berofsortedtypes Figure 7. Cumulative contribution of delinquent \ntypes to total cache miss latency. 3.3 The Metadata Graph The metadata graph consists of delinquent types \nand the edges between them called delinquent edges. MS Delta piggybacks on the GC s heap traversal to \ncollect information needed to identify the metadata graph. When MS Delta encounters an object of delinquent \ntype during heap traversal, it iterates through each of the reference fields in the object to see if \nthey point to a child object of delinquent type. If MS Delta finds such a child object the pair has one \nof 4 possible delinquent relationships: Delinquent object to delinquent object (O\u00c6O) if both objects \nare delinquent objects. Figure 9 shows the DMT for the metadata graph in Figure 8. The y-axis contains \nthe parent delinquent types and the x\u00adaxis contains the child delinquent types. Each element of the matrix \ncontains a list of the fields connecting that element s parent type to its child type, or null if no \nfields connect the two types. For example, the element DMT[Item, String] consists of a linked list of \ntwo nodes, one of which corresponds to the brandInfo field connecting type Item to type String and the \nsecond corresponds to the name field between the same two types. These nodes contain the delinquent relationship \ncounters updated during heap traversal. Child Types String char Item array Null field ( value ); int \nO_to_O; int O_to_T; int T_to_O; int T_to_T; edge *next_edge; Null Null Null Null field( brandInfo ); \nint O_to_O; int O_to_T; int T_to_O; Null Null String Delinquent object to delinquent type (O\u00c6T) if only \nchar array the parent is a delinquent object. Delinquent type to delinquent object (T\u00c6O) if only Item \nthe child is a delinquent object. Delinquent type to delinquent type (T\u00c6T) if neither int T_to_T; edge \n*next_edge is a delinquent object. These counts are updated during heap traversal field( name ); MS Delta \nmaintains counts for each of the relationships in a sparse NxN matrix called the Dynamic Metadata Table \n (DMT), indexed using ids assigned to delinquent types. Each Figure 9. Portion of SPEC JBB2000 dynamic \nmetadata table. element in the matrix contains a linked list of nodes. Each node represents a field pointing \nfrom the parent type to the child type, and records delinquent relationships corresponding 4. DETERMINING \nDELINQUENT PATHS A delinquent edge connects a parent type to a child type in the metadata graph and represents \na delinquent load of the child using a reference field in the parent. A delinquent path comprises one \nor more delinquent edges and represents a traversal of a linked data structure that frequently misses. \nThe first type in a delinquent path is the delinquent base type. Discovering the delinquent base type \nand the associated load is key to locating where to inject prefetches. MS Delta uses the DMT to identify \ndelinquent edges. For each pair of delinquent types MS Delta examines the DMT to see if heap traversal \ndiscovered an edge connecting the pair. If so, MS Delta sums the O\u00c6O and the T\u00c6O delinquent relationships \nfor that edge. If this is greater than some lower bound N (a small fraction of the total number of distinguished \nobjects), then MS Delta considers this edge a delinquent edge candidate and further calculates a complex \nedge weight (CEW): CEW = 100*O O + 10*T O + O T CEW gives the highest weighting to the O\u00c6O component \nbecause it represents good evidence that the application followed this edge, causing a cache miss. The \nT\u00c6O component is important because it indicates how we actually reached a known delinquent object following \nan edge (field dereference) from a delinquent type. The O\u00c6T component is less important since it gives \nless assurance that the edge being followed leads to a delinquent object. This is particularly true if \nmultiple fields in a delinquent type have the same type. MS Delta sorts the delinquent edge candidates \nbased on their CEW, filtering all but the topmost edges. This information is then rolled up into the \nmetadata graph. MS Delta builds delinquent paths by composing delinquent edges. Initially, each delinquent \nedge is a delinquent path. To lengthen a delinquent path, MS Delta recursively finds an edge whose parent \ntype matches the child type of the last edge in the path. The algorithm terminates once it finds the \nlongest path for each delinquent edge, it encounters an array, or the path reaches a length limit. Each \npath has a weight equal to the sum of its edge s CEWs. This delinquent path information is then rolled \nup into the metadata graph. The algorithm for building delinquent paths misses some paths because it \nrequires all types along the path to be delinquent. If a delinquent object sits adjacent to its next \ndownstream object so that they often reside in the same cache line, the second object will rarely be \ndelinquent. Further analysis by the GC can detect when two connected types tend to reside on the same \ncache line, allowing the second type to be considered as part of the delinquent path. 5. DETERMINING \nPREFETCH DELTAS For each delinquent path, the delta determination algorithm computes deltas relative \nto the path s delinquent base type. The algorithm iterates through the delinquent object set and each \ntime it encounters an object whose type matches a delinquent base type, it traces the objects along delinquent \npaths starting from the delinquent object. For each edge it traverses along the path (i.e., each field \nit dereferences) it calculates the delta from the base object, binning the delta into a delta histogram \nfor that edge. After collecting the deltas into histograms, the algorithm discards deltas whose bins \ncomprise less that 10% of the deltas for that edge and annotates the metadata graph s edges with the \nremaining deltas. Note, that by only traversing paths starting from delinquent objects, MS Delta effectively \nsamples paths and deltas. The deltas indicate distances between bases of two objects that miss. Cache \nmisses, however, typically occur on an access to a field at some offset within the object; therefore, \nMS Delta also determines the effective offsets that cause misses by iterating over the delinquent object \nset, subtracting the object base from the effective address the HPM delivered. MS Delta then annotates \nthe metadata graph s edges with these effective offsets. The JIT adds the deltas and the effective offsets \nto the address of the base object to determine the prefetch target. This refinement proved more effective \nthan simply prefetching the entire referent object. The delta determination algorithm computes path-specific \ndeltas, improving prefetch accuracy. For example, depending on the path, the character array associated \nwith each string object is sometimes located before the string object and sometimes after it. One path \nwants to use the negative delta to prefetch the character array while another path wants to use a positive \ndelta. The delta determination algorithm distinguishes between these two paths. 5.1 Maintaining Deltas \nduring GC The ORP GC allocates using a frontier pointer scheme [16] resulting in allocation order object \nplacement. For many applications (e.g., SPEC JBB2000 and db) allocation order results in delinquent objects \nhaving regular deltas along delinquent paths. To maintain allocation order and also deal with fragmentation \nthe ORP GC employs sliding compaction. Performing compaction prior to calculating deltas results in more \nregular deltas between objects. This seems primarily due to short\u00adlived objects being interspersed with \nthe longer living delinquent objects. Because MS Delta abstracts deltas up to the type level, improving \ndelta consistency improves prefetch effectiveness. Compaction (or any other object movement during garbage \ncollection), however, requires the GC to update the delinquent object set during the repoint phase. 5.2 \nComputing Prefetch Deltas The benefit of prefetching a cache line is the total cache miss latency avoided. \nTo estimate this, MS Delta combines delta information from all delinquent paths starting at each base \ndelinquent type. It adds each delta and effective offset and divides the sum by the cache line size to \ncompute a delta in terms of cache lines. It then bins the associated latency into a histogram for that \nbase delinquent type. Each histogram bin reflects the benefit from prefetching that bin s cache line. \nMS Delta then assigns a low, medium, or high confidence rating based on this benefit, and does not prefetch \nlow confidence cache lines. MS Delta prefetches medium confidence cache lines using a non-temporal prefetch \ninstruction [19], which minimizes the risk of cache pollution, and prefetches high confidence cache lines \nusing a regular prefetch instruction. Figure 10 shows the layout for the metadata graph shown in Figure \n8. Consider the two paths starting at Item containing Char Arrays of variable size. The varying size \nof the Char Arrays reduces the accuracy of the deltas along the second path. If, however, the deltas \nare abstracted to cache lines as above, the prefetch will help along at least one of the paths. Figure \n11 shows that the SPEC JVM98 benchmarks do not exhibit many high-latency cache misses to the heap, whereas \nSPEC JBB2000 spends 27% of its execution stalled on high\u00adlatency cache misses to the heap. This figure \ncategorizes each cache miss latency cycle according to whether it was to the heap, and whether it was \na high or low-latency miss. High\u00adlatency misses typically access DRAM, which has a latency of 300-400 \ncycles. MS Delta, therefore, should aim to improve on SPEC JBB200 without degrading the other applications. \n Figure 12. SPEC JBB2000 metadata graph with deltas. 6. INJECTING PREFETCHES The compiler identifies \nthe candidate methods in which MS Delta injects prefetches, and the intermediate representation (IR) \nfor the delinquent loads, using a map from IPs to loads in the IR. For each delinquent load of a base \ntype, the compiler follows use-def links to track down the operation that produces that load s effective \naddress that is, the operation that adds the field offset to the object s base address. It then generates \ninstructions that add the base address to the constant prefetch deltas, thus materializing prefetch addresses. \nFinally, the JIT injects prefetches before the base type s delinquent load. Before invoking the compiler, \nMS Delta filters out any delinquent load of a base type that accounts for less than 10% of all misses \nof its delinquent type, thus focusing the compiler analysis. In contrast to prefetch techniques in scientific \ncodes, which typically overlap prefetch latency with computation, MS Delta overlaps prefetch latency \nwith the miss latency of the base type s delinquent load. This approach eliminates microarchitecture-specific \nmemory latency calculations, and generalizes across microarchitecture generations (which may Figure 12 \nshows the metadata graph that MS Delta builds for SPEC JBB2000 when run using compressed 32-bit pointers \n[2]. The edges contain the deltas (in cache lines) and field names. SPEC JBB2000 has seven delinquent \ntypes, some lying along multiple paths. MS Delta injects prefetches for seven delinquent paths at four \nlocations in two methods. have different memory latency) because both the miss and prefetch latency \nincrease at the same rate. 7. RESULTS We have run MS Delta against SPEC JBB2000 and the SPEC JVM98 suite. \nSPEC JBB2000 shows considerable improvement, while the SPEC JVM98 benchmarks show neither improvements \nnor degradations. 32b ptr, 32b ptr, 64b ptr, 64b ptr, large small large small  pages pages pages pages \n Figure 13. Improvements in SPEC JBB2000. 32-bit pointers, and small (8 kilobyte) versus large (16 megabyte) \npages. Figure 14 shows the non-heap, low-latency heap, and high-latency heap stall cycles for the baseline \nsystem and MS Delta, using 64\u00adbit and 32-bit pointers with a small page size. With 32-bit pointers, MS \nDelta reduces high-latency heap miss stalls from 25% down to 18% of the total cycles, a 28% reduction \nin high\u00ad heap-high latency heap-low latency non-heap- high latency non-heap- low latency latency heap \nmiss stalls. Similarly, with 64-bit pointers, MS Delta reduces high-latency heap miss stalls from 28% \ndown to 20% of the total cycles, a 29% reduction in latency in high-latency heap Figure 11. Cycles spent \non memory stalls. miss stalls. % of execution cycles 60% 50% 40% 30% 20% 10% 0% 32b ptr, 32b ptr, 64b \nptr, 64b ptr, base MS Delta base MS Delta non-heap low latency high latency Figure 14. Data stall reduction \nin SPEC JBB2000 with 64-bit and compressed 32-bit pointers. The samples are collected in buffers of 5000 \nsamples each. GC consumes full buffers, flushing any partially-filled buffers. If an application does \nnot exhibit enough cache misses between GCs, MS Delta will not see sufficient cache misses to apply its \nanalysis (and will not incur any overhead other than sample collection). To characterize SPEC JVM98, \nwhich has few high-latency cache misses, we had to increase the sampling rate to 100. GC takes up approximately \n2% of execution time for SPEC JBB2000. Performing path and delta determination at each GC (and then discarding \nthe results) increases this time to 4%. So for SPEC JBB2000 the upper bound on the cost is 2% or double \nthe normal cost of GC. Performing delta and path analysis at a GC is necessary only if the program moves \nto a new phase that could benefit from prefetching. Therefore, once MS Delta has samples it determines \nthe potential benefit from prefetching. If the benefit is too low, or there is no The ORP GC uses a frontier \npointer based allocation scheme and a significant change in miss behavior since the last prefetch optimization \nsliding compaction algorithm. We had assumed that the GC would (i.e., no phase change), then there is \nno point in performing any further need to proactively place objects based on delinquent paths but analysis \nregardless of the cost. We detect phase changes using the discovered that this didn t appear to be required. \nFurther investigation following metrics: revealed that allocation order placement already arranged objects \nin an Changes in the set of delinquent types.  Changes in the set of delinquent loads.  appropriate \norder. It is important to note that object placement schemes that segregate individual objects based \non size or schemes that result in random placement will not produce deltas usable by MS Delta. The SPEC \nJVM98 benchmark db is an example of a benchmark that is sensitive to cache size. On an earlier generation \nItanium\u00ae processor with a smaller 3-megabyte 3rd-level cache, MS Delta located two delinquent paths, \nand prefetch injection resulted in an overall improvement of 2%. When we moved to the later generation \nprocessor a noticeable reduction in high-latency cache misses reduced the opportunity for MS Delta and \nwhile our performance did not degrade we no longer saw any improvement. Db is interesting in another \naspect since it shows one of the drawbacks to the current algorithm, that of misidentifying the IP associated \nwith the base of a delinquent path. MS Delta detected two delinquent loads that loaded the same type. \nAt one delinquent load this type formed the base of a delinquent path and the inserted prefetch produced \na 5% improvement. Unfortunately at the other IP the detected delinquent path did not actually exist. \nInjecting prefetches at the second IP reduces performance from 5% down to only 2%, a graphic example \nof the dangers of over aggressive prefetching. We leave for future work how to deal with this problem. \n Increase in the rate of high-latency cache misses.  Changes in the number of threads producing samples. \n On SPEC JBB2000, MS Delta processes the samples, calculates the paths and deltas during GC, and recompiles \nonly once, resulting in minimal overhead during warm-up. The total compilation cost was approximately \n0.08 seconds, negligible for SPEC JBB2000, which runs for several minutes. 7.2 Filtering Characterization \n 7.1 Overheads Any system relying on dynamic profile-guided optimization includes a feedback loop that \nprofiles the running code followed by recompiling the code followed by executing the code. The value \nof the optimization is the difference between the benefit of the optimizations and the cost of the profiling, \nanalysis, and recompilation. Reducing profiling cost or frequency can control the cost. MS Delta uses \nthe HPM, which has a very low sampling overhead, to reduce the cost. Not surprisingly, the cost related \nto GC heap traversal dominates. For SPEC JBB2000, a sampling rate of 1400, which generates one sample \nevery 1400 high-latency cache misses, results in the delinquent paths shown in Figure 12. Increasing \nthe rate produces the same  vtable not found not delinquent load not delinquent type delinquent types \nand paths. (Similarly for db on the previous generation Itanium\u00ae processor.) Obtaining a sample costs \nabout 1000 cycles. We measured a negligible overhead (i.e., much less than 1%) Figure 15. Effectiveness \nof filtering. due to collecting samples on SPEC JBB2000. This figure shows the percentage of samples \neliminated if (a) the object vtable was not found, which eliminates less than 2% of the samples; (b) \nthe sample s load was not a % of references delinquent load, which eliminates up to an additional 5% \nof the samples; and (c) the sample s delinquent load did not access a delinquent type, which eliminates \nless the 1% of the samples. These filters combined eliminate 2 to 7.5% of the samples. 7.3 Delta Characterization \nTo determine whether allocation order produces predictable deltas between objects, we instrumented the \nGC to look at each reference and determine the number of cache lines separating the referencing object \nfrom the referent object. From this we construct a histogram of deltas for each field of reference type, \nand extract the most common cache line delta from each histogram. We sum these most common deltas to \ndetermine the percent of total references that Non-Heap Young Mature  Figure 17. Age of objects causing \nlatency. exhibit the most common deltas for their field. Figure 16 shows that for a GC that maintains \nallocation order 8. RELATED WORK placement the percent of common deltas ranges from 20% to Several authors \nhave recognized the importance of garbage 52% across the SPEC JVM98 and SPEC JBB2000 collection techniques \nto improve memory performance bybenchmarks suite, a surprising high number. This data positioning objects. \nOne of earliest works employed cdr coding inshows how often one can correctly predict the value of a \nthe Lisp Machine [14]. White [31] suggested that paging reference field using the most common delta for \nthat field; performance should be a primary task of garbage collection. for example, 20% of SPEC JBB2000 \ns references can be Chilimbi and Larus [5] improved cache line packing by using correctly predicted using \ndeltas. software to monitor loads and having the GC place objects based on temporal locality. Yefim et \nal [28] used allocation frequency to 60% 50% 40% 30% 20% 10% 0% Figure 16. Percent of references with \nfrequent field-level identify prolific types and then to place objects based on prolificacy. Wilson et \nal [32] focused on ameliorating the negative paging effects associated with garbage collection by improving \nthe placement of objects using connectivity. Inagaki et al [18] also recognize the benefits of maintaining \nallocation order at garbage collection time to maintain deltas between objects. Early prefetching work \nconcentrated on improving performance in scientific code with densely packed arrays; see [30] for a survey. \nPrefetching linked data structures requires predicting the access patterns, a challenging problem. Luk \net al [23] and Wu et al [34] use stride prefetching to exploit regular patterns of access in linked-list \ntraversals. The literature for hardware stride prefetching is abundant; for example, see Sair et al [26]. \nSeveral authors have recently recognized the existence of deltas between loads or between objects that \ncan be used for prefetching. Inagaki et al [18] explore software delta prefetching within loops and Zhou \net al [35] explore hardware value prediction. deltas. 7.4 Delinquency Characterization Figure 17 breaks \nout total execution cycles stalled due to memory latency according to object age. This includes both \nhigh and low\u00adlatency stalls as well as non-heap stalls. An object is young until it has survived a garbage \ncollection at which point it matures. For SPEC JBB2000 and db, the two benchmarks with the highest memory \nstalls, mature objects account for most of the memory stalls. This indicates that objects causing most \nof the miss latency survive a garbage collection, and are thus available for delta and delinquency analysis \nby the GC. This further indicates that delinquent objects are available to the GC in case it decides \nto induce deltas between objects along a delinquent path as it moves them during a GC cycle. Helper or \nspeculative threads [20] attempt to prefetch data by forcing cache misses ahead of the worker thread. \nThese techniques can use MS Delta techniques to materialize prefetch addresses in the helper thread without \nloss of generality of either technique. Roth and Sohi [25] prefetch linked data structures by augmenting \nobjects with fields containing the addresses of objects to prefetch. MS Delta materializes prefetch addresses \nusing constant deltas compiled into the code rather than augmenting objects with a new field. Chilimbi \nand Hirzel [6] predict hot data streams using a finite state machine that represents a program s frequently \nexecuted address streams. In contrast, MS Delta concisely models the cache miss behavior of a program \nusing metadata, and predicts miss addresses using deltas, which allow MS Delta to prefetch addresses \nthat have not been profiled. Similar to MS Delta, other authors have also used metadata to concisely \nmodel memory behavior. Wu et al [33] use types to characterize cache misses. Their characterization of \ncache misses replaces effective address with the object type, thus achieving a more concise representation \nto compress traces of data cache misses. Calder at al [4] recognized other forms of metadata that allow \nconcise modeling; for example allocation units managed by malloc-like allocators and memory regions (stack, \nheap, constant area, etc). Abstracting addresses up to metadata dramatically reduces the amount of information \nneeding analysis, and exposes patterns in address streams. MS Delta uses hardware monitoring, which has \nfewer overheads than software monitoring and accurately identifies delinquent loads, which benefit from \nprefetch. Other authors [23][22] have also used hardware monitoring of cache misses to concentrate prefetch \non delinquent loads. In contrast, several authors have used software instrumentation to predict cache \nmisses. Chilimbi and Hirzel [6] used whole program instrumentation to track memory references, using \nbursty profiling to reduce instrumentation overhead. Chilimbi and Larus [5] reduce instrumentation overhead \nby tracking only the base address of an object. Wu et al [34] and Inagaki et al [18] used software-based \nprofiling to guide prefetching optimizations in loops, where cache misses are likely to occur. 9. CONCLUSIONS \nIn this paper, we have presented Mississippi Delta, a novel technique for prefetching linked data structures \nthat closely integrates the hardware performance monitor, the garbage collector s global view of heap \nand object layout, the type-level metadata inherent in type-safe programs, and JIT compiler analysis. \nWe have shown how Mississippi Delta s dynamic closed loop system abstracts raw addresses and instruction \npointers delivered by the hardware up into a concise metadata graph where reasoning can be done at the \ntype level instead of at the raw address level. We have shown how Mississippi Delta guides the JIT analysis \nin inserting timely prefetches by finding delinquent paths through the metadata graph and calculating \ndeltas. Finally, we have shown how these prefetch techniques result in a 11-14% speedup on the cache \nmiss intensive SPEC JBB2000 benchmark. Mississippi Delta further expands the garbage collector s role \nto include observing memory system performance and guiding memory optimizations using global heap properties \nrelated to object placement and connectivity. Mississippi Delta demonstrates that researchers should \nview the garbage collector as an integral part of the dynamic profile feedback loop that produces highly \noptimized code. 10. ACKNOWLEDGMENTS The authors wish to thank the members of the StarJIT dynamic compiler \nand ORP virtual machine teams, Jay Bharadwaj, Dong-Yuan Chen, Michal Cierniak, Marsha Eng, Anwar Ghuloum, \nNeal Glew, Brian T. Lewis, Vijay Menon, Brian R. Murphy, Bratin Saha, Tatiana Shpeisman, James Stichnoth, \nand Weldon Washburn, for providing a high-performance Java infrastructure that allowed us to do this \nresearch. The authors also thank Jesse Fang for his encouragement and insights, which made this research \npossible. 11. REFERENCES [1] Adl-Tabatabai, A., Bharadwaj, J., Chen, D-Y, Ghuloum, A., Menon, V., Murphy, \nB., Serrano, M., and Shpeisman, T. The StarJIT Compiler: A Dynamic Compiler for Managed Runtime Environments. \nIntel Technology Journal, February 2003. [2] Adl-Tabatabai, A., Bharadwaj, J., Eng, M., Fang, J., Lewis, \nB.T., Murphy, B.R., Stichnoth, J., and Cierniak, M. Improving 64-bit Java IPF Performance by Compressing \nHeap References. In Code Generation and Optimization (CGO), 2004. [3] Cahoon, B., and McKinley, K. Data \nFlow Analysis for Software Prefetching Linked Data Structures in Java. In Parallel Architectures and \nCompilation Techniques (PACT), 2001. [4] Calder, B., Krintz, C., John, S., and Austin, T. Cache-Conscious \nData Placement. In Architecture Support for Programming Languages and Operating Systems (ASPLOS), 1998. \n[5] Chilimbi, T., and Larus, J. Using Generational Garbage Collection To Implement Cache-Conscious Data \nPlacement, In Proceedings of International Symposium on Memory Management (ISMM), 1998. [6] Chilimbi, \nT., and Hirzel, M. Dynamic Hot Data Stream Prefetching for General Purpose Programs. In Programming Languages \nDesign and Implementation (PLDI), 2002. [7] Chilimbi, T., and Larus, J. Cache-conscious Structure Layout. \nIn Programming Languages Design and Implementation (PLDI), 1999. [8] Chilimbi, T. Efficient Representations \nand Abstractions for Quantifying and Exploiting Data Reference Locality. In Programming Languages Design \nand Implementation (PLDI), 2001. [9] Cierniak, M., Eng, M., Glew, N., Lewis, B., and Stichnoth, J. The \nOpen Runtime Platform: A Flexible High-Performance Managed Runtime Environment. Intel Technology Journal. \nhttp://developer.intel.com/technology/itj/2003/volume07issu e01, February 2003. [10]Collins, J., Wang, \nH., Tullsen, D., Hughes, C., Lee, Y-F., Lavery, D., and Shen, J. Speculative Precomputation: long\u00adrange \nprefetching of delinquent loads. In International Symposium of Computer Architecture (ISCA), 2001. [11]Dieckmann, \nS., and H\u00f6lze, U. A Study of the Allocation Behavior of the SPECjvm98 Java Benchmarks. In European Conference \non Object-Oriented Programming (ECOOP), 1999. [12]Dimpsey, R., Arora, R., and Kuiper, K. Java Server \nPerformance: A Case Study of Building Efficient, Scalable JVMs. IBM Systems Journal, 39(1): 151-174, \n2000. [13]Fenichel, R., and Yochelson, J., A Lisp Garbage Collector for Virtual Memory Computer Systems. \nCommunications of the ACM, 12(11):611-612, November 1969. [14]Greenblatt, R. The LISP Machine; Working \nPaper No. 79, M.I.T. A. I. Lab, Cambridge MA (Nov 1974). [15]Hirzel, M., Diwan, A., and Hertz, M. Connectivity-Based \nGarbage Collection. In Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA), 2003. \n[16]Hudson, R., Moss, J.E.B., Subramoney, S., and Washburn, W. Cycles to Recycle: Garbage Collection \non the IA-64. In International Symposium on Memory Management (ISMM), 2000. [17]Hudson, R., and Moss, \nJ.E.B. Copying Garbage Collection without stopping the world. Concurrency and Computation: Practice and \nExperience 15(3-5), 2003. [18] Inagaki, T., Onodera, T., Komatsu, H., and Nakatani, T. Stride Prefetching \nby Dynamically Inspecting Objects. In Programming Languages Design and Implementation (PLDI), 2003. [19]Intel \nCorp. IA-64 Application Developers Architecture Guide. May 1999. [20]Kim, D., Liao, S., Wang, P., Cuvillo, \nJ., Tian, X., Zou, X., Wang, H., Yeung, D., Gikar, M., and Shen, J. Physical Experimentation with Prefetching \nHelper Threads on Intel s Hyper-Threaded Processors. In Code Generation and Optimization (CGO), 2003. \n[21]Lam, M., Wilson, P., and Moher, T. Object Type Directed Garbage Collection to Improve Locality. In \nInternational Workshop of Memory Management ( IWMM), 1992. [22] Lu, J., Chen, H., Fu, R., Hsu, W-C, Othmer, \nB., Yew, P-C, and Chen, D-Y. The Performance of Runtime Data Cache Prefetching in a Dynamic Optimization \nSystem. In International Symposium on Microarchitecture (MICRO), Dec. 2003. [23]Luk, C-K, Muth, R., Patil, \nH., Weiss, R., Lowney, P.G., and Cohn, R. Profile-guided post-link stride prefetching. In International \nConference on Supercomputing (ICS), 2002. [24]Jones, R., and Lins, R. Garbage Collection, Algorithms \nfor Automatic Dynamic Memory Management. John Wiley and Sons, 1996. [25]Roth, A., and Sohi, G. Effective \nJump Pointer Prefetching for Linked Data Structures. In International Symposium on Computer Architecture \n(ISCA), 1999. [26]Sair, S., Sherwood, T., and Calder, B. Quantifying Load Stream Behavior. In International \nSymposium on Microarchitecture (MICRO), 2002. [27] Shuf, Y., Serrano, M.J., Gupta, M., and Singh, J.P. \nCharacterizing the Memory Behavior of Java Workloads: A Structured View and Opportunities for Optimizations. \nIn Conference on Measurement and Modeling of Computer Systems (SIGMETRICS), 2001. [28]Shuf, Y., Gupta, \nM., Franke, H., Appel, A., and Singh, J.P. Creating and Preserving Locality of Java Applications at Allocation \nand Garbage Collection Times. In Object-Oriented Programming Systems, Languages, and Applications (OOPSLA), \n2002. [29]Standard Performance Evaluation Corporation. http://www.specbench.org. [30]VanderWiel, S. and \nLilja, D. Data Prefetch Mechanisms. In ACM Computing Surveys, 2000. [31]White, J.L. Address/Memory Management \nfor a Gigantic LISP Environment or, GC Considered Harmful. Conference Record of the 1980 LISP Conference, \nStanford University, Palo Alto California. [32]Wilson, P.R., Lam, M.S., and Moher, T.G. Effective Static\u00adgraph \nReorganization to Improve Locality in Garbage-Collected Systems. In Programming Languages Design and \nImplementation (PLDI), 1991. [33]Wu, Q., Pyatakov, A., Spiridonov, A., and August, D. Exposing Memory \nAccess Regularities for Effective Memory Profiling. In Code Generation and Optimization (CGO), 2004. \n[34]Wu, Y., Serrano, M.J., Krishnaiyer, R., Li, W., and Fang, J. Value-Profile Guided Stride Prefetching \nfor Irregular Code. In Compiler Construction Conference (CC), 2002. [35]Zhou, H., Flanagan, J., and Conte, \nT. Detecting Global Stride Locality in Value Streams. In International Symposium on Computer Architecture \n(ISCA), 2003. \n\t\t\t", "proc_id": "996841", "abstract": "Cache miss stalls hurt performance because of the large gap between memory and processor speeds - for example, the popular server benchmark SPEC JBB2000 spends 45% of its cycles stalled waiting for memory requests on the Itanium&#174; 2 processor. Traversing linked data structures causes a large portion of these stalls. Prefetching for linked data structures remains a major challenge because serial data dependencies between elements in a linked data structure preclude the timely materialization of prefetch addresses. This paper presents <i>Mississippi Delta</i> (MS Delta), a novel technique for prefetching linked data structures that closely integrates the hardware performance monitor (HPM), the garbage collector's global view of heap and object layout, the type-level metadata inherent in type-safe programs, and JIT compiler analysis. The garbage collector uses the HPM's data cache miss information to identify cache miss intensive traversal paths through linked data structures, and then discovers regular distances (<i>deltas</i>) between these linked objects. JIT compiler analysis injects prefetch instructions using deltas to materialize prefetch addresses.We have implemented MS Delta in a fully dynamic profile-guided optimization system: the StarJIT dynamic compiler [1] and the ORP Java virtual machine [9]. We demonstrate a 28-29% reduction in stall cycles attributable to the high-latency cache misses targeted by MS Delta and a speedup of 11-14% on the cache miss intensive SPEC JBB2000 benchmark.", "authors": [{"name": "Ali-Reza Adl-Tabatabai", "author_profile_id": "81100032153", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "PP14023844", "email_address": "", "orcid_id": ""}, {"name": "Richard L. Hudson", "author_profile_id": "81100566849", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "P242189", "email_address": "", "orcid_id": ""}, {"name": "Mauricio J. Serrano", "author_profile_id": "81339527190", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "PP43116628", "email_address": "", "orcid_id": ""}, {"name": "Sreenivas Subramoney", "author_profile_id": "81100646451", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "P266440", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996873", "year": "2004", "article_id": "996873", "conference": "PLDI", "title": "Prefetch injection based on hardware monitoring and object metadata", "url": "http://dl.acm.org/citation.cfm?id=996873"}