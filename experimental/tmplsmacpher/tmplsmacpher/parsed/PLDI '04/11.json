{"article_publication_date": "06-09-2004", "fulltext": "\n Cloning-Based Context-Sensitive Pointer Alias Analysis Using Binary Decision Diagrams John Whaley Monica \nS. Lam Computer Science Department Stanford University Stanford, CA 94305 {jwhaley, lam}@stanford.edu \n ABSTRACT This paper presents the .rst scalable context-sensitive, inclusion\u00adbased pointer alias analysis \nfor Java programs. Our approach to context sensitivity is to create a clone of a method for every con\u00adtext \nof interest, and run a context-insensitive algorithm over the ex\u00adpanded call graph to get context-sensitive \nresults. For precision, we generate a clone for every acyclic path through a program s call graph, treating \nmethods in a strongly connected component as a sin\u00adgle node. Normally, this formulation is hopelessly \nintractable as a call graph often has 1014 acyclic paths or more. We show that these exponential relations \ncan be computed ef.ciently using binary de\u00adcision diagrams (BDDs). Key to the scalability of the technique \nis a context numbering scheme that exposes the commonalities across contexts. We applied our algorithm \nto the most popular applications available on Sourceforge, and found that the largest programs, with \nhundreds of thousands of Java bytecodes, can be analyzed in under 20 minutes. This paper shows that pointer \nanalysis, and many other queries and algorithms, can be described succinctly and declaratively using \nDatalog, a logic programming language. We have developed a sys\u00adtem called bddbddb that automatically \ntranslates Datalog programs into highly ef.cient BDD implementations. We used this approach to develop \na variety of context-sensitive algorithms including side effect analysis, type analysis, and escape analysis. \n Categories and Subject Descriptors D.3.4 [Programming Languages]: Processors Compilers;E.2 [Data]: \nData Storage Representations General Terms Algorithms, Performance, Design, Experimentation, Languages \n Keywords context-sensitive, inclusion-based, pointer analysis, Java, scalable, cloning, binary decision \ndiagrams, program analysis, Datalog, logic programming Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 04, June 9 11, 2004, Washington, DC, USA. Copyright 2004 \nACM 1-58113-807-5/04/0006 ...$5.00. 1. INTRODUCTION Many applications of program analysis, such as program \nopti\u00admization, parallelization, error detection and program understand\u00ading, need pointer alias information. \nScalable pointer analyses developed to date are imprecise because they are either context\u00adinsensitive[3,17, \n19,33] or uni.cation-based[15, 16]. A context\u00ad insensitive analysis does not distinguish between different \ncalling contexts of a method and allows information from one caller to propagate erroneously to another \ncaller of the same method. In uni.cation-based approaches, pointers are assumed to be either un\u00adaliased \nor are pointing to the same set of locations[28]. In contrast, inclusion-based approaches are more ef.cient \nbut also more expen\u00adsive, as they allow two aliased pointers to point to overlapping but different sets \nof locations. We have developed a context-sensitive and inclusion-based pointer alias analysis that scales \nto hundreds of thousands of Java bytecodes. The analysis is .eld-sensitive, meaning that it tracks the \nindividual .elds of individual pointers. Our analysis is mostly .ow-insensitive, using .ow sensitivity \nonly in the analysis of local pointers in each function. The results of this analysis, as we show in \nthis paper, can be easily used to answer users queries and to build more advanced analyses and programming \ntools. 1.1 Cloning to Achieve Context Sensitivity Our approach to context sensitivity is based on the \nnotion of cloning. Cloning conceptually generates multiple instances of a method such that every distinct \ncalling context invokes a different instance, thus preventing information from one context to .ow to \nanother. Cloning makes generating context-sensitive results algo\u00adrithmically trivial: We can simply apply \na context-insensitive algo\u00adrithm to the cloned program to obtain context-sensitive results. Note that \nour analysis does not clone the code per se; it simply produces a separate answer for each clone. The \ncontext of a method invocation is often distinguished by its call path, which is simply the call sites, \nor return addresses, on the invocation s call stack. In the case of a recursive program, there are an \nunbounded number of calling contexts. To limit the number of calling contexts, Shivers proposed the concept \nof k-CFA (Con\u00adtrol Flow Analysis) whereby one remembers only the last k call sites[26]. Emami et al. \nsuggested distinguishing contexts by their full call paths if they are acyclic. For cyclic paths, they \nsuggested including each call site in recursive cycles only once[14]. Our ap\u00ad proach also uses entire \ncall paths to distinguish between contexts in programs without recursion. To handle recursion, call paths \nare reduced by eliminating all invocations whose callers and callees be\u00adlong to the same strongly connected \ncomponent in the call graph. These reduced call paths are used to identify contexts. It was not obvious, \nat least to us at the beginning of this project, that a cloning-based approach would be feasible. The \nnumber of re\u00adduced call paths in a program grows exponentially with the number of methods, and a cloning-based \napproach must compute the result of every one of these contexts. Emami et al. have only reported context-sensitive \npoints-to results on small programs[14]. Realistic programs have many contexts; for example, the megamekapplica\u00adtion \nhas over 1014 contexts (see Section 6.1). The size of the .nal results alone appears to be prohibitive. \nWe show that we can scale a cloning-based points-to analysis by representing the context-sensitive relations \nusing ordered binary decision diagrams (BDDs)[6]. BDDs, originally designed for hard\u00ad ware veri.cation, \nhave previously been used in a number of pro\u00adgram analyses[2, 23, 38], and more recently for points-to \nanalysis[3, 39]. We show that it is possible to compute context-sensitive points\u00ad to results for over \n1014 contexts. In contrast, most context-sensitive pointer alias analyses devel\u00adoped to date are summary-based[15, \n34, 37]. Parameterized sum\u00ad maries are created for each method and used in creating the sum\u00admaries of \nits callers. It is not necessary to represent the results for the exponentially many contexts explicitly \nwith this approach, be\u00adcause the result of a context can be computed independently using the summaries. \nHowever, to answer queries as simple as which variables point to a certain object would require all the \nresults to be computed. The readers may be interested to know that, de\u00adspite much effort, we tried but \ndid not succeed in creating a scalable summary-based algorithm using BDDs. 1.2 Contributions The contributions \nof this paper are not limited to just an algorithm for computing context-sensitive and inclusion-based \npoints-to infor\u00admation. The methodology, speci.cation language, representation, and tools we used in \nderiving our pointer analysis are applicable to creating many other algorithms. We demonstrate this by \nusing the approach to create a variety of queries and algorithms. Scalable cloning-based context-sensitive \npoints-to analysis using BDDs. The algorithm we have developed is remarkably sim\u00adple. We .rst create \na cloned call graph where a clone is created for every distinct calling context. We then run a simple \ncontext\u00adinsensitive algorithm over the cloned call graph to get context\u00adsensitive results. We handle \nthe large number of contexts by rep\u00adresenting them in BDDs and using an encoding scheme that al\u00adlows \ncommonalities among similar contexts to be exploited. We improve the ef.ciency of the algorithm by using \nan automatic tool that searches for an effective variable ordering. Datalog as a high-level language \nfor BDD-based program analyses. Instead of writing our program analyses directly in terms of BDD operations, \nwe store all program information and results as relations and express our analyses in Datalog, a logic \nprogramming language used in deductive databases[30]. Because Datalog is suc\u00ad cinct and declarative, \nwe can express points-to analyses and many other algorithms simply and intuitively in just a few Datalog \nrules. We use Datalog because its set-based operation semantics matches the semantics of BDD operations \nwell. To aid our al\u00adgorithm research, we have developed a deductive database system called bddbddb (BDD \nBased Deductive DataBase) that automati\u00adcally translates Datalog programs into BDD algorithms. We provide \na high-level summary of the optimizations in this paper; the details are beyond the scope of this paper[35]. \nOur experience is that programs generated by bddbddb are faster than their manually optimized counterparts. \nMore importantly, Dat\u00adalog programs are orders-of-magnitude easier to write. They are so succinct and \neasy to understand that we use them to explain all our algorithms here directly. All the experimental \nresults reported in this paper are obtained by running the BDD programs automatically generated by bddbddb. \nContext-sensitive queries and other analyses. The context\u00adsensitive points-to results, the simple cloning-based \napproach to context sensitivity, and the bddbddb system make it easy to write new analyses. We show some \nrepresentative examples in each of the following categories: 1. Simple queries. The results from our \ncontext-sensitive pointer analysis provide a wealth of information of interest to pro\u00adgrammers. We show \nhow a few lines of Datalog can help programmers debug a memory leak and .nd potential secu\u00adrity vulnerabilities. \n 2. Algorithms using context-sensitive points-to results. We show how context-sensitive points-to results \ncan be used to cre\u00adate advanced analyses. We include examples of a context\u00adsensitive analysis to compute \nside effects (mod-ref) and an analysis to re.ne declared types of variables. 3. Other context-sensitive \nalgorithms. Cloning can be used to trivially generate other kinds of context-sensitive results be\u00adsides \npoints-to relations. We illustrate this with a context\u00adsensitive type analysis and a context-sensitive \nthread escape analysis. Whereas previous escape analyses require thou\u00adsands of lines of code to implement[34], \nthe algorithm here has only seven Datalog rules.  Experimental Results. We present the analysis time \nand mem\u00adory usage of our analyses across 21 of the most popular Java appli\u00adcations on Sourceforge. Our \ncontext-sensitive pointer analysis can analyze even the largest of the programs in under 19 minutes. \nWe also compare the precision of context-insensitive pointer analysis, context-sensitive pointer analysis \nand context-sensitive type analy\u00adsis, and show the effects of merging versus cloning contexts. 1.3 Paper \nOrganization Here is an overview of the rest of the paper. Section 2 ex\u00ad plains our methodology. Using \nBerndl s context-insensitive points\u00adto algorithm as an example, we explain how an analysis can be expressed \nin Datalog and, brie.y, how bddbddb translates Dat\u00adalog into ef.cient BDD implementations. Section 3 \nshows how we can easily extend the basic points-to algorithm to discover call graphs on the .y by adding \na few Datalog rules. Section 4 presents our cloning-based approach and how we use it to compute context-sensitive \npoints-to results. Section 5 shows the represen\u00ad tative queries and algorithms built upon our points-to \nresults and the cloning-based approach. Section 6 presents our experimental results. We report related \nwork in Section 7 and conclude in Sec\u00ad tion 8.  2. FROM DATALOG TO BDDS In this section, we start with \na brief introduction to Datalog. We then show how Datalog can be used to describe the context\u00adinsensitive \npoints-to analysis due to Berndl et al. at a high level. We then describe how our bddbddb system translates \na Datalog pro\u00adgram into an ef.cient implementation using BDDs. 2.1 Datalog We represent a program and \nall its analysis results as relations. Conceptually, a relation is a two-dimensional table. The columns \nare the attributes, each of which has a domain de.ning the set of possible attribute values. The rows \nare the tuples of attributes that share the relation. If tuple (x, y, z) is in relation A, we say that \npredicate A(x, y, z) is true. A Datalog program consists of a set of rules, written in a Prolog\u00adstyle \nnotation, where a predicate is de.ned as a conjunction of other predicates. For example, the Datalog \nrule D(w,z):- A(w,x),B(x,y),C(y,z). says that D(w,z)is true if A(w,x), B(x,y),and C(y,z)are all true. \nVariables in the predicates can be replaced with constants, which are surrounded by double-quotes, or \ndon t-cares, which are signi.ed by underscores. Predicates on the right side of the rules can be inverted. \nDatalog is more powerful than SQL, which is based on relational calculus, because Datalog predicates \ncan be recursively de.ned[30]. If none of the predicates in a Datalog program is inverted, then there \nis a guaranteed minimal solution consisting of relations with the least number of tuples. Conversely, \nprograms with inverted pred\u00adicates may not have a unique minimal solution. Our bddbddb system accepts \na subclass of Datalog programs, known as strati\u00ad.ed programs[7], for which minimal solutions always exist. \nInfor\u00admally, rules in such programs can be grouped into strata, each with a unique minimal solution, \nthat can be solved in sequence. 2.2 Context-Insensitive Points-to Analysis We now review Berndl et al. \ns context-insensitive points-to analysis[3], while also introducing the Datalog notation. This al\u00ad gorithm \nassumes that a call graph, computed using simple class hi\u00aderarchy analysis[13], is available a priori. \nHeap objects are named by their allocation sites. The algorithm .nds the objects possibly pointed to \nby each variable and .eld of heap objects in the program. Shown in Algorithm 1 is the exact Datalog program, \nas fed to bddb\u00adddb, that implements Berndl s algorithm. To keep the .rst example simple, we defer the \ndiscussion of using types to improve precision until Section 2.3. ALGORITHM 1. Context-insensitive points-to \nanalysis with a precomputed call graph. DOMAINS V H F 262144 65536 16384 variable.map heap.map field.map \nRELATIONS input input input input output output vP0 store load assign vP hP (variable :V,heap :H) (base \n:V,.eld :F,source :V) (base :V,.eld :F,dest :V) (dest :V,source :V) (variable :V,heap :H) (base :H,.eld \n:F,target :H) RULES vP(v,h) :- vP0(v,h). (1) vP(v1,h) :- assign(v1,v2),vP(v2,h). (2) hP(h1,f,h2) :- store(v1,f,v2), \nvP(v1,h1),vP(v2,h2). (3) vP(v2,h2) :- load(v1,f,v2), vP(v1,h1),hP(h1,f,h2). (4) . A Datalog program \nhas three sections: domains, relations, and rules. A domain declaration has a name, a size n, and an \noptional .le name that provides a name for each element in the domain, inter\u00adnally represented as an \nordinal number from 0 to n- 1. The latter allows bddbddb to communicate with the users with meaningful \nnames. A relation declaration has an optional keyword specifying whether it is an input or output relation, \nthe name of the relation, and the name and domain of every attribute. A relation declared as neither \ninput nor output is a temporary relation generated in the analysis but not written out. Finally, the \nrules follow the standard Datalog syntax. The rule numbers, introduced here for the sake of exposition, \nare not in the actual program. We can express all information found in the intermediate repre\u00adsentation \nof a program as relations. To avoid inundating readers with too many de.nitions all at once, we de.ne \nthe relations as they are used. The domains and relations used in Algorithm 1 are: V is the domain of \nvariables. It represents all the allocation sites, formal parameters, return values, thrown exceptions, \ncast op\u00aderations, and dereferences in the program. There is also a special global variable for use in \naccessing static variables. H is the domain of heap objects. Heap objects are named by the invocation \nsites of object creation methods. To increase pre\u00adcision, we also statically identify factory methods \nand treat them as object creation methods. F is the domain of .eld descriptors in the program. Field \ndescrip\u00adtors are used when loading from a .eld (v2 =v1.f;)or storing to a .eld (v1.f =v2;). There is \na special .eld de\u00adscriptor to denote an array access. vP0:V \u00d7 H is the initial variable points-to relation \nextracted from object allocation statements in the source program. vP0(v,h) means there is an invocation \nsite h that assigns a newly allocate object to variable v. store:V \u00d7 F \u00d7 V represents store statements. \nstore(v1,f,v2) says that there is a statement v1.f=v2; in the program. load:V \u00d7 F \u00d7 V represents load \nstatements. load(v1,f,v2)says that there is a statement v2 =v1.f; in the program. assign:V \u00d7 V is the \nassignments relation due to passing of argu\u00adments and return values. assign(v1,v2)means that variable \nv1 includes the points-to set of variable v2. Although we do not cover return values here, they work \nin an analogous man\u00adner. vP:V \u00d7 H is the output variable points-to relation. vP(v,h) means that variable \nv can point to heap object h. hP:H \u00d7 F \u00d7 H is the output heap points-to relation. hP(h1,f,h2)means that \n.eld f of heap object h1 can point to heap object h2. Note that local variables and their assignments \nare factored away using a .ow-sensitive analysis[33]. The assign relation is derived by using a precomputed \ncall graph. The sizes of the domains are determined by the number of variables, heap objects, and .eld \nde\u00adscriptors in the input program. Rule (1) incorporates the initial variable points-to relations into \nvP. Rule (2) .nds the transitive closure over inclusion edges. If v1 includes v2 and variable v2 can \npoint to object h,then v1 can also point to h. Rule (3) models the effect of store instructions on heap \nobjects. Given a statement v1.f= v2; , if v1 can point to h1 and v2 can point to h2,then h1.f can point \nto h2.Rule (4) resolves load instructions. Given a statement v2 =v1.f; , if v1 can point to h1 and h1.f \ncan point to h2, then v2 can point to h2. Applying these rules until the results converge .nds all the \npossible context-insensitive points-to relations in the program. 2.3 Improving Points-to Analysis with \nTypes Because Java is type-safe, variables can only point to objects of assignable types. Assignability \nis similar to the subtype relation, ALGORITHM 2. Context-insensitive points-to analysis with type .ltering. \nDOMAINS Domains from Algorithm 1, plus: T 4096 type.map RELATIONS Relations from Algorithm 1, plus: input \nvT (variable :V,type :T) input hT (heap :H,type :T) input aT (supertype :T,subtype :T) vP.lter (variable \n:V,heap :H) RULES vP.lter(v,h): - vT (v,tv),hT (h,th),aT (tv,th). (5) vP(v,h) : - vP0(v,h). (6) vP(v1,h) \n: - assign(v1,v2),vP(v2,h), vP.lter(v1,h). (7) hP(h1,f,h2): - store(v1,f,v2), vP(v1,h1),vP(v2,h2). (8) \nvP(v2,h2) : - load(v1,f,v2),vP(v1,h1), hP(h1,f,h2),vP.lter(v2,h2). (9) . with allowances for interfaces, \nnull values, and arrays[22]. By drop\u00ad ping targets of unassignable types in assignments and load state\u00adments, \nwe can eliminate many impossible points-to relations that result from the imprecision of the analysis. \n1 Adding type .ltering to Algorithm 1 is simple in Datalog. We add a new domain to represent types and \nnew relations to repre\u00adsent assignability as well as type declarations of variables and heap objects. \nWe compute the type .lter and modify the rules in Algo\u00adrithm 1 to .lter out unsafe assignments and load \noperations. T is the domain of type descriptors (i.e. classes) in the program. vT :V \u00d7 T represents the \ndeclared types of variables. vT (v,t) means that variable v is declared with type t. hT :H \u00d7 T represents \nthe types of objects created at a particular creation site. In Java, the type created by a new instruction \nis usually known statically.2 hT (h,t) means that the object created at hhas type t. aT :T \u00d7 T is the \nrelation of assignable types. aT (t1,t2) means that type t2 is assignable to type t1. vP.lter:V \u00d7 H is \nthe type .lter relation. vP.lter(v,h) means that it is type-safe to assign heap object hto variable v. \nRule (5) in Algorithm 2 de.nes the vP.lter relation: It is type\u00adsafe to assign heap object hof type th \nto variable v of type tv if tv is assignable from th. Rules (6) and (8) are the same as Rules (1) and \n(3) in Algorithm 1. Rules (7) and (9) are analogous to Rules (2) and (4), with the additional constraint \nthat only points-to relations that match the type .lter are inserted. 1We could similarly perform type \n.ltering on stores into heap ob\u00adjects. However, because all stores must go through variables, such a \ntype .lter would only catch one extra case when the base object is a null constant. 2The type of a created \nobject may not be known precisely if, for example, the object is returned by a native method or re.ection \nis used. Such types are modeled conservatively as all possible types. 2.4 Translating Datalog into Ef.cient \nBDD Implementations We .rst describe how Datalog rules can be translated into opera\u00adtors from relational \nalgebra such as join and project , then show how to translate these operations into BDD operations. 2.4.1 \nQuery Resolution We can .nd the solution to an unstrati.ed query, or a stratum of a strati.ed query, \nsimply by applying the inference rules repeatedly until none of the output relations change. We can apply \na Datalog rule by performing a series of relational natural join, project and re\u00adname operations. A natural \njoin operation combines rows from two relations if the rows share the same value for a common attribute. \nA project operation removes an attribute from a relation. A rename operation changes the name of an attribute \nto another one. For example, the application of Rule (2) can be implemented as: t1 = rename(vP,variable,source); \nt2 = project(join(assign,t1),source); vP = vP . rename(t2,dest,variable); We .rst rename the attribute \nin relation vP from variable to source so that it can be joined with relation assign to create a new \npoints-to relation. The attribute dest of the resulting relation is changed to variable so that the tuples \ncan be added to the vP tuples accumu\u00adlated thus far. The bddbddb system uses the three following optimizations \nto speed up query resolution. Attributes naming. Since the names of the attributes must match when two \nrelations are joined, the choice of attribute names can affect the costs of rename operations. Since \nthe renaming cost is highly sensitive to how the relations are implemented, the bddbddb system takes \nthe representation into account when minimizing the renaming cost. Rule application order. A rule needs \nto be applied only if the input relations have changed. bddbddb optimizes the ordering of the rules by \nanalyzing the dependences between the rules. For ex\u00adample, Rule 1 in Algorithm 1 does not depend on any \nof the other rules and can be applied only once at the beginning of the query resolution. Incrementalization. \nWe only need to re-apply a rule on those combinations of tuples that we have not seen before. Such a \ntech\u00adnique is known as incrementalization in the BDD literature and semi-na\u00a8ive .xpoint evaluation in \nthe database literature[1]. Our system also identi.es loop-invariant relations to avoid unnecessary difference \nand rename operations. Shown below is the result of in\u00adcrementalizing the repeated application of Rule \n(2): d= vP; repeat t1 = rename(d,variable,source); t2 = project(join(assign,t1),source); d. = rename(t2,dest,variable); \nd = d. - vP; vP = vP . d; until d == \u00d8; 2.4.2 Relational Algebra in BDD We now explain how BDDs work \nand how they can be used to implement relations and relational operations. BDDs (Binary De\u00adcision Diagrams) \nwere originally invented for hardware veri.ca\u00adtion to ef.ciently store a large number of states that \nshare many commonalities[6]. They are an ef.cient representation of boolean functions. A BDD is a directed \nacyclic graph (DAG) with a single root node and two terminal nodes, representing the constants one and \nzero. Each non-terminal node in the DAG represents an input variable and has exactly two outgoing edges: \na high edge and a low edge. The high edge represents the case where the input variable for the node is \ntrue, and the low outgoing edge represents the case where the input variable is false. On any path in \nthe DAG from the root to a terminal node, the value of the function on the truth val\u00adues on the input \nvariables in the path is given by the value of the terminal node. To evaluate a BDD for a speci.c input, \none simply starts at the root node and, for each node, follows the high edge if the input variable is \ntrue, and the low edge if the input variable is false. The value of the terminal node that we reach is \nthe value of the BDD for that input. The variant of BDDs that we use are called ordered binary de\u00adcision \ndiagrams, or OBDDs[6]. Ordered refers to the constraint that on all paths through the graph the variables \nrespect a given lin\u00adear order. In addition, OBDDs are maximally reduced meaning that nodes with the same \nvariable name and low and high successors are collapsed as one, and nodes with identical low and high \nsuccessors are bypassed. Thus, the more commonalities there are in the paths leading to the terminals, \nthe more compact the OBDDs are. Accord\u00adingly, the amount of the sharing and the size of the representation \ndepends greatly on the ordering of the variables. We can use BDDs to represent relations as follows. \nEach element d in an n-element domain D is represented as an integer between 0 and n-1 using log2(n) \nbits. A relation R : D1 \u00d7...\u00d7Dn is represented as a boolean function f : D1 \u00d7...\u00d7Dn .{0,1}such that (d1,...,dn) \n.R iff f(d1,...,dn)=1,and (d1,...,dn) ./Riff f(d1,...,dn)=0. A number of highly-optimized BDD packages \nare available[21, 27]; the operations they provide can be used directly to implement relational operations \nef.ciently. For example, the replace oper\u00adation in BDD has the same semantics as the rename operation; \nthe relprod operation in BDD .nds the natural join between two relations and projects away the common \ndomains. Let us now use a concrete example to illustrate the signif\u00adicance of variable ordering. Suppose \nrelation R1 contains tu\u00adples (1,1),(2,1),...,(100,1) and relation R2 contains tuples (1,2),(2,2),...,(100,2). \nIf in the variable order the bits for the .rst attribute come before the bits for the second, the BDD \nwill need to represent the sequence 1,...,100 separately for each rela\u00adtion. However, if instead the \nbits for the second attribute come .rst, the BDD can share the representation for the sequence 1,...,100 \nbetween R1 and R2. Unfortunately, the problem of .nding the best variable ordering is NP-complete[5]. \nOur bddbddb system auto\u00admatically explores different alternatives empirically to .nd an ef\u00adfective ordering[35]. \n  3. CALL GRAPH DISCOVERY The call graph generated using class hierarchy analysis can have many spurious \ncall targets, which can lead to many spurious points\u00adto relations[19]. We can get more precise results \nby creating the call graph on the .y using points-to relations. As the algorithm gener\u00adates points-to \nresults, they are used to identify the receiver types of the methods invoked and to bind calls to target \nmethods; and as call graph edges are discovered, we use them to .nd more points-to re\u00adlations. The algorithm \nconverges when no new call targets and no new pointer relations are found. Modifying Algorithm 2 to discover \ncall graphs on the .y is sim\u00ad ple. Instead of an input assign relation computed from a given call graph, \nwe derive it from method invocation statements and points-to relations. ALGORITHM 3. Context-insensitive \npoints-to analysis that computes call graph on the .y. DOMAINS Domains from Algorithm 2, plus: I 32768 \ninvoke.map N 4096 name.map M 16384 method.map Z 256 RELATIONS Relations from Algorithm 2, with the modi.cation \nthat assign is now a computed relation, plus: input cha (type :T,name :N,target :M) input actual (invoke \n:I,param :Z,var :V) input formal (method :M,param :Z,var :V) input IE0 (invoke :I,target :M) input mI \n(method :M,invoke :I) output IE (invoke :I,target :M) RULES Rules from Algorithm 2, plus: IE (i,m): - \nIE 0(i,m). (10) IE (i,m2): - mI (m1,i,n),actual(i,0,v), vP(v,h),hT (h,t),cha(t,n,m2).(11) assign(v1,v2): \n- IE (i,m),formal(m,z,v1), actual(i,z,v2). (12) . I is the domain of invocation sites in the program. \nAn invocation site is a method invocation of the form r=p0.m(p1 ... pk). Note that H .I. N is the domain \nof method names used in invocations. In an invo\u00adcation r=p0.n(p1 ... pk), nis the method name. M is the \ndomain of implemented methods in the program. It does not include abstract or interface methods. Z is \nthe domain used for numbering parameters. cha:T \u00d7N \u00d7M encodes virtual method dispatch information from \nthe class hierarchy. cha(t,n,m) means that m is the target of dispatching the method name non type t. \nactual:I \u00d7Z \u00d7V encodes the actual parameters for invocation sites. actual(i,z,v) means that v is passed \nas parameter number z at invocation site i. formal:M \u00d7Z \u00d7V encodes formal parameters for methods. formal(m,z,v) \nmeans that formal parameter z of method mis represented by variable v. IE0:I \u00d7M are the initial invocation \nedges. They record the invo\u00adcation edges whose targets are statically bound. In Java, some calls are \nstatic or non-virtual. Additionally, local type analy\u00adsis combined with analysis of the class hierarchy \nallows us to determine that some calls have a single target[13]. IE 0(i,m) means that invocation site \nican be analyzed statically to call method m. mI :M \u00d7I \u00d7N represents invocation sites. mI (m,i,n) means \nthat method m contains an invocation site i with virtual method name n. Non-virtual invocation sites \nare given a spe\u00adcial null method name, which does not appear in the cha re\u00adlation. IE:I \u00d7M is an output \nrelation encoding all invocation edges. IE(i,m) means that invocation site icalls method m. The rules \nin Algorithm 3 compute the assign relation used in Algorithm 2. Rules (10) and (11) .nd the invocation \nedges, with the former handling statically bound targets and the latter handling virtual calls. Rule \n(11) matches invocation sites with the type of the this pointer and the class hierarchy information to \n.nd the possible target methods. If an invocation site i with method name n is invoked on variable v,and \nv can point to h and h has type t,and invoking n on type t leads to method m,then m is a possible target \nof invocation i. Rule (12) handles parameter passing.3 If invocation site i has a target method m, variable \nv2 is passed as argument number z,and the formal parameter z of method m is v1, then the points-to set \nof v1 includes the points-to set of v2. Return values are handled in a likewise manner, only the inclusion \nrelation is in the opposite direction. We see that as the discovery of more variable points\u00adto (vP) can \ncreate more invocation edges (IE), which in turn can create more assignments (assign) and more points-to \nrelations. The algorithm converges when all the relations stabilize.  4. CONTEXT SENSITIVE POINTS-TO \nA context-insensitive or monomorphic analysis produces just one set of results for each method regardless \nhow many ways a method may be invoked. This leads to imprecision because information from different calling \ncontexts must be merged, so information along one calling context can propagate to other calling contexts. \nA context-sensitive or polymorphic analysis avoids this imprecision by allowing different contexts to \nhave different results. We can make a context-sensitive version of a context-insensitive analysis as \nfollows. We make a clone of a method for each path through the call graph, linking each call site to \nits own unique clone. We then run the original context-insensitive analysis over the ex\u00adploded call graph. \nHowever, this technique can require an exponen\u00adtial (and in the presence of cycles, potentially unbounded) \nnumber of clones to be created. It has been observed that different contexts of the same method often \nhave many similarities. For example, parameters to the same method often have the same types or similar \naliases. This obser\u00advation led to the concept of partial transfer functions (PTF), where summaries for \neach input pattern are created on the .y as they are discovered[36, 37]. However, PTFs are notoriously \ndif.cult to im\u00adplement and get correct, as the programmer must explicitly calcu\u00adlate the input patterns \nand manage the summaries. Furthermore, the technique has not been shown to scale to very large programs. \nOur approach is to allow the exponential explosion to occur and rely on the underlying BDD representation \nto .nd and exploit the commonalities across contexts. BDDs can express large sets of re\u00addundant data \nin an ef.cient manner. Contexts with identical infor\u00admation will automatically be shared at the data \nstructure level. Fur\u00adthermore, because BDDs operate down at the bit level, it can even exploit commonalities \nbetween contexts with different information. BDD operations operate on entire relations at a time, rather \nthan one tuple at a time. Thus, the cost of BDD operations depends on the size and shape of the BDD relations, \nwhich depends greatly on the variable ordering, rather than the number of tuples in a relation. Also, \ndue to caching in BDD packages, identical subproblems only have to be computed once. Thus, with the right \nvariable ordering, the results for all contexts can be computed very ef.ciently. 4.1 Numbering Call \nPaths A call path is a sequence of invocation edges (i1,m1), (i2,m2),..., such that i1 is an invocation \nsite in 3We also match thread objects to their corresponding run()meth\u00adods, even though the edges do \nnot explicitly appear in the call graph.  Figure 1: Example of path numbering. The graph on the left \nis the original graph. Nodes M2 and M3 are in a cycle and there\u00adfore are placed in one equivalence class. \nEach edge is marked with path numbers at the source and target of the edge. The graph on the right is \nthe graph with all of the paths expanded. Call paths Reduced call paths reaching M6 reaching M6 a(cd) \n* eh aeh b(dc) * deh beh afh a(cd) * cfh b(dc) * fh bf h a(cd) * cgi agi b(dc) * gi bgi Figure 2: The \nsix contexts of function M6 in Example 1 an entry method, typically main4,and ik is an invocation site \nin method mk-1 for all k> 1. For programs without recursion, every call path to a method de\u00ad.nes a context \nfor that method. To handle recursive programs, which have an unbounded number of call paths, we .rst \n.nd the strongly connected components (SCCs) in a call graph. By elimi\u00adnating all method invocations \nwhose caller and callee belong to the same SCC from the call paths, we get a .nite set of reduced call \npaths. Each reduced call path to an SCC de.nes a context for the methods in the SCC. Thus, information \nfrom different paths lead\u00ading to the SCCs are kept separate, but the methods within the SCC invoked with \nthe same incoming call path are analyzed context\u00adinsensitively. EXAMPLE 1. Figure 1(a) shows a small \ncall graph with just six methods and a set of invocation edges. Each invocation edge has a name, being \none of a through i; its source is labeled by the context number of the caller and its sink by the context \nnumber of the callee. The numbers will be explained in Example 2. Methods M2 and M3 belong to a strongly \nconnected component, so invocations along edges c and d are eliminated in the computation of reduced \ncall graphs. While there are in.nitely many call paths reaching method M6, there are only six reduced \ncall paths reaching M6, as shown in Figure 2. Thus M6 has six clones, one for each reduced call path. \nUnder this de.nition of context sensitivity, large programs can have many contexts. For example, pmdfrom \nour test programs has 1971 methods and 1023 contexts! In the BDD representation, we give each reduced \ncall path reaching a method a distinct context 4Other entry methods in typical programs are static class \ninitial\u00adizers, object .nalizers, and thread run methods. number. It is important to .nd a context numbering \nscheme that allows the BDDs to share commonalities across contexts. Algo\u00adrithm 4 shows one such scheme. \nALGORITHM 4. Generating context-sensitive invocation edges from a call graph. INPUT: A call multigraph. \nOUTPUT: Context-sensitive invocation edges IEC:C \u00d7 I \u00d7 C \u00d7 M, where C is the domain of context numbers. \nIEC (c,i,cm,m)means that invocation site iin context ccalls method min context cm. METHOD: 1. A method \nwith n clones will be given numbers 1,...,n. Nodes with no predecessors are given a singleton context \nnumbered 1. 2. Find strongly connected components in the input call graph. The ith clone of a method \nalways calls the ith clone of another method belonging to the same component. 3. Collapse all methods \nin a strongly connected component to a single node to get an acyclic reduced graph. 4. For each node \nnin the reduced graph in topological order,  Set the counts of contexts created, c,to 0. For each incoming \nedge, If the predecessor of the edge phas kcontexts, create kclones of node n, Add tuple (i,p,i+c,n)to \nIE C, for 1= i = k, c =c+k. . EXAMPLE 2. We now show the results of applying Algorithm 4 to Example 1. \nM1, the root node, is given context number 1. We shall visit the invocation edges from left to right. \nNodes M2 and M3, being members of a strongly connected component, are repre\u00adsented as one node. The strongly \nconnected component is reached by two edges from M1.Since M1 has only one context, we create two clones, \none reached by each edge. For method M4, the pre\u00addecessor on each of the two incoming edges has two contexts, \nthus M4 has four clones. Method M5 has two clones, one for each clone that invokes M5. Finally, method \nM6 has six clones: Clones 1-4 of method M4 invoke clones 1-4 and clones 1-2 of method M5 call clones \n5-6, respectively. The cloned graph is shown in Figure 1(b). The numbering scheme used in Algorithm 4 \nplays up the strengths of BDDs. Each method is assigned a contiguous range of contexts, which can be \nrepresented ef.ciently in BDDs. The con\u00adtexts of callees can be computed simply by adding a constant \nto the contexts of the callers; this operation is also cheap in BDDs. Be\u00adcause the information for contexts \nthat share common tail sequences are likely to be similar, this numbering allows the BDD data struc\u00adture \nto share effectively across common contexts. For example, the sequentially-numbered clones 1 and 2 of \nM6 both have a common tail sequence eh. Because of this, the contexts are likely to be sim\u00adilar and therefore \nthe BDD can take advantage of the redundancies. To optimize the creation of the cloned invocation graph, \nwe have de.ned a new primitive that creates a BDD representation of con\u00adtiguous ranges of numbers in \nO(k) operations, where kis the num\u00adber of bits in the domain. In essence, the algorithm creates one BDD \nto represent numbers below the upper bound, and one to represent numbers above the lower bound, and computes \nthe conjunction of these two BDDs.  4.2 Context-Sensitive Pointer Analysis with a Pre-computed Call \nGraph We are now ready to present our context-sensitive pointer analy\u00adsis. We assume the presence of \na pre-computed call graph created, for example, by using a context-insensitive points-to analysis (Al\u00adgorithm \n3). We apply Algorithm 4 to the call graph to generate the context-sensitive invocation edges IEC. Once \nthat is created, we can simply apply a context-insensitive points-to analysis on the exploded call graph \nto get context-sensitive results. We keep the results separate for each clone by adding a context number \nto meth\u00adods, variables, invocation sites, points-to relations, etc. ALGORITHM 5. Context-sensitive points-to \nanalysis with a pre\u00adcomputed call graph. DOMAINS Domains from Algorithm 2, plus: C 9223372036854775808 \nRELATIONS Relations from Algorithm 2, plus: input IE C (caller :C,invoke :I,callee :C,tgt :M) assignC \n(destc :C,dest :V,srcc :C,src :V) output vPC (context :C,variable :V,heap :H) RULES vP.lter(v,h):- vT(v,tv),hT \n(h,th),aT (tv,th). (13) vPC(c,v,h) :- vP0(v,h),IE C (c,h, , ). (14) vPC(c1,v1,h):- assignC (c1,v1,c2,v2), \nvPC (c2,v2,h),vP.lter(v1,h). (15) hP(h1,f,h2) :- store(v1,f,v2), vPC (c,v1,h1),vPC (c,v2,h2). (16) vPC(c,v2,h2):- \nload(v1,f,v2),vPC (c,v1,h1), hP(h1,f,h2),vP.lter(v2,h2). (17) assignC (c1,v1,c2,v2) :- IE C (c2,i,c1,m),formal(m,z,v1), \nactual(i,z,v2). (18) . C is the domain of context numbers. Our BDD library uses signed 64-bit integers \nto represent domains, so the size is limited to 63 2 . IE C:C \u00d7 I \u00d7 C \u00d7 M is the set of context-sensitive \ninvocation edges. IEC (c,i,cm,m)means that invocation site i in con\u00adtext c calls method m in context \ncm. This relation is com\u00adputed using Algorithm 4. assignC:C \u00d7 V \u00d7 C \u00d7 V is the context-sensitive version \nof the assign relation. assignC (c1,v1,c2,v2)means variable v1 in context c1 includes the points-to set \nof variable v2 in context v2 due to parameter passing. Again, return values are handled analogously. \nvPC:C \u00d7 V \u00d7 H is the context-sensitive version of the variable points-to relation (vP). vPC (c,v,h)means \nvariable vin con\u00adtext ccan point to heap object h. Rule (18) interprets the context-sensitive invocation \nedges to .nd the bindings between actual and formal parameters. The rest of the rules are the context-sensitive \ncounterparts to those found in Algorithm 2. Algorithm 5 takes advantage of a pre-computed call graph \nto cre\u00adate an ef.cient context numbering scheme for the contexts. We can compute the call graph on the \n.y while enjoying the bene.t of the numbering scheme by numbering all the possible contexts with a conservative \ncall graph, and delaying the generation of the invoca\u00adtion edges only if warranted by the points-to results. \nWe can reduce the iterations necessary by exploiting the fact that many of the in\u00advocation sites of a \ncall graph created by a context-insensitive anal\u00adysis have single targets. Such an algorithm has an execution \ntime similar to Algorithm 5, but is of primarily academic interest as the call graph rarely improves \ndue to the extra precision from context\u00adsensitive points-to information.  5. QUERIES AND OTHER ANALYSES \nThe algorithms in sections 2, 3 and 4 generate vast amounts of re\u00adsults in the form of relations. Using \nthe same declarative program\u00adming interface, we can conveniently query the results and extract exactly \nthe information we are interested in. This section shows a variety of queries and analyses that make \nuse of pointer information and context sensitivity. 5.1 Debugging a Memory Leak Memory leaks can occur \nin Java when a reference to an object remains even after it will no longer be used. One common approach \nof debugging memory leaks is to use a dynamic tool that locates the allocation sites of memory-consuming \nobjects. Suppose that, upon reviewing the information, the programmer thinks objects allocated in line \n57 in .le a.java should have been freed. He may wish to know which objects may be holding pointers to \nthe leaked objects, and which operations may have stored the pointers. He can consult the static analysis \nresults by supplying the queries: whoPointsTo57 (h, f):-hP(h, f, a.java :57 ). whoDunnit(c, v1,f,v2):-store(v1,f, \nv2), vPC (c, v2, a.java :57 ). The .rst query .nds the objects and their .elds that may point to objects \nallocated at a.java:57 ; the second .nds the store instructions, and the contexts under which they are \nexecuted, that create the references. 5.2 Finding a Security Vulnerability The Java Cryptography Extension \n(JCE) is a library of crypto\u00adgraphic algorithms[29]. Misuse of the JCE API can lead to security vulnerabilities \nand a false sense of security. For example, many operations in the JCE use a secret key that must be \nsupplied by the programmer. It is important that secret keys be cleared after they are used so they cannot \nbe recovered by attackers with access to mem\u00adory. Since String objects are immutable and cannot be cleared, \nsecret keys should not be stored in Stringobjects but in an array of characters or bytes instead. To \nguard against misuse, the function that accepts the secret key, PBEKeySpec.init(), only allows arrays \nof characters or bytes as input. However, a programmer not versed in security issues may have stored \nthe key in a String object and then use a routine in the String class to convert it to an array of characters. \nWe can write a query to audit programs for the presence of such id\u00adioms. Let Mret(m, v)be an input relation \nspecifying that vari\u00adable v is the return value of method m. We de.ne a relation fromString(h)which indicates \nif the object h was directly derived from a String. Speci.cally, it records the objects that are re\u00adturned \nby a call to a method in the String class. An invocation i to method PBEKeySpec.init()is a vulnerability \nif the .rst argu\u00adment points to an object derived from a String. fromString(h):-cha( String , ,m), Mret(m, \nv), vPC ( ,v,h). vuln(c, i):-IE(i, PBEKeySpec.init() ), actual(i, 1,v), vPC (c, v, h), fromString(h). \n Notice that this query does not only .nd cases where the object derived from a String is immediately \nsupplied to PBEKeySpec.init(). This query will also identify cases where the object has passed through \nmany variables and heap objects. 5.3 Type Re.nement Libraries are written to handle the most general \ntypes of objects possible, and their full generality is typically not used in many ap\u00adplications. By \nanalyzing the actual types of objects used in an ap\u00adplication, we can re.ne the types of the variables \nand object .elds. Type re.nement can be used to reduce overheads in cast operations, resolve virtual \nmethod calls, and gain better understanding of the program. We say that variable v can be legally declared \nas t, written varSuperTypes(v, t),if t is a supertype of the types of all the ob\u00adjects v can point to. \nThe type of a variable is re.nable if the variable can be declared to have a more precise type. To compute \nthe super types of v,we.rst .nd varExactTypes(v, t), the types of objects pointed to by v. We then intersect \nthe supertypes of all the exact types to get the desired solution; we do so in Datalog by .nding the \ncomplement of the union of the complement of the exact types. varExactTypes(v, t):-vPC ( ,v,h), hT (h, \nt). notVarType(v, t):-varExactTypes(v, tv), \u00acaT(t, tv). varSuperTypes(v, t):-\u00acnotVarType(v, t). re.nable(v, \ntc):-vT (v, td), varSuperTypes(v, tc), aT (td,tc),td =tc. The above shows a context-insensitive type \nre.nement query. We .nd, for each variable, the type to which it can be re.ned regardless of the context. \nEven if the end result is context-insensitive, it is more precise to take advantage of the context-sensitive \npoints-to results available to determine the exact types, as shown in the .rst rule. In Section 6.3, \nwe compare the accuracy of this context-insensitive query with a context-sensitive version. 5.4 Context-Sensitive \nMod-Ref Analysis Mod-ref analysis is used to determine what .elds of what objects may be modi.ed or referenced \nby a statement or call site[18]. We can use the context-sensitive points-to results to solve a context\u00adsensitive \nversion of this query. We de.ne mV (m, v)to mean that v is a local variable in m. The mV * C relation \nspeci.es the set of vari\u00adables and contexts of methods that are transitively reachable from a method. \nmV * C (c1,m, c2,v)means that calling method m with context c1 can transitively call a method with local \nvariable v under context c2. mV * C (c, m, c, v):-mV (m, v). mV * C (c1,m1,c3,v3):-mI (m1,i), IE C (c1,i,c2,m2), \nmV * C (c2,m2,c3,v3). The .rst rule simply says that a method m in context c can reach its local variable. \nThe second rule says that if method m1 in context c1 calls method m2 in context c2, then m1 in context \nc1 can also reach all variables reached by method m2 in context c2. We can now de.ne the mod and ref \nset of a method as follows: mod(c, m, h, f):-mV * C (c, m, cv,v), store(v, f, ), vPC (cv,v,h). ref (c, \nm, h, f):-mV * C (c, m, cv,v), load(v, f, ), vPC (cv,v,h). The .rst rule says that if method min context \nccan reach a vari\u00adable v in context cv, and if there is a store through that variable to .eld f of object \nh, then min context ccan modify .eld f of object h. The second rule for de.ning the ref relations is \nanalogous. 5.5 Context-Sensitive Type Analysis Our cloning technique can be applied to add context sensitivity \nto other context-insensitive algorithms. The example we show here is the type inference of variables \nand .elds. By not distinguish\u00ading between instances of heap objects, this analysis does not gener\u00adate \nresults as precise as those extracted from running the complete context-sensitive pointer analysis as \ndiscussed in Section 5.3, but is much faster. The basic type analysis is similar to 0-CFA[26]. Each variable \nand .eld in the program has a set of concrete types that it can re\u00adfer to. The sets are propagated through \ncalls, returns, loads, and stores. By using the path numbering scheme in Algorithm 4, we can convert \nthis basic analysis into one which is context-sensitive in essence, making the analysis into a k-CFA \nanalysis where k is the depth of the call graph and recursive cycles are collapsed. ALGORITHM 6. Context-sensitive \ntype analysis. DOMAINS Domains from Algorithm 5 RELATIONS Relations from Algorithm 5, plus: output vT \nC (context :C,variable :V,type :T) output fT (.eld :F,target :T) vT.lter (variable :V,type :T) RULES \nvT.lter(v,t):- vT(v,tv),aT (tv,t). (19) vT C (c,v,t):- vP0(v,h),IE C (c,h, , ),hT(h,t).(20) vT C (cv1 \n,v1,t):- assignC (cv1 ,v1,cv2 ,v2), vT C (cv2 ,v2,t),vT.lter(v1,t). (21) fT (f,t):- store(,f,v2),vT C \n(,v2,t). (22) vT C (,v,t):- load(,f,v),fT (f,t), vT.lter(v,t). (23) assignC (c1,v1,c2,v2) :- IE C (c2,i,c1,m),formal(m,z,v1), \nactual(i,z,v2). (24) . vT C:C \u00d7 V \u00d7 T is the context-sensitive variable type relation. vT C (c,v,t)means \nthat variable v in context cv can refer to an object of type t. This is the analogue of vPC in the points\u00ad \nto analysis. fT :F \u00d7 T is the .eld type relation. fT(f,t)means that .eld f can point to an object of \ntype t. vT.lter:V \u00d7 T is the type .lter relation. vT.lter(v,t)means that it is type-safe to assign an \nobject of type tto variable v. Rule (20) initializes the vT C relation based on the initial local points-to \ninformation contained in vP0, combining it with hT to get the type and IEC to get the context numbers. \nRule (21) does tran\u00adsitive closure on the vT C relation, .ltering with vT.lter to enforce type safety. \nRules (22) and (23) handle stores and loads, respec\u00adtively. They differ from their counterparts in the \npointer analysis in that they do not use the base object, only the .eld. Rule (24) models the effects \nof parameter passing in a context-sensitive manner.    5.6 Thread Escape Analysis Our last example \nis a thread escape analysis, which determines if objects created by one thread may be used by another. \nThe re\u00adsults of the analysis can be used for optimizations such as synchro\u00adnization elimination and allocating \nobjects in thread-local heaps, as well as for understanding programs and checking for possible race conditions \ndue to missing synchronizations[8, 34]. This example illustrates how we can vary context sensitivity \nto .t the needs of the analysis. We say that an object allocated by a thread has escaped if it may be \naccessed by another thread. This notion is stronger than most other formulations where an object is said \nto escape if it can be reached by another thread[8, 34]. Java threads, being subclasses of java.lang.Thread,are \nidenti.ed by their creation sites. In the special case where a thread creation can execute only once, \na thread can simply be named by the creation site. The thread that exists at virtual machine startup \nis an example of a thread that can only be created once. A creation site reached via different call paths \nor embedded in loops or recur\u00adsive cycles may generate multiple threads. To distinguish between thread \ninstances created at the same site, we create two thread con\u00adtexts to represent two separate thread instances. \nIf an object created by one instance is not accessed by its clone, then it is not accessed by any other \ninstances created by the same call site. This scheme creates at most twice as many contexts as there \nare thread creation sites. We clone the thread run()method, one for each thread context, and place these \nclones on the list of entry methods to be analyzed. Methods (transitively) invoked by a context s run() \nmethod all inherit the same context. A clone of a method not only has its own cloned variables, but also \nits own cloned object creation sites. In this way, objects created by separate threads are distinct from \neach other. We run a points-to analysis over this slightly expanded call graph; an object created in \na thread context escapes if it is accessed by variables in another thread context. ALGORITHM 7. Thread-sensitive \npointer analysis. DOMAINS Domains from Algorithm 5 RELATIONS Relations from Algorithm 2, plus: input \nHT (c :C,heap :H) input vP0T (cv :C,variable :V,ch :C,heap :H) output vPT (cv :C,variable :V,ch :C,heap \n:H) output hPT (cb :C,base :H,.eld :F,ct :C,target :H) RULES vP.lter(v,h):-vT (v,tv),hT (h,th),aT (tv \n,th).(25) vPT (c1,v,c2,h):-vP0T (c1,v,c2,h). (26) vPT (c,v,c,h):-vP0(v,h),HT (c,h). (27) vPT (c2,v1,ch,h):-assign(v1,v2),vPT \n(c2,v2,ch,h), vP.lter(v1,h). (28) hPT (c1,h1,f,c2,h2):-store(v1,f,v2),vPT (c,v1,c1,h1), vPT (c,v2,c2,h2). \n(29) vPT (c,v2,c2,h2):-load(v1,f,v2),vPT (c,v1,c1,h1), hPT (c1,h1,f,c2,h2), vP.lter(v2,h2). (30) . HT:C \n\u00d7 H encodes the non-thread objects created by a thread. HT (c,h)means that a thread with context cmay \nexecute non\u00adthread allocation site h; in other words, there is a call path from the run()method in context \ncto allocation site h. vP0T:C \u00d7 V \u00d7 C \u00d7 H is the set of initial inter-thread points-to relations. This \nincludes the points-to relations for thread cre\u00adation sites and for the global object. vP0T (c1,v,c2,h)means \nthat thread c1 has an thread allocation site h, and v points to the newly created thread context c2. \n(There are usually two contexts assigned to each allocation site). All global objects across all contexts \nare given the same context. vPT:C \u00d7 V \u00d7 C \u00d7 H is the thread-sensitive version of the variable points-to \nrelation vPC. vP T (c1,v,c2,h)means variable v in context c1 can point to heap object h created under \ncontext c2. hPT:C \u00d7 H \u00d7 F \u00d7 C \u00d7 H is the thread-sensitive version of the heap points-to relation hP. \nhPT (c1,h1,f,c2,h2)means that .eld f of heap object h1 created under context c1 can point to heap object \nh2 created under context c2. Rule (26) incorporates the initial points-to relations for thread creation \nsites. Rule (27) incorporates the points-to information for non-thread creation sites, which have the \ncontext numbers of threads that can reach the method. The other rules are analogous to those of the context-sensitive \npointer analysis, with an additional context attribute for the heap objects. From the analysis results, \nwe can easily determine which objects have escaped. An object hcreated by thread context chas escaped, \nwritten escaped(c,h), if it is accessed by a different context cv. Complications involving unknown code, \nsuch as native methods, could also be handled using this technique. escaped(c,h):- vPT (cv, ,c,h),cv \n=c. Conversely, an object hcreated by context cis captured, written captured(c,h), if it has not escaped. \nAny captured object can be allocated on a thread-local heap. captured(c,h):- vPT (c,v,c,h),\u00acescaped(c,h). \nWe can also use escape analysis to eliminate unnecessary syn\u00adchronizations. We de.ne a relation syncs(v)indicating \nif the pro\u00adgram contains a synchronization operation performed on variable v. A synchronization for variable \nv under context cis necessary, writ\u00adten neededSyncs(c,v),if syncs(v)and v can point to an escaped object. \nneededSyncs(c,v):- syncs(v),vPT (c,v,ch,h), escaped(ch,h) Notice that neededSyncs is context-sensitive. \nThus, we can distinguish when a synchronization is necessary only for certain threads, and generate specialized \nversions of methods for those threads.  6. EXPERIMENTAL RESULTS In this section, we present some experimental \nresults of using bd\u00addbddb on the Datalog algorithms presented in this paper. We de\u00adscribe our testing \nmethodology and benchmarks, present the anal\u00adysis times, evaluate the results of the analyses, and provide \nsome insight on our experience of developing these analyses and the bd\u00addbddb tool. 6.1 Methodology The \ninput to bddbddb is more or less the Datalog programs ex\u00adactly as they are presented in this paper. (We \nadded a few rules to handle return values and threads, and added annotations for the physical domain \nassignments of input relations.) The input rela\u00adtions were generated with the Joeq compiler infrastructure[32]. \nThe entire bddbddb implementation is only 2500 lines of code. bd\u00addbddb uses the JavaBDD library[31], \nan open-source library based on the BuDDy library[21]. The entire system is available as open\u00adsource[35], \nand we hope that others will .nd it useful. All experiments were performed on a 2.2GHz Pentium 4 with \nSun JDK 1.4.2 04 running on Fedora Linux Core 1. For the context\u00adinsensitive and context-sensitive experiments, \nrespectively: we used initial BDD table sizes of 4M and 12M; the tables could grow by 1M and 3M after \neach garbage collection; the BDD operation cache sizes were 1M and 3M. To test the scalability and applicability \nof the algorithm, we ap\u00adplied our technique to 21 of the most popular Java projects on Sourceforge as \nof November 2003. We simply walked down the list of 100% Java projects sorted by activity, selecting \nthe ones that would compile directly as standalone applications. They are all real applications with \ntens of thousands of users each. As far as we know, these are the largest benchmarks ever reported for \nany context-sensitive Java pointer analysis. As a point of comparison, the largest benchmark in the specjvm \nsuite, javac, would rank only 13th in our list. For each application, we chose an applicable main()method \nas the entry point to the application. We included all class initializers, thread run methods, and .nalizers. \nWe ignored null constants in the analysis every points-to set is automatically assumed to include null. \nException objects of the same type were merged. We treated re.ection and native methods as returning \nunknown objects. Some native methods and special .elds were modeled explicitly. A short description of \neach of the benchmarks is included in Fig\u00adure 3, along with their vital statistics. The number of classes, \nmeth\u00adods, and bytecodes were those discovered by the context-insensitive on-the-.y call graph construction \nalgorithm, so they include only the reachable parts of the program and the class library. The number \nof context-sensitive (C.S.) paths is for the most part correlated to the number of methods in the program, \nwith the excep\u00adtion of pmd. pmd has an astounding 5\u00d71023 paths in the call graph, which requires 79 bits \nto represent. pmd has different characteristics because it contains code generated by the parser generator \nJavaCC. Many machine-generated methods call the same class library rou\u00adtines, leading to a particularly \negregious exponential blowup. The JavaBDD library only supports physical domains up to 63 bits; con\u00adtexts \nnumbered beyond 263 were merged into a single context. The large number of paths also caused the algorithm \nto require many more rule applications to reach a .xpoint solution.  6.2 Analysis Times We measured \nthe analysis times and memory usage for each of the algorithms presented in this paper (Figure 4). The \nalgorithm with call graph discovery, in each iteration, computes a call graph based on the points-to \nrelations from the previous iteration. The number of iterations taken for that algorithm is also included \nhere. All timings reported are wall-clock times from a cold start, and include the various overheads \nfor Java garbage collection, BDD garbage collection, growing the node table, etc. The memory num\u00adbers \nreported are the sizes of the peak number of live BDD nodes during the course of the algorithm. We measured \npeak BDD mem\u00adory usage by setting the initial table size and maximum table size increase to 1MB, and \nonly allowed the table to grow if the node table was more than 99% full after a garbage collection.5 \n5To avoid garbage collections, it is recommended to use more mem\u00adory. Our timing runs use the default \nsetting of 80%. Name Description Classes Methods Bytecodes Vars Allocs C.S. Paths freetts speech synthesis \nsystem 215 723 48K 8K 3K 4 \u00d7 104 nfcchat scalable, distributed chat client 283 993 61K 11K 3K 8 \u00d7 106 \njetty HTTP Server and Servlet container 309 1160 66K 12K 3K 9 \u00d7 105 openwfe java workflow engine 337 \n1215 74K 14K 4K 3 \u00d7 106 joone Java neural net framework 375 1531 92K 17K 4K 1 \u00d7 107 jboss J2EE application \nserver 348 1554 104K 17K 4K 3 \u00d7 108 jbossdep J2EE deployer 431 1924 119K 21K 5K 4 \u00d7 108 sshdaemon SSH \ndaemon 485 2053 115K 24K 5K 4 \u00d7 109 pmd Java source code analyzer 394 1971 140K 19K 4K 5 \u00d7 1023 azureus \nJava bittorrent client 498 2714 167K 24K 5K 2 \u00d7 109 freenet anonymous peer-to-peer file sharing system \n667 3200 210K 38K 8K 2 \u00d7 107 sshterm SSH terminal 808 4059 241K 42K 8K 5 \u00d7 1011 jgraph mathematical graph-theory \nobjects and algorithms 1041 5753 337K 59K 10K 1 \u00d7 1011 umldot makes UML class diagrams from Java code \n1189 6505 362K 65K 11K 3 \u00d7 1014 jbidwatch auction site bidding, sniping, and tracking tool 1474 8262 \n489K 90K 16K 7 \u00d7 1013 columba graphical email client with internationalization 2020 10574 572K 111K 19K \n1 \u00d7 1013 gantt plan projects using Gantt charts 1834 10487 597K 117K 20K 1 \u00d7 1013 jxplorer ldap browser \n1927 10702 645K 133K 22K 2 \u00d7 109 jedit programmer s text editor 1788 10934 667K 124K 20K 6 \u00d7 107 megamek \nnetworked BattleTech game 1265 8970 668K 123K 21K 4 \u00d7 1014 gruntspud graphical CVS client 2277 12846 \n687K 145K 24K 2 \u00d7 109 Figure 3: Information about the benchmarks we used to test our analyses. The context-insensitive \nanalyses (Algorithms 1 and 2) are re\u00admarkably fast; the type-.ltering version was able to complete in \nunder 45 seconds on all benchmarks. It is interesting to notice that introducing type .ltering actually \nimproved the analysis time and memory usage. Along with being more accurate, the points-to sets are much \nsmaller in the type-.ltered version, leading to faster anal\u00adysis times. For Algorithm 3, the call graph \ndiscovery sometimes took over 40 iterations to complete, but it was very effective in reducing the size \nof the call graph as compared to CHA[19]. The complexity of the call graph discovery algorithm seems \nto vary with the number of virtual call sites that need resolving jedit and megamek have many methods \ndeclared as .nal, but jxplorer has none, leading to more call targets to resolve and longer analysis \ntimes. The analysis times and memory usages of our context-sensitive points-to analysis (Algorithm 5) \nwere, on the whole, very reason\u00adable. It can analyze most of the small and medium size benchmarks in \na few minutes, and it successfully .nishes analyzing even the largest benchmarks in under 19 minutes. \nThis is rather remarkable considering that the context-sensitive formulation is solving up to 1014 times \nas many relations as the context-insensitive version! Our scheme of numbering the contexts consecutively \nallows the BDD to ef.ciently represent the similarities between calling contexts. The analysis times \nare most directly correlated to the number of paths in the call graph. From the experimental data presented \nhere, it ap\u00adpears that the analysis time of the context-sensitive algorithm scales approximately with \nO(lg2 n) where n is the number of paths in the call graph; more experiments are necessary to determine \nif this trend persists across more programs. The context-sensitive type analysis (Algorithm 6) is, as \nexpected, quite a bit faster and less memory-intensive than the context\u00adsensitive points-to analysis. \nEven though it uses the same number of contexts, it is an order of magnitude faster than the context-sensitive \npoints-to analysis. This is because in the type analysis the number of objects that can be pointed to \nis much smaller, which greatly increases sharing in the BDD. The thread-sensitive pointer analy\u00adsis (Algorithm \n7) has analysis times and memory usages that are roughly comparable to those of the context-insensitive \npointer anal\u00adysis, even though it includes thread context information. This is because the number of \nthread creation sites is relatively small, and we use at most two contexts per thread.  6.3 Evaluation \nof Results An in-depth analysis of the accuracy of the analyses with respect to each of the queries in \nSection 5 is beyond the scope of this paper. Instead, we show the results of two speci.c queries: thread \nescape analysis (Section 5.6) and type re.nement (Section 5.3). The results of the escape analysis are \nshown in Figure 5. The .rst two columns give the number of captured and escaped object creation sites, \nrespectively. The next two columns give the number of unneeded and needed synchronization operations. \nThe single\u00adthreaded benchmarks have only one escaped object: the global ob\u00adject from which static variables \nare accessed. In the multi-threaded benchmarks, the analysis is effective in .nding 30-50% of the al\u00adlocation \nsites to be captured, and 15-30% of the synchronization operations to be unnecessary. These are static \nnumbers; to fully evaluate the results would require dynamic execution counts, which is outside of the \nscope of this paper. The results of the type re.nement query are shown in Figure 6. We tested the query \nacross six different analysis variations. From left to right, they are context-insensitive pointer analysis \nwith\u00adout and with type .ltering, context-sensitive pointer analysis and context-sensitive type analysis \nwith the context projected away, and context-sensitive pointer and type analysis on the fully cloned \ngraph. Projecting away the context in a context-sensitive analysis makes the result context-insensitive; \nhowever, it can still be more precise than context-insensitive analysis because of the extra pre\u00adcision \nat the intermediate steps of the analysis. We measured the percentages of variables that can point to \nmultiple types and vari\u00adables whose types can be re.ned. Including the type .ltering makes the algorithm \nstrictly more precise. Likewise, the context-sensitive pointer analysis is strictly more precise than \nboth the context-insensitive pointer analysis and the context-sensitive type analysis. We can see this \ntrend in the results. As the precision increases, the percentage of multi-typed variables drops and the \npercentage of re.nable variables increases. The context-insensitive pointer analysis and the context-sensitive \ntype analysis are not directly comparable; in some cases the point\u00ad Context-insensitive pointers Context-sensitive \nThread-sensitive Name pointer analysis time mem time mem time mem    freetts 13 13 202 4 16 16 \n14 nfcchat 14 14 234 6 2 12 2 12 16 jetty 15 15 224 7 3 12 2 10 16 openwfe 15 16 235 8 4 14 2 14 17 \n27 17 24 710 4 18 3 18 19 joone jboss 27 27 30 810 7 24 4 22 29 jbossdep 29 29 26 712 9 30 5 26 3 \n11 29 2 10 2613 14 12 34 6 28 3 13 sshdaemon pmd 17 17 33 910 297 111 19 36 19 azureus 2 10 2 10 2913 \n15 9 32 6 30 2 12 freenet 7 16 5 16 4041 23 21 38 10 32 6 21 8 17 5 17 3137 25 50 86 18 60 7 23 sshterm \njgraph 17 27 11 25 4278 37 119 134 33 20 13 35 umldot 17 30 11 29 3497 43 457 304 63 130 16 41 31 43 \n20 40 32 149 58 580 394 68 140 25 56 jbidwatch columba 43 55 27 49 42 273 73 807 400 123 178 38 72 \ngantt 41 59 26 51 39 261 76 1122 632 113 174 34 71 jxplorer 57 68 39 60 41 390 88 337 198 78 118 51 \n83 61 61 38 54 37 278 80 113 108 60 82 50 76 jedit megamek 40 57 26 51 34 201 76 1101 600 100 224 34 \n73 gruntspud 66 76 41 67 35 389 99 312 202 86 130 58 95 Figure 4: Analysis times and peak memory usages \nfor each of the benchmarks and analyses. Time is in seconds and memory is in megabytes. ers are more \nprecise, in other cases the context-sensitive types are more precise. When we do not project away the \ncontext, the context-sensitive results are remarkably precise the percentage of multi-typed vari\u00adables \nis never greater than 1% for the pointer analysis and 2% for the type analysis. Projecting away the context \nloses much of the bene.t of context sensitivity, but is still noticeably more precise than using a context-insensitive \nanalysis. heap objects sync operations Name captured escaped \u00acneeded needed freetts 2349 1 43 0 nfcchat \n1845 2369 52 46 jetty 2059 2408 47 89 openwfe 3275 1 57 0 joone 1640 1908 34 75 jboss 3455 2836 112 105 \njbossdep 1838 2298 32 94 sshdaemon 12822 22669 468 1244 pmd 3428 1 47 0 azureus 8131 9183 226 229 freenet \n5078 9737 167 309 sshterm 16118 24483 767 3642 jgraph 25588 48356 1078 5124 umldot 38930 69332 2146 8785 \njbidwatch 97234 143384 2243 11438 columba 111578 174329 3334 18223 gantt 106814 156752 2377 11037 jxplorer \n188192 376927 4127 18904 jedit 446896 593847 7132 36832 megamek 179221 353096 3846 22326 gruntspud 248426 \n497971 5902 25568 Figure 5: Results of escape analysis.  6.4 Experience All the experimental results \nreported here are generated using bd\u00addbddb. At the early stages of our research, we hand-coded every \npoints-to analysis using BDD operations directly and spent a con\u00adsiderable amount of time tuning their \nperformance. Our context\u00adnumbering scheme is the reason why the analysis would .nish at all on even small \nprograms. Every one of the optimizations described in Section 2.4 was .rst carried out manually. After \nconsiderable ef\u00adfort, megamek still took over three hours to analyze, and jxplorer did not complete at \nall. The incrementalization was very dif.cult to get correct, and we found a subtle bug months after \nthe imple\u00admentation was completed. We did not incrementalize the outermost loops as it would have been \ntoo tedious and error-prone. It was also dif.cult to experiment with different rule application orders. \nTo get even better performance, and more importantly to make it easier to develop new queries and analyses, \nwe created bddbddb. We automated and extended the optimizations we have used in our manual implementation, \nand implemented a few new ones to em\u00adpirically choose the best BDD library parameters. The end result \nis that code generated by bddbddb outperforms our manually tuned context-sensitive pointer analysis by \nas much as an order of magni\u00adtude. Even better, we could use bddbddb to quickly and painlessly develop \nnew analyses that are highly ef.cient, such as the type anal\u00adysis in Section 5.5 and the thread escape \nanalysis in Section 5.6.  7. RELATED WORK This paper describes a scalable cloning-based points-to analysis \nthat is context-sensitive, .eld-sensitive, inclusion-based and imple\u00admented using BDDs. Our program analyses, \nexpressed in Datalog, are translated by bddbddb into a BDD implementation automati\u00adcally. We also presented \nexample queries using our system to check for vulnerabilities, infer types, and .nd objects that escape \na thread. Due to space constraints, we can only describe work that is very closely related to ours. Scalable \npointer analyses. Most of the scalable algorithms pro\u00adposed are context-insensitive and .ow-insensitive. \nThe .rst scalable pointer analysis proposed was a uni.cation-based algorithm due to Steensgaard[28]. \nDas et al. extended the uni.cation-based approach to include one-level-.ow [10] and one level of context \nsensitiv\u00adity[11]. Subsequently, a number of inclusion-based algorithms have been shown to scale to large \nprograms[3, 17, 19, 33]. A number of context-sensitive but .ow-insensitive analyses have been developed \nrecently[15, 16]. The C pointer analysis due to Context-insensitive pointers Projected context-sensitive \n Context-sensitive Name no type filter with type filter pointer analysis type analysis pointer analysis \ntype analysis multi refine multi refine multi refine multi refine multi refine multi refine  freetts \n5.1 41.1 2.3 41.6 2.0 41.9 2.5 41.3 0.1 44.4 0.3 44.0 nfcchat 12.4 36.4 8.6 37.0 8.2 37.4 8.6 36.9 \n0.1 45.9 0.7 45.3 jetty 12.6 36.2 7.7 37.1 7.3 37.4 7.7 37.1 0.1 45.4 0.6 44.8 openwfe 12.1 36.9 7.0 \n37.7 6.6 38.0 7.0 37.6 0.1 45.5 0.5 44.8 11.9 37.5 6.8 38.1 6.4 38.4 6.7 38.1 0.1 45.8 0.5 45.0 joone \njboss 13.4 37.8 7.9 38.7 7.4 39.3 7.8 38.7 0.1 47.3 0.7 46.4 jbossdep 10.2 40.3 7.4 39.5 7.0 40.0 7.5 \n39.4 0.2 47.6 0.8 46.6 10.7 39.3 6.0 40.3 5.8 40.5 5.9 40.4 0.1 46.8 0.6 46.1 sshdaemon pmd 9.6 42.3 \n6.2 43.1 5.9 43.4 6.2 43.1 0.1 52.1 0.6 48.1 azureus 10.0 43.6 6.1 44.1 6.0 44.3 6.2 44.1 0.1 50.8 \n0.9 49.7 freenet 12.1 39.1 6.3 40.0 5.9 40.5 6.3 40.1 0.1 47.0 0.8 46.0 14.7 40.8 8.9 42.0 8.5 42.5 \n9.0 42.1 0.6 51.3 1.6 49.9 sshterm jgraph 16.1 43.2 9.6 45.1 9.3 45.4 9.7 45.2 0.7 54.7 1.9 53.2 umldot \n15.7 42.3 9.4 43.6 9.0 43.9 9.4 43.6 0.6 53.0 2.0 51.2 14.9 42.3 8.6 43.4 8.2 43.7 8.6 43.4 0.6 52.0 \n1.7 50.5 jbidwatch columba 15.7 42.3 9.0 43.7 8.6 44.1 8.9 43.9 0.6 52.4 1.8 51.0 gantt 15.0 43.4 8.2 \n44.7 7.9 45.0 8.2 44.7 0.5 53.0 1.7 51.4 jxplorer 15.2 43.1 7.9 44.3 7.7 44.6 8.0 44.4 0.5 52.5 1.6 \n50.8 15.4 43.6 8.1 44.7 7.9 44.9 8.1 44.7 0.6 53.1 1.6 51.5 jedit megamek 13.3 44.6 7.1 45.1 6.8 45.3 \n7.2 45.2 0.5 53.3 1.4 51.6 gruntspud 15.4 44.0 7.7 45.5 7.5 45.7 7.8 45.5 0.5 53.6 1.4 52.1    Figure \n6: Results of the type re.nement query. Numbers are percentages. Columns labeled multi and re.ne refer \nto multi-type variables and re.nable-type variables, respectively. F\u00a8ahndrich et al.[15] has been demonstrated \nto work on a 200K-line gccprogram. Unlike ours, their algorithm is uni.cation-based and .eld-independent, \nmeaning that .elds in a structure are modeled as having the same location. Their context-sensitive analysis \ndiscov\u00aders targets of function pointers on-the-.y. Our algorithm .rst com\u00adputes the call graph using \na context-insensitive pointer alias analy\u00adsis; there are signi.cantly more indirect calls in Java programs, \nthe target of our technique, due to virtual method invocations. Their al\u00adgorithm uses CFL-reachability \nqueries to implement context sensi\u00adtivity[24]. Instead of computing context-sensitive solutions on de\u00admand, \nwe compute all the context-sensitive results and represent them in a form convenient for further analysis. \nOther context-sensitive pointer analysis. Some of the earlier attempts of context-sensitive analysis \nare .ow-sensitive[14, 18, 34, 37]. Our analysis is similar to the work by Emami et al. in that they also \ncompute context-sensitive points-to results directly for all the different contexts. Their analysis is \n.ow-sensitive; ours uses .ow sensitivity only in summarizing each method intraprocedurally. While our \ntechnique treats all members of a strongly connected component in a call graph as one unit, their technique \nonly ignores subsequent invocations in recursive cycles. On the other hand, their technique has only \nbeen demonstrated to work for programs under 3000 lines. As discussed in Section 1, using summaries is \nanother common approach to context sensitivity. It is dif.cult to compute a compact summary if a fully \n.ow-sensitive result is desired. One solution is to use the concept of partial transfer functions, which \ncreate sum\u00admaries for observed calling contexts[36, 37]. The same summary can be reused by multiple contexts \nthat share the same relevant alias patterns. This technique has been shown to handle C programs up to \n20,000 lines. One solution is to allow only weak updates[34]; that is, a write to a variable only adds \na value to the contents of the variable without removing the previously held value. This greatly reduces \nthe power of a .ow-sensitive analysis. This approach has been used to handle programs up to 70,000 lines \nof code. However, on larger programs the representation still becomes too large to deal with. Because \nthe goal of the prior work was escape analysis, it was not necessary to maintain precise points-to relations \nfor locations that escape, so the algorithm achieved scalability by collapsing escaped nodes. BDD-based \npointer analysis. BDDs have recently been used in a number of program analyses such as predicate abstraction[2], \nshape analysis[23, 38], and, in particular, points-to analysis[3, 39]. Zhu proposed a summary-based context-sensitive \npoints-to analysis for C programs, and reported preliminary experimental results on C programs with less \nthan 5000 lines[39]. Berndl et al. showed that BDDs can be used to compute context-insensitive inclusion\u00adbased \npoints-to results for large Java programs ef.ciently. In the same conference this paper is presented, \nZhu and Calman describe a cloning-based context-sensitive analysis for C pointers, assuming that only \nthe safe C subset is used. The largest program reported in their experiment has about 25,000 lines and \n3 \u00d7 108 contexts[40]. High-level languages and tools for program analysis. The use of Datalog and other \nlogic programming languages has previ\u00adously been proposed for describing program analyses[12, 25, 30]. \nOur bddbddb system implements Datalog using BDDs[35] and has been used to compute context-sensitive points-to \nresults and other advanced analyses. Other examples of systems that translate pro\u00adgram analyses and queries \nwritten in logic programming languages into implementations using BDDs include Toupie[9] and Croco\u00adPat[4]. \nJedd is a Java language extension that provides a relational algebra abstraction over BDDs[20].  8. \nCONCLUSION This paper shows that, by using BDDs, it is possible to obtain ef.cient implementations of \ncontext-sensitive analyses using an ex\u00adtremely simple technique: We clone all the methods in a call graph, \none per context of interest, and simply apply a context-insensitive analysis over the cloned graph to \nget context-sensitive results. By numbering similar contexts contiguously, the BDD is able to handle \nthe exponential blowup of contexts by exploiting their commonal\u00adities. We showed that this approach can \nbe applied to type infer\u00adence, thread escape analysis and even fully context-sensitive points\u00adto analysis \non large programs. This paper shows that we can create ef.cient BDD-based anal\u00adyses easily. By keeping \ndata and analysis results as relations, we can express queries and analyses in terms of Datalog. The \nbddb\u00adddb system we have developed automatically converts Datalog pro\u00adgrams into BDD implementations that \nare even more ef.cient than those we have painstakingly hand-tuned. Context-sensitive pointer analysis \nis the cornerstone of deep pro\u00adgram analysis for modern programming languages. By combining (1) context-sensitive \npoints-to results, (2) a simple approach to con\u00adtext sensitivity, and (3) a simple logic-programming \nbased query framework, we believe we have made it much easier to create ad\u00advanced program analyses. Acknowledgments \nThis material is based upon work supported by the National Sci\u00adence Foundation under Grant No. 0086160 \nand an NSF Graduate Student Fellowship. We thank our anonymous referees for their helpful comments. \n9. REFERENCES [1] I. Balbin and K. Ramamohanarao. A generalization of the differential approach to recursive \nquery optimization. Journal of Logic Programming, 4(3):259 262, Sept. 1987. [2] T. Ball and S. K. Rajamani. \nA symbolic model checker for boolean programs. In Proceedings of the SPIN 2000 Workshop on Model Checking \nof Software, pages 113 130, Aug. 2000. [3] M. Berndl, O. Lhot\u00b4ak, F. Qian, L. Hendren, and N. Umanee. \nPoints-to analysis using BDDs. In Proceedings of the SIGPLAN Conference on Programming Language Design \nand Implementation, pages 103 114, June 2003. [4] D. Beyer, A. Noack, and C. Lewerentz. Simple and ef.cient \nrelational querying of software structures. In Proceedings of the 10th IEEE Working Conference on Reverse \nEngineering, Nov. 2003. [5] B. Bollig and I. Wegener. Improving the variable ordering of OBDDs is NP-complete. \nIEEE Transactions on Computers, 45(9):993 1002, Sept. 1996. [6] R. E. Bryant. Graph-based algorithms \nfor Boolean function manipulation. IEEE Transactions on Computers, C-35(8):677 691, Aug. 1986. [7] A. \nChandra and D. Harel. Horn clauses and generalizations. Journal of Logic Programming, 2(1):1 15, 1985. \n[8] J.-D. Choi, M. Gupta, M. J. Serrano, V. C. Sreedhar, and S. P. Midkiff. Escape analysis for Java. \nIn Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, \npages 1 19, Nov. 1999. [9] M.-M. Corsini, K. Musumbu, A. Rauzy, and B. L. Charlier. Ef.cient bottom-up \nabstract interpretation of Prolog by means of constraint solving over symbolic .nite domains. In Proceedings \nof the International Symposium on Programming Language Implementation and Logic Programming, pages 75 \n91, Aug. 1993. [10] M. Das. Uni.cation-based pointer analysis with directional assignments. In Proceedings \nof the SIGPLAN Conference on Programming Language Design and Implementation, pages 35 46, June 2000. \n[11] M. Das, B. Liblit, M. F\u00a8 ahndrich, and J. Rehof. Estimating the impact of scalable pointer analysis \non optimization. In Proceedings of the 8th International Static Analysis Symposium, pages 260 278, July \n2001. [12] S. Dawson, C. R. Ramakrishnan, and D. S. Warren. Practical program analysis using general \npurpose logic programming systems a case study. In Proceedings of the SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 117 126, May 1996. [13] J. Dean, D. Grove, and C. Chambers. \nOptimization of object-oriented programs using static class hierarchy analysis. In Proceedings of the \n9th European Conference on Object-Oriented Programming, pages 77 101, Aug. 1995. [14] M. Emami, R. Ghiya, \nand L. J. Hendren. Context-sensitive interprocedural points-to analysis in the presence of function pointers. \nIn Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, pages 242 \n256, June 1994. [15] M. F\u00a8 ahndrich, J. Rehof, and M. Das. Scalable context-sensitive .ow analysis using \ninstantiation constraints. In Proceedings of the SIGPLAN Conference on Programming Language Design and \nImplementation, pages 253 263, June 2000. [16] J. S. Foster, M. F\u00a8ahndrich, and A. Aiken. Polymorphic \nversus monomorphic .ow-insensitive points-to analysis for C. In Proceedings of the 7th International \nStatic Analysis Symposium, pages 175 198, Apr. 2000. [17] N. Heintze and O. Tardieu. Ultra-fast aliasing \nanalysis using CLA: A million lines of C code in a second. In Proceedings of the SIGPLAN Conference on \nProgramming Language Design and Implementation, pages 254 263, June 2001. [18] W. Landi, B. G. Ryder, \nand S. Zhang. Interprocedural modi.cation side effect analysis with pointer aliasing. In Proceedings \nof the SIGPLAN Conference on Programming Language Design and Implementation, pages 56 67, June 1993. \n[19] O. Lhot\u00b4ak and L. Hendren. Scaling Java points-to analysis using Spark. In Proceedings of the 12th \nInternational Conference on Compiler Construction, pages 153 169, April 2003. [20] O. Lhot\u00b4ak and L. \nHendren. Jedd: A BDD-based relational extension of Java. In Proceedings of the SIGPLAN Conference on \nProgramming Language Design and Implementation, June 2004. [21] J. Lind-Nielsen. BuDDy, a binary decision \ndiagram package. http://www.itu.dk/research/buddy/. [22] T. Lindholm and F. Yellin. The Java Virtual \nMachine Speci.cation. Addison-Wesley, 2nd edition, 1999. [23] R. Manevich, G. Ramalingam, J. Field, D. \nGoyal, and M. Sagiv. Compactly representing .rst-order structures for static analysis. In Proceedings \nof the 9th International Static Analysis Symposium, pages 196 212, Sept. 2002. [24] T. Reps, S. Horwitz, \nand M. Sagiv. Precise interprocedural data.ow analysis via graph reachability. In Proceedings of the \n24th Annual Symposium on Principles of Programming Languages, pages 49 61, Jan. 1995. [25] T. W. Reps. \nDemand Interprocedural Program Analysis Using Logic Databases, pages 163 196. Kluwer, 1994. [26] O. Shivers. \nControl-Flow Analysis of Higher-Order Languages. PhD thesis, Carnegie Mellon University, May 1991. [27] \nF. Somenzi. CUDD: CU decision diagram package release, 1998. [28] B. Steensgaard. Points-to analysis \nin almost linear time. In Symposium on Principles of Programming Languages, pages 32 41, Jan. 1996. [29] \nJava cryptography extension (JCE). http://java.sun.com/products/jce, 2003. [30] J. D. Ullman. Principles \nof Database and Knowledge-Base Systems. Computer Science Press, Rockville, Md., volume II edition, 1989. \n[31] J. Whaley. JavaBDD library. http://javabdd.sourceforge.net. [32] J. Whaley. Joeq: A virtual machine \nand compiler infrastructure. In Proceedings of the SIGPLAN Workshop on Interpreters, Virtual Machines, \nand Emulators, pages 58 66, June 2003. [33] J. Whaley and M. S. Lam. An ef.cient inclusion-based points-to \nanalysis for strictly-typed languages. In Proceedings of the 9th International Static Analysis Symposium, \npages 180 195, Sept. 2002. [34] J. Whaley and M. Rinard. Compositional pointer and escape analysis for \nJava programs. In Conference of Object Oriented Programming: Systems, Languages, and Applications, pages \n187 206, Nov. 1999. [35] J. Whaley, C. Unkel, and M. S. Lam. A BDD-based deductive database for program \nanalysis. http://suif.stanford.edu/bddbddb, 2004. [36] R. P. Wilson. Ef.cient, context-sensitive pointer \nanalysis for C programs. PhD thesis, Stanford University, Dec. 1997. [37] R. P. Wilson and M. S. Lam. \nEf.cient context-sensitive pointer analysis for C programs. In Proceedings of the SIGPLAN Conference \non Programming Language Design and Implementation, pages 1 12, June 1995. [38] T. Yavuz-Kahveci and T. \nBultan. Automated veri.cation of concurrent linked lists with counters. In Proceedings of the 9th International \nStatic Analysis Symposium, pages 69 84, Sept. 2002. [39] J. Zhu. Symbolic pointer analysis. In Proceedings \nof the International Conference in Computer-Aided Design, pages 150 157, Nov. 2002. [40] J. Zhu and S. \nCalman. Symbolic pointer analysis revisited. In Proceedings of the SIGPLAN Conference on Programming \nLanguage Design and Implementation, June 2004.  \n\t\t\t", "proc_id": "996841", "abstract": "This paper presents the first scalable context-sensitive, inclusion-based pointer alias analysis for Java programs. Our approach to context sensitivity is to create a clone of a method for every context of interest, and run a <i>context-insensitive</i> algorithm over the expanded call graph to get <i>context-sensitive</i> results. For precision, we generate a clone for every acyclic path through a program's call graph, treating methods in a strongly connected component as a single node. Normally, this formulation is hopelessly intractable as a call graph often has 10 14 acyclic paths or more. We show that these exponential relations can be computed efficiently using binary decision diagrams (BDDs). Key to the scalability of the technique is a context numbering scheme that exposes the commonalities across contexts. We applied our algorithm to the most popular applications available on Sourceforge, and found that the largest programs, with hundreds of thousands of Java bytecodes, can be analyzed in under 20 minutes.This paper shows that pointer analysis, and many other queries and algorithms, can be described succinctly and declaratively using Datalog, a logic programming language. We have developed a system called bddbddb that automatically translates Datalog programs into highly efficient BDD implementations. We used this approach to develop a variety of context-sensitive algorithms including side effect analysis, type analysis, and escape analysis.", "authors": [{"name": "John Whaley", "author_profile_id": "81100268439", "affiliation": "Stanford University, Stanford, CA", "person_id": "PP37025809", "email_address": "", "orcid_id": ""}, {"name": "Monica S. Lam", "author_profile_id": "81100237956", "affiliation": "Stanford University, Stanford, CA", "person_id": "PP14092336", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996859", "year": "2004", "article_id": "996859", "conference": "PLDI", "title": "Cloning-based context-sensitive pointer alias analysis using binary decision diagrams", "url": "http://dl.acm.org/citation.cfm?id=996859"}