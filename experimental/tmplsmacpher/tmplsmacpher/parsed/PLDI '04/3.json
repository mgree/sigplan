{"article_publication_date": "06-09-2004", "fulltext": "\n Scalable Lock-Free Dynamic Memory Allocation Maged M. Michael IBM Thomas J. Watson Research Center \nP.O. Box 218, Yorktown Heights, NY 10598, USA magedm@us.ibm.com ABSTRACT Dynamic memory allocators (malloc/free) \nrely on mutual exclusion locks for protecting the consistency of their shared data structures under multithreading. \nThe use of locking has many disadvantages with respect to performance, avail\u00adability, robustness, and \nprogramming .exibility. A lock-free memory allocator guarantees progress regardless of whether some threads \nare delayed or even killed and regardless of scheduling policies. This paper presents a completely lock\u00adfree \nmemory allocator. It uses only widely-available oper\u00adating system support and hardware atomic instructions. \nIt o.ers guaranteed availability even under arbitrary thread termination and crash-failure, and it is \nimmune to dead\u00adlock regardless of scheduling policies, and hence it can be used even in interrupt handlers \nand real-time applications without requiring special scheduler support. Also, by lever\u00adaging some high-level \nstructures from Hoard, our allocator is highly scalable, limits space blowup to a constant factor, and \nis capable of avoiding false sharing. In addition, our allocator allows .ner concurrency and much lower \nlatency than Hoard. We use PowerPC shared memory multipro\u00adcessor systems to compare the performance of \nour allocator with the default AIX 5.1 libc malloc, and two widely-used multithread allocators, Hoard \nand Ptmalloc. Our allocator outperforms the other allocators in virtually all cases and often by substantial \nmargins, under various levels of paral\u00adlelism and allocation patterns. Furthermore, our allocator also \no.ers the lowest contention-free latency among the al\u00adlocators by signi.cant margins. Categories and \nSubject Descriptors: D.1.3 [ Programming Techniques]: Concurrent Programming; D.3.3 [Program\u00adming Languages]: \nLanguage Constructs and Features dynamic storage management; D.4.1 [Operating Systems]: Process Management \nconcurrency, deadlocks, synchroniza\u00adtion, threads. General Terms: Algorithms, Performance, Reliability. \nKeywords: malloc, lock-free, async-signal-safe, availability. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for profit or commercial advantage and that copies bear this notice and the \nfull citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior specific permission and/or a fee. PLDI 04, June 9 11, 2004, Washington, DC, \nUSA. Copyright 2004 ACM 1-58113-807-5/04/0006 ...$5.00.  1. INTRODUCTION Dynamic memory allocation \nfunctions, such as malloc and free, are heavily used by a wide range of important multi\u00adthreaded applications, \nfrom commercial database and web servers to data mining and scienti.c applications. In order to be safe \nunder multithreading (MT-safe), current alloca\u00adtors employ mutual exclusion locking in a variety of ways, \nranging from the use of a single lock wrapped around single\u00adthread malloc and free, to the distributed \nuse of locks in order to allow more concurrency and higher scalability. The use of locking causes many \nproblems and limitations with respect to performance, availability, robustness, and pro\u00adgramming .exibility. \nA desirable but challenging alternative approach for achiev\u00ading MT-safety is lock-free synchronization. \nA shared object is lock-free (nonblocking) if it guarantees that whenever a thread executes some .nite \nnumber of steps, at least one operation on the object by some thread must have made progress during the \nexecution of these steps. Lock-free syn\u00adchronization implies several inherent advantages: Immunity to \ndeadlock: By de.nition, a lock-free object must be immune to deadlock and livelock. Therefore, it is \nmuch simpler to design deadlock-free systems when all or some of their components are lock-free. Async-signal-safety: \nDue to the use of locking in cur\u00adrent implementations of malloc and free, they are not consid\u00adered async-signal-safe \n[9], i.e., signal handlers are prohibited from using them. The reason for this prohibition is that if \na thread receives a signal while holding a user-level lock in the allocator, and if the signal handler \ncalls the allocator, and in the process it must acquire the same lock held by the interrupted thread, \nthen the allocator becomes deadlocked due to circular dependence. The signal handler waits for the interrupted \nthread to release the lock, while the thread cannot resume until the signal handler completes. Masking \ninterrupts or using kernel-assisted locks in malloc and free is too costly for such heavily-used functions. \nIn contrast, a completely lock-free allocator is capable of being async\u00adsignal-safe without incurring \nany performance cost. Tolerance to priority inversion: Similarly, in real-time applications, user-level \nlocking is susceptible to deadlock due to priority inversion. That is, a high priority thread can be \nwaiting for a user-level lock to be released by a lower priority thread that will not be scheduled until \nthe high priority thread completes its task. Lock-free synchronization guarantees progress regardless \nof scheduling policies. Kill-tolerant availability: A lock-free object must be immune to deadlock even \nif any number of threads are killed while operating on it. Accordingly, a lock-free object must o.er \nguaranteed availability regardless of arbitrary thread CAS(addr,expval,newval) atomically do if (*addr \n== expval) { *addr = newval; return true; } else return false; Figure 1: Compare-and-Swap. termination \nor crash-failure. This is particularly useful for servers that require a high level of availability, \nbut can toler\u00adate the infrequent loss of tasks or servlets that may be killed by the server administrator \nin order to relieve temporary re\u00adsource shortages. Preemption-tolerance: When a thread is preempted while \nholding a mutual exclusion lock, other threads wait\u00ading for the same lock either spin uselessly, possibly \nfor the rest of their time slices, or have to pay the performance cost of yielding their processors in \nthe hope of giving the lock holder an opportunity to complete its critical section. Lock-free synchronization \no.ers preemption-tolerant perfor\u00admance, regardless of arbitrary thread scheduling. It is clear that it \nis desirable for memory allocators to be completely lock-free. The question is how, and more im\u00adportantly, \nhow to be completely lock-free and (1) o.er good performance competitive with the best lock-based allocators \n(i.e., low latency, scalability, avoiding false sharing, constant space blowup factor, and robustness \nunder contention and preemption), (2) using only widely-available hardware and OS support, and (3) without \nmaking trivializing assump\u00adtions that make lock-free progress easy, but result in unac\u00adceptable memory \nconsumption or impose unreasonable re\u00adstrictions. For example, it is trivial to design a wait-free allocator \nwith pure per-thread private heaps. That is, each thread allocates from its own heap and also frees blocks \nto its own heap. However, this is hardly an acceptable general-purpose solution, as it can lead to unbounded \nmemory consumption (e.g., under a producer-consumer pattern [3]), even when the program s memory needs \nare in fact very small. Other unacceptable characteristics include the need for initializing large parts \nof the address space, putting an arti.cial limit on the total size or number of allocatable dynamic blocks, \nor restricting beforehand regions of the address to speci.c threads or speci.c block sizes. An acceptable \nsolution must be general-purpose and space e.cient, and should not im\u00adpose arti.cial limitations on the \nuse of the address space. In this paper we present a completely lock-free allocator that o.ers excellent \nperformance, uses only widely-available hardware and OS support, and is general-purpose. For constructing \nour lock-free allocator and with only the simple atomic instructions supported on current mainstream \nprocessor architectures as our memory access tools, we break down malloc and free into .ne atomic steps, \nand organize the allocator s data structures such that if any thread is delayed arbitrarily (or even \nkilled) at any point, then any other thread using the allocator will be able to determine enough of the \nstate of the allocator to proceed with its own operation without waiting for the delayed thread to resume. \nBy leveraging some high-level structures from Hoard [3], a scalable lock-based allocator, we achieve \nconcurrency be\u00adtween operations on multiple processors, avoid inducing false sharing, and limit space \nblowup to a constant factor. In addition, our allocator uses a simpler and .ner grained or\u00ad AtomicInc(addr) \ndo { oldval = *addr; newval = oldval+1; } until CAS(addr,oldval,newval); Figure 2: Atomic increment using \nCAS. ganization that allows more concurrency and lower latency than Hoard. We use POWER3 and POWER4 \nshared memory mul\u00adtiprocessors to compare the performance of our allocator with the default AIX 5.1 libc \nmalloc, and two widely-used lock-based allocators with mechanisms for scalable perfor\u00admance, Hoard [3] \nand Ptmalloc [6]. The experimental per\u00adformance results show that not only is our allocator compet\u00aditive \nwith some of the best lock-based allocators, but also that it outperforms them, and often by substantial \nmargins, in virtually all cases including under various levels of par\u00adallelism and various sharing patterns, \nand also o.ers the lowest contention-free latency. The rest of the paper is organized as follows. In \nSection 2, we discuss atomic instructions and related work. Section 3 describes the new allocator in \ndetail. Section 4 presents our experimental performance results. We conclude the paper with Section 5. \n 2. BACKGROUND 2.1 Atomic Instructions Current mainstream processor architectures support ei\u00adther Compare-and-Swap \n(CAS) or the pair Load-Linked and Store-Conditional (LL/SC). Other weaker instructions, such as Fetch-and-Add \nand Swap, may be supported, but in any case they are easily implemented using CAS or LL/SC. CAS was introduced \non the IBM System 370 [8]. It is supported on Intel (IA-32 and IA-64) and Sun SPARC ar\u00adchitectures. In \nits simplest form, it takes three arguments: the address of a memory location, an expected value, and \na new value. If the memory location is found to hold the expected value, the new value is written to \nit, atomically. A Boolean return value indicates whether the write occurred. If it returns true, it is \nsaid to succeed. Otherwise, it is said to fail. Figure 1 shows the semantics of CAS. LL and SC are supported \non the PowerPC, MIPS, and Alpha architectures. LL takes one argument: the address of a memory location, \nand returns its contents. SC takes two arguments: the address of a memory location and a new value. Only \nif no other thread has written the memory lo\u00adcation since the current thread last read it using LL, the \nnew value is written to the memory location, atomically. A Boolean return value indicates whether the \nwrite occurred. Similar to CAS, SC is said to succeed or fail if it returns true or false, respectively. \nFor architectural reasons, current architectures that support LL/SC do not allow the nesting or interleaving \nof LL/SC pairs, and infrequently allow SC to fail spuriously, even if the target location was never written \nsince the last LL. These spurious failures happen, for exam\u00adple, if the thread was preempted or a di.erent \nlocation in the same cache line was written by another processor. For generality, we present the algorithms \nin this paper using CAS. If LL/SC are supported rather than CAS, then CAS(addr,expval,newval) can be \nsimulated in a lock-free manner as follows: {do {if (LL(addr)!=expval) return false;} until SC(addr,newval); \nreturn true;}. Support for CAS and restricted LL/SC on aligned 64-bit blocks is available on both 32-bit \nand 64-bit architectures, e.g., CMPXCHG8 on IA-32. However, support for CAS or LL/SC on wider block sizes \nis generally not available even on 64-bit architectures. Therefore, we focus our presentation of the \nalgorithms on 64-bit mode, as it is the more challenging case while 32-bit mode is simpler. For a very \nsimple example of lock-free synchronization, Figure 2 shows the classic lock-free implementation of Atomic-Increment \nusing CAS [8]. Note that if a thread is de\u00adlayed at any point while executing this routine, other active \nthreads will be able to proceed with their operations with\u00adout waiting for the delayed thread, and every \ntime a thread executes a full iteration of the loop, some operation must have made progress. If the CAS \nsucceeds, then the incre\u00adment of the current thread has taken e.ect. If the CAS fails, then the value \nof the counter must have changed during the loop. The only way the counter changes is if a CAS succeeds. \nThen, some other thread s CAS must have succeeded during the loop and hence that other thread s increment \nmust have taken e.ect.  2.2 Related Work The concept of lock-free synchronization goes back more than \ntwo decades. It is attributed to early work by Lam\u00adport [12] and to the motivating basis for introducing \nthe CAS instruction in the IBM System 370 documentation [8]. The impossibility and universality results \nof Herlihy [7] had signi.cant in.uence on the theory and practice of lock-free synchronization, by showing \nthat atomic instructions such as CAS and LL/SC are more powerful than others such as Test-and-Set, Swap, \nand Fetch-and-Add, in their ability to provide lock-free implementations of arbitrary object types. In \nother publications [17, 19], we review practical lock-free algorithms for dynamic data structures in \nlight of recent advances in lock-free memory management. Wilson et. al. [23] present a survey of sequential \nmemory allocation. Berger [2, 3] presents an overview of concurrent allocators, e.g., [4, 6, 10, 11, \n13]. In our experiments, we compare our allocator with two widely-used malloc replace\u00adment packages for \nmultiprocessor systems, Ptmalloc and Hoard. We also leverage some scalability-enabling high-level structures \nfrom Hoard. Ptmalloc [6], developed by Wolfram Gloger and based on Doug Lea s dlmalloc sequential allocator \n[14], is part of GNU glibc. It uses multiple arenas in order to reduce the adverse e.ect of contention. \nThe granularity of locking is the arena. If a thread executing malloc .nds an arena locked, it tries \nthe next one. If all arenas are found to be locked, the thread creates a new arena to satisfy its malloc \nand adds the new arena to the main list of arenas. To improve locality and reduce false sharing, each \nthread keeps thread-speci.c in\u00adformation about the arena it used in its last malloc. When a thread frees \na chunk (block), it returns the chunk to the arena from which the chunk was originally allocated, and \nthe thread must acquire that arena s lock. Hoard [2, 3], developed by Emery Berger, uses multiple processor \nheaps in addition to a global heap. Each heap contains zero or more superblocks. Each superblock con\u00adtains \none or more blocks of the same size. Statistics are maintained individually for each superblock as well \nas col\u00adlectively for the superblocks of each heap. When a processor heap is found to have too much available \nspace, one of its su\u00adperblocks is moved to the global heap. When a thread .nds that its processor heap \ndoes not have available blocks of the desired size, it checks if any superblocks of the desired size \nare available in the global heap. Threads use their thread ids to decide which processor heap to use \nfor malloc. For free, a thread must return the block to its original superblock and update the fullness \nstatistics for the superblock as well as the heap that owns it. Typically, malloc and free require one \nand two lock acquisitions, respectively. Dice and Garthwaite [5] propose a partly lock-free allo\u00adcator. \nThe allocator requires special operating system sup\u00adport, which makes it not readily portable across \noperating systems and programming environments. In the environ\u00adment for their allocator, the kernel monitors \nthread migra\u00adtion and preemption and posts upcalls to user-mode. When a thread is scheduled to run, the \nkernel posts the CPU id of the processor that the thread is to run on during its upcom\u00ading time slice. \nThe kernel also saves the user-mode instruc\u00adtion pointer in a thread-speci.c location and replaces it \nwith the address of a special noti.cation routine that will be the .rst thing the thread executes when \nit resumes. The noti.\u00adcation routine checks if the thread was in a critical section when it was preempted. \nIf so, the noti.cation routine passes control to the beginning of the critical section instead of the \noriginal instruction pointer, so that the thread can retry its critical section. The allocator can apply \nthis mechanism only to CPU-speci.c data. So, it is only used for the CPU s local heap. For all other \noperations, such as freeing a block that belongs to a remote CPU heap or any access to the global heap, \nmutual exclusion locks are used. The allocator is not completely lock-free, and hence without additional \nspecial support from the kernel it is susceptible to deadlock under arbitrary thread termination or priority \ninversion.  3. LOCK-FREE ALLOCATOR This section describes our lock-free allocator in detail. Without \nloss of generality we focus on the case of a 64-bit address space. The 32-bit case is simpler, as 64-bit \nCAS is supported on 32-bit architectures. 3.1 Overview First, we start with the general structure of \nthe allocator. Large blocks are allocated directly from the OS and freed directly to the OS. For smaller \nblock sizes, the heap is com\u00adposed of large superblocks (e.g., 16 KB). Each superblock is divided into \nmultiple equal-sized blocks. Superblocks are distributed among size classes based on their block sizes. \nEach size class contains multiple processor heaps propor\u00adtional to the number of processors in the system. \nA proces\u00adsor heap contains at most one active superblock. An active superblock contains one or more blocks \navailable for reser\u00advation that are guaranteed to be available to threads that reach them through the \nheader of the processor heap. Each superblock is associated with a descriptor. Each allocated block contains \na pre.x (8 bytes) that points to the descrip\u00adtor of its superblock. On the .rst call to malloc, the static \nstructures for the size classes and processor heaps (about 16 KB for a 16 processor machine) are allocated \nand initialized in a lock-free manner. Malloc starts by identifying the appropriate processor heap, based \non the requested block size and the identity of the calling thread. Typically, the heap already has an \nactive superblock with blocks available for reservation. The thread atomically reads a pointer to the \ndescriptor of the active su\u00adperblock and reserves a block. Next, the thread atomically // Superblock \ndescriptor structure typedef anchor : // fits in one atomic block unsigned avail:10,count:10,state:2,tag:42; \n// state codes ACTIVE=0 FULL=1 PARTIAL=2 EMPTY=3 typedef descriptor : anchor Anchor; descriptor* Next; \nvoid* sb; // pointer to superblock procheap* heap; // pointer to owner procheap unsigned sz; // block \nsize unsigned maxcount; // superblock size/sz // Processor heap structure typedef active : unsigned ptr:58,credits:6; \ntypedef procheap : active Active; // initially NULL descriptor* Partial; // initially NULL sizeclass* \nsc; // pointer to parent sizeclass // Size class structure typedef sizeclass : descList Partial; // initially \nempty unsigned sz; // block size unsigned sbsize; // superblock size Figure 3: Structures. pops a block \nfrom that superblock and updates its descrip\u00adtor. A typical free pushes the freed block into the list \nof available blocks of its original superblock by atomically up\u00addating its descriptor. We discuss the \nless frequent more complicated cases below when describing the algorithms in detail.  3.2 Structures \nand Algorithms For the most part, we provide detailed (C-like) code for the algorithms, as we believe \nthat it is essential for under\u00adstanding lock-free algorithms, unlike lock-based algorithms where sequential \ncomponents protected by locks can be de\u00adscribed clearly using high-level pseudocode. 3.2.1 Structures \nFigure 3 shows the details of the above mentioned struc\u00adtures. The Anchor .eld in the superblock descriptor \nstruc\u00adture contains sub.elds that can be updated together atom\u00adically using CAS or LL/SC. The sub.eld \navail holds the index of the .rst available block in the superblock, count holds the number of unreserved \nblocks in the superblock, state holds the state of the superblock, and tag is used to prevent the ABA \nproblem as discussed below. The Active .eld in the processor heap structure is primar\u00adily a pointer to \nthe descriptor of the active superblock owned by the processor heap. If the value of Active is not NULL,itis \nguaranteed that the active superblock has at least one block available for reservation. Since the addresses \nof superblock descriptors can be guaranteed to be aligned to some power of 2 (e.g., 64), as an optimization, \nwe can carve a credits sub.eld to hold the number of blocks available for reserva\u00adtion in the active \nsuperblock less one. That is, if the value of credits is n, then the active superblock contains n+1 blocks \navailable for reservation through the Active .eld. Note that the number of blocks in a superblock is \nnot lim\u00adited to the maximum reservations that can be held in the credits sub.eld. In a typical malloc \noperation (i.e., when Active NULL = and credits > 0), the thread reads Active and then atomically decrements \ncredits while validating that the active superblock is still valid. 3.2.2 Superblock States A superblock \ncan be in one of four states: ACTIVE, FULL, PARTIAL,or EMPTY. A superblock is ACTIVE if it is the active \nsuperblock in a heap, or if a thread intends to try to install it as such. A superblock is FULL if all \nits blocks are either allo\u00adcated or reserved. A superblock is PARTIAL if it is not ACTIVE and contains \nunreserved available blocks. A superblock is EMPTY if all its blocks are free and it is not ACTIVE.An \nEMPTY superblock is safe to be returned to the OS if desired.  3.2.3 Malloc Figure 4 shows the malloc \nalgorithm. The outline of the algorithm is as follows. If the block size is large, then the block is \nallocated directly from the OS and its pre.x is set to indicate the block s size. Otherwise, the appropriate \nheap is identi.ed using the requested block size and the id of the requesting thread. Then, the thread \ntries the following in order until it allocates a block: (1) Allocate a block from the heap s active \nsuperblock. (2) If no active superblock is found, try to allocate a block from a PARTIAL superblock. \n(3) If none are found, allocate a new superblock and try to install it as the active superblock. Malloc \nfrom Active Superblock The vast majority of malloc requests are satis.ed from the heap s active superblock \nas shown in the MallocFromActive routine in Figure 4. The routine consists of two main steps. The .rst \nstep (lines 1 6) involves reading a pointer to the ac\u00adtive superblock and then atomically decrementing \nthe num\u00adber of available credits thereby reserving a block while validating that the active superblock \nis still valid. Upon the success of CAS in line 6, the thread is guaranteed that a block in the active \nsuperblock is reserved for it. The second step of MallocFromActive (lines 7 18) is pri\u00admarily a lock-free \npop from a LIFO list [8]. The thread reads the index of the .rst block in the list from Anchor.avail \nin line 8, then it reads the index of the next block in line 10,1 and .nally in line 18 it tries to swing \nthe head pointer (i.e., Anchor.avail) atomically to the next block, while validat\u00ading that at that time \nwhat it thinks to be the .rst two indexes in the list (i.e., oldanchor.avail and next)are in\u00addeed the \n.rst two indexes in the list, and hence in e.ect popping the .rst available block from the list. Validating \nthat the CAS in line 18 succeeds only if Anchor.avail is equal to oldanchor.avail follows directly from \nthe semantics of CAS. However, validating that at that time *addr=next is more subtle and without the \ntag sub\u00ad.eld is susceptible to the ABA problem [8, 19]. Consider the case where in line 8 thread X reads \nthe value A from Anchor.avail and in line 10 reads the value B from *addr. After line 10, X is delayed \nand some other thread or threads pop (i.e., allocate) block A then block B and then push (i.e., free) \nsome block C and then block A back in the list. Later, X resumes and executes the CAS in line 18. Without \nthe tag sub.eld (for simplicity ignore the count sub.eld), the CAS would .nd Anchor equal to oldanchor \nand succeeds where 1This is correct even if there is no next block, because in such a case no subsequent \nmalloc will target this superblock before one of its blocks is freed. void* malloc(sz) { void* MallocFromPartial(heap) \n{// Use sz and thread id to find heap. retry: 1 heap = find heap(sz); 2 if (!heap) // Large block 3 Allocate \nblock from OS and return its address. 4 while(1) addr = {MallocFromActive(heap); 5 if (addr) return addr; \n6 addr = MallocFromPartial(heap); 7 if (addr) return addr; 8 addr = MallocFromNewSB(heap); 9 if (addr) \nreturn addr; } } void* MallocFromActive(heap) { do { // First step: reserve block 1 newactive = oldactive \n= heap->Active; 2 if (!oldactive) return NULL; 3 if (oldactive.credits == 0) 4 newactive = NULL; else \n5 newactive.credits--; 6 } until CAS(&#38;heap->Active,oldactive,newactive); // Second step: pop block \n7 desc = mask credits(oldactive); do { // state may be ACTIVE, PARTIAL or FULL 8 newanchor = oldanchor \n= desc->Anchor; 9 addr = desc->sb+oldanchor.avail*desc->sz; 10 next = *(unsigned*)addr; 11 newanchor.avail \n= next; 12 newanchor.tag++; 13 if (oldactive.credits == 0) { // state must be ACTIVE 14 if (oldanchor.count \n== 0) 15 newanchor.state = FULL; else {16 morecredits = min(oldanchor.count,MAXCREDITS); 17 newanchor.count \n-= morecredits; } }18 } until CAS(&#38;desc->Anchor,oldanchor,newanchor); 19 if (oldactive.credits==0 \n&#38;&#38; oldanchor.count>0) 20 UpdateActive(heap,desc,morecredits); 21 *addr = desc; return addr+EIGHTBYTES; \n} UpdateActive(heap,desc,morecredits) { 1 newactive = desc; 2 newactive.credits = morecredits-1; 3 if \nCAS(&#38;heap->Active,NULL,newactive) return; // Someone installed another active sb // Return credits \nto sb and make it partial do { 4 newanchor = oldanchor = desc->Anchor; 5 newanchor.count += morecredits; \n6 newanchor.state = PARTIAL; 7 } until CAS(&#38;desc->Anchor,oldanchor,newanchor); 8 HeapPutPartial(desc); \n } 1 desc = HeapGetPartial(heap); 2 if (!desc) return NULL; 3 desc->heap = heap; do { // reserve blocks \n4 newanchor = oldanchor = desc->Anchor; 5 if (oldanchor.state == EMPTY) { 6 DescRetire(desc); goto retry; \n}// oldanchor state must be PARTIAL // oldanchor count must be > 0 7 morecredits = min(oldanchor.count-1,MAXCREDITS); \n8 newanchor.count -= morecredits+1; 9 newanchor.state = (morecredits > 0) ? ACTIVE : FULL; 10 } until \nCAS(&#38;desc->Anchor,oldanchor,newanchor); do { // pop reserved block 11 newanchor = oldanchor = desc->Anchor; \n12 addr = desc->sb+oldanchor.avail*desc->sz; 13 newanchor.avail = *(unsigned*)addr; 14 newanchor.tag++; \n15 } until CAS(&#38;desc->Anchor,oldanchor,newanchor); 16 if (morecredits > 0) 17 UpdateActive(heap,desc,morecredits); \n18 *addr = desc; return addr+EIGHTBYTES; } descriptor* HeapGetPartial(heap) {do { 1 desc = heap->Partial; \n2 if (desc == NULL) 3 return ListGetPartial(heap->sc); 4 } until CAS(&#38;heap->Partial,desc,NULL); 5 \nreturn desc; } void* MallocFromNewSB(heap) { 1 desc = DescAlloc(); 2 desc->sb = AllocNewSB(heap->sc->sbsize); \n3 Organize blocks in a linked list starting with index 0. 4 desc->heap = heap; 5 desc->Anchor.avail = \n1; 6 desc->sz = heap->sc->sz; 7 desc->maxcount = heap->sc->sbsize/desc->sz; 8 newactive = desc; 9 newactive.credits \n= min(desc->maxcount-1,MAXCREDITS)-1; 10 desc->Anchor.count = (desc->maxcount-1)-(newactive.credits+1); \n11 desc->Anchor.state = ACTIVE; 12 memory fence. 13 if CAS((&#38;heap->Active,NULL,newactive) { 14 addr \n= desc->sb; 15 *addr = desc; return addr+EIGHTBYTES; } else { 16 Free the superblock desc->sb. 17 DescRetire(desc); \nreturn NULL; }} Figure 4: Malloc. Active Active Active Active avail count state tag 0 1 2 3 4 5 6 7 \navail count state tag 0 1 2 3 4 5 6 7  avail count state tag 0 1 2 3 4 5 6 7 avail count state tag \n0 1 2 3 4 5 6 7  (a) (b) (c) (d) Figure 5: An example of a typical malloc and free from an active superblock. \nIn con.guration (a), the active superblock contains 5 available blocks organized in a linked list [5,3,6,7,1], \nfour of which are available for reservation as indicated by Active.credits=3. In the .rst step of malloc, \na block is reserved by decrementing Active.credits, resulting in con.guration (b). In the second step \nof malloc, block 5 is popped, resulting in con.guration (c). Free pushes the freed block (block 5) resulting \nin con.guration (d). it should not, as the new head of the free list would become Note that, after a \nthread .nds Active.credits>0 and af\u00adblock B which is actually not free. Without the tag sub-ter the success \nof the CAS in line 6 and before the thread .eld, X is unable to detect that the value of Anchor.avail \nproceeds to a successful CAS in line 18, it is possible that the changed from A to B and .nally back \nto A again (hence the active superblock might have become FULL if all available name ABA). To prevent \nthis problem for the Anchor .eld, blocks were reserved, PARTIAL,oreventhe ACTIVE superblock we use the \nclassic IBM tag mechanism [8]. We increment the of a di.erent processor heap (but must be the same size \ntag sub.eld (line 12) on every pop and validate it atomically class). However, it cannot be EMPTY. These \npossibilities do with the other sub.elds of Anchor. Therefore, in the above not matter to the original \nthread. After the success of the mentioned scenario, when the tag is used, the CAS fails CAS in line \n6, the thread is guaranteed a block from this as it should and X starts over from line 8. The tag must \nspeci.c superblock, and all it need do is pop a block from have enough bits to make full wraparound practically \nimpos-the superblock and leave the superblock s Anchor.state un\u00adsible in a short time. For an absolute \nsolution for the ABA changed. Figure 5 shows a typical malloc and free from an problem, an e.cient implementation \nof ideal LL/SC which active superblock. inherently prevents the ABA problem using pointer-sized CAS can \nbe used [18, 19]. Updating Active Credits In lines 13 17, the thread checks if it has taken the last \nTypically, when the routine UpdateActive in Figure 4 credit in Active.credit. If so, it checks if the \nsuperblock is called, it ends with the success of the CAS operation has more available blocks, either \nbecause maxcount is larger in line 3 that reinstalls desc->sb as the active superblock than MAXCREDITS \nor because blocks were freed. If more blocks for heap with oneormorecredits. However, itispossible are \navailable, the thread reserves as many as possible (lines that after the current thread had set heap->Active \nto NULL 16 and 17). Otherwise, it declares the superblock FULL (line (line 6 of MallocFromActive), some \nother thread installed a 15). The reason for doing that is that FULL superblocks new superblock. If so, \nthe current thread must return the are not pointed to by any allocator structures, so the .rst credits, \nindicate that the superblock is PARTIAL,and make thread to free a block back to a FULL superblock needs \nto the superblock available for future use in line 8 by calling know that, in order to take responsibility \nfor linking it back HeapPutPartial (described below). to the allocator structures. If the thread has \ntaken credits, it tries to update Active Malloc from Partial Superblock by executing UpdateActive. There \nis no risk of more than The thread calls MallocFromPartial in Figure 4 if it .nds one thread trying to \ntake credits from the same superblock Active=NULL. The thread tries to get a PARTIAL superblock at the \nsame time. Only the thread that sets Active to NULL by calling HeapGetPartial. If it succeeds, it tries \nto re\u00adin line 6 can do that. Other concurrent threads .nd Active serve as many blocks including one for \nitself from the either with credits>0 or not pointing to desc at all. superblock s descriptor. Upon the \nsuccess of CAS in line Finally the thread stores desc (i.e., the address of the 10, the thread is guaranteed \nto have reserved one or more descriptor of the superblock from which the block was allo-blocks. It then \nproceeds in lines 11 15 to pop its reserved cated) into the pre.x of the newly allocated block (line \n21), block, and if it has reserved more, it deposits the additional so that when the block is subsequently \nfreed, free can de-credits in Active by calling UpdateActive. termine from which superblock it was originally \nallocated. In HeapGetPartial, the thread .rst tries to pop a su-Each block includes an 8 byte pre.x (overhead). \nperblock from the Partial slot associated with the thread s processor heap. If Partial=NULL, then the \nthread checks the Partial list associated with the size class as described in Section 3.2.6. Malloc from \nNew Superblock If thethreaddoesnot .ndany PARTIAL superblocks, it calls MallocFromNewSB in Figure 4. \nThe thread allocates a descriptor by calling DescAlloc (line 1), allocates a new superblock, and sets \nits .elds appropriately (lines 2 11). Fi\u00adnally, it tries to install it as the active superblock in Active \nusing CAS in line 13. If the CAS fails, the thread deallocates the superblock and retires the descriptor \n(or alternatively, the thread can take the block, return the credits to the su\u00adperblock, and install \nthe superblock as PARTIAL). The failure of CAS in line 13 implies that heap->Active is no longer NULL, \nand therefore a new active superblock must have been installed by another thread. In order to avoid having \ntoo many PARTIAL superblocks and hence cause unnecessary ex\u00adternal fragmentation, we prefer to deallocate \nthe superblock rather than take a block from it and keep it as PARTIAL. On systems with memory consistency \nmodels [1] weaker than sequential consistency, where the processors might ex\u00adecute and observe memory \naccesses out of order, fence in\u00adstructions are needed to enforce the ordering of memory ac\u00adcesses. The \nmemory fence instruction in line 12 serves to ensure that the new values of the descriptor .elds are \nob\u00adserved by other processors before the CAS in line 13 can be observed. Otherwise, if the CAS succeeds, \nthen threads running on other processors may read stale values from the descriptor.2  3.2.4 Free Figure \n6 shows the free algorithm. Large blocks are returned directly to the OS. The free algorithm for small \nblocks is simple. It primarily involves pushing the freed block into its superblock s available list \nand adjusting the superblock s state appropriately. The instruction fence in line 14 is needed to ensure \nthat the read in line 13 is executed before the success of the CAS in line 18. The memory fence in line \n17 is needed to ensure that the write in line 8 is observed by other processors no later than the CAS \nin line 18 is observed. If a thread is the .rst to return a block to a FULL su\u00adperblock, then it takes \nresponsibility for making it PARTIAL by calling HeapPutParial, where it atomically swaps the su\u00adperblock \nwith the prior value in the Partial slot of the heap that last owned the superblock. If the previous \nvalue of heap->Partial is not NULL, i.e., it held a partial superblock, then the thread puts that superblock \nin the partial list of the size class as described in Section 3.2.6. If a thread frees the last allocated \nblock in a superblock, then it takes responsibility for indicating that the superblock is EMPTY and frees \nit. The thread then tries to retire the associated descriptor. If the descriptor is in the Partial slot \nof a processor heap, a simple CAS will su.ce to remove it. Otherwise, the descriptor may be in the Partial \nlist of the size class (possibly in the middle). We discuss this case in Section 3.2.6. 2Due to the variety \nin memory consistency models and fence instructions among architectures, it is customary for concur\u00adrent \nalgorithms presented in the literature to ignore them. In this paper, we opt to include fence instructions \nin the code, but for clarity we assume a typical PowerPC-like archi\u00adtecture. However, di.erent architectures \nincluding future ones may use di.erent consistency models. free(ptr) { 1 if (!ptr) return; 2 ((void**)ptr)--; \n// get prefix 3 desc = *(descriptor**)ptr; 4 if (large block bit set(desc)) // Large block -desc holds \nsz+1 5 { Return block to OS. return; }6 sb = desc->sb; do {7 newanchor = oldanchor = desc->Anchor; 8 \n*(unsigned*)ptr = oldanchor.avail; 9 newanchor.avail = (ptr-sb)/desc->sz; 10 if (oldanchor.state == FULL) \n11 newanchor.state = PARTIAL; 12 if (oldanchor.count==desc->maxcount-1) {13 heap = desc->heap; 14 instruction \nfence. 15 newanchor.state = EMPTY; } else 16 newanchor.count++; 17 memory fence. 18 } until CAS(&#38;desc->Anchor,oldanchor,newanchor); \n19 if (newanchor.state == EMPTY) {20 Free the superblock sb. 21 RemoveEmptyDesc(heap,desc); 22 } elseif \n(oldanchor.state == FULL) 23 HeapPutPartial(desc); } HeapPutPartial(desc) { 1 do { prev = desc->heap->Partial; \n2 } until CAS(&#38;desc->heap->Partial,prev,desc); 3 if (prev) ListPutPartial(prev); } RemoveEmptyDesc(heap,desc) \n{1 if CAS(&#38;heap->Partial,desc,NULL) 2 DescRetire(desc); 3 else ListRemoveEmptyDesc(heap->sc); } Figure \n6: Free.  3.2.5 Descriptor List Figure 7 shows the DescAlloc and DescRetire routines. In DescAlloc, \nthe thread .rst tries to pop a descriptor from the list of available descriptors (lines 3 4). If not \nfound, the thread allocates a superblock of descriptors, takes one descriptor, and tries to install the \nrest in the global available descriptor list. In order to avoid unnecessarily allocating too many descriptors, \nif the thread .nds that some other thread has already made some descriptors available (i.e., the CAS \nin line 8 fails), then it returns the superblock to the OS and starts over in line 1, with the hope of \n.nding an available descriptor. DescRetire is a straightforward lock-free push that follows the classic \nfreelist push algorithm [8]. As mentioned above in the case of the pop operation in the MallocFromActive \nroutine, care must be taken that CAS does not succeed where it should not due to the ABA prob\u00adlem. We \nindicate this in line 4, by using the term SafeCAS (i.e., ABA-safe). We use the hazard pointer methodology \n[17, 19] which uses only pointer-sized instructions in order to prevent the ABA problem for this structure. \ndescriptor* DescAvail; // initially NULL descriptor* DescAlloc() { 1 while (1) {desc = DescAvail; 2 3 \nif (desc) {next = desc->Next; 4 if SafeCAS(&#38;DescAvail,desc,next) break; 5 } else desc {= AllocNewSB(DESCSBSIZE); \n6 Organize descriptors in a linked list. 7 memory fence. 8 if CAS(&#38;DescAvail,NULL,desc->Next)) break; \n9 Free the superblock desc. 10 }}return desc; } DescRetire(desc) { do {1 oldhead = DescAvail; 2 desc->Next \n= oldhead; 3 memory fence. 4 } until CAS(&#38;DescAvail,oldhead,desc); } Figure 7: Descriptor allocation. \nIn the current implementation, superblock descriptors are not reused as regular blocks and cannot be \nreturned to the OS. This is acceptable as descriptors constitute on average less than 1% of allocated \nmemory. However, if desired, space for descriptors can be reused arbitrarily or returned to the OS, by \norganizing descriptors in a similar manner to regular blocks and maintaining special descriptors for \nsuperblocks of descriptor, with virtually no e.ect on average performance whether contention-free or \nunder high contention. This can be applied on as many levels as desired, such that at most 1% of 1% and \nso on of allocated space is restricted from being reused arbitrarily or returned to the OS. Similarly, \nin order to reduce the frequency of calls to mmap and munmap, we allocate superblocks (e.g., 16 KB) in \nbatches of (e.g., 1 MB) hyperblocks (superblocks of superblocks) and maintain descriptors for such hyperblocks, \nallowing them eventually to be returned to the OS. We organize the de\u00adscriptor Anchor .eld in a slightly \ndi.erent manner, such that superblocks are not written until they are actually used, thus saving disk \nswap space for unused superblocks.  3.2.6 Lists of Partial Superblocks For managing the list of partial \nsuperblocks associated with each size class, we need to provide three functions: ListGetPartial, ListPutPartial,and \nListRemoveEmpty-Desc. The goal of the latter is to ensure that empty de\u00adscriptors are eventually made \navailable for reuse, and not necessarily to remove a speci.c empty descriptor immedi\u00adately. In one possible \nimplementation, the list is managed in a LIFO manner, with the possibility of removing descriptors from \nthe middle of the list. The simpler version in [19] of the lock-free linked list algorithm in [16] can \nbe used to manage such a list. ListPutPartial inserts desc at the head of the list. ListGetPartial pops \na descriptor from the head of the list. ListRemoveEmptyDesc traverses the list until it removes some \nempty descriptor or reaches the end of the list. Another implementation, which we prefer, manages the \nlist in a FIFO manner and thus reduces the chances of con\u00adtention and false sharing. ListPutPartial enqueues \ndesc at the tail of the list. ListGetPartial dequeues a descrip\u00adtor from the head of the list. ListRemoveEmptyDesc \nkeeps dequeuing descriptors from the head of the list until it de\u00adqueues a non-empty descriptor or reaches \nthe end of the list. If the function dequeues a non-empty descriptor, then it reenqueues the descriptor \nat the tail of the list. By re\u00admoving any one empty descriptor or moving two non-empty descriptor from \nthe head of the list to its end, we are guar\u00adanteed that no more than half the descriptors in the list \nare left empty. We use a version of the lock-free FIFO queue algorithm in [20] with optimized memory \nmanagement for the purposes of the new allocator. For preventing the ABA problem for pointer-sized vari\u00adables \nin the above mentioned list implementations, we can\u00adnotuse IBMABA-preventiontags(such as in Anchor.tag), \ninstead we use ideal LL/SC constructions using pointer-sized CAS [18]. Note that these constructions \nas described in [18] use memory allocation, however a general-purpose malloc is not needed. In our implementation \nwe allocate such blocks in a manner similar but simpler than allocating descriptors. Note that in our \nallocator, unlike Hoard [3], we do not maintain fullness classes or keep statistics about the full\u00adness \nof processor heaps and we are quicker to move partial superblocks to the partial list of the size class. \nThis simplic\u00adity allows lower latency and lower fragmentation. But, one concern may be that this makes \nit more likely for blocks to be freed to a superblock in the size class partial lists. How\u00adever, this \nis not a disadvantage at all, unlike Hoard [3] and also [5] where this can cause contention on the global \nheap s lock. In our allocator, freeing a block into such a superblock does not cause any contention with \noperations on other su\u00adperblocks, and in general is no more complex or less e.cient than freeing a block \ninto a superblock that is in the thread s own processor heap. Another possible concern is that by moving \npartial superblocks out of the processor heap too quickly, contention and false sharing may arise. This \nis why we use a most-recently-used Partial slot (multiple slots can be used if desired) in the processor \nheap structure, and use a FIFO structure for the size class partial lists.  4. EXPERIMENTAL RESULTS \nIn this section, we describe our experimental performance results on two PowerPC multiprocessor systems. \nThe .rst system has sixteen 375 MHz POWER3-II processors, with 24 GB of memory, 4 MB second level caches. \nThe second sys\u00adtem has eight 1.2 GHz POWER4+ processors, with 16 GB of memory, 32 MB third level caches. \nBoth systems run AIX 5.1. We ran experiments on both systems. The results on the POWER3 system (with \nmore processors) provided more insights into the allocators scalability and ability to avoid false sharing \nand contention. The results on the POWER4 system provided insights into the contention-free latency of \nthe allocators and contention-free synchronization costs on recent processor architectures. We compare \nour allocator with the default AIX libc mal\u00adloc,3 Hoard [3] version 3.0.2 (December 2003), and Ptmal\u00ad \n3 Our observations on the default libc malloc are based on external experimentation only and are not \nbased on any knowledge of its internal design. 375 MHz POWER3-II 1.2 GHz POWER4+ New Hoard Ptmalloc New \nHoard Ptmalloc Linux scalability 2.25 1.11 1.83 2.75 1.38 1.92 Threadtest 2.18 1.20 1.94 2.35 1.23 1.97 \nLarson 2.90 2.22 2.53 2.95 2.37 2.67 Table 1: Contention-free speedup over libc malloc. loc2 (Nov. 2002) \n[6]. All allocators and benchmarks were compiled using gcc and g++ with the highest optimization level \n(-O6) in 64-bit mode. We used pthreads for multi\u00adthreading. All allocators were dynamically linked as \nshared libraries. For meaningful comparison, we tried to use opti\u00admal versions of Hoard and Ptmalloc \nas best we could. We modi.ed the PowerPC lightweight locking routines in Hoard by removing a sync instruction \nfrom the beginning of the lock acquisition path, replacing the sync at the end of lock acquisition with \nisync, and adding eieio beforelockre\u00adlease. These changes reduced the average contention-free latency \nof a pair of malloc and free using Hoard from 1.76 \u00b5s. to 1.51 \u00b5s. on POWER3, and from 885 ns. to 560 \nns. on POWER4. The default distribution of Ptmalloc2 uses pthread mutex for locking. We replaced calls \nto pthread mutex by calls to a lightweight mutex that we coded us\u00ading inline assembly. This reduced the \naverage contention\u00adfree latency of a pair of malloc and free using Ptmalloc by more than 50%, from 1.93 \n\u00b5s. to 923 ns. on POWER3 and from 812 ns. to 404 ns. on POWER4. In addition, Ptmalloc showed substantially \nbetter scalability using the lightweight locks than it did using pthread mutex locks. 4.1 Benchmarks \nDue to the lack of standard benchmarks for multithreaded dynamic memory allocation, we use microbenchmarks \nthat focus on speci.c performance characteristics. We use six benchmarks: benchmark 1 of Linux Scalability \n[15], Thread\u00adtest, Active-false,and Passive-false from Hoard [3], Lar\u00adson [13], and a lock-free producer-consumer \nbenchmark that we describe below. In Linux scalability, each thread performs 10 million mal\u00adloc/free \npairs of 8 byte blocks in a tight loop. In Threadtest, each thread performs 100 iterations of allocating \n100,000 8-byte blocks and then freeing them in order. These two benchmarks capture allocator latency \nand scalability under regular private allocation patterns. In Active-false, each thread performs 10,000 \nmalloc/free pairs (of 8 byte blocks) and each time it writes 1,000 times to each byte of the allocated \nblock. Passive-false is simi\u00adlar to Active-false, except that initially one thread allocates blocks and \nhands them to the other threads, which free them immediately and then proceed as in Active-false.These \ntwo benchmarks capture the allocator s ability to avoid causing false sharing [22] whether actively or \npassively. In Larson, initially one thread allocates and frees ran\u00addom sized blocks (16 to 80 bytes) \nin random order, then an equal number of blocks (1024) is handed over to each of the remaining threads. \nIn the parallel phase which lasts 30 sec\u00adonds, each thread randomly selects a block and frees it, then \nallocates a new random-sized block in its place. The bench\u00admark measures how many free/malloc pairs are \nperformed during the parallel phase. Larson captures the robustness of malloc s latency and scalability \nunder irregular allocation patterns with respect to block-size and order of deallocation over a long \nperiod of time. In the lock-free Producer-consumer benchmark, we mea\u00adsure the number of tasks performed \nby t threads in 30 sec\u00adonds. Initially, a database of 1 million items is initialized randomly. One thread \nis the producer and the others, if any, are consumers. For each task, the producer selects a random-sized \n(10 to 20) random set of array indexes, allo\u00adcates a block of matching size (40 to 80 bytes) to record \nthe array indexes, then allocates a .xed size task structure (32 bytes) and a .xed size queue node (16 \nbytes), and en\u00adqueues the task in a lock-free FIFO queue [19, 20]. A con\u00adsumer thread repeatedly dequeues \na task, creates histograms from the database for the indexes in the task, and then spends time proportional \nto a parameter work performing local work similar to the work in Hoard s Threadtest bench\u00admark. When \nthe number of tasks in the queue exceeds 1000, the producer helps the consumers by dequeuing a task from \nthe queue and processing it. Each task involves 3 malloc op\u00aderations on the part of the producer, and \none malloc and 4 free operations on the part of the consumer. The consumer spends substantially more \ntime on each task that the pro\u00adducer. Producer-consumer captures malloc s robustness un\u00adder the producer-consumer \nsharing pattern, where threads free blocks allocated by other threads. 4.2 Results 4.2.1 Latency Table \n1 presents contention-free4 speedups over libc mal\u00adloc for the new allocator, Hoard, and Ptmalloc, for \nthe benchmarks that are a.ected by malloc latency: Linux scal\u00adability, Threadtest,and Larson. Malloc \ns latency had little or no e.ect on the performance of Active-false, Passive-false, and Producer-consumer. \nThe new allocator achieves signi.cantly lower contention\u00adfree latency than the other allocators under \nboth regular and irregular allocation patterns. The reason is that it has a faster execution path in \nthe common case. Also, unlike lock-based allocators, it operates only on the actual allo\u00adcator variables \nwithout the need to operate on additional lock related variables and to synchronize these accesses with \nthe accesses to the allocator variables through fence instruc\u00adtions. The new allocator requires only \none memory fence instruc\u00adtion (line 17 of free) in the common case for each pair of malloc and free, \nwhile every lock acquisition and release re\u00adquires an instruction fence before the critical section to \npre\u00ad 4It appears that libc malloc as well as Hoard use a tech\u00adnique where the parent thread bypasses \nsynchronization if it knows that it has not spawned any threads yet. We ap\u00adplied the same technique to \nour allocator and the average single-thread latency for our allocator was lower than those for libc malloc \nand Hoard. However, in order to measure true contention-free latency under multithreading, in our experiments, \nthe parent thread creates an additional thread at initialization time which does nothing and exits immedi\u00adately \nbefore starting time measurement. vent reads inside the critical section from reading stale data before \nlock acquisition, and a memory fence after the end of the critical section to ensure that the lock is \nnot observed to be free before the writes inside the critical sections are also observed by other processors. \nIn the common case, a pair of malloc and free using Ptmalloc and Hoard need to acquire and release two \nand three locks, respectively. Interestingly, when we conducted experiments with a lightweight test-and-set \nmutual exclusion lock on the POWER4 system, we found that the average contention\u00adfree latency for a pair \nof lock acquire and release is 165 ns. On the other hand. the average contention-free latency for a pair \nof malloc and free in Linux Scalability using our allo\u00adcator is 282 ns., i.e., it is less than twice \nthat of a minimal critical section protected by a lightweight test-and-set lock. That is, on that architecture, \nit is highly unlikely if not impossible for a lock-based allocator (without per-thread private heaps) \nto have lower latency than our lock-free allo\u00adcator, even if it uses the fastest lightweight lock to \nprotect malloc and free and does nothing in these critical sections.  4.2.2 Scalability and Avoiding \nFalse Sharing Figure 8(a) shows speedup results relative to contention\u00adfree libc malloc for Linux scalability. \nOur allocator, Ptmal\u00adloc, and Hoard scale well with varying slopes proportional to their contention-free \nlatency. Libc malloc does not scale at all, its speedup drops to 0.4 on two processors and contin\u00adues \nto decline with more processors. On 16 processors the execution time of libc malloc is 331 times as much \nas that of our allocator. The results for Threadtest (Figure 8(b)) show that our allocator and Hoard \nscale in proportion to their contention\u00adfree latencies. Ptmalloc scales but at a lower rate under high \ncontention, as it becomes more likely that threads take over the arenas of other threads when their own \narenas have no free blocks available, which increases the chances of con\u00adtention and false sharing. Figures \n8(c d) show the results for Active-false and Passive-false. The latency of malloc itself plays little \nrole in these results. The results re.ect only the e.ect of the allocation policy on inducing or avoiding \nfalse sharing. Our allocator and Hoard are less likely to induce false sharing than Ptmalloc and libc \nmalloc. In Larson (Figure 8(e)), which is intended to simulate server workloads, our allocator and Hoard \nscale, while Pt\u00admalloc does not, probably due to frequent switching of threads between arenas, and consequently \nmore frequent cases of freeing blocks to arenas locked by other threads. We also noticed, when running \nthis benchmark, that Ptmalloc creates more arenas than the number of threads, e.g., 22 arenas for 16 \nthreads, indicating frequent switching among arenas by threads. Even though freeing blocks to remote \nheaps in Hoard can degrade performance, this e.ect is elim\u00adinated after a short time. Initially threads \nfree blocks that were allocated by another thread, but then in the steady state they free blocks that \nthey have allocated from their own processor heaps.  4.2.3 Robustness under Producer-Consumer For Producer-consumer \nwe ran experiments with various values for work (parameter for local work per task). Fig\u00adures 8(f h) \nshow the results for work set to 500, 750, and 1000, respectively. The results for all the allocators \nare vir\u00adtually identical under no contention, thus the latency of the allocator plays a negligible role \nin the results for this bench\u00admark. The purpose of this benchmark is to show the robust\u00adness of the allocators \nunder the producer-consumer sharing pattern when the benchmark is scalable. The case where the benchmark \ncannot scale even using a perfect allocator is not of interest. We focus on the knee of the curve, where \nthe di.erences in robustness between allocators impact the scalability of the benchmark. Our allocator \nscales perfectly with work set to 1000 and 750, and up to 13 processors with work set to 500. With more \nthan 13 processors (and with work set to 500), we found that the producer could not keep up with the \ncon\u00adsumers (as the queue was always empty at the end of each experiment), which is not an interesting \ncase as the appli\u00adcation would not be scalable in any case. Our allocator s scalability is limited only \nby the scalability of the applica\u00adtion. Ptmalloc scales to a lesser degree, but at the cost of higher \nexternal memory fragmaentation, as the producer keeps creating and switching arenas due to contention \nwith consumers, even though most arenas already have available blocks. Hoard s scalability su.ers due \nto high contention on the producer s heap, as 75% of all malloc and free operations are targeted at the \nsame heap. Our allocator s performance does not su.er, although it faces exactly the same situation. \nThe main reason is that in Hoard, even in the common case, free operations need to acquire either the \nprocessor heap s lock or the global heap s lock. In our allocator typical free oper\u00adations are very simple \nand operate only on the superblock descriptor associated with the freed block, thus allowing sub\u00adstantially \nmore concurrency than Hoard. Other minor rea\u00adsons for our allocator s ability to perform well even under \ncontention on the same superblock are: (a) In our alloca\u00adtor, read-modify-write code segments are shorter \nin dura\u00adtion, compared with critical sections in Hoard. (b) Success\u00adful lock-free operations can overlap \nin time, while mutual exclusion locks by de.nition must strictly serialize critical sections. 4.2.4 \nOptimization for Uniprocessors With uniprocessors in mind, we modi.ed a version of our allocator such \nthat threads use only one heap, and thus when executing malloc, threads do not need to know their id. \nThis optimization achieved 15% increase in contention\u00adfree speedup on Linux scalability on POWER3. When \nwe used multiple threads on the same processor, performance remained una.ected, as our allocator is preemption-tolerant. \nIn practice, the allocator can determine the number of pro\u00adcessors in the system at initialization time \nby querying the system environment. 4.2.5 Space Efficiency We tracked the maximum space used by our \nallocator, Hoard, and Ptmalloc when running the benchmarks that allocate a large number of blocks: Threadtest, \nLarson,and Producer-consumer. The maximum space used by our allo\u00adcator was consistently slightly less \nthan that used by Hoard, as in our allocator each processor heap holds at most two su\u00adperblocks, while \nin Hoard each processor heap holds a vari\u00adable number of superblocks proportional to allocated blocks. \nThe maximum space allocated by Ptmalloc was consistently more than that allocated by Hoard and our allocator. \nThe ratio of the maximum space allocated by Ptmalloc to the maximum space allocated by ours, on 16 processors, \nranged from 1.16 in Threadtest to 3.83 in Larson. Speedup over contention-free libc malloc Speedup over \ncontention-free libc malloc 35 30 25 20 15 10 5 45 40 35 30 25 20 15 10 5  1 2 3 4 5 6 7 8 9 10 11 \n12 13 14 15 16 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Processors Processors (a) Linux scalability (e) \nLarson Speedup over contention-free libc malloc Speedup over contention-free libc malloc 30 25 20 15 \n10 5 18 16 14 12 10 8 6 4 2  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \n15 16 Processors Processors (b) Threadtest (f) Producer-consumer with work = 500 Speedup over contention-free \nlibc malloc Speedup over contention-free libc malloc 18 16 14 12 10 8 6 4 2 18 16 14 12 10 8 6 4 2 \n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Processors Processors \n(c) Active false sharing (g) Producer-consumer with work = 750 Speedup over contention-free libc malloc \nSpeedup over contention-free libc malloc 18 16 14 12 10 8 6 4 2 18 16 14 12 10 8 6 4 2  1 2 3 4 5 \n6 7 8 910111213141516 1 2 3 4 5 6 7 8 910111213141516 Processors Processors (d) Passive false sharing \n(h) Producer-consumer with work = 1000 Figure 8: Speedup results on 16-way 375 MHz POWER3.  5. SUMMARY \nIn this paper we presented a completely lock-free dynamic memory allocator. Being completely lock-free, \nour allocator is immune to deadlock regardless of scheduling policies and even when threads may be killed \narbitrarily. Therefore, it can o.er async-signal-safety, tolerance to priority inversion, kill-tolerance, \nand preemption-tolerance, without requiring any special kernel support or incurring performance over\u00adhead. \nOur allocator is portable across software and hard\u00adware platforms, as it requires only widely-available \nOS sup\u00adport and hardware atomic primitives. It is general-purpose and does not impose any unreasonable \nrestrictions regard\u00ading the use or initialization of the address space. It is space e.cient and limits \nspace blowup [3] to a constant factor. Our experimental results compared our allocator with the default \nAIX 5.1 libc malloc, and two of the best multithread allocators, Hoard [3] and Ptmalloc [6]. Our allocator \noutper\u00adformed the other allocators in all cases, often by signi.cant margins, under various levels of \nparallelism and allocation patterns. Our allocator showed near perfect scalability un\u00adder various allocation \nand sharing patterns. Under maxi\u00admum contention on 16 processors, it achieved a speedup of 331 over libc \nmalloc. Equally signi.cant, our allocator o.ers substantially lower latency than the other allocators. \nUnder no contention, it achieved speedups of 2.75, 1.99, and 1.43 over libc malloc, and highly-optimized \nversions of Hoard and Ptmalloc, re\u00adspectively. Scalable allocators are often criticized that they achieve \ntheir scalability at the cost of higher latency in the more common case of no contention. Our allocator \nachieves both scalability and low latency, in addition to many other performance and qualitative advantages. \nFurthermore, this work, in combination with recent lock\u00adfree methods for safe memory reclamation [17, \n19] and ABA prevention [18] that use only single-word CAS, allows lock\u00adfree algorithms including e.cient \nalgorithms for important object types such as LIFO stacks [8], FIFO queues [20], and linked lists and \nhash tables [16, 21] to be both com\u00adpletely dynamic and completely lock-free, including in 64-bit applications \nand on systems without support for automatic garbage collection, all e.ciently without requiring special \nOS support and using only widely-available 64-bit atomic instructions. Acknowledgments The author thanks \nEmery Berger, Michael Scott, Ye.m Shuf, and the anonymous referees for valuable comments on the paper. \n 6. REFERENCES [1] Sarita V. Adve and Kourosh Gharachorloo. Shared memory consistency models: A tutorial. \nIEEE Com\u00adputer, 29(12):66 76, 1996. [2] Emery D. Berger. Memory Management for High-Performance Applications. \nPhD thesis, University of Texas at Austin, August 2002. [3] Emery D. Berger, Kathryn S. McKinley, Robert \nD. Blu\u00admofe, and Paul R. Wilson. Hoard: A scalable memory allocator for multithreaded applications. In \nProceed\u00adings of the 9th International Conference on Architec\u00adtural Support for Programming Languages \nand Operat\u00ading Systems, pages 117 128, November 2000. [4] Bruce M. Bigler, Stephen J. Allan, and Rodney \nR. Old\u00adehoeft. Parallel dynamic storage allocation. In Proceed\u00adings of the 1985 International Conference \non Parallel Processing, pages 272 275, August 1985. [5] Dave Dice and Alex Garthwaite. Mostly lock-free \nmal\u00adloc. In Proceedings of the 2002 International Sympo\u00adsium on Memory Management, pages 269 280, June \n2002. [6] Wolfram Gloger. Dynamic Memory Allocator Imple\u00admentations in Linux System Libraries. http://www.dent.med.uni-muenchen.de/~wmglo/. \n[7] Maurice P. Herlihy. Wait-free synchronization. ACM Transactions on Programming Languages and Systems, \n13(1):124 149, January 1991. [8] IBM. IBM System/370 Extended Architecture, Princi\u00adples of Operation, \n1983. Publication No. SA22-7085. [9] IEEE. IEEE Std 1003.1, 2003 Edition, 2003. [10] Arun K. Iyengar. \nDynamic Storage Allocation on a Mul\u00adtiprocessor.PhD thesis,MIT,1992. [11] Arun K. Iyengar. Parallel dynamic \nstorage allocation algorithms. In Proceedings of the Fifth IEEE Sympo\u00adsium on Parallel and Distributed \nProcessing, pages 82 91, December 1993. [12] Leslie Lamport. Concurrent reading and writing. Com\u00admunications \nof the ACM, 20(11):806 811, November 1977. [13] Per-\u00b0Ake Larson and Murali Krishnan. Memory alloca\u00adtion \nfor long-running server applications. In Proceedings of the 1998 International Symposium on Memory Man\u00adagement, \npages 176 185, October 1998. [14] Doug Lea. A Memory Allocator. http://gee.cs.oswego.edu/dl/html/malloc.html. \n[15] Chuck Lever and David Boreham. Malloc() perfor\u00admance in a multithreaded Linux environment. In Pro\u00adceedings \nof the FREENIX Track of the 2000 USENIX Annual Technical Conference, June 2000. [16] Maged M. Michael. \nHigh performance dynamic lock\u00adfree hash tables and list-based sets. In Proceedings of the Fourteenth \nAnnual ACM Symposium on Parallel Al\u00adgorithms and Architectures, pages 73 82, August 2002. [17] Maged \nM. Michael. Safe memory reclamation for dy\u00adnamic lock-free objects using atomic reads and writes. In \nProceedings of the Twenty-First Annual ACM Sym\u00adposium on Principles of Distributed Computing, pages 21 \n30, July 2002. [18] Maged M. Michael. ABA prevention using single\u00adword instructions. Technical Report \nRC 23089, IBM T. J. Watson Research Center, January 2004. [19] Maged M. Michael. Hazard pointers: Safe \nmemory reclamation for lock-free objects. IEEE Transactions on Parallel and Distributed Systems, 2004. \nTo appear. See www.research.ibm.com/people/m/michael/pubs.htm. [20] Maged M. Michael and Michael L. Scott. \nSimple, fast, and practical non-blocking and blocking concurrent queue algorithms. In Proceedings of \nthe Fifteenth An\u00adnual ACM Symposium on Principles of Distributed Computing, pages 267 275, May 1996. \n[21] Ori Shalev and Nir Shavit. Split-ordered lists: Lock-free extensible hash tables. In Proceedings \nof the Twenty-Second Annual ACM Symposium on Principles of Dis\u00adtributed Computing, pages 102 111, July \n2003. [22] Josep Torrellas, Monica S. Lam, and John L. Hennessy. False sharing and spatial locality in \nmultiprocessor caches. IEEE Transactions on Computers, 43(6):651 663, June 1994. [23] Paul R. Wilson, \nMark S. Johnstone, Michael Neely, and David Boles. Dynamic storage allocation: A sur\u00advey and critical \nreview. In Proceedings of the 1995 In\u00adternational Workshop on Memory Management,pages 1 116, September \n1995. \n\t\t\t", "proc_id": "996841", "abstract": "Dynamic memory allocators (malloc/free) rely on mutual exclusion locks for protecting the consistency of their shared data structures under multithreading. The use of locking has many disadvantages with respect to performance, availability, robustness, and programming flexibility. A lock-free memory allocator guarantees progress regardless of whether some threads are delayed or even killed and regardless of scheduling policies. This paper presents a completely lock-free memory allocator. It uses only widely-available operating system support and hardware atomic instructions. It offers guaranteed availability even under arbitrary thread termination and crash-failure, and it is immune to deadlock regardless of scheduling policies, and hence it can be used even in interrupt handlers and real-time applications without requiring special scheduler support. Also, by leveraging some high-level structures from Hoard, our allocator is highly scalable, limits space blowup to a constant factor, and is capable of avoiding false sharing. In addition, our allocator allows finer concurrency and much lower latency than Hoard. We use PowerPC shared memory multiprocessor systems to compare the performance of our allocator with the default AIX 5.1 libc malloc, and two widely-used multithread allocators, Hoard and Ptmalloc. Our allocator outperforms the other allocators in virtually all cases and often by substantial margins, under various levels of parallelism and allocation patterns. Furthermore, our allocator also offers the lowest contention-free latency among the allocators by significant margins.", "authors": [{"name": "Maged M. Michael", "author_profile_id": "81332515587", "affiliation": "IBM Thomas J. Watson Research Center, Yorktown Heights, NY", "person_id": "PP42049628", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996848", "year": "2004", "article_id": "996848", "conference": "PLDI", "title": "Scalable lock-free dynamic memory allocation", "url": "http://dl.acm.org/citation.cfm?id=996848"}