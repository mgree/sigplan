{"article_publication_date": "06-09-2004", "fulltext": "\n A Generalized Algorithm for Graph-Coloring Register Allocation Michael D. Smith, Norman Ramsey, and \nGlenn Holloway Division of Engineering and Applied Sciences Harvard University {smith, nr, holloway}@eecs.harvard.edu \nAbstract Graph-coloring register allocation is an elegant and extremely pop\u00adular optimization for modern \nmachines. But as currently formu\u00adlated, it does not handle two characteristics commonly found in commercial \narchitectures. First, a single register name may ap\u00adpear in multiple register classes, where a class \nis a set of register names that are interchangeable in a particular role. Second, mul\u00adtiple register \nnames may be aliases for a single hardware register. We present a generalization of graph-coloring register \nallocation that handles these problematic characteristics while preserving the elegance and practicality \nof traditional graph coloring. Our gen\u00aderalization adapts easily to a new target machine, requiring only \nthe sets of names in the register classes and a map of the regis\u00adter aliases. It also drops easily into \na well-known graph-coloring allocator, is ef.cient at compile time, and produces high-quality code. Categories \nand subject descriptors D.3.4 [Programming Languages]: Processors code generation, compilers, optimization, \nretargetable compilers; G.2.2 [Discrete Mathematics]: Graph Theory graph algorithms General terms Algorithms, \nLanguages Keywords Graph coloring, register allocation  1 Introduction The reduction of register allocation \nto a graph-coloring problem is elegant, effective, and practical. It is warmly endorsed by mod\u00adern textbooks \n[Muchnick 1997; Appel and Palsberg 2002; Cooper and Torczon 2003] and widely used in modern compilers. \nBut two assumptions at the heart of the algorithm are invalid for most com\u00admercial instruction sets: \nregisters are expected to be interchange\u00adable and independent. Registers are interchangeable if they \nare equally suitable in any program context. Registers are indepen\u00addent if writing to one cannot change \nthe value of another. Permission to make digital or hard copies of part or all of this work for personal \nor classroom use is granted without fee provided that copies bear this notice and the full citation on \nthe .rst page. To copy otherwise, to republish, to post on servers, or to redistribute to lists requires \nprior speci.c permission and/or a fee. PLDI'04, June 9 11, 2004, Washington, DC, USA. Copyright 2004 \nACM 1-58113-807-5/04/0006 . . . $5.00. This mismatch between the assumptions of the algorithm and realities \nof commercial architectures forces compiler writers to augment Chaitin s [1981] original formulation \neach time they implement it to handle the peculiarities of each target machine. In this paper, we generalize \nthe graph-coloring approach in a way that addresses this mismatch. Using our generalization, a com\u00adpiler \nwriter can create a register-allocation pass that is as elegant and practical as the original formulation \nwhile also being trivial to target to real machines. 1.1 The need Machines with completely interchangeable \nregisters are unusual. Even very regular architectures partition registers according to function. For \nexample, the Alpha architecture de.nes a set of reg\u00adisters for use in .oating-point calculations, and \nthese registers are not interchangeable with those used for operating on integers and addresses. In response, \ncompiler writers have developed the notion of reg\u00adister classes, where a class is a set of register names \nthat are in\u00adterchangeable in a particular role. When all of a target s register classes are disjoint, \nas they are in the Alpha architecture, a graph\u00adcoloring allocator can simply run a separate Chaitin-style \nalloca\u00adtion pass for each register class. But if a target has register classes that are not disjoint, \nor if optimizations force non-disjoint register classes, then in order to generate good code, a graph-coloring \nallo\u00adcator needs to allocate the register candidates of multiple classes simultaneously. (A register \ncandidate may be a source-language variable, a compiler-generated temporary, or a live range.) Non-disjoint \nclasses occur in machines where source-language data types do not clearly de.ne the target s register \nclasses. For example, in the Motorola 68000 family and its Cold.re descen\u00addants, the instruction for \nadding 32-bit integer data accepts either an address register or a data register as its source operand. \nBut the instruction for multiplying integers only accepts data registers, not address registers, as operands. \nA similar irregularity occurs in the Itanium instruction set, which has add-immediate instructions that \ncan write only a few of the general-purpose registers. Non-disjoint classes can also be induced by optimizations \nper\u00adformed at compile time. For example, to translate a target\u00adindependent, memory-to-memory move, a \ncode generator for an Alpha needs at least one register candidate. If the only regis\u00adter classes in the \nAlpha are the disjoint integer and .oating-point classes, the code generator will be forced to label \nthe register can\u00addidate with one of those two classes. The compiler could pro\u00adduce better code, however, \nif it could postpone the decision of whether to use an integer or .oating-point register until it knew \nthe register pressure for each class at the point of the move. We can achieve this postponement by de.ning \na register class that is the union of the integer and .oating-point register classes and by having a \nregister allocator that simultaneously allocates mul\u00adtiple non-disjoint register classes. Such a register \nallocator could also take advantage of instructions in the Alpha architecture that move values directly \nbetween the integer and .oating-point regis\u00adter banks [Kessler, McLellan, and Webb 1998]. In particular, \nthe allocator might take advantage of these inter-bank move instruc\u00adtions to use registers outside a \ncandidate s class as fast spill space. Machines that violate the register-independence assumption are \nalso common. When an assignment to one architectural regis\u00adter name can affect the value of another, \nsuch register names are said to alias. A classic example is the combination of two single\u00adprecision .oating-point \nregisters to form one double-precision reg\u00adister [Briggs, Cooper, and Torczon 1992]. Early HP PA-RISC \nand Sun SPARC processors used this design. Some modern embed\u00added and recon.gurable architectures carry \nit further. The ARM VFP10 unit, for example, has a .oating-point register .le that can be organized as \n 32 single-precision registers,  16 double-precision registers,  8 scalar registers and 6 vectors of \n4 elements, or  8 scalar registers and 3 vectors of 8 elements.  The double-precision registers are \ntypically aligned with respect to the single-precision registers, which means that only a pair that starts \nat an even-numbered single-precision register aliases with a double-precision register. Architectures \nthat use unaligned pairing also exist. Of these, some allow for wrap around , where the last single-precision \nregister in the hardware register bank is paired with the .rst. For instance, the ARM VFP coprocessor \nimplements .oating-point pairs, quadruples and octuples, any of which may be unaligned and wrap around. \nAliasing is not limited to .oating-point registers. The Intel x86 family has byte-sized integer registers \nthat alias with 16-bit regis\u00adters, which in turn alias with 32-bit registers. In sum, interchangeability \nand independence are more the ex\u00adception than the rule. To be able to use graph-coloring regis\u00adter allocation \nanyway, compiler writers continually invent new workarounds. Michael Matz s [2003] retrospective on what \nit took to implement a graph-coloring register allocator for GCC is a poignant example of the ad-hoc \nnature of such workarounds. Matz states clearly that it was dif.cult to build a multi-target allocator \nbased on graph coloring because of machine features prevalent in the real world but not considered by \nthe traditional formulation. The fact that graph coloring has become popular despite the need for these \nworkarounds is a testament to its appeal. 1.2 Our solution This paper generalizes the graph-coloring \napproach to register allocation in a way that eliminates the need for the kinds of workarounds currently \nemployed for modern commercial architec\u00adtures. Our generalization permits simultaneous allocation of \nmul\u00adtiple register classes, even when registers alias, while maintaining the ef.ciency and general structure \nof the original graph-coloring formulation. We exploit the fact that compiler writers like to group a \nma\u00adchine s registers into potentially overlapping classes. We de\u00ad.ne a class simply as a set of register \nnames. Registers within a class must be interchangeable but need not be independent. Aliasing (nonindependence) \nis made explicit by a map alias(r), which takes each register name rto the set of register names with \nwhich it aliases. By de.nition, alias(r)includes r, and for nota\u00adtional convenience, we extend the alias \nmap to sets of registers: S alias(S)= r.S alias(r). The alias map and the grouping of register names \ninto classes are the only properties needed to target our allocator. The remainder of the paper is organized \nas follows: Section 2 presents a brief overview of traditional graph-coloring allocation and identi.es \nthe beautiful aspects of the original formulation that we would like to maintain in a new formulation. \nSection 3 explains how we generalize the graph-coloring heuristic, while Section 4 describes an ef.cient \nimplementation of that generalized heuris\u00adtic. Section 5 then presents the highlights of a retargetable \nallo\u00adcator that we built based on our generalization of a well-known graph-coloring allocator. Section \n6 reports on the practicality of our implementation.  2 Identifying the beauty A number of published \nalgorithms rely on the traditional formu\u00adlation of graph-coloring allocation, and we would like these \nalgo\u00adrithms to work seamlessly with our new generalization. To that end, our generalization preserves \nthree elegant aspects of the tra\u00additional formulation: an intuitive interpretation of the interference \ngraph, a simple criterion for computing when a node is trivially colorable, and incremental computation \nof that criterion as nodes enter and leave the interference graph. We put these aspects in context through \na brief review of how a traditional allocator sets up a graph-coloring problem and searches for a solution. \nThe primary task of a register allocator is to .nd the most impor\u00adtant register candidates and replace \nthem with registers. In general, a program contains more register candidates than the hardware has available \nregisters. To help identify register candidates that can share hardware registers, a graph-coloring allocator \nbuilds an in\u00adterference graph. To construct an interference graph, an allocator needs to know the register \nclass of each candidate and at what points in the pro\u00adgram each candidate is live (i.e., holds a value \nthat may be used before it is overwritten). The candidate s class is chosen by in\u00adtersecting the register-class \nrequirements of all operand locations occupied by the candidate [Briggs 1992]. The set of live points \nis obtained by running live-variable analysis [Muchnick 1997]. With this information, the construction \nof an interference graph is straightforward. Each node represents a register candidate. An edge connects \ntwo nodes if the register classes of the candidates represented by the nodes alias and at any point in \nthe program the candidates are simultaneously live. In other words, interference graph edges identify \nthose candidates that cannot be allocated to registers that alias. Here s where the coloring metaphor \ncomes in. If the interfer\u00adence graph contains nodes of only a single register class and that class contains \nkindependent and interchangeable registers, then .nding a k-coloring of the interference graph solves \nthe alloca\u00adtion problem. The color assigned to each candidate node maps uniquely to an available register, \nand nodes that are neighbors in the graph never receive the same assignment. Although k-coloring is NP-complete, \nChaitin developed a sim\u00adple approach that does well in practice for interference graphs con\u00adtaining nodes \nof a single register class [Chaitin et al. 1981; Chaitin 1982]. Chaitin s approach is based on the observation \nthat when node nhas fewer than kneighbors, i.e., degreen <k,itis triv\u00adially colorable. No matter how \ncolors are assigned to its neighbor nodes, there will be a distinct color left for n. Chaitin s heuristic \nrepeatedly simpli.es the graph by removing and stacking trivially colorable nodes. Each removal lowers \nthe degrees of neighbor nodes and may make additional nodes trivially colorable. If the process succeeds \nin stacking all of the nodes, then it is easy to as\u00adsign colors by popping one node at a time, restoring \nits edges to former neighbors already popped, and picking a color not already assigned to one of them. \nOf course, the graph-simpli.cation phase may block with no trivially colorable nodes to remove and stack. \nIn that case, Chaitin s method picks a node whose degree in the remaining graph is relatively high (so \nthat its removal liberates as many sub\u00adsequent nodes as possible) but whose spill cost is relatively \nlow (so that the run-time impact of this spill is low). It removes and stacks that node, and then continues \nwith the simpli.cation phase. This brute-force simpli.cation means that color assignment may later fail \nfor some of the forcibly removed nodes.1 In that case, the al\u00adlocator inserts spill code for the occurrences \nof the corresponding register candidates and starts over on the modi.ed program. This method can be implemented \nquite ef.ciently. The degree of each node is cached and updated incrementally. When the al\u00adlocator removes \na node from the graph, it sets the node s cached degree to zero and decrements the cached degrees of \nthe node s neighbors, but it leaves the edge representation in place for use later, when the node is \nreinstated in the graph and given a color. The color-assignment algorithm just ignores edges to neighbors \nwhose cached degree is zero. In summary, the traditional formulation of graph coloring regis\u00adter allocation \nis based upon an intuitive interpretation of the inter\u00adference graph, a beautifully simple criterion \nfor computing when a node is trivially colorable, and an incremental method for ef.\u00adciently computing \ncolorability even as nodes enter and leave the interference graph. Our goal is to provide an equally \nsimple crite\u00adrion for computing when a node is trivially colorable, even when registers are not completely \ninterchangeable or independent. In addition, our generalization of the colorability criterion should \nnot require changing the structure or interpretation of the inter\u00adference graph. Finally, this generalization \nof the criterion must be amenable to an ef.cient implementation and speci.cally one that supports incremental \ncomputation. 3 Generalizing the Colorability Criterion We now broaden the scope of the graph-coloring \nheuristic by de\u00adveloping and illustrating a drop-in replacement for the traditional colorability criterion. \nSection 3.1 begins with a new formulation of the colorability criterion that is easy to understand, is \nprecise for all architectures, but is expensive to compute. Sections 3.2 and 3.3 present a safe and practical \napproximation of this formu\u00adlation based on register classes. Section 3.4 presents an optimality property \nand shows that our approximation is exact for many com\u00admercial architectures. 3.1 Same heuristic, broader \nscope Our goals are to allocate register candidates from different register classes simultaneously and \nallow these classes to contain regis\u00adters that may alias. From Section 2, we know that two candidates \nn1 and n2 interfere if they are simultaneously live and if a color\u00ading of these nodes may lead to aliasing. \nThe possibility of aliasing may be stated formally as: alias(classn1 ) nclassn2 = \u00d8.classn1 nalias(classn2 \n) = \u00d8 As always, the neighbors of a node nin the interference graph combine to constrain that node s \ncolorability. But our view of col\u00adorability is complicated by two problems. Because there may not be \na resource limit k that all of the nodes have in common, it no longer makes sense to look for a k-coloring \nof the interference graph. And the impact of a neighbor on the colorability of nmay vary from neighbor \nto neighbor. Figure 1 presents a simple ar\u00adchitecture and example interference graph that illustrate \nthese two problems. 1On the other hand, sometimes a node that wasn t trivially colorable turns out to \nbe colorable [Briggs, Cooper, and Torczon 1994]. Architectural de.nition: F = {f0,f1,f2,f3} D = {d0,d1,d2} \nalias(f0) = {f0,d0} alias(d0) = {d0,d1,f0,f1} alias(f1) = {f1,d0,d1} alias(d1) = {d0,d1,d2,f1,f2} alias(f2) \n= {f2,d1,d2} alias(d2) = {d1,d2,f2,f3} alias(f3) = {f3,d2} . .. . d0 d2 . d1 . Example interference \ngraph:  Figure 1. An example architecture with two register classes, F and D. Class F contains four \nsingle-precision .oating-point registers, which alias with the three unaligned double-precision registers \nlisted in D. Because the register .le does not permit a double-precision register to wrap around the \nend, the two classes have different resource limits: four single-precision registers cre\u00adate only three \ndouble-precision ones. In the interference graph, node n3 is drawn as a larger circle because it places \na greater constraint on the colorability of n1 than does n2. On the other hand, there are still only \n.nitely many choices for a node n, namely the number of members in the class of n, that is, |classn|. \nTherefore, to produce a new criterion for trivial col\u00adorability, we must .nd a measure of the constraints \nimposed on n by n s neighbors, and this measure must be comparable with the number of choices |classn|. \nWe call this measure the squeeze. More precisely, squeeze n * is the maximum number of names from classn \nthat could be denied to n because of an assignment of registers to n s current neighbors. Node nis trivially \ncolorable provided squeeze * <|classn| (1) n This inequality has the same form as the traditional criterion. \nIf squeeze * can be computed ef.ciently, as is done for degreein nn the traditional graph-coloring implementation, \nthen we can use Equation 1 as a drop-in replacement for the traditional criterion. So how should squeeze \n* be de.ned? Imagine a game in which n we want to allocate a register for node n, and an adversary wants \nto stop us. The adversary gets to move .rst, by picking a coloring of the neighbors of n. This coloring \nassigns to each neighbor a single register chosen from that neighbor s register class. When it is our \nturn, we must choose for n a register that does not alias with any of the registers chosen by the adversary. \nThe adversary s best move is to consider all possible colorings and choose one that eliminates as many \nchoices for nas possible. In other words, if we write Sfor the set of registers in the coloring, the \nadversary should choose a coloring that maximizes |classn nalias(S)|. Therefore, the maximum number of \nnames from classn that could be denied to nbecause of an assignment of registers to n s neighbors is \nsqueeze * = max |classn nalias(S)| (2) n S.colorings of n s neighbors If this ideal number is at least \n|classn|, the adversary wins. But if squeeze * < |classn|, then node n is trivially colorable, and we \nn win. 3.2 Decomposition by class We obviously cannot afford to enumerate all colorings of n s neighbors \nevery time we need to determine if it is trivially col\u00adorable. We instead de.ne an approximation, squeezen, \nthat is fast, safe, and good. By fast, we mean that squeezen can be com\u00adputed quickly. By safe, we mean \nthat squeeze n * =squeezen always, so if squeeze< |classn|then squeeze * < |classn|, nn and node n is \ntrivially colorable. And by good, we mean that squeeze * =squeezefor a great many real architectures. \nIn this nn and the next subsection, we develop the key ideas behind our ap\u00adproximation squeezen. Section \n3.4 gives the complete de.nition of squeezen. The .rst key idea is to consider the impact of n s neighbors \nby class, rather than individually. To motivate this idea, let us consider the case in which all of n \ns neighbors have the same class C. Class C might be different from n s class, classn, which we write \nN. The worst-case number of elements of N that can be blocked by an adversary s coloring of some number \nm of n s neighbors is a constant that depends only on the properties of the target architecture. We call \nthis number the worst-case displace\u00adment of N by C using m nodes, worstm(N, C): worst m(N, C)= max |N \nnalias(S)| (3) S.C.|S|=m Worst-case displacement doesn t depend on the interference graph being colored, \nwhich means that we can precompute it for all pairs of classes N and C and for all values of m up to \n|C|. The precomputed values can be stored in a lookup table for use during compilation. For instance, \nfor the example classes in Fig\u00adure 1, worst1(F, D)=2 since one double-precision register consumes two \nsingle-precision ones, worst1(D, F)=2since one single-precision register can block two double-precision \nones, worst1(D, D)=3since register d1aliases with all of the other double-precision registers, and also \nworst2(D, D)=3since a coloring cannot consume more than the number of registers in n s class. The worst-case \ndisplacement of N by C is an integral compo\u00adnent of our approximation. Whenever node n has exactly m \nneigh\u00adbors, all of class C, worstm(N, C)=squeeze * . Since m is the n number of neighbors of class C, \nwe write it as degreen(C). When n has neighbors of more than one class, we estimate squeeze n * by summing \nworst-case displacements over a set of classes C: X degree(C) n Wn(C)= worst(N, C) (4) C.C If we sum \nover all classes Call , the sum Wn(Call ) is at least as great as squeeze n* , so it is a safe approximation. \nTo under\u00adstand why, think about the contradiction: if the ideal squeeze n * could be greater than Wn(Call \n), the contribution from at least one class of a coloring that achieves squeeze n * would have to degree(C) \nn exceed worst(N, C), contradicting the de.nition of worst. A formal proof of safety relies primarily \non the trian\u00adgle inequality |A .B|=|A|+|B|and on the interchange rule PP maxSC f(S, C)= C maxS f(S, C). \n 3.3 Saturation to avoid overcounting Although Wn(Call ) is safe, it is not always exact. For exam\u00adple, \nwhen two register classes use overlapping hardware resources, Wn(Call )may count the overlapping resources \ntwice. Figure 2 shows an example in which the overlapping resources are registers r0and r1. To improve \non Wn(Call ), we observe that the worst the adver\u00adsary can do with any group of neighbors is to use all \nthe registers in those neighbors classes. In Figure 2, the worst is bounded by Architectural de.nition: \nA ={r0,r1} B ={r0,r1,r2} C ={r0,r1,r2,r3} .r .A,B,C :alias(r)={r} C z }| { A z }| { | {z } B Example \ninterference graph: Figure 2. This example illustrates overcounting of registers. The machine has three \nregister classes A, B, and C. In the interference graph, n1 has one neighbor of class A and three of \nclass B. The sum Wn({A,B,C})counts 1for class A and 3for class B, for a total of 4, but the actual squeeze \nimposed by classes A and B together is only 3. Node n is saturated with respect to classes A and B. Node \nn is in fact trivially colorable. the number of registers in the set of classes {A,B}. But the idea applies \nto any set of classes: given a set of classes C, it follows from Equation 2 that the contribution to \nsqueeze * from neighbors n of those classes is bounded by the alias sets of those classes. We write this \nbound as bound (N, C), de.ned by [ bound(N, C)=|N n(alias(C))| (5) C.C For any C, if we consider terms \nin Wn(Call )that depend on C, we can replace the partial sum over those terms, Wn(C),by min(bound (N, \nC), Wn(C)), and we avoid overcounting the over\u00adlapping resources in C. To avoid more overcounting, we \ncan re\u00adorder and parenthesize partial sums in Wn(Call ), then cap each parenthesized partial sum by a \nbound described below. Section 3.4 explains how we structure this bounded sum to best approxi\u00admate squeeze \n* . Though there are many choices for ordering and n parenthesization, Section 3.4 shows that there is \nonly one sensible choice for any real machine. Thus, for the rest of this section, we focus on a fast \nmethod for evaluating the bounded sum. Our method for evaluating the bounded sum is motivated by the \nobservation that the parenthesized expression for Wn(Call )can be viewed as a tree. We refer to this \ntree as a class tree. Each pair of parentheses in the expression corresponds to a vertex in the tree. \nEach vertex v has a set of register classes, written classes(v). Each class in classes(v)corresponds \nto a term in Wn(Call )that is inside the parentheses for v but not in those of a child of v. The set \nof child vertices of v is written children(v). Every vertex except the root has a parent vertex, written \nparent(v). Parents correspond to immediately enclosing parentheses. Finally, each class C appears in \nexactly one term in Wn(Call )and thus in one vertex in the tree, which we write vertex (C). Recall that \nthis class tree is meant to help us avoid overestimat\u00ading the squeeze on candidate node n by its neighbors. \nIn the simple case, n becomes saturated with respect to a set of classes C when Wn(C)reaches bound(N, \nC).2 For any vertex v in the class tree, the bound we use is with respect to the set of classes in the \nsubtree rooted at v. We write this set v., formally de.ned as: [ ' v.=classes(v). v. (6) v'.children(v) \nAnd we call bound(N, v.)the saturation bound at vertex v. Given a class tree containing vertex (classn), \nwe can estimate the total squeeze on n as the bounded sum at the root R of this tree: squeezen =Z(n, \nR) (7) The bounded sum Z is computed using the following recursive function: Z(n, v)=min(bound(N, v.), \nraw Z(n, v)) X degree(C) n raw Z(n, v)= worst(N, C) (8) C.classes(v) X ' + Z(n, v) v'.children(v) Without \nmin and bound , Z(n, R) would be exactly equal to Wn(Call ). But Z(n, R)is a better estimate because \nit is .ltered: our estimate of the cumulative number of colors denied by the ad\u00adversary at the root of \nany subtree in n s class tree can never exceed the saturation bound at v. At each vertex v of the class \ntree, we cal\u00adculate rawZ(n, v), the raw squeeze on node n due to neighbors with classes in classes(v)or \nto the children of v. The word raw is a reminder that this variant of squeeze is not yet .ltered. Raw \nsqueeze is simply the total worst-case squeeze from n s neighbors whose classes are in classes(v) plus \nthe .ltered squeeze values ' Z(n, v)for each vertex v' in children(v). For each vertex, .l\u00adtering recognizes \nthat the adversary cannot consume more colors than possible by using all registers in classes in the \nsubtree rooted at that vertex. Safety. To show that Z(n, R)safely approximates squeeze n* ,we begin by \nde.ning Z * (n, v) to be the maximum amount the ad\u00adversary can squeeze node n by coloring neighbors of \nn whose classes are in v.. The ideal squeeze squeeze * is exactly equal n to Z * (n, R). Our approximation \nis safe because for any vertex v, Z * (n, v)=Z(n, v). We prove this fact by induction on the height of \nthe subtree rooted at v. The key lemma is that XX * degree(C)*' n Z (n, v)= worst(N, C)+ Z (n, v) C.classes(v) \nv'.children(v) This lemma is proved using the triangle inequality and interchange rule. 3.4 Alias relationships \nand the class tree To get the best possible approximation, we want a class tree that minimizes Z. Since \novercounting occurs when classes overlap, a key property of good class trees is that classes with aliases \nin com\u00admon appear under the same saturation bound. Under constraints that are satis.ed for all machines \nof which we are aware, we show how to construct class trees for which Zis as small as possible. Consider \nthe case in which two classes C1 and C2 alias exactly the same registers. We say such classes are alias-equivalent, \nwrit\u00adten C1 ~C2: C1 ~C2 . alias(C1)=alias(C2). (9) 2A node can even be saturated with respect to a set \nof classes without necessarily being saturated with respect to any of the individual classes in the set. \nIf C1 ~ C2, then sets {C1}, {C2}, and {C1 .C2}all provide degree(C1) n the same saturation bound. So \nto add worst(N, C1)to degree(C2) n worst(N, C2)and then bound them together is at least as good as to \nbound them separately and then add. It is there\u00adfore not hard to show that to get the best approximation, \nalias\u00adequivalent classes should always be in the same vertex of the class tree. It is also not hard to \nshow that we get a better approximation if each vertex contains only alias-equivalent classes. A classic \nexample of alias-equivalent register classes is .oating\u00adpoint register pairing as found in the original \nMIPS, SPARC, and HP PA-RISC microprocessor families: each consecutive pair of single-precision .oating-point \nregisters combines to form one double-precision register. But alias equivalence is broader than traditional \npairing of registers, as illustrated by the register classes in Figure 1. Another case in which it is \nuseful to apply the same bound to two classes is one in which the alias set of class C1 is contained \nwithin the alias set of class C2. We say that C1 is alias-contained in C2, written C1 C2: C1 C2 . alias(C1).alias(C2) \n(10) If the vertex containing C1 is a descendant of the vertex contain\u00ading C2, we can prevent the common \nregisters from being counted in both C1 and C2. Alias-contained register classes are found on such architectures \nas the Motorola 68K, the Intel x86, and the Intel Itanium. The 68K is a classic example: address registers \nCa and data registers Cd form distinct register classes, each of which is alias contained in a third \nclass Cad, which contains both the address and data registers (Cad =Ca .Cd). When classes can overlap \nwithout being alias-equivalent or alias-contained, we know of no way to construct a class tree that always \ngives the best approximation. But for every real architec\u00adture we have studied, classes whose alias sets \noverlap are always alias-equivalent or alias-contained. For these architectures, we can build a class \ntree that is guaranteed to give the best possible Zfor any interference graph. This tree has three properties: \n For every vertex v, classes(v)is not empty.  The alias set of every child vertex is contained in the \nalias set of its parent vertex, where the alias set of a vertex v is the union of the alias sets of classes \nin classes(v).  If two vertices have the same parent, their alias sets are disjoint. Such a class tree \nalways exists, and it is easy to show (by contra\u00addiction) that it is unique. For example, the Motorola \n68040, with its on-chip .oating\u00adpoint unit, would have two class trees. The integer class tree would \nbe rooted with the alias set of Cad; this vertex would have two chil\u00addren corresponding to vertices with \nalias sets of Ca and Cd. The  other class tree would contain a single vertex corresponding to the aliases \nof the .oating-point class. Optimality. To show that the unique class tree above gives the best possible \napproximation, we de.ne a good vertex as one that alias-contains each of its children, whose children \nare all disjoint, and whose classes set is not empty. A bad vertex violates one or more of these conditions. \nIn the unique class tree above, all vertices are good. Suppose there is some other class tree that pro\u00advides \na better approximation. Then we can .nd a bad vertex v whose proper descendants are all good. No matter \nhow v is bad, there is a local transformation of the tree that has two properties: 1. It improves Z, \nor at worst leaves it unchanged. 2. Either it decreases the number of vertex pairs in which alias\u00adcontainment \ndoes not imply ancestry, or it leaves this number unchanged and decreases the number of parent-child \npairs in which the parent does not alias-contain the child.  By property 2, we can repeat local transformations \nuntil there are no more bad vertices, and this repetition is guaranteed to termi\u00adnate. By property 1, \nthis sequence of transformations makes Z no worse. Therefore the good class tree produces an approximation \nthat is at least as good as any other class tree. Exactness. We can show that our approximation is exact \nfor a large number of real architectures. For example, it is not dif.cult to show that exactness holds \nwhen no register classes have alignment restrictions, and the classes with overlapping alias sets are \nalias\u00adequivalent. In such a case, no overcounting of the aliased register resources is possible in Equation \n8, because each class tree has exactly one vertex. Our approximation remains exact even if we allow some \nalign\u00adment restrictions within a register class; an acceptable alignment restriction simply needs to \nexhibit a large amount of regularity. By regularity we mean that all multi-registers are a power of two \nin size, when measured in units of singleton registers, and these multi-registers all align on the appropriate \npower-of-two bound\u00adary, as de.ned by the singleton numbering. A less regular architecture which demonstrates \nwhen our ap\u00adproximation is not exact (though still safe) is the Intel i960. The i960 has not only single-width \nand quadruple-width integer reg\u00adisters, but also triple-width registers, each of which aliases with three \nsingle registers and must align on a quadruple-width bound\u00adary. For this machine, our colorability criterion \nmay overestimate the squeeze; for example, if a single-width node has neighbors of both triple-width \nand quadruple-width classes, our coloring crite\u00adrion cannot detect that because of alignment constraints, \na register numbered 3 modulo 4 may be available.  4 Implementing Our Colorability Criterion This section \ndescribes how we ef.ciently implement our colorabil\u00adity criterion and, in particular, Z(n, R), which \nis the measure of the constraint (or squeeze ) on node n by its neighbors. Just as a traditional graph-coloring \nregister allocator caches the degree of each interference-graph node, we cache the value of Z(n, R). \nAnd as in a traditional allocator, when node n gains or loses a neighbor, we must incrementally update \nZ(n, R). Saturation makes this up\u00addate tricky, since the effect of adding or removing a neighbor of class \nC depends on whether n is saturated with respect to some set of classes containing C. A barrier to incrementally \nupdating Z(n, R) is that the value degree(C) n of worst(N, C) in Equation 8 may change in nonlinear ways \nas degreen(C) changes. But as an approximation, the harm the adversary can do with m registers is no \nmore than m times the harm the adversary can do with one register: worstm(N, C) = m \u00d7 worst1(N, C) (11) \nEven better, for the vast majority of real commercial architectures, this approximation is exact up to \nbound (N, {C}). As a bonus, using this approximation means we have to store only the table of worst1(N, \nC) values, not worstm(N, C) for every m up to |C|. We therefore use this approximation of worstm(N, C). \nTo update Z(n, R) incrementally, we observe that adding or removing a neighbor of class C affects the \nvalue of rawZ(n, v) only at vertices v on the path from vertex (C) to the root vertex R. That s because \nthose are the only vertices whose raw Z values de\u00adpend on degreen(C). We can minimize the amount of recalculation \ndone when adding or removing a neighbor if we cache not only the .ltered squeeze Z(n, R), but also the \nvalue of the raw Z(n, v) for each vertex v in n s class tree. Notice that it is incorrect to cache the \n.ltered Z(n, v) values, since .ltering loses information about how many neighbors of a class were added \nand this count is needed when neighbors drop out of the graph. Now consider the sequence of p vertices \nthat starts at vertex (C) and then follows parent links to the root class R: v1 = vertex (C), vi+1 = \nparent(vi), vp = R. From this sequence, we can obtain adjustments d1,...,dp for the cached raw squeeze \nvalues using the following recurrence relations: d1 = \u00b1worst1(classn,C) ai = rawZ(n, vi) \u00dfi = bound(classn,vi.) \ndi+1 =.(ai,di,\u00dfi) for 1 = i = p, where ai is the cached raw squeeze, di is the change in ai, and di+1 \nis the change propagating along the parent link after .ltering by the bound \u00dfi. The initial change d1 \nis pos\u00aditive when a neighbor is added and negative when a neighbor is removed. The function .(a, d, \u00df) \nis de.ned in terms of an initial raw squeeze a, a change d, and a saturation bound \u00df: . max(0, min (d, \n\u00df - a)) if d = 0 .(a, d, \u00df)= min (0, max(d, d - (\u00df - a))) if d< 0 When raw Z(n, vi) goes from ai to ai \n+ di, the resulting change in Z(n, vi) is given by .(ai,di,\u00dfi). First, consider when d1 > 0, which corresponds \nto adding a neighbor. If both a and a + d are below the bound \u00df, then the change in squeeze is the same \nas the change in raw squeeze. If both are above the bound, then there s no change in squeeze. If they \nbracket the bound, then the change in squeeze is limited to \u00df - a. The logic for d1 < 0 (removing a neighbor) \nis analogous. When di goes to 0 for some i, it means that a bound somewhere along the path to the root \nkept the rest of the nodes along the path from being affected by the addition or removal of the neighbor. \nBy the de.nition of raw Z, the change in raw Z(n, vi+1) comes from one term in the sum over the children \nof vi+1, namely Z(n, vi). So the change in raw Z(n, vi+1) is .(ai,di,\u00dfi), i.e., di+1. And the net effect \non node n of the neighbor change, i.e., the net change in Z(n, vp),is .(ap,dp,\u00dfp). To update n s cached \nsqueeze, we compute .(ap,dp,\u00dfp). Each ai is available as a cached raw squeeze value, and the im\u00adplementation \nmust update each cached value that changes due to addition or removal of n s neighbors. Figure 3 presents \nC++ code for computing .(ap,dp,\u00dfp) given a node n, a vertex v, and a raw change d1. During the computation, \nthe code updates n s raw\u00adsqueeze cache as necessary. The function bound(n.class, v) returns bound (N, \nv.). The computation terminates either when it reaches the root vertex vp = R or when filteredChange \nbecomes zero. When filteredChange becomes zero, it means that the ad\u00addition or removal of n s neighbor \nhas no immediate effect on n s squeeze value, and hence, on the colorability of n. Note that ad\u00addition \nor removal of a neighbor will always change at least one cached raw squeeze value, even when the .nal \nfilteredChange value is zero, so that the effect of the change is not lost to the system. To re.ect removal \nof a neighbor t of node n, a register allocator might use the function squeezeChange as follows: n.squeeze \n+= squeezeChange(n, vertex(t.class), -worst1(n.class, t.class)); 5 Generalizing a Representative Allocator \nThe iterated-coalescing algorithm is a textbook example of graph\u00adcoloring register allocation [George \nand Appel 1996; Appel and int squeezeChange(IgNode n, Vertex v, int delta) { int alpha = n.rawSqueeze[v]; \nn.rawSqueeze[v] += delta; int filteredChange = Delta(alpha, delta, bound(n.class, v)); if (filteredChange \n== 0 || parent(v) == noVertex) return filteredChange; return squeezeChange(n, parent(v), filteredChange); \n} Figure 3. To compute the change in squeezen due to adding or removing a neighbor of class C, we start \nwith node n, vertex (C), and d1, which is positive to add and negative to remove. Auxiliary function \nDelta is .. Function call parent(v) produces the distin\u00adguished value noVertex when v is the root R of \nn s class tree. The value .nally returned is the change in Z(n, R). Palsberg 2002]. In six pages of well-documented \npseudocode, it covers all the important details of a practical implementation of a Chaitin-style allocator, \nas modi.ed to re.ect George and Appel s strategy for coalescing copy instructions and for representing \nreg\u00adister exclusions. Before developing the ideas in this paper, we implemented the iterated-coalescing \nalgorithm in C++ following George and Ap\u00adpel s pseudocode, with extensions suggested by Leung and George \n[1998]. We have derived a second implementation from that .rst one by substituting our generalization \nof the colorability criterion and by using class trees to account for saturation. In this section, we \ndescribe the effort required to generalize this representative register allocator. In the next section, \nwe show that the result is practical to use in a production compiler. There are a dozen places where \nthe allocator tests whether a node is trivially colorable. Naturally the allocator makes this test during \ngraph simpli.cation, when it is trying to determine a col\u00adoring order by eliminating underconstrained \nnodes from the inter\u00adference graph. But it also tests trivial colorability as part of its heuristics \nfor deciding when to try coalescing a copy instruction and whether the decision to coalesce a copy could \nhave negative consequences. The traditional allocator uses the criterion degreen <k to test trivial colorability \nof node n. Our generalization replaces that test with squeezen < |classn|. In each case, the test is \nsmall (one line of code) and ef.cient (constant time, no procedure calls). Strategy for coalescing. Coalescing \nis affected by more than just the generalization of the colorability criterion. If an allocator decides \nto eliminate a copy and coalesce the interference-graph nodes representing its source and destination \noperands, the class of the resulting coalesced node must be the intersection of the operands classes. \nA copy instruction can be coalesced only if the result of the intersection is a register class. On every \nmachine of which we are aware, the intersection of two classes is either empty or is one of the two classes, \nso our implementation prohibits coa\u00adlescing only when the operands classes do not overlap. We check for \noverlap during the construction of the interference graph, at the point where the original allocator \nidenti.es copy instructions that might be coalesced. When two nodes are coalesced, the class of the coalesced \nnode is the smaller of the two original classes. Except for the fact that the allocator must retain the \nnode with the smaller class, coalesc\u00ading is as implemented by George and Appel. Should we ever encounter \na machine in which two classes could overlap without one being contained in the other, we would have \nto change our code. First, we would have to add classes as needed to make the set of classes closed under \nnonempty intersection. Sec\u00adond, to coalesce two nodes, the allocator would have to create a new node \nto replace the original nodes, making the new node s class the intersection of the original nodes classes. \nTransferring edges to the new node would use the same procedure as transfer\u00adring edges in the original \npseudocode, maintaining the integrity of the approach. Representing register exclusions. In general, \nthere are points in a program where a register and all of its aliases are unavailable for allocation. \nFor example, a caller-saves register is unavailable at a call site. The register allocator needs a way \nto inhibit allocation of the register at such a point, i.e., the register must be excluded from the set \nof allocable registers of candidates whose lifetimes cross the point of unavailability. For candidates \nwhose register classes don t contain an excluded register, exclusion is implicit and needs no special \nrepresentation. For other candidates, it is customary to represent an exclusion by extending the graph \nwith an exclusion node that represents the ex\u00adcluded register, and to add an interference-graph edge \nfrom the exclusion node to the candidate s node. Such an exclusion edge is needed for each member of \nthe candidate s class that is unavail\u00adable. George and Appel use exclusion nodes and edges in their allo\u00adcator. \nBut because an exclusion node can have a very large number of exclusion edges, they omit neighbor lists \nfrom such nodes, and they carefully design their allocator to avoid needing those lists. We prefer to \nomit exclusion nodes from the interference graph altogether. Instead, to identify the registers from \nwhich a can\u00addidate is excluded, our implementation associates an excluded\u00adregister set with each candidate. \nWhen testing for colorability, we still calculate squeezen and compare it to the number of reg\u00adister \nnames available to candidate n. The number of names avail\u00adable simply becomes the size of n s class minus \nthe size of n s excluded-register set E, |N|-|E|, which is a constant. When the color-selection phase \nof the allocator computes the set of excluded colors for each candidate, the excluded-register set is \nused to ini\u00adtialize the set of excluded colors. As Section 6 shows, omitting ex\u00adclusion nodes from the \ninterference graph also leads to space bene\u00ad.ts. Omission of exclusion nodes can also improve the cost/bene.t \nestimates used for choosing a candidate to spill. The degree of a candidate s node is traditionally part \nof such estimates because it approximates the increase in overall colorability to be gained by removing \nthe node from the graph. But counting exclusion edges in such an estimate skews the result, since the \ncolorability of the exclusion nodes that they connect to is not in question. Effort required. Overall, \nour original implementation of the George and Appel allocator with extensions by Leung and George took \n1215 lines of code. For our generalized version, we changed that code in 25 places. There are 80 lines \nof new code for de.ning and maintaining extra .elds for squeeze caches in the node data structure. The \nsqueezeChange function in Figure 3 is typical of this added code. In addition, we replaced 37 lines of \noriginal code with 68 lines of generalized but functionally similar code. The twelve places where we \ngeneralized the colorability criterion are typical of these replacements. Finally, we wrote 210 lines \nof code that runs once, when the compiler con.gures itself to the target machine. This code derives a \nrepresentation of the register class tree, the worst-case-displacement table, and other static structures \nthat allow the allocator to operate ef.ciently. 6 Practicality Section 3.2 talks about an approximation \nfor the ideal squeeze * n that is safe, good, and arguably fast. Here we explore exactly how fast it \nis. Our generalization of the George and Appel allocator, as dis\u00adcussed in Section 5, is implemented \nin Machine SUIF. This allo\u00adcator is not just an experimental prototype; we use it in our ev\u00aderyday research. \nWe measured register-allocation times for the SPEC2000 benchmark suite; each measurement is the average \nof .ve runs on an unloaded 2.53 GHz Pentium 4 with 2 GB of mem\u00adory. Machine SUIF includes back ends for \nAlpha and x86, and we are able to compile and run all of the C and FORTRAN-77 bench\u00admarks on these two \ntargets. Because SUIF does not support C++, FORTRAN-90, or extended FORTRAN-77, we do not include re\u00adsults \nfor the SPEC benchmarks written in these languages. Our register allocator can be compiled to use either \nthe tradi\u00adtional colorability criterion or our new, generalized criterion. Re\u00adcon.guring the allocator \nfor a new machine requires specifying the register classes, their members, and the register-alias map. \nIn our C++ implementation, this speci.cation takes one line of code for the class enumeration, one line \nper class for de.ning class mem\u00adbership, and one line per register name for specifying its aliases. We \nare working on a scheme to generate this code automatically from a simple speci.cation language. Register \nclasses for x86: CEX : CX : CLH : CEI : CI : CEXI : {eax, ebx, ecx, edx}{ax, bx, cx, dx}{al, ah,bl, bh,cl, \nch,dl, dh }{esi, edi}{si, di}CEX . CEI CXI : CX . CI Class tree:  Figure 4. Class de.nitions and class \ntree for x86. Many of the classes are alias-equivalent, e.g., the class CEX, containing the 32-bit accumulator \nclasses, is alias-equivalent with CX, contain\u00ading the 16-bit accumulators, and CLH, containing the 8-bit \naccu\u00admulators. 1.4 1.2 This section presents three sets of experiments that focus on the practicality \nof our generalized colorability criterion. Section 6.1 looks at the cost of our approach for an x86 target, \nwhich is an architecture that exhibits register aliasing and a non-trivial class tree. Section 6.2 shows \nhow the cost of our allocation approach scales with increased register pressure. Section 6.3 measures \nthe cost of our approach for an Alpha target, which is an architecture Normalized compile times 1.0 0.8 \n0.6 0.4 0.2 that doesn t always need the generality of our approach. 0.0 6.1 Cost of doing allocation \nright Our .rst set of experiments measures the cost of allocating integer Trad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-realTrad-idealGen-noaliasGen-real \nbzip2 crafty gap gcc gzip mcf parser perlbmk twolf vortex vpr registers for the Intel x86 target. The \nx86 architecture is interesting because it includes alias-equivalent 16-bit and 32-bit accumulator registers \nthat also alias with pairs of byte registers. In addition, the architecture includes two alias-equivalent \nclasses of 16-and 32-bit index registers that cannot be used everywhere the 16-and 32\u00ad bit accumulator \nregisters can be used. As illustrated in Figure 4, we thus have two register classes the accumulator \nregisters and the index registers that are alias-contained in the complete set of integer registers. \nIn Figure 5, we evaluate the impact on compile time of using our generalized algorithm with the register \nmodel illustrated in Fig\u00adure 4. To help analyze the components of allocation time, we also show two other \ntimings. The .rst (Trad-ideal) uses the traditional graph-coloring formulation and targets an x86-like \nmachine that has a single ideal register class containing six 32-bit registers that are interchangeable \nand independent. The second (Gen-noalias) uses our generalized formulation and the same set of x86 register \nclasses shown in Figure 4 but without any aliasing of their mem\u00adbers. The third (Gen-real) uses the generalized \nformulation for the real x86 target, including aliasing. The allocation times are reported, for each \nbenchmark, relative to the allocation time of the (Trad-ideal) case. For these experiments, we measure \nonly the cost of the .rst iteration of coloring, since the algorithms may iterate different numbers of \ntimes given the different hardware\u00adresource constraints. Also, because the x86 does not have allo\u00adcable \n.oating-point registers, we report allocation times for only the integer benchmarks. The times are averages \nover .ve runs, with all standard deviations well below 1%. Each bar in the graph breaks the total allocation \ntime into the time spent building the in\u00adterference graph, time devoted to coalescing copy instructions, \nand Figure 5. The cost of our approach when registers aren t inter\u00ad changeable and independent. The target \nmachine is an x86. Al\u00ad location times are presented for the traditional approach (Trad\u00ad ideal) using \na single idealized register class (with interchangeable and independent registers), and for our approach \nusing the real set of x86 register classes (Gen-real) and using the same set of x86 register classes \nbut without any aliasing of their members (Gen\u00ad noalias). The results are scaled for each benchmark to \nthe alloca\u00ad tion time of the traditional approach. time for other allocation activities (classifying \noperands, inserting spill instructions, rewriting code to replace register candidates with their assigned \nregisters, etc.). The results in Figure 5 show that our generalized approach in\u00adcreases allocation times \nby less than 30% for all benchmarks and less than 15% for all but perlbmk. By comparing the numbers for \nGen-real against Gen-noalias, we can quantify the cost of aliasing, and by comparing Gen-noalias against \nTrad-ideal, we can quan\u00adtify the cost of class trees. Increases in the cost to build an interference \ngraph come from several sources. When registers alias, the generalized allocator must perform an interference \ncheck not just for the register de\u00ad.ned at a de.nition point, but also for each alias of the de.ned register. \nThis repeated work in the inner loop of building the in\u00adterference graph accounts for much of the difference \nin allocation time between Gen-noalias and Gen-real. Most of the rest of the extra time to build the \ninterference graph is due to an increase in the number of edges inserted into the interference graph \nwhen reg\u00adister classes alias. This resulting increase in register contention also accounts for increases \nin the time to complete the allocation tasks in the Coalescing and Other categories. In the cost to build \nan interference graph, the differences be\u00adtween Trad-ideal and Gen-noalias are due to the cost of running \nsqueezeChange. This routine is run twice (once for each endpoint) when adding an edge to the interference \ngraph under Gen-noalias. The routine is also run when nodes are removed from the graph, explaining the \nsmall change in portions of the allocation times la\u00adbelled Other. 6.2 Cost of increased register pressure \nWe now present an example of how the compile-time costs of our generalized algorithm scale as registers \nbecome scarce. We focus on architectures with aliased registers because, as shown in the previous experiment, \naliasing has a noticeable impact on allocation time. We de.ne an imaginary family of targets based on \nthe Al\u00adpha architecture, identical except for the sizes of their .oating\u00adpoint register .les. Our primary \ntarget in this section is one that creates double-precision registers out of aligned pairs of single\u00adprecision \nregisters. To verify that our algorithm can successfully exploit the single-precision register pairs, \nwe also de.ne a base\u00adline machine model with only double-precision registers so that a single-precision \nvalue consumes an entire double-precision reg\u00adister. For this experiment, we chose to use the benchmark \nGSM, a speech-compression program from the MediaBench suite [Lee, Potkonjak, and Mangione-Smith 1997]. \nThis program contains a good mix of single-and double-precision .oating-point register candidates. All \nrun-time results for GSM were generated using its clinton input. Since we would like to compile GSM under \na range of regis\u00adter pressures, we must identify a proxy for register pressure. The proxy we use is the \npercentage of spill instructions (loads and stores) executed. Using this measure, Figure 6 shows that \nour algo\u00adrithm encounters nearly no register pressure when compiling GSM for a target with 12 double-precision \nregisters (with pairs). The number of executed spill instructions (and thus register pressure) increases \nsteadily as we reduce the number of available .oating\u00adpoint registers. Figure 6 also reports the percentage \nof spill instructions exe\u00adcuted by GSM when compiled for a target without single-precision pairs. As \nexpected, an aliasing-aware allocator is able to reduce spilling by exploiting the single-precision register \npairs. Figure 7 resumes our focus on the targets with aliased pairs. It shows the total time spent in \nallocation for all procedures in GSM. As registers become scarce and register pressure increases (reading \nthe bars right to left), total allocation time also increases. Interestingly, as Figure 7 illustrates, \nthe change in allocation time comes in steps. The reason is that when spilling occurs, the al\u00adlocator \nis forced to rebuild the interference graph and to launch a new coloring attempt. As register pressure \nincreases, the alloca\u00adtor must discard and rebuild the interference graph more often. In this experiment, \nthe targets with 10 and 12 double-precision regis\u00adters required the same number of iterations of the \nbuild-graph-and\u00adcolor loop; the targets with 6 and 8 double-precision registers re\u00adquired an extra two \niterations due to spilling; and the target with 4 double-precision registers required yet another two \nrounds. Hence the steps up in time. It may seem odd that the times tend to be so even within the steps. \nThe reason the 10 pairs case resembles 12 pairs is sim\u00adply that, for the GSM benchmark, spilling doesn \nt change between the two. But that s not true for the transition between 6 and 8 pairs. To understand \nthe effect of this difference, consider the time 4 6 8 1012 Number of double-precision registers Figure \n6. Dynamic spill-code fractions for the GSM benchmark. Targets labelled With pairs create double-precision \n.oating-point registers from aligned pairs of single-precision registers. Targets labelled Without pairs \nstore all .oating-point values in double\u00adprecision registers. The vertical axis shows the fraction of \ndynamic instructions that are spills. Figure 7. Register-allocation times for the GSM benchmark, as \ncompiled for an imaginary Alpha family with .oating-point regis\u00adter pairs. The horizontal axis shows \nthe number of single-precision pairs comprising the .oating-point register pool. The vertical axis shows \nthe total number of seconds required for register allocation of the entire GSM benchmark. required to \nbuild an interference graph. For a given procedure, the .rst graph takes as long to build for one target \nas for another. But when spilling forces a second or subsequent iteration of the build\u00adand-color loop, \ntwo kinds of changes affect graph-building time. The addition of spill instructions to the program means \nthat there are more instructions to be scanned while creating the interference graph. However, the removal \n(by spilling) of highly constrained register candidates means that there are fewer interference-graph \nedges to be created. The time cost of graph building is very nearly a linear combination of the number \nof instructions scanned and the number of edges created. For allocations with 6 and 8 pairs, the two \nterms counterbalance each other almost exactly. The cost of copy coalescing also depends heavily on the \nedge density of the graph, because the heuristic that avoids over\u00ad Normalized compile times 1.6 1.4 \n1.2 1 0.8 0.6 0.4 0.2 0 Separate Combined Benchmark Procedures Trad Gen Gen ammp 179 402 402 218 mesa \n1106 2329 2329 1216 apsi 98 256 256 157 mgrid 13 29 29 16 art 26 53 53 27 sixtrack 147 322 322 172 equake \n27 55 55 28 swim 7 14 14 7 wupwise 22 50 50 28 Trad-sepGen-sepGen-combTrad-sepGen-sepGen-combTrad-sepGen-sepGen-combTrad-sepGen-sepGen-combTrad-sepGen-sepGen-combTrad-sepGen-sepGen-combTrad-sepGen-sepGen-combTrad-sepGen-sepGen-combTrad-sepGen-sepGen-comb \nTable 1. Number of procedures compiled per benchmark and to\u00adtal number of coloring iterations required \nduring register alloca\u00adtion under the traditional (Trad) and our generalized (Gen) ap\u00ad ammp mesa apsi \nmgrid art sixtrack equake swim wupwise proaches. Figure 8. The cost of our generalization when it isn \nt necessary. The target is an Alpha. Allocation times are presented for the tra\u00additional approach (Trad-sep), \nour approach using separate allo\u00adcations for each register class (Gen-sep), and our approach using a \nsingle combined allocation pass for all classes (Gen-comb). The results are scaled for each benchmark \nto the allocation time of the traditional approach. coalescing requires visiting the neighbors of potential \ncoalesced nodes. However, the heuristic also entails more bookkeeping when the number of overconstrained \nneighbors of a coalesced node is higher, which becomes more likely as register pressure grows. So like \ninterference-graph building time, the time for copy coalescing stays about level as the register pool \ndrops from 8 pairs to 6 pairs, because the lower edge density on second and subsequent color\u00ading iterations \nis counterbalanced by a higher relative population of overconstrained candidate nodes. The effect of \nincreased spilling on the Other time costs of register allocation is smaller, because the extra time \nto insert load and store instructions and to create short-lived temporaries is a relatively small fraction \nof the work in this catchall category. In summary, the allocation-time performance of our generalized \nalgorithm increases slowly and in a predictable manner as register pressure increases. Part of the appeal \nof traditional graph coloring is that its cost is commensurate in practice with the work it gets done, \nand our generalization retains that appealing property. 6.3 Cost of always doing allocation right Our \nlast experiment measures the cost of allocating the integer and .oating-point registers for a real Alpha \ntarget. The Alpha architecture is interesting because if we allocate Alpha s integer and .oating-point \nregisters separately, our generalization is not needed we can use the traditional formulation of graph \ncoloring. Figure 8 compares allocation times for the traditional formulation; for our formulation, but \nusing separate allocation passes for integer and .oating-point registers; and for our formulation using \na single combined allocation pass for all registers. Since we re interested in compilation involving \nmultiple register classes, this section in\u00adcludes results for only the SPEC .oating-point benchmarks. \nAs the .gure illustrates, the allocation times for our approach with separate allocations of the integer \nand .oating-point registers are within 5% of the times of the traditional approach. When we run the allocation \nof integer and .oating-point registers together, however, you can again see the costs of allocating multiple \nregister classes simultaneously, which were highlighted in Section 6.1. Total edges Edges /node Benchmark \nout in out in ammp 1880.1 2107.7 2.4 3.0 mesa 1958.5 2090.3 1.2 1.6 apsi 8819.6 9339.5 7.3 8.4 mgrid \n10163.4 10440.4 9.0 9.7 art 775.6 888.5 1.3 1.6 sixtrack 27413.6 28294.2 3.6 4.2 equake 2419.5 2592.3 \n1.5 1.7 swim 2755.6 2887.6 3.0 3.3 wupwise 5962.2 6385.1 3.6 4.6 Table 2. Increase in the number of \nedges per interference graph and the average number of edges per node in an interference graph when compiling \nwithout (out) and with (in) special register nodes in the interference graph. These numbers are averages \nover all interference graphs produced during each benchmark s compila\u00adtion; the edges-to-nodes ratio \nwas computed as a geometric mean. Table 1 may help to explain the consistent nature of the in\u00adcreases \nin Figure 8. The table lists the number of procedures com\u00adpiled and the total number of coloring iterations \nrequired for reg\u00adister allocation. Notice that there are always slightly more than half as many iterations \nrequired in the combined case. This is a result of the fact that spilling in one class requires reallocation \nof all classes. This extra cost, plus the non-linear cost of interference\u00adgraph building with larger \nsets of live candidates and greater num\u00adbers of relevant candidate-de.nition points, accounts for the \nma\u00adjority of the increase in allocation time. Overall, these compile\u00adtime costs should be considered \nwhen investigating new optimiza\u00adtions that require the simultaneous allocation of register classes, as \ndiscussed in the introduction. Using the Alpha con.guration, we also investigated the time and space \neffects of including special register nodes in the inter\u00adference graph. In this experiment, we con.gure \nour generalized algorithm so that it allocates all register classes in a single pass. We don t present \nthe time effects in detail because there was very little difference between the allocation times (all \nwithin 2%). With respect to space savings, Table 2 reports on the change in the av\u00aderage number of edges \nper interference graph and the average ra\u00adtio of edges-to-nodes per interference graph. We found that \nhan\u00addling register exclusions without introducing special register nodes eliminates about 6%, on average, \nof the edges in each interference graph.  7 Related Work Starting with Chaitin et al. [1981], there \nis a large body of work on global register allocation by graph coloring. But only a handful of authors \ndescribe algorithms that extend graph-coloring allocation beyond the assumptions that registers are interchangeable \nand in\u00addependent.3 As we explain below, none of these algorithms is as complete a solution as ours. Briggs \ndescribes an algorithm for coloring aligned and un\u00adaligned register pairs [Briggs 1992; Briggs, Cooper, \nand Torczon 1992]. This algorithm requires that a node s degree accurately re.ect its colorability. To \nmake a node s degree re.ect its col\u00adorability even in the presence of aliasing, Briggs adds additional \nedges to the interference graph in an attempt to model the aliasing constraints. Unfortunately, this \nedge-focused approach sometimes reports that a node is trivially colorable when it is not, and it is \nnot easy to see how the approach could be extended to handle the simultaneous allocation of multiple, \noverlapping register classes. Nickerson [1990] presents an algorithm that handles register candidates \nrequiring two or more adjacent, aligned registers. Can\u00addidates requiring two or more registers are called \nclusters and the individual registers of a cluster are called cluster-mates . In Nickerson s approach, \nan interference-graph node represents an individual register of a cluster. Nickerson points out that \nit is not always possible to use the traditional colorability criterion every\u00adwhere in his interference \ngraph, even after identifying and remov\u00ading implicit edges whose interference relation is subsumed by \nan edge of a cluster-mate. For these cases, Nickerson invents an arti\u00ad.cial k to make his model work. \nRuneson and Nystr\u00a8om [2003] describe a design for a retar\u00adgetable graph-coloring allocator for irregular \narchitectures. Their work goes part of the way along the path to a generalized color\u00ading criterion. When \noverlapping alias sets are alias-equivalent, our generalized colorability criterion simpli.es to their \np, q. test. Our independently discovered results, however, go quite a bit farther. We show how nested \nregister classes can lead the p, q. test to identify candidates as more squeezed than they truly are, \nand we show how to avoid this inaccuracy by using saturation bounds. Koseki, Komatsu, and Nakatani [2002] \ndescribe a technique for modifying the selection phase of graph-coloring allocation to in\u00adcrease the \nlikelihood that candidates are given their preferred reg\u00adisters. Preference-directed graph coloring is \nrelated to our work in that it handles multiple register classes. However, while we use class information \nto help determine when candidate nodes are trivially colorable, Koseki et al. use class information only \nduring register selection (i.e., register classes appear only in their register\u00adpreference graph, not \nin their interference graph). Their approach has no notion of saturation and can incorrectly assume that \nan in\u00adterference node is not trivially colorable when it actually is. Fi\u00adnally, their algorithm does \nnot seem to support architectures in which registers alias. A number of researchers have cast register \nallocation as a mathematical-programming problem, rather than a graph-coloring problem [Goodwin and Wilken \n1996; Kong and Wilken 1998; Ap\u00adpel and George 2001; Fu and Wilken 2002; Scholz and Eckstein 2002; Hirnschrott, \nKrall, and Scholz 2003]. These approaches can handle a wide variety of architectural irregularities, \nbut these ben\u00ade.ts come at the cost of signi.cant increases in compile time. 8 Conclusions Despite decades \nof research on compiler construction, reusable compiler components remain all too rare. Chaitin s graph-coloring \n3Clearly, many others have implemented allocators that go beyond these assumptions, but here, we avoid \ndiscussing what would be catego\u00adrized as workarounds . formulation of register allocation has been remarkably \nrobust, but to make it usable for real targets, practitioners have almost always had to augment it in \nunstructured ways. We maintain the structure and ef.ciency of the original algorithm while making it \nextremely simple to target new machines and retro.t existing allocators. One of our key insights is that \ncoloring constraints on each interference-graph node should be expressed in terms of the set of registers \navailable to it. With this insight we produce a gener\u00adalization that handles simultaneous allocation \nof multiple register classes and accommodates register aliasing in an elegant way. Be\u00adcause allocators \nusing our approach know about the set of registers available to each node, they can recognize when overlap \nbetween such sets would introduce inaccuracies in the criterion for col\u00adorability, and thereby avoid \nthe overcounting inherent in simpler formulations. Acknowledgments We thank Jo ao Dias, Greg Morrisett, \nand the anonymous referees for their comments and suggestions. This work has been funded in part by gifts \nfrom Intel and Microsoft, by an Alfred P. Sloan Research Fellowship, and by NSF grants CCR-0310877, CCR\u00ad0311482, \nand ITR-0325460. References Andrew W. Appel and Lal George. 2001 (May). Optimal spilling for CISC machines \nwith few registers. In 2001 ACM SIGPLAN Conference on Programming Language Design and Implemen\u00adtation, \npages 243 253. Andrew W. Appel and Jens Palsberg. 2002. Modern Compiler Im\u00adplementation in Java. Cambridge \nUniversity Press, 2nd edition. Preston Briggs. 1992 (April). Register allocation via graph color\u00ading. \nTechnical Report TR92-183, Rice University, Department of Computer Science. Preston Briggs, Keith Cooper, \nand Linda Torczon. 1992 (March). Coloring register pairs. ACM Letters on Programming Lan\u00adguages and Systems, \n1(1):3 13. Preston Briggs, Keith Cooper, and Linda Torczon. 1994 (May). Improvements to graph coloring \nregister allocation. ACM Transactions on Programming Languages and Systems, 16(3): 428 455. Gregory J. \nChaitin. 1982. Register allocation and spilling via graph coloring. In 1982 SIGPLAN Symposium on Compiler \nConstruction, pages 98 105. Gregory J. Chaitin, Marc A. Auslander, Ashok K. Chandra, John Cocke, Martin \nE. Hopkins, and Peter W. Markstein. 1981. Reg\u00adister allocation via coloring. Computer Languages, 6(1):47 \n57. Keith Cooper and Linda Torczon. 2003. Engineering a Compiler. Morgan Kaufmann. Changqing Fu and Kent \nD. Wilken. 2002 (November). A faster op\u00adtimal register allocator. In 35th ACM/IEEE International Sym\u00adposium \non Microarchitecture, pages 245 256. Lal George and Andrew W. Appel. 1996 (May). Iterated register coalescing. \nACM Transactions on Programming Languages and Systems, 18(3):300 324. David W. Goodwin and Kent D. Wilken. \n1996 (August). Optimal and near-optimal global register allocations using 0 1 integer programming. Software \nPractice &#38; Experience, 26(8):929 965. Ulrich Hirnschrott, Andreas Krall, and Bernhard Scholz. 2003 \n(August). Graph coloring vs. optimal register allocation for op\u00adtimizing compilers. In Joint Modular \nLanguages Conference, volume 2789 of Lecture Notes in Computer Science, pages 202 213. Springer Press, \nKlagenfurt, Austria. Richard E. Kessler, Edward J. McLellan, and David A. Webb. 1998 (October). The Alpha \n21264 microprocessor architecture. In International Conference on Computer Design, pages 90 95. Timothy \nKong and Kent D. Wilken. 1998 (December). Precise register allocation for irregular architectures. In \n31st ACM/IEEE International Symposium on Microarchitecture, pages 297 307. Akira Koseki, Hideaki Komatsu, \nand Toshio Nakatani. 2002 (June). Preference-directed graph coloring. In 2002 ACM SIG-PLAN Conference \non Programming Language Design and Im\u00adplementation, pages 33 44. Chunho Lee, Miodrag Potkonjak, and William \nH. Mangione-Smith. 1997 (December). MediaBench: a tool for evaluat\u00ading and synthesizing multimedia and \ncommunications systems. In 30th ACM/IEEE International Symposium on Microarchitec\u00adture, pages 330 335. \nAllen Leung and Lal George. 1998. A new MLRISC register al\u00adlocator. Standard ML of New Jersey compiler \nimplementation notes. Michael Matz. 2003 (May). Design and implementation of a graph coloring register \nallocator for GCC. In GCC Developers Sum\u00admit, pages 151 170. Steven S. Muchnick. 1997. Advanced Compiler \nDesign and Im\u00adplementation. Morgan Kaufmann. Brian R. Nickerson. 1990 (June). Graph coloring register \nalloca\u00adtion for processors with multi-register operands. In 1990 ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 40 52. Johan Runeson and Sven-Olof Nystr\u00a8om. 2003 (September). \nRe\u00adtargetable graph-coloring register allocation for irregular archi\u00adtectures. In Software and Compilers \nfor Embedded Systems (SCOPES), volume 2826 of Lecture Notes in Computer Science, pages 240 254. Springer \nPress, Klagenfurt, Austria. Bernhard Scholz and Erik Eckstein. 2002 (June). Register allo\u00adcation for \nirregular architectures. In Proceedings of the Joint Conference on Languages, Compilers and Tools for \nEmbedded Systems, pages 139 148.  \n\t\t\t", "proc_id": "996841", "abstract": "Graph-coloring register allocation is an elegant and extremely popular optimization for modern machines. But as currently formulated, it does not handle two characteristics commonly found in commercial architectures. First, a single register name may appear in multiple register classes, where a class is a set of register names that are interchangeable in a particular role. Second, multiple register names may be aliases for a single hardware register. We present a generalization of graph-coloring register allocation that handles these problematic characteristics while preserving the elegance and practicality of traditional graph coloring. Our generalization adapts easily to a new target machine, requiring only the sets of names in the register classes and a map of the register aliases. It also drops easily into a well-known graph-coloring allocator, is efficient at compile time, and produces high-quality code.", "authors": [{"name": "Michael D. Smith", "author_profile_id": "81100077421", "affiliation": "Harvard University", "person_id": "PP39026087", "email_address": "", "orcid_id": ""}, {"name": "Norman Ramsey", "author_profile_id": "81100300481", "affiliation": "Harvard University", "person_id": "PP14110628", "email_address": "", "orcid_id": ""}, {"name": "Glenn Holloway", "author_profile_id": "81100132825", "affiliation": "Harvard University", "person_id": "P98433", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996875", "year": "2004", "article_id": "996875", "conference": "PLDI", "title": "A generalized algorithm for graph-coloring register allocation", "url": "http://dl.acm.org/citation.cfm?id=996875"}