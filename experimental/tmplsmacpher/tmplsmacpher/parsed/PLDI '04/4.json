{"article_publication_date": "06-09-2004", "fulltext": "\n Kill-Safe Synchronization Abstractions Well, it just so happens that your friend here is only mostly \ndead. There s a big difference between mostly dead and all dead. Miracle Max in The Princess Bride Matthew \nFlatt Robert Bruce Findler University of Utah University of Chicago Abstract When an individual task \ncan be forcefully terminated at any time, cooperating tasks must communicate carefully. For example, \nif two tasks share an object, and if one task is terminated while it manipu\u00adlates the object, the object \nmay remain in an inconsistent or frozen state that incapacitates the other task. To support communication \namong terminable tasks, language run-time systems (and operating systems) provide kill-safe abstractions \nfor inter-task communica\u00adtion. No kill-safe guarantee is available, however, for abstractions that are \nimplemented outside the run-time system. In this paper, we show how a run-time system can support new \nkill-safe abstractions without requiring modi.cation to the run-time system, and without requiring the \nrun-time system to trust any new code. Our design frees the run-time implementor to provide only a modest \nset of synchronization primitives in the trusted computing base, while still allowing tasks to communicate \nusing sophisticated abstractions. Categories and Subject Descriptors D.3.3 [Programming Languages]: \nLanguage Constructs and Features Concurrent programming structures; D.4.1 [Operating Systems]: Process \nManagement Synchronization  General Terms Languages, Design 1 Introduction Most modern programming languages \noffer support for multi\u00adple tasks in the form of threads. Support for task termination is less widely \nimplemented and generally less understood, but no less useful to programmers. The designers of Java, \nfor ex\u00adample, understood the need for termination, and they included Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 04, June 9 11, 2004, Washington, DC, USA. \nCopyright 2004 ACM 1-58113-807-5/04/0006 ...$5.00 Thread.stop and Thread.destroy in the language. Flaws \nin the speci.cation of Thread.stop forced its withdrawal, however, and Thread.destroy has never been \nimplemented. Meanwhile, var\u00adious extensions of Java have provided termination in a more con\u00adtrolled form \n[1, 2, 9, 10, 12], and termination of Java tasks is a driving goal of the new JSR-121 standard [24]. \nTermination in any language becomes troublesome when tasks share objects. Two tasks may share a queue, \nfor example, and they may require that terminating one task does not corrupt or per\u00admanently freeze the \nqueue for the other task. In other words, the tasks require a kill-safe queue. Just as thread-safe means \nthat an ab\u00adstraction s operations appear atomic in the presence of interleaved threads of execution, \nkill-safe means that abstraction s operations appear atomic in the presence of thread termination. Java \nextensions such as JSR-121 do not allow a programmer to implement kill-safe abstractions. Instead, such \nextensions restrict sharing among terminable tasks to objects that are managed by the run-time system \nkernel, so that only the kernel needs to imple\u00adment kill safety. In particular, if one task is terminated \nwhile ma\u00adnipulating a kernel-maintained queue, the kernel delays termination until it can leave the queue \nin a consistent state. On the one hand, when the kernel implementor s work is complete, application pro\u00adgrammers \nneed not worry about termination when using shared ob\u00adjects. On the other hand, application programmers \nare restricted to the kernel s abstractions for reliable communication. In this paper, we show how to \nextend a run-time system (once and for all) so that programmers can de.ne kill-safe abstractions outside \nthe kernel. Furthermore, with our design, the set of cooperating tasks that share an object need not \nbe de.ned in advance, and the cooperating tasks need not trust each other; the tasks must trust only \nthe implementation of the shared object. Our design builds on the observation that termination of a thread \nis much like inde.nite suspension of the thread. By creating a thread to manage a particular synchronization \nabstraction, and by employing our new primitives to protect the thread, a programmer can ensure that \nan abstraction instance is suspended when it might otherwise be killed. In other words, when the instance \nis killed as part of a task termination, it turns out to be only mostly dead, and a surviving task that \nshares the instance can resurrect it. This technique succeeds because our primitives allow a manager \nthread to preserve its instance s consistency across suspends and resumes, and this consistency is the \nessence of kill-safety. At the same time, a rogue task cannot escape termination through accomplices \nof equal stature, because a resurrected task gains no more privileges than those of its resurrector. \nThe latest version of MzScheme [5] implements our design for kill\u00adsafe abstractions. MzScheme builds \non the primitives of Concurrent ML [21], which enable a programmer to construct synchronization abstractions \nthat have the same .rst-class status as built-in abstrac\u00adtions. By starting with Concurrent ML s primitives, \nwe ensure that our model and implementation cover a large class of abstractions. In general, MzScheme \ncan express any abstraction that is express\u00adible in Concurrent ML, and we believe that any such abstraction \ncan be made kill-safe. Section 2 describes our model of task management and kill-safe abstractions. Section \n3 presents MzScheme s task-control mech\u00adanisms, and Section 4 sketches the implementation of a kill-safe \nqueue. Section 5 reviews MzScheme s embedding of Concurrent ML primitives, mainly for readers who are \nnot familiar with Con\u00adcurrent ML. Section 6 presents a complete and realistic queue im\u00adplementation using \nthe Concurrent ML primitives. This full imple\u00admentation motivates a remaining detail of our design that \nis covered in Section 7. Section 8 explores in more detail some of our design choices. Sections 9 and \n10 summarize related work and conclude. 2 Motivating Example Consider the implementation of a web server \nwith servlets. The system administrator allows certain users to implement servlets, but the administrator \nreserves the right to terminate any servlet-based session that appears to misbehave (e.g., consumes too \nmuch mem\u00adory). For various reasons, the servlets for two active sessions might dis\u00adcover each other and \nwish to communicate. For example, the ses\u00adsions may share a collaborative document whose implementation \nis speci.c to the pair of servlets. The servlet tasks trust the document implementation, but they cannot \ntrust each other to survive, because the server might terminate one or the other session at any time. \nIn short, the servlets need to share a kill-safe document. 2.1 Existing Approaches If the server and \nservlets are implemented as processes in a con\u00adventional operating system, then they are strictly isolated, \nas in Figure 1. Each task occasionally communicates across the task boundary (drawn as a thick gray line \nin the .gure) to the kernel task, but a task does not communicate directly to other tasks or cross into \nanother task s space (as indicated in the .gure by thick black lines). As a result, a misbehaving session \nis terminated eas\u00adily. If two servlets need to communicate, however, they must use the primitives provided \nby the kernel (depicted in the .gure by a telecast from the left task to the right task via the kernel \ntask). The kernel s set of primitives is unlikely to include a document abstrac\u00adtion, so this architecture \ndoes not meet the needs of the servlet im\u00adplementors; the document must reside in one servlet or another, \nso it will be terminated with the servlet. If the server and servlet tasks are implemented as threads \nin a safe programming language, the server can rely on abstract datatypes to protect its data structures \nfrom misbehaving servlets. As illustrated in Figure 2, task boundaries fade away, and servlets are free \nto set up communication abstractions that better match their needs (as de\u00adpicted in the .gure by a close-range \ntelecast in a task s space). With no boundaries between tasks, however, there is no guarantee that a \nservlet will not be terminated while it is manipulating a shared doc\u00adument, which means that the document \nis not kill-safe. Figure 1. Figure 2. OS (e.g., Unix) Safe run-time (e.g., JVM) Figure 3. Figure 4. \nNested tasks Kill-safe (MzScheme) A nested-task architecture can avoid the .xed set of kill-safe com\u00admunication \nprimitives while providing control. As illustrated in Figure 3, nesting effectively allows a programmer \nto extend the kernel s set of communication primitives by implementing a new nested kernel. In this architecture, \nthe servlets that share a docu\u00adment must run as sub-tasks, controlled by a master servlet that im\u00adplements \na document. The server administrator s needs are met, be\u00adcause servlets can be controlled. The servlet \nimplementors needs are met for small groups of servlets, but not for large groups. Ses\u00adsions must be \ngrouped for communication, so the more each session communicates with other sessions, the more all sessions \nbecome grouped together and controlled by a monolithic master servlet, which defeats the purpose of servlets. \nFigure 4 illustrates an architecture that meets the needs of both the server administrator and servlet \nimplementors. The small gray box in the middle of the .gure represents a kill-safe abstraction that the \nkernel need not trust, but that can be loaded as needed by cooperat\u00ading servlets. This pattern cannot \nbe implemented in existing systems not even systems that support nested tasks or shared memory. With \nnested tasks, the gray-box task must be a sub-task of the left or right task, and therefore subject to \ntermination along with its parent task. With shared memory, either the left or right task must cross \ninto the small box, and it might get terminated while manipulating struc\u00adtures there. Finally, the problem \ncannot be solved by allowing the two tasks to enter the gray box and execute atomically, since the two \ntasks could then collude to starve the rest of the system. For the same reason, the termination of a \ntask cannot be delayed until it leaves the gray box. 2.2 Our Solution Our solution requires either the \nleft or right task to create the gray\u00adbox task initially as a sub-task. Later, when the other task gains \naccess to the gray box, it promotes the box as its own sub-task. As a result, the gray-box task becomes \nmore resistant to termination than either the left or right task alone, though no more resistant than \nthan the tasks combined. If the left task is terminated, the box task is merely suspended. When the right \ntask later accesses the box, it resumes the box task, and safely continues. If both the left and right \ntasks are terminated, the box task becomes both suspended and inaccessible, and there\u00adfore effectively \nterminated. Thus, the system as a whole can protect itself against malicious (or buggy) collaborations \nby terminating both collaborators. Meanwhile, communication channels that are provided by the box protect \nthe left and right tasks from each other, much as kernel-supplied channels protect tasks from each other. \nThis solution combines three lines of work: Our earlier work for nested tasks (i.e., the gray boxes) \nin MzScheme [6] provides the base task model.  The primitives of Concurrent ML [21] enable tasks to \nim\u00adplement communication abstractions that have the same .rst\u00adclass status as kernel abstractions.  \nNew primitives allow modifying the task hierarchy without threatening bystander tasks.  Technically, \nour extension of existing task and concurrency models is modest, and the pattern that we show for kill-safety \nis a straight\u00adforward extension of Concurrent ML patterns once our new prim\u00aditives are given. Our contribution \nlies in the synthesis of these el\u00adements to provide a simple and expressive mechanism for kill-safe abstractions. \nTo our knowledge, it is the .rst such combination to solve the servlet problem described in the previous \nsection (and other problems like it). The servlet problem closely mirrors a problem in the implementa\u00adtion \nof DrScheme s help system. Help pages are written in HTML, and the help system works by running the PLT \nweb server [7] plus a browser that is connected to the server. Although the server and browser could \nexecute as different OS tasks and communi\u00adcate through TCP sockets (as web servers and browsers normally \ndo), production OSes make this architecture surprisingly fragile. Therefore, DrScheme implements its \nown browser, and it runs a web server and a browser directly in its own MzScheme vir\u00adtual machine. The \ntwo parties communicate through a socket-like abstraction whose core is an asynchronous buffered queue. \nThe MzScheme kernel provides no such abstraction, and due to the way that DrScheme is organized, adding \nan intermediate kernel layer for the web browser and server would be prohibitively dif.cult. Furthermore, \nboth the server and browser take advantage of termi\u00adnation for internal tasks (e.g., to cancel a browser \nclick), and those tasks are involved in communication. Such terminations then wreak havoc with the queue \nimplementation. In the new MzScheme, small adjustments to the queue implemen\u00adtation make it kill-safe \nas well as thread-safe. The help system now works reliably with no additional changes to DrScheme, the \nserver, or the browser. At the same time, the kill-safe abstraction does not (and cannot) compromise \ntask control. In particular, when testing DrScheme within DrScheme, we can terminate the inner DrScheme, \nand it reliably terminates the associated help system, including any queue-manager threads. Kill-safe \nbuffered queues are merely the tip of the abstraction ice\u00adberg, but we use this example in the following \nsections to illus\u00adtrate essential techniques for kill-safe abstractions. See Concurrent Programming in \nML by John Reppy [21] for many other example abstractions that can be made kill-safe using our technique. \n 2.3 Abandoned Approaches Before arriving at MzScheme s current primitives for kill-safe ab\u00adstractions, \nwe explored two main alternatives. Restricted atomic sections: As mentioned at the end of Sec\u00adtion 2.1, \nthe kernel cannot allow a task to execute arbitrary code atomically, otherwise it might starve the rest \nof the system. The kernel might, however, allow a task to execute atomically for a short period of time, \nor to execute code that provably terminates in a short time. We abandoned this approach, because we could \nnot .nd a way to de.ne time that makes sense to a programmer. Dy\u00adnamic measurements in terms of clock \nticks or program operations were too sensitive to small program changes, and static methods, based on \nlimiting the code to certain primitive operations, proved insuf.ciently expressive. Transactions with \nrollbacks and commit points: Although a transaction-oriented approach looked promising, and although \nRudys and Wallach have made progress in this direction [23], syn\u00adchronous channels encode directly the \nkind of transactions that seem most useful for our purposes. We therefore abandoned this direction and \nembraced the Concurrent ML primitives as our base.  3 Task Control in MzScheme To provide a more concrete \nexplanation of kill-safe abstractions, we must .rst introduce some terminology and basic task constructs. \nIn this section, we present the constructs as they are implemented in MzScheme.1 MzScheme s support for \ntasks encompasses threads of execution, task-speci.c state, per-task resource control, per-task GUI modal\u00adities, \nand more. Instead of supplying a monolithic process con\u00adstruct, however, MzScheme supports the many different \nfacets of a process through many speci.c constructs [6]. With respect to kill-safe abstractions, the \nonly relevant facets are threads of execu\u00adtion, resource control as it relates to thread termination, \nand thread\u00adspeci.c state as it relates to determining the resource controller. 3.1 Threads The spawn \nprocedure takes a function of no arguments and calls the function in a new thread of execution. The thread \nterminates when the function returns. Meanwhile, spawn returns a thread descriptor to its caller. (define \nt1 (spawn (lambda () (printf \"Hello\")))) (define t2 (spawn (lambda () (printf \"Nihao\")))) ;; prints Hello \nand Nihao , possibly interleaved 3.2 Resource Control A custodian is a resource controller in MzScheme. \nWhenever a thread is created, a network socket is opened, a GUI window is created, or any other primitive \nresource is allocated, it is placed under the control of the current custodian. A thread can create and \ninstall a new custodian, but the newly created custodian is a sub\u00adcustodian that is controlled by the \ncurrent custodian. The only operation on a custodian is custodian-shutdown-all, which suspends all threads, \ncloses all sockets, destroys all GUI windows, etc. that are controlled by the custodian, and prevents \nany further resources allocated to the custodian. The shut-down 1Some functions are de.ned in the (lib \n\"cml.ss\") module. command also propagates to any controlled sub-custodians. After a custodian is shut \ndown, it drops references to primitive resources, and the memory for such objects can be reclaimed by \nthe garbage collector.2 Unlike other objects, a thread can have multiple cus\u00adtodians (added with thread-resume, \nwhich we describe later, in Section 3.3). A thread is suspended only when all of its controlling custodians \nare shut down. The make-custodian procedure creates a new custodian. The parameterize form with current-custodian \nsets the current custodian during the evaluation of an expression. In particular, parameterize can be \nused to install a custodian while creating a new thread, and the new thread is then controlled by the \ncustodian. (define cust (make-custodian)) (define (lots-of-work ) .... ) (parameterize ([current-custodian \ncust ]) (spawn lots-of-work )) (custodian-shutdown-all cust ); stops lots-of-work When a thread is created, \nit inherits the current custodian from its creating thread. Thus, assuming that lots-of-work is not closed \nover the original custodian, (custodian-shutdown-all cust ) reliably terminates the task that executes \nlots-of-work no mat\u00adter how many threads that it spawns, sockets that it opens, GUI windows that it creates, \nor sub-custodians that it generates. The current custodian for a particular thread is not necessarily \nthe same as the thread s controller. The thread s controlling custodian is determined when the thread \nis spawned, but the current custodian (for controlling newly allocated resources) can be changed by the \nthread at any time through parameterize. 3.3 Thread Resumption The thread-resume primitive is the key \nto implementing kill\u00adsafe abstractions. Given a single thread argument, MzScheme s thread-resume function \nresumes the thread if it is suspended: (define t (spawn lots-of-work )) (thread-suspend t ); suspends \nlots-of-work (thread-resume t ); resumes lots-of-work The thread-resume function can only resume a thread \nthat has a custodian. If a thread s only custodian has been shut down, the resume request has no effect. \n(define cust (make-custodian)) (define t (parameterize ([current-custodian cust ]) (spawn lots-of-work \n))) (custodian-shutdown-all cust ); stops lots-of-work (thread-resume t ); doesn t resume lots-of-work \nThe thread-resume function accepts an optional second argument to provide a new custodian to the thread \nbefore attempting to re\u00adsume it. The optional argument can be either a custodian, in which case it is \nadded to the thread s set of controllers, or another thread, in which case this other thread s custodians \nare added to the set of controllers for the .rst thread. (define cust (make-custodian)) (define cust2 \n(make-custodian)) (define t1 (parameterize ([current-custodian cust1 ]) (spawn lots-of-work ))) (define \nt2 (parameterize ([current-custodian cust2 ]) (spawn lots-of-work ))) 2Shutting down a resource removes \ninternal references, which frees most of the memory associated with the resource. (custodian-shutdown-all \ncust1 ); suspends t1 (thread-resume t1 ); doesn t resume t1 (thread-resume t1 t2 ); resumes t1 , adds \ncust2 (custodian-shutdown-all cust2 ); stops t1 and t2 If the second argument to thread-resume is a thread, \nthen in ad\u00addition to adding a custodian to the .rst thread, the resume yokes the .rst thread to second \nas follows: Whenever the second thread is resumed, the .rst thread is also resumed.  Whenever the second \nthread acquires a new custodian, the .rst thread also acquires the custodian.  The overall effect of \n(thread-resume t1 t2 ) is to ensure that t1 survives at least as long as t2 assuming that t1 is suspended \nonly indirectly via custodian-shutdown-all. This effect holds because a custodian-based suspension of \nt1 will necessarily also suspend t2 , since t1 can only run out of custodians if t2 also runs out. Meanwhile, \nif both are suspended and t2 is resumed, then so is t1 . The two-argument thread-resume allows two threads \nt1 and t2 share an object that embeds a thread t . In that case, (thread-resume tt1 ) plus (thread-resume \ntt2 ) makes the embedded thread t act as though it has no controlling custo\u00addian, at least as far as \nt1 and t2 can tell, since t runs whenever t1 or t2 runs. This combination is the key to implementing \na kill-safe version of the queue abstraction. Furthermore, the two-argument thread-resume does not enable \na set of processes to conspire and escape termination. The processes may share their custodians, but \nafter all of the custodians are shut down, no thread created by the processes can execute without out\u00adside \nhelp. Indeed, in the absence of outside references, the process s threads will be garbage-collected. \n 4 Sketch for a Kill-Safe Queue The primitive synchronization abstraction in MzScheme is a syn\u00adchronous \nchannel [11, 15], which allows two tasks to rendezvous and exchange a single value. This built-in abstraction \nis kill-safe, in that the termination of a task on one end of the channel does not en\u00addanger the task \non the other end of the channel though, obviously, no further communication will take place. In this \nsection, we consider the implementation of a kill-safe queue (a.k.a. asynchronous buffered channel). \nValues sent into the queue are parceled out one-by-one to receivers. A send to a queue never blocks, \nexcept to synchronize access to the internal list of queued items. A receive blocks only when the queue \nis empty, or to syn\u00adchronize internal access. (define q (queue )) (queue-send q \"Hello\") (queue-send \nq \"Bye\") (queue-recv q ); . \"Hello\" (queue-recv q ); . \"Bye\" Figure 5 sketches an implementation of queues. \nEach queue con\u00adsists of a channel in-ch for putting items into the queue, a channel out-ch for getting \nitems out of the queue, and a manager thread running serve to pipe items from in-ch to out-ch . Even \nwith only this sketch, we can see that the queue is not yet kill-safe. Suppose that a thread t1 creates \nq by calling (queue ). Suppose further that t1 is controlled by custodian c1 , and that q is made available \nto a thread t2 controlled by custodian c2 : ;; t1 , controlled by c1 ;; t2 , controlled by c2 (define \nq (queue )) (send-to-other q ) (define q (get-from-other )) ;; suspend threads of c1 ;; stuck q was \nsuspended by c1 (queue-send q 10) Since t1 creates q , the queue s internal thread mgr-t is controlled \nby c1 . Suspending all threads of c1 suspends both t1 and mgr-t . As a result, the send in t2 gets stuck \nand a send into a buffered queue should never get stuck. We might attempt to .x the problem with a resume \nof the queue s thread before each queue operation. A simple resume is not enough, however; between the \ntime that t2 resumes mgr-t and the time that it performs its action on the queue, another thread might \nre-suspend all threads of c1 , thus re-suspending mgr-t . The solution is (thread-resume mgr-t t2 ), \nwhich not only re\u00adsumes the queue thread, but also adds t2 s custodian, c2 , as a con\u00adtroller of mgr-t \n. Afterward, a mere suspension of c1 s threads does not suspend mgr-t , since it is also controlled by \nc2 . Since mgr-t is not accessible outside the queue implementation, it can be suspended only by shutting \ndown both of its custodians, c1 and c2 . In that case, then both t1 and t2 will be suspended as well \nas mgr-t which is precisely the desired behavior if the custodians were shut down to terminate tasks \nt1 and t2 . In other words, mgr-t acquires no more priviledge to run than the sum of t1 and t2 s priviledges. \nIf the suspension is not intended to terminate the task, and if t2 is later resumed, then mgr-t is also \nresumed, due to the chaining installed by (thread-resume mgr-t t2 ). More gen\u00aderally, by guarding each \nqueue operation with (thread-resume mgr-t (current-thread)) we ensure that mgr-t runs when\u00adever a queue-using \nthread runs. Figure 6 shows revisions of the queue implementation with these guards, which make it kill-safe. \nThis example demonstrates both how kill-safe abstractions are pos\u00adsible, and how abstractions can be \nmade kill-safe with relative ease. Nevertheless, it does not demonstrate the full power of our primi\u00adtives \nfor de.ning kill-safe abstractions. For such a demonstration, we must introduce MzScheme s embedding \nof the Concurrent ML primitives, so that we can build more .exible abstractions. 5 Review of Concurrent \nML This section provides a brief tutorial on MzScheme s embedding of the Concurrent ML [21] primitives. \nThe tutorial is intended mainly for readers who are unfamiliar with Concurrent ML. The primitives support \nsynchronization among tasks via .rst-class events. A few kinds of events are built in, such as events \nfor send\u00ading or receiving values through a channel. More importantly, the primitives enable the construction \nof entirely new kinds of events that have the same .rst-class status as the built-in events. sync : a-event \n. a The sync procedure takes an event and blocks until the event is ready to supply a value. Some primitives \nprovide a source of events. For example, thread-done-evt takes a thread descriptor and re\u00ad ;; queue : \n. a-queue ;; queue-send : a-queue a . void ;; queue-recv : a-queue . a ;; Declare an opaque q record \nwith two .elds; the constructor ;; is make-q , and the .eld selectors are q-in-ch and q-out-ch (define-struct \nq (in-ch out-ch )) ;; make-q : a-channel a-channel . a-queue (define (queue ) (define in-ch (channel)) \n; to accept send s into queue (define out-ch (channel)) ; to supply recv s from queue ;; A manager thread \nloops with serve (define (serve items ) ;; Handle send s and recv s .... ;; Loop with new queue items: \n(serve new-items )) ;; Create the manager thread (spawn (lambda () (serve (list)))) ;; Return a queue \nas an opaque q record (make-q in-ch out-ch )) (define (queue-send q v ) ;; Send v to (q-in-ch q ) .... \n) (define (queue-recv q ) ;; Receive from (q-out-ch q ) .... ) Figure 5. Implementation sketch for a \nqueue (define-struct q (in-ch out-ch mgr-t )) ;; make-q : a-channel a-channel thread . a-queue (define \n(queue ) .... ;; Create a manager thread (define mgr-t (spawn (lambda () (serve (list))))) ;; The q record \nnow refers to the manager thread (make-q in-ch out-ch mgr-t )) (define (queue-send q v ) ;; Make sure \nthe manager thread runs (thread-resume (q-mgr-t q ) (current-thread)) ;; Send v to (q-in-ch q ) .... \n) (define (queue-recv q ) ;; Make sure the manager thread runs (thread-resume (q-mgr-t q ) (current-thread)) \n;; Receive from (q-out-ch q ) .... ) Figure 6. A kill-safe queue, revises Figure 5 turns an event that \nis ready (with a void value) when the thread has terminated. ;; thread-done-evt : thread . void-event \n (define t1 (spawn (lambda () (printf \"Hello\")))) (define t2 (spawn (lambda () (printf \"Nihao\")))) (sync \n(thread-done-evt t1 )) ; waits until t1 is done (sync (thread-done-evt t2 )) ; waits until t2 is done \n(printf \"Bye\") ;; prints Hello and Nihao interleaved, then Bye channel : . a-channel channel-recv-evt \n: a-channel . a-event channel-send-evt : a-channel a . void-event The channel procedure takes no arguments \nand returns a chan\u00adnel descriptor. A channel s only purpose is to generate events; the channel-recv-evt \nand channel-send-evt procedures cre\u00adate events for receiving values from the channel and sending values \ninto the channel, respectively. The result of a receive event is a value sent through the channel, and \nthe result of a send event is void. A send event is created with a speci.c value to put into the channel, \nand the event is ready only when a receive event can ac\u00adcept the value simultaneously. Similarly, a receive \nevent is ready only when a send event can provide a value simultaneously. (define c (channel)) (spawn \n(lambda () (sync (channel-send-evt c \"Hello\")))) (sync (channel-recv-evt c )) ; . \"Hello\" Multiple threads \ncan attempt to send or receive through a particu\u00adlar channel concurrently. In that case, the system selects \nthreads arbitrarily (but fairly) to form a send receive pair. (define c (channel)) (spawn (lambda () \n(sync (channel-send-evt c \"Hello\")))) (spawn (lambda () (sync (channel-send-evt c \"Nihao\")))) (sync (channel-recv-evt \nc )) ; . \"Hello\" or \"Nihao\" (sync (channel-recv-evt c )) ; . the other string, ; \"Nihao\" or \"Hello\" choice-evt \n: a-event ... a-event . a-event The choice-evt procedure takes any number of events and com\u00adbines them \ninto a single event. The combining event is ready when one of the original events is ready. If multiple \nevents are ready, one is chosen arbitrarily (but fairly), and the value produced by the combining event \nis the value produced by the chosen event. (define c1 (channel)) (define c2 (channel)) (spawn (lambda \n() (sync (channel-send-evt c1 \"Hello\")))) (spawn (lambda () (sync (channel-send-evt c2 \"Nihao\")))) (define \ncc (choice-evt (channel-recv-evt c1 ) (channel-recv-evt c2 ))) (sync cc ); . \"Hello\" or \"Nihao\" (sync \ncc ); . the other string, \"Nihao\" or \"Hello\" In the above example, even if both sending threads are ready \nwhen the main thread .rst calls sync, only one receive event in cc is chosen, and so it is matched with \nonly one sending thread. The other sending thread remains blocked until the second (sync cc ). wrap-evt \n: a-event (a . \u00df) . \u00df-event The wrap-evt function takes an event and a transformer procedure of one argument, \nand it produces a new event. The new event is ready when the given event is ready, and its value is the \nresult of the transformer procedure applied to the original event s value. (define c1 (channel)) (define \nc2 (channel)) (spawn (lambda () (sync (channel-send-evt c1 \"Hello\")))) (spawn (lambda () (sync (channel-send-evt \nc2 \"Nihao\")))) (sync (choice-evt (wrap-evt (channel-recv-evt c1 ) (lambda (x ) (list x \"from 1\"))) (wrap-evt \n(channel-recv-evt c2 ) (lambda (x ) (list x \"from 2\"))))) ;; . (list \"Hello\" \"from 1\") or (list \"Nihao\" \n\"from 2\") guard-evt :(. a-event) . a-event An event created by guard-evt encapsulates a procedure that \nis called when sync is applied to the event. The procedure s result is an event to use to in place of \nthe guard event for the sync. For ex\u00adample, assume that current-time produces the current time, and that \ntime-evt produces an event that is ready at a given absolute time. Then, guard-evt can be used to construct \na timeout event. ;; current-time : . num ;; time-evt : num . event (define one-sec-timeout (guard-evt \n(lambda () (time-evt (+ 1 (current-time)))))) (sync one-sec-timeout ); . void, one second later (sync \none-sec-timeout ); . void, another second later The result from guard-evt might be best described as \nan event generator instead of an event, but this generator can be used anywhere than an event can be \nused. Event generation is im\u00adportant for one-sec-timeout , which must construct an alarm time based on \nthe time that one-sec-timeout is used, not when one-sec-timeout is created. nack-guard-evt :(void-event \n. a-event) . a-event The nack-guard-evt function generalizes guard-evt. For nack-guard-evt, the given \nguard procedure must accept a sin\u00adgle argument. The argument is a Negative ACKnowledgment event that \nbecomes ready if the guard-generated event is not cho\u00adsen by sync usually because the event is combined \nwith others using choice-evt. (sync (choice-evt (wrap-evt one-sec-timeout (lambda (void ) \"Hello\")) (nack-guard-evt \n(lambda (nack ) ;; Start a thread to watch nack (spawn (lambda () (sync nack ) (printf \"nack\"))) ;; This \nevent is never ready (channel-recv-evt (channel))))))) ; . \"Hello\" ;; Meanwhile, nack is printed Each \ntime sync is applied to a NACK-guarded event, the guard procedure is called with a newly generated NACK \nevent. Thus, a NACK event becomes ready only when a speci.c guard-generated event is not chosen in a \nspeci.c sync call. We defer a complete de.nition of not chosen to Section 7, fol\u00adlowing a motivating \nexample. 6 Queue: Complete and Improved Having reviewed the Concurrent ML primitives, we are almost \nready to complete the implementation sketch of queues from Sec\u00adtion 4. First, however, we re.ne the queue \nabstraction to better match the programming idioms of Concurrent ML. This re.nement helps demonstrate \nthat our strategy for kill-safety applies to other Concurrent ML abstractions. After showing the implementation \nof the .rst improved queue abstraction, we improve the abstraction one step further to demonstrate an \nadditional key idiom. ;; queue : . a-queue ;; queue-send-evt : a-queue a . void-event ;; queue-recv-evt \n: a-queue . a-event (define-struct q (in-ch out-ch mgr-t )) ;; make-q : a-channel a-channel thread . \na-queue (define (queue ) (define in-ch (channel)) ; to accept send s into queue (define out-ch (channel)) \n; to supply recv s from queue ;; A manager thread loops with serve (define (serve items ) (if (null? \nitems ) ;; Nothing to supply a recv until we accept a send (serve (list (sync (channel-recv-evt in-ch \n)))) ;; Accept a send or supply a recv , whichever is ready (sync (choice-evt (wrap-evt (channel-recv-evt \nin-ch ) (lambda (v ) ;; Accepted a send ; enqueue it (serve (append items (list v ))))) (wrap-evt (channel-send-evt \nout-ch (car items )) (lambda (void ) ;; Supplied a recv ; dequeue it (serve (cdr items )))))))) ;; Create \nthe manager thread (define mgr-t (spawn (lambda () (serve (list))))) ;; Return a queue as an opaque q \nrecord (make-q in-ch out-ch mgr-t )) (define (queue-send-evt q v ) (guard-evt (lambda () ;; Make sure \nthe manager thread runs (thread-resume (q-mgr-t q ) (current-thread)) ;; Channel send (channel-send-evt \n(q-in-ch q ) v )))) (define (queue-recv-evt q ) (guard-evt (lambda () ;; Make sure the manager thread \nruns (thread-resume (q-mgr-t q ) (current-thread)) ;; Channel receive (channel-recv-evt (q-out-ch q ))))) \nFigure 7. Implementation of a kill-safe queue 6.1 Queue Actions as Events Our original queue sketch provided \nqueue-send and queue-recv functions that block until the corresponding action completes. We should instead \nprovide queue-send-evt and queue-recv-evt functions that generate events. With events, a programmer can \nin\u00adcorporate queues in future synchronization abstractions, which may need to select among multiple blocking \nactions. (define q (queue )) (sync (queue-send-evt q \"Hello\")) (sync (queue-send-evt q \"Bye\")) (sync \n(queue-recv-evt q )) ; . \"Hello\" (sync (queue-recv-evt q )) ; . \"Bye\" Figure 7 shows the complete implementation \nof improved, kill-safe queues: The queue function creates a thread to manage the internal list of values. \nAccess to the internal list is thus implicitly single-threaded, avoiding race conditions. When the queue \nis neither empty nor full, the queue-managing thread uses choice-evt to select among the send and receive \nactions. If both actions become enabled at once, one or the other is chosen atomically and fairly.  \nIn the manager thread, wrap-evt meshes with choice-evt to implement a dispatch for whichever action becomes \nready.  The queue-send-evt function guards its result event with a use of thread-resume. The guard ensures \nthat the man\u00adager thread runs to service the send. The queue-recv-evt similarly guards its result.  \nIf a queue becomes unreachable, its manager thread is garbage collected. More generally, when a thread \nbecomes permanently blocked because all objects that can unblock it become unreach\u00adable, the thread itself \nbecomes unreachable, and its resources can be reclaimed by the garbage collector. To a consumer of the \nabstraction, the values produced by queue , queue-recv-evt , and queue-send-evt have the same .rst-class \nstatus as values produced by channel, channel-recv-evt, and channel-send-evt. For example, queue send \nand receive events can be multiplexed with other events (using choice-evt) in build\u00ading additional abstractions. \n 6.2 Selective Dequeue In DrScheme s help system, a queue is used in place of a socket that listens for \nconnections. The queue abstraction might also be useful for handling messages to GUI objects, such as \na mouse-click messages and refresh messages. A GUI message queue, however, must support a selective dequeuing. \nFor example, a task might wish to handle only refresh messages posted to the queue, leaving mouse-click \nmessages intact. Unfortunately, selective dequeue cannot be implemented by de\u00adqueuing a message, applying \na predicate, and then re-posting the message if the predicate fails; re-posting the unwanted message \nchanges its order in the queue with respect to other messages. To support selective dequeue, we must \nmodify the server so that it accepts dequeue requests with a corresponding predicate, and then satis.es \na request only when an item in the queue matches the pred\u00adicate. On the client side, the selective receive \nevent must be guarded so that it sends a request to the server, then accepts a result through a newly \ncreated channel. The new channel ties together the request and the result, so that a result is sent to \nthe correct receiver. Figure 8 shows a revision of the queue implementation to sup\u00adport selective dequeue. \nThe manager thread still accepts send s through in-ch , but it no longer supplies queued items to a .xed \nout-ch channel. Instead, the manager thread accepts receive re\u00adquests through req-ch , and it keeps a \nlist of the requests. While the manager waits for sends and additional receive requests, it also services \nrequests for which a matching item is available. One problem with this implementation is that the manager \nthread executes an arbitrary predicate procedure that is supplied by a client of the queue. A client \ncould supply a predicate that does not return or that suspends the current thread, thus incapacitat\u00ading \nthe server thread. One solution to this problem is to change msg-queue-recv-evt so that it accepts only \nsimple predicates, ;; msg-queue : . a-msg-queue ;; msg-queue-send-evt : a-msg-queue a . void-event ;; \nmsg-queue-recv-evt : a-msg-queue (a . bool) . a-event (define-struct q (in-ch req-ch mgr-t )) ;; make-q \n: a-channel a req-channel thread . a-queue (define-struct req (pred out-ch )) ;; make-req :(a . bool) \na-channel . a-req (define (msg-queue ) (define in-ch (channel)) (define req-ch (channel)) (define never-evt \n(channel-recv-evt (channel))) (define (serve items reqs ) (sync (apply choice-evt ;; Maybe accept a send \n(wrap-evt (channel-recv-evt in-ch ) (lambda (v ) ;; Accepted a send ; enqueue it (serve (append items \n(list v )) reqs ))) ;; Maybe accept a recv request (wrap-evt (channel-recv-evt req-ch ) (lambda (req \n) ;; Accepted a recv request; add it (serve items (cons req reqs )))) ;; Maybe service a recv request \nin reqs (map (make-service-evt items reqs ) reqs )))) (define (make-service-evt items reqs ) (lambda \n(req ) ;; Search queue items using pred (find-first-item (req-pred req ) items (lambda (item ) ;; Found \nan item; try to service req (wrap-evt (channel-send-evt (req-out-ch req ) item ) (lambda (void ) ;; \nServiced, so remove item and request (serve (remove item items ) (remove req reqs ))))) (lambda () ;; \nNo matching item to service req never-evt )))) (define mgr-t (spawn (lambda () (serve (list) (list))))) \n(make-q in-ch req-ch mgr-t )) (define (msg-queue-send-evt q v ) ;; Same as queue-send-evt in Figure \n7 .... ) (define (msg-queue-recv-evt q pred ) (guard-evt (lambda () (define out-ch (channel)) ;; Make \nsure the manager thread runs (thread-resume (q-mgr-t q ) (current-thread)) ;; Request for an item matching \npred with reply to out-ch (sync (channel-send-evt (q-req-ch q ) (make-req pred out-ch ))) ;; Result arrives \non out-ch (channel-recv-evt out-ch )))) Figure 8. Queue with selective dequeue, .rst attempt such as \nodd? and even?, that are known to be harmless. We show how to allow arbitrary predicates in Section 8.1. \nEven if we constrain pred , the implementation of selective de\u00adqueue contains a space leak. The following \nexample illustrates the problem: (define q (msg-queue )) (sync (msg-queue-send-evt q 1)) (sync (msg-queue-send-evt \nq 2)) (sync (choice-evt (msg-queue-recv-evt q odd?) (msg-queue-recv-evt q even?))) The sync call sends \ntwo requests to the server. One is serviced, and the program continues. Meanwhile, a leftover request \nremains with the server. The request will never be successfully serviced, because no sync waits on the \nassociated out-ch . Still, the request is stuck in the internal reqs list, and leftover requests can \npile up over time, degrading performance and wasting resources. A similar problem occurs if the thread \nmaking a request is terminated. To avoid this problem, the server needs to know when a client sync has \nabandoned a dequeue request. Figure 9 shows how nack-guard-evt can provide this information. The msg-queue-recv-evt \nfunction now sends the manager a gave up event in addition to a result channel. The manager thread uses \nthe new event to keep the request list clean. The msg-queue example illustrates a particular Concurrent \nML id\u00adiom: a client server protocol where the client sends a request to the server, but may withdraw \nthe request before it can be satis.ed. Withdrawal reliably prevents acceptance and vice-versa, due to \nthe rendezvous associated with a channel transfer (i.e., the sender and receiver must simultaneously \nagree to the transfer of a result). The request idiom poses an extra challenge for kill-safety. A client \ncan be terminated at any point in the request cycle, so we must de.ne nack-guard-evt so that it handles \nthis possibility. The next section completes our explanation of MzScheme s primitives with a suitable \nde.nition of nack-guard-evt.  7 Termination and NACKs Recall that the event provided to a guard procedure \nby nack-guard-evt becomes ready if the guard-generated event is not chosen. MzScheme extends the Concurrent \nML de.nition of not chosen so that it includes all of the following cases, which cover all of the ways \nthat a thread can abandon an event: The sync call chooses an event other than the one returned by the \nguard.  Control escapes from the sync call through an exception or continuation jump. The exception \nor jump may have been triggered through a break signal (discussed further in Sec\u00adtion 8.2), by another \nguard involved in the same sync,or even by the guard procedure that received the NACK event. Con\u00adtinuation \njumps back into a guard are always blocked by our de.nition of nack-guard-evt, so multiple escapes are \nnot possible.  The syncing thread terminates (i.e., it is suspended and un\u00adreachable).  In the code \nfrom Figure 9, the event produced by msg-queue-recv-evt can be used in an arbitrary client context, so \nall of the above cases are possible. For example, the context might begin a sync on the event in a particular \nthread, then terminate the thread during the sync. If the guard procedure is executing at the time of \ntermination, and if termination occurs before the nested sync completes a send to (q-req-ch q ), then \nthe server never becomes aware of the request, so the server is left in a consistent state. If termination \noccurs after the nested sync but before the outer sync chooses the guard s result (channel-recv-evt out-ch \n), the server has already received gave-up-evt , and therefore knows to abandon the request (because \ngave-up-evt becomes ready). Finally, if termination occurs after a successful outer sync on (channel-recv-evt \nout-ch ), then the server has completed the request, so termination does not affect the server. MzScheme \ns nack-guard-evt corresponds to Concurrent ML s withNack. An earlier version [19] of Concurrent ML offered \nwrapAbort, instead, and a later presentation [21] explains how withNack can be implemented with wrapAbort. \nOur de.nition of not chosen does not allow such an implementation, and thus strengthens the argument \nthat withNack is the right operation to designate as primitive.  8 Beyond Kill-Safety To further explain \nour design choices, we show in the following sec\u00adtions how custodians and events solve problems besides \nkill-safety, and how they interact with cooperative termination. 8.1 Custodians and Events At Work, Again \nAs noted in Section 6.2, our initial implementation of selective de\u00adqueue is unsafe; the server executes \narbitrary predicate procedures that are supplied by clients, which might damage the server thread. For \nexample, a thread can provide a predicate to the server that sus\u00adpends the current thread, thus disabling \nthe queue. (define q (msg-queue )) (sync (msg-queue-send-evt q 1)) (spawn (lambda () (define (die x ) \n(thread-suspend (current-thread))) (sync (msg-queue-recv-evt q die )))) (sync (msg-queue-recv-evt q odd?)) \n; probably stuck To avoid this problem, the server can run the predicate in a new thread, which prevents \nthe predicate from harming the server thread. Moreover, the new thread should be executed under a custo\u00addian \nthat is supplied by the client thread (as part of a request), which means that the predicate-running \nthread can execute only when the client is still allowed to execute. This arrangement is analogous to \na remote procedure call, except that remoteness is implemented by using another process s custodian. \nThe server cannot simply wait in turn for each remote thread to complete its work, because a predicate \nmight not terminate. Instead, the server must sync on an event that corresponds to completion of the \nremote thread. When the event delivers a list of acceptable items, they can be added to the request. \nIn later iterations, a remote thread is started for the request only if the list of known acceptable \nitems becomes empty. To implement this change, we modify only make-service-evt and msg-queue-recv-evt \nas shown in Figure 10. The change to msg-queue-recv-evt adds a custodian and empty list (of known (define-struct \nreq (pred out-ch gave-up-evt )) ;; make-req :(a . bool) a-channel void-event . a-req (define (msg-queue \n) .... (define (serve items reqs ) .... ;; Add make-abandon-evt events (append (map (make-service-evt \nitems reqs ) reqs ) (map (make-abandon-evt items reqs ) reqs ))))) .... (define (make-abandon-evt items \nreqs ) (lambda (req ) ;; Event to detect that the receiver gives up (wrap-evt (req-gave-up-evt req ) \n (lambda (void ) ;; Receiver gave up; remove request (serve items (remove req reqs )))))) .... (define \n(msg-queue-recv-evt q pred ) (nack-guard-evt (lambda (gave-up-evt ) (define out-ch (channel)) (thread-resume \n(q-mgr-t q ) (current-thread)) ;; As before, but also send the server gave-up-evt (sync (channel-send-evt \n(q-req-ch q ) (make-req pred out-ch gave-up-evt ))) (channel-recv-evt out-ch )))) Figure 9. Revision \nto Figure 8 acceptable items) to the request. The new make-service-evt checks whether a particular request \nhas at least one known ac\u00adceptable item. If the request has none, then service-evt uses ok-items-evt \nto call the predicate remotely on the current list of items; if those items are received from the remote \ncall, the request s list is updated. Otherwise, the request has known acceptable items, and make-service-evt \ncreates an event to service the request with the .rst acceptable item. When an item is delivered in this \nway, it is removed from the current list of queued items, and also removed from every remaining request \ns list of acceptable items. This example illustrates how custodians and Concurrent ML s prim\u00aditives complement \neach other beyond kill-safety. These additional uses increase our con.dence that the combination is general, \nand therefore a good approach to the speci.c problem of kill-safety.  8.2 Cooperative Termination Cooperative \ntermination allows a thread to execute clean-up actions (e.g., .ush a .le buffer, update a shared GUI \ndisplay) before ter\u00adminating. Cooperative termination is useful for many of the same reasons as uncooperative \ntermination, though only when a process can be trusted to exit quickly. MzScheme s break-thread function \nenables cooperative termi\u00adnation. This function takes a thread descriptor and sends the thread a break \nsignal. The signal is analogous to a Unix process signal, but the break signal is manifest in the target \nthread as an asynchronous exception, much as in Concurrent Haskell [14]. (define t (spawn lots-of-work \n)) (break-thread t ); possibly interrupts lots-of-work (define-struct req (pred out-ch gave-up-evt cust \nok-items )) ;; make-req :(a. bool) a-channel void-event ;; custodian a-list . a-req (define (msg-queue \n) .... (define (make-service-evt items reqs ) (lambda (req ) (if (null? (req-ok-items req )) ;; Look \nfor items acceptable to pred (wrap-evt (ok-items-evt req items ) (lambda (ok-items ) ;; Got a list of \nacceptable items, so update req (serve items (cons (new-ok-items req ok-items ) (remove req reqs ))))) \n;; Use .rst acceptable item to service req (wrap-evt (channel-send-evt (req-out-ch req ) (car (req-ok-items \nreq ))) (lambda (void ) ;; Serviced, so remove item and request (define item (car (req-ok-items req ))) \n(serve (remove item items ) (map (remove-ok-item item ) (remove req reqs )))))))) (define (ok-items-evt \nreq items ) ;; New thread runs pred and delivers a list to items-ch (define items-ch (channel)) (parameterize \n([current-custodian (req-cust req )]) (spawn (lambda () (define ok-items (filter (req-pred req ) items \n)) (sync (channel-send-evt items-ch ok-items ))))) (channel-recv-evt items-ch )) (define (remove-ok-item \nitem ) ;; Given a req , remove item from its list of acceptable items (lambda (req ) (new-ok-items req \n(remove item (req-ok-items req ))))) (define (new-ok-items req ok-items ) (make-req (req-pred req )(req-out-ch \nreq ) (req-gave-up-evt req )(req-cust req ) ok-items )) .... (define (msg-queue-recv-evt q pred ) (nack-guard-evt \n(lambda (gave-up-evt ) (define out-ch (channel)) (thread-resume (q-mgr-t q ) (current-thread)) ;; Include \na custodian and an initially empty list of ;; known acceptable items (sync (channel-send-evt (q-req-ch \nq ) (make-req pred out-ch gave-up-evt (current-custodian) (list)))) ;; Result arrives on out-ch (channel-recv-evt \nout-ch )))) Figure 10. Revision to Figure 9 for arbitrary predicates Since breaks are for cooperative \ntermination, a thread is allowed to disable breaks by using parameterize with break-enabled.Ifa break \nsignal is sent to a thread when breaks are disabled, the signal ;; swap-channel : . a-swap-channel ;; \nswap-evt : a-swap-channel a. a (define-struct sc (ch )) ;; make-sc : a-req-channel . a-swap-channel \n (define-struct req (vch )) ;; make-req : aa-channel . a-req (define (swap-channel )(make-sc (channel))) \n (define (swap-evt sc v ) (guard-evt (lambda () (define in-ch (channel)) (choice-evt ;; Maybe act as \nserver and receive req (wrap-evt (channel-recv-evt (sc-ch sc )) (lambda (req ) ;; Reply to req (sync \n(channel-send-evt (req-ch req ) v )) (req-v req ))) ;; Maybe act as client and send req (wrap-evt (channel-send-evt \n(sc-ch sc )(make-req v in-ch )) (lambda (void ) ;; Receive answer to req (sync (channel-recv-evt in-ch \n)))))))) Figure 11. A break-safe implementation of swap channels is delayed until breaks are re-enabled \nin the thread. A break signal has no effect if the target thread has a delayed break already. MzScheme \nautomatically disables breaks in certain contexts, so that many synchronization abstractions are naturally \nbreak-safe. One such abstraction is a swap channel [21, pg. 59], as shown in Fig\u00adure 11. A swap channel \nis like a channel, except that both syn\u00adchronizing threads provide a value to the other. Implementing \nthis two-way channel with one-way channels requires two phases. In the .rst phase, the thread that is \nelected to act as the client sends its value to the other thread, which is elected as the server. In \nthe second phase, the server thread sends its value back to the client thread. The client and server \nthreads are elected through sync s non-deterministic choice. When two threads complete the .rst phase, \nthey are committed to the swap. In other words, a break should not interrupt the second phase. In Figure \n11 s implementation of swap-evt , a break cannot interrupt the second phase, because the second phase \nis in a wrap procedure. MzScheme implicitly disables breaks from time that sync chooses an event until \nthe event s wrap procedure completes. Although the body of a wrap procedure may explicitly re-enable \nevents, this example also illustrates why breaks are not implicitly enabled by sync, unlike Concurrent \nHaskell s takeMVar.If sync implicitly enabled breaks, then the second phase of a swap might be skipped \nafter the threads have committed to swapping. For cases where a programmer would like to re-enable breaks \nwhile sync blocks, MzScheme provides a separate sync/enable-break function. This function enables breaks \nsuch that either a break exception is raised or an event is chosen, but not both. (Merely wrapping a \nsync with parameterize to enable breaks does not achieve sync/enable-break s exclusive-or behavior. With \nparameterize and sync, the break may occur after an event is chosen but before breaks are re-disabled, \nthus allowing both choice and a break.) In our experience, sync/enable-break s exclusive\u00ador guarantee \nis important for building break-safe code on top of synchronization abstractions. In the same way that \na synchronization abstraction is re\u00adsponsible for providing an appropriate commit point so that events \ncan be combined with others through choice-evt each synchronization abstraction is responsible for preserving \nsync/enable-break s exclusive-or guarantee. For example, adding (parameterize ([break-enabled #t]) #f) \nto Fig\u00adure 11 after (sync (channel-send-evt (req-ch req ) v )) would defeat sync/enable-break s exclusive-or \nguarantee, though without damaging the swap abstraction in any other way. Many kill-safe synchronization \nabstractions are naturally break\u00adsafe, too. For example, the queue implementations of Figure 7 and Figure \n10 interact perfectly with cooperative termination, including sync/enable-break. Unfortunately, sync/enable-break \ns exclusive-or guarantee is not preserved by a kill-safe version of the swap abstraction. In the kill-safe \nimplementation, which is shown in Figure 12, a manager thread pairs swapping clients and delivers a value \nto each client. From the manager perspective, two clients are committed to swap as soon as they are both \nknown; from the client perspective, the swap commits when the manager delivers a value. The mismatch \nmeans that a client may be interrupted between the time that the manager commits the swap and the time \nthat the clients receive values, thus defeating an exclusive-or guarantee for sync/enable-break (al\u00adthough \na break still does not damage the abstraction in any other way). This example illustrates how break-safety \nis not necessarily easier than kill-safety, and vice-versa. Although break-safety seems intu\u00aditively \neasier, because a thread can disable breaks during sensitive operations, continuing to execute after \na break introduces concerns that are absent with immediate termination. Future work may sug\u00adgest a way \nto reconcile these forms of termination, or, in the case of swap channels, they may be irreconcilable \ndue to the limitations of channel rendezvous [17].  9 Related Work Many systems provide a mechanism \nfor cooperative interruption of a process, such as thread cancellation in Posix [16], alerts in Modula-3 \n[8], and asynchronous exceptions in Haskell [14] or MzScheme [5]. For applications like our servlets \nexample, how\u00adever, forced termination is necessary, and our work is concerned with kill-safety with respect \nto forced termination. Some previous work addresses the interaction between termination and synchronization \nfor speci.c primitives. Examples include work on monitors in Pilot [18] and remote pointers in Luna [10]. \nTo our knowledge, no previous work addresses the problem of termination with respect to programmer-de.ned \nsynchronization abstractions. Indeed, the problem makes sense only after programmers are given signi.cant \nabstraction capability, which is why our work depends on Concurrent ML [19, 20, 21]. The idea of managing \na resource through a designated thread ap\u00adpears in many contexts, notably in microkernels [4]. Argus \ns (define-struct sc (ch mgr-t )) ;; make-sc : a-req-channel thread . a-swap-channel (define-struct req \n(v ch gave-up )) ;; make-req : aa-channel void-event . a-req (define (swap-channel ) (define ch (channel)) \n(define (serve-first ) ;; Get .rst thread for swap (sync (wrap-evt (channel-recv-evt ch ) serve-second \n))) (define (serve-second a ) ;; Try to get second thread for swap (sync (choice-evt ;; Possibility \n1 got second thread, so swap (wrap-evt (channel-recv-evt ch ) (lambda (b ) ;; Send each thread the \nother s value (send-eventually (req-ch a )(req-v b )) (send-eventually (req-ch b )(req-v a )) (serve-first \n))) ;; Possibility 2 .rst gave up, so start over (wrap-evt (req-gave-up a ) (lambda (void )(serve-first \n)))))) (define (send-eventually ch v ) ;; Spawn a thread, in case ch s thread isn t ready (spawn (lambda \n() (sync (channel-send-evt ch v ))))) (make-sc ch (spawn serve-first ))) (define (swap-evt sc v ) (nack-guard-evt \n(lambda (gave-up ) (define in-ch (channel)) (thread-resume (sc-mgr-t sc ) (current-thread)) (sync (wrap-evt \n(channel-send-evt (sc-ch sc ) (make-req v in-ch gave-up )) (lambda (void ) in-ch )))))) Figure 12. A \nkill-safe implementation of swap channels guardians [13] re.ect a similar idea in the area of persistent, \ndis\u00adtributed computing. Our speci.c use of the thread-manager pattern is typical of Concurrent ML programs, \nbut also reminiscent of the J-Kernel [9] approach, which creates a thread when crossing a trust boundary \nto defend against termination. We extend this idea by adding a mechanism to adjust a thread s execution \ncapability rela\u00adtive to other threads. MzScheme does not provide a way to revoke access to an object, \nas in Luna [10]. It also provides no way to disable code that is asso\u00adciated with a task, as in Rudys \net al. s soft termination [22]. Given a mechanism for disabling code, we conjecture that code fragments \ncould be connected to the custodian hierarchy to prevent a shared abstraction s code from being disabled \nprematurely. The architectures in Figure 1 and 2 (in Section 2) illustrate a trade\u00adoff between ease of \ncommunication and ease of termination, but they are merely the extremes. A variation of the OS-style \narchi\u00adtecture can improve communication by enriching the kernel s set of primitives, as in KaffeOS [1], \nAlta [2], SPIN [3], J-Kernel [9], Luna [10], and Nemesis [12]. In each case, however, the system offers \na .xed set of kill-safe primitives to applications, and our goal is to allow programmer-de.ned kill-safe \nabstractions. 10 Conclusion Many real-world programming tasks require concurrency. Never\u00adtheless, certain \nprogramming models make correct concurrency dif\u00ad.cult, so that programmers speak of thread-safe implementations \nand work hard to ensure that an abstraction is thread-safe. Lan\u00adguages that are speci.cally designed \nfor concurrency, (e.g., Erlang, Concurrent ML) can encourage thread-safe implementations, mak\u00ading them \nthe rule rather than the exception. Indeed, in such lan\u00adguages, concurrency tends to simplify implementations, \nrather than complicate them. Many real-world programming tasks with concurrency also ben\u00ade.t from termination. \nNevertheless, programming systems have not been designed to encourage (or even enable) kill-safe abstrac\u00adtions. \nWe have taken a step in this direction, extending constructs for thread-safe abstractions to enable kill-safe \nabstractions, thus in\u00adcreasing the potential of termination to simplify implementations. Acknowledgements \nWe would like to thank John Reppy and the anonymous reviewers for their comments and suggestions. The \ncode in this paper is available at the following URL: http : //www.cs.utah.edu/plt/kill - safe/ 11 References \n[1] G. Back, W. Hsieh, and J. Lepreau. Processes in KaffeOS: Isolation, resource management, and sharing \nin Java. In Proc. USENIX Conference on Operating Systems Design and Im\u00adplementation, pages 333 346, Oct. \n2000. [2] G. Back, P. Tullmann, L. Stoller, W. C. Hsieh, and J. Lepreau. Java operating systems: Design \nand implementation. In Pro\u00adceedings of the USENIX 2000 Technical Conference, pages 197 210, San Diego, \nCA, June 2000. [3] B. N. Bershad, S. Savage, P. Pardyak, E. G. Sirer, M. Fi\u00aduczynski, D. Becker, S. Eggers, \nand C. Chambers. Extensi\u00adbility, safety and performance in the SPIN operating system. In Proc. ACM Symposium \non Operating Systems Principles, pages 267 284, Dec. 1995. [4] D. L. Black, D. B. Golub, D. P. Julin, \nR. F. Rashid, R. P. Draves, R. W. Dean, A. Forin, J. Barrera, H. Tokuda, G.- R. Malan, and D. Bohman. \nMicrokernel operating system architecture and Mach. Journal of Information Processing, 14(4):442 453, \n1991. [5] M. Flatt. PLT MzScheme: Language Manual, 2004. www.mzscheme.org. [6] M. Flatt, R. B. Findler, \nS. Krishnamurthi, and M. Felleisen. Programming languages as operating systems (or revenge of the son \nof the Lisp machine). In Proc. ACM Interna\u00adtional Conference on Functional Programming, pages 138 147, \nSept. 1999. [7] P. Graunke, S. Krishnamurthi, S. V. D. Hoeven, and M. Felleisen. Programming the Web \nwith high-level program\u00adming languages. In Proc. European Symposium on Program\u00adming, volume 2028 of Lecture \nNotes in Computer Science. Springer-Verlag, 2001. [8] S. P. Harbison. Modula-3. Prentice Hall, 1991. \n[9] C. Hawblitzel, C.-C. Chang, G. Czajkowski, D. Hu, and T. von Eicken. Implementing multiple protection \ndomains in Java. In Proc. of USENIX Annual Technical Conference, pages 259 270, June 1998. [10] C. Hawblitzel \nand T. von Eicken. Luna: a .exible Java pro\u00adtection system. In Proc. USENIX Conference on Operating Systems \nDesign and Implementation, Oct. 2002. [11] C. A. R. Hoare. Communicating Sequential Processes. Prentice-Hall, \nEnglewood Cliffs, NJ, 1985. [12] I. M. Leslie, D. McAuley, R. J. Black, T. Roscoe, P. R. Barham, D. M. \nEvers, R. Fairburns, and E. A. Hyden. The design and implementation of an operating system to sup\u00adport \ndistributed multimedia applications. IEEE Journal on Selected Areas in Communications, 14(7):1280 1297, \nSept. 1996. [13] B. Liskov and R. Schei.er. Guardians and actions: Linguistics support for robust, distributed \nsystems. ACM Transactions on Computing Systems, 5(3):381 404, 1983. [14] S. Marlow, S. L. Peyton Jones, \nA. Moran, and J. H. Reppy. Asynchronous exceptions in Haskell. In Proc. ACM Confer\u00adence on Programming \nLanguage Design and Implementation, pages 274 285, 2001. [15] R. Milner. Communication and Concurrency. \nInternational Series in Computer Science. Prentice Hall, 1989. [16] National Institute of Standards and \nTechnology (U.S.). POSIX: portable operating system interface for computer en\u00advironments, Sept. 1988. \n[17] P. Panangaden and J. H. Reppy. The essence of Concur\u00adrent ML. In F. Nielson, editor, ML with Concurrency: \nDe\u00adsign, Analysis, Implementation and Application, Monographs in Computer Science, pages 5 29. Springer-Verlag, \n1997. [18] D. Redell, Y. Dalal, T. Horsley, H. Lauer, W. Lynch, P. McJones, H. Murray, and S. Purcell. \nPilot: An operating system for a personal computer. Communications of the ACM, 23(2):81 92, Feb. 1980. \n[19] J. H. Reppy. Synchronous operations as .rst-class values. In Proc. ACM Conference on Programming \nLanguage Design and Implementation, pages 250 259, 1988. [20] J. H. Reppy. Higher Order Concurrency. \nPhD thesis, Cornell University, 1992. [21] J. H. Reppy. Concurrent Programming in ML. Cambridge University \nPress, 1999. [22] A. Rudys, J. Clements, and D. S. Wallach. Termination in language-based systems. ACM \nTransactions on Information and System Security, 5(3):138 168, 2002. [23] A. Rudys and D. S. Wallach. \nTransactional rollback for language-based systems. In Proc. International Conference on Dependable Systems \nand Networks, June 2002. [24] Soper, P., speci.cation lead. JSR 121: Application isolation API speci.cation, \n2003. http://www.jcp.org/.  \n\t\t\t", "proc_id": "996841", "abstract": "When an individual task can be forcefully terminated at any time, cooperating tasks must communicate carefully. For example, if two tasks share an object, and if one task is terminated while it manipulates the object, the object may remain in an inconsistent or frozen state that incapacitates the other task. To support communication among terminable tasks, language run-time systems (and operating systems) provide kill-safe abstractions for inter-task communication. No kill-safe guarantee is available, however, for abstractions that are implemented outside the run-time system.In this paper, we show how a run-time system can support new kill-safe abstractions without requiring modification to the run-time system, and without requiring the run-time system to trust any new code. Our design frees the run-time implementor to provide only a modest set of synchronization primitives in the trusted computing base, while still allowing tasks to communicate using sophisticated abstractions.", "authors": [{"name": "Matthew Flatt", "author_profile_id": "81100490544", "affiliation": "University of Utah", "person_id": "PP39045354", "email_address": "", "orcid_id": ""}, {"name": "Robert Bruce Findler", "author_profile_id": "81100028925", "affiliation": "University of Chicago", "person_id": "PP14022884", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996849", "year": "2004", "article_id": "996849", "conference": "PLDI", "title": "Kill-safe synchronization abstractions", "url": "http://dl.acm.org/citation.cfm?id=996849"}