{"article_publication_date": "06-09-2004", "fulltext": "\n Vectorization for SIMD Architectures with Alignment Constraints Alexandre E. Eichenberger Peng Wu Kevin \nO Brien IBM T.J. Watson Research Center Yorktown Heights, NY {alexe,pengwu,caomhin}@us.ibm.com ABSTRACT \nWhen vectorizing for SIMD architectures that are commonly employed by today s multimedia extensions, \none of the new challenges that arise is the handling of memory alignment. Prior research has focused \nprimarily on vectorizing loops where all memory references are properly aligned. An im\u00adportant aspect \nof this problem, namely, how to vectorize misaligned memory references, still remains unaddressed. This \npaper presents a compilation scheme that systemat\u00adically vectorizes loops in the presence of misaligned \nmem\u00adory references. The core of our technique is to automat\u00adically reorganize data in registers to satisfy \nthe alignment requirement imposed by the hardware. To reduce the data reorganization overhead, we propose \nseveral techniques to minimize the number of data reorganization operations gen\u00aderated. During the code \ngeneration, our algorithm also ex\u00adploits temporal reuse when aligning references that access contiguous \nmemory across loop iterations. Our code gener\u00adation scheme guarantees to never load the same data associ\u00adated \nwith a single static access twice. Experimental results indicate near peak speedup factors, e.g., 3.71 \nfor 4 data per vector and 6.06 for 8 data per vector, respectively, for a set of loops where 75% or more \nof the static memory references are misaligned. Categories and Subject Descriptors D.3.4 [Programming \nLanguages]: Processors -compilers, code generation, optimization General Terms Languages, Performance, \nDesign, Algorithms Keywords SIMD, compiler, vectorization, simdization, multimedia ex\u00adtensions, alignment \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n04, June 9 11, 2004, Washington, DC, USA. Copyright 2004 ACM 1-58113-807-5/04/0006 ...$5.00. 1. INTRODUCTION \nMultimedia extensions have become one of the most pop\u00adular additions to general-purpose microprocessors. \nExist\u00ading multimedia extensions can be characterized as Single Instruction Multiple Data (SIMD) units \nthat support packed .xed-length vectors. The traditional programming model for multimedia extensions \nhas been explicit vector programming using either (in-line) assembly or intrinsic functions embedded \nin a high-level programming language. Explicit vector programming is time consuming and error\u00adprone. \nA promising alternative is to exploit vectorization technology to automatically generate SIMD codes from \npro\u00adgrams written in standard high-level languages. Although vectorization has been studied extensively \nfor traditional vector processors decades ago, vectorization for SIMD architectures has raised new issues \ndue to several fun\u00addamental di.erences between the two architectures [1]. To distinguish between the \ntwo types of vectorization, we refer to the latter as simdization. One such fundamental di.er\u00adence comes \nfrom the memory unit. The memory unit of a typical SIMD processor bears more resemblance to that of a \nwide scalar processor than to that of a traditional vector pro\u00adcessor. In AltiVec [2], for example, a \nload instruction loads 16-byte contiguous memory from 16-byte aligned memory, ignoring the last 4 bits \nof the memory address in the instruc\u00adtion. The same applies to store instructions. In this paper, architectures \nwith alignment constraints refer to ma\u00adchines that support only loads and stores of register-length aligned \nmemory. The alignment constraints of SIMD memory units present a great challenge to automatic simdization. \nConsider the code fragment in Figure 1 where integer arrays a, b,and c are aligned1 . Although this loop \nis easily vectorizable for for (i =0; i< 100; i++) { a[i+3] = b[i+1] + c[i+2]; } Figure 1: A loop with \nmisaligned references. traditional vector processors, it is non-trivial to simdize it for SIMD architectures \nwith alignment constraints. The most commonly used policy today is to simdize a loop only if all memory \nreferences in the loop are aligned. In the presence of misaligned references, one common technique is \nto peel 1An aligned reference means that the desired data reside at an address that is a multiple of \nthe vector register size. a) Layout of array b in memory boundaries b) Loading one vector starting at \nb[1] vload b[0] vload b[4]  c) Loading multiple vectors starting at b[1] vload b[0] vload b[4] vload \nb[8]  ...   Figure 2: Loading from misaligned addresses. the loop until all memory references inside \nthe loop become aligned [3, 4]. The peeling amount can be determined either at compile-time or at runtime. \nHowever, this approach will not simdize the loop in Figure 1 since any peeling scheme can only make at \nmost one reference in the loop aligned. In this paper, we propose a systematic approach to simdiz\u00ading \nloops with misaligned stride-one memory references for SIMD architectures with alignment constraints. \nThis is achieved by automatically generating data reorganization instructions during the simdization \nto align data in registers. Using the array reference b[i+1] as an example, Figure 2b illustrates the \nbasic mechanism to implement a misaligned load on a typical SIMD unit with alignment constraints. We \nuse here instruction vload to load a vector from 16\u00adbyte aligned memory and instruction vshiftpair to \nselect consecutive elements of two vector registers to an output vector register. The misalignment handling \ncan be further improved, by reusing the vector loads across loop iterations as shown in Figure 2c. Our \nalgorithm is able to exploit such reuse and guarantees that data associated with a sin\u00adgle static reference \nin the original loop will not be loaded twice. We adopt a systematic and non-intrusive approach to the \nhandling of misalignment in simdization. First, the loop is simdized as if for a machine with no alignment \nconstraints. Second, data reorganization operations are inserted into the simdized code to satisfy the \nactual alignment constraints. The second step is our key contribution to alignment han\u00addling and is the \nprimary focus of this paper. The second step occurs in following two phases which com\u00admunicate via a \ndata reorganization graph. Data Reorganization Phase inserts data reordering op\u00aderations in the code \nproduced by the previous step to satisfy the actual alignment constraints. Optimizations are applied \nto minimize the number of data reordering operations generated. This phase is relatively architec\u00adture \nindependent and its output is a data reorganization graph. SIMD Code Generation Phase maps the simdized \noper\u00adations (including the data reordering operations inserted by the previous phase) to SIMD instructions \nspeci.c to the target platform. This phase addresses issues such as runtime alignments, unknown loop \nbounds, multiple misalignments, and multiple statements. Performance evaluation indicates that near peak \nspeedup can be achieved even in the presence of large numbers of misaligned references in the loop. Comparing \nthe dynamic instruction count of simdized codes generated by our pro\u00adduction compiler to an ideal scalar \ninstruction count, we achieve the following speedups over a wide range of loop benchmarks. With 4 integers \npacked in a vector register andwithonaverage 3/4 of the static memory references misaligned, speedups \nof up to 3.71 and 2.69 are achieved with and without static alignment information, respectively. With \n8 short integers packed in a vector register and with on average 7/8 of the memory references misaligned, \nwe achieve speedups of up to 6.06 and 4.64 with and without static alignment information, respectively. \nIn summary, this paper makes the following contribu\u00adtions: Introduces a new abstraction, the data reorganization \ngraph, to incorporate alignment constraints and to en\u00adable the systematic generation and optimization \nof data reorganization operations during simdization.  Proposes a robust algorithm to simdize misaligned \nloads and stores including loops with multiple misaligned ref\u00aderences, runtime alignments, unknown loop \nbounds, and multiple statements.  Proposes an e.cient code generation algorithm that ex\u00adploits reuse \non stride-one misaligned memory references to minimize the number of vector loads and stores.  Demonstrates \nnear peak speedup even in the presence of large numbers of misaligned memory references.  The rest of \nthe paper is organized as follows. Section 2 gives an overview on SIMD architectures. We then describe \nthe data reorganization and code generation phases of the simdization algorithm in Sections 3 and 4, \nrespectively. Ex\u00adperimental results are presented in Section 5. Section 6 dis\u00adcusses the related work \nand we conclude in Section 7.  2. BACKGROUND 2.1 SIMD Architectures Multimedia extensions have been \nadopted by most ma\u00adjor computer manufactures such as MMX/SSE for Intel, 3DNow! for AMD, VMX/AltiVec for \nIBM/Motorola, and VIS for SUN. Similar architectures can also be found in graphics engines and game consoles \nsuch as NVDIA, ATI, PS2, and XBOX, and some of the DSP processors. These processing units can be characterized \nas SIMD pro\u00adcessors operating on packed .xed-length vectors. A typical SIMD unit provides a set of vector \nregisters that are usually 8-or 16-byte wide. It supports SIMD operations on 1, 2, 4, and possibly 8 \nbyte data types. For example, a 2-byte vector add on a 16-byte vector would add 8 distinct data in a \nvector in parallel. In terms of memory units, most media processing units mentioned before2 provide a \nload-store unit similar to AltiVec s as described in Section 1. 2SSE2 supports some limited form of misaligned \nmemory accesses which incurs additional overhead. 2.2 Generic Data Reorganization Operations Most SIMD \narchitectures support a rich set of operations to reorder data in vector registers. These operations \nare heavily used in our alignment handling. In order to present a general-purpose simdization scheme, \nwe introduce three generic data reorganization operations. These generic oper\u00adations can be easily mapped \nto instructions of speci.c plat\u00adforms. We will illustrate their implementations on existing SIMD architectures \nusing AltiVec as an example. In the rest of the section, we use V to denote the vector length. vsplat(x) \nreplicates a scalar value x to form a full vector by V/sizeof(x)times. This operation is directly supported \nby most SIMD architectures, e.g., vec splat on AltiVec. vshiftpair(v1 ,v2,) selects bytes ,+1,...,+V-1from \na double-length vector constructed by concatenating vec\u00adtors v1 and v2,where 0 = <V. This operation can \nbe implemented by permute op\u00aderations that combine two vectors through a permute vector, e.g., vec perm \non AltiVec. Each byte of the per\u00admute vector speci.es which byte of the two concatenated input vectors \nis selected. The permute vector can be constructed as vector literal (,+1,...,. + V - 1) if . is known \nat compile-time, or as the result of adding vsplat((char)) with vector literal (0,...,V - 1). vsplice(v1 \n,v2,) splices two vectors v1 and v2 at a splice point speci.ed by an integer value . Speci.cally, it \ncon\u00adcatenates the .rst . bytes of v1 with the last (V - ) bytes of v2 when 0 <<V,copies v1 when . = 0, \nand copies v2 when . = V. This operation can be implemented by the select operation available on most \nSIMD architectures, e.g., vec sel on AltiVec. For each bit of the output vector, this operation selects \nthe bit from one of the two input vector registers based on a mask vector. The mask vec\u00adtor can be computed \nas the result of comparing vector literal (0,1,...,V - 1) against vsplat((char)).  3. DATA REORGANIZATION \nPHASE In this section, we .rst give an intuitive example of why byte reordering operations are needed \nfor alignment han\u00addling in Section 3.1. We then introduce the concept of stream and stream shift in Section \n3.2 and the data reor\u00adganization graph in Section 3.3. Graph optimizations to minimize the amount of \ndata reorganization are presented in Section 3.4. For the simplicity of the description, the code examples \nused in this section assume that the vector length is 16 bytes, the base address of an array is 16-byte \naligned, and the values are 32 bit integer values. 3.1 Constraints of a Valid Simdization Consider our \noriginal example of a[i+3]=b[i+1]+c[i+2] in Figure 1. Since there is no loop-carried dependence, the \nloop can be easily simdized for machines with no align\u00adment constraints. However, such simdized code \nis invalid for SIMD units that support only aligned loads and stores. Figure 3 illustrates the execution \nof the simdized loop on a hardware with alignment constraints. Consider the i=0 iteration of the simdized \nloop in Fig\u00adure 3a, focusing on the values of expression a[3]=b[1]+c[2] which are highlighted by white \ncircles on gray background  a) Invalid SIMD Code b) Memory and register streams for b[i+1] for(i=0;i<100;i+=4) \n 16-byte boundaries b[i+1]  ... offset = 4 c) Memory and register streams for c[i+2] 16-byte boundaries \nc[i+2]  ... offset = 8 d) Register and memory streams for a[i+3] ... offset = 12 a[i+3] 16-byte \nboundaries b0 b1 b2 b3 Reg: Values of focus (i=0): Legend: Mem: Figure 3: An invalid simdization on \nhardware with alignment constraints. in Figures 3b-d. The vload b[1] operation loads vector b[0],...,b[3] \nwith the desired b[1] value at byte-o.set 4 in its vector register, as shown in Figure 3b. Similarly, \nthe vload c[2] operation loads c[0],...,c[3] with c[2] at byte o.set 8, as depicted in Figure 3c. Adding \nthese two vector registers yields the values b[0]+c[0],...,b[3]+c[3], as illus\u00adtrated in Figure 3d. This \nis clearly not the result speci.ed by the original b[i+1]+c[i+2] computation. Based on these observations, \nwe list the following con\u00adstraints that a valid simdization must satisfy: 1. When performing a vector \nload, the 16-byte alignment of the load address dictates the byte-o.set of the data in its destination \nvector register. For example, the 16-byte alignment of b[1] and c[2] in memory is 4 and 8 bytes, respectively, \nas is the byte o.set in their respective vector registers. 2. When computing vector operations (possibly \nexclud\u00ading data reordering operations), the data involved in the original operation must reside at the \nsame byte\u00ado.set in their respective vector registers. 3. When performing a vector store, the byte-o.set \nof the data in the vector register must match the mem\u00adory alignment of the store address. For example, \nb[1]+c[2], when being stored to a[3],must reside at byte-o.set 12 in its vector register to match the \nmemory alignment of a[3].  Thus, data reorganization for a valid simdization can be summarized as reordering \ndata in vector registers so that the above speci.ed constraints are satis.ed. The formalization of these \nconstraints will be presented later in Section 3.3.  3.2 Streams and Stream Shifts Given a stride-one \nmemory reference in a loop, a memory stream corresponds to all the contiguous locations in mem\u00adory addressed \nby that memory reference over the lifetime of the loop. For example, the gray boxes in the contiguous \nband in Figure 4b depict the memory stream associated with a) Valid SIMD Code* b) Memory and register \nstreams for b[i+1] 16-byte boundaries for(i=0; i<100; i+=4)   b[i+1]  b4 b5 b6 b7 ....... offset \n= 4 b5 b6 b7 b8  ....... offset = 0 c) Memory and register streams for c[i+2] b100 b101 b102 b103 \n 16-byte boundaries b98+ b99+ b100+ c99 c100 c101 Legend: Mem: Reg:  b0 b1 b2 b3 Values of focus \n(i=0): b96 b97 b98 b99  offset = 12 16-byte boundaries Figure 4: A valid simdization for hardwares \nwith alignment constraints. b97 b98 b99 b100   ....... offset = 8 c6 c7 c8 c9  ....... offset = \n0 d) Register and memory streams for a[i+3] b5+ b6+ b7+ b8+ c6 c7 c8 c9  .......  * boundary conditions \nexcluded offset = 0 ....... c4 c5 c6 c7 c96 c97 c98 c99 c98 c99 c100 c101 b97+ b98+ b99+ b100+ c98 \nc99 c100 c101  b2+ b3+ b4+ b5+ c3 c4 c5 c6 b94+ b95+ b96+ b97+ c95 c96 c97 c98 b[i+1] in the i=0 to \n99 loop, spanning the values from b[1] to b[100]. Similarly in Figure 4c, the memory stream asso\u00adciated \nwith c[i+2] spans the values from c[2] to c[101]. Similarly, a register stream corresponds to all the \ncon\u00adsecutive registers produced by a single vector operation over the lifetime of a loop. Note that, \nas a memory stream is read from memory by vector loads in discrete chunks of 16 bytes, extra values may \nbe introduced at the beginning and the end of a register stream. For example, in Figure 4b, the .rst \nvalue in the register stream is not b[1] but b[0]. To distinguish the desired values from the extra values \nin a register stream, we introduce the concept of a stream o.set, de.ned as the byte-o.set of the .rst \ndesired value of a register stream. Namely, stream o.set is the byte-o.set of the data associated with \nthe i=0 computation. Stream o.set values are by de.nition nonnegative and smaller than the vector length. \nIn Section 3.1, we establish that a simdization is valid when all of the data processed by an original \noperation re\u00adside at the same byte-o.set in their respective vector regis\u00adters. To that e.ect, we introduce \na new data reorganization operator, vshiftstream(c1 ,c2),which shifts allvaluesof a register stream among \nconsecutive registers of that stream. Essentially, it takes an input register stream whose o.set is c1 \nand generates a register stream of the same values but with a stream o.set of c2. For example, vshiftstream(4,0) \nin Figure 4a shifts the register stream associated with vload b[i+1] to the left by 4 bytes, as shown \nin Figure 4b, eliminating the extra initial value b[0] from the register stream. The same operator can \nalso be used to shift values to the right, as shown in Fig\u00adure 4d, where vshiftstream(0,12) shifts right \nthe register stream of b[i+1]+c[i+2] by 12 bytes. The resulting register stream has an o.set of 12, which \nmatches the alignment of the memory stream generated by reference a[i+3].   3.3 Data Reorganization \nGraph A data reorganization graph is an expression tree aug\u00admented with data reordering operations. Figure \n4a is an example of such a graph. Each node in the graph is associ\u00adated with a stream o.set property. \nSince the stream o.set property is key to our de.nition of a valid data reorganiza\u00adtion graph, we describe \nbelow how to compute the stream o.set for each type of data reorganization graph nodes. The rest of the \nsection uses the following notations: V for the vector length, i for the loop counter, O and Ox for the \nstream o.set associated with the current node in con\u00adsideration and any other node x, respectively. For \nan o.set known at compile times, Ox is a compile time constant that is directly used by our algorithms; \notherwise, for runtime o.sets, Ox is a register value that is computed at runtime by anding memory addresses \nwith literal V - 1. vload(addr(i)) This node loads a vector from a stride-one memory reference addr(i). \nThis operation produces a register stream whose stream o.set is de.ned by the alignment of addr(i), i.e., \nO . addr(i =0) mod V (1) vstore(addr(i),src) This node stores a vector stream pro\u00adduced by node src to \na stride-one reference addr(i). This node does not have a stream o.set. However, in order for the store \nto be valid, the stream o.set of node src a) Valid SIMD Code* for(i=0; i<100; i+=4) b[i+1]  b) Memory \nand register streams for b[i+1] 16-byte boundaries  b96 b97 b98 b99 b94 b95 b96 b97  ....... offset \n= 4  b2 b3 b4 b5  ....... offset = 12 c) Memory and register streams for c[i+2] b4 b5 b6 b7  ....... \n offset = 8  c3 c4 c5 c6  ....... offset = 12 d) Register and memory streams for a[i+3] ....... \n c4 c5 c6 c7 b2+ b3+ b4+ b5+ c3 c4 c5 c6 b100 b101 b102 b103 b98 b99 b100 16-byte boundaries c99 \nc100 c101 Legend: Mem: b98+ b99+ b100+ c99 c100 c101 b0 b1 b2 b3 Reg: Values of focus (i=0):  c96 \nc97 c98 c99 c95 c96 c97 c98 b94+ b95+ b96+ b97+ c95 c96 c97 c98 offset = 12 16-byte boundaries  * \nboundary conditions excluded  Figure 5: Illustration of the eager-shift policy for the example in Figure \n4. must satisfy the following condition: Osrc = addr(i =0)mod V (C.2) vop(src1,..., srcn) This node represents \na regular vector operation that takes as input register streams associated with nodes src1,..., srcn \nand produces one output reg\u00adister stream. In order for the computation to be valid, input register streams \nmust have matching stream o.\u00adsets, i.e., Osrc1 = Osrc2 = ... = Osrcn (C.3) The stream o.set of this node \nis de.ned by the uniform stream o.set of its input nodes, i.e., O .Osrc1 (4) vshiftstream(src, Osrc,c) \nThis node shifts the register stream associated with the input node src and stream o.set Osrc to a register \nstream with a stream o.set c. This is a data reorganization node which can change the o.set of a register \nstream. By the de.nition of the op\u00aderation, the stream o.set of this node is: O .c (5) where 0 =c<V and \nmust be a loop invariant. vsplat(x) This node replicates a loop invariant x to produce a register stream \nwith concatenated values of x.The stream o.set of this node is unde.ned and is associ\u00adated with the symbol \n., as the same value is replicated in all register slots,i.e., O .. (6) Note that .can be any de.ned \nvalue in (C.2) and (C.3). Essentially, (C.2) and (C.3) specify the constraints that must be satis.ed \nto produce a valid data reorganization graph. They are the formalization of the second and the third \nconstraints described in Section 3.1.  3.4 Generating a Data Reorganization Graph A valid data reorganization \ngraph require the stream o.\u00adset of each node in the graph satisfy Constraints (C.2) and (C.3). In the \npresence of misalignments, this property is only achievable by judicious placement of data reordering \nnodes such as vshiftstream to the original expression tree. We investigate several policies to place \nvshiftstream-nodes to generate a valid data reorganization graph. Zero-Shift Policy The main idea behind \nthis policy is to (1) shift each mis\u00adaligned register stream to a stream o.set of 0 immediately after \nit is loaded from memory, and (2) to shift each register stream to the alignment of the store address \njust before it is stored to memory. More speci.cally, For each vload-node x,insert vshiftstream(x, Ox, \n0) between x and its output nodes.  For each vstore-node x of vstore(addr(i),src), insert vshiftstream(src, \nOsrc,c) between nodes src and x where c is equal to addr(i =0)mod V .  For each loop invariant node \nx used as a register stream, insert vsplat(x) between x and its output node.  The simdization example \nin Figure 4 uses the zero-shift policy. This policy is the least optimized in terms of the number of \ndata reorganization operations since it inserts one vshiftstream for each misaligned memory stream. Eager-Shift \nPolicy This policy shifts each misaligned load stream directly to the alignment of the store, rather \nthan to 0 as the zero-shift policy does. Speci.cally, for each vload-node x in the graph, a) Graph illustrating \nLazy-Shift b) Graph illustrating Dominant-Shift for(i=0; i<100; i++)for(i=0; i<100; i++) a[i+3] = b[i+1] \n+ c[i+1] a[i+3] = b[i+1] * c[i+2] + d[i+1]  b[i+1] c[i+2] vstore a Figure 6: Lazy-shift and dominant-shift \npolicies. the policy inserts a vshiftstream(x, Ox,c) between x and its output nodes, where c is the alignment \nof the store. Due to code generation issues investigated in Section 4.2, this policy requires alignments \nof loads and stores to be known at compile-time. Figure 5 illustrates the eager-shift placement policy, \nlowering the total number of stream shift operations from 3 to 2. Lazy-Shift Policy This policy is based \non the eager-shift policy but is im\u00adproved further by delaying stream shifts as long as Con\u00adstraints \n(C.2) and (C.3) are satis.ed. Consider the example a[i+3]=b[i+1]+c[i+1] in Fig\u00adure 6a. Zero-shift policy \nwould insert 3 vshiftstream oper\u00adations. Eager-shift would require 2, one for each misaligned load. This \npolicy, however, exploits the fact that b[i+1] and c[i+1] are relatively aligned, thus satisfying (C.3) \nand canbe safelyoperatedonas is. Only the resultofthe add needs to be shifted so as to match the alignment \nof the store, as shown in Figure 6a. Dominant-Shift Policy This policy further reduces the number of \nstream shifts by shifting register streams to the most dominant stream o.set in the graph. This policy \nis most e.ective if applied after the lazy-shift policy. For example, in Figure 6b, the domi\u00adnant o.set \nis stream o.set 4. Shifting stream to this o.set decreases the number of vshiftstream operations from \n4 (for the zero-shift policy) to 2.  4. SIMD CODE GENERATION This section presents the code generation \nalgorithm. We start with an algorithm that simdizes a single-statement loop with compile-time alignments \nand loop bounds. We then augment the algorithm to handle multiple-statement loops, runtime alignments, \nand unknown loop bounds. 4.1 Assumptions and Notations In our algorithm, we assume the loop to be simdized \nis an innermost loop that satis.es the following conditions: All memory references are either loop invariant \nor stride\u00adone array references.  The base address of an array is naturally aligned to the data length \nof its array elements.  The loop counter can only appear in the address com\u00adputation of stride-one references. \n All memory references access data of the same length. There is no conversion between data of di.erent \nlengths. The rest of the paper uses the following notations: V for the vector length, D for the uniform \ndata length of all memory references in the loop, and Ox for the stream o.set of a graph node x. We also \ndenote the blocking factor of the simdized loop as B, which is computed as the number of data per vector, \ni.e., B = V/D. (7) 4.2 Single-Statement Algorithm This algorithm simdizes a single-statement loop where \n memory alignments and loop bounds are known at compile\u00adtime. We assume that the loop is normalized and \nhas a loop counter i and an upper bound ub. The input to the algorithm is the data reorganization graph \nof the single statement in the loop. The algorithm traverses the graph in postorder starting from the \nstore\u00adnode and recursively processes each child before itself. The code generation algorithm relies on \nnative vector operations of the target machine plus an implementation of the generic data reordering \noperations presented in Section 2.2, namely, vsplat, vshiftpair,and vsplice. In addition, we use the \nfollowing helper functions: Runtime(c) determines whether c is a compile-time or run\u00adtime value. Substitute(n, \nx . y) traverses the tree starting at node n and replaces all occurrences of x by y. GenStoreStmt(addr, \nexpr, ptr) generates a store statement of expression expr to address addr at the insertion point speci.ed \nby ptr.If addr is given as a string, e.g., t ,it represents the address of a local variable named t . \nSimdizing an Expression The following tasks are performed when processing nodes in the data reorganization \ngraph of an expression, including all but the .nal store node in the graph. Store nodes are special cases \nthat are presented in the next subsection. The detailed algorithm is given in Figure 7. vload(addr(i)) \nWhen processing this node, we emit a vload vector operation of address addr(i) without fur\u00adther simdizing \nthe load s inputs. vop(src1,...,srcn) When processing this node, we .rst gen\u00aderate SIMD codes to compute \nevery source value, which is then used by a SIMD version of the vop operation. vsplat(x) When processing \nthis node, we .rst generate tra\u00additional code to compute the x value, which is then used by a vsplat \nvector operation. vshiftstream(src, Osrc,c) When processing this node, the algorithm .rst determines \nwhether the register stream associated with src is shifted left (e.g., Figure 4b) or shifted right (e.g., \nFigure 4d). When shifting a register stream left, i.e., Osrc >c, data from the next register of the src \nregister stream is shifted into the current register of the stream. Con\u00adsider the vshiftstream(b[i + \n1], 4, 0) in Figure 4b. Data b[4] from the second register of the stream is shifted into the .rst register \nof the stream to produce (b[1],b[2],b[3],b[4]) as the .rst register of the out\u00adput register stream. GenSimdExpr(n) \n1if n = vload(addr(i)) return vload(addr(i)) 2if n = vsplat(x)return vsplat(GenExpr(x)) 3if n = vshiftstream(src, \nOsrc,c) 4 return GenSimdShiftStream(src, Osrc,c) 5if n = vop(src1, ...,srcn) 6 for (k =1..n) vregk.GenSimdExpr(srck \n) 7 return vop(vreg1,...,vregn) GenSimdShiftStream(n, from, to) 8 shift . (from -to)mod V 9if(from> \nto |Runtime(to)) /* shift left */ 10 curr .GenSimdExpr(n) 11 next .GenSimdExpr(Substitute(n, i . i + \nB)) 12 return vshiftpair(curr, next,shift) 13 elseif(from< to |Runtime(from)) /* shift right */ 14 curr \n.GenSimdExpr(n) 15 prev .GenSimdExpr(Substitute(n, i . i -B)) 16 return vshiftpair(prev, curr, shift) \n Figure 7: SIMD code generation for expressions. Since all memory streams are based on stride-one memory \nreferences, the next register in a register stream corresponds to the vector produced by the next simdized \niteration. Thus, it can be computed by replacing i with (i + B) in the simdized node. When shifting a \nstream right, i.e., Osrc <c,the re\u00adsulting vector register is similarly obtained by combining the previous \nand the current vector registers of the src register stream. Simdizing a Statement When simdizing a vstore(addr(i)), \nextra precaution must be taken for the .rst and last few iterations of the original loop. Consider, for \nexample, the store a[i+3] = ... origi\u00adnally illustrated in Figure 4d. Since a[i+3] has an o.set of 12 \nbytes, only 4 bytes of the newly computed data should be stored during the .rst iteration of the simdized \nloop. Sim\u00adilarly, only 12 bytes of the newly computed data should be stored in the last iteration of \nthe simdized loop. Figure 8: Special cases for prologue and epilogue. In general, such partial vector \nstores can only occur in the .rst and/or the last iterations of a simdized loop. To handle such cases \nwithout impact on the steady state per\u00adformance of a loop, we peel the .rst and the last iteration of \na simdized loop into, respectively a prologue and epilogue that are customized to handle partial stores. \nAs illustrated in Figure 8, on SIMD units without dedicated hardware sup\u00ad GenSimdStmt-Prologue(addr(i), \nsrc) 1 spliceP oint . addr(0) mod V 2 new .GenSimdExpr(src) 3 old .vload(addr(0)) 4 spliced .vsplice(old, \nnew, spliceP oint) 5 GenStoreStmt(addr(0),spliced, 'in prologue') GenSimdStmt-Steady(addr(i), src) 6 \nnew .GenSimdExpr(src) 7 GenStoreStmt(addr(i),new, 'in loop') GenSimdStmt-Epilogue(addr(i), src, ub) 8 \nspliceP oint . (addr(0) + ub *D)mod V 9 new .GenSimdExpr(src) 10 old .vload(addr(i)) 11 spliced .vsplice(new, \nold, spliceP oint) 12 GenStoreStmt(addr(i),spliced, 'in epilogue') Figure 9: SIMD code generation of \nstatements for the prologue, the steady-state, and the epilogue. port, partial stores are implemented \nby loading the original value prior to the store, splicing it with the newly computed value, then storing \nthe spliced value back into memory using vsplice operation. The algorithm to handle the prologue, steady-state, \nand epilogue is given in Figure 9. For the prologue, the newly computed values are spliced into the original \nvalue prior to the store from byte ProS\u00adplice to V -1. ProSplice is precisely the alignment associ\u00adated \nwith the store memory stream, i.e., ProSplice = addr(i =0)mod V. (8) For the epilogue, the newly computed \nvalues are spliced into the original value prior to the store from byte 0 to EpiSplice-1, where EpiSplice \ncorresponds to the o.set of the .rst byte after the end of the store memory stream. Since store memory \nstream is ub D bytes long, EpiSplice is computed as, EpiSplice = (addr(i =0)+ ub D)mod V. (9) Simdizing \na Loop There is more to simdizing a single statement loop than gen\u00aderating codes for the prologue, steady-state, \nand epilogue. We must also specify the bounds and the step of the steady\u00adstateloop. Thesesteps aredetailed \nbelow. The step of the steady-state loop is set to be the blocking factor B.  The lower bound of the \nsteady-state loop is set to be the number of original loop iterations being peeled into the prologue, \ni.e.,  V -ProSplice LB = LJ. (10) D The upper bound of the steady-state loop is set to be the original \nupper bound minus the number of original loop iterations being peeled into the epilogue, i.e., EpiSplice \nUB = ub -LJ. (11) D 4.3 Multiple-Statement Algorithm Most handling in the SIMD code generation is performed \non a per statement basis. Thus, the algorithm in Section 4.2 can naturally handle each statement of a \nmultiple-statement loop. The only exceptions are the loop bound computations in Equations (10) and (11) \nwhich clearly need to be com\u00adputed on a per loop basis. The bounds are thus re.ned below in the context \nof multiple-statement loops. Since Equation (10) computes the lower bound using the alignment of the \nstore, it is not applicable to loops with statements of distinct store alignments. The key observa\u00adtion \nto address this issue is that we do not need to compute the precise lower bound for each statement, as \nlong as each memory operation loads and stores the right data. This is based on our assumption that the \nloop counter only ap\u00adpears in address computation. Recall that vector memory instructions implicitly \ntruncate the address as they access only aligned data. For example, on AltiVec, loads from ad\u00addresses \n0x1000, 0x1001,or 0x100E each load the same 16 bytes of data starting at 0x1000. Exploiting the truncation \ne.ect of address computation, we set the lower bound to be the blocking-factor, i.e., LB = B. (12) Equation \n(12) guarantees that the store associated with each statement in the .rst iteration of the steady-state \nloop cor\u00adresponds to the .rst full vector store of its corresponding stream. The upper bound speci.es \nthe highest iteration in the steady-state loop by which every store in the loop is guar\u00adanteed to be \na full vector store. For an n-statement loop, we compute the upper bound of the steady-state loop by \nsub\u00adtracting the largest EpiSplice over all statements from the original upper bound, i.e., maxk=1..n \nEpiSplicek UB = ub -L J. (13) D Furthermore, we need to compute the number of bytes that must be stored \nin the epilogue, referred to as EpiLeft-Over. This value is computed on a per statement ba\u00adsis as the \ntotal number of bytes in the memory stream, ub D, minus the number of bytes processed in the prologue, \nV -ProSplice, and the steady-state loop, .(UB -LB)/B.V combined. After simpli.cation using (12), we have \nUB EpiLeftOver = ub D + ProSplice -. .V. (14) B For some combinations of ProSplice and ub,EpiLeftOver \ncan be greater than V but is necessarily smaller than 2V .The epilogue code generation thus has to generate \na full vector store followed by a partial one with an epilogue splice point of (EpiLeftOver -V ). 4.4 \nRuntime Alignments and Upper Bounds The algorithm that handles vshiftstream in Figure 7 generates di.erent \ncode sequences depending on whether a stream is shifted left or right. For runtime alignments, we must \nintroduce vshiftstream in such a way that the shift direction can be determined at compile-time in spite \nof run\u00adtime alignments. The zero-shift policy exhibits this property as all misaligned loads are shifted \nleft (to o.set 0) and all misaligned stores are shifted right (from o.set 0). Therefore we can still \nuse the algorithm in Figure 7 to handle runtime alignment as long as zero-shift policy is applied. GenSimdStmtSP-Steady(addr(i), \nsrc) 1 new .GenSimdExprSP(src) 2 GenStoreStmt(addr(i),new, ' in loop ' ) GenSimdExprSP(n) 3 if n =vload(addr(i)) \nreturn vload(addr(i)) 4 if n =vsplat(x)return vsplat(GenExpr(x)) 5 if n =vshiftstream(src, Osrc,to) 6 \nreturn GenSimdShiftStreamSP(src, Osrc,to) 7 if n =vop(src1,...,srcn) 8 for (k =1..n) vregk .GenSimdExprSP(srck) \n9 return vop(vreg1,...,vregn) GenSimdShiftStreamSP(n, from, to) 10 shift . (from -to)mod V 11 if(from> \nto |Runtime(to)) /* shift left */ 12 first .GenSimdExpr(n) 13 second .GenSimdExprSP(Substitute(n, i . \ni + B)) 14 elseif(from< to |Runtime(from)) /* shift right */ 15 first .GenSimdExpr(Substitute(n, i . \ni -B)) 16 second .GenSimdExprSP(n) 17 GenStoreStmt( ' old ' ,first, ' in prologue ' ) 18 GenStoreStmt( \n' new ' ,second, ' in loop ' ) 19 GenStoreStmt( ' old ' , vload( ' new ' ), ' bottom of loop ' ) 20 return \nvshiftpair(vload( ' old ' ),second, shift) Figure 10: Software pipelined SIMD code genera\u00adtion for expressions. \nFor the lower bound, we can safely use Equation (12) as it solely depends on the blocking factor. However, \nwe need to re.ne the upper bound formula (13) as maxk=1..n EpiSplicek is expensive to compute at runtime. \nThis can be achieved by .nding a suitable upper bound to replace the max term. Recall our assumption \nthat each array is naturally aligned to its data element length. Thus, addr(i) can be represented as \nmD for some integer m. Equation (9) then becomes (mD + ub D)mod V and can be further sim\u00adpli.ed to ((m \n+ ub)mod B) D. According to the de.nition of mod, the largest value for EpiSplice is thus (B -1) D. Replacing \nthe max term in (13) by (B -1) D,we get this new upper bound: UB = ub -B +1. (15) Accordingly, (14) can \nbe simpli.ed to EpiLeftOver = ProSplice + (ub mod B) D. (16) Using (16), one can easily prove EpiLeftOver \n< 2V . Since the prologue always peels one simdized iteration and the epilogue stores at most 2 full \nvectors, i.e.,two simdized iterations, the simdization is guaranteed to be valid if the original trip \ncount is greater than 3B. When the trip count is unknown, the simdized codes must be guarded by a test \nof ub > 3B. 4.5 Software Pipelined Algorithm We can further improve the standard algorithm in Sec\u00adtion \n4.2 by eliminating the redundant computation intro\u00adduced during stream shift handling. Recall that, in \nFigure 9, GenSIMDShiftStream combines the values of two consecutive loop iterations, either the current \nand next iterations for left shifts or the current and previous iterations for right shifts. For conciseness, \nwe describe here and in Figure 10 the values associated with the smaller iteration count as .rst and \nthe one with the larger iteration count as second. The key idea is to software pipeline the computation \nof the .rst and second values. Instead of computing both values associated with the .rst and second iterations \nin the loop, we only compute the values associated with the second iteration and preserve them to the \nnext iteration, since this iteration s second values will become next iteration s .rst values. As shown \nin Figure 10, the software pipelined code gen\u00aderation scheme involves the following 3 steps. 1. We precompute \nfirst in a non software pipelined fash\u00adion (lines 12 and 15) using the standard algorithm GenSimdExpr. \nWe then generate a statement to store the values of first to register old (line 17), inserted to the \nprologue of the loop. 2. We compute second in a software pipelined fashion (lines 13 and 16). And store \nsecond to register new (line 18). Since this expression is in the loop, we re\u00adcursively use software \npipelined GenSimdExprSP. 3. We generate a statement to copy register new to regis\u00adter old (line 19) \nat the bottom of the loop.  Note that the steady-state loop involves only the compu\u00adtation of second \n(line 2) and the copy operation between new and old (line 19). In other words, we have replaced the computation \nof first in the steady-state loop by a copy operation. Note that the copy operation can be easily re\u00admoved \nby unrolling the loop twice and forward propagating the copy operation.  5. EVALUATION In this section, \nwe present a detailed evaluation of the simdization algorithm. We compare the actual throughput achieved \non SIMD units to the bounds derived from code analysis. 5.1 Target Machine Description The target machine \ncontains generic 16-byte wide SIMD units that are representative of most SIMD architectures currently \navailable. The load-store unit supports 16-byte aligned loads and stores only. Data reorganization is \nsup\u00adported by a permute operation that selects arbitrary bytes from two vector registers, similar to \nthe byte permutation operation described in Section 2.2. 5.2 Compiler Infrastructure Our implementation \nis based on IBM s xl compiler infras\u00adtructure, which supports multiple languages including C, C++, and \nFortran, and generates highly optimized codes. The simdization algorithm is implemented in the Toronto \nPortable Optimizer (TPO), the component that performs aggressive dependence analysis and high-level loop \ntransfor\u00admations. The simdization phase occurs after several loop transformations such as loop interchange \nand loop distri\u00adbution that enhance simdization by removing loop-carried dependences along innermost \nloops. It is followed by other loop transformations that can signi.cantly improve the qual\u00adity of the \nsimdized codes, notably loop unrolling that re\u00admoves needless copy operations and a special form of com\u00admon \nsubexpression elimination, referred to as Predictive Commoning (PC) [5], which exploits the reuse among \ncon\u00adsecutive loop iterations. The back-end code generator (TO-BEY) has been extended to target a PowerPC-based \npro\u00adcessor with SIMD vector units. It performs various target\u00adspeci.c optimizations including instruction \nscheduling and register allocation. 5.3 Evaluation Methodology To better evaluate our simdization scheme, \nexperiments were conducted on a set of synthesized loops. These loops heavily stress our heuristics as \nthey exhibit a high ratio of misaligned data references versus computations. The loop benchmarks are \nsynthesized based on a set of parameters, s, the number of statements, l, the number of load refer\u00adences \nper statement, and, n, the iteration count. Since all arithmetic operations are essentially the same \nfor alignment handling, we use add as the sole arithmetic operation in the synthesized loops. The alignment \nof each memory reference is randomly selected, with a possible bias b (0 = b = 1) toward a single, randomly \nselected alignment. Each mem\u00adory reference within a single statement accesses a distinct array, but di.erent \nstatements can contain accesses to the same array. The amount of array reuse r (0 = r = 1, from no reuse \nto full reuse) among multiple statements is also parameterized. The metric being used is operations per \ndatum (OPD), namely the number of operations needed to compute a single data element. We believe that \nthis metric is more micro\u00adarchitecture independent than wall time or clock cycles, as it does not depend \non the cycle time, instruction latency, and issue width of a particular architecture instantiation. OPD \nalso provides a very intuitive feel for the peek speedup that can be achieved with simdization, e.g. \na factor of 4 when 4 integers are packed in a single 16-byte vector register. We compare the compiler \ngenerated code measurement to a lower bound (LB) of operations per datum. The lower bound is computed \nbased on parameters (l, s, n, b, r).It ac\u00adcounts for the following factors. It includes each distinct \n16-byte aligned load and store in the loop3 . The bound also accounts for a minimum number of data reorganizations \nper statement. This is based on the observation that for a state\u00adment with accesses of n distinct alignments, \na minimum of n - 1 vshiftpair operations are required. Note that for the shift-zero policy, the number \nof vshiftpair operations is fully deterministic, namely one for each of the m mis\u00adaligned memory streams. \nFor that policy only, LB re.ects m instead of n - 1. The bound also includes the data com\u00adputations in \nthe loop, but explicitly ignores all architecture\u00adand compiler-dependent factors such as address computa\u00adtion, \nconstant generation, and loop overhead. When reporting measurements for the compiler-generated codes, \nthe operations per datum metric includes all over\u00adhead present in the execution of the real code, including \na single function call and return, address computation, and loop overhead.  5.4 Coverage Analysis We \n.rst evaluate the robustness of our implementation. More than a thousand loops were generated with varying \n(l, s, n, b, r) parameters. In particular, we tested up-to eight 3For example, loading a[i] and a[i+1] \nanywhere in the loop counts as one when both loads are known at the compile time to map to the same 16-byte \naligned memory location 10.182 12.000 10.182 12.000 7 7 6.8 6.8 6.6 6.4 6.2 6 5.8 5.8 5.6 5.6  Operation \n/ data Operation / data 5.4 5.2 5 4.8 4.6 4.4 4.2 4 3.8 3.6 3.4 3.2 3 4.4 4.2 4 3.8 3.6 3.4 3.2 3 loads \nper statement, four statements per loop, and a loop trip count in the range of [997, 1000] (for 4-element \nvectors). The loop count (n), alignment bias (b), the reuse ratio (r) were all randomly selected. Our \ncompiler simdized all the loops. The generated binaries were simulated on a cycle\u00adaccurate simulator, \nand the results were veri.ed.  5.5 Evaluation of Optimization Combinations This set of experiments evaluates \nthe combinations of shift placement policies and code generation optimizations. Each benchmark used in \nthe experiments consists of 50 distinct loops with identical (l, s, n, b, r) characteristics. The results \nare reported as the harmonic means over all 50 loops. Four shift placement policies are considered, i.e., \nthe zero-shift (ZERO), eager-shift (EAGER), lazy-shift (LAZY), and dominant-shift (DOM) policies. The \nzero-shift policy, al\u00adthough least optimized, is necessary when the alignments are not known at compile-time. \nThus measurement of this pol\u00adicy highlights the potential performance degradation due to the lack of \ncompile-time alignment information. Zero-shift policy is also the policy used by prior work [6, 7]. Each \nshift placement policy can be combined with the following (mostly) orthogonal code generation optimiza\u00adtions. \nSoftware Pipelining (SP) where we directly generate software-pipelined codes to exploit the reuse between \nconsecutive misaligned loads. Predictive Commoning (PC) where we rely on the more general TPO optimization \nto exploit the reuse between consecutive misaligned loads. Memory Normalization (MemNorm) where addresses \nused in vector memory operations are normalized to their lower 16-byte aligned memory locations to facili\u00adtate \ntraditional redundancy elimination optimization. Common O.set Reassociation (O.setReassoc) where the \nassociativity and commutativity of the computation are used to group computations with identical o.sets \nto make the lazy-shift and dominant-shift policies more successful. For conciseness, not all 64 (4 policies \ntimes 16 code-gen optimization combinations) results are reported here. Since MemNorm is always bene.cial \nby approximately 0.5% across the board, schemes without it are removed from the .g\u00adures. Furthermore, \nusing predictive commoning in addition to software pipelining does not bring any additional bene\u00ad.t, \nthus this combination is also removed from the .gures. However, we report data with and without O.setReassoc \nseparately. For each data point, we report operation per datum that is broken down into 3 components. \nThe bottom compo\u00adnent is the lower bound LB, as de.ned in Section 5.3. The middle component corresponds \nto the data reorganization overhead actually introduced by the shift policies over the lower bound. Recall \nthat there is no such overhead for the zero-shift policy because the fully deterministic number of vshiftpair \noperations is fully accounted by LB. The sum of the 3 components is the total cost, as measured by our \ncycle accurate simulator for the entire program. Thus the top component corresponds to the compiler overhead \nnot accounted for by the previous two components. We .rst consider loops with a single integer statement \nincluding 6 distinct loads with randomly selected o.sets with a bias of 30% (i.e., among the 6 loads, \non average 1.8 loads have an identical, randomly pre-selected o.set). Figure 11 shows the resulting operation \nper datum metric for all signi.cant code generation schemes with O.setReas\u00adsoc turned o.. When static \nalignment information is avail\u00adable, our schemes can achieve an opd as low as 4.022 com\u00adpared to 12 for \nnon-simdized codes4 (SEQ bar). In general, schemes that introduce redundant operations (i.e. without \neither PC or SP) perform poorly, with opd ranging from 5.372 to 10.182. Our best schemes also exhibit \nmore than one operation less per datum compared to VAST s approach (ZERO-sp)[7]. Our best schemes perform \nwell with respect to the naive5 3.000 bound and the more realistic 3.587 opd bound based on LB. Further \nanalysis indicates that dominant-shift introduces fewer shifts than lazy-shift or eager-shift, as seen \nby the con\u00adtribution of the middle component of each bar. However, the compiler overheads are currently \nlarger for dominant-shift, as seen by the top component of each bar, as it introduces 4The original loop \nhas 6 loads, 5 adds, and 1 store. 512 vector operations of 4 integers yields 12/4=3 opd.  Align at \ncompile time Align at runtime time Loop Best Speedup Best Speedup Descr. Policy Actual LB Policy Actual \nLB  S1*L2 LAZY-pc 2.72 3.17 ZERO-pc 2.15 2.36 S1*L4 LAZY-pc 3.02 3.27 ZERO-pc 2.35 2.51 S1*L6 LAZY-pc \n3.14 3.35 ZERO-pc 2.42 2.54 S2*L4 DOM-sp 3.42 3.64 ZERO-sp 2.47 2.68 S4*L4 LAZY-sp 3.47 3.64 ZERO-sp \n2.43 2.69 S4*L8 DOM-sp 3.71 3.93 ZERO-sp 2.17 2.78 Table 1: Speedup factors of simdized versus scalar \ncodes (4 ints per registers, peek speedup is 4). more redundancy and may generate codes that are more \ndi.cult to optimize. When alignment information is not available at compile time, we must revert to the \nzero-shift policy, which achieves a 4.963 opd compared to the lower bound of 4.750 opd. Figure 12 presents \nthe measurements in the same setting as in Figure 11, but with O.setReassoc turned on6.This enables lazy-shift \nand dominant-shift to have on average no shift overhead over LB, thus resulting in lower overall op\u00aderations \nper datum: 3.823, 3.963, and 3.963 for the top 3 schemes compared to 4.022, 4.13, and 4.164 in Figure \n11, respectively.  5.6 Ef.ciency Analysis This set of experiments investigates the general speedups \nthat can be achieved by our simdization scheme. The mea\u00adsurements are conducted in a wider range of loops, \nranging from 1 statement with 2 loads to 4 statements with 8 loads each, all accessing integer arrays. \nThe speedup factors7 of the simdization are summarized in Table 1. Each row cor\u00adresponds to the harmonic \nmeans over a 50 loop benchmark whose characteristics are summarized in the .rst column (reuse and bias \nset to 30%). For each benchmark, we report the speedup factors of the best performing simdization pol\u00adicy \nfor both the compile-time and runtime alignments. For reference, we also indicate an upper-bound speedup \nfactor basedonLB. The general trend in Table 1 is that we achieve higher speedup factors as the loops \nbecome more complex, e.g. reaching a speedup factor of 3.71 for a loop with 4 state\u00adments with 8 loads \neach. This is due in part to exploiting more more data locality for the same code size, because each \nsimdized loop iteration covers 4 times more data than origi\u00adnal loop iteration and each 16 byte data \nquantity should be loaded only once using predictive commoning and software pipelining. This is also \ndue in part to the loop overhead becoming smaller for larger loops. The second general trend in Table \n1 is that the lazy\u00adshift policy combined with predictive commoning and the dominant-shift policy with \nsoftware pipelining are the high\u00adest performing policies. Table 2 indicates the speedup when simdizing \nloops with short int arithmetic, where 8 shorts are packed in a vector 6Since the loops contains only \nadd operations, our results with O.setReassoc may be more optimistic than those of real loops where di.erent \noperations may be involved in an expression which may not be reassociated. 7Speedup factor corresponds \nto the total number of instruc\u00adtions over all loops of the scalar code divided by these of the simdized \ncode.  Align at compile time Align at runtime time Loop Best Speedup Best Speedup Descr. Policy Actual \nLB Policy Actual LB S1*L2 LAZY-pc 5.10 5.85 ZERO-pc 4.22 4.63 S1*L4 LAZY-pc 5.49 6.12 ZERO-pc 4.65 \n4.97 S1*L6 LAZY-pc 5.67 6.25 ZERO-pc 4.83 5.09 S2*L4 DOM-sp 6.06 6.94 ZERO-sp 4.81 5.45 S4*L4 DOM-sp \n6.06 6.91 ZERO-sp 4.64 5.43 S4*L8 DOM-sp 6.05 7.32 ZERO-sp 3.88 5.67  Table 2: Speedup factors of \nsimdized versus scalar code (8 short ints per registers, peek speedup is 8). register instead of the \n4 ints. Simdization achieves a speedup factor of up to 6.06, compared to a peek speedup of 8 and a more \nrealistic upper bound speedup of 7.32.  6. RELATED WORK There has been a recent spike of interest in \ncompiler tech\u00adniques to automatically extract SIMD parallelism from pro\u00adgrams [4, 6, 8, 9, 10]. This \nupsurge was driven by the increasing prevalence of SIMD architectures in multimedia processors. Two principal \ntechniques have been used, the traditional loop-based vectorization pioneered for vector su\u00adpercomputers \n[11, 12] and the unroll-and-pack approach .rst proposed by Larsen and Amarasinghe [9]. Our simdization \nscheme falls into the .rst category among with others [4, 10, 13, 14]. The most extensive discussion \nof alignment considera\u00adtions is in [3]. However, [3] is concerned with the detection of memory alignments \nand with techniques to increase the number of aligned references in a loop, whereas our work fo\u00adcuses \non generating optimized SIMD codes in the presence of misaligned references. The two approaches are complemen\u00adtary. \nThe use of loop peeling to align accesses was discussed in [3, 4]. The loop peeling scheme is equivalent \nto the eager\u00adshift policy with the restriction that all memory references in the loop must have the same \nmisalignment. Even under this condition, our scheme has the advantage of generating simdized prologue \nand epilogue, which is the by-product of peeling from the simdized loop. Direct code generation for misaligned \nreferences have been discussed by several prior works. [6] described the vectoriza\u00adtion of misaligned \nloads and stores using the VIS instruction set. Their scheme is equivalent to our zero-shift placement \npolicy plus the non software pipelined code generation algo\u00adrithm. It is not clear whether multiple statements, \nruntime alignments, and unknown loop bounds can be handled. In [4], Bik et al. described a speci.c code \nsequence of aligned loads and shu.e to load memory references that cross cache line boundaries, which \nis implemented in Intel s compiler for SSE2. However, their method is not discussed in the context of \ngeneral misalignment handling. Furthermore, neither [6] nor [4] exploit the reuse when aligning a stream \nof contiguous memory. As shown in our evaluation in Figure 11, without exploiting the reuse, there can \nbe a performance slowdown of more than a factor of 2. The most extensive alignment handling was implemented \nin the VAST compiler [7]. Like our scheme, VAST is able to simdize loops with multiple misaligned references, \nun\u00adknown loop bounds, and runtime alignments, and exploit the reuse when aligning a steam of contiguous \nmemory. How\u00adever, there is no public information available regarding their alignment handling scheme. \nWe can only conjecture, from the simdized codes produced by the compiler, that VAST s scheme is equivalent \nto our zero-shift policy combined with software pipelining. Therefore, our scheme has the advan\u00adtage \nof the other three additional placement policies.  An interesting simdization scheme using indirect \nregister accesses is discussed in [10]. However, their method is spe\u00adci.c to the eLite processor that \nsupports gather and scat\u00adter within a special register .le, which is not applicable to typical MME processors. \nIn [15], register packing and shift\u00ading instructions were used to exploit temporal and spatial reuse \nin vector registers. Their de.nition of replicate and shift-and-load is very similar to our vsplat and \nvshiftpair operations. However, their work does not address alignment handling. In earlier work on compiling \nfor distributed memory sys\u00adtems, [16] describes the Alignment-Distribution Graph that has some features \nin common with our data reorganization graph, notably the existence of nodes to specify transforma\u00adtion \nof data related to alignment or placement in memory.  7. CONCLUSION This paper proposes a compilation \nscheme to vectorize misaligned references for SIMD architectures that support only aligned loads and \nstores. In our framework, a loop is .rst simdized as if the memory unit imposes no alignment constraints. \nThe compiler then inserts data reorganization operations to satisfy the actual alignment requirement \nof the hardware. Finally, the code generation algorithm gen\u00aderates SIMD codes based on the data reorganization \ngraph, addressing realistic issues such as runtime alignments, un\u00adknown loop bounds, residue iteration \ncounts, and multiple statements with arbitrary alignment combinations. Beyond generating a valid simdization, \nwe investigate methods to further improve the quality of the generated codes. We propose four stream-shift \nplacement policies to minimize the number of data reorganization generated by the alignment handling. \nAnd our code generation algorithm exploits the reuse when aligning a stream of contiguous memory using \nsoftware pipelining techniques. We demonstrate near peak speedup for a set of loops where 75% of the \nstatic memory references in the loops are misaligned. Comparing the dynamic instruction count of simdized \ncodes to an idealistic scalar instruction count, we achieve speedup factors of up to 3.71 and 6.06 for \nvectors packed with 4 and 8 data, respectively. Many further issues need to be investigated to match \nthe wide range of situations that are only handled at present by experienced assembly programmers. Examples \nof such is\u00adsues are alignment handling of loops with non-unit stride ac\u00adcesses, accesses to scalar variables \nincluding induction vari\u00adables occurring in non-address computation, non-naturally aligned arrays, and \ndata conversions that require packing and unpacking capability. While these issues were not ad\u00addressed \nby this paper, we believe that our approach based on data reorganization graphs provides a solid foundation \nto solving these problems in the future. 8. REFERENCES [1] Gang Ren, Peng Wu, and David Padua. A Preliminary \nStudy on the Vectorization of Multimedia Applications for Multimedia Extensions. In 16th International \nWork\u00ad shop of Languages and Compilers for Parallel Comput\u00ading, October 2003. [2] Motorola Corporation. \nAltiVec Technology Program\u00adming Interface Manual, June 1999. [3] Samuel Larsen, Emmett Witchel, and Saman \nAmaras\u00adinghe. Increasing and Detecting Memory Address Con\u00adgruence. In Proceedings of 11th International \nConfer\u00adence on Parallel Architectures and Compilation Tech\u00adniques, September 2002. [4] Aart Bik, Milind \nGirkar, Paul M. Grey, and Xinmin Tian. Automatic Intra-Register Vectorization for the Intel Architecture. \nInternational Journal of Parallel Programming, (2):65 98, April 2002. [5] Kevin O Brien. Predictive Commoning: \nA Method of Optimizing Loops Containing References to Consecu\u00adtive Array Elements. In IBM Interdivisional \nTechnical Liason, 1990. [6] Gerald Cheong and Monica S. Lam. An Optimizer for Multimedia Instruction \nSets. In Second SUIF Compiler Workshop, August 1997. [7] Crescent Bay Software. VAST-F/AltiVec: Auto\u00admatic \nFortran Vectorizer for PowerPC Vector Unit. altivec.html, 2004. http://www.psrv.com/vast [8] Andreas \nKrall and Sylvain Lelait. Compilation Tech\u00adniques for Multimedia Processors. International Jour\u00adnal of \nParallel Programming, (4):347 361, August 2000. [9] Samuel Larsen and Saman Amarasinghe. Exploiting Superword \nLevel Parallelism with Multimedia Instruc\u00adtion Sets. In Proceedings of the SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 145 156, June 2000. [10] Dorit Naishlos, Marina Biberstein, \nShay Ben-David, and Ayal Zaks. Vectorizing for a SIMdD DSPArchi\u00adtecture. In Proceedings of International \nConference on Compilers, Architectures, and Synthesis for Embedded Systems, pages 2 11, October 2003. \n[11] John Randal Allen and Ken Kennedy. Automatic Translation of Fortran Programs to Vector Form. ACM \nTransactions on Programming Languages and Systems, (4):491 542, October 1987. [12] Hans Zima and Barbara \nChapman. Supercompilers for Parallel and Vector Computers. ACM Press, 1990. [13] N. Sreraman and R. Govindarajan. \nA Vectorizing Com\u00adpiler for Multimedia Extensions. International Journal of Parallel Programming, 28(4):363 \n400, August 2000. [14] Corinna G. Lee and Mark G. Stoodley. Simple Vector Microprocessors for Multimedia \nApplications. In Pro\u00adceedings of International Symposium on Microarchitec\u00adture, pages 25 36, 1998. [15] \nJaewook Shin, Jacqueline Chame, and Mary W. Hall. Compiler-Controlled Caching in Superword Register Files \nfor Multimedia Extension Architectures. In Pro\u00adceedings of International Conference on Parallel Archi\u00adtectures \nand Compilation Techniques, September 2002. [16] Siddhartha Chatterjee, John R. Gilbert, Robert Schreiber, \nand Thomas J. She.er. Modeling Data-Parallel Programs with the Alignment-Distribution Graph. Journal \nof Programming Languages, 2(3):227 258, 1994.  \n\t\t\t", "proc_id": "996841", "abstract": "When vectorizing for SIMD architectures that are commonly employed by today's multimedia extensions, one of the new challenges that arise is the handling of memory alignment. Prior research has focused primarily on vectorizing loops where all memory references are properly aligned. An important aspect of this problem, namely, how to vectorize misaligned memory references, still remains unaddressed.This paper presents a compilation scheme that systematically vectorizes loops in the presence of misaligned memory references. The core of our technique is to automatically reorganize data in registers to satisfy the alignment requirement imposed by the hardware. To reduce the data reorganization overhead, we propose several techniques to minimize the number of data reorganization operations generated. During the code generation, our algorithm also exploits temporal reuse when aligning references that access contiguous memory across loop iterations. Our code generation scheme guarantees to never load the same data associated with a single static access twice. Experimental results indicate near peak speedup factors, e.g., 3.71 for 4 data per vector and 6.06 for 8 data per vector, respectively, for a set of loops where 75% or more of the static memory references are misaligned.", "authors": [{"name": "Alexandre E. Eichenberger", "author_profile_id": "81100575094", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY", "person_id": "P14433", "email_address": "", "orcid_id": ""}, {"name": "Peng Wu", "author_profile_id": "81408599112", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY", "person_id": "PP39052835", "email_address": "", "orcid_id": ""}, {"name": "Kevin O'Brien", "author_profile_id": "81407594236", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY", "person_id": "PP55040384", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996853", "year": "2004", "article_id": "996853", "conference": "PLDI", "title": "Vectorization for SIMD architectures with alignment constraints", "url": "http://dl.acm.org/citation.cfm?id=996853"}