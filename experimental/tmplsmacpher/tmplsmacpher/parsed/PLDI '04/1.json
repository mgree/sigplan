{"article_publication_date": "06-09-2004", "fulltext": "\n KISS: Keep It Simple and Sequential Shaz Qadeer Dinghao Wu Microsoft Research Department of Computer \nScience One Microsoft Way Princeton University Redmond, WA 98052 Princeton, NJ 08544 ABSTRACT The design \nof concurrent programs is error-prone due to the interaction between concurrently executing threads. \nTra\u00additional automated techniques for .nding errors in concur\u00adrent programs, such as model checking, \nexplore all possi\u00adble thread interleavings. Since the number of thread inter\u00adleavings increases exponentially \nwith the number of threads, such analyses have high computational complexity. In this paper, we present \na novel analysis technique for concurrent programs that avoids this exponential complexity. Our anal\u00adysis \ntransforms a concurrent program into a sequential pro\u00adgram that simulates the execution of a large subset \nof the behaviors of the concurrent program. The sequential pro\u00adgram is then analyzed by a tool that only \nneeds to under\u00adstand the semantics of sequential execution. Our technique never reports false errors \nbut may miss errors. We have im\u00adplemented the technique in KISS, an automated checker for multithreaded \nC programs, and obtained promising initial results by using KISS to detect race conditions in Windows \ndevice drivers. Categories and Subject Descriptors D.2.4 [Software Engineering]: Software/Program Veri.\u00adcation \nassertion checkers, model checking, formal methods; F.3.1 [Logics and Meanings of Programs]: Specifying \nand Verifying and Reasoning about Programs assertions, mechanical veri.cation; F.3.2 [Logics and Meanings \nof Programs]: Semantics of Programming Languages pro\u00adgram analysis General Terms Veri.cation, Reliability \n Keywords Model checking, race detection, program analysis, concur\u00adrent software, assertion checking \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n04, June 9 11, 2004, Washington, DC, USA. Copyright 2004 ACM 1-58113-807-5/04/0006 ...$5.00. Concurrent \nC program Instrumentation Sequential C program SLAM  Error trace No bug found Figure 1: The KISS architecture. \n1. INTRODUCTION The design of concurrent programs is a complex endeavor. The main intellectual di.culty \nof this task lies in reason\u00ading about the interaction between concurrently executing threads. Concurrency \nresults in insidious programming er\u00adrors that are di.cult to reproduce, locate, and .x. There\u00adfore, analysis \ntechniques that can automatically detect and pinpoint errors in concurrent programs can be invaluable. \nIn this paper, we present and evaluate such an analysis tech\u00adnique for detecting violations of safety \nproperties in concur\u00adrent programs. Traditionally, model checkers [27, 23, 11, 35] have been used to \ncheck safety properties of concurrent programs. These tools ensure high coverage of program behavior \nby explor\u00ading all possible thread interleavings. But the large coverage comes at the price of computational \ncomplexity. The anal\u00adysis must explore the set of all reachable control states of the concurrent program. \nThis set grows exponentially with the number of threads, thus severely limiting the scalability of the \nanalysis. The subject of this paper is a new tech\u00adnique for avoiding this exponential complexity in analyzing \ninterleavings. Our analysis is based on a technique to transform a con\u00adcurrent program P into a sequential \nprogram P . that sim\u00adulates the execution of a large subset of the behaviors of P . The program P . is \nthen analyzed by a checker that only needs to understand the semantics of sequential ex\u00adecution. In particular, \nthe checker does not need to un\u00adderstand thread interleavings. The transformation has the property that \nif P . goes wrong by failing an assertion, then P must also go wrong by failing an assertion. Moreover, \nthe error trace leading to the assertion failure in P is easily constructed from the error trace in P \n. . The problem of checking safety properties on concurrent programs with .nite data is undecidable. \nRamalingam [33] has shown that the undecidable problem of checking the emptiness of the intersection \nof context-free languages is re\u00adducible to this problem. Our technique provides a complete (no false \nerrors) but unsound (may miss errors) reduction of this undecidable problem to the problem of checking \nsafety properties on sequential programs (with .nite data). The latter problem is decidable [37, 34] \nand there are several e.cient tools for solving it [8, 15, 13, 3, 25]. Thus, our technique provides a \nmethod for .nding errors in concur\u00adrent programs by leveraging a variety of analysis techniques developed \nfor sequential programs. We have implemented our technique in a tool called KISS (Keep ItSimple and Sequential!). \nKISS is an assertion checker for multithreaded C programs built on top of the SLAM [3] model checker \nfor sequential C programs. It would be straightforward to adapt our technique to other similar tools \nsuch as PRE.x [8], MC [15], ESP [13], and Blast [25]. The architecture of KISS is illustrated in Fig\u00adure \n1. KISS transforms the control .ow graph of the input multithreaded C program into the control .ow graph \nof a sequential C program, which is then analyzed by SLAM. An error trace produced by SLAM is transformed \ninto an error trace of the original concurrent program. We have ap\u00adplied KISS to the problem of detecting \nrace conditions in Windows NT device drivers. So far, KISS has analyzed 18 drivers ranging from 1 KLOC \nto 10 KLOC for a total of 70 KLOC and found 30 race conditions of which several have been determined \nto be bugs. 2. OVERVIEW KISS translates a concurrent program P into a sequen\u00adtial program P . that simulates \na large subset of the be\u00adhaviors of P . In a concurrent program, each thread has its own stack. On the \nother hand, the unique thread in a sequential program has a single stack. Thus, we need to use a single \nstack to generate behaviors that will simulate interleavings generated by multiple stacks. The sequential \nprogram P . is essentially the concurrent program P execut\u00ading under the control of a nondeterministic \nscheduler. This scheduler follows a stack discipline for scheduling threads; it supports partial thread \nresumption. At any point in time, the frames on the unique stack can be partitioned into con\u00adtiguous \nblocks. Each contiguous block is the stack of one of the threads executing currently. The scheduler nonde\u00adterministically \nchooses to do one of the following tasks. It may terminate the thread executing at the top of the stack \nby popping its contiguous block of stack frames and resume the execution of the thread whose block of \nstack frames is just below that of the terminated thread. Otherwise, it may schedule another thread by \ncalling its starting function. To perform these scheduling decisions, the scheduler requires only a few \nextra global variables. Keeping the number of extra global variables small is important since the complex\u00adity \nof most sequential-program analyses varies exponentially with the number of global variables. The algorithm \nfor stack-based nondeterministic schedul\u00ading is based on two ideas. The .rst idea allows us to nonde\u00adterministically \nterminate a thread at any time during its ex\u00adecution. We introduce a fresh global boolean variable raise \nto encode the e.ect of raising an exception; this variable is initialized to false. Preceding every statement \nin every function, we also introduce new instrumentation code that nondeterministically chooses to either \ndo nothing or set raise to true and execute a return statement. To propagate the return, we add code \nafter each function call to test the value of raise and execute another return statement if the value \nof raise is true.   The second idea allows us to schedule a nondeterminis\u00adtically chosen number of \nexisting threads at any time dur\u00ading the execution of a thread. We introduce a fresh global variable \nts, whose value is a bounded-size multiset of the starting functions of threads that have been forked \nbut not scheduled. Whenever the concurrent program invokes the function f asynchronously, we add f to \nts if ts is not full. In this case, this function will be executed at some nonde\u00adterministically chosen \ntime later on. If the set ts is full, then we replace the asynchronous call to f with a synchronous call \nto f, thus executing it immediately. The instrumen\u00adtation code preceding every statement, prior to executing \nthe nondeterministic return, performs the following task a nondeterministic number of times: it nondeterministically \nchooses a function from the set ts,invokes it,and sets raise to false when it returns. Using raise, ts, \nand the instrumentation described above, we can simulate a large number of the executions of the con\u00adcurrent \nprogram. The set ts provides a tuning knob to trade o. coverage for computational cost of analysis. Increasing \nthe size of ts increases the number of simulated behaviors at the cost of increasing the global state \nspace of the trans\u00adlated sequential program. In practice, we expect to start KISS with a small size for \nts andthenincrease it as permit\u00adted by the computational resources available for debugging. The generated \nsequential program only simulates a sub\u00adset of all executions of the concurrent program. The static nature \nof our analysis allows us to formalize this unsound\u00adness: given a 2-threaded concurrent program, the \nsequential program simulates all executions with at most two context switches. Thus, the unsoundness \nof our analysis is qual\u00aditatively di.erent from that of dynamic techniques which may explore executions \nwith multiple context switches but cannot provide any guarantees. In Section 4, we present a precise \ncharacterization of the executions of a general con\u00adcurrent program (with many threads) that are simulated \nby the transformed sequential program. We illustrate our technique by showing how it can be used to .nd \nconcurrency errors in Windows device drivers. A device typically processes a number of concurrent requests \nfrom the operating system. These requests share a data structure called device extension, which is allocated \nonce when the device starts up. Concurrent con.icting accesses to the .elds of the device extension is \na signi.cant source of errors. A second source of errors is in the synchroniza\u00adtion required for reference \ncounting of allocated resources. The operating system may issue a request to stop the de\u00advice at any \ntime. The thread performing this request must wait until all other threads executing in the driver have \n.n\u00adished their work and then free all allocated resources. We illustrate both these types of errors on \na simpli.ed model of one of the Bluetooth drivers in Windows NT. To keep the example simple yet illustrative, \nwe have abstracted away a lot of the complexity of the data structures but modeled the synchronization \nused in the driver accurately. struct DEVICE_EXTENSION { int pendingIo; bool stoppingFlag; bool stoppingEvent; \n }; bool stopped; void main() { DEVICE_EXTENSION *e = malloc(sizeof(DEVICE_EXTENSION)); e->pendingIo \n= 1; e->stoppingFlag = false; e->stoppingEvent = false; stopped = false; async BCSP_PnpStop(e); BCSP_PnpAdd(e); \n} void BCSP_PnpAdd(DEVICE_EXTENSION *e) { int status; status = BCSP_IoIncrement (e); if (status == 0) \n{ // do work here assert !stopped; } BCSP_IoDecrement(e); } void BCSP_PnpStop(DEVICE_EXTENSION *e) \n{ e->stoppingFlag = true; BCSP_IoDecrement(e); assume e->stoppingEvent; // release allocated resources \nstopped = true; } int BCSP_IoIncrement(DEVICE_EXTENSION *e) { if (e->stoppingFlag) return -1; atomic \n{ e->pendingIo = e->pendingIo + 1; } return 0; } void BCSP_IoDecrement(DEVICE_EXTENSION *e) { int pendingIo; \natomic { e->pendingIo = e->pendingIo -1; pendingIo = e->pendingIo; } if (pendingIo == 0) e->stoppingEvent \n= true; } Figure 2: The simpli.ed model of Bluetooth driver. 2.1 Bluetooth driver The simpli.ed model \nof the Bluetooth driver is shown in Figure 2. The device extension of the driver has four .elds pendingIo, \nstoppingFlag, stoppingEvent.The in\u00adteger .eld pendingIo keeps count of the number of threads that are \ncurrently executing in the driver. It is initialized to 1, incremented atomically whenever a thread enters \nthe driver, and decremented atomically whenever a thread exits the driver. The boolean .eld stoppingFlag \nis initialized to false and set to true by athread that is tryingtostop the driver. New threads are not \nsupposed to enter the driver once this .eld is true. The boolean .eld stoppingEvent models an event. \nThis .eld is initialized to false,and set to true when the event happens. The event .res when a decrement \nof pendingIo results in a value of 0. Finally, the global variable stopped is introduced to conveniently \nspec\u00adify an important safety property of the driver. This .eld is initialized to false. The thread stopping \nthe driver sets this .eld to true after it has established that there are no other threads executing \nin the driver. Other threads assert that this .eld is false just before starting their work in the driver. \nThere are two dispatch functions in the simpli.ed driver BCSP PnpAdd and BCSP PnpStop. The .rst dispatch \nfunction BCSP PnpAdd is a prototypical routine called by the operat\u00ading system to perform I/Oin the driver. \nThe second dis\u00adpatch function BCSP PnpStop is called to stop the driver. The assume statement in its \nbody blocks until the condi\u00adtion e->stoppingEvent becomes true; this statement is ex\u00adplained in more \ndetail in Section 3. We model concurrent execution of the driver by a program that begins by calling \nthe function main. This function allocates a device exten\u00adsion, initializes its .elds, forks o. a thread \nto asynchronously execute BCSP PnpStop andthencalls BCSP PnpAdd. 2.2 Race detection We now show how \nour analysis detects a race condition on the .eld stoppingFlag of the device extension. For this example, \na size 0 for the multiset ts is enough to expose the race. In the translation, bounding ts by 0 e.ectively \nreplaces the asynchronous function calls in the function main by the corresponding synchronous function \ncalls. In addition, the instrumentation before every statement in every function allows a function to \nreturn from any control location after setting raise to true. When we run the model checker on the transformed \nse\u00adquential program, it explores the following erroneous path. The path starts execution at the beginning \nof main and makes a synchronous function call to BCSP PnpStop.In the function BCSP PnpStop, just after \nthe write to stoppingFlag, raise is set to true and a return statement is executed. When control returns \nto main, raise is reset to false and BCSP PnpAdd is called. The function BCSP PnpAdd calls the function \nBCSP IoIncrement, where there is a read of the .eld stoppingFlag. Thus, this execution exposes a race \ncondi\u00adtion on the .eld stoppingFlag. 2.3 Assertion checking We now show how our analysis detects the \nviolation of the assertion in the dispatch function BCSP PnpAdd. The error trace leading to the assertion \nviolation cannot be simulated by the transformed sequential program if the size of ts is 0. However, \nthe error trace can be simulated if the size of ts is increased to 1. The erroneous path explored by \nthe model checker in the transformed sequential program is as follows. After the main function .nishes \ninitializing the allocated device extension, function names f ::= f0 |f1 |...       integers i \n::= ... |-1 |0 |1 |... boolean constants b ::= true |false constants c ::= i |b |f primitives op ::= \n+ |-|\u00d7|== variables v ::= v0 |v1 |... values u ::= v |c statements s ::= v0 = c | v0 =&#38;v1 | v0 = \n*v1 |*v0 = v1 | v0 = v1 op v2 | assert(v0) | assume(v0) | atomic{s} | v = v0() | async v0() | return \n| s1; s2 | choice{s1 [] ... [] sn} | iter{s} Figure 3: A parallel language. it adds BCSP PnpStop to ts \nandthencalls BCSP PnpAdd.The function BCSP PnpAdd calls BCSP IoIncrement which reads the .eld stoppingFlag. \nSince the value of stoppingFlag is false, control moves to the beginning of the atomic in\u00adcrement. At \nthis point, BCSP PnpStop is removed from ts and its execution begins. It sets stoppingFlag to true and \ncalls BCSP IoDecrement. The function BCSP IoDecrement decrements pendingIo to0and sets stoppingEvent \nto true. Consequently, when BCSP IoDecrement returns, the assume statement in BCSP PnpStop does not block \nand stopped is set to true. Now the execution of BCSP PnpStop termi\u00adnates. At this point, the execution \nstack has two entries BCSP IoIncrement at the top and BCSP PnpAdd at the bot\u00adtom. The function BCSP IoIncrement \nresumes execution, in\u00adcrements pendingIo to 1, and returns 0. Since the returned value is 0, the conditional \nof the if statement in BCSP PnpAdd is true and control moves to the assertion, which is violated since \nthe value of stopped is true. The examples discussed in this section suggest that the executions explored \nby the transformed sequential program, although a subset of the set of all behaviors of the concur\u00adrent \nprogram, are still varied enough to catch a variety of common concurrency errors.  3. A PARALLEL LANGUAGE \nKISS is capable of handling general multithreaded C pro\u00adgrams. To succinctly present the main idea behind \nKISS, we formalize its analysis for a simple parallel language that is capable of modeling conventional \nconcurrent programs. The syntax for this language is shown in Figure 3. We essentially have a procedural \nlanguage extended with asyn\u00adchronous procedure calls (async), atomic statements (atomic), and blocking \nstatements (assume). The language is equipped with pointer operations for taking the address of a variable \nand for obtaining the contents of an address. Fields have been omitted for simplicity of exposition; \nhowever, KISS can handle them just as well.        The asynchronous function call async v0() creates \na new thread whose starting function is the value of the variable v0. After this thread is created, its \nactions get interleaved with the actions of the existing threads. The statement assume(v0) blocks until \nthe variable v0 be\u00adcomes true. In a sequential program, if control arrives at assume(v0)when v0 is false, \nthen the program is blocked for\u00adever. However, in a concurrent program a thread blocked at the assume \nstatement might get unblocked if another thread changes the value of v0. The statement atomic{s}executes \njust like s except that the execution may not be interrupted in the middle by other threads. The atomic \nstatement, together with the assume statement, is used to implement synchronization primitives, such \nas lock acquire and lock release. def lock acquire(l)= atomic{assume(*l == 0); *l =1; } def lock release(l)= \natomic{*l =0; } Here, the type of the variable l is a pointer to a integer. The nondeterministic choice \nstatement makes choices be\u00adtween di.erent branches; exactly one branch will be exe\u00adcuted nondeterministically. \nThe iteration statement iter{s}does not have a termination condition. It executes s anon\u00addeterministic \nnumber of times. The conventional conditional and loop statements can be modeled as follows: def if (v) \ns1 else s2 = choice{assume(v); s1 [] assume(\u00acv); s2} def while (v) s = iter{assume(v); s}; assume(\u00acv) \nHere, the symbol \u00acis logical negation as usual. There are no explicit boolean expressions in the language; \ndecisions are made on variables. Decisions on an expression can be modeled by .rst assigning the expression \nto a fresh variable. We assume that other analyses are used to check that a program written in this parallel \nlanguage is well-typed. In addition to the usual requirements, we also require that the statement s in \natomic{s}is free of function calls (both syn\u00adchronous and asynchronous), return statements, and nested \natomic statements. This requirement does not pose any re\u00adstriction on the expressiveness of the language \nsince the most common use of the atomic statement is to implement syn\u00adchronization primitives.  4. PROGRAM \nTRANSFORMATION In this section, we present our method for translating a concurrent program into a sequential \nprogram. For the pur\u00adpose of this section, a concurrent program is one express\u00adible in the parallel language \nof Section 3 and a sequential program is one expressible in the parallel language without using asynchronous \nfunction calls and atomic statements. The translation function [ \u00b7] for translating a concurrent program \nto a sequential program is de.ned recursively in Figure 4. For any statement s, the transformed code \n[ s]] isa statement without any asynchronous function calls and syn\u00adchronization statements. For any \nfunction f in the program with body s, we introduce a new function [ f]] with body [[s]]. To achieve \nnondeterministic termination of a thread at any time during its execution, we introduce a fresh global \nboolean variable raise. To terminate a thread, this vari\u00adable is set to true and a return statement is \nexecuted. The [[v0 = c]] [[v0 =&#38;v1]] [[v0 = *v1]] [[*v0 = v1]] [[v0 = v1 op v2]] [[assert (v0)]] \n[[assume(v0)]] [[atomic{s}]] [[v = v0()]] [[async v0()]] [[return]] [[s1; s2]] [[choice{s1[]...[]sn}]] \n[[iter{s}]]  = schedule(); choice{skip [] RAISE}; v0 = c = schedule(); choice{skip [] RAISE}; v0 =&#38;v1 \n= schedule(); choice{skip [] RAISE}; v0 = *v1 = schedule(); choice{skip [] RAISE}; *v0 = v1 = schedule(); \nchoice{skip [] RAISE}; v0 = v1 op v2 = schedule(); choice{skip [] RAISE}; assert (v0) = schedule(); choice{skip \n[] RAISE}; assume(v0) = schedule(); choice{skip [] RAISE}; s = schedule(); choice{skip [] RAISE}; v =[[v0] \n(); if (raise) return = schedule(); choice{skip [] RAISE}; if (size() < MAX ) put(v0) else {[[v0] (); \nraise = false} = schedule(); return = [ s1]]; [ s2]] = choice{[[s1]] [] ... [] [ sn]]} = iter{[[s]]} \n Figure 4: Instrumentation for assertion checking. RAISE statement performs this task. def RAISE = raise \n= true; return Let skip represent the statement assume(true). At every control location, we introduce \nthe following code to execute the RAISE statement nondeterministically. choice{skip [] RAISE} A thread \nmay return after setting raise to true with a num\u00adber of functions on its stack. To terminate the thread, \nall of these functions need to be popped. Therefore, we introduce after each function call, a statement \nthat checks the value of raise and returns if the value is true. As described later, the variable raise \nis reset to false when all stack frames of the terminated thread have been popped. In addition to terminating \na thread nondeterministically, we also need to schedule other threads at any point dur\u00ading a thread s \nexecution. We introduce a fresh global vari\u00adable ts to keep track of the set of threads that have been \nforked but not scheduled yet. The variable ts is a multiset of function names; each name indicates the \nstart function of an unscheduled thread. Our translation is parameterized by MAX , the maximum size of \nthis set. There are three special functions to access and modify the variable ts. The function get requires \nthat ts is not empty; it removes and returns a nondeterministically chosen element of ts. The function \nput requires that the number of elements in ts is less than MAX ; it takes as argument a function name \nand adds it to ts.The function size returns the number of elements in ts. The function schedule allows \nus to schedule a nondeter\u00administically chosen set of threads from ts. schedule() { var f; iter { if (size() \n>0) { f = get(); [[f] (); raise = false; } } } This function gets an arbitrary number of existing threads \nin the set ts and executes them one after another. After a thread returns, potentially because it set \nraise to true,the variable raise is reset to false. The function schedule encapsulates the scheduling \npolicy for the concurrent program. The implementation of this function presented above assumes a completely \nnondeter\u00administic scheduler. A more sophisticated scheduler can be provided by writing a di.erent implementation \nof schedule. Before most statements, the translation function inserts a call to schedule followed by \nthe nondeterministic execution of RAISE. The instrumentation for asynchronous and syn\u00adchronous function \ncalls is noteworthy. When a function f is called asynchronously, the instrumentation checks the size \nof ts.If ts is full, the function [ f] is called synchronously. Otherwise, the function f is added to \nts.Thus, the maxi\u00admum size of ts determines the number of possible executions of the original program \nthat can be simulated by the trans\u00adlated program. When a function f is called synchronously, the instrumentation \ncalls [ f] instead. When [ f] returns, the value of raise is checked and if it is true, a return statement \nis executed to propagate the exception. Given a concurrent program s, the sequential program to be analyzed \nis de.ned as follows: def Check(s)= raise = false; ts = \u00d8;[[s]]; schedule(); The program Check(s) initializes \nraise and ts appropriately, executes [ s] , and .nally schedules the remaining unsched\u00aduled threads. \nFor a sequential program with boolean variables, the com\u00adplexity of model checking (or interprocedural \ndata.ow anal\u00adysis) is O(|C|\u00b72g+l), where |C| is the size of the control-.ow graph, g is the number of \nglobal variables, and l is the max\u00adimum number of local variables in scope at any location. Our instrumentation \nintroduces a small constant blowup in the control-.ow graph of the concurrent program and adds a small \nconstant number of global variables. Thus, the com\u00adplexity of using KISS on a concurrent program of a \ncertain size is about the same as using a standard interprocedural data.ow analysis or model checking \non a sequential program of the same size. [[v = c]] = [[v =&#38;v1]] = [[v = *v1]] = [[*v = v1]] = [[v \n= v1 op v2]] = [[assert (v)]] = [[assume(v)]] = [[atomic{s}]] = [[v = v0()]] = [[async v0()]] = [[return]] \n= [[s1; s2]] = [[choice{s1[]...[]sn}]] = [[iter{s}]] = 4.1 Coverage analysis schedule(); choice{skip \n[] check w(&#38;v); RAISE}; v = c schedule(); choice{skip [] check w(&#38;v); RAISE}; v =&#38;v1 schedule(); \nchoice{skip [] checkr(&#38;v1); RAISE [] check r(v1); RAISE [] check w(&#38;v); RAISE}; v = *v1 schedule(); \nchoice{skip [] checkr(&#38;v1); RAISE [] check r(&#38;v); RAISE [] check w(v); RAISE}; *v = v1 schedule(); \nchoice{skip [] checkr(&#38;v1); RAISE [] check r(&#38;v2); RAISE [] checkw(&#38;v); RAISE}; v = v1 op \nv2 schedule(); choice{skip [] checkr(&#38;v); RAISE}; assert(v) schedule(); choice{skip [] checkr(&#38;v); \nRAISE}; assume(v) schedule(); choice{skip [] RAISE}; s schedule(); choice{skip [] checkrv =[[v0] (); \nif (raise) return schedule(); choice{skip [] checkr if (size() <MAX ) put(v0) else {[[v0] (); raise = \nfalse} schedule(); return [ s1]]; [ s2]] choice{[[s1]] [] ... [] [ sn]]} iter{[[s]]}  Figure 5: Instrumentation \nfor race checking. Every path in the sequential program Check(s)simulates a potential execution of the \noriginal program s. However, the sequential program Check(s) does not simulate all ex\u00adecutions of s. \nTherefore, if an assertion is violated in the translated sequential program, it is violated in some exe\u00adcution \nof the multithreaded program as well, but not vice versa. In this section, we characterize more formally \nthe set of executions of s that are covered by Check(s). We .rst introduce some notation to enable the \nformal characterization. Suppose that each thread created by a concurrent program has a unique identi.er \nin the set N = {1,2,...}. For any .nite set X . N, we de.ne a language LX . N * recursively as follows: \n* ** LX = {i \u00b7 LX1 \u00b7 ...\u00b7 i \u00b7 LXk \u00b7 i |{i},X1, ...,Xk form a partition of X} where \u00b7 denotes concatenation \nover strings and string lan\u00adguages as usual, and * stands for Kleene closure. A string in N * is balanced \nif it belongs to LX for some .nite X . N. An execution of a concurrent program is a .nite sequence of \nstates and transitions, where each transition is labeled with the identi.er of the thread that performed \nthe transi\u00adtion. From each execution, we generate a string in N * by concatenating the identi.ers labeling \nthe transitions in the execution. An execution is balanced if the corresponding string is balanced. We \ncan now state the following theorem characterizing the executions simulated by Check(s). Theorem 1 (Completeness). \nSuppose the multiset ts is unbounded. If a balanced execution of a concurrent pro\u00adgram s goes wrong by \nfailing an assertion, then the sequential program Check(s) also goes wrong, and vice versa. (&#38;v0); \nRAISE [] check w(&#38;v); RAISE}; (&#38;v0); RAISE};  5. RACE DETECTION In this section, we augment \nthe translation of Section 4 with auxiliary information to enable the detection of race conditions. We \n.x a distinguished variable r and describe instrumentation that checks for race conditions on r. In addition \nto the variables added by the instrumentation described in Section 4, the new instrumentation also requires \na fresh global variable access that takes values from the set {0,1,2}.The value of access is 0 if no \naccess to r has oc\u00adcurred, 1 if a read access has occurred, and 2 if a write access has occurred. We \nalso need two functions, checkr and check w, which are de.ned below. check r(x) {if (x== &#38;r) {assert(\u00ac(access \n== 2)); access =1; }} Acall check r(x) checks that there is no race on r due to a read of the address \ncontained in x. If the address x is an alias of &#38;r, the address of the variable being checked for \nrace conditions, the function check r asserts that there has not been a write access to r. Since we check \nfor read/write and write/write races, two simultaneous read accesses are allowed. If the assertion passes, \nthe variable access is set to 1toindicate that aread access to r has happened. check w(x) { if (x== &#38;r) \n{assert(access == 0); access =2; } } Similarly, a call checkw(x) checks that there is no race on r due \nto a write to the address contained in x. If the address Driver KLOC Fields Races No Races tracedrv 0.5 \n3 0 3 mou.ltr 1.0 14 7 7 kb.ltr 1.1 15 8 7 imca 1.1 5 1 4 startio 1.1 9 0 9 toaster/toastmon 1.4 8 1 \n7 diskperf 2.4 16 2 14 1394diag 2.7 18 1 17 1394vdev 2.8 18 1 17 fakemodem 2.9 39 6 31 gameenum 3.9 45 \n11 24 toaster/bus 5.0 30 0 22 serenum 5.9 41 5 21 toaster/func 6.6 24 7 17 mouclass 7.0 34 1 32 kbdclass \n7.4 36 1 33 mouser 7.6 34 1 27 fdc 9.2 92 18 54 Total 69.6 481 71 346 Table 1: Experimental results \n(I). x is an alias of &#38;r, it asserts that there has not been either a read or a write access to r. \nMoreover, if the assertion passes, it sets access to 2 to indicate that a write access to r has happened. \nThe translation function is shown in Figure 5. The trans\u00adlation looks very similar to that for assertion \nchecking, ex\u00adcept that we introduce a call checkr(&#38;v) for each read access to variable v,and a call \ncheck w(&#38;v) for each write access to v. Every such call by a thread is followed immediately by RAISE \nwhich causes the thread to terminate. Thus, an assertion in one of these calls is violated only if there \nare con\u00ad.icting (read/write or write/write) accesses by two di.erent threads. We use a static alias analysis \n[12] to optimize away most of the calls to check r and check w. If the alias analysis deter\u00admines that \nthe variable v being accessed cannot be aliased to the distinguished variable r, then the call to checkr \n(or check w) has no e.ect and is therefore omitted in the instru\u00admentation. Thus, our analysis generates \na separate sequen\u00adtial program for detecting race conditions on each shared variable. Given a concurrent \nprogram s, the sequential program to be analyzed is as follows: Check(s) def raise = \u00d8; access =0; [ \ns]]; schedule(); == false; ts As for the translation in Section 4, every path in Check(s) simulates a \npotential execution of the original program s, but Check(s) does not capture all possible executions \nof s. If an assertion is violated in Check(s), there is an execution of s in which either an assertion \nis violated or there is a race condition on r. 6. EVALUATION We have used KISS to detect race conditions \nin a number of device drivers in the Windows Driver Development Kit. In this section, we present the \nresults of our experiments. As mentioned earlier in Section 2, each device driver has a data structure \ncalled the device extension that is shared Driver Races mou.ltr 0 kb.ltr 0 imca 1 toaster/toastmon 1 \ndiskperf 0 1394diag 1 1394vdev 1 fakemodem 6 gameenum 1 serenum 2 toaster/func 5 mouclass 1 kbdclass \n1 mouser 1 fdc 9 Total 30 Table 2: Experimental results (II). among the various threads executing in \nit. For each de\u00advice driver, we checked for race conditions on each .eld of the device extension separately. \nA device driver is writ\u00adten as a library of dispatch routines that may be called by the operating system. \nFor each device driver, we created a concurrent program with two threads, each of which nonde\u00adterministically \ncalls a dispatch routine. To have a complete concurrent program, we also need models for the routines \nof the operating system called by the driver. SLAM already provided stubs for these calls; we augmented \nthem to model the synchronization operations accurately. Some of the syn\u00adchronization routines we modeled \nwere KeAcquireSpinLock, KeWaitForSingleObject, InterlockedCompareExchange, InterlockedIncrement, etc. \nGuided by the intuition of the Bluetooth driver example in Section 2.2, we set the size of ts to 0. We \nperformed the experiments on a 2.2 GHz PC running Windows XP. For each run of KISS on a device driver \nand a .eld of the device extension, we set a resource bound of 20 minutes of CPU time and 800MB of memory. \nTable 1 gives a summary of our results. For each driver, we give the code size in KLOC (thousand lines \nof code), the number of .elds in the device extension, the number of .elds on which a race condition \nwas detected, and the number of .elds on which the analysis terminated within the resource bound without \nreporting any errors. We ran KISS on 18 device drivers ranging from 0.5 KLOC to 9.2 KLOC for a total \nof 69.6 KLOC. The tool reported at least one race condition in 15 drivers for a total of 71 race conditions. \nDue to the large number of reported race conditions, it was infeasible to carefully review them all. \nTherefore, we showed a small subset of these race conditions to the Win\u00addows driver quality team. We \nfound that KISS was reporting spurious race conditions primarily because of the impreci\u00adsion of the concurrent \nharness executing dispatch functions in the device driver. Drivers are written under the (typically undocumented) \nassumption that certain pairs of dispatch routines cannot be called concurrently by operating system, \nbut out harness allowed all such pairs to be executed con\u00adcurrently. The most important such assumptions \nmentioned by the driver quality team are the following: A1. Two Pnp IRPs (interrupt request packets) \nwill not be sent by the operating system concurrently. A2. The operating system will not send any IRP \nconcur\u00ad rently with a Pnp IRP for starting or removing a de\u00ad vice. A3. There are two categories of Power \nIRPs system and device. Two Power IRPs sent concurrently by the op\u00ad erating system must belong to di.erent \ncategories. The above rules are general and applicable to all drivers. But some rules are speci.c to \nparticular drivers, as in the case of kb.ltr and mou.ltr. The error traces for all race conditions reported \nby KISS on these two drivers involved two concurrent Ioctl IRPs. However, the position of these two drivers \nin the driver stack ensures that they will never receive two concurrent Ioctl IRPs; consequently, the \nrace conditions reported by KISS were spurious. We used the feedback from the driver quality team to \nre.ne the harness and ran KISS again on the .elds on which race conditions were reported in the .rst \nset of experiments. We present the results of this second set of experiments in Table 2. The total number \nof reported race conditions went down from 71 to 30. After examining a subset of the remaining race conditions, \nthe driver quality team con.rmed that the race conditions in toaster/toastmon, mouclass, and kbdclass \nare bugs. In addi\u00adtion, the race conditions on three .elds of fdc generated a lot of debate and were \nconsidered serious enough to be tabled for further discussion. The feedback from the driver quality team \nsuggested that the warnings produced by KISS were useful for more than just .nding concurrency bugs. \nThese warnings also served to focus costly manual code inspection resources on tricky areas of the driver \ncode. We illustrate the errors found by KISS with the race con\u00addition on the .eld DevicePnPState of the \ndevice extension in toaster/toastmon. This .eld is accessed in most places while holding a lock but there \nis an unprotected read to it as well. The read/write race condition is exposed by the concurrent execution \nof the two dispatch functions shown in Figure 6. Another interesting source of spurious warnings are \nbe\u00adnign race conditions. Consider the race condition found by KISS on the .eld OpenCount of the device \nextension of the fakemodem driver. This .eld keeps track of the number of threads executing in the driver. \nIn all places but one, OpenCount is incremented while holding a lock. But there is a single unprotected \naccess in which a decision is based on whether the value read for OpenCount is 0. The read op\u00aderation \nis atomic already; performing it while holding the protecting lock will not reduce the set of values \nthat may be read. So the programmer chose to not pay for the overhead of locking. We are continuing our \ndialogue with the driver quality team to establish which races are benign. In future work, we intend \nto deal with the problem of benign races by allowing the programmer to annotate an access as benign. \nKISS can then use this annotation as a directive to not instrument that access. We are also planning \nto use the ideas behind the type system for atomicity [20] to automatically prune such benign race conditions. \nWe have also used KISS to .nd concurrent reference count\u00ading errors in device drivers, as exempli.ed \nby the assertion NTSTATUS ToastMon_DispatchPnp ( IN PDEVICE_OBJECT DeviceObject, IN PIRP Irp ) { . . \n. status = IoAcquireRemoveLock (&#38;deviceExtension->RemoveLock, Irp); . . . switch (irpStack->MinorFunction) \n{ . . . case IRP_MN_QUERY_STOP_DEVICE: // Race: write access deviceExtension->DevicePnPState = StopPending; \nstatus = STATUS_SUCCESS; break; . . . } . . . IoReleaseRemoveLock (&#38;deviceExtension->RemoveLock, \nIrp); return status; } NTSTATUS ToastMon_DispatchPower( IN PDEVICE_OBJECT DeviceObject, IN PIRP Irp ) \n{ . . . // Race: read access if (Deleted == deviceExtension->DevicePnPState) { PoStartNextPowerIrp(Irp); \nIrp->IoStatus.Status = STATUS_DELETE_PENDING; IoCompleteRequest(Irp, IO_NO_INCREMENT ); return STATUS_DELETE_PENDING; \n } . . . } Figure 6: Race condition in toaster/toastmon. violation in our simple model of the bluetooth \ndriver (Sec\u00adtion 2.3). Just as in the simple model, we manually in\u00adtroduced into the code of each driver \nan auxiliary boolean global variable stopped to model the stopping of the driver. We introduced assignments \ninitializing stopped to false and updating it to true when the driver is stopped, and asser\u00adtions at \nappropriate places in the code of the various dis\u00adpatch routines stating that this variable is false. \nGuided by the intuition of Section 2.3, we set the size of ts to 1. We ran KISS on two drivers bluetooth \nand fakemodem. Not surprisingly, since our example in Section 2.3 is based on the bluetooth driver, KISS \nfound the assertion violation in the actual driver as well. The bug is in the implementation of the BCSP \nIoIncrement function. After .xing the bug as suggested by the driver quality team, we ran KISS again \nand this time KISS did not report any errors. KISS did not report any errors in the fakemodem driver. \nWe examined the code dealing with reference counting in the fakemodem driver and observed that it behaved \nexactly according to the .xed implementation of BCSP IoIncrement.Hence, we believe that the fakemodem \ndriver does not have this error. 6.1 Discussion Our experience with KISS shows that it is a useful and \nviable approach for .nding errors in concurrent programs. Although unsound, the KISS approach has managed \nto un\u00adcover a number of subtle concurrency errors in device drivers. We believe that the .exibility of \nour approach sets it apart from other existing work on race-detection. Flexibility in implementation: \nOur checker can con\u00adveniently support a variety of synchronization mechanisms and is easily extensible \nto new ones. For analyzing systems code, this .exibility is essential as illustrate by our experi\u00adence \nwith NT drivers. To analyze these drivers, we mod\u00adeled several synchronization mechanisms such locks, \nevents, interlocked compare and exchange, etc. Most existing race\u00addetection tools, both static and dynamic, \nare based on the lockset algorithm which can handle only the simplest syn\u00adchronization mechanism of locks. \nFlexibility in environment modeling: Our experi\u00adence with checking low-level systems code indicates that \nto avoid being inundated with false alarms, care must be taken in modeling the environment of the module \nbeing analyzed. Our tool provides a .exible mechanism for writing an ex\u00adperimenting with such environments. \nFlexibility in speci.cation: Our tool is a general asser\u00adtion checker for concurrent programs and can \ncheck safety properties other than just race-freedom. For example, the reference counting error in the \nbluetooth driver manifested itself through an assertion violation. This error is not a race condition \naccording to the traditional de.nition of race\u00adfreedom.  7. RELATED WORK There has been a substantial \namount of research on the problem of debugging and verifying concurrent programs. Here, we discuss the \nmore relevant research along several axes. Model checking: Model checkers systematically explore the \nstate space of a model of the concurrent program. The model is constructed either manually or extracted \nautomat\u00adically by a tool. The model checker SPIN [27] checks mod\u00adels written in the Promela [26] modeling \nlanguage. Other model checkers such as the JPF [23, 39], Bandera [11], and Bogor [35] directly analyze \nmultithreaded Java programs. These model checkers exploit partial-order reduction tech\u00adniques [31, 21] \nto reduce the number of explored interleav\u00adings. But in the worst case, they must still explore an exponential \nnumber of control states. The model checkers SLAM [3] and Blast [25] analyze sequential C programs. Re\u00adcently, \nBlast has been extended to check properties of multi\u00adthreaded C programs using the approach of thread-modular \nmodel checking [19, 24]. This approach is sound but may report false errors. Our technique is complementary \nbecause although it is unsound, it will never report false errors. Static analysis: Static analysis tools \nfor concurrent pro\u00adgrams are typically based on type systems and data.ow analyses. In general, they do \nnot directly analyze thread interleavings. Consequently, they are less precise but more scalable than \nmodel checkers. Warlock [38] is a static race detection tool for ANSI C programs. Aiken and Gay [1] in\u00advestigate \nstatic race detection in the context of SPMD pro\u00adgrams. The Race Condition Checker (RccJava) [16, 17] \nuses a type system to catch race conditions in Java programs. This approach has been extended [6, 5] \nand adapted to other languages [22]. Engler and Ashcraft [14] have developed a static tool RacerX based \non interprocedural data.ow anal\u00adysis to detect both race conditions and deadlocks. The Ex\u00adtended Static \nChecker for Java (ESC/Java) [18], which uses a veri.cation-condition generator and an automatic theorem \nprover to .nd errors, catches a variety of software defects in addition to race conditions. ESC/Java \nhas been extended to catch higher-level race conditions, where a stale value from one synchronized block \nis used in a subsequent synchro\u00adnized block [7]. Flanagan and Qadeer [20] have developed a type and e.ect \nsystem, which is a synthesis of Lipton s theory of reduction [29] and type systems for race detec\u00adtion, \nfor checking atomicity of methods in multithreaded Java programs. The advantage of our approach over \nthese static analyses is that it is more precise and it can check more general speci.cations such as \nprogram assertions. Dynamic analysis: Dynamic tools work by instrument\u00ading and executing the program. \nThey are easy to use but their coverage is typically small since only a few executions are explored. \nSeveral methods [2, 30, 32] have been de\u00adveloped to detect race conditions by computing Lamport s happens-before \nrelation [28] dynamically. Eraser [36] is a dynamic race-detection tool aimed at the lock-based syn\u00adchronization. \nEraser .nds races by keeping track of locks held during program execution. This algorithm has been extended \nto object-oriented languages [40] and improved for precision and performance [10]. A race detection tool \nhas also been developed for Cilk programs [9]. Although both the dynamic approach and our static approach \nare unsound, the coverage provided by them seem to be complementary in nature. Our approach can schedule \nthreads only according to the stack discipline but for each such schedule all possi\u00adble paths in each \nthread are explored. A dynamic approach may allow schedules not allowed by our approach but for each \nschedule only a small number of paths in each thread are explored. Others: Bouajjani et al. [4] present \na generic approach to the static analysis of concurrent programs, focusing on the synchronous message-passing \nmechanism. Their veri.cation method is not automated whereas the approach described in this paper is \nfully automated. 8. CONCLUSION We have introduced a novel technique for checking as\u00adsertions in multithreaded \nprograms. The technique never reports false errors but may miss errors. The key idea of our analysis \nis the transformation of a concurrent program into a sequential program which simulates a large subset \nof the behaviors of the concurrent program. The transformed sequential program may then be checked by \nany sequential analysis tool. We have implemented our debugging technique in KISS (Keep ItSimple and \nSequential!), an automated checker for multithreaded C programs built on top of the SLAM [3] model checker \nfor sequential C programs. It is straightfor\u00adward to adapt our technique to other similar tools such \nas PRE.x [8], MC [15], ESP [13], and Blast [25]. Thus, our technique is a general framework for checking \nsafety prop\u00aderties of concurrent programs, that can leverage a variety of analysis techniques developed \nfor sequential programs. We have applied KISS to the problem of detecting race condi\u00adtions in Windows \nNT device drivers and obtained promising initial results. KISS has analyzed 18 drivers for a total of \n70 KLOC and found 30 race conditions of which several have been determined to be bugs.   Acknowledgments \nWe gratefully acknowledge the help of our colleagues, Tom Ball, Byron Cook, Jakob Lichtenberg, and Sriram \nRajamani, for answering numerous questions about SLAM and for help\u00ading with the implementation of KISS. \nWe also thank Trishul Chilimbi for suggesting the name KISS, and Andrew Appel, Jim Larus, Xinming Ou, \nSriram Rajamani, and anonymous reviewers for their feedback on earlier drafts of this paper. 9. REFERENCES \n[1] A. Aiken and D. Gay. Barrier inference. In Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on \nPrinciples of Programming Languages (POPL 98), pages 243 354. ACM Press, 1998. [2] Anne Dinning and Edith \nSchonberg. An empirical comparison of monitoring algorithms for access anomaly detection. In Proceedings \nof the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP), pages \n1 10, 1990. [3] T. Ball and S. Rajamani. The SLAM project: debugging system software via static analysis. \nIn Proceedings of the 29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL \n02), pages 1 3. ACM Press, 2002. [4] A. Bouajjani, J. Esparza, and T. Touili. A generic approach to the \nstatic analysis of concurrent programs with procedures. In Proceedings of the 30th ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages (POPL 03), pages 62 73. ACM Press, 2003. [5] C. Boyapati, \nR. Lee, and M. Rinard. Ownership types for safe programming: preventing data races and deadlocks. In \nProceedings of the 17th Annual Conference on Object-Oriented Programming Systems, Languages, and Applications \n(OOPSLA 02), pages 211 230. ACM Press, 2002. [6] C. Boyapati and M. Rinard. A parameterized type system \nfor race-free Java programs. In Proceedings of the 16th Annual Conference on Object-Oriented Programming \nSystems, Languages, and Applications (OOPSLA 01), pages 56 69, Tampa Bay, FL, 2001. [7] M.Burrows and \nK. R.M.Leino.Finding stale-value errors in concurrent programs. Technical Note 2002-4, Compaq Systems \nResearch Center, May 2002. [8] W. R. Bush, J. D. Pincus, and D. J. Siela.. A static analyzer for .nding \ndynamic programming errors. Software-Practice and Experience, 30(7):775 802, June 2000. [9] G.-I. Cheng, \nM. Feng, C. E. Leiserson, K. H. Randall, and A. F. Stark. Detecting data races in Cilk programs that \nuse locks. In Proceedings of the 10th annual ACM Symposium on Parallel Algorithms and Architectures, \npages 298 309. ACM Press, 1998. [10] J.-D. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, and M. \nSridharan. E.cient and precise datarace detection for multithreaded object-oriented programs. In Proceedings \nof the ACM SIGPLAN 2002 Conference on Programming Language Design and Implementation (PLDI 02), pages \n258 269, June 2002. [11] J. Corbett, M. Dwyer, J. Hatcli., S. Laubach, C. P.as.areanu, Robby, and H. \nZheng. Bandera: extracting .nite-state models from Java source code. In International Conference on Software \nEngineering, pages 439 448, 2000. [12] M. Das. Uni.cation-based pointer analysis with directional assignments. \nIn Proceedings of the ACM SIGPLAN 2000 Conference on Programming Language Design and Implementation (PLDI \n00), pages 35 46. ACM Press, 2000. [13] M. Das, S. Lerner, and M. Seigle. ESP: Path-sensitive program \nveri.cation in polynomial time. In Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language \nDesign and Implementation (PLDI 02), pages 57 69, 2002. [14] D. Engler and K. Ashcraft. RacerX: e.ective, \nstatic detection of race conditions and deadlocks. In Proceedings of the 19th ACM Symposium on Operating \nSystems Principles, pages 237 252. ACM Press, 2003. [15] D. Engler, B. Chelf, A. Chou, and S. Hallem. \nChecking system rules using system-speci.c, programmer-written compiler extensions. In Proceedings of \nthe 4th Symposium on Operating Systems Design and Implementation (OSDI 00), pages 1 16. Usenix Association, \n2000. [16] C. Flanagan and M. Abadi. Types for safe locking. In Proceedings of European Symposium on \nProgramming, pages 91 108, March 1999. [17] C. Flanagan and S. Freund. Type-based race detection for \nJava. In Proceedings of the ACM SIGPLAN 2000 Conference on Programming Language Design and Implementation \n(PLDI 00), pages 219 232, 2000. [18] C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson,J. B.Saxe, \nand R.Stata.Extended static checking for Java. In Proceedings of the ACM SIGPLAN 2002 Conference on Programming \nLanguage Design and Implementation (PLDI 02), pages 234 245. ACM Press, 2002. [19] C. Flanagan and S. \nQadeer. Thread-modular model checking. In Proceedings of the SPIN Workshop on Software Veri.cation, pages \n213 224, 2003. [20] C. Flanagan and S. Qadeer. A type and e.ect system for atomicity. In Proceedings \nof the ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation (PLDI 03), pages \n338 349, 2003. [21] P. Godefroid. Partial-Order Methods for the Veri.cation of Concurrent Systems: An \nApproach to the State-Explosion Problem. Lecture Notes in Computer Science 1032. Springer-Verlag, 1996. \n[22] D. Grossman. Type-safe multithreading in Cyclone. In Proceedings of the 2003 ACM SIGPLAN International \nWorkshop on Types in Language Design and Implementation, pages 13 25. ACM Press, 2003. [23] K. Havelund \nand T. Pressburger. Model checking Java programs using Java PathFinder. Software Tools for Technology \nTransfer (STTT), 2(4):72 84, 2000. [24] T. A. Henzinger, R. Jhala, R. Majumdar, and S. Qadeer. Thread-modular \nabstraction re.nement. In CAV 2003: Computer Aided Veri.cation, pages 262 274, 2003. [25] T. A. Henzinger, \nR. Jhala, R. Majumdar, and G. Sutre. Lazy abstraction. In Proceedings of the 29th ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages (POPL 02), pages 58 70. ACM Press, 2002. [26] G. Holzmann. \nDesign and Validation of Computer Protocols. Prentice-Hall, 1991. [27] G. Holzmann. The model checker \nSPIN. IEEE Transactions on Software Engineering, 23(5):279 295, May 1997. [28] L. Lamport. Time, clocks, \nand the ordering of events in a distributed program. Communications of the ACM, 21(7):558 565, 1978. \n[29] R. Lipton. Reduction: A method of proving properties of parallel programs. Communications of the \nACM, 18(12):717 721, 1975. [30] J. Mellor-Crummey. On-the-.y detection of data races for programs with \nnested fork-join parallelism. In Proceedings of the 1991 ACM/IEEE conference on Supercomputing, pages \n24 33. ACM Press, 1991. [31] D. Peled. Combining partial order reductions with on-the-.y model checking. \nIn D. Dill, editor, CAV 94: Computer Aided Veri.cation, Lecture Notes in Computer Science 818, pages \n377 390. Springer-Verlag, 1994. [32] D. Perkovic and P. Keleher. Online data-race detection via coherency \nguarantees. In Proceedings of the 2nd Symposium on Operating Systems Design and Implementation (OSDI \n96), pages 47 57, 1996. [33] G. Ramalingam. Context-sensitive synchronization-sensitive analysis is undecidable. \nACM Transactions on Programming Languages and Systems, 22(2):416 430, 2000. [34] T. Reps, S. Horwitz, \nand M. Sagiv. Precise interprocedural data.ow analysis via graph reachability. In Proceedings of the \n22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 49 61. ACM, 1995. [35] \nRobby, M. B. Dwyer, and J. Hatcli.. Bogor: an extensible and highly-modular software model checking framework. \nIn FSE 2003: Foundations of Software Engineering, pages 267 276, 2003. [36] S. Savage, M. Burrows, G. \nNelson, P. Sobalvarro, and T. E. Anderson. Eraser: A dynamic data race detector for multithreaded programs. \nACM Transactions on Computer Systems, 15(4):391 411, 1997. [37] M. Sharir and A. Pnueli. Two approaches \nto interprocedural data .ow analysis. In Program Flow Analysis: Theory and Applications, pages 189 233. \nPrentice-Hall, 1981. [38] N. Sterling. WARLOCK a static data race analysis tool. In USENIX Technical \nConference Proceedings, pages 97 106, Winter 1993. [39] S. Stoller. Model-checking multi-threaded distributed \nJava programs. In Proceedings of the 7th International SPIN Workshop on Model Checking and Software Veri.cation, \nLecture Notes in Computer Science 1885, pages 224 244. Springer-Verlag, 2000. [40] C. von Praun and T. \nGross. Object-race detection. In Proceedings of the 16th Annual Conference on Object-Oriented Programming \nSystems, Languages, and Applications (OOPSLA 01), pages 78 82, Tampa Bay, FL, October 2001.  \n\t\t\t", "proc_id": "996841", "abstract": "The design of concurrent programs is error-prone due to the interaction between concurrently executing threads. Traditional automated techniques for finding errors in concurrent programs, such as model checking, explore all possible thread interleavings. Since the number of thread interleavings increases exponentially with the number of threads, such analyses have high computational complexity. In this paper, we present a novel analysis technique for concurrent programs that avoids this exponential complexity. Our analysis transforms a concurrent program into a sequential program that simulates the execution of a large subset of the behaviors of the concurrent program. The sequential program is then analyzed by a tool that only needs to understand the semantics of sequential execution. Our technique <i>never</i> reports false errors but may miss errors. We have implemented the technique in KISS, an automated checker for multithreaded C programs, and obtained promising initial results by using KISS to detect race conditions in Windows device drivers.", "authors": [{"name": "Shaz Qadeer", "author_profile_id": "81100286660", "affiliation": "Microsoft, Redmond, WA", "person_id": "PP14106781", "email_address": "", "orcid_id": ""}, {"name": "Dinghao Wu", "author_profile_id": "81100657993", "affiliation": "Princeton University, Princeton, NJ", "person_id": "P517405", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996845", "year": "2004", "article_id": "996845", "conference": "PLDI", "title": "KISS: keep it simple and sequential", "url": "http://dl.acm.org/citation.cfm?id=996845"}