{"article_publication_date": "06-09-2004", "fulltext": "\n The Liberty Structural Speci.cation Language: A High-Level Modeling Language for Component Reuse Manish \nVachharajani Neil Vachharajani David I. August Departments of Computer Science and Electrical Engineering \nPrinceton University Princeton, NJ 08544 {manishv, nvachhar, august}@princeton.edu ABSTRACT Rapid exploration \nof the design space with simulation models is essential for quality hardware systems research and development. \nDespite striking commonalities across hardware systems, design\u00aders routinely fail to achieve high levels \nof reuse across models constructed in existing general-purpose and domain-speci.c lan\u00adguages. This lack \nof reuse adversely impacts hardware system de\u00adsign by slowing the rate at which ideas are evaluated. \nThis paper presents an examination of existing languages to reveal their funda\u00admental limitations regarding \nreuse in hardware modeling. With this understanding, a solution is described in the context of the design \nand implementation of the Liberty Structural Speci.cation Lan\u00adguage (LSS), the input language for a publicly \navailable high-level digital-hardware modeling tool called the Liberty Simulation En\u00advironment. LSS is \nthe .rst language to enable low-overhead reuse by simultaneously supporting static inference based on \nhardware structure and .exibility via parameterizable structure. Through LSS, this paper also introduces \na new type inference algorithm and a new programming language technique, called use-based special\u00adization, \nwhich, in a manner analogous to type inference, customizes reusable components by statically inferring \nstructural properties that otherwise would have had to have been speci.ed manually. Categories and Subject \nDescriptors I.6.2 [Simulation and Modeling]: Simulation Languages; I.6.5 [Simulation and Modeling]: Model \nDevelopment Model\u00ading methodologies  General Terms Design, Languages  Keywords Liberty Simulation Environment \n(LSE), Liberty Structural Speci.\u00adcation (LSS), component reuse, simulator construction, structural modeling, \ntype inference, use-based specialization Permission to make digital or hard copies of all or part of \nthis work for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 04, June 9 11, 2004, Washington, DC, USA. Copyright 2004 ACM 1-58113-807-5/04/0006 \n...$5.00. 1. INTRODUCTION AND MOTIVATION In digital hardware design, early design decisions signi.cantly \nimpact the overall quality of the system produced. Current ana\u00adlytical models fail to provide guidance \ndue to the complexity of these systems. Producing and measuring candidate hardware pro\u00adtotypes to test \nthese early design decisions is prohibitively expen\u00adsive. As a result, designers turn to high-level (e.g. \nmicroarchitec\u00adtural level) software simulation models for feedback in iteratively re.ning these critical \nearly design decisions. The quality of the resulting high-level design is directly related to the rate \nat which high-level design candidates can be explored. Just as reuse in software development signi.cantly \nimproves program\u00admer ef.ciency, reuse in high-level design modeling reduces model speci.cation time, \ndramatically increasing the exploration rate of design candidates. Reuse here is particularly attractive \nbecause high-level hardware design exploration is replete with opportunities to employ it; many behaviors \nsuch as arbitration and queuing, are extremely common in a wide range of hardware systems, and other \ncommon structures exist among designs within an exploration. Un\u00adfortunately, current modeling systems \neither do not support reuse or require signi.cant effort to achieve reuse, negating any poten\u00adtial bene.ts. \nConsequently, model construction and modi.cation times when using these systems is on the order of months \nto years, severely limiting the range of alternatives explored in the early de\u00adsign phases and negatively \nimpacting .nal design quality [4, 15]. In the general purpose microprocessor research and design com\u00admunity, \nmanually coding a simulator in a sequential programming language such as C or C++ is the most common \nmethod of high\u00adlevel modeling1. This method does not allow component-based reuse because the notion of \na hardware component does not map well to any type of modular block in C or C++ [17]. Concurrent-structural \nmodeling tools present an alternative by modeling hardware components with concurrently executing soft\u00adware \ncomponents that communicate through statically connected communication channels. Since this modeling \nparadigm matches the structural composition and concurrent processing of hardware components, component-based \nreuse becomes a possibility [17]. These systems fall into two categories, static concurrent-structural \nsystems and structural object oriented programming (OOP) sys\u00adtems. Unfortunately, as will be described \nin this paper, the spec\u00adi.cation style in each of these systems forces a trade-off between ease of building \nreusable components and ease of using reusable components. In both cases, the dif.culties in building \nand using reusable components discourage reuse in practice. 1In the 30th International Symposium on Computer \nArchitecture at FCRC, at least 23 of 37 papers used this simulation technique. component adder { ... \n ... /* Instantiate adder */ void compute() { instance addblock:adder; int x, y, z; x = receive(input1); \n/* Connect ports */ y = receive(input2); block1.x -> addblock.input1; z = add(x,y); block2.y -> addblock.input2; \n send(output, z); addblock.output -> block3.z; } } (b) Structural Code (c) Behavioral Code Figure 1: \nStructural speci.cations. In this paper, we present a hybrid model speci.cation style that allows easy \nconstruction and easy use of .exible, reusable com\u00adponents. This paper also presents the design and implementation \nof the Liberty Structural Speci.cation Language (LSS), a high\u00adlevel hardware modeling language that uses \nthis hybrid speci.ca\u00adtion style. This style opens the door to techniques that were pos\u00adsible, but of \nlimited utility, in static structural systems and use\u00adful, but unimplementable, in structural-OOP systems. \nThis paper presents the implementation of two such techniques used in LSS: structural type inference \nin the presence of both component over\u00adloading and parametric polymorphism and use-based specializa\u00adtion, \na new technique to further reduce the overhead in using .ex\u00adible components. These techniques required \nthe development of a novel algorithm for type inference and unique evaluation semantics for use-based \nspecialization. The remainder of the paper is organized as follows. Section 2 provides an overview of \nhigh-level concurrent structural modeling. Section 3 identi.es key attributes for fully supporting component\u00adbased \nreuse and surveys existing modeling systems to identify which attributes are missing. Sections 4, 5, \nand 6 describe the design of the LSS language, including implementation challenges and solu\u00adtions to \nthese challenges. Section 7 summarizes our experience with the LSS language, emphasizing the applicability \nof techniques described in this paper. Section 8 discusses related work, and Sec\u00adtion 9 concludes the \npaper. 2. CONCURRENT-STRUCTURAL MODELS Concurrent-structural systems, in general, are those systems \nin which computation is encapsulated in concurrently executing sys\u00adtem components that communicate values \nto one another by send\u00ading and receiving data on a prede.ned communication network. Typically, each component \nde.nes a set of input and output ports and continuously computes its outputs given the current values \nof its inputs and internal state. Components whose input ports are con\u00adnected to a particular output \nport receive the value sent on it and accordingly update their internal state and outputs. Synchronous \ndigital hardware, where state update is synchronized to a global clock, is an example of a concurrent-structural \nsystem. Concurrent- Static Structural Object Oriented Capability Theory Practice Theory Practice Parameters \nyes yes yes yes Structural yes yes Algorithmic yes yes yes yes Polymorphism yes yes yes yes Parametric \nyes yes yes Overloading yes yes Static Analysis yes yes Instrumentation yes yes Table 1: Capabilities \nof existing methods and systems. structural modeling systems are the most natural way to model such hardware \nand are often used for this purpose. Figure 1a shows a structural model that adds two numbers together. \nFigure 1b shows a possible textual description of the structural model. In high-level concurrent-structural \nmodels, the focus of this work, the primitive components port I/O relation (e.g. the function that the \nadder component will compute) is speci.ed using conven\u00adtional function-invocation based code. Despite \nthe use of function\u00adinvocation code within a particular component, communication be\u00adtween components \noccurs structurally. This distinction clearly sep\u00adarates functionality and communication, a hallmark \nof concurrent\u00adstructural systems. Continuing the earlier example, Figure 1c shows a possible description \nof the addercomponent s behavior.  3. REUSE IN EXISTING METHODS High-level concurrent-structural modeling \nlanguages should have certain capabilities to fully support component-based reuse. These languages should \nsupport: Parameterizable Components -the ability to customize compo\u00adnent properties with parameters. \nExample: a cache component whose replacement policy can be selected from an enumerated set of prede.ned \npolicies. Structural Customization -the ability to customize hierarchi\u00ad cal structure with parameters. \nThis allows existing compo\u00adnents to be reused hierarchically to create a .exible com\u00adponent. Example: \ncustomizing the mix of functional units and bypass connection speci.cation in a structurally speci\u00ad.ed \nreusable CPU core. Algorithmic Customization -the ability to inherit and augment the behavior of an existing \ncomponent with an algorithm. Example: customizing arbitration logic inside a bus arbiter component. Polymorphism \n-the ability to support reuse across types. Parametric Polymorphism -the ability to create and use com\u00adponent \nmodels in a datatype independent fashion. Exam\u00adples: queues, memories, and crossbar switches that support \nall types. Component Overloading -the ability for a component s im\u00adplementation to be automatically selected \nfrom a family of implementations that support different datatypes. Note that function overloading, in \nwhich argument types select a func\u00adtion s implementation, differs from component overloading, where port \nand connection types select a component s im\u00adplementation. Example: An ALU with an implementation family \nthat operates on integer and .oating point numbers. Static Model Analysis -the ability to analyze the \nmodel for op\u00adtimization and user convenience. Example: type inference to resolve polymorphic port types. \nInstrumentation -the ability to insert probes into a model without Figure 2: Block diagram of a 3-stage \ndelay chain speci.cation. modifying the internals of any component. This allows models to be reused to \nsatisfy different data collection needs. Examples: instrumentation for performance measurement, debugging, \nor visualization. The following two subsections relate the above abilities to two existing modeling methodologies: \nstatic structural modeling and structural modeling in OOP. This analysis will identify desirable features \nand highlight potential pitfalls present in these methods. The insight gained will guide the design of \nthe LSS language pre\u00adsented in the remainder of this paper. Table 1 can be used as a reference during \nthe discussion. 3.1 Static Structural Modeling Static structural modeling systems are concurrent-structural \nmod\u00adeling systems which statically describe a model s overall structure. Models in these systems are \noften netlists of interconnected com\u00adponents augmented with component parameterizations, and typi\u00adcally \nthese tools have drag-and-drop graphical user interfaces to construct models. An example of such a tool \nis Ptolemy II with the Vergil interface [7]. These systems support many of the features described above. \nComponents typically export parameters so that they can be cus\u00adtomized. Depending on the underlying language \nused to implement the components, inheritance may allow algorithmic customization. Some systems support \npolymorphism [7] and type inference to re\u00adsolve the polymorphism [20]. Models could even be instrumented \nusing aspect-oriented programming (AOP) [8] to weave instrumen\u00adtation code into the structure of the \ndescribed model. Unfortunately, the fact that these speci.cations are static im\u00adplies a fundamental limitation \nof static structural modeling systems. Consider the structure shown in Figure 2. In static structural \nsys\u00adtems, one would explicitly instantiate the three blocks within the dotted box in the .gure. However, \nthis chain of blocks could not be wrapped into a .exible hierarchical component where the length of the \nchain is a parameter since static structural systems provide no mechanism to iteratively connect the \noutput of one block to the input of the next a parametric number of times. As a result, to permit .exibility, \nthis simple hierarchical design would have to be discarded in favor of a more complex implementation \nof a primitive component. Implementing the primitive component for this simple example may not be dif.cult, \nbut in more complex examples, such as controlling the mix of functional units in a processor model, im\u00adplementation \nof a monolithic primitive component would be over\u00adwhelming. Note that some static structural modeling \nsystems may provide idioms for common patterns, such as chained connections. However, the fundamental \nlack of general mechanisms to paramet\u00adrically and programmatically control model structure still remains. \n 3.2 Structural Modeling in OOP A promising concurrent-structural modeling approach, such as the one \ntaken by SystemC [11], which allows .exible primitive and hierarchical components is to augment an existing \nOOP language with concurrency and a class library to support structural entities such as ports and connections. \nObjects take the place of compo\u00ad 1 class delayn { 2 public InPort in; 3 public OutPort out; 4 5 Delay[] \ndelays; 6 delayn(int n) { 7 int i; 8 9 in=new InPort(); 10 out=new OutPort(); 11 12 delays=new Delay[](); \n13 in.connect(delays[0].in); 14 for(i=0;i<n-1;i++) { 15 delays[i].out.connect(delays[i+1].in); 16 } 17 \ndelays[n-1].out.connect(out); 18 } 19 }; Figure 3: Structural OOP pseudo-code for an n-stage delay chain. \nnents, and simulator structure is created at run-time by code that instantiates and connects these objects. \nThe basic features of object-oriented languages provide many of the capabilities described at the beginning \nof Section 3. Ob\u00adject behavior can be customized via instantiation parameters passed to class constructors. \nAlgorithmic customization is supported via class inheritance. If the OOP language and the added structural \nentities support parametric polymorphism then type-neutral com\u00adponents can be modeled as well. Since \ncomponent instantiation and connection occur at run time, the OOP language s basic control .ow primitives \n(i.e. loops, if statements, etc.) can be used to algorithmically build the structure of the system. This \ncode can be encapsulated into an object and the internal structure can easily be customized by structural \nparameters thus producing .exible hierarchical components. For example, the n-cycle delay component (Figure \n2) seen in the last section could be built by composing n single-cycle delay components as shown in the \npseudo-code in Figure 3. Unfortunately, run-time composition of structure provides com\u00adponent .exibility \nby precluding static analysis of model structure. This makes using these .exible components cumbersome. \nFor ex\u00adample, any parametric polymorphism must be resolved via explicit type instantiation by the user \nsince the constraints used in type in\u00adference are obtained from the model s structure which is unavail\u00adable \nat compile time. Ideally, connecting the output of a .oating point register .le to an overloaded ALU \nwould automatically se\u00adlect the ALU implementation which handles .oating point data. However, this component \noverloading is not possible since the user must codify the particular ALU implementation in the instantia\u00adtion \nstatement rather than the compiler automatically determining this based on connectivity. Additionally, \nparameters controlling the extent of all port arrays must be speci.ed explicitly by the user rather than \nthe compiler automatically inferring these extents from their connectivity. Finally, implementing instrumentation \nthat is or\u00adthogonal to machine speci.cation is at best cumbersome. Powerful techniques, such as aspect-oriented \nprogramming cannot be used since the desired join points (locations where instrumentation code should \nbe inserted) are often parts of the model structure which is not known until run time.  4. THE LSS \nLANGUAGE The modeling methodologies discussed in Section 3.1 and Sec\u00adtion 3.2 possessed many of the capabilities \nnecessary for reuse in Figure 4: Overview of LSS based compilation. a concurrent-structural modeling \ntool. Unfortunately, those sys\u00adtems forced a trade-off between the ability to algorithmically con\u00adtrol \nstructure and the ability to statically analyze it. The Liberty Structural Speci.cation Language (LSS) \nis a language designed to specify structure of concurrent-structural systems that obviates this trade-off \nby combining the desirable attributes of both existing methodologies. To allow algorithmic speci.cation \nof structure, LSS possesses common imperative control .ow constructs in addition to its struc\u00adtural modeling \nconstructs. Using these constructs, a model s struc\u00adture can be built using code similar to that in Figure \n3. However, unlike modeling in OOP, the LSS code can be executed at com\u00adpile time since the LSS code \nonly describes the model s structure and not its run-time behavior. Since the LSS code is executed at \ncompile time, the model s structure is still known statically and therefore can be used for analysis. \nFigure 4 shows this LSS compilation process. In the .rst phase of compilation, the LSS speci.cation undergoes \ninterpreted exe\u00adcution to build a netlist that represents the static structure of the model. Once the \nnetlist is generated, various static analyses are performed on the netlist. In the current implementation \nof the LSS compiler, these analyses include structure-based type inference, de\u00adscribed in Section 5, \nand static concurrency scheduling [12]. Fi\u00adnally, after static analysis, the code generator combines \nthe netlist with the leaf (i.e. not hierarchical) component behavior speci.ca\u00adtions, applies non-structural \ncustomizations to these behaviors, and emits an executable simulator binary. We refer to the language \nin which the leaf module behaviors are speci.ed as the behavior spec\u00adi.cation language (BSL)2. This section \ndescribes the LSS language and its features that support all the desired capabilities listed in Section \n3. Addition\u00adally, this section will describe enough about the language so that later sections can discuss \nthe LSS type inference problem and the implementation of a novel technique, called use-based specializa\u00adtion, \nfor parameter value inference. Note, since LSS was designed for algorithmic speci.cation of structure, \nthe design decisions for some features differ from those made in traditional programming languages. These \ndesign decisions and their implications will be discussed throughout this section. 4.1 LSS Modules In \nLSS, components are created from component templates, anal\u00adogous to classes in structural OOP modeling, \ncalled modules. The 2LSS is independent of the BSL, but a component written in LSS for a particular BSL \nis not necessarily compatible with another component written in LSS for another BSL. As a consequence \nof this independence, discussion of BSL details is beyond the scope of this paper. 1 module delay { \n2 parameter initial_state = 0:int; 3 inport in:int; 4 outport out:int; 5 6 tar_file=\"corelib/delay.tar\"; \n7 8 // BSL specific parameters here 9 }; Figure 5: An LSS module declaration for a leaf delay element. \n 1 instance d1:delay; 2 instance d2:delay; 3 ... 4 d1.initial_state = 1; 5 d1.out -> d2.in; 6 ... Figure \n6: A sample use of the delaymodule. body of an LSS module speci.es the component s parameteriza\u00adtion \ninterface, communication interface, and constructor. There are two types of modules in LSS. The .rst, \nleaf modules, are simple modules de.ned without composing behavior from other modules. The second, hierarchical \nmodules, are more complex modules ob\u00adtaining their behavior through the composition and customization \nof existing components. The next few sections will describe leaf and hierarchical modules and their parameterization. \n 4.1.1 Leaf Modules Figure 5 shows the declaration of a leaf module named delay. Line 2 in the .gure \ndeclares a parameter named initial state with type intand assigns the parameter a default value of 0. \nMod\u00ad ule parameters can be set by the user when instantiating a module to customize its behavior. These \nparameter values are forwarded to the BSL code so they can be used to customize module behavior. Lines \n3 and 4 de.ne the communication interface of the module. These two lines de.ne an input port named in \nand an output port named out. The computation which links the data received on port into the data produced \non port outis speci.ed externally in leaf modules. The value in the internal parameter tar file (shown \non Line 6 of the .gure) tells the code generator where to .nd the run-time behavior for instances of \nthis module. Note that internal parameters, unlike module parameters, cannot be overridden by a user \nof the module. Figure 6 shows an example of instantiating and parameterizing the delay module. Lines \n1 and 2 each instantiate the delay module to create module instances named d1and d2respectively. Line \n4 gives the initial state parameter on instance d1 the value 1. Line 5 of Figure 6 connects the output \nof d1 to the input of d2. Notice that the initial state parameter on instance d2 is not set. When such \nassignments are omitted, the parameter takes on its default value as de.ned in the module body (Line \n2 of Figure 5). Notice from the .gures that parameters in LSS are referenced nominally and can be speci.ed \nafter the instantiation statement (e.g. initial stateis referenced on Line 4 of the .gure) rather than \nin a positional argument list as part of the instantiation statement. These choices were made because \n.exible modules typically have many parameters. Nominal parameter references clarify models since parameter \nnames describe the parameter s purpose better than position in an argument list. Similarly, .exible placement \nof pa\u00ad rameter assignment allows groups of related parameter assignments  Figure 7: Hierarchical component \ncomposition. 1 module delayn { 2 parameter n:int; 3 4 inport in: a; 5 outport out: a; 6 7 var delays:instance \nref[]; 8 delays=new instance[n](delay,\"delays\"); 9 10 var i:int; 11 12 in -> delays[0].in; 13 for(i=1;i<n;i++) \n{ 14 delays[i-1].out -> delays[i].in; 15 } 16 delays[n-1].out -> out; 17 }; Figure 8: A LSS module declaration \nfor an n-stage delay chain. for different module instances to be co-located rather than scattered based \non module instantiation location. Both features make using .exible components (i.e. those with many parameters) \neasier, en\u00adcouraging their construction and use.  4.1.2 Hierarchical Modules In addition to leaf modules, \nLSS supports the creation of com\u00adplex modules by composing the behavior of existing modules into new \nhierarchical modules. Hierarchical modules, just like leaf modules, de.ne a parameterization and communication \ninterface by de.ning ports and parameters. However, unlike leaf modules, the behavior of the module is \nspeci.ed by instantiating modules and connecting these instances to the module s input and output ports \n(see Figure 7). Recall that allowing parameters to control the structure of these modules was a requirement \noutlined in Section 3. To allow this, LSS uses imperative control .ow constructs to guide the sub-component \ninstantiation, parameterization, and connection. To understand how these features work together, consider \nthe LSS code shown in Figure 8. (Note that this is the LSS version of the pseudo-code shown in Figure \n3.) This code de.nes a module that models an arbitrary depth delay pipeline built using single\u00adcycle \ndelay modules. The module delayn declares a single pa\u00adrameter n(Line 2) that controls the number of stages \nin the pipeline. The parameter nis a structural parameter; anywhere after this dec\u00adlaration, the body \nof the module can read this parameter to guide how subinstances will be created, connected, or parameterized. \nLine 7 and 8 create an array of instances of the delay module that will be named delays in the BSL. Notice \nthat the length of the array (the value enclosed in brackets on Line 8 of the .gure) is controlled by \nthe parameter n. Lines 12 through 16 connect the delay instances in a chain as shown for n=3 in Figure \n2. Notice how the general purpose C-like for-loop causes the length of the connection chain to vary with \nthe parameter n. Also, notice that while the C-like for-loop was able to 1 instance gen:source; 2 instance \nhole:sink; 3 instance delay3:delayn; 4 5 delay3.n=3; 6 7 gen.out -> delay3.in; 8 delay3.out -> hole.in; \n Figure 9: LSS speci.cation of a 3-stage delay pipeline. capture a parameterized idiomatic connection \npattern in this exam\u00ad ple, LSS supports constructs (including loops, conditionals, etc.) that permit \ngeneral algorithmic speci.cation of structure. This al\u00ad lows any non-idiomatic connection pattern to \nbe created and pa\u00ad rameterized. Figure 9 shows how the delaynmodule can be used to create a 3-stage delay \npipeline. The module is instantiated on Line 3, its n parameter is set on Line 5, and .nally the instance \nis connected on Lines 7 and 8. A block diagram of this system is shown in Figure 2. The genand holeinstances \njust provide data to and consume data from the pipeline respectively.  4.2 Flexible Communication Interfaces \nModule instances communicate via input and output ports de\u00ad .ned by the modules from which they were \ninstantiated. To fa\u00ad cilitate scalable interfaces such as a register .le with a customiz\u00ad able number \nof read ports, each port in LSS is actually a variable length array of port instances. Rather than connecting \ntwo ports to\u00ad gether to have two instances communicate, one connects two port instances together. If \nno port instance number is speci.ed, one is inferred by the interpreter. For each port in a module, the \nport s width (the number of connections made to the port) is available in the module body as a parameter. \nThis parameter is automatically set by counting the number of connections actually made to the port. \nModules can use the width parameter, like any other param\u00ad eter, to customize the components created \nfrom it. This automatic customization is an instance of use-based specialization and will be discussed \nin more detail in Section 6. LSS also supports leaving ports unconnected (ports with zero width). Using \nthe width parameter, a module can detect whether or not a port is connected and customize its behavior \naccordingly. These unconnected port semantics allow modules to have rich com\u00ad munication interfaces without \nburdening a user with the responsi\u00ad bility of connecting all the ports. Without such a feature, it may \nbe tempting to replicate simple functionality rather than reuse a com\u00ad plex module with many ports that \nare unnecessary for a given situa\u00ad tion. These unconnected port semantics are especially useful when \nre.ning a model to a more precise model since the initial and re\u00ad .ned model can reuse the same components; \nthe initial model relies on unconnected port semantics, while the re.ned model connects the ports to \nachieve a speci.c desired behavior. 4.3 Customizing Component Computation LSS provides two mechanisms \nto customize the computation of existing modules (algorithmic customization), increasing their reusability. \nThe .rst mechanism is simply wrapping an existing module within another module and adding modules along \ncompu\u00adtation paths to customize behavior. Figure 7 demonstrates how this can be done. Those computation \npaths which should be identical to the base component are connected directly to the wrapping compo\u00adnent \ns input and output ports. In the .gure, component C inherits the behavior of ports 1, 2, and 3 from component \nA. Component C overrides the behavior of component A s output port 4 since com\u00adponent B has been placed \nbetween component A s output and com\u00adponent C s corresponding output. In this way, component C has extended \ncomponent A. The second way to customize computation is via userpoint pa\u00adrameters. These algorithmic \nparameters accept string values whose content is BSL code. This BSL code forms the body of a function \non a module instance where the function signature is de.ned by the userpoint declaration in the declaring \nmodule s body. The declara\u00adtion identi.es a set of arguments whose values may be used in the userpoint \nBSL code and a return type for a return value that must be produced by the BSL code. The code in the \nuserpoint is invoked by the module s behavioral speci.cation to accomplish some com\u00adputation or state-update \ntask. Just like other parameters, userpoint parameters can have default values, thus allowing the module \nto de.ne default behavior which can be overridden by the user. A single userpoint parameter assignment \non a module instance is the OOP equivalent of inheriting a class, overriding a virtual mem\u00adber function, \nand then instantiating the inherited class. This allows userpoints to dramatically reduce the overhead \nof one-off inher\u00aditance (i.e. inheriting a module and instantiating it once). Since one-off inheritance \nis common in structural modeling, this reduces speci.cation overhead in LSS. More formal styles of inheritance \ncan be achieved via userpoint assignment and module wrapping. To allow userpoints to maintain state across \ninvocations, LSS also supports the ability to add state by declaring runtime vari\u00adables. Runtime variables \nare variables available during simulation rather than during model compilation. To allow initialization \nand synchronous update of this added state, all modules possess two system-de.ned userpoints, init and \nend of timestep, that are invoked at the beginning of simulation and the end of each clock cycle respectively. \nOnce created, users can reference runtime vari\u00adables in other userpoints to help customize computation. \n 4.4 Polymorphism To support reuse across datatypes, LSS supports two types of polymorphism: parametric \npolymorphism and component overload\u00ading. Parametric polymorphism is supported through use of type variables. \nFor example, any port in LSS, instead of having a basic type, such as int, may have a polymorphic type \nthat contains type variables. Line 4 and 5 in Figure 8 state that the in and out port will have the type \nspeci.ed by the type variable a (all type vari\u00adables in LSS begin with a ). The type variable can be \ninstantiated with any LSS type. The fact that both the inand outports use the same type variable means \nthat both ports must have the same basic type. While this example demonstrates parametric polymorphism \nmorphism can be very tedious. In practice, hundreds of explicit type instantiations are necessary to \nresolve the polymorphism [18]. To avoid this overhead, LSS automatically resolves polymorphism via type \ninference based on the structure of the model. For ex\u00adample, in the code shown in Figure 8, since the \ndelay module requires type int on its ports and both the in and out ports of the delaynmodule are connected \nto instances of this module, the type variable awill be resolved to have type int. Since ports can have \ndisjunctive types, the LSS type inference problem is non-trivial. Details regarding the LSS type inference \n problemcanbefoundinSection5. , 4.5 Instrumentation To allow a model to be reused for different data \ncollection needs, LSS supports a mechanism to separate model speci.cation from model instrumentation. \nAs was possible in static structural mod\u00adeling, LSS uses an aspect-oriented data collection scheme. Each \nmodule can declare that its instances emit certain events at run\u00adtime. These events behave like join \npoints in aspect-oriented pro\u00adgramming (AOP). Each time a certain state is reached or value computed, \nthe instance will emit the corresponding event and user\u00adde.ned collectors will .ll these join points \nand collect information for statistics calculation and reporting. BSL code may be speci\u00ad.ed for the collector \nthat processes the data sent with the event to accumulate statistics that can be reported during or at \nthe end of simulation and used for visualization or model debugging. In addition to declared events, \nLSS automatically adds code to emit an event whenever a value is sent on a port. Since many impor\u00adtant \nhardware events are synchronized with communication, many useful statistics can be gathered using just \nthese port .ring events.  5. TYPE INFERENCE As described earlier, LSS will attempt to assign basic types \nto all ports via type inference. This type inference greatly reduces the tedium in using polymorphic \ncomponents since it frees the user from explicitly specifying each type. The type inference problem for \nLSS can be formulated as try\u00ading to assign values to a set of type variables under a set of con\u00adstraints. \nWhen de.ning a system s ports and connections, the user annotates each port and optionally annotates \neach connection with a type scheme. The legal types and type schemes in the system are speci.ed by the \nfollowing grammar: Basic Types t ::= int | ... | t [n] |struct{i1 : t1; ...in : tn; } on a hierarchical \ncomponent, it can also be used on leaf compo-Type Variables a, \u00df, . ::= i nents. In such cases, the \nBSL code for the leaf component is spe-Type Schemes t * ::= a | (t int * * 1 cialized based on the basic \ntype given to all type variables. * | ... | tn) |... | t * [n] | 1 ; ...in : t * | Component overloading \nin LSS is achieved through the use of struct{i1 : t any identi.er disjunctive-types. A disjunctive-type, \ndenoted as type1|type2 Identi.ers ; } n i ::= in LSS, speci.es that the entity with this type may statically \nhave type type1 or type2, but not both simultaneously. Notice that this is different from union types \nwhich may store either type de\u00adpending on the value assigned at runtime. Since modules may de\u00ad.ne many \nports, implementing the full cross-product of allowable overloaded con.gurations may be extremely cumbersome. \nHow\u00adever, since the types are resolved statically, rather than implement\u00ading multiple entire behaviors \nfor a given component, the BSL can If two ports in the system are connected, a constraint term that equates \nthe corresponding type variables is added to the overall constraint. For each connection annotated with \na type scheme, a pair of constraint terms that equate the connected ports type vari\u00adables to the annotated \ntype scheme is added to the constraint. The form of a legal constraint in the type inference problem \nis given by the following grammar: specify type dependent code fragments and the code generator can \nConstraints f ::= T| t customize this code using the statically resolved type information. ** 1 = t 2 \n| f1 . f2 Since it is common to have many polymorphic components in a The constraint T represents the \ntrivially true constraint, the con\u00ad model (e.g. long chains of polymorphic data routing components straint \nt * * = t 12 asserts the equality of two type schemes, and the and polymorphic state elements), manually \nresolving all the poly-constraint f1 . f2 represents the conjunction of the constraints f1 and f2. The \ntype inference engine must assign a basic type to all the type variables while satisfying the constraint. \nThe type system and constraints are very similar to those found in languages such as ML [9]. However, \nnotice the (t1 * | ... | tn* ) type scheme. Any entity annotated with this type scheme must statically \nhave a single basic type which is accepted by one of the type schemes t1 * , t2 * , ..., or tn*. This \nis different than a union type in which values that match any of the type schemes can be passed at run-time. \nThis disjunctive type scheme comes from the need to allow overloading of port types as discussed in Section \n4.4. The presence of this disjunctive type prevents the typical uni.\u00adcation algorithm from working for \nthe LSS type system. The prob\u00adlem arises because it is not possible to assign a basic type to a type \nvariable based solely on the disjunctive type constraint, even if the disjunctive type scheme has no \nunbound type variables. In fact, the LSS type inference problem is NP-complete [18]. The type system \nand inference problem presented here is very similar to the type system and inference problems in languages \nsuch as Haskell. However, the Haskell problem is undecidable in general [16]. There exist restricted \nversions of the type system that are decidable [10, 14]. Unfortunately, of these, the restrictions that \nyield acceptable computational complexity [10] are not desirable in a structural modeling environment \nsince they forbid common port interface typings. For other restricted versions of the type sys\u00adtem, we \nknow of no heuristic algorithms that are appropriate for instances of the problem that arise when using \nLSS. Thus, to perform type inference, LSS uses a modi.ed version of the typical uni.cation algorithm. \nThis algorithm, upon encounter\u00ading a constraint of the form (t * = t1 * | ... | tn* ) .f, recursively \napplies itself to all constraint systems of the form t * = ti * . f. If at least one of those constraints \nhas a solution, then that is also a solution to the original constraint. Since this straight-forward \nextension of the uni.cation algorithm is too slow in practice, a few heuristics are used make the algo\u00adrithm \npractical. First, constraint terms are reordered so that non\u00addisjunctive constraint terms are simpli.ed \n.rst. This eliminates the need to re-solve them during the recursion used to handle disjunc\u00adtive terms. \nSecond, a heuristic is employed that intelligently solves certain disjunctive terms without recursion. \nThird, a divide-and\u00adconquer heuristic that partitions disjoint constraint terms into sepa\u00adrate simpler \nconstraints is applied and these constraints are solved separately. Factoring the constraint in this \nway exponentially re\u00adduces the number of recursive calls. With these heuristics, type inference completes \nin several seconds for all cases we have ob\u00adserved, and we expect comparable times for all practical \nmodels. Without these heuristics, type inference times exceeded 12 hours for most models. A detailed \ndescription and analysis of the algo\u00adrithm and heuristics is beyond the scope of this paper but can be \nfound in the references [18].  6. USE-BASED SPECIALIZATION Just as explicitly specifying types is tedious \nand often unnec\u00adessary, explicit parameter value speci.cation is often tedious and redundant. In a manner \nanalogous to type inference, the LSS com\u00adpiler infers certain parameter values from the way in which \na com\u00adponent is used. We refer to the process of components customiz\u00ading themselves according to these \ninferred parameter values as use\u00adbased specialization. 6.1 Use-Based Specialization Design The simplest \nexample of use-based specialization involves port widths. Consider the delayn module presented in Figure \n8. The delay module used as the building block of the delayn mod\u00ad 1 module delayn { 2 parameter n:int; \n3 parameter width = 1:int; 4 5 inport in: a; 6 outport out: a; 7 8 var delays:instance ref[]; 9 delays=new \ninstance[n](delay,\"delays\"); 10 var i:int; 11 12 /* The LSS_connect_bus(x,y,z) built-in does: 13 * 14 \n* for(i=0; i<z; i++) { x[i]->y[i]; } 15 */ 16 LSS_connect_bus(in,delays[0].in,width); 17 in -> delays[0].in; \n18 for(i=1;i<n;i++) { 19 LSS_connect_bus(delays[i-1],delays[i].in,width); 20 } 21 LSS_connect_bus(delays[n-1],out,width); \n22 }; Figure 10: Modi.ed delayn module that supports multiple port connections. 1 instance gen:source; \n2 instance hole:sink; 3 instance delay3:delayn; 4 5 delay3.n=3; 6 delay3.width=5; 7 8 LSS_connect_bus(gen.out, \ndelay3.in, 5); 9 LSS_connect_bus(delay3.out, hole.in, 5); Figure 11: Use of the modi.ed delaynmodule. \nule supports multiple connections to its in and out ports. How\u00adever, any such connections made to the \nin and out ports of the delayn module will do nothing since only the .rst port instance is connected \ninternally. To alter the behavior of delaynwe could change the code so that it de.nes a width parameter \nthat makes multiple connections between the chain of delay elements. Fig\u00adure 10 shows what the code would \nlook like. To use the module, one would instantiate the new delayn, set the width parameter, and then \nmake the corresponding number of connections to the instance. The instantiation code is shown in Fig\u00adure \n11. While setting this single width parameter does not seem overwhelming, with many ports this type of \nconstruct can quickly clutter code and easily lead to errors, especially if this parameter must be kept \nconsistent with the connectivity of each port. Use\u00adbased specialization can be used to avoid this scenario. \nIn LSS, an implicit parameter named width is de.ned on each port. Rather than the user explicitly setting \nthis parameter, its value is inferred by counting the number of connections made to the port. With use-based \nspecialization, the code in Figure 11 would be identical, except that Line 6 could be omitted. Figure \n10 would be modi.ed by omitting Line 3, replacing occurrences of widthwith in.width, and adding a check \nto ensure that in.width is the same as out.width. While the above example is extremely simple, use-based \nspecial\u00adization can be extremely powerful. Consider, for example, a branch prediction module which also \nsupports branch target buffer (BTB) functionality. Since it is clear that requesting branch target infor\u00admation \nrequires a BTB, using use-based specialization, the branch prediction module can infer whether BTB behavior \nis necessary by checking to see if a branch targetport is connected. 1 module ... { 2 inport in: a; \n3 outport out: a; 4 ... 5 if(out.width < in.width) { 6 parameter arbitration_policy: 7 userpoint( /* \nargs */ => 8 /* ret */); 9 instance arb:arbiter; 10 arb.policy = arbitration_policy; 11 ... 12 } else \n{ 13 ... 14 } 15 ... 16 }; Figure 12: Use-based specialization exporting additional pa\u00adrameters Figure \n12 is another example of use-based specialization. Here, the module infers whether an internal arbiter \nis necessary by com\u00adparing the width of input ports to those of output ports. If the ar\u00adbiter is necessary \n(i.e. the input port is wider than the output port), the module can export a userpoint parameter so that \nthe arbitra\u00adtion policy can be parametrically speci.ed (Lines 5-12). Without use-based specialization, \nthe parameter arbitration policy would have to exist and, since it has no default value, would also have \nto be set even when no arbitration is necessary. A default arbi\u00adtration policy can be added. However, \nin the case where arbitration is required, having the module quietly select a policy is undesirable since \nthere are many reasonable default policies. Use-based spe\u00adcialization eliminates this trade-off by providing \nthe best of both alternatives; the user is required to specify the policy when it is necessary and is \nnot required to specify the policy otherwise. It should be noted, as the last example demonstrates, that \nuse\u00adbased specialization allows a module s parameterization and com\u00admunication interface to be affected \nby the connectivity and parame\u00adterization of other ports and parameters on the module. This creates a \ndilemma for straight-forward evaluation of LSS. A module can\u00adnot be used until it is instantiated, but \nthe constructor cannot be called until code following the instantiation line has executed. To resolve \nthis dif.culty, LSS has novel evaluation semantics that are described in the next section.  6.2 Use-Based \nSpecialization Implementation Use-based specialization requires that the module body has ac\u00adcess to values \nthat are de.ned by the usage of the module instance (e.g. the number of connections to a port and values \nof all explic\u00aditly speci.ed parameters). However, use-based specialization also allows the module s interface \n(i.e. the module s ports and parame\u00adters) to depend on the same values. Thus, use-based specialization \nrequires deferring module body evaluation until after the module is instantiated and used, however, conventional \nevaluation requires that the module body be evaluated before it can be used so that its interface is \nknown. To remedy this circularity, LSS uses the novel evaluation semantics described in this section. \nClearly, evaluation of the module body cannot occur as soon as an instance is created since the module \nbody depends on the values of the module s parameters. Thus, rather than invoking the module body when \ncreating a new instance, the name of the newly created instance and the module from which it was instantiated \nare pushed onto an instantiation stack. Code continues to execute from the current module body, and whenever \nan assignment to a sub.eld of a sub-instance (e.g. Line 5 in Figure 9), is encountered, the assignment \nis recorded as a po\u00ad (a) Instantiation stack. (b) Context for delay3. Figure 13: LSS interpreter state. \ntential parameter assignment. Similarly, whenever any connection is made to a sub.eld of a sub-instance, \nthe connection is recorded as a potential port connection. When the current module body .nishes evaluation, \nthe instance at the top of the instantiation stack is popped off and its module body executed. Whenever \nthe module body declares a parameter, the previously recorded potential parameter assignments are con\u00adsulted \nto see if the parameter has a user speci.ed value. If so, the type of the value is checked against the \nparameter s type and if the types match, the parameter is assigned that value. If no assign\u00adments were \nrecorded, the parameter will get its value from default parameter assignments inside the module body, \nif they exist. Sim\u00adilarly, when a port is declared, the recorded list of connections is consulted to \nsee if any attempts to connect to this port have been made. If so, the port is connected, and its implicit \nwidth attribute is set. After evaluation of the module completes, the potential sub.eld assignment and \npotential connection records are checked to make sure no non-existent parameters or ports on this instance \nwere ref\u00aderenced. Additionally, all the parameters are checked to ensure that they have some value. The \nfollowing example will illustrate the execution of the code shown in Figure 11. 1. Line 1. The interpreter \nrecords that an instance of the source module named gen was created by pushing it onto the in\u00adstantiation \nstack. 2. Line 2-3. The same is done for the holeand delay3mod\u00adules. 3. Line 5-6. The interpreter records \nthe assignments to potential parameters nand width. 4. Line 8-9. The interpreter records the connections \nmade.  At this point, the top-level code has .nished and so the module at the top of the instantiation \nstack is popped and its constructor evaluated. Figure 13a shows the instantiation stack in the LSS in\u00adterpreter \nat this point in the execution. In this case, the next set of code to run is that for the delaynmodule \nshown in Figure 10. 5. Line 2. Check to see that nhas an integer value in the record. If so, add it to \nthe evaluation context based on the value in the record. The evaluation context is shown in Figure 13b. \n 6. Line 3. Do the same for the widthparameter. 7. Line 5-6. Record the fact that connections to the \nin and out port are valid, compute the port widths, and add the portname.width parameters to the context. \n 8. Line 12-21. Execute the code, recording the instantiations, assignments, and connections as before. \nOnce this code is .nished, the interpreter ensures that no connec\u00adtions were made to non-existent ports \nand no illegal parameter as\u00adsignments were made. In this example, the code is correct so eval\u00aduation \ncontinues. The next instance on the stack, in this case one of the delaymodules pushed onto the stack \nduring the evaluation of the instance delay3, is popped off the stack and evaluated. This behavior can \nbe speci.ed more formally by describing the execution semantics for the LSS language as an evolution \nof pro\u00adgram states. Execution semantics expressed in this way are typ\u00adically called small-step semantics \n[5]. The complete small-step semantics has numerous state transition rules that closely resem\u00adble the \nsemantics for common imperative programming languages. Therefore, in this section, only the state transitions \nthat relate to the implementation of use-based specialization will be described. This section uses the \nnotation and terminology that is used by Harper [5], unless de.ned differently below. The state of an \nLSS program during execution will be repre\u00adsented by a 7-tuple, (M, Is, L, A, B, e, S). M is the netlist \nof the design as it is known at the current point in program evaluation. Is is the stack of instances \nthat need to be processed. L is the eval\u00aduation context and maps symbols to values. A is the recorded \nlist of potential parameter assignments and port connections obtained from the parent instance (the instance \nin the hierarchy above the one currently being processed). B is a context that records poten\u00adtial parameter \nassignments and port connections for children of the current instance. e is the current expression being \nevaluated, and S is the current list of statements being evaluated. The program starts in the initial \nstate (\u00b7, \u00b7,L0, \u00b7, \u00b7, \u00b7,S0), where L0 de.nes built-in functions and S0 is the statement list at the top\u00adlevel \nof the LSS speci.cation. The state transition function for LSS program states are expressed using propositional \nlogic. In the transition rules below, items that appear above the horizontal bar represent the hypothesis \nof a logical statement. The items that appear below the bar represent the con\u00adclusions of the statement. \nThe notation q0 . q1 is used to denote that q0 can transition to state q1. The conclusions of all the \ntransi\u00adtion rules identify all the legal transitions. Since any given state of an LSS program satis.es \nthe hypothesis for at most one transition rule, the transition rules de.ne the state transition function. \nThe interesting rules for LSS evaluation are used when a new instance is created. The rule for this statement \nis shown below. Note that the portion of the rules related to actually augmenting M is not shown but \nthe extension is straightforward. c current instance name n/. dom(L) m . dom(L) S, = body(m) i =(c.n, \nS,) (M, Is, L, A, B, \u00b7, instance n : m;S) . (M,,i c Is, {n . (c.n, S,)}. L, A, B, \u00b7,S) This rule pushes \nthe constructor for instance i onto the stack of constructors Is that must be evaluated and continues \nevaluating the statements in the current statement list. (Note that i c Is denotes a stack with the element \ni at the top and the stack Is below it.) Notice that this differs from standard evaluation which would \nhave immediately begun processing S,. When the current instance is .nished (i.e. no statements are left \nin the current statement list), the following rule begins evaluating the next instance constructor. A \n= \u00d8 c current instance name i =(c.n, S,) A * = extract(c.n, B) A, = strip(A * ) (M, i c Is, L, A, B, \n\u00b7, \u00b7) . (M, Is,L0,A,,B \\ A * , \u00b7,S,) The function extract(c.n, B) extracts from B all parameter as\u00adsignments \nand connections for the instance named c.n. The func\u00adtion strip(A * ) strips the c. pre.x from all the \nsymbol names, c.n, in the context A *. The state for the next instance to be processed is established \nby extracting the recorded potential assignments for the about-to-be-processed instance and making this \nset of assignments the new A context. The A = \u00d8 hypothesis ensures that no assign\u00adments to unde.ned parameters \ncan occur. The mechanism for this is explained below. The remaining small-step inference rules are very \nsimilar to other imperative programming languages. The most complex rules not shown are the ones for \nparameter and port declarations. The param\u00adeter rule removes from A any assignments to the parameter \nbeing de.ned and updates L and M appropriately. The port declaration rule is similar. Since the records \nare removed from A, if A = \u00d8 af\u00adter a module .nishes evaluation, then an assignment or connection was \nmade to an undeclared parameter or port.  7. EXPERIENCE WITH LSS LSS is the front-end language to the \nLiberty Simulation Envi\u00adronment (LSE). This section gives some background that provides additional insight \ninto the design of LSS, describes experience with LSE, and discusses the reuse provided by LSS. LSE originally \nused a static structural speci.cation language in\u00adstead of LSS. Thus, the system resembled those described \nin Sec\u00adtion 3.1. In this system, a few models were created, the largest being a cycle-accurate clone \nof a popular simulator hand-coded in C, SimpleScalar [1]. Development of larger, more ambitious mod\u00adels \nwas hindered by the lack of .exible hierarchical components. In developing microarchitectural models, \ncommon instance and con\u00adnection patterns emerged, but in each case the structure or width necessary varied \nslightly. For the reasons described in Section 3.1, these patterns could not be encapsulated into reusable \nhierarchical components. This forced cut-and-paste reuse rather than the more formal reuse patterns described \nin this paper. As model complex\u00adity grew, managing code riddled with cut-and-pasted fragments be\u00adcame \noverwhelming. An alternate solution was clearly necessary. In response to this need, the LSS language \nwas designed and implemented. After a direct conversion of the non-LSS version of the SimpleScalar model \nto the LSS-based model, there was a 35% reduction in line count. Furthermore, since the creation of LSS, \nwe have been able to build larger more aggressive models for research and instruction. Table 3 lists \nseveral such models. LSS allows the creation of .exible models and components in practice. For example, \nthe IA-64-based chip multiprocessor (CMP) model (Model E), was constructed by instantiating two IA-64 \ncores (Model D) and connecting them to a shared cache hierarchy. Model E was suf.ciently .exible to allow \nexploration of a novel com\u00admunication structure between processor cores, to study the effect of the number \nof functional units and their mix, to evaluate the effect of static and dynamic instruction scheduling, \nand to mea\u00adsure the effect of various memory subsystems. To facilitate this study, each processor core \nin the model exported parameters rang\u00ading from simple parameters which controlled the number of in\u00adstructions \nthat should be fetched per cycle to complex parameters which controlled whether the processor can issue \ninstructions out\u00adof-order. Other researchers have also used LSS and LSE to create .exible models and \nlibraries of .exible components. For exam\u00adple, researchers at Rice University have used LSS to model \npro\u00adgrammable network interface architectures [19]. LSS s features greatly simpli.ed construction of \nthese models. Table 2 summarizes data that quanti.es these bene.ts. Overall, use-based specialization \nwas able to infer 3904 port widths across Instances Instances Modules Explicit Type Explicit Type Inferred \nModel Hierarchical Leaf per from from Instantiations Instantiations Port Name Instances Modules Modules \nModule Library Library w/o Type Infer. w/ Type Infer. Widths Connections A 277 46 (10) 18 4.33 (8.61) \n73% 13 115 8 816 919 B 281 46 (11) 18 4.39 (8.48) 73% 13 116 8 823 929 C 62 1 18 3.37 73% 10 38 30 147 \n304 D 192 4 25 6.62 86% 22 147 71 611 3975 E 329 4 26 10.97 89% 22 162 71 984 4528 F 183 18 (3) 19 4.95 \n(8.32) 82% 18 101 38 523 1395 Total 1324 69 (19) 39 12.26 (22.83) 80% 22 679 226 3904 12050 Model descriptions \nare in Table 3. Values in parenthesis discount trivial hierarchical modules used simply to wrap a collection \nof components. Table 2: Quantity of Component-based Reuse Model Name Model Description A A Tomasulo Style \nmachine for the DLX instruction set. B Same as A, but with a single issue window. C A model equivalent \nto the SimpleScalar simulator [1]. D An out-of-order processor core for IA-64. E Two of the cores from \nD sharing a cache hierarchy. F A validated Itanium 2 processor model. Table 3: Several models developed \nwith LSS. the models, obviating the need to keep these parameter values con\u00adsistent with the 12050 connections \nin the models. As is obvious from these numbers, manually specifying all the connections would be impractical; \nalgorithmic speci.cation of structure was vital in developing this model. Further, notice that type inference \nreduced the total number of required type instantiations from 679 to 226, a 66% reduction. The aspect-oriented \ninstrumentation features of LSS also proved invaluable allowing easy migration between data collection \nprobes for experimentation and debugging probes to cor\u00adrect inaccuracies in the models. Overall, the \nquality of the LSE system and degree of component reuse has improved dramatically with the addition of \nLSS. From Table 2 one can see that 80% of the 1324 component instances in these models came from a library \nof only 22 components. Over all the models, each module was used approximately 12 times. If triv\u00adial \nhierarchical modules used simply to wrap a collection of com\u00adponents are discounted each module is used \nabout 22 times across the models. This reuse translates into reduced speci.cation time. For example, \na single student, in only 7 weeks, was able to specify and validate, to within a few percent of hardware \nCPI (cycles per instruction), the Itanium 2 model (Model F).  8. RELATED WORK Section 3 described the \ntwo major classes of concurrent-structural systems, OOP-based concurrent structural systems and static \nstruc\u00adtural systems, and explained the strength and weakness of each. In this section, we classify several \nwell known concurrent-structural modeling systems and explore their strengths and weaknesses. SystemC. \nSystemC [11] is an OOP-based concurrent-structural modeling system built as a library for the C++ programming \nlan\u00adguage. Its limitations are described in Section 3.2. In terms of sim\u00adulation speed, reusable components \nin LSE with LSS are at least as fast as custom components written in SystemC [12]. Ptolemy II. Ptolemy \nII [7], when used without the Vergil inter\u00adface, is an OOP-based concurrent-structural modeling system \nfor systems with heterogeneous models of concurrency. Ptolemy al\u00adlows users to de.ne system structure \ndirectly in Java. However, when used in this way it suffers from the shortcomings of structural-OOP systems \ndescribed in Section 3.2. At no point during execu\u00adtion does structure need to be immutable limiting \nstatic analysis capabilities described in Section 3. Using LSS with Ptolemy II as a BSL, however, would \naddress these shortcomings and bring pow\u00aderful reuse to heterogeneous system exploration. Ptolemy II \nwith Vergil. Ptolemy II, when used with the Vergil interface, is a static structural modeling system \nthat supports structure based analyses such as parameterization of non-structural speci.cation (but not \nof structural speci.cation). Ptolemy cannot be used with and without Vergil simultaneously. VHDL. VHDL \n[6] is a tool commonly used for RTL-level modeling and synthesis of hardware systems rather than high-level \nmodeling. Despite its low-level target, VHDL does have a .ex\u00adible type system, limited support for parameter-based \nstructure, and syntax for behavioral (as opposed to RTL) speci.cation. But, VHDL does not support many \nof the features outlined in Section 3, making component reuse dif.cult. For example, VHDL does not support \npolymorphic types, thus forcing reimplementation of com\u00admon components like arbiters based on the datatypes \ninvolved. Fur\u00adthermore, VHDL has no inheritance mechanism to allow the cus\u00adtomization and extension of \ncomponents. Finally, VHDL does not support use-based specialization. It may be possible, however, to \nadd these capabilities to VHDL by using it as a BSL for LSS. Balboa. Balboa [2] is a structural modeling \nsystem designed to allow components developed in various otherwise incompatible C++ modeling environments \nto be composed. Balboa separates in\u00adterface de.nition and structure from component behavior by using \nan interface de.nition language (IDL), with behavior is speci.ed in C++. They call this approach split-level \nprogramming. The com\u00adposition language in Balboa is a program, and thus split-level pro\u00adgramming is closely \nrelated to the compilation process with LSS. Unlike LSS, however, the Balboa structure speci.cation language \nis evaluated at simulator run-time and thus suffers from problems similar to structural-OOP systems. \nHowever, Balboa does use run\u00adtime component connection to provide component overloading. The IDL program \nis run to determine the structure of the model and the resulting structure is used to infer the particular \nversion of an over\u00adloaded component that should be instantiated and the correct com\u00adponent is connected. \nUnfortunately, this approach cannot resolve parametric polymorphism via structure since the resolved \ntypes di\u00adrect compilation of behavioral code at compile-time. Note that the techniques Balboa uses to \nreconcile differences be\u00adtween components from different simulation systems can be used in conjunction \nwith LSS to gain the bene.ts of both LSS and Bal\u00adboa. Also note that Balboa s type inference problem \n[3] is closely related to LSS s type inference problem. However, the LSS al\u00adgorithm is more closely related \nto the basic uni.cation algorithms used in languages such as ML [9]. Polylith. Outside the hardware speci.cation \ndomain, structural interface de.nition languages (IDL) such as the MIL language used in the Polylith \nsoftware bus system [13] also employ concurrent\u00adstructural modeling. This approach is a natural .t since \nthe goal of these tools is to separate the speci.cation of functionality from the speci.cation of interface \nand communication. Similar to static structural systems, Polylith s MIL structure speci.cation language \nuses a declarative syntax to specify component interconnectivity. Most of the features related to reuse \ninvolve resolving differences in datatypes and communication semantics in systems written in dif\u00adferent \nlanguages or running on different platforms in a distributed computing environment. Since these systems \nspecify the behavior of a program by structurally composing components, the ideas pre\u00adsented in this \npaper can be used to add reuse, such as the ability to reuse components to structurally build new easy-to-use \nreusable components. Other IDL systems, similar to Polylith, exist, but a comparison to these systems \nis beyond the scope of this paper. Asim. Asim [4] is a pseudo-structural processor modeling tool developed \nat Digital Equipment Corporation (and now worked on at Intel). Of all the related work, its high-level \narchitectural model\u00ading goals are perhaps the most in line with LSE s. Asim uses struc\u00adtural composition \nbetween components, but uses functional com\u00adposition for communication within a clock cycle. Thus, the \nsystem is not purely concurrent-structural, making component based reuse dif.cult [17]. Since the system \nis not a pure concurrent-structural system, the techniques presented in this paper may not be directly \napplicable to Asim. Asim, however, does support some component reuse through inheritance. Asim details \nare dif.cult to evaluate be\u00adcause the tool is not openly available. 9. CONCLUSION This paper presents \nseveral programming language techniques targeted at improving hardware systems development by increas\u00ading \nthe rate at which ideas can be evaluated. These techniques, described in the context of the design and \nimplementation of the Liberty Structural Speci.cation language (LSS), increase designer productivity \nby encouraging wide-scale component-based reuse. While prior structural modeling approaches forced a \ntrade-off be\u00adtween easy reuse and easy construction of reusable components, LSS provides the best of \nboth through a hybrid solution. The LSS language provides imperative programming constructs to allow \nfor programmatic control of structure in .exible hierarchical compo\u00adnents, but is evaluated at compile \ntime thus also allowing static analysis of the model structure. These static analyses allow the many \nproperties of .exible components to be inferred, reducing speci.cation overhead. This paper presents \nthe static type infer\u00adence algorithm used in LSS to resolve both parametric polymor\u00adphism and component \noverloading. It also presents a new program\u00adming language technique, called use-based specialization, \nwhich, in a manner analogous to type inference, customizes reusable com\u00adponents by statically inferring \ncomponent parameter values that would otherwise have had to be speci.ed manually. Experience with LSS \nindicates that these features signi.cantly improve the reusability of components, dramatically improving \nproductivity in hardware modeling. Acknowledgments We thank Jason Blome, Azmat Hussain, Sharad Malik, \nVijay Pai, David Penry, Ram Rangan, Paul Willmann, and the entire Liberty Research Group for their support \nthroughout the development of LSE and LSS. This work has been supported by the National Sci\u00adence Foundation \n(NGS-0305617) and Intel Corporation. Opinions, .ndings, conclusions, and recommendations expressed throughout \nthis work are not necessarily the views of the National Science Foundation or Intel Corporation. 10. \nREFERENCES [1] BURGER, D., AND AUSTIN, T. M. The SimpleScalar tool set version 2.0. Tech. Rep. 97-1342, \nDepartment of Computer Science, University of Wisconsin-Madison, June 1997. [2] DOUCET, F., OTSUKA, M., \nSHUKLA, S., AND GUPTA, R. An environment for dynamic component composition for ef.cient co-design. In \nProceedings of the Conference on Design, Automation and Test in Europe (2002). [3] DOUCET, F., SHUKLA, \nS., AND GUPTA, R. Typing abstractions and management in a component framework. In Proceedings of Asia \nand South Paci.c Design Automation Conference (2003). [4] EMER, J., AHUJA, P., BORCH, E., KLAUSER, A., \nLUK, C.-K., MANNE, S., MUKHERJEE, S. S., PATIL, H., WALLACE, S., BINKERT, N., ESPASA, R., AND JUAN, T. \nAsim: A performance model framework. IEEE Computer 0018-9162 (February 2002), 68 76. [5] HARPER, R. Programming \nLanguages: Theory and Practice. Draft, 2002. [6] IEEE. VHDL: IEEE Standard 1076. http://www.ieee.org. \n[7] JANNECK, J. W., LEE, E. A., LIU, J., LIU, X., NEUENDORFFER, S., SACHS, S., AND XIONG, Y. Disciplining \nheterogeneity the Ptolemy approach. In ACM SIGPLAN 2001 Workshop on Languages, Compilers, and Tools \nfor Embedded Systems (LCTES 2001) (June 2001). [8] KICZALES, G., LAMPING, J., MENDHEKAR, A., MAEDA, C., \nLOPES, C., LOINGTIER, J.-M., AND IRWIN, J. Aspect-oriented programming. In Proceedings of the 11th European \nConference for Object-Oriented Programming (1997), pp. 220 242. [9] MILNER, R., TOFTE, M., HARPER, R., \nAND MACQUEEN, D. The De.nition of Standard ML (Revised). The MIT Press, Cambridge, MA, 1997. [10] ODERSKY, \nM., WADLER, P., AND WEHR, M. A second look at overloading. In Proceedings of the Conference on Functional \nProgramming Languages and Computer Architecture (1995), pp. 135 146. [11] OPEN SYSTEMC INITIATIVE (OSCI). \nFunctional Speci.cation for SystemC 2.0, 2001. http://www.systemc.org. [12] PENRY, D., AND AUGUST, D. \nI. Optimizations for a simulator construction system supporting reusable components. In Proceedings of \nthe 40th Design Automation Conference (June 2003). [13] PURTILO, J. M. The Polylith Software Bus. ACM \nTransactions on Programming Languages and Systems (TOPLAS) 16, 1 (January 1994), 154 174. [14] SEIDL, \nH. Haskell overloading is dexptime-complete. Information Processing Letters 52, 2 (1994), 57 60. [15] \nSKADRON, K., MARTONOSI, M., AUGUST, D. I., HILL, M. D., LILJA, D. J., AND PAI, V. S. Challenges in computer \narchitecture evaluation. IEEE Computer (August 2003), 30 36. [16] SMITH, G. Principal type schemes for \nfunctional programs with overloading and subtyping. Science of Computer Programming 23, 2-3 (1994), 197 \n226. [17] VACHHARAJANI, M., VACHHARAJANI, N., PENRY, D. A., BLOME, J. A., AND AUGUST, D. I. Microarchitectural \nexploration with Liberty. In Proceedings of the 35th International Symposium on Microarchitecture (November \n2002), pp. 271 282. [18] VACHHARAJANI, M., VACHHARAJANI, N., PENRY, D. A., BLOME, J. A., MALIK, S., AND \nAUGUST, D. I. The Liberty Simulation Environment: A deliberate approach to high-level system modeling. \nTech. Rep. Liberty-04-02, Liberty Research Group, Princeton University, January 2004. [19] WILLMANN, \nP., BROGIOLI, M., AND PAI, V. Spinach: A Liberty-based simulator for programmable network interface architectures. \nIn Proceedings of the SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems \n(June 2004). [20] XIONG, Y., AND LEE, E. A. An extensible type system for component-based design. In \nProceedings of the 6th International Conference on Tools and Algorithms for the Construction and Analysis \nof Systems (March 2000), pp. 20 37.   \n\t\t\t", "proc_id": "996841", "abstract": "Rapid exploration of the design space with simulation models is essential for quality hardware systems research and development. Despite striking commonalities across hardware systems, designers routinely fail to achieve high levels of reuse across models constructed in existing general-purpose and domain-specific languages. This lack of reuse adversely impacts hardware system design by slowing the rate at which ideas are evaluated. This paper presents an examination of existing languages to reveal their fundamental limitations regarding reuse in hardware modeling. With this understanding, a solution is described in the context of the design and implementation of the Liberty Structural Specification Language (LSS), the input language for a publicly available high-level digital-hardware modeling tool called the Liberty Simulation Environment. LSS is the first language to enable low-overhead reuse by simultaneously supporting static inference based on hardware structure <i>and</i> flexibility via parameterizable structure. Through LSS, this paper also introduces a new type inference algorithm and a new programming language technique, called <i>use-based specialization</i>, which, in a manner analogous to type inference, customizes reusable components by statically inferring structural properties that otherwise would have had to have been specified manually.", "authors": [{"name": "Manish Vachharajani", "author_profile_id": "81100483113", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP39044974", "email_address": "", "orcid_id": ""}, {"name": "Neil Vachharajani", "author_profile_id": "81100483107", "affiliation": "Princeton University, Princeton, NJ", "person_id": "P513572", "email_address": "", "orcid_id": ""}, {"name": "David I. August", "author_profile_id": "81100388492", "affiliation": "Princeton University, Princeton, NJ", "person_id": "P60452", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996865", "year": "2004", "article_id": "996865", "conference": "PLDI", "title": "The liberty structural specification language: a high-level modeling language for component reuse", "url": "http://dl.acm.org/citation.cfm?id=996865"}