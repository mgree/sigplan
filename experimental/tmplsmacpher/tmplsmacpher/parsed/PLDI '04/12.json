{"article_publication_date": "06-09-2004", "fulltext": "\n Symbolic Pointer Analysis Revisited * Jianwen Zhu Silvian Calman Department of Electrical and Computer \nEngineering University of Toronto, Toronto, Ontario, Canada {} jzhu, calman@eecg.toronto.edu ABSTRACT \nPointer analysis is a critical problem in optimizing compiler, par\u00adallelizing compiler, software engineering \nand most recently, hard\u00adware synthesis. While recent efforts have suggested symbolic method, which uses \nBryant s Binary Decision Diagram as an alternative to capture the point-to relation, no speed advantage \nhas been demon\u00adstrated for context-insensitive analysis, and results for context-sensitive analysis are \nonly preliminary. In this paper, we re.ne the concept of symbolic transfer func\u00adtion proposed earlier \nand establish a common framework for both context-insensitive and context-sensitive pointer analysis. \nWith this framework, our transfer function of a procedure can abstract away the impact of its callers \nand callees, and represent its point-to in\u00adformation completely, compactly and canonically. In addition, \nwe propose a symbolic representation of the invocation graph, which can otherwise be exponentially large. \nIn contrast to the classical frameworks where context-sensitive point-to information of a pro\u00adcedure \nhas to be obtained by the application of its transfer func\u00adtion exponentially many times, our method \ncan obtain point-to in\u00adformation of all contexts in a single application. Our experimen\u00adtal evaluation \non a wide range of C benchmarks indicates that our context-sensitive pointer analysis can be made almost \nas fast as its context-insensitive counterpart. Categories and Subject Descriptors D.3 [Software]: Programming \nLanguages; D.3.4 [Programming Languages]: Processors compilers, optimization General Terms Languages, \nExperimentation Keywords Pointer analysis, call graph construction, binary decision diagrams *This work \nis supported by NSERC and University of Toronto. Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 04 June 9 11, 2004, Washington DC, USA Copyright 2004 ACM \n1-58113-807-5/04/0006 ...$5.00. 1. INTRODUCTION As an abstraction of memory addresses, a pointer is one \nof the most powerful yet problematic constructs in modern imperative programming languages. Pointers \nare often the sources of non\u00adtrivial software bugs, such as freed memory accesses and memory leaks, which \nreveal symptoms much later than their causes. Point\u00aders signi.cantly reduce the effectiveness of compiler \noptimizations, since they cause memory alias problems that obscure the data de\u00adpendency. In addition, \nthe presence of function pointers and virtual functions complicates the complete construction of call \ngraphs and therefore interprocedural optimization. Pointers also limit the prac\u00adtical application of \nclassical behavioral synthesis, which strives to compile an ordinary program directly into digital hardware, \nsince the hardware semantics of pointers are not yet clear. Pointer analy\u00adsis, which determines the point-to \ninformation, or the runtime val\u00adues of program pointers at compile time, is therefore a subject of intensive \nresearch for the last two decades in the broad areas of pro\u00adgramming languages, optimizing and parallelizing \ncompiler, soft\u00adware engineering and more recently, computer-aided design (CAD) for integrated circuits. \nThe reported analysis algorithms vary with different accuracy\u00adspeed tradeoff and can be categorized according \nto two criteria: .ow sensitivity and context sensitivity. A .ow-insensitive (FI) al\u00adgorithm ignores the \norder of statements when it calculates pointer information, whereas a .ow-sensitive (FS) algorithm takes \ncontrol .ow within a procedure into account. A context-insensitive (CI) al\u00adgorithm does not distinguish \nthe different calling contexts of a pro\u00adcedure, whereas a context-sensitive (CS) does. Fast polynomial \nal\u00adgorithms, such as derivatives of Steensgaard s [36] and Andersen s [3], have been developed for context-insensitive \nanalysis. It has been shown that state-of-the-art implementation of CI analysis can analyze million-line \ncode [19]. On the other hand, most context\u00adsensitive analysis algorithms reported in the literature suffer \nfrom a worst-case exponential time complexity. The best efforts today to address the scalability problem \nseem to be the use of partial con\u00adtext sensitivity [27], or the use of a polymorphic, constraint-based \nanalysis engine [17, 16]. Representing a wide departure from the traditional methods that use explicit \npoint-to graph to capture the program state, in [41] we proposed the use of Binary Decision Diagram (BDD) \nto capture the point-to relation implicitly as Boolean functions and demonstrated positive, yet preliminary \nruntime result for context-sensitive anal\u00adysis. In [5] Berndl et. al. demonstrated the space ef.ciency \nof a similar method applied to the context-insensitive analysis of Java programs. In this paper, we extend \nthe previous two efforts and make the following contributions. Symbolic transfer function. We extend \nour original pro\u00adposal of symbolic transfer function in [41], which uses a Boolean function represented \nby BDD to capture the pro\u00adgram state of a procedure as a function of its caller program state. Our extension \nallows the additional parameterization of callee program state, which enables the capture of transfer \nfunctions in a single pass. Common CI/CS symbolic analysis framework.We estab\u00adlish a common, ef.cient \nframework for both context-sensitive and context-insensitive analysis. This not only enables the leverage \nof transfer function for the .rst time to speed up CI analysis, but also enables the study of speed-accuracy \ntrade\u00adoff among a spectrum of symbolic analysis methods with dif\u00adferent context-sensitivity. To the best \nof our knowledge, such frameworks useful in many studies [22, 21, 23, 17] have not been reported for \nBDD-based pointer analysis.  Symbolic invocation graph. Most previous methods [14, 39] for context sensitive \nanalysis, including our own [41], re\u00adquires the construction of an invocation graph, which can be exponentially \nlarge. To avoid this problem, we propose the use of BDDs to annotate the call graph edges with Boolean \nfunctions to implicitly capture the corresponding invocation edges. Such representation of the invocation \ngraph leads to the exponential reduction of memory size in practice.  State superposition. In contrast \nto the previous efforts where program states of a procedure under different calling contexts have to \nbe evaluated separately by the application of transfer functions, we devise a scheme where the the symbolic \ninvo\u00adcation graph is leveraged to collectively compute a superpo\u00adsition of all states of a procedure \nunder different contexts. This leads to an exponential reduction of analysis runtime in practice.  \nThe implementation of the aforementioned ideas yielded inter\u00adesting new results on a comprehensive set \nof C benchmarks. First, we show that the speed of the symbolic method can be made com\u00adparable to the \ntraditional methods for context-insensitive analysis [23]. Second, we show that context-sensitive analysis \ncan have a runtime in the same order of magnitude as its context-insensitive counterpart. The rest of \nthe paper is organized as follows. In Section 2, we describe the construction of our symbolic transfer \nfunction. In Sec\u00adtion 3, we describe our analysis framework as well as the core algo\u00adrithms involved. \nIn Section 4, we describe the symbolic invocation graph and show how it can be used to compute the state \nsuperposi\u00adtion. In Section 5, we complement the theory with a discussion on various engineering issues. \nIn Section 6, we present experimental results. We discuss the related work in Section 7. 2. SYMBOLIC \nTRANSFER FUNCTION 2.1 Symbolic Program State The goal of pointer analysis is to statically estimate the \nruntime program state, or the set of values each program location can hold. To trade accuracy for analysis \nspeed, we often collapse related pro\u00adgram locations together, thereby forming a block. Locations within \na block are not distinguished. The blocks can be global variables, or local variables, or procedure parameters, \nor dynamically allo\u00adcated memory blocks. The values of interest are only the addresses of the blocks. \nEXAMPLE 1. Consider the C program in Figure 1 (a), which is modi.ed from [27]. The program contains global \nblocks g, a, local blocks p, q, r, t, f, and a dynamic block m allocated at S3. The program state is \noften abstracted as a point-to graph 8V, E., whose vertices V represent the set of blocks, and an edge \n8u, v.E E from block u to block v indicates that it is possible that the con\u00adtent of block u is the address \nof block v. The set of all edges de.nes the point-to relation. EXAMPLE 2. Figure 2 shows a point-to graph \ncapturing the program state after the completion of the main procedure in Exam\u00adple 1. Figure 2: Program \nstate on the completion of Example 1. In [41], we proposed an alternative way to capture the point-to \nrelation, which associates each block u with two Boolean func\u00adtions, called its domain (denoted by u*) \nand range (denoted by u for convenience). The set of domain functions of all blocks form an orthogonal \nfunction set in the Boolean space, called the ** domain space, spanned by the set of Boolean variables \n-x = {x0*, ..., xn*-1}, such that .u . Similarly, the set of =v, u \u00d7v =0range functions of all blocks \nform a orthogonal function set in the companion Boolean space, called the range space, spanned by the \n* set of Boolean variables -x ={x0, ..., xn-1}. The domain and range functions of blocks are most conveniently \nselected as disjoint minterms in the Boolean spaces [18]. For each block u EV , we denote its corresponding \nminterms as Xu*, Xu, * or simply u, u 1. Example 3 shows the assignment of minterms to the blocks. It \nis important to note that with this encoding scheme, ** the dimension of the Boolean spaces -x and -x \n* is an exponential reduction of the number of minterms, or the number of blocks. This fact directly \ncontributes to the ef.ciency of our representation, as will be explained in Section 2.3. EXAMPLE 3. The \nfollowing table shows how the blocks in Ex\u00ad * ample 1 are mapped to minterms in the Boolean spaces -x \nand -** x . Note that the dimension (number of Boolean variables) of both spaces is 4. domain range * \n**** a =X0 =\u00afxx\u00afx\u00afx\u00afa =X*=\u00afx0x\u00af1x\u00af2x\u00af3 0123 0 * **** g =X1 =\u00afxx\u00afx\u00af2xg =X*=\u00afx0x\u00af1x\u00af2x3 013 1 * **** p=X2 \n=\u00afxx\u00afx\u00afp =X*=\u00afx0x\u00af1x2x\u00af3 01x23 2 * **** q =X3 =\u00afxx\u00afq =X*=\u00afx0x\u00af1x2x3 01x2x33 t* ****X* =X4 =\u00afx0xx\u00afx\u00aft \n==\u00afx0x1x\u00af2x\u00af3 123 4 * **** r =X5 =\u00afx0xx\u00af2xr =X*=\u00afx0x1x\u00af2x3 13 5 f* ****X* =X6 =\u00afx0x1xx\u00aff ==\u00afx0x1x2x\u00af3 \n2 3 6 * **** m=X7 =\u00afxm =X*=\u00afx0x1x2x3 0x1x2x37 We can now capture the point-to relation by mapping each \nedge ** 8u, v.in the point-to graph by a Boolean product uv,where urepresents the domain minterm of \nu,and v represents the range minterm of v. In other words, given a program state represented by E, the \npoint-to relation can be represented by a Boolean function * L(u,v.*E uv. 1Hereafter we use the convention \nthat subscripted lower case letters denote Boolean space variables, whereas subscripted upper case letters \ndenote minterms in the Boolean space. char *g, a; 1 void main() { 2 char *p, *q; 3 S1: alloc( &#38;p \n); 4 getg( &#38;q ); 5 g=&#38;a; 6 } 7 8 void getg( char** r ) { 9 char **t = &#38;g; 10 if(g==NULL) \n11 S2: alloc( t ); 12 *r=*t; 13 } 14 15 void alloc( char** f ) { 16 S3: *f = malloc(1); 17 } 18 alloc \ngetg main e0f e1r t g G0 m e2G1 g a T alloc =f *G0 +e* 0 m =\u00afx * 0x * 1x * 2 \u00afx * 3x0 \u00afx1 \u00afx2 \u00afx3 +x \n* 0 \u00afx * 1 \u00afx * 2x3 \u00afx0x1x2x3 T getg =r *G1 +t * g +e* 1 e2 =\u00afx * 0x * 1 \u00afx * 2x * 3x0 \u00afx1x2 \u00afx3 +\u00afx \n* 0x * 1 \u00afx * 2 \u00afx * 3 \u00afx0 \u00afx1 \u00afx2x3 +x * 0 \u00afx * 1x * 2x * 3x0x1 \u00afx2 \u00afx3 T main =g * a =\u00afx * 0 \u00afx * 1 \n\u00afx * 2x * 3 \u00afx0 \u00afx1 \u00afx2 \u00afx3 (a) C source code (b) Transfer functions Figure 1: A walk-through example. \nEXAMPLE 4. The program state in Example 2 can be repre-much on the transfer functions of its callees. \nTo make sure that the sented by a Boolean function: point-to information of a procedure is evaluated \nas late as possible, in this paper we introduce .nal state blocks, which represent pos\u00ad ** m +g * a \n+q ** m +g ** m +q ** p a sible values of a memory dereference before leaving the procedure. 0x\u00af1x\u00af2 \nx *** 0x\u00af1x2 x\u00af * * 0 x\u00af1x\u00af2x3 x\u00af0x1x2x3 * * * x\u00af 3x\u00af0x1x2x3 +\u00afx = * and -x * Again, we use disjoint \nminterms in Boolean spaces -x * encode initial and .nal state blocks. We follow the convention that \nto * 0 x\u00af1x2x3 x\u00af0x1x2x3 * ** x\u00af 3x\u00af0x\u00af1x\u00af2x\u00af3 +\u00afx +  2.2 Symbolic Transfer Function The point-to graph \ncan be used to represent the program state in a procedure only when the program state before the procedure \nis called is known. To safely capture the point-to relation under all circumstances, the concept of transfer \nfunction, which can be intu\u00aditively considered as point-to relation parameterized over different calling \ncontexts, has been widely used [39, 10, 11]. The parameters of the transfer function do not necessarily \ncorrespond to the param\u00adeters of the procedure. In fact, any memory dereferences, including parameter, \nlocal and global dereferences within the procedure can be a transfer function parameter, since their \nvalues are not known * until the state of its caller is known. A memory dereference can be characterized \nby the notion of access path 8b, l.,where b is the root * memory block, and l is the level of dereferences. \nAn access path with the form 8b, 0. is trivial and always resolve to the constant ** x\u00af 3x\u00af0x\u00af1x\u00af2x\u00af3 \n+ 0x\u00af1x2 x the minterms Gk and ek represents the initial and .nal state block for memory dereference \nk respectively. EXAMPLE 5. Consider the procedure alloc in Example 1, where the parameter f is dereferenced. \nSince the value of f is unknown, we cannot determine the memory blocks to be updated. With the intro\u00adduction \nof the initial state block G0, and the .nal state block e0,the procedure can be summarized with a transfer \nfunction as shown in the point-to graph of Figure 1 (b). Similarly, we can obtain the transfer function \nof procedure getg in Example 1 in Figure 1 (b) where memory dereference 1 corresponds to *r and memory \ndereference 2 corresponds to **t2. The introduced initial and .nal ** blocks can be encoded as minterms \nin -x and -x * in the following table. domain range deref *** x\u00af * x\u00af * x\u00af * A0 = X8 = x0x\u00af1x\u00af2x\u00af3 *f \n= (f, 1) A = X= x 0 8 0123 address value b, whereas an access path with the form 8b, 1. repre\u00ad ***** \n*f = (f, 1) BB0 = X x\u00afx\u00af= X9 = x0x\u00af1x\u00af2x3 = x 2x30 9 01 sents the address values stored in b. After \nthe transfer functions of * = X* **** *r = (r, 1) AA1x\u00afx\u00af = X10 = x0x\u00af1x2x\u00af3 = x 1x1 10 0 23 procedures \nare derived, they can be applied at their corresponding * = X* * *** *r = (r, 1) BB1x\u00af = X11 = x0x\u00af1x2x3 \n= x 1x2x1 11 0 3 call sites by substituting the parameters, or the unknowns, with the known program \nstate. Many analysis techniques, especially those that are context-insensitive, do not use transfer functions \n[5]. While the overhead of transfer function application can be avoided, these techniques may have to \nre-analyze the procedures, which is often the case during .xed\u00adpoint iteration. This not only implies \nredundant computation, but **** * B= X* = x0xx\u00afx\u00afB2 = X12 = x0x1x\u00af2x\u00af3 **t = (t, 2) 2 12 123 In addition, \nwe introduce .nal blocks corresponding to actual pa\u00adrameter values passed to procedures at Line 4, 5 \nand 12 respec\u00adtively. Note that while they do not appear in transfer functions, they will be used in \nthe future for transfer function application. domain range deref also implies that the program information \nhas to be kept in memory * = X* 13 **** p= (p, 0) BB3x\u00af = X13 = x0x1x\u00af2x3 = x 0x 2x3 1 3 during analysis. \nThis potential scalability problem leads us to the * = X* 14 *** * q= (q, 0) BB4 \u00af = X14 = x0x1x2x\u00af3 \n= x0x1x x 234 decision of using the transfer function approach even for context\u00ad * * * * * B= X* = \nx0x1x2xB5 = X15 = x0x1x2x3 *t = (t, 1) 515 3 insensitive analysis. In [41] we introduce the notion of \ninitial state blocks, each of which corresponds to the set of possible values of a memory dereference \nbefore entering the procedure. An initial state block is treated as if it was a separate memory block. \nOne problem with only using initial blocks as transfer function parameters is that the transfer function \nof a procedure depends very 2.3 Binary Decision Diagram We have established the use of Boolean functions \nas an alterna\u00adtive to capture the point-to relation. However, other than being well 2Note that here we \nfollow the convention of writing L-values, thus the R-value *t at line 14 of Example 1 is written as \n**t.  alloc * * * * *  * * * x x x 2 * * * * * * * * x2 x2  x0 x0 x0 x0 x1 x1 x1 x1 x3 x3 x3 x3 \n(a) alloc (b) getg (c) main (d) all Figure 3: Transfer functions in BDD. founded on the formalism of \nBoolean algebra, we have not yet jus\u00adti.ed its use in terms of ef.ciency. In this section, we introduce \nBryant s Reduced Ordered Binary Decision Diagram (ROBDD or simply BDD) [6], a proven technology for the \nef.cient manipula\u00adtion of Boolean functions. Traditional representations of Boolean functions include \ntruth tables, Karnaugh maps, or sum-of-products [18], each suffering from an exponential size with respect \nto the number of variables. Bryant used a rooted, directed binary graph to represent an arbitrary * \nBoolean function. Given a Boolean space -x = {x0,x1, ..., xn-1}, a Boolean function fv corresponds to \na graph rooted at graph node v. Each node in the graph is characterized by an index i, corre\u00adsponding \nto a Boolean variable xi, as well as its negative cofac\u00adtor flow and positive cofactor fhigh, each of \nwhich is by itself a Boolean function, and therefore a graph node. Logically, fv is re\u00adlated to its two \ncofactors by Shannon expansion fv = xiflow + x\u00afifhigh. Two outstanding nodes, called the terminal nodes,rep\u00adresent \nthe constant logic value 0 and 1. The terminal nodes are assumed to have an index of in.nity. By imposing \ntwo invariants on the graph, Bryant manages to keep the representation canoni\u00adcal. First, all variables \nhave a .xed ordering, that is, the index of any non-terminal node must be less than the index of its \ncofactors. Second, all isomorphic subgraphs are reduced into one, that is, if the cofactors of two graph \nnodes u and v are the same, and their indices are the same, then they will be the same. Figure 3 shows \nthe BDD representation of symbolic transfer func\u00adtions in the previous section3. Note that we use BDD \nto represent both the transfer functions and the program states. The fact that BDD is nothing but a graph \nrepresentation of a Boolean function begs the question that why we do not use the point-to graph in the \n.rst place, which seems to be much more intuitive. One primary advantage of using BDD is that point-to \ngraphs need to be main\u00adtained for every procedure, each of which may share many common edges. In other \nwords, there is a large amount of redundancy. In contrast, BDD enables the maximum sharing among graph \nnodes, and point-to information in different procedures, at different pro\u00adgram points can be reused. \nAs an example, the internal BDD nodes 8a, d5, c2 are shared among different transfer functions. As the \nprogram grows large, such sharing occurs in a large scale. As a result, when BDD is used to represent \na point-to set, its size is not necessarily proportional to its cardinality, as in the case of point\u00adto \ngraph often times it is proportional to the dimension of the Boolean space. This space ef.ciency will \ntranslate into speed ef.\u00adciency, as will become apparent in later sections. 3Note that we use a variant \nof BDD that uses complementary edges (dashed lines), where a reference to terminal node 0 is implicitly \nrepresented as a complementary edge to terminal node 1. 3. SYMBOLIC POINTER ANALYSIS FRAME-WORK 3.1 \nRecurrence Equations We now describe our pointer analysis framework. In order to fo\u00adcus on the fundamentals, \nrather than the implementation details, we assume that after preprocessing, the program can be characterized \nby the following mathematical model. Note that in this model we do not distinguish between call graph \nand invocation graph, thus both context-insensitive analysis and context-sensitive analysis can be applied \nequally well based on this formulation. Also note that for now we assume there is no dynamic procedure \ncalls. The call graph or invocation graph can therefore be built in advance. This assumption will be \nrelaxed by more careful engineering discussed in Section 5. I . [0, .) is the set of procedures. For \ncontext-insensitive analysis, they correspond to the nodes in the call graph. For context-sensitive analysis, \nthey correspond to the nodes in the invocation graph, each of which corresponds to a call\u00ading path in \nthe call graph. We also assume that procedure 0 corresponds to the top procedure in the whole program. \n J . [0, .) is the set of memory blocks contained in the program. It includes globals, locals, parameters \nas well as heap objects.  K .[0, .), .i EI corresponds to the set of memory deref\u00aderences.  D : K .*J \n\u00d7Z characterizes the access path of each mem\u00adory dereference k E K by a tuple 8b, l. where b E J is a \nmemory block, and l EZ is the level of dereferences. This representation can be extended with more complex \naccess patterns.  -* -* {Ti( G, e )|.i EI}corresponds to the set of transfer func\u00ad -* tions for each \nprocedure i.Here G =[G0, ...G|K|-1] cor\u00ad -* responds to the initial state blocks, and e =[G0, ...G|K|-1] \ncorresponds to .nal state blocks. C : I .* 2I corresponds to the calling relation. .i E I, C(i) gives \nthe set of callees of i, C-1(i) gives the set of callers of i.  B : I \u00d7 I \u00d7 K .* K corresponds to parameter \nbinding. For each call site with caller i E I and callee j E I,and the formal parameter dereference k \nE K, B(i, j, k) gives the dereference in caller i corresponding to the actual.  The task of pointer \nanalysis is therefore .nding program state Si for each procedure i E I. We obtain the results by solving \nthe following recurrence equations. Ai k = j*C-1(i) ej B(j,i,k), .k E K, i E I (1) ei k = query(Si , \nD(k)), .k E K, i E I (2) Si = Sj + Sj + (3) j*C-1(i) j*C(i) T i( -* G * -* A i , -* e i * -* ei), .i \nE I  Equation (1) computes the initial value of a formal parameter, or memory dereference k in procedure \ni before entering the proce\u00addure. It is computed by combining the states of the corresponding actuals \nfrom all incoming callers. The set of callers are computed by C-1(i). Given caller j and callee i, the \nactual memory deref\u00aderence corresponding to the formal k is given by B(j, i, k), whose corresponding \nvalue is given by ej . Equation (2) computes B(j,i,k) the .nal value of memory dereference k in procedure \ni before leav\u00ading the procedure. It is computed by performing a state query on Si . Equation (3) computes \nthe state Si of procedure i.It is com\u00adputed by adding the states of its callers and callees as well as \nnew states originating from itself. The latter is computed by substituting the initial and .nal state \nblocks that appear in its transfer functions by the actual state blocks computed in Equation 1 and Equation \n2. This procedure is called transfer function application. The recurrence equation set can be solved \nby standard iterative framework that terminates at a .xed point. The initial condition for the iteration \nis set in the following equation, which essentially com\u00adputes the sum of all parameter-independent point-to \ninformation in the transfer functions. i T i-* - * S=( G * 0,e * 0) (4) i*I EXAMPLE 6. The initial state \nof the program in Example 1 is g * a + t * g. 3.2 Symbolic State Query We now consider how to perform \nstate query ef.ciently. Given a memory dereference of block b with level l, Algorithm 1 performs the \nstate query by computing the reachable envelop of depth l on the point-to graph starting from block b. \nIn contrast to the tradi\u00adtional approach where a breadth-.rst search has to be performed to explicitly \nenumerate all neighbors of a node in the point-to graph, our representation enables the use of implicit \ntechnique originally developed in the CAD community for the formal veri.cation of digital hardware. This \napproach relies on the ef.ciency of image computation,which collectively computes the set of successors \nin a graph given a set of predecessors. Since in our representation, a set of memory blocks can be represented \nas a Boolean function, the image computation can be formulated as Boolean function ma\u00adnipulation, which \nin turn can be ef.ciently implemented on BDD. As shown in Line 5, the image computation is performed \nby multi\u00adplying the state with the Boolean function of the predecessor in the domain space, and then \nexistentially abstracting away the Boolean variables in the domain space. Example 7 illustrate how it \nworks. Many efforts have been invested to make this operation particularly ef.cient [12, 13, 7, 29]. \nALGORITHM 1. State query. query( S, (b, l) ) { 1 if( l == 0 ) return Xb ; 2 else { 3 domain = query(S, \n(b, l - 1))|-yx y-yx * ; return :-Ax * .[S . domain] ; 4 5 } 6 } 7  EXAMPLE 7. Consider the state of \nprocedure main represented by the point-to graph in Figure 2, which can be represented sym\u00ad * * *** \nbolically by S = pm+gm+ga+qm+qa. To .nd out where g points to, we .rst multiply S by g *.Since g * is \northogonal to p * and q * by the property of minterms, the step yields g * m + g * a = **** **** x\u00af0x\u00af1x\u00af2x3x\u00af0x1x2x3 \n+\u00afx0x\u00af1x\u00af2x3x\u00af0x\u00af1x\u00af2x\u00af3,in other words, all irrelevant point-to facts are .ltered. We then abstract \naway all do\u00ad * main variables -x *, which yields x\u00af0x1x2x3 +\u00afx0x\u00af1x\u00af2x\u00af3 = m+a. 3.3 Symbolic Transfer \nFunction Application We now consider how to perform transfer function application ef.ciently. A naive \nway is to .nd the cofactors of transfer function T i with respect to each parameter to be substituted. \nFor example, * the cofactor with respect to Gk can be found by :-x.(Gk .T i).The application result \ncan then be found by summing up all cofactors multiplied by the corresponding substituent. We propose \na new method such that the substitutions can be performed collectively. This is achieved by introducing \nanother ** Boolean space -y = {y0, ..., ym-1} and its companion -y *,the minterms of which are used \nto distinguish different memory deref\u00aderences such that dereference k E K corresponds to minterms Yk \nand Yk * respectively. In addition, we introduce another Boolean variable pair z and z * to distinguish \nthe initials and .nals. The Boolean variables introduced help to form determinants that can help to distinguish \nthe parameters to be substituted. We can then modify each of the transfer function T i into an augmented \ntransfer function T i where each occurrence of parameter Gk is multiplied * Y * by its determinant \u00afk \n* by z k* . zYk, ek by zYk,and e k e EXAMPLE 8. The augmented transfer functions of procedures T alloc \n* T getg * in Example 1 are: = f * \u00afY0 * m, \u00af zY0G0+z = r zY1G1+ ** T main = T main tg + zY1 * e1zY2e2 \nand . Similarly, we can create a binding between all substituents and parameters by multiplying each \nwith the corresponding determi\u00adnant, that is, Aik by \u00afk by zYk. As shown in Algorithm 2, the zYk, ei \nbinding can be used to multiply the augmented transfer function. Since terms with different determinants \nwill be canceled thanks to the orthogonality of minterms, the desired result can be obtained from the \nmultiplication result by existentially abstracting away the determinant variables. ALGORITHM 2. Transfer \nFunction Application. A--A apply( T i , A i , 8i ) { 8 s =; 9 T i . binding = (\u00afzYkAi + zYk8i ); 10 \nkEKk k AT i s = :z.:-y.[ . binding]; 11 -y-y12 binding* = binding|*y*y* ; xyx ,y y-y ,z y- z * A* return \n:z.:-y.[s . binding* ] ; 13 } 14  (a) call graph (b) invocation graph (c) symbolic invocation graph \nFigure 4: Call graph and invocation graph.  4. SYMBOLIC INVOCATION GRAPH 4.1 Invocation Graph An invocation \ngraph is an expansion of the call graph [14]. Each node in the call graph is expanded into multiple instances \nin the invocation graph such that each node corresponds to a unique path in the call graph. The node \nin the invocation graph thus identi\u00ad.es a unique calling context. Figure 4 (a) shows the call graph of \na program, whose corresponding invocation graph is shown in Figure 4 (b), where each node is labeled \nby an integer index repre\u00adsenting the different instances of the procedure. Invocation graph is essential \nfor context-sensitive analysis since program state corresponding to each node in the invocation graph \nhas to be computed. Unfortunately, the size of the invocation graph is exponential in relation to the \ncall graph size. Some analysis tech\u00adniques avoid the explicit construction of the invocation graph, how\u00adever, \nthe computation of context state still has to be carried out ex\u00adponential number of times. We now propose \na new representation of the invocation graph whose size can be reduced exponentially. We introduce a \nnew pair ** * of Boolean spaces, -w (domain) and -w (range) to represent the different instances of \na call graph node in the invocation graph. A node in the invocation graph can therefore be identi.ed \nby the corresponding call graph node, as well as a minterm in the Boolean space of interest. For example, \nC0 in Figure 4 (b) can be identi.ed by C and the minterm W0,and C1 can be identi.ed by C and the minterm \nW1. We de.ne a symbolic invocation graph to be a call graph where each 8i, j., representing a call site \nfrom procedure i to procedure j, is annotated with a Boolean function E(i, j), representing the set of \ninvocation graph edges associated with 8i, j.. Figure 4 (c) shows the symbolic invocation graph equivalent \nto Figure 4 (b). For ex\u00adample, the edge 8C, D.is annotated with W0 * W0 + W1 * W1, mean\u00ading that 8C, \nD.in the call graph can be re.ned into 8C0,D0.and 8C1,D1.in the invocation graph. Note that when E(i, \nj) is rep\u00adresented by BDD, the BDD nodes can be shared among all edges in the call graph. For example, \nthe symbolic invocation edges for 8C, D., 8C, E.and 8C, F .in the example in Figure 4 share a com\u00admon \nBDD node since they have exactly the same pattern. 4.2 Symbolic Invocation Graph Construction We now \npresent our symbolic invocation graph construction al\u00adgorithm. Without loss of generality, in Algorithm \n3 we only show the construction algorithm for an acyclic call graph. We maintain an instance count for \neach procedure i. Initially, the instance count of the top procedure is set to 1. We then traverse each \nprocedure in topological order, and process each call graph edge 8i, j.. The symbolic invocation edge \nE(i, j) is essentially a relation between the set of all instances of i to the set of instances of j \noriginating from i. If we treat each instance as a number,then any 8u, v.EE(i, j) satis.es two conditions: \n(a) u< count(i);(b) u + offset = v. Condition (a) can be generalized over any instance count number into \na relation R<(x, y). This relation can be easily pre-constructed using BDD in a way that mimics the construction \nof the hardware comparator [18] for less than , as shown in Figure 5 (a). Similarly, condition (b) can \nbe generalized over any offset number into a rela\u00adtion R+(x, y, z). This relation can be easily pre-constructed \nusing BDD in a way that mimics the hardware adder [18] concatenated with a hardware comparator for equality, \nas shown in Figure 5 (b). Computing E(i, j) then amounts to plugging in the constant values of instance \ncount and offset into the pre-constructed relations and then .nding their conjunction. After a call graph \nedge is processed, the offset value is updated accordingly. After all call graph edges originating from \na procedure are processed, its instance count is updated accordingly. We now show that both the space \ncomplexity of symbolic in\u00advocation graph representation, and the time complexity of its con\u00adstruction \nalgorithm are polynomial with respect to the number of call graph nodes. It is important to note that \nwhile the number of contexts, or the number of call graph node instances, are exponen\u00adtial in relation \nto |I|, the number of BDD variables used to encode the contexts is logarithmic to the number of contexts. \nTherefore, ** |-w |and |-w * |is of O(|I|). On the other hand, it is well-known that the BDD representations \nof both the adder and comparator cir\u00adcuits are linear with respect to the number of BDD variables, we \ncan therefore conclude that the size of the generalized relation is O(|I|). Since BDD conjunction is \nproportional to the size of its operands only, our conclusion follows. ALGORITHM 3. Symbolic Invocation \nGraph Construction. constructSymbolicInvocationGraph() {count(0) = 1; forall( i . =0,i. I) in topological \norder {offset = 0; forall( j . C-1(i) ) { -* A A-* A- E(i,j) = R+(w,offset,w) . R<(w offset = offset \n+ count(j); } count(i) =offset; } } 15 16 17 18 19 ,count(j)); 20 21 22 23 24 25 (a) R<(x, y): x<y \nx0y0z0 x1 y1 z1 x2 y2z2 x3 y3 z3  (b) R+(x, y, z): x + y = z Figure 5: Construction of helper symbolic \nrelations.  4.3 Symbolic State Superposition We now demonstrate that the space ef.ciency achieved by \nthe symbolic invocation graph representation can be exploited to achieve an exponential reduction of \nanalysis runtime in practice as well. The key idea is to compute the state of an invocation graph node \nas\u00adsociated with a common procedure collectively. Note that this does not mean we will collapse all states \ntogether, as is done in context\u00adinsensitive analysis. Instead, we compute what we call a state su\u00adperposition, \nde.ned as the sum of all invocation graph node states associated with a common procedure multiplied by \nthe correspond\u00ad * ing minterms in the instance space -w . Note that the state of an in\u00addividual invocation \ngraph node can be retrieved from the state su\u00adperposition easily by multiplying the corresponding minterm \nand then abstracting away the instance variables. EXAMPLE 9. Consider procedure alloc in Example 1, which \ncontains two invocation graph node instances alloc0 and alloc1, where the formal corresponds to the calling \npath main * alloc and the latter corresponds to the calling path main * getg * alloc. The state for alloc0 \nis p * m. The state for alloc1 is g * m. The state superposition for alloc is W0p * m+W1g * m. The state \nof * alloc0 can be retrieved from the state superposition by :-w.[W0 . * ** (W0pm + W1gm)] = pm. The \nrecurrence equations (5), (6) and (7) are modi.ed from equa\u00adtions (1), (2) and (3) to carry out context-sensitive \nanalysis. Note that the procedure of state query and transfer function application remains unchanged, \nexcept that they now operate on state superpo\u00adsition. All modi.ed components concern propagating states, \nor point\u00adto facts from caller to callee and vise versa. The challenge stems from the fact that in order \nto be context-sensitive, states need to be translated from the instance space of procedure i to a different \nin\u00adstance space of procedure j. Such translation can be achieved by exploiting the symbolic invocation \nedges E(i, j). For example, the modi.ed Equation (5), which is responsible for parameter binding, j ** \n .rst mirrors the actual efor parameter k into the -w space, B(j,i,k) and then multiply it by E(j, i). \nThis way, the state information from caller j will not corrupt the state information of other contexts \noriginating from a different caller of i. The desired state values can ** be obtained by further abstracting \naway the -w variables. It is important to note that E(i, j) may capture thousands of actual in\u00advocation \nedges, therefore the symbolic procedure described above is very ef.cient. Similarly, in (7), such instance \nspace translation between callers and callees can be computed symbolically. Note that when propagating \npoint-to information from callee to caller, irrelevant information, such as the state of callee formal \nparame\u00adters needed not to be propagated. Such pruning can be computed ef.ciently using symbolic method \n[41]. Ai k = :-* w * .[ej B(j,i,k)|-. w .-. w * . E(j, i)], (5) j*C-1(i) .k E K, i E I e i k = query(Si \n, D(k)), .k E K, i E I (6) Si = :-* w * .(Sj |-. w .-. w * . E(j, i)) + (7) j*C-1(i) :-* w.[prune(Sj \n) . E(i, j)]|-. w *.-. w + j*C(i) apply( T i , -* A i , -* e i), .i E I  EXAMPLE 10. The complete illustration \nof solving the above equations for Example 1 can be found in Appendix A.  5. ENGINEERING ISSUES We have \nleft out several engineering issues in the theoretical dis\u00adcussion earlier. They are nevertheless important \nfactors that con\u00adtribute to the overall ef.ciency of the proposed methods. Some issues are common to \nall pointer analysis frameworks, some are unique to the proposed symbolic analysis framework. The presence \nof recursion in the program can make the invo\u00adcation graph in.nitely large. We use Tarjan s algorithm \nto detect nested strongly connected components [37] in the call graph. The acyclic symbolic call graph \nconstruction algorithm presented ear\u00adlier is then applied hierarchically in a bottom up fashion. The \npres\u00adence of function pointers prevents the complete pre-construction of the call graph. In our analysis, \nnew call graph edges will be dynamically added as new point-to information related to function pointers \nare discovered. The affected symbolic edges will also be dynamically constructed. It is well known that \nvariable ordering has a large impact on the size of BDD and dynamic variable reordering is often the \nstrategy of choice in many BDD-based algorithms. As later shown in Sec\u00adtion 6, we have found that for \npointer analysis, the variable order has a rather small impact on BDD size. As a result, dynamic vari\u00adable \nreordering adversely impacts the analysis speed. While we do not perform variable reordering during the \nanalysis, we do apply one important constraint to the variable order. By making the cor\u00adresponding variables \nin the domain and range spaces adjacent to each other, we can keep the mirroring operation, which substitutes \nthe range variables in a Boolean function by its domain variables, linear. As shown in Algorithm 1 Line \n4, mirroring is a frequent operation. An extremely important technique that can help speed up the analysis \ntime is the use of caching. Caching keeps a hash table that stores the result of a BDD computation. The \nhash table is keyed by 4 x 10 11 11 property of BDD, common BDD computation that shares the same 10 \n10 12 12 result should be shared by other upper-level problems. The use Total Space ( MB ) 7 6 6 5 \n5 4 4 of BDD allows dynamic programming to be applied at a very .ne 3 3 2 2 1 grain level, which is \notherwise very hard to identify manually. Another important technique is lazy garbage collection.BDD \n1 # BDD Nodes in Symbolic Invocation Graph nodes are often shared by other BDD nodes. When the reference \ncount of a BDD node goes to zero, its memory needs to be re\u00adclaimed, or garbage collected. On the other \nhand, there is a high chance that this BDD node maybe re-created later. We choose to garbage collect \na BDD node lazily, that is, only when a threshold value of heap size is exceeded. As shown later in Section \n6, this choice has a positive impact on the analysis speed. We also apply incremental evaluation of the \nrecurrence equa\u00adtions, meaning that we only apply the equations on the changes from the previous iterations. \nThis greatly limits the computation involved in the later iterations of the .xed-point computation since \nthe BDD size involved is much smaller. This technique is well known in symbolic reachability analysis \nand is used in [5] as well. 6. EXPERIMENTAL RESULTS Our symbolic pointer analysis tool is implemented \nin C, and makes use of a compiler infrastructure to translate from several frontends (e.g. C, Java, Verilog, \netc.), into an intermediate rep\u00adresentation (IR). In the setup pass, the infrastructure traverses the \nIR generated by the frontends to produce the call graph (CG) and control .ow graph (CFG). Following the \nsetup, an intraprocedu\u00adral analysis pass is performed on all user-de.ned procedures in the program, iterating \nover the CFG and creating a .ow-insensitive transfer function for each procedure. An interprocedural \npass is then followed, which performs either a context-insensitive analysis, or context-sensitive analysis. \nWe use Somenzi s publicly available CUDD package [35] for BDD implementation. Our current imple\u00admentation \ndoes not support non-local control transfer (setjmp/longjmp calls), location sets [39], and assumes no \nill advised use of pointers is made (like random memory accessing via integers). Heap objects are named \nafter the allocation site. Lastly, the C library function s transfer functions are precomputed and applied \nas necessary. The goal of our empirical evaluation is three-fold. Our primary goal is to quantify the \nspeed and space ef.ciency of the proposed symbolic method. Our second goal is to verify if a context-sensitive \nanalysis can provide more precision than context-insensitive anal\u00adysis. Our third goal is to quantify \nthe BDD-related engineering issues discussed in Section 5. With the common analysis framework described \nearlier, we re\u00adport results on both context-insensitive analysis (Referred to as CI) and two types of \ncontext-sensitive analysis. Referred to as CS I, the .rst type does not distinguish between call sites \nin a procedure targeting the same callee. Note that results from [17, 16] are re\u00adported with this type \nof context-sensitivity. Referred to as CS II, the second type does make such a distinction, and it was \nour ob\u00adservation that the size of contexts involved in CS II is signi.cantly larger than CS I. We perform \nour evaluation against three benchmark suites: prolangs [32], the popular benchmark suite from the pointer \nanalysis com\u00admunity, the integer suite in SPEC2000 [1], and .nally MediaBench [25]. The prolangs benchmarks \nwere utilized in evaluating the per\u00adformance of many pointer analysis algorithms, and as such serves \n0 101 102 103 104 105 106 107 108 109 Contexts Figure 6: Memory usage versus context count. as a valid \ncomparison with previous work in this area. The SPEC2000 and MediaBench benchmarks, which are relatively \nlarge, are se\u00adlected to help study the robustness and scalability of our algorithm. The characteristics \nof the reported benchmarks in this paper are shown in Table 1. The experiment was performed on a Sun \nBlade 150 workstation with 550 MHz CPU and 128MB RAM, running on Solaris 8 Op\u00aderating System. The executable \nwas built using gcc-2.93 with the -O2 option. 6.1 Space Ef.ciency We .rst demonstrate in Figure 6 that \nthe symbolic representation in general, and symbolic invocation graph in particular is ef.cient in space. \nHere, the horizontal axis indicates the number of contexts in the evaluated benchmarks in log scale. \nIt can be observed that some benchmarks may approach half a billion contexts. In the .rst plot, we show \nthe total memory usage with respects to the context count. The total memory usage never exceeds 11MB. \nWe also plot the number of BDD nodes used in the symbolic invocation graph. Compared to the corresponding \ncontext count, which is the number of invocation graph nodes if an explicit invocation graph represen\u00adtation \nis used, the BDD node count is exponentially smaller. 6.2 Runtime Ef.ciency We now demonstrate the runtime \nef.ciency of the proposed sym\u00adbolic analysis algorithms. The detailed results on runtime and mem\u00adory \nstatistics for three types of analysis are given in Table 6.2. Here, the time for the setup pass is referred \nto as the Setup Time.The time it takes the intra-procedural analysis pass to derive all transfer functions \nis referred to as the Intra-Time. The time it takes for the interprocedural analysis pass to reach a \n.xed point is referred to as the Inter-Time. We draw several observations from the runtime result. First, \nthe runtime of our context-insensitive analysis (CI), based on a loose comparison with [23], is comparable \nwith classical methods such as Anderson s algorithm. Second, the runtime of type 1 context\u00adsensitive \nanalysis (CS I) is very close to its context-insensitive coun\u00adterpart. Almost all benchmark takes at \nmost twice as much time to execute. Third, the full-context sensitive analysis (CS II), is at most 6 \ntimes slower than its context-insensitive counterpart. Figure 7 offers more insight on the dependency \nof total analysis time versus context count. Again, the context count is indicated as the horizontal \naxis in log scale. Figure 7 also plots the construction time of symbolic call graph. It is clear that \neven for benchmark with half a billion contexts, the graph can be constructed in a few seconds. prolangs \nMediaBench SPEC2000 name #lines #contexts #blocks name #lines #contexts #blocks name #lines #contexts \n#blocks 315 1411 49 136 gsm 5473 267 1124 bzip2 4665 495 995 TWMC 24032 6522 4613 pegwit 5503 1968 1121 \ngzip 8218 503 905 simulator 3558 8953 1316 pgp 28065 199551 5265 vpr 16984 179905 4318 larn 9933 1750823 \n6180 mpeg2dec 9823 44979 2748 crafty 19478 317378 5282 moria 25002 318675286 9446 mpeg2enc 7605 1955 \n2997 twolf 19756 5538 4231 Time ( s ) 180 160 140 120 100 80  Table 2: Analysis runtime and space usage \nresult. 60  40 Intra Inter Total Memory  20 Benchmarks time time time used (s) (s) (s) (MB)  0 \nCI 0.04 0.03 0.07 1.397  Contexts 315 CS I 0.08 0.08 0.16 1.710 CS II Figure 7: Algorithm runtime \nversus context count. T-W-MC SPEC2000 MediaBench prolangs 100 larn CS II 6.65 88.79 95.44 9.444 90 \n 80 70 60 50 40 % Difference in dereferences  30 CS II 0.90 0.55 1.45 4.238  mpeg2dec CS I 1.92 1.44 \n3.36 7.696  10 20  0 T-W-MC larn moria pgp crafty twolf vpr Figure 8: Precision result. pgp  6.3 \nPrecision Many studies have been performed on the impact of context sen\u00ad sitivity on analysis precision \n[31, 17]. Since this study focuses on CS II CI 4.97 3.25 8.22 5.551 the runtime of symbolic analysis, \nother analysis dimensions, such  crafty as .eld sensitivity, heap naming scheme, which could signi.cantly \naffect the analysis precision, are not included. Our reported results should therefore be taken as a \ncon.rmation that context-sensitivity does help improve analysis precision for some benchmarks rather \nthan basis for a quantitative conclusion. We use the popular metric twolf CS I 10.86 5.77 16.63 7.886 \n of average dereference size, de.ned as the average size of a point-to CS II  CI 5.21 2.50 7.71 5.339 \nset for each memory load or store in the program. The dereference vpr sizes for all three types of \nanalysis are plotted for comparison. As in [17], we normalize the metric to the context-insensitive analysis \nresult. It can be observed that while large improvement can some\u00adtime result with context-sensitive analysis, \nthe difference between the two types of context-sensitive analysis is usually minor. 80 200 120 70 40 \n30 20 10 0 Figure 9: Cache hit rate. 180 Time ( s ) 100 80 60 40 20 0 Figure 11: Time spent on variable \nreordering. 12 Analysis Time ( s ) Hit % 200 180 160 140 120 100 80 60 40 20 0 Figure 10: Time spent \non garbage collection.  6.4 Impact of Caching As discussed earlier, the cache is used to store the results \nof basic BDD operations like AND, OR, and many others. As such, a higher hit rate will translate into \nimproved performance, since a successful cache lookup requires fewer computations. The cache hit rate \nusu\u00adally ranges from 40% to 60%. We also observe a lower cache hit rate in the context-sensitive analysis. \nThis can be explained by the higher memory consumption in context-sensitive analysis, which forces the \nBDD manager to evict nodes out of the cache. It is obvious that the size of cache may impact the cache \nhit rate. Figure 9 shows the cache hit rate of selected large benchmarks un\u00adder different cache size \ncon.gurations. It can be observed that a large cache size in general lead to a higher hit rate. On the \nother hand, up to certain limit, increasing the cache size does not increase the hit rate. 6.5 Impact \nof Lazy Garbage Collection To see how lazy garbage collection can affect analysis speed, we demonstrate \nthe time spent on garbage collection versus other processing time for selected benchmarks under different \nthreshold heap size values. It can be observed that in general a larger heap size will reduce the amount \nof time spent on garbage collection and therefore the overall analysis speed. On the other hand, there \nis almost nothing to gain if the threshold is increased beyond a certain value. 6.6 Impact of Variable \nReordering Variable reordering was attempted in order to see what improve\u00adments might have in terms of \nspace and runtime. Sifting, com- 10 8 Memory (MB) 6 4 2 0 Figure 12: Memory size with/without variable \nreordering. monly regarded as the best reordering algorithm, was used to dy\u00adnamically reorder the BDD \nvariables in the program. However, as can be seen from Figure 11 and Figure 12, the results are rather \nnegative. The analysis takes longer to complete, with most of the time spent on reordering the variables. \nFurthermore, even if we discount the time spent on reordering the variables, only minor im\u00adprovements \nare obtained in terms of runtime. In terms of space ef\u00ad.ciency, no major improvements are obtained with \nfew exceptions. These results seem to show that variable reordering, as is done by the CUDD package, \noffers no improvement over our static variable ordering.  7. RELATED WORK Due to its importance, pointer \nanalysis has been actively inves\u00adtigated for the past two decades. Hind gave an excellent survey on the \nstate-of-the-art in the .eld [20]. According to Hind, over seventy-.ve papers and nine PhD thesis was \npublished on the sub\u00adject by the time [20] was published. In the category of FICI pointer analysis, Steensgaard \ns work [36] stands out as the .rst equality-based method, which treats assign\u00adment as bidirectional and \nuses a union-.nd data structure. His ana\u00adlyzer is extremely fast and has analyzed million lines of industrial \ncode. However, the precision of equality-based approach degrades very fast in general, even with later \nimprovement [40]. Andersen s [3] popular subset-based improves precision by treating assignment as a \nunidirectional .ow of values. However, Andersen s algorithm has a cubic runtime. While there are many \nvariations and improvements of Steensg\u00adgard s and Anderson s algorithm, a major advancement of analysis \nef.ciency attributes to the use of a constraint-based solver [15, 30]. With this formulation, the point-to \ninformation is evaluated lazily instead of modeling the state of a block as the immediate succes\u00adsors \nof the corresponding node in the point-to graph, it is modeled as all nodes reachable from the corresponding \nnode. Point-to in\u00adformation of different blocks can therefore be shared via common path. As a result, \nthe state-of-the-art implementation of this method for FICI analysis can scale to million-line code [19]. \nA de.nition of context-sensitivity has been given in [34]. The most popularly used form of context-sensitivity \nis the concept of call string, de.ned as a path of call sites on the call stack. A new form, called object-sensitivity \nhas been proposed for object oriented programs [28]. Landi et al. [24] .rst performed context\u00adsensitive \npointer analysis by the use of inter-procedural control .ow graph, which can be prohibitively large. \nEmami et al. [14] intro\u00adduced the use of invocation graph, where control .ow graph among different invocations \nof the same procedure can be shared. Wilson and Lam [39] also used invocation graph. In addition, the \nconcept of partial transfer function was proposed in an effort to reduce the number of times a procedure \nhas to be re-analyzed. Chatterjee et al. [10] proposed the use of summary functions to completely cap\u00adture \nthe transfer function of a procedure. A further development with the same strategy was proposed by Cheng \nand Hwu [11], with the addition of using access path originating from parameters and globals as transfer \nfunction parameters. Context-sensitive analysis algorithms suffer from an exponential runtime in general. \nSeveral efforts target towards analysis scala\u00adbility. One direction is to use partial sensitivity. For \nexample, Re\u00adcently Liang and Harrold [27] s analyzer treats globals in a context\u00adinsensitive way and \nis able to analyze industrial programs. Another direction is to exploit the ef.ciency of constraint-based \nsolver, which is extremely successful in context-insensitive analysis. F\u00a8ahndrich et al. reported a polymorphic \n(context-sensitive) analyzer (equiva\u00adlent to CS I) with a cubic runtime [16]. Even though the concept \nof BDD appeared much earlier [2], it was Bryant s ROBDD [6], designed to be compact and canonical, makes \nit successful. It was applied to a wide range of tasks, in\u00adcluding simulation, synthesis and formal veri.cation \nin the CAD community. McMillan et al. [9] and O. Coudert et al. [12] were the .rst to introduce BDD into \nthe model checking of sequential circuits, which can be abstracted as .nite state machines. Their pioneer \nwork replaces the explicit state enumeration by implicit state enumeration using BDDs. This key concept, \ncomplemented by further improvements [7, 13, 8, 29], was responsible for the .rst application of model \nchecking to practical problems. Other efforts in using a Boolean framework for program anal\u00adysis can \nbe found in areas such as shape analysis [33] and pred\u00adicate abstraction [4]. However, the number of \nBoolean variables introduced in these frameworks is proportional to the number of subjects of interest. \nThe application of BDD technique to pointer analysis problem was .rst reported in [41], where memory \nblocks are logarithmically encoded into the Boolean domain. The concept of symbolic transfer function \nand the use of BDD image computa\u00adtion to perform program state query was proposed and its speed ef.ciency \nwas demonstrated. Berndl et al. reported a context\u00adinsensitive pointer analysis algorithm using BDD in \n[5], where the space ef.ciency, and therefore better scalability than the classical methods for analyzing \nJava programs was demonstrated. The inter\u00adest in exploiting BDD for program analysis seems to be growing: \nin the same proceeding Lhot\u00b4ak and Hendren [26] built a relational database abstraction on top of the \nlow-level BDD manipulation to facilitate program analysis. Whaely and Lam [38] reported another method \nfor context-sensitive analysis using BDD. 8. CONCLUSION In this paper, we present a new formalism for \npointer analy\u00adsis. Based on Boolean algebra, this formalism is simple enough to be summarized in three \nrecurrence equations. In addition, it en\u00adables the use of Binary Decision Diagram to achieve both space \nand speed ef.ciency. A common framework is established to perform both context-insensitive and context-sensitive \nanalysis. Based on our study, we conclude that the key concepts proposed in this paper, namely symbolic \ntransfer function and symbolic in\u00advocation graph, can effectively reduce the runtime of the other\u00adwise \nexpensive context-sensitive analysis to one comparable to its context-insensitive counterpart. In the \nfuture, we plan to leverage and extend our symbolic frame\u00adwork for other important issues, including \n.ow sensitivity, distinc\u00adtion of record .elds and array elements, as well as the generaliza\u00adtion of the \nsymbolic framework to other program analysis prob\u00adlems. 9. ACKNOWLEDGMENT We would like to sincerely \nthank the anonymous reviewers for their constructive comments for the draft of this paper. We would also \nlike to thank Dr. Hind for pointing us to the relevant bench\u00admarks in this area. 10. REFERENCES [1] SPEC \nCPU2000 benchmarks. http://www.specbench.org/cpu2000/. [2] S. B. Akers. Binary decision diagrams. IEEE \nTransactions on Computer, C-27(6):509 516, June 1978. [3] O. Andersen. Program Analysis and Specialization \nfor the C Programming Language. PhD thesis, Computer Science Department, University of Copenhagen, 1994. \n[4] T. Ball and T. Millstein. Polymorphic predicate abstraction. Technical Report MSR-TR-2001-10, Microsoft \nResearch, June 24, 2003. [5] M. Berndl, O. Lhot\u00b4ak, F. Qian, L. Hendren, and N. Umanee. Point-to analysis \nusing BDD. In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, \nSan Diego, June 2003. [6] R. E. Bryant. Graph-based algorithms for Boolean function manipulation. IEEE \nTransactions on Computer, C-35(8):677 691, August 1986. [7] J. R. Burch, E. M. Clarke, and D. E. Long. \nSymbolic model checking with partitioned transition relations. In International Conference on Very Large \nScale Integration, Edinburgh, Scotland, 1991. [8] J. R. Burch, E. M. Clarke, D. E. Long, K. L. McMillan, \nand D. L. Dill. Symbolic model checking for sequential circuit veri.cation. IEEE Transactions on Computer-Aided \nDesign of Integrated Circuits and Systems, (13), 1994. [9] J. R. Burch, E. M. Clarke, K. L. McMillan, \nD. L. Dill, and L. J. Hwang. Symbolic model checking: 1020 states and beyond. In Proceedings of the Fifth \nAnnual IEEE Symposium on Logic in Computer Science, Washington, DC, 1990. [10] R. Chatterjee, B. G. \nRyder, and W. A. Landi. Relevant context inference. In Proceedings of Symposium on Principles of Programming \nLanguages, pages 133 146, 1999. [11] B.-C. Cheng and W.-M. W. Hwu. Modular interprocedural pointer analysis \nusing access paths: Design implementation and evaluation. In Proceedings of SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 57 69, Vancouver, British Columbia, Canada, June 2000. [12] \nO. Coudert, C. Berthet, and J. C. Madre. A uni.ed framework for the formal veri.cation of sequential \ncircuits. In Proceedings of the International Conference on Computer-Aided Design, pages 126 129, November \n1990. [13] O. Coudert and J. C. Madre. Symbolic computation of the valid states of a sequential machine: \nAlgorithms and discussion. In ACM Workshop on Formal Methods in VLSI Design, 1991. [14] M. Emami, R. \nGhiya, and L. J. Hendren. Context-sensitive interprocedural points-to analysis in the presence of function \npointers. In Proceedings of SIGPLAN Conference on Programming Language Design and Implementation, pages \n242 256, 1994. [15] M. F\u00a8ahndrich, J. S. Foster, Z. Su, and A. Aiken. Partial online cycle elimination \nin inclusion constraint graphs. ACM SIGPLAN Notices, 33(5):85 96, 1998. [16] M. F\u00a8ahndrich, J. Rehof, \nand M. Das. Scalable context-sensitive .ow analysis using instantiation constraints. In Proceedings of \nthe ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 253 263, Vancouver, \nBritish Columbia, Canada, June 2000. [17] J. S. Foster, M. F\u00a8ahndrich, and A. Aiken. Polymorphic versus \nmonomorphic .ow-insensitive points-to analysis for C. In Proceedings of Static Analysis Symposium, pages \n175 198, June 2000. [18] D. Gajski. Principles of Digital Design. Prentice Hall, 1997. [19] N. Heintze \nand O. Tardieu. Ultra-fast aliasing analysis using CLA: A million lines of C code in a second. In Proceedings \nof SIGPLAN Conference on Programming Language Design and Implementation, pages 254 263, 2001. [20] M. \nHind. Pointer analysis: Haven t we solved this problem yet. In ACM SIGPLAN-SIGSOFT Workshop on Program \nAnalysis for Software Tools and Engineering (PASTE), June 2001. [21] M. Hind, M. Burke, P. Carini, and \nJ.-D. Choi. Interprocedural pointer alias analysis. ACM Transactions on Programming Languages and Systems, \n21(4):848 894, 1999. [22] M. Hind and A. Pioli. Assessing the effects of .ow-sensitivity on pointer alias \nanalyses. In Proceedings of Static Analysis Symposium, pages 57 81, 1998. [23] M. Hind and A. Pioli. \nWhich pointer analysis should I use? In International Symposium on Software Testing and Analysis, pages \n113 123, 2000. [24] W. Landi and B. Ryder. A safe approximate algorithm for inter-procedural pointer \naliasing. In Proceedings of SIGPLAN Conference on Programming Language Design and Implementation, pages \n235 248, June 1992. [25] C. Lee, M. Potkonjak, and W. H. Mangione-Smith. Mediabench: A tool for evaluating \nand synthesizing multimedia and communications systems. In Micro 30, 1997. [26] O. Lhot\u00b4ak and L. Hendren. \nJedd: A BDD-based relational extension of Java. In Proceedings of SIGPLAN Conference on Programming Language \nDesign and Implementation, June 2004. [27] D. Liang and M. J. Harrold. Ef.cient computation of parameterized \npointer information for interprocedural analyses. In Proceedings of Static Analysis Symposium, pages \n279 298, 2001. [28] A. Milanova, A. Rountev, and B. Ryder. Parameterized object-sensitivity for points-to \nand side-effect analysis for Java. In Proceedings of International Symposium on Software Testing and \nAnalysis, pages 1 12, 2000. [29] I.-H. Moon, J. H. Kukula, K. Ravi, and F. Somenzi. To split or to conjoin: \nthe question in image computation. In Design Automation Conference, pages 23 28, 2000. [30] A. Rountev \nand S. Chandra. Off-line variable substitution for scaling points-to analysis. ACM SIGPLAN Notices, 35(5):47 \n56, 2000. [31] E. Ruf. Context-insensitive alias analysis reconsidered. In Proceedings of SIGPLAN Conference \non Programming Language Design and Implementation, pages 13 22, La Jolla, California, June 1995. [32] \nB. Ryder. Prolangs analysis framework. http://www.prolangs.rutgers.edu. [33] M. Sagiv, T. Reps, and R. \nWilhelm. Parametric shape analysis via 3-valued logic. ACM Transactions on Programming Languages and \nSystems, 24(3):217 298, 2002. [34] M. Sharir and A. Pnueli. Two approaches to interprocedural data .ow \nanalysis. In Program Flow Analysis: Theory and Applications, pages 189 234. Prentice Hall, 1981. [35] \nF. Somenzi. CUDD: Binary decision diagram package release. http://vlsi.Colorado.EDU/ fabio/ CUDD/cuddIntro.html, \n1998. [36] B. Steensgaard. Points-to analysis in almost linear time. In Proceedings of Symposium on Principles \nof Programming Languages, pages 32 41, 1996. [37] R. Tarjan. Depth .rst search and linear graph algorithms. \nSIAM Journal of Computing, 1(2):146 160, 1972. [38] J. Whaley and M. Lam. Cloning-based context-sensitive \npointer alias analysis using binary decision diagrams. In Proceedings of SIGPLAN Conference on Programming \nLanguage Design and Implementation, June 2004. [39] R. Wilson and M. Lam. Ef.cient context-sensitive \npointer analysis for C programs. In Proceedings of the ACM SIGPLAN Conference on Programming Language \nDesign and Implementation, pages 1 12, June 1995. [40] S. Zhang, B. G. Ryder, and W. Landi. Program decomposition \nfor pointer aliasing: A step toward practical analyses. In Foundations of Software Engineering, pages \n81 92, 1996. [41] J. Zhu. Symbolic pointer analysis. In Proceedings of the International Conference in \nComputer Aided Design,San Jose, November 2002. APPENDIX A. SOLUTION PROCESS ILLUSTRATION Here we show \nthe complete .xed-point iteration process of Ex\u00adample 1 for solving recurrence equations (1), (2) (3) \nfor context\u00adinsensitive analysis; and recurrence equations (5), (6), (7) for context\u00adsensitive analysis. \nFor the economy of space, those values that are unchanged during the iterations are listed separately \nin the row marked as Unchanged values . For fast convergence, the pro\u00adcedure states are evaluated in \na bottom-up fashion along the call graph. For presentation clarity, the augmented transfer functions \nare not used. In addition the pruning process is applied for both analysis and therefore formal parameter \nstates are not propagated to callers. * * 1 T getg ** C(1) = {2} E(0, 2)=W0 W0 B(0, 2, 0)=3 T ==r.1 \n+e1 * e2 +tg * C(2) = o E(1, 2)=W0 W1 B(1, 2, 0)=5 2 alloc * T = T =f.0 +e0 * m Iteration Context-insensitive \nContext-sensitive Initial values S0 = S1 =S2 =g * a +t * g 80 = 81 =0 82 = query(S1 , (t, 2))=a S0 80 \n82 = S1 =S2 =g * a +t * g = 81 =0 = query(S1 , (t, 2))=a Unchanged values 83 = query(S0 , (p, 0))=p 84 \n= query(S0 , (q, 0))=q 85 = query(S1 , (t, 1))=g A0 = 8B(0,2,0) +8B(1,2,0) =p +g A1 = 8B(0,1,1) =q 83 \n84 85 A0 A1 = query(S0 , (p, 0))=p = query(S0 , (q, 0))=q = query(S1 , (t, 1))=g = W0p +W1g = W0q 1 S2 \n= g * a +t * g +f * p +f * g S1 = g * a +t * g +r * q S0 = g * a +t * g 80 = p +g 81 = q 82 = a S2 S1 \nS0 80 81 82 = = = = = = g * a +t * g +W0f * p +W1f * g g * a +t * g +W0r * q g * a +t * g W0p +W1g W0q \na 2 S2 = g * a +t * g +f * p +f * g + p * m +g * m S1 = g * a +t * g +r * q + p * m +g * m +q * a S0 \n= g * a +t * g + p * m +g * m +q * a 80 = p +g 81 = q 82 = a +m S2 S1 S0 80 81 82 = + = + = + = = = g \n* a +t * g +W0f * p +W1f * g W0p * m +W1g * m g * a +t * g +W0r * q W0g * m +W0q * a g * a +t * g W0p \n* m +W0g * m +W0q * a W0p +W1g W0q a +W0m 3 S2 = g * a +t * g +f * p +f * g + p * m +g * m +q * a S1 \n= g * a +t * g +r * q + p * m +g * m +q * a +q * m S0 = g * a +t * g + p * m +g * m +q * a +q * m 80 \n= W0p +W1g 81 = W0q 82 = a +W0m S2 S1 S0 80 81 82 = + = + = + = = = g * a +t * g +W0f * p +W1f * g W0p \n* m +W1g * m +W1q * a g * a +t * g +W0r * q +W0g * m W0q * a +W0q * m g * a +t * g +W0p * m +W0g * m \nW0q * a +W0q * m W0p +W1g W0q a +W0m S2 = g * a +t * g +f * p +f * g + p * m +g * m +q * a +q * m S1 \n= g * a +t * g +r * q * * * * S2 S1 = + + = g * a +t * g +W0f * p +W1f * g W0p * m +W1g * m +W1q * a \nW1q * m g * a +t * g +W0r * q +W0g * m 4 + p m +g m +q a +q m S0 = g * a +t * g + p * m +g * m +q * a \n+q * m S0 + = W0q * a +W0q * m g * a +t * g +W0p * m +W0g * m * * 80 = p +g 81 = q 82 = a +m 80 81 82 \n+ = = = W0q a +W0q m W0p +W1g W0q a +W0m  \n\t\t\t", "proc_id": "996841", "abstract": "Pointer analysis is a critical problem in optimizing compiler, parallelizing compiler, software engineering and most recently, hardware synthesis. While recent efforts have suggested symbolic method, which uses Bryant's Binary Decision Diagram as an alternative to capture the point-to relation, no speed advantage has been demonstrated for context-insensitive analysis, and results for context-sensitive analysis are only preliminary.In this paper, we refine the concept of symbolic transfer function proposed earlier and establish a common framework for both context-insensitive and context-sensitive pointer analysis. With this framework, our transfer function of a procedure can abstract away the impact of its callers and callees, and represent its point-to information completely, compactly and canonically. In addition, we propose a symbolic representation of the invocation graph, which can otherwise be exponentially large. In contrast to the classical frameworks where context-sensitive point-to information of a procedure has to be obtained by the application of its transfer function exponentially many times, our method can obtain point-to information of all contexts in a single application. Our experimental evaluation on a wide range of C benchmarks indicates that our context-sensitive pointer analysis can be made almost as fast as its context-insensitive counterpart.", "authors": [{"name": "Jianwen Zhu", "author_profile_id": "81100415574", "affiliation": "University of Toronto, ON, Canada", "person_id": "PP39041749", "email_address": "", "orcid_id": ""}, {"name": "Silvian Calman", "author_profile_id": "81100434870", "affiliation": "University of Toronto, ON, Canada", "person_id": "P677805", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/996841.996860", "year": "2004", "article_id": "996860", "conference": "PLDI", "title": "Symbolic pointer analysis revisited", "url": "http://dl.acm.org/citation.cfm?id=996860"}