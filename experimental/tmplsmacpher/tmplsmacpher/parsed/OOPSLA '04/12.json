{"article_publication_date": "10-01-2004", "fulltext": "\n Transparent Proxies for Java Futures Polyvios Pratikakis Jaime Spacco Michael Hicks polyvios@cs.umd.edu \njspacco@cs.umd.edu mwh@cs.umd.edu Department of Computer Science University of Maryland College Park, \nMD 20742 ABSTRACT A proxy object is a surrogate or placeholder that controls access to another target \nobject. Proxies can be used to sup\u00adport distributed programming, lazy or parallel evaluation, access \ncontrol, and other simple forms of behavioral re.ec\u00adtion. However, wrapper proxies (like futures or suspensions \nfor yet-to-be-computed results) can require signi.cant code changes to be used in statically-typed languages, \nwhile prox\u00adies more generally can inadvertently violate assumptions of transparency, resulting in subtle \nbugs. To solve these problems, we have designed and imple\u00admented a simple framework for proxy programming \nthat employs a static analysis based on quali.er inference, but with additional novelties. Code for using \nwrapper proxies is automatically introduced via a class.le-to-class.le trans\u00adformation, and potential \nviolations of transparency are sig\u00adnaled to the programmer. We have formalized our analysis and proven \nit sound. Our framework has a variety of appli\u00adcations, including support for asynchronous method calls \nre\u00adturning futures. Experimental results demonstrate the bene\u00ad.ts of our framework: programmers are relieved \nof managing and/or checking proxy usage, analysis times are reasonably fast, overheads introduced by \nadded dynamic checks are neg\u00adligible, and performance improvements can be signi.cant. For example, changing \ntwo lines in a simple RMI-based peer\u00adto-peer application and then using our framework resulted in a large \nperformance gain. Categories and Subject Descriptors D.3.3 [Programming Languages]: Language Constructs \nand Features Frameworks,Concurrent programming struc\u00adtures,Control structures; D.2.3 [Software Engineering]: \nCoding Tools and Techniques Object-oriented Programming General Terms Languages, Experimentation, Reliability, \nTheory Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA \nO4 Oct. 24-28, 2004, Vancouver, British Columbia, Canada. Copyright 2004 ACM 1-58113-831-8/04/0010 ...$5.00. \n Keywords Java, future, proxy, type inference, type quali.er 1. INTRODUCTION A proxy object is a surrogate \nor placeholder that con\u00adtrols access to another object. One example of a proxy is a future, popularized \nin MultiLisp [23]. In MultiLisp, the syntax (future e) designates that expression e should be evaluated \nconcurrently. A future for it is returned, and some time later the program claims the future, possibly \nblocking until the result of evaluating e is available. For example, in the following code, the two lists \nx and y are sorted in paral\u00adlel, the former in a new thread, and the latter in the parent thread: (merge \n(future (mergesort x)) (mergesort y)) The results of both mergesort computations are passed to the merge \nroutine; the .rst argument will be a future while the second argument will be a sorted list. In MultiLisp, \nclaims are performed transparently by the interpreter. In our example, this allows the programmer to \nwrite merge as if it takes two sorted lists as arguments, and the interpreter will perform claims as \nnecessary. In general, the programmer simply inserts future annotations in the program and the runtime \ntransparently takes care of the rest.1 This makes the use of futures simple and lightweight. A future \nis an example of a wrapper proxy in that it wraps the actual result; whenever the actual result is needed, \nthe future must be unwrapped to retrieve it. Other examples of wrapper proxies include suspensions, which \nare wrappers for lazy computations, and capabilities, which are wrappers for controlled resources. We \nwould like to support wrapper proxies in Java with the same kind of transparency a.orded by MultiLisp. \nTo add futures, we would provide asynchronous method calls to return a future for a non-void result. \nExisting proposals to do this [28, 24, 35] fall short of our goal because they make futures manifest \nto the programmer. For example, Java 1.5 s util.concurrent library [24] de.nes a future with the following \nJava interface: public interface Future<V >{ V get(); V get(long timeout, TimeUnit unit); ... } Introducing \nutil.concurrent futures into a Java program thus imposes two programming tasks. First, whenever a Future<V \n> value could be passed to a function, the func\u00adtion s type must be changed. In our example, we would \nhave 1There is the possible need for added synchronization due to side-e.ects in futurized computations. \nto change the type of merge to take a Future<List> as its .rst argument (or Object if merge could also \nbe called with normal List objects). Second, all futures must be claimed manually by call\u00ading get. For \nexample, the merge function would claim the Future<List> to store its values in the merged list. We might \nalso claim a future o to avoid revealing its identity, e.g., in the expression o==o . . Not doing so \ncould lead to sub\u00adtle bugs which we call transparency violations. For example, when o is the future wrapping \no ', then o==o . would be false, which could result in unexpected behavior, such as storing a future \nand its value in the same container. Changing types and adding claims can require considerable programming \nef\u00adfort, whether to add futures or to later remove them. To solve these problems, we have developed a \nframework for proxy programming. At the core of the framework is a static analysis that tracks how a \nproxy might .ow through the program, coupled with a transformation to implement proxy manipulations at \nruntime. To customize the frame\u00adwork, a programmer speci.es the syntactic points where a proxy is introduced \n(e.g., by specifying a method call is asyn\u00adchronous), and the expression forms that require a claim (e.g., \nwhen a proxy is an argument to ==). The programmer also provides the code that implements the claim. \nWe have used our framework for a variety of applications: We have implemented support for transparent \nfutures. The programmer indicates when a method call should be asynchronous, and speci.es a thread manager \nfor handling the call. Thread managers include global thread pools, per-object thread pools, and others. \nPro\u00adgrammers can also in.uence where futures are claimed. In essence, the framework drastically simpli.es \npro\u00adgramming with Futures in util.concurrent, which is timely given the recent release of Java 1.5. \n We have implemented support for transparent suspen\u00adsions. The programmer annotates when a method call \nshould be performed lazily, and the call is delayed until its suspension is claimed.  We have implemented \nan analysis to discover possible transparency violations due to the introduction of in\u00adterface proxies \nin large programs. An interface proxy shares an interface with its target object, as speci.ed by the \nproxy design pattern [18]. As with wrapper proxies, incorrect usage of these proxies could result in \ntransparency violations.  Our static analysis is based on quali.er inference [15], but improves on it \nin two ways. First, we support dynamic co\u00adercions, needed to claim futures and other wrapper proxies. \nSecond, we use a simple form of .ow-sensitivity to avoid claiming the same expression more than once. \nWhile our framework was developed for proxy programming, these ad\u00advances apply to quali.er systems in \ngeneral. As described in Section 3.8, they enable a number of new or improved applications, including \ntracking security-sensitive data in a program [37], and supporting stack allocation and non-null types \n[13]. 1.1 Contributions This paper describes the design, theory, implementation, and evaluation of a \nframework for proxy programming. We make the following contributions: We formalize the problem of transparent \nproxy pro\u00adgramming as one of quali.er inference, extending ex\u00adisting algorithms to support dynamic coercions \nand a form of .ow-sensitivity. We have formalized our anal\u00adysis as an extension of Featherweight Java \n(FJ) [21], and proven it sound (Section 3). We are the .rst to consider quali.er inference in an object-oriented \nset\u00adting, and our approach enables new or improved ap\u00adplications of quali.er systems (Section 3.8). \n We present the design and implementation of three applications of our framework (described above): pro\u00adgramming \nwith transparent futures and suspensions (Section 4), and discovering transparency violations (Section \n5.4).  We evaluate the framework s performance on our three applications (Section 5). Analysis times \nare compara\u00adble to those of similar static analyses, and overheads due to inserted claims are negligible. \nSection 5.3 de\u00adscribes how we pro.tably used futures and suspen\u00adsions together in an RMI-based peer-to-peer \napplica\u00adtion: changing two lines resulted in a large perfor\u00admance gain. Section 5.4 describes how our \ntranspar\u00adency analysis discovered a number of potential trans\u00adparency violations arising from the introduction \nof in\u00adterface proxies in large programs.   2. OVERVIEW In this section, we present an overview of our \nframework, including the API seen by the user, and the basic .avor of our static analysis. 2.1 User API \nAs inputs, our framework takes application and library class.les to analyze, and a proxy policy and implementation \nspeci.cation (a pspec and ispec, respectively). As outputs, the framework produces modi.ed application \nand library class.les which form the new application. The pspec and ispec allow the user to customize \nthe framework to support di.erent kinds of proxies. In particular, the pspec de.nes syntactic patterns \nin the program that indicate where prox\u00adies should be introduced and coerced, while the ispec indi\u00adcates \nhow proxy introduction and coercion are implemented at runtime. The framework itself consists of two \nparts: a static anal\u00adysis (which uses the pspec) and a program transformation (which uses the ispec). \nThe static analysis discovers where proxies are introduced in the program and then tracks their .ow. \nThe analysis observes when a proxy could .ow to a location requiring a non-proxy, thus requiring a coercion \nto convert the proxy to a non-proxy. Based on the results of static analysis, the program transformation \ngenerates a modi.ed program. In particular, the code at each proxy in\u00adtroduction site is modi.ed to actually \ncreate the proxy at runtime, and code is inserted at each coercion site to imple\u00adment the proxy-to-non-proxy \ncoercion. As an example, consider how we implement asynchronous method calls in Java using this API (more \ndetails are in Section 4). The proxy pspec and ispec are as follows: Policy Spec Proxies are introduced \nby method calls marked by the user as being asynchronous. All expressions that are identity-revealing, \ne.g., dynamic downcasts or subexpressions of instanceof, must operate on non\u00adproxies (thus necessitating \na possible coercion). More\u00adover, any concrete usage of an object, such as invoca\u00adtions of its methods \nor extractions of its .elds, requires that it be a non-proxy. Implementation Spec Calls marked as asynchronous \nare replaced by code that (1) executes the original call in a separate thread, and (2) returns a Future \nas a placeholder for the eventual result. Coercing a possible future requires checking that it is indeed \na Future (the analysis may have been imprecise), and if so, calling its get method to extract the underlying \nobject. This may entail waiting until the result is available. Lazy method calls are supported similarly, \nand other appli\u00adcations are described in Section 3.8 and 5.4. Further imple\u00admentation details are presented \nin Section 4.1. Our goal is for the framework to be used during normal software development: the programmer \ndevelops the anno\u00adtated .les, and the framework generates the .nal bytecode. Alternatively, the framework \ncould be used to add needed features to a Java program; the annotated .les would simply direct the transformation, \nand development would proceed with the modi.ed .les. This would allow programmers to manually optimize \nthe compiled code, but would eliminate the bene.ts of the lighter-weight, speci.cation-based use of proxies \nduring development. We now turn to an overview of our analysis. 2.2 Proxies as Quali.ers Conceptually, \nwhether or not a particular program vari\u00adable refers to a proxy is independent of that variable s type. \nAs such, we can think about proxies using type quali.ers, which re.ne the meaning of a particular type. \nA quali.ed type is written Qt , where Q is a quali.er and t is a type. A familiar use of a type quali.er \nis .nal: a variable with this quali.er must be immutable, whatever the variable s actual type may be. \nProxies can be annotated in the same way. A variable with quali.er nonproxy is de.nitely not a proxy, \nwhile one with quali.er proxy may or may not be a proxy. Quali.ed types admit a natural subtyping relationship. \nIn particular, nonproxy t = proxy t . That is, a t object that is de.nitely not a proxy can be used where \na t that may or may not be a proxy is expected. The problem solved by our framework is akin to quali.er \ninference [15]. When using quali.er inference, the program\u00admer annotates expressions that introduce values \nwith a par\u00adticular quali.ed type. The inference algorithm determines how these values .ow through the \nprogram to ensure they are used correctly. Existing quali.er inference systems are not su.cient to model \nwrapper proxies like futures because they treat quali.ers as having no runtime e.ect. Creating a future \nrequires spawning a thread and creating a placeholder for its result. Moreover, using a wrapper proxy \nin a context expecting a nonproxy should not signal an error, but rather should induce a runtime claim \nto acquire the underlying result. Our analysis augments quali.er inference to support coer\u00adcions. In \nparticular, our formal target language (Section 3) includes an expression form coerce e, whose type is \nthe same as that of e but has quali.er nonproxy. During quali.er inference, expression forms in the user \ns pspec drive where coercions are inserted. At runtime, the coercions are imple\u00admented following the \nuser s ispec. For example, for a possible wrapper proxy e, a dynamic coercion is inserted to convert \ne.m() to be (coerce e).m(). At runtime, this coercion is implemented by checking whether e is indeed \na proxy, and if so extracting its underlying object to call method m. As an optimization, if e is a local \nvariable x, then x is treated .ow-sensitively by the analysis: the type of x following a coercion will \nhave quali.er nonproxy. To justify this .ow\u00adsensitivity, code for a coercion logically assigns the coerced \nvalue back to source variable x. We can easily generalize our support for .ow-sensitive co\u00adercions to \napply it to traditional quali.er systems. This leads to new or improved applications, as described in \nSec\u00adtion 3.8.  3. FORMAL DEVELOPMENT This section describes our analysis formally and proves it sound. \nWe model the analysis as an extension to Feather\u00adweight Java (FJ) [21], a purely-functional object calculus. \nWe de.ne an implicitly-typed calculus, which we call FJi Q, and an explicitly-typed calculus, called \nFJQ. Source pro\u00adgrams are written in FJi Q, and these are translated into pro\u00adgrams in FJQ, making manifest \noperations for manipulating proxies. This translation occurs in two stages, inference and transformation, \nformalized as follows: The judgment G hi e : T ;G. de.nes proxy inference for an expression e in the \nlanguage FJi A deriva- Q. tion induces two sets of subtyping constraints F and C. The F constraints \ncapture how proxies .ow through the program, and the C constraints indicate where co\u00adercions could be \ninserted. The judgment states that, assuming the generated constraints have a solution, expression e \nhas type T in context G. Flow-sensitivity is modeled with output context G', which has the same domain \nas G, but for which some variables may have nonproxy quali.ers rather than proxy quali.ers, as a re\u00adsult \nof evaluating expression e.Constraints are solved using standard techniques. The judgment T [ e] . e \nde.nes the transformation of the original implicitly-typed FJi  Q program into an explicitly-typed program \nin the language FJQ. The T [ \u00b7] function uses the solutions to the constraints to add coercions where \nneeded, and to .ll in needed qual\u00adi.er and type annotations. The resulting FJQ ex\u00adpression e can be typechecked \nin an explicitly-typed system, described by the judgment G . e : T ;G. . We can show that our system \nis sound: those FJi Q programs for which inference is successful will always type-check, which in turn \nimplies that they will not go wrong during execution. We establish this result by de.ning an operational \nsemantics for FJQ and prov\u00ading standard type soundness and inference soundness theorems. We present the \nsyntax of the implicitly-typed language FJi Q, de.ne the process of inference and transformation de\u00adscribed \nabove, and conclude with the relevant soundness the\u00adorems. Additional details can be found in the Appendix. \n3.1 Syntax The syntax of the implicitly-typed calculus FJi Q is shown in Figure 1. Expressions e consist \nof a raw expression Terms: \u00af\u00af\u00af CL ::= class C extends C { Tf; KM }\u00af\u00af\u00af K ::= C(T\u00aff) { super(f\u00af); this.f \n= f; } M ::= Tm(T\u00afx\u00af) { return e; } E ::= x | e.f | e.m(\u00afe) | new C(\u00afe) | (C)e | let x = e in e | makeproxy \ne | if e = e then e else e e ::= El Types: C, D, E class names Q ::= proxy | nonproxy | . . ::= {C1,...Cn}| \na N ::= .C S, T, U ::= QN Figure 1: Syntax of FJi Q E and a unique label l, used to designate where \ncoercions should be inserted following inference. There is no explicit coercion expression; these are \nonly present in the target lan\u00adguage FJQ. As in FJ, programs consist of a class table CT , which maps \nclass names to class de.nitions CL. Each class de.ni\u00ad\u00af\u00af tion de.nes a list of .elds Tf, a constructor \nK, and a list \u00af of methods M. Constructors K merely assign their argu\u00adments to .elds, either directly \nor by invoking the superclass constructor. Method bodies consist of a single expression e. \u00af\u00af We write \nx\u00afas shorthand for x1,...,xn (similarly for C,f , \u00af etc.) and write M for M1 ...Mn (no commas). We ab\u00adbreviate \noperations on pairs of sequences similarly, writing \u00af\u00af\u00af Tf for T1 f1,...,Tn fn, where n is the length \nof T and \u00af f. Sequences of .eld declarations, parameter names, and method declarations are assumed to \ncontain no duplicate names. Note that this is not syntactically di.erent than any other variable, but \nwe typeset it in bold for emphasis, and similarly for Object. Most expressions e are as in FJ, including \n.eld access e.f, method invocation e.m(\u00afe), object creation new C(\u00afe), and cast (C)e. We also have support \nfor local variables (lets) and if then else expressions to illustrate e.ects of .ow sensitivity, described \nbelow. Programmers use the ex\u00adpression makeproxy e to designate or create a proxy. Our formalism treats \nproxies generically, ignoring how particu\u00adlar proxies might be implemented. In particular, the opera\u00adtional \nsemantics merely tags the result of evaluating e as being a possible proxy. Types T consist of a quali.er \nQ and a set type N. Set types are a set . of class names {C1,...,Cn} coupled with a upper bound C which \nmust be a supertype of all the Ci. Set types are a technical device to allow inference to be more precise; \nwe do not expect programmers to use them directly. In essence, the set type s upper bound is what one \nwould write in a normal Java program, and the set provides a more precise re.nement (which will be determined \nby inference). For example, say we have de.ned classes A, B, and C, where B and C are subclasses of A. \nIf some variable x could be assigned objects of either class B or C, in a normal Java program we would \ngive x type A. Q, we can give x In FJi type {B, C}A, indicating that x will only ever be assigned objects \nof classes B and/or C, but not objects of type A. SubRef C = C C = DD = E SubTrans C = E CT (C)= class \nC extends D { ... ; ... } SubDef C = D {C1,...Cn}.{D1,...Dn}C0 = D0 Di = D0 Ci = C0 for all i> 0 SubN \n{C1,...Cn}C0 ={D1,...Dn}D0 SubQConst nonproxy = proxy Q = Q. N = N. SubTyp QN = Q. N. Figure 2: FJQ and \nFJi Q: Subtyping Note that checked casts refer to class names C, rather than types T no quali.er is necessary \nbecause it is assumed to be nonproxy, and no set type is necessary as the inference system will infer \nit. Proxy inference takes a normal Java program and infers the necessary quali.ers, set-types, and coercions. \nWe model this in FJi Q by extending quali.ers Q with variables ., and sets of class names . with variables \na. These stand for as\u00adyet-unknown quali.ers and sets of class names, which will be solved for during \ninference. In the simplest case, we could automatically decorate a normal Java program with fresh variables \nbefore performing inference. For example, a Java variable declaration C x would be rewritten to be .aC \nx, for fresh . and a. In fact, the inference rules require explicit types to have this form. In our implementation, \nwe allow users to decorate Java types with quali.ers manually, to implement coercion policies. For example, \nif a user wished to ensure that no proxies are stored in the Set class, she could decorate all relevant \nSet methods to require that input arguments have quali.er nonproxy. As with FJ, FJi does not support \nmutation (although Q the .ow-sensitivity of coercions updates local variables types implicitly): all \nobjects are purely functional. This avoids unnecessary complication in the formalism, though our im\u00adplementation \nhandles the full Java language. Further dis\u00adcussion can be found in Section 3.7.  3.2 Subtyping Rules \nfor subtyping are shown in Figure 2. These are FJ s subtyping rules extended to consider set types N \nand quali.ed types T . The (SubN) rule indicates that a set type N is a subtype of M if N s bound is \na subtype of M s, and if N s set is a subset of M s. We include a well-formedness condition here for \nconvenience, stating that all of the types in N s set must be subtypes of N s bound. Subtyping be\u00adtween \nquali.ed types using the (SubTyp) rule is natural. For example, if B and C are subclasses of A, given \nthat nonproxy = proxy then nonproxy {B}B = proxy {B, C}A . That is, an object that is de.nitely not a \nproxy of class B can be used where a possible proxy of either class B or C, both subtypes of A, is expected. \nFields-Object .elds(Object)= \u00b7 CT (C)= class C extends D { Tf; KM } \u00af\u00af\u00af.elds(D)= Ug\u00af \u00af Fields-C \u00af.elds(C)= \nTf .elds(C)= U\u00af\u00afT \u00af g, f \u00af\u00af Fields-N \u00af\u00afCT (C)= class C extends D { Tf; KM } .elds(.C )= Tf \u00af\u00af\u00afUm(T\u00afx\u00af) \n{ return e; }. M\u00af MType-C \u00afCT (C)= class C extends D { Tf; KM } mtype(m, C)= T . U \u00af\u00af\u00afm not de.ned in \nM\u00af MType-CSub mtype(m, C)= mtype(m, D) mtype(m, Ci)= Ti . Ui for all i \u00af MType-N \u00af\u00afCT (C)= class C extends \nD { Tf; KM } mtype(m, {C1,...Cn}C0 )= T1 . U1,... Tn . Un \u00af\u00af\u00afUm(T\u00afx\u00af) { return e; }. M\u00af MBody-C mbody(m, \nC) = (\u00afx, e) CT (C)= class C extends D { Tf\u00af; KM } \u00af\u00afm not de.ned in M\u00af MBody-CSub mbody(m, C)= mbody(m, \nD) D1 D0 mtype(m, D)=(.1 .,...,.n .Dn ) . .0 . n 10 C1 C0 \u00af T . U =(.n+2 .,...,.2n+1 .Cn ) . .n+1 . \n n+22n+1n+1 C\u00af= DC0 = D0 \u00af Override override(m, D, T\u00af. U) \u00af for each Ci = C where mtype(m, Ci)= Ti . \nQi .D i Ci . . . (S\u00af= Ti &#38; Qi .D = .aD) \u00af i ., a fresh Call \u00af call(m, .C ,S)= .aC Figure 3: FJQ and \nFJi Q: Auxiliary De.nitions  3.3 Inference Inference is expressed as the judgment hi CL for class de.nitions, \nhi M for method de.nitions, and G hi e : T ;G' for expressions. The rules are in Figures 4 and 5. The \njudg\u00adment G hi e : T ;G' indicates that in context G, expression e has type T and output context G' . \nThe rules specify that a nonproxy is required by appealing to the coercion judgment G hc e : T ;G' (notice \nthe sub\u00adscript c on hc rather than i). For example, the (I-Field) rule, which checks an expression (e.fi)l, \nindicates that the receiver e must be a nonproxy by including the requirement G hc e : nonproxy N;G' \nin the premise. In our implementa\u00adtion, those expressions that require nonproxy are determined by the \nuser s pspec. For simplicity, the rules presented in Fig\u00adure 4 are specialized for the case of wrapper \nproxies. In this case, a nonproxy type implies that operations must occur on the underlying object, rather \nthan on a wrapper proxy. The coercion judgment is used to note the labels of ex\u00adpressions that may need \nan inserted coercion. It has two forms. The (I-CoerceExp) rule creates an implication con\u00adstraint that \nif the quali.er of the given expression e is not I-Var l G[x . T ] fi x: T ; G[x . T ] G fi e1 : T ;G1 \nG1[x . T ] fi e2 : T ' ;G' [x . T '' ] I-Let G fi (let x = e1 in e2)l : T ' ;G' G fc e1 : nonproxy N1;G1 \nG1 fc e2 : nonproxy N2;G2 G2 fi e3 : Q3 .C ;G3 G3 fi e4 : Q4 .D;G4 34 T ' = .aE Q3 .C = T ' Q4 .D = \nT ' 34 E = lub(C, D)G' = merge(G3, G4) I-If G fi (if e1 = e2 then e3 else e4)l : T ' ;G' G fc e : nonproxy \nN;G' .elds(N)= Tf \u00af\u00af I-Field G fi (e.fi)l : Ti;G' G fc e0 : nonproxy .C ;G' G' fi e\u00af: S\u00af; G'' call(m, \n.C ,S)= .aC \u00af I-Invoke G fi (e0.m(\u00afe))l : .aC ;G'' \u00af\u00af\u00af\u00af\u00af .elds({C}C )= Tf G fi e\u00af: S;G' S = T I-New G \nfi (new C(\u00afe))l : nonproxy {C}C ;G' G fc e : nonproxy .D;G' a = subtypes(C) n .a fresh I-Cast G fi ((C)e)l \n: nonproxy aC ;G' G fc e : nonproxy N;G' I-MakeProxy G fi (makeproxy e)l : proxy N;G' G fi El0 : QN;G' \nE = xl fresh proxy = Q . l . L I-CoerceExp G fc El : nonproxy N;G' G fi xl0 : QN;G l fresh G=G' [x . \nQN] proxy = Q . l . L I-CoerceVar G fc xl : nonproxy N;G' [x . nonproxy N] Figure 4: FJi Q: Inference \nfor Expressions \u00af CT (C)= class C extends D { ... ; ... } override(m, D, T\u00af. S) S = .aC T C1 ,....n aCn \n x\u00af: T, this : nonproxy {C}C fi e : U;G' U = S \u00af = .1 a1 n ., .i, a, ai fresh I-Method fi Sm(T\u00afx\u00af) { \nreturn e; } K = C(\u00af\u00af\u00af\u00afg); this.f f\u00af; } T g, S f) { super(\u00af\u00af= C1 .elds(D)= T\u00afg\u00afT\u00af,....n aCn = .1 a1 n \n' C1 S\u00af= .' a,....' a' nCn .i,.',ai,a'fresh 11 n ii fi M \u00af I-Class \u00af\u00af\u00af fi class C extends D { Tf; KM \n} Figure 5: FJi Q: Inference for Classes and Methods nonproxy, then a fresh label l for e is included \nin a set L. (The fact that this label is fresh simpli.es the proof, but is not otherwise important.) \nThis set is used during the trans\u00adformation to determine where coercions must be inserted. The output \ntype of this judgment always has a nonproxy quali.er; this will be justi.ed by inserting coercions during \ntransformation. The (I-CoerceVar) rule is similar, except that the variable x in the input context is \nre-bound in the output context to its coerced type. This .ow-sensitive treat\u00adment allows the continuation \navoid coercing a variable that has already been coerced. Most inference rules thread the output context \nof one subexpression to the input context of another. When typing \u00af G h e\u00af: T ;G ' , the output context \nGi from typing expression ei is used as the input context when typing ei+1. Here are highlights of the \nother interesting rules: In the (I-Let) rule, the output context G1 of the bind\u00ading expression e1 is \nextended with the binding x . T when used as the input context of the body e2. When typechecking of the \nbody is completed, the x binding is removed from output context G ' .  In the (I-If) rule, the output \ncontext is a merging of the output context of each of the branches of the if. In particular, the function \nmerge(G1, G2) is the context G ' such that for each x in dom(G1) n dom(G2), G ' (x)= T where G1(x) = \nT and G2(x) = T . The result type is T ' , which is a supertype of the types of each of the if branches, \nbounded by the least of upper bound of their bounds.  The (I-Invoke) rule creates subtyping constraints \nbe\u00ad\u00af  tween the arguments S and all methods that are pos\u00adsible receivers of the call using the auxiliary \nfunction \u00af call(m, .C ,S) (this and other auxiliary functions are shown in Figure 3). This is done using \nimplication constraints: for all possible subtypes of C, only those that appear in . are constrained. \nThis allows overrid\u00ading methods to have arguments with di.erent quali.ers than the methods they are overriding, \nimproving the precision of the analysis. For example, the argument o to class A s method m might by a \nnonproxy, while the argument to its subclass B s overriding method m could be a proxy. This is sound \nbecause all calling contexts of m are considered. The (I-Cast) rule requires that the resulting set-type \na contains those names in e s set-type ., limited to those that are also subtypes of the bound C. The \npredicate subtypes(C) is the set of all subtypes of C de.ned in the class table CT . There are three \npossible outcomes. First, if C is a subtype of D, then . may contain classes B such that C = B. These \nwill be pruned from the solution, since this is a downcast. Second, if C is a supertype of D, then the \nintersection will be ., since all the class names in ., which are bounded by D, are also bounded by C. \nFinally, if neither situation holds, which is to say that C and D are unrelated, then the intersection \nwill be empty, signaling that we have a type error.  The (I-MakeProxy) rule requires that e be a nonproxy \nin makeproxy e. This prevents proxies of proxies. While not technically necessary, it simpli.es our im\u00adplementation \nof coercions. For example, for a wrapper proxy, the underlying object can always be extracted directly; \notherwise a coercion would have to iterate until it reached a non-wrapper.  F.{Q.C = Q ' . 'D}= F.{Q \n= Q ' }.{. . . ' }. {. . subtypes(C)}.{. ' . subtypes(D)}. {C = D} \u00af F .{{D}. a}.{D . aC . (S\u00af= Ti &#38; \nQi .C = .aC )}= i F .{{D}. a}.{ S\u00af= Ti}.{Qi .C = .aC } \u00af i F.{a . (subtypes(C) n .)}= F.{a . subtypes(C)}.{a \n. .} F .{{D}. a}.{a . .}= F .{{D}. a}.{a . .} . {{D}. .} F .{{D}. .}.{(subtypes(C) n .) . a}= F .{{D}. \n.}.{(subtypes(C) n .) . a} . {{D}. a} if D = C Figure 6: Subtype Constraint Reduction In the standard \nparlance, our inference system is monomor\u00adphic: it is .eld-insensitive and context-insensitive. Context\u00adand \n.eld-sensitivity could be supported by adding class and method parameterization, as with Generic Java \n(GJ) [6].  3.4 Constraint Solving Proxy inference generates constraints on the .ow of prox\u00adies of the \nfollowing forms (listed with the rules that generate them): T = U (I-If), (I-New) a = subtypes(C) n . \n(I-Cast) \u00af Ci . . . (S\u00af= Ti &#38; Qi .Ci = .aC ) (I-Invoke) Note that we represent the equality constraint \nfrom (I-Cast) as two subset constraints. Constraints on where coercions might be introduced have the \nform proxy = Q . l . L. Call the set of .ow constraints F, and the set of coercion constraints C. We \ncan solve these constraints as follows. We can reduce F by continuously applying the rewrit\u00ading rules \nshown in Figure 6. These reduce compound con\u00adstraints into simpler ones following the subtyping rules, \nand iteratively discharge the implication constraints when the left-hand-side of the implication can \nbe solved. When .n\u00adished, all constraints will have the following forms: C = D, . . . ' , and Q = Q ' \n. The .rst form are subtyping require\u00adments determined by the program; if they do not hold then the program \nwould not be type-correct in FJ. The remaining two forms can be solved by standard tech\u00adniques. In particular, \nthe quali.er constraints in F form an atomic subtyping constraint system. Given n such con\u00adstraints, \nthe fact that proxy and nonproxy form a .nite lattice allows us to solve them in O(n) time [36]. The \nset-type con\u00adstraints in F are subset constraints, as occur in Andersen\u00adstyle points-to analysis. Given \nn such constraints, these can be solved in at worst O(n 3) time [2], though in practice it is often faster. \nA solution s to constraints in F is a mapping from qual\u00adi.er variables . to constants proxy and nonproxy, \nand set\u00adtype variables a to sets of class names {C1,...Cn}. The solution ensures that for each constraint \nQ1 = Q2 .F we have s(Q1) = s(Q2), and similarly for set-type constraints. We write s |= F if s is a solution \nof F. We are interested in a least solution to a for set-types, to reduce spurious \u00af\u00af\u00af T [ class C extends \nD { Tf; KM }] . T [ C(T\u00af\u00afSg); this.f = f; }] . \u00af\u00af\u00af\u00afT [ Sm(T\u00afx\u00af) { return e; }] . g, f) { super(\u00af T [ \nx] T [ let x = e1 in e2] T [ e.fi] T [ e.m(\u00afe)]] T [ new C(\u00afe)]] T [[(N)e] T [ if e1 = e2 then e3 else \ne4] T [ makeproxy e] T [ El]  . . . . . . . . . \u00af\u00af class C extends D { s(T\u00af) f; T [ K] T [ M\u00af] } C(s(T\u00af) \n\u00afg, s(S\u00af) f\u00af) { super(\u00afg); this.f = f\u00af; } s(S) m(s(T\u00af) \u00afx) { return T [ e]]; } x let x = T [ e1] in \nT [ e2] T [ e] .fi T [ e] .m(T [ \u00afe]]) new C(T [ \u00afe]]) (s(N))T [ e] if T [ e1] = T [ e2] then T [ e3] \nelse T [ e4] makeproxy T [ e] j coerce T [ E] l . L T [ E] otherwise  Figure 7: Transforming a FJi \nexpression to a FJQ expression following inference Q constraints on quali.ers, and favor proxy over nonproxy \nfor unconstrained quali.er variables so that we might delay in\u00adserting a coercion until absolutely necessary. \nGiven a solution s to constraints F, we can solve the coercion constraints C. In particular, we apply \ns to the left-hand-side of each implication in C, and then solve. The result is a set L of all program \nlabels that require a runtime coercion to properly typecheck. We write s, L |= C for the set L and substitution \ns that satis.es constraints C.  3.5 Transformation We can now transform a FJi program to a FJQ pro- \nQ gram, using L and s resulting from inference. FJQ di.ers from FJi only in the addition of expressions \nof the form Q coerce e, and in the absence of all quali.er and set-type variables (these are substituted \nout by their solutions). The expression coerce e takes a possible proxy e, and coerces it to a non-proxy \nat runtime. Like makeproxy e, our seman\u00adtics treats coercions generically, merely changing the tag on \ne to be nonproxy. The transformation is shown as the function T [ \u00b7] in Fig\u00adure 7, where L and s are \nglobal to avoid clutter. This function simply inserts coercions where directed by L, and rewrites the \ntypes on method declaration parameters and .eld declarations as directed by s. To avoid clutter, it strips \no. all labels l. In the case that we are doing a completely static analysis, e.g., to look for transparency \nviolations, the fact that L is non-empty would denote a possible violation, so the trans\u00adformation stage \nwould signal an error, as directed by the user. 3.6 Properties We wish to prove that FJQ is sound with \nrespect to an operational semantics, and that a transformed FJi Q program is sound with respect to the \nsemantics of FJQ. For the .rst, the proof follows the standard syntactic approach of using progress and \npreservation lemmas. The second is done by proving well-typedness of the transformed program given the \nwell-typedness of the source FJi Q program. Well-typedness of FJQ programs is expressed as the judg\u00adment \nh CL for class de.nitions, h M for method de.nitions and G h e : T ; G for expressions. The typing rules \nare in Figure 9 in the Appendix. Typechecking FJQ is straight\u00adforward, and similar to inference on FJi \nQ. The operational semantics of FJQ is set up as an abstract machine. Programs consist of a store S and \nan expression to evaluate e, and the transition relation . maps programs (S, e) to programs (S ' ,e ' \n). The store maps variables x (ei\u00adther source program variables or fresh addresses allocated during evaluation) \nto values. The complete transition rules are presented in the Appendix (Figure 10). We also extend FJQ \ntyping to programs, to support the proof of preserva\u00adtion. The progress and preservation lemmas for FJQ \nare as fol\u00adlows: Lemma 3.1 (Progress). Given that h (S, e): T ;G ' , then either e is a variable x. \n (S, e) . (S ' ,e ' ) for some S ' and e ' .  (S, e) is stuck due to a failed dynamic downcast.  Lemma \n3.2 (Preservation). Given that h (S, e): T , and that (S, e) . (S ' ,e ' ), then h (S ' ,e ' ): U such \nthat U = T . Note that the type U of the program after it takes a step may be a subtype of its original \ntype T due to both coercions (to downcast the proxy quali.er) and dynamic downcasts. Using the above \nlemmas, the following theorem follows. Theorem 3.3 (Type Soundness). Given h e : T ;G ' , then either \n (\u00d8,e) . * (S, x) for some S and x.  (\u00d8,e) . * (S, e ' ) for some S and e ' , where (S, e ' ) is stuck \ndue to a failed dynamic downcast.  (\u00d8,e) executes forever.  Here, we de.ne . * to mean the re.exive, \ntransitive closure of the transition relation .. Implicit in all of these state\u00adments is the presence \nof the well-formed class table CT . As is standard, the proofs of progress and preservation are by induction \non the typing and evaluation derivations, respec\u00adtively, and type soundness follows from them. Finally, \nwe can show that our proxy transformation from FJi Q to FJQ is sound. Theorem 3.4 (Inference Soundness). \nGiven a sub\u00adstitution s, label set L, and an inference derivation hi CT which generates constraints F \nand C, if s |= F and s, L |= C, then hT [ CT ] . Moreover, for each subderivation of hi CT which contains \nsubderivations of the form 1. hi CL 2. hi M  3. G hi El : T ;G ' , or G hc El : T ;G ' there is a \ncorresponding subderivation of hT [ CT ] having the form: 1. hT [ CL]  2. hT [ M]  3. s(G) hT [ El] \n: s(T ); s(G ' )  The proof is by induction on the inference derivation. All proofs can be found in \nour companion technical report [34]. 3.7 Discussion Compared to past work in .ow-sensitive type quali.ers, \n.ow-sensitivity in our system is signi.cantly simpler. The approach of Foster et al. [16] allows arbitrary \nmemory lo\u00adcations to be treated .ow-sensitively, which is complicated by the combination of aliasing \nand mutation. In particular, allowing the quali.er of a value to change .ow-sensitively requires proving \nthat the value is not aliased (is linear ). In contrast, our approach only treats local variables .ow\u00adsensitively, \nand since Java has no address-of operator &#38;, the contents of a local variable can only be accessed \nthrough that variable. Thus, we get linearity for free, trading ex\u00adpressive power for simplicity. The \ncaveat is that the im\u00adplementation of coerce x provided by the user must only operate on the variable \nx, not on the object x refers to. For wrapper proxies, this is what happens: x is overwritten to point \nto the underlying object instead of the wrapper. If co\u00adercions do not meet this criteria, then they are \nnot treated .ow-sensitively. It is because we are .ow-sensitive only for local variables that we opted \nnot to model .eld and variable updates in the FJQ. While adding updates would be straightforward (it \nis modeled in MJ [5] and existing quali.er systems [15, 16], for example), it would not change the character \nof our approach, adding only unnecessary complication. In order to be able to support the full Java language, \nwe had to address the use of the JNI and re.ection mechanisms. We have assumed a conservative approach \nin this case, by demanding that no proxy object ever .ows in the JNI API or in any re.ection invocation. \nThis approach inserts claims at all places where a native method is called, and on the argu\u00adments of \njava.lang.reflect.Method.invoke(...), ensur\u00ading that no proxy Object will ever be passed to a re.ection \nor JNI invocation. In addition, a proxy object might be ac\u00adcessed via re.ection, e.g., by reading the \n.elds of another object. Therefore, the analysis treats all objects obtained that way as possible proxies. \n 3.8 Other Applications While the formal presentation of our analysis is speci.c to proxies, our added \nsupport for coercions can easily be folded into more general quali.er systems, admitting new or improved \napplications. Here we consider three possibilities. Security-sensitive Data. Shankar et al. [37] describe \nan application of type quali.ers in which untrusted data, e.g., arriving from a user login prompt or \na network connection, is given the quali.er tainted, while trusted data is given qual\u00adi.er untainted. \nQuali.er inference is used to ensure that tainted data does not .ow to functions requiring untainted \ndata. A similar analysis is supported in Perl programs, ex\u00adcept that checks for tainted data are performed \ndynamically. This has the drawback of the potentially-signi.cant added runtime overhead of dynamic checks, \nbut has the bene.t that it is precise, and will thus avoid the false alarms gener\u00adated by the purely \nstatic approach. We can use our framework to implement a blending of these two approaches. In particular, \nthe pspec would specify which routines returned tainted data, and which expected untainted data, while \nthe ispec would implement coercions as a check to determine whether the data came from an untrusted source, \ne.g., by reading a required .eld from the object. This approach blends the two prior approaches by using \nstatic analysis to avoid many, but not all, runtime checks. Stack allocation. Java objects have dynamic, \nunrestricted lifetimes, implemented using heap allocation and garbage collection. While stack-allocating \nobjects could improve per\u00adformance, avoiding dangling pointers would entail that no stack-allocated object \nescape its de.ning scope. This could happen if the object was assigned to a .eld or returned from its \nde.ning function. One solution would be to copy a stack\u00adallocated object to the heap at the point it \nescapes its scope. However, doing so might violate transparency if that ob\u00adject s identity had already \nbeen revealed, e.g., by using the stack-allocated object as an argument to ==. Our analysis can support \ntransparent stack allocation us\u00ading two quali.ers, heap and stack, where the latter annotates an object \nthat could be either heap-or stack-allocated, and the former indicates an object that must be heap-allocated; \nwe thus have heap = stack. Any operation that could re\u00adveal the identity of an object or cause it to \nescape (e.g., by assigning it to a .eld of a heap object) would require the ob\u00adject have quali.er heap. \nA coercion would check if an object was on the stack (perhaps using a bit mask), and copy it to the heap \nif necessary. Not-null types. Another application is the use of null and nonnull quali.ers to characterize \nobjects that are possibly null, or de.nitely not null, respectively [13]. This would provide a simple \nway of specifying the standard null-check elimination optimization as a quali.er system, and would allow \nusers to manually annotate .elds or method arguments as being nonnull, to avoid explicit null tests. \nTo implement this in our framework, the pspec would indi\u00adcate that all occurrences of the constant null \nhave quali.er null (including default initialization of .elds), and that con\u00adcrete object usages, e.g., \nto call a method, require that the object quali.er be nonnull. The ispec would implement coer\u00adcions as \nnull-checks (throwing an exception on failure), with .ow-sensitivity naturally eliminating redundant \nchecks. Of course, to be truly useful, we would require the coopera\u00adtion of the JVM to avoid checks proven \nredundant by our framework.  4. ASYNCHRONOUS METHOD CALLS Having described our proxy framework formally, \nwe now describe our implementation of asynchronous method invo\u00adcations in Java. 4.1 Framework Implementation \nOur analysis is implemented as an extension to Soot [40] (version 2.1.0), a framework for analyzing and \ntransforming Java class.les. Soot provides a framework for implementing .ow-insensitive points-to analyses \ncalled SPARK [27]. We extended SPARK to track proxies and generate set types based on points-to information. \nSPARK s constraint graph representation uses a node (corresponding variously to a quali.er variable . \nor a set type variable a) for each lo\u00adcal variable and method parameter. We extended this to be .ow-sensitive \nby assigning multiple nodes to each vari\u00adable or method parameter, one per use. As an optimization, we \ndo so only for nodes that could possibly contain proxies, as determined by a .ow-insensitive analysis. \nThis reduces the total nodes to consider, since proxies are typically used sparingly in the program (relative \nto the total number of objects). For the applications presented in Section 5, this optimization yields \na 6% to 45% improvement in the cost of the .ow-sensitive analysis. Note that SPARK also supports context-sensitivity, \nbut we have not taken advantage of this as of yet. Programmers implement the pspec and ispec by providing \nthree classes and linking them into the analysis: 1. The AsyncGen class in the pspec de.nes syntactic \npat\u00adterns that indicate where proxies are introduced. These patterns must, of course, be legal Java syntax \nthat could have been compiled to bytecode. 2. The Policy class in the pspec de.nes coercions using a \nvisitor over the Jimple syntax tree that speci.es which expressions require non-proxies. 3. The ClaimTransformer \nclass implements the ispec. It de.nes how call sites that create proxies are trans\u00adformed, and how coercions \nare implemented. It may direct that supporting classes be linked into the trans\u00adformed application. \n Because Jimple represents typed bytecode, coercions that assign back to the original variable must be \nwell-typed. Thus we give type Object to each Jimple variable x of type A that could contain a proxy. \nWhenever x is coerced, we assign the result to a newly-introduced variable y with type A, and replace \nwith y subsequent occurrences of x in the contin\u00aduation. This transformation is sound because proxies \nare treated transparently, and because there is no way to alias and mutate the storage of the original \nvariable x. 4.2 Asynchronous Invocations Programmers invoke methods asynchronously using the syntax \nr = Async.invoke(t,o.m(e1,e2,...)); According to the pspec, this syntax indicates that method m should \nbe invoked asynchronously and the result (if any) returned to the caller will be a future. The method \ns argu\u00adments e1,e2, ..., en are still evaluated in the current thread. The ispec de.nes the steps needed \nto implement an asyn\u00adchronous call. First, the program creates an anonymous subclass of ProxyImpl that \nencapsulates the invocation of method m. ProxyImpl has the following signature: public class ProxyImpl \nimplements Runnable, Wrapper { public void run(); // executes the invocation public Object get(); // \nacquires the result } The Wrapper interface simply de.nes a single get method, which extracts the underlying \nobject for which the wrapper is a proxy. public interface Wrapper { Object get(); } Next, the ProxyImpl \nobject is passed to a thread manager. Thread managers implement the Java 1.5 Executor inter\u00adface: public \ninterface Executor { void execute(Runnable command); } The thread manager will call the ProxyImpl s run \nmethod in a separate thread to achieve asynchrony. The run method will execute the method invocation \no.m(e1,e2,...) and store the result in a private .eld, to be extracted by a call to get. Finally, the \nProxyImpl is returned to the caller of the original method m in place of the result r. If the analysis \ndetermines that a program variable x with type A could contain a future, a coercion is required before \nx can be used concretely. The ispec implements coercions with the following code fragment: (A)(x instanceof \nWrapper ? ((Wrapper)o).get() : x) That is, if x is a wrapper, then we must call get to extract the result. \nThe get method in turn will wait if the result is not yet available. Any implementation of Executor can \nbe used as a thread manager. We have used the Java 1.5 ThreadPoolExecutor, which provides an extensible \nthread pool implementation, as well as our own ThreadPerObjectExecutor, which emu\u00adlates active objects \n[26] by mapping each object receiving an asynchronous method call to an executor. Note that programmers \ncan in.uence where claims occur by performing null casts. That is, the expression (C)e requires e s quali.er \nto be nonproxy, so casting it to its known type will have the e.ect of forcing a claim. This design is \nboth lightweight and .exible. Program\u00admers can easily experiment with method asynchrony with\u00adout rewriting \nsubstantial amounts of code. In addition, pro\u00adgrammers can experiment with a variety of threading poli\u00adcies \nby choosing di.erent thread managers. A simple extension supports lazy evaluation. To invoke method m \nof object o lazily, the programmer uses the syn\u00adtax: r = Lazy.invoke(o.m(e1,e2,...)); A ProxyImpl subclass \nis generated as above, but here the run method is called by get (called when the wrapper is claimed) \nif no .nal result yet exists. 4.3 Exceptions If an asynchronous method call o.m() throws an exception \nE, that exception is cached inside the future returned by m. When the future is claimed, the exception \nE is re-thrown.2 This presents some challenges to the analysis. 2This di.ers from a Future in util.concurrent, \nwhose get method declares it could throw an ExecutionException, encapsulating any exception thrown by \nthe computa\u00adtion. As such, the programmer is required to handle ExecutionException each time that a future \nis claimed. Our implementation of claim essentially catches this excep\u00adtion, and then re-throws the exception \nit encapsulates. The fact that claims could throw exceptions can be mod\u00adeled as a simple extension to \nFJQ. We .rst must extend the language to model exceptions. We extend expressions e to include the form \ntry e catch E . e, where E is the name of the exception being handled. Method declarations are extended \nto include throws clauses. We also add a form throw E for throwing an exception of type E (throw could \ntake arbitrary expressions of exception type, but this sim\u00adpli.es the presentation). We extend the typing \njudgment from Figure 9 to include the throw set T of exceptions E that could be thrown by evaluating \nan expression. The typing rule for try-blocks is: G, h e1 : T1;G1; T1 G h e2 : T2;G2; T2 T2 = TT1 = T \n= merge(G1, G2) G ' T ' = handles(E, T1) .T2 G h try e1 catch E . e2 : T ;G ' ; T ' The function handles(E, \nT1) prunes those exceptions E ' . T1 which are subtypes of E. The resulting throw set is this pruned \nset and the set from the handler. This rule conserva\u00adtively assumes any .ow-sensitive e.ects of e1 re.ected \nin G1 will not be seen in e2. When checking a method consisting of expression e, we make sure that e \ns resulting throws set is covered by the throws clauses the method declares. Now we must re.ect into \na proxy s type what exceptions it might throw. To do this we expand the proxy quali.er into a family \nof quali.ers, where each mentions an exception E that could be thrown if the quali.ed value is coerced. \nThese form a lattice based on the subtyping relationship between exceptions E. For example, we have proxyE \n= proxyE2 if E = E2. For all E, we have proxy = proxyE. The rule for makeproxy e becomes G h e : nonproxy \nN;G ' ; T E = lub(T ) G h makeproxy e : proxyEN;G ' ; \u00d8 That is, the exceptions that e could throw are \nre.ected into its quali.er. For this rule to be sound, we must modify the operational semantics to capture \nany exception thrown when evaluating e in the proxy, and then re-throw the exception when doing the coercion. \nThe typing rule for coerce re.ects that an exception could be thrown: G h e : QN;G ' ; T Q = proxyE G \nh coerce e : nonproxy N;G ' ; T .{E} In our implementation, we must extend the de.nition of the Wrapper \ninterface to de.ne get methods that could throw the various expressions E determined by the analysis, \nand adjust ProxyImpl and claim code accordingly (which is easy to do automatically). Given this formulation, \nwe ensure that proxy inference deals with exceptions properly in a couple of ways. In the simplest case, \nwe ensure that in expression makeproxy e, e never throws an exception. This is done by allowing the programmer \nto provide a handler for possible exceptions when creating the proxy. In particular, users can use an \nExecutor that handles exceptions in a user-speci.ed way inside spawned threads. This approach also requires \nthat the user specify a default value for the object returned by a claim, since the swallowed exception \nwill have prevented the method from returning a value. In our experience, this simple approach works \nfairly well in practice. In the second case, we let inference determine where prox\u00adies could .ow, signaling \nan error only if an inserted coercion could throw an exception not covered by the throws clause for the \nmethod in which it occurs. For many applications we have considered, unclaimed proxies do not .ow outside \nthe scope of a reasonable exception handler. This is frequently true for event-style server applications, \nwhich have an outer\u00admost exception handling block coupled with the event loop to catch exceptions raised \nby event handlers. In the case that a proxy does .ow to an unexpected location, the user learns exactly \nwhere the o.ending claim was inserted and can man\u00adually alter the code to insert a handler. Alternatively, \nwhen the user speci.es a method call should be asynchronous, she can provide a handler object whose handle \nmethod is called with argument E when a claim would cause E to be thrown. Any exceptions thrown by this \nhandler (e.g., to delegate to an outer-scope handler) are re.ected in the type of the proxy. Even when \nthe surrounding context can handle an excep\u00adtion E thrown due to a claim, it could be incorrect to do \nso. Some exceptions, like IOException, are thrown by many methods, and the exception generated by the \nclaim may vi\u00adolate some invariant expected by the programmer. Though we have not yet done so, we should \nbe able to ensure that a proxy can only throw to handlers that were present in its original context. \nTo do this, rather than track the excep\u00adtions possibly thrown by an expression e, we could track all \nof the handlers that would catch exceptions thrown by e. These would create a similar partial order that \nwould be folded into the proxy quali.er. At the same time, the typing judgment would keep track of the \nhandler context, which is the set of all handlers that an exception could possibly throw to (including \nthose in method callers). Typecheck\u00ading a coercion would require that the handler context be a subset \nof the handlers mentioned in the proxy. Note that all of this discussion need only apply to checked exceptions. \nAs unchecked exceptions typically signal dis\u00adastrous (unrecoverable) situations, we can choose to ignore \nthem in the analysis. 4.4 Synchronization Concurrent programs must balance safety and liveness, by guarding \nagainst invariant violations and preventing dead\u00adlock. Our approach no worse and no better than standard \nJava thread programming. When using asynchronous me\u00adthod calls, programmers must use ordering, synchroniza\u00adtion, \nimmutability, and other techniques to ensure safety and liveness no automatic support is provided. Ideally, \nensuring a program is safe and live could be as lightweight as introducing an asynchronous invocation. \nIn Lisp, this is trivial because programs are written in a mostly\u00adfunctional (if not purely-functional) \nstyle, which means that added concurrency will not a.ect the program s safety. We contemplated approaches \nto inserting synchronization au\u00adtomatically [26, 7, 22, 17], but rejected this idea because of its lack \nof generality and potentially negative impact on performance. We discuss this issue more in Section 6. \nInstead, we feel a more promising approach is to have programmers specify synchronization requirements \ndeclara\u00adtively. Declarative speci.cations should change infrequently, even as the programmer changes \nvarious method invocations to be or not be asynchronous. Therefore, the proper syn\u00adchronization code \ncould be generated from the speci.cation as changes are made. Work in aspect-oriented program\u00adming [29, \n25, 8] and language-level transactions [41, 19] aim to realize this goal. By not making any assumptions \ntest tot (s) per-check (ns) % ovr no claim 0.122 n/a n/a redundant claim 0.1637 16.37 34% necessary claim \n0.335 33.5 175% Table 1: Overhead of inserted claims, N = 107 about synchronization, we can readily \nincorporate good re\u00adsults from these projects.  5. EVALUATION We evaluate our framework in terms of \n(1) programming bene.t (how does our framework simplify the programming task), (2) analysis e.ectiveness \n(how does it impact the run\u00adtime of the instrumented program), and (3) analysis perfor\u00admance (how fast \nis the analysis). We present a number of applications of both wrapper proxies and transparency checking \nto give a sense of the costs and bene.ts of our ap\u00adproach. As use of the Java 1.5 concurrency libraries \nbecomes more widespread, we hope to adapt larger examples to use our framework. We ran our experiments \non a 2 GHz AMD Athlon 2600+ with 1 GB of RAM, running Mandrake Linux 9.1 (kernel version 2.4.21.) 5.1 \nClaim Overhead Wrapper proxies can .ow to potentially many parts of the program, and because our static \nanalysis must be conserva\u00adtive, classes may be instrumented with redundant claims. To measure the performance \noverhead of necessary as well as redundant claims, we constructed a simple microbench\u00admark: Object o,p \n= ... for (int i=0; i<N; i++) {p=o; p.m(); } The method m simply increments a volatile counter. We var\u00adied \no to be either a normal object, an already-claimed wrap\u00adper proxy, or an unclaimed wrapper proxy (in \nthis last case, the copy from o to p ensures it will be claimed each time, since o never gets claimed \nand thus will never be rewrit\u00adten to be the wrapped object). The results are shown in Table 1 for N = \n107 (other values of N showed a similar relationship). Redundant claims consist of essentially three \ninstructions at runtime: an instanceof check, a cast, and an assign\u00adment. Our measurements show this \nadds 34% to the loop running time. Necessary claims require an additional syn\u00adchronized method call and \nassignment, and cost more. How\u00adever, these are unlikely to appear frequently because the fu\u00adture is overwritten \nafter the underlying object is acquired, inducing only redundant claims from then on. In actual applications \nwe expect the overhead of claims to be small because (1) not all method calls require claims, and (2) \nme\u00adthod calls perform real work, dwar.ng the cost of claims relative to program running time. 5.2 Programming \nwith Futures A central bene.t of our approach over a manual coding of proxies is that it simpli.es the \nprogramming process. To il\u00adlustrate this, we take an example from the util.concurrent API documentation \n[24, 12] that describes how to convert a blocking service into a non-blocking service using futures. \nThe blocking service implements the following interface: interface BlockingService { public Response \nserve (Request req) throws ServiceException; } We .rst present how we would convert BlockingService \nobjects to be non-blocking using our approach, and then present the manual approach proposed in the documentation \nfor util.concurrent. Our Approach. Given BlockingService object bs, we make calls to its serve method \nasynchronous by simply changing existing method calls bs.serve(request) to be Async.invoke(executor,bs.serve(request)) \nThe analysis will infer where claims are required and insert them directly into the bytecode of both \napplications and library classes, based on user input. Assuming claims occur where ServiceExceptions \ncan be caught, we are .nished. Otherwise, we can modify invocations to include a wrapping exception handler, \nor add handlers to claim locations, as described in Section 4.3. We might also wish to insert null casts \nto force claims early, for performance reasons. Manual Approach. To use Java 1.5 Futures instead, we \nwould take the following steps [12]. First, we de.ne a non\u00adblocking variant of the BlockingService interface \nwhose serve method returns a Future, and then build an adapter class to wrap a BlockingService object, \nas shown in Fig\u00adure 8. The serve method of NBSAdapter creates a task to invoke the underlying BlockingService \nobject s serve method, handling any exception locally. This task is exe\u00adcuted by the adapter s Executor \nobject after turning it into a FutureTask, which implements Future. The future is then returned to the \ncaller. Now we can make our original bs object non-blocking by creating nbs = new NBSAdapter(bs). Existing \ncalls bs.serve(request) are changed to be nbs.serve(request) At this point, we must adjust old client \ncode to handle the fact that nbs.serve returns a Future<Response> rather than a Response. So that futures \nare claimed as late as possible, we must follow how Response objects would have .owed from calls to serve \nand sprinkle claims just before a futurized Response object is used. This can be tricky if Response objects \nwere stored in containers that could be accessed by many methods or threads throughout the pro\u00adgram. \nIf a now-futurized Response object could .ow into library routines or third-party components, the program\u00admer \nmay be forced to claim the future early, which could hurt performance. Compared to one-line-per-invocation \nchange imposed by our framework, this is a fair amount of programming over\u00adhead. Moreover, a similar \noverhead is required to undo the change.  5.3 Asynchronous RMI For an asynchronous method call to be \nworthwhile, the added parallelism must overcome the added overheads, such as thread creation time and \nsynchronization, to realize a interface NonBlockingService { public Future<Response> serve (Request req); \n} class NBSAdapter implements NonBlockingService { public NBSAdapter (BlockingService svc) { this.blockingService \n= svc; this.executor = Executor.newFixedThreadPool(3); } public Future<Response> serve (final Request \nreq) { Callable<Response> task = new Callable<Response>() { public Response call () { try { return blockingService.serve(req); \n} catch (ServiceException e) { e.printStackTrace(); // more exception handling } } }; FutureTask<Response> \nftask = new FutureTask<Response>(task); executor.execute(ftask); return ftask; } private final BlockingService \nblockingService; private final Executor executor; } Figure 8: A BlockingService adapter class performance \ngain. Remote method calls are a natural candi\u00addate, because they must pay the cost of a network round-trip \ntime for each invocation. Indeed, asynchronous RPC was the initial motivation for Liskov and Shrira s \npromises [28], and recent work has considered the idea for Java [35, 39]. To illustrate this bene.t, \nwe have applied our framework to a RMI-based peer-to-peer service sharing application de\u00adveloped for \na class at the University of Maryland3 . Each peer can perform text processing using a number of com\u00adposable \nservices, which are simply references to objects im\u00adplementing a Service interface. If the application \ndoes not have all of the services it wants, it can ask for them from the network, and will receive remote \nreferences for each in mes\u00adsages from peers. These are stored with the local services in a table. The \ncode to .nd a (potentially remote) service is roughly as follows: Service findService(LocalPeer self, \nString sName) { Service s = self.getService(sName); if (s != null) return s; else { self.forward(new \nFindServiceMessage(sName)); return getRemoteService(self, sName); } } If the service is present in the \nlocal table, the method im\u00admediately returns it. Otherwise, the forward method will use RMI to send messages \nto the node s peers, asking for the service. The .rst thing we did was make this method call asynchronous \n(though no future is returned) The getRemoteService call will block (using wait) un\u00adtil it observes that \nthe desired service has been installed in the table. This is problematic when the client appli\u00ad http://www.cs.umd.edu/class/fall2003/ \ncmsc433-0201/p5/p5.htm Analysis Time classes (s) analyzed w/ fut. transformed claims FI 73 1324 27 2 \n7 FS 92 1324 9 2 2 SPARK 66 1320 n/a n/a n/a Table 2: Analysis Performance on Async RMI cation wishes \nto invoke findService n times to create a composed service as each call must wait until the prior ser\u00advice \nis found and the network will not be used to search for services in parallel. To address this issue, \nwe made the call to getRemoteService lazy, changing it to be Lazy. invoke(getRemoteService(self,sName)). \nAs this syntax introduces a wrapper proxy, the framework rewrites the caller s class to delay the invocation \nof the method until the proxy is unwrapped. Thus, all n calls to getService will proceed in parallel, \nand will only block when the service is used concretely. Analysis Performance. The analysis times for \nthis bench\u00admark are shown in Table 2. Here we show the results of both our .ow-sensitive analysis (FS), \nand a .ow-insensitive variant of it (FI). Times are in seconds, and we show the total number of classes \nanalyzed (which are largely library classes), those into which futures could .ow, and .nally those that \nwere transformed. For those classes transformed, we indicate how many coercions (claims) were inserted. \nThe results show the bene.t of .ow-sensitivity: fewer classes are polluted with futures and fewer claims \nare required. The .ow-sensitive analysis takes more time to run than the .ow-insensitive version. Both \nprocess the same num\u00adber of classes, but the .ow-sensitive version generates more constraints. Indeed, \nthe .ow-insensitive analysis is virtually identical to the cost of just running the SPARK without modi.cation. \nThe .ow sensitive analysis uses the result of a .ow-insensitive analysis to limit the number of variables \nthat are analyzed .ow-sensitively. In particular, only the variables that have quali.er proxy are re-analyzed \n.ow sen\u00adsitively. However, the time saved compared to running the .ow-sensitive analysis for the whole \nprogram is still signi.\u00adcant, even though we are running the analysis twice. Runtime Performance. To \nassess the runtime bene.t to asynchronous remote invocations, we ran some simple ex\u00adperiments on a two-node \nnetwork connected by 100 Mbps Ethernet. The application attempts to acquire n services, for 1 = n = 10, \nall of which are non-local. We compare the original application (Orig) to our changed version (Async). \nIn addition to normal RMI messaging, we ran a version that inserts an 80 ms delay for each message send, \nto simulate a wide area message. The results shown in Table 3 represent the median of 11 runs, with all \ntimes in milliseconds (the mean and median values were similar). For the local area tra.c, the added \nparallelism of asyn\u00adchronous RMI nets performance gains of up to 40%. For the delayed case, the running \ntime of the original applica\u00adtion tracks the number of services times the round trip delay, while the \nAsync version signi.cantly amortizes this cost. Of course, these results could have been achieved by \nrewrit\u00ading the application by hand to capture the invocation, and Version Services requested and used \n1 2 3 4 5 6 7 8 9 10 Orig. 18 32 48 65 90 100 113 124 143 153 Async 17 26 34 42 50 57 62 78 83 84 \nOrig. + delay 101 203 304 406 507 607 707 811 916 1010 Async + delay 106 117 122 133 145 153 157 160 \n171 178 Table 3: Elapsed time (s) of Peer-to-Peer RMI application with varying workload acquire it before \napplying the result. Our framework made it signi.cantly easier to do this: we only had to annotate two \nmethod calls, and the framework did the rest automatically.  5.4 Transparency Checking We have also \nused our framework to search for possible transparency violations through the use of interface proxies. \nHere, we consider a programmer that might like to specialize an object implementing interface I, e.g., \nto count how often a particular method is called. Following the proxy design pattern, the programmer \ncould use a dynamic proxy class [9] to create a method-counting object that also implements I, which \nforwards calls to the original object. Our framework can ensure that the program will never distinguish \nbetween the proxy and the underlying object by using an identity\u00adrelated operation, like ==, instanceof, \netc. This is done with the following policy and implementation speci.cation: Policy Calls to Proxy.newProxyInstance(...) \nintroduce proxies. All expressions that are identity-revealing must operate on non-proxies, including \nsynchronized, ==, and instanceof. Note that unlike futures and other wrapper proxies, method calls do \nnot require the object be a non-proxy. Implementation No code is needed to generate proxies (that is \nalready being done by the program) or to co\u00aderce them. Any requirement of a coercion implies a possible \ntransparency violation, which is signaled by the analysis. We ran our checker on two examples: an XML-based \nim\u00adplementation of SOAP over RMI that uses dynamic proxy classes [38], and the Soot bytecode analysis \nframework [40] (version 2.0.1).4 In the former case, the analysis tracks all proxies created with Proxy.newProxyInstance. \nIn the lat\u00adter, we selected three di.erent methods that return inter\u00adfaces, and told the checker that \ncalling these methods might return proxies. This simulates a user wishing to proxy an object returned \nby one of these methods, e.g., to perform pro.ling, but ensuring that transparency will not be vio\u00adlated. \nWe ran the .ow sensitive and a .ow insensitive analysis to detect possible errors. For the SOAP/RMI example, \nwe ran the checker over the code as is, and found no transparency violations. Table 4 summarizes the \nresults. Once again, the .ow-insensitive analysis had essentially the same running time as SPARK points-to \nanalysis (not shown), and the .ow\u00adsensitive version added some overhead. Interestingly, the .ow-sensitive \nanalysis adds no value in this case. It could potentially reduce false positives due to spurious .ows, \nbut does not do so. Version Time # of classes Errors (s) analyzed with proxies FI 48 2189 3 0 FS 58 2189 \n3 0 SPARK 45 2189 n/a n/a Table 4: Analysis Performance for SOAP/RMI Example Time (s) # of classes Errors \nFI FS analyzed with proxies 1 181 210 2092 16 0 2 174 209 2092 3 1 3 182 214 2092 12 9 SPARK 151 n/a \n2092 n/a n/a Table 5: Analysis Performance for 3 Soot Examples The Soot examples for the three di.erent \nmethods are shown in Table 5. The SPARK number is the average time for all three examples, which had \nsimilar running times. We looked at the reported violations, and veri.ed that they were genuine transparency \nviolations that could lead to bugs. Once again, it was interesting to see that .ow-sensitivity added \nno precision (only overhead!), and that the origi\u00adnal SPARK analysis times are relatively close to our \n.ow\u00adinsensitive analysis times.  6. RELATED WORK Proxies. Gamma et al. [18] present many uses of the \nproxy design pattern, including remote references, lazy evaluation, and access control. Other uses5 include \nmemoization, del\u00adegation, synchronization addition, generic event listeners, and views for abstract data \ntypes. Java s dynamic proxy classes [9] permit the simple construction of interface prox\u00adies, and have \nbeen used in a variety of applications [38, 4]. Static Analysis. Our analysis is a variant of quali.er \nin\u00adference, which draws upon techniques developed in other static analyses, including constraint-based \nanalysis [1] and points-to analysis [10]. Our approach extends Foster et al. s quali.er inference [15] \nwith support for coercions that im\u00adplement checks at runtime, e.g., to claim a future. These coercions \nare treated .ow-sensitively. Foster et al. also de\u00ad.ne a .ow-sensitive variant of their analysis [16], \nbut their approach allows heap locations, and not just variables, to be treated .ow-sensitively. This \nadds expressive power but signi.cant complication. 4We analyze Soot 2.0.1 because analyzing 2.1.0 causes \nour 5See, for example http://blog.monstuff.com/archives/ benchmark machine to swap. 000098.html. Asynchronous \nMethod Calls and Futures. The notion of a future was popularized by Halstead in MultiLisp [23]. In a \ndynamically-typed language like Lisp or Scheme, potentially any value could be a future, necessitating \na runtime check. Flanagan and Felleisen [14] de.ne a whole-program static analysis for reducing eliminating \nsome unnecessary checks; our analysis conversely adds needed checks based on the possible .ow of futures. \nLiskov and Shrira proposed promises [28], which are fu\u00adtures for statically-typed languages. A promise \nis a type parameterized by the type of object it will ultimately com\u00adpute, like a Java 1.5 Future [24]. \nWe found a number of applications of futures to statically-typed, object-oriented languages [31, 24, \n20, 35, 11]. Mandala [30] is another framework that provides asyn\u00adchronous method invocation and futures \nfor Java. Asyn\u00adchronous calls are implemented with re.ection, using dy\u00adnamic proxy classes, which is \nmore modular than our ap\u00adproach. However, Mandala is less e.cient and less trans\u00adparent. Identity-revealing \noperations like == could distin\u00adguish the proxied object. Dynamic proxies use re.ection for each method \ncall, which is notoriously slow (more than an order of magnitude slower than a normal method call on \nour benchmark machine). To work around this overhead, a Mandala programmer can treat the returned value \nof an asynchronous call as an explicit FutureClient object (much like a Java 1.5 Future) which must be \nmanually claimed, thus sacri.cing the programming bene.t of transparency. A number of languages support \nactive objects [26], such as the SCOOP extension to Ei.el [7] and Io [22], which return futures.Method \ncalls are handled by a per-object thread, and automatically synchronized based on programmer-supplied \nmethod preconditions. While simple to use, programmers are forced to use concurrency only on a per-object \nbasis, as opposed to per activity, which could severely limit perfor\u00admance without potentially unnatural \nprogram restructur\u00adings.In our approach, concurrency is handled per-method by arbitrary Executor objects, \nbut synchronization must be handled by the programmer. Polyphonic C# [3] adds concurrency abstractions \nto C# based on the join calculus. Method declarations annotated as async are always invoked asynchronously. \nThese methods must not return results, so there is no need for futures. Asynchronous remote method invocation \ncan be used to batch remote calls and thus amortize the delay of round\u00adtrip times. Promises were developed \nin this context. Raje et al. [35] propose an approach in which the returned fu\u00adture is made manifest \nto the programmer, adding to the programming burden. Sysala and Janecek [39] require that remote calls \nbe provided a callback, to be invoked the result is available. This simpli.es exception handling but \nobscures the control .ow of the program, making debugging more di.cult. It also forces programmers to \ndistinguish between remote and local references, eliminating the transparency a.orded by RMI.  7. CONCLUSIONS \nWe have presented a simple and .exible framework for transparent programming with proxies in Java. The \nframe\u00adwork uses a sound static analysis to track the .ow of proxies throughout the program. The analysis \nis based on quali.er inference [15], with two extensions: we permit the use of dy\u00adnamic coercions to \nallow proxies to have runtime e.ect, and use .ow-sensitivity to avoid redundant coercions. We have used \nour framework to implement a natural form of asyn\u00adchronous and lazy method invocation for Java, and to \ncheck for possible transparency violations when using the proxy design pattern. The framework is general \nenough to apply to other interesting applications, including the tracking of security-sensitive data, \nand supporting not-null types and stack-allocated objects. We are currently pursing two avenues of future \nwork. First, we are generalizing our framework to support arbi\u00adtrary quali.ers, to support the other \napplications mentioned above. In doing so, we plan to support more sophisticated context-sensitive analysis. \nSecond, we are exploring how to make our analysis incremental, to avoid reanalyzing the whole program \neach time a source .le is changed. Rather, we are developing a dependency-tracking system that would \nallow for selective reanalysis of unchanged classes, possibly in the background for better performance. \nWe would hope to generalize our approach to other static analyses. Acknowledgments. We thank Je. Foster, \nNikhil Swamy, James Rose, and the anonymous referees for helpful com\u00adments on drafts of this paper. \n8. REFERENCES [1] Alexander Aiken. Introduction to set constraint-based program analysis. Science of \nComputer Programming (SCP), 35(2):79 111, 1999. [2] Lars Ole Andersen. Program Analysis and Specialization \nfor the C Programming Language. PhD thesis, DIKU, University of Copenhagen, May 1994. (DIKU report 94/19). \n[3] Nick Benton, Luca Cardelli, and C\u00b4edric Fournet. Modern concurrency abstractions for C#. ACM Transactions \non Programming Languages and Systems (TOPLAS), 2003. Special Issue of papers from FOOL 9. [4] Gregory \nBiegel, Vinny Cahill, and Mads Haahr. A dynamic proxy based architecture to support distributed Java \nobjects in a mobile environment. In Proceedings of the CoopIS/DOA/ODBASE, pages 809 826, 2002. [5] Gavin \nM. Bierman, Matthew J. Parkinson, and Andrew M. Pitts. An imperative core calculus for Java and Java \nwith e.ects. Technical Report 563, University of Cambridge Computer Laboratory, April 2003. [6] Gilad \nBracha, Martin Odersky, David Stoutamire, and Philip Wadler. Making the future safe for the past: adding \ngenericity to the Java programming language. In Proceedings of the ACM Conference on Object-Oriented \nProgramming, Systems, Languages, and Applications (OOPSLA), pages 183 200, Vancouver, British Columbia, \nCanada, 1998. [7] Michael James Compton. SCOOP: An investigation of concurrency in Ei.el. Master s thesis, \nDepartment of Computer Science, The Australian National University, December 2000. [8] Xianghua Deng, \nMatthew B. Dwyer, John Hatcli., and Masaaki Mizuno. Invariant-based speci.cation, synthesis, and veri.cation \nof synchronization in concurrent programs. In Proceedings of the IEEE International Conference on Software \nEngineering (ICSE), pages 442 452, Orlando, Florida, USA, 2002. [9] Dynamic proxy classes. http://java.sun.com/j2se/1.5.0/ \ndocs/guide/reflection/proxy.html. JDK 1.5 documentation. [10] Maryam Emami, Rakesh Ghiya, and Laurie \nJ. Hendren. Context-sensitive interprocedural points-to analysis in the presence of function pointers. \nIn Proceedings of the ACM Conference on Programming Language Design and Implementation (PLDI), pages \n242 256, Orlando, Florida, USA, 1994. \u00b4 Cointe. Partial behavioral re.ection: spatial and temporal selection \nof rei.cation. In Proceedings of the ACM Conference on Object-Oriented Programming, Systems, Languages, \nand Applications (OOPSLA), pages 27 46, Anaheim, California, USA, 2003. [11] Eric Tanter, Jacques Noy\u00b4e, \nDenis Caromel, and Pierre [12] Executor examples. http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/ \netc/notes/tim-execu%tor-examples.html?rev=1.5. [13] Manuel F\u00a8ahndrich and K. Rustan M. Leino. Declaring \nand checking non-null types in an object-oriented language. In Proceedings of the ACM Conference on Object-Oriented \nProgramming, Systems, Languages, and Applications (OOPSLA), pages 302 312, Anaheim, California, USA, \n2003. [14] Cormac Flanagan and Matthias Felleisen. The semantics of Future and its use in program optimizations. \nIn Proceedings of the ACM Symposium on Principles of Programming Languages (POPL), pages 209 220, San \nFrancisco, CA, January 1995. [15] Je.rey S. Foster, Manuel F\u00a8ahndrich, and Alexander Aiken. A theory \nof type quali.ers. In Proceedings of the ACM Conference on Programming Language Design and Implementation \n(PLDI), pages 192 203, May 1999. [16] Je.rey S. Foster, Tachio Terauchi, and Alex Aiken. Flow-sensitive \ntype quali.ers. In Proceedings of the ACM Conference on Programming Language Design and Implementation \n(PLDI), pages 1 12, Berlin, Germany, June 2002. [17] Matteo Frigo, Charles E. Leiserson, and Keith H. \nRandall. The implementation of the Cilk-5 multithreaded language. In Proceedings of the ACM Conference \non Programming Language Design and Implementation (PLDI), pages 212 223, Montreal, Canada, 1998. [18] \nErich Gamma, Richard Helm, Ralph E. Johnson, and John Vlissides. Design Patterns: Elements of Reusable \nObject-Oriented Software. Addison-Wesley, 1995. [19] Tim Harris and Keir Fraser. Language support for \nlightweight transactions. In Proceedings of the ACM Conference on Object-Oriented Programming, Systems, \nLanguages, and Applications (OOPSLA), pages 388 402, Anaheim, California, USA, 2003. [20] Claude Hussenet. \nPersonal Communication. Describes the use of JSR 166 futures for an enterprise application. [21] Atsushi \nIgarashi, Benjamin C. Pierce, and Philip Wadler. Featherweight Java: a minimal core calculus for Java \nand GJ. ACM Transactions on Programming Languages and Systems (TOPLAS), 23(3):396 450, 2001. [22] Io: \nA small programming language. http://www.iolanguage.com/. [23] Robert H. Halstead Jr. Multilisp -a language \nfor concurrent symbolic computation. ACM Transactions on Programming Languages and Systems (TOPLAS), \n7(4):501 538, 1985. [24] JSR 166: Concurrency utilities. http://www.jcp.org/en/jsr/detail?id=166. [25] \nGregor Kiczales, Erik Hilsdale, Jim Hugunin, Mik Kersen, Je.rey Palm, and William G. Griswold. An overview \nof AspectJ. In Proceedings of the European Conference on Object-Oriented Programming (ECOOP), volume \n2072 of Lecture Notes in Computer Science, pages 327 353, Budapest, Hungary, 2001. Springer-Verlag. [26] \nR. Greg Lavender and Douglas C. Schmidt. Active object: an object behavioral pattern for concurrent programming. \nIn Proceedings of the Pattern Languages of Programs, September 1995. [27] Ondrej Lhot\u00b4ak and Laurie Hendren. \nScaling Java points-to analysis using SPARK. In Proceedings of the International Conference on Compiler \nConstruction (CC), volume 2622 of Lecture Notes in Computer Science, pages 153 169, Warsaw, Poland, 2003. \n[28] Barbara Liskov and Liuba Shrira. Promises: linguistic support for e.cient asynchronous procedure \ncalls in distributed systems. In Proceedings of the ACM Conference on Programming Language Design and \nImplementation (PLDI), pages 260 267, Atlanta, Georgia, USA, July 1988. [29] Cristina Videira Lopes and \nKarl J. Lieberherr. Abstracting process-to-function relations in concurrency object-oriented applications. \nIn Proceedings of the European Conference on Object-Oriented Programming (ECOOP), volume 821 of Lecture \nNotes in Computer Science, pages 81 99, Bologna, Italy, July 1994. Springer. [30] Mandala. http://sourceforge.net/projects/mandala/. \n[31] Dragos A. Manolescu. Work.ow enactment with continuation and future objects. In Proceedings of the \nACM Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA), pages 40 \n51, Seattle, Washington, USA, 2002. [32] Eric Mohr, David A. Kranz, and Robert H. Halstead Jr. Lazy task \ncreation: A technique for increasing the granularity of parallel programs. IEEE Transactions on Parallel \nand Distributed Systems, 2(3):264 280, 1991. [33] Greg Morrisett, Matthias Felleisen, and Robert Harper. \nAbstract models of memory management. In Proceedings of the International Conference on Functional Programming \nLanguages and Computer Architecture (FPCA), pages 66 77, La Jolla, California, USA, 1995. [34] Polyvios \nPratikakis, Jaime Spacco, and Michael Hicks. Transparent proxies for Java futures. Technical Report CS-TR-4574, \nDepartment of Computer Science, University of Maryland, College Park, March 2004. [35] Rajeev R. Raje, \nJoseph I. William, and Michael Boyles. An asynchronous remote method invocation (ARMI) mechanism for \nJava. In Proceedings of the ACM Workshop on Java for Science and Engineering Computation, Las Vegas, \nNevada, 1997. [36] Jakob Rehof and Torben Mogensen. Tractable constraints in .nite semilattices. Science \nof Computer Programming, 35(2 3):191 221, 1999. [37] Umesh Shankar, Kunal Talwar, Je.rey S. Foster, and \nDavid Wagner. Detecting format string vulnerabilities with type quali.ers. In Proceedings of the 10th \nUsenix Security Symposium, Washington, D.C., August 2001. [38] Aleksander Slominski, Madhusudhan Govindaraju, \nDennis Gannon, and Randall Bramley. Design of an XML based interoperable RMI system : SoapRMI C++/Java \n1.1. In Proceedings of the International Conference on Parallel and Distributed Processing Techniques \nand Applications, pages 1661 1667, Las Vegas, Nevada, June 2001. [39] Tom\u00b4as Sysala and Jan Janecek. \nOptimizing remote method invocation in Java. In Proceedings of the International Workshop on Database \nand Expert Systems Applications (DEXA), pages 29 35, Aix-en-Provence, France, September 2002. [40] Raja \nVall\u00b4ee-Rai, Laurie Hendren, Vijay Sundaresan, Patrick Lam, Etienne Gagnon, and Phong Co. Soot a Java \noptimization framework. In Proceedings of the IBM Centers for Advanced Studies Conference (CASCON), pages \n125 135, 1999. [41] Adam Welc, Suresh Jagannathan, and Antony L. Hosking. Transactional monitors for \nconcurrent objects. In Proceedings of the European Conference on Object-Oriented Programming (ECOOP), \nOslo, Norway, 2004. APPENDIX A. PROXY CALCULUS FJQ Here we include more details on the explicitly-typed \ncalcu\u00adlus FJQ, introduced in Section 3, including its typing rules and operational semantics. A.1 Typing \nThe syntax of FJQ is the same as FJi Q (Figure 1), minus quali.er and set type variables . and a, plus \nexpressions coerce e. The typing rules are shown in Figure 9. We have stripped labels from expressions \nfor clarity, since they are not used. The subtyping rules and auxiliary de.nitions are the same as those \nin Figures 2 and 3. The rules are basically straightforward analogues of the inference rules. Note that \nthere are two rules for typing casts. The (Cast) rule types an upcast or a downcast, and the (SCast) \nrule types a stupid cast. The last is a tech\u00adnical device borrowed from FJ to allow all possible casts \nto be considered well-typed, which is necessary to prove type soundness via the property of type preservation \n(theorems are stated in Section 3.6). The Java compiler would reject programs containing stupid casts. \n A.2 Operational Semantics The operational semantics of FJQ are set up as an ab\u00adstract machine. Programs \nconsist of a store S and an ex\u00adpression to evaluate e, and the transition relation . maps programs (S, \ne) to programs (S ' ,e ' ). We use a call-by-value allocation-style semantics [33], in which all objects \nare al\u00adlocated and looked up in the store, rather than being sub\u00adstituted into the term. This allows \nus to model the .ow\u00adsensitivity of coercions on variables. The store essentially represents a hybrid \nof the stack and the heap. The com\u00adplete transition rules are presented in Figure 10. Since this is a \nquali.ed system, the store maps variables to quali.ed store values, which are store values h paired with \na quali.er Q. A store value is simply an object of the form new C(\u00afy), where the variables \u00afy index other \nquali.ed store values in S. Quali.ed store values are allocated by the fol\u00adlowing (TransAnnot) rule, \nwhich replaces a store value h with a fresh variable x, and then maps that variable to h in the store \nS: (S, new C(\u00afy)) . (S l{x . (nonproxy, new C(\u00afy))},x) The other computation rules always operate on \nvariables indexing the store, and so must look up the correspond\u00ading value for evaluation. For example, \nthe (TransInvoke) rule is between two variables x and y; it looks up x in the store to discover a function, \nand then continues by evaluat\u00ading the function s body e, having updated the store to map the function \ns parameter z to the actual argument pointed at by y. S(x)=(nonproxy, new C(\u00afy)) mbody(m, C) = (\u00afz, e) \n(S, x.m(\u00afy)) . (S l{z\u00af . S(\u00afy)},e[this . x]) Note that we encode freshness by not adding variables to \nthe domain of the store if they are already present; this is illustrated by the use of l. We can always \nenforce this condition using alpha conversion. All quali.ed store values that are used concretely must \nhave quali.er nonproxy, indicating that the actual value is available. These conditions match those in \nthe type rules. Relaxing a requirement in the type rules (e.g., as would hap\u00adpen for interface proxies) \nwould require relaxing it here. The (TransCoerce) rule handles .ow-sensitive coercions: (S l{x . (Q, \nh)}, coerce x) . (S l{x . (nonproxy,h)},x) Here, when a variable x is coerced, we remap x in the output \nstore so that its quali.er is nonproxy. Therefore, subsequent uses of x will not require coercions. This \nwill have little ef\u00adfect unless x was a variable in the original program. Other\u00adwise it was a constant \nexpression, which will never again be reused. Note that the (TransCoerce) rule is well-de.ned for all \nquali.ed store values, not just those with quali.er proxy; this is critical because the subtyping rule \nnonproxy = proxy employed by the type system allows non-proxies to be used wherever proxies are expected. \nWe extend the typing judgment to programs (S, e) as shown in Figure 9. Here, the (CheckState) rule requires \nthat the store S can be characterized by a G su.cient to typecheck e. Notice that the (CheckStore) rule \nonly checks values mapped to by variables in the domain of G, rather than the domain of S. This allows \nG to refer only to vari\u00adables in the transitive closure of the variables appearing in e; any other indexes \nin the store are essentially garbage, and could be removed. Also note that (CheckNewQ) returns the exact \n(dynamic) type of objects that it .nds. Because these objects could be given higher type in the program \ne, we allow T = G(x) in the (CheckStore) rule. G f e : T ;G ' G f e1 : T ;G1 '' ] G1[x . T ] f e2 : T \n' ;G ' [x . T Var Let ' G[x . T ] f x : T ; G[x . T ]G f let x = e1 in e2 : T ;G ' G f e1 : nonproxy \nN1;G1 G1 f e2 : nonproxy N2;G2 G f e0 : nonproxy N;G ' G ' f e\u00af: S\u00af; G '' G2 f e3 : T3;G3 G3 f e4 : T4;G4 \nmtype(m, N)= T\u00af1 . U1,... T\u00afn . Un T3 = TT4 = T G ' = merge(G3, G4) S\u00af= T\u00afi Ui = T for all i If Invoke \nG f if e1 = e2 then e3 else e4 : T ;G ' G f e0.m(\u00afe): T ;G '' G f e : nonproxy N;G ' .elds(N)= T\u00aff\u00af.elds({C}C \n)= T\u00aff\u00afG f e\u00af: S\u00af; G ' S\u00af= T\u00af Field New G f e.fi : Ti;G ' G f new C(\u00afe): nonproxy {C}C ;G ' G f e : nonproxy \n.D;G ' G f e : nonproxy .D;G ' .1 = subtypes(C) n ..1 = \u00d8 .1 = subtypes(C) n ..1 = \u00d8 stupid warning Cast \nSCast G f (C)e : nonproxy .C ;G ' G f (C)e : nonproxy subtypes(C)C ;G ' 1 G f e : nonproxy N;G ' G f \ne : QN;G ' e = x MakeProxy CoerceExp G f makeproxy e : proxy N;G ' G f coerce e : nonproxy N;G ' G f \nx : QN;G G=G ' [x . QN] CoerceVar G f coerce x : nonproxy N;G ' [x . nonproxy N] f M f CL \u00afCT (C)= \nclass C extends D { ... ; ... } K Tg, Sf) { super(\u00afg); this.f = f; } x\u00af: T, this : nonproxy {C}C f e \n: UU = S \u00af\u00af\u00af\u00af= C(\u00af\u00af\u00af\u00af override(m, D, T\u00af. S) .elds(D)= Tg\u00aff M Method Class \u00af\u00af\u00af f Sm(T\u00afx\u00af) { return e; \n}f class C extends D { Tf; KM } G f (Q, h): T f S :G \u00af\u00af\u00af\u00af\u00af .elds({C}C )= Tf G(\u00afx)= UU = T G f S(x): \nTT = G(x) all x . dom(G) CheckNewQ CheckStore G f (Q, new C(\u00afx)) : Q {C}C f S :G f (S, e): T f S :G G \nf e : T ;G ' CheckState f (S, e): T Figure 9: FJQ: Typing (S, e) . (S ' ,e ' ) Transitions: TransAnnot \n(S, new C(\u00afx)) . (S l{x . (nonproxy, new C(\u00afx))},x) S(x)=(nonproxy, new C(\u00afy)) mbody(m, C) = (\u00afz, e)TransInvoke \n (S, x.m(\u00afy)) . (S l{z\u00af . S(\u00afy)},e[this . x]) S(x) = (nonproxy, new C(\u00afx)) .elds({C}C ) = \u00afT \u00aff TransField \n(S, x.fi) . (S, xi) S(x) = (nonproxy, new D(\u00afy)) D = C TransCast (S, (C)x) . (S, x) TransLet  (S, let \nx = y in e) . (S l{x . S(y)},e) TransIfTrue (S, if x = x then e1 else e2) . (S, e1) x = y TransIfFalse \n (S, if x = y then e1 else e2) . (S, e2) S(x)=(nonproxy,h) TransProxy (S, makeproxy x) . (S l{y . (proxy,h)},y) \nTransCoerce (S l{x . (Q, h)}, coerce x) . (S l{x . (nonproxy,h)},x) Congruence rules: (S, e) . (S ' \n,e ' ) C-CongruenceE (S, e.m(\u00afy)) . (S ' ,e ' .m(\u00afy)) (S, e.fi) . (S ' ,e ' .fi) (S, (N)e) . (S ' , \n(N)e ' ) (S, let x = e in e2) . (S ' , let x = e ' in e2) (S, if e = e1 then e2 else e3) . (S ' , if \ne ' = e1 then e2 else e3) (S, if x = e then e1 else e2) . (S ' , if x = e ' then e1 else e2) (S, makeproxy \ne) . (S ' , makeproxy e ' ) (S, coerce e) . (S ' , coerce e ' ) (S, e\u00af) . (S ' ,e\u00af' )C-CongruenceBarE \n(S, new C(\u00afe)) . (S ' , new C(\u00afe ' )) (S, x.m(\u00afe)) . (S ' , x.m(\u00afe ' )) Figure 10: FJQ: Operational Semantics \n \n\t\t\t", "proc_id": "1028976", "abstract": "<p>A &#60;i>proxy&#60;/i> object is a surrogate or placeholder that controls access to another target object. Proxies can be used to support distributed programming, lazy or parallel evaluation, access control, and other simple forms of behavioral reflection. However, &#60;i>wrapper proxies&#60;/i> (like &#60;i>futures&#60;/i> or &#60;i>suspensions&#60;/i> for yet-to-be-computed results) can require significant code changes to be used in statically-typed languages, while proxies more generally can inadvertently violate assumptions of transparency, resulting in subtle bugs.</p> <p>To solve these problems, we have designed and implemented a simple framework for proxy programming that employs a static analysis based on qualifier inference, but with additional novelties. Code for using wrapper proxies is automatically introduced via a classfile-to-classfile transformation, and potential violations of transparency are signaled to the programmer. We have formalized our analysis and proven it sound. Our framework has a variety of applications, including support for asynchronous method calls returning futures. Experimental results demonstrate the benefits of our framework: programmers are relieved of managing and/or checking proxy usage, analysis times are reasonably fast, overheads introduced by added dynamic checks are negligible, and performance improvements can be significant. For example, changing two lines in a simple RMI-based peer-to-peer application and then using our framework resulted in a large performance gain.</p>", "authors": [{"name": "Polyvios Pratikakis", "author_profile_id": "81100266082", "affiliation": "University of Maryland, College Park, MD", "person_id": "P698422", "email_address": "", "orcid_id": ""}, {"name": "Jaime Spacco", "author_profile_id": "81100189856", "affiliation": "University of Maryland, College Park, MD", "person_id": "PP14075914", "email_address": "", "orcid_id": ""}, {"name": "Michael Hicks", "author_profile_id": "81100060959", "affiliation": "University of Maryland, College Park, MD", "person_id": "PP40023253", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1028976.1028994", "year": "2004", "article_id": "1028994", "conference": "OOPSLA", "title": "Transparent proxies for java futures", "url": "http://dl.acm.org/citation.cfm?id=1028994"}