{"article_publication_date": "10-01-2004", "fulltext": "\n The Garbage Collection Advantage: Improving Program Locality Xianglong Huang Stephen M Blackburn Kathryn \nS McKinley. The University of Texas at Austin Australian National University The University of Texas \nat Austin xlhuang@cs.utexas.edu Steve.Blackburn@anu.edu.au mckinley@cs.utexas.edu J Eliot B Moss Zhenlin \nWang Perry Cheng The University of Massachusetts, Amherst Michigan Technological University IBM T.J. \nWatson Research Center moss@cs.umass.edu zlwang@mtu.edu perryche@us.ibm.com ABSTRACT As improvements \nin processor speed continue to outpace improve\u00adments in cache and memory speed, poor locality increasingly \ndegrades performance. Because copying garbage collectors move objects, they have an opportunity to improve \nlocality. However, no static copy\u00ading order is guaranteed to match program traversal orders. This pa\u00adper \nintroduces online object reordering (OOR) which includes a new dynamic, online class analysis for Java \nthat detects program traver\u00adsal patterns and exploits them in a copying collector. OOR uses run\u00adtime \nmethod sampling that drives just-in-time (JIT) compilation. For each hot (frequently executed) method, \nOOR analysis identi.es the hot .eld accesses. At garbage collection time, the OOR collector then copies \nreferents of hot .elds together with their parent. Enhancements include static analysis to exclude accesses \nin cold basic blocks, heuris\u00adtics that decay heat to respond to phase changes, and a separate space for \nhot objects. The overhead of OOR is on average negligible and always less than 2% on Java benchmarks \nin Jikes RVM with MMTk. We compare program performance of OOR to static class-oblivious copying orders \n(e.g., breadth and depth .rst). Performance variation due to static orders is often low, but can be up \nto 25%. In contrast, OOR matches or improves upon the best static order since its history\u00adbased copying \ntunes memory layout to program traversal. Categories and Subject Descriptors D.3.4 [Programming Languages]: \nProcessors Compilers, Memory management (garbage collection)  General Terms Languages, Performance, \nExperimentation, Algorithms Keywords adaptive, generational, compiler-assisted, locality .This work \nis supported by NSF ITR CCR-0085792, NSF CCR\u00ad0311829, NSF EIA-0303609, DARPA F33615-03-C-4106, ARC DP0452011, \nand IBM. Any opinions, .ndings and conclusions ex\u00adpressed herein are the authors and do not necessarily \nre.ect those of the sponsors. Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. OOPSLA 04, Oct. 24-28, 2004, Vancouver, British Columbia, Canada. Copyright \n2004 ACM 1-58113-831-8/04/0010 ...$5.00. 1. Introduction The goals of software engineering and high performance \nare often at odds. Common wisdom holds that garbage collected languages such as Java offer software engineering \nbene.ts of reduced errors and de\u00advelopment time, but at a cost: the collector must periodically scavenge \nfor unused memory. Common wisdom also holds that explicitly man\u00adaged languages such as C offer performance \nbene.ts at a software engineering cost. In theory, programmers can free memory as soon as possible, and \nuse specialized allocators for memory ef.ciency and speed. However, C has a hidden performance cost. \nBecause it can\u00adnot move objects without violating language semantics, it requires a non-moving allocator, \nsuch as a free list. A free-list allocator places contemporaneously allocated objects in locations free \nat that time, but that are not necessarily adjacent or even nearby in memory. Java does not have this \nrestriction, and can thus use contiguous allocation to attain locality for contemporaneously allocated \nobjects, and copying collection to place objects with temporal locality closer together. Prior research \non improving locality with generational copying col\u00adlectors uses a priori static orders [13, 22], static \nclass pro.ling [7, 18], and online object instance sampling [9]. Static orders are problem\u00adatic when \ntraversal patterns do not match the collector s single order. Although for many benchmarks the locality \nof static copying orders has negligible impact, we show large differences of up to 25% in to\u00adtal time \nfor some benchmarks. In a Java just-in-time (JIT) compiler, the generality of static pro.ling is limited \nbecause it con.icts with dynamic class loading. Instance based reordering is potentially more powerful \nthan the class based orders we introduce here, since objects with locality are not necessarily connected. \nHowever, sampling space and time overheads just for the mature objects are signi.cant (6% in time for \nCecil [9]) and miss the opportunity to improve locality when the collector promotes young (nursery) objects. \nWe introduce online object reordering (OOR) which includes a low cost dynamic class analysis that drives \na generational copying collec\u00adtor [15, 21]. Previous copying collectors choose an a priori order such \nas breadth .rst to copy reachable (live) objects. This order may not match program traversal patterns, \nand thus exposes program perfor\u00admance to copying order jeopardy. The OOR collector instead uses copying \norders that match program access patterns to provide locality. OOR compiler analysis .nds hot (frequently \nexecuted) .eld ac\u00adcesses and is low cost (at most 1.9% of total time). It piggybacks on method sampling \nin an adaptive JIT compiler. The adaptive compiler in Jikes RVM uses timer-driven sampling to identify \nhot methods, and recompiles them at higher optimization levels. At compile time, OOR analysis enumerates \nthe .eld accesses in each method. During execu\u00adtion, when the adaptive compiler identi.es a hot method \n(regardless of its optimization choice), OOR analysis marks as hot the .elds the method accesses. At \ngarbage collection time, the OOR collector pref\u00aderentially copies referents of hot .elds .rst together \nwith their parent. We further improve the OOR system by decaying heat to respond to phase changes, by \nexploiting Jikes RVM static analysis to exclude cold basic blocks from the reordering analysis, and by \nusing a sepa\u00adrate copy space to group objects of hot classes together. In addition to the SPECjvm98 benchmarks, \nwe use .ve Java pro\u00adgrams from the DaCapo benchmark suite [6] that vigorously exercise garbage collection. \nExperimental results show that many programs use data structures with only one or two pointer .elds, \nand copying order does not in.uence their performance much. However, a number of programs are very sensitive \nto copying order. For example, depth\u00ad.rst order consistently improves upon breadth .rst performance by \naround 25% on a wide range of heap sizes for one program. OOR protects user programs from this source \nof potentially adverse effects, i.e., copying order jeopardy. Running time and hardware performance counter \nexperiments show that OOR matches or improves upon the best of the class-oblivious orders for each program \nby improving mu\u00adtator locality. Additional experiments show that our algorithm is ro\u00adbust across architectures, \nand not very sensitive to the policy knobs. As a .nal experiment, we explore the question: How signi.cant \nis the locality bene.t of copying collection compared to non-moving ex\u00adplicit memory management? We .rst \ndemonstrate that indeed copying collectors offer a locality advantage over a high performance mark\u00adsweep \nimplementation [4, 5]. However, mark-sweep s space ef.\u00adciency yields better total performance when heap \nspace is limited. To examine roughly the difference between explicit mark-sweep mem\u00adory management and \ncopying collection, we compare copying total time to only the mutator time of mark-sweep, thus excluding \nthe di\u00adrect cost of freeing. This measure is imperfect since continuous, im\u00admediate freeing should reduce \nthe total memory footprint and improve the locality of free-list allocations as compared to the more \nperiodic inhale/exhale pattern of mark-sweep collection. Nonetheless, the total (mutator +collector) \ntime using a copying collector is some\u00adtimes better than the mutator time alone of mark-sweep. In small \nheaps, the idealized mark-sweep does much better, because copying collection triggers more frequent collections \nand this cost dominates. However, in moderate and large heaps, the mutator locality bene.ts of contiguous \nallocation and copying collection can offer total perfor\u00admance improvements, including the cost of GC, \nof up to 15%. Since future processors will demand locality to achieve high performance, copying garbage \ncollection may soon combine software engineering with performance bene.ts. Furthermore, an OOR system \nwill pro\u00advide growing bene.ts with its adaptive online mechanisms that match object layout to past program \nusage patterns. 2. Related Work The key investigations of this work are (1) exploiting the object re\u00adordering \nthat happens during copying generational garbage collec\u00adtion [15, 21], and (2) using online pro.ling \nto collect information for controlling the copying order. Much previous research in this area considers \nnon-garbage collected languages (such as C) [7, 8, 22], or does not address the effects of copying collectors \n[12]. In other words, it neither considers nor exploits the moving of heap objects. The related work \nmost pertinent to ours falls into two categories: techniques that group objects to improve inter-object \nlocality [7, 9, 13, 22], and those that reorder .elds within an instance to improve intra-object locality \n[7, 12]. This prior work relies on static analysis or of.ine pro.ling to drive object layout decisions \nand is class-oblivious for the most part, i.e., it treats all classes the same. One can improve inter-object \nlocality by clustering together objects whose accesses are highly correlated. The work in this area differs \nin how to de.ne correlation and speci.c methods to cluster objects. Wil\u00adson et al. describe a hierarchical \ndecomposition algorithm to group data structures of LISP programs using static-graph reorganization to \nimprove locality of memory pages [22]. They found that using a two\u00adlevel queue for the Cheney scan groups \nobjects effectively. Lam et al. later conclude that hierarchical decomposition is not always effec\u00adtive \n[13]. They suggest that users supply object type information to group objects. We automatically and adaptively \nexamine .ne-grained .eld accesses to generate such class advice. Chilimbi and Larus use a continuously \nrunning online pro.ling technique to track recently referenced objects and build a temporal af.nity graph \n[9] based on the frequency of accesses to pairs of ob\u00adjects within a temporal interval. The object pair \nneed not be connected by a pointer, but must lie in the same non-nursery generation to reduce overhead. \nTheir dynamic instance-level pro.ling records in a buffer most pointers fetched from the heap. They report \noverheads of 6% for Cecil. Exploiting the timer-driven sampling, already in the adaptive optimization \nsystem of Jikes RVM, is much cheaper, while copying cannot guarantee to improve every program by at least \n6% so as to overcome instance pro.ling costs. Their algorithm copies together objects with high af.nity \nonly during collection of the old generation whereas our system reorders objects during both nursery \nand old gen\u00aderation collections. Chilimbi et al. split objects into hot and cold parts to group the hot \nparts together [7]. This technique is not fully automated and requires substantial programmer intervention. \nChilimbi et al. s clustering and coloring methods also rely on manual insertion of special allocation \nfunctions [8]. Our technique is automatic. Intra-object locality can be improved by grouping hot .elds \nto\u00adgether so that they will usually lie in the same cache line, and is most useful for objects somewhat \nbigger than a cache line. The size of hot objects in Java benchmarks is close to and rarely exceeds 32 \nbytes [10], whereas typical L1 cache line sizes are 32 or 64 bytes and L2 line sizes are 64 to 256 bytes. \nThus the performance improve\u00adment offered by .eld reordering alone is usually small. Kistler and Franz \nuse an LRU stack to track the temporal af.nity of object .elds, and they partition and reorder .elds \nbased on their af.nity graph [12]. They use a mark-sweep collector, where .eld reordering has no effect \non the object order after collection. Chilimbi et al. s .eld reordering depends on pro.ling to generate \nreordering advice [7]. The program\u00admer then follows the advice to rewrite the code and reorder .elds. \nRubin, Bodik, and Chilimbi developed a framework that attempts to pull together much prior work in this \narea [18]. Their approach in\u00advolves the following steps. (1) Produce an access trace with instance and \n.eld labels. (2) Compress the trace to .t in main memory and in\u00adclude only accesses relevant to a speci.c \ncache size and con.guration. (3) Compute the objects with the most accesses and misses. (4) Use object \nproperties (e.g., size, .eld access frequencies, .eld access cor\u00adrelations) to select optimizations. \n(5) Perform a hill-climbing search of possible .eld and object layout schemes, and model misses for each \nscheme on the compressed trace. Their framework would need signif\u00adicant changes to address moving collectors, \nand is practical only as an of.ine tool. In contrast, we exploit the reordering of objects inher\u00adent \nin copying collection and our online analysis is inexpensive and robust to phase behavior. 3. Background \nWe .rst describe how the adaptive compilation system in Jikes RVM works, and the generational copying \ncollector from the Memory Man\u00adagement Toolkit (MMTk) that we use, to set the stage to explain the online \nobject reordering system. Jikes RVM [1] is an open source high performance Java virtual ma\u00adchine (VM) \nwritten almost entirely in a slightly extended Java. Jikes RVM does not have a bytecode interpreter. \nInstead, a fast template\u00addriven baseline compiler produces machine code when the VM .rst encounters each \nJava method. The adaptive compilation system then judiciously optimizes the most frequently executed \nmethods [3]. Us\u00ading a timer-based approach, it schedules periodic interrupts. At each interrupt, the \nadaptive system records the currently executing method. Using a threshold, it then selects frequently \nexecuting methods to opti\u00admize. Finally, the optimizing compiler thread re-compiles these meth\u00adods at \nincreasing levels of optimizations. MMTk is a composable Java memory management toolkit that im\u00adplements \na wide variety of high performance collectors that reuse shared components [4, 5]. It provides the garbage \ncollectors of Jikes RVM, and we use its generational copying collector (GenCopy). A generational copying \ncollector divides the heap into two portions, a nursery containing newly allocated objects, and a mature \nspace, containing older objects [15, 21]. It further divides the mature space into two semispaces. It \ncollects the nursery frequently (whenever it .lls up), by copying reachable nursery objects into one \nof the mature semispaces. Once the mature semispace is full, at the next collection the whole heap is \ncollected, all surviving objects are copied into the empty semispace and the roles of the semispaces \nare .ipped. Since the generational collector collects the nursery separately from the mature space, it \nmust assume any pointers into the nursery are live. To .nd these pointers, the compiler inserts write-barrier \ncode, which at run time records stores of pointers from mature to nursery objects in a remembered set. \nWhen the collector starts a nursery collection, the remembered set forms part of the set of root pointers, \nwhich also consists of the stacks, registers, and static variables. It copies any referents of the root \npointers that lie in the nursery, and iteratively enumerates the pointers in newly copied objects, copying \ntheir nursery referents, until it copies all reachable nursery objects. Mature space collection proceeds \nsimilarly, except the remembered set is empty and the collector copies any uncopied object, not just \nnursery objects. This scheme generalizes to multiple generations, but we use two. We use a bounded generational \ncollector. It follows Appel s .exi\u00adble nursery [2], which shrinks the nursery as mature space occupancy \ngrows, except that the nursery never exceeds a .xed chosen bound (4MB). When mature space occupancy approaches \nthe maximum to\u00adtal heap size, GenCopy shrinks the nursery, until it reaches a lower bound (256KB) that \ntriggers mature space collection. We select this con.guration because it performs almost as well as the \nAppel nurs\u00adery [2], but has more regular behavior and lower average pause times. MMTk manages large objects \n(8KB or bigger) separately in a non\u00adcopying space, and puts the compiler and a few other core elements \nof the system into the boot image, an immortal space. Blackburn et al. include additional implementation \ndetails [4, 5]. 4. Online Object Reordering The Online Object Reordering (OOR) system is class-based, \ndynamic, and low-overhead. OOR consists of three components, each of which extends a subsystem of Jikes \nRVM: (1) static compiler analysis; (2) adaptive sampling for hot methods in the adaptive optimization \nsub\u00adsystem; and (3) object traversal and reordering in garbage collection. Figure 1 depicts the structure \nand interactions of the OOR system. When Jikes RVM initially compiles a method, we collect information \nabout .eld accesses within that method. Later, the Jikes RVM adap\u00adtive compilation system identi.es frequently \nexecuted (hot) methods and blocks using sampling (see Section 3). We piggyback on this mechanism to mark \nhot .eld accesses by combining the hot method information with the previously collected .eld accesses. \nWe then use this information during garbage collection to traverse the hot .elds .rst. The next three \nsections discuss each component in more detail. Figure 1: OOR System Architecture 4.1 Static Identi.cation \nof Field Accesses OOR analysis .rst identi.es potentially hot .elds by noting .eld ac\u00adcesses when .rst \ncompiling each method. The Jikes RVM optimiz\u00ading compiler uses a static analysis with a coldness threshold \nto mark cold basic blocks. OOR does not enumerate .eld accesses in cold blocks, and uses the compiler \ns default threshold (see Section 6.5). The compiler uses loop and branch prediction heuristics to estimate \nthe execution frequency of basic blocks in a method. For example, it marks exception handler basic blocks \nas cold, and basic blocks in loops as potentially hot. For each method, OOR analysis enumerates all the \n.eld accesses in potentially hot blocks, generating tuples of the form <class, offset>. The tuples identify \nthe class and off\u00adset of any potentially hot .eld, and OOR associates each tuple with the compiled method. \nThis analysis thus .lters out .eld accesses the compiler statically determines are cold and associates \na list of all non\u00adcold .eld accesses with each compiled method. At present, we do not perform any .eld \naccess analysis in the Jikes RVM baseline compiler. Since the Jikes RVM adaptive compilation framework \nrecompiles hot methods with the optimizing compiler, we use it to apply our analy\u00adsis selectively to \nhot methods. Jikes RVM also collects basic-block dynamic execution frequencies using a counter on every \nbranch. We believe this information can improve the accuracy of OOR analysis, although we have not implemented \nthis feature here. 4.2 Dynamically Identifying Hot Fields The Jikes RVM adaptive sampling system detects \nhot methods by pe\u00adriodically sampling the currently executing method. When the number of samples for \na method grows beyond a threshold the adaptive sys\u00adtem invokes the optimizing compiler on it. OOR analysis \npiggybacks on this mechanism. The .rst time it identi.es a hot method, it marks all the potentially hot \n.eld access for the method as hot. Each time the sampling mechanism re-encounters a hot method (regardless \nof whether the adaptive system recompiles it), it updates the heat metric for the corresponding hot .elds. \nFigure 2 shows OOR s decay mechanism for adapting to phase changes. Other policies are possible of course. \nThe high and low heat thresholds, HI and LO (default values of 100 and 30 respectively) indicate the \nhottest .eld with heat HI1 Any .eld cooler than LO is regarded as cold. Initially all .elds are cold, \nwith heat 0. When the timer goes off, the heuristic records the current sampling time, NOW(), and updates \none or more heat .elds in class for the method. This heuristic decays heat for unaccessed .elds based \non the last time the analysis updated the instantiating class, class.lastUpdate.How\u00adever, the heuristic \ndoes not decay .eld heat for all classes every sample period, since the cost would be prohibitive. Instead, \nit updates a class only when the adaptive compiler samples another method that uses a .eld instantiated \nby it. In the worst case of not strictly decaying .eld 1The units for these thresholds are sample intervals, \nwhich are ap\u00adproximately 10ms: HI .1 sec, LOW .0.3 sec. DECAY-HEAT (method) 1 for each f ieldAccess in \nmethod do 2 if POTENTIALLYHOT (f ieldAccess)then 3 hotField .f ieldAccess.f ield 4 class .hotField.instantiatingClass \n5 class.hasHotField .true 6 for each f ield in class do 7 period .NOW ().class.lastU pdate 8 decay .HI/(HI \n+period) 9 f ield.heat .f ield.heat .decay 10 if f ield.heat <LO then 11 f ield.heat =0 12 hotField.heat \n.HI 13 class.lastU pdate .NOW() Figure 2: Pseudocode for Decaying Field Heat heat for all classes, the \nOOR collector will copy an old object using obsolete hot .eld information. Since none of the hot methods \naccess this .eld, the order in which the collector copies these objects will simply be based on access \norders further back in history and should not degrade performance. If these objects never become hot \nagain, this mechanism does no harm. Otherwise, if their past accesses pre\u00addict the future, program locality \nwill bene.t. 4.3 Reordering during Garbage Collection The copying phase of the collector applies OOR \nadvice. For each in\u00adstance of a class, the collector traverses the hot .elds (if any) .rst. At class \nload time, the OOR system constructs an array for each class, with one integer representing the heat \nof each .eld in the class. Ini\u00adtially all .elds have a heat of zero. OOR analysis uses the algorithm \nin Figure 2 to set the heat value for each .eld and thus identify hot .elds to the collector. The OOR \ncollector then copies and enqueues the hot .elds .rst. Figure 3 shows how the collector copies data. \nFor a nursery collection, it begins by processing the remembered sets (these are empty in a full heap \ncollection), and then processes the roots. ADVICE-PROCESS() places all uncopied objects (line 2) in the \ncopy buffer, and updates the pointer for already copied objects. ADVICE-SCAN()) then copies all the hot \n.elds .rst (line 3), and enqueues the remaining .elds to process later. Without advice, all .elds are \ncold. We also experiment with using a hot space that segregates hot ob\u00adjects from the others to increase \ntheir spatial locality, which should improve cache line utilization, reduce bus traf.c, and reduce paging. \nWe re.ne hot objects to hot referents instances referred to by hot .elds, and hot parents instances of \nclasses that instantiate hot .elds. When copying an object, it is identi.ed as a hot parent if the hasHot-Field \nvalue of the object s class is true. Hot referents are discovered when traversing hot .elds. The hot \nspace contains all the hot objects and is part of the older space; during nursery garbage collection, \nthe collector copies into the hot space all objects that contain hot .elds and the objects to which the \nhot .elds point. During older generation collection, the collector copies objects in the hot space to \na new hot space. It always copies all other objects into a separate space in the older generation. We \ndo not need to change the write barrier to add a hot space since we always collect it at the same time \nas other objects in the older generation. Therefore, this change does not in.uence write barrier overhead \nin the mutator. An advantage of advice-directed traversal is that it is not exclusive. For those objects \nwithout advice, we can use the best static traversal order available to combine the bene.t of both methods. \nIn our current implementation, the default copy order is pure depth .rst for cold ob\u00adjects, last child \n.rst, because this static order generally generates good performance, as we will show in the following \nsection.  5. Methodology We now describe our experimental methodology, platforms, and rele\u00advant characteristics \nof the benchmarks we use. We use two method\u00adologies for these experiments. (1) The adaptive methodology \nlets ADVICE-BASED-COPYING () 1 Ob jects .EMPTYQUEUE () 2 Cold .EMPTYQUEUE () 3 4 for each location in \nRemsets do 5 ADVICE-PROCESS (location) 6 for each location in Roots do 7 ADVICE-PROCESS (location) 8 \nrepeat 9 while Ob jects.NOTEMPTY ()do 10 ADVICE-SCAN (Ob jects.DEQUEUE ()) 11 while Cold.NOTEMPTY ()do \n12 ADVICE-PROCESS (Cold.DEQUEUE ()) 13 until Ob jects.ISEMPTY () ADVICE-PROCESS (location) 1 ob j ..location \n2 if NEEDSCOPYING (ob j)then 3 Ob jects.ENQUEUE (COPY(ob j)) 4 if FORWARDED (ob j)then 5 .location .NEWADDRESS \n(ob j) ADVICE-SCAN (ob j) 1 for each f ield in ob j.f ields()do 2 if f ield.isHot(location)// advice \n3 then ADVICE-PROCESS (ob j.f ield) 4 else Cold.ENQUEUE (ob j.f ield) Figure 3: Pseudocode for Advice \nBased Copying the adaptive compiler behave as intended and is non-deterministic. (2) The pseudo-adaptive \nmethodology is deterministic and eliminates memory allocation and mutator variations due to non-deterministic \napplication of the adaptive compiler. We need this latter methodol\u00adogy because the non-determinism of \nthe adaptive compilation system makes it a dif.cult platform for detailed performance studies. For ex\u00adample, \nwe cannot determine if a variation is due to the system change being studied or just a different application \nof the adaptive compiler. In the adaptive methodology, the adaptive compiler uses non-deter\u00administic \nsampling to detect hot methods and blocks, and then tailors optimizations for the hot blocks. Thus on \ndifferent executions, it can optimize different methods and, for example, choose to inline differ\u00adent \nmethods. Furthermore, any variations in the underlying system induce variation in the adaptive compiler. \nWe use this methodology only for measuring the overhead of our system. For all other experiments, we \nuse a deterministic methodology that holds the allocation load and the optimized code constant. The pseudo\u00adadaptive \nmethodology gives a mixture of optimized and unoptimized code that re.ects what the adaptive compiler \nchooses, but is speci.ed by an advice .le from a previous run. We run each benchmark .ve times and pro.le \nthe optimization plan of the adaptive compiler for each run. We pick the optimization plan of the run \nwith best perfor\u00admance and store it in an advice .le. For the performance measurement runs, we execute \ntwo iterations of each benchmark and report the sec\u00adond. We turn off the adaptive compiler, but not the \nadaptive sam\u00adpling. In the .rst iteration, the compiler optimizes selected methods at selected level \nof optimization according to the advice .le. Before the second iteration, we perform a whole heap collection \nto .ush the heap of compiler objects. We then measure the second iteration. Thus we have optimized code \nonly for the hot methods (as determined in the advice .le). This strategy minimizes variation due to \nthe adap\u00adtive compiler since the workload is not exposed to varying amounts of allocation due to the \nadaptive compilation. We measure only the application behavior and exclude the compiler in this methodology. \nWe report the second iteration because Eeckhout et al. show that measuring the .rst iteration, which \nincludes the adaptive compiler, is dominated by the compiler rather than the benchmark behavior [11]. \nFor each experiment we report, we execute the benchmark .ve times, interleaving the compared systems. \nWe use the methodologies Benchmark loaded compiled (MB) min (MB) min srv take 0 1 many 0 1 many 0 1 \nmany jess 155 507 403 25:1 261 17:1 1 0.08 18% 40% 42% 1% 52% 47% 7% 49% 43% jack 61 331 307 22:1 231 \n17:1 3 3.15 48% 31% 22% 21% 44% 35% 34% 53% 13% javac 160 821 593 23:1 185 7:1 23 1.21 29% 34% 37% \n5% 27% 68% 6% 34% 60% raytrace 34 227 215 12:1 135 8:1 2 0.01 89% 1% 10% 55% 12% 33% 57% 14% 29% mtrt \n35 225 224 11:1 142 7:1 5 0.65 87% 2% 11% 55% 12% 33% 57% 14% 29% compress 16 99 138 8:1 99 6:1 0 \n1.20 56% 34% 10% 41% 31% 29% 43% 37% 20% db 8 92 119 6:1 82 4:1 9 1.21 4% 95% 1% 42% 53% 5% 42% 53% \n5% mpegaudio 59 270 51 4:1 3 1:1 0 0.00 76% 15% 10% 83% 5% 12% 83% 5% 12%             \n ps-fun 347 522 8602 410:1 8589 409:1 0 0.00 95% 2% 3% 25% 30% 45% 25% 30% 44% ipsixql 120 381 1777 \n105:1 1739 102:1 31 1.17 40% 3% 56% 39% 2% 59% 39% 2% 59% hsqldb 90 432 6804 76:1 6720 75:1 4 0.01 \n44% 41% 16% 50% 0% 50% 50% 0% 50% jython 175 1050 796 47:1 722 42:1 1 0.103 0% 78% 22% 1% 62% 37% 2% \n64% 34% antlr 114 719 22 18:1 5 3:1 11 1.78 68% 23% 9% 25% 26% 48% 30% 41% 28% pseudojbb 13 92 339 \n7:1 216 5:1 32 1.82 51% 26% 23% 36% 29% 35% 37% 29% 34% Table 1: Benchmark Characteristics above, and \ntake the fastest time. The variation between these mea\u00adsurements is low. We believe this number is relatively \nundisturbed by other system factors. When measuring the system overhead in the adaptive compiler, we \nbelieve the low variation from the fastest time re.ects a stable application of the adaptive compiler. \n5.1 Experimental Platform We perform our experiments on four platforms and .nd similarities across these. \nSection 7 reports on cross architecture results. For brevity and unless otherwise noted, we report experiments \non a ma\u00adchine with the following characteristics: 3.2GHz P4 The machine is a 3.2 GHz Pentium 4 with hyper-threading \nenabled and user accessible performance counters. It has a 64 byte L1 and L2 cache line size, an 8KB \n4-way set associa\u00ad tive L1 data cache, a 12K\u00b5ops L1 instruction trace cache, a 512KB uni.ed 8-way set \nassociative L2 on-chip cache, 1GB main memory, and runs Linux 2.6.0. We instrument MMTk and Jikes RVM \nto use the CPU s perfor\u00admance counters to measure cycles, retired instructions, L1 and L2 cache misses, \nand TLB (translation look-aside buffer) misses of both the mutator and collector, as we vary the collector \nalgorithm, heap size, and other features. Because of hardware limitations, each per\u00adformance counter \nrequires a separate execution. We use version 2.6.5 of the perfctr Intel/x86 hardware performance counters \nfor Linux with the associated kernel patch and libraries [17]. 5.2 DaCapo Benchmarks As part of an ongoing \neffort with our collaborators in the DaCapo project [16], we collected several memory intensive Java \nprograms for the DaCapo benchmark suite [6].2 These benchmarks are intended to exercise garbage collection \nvigorously in order to reveal collector and platform induced differences. 1. antlr: Language tool for \nconstructing complier, language rec\u00adognizer, and translators. 2. hsqldb: Database written in Java. \n3. ipsixql: Persistent XML database. 4. jython: Python interpreter written in Java. 5. postscript-fun: \nA PostScript interpreter.  5.3 Benchmark Characteristics Table 1 shows key characteristics of our benchmarks \nusing the .xed workload and adaptive methodologies. We use the eight SPECjvm98 benchmarks, .ve DaCapo \nbenchmarks, plus pseudojbb, a variant of 2A pre-release of these benchmarks may be downloaded at: http://www.cs.utexas.edu/users/speedway/dacapo/DaCapo.html \nSPECjbb2000 [19, 20] that executes a .xed number of transactions (70000), rather than running for a .xed \ntime (for comparisons under a .xed garbage collection load). The alloc columns in Table 1 indi\u00adcate the \ntotal number of megabytes allocated under adaptive and .xed GC loads respectively. The alloc:min column \nlists the ratio of total allocation to the minimum heap size in which the program executes in MMTk. Including \nthe adaptive compiler substantially increases al\u00adlocation and collector load (compare column four with \nsix, and .ve with seven). This behavior can obscure program behaviors and fur\u00adther con.rms Eeckhout et \nal. [11]. Notice that mpegaudio allocates only 3MB, and with a 4MB heap is never collected; hence we \nex\u00adclude it from the remaining experiments. Also notice that the DaCapo benchmarks place substantially \nmore load on the memory manage\u00adment system than the SPECjvm98 benchmarks. The % nursery survival column \nindicates the percent of allocation in the nursery that the collector copies. OOR can in.uence the subset \nof these objects with two or more non-null pointers. Notice that most programs follow the weak generational \nhypothesis, but that javac and ipsixql are memory intensive while not being very generational. How\u00adever, \ngenerational collectors still improve their performance [4]. The % wb take column shows the percent of \nall writes that the write barrier records in the remembered set. The remaining columns indi\u00adcate the \npercentage of objects with 0, 1, or many pointer .elds. The alloc pointers column indicates these proportions \nwith respect to al\u00adlocated objects. The scan pointers column indicates the proportions with respect to \nobjects scanned at collection time, and scan non-null pointers indicates the proportions with respect \nto non-null pointers in objects scanned at collection time. Since OOR in.uences only objects with two \nor more non-null pointers, the .nal column in Table 1 indi\u00adcates the proportion of scanned (copied) objects \nto which OOR can be applied effectively. We ran all the experiments we report here on all the benchmarks. \nFor all but four of these benchmarks, performance variations due to copying orders are relatively small. \nFor brevity and clarity, the results section focuses on programs that are sensitive to copy order, and \njust summarizes the programs where copy order has little effect.  6. Experimental Results We now present \nevaluation of our online object reordering system. We begin with results that show that the overhead \nfor the reordering analysis, including its use by the collector, adds at most 1 to 2% to total time. \nWe then show some programs are sensitive to copying order. Comparisons with OOR show that it essentially \nmatches or improves over the oblivious orders. A series of experiments demon\u00adstrates the sensitivity \nof OOR to the decay of .eld heat to respond to phase changes, the use of a hot space, cold block analysis, \nand hot method analysis. We also compare OOR with class-oblivious copying on three additional architectures. \nStatic ordering performance is not Benchmark Default OOR Overhead Heap size jess 4.39 4.43 0.84% 15MB \n20MB 25MB 30MB 35MB 40MB 45MB 50MB 1.6 jack 5.79 5.82 0.57% 3.8 raytrace 4.63 4.61 -0.59% 1.5 3.6 mtrt \n4.95 4.99 0.7% 3.4 1.4 javac 12.83 12.70 -1.05% compress 8.56 8.54 -0.2% 3.21.3    Normalized GC \nTimeNormalized Mutator L2 MissesNormalized Mutator Time Normalized Time GC Time (sec) Mutator L2 Misses \n(10^6) Mutator Time (sec) Time (sec) pseudojbb 13.39 13.43 0.36% 3 1.2 db 18.88 18.88 -0.03% 2.8 antlr \n0.94 0.91 -2.9% 1.1 2.6 gcold 1.21 1.23 1.49% 1 2.4 hsqldb 160.56 158.46 -1.3% ipsixql 41.62 42.43 1.93% \nHeap size relative to minimum heap size jython 37.71 37.16 -1.44% (a) Total Time ps-fun 129.24 128.04 \n-1.03% Heap size mean -0.19% 15MB 20MB 25MB 30MB 35MB 40MB 45MB 50MB 1.5 Table 2: OOR System Overhead \n always consistent across architectures. However, OOR consistently attains essentially the same performance \nas the best static order across these platforms. 6.1 Overhead of Reordering Analysis To explore the overhead \nof the analysis, we measure the .rst itera\u00adtion of the benchmark (where the compiler is active) with \nthe adaptive compiler on a moderate heap size (1.8 .maximum live) and pick the fastest of 5 runs. This \nexperiment performs the additional run-time work to record hot class .elds, and examines the results \nat collection 3 2.8 1.4 1.3 2.6 1.2 2.4 1.1 2.2 1 Heap size relative to minimum heap size (b) Mutator \nTime Heap size 15MB 20MB 25MB 30MB 35MB 40MB 45MB 50MB  time, but never acts on those results. Therefore, \nthe system does all the 2  work of class reordering, but obtains no bene.t from it. Table 2 com\u00ad pares \nthe original adaptive system with the augmented system. The table shows some improvements as well as \ndegradations. At worst, OOR adds a 2% overhead, but this overhead is obscured by larger variations due \nto the timer-based sampling. For the exact same pro\u00ad gram, VM, and heap size, the timer-based sampling \ncan cause varia\u00ad tions up to 5% because of the non-determinism, and this variation is 4.5 4 1.8 1.6 3.5 \n1.4 3 1.2 2.5 1 the dominant factor, not the OOR analysis. Heap size relative to minimum heap size \n6.2 Class Sensitive vs. Class Oblivious (c) L2 Mutator Misses This and all remaining sections apply \nthe pseudo-adaptive method- Heap size 15MB 20MB 25MB 30MB 35MB 40MB 45MB 50MB ology, reporting only application \nbehavior. This section compares 5 1.4 1.2  static and OOR copying orders. OOR uses a hot space (Sections \n4.3 4.5 and 6.4), the decay function described in Section 4.2, and excludes .eld accesses from cold blocks \n(Sections 4.1 and 6.5). This con.gu\u00ad ration produces the best results across all architectures. Most \nof the benchmark programs vary due to copy order by less than 4%. However, four programs (jython, db, \njess, and javac) show 4 1 3.5 3 0.8 2.5 0.6 2 variations of up to 25% due to copying order, so we focus \non them. Figure 4 (jess) and Figure 5 (jython, db, javac) compare OOR with three static, class-oblivious \norders: breadth .rst, depth .rst, and par\u00adtial depth .rst using the .rst two children (a hierarchical \norder). The .gures present total time, mutator time, mutator L2 misses (from per\u00adformance counters), \nand garbage collection time. Notice that the total time of jess and javac and the mutator L2 misses of \njython use scales different from the other benchmarks in the .gures. First consider variations due to \na priori breadth or depth .rst on db and jython (Figure 5). In db, class-oblivious depth .rst and partial \ndepth .rst using the .rst two children perform over 25% better in total time than breadth .rst copying \norder. For jess (Figure 4), partial depth .rst is more than 20% worse than breath .rst. For jython, depth \n.rst performs about 18% better than breadth .rst and partial depth .rst. Locality explains these differences \nas shown in the mutator time and L2 miss graphs. For a few other programs, partial depth .rst offers \na minor improvement (1 to 4%) over the best of breadth or depth .rst. The wide variation in performance \nis a pathology of static copying orders, and is of course undesirable. 1.5 0.4 1 Heap size relative to \nminimum heap size (d) GC Time Figure 4: OOR vs. Class-Oblivious Traversals .jessl Figures 4 and 5 show \nthat OOR is not subject to this variation and matches or improves over the best static orders. In javac \nand jess, OOR sometimes degrades mutator time by 2 to 3% which degrades the total performance by 2%. \nThe worst case for OOR on all bench\u00admarks and platforms is 4% for ipsixql on the 3.2 GHz P4. For all \nother benchmarks, OOR matches or improves over the best mutator locality and total performance. These \nresults are consistent with cache and page replacement al\u00adgorithms, among others, that use past access \npatterns to predict the future. OOR dynamically tunes itself to program behavior and thus protects copying \ngarbage collection from the high variations that come from using a single static copying order that may \nor may not match program traversal orders. Heap size Heap size Heap size 30MB 40MB 50MB 60MB 70MB 80MB \n90MB 15MB 20MB 25MB 30MB 35MB 40MB 45MB 50MB 55MB 60MB 65MB 20MB 30MB 40MB 50MB 60MB 70MB 80MB 1.6 1.6 \n18 1.5 1.5 24 17 1.4 1.4 16 22 1.3 1.3  18 13 1.1 1.1 1.1 7 12 6.5 1 1 16 1 1.2  Normalized GC TimeNormalized \nMutator L2 MissesNormalized Mutator Time Normalized Time GC Time (sec) Mutator L2 Misses (10^6) Mutator \nTime (sec) Time (sec) Normalized GC TimeNormalized Mutator L2 MissesNormalized Mutator TimeNormalized \nTime GC Time (sec) Mutator L2 Misses (10^6) Mutator Time (sec) Time (sec) Normalized GC TimeNormalized \nMutator L2 MissesNormalized Mutator TimeNormalized Time GC Time (sec) Mutator L2 Misses (10^6) Mutator \nTime (sec) Time (sec) 15 20 141.2 (a) jython Total Time (b) db Total Time (c) javac Total Time Heap \nsize Heap size Heap size 30MB 40MB 50MB 60MB 70MB 80MB 90MB 15MB 20MB 25MB 30MB 35MB 40MB 45MB 50MB 55MB \n60MB 65MB 20MB 30MB 40MB 50MB 60MB 70MB 80MB 1.5 1.1   17 22 21 20 19 18 1.08 1.06 1.4 1.3 1.2 1.1 \n16 15 14 13 1.04 1.02 1 17 0.98 16 12 1 115 0.96 11 5.1 Heap size relative to minimum heap size Heap \nsize relative to minimum heap size Heap size relative to minimum heap size (d) jython Mutator Time (e) \ndb Mutator Time (f) javac Mutator Time Heap size Heap size Heap size 30MB 40MB 50MB 60MB 70MB 80MB 90MB \n15MB20MB25MB30MB35MB40MB45MB50MB55MB60MB65MB 20MB 30MB 40MB 50MB 60MB 70MB 80MB 5 2 2160  220 200 180 \n160 140 140 1.8 1.6 1.4 1.2 1.8 120 1.6 100 1.4 1.2 80 60 18 40 120 1 1 16 Heap size relative to minimum \nheap size Heap size relative to minimum heap size Heap size relative to minimum heap size (g) jython \nL2 Mutator Misses (h) db L2 Mutator Misses (i) javac L2 Mutator Misses Heap size Heap size Heap size \n30MB 40MB 50MB 60MB 70MB 80MB 90MB 15MB20MB25MB30MB35MB40MB45MB50MB55MB60MB65MB 20MB 30MB 40MB 50MB 60MB \n70MB 80MB 5 5   0.7 0.6 0.5 0.4 0.3 3.5 3 2.5 4.5 4 3.5 3 2.5 2 4.5 4 3.5 3 2.5 2 2 1.5 1.5 1 1.5 \n1.5 1.5 0.2 1 11 1 Heap size relative to minimum heap size Heap size relative to minimum heap size \nHeap size relative to minimum heap size (j) jython GC Time (k) db GC Time (l) javac GC Time Figure 5: \nOOR vs. Class-Oblivious Traversals jython, db &#38; javacl 6.3 Capturing Phase Changes benchmark. Phase \nchange detection improves OOR total time by 25% and improves over the default depth .rst traversal by \n55%. Mutator OOR can adapt to changes within the execution of a given applica\u00adperformance is improved \nby 37% and 70% respectively (Figure 6(b)). tion. Section 4.2 describes how the decay model ensures that \n.eld Much of this difference is explained by reductions in L2 misses of heat metrics adapt to changes \nin application behavior. We now exam\u00ad50% and 61% (Figure 6(c)). Figure 7 compares OOR with and with\u00adine \nthe sensitivity of this approach. We use a synthetic benchmark, out phase change detection on jess, jython, \njavac, and db. These and phase, which exhibits two distinct phases. The phase benchmark re\u00adthe other \nbenchmarks are insensitive to OOR s phase change adaptiv\u00adpeatedly constructs and traverses large trees \nof arity 11. The traversals ity, which indicates that they have few, if any, traversal order phases. \nfavor a particular child. Each phase creates and destroys many trees and performs a large number of traversals. \nThe .rst phase traverses 6.4 Hot Space only the 4th child, and the second phase traverses the 7th child. \nIn order to improve locality further, OOR groups objects with hot Figure 6 compares the default depth \n.rst traversal in Jikes RVM .elds together in a separate copy space within the mature space, as against \nOOR and OOR without phase change detection on the phase described in Section 4.3. Figure 8 shows results \nfrom four representa\u00ad Heap size Heap size Heap size 20MB 30MB 40MB 50MB 60MB 70MB 20MB 30MB 40MB 50MB \n60MB 70MB 20MB 30MB 40MB 50MB 60MB 70MB 16 5 4 104.5 3.5 14 94 3 12 83.5 7   Mutator Time (sec) Normalized \nMutator L2 Misses 2.5 2 1.5 Time (sec) Normalized Mutator Time Mutator L2 Misses (10^6) Normalized \nTime 10 8 3 2.5 6 5 2 4 6 1.5 3 601 1 Heap size relative to minimum heap size Heap size relative to \nminimum heap size Heap size relative to minimum heap size 41 (a) phase Total Time (b) phase Mutator Time \n(c) phase Mutator L2 Misses Figure 6: Performance Impact of Phase Changes Using a Synthetic Benchmark \ntive benchmarks for OOR with and without a hot space. On average, these con.gurations perform similarly. \nHowever, in our experiments for other platforms, we found OOR with the hot space usually has slightly \nbetter results (see Figure 11(b) in Section 7). The hot space generally reduces the footprint of the \nhot objects but this bene.t is not as signi.cant as copying order. 6.5 Hot Field Analysis We now explore \nthe impact of the Jikes RVM static analysis thresh\u00adolds for basic block heat on OOR (see Section 4.1). \nThe Jikes RVM optimizing compiler assigns a heat value to basic blocks based on static loop iteration \nestimates (or counts if available) and branches. It then classi.es them as hot or cold based on a run-time \ncon.guration threshold. OOR directly uses this classi.cation to enumerate .eld ac\u00adcesses in hot basic \nblocks. The default con.guration marks the fewest blocks cold (BB1 in Figure 9). BB20 through BB150 mark \nincreas\u00adingly more basic blocks cold. Figure 9 presents the sensitivity of OOR to this threshold. Most \nof the benchmarks, including jess and javac, are fairly insensitive to it, but jython is particularly \nsensitive, with a worst case degradation of 20%. For db, when OOR marks only ba\u00adsic blocks with heat \ngreater than 20 as hot, the program has the worst performance. One possible explanation is that this \nthreshold causes OOR to distribute an important data structure between the hot and cold spaces. With \nthresholds higher and lower than 20, OOR prob\u00adably tends to put the whole data structure in one space \nor the other. Based on these results, we use the Jikes RVM default and mark as hot any basic block with \na heat greater than or equal to one. 6.6 Hot Method Analysis Finally, Figure 10 examines the sensitivity \nof the sampling frequency for selecting hot methods. Hot methods are identi.ed according to the number \nof times the adaptive optimization infrastructure samples them. Figure 10 shows OOR with sampling rates \nof 20ms, 10ms, and 5ms. More frequent sampling marks more methods as hot. OOR is quite robust with respect \nto this threshold. One possible explanation for this insensitivity is that method heat tends to be bimodal \nmethods are either cold or very hot. Another explanation is that warm methods (those neither hot nor \ncold) tend not to impact locality through .eld traversal orders.  7. Different Platforms This section \nexamines the sensitivity of OOR to architecture varia\u00adtions, including processor speed and memory system. \nWe run the same experiments as before on an three additional architectures. 933MHz PPC The Apple G4 has \na 933MHz PowerPC 7450 proces\u00ad sor, separate 32KB on-chip L1 data and instruction caches, a 256KB uni.ed \nL2 cache, 512MB of memory, and runs Linux 2.4.25. 1.9GHz AMD The 1.9GHz AMD Athlon XP 2600+ has a 64 \nbyte L1 and L2 cache line size. The data and instruction L1 caches are 64KB 2-way set associative. It \nhas a uni.ed, exclusive 512KB 16-way set associative L2 cache. The L2 holds only replace\u00ad ment victims \nfrom the L1, and does not contain copies of data cached in the L1. The Athlon has 1GB of main memory \nand runs Linux 2.6.0. 2.4GHz P4 The 2.4GHz Pentium 4 uses hyper-threading. It has a 64 byte L1 and L2 \ncache line size, an 8KB 4-way set associative L1 data cache, a 12K\u00b5ops L1 instruction trace cache, and \na 512KB uni.ed 8-way set associative L2 on-chip cache, 1 GB main memory, and runs Linux 2.6.0. 3.2GHz \nP4 The 3.2GHz Pentium 4 is con.gured identically to the 2.4GHz P4 except for the faster clock speed (see \nSection 5.1). We present a representative benchmark with variations due to locality. Figure 11 shows \njython on all four architectures. Not surprisingly, the two Intel Pentium 4 architecture graphs have \nvery similar shapes and the 3.2GHz P4 is faster. Comparing between architectures shows that the memory \narchitecture mainly dictates differences among traversal orders. The 1.9GHz AMD and 933MHz PPC are less \nsensitive to locality because they have larger and relatively faster caches compared to the P4s which \nhave higher clock speeds. Interestingly, the slower AMD processor achieves the best, performance, possibly \ndue to its large non-inclusive caches. However, on all four architectures, OOR consistently provides \nthe best performance, across all benchmarks and architectures. 8. The Copying Advantage We now present \nevidence con.rming the locality advantages of copy\u00ading. We .rst examine mutator locality by comparing \na standard copy\u00ading collector with a non-copying mark-sweep collector. We then com\u00adpare the mutator time \nof a non-copying mark-sweep collector with the total time of the copying collector to see whether the \nbene.ts of copy\u00ading can ever outweigh the cost of garbage collection. Figure 12(a) compares just the \nmutator performance of the bounded (4MB) nursery generational copying collector using OOR to a whole \nheap mark-sweep collector [5], labeled OOR and Mark-Sweep respec\u00adtively. The .gure shows mutator time \nas a function of heap size for javac, a representative program. OOR has a mutator-time advantage of around \n8-10% over Mark-Sweep due to fewer L1 misses on javac (Figure 12(b)). The L2 and TLB misses follow the \nsame trend, and this advantage holds across all of our benchmarks, ranging from a few percent on jython \nand compress, to 15% on pseudojbb and 45% on ps-fun. Our analysis con.rms a prior result [4]: it is locality \nrather than the cost of the free-list mechanism that accounts for the perfor\u00admance gap. Note that this \nresult is contrary to the oft-heard claim that non-moving collectors disturb the cache less than do copying \ncollectors. 2 2 4.5 4.5 1.8 1.8 4 41.6 1.6  Normalized Time Normalized TimeNormalized TimeNormalized \nTime Time (sec) Time (sec) Time (sec) Time (sec) Normalized Time Normalized TimeNormalized TimeNormalized \nTime Time (sec) Time (sec) Time (sec) Time (sec) 3.5 3.51.4 1.4 3 31.2 1.2 2.5 2.5 1 1 Heap size relative \nto minimum heap size Heap size relative to minimum heap size (a) jess Total Time (a) jess Total Time \nHeap size Heap size 30MB 40MB 50MB 60MB 70MB 80MB 90MB 30MB 40MB 50MB 60MB 70MB 80MB 90MB 2 32 2 32 \n1.8  1.8 28 28 30 30 26 261.6 1.6 24 24 1.4 1.422 22 20 20 1.2 1.2 18 18 1 16 1 16 11.522.53 11.522.53 \nHeap size relative to minimum heap size Heap size relative to minimum heap size (b) jython Total Time \n(b) jython Total Time Heap size Heap size 15MB 20MB 25MB 30MB 35MB 40MB 45MB 50MB 55MB 60MB 65MB 15MB \n20MB 25MB 30MB 35MB 40MB 45MB 50MB 55MB 60MB 65MB 2 2  22 22 1.8 1.8 20 20 1.6 1.4 1.6 1.4 18 16 18 \n16 14 12 1.2 14 1.2 121 1 Heap size relative to minimum heap size Heap size relative to minimum heap \nsize (c) db Total Time (c) db Total Time Heap size Heap size 20MB 30MB 40MB 50MB 60MB 70MB 80MB 20MB \n30MB 40MB 50MB 60MB 70MB 80MB 2 2  12 12 1.8 1.8 11 11 1.6 1.4 1.6 1.4 10 9 10 9 8 8 1.2 7 1 Heap size \nrelative to minimum heap size (d) javac Total Time Figure 7: Absence of Phasic Behavior in Standard \nBenchmarks We now examine the overall impact of garbage collection when the locality advantage and collection \noverhead are combined. Figure 13 compares the total execution time of the copying collector (labeled \nOOR) with the mutator time of mark-sweep (Mark-Sweep), which we regard as an approximation to the performance \nof explicit memory management. We use a standard free-list allocator [14, 4] and subtract the cost of \ngarbage collection. The approximation is imperfect. On one hand, the application does not pay the cost \nof free(). On the other hand, it does not reclaim memory as promptly as explicit mem\u00adory management does. \nIn both graphs, the performance of the copying collector is normalized against the mutator time for Mark-Sweep. \nA 1.2 7 1 Heap size relative to minimum heap size (d) javac Total Time Figure 8: OOR without Hot Space \n result less than 1 indicates that the total time for the copying collector is less than the Mark-Sweep \nmutator time. Three patterns emerge in our results. Figure 13(a) shows three rep\u00adresentative benchmarks: \npseudojbb, ps-fun, and ipsixql. ipsixql is the only outlier where the Mark-Sweep mutator actually has \nconsistently better performance than the copying collector. Seven benchmarks are like pseudojbb. In modest \nto large heaps, the locality advantage of copying garbage collection compensates for its collection costs, \nto the point where the total time of OOR is the same as the mutator time of Mark-Sweep. ps-fun represents \n.ve benchmarks, where the locality advantage is so signi.cant that OOR improves over the mutator time \n2 2 4.5 4.51.8 1.8 4 41.6 1.6  Normalized Time Normalized TimeNormalized TimeNormalized Time Time (sec) \nTime (sec) Time (sec) Time (sec) Normalized Time Normalized TimeNormalized TimeNormalized Time Time (sec) \nTime (sec) Time (sec) Time (sec) 3.5 3.51.4 1.4 3 31.2 1.2 2.5 2.5 1 1 Heap size relative to minimum \nheap size Heap size relative to minimum heap size (a) jess Total Time (a) jess Total Time Heap size Heap \nsize 30MB 40MB 50MB 60MB 70MB 80MB 90MB 30MB 40MB 50MB 60MB 70MB 80MB 90MB 2 32 2 32 20 20 1.2 1.2 \n18 18 1 16 1 16 28 28 30 30 1.8 1.8 26 261.6 1.6 24 24 1.4 1.422 22 11.522.53 11.522.53 Heap size \nrelative to minimum heap size Heap size relative to minimum heap size (b) jython Total Time (b) jython \nTotal Time Heap size Heap size 15MB 20MB 25MB 30MB 35MB 40MB 45MB 50MB 55MB 60MB 65MB 15MB 20MB 25MB \n30MB 35MB 40MB 45MB 50MB 55MB 60MB 65MB 2 2  22 22 1.8 1.6 1.4 1.8 20 20 1.6 1.4 18 16 18 16 14 12 \n1.2 14 1.2 121 1 Heap size relative to minimum heap size Heap size relative to minimum heap size (c) \ndb Total Time (c) db Total Time Heap size Heap size 20MB 30MB 40MB 50MB 60MB 70MB 80MB 20MB 30MB 40MB \n50MB 60MB 70MB 80MB 2 2 12 10 9 8 1.8 1.6 1.4 1.2 7 1 Heap size relative to minimum heap size (d) javac \nTotal Time Figure 9: Using Different Policies to Determine Cold Fields of Mark-Sweep, even in small \nheap sizes. Figure 13(b) is remarkable because it shows that for one of the largest and most realistic \nbench\u00admarks in our suite, garbage collection produces a net performance win. These results stand against \nthe conventional wisdom that garbage col\u00adlection always comes at a performance price. 9. Conclusions \nWe show that the performance of class-oblivious traversal orders can be unpredictable and expose programmers \nto variations outside of their control. We show that our online object reordering system elimi\u00adnates \ncopying order gambling. It has a negligible overhead, is amenable 12 1.8 11 11 1.6 10 91.4 8 1.2 7 1 \nHeap size relative to minimum heap size (d) javac Total Time Figure 10: Using Different Policies to \nDetermine Hot Methods to the virtual machine context, and adaptively matches or improves over the best \nstatic, class-oblivious order for a given program. Common wisdom holds that the software engineering \nbene.ts of garbage collection come with a performance penalty. We show that copying collectors have a \nlocality advantage over the free-list orga\u00adnizations of explicitly managed memory. Copying collectors \nachieve good locality by placing contemporaneously allocated objects together in memory and copying connected \nobjects together in the mature space. OOR further adapts copying order to program access patterns. Since \nfuture processors will demand locality to achieve high performance, we can look forward to a future where \ngarbage collection combines software engineering and performance bene.ts. Heap size Heap size 30MB 40MB \n50MB 60MB 70MB 80MB 90MB 20MB 30MB 40MB 50MB 60MB 70MB 80MB 1.4 1.2 6.4521.35 1.3 50 6.2 1.15 1.25 48 \n6 1.1 1.2 46  Normalized Mutator L1 MissesNormalized Mutator Time Normalized TimeNormalized TimeNormalized \nTimeNormalized Time Mutator L1 Misses (10^6) Mutator Time (sec) Time (sec) Time (sec) Time (sec) Time \n(sec) 5.8 5.6 1.15 44 1.051.1 42 1.05 40 5.4 1 1 38 5.2 0.95 0.95 Heap size relative to minimum heap \nsize Heap size relative to minimum heap size (a) jython 933MHz PowerPC Total Time (a) Mutator Time Heap \nsize Heap size 30MB 40MB 50MB 60MB 70MB 80MB 90MB 20MB 30MB 40MB 50MB 60MB 70MB 80MB 1.4  17 1.6 1.35 \n1.3 1.25 2401.516 1.4 220 15 1.2 1.3 1.2 1.1 1.15 1.1 200 180 14 13 1.05 1 12 160 1 0.95 Heap size relative \nto minimum heap size Heap size relative to minimum heap size (b) jython 1.9GHz AMD Total Time (b) Mutator \nL1 Cache Misses Heap size 30MB 40MB 50MB 60MB 70MB 80MB 90MB  Figure 12: Mutator Performance for Copying \nand Mark-Sweep 1.4 Collectors on javac 1.35 1.3 1.25 36 34 [3] M. Arnold, S. J. Fink, D. Grove, M. \nHind, and P. Sweeney. Adaptive optimization in the Jalape no JVM. In ACM Conference on Object-Oriented \nProgramming Systems, Languages, and Applications, pages 47 65, Minneapolis, MN, 1.2 32 1.15 30 1.1 1.05 \n 28 October 2000. 1 26 [4] S. M. Blackburn, P. Cheng, and K. S. McKinley. Myths and 0.95 realities: \nThe performance impact of garbage collection. In Heap size relative to minimum heap size ACM SIGMETRICS \nConference on Measurement &#38; Modeling (c) jython 2.4GHz P4 Total Time Computer Systems, pages 25 36, \nNY, NY, June 2004. Heap size [5] S. M. Blackburn, P. Cheng, and K. S. McKinley. Oil and water? 30MB \n40MB 50MB 60MB 70MB 80MB 90MB High performance garbage collection in Java with JMTk. In 1.4 1.35 1.3 \n22  1.05 17 1 16 0.95 1 1.5 2 2.5 3 Heap size relative to minimum heap size (d) jython 3.2GHz P4 Total \nTime Proceedings of the International Conference on Software 21 Engineering, pages 137 146, Scotland, \nUK, May 2004. 1.25 20 [6] S. M. Blackburn, K. S. McKinley, J. E. B. Moss, S. Augart, E. D. Berger, P. \nCheng, A. Diwan, S. Guyer, M. Hirzel, C. Hoffman, A. Hosking, X. Huang, A. Khan, P. McGachey, 1.2 19 \n1.15 18 1.1 Figure 11: Performance on Different Architectures 10. REFERENCES [1] B. Alpern et al. The \nJalape no virtual machine. IBM Systems Journal, 39(1):211 238, February 2000. [2] A. W. Appel. Simple \ngenerational garbage collection and fast allocation. Software Practice and Experience, 19(2):171 183, \n1989. D. Stefanovic, and B. Wiedermann. The DaCapo benchmarks. Technical report, 2004. http://ali-www.cs.umass.edu/DaCapo/Benchmarks. \n[7] T. M. Chilimbi, B. Davidson, and J. R. Larus. Cache-conscious structure de.nition. In ACM SIGPLAN \nConference on Programming Languages Design and Implementation, pages 13 24, Atlanta, GA, May 1999. [8] \nT. M. Chilimbi, M. D. Hill, and J. R. Larus. Cache-conscious structure layout. In ACM SIGPLAN Conference \non Programming Languages Design and Implementation, pages 1 12, Atlanta, GA, May 1999. [9] T. M. Chilimbi \nand J. R. Larus. Using generational garbage collection to implement cache-conscious data placement. In \nACM International Symposium on Memory Management, pages 37 48, Vancouver, BC, Oct. 1998. 2.2 2 1.8 1.6 \n1.4 1.2 1 0.8 (a) Total Time, pseudojbb Heap size 20MB 30MB 40MB 50MB 60MB 70MB [11] L. Eeckhout, A. \nGeorges, and K. D. Bosschere. How Java programs interact with virtual machines at the microarchitectural \nlevel. In ACM Conference on Object-Oriented Programming Systems, Languages, and Applications, pages 244 \n358, Anaheim, CA, Oct. 2003. [12] T. Kistler and M. Franz. Automated data-member layout of heap objects \nto improve memory-hierarchy performance. ACM Transactions on Programming Languages and Systems, 22(3):490 \n505, May 2000. [13] M. S. Lam, P. R. Wilson, and T. G. Moher. Object type directed garbage collection \nto improve locality. In Y. Bekkers and J. Cohen, editors, ACM International Workshop on Memory Management, \nnumber 637 in Lecture Notes in Computer Science, pages 404 425, St. Malo, France, Sept. 1992. Springer-Verlag. \n[14] D. Lea. A memory allocator. http://gee.cs.oswego.edu/dl/html/malloc.html, 1997. [15] H. Lieberman \nand C. E. Hewitt. A real time garbage collector based on the lifetimes of objects. Communications of \nthe ACM, 26(6):419 429, 1983. [16] J. E. B. Moss, K. S. McKinley, S. M. Blackburn, E. D. Berger, A. Diwan, \nA. Hosking, D. Stefanovic, and C. Weems. The DaCapo project. Technical report, 2004. http://ali-www.cs.umass.edu/DaCapo/. \n[17] M. Pettersson. Linux Intel/x86 performance counters, 2003. http://user.it.uu.se/ mikpe/linux/perfctr/. \n[18] S. Rubin, R. Bodik, and T. Chilimbi. An ef.cient pro.le-analysis framework for data-layout optimizations. \nIn ACM Symposium on the Principles of Programming Languages, pages 140 153, Portland, OR, 2002. [19] \nStandard Performance Evaluation Corporation. SPECjvm98 Documentation, release 1.03 edition, March 1999. \n[20] Standard Performance Evaluation Corporation. SPECjbb2000 (Java Business Benchmark) Documentation, \nrelease 1.01 edition, 2001. [21] D. M. Ungar. Generation scavenging: A non-disruptive high performance \nstorage reclamation algorithm. In ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software \nDevelopment Environments, pages 157 167, April 1984. [22] P. R. Wilson, M. S. Lam, and T. G. Moher. Effective \nstatic-graph reorganization to improve locality in garbage-collected systems. In ACM SIGPLAN Conference \non Programming Languages Design and Implementation, pages 177 191, Toronto, Canada, June 1991. Total \nTime Normalized To MarkSweep Mutator Total Time Normalized To MarkSweep Mutator Total Time Normalized \nTo MarkSweep Mutator 1.15 1.1 1.05 1 0.95 0.9 0.85 0.8 (b) Total Time, ps-fun Heap size 20MB 30MB 40MB \n50MB 60MB 70MB 80MB 4.5 4 3.5 3 2.5 2 1.5 (c) Total Time, ipsixql Figure 13: Garbage Collection vs. \nIdealized Mark-Sweep [10] S. Dieckmann and U. H\u00a8olzle. A study of the allocation behavior of the SPECjvm98 \nJava benchmarks. In Proceedings of the European Conference on Object-Oriented Programming, pages 92 115, \nJune 1999.   \n\t\t\t", "proc_id": "1028976", "abstract": "<p>As improvements in processor speed continue to outpace improvements in cache and memory speed, poor locality increasingly degrades performance. Because copying garbage collectors move objects, they have an opportunity to improve locality. However, no static copying order is guaranteed to match program traversal orders. This paper introduces &#60;i>online object reordering&#60;/i> (OOR) which includes a new dynamic, online class analysis for Java that detects program traversal patterns and exploits them in a copying collector. OOR uses run-time method sampling that drives just-in-time (JIT) compilation. For each &#60;i>hot&#60;/i> (frequently executed) method, OOR analysis identifies the hot field accesses. At garbage collection time, the OOR collector then copies referents of hot fields together with their parent. Enhancements include static analysis to exclude accesses in cold basic blocks, heuristics that decay heat to respond to phase changes, and a separate space for hot objects. The overhead of OOR is on average negligible and always less than 2% on Java benchmarks in Jikes RVM with MMTk. We compare program performance of OOR to static class-oblivious copying orders (e.g., breadth and depth first). Performance variation due to static orders is often low, but can be up to 25%. In contrast, OOR matches or improves upon the best static order since its history-based copying tunes memory layout to program traversal.</p>", "authors": [{"name": "Xianglong Huang", "author_profile_id": "81451600182", "affiliation": "University of Texas at Austin", "person_id": "P338849", "email_address": "", "orcid_id": ""}, {"name": "Stephen M. Blackburn", "author_profile_id": "81100547435", "affiliation": "Australian National University", "person_id": "P268028", "email_address": "", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "University of Texas at Austin", "person_id": "P157900", "email_address": "", "orcid_id": ""}, {"name": "J Eliot B. Moss", "author_profile_id": "81406593781", "affiliation": "University of Massachusetts, Amherst, MA", "person_id": "P698418", "email_address": "", "orcid_id": ""}, {"name": "Zhenlin Wang", "author_profile_id": "81100213472", "affiliation": "Michigan Technological University", "person_id": "PP39032757", "email_address": "", "orcid_id": ""}, {"name": "Perry Cheng", "author_profile_id": "81451593218", "affiliation": "IBM T.J. Watson Research Center", "person_id": "PP43116113", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1028976.1028983", "year": "2004", "article_id": "1028983", "conference": "OOPSLA", "title": "The garbage collection advantage: improving program locality", "url": "http://dl.acm.org/citation.cfm?id=1028983"}