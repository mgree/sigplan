{"article_publication_date": "10-01-2004", "fulltext": "\n A Uni.ed Theory of Garbage Collection David F. Bacon Perry Cheng V.T. Rajan dfb@watson.ibm.com perryche@us.ibm.com \nvtrajan@us.ibm.com IBM T.J. Watson Research Center P.O. Box 704 Yorktown Heights, NY 10598 ABSTRACT \nTracing and reference counting are uniformly viewed as being fun\u00addamentally different approaches to garbage \ncollection that possess very distinct performance properties. We have implemented high\u00adperformance collectors \nof both types, and in the process observed that the more we optimized them, the more similarly they behaved \nthat they seem to share some deep structure. We present a formulation of the two algorithms that shows \nthat they are in fact duals of each other. Intuitively, the difference is that tracing operates on live \nobjects, or matter , while reference count\u00ading operates on dead objects, or anti-matter . For every operation \nperformed by the tracing collector, there is a precisely correspond\u00ading anti-operation performed by the \nreference counting collector. Using this framework, we show that all high-performance col\u00adlectors (for \nexample, deferred reference counting and generational collection) are in fact hybrids of tracing and \nreference counting. We develop a uniform cost-model for the collectors to quantify the trade-offs that \nresult from choosing different hybridizations of trac\u00ading and reference counting. This allows the correct \nscheme to be selected based on system performance requirements and the ex\u00adpected properties of the target \napplication. General Terms Algorithms, Languages, Performance Categories and Subject Descriptors D.3.3 \n[Programming Languages]: Language Constructs and Fea\u00adtures Dynamic storage management; D.3.4 [Programming \nLan\u00adguages]: Processors Memory management (garbage collection); D.4.2 [Operating Systems]: Storage Management \nGarbage col\u00adlection  Keywords Tracing, Mark-and-Sweep, Reference Counting, Graph Algorithms Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA 04, Oct. \n24-28, 2004, Vancouver, British Columbia, Canada. Copyright 2004 ACM 1-58113-831-8/04/0010 $5.00. 1. \nINTRODUCTION By 1960, the two fundamental approaches to storage reclama\u00adtion, namely tracing [33] and \nreference counting [18] had been de\u00adveloped. Since then there has been a great deal of work on garbage \ncollec\u00adtion, with numerous advances in both paradigms. For tracing, some of the major advances have been \niterative copying collection [15], generational collection [41, 1], constant-space tracing [36], barrier \noptimization techniques [13, 45, 46], soft real-time collection [2, 7, 8, 14, 26, 30, 44], hard real-time \ncollection [5, 16, 23], distributed garbage collection [29], replicating copying collection [34], and \nmultiprocessor concurrent collection [21, 22, 27, 28, 39]. For reference counting, some of the major \nadvances have been incremental freeing [42], deferred reference counting [20], cycle collection [17, \n32, 6], compile-time removal of counting opera\u00adtions [9], and multiprocessor concurrent collection [3, \n19, 31]. However, all of these advances have been re.nements of the two fundamental approaches that were \ndeveloped at the dawn of the era of high-level languages. Tracing and reference counting have consistently \nbeen viewed as being different approaches to storage reclamation. We have imple\u00admented both types of \ncollector: a multiprocessor concurrent refer\u00adence counting collector with cycle collection [3, 6] and \na uniproces\u00adsor real-time incremental tracing collector [4, 5]. In this process, we found some striking \nsimilarities between the two approaches. In particular, once substantial optimizations had been applied \nto the na\u00a8ive algorithms, the dif.cult issues that arose were remark\u00adably similar. This led us to speculate \nthat the two algorithms in fact share a deep structure . In this paper we show that the two fundamental \napproaches to storage reclamation, namely tracing and reference counting, are al\u00adgorithmic duals of each \nother. Intuitively, one can think of tracing as operating upon live objects or matter , while reference \ncount\u00ading operates upon dead objects or anti-matter . For every oper\u00adation performed by the tracing collector, \nthere is a corresponding anti-operation performed by the reference counting collector. Approaching the \ntwo algorithms in this way sheds new light on the trade-offs involved, the potential optimizations, and \nthe pos\u00adsibility of combining reference counting and tracing in a uni.ed storage reclamation framework. \nWe begin with a qualitative comparison of tracing and reference counting (Section 2) and then show that \nthe two algorithms are in fact duals of each other (Section 3). We then show that all real\u00adistic, high-performance \ncollectors are in fact hybrids that combine tracing and reference counting (Section 4). We then discuss \nthe problem of cycle collection (Section 5) and extend our framework to collectors with arbitrary numbers \nof separate heaps (Section 6). Using our categorization of collectors, we then present a uniform Tracing \nReference Counting Collection Style Batch Incremental Cost Per Mutation None High Throughput High Low \nPause Times Long Short Real Time? No Yes Collects Cycles? Yes No Tracing Reference Counting Starting \nPoint Roots Anti-roots Graph Traversal Fwd. from roots Fwd. from anti-roots Objects Traversed Live Dead \nInitial RC Low (0) High RC Reconstruction Addition Subtraction Extra Iteration Sweep Phase Trial Deletion \n Figure 1: Tracing vs. Reference Counting. cost model for the various collectors, which allows their \nperfor\u00admance characteristics to be compared directly (Section 7). We then discuss some space-time trade-offs \nthat can be made in the imple\u00admentation of a collector (Section 8). Finally, we present our con\u00adclusions. \n 2. QUALITATIVE COMPARISON We begin with a qualitative comparison of the differences be\u00adtween tracing \nand reference counting collectors, and discuss how the algorithms become more similar as optimizations \nare applied. 2.1 Diametrical Opposites? The na\u00a8ive implementations of tracing and reference counting \nare quite different. The most commonly cited differences are shown in Figure 1. Reference counting is \ninherently incremental since it updates ref\u00aderence counts on each pointer write; tracing operates in \nbatch mode by scanning the entire heap at once. Tracing incurs no penalty for pointer mutation, while \nreference counting incurs a high cost every pointer write (including those to stack frames) results \nin reference count updates. Throughput for tracing collectors is correspondingly higher. On the other \nhand, reference counting collectors incur very short pause times, which makes them naturally suitable \nfor real-time ap\u00adplications. Finally, tracing collects cyclic garbage while reference counting does not. \nAs a result, when reference counting is applied to heaps that may contain cyclic garbage, cycles must \neither be collected us\u00ading a backup tracing collector [43] or with a trial deletion algorithm [6, 17, \n32]. 2.2 Convergence Our investigation of the similarities between tracing and refer\u00adence counting began \nwhen we noticed that as we optimized our reference counting and tracing collectors, they began to take \non more and more of the each other s characteristics. The incremental nature of reference counting is \ngenerally con\u00adsidered to be its fundamental advantage. However, the cost of up\u00addating reference counts \nevery time a new pointer is loaded into a register is typically much too high for high-performance applica\u00adtions. \nAs a result, some form of deferred reference counting [20], in which references from stack frames are \naccounted for separately, is used in most high-performance implementations of reference counting [3, \n19]. However, this means that when an object s reference count drops to zero, it can not be reclaimed \nimmediately, since there might be a reference from the stack that is not accounted for. As a result, \ncollection is deferred until the periodic scanning of the stack refer\u00adences. However, the result is delayed \ncollection, .oating garbage, and longer application pauses the typical characteristics of trac\u00ading collectors! \nFigure 2: Tracing vs. Reference Counting, Revisited. Now consider an implementation of a high-performance \ntrac\u00ading collector: two of its fundamental advantages are the lack of per-mutation overhead and the natural \ncollection of cyclic garbage. However, a fundamental disadvantage of tracing is that freeing of dead \nobjects is delayed until the end of a collection cycle, resulting in delayed reclamation of objects and \nlong pause times. One of the .rst optimizations that is typically applied to a tracing collector is generational \ncollection [41]. This reduces the average pause time and the delay in reclaiming objects, but it also \nintro\u00adduces per-mutation overhead thus it takes on both some of the positive and the negative aspects \nof reference counting collection. A further attempt to precisely limit the pause time is manifest in \nthe train algorithm [25], which breaks memory up into .xed-size cars which are grouped together into \ntrains. One car is collected at a time, which yields deterministic pause times, except in the pres\u00adence \nof popular objects. Furthermore, inter-car cycles can cause pathological behavior. But problematic behavior \nin the presence of cycles is a paradigmatic quality of reference counting!  3. THE ALGORITHMIC DUALS \nOur .rst-hand experience of (and frustration with) the conver\u00adgence of optimized forms of reference counting \nand tracing collec\u00adtors led directly to a deeper study of the algorithms in the hope of .nding the fundamental \nsimilarities that seem to be appearing in practice. 3.1 Matter vs. Anti-matter In order to see the connection \nbetween the two algorithms it is necessary to view them somewhat differently than usual. First of all, \nwe consider a version of reference counting in which the decre\u00adment operations are batched and performed \nat collection time instead of being performed immediately (this can be viewed as a subsequent optimization). \nSecond, we consider a version of tracing in which the tracing process reconstructs the actual reference \ncount of each object instead of simply setting a mark bit (mark bits can be viewed as a subsequent optimization \nin which the reference count is turned into a one-bit sticky reference count). Viewed in this light, \nthe parallels between the two algorithms are quite striking, and are summarized in Figure 2. Tracing \ngarbage collection traverses the object graph forward, starting with the roots, to .nd the live data. \nReference counting traverses the object graph forward, starting with the anti-roots (the set of objects \nwhose reference counts were decremented to 0), to .nd dead data. Intuitively, one can think of tracing \nas operating on matter and reference counting as operating on anti-matter . Formally, in the absence \nof cycles, reference counting computes the graph comple\u00adment of tracing. Tracing initializes object reference \ncounts to zero, and in the pro\u00adcess of graph traversal increments them until they reach the true ref\u00aderence \ncount. Reference counting initializes the reference counts to a value that is in excess of the true count, \nand in the process  (a) Schematic collect-by-tracing() initialize-for-tracing(W) scan-by-tracing(W) \nsweep-for-tracing() scan-by-tracing(W) while W=\u00d8 remove w from W .(w)..(w)+1 if .(w)=1 for each x .[v \n:(w, v).E] W .W l[x] sweep-for-tracing() for each v .V if .(v)=0 VF .VF .{v}.(v).0 new(x) .(x).0 initialize-for-tracing(W) \nW ..nd-roots() (b) Algorithm Figure 3: Tracing Garbage Collection graph traversal decrements them until \nthey reach the true reference count (ignoring the presence of cycles). Reference counting must perform \nextra graph iterations in order to complete collection of cyclic data. This is typically viewed as a \nmajor drawback of reference counting. But tracing must also perform an extra iteration, and over the \nen\u00adtire object space: the sweep phase, which collects those objects whose reference count is 0 (mark \nbit clear). While semi-space copying collectors avoid this time cost by copying only live data, this \nis in fact a simple linear space-time trade-off: a linear traversal is saved at the expense of a linear \ncost in space.  3.2 Fix-point Formulation We begin by describing the algorithm for garbage collection \nab\u00adstractly. We will then re.ne this into the tracing and reference counting duals. Throughout this paper, \nwe assume that all memory consists of .xed-size objects, and therefore ignore fragmentation [4]. We use \nthe notation [a, a, b]to denote the multiset containing two a s and one b, [a, b]l [a]=[a, a, b]to denote \nmultiset union, and [a, a, b]8 ={a, b} to denote the projection of a multiset onto a set. We characterize \nthe memory of the system formally as: V is the set of vertices in the object graph. V is the universe \nof all objects, and includes both garbage as well as objects in the free list . V does not comprise all \nof memory, since the collector must also maintain meta-data to support collection. (a) Schematic collect-by-counting(W \n) scan-by-counting(W ) sweep-for-counting() scan-by-counting(W ) while W=\u00d8 remove w from W .(w)..(w)-1 \nif .(w)=0 for each x .[v :(w, v).E] W .W l[x] sweep-for-counting() for each v .V if .(v)=0 VF .VF .{v} \nnew(x) .(x).0 dec(x) W .W l[x] inc(x) .(x)..(x)+1 assign(a, p) l .[a] [a].p dec(l) inc(p) (b) Algorithm \nFigure 4: Reference Counting Garbage Collection. Note the exact correspondence of the scan and collect \nmethods with the Tracing Algorithm in the .gure to the left. E is the multiset of edges in the graph \n(a node can have more than one pointer to the same node).  R where R8 . V is the multiset of roots of \nthe graph (in stack frames and global variables).  VF . V is the free list , the set of vertices known \nto be available for allocation.  VL =R* is the set of live vertices in the object graph: the set of \nvertices reachable from the roots.  EL ={(x, y):x . VL} is the set of live edges in the object graph. \n VD =V - VL is the set of dead vertices. In general VF . VD, but throughout this paper we assume that \ncollection is only triggered when VF =\u00d8.  VC . VD is the set of vertices that are cyclic garbage; that \nis, they are not in VL but they all have in-edges in the graph.  .(v), where v . V , is the reference \ncount of vertex v,as computed by the collector.  The object graph is the triple G =< V,E,R >. Garbage \ncollection can be expressed as a .x-point computation. A .x-point is computed for the assignment of reference \ncounts .(v) to vertices v . V . Reference counts include contributions from the root set R and incoming \nedges from vertices with non-zero refer\u00adence counts: .(x)= [x :x . R] +[(w, x):(w, x). E . .(w)> 0] (1) \nOnce reference counts have been assigned, vertices with a refer\u00adence count of 0 are reclaimed: VF =[v \n. V :.(v)=0] (2) In general, there may be many such .x-points for a given ob\u00adject graph. For example, \nconsider the case where V = {a, b}, R =\u00d8 and E ={(a, b), (b, a)}. Then .(a)=.(b)=0and .(a)=.(b)=1are \nthe two possible .x-points of the equation. The former is the least .x-point and the latter is the greatest \n.x\u00adpoint. Clearly, we wish to collect the garbage identi.ed by the least .x-point. The .x-point formulation \nis not in itself an algorithm. We now consider the solutions arrived at by garbage collection algorithms. \n 3.3 Tracing Garbage Collection The real algorithms operate on the object graph G de.ned above. In addition \nthey maintain W , the work-list of objects to be processed by the algorithm. When W is empty the algorithm \nterminates. The tracing garbage collection algorithm is shown in Figure 3(b). Initially, the reference \ncounts of all vertices are zero, either because they were created that way by new() or because their \nreference count was reset to zero during the previous sweep-for-tracing(). The initialize-for-tracing() \nfunction initializes the work-list to be the root set R. The heart of algorithm is the function scan-by-tracing(), \nwhich re\u00adconstructs the reference count of each vertex. It scans forward from each element of the work-list, \nincrementing the reference counts of vertices that it encounters. When it encounters a vertex w for the \n.rst time (.(w)=1), it recurses through all of the out-edges of that vertex by adding them to the work-list \nW . When the while loop terminates, it will have discovered all of the nodes in R * that is, the set \nof all live nodes VL and set their reference counts to be the corresponding number of in-edges in EL. \nFinally, the sweep-for-tracing() function is invoked to return the unused vertices to free storage VF \nand reset the reference counts to zero in preparation for the next collection. The only substantive difference \nbetween this algorithm and a standard tracing collector is that we are maintaining a full reference count \ninstead of a boolean .ag that tells whether or not a vertex has already been visited. However, this does \nnot change the complexity of the algorithm (although it would affect its running time in prac\u00adtice). \nAs we have already mentioned, the mark bit can be viewed as a degenerate reference count that sticks \nat one. Tracing garbage collection computes the least .x-point of the equation in equation 1. Throughout \nthe paper, we will be using schematic diagrams to show how collectors handle pointers between different \nregions of memory. In Figure 3(a) we show the structure of the tracing collec\u00adtor, which traces references \nfrom the roots to the heap and within the heap. These are shown with arrows labeled with T . This di\u00adagram \nis trivial, but as we discuss more and more complex collec\u00adtors, the diagrams provide a simple way to \nsummarize the collector architecture.  3.4 Reference Counting Garbage Collection The reference counting \ngarbage collection algorithm is shown in Figure 4(b). The horizontal lines that match up with Figure \n3(b) are there to emphasize the similarity between the component functions of the algorithm. This formulation \nof the reference counting algorithm is some\u00adwhat unusual in that decrement operations are buffered, rather \nthan being performed immediately. We are not advocating this as an im\u00adplementation, but rather as a way \nof understanding the relationship between the algorithms. Delaying the decrements shifts some of the \nwork in time, but does not affect the complexity of the algo\u00adrithm. Therefore, the dec() function adds \nvertices to the work list W , instead of the vertices being added by the initialize function. During \nmutation when a pointer is stored into memory by calling the assign function, which takes the pointer \np to be stored and the address a at which to store it. The function loads the old referent l at address \na and calls the dec(l) function which adds l to the work\u00adlist W . The address is updated, and the reference \ncount of the new referent p is incremented calling inc(p). When a collection is triggered, all increments \nhave been per\u00adformed, but the decrements since the last collection have not; they have been recorded \nin W . As a result, at the commencement of the scan function, the reference counts are over-estimates \nof the true counts. As with tracing collection, the heart of the algorithm is the scan\u00adning phase, performed \nby the function scan-by-counting() at col\u00adlection time. The algorithm scans forward from each element \nof the work-list, decrementing the reference counts of vertices that it encounters. When it discovers \na garbage vertex w (.(w)=0), it recurses through all of the edges of that vertex by adding them to the \nwork-list W . Finally, the sweep-for-counting() function is invoked to return the unused vertices to \nfree storage. The relationship between the two algorithms becomes obvious when one looks at Figures 3 \nand 4 side by side. The scan functions are identical except for the use of reference count increments \nin tracing instead of reference count decrements in reference count\u00ading, and the recursion condition \nwhich checks whether the refer\u00adence count is 1 in tracing instead of 0 in reference counting. By changing \ntwo characters in the heart of the algorithm, we have changed from tracing to reference counting! The \nother interesting difference between the collectors is that the sweep-for-counting() function does not \nreset reference counts to 0. The architecture of the simple reference counting collector is shown in \nFigure 4(a). Arrows labeled with C represent refer\u00adence counted pointers. Reference counting is performed \nboth for references from the roots to the heap and for intra-heap references. By considering the tracing \nand reference counting algorithms in this light we see that they share the same fundamental structure. \nThe only difference is that tracing begins with an underestimate of the reference counts and converges \ntoward the true value by incre\u00admenting the counts as it encounters vertices in its trace. On the other \nhand, reference counting starts with an overestimate due to the counted in-edges from objects that are \nin fact no longer live, and by processing decrement operations it converges toward the true reference \ncount.  (a) Schematic collect-by-drc(W ) R ..nd-roots() trace-roots(R) scan-by-counting(W ) sweep-for-counting() \nuntrace-roots(R) trace-roots(R) for r .R .(r)..(r)+1 untrace-roots(R) for r .R .(r)..(r)-1 drc-assign(a, \np) l .[a] [a].p if \u00acRootPointer(a) dec(l) inc(p) (b) Algorithm Figure 5: Deferred Reference Counting \nViewed in another light, while tracing computes the least .x\u00adpoint to the equation in equation 1, reference \ncounting computes the greatest .x-point. The set difference between these two solutions comprises the \ncyclic garbage.  4. TRACING/COUNTING HYBRIDS Given the similarity in structure that we discovered between \ntrac\u00ading and reference counting, we began to re-examine various collec\u00adtor architectures to understand \nthe interplay between these styles of collection. We observed that all realistic garbage collectors are \nin fact some form of hybrid of tracing and reference counting. This explains why an optimized tracing \ncollector and an opti\u00admized reference counting collector become more and more simi\u00adlar: because they \nare in fact taking on characteristics of each other. As we will see, the only fundamental differences \nbetween vari\u00adous collectors are in the division of storage, and in the assignment of responsibility for \nmaintenance of reference counts in the differ\u00adent divisions to either tracing or reference counting. \nAfter these decisions have been made, the remaining choices are implementa\u00adtion details which amount \nto making various space-time trade-offs, which we will discuss in detail in Section 8. We broadly characterize \ncollectors based on their division of storage: uni.ed heap collectors have a single heap in which all \ndata resides; split heap collectors divide memory into two regions, such as in a generational collector; \nand multiple heap collectors have more than two memory regions, as for instance distributed garbage collectors \nor the Train algorithm [25]. Note that in this analysis we consider semi-spaces as a single heap region, \nsince only one semi-space is active at a time (we are not considering concurrent collectors). The use \nof semi-spaces is one of the time-space trade-offs considered in Section 8. (a) Schematic collect-by-partial-tracing(R) \nscan-by-tracing(R) sweep-for-tracing() pt-inc(x) R .R l[x] pt-dec(x) R .R -[x] pt-assign(a, p) l .[a] \n[a].p if RootPointer(a) pt-dec(l) pt-inc(p) (b) Algorithm Figure 6: Partial Tracing 4.1 Deferred Reference \nCounting A Deferred Reference Counting (DRC) collector is a uni.ed heap collector. However, such collectors \nstill have two regions of storage, namely the heap V and the roots R. The various combi\u00adnations of tracing \nand reference counting across these two regions yield different algorithms. Deferred reference counting \nis a hybrid in which reference count\u00ading maintains the counts between heap objects. Objects with refer\u00adence \ncount 0 are maintained in a zero count table (ZCT). Root references are not counted. Instead, at collection \ntime any elements of the ZCT that are pointed to by roots are removed from the ZCT and the remaining \nZCT entries are collected. Because the root mutation rate is almost always extremely high, deferred reference \ncounting moves the cost of considering the roots from the application to the collector. But the act of \nexamining the root pointers and removing their ref\u00aderents from the ZCT is tracing: it is the act of following \na pointer forward and incrementing the reference count of the discovered ob\u00adjects. The structure of deferred \nreference counting is shown in Fig\u00adure 5(a). References from the stack to the heap are traced, while \nreferences within the heap are reference counted. The formulation of the deferred reference counting \nalgorithm is shown in Figure 5(b). The write barrier (assign function) has been modi.ed to .lter out \nany pointers where the source is not a root. Thus at collection time the increments for all intra-heap \npointers have been performed, and the decrements have been placed in the work list W . The collection \noperation itself .nds the root set and increments all of its targets. It then invokes the standard reference \ncounting col\u00adlection operations (scan-by-counting and sweep-for-counting) which compute reference counts \nand then collect objects with reference count 0. Finally, the updates to reference counts from the roots \nare undone by untrace-roots. The only difference between this algorithm and the classical DRC algorithm \nis that we do not explicitly maintain the ZCT; by defer\u00adring the decrements to the work list we discover \ngarbage objects when their reference counts drop to zero. But this is merely an implementation choice. \nSome DRC collectors use this alternative approach [3]. 4.2 Partial Tracing In a uni.ed heap, one could \nalso consider implementing the con\u00adverse of deferred reference counting, namely reference counting the \nroots and tracing the heap, which we call a partial tracing algo\u00adrithm. This is shown in Figure 6(a). \nIt is simply deferred reference counting with the role of the edges exchanged; it therefore has a du\u00adality \nwith deferred reference counting in a similar way that tracing and reference counting are themselves \nduals. The partial tracing algorithm has an assign function that has the complementary .lter on pointers: \nit only considers root pointers. For those pointers, it invokes special increment and decrement op\u00aderations \nwhose function is to dynamically maintain the root set. In essence, this set can be thought of as a reference \ncount maintained only for roots (that is, different from .). Once the root set has been maintained by \nthe write barrier, col\u00adlection is simply a matter of invoking the standard tracing algo\u00adrithm. Instead \nof .nding roots by searching (for example, scanning stacks and global variables), it simply passes the \nroot set it has been maintaining. The fundamental property of the hybridization is that when trac\u00ading \nstarts, reference counting has already caused some vertices to have non-zero reference counts, by virtue \nof their being in the set R. These virtual reference counts are then materialized by being fed as work \nlist inputs to the scan-by-tracing function. Note that the assign function is always associated with \nthe ref\u00aderence counting, rather than the tracing part of the hybrid collec\u00adtor. For DRC, the heap is \nreference counted and the barrier records pointers from the heap. For partial tracing, the roots are \nreference counted and the barrier records pointers from the stack. In gen\u00aderal, the presence of a write \nbarrier is an indication of some sort of reference count-like behavior in an algorithm. We know of no \nimplementation of partial tracing. For a lan\u00adguage run-time system, it would have singularly poor performance \nproperties. It manages to combine most of the worst aspects of both tracing and reference counting: it \nhas extremely high muta\u00adtion cost, as in pure reference counting, while gaining none of the incrementality \nof reference counting. However, in the implementation garbage-collected systems in other environments, \nwhere the operations might be performed on disks, networks, or expensive run-time structures, such an \nalgo\u00adrithm might be worthwhile. For instance, if the cost of writing a root pointer was already fairly \nhigh, and .nding the roots by scan\u00adning was very expensive, then reference counting the roots might be \nthe best solution. 4.3 Generational Garbage Collection Deferred reference counting illustrates hybridization \nwithin a uni\u00ad.ed heap. We will now consider collectors which split the heap into two regions: a nursery \nand a mature space. Split-heap collectors actually have three memory regions: the roots, the nursery, \nand the heap. All split-heap collectors have the property that they are some form of hybridization of \ntracing and reference counting, as we will now show. M (a) Nursery and Mature Space are Traced (Standard \nGenerational Collection) M (b) Nursery is Reference Counted and Mature Space is Traced M (c) Nursery \nis Traced and Mature Space is Reference Counted (Ulterior Reference Counting) Figure 7: Generational \nCollectors A generational collector effectively attenuates the allocation rate into the mature space \nby allocating objects into the nursery, and only moving objects that survive nursery collection into \nthe mature space. Average pause times are substantially reduced and through\u00adput is often increased as \nwell. 4.3.1 Tracing Generational Collection The most common split-heap collector architecture is a genera\u00adtional \ncollector [41]. In order to collect the nursery independently (without having to trace the entire mature \nspace) a generational collector maintains a remembered set of objects in the nursery that are pointed \nto by ob\u00adjects in the mature space. The remembered set may be implemented with a bitmap, card marking, \nor a sequential store buffer (SSB). The remembered set is maintained by a write barrier which is executed \nat every heap pointer update. The write barrier checks whether the pointer crosses from mature space \nto the nursery, and if so adds it to the remembered set. By now, the analogy with previous collectors \nshould be some\u00adwhat obvious: the write barrier is the assign function, which we have observed is correlated \nto the reference counting portion of a collector. The remembered set is in fact a set representation \nof non-zero reference counts the complement of the zero count table (ZCT) used in deferred reference \ncounting, except that its range is limited to the nursery. As we have seen, starting with non-zero reference \ncounts is a fundamental feature of reference counting. gen-collect-nursery() gen-nursery-initialize() \ngen-nursery-scan() nursery-sweep() gen-nursery-initialize() R ..nd-roots() RN .[r :r .R .r .VN] for each \nr .RN W .W l[r] gen-nursery-scan() while W =\u00d8 remove w from W .(w)..(w)+1 if .(w)=1 for each x .[v :(w, \nv).E] if x .VN W .W l[x] gen-assign(a, p) l .[a] [a].p if InMatureSpace(a) gen-dec(l) gen-inc(p) gen-inc(x) \nif x .VN W .W l[x] gen-dec(x) if x .VN .(x)..(x)-1 gen-collect-heap() gen-collect-nursery() collect-by-tracing() \nnursery-sweep() for each v .VN if .(v)=0 VNF .VNF .{v} else VN .VN \\{v} VH .VH .{v} .(v).0 Figure 8: \nGenerational Garbage Collection Algorithm A generational collection algorithm (for collecting the nursery) \nusing our formalism is shown in Figure 8. The assign function only considers pointers from the mature \nspace into the nursery. Decre\u00adments are performed immediately and increments are deferred by placing \nthem into a work list. While this may seem slightly coun\u00adterintuitive, recall that in our formulations \nall collectors compute reference counts, rather than just mark bits. If we only needed mark bits, we \ncould omit performing the decrements. The point of recording the increments in a work list is that they \nform a set of roots from which the tracing of the nursery proceeds (in addition to stack roots). The \ngen-nursery-initialize function takes the work list created by the generational write barrier, and adds \nthe roots that point into the nursery. Then it performs the tracing or the nursery with the gen-nursery-scan \nfunction. This function is the same as the scan\u00adby-tracing function of the basic tracing algorithm (Figure \n3), except that nodes are only added to W if they are in the nursery VN. The sweep function moves nodes \nwith non-zero reference counts rcn-collect-nursery() rcn-trace-roots() rcn-nursery-scan() nursery-sweep() \nrcn-trace-roots() R ..nd-roots() RN .[r :r .R .r .VN] for each r .RN .(r)..(r)+1 rcn-nursery-scan() while \nW =\u00d8 remove w from W .(w)..(w)-1 if .(w)=0 for each x .[v :(w, v).E] if x .VN W .W l[x] rcn-assign(a, \np) l .[a] [a].p rcn-dec(l) rcn-inc(p) rcn-dec(x) if x .VN W .W l[x] rcn-inc(x) if x .VN .(x)..(x)+1 \nrcn-collect-heap() rcn-collect-nursery() collect-by-tracing() Figure 9: Reference Counted Nursery Collection \nAlgorithm from the nursery into the mature-space, and sets their reference count to zero. This maintains \nthe invariant that between mature space collections, all nodes in the mature space have reference count \n0 (tracing invariant). To collect the whole heap (gen-collect-heap), the nursery is col\u00adlected and then \nthe standard tracing collector is invoked. The nurs\u00adery is known to be empty so only mature space objects \nare consid\u00adered. A schematic of the generational collector is shown in Figure 7(a). References from the \nroot set to both the nursery and the mature space are traced. References within both the nursery and \nthe ma\u00adture space are traced. References from the mature space to the nurs\u00adery are reference counted. \nFinally, there is a macro-edge from the nursery to the mature space (designated by the arrow labeled \nwith M ). The macro edge can be thought of as a summary reference count. Since we do not keep track of \npointers from the nursery into the mature space, the mature space can not be collected independently. \nTheir might be a reference from the nursery to any or all of the objects in the mature space. Therefore, \nthe only time when it is safe to collect the mature space is when the nursery is empty, because then \nthe reference count from the nursery to the mature space is known to be zero.  4.3.2 Generational with \nReference Counted Nursery We can now start exploring the design space for generational collectors by \nconsidering the different combinations of tracing and reference counting. We .rst consider the case where \nwe apply the dual approach (reference counting) to the nursery while applying to the same approach (tracing) \nto the mature space. The result is the algorithm in Figure 9. This algorithm performs deferred reference \ncounting for the nurs\u00adery, and maintains reference counts from the mature space into the nursery. The \narchitecture is shown schematically in Figure 7(b). To be more speci.c, we apply deferred reference counting \nto the nursery (we do not reference count updates to root pointers into the nursery). Instead, at the \nbeginning of rcn-collect-nursery, we ap\u00adply the same operation that we apply at the beginning of DRC, \nbut restricted to the nursery: we trace from the roots into the nursery, incrementing the reference counts \nof the target objects. Note that this operation is also essentially doing the same thing as the cor\u00adresponding \noperation for the generational traced nursery collector, which adds the nursery roots to the work list \nfor tracing. The rcn-nursery-scan function is simply the reference counting dual of the gen-nursery-scan \nfunction: it recursively decrements reference counts instead of incrementing them, except that it does \nnot cross into the mature space. Finally, the same nursery-sweep function is called as for the gen\u00aderational \ncollector. Unlike the DRC collector, there is no untrace operation that is performed in rcn-nursery-collect. \nThe reason is that nursery-sweep sets the reference count of objects moved into the mature space to zero, \nundoing the incrementing performed by rcn-trace-roots. Since the mature space will be traced, all reference \ncounts must start at zero and there is no need to accurately undo the effect of tracing the roots and \nincrementing their reference counts. The advantage of this collector is that cyclic garbage will even\u00adtually \nbe collected because the mature space is traced; the disad\u00advantage is that it reference counts exactly \nthose objects which are likely to have a high mutation rate (the young objects). Therefore, the expensive \nwrite barrier operations will be performed for the most frequent operations rather than the least frequent \noperations. 4.3.3 Generational with Reference Counted Heap The problems with the previous algorithm \nsuggest taking the op\u00adposite approach: tracing the nursery and reference counting the ma\u00adture space. \nThis has the advantage that mutations in the nursery are not recorded by the write barrier, but the disadvantage \nthat some additional cycle collection mechanism is required for the mature space. The algorithm is shown \nschematically in Figure 7(c). This architecture was in fact implemented recently by Blackburn and McKinley \nunder the name Ulterior Reference Counting [12]. They used a trial deletion algorithm (see Section 5.3) \nto collect cycles in the mature space. As we begin to explore more exotic permutations of tracing and \nreference counting, the power of the methodology becomes clear: it allows us to easily explore the design \nspace of possible collector architectures, and to clearly classify them relative to each other. Such \nan algorithm is shown in Figure 10. Its scan method is the same as for the standard generational collector \n(Figure 8), with the addition that references from live objects in the nursery to the ma\u00adture space must \nincrement the reference counts of the mature space objects prior to evacuation (to maintain the mature \nspace invariant that its objects contain their heap reference counts). The nursery-sweep function is \nalso similar to that of the standard generational collector, except that reference counts of objects \nbeing moved from the nursery to the mature space must have the contri\u00adbutions from the roots subtracted. \nThis is because the mature space is being collected by deferred reference counting, so once again we \nmust maintain the DRC heap invariant. urc-collect-nursery() urc-nursery-initialize() urc-nursery-scan() \nurc-nursery-sweep() urc-nursery-initialize() R ..nd-roots() RN .[r :r .R .r .VN] for each r .RN W .W \nl[r] urc-nursery-scan() while W =\u00d8 remove w from W .(w)..(w)+1 if .(w)=1 for each x .[v :(w, v).E] if \nx .VN W .W l[x] else .(x)..(x)+1 urc-nursery-sweep() for each v .VN if .(v)=0 VNF .VNF .{v} else VN \n.VN \\{v}VH .VH .{v}for each r .RN .(r)..(r)-1 urc-assign(a, p) l .[a] [a].p if InMatureSpace(a) urc-dec(l) \nurc-inc(p) urc-dec(x) if x .VN .(x)..(x)-1 else WH .WH l[x] urc-inc(x) if x .VN W .W l[x] else .(x)..(x)+1 \nurc-collect-heap() urc-collect-nursery() collect-by-drc(WH)  Figure 10: Traced Nursery and Reference \nCounted Heap The assign function performs the same write barrier as the stan\u00addard generational collector, \nexcept that pointers within the mature space are also reference counted: increments are applied eagerly, \nand decrements are placed in a separate work list for the mature space. A full collection .rst collects \nthe nursery, after which the nursery is empty and the mature space obeys the DRC invariant: the refer\u00adence \ncount of every object is the number of references from objects in the heap. Then the DRC algorithm is \ninvoked collect garbage in the mature space.   5. CYCLE COLLECTION One of the primary disadvantages \nof reference counting collec\u00adtors is that they do not .nd cyclic garbage. Therefore, an additional mechanism \nis required. So far our examination of reference counting has ignored cycles. We now consider various \nways of collecting cyclic garbage. There are two fundamental methods: a backup tracing collector, or \na cycle collector. We .rst present these algorithms in the context of a single-heap collector. 5.1 Backup \nTracing Collection The .rst and most commonly used is a reference counting collec\u00adtor that occasionally \nperforms a tracing collection in order to free cycles [43]. Reference counting is performed for both \nreferences from the roots to the heap and intra-heap references, but occasion\u00adally tracing is used over \nthe whole heap, in which case it will collect garbage cycles missed by reference counting. 5.1.1 Reference \nCounting with Sticky Counts A reference counting system with sticky counts is an extension of reference \ncounting with tracing backup. A value 2. -1is cho\u00adsen at which the reference count sticks , and ceases \nto be further incremented or decremented. This is typically done to reduce the space that must be allocated \nin the object header to a few bits. When tracing is performed, it recomputes all of the reference counts. \nLive objects whose count was stuck but now have less than 2. -1 references will have the correct count, \nand dead objects (including those that were stuck and those that were part of garbage cycles) will have \ncount 0.  5.2 Fix-point Formulation In equation 1 we presented garbage collection as an abstract .x\u00adpoint \ncomputation. Tracing computes the least .x-point VL while reference counting computes the greatest .x-point. \nThus the set dif\u00adference between these two solutions comprises the cyclic garbage VC . There may exist \nother .x-point solutions between the least (trac\u00ading) and greatest (reference counting) .x-points. If \nthere are n non\u00adtrivial strongly connected components in VC then there will be be\u00adtween n +1and 2n solutions \nto the .x-point equation, depending upon the topology of the graph. The general method for .nding the \ncyclic garbage is to .nd a subset of nodes, S .V , such that (S nR =\u00d8) .{(x, y).E :y .S .x .V -S}=\u00d8(3) \nIn other words, S is a set which contains no roots and only internal references. Therefore, there is \na .x-point solution in which for s .S, .(s)=0and S is garbage. The dif.cult question for cycle collection \nprocedures is how to choose the set S. collect-by-counting-with-cc() scan-by-counting() collect-cycles() \nsweep-for-counting() collect-cycles() S .\u00d8 trial-deletion() trial-restoration() P .\u00d8 trial-deletion() \nfor each r .P if .(r)=0 P .P \\{r} else try-deleting(r) try-deleting(v) if v .S S .S .{v} for each w \n.[x :(v, x).E] .(w)..(w)-1 try-deleting(w) trial-restoration() for each r .P try-restoring(r) try-restoring(v) \nS .S \\{v} if v .S if .(v)> 0 restore(v) else for each w .[x :(v, x).E] try-restoring(w) restore(v) for \neach w .[x :(v, x).E] .(w)..(w)+1 if w .S restore(w) assign-cc(a, p) l .[a] [a].p dec(l) inc(p) inc(x) \nif x =null .(x)..(x)+1 P .P \\{x} dec(x) if x =null W .W l[x] P .P .{x}  Figure 11: Algorithm for Reference \nCounting with Cycle Col\u00adlection by Trial Deletion.  5.3 Reference Counting with Trial Deletion We now \nconsider reference counting with cycle collection by trial deletion rather than with a backup tracing \ncollector. In the trial deletion we start with a node x, which we suspect to be part of a garbage cycle, \nand consider the set S = x * the set of all nodes reachable from x.If x is part of a cycle, then all \nnodes of the cycle are reachable from x. Therefore, the cycle is a subset of x * . We decrement the internal \nreference count to get the external reference count of each node. If we .nd any node has an external \nreference count greater than zero, we remove it from the set and restore all the reference counts for \nits children, since this node is now external to the set. We do this until no more nodes with non\u00adzero \nexternal reference count are left in the set. If the set is not null, we have found a set of garbage \nnodes. There remains the issue of how to choose the nodes x from which we start the trial deletion procedure. \nFor example, the algorithm of Bacon and Rajan [6] produces a complete set of candidates (if trial deletion \nis performed on all candidates then all cyclic garbage will be found) while employing a number of heuristics \nto reduce the number of candidates. The algorithm is shown in Figure 11. During mutation, the al\u00adgorithm \nmaintains a set P of purple vertices, those that are po\u00adtentially roots of cyclic garbage. A vertex becomes \npurple when its reference count is decremented; it ceases to be purple when its reference count is incremented. \nAt collection time, purple vertices with non-zero reference counts are considered as the potential roots \nof cyclic garbage. Trial deletion is then performed, with the set S representing those vertices that \nhave been marked gray , or visited by the algorithm. Finally, if trial deletion gives rise to a region \nof vertices with reference count 0, those vertices will be reclaimed by sweep(). Otherwise, the reference \ncounts are restored. Other algorithms in this family include those of Christopher [17] and of Mart\u00b4inez \net al. [32].  6. MULTI-HEAP COLLECTORS So far we have discussed whole-heap and generational garbage \ncollection systems. We now extend our analysis of garbage collec\u00adtion to multiple heaps, which may be \ntreated asymmetrically (as in generational systems) or symmetrically. Multi-heap garbage col\u00adlection \nwas pioneered by Bishop [10] for the purpose of allowing ef.cient collection of very large heaps that \ngreatly exceeded the size of physical memory. Multi-heap systems generally partition the heap in order \nto col\u00adlect some regions independently of others. The bene.ts are reduced pause times and increased collector \nef.ciency by preferentially col\u00adlecting regions with few live objects. Together, the duality of tracing \nand reference counting, its ex\u00adtension to multiple heaps, and the approaches to cycle collection provide \nan intellectual framework in which we can understand the inter-relation of fundamental design decisions \nand their algorithmic properties. 6.1 Ubiquitous use of Reference Counting As is well known, reference \ncounting is fundamentally incre\u00admental while tracing is not. However, we claim that any algorithm that \ncollects some subset of objects independently is fundamentally making use of reference counting. Reference \ncounting allows one to collect an object x without consulting other objects. Similarly, incremental collection \nalgo\u00adrithms allow one to collect a set of objects X without consulting some other set of objects Y . \n(Here, we are referring to the class of collectors that incrementally collects the heap by scavenges \na well\u00adde.ned portion of the heap.) Thus the only issue is the granularity at which reference counting \nis performed. We use the generic term macro-node to refer to a collection of objects that typically serves \nas a unit of collection. We have already seen that remembered sets are a reference count\u00adlike abstraction. \nThus generational collectors keep reference counts for heap to nursery references. However, there is \nalso a nursery\u00adto-heap reference count, although it is implicit. By considering the nursery and the mature \nspace as two macro-nodes, there is a macro\u00adnode edge from the nursery to the mature space. In other words, \nthe mature space macro-node has at least a reference count of at least one even if there are edges from \nthe root set. This implies that the mature space may not be collected independently from the nursery. \nInstead, we must .rst collect the nursery and move all live objects into the heap (at which point, the \nnursery macro-node disappears and the mature space macro-node s count drops to zero). Alter\u00adnatively, \nwe can perform a single, uni.ed collection of the heap and the nursery by temporarily considering them \nas a single macro\u00adnode. Coalescing the macro-nodes eliminates the macro-node edge and is sensible since \ntheir internal edge type are both of the tracing .avor. A macro-node edge summarizes the fact that there \nmay be edges between the constituent objects of the two macro-nodes. Fundamentally, there are two ways \nof collecting cycles: (1) move all of the objects into a single heap and trace it, or (2) perform a trial \ndeletion algorithm in which cyclic garbage is (logically) moved into a single region which is then entirely \ndiscarded. Moving partici\u00adpants of a cycle into a single heap does not imply that there must only be \none such heap. For instance, it may be possible to statically or dynamically partition objects to avoid \nsuch references. 6.2 Object Relocation Multi-heap collectors group objects into macro-nodes (variously \ncalled windows, cars, trains, regions, increments, and belts). In order to perform collection, these \nalgorithms copy objects from one macro-node to another. However, though reference counts can be used \nto detect that an object is live (or dead), direct pointers preclude object relocation without traversing \nthe entire heap. Indirect pointers allow reloca\u00adtion without the space cost of remembered sets but pay \nthe run-time cost of indirection and the space cost of both the indirection object and the fragmentation \nit may create. Read-barrier techniques typi\u00adcally treat every object as its own indirection object, except \nwhen it has actually been moved. This provides .exibility at the expense of read-barrier execution, and \nstill suffers from fragmentation induced by indirection objects. Remembered sets is the other approach \nto allowing relocation. They avoid the run-time cost of a read barrier while allowing incre\u00admental relocation \nand compaction, but the object relocation and the update of the pointers from its remembered set must \nbe performed atomically, which limits the level of incrementality. In particular, when there are many \nreferences to a single object, remembered sets suffer from the popular object problem. The space cost \nof the remembered set is high because there are many incoming point\u00aders, and the incrementality is poor \nbecause an arbitrary number of pointers must be updated in a single atomic step.  6.3 The Train Algorithm \nHudson and Moss designed an algorithm for garbage collection which later came to be know as the Train \nalgorithm [25]. Selig\u00admann and Garup found and .xed a small .aw in the algorithm and implemented it [37]. \nThe primary purpose of the Train algorithm is to reduce the pause time associated with the collection \nof the Mature Object Space. It is assumed the Train is a generational system: there is a nursery which \nkeeps the recently created objects and promotes the objects found during its collection.  The train \nalgorithm divides the Mature Object Space (MOS) into cars of .xed size. During the collection of the \nMOS one car is collected at a time making the train algorithm incremental at the level of a car. Thus \nthe pause time requirements determine the size of the cars. The cars are organized into trains of variable \nsize. Both the cars in a train and the trains themselves are ordered. When an object is moved from the \nnursery to the MOS, it is generally moved to the end of .rst train, or to the second train if the .rst \ntrain is in the midst of being collected. Collection is always done on the .rst train. If there are no \nex\u00adternal pointers to the .rst train (from roots or other trains), then all the objects in the train \nare garbage and the whole train is collected. If not, the .rst car of the .rst train is examined. If \nthere are no incoming pointers (in the remembered set), then the car can be col\u00adlected. If there are \nobjects with pointers only from later cars in the .rst train, then they are moved to the last car which \npoints to them, or, if there is not enough space in the last car, into any later car. If necessary, a \nnew car is created for the object. If there are pointers from later trains, then the object is moved \nto a later train. The best choice would be to move it to the last train that has pointers to this object. \nIf there is a pointer to the object from outside the MOS (that is, from the nursery), then the object \nis moved to a later train. After this is done with all the objects in the current car with pointers from \noutside, there would be no pointers from outside the car, and so any remaining objects are garbage and \nthe whole car can be collected. After this is done with all the cars in the .rst train, all the external \npointers to the train will be gone, and the whole train can be collected. For this to work, the algorithm \nmaintains remembered sets of pointers to objects in each car from later cars in the same train and from \nobjects in later trains, and from outside the MOS. The pointers from earlier trains and earlier cars \nneed not be remembered since they will be collected before this car is collected. 6.3.1 The Train as \nHybrid We now consider the train algorithm from our perspective as shown in Figure 12. Obviously it has \na tracing component, since tracing is performed within each car. However, there is also refer\u00adence counting \ncomponent since there are remembered sets to han\u00addle inter-car references. The train algorithm also has \nthe interesting feature that some ref\u00aderence counts are encoded positionally: pointers to subsequent \ncars and cars from subsequent trains are not recorded in remembered sets. Each car can be considered \nas a supernode aggregating ob\u00adjects and a train as a supernode of cars. The macro-node counts are induced \nby the links from earlier to later cars of the same train and from earlier to later trains. As in the \ngenerational case, the macro-node edges are directly re.ected in the train algorithm. For example, the \n.rst train as a whole can be collected because there are no root or remembered set references after processing \nall the cars and because the macro\u00adnode count of the .rst train is zero. 6.3.2 Cycle Collection in the \nTrain Algorithm The hybridization in the train algorithm is especially apparent because it suffers from \none of the fundamental problems of refer\u00adence counting, namely cycle collection. The train algorithm \nworks well with intra-car cycles since cars are collected with tracing. But inter-car and inter-train \ncycles can cause signi.cant problems. But this is unsurprising as these are exactly the cycles at the \nmacro-node level, which is reference counted rather than traced. In the multi-heap collectors, such as \nthe train algorithm, we use the same procedure. For each node in a train, we keep a list of pointers \nto it from nodes in the later trains (remembered sets). We collect the .rst train in the sequence of \ntrains. If there are no point\u00aders in the list, and no pointers from the root, then the set of nodes in \nthis train satisfy the condition in equation 3 and therefore can be collected. Thus we can view the set \nof nodes in a train as S in our discussion in Section 5.2. The list of pointers from later trains can \nbe viewed as a measure of external reference counts to S. If however, a node x in train 1 is being pointed \nto by a node y in train n, then we move x to train n. This is equivalent to trial dele\u00adtion from the \npoint of view of train n, since the pointer from y to x is no longer part of any remembered set. At the \nsame time, from the point of view of train 1, it corresponds to the restoration step of the trial deletion \nalgorithm, since we have an external pointer to x, and therefore we removed it from the set corresponding \nto train 1. After we have removed all the externally referenced nodes from train 1, the remaining nodes \nare garbage and are collected. In actual practice we collect a car at a time, rather than the whole train. \nBut that is done only to limit the pause time, and does not essentially change the logic of the algorithm. \nIf x and y are part of a garbage set S, and train n is the highest numbered train containing nodes that \ncan reach x, then the set S will be collected when train n is collected. Thus the train algorithm, and \ntrial deletion algorithm are both ways of .nding the set S that satis.es the condition in equation 3. \n  6.4 The Older-First Algorithm In [40], Stefanovi.c et al. advocated a collector which scavenges older \nobjects before the youngest ones so that the young objects are more likely to die. In the extreme case, \ntheir oldest-only collector will always collect some subset of the oldest objects. However, it will copy \nold, live objects many times. Instead, they propose the older-.rst collector (Figure 13) which sweeeps \nthrough the heap, collecting groups of objects from the oldest to the youngest group. Figure 14: Schematic \nof Lang s Distributed GC Algorithm Because of the sweep, recently allocated objects will be collected \nat least once before the oldest objects are reconsidered. Because older objects are collected .rst, the \nremembered sets in these collectors record references from older regions to younger objects, unlike a \ntraditional generational collector. Unlike the train collector, there are no macro-nodes other than the \nwindows. Because cyclic garbage can permanently span mul\u00adtiple macro-nodes and be permanently uncollected, \nthis algorithm is incomplete. In contrast, all cyclic garbage in a train algorithm eventually is promoted \nto a train that is otherwise dead at which point the entire train is collected en masse. 6.5 Distributed \nGarbage Collection In [29], Lang et al. describe a garbage collector suitable for a dis\u00adtributed system \nas illustrated in Figure 14. Each node in the system performs tracing which conservatively detects garbage. \nHowever, cyclic garbage that spans more than one node will never be col\u00adlected. They solve this with \nthe concept of groups of processors, which correspond to our notion of macro-nodes. By using larger groups, \nall garbage will be eventually collected. In practice, a node may choose to not participate in a particular \ngroup collection. Re\u00adducing the group dynamically does not compromise correctness as long as the notion \nof exterior references is appropriately adjusted. 6.6 The Log-Structure Filesystem It is instructive \nto consider how the implementation of a garbage collector changes as the trade-offs between operations \nchange. Log\u00adstructured .lesystems [35] implement a Unix .lesystem by writing updated .lesystem data and \nmetadata sequentially to the disk. The Unix .lesystem is a reference-counted directed acyclic graph (hard \nlinks can create acyclic cross-edges). As .les are overwritten, data earlier in the log becomes dead. \nTo reclaim this data, cleaning (garbage collection) is performed. Cleaning is performed on .xed-size \nincrements called segments: some number of segments are compacted at a time. However, the performance \nof the system is critically dependent on the quality of the cleaning algorithm. In order to achieve good \nperformance, a second level of reference counting is performed, treating the segments as macro-nodes \n(this is called the segment usage table ). In addition, the age of each segment is recorded. The collector \nthen tries to clean old segments with low reference counts effectively dynamically selecting a nursery. \nSuch an approach is practical for .lesystems because the over\u00adheads are large enough that the tradeoffs \nchange. In log-structured .lesystems, all pointers (inode numbers) are followed indirectly in order to \nallow the inodes themselves to move as their changed ver\u00adsions are appended to the log. Therefore, there \nis no need to .x the pointers from other seg\u00adments, and consequently there is no need for remembered \nsets. In addition, the write barrier is executed for disk block operations, so the additional overhead \nof maintaining a second reference count is trivial. Thus we see that obviously bad garbage collection \nalgorithms may work very well when garbage collection is applied to other domains than language run-time \nsystems. 6.7 Other Multiple Heap Collectors There are other potential bases for splitting the heap. \nShuf et al. allocate objects of a proli.c type (high allocation rate) separately from those of a non-proli.c \ntype [38]. Optimizations are used to reduce the overhead of the remembered set between the two regions. \nIt is like the distributed algorithm in that there are no macro-node edges. The connectivity-based algorithm \nuses static analysis to obviate the write barriers so that no remembered sets are required [24]. Instead \nthe macro-nodes and the macro-node edges are computed online to form a macro-node DAG. Whenever a particular \nmacro\u00adnode needs to be collected, all its predecessors (transitively) must be collected at the same time. \nThe Beltway collector by Blackburn et al. generalizes various copying collectors including the tracing \ncollector, generational trac\u00ading collector, and older-.rst collectors [11]. Like the train algo\u00adrithm, \nthere are two levels: belts (like trains) and increments (like cars). However, the macro-node edges between \nincrements of the same belt follow the order found in the older-.rst collector. Be\u00adcause of this ordering, \nthere is a potential problem with cyclic garbage which is solved by stipulating that the oldest belt \nbe com\u00adposed of a single (potentially large) increment. Additionally, aside from the degenerate oldest \nbelt, the belts are not macro-nodes be\u00adcause a belt is never discarded as a whole.  7. COST ANALYSIS \nFor each collector, we analyze the cost in a common framework. This allows precise comparison of the \nstrengths and weaknesses of each algorithm with respect to a given combination of storage availability \nand application characteristics. We analyze the cost per collection ., the frequency of collection f, \nand the total cost imposed by the garbage collector t , including both collection and collector code \ninserted into the mutator (such as write barriers). In general, we make steady state assumptions about \nthe mutator: in particular, that the allocation rate and fraction of the heap that is garbage are constants. \nNaturally these are unrealistic assumptions, but they allow us to quantify the collectors with a reasonable \nnum\u00adber of variables, and provide a solid foundation for comparing the characteristics of the different \ncollectors. 7.1 Cost Factors We analyze the cost of each collector, including constant factors. However, \nwe will not specify the coef.cients for each parameter, since this would make the formulae unwieldy. \nThe reader should be aware that these are real costs with implicit coef.cients, rather than big-Oh notation. \nThe cost of a collector X is characterized with the following .ve quantities: .(X) is the time required \nfor a single garbage collection in seconds;  s(X) is the space overhead in units of m (de.ned below) \nwords for the collector meta-data;  f(X) is the frequency of collection in hertz;  \u00b5(X) is the mutation \noverhead as a fraction of the applica\u00adtion running time; and  t (X)is the total time overhead for collection. \nIf a program in isolation takes 1 second to execute, and t (X)=0.5, then the same program running with \ncollector X takes 1.5 seconds to execute. the program Quantities that are not parameterized by the collector \nname, such as \u00b5E or VL, are invariant across all collector types. 7.2 Collector-Independent Parameters \nTo analyze the performance of the collectors, we de.ne the fol\u00adlowing additional terms: m is the (.xed) \nsize of each object, in words. ' Mis the size of memory, in m-word objects. M=mM is the size of memory \nin words. . is the object size in bits and .' = ./m is the word size in bits. Because a word must be \nlarge enough to hold the address of any word, we also have .' =llog2 M'l. a is the allocation rate, \nin objects/second.  E is the pointer density, that is the average number of non-null pointers per object; \n \u00b5R is the root mutation rate in writes/second.  \u00b5E is the edge mutation rate in writes/second.  .(v)is \nthe reference count of v.  For sets and multisets, we use script letters to denote cardinality. For \nexample, VL =|VL|is the number of live vertices. Note that while the set of live vertices VL is always \ncollector\u00adindependent, the total number of vertices V and the number of dead vertices VD are both collector-dependent. \nFor collector X, V(X)=M-s(X) (4) and the free memory available after collection is VD(X)=V(X)-VL (5) \n also, since we are assuming a pointer density of E it follows that EL =EVL and ED(X)=EVD(X). 7.3 Total \nTime The total time cost of collection is generally t (X)=f(X).(X)+ \u00b5(X). (6) For each collector we will \nde.ne the cost of the component terms, and then present an equation for the total cost that is expressed \nin terms of collector-independent parameters. This allows direct com\u00adparison of the different algorithms. \nThe actual cost of collection operations is dependent on the par\u00adticular implementation and the hardware/software \nplatform upon which it runs. Therefore, we convert the abstract component operations into time via an \nn-ary linear function with implicit coef.cients denoted by L(...). For example, in a mark-sweep collector, \nthere is a cost for each root, mark cost for each live vertex, a mark-check cost for each live edge, \nand a sweep-cost for all vertices. So the time cost is L(R, VL, EL, V). 7.4 Uni.ed Heap Collectors We \nbegin with a cost analysis of the simple tracing and reference counting algorithms, and then examine \nthe various uni.ed-heap hy\u00adbrid algorithms. void mark(Object obj) { do { obj.mark(); Object cdr .null; \n for (Object p: obj.referents()) if (p = null &#38;&#38; \u00acp.isMarked()) if (cdr = null) cdr .p; else \nmark(p); obj .cdr; }while (obj = null); } Figure 15: Optimization of traversal stack space during the \nmark phase.  7.5 T: Tracing We begin by discussing the space and time costs for the simple tracing garbage \ncollection algorithm; these formulae form the basis of subsequent trace-based collector analyses. 7.5.1 \nSpace Cost There are two fundamental sources of space overhead in tracing collection: the mark bits and \nthe stack for the recursive traversal of the object graph. While pointer reversal techniques [36] exist \nthat allow the elimination of the latter overhead, this is a signi.cant space-time trade-off since it \nmeans more writes and more traversal. In this paper, to avoid an explosion of alternate cost models, \nwe will assume that pointer reversal is not used, while noting that it is an option. The space cost for \nthe traversal stack is proportional to the depth of the object graph. This is typically viewed as problematic \ngiven the existence of long linked structures. However, we argue that with a few simple optimizations \nwhich have the .avor of tail-recursion elimination, the traversal depth can be greatly reduced at very \nlittle cost. Consider the code in Figure 15. The mark(obj) function has been modi.ed slightly so that \nits parameter is known to be non-null and unmarked. The loop over the referents of obj stores the .rst \nnon-null pointer to an unmarked object that it encounters in the variable cdr. If more non-null unmarked \nreferents are discovered, the mark(p) call recurses to process them, consuming another stack frame. However, \nif there is at most one non-null unmarked referent, there is no recursion. The function either returns \nif there is no non\u00adnull unmarked referent, or if there is exactly one it handles the cdr pointer via \ntail-recursion elimination. As a result, both singly-and doubly-linked lists will have a re\u00adcursion depth \nof 1: singly-linked lists because there is only one referent, and doubly-linked lists because one of \nthe two referents is guaranteed to have been previously marked. We therefore de.ne D' as the traversal \ndepth of the object graph at collection time, that is the depth of the recursion stack required for traversing \nthe live object graph after the above optimizations have been applied. The space cost for the mark phase \nwill then be proportional to D'. In a system that works with interior pointers, the space is sim\u00adply \nD ' pointers. In a system without interior pointers, a cursor into the object being traversed must be \nseparately maintained. The space cost D, measured in objects, of the traversal stack is therefore D ' \nD= (7) m or, in a system without interior pointers, ' () Dllog2 ml D= \u00b71+ (8) m. For programs whose data \nstructures are tree-like, the traversal depth will be logarithmic rather than linear in the number of \nob\u00adjects. For more general graph structures, the depth is less pre\u00addictable. Since Dis in general not \npredictable, and it is undesirable to reserve V(T)words for the traversal stack, most collectors in fact \nuse a .xed-size pre-allocated traversal stack. When the stack over.ows, an alternative method is used. \nWhile pointer reversal is asymptotically better, in practice it is often preferable to use a sim\u00adple \nO(n 2)algorithm in which the heap is simply rescanned when the recursion stack over.ows. 7.5.2 Generic \nSpace Formula We now present a generic formula for space overhead that can be specialized to a number \nof collectors, including tracing. We generically assume that bbits are required for the reference count \n. If b =1, it is a mark bit; if b = . ' , it is a full-word reference count; if 1<b<. ' , it represents \na trade-off between these extremes. For some collector Xthat uses bbits per object and has a traver\u00adsal \nstack of depth D, the space required is bV(X) s(X)= D+ . V(X)= M-s(X) bV(X) = M-D- . M-D = (9) 1+.b D+.b \nM s(X)= (10) 1+.b 7.5.3 Space Cost of the Tracing Collector For a tracing collector that is optimized \nto use a single mark bit per object, b=1and the formula simpli.es to M-D V(T)= (11) 1+. 1 D+M s(T)= . \n(12) 1+. 1 On a machine with a word size . ' =32and a .xed object size m=2(such as Lisp cons cells), \n.=64\u00bb1, so we can approx\u00adimate the space required as one bit for every possible object (as if there were \nno metadata at all), plus the space for the recursion stack. Note that we implicitly also assume that \nM\u00bbD. V(T) M-D (13) M s(T) +D (14) . 7.5.4 Time Cost The cost per collection is proportional to the size \nof the root set, the number of vertices examined, and the number of edges tra\u00adversed for the trace (mark) \nphase, and the total number of vertices for the sweep phase. So the total cost of a tracing collection \nis .(T)= LT (R,VL,EL,V(T)) (15) A collection has to be performed after the reclaimed cells are consumed, \nso the frequency of collection (in collections/second) is a f(T)= VD(T)a (16) M-D-VL using the approximation \nfrom Equation 13. Therefore the total cost of collection is t(T)= f(T)\u00b7.(T) a LT (R,VL,EL,V(T)) (17) \nM-D-VL  7.6 C: Reference Counting We now develop space and time cost functions for reference counting \nand its derivative collectors. 7.6.1 Space Cost While reference counting does not perform tracing, it \ndoes per\u00adform recursive deletion when an object s reference count drops to zero. There is no difference \nin principle between the two, so it would seem that the amount of space consumed by recursive traver\u00adsal \nis the same. However, by using Weizenbaum s method for non-recursive free\u00ading [42], the space for the \ntraversal stack can be eliminated, at the expense of delaying freeing until the next allocation. There \nis in fact a much simpler variant of pointer threading that can be applied which allows ef.cient and \nimmediate traversal of a stack of dead objects without requiring any extra memory or cache read/write \noperations. To our knowledge this technique has not been published previously. Recursive deletion implies \nthat the object from which we are re\u00adcursing has aleady been identi.ed as dead; therefore, we do not \nneed to preserve the data values it contains; we only need to pre\u00adserve the pointers which have not yet \nbeen traversed. The ability to use the space in dead objects is the key to our technique. When recursively \ntraversing the object graph to decrement refer\u00adence counts and free those with .=0, there are two fundamental \npieces of information in every stack frame: one points to the object being collected; the other identi.es \nwhich .eld was most recently processed. When we recurse for the .rst time, there is obviously at least \none pointer in the object, and since we are traversing it, we no longer need it. Therefore, we can store \na pointer to the parent object in that freed pointer cell. And since we already know the reference count \nof the object (zero), we can over-write the reference count with a .eld that indicates which pointer \nwe are currently travers\u00ading. A reference count is necessarily large enough to count the total number \nof pointers in an object, since they might all point to some other (reference counted) object. Therefore, \nwe can guarantee that any object that might cause recursion will have suf.cient space to store the necessary \nstack frame of the recursive deletion. Furthermore, this technique does not require the reading or writ\u00ading \nof any additional cache lines the .rst cache line of each object has to be examined anyway to perform \nthe storage reclamation. However, unlike with tracing, the reference count .eld can not be optimized \ndown to a single bit: it occupies a full word (this assumption can be relaxed with the use of sticky \ncounts). M mM V(C)= = (18) 1+ 1 m +1 m M s(C)= (19) m +1 That is, the space overhead is one word per \nobject, which increases the effective object size by 1 word, which is precisely what we obtain by substituting \nb =. ' and D=0into equations 9 and 10. 7.6.2 Time Cost The cost per collection is simply .(C)=LC1 (VD(C),ED(C)) \n(20) in other words, the cost of identifying the dead vertices. The frequency of collection is the same \nas with tracing, namely a f(C)= (21) VD(C) 7.6.3 Mutation Cost However, reference counting skips the \ninitialization step per\u00adformed by tracing and instead inserts a write barrier into the code. Therefore, \nthe total cost must include the mutation rate, which for na\u00a8ive reference counting is proportional to \n\u00b5R and \u00b5E,so \u00b5(C)=LC2 (\u00b5R,\u00b5E) (22) So the total cost of reference counting in the absence of cycles is \nt(C)= f(C)\u00b7.(C)+\u00b5(C) a = mM LC1 (VD(C),ED(C))+ m+1 -VL LC2 (\u00b5R,\u00b5E) (23)  7.7 CT: Reference Counting, \nTracing Backup We now consider reference counting collectors which periodi\u00adcally use a tracing collector \nto collect cyclic garbage, as described in Section 5.1. 7.7.1 Space Cost In the CT algorithm, each object \nhas a reference count, and space is required for recursive traversal by the tracing portion of the col\u00adlector. \nTherefore, the space cost of CT is M-D V(CT)= (24) 1+ 1 m M+D s(CT)= (25) 1+ 1 m 7.7.2 Time Cost In \norder to evaluate the performance of cycle collection, we de\u00ad.ne c =a, the rate of generation of cyclic \ngarbage. In order to compute the total cost of the collector we must com\u00adpute the costs due to both reference \ncounting and tracing. We will examine the cost from the point of view of the tracing collections, since \nthose happen on a regular (and less frequent) basis. This leads to a simpler analysis; if one tries to \nevaluate the cost from the point of view of the reference counting portion of the collector, the model \nis complicated because each successive collection frees less mem\u00adory, causing the frequency of collection \nto increase over time, until a tracing collection is performed. From the point of view of the tracing \ncollector, one can think of the reference counting collector as a nursery collector that reduces the \nallocation rate into the mature space of the tracing collector. In particular, while the application \nallocates data at rate a, the system only creates data for the tracing collector at rate c, since all \ngarbage except cyclic garbage is collected by the refer\u00adence counting collector. Therefore, the rate \nof tracing collection is c f(CT)= (26) VD(CT) which is the same as the equation for f(T)except that c \nhas re\u00adplaced a. For the purposes of modelling the two collectors together, we will assume that the reference \ncounting collector has the same frequency as the tracing collector. The cost of the tracing collection \nitself is unchanged, so .(CTT )=.(T)=LT (R,EL,VL,V(CT)) (27) To analyze the cost of reference counting, \nwe will now account for the cost as though it were run in a continuous, incremental fashion. There are \nVc D seconds between tracing collections, dur\u00ad ing which Vc D a cells are allocated. Of those, VD are \nnot freed by reference counting (because they are cyclic garbage). So the num\u00adber of cells freed by reference \ncounting between tracing collections is a VD -VD = a -1 VD cc We assume that the pointer density is uniform, \nso that for each vertex v we traverse ED/VD pointers, or ED pointers in all. There\u00adfore, the cost of \nreference counting for each tracing period is a .(CTC)= -1 \u00b7LC1 (VD,ED) (28) c Combining these results \nwe get the total cost of reference count\u00ading with a tracing backup collector as t(CT)= LC2 (\u00b5R,\u00b5E)+f(CT)\u00b7(.(CTT \n)+.(CTC)) a = LC2 (\u00b5R,\u00b5E)+ LC1 (VD,ED)+ (29) VD c (LT (R,VL, EL,V(CT))-LC1 (VD,ED))VD Of course, when \nthere is no cyclic garbage c =0and the last term of the equation drops out, so that t(CT)=t(C).  7.8 \nCD: Deferred Reference Counting Deferred reference counting (Section 4.1) moves the cost of con\u00adsidering \nthe roots from the application to the collector. Therefore, the cost of collection becomes .(CD)=LCD(R)+LC1 \n(VD,ED) (30) The frequency of collection is the same as with tracing and ref\u00aderence counting, namely \na f(CD)=f(C)= (31) VD so the total cost of collection is t(CD)= f(CD)\u00b7.(CD)+LC2 (0,\u00b5E) a =(LCD(R)+LC1 \n(VD,ED))+ VD LC2 (0,\u00b5E) (32) 7.8.1 Space Cost The space cost of deferred reference counting is the cost \nof keep\u00ading the reference costs plus the space consumed by the zero count table (ZCT). In general the \nnumber of entries in the ZCT can equal the total number of live and dead objects in the system. Therefore, \nrobust implementations use a bit in each object to indicate whether it is the ZCT. So the total cost \nis the space for the reference counts plus the space for the ZCT presence bits : V Vllog2 Vl s(CD)= + \n.. V = \u00b7(1+llog2 Vl) (33) .  7.9 CC: Reference Counting, Trial Deletion We now consider reference counting \nwith cycle collection by trial deletion (Section 5.3) rather than with a backup tracing col\u00adlector. The \ncost of this algorithm is the cost of the basic reference count\u00ading algorithm plus the additional work \nperformed by the trial dele\u00adtion of cycles. However, trial deletion will also be applied to some portion \nof the live subgraph, and this cost must also be factored in. We introduce the parameter ., the fraction \nof live vertices VL that are examined by the trial deletion algorithm (0=. =1). To compute the cost of \ncollection, we use the same methodology as with the CT algorithm: the trial deletion phase CCD is viewed \nas dominant and collection is described in terms of the period of that collection. The trial deletion \nphase is invoked when all free memory is con\u00adsumed by cyclic garbage: c f(CC)=f(CT)= (34) VD The cost \nof the trial deletion algorithm is two traversals over all of the cyclic garbage (which is all of VD \nin this case) plus the traver\u00adsals over the live subgraph: .(CCD)= LCCD(VD +.VL,ED +.EL) (35) The time \ncost of the reference counting collection for non-cyclic garbage is the same as for the CT algorithm: \na .(CCC)=.(CTC)= -1 \u00b7LC1 (VD,ED) (36) c Thus the total cost of the CC collector is t(CC)= f(CC)\u00b7(.(CCD)+.(CCC))+LC2 \n(\u00b5R,\u00b5E) a = LC2 (\u00b5R,\u00b5E)+ LC1 (VD,ED)+ (37) VD c (LCCD(VD,.VL, ED,.EL)-LC1 (VD,ED))VD 7.9.1 Space Cost \nThe space cost of reference counting with cycle collection is the cost of reference counts plus the space \nconsumed by the purple set P plus the per-object color information, represented by the set Y in the abstract \nalgorithm. Let p be the fraction of nodes that are purple, then the space cost is ( ) llog2 V(CC)l 1 \np s(CC)=V(CC)++ (38) . .m  7.10 Split-Heap Collectors We characterize split-heap collectors with the \nfollowing quanti\u00adties: N .V is the nursery.  H =N is the mature space heap.  VNL and ENL are the set \nof live vertices and the set of live edges in the nursery.  VND and END are the set of dead vertices \nand the set of dead edges in the nursery.  VHL, EHL, VHD, and EHD are the corresponding sets in the \nmature space heap.  7.11 GT: Tracing Generational Collection We now consider standard tracing generational \ncollectors as de\u00adscribed in Section 4.3.1. We will assume a simple generational collector in which the \nsize of the nursery is .xed and objects are evacuated into the mature space after surviving a single \nnursery collection. We will use the term heap in this section as a syn\u00adonym for mature space . To collect \nthe nursery we trace forward within the nursery from the roots R and the roots R ' from the mature space \ninto the nursery. Afterwards, the nursery is cleared. The cost is .(GTN)=LT (R+R ' ,VNL,ENL,N) (39) The \nfrequency of nursery collection is simply a f(GTN)= (40) N The size of the mature root set can be as \nhigh as VH and is further discussed below. Collecting the mature heap is just like performing a simple \ntrac\u00ading collection. The cost is .(GTH)=LT (R, VHL,EHL,H) (41) The allocation rate into the heap is attenuated \nby the use of the nursery. The resulting heap allocation rate is a VNL . Therefore the N frequency of \nheap collection is VNL a f(GTH)= N (42) VHD The total cost of generational collection is the sum of the \ncosts of the nursery collections, the heap collections, and the write barriers: t(GT)= f(GTN)\u00b7.(GTN)+ \nf(GTH)\u00b7.(GTH)+LGT (\u00b5E) a ' = \u00b7LT (R+R,VNL,ENL,N)+ (43) N VNL a N \u00b7LT (R,VHL,EHL,H)+LGT (\u00b5E)VHD 7.11.1 \nSpace Cost Like its non-generational counterpart, there is a space cost for the mark bits and the traversal \ndepth. In addition, if the remembered set is maintained as a sequential store buffer (i.e. a list of \nmodi.ed objects), it can take VH space if every object in the mature space is modi.ed between consecutive \ncollection. The space overhead is equal to that of the tracing collector plus the remembered set s(GT)=D \n+V/.  7.12 GCH: Generational with Counted Heap We now consider a generational collector with a traced \nnursery and a reference counted heap (Section 4.3.3). For the nursery, the cost and frequency is identical \nto the GT algorithm. The frequency of heap collection is also the same. The cost of heap collection is \nthe cost of deferred reference counting applied to the heap. .(GCHN)= .(GTN) (44) a f(GCHN)= f(GTN)= \n(45) N .(GCHH)= LCD(R)+ LC1 (VHD(GCH), EHD(GCH)) (46) VNL a f(GCHH)= f(GTH)= N (47) VHD(GCH) t (GCH)= \nf(GCHN)\u00b7.(GCHN)+ (48) f(GCHH)\u00b7.(GCHH)+LGT (\u00b5EH)  8. SPACE-TIME TRADEOFFS So far we have always considered \na single, canonical implemen\u00adtation of each collector. Of course, there are many implementation decisions \nthat can be made that will cause the performance char\u00adacteristics to vary. However, almost all of these \nare some form of space-time trade-off that can be applied to individual memory re\u00adgions once the basic \ncollector design has been selected. 8.1 Copying Collectors Copying collectors trade space for time by \nallocating an extra semi-space and copying the live data into the new semi-space. Thus they save the \nfactor of Viteration over the dead data required by mark-and-sweep style collectors (the sweep-for-tracing() \nfunction of Figure 3), but at an equivalent cost of V/2in space. 8.2 Remembered Set Although the remembered \nset in a generational collector could contain all objects in the mature space, this is very unlikely. \nPre\u00adallocating space for this situation is excessive over-provisioning. Instead, one can dynamically \nborrow space for the remembered set from the mature space and nursery. It is preferable to borrow from \nthe mature space. If the mutation rate is low enough that the bor\u00adrowed space is not exhausted, the nursery \ncollection frequency is unaffected. Alternatively, borrowing space from the nursery will de.nitely increase \nthe frequency of minor collection to f(GTN)=a/(N -.) (49) where .is the amount of space allowed for the \nremembered set in the nursery. This technique trades space for time by making the usually true assumption \nthat mutation rate is not that high. Alternatively, one can consider a bitmap or card-marking ap\u00adproach \nwhere the overhead is greatly diminished by either w or k, the size of the card. In the former case, \nthere is no loss of precision but the write barrier must perform bit updates. With card marking, the \nwrite barrier code is shorter and faster though the loss in pre\u00adcision (one card corresponds many objects) \nwill result in a longer scanning time during garbage collection. For slot-based bitmap, the space overhead \nis reduced to s(GT )=D +V/. +VH/. (50) For card marking, the space overhead is even less: s(GT )=D +V/. \n+VH/k (51) where k is the card size. 8.3 Traversal For tracing collectors, the recursive traversal in \nthe reconstruct function requires stack space D. This can be eliminated entirely at the cost of an extra \npass over the live objects VL by using pointer reversal [36]. However, this is usually a poor trade-off \nbecause the stack depth in practice is much smaller than the number of live objects (D\u00abVL). A better \nstrategy is to use a .xed-size recursion stack and then use some technique to handle stack over.ow. One \ncan either fall back on pointer reversal when the stack over.ows, or one can dis\u00adcard the stack and begin \nscanning the heap from left to right to .nd unmarked objects. While this approach is simpler to imple\u00adment \nand is a more natural implementation in a concurrent system, it does have the distinct disadvantage that \nits complexity is n 2 .  9. CONCLUSIONS We have shown that tracing and reference counting garbage col\u00adlection, \nwhich were previously thought to be very different, in fact share the exact same structure and can be \nviewed as duals of each other. This in turn allowed us to demonstrate that all high-performance garbage \ncollectors are in fact hybrids of tracing and reference count\u00ading techniques. This explains why highly \noptimized tracing and ref\u00aderence counting collectors have surprisingly similar performance characteristics. \nIn the process we discovered some interesting things: a write barrier is fundamentally a feature of reference \ncounting; and the ex\u00adistence of cycles is what makes garbage collection inherently non\u00adincremental: cycle \ncollection is trace-like . We have also provided cost measures for the various types of collectors in \nterms of collector-independent and -dependent quan\u00adtities. These cost measures do not cheat by for example \nignoring the space cost of collector metadata. They therefore allow direct head-to-head comparisons. \nDesign of collectors can be made more methodical. When con\u00adstructing a collector, there are three decisions \nto be made: Partition. Divide memory (heap, stack, and global variables) into a set of partitions, within \nwhich different strategies may be applied; Traversal. For each partition, decide whether the object graph \nwill be traversed by tracing or reference counting; and Trade-offs. For each partition, choose space-time \ntrade-offs such as semi-space vs. sliding compaction, pointer reversal vs. stack traversal, etc. Our \nuni.ed model of garbage collection allows one to system\u00adatically understand and explore the design space \nfor garbage col\u00adlectors, and paves the way for a much more principled approach to selecting a garbage \ncollector to match the characteristics of the associated application. In the future, this methodology \nmay help enable the dynamic construction of garbage collection algorithms that are tuned to par\u00adticular \napplication characteristics. Acknowledgements Alex Aiken suggested the .x-point formulation of the garbage \ncol\u00adlection algorithm. We gratefully thank Ras Bodik, Hans Boehm, Richard Fateman, Matthew Fluet, Richard \nJones, Greg Morrisett, Chet Murthy, and George Necula, and the anonymous referees for their helpful comments. \nThis work began with a Five Minute Madness presentation by the .rst author at the 2004 Semantics, Program \nAnalysis, and Com\u00adputing Environments for Memory Management (SPACE) Work\u00adshop in Venice, Italy. We thank \nthe organizers of and participants in the workshop for providing the stimulating atmosphere which gave \nrise to this work. 10. REFERENCES [1] APPEL, A. W. Simple generational garbage collection and fast allo\u00adcation. \nSoftware Practice and Experience 19, 2 (1989), 171 183. [2] APPEL,A. W., ELLIS, J. R., AND LI, K. Real-time \nconcurrent col\u00adlection on stock multiprocessors. In Proceedings of the SIGPLAN 88 Conference on Programming \nLanguage Design and Implementation (Atlanta, Georgia, June 1988). SIGPLAN Notices, 23, 7 (July), 11 20. \n[3] BACON,D. F., ATTANASIO, C. R., LEE, H. B., RAJAN,V.T., AND SMITH, S. Java without the coffee breaks: \nA nonintrusive mul\u00adtiprocessor garbage collector. In Proc. of the SIGPLAN Conference on Programming Language \nDesign and Implementation (Snowbird, Utah, June 2001). SIGPLAN Notices, 36, 5 (May), 92 103. [4] BACON,D.F., \nCHENG,P., AND RAJAN, V. T. Controlling fragmen\u00adtation and space consumption in the Metronome, a real-time \ngarbage collector for Java. In Proceedings of the Conference on Languages, Compilers, and Tools for Embedded \nSystems (San Diego, California, June 2003). SIGPLAN Notices, 38, 7, 81 92. [5] BACON,D.F., CHENG,P., \nAND RAJAN, V. T. A real-time garbage collector with low overhead and consistent utilization. In Proceedings \nof the 30th Annual ACM SIGPLAN-SIGACT Symposium on Princi\u00adples of Programming Languages (New Orleans, \nLouisiana, Jan. 2003). SIGPLAN Notices, 38, 1, 285 298. [6] BACON,D.F., AND RAJAN, V. T. Concurrent cycle \ncollection in ref\u00aderence counted systems. In European Conference on Object-Oriented Programming (Budapest, \nHungary, June 2001), J. L. Knudsen, Ed., vol. 2072 of Lecture Notes in Computer Science, Springer-Verlag, \npp. 207 235. [7] BAKER, H. G. List processing in real-time on a serial computer. Com\u00admun. ACM 21, 4 (Apr. \n1978), 280 294. [8] BAKER, H. G. The Treadmill, real-time garbage collection without motion sickness. \nSIGPLAN Notices 27, 3 (Mar. 1992), 66 70. [9] BARTH, J. M. Shifting garbage collection overhead to compile \ntime. Commun. ACM 20, 7 (July 1977), 513 518. [10] BISHOP,P. B. Computer Systems with a Very Large Address \nSpace and Garbage Collection. PhD thesis, Laboratory for Com\u00adputer Science, Massachussets Institute of \nTechnology, May 1977. MIT/LCS/TR-178. [11] BLACKBURN, S. M., JONES, R., MCKINLEY, K. S., AND MOSS,J. \nE. B. Beltway: getting around garbage collection gridlock. In Proc. of the SIGPLAN Conference on Programming \nLanguage Design and Implementation (Berlin, Germany, June 2002). SIGPLAN Notices, 37, 5, 153 164. [12] \nBLACKBURN, S. M., AND MCKINLEY, K. S. Ulterior reference counting: Fast garbage collection without a \nlong wait. In Proceed\u00adings of the Conference on Object-oriented Programing, Systems, Lan\u00adguages, and \nApplications (Anaheim, California, Oct. 2003). SIG-PLAN Notices, 38, 11, 344 358. [13] BROOKS, R. A. \nTrading data space for reduced time and code space in real-time garbage collection on stock hardware. \nIn Conference Record of the 1984 ACM Symposium on Lisp and Functional Pro\u00adgramming (Austin, Texas, Aug. \n1984), G. L. Steele, Ed., pp. 256 262. [14] CHEADLE, A. M., FIELD,A.J., MARLOW, S., PEYTON JONES, S. \nL., AND WHILE, R. L. Non-stop Haskell. In Proc. of the Fifth In\u00adternational Conference on Functional \nProgramming (Montreal, Que\u00adbec, Sept. 2000). SIGPLAN Notices, 35, 9, 257 267. [15] CHENEY, C. J. A nonrecursive \nlist compacting algorithm. Commun. ACM 13, 11 (1970), 677 678. [16] CHENG,P., AND BLELLOCH, G. A parallel, \nreal-time garbage collec\u00adtor. In Proc. of the SIGPLAN Conference on Programming Language Design and Implementation \n(Snowbird, Utah, June 2001). SIGPLAN Notices, 36, 5 (May), 125 136. [17] CHRISTOPHER, T. W. Reference \ncount garbage collection. Software Practice and Experience 14, 6 (June 1984), 503 507. [18] COLLINS, \nG. E. A method for overlapping and erasure of lists. Com\u00admun. ACM 3, 12 (Dec. 1960), 655 657. [19] DETREVILLE, \nJ. Experience with concurrent garbage collectors for Modula-2+. Tech. Rep. 64, DEC Systems Research Center, \nAug. 1990. [20] DEUTSCH,L. P., AND BOBROW, D. G. An ef.cient incremental au\u00adtomatic garbage collector. \nCommun. ACM 19, 7 (July 1976), 522 526. [21] DIJKSTRA,E. W., LAMPORT, L., MARTIN, A. J., SCHOLTEN, C. \nS., AND STEFFENS, E. F. M. On-the-.y garbage collection: An exercise in cooperation. In Hierarchies and \nInterfaces, F. L. Bauer et al., Eds., vol. 46 of Lecture Notes in Computer Science. Springer-Verlag, \n1976, pp. 43 56.  [22] DOLIGEZ, D., AND LEROY, X. A concurrent generational garbage collector for a \nmulti-threaded implementation of ML. In Conf. Record of the Twentieth ACM Symposium on Principles of \nProgramming Lan\u00adguages (Jan. 1993), pp. 113 123. [23] HENRIKSSON,R. Scheduling Garbage Collection in \nEmbedded Sys\u00adtems. PhD thesis, Lund Institute of Technology, July 1998. [24] HIRZEL, M., DIWAN, A., AND \nHERTZ, M. Connectivity-based garbage collection. In Proceedings of the Conference on Object\u00adoriented \nPrograming, Systems, Languages, and Applications (Ana\u00adheim, California, Oct. 2003). SIGPLAN Notices, \n38, 11, 359 373. [25] HUDSON, R. L., AND MOSS, J. E. B. Incremental collection of ma\u00adture objects. In \nProc. of the International Workshop on Memory Man\u00adagement (St. Malo, France, Sept. 1992), Y. Bekkers \nand J. Cohen, Eds., vol. 637 of Lecture Notes in Computer Science, pp. 388 403. [26] JOHNSTONE,M. S. \nNon-Compacting Memory Allocation and Real-Time Garbage Collection. PhD thesis, University of Texas at \nAustin, Dec. 1997. [27] KUNG,H. T., AND SONG, S. W. An ef.cient parallel garbage collec\u00adtion system and \nits correctness proof. In IEEE Symposium on Founda\u00adtions of Computer Science (1977), pp. 120 131. [28] \nLAMPORT, L. Garbage collection with multiple processes: an exer\u00adcise in parallelism. In Proc. of the \n1976 International Conference on Parallel Processing (1976), pp. 50 54. [29] LANG, B., QUENNIAC, C., \nAND PIQUER, J. Garbage collecting the world. In Conference Record of the Nineteenth Annual ACM Sym\u00adposium \non Principles of Programming Languages (Jan. 1992), SIG-PLAN Notices, pp. 39 50. [30] LAROSE, M., AND \nFEELEY, M. A compacting incremental collector and its performance in a production quality compiler. In \nProc. of the First International Symposium on Memory Management (Vancouver, B.C., Oct. 1998). SIGPLAN \nNotices, 34, 3 (Mar., 1999), 1 9. [31] LEVANONI,Y., AND PETRANK, E. An on-the-.y reference counting garbage \ncollector for java. In Proceedings of the 16th ACM SIGPLAN conference on Object Oriented Programming, \nSystems, Languages, and Applications (Tampa Bay, Florida, Oct. 2001), pp. 367 380. [32] MART\u00b4INEZ,A.D.,WACHENCHAUZER,R., \nANDLINS,R.D.Cyclic reference counting with local mark-scan. Inf. Process. Lett. 34,1 (1990), 31 35. [33] \nMCCARTHY, J. Recursive functions of symbolic expressions and their computation by machine. Commun. ACM \n3, 4 (1960), 184 195. [34] NETTLES, S., AND O TOOLE, J. Real-time garbage collection. In Proc. of the \nSIGPLAN Conference on Programming Language Design and Implementation (June 1993). SIGPLAN Notices, 28, \n6, 217 226. [35] ROSENBLUM, M., AND OUSTERHOUT, J. K. The design and imple\u00admentation of a log-structured \n.le system. In Proc. of the Thirteenth ACM symposium on Operating Systems Principles (Paci.c Grove, California, \nOct. 1991). SIGOPS Operating Systems Review, 25,5, 1 15. [36] SCHORR, H., AND WAITE, W. M. An ef.cient \nmachine-independent procedure for garbage collection in various list structures. Commun. ACM 10, 8 (1967), \n501 506. [37] SELIGMANN, J., AND GRARUP, S. Incremental mature garbage col\u00adlection using the Train algorithm. \nIn Ninth European Conference on Object-Oriented Programming (\u00b0 Aarhus, Denmark, 1995), W. G. Olthoff, \nEd., vol. 952 of Lecture Notes in Computer Science, pp. 235 252. [38] SHUF,Y., GUPTA, M., BORDAWEKAR, \nR., AND SINGH, J. P. Ex\u00adploiting proli.c types for memory management and optimizations. In Proceedings \nof the 29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (Portland, Oregon, Jan. \n2002). SIGPLAN Notices, 37, 1, 295 306. [39] STEELE, G. L. Multiprocessing compactifying garbage collection. \nCommun. ACM 18, 9 (Sept. 1975), 495 508. [40] STEFANOVI C., D., MCKINLEY,K.S., AND MOSS, J. E. B. Age\u00adbased \ngarbage collection. In Proc. of the Conference on Object-Oriented Programming, Systems, Languages, and \nApplications (Den\u00adver, Colorado, Oct. 1999). SIGPLAN Notices, 34, 10, 370 381. [41] UNGAR, D. M. Generation \nscavenging: A non-disruptive high per\u00adformance storage reclamation algorithm. In Proceedings of the ACM \nSIGSOFT/SIGPLAN Software Engineering Symposium on Practi\u00adcal Software Development Environments (Pittsburgh, \nPennsylvania, 1984), P. Henderson, Ed. SIGPLAN Notices, 19, 5, 157 167. [42] WEIZENBAUM, J. Symmetric \nlist processor. Commun. ACM 6,9 (Sept. 1963), 524 536. [43] WEIZENBAUM, J. Recovery of reentrant list \nstructures in SLIP. Com\u00admun. ACM 12, 7 (July 1969), 370 372. [44] YUASA, T. Real-time garbage collection \non general-purpose ma\u00adchines. Journal of Systems and Software 11, 3 (Mar. 1990), 181 198. [45] ZEE, K., \nAND RINARD, M. Write barrier removal by static analysis. In Proc. of the Conference on Object-Oriented \nProgramming, Sys\u00adtems, Languages, and Applications (Seattle, Washington, Oct. 2002), ACM Press. SIGPLAN \nNotices, 37, 11 (Nov.), 191 210. [46] ZORN, B. Barrier methods for garbage collection. Tech. Rep. CU-CS\u00ad494-90, \nUniversity of Colorado at Boulder, 1990.   \n\t\t\t", "proc_id": "1028976", "abstract": "<p>Tracing and reference counting are uniformly viewed as being fundamentally different approaches to garbage collection that possess very distinct performance properties. We have implemented high-performance collectors of both types, and in the process observed that the more we optimized them, the more similarly they behaved - that they seem to share some deep structure. </p> <p>We present a formulation of the two algorithms that shows that they are in fact duals of each other. Intuitively, the difference is that tracing operates on live objects, or \"matter\", while reference counting operates on dead objects, or \"anti-matter\". For every operation performed by the tracing collector, there is a precisely corresponding anti-operation performed by the reference counting collector.</p> <p>Using this framework, we show that all high-performance collectors (for example, deferred reference counting and generational collection) are in fact hybrids of tracing and reference counting. We develop a uniform cost-model for the collectors to quantify the trade-offs that result from choosing different hybridizations of tracing and reference counting. This allows the correct scheme to be selected based on system performance requirements and the expected properties of the target application.</p>", "authors": [{"name": "David F. Bacon", "author_profile_id": "81100628167", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY", "person_id": "P60470", "email_address": "", "orcid_id": ""}, {"name": "Perry Cheng", "author_profile_id": "81451593218", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY", "person_id": "PP43116113", "email_address": "", "orcid_id": ""}, {"name": "V. T. Rajan", "author_profile_id": "81331502483", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY", "person_id": "PP43115622", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1028976.1028982", "year": "2004", "article_id": "1028982", "conference": "OOPSLA", "title": "A unified theory of garbage collection", "url": "http://dl.acm.org/citation.cfm?id=1028982"}