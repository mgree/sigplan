{"article_publication_date": "05-01-1996", "fulltext": "\n A Reduced Multipipeline Machine Description that Preserves Scheduling Constraints Alexandre E. Eichenberger \nand Edward S. Davidson Advanced Computer Architecture Laboratory EECS Department, University of Michigan \n1301 Beal Ave, Ann Arbor, MI 48109-2122 alexe, davidson@eecs .um~ch. edu Abstract High performance compilers \nincreasingly rely on accurate model\u00ad ing of the machine resources to efficiently exploit the instruction \nlevel parallelism of an application. In this paper, we propose a re\u00ad duced machine description thatresults \nin faster detection of resource contentions while preserving the scheduling constraints present in the \noriginal machine description. The proposed approach reduces a machine description in an automated, error-free, \nand efficient fash\u00ad ion, Moreover, it fully supports schedulers that backtrack and pro\u00ad cess operations \nin arbitrary order. Reduced descriptions for the DEC Alpha 21064, MIPS R3000/R3010, and Cydra5 result \nin 4 to 7 times faster detection of resource contentions and require 22 to 90% of the memory storage \nused by the original machine descriptions. Precise measurement for the Cydra 5 indicates that reducing \nthe machine description results in a 2.9 times faster contention query module. Introduction Current \ncompilers for VLIW and superscalarmachines focus on ex\u00ad ploiting more of the inherent parallelism in \nan application in order to obtain higher performance. Fine grain schedulers are a critical element in \nefficiently exploiting instruction level parallelism and a significant body of research has sought more \neffective scheduling algorithms. Several new directions have been explored: schedulers may not schedule \noperations in cycle order, focusing initially on op\u00ad erations along critical paths [1][2][3][4][5] [6], \nthey may backtrack to reverse poor scheduling decisions [1][2][3][4][7], and they may hide long latencies \nby speculating operations across branches and basic blocks [1][6][7][8][9] [10]. High performance compilers \nhave also used precisely detailed machine models [1][3][7][11][12] [13] to better utilize the machine \nresources of current processors with increasingly wider issue mech\u00ad anisms, deeper pipelines, and more \nheterogeneous functional units. Precise modeling of machine resources is critical to avoid resource contentions \nthat may stall some of the pipelines or, in the absence of hardware interlocks, corrupt some of the results. \nResource model\u00ad ing has to cope with rapidly changing processor models while con\u00ad trolling development \ncost by reusing existing compiler technology. To meet these challenges, compilers have increasingly relied \non a resource modeling utility, separated from the rest of the compiler, Permission to make digitabhard \ncopy of part or all of this work for personal or classroom use is ranted without fee provided that copies \nare not made of distributed for pro I t or commercial advantage, the copyright noti~, the title of the \nblication and its date appear, and noti-is given that copying is r y pernuesion of ACfvl, ho. To mpy \notherwise, to republish, to post on servers, or to redistribute to lists, requires prior spedfic permission \nandlor a fee. PLDI 96 5/9$ PA, USA 0 19% ACM 0-89791 -795-2/96/0005 ...$3.50 that can quickly answer \nthe following query: Given a target ma\u00adchine and a partial schedule, can I place this additional operation \nin this cycle without resource contention? Typically, this func\u00adtionality has been provided by a contentwn \nquery module that pro\u00adcesses the machine description of a target machine, generates an in\u00adternal representation \nof the resource requirements, and provides for a querying mechanism [1][3][7][11][12][13]. The IMPACT \ncom\u00adpiler, for example, implemented such a module [12] to produce high performance schedules for a wide \nrange of machines, from existing architectures such as X86, PA-RISC, and SPARC to research archi\u00adtectures \nsuch as PlayDoh [14]. With the recent emphasis on exploiting instruction level paral\u00adlelism, compile \ntime N increasingly spent in the contention query module as several cycles of a schedule, possibly in \nseveral ba\u00adsic blocks [9][10], are queried per operation in order to achieve good schedules. Optimizing \ncontention query modules therefore has a significant impact on the overall performance of a com\u00adpiler, \nas queries are issued in the innermost loop of the scheduler. This optimizing issue has recently been \naddressed in several papers [15][16][17], but these either overrestrict the manner in which op\u00aderations \nare placed or approximate the actual resource requirements of a schedule. In this paper, we propose a \nreduced machine description that re\u00adsults in significantly faster detection of resource contentions while \nexactly preserving the scheduling constmints present in the original machine description. The reduced \nmachine description is expressed using reservation tables that determine the resource usage for each \noperation. We demonstrate how to derive a reduced machine de\u00adscription for a given target machine and \npresent several examples illustrating the effectiveness of our approach. The proposed approach fully \nsupports unrestricted scheduling models where operations can be scheduled in arbitrary order and prior \nscheduling decisions can be reversed. Unrestricted schedul\u00ading is essential to accommodate the elaborate \nscheduling techniques used by today s high performance compilers. The Cydra 5 com\u00adpiler, for example, \nuses an operation-driven scheduler that reduces the schedule length of a basic block by scheduling operations \nalong the critical path first [1]. Operation-driven schedulers consider op\u00aderations in topological order, \nnot in order of monotonically increas\u00ading (or decreasing) schedule time. Also, the Cydra 5 and IMPACT \ncompilers, as well as others, use software pipelining techniques to achieve loop schedules with high \nthroughput [1 ][2][10]. Soft\u00adware pipelining schedulers do not consider operations in topolog\u00adical order \nas, in general, no topological order is defined in depen\u00addence graphs with loop-carried dependence. Moreover, \nexperi\u00admental results indicate that software pipelined loops can achieve higher throughput in less compilation \ntime when some limited num\u00adber of scheduling decisions can be reversed, as shown by Rau [3], and used \nin numerous compilers [1][2][3][4][18]. The Multiflow compiler also uses a backtracking mechanism to \nimprove scalar code schedules [7]. The proposed approach also precisely handles basic block boundary \nconditions, i.e. the dangling resource requirements from predecessor basic blocks. In general, the resourcerequirernents \nat the beginning of a basic block consist of the union of all therescmrce requirements dangling from \npredecessor basic blocks. Handling boundary conditions is even more important for high performance compilers \nthat hide operation latencies by (speculatively) mewing operations across branches and basic blocks [1][6][7][8][9] \n[10]. Both the Cydra 5 and the Multiilow compilers, for example, use scheduling algorithms that handle \ndangling resource requirements [11[71. ... . Currently, most compilers rely on machine descriptions that \nhave been manually reduced using emor prone ad-hoc methods. To avoid errors or to reduce the machine \ndescription more eas\u00adily or further, conservative assumptions may be employed. Thus, the reduced machine \ndescription may prohibit certain operation se\u00adquences that cause no contentions on the target machine. \nFurther\u00admore, high performance compilers are often developed in paral\u00adlel with micro-architecture development \nduring which resource re\u00adquirements often change. Manually reducing the machine descrip\u00adtion must then \nbe carried out several times, introducing more pcJten\u00adtial for errors, suboptimal solutions, and increased \ndevelopment and maintenance cost. Using our approach, the resource requirements can be expressed in terms \nclose to the actual hardware structure of the target machine and the reduced machine description used \nby the compiler is generated in an error-free and automated fashion. Experirnen@ with the DEC Alpha 21064 \n[19], MIPS R3CIOO/-R301O [20], and Cydra 5 [21] machines indicate 4 to 7 times fnster contention queries \nand require 22 to 90% of the memory storage used by the origimd machine descriptions. These improvements \nare obtained by using highly reduced machine descriptions instead of the original or manually optimized \nmachine descriptions. When us\u00ading our reduced machine description during Cydra 5 compilation, precise \nmeasurements with a state-of-the-art scheduler and an effi\u00adcient contention query module for a benchmark \nof 1327 loops from the Perfect Club, SPEC-89, and the Livermore Fortran Kernels re\u00adsulted in a 2.9 times \nfaster contention query module. In this paper, we present related work in Section 2 and an in\u00adtroductory \nexample in Section 3. Algorithms to construct reduced machines are developed in Sections 4 and 5. Reduced \nmachine ex\u00adamples are presented in Section 6. A contention query modu [e is developed in Section 7 and \nits performance is investigated in Sec\u00adtion 8. We present our conclusions in Section 9. Related Work \n Resource contention in multipipeline scheduling maybe basecl di\u00ad rectly on reservation tables, or on \nthe forbidden latency seti or contention-recognizing state machines derived from them, as in\u00ad troduced \nby Davidson e~ al [22]. Traditionally, reservation talbles contain much redundant information that consumes \nmemory and increases query response time. As a result recent advances fawor finite-state automata approaches. \nIn this paper, however, we pro\u00ad pose a reduced reservation table approach that eliminates much of the \nredundancy and does not suffer from the limitations of the au\u00ad tomata approaches, as detailed below. \nProebsting and Fraser [15] as well as Muller [16] proposed a contention query module using a finite-state \nautomaton that rec\u00adognizes all contention-free schedules. The technique proposecl by Proebsting and Fraser \ndirectly results in minimal finite-state au\u00adtomata [15]. This approach was recently extended for unrestricted \nscheduling models by Bala and Rubin using a forward and re\u00adverse pair of automata [17]. In their approach, \noperations corrsid \u00adered in order of monotonically increasing (or decreasing) scheclule time are quickly \nscheduled using a forward automaton. Additional operations are then inserted in the schedule in cycles \nrecognized as contention-free by the forward and reverse automata. Because an inserted operation introduces \nadditional resource requirements, these additional requirements must be propagated in adjacent cy\u00adcles, \ni.e. the state of scheduled operations in adjacent cycles must be updated in both the fonvard and reverse \nautomata. Their approach also addresses the handling of basic block boundary conditions at the cost of \npotentially introducing up to 0(s2 ) new states in the au\u00adtomata, wheres is the number of cycle-advancing \nstates in the ori\u00adginal automata [17]. The principal advantage of automaton-based approaches is that \na single table lookup can determine the next contention-tiee cycle. A potential problem of this approach, \nhowever, is the size of these automata. This issue is addressed in the literature in three ways. First \noperations of a target machine can be combined into classes of operations that have compatible resource \ncontentions [15]. Second, large automata can be factored into sets of smaller ones [16] [17], re\u00adducing \nthe size of the automata, but increasing the number of table lookups necessary to process a contention \nquery. Third, the num\u00adber of additional states introduced in the automata to handle bound. ary conditions \ncan be reduced [17], at the cost of making conser\u00advative approximations. However, new experimental evidence \nthat was gathered by Brda and Rubin [23] for the Alpha, PAIISC, and MIPS families indicates that in practice, \nno additional state is in\u00adtroduced to precisely handle boundary conditions, when minimal finite-state \nautomata are constructed. Another problem arises when supporting unrestricted schedul\u00ading models, since \nthe state of the forward and reverse automata must be saved for each scheduled operation. In addition \nto storing the descriptions of the two automata, two states per operation must be stored, which may result \nin a large memory overhead, especially for wide-issue machines. Supporting unrestricted scheduling mod\u00adels \nalso requires the consistency of the stored state to be maintained when scheduling additional operations \n[17], as inserted operations introduce additional resource requirements. Thus, handling ume\u00adstricted \nscheduling models introduces both memory and computa\u00adtion overhead that is similar to, or may exceed, \nthe overhead in\u00adcurred by the reservation table approach. A more detailed compar\u00adison is provided in \nSections 6 and 8. Finally, some backtracking schedulers may schedule an opera\u00adtion even though it may \nresult in resource contentions, in which case the earlier scheduled operations that conflict are then \nunscheduled. For example, this mechanism is a key component of the scheduling algorithm proposed by Rau \nto generate high performance software\u00adpipelined loop schedules at a low level of computational complexity \n[3]. Using reservation tables, this mechanism can be easily imple\u00admented by keeping a mapping from each \nreserved resource to the scheduled operation that consumes it. Implementing this mecha\u00adnism with finite-state \nautomata appears to be more difficul~ as it corresponds to modifying the path in the forward and backward \nau\u00adtomata so that the new operation is accepted by the automata in the desired cycle. 3 Reducing a Machine \nDescription In this section, we illustrate the three-step process of constructing a synthesized machine, \nresulting in reduced numbers of resources and resource usages while exactly preserving the scheduling \nconstraints due to resource contentions in the target machine. The machines handled here may have arbitrary \nresource require\u00adments, including alternative resource usages, but must have laten\u00adcies that are known \nat compile time. Alternative resource usages, e.g. operation X using either resource O or 1 interchangeably, \nre\u00ad quire some preprocessing. In this case, we would replace operation X in the original machine description \nwith two new operations, XO 13 a)Machine description (reservation tables) (usagesets) b)Forbidden latency \nsetmatrix cycles cycles 012 01234567 operations A AO={O) BO=@ BA AB AB BBBB 4 BB * EE d) Reduced machine \ndescription (reservation tables) cycles cycles 01 0123 m 0 A B : 1 B B B  A!. ={l} B1={O) A2={2) B2={1} \nBA3= q B3={2,3,4,5} kid A4= g B4={6,7) (usagesets) AO ={1) A1 =q BO ={0 BI =(0 1(3) c) Generating set \nof maxind cycles 0123 UiO, BA : 1 BBBB resources EEEEl Figure 1: Reducing a machine description. and \nXI, identical to X but with operation XO exclusively using resource Oandoperation Xlexclusively using \nresourcel. Ingen\u00aderal, new operations are created until all alternative resource us ages present in the \noriginal machine description are removed. The oper\u00adations generated from a unique operation in the original \ndescription are subsequently referred tQ as alternative operations, e.g. XO and XI are the alternative \noperations of X. We begin with a given machine description consisting of a set of reservation tables, \none per operation, that expresses the resource requirements of each operation in terms close to the actual \nhard\u00adware structure of the target machine. The rows of a reservation ta\u00adble correspond to distinct resources \nof the target machine and its columns correspond to the cycles in which resources are used rel\u00adative \nto the issue time of the corresponding operation. An X entry in row i/column j is made in the reservation \ntable associated with operation X if there is a usage of resource i in cycle j by operation X, i.e. if \nresource i is reserved for exclusive use during cycle j by operation X. Figure la shows the reservation \ntables of a hypothetical machine with 2 operations (A and B) and 5 distinct resources (O, . . . . 4). \nOperation A is representative of theresourcerequirements of a fully pipelined functional unit. Operation \nB is representative of the re\u00adsource requirements of a partially -pipelined functional unit where resource \n3 may correspond to a multiply stage used for 4 consecu\u00adtive cycles and resource 4 may correspond to \na rounding mode stage used for 2 consecutive cycles. Although this hypothetical machine was constructed \nto concisely illustrate our methodology, it is repre\u00adsentative of some of the resource usage patterns \nfound in our bench\u00admark examples (see Figure 4 for example). Step 1. For each pair of operations, we \nextract from the correspond\u00ading pair of reservation tables of the target machine the set of~or\u00adbidden \nlatencies, i.e. the set of initiation intervals for which a re\u00adsource contention occurs between the two \noperations. Visually, the set of forbidden latencies between operations X and Y is obtained by overlapping \ntheir reservation tables, and searching for all initia\u00adtion intervals that result in simultaneous use \nof one or more shared resources. To formalize the definition of forbidden latencies, we define the usage \nset X, as the set of cycles in which operation X reserves resource i for exclusive use. Figure 1a illustrates \nthe usage sets of our example machine. For example, usage set Bs is equal to ~2. 3.4. 5], as oueration \nB uses resource 3 in cvcle 2.3.4. and 5. Two oper&#38;ons, X and Y scheduled at times t> and t~,respec\u00adtively, \nconflict if and only if there is some resource, i, and elements zcX, andveY,suchthat tX +z=ty +y,i.e. \nbothoper\u00adations use resource i simultaneously. When such a,conflict occurs, operation X cannot be scheduled \n(y -z) cycles after operation Y. We thus obtain Fx,y = {j I operation X cannot be scheduled ~ cycles \nafter operation Y}, i.e. FX,Y = {(y z)l foralli CQ, zCX,, ySX} (1) Equation (1) defines a matrix of forbidden \nlatency sets for all pairs of operations, where Fx,y is the set in row X, column Y of the matrix. Figure \nlb illustrates this matrix computed for our ex\u00adample machine. While these sets are computed for each \noperation of the target machine, we need list these sets only for each opera\u00adtion class, as presented \nby Proebsting and Fraser [15]. In general, two operations belong to the same operation class if they \nhave the same sets of forbidden latencies, i.e. operations X and Y belong to the same class if Fx,z = \nFY2Z and FZ,X = FZ,Y for each operation Z of the target machine.. Note two properties of the for\u00adbidden \nlatency matrix. FirsL operation X necessarily conflicts with itself for an initiation interval of O (i.e. \nO ~ Fx,x) if it uses any resources. Second, operation X cannot be scheduled f cycles afier operation \nY if and only if Y cannot be scheduled f cycles before X (i.e. f E FX,Y + f G FY,x). Formal Problem Definition. \nGenerate a reduced machine descrip\u00adtion, i.e. one with a reduced number of resources and resource us\u00adages \nin its reservation tables, which for each operation pair produces exactly the same forbidden latencies \nas the target machine. One of several objective functions (e.g. the number of resources or re\u00adsource \nusages) maybe minimized, depending on the desired internal representation. Querying for resource contentions \nusing either the original or reduced machine descriptions yields the same answer, as both descriptions \nenforce the same forbidden latencies. Note that to schedule a given machine, we need know only whether, \nnot where, resource conflicts occur. Thus we are free to represent the machine with any set of synthetic \nresources and usages that preserves the for\u00adbidden latencies. Step 2. We build the generating set of \nmaximal resources which is defined as a set of resources that contains all maximal resources c) Process \n2 in FB B a) recess 1 n B,A b!l!..- , EtFl 01 012 O BA Rule 3: create 0 with O BA incompatible m elementary \npair 1 BBB Rule 1: fully compatible-> add EEEl elementary pair b) Process 1 in FB B9 EEl ) rwess 3 \nn B,B m 01 0123 t+lOIBA 1 BB Rule 3: incompatible create 1 elementary with pair EEEEl O BA 1 BBBB Rule \n1: incompatible fully compatible-> elementary pair add Figure3: Building thegenerating set forourexample \nmachirw Elementary pair p is filly compatible with resource q, i.e. with allusagesin q. Inthiscase, weaddthe \nusages ofpto resourceq. This process isrefemedto as Rule l,andisi~us\u00adtrated in Figure 2a for the elementary \npair associated with the forbidden latency 3 c FX,Y. c Elementary pairpispariially compatible withresourceq, \ni.e. itis incompatible with atleastoneusageio q. We may not simply addtheusages ofptoresourceq, as this \nwould gen\u00aderate some forbidden latencies notpresentirr the forbidden Iatencymatxix. Instead, weleave \nresource qinthe the cur\u00adrent generating set unchanged and consider adding a new re\u00adsource, consisting \nof the usages of p and each of the usages of resource qthatarecompatible withp. Ifthisnewresourceis not \nsimply p itself with no other usages, then it is added to the current generating se~ otherwise it is \ndiscarded. This process is referred to as Rule 2, and is depicted in Figure 2b and 2c. After applying \nRule 1 or Rule 2forp with each resource in the cument set and placing the corresponding updated and new \nre\u00adsources in the current seg we add elementary pair p itself as anew resource if the two usages of p \nare not yet found together in any sin\u00adgle resource in the set. This is referred to as Rule 3. Elementary \npair p is then removed from the list of elementruy pairs and the second step of the rdgorithm is executed \nrepeatedly un\u00adtil the pair list is empty. For each operation, X, (if any) that has O E Fx,x as its only \nforbidden latency, the third step adds a new maximal resource! that consists of one usage, by operation \nX in cycle O. This is referred to as Rule 4. All other operations, Y, must be part of at least one elementary \npair, and O c FY, Y was forbidden automatically when the tirst elementary pair with a Y usage was processed. \nTheorem 1 Building the generating set of maximal resources as described in Algorithm 1 produces resources \nthat forbid only those latencies that areforbidden in the target machine. Furthermore, the jinalgeneratingset \nincludes allrnaximalresourcesof the targetma\u00adchine. Proof. Rules 1,2,3, and4 neverplacea usage in a resource \nunless it is compatible with each other usage in that resource, i.e. no resource in the current (and \nhence final) generating set forbids any latency not forbidden in the target machine. We prove. the second \npart of Theorem 1 by contradiction. Sup\u00adpose there is a maximal resource not in the generating set. We \nshift its resource usages so that its earliest usage occurs in cycle O and call that maximum resource \ng. If q has a single usage, by operation X, either Rule 4 applies and thus q is present in the final \ngenerating set or Rule 4 does not apply and thus q is not a maximal resource since at least one resource \n(with two or more usages) in the final generating set has a usage associated with operation X. Otherwise, \nlet q have n usages, UI to Un, with UI in cycle O. We refer to the elementary pairs containing usage \nal and each of the other n 1 usages as pz to p.. Without loss of generality, we may assume that the \nelementary pairs p2 to pn are numbered in the order in which they are processed by Algorithm 1. After \np2 is processed (by Rules 1,2, and 3), its corresponding usages ul and U2 are present in at least one \nresource, qlz, of the current generating set. Other elementary pairs are then processed, possibly adding \nusages to q12, but never removing any. Eventually, the algorithm will process p3. From resource q, we \nknow that the usages of pz are both compatible with p~. Hence Rule 1 or 2 wiU result in a resource qlzs \ncontaining usages UI, ZL2,us, and possibly others; Rule 3 will not apply. Repeating this process with \nall the remaining elementary pairs, including p4 through p., we obtain resource q12.,, ~ containing all \nusages U1 through w., and possibly others. Thus the set of usages in resource q is a subset of the usages \nin qlz .... which is in the final generating set. Hence q is either not maximal or is present in the \nfinal generating se~ which contradicts the initial assumption. 0 Figure 3 illustrates the algorithm, \nstep by step, for our exam\u00adple machine. The algorithm processes the four nonnegative forbid\u00adden latencies \n(excluding the O self-contention latencies) 1 c FB,A, 1 c FB,B, 2 G FB,B, and 3 E FB,B, in that order. \nThe O self\u00adcontention Iatencies are included automatically without special sin\u00adgle usage resources in \nthis example. The generating sets are shown at each step, in Figures 3a, 3b, 3c, and 3d, respectively. \nThe rule ap\u00adplied to each resource is also indicated to the right of each resource. 5 Selecting Synthesized \nResources and Resources Usages Once the generating set of maximal resources has been computed, we select \na subset of these resources and their usages that covers all the forbidden latencies in the forbidden \nlatency matrix. The selec\u00adtion heuristic attempts to minimize an objective function that varies as a \nfunction of the desired internal representation for partial sched\u00adules. In this paper, we consider the \ntwo following internal represen\u00adtations. Discrete-Representation. This representation uses a reserved \nta\u00adble with one row per resource and one column per schedule cy\u00adcle. Each entry contains a flag indicating \nwhether the correspond\u00ading resource has been reserved by an operation in the current par\u00adtial schedule. \nEntries may contain additional fields, such as a field identifying the operation that consumes the corresponding \nresource, a) Fully compatible b) Partially compatible c) Partially compatible, no other usages sO  &#38;EMfl \n source &#38;ikfl sO  m.:.4:5ig~ Elementary pair m Elementary pair m Elementary pair m Updated source \nm :~~:e m No update, no new resource 1,,:,,,,,,,,,,,,  ,,, ,,, Compatible elementary with pair 0~~; \nIncompatible :.:.:.:.:.:.:. elementary with pair Figure 2 Three situations when adding an elementary \npair to a resource. associated with thetarget machine [24]. Amaximalresource is de\u00adftned as a synthesized \nresource such that (a) every forbidden latency generated by this resource is forbidden in the target \nmachine and(b) no additional usage by any operation can be added to this resource without generating \na forbidden latency that is not forbidden in the target machine. Finally since shifting allusages inaresourceby \nsome constantin time has noeffect ontheforbidden latencies, we only consider maximrd resources that have \ntheir earliest usage in cy\u00adcle O. From the construction in Theorem 1 below, it follows that there are \nonly two maximal resources in our example machine, as shown Figurelc. The6rst resource, resource 0 , \nisa maximal resource thatgeneratesl c l B,A; italsoincludes forbidden latencies: O &#38; F~,A, O c FB,B, \nand 1 c FA B. Note that no other usages of A or13can beadded toresource O , astheywould necessarily \nintro\u00adduce forbidden latencies not present in the forbidden latency matrix of our example machine. Similarly \nthesecond maximal resource, resource 1 , generates FB,B which includes allthe remaining for\u00adbidden latencies \nandnoother usages can be added. Note thatthe forbidden latency sets of the maximal resources need not \nbe disjoint e.g. O c FB,Eisgeneratedby bothmaximalrows here. The maximal resources are interesting because \nany reservation table that generates the same forbidden latency matrix can be con\u00adstructed from subsets \nof maximal resources, where the selected us\u00adage set in each resource may be translated by some number \nof cy\u00adcles. Asaresu14we canusea (possibly empty) subsetoftheusages of each maximal resource to cover \nalltheforbidden latenciesof a target machine with the fewest number of (nonempty) synthesized resources. \nStep3. Weselect asubset of themaximrd resources andtheirre\u00adsoume usages which covers all the forbidden \nlatencies in the forbid\u00adden latency matrix. The selection heuristic minimizes an objective function that \nvaries as a function of the desired internal representa\u00adtion. For our example machine, if the objective \nis to minimize the number of synthesized resources, we must select both resources O and 1 , since resource \nO is the only resource covering O E FA,A and resource 1 is the only resource covering 3 G F=,=. However, \nif the objective function is to minimize the number of resource us\u00adages, we may also remove the second \nor third usage of B in resource 1 , shown Figure lc, since the three remaining usages of B are suf\u00adficient \nto generate all the forbidden latencies in FB,B. Comparing Figure la to Figure ld, we can appreciate \nthe bene\u00adfit of reducing the reservation tables of a target machine. First the reduced machine description \nreduces the number of resources from 5 to 2, thus potentially decreasing the memory requirements needed \nto store the reserved resources of a schedule. Second, the number of resource usages decreases from 3 \nto 1 for operation A, and from 8 to 4 for operation B. If detecting resource contentions is linear in \nthe number of usages, the reduced machine description results in significantly faster queries. We refine \nthis view in Section 7. 4 Building Generating Sets of Maximal Resources In this section, we present an \nalgorithm that constructs the gener\u00adating set of maximal resources, a set that contains all the maximal \nresources of a target machine. The algorithm builds the maximal re\u00adsources incrementally, adding usages \nto current resources and cre\u00adating new resources when appropriate. It is an efficient algorithm that \ndoes not backtrack, however, it may produce some submaximal resources in addition to rdl the maximal \nresources. A mechanism to remove submaximal resources as well as redundant maximal re\u00adsources is discussed \nin Section 5. We do not consider here the forbidden latencies directly but em-P1OYelementary pairs of \nusages that generate them. We define the elementary pair associated with forbidden latencies f E FX,Y \nas a usage by operation X in cycle O and a usage by operation Y m cycle f. We also define a compatibility \nrelation between an elementary pair and the usage of a resource. Elementmy pair, p, with usages U. and \nU1 is compatible with a usage, u, in resource q if the (non\u00adnegative) forbidden latencies generated by \nu, U. and u, U1 are both in the forbidden latency matrix.  Note that any resource with n usages can \nbe constructed from n 1 elementary pairs, namely by (a) shifting all its usages by some constant so \nthat its first usage occurs in column O, (b) choosing one usage in column O and constructing a set of \nelementmy pairs con\u00adsisting of this usage together with each other usage in the resource, and (c) placing \nall these pairs, which are known to be compatible since they exist together in the given resource, together \nin one re\u00adsource which is then the same as the given resource. Algorithm 1 (Buildiug Generating Sets \nof Maximal Resources) The tirst step assigns the initial generating set to the empty set and builds a \nlist of elementmy pairs associated with the forbidden laten\u00adcies of the target machine. We exclude here \nthe elementary pairs associated with the negative forbidden Iatencies (f < O) since they are redundant \n(i.e. f c FX, Y + f G FY,x). We ~SO exclude the elementary pairs associated with the O self-contention \nIatencies (O c l x,x), which are processed as a special case at the end of the algorithm. The second \nstep attempts to add the first elementary pair on the list to each of the resources of the current generating \nset in turn, One of two cases will occur when attempting to add elementary pair p to resource q Representation: \nongmal discrete bltvectors (32 bits) (64 bits) Objective function minimizing: - res-uses l-cycle-word \nuses 2-cycle-word uses 4-cycle-word uses number of resources 56 15 15 15 15 average resource usages J \noperation 18.2 8.3 8.8 10.1 11.4 average word usages / operation 13.2 z? Q 4.7 ~ Table 1: Results for \nthe Cydra 5:52 operation classes, 10223 forbidden latencies (all < 41). Representation: Origlrlal discrete \nbltvectors (32 bits) (64 bits) objective function mummzmg: res-uses 1-cycle-word uses 3-cycle-word uses \n7-cycle-word uses number of resources 39 9 9 9 9 average resource usages / operation 9.4 Z!.9 2.9 3.6 \n4.2 j= average word usages J operation 7.5 26 20 15 Table 2: Results for a subset of the Cydra 5:12 operation \nclasses, 166 forbidden latencies (all < 21). as used in the Iterative Modulo Scheduler algorithm [3], \nor a ltield identifying the predicate under which the resource is reserveci, as proposed in the EnhancedModulo \nScheduling scheme [2], Because the number of entries tested to detectresource contentions is propor\u00adtional \nto the number of resource usages overall reduced reservation tables, the primary objective of the selection \nheuristic is to minimize the number of resource usages in the reduced machine description. This objective \nfunction is referred to as res-uses. Bitvector-representation. This representation extracts the flag \nbits of the discrete representation and packs them into one bi~ector per schedule cycle (and reduced \nreservation tables are represented like\u00adwise). If k bitvectors can be packed per memory word, the number \nof words tested to detect resource contentions is reduced, as are the memory requirements for storing \nthe reserved table. The primary objective of the selection heuristic is now to minimize the number of \nwords that need to be tested, i.e. the number of nonempty groups of k consecutive cycles in the reduced \nreservation tables. A seco\u00adndary objective is to maximize the numbers of resource usages in these nonemply \nwords, as more resource usages per word permit faster (early out) detection of resource contentions. \nThis objective function is referred to as k-cycle-word uses, where k is the number of bitvectors packed \nin a single memory word. Selection Heuristic. Although integer programming can solve these minimum cover \nproblems, we have found a fast and effec\u00adtive heuristic. FirsL we prune the resources of the generating \nset by successively removing each resource that produces a set of forbid\u00adden latencies that is generated \nor covered by a remaining resource. At this point all nonmaximal resources, if any, and others such as \nmirror-images of maximal resource, are eliminated from the gener\u00adating set. Second, for each nonnegative \nforbidden latency, we buiId a list containing all usage pairs that generate the forbidden latency in \nthe pruned generating set. Third, we choose one of the forbidden Iatencies with the short\u00adest list of \nusage pairs. The heuristic selects from the list the usage pair that covers the largest number of forbidden \nlatencies not !tet covered by currently selected resource usages. In case of ties, the heuristic selects \nthe usage pair whose newly covered forbidden la\u00adtencies have a larger sum. Once a usage pair is selected, \nthe pair of usages and the corresponding resource are marked as selected. When using the bitvector-representation, \nthe heuristic also marks every other usage of marked resources within the same word. The selection heuristic \nthen proceeds with the next nonnegative forbid\u00ad den latency (third step) until the marked resource usages \ncover ev\u00ad ery forbidden latency in the target machine. 6 Reduced Machine Examples In this section, we \npresent experimental results for three machines, the DEC Alpha 21064, the MIPS R3OOWR3O1O, and the Cydra \n5. Each reduced machine description generates exactly the same for\u00adbidden latency matrix as the original \nmachine description. For the Cydra 5 machine descriptions, we also verified that precisely the same schedules \nwere produced regardless of the machine descrip\u00adtion used by the compiler when scheduling a benchmark \nsuite of 1327 loops obtained from the Perfect Club [25], SPEC-89 [26], and the Livermore Fortran Kernels \n[27]. For each machine and internal representation, we present three data points, including the total \nnumber of resources in the machine description, the average number of resource usages per operation class \nin the machine description, and the average number of words of bitvectors that need to be tested to answer \na query, i.e. the num\u00adber of nonempty groups of k consecutive cycles in the reservation tables. The third \nmetric, referred to as word usage, is averaged over all operation classes and possible alignments between \nthe bitvec\u00adtors encoding the reserved and reservation tables. In this section we assume that each operation \nclass has the same frequency, which yields pessimistic average usages since complex operations are usu\u00adally \nless frequent than simple operations. We also assume that the performance of the contention query module \nis proportional to the average resource usage or word usage per operation, depending on the internal \nrepresentation. A more detailed performance analysis of the contention query module is presented in Section \n8. As a proof of concept we investigated our technique on the Cy\u00addra 5 machine [21] which has the most \ncomplex resource require\u00adments of the three machines. The machine configuration investi\u00adgated here has \n7 functional units: 2 memory pofi 2 address gen\u00aderation, 1 FP adder, 1 FP multiplier, and 1 branch unit. \nThe origi\u00adnal machine description used by the Cydra 5 Fortran77 compiler [1 ] was manually optimized, \ni.e. some physical resources were elimi\u00adnated from the machine description as they did not introduce \nany new forbidden latencies [28]. This description models 56 resources and 152 distinct patterns of resource \nusages, resulting in 52 distinct operation classes with 10223 forbidden latencies. It is significantly \nlarger than the machine descriptions used in previous studies, e.g. it has 3.5 times more operation classes \nand 2.4 times more forbidden Iatencies than the MIPS R3000/R3010 machine description used in [15]. Our \nalgorithm reduced this original Cydra 5 machine descrip\u00adtion in less than 11 minutes on a SPARC-20. Table \n1 presents data for four reduced machine descriptions and the original description of the Cydra 5. The \nsecond col\u00ad Representation: original discrete bltvectors (32 bits) (64 bits) Objective function mmummng: \nnumber of resources average resource usages / operation average word usages / operation res-uses l-cycle-word \nuses 4-cycle-word uses 9-cycle-word uses 87 77 12.8 ~ 5 !9 8.1 10.9 11.6 5.0 fL&#38;3 ~ 20 -L.. Table \n3: Results for the DEC Alpha 21064:12 operation classes, 293 forbidden latencies (all < 58). Representation: \nongmal discrete bitvectors (32 bits) (64 bits) res-uses ~ 1-eye e-word uses -cycle-word uses number of \nresources 22 7 7 7 7 average resource usages / operation 17.3 ~ 8.1 8.3 8.5 average word usages / operation \n11.0 5.6 ~ g 1.6  Table 4: Results for the MIPS R3000/R3010: 15 operation classes, 428 forbidden latencies \n(all < 34). umn corresponds to the machine description reduced for discrete\u00adrepresentation, i.e. it attempts \nto minimize res-uses. The three re\u00admaining columns correspond to machine descriptions for reduced bi~ector-representation, \ni.e. they attempt to minimize k-cycle-word uses and secondarily maximize res-uses. Underlined numbers \ncor\u00adrespond to the entries minimized by the respective objective func\u00adtions. Compared to the original \nmachine description, the reduced ma\u00adchine descriptions reduce the number of modeled resources by a fac\u00adtor \nof 3.7 (from 56 to 15). For discrete representation, the average resource usage is reduced by a factor \nof 2.2 (from 18.2 to 8.3). Sim\u00adilarly, for the 64 bit word bitvectorrepresentation, the average word \nusage is decreased by a factor of 4.0 (from 13.2 to 3.3). Only 2590 of the data storage used by the original \nmachine descriptions required to store the reserved tables (4 cycles of 15 bits each vs. 1 cycle of 56 \nbits per word). Note the successive increases in the number of re\u00adsource usages when reducing for 1,2, \nand 4 cycles per word. These increases permit faster detection of resource contentions and do not increase \nmemory space for state storage. Table 2 presents similar data for the subset of operations actu\u00adally \nused in the 1327 loop benchmark compiled for the Cydra 5. Comparing the original description to the reduction \nfor a 64 bit word bitvector representation, the reduced machine description decreases the average word \nusage by a factor of 5 (from 7.5 to 1.5). The reser\u00advation tables associated with the machine descriptions \nof the origi\u00adnal model, the discrete reduction, and the 64 bit word bitvector re\u00adduction are shown, respectively, \nin Figures444b, and 4c. Table 3 shows the results of our technique for the DEC Alpha 21064 [19] using \nthe machine description presented by Brda and Rubin [17]. Comparing the original description to the specific \nre\u00adduction for a 64 bit word bitvectorrepresentation, the average word usage is decreased by a factor \nof 5.8. This reduced representation may detect all resource contentions by testing on average two 64 \nbit words even though the largest forbidden latency is 58 cycles. Bala and Rubin havepresented factored \nfinite-state automata for this pro\u00ad cessor with (237 + 232) states in the forward automata and (237 + \n231) states in the reverse automata. By encoding each factored state in 8 bits, and assuming that each \nstate is stored as opposed to recom\u00adputed, 64 bits of memory per schedule cycle are needed to cache the \n8 states per cycle of the factored forward and reverse automata for this dual issue microprocessor, compared \nto 7 bits per schedule cy\u00adcle for the bi~ector specific reductions. Table4 shows theresulta of our technique \nfor the MIPS R3000/-R301O [20] using the machine description presented by Proebsting and Fraser [15]. \nComparing the original description to the specific 64 bit word bitvector reduction, the reduced machine \ndescription decreases the average word usage by a factor of 6.9. Proebsting and Fraser reported a (forward-only) \nfinite-state automaton for this pro\u00adcessor with 6175 states [15]. 7 Contention Query Module To evaluate \nthe impact of performance of contention query module for the two The module supports four ass i gn&#38; \nf ree, and free reduced machine descriptions on the queries, we implemented a contention representations \ndescribed in Section 5. basic functions: check, ass ign, for a given operation X and cycle j. Check. \nThis function determines whether operation X can be scheduled in cycle j in the current partial schedule \nwithout gen\u00aderating resource contentions. For the discrete representation, this query checks each usage \nin the reservation table for operation X (offset by j cycles) against the corresponding entry in the \nreserved table. When a resource contention is detected, the function aborts its search; otherwise, every \nusage is checked before the query com\u00adpletes successfully. The number of usages tested by the function \nis thus bounded by the total number of usages in the reservation table for operation X. For the bitvector \nrepresentation, this function simply amounts to anding each nonempty bitvector in the reservation table \nwith the corresponding column bitvector in the reserved table and check\u00ading for a Oresult. With k bi~ectors \npacked per memory word, con\u00adtentions for k consecutive cycles are effectively detected by per\u00adforming \na one word and and test. The function aborts as soon as contentions are detected; otherwise, every non-empty \nword in the reservation table is checked before the query completes success\u00adfully. The number of words \ntested by the function is thus bounded by the total number of non-empty words in the reservation table \nfor operation X. Assign. This function reserves each of the resources consumed by operation X scheduled \nin cycle j. When a discrete representation is used, this function simply sets the flag of each reserved \ntable en\u00ad hy corresponding to a usage in the reservation table for operation X (offset by j cycles). \nWhen a bitvector representation is used, the words encoding the bitvectors of the reservation table for \noperation X (offset by j cycles) are ored to the corresponding words encod\u00ading the bitvectors of the \nreserved table. Assign&#38;free. Unlike the previous function, the ass ign&#38; f ree function tirst \nensures that the resources consumed by operation X are available. If any of the resources are already \nreserved by ether operations, these operations (and possibly others [3]) will be un\u00adscheduled and their \nresources released. The function is implemented by adding a new field to each re\u00adserved table entry, \nidentifying the operation that reserves the corre\u00adsponding resource. The new field is used to determine \nwhich opera\u00adtion to unscheduled, and is updated each time a resource is reserved. For the discrete representation, \nthe function iterates over each usage in the reservation table for operation X, detecting resource contentions, \nunscheduling operations, and updating the correspond\u00ading reserved table entry fields (flag and new field). \nFor the bitvec\u00adtor representation, we use an optimistic strategy which initially does not update the \nnew fields (optimisdc mode). Thus the resources are checked and reserved, respectively, by simply anding \nand oring the words encoding the bitvectors. However, when an operation must be unscheduled because of \nresource contentions, the entire list of scheduled operations is scanned to reconstruct the new field \nen\u00adtries, which will be kept up-to-date thereatler (update mode). In up\u00addate mode, the function iterates \nover each usage in the reservation table for operation X since the additional fields must be updated \nfor each resource usage anyway. Free. This function releases the resources consumed by opera[ion X scheduledin \ncycle j. When a discrete representation is used, this function simply resets the flag of each reserved \ntable entry corre\u00adsponding to a usage in the reservation table for operation X (offset by j cycles). \nWhen a bitvector representation is used, this function simply ands the complement of the words encoding \nthe bitvectors of the reservation table for operation X (offset by j cycles) to the words encoding the \nbitvectors of the reserved table. Note that the four basic functions iterate over the resource us\u00adages \nfor the discrete representation and over the words encod\u00ading the bitvectors for the bitvector representation, \nexcept for the ass ign&#38; f ree function in update mode which always iterates over the resource usages. \nNote also that the work performed to han\u00addle a resource usage is approximately comparable to the work \nre\u00adquired to handle a word encoding the bitvectors. As defined in this section, either the assign or \nassign&#38;free function, but not both, may be used within a partial schedule as the later one relies \non the additionrd field in the reserved table. The contention query module provides an additional function \nthat facilitates the finding of a contention-free operation at a giv en cycle in presence of alternatives. \nAlternative operations were intro\u00adduced in Section 3 as related operations performing an identical task \nbut using different resources, e.g. addl and add2 where both c~p\u00aderations perform an addition, but use \ndistinct functional units. fil\u00adtemative operations may contain more operations than those caused by replicated \nhardware structures, e.g. a move operation may also be implemented as add O or mul t 1. The additional \nfunction is defined as follows. Check-with-aIt. This function determines if operation X, or any of its \nrdtemative operations, can be scheduled in cycle j without re\u00adsource contentions. If so, the function \nreturns one of the contention\u00adfree operations; otherwise, it returns an error value. In this paper, we \nimplemented this function by repetitively calling the check function for each of the alternative operations \nuntil it succeeds. Other more efficient techniques could be implemented. 8 Performance of the Contention \nQuery Module To evaluate the impact of the contention query module and the reduced machine representation, \nwe have selected a state-of-the\u00adart scheduler that results in high performance code at low compu\u00adtational \ncomplexity, and is thus likely to be representative of the scheduling algorithms used in future high-performance \ncompilers. We implemented a scheduler for software pipelined loops using the algorithm developed and \ndescribed by Rau in [3]. This algo\u00adrithm, referred to as the Iierative Modulo Scheduler, exploits the \nin\u00adstruction level parallelism present in loop iterations by overlapping the execution of consecutiveiterations. \nThekeycharacteristicof the scheduling algorithm is its iterative nature it schedules operations using \na priority function that gives precedence to operations along critical paths and allows prior scheduling \ndecisions to be reversed, unscheduling operations when data dependence are violated or re\u00adsource contentions \noccur. The algorithm satisfies the definition of the unrestricted scheduling model since it schedules \noperations in arbitmy order and may reverse scheduling decisions. We used a benchmark of loops obtained \nfrom the Perfect Club [25], SPEC-89 [26], and the Liverrnore Fortran Kernels [27] which consists exclusively \nof innermost loops with no early exits, no pro\u00adcedure calls, and fewer than 30 basic blocks, as compiled \nby the Cydra 5 Fortran77 compiler [1]. The input to the scheduling algo\u00adrithms consisk of the Foriran77 \ncompiler intermediate representa\u00adtion after load-store elimination, recurrence back-substitution, and \nIF-conversion. The benchmark suite consists of the 1327 loops suc\u00adcessfully modulo scheduled by the Cydra \n5 Fortran77 compiler. The characteristics of the generated schedules for the 1327 loop benchmark are \nsummarized in Table 5. The fist two rows indicate the number of operations per loop iteration and the \ninitiation inter\u00adval of the software pipelined loops. The third row shows to the ra\u00adtio of the initiation \ninterval (11) to the minimum initiation inter\u00adval (MII), and is a good indication of the quality of the \nproduced schedules. We see that in 95.69. of the loops, our implementation of the Iterative Modulo Schedulerproduces \na schedule with minimum initiation interval, i.e. achieving the maximum feasible steady-state throughput. \nThis ratio is within 0.5% of that obtained in [3]. ~1 easuremenk: 1 ea. 1 av ~ 1 max I number of operations \nI 2.00 0.4% I 17.54 I 161.001 initiation int&#38;val (11) 1.00 28.7% 11.52 165.00 11/MII 1.00 95.6% 1.01 \n1.50 sched. decisions I oDeration 1.00 78.7% 1.52 6.00 Table 5: Characteristics of the 1327 loop benchmark. \n A key feature of the Iterative Modulo Scheduler algorithm is that it can reverse a limited number of \nscheduling decisions. In this paper, the scheduler may perform up to 6N scheduling decisions, where N \nis the number of operations in the loop being scheduled. When the scheduler exceeds the allocated budget \nof scheduling de\u00adcisions, the scheduling rdgonthm makes a new attempt with a larger initiation interval. \nThe last row of Table 5 indicates that in 78.7$Z0of the loops, no scheduling decision was ever reversed. \nThe actual ratio of schedule decisions to the number of operations is 1.52, when averaged over each loop \nand each scheduling attemp~ including the 9.6% of the attempts for which the 6N upper limit was exceeded. \nThe ratio is highly sensitive to the upper limit used by the schedule~ e.g. an Upper limit of 2N resuks \nin an average ratio of 1.14, including the   11.3% of the attempts for which the 2N upper limit was \nexceeded. The contention query module used in this section closely corre\u00adsponds to the one described \nin Section 7, adapted to handle the pe\u00adriodicity of the modulo schedules (i.e. using a Modulo Reservation \nTable [24][29]). We used here the assign&#38;free function instead of the simpler assign function because \nthe scheduling algorithm schedules an operation even though it may result in resource con\u00ad tentions, \nin which case the earlier scheduled operations that conflict are unscheduled. In the 1327 loop benchmark, \nthe assign&#38;free function unscheduled one or more operations in 13.0% of the at\u00adtempts, accounting \nfor 14.6% of all reversed scheduling decisions; the other reversed scheduling decisions were due to violated \ndepen\u00addence constraints. ~ R epresentatton: Ongulal discrete 32 bits) (64 bits) objective function muunumng: \n- res-uses 1-cycle-word uses 2-cycle-word uses 4-cycle-word uses frequency check 2.62 2.06 1.90 1.25 \n1.11 1>.6% assign&#38;free 5:68 2.15 1.75 1.67 1.63 16.0% free 6.48 2.58 2.23 1.58 1.29 8.4% Weighted \nsum: 3.46 2.11 1.91 1.35 1.21 100.0% Table 6: Performance of the basic functions (in work units per call), \n The performance of each basic function is quantified by count\u00ading the number of units of work performed \nby each function, where one unit of work handles a single resource usage or a single non\u00adempty word in \na reservation table. The overhead incurred in the transition from the optimistic mode to the update mode \nassociated with the ass ign&#38; f ree function is also taken into account. The average number of work \nunits per function call is given for each of the basic functions and machine representations for the \ncomplete Cydra 5 description. The machine representations are those in Ta\u00adble 1. First consider the performance \nassociated with the discrete rep\u00adresentations. Although the reduced machine representation in Col\u00adumn \n2 of Table 6 eliminates much of the redundancy in Column 1, decreasing the average resource usages per \noperation by a factor of 2.2 (from 18.2 to 8.3 in Table 1), the average work units performed by the check \nfunction decreases by only a factor of 1.3, from 2.62 to 2.06 work units. This effect maybe attributed \nto the fact that the redundancy in the original machine description helps in findiog re\u00adsource contention \nquickly. However, the redundancy in the origi\u00adnal machine description significantly affects the average \nwork per\u00adformed by the assign&#38;free and f ree functions, as the reduced description decreases the \naverage work units by a factor of 2.6 and 2.5, respectively. The performance associated with the bitvector \nrepresentations and 1, 2, and 4 bitvectors per word, is shown in Columns 3, 4, and 5 of Table 6, respectively. \nWe can see that increasing the number of bitvectors per word significantly decreases the average work \nunits performed by the check and free functions, each of which iter\u00adates exclusively over non-empty words. \nThe work performed by ass i gn&#38; f r ee also decreases, but more moderately as it iterates either \nover words in the optimistic mode or over resource usages in the update mode, and incurs a mode transition \noverhead. The overall performance of the contention query module is ob\u00adtained by multiplying the average \nwork units performed by each function by the relative frequency of scheduler calls to that fonc\u00adtion \nand summing these products. These frequencies are shown in the rightmost column of Table 6. The most \nfrequently called fonc\u00adtion is the check function as, on average, the scheduler issues 4.74 check queries \nper scheduling decision. Of all the schedule deci\u00adsions, the scheduler issued a single check query in \n49.5% of the cases, two in 15. i ~o, three in 8.770, four in 5.69Z0,five to twenty in 17.0%, and up to \n96 queries in the remaining 3.5 Y.. These numbers include the number of additional check queries generated \nby the check-wit h-a 1 t function used to select an advantageous alter\u00adnative operation; in the benchmark, \n79~0 of the operations have no alternative and 21 YOof the operations have exactly one alternative. The \noverall performance for the five machine descriptions are given in the last row of Table 6. When using \na discrete represen\u00adtation, we see that reducing the machine description increases the performance of \nthe contention query module by a factor of 1.6, de\u00adcreasing the average work units from 3.46 to 2.11. \nWhen using a 64 bit word bitvector representation, reducing the machine descrip\u00adtion increases performance \nby a factor of 2.9, decreasing the aver\u00adage work units from 3.46 to 1.21. Query module work with a 64-bit \nmachine description is thus only2190 above the absolute minimum since the contention query module must \nhandle at least one unit of work per call to detec; reserve or free the resources modeled in any finite-resource \nmachine model. 9 Conclusions In this paper, we have presented an efficient contention query mod\u00adule that \nsupports the elaborate scheduling techniques used by to\u00adday s high performance compilers. In particular, \nwe support un\u00adrestricted scheduling models, where the operation currently be\u00ading scheduled may be placed \nbefore some already scheduled op\u00aderations and backtracking is performed to produce highly opti\u00admized \nsoftware-pipelined and critical-path sensitive schedules. We also support precise boundary conditions \nwhere resource require\u00adments may dangle from predecessor basic blocks to permit effective latency-hiding \ntechniques. Our contention query module is based on a reduced machine description that results in significantly \nfaster detection of resource contentions while exactly preserving the scheduling constraints present \nin the original machine description. This approach achieves two goals. Firs~ it handles queries significantly \nfaster which is in\u00adcreasingly important as queries for contentions are issued within the innermost loop \nof a scheduler and their complexity increases with machine complexity. Second, it reduces machine descriptions \nin an error-free and automated fashion, thus, simplifying the inter\u00adface between the actual hardware \nstructure of the target machine and the compiler representation of the scheduling constraints due to \nre\u00adsource contentions. Experiments with three machine descriptions indicate that our approach addresses \nthe perceived weakness of resource modeling approaches based on reservation tables, Because the machine \nde\u00adscriptions are reduced, all resource contentions of one query are detected by a conservative (unweighed) \naverage of 1.6 (MIPS R3000/R3010), 2.0 (DEC Alpha 21064), and 3.3 (Cydra 5) and operations when using \nthe 64 bit word bitvector representation. Pre\u00adcise experiments with a state-of-the-art scheduler and \na contention query module indicates that the average number of work units @re\u00adcessing one non-empty word \nor resource usage in a reservation ta\u00adble) is as low as 1.21 for a benchmark of 1327 loops from the Perfect \nClub, SPEC-89, and the Livermore Fortran Kernels on the Cydra 5 using the 64-bit word bitvector representation. \nMoreo~er, the mem\u00adory requirements needed to store the reserved resources of a sched\u00adule are small, as \na 64 bit word may encode the bitvector of 4 (Cy\u00addra 5),9 (MIPS R3000/R3010), or 9 (DEC Alpha 21064) schedule \ncycles. Acknowledgments This work was supported in part by the Office of Naval Research under grant number \nNOO014-93-1 -0163 and by Hewlett-Packard; much of this work was carried out whiIe visiting Hewlett Packard \nLaboratories in summer 1995. The authors would particularly like to thank B. Ramakrishna Rau for suggesting \nthe problem and pro\u00adviding much helpful guidance in formulating it. The authors would also like to thank \nSantosh Abraham, Scott Mahike, B. Ramakrishna Rau, and Michael Schlansker for many useful suggestions \nand for providing the Cydra 5 machine model and loop benchmark. The help of Todd Proebsting regarding \ntheMIPS R3000/R3010machine model and Vasanth Bala on the Alpha 21064 machine model is also gratefully \nacknowledged. References [1] J. C. Dehnert and R. A. Towle. Compiling for the Cydra 5. In The Journal \nof Supercort+outing, volume 7, pages 181-227, 1993. [2] N. J. Warter, G. E. Haab, K. Subramanian, and \nJ. W. Bock\u00adhaus. Enhanced Modulo Scheduling for loops with condi\u00adtional branches. Proc. of the 25th Annual \nInternational Sym\u00adposium on Microarchitecture, pages 170-179, Dec. 1992. [3] B. R. Rau. Iterative Modulo \nScheduling: An algorithm for software pipelining loops. Proc. of the 27th Annual Interna\u00adtional Symposium \non Microarchitecture, pages 63-74, Nov. 1994. [4] R. A. Huff. Lifetime-sensitive modulo scheduling. Proc.of \nthe ACM SIGPLAN 93 Conference on Programming Languuge Design and Implementation, pages 258-267, June \n1993. [5] J. R. Goodman and W.-C. Hsu. Code scheduling and regis\u00adter allocation in large basic blocs. \nProceedings of the Interrsa\u00adtional Conference on Supercomputing, pages 442-452, 1988. [6] K. Ebcioglu, \nR. D. Groves, K.-C. Kim, G. M. Silberman, amd I. Ziv. VLIW compilation techniques in a superscalarenvirun\u00adment. \nIn Proc. of the ACM SIGPLAN94 Conference on Pro\u00adgramming Language Design and Implementation, pages 36\u00ad48.1994. \n [7] G. P. Lowney et al. The Multitlow trace scheduling compiler. In The Journal of Supercomputing, volume \n7, pages 5 1 142, 1993. [8] P. P. Chang, N. J. Warter, S. A. Mahlke, W. Y. Chen, andw. W. Hwu. Three \narchitectural models for compiler-controlled speculative execution. IEEE Transactions on Computers, 44(4):481494, \nAprd 1995. [9] D. Bernstein and M. Rodeh. Global instmction scheduling :for superscalar machines. In \nProc. of the ACM SIGPLAW91 Con\u00adference on Programming Language Design and Implementa\u00adtion, pages 241-255, \nJune 1991. [10] S.-M. Moon and K. Ebcioglu. An efficient resource\u00adconstrained global scheduling technique \nfor superscalar and VLIW processors. Proc. of the 2.5th Annual International Symposium on Microarchitecture, \npages 55-71, Sept. 1992. [11] P. P. Chang, S. A. Mahlke, W. Y. Chen, N. J. Warter, and W. W. Hwu. IMPACT \nAn architectural framework for multiple\u00adinstruction-issue processors. In Proceedings of the Eighteenth \nAnnual International Symposium on Computer Architecture, pages 266-275, May 1991. [12] J. C. Gyllenhaal. \nA machine description language for compila\u00adtion. Master s thesis, Department of Electrical and Computer \nEngineering, University of Illinois, Urbana, IL, 1994. [13] J. A. Fisher. Trace scheduling: a technique \nfor global mi\u00adcrocode compaction. IEEE Transactions on Computers, 30(7):478-490, July 1981. [14] V. Kathail, \nM. S. Schlansker, and B. R. Rau. HPL PlayDoh ar\u00adchitecture specification: Version 1.0. Technical Report \nHPL\u00ad93-80, HP Laboratories, Feb. 1994. [15] T. A. Proebsting and C. W. Fraser. Detecting pipeline struc\u00adtural \nhazards quickly. Twenty-First Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan\u00adguages, \npages 280-286, Jan. 1994. [16] T. Mi.dler. Employing finite automata for resource schedul\u00ading. Proc. \nof the 26th Annual International Symposium on Mi\u00adcroarchitecture, pages 12-20, 1993. 17] V. Brda and \nN. Rubin. Efficient instruction scheduling using finite state automata. Proc. of the 28th Annual International \nSymposium on Microarchitecture, pages 46 56, Nov. 1995. 18] M. Lam. Software Pipelining: An effective \nscheduling tech\u00adnique for VLIW machines. Proc. of the ACM SIGPLAN 88 Conference on Programming Language \nDesign and Implem\u00adentation, pages 318-328, June 1988. r 119] Digital Equipment Corp., Maynard, MA. DecChip \n21064 Mi\u00adcroprocessor Hardware Reference Manual EC-NO079-72. [20] G. Kane and J. Heinrich. MIPS RISC \nArchitecture. Prentice Hall, 1992. [21] G. R. Beck, D. W. L. Yen, and T. L. Anderson. The Cydra 5 minLsupercompute~ \nArchitecture and implementation. In The Journal of Supercomputing, volume 7, pages 143-180, 1993. [22] \nE. S. Davidson, L. E. Shar, A. T. Thomas, and J. H. Patel. Ef\u00adfective control for pipelined computers. \nSpring COMPCON\u00ad75 digest of papers, pages 181-184, Feb. 1975. [23] V. Bala. Personal communication. Feb. \n1996. [24] J. H. Patel and E. S. Davidson. Improving the throughput of a pipeline by insertion of delays. \nProceedings of the Third Annual International Symposium on Computer Architecture, pages 159-164,1976. \n[25] M. Berry et al. The Perfect Club Benchmarks: Effective per\u00adformance evaluation of supercomputers. \nThe International JournalofSupercornputerApplications, 3(3):5-40, Fall 1989. [26] J. Uniejewski. SPEC \nBenchmark Suite: Designed for today s advanced system. SPEC Newsletter, Fall 1989. [27] F. H. McMahon. \nThe Livermore Fortran Kernels: A com\u00adputer test of the numericrd performance range. Technical Re\u00adport \nUCRL-53745, Lawrence Livermore National Laboratory, Livermore, California, 1986. [28] M. S. Schlansker. \nPersonal communication. June 1995. [29] P. Y. Hsu. Highly Concurrent Scalar Processing. PhD thesis, Universi~ \nof Illinois at Urbana-Champaign, 1986. c)Bitvector representation machine demription (64 hit word) (9 \nresources, 63 resource ussgea) 00000000001111 11111122 012345678901234 56789ol qo ,= ql J q5 , q6 , \nql , q5 , q6 , ql , qs , q6 t 000000000011111 1111122 012345678901234 567e901 5, a) Ori&#38;inal machine \ndescription (39 ;eeources, 132 resou;ce 0000000000111111 01234567890123 qo q2 q3 q4 qO ql c12 q4 q5 q6 \nq7 q8 C19 qlo qll q12 q13 q14 qls q9 qlo qll qlz q13 q14 q15 q17 I I I I I I I I I q18 q19 I I I I I \nI I I I  b) Discreterewesentation usages) machine description (9 reeources, 43 resource usages) 1111222222 \n0000000000111111111122 456789012345 01234567!39012345 678901 qo ~ ql, III q5 , q6 ! 11111 ql , q5 , \nq6 , IIIIIIIIIIIII II I  111111I II I q2 o 11111111111111111=111 II q22 q23 q24 q25 Ill I I I I II \nI I 1111 I I II I I I I q5 q6 q7 q26 I + I I i-t\u00ad I I I I T  -T\u00ad TllT! I I I + q27 II 11111 1111111111111[ \n .g29 q2 s11111III III IIIHI IIII q3 o q21 q31 q32 q33 q34 q35 q36 q38 r q9 ql qlo q5, qll q6, q12 000000000011111 \n1111122 q13 012345678901234 567e901 q14 q15 0000000000111 1111111222222 01234567890123 4567139012345 \nFigure 4: Reservation tables for a subset of the Cydra 22 \n\t\t\t", "proc_id": "231379", "abstract": "High performance compilers increasingly rely on accurate modeling of the machine resources to efficiently exploit the instruction level parallelism of an application. In this paper, we propose a reduced machine description that results in faster detection of resource contentions while preserving the scheduling constraints present in the original machine description. The proposed approach reduces a machine description in an automated, error-free, and efficient fashion, Moreover, it fully supports schedulers that backtrack and process operations in arbitrary order. Reduced descriptions for the DEC Alpha 21064, MIPS R3000/R3010, and Cydra 5 result in 4 to 7 times faster detection of resource contentions and require 22 to 90% of the memory storage used by the original machine descriptions. Precise measurement for the Cydra 5 indicates that reducing the machine description results in a 2.9 times faster contention query module.", "authors": [{"name": "Alexandre E. Eichenberger", "author_profile_id": "81100575094", "affiliation": "Advanced Computer Architecture Laboratory, EECS Department, University of Michigan, 1301 Beal Ave, Ann Arbor, MI", "person_id": "P14433", "email_address": "", "orcid_id": ""}, {"name": "Edward S. Davidson", "author_profile_id": "81100100296", "affiliation": "Advanced Computer Architecture Laboratory, EECS Department, University of Michigan, 1301 Beal Ave, Ann Arbor, MI", "person_id": "PP14044916", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/231379.231386", "year": "1996", "article_id": "231386", "conference": "PLDI", "title": "A reduced multipipeline machine description that preserves scheduling constraints", "url": "http://dl.acm.org/citation.cfm?id=231386"}