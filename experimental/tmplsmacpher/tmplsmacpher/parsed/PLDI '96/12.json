{"article_publication_date": "05-01-1996", "fulltext": "\n Efficient and Language-Independent Mobile Programs Ali-Reza Adl-Tabatabai*, Geoff Langdale*, 1School \nof Computer Science Carnegie Mellon University Pittsburgh, PA 5213 Abstract This paper evaluates the \ndesign and implementation of Omni\u00adware: a safe, efficient, and language-independent system for executing \nmobile program modules. Previous approaches to implementing mobile code rely on either language semantics \nor abstract machine interpretation to enforce safety. In the former case, the mobile code system sacrifices \nuniversality to gain safety by dictating a particular source language or type system. In the latter case, \nthe mobile code system sac\u00adrifices performance to gain safety through abstract machine interpretation. \nOmniware uses software fault isolation, a technology de\u00adveloped to provide safe extension code for databases \nand operating systems, to achieve a unique combination of language-independence and excellent performance. \nSoft\u00adware fault isolation uses only the semantics of the underlying processor to determine whether a \nmobile code module can corrupt its execution environment. This separation of pro\u00adgramming language implementation \nfrom program module safety enables our mobile code system to use a radically simplified virtual machine \nas its basis for portability. We measured the performance of Omniware using a suite of four SPEC92 programs \non the Pentium, PowerPC, Mips, and Spare processor architectures, Including the overhead for enforcing \nsafety on all four processors, OmniVM executed the bench\u00admark programs within 21% as fast as the optimized, \nunsafe code produced by the vendor-supplied compiler. Permissionto make digitathard copy of part or \nall of this work for personal orolassroomuseis rantadwithoutfeeprovidedthatcopiesarenotmade ! ordistributedfor \nproNoreommaroialadvantage,the copyrightnotice,the title of the ubliition and&#38; date appear, and notice \nis given that copyingisi ypermissionofACM,ho. Tocopyotherwise,torepublish,to pestonservers,ortoredistributetolists,requirespriorspedfie \npermission and/or a fee. PLDI 96 Y96 PA, USA @ 1am ACfvt o-ae79t-79tk~wooo5...$5050 Steven LUCC02 and \nRobert Wahbe2 2Colusa Software 1563 Solano Ave. MS-350 Berkeley, CA 94707 1 Introduction The term mobile \ncode describes any program that can be shipped unchanged to a heterogeneous collection of proces\u00adsors \nand executed with identical semuntics on each processor. Currently, the most visible computer application \nrequiring mobile code is executable content for electronic documents. While documents containing executable \ncontent have been around for at least two decades [46, 13], the combination of electronic documents with \nwidely adopted network proto\u00adcols [5] on the Internet requires mobile executable document content. Because \nmobile programs are often untrusted, safety is an essential feature of any mobile code system. The system \nmust maintain precise control over a mobile code module s access to the resources of its execution environment. \nWe call the computer application that loads a mobile code module the host. To achieve safety, it is necessary \nfor the mobile code mechanism to prevent a faulty or malicious module from corrupting host data or calling \nunauthorized host functions. Our mobile code system, Omniware [28], uses software fault isolation (SFI) \nto enforce safety [42]. SFI enables mu\u00adtually distrustful program modules to safely share an address \nspace. Table 1 summarizes the Omniware performance for four SPW92 programs; Section 4 provides detailed \nperfor\u00admance results. To support universal, efficient mobile code, we generalize the notion of a virtual \nmachine to what we call a software-dejined computer architecture. A software-defined computer architecture \n(SDCA) implements a set of virtual instructions, virtual memory management, and a virtual ex\u00adception \nmodel. Our SDCA, the Omniware virtual machine (OmniVM), provides a segmented address space, enforces \nhost-imposed permissions on access to this address space, and delivers an access violation exception \nto the module when\u00adever it makes an unauthorized attempt to access a memory segment. Section 4 quantifies \nthe overhead of using Om\u00adniVM to enforce write and execute protections on multi-page segments. Software \nfault isolation can also support efficient read protection and fine-grained access protection [42, 43]. \n Execution time relative to native program Mips Spare PPC x86 li 1.10 1.05 1.18 1.11 compress 1.04 1.02 \n1.23 1.02 alvinn 1.20 1.07 1.08 1.25 eqntott 1,20 1.04 1.35 1.06 average 1.14 1.05 1.21 1.11 Table 1: \nExecution time of translated code with SFI, relative to native code. Omniware does not yet incorporate \nthese capabilities, SFI uses only the semantics of the underlying processor to determine whether a mobile \ncode module can corrupt the host execution environment. SFI checks each unsafe memory access or indirect \nbranch instruction at runtime to ensure that it does not violate access restrictions. The current Omniware \nsystem inlines these checks when a mobile program is loaded into the host address space and translated \nfrom OmniVM to native code (load time). This separation of programming lan\u00adguage implementation from \nprogram module safety enables Omniware to use a radically simplified (RISC-like) virtual machine as its \nbasis for portability [33]. This design choice has two advantages. First, it simplifies the implementation \nof compilers to OmniVM and transla\u00adtors from OmniVM. For example, we retargeted both gcc [17] and lcc \n[16] to OmniVM within two months. Sec\u00adond, the use of simple instructions gives the source language compiler \nmore opportunity for optimization because more aspects (such as data layout) of the final code are defined \nby the compiler. Hence, a compiler can perform a great deal of machine-independent optimization (such \nas register allo\u00adcation, constant folding, constant propagation, and strength reduction [2]) prior to \nmodule load time. This is important in many mobile code contexts such as Web pages where load time, and \nhence optimization during loading, must be mini\u00admized. Section 4 demonstrates quantitatively that compilers \ncan substantially optimize OmniVM modules prior to load time. The remainder of this paper is organized \nas follows. Sec\u00adtion 2 describes in more detail the types of computer appli\u00adcations that can benefit \nfrom mobile code. Section 3 gives an overview of OmniVM and the tradeoffs in its design. Section 4 presents \na detailed performance analysis of our system. We quantify the overheads introduced by translation and \nsoftware fault isolation, and measure the effectiveness of optimization performed by the translator. \nSection 5 com\u00adpares our approach to mobile code with other mobile code systems and related projects. \n1This document describes Cohrsa t.hnniware Beta version 1.68; later versions may have different features. \nTMs document does not provide an express or implied warranty for any Colusa product or license to any \nColusa intellectual property.  2 Background In the software industry, the need for mobile code is increas\u00adingly \nwidespread. For example, distributed database systems [37] and tile systems [30] require safe function \nshipping to achieve scalability. An e-mail client can ship a mail-filtering function to a server to reduce \nserver bandwidth requirements. A file system server can ship a decompression function to a client to \noffload its processing. Moreover, multi-platform operating systems, such as Mi\u00adcrosoft Windows NT [31], \nwhen combined with network file systems, require either cumbersome management of processor-specific binaries \nor some form of mobile code. Similarly, distributed object-oriented database systems [4] use method invocation \nas a basis for data queries. In the absence of mobile code, these systems must manage het\u00aderogeneous \nbinaries for each dynamically created data class. Because of these requirements, several languages for \npro\u00adgramming distributed systems, such as Orca [3] and Emerald [36], incorporate mobile code as afundrrmental \nprogramming construct. The mobile code systems introduced to date have used one of two methods for enforcing \nsafe execution: abstract machine interpretation or language semantics. Abstract ma\u00adchine interpreters \n[12] trade performance for safety. A mo\u00adbile code system based around an abstract machine consists of \na compiler for some number of source languages cou\u00adpled with an interpreter for the abstract machine. \nThe inter\u00adpreter manages the mapping between virtual resources used by the abstract machine and the physical \nresources of the host, preventing unauthorized access by checking that only valid mappings are used, \nThis mechanism is effective and language-independent, but inherently slow. A mobile code system can use \nlanguage semantics to en\u00adforce safety by guaranteeing that a program can t affect re\u00adsources that it \ncan t name [38, 9, 40]. Though rare in current practice, it is possible to achieve good performance using \nthis approach if the compiler intermediate representation retains type information [23, 39]. However, \nthis approach works through restriction. For example, a strongly-typed intertne\u00addiate language might \npromise through the type system that integer arithmetic will not be performed on a particular value, \nbecause the value has a pointer type. A virtual machine im\u00adplementing this type system can check whether \nthis promise is kept and reject programs that perform type-violating oper\u00adations [18]. Hence, a mobile \ncode system that uses language semantics to enforce safety sacrifices universality. This has two draw\u00ad \nbacks. First, type-based mobile code systems can t imple\u00ad ment type-unsafe languages such asC, C++, Pascal, \nCommon Lisp, and Fortran. In the software industry, the vast majority of re-usable components, software \nlibraries, and programmer expertise is in these languages. Second, and most important, a mobile code \ninfrastructure 128 based on a particular type system imposes barriers to pro\u00adgramming language innovation \nand experimentation. If a programmer invents a better type system, she can t simply deploy on the Internet \na language embodying this type sys\u00adtem, because a type-based infrastructure can only guarantee safety \nwith respect to its existing type system.  3 The design of OmniVM OmniVM is a RISC-based design that \ndefines an instruction set, a register file organization, data formats, an exception model, and a segmented \nvirtual memory model. The design of OmniVM reflects three goals: 1. Portability. OmniVM must be retargetable \nto a variety of target architectures. Moreover, OmniVM must be powerful and flexible enough to support \nthe safe execu\u00adtion of any source language. 2. Efficiency. Translation of OmniVM must be fast, since \nin many applications of mobile code, translation speed is an important factor. Thus, a translator should \nnot require expensive transfonnations. Such a translation scheme must still yield high performance object \ncode on all target architectures. 3. Ease of code generation. OmniVM must be a simple target for a high-level \nlanguage compiler.  3.1 RISC-based design Portability across source languages is achieved with an ar\u00adchitecture \nthat resembles a typical RISC architecture. The OmniVM instruction set is rich enough to support any \nsource language. OmniVM s load/store instruction set also makes it a simple code generator target. The \nOmniVM architecture is designed to map directly onto a variety of target processors: each OmniVM instruc\u00adtion \nmaps to one or more target machine instructions and each OmniVM register maps to a target machine register \nor memory location in the runtime environment. Since the majority of instructions map to a single target \nmachine in\u00adstruction, most of the generated object code has already been exposed to optimization in the \ncompiler. By delegating the bulk of optimization to the compiler, the translator is left with the task \nof straightforward code generation. Hence, our system achieves efficiency in both the translation time \nand performance of generated target code. The optimization opportunities that remain after transla\u00adtion \nare mainly machine-dependent optimization. The mea\u00adsurements presented in Section 4 show that the bulk \nof speed\u00adup opportunities are obtained by the machine-independent optimization performed by the compiler. \nThese measure\u00adments shows that the design of our virtual machine instruction Number of Average Registers \nOverhead 8 1,11 10 1.11 12 1,08 = 14 1.06   EEEl Table 2: Average execution time of mobile code relative \nto native Spare code generated by cc for various OmniVM register file sizes. set effectively exposes \ntarget machine resources to compiler optimization. Using a RISC-like virtual machine also yields competi\u00adtive \nx86 code. A number of superscalar implementations of the x86 architecture provide a RISC core instruction \nset. For instance, Intel s Pentium [10] and Pentium Pro [20], AMD s K5 [35], and NexGen s Nx686 [21] \nprocessors are superscalar implementations of the x86 architecture, that can concurrently dispatch only \nRISC-like instructions [25]. An Intel application note describing instruction selection and scheduling \nfor the Pentium processor, advises against se\u00adlecting complex instructions and suggests using a load/store \nmodel of instruction selection [24]. 3.2 Register file organization The OmniVM has 16 integer registers \nand 16 floating-point registers. On the RISC targets, the OmniVM registers are mapped directly onto physical \nregisters, while on the x86, some registers are mapped to memory locations. Since the newer implementations \nof the x86 architecture are optimized to efficiently execute instructions with memory operands, this \nstrategy works well (see the performance measurements in Section 4). Table 2 shows that using fewer than \n16 registers penalizes performance on the Spare. On RISC targets, the runtime system reserves some regis\u00adters \nto efficiently implement SF.I [42], to store environment information, and to preserve compatibility with \nthe native application binary interface. On processors such as the Pow\u00aderPC or Spare, we could use as \nmany as 23 OmniVM regis\u00adters. However, Table 2 shows that Spare performance does not improve significantly \nwith the addition of more than 16 registers to the OmniVM. 3.3 Data formats OmniVM defines the size \nof basic data types and supports integer types of byte, halfword, and word (8, 16, and 32 bits) and IEEE \nsingle-and double-precision floating-point types. We anticipate supporting 64 bit integer types and 64 \nbit addressing in future versions. By defining the sizes of primitive data types, OmniVM enables the \ncompiler to define the layout of aggregate data types and generate explicit address arithmetic code. \nThis is important, because many optimization such as common subexpression elimination, code motion, and \nstrength reduc\u00adtion within loops, are effective on address arithmetic code. OmniVM s basic data types \nare endian-neutral; the ad\u00addressing of bytes within halfwords or words, and of halfwords within words \nis not defined. OmniVM provides data manipu\u00adlation instructions to assure portability across machines \nwith different byte orderings; these instructions are mapped to endian-dependent extract and insert instruction \nsequences of the target machine. 3.4 RISC instruction set enhancements OmniVM generalizes sizes of address \noffsets and branch architecture. OmniVM provides memory access instructions with 32 bit immediate offsets. \nThis choice guarantees that when an OmniVM translator encounters a memory access instruction, it has \nall the information necessary to generate good code for that instruction. On aCISC machine such as the \nx86, a single instruction will suffice. On a RISC machine, the translator typically generates one additional \ninstruction for address calculation. Section 4 shows the overhead introduced through using large address \noffsets and how, by using a global pointer [11], we can eliminate the bulk of this overhead. In contrast, \nif OmniVM were to restrict the size of address offsets, the compiler would generate additional address \ncal\u00adculation instructions; further, an optimizing compiler might move these instructions across basic \nblocks. Hence, an x86 translator would be required to perform local or even global instruction combining \nto reconstruct the simplest instruction sequence for a given memory access. OmniVM has general compme-and-branch \ninstructions that branch on the result of a comparison between two reg\u00adisters or between a single register \nand an immediate value. These branch instructions are necessary for production of good code across a \nwide variety of branch models; for ex\u00adample, if compare results were placed in general purpose registers, \nit would be difficult to implement efficient condi\u00adtional branches on architectures that use condition \ncodes.  Evaluation To evaluate the performance of mobile code based on Om\u00adniVM, we used gcc (version \n2.4.5) to generate OmniVM instructions from a set of benchmark programs written in the C programming \nlanguage; we used the OmniVM assembler and linker to generate OmniVM executable files for these programs. \nThe executable generated by the linker are mo\u00adbile code modules that are translated and executed by a \nhost program that incorporates the runtime environment. The Omniware runtime environment includes both \nan OmniVM translator for the given target machine, and a set of library functions, such as memory management, \nthreads, synchro\u00adnization, and graphics that the host program can safely export to dynamically loaded \nOmniware modules. We evaluated OmniVM translators and runtime environ\u00adments on four different platforms: \na Mips R4400 based SGI Indigo-2 machine running Irix 5.2, a PowerPC 601 based IBM RSJ6000 running AIX \nversion 3, a Spare based SPARC-Station 10 running Solaris 2.4, and a 90 MHz Intel Pentium based Precision \nPentium machine running Microsoft Win\u00addows NT version 3.5. Our translators include several optimizations. \nWe have implemented local instruction scheduling in our Mips and PowerPC translators based on the algorithm \ndescribed in [45]. We implement a global pointer in our Spare trans\u00adlator and fill branch delay slots. \nOn the x86, we perform only floating-point pipeline scheduling and peephole opti\u00admization. In addition, \nwe have implemented instrumentation hooks in our translators so that we can gather information on the \ndynamic behavior of our benchmarks, such as instruction mixes. For the measurements in this section, \nno interproce\u00addural optimizations were used. We used four C programs from the SPEC92 suite for our evaluation: \nli, compress, alvinn and eqntott. The reference input files provided in the SPEC92distribution were used \nas input data. We compiled these programs using both the vendor-supplied cc compiler and gcc (version \n2.5.8 on Mips, Spare and x86, version 2.6.3 on the PowerPC). For all compilers, we used the highest available \nlevel of intra\u00adprocedural global optimizations. Our evaluation is organized as follows. In Section 4.1 \nwe compare the performance of mobile code based on Om\u00adniVM with the performance of native code. In Section \n4.2 we measure the performance improvements from performing optimization in the translator. In Section \n4.3 we measure the expansion in number of instructions due to differences between the OmniVM and host \ninstruction sets, and due to software fault isolation. 4.1 Performance of mobile code We compare the \nexecution time of a dynamically loaded OmniVM executable with the execution time of object code generated \nby the native compiler. Tables 3 and 4 show execu\u00adtion times of translated OmniVM (both with and without \nSFI) relative to the execution times of native code generated by the host cc and gcc compilers. In the \ncase of the three RISC architectures, the performance of safe mobile code based on OmniVM is virtually \nindistinguishable from the performance of native code generated by gc c. When compared to native 130 \n Execution time relative to native program Mips Spare PPC x86 SFI no SFI SFI no SFI SFI no SFI SFI no \nSFI Ii 1.10 0!91 1.05 1.02 1.18 1.08 1.11 1.10 compress 1,04 0.96 1.02 1.01 1.23 1.18 1.02 1.02 alvinn \n1.20 1,09 1.07 1.03 1.08 0.97 1.25 1.22 eqntott 1.20 1.18 1.04 0.99 1.35 1.35 1.06 1,04 average 1.14 \n1.03 1.05 1.02 1.21 1.14 1.11 1.10 Table 3: Execution time of mobile code relative to native code generated \nby cc. Execution time relative to native program Mips Spare PPC x86 SFJI no SFI SFI no SFI SFI no SFI \nSPI no SFI li 1.11 0.92 1.05 1,01 1.04 0.94 1.09 1,09 compress 0.78 0.72 1.02 1.01 1.08 1.13 1.01 1.01 \nalvinn 1.12 1.01 1.08 1.02 1.36 1.21 1.09 1.06 eqntott 1.04 1.02 1.03 1.01 0.66 0.66 1.05 1.03 average \n1.01 0.92 1!05 1.02 1.03 0.98 1.06 1.05 Table 4: Execution time of mobile code relative to native code \ngenerated by gee. Execution time relative to native program Mips Spare PPC x86 SFI no SFI SFI no SFI \nSFI no SFI SFI no SFI Ii 1.18 1,06 1.11 1.07 1.35 1.14 1.18 1.15 compress 1.04 0.84 1.18 1.16 1.28 1.23 \n1.09 1.07 alvinn 1.37 1.20 1.21 1.17 1.32 1.04 1.79 1.71 eqntott 1.08 1.06 1.24 1.21 1.35 1.35 1.22 1.16 \naverage 1.17 1.04 1.21 1.15 1.33 1.19 1.32 1.27 Table 5: Execution time of mobile code without translator \noptimizations, relative to native code generated by cc. program Mips Spare PPC x86 to its 1670 performance \ndifference from gcc. li 0.98 1.01 1.14 1.13 Tables 3 and 4 also show the execution time overhead in\u00ad \ntroduced by SFI. On all platforms, there is a performance penalty of approximately 10%. Other reports \nhave investi\u00ad gated the effect of applying compiler optirnizations to soft\u00ad  pq@MB!q ware fault isolation \n[42]. Based on these studies, we expect average 1.14 1.01 I 1.27 I 1.16 Table 6: Execution time of native \ncode generated by gcc relative to native code generated by cc. code generated by the c c compilers, mobile \ncode is 10-2070 slower. There are four factors that contribute to performance dif\u00adferences between mobile \nand native cc generated code: (i) overheads due to software fault isolation, (ii) differences in the \nOmniVM and target instruction sets, (iii) better global optirnizations in the cc compilers, and (iv) \nbetter machine\u00addependent optimizations in the cc compilers (e.g., instruc\u00adtion selection and scheduling). \nBecause of the effects of cache misses and pipeline interlocks, it is difficult to quantify the contribution \nof each of these factors to execution times without simulating the pipeline and memory system of each \narchitecture. In Section 4.3 we quantify the effects of (i) and (ii) in terms of instruction counts and \ndiscuss techniques to alleviate these overheads. In the case of (iii), retargeting the cc compilers to \nOmniVM would result in faster mobile code, since mobile code would also benefit from reductions in path \nlength due to better global optimization. We can measure the combined effects of (iii) and (iv) by comparing \nthe native cc and gcc compilers. Table 6 shows the performance difference between native code compiled \nwith gcc versus native code generated by cc. In general, the quality of code generated by the native \ncc compilers is better than gee. The difference is greatest on the PowerPC (27%). We believe this is \ndue mainly to better code selec\u00adtion and aggressive instruction scheduling performed by the XIC compiler. \nThe PowerPC has a few features that are unusually challenging for code generators, specifically, auto\u00adupdate \naddressing modes, branch-and-decrement instructions and multiple condition registers. Effective use of \nthese fea\u00adtures can result insubstantial speed-ups [22], especially when the compiler performs global \ninstruction scheduling [6]. We are currently enhancing our translators with global in\u00adstruction scheduling \nand a framework for machine-dependent peephole optimizations. We expect these improvements to bring the \nperformance of translated code on the PowerPC in line with that of the other two RISC processors. We \nalso expect that these optimizations will improve performance of translated code on the x86, especially \nfor pipelined im\u00adplementations of the architecture, because Microsoft Visual C++ performs a number of \ncomplex peephole optimizations and instruction scheduling decisions for the Pentium that lead that Omniware \ns software fault isolation overhead will be cut to approximately 570 through these optirnizations. 4.2 \nBenefits from translator optimization Table 5 shows that simple local instruction scheduling can substantially \nimprove native code generated by OmniVM translators. This is encouraging, since mobile code appli\u00adcations \nwill often require fast load times, making the use of global optimizations unattractive. This table shows \nexecution times of mobile code relative to the execution times of native code generated by cc. Comparing \nTable 5 with Table 3 we see that the Mips, PowerPC, and x86 benefit greatly from in\u00adstruction scheduling; \nwe assume that this is because all three architectures offer machine-level parallelism that the instruc\u00adtion \nscheduler can exploit (the R4400 is superpipelined while the PowerPC601 is superscalar). For example, \nthe measure\u00adments for ALVINN on the x86 show the benefits of floating\u00adpoint pipeline scheduling in our \ntranslator for the Pentium processor. More importantly, instruction scheduling improves the per\u00adformance \nof code translated with SFI, more than it improves the performance of code that has been translated without \nSFI. This is because instruction scheduling is able to hide some of the software fault isolation overhead \nwithin pipeline in\u00adterlock cycles. Hence, the overhead of performing software fault isolation is alleviated \nby instruction scheduling. It is also interesting to observe from comparing Tables 5 and 3, that translator \noptirnizations make up for some of the over\u00adhead introduced by SFI. Although we do not perform instruction \nscheduling for the Spare, performance on the Spare is the most competitive with the native cc compiler. \nSpare performance benefits from using a global data pointer (even though it has only a 13 bit offset \nfor immediate) as well as using annulled branches. Since symbols are resolved during translation, our \nsystem does not pay the usual dynamic linking cost of setting and restoring a global pointer on each \nfunction call. We expect better performance from our Mips and PowerPC translators once we implement a \nglobal pointer in these translators; the numbers presented in Section 4.3 support this conclusion.  \n4.3 Instruction expansion The charts in Figure 1 give a detailed view of the expansion introduced during \ntranslation from OmniVM instructions to native instructions, for the Mips and PowerPC architectures. \n ~ 0.7 ~ 0.6  f 0.5 1 bnop g 0.4 ~ 0.3 1 ldi ; 0.2 W cmp s 0.1 z MO H addr li compressalvinn eqntott \nli compressalvinn eqntott Mips PowerPC Figure 1: Expansion introduced by translation. If all OmniVM instructions \ntranslated to a single native in\u00adstruction, then there would be no expansion during transla\u00adtion. However, \nthere are several situations where additional instructions are introduced during translation, and the \ncharts in Figure 1 show the dynamic counts of these additional in\u00adstructions relative to the number of \nOmniVM instructions executed: OmniVM includes addressing modes that translate to more than one instruction \non these architectures. Ex\u00adpansion due to these additional instructions is labeled addr in the charts. \n OmniVM includes powerful conditional branches that sometimes translate to a compare and a branch on \nthese architectures. Expansion due to these additional com\u00adpares is labeled crop in the charts.  OmniVM \nhas 32 bit immediate and thus additional instructions may be necessary to load an address or an immediate \ninto a register when this immediate does not fit into the target architecture s instruction format. Expansion \ndue to these additional instructions is labeled ldi in the charts.  On the Mips, branches have a delay \nslot that must be filled. Expansion due to branch deiay slots containing nops are labeled bnop in the \ncharts.  c Additional instructions are inserted to enforce software fault isolation for unsafe store \ninstructions. Expansion due to these additional instructions is labeled sfl in the charts. These charts \nshow how differences in the target architectures result in different overheads: The PowerPC executes \nsubstantially more compare in\u00adstructions than the Mips. The reason for this is that most conditional \nbranches in these programs involve a comparison against zero, which map to a single in\u00adstruction on the \nMips. The PowerPC must perform an explicit comparison for all conditional branches. Be\u00adlow, we discuss \na few optirnizations that can reduce this overhead on the PowerPC. The Mips has slightly more ldi overhead \nin eqnt ot t and compress. This is because these programs have conditional branches involving comparisons \nagainst a constant. On the PowerPC, these constants fit into the immediate form of the compare instruction. \nThe Mips has only a single compare with immediate instruction; if the branch condition does not match \nthis compare instruction, the immediate must be first loaded into a register.  The PowerPC executes \nfewer SFI instructions. The reason for this is that the PowerPC has an indexed ad\u00addressing mode (i.e., \nregister plus register) that allows the PowerPC SFI check sequence to be shorter than the check sequence \nfor the Mips.  Both architectures execute an equally significant num\u00adber of addressing mode overhead \ninstructions in 1 i and compress. The OmniVM indexed addressing mode maps one-to-one on the PowerPC but \nrequires an addi\u00adtional add instruction on the Mips. Since there is no difference in the addressing mode \nexpansion between these two architectures, indexed mode addressing does not seem to be important for \nthese programs. Both architectures execute many addressing mode overhead instructions that can be eliminated \nwith a global pointer.  Even though the scheduler attempts to fill branch delay slots on the Mips, there \nare still many branch nops that remain.   4.4 Discussion The performance measurements presented in \nthis section demonstrate that Omniware can achieve excellent mobile code performance. Omniware s overhead \nof only 10-20% makes it an order of magnitude faster than any other uni\u00adversal mobile code system, because \nother universal sys\u00adtems must rely on abstract machine interpretation to enforce safety [12, 32]. For \nmany applications of mobile code, such as executable content for Internet documents, our current performance \nis sufficient. However, we plan to add the capa\u00adbility for aggressive optimization to our translators, \ninclud\u00ading global optimizations, link-level (interProcedural) opti\u00admization, and chip-specific transformations \nsuch as global instruction scheduling, instruction combination and the or\u00adganization of code and data \nto fit cache capacity and layout [27]. By adding these capabilities, we hope to make the Omniware system \nsuitable for tasks such as general software distribution. In performing these optimizations, OmniVM translators \nhave two advantages over typical compilers: not only does a translator have complete inter-procedural \ninfor\u00admation (i.e., across module boundaries), it has exact knowl\u00adedge of the target machine. Typically, \ncompilers target an entire architecture family, not a particular processor imple\u00admentation. Several studies \nsuggest that we can significantly improve performance using this information [27, 44, 8]. In addition, \nour results suggest several simple steps to\u00adwards this goal. First, implementing a global pointer can \nsignificantly improve performance. The performance im\u00adprovement resulting from implementing a global \npointer on the Spare confirms this assertion. Second, the PowerPC is paying a significant overhead due \nto extra compare instruc\u00adtions, especially since these compare instructions have multi\u00adcycle latencies \nand must be scheduled. Some comparisons against zero can be eliminated on the PowerPC by folding the \nsetting of the condition codes into a prior arithmetic instruc\u00adtion. Moreover, the PowerPC branch and \ncount instruction can fold an induction variable decrement, test against zero and branch instruction \ninto a single instruction. Finally, SFI forms the foundation of our approach, but incurs an execu\u00adtion \ntime overhead of approximately 10%. The overhead of SFI optimizations can be reduced using standard compiler \ntechniques such as loop invariant code motion, as described in [42]. We have not implemented SFI optimizations \nand expect optimization will cut this overhead in half.  Related projects Several projects have employed \nvirtual machine architectures with low-level instruction sets that resemble the OmniVM instruction set. \nDesigned for portable optimization rather than mobile code, Mahler [45] defines a virtual machine that \nabstracts over the details of several different Titan processor implementations. OmniVM differs from \nMahler in the far wider range of architectures it supports, and the requirement for safe execution. Similarly, \nthe Taos operating system [34] defines as its compiler target the Taos Virtual Processor, which, like \nMahler, is an attempt to support multi-platform optimization. Binary translation systems [1] address \nthe problem of mi\u00adgrating existing native code from one platform to another. A similar approach is the \nidea of fat binaries, where the com\u00adpiler generates an object file containing multiple text sections \n one for each of the target architectures. Neither of these methods address the issue of safety. The \nANDF [29] project is a recent attempt to standardize a universal intermediate language for software distribution \n[14]. ANDF s intermediate representation comprises typed expression trees. This representation is at \na higher level than the OmniVM, and more work is required to translate it to native code. Thus, this \nrepresentation is less suitable for applications where speed of translation is important, and will not \nbenefit as much from compiler optimization as OmniVM does. The OMI project [15] uses a similar approach. \nTelescript [26] and Java [19] are two mobile code systems that achieve portability and safety by compiling \nto a machine\u00adindependent intermediate representation. Telescript enforces safety in its interpreter. \nJava depends on a type system for mobile code safety. Java s intermediate representation is tailored \nfor fast interpretation by a stack machine [18], and, because it defers decisions such as data layout, \nrequires more work than OmniVM to translate into efficient machine code. No performance evaluations have \nbeen released for Java, so it is difficult to evaluate the performance of the Java compiler or interpreter. \nSome mobile code systems rely entirely on interpretation of source code at the host. Many scripting languages \nare in this category, including safe variants of Perl, Tcl [7] and Python [41]. These language-specific \nmobile code systems are useful for certain unstructured tasks such as parsing user input, but they require \nsoftware distribution in source form and their performance is limited. A universal mobile code substrate \nsuch as Omniware provides a host program such as an Internet browser the capability for running any of \nthese systems, without requiring that the host program statically incorporate a wide variety of interpreters. \nTo provide a new interpreted language on the Internet, a programmer can write an interpreter in C or \nC++ and make it available as an Omni\u00adware module. 6 Conclusion This paper described a mobile code system \nand its imple\u00admentations on the Pentium, PowerPC, Mips, and Spare pro\u00adcessors. Including the overhead \nfor enforcing safety, our current system can execute real C programs at execution speeds within 21 %o \nof the unsafe optimized code produced by the vendor-supplied compiler. Our evaluations suggest optimizations \nthat can further improve performance. To our knowledge, Omniware is the fastest system for mobile code \nto date, and the first to efficiently implement safe, mobile c JAVA ML Fortraa Sourceprogram source \nsource surrrce source Mobile object Mobile code   :~:F@:::@@ Loadednative MIPS SPARC POwerPC x86 executable \nobject object object object Figure 2: A universal code in a language-independent way. Hence, as illustrated \nin Figure 2, we consider Omniware to be the first practical, universal substxate for mobile code. References \n[1] K. Andrews and D. Sand. Migrating a CISC computer family onto RISC via object code translation. In \nProceedings of the Sth International Conference on Architectural Support for Programming Languages and \nOperating Systems, pages 213\u00ad222, October 1992. [2] D. Bacon, S. Graham, and O. Sharp. Compiler transforma\u00adtions \nfor high-performance computing. ACM Comput. Surv., 26(4):345-420, December 1994. [3] H. Bal, A. Tanenbaum, \nand M. Kaashoek. ORCA: a language for distributed programming. SIGPLANNotices, 25(5): 17 -24, May 1990. \n[4] J. Bennerjee, W. Kim, H. Kim, and H. Korth. Semantics and implementation of scheme evolution in object-oriented \ndatabases. In Proc. ACM SIGMOD Conference, pages 311\u00ad322, December 1987. [5] T. Bemers-Lee, R. Fielding, \nand H. Nielsen. HTTP/1.0 Inter\u00adnet Draft 04, October 1995. Intemet Draft (work in progress). [6] D. Bernstein \nand M. Rodeh. Global instruction scheduling for superscalar machines. In Proceedings of the SIGPL4N 91 \nConference on Programming Language Design and Im\u00adplementation, pages 241-255, June 1991. [7] N. Borenstein. \nEMail with a mind of its own: The Safe-Tcl language for enabled mail. In IFIP Working Group 6.5 Conference, \nMay 1994. [8] M. Burke and L. Torczon. Interprocedural optimization: elim\u00adinating unnecessaryrecompilation. \nACM Transactions on Pro\u00adgrammingLunguagesand Systems, 15(3):367 399, July 1993. mobile code substrate. \n[9] L, Cardelli, J. Donahue, L. Glassman, M. Jordan, B. Kalsow, and G. Nelson. Modula-3 language definition. \nSIGPLAN Notices, 27(8), August 1992. [10] B. Case. Intel reveals Pentium implementation details. Micro\u00adprocessor \nReport, pages 9-17, March 1993. [11] F. Chow, S. Correll, M. Himelstein, E. Killian, and L. Weber. How \nmany addressing modes are enough? In Proceedings of the 2nd International Conference on Architectural \nSupport for Programming Languages and Operating Systems, pages 117-121, October 1987. [12] K. Chung \nand H. Yuen. A tiny Pascalcompiler. Byte, 39(9):58\u00ad64, September 1978. [13] Compton s Interactive Encyclopedia, \n1995. [14] J. Strong et. al. The problem of programming communica\u00adtion with changing machines. Communications \nof the ACM, 1(8):12-18, August 1958. [15] M. Franz. Code-Generation On-the-Fly: A Key to Portable Software. \nPhD thesis, Swiss Federal Institute of Technology Zurich, 1994. Diss. ETH No. 10497. [16] C. Fraser and \nD. Hanson. A retargetable compiler for ANSI C. SIGPLANNotices, 26(10):2943, Ott 1991. [17] Gee, 1994. \nFree Software Foundation. [18] J. Gosling, Java intermediate bytecodes. In ACM SIGPLAN Workshop on Intermediate \nRepresentations (IR 95), pages 11 1-118, January 1995. [19] J. Gosling and H. McGilton. The Java language \nenvironment A white paper, 1995. [20] L. Gwennap. Intel s MicroprocessorReport, [21] L. Gwennap. Nx686 \ncroprocessorReport, Sun Microsystems, Inc. P6 uses decoupled superscalar design. pages 9-15, February \n1995. goes toe-to-toe with Pentium Pro. Mi\u00adpages 1 10, October 1995. [22] [23] [24] [25] [26] [27] [28] \n[29] [30] [31] [32] [33] [34] [35] [36] [37] [38] [39] C. B. Hall and K. O Brien. Performance characteristics \nof architectural features of the IBM RISC Systern/6000. In Pro\u00adceedings of the 4th International Conference \non Architectural Support for Programming Lunguagesand Operating Systems, pages 303-309, April 1991. R. \nHarper and P. Lee. Advanced languages for systems soft\u00adware: The Fox project in 1994. Technical report, \nSchool of Computer Science, Carnegie Mellon University, January 1994. techreport CMU-CS-FOX-94-01. Intel. \nOptimization forlntel s 32-Bit Processors. Application Note AP-500, Intel Corp., February 1994. K. Johnson, \nRISC-like design fares well for x86 CPUS. Mi\u00adcroprocessorReport, pages 26-27, November 1995. S. Knaster. \nMagic Cap concepts, May 1995. General Magic, Inc. M, Lam, E. Rothberg, and M. Wolf. The cache performance \nand optimizations of blocked algorithms. In Proceedings of the 4th International Conference on Architectural \nSupport for Programming Lunguages and Operating Systems, pages 63\u00ad74, April 1991. S. Lucco, O. Sharp, \nand R. Wahbe. Omniware: A universal substrate for web programming. In Fourth International World Wide \nWeb Conference, December 1995. S. Macrakis. From UNCOL to ANDF Progress in standard intermedia languages, \n1993. Open Software Foundation. B. Noble, M. Price, and M. Satyanarayanan. A programming interface for \napplication-aware adaptation in mobile comput\u00ading. In Proceedings of the Second USENIX Symposium on Mobile \nand Location-Independent Computing, April 1995. Windows NT Workstation 3.51 Product Overview, 1995. Mi\u00adcrosoft \nCorporation. J. Ousterhout. TCL An embeddable command language. In Proceedings of the 1990 Usenix Winter \nConference, pages 22-26, January 1990. D. Patterson. Reduced instruction set computers. Communi\u00adcations \nof the ACM, 28(1):8-21, January 1985. D. Pountain. Parallel course. Byte, 19(7):53-60, July 1994. M. \nSlater. AMD s K5 designed to outrun Pentium. Micropro\u00adcessor Report, pages 1-11, October 1994. B. Steensgaard \nand E. Jul. Object and native code thread mobility among heterogeneous computers. In Proceedings of the \n15th ACM Symposium on Operating Systems Principles, December 1995, M. Stonebraker and G. Kemnitz. The \nPOSTGRES next\u00ad generation database management system. Communications efthe ACM, 34(1 0):78 92, October \n1991. R. Sweet. The Mesa programming environment. In Proceed\u00adings SIGPL4N Symposium on Lunguage Issues \nin Program\u00adming Environments, pages 216-229, July 1985. D. Tarditi, G. Morrisett, P. Cheng, C. Stone, \nR. Harper, and P. Lee, TIL: A type-directed optimizing compiler for ML. In Proceedings of the ACM SIGPLAN \n96 Conference on Programming Languages Design and Implementation. ACM, May 1996. To appear. [40] J. \nUnman, Elements of i14Lprogramming. Prentice Hall, 1994. [41] G. van Rossum. Python tutorial, October \n1995. Online at http://www.python.orgldoc/tut/hrt.html. [42] R. Wahbe, S. Lucco, T, Anderson, and S. \nGraham. Efficent software-based fault isolation. In Proceedings of the 14thACM Symposium on Operating \nSystems PrincsjJes, pages 203-216, June 1993. [43] R. Wahbe, S. Lucco, and S. Graham. Practical data \nbreak\u00adpoints: Design and implementation. In Proceedings of the SIGPLAN 93 Conference on Programming Language \nDesign and Implementation, pages 1-12, June 1993. [44] D. Wall. Global register allocation at link time. \nIn Proceedings of the 7th SIGPL4N Symposium on Compiler Construction, pages 264-275, June 1986. [45] \nD. Wall. Experience with a software-defined machine archi\u00adtecture. ACM Transactions on Progranuning Languages \nand Systems, 14(3), July 1992. [46] G. Williams. Hypercard (personal toolkit). Byte, 12(14):109\u00ad117, \nDecember 1987. \n\t\t\t", "proc_id": "231379", "abstract": "This paper evaluates the design and implementation of Omniware: a safe, efficient, and language-independent system for executing mobile program modules. Previous approaches to implementing mobile code rely on either language semantics or abstract machine interpretation to enforce safety. In the former case, the mobile code system sacrifices universality to gain safety by dictating a particular source language or type system. In the latter case, the mobile code system sacrifices performance to gain safety through abstract machine interpretation.Omniware uses software fault isolation, a technology developed to provide safe extension code for databases and operating systems, to achieve a unique combination of language-independence and excellent performance. Software fault isolation uses only the semantics of the underlying processor to determine whether a mobile code module can corrupt its execution environment. This separation of programming language implementation from program module safety enables our mobile code system to use a radically simplified virtual machine as its basis for portability. We measured the performance of Omniware using a suite of four SPEC92 programs on the Pentium, PowerPC, Mips, and Sparc processor architectures. Including the overhead for enforcing safety on all four processors, OmniVM executed the benchmark programs within 21% as fast as the optimized, unsafe code produced by the vendor-supplied compiler.", "authors": [{"name": "Ali-Reza Adl-Tabatabai", "author_profile_id": "81100032153", "affiliation": "School of Computer Science, Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP14023844", "email_address": "", "orcid_id": ""}, {"name": "Geoff Langdale", "author_profile_id": "81339511306", "affiliation": "School of Computer Science, Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP39028524", "email_address": "", "orcid_id": ""}, {"name": "Steven Lucco", "author_profile_id": "81100431977", "affiliation": "Colusa Software, 1563 Solano Ave. MS-350, Berkeley, CA", "person_id": "PP42051841", "email_address": "", "orcid_id": ""}, {"name": "Robert Wahbe", "author_profile_id": "81100055503", "affiliation": "Colusa Software, 1563 Solano Ave. MS-350, Berkeley, CA", "person_id": "PP31025078", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/231379.231402", "year": "1996", "article_id": "231402", "conference": "PLDI", "title": "Efficient and language-independent mobile programs", "url": "http://dl.acm.org/citation.cfm?id=231402"}