{"article_publication_date": "05-01-1996", "fulltext": "\n VCODE: A Retargetable, Extensible, Very Fast Dynamic Code Generation System Dawson R. Engler engler@lcs.mit \n.edu Laboratory for Computer Science Massachusetts Institute of Technology Cambridge, MA 02139 Abstract \nDynamic code generation is the creation of executable code at runtime. Such on-the-fly code generation \nis a powerful technique, enabling applications to use rrmtime information to improve performance by up \nto an order of magnitude [4, 8,20, 22, 23]. Unfortunately, previous general-purpose dynamic code gen\u00aderation \nsystems have been either inefficient or non-portable. We present VCODE, a retargetable, extensible, very \nfast dy\u00adnamic code generation system. An important feature of VCODE is that it generates machine code \nin-place without the use of intermediate data structures. Eliminating the need to construct and consume \nan intermediate representation at rrmtime makes VCODE both efficient and extensible. VCODE dynamically \ngen\u00aderates code at an approximate cost of six to ten instructions per generated instruction, making it \nover an order of magnitude faster than the most efficient general-purpose code generation system in the \nliterature [10]. Dynamic code generation is relatively well known within the compiler community. However, \ndue in large part to the lack of a publicly available dynamic code generation system, it has remained \na curiosity rather than a widely used technique. A practical contribution of this work is the free, unrestricted \ndistribution of the VCODE system, which currently runs on the MIPS, SPARC, and Alpha architectures. Introduction \n Dynamic code generation is the generation of machine code at runtime. It is typically used to strip \na layer of interpretation by allowing compilation to occur at runtime. One of the most Thisworkwsasupportedin \npartbytheAdvarreedResesrchRejectsAgency underCorrtxactNOOO1 4-94-1-0985.Theviewsandconclusionscontainedin \nthis documentarethoseof theauthorsrmdshouldnotbeinterpretedssrepresenting the official policies, either \nexpressedor implied, of the U.S.gnverrrmerrt. Permission to make digiteb?mrd copy of part or sdl of this \nwork for personal or classroom uae is ranted without fee provided that copies are not made or distributed&#38;r \n~ i t or commercial advanta e the copyright notice, the title of the ublrcabon and its date appeaf, en \n% noboa is given that copying is ! y permission of ACM, Inc. To copy othenvise, to republish, to poet \non eervera, or to redistribute to lists, requires prior spadfic permission arrdbr a fee. PLDi 9S W96 \nPA, USA O 199S ACM @S9791-795-Z@6/0005.. $3.5O well-known applications of dynamic code generation is \nby in\u00adterpreters that compile frequently used code to machine code and then execute it directly [2, 6, \n8, 13]. Hardware simulators and binary emulators can use the same techniques to dynami\u00adcally translate \nsimulated instructions to the instructions of the underlying machine [4, 22, 23]. Runtime partial evaluation \nalso uses dynamic code generation in order to propagate run\u00adtime constants to feed optimization such \nas strength reduction, dead-code elimination, and constant folding [7, 20]. Unfortunately, portability \nand functionality barriers limit the use of dynamic code generation. Because binary instruc\u00adtions are \ngenerated, programs using dynamic code generation must be retargeted for each machine. Generating binary \nin\u00adstructions is non-portable, tedious, error-prone, and frequently the source of latent bugs due to \nboundary conditions (e.g., constants that don t fit in immediate fields) [21]. Many of the amenities \nof symbolic assemblers are not present, such as de\u00adtection of scheduling hazards and linking of jumps \nto target ad\u00addresses. Finally, dynamic code generation requires a working knowledge of chip-specific \noperations that must be performed, the most common being programmer maintenance of cache coherence between \ninstruction and data caches. Once the goals of portability and usability have been sat\u00adisfied, the main \nfocus of any dynamic code generation system must be speed, both in terms of generating code (since code \ngeneration occurs at runtime) and in terms of the generated code. This paper describes the VCODE dynamic \ncode generation system. The goal of VCODE is to provide a portable, widely available, fast dynamic code \ngeneration system. This goal forces two implementation decisions. First, to ensure wide availability \nacross different languages and dialects with modest effort, VCODE cannot require modifications to existing \ncompil\u00aders (or require its own sophisticated compiler). Second, in order to generate code efficiently \nVCODE must generate code in place, I.e., VCODE must dynamically generate code without the luxury (and \nexpense) of representing code in data structures that are built up and consumed at runtime, The main \ncontribution of VCODE is a methodology forpor-tably generating machine code at speeds that formerly required \nsophisticated compiler support or the use of hand-crafted, non-portable code generators. The VCODE machine-independent \ninterface is that of an ide\u00adalized load-store RISC architecture. This low-level interface allows VCODE \nto generate machine code from client specifi\u00adcations at an approximate cost of six to ten instructions \nper generated instruction. This overhead is roughly equivalent to that of a highly tuned, non-portable \ndynamic code generator (or faste~ compare [21]). Furthermore, the low-level instruc\u00ad 160 tion set can \nbe used by clients to write portable VCODE that translates to high-quality code. VCODE is extensible, \nallowing clients to dynamically modify calling conventions and register classifications on a per-generated-function \nbasis; it also pro\u00advides a simple modular mechanism for clients to augment the VCODE instruction set. \nFinally, the VCODE system is simple to retarget, typically requiring one to four days to port to a RISC \narchitecture. VCODE currently runs on MIPS, SPARC, and Alpha processors. As discussed above, VCODE generates \ncode in place. Elim\u00adinating the need to build and then consume an intermediate representation at mntime \nhas powerful effects. Code genera\u00ad tion is more efficient, since intermediate data structures are not \nconstmcted and consumed. Elimination of intermediate struc\u00ad tures also removes the need for VCODE to \nunderstand instmction semantics. As a result, extending the VCODE instruction set is simple, usually \nrequiring the addition of a single line to the VCODE machine specification. VCODE is a general-purpose \ndynamic code generation sys\u00adtem in that it allows clients to portably and directly construct arbitrary \ncode at runtime. It is the fastest such system in the lit\u00aderature (by more than an order of magnitude). \nIt is also the first general-purpose system to generate code without the use of an intermediate representation, \nthe first to support extensibility; and the first to be made publicly available, This paper is structured \nas follows: we discuss related work in Section 2. We provide an overview of the system, retargeting, \nand some details of the client/vCODE interface in Section 3, We measure the performance of three experimental \nclients in Section 4. Section 5 presents some key implementation details and Section 6 reports on our \nexperiences using VCODE. Finally, we conclude in Section 7. 2 Related Work Dynamic code generation has \nalong history. It has been used to increase the performance of operating systems [20], window\u00ading operations \n[18], dynamically typed languages [2, 13, 6], simulators [23] and matrix manipulations [10]. In [14], \nKep\u00adpel, Eggers and Henry survey many advantageous uses for dynamic code generation, ParcPlace sells \nan implementation of Smalltalk-80 that uses a dynamic code generator for SPARC, Motorola 68k, PowerPC, \nIntel x86, and other architectures. Unlike VCODE, their system is designed specifically for the compilation \nof Smalltalk-80, and not as a stand-alone system for dynamic code generation. Engler and Proebsting [10] \ndescribe DCG, ageneral-purpose dynamic code generation system. VCODE grew out of my expe\u00adriences building \nDCG and the subsequent use of DCG in building a compiler for the C kmguage [7]. Compared to DCG, VCODE \nis both substantially simpler and approximately 35 times faster. Both of these benefits come from eschewing \nm intermediate representation during code generatio~ in contrast, DCG builds and consumes IR-trees at \nmntime. VCODE also provides an extensible framework and generates more efficient code than DCG. Engler, \nHsieh, and Kaashoek [7] describe the language C (tick C), a superset of ANSI C that is designed for the \nhigh\u00adlevel, efficient, and machine-independent specification of dy\u00adnamically generated code. Their implementation \nuses the DCG dynamic code generation system that, as we described above, is both substantially less efficient \nand more complex than VCODE. Poletto, Engler, and Kaashoek [19] describe a reimplementa\u00adtion of C that \nuses VCODE as its target machine. As a result, C can automatically generate code for any architecture \nVCODE has been ported to, and gains the advantages of VCODE: fast code generation and efficient generated \ncode. C and VCODE are complemental. The primary advantage of VCODE over C is that VCODE is, in principle, \nlanguage independent; in con\u00adtrast, since it is a language, C requires relatively sophisticated modifications \nto existing compilers. Also, VCODE S low-level nature allows greater control over low-level details (calling \nconventions, register names, etc.). VCODE is a manual code generation system. An alter\u00adnative approach \nis to dynamically generate code automati\u00adcally [5, 15, 16]. While an automatic system can be easier to \nuse, it does require complex compiler support and can be less applicable than a manual system. The reason \nfor reduced applicability is that automatic systems are primarily users of dynamic code generation rather \nthan providers of it. In con\u00adtrast, VCODE clients control code generation and can create ar\u00adbitrary code \nat mntime. For instance, clients can use VCODE to dynamically generate functions (and function calls) \nthat take an arbitrary number and type of arguments, allowing them to construct efficient argument marshaling \nand unmarshaling code [7]. It does not seem possible to efficiently perform such operations with current \nautomatic systems [5, 15, 16]. Leone and Lee [15] describe an interesting automatic dy\u00adnamic code generation \nsystem that performs compile-time spe\u00adcialization of a primitive functional language. Recently, they \nhave extended their compiler, FABIUS, to accept a functional subset of ML [16]. FABIUS generates code \nquickly by using techniques developed by programmers to dynamically generate code by hand : dynamic code \nis emitted by inline expanded macros that create instructions whose operand register names are determined \nat static compile time. In contrast, VCODE pro\u00advides a new technique for portably generating code at \nequiv\u00adalent speeds without the support of a sophisticated compiler. As a result, VCODE can be used, practically \nspeaking, in more arenas than FABIUS (e.g., in the context of a pointer and side\u00adeffect rich language \nsuch as C). Another interesting automatic code generation system is Tempo [5], ageneral-purpose dynamic \nspeciaIizerfor C. Tempo can be easier to use than VCODE, but like other automatic sys\u00adtems, it requires \ncomplex compiler support and can be less applicable. For example, the scope of Tempo s optirnizations \nis limited by the usual challenges C presents to optimizing compilers (e.g., unrestricted aliasing). \nRamsey and Femandez have developed a tool kit for the concise specification of functions to emit and \ndisassemble ma\u00adchine code [21 ]. Like VCODE, their system can be used to dynamically generate code quickly, \nis extensible, and is freely distributed. Unlike VCODE, their system s client interface is not portable \nand, therefore, requires clients be rewritten for each new architecture. 3 System Overview The VCODE \nsystem is a set of C macros and support functions that allow programmers to portably and efficiently \ngenerate code at runtime. The VCODE interface is that of an idealized load-store RISC architecture, VCODE \ninstructions are simple primitives (e.g., add, sub, load) that map readily to modem architectures. This \nmapping is direct enough that most VCODE instructions are translated to their machine code equivalents \nin-place in client code. An important benefit of VCODE S in-place code generation is that it consumes \nlittle space. Other than the memory needed 161 to store emitted instructions, VCODE need only store \npointers to labels and unresolved jumps. At a cost of a few words per label, this is a relatively insignificant \namount of memory. In contrast, a system that uses intermediate data structures requires space proportional \nto the number of instructions. VCODE has been designed with the main aim of reconcil\u00ading the conflicting \ngoals of fast code generation and efficient generated code. VCODE achieves these goals via a low-level \ninterface (i.e., the assembly language of an idealized RISC ar\u00adchitecture). This interface has three \nmain benefits. The first is that it allows clients to perform many of the expensive code generation operations \n(notably, virtual register allocation) at static compile time, leaving VCODE to concentrate on the sim\u00adple \njob of translating its instruction set into machine code, a process that is neither difficult nor expensive. \nThe second benefit is that it allows code to be generated quickly without the need for compiler support. \nThis charac\u00adteristic has three desirable features. First, it makes the VCODE system simple to implement, \nwhich has obvious pragmatic re\u00adsults. Second, and more subtly, the close match between VCODE instructions \nand modern architectures allows VCODE to gener\u00adate code in zero passes : VCODE instructions are translated \ndirectly to the machine instructions that they correspond to. In some sense, code generation has been \nreplaced with transliter\u00adation. Finally, since VCODE does not need compiler support, it is (in principle) \nlanguage independent. The final benefit is that VCODE S low-level interface allows code to be written \nthat is not possible from within a higher-level language such as C. For example, VCODE clients can portably \ngenerate function calls on-the-fly and access instructions that have no natural higher-level idioms such \nas prefetching, branch prediction, and byte swapping. 3.1 Instruction set architecture The VCODE instruction \nset was designed by choosing and de\u00ad riving instructions that closely match those of most existing RISC \narchitectures. This process has also been influenced by a number of compiler intermediate representations, \nthe strongest influence being the intermediate representation language of the kc compiler [12]. The instruction \nset is built from a set of base operations (e.g., sub, mul) that are composed with a set of types (e.g., \ninteger, unsigned). Each instruction takes register or immediate operands and, usually, performs a simple \noperation on them. VCODE supports a full range of types: signed and unsigned bytes, halfwords, words \nand long words and single and double precision floating-point. The base VCODE types, named for their \nmappings to ANSI C types, are listed in Table 1. Some of these types may not be distinct (e.g., I is \nequivalent to i on 32-bit machines). Each VCODE instruction operates on some number of typed operands. \nTo reduce the instruction set, and because most architectures only provide word and long word operations \non registers, most non-memory VCODE operations do not take the smaller data types (i.e., c, UC,s, and \nus) as operands. The VCODE htStIUCtiOn Set COnSiStSOf a Single core layer that must be retargeted for \neach new machine and multiple extension layers that are built on top of this core. The core layer consists \nof instructions not readily synthe\u00ad sized from other instructions, such as add. Table 2 lists the VCODE \ncore. Extension layers provide additional functional\u00ad ity less general than that of the core (e.g., conditional \nmove, floating-point square root). For porting convenience, most of these extensions are expressed in \nterms of the core itself. There\u00adfore, once the core has been retargeted, extensions will work on the \nnew machine as well. However, for efficiency, these default definitions can be overridden and implemented \ninstead in terms of the resources provided by the actual hardware. This duality of implementation allows \nsite-specific extensions and common idioms to be implemented in a portable manner without affecting ease \nof retargeting. 3.2 Client/VCODE interface Client programs specify code using VCODE S machine\u00adindependent \ninstruction set. This instruction set is simple and regular. These properties are important because the \ninstructions must be easily generated by client programs. In essence, every client program is a small \ncompiler front-end. VCODE transliterates the instructions selected by clients to machine code immediately, \nwithout the code generation passes typical of other code generators. VCODE omits any significant global \noptimizations and pipeline scheduling, which would require at least a single pass over some intermediate \nrepresen\u00adtation, slowing VCODE by an order of magnitude. (Clients that desire such optimization can layer \nthem on top of the generic VCODE system.) Global optimizations are the responsibility of the client, \nwhich has access to the low-level VCODE instruc\u00adtion set. VCODE is only responsible for emitting efficient \ncode locally. VCODE includes a mechanism to allow clients to perform register allocation in a machine-independent \nway. The client declares an allocation priority ordering for all register candi\u00addates along with a class \n(the two classes are temporary and persistent across procedure calls ). VCODE allocates registers according \nto that ordering. Once the machine s registers are exhaust&#38;1, the register allocator returns an error \ncode. Clients are then responsible for keeping variables on the stack. In practice, modem RISC architectures \nprovide enough registers that this arrangement is satisfactory. (This scheme works on CISC machines as \nwell, since they typically allow operations to work on both registers and memory locations.) Although \nthe VCODE register allocator has limited scope, it does its job well; it makes unused argument registers \navailable for allocation, is intelligent about leaf procedures, and generates code to allow caller-saved \nregisters to stand in for callee-saved registers and vice-versa. Complete code generation includes instruction \nselection, binary code emission, and jump resolution. For most instruc\u00ad tions, the first and second steps \noccur at the specification site of the VCODE instruction. The only complications are jump in\u00ad structions \nand branches: VCODE marks where these instructions occur in the instruction stream and, when the client \nindicates that code generation is finished, backpatches unresolved jumps. Currently VCODE creates code \none function at a time.1 A sample VCODE specification to dynamically create a function that takes a single \ninteger argument and returns its argument plus one is given in Figure 1. This example illustrates a number \nof boilerplate issues: VCODE macro names are formed by prepending a v-prefix to the base instruction \nand appending the type letter. If the instruction takes an immediate operand, the letter i is appended \nto the end result. For example, the VCODE instruction specifying add integer immediate is named v.addii \n(ADD Integer Immediate). The following actions occur during dynamic code genera\u00ad tion In the future, \nthis interface will be extended so that ctients can create several functions simultaneously, 162 ~ \nI C equivalent v void c signed char Uc unsigned char s signed short us unsigned short i int u unsigned \n~ void * long Ill unsigned long f float d double Table 1: VCODE types Standard b-operations (rd, rsf, \nrs2t) add iululpfd addition sub iululpfd subtraction mul iululpfd mukipfication div iululpfd division \nmod iululp moduhrs and Iulul logical and or iulul logical or xor iulul Iogicaf xor ish iulul left shift \nrsh iulul right sbiti, the sign blt is propagated for signed types Standard wary operations (rd, rs) \ncom iulld bit complement not iulul logical not mov iululpfd copy rs to rd neg iUIUl fd negation set iululpfd \nload constant into r~ rsmust be an immediate cvi2 u UI 1 convefi integer to type CVU2 i d 1 convert unsigned \nto type cvi2 iU d fd convert long to type CVU12 iul p convert unsigned long to type cvp2 Ill convefi \npointer to type cvf2 Id convert float to type cvd2 If convert double to type Memory operations (rd, \nrs, or%eti) Id cucsusiululpfd load St cucsusiululpfd store Return to cafler (rs) ret v iululpfd return \nvahre Jumps (addr) v jump to immediate, register, or label ~al v jump and fink to immediate, register, \nor label Branch instructions (rsf, rs2t, /abe/) blt iululpfd branch if less than ble iululpfd branch \nif less than eqrrd bgt Iuluipfd brsnch if greater thsn bge iululpfd branch if greater tharsequal beq \niululpfd branch if eqsraf bne iululpfd branch if not equal Nuflary operation nop no operation II 1 \ntllris operand maybe an immediate provided its type is not ford. Table 2 Core VCODE instructions, 163 \n typedef int (*iptr)(int); /* Called at runtime to create a function which returns its argument + 7. \n*/ iptr mkplusl (struct v.code *ip) { v-reg arg[l 1; A Begin code generation. The type string ( %i \n) indicates that this routine takes a single integer (i) argument; the re ister to hold this argument \nis returned in ar [0]. V.LEAF indicates that this function is a lea ?procedure. ip is a pointer to storage \nto hol f the generated code. */ v_lambda( %i , arg, V-LEAF, ip); A Add the argument register to 1. +/ \nv_addii(arg[Ol, arg[Ol, 1); A ADD Integer Immediate */ A Return the result. *I v-reti(arg[Ol); A RETurn \nInteger*/ 1+ End code generation. v-end links the generated code and performs cleanup. It then returns \na pointer to the final code. */ return (iptr)v-endo; ) Figure 1: VCODE specification for function corresponding \nto int plusl (int x) { return x + 1; } 1. Clients begin dynamic code generation of a new func\u00adtion with \na call to v_lambda, which takes a type string listing the function s incoming parameter types, a vec\u00adtor \nof registers to put these parameters in, a boolean flag indicating whether the function is a leaf procedure, \nand finally a pointer to memory where the code will be stored. The number and type of parameters a dynamic\u00adally \ngenerated function takes do not have to be fixed at static compile time but, rather, can be determined \nat runtime. .-i L. In v-lambda VCODE uses the parameter type string and the machine s calling conventions \nto compute where the function s incoming parameters are: if the arguments m-e on the stack VCODE will, \nby default, copy them to a register. At this point, VCODE also reserves space for prologue code. Control \nis then returned to the client to begin code generation. 3. The client uses VCODE macros to dynamically \ngenerate code. During code generation the client can allocate a number of VCODE objects: registers (using \nv-getreg and v-putreg), local variables (using vdocal), and labels (us\u00ading v-genlabel). After all code \nhas been generated, the client calls v_end to return control back to VCODE. 4, VCODE then backpatches \nprologue and epilogue code, links the client code, and, if necessary, ensures instruc\u00adtion and data cache \ncoherency. VCODE then returns a pointer to the generated code to the application. This pointer must be \ncast to the appropriate function pointer type before being used. 5. The client can then run the dynamically \ngenerated code. The VCODE backend performs rudimentary delay slot schedul\u00ading and strives to keep parameters \nin their incoming registers. The result is reasonably efficient code, as can be seen in the MIPS code \ngenerated by VCODE for PIUSI: # add 1 to argument (passed in aO) addiu aO, aO, 1 # jump to the return \naddress j ra # delay slot: move result to the return register VO move vO, aO For improved efficiency, \nVCODE provides mechanisms that clients can use to target specific registers (such as the register used \nto return results). For simplicity we do not present them here.  3.3 Retargeting VCODE Retargeting VCODE \ninvolves (1) constructing macros to gener\u00adate executable code for each machine instruction to be used, \n(2) mapping the core VCODE instruction set onto these macros, and (3) implementing the machine s default \ncalling conven\u00adtions and activation record management. Generating the code to emit binary instructions \ncan be done using either VCODE S preprocessor or programs such as the New Jersey Toolkit [21]. Since \nthe VCODE core is small and simple, mapping its instruc\u00adtions to their corresponding binary emitters \nis straightforward. To aid this process, we have developed a concise preprocessor specification language \nin the spirit of Fraser [11] that handles much of the details of this mapping. Complete mapping spec\u00adifications \nfor the MIPS, SPARC, and Alpha architectures take approximately 40-100 lines each. Finally, the construction \nof calling conventions and activation record management can typ\u00adically be based on existing code. For \ninstance, the Alpha port of VCODE is largely based on the MIPS port. To aid in the retarget\u00ading process \nVCODE includes a script to automatically generate regression tests for errors in instruction mappings \nand calling conventions. As a result of VCODE S simplicity and porting assistance, a RISC retarget typically \ntakes one to four days. The VCODE instruction set is heavily RISC based. This model can conflict with \nthe underlying hardware if its archi\u00adtecture is very different. Surprisingly, there is no real conflict \nbetween VCODE S interface and that of the most widely used CISC on the market, the x86. The main conflict \nthat could arise from mapping VCODE instructions to the x86 integer instruc\u00adtion set is the x86 s lack \nof registers. However, the x86 can use memory operands in instructions instead of registers, with little \nto no loss of performance. Such an ability can be used to, in effect, support an unlimited virtual register \nset, 164 The most serious conflict with the VCODE architecture arises on stack-based architectures. \nGenerating code on a stack architecture using VCODE seems to require a post-construction pass over the \ngenerated code to couch VCODE register names in terms of stack positions. Fortunately, stack architectures \nare relatively rare. 4 Experimental Clients We discuss three experimental clients, The first client is \na com\u00adpiler for the C language that demonstrates VCODE S viability as a code generation substrate [ 19]. \nThe last two are network sub\u00adsystems within the Aegis exokemel operating system [8]. They demonstrate \nVCODE S suitability for use in an operating system context, and general effectiveness as a real-world \ncode gen\u00aderation tool. (Note that since our operating system only runs on MIPS machines, these two experiments \nwere done on the MIPS platform only.) 4.1 tee: a C compiler VCODE S low-level interface makes it a good \ncompiler target language: compilers can rely on it to emit code efficiently while retaining sufficient \ncontrol to perform many optirniza\u00adtions. Furthermore, since VCODE is portable, a compiler that compiles \nto it has the benefit of its generated code working on the machines that VCODE supports. We have implemented \na C compiler, tee, that uses VCODE as an abstract machine to generate code dynamically [19]. As discussed \nin Section 2, C is a superset of ANSI C that provides language constructs programmers can use to generate \ncode at runtime. For example, programmers use C to specify expres\u00adsions and statements that will be generated \nat nmtime; these code fragments can be dynamically composed and compiled at runtime. tcc is based on \nthe Icc ANSI C compiler. We modi\u00adfied Icc to use two code generation backends. The first backend is used \nto emit assembly for traditional staticrdly generated code. The second backend is used to compile C constructs \nto VCODE. The emitted VCODE is then executed at runtime to gen\u00aderate the code specified by the application \nprogrammer. The use of VCODE as a target machine has allowed us to build a C compiler that runs on a \nvariety of machines with modest effort. Our experience using VCODE as a target machine has been positive. \nCompiling to VCODE has been easier than compiling to more traditional RISC architectures. This ease is \ndue both to the regularity of the VCODE instruction set and to the fact that VCODE handles calling conventions. \nThe use of VCODE has allowed us to isolate most machine dependencies from the tcc compiler itself, For \ninstance, tcc uses the same VCODE generation backend on the two architectures it supports (MIPS and SPARC). \n 4.2 DPF There have beerr many interpreters that dynamically compile frequently used code at runtime \n[2, 4,6,13,22, 23]. In a similar vein, we used VCODE as a dynamic compiler for a packet-filter message \ndemultiplexer [8, 9]. Message demultiplexing is the process of determining which application an in~oming \nmessage should be delivered to. Packet filters are a well-known technique used to implement exten\u00adsible \nkernel demultiplexing [17]. A packet filter is a piece of user-level code downloaded into the kernel \nthat is used to Table 3: Average time on a DEC5000/200 to classify TCP/IP headers destined for one often \nTCP/IP filters; times are in mi\u00adcroseconds. DPF uses VCODE to dynamically compile packet\u00adfilters, while \nPATHFINDER and MPF are both interpreter\u00adbased. claim packets belonging to a given application. Packet \nfilters are predicates written in a small safe language. This approach allows new protocols to be implemented \noutside of the ker\u00adnel (and then downloaded into the packet filter driver), greatly increasing flexibility. \nTraditionally, packet filters are interpreted, which entails a high computational cost. As a result, \nmost high-performance networking systems do not use them, despite the flexibility and extensibility they \nprovide. To remedy this situation, we have implemented Dynamic Packet Filters (DPF), a new packet filter \nsystem that is over an order of magnitude more efficient than previous systems [8, 9]. The key to our \napproach is dynamic code generation. DPF exploits dynamic code generation in two ways: (1) by using it \nto eliminate interpretation overhead by compiling packet filters to executable code when they are installed \ninto the kernel and (2) by using filter constants to aggressively optimize this executable code. As a \nresult, DPF is equivalent in performance to hand-crafted message classifying routines (when it can exploit \nruntime information, it is even faster) while still retaining the flexibility of the packet filter model. \nAn example of how DPF exploits runtime information is how it optimizes the common situation where concurrently \nac\u00adtive filters examine the same part of a message and compare against different values. For instance, \nall TCP/IP packet fil\u00adters will look in messages at identical fixed offsets for port numbers. In static \nsystems these values are not known at com\u00adpile time, and so a general-purpose, possibly expensive hash \ntimction must be used, along with checks for collisions, etc. However, since DPF knows both the number \nand the actual val\u00adues that must be compared, it can optimize the comparison in a manner similar to how \noptimizing compilers treat C switch statements: a small range of values is searched directly, sparse \nvalues are matched using binary search, and dense ranges are matched using an indirect jump. Additionally, \nsince the num\u00adber and value of keys are known at runtime, DPF can select among several hash functions \nto obtain the best distribution, and then encode the chosen function directly in the instruction stream. \nFurthermore, since DPF knows at code-generation time whether keys have collided, it can eliminate collision \nchecks if no collisions have occurred. We measure DPF s time to classify packets destined for one of \nten TCP/IP filters, and compare its time to measurements for PATHFINDER [1], the fastest packet filter \nengine in the literature, and MPF [24], a widely used packet filter engine. To ensure that the comparison \nis meaningful, we perform the same experiment described in [1]: the average of 100,000 trirds is taken \nas the base cost of message classification. Table 3 presents the time to perform this message classification. \nThis experiment is more fully described in [8]. In this experiment, DPF is 20 times faster than MPF and \n10 times faster than PATHFINDER, The bulk of this performance improvement is 165 due to the use of dynamic \ncode generation, 5.1 The life of one instruction 4.3 ASHS ASHS are user message handlers that are safely \ndownloaded into the operating system kernel in order to direct message pro\u00adcessing [8]. VCODE has been \nused as part of the ASH system to provide support for dynamic andefficient modular composition of network \nprotocols. Modular composition of different network protocols has long been a goal in the networking \ncommunity [3]. Unfor\u00adtunately, modular composition is expensive. The problem it presents is that each \nprotocol layer frequently has data-touching operations associated with it (e.g., to perform checksumming \nor byte swapping). Each operation typically touches all (or most) bytes in a message. Separating these \noperations into modular pieces has meant that data is manipulated multiple times. As a result, modularity \nhas exacted a high performance penalty [3], both because many excess scalar operations are performed \n(e.g., looping overhead) and because touching memory multi\u00adple times stresses the weak link in modern \nworkstations, the memory subsystem. To solve this problem we have constructed a network sub\u00adsystem that \nuses VCODE to integrate protocol data operations into .a single optimized pass over memory (e.g., integrating \nchecksumming and byte swapping into a memory copy opera\u00adtion). We gain efficiency from VCODE in two ways. \nFirst, it allows access to machine instructions that have no natural high-level idiom. By writing each \ndata processing step in terms of VCODE it is possible for clients to write code that is more efficient \nthan if it were written in a high-level language. Second, it is used to compose multiple data processing \nsteps dynamically into a single specialized data copying loop generated at runtime. This system is described \nand measured in [9]. Table 4 shows the performance benefit of integrating check\u00adsumming and byte swapping \nroutines into the copying loop from a network buffer to an application s memory. Measure\u00adments are taken \nboth when the data is in the cache and when it has been flushed. Even without an intervening cache flush, \nthe integration provides a performance benefit of 20-50%, and is clearly worthwhile. In the case where \nthere is a flush, the integration almost always provides a factor of two performance improvement. The \ntable also shows the relative efficiency of our emitted copying routines (labeled ASH ) by comparing \nthem to hand-integrated, non-modular loops written in C. The main reason for ASH s better performance \nrelative to the C routines is that the ASH system dynamically generates a mem\u00adory copying loop specialized \nto the operations performed by each layer. The use of VCODE allows flexibility not previously possible \n(i.e., the dynumic composition of data manipulation routines) while simultaneously making ASHS as efficient \nas previous systems that provided neither modular nor dynamic composi\u00adtion (i.e., systems where data \nmanipulation steps were merged by hand). Due to the use of dynamic code generation, the ASH system is \na rare case where flexibility has been provided <for free. 5 VCODE Generator Design VCODE S code generator \nemits machine code in place. This section provides details of this approach and discusses a few of its \nconsequences, VCODE can generate machine code in place because(1) clients associate each VCODE instruction \nwith virtual registers at static compilation time and (2) VCODE S instructions closely match those of \nmodem architectures. To make (2) concrete, we ex\u00adplain what happens to a single VCODE instruction, v.addu. \nIts macro definition and expansion is given in Figure 2, along with the machine code required to dynamically \ngenerate it. In this case, the total cost is nine MIPS instructions. With a contigu\u00adous run of VCODE \ninstructions, some of the operations used to generate code can be reused by the compiler compiling the \nVCODE macros, bringing the total cost even lower. 5.2 Challenges of in-place code generation Generating \ncode in place is challenging, since it requires that VCODE emit code without global knowledge about the \nfunction it is creating. For instance, VCODE does not know if the func\u00adtion it is generating is a leaf \nprocedure, the number of local variables it allocates, the amount of memory (and the number of instructions!) \nit needs to save floating point and temporary registers, etc. Traditionally, such knowledge would be \nderived by making at least one pass over intermediate data structures. Unfortunately, similar methods \nwould have added unaccept\u00adable overhead to VCODE. We briefly look at four of the main challenges to in-place \ncode generation below. Instructions that access a procedure s stack typically re\u00adquire information about \nthe size of its activation record. For instance, on many machines, instructions that save and restore \nregisters must know the activation record size in order to com\u00adpute offsets into the register save area. \nSimilarly, accesses to local variables must know the size in order to compute a given local s stack offset. \nWithout the activation record size, these instructions cannot be emitted. Unfortunately, this size is \nnot known until all code is constructed. Therefore, in order to generate code in place, VCODE must finesse \nthe need to accu\u00adrately know the activation record size. An awkward solution to this problem would be \nto force clients to rdlocate all locals and registers before any code generation occurs. In practice, \nthk restriction would limit client flexibility. Furthermore, in many cases, this restriction would hurt \nperformance since it would require that clients generate VCODE in two passes: the first pass to compute \nthe number of local variables and registers they need, the second pass to actually dynamically generate \ncode using VCODE. VCODE S solution is inelegant but workable it simply allocates the space needed to \nsave all machine registers and then locates space for locals above this fixed-sized area (or below, depending \non how the stack grows). With this solution, register offsets are known at code emission time, and offsets \nfor locrd variables can be computed as the variables are allo\u00adcated. VCODE also marks where in the generated \ninstruction stream the activation record is allocated and then backpatches this instruction when the \nfinal activation record size is known (i.e., after all locals have been allocated). VCODE S solution \nis a tradeoff of space for time. On modem RISC machines it wastes, in the worst case, the stack space \nrequired to save 32 integer and floating point registers (about 64 words). For clients that find this \ntradeoff unacceptable it would not be hard to turn it off on a per-function basis. We have not yet found \nthe need to do SO. The second challenge deals with handling the saving and restoring of callee-saved \nregisters in a function s prologue, The problem VCODE must solve is that when a client begins gen\u00aderating \ncode for a function, VCODE does not know the number 166 Machine Method copy + checksum copy + checksum+ \nbyte swap DEC31OO separateI uncached 1630 3190 separate 1290 2230 C integrated 1120 1750 ASH 1060 1600 \nDEC5000 separateI uncached 812 1640 separate 656 1280 C integrated 597 976 ASH 455 836 Table 4 Cost \nof integrated and non-integrated memory operations. Times are in microseconds. /* vcode instruction to \nadd two unsigned integer registers on the MIPS architecture. */ #define v.addu(rd,rsl ,rs2) addu(rdr \nrsl, rs2) /* Macro to generate the MIPS addu instruction (opcode is OX21). */ #define addu(dst, srcl, \nsrc2) (*v.ip++ = (((srcl ) cc 21 ) I ((src2) cc 16) I ((dst) cc 11 ) I 0x21)) # MIPS assembly code generated \nby gcc -02 to implement the Jaddu macro. Iw VI,1244(gp) # allocate instruction Sll al ,al ,21 # shift \nand then or in the register values Sll a2,a2,16 or al ,al ,a2 Sll aO,aO,l 1 or al ,al ,aO addiu vO,VI,4 \n# bump instruction pointer Sw Vorl 244(gp) # store the new instruction pointer Ori al ,al ,0x21 #or in \nthe opcode Sw al ,O(vl ) # store instruction in memory Figure 2 Top-down expansion of the VCODE v.addu \ninstruction, of callee-registers that the client will use and so cannot gen\u00aderate the function s prologue \ncode. As with activation record size, VCODE only knows how many cake-saved registers a client used after \nall client code generation for the function is complete. VCODE solves the problem by reserving space \nin the instruction stream to save the maximum number of callee\u00adsaved registers an architecture supports. \nThis reservation is done when code generation for a function is initiated (i.e., during the call to v-lambda). \nRegister saves are then inserted into this prologue area after the client is finished generating code. \nIn practice, the amount of space wasted is small (e.g., 32-64 words of memory per generated function). \nThe dual of this problem is that during code generation the epilogue code VCODE needs to generate is \nalso not known. VCODE uses the traditional compiler method of jumping to a piece of per\u00adfunction epilogue \ncode when a client indicates control should return from the function. While back-patching jumps, VCODE \ndoes some simple optimizations to eliminate this jump if the procedure did not use any callee-saved registers. \nOn many architectures, leaf procedures can be profitably optimized. For instance, activation record allocation \ncan be elided and caller-saved registers can be used to hold persistent variables. Unfortunately, VCODE \ncannot determine if a pro\u00adcedure is a leaf procedure until all code is generated. More importantly there \nis, in general, no easy way to assume a pro\u00adcedure is a leaf for optimization purposes and then rollback \nany code transformations: the effects of leaf optimizations can be pervasive and, as a result, make code \nbackpatching expen\u00adsive or difficult to implement. To address this problem VCODE allows programmers to \nindicate if a function is a leaf proce\u00addure. If the client attempts to call a procedure from the func\u00adtion, \nVCODE signals an error. However, this is not a complete solution: VCODE instructions may cause function \ncalls, For instance, on machines that do not provide division in hard\u00adware, the VCODE integer division \ninstructions require subrou\u00adtine calls. To preserve portability, these calls should not cause the user-program \nto get a runtime error from VCODE. In the worst case VCODE ignores client hints when running on those \nmachines. Fortunately, routines that emulate common machine instructions frequently obey different calling \nconventions than normal subroutines in that they save all caller-saved registers. In this case VCODE \nis able to call the emulated routine after saving the registers used to pass its arguments. A final problem \nnot necessruily unique to in-place code generation is the handling of floating point immediate, Un\u00adlike \ninteger immediate, many architectures do not provide support for encoding floating point immediate in \narithmetic instructions. As a result, a dynamic code generation system must allocate space for them and \nload them from this space. To make garbage collection of floating-point constants easy, VCODE places \nthem at the end of a function s instruction stream. In this way, the space for the immediate is easily \nreclaimed when the function is deallocated. 5.3 Violating VCODE abstractions An often-ignored aspect \nof fast systems is the question of how to allow high-level interfaces to be gracefully violated for im\u00adproved \nperformance or control. Since we use VCODE in situa\u00adtions where every cycle is precious and where the \nenvironment has peculim constraints (e.g., operating system interrupt han\u00addlers), we have designed mechanisms \ninto VCODE to allow 167 clients to violate VCODE abstractions in order to achieve both more efficient \ncode generation and more efficient generated code. We briefly outline three of these mechanisms below. \nClients can dynamically control the register class VCODE assigns to each physical register (cake-saved, \ncaller-saved, or unavailable). This allows clients to use VCODE S generated code in situations where \nnormal register conventions do not hold. For instance, in an interrupt handler all registers are live, \nTherefore, for correctness, VCODE must treat all registers as callee-saved. Clients that wish to trade \nregister allocation flexibility can obtain faster code generation spetds by using hard-coded regis\u00adter \nnames. This reduces the cost of code generation by approx\u00adimately a factor of two. To support this optimization, \nVCODE provides architecture-independent names for temporwy ( TO , TI , etc.) and callee-saved registers \n(e.g., SO , S1 , etc.). Clients (in this case, typically compilers) use these names in their VCODE instructions. \nSince these names are constants, the C compiler can perform constant folding and reduce the over\u00adhead \nof dynamic code generation to the loading of a 32-bit immediate into a register and the storing of this \nregister into memory (approximately five instructions). We note that while this mechanism was originally \nintended to make code genera\u00adtion faster, it also supports a form of register assertion : clients that \nuse it will get compilation errors if the machine they are being compiled for does not support the number \nof temporary and variable registers that they require. Such errors could be used to select different \ncode to compile (e.g., code that either uses virtual registers or fewer physical registers). Finally, \nclients that are willing to deal with a lower-level and more dangerous interface are able to perform \ninstruction scheduling of loads and branch delay slots without impact\u00ading code generation speed. The \nbasic problem with portably exposing delay slots within the VCODE instruction set is that reconciling \nthem with the underlying machine can be expen\u00adsive. In general, it requires some form of per-instruction \ncheck. For instance, if VCODE jump delay slots were one instruction and the underlying machine did not \nhave delay sIots, then ev\u00adery instruction would have to check if it was in a logical delay slot and, \nif so, swap places with the already generated jump instruction. Performing this switch would not be trivial, \nsince a jump instruction could have expanded to be several in\u00adstructions. Fortunately, the solution is \nsimple. VCODE includes two macros: v.schedule-delay and v-rawJoad that are used by clients to schedule \ninstructions across branches and loads re\u00adspectively. The first macro takes a VCODE branch instruction \ndefinition (e.g., v-bneii(rs, 10, label)) and an instruction to put in its delay slot. If the machine \nhas delay slots and the instruc\u00adtion fits in the delay slot, VCODE inserts the instruction in the delay \nslot. Otherwise this instruction is simply placed before the branch in the instruction stream. The v-raw-load \nmacro is even simple~ it takes a memory instruction as an operand along with a count of the number of \nVCODE instructions that will be emitted before the result is to be used, If this number is less than \nthe number of cycles required to safely make the result of the load available, VCODE will insert the \nrequired number of nops. With these macros, clients are able to portably and effi\u00adciently schedule load \nand branch delay slots without affecting code generation speed.  5.4 Extensibility The VCODE system \nis simple and modular. These character\u00adistics make it easy to dynamically reconfigure and extend. For \ninstance, we have built a sophisticated strength reducer for multiplication and division by integer constsmts \non top of VCODE; support for unlimited virtual registers could be added in a similar manner. Clients \ncan dynamically substitute calling conventions on a per-generated-function basis. An example of VCODE \ns extensibility is the ease with which its instruction set can be extended. As discussed in Section 3, \nthe elimination of intermediate structures contributes the most to this feature as it removes the need \nfor VCODE to understand instruction semantics. With intermediate data structures, ex\u00adtension is more \ncomplex, since any extension must be couched within the context of a well-formed data structure. VCODE \nprovides a preprocessor that consumes a concise instruction specification and automatically generates \nthe spec\u00adified set of VCODE instruction definitions. A simplified form of this specification is: ( base-insnmame \n( paramlist ) ,), [ ( type-list mach_insn [ math-imm_insn ] ) ]+ Each base-insnmame is composed with \neach type-list and mapped to the associated register-only machine instruction (math-insn) and, if it \nis given, the associated immediate in\u00adstruction (math-imm-insn). Machine instructions are usually provided \nby VCODE itself. However, on machines with large instruction sets, VCODE may negh?ct to specify all instmctions \nand the client must then provide any missing instructions that it needs. For instance, the following \nclient specification adds a square\u00adroot instruction on the MIPS: (sqrt (rd, rs) (f fsqrts) (d fsqrtd)) \nThis specification composes the base instruction type sqrt with the two types f (float) and d (double) \nand associates them with the target MIPS instructions fsqrts and fsqrtd, respectively. It generates the \nfollowing VCODE instruction definitions: #define v~qrtf(rd,rs) fsqrts(rd,rs) #define v~qrtd(rd,rs) fsqrtd(rd,rs) \n To simplify instruction extension, our specification lan\u00adguage includes facilities for constructing \nmore complicated sequences of instructions, acquiring access to scratch regis\u00adters, and couching new \ninstructions in terms of existing VCODE instructions. Thus, a single line in a preprocessing specification \ncan add a new family of instructions. By additionally couching an extension in terms of the VCODE core \n(or other extensions), a client can ensure that its extensions will be present on all machines, 6 Discussion \nA reasonable question to ask is how fast a dynamic code gen\u00aderation system must be before it is fast \nenough. The main determinant of this question what actions a client must take during code generation: \ndynamically generated code is gen\u00aderally not created ex nihilo but rather is based on client data structures. \nTraversing these data structures to determine what 168 code to emit can consume tens or even thousands \nof instruc\u00adtions (e.g., in the case of compilation from a high-level source). As a result, VCODE S performance \nis likely to be more than sufficient for most applications. Furthermore, as we show in Section 5 clients \ncan use hard-coded register names and reduce this overhead by about a factor of two. This section reports \non our experience using VCODE and some limitations of the current system. 6.1 Experience VCODE has been \nin daily use in real systems for over a year. It has proved to be a useful tool and has performed well \nin de\u00admanding situations. For instance, the DPF system we described earlier in the paper is used as the \npacket filter system for the Aegis exokernel operating system [8]. A nice practical feature of VCODE \nis that its complexity is mostly horizontal rather than vertical: each additional piece of the VCODE \nsystem usually does not depend on others. As a result, each extension increases the number of system \nstates roughly additively rather than mukiplicatively. This feature makes testing more simple than the \nDCG system that vcorxl descends from. The most common error we have found is the mis-mapping of VCODE \ninstructions to machine instructions. Compared to the complexities of finding code generation bugs in \nfull-fledged compilers, this is a fairly benign error, easily caught with automatically generated regression \ntests. One disappointment in the implementation of VCODE is the inadequacies it exposed in current compiler \nand linker im\u00adplementations. There were three main problems the VCODE implementation continually ran \ninto: linkers which brought in all routines from a file rather than those needed, compilation of inlined \nroutines that were not referenced, and inefficient han\u00addling of word-sized structures. A VCODE machine \nspecification generates many procedures (one for each VCODE instmction). Most of these procedures will \nnot be used by a given applica\u00adtion. Unfortunately, if these procedures are stored in a single file, \nall Unix linkers we used linked in the entire file rather than simply pulling in the VCODE procedures \nthat were needed. This space overhead was unacceptable, especially when the solution was not difficult \nto implement. The second problem was less easy to solve, but just as detrimental. For high performance, \nit is appropriate to inline most VCODE instruction invocations. Unfortunately, those few compilers that \nprovide an inline di\u00adrective will parse all inline functions, even if they are static and not referenced \nby any procedure in scope. Since VCODE creates a procedure per VCODE instruction this problem leads to \nlong compilation times. VCODE S solution to this problem and the previous one was to use macros to implement \nVCODE instructions: macros do not take up space when they are not referenced, and they are fast to parse. \nUnfortunately, this is far from a perfect solution, since it can cause a space explosion if many VCODE \ninstructions are used, The final problem was how badly many compilers handled word-sized structures: \nrather than allocating the structure to a register and operating on it directly, most compilers we used \nwould load and store the struc\u00adture to memory on every operation. This was true even when the structure \ncontained a single unsigned integer. Since VCODE registers are represented asC structures (to allow stronger \ntype checking than would be possible with a unwrapped integer), this overhead could add a noticeable \ncost to every VCODE in\u00adstruction. We solved this problem by allowing VCODE to be optionally compiled \nto represent registers using integers. 6.2 VCODE limitations While VCODE has been useful in practice, \nit has four main drawbacks: the lack of a symbolic debugger, limited registers, no peephole optimizer \nand no instruction scheduler. Of the four, the first is the most critical: debugging dynamically gen\u00aderated \ncode currently requires stepping through it at the level of host-specific machine code. If one does not \nhave a working knowledge of this instruction set, making sense of the debug\u00adging output is challenging. \nFortunately, fixing this problem is not difficult. With modifications, the preprocessor could auto\u00admatically \ngenerate a debugger from the machine specification files. Each instruction would be interpreted by generating \nit using VCODE and recording its effects. A nice consequence of this arrangement is that client-added \ninstructions can be incorporated into the debugger automatically. We are currently adding support for \nunlimited virtual reg\u00adisters as a VCODE extension layer. preliminary resuks indicate that the addition \nof this (optional) support would increase code generation cost by roughly a factor of two. However, we \nnote that in the systems we have built so far the current VCODE ar\u00adrangement of client-managed registers \nhas not presented prob\u00adlems. On machines where VCODE instructions map more or less directly to native \ninstructions (e.g., tbe MIPS architecture), the lack of a peephole optimizer has not noticeably hurt \nthe qual\u00adity of VCODE S generated code. However, on machines where a single VCODE instruction can map \nto multiple machine instruc\u00adtions, a peephole optimizer would be useful. For instance, the current generation \nof Alpha chips lack byte dnd short word op\u00aderations. As a result, VCODE must synthesize its load and \nstore byte instructions from multiple Alpha instructions. This emu\u00adlation can require a large number \nof instructions: in the worst case an unsigned store byte instruction requires eleven Al\u00adpha instructions \nand five temporary registers ! These emulated instructions typically compute useful intermediate results \nthat a peepbole optimizer could reuse. Unfortunately, the current implementation of VCODE cannot similarly \nexploit these regu\u00adlarities since it has an extremely local view of code generation (i.e., a single VCODE \ninstruction). Future work will include im\u00adplementing a vcoDE-level peephole optimizer for clients that \nwish to trade runtime compilation overhead for better gener\u00adated code. Of all drawbacks, the lack of \nan instruction scheduler is the least critical. Most instruction scheduling can actually be handled above \nVCODE by separating register uses from def\u00adinitions. Clients that wish to micro-schedule delay slots \ncan do so using VCODE S portable instruction scheduling interface. Furthermore, current architectural \ntrends are to deep instruc\u00adtion reorder buffers (e.g., 64-entries deep). At this level, static instruction \nscheduling is not particularly important. 2 7 Conclusion We have presented VCODE, a fast, retargetable \nand extensible dynamic code generation system. It generates machine code at an approximate cost of ten \ninstructions per generated instruc\u00adtion, which is roughly 35 times faster than the fastest equivalent \nsystem in the literature [10]. It can be retargeted to RISC ma\u00adchines in approximately one to four days. \nFinally, it allows many levels of the system to be parametrized at runtime. VCODE provides a portable, \nidealized RISC instruction set to clients. Clients use this interface to specify dynamically This insight \nis due tn ToddPmebsting. 169 generated code from witiln applications. VCODE generates ma-[9] chine \ncode in place, without the intermediate passes typical of other code generation systems. As a result, \nVCODE is substan\u00adtially faster than previous systems and consumes little memory [10] during code generation. \nAn important side-effect of eliminat\u00ading intermediate data structures is that the VCODE instruction set \ncan be readily extended by clients since VCODE does not [11] enforce any particular semantics on instructions. \n VCODE is not a toy system. We have used it extensively in the networking subsystem of our experimental \nexokernel [12] operating system [8] and as a compiler backend for an extension of ANSI C that supports \ndynamic code generation. [13] VCODE both generates code efficiently and generates effi\u00adcient code. Its \ninterface and abilities make it useful for a broad class of clients. VCODE is the first general-purpose \ndynamic [14] code generation system to generate code without the use of an intermediate representation, \nthe first to support extensibil\u00ad [15] ity, and the first system to be made publicly available (source \ncan be obtained from the author). We hope that the availabil\u00adity of VCODE will help raise dynamic code \ngeneration from a curiosity to its rightful position as a common optimization tool. [16] Acknowledgments \n[17] I thank Massimiliano Poletto for his patience while porting C to VCODE and Marcus Daniels for his \nrole as beta-tester. I thank Eddie Kohler for extensive editing and typesetting assistant% Greg Ganger \nand ,Deborah Wallach for thorough readings of [18] the paper. I especially thank Professor Frans Kaashoek \nfor his support of this research and Todd Proebsting for many insightful discussions about dynamic code \ngeneration. [19] References [20] [1] M. L. Bailey, B. Gopal, M. A. Pagels, L. L. Peterson, and P. Saskar. \nPATHFINDER A pattern-based packet classifier. In [21]Proceedings of the First Symposium on Operating \nSystems De\u00adsign and Implementation, pages 115-123, November 1994. [2] C. Chambers and D. Ungw. Customization: \nOptimizing com\u00adpiler technology for SELF, a dynamically-typed object-oriented [22]prograrnrning language. \nIn Proceedings of PLDI 89, pages 146\u00ad160, Pordand, OR, June 1989. [3] D. D. Clark and D. L. Tennenhouse. \nArchitectural considera\u00ad[23] tions for a new generation of protocols. In ACM Communication Architectures, \nProtocols, and Applications (SIGCOMM) 1990, September 1990. [4] R. F. Cmelik and D. Keppel. Shade A \nfast instruction-set simula-[24] tor for execution profiling. In Proceedings of the 1994 ACM SIG-METRICS \nConference on Measurement and Modeling of Com\u00adputer Systems, pages 128-137, May 1994. [5] C. Consel and \nF. Noel. A general approach for inn-time spe\u00adcialization and its application to C. In Proceedings of \nthe 23th Annual Symposium on Principles of Programming Lartguages, St. Petersburg, FL, January 1996. \n [61 P. Deutsch and A.M. Schiffman, Efficient implementation of the Smalltalk-80 system. In Proceedings \nof Ilth POPL, pages 297 302, Salt Lake City, UT, January 1984. [7] D. R. Engler, W. C. Hsieh, and M. \nF. Kaashoek. C: A language for high-level, efficient, and machine-independent dynamic code generation. \nIn Proceedings of the 22th Annual Symposium on Principles of Programming Languages, 1995. [8] D. R. \nEngler, M. F. Kaashock, and J. O Toole Jr. Exokemel: an operating system architecture for application-specific \nresource management. In Proceedings of the Fifteenth ACM Symposium on Operating System.r Principles, \nDecember 1995. D. R. Engler, D. Wallach, and M. F. Kaashoek. Efficient, safe, application-specific message \nprocessing. Technical Memoran\u00addum MIT/LCS~M533, MIT, March 1995. D.R. Engler and T.A. Proebsting. DCG: \nAn efficient, retargetable dynamic code generation system. Proceedings of ASPLOS-VI, pages 263-272, October \n1994. C. W. Fraser. A language for writing code generators. In Proceed\u00adings of the S1GPL4N 89 Conference \non Programming Language Design and Implementation, pages 238-245, 1989. C. W. Fraser rmd D. R. Hanson. \nA retargetable compiler for ANSI C. SIGPLANNotices, 26(10), October 1991. U. Holzle and D. Ungar. Optimizing \ndynamically-dispatched calls with inn-time type feedback. In Proceedings of PLDI 94, pages 326-335, Orlando, \nFlorid% June 1994. D. Keppel, S.J. Eggers, and R.R. Henry. A case for mntime code generation. TR 91-11-04, \nUniv. of Washington, 1991. M. Leone and P. Lee. Lightweight inn-time code generation. hr Proceedings \nof the Workshop on Partial Evaluation and Semantics-Based Program Manipulation, pages 97 106, Copen\u00adhagen, \nDenmark, June 1994. M. Leone and P. Lee. Optimizing ML with run-time code gen\u00aderation. In Proceedings \nof the SIGPLAN 96 Conference on Pro\u00adgramming Language Design and Implementation, May 1996.  J.C. Mogul, \nR.F. Rasbid, and M.J. Accetta. The packet filter An efficient mechanism for user-level network code. \nIn Pro\u00adceedings of the Eleventh ACM Symposium on Operating Systems M. Poletto, D. R. Engler, and M. \nF. Kaashoek. tee: A template\u00adbased compiler for C. In Workshop on Compiler Support for Systems Software, \nTucson, AZ, February 1996. C. Prr, H. Massahi, and J. Ioannidk. The Synthesis kernel. Compu?irrg Systems, \nl(l): 11 32, 1988. N. Ramsey and M. F. Femandez. The New Jersey Machine-Code Toolkit. Technical Report \n95-082, Purdue University, Dept of Computer Sciences, December 1995. Submitted to ACM Trans\u00adactions on \nProgramming Languages and Systems M. Rosenblum, S. A. Herrod, E. Wltchel, and A. Gupta. Complete computer \nsimulation: The SirnOS approach. IEEE Parallel and Distributed Technology, Fall 1995.  Principles, pages \n39-51, November 1987. R. Pike, B.N. Locantbi, and J.F. Reisez offs for bitmap graphics on the Blit. Experience, \n15(2): 131-151, February Hardware/software Soflware-Practice 1985. trade\u00adand J.E. Veenstra and R.J. \nFowler. MINT: a front end for efficient sim\u00adulation of shared-memory multiprocessors. In Modeling and \nSim\u00adulation of Computers and Telecommunications Systems, 1994. M. YalI~ B. Bershad, C. Maedz and E. \nMoss. Efficient packet demultiplexing for multiple endpoints and large messages. In Proceedings of the \nWinter 1994 USENLY Conference, 1994.  170   \n\t\t\t", "proc_id": "231379", "abstract": "Dynamic code generation is the creation of executable code at runtime. Such \"on-the-fly\" code generation is a powerful technique, enabling applications to use runtime information to improve performance by up to an order of magnitude [4, 8,20, 22, 23].Unfortunately, previous general-purpose dynamic code generation systems have been either inefficient or non-portable. We present VCODE, a retargetable, extensible, very fast dynamic code generation system. An important feature of VCODE is that it generates machine code \"in-place\" without the use of intermediate data structures. Eliminating the need to construct and consume an intermediate representation at runtime makes VCODE both efficient and extensible. VCODE dynamically generates code at an approximate cost of six to ten instructions per generated instruction, making it over an order of magnitude faster than the most efficient general-purpose code generation system in the literature [10].Dynamic code generation is relatively well known within the compiler community. However, due in large part to the lack of a publicly available dynamic code generation system, it has remained a curiosity rather than a widely used technique. A practical contribution of this work is the free, unrestricted distribution of the VCODE system, which currently runs on the MIPS, SPARC, and Alpha architectures.", "authors": [{"name": "Dawson R. Engler", "author_profile_id": "81100222430", "affiliation": "Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA", "person_id": "P64637", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/231379.231411", "year": "1996", "article_id": "231411", "conference": "PLDI", "title": "VCODE: a retargetable, extensible, very fast dynamic code generation system", "url": "http://dl.acm.org/citation.cfm?id=231411"}