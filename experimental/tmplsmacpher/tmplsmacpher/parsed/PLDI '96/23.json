{"article_publication_date": "05-01-1996", "fulltext": "\n Target-Sensitive Construction of Diagnostic Programs for Procedure Calling Sequence Generatorst Mark \nW. Bailey Jack W. Davidson Department of Computer Science University of Virginia Charlottesville, USA \nAbstract Building compilers that generate correct code is difficult. In this paper we present a compiler \ntesting technique that closes the gap between actual compiler implementations and correct compilers. \nUsing fonnaf specifications of procedure calling conventions, we have built a target-sensitive test suite \ngenerator that builds test crisesfor a specific aspect of compiler code generators the proce\u00ad dure calling \nsequence generator. By exercising compilers with these target-specific test suites, our automated testing \ntool has exposed bugs in every compiler tested. These compilers include ones that have been in heavy \nuse for many years. The detected bugs cause more than 14,000 test cases to fail. 1Introduction Building \ncompilers that generate correct code is difficult. To achieve this goal, compiler writers rely on automated \ncompiler building tools and thorough testing. Automated tools, such as parser generators, take a specification \nof a task and generate imple\u00ad mentations that are more robust than hand-coded implementations. Conversely, \ntesting tries to make hand-coded implementations more robust by detecting errors, One aspect of a compiler \nthat has traditionally been hand-coded is the portion that genemtes calling sequences that implement \nprocedure calls. We have developed a language, called CCL, for specifying procedure calling conven\u00ad tions, \nCCL specifications are used to automatically generate call\u00ad ing sequences for a retsrgetable optimizing \ncompiler [BD95]. In doing so, we realized that CCL descriptions could be used to make other compilers \nmore robust without requiring that the compiler implementation use CCL. In this paper, we describe how \nCCL specifications can be used to generate tests for hand-coded calling sequence generators in other \ncompilers. This twhnique has exposed a number of calling convention errors in production-qual\u00ad ity compilers \nthat have been heavily used for years. One feature of high-level programming languages that com\u00ad pilers \nmust implement is the procedure call. The interface between procedures facilitates separate compilation \nof program modules and interoperabllity of programming languages. This is accom\u00ad plished by defining \na procedure calling convention that dictates the t This work was supported in part by National Science \nFoundation grant CCR-9214904. Authors addresses: mark@virginia. edu, jwd@vir \u00adginia. edu. Permissionto \nmake digitaikmd copy of part or ail of We work for personal orclassroomuseisgrantedwithout fee providedthat \ncopiesare not made or distributed fer prefit or eammweiai advanta e, the eowright nOfiOS,the title of \nthe bkation and its date appear, an t notice is given mat rotherwise, to republish, lb copying IS y permission \nof ACM, inc. To COPYpostonservers,ortoradktribute tolists,requirespriorspecificpermission andlor a fee. \nPLDi 96 Y96 PA, USA O 1996 ACM 0-69791-795-2/9640005...$3.50 VA 22903 way that program values are communicated, \nand how machine resources are shared, between a procedure making a cdl (the caller) and the procedure \nbeing called (the callee). The calling convention is machine-dependent because the roles for passing \nvalues from one procedure to another depend on machine-specific features such as memory alignment restrictions \nand register usage conventions. The code that implements the calling convention, known as the calling \nsequence [Job], must be generated by the code generator. This aspect of the code generator, which we \nrefer to as the calling sequence generator, is a source of great difficulty for the compiler writer because \nit not only suffers from being hand-coded, it also changes each time the compiler is retsrgetcd. As part \nof research whose objective is to develop more retar\u00adgetable optimizing compilers, we have developed \na formal specifi\u00adcation language for describing procedure calling conventions. This language, called \nCCL, has been used to generate automatically the calling sequence generator for a compiler [BD95]. The \ncompiler, called vpcdvpo, is a retargetable optimizing compiler for the C language that has been targeted \nto over a dozen different architec\u00adtures [BD88, BD94]. The procedure calling convention for a target \nmachine is described using CCL. The resulting specification is processed by a CCL interpreter. The interpreter \ncan generate tables that can be used in the calling-convention-specific portion of vpccfipo, or in a \ntest suite generator, This process is pictured in Figure la. The test suite generator uses information \nfrom the table to tailor the test suite to the specific calling convention. The test suite can either \nbe used to confirm that the vpca vpo implementation propcrl y uses the convention tables, or that another, \nindependent compiler conforms to the convention described in the CCL specification. As shown in Figure \nlb, a calling convention description can be used to automatically generate test cases that exercise a \ncom\u00adpiler s calling sequence generator. A test case is composed of two procedures, each in its own file. \nOne file is compiled by the com\u00adpiler under test, while the other is compiled by the reference com\u00adpiler. \nThe reference compiler operationally defines the procedure calling convention (its implementation is \ndefined to be cortect). The resulting objects files are linked together and run. Results of the test \nare checked by the conformance verifier and given to the test conductor. The test conductor tallies the \nresults of rdl tests for a test suite and generates a conformance report. This paper makes several contributions. \nFirst a method for automatically y testing implementations of procedure calling con\u00adventions is presented. \nUsing this technique we have found bugs in mature C compilers. This technique, which uses a formal specifi\u00adcation \nof procedure calling conventions, methodicrdly generates tests that offer complete coverage of the problem \ndomain. Second, an algorithm for intelligently selecting important tests from the complete coverage suite \nis introduced. These tests include bound\u00ad Calling Calling Convention Convention -Specification Tables \n1 G5D- Test Suite Figure Iw How CCL specifications are used. Test --------Results Analysis -r? ,,\u00ad,/ \n, / / / ,,-mkkh Calling Convention Specification Test Case Figure lb: Using test suites to determine \nary cases that are more likely to reveal bugs than exhaustive or ran\u00addomly genemted tests. Third, because \nthe tests focus only on the calling convention, they can isolate errors more effectively than tests from \na generai test suite. Finally, a method for quickly deter\u00admining the conformance of multiple compilers \nat once is described, 2 Procedure Calling Conventions A calling convention is the set of rules to which \na caller and cake must conform. Figure 2 contains the calling convention rules for a hypothetical machine. \nConsider the following ANSI C prototype for a function foo: int foo (char pl, int p2, int p3, double \np4) ; Forthe purpose of transmitting procedure arguments foroursim\u00adple convention, weareonly interested \ninthesignature of the pro\u00adcedure. We define a procedure s signature to be the procedure s name, the order \nand types of its arguments, and its return type, This k analogous to ANSIC S abstract declaratory, which \nfor the above function prototype is: int foo(char, int, int, double) ; which defines a function that \ntakes four arguments (a char, two int s, and a double), and returns an int. convention conformance of \na compiler. 1. Registers ai, a2, a3, and a4 are 32-bit argument-transtnit\u00adting registers. 2. Arguments \nare also passed on the stack in increasing mem\u00adory locations starting at the stack pointer (M[ap]). \n3. An argument may have type char ( 1 byte), int (4 bytes), or double (8 bytes). 4. An argument is passed \nin registers (if enough are available to hold the entire argument), and then on the stack. 5. Arguments \nof type int are 4-byte aligned on the stack. 6. Arguments of type double are 8-byte aligned on the stack. \n 7. Stack elements that are skipped over cannot be rtilocated later.  s. Return values are passed in \nre isters a and a2, 9. Values of registers a6, a , a? and ag must be preserved across a procedure call. \nFigure 2: Rules for a simple calling convention. With foo s signature, we can apply the calling convention \nin Figure 2 to determine how to call foo. Arguments to foo would be placed in the following locations: \n pl in register al,  p2 in register a2,  w p3 in register a3, and s p4 on the stack in M[spsp + 71(M \ndenotes memory). Notice that although register a4 is available, p4 is placed on the stack since it cannot \nbe placed completely in the remaining register (rule 4). Such restrictions are common in actual calling \nconven\u00adtions. Now that we have seen how arguments are transmitted for a simple example, we can describe \nthe objects in our model. The pri\u00admary objects of interest are machhte resources, A machine resource \nis simply any location that can store a value. Examples include registers and memory locations, such \nas the stack. Defin\u00ading where required values are located is accomplished by specify\u00ading a mapping from \none resource to another, We call such a mapping a placement. CCL descriptions define placement finctions \nfor both proce\u00addure arguments and return values. They also describe other aspects of calling conventions \nsuch as frame layout and stack allocation. However, these features of CCL are not considered in this \npaper since the focus of our test suite generator is verifying the imple\u00admentation of placement functions. \n3 The Formal Model We use finite state automata to model each placement in a calling convention. A placement \nFSA (P-FSA) takes a procedure s signa\u00adture as input and produces locations for the procedure s arguments \nas output. The automaton works by moving from state to state as the location of each value is determined. \nWhen a transition is used to move from one state to the next, information about the current parameter \nis read from the input, and the resulting placement is written to the output, Placement functions are \ndeseribed in terms of finite resources, infinite resources, and selection criteria. A set of finite resources \nR = {rz,r2, .... rn} are used to represent machine regis\u00adters, while an infinite resource I = {il, i2, \n...] is used represented the stack. The selection criteria C = {cl, C2,.... cm} correspond to characteristics \nabout arguments (such as their type and size) that the calling convention uses to select the appropriate \nlocation for a value. We encode the signature of a procedure with a tuple w e (C*, C*). Each state q \nin the automaton is labeled according to the allocation state that it represents. The label includes \na bit vector v of size n that encodes the allocation of each of the finite resources in R. Additionally, \nto express the state of allocation for the stack, we include d, the distinguishing bits that indicate \nthe state of stack alignment. So, a state label is a string vd that indicates the resource allocation \nstate. In our example convention, n = 4, and IId! = 3. So, each state is labeled by a string from the \nlanguage {O, 1)4{0, 1]3. The output of M is a strings c P, where P = R u {q 1) IIdl, which contains the \nplacement information. Since the P-FSA produces output on transitions, we have a Mealy machine [Mea55]. \nWe define a P-FSA, M, as a six-tuple M= (Q, X, A, 8, h, go), where: . Q is the set of states with labels \n{Q 1] {Q represent\u00ad 1} 11~11ing the allocation state of machine resources, . the input alphabet X = C, \nis the set of selection criteria . the output alphabet A = P, is the set of placement strings, the transition \nfunction 8:Q x Z + Q, the output function L:Q x Z. + A+, and go is the state labeled by @w where Ilwll \n= Ildll, and w is the initial state of d. The P-FSA that corresponds to our hypothetical calling con\u00ad \n vention is shown in Figure 3. Its output function L is shown in Table L The states of the automaton \nrepresent that state of alloca\u00adtion for the machine resources, For example, the state labeled q2 (1100 \n000) represents the fact that register al and a2 have been allocated, but that a3, a4 and stack locations \nhave not been allo\u00adcated. The transitions between states represent the placement of a single argument. \nSince arguments of different types and sizes impose different demands on the machine s resources, we \nmay find more than one transition leaving a particular state. In our example, qg has three transitions \neven though two of them (int and doubls) have the same target state (q4). This duplication is required \nsince the output from mapping an Int is different horn the output from mapping a double. dd Figure 3: \nA simple placement finite-state automaton, 251 1 90 ql q2 % q4 q5 q6 q7 q8 q9qfoqll char a a2 a3 a 000 \n001 010 011 100 101 110 111 int al a2 a3 a4 memla mem2b mem2 mem2 mem2 mem 1 meml mem j ~la2 ~2a3 ~3a4 \n double mernf mem3 mem3 mem3 mem3 mem3 mem3 mem3 mem3 Table I: Definition a. tnem~ = 000001010011 b.rnem2 \n= 100101110111  c. memj =000001 010011100101110111  The signature: int phred(double, double, char, \nint); will take the P-FSA in Figure 3 from state q. to q4 producing the string (al a2) (a3 a4) (000) \n(100 101 110 111) along the way. From the string, we can derive the placement of the bred s arguments. \n? The first double is placed in registers al and a , the second in reg\u00adisters a3 and a4, the char at \nthe first stack location and the int start\u00ading in the fifth stack location. 4 Test Vector Selection In \norder to test a compiler s implementation of a calling conven\u00adtion, we must select a set of programs \nto compile. To exercise the calling convention, each test program must contain a caller and a callee \nprocedure. For the purpose of testing the proper transmis\u00adsion of program values between procedures, \nthe signature of the cake uniquely identifies a test case. Thus, two differmt programs, whose callees \nsignatures match, perform the same test. Therefore, the problem of generating test cases reduces to the \nproblem of selecting signatures to test. Selecting which procedure signatures to test is a difficult \nproblem. Obviously, one cannot test all signatures since the set of signatures, S = {(C*, C*)), is infinite. \nHowever, since we can model the function that computes the placement of arguments as an FSA, there must \nbe a finite number of states in an implementa\u00adtion to be tested. This is the casefor any implementation, \nincluding those that do not explicitly use FSA S to model the placement func\u00adtion. The problem of confirming \nthat an implementation properly places procedure arguments is equivalent to experimentally deter\u00admining \nif the implementation behaves as described by the P-FSA state table. This problem is known as the checking \nexperiment problem from finite-automata theory [Hen64, Koh78]. There are numerous approaches to this \nproblem, most of them are based on transition testing. Transition testing forces the implementation to \nundergo all the transitions that are specified in the specification FSA. of k for example P-FSA. An obvious \nfirst approach to generating test vectors using the P-FSA specification is to generate all vectors whose \npaths through the FSA are acyclic, or whose path ends in a cyclel. This solution insures that each state \nq is visited, and each transition 8(q,a) is tra\u00adversed. For an FSA with a small number of states, and \na small input alphabet, this may be acceptable. However, the number of such paths for an FSA is O(llZ// \nIIQII). Table II contains profiles for five P-FSA S that we have built from CCL descriptions. For com\u00adplex \nconventions, like the MIPS and SPARC, the number of transi\u00adtions, and more importantly, the number of \nstates can be lar~~ For the MIPS, this results in an upper bound of 2512 = 2.3xl O test vectors. In practice, \nthe number of test vectors is closer to 108 vec\u00adtors. However, this is still too many to run feasibly. \nAnother, simpler, approach is to guarantee that each transition is exercised at least once. Since there \nare no more than IIQIIIIzII transitions, the number of test vectors that this generates is not unreasonable. \nHowever, this method results in poor coverage that does not inspire confidence in the test suite. For \nexample, for the P-FSA in Figure 3, the two signatures: void f (double, double) ; void f (int, int, int, \nint) ; void f (int, double) ; cover all int and double transitions leaving states qo-3.This leaves the \nsignature: void f (double, int) ; untested, Clearly such a test should be included in the suite. To fur\u00adther \nillustrate the problem, consider the FSA specification shown in Figure 4a. An erroneous implementation, \nshown in Figure 4b, contains an extra state ql that is reached on initial input b. The two strings, aaa \nand bbb completely cover the transitions, Unfor\u00adtunately, these test vectors will not detect that the \nimplementation has an additional (fault) state. Thus, it is not sufficient to include only test vectors \nthat cover the transition set. 1We define a path that ends in a cycle to be a cyclic path wa where the \npath w is acyclic. Memory Longest Allocation Partition Acyclic Machine Vector Bits BKs IIQII 11511 Ilzll \nPath DEC VAX o 0 1 3 3 0 M66020 (Sun) o 2 4 24 6 3 SPARC (Sun) 6 3 9 90 10 6 M66100 (Motorola) 6 3 72 \n720 10 15 MIPS R3000 (DEC) 6 3 70 772 25 11 lhble Ik P-FSA profiles for several calling conventions. \n252 do S/o SJI bll b/O II/l Figure 4a: Specification FSA. do Figure 4b: Implementation FSA. Figure 4: \nExample FSA where a fault will not be detected An alternative, which falls between the simple transition \napproach and the acyclic path approach, we call the transition\u00adpainng approach. In transition pairing, \nwe examine each state in the specification FSA. As shown in Figure 5, a state has entering and exiting \ntransitions. For each state, we include a test vector that covers each pair of entering and exiting transitions. \nThis elimin\u00adates the faulty state detection problem illustrated in Figure 4. Fur\u00adthermore, it provides \ntests that have a similar characteristic to the acyclic method: transitions are tested in all the contexts \nthat they can be applied. Although there are many combinations that are not tested, they are similar \nto ones included in the set. For example, in the simple FSA pictured in Figure 3, we could have a set \nof test vectors that includes the vector double double double to exercise the state q4 with the transition \npair ((q3, double), (q4, double)). Such a set would not need to include int lnt double double to cover \nthe same transition pair. Figure 5: Entering and exiting transitions for a state. This method of test \nvector generation provides a complete coverage of transitions in the specification FSA. Further, the \ntests reflect the context sensitivity that transitions have. This allows for some erroneous state and \ntransition detection, while significantly reducing the number of test vectors. The test vector sizes \nare sig\u00adnificantly smaller than the acyclic method, while still providing a si~ificant confidence level, \nAn algorithm for generating transition-pair paths is shown in Figure 8 (in the apprxdx). The algorithm \nperforms a depth-first search of the FSA state graph. Each time a transition (q, a) is encounte~d, it \nis marked. This mark indicates that all paths that go I Transition Transition-Acyclic Machine Paths \npair paths paths II 1! IDECVAX \\ 3I 12I 31 I M66020 (Sun) I 24 I 324 I 961 I SPARC (Sun) I 224 I 7434 \nI >108 I I M861OO(Motorola) I 720 I 22,412 I >108 I I MIPS R3000 (DEC) I 772 I 5655 I 8X108 I Table III: \nSizes of test suites for various selection methods. beyond (q, a) are have been visited. When the algorithm \nreaches a state qn on transition (qm, a), each transition (qn, b) where b G % is visited whether or not \nit is marked. This causes all pairs of transi\u00ad tions ((qm, a), (qn, b)) to be included. These pairs represent \nall combinations of one entering transition with all exiting transitions. Because the algorithm is depth-first, \neach entering transition is guaranteed to be visited. Thus all combinations of entering and exiting transitions \nare included. 5 Test Case Generation After selecting the appropriate test vectors, or procedure signa\u00ad \ntures, the corresponding test cases must be realized. In our approach, we generate a separate test program \nfor each test vector so that we can easily match any teported errors to the specific test vector. A procedure \ncall is broken into two pieces: the procedure call within the caller (the call-site) and the body of \nthe callee. Because they are implemented differently, these two pieces of code are typ\u00adically generated \nin separate locations in a compiler. This natural separation is reflected in the way that we construct \nour test cases. Each test case is composed of two files, one contains the caller, the other contains \nthe callee. The two files are compiled and linked together. The programs are self-checking, so that if \na procedure call fails, this event is reported by the test itself. Figure 7 (in the appendix) shows an \nexample test case for the C signature void (int, double, struct(2)2). The caller (Figure 7a) loads each \nof the arguments with randomly selected bytes. How\u00adever, the values of these bytes have an important \nproperty: each contiguous set of two bytes is unique. Thus, for a string B of m bytes, for all indexes \nO <is m, there exists no index O cj S m and j # i such that B~ + k] =B[i+k] fora110Sk<2. Wecan easily \nguarantee this property for rdl strings B whose length is no more than 65536 (216) bytes. Since the likelihood \nof using an argu\u00adment list of size greater than 64 Kbytes is small, this is sufficient to guarantee that \nany two bytes passed between procedures are unique. This makes it easy to identify if an argument has \nbeen shifted or misplaced since each argument s value is guaranteed to be unique. The callee (Figure \n7b) receives the values, and checks them against the expected values. If the values do not match, an \nerror condition is signalled. The generation of good test cases from selected signatures is language \ndependent. One convention used in the C programming language is varargs. varargs is a standard for writing \nprocedures that accept variable length argument lists. The proper implementa\u00adtion of varargs in a C compiler \ncan be tricky. For each test case that we generate we also generate a varargs version to verify that \nthis standard convention is implemented correctly. However, we do not include an example here. 2 we d~n~t~ \na ,qructwe whose size is n bytes as Stmct(n). 2,53 6 Results We used our technique for selecting test \nvectors to test a number of compilers on several target machines. Several errors were found in C compilers \non the MIPS. In this section, we present these results. We selected several C compilers that genetate \ncode for the MIPS architecture (a DECStation Model 5000/125). These included the native compiler supplied \nby DEC, a version of Fraser and Hanson s lcc [FH91] compiler, several versions of GNU s gcc [Sta92], \nand a previous version of our own C compiler that used a hand-coded calling sequence generator. Although \nwe feel that this technique is extremely valuable throughout the compiler develop\u00adment cycle, we believe \nthat it would be fairest to evaluate its effec\u00adtiveness in finding errors in young implementations of \ncompilers. Where possible, we have used early versions of these compilers, These versions, called legacy \ncompilers, represent younger imple\u00admentations that more accurately exhibit bugs found in initial releases \nof compilers. However, each of these compilers is a pro\u00adduction-quality compiler that has been widely \nused for years. Find\u00ading any bugs in their implementations is still a significant challenge. In testing \nthe compilem, we checked for two types of con\u00adformance: internal and external. Compiler A internally \nconforms if code that it generates for a caller can properly call code for a cake that it generated. \nWe denote this using A &#38;A. Compiler A exter\u00adnally conforms if its caller code can call another compiler \nB s callee code, and vice versa (A -&#38;B and B &#38;A). Thus, the callees and callers are compiled \nusing each of the compilers under test, This results in n object versions for n compilers. Each caller \nver\u00adsion is then linked with the callee that was generated by the same compiler. This results in the \nn tests necessary to verify internal conformance for this test case. To establish external conformance, \nwe could naively link each caller to each callee, which would yield 2n2 tests. However, we can do better. \nRecognizing that rocedure ? call (Z+ ) is symmetric we cart easily reduce this to n (since if A &#38; \nB , then B &#38;A). Furthermore, procedure call is also tnutsi\u00adtive, so if A -@B and B -&#38; C, then \nA &#38; C. This reduces the number to 2n -n as pictured in Figure 6. If a reference compiler (an operational \ndefinition of the calling convention), Cm is used, Figure 6 would look different. Each compiler s caller/cal \n{ee would be linked to the reference compiler s callee/caller. This facilitates the isolation of which \ncompiler does not conform when an error is detected. The results of running both internal and external \ntests on the compiler set for the MIPS are shown in Table IV. We found both internal and external conformance \nerrors in all of the tested com\u00adpilets. Table IV reports internal and external errors separately. Within \neach class, the number of actual tests that failed and the number of faults that caused test failure \nare indicated. The num\u00adbers reported in the fault columns indicate the approximate number of actual coding \nerrors resulting in test failures. These numbers are only approximate. We tried, as best we could, to \nglean this infor\u00admation from the results of tests. More accurate numbers can only be obtained by examining \nthe compiler s source. 6.1 Standard Procedure Calls Internal conformance errors were found in two versions \nof gee. gcc 1.38 failed 24 tests that focus on passing structures in registers. Structures between 9 \nand 12 bytes in sire (3 words) are not prop erly passed starting in the second argument register. Procedure \nsig\u00adnatures that correspond to these tests include: void ( int, struct (9-12) ) ; gcc 2.4.5 fails a single \ntest. The fault occurs with procedures with the signature: void (struct (l) , struct (l) , struct (l) \n) ; gcc 2.4.5 fails to even compile a procedure with this signature. The fact that gcc 2.1 does not have \nthis error indicates that the error was introduced after version 2.1. This supports our conjec\u00adture that \nsuch method of automatic testing is extremely useful throughout the development and maintenance life-cycle \nof a com\u00adpiler. External conformance errors were more prevalent, gcc 1.38 does not properly pass l-byte \nstructures in registers. This results in 208 test case failures, gcc 1.38 and 2.4.5 cannot pass a structure \nin the third argument register when that structure is followed by another. The fault occurs with signatures \nmatching: void(int, int, struct (l-4) , struct (any) ) ; This results in another 13 test failures. Finally, \nvpcchpo has 486 tests that fail. llvo faults are responsible: 1) structures are not passed properly in \nregisters, and 2) 1 to 4-byte structures are not passed in memory correctly if they are immediately followed \nby another structure. These match signatures: void (int, int, int, int, struct (l-4) , struct) ; 6.2 \nVariadic Procedure Calls Procedures that take variable-length argument lists (variadic ftmc\u00adtions) are \nwritten using one of two standard header files: varargs. h (for traditional C) and s tdarg. h (for ANSI \nC). These files provide a standard interface for the programmer to write variadic functions. Because \na variadic function s caller uses the standard procedure calling convention, the variadic callee must \nalso conform to this convention. The following paragraphs detail the results of calling callees that \nare implemented using varargs/ stdarg. Most variadic functions in C have signatures similar to the standard \nlibrary function print f: void func (char *, . ..). the function determines the number of arguments from \nthe first parameter. However, functions of the form void func (double, . . , ) ; are also perfectly valid. \nWhen running test cases that contained variadic functions whose first argument was a double, we found \nthat none of the compilers, including the reference compiler, prop erly implemented the calling convention. \nThe diftlculty stems from the fact that until the type of the argument is known, the callee can\u00adnot determine \nwhether to fetch the first argument from the float\u00ading-point register or the integer register. Most implementations \nof varargs dump the contents of the argument-passing registers to the stack in the function s prologue. \nFor calling conventions like the MIPS, a more sophisticated solution must be used. This error caused \n2346 test cases to fail for all of the compilers. Version 2 releases of gcc managed to avoid this problem \nat the expense of interoperability; their generated callces do not conform to the established calling \nconvention. From these results, it is clear that the state-of-the-art in com\u00adpiler testing is inadequate, \nBecause these are production-quality compilers, each of them has undoubtedly undergone rigorous test\u00ading. \nHowever, hand development of test suites is an arduous and itself error-prone task. Furthermore, because \nthese tests are target specific, they must be revisited with each retargeting of the com\u00adpiler. In contrast, \nby using automatic test generators that are target 3 These num~rs include tests of both standard procedure \ncdk and vfi\u00ad 4 The error returned by gcc 2.4.5 is: gcc: Internal compiler adic procedure calls. error: \nprogrsm ccl got fatal signal 4. Cct CC2 CC3  Ccn caller caller caller caller ( cc, CC* CC3 ... Ccn \ncame cake ( cabs cake ~e<z7 Figure 6: Determining conformance of n compilers. internal Externai Compiler \nFaiiad teata Fauita Faiiad Taste Fauits cc (native) 2348 gcc (1.38) 2370 gcc (2.1) 01 gcc (2.4.5) Icc \n(1 .9)a Icc (3.3) 2407 I Vpcclvpo 2W81 I Total I 14162 I 1 2348 1 2 2567 3 =9 2346 1 2374 3 00 2 2407 \n2 11 4661 31 91 14872 I 13I  0 3= Table Iv Results of running MIPS test suite on several compilers. \na. Version 1.9 of lcc was not tested using varcngs because we could not get the compiler to accept vamrgs \ncakes. This could either be a problem with the compiler, or the particular version ofs tdarg. h on our \nmachine. sensitive, compilers can be quickly be validated before each release. 7 Related Work The automatic \ngeneration of test suites has received much attention recenti y in the area of conformance testing of \nnetwork protocols [SL89]. The purpose of the suite is to determine if the implementa\u00adtion of a communication \nprotocol adheres to the protocol s specifi\u00adcation. In many cases, the protocol specification is provided \nin the form of a finite-state machine. This has resulted in many methods of test selection including \nthe Transition tour, Partial W-method [FBK+91], Distinguishing Sequence Method [Koh78], and Unique-Input-Output \nmethod [ADLU91]. These methods are derivatives of the checking experiment problem where an imple\u00admentation \nis checked against a specification FSM [YL95]. What distinguishes these methods from ours is that a bound \non the num\u00adber of states in the implementation FSM is assumed. Because we have no practical bound on \nthe number of states in the implementa\u00adtion, their work is not applicable, Finally, a similarly related \nfield is the automatic verification of digital circuits [Hen64, HYHD951. 8 Summary Building compilers \nthat generate correct code continues to be a dif\u00adficult problem. Using automated compiler tools and testing, \none can significantly increase the robustness of a compiler. We have combined these two techniques, in \na new way, that further closes the gap between actual compiler implementations and the ever\u00adsought-after \ncorrect compiler. By using formal specifications of procedure calling conventions, we have designed and \nimplemented a technique that automatically identifies boundary test cases for calling sequence generators. \nWe then applied this technique to measure the conformance of a number of production-quality com\u00adpilers \nfor the MIPS. This system identified a total of a least 22 faults in the tested compilers. These errors \nwere significant enough to cause over 2,300 different test cases to fail. Clearly, this tech\u00adnique is \neffective at exposing and isolating bugs in calling sequence generators of mature compilers. It would \nbe even more effective during the initial development of a compilation system. References [ADLU91] Alfred \nV. Aho, Anton T. Dahbura, David Lee, and M. Uyar. An optimization technique for protocol conform\u00adance \ntest generation based on uio sequences and rural chinese postman tours. IEEE Transactions on Commu\u00adnications, \n39(1 1): 1604-1615, November, 1991. [BD88] Manuel E. Benitez and Jack W. Davidson. A portable global \noptimizer and linker. In Proceedings of the ACM SIGPL4N 88 Conference on Programming Language Design \nand Implementation, pages 329 338, July 1988, [BD94] Manuel E. Benitez and Jack W. Davidson. The advan\u00adtages \nof machine-dependent global optimization. In Proceedings of the 1994 Conference on Programming Languages \nand Systems Architectures, pages 105 124, March 1994. [BD95] Mark W. Bailey and Jack W. Davidson. A formal \nmodel and specification language for procedure calling conventions. In Proceedings of the 22nd SIGPLAN-SIGACT \nSymposium on Principles of Programming Lunguages, pages 298 310, January 1995. [FBK+91] Susumu Fujiwar&#38; \nGregor v. Bochmann, Ferhat Khendek, Mokhtar Amalou, and Abdertazak Ghedamsi. Test selection based on \nfinite state models. IEEE Transactions 17(6):591-603, June on 1991. Software Engineering, [FH91] Christopher \nW. Fraser and David generation interface for ANSI-C. and Experience, 21(9), 1991. R. Hanson. A code Software-Practice \n[Hen64] F. C. Hennie. Fault detecting experiments for tial circuits. In Proceedings of the Fijlh Annual \nsequen-Sympo\u00ad sium on Switching Theory and Logical Design, pages [SL89] Deepinder P. Sidhu and Ting-Kau \nLeung. Formal 95 110, November 1964, methods for protocol testing: A detailed study. IEEE Transactions \nof Software Engineering, 15(4):413\u00ad [HYHD95] Richard C. Ho, C. Han Yang, Mark A. Horowitz, and David \nL. Dill. Architecture validation for processors. 426, April 1989. In ISCA95, pages 404413, 1995. [Sta92] \nRichard M. Stallman. Using and Porting GNU CC [Job] S, C. Johnson. A tour through the portable c compiler. \n(Version 2.0). Free Software Foundation, Inc., Febru\u00ad[Koh78] Zvi Kohavi. Switching and Finite Automata \nTheory. ary 1992. McGraw-Hill, second edition, 1978. [YL95] Mihalis Yannakakis and David Lee. Testing \nfinite state [Mea55] G. H, Mealy. A method for synthesizing sequential cir\u00adcuits, Bell System Technical \nJournal, 35(5): 1045 machines: Fault detection. Journal of Computer and 1079, 1955. System Sciences, \n50:209-227, 1995. Appendix typedef union { typedef union { unsigned char bytes [81 ; unsigned char bytes \n[8] ; double dbl; double dbl; } dblcvt; } dblcvt; typedef struct struct_2 { typedef struct struct_2 \n{ unsigned char field[2]; unsigned char field[2] ; } struct_2; } struct_2; void test_function_callee \n() ; void test_function_callee (long_arg_l, double_arg_2, struct_2_arg_3) void test_function_caller \n() long long_arg_l; { double double_arg_2; dblcvt cvt; struct_2 struct_2_arg_3; static struct_2 struct_2_arg_3 \n= { ( { Ox34,0x8f, ) dblcvt Cvt; }; double double_arg_2; if(long_arg_l != OX440260971) { fprintf(stderr, \nBad long_arg_l\\n ) ; cvt.bytes[O] = Oxe2; exit(1) ; cvt.bytes[l] = Oxed; } cvt.bytes[21 = Oxab; cvt.bytes[O] \n= Oxe2; cvt.bytes[3] = Oxad; cvt.bytes[l] = Oxed; cvt.bytes[4] = OX67; cvt.bytes[2] = Oxab; cvt.bytes[5] \n= OX31; cvt.bytes [3] = Oxad; cvt.bytes[6] = Oxee; cvt.bytes[4] = 0x67; cvt.bytes[71 = 0x7; cvt.bytes[5] \n= OX31; double_arg_2 = cvt.dbl; cvt.bytes [6] = Oxee; cvt.bytes [7] = 0x7; test_function_callee (Ox440260971, \nif(double_arg_2 != cvt.dbl) { double_arg_2, fprintf(stderr, Bad double_arg_2\\n ) ; struct_2_ar9_3 ) ; \nexit(1) ; } if (struct_2_arg_3 .field[ 01 != 0x34) { fprintf(stderr, Element O is bad in struct_2_arg_3 \n.field\\n ); exit(l); } if (struct_2_arg_3 .field[l] != 0x8f) { fprintf(stderr, Element 1 is bad in struct_2_arg_3 \n.field\\n ) ; exit(1) ; } } Figure 7a: Code generated for caller. Figure 7b: Code generated for callee. \nFigure 7: Example test case. Input. A finite-state machine M. Output. The set of transition-pair paths \nin M that take M from go to qn with at most one cycle. The set traverses all pairs of transitions ((qn \na), (q$, b)) such that a(qn a)= qs. Initial call, TRANSITION-pAIRS(qO, &#38;, g, O); Algorithm: function \nTRANSITION-pAIRS(q, w, y cycle) paths 4-0; for each a where a e Z A ~(q, a) is defined do // For each \ntransition from state q... if cycle # 1 A (q, a) Z T then //No cycles and (q, a) is new if q @ V then \n11~ there is no cycle T+ Z u{(q, a)); //Mark transition as followed cycle + O; //Indicate no cycle else \n cycle + 1; //Indicate cycle end if P + TRANs11 ioN-PAIRs(6 (q, a), Wa, V u [q }, cycle); // Compute \npaths from here paths + paths u P; end if paths e paths W {wa}; I/Add this path to paths end for return \npaths; //Return pathsfiom q end function Figure 8: Test vector generation algorithm, \n\t\t\t", "proc_id": "231379", "abstract": "Building compilers that generate correct code is difficult. In this paper we present a compiler testing technique that closes the gap between actual compiler implementations and correct compilers. Using formal specifications of procedure calling conventions, we have built a target-sensitive test suite generator that builds test cases for a specific aspect of compiler code generators the procedure calling sequence generator. By exercising compilers with these target-specific test suites, our automated testing tool has exposed bugs in every compiler tested. These compilers include ones that have been in heavy use for many years. The detected bugs cause more than 14,000 test cases to fail.", "authors": [{"name": "Mark W. Bailey", "author_profile_id": "81100645474", "affiliation": "Department of Computer Science, University of Virginia, Charlottesville, VA", "person_id": "PP15038355", "email_address": "", "orcid_id": ""}, {"name": "Jack W. Davidson", "author_profile_id": "81100099215", "affiliation": "Department of Computer Science, University of Virginia, Charlottesville, VA", "person_id": "PP14044617", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/231379.231431", "year": "1996", "article_id": "231431", "conference": "PLDI", "title": "Target-sensitive construction of diagnostic programs for procedure calling sequence generators", "url": "http://dl.acm.org/citation.cfm?id=231431"}