{"article_publication_date": "05-01-1996", "fulltext": "\n Teapot: Language Support for Writing Memory Coherence Protocols Satish Chandra, Brad Richards, and James \nR.Lams Computer Sciences Department University of Wisconsin-Madison 1210 West Dayton St. Madison, WI \n53706 USA {chandra, richards, lams} @cs,wisc.edu Abstract Recent shared-memory parallel computer systems \noffer the exciting possibility of customizing memory coherence pmto- COISto lit an application s semantics \nand sharing patterns. Custom protocols have been used to achieve message-pass\u00ad ing performance-while \nretaining the convenient program\u00ad ming model of a global address space-and to implement high-level language \nconstructs. Unfortunately, coherence protocols written in a conventional language such as C are dlficult \nto write, debug, understand, or modlfi. This paper describes Teapot, a small, domain-specij$c language \nfor writing coherence protocols. Teapot uses continuations to help reduce the complexity of writing protocols. \nSimple static analysis in the Teapot compiler eliminates much of the overhead of continuations and results \nin protocols that run nearly as fast as hand-written C code. A Teapot specifica\u00adtion can be compiled \nboth to an executable coherence pmto-CO1and to input for a model checking system, which permits the specljication \nto be venjied. We report our experiences coding and venfiing several protocols written in Teapot, along \nwith measurements of the overhead incurred by writ\u00ading a protocol in a higher-level language. This work \nis supported in part by Wright Laboratory Avionics Directorate, Air Force Materiat Command, USAF, under \ngrant #F33615-94-l-1525 and ARPA order no. B550, an NSF NYI Award CCR-9357779, NSF Grant MIP-9225097, \nDOE Grant DE-FG02-93ER25176, and donations from Digitat Equipment Corporation and Sun Microsystems. The \nU.S. Gover\u00adnment is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding \nany copyright notation thereon, The views and conclusions contained herein are those of the authors and \nshould not be interpreted as necessarily representing the official policies or endorse\u00ad ments, either \nexpressed or implied, of the Wright Laboratory Avionics Directorate or the U.S. Government. Permissionto \nmake digitelhrci copy of part or atl of this work for persondl orclassroomuseis rantedwithoutfeeprovidedUmtcopiesarenotmada \nf! or distributed for pro t or commercial advanta e, the copyright notice, fhe title of the ublication \nand its date appear, an8 notice ia given that copying is ! y parmisdon of ACM, ino. To copy otherwise, \nto republish, to post on asrwrs, or to redistribuk to lists, raquires prior spedfio perrrrisskm andbr \na fee. 1 Introduction A shared-memory coherence protocol manages the repli\u00adcation of data, to ensure \nthat a parallel program sees a con\u00adsistent view of memory. In general, a coherence protocol ensures consistency \nwhen a processor writes to a shared location either by invalidating outstanding copies or by updating \ncopies with the new value. A protocol can deter\u00admine, to a large extent, the performance of a shared-memory \nprogram, since communication occurs through loads and stores to shared data. A mismatch between a protocol \nand an application s sharing pattern leads to excessive commu\u00adnication. For example, invalidation protocols \nperform poorly for producer-consumer sharing, since invalidating outstanding copies forces the consumers \nto re-request data, which requires up to four protocol messages for a small data transfer [7]. Recent \nshared-memory architectures provide, to varying degrees, the flexibility of tailoring a coherence protocol \nto better fit an application s needs. An example of such an architecture, the one on which this work \nis based, is the Tempest interface, a specification of the mechanisms neces\u00adsary to implement shared-memory \ncoherence protocols at user-level, i.e., as unpriviledged code running in an applica\u00adtion program [14, \n23]. With Tempest, an application pro\u00adgrammer can either use a ready-made shared-memory protocol from \na library or construct a customized shared\u00admemory protocol that suits an application s needs, thereby \nachieving higher performance [11 ]. Compiler writers can exploit custom coherence policies as well. For \nexample, a recent paper showed how a custom protocol (LCM) enables a compiler to use a fine-grain, copy-on-write \nmechanism to implement a language s copy-in, copy-out semantics, with\u00adout being limited by conservative \npointer analysis [18]. Unfortunately, Tempest mechanisms are low level and protocols can be difficult \nto write, debug, and modify. Writ\u00ading coherence protocols in an ad-hoc manner (as C pro\u00ad grams) artificially \nlimits the number of programmers PLDi 965 96 PA, USA willing or able to develop custom protocols. This \npaper CI 1996ACM 0-89791-795-290/0005... $3.50 addresses the problem with anew language, called Teapot, \nthat supports both writing and verifying coherence proto\u00adcols. By reducing the complexity of developing \nnew proto\u00adcols, Teapot increases the attractiveness of systems, such as Stanford Flash [17], Wisconsin \nTyphoon [23], and Blizzard [24], that implement protocols in software. Protocols writ\u00adten in Teapot could \nalso be used for distributed object sys\u00ad tems, such as Multipol [6], CRL [16], and Orca [3]. The main \ndifficulty in writing a coherence protocol is the requirement that all protocol actions (code executed \nin response to a protocol event, such as a read miss or an incoming message) run to completion before \nrelinquishing the processor to execute protocol code for other cache blocks. Action code, however, frequently \nneeds to engage in blocking communication, e.g., sending a request message to another node and awaiting \na reply. To circumvent this prob\u00adlem, protocol programmers introduce intermediate states in their finite \nstate machines. A protocol awaits a reply mes\u00adsage by shifting into an intermediate state and relinquishing \nthe processor. The intermediate state handles the message on its arrival, and then goes to the destination \nstate (one that reflects the overall effect of the protocol event). The result\u00ading proliferation of states \ncomplicates protocols, because non-atomic transitions force a programmer to reason about the interaction \nbetween all messages and each state. In prac\u00adtice, protocols written in this style are difficult to debug \nor modify. Detailed discussion of coherence protocols and their complications appears in Section 2. Teapot \nallows a programmer to suspend an action han\u00addler and await an asynchronous event by calling a waiting \nfunction with the current continuation (Section 3 and Section 4). Teapot also permits the programmer \nto concisely specify how to handIe other messages that arrive while wait\u00ading. The Teapot compiler transforms \nthe handler with sus\u00adpending calls into atomically executable pieces that can run without causing deadlock, \nAnalysis and optimization in the Teapot compiler (Section 5) eliminates most of the over\u00adhead incurred \nby writing protocols at a higher level of abstraction. Section 6 presents our experience with using Teapot \nto write several protocols for the Blizzard system [24]. With optimization disabled, our compiler generates \nprotocol code in C that runs application programs within 1370 of the speed of a hand-written protocol. \nWith optimization enabled, the performance is (except for one program) within 10% of the corresponding \nhand-written protocol, which is very attrac\u00adtive given the vastly superior protocol writing environment. \nEven with better programming abstractions, protocols can be difficult to write correctly. Field testing \ncannot ensure correctness since protocols contain complex timing\u00addependent paths. Although completely \nverifying a nontriv\u00adial protocol is difficult, model checking through state space exploration has emerged \nas a viable debugging aid for com\u00adplex protocols [8, 9, 22, 28]. In addition to executable C code, the \nback-end of the Teapot compiler can generate input for the Mur@ [9] verification system (Section 7). \nPro\u00adtocol verification has been one of the greatest benefits of this system, as it has reduced the time \nto develop a complex protocol by an order of magnitude.  2 Why are coherence protocols hard? A shared-memory \nsystem can be built on two basic mechanisms. The first mechanism, access control, allows the system to \ncontrol access to memory by permitting read and write accesses only for valid, cached data. Reading or \nwriting an invalid location or writing a valid but read-only location must cause an access fault and \ninvoke the coher\u00adence protocol. The second mechanism, communication, enables a system to transfer control \ninformation and data among processors. A protocol comes into play at an access fault. It must sat\u00adisfy \nthe memory access by bringing the data to the faulting processor s memory. In many protocols, each block \nof shared data has a home node that coordinates accesses to the block. The accessing processor sends \na request to the refer\u00adenced block s home processor, which perfomns bookkeep\u00ading and returns the data. \nOnce a processor obtains the data, it caches a copy, which can be subsequently accessed until it is invalidated. \nMany protocols, for example our Stache pro\u00adtocol [23], enforce coherence by permitting only a single \nwriter (or multiple readers) to a block. When a home node receives a request for a writable copy of a \nblock, it invali\u00addates the outstanding copies before returning the block. The memory reference and the \nrequest and invalidation mes\u00adsages are protocol events, which cause transitions in a pro\u00adtocol state \nmachine. Both the home node and caching processors record state for a block. At a protocol event for \nblock B, the protocol consults B s state to determine an action, which may send messages and update both \nthe state and the contents of the block in memory. For example, Figure 1 depicts states in a simple protocol \nfor a block at a non-home node (Figure 2 shows the corresponding home node state machine.) Con\u00adsider \na block that is initially Invalid. When the processo~ Readable invalidatemsg (acknowledge) o $A yg:p \n*Q $%= &#38;J + Writable Figure 1: Idealized protocol state machine (non-home ~ 7 ~Figure 2: Idealized \nprotocol state machine (home side). ~Transitions are labeled with cause and, in parenthesis, / action. \nreads the block, the protocol obtains a read-only copy from the home node and changes its state to Readable. \nLater, the home node may invalidate the copy with an Invalidate mes\u00adsage, which causes a transition to \nstate Invalid. Simulta\u00adneously, the block s access permissions are changed so subsequent reads or writes \ncause an access fault. In general, actions execute on transitions between states, which are caused by \nprotocol events. Actions may send messages to other processors, await their replies, update protocol-specific \ninformation, and change access permiss\u00adions. The exact states, transitions, and actions depend on the \ncoherence algorithm and the memory consistency model. To illustrate the complications in writing a protocol, \ncon\u00ad sider the home-side state machine of the Stache protocol (Figure 2). Conceptually, the protocol \nrequires only three states: Idle, ReadShared, and Exclusive (a non-home pro\u00adcessor currently has the \nsingle valid copy.) Although transi\u00adtions appear as atomic, state changes in response to protocol events \ncannot be atomic. Consider the transition from Exclusive to ReadShared, which responds to a read request \nby a processor. This transition can complete only when the block s previous owner relinquishes it. Conceptually, \nthe action for this transition sends an invalidation message and awaits the block s new value (Figure \n3a). However, to avoid deadlock in a real system, protocol handlers must run to completion and terminate. \nHandlers cannot wait on an asyn\u00adchronous event, such as a message arrival. Only the automa\u00adton can wait \nfor a protocol event to cause a transition. Hence, after sending the invalidate message, the ReadRequest \nhandler changes to an intermediate state (Excl-To-ReadShared) and terminates. When the PutRe\u00adsponse subsequently \narrives, the transition completes by changing to state ReadShared (Figure 3b). Other states also require \nintermediate states for their transitions. Figure 4 shows the new, more complex state machine which is \nstill a simplification of the actual protocol. Intermediate states complicate programming because they \nmake transitions non-atomic. While in an intermediate state, the protocol may receive messages other \nthan the expected reply message. For example, the state Excl-To- ReadShared waits for a PutResponse message. \nBefore that message arrives, the home node may also attempt to write the same block and send a WriteFault \nmessage. The proto\u00adcol programmer must consider these possibilities and pro\u00advide the Excl-To-ReadShared \nstate with a suitable action. One unattractive approach is to receive these messages and encode a block \ns history, including pending actions, in its state. For example, a block in state Excl-To-ReadShared \nreceives a WriteFault message and moves to another state Excl-To-ReadShared-Pending-WriteFault. When \nthe Read-Shared transition completes, the protocol processes the pending WriteFault. Because this approach \ngreatly expands the state space, protocols either encode this information in an auxiliary data structure, \nnegatively acknowledge (nack) unexpected messages, or queue unexpected messages for later processing. \nAll three approaches have disadvantages, An auxiliary data structure complicates programming, because \na programmer must remain aware that a block s state is split between two representations. Nacks can lead \nto deadlock, so they must be employed carefully. And, queu\u00ading requires additional memory. Teapot offers \nall three options, but advocates queuing unexpected messages. Message reordering in a network further \nadds to the complexity, because messages may arrive in an unexpected order. For example, a ReadRequest \nfrom a processor that already has a readable copy cannot be ignored or treated as an error. The processor \nmay have returned its copy with a PutNoData message and subsequently requested a readable copy with a \nReadRequest. If messages can pass each other, ,~-. - .. = .-- \u00ad . .... .. ... ,.. ? (3 GE &#38; . \nExciiis ive { Message ReadRequest (Node R) Send (Owner, Put Request) ; I AWAIT PutResponse; \\(a) ~ SendSharedCopy \n(R) ; ~ State : = ReadShared; I exit; 2 .., .,..-.... . ...... .... ... .. . ..-..,. .... .. .. ., ;State \nExclu-sive 3 Message ReadRequest (Node R) I I Send (Owner, PutRequest) ; sharer :. R; State : = Excl-To-ReadShared; \n~ 1 exit; (b) I State Excl-To-ReadShared Message PutResponse (Node R) SendSharedCopy (sharer) ; I State \n:. ReadShared; ~, exit; ... .. . . ... .-.. ....... . . .  Figure 3: The action in box(a) executes the \nexclusive to shared transition using synchronous (blocking) communication, which could deadlock on a \nreal system. The action in box (b) shows an approach to avoiding synchronous communication: it introduces \nan intermediate state, which waits for a reply message. Figure 4: State machine (home side) with intermediate \nstates necessary to avoid synchronous communication. ~eseemingly gratuitous ReadRequest must be retained \nan{ processed after the PutNoData message. Teapot, by default, queues such messages for processing at \na Iater time, Another important consideration is that a protocol can be difficult to modify, although \nthis is a desirable way of devel\u00adoping a custom protocol. Consider adding a Com-pare&#38;Swap primitive \nto the basic protocol, This primitive is a minor variation of a WriteRequest that also executes the compare \nand swap operation at a block s home node once the block becomes Idle. Tracking a pending Com-pare&#38;Swap \ncomplicates nearly every transition in a home node state machine. The state machine-based implementa\u00adtion \nneeds to test for this condition at 14 different places. 1  3 Continuations and Protocols This section \ndescribes our approach to writing handlers. In general, any mechanism that permits multiple execution \ncontexts to coexist can solve the problem of synchronous communication inside a handler without introducing \nexplicit intermediate states. Continuations, coroutines, and threads2 are three such mechanisms. Using \nthreads, a protocol event handler can be launched in a new thread, which yields control at a synchronous \ncom\u00admunication point. When the subsequent response message arrives, the thread is re-scheduled and runs \nto completion (or to a later synchronous communication point). Corou\u00adtines can be used in a similar way. \nContinuations can also support synchronous communi\u00adcation in the following way. Recall that a continuation \ncap\u00adtures the execution state of the current computation, and passes the encapsulated state as an object \nto another compu\u00ad 1. In C code, we used a flag in the protocol state associated with a block, which is \nbasically a doubling of existing states. Maintaining flags, how\u00adever, is more tractable from a programmer \ns point of view. 2. These are light-weight, self-scheduling threads that yield control to each other \n(through a scheduler), rather than true concurrent threads that can potentially execute on multiple CPUs. \n tation. The second computation can then resume the cap\u00ad tured computation, often passing along a value. \nConsider the example from the previous section. Figure 5 shows how to write the protocol transition with \ncontinuations. The Teapot Suspend statement in the ReadRequest handler is similar to a cal lCC. It passes \nthe current continuation (L, the first argument to Suspend) to the function that is its second argument. \nThe Teapot Resume statement is similar to a throw, except that it does not return a value.3 The Suspend \nstatement captures its environment (the program position, as well as local vari\u00adables) at the call point \nin its first argument, switches to the subroutine state specified by the second argument, and passes \nthe continuation. At this point, the handler yields control (to a dispatch loop), until an action in \nresponse to a message to the subroutine state causes the suspended han\u00addler to resume. Subroutine states \nare parameterized by a continuation (e.g., the Cent L parameter in Figure 5b), which is part of the environment \nof all handlers in the state. A subroutine state differs from a normal state in two ways: it is entered \nsynchronously by a Suspend command in another handler, and it can execute a Resume command to restore \nthe environment and transfer control to the program point captured by the continuation. Using these mechanisms, \na programmer need not split the code in a handler into atomically executable fragments when waiting for \na particular message. However, as dis\u00adcussed in Section 2, many protocol transitions are not sim\u00adply \na matter of awaiting a particular message unexpected messages may also arrive during the transition and \nneed action. These messages require an explicit intermediate state in which the programmer handles all \nmessages that may arrive while waiting for a particular event. An attractive benefit of continuations \nis that they allow reuse of such intermediate states between different transi\u00adtions bv movidin~ the notion \nof calls between states. A sub\u00ad .. ,@%K e ExcY il-<i v&#38;  --  -   -  -- : Message ReadRequest \n(Node R) Send (Owner, PutRequest ) ; Suspend (L, Await PutResponse{L} ) ; I SendSharedCopy (R) ; (a) \n~ 3 State :. ReadShared; exit; ... L  - .. . . . . ~a=wa=t~&#38;~po n~e(?~L~ --Message PutResponse \n(b); Resume (L) ; exit; i . .. .  .. .. . ..... .+,. - c Figure 5: Using continuations to avoid introducing \nnew states. State AwaitPutResponse is used as a subroutine state. 3. This is in keeping with the imperative \nnature of Teapot. Each block has a globat info ~ea &#38;ilable, w~ch cart be used to communicate vatues. \n routine state (such as Await Put Re8ponse) is oblivious to the state from which it was invoked and the \nstate to which it goes next, since the continuation contains this informat\u00adion. Thus, the state can be \na subroutine for all transitions that await and anticipate the same message(s) and perform the same actions \nin response to those messages. By contrast, a state machine requires each handler to have a distinct \nintermediate state to encode subsequent transitions. Subrou\u00adtine calls permit significant code reuse \nin real protocols, as the action codes effecting transitions between states are fre\u00adquently identical. \nFor example, in the Stache protocol, the four different handlers that wait for a PutResponse message \nshare a single subroutine state. More complex protocols (LCM in Section 6) presented even more code reuse \noppor\u00adtunities. In effect, continuations turn a finite-state automa\u00adton into a push-down automaton. Continuations \ncan nest: a subroutine called from a sus \u00adpenal can itself invoke another Suspend. A stackl of con\u00adtinuations \noffers a convenient mechanism to record incomplete tasks. In a state machine, waiting for a succes\u00adsion \nof messages requires new intermediate states. By con\u00adtrast, a function called from Suspend can itself \nsuspend for another message. This provides a useful abstraction for processing a series of messages M \n1 and M2 since the code in Awai.kMl can execute a Suspend ( AwaitM2 ). For example, in the Stanford DASH \ncoherence protocol [19], a home node returns a WriteResponse that requires the writer to wait for Invalidation-Acks \nfrom the current readers. With this mechanism, the handler processing the response can directly Suspend \nto wait for the next acknowledgment. This feature was used several times in the LCM protocol. Figure \n6 shows how continuations simplify adding a Com~are&#38;Swa~ mimitive to the Stache motocol. It con\u00ad \n... . : ~tate ReadShared I Message Compare-N-Swap (Node n, / Address a, Value old_val, I Value new_val \n) ~ ... Suspend (L, ReadShared-To-Idle {L} ) ; 1, If (*a .= old_val) Then ~ *a := new_val; Send(n, Compare-N-Swap-Success); \nElse Send(n, Compare-N-Swap-Failure) ; , Endif I exit; Figure 6: Adding Compare&#38;Swap to Stache protocol. \nThe ~ code in this figure shows the code for the ReadShared state. Similar ;hanges are required to Idle \nand Exclusive\\ states. 1. Thisisnotto imply that Resmesshould dynamically match thecome\u00adspending Suspends; \nhowever, all Suspends must eventually be Resumed (or otherwise deallocated) to prevent memory leaks, \nas there is no built-in garbage collection. tains code that handles a message to a home node for a block \nin ReadShared state. The handler first invalidates out\u00adstanding copies and then invokes the transition \nReadShared\u00adTo-Idle. Then, it performs the actual Compare&#38;Swap opera\u00adtion. Similar changes (not shown) \nare necessary in states Idle and Exclusive. If the Compare&#38;Swap message arrives in any other state, \nTeapot automatically queues it until the block enters a state that can process the message. The Tea\u00adpot \ncode, unlike a state machine, forces the transition to the Idle state by a subroutine-like mechanism, \nrather than encoding the pending Compare&#38;Swap operation in the state until it can be executed in \na transition into the Idle state. A state, subroutine or normal, waits for and processes a limited collection \nof messages. All other messages can be queued for delivery after a transition out of the state-or discarded \nor nack ed, as a programmer chooses. Teapot does not impose a general solution to the problem of unin\u00adtended \nmessages, because different protocols have different needs. However, Teapot provides general mechanisms \nthat permit a programmer to specify: which messages should be processed in a state, how to handle other \nmessages that arrive, and what to do with these unintended messages. In a subroutine state (such as Await \nPut Response in Figure 5) that waits for a reply message to complete a tran\u00adsition, a programmer typically \nspecifies a limited set of messages that should be processed immediately and defers the others (by enqueuing \nthem) until the transition com\u00adpletes. In order to convert a handler containing blocking calls into non-blocking \ncode, the Teapot compiler captures a han\u00addler s environment immediately before a Suspend (Section 5). \nTeapot continuations are not fully general: calls to Suspend can appear only in a handler s body and \nnot in an external procedure called from a handler. This reduces the state that must be captured to only \nthe local variables of the calling routine, and thus facilitates optimizations. In principle, we could \nhave achieved the same effect by providing a light-weight threads package to the program\u00admer. However, \ncontinuations are a higher-level language feature and lend themselves more readily to compiler opti\u00admization. \n 4 Teapot Language Teapot is best introduced by a code fragment from the Stache protocol (Figure 7 and \nFigure 8). Note that this is the complete, executable code for those states: no details are elided. This \ncode implements the protocol messages gov\u00aderning a block in ReadOnly state on a non-home processor. If \nthe processor attempts to write to the block, Tempest sends a protocol event WR_RO_FAULT. The action \nfor this event first sends an UPGRADE_REQ to the home node and then Suspends, calling the subroutine \nstate Cache_RO_To_RW. Later the code for State Stache.Cache_ReadOnly{ } Begin Message WR_RO_FAULT (id: \nID; Var info: INFO; home: NODE) Begin Send(home, UPGRADE_REQ, id); Suspend(L, Cache_RO_To_RW{L}); WakeUp(id) \n; End; Message PUT_NO_DATA_REQ (id:ID; Var info:INFO; home: NODE) Begin Send(home, PUT_NO_DATA_RESP, \nid) ; SetState(info, Cache_Inv{}); AccessChange(id, Blk_Invalidate); End; Message DEFAULT(id: ID; Var \ninfo: INFO; home: NODE) Begin Error( Invalid msg %s to Cache_RO , Msg_To_Str (MessageTag) ) ; End; End; \n~igure 7: Teapot example from the Stache protocol. ;ontinued in Figure 8. . . . .. .. . . Cache_RO_To_RW \nexecutes aResurae statement, whit. restarts the suspended handler, which in turn restarts (wakes up) \nthe original computation thread that faulted. State Cache_ReadOnlY (Figure 7) explicitly handles only \nthe WR_RO_FAULT and PUT_NO_DATA_REQ mes\u00adsages. All other messages pass to the DEFAULT code, which raises \nan error since other messages are erroneous in this state. Figure 8 shows the subroutine state Cache_RO_To_RW. \nThe home node responds to an UPGRADE_REQ with one oftwo messages, hence the state must be prepared to \nhandle both. In this state, the DEFAULT case enqueues all other message for later processing. The operation \nResume(C) takes a continuation and restarts the suspended handler (after restoring its environ\u00adment). \nNotice the continuation parameter (C) in this state s definition. This argument is bound to the continuation \npassed at the Suspend in the previous handler (State Cache_ReadOnly, Message WR_RO_FAULT, in Our case). \nIf a message handler in this state contained a Sus \u00adpenal operation, the variable C would also be saved \nand restored. In this way, Suspends nest dynamically, like callccinML or Scheme. In addition to continuation \nstatements, Teapot handler bodies can contain conventional imperative constructs: assignments, procedure \ncalls, conditionals and while loops. Handler bodies are typically short. :tate Stache.Cache_RO_To_RW{C \n:CONT} 3egin Message UPGRADE_ACK (id: ID; Var info: INFO; home: NODE ) Begin SetState(info, Cache_RW{}); \nAccessChange(id, Blk_Upgrade_RW); Resume(C) ; End: Message GET_RW_RESP (id: ID; Var info: INFO; home: \nNODE ) Begin RecvData(id, Blk_Upgrade_RW) ; SetState(info, Cache_RW{}); Resume(C) ; End; Message DEFAULT(id: \nID; Var info: INFO; home: NODE ) Begin Enqueue (MessageTag, id, info, home) ; End; ;nd; tigure8: Teapot \nexample continued from Figure7. -- ..,.. . Teapot supports basic integer and boolean types anc includes \na facility for declaring compound types and proto\u00adtypes of functions that manipulate values of those \ntypes. Datatypes must be abstract because the Teapot system derives C code and Mur@ code from the same \nprotocol specification. Mur@ s types are far more limited than C s [9]. Consider maintaining a list of \nprocessors in a data struc\u00adture that supports operations such as include-sharer, delete\u00adsharer, etc. \nA C implementation could keep a bit vector in a word and implement operations with efficient logical \nopera\u00adtions. Mur@, on the other hand, represents the same infor\u00admation as an array of BitType, where \nBitType is a enumerated type of two values. To support both targets, a Teapot program does not specify \nthe implementation ofa data structure. Instead, these programs declare abstract types, e.g., SharerList. \nAs a result, a Teapot specification is neithera complete Cprogram, nor aMur@ program. The programmer \nmust instantiate abstract data types bydefining concrete representations and functions. In addition, \nsome system-level issues, such as obtaining a proper dispatch function for both the C and the Murc@ code, \nare omitted from this paper since they are routine and reusable for dif\u00adferent protocols. Appendix A \npresents the Teapot grammar. 242 . . .. ... . . ... . -. ..  5 Compilation I ~~esbage ~fi~~E~( argl \n: T1; arg2 : T2 ) War Teapot code could be compiled to use light-weight 11,12: T3; i threads in which \nSuspends and Resumes would cause ~Begin saves and restores of thread contexts. Since we restricted stmtl \nour input language, the generality of threads is unnecessary. First, Suspends occur only at statement \nlevel (by contrast call/cc can occur anywhere in an expression). Second, a Suspend cannot appear in a \nfunction called from the main handler. Given these restrictions, a handler written with Suspends and \nResumes can be directly compiled into non-blocking event handlers, without multiple stacks. To illustrate \nthe process, we will apply source-level transformation to the handler in Figure 9. The compiler first \ntransforms the handler into two routines (Figure 10), the first of which includes code up to the Suspend \nand the second that includes the remaining code. A Resume state\u00adment simply extracts the function pointer \nfrom the continua\u00adtion record and calls the second function. This transformation works even if Suspend \nstatements occur within control structures (nested loops and conditionals). The first fragment runs through \nthe Suspend then exits the handler routine. The code for the second part starts after the Suspend. Well-structured \nprograms all Teapot pro\u00adgrams-can always be split this way. An optimization is to save and restore in \nthe continuation only values that are referenced after the Suspend. Often in a handler, no values are \nsaved and restored, so that a contin\u00aduation can be statically allocated and used by all handler invocations. \nFurthermore, the compiler detects if a constant continuation reaches a particular Resume site. If so, \nthe code from the handler can be in-lined at the Resume site. This optimization is similar to ~-contraction, \nas discussed by Appel [2], and has proved effective in our experiments . 6 Case Studies Previous sections \npresented several examples from the Stache protocol. We wrote the Stache protocol in Teapot (600 lines, \nwhich compiles to 1000 lines of C code) and compared its performance against the original, hand-writ\u00adten, \nstate ma~hine implementation (approximately 1000 Message HANDLER1 (argl: T1; arg2 : T2 ) ~ Var 11,12: \nT3; Begin stmtl stmt2 ) 3Suspend (L, NewState{L} ) ; stmt3 stmt4 End; i Figure 9: A sample handler, \nwith a suspend point. Thel :ompiled code is in Figure 10. 243 1 stmt2 L :. AllocContinuation ( ) ; (a) \nL. func Ptr :. HANDLERl_af ter_L; : Save argl, arg2, 11, 12 in L; Put L in environment; State := NewState; \nexit; Ind; . ,.-. ..... . . . -- . -... . . ....... ... . ... ... . , \u00ad ~ . .. , ..- Mes sage HANDLER?Ta~e~~~C~T~ \nargl: Tl; arg2: T2: I 11,12: T3; Begin (b): Restore argl, arg2, 11, 12 from L; ~ FreeContinuation ( \nL ) ; stmt3 stmt4 [ exit; knd; ,. .,.... ~ Figur; 10: Code generated for the handler i n Figure 9. \nL_ I lines of C). Table 1 contains performance evaluation of four benchmarks running under the Stache \nprotocol (on a 32 pro\u00adcessor CM-5 running Blizzard-E [24]). The second column reports the application \nrunning time (millions of cycles) for the hand-written C protocol. The next two columns report times \nfor unoptimized and optimized Teapot protocols. In the unoptimized results, the compiler performs live \nvariable analysis but not the constant continuation optimization. The optimized numbers show the times \nwhen the compiler per\u00adforms both live variable analysis and the constant continua\u00adtion optimization. \nThe next column reports the number of continuation and queue records allocated and freed on all nodes. \nThe last column reports the average time across nodes spent waiting for faults and message handlers in \nthe C state machine. This number is a measure of the communica\u00adtion overhead of a program. It, however, \nis not a true mea\u00adsure of the time spent in protocol processing, because running a handler while waiting \nfor an earlier fault adds no overhead. This number puts the performance overhead of Teapot in proper \nperspective. The optimized Stache protocol ran 5-10% slower than the C version. The constant continuation \noptimization, how\u00adever, effectively reduced the number of continuations and improved execution time of \nprograms that allocate a dispro\u00adportionate number of continuations on a few processors (because of memory \nreference patterns). We will shortly return to the issue of performance difference between the Teapot \nand state machine versions. We believe tliat most new protocols will be variants of existing ones. For \nexample, we implemented a variant of the Stache protocol that attempts to overlap the latency of acquiring \na writable copy of a cache block with future com\u00adputation by buffering writes until a synchronization \npoint. The modification to Stache code involved adding 4 new states, 4 new message types, and some support \nroutines. This protocol requires an application to have the synchroni\u00adzation needed by the weakly consistent \nmemory model [1]. Since we did not have a state machine-based implementa\u00adtion, we are unable to present \ncomparative performance data for this protocol. LCM is a far more complex protocol [18]. It exploits \ncontrolled inconsistency in phases of parallel programs and has been used as run-time support for languages \nthat require copy-in-copy-out semantics for parallel loops. When a pro\u00adgram enters an LCM phase, each \nprocessor can obtain a copy of a location that is not kept consistent. A node can access its copy without \naffecting another processor. At the end of the LCM phase, each node with a copy reconciles its modifications \nwith other nodes, so that the system returns to a consistent state. Figure 11 shows how Teapot facilitates \nhandling a complex network reodering problem that arises in the LCM protocol. The LCM protocol in Teapot \napproximately 2300 lines of C implementation of LCM protocol 2500 lines of C. Table 2 contains three \nbenchmarks running under optimizations, the LCM protocol (1500 lines) compiled to code. The state machine \nrequired approximately performance numbers for the LCM protocol. With performed comparably with the state \nmachine version in most cases tested. Table 1: Performance of Teapot system with Stache protocol. Execution \nTime Benchmark C State Machine gauss 1930 M appbt 1860 M shallow 1160M mp3d 2210 M  in cycles (% increase \nTeapot Unoptimized 2150 M (11.4%) 21 OOM(13%) 131 OM(13%) 2340 M (5.9%) over C code) Teapot Optimized \n2050 M (6.2%) 1990 M (7%) 1280 M (10%) 2320 M (5%) Table 2: Performance of Teapot system with LCM protocol. \nExecution Time in cycles (% increase over C code) Teapot Teapot Benchmark C State Machine Unoptimized \nOptimized adaptive 3301 M 3440 M (4,2%) 3376 M (2.3%) stencil 3717 M 4120M (10.8%) 3859 M (3.8%) unstruct \n1431 M 1710 M(19.4%) 1666 M (16.4%) 244 Because of Teapot, we were able to implement easily three variants \nof LCM: one that eagerly sends updates to consumers at the end of an LCM phase (LCM-Update), another \nthat manages multiple, distributed copies of some data as a performance optimization (LCM-MCC), and a \nver\u00adsion of LCM that incorporates both (LCM-Both) of these changes. Again, equivalent state machine versions \nof these protocols were not available for a performance comparison. We found it very difficult to isolate \nthe factors that would account for the performance difference between the Teapot and state machine protocols. \nIn particular, CM-5 processors have small (64Kb), unified, direct-mapped caches, which can exaggerate \nthe effect of small increases in code and local data. In addition, the SPARC register windows can penalize \nTeapot handlers since they add a level of indirect function call at all handlersl. To understand better \nthe performance differences, we used a detailed architectural simulator of a multiprocessor that implements \nthe Tempest interface. The simulated machine differs from the CM-5: it has larger (256Kb) data caches \nand unlimited register windows. Experiments with the Stache protocol showed that Teapot versions were \ncon\u00adsistently within 5% of the execution times of the state machine versions. Simulator statistics also \nshow that event counts and the times spent in the two versions are compara\u00ad ble. Teapot overheads account \nfor the remaining 1. hr the LCM benchmark that ence was reduced to within 6% register windows at one \ncall site. in message handler invocations difference. perforrued worst, the perforrrrance differ\u00adby avoiding \n(via hand-coding) the use of Allots in Opt/ AI1OCS in UnOpt Fault time 65.7K/551K 40% 19.9K / 1197K 36% \n0.3K / 1001 K 44 %0 443 K / 3249 K 72% Allots in Opt/ A11OCS in UnOpt Fault time 124 K/4410K 28% 3347 \nK / 7452 K 63% 62 K / 2572 K 38910 Cache(non-home)Side HomeSide [CacheWritable] [HomeExclusive] EnterLCM: \n\\ FlushCOPy: PUT.ACCUM [HomeAwaitBeginLCM]ReadFault: [CachelnvalidToRO] QET_RO_REQ Enqueuethe message \nk BEGIN_LCM M [HomeLCM] XPr cess hequeue [CacheReadOnly] Figure ll:ThLs figure shows a network reordering \nproblem side sends the home aBEGIN_LcM message indicating that aftertwo other messages. TheTeapotcode \nontherighthandles the qUeUinq Of GET_RO_REQ.  7 Verification Several techniques can verify the correctness \nof a proto\u00adcol by ensuring that it does not violate a set of invariants. Model checking by exhaustive \nstate-space exploration is a popular technique in hardware cache-coherence community. The Mur@ system, \nbuilt by Dill et al. at Stanford University, uses this technique. A Mur@ program specifies an initial \nstate, a set of rules, and a set of invariants. Rules fire only if their preconditions are satisfied. \nWhen a rule fires, an action code executes and the system s state changes. Mur@ uses a Pascal-like input \nlanguage to express conditions and actions. It selects the firing rule non-deterministically from the \nenabled rules, which permits simulation of asynchro\u00adnous events. Mur@ explores all possible interleavings \nof events ina breadth-first fashion (although it has options for different search strategies) and checks \nthat the invariants hold in every state. Should an assertion fail, Mur@ produces a trace of events leading \nto the erroneous state. In general, Mur@ requires a programmer to write a pro\u00adtocol twice, once in an \nexecutable form and once in Mur@ s specification language. Writing a MurcD specification requires significant \neffort. Our hand-coded specification of the Stache protocol was approximately 800 lines of Mur@ code. \nIn addition, verifying a specification-rather than an executable protocol-can hide errors arising from \nthe dif\u00adferences between the two. To solve this problem, Teapot automatically generates a Mur@ specification \nfrom a Teapot protocol. Since a single source produces both verification and executable code, the Mur@ \nspecification accurately captures the behavior of the State LCM. Home_Excl{} Message PUT_ACCUM( ...) \nEiegin ... Send (srcr PUT_ACCUM_ACK) ; Suspend (L,Home_Awai t_BEGIN_LCM{ L}); State := Home_LCM; ... \nEnd; ... State LCM.Home_Await_BEGIN_LCM{C :CONT} Message BEGIN_LCM( ...) Begin ... Resume(C) ; End; \n Message DEFAULT(. ..) Begin Enqueue(. . .) End;  occuringat several places inLCM. The cache (non-home) \nit is entering LCM phase. The message reaches the home thisscenarioby going toanAwaitBeginLCM state. \nNote executable code. In addition, Teapot saves the effort of writ\u00ading a separate specification. However, \na protocol writer must supply support routines that define data structures in Mur@ s input language and \nan event generation loop that generates a random sequence of events for which the proto\u00adcol must work \ncorectly. For example, in the Stache protocol, each node should process any stream of loads and stores \nto any shared addresses. For the Buffered-write protocol, each node must handle synchronization operations \nrandomly interleaved with the loads and stores. To further check the correctness of values in the shared \nmemory, a more stylized event generation loop is necessary, as the values will be con\u00adsistent only if \nloads and stores obey a discipline [1] with respect to synchronization operations. Event generation for \nStache and Buffered-write protocols required about 50 and 100 lines respectively of Mur@ code. LCM protocol \nevent generation is quite complicated it took about 400 lines of Mur@ code. One problem with model checking \nis limiting the size of the state space that must be explored. In general, we simu\u00adlated a minimal machine \nwith 2 processor nodes and 2 shared memory addresses. Also, our verifications did not test actual data \nvalues. We currently verify that a protocol does not deadlock and that it does not receive a message \nthat is not anticipated in a given state. Additional assertions can be verified as needed, but have not \nproven necessary. Our experience with Mur@ has been very good. It found errors in a reasonable amount \nof CPU time (typically within an hour on a 66 Mhz SparcStation with 150M memory). It even uncovered an \nunsuspected protocol bug in a heavily\u00adused implementation of the Stache protocol, which could occur under \na particular interleaving of messages in the net\u00adwork. Table 3 lists the verification times on a 66 MHz \nSpare with 150M of memory for each of the protocols we wrote. Table 3: Protocol verification times Time \nTaken 4900 seconds Buffered-2 nodes, 1 address 302 seconds Write 1 reordering max - LCM Simple I 2 nodes, \n1 address 11515 seconds I 1 reordering max LCM MCC I 2 nodes, 1 address 5804 seconds 8745 seconds + a. \nOut-of-order messages increase the number of states that Mtrr@ has to explore. We limited the amount \nof reodering in the simulated network, because unrestricted reordering (i.e., any number of later messages \nalong a channel can cross an earlier message) led to impractical simulation sizes. Mur@ proved even more \nvaluable for complex proto\u00adCOIS1,such as LCM. The original, hand-written LCM proto\u00adcol contained numerous \nbugs that consumed months of effort to fix, and that continually re-emerged as the protocol evolved. \nMur@ uncovered approximately 25 errors in the Teapot LCM specification.2 After verifying the Teapot code \nfor LCM, we ran the automatically generated C code on several applications with little effort. The remaining \nprob\u00adlem was an error in a support function that was not verified. Model checking technology will doubtlessly \nimprove and allow larger protocols and systems to be checked. Researchers are exploring techniques that \nexploit symmetry or domain-specific knowledge [22] to make systems less dependent on a brute-force exploration \nof a state space. Tea\u00adpot is poised to benefit from the progress in this area.  8 Related Work Distributed \nshared memory (DSM) systems are an active area of research since Li s first system [20]. Most systems \nfocus on a single general-purpose protocol that, hopefully, 1. Mur@ simulating LCM had hundreds of times \nas many configurations as when simulating Stache. 2, Wkh the limited memory available, we could only \nverify LCM with 2 processor nodes, 1 address, and maximum network reordering of one. Ver\u00adification of \neither 2 addresses or more network reordering dld not com\u00adplete, although Mur@ did not report new errors \nfor as long as it ran. is efficient for a wide range of programs. Munin [5] was the first DSM system \nto support a limited collection of proto\u00adcols intended for different sharing patterns. Recent systems \n[17, 23] take a different approach and expose the primitives necessaty to implement a coherence protocol. \nDistributed object systems [3, 6, 16] also provide primitives to support different object coherence protocols. \nTeapot is not tied to a particular system and could be used with any of them. Our work most closely resembles \nthe PCS system by Uehara et al. at the University of Tokyo [25]. They described a framework for writing \ncoherence protocols for distributed file system caches. Unlike Teapot, they use an interpreted language \n(implemented on Tcl !). Like Teapot, they write protocol handlers with blocking primitives and transform \nthe program into a message-passing style. Our work differs in several aspects. Teapot s continuation \nsemantic model is more general than PCS s, which is a mes\u00adsage-driven interpretation of a protocol specification. \nPCS s application domain is less sensitive to protocol code effi\u00adciency, so they do not explore optimization. \nFinally, we exploit verification technology by automatically generating an input specification for the \nMur@ verification system. Wallach et al. propose Optimistic Active Messages [26] that permit the use \nof blocking primitives inside handlers. They detect at runtime whether a handler involves a block\u00ading \nprimitive; and if so, they launch a separate thread in which to rerun the handler. Synchronous programming \nlanguages, such as ESTEREL [4], are useful for describing reactive systems and real-time applications. \nTeapot resembles ESTEREL in that it provides a specification of the control part of the pro\u00adtocol, leaving \ndata manipulation to separately written (often in C) support routines. Like ESTEREL, Teapot supports \nverification and can be translated to executable code. Teapot differs from ESTEREL in that its emphasis \nis on simplify\u00ading the task of programming complicated finite-state machines. Continuations can express \ncoroutines [13] and parallel\u00adism [12, 27]. However, few domain-specific languages exploit continuations, \nperhaps because of concerns about their implementation complexity and cost. Teapot demon\u00adstrates that \na restricted form of this feature can be imple\u00admented easily and efficiently, without losing its benefits. \nDraves et al. [10] used continuations to implement thread management and communication in an operating \nsystem. They found many benefits, including reducing the number of kernel stacks from one per thread \nto one per processor, and unifying implementations of diverse control transfer operations, such as exception \nhandling, preemptive schedul\u00ad ing, and user-level page faults. The networking community has developed \na number of approaches to validating protocols. Besides temporal logic, they also use model-checking \ntechniques based on state\u00adspace exploration [15, 21]. To the best of our knowledge, most of their programming \nmodels are based on state machines and do not use continuations. Wing et al. [28] present an eloquent \ncase for using model checking technology with complex software systems, such as a distributed file system \ncoherence protocols. We also use model checking technology, but our primary focus is on a language for \nwriting coherence protocols, and on deriving executable code as well as the verification system input \nfrom a single source. They write the input to the model checker separately from their code, which introduces \nthe possibility of errors. 9 Conclusion Many programming language features are developed and explored \nin general-purpose programming languages and rarely find their way into domain-specific languages. This \npaper provides a counter-example by showing how ideas such as continuations can flow back into a special-purpose \nlanguage that supports the process of writing and verifying memory-system coherence protocols. These \nprotocols are important to the programming languages community because they facilitate parallel programming \nand provide an efficient basis for implementing languages and compiler run-time systems. For more information \nabout Teapot, please visit the URL http:llwww.cs.wise .edul-wwtlteapot.  Acknowledgements Bob Zak of \nSun Microsystems pointed us towards auto\u00admatic verification. Anne Rogers and an anonymous reviewer provided \ndetailed comments that helped improve our presentation. Shubu Mukherjee and Steve Reinhardt generously \nassisted us with the simulator used in Section 6, References [1] Snrita V. Adve and Mark D. HW Weak \nOrdering -A New Detirri\u00adtion. hr Proceedingsof the 17thAnnual International Symposium on ComputerArchitecture,pages \n2-14, May 1990. [2] Andrew W. Appel. Compiling with Continuations. Cambridge University Press, 1992. \n[3] Henri E. Bal, Andrew S. Tanenbaum, and M. Frans Kaashoek. Or\u00adca A Language for DMributed Prograrnmbrg. \nACM SIGPLANNo\u00adtices,25(5):17 24,May 1990. [4] G emrd Berry and Georges Gonthier. The ESTEREL Synchronous \nProgramming Language: Design, Semantics, Implementation. Technical Report nn, Ecole Nationale Sup erierrre \ndes Mines de Paris, nd. [5] John B. Carter, John K. Bennett, and Winy Zwaenepoel. Imple\u00admentation and \nPerformance of Munin. In Proceedingsof the 13th ACM Symposiumon OperatingSystemPrinciples(SOSP),pages \n152 164, October 1991. [6] S. Chakrabarti, E. Deprit, E.-J. Im, A. Krishnaumrthy, C.-P. Wen, and K. Yelick. \nMultipol: A Distributed Data Structure Library. Technicat Report UCB/CSD-95-879, Computer Science Division \n(EECS), University of CaEfomia at Berkeley, July 1995. [7] Satish Chandra, James R. Lams, and Anne Rogers. \nWhere is Time Spent in Message-Passing and Shared-Memo~ Programs? In Pro\u00ad ceedingsof the Sixth International \nConferenceon Architectural Supportfor ProgrammingLanguagesandOperatingSystems(AS- P.LOSW), pages 61-75, \nOctober 1994. [8] Edmund M, Clarke, Oma Gramberg, and David E. Long. Model Checking and Abstraction. \nACM Transactionson Programming LanguagesandSystems,16(5):1512-1542,September 1994. [9] David L. Dill, \nAndreas J. Drcxler, Alan J. Hu, and C. Han Yang. Protocol Verification as a Hardware Design Aid. In 1992 \nIEEEIn\u00adternational Conference on Computer Design: VLSI in Computers and Processors, pages 522-525, 1992. \n[10] Richard P. Draves, Brian N. Bershad, Richard F. Rashid, and Randafl W. Dean. Using Continuations \nto Implement Thread Man\u00adagement and Communication in Operating Systems. In Proceed\u00adings of the 13th ACM \nSymposium on Operating System Principles (SOSP), pages 122-136, October 1991. [11] Babak Falsati, Alvin \nLebeck, Steven Reinhardt, Ionnnis Schoinas, Mark D. Hill, James Lams, Anne Rogers, and David Wood. Appli\u00adcation-Specific \nProtocols for User-Level Shared Memory. In Pro\u00adceedings of Supercomputing 94, pages 380-389, November \n1994. [12] Christopher T. Haynes and Daniel P. Friedman. Engines Build Process Abstractions. In Conference \nRecord of the 1984 ACM Symposium on LISP and Functional Programming, pages 18-24, August 1984. [13] Christopher \nT. Haynes, Daniel P. Friedman, and Mitchell Wand. Continuations and Coroutines. In Conference Record \nof the 1984 ACM Symposium on LISP and Functional Programming, pages 293-298, August 1984. [14] Mark D. \nHill, James R. Lams, and David A. Wood. Tempest: A Substrate for Portable Paraflel Programs. In COMPCON \n95, pag\u00ades 327 332, San Francisco, Cafifomia, March 1995. IEEE Com\u00adputer Society. [15] Gerard Holzmann. \nDesign and Validation of Computer Protocols. Prentice Hafl, 1991. [16] Kirk L. Johnson, M. Frank Kaashoek, \nand DeboraJr A. Wallach. CRL: High Performance All-Software Distributed Shared Memo\u00adry. hr Proceedings \nof the 15th ACM Symposium on Operating Sys\u00adtem Principles (SOSP), December 1995. [17] Jeffrey Knskin \net al. The Stanford FLASH Multiprocessor. In Pro\u00adceedings of the 21st Annual International Symposium \non Computer Architecture, pages 302 31 3, April 1994. [18] James R. Lams, Brad Richards, and Guhan Viswrmathan. \nLCM: Memory System Support for Parallel Language Implementation. In Proceedings of the Sixth International \nConference on Architec\u00adtural Support for Programming Lxznguages and Operating Systems (ASPLOS W), pages \n208-218, October 1994. [19] Daniel Lenoski, James Larrdon, Kourosh Ghnrachorloo, Wolf-Di\u00adetrich Weber, \nAnoop Gupta, John Hennessy, Mark Horowitz, and Monica Lnm. The Stanford DASH Multiprocessor. IEEE Comput\u00ader, \n25(3):63-79, March 1992. [20] Kai Li and Paul Hudak. Memory Coherence in Shared Virtual Memory Systems. \nACM Transactions on Computer Systems, 7(4):321-359, November 1989. [21] Chung-Shyan Liu. An Object-Based \nApproach to Protocol Soft\u00adware Implementation. In SIGCOMM 94, pages 307 3 16, London, England, August \n1994. [22] Fong Pong and Michel Dubois. A New Approach for the Verifica\u00adtion of Cache Coherence Protocols. \nIEEE Transactions on Parallel and Distributed Systems, 6(8):773 787, August 1995. [23] Steven K. Reinhardt, \nJames R. Lams, and David A, Wood. Tem\u00adpest and Typhoon: User-Level Shared Memory. In Proceedings of the \n21st Annual International Symposium on Computer Architec\u00adture, pages 325 337, April 1994. [24] Ioarmis \nSchoinas, Babak Fnfsnti, Alvin R. Lebeck, Steven K. Re\u00adinhardt, James R. Lams, and David A. Wood. Fine-grain \nAccess Control for Dktributed Shared Memory. In Proceedings of the Sixth International Conference on \nArchitectural Support for Pro\u00adgramming Languages and Operating Systems (ASPLOS VI), pages 297 307, October \n1994. [25] Keiraro Uehara, Hajime Miyazawa, Kouhei Yamamoto, Shlgeka\u00ad 247 zu Inohara, and Takasha Masuda. \nA Framework for Customizing Coherence Protocols of Distributed File Caches in Lucas File Sys\u00adtem. Technical \nReport 94-14, Department of Information Science, University of Tokyo, December 1994. [26] Deborah A. \nWallach, Wilson C. Hsieh, Kirk L. Johnson, M. Frans Kaashoek, and WNiam E. Weihl. Optimistic Active Messages; \nA Mechanisms for Scheduling Communication with Computation. In Fifih ACM SIGPLAN Symposium on Principles&#38; \nPractice of Par\u00adallel Programming (PPOPP), pages 217-226, August 1995. [27] Mitchell Wand. Continuation-Based \nMultiprocessing. In Confer\u00adence Record of the 1980 LISP Conference, pages 19-28, Stanford Univ., Palo \nAlto CA, August 1980. [28] Jeannette M. Wing and Mandana Vaziri-Farahani. Model Check\u00ading Software Systems: \nA Case Study. In Proceedings ACM SIG-SOFT Symposium On The Founalztions Of Software Engineering, October \n1995. Appendix A: Teapot grammar program: modules protocol states modules: [ module]* module: module \nid begin mod-decls end ; mod-decls: [ mod-decl ]+ mod-decl: type id ; sub-decl const id:id; sub-decl: \nf unct ion id ( sub-argsopt ) : id ; procedure id ( sub-argsopt ) ; protocol: protocol id begin prot-declsopt \nend ; prot-decls: [ prot-decl ]+ prot-decl: var id:id; const id := id ; state id ( state-argsopt ) trzmsientopt \n; inessage id : states: [ state]+ state:  state id . id ( state-argsopt ) be~h msgs end : state -args: \nstate-arg [ ; state-arg ]+ state-arg: vars : id msgs: [ msg ]+ msg: message id ( sub-argsopz ) block-declsoPt \nbegin stints end ; sub-args: sub-arg [ ; sub-q 1+ sub-arg: var vars : id vars : id block-decls: var [ \nvar-decl ]+ var-decl: vars :id; vars: id[ , id]* stints: &#38; stint ; stints stint: i. f ( expr ) then \nstints else stints endi f if ( expr ) then stints endi f while ( expr ) do stints end id (exprs ) id \n:= expr suspend ( id , stint ) resume ( id ) return expr return print ( exprs ) exprs: &#38; expr [ ; \nexpr ]* expr: expr sym-id app-expr app-expr app-expr: id (exprs ) id {exprs } atomic-expr atomic -expr: \nid const ( expr ) \n\t\t\t", "proc_id": "231379", "abstract": "Recent shared-memory parallel computer systems offer the exciting possibility of customizing memory coherence protocols to fit an application's semantics and sharing patterns. Custom protocols have been used to achieve message-passing performance---while retaining the convenient programming model of a global address space---and to implement high-level language constructs. Unfortunately, coherence protocols written in a conventional language such as C are difficult to write, debug, understand, or modify. This paper describes Teapot, a small, domain-specific language for writing coherence protocols. Teapot uses continuations to help reduce the complexity of writing protocols. Simple static analysis in the Teapot compiler eliminates much of the overhead of continuations and results in protocols that run nearly as fast as hand-written C code. A Teapot specification can be compiled both to an executable coherence protocol and to input for a model checking system, which permits the specification to be verified. We report our experiences coding and verifying several protocols written in Teapot, along with measurements of the overhead incurred by writing a protocol in a higher-level language.", "authors": [{"name": "Satish Chandra", "author_profile_id": "81100394237", "affiliation": "Computer Sciences Department, University of Wisconsin-Madison, 1210 West Dayton St., Madison, WI", "person_id": "PP39040833", "email_address": "", "orcid_id": ""}, {"name": "Brad Richards", "author_profile_id": "81100451948", "affiliation": "Computer Sciences Department, University of Wisconsin-Madison, 1210 West Dayton St., Madison, WI", "person_id": "PP14158792", "email_address": "", "orcid_id": ""}, {"name": "James R. Larus", "author_profile_id": "81100277326", "affiliation": "Computer Sciences Department, University of Wisconsin-Madison, 1210 West Dayton St., Madison, WI", "person_id": "P132790", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/231379.231430", "year": "1996", "article_id": "231430", "conference": "PLDI", "title": "Teapot: language support for writing memory coherence protocols", "url": "http://dl.acm.org/citation.cfm?id=231430"}