{"article_publication_date": "05-01-1996", "fulltext": "\n A New Framework for Exhaustive and Incremental Data Flow Analysis Using DJ Graphs Vugranam C. Sreedhar* \nGuang R. Gao Yong-fong Lee Hewlett-Packard Company McGill University Intel Corporation Cupertino, CA \n95014-9804 Montreal, PQ H2X 1W7 Santa Clara, CA 95052-8119 sreedha@cup .hp.com gao@cs.mcgill.ca yflee@gomez.sc.intel.com \nAbstract We present a new elimination-based framework for exhaustive and incremental data flow analysis \nusing the DJ graph representation of a program. Unlike the previous approaches to elimination-based incremental \ndata flow analysis, our approach can handle arbitrary non-structural and structural changes to program \nflowgraphs, in\u00adcluding those causing irreducibility. We show how our approach is related to (iterated) \ndominance frontiers, and exploit this relation\u00adship to establish the complexity of our exhaustive analysis \nand to aid the design of our incremental analysis. 1 Introduction Traditional elimination methods consist \nof three steps [15]: (1) re\u00adducing the flowgraph to a single node, (2) eliminating variables in the data \nflow equations by substitution, and (3) once the so\u00adlution to the single node is determined, propagating \nthe solution to other nodes to determine their respective solutions. Elimina\u00adtion methods for data flow \nanalysis have been studied by many authors [2, 3,7,24, 25]. An excellent survey can be found in [15]. \nIn this paper we present a new framework for both daustive and incremental data flow analysis based on \nelimination methods. At the heart of our framework is the DJ graph representation [1 8,20, 23]. A DJ \ngraph is just the dominator tree of a flowgraph augmented with join edges from the flowgraph (see Figure \n1). A flowgraph edge is a join edge (J edge) if it has no corresponding edge in the dominator tree. A \ndominator tree edge is called a D edge. Unlike the previous elimination methods that typically reduce \na fiowgraph to a single node, our approach only eliminates J edges from a DJ graph in a bottom-up fashion \non the dominator tree (which may be compressed in the process). It performs variable elimination either \neagerly or in a delayed manner. At the end of the bottom-up elimination phase, all the J edges are eliminated, \nand the data flow solution at every node, except for the root, is expressed only in terms of its parent \ns solution in the dominator tree, Once we determine the solution for the root node, we propagate this \ninformation on the dominator tree in a top-down fashion to compute the solution for every other node. \n-Thls WOI ICwas done When UIC author was at the School Of Computm acimffi, McGill University, Permission \nto make d~italhrd copy of part or all of tMs work for personal or classroom use is asnted without fee \nprovided that copies are not made or distributed for pro i t or commercial advantage, the copyright notice, \nthe title of the ubiiition and its date appear, and notice is given that copying is Ey permission of \nACM, Inc. To copy otherwise, to republish, to poet on servers, or to redistribute to lists, requires \nprior specific permission andior a fee. PLDI 96 5/96 PA, USA 01996 ACM 0-69791 -795-2/96/0005 ...$3.50 \nIncremental analyses have many applications in program de\u00advelopment environments (e.g., Matlab) and aggressive \noptimizing compilers, especially those performing interprocedurd optimiza\u00adtion. Unlike previous elimination-based \nincremental methods, our approach can handle arbitrary program changes, including struc\u00adtural changes \nthat cause irreducibility. A novel aspect of our frame\u00adwork is that we found a surprisingly simple relationship \nbetween (iterated) dominance frontiers and incremental data flow analysis. Since we use dominance frontiers \nin our incremental analysis, we also show how to incrementally compute the dominance frontier relation. \nAlthough it is not described in this paper, we can extend our framework to an interprocedural setting \nsimilar to that proposed by Burke [3]. The next section introduces some useful notation and defini\u00adtions. \nSection 3 describes our exhaustive analysis. Sections 4 to 7 discuss our incremental analysis in detail. \nFinally, Section 8 compares our approach with related work. 2 Background and Notation 2.1 Flowgraph Terminology \nA flowgraph is a directed graph G = (N, E, START), where N is the set of nodes, E is the set of flow \nedges, and START E N is the distinguished start node. A flowgraph does not need to be connected, that \nis, some nodes may not be reachable from the START node. We define the reachable subgrsph REACH (STmT) \nto be a subgraph of G such that all nodes in REAC H(START) are reachable from START, If S is a set, we \nuse ISl to represent the cardinality of S. In the reachable subgraph REACH (START), a node x domi\u00adnates \nanother node y, denoted as z dom y, if and only if all paths from START toy pass through z. If x dom \nu and x # g, x strictly dominates U, We write x stdom g to indicate that x strictly dom\u00adinates y. A node \nx is said to immediately dominute another node g, denoted as x = idonz(y), if x stdom y and there is \nno other node z such that z stdom z stdom ~. The dominance relation is reflexive and transitive, and \ncan be represented by a tree, called the dominator tree. For each node x in the dominator tree, we asso\u00adciate \nwith it a tevet rturn6er, dmtotcd a~ wJeue?, that ifi the dripth of the node from the mot of the tree. \nThe dominance frontier DF(a) of a node z is the set of all nodes y such that x dominates a predecessor \nof y but does not strictJy dominate g [6]. We can extend the definition of dominance frontier to a set \nS of nodes: DF(S) = u DF(X) %es 278 Level O Level 1 Level 2 Level 3 Level 4 (b)WGraph Level 5  (a)mw$rs@l \nFigure 1: A Flowgraph and its DJ graph We define iterated dominance frontier IDF(S) for a set S of nodes \nas the limit of the increasing sequence: IDFI(S) = DF(S), (1) ZDFi+l(S) = DF(S U ZDFi(S)) (2) Throughout \nthis paper, all flowgraph properties such as dom\u00adinance, dominance frontiers, etc., are defined only \nfor the reach\u00adable subgraph REACH (START). Therefore, whenever we use the phrase a flowgraph and its \ndominator tree we are referring to the reachable subgraph REAC H(START) and its dominator tree . This \nconvention applies to other properties as well (including data flow properties and DJ graphs). 2.2 Data \nFlow Analysis Data flow analysis is a process of estimating facts about a program statically. These facts, \nor data flow information, can be modeled by elements of a lattice L. Associated with each flowm anh node \nz is w. a flow function ~. that maps input information to output i33f03ma\u00adtion [9. 10. 121.1 ~t 1. ~ \n~ be the information at the entry of a node x, and let O. c C be the information at the exit of the node, \nThen the input-output relationship can be expressed as 0. = f=(L) We can rewrite this equation as follows \nfor forward union problems:2 0= = f=(I=) = P=IZ + G= (3) Forsome problems, it is mom convenient to associatetlow \nfrmctions with flow\u00adgraphedges instead of nod.,. 2Tbrougfrout tfda paper we will &#38;saumea forward \nunion problem to illustrate our approach. Forward inter =~tion problems have a dual formulation, and \nbackward pmhlemscanbe solved on Ore reverse flowgraph. where P=, G. c L, + is the union operation, and \njuxtaposition is the intersection operation? We can interpret the above equation as follows: The Output \nflow information at a node s exit is either (1) what is Generated within the node or (2) what arrives \nat its input and is Preserved through the node. We need another set of equations to relate the output \ninformation at a node v to the input information at x when an edge u + x exista. The input information \n1= is the merge of all the output information Ov of nodes yin PrecJf (x), which is the set of predecessors \nof z on the flowgraph; i.e., I.= (4) A ~ yCPredf (z) A is usually a union or intersection operation, \ndepending upon the data flow problem being solved. Combining Equation 3 and 4, we obtain the following \nequation, denoted I-I=, for each x c N. (5) Hx: 0==f.( ~ 0,) #~Prec3f(r) Hz: 0= = P.( ~ Ov)+ G. (6) ~GPredt \n($) Since there is one equation for each node, we have a total of INI equations. Notice that the first \nvariation (Equation 5) is more gen\u00aderal than the second (Equation 6), since for some data flow problems \nthe information generated within a node z is not independent of Z= [12, 10], We use the term output variable \nto name the variable O. that appears on the left-hand side (LHS) of equation H.. Any variable appearing \non the right-hand side (RHS) of the equation is called an input variable. Furthermore, P. and G. are \ncalled the parameters of the equation. Given any two equations H. and Hv, we say that H. depends on Hv \nif the output variable of Hu appears on the RHS of H., That is, we need the solution of Oti in order \nto compute the solution of 0=. Also, if H. depends on Hv, then there is an edge tim y to x in the corresponding \nflowgraph, We define the closure operation for recursive equations. If at any node y, the data flow equation \nis of the form Hv : Oy = mOv +k = ft/(%), (7) where m and k are terms that do not contain OY, then the \nclosure operation of this equation is Hv : Ov = f;(o,) (8) In other words, f; (Ou ) is a fixed point \nof the above recursive equation. Such a fixed point exista if the flow function associated with each \nnode is monotone and the lattice does not contain infinite descending chains [12]. For many of the classical \nproblems, such as Reaching Defi\u00adnitions and Available Expressions, f* can be computed quickly, essentially \nin constant time [12]. Ryder and Paull call such closure operations the loop-breaking rules [15]. Throughout \nour discussion, we assume a monotone data flow framework in which all flow functions are monotone [1 \n2]. 3 Exhaustive Elimination Methods To solve a system of data flow equations, we propose two methods \nin our exhaustive analysis: eager elimination and delayed elimination. 3hr general, G. may not be a constant \n[10, 12]. It can also depend on 1=. That ia, the information that is generated at a node depends on (1) \nfbe local data flow information at the node and (2) tbe inpnt data flow information to the node. >, Em \nQ \\ , z . . x J:? Y Figure 2: Graph reduction due to the E-rules Both methods consist of two phases: \n(1) bottom-up DJ graph re\u00adduction and variable elimination, called the elimination phase; and (2) top-down \npropagation of data flow solutions, called the props. gation phase. It is assumed that the initial data \nflow equations are properly set up according to the originalflowgraph[15, 16], 3.1 Eager Elimination \nMethod Our eager elimination method uses the El and E2 rules, together called the &#38;-rules, to reduce \na DJ graph in a bottom-up fashion. Figure 2 gives a graphical illustration of these rules. The &#38;-rules \nare always applied to a J edge g -+ z such that y is a non-join node, and there is no J edge with its \nsource node at a level greater than y.level in the xeduced DJ graph. In this paper we adopt the following \nrelaxed definition of non-join nodes: A node v is a non. join node if and only if Pred(y) contains no \nnodes other than y and idorn(g).4 We use go to represent the original (zerotb) DJ graph. Each application \nof the &#38;-rules transforms some reduced DJ graph ~i to Q + 1 until the resulting DJ graph degenerates \ninto its dominator tree. The El rule eliminates a self-loop, and computes the closure of a recursive \nequation, Definition 3.1 (El rule) Let ~ = (N, E) be the ith reduced DJ graph. Let y be a non-join node \nsuch that the self-loop y ~ g exists. Let OY = fy (Ov ) be the$ow equation Hv at node y. Then (i) Graph \nreduction: 131(< G , IV, E, y $ y >) a<g + , fv, E-{y4 y}>  (ii) Variable elimination: El (< Ov = \n~U(OV) >)  * < Ov = f;(ov) > 4That is, a self-loop y -t g does not prevent y from being a non-join node. \nMainDFA() ~ : Initialize Priori tyList 2: for i = NumLevel -1 downto 1 do 3: ReduceLevel(i); 4: if(PriorityList \n[a] is not empty) then 5: CollapseIrreducible(i); 6: endif 7: endfor 8: DomTDPropagateo; } Procedure \nReduceLevel(i) ; : while((y = GetNode(i)) # NULL) do 10 foreach outgoing J edge y + z do 11: if(z == \ny) then /* self-loop / 12: Eagerl (y ~ y) ; 13: else 14: if(y.leuel == .z.leuel) then 15: Eager2a(y + \nz) ; 16: else 17: Eager2b(y -+ z); 18: endif 19: endif end for E endwhile } Figure 3: Algorithm outline \nfor our framework An E2 rule is applied to a J edge y + z only if y is a non-join node and y + y does \nnot exist. Recall that y.letrel ~ z.level for any J edge ~ + z, We distinguish between two types of E2 \nrules depending on the levels of y and z. If y.level = z~level, we apply E2a; otherwise we apply E2b. \nDefinition 3.2 (E2 rules) Let L7 = (N, E) be the ith reducedDJ graph. Let y be a non-join node such that \ny ~ y does not exist. Let y ~ z be aJedge, and let x = idom(y). Let Ov = kO= + m be the equation HY at \nnode y, such that the parameters k and m do not contain any variables. Finally, let O. = a09 + b be the \nequation H= at node z, where a and b do not contain the variable Ou. There are two cases: (E2a rule) \nIfy.level = z.ievel, then (i) Graph reduction: E2a(< ~ , N, E, y ~ z >) *<@+ , N, E-{y3 z}>  (ii) \nVariable elimination: E2a( < O= = aOv + b >)  =< O~=a(kOs+m)+b> (E2b rule) ffy.level # z.levei, then \n (i) Graph reduction: E2b(< f?, N, E, y ~ z >) a<&#38;+l, N,(E-{y~z})u{c~ 2}>5  (ii) Variable elimination: \nE2a(< 0, = aOV + b >)  ~<O. =a(kO=+m)+b> The newly inserted edge idom(y) + z in E2b is called a derived \nedge of y + z, which is removed. An important point to We do not insert z + z in G + i if it is already \npresent in L2 . rithm is expected to behave linearly in practice. Procedure Eagerl(y + y) { 22: Compute \nthe closure Hti : Oy = fJ(Ov). 23: Delete the edge y ~ v; } Procedure Eager2a(y + z) { 24: Eliminate \n09 in Hz by replacing it with the RHS of Hv. 25: Delete the edge v ~ z ; 26: if(z becomes a non-join \nnode) then 27: Putzat the head of PriorityList[z.leveJ] list; 28: endif } Procedure Eager2b(~ + z) { \n29: Eliminate OV in Hz by replacing it with the RHS of Hy, 30 z= idovn(y) ; 31: Delete the edge y ~ z \n; 32: if(z + z does not exist) then 33: Insert anew Jedge z ~ z ; 34: endif . J Figure 4: Procedures \nfor E-rules note is that before an E2 rule is applied to an edge g + z, we first eliminate the self-loop \ny + V, if it exists, by E-l. The difference between E2a and E2b is minor, but this distinction is useful \nwhen we discuss delayed elimination and when we handle irreducibility. The algorithm outline for eager \nelimination is given in Fig\u00ad ure 3. NumLevel is the total number of levels in the DJ graph. PriorityList[i] \nmaintains an orde~d list of nodes at level i to be processed by procedure ReduceLevel(i), such that non-join \nnodes always appear earlier than join nodes. We first initialize PriorityList to contain all the nodes \nin the DJ graph. MainDFA() calls ReduceLevelo in a bottom-up fashion. When ReduceLevel(i) terminates, \nPriori tyList[i] will be empty if the flowgraph is reducible. For an irreducible flowgraph, procedure \nCollapseIrreducible(i) is invoked to handle irreducible regions at level i; details are given in Section \n3.3. At the end of the elimina\u00adtion phase, the data flow solution at every node (except for the root) \ndepends only on the solution of its immediate dominator. At this poitt~ MainDFA() calls procedme DomTDPropagateo \nto propa\u00adgate solutions down the dominator tree and finishes the entire data flow solution process. Procedure \nReduceLevel(i) eliminates J edges whose soume nodes arc at level i (for a reducible flowgraph) by applying \nthe S\u00adrules. We ensure that if the self-loop edge ~ + y exists, it will be the first outgoing edge from \nnode y. Consequently, when an E2 rule is applied to an outgoing J edge from y, there will be no self-loop \nat y. Procedure GetNode(i) returns a non-join node at level i whenever one exists. Otherwise, it returns \nNULL under two cir\u00adcumstances: (1) PriorityList[i] is empty, and(2) PriorityList[i] is not empty but \nall its remaining nodes arc join nodes. The second case indicates the existence of irreducibility. Procedures \nEagerlo, Eager2ao, and Eager2bo imple\u00adment the El, E2a, and E2b rules, respectively, and their associated \nvariable eliminations (see Flgurc 4). Although the worst-case time complexity of eager elimination is \n0( IEI x IIVl ), we will demonstrate in Section 3.4 that the algo- Example: Consider the example flowgraph \nin Figtnv 1. Flgurc 5 gives a trace of the graph teduction process. Assume a forwaxd data flow problem \nwith union as the meet operation, Table 1 gives a partial trace of the variable elimination corresponding \nto the graph reduction shown in Figure 5. I I Rule I V+Z I g t I g + t II O;+ 111 E2b 17+91(a) I (b) \nII @o 4+ P908+P98 06 + I fiG7 I-G9 2 E2b 4+9 (b) (c) P9J?403 + P9G4+ p@s + p9fi06 + P9G7 + G9 3 E2a 4+6 \n(c) (d) p?jp@3 + P6G4 + ? 605 + G6 4 E2a 5+6 (d) (e) (P6P4+P6P5)03+P6 G4+ P6G5+ G6 - 5 E2b 6+9 (e) (f) \n(P9P4 + P9J3P 6p4 + p9fip6p5)03 + P90s + P9G4 -t p9fip6G4 + p9fip6G5 + P9J3G6 -I-J3G7 + G9 t Corresponding \nDJ graphs in Figure 5 Table 1: Partial trace of variable elimination  3.2 Delayed Elimination Method \nTo improve the worst-case quadratic behavior of eager elimination, we propose the delayed elimination \nmethod, whose worst-case time complexity is 0( I,?31x log( INI )). The key intuition behind our de\u00adlayed \nelimination method is based on the following observation. Consider the J edge 7 + 9 in Figure 5(a). The \neffect of our eager elimination triggered by this edge is as follows: 1. E2b derives 6 + 9 from 7 + 9 \n(Hgttre 5(b)). 2. E2b derives 3 + 9 from 6 + 9 (Figure 5(g)). 3. E2a removes 3 + 9 (Figure 5(h)), \n Rather than moving the source nodes of derived edges one level up at a time, we can directly generate \njust one derived edge such that its source and destination nodes ate at the same level. We can do so \nif we know exactly which node is that source node. For each J edge y + z, its top node is x = Top9~Z \nsuch that z dominates y and x.levei = z.level. For example, node 3 is the top node for the J edge 7 + \n9. In a pre-processing step we can easily compute the top nodes of all J edges in linear time [18,21]. \nAn interesting point to note is that the destination node 9 of edges 7 + 9,6 + 9, and 3 -+ 9 is in the \ndominance frontiers of the source nodes 7, 6, and 3. Thus, we use the term dominance frontier interval \npath of the J edge 7 + 9 to mean the dominator tree path from node 3 to 7. Note that the first node (i.e. \nnode 3) on the path is the top node of the Jedge7+9, Now we can define the D2b rule: D2b(<@, N, E,y4z, \nx>) *  <g +l, N,(E-{y4z})u{z4 z}, where idorn(y) # idom(z), and x = Topv~z. Unlike in eager elimination, \nno variable elimination is performed by the D2b tulcq it is intentionally delayed. For DJ graph reduction, \nwe carry over the definition of the El and E2a rides to our delayed elimination method, and Gall them \nthe DI and D2a rules, respectively. But the associated variable elimination performed during D 1 and \nD2a is different from that of their counterpart rules El and E2x in DI and D2a we also  , 7 7  b15~tl \n62 Figure 5: DJ graph reduction with eager elimination (e.g., fmm a to b, we apply the E2b rule to J \nedge 7 + 9) o Procedure CollapseIrreducible(i) 1 2 3 4 5 6 7 8 b u (b)(a) Figure 6: An irreducible flowgraph \nand its DJ Graph eliminate variables that were delayed by D2b. We will call the D1, D2a, and D2b rules \ncollectively the D-rules. The algorithm outline given in Figure 3 for eager elimination can be used for \nde\u00ad layed elimination, by replacing the calls to Eager lo, Eager2ao, and Eager2bo in procedure ReduceLevel(i) \nby the crdls to Delayed lo, Delayed2ao, and Delayed2bo (which imple\u00ad ment the V-rules), respectively.The \nprocedures for implementing the D-rules are given in [21]. To eliminate variables delayed by D2b, we \nperform path com\u00ad pression akin to Tarjan s simple path compression during D1 and D2a rules (for details \nplease see [18, 21]). But unlike Tarjan s method, which dynamically creates path compression trees, we \nperform path compression on a static dominator tree.b 3.3 Handling Irreducibility In this section, we \ndescribe our strate$y for handling irreducibility in flowgraphs using eager elimination. One classical \ndefinition for irreducibility is as follows [1, 8]: A flowgraph is irreducible if and ordy if we cannot \npartition the edges into forward edges and back edges such that the destination node of every back edge \ndominates the source node. Figure 6 shows an irreducible flowgraph and its DJ graph. In our elimination \nmethods we detect irreducibility if during the bottom-up reduction, GetNode(i) returns NULL but there \nare still J edges to be processed at this level. At step , if PriorityList[i] is not empty, then there \nare still nodes to be pro\u00adcessed at this level, but none are non-join nodes. This condition is sufficient \nto signal irreducibility, and we invoke the procedure CollapseIrreducible(i) to handle irreducibility \nat level i. The description of CollapseIrreducible(i) under eager elimination is given in Figure 7. We \nfirst apply Tarjan s Strongly Connected Component (SCC) algorithm on nodes at level i (step ~. It is \nimportant to ensure that during Tarjan s algorithm, we never visit any node whose level is not i. This \ngenerates dag(s) of SCCS. Notice that there can be more than one disjoint dag at a leveI. For every dag, \nwe process each SCC .S in the dag in topological order (step 36 . We compute the closure of the equations \nfor all nodes in R 1 S is nontrivial 0 6By static we mean the nodes on the tree stay the same, even \nthough them are changes to the edges. 7We can similarly handle irreducibility in delayed elimination. \n{ /* s~~ ~1~~ the d~~cripti~n in the main t~~t */ 35: Deteonine the SCCS for the nodes at level i, and \nconstruct dag(s) of SCCS; 36: Process each SCC S in each dag in topological order as follows: 37: If \nS contains a cycle then compute the closure for the equations of all the nodes in the cycle. Also express \nthe RHS of the equation at each node in terms of its immediate dominator s flow variable. 38: Ifanodes \nEShasanedges + tto node t @ S then replace 0. on the RHS of equation Ht by the RHS of H,, which is expressed \nas a function of O,~OmIgJ. /* After all the SCCS are processed, / I* the equation of every node at level \ni / / is expressed as a function of its *I / immediate dominator s flow variable. */ 39: Remove all J \nedges whose source and destination are at level i. 40: Apply the E2b rule to every J edge whose source \nis at level i but whose destination is at level less than i. } Figure 7: Algorithm for handling irreducibility \nwith eager elim\u00ad ination (step ~. We also express the equation at every node at level i in terms of \nits immediate dominator s flow variable (step @). This is uossible r because we arc eliminating the flow \nvariables m SCCS topological order. Finally, we elimina~ all the J edges lying at level i (step 39 . \nFigure 8 gives a trace of the DJ graph reduction using the S-ru P es for the DJ graph shown in Figure \n6. 3.4 Complexity and Empirical Observation Although both eager and delayed elimination are theoretically \nworse than linear, they can behave as if they were linear in practice. To establish this statement, we \nfirst state two claims to relate our elimination methods to dominance frontiers, Claim 3.1 The number \nof E-rules applied during the entire elimi\u00adnation phase is bounded by the total size of dominance frontiers \nof the flowgraph. Claim 3.2 In delayed elimination, the total length of the paths compressed during the \nD1 and D2a rules is bounded by the total size of the dominance frontier relation. In [6], Cytron et al, \nhave shown that, in practice, the size of the dominance frontier relation is linear in the size of its \nflowgraph. Therefore, the time complexity of our elimination methods is ex\u00adpected to be linear in practice. \nWe have also implemented our exhaustive methods, and our preliminary empirical results support our statement \nabove. We used as test data a set of 40 FORTRAN procedures taken from SPEC92, RiCEPS, LAPACK, and GA~R. \nWe performed our experiments on a SPARC-20 workstation. Below we briefly summarize our observations (more \ndetails can be found in [18, 21]): We found that the number of &#38;-rules applied is bounded by the \nsize of the dominance frontier relation. The average \\ \\ h 5 6 6  I&#38;l8 8 Irreducib e Oetected @ \n(h) o ,.. ,, II I 88 8 66 6 Figure 8: A trace of DJ graph reduction for the example irreducible flowgraph \nnumber of t?-rules applied is about 0.76 times the average ~gions to be 25 for coef, 33 for colmr, 78 \nfor card, and 28 size of the dominance frontier relation, We also found that the for dcdcmp.8 In [3], \nBurke proposes a method that is similar number of D-rules applied is about 0.52 times the number to Schwartz \nand Sharir s method, except that the single entry re\u00adof flowgraph edges. gion need not be strongly connected. \nAlthough Burke s method is an improvement, it still identifies a much larger region than our We also \ncompared the performance of the eager and delayed method does, We manually applied Burke s method for \nthe pro\u00adelimination methods. We first computed the average ratio of cedure comlr, and found the size \nof the single entry region that the total length of the dominance frontier interval path without encloses \nthe irreducible region tobe31. path compression to the total length of the domimmcefrontier interval \npath with path compression. We found this ratio to 4 Incremental Data Flow Analysis: Problem Formulation \nbe 1.28. This ratio indicates that all the dominancefiontier l.zs lm = 21.8% of their edges interval \npaths have about 1.2s In the next several sections we present our incremental data flow overlapped. \nThe value of this ratio also suggests that, in an analysis. This section lays the foundation of our incremental \ndata ideal situation, the delayed elimination method can be about flow analysis by introducing the concept \nof initial and final flow 1.28 times faster than eager elimination. equations, and the representation \ncalled the DF graph, that are A very important aspect of our ~pproach i~ the handling fundamental to \nour approach, Section 5 shows how to update the final flow equations for non-structural changes, and \nSection 6 shows of imeducibility. We found the large;~ SCC to contain onl~ how to handle structural changes. \nHere we also give an algorithm four nodes when Tarjan s SCC algorithm is applied during for updating \nthe dominance frontier relation. Section 7 describes CollapseIrreducibleo (found in procedure coef ). \nThis sug\u00adhow to update the final data flow solutions for both structural andgests that our approach is \nindeed very efficient, in practice, for non-structural changes. handling irreducible loops. Previous \napproaches usually perform fixed-point iteration over a much larger region when an irreducible 8These \nnumbers were generated by using tfre Spin-secompiler developed at Oregon region is encountered [3, 17], \nOne classical approach, proposed by Gr8duate Institute of Science nnd Technology. We thnnk Priyadarshtm \nKoRe for Schwartz and Sharir, to handling irreducible regions is to perform providing tfrese rmdts. iteration \nover the smallest single entry strongly connected region that encloses an irreducible region [17]. Using \nthis method, we found the sizes of the single entry regions enclosing the irreducible 4.1 initial and \nFinal Flow Equations In our exhaustive eager elimination method, we showed how to express the RHS of \na node s flow equation only in terms of its immediate dominator s flow variable by DJ graph reduction \nand variable elimination. We use the term final flow equations to name the set of equations at the end \nof the elimination phase. In contrast, we use the term initial flow equations for the set of flow equations \nprior to graph reduction and variable elimination. III 1 / . ~, 0 ! s. \\,/ \\ Example: Consider a forward \ndata flow problem with union as the merge operation (e.g., Reaching Definitions). The initird flow equa\u00adtions \nfor the example flowgraph in Figure 6 are (the superscripts O and F are used to indicate initial andfinal, \nrespectively): H; : 00=@ q: 01 = P;oo+@ H: : Oz = P;OI+G; H; : 03 = P$(ol +08)+@ H: : 04 = Pf(02 +03+07) \n+G H; : 05 = P~04+ G; H&#38; : 04 = p;04 +G: H; : 07 = P:(O5 +06)+~ H; ; 08 = P:07+@ The corresponding \nfinal flow equations are given below. Equa\u00adtions H3~ and H4F are mutually recursive. Once their closure \nis determined, their final flow equations will be expressed only in terms of variable O] on the RHS. \n 4.2 Basic Steps To simplify the presentation, we consider only two types of incre\u00admental changes. One \ncan easily extend and implement other types of changes using our results. 1. Non-structural change: The \nparameters ~ and @v of the initial flow equation Hi at a node y are modified. 2. Structural change: \nA flowgraph edge x + y is either inserted or deleted in the flowgraph.  23 4 ~ i \\ 1 i \\, 7 65 8 w \n (a) Flowgraph (b) DF graph Figure 9: A flowgraph and its DF graph It is important to remember that \nall inc~mental algorithms rely on having conect solutions at all nodes prior to incremental changes. \nOnce a change occurs, incremental algorithms will update (ideally) only those solutions that are affected \ndue to the change [1 O, 11]. It is also important to remember that we maintain (and hence update) data \nflow solutions only for nodes in REACH(START). Let a~ denote the data flow solution at each node v prior \nto an incremental change. That is, cr~ is the that flow solution at y before the change. Our approach \nannotates each node v with (1) the initial flow equation @ (2) the final flow equation H;, and (3) the \nfinal flow solution a~. Whenever an incremental change is introduced, our approach updates all three \npieces of information. Updating the initial flow equations is straightforward. Our further discussion \nfocuses on the strategy to update the final flow equations and the final flow solutions. To effectively \nhandle incremental updates, we use a represen\u00adtation crdled the Dominance Frontier (DF) graph. A DF graph \nis just the dominator tree of a flowgrsph augmented with edges x + tJ such that y c DF(z).9 We use DF \ngraphs for updating the final flow equations. Figure 9 gives the DF graph for our example flowgraph. \n5 Updating Final Data Flow Equations: Non-Structural Changes 5.1 Basic Approach In this section, we show \nhow to update the final data flow equations in response to a non-structural change in the flowgraph. \nGiven an incremental change at a node ~, the first step is to determine the set of nodes whose final \nflow equations are affected, To determine the set of affected nodes we made one key observation. Consider \nthe final flow equation of node 7 of the example flowgraph shown in Figure 6. H: : 07 = (P:P: + P;P:)04 \n+P;@ +P%$ +G = P7F04 + G[ % implementation, there is no need to construct a separateconsttuctionof the \nDF grsph.Toachieve what is needed in our approach, one can augment the DJ graph with additional edges. \nWe notice that the final parameters P7F and G; on the RHS of the equation contain the initial parameters \nP:, @ P:, and dc from nodes 5 and 6. It is important to remember that the parameters of both the initial \nflow equation and the final flow equation at a node are constant values. We use the term appear to mean \nthat the parameters of the final flow equations are computed from the parameters of the initial flow \nequations during the reduction and variable elimination phase of our eager elimination method. Given \nthis notion, the key question is this: How are the parameters of the final flow equations related to \nthose of the Mltiai flow equations? We found a surprisingly simple relationship between them. Claim 5.1 \nLet P: and G: be the parameters o the jinal jlow i equations at node w. ~ and @U will appear in PW and \nG; if and only if either w = u or w c IDF(u). IDF(u) represents the iterated dominance frontier of u. \nThe above claim has an important implication in our incremental al\u00adgorithm. Suppose we make a non-structural \nchange at a node y, thereby affecting P; and @y. From Claim 5.1 we may have to update the final flow \nequation at all nodes in lDF(Y). Since we are changing P: and @Y, the final flow equation H: at node \ng should be updated. Let FEqAffected (y) be the set of all nodes whose final flow equations potentially \nchange due to a non-structural change at w that is, FEqAffected (y) is the set of possibly affected nodes. \nBy possibly affected we mean that if the final flow equation at a node w changes it will be in FEqAffected \n(y) (see also Section 5.2). To discover the set of possibily affected nodes, we use the following key \nresulti Claim 5.2 Let a non-structural change be introduced at node y. Then the$nalflow equation at a \nnode w is possibly affected (i.e., w is in FEqAffected(g)) if and only ~ w E {y} U IDF(y). Thus the first \nstep in updating the final flow equations is to compute the set IllF (y). Computing lDF(y) is much simpler \nusing DF graphs than DJ graphs. We can easily show that a node w is in IDF( y) if and only if there exists \na path from y to w in the DF graph such that the path contains no D edges. Therefore, to compute IDF(y) \nwe find all the nodes reachable from y without visiting any D edges. After we compute IllF(y), we construct \na Projection Graph Proj(y) of the DFgraph with respect to the nodesin {g}uII)F (y). The projection graph \nProj(y) contains nodes in {Y} U IDF (Y), and we insert an edgep + q in Proj(y) if and only if q c llF(p). \n2Scc 3 34 75 @7 5 (a) (b) Figure 10: The projection graph Proj(5) and its dag Given the projection graph, \nwe next show how to update the final flow equations of the possibly affected nodes. Notice that a node \nw is possibly affected (because of a non-structural change at node Y) if and only if w is in proj(y). \nFurthermore, Proj(u) need not be acyclic, So the first step is to apply Tarjan s Strongly Connected Component \n(SCC) algorithm and to provide a topological ordering over the dag of SCCS. Figure 10 shows Proj(5) and \nita dag for our example DF graph. As for variable elimination, if an SCC contains a cycle, we compute \nthe closure of the equations for all nodes in the SCC (as in the exhaustive case). We can easily show \nthat if an SCC contains more than one node, all these nodes will be at the same level in the DF graph \n[18, 22]. We visit each SCC of the projection ~aph in topological order. When processing an SCC S, we \nhave three cases to conside~ Case 1: S is a single node and has no self-loop. Let Predf (S) be S s predecessors \nin the corresponding flowgraph. As\u00adsume that the final flow equation at every predecessor p E Predf (S) \nis correct (either previously updated or unaffected by the incremental change). To update the final flow \nequation H: at node S, we start with ita initial flow equation. That is, we first construct the following \nequation at node S: HS : 0,9= Pg( A Ot) +@ (9) tGPredf(S) Starting with this equation, we eliminate variables \nfrom it in a bottom-up fashion, as in our exhaustive eager elimination, until the only variable on the \nRHS of HS is O,dOm(s,, At the end of the elimination process, the equation at node S wfll be in its final \nform. Notice that the above (incremental) update can be seen as a selective exhaustive eager elimination \nprocess and is restricted to the equation at node S. Case 2: S is a single node and has a self.loop. \nHere, we assume that the final flow equation at every predecessor of node S, excluding S itself, is correct. \nWe also perform a selective exhaustive variable elimination starting with the initial flow equation HS \nof node S. At the end of this selective variable elimination, the only variables that will remain in \nHS are OS and O,d.m(s,. At this point, we compute the closure of the recursive equation to break the \ndependency of 0s on itself @la the El rule) and obtain the updated final flow equation H:. Case 3: S \ncontains more than one node. In this case, we have ir\u00adreducibility, and so we must simultaneously determine \nthe final flow equations for all nodes in S. Note that these nodes have the same immediate dominator. \nAs before, we perform selective variable elimination for each equation at node w in S until the only \nvariables remaining in the (sub-)system of equations are those from the nodes in S and their immediate \ndominator. Finally, we compute the closure for all mutually recursive equations simultaneously.  5.2 \nImprovement and Trade-Off Claim 5.1 states that PI and@. will appear in P: and G: if and only if either \nw = u or w c lDF(u). We used this property in Claim 5.2 to determine the set of nodes whose final flow \nequations are possibly affected. Consequently, if we update the initial pa\u00adrameters PO and @ at a node \ny, we will have tQ update the final flow equations at all node in {y} U Il)F(y). Although it is safe \nto do so, we can improve the efficiency by limiting the set of nodes whose final flow equations need \nto be updated. We illustrate this by using the following example, where a node is assumed to represent \na statement, and the data flow problem is Reaching Definitions:10 Io~l~ ~xmple is due to a PLD1Rviewm \n if (P) then noop; / node q / a= b+l; /*node r*/ b=20; / node t / endi f c= b+2; / node z / Now, change \nnoop to b=10. WhhClaim5.2,w ewillupdate the final flow equation at node z, although it does not change \nsince the effect of the change at node q does not propagate past node t, which kills the newly introduced \ndefinition. This example shows that IZDF(V) I can be (much) larger than the set of nodes that are indeed \naffected. An improvement over our basic approach is as follows: Instead of processing all SCCS in the \nprojection graph, we can use a worklist queue to maintain the SCCS of two types: (1) those containing \nnodes of which the final flow equations wifl actually change, and (2) those that are successors of the \nSCCS of the first type but whose nodes final flow equations do not change. Initially, the SCC containing \nnode g is inserted into the worklist. Whenever the worklist is not empty, we remove and process the SCC \nat ita head. If the final flow equations do not change for all nodes in the SCC, there is no need to \nenqueue its successor SCCS. Otherwise, these successorSCCs are enqueued if they are not in the worklist. \nNotice that we still have to compute the dag, and hence visit all the nodes in lDF(~) at leastonce.11 \nIn incremental analysis, there are usually trade-offs between space and time requirements [10]. By keeping \nmore intermediate information, one may avoid unnecessary work that is otherwise performed in the update \nprocess. For example, in our eager elimi\u00adnation, we do not maintain the sequence of the &#38;-rules applied \nto the (original and derived) J edges incoming to each node we also do not maintain the intermediate \nflow equations for each node. There\u00adfore, when we update the final flow equation for a node, we always \nstart with its initial flow equation. This would be unnecessary if we had kept relevant intermediate \ninformation around. There are however advantages for not maintaining intermediate information: (1) smaller \nspace requirements, and (2) no need to update the in\u00adtermediate information (for example, the sequence \nof the &#38;-rules applied to the J edges), Carrel and Ryder chose the alternative option of keeping \nthe relevant intermediate information around [4] (see Section 8). 6 Updating Final Data Flow Equations: \nStructural Changes Our approach to handling structural changes consists of three steps: 1. Update the \ndominator tree of the flowgraph. 2. Update the dominance frontier relation of the flowgraph. 3. Update \nthe final flow equations.  In Section 6.1, we briefly describe our algorithm for maintaining the dominator \ntree of a flowgraph. We wiU use its result later for updating the DF graph. In Sections 6.2 and 6.3, \nwe present incremental algorithms for updating the dominance frontier relation for edge insertion and \nfor edge deletion, respectively. Recalf that p + q is an edge in a DF graph if and only if q c ~F(p). \nTherefore, the problem of updating DF graphs is isomorphic to the problem of updating the dominance frontier \nrelation. 11,f the flowgmph is ~du~ibl~, rhe l+. oj (y ) will contain no cycles.exceptfn~ self-cycles.Inthkcase,wecanlimit \ntheupdatingofthefinalflowequationsforthe nodes in Proj (y) during IDF(v) computation. 6.1 Updating Dominator \nTrees: An Overview In [23], we presented an algorithm for updating a DJ graph in response to changes \nto its flowgraph. The DJ graph update problem subsumes that of updating the dominator tree. To maintain \nthe DJ graph (or dominator tree) for a flowgraph being updated, our approach first identifies the set \nof affected nodes whose immediate dominators will change [23, 13], Let x + y be some edge that is inserted \nor deleted in the flowgraph, and assume both nodes x and g are reachable from START node before and after \nthe change.12 To determine the set of affected nodes, our approach relies on two components: (1) IDF \n(u), the iterated dominance frontier of y, and (2) the level numbers of y and nodes in lDF(v). For the \nedge insertion case, we can compute the exact set of affected nodes even before restructuring the DJ \ngraph. This set is {w(w e ({Y} u IDF(V)) and w.kvel > nca(~, Y)J-J + 1}, where nca(x, ~) is the nearest \ncommon ancestor of x and g in the dominator tree. The new immediate dominators of all affected nodes \nare the samq it is nca(x, v), For the deletion case, we cannot compute the exact set of af\u00adfected node \nas elegantly as for the insertion case. Instead, we have an approximation set initially the set of potentially \naffected nodes is {WIW E IDF (y) and w.leue~ = V.level}. Then, an incremental version of the Furdom-Moore \nalgorithm for computing dominators is used to find the dominators for the potentially affected nodes. \nFL nally, we can compute the immediate dominators for the potentially affected nodes and determine the \nexact set of affected nodes, whose immediate dominators indeed change. h the following, DomAffected (y) \nrepresents the exact set of affected nodes, whose immediate dominators change, when z + ~ is inserted/deleted \n[23]. LevelO El Level 1 Level 2 I Level 3 uu (b) (a) Figure 11: Flowgraph and its DJ graph after 2 + \n5 is inserted  6.2 Updating Dominance Frontiers: Insertion of an Edge In this section, we present a \nsimple algorithm for updating the dom\u00adinance tlcmtiers of all the nodes that are possibly affected (i.e., \nin DFAffectedl(y)) when an edge x + v is inserted in the flow\u00adgraph. The key question is this: At which \nnodes may the dom\u00ad .,. mane-e rrcrrmers cnange when w -+ g is inserted? In [23], we nmer Caws,~hemtie \nmchablhty ofzand/orYdiffers,can~ haodedasWcial cases. show that a node w G DomAffected (y) moves up \nin the domi\u00ad nator tree after the DJ graph is updated. When this happens, the dominance frontiers of \nall nodes that dominate node w or x prior to updating are possibly affected. Now let z = nca(x, ~), and \nlet DFAffected I(g = {u Iz stdom u and u dominates a node w c {z} U Dom i ffected (y) prior to updating \nthe DJ graph}. We claim that if a node is not in D FAffected I y), its dominance frontier does not change. \nBut if a node is in D { Affected I(g), we are not certain whether its dominance frontier will change \nor not. Notice that we can easily compute the set DFAffected I(y) by a bottom-up traversal of the (old) \ndominator tree starting from nodes in the set {z} u DomAffected (v). After we have determined he set \nof possibly affected nodes, we update their dominance frontiers. For this, we first update the DJ graph \nusing the algorithm given in [23]. Next, for each node w c DFAffected I(y), we recompute DF(vJ) in a \nbottom\u00ad up fashion on the new DJ graph as follows: Let w be a node in DFAffectedl(g) and assume that \nthe dominance frontiers of all the children of w are correct. Let p c Children(w), then the new DF(w) \nis given by the following formula [6, 18]: Dl%xd(w) = {rlw + risa Jedge} DFuP(p) = {qlq c DF (p) and \nq.leuel < icforrz(p).level} DF(w) = DFIOca[(w) U DFuP(p) (lo) u pEChi[ciren(w) Notice that the above \nformula is equivalent to the one given by Cytron et al. for (exhaustively) computing the dominance frontiers \nof all nodes [6]. But, unlike in the exhaustive case, we apply the above formula only to the nodes in \nD FAffected I(g), which is the set of affected nodes. Example: Consider the flowgraph and its DJ graph \nin Figure 6. Let us insert an edge from node 2 to node 5. The resulting flowgraph and the updated DJ \ngraph are shown in Figure 11. Using the algorithm given in [23], the set DomAffected(5) is {5, 7}, and \nnca(2, 5) = 1. Next, we compute the D FAffected I(5). This set contains any node that dominates some \nnode in {2} u DomAffected (5) (i.e., 2, 5, and 7), and is itself strictly dominated by raca(2, 5) (i.e., \n1). We compute the set DFAffectedl(5) before updating the dominator tree. To compute the set DFAffectedl \n(5), we simply perform a bottom-up traversal of the dominator tree starting from nodes 2, 5, and 7 until \nwe reach raca(2, 5). We include in the set D FAffected 1(5) all the nodes, except nca(2, 5), visited \ndur\u00ading this bottom-up traversal. Consequently, DFAffected 1(5) = {2,4, 5, 7}. The dominance fi-cmtiersof \nthe nodes in DFAffected I(5), prior to the insertion of 2 + 5, are: llF(2) = {4, END}, ~F(4) = {3, END}, \n~F(5) = {7}, and DF(7) = {3,4, END}. After the edge insertion the new dominance frontiera for these nodes \nare: LlF(2) = {4,5, END}, DF(4) = {5,7}, DF(5) = {7}, and DF(7) = {3,4, END}. Other Cases If z is not \nreachable we do nothing since we maintain the DJ graph and the dominance frontiers only for REACH(START). \nNow, con\u00adsider the case where y becomes reachable only after the edge inser\u00adtion. Fnt, we build (using \nexhaustive algorithm) the DJ subgraph and the corresponding dominance frontiers for the sub-flowgraph \ninduced by nodes reachable from y but not reachable from START. For this, we treat v as the root node \nof the subgraph. Since z must dominate y, we then insert a D edge from ~ to y (to connect the newly built \nDJ subgraph with the existing DJ graph). Finally, from the viewpoint of updating the DJ graph and dominance \nfrontiers, we treat each edge u + v as a newly inserted flowgraph edge, where u becomes reachable only \nafter x + II is inserted, and v is reachable even before the edge insertion. This corresponds to the \ncase that we discussed earlier. 6.3 Updating Dominance Frontiers: Deletion of an Edge The effect of \ndeleting an edge is opposite and complementary to that of inserting the same edge. Recall that when inserting \nx + w we pull up all the nodes whose immediate dominators change. By contrast, when deleting an edge \nx + g, we pull down these affected nodes, So we must recompute the dominance frontiers for all possibly \naffected nodes, Again, let z = raca(x, y), and let DFAffectedD(y) = {UIZ stdom u and u dominates a node \nw c {z} u DomAffected (y) ajter updating the DJ graph}. Now, we claim that if a node is not in D FAffected \nD (y), its dominance frontier does not change. In the deletion case we compute the set DFAffected D(y) \naf\u00ad ter updating the DJ graph. Once the DFAffected D(V) set is determined, we update the dominance frontiers \nof the nodes in DFAffected D(y), as in the insertion case. Other Cases As before, if x is not reachable, \nwe do nothing. Now, assume that x is reachable and y becomes unreachable after x + y is deleted. We first \ndetermine the set U of nodes that have become unreachable, and then find the setF of edges u + v, where \nu c U and v @U. Now, we process the edges in F as if they were deleted from the flowgraph. Finally, we \nremove all the unreachable nodes. 6.4 Updating Final Flow Equations After we have updated the dominance \nfrontier relation, we update the final flow equations at all the affected nodes. Again, let the edge \nx + y be the structural update (either inserted or deleted). Now the key question is this: At which nodes \nare the final data flow equations affected when an edge x + y is updated? The answer to this question \nis given in the following claim: Claim 6.1 Let x + y be the edge that is updated in thejowgraph. The \nfinal datafiow equation at a node w is possibly affected if and only zfw g {v} u IDF(y). This is very \ninteresting. Recall that in Section 5, we made a similar claim (Claim 5.2) for non-structural updates. \nSo we can essentially use the same algorithm for structural changes as that given in Section 5 for updating \nthe final data flow equations. But rather than using the old DF graph, we will have to use the updated \nDF graph, to compute the new set of final flow equations. 7 Updating Final Data Flow Solutions In this \nsection, we describe how to update the final data flow solu\u00adtions a , once the final data flow equations \nhave been updated. A key question is this: At which nodes are the final data flow solu\u00adtions affected \nbecause of an incremental change? Let w be a node in Proj(g) whose new final flow equation is $~ ew (OidOm(W) \n), and let crfitd be its old final solution (which may no longer be correct). Also let u = idom (w), \nwhose data flow solution CY~cor is correct. 13 We do not need to update the final solutions for the child \nnodes of w if the following relationship exista at node w: ffw td = Rew(dc r), 13B~~omct solution we \n~em that eitier its original solution wasnot affectedW the incremental change, or somehow has been correctly \nupdated. Otherwise, we must compute a~ and mark the children of w (on the dominator tree) as potentially \naffected, and repeat the process for each child node. Since the flow equation at node w depends only \non its immediate dominator, and the solution at its immediate dominator is correct, we can compute the \nnew correct final solution at w as follows: Ct wFcor = fl? ew (a: ) It is important to observe that \nbefore we can update the final solution at a node w, we must ensure that the final solution of its immediate \ndominator is correct. Also, once (and if) we update w s final solution, we must mark all its child nodes \npotentially affected, and so their final sohttions will be considered for potential updates. Therefore, \nwe order the nodes in Proj(y) in terms of their levels on the dominator tree, and process them in a top-down \nfaahion. 8 Discussion and Related Work Our two exhaustive elimination methods are related to all of tic \nfour classical elimination methods: the Allen-Cocke method, the Hecht-Ullman method, the Graham-Wegman \nmethod, and the Tar\u00adjan method. Except for the Graham-Wegman method, these elimi\u00adnation methods are applicable \nonly to reducible flow graphs. They mainly use two approaches to handle irreducible flow graphs. One \nis node splitting, which generates an equivalent reducible flowgrapb by splitting nodes [1 ]. The other \napproach is to form improper re\u00adgions to accommodate irreducibility and to use fixed-point iteration \nin those regions [3, 17]. We take the second approach, but perf\u00adorm fixed-point iteration only over nodes \nthat are in the irreducible region and are at the same level (on the dominator tree). Our delayed elimination \nmethod is comparable to Tarjan s path compression-based intervrd analysis, but simply performed on a \nstatic dominator tree, In Section 5 of [24], Tarjan defines a denvecl graph G of a flow graph G in order \nto solve path problems on both reducible and irreducible graphs. The derived graph of a flowgraph has \nthe same set of nodes as in the flowgraph. An edge x + ~ is inserted in a derived graph if (1) a = idorn \n(y) and x + y is also an edge in the tlowgraph, or (2) ~ is in the dominance frontier of x and x.level \n= y.leveL Using our terms, we observe that all the D edges in G also appear in G . On the other hand, \nfor eachl J edge in G, the corresponding edge in G is exactly the same as the new J edge that we would \ncreate in our D2b ntle. Also, the number and size of SCCS (both trivial and nontrivial) identified at \nany particular level during our bottom-up elimination phase will be exactly same as the number and size \nof SCCS in G at that level. We suspect that this coincidence may partially explain why we can handle \nirreducibility efficiently. Our reduction rules are similar to Hecht and Unman s T1 and T2 rules. But \nwe use the notion of top nodes to remember delayed variables, whereas Hecht and Unman use a more complicated \ndata structure, height-balanced 2-3 tree, to save delayed variables. The Graham-Wegman method uses non-disjoint \nsets called the S-sets, which are strongly connected regions and analogous to Tarjan s intervals, for \nreduction and elimination. Unlike Tarjan s method, in the Graham-Wegman method, not all the nodes in \nan S-set are collapsed into the S-set entry node. The variables representing sohl\u00adtions at the remaining \nnodes, therefore, still exist in a reduced system of equations after the S-set is processed, thereby \nmaking explicit the delayed substitutions of variables. These delayed variables are remembered in a reduced \nflowgmph. Unlike our approach, Graham and Wegman perform path compression on a depth-first spanning tree. \nFurthermore, in their T2 rule they need to inspect which outgoing edges from anode are witttin the current \nS-set, In our case, the D2b rule eliminates such edges, so we never need to inspect any J edges during \npath compression. Elimination methods are general-purpose data flow solution pr\u00adocedures[3, 10, 24]. \nIn [3] Burke reformulates Tarjan s interval anal\u00adysis so that it can be applied to any monotone data \nflow problem. Burke proposes to use the closure of an interval to summarize local data flow information \nfor monotone problems. In our approach, we similarly define a closure operation for a recursive data \nflow equation. Our incremental algorithm uses simple properties of dominance frontiers and iterated dominance \nfrontiers for updating data flow so\u00adlutions. Previous work that is most relevant to ours is due to Carroll \nand Ryder [4, 5]. Carroll and Ryder s method is based on the reduce and borrow concept for updating data \nflow solutions [4, 5]. They reduce a monotone data flow problem to an attributed (dominator) tree problem, \nand then borrow the well-known Reps s attribute up\u00addate algorithm for updating data flow solutions [14]. \nThey use the Graham-Wegman elimination method as a starting point for map\u00adping data flow problems to \nattributed dominator tree problems [7]. They decorate each node in the dominator tree with its(1) initial \nflow equation, (2) final flow equation, and (3) correct solution. These decorations are treated as attributes \nof the dominator tree. Once they construct an attributed dominator tree, they modify Reps s al\u00adgorithm \nfor updating the attributes [14]. Reps s original algorithm can only handle updates to attributed parse \ntrees that are derived from attribute grammars. Since dominator trees are not parse trees, Carroll and \nRyder generalize Reps s algorithm to handle arbitraty trees. Carroll and Ryder ahow that if the original \nflowgraph ia re\u00adducible, the dependence graph of the attributed dominator tree is acyclic. Fresence of \nirreducibility in the original flowgraph intr\u00adoducescycles in the dependence graph of the attributed \ndominator tree, so one cannot use Reps s algorithm for updating such trees. The sub-parse tree replacement \nin Reps s algorithm corresponds to restructuring of the dominator tree in Carroll and Ryder s method. \nCarroll and Ryder also propose an algorithm for updating the dominator tree of a flowgraph. While updating \nthe dominator tree, they compute what they call representative edges, which are central 14 ~ese ~Pmsentitive \nedges am then to their update algorithm. used for updating both the dominator tree and attributes of \nthe dom\u00adinator tree. Fmjection of these representative edges with respect to the root of the affected \nsubtree corresponds to the characteristic graphs in Reps s algorithm. For reducible flow graphs, the \nprojec\u00adtion of the representative edges forms a dag, so they can update the attributes of the dominator \ntree in the topological order of the projec\u00adtion graph. In our approach, we also reduce a data flow problem \nto an attribute problem by annotating every node in the DJ graph with its initial flow equation, final \nflow equation, and final flow solution. But, unlike Carroll and Ryder s method, we use simple properties \nof dominance frontiers and iterated dominance fi ontiers for updating the final data flow solutions, \nand these properties are valid for both reducible and irreducible flowgraphs. Burke proposes a method \nfor elimination-based incremental data flow analysis that uses Tarjan s intervals for updating and propagating \ndata flow solutions [3]. His approach can only handle structural changes to flowgraphs that do not modify \nthe depth-first spanning tree of the flowgraph. Marlowe and Ryder propose a hybrid incremental method \nthat combines iterative and elimination methods [11 ]. They first identify strongly connected components \nin the flowgraph. Then, they use iteration within individual compo\u00adnents but propagate data flow information \namong components us\u00ading an elimination-like method. Although they can handle arbitrmy program updates, \ntheir incremental method is more coarse-graineck they update and propagate solutions to a much larger \nset of nodes than in our approach or in Carroll and Ryder s approach. 14suw<.in81Y, ~P=~mt.&#38;.. .A6.. \n.-~la+.d +0d~~km= f~ t;.=. k [ 18. 19] for more details. Acknowledgement We would like to thank Michael \nBurke, Paul Carini, Rakesh Ghiya, William Landi, Thomas Marlowe, G. Ramalingarn, Kares Theme, and the \nPLDI 96 program committee membws for their comments that greatly helped improve our presentation, We \nalso thank Xinan Tang for helping us draw a figure. Finally, the first two authors would like to thank \nthe National Sciences and Engineering Resrmreh Council (NSERC) and the Canadian Centers of Excellence \n(IRIS) for their continued support of this research. References [1] AHO, A, V., SETHI, R., AND ULLMAN, \nJ. D. Compilers-Principles, Techniques, and Tools. Addison-Wesley Publish\u00ading Co., 1986. [2] ALLEN, F. \nE,, AND COCKE, J. A program data flow analysis procedure. Communications of the ACM l!?, 3 (March 1976), \n137-147. [3] BURKE, M. An interval-based approach to exhaustive and incremental interprocedurrd data-flow \nanalysis. ACM Trarts\u00adactions on Programming Languages and Systems12,3 (July 1990), 341-395. [4] CARROLL, \nM., AND RYDER, B. G. Incremental data flow up\u00addate via attribute and dominator updates. In ACM SIGPLAN-SIGACT \nSymposium on the Principles QfProgramming Lan\u00adguages (January 1988), pp. 274-284, [5] CARROLL, M. D. \nData Flow Update via Dominator and Attribute Updates. PhD thesis, Rutgers University, New Brunswick, \nNJ, May 1988. [6] CYTRON,R,, FERRArVrE,J., ROSEN,B. K., WEGMAN, M. N., AND ZADECK, F. K. Efficiently \ncomputing static single as\u00adsignment form and control dependence graph. ACM Transac\u00adtions on Programming \nLanguagesandSystems 13,4 (October 1991), 452-490. [7] GRAHAM, S. L., AND WEGMAN, M. A fast and usually \nlinear algorithm for global flow analysis. Journal of the ACM 23, 1 (January 1976), 172-202. [8] HECHT, \nM. S. Flow Analysis of Computer Programs, Elsevier North-Holland, Inc., 1977. [9] KILDALL, G. A. A unified \napproach to globaf program op\u00ad timization. In Conference Record of the First ACM Sympo\u00adsium on Principles \nof ProgramPing Lang~ges (Boston, Mas\u00adsachusetts, 1973), ACM SIGACT and SI~PLAN, pp. 194\u00ad 206. [10] MARLOWE, \nT. J, Data Flow Analysis and Incremental Itera\u00adtion. PhD thesis, Rutgers University, New Brunswick, New \nJersey, October 1989. [11] MARLOWE, T. J., AND RYDER. B. G. An efficient hybrid algo\u00adrithm for incremental \ndata flow analysis. In Conference Record of the Seventeenth Annual ACM Symposium an Principles of Programming \n.lmnguages (January 1990), ACM SIGACT and SIGPLAN, pp. 184-196. [12] MARLOWE, T. J., AND RYDER, B, G, \nPmperites of data flow frameworks: A unified model. Acts Informatica 28 (1990), 121-163. [13] RAMALINGA&#38;f, \nG., AND REPS, T. An incremental algorithm for maintaining the dominator be of a reducible flowgraph. \nin ACM SIGPLAN-SIGACT Symposium on the Principles of Programming Languages (January 1994). [14] REPS, \nT. Optimal-time incremental semantic analysis for syntax-directed editors. In Conference Record of the \nNinth Annual ACM Symposium on Principles of Programming Lan\u00adguages (January 1982), ACM SIGACT and SIGPLAN. \n[15] RYDER, B. G., AND PAULL, M. C. Elimination algorithms for data flow analysis. ACM Computing Surveys \n18,3 (September 1986), 277-316. [16] RYDER, B. G., AND PAULL, M. C. Incremental data-flow anal\u00adysis \nalgorithms, ACM Transactions on Programming Lan\u00adguagesand Systems 10, 1 (January 1988), 1-50. [17] SCHWARTZ, \nJ. T., AND SHARIR, M. A design for optimiza\u00adtion of the bitveetoring class. Tech. rep., Courant Institute \nof Mathematical Sciences, New York University, September 1979. Courant Computer Science Report No. 17. \n[18] SREEDHAR, V. C. Eflcient Program Analyses Using DJ Graphs. PhD thesis, School of Computer Science, \nMcGill University, September 1995. [19] SREEDHAR, V. C., AND GAO, G. R. An elimination-based ap\u00adproach \nto incremental data flow analysis. Tech. Rep. ACAPS Memo 94, McGill University, June 1995. [20] SREEDHAR, \nV. C., AND GAO, G. R. A linear time algorithm for placing r+nodes. In ACM SIGPLAN-SIGACT Symposium on \nPrinciples of Programming Languages (January 1995). A longer version to appear in Journal of Programming \nLan\u00ad guages. [21 ] SREEDHAR, V. C., GAO, G. R., AND LEE, Y. Efficient data flow analysis using DJ graphs: \nElimination methods revisited. Tech. Rep. ACAPS Memo 93, McGill University, June 1995. [22] SREEDHAR, \nV. C., GAO, G. R., AND LEE, Y. Identifying loops using DJ graphs. Tech, Rep. ACAPS Memo 98, McGill Uni\u00adversity, \nSeptember 1995. [23] SREEDHAR, V. C., GAO, G, R., AND LEE, Y. Incremental com\u00adputation of dominator \ntrees. In ACM SIGPLAN Workshop on Intermediate Representation (in conjunction with the ACM SIGPLAN-SIGACTSymposium \non Principles of Programming Languages) (January 1995). Also appears in SIGPLAN No\u00adtices Volume 30, Number \n4, 1995. [24] TARJAN, R. E. Fast algorithms for solving path problems. Journal of the ACM 28,3 (July \n1981), 594-614. [25] ULLMAN, J, D. Fast algorithms for the elimination of common subexpressions. Acts \nInformatica 2,3 (1973), 191-213.   \n\t\t\t", "proc_id": "231379", "abstract": "We present a new elimination-based framework for exhaustive and incremental data flow analysis using the DJ graph representation of a program. Unlike the previous approaches to elimination-based incremental data flow analysis, our approach can handle arbitrary non-structural and structural changes to program flowgraphs, including those causing irreducibility. We show how our approach is related to (iterated) dominance frontiers, and exploit this relationship to establish the complexity of our exhaustive analysis and to aid the design of our incremental analysis.", "authors": [{"name": "Vugranam C. Sreedhar", "author_profile_id": "81100375252", "affiliation": "Hewlett-Packard Company, Cupertino, CA", "person_id": "P292332", "email_address": "", "orcid_id": ""}, {"name": "Guang R. Gao", "author_profile_id": "81100134147", "affiliation": "McGill University Montreal, PQ H2X 1W7", "person_id": "P100128", "email_address": "", "orcid_id": ""}, {"name": "Yong-Fong Lee", "author_profile_id": "81542607956", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "PP309117800", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/231379.231434", "year": "1996", "article_id": "231434", "conference": "PLDI", "title": "A new framework for exhaustive and incremental data flow analysis using DJ graphs", "url": "http://dl.acm.org/citation.cfm?id=231434"}