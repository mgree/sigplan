{"article_publication_date": "05-01-1996", "fulltext": "\n Global Communication Analysis and Optimization Soumen Chakrabarti* Manish Guptat Jong-Deok Choit Abstract \nReducing communication cost is crucial to achieving good performance on scalable parallel machines. This \npaper presents a new compiler algorithm for global analysis and optimization of communication in data-parallel \nprograms. Our algorithm is distinct from existing approaches in that rather than handling loop-nests \nand array references one by one, it considers all communication in a procedure and their interactions \nunder different placements before making a final decision on the placement of any communication. It exploits \nthe flexibility resulting from this advanced analysis to eliminate redundancy, reduce the number of messages, \nand reduce contention for cache and communication buffers, all in a unified framework. In contrast, single \nloop-nest analysis often retains redundant communication, and more aggressive dataflow analysis on array \nsections can generate too many messages or cache and buffer contention. The algorithm has been implemented \nin the IBM pHPF compiler for High Performance Fortran. During compilation, the number of messages per \nprocessor goes down by aa much as a factor of nine for some HPF programs. We present performance results \nfor the IBM SP2 and a network of Spare workstations (NOW) connected by a Myrinet switch. In many cases, \nthe communication cost is reduced by a factor of two. 1 Introduction Distributed memory architectures \nprovide a cost-effective method of building scalable parallel computers. However, the absence of global \naddress space, and the resulting need for explicit message passing makes these machines difficult to \nprogram. This has motivated the design of languages like High Performance Fortran (HPF) [9], which allow \nthe programmer to write sequential or shared-memory parallel programs that are annotated with directives \nspecifying data decomposition. The compilers for these languages are responsible for partitioning the \ncomputation, and generating the communication necessary to fetch values of non-local data referenced \nby a processor [15, 30, 4, 3, ,5, 12]. Accessing remote data is usually orders of magnitude slower than \naccessing local data. This gap is growing Computer Science Division, U. C. Berkeley, CA 94720. Partly \nsupported by ARPA/DOD (DABT63-92-C-0026), DOE (DE-FG03\u00ad 94 ER25206), and NSF (CCR-921026O, CDA-8722786 \nand CDA\u00ad 9401156). Part of the work was done while the author was visiting IBM Research. Email: soumenOcs. \nberkeley. edu. t IBM T. J. Watson Research Center, Yorktown Heights, P. 0. BOX 704, NY 10598. Email: \n{mgupta, jdchoi}@watson, ibm. corn. Permission to make digitablwd copy of part or all of this work for \npersonal or classroom use is ranted without fee provided that copies are not made or distributed for \npro I t or commercial advanta e the copyright notica, the title of the publication and its date appear, \nan i nobce is given that copying is by permission of ACM, Inc. To copy otherwise, to republish, to post \non servers, of to redistribute to iisk, requires prior specific permission and/or a fee. P~Dl 90 WS6 \nPA, USA 01996 ACM 0-S9791-795-2/98/0005... $3.50 because CPU performance is out-growing network perfor\u00admance, \nCPU s are running relatively independent multipro\u00adgrammed operating systems, and commodity networks are \nbeing found more cost-effective. As a result, communication startup overheads tend to be astronomical \non most dis\u00adtributed memory machines, although reasonable bandwidth can be supported for sufficiently \nlarge messages [25, 24]. Thus compilers must reduce the number as well as the volume of messages. This \ncan improve performance on shared memory machines as well, because fewer messages translate into fewer \nsynchronization events [26, 22, 13]. Consequently, communication optimization has been extensively researched, \nfrom local single loop-nest to global and even interprocedural optimization, The earliest and most commonly \nused optimizations include message vec\u00ad torization [15, 30], using collective communication [11, 20], \nmessage coalescing [15], and exploiting pipelined communi\u00ad cation [15, 12], all withh the scope of a \nsingle loop nest. Local analysis of array accesses based on dependence testing alone often retains redundant \ncommunication. Naturally, the next step waa the use of dataflow analysis, e.g.. using precise array dataflow \nanalysis to detect redundant comm\u00adunication within a loop nest [3], and those using global dataflow analysis \nfor redundancy elimination across loop nests as well, These include dataflow analysis over array sections \nfor regular computations [10, 14, 17, 18] and over entire arrays for irregular computations [27, 1]. \nTypically, the technique is to move communication to the earliest possible point dictated by data dependency \nand control flow. Superficially, this appears to give the additional benefit of maximum overlap between \nCPU and network activity. Recently, it has been pointed out that communication that is scheduled too \neagerly can lead to problems like contention (which reduce effective network bandwidth) and excessive \nbuffer requirement (which upsets the computation s cache and thereby degrades performance) [18, 21]. \nThis is similar to the issue of register pressure [19]. However, a more striking fact we point out is \nthat earliest placement can also lead to valuable opportunities being missed for reducing the number \nof messages or eliminating partial redundancy, making it a sub-optimal strategy even in the absence of \nresource constraints. There is thus a clear need for global scheduling of communication. In this paper \nwe present a novel compiler algorithm that includes and extends all the optimizations mentioned above. \nOur algorithm derives from static single assignment analysis, array dependence analysis, and the recently \nintroduced data availability y analysis [14], which is extended to detect compatibility of communication \npatterns in addition to redundancy. We differ significantly from existing research in that the position \nof communication code for each remote access is not decided independent of other remote accesses; instead, \nthe positions are decided in an interdependent and global manner, The algorithm achieves both redundancy \nelimination and message combining glob\u00adally, and is able to reduce the number of messages to an extent \nthat is not achievable with any previous approach. 68 our algorithm has been implemented in the IBM \npHPF prototype compiler [12], We report results from a prelim\u00adinary study of some well-known HPF programs. \nThe per\u00adformance gains are impressive. Reduction in static message count can be up to a factor of almost \nnine, Time spent in communication is reduced in many cases by a factor of two or more. We believe that \nthese are also the first results from any implementation of redundant message elimination across different \nloop nests, and add significant experimental experience to research on communication optimization. 2 \nMotivating codes We motivate the need for our proposed optimization by analyzing a series of real-life \nF90/HPF source codes. Specif\u00adically, we demonstrate the following. Redundancy elimination is useful, \nbut often not enough to reduce the number of messages. This is crucial for our target architectures, \nespecially for synchronous and collective communication,  In fact, the traditional mechanisms of redundancy \nelimination can sometimes prevent the compiler from generating the best communication code.  b The well-known \nredundancy elimination techniaue of earliest communication placement is sensitive to &#38;inor syntactic \ndifferences in the high-level source, and may produce suboptimal code. In the code fragments that we \npresent, we will elide actual operations and show each RHS as a list of variables accessed. Frequently \nwe deal with F90 style shift operations that involve nearest-neighbor communication (NNC); we show this \npictorially using arrows. For simplicity, the combinable messages in our examples have identical patterns \non the processor template; in reality, combining is feaaible when one pattern is a subset of another. \n2.1 Beyond redundancy elimination Redundancy elimination seeks to avoid unnecessary repeti\u00adtions of communication \nfor the same data. Often programs exhibit similar communication patterns involving different data as \nwell. Combining those communications to use fewer messages is a crucial goal on current multicomputers \nlike the SP2 as the message startup costs are large. In the NPAC gravity codel, all 2-d arrays are of \ndimen\u00adsion (ny, nz) distributed (BLOCK, BLOCK) and all 3-d arrays are of dimension (nx ,ny ,nz) distributed \n(*, BLOCK, BLOCK). A simplified form of the code is shown in Figure 1. In this code it is easy to detect \nthat the NNC for g and glast can be combined, as can be the sum operations. Thus we can combine the eight \nNN messages into four and the eight global sums into two parallel sets of four global sums. 2.2 Earliest \nplacement may hurt While in the last example we merely needed a combining pass after earliest placement, \nin general the situation could be more complicated. In particular, redundancy elimination via earliest \nplacement can prevent the combining possibili\u00adties from being exploited. To demonstrate this, we study \nthe NCAR shallow water code, which has NN message pattern. As discussed in [12], the message coalescing \noptimization implemented in the pHPF compiler allows the diagonal communication to be subsumed by an \naugmented form of the NNC along the two axes. A simplified form of the original code is shown in Figure \n2. If no redundant message elimination is done across different loop nests, there would be 20 exchanges \ngenerated per processor, following the subsumption of diagonal communication by message-coalescing. Earliest \nplacement will move up a communication as far as possible within the loop, commu\u00adnicating data right \nafter definition. 14 array sections will be communicated per processor. In contrast, using message combining \nas the guiding profit motive, we get a schedule with only 8 exchanges per processor, in which placement \nof communication is not at the earliest point detected by dataiiow analysis. (The IBM compiler already \noptimizes diagonal communication like p~ by subsuming it using p~ and p+. This is reflected by the message \ncounts.) 2.3 Syntax sensitivity Since earliest placement pushes communication close to the production \nof the data value, placement is sensitive to the structure of intervals containing the production. As \na case in point, consider the semantically equivalent codes in the three columns of Figure 3. Suppose \narrays a and b have identical layout, say blocked. Using earliest placement, the messages for the two \narrays can be combined in the third column whereas they cannot in the second code. Even if the programmer \nwere careful enough to write the code in the first column, intermediate passes of compilation may destroy \nthe interwd containment. In fact, the current IBM HPF scalarizer [12] will translate the F90-style source \nto the scalarized form in the second column. If loop fusion can be performed before this analysis, as \nin this case, the problem can be avoided. But this is not always possible [28, ~ 9.2]. Thus, limited \ncommunication analysis at a single loop-nest level or a rigid placement policy may not work well. Our \nframework, by not relying on any restricted placement (like earliest or latest) but evaluating many choices \nglobally, proves to be a much more robust strategy that is not easily perturbed by minor syntactic differences. \n3 Network performance By profiling our target networks, we justify why global message scheduling is necessary, \nand what reasonable sim\u00adplifying assumptions can be made about the optimization problem. We pick two \nplatforms: the IBM SP2 with a custom network, and a network of Spare workstations (NOW) connected by \na commodity network \\Myrinet). IBM s message passing library MPL and MPIC!H are used for communication. \nDetails of the networks can be found in [25, 24, 16]. We want to measure how large messages are rewarded \nby the network, while estimating the local buffer-copy cost to collect small messages. Figure 5 shows \nthe profiling code and results. The top curve shows the bandwidth of local bcopy as a function of buffer \nsize. The bottom curve plots network bandwidth as a function of message length, based on the time that \nthe receiver waits for completion. As long as the buffers fit in cache, we can ignore the overhead of \nbcopy. Fortunately, most of the message startup amortization benefits occur at message sizes much smaller \n2&#38;fp~CH is an implementation of the MpI standard. Timestep loop: glast(:,:) = g(l,: . :) fori=2tonx-1 \n ... = g(i, :, :)T+J-+ . . . = sum(g(i, ny, :)), sum(g(i, ny 1, :)), swn(g(i, O, :)), snrn(g(i, 1, \n:)) . . . = glast(:, :)~e$+ . ~. = swn(glast(ny, :)), surn(glast(ny 1, :)), swn(glast(O, :)), sum(glast(l, \n:)) glast(:,:) = g(i,:,:) g(i):,:) =,.. Figure 1: Asimplified form of the NPAC gravity code illustrating \ntheneed for combining communication. Earliest placement Combined placement Loop: Loop: COMM+D,v I-p$u \n+U Jv COMM+P,v -rP, u tu Lv Cu =p+ Cu =p+ Cu =p+ COMM+Cu -rCu Cv Cv Cv =P? =Pt =Pt\u00adCOMM-+Cv .l.Cv z \n=Ut,v+, p+, pt, p~ z =u~,v+, p+, pt, p> Z =Ut,v+, p+, Pt,P7 COMMJ,z 4-z h =Ui-, V$ h =u+-, V$ h =u+, \nV$ COMM+h Th COMM+cv,h lZ,CV +Z, cu ~cu,h une w = Z$, h+, CV+, CV$, CV\\ unew = zJ, h+, cv~, CVJ, cv\\ \nnnew = z+, h+, CV+, CV$, cv\\ vnew = z4-, h~, CU4-, cut, cu\\ vnew = z4-, h~, cue, cu~, cu\\ vnew = z+, \nh~, CU+, cut, cu\\ pnew = cue, Cv$ mew = Cu+. Cv.1 pnew = cue, CVJ Figure 2: The NCAR shallow benchmark \nillustrating that redundancy elimination via earliest placement may lose valuable opportunity for message \ncombining. F90 Source code Scalarized code Hand coded F77 doi=l:n a(i) = 3 doi=l:n distribute a, b, \nc:: (BLOCK) COMMEarliest(a) a(i) = 3 a=3 doi=l:n b(i) = 4 b=4 b(i) = 4 COf414Earliest(a), Earliest(b} \nc(2:n)= cJ(l:n-l)+b(l: n-1) CO!4!4 Earliest(b) doi=2:n doi=2:n c(i) = a(i 1) + b(i 1) c(i) = a(i -1) \n-I-b(i 1) Figure 3: Syntax sensitivity of earliest placement. marking elimination elimination placement \ndistribute a, b, c, d :: (BLOCK,*) 1 b(:,l:n:2)=l bl bl 2 b(:,2:n: 2)=2 bl , bz bz 3 if (cond ) 4 a=3 \na2 5 else 6 a=d az 7 endif al, az, bl, b2 al,az,bl,bz az, bz 8 doi=2:n 9 doj=l:n:2 10 c(i, j) = a(i \nl,j) +b(i l,j) // use al, bl 11 doj=l:n ~12use a2, b2 Figure 4: Running example for analysis and optimization \nsteps. Code for each communication entry is executed after executing the statement. The notation {az, \nbz } means the messages for these accesses can be combined. The results of traditional earliest placement \nis shown in the last column for comparison. C. --A-.. cxmueri Barrier Time { blocking a z.5W-----\u00ad P \n7 2 WY $ 51.5 Y -? fl . rn Sqd 0.5 ,,, , ,,...<.<-- ti   -- ,\\<:,,. ----\u00ad0 106 Buffer size (Bvtes) \n cation 1. 2.  Receiver: send } Post non-blocking receive Barrier Modified pHPF SPMDizer Time { wait \nfor completion } 8k--\u00ad   f%,, Trace dump to Ist file for hand compdation s ~4 Code Generation Transformer \nJ w Data d g =2 Figure 6: Prototype modifications to the IBM PHPF SPMDizer. Semd.. .,, ~....... ., ..., \nFrev ........ . .+_  I_.._._ 0 102 104 1 Buffarsize (Bvtes) Figure 5: Buffer convirw and network \nbandwidth studies On the lB-M SP2 using MPL an~ the Berkeley NOW using MPICH. The x-axis is to a log \nscale. the cache limit, for both machines. Given typical cache sizes, we believe this is a fairly general \nfeature. It may be important to suppress combining communication from different large non-contiguous \narray sections. E.g., for the SP2, bcopy bandwidth is barely twice message beyond cache size. The middle \ncurve shows bandwidth computed time the sender takes to inject the message. injection bandwidth is much \nlower than bcopy, than receive bandwidth for certain message bandwidth using the While the it is larger \nsizes. Our algorithm permits additional techniques like Give-n-Take to be used to overlap this latency \nwith code at the sender [27]. We did not implement this because the potential gain was not clear in our \narchitectures and bulk-synchronous SPMD model. It also depends on the co-processor software. E.g., the \nimplementors of MPL processor assistance because it is much slower and the channel between the CPU and \nthe S1OW [24]. Compiler algorithms In this section we describe the algorithm for and network minimize \nco\u00adthan the CPU, co-processor is placing comm\u00ad unication code. This analysis is done after the compiler \nhas performed transformations like loop distribution interchange to increase opportunities for moving \noutside loops [12]. For each RHS expression that may need cation, identify the earliest (54.3) and latest \nposition to place that communication. This done using a backward and forward dataflow with array section \ndescriptors or bit-vectors. and loop communi\u00ad communi\u00ad($4.2) safe is typically approach We find it more \nefficient to exploit the SSA clef-use information already computed in an earlier phase [8, 6], refined \nby array dependence-testing [29]. For each non-local reference, identify a set of candidate positions, \nany one of which can be potentially chosen Data Parhtloning Preprocessing .< 4 Dataflow/Communication \nDependenceAnalysis Analyzer J Commumcation LooP 3. Perform the array-section analog of common subex\u00adpression \nelimination: detect and eliminate subsumed communication ($4.6). 4. For the remaining communication, \nchoose one from the set of candidate placements. In the prototype we do this in two substeps that will \nbe explained later (\\4.5 and $4.7).  The above algorithms have been added to a proto\u00adtype version of \nthe pHPF compiler as shown in Figure 6. Throughout this section, we will use the code in Figure 4 as \na running example to illustrate the operation of the steps of the algorithm. 4.1 Representation and \nnotation We represent the program using the augmented control flow graph (CFG), which makes loop (interval) \nstructure more explicit than the standard CFG by placing preheader-and postezit nodes [2, 23]. These \nextra nodes also provide convenient locations for summarizing dataflow information for the loop. The \nCFG is a directed graph where each node is a basic block, a sequence of statements without jumps. A statement \nS may have a use u or def d of an array variable. d can be either a regular def found in the source code, \nor a rj-def inserted during conversion to SSA form. All regular array clefs are preserving. We refer \ninterchangeably to a use, clef, statement, or the node containing them. The node containing S is called \nCfgNode(S). When we say communication is placed at d we mean immediately ajler d. kPre-heeder Header \nZero-trip Body edge Exit (v =Q P.st-exit + as the final point to emit a call to a message-passing runtime \nroutine ($4.4). Figure 7: The augmented control flow graph. A path x : vo~vj from V. to vj is a non-empty \nnode sequence (w) with edges (vj-1, v;), 1 < i < j; we also call n a backward path or backpath from Vj \nto vo. T bypasses v if v does not occur on m. Possibly empty paths are denoted VO--%Vj. Two paths are \nnon-overlapping if they are node-disjoint. Non-empty paths m : vo>vj, T2 : WO&#38;W,$ converge at -? \nif VO # wO, vj = z = wh, and(vP= w~)*(p=j Vq= k). Loops are named L. Every loop haa a well-defined nesting \nleve~ called NL(L): this is the number of loops containing it. NL(v) for node v is defined likewise. \nL or v is deep or shailow according as N L is large or small. The common nesting level CN L(u, v) of \ntwo nodes u and v is the NL of the deepest loop containing them both. Every loop L has a single preheader \nnode, PreHdr(L), and there is an edge from PreHdr(L) to Hdr(L), the header node. PreHdr(L) dominates \nall nodes in L. There is a postemt node for each distinct loop exit target. Each postexit node of L has \nan incoming edge, called zero-trip edge, from PreHdr(L) (along with the original loop-exiting edges). \nSee Figure 7. L has a ~-def at Hdr(L), called @ti&#38;, for each variable defined in the loop or in a \nloop transitively nested in L. &#38;id, has two parameters, rP,, and rp.,t,that there exists such a backpath \nfrom rP,, to ENTRY that bypasses all nodes in the loop, and there exists a path from any node in the \nloop to rPo,t which never takes an exit edge out of the loop. Each postexit node of a loop L has a ~-def, \ncalled @Exit, for each variable defined in the loop or in a loop transitively nest ed in it. Because \nof #EX!t, a definition d can reach a use u only through a definition d at a level CNL(d, u). d can \npossibly be d only if CNL(d, u) = NL(d); otherwise, d is a ~-def at a level CNL(d,u).  4.2 Identifying \nthe latest position We describe how the compiler finds Latest(u), the latest point to place communication \nfor u which is as shallow as possible. This follows from standard communication analysis in which communication \nis placed just before the outermost loop in which there is no true dependence on u, and is placed just \nbefore the statement containing u if no such loop exists [30, 15, 12]. Given a use u, let d range over \nthe reaching regular clefs of u. Consider some d. Observe that it is never necessary to place communication \nfor u deeper than at CN L(d, u). Given d and u, we can compute all possible direction vectors (each is \na C N L (d, u)-dimensional vector) [28]. These vectors are used in lsArrayDep in Figure 8(d). Let DepLevel(d, \nu) = maxt{lsArrayDep(d, u, 1)}, Because of the dependency at level DepLevel(d, u), communication for \nu cannot be moved outside loop level DepLevel(d, u). The overall communication level for use u, denoted \nComm Level(u), is set to maxd{DepLevel(d, u)}. Finally, to place communication, we check CommLevel(u): \nif Comm Level(u) = NL(u), communication is placed immediately before the statement containing U3; if \nCommLevel(w) < NL(u), communication is placed in the loop preheader of the loop at level (CommLevel(u) \n+ 1) that contains u. Note that CommLevel(u) > N L(u) is not possible, and that by construction Latest(u) \ndominates u. 31n this ~a~e no vectorization has been possible. For each def d of use u in depth-first \npreorder traversal: ~ ,,. ... For each q5-~arameter r~ visit ~] = O, visit [d] = 1 Let Ci = Rcount(Reaching( \nri), u, CNL(d, u), visit) If two or more c~ s are positive Return TRUE else (d is a regular clef) If \nlsArrayDep(d, u, CNL(d, u)) Return TRUE. ,. Rcount(d, u, 1,visit) Ifdisa@-def, sayd=r$(... ,i,i, . . \n.) If visit[dl return O visit[d] = 1 Return xi Rcount(Reaching (ri), u, 1,visit) else (d is a regular \nclef) If lsArrayDep(d, u, t) Return 1 else if d is a preserving def Return Rcount(Reaching( d), u, 1,visit) \nelse return O. L lsArrayDep(d, u, i?) [f d is the pseudo-def at ENTRY then return TRUE If t? > CNL(d, \nu) then return FALSE If 3 direction vector Z = (trl,. . . . VCNL[,j,uJ) such that vi= O, fori E{l, .,, \n,l l}, and Qvi>o then return TRUE else return FALSE Figure 8: (a) Pseudocode for iterating over reaching \nclefs of u. (b) Pseudocode for testing a def d to identify if d is the earliest communication placement \npoint. (c) Pseudocode for recursively counting the number of incoming edges at @clefs or preserving regular \nclefs that bear possible dependence. (In our SSA implementation, there is a pseudo-def at ENTRY for each \nvariable accessed in the routine, which simplifies dataflow analyses.) (d) Routine to check array dependencies \nat the leaf clefs.  4.3 Identifying the earliest position We now describe how compute Earliest(u) for \nuse u. Typ\u00adically, dataflow analysis with array sections marks a set of nodes as tearliest such that \na copy of the communication code has to be placed at all these points. This is acceptable if each array \nsection is communicated using a separate runtime call, but for our purposes, this greatly complicates \ncode generation. In different control flow paths, communication for u may be combined with different \nreferences, making it impossible to generate a single version of the original computation containing \nu. The resulting code expansion can be enormous. Therefore, we restrict our search to the single earliest \nposition that dominates the use. Our experience with benchmarks, albeit limited, suggests that further \nsophisti\u00adcation is often unnecessary. The pseudocode for computing Earliest(u) for a use u is shown in \nFigure 8. Claim 4.1 Earliest(u) returns the earliest single dominating communication point dl for use \nU. In Figure 4, Earliest(al ) = Earliest = 7. Traditional array dataflow analysis, which does not insist \non dominating e. Mark candidates: c = CfgNode(Latest(u)) While c # CfgNode(Earliest(u)) do Mark all \nstatements up to Latest(u) in basic block c c = DomTreeparent(c) Mark all statements between Earliest(u) \nand Latest(u) in CfgNode(Earliest(u)), f. Eliminate redundancy: Repeat until no progress: Find statement \nS and CI, C2c CommSet(S) such that CIZsubsumesCI For all S dominated by S disable c1 in CommSet(S ) \ng. GreedyChoose: Let StmtSet(c) = {S: c E CommSet(S)} Consider entries c in increasing order of lStmtSet(c)l: \nFor each S c StmtSet(c), count the number of entries in CommSet(S) with which c can combine (see text) \nPick S with the highest count to place c Delete c from CommSet(S ) for all S # S Place each group of \ncombined entries at the latest position common to the candidate placements of the entries it contains, \nincluding entries disabled during redundancy elimination.  Figure 9: Pseudocode for communication placement. \n(e) Pseu\u00addocode for marking all candidate statements for commuriication placement. (f) Pseudocode for \nglobal redundancy elimination. (g) Simple greedy heuristic to choosea final position from the set of \ncandidates. clefs [14], would lead to Earliest (al) = Earliest = {4, 6}. In both cases, az subsumes al. \nWe prove Claim 4.1 using the following three lemmas. We defer their proofs to the appendix. Lemma 4.2 \ndl dominates u. Lemma 4.3 Let ns be any proper dominator-tree ancestor of dl . Then there exists a regular \ndef dz such that lsArrayDep(dz, u, CNL(dl, u)) returnsTRUE and a path dz+dl *U that bypasses ns. Lemma \n4.4 There is no regular def d4 along a path dl ~di-u such that lsArrayDep(d4, u, CNL(dA, u)) returns \nTRUE, and there is a path from db to u that bypasses dl. Proof of Claim 4.1. Observe that only a node \nthat dom\u00adinates u can serve as a single communication point for u. Lemma 4.2 says that dl = Earliest(u) \ndominates u. Consider all dominator-tree ancestors of u. From this set, Lemma 4.3 rules out all nodes \nthat strictly dominate dl as unsafe. Finally, Lemma 4.4 implies that dl is a safe communication point \nfor u. 4,4 Generating candidate positions Since any safe position to insert a single copy of commu\u00adnication \nfor use u must dominate u, the set of candidate positions has a very simple characterization in terms \nof the following claims. We omit the proofs. Claim 4.5 Starting at the basic block containing Latest(u), \nif we follow parent ltnks in the dominator tree of the CPG, we will reach the basic block containing \nEarliest(u). Claim 4.6 The statements marked in the basic blocks encourstered dursq the dominator tree \ntraversal from c(Latest(u)) up to c(Earliest(u)) are exactly those that are single candidate positions \njor commu nication placement for use u. Our algorithm for finding candidate placements of comm\u00adunication \nis thus extremely simple, and shown in Figure 9(e). In our example (Figure 4), statements 3, 4, 5, and \n6 are not candidates for bl and b2 because they do not dominate those uses. 4,5 Subset elimination Our \ncurrent algorithm gives priority to reducing the volume and number of messages over exploiting overlap \nbenefits or reducing contention for buffers and cache. Given this simplification, we can preclude a large \nnumber of candidate positions without compromising the quality of the solution. Specifically, let CommSet \n(S) denote all communication en\u00adtries associated with the statement S. A given entry can occur in the \nCornmSet of many statements. If for statements S1 and Sz we have CommSet(Sl) C CommSet(Sz), we can reset \nCornmSet(S1) = 0 without losing opportunities for combining or redundancy elimination. For example, in \nFigure 4, the CommSet of statements 1 and 2 can be safely set to 0. In the case that CommSet(Sl) = CommSet(%), \neither set may be emptied at thk stage, because the actual choice governing the placement of communication \nwould be made in the final step (~4.7). 4.6 Redundancy elimination Typically, earlier approaches eliminated \nredundancy by ex\u00adamining the list of communications placed before each state\u00adment, and check each pair \nof entries to see if one subsumes the other. This test is based on the Available Section Descriptor (ASD) \nrepresentation of communication [14]. Briefly, an ASD consists of a pair (D, M), where D represents the \ndata (scalar variable or an array section) being communicated, and M is a mapping function that maps \ndata to the processors which receive that data. A communication (DI, MI ) is made redundant by another \ncommunication (Dz,kfz) if DI ~ Dz, and M~(DI) C Mz(D,). In our case, since there can be many entries \nfor a reference, we have to propagate the redundancy information globally. The pseudocode for eliminating \nredundant comm\u00adunication in the context of our current framework is shown in Figure 9(f). The modification \nis that in each step examining a statement S, the subsumed communication entry is cleared not only from \nCornmSet(S) but from all statements S such that S dominates S . (The dominance ordering prevents a cycle \nof deletions. ) We iterate over statements and communicant ion pairs until no more elimination occurs. \nClaim 4.7 The subset and redundancy elimination steps are safe, i.e., the remainmg communication entries \nare suficient. One implication of the above ordering of eliminations is noteworthy. Consider our running \nexample (Figure 4), specifically the communication due to the uses bl and b2 (ASD(bI) c ASD(b*)). Since \nEarliest = 1 # Earliest = 2, an initial test of redundancy based on earliest placement, followed by candidate \nmarking and subset elimination will not catch the redundancy. Thus, by choosing a later (than the earliest \npossible) placement for bl, we are able to eliminate that communication completely. In contrast, the \nsolution proposed in [14] would move each communication to the earliest point, and reduce the communication \nfor bz to ASD(bZ ) ASD(bl ), while the communication for bl would remain unchanged. The solution obtained \nwith our current method is superior because it reduces the communication startup overhead, and it makes \ncode generation much simpler.  4.7 Choosing from the candidates At this stage we can still have a communication \nentry c in multiple CornmSet s, and we have to arbitrate in favor of one. The goal is to minimize the \ntotal communication cost. In the common message cost model using fixed overhead per message and bandwidth, \nminimizing the cost is N P-hard (also see 56). In practice, simple greedy heuristics work quite well; \nsee Figure 9(g). It is similar to Click s global code motion heuristic [7]: consider the most constrained \ncommunication entry next, and put it where it is compatible in communication pattern (as shown by the \ntest below) with the largest number of other candidate communication. A more refined heuristic would \nuse estimates of message sizes and consider the communication cost if the current entry were combined \nwith a given set of entries. The entries in the CornmSet of each statement can now be partitioned into \ngroups, each group consisting of one or more entries which will be combined into a single aggregate communication \noperation. Any flexibility still available in placing this aggregate can be used to push this communi\u00adcation \nlater if reducing contention for buffers and cache is more important than overlap benefits (as is folk \ntruism for the SP2), or push it earlier if the situation were reversed. Our algorithm places communication \nfor each group at the latest position common to the possible placements of each entry in that group (including \npositions disabled during the previous step for redundancy elimination). Deferring the placement decision \nuntil this final step enables our algorithm to take advantage of any possible placement that leads to \nredundancy elimination or combining benefits, without the drawback of unnecessary movement of communication \nthat uses up more resources or degrades performance. Criteria for communication compatibility. While \nin princi\u00adple, code for any arbitrary communications can be combined into code for a single (and potentially \ncomplex) communi\u00adcation operation, we are interested in combining messages only when the startup overheads \nassociated with all but one of them can be eliminated, leadlng to improved performance. Hence, we view \ntwo communications as compatible for combining if the associated sender-receiver relationships are identical \nor one is a subset of the other. Thus, communications for (DI, Ml) and (Dz, &#38;fz) are combined only \nif Ml = &#38;fz or Ml c MZ. The combined communication is given by (DI U DZ, MZ ). In order to ensure \nbetter performance and for simplicity of code generation, we impose the following additional constraints \non combining. . The combined data size of D1 U Dz must be below a threshold (based on our study reported \nin $3, currently set to 20 KB for SP2), beyond which combining messages leads to diminishing returns \nor even worse performance. When data sizes are unknown, the compiler uses rules of thumb like assuming \nthat NNC and reductions (where volume of data communicated is significantly lower than that involved \nin computation) are operating within the range suitable for combining. The size of DI U D2, as amroxirnated \nbv a siruzle -. .. section descriptor (array sections are not closed un~er the union operation), should \nnot exceed the combined size of DI and Dq by more than a small constant. This descriptor for DI U DZ \nrefers to identical sections of different arrays if DI and D2 correspond to different arrays, and to \na single array otherwise. The check for Ikfl ~ M2 is done in the virtual processor space of template \npositions, as described in [14]. However, we have incorporated extensions to check for equality of mappings \nin physical processor space for nearest-neighbor communication and for mappings to a constant processor \nposition [14].  4.8 Code generation As shown in Figure 6, the step after communication analysis and \noptimization is to insert communication code in the form of subroutine calls to the pHPF runtime library \nroutines, which in turn invoke MPL/M PI. The runt ime library provides a high-level interface through \nwhich the compiler specifies the data being communicated in the form of array sections, and the runtime \nsystem takes care of packing and unpacking of data. For NNC, data is received in overlap regions [30] \nsurrounding the local portion of the arrays. For other kinds of communication involving arrays, data \nis received into a buffer that is allocated dynamically, and the array reference that led to this communication \nis replaced by a reference to the buffer. Redundant message elimination for NNC requires no further change \nto code generation. For other forms of communication, code generation has been modified to en\u00adsure that \nthe array reference corresponding to eliminated communication is also replaced by a reference to the \nbuffer holding non-local data, and that this buffer is deallocated only after its last use is over. Combining \nmessages for different arrays requires changes in code generation and the HPF runtime library routines, \nThe data being sent or received is still represented by a single section descriptor, but now has a list \nof arrays associated with it. Correspondingly, the runtime routines now have to take on additional responsibilities \nof packing and unpacking data for the multiple array sections. Our benchmarks currently emit calls to \na rudimentary runtime library with these features, but this has not been integrated into the compiler \nyet. 5 Performance The analysis described in this paper has been implemented in the pHPF compiler. In \norder to study the potential performance benefits before the code generator and the run-time library \ncould be modified to take advantage of the superior communication placement, we emitted scalarized code \nannotated with human readable communication entries after the analysis and optimization pass of the compiler. \nThe table in Figure 10 shows some compile-time statistics of the reduction in the number of static call \nsites to the communication library. Static message counts are reduced by a factor of roughly 2-9. The \ntrace emitted was then used to generate C programs with calls to MPL/MPICH message passing libraries. \nThis Benchmark Routine Comm Type Original (orig) + Redundancy elimination (nored) + Combined messages(comb) \n (a) SP2 shallow P = 25, n x n, 50 runs shallow gravity gravity trimesh trimesh hydflo hydflo main \nmain main normdot gauss flux hydro NNC NNC SUM NNC NNC NNC NNC 20 8 8 24 13 52 12 14 8 8 24 13 30 12 \n8 4 2 4 4 6 6 (b) SP2 gravity P = 25, n x n x n, 50 runs n-l 00 n=l 25 n-l 50 n=175 n=200 n=225 n-250 \nn-275 n=100 n=125 n-l 50 n-l 75 n-200 n-225 n=250 n=275 n-300 n-325 (c)NOWshallov P=8,n xn,20runs (d)NOWgravity \nP=8,nxnxn,5runs n=400 n=450 n=500 n=lOO n=124 n..l5O n=174 n=200 n=224 n=250 II-274 < n, 5 runs (f) NOW \ntrimesh n=2S 0=32 n=40 n-4S n=56 n-64 P = 8, n x n x n, 5 runs NW 1 0.9 0.s 0.7 0.6 0.5 0.4 0.3 0.2 0.1 \n0 ?$ n=192 n=256 n=320  Figure 10: Performance analysis of the new algorithm: compile-time messagecounts \nand normalized running times. 75 enabled us to study performance improvements not only on the IBM SP2 \nbut also on a network of workstations (NOW) consisting of Spare workstations connected by a Myrinet switch. \nFor each benchmark, the compiler generated two or three versions of code. The baseline pulls communication \ninto outermost possible loops but does not detect redun\u00addancy or perform message scheduling. The next \nversion uses earliest placement for redundancy elimination but does not perform message scheduling or \ncombining. The final version uses the new algorithm. (Note: gravity and trime sh have no redundancy. \n) On the SP2, all codes were compiled using the IBM XIC compiler. On the NOW, we used SUNWspro compiler \ncc. Optimization -03 was used. We report the results in Figure 10. Each -diagram mentions the number \nof processors and the number of runs over which the median performance is reported. In each bar-chart \nthe x-axis is the problem size. For each size two or three bars are plotted, one for each version of \ngenerated code. The y-axis is normalized so that the original code has unit running time, and the dark \nsegment representing network cost shortens as optimizations are applied. These measurements were made \nwith overlap dkabled to clearly account for CPU and network activity. All floating point operations are \non double (eight bytes). shallow and trimesh involve 2-d n x n arrays distributed (BLOCK,BLOCK); shallow \nhas 13 and trimesh has over 25 such arrays. Thus the problem sizes are realistic in that they occupy \nseveral MBytes. Communication time is reduced by a factor of 2-3. This typically translates to 10 40% \noverall running time reduction. gravity uses a 3-d n x n x n array distributed (*, BLOCK, BLIJcK), Thus \nmemory needed even at moderate n is quite staggering, and the graphs again show 10 40% overall gain \nin this reasonable size range. hydflo uses eight 5 x (n+ 2)3 arrays. Therefore even for small n, the \nmemory requirement is enormous, which affects the size range shown. Finally, the SP2 network has lower \noverhead and higher bandwidth than the NOW4, which is evident from the higher overall performance gains \non NOW compared to SP2, although the reduction in communication cost alone is roughly proportionate. \n6 Extensions The basic idea of exploiting flexibility in communication placement is rather general. Although \nfor the sake of practicality our current prototype makes some justified simplifications, it would be \ninteresting to extend the work in two ways. Currently, network architecture is undergoing considerable \nflux. If the CPU-network overlap can be exploited more effectively in future generation machines, the \ncompiler could obtain better performance by considering the trade-offs between enhancing the overlap \nand reducing the number of messages and buffer contention. In particular, the simple subset elimination \nstep (54.5) would have to be dropped, as it could easily degrade the quality of the solution. In fact, \nthe general problem becomes intractable when all of these conflicting optimizations are considered. The \nother direction comprises enhancements for handling special communication patterns like reductions. 6.1 \nGeneral models In a well-known model of communication cost, the prob\u00ad lem of optimally selecting final \ncandidates is AfP-hard, 4NOte ~ha~ we ~,$e MPI 011 both machines, not Active Messages justifying our \nheuristic approach. A runtime call to the communication library in general leads to a many-to-many communication \npattern. Let the inverse bandwidth of the network be scaled to one, and the message startup cost be C \nin these units. The cost of this pattern to a given processor is C times the total number of distinct \nprocessors that it sends to or receives from, plus the total volume of data that it sends or receives. \nIgnoring CPU-network overlap in our bulk-synchronous model, the cost of a pattern is the maximum cost \nover all processors, and the cost of a set of patterns is the sum of their costs. Unfortunately, we can \nshow the following. Claim 6.1 Picking one candidate position for each refer\u00ad ence, such that the total \ncost of all patterns is minimized, is NP-hard. Specifically, there is an approximation-preserving reduction \nfrom chromatic number. Thus it is unlikely that our problem can be solved near\u00adoptimally in the worst \ncase in polynomial time. Like many other ~P-hard problems, the optimization problem can be formulated \nas an integer linear program (ILP). Furthermore, several additional constraints can be incorporated into \nthe ILP, including overlap between CPU and network and message buffer and cache constraints. Profile \ninformation would be crucial to specify this ILP and solve it to adequate precision.  6.2 Special communication \npatterns Reduction communication is dealt with in a special way in the compiler since communication requirement \nis inverted, in a sense, for reductions. Whereas ordinary statements require communication to fill in \nremote values before com\u00adputation can proceed, for reduction the computation occurs first (for the partial \nreduction operation on individual pro\u00adcessors), followed by communication for the global reduction operation \nthat must be completed before the use. Our preliminary prototype does not do reduction candidate marking \nyet. For communications which are marked as reductions, we need to employ a reversed SSA analysis, i.e., \niterating through reached uses of a given definition to determine the latest point at which communication \nmay be safely placed. Conceptually this is identical to the framework in this paper, but the implementation \nis left for future work. The current implementation does allow reduction communications placed at the \nsame point to be combined, as in gravity. 7 Conclusion We have presented an algorithm for global optimization \nof communication code placement in compilers for data\u00adparallel languages like HPF. Modern parallel architectures \ngreatly reward dealing with remote accesses throughout a program in an interdependent manner rather than \nnaively generating messages for each of them. We achieve precisely this enabling optimization. In particular, \nwe explore later placements of communication that preserve the benefits of redundancy elimination (normally \nobtained by moving communication earlier), reduce the wastage of resources like buffers for non-local \ndata, and improve performance due to other factors like fewer messages. Preliminary performance results \nobtained on some HPF benchmarks show significant reduction in communication costs and overall improvements \nin performance of those programs on the IBM SP2 and a cluster of Spares connected by Myrinet. In the \nfuture, we will conduct performance studies to investigate the desirability of including partial redundancy \nelimination as well into our framework. Another area for future work is interprocedural analysis; we \nbelieve that the application of our algorithm across procedure boundaries can often lead to further improvements \nin performance. Acknowledgements. We wish to thank Edith Schonberg, Harini Srinivasan, Ko-Yang Wang, \nCharles Koelbel, Thomas Brandes, Ajay Sethi, Saman Amaraainghe, and Chau-Wen Tseng for helpful discussions, \nand Rich Martin and Lok Liu for help with NOW measurements. A Appendix: Proofs Proof of Lemma 4.2. (By \ncontradiction.) We assume dl is not the pseudo-def at ENTRY,since the latter dominates all nodes in the \nCFG. Let 11 = NL(dl ), and L1 be the loop containing dl. Note that l?l < NL(u) because Earliest will \nnever flag a dl with NL(dl) > NL(u). Assume dl does not dominate u. Then there exist two or more paths: \none from ENTRYto u that bypasses dl, and another from dl to u. If NL(w) = N L(dl ), these two paths imply \nthat there exizts a @clef at level 11 with (at least) two parameters, rl and rz, such that there exist \ntwo non-overlapping backpaths: one from rl to dl, and the other from 72 to the pseudo-def at ENTRYthat \nbypasses dl. (Because of the zero-trip edges, we can ignore other loops nested in L1. ). That there is \nsuch a @-clef at level 11 still holds if NL(u) > NL(dl ), because the preheader node of each loop containing \nu dominates u, and the two (or more) paths converge at the preheader node which is at level tl, at the \nlatest. Test is called on at least one of these ~-defs, say p, before dl during the traversal of Earliest(u), \nstarting from u. During execution of Test(p, u), Rcount gets called on clefs Reaching(?-l ) and Reaching, \nwith nesting level CNL(p, u) = 11. The call at Reachi ng(rl) returns a positive number, because some \nrecursive call inspects dl. Similarly the call at Reaching(rz ) also returns a positive number, because \nsome recursive call inspects ENTRY, Since at least two invocations of Rcou nt return a positive numbers, \nthe @clef, not dl, will be returned as Eadiest (u) if dl does not dominate u, a contradiction. 9 Proof \nof Lemma 4.3. If dl is the pseudo-def at ENTRY, there is nothing to prove. Also, if dl is a regular clef, \nlsArrayDep(dl, u, CNL(dl, u)) must hold for dl to be returned as Earliest(u), in which case dl serves \nas the definition dz in the statement of the lemma. Therefore, we can assume dl is a @clef. By design, \nTest(dl ) returned TRUEbecause at least two Rcount calls on the @parameters of dl returned positive counts. \nBut because of the visit [ ] array, no def is accounted more than once. Therefore the two positive counts \ncan be attributed to two node-disjoint backpaths to two distinct regular clefs (one of which could be \nENTRY). At most onf? of these paths contain TZ3. Let dz be some regular def on the other path such that \nlsArrayDep(a 2, U, CNL(dl, u)) = TRUE. Then there is a dz--f-M path bypassing n3. Proof of Lemma 4.4. \n(By contradiction.) Assume there exists such a dl, According to SSA construction, two cases can occur: \neither (1) dl, as well as dl, dominates u, or (2) d4 has a path, bypassing dl, from it to u through one \nor more +-clefs that dominate u. Case 1. If dl dominates u, di cannot also dominate dl. Otherwise, there \nexists a path from ENTRYto d4 to u that bypasses dl (second condition in the lemma), in which case dl \ncannot dominate u, contradicting Lemma 4.2. Therefore, dl dominates d4 (note that if both dA and dl dominate \nu, one of them must dominate the other), which in turn dominates u. Thus Test(dl, u) is called before \nTest(dl, u) by Earliest(u). Test(d4, u) = TRUE because lsArrayDep(d4, u, CNL(d4, u)) = TRUE,so d4 will \nget returned as Earliest(u); a contradiction. Case 2. In the second case, dl dominates the @clefs. If \nnot, then dl would not dominate u either, (contrary to Lemma 4.2) because there is a path d4~#~u avoiding \ndl. Hence, these @clefs are dominated by dl and are visited before dl by Earliest(u). It follows, from \na similar argument in the proof of Lemma 4.2, that these two paths converge at some node at level CNL(di, \nw), creating a qLdef at level CNL(d4, u). This #-node has (at least) two parameters, rl and rz, such \nthat there exist two non-overlapping paths: one from dl to rl, and the other from dl to r2. When applied \nto rl, Rcount returns positive, possibly because of d4, which satisfies lsArrayDep(dl, u, CNL(dA, u)). \nWhen applied to rz, Rcount returns positive, possibly because of the pseudo-def at ENTRY. Since (at least) \ntwo parameters return positive, the r$def, not dl, is returned by Earliest(u), another contradict ion. \nReferences [1] G. Agarwal, J. Saltz, and R. Das. Interprocedural partial redundancy elimination and its \napplication to distributed memory compilation. In Programming Language Design and Implementation (PLDI), \nLa Jolla, CA, June 1995. [2] F. Allen, M. Burke, P. Charles, R. Cytron, and J. Ferrante, An overview \nof the ptran analysis system for multiprocessing. Proc. ACM 1987 International Conference on Supercomputing, \n1987. Also published in Journal of Parallel and Distributed Computing, Ott., 1988, 5(5) pages 617-640. \n[3] S. P. Amarasinghe and M. S. Lam. Communication optimization and code generation for distributed mem\u00adory \nmachines. In Programming Language Design and Implementation (PLDI), Albuquerque, NM, June 1993. ACM SIGPLAN. \n[4] Z. Bozkus, A. Choudhary, G. Fox, T. Haupt, and S. Ranka. A compilation approach for Fortran 90D/HPF \ncompilers on distributed memory MIMD computers. In Proc. Sixth Annual Workshop on Lan\u00adguages and Compilers \nfor Parallel Computing, Port\u00adland, Oregon, Aug. 1993. [5] T. Brandes. ADAPTOR A compilation system for \ndata-parallel Fortran programs. In C. W. Kessler, editor, Automatic pamllelization new approaches to \ncode generation, data distribution, and performance prediction. Vieweg Advanced Studies in Computer Sci\u00adence, \nVieweg, Wiesbaden, Jan. 1994. [6] J.-D. Choi, R. Cytron, and J. Ferrante. On the efficient engineering \nof ambitious program analysis. IEEE Transactions on Software Engineering, 20(2):105-114, Feb. 1994. \n[7] C. Click. Global code motion global value numbering. In Progmmming Language Design and Implementation \n(PLDI), pages 246-257. ACM SIGPLAN, 1995. [8] R. Cytron, J. Ferrante, B. Rosen, M. Wegman, and F. Zadeck. \nEfficiently computing static single assign\u00adment form and the control dependence graph. ACM Transactions \non Progmmming Languages and Systems, 13(4):451-490, Oct. 1991.  [9] H. P. F. Forum. H@h Performance \nFortran language specification, version 1.0. Technical Report CRPC-TR92225, Rice University, May 1993. \n[10] E. Granston and A. Veidenbaum. Detecting redundant accesses to array data. In PTOC. Supercomputing \n91, pages 854-965, 1991. [11] M. Gupta and P. Banerjee. A methodology for high\u00adlevel synthesis of communication \non multicomputers. In Proc. 6th ACM International Conference on Supercom\u00adputing, Washington D. C., July \n1992. [12] M. Gupta, S. Midkiff, E. Schonberg, V. Seshadri, K. Wang, D. Shields, W.-M. Ching, and T. \nNgo. An HPF compiler for the IBM SP2. In Proc. Supercomput\u00ading 95, San Diego, CA, Dec. 1995.  [13] M. \nGupta and E. Schonberg. Static analysis to reduce synchronization costs in data-parallel programs. In \nPrinciples of Progmmming Languages (POPL), St. Petersburg Beach, FL, Jan. 1996, [14] M, Gupta, E. Schonberg, \nand H. Srinivasan. A uni\u00adfied framework for optimizing communication in data\u00adparallel programs. Technical \nReport RC 19872(87937) 12/14/94, IBM Research, 1994. To appear in IEEE Transactions on Parallel and Distributed \nSystems. [15] S. Hiranandani, K. Kennedy, and C. Tseng. Compiling Fortran D for MIMD distributed-memory \nmachines. Communications of the ACM, 35(8):66-80, Aug. 1992. [16] K. Keeton, T. Anderson, and D. Patterson. \nLogP quan\u00adtified: The case for low-overhead local area networks. In PTOC. Hot Interconnects III: A Symposium \non High Performance Interconnects, Stanford, CA, Aug. 1995. [17] K. Kennedy and N. Nedeljkovic. Combining \ndepen\u00addence and data-flow analyses to optimize communi\u00adcation. In International Parallel Processing Symposium. \nIEEE, 1995. [18] K. Kennedy and A. Sethi. A constraint-based commu\u00adnication placement framework. Technical \nReport CRPC-TR95515-S, CRPC, Rice University, 1995. [19] J. Knoop, 0. Riithing, and B. Steffen. Lazy \ncode motion. In Programming Language Design and Imple\u00admentation (PLDI), San Francisco, CA, June 1992. \n[20] J. Li and M. Chen. Compiling communication-efficient programs for massively parallel machines. IEEE \nTrans\u00adactions on Pamllel and Distributed Systems, 2(3):361 376, July 1991. [21] T. Mowry, M. Lam, and \nA. Gupta. Design and evaluation of a compiler algorithm for prefetching. In Fifih International Conference \non Architectuml Support for Programming Languages and Operating Systems (ASPLOS), pages 62-73. ACM SIGPLAN, \n1992, [22] M. O Boyle and F. Bodin. Compiler reduction of synchronization in shared virtual memory systems. \nIn PTOC. 9th ACM International Conference on Supercom\u00adputing, Barcelona, Spain, July 1995. [23] V. Sarkar. \nThe PTRAN parallel programming system. Parallel Functional Programming Languages and Com\u00adpilers, pages \n309-391, 1991. [24] M. Snir et al. The communication software and parallel environment of the IBM SP2. \nIBM Systems Journal, 34(2):205-221, 1995. [25] C. Stunkel et al. The SP2 high performance switch. IBM \nSystems Journal, 34(2):185-204, 1995. [26] C.-W. Tseng. Compiler optimizations for eliminating barrier \nsynchronization. In Principles and Pmctice of Parallel Programming (PPoPP), Santa Barbara, CA, July 1995. \n[27] R. v Hanxleden and K. Kennedy. Give-n-Take--a balanced code placement framework. In Program\u00adming \nLanguage Design and Implementation (PLDI), Orlando, FL, June 1994. ACM SIGPLAN. [28] M. Wolfe. High Performance \nCompilers for Parallel Computing. Addison-Wesley, 1996. [29] M. Wolfe and U. Banerjee. Data dependence \nand its application to parallel processing. International Journal of Parallel Programming, 16(2):137-178, \nApr. 1987. [30] H. Zima, H. Bast, and M. Gerndt. SUPERB: A tool for semi-automatic MIMD/SIMD parallelization. \nParallel Computing, 6:1-18, 1988.   \n\t\t\t", "proc_id": "231379", "abstract": "Reducing communication cost is crucial to achieving good performance on scalable parallel machines. This paper presents a new compiler algorithm for global analysis and optimization of communication in data-parallel programs. Our algorithm is distinct from existing approaches in that rather than handling loop-nests and array references one by one, it considers all communication in a procedure and their interactions under different placements before making a final decision on the placement of any communication. It exploits the flexibility resulting from this advanced analysis to eliminate redundancy, reduce the number of messages, and reduce contention for cache and communication buffers, all in a unified framework. In contrast, single loop-nest analysis often retains redundant communication, and more aggressive dataflow analysis on array sections can generate too many messages or cache and buffer contention. The algorithm has been implemented in the IBM pHPF compiler for High Performance Fortran. During compilation, the number of messages per processor goes down by as much as a factor of nine for some HPF programs. We present performance results for the IBM SP2 and a network of Sparc workstations (NOW) connected by a Myrinet switch. In many cases, the communication cost is reduced by a factor of two.", "authors": [{"name": "Soumen Chakrabarti", "author_profile_id": "81100424876", "affiliation": "Computer Science Division, U. C. Berkeley, CA", "person_id": "PP43120476", "email_address": "", "orcid_id": ""}, {"name": "Manish Gupta", "author_profile_id": "81100021061", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, P.O. Box, 704, NY", "person_id": "PP42053581", "email_address": "", "orcid_id": ""}, {"name": "Jong-Deok Choi", "author_profile_id": "81423596242", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, P.O. Box, 704, NY", "person_id": "PP43136027", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/231379.231391", "year": "1996", "article_id": "231391", "conference": "PLDI", "title": "Global communication analysis and optimization", "url": "http://dl.acm.org/citation.cfm?id=231391"}