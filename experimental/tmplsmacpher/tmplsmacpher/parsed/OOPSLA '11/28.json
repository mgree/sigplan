{"article_publication_date": "10-22-2011", "fulltext": "\n Enhancing Locality for Recursive Traversals of Recursive Structures Youngjoon Jo and Milind Kulkarni \nSchool of Electrical and Computer Engineering Purdue University {yjo,milind}@purdue.edu Abstract While \nthere has been decades of work on developing au\u00adtomatic, locality-enhancing transformations for regular \npro\u00adgrams that operate over dense matrices and arrays, there has been little investigation of such transformations \nfor irregular programs, which operate over pointer-based data structures such as graphs, trees and lists. \nIn this paper, we argue that, for a class of irregular applications we call traversal codes, there exists \nsubstantial data reuse and hence opportunity for locality exploitation. We develop a novel optimization \ncalled point blocking, inspired by the classic tiling loop transformation, and show that it can substantially \nenhance temporal locality in traver\u00adsal codes. We then present a transformation and optimiza\u00adtion framework \ncalled TreeTiler that automatically detects opportunities for applying point blocking and applies the \ntransformation. TreeTiler uses autotuning techniques to de\u00adtermine appropriate parameters for the transformation. \nFor a series of traversal algorithms drawn from real-world ap\u00adplications, we show that TreeTiler is able \nto deliver perfor\u00admance improvements of up to 245% over an optimized (but non-transformed) parallel baseline, \nand in several cases, sig\u00adni.cantly better scalability. Categories and Subject Descriptors D.3.4 [Processors]: \n[compilers,optimization] General Terms Languages Keywords locality transformations, irregular programs, \ntree traversals Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. OOPSLA 11, October 22 27, 2011, Portland, Oregon, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0940-0/11/10. \n. . $10.00 1. Introduction It has long been understood that locality is a crucial factor in delivering \nhigh performance scienti.c applications. Over the past several decades, there has been substantial work \non automatically transforming regular programs, which operate over dense matrices and arrays, to enhance \nlocality. These investigations have led to the creation of catalogs of trans\u00adformations and techniques \nto determine when those trans\u00adformations are legal and effective [16]. In contrast, there has been relatively \nlittle attention paid to locality in irregular programs, which operate over pointer-based structures \nsuch as trees and graphs. While there have been various tech\u00adniques and transformations proposed for \nenhancing the lo\u00adcality of speci.c irregular applications [2, 22, 24, 29], gen\u00aderal approaches to improving \nthe locality of broad classes of irregular applications are few and far between. This lack of progress \nis unsurprising. Pointer-based data structures are highly dynamic and the resulting memory\u00adaccess patterns \nof applications that use them are highly input-dependent and unpredictable. As a result, the standard \ntechniques for reasoning about locality in regular applica\u00adtions are simply inapplicable1. The apparent \nlack of structure in irregular programs can be misleading. While the particular set of concrete memory \naccesses may exhibit little regularity, at an abstract level there are organizing principles governing \nthese accesses, such as the topology of the irregular data structure, or the nature of operations on \nthat data structure. Recent work by Pingali et al. has suggested that there may, indeed, be signi.cant \nstructure latent in irregular applications [25]. Can this structure be exploited to transform irregular \napplications so as to enhance locality? In this paper, we focus on enhancing and exploiting tem\u00adporal \nlocality in algorithms that perform repeated traversals of recursive structures, such as trees, DAGs \nand graphs. Such 1 While there has been progress, in the form of complex compiler analyses like shape \nanalysis [11, 27], in discerning properties of irregular data structures (primarily, their topology), \nthese techniques have mostly been put to ends such as veri.cation and parallelization, rather than locality \nenhancement.  applications are widespread; examples include scienti.c al\u00adgorithms such as Barnes-Hut \n[3], graphics algorithms such as bounding volume hierarchies [34] and Lightcuts [36], and data mining \nalgorithms such as nearest neighbor and point correlation [12]. The goal of each of these algorithms \nis to compute a value (force, illumination, etc.) for each of a set of entities (bodies, rays, etc.). \nThis computation is per\u00adformed by constructing a tree-based acceleration structure and then traversing \nthat structure for each entity to compute the desired value. In other words, these algorithms perform \nrepeated series of tree traversals. The tree traversals performed by the aforementioned al\u00adgorithms are \nhighly irregular in nature. This is because the structure of the tree is determined primarily by the \ninput data and because the actual layout of the tree in memory is unpre\u00addictable. Nevertheless, the trees \nconstructed in these algo\u00adrithms are traversed numerous times, leading to signi.cant data reuse. Any \ntime there is data reuse, there may be an opportunity to exploit temporal locality. By drawing an analogy \nwith loop transformations in regu\u00adlar programs, where loop tiling has proved to be an effective technique \nto improve locality in matrix codes, we develop a novel, locality-enhancing transformation for tree traversal \ncodes that we call point blocking. Because point blocking can be applied to any parallelizable tree traversal \ncode, it is a general transformation, and can be effectively employed in all the applications mentioned \npreviously. We then describe TreeTiler, a compiler framework that automatically identi.es regions of \nprograms where data reuse implies that point blocking might be successfully ap\u00adplied. In regular programs, \ndata reuse often arises in nested loops that manipulate arrays and matrices, and can be read\u00adily identi.ed. \nIn irregular programs, in contrast, data reuse is often masked by pointer-manipulation operations. TreeTiler \nidenti.es code where point blocking might be performed by looking for recursive traversals of recursive \nstructures. If point blocking is legal for such a traversal, TreeTiler auto\u00admatically performs the transformation. \nPoint blocking, like loop tiling, requires that optimiza\u00adtion parameters be carefully tuned to match \nboth the ap\u00adplication and the architecture. Autotuning has emerged as a popular approach to parameter \nselection as it can select optimization parameters for a particular execution scenario without programmer \nintervention [31, 33, 37], a necessity for any automated transformation framework. Because ir\u00adregular \nprograms are highly input-dependent, TreeTiler uses run-time pro.ling to guide its selection of parameters \nfor point-blocking. Contributions The contributions of this paper are threefold: 1. We present an abstract \nmodel of tree traversal codes that allows reasoning about locality effects. We then describe a novel \ntransformation, point blocking, that applies to recursive traversal of recursive structures, such as \ntree traversals (Section 2). 2. We develop TreeTiler, a compiler that identi.es opportu\u00adnities for applying \npoint blocking and automatically per\u00adforms the transformation (Section 3). 3. We implement two autotuners \nthat use run-time pro.ling to automatically tune the parameters of a point-blocked application (Section \n4).  In Section 5, we evaluate the effectiveness of point block\u00ading, and the TreeTiler transformation \nand tuning framework, on a suite of .ve applications that perform tree traversals. The automatically \ntransformed applications achieve perfor\u00admance improvements of up to 245% over hand-optimized parallel \nbaselines that do not use point-blocking. Further, TreeTiler s autotuning is able to select transformation \npa\u00adrameters that are competitive with hand-tuned transforma\u00adtions. For several benchmarks, the locality \nbene.ts of point blocking also result in signi.cantly greater scalability. 2. Transformations for tree-traversal \ncodes In this section, we begin by discussing some background on applications that perform recursive \ntraversals over recursive data structure. We next describe an abstract model for rea\u00adsoning about the \nlocality properties of such applications. Fi\u00adnally, we present the point blocking optimization, and dis\u00adcuss \nits locality effects in relation to our abstract model. 2.1 Background As discussed in the introduction, \nwe are interested in appli\u00adcations that perform repeated traversals of recursive struc\u00adtures such as \ntrees, DAGs and graphs. Because these re\u00adpeated traversals each access the same data structure, there \nis an abundance of data reuse, and hence locality, to be ex\u00adploited. These applications all follow the \nsame general pattern. To explain this pattern, we will make reference to perhaps the canonical tree-traversal \nalgorithm, Barnes-Hut [3], whose pseudocode is given in Figure 12. The outer loop of a traver\u00adsal code \niterates over a set of entities or points; in Barnes-Hut, these are the bodies in space (line 1). For \neach point, a recursive structure, the environment is traversed; in Barnes-Hut, the environment is an \noct-tree built over the entities (line 2). This traversal is performed recursively: at each node in the \nenvironment, a check is made to see if the traver\u00adsal should be stopped (line 8) or whether it should \ncontinue (lines 11 14). Because the traversal is recursive, it explores the data structure in depth-.rst \norder. Simple locality-enhancing transformations Because the oct-tree in Barnes-Hut is a highly dynamic \ndata structure, exploiting locality in the traversals is dif.cult. However, as 2 The full Barnes-Hut \nalgorithm consists of several phases; we concentrate on the force computation phase, which is both the \nmost time-consuming phase, and the phase with the computational structure we are interested in.  1 Set<Point> \npoints = /* entities */ 2 OctTreeCell root = /* environment */ 3 foreach ( Point p : points ) { 4 Recurse(p, \nroot); 5 } 6 7 void Recurse(Point p, OctTreeCell c) { 8 if (farEnough(p, c.cofm) || c . isLeaf ) { 9 \nupdateContribution(p, c.cofm); 10 } else { 11 foreach (OctTreeCell child : c.children) { 12 if ( child \n!= null ) 13 Recurse(p, child ); 14 } 15 } 16 } Figure 1. Force computation algorithm for Barnes-Hut \n# Objects Traversal size (Bytes) L2 miss rate (%) % Improvement in cycles over un-optimized 10000 63, \n944 21.61 67.3 100000 108, 656 44.97 45.9 1000000 139, 616 55.30 26.4 Table 1. Ef.cacy of sorting optimization \nfor various traver\u00adsal sizes the same tree is traversed by each point (the outer loop in Figure 1), there \nis signi.cant data reuse. Points that are nearby in space are likely to perform very similar traversals \nof the oct-tree, visiting the same set of tree nodes. Thus, if these traversals are performed consecutively, \nthe oct-tree nodes visited during the .rst traversal are likely to remain in cache during the second \ntraversal, exploiting temporal locality. Such a locality-exploiting order of traversals can be ar\u00adranged \nby processing the points according to their geometric position (e.g., with a space-.lling curve), so \nthat adjacent points in the sorted order are nearby geometrically [2, 29]; we use this optimization in \nthe baseline we use in the eval\u00aduation of Section 5. Though the optimization has only been applied to \nBarnes-Hut in the literature, we note that analo\u00adgous transformations can be applied to any traversal \ncode: if the points are sorted to maximize the overlap between con\u00adsecutive traversals, locality can \nbe improved. This optimization loses its effectiveness as the traversal sizes get larger. With a suf.ciently \nlarge traversal, the least recently visited nodes of the oct-tree will be evicted from cache, and hence \nwhen the next point is processed those nodes will have to be brought back in to cache, incurring additional \nmisses. Table 1 shows, for several tree sizes, the average traversal size, the L2 miss rate of an optimized \nim\u00adplementation, and the % improvement in cycles over an un\u00adoptimized implementation. The test system \nis a dual-core In\u00adtel Pentium with 32K L1 data cache per core and 1M shared L2 cache. The ef.cacy of \nsorting is clear for small sizes: in an input with 10,000 points, the sorting optimization im\u00adproves \nruntime by 67%. However, with an input of 1 million points, the sorting optimization has much higher \nmiss rates, and only improves runtime by 26% compared to the un\u00ad 1 Set<Point > points = / * entities \nin algorithm */ 2 Set<Point > objects = / * environment objects */ 3 OctTreeCell root = buildTreeAndComputeCofM(objects); \n4 foreach ( Point p : points ) { 5 foreach (OctTreeCell c : traverse(root, p)) { 6 if (farEnough(p, c.cofm) \n|| c. isLeaf ) { 7 updateContribution(p, c.cofm); 8 } 9 }10 } Figure 2. Abstract algorithm for tree-traversal \noptimized version. Clearly, a more sophisticated optimiza\u00adtion is necessary to continue exploiting locality \nas traversal sizes get larger.  2.2 An abstract model Reasoning about locality in codes that traverse \nrecursive structures is dif.cult for a number of reasons. First, unlike in regular applications, the \nstructure of the key data struc\u00adtures is highly input-dependent. The oct-tree generated in Barnes-Hut \nis dependent on the particular locations of the points in the system. Furthermore, the data structures \nare dy\u00adnamically allocated, and hence can be scattered throughout memory. Finally, the traversals are \nnot uniform; a traversal can be truncated (e.g., due to the distance check in line 8 of Figure 1), and \ntraversals for two different points are not necessarily similar. However, we can still reason about locality \nby consider\u00ading the behavior of a traversal algorithm in a more abstract sense. Rather than viewing a \ntraversal as a recursive, depth\u00ad.rst walk of a data structure, we can instead visualize the traversal \nin terms of the actual nodes touched. Fundamen\u00adtally, processing a single point requires accessing some \nse\u00adquence of tree nodes. The particular arrangement within the tree of those nodes is irrelevant; all \nthat matters is the ulti\u00admate sequence in which the nodes are touched. If we imag\u00adine that there is an \noracle function traverse that generates the sequence of nodes accessed while processing a particular \npoint, we can rewrite the code of Figure 1 as shown in Fig\u00adure 2. In other words, we can view the algorithm \nas a simple, doubly-nested loop. Notably, for the purposes of locality, the behavior of the original \nBarnes-Hut code is equivalent to the abstract algorithm. All that matters is the sequence of accesses; \nthe additional computations required to determine whether to continue a traversal or not do not affect \nlocal\u00adity. Thus, the sequences of memory accesses for the code in Figure 1 and Figure 2 are identical. \nRecursive traversals as outer products This abstract algo\u00adrithm provides insight into why sorting the \npoints (as dis\u00adcussed in Section 2.1) is useful for locality. Consider the be\u00adhavior of two consecutive \npoints, p1 and p2. In the unsorted algorithm, there is little overlap between traverse(p1) and traverse(p2). \nMost of the inner-loop accesses for the p2 iteration will result in cache misses. However, sorting the \n \n\t\t\t", "proc_id": "2048066", "abstract": "<p>While there has been decades of work on developing automatic, locality-enhancing transformations for regular programs that operate over dense matrices and arrays, there has been little investigation of such transformations for irregular programs, which operate over pointer-based data structures such as graphs, trees and lists. In this paper, we argue that, for a class of irregular applications we call traversal codes, there exists substantial data reuse and hence opportunity for locality exploitation. We develop a novel optimization called point blocking, inspired by the classic tiling loop transformation, and show that it can substantially enhance temporal locality in traversal codes. We then present a transformation and optimization framework called TreeTiler that automatically detects opportunities for applying point blocking and applies the transformation. TreeTiler uses autotuning techniques to determine appropriate parameters for the transformation. For a series of traversal algorithms drawn from real-world applications, we show that TreeTiler is able to deliver performance improvements of up to 245% over an optimized (but non-transformed) parallel baseline, and in several cases, significantly better scalability.</p>", "authors": [{"name": "Youngjoon Jo", "author_profile_id": "81464662508", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2839212", "email_address": "yjo@purdue.edu", "orcid_id": ""}, {"name": "Milind Kulkarni", "author_profile_id": "81331496893", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2839213", "email_address": "milind@purdue.edu", "orcid_id": ""}], "doi_number": "10.1145/2048066.2048104", "year": "2011", "article_id": "2048104", "conference": "OOPSLA", "title": "Enhancing locality for recursive traversals of recursive structures", "url": "http://dl.acm.org/citation.cfm?id=2048104"}