{"article_publication_date": "10-22-2011", "fulltext": "\n Type Checking Modular Multiple Dispatch with Parametric Polymorphism and Multiple Inheritance Eric \nAllen Justin Hilburn Scott Kilpatrick Victor Luchangco Oracle Labs Oracle Labs University of Texas Oracle \nLabs eric.allen@oracle.com justin.hilburn@oracle.com at Austin victor.luchangco@oracle.com scottk@cs.utexas.edu \n Sukyoung Ryu David Chase Guy L. Steele Jr. KAIST Oracle Labs Oracle Labs sryu.cs@kaist.ac.kr david.r.chase@oracle.com \nguy.steele@oracle.com Abstract In previous work, we presented rules for de.ning overloaded functions \nthat ensure type safety under symmetric multiple dispatch in an object-oriented language with multiple \ninher\u00aditance, and we showed how to check these rules without requiring the entire type hierarchy to be \nknown, thus sup\u00adporting modularity and extensibility. In this work, we extend these rules to a language \nthat supports parametric polymor\u00adphism on both classes and functions. In a multiple-inheritance language \nin which any type may be extended by types in other modules, some overloaded functions that might seem \nvalid are correctly rejected by our rules. We explain how these functions can be permitted in a language \nthat additionally supports an exclusion relation among types, allowing programmers to declare nominal \nexclusions and also implicitly imposing exclusion among different instances of each polymorphic type. \nWe give rules for computing the exclusion relation, deriving many type exclusions from declared and implicit \nones. We also show how to check our rules for ensuring the safety of overloaded functions. In particular, \nwe reduce the problem of handling parametric polymorphism to one of determining subtyping relationships \namong universal and existential types. Our system has been implemented as part of the open-source Fortress \ncompiler. Categories and Subject Descriptors D.3.3 [Programming Languages]: Language Constructs and Features \nclasses and objects, inheritance, modules, packages, polymorphism General Terms Languages Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA 11 October \n22 27, 2011, Portland, Oregon, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0940-0/11/10. . . $10.00 \nKeywords object-oriented programming, multiple dispatch, symmetric dispatch, multiple inheritance, overloading, \nmod\u00adularity, methods, multimethods, static types, run-time types, ilks, components, separate compilation, \nFortress, meet rule 1. Introduction A key feature of object-oriented languages is dynamic dis\u00adpatch: \nthere may be multiple de.nitions of a function (or method) with the same name we say the function is \nover\u00adloaded and a call to a function of that name is resolved at run time based on the run-time types \nwe use the term ilks of the arguments, using the most speci.c de.nition that is applicable to arguments \nhaving those particular ilks. With single dispatch, a particular argument is designated as the receiver, \nand the call is resolved only with respect to that argument. With multiple dispatch, the ilks of all \narguments to a call are used to resolve the call. Symmetric multiple dis\u00adpatch is a special case of multiple \ndispatch in which all ar\u00adguments are considered equally when resolving a call. Multiple dispatch provides \na level of expressivity that closely models standard mathematical notation. In particu\u00adlar, mathematical \noperators such as + and = and . and es\u00adpecially \u00b7 and \u00d7 have different de.nitions depending on the types \n(or even the number) of their operands; in a language with multiple dispatch, it is natural to de.ne \nthese operators as overloaded functions. Similarly, many operations on col\u00adlections such as append and \nzip have different de.nitions depending on the ilks of two or more arguments. In an object-oriented language \nwith symmetric multiple dispatch, some restrictions must be placed on overloaded function de.nitions \nto guarantee type safety. For example, consider the following overloaded function de.nitions: f (a: Object,b: \nZ): Z =1 f (a: Z,b: Object): Z =2 To which of these de.nitions ought we dispatch when f is called with \ntwo arguments of ilk Z? (We assume that Z is a subtype of Object, written Z <: Object .)  Castagna et \nal. [4] address this problem in the context of a type system without parametric polymorphism or multiple \ninheritance by requiring every pair of overloaded function de.nitions to satisfy the following properties: \n(i) whenever the domain type1 of one is a subtype of the domain type of the other, the return type of \nthe .rst must also be a subtype of the return type of the second; and (ii) whenever the domain types \nof the two de.nitions have a common lower bound (i.e., a common nontrivial2 subtype), there is a unique \nde.nition for the same function whose domain type is the greatest lower bound of the domain types of \nthe two de.nitions. Thus, to satisfy the latter property for the example above, the programmer must provide \na third de.nition, such as: f(a: Z,b: Z): Z =3 We call this latter property the Meet Rule because it \nis equivalent to requiring that the de.nitions for each over\u00adloaded function form a meet semilattice \npartially ordered by the subtype relation on their domain types, which we call the more speci.c than \nrelation.3 The Meet Rule guarantees that there are no ambiguous function calls at run time. We call the \n.rst property above the Return Type Rule (or Subtype Rule). It ensures type preservation when a function \ncall is resolved at run time (based on the ilks of the argument values) to a different (and more speci.c) \nde.nition than the most speci.c one that could be determined at compile time (based on the types of the \nargument expressions). In this paper, we give new Meet and Return Type Rules that ensure safe overloaded \nfunctions in a language that sup\u00adports symmetric multiple dispatch, multiple inheritance, and parametric \npolymorphism for both types and functions (i.e., generic types and generic functions), as does the Fortress \nlanguage we are developing [1]. We prove that these rules guarantee type safety. This extends previous \nwork [2] in which we gave analogous rules, and proved the analogous result, for a core of Fortress that \ndoes not support generics. To handle parametric polymorphism, it is helpful to have an intuitive interpretation \nfor generic types and functions. One way to think about a generic type such as List[T ] (a list with \nelements of type T type parameter lists in Fortress are delimited by white square brackets) is that it \nrepresents an in.nite set of ground types: List[Object] (lists of ob\u00adjects), List[String] (lists of strings), \nList[Z] (lists of inte\u00adgers), and so on. An actual type checker must have rules for working with uninstantiated \n(non-ground) generic types, but for many purposes this model of an in.nite set of ground 1 The domain \ntype of a function de.nition is the type of its parameter. Hereafter we consider every function to have \na single parameter; the ap\u00adpearance of multiple parameters denotes a single tuple parameter. 2 A type \nis a nontrivial subtype of another type if it is not the trivial bottom type de.ned in the next section. \n3 Despite its name, this relation, like the subtype relation, is re.exive: two function de.nitions with \nthe same domain type are each more speci.c than the other. In that case, we say the de.nitions are equally \nspeci.c. types is adequate for explanatory purposes. Not so, how\u00adever, for generic functions. For some \ntime during the development of Fortress, we considered an interpretation of generic functions analogous \nto the one above for generic types; that is, the generic func\u00adtion de.nition:4 `\u00b4 tail[X] x: List[X] \n: List[X] = e should be understood as if it denoted an in.nite set of monomorphic de.nitions: `\u00b4 tail \nx: List[Object] : List[Object] = e `\u00b4 tail x: List[String] : List[String] = e `\u00b4 tail x: List[Z] : List[Z] \n= e ... The intuition was that for any speci.c function call, the usual rule for dispatch would then \nchoose the appropriate most speci.c de.nition for this (in.nitely) overloaded function. Although that \nintuition worked well enough for a sin\u00adgle polymorphic function de.nition, it failed utterly when we \nconsidered multiple function de.nitions. For example, a programmer might want to provide de.nitions for \nspeci.c monomorphic special cases, as in: `\u00b4 tail[X] x: List[X] : List[X] = e1 `\u00b4 tail x: List[Z] : List[Z] \n= e3 If the interpretation above is taken seriously, this would be equivalent to: `\u00b4 tail x: List[Object] \n: List[Object] = e1 `\u00b4 tail x: List[String] : List[String] = e1 `\u00b4 tail x: List[Z] : List[Z] = e1 ... \n`\u00b4 tail x: List[Z] : List[Z] = e3 which is ambiguous for calls in which the argument is of type List[Z] \n. It gets worse if the programmer wishes to handle an in.nite set of cases specially. It would seem natural \nto write: `\u00b4 tail[X] x: List[X] : List[X] = e1 `\u00b4 tail[X<: Number] x: List[X] : List[X] = e2 to handle \nspecially all cases where X is a subtype of Number. But the model would regard this as an overloaded \nfunction with an in.nite number of ambiguities. It does not suf.ce to break ties by choosing the instan\u00adtiation \nof the more speci.c generic de.nition. Consider the following overloaded de.nitions: quux[X](x: X): Z \n=1 quux(x: Z): Z =2 Intuitively, we might expect that the call quux(x) evaluates to 2 whenever the ilk \nof x is a subtype of Z, and to 1 4 The .rst pair of white square brackets delimits the type parameter \ndecla\u00adrations, but the other pairs of white brackets provide the type arguments to the generic type List. \n otherwise. However, under the in.nite set of monomorphic de.nitions interpretation, the call quux(x) \nwhen x has type N <: Z would evaluate to 1 because the most speci.c monomorphic de.nition would be the \nthe instantiation of the generic de.nition with N. It is not even always obvious which function de.nition \nis the most speci.c one applicable to a particular call in the presence of overloaded generic functions: \nthe overloaded de.nitions might have not only distinct argument types, but also distinct type parameters \n(even different numbers of type parameters), so the type values of these parameters make sense only in \ndistinct type environments. For example, con\u00adsider the following overloaded function de.nitions: foo \nX<: Object](x: X, y: Object): Z =1 foo[ Y<: Number](x: Number,y: Y ): Z =2 The type parameter of the \n.rst de.nition denotes the type of the .rst argument, and the type parameter of the second de.nition \ndenotes the type of the second argument; they bear no relation to each other. How should we compare such \nfunction de.nitions to determine which is the best to dispatch to? How can we ensure that there even \nis a best one in all cases? Under the in.nite set of monomorphic de.nitions in\u00adterpretation, these de.nitions \nwould be equivalent to: foo(x: Object,y: Object): Z =1 foo(x: Number,y: Object): Z =1 foo(x: Z,y: Object): \nZ =1 ... foo(x: Number,y: Number): Z =2 foo(x: Number,y: Z): Z =2 ... When foo is called on two arguments \nof type Z, both foo(x: Z,y: Object) and foo(x: Number,y: Z) are ap\u00adplicable (assuming Z <: Number <: \nObject ). Neither is more speci.c than the other, and moreover no de.nition of foo(x: Z,y: Z) has been \nsupplied to satisfy the Meet Rule, so this overloading is ambiguous. We propose to avoid such ambiguities \nby adopting an al\u00adternate model for generic functions, similar to one proposed by Bourdoncle and Merz \n[3], in which each function de.ni\u00adtion is regarded not as an in.nite set of de.nitions, but rather as \na single de.nition whose domain type is existentially quanti.ed over its type parameters. (A monomorphic \nde.\u00adnition is then regarded as a degenerate generic de.nition.) In this model, overloaded function de.nitions \nare (partially) or\u00addered by the subtype relation on existential types. Adapting dispatch and the Meet \nRule to use this new partial order is straightforward. Adapting the Return Type Rule is somewhat more \ncomplicated, but checking it reduces to checking sub\u00adtyping relationships between universal types. Adopting \nthis model has made overloaded generic functions in Fortress both tractable and effective. In particular, \nthe overloading of foo just shown is permitted and is not ambiguous, because under this interpretation \nthe second de.nition is more spe\u00adci.c than the .rst. In providing rules to ensure that any valid set \nof over\u00adloaded function de.nitions guarantees that there is always a unique function to call at run time, \nwe strive to be maximally permissive: A set of overloaded de.nitions should be disal\u00adlowed only if it \npermits ambiguity that cannot be resolved at run time. Unfortunately, this goal is in tension with another \nrequirement, to support modularity and extensibility. In par\u00adticular, we assume the program will be composed \nof several modules, and that types de.ned in one module may be ex\u00adtended by types de.ned in other modules. \nWe want to be able to check the rules separately for each module, and not have to recheck a module when \nsome other module extends its types. The dif.culty is due to multiple inheritance: Because the type hierarchy \nde.ned by a module may be extended by types in other modules, two types may have a common nontrivial \nsubtype even if no type declared in this module extends them both. Thus, for any pair of overloaded func\u00adtion \nde.nitions with incomparable domain types (i.e., nei\u00adther de.nition is more speci.c than the other), \nthe Meet Rule requires some other de.nition to resolve the potential ambiguity. Because explicit intersection \ntypes cannot be ex\u00adpressed in Fortress, it is not always possible to provide such a function de.nition. \nConsider, for example, the following overloaded function de.nitions: print(s: String): () print(i: Z): \n() Although this overloading may seem intuitively to be valid, in a multiple-inheritance type system \nthat allows any type to be extended by some other module, one could de.ne a type StringAndInteger that \nextends both String and Z. In that case, a call to print with an argument of type StringAndInteger would \nbe ambiguous. Thus, this over\u00adloading must be rejected by our overloading rules. To address this problem, \nFortress enables programmers to declare nominal exclusion , restricting how type construc\u00adtors may be \nextended, and uses this to derive an exclusion relation on types. Types related by exclusion must not \nhave any nontrivial subtype in common. Many languages enforce and exploit exclusion implicitly. For example, \nsingle inheri\u00adtance ensures that incomparable types exclude each other. If the domains of two overloaded \nfunction de.nitions exclude each other, then these de.nitions can never both be applica\u00adble to the same \ncall, so no ambiguity can arise between them. In the example above, if String and Z exclude each other,5 \nthen the overloaded de.nitions of print above are valid. We already exploited exclusion in our prior \nwork on Fortress without generics, but the constructs Fortress pro\u00advides for explicitly declaring exclusion \nare insuf.cient for 5 Indeed, String and Z are declared to exclude each other in the Fortress standard \nlibrary.  allowing some intuitively appealing overloaded functions involving generic types. In particular, \nwe could not guaran\u00adtee type safety when a type extends multiple instantiations of a generic type. Implicitly \nforbidding such extension a property we call multiple instantiation exclusion allows these intuitively \nappealing overloaded functions. 2. Preliminaries In this section, we describe the standard parts of the \ntype system we consider in this paper, and establish terminol\u00adogy and notation for entities in this system. \nTo minimize the syntactic overhead, we avoid introducing a new language and instead give a straightforward \nformalization of the type system. Novel parts of the type system, including the rules for type checking \noverloaded function declarations, are de\u00adscribed in later sections. 2.1 Types Following Kennedy and \nPierce [8], we de.ne a world of types ranged over by metavariables S, T , U, V , and W . Types are of \n.ve forms: type variables (ranged over by metavariables X, Y , and Z); constructed types (ranged over \nby metavariables K, L, M and N), consisting of the spe\u00adcial constructed type Any and type constructor \napplications, written C[T ] , where C is a type constructor and T is a list of types; structural types, \nconsisting of arrow types and tuple types; compound types, consisting of intersection types and union \ntypes; and the special type Bottom, which represents the uninhabited type (i.e., no value belongs to \nBottom). The abstract syntax of types is de.ned as follows (where A indi\u00adcates a possibly empty comma-separated \nsequence of syn\u00adtactic elements A): T ::= X type variable | Any | type constructor application C[T] | \nT . T arrow type | (T) tuple type | T n T intersection type | T . T union type | Bottom A type may have \nmultiple syntactic forms.6 In particular, a tuple type of length one is synonymous with its element type, \nand a tuple type with any Bottom element is synony\u00admous with Bottom. In addition, any types that are \nprovably equivalent as de.ned below are also synonymous. As in Fortress, compound types intersection \nand union types and Bottom are not .rst-class: these forms of types cannot be written in a program; rather, \nthey are used by the type analyzer during type checking. For example, type vari\u00adables may have multiple \nbounds, so that any valid instantia\u00adtion of such a variable must be a subtype of the intersection of \nits bounds. 6 We abuse terminology by not distinguishing type terms and types. Type checking is done \nin the context of a class table T , which is a set of type constructor declarations (at most one declaration \nfor each type constructor) of the following form: C[X<: {M}] <: {N} where the only type variables that \nappear in M and N are those in X. This declares the type constructor C, and each Xi is a type parameter \nof C with bounds Mi. As usual for languages with nominal subtyping, we allow recursive and mutually recursive \nreferences in T (i.e., a type constructor can be mentioned in the bounds and supertypes of its own and \nother type constructors declarations). We say that C extends a type constructor D if Ni = D[T ] for some \nNi and T . A class table is well-formed if every type that appears in it is well-formed, as de.ned below, \nand the extends relation over type constructors is acyclic. The type constructor declaration above speci.es \nthat the constructed type C[U] (i) is well-formed (with respect to T ) if and only if |U| = |X| and Ui \n<:[U/X]Mij for 1 = i =|U| and 1 = j =|Mi| (where <: is the subtyping relation de.ned below, and [U/X]Mij \nis Mij with Uk sub\u00adstituted for each occurrence of Xk in Mij for 1 = k =|U |); and (ii) is a subtype \nof [U/X]Nl for 1 = l =|N|. The class table induces a (nominal) subtyping relation <: over the con\u00adstructed \ntypes by taking the re.exive and transitive closure of the subtyping relation derived from the declarations \nin the class table. In addition, every type is a subtype of Any and a supertype of Bottom. We say that \na type T (of any form) is well-formed with respect to T , and write T .T , if every constructed type \noccurring in T is well-formed with respect to T . Typically, the class table is .xed and implicit, and \nwe assume it is well\u00adformed and often omit explicit reference to it. Given the type constructor declaration \nabove, we denote the set of explicitly declared supertypes of the constructed type C[T ] by: C[T ].extends \n= {[T /X]N} and the set of ancestors of C[T ] (de.ned recursively) by:  ancestors(C[T ])= {C[T ]}. ancestors(M). \nM.C[T ].extends To reduce clutter, nullary applications are written without brackets; for example, C[] \nis written C . We also elide the braces delimiting a singleton list of either bounds of a type parameter \nor supertypes of a class in a type constructor declaration. We extend the subtyping relation to structural \nand com\u00adpound types in the usual way: Arrow types are contravariant in their domain types and covariant \nin their return types. One tuple type is a subtype of another if and only if they have the same number \nof elements, and each element of the .rst is a subtype of the corresponding element of the other. An \nin\u00adtersection type is the most general type that is a subtype of each of its element types, and a union \ntype is the most spe\u00adci.c type that is a supertype of each of its element types.  To extend the subtyping \nrelation to type variables, we require a type environment, which maps type variables to bounds: .= X<: \n{M } In the context of ., each type variable Xi is a subtype of each of its bounds Mij . Note that the \ntype variables Xi may appear within the bounds Mij. We write . f S<: T to indicate the judgment that \nS is a subtype of T in the context of .. When . is empty, we write this judgment simply as S<: T . And \nwe say that the types S and T are equivalent, written S = T , when S<: T and T<: S. Henceforth, given \na type environment, we consider only types whose (free) type variables are bound in the type environment. \nBecause our type language does not involve any type variable binding type variables are bound only by \ngeneric type constructor or function declarations the set of free type variables of T , written FV (T \n), is de.ned as the set of all type variables syntactically occurring within T .  2.2 Extensibility \nTo enable modular type checking and compilation, we do not assume that the class table is complete; there \nmight be declarations yet unknown. Speci.cally, we cannot infer that two constructed types have no common \nconstructed subtype from the lack of any such type in the class table. However, we do assume that each \ndeclaration is complete, so that all the supertypes of a constructed type are known. A class table T \nT is an extension of T (written TT .T ) if every declaration in T is also in TT. From this, it follows \nthat for any well-formed extension T T of a well-formed class table T , any type that is well-formed \nwith respect to T is well-formed with respect to TT and the subtyping relation T on TT agrees with that \nof T . That is, T .T implies T .T, T and T<: U in T implies T<: U in T. 2.3 Values and Ilks Types are \nintended to describe the values that might be pro\u00adduced by an expression or passed into a function. In \nFortress, for example, there are three kinds of values: objects, func\u00adtions, and tuples; every object \nbelongs to at least one con\u00adstructed type, every function belongs to at least one arrow type, and every \ntuple belongs to at least one tuple type. We say that two types T and U have the same extent if every \nvalue v belongs to T if and only if v belongs to U . No value belongs to Bottom. We place a requirement \non values and on the type system that describes them: Although a value may belong to more than one type, \nevery value v belongs to a unique type ilk(v) (the ilk of the value) that is representable in the type \nsystem7 and has the property that for every type T , if v belongs 7 The type system presented here satis.es \nthis requirement simply by pro\u00adviding intersection types. to T then ilk(v) <: T . (This notion of ilk \ncorresponds to what is sometimes called the class or run-time type of the value.8) The implementation \nsigni.cance of ilks is that it is possi\u00adble to select the dynamically most speci.c applicable func\u00adtion \nfrom an overload set using only the ilks of the argument values; no other information about the arguments \nis needed. In a safe type system, if an expression is determined by the type system to have type T , \nthen every value computed by the expression at run time will belong to type T ; more\u00adover, whenever a \nfunction whose ilk is U . V is applied to an argument value, then the argument value must belong to type \nU .  2.4 Generic Function Declarations A function declaration (for a class table) consists of a name, \na sequence of type parameter declarations (enclosed in white square brackets), a type indicating the \ndomain of the func\u00adtion, and a type indicating the codomain of the function (i.e., the return type). \nA type parameter declaration consists of a type parameter name and its bounds. For example, in the following \nfunction declaration: <N f[X<: M,Y <: N] List[X], Tree[Y ] : Map[X, Y ] the name of the function is f \n, the type parameter decla\u00adrations are X : M and Y<: N , the domain type is < N the tuple type List[X], \nTree[Y ] , and the return type is Map[X, Y ] . We abbreviate a function declaration as f[.] S :T when \nwe do not want to emphasize the bounds. To reduce clutter, we omit the white square brackets of a dec\u00adlaration \nwhen the sequence of type parameter declarations is empty, and elide braces around singleton lists of \nbounds. A function declaration d = f[X<: {N}] S :T may be instantiated with type arguments W if |W | \n= |X| and Wi <:[W /X]Nij for all i and j; we call [W /X]fS :T the instantiation of d with W . When we \ndo not care about W , we just say that fU :V is an instance of d (and it is understood that U =[W /X]S \nand V =[W /X]T for some W ). We use the metavariable D to range over .nite collections of sets of function \ndeclarations and Df for the subset of D that contains all declarations of name f. An instance fU :V of \na declaration d is applicable to a type T if and only if T<: U. A function declaration is applicable \nto a type if and only if at least one of its instances is. For any type T , the set Df (T ) contains \nprecisely those declarations in Df that are applicable to T . 8 We prefer the term ilk to run-time type \nbecause the notion and usefulness of the most speci.c type to which a value belongs is not con.ned to \nrun time. We prefer it to the term class, which is used in The Java Language Speci.cation [7], because \nnot every language uses the term class or requires that every value belong to a class. For those who \nlike acronyms, we offer the mnemonic retronyms implementation-level kind and intrinsically least kind. \n 3. Overloading Rules and Resolution In this section, we de.ne the meaning of overloaded generic functions; \nthat is, we de.ne how a call to such a function is dispatched, and we give rules for overloaded declarations \nthat ensure that our dispatch procedure is well\u00adde.ned, as Castagna et al. do for overloaded monomorphic \nfunctions [4]. The basic idea is simple: For any set of over\u00adloaded function declarations, we de.ne a \npartial order on the declarations we call this order the speci.city relation and dispatch any call to \nthe most speci.c declaration applicable to the call, based on the ilks of the arguments. The rules for \nvalid overloading ensure that the most speci.c declaration is well-de.ned (i.e., unique) for any call \n(assuming that some declaration is applicable to the arguments), and that the re\u00adturn type of a declaration \nis a subtype of the return type of any less speci.c declaration. The latter property is necessary for \ntype preservation for dynamic dispatch: a more speci.c declaration may be applicable to the ilks of the \narguments than the most speci.c declaration applicable to the static types of the argument expressions, \nso we must ensure that the return type of this more speci.c declaration is a subtype of the return type \nused to type check the program (i.e., at compile time). Speci.cally, we de.ne three rules:9 the No Duplicates \nRule ensures that no two declarations are equally speci.c; the Meet Rule ensures that the set of overloaded \ndeclarations form a meet semilattice under the speci.city relation; and the Return Type Rule ensures \ntype preservation for dynamic dispatch. We prove that any set of overloaded function dec\u00adlarations satisfying \nthese three properties is safe, even if the class table is extended (Theorem 1). 3.1 Speci.city of Generic \nFunction Declarations For monomorphic function declarations, the speci.city rela\u00adtion is just subtyping \non their domain types. However, the domain type of a generic function declaration may include type parameters \nof the declaration, and type parameters of distinct declarations bear no particular relation to each \nother. Furthermore, the subtyping relation between their domain types of may depend on the instantiation \nof their type pa\u00adrameters, as illustrated by foo and quux in the introduction. Instead of using subtyping, \nwe adopt the following intu\u00aditive notion of speci.city: One declaration is more speci.c than another \nif the second is applicable to every argument that the .rst is applicable to. That is, for any d1,d2 \n.Df , d1 is more speci.c than d2 (written d1 j d2) if d1 .Df (T ) implies d2 .Df (T ) for every well-formed \ntype T . Neatly, this turns out to be equivalent subtyping over domain types where the domain type of \na generic function declaration is interpreted as an existential type [3]; we use that formulation to \nmechanically check the overloading rules (see Section 6). 9 The meet rule of Castagna et al. requires \nthe existence and uniqueness of the meet. We split these into two rules. This de.nition of speci.city \nintroduces a type inference problem for dynamic dispatch: If d2 is the most speci.c dec\u00adlaration applicable \nto the static types of the argument expres\u00adsions, and d1 j d2 is the most speci.c declaration applicable \nto the ilks of the arguments, then the type parameter instanti\u00adations derived by static type inference \nare relevant to d2, but not to d1. Because the call is dispatched to d1, we require type parameters for \nd1 to be inferred dynamically. Showing how to do so is beyond the scope of this paper.  3.2 Overloading \nRules Given a class table T , a set D of generic function declara\u00adtions for T , and a function name f, \nthe set Df is valid (or is a valid overloading) if it satis.es the following three rules: No Duplicates \nRule For every d1,d2 .Df , if d1 j d2 and d2 j d1 then d1 = d2. Meet Rule For every d1,d2 .Df , there \nexists a declaration d0 .Df (possibly d1 or d2) such that, d0 j d1 and d0 j d2 and d0 is applicable to \nany type T .T to which both d1 and d2 are applicable. Return Type Rule For every d1,d2 .Df with d1 j \nd2, and every type T = Bottom such that d1 .Df (T ), if an instance fS2 :T2 of d2 is applicable to T \n, then there is an instance fS1 : T1 of d1 that is applicable to T with T1 <: T2. The No Duplicates Rule \nforbids distinct declarations from being equally speci.c (i.e., each more speci.c than the other). The \nMeet Rule requires every pair of declarations to have a disambiguating declaration, which is more speci.c \nthan both and applicable whenever both are applicable. (If one of the pair is more speci.c than the other, \nthen it is the disambiguating declaration.) The Return Type Rules guarantees that whenever the type checker \nmight have used an instance of a declaration d2 to check a program, and then a more speci.c declaration \nd1 is selected by dynamic dispatch, then there is some instance of d1 that is applicable to the argument \nand whose return type is a subtype of the return type of the instance of d2 the type checker used, which \nis necessary for type preservation, as discussed above. Since Bottom is well-formed, and tuple types \nwith differ\u00adent numbers of arguments have no common subtype other than Bottom, the Meet Rule requires \nthat an overloaded function with declarations that take different numbers of arguments have a declaration \napplicable only to Bottom. Such a declaration would never be applied (because no value belongs to Bottom), \nand it cannot be written in Fortress (because Bottom is not .rst-class). To avoid this technical\u00adity, \nwe implicitly augment every set Df with a declaration f Bottom:Bottom. This declaration is strictly more \nspeci.c than any declaration that a programmer can write, and its re\u00adturn type is a subtype of every \ntype, so it trivially satis.es all three rules when checked with any other declaration in Df .  This \ntechnicality raises the following question: Must the Meet Rule hold for every T .T ? Could we not, for \nex\u00adample, have excluded Bottom from consideration, as in the Return Type Rule, and avoided the technicality? \nIf so, for which types is it necessary that the Meet Rule hold? The an\u00adswer is, we must check the Meet \nRule for a type T .T to which both d1 and d2 are applicable if there could be a value of type T such \nthat for any type T T .T to which the value belongs, T<: T T. In other words, we must check it for all \nleaf types. Thus, if we did not require extensibil\u00adity, we can check the Meet Rule only for those types \nthat are ilks of values. However, because we require extensibil\u00adity, and we support multiple inheritance, \nwe use intersection types instead.  3.3 Properties of Overloaded Functions With the rules for valid \noverloading laid out, we now de\u00adscribe some useful properties of valid overloaded sets and of the rules \nthemselves. Lemma 1 If d1 and d2 are declarations in Df such that d1 j d2 and d2 j d1, then the pair \n(d1,d2) satis.es the No Duplicates Rule and the Meet Rule. Proof: The No Duplicates Rule is vacuously \nsatis.ed, and the Meet Rule is satis.ed with d0 = d1 since d1 j d2 implies that d1 is applicable to a \ntype T if and only if both d1 and d2 are applicable to T . D Lemma 2 For every type T .T , if Df is a \nvalid set with respect to T then so is Df (T ). Proof: The No Duplicates Rule and Return Type Rule are \nstraightforward applications of the respective rules on Df . Let d1,d2 be declarations in Df (T ) and \nlet d0 .Df be its disambiguating declaration guaranteed by the Meet Rule on Df . Then d0 is applicable \nto exactly those types U to which d1 and d2 are both applicable. Since d1 and d2 are by de.nition both \napplicable to T , d0 must also be applicable to T , and hence d0 .Df (T ). Therefore the Meet Rule on \nDf (T ) is satis.ed. D To further characterize valid sets of overloaded de.ni\u00adtions and the more speci.c \nrelation j, we interpret them as meet semilattices. A partially ordered set (A, .) forms a meet semilattice \nif, for every pair of elements a, b . A, their greatest lower bound, or meet, is also in A. Lemma 3 A \nvalid set of overloaded function declarations forms a meet semilattice with the more speci.c relation. \nProof: Suppose Df is a valid set of overloaded function declarations with respect to class table T . \nFirst, (Df , j) forms a partially ordered set: clearly j is re.exive and transitive, and antisymmetry \nis a direct corollary of the No Duplicates Rule. Second, we must show that (i) for every d1,d2 .Df there \nexists a d0 .Df such that d0 j d1 and d0 j d2 and (ii) if there exists a dT 0 .Df such that dT 0 j d1 \nand d0 T j d2 then dT 0 j d0. Let d1 and d2 be declarations in Df . By the Meet Rule, there exists a \ndeclaration d0 .Df that is applicable to a type T .T if and only if both d1 and d2 are too. Since for \nevery T to which d0 is applicable we have that d1 and d2 are also applicable to it, we know that d0 j \nd1 and d0 j d2. Now let dT .Df be more speci.c than both d1 and d2. 0 Then for every type T .T such that \ndT is applicable to T , 0 d1 and d2 are also applicable to T ; thus d0 is applicable to T and dT 0 j \nd0. D The No Duplicates Rule and the Meet Rule each corre\u00adsponds to a de.ning property of meet semilattices \n(antisym\u00admetry and the existence of meets, respectively), while the Return Type Rule guarantees that \nthis interpretation is con\u00adsistent with the semantics of multiple dynamic dispatch. Lemma 4 A valid set \nof overloaded function declarations Df (T ) has a unique most speci.c declaration. Proof sketch: The \nset Df (T ) forms a meet semilattice by the previous lemma and moreover it is clearly .nite. By straightforward \ninduction a .nite meet semilattice has a least element, so there exists a unique declaration in Df (T \n) that is more speci.c than all others. D  3.4 Overloading Resolution Safety We now prove the main theorem \nof this paper, that a valid set of overloaded generic function declarations is safe even if the class \ntable is extended. Before proving the theorem we establish two lemmas. First, we show that if a set of \ndeclarations is valid for a given class table, then it is valid for any (well-formed) extension of that \nclass table. Second, we show that if a set of overloaded declarations is valid, then there is always \na single best choice of declaration to which to dispatch any (legal) call to that function (i.e., the \nunique most speci.c declaration applicable to the arguments). Lemma 5 (Extensibility) If Df is valid \nwith respect to the class table T , then Df is valid with respect to any extension T T of T . Proof sketch: \nIn Section 6 we will show that checking the validity of Df can be reduced to examining subtype rela\u00adtionships \nbetween existential and universal types, which are constructed solely from types appearing in Df and \nhence T . Extension of the class table preserves subtype relationships between types in T and hence preserves \nvalidity of Df . D Lemma 6 (Unambiguity) If Df is valid with respect to the class table T , then for \nevery type T .T such that Df (T ) is nonempty, there is a unique most speci.c declaration in Df (T ). \n Proof: Let T .T be a type such that Df (T ) is nonempty. This set is valid by Lemma 2 and thus contains \na unique most speci.c declaration by Lemma 4. D Theorem 1 (Overloading Safety) Suppose Df is valid with \nrespect to the class table T . Then for any type S .T T .T , if Df (S) is nonempty then there exists \na unique most speci.c declaration dS .Df (S). Furthermore for any declaration d .Df (S) and instance \nfT :U of d, there exists an instance fV :W of dS that is applicable to S such that W<: U. Proof: The \nExtensibility Lemma lets us consider only the case when T T = T . Now the Unambiguity Lemma entails that \nsuch a dS exists, and the Return Type Rule entails the rest. D 4. Exclusion Although the rules in Section \n3 allow programmers to write valid sets of overloaded generic function declarations, they sometimes reject \noverloaded de.nitions that might seem to be valid. For example, given the type system as we have described \nit thus far, the overloaded tail function from the introduction would be rejected by the overloading \nrules. These are not false negatives: multiple inheritance can in\u00adtroduce ambiguities by extending two \nincomparable types, as discussed in the introduction. Because we allow class ta\u00adbles to be extended by \nunknown modules, we cannot gener\u00adally infer that two types have no common nontrivial subtype from the \nlack of any such declared type. Therefore, the Meet Rule requires the programmer to provide a disambiguating \nde.nition for any pair of overloaded de.nitions whose do\u00admain types are incomparable. This problem is \nnot new with parametric polymorphism, as the print example in the introduction shows. To ad\u00address the \nproblem, Fortress de.nes an exclusion relation . over types such that two types that exclude each other \nhave no common nontrivial subtypes; that is, if T . U then T n U is synonymous with Bottom. Thus, overloaded \nde.\u00adnitions whose domain types exclude each other trivially sat\u00adisfy the Meet Rule: there are no types \n(other than Bottom) to which both de.nitions are applicable. Exclusion allows us to describe explicitly \nwhat is typically implicit in single\u00adinheritance class hierarchies. In our previous work on Fortress \nwithout generics [2], we provided a special rule the Exclusion Rule to exploit this information. However, \nthe Exclusion Rule can also be viewed, as we do in this paper, as a special case of the Meet Rule, where \nthere are no nontrivial types to which both de.nitions are applicable. Fortress provides three mechanisms \nto explicitly declare exclusion [1]: an object declaration, a comprises clause and an excludes clause. \nWe describe these precisely in Section 4.1, but for now, we simply note that they do not help with the \noverloaded tail function. Speci.cally, even with these exclusion mechanisms, we cannot de.ne List so \nthat the de.nitions for tail satisfy the Return Type Rule. To see this, consider the following overloaded \nde.nitions (from Section 1): `\u00b4 tail[T ] x: List[T ] : List[T ] `\u00b4 tail x: List[Z] : List[Z] and the \nfollowing type constructor declaration: .\u00af BadList <: List[Z], List[String] Both de.nitions of tail are \napplicable to the type BadList, and the monomorphic one is more speci.c. Two instances of the generic \nde.nition are applicable to this type: `\u00b4 tail List Z] : List[Z] `\u00b4 tail List[ String] : List[String] \nThe Return Type Rule requires that the return type of each of these instances be a supertype of the return \ntype of the monomorphic de.nition (the monomorphic de.nition is its only one instance); that is, it requires \nList[Z] <: List[Z]and List[Z] <: List[String] . The latter is clearly false. A similar issue arises when \ntrying to satisfy the Meet Rule by providing a disambiguating de.nition for incomparable de.nitions, \nas in the following example (where Z <: R): `\u00b4 minimum X<: R,Y <: Z p: Pair X, Y : R `\u00b4 minimum X<: Z,Y \n<: R p: Pair X, Y : R `\u00b4 minimum[ X<: Z,Y <: Z] p: Pair[ X, Y ] : Z The .rst de.nition is applicable \nto exactly those arguments of type Pair[X, Y ] for some X<: R and Y<: Z; the second is applicable to \nexactly those arguments of type Pair[X, Y ] for some X<: Z and Y<: R. So we might think that both de.nitions \nare applicable to exactly those arguments of type Pair[X, Y ] for some X<: Z and Y<: Z, which is exactly \nwhen the third de.nition is ap\u00adplicable. However, this is not true! We could, for example, have the following \ntype constructor declaration: .\u00af BadPair <: Pair[R, Z], Pair[Z, R] The .rst two de.nitions of minimum \nare both applicable to BadPair but the third is not. We might say that the problem with the above examples \nis not with the de.nitions of tail and minimum , but with the de.nitions of BadList and BadPair; we must \nreject the idea that a value may belong to List[Z] or List[String] or to Pair[Z, R] or Pair[R, Z] but \nnot to both. Indeed, Fortress imposes a rule that forbids multiple instantiation inheritance [8], in \nwhich a type (other than Bottom) is a subtype of distinct applications of a type constructor.10 We 10 \nThis de.nition suf.ces for the type system described in this paper, in which all type parameters are \ninvariant. It is straightforward, but beyond the scope of this paper, to extend this de.nition to systems \nthat support covariant and contravariant type parameters.  call this rule multiple instantiation exclusion \nand adopt it here. Multiple instantiation exclusion is easy to enforce stati\u00adcally, and experience suggests \nthat it is not onerous in prac\u00adtice: it is already required in Java, for example [7]. Also, Kennedy and \nPierce have shown that in systems that enforce multiple instantiation exclusion (along with some technical \nrestrictions), nominal subtyping is decidable [8].11 4.1 Well-Formed Class Tables with Exclusion To \nincorporate exclusion into our type system, we .rst augment type constructor declarations with two (optional) \nclauses the excludes and comprises clauses and add a new kind of type constructor declaration the object \ndeclaration. We then change the de.nition of well-formed class tables to re.ect the new features, and \nto enforce multi\u00adple instantiation exclusion. The syntax for a type constructor declaration with the \noptional excludes and comprises clauses, each of which speci.es a list of types, is:  C[X<: {M}] <:{N}excludes \n{L}comprises {K} This declaration asserts that for well-formed type C[T ] , the only common subtype of \nC[T ] and [T /X]Li for any Li in L is Bottom, and any strict subtype of C[T ] must also be a subtype \nof [T /X]Ki for some Ki in K. Omitting the excludes clause is equivalent to having excludes {} ; omitting \nthe comprises clause is equiva\u00ad 12 lent to having comprises { Any } . We de.ne the sets of instantiations \nof types in excludes and comprises clauses analogously to C[T ].extends. That is, for an application \nC[T ] of the declaration above, we have: C[T ].excludes = {[T /X]L} C[T ].comprises = {[T /X]K} A class \ntable may also include object declarations, which have the following syntax: object D[X<: {M}] <:{N} \nThis declaration is convenient for de.ning leaf types : it asserts that D[T ] has no subtypes other than \nitself and Bottom. Although the declaration has no excludes or comprises clause, this condition implies \nthat ex- D[T ] cludes any type other than its supertypes (and therefore it is as if it had a clause comprises \n{} ). 11 They also show that forbidding contravariant type parameters results in decidable nominal subtyping, \nso subtyping in our type system is decidable in any case. 12 To catch likely programming errors, Fortress \nrequires that every Ki in a comprises clause for C[T ] be a subtype of C[T ], but allowing Any to appear \nin a comprises clause simpli.es our presentation here. Multiple instantiation exclusion further restricts \ngeneric types: Distinct instantiations of a generic type (i.e., distinct applications of a type constructor) \nhave no common subtype other than Bottom. To de.ne well-formedness for class tables with exclusion (including \nmultiple instantiation exclusion), we de.ne an exclusion relation . over well-formed types: S . T asserts \nthat S and T have no common subtypes other than Bottom. For constructed types C[T ] and D[U], C[T ] . \nD[U] if D[U] . C[T ].excludes;  for all L . C[T ].comprises, D[U] is not a subtype of L;  C[T ] is \ndeclared by an object declaration and C[T ] is not a subtype of D[U];  D[U] . C[T ] by any of the conditions \nabove;  C = D and T = U; or  M . N for some M :>C[T ] and N :>D[U].  We augment our notion of a well-formed \nclass table to require that the subtyping and exclusion relations it induces respect each other. That \nis, for all well-formed constructed types M and N, if M . N then no well-formed constructed type is a \nsubtype of both M and N. A well-formed extension to a class table T must preserve this property. Except \nfor the imposition of multiple instantation exclu\u00adsion, these changes generalize the standard type system \nde\u00adscribed in Section 2: A class table that does not use any of the new features is well-formed in this \naugmented system exactly when it is well-formed in the standard system. On the other hand, multiple instantiation \nexclusion restricts the set of well-formed class tables: a table that is well-formed when multiple instantiation \ninheritance is permitted might not be well-formed under multiple instantiation exclusion. We extend the \nexclusion relation to structural and com\u00adpound types as follows: Every arrow type excludes every non-arrow \ntype other than Any. Every non-singleton tu\u00adple type excludes every non-tuple type other than Any. (A \nsingleton tuple type is synonymous with its element type, and so excludes exactly those types excluded \nby its element type.) Non-singleton tuple type (V ) excludes non-singleton tuple type (W ) if either \n|V | = |W | or Vi excludes Wi for some i. An intersection type excludes any type excluded by any of its \nconstituent types; a union type excludes any type excluded by all of its constituent types. Bottom excludes \nev\u00adery type (including itself it is the only type that excludes it\u00adself), and Any does not exclude any \ntype other than Bottom. (We de.ne the exclusion relation formally in Section 7.) 5. Examples We now consider \nseveral sets of overloaded generic function declarations, and argue informally why they are (or are not, \nin one case) permitted by the rules in Section 3, paying particular attention to where multiple instantiation \nexclusion  is required. We give a formal system and algorithm for performing these checks in Section \n6. First, consider the function foo from Section 1: foo X<: Object](x: X, y: Object): Z =1 foo[ Y<: Number](x: \nNumber,y: Y ): Z =2 This overloading is valid: The second de.nition is strictly more speci.c than the \n.rst because the .rst de.nition is applicable to a pair of arguments exactly if the type of each is a \nsubtype of Object, whereas the second is applicable to a pair of arguments exactly if the type of each \nis a subtype of Number. Thus, these de.nitions satisfy the No Duplicates Rule and the Meet Rule by Lemma \n1. And they satisfy the Return Type Rule because the return type of both de.nitions is always Z. The \noverloaded de.nitions for tail are also valid: `\u00b4 tail X] x: List[X] : List[X] = e1 `\u00b4 tail[ X<: Number] \nx: List[X] : List[X] = e2 `\u00b4 tail x: List[Z] : List[Z] = e3 The .rst de.nition is applicable to any argument \nof type List[T ] for any well-formed type T , the second is applica\u00adble to an argument of type List[T \n] when T<: Number , and the third is applicable to an argument of type List[Z] . Thus, each de.nition \nis strictly more speci.c than the pre\u00adceding one, so the No Duplicates Rule and Meet Rule are satis.ed \nfor each pair of de.nitions by Lemma 1. To see that the Return Type Rule is satis.ed by the .rst two \nde.nitions, consider any type W = Bottom to which the second de.nition is applicable so W<: List[T ] \nfor some T<: Number and any instantiation of the .rst def\u00adinition with type U that is applicable to W \nso W<: List[U] . Then W<: List[T ] n List[U] . By multiple in\u00adstantiation exclusion, List[T ] n List[U] \n= Bottom unless T = U. Since W = Bottom, we have T = U, so W<: List[U] with U<: Number. Thus, the instantiation \nof the second de.nition with U has return type List[U] , which is also the return type of the instantiation \nof the .rst de.\u00adnition under consideration. (In Section 7.8 we describe how to incorporate this sort \nof reasoning about validity into our algorithmic checking of the overloading rules.) The Return Type \nRule is also satis.ed by the third de.ni\u00adtion and either of the .rst two because the third de.nition \nis applicable only to arguments of type List[Z] , and because of multiple instantiation exclusion, the \nonly instantiation of either the .rst or second de.nition that is applicable to such an argument is its \ninstantiation with Z. That instantiation has return type List[Z] , which is also the return type of the \nthird de.nition. The minimum example from Section 4 is also valid under multiple instantiation exclusion, \nwhich is necessary in this case to satisfy the Meet Rule rather than the Return Type Rule: `\u00b4 minimum[X<: \nR,Y <: Z] p: Pair[X, Y ] : R `\u00b4 minimum[X<: Z,Y <: R] p: Pair[X, Y ] : R `\u00b4 minimum[X<: Z,Y <: Z] p: \nPair[X, Y ] : Z Any argument to which the .rst two de.nitions are both applicable must be of type Pair[X1,Y1] \nn Pair[X2,Y2]for some X1 <: R, Y1 <: Z, X2 <: Z, and Y2 <: R. Multiple instantiation exclusion implies \nthat X1 = X2 and Y1 = Y2, so the argument must be of type Pair[X1,Y1], where X1 <: RnZ = Z and Y1 <: \nZnR = Z, so the third de.nition is applicable to it. And since the third de.nition is more speci.c than \nthe .rst two, it satis.es the requirement of the Meet Rule. The following set of overloaded declarations \nis also valid (given the declaration ArrayList[X] <: List[X] ): bar X]ArrayList[X]: Z bar Y<: Z List[Y \n]: Z bar[ Z<: Z] ArrayList[Z]: Z The .rst two declarations are incomparable: the .rst is ap\u00adplicable \nto ArrayList[T ] for any type T , the second to List[U] for U<: Z. Thus, both declarations are applica\u00adble \nto any argument of type ArrayList[T ] n List[U] for any T and U<: Z. Since ArrayList[T ] <: List[T ] \n, this type is a subtype of List[T ] n List[U] , which, because of multiple instantiation exclusion, \nis Bottom unless T = U, in which case, ArrayList[T ] n List[U] = ArrayList[U] . This is exactly the type \nto which the third declaration is ap\u00adplicable, so the Meet Rule is satis.ed. Note that this example is \nsimilar to the previous one with minimum except that rather than having each of the two de.nitions being \nmore restrictive on a type parameter, one uses a more speci.c type constructor. Finally, we consider \nthree examples that do not involve generic types, beginning with the following declarations: baz[X](x: \nX): X baz(x: Z): Z This pair is not valid: it does not satisfy the Return Type Rule. Consider, for example, \nan argument of type N <: Z. The second declaration, which is more speci.c than the .rst, and the instantiation \nof the .rst declaration with N are both applicable to this argument, but the return type Z of the second \ndeclaration is not a subtype of the return type N of the instance of the .rst declaration. This rejection \nby the Return Type Rule is not gratuitous: baz may be called with an argument of type N in a context \nthat expects an N in return. We can .x this example by making the second declaration generic: baz[X](x: \nX): X baz[X<: Z](x: X): X This pair is valid: the second declaration is strictly more spe\u00adci.c than the \n.rst, so the No Duplicates and Meet Rules are satis.ed. To see that the Return Type Rule is satis.ed, \nconsider any type W = Bottom to which the second dec\u00adlaration is applicable so W<: Z and any instantiation \nof the .rst with some type T that is applicable to W so W<: T . Then the instantiation of the second \ndeclaration with W has return type W , which is a subtype of the return type T of the instance of the \n.rst declaration under consid\u00aderation.  6. Overloading Rules Checking In this section, we describe how \nto mechanically check the overloading rules from Section 3. The key insight is that the more speci.c \nrelation on overloaded function declarations corresponds to the subtyping relation on the domain types \nof the declarations, where the domain types of generic function declarations are existential types [3]. \nThus, the problem of determining whether one declaration is more speci.c than another reduces to the \nproblem of determining whether one existential type is a subtype of another. We then formulate the overloading \nrules as subtyping checks on existential and universal types (universal types arise in the reformulation \nof the Return Type Rule), and give an algorithm to perform these subtyping checks. The algorithm we describe \nis sound but not complete: it does rejects some sets of overloaded functions that are valid by the overloading \nrules in Section 3, but it accepts many of them, including all of the valid examples in Section 5. 6.1 \nExistential and Universal Types Given a generic function declaration d = f[.] S :T , its domain type, \nwritten dom(d), is the existential type .[.]S. An existential type binds type parameter declarations \nover a type, but these type parameters cannot be instantiated; instead, the existential type represents \nsome hidden type instantiation and the corresponding instantiated type. We write .[X<: {N}]T to bind \neach type variable Xi with bounds {Ni} over the type T , and we use the metavariable d to range over \nexistential types. The arrow type of declaration d above, written arrow(d), is the universal arrow type \n.[.]S . T . We use this to for\u00admulate the Return Type Rule. A universal type binds type parameter declarations \nover some type and can be instanti\u00adated by any types .tting the type parameters bounds. We write .[X<: \n{N}]T to bind each type variable Xi with bounds {Ni} over the type T , and we use the metavariable s \nto range over universal types. Note that universal and existential types are not actually types in our \nsystem.  6.2 Universal and Existential Subtyping We de.ne subtyping judgments for universal and existential \ntypes, which we use in checking the overloading rules. We actually de.ne inner and outer subtyping judgments \non uni\u00adversals and existentials; the former correspond to a relatively standard interpretation of each \n(which resembles those de\u00ad.ned in [3]); the latter incorporate quanti.er reduction, de\u00ad.ned in Section \n7.8. Existential Subtyping: . f d d . f d = d .T =.,X <: {M} X n (FV (U) . FV (N)) = \u00d8 .T f T<:[V /Y \n]U .i. .T f Vi <:[V /Y ]{Ni} . f.[X<: {M}]T .[Y<: {N}]U = . f d -. dr . f dr dT . f d = dT Universal \nSubtyping: . f s s . f s = s .T =.,Y <: {N} Y n (FV (T ) . FV (M)) = \u00d8 .T f [V /X]T<: U .i. .T f Vi <:[V \n/X]{Mi} . f.[X<: {M}]T .[Y<: {N}]U = . f sT -. sT r . f s sT r . f s = sT Figure 1. Subtyping of universal \nand existential types. Note that alpha-renaming of type variables may be necessary to apply these rules. \nThe inner subtyping judgment on existentials . f d1 d2, de.ned in Figure 1, states that d1 is a subtype \nof d2 in the environment . if the constituent type of d1 is a subtype of an instance of d2 in the environment \nobtained by conjoining . and the bounds of d1. In the outer subtyping judgment . f d = dT, we .rst perform \nexistential reduction to produce dr (denoted = . f d -. dr). Then we check whether . f dr dT . We provide \n(and explain) the formal de.nition of existential reduction in Section 7.8, but for now note that it \nhas the following properties: 1. . f dr d 2. . f d dT implies . f dr dT r 3. (dr)= dr  r 4. (.[]T \n)r = .[]T The .rst three properties show that = is a preorder and that implies =. Adding the fourth property \nlets us show that any ground instance T of d with T = Bottom is an instance of dr We use existential \nreduction because merely extending the subtyping relation for ordinary types with exclusion is not enough \nto let us check the overloading rules. For ex\u00adample, to check that the .rst two declarations of Dbar \nfrom Section 5 satisfy the Meet Rule, we must be able to deduce that the existential <N .[X<: Any,Y <: \nZ] ArrayList[X] n List[Y ]  and the existential .[W<: Z]ArrayList[W ] describe the same set of ground \ninstances of types. The rules for universals are dual to those for existentials. The inner subtyping \njudgment on universals . f s1 s2, de.ned in Figure 1, states that s1 is a subtype of s2 in the environment \n., if an instance of s1 is a subtype of the con\u00adstituent type of s2 in the environment obtained by conjoin\u00ading \n. and the bounds of s2. In the outer universal subtyping judgment . f s = sT, we .rst perform universal \nreduction = to produce sT r (denoted . f sT -. sT r) and then check whether . f ssT r. Again, we provide \nthe formal de.\u00adnition of universal reduction in Section 7.8, noting that it has the following properties: \n1. . f ssr 2. . f ssT implies . f sr sT r 3. (sr)= sr  r r 4. (.[]S . T )= .[]S . T Again the .rst \nthree properties show that = is a preorder and that implies =. Adding the fourth property lets us show \nthat any ground instance S . T of d with S = Bottom is an instance of sr. We need universal reduction \nfor the same reason we need existential reduction, to check the overloading rules. For example to show \nthe .rst two declarations in Dtail from Section 5 satisfy the Return Type Rule, we use universal reduction \nto show that <N .[X<: Number,Y <: Any] List[X] n List[Y ] and .[W<: Number]List[W ] . List[W ] have all \nthe same nontrivial instances.  6.3 Mechanically Checking the Rules With our interpretations of applicability \nand speci.city into existential subtyping, we now describe the process of check\u00ading the validity of a \nset of overloaded declarations Df ac\u00adcording to the rules in Section 3. We can check the No Duplicates \nRule by verifying that for every pair of distinct function declarations d1,d2 .Df either d1 j d2 or d1 \nj d2. The Meet Rule requires that every pair of declarations d1,d2 .Df has a meet in Df . Because the \nmore speci.c relation on function declarations corresponds to the subtyp\u00ading relation on the (existential) \ndomain types, we just need to .nd a declaration d0 .Df whose domain type dom(d0) is equivalent to the \nmeet (under =) of the existential types dom(d1) and dom(d2). Figure 2 shows how to compute the meet of \ntwo existential types. Lemma 7 d1 . d2 (as de.ned in Figure 2) is the meet of d1 and d2 under =. Proof: \nFirst we show that d1 . d2 is the meet of d1 and d2 under . That d1 . d2 d1 and d1 . d2 d2 is obvious. \nFor any d0, if U and V are instantiations that prove d0 d1 and d0 d2, respectively, then we can use the \ninstantiation U, V to prove that d0 = d1 . d2. Now we show that the meet under is also the meet = under \n=. Suppose that d0 = d1, d0 = d1, and . f d0 -. dT . A little work lets us deduce that dT d1 . d2 and \nhence 00 d0 = d1 . d2. The fact that d1 . d2 = d1 and d1 . d2 = d2 follows from the fact that implies \n=. D We can check the Return Type Rule using the subtype relation on universal types. Theorem 2 Let d1 \n= f[.1] S1 : T1 and d2 = f[.2] S2 : T2 be declarations in Df with d1 j d2. They satisfy the Return Type \nRule if arrow(d1) is a subtype of the arrow type s. = .[.1, .2](S1 n S2) . T2. Proof: Let d. = f[.1, \n.2]S1 n S2 : T2, so arrow(d.)= s.. Note that d. and d1 are equally speci.c and that d. and d2 satisfy \nthe Return Type Rule. Because arrow(d1) = s., for every instance U . V of s. with U = Bottom, we can \n.nd an instance U1 . V1 of arrow(d1) with U<: U1 and V1 <: V . Thus, the pair d1 and d2 satisfy the Return \nType Rule because the pair d., d2 does. D 7. Constraint-Based Judgments Up to this point the precise \nde.nitions of subtyping and ex\u00adclusion between types (and quanti.er reduction) have re\u00admained unspeci.ed. \nIn this section we describe a small lan\u00adguage of type constraints and we de.ne subtyping and ex\u00adclusion \nwith respect to constraints. Finally, with constraint\u00adbased subtyping and exclusion de.ned, we explain \nin more detail the notion of quanti.er reduction used in the = judg\u00adments (and thus in our rule-checking). \n7.1 Inference Variables Until now we have only considered types whose free vari\u00adables are bound in an \nexplicit type environment. To gather constraints, however, we must check subtype and exclusion relationships \nbetween types with unbound inference vari\u00adables. Intuitively, we have no control over the constraints \non a bound type variable (which are .xed by the associated type environment), but we may introduce constraints \non an infer\u00adence variable. While the syntax of type variables is uniform, we conventionally distinguish \nthem by using the metavari\u00adables X and Y for bound type variables and I and J for inference type variables. \n 7.2 Judgment Forms In Figure 3, we list the judgments for generating constraints. A judgment of the \nform . f S * T .C states that under the assumptions ., the constraint C on the inference vari\u00adables implies \nthe proposition S * T , where * ranges over <:, <:, ., ., =, and =. If S and T contain no inference \n Existential Meet: d1 . d2  def .[X<: {M}]T..[Y<: {N}]U= .[X<: {M},Y <: {N}] (T n U) where X n Y = X \nn (FV (U) . FV (N)) = Y n (FV (T ) . FV (M)) = \u00d8 Figure 2. The computed meet of existential types. Primitive \nJudgments: . f T * T .C . f S<: T .C . f S . T .C . f S<: T .C . f S . T .C Derived Judgments: . f T \n* T .C . f S<: T .C . f T<: S .CT . f S = T . C.CT . f S<: T .C . f T<: S .CT . f S = T . C.CT Derived \nJudgments: . f T * T .C . f S = T .C . f S = T . \u00acC Figure 3. Constraint-based judgment forms. variables \nthe judgment behaves like an unconditional judg\u00adment (i.e., it only produces the constraints true or \nfalse). Similarly, the judgment of the form . f S * T .C states that under the assumptions ., if the \nproposition S * T holds, then C must be true of the inference variables. In particular, when C holds \nof the inference variables, S * T does not have to hold for every valid instantiation of the bound type \nvariables. (Note that we only make use of this judgment where * is =.) An important point about both \nkinds of judgments is that the types S and T should be considered inputs and the constraint C should \nbe considered an output.  7.3 Constraint Forms Our grammar for type constraints is de.ned in Figure \n4. A primitive constraint is either positive or negative. We de.ne positive primitive constraints: S<: \nT speci.es that a S is a subtype of T , and S . T speci.es that S must exclude T . Similarly, we de.ne \nnegative primitive constraints: S<: T and S . T with the obvious interpretations. A conjunction Figure \n4. Constraints. Note that unify and toBounds are partial functions. Constraint Grammar Constraint Utilities \nC ::= S <: T \u00acC = C | S . T | S <: T toConstraint(.) = C | S . T | C . C toBounds(C) = . | C . C | false \n. f unify(C) = f , C | true constraint C1 .C2 is satis.ed exactly when both C1 and C2 are satis.ed, \nand a disjunction constraint C1 .C2 is satis.ed exactly when one or both of C1 and C2 are satis.ed. The \nconstraint false is never satis.ed, and the constraint true is always satis.ed. The equivalence constraint \nS = T is derived as S<: T . T<: S. Following Smith and Cartwright [16], we normalize all constraint formulas \ninto disjunctive normal form and sim\u00adplify away obvious contradictions and redundancies. We fur\u00adther \nmake use of some auxiliary meta-level de.nitions, de\u00ad.ned in Figure 4. The negation \u00acC of a constraint \nC has a standard de Morgan interpretation. Each type environment .= X<: {M} naturally describes a constraint \non the vari\u00adables X, which we denote toConstraint(.). This conversion has a partial inverse toBound(C) \nthat is de.ned whenever C can be written as a conjunction of constraints of the form 13 X<: M.  7.4 \nSubtyping Figure 5 presents the full de.nition of our constraint-based subtyping algorithm as inference \nrules for the judgment . f T<: T .C. Note that our algorithm requires that these rules be processed in \nthe given order. Smith and Cartwright similarly de.ne a sound and com\u00adplete algorithm for generating \nconstraints from the Java sub\u00adtyping relation [16]. We essentially preserve their semantics with two \nnotable differences. First, our de.nition includes additional rules for tuple types to account for the \nfact that 13 If C has multiple conjuncts of this form for a single X, then the resulting environment \ncontains multiple bounds for X using the {M} notation.  Subtyping Rules: . f T<: T .C Logical rules \nStructural rules . f Bottom <: T . true |S| = |T |.i. . f Si <: Ti .Ci .i. . f Si <: Bottom .Di . f \n(S) <:(T ) . (Ci) . (Di). f M<: Bottom . false |S| =1 .i. . f Si <: Bottom .Ci . f S . T<: Bottom . \nfalse . f (S) <: T .Ci . f U<: S .C . f T<: V .CT . f T<: Any . true . f S . T<:U . V . C.CT . f Any \n<:S . T . false |U| =1 . f S . T<:(U) . false . f T<: U .C . f T<: V .CT . f T<: U n V . C.CT |T | =1 \n. f M<:(T ) . false . f S<: U .C . f T<: U .CT . f S . T .CTT . f S n T<: U . C.CT .CTT . f S . T<: \nM . false . f T<: U .C . f T<: V .CT . f M<:S . T . false . f T<: U . V . C.CT . f S<: U .C . f T<: \nU .CT Constructed types . f S . T<: U . C.CT C = D .M .C[S].extends. . f M<:D[T ] .CM . f C[S] <:D[T \n] .CM Inference Variables I . . .i. . f Si = Ti . Ci . f I<: I . true . f C[S] <: C[T ] .Ci I . . . \nf I<: T . I <: T I . . . f S<: I . S <: I Bound Variables . f X<: X . true . f .(X) <: T .C . f X<: \nT .C . f S<: Bottom .C . f S<: X .C  Figure 5. Algorithm for generating subtyping constraints. Apply \nthe .rst rule that matches. any tuple is equivalent to Bottom if any of its element types is equivalent \nto Bottom. |S| = |T |.i. . f Si <: Ti .Ci .i. . f Si <: Bottom .CT i . f (S) <:(T ) . ( Ci) . ( CT) i \n|S| =1 .i. . f Si <: Bottom .Ci . f (S) <: T .Ci Second, our de.nition includes an additional rule for \ninter\u00adsection types to account for exclusion since the intersection of excluding types is equivalent \nto Bottom. This rule makes our exclusion and subtyping rules mutually dependent. . f S<: U .C . f T<: \nU .CT . f S . T .CTT . f S n T<: U . C.CT .CTT We formally de.ne the subtyping judgment from Sec\u00adtion \n2 as a trivial application of constraint-based subtyping with the following rule: . f S<: T . true . \nf S<: T  7.5 Exclusion Figure 6 presents our de.nition of constraint-based exclu\u00adsion as inference rules \nfor the judgment . f T . T .C. As with subtyping, our algorithm requires that these rules be processed \nin order. Additionally, if no rule matches, then the l.h.s. and r.h.s. types should be swapped and the \nrules tried again. To make these rules algorithmic, we break the exclusion relation on constructed types \ninto four subrelations .x, .c, .o, and .m. The .rst three relations are further decomposed into the asymmetric \nrelations .x, .c, and .o. 1. C[ S ] .x D[ T ] determines whether D[ T ] has a su\u00adper type N such that \nN appears in the excludes clause of an ancestor of C[ S ] . 2. C[ S ] .c D[ T ] determines whether D[ \nT ] excludes every type in the (nontrivial) comprises clause of C[ S ] . 3. C[ S ] .o D[ T ] determines \nwhether C[ S ] is an ob\u00adject and D[ T ] is not a supertype of C[ S ] . 4. C[ S ] .m D[ T ] determines \nwhether there is a pair of types (M, N) such that M is an ancestor of  C[ S ] , N is an ancestor of \nD[ T ] , and M and N are distinct applications of the same type constructor. As with subtyping, we formally \nde.ne the exclusion judgment described in Section 4 as a trivial application of constraint-based exclusion \nwith the following rule: . f S . T . true . f S . T 7.6 Negative Judgments and Negation In the rules \nfor constraint-based exclusion (Figure 6), we use the negative judgments . f T<: T .C and . f T . T .C \nto determine constraints under which the negations hold. Instead of de.ning negative judgments explicitly, \nwe describe how to derive them from their positive counterparts according to de Morgan s laws. For the \nnegative subtyping judgment . f T<: T .C, the rules for bound variables are given below: X . .. f S<: \n.(X) .C . f X<: T . false . f S<: X .C The other rules for . f T<: T .C are obtained as follows: For \neach rule of . f T<: T .C that is not in the section marked bound variables, make a new rule for . f \nT<: T .C by replacing each occurrence of a relation symbol * with its negation, and by swapping each \n. with . and true with false, and vice versa. For example, the rule for intersection types on the r.h.s. \n. f T<: U .C . f T<: V .CT . f T<: U n V . C.CT becomes the following rule in the negative subtyping \njudg\u00adment . f T<: U .C . f T<: V .CT . f T<: U n V . C.CT The rules for the negative exclusion judgment \n. f T . T .C are derived from those of . f T . T .C according to the process above. The rule for bound \nvariables is X . . . f X . T . false The negative subtyping judgment should not be confused with the \nderived contrapositive judgment . f T = T .C given in Figure 3, for the two judgments handle bound type \nvariables very differently. Intuitively, the negative assertion . f S = T .C computes the constraint \nC that satis.es the inequivalence for an arbitrary instantiation of the type variables bound in .. Whereas \nthe contrapositive assertion . f S = T .C computes the constraint C that holds for any instantiation \nof . such that the inequivalence is true. The following derivable assertions further illustrate this \ndistinction, for .= X<: Any,Y <: Any : < N . f Pair X, I n Pair Y, J = Bottom . false < N . f Pair[ X, \nI] n Pair[ Y, J] = Bottom . I = J  7.7 Uni.cation Suppose that C is a conjunction of type equivalences. \nA uni.er of C is a substitution f of types for inference type  Exclusion: . f T . T .C Logical rules \n. f Bottom . T . true . f T<: Bottom .C . f Any . T .C . f S . U .C . f T . U .CT . f S n T<: Bottom \n.CTT . f S n T . U . C.CT .CTT . f S . U .C . f T . U .CT . f S . T . U . C.CT Inference Variables I \n. . . f I . I . false I . . . f I . T . I . T Bound Variables . f .(X) . T . C . f X . T . C Structural \nrules |S| = |T |.i.. f Si . Ti .Ci . f (S) . (T ) .Ci |S| = |T | . f (S) . (T ) . true M = Any |T | =1 \n. f M . (T ) . true |T | =1 . f S . R . (T ) . true . f S . T .U . V . false M = Any . f M .T . U . true \n Constructed types . f CS .x DT .Ce . f CS .c DT .Cc . f C[ S] .o D[ T ] .Co . f C[S] .m D[T ] .Cp . \nf C[S] .D[T ] .Ce .Cc .Co .Cp * D[T ] .C. f C[S] * C[S] .CT . f D[T ]. f C[S] .* D[T ] . C.CT where *.{x, \nc, o} * C[T ] . false . f C[S] where *.{x, c, o} C = DA = ancestors(C[S]) < N .N . M.excludes . . f \nD[T ] <: N .CN M.A . f C[S] x D[T ] .CN C = D .M .C[S].comprises. . f M .D[T ] .CM . f C[S] c D[T ] \n.CM C = DC does not have a comprises clause c D[T ] . false . f C[S]C = D object C . f C[S] <:D[T ] .C \no D[T ] .C . f C[S] C = D \u00ac(object C) o D[T ] . false . f C[S] .M . ancestors(CS ). .N . ancestors(D[ \nT ] ). . f M .\u00b7 m N .CM,N . f C[S] .m D[T ] .CM,N .i.. f Si = Ti .Ci \u00b7 . f C[S] .m C[T ] .Ci C = D \u00b7 \nm D[T ] . false . f C[S] . Figure 6. Algorithm for generating exclusion constraints. Each rule is symmetric; \napply the .rst one that matches. variables such that f(C)= true. We say that a uni.er f is more general \nthan a uni.er . if there exists a substitution t such that t . f = .. In other words f is more general \nthan . if . factors throughout f. We can extend the notion of a uni.er to an arbitrary conjunction C \nin the case that C can be expressed as a conjunction CT .CTT where CT is entirely equivalences and CTT \ncontains no type equivalences. Then we de.ne a uni.er of C to be a uni.er of CT. Finally, we can extend \nthe notion of uni.er to a constraint C in disjunctive normal form to be a uni.er of any disjunct of C. \nThe (partial) function unify in Figure 4 takes a constraint C and produces a most general uni.er f if \none exists. This is always the case if C consists of a single conjunct. unify additionally produces the \nsubstituted leftover part, f(CTT).  7.8 Quanti.er Reduction In the evaluation of valid overloadings \nfrom Section 5, in\u00adtensional type analysis was required in order to reason about certain examples. Since \nthis reasoning justi.ed the valid\u00adity of these overloaded functions, we incorporate it into the present \nformal system as well. Whenever two different domain types should be applica\u00adble to the same argument \ntype W (in order to validate the Meet Rule or Return Type Rule), an existentially quanti.ed intersection \ntype naturally arises as the necessary supertype of W . Intersection types S n T in our type system naturally \nfall into two distinct cases: either S . T , or S . T in which case the intersection has the same extent \nas Bottom. In the second case, the intersection is trivial and W , as a subtype of the intersection, \nmust also be trivial. Moreover, because the argument type W to which both declarations must be appli\u00adcable \nis necessarily equivalent to Bottom, then the Meet Rule and Return Type Rule are both trivially satis.ed \nby the presence of the implicit overloading on Bottom. In this manner case analysis on whether an existentially \nquanti.ed (intersection) type is Bottomfacilitates the checking of our rules. Na\u00a8ively one might expect \nthis case analysis on S n T to simply check whether S . T . However, as is the case when checking generic \nfunction declarations, the types S and T might have free type variables, whose uncertainty often precludes \na de.nitive statement about S . T . (For example, C[X] . C[Y ] holds only if X = Y .) Our solution is \nto reason backwards: Under the assumption that the intersection is nontrivial (that the types do not \nexclude), gather the necessary constraints on type parameters. (For example, C[X] n C[Y ] = Bottom yields \nthe constraint X = Y .) These constraints are then reduced, resulting in an instantiation (and potentially \ntighter bounds on type parameters) that necessarily follows from our assumption of nontriviality.14 14 \nA similar sort of case analysis and constraint solving arises for pattern matching with generalized algebraic \ndata types (GADTs) [15]: GADTs We call the general pattern of simplifying an existentially quanti.ed \n(intersection) type existential reduction, given by = the judgment . f d -. d in Figure 7. The .rst rule \nfor existential reduction performs the constraint-based case analysis described above, while the second \nmerely relates the existential to itself if the premises of the .rst rule do not hold. We thus explain \nthe .rst rule in more detail. The .rst premise determines the constraints C that must be true under the \nhypothesis that T = Bottom (i.e. that this type is nontrivial). Note that the type variables from . are \nbound, while any type variables from the existential itself, .T, become inference type variables mentioned \nin C. The second premise binds CT to exactly the inference type vari\u00adables and bounds denoted by the \nexistential s type param\u00adeters; these are the constraints that must hold for T to still make sense. In \nthe third premise, if unify succeeds, it pro\u00adduces a substitution f for any inference type variables \nfrom .T constrained by equalities. Because f is a most general uni.er, it has the property that any other \nvalid substitution . of .T s variables with .(T ) = Bottom must be equal to t . f, for some other substitution \nt . Moreover, if unify suc\u00adceeds, it produces a set of leftover constraints CTT that are not uni.able \nequalities (but have still been simpli.ed). If it is possible to express CTT as some type environment \n.TT, then we use this as the new type parameters over the simpli.ed type f(T ). Similarly we call the \ngeneral pattern of simplifying a universally quanti.ed arrow type universal reduction, given = by the \njudgment . f s1 -. s2 The .rst premise reduces the domain type dom(s)= .[.T]S, resulting in a new existential \ntype d = .[.TT]ST and a substitution f mapping type variables from .T to types with variables in .TT. \nWe then construct a new arrow with domain d and range f(T ). As an example, in order to check that the \n.rst two dec\u00adlarations of Dbar from Section 5 satisfy the Meet Rule, we must reduce the existential <N \n.[X<: Any,Y <: Z] ArrayList[X] n List[Y ] . Thus we must .nd the constraint C such that f ArrayList[X] \nn List[Y ] = Bottom .C can be derived, noting that X and Y are actually (un\u00adbound) type inference variables \nhere. In this instance C = X = Y due to multiple instantiation exclusion. Then we convert the bounds \non the existential s type parameters into the constraint CT on X and Y as inference variables: toConstraint(X<: \nAny,Y <: Z)= X<: Any,Y <: Z. Unifying the constraint C.CT = X = Y . X<: Any . Y<:Z yields the type substitution \nf =[W/X, W/Y ] (for some fresh variable W ) and the simpli.ed leftover constraint CTT = resemble our \nexistential types and pattern matching resembles our function application.  = Existential Reduction: \n. f d -. d, f . f T = Bottom .C toConstraint(.T)= CT .TT . f unify(C.CT)= f, CTT toBounds(CTT)= = . f.[.T-. \n.[.TT]f(T ) ,f ]T otherwise = . f.[.T-. .[.T]T, [/] ]T = Universal Reduction: . f s -. s, f = . f.[.T-. \n.[.TT]ST ,f ]S ]S . T = . f.[.T-. .[.TT]ST . f(T ) ,f Figure 7. Quanti.er reduction judgments. W<: Z. \nSince CTT has the form of a type environment, toBounds(CTT)= W<: Z, we .nally reduce this existential \n< N to .[W<: Z] ArrayList[W ] n List[W ] . However, due to the class table declaration of ArrayList[W \n] this existen\u00adtial type will be indistinguishable (by ) from the simpler .[W<: Z]ArrayList[W ] . When \nchecking that the .rst two declarations Dtail from Section 5 satisfy the Return Type Rule, we use universal \nreduction to prove f.[X<: Any]List[X] . List[X] < N =.[X<: Any,Y <: Number] List[X] n List[Y ]. List[Y \n] First, note that by reasoning similar to that in the previous example we know < N f.[X<: Any,Y <: Number \nList[X] n List[Y ] = -. .[W<: Number] List[W ] with substitution [W/X, W/Y ]. Using this substitution \nwe must now prove f.[X<: Number]List[X] . List[X].[W<: Number]List[W ] . List[W ] which is clearly true. \n8. Overloading Across Modules To demonstrate the modularity of our design, we present a lightweight modeling \nof program modules, and show how applying our rules to each module separately suf.ces to guarantee the \nsafety of the entire program. In our model, a program is a module, which may be either simple or com\u00adpound.A \nsimple module consists of (i) a class table and (ii) a collection of function declarations. That is, \na simple mod\u00adule is just a program as described in the rest of this paper. It is well-formed if it satis.es \nthe well-formedness conditions of a whole program, as described in previous sections. A compound module \ncombines multiple modules, pos\u00adsibly renaming members (i.e., classes and functions) of its constituents. \nMore precisely, a compound module is a col\u00adlection of .lters, where a .lter consists of a module and \na complete mapping from names of members of the module to names. The name of a member that is not renamed \nis simply mapped to itself. The semantics of a compound module is the semantics of the simple module \nthat results from recursively .attening the compound module as follows: Flattening a simple module simply \nyields the same mod\u00adule.  Flattening a compound module C consisting of .lters (module/mapping pairs) \n(c1,m1),..., (cN ,mN ) yields a simple module whose class table and collection of func\u00adtion declarations \nare the unions of the class tables and collections of function declarations of s1,...,sN , where si is \nthe simple module resulting from .rst .attening ci and then renaming all members of the resulting simple \nmodule according to the mapping mi.  A compound module is well-formed if its .attened version is well-formed. \nThis requirement implies that the type hierar\u00adchies in each constituent component are consistent with \nthe type hierarchy in the .attened version. We can now use this model of modularity to see that we can \nseparately compile and combine modules. First consider the case of a collection of modules with no overlapping \nfunction names such that each module has been checked separately to ensure that the overloaded func\u00adtions \nwithin them satisfy the overloading rules. Because the type hierarchies of each constituent of a compound \nmodule must be consistent with that of the compound module, all overloaded functions in the resulting \ncompound module also obey the overloading rules. Now consider the case of a collection of separately \nchecked modules with some overlapping function names. When overloaded functions from separate modules \nare com\u00adbined, there are three rules that might be violated by the resulting overloaded de.nitions: (1) \nthe Meet Rule, (2) the No Duplicates Rule, (3) the Return Type Rule. If the Meet Rule is violated, the \nprogrammer need only de.ne yet an\u00adother module to combine that de.nes the missing meets of the various \noverloaded de.nitions. If the No Duplicates Rule or the Return Type Rule is violated, the programmer \ncan .x the problem by renaming functions from one or more com\u00adbined components to avoid the clash; the \nprogrammer can then de.ne another component with more overloadings of the same function name that dispatch \nto the various renamed functions in the manner the programmer intends.  Consider the following example:15 \nSuppose we have a type Number in module A, with a function: add : (Number, Number) . Number Suppose we \nhave the type and function: BigNum <: Number add : (BigNum, BigNum) . BigNum in module B and the type \nand function: Rational <: Number add : (Rational, Rational) . Rational in module C . Each of modules \nB and C satisfy the No Duplicates and Meet rules. Now, suppose we de.ne two compound modules D and E \n, each of which combines modules B and C without renaming add . In each of D and E , we have an ambiguity \nin dispatching calls to add with types (BigNum, Rational) or (Rational, BigNum) . Our rules require adding \ntwo declarations, one in each of D and E , to resolve these ambiguities. Now let us suppose we wish to \ncombine D and E into a compound component F . Without renaming, this combina\u00adtion would violate the No \nDuplicates Rule; each of D and E has an implementation of add(Bignum, Rational) . To re\u00adsolve this con.ict, \nthe program can rename add from both D and E , and de.ne a new add in F . This new de.nition could dispatch \nto either of the renamed functions from D or E , or it could do something entirely different, depending \non the programmer s intent. 9. Related Work 9.1 Overloading and Dynamic Dispatch. Castagna et al. proposed \nrules for de.ning overloaded func\u00adtions to ensure type safety [4]. They assumed knowledge of the entire \ntype hierarchy (to determine whether two types have a common subtype), and the type hierarchy was as\u00adsumed \nto be a meet semilattice (to ensure that any two types have a greatest lower bound). Millstein and Chambers \ndevised the language Dubious to study how to modularly ensure safety for overloaded functions with symmetric \nmultiple dynamic dispatch (mul\u00adtimethods) in a type system supporting multiple inheritance [11, 12]. \nWith Clifton and Leavens, they developed Multi-Java [5], an extension of Java with Dubious semantics \nfor multimethods. Lee and Chambers presented F(EML) [9], a language with classes, symmetric multiple \ndispatch, and pa\u00adrameterized modules. In previous work [2], we built on the work of Millstein and Chambers \nto give modular rules for a core of the Fortress language [1], which supports multiple inheritance and \ndoes not require that types have expressible meets (i.e., the types that can be expressed in the language \nneed not form a meet semilattice), but de.nes an exclusion 15 Suggested by an anonymous reviewer of a \nprevious version of this paper. relation on types to allow more valid overloadings. For de\u00adtailed comparison \nof modularity and dispatch for these sys\u00adtems, see the related work section of our previous paper [2]. \nNone of the systems described above support polymor\u00adphic functions or types. F(EML) s parameterized modules \n(functors) provide a form of parametricity but they cannot be implicitly applied; the functions de.ned \ntherein cannot be overloaded with those de.ned in other functors. This pa\u00adper extends our previous work \n[2] with parametric polymor\u00adphism for both types and top-level functions. Overloading and multiple dispatch \nin the context of poly\u00admorphism has previously been studied by Bourdoncle and Merz [3]. Their system, \nML=, integrates parametric poly\u00admorphism, class-based object orientation, and multimeth\u00adods, but lacks \nmultiple inheritance. Each multimethod (over\u00adloaded set) requires a unique speci.cation (principal type), \nwhich greatly simpli.es the checking of their equivalent of the Return Type Rule: the return type of \neach de.nition needs to be compared only with the return type of the prin\u00adcipal type. Also, to check \ntheir equivalent of the Meet Rule, the entire type hierarchy relevant to the multimethod must be known, \nso in general, this check must be done at link time. Finally, their type system does not provide any \nexclusion re\u00adlation. On the other hand, ML= allows variance annotations on type constructors something \nwe defer to future work. Litvinov [10] developed a type system for the Cecil lan\u00adguage, which supports \nbounded parametric polymorphism and multimethods. Because Cecil has a type-erasure seman\u00adtics, statically \nchecked parametric polymorphism has no ef\u00adfect on run-time dispatch.  9.2 Type classes Wadler and Blott \n[17] introduced the type class as a means to specify and implement overloaded functions such as equal\u00adity \nand arithmetic operators in Haskell. Other authors have translated type classes to languages besides \nHaskell [6, 14, 18]. Type classes encapsulate overloaded function declara\u00adtions, with separate instances \nthat de.ne the behavior of those functions (called class methods) for any particular type schema. Parametric \npolymorphism is then augmented to ex\u00adpress type class constraints, providing a way to quantify a type \nvariable and thus a function de.nition over all types that instantiate the type class. In systems with \ntype classes, overloaded functions must be contained in some type class, and their signatures must vary \nin exactly the same structural position. This uniformity is necessary for an overloaded function call \nto admit a princi\u00adpal type; with a principal type for some function call s con\u00adtext, the type checker \ncan determine the constraints under which a correct overloaded de.nition will be found. Because of this \nrequirement, type classes are ill-suited for .xed, ad hoc sets of overloaded functions like: println():() \n= println( ) println(s: String): () = ...  or functions lacking uniform variance in the domain and range16 \nlike: bar(x: Z): Boolean = (x = 0) bar(x: Boolean): Z = if x then 1 else 2 end bar(x: String): String \n= x With type classes one can write overloaded functions with identical domain types. Such behavior is \nconsistent with the static, type-based dispatch of Haskell, but it would lead to ir\u00adreconcilable ambiguity \nin the dynamic, value-based dispatch of our system. A broader interpretation of Wadler and Blott s [17] \nsees type classes as program abstractions that quotient the space of ad-hoc polymorphism into the much \nsmaller space of class methods. Indeed, Wadler and Blott s title suggests that the unrestricted space \nof ad-hoc polymorphism should be tamed, whereas our work embraces the possible expressivity achieved \nfrom mixing ad-hoc and parametric polymorphism by specifying the requisites for determinism and type \nsafety. 10. Conclusion and Discussion We have shown how to statically ensure safety of over\u00adloaded, polymorphic \nfunctions while imposing relatively minimal restrictions, solely on function de.nition sites. We provide \nrules on de.nitions that can be checked modularly, irrespective of call sites, and we show how to mechanically \nverify that a program satis.es these rules. The type analysis required for implementing these checks \ninvolves subtyping on universal and existential types, which adds complexity not required for similar \nchecks on monomorphic functions. We have de.ned an object-oriented language to explain our system of \nstatic checks, and we have implemented them as part of the open-source Fortress compiler [1]. Further, \nwe show that in order to check many natural overloaded functions with our system in the context of a \ngeneric, object-oriented language with multiple inheritance, richer type relations must be available \nto programmers the subtyping relation prevalent among such languages does not afford enough type analysis \nalone. We have therefore introduced an explicit, nominal exclusion relation to check safety of more interesting \noverloaded functions. Variance annotations have proven to be a convenient and expressive addition to \nlanguages based on nominal subtyp\u00ading [3, 8, 13]. They add additional complexity to polymor\u00adphic exclusion \nchecking, so we leave them to future work. Acknowledgments This work is supported in part by the Engineering \nResearch Center of Excellence Program of Korea Ministry of Educa\u00adtion, Science and Technology(MEST) / \nNational Research Foundation of Korea(NRF) (Grant 2011-0000974). 16 With the multi-parameter type class \nextension, one could de.ne functions as these. A reference to the method bar, however, would require \nan explicit type annotation like :: Int -> Bool to apply to an Int. References [1] Eric Allen, David \nChase, Joe Hallett, Victor Luchangco, Jan-Willem Maessen, Sukyoung Ryu, Guy L. Steele Jr., and Sam Tobin-Hochstadt. \nThe Fortress Language Speci.cation Ver\u00adsion 1.0, March 2008. [2] Eric Allen, J. J. Hallett, Victor Luchangco, \nSukyoung Ryu, and Guy L. Steele Jr. Modular multiple dispatch with multiple inheritance. In SAC 07, 2007. \n[3] Franc\u00b8ois Bourdoncle and Stephan Merz. Type checking higher-order polymorphic multi-methods. In POPL \n97, 1997. [4] Giuseppe Castagna, Giorgio Ghelli, and Giuseppe Longo. A calculus for overloaded functions \nwith subtyping. Information and Computation, 117(1):115 135, 1995. [5] Curtis Clifton, Todd Millstein, \nGary T. Leavens, and Craig Chambers. MultiJava: Design rationale, compiler implemen\u00adtation, and applications. \nACM TOPLAS, 28(3), 2006. [6] Derek Dreyer, Robert Harper, and Manuel M. T. Chakravarty. Modular type \nclasses. In POPL 07, 2007. [7] James Gosling, Bill Joy, Guy Steele, and Gilad Bracha. The Java Language \nSpeci.cation, Third Edition. Addison-Wesley Longman, Amsterdam, 3 edition, June 2005. [8] Andrew J. Kennedy \nand Benjamin C. Pierce. On decidability of nominal subtyping with variance, September 2006. FOOL-WOOD \n07. [9] Keunwoo Lee and Craig Chambers. Parameterized modules for classes and extensible functions. In \nECOOP 06, 2006. [10] Vassily Litvinov. Constraint-based polymorphism in Cecil: Towards a practical and \nstatic type system. In OOPSLA 98, 1998. [11] Todd Millstein and Craig Chambers. Modular statically typed \nmultimethods. Information and Computation, 175(1):76 118, 2002. [12] Todd David Millstein. Reconciling \nsoftware extensibility with modular program reasoning. PhD thesis, University of Wash\u00adington, 2003. [13] \nMartin Odersky. The Scala Language Speci.cation, Version 2.7. EPFL Lausanne, Switzerland, 2009. [14] \nJeremy G. Siek. A language for generic programming. PhD thesis, Indiana University, Indianapolis, IN, \nUSA, 2005. [15] Vincent Simonet and Franc\u00b8ois Pottier. A constraint-based ap\u00adproach to guarded algebraic \ndata types. ACM Trans. Program. Lang. Syst., 29(1):1, 2007. [16] Daniel Smith and Robert Cartwright. \nJava type inference is broken: can we .x it? In OOPSLA 08, 2008. [17] P. Wadler and S. Blott. How to \nmake ad-hoc polymorphism less ad hoc. In POPL 89, 1989. [18] Stefan Wehr, Ralf L\u00a8ammel, and Peter Thiemann. \nJavaGI: Generalized interfaces for Java. In ECOOP 2007, 2007.     \n\t\t\t", "proc_id": "2048066", "abstract": "<p>In previous work, we presented rules for defining overloaded functions that ensure type safety under symmetric multiple dispatch in an object-oriented language with multiple inheritance, and we showed how to check these rules without requiring the entire type hierarchy to be known, thus supporting modularity and extensibility. In this work, we extend these rules to a language that supports parametric polymorphism on both classes and functions.</p> <p>In a multiple-inheritance language in which any type may be extended by types in other modules, some overloaded functions that might seem valid are correctly rejected by our rules. We explain how these functions can be permitted in a language that additionally supports an exclusion relation among types, allowing programmers to declare \"nominal exclusions\" and also implicitly imposing exclusion among different instances of each polymorphic type. We give rules for computing the exclusion relation, deriving many type exclusions from declared and implicit ones.</p> <p>We also show how to check our rules for ensuring the safety of overloaded functions. In particular, we reduce the problem of handling parametric polymorphism to one of determining subtyping relationships among universal and existential types. Our system has been implemented as part of the open-source Fortress compiler.</p>", "authors": [{"name": "Eric Allen", "author_profile_id": "81100652164", "affiliation": "Oracle Labs, Austin, TX, USA", "person_id": "P2839307", "email_address": "eric.allen@bazaarvoice.com", "orcid_id": ""}, {"name": "Justin Hilburn", "author_profile_id": "81490644681", "affiliation": "Oracle Labs, Burlington, MA, USA", "person_id": "P2839308", "email_address": "justin.hilburn@oracle.com", "orcid_id": ""}, {"name": "Scott Kilpatrick", "author_profile_id": "81490691999", "affiliation": "University of Texas at Austin, Austin, TX, USA", "person_id": "P2839309", "email_address": "scottk@cs.utexas.edu", "orcid_id": ""}, {"name": "Victor Luchangco", "author_profile_id": "81100464444", "affiliation": "Oracle Labs, Burlington, MA, USA", "person_id": "P2839310", "email_address": "victor.luchangco@oracle.com", "orcid_id": ""}, {"name": "Sukyoung Ryu", "author_profile_id": "81100170344", "affiliation": "KAIST, Daejeon, South Korea", "person_id": "P2839311", "email_address": "sryu.cs@kaist.ac.kr", "orcid_id": ""}, {"name": "David Chase", "author_profile_id": "81542812556", "affiliation": "Oracle Labs, Burlington, MA, USA", "person_id": "P2839312", "email_address": "david.r.chase@oracle.com", "orcid_id": ""}, {"name": "Guy Steele", "author_profile_id": "81100586340", "affiliation": "Oracle Labs, Burlington, MA, USA", "person_id": "P2839313", "email_address": "guy.steele@oracle.com", "orcid_id": ""}], "doi_number": "10.1145/2048066.2048140", "year": "2011", "article_id": "2048140", "conference": "OOPSLA", "title": "Type checking modular multiple dispatch with parametric polymorphism and multiple inheritance", "url": "http://dl.acm.org/citation.cfm?id=2048140"}