{"article_publication_date": "10-22-2011", "fulltext": "\n SOS: Saving Time in Dynamic Race Detection with Stationary Analysis Du Li, Witawas Srisa-an, and Matthew \nB. Dwyer Department of Computer Science and Engineering University of Nebraska-Lincoln Lincoln, NE 68588-0115 \n {dli,witty,dwyer}@cse.unl.edu Abstract Data races are subtle and dif.cult to detect errors that arise \nduring concurrent program execution. Traditional testing techniques fail to .nd these errors, but recent \nresearch has shown that targeted dynamic analysis techniques can be de\u00adveloped to precisely detect races \n(i.e., no false race reports are generated) during program execution. Unfortunately, precise race detection \nis still too expensive to be used in practice. State-of-the-art techniques still slow down program execution \nby a factor of eight or more. In this paper, we incorporate an optimization technique based on the observation \nthat many thread-shared objects are written early in their lifetimes and then become read\u00adonly for the \nremainder of their lifetimes; these are known as stationary objects. The main contribution of our work \nis the insight that once a stationary object becomes thread-shared, races cannot occur. Therefore, our \nproposed approach does not monitor access to these objects. As such, our system only incurs an average \noverhead of 45% of that of an implemen\u00adtation of FastTrack, a low-overhead dynamic race detector. We \nthen compared the effectiveness of our approach to de\u00adtect races in deployed environments with that of \nPacer,a sampling based race detector based on FastTrack. We found that our approach can detect over .ve \ntimes more races than Pacer when we budget 50% for runtime overhead. Categories and Subject Descriptors \nD.3.4 [Programming Language]: Processors Optimization, Run-time environ\u00adments General Terms Experimentation, \nLanguages, Performance Keywords Race, concurrency, threading, monitoring Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 11, October 22 27, 2011, Portland, Oregon, \nUSA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0940-0/11/10. . . $10.00 1. Introduction Modern microprocessors \nprovide multiple processing cores per chip. As such, a natural way for developers to achieve higher performance \nis to employ thread-level parallelism in their applications. However, writing correct concurrent pro\u00adgrams \ncan be challenging, especially achieving proper syn\u00adchronization of access to shared resources. Improper \nsyn\u00adchronization can lead to runtime errors such as deadlocks and data races, which are dif.cult to detect, \nisolate, and cor\u00adrect. As an example, data races are often sensitive to exe\u00adcution interleaving, and \nhence, may only occur infrequently and intermittently. Further, many of these races do not al\u00adways produce \nincorrect results, making it dif.cult to de\u00adtect their presence. Thus, we have seen many instances in \nwhich these races stay dormant during the testing period and then manifest themselves during deployed \nsystem op\u00aderation [2, 13, 28]. Detecting data races can lead to improved dependabil\u00adity of multithreaded \napplications. However, doing so can prove to be dif.cult. Scaling static program analyses to large code \nbases requires conservative approximation of potential sources of data races [1, 32, 44] many of which \nare infea\u00adsible. On the other hand, dynamic detection techniques that use vector clocks to track the \nordering of accesses to indi\u00advidual object .elds are precise, but incur very high runtime overhead [11, \n20, 35, 36]. Dynamic detection techniques based on recording information at the class level rather than \nthe object level, such as lockset approaches, can reduce run\u00adtime overhead, but they can also issue many \nfalse race re\u00adports [19, 39]. FastTrack, a dynamic race detection system introduced by Flanagan and Freund, \ncan reduce the overhead of vector clock based race detection to be about the same as that of lockset \nbased race detection, but without compromising the precision provided by the use of vector clocks [20]. \nThe key idea in FastTrack is to replace a large percentage of full vector clock operations with a more \ntime-and space\u00adef.cient operation to track access ordering. According to their reported results, even \nwith this optimization FastTrack still slows applications down by a factor of eight on average, making \nit infeasible for use in many testing and system deployment contexts. To reduce the runtime overhead \nof dynamic analyses, a number of researchers have explored the use of sampling techniques, e.g., [3, \n8, 18]. For race detection, the Pacer sys\u00adtem adds sampling to the FastTrack algorithm [11]. Sam\u00adpling \nis effective in reducing runtime overhead, but there is a corresponding reduction in data race detection. \nAs an exam\u00adple, when the sampling rate of Pacer is set to 1% and 3%, the execution overheads are on average \n52% and 86%, respec\u00adtively. At 86% overhead, the average race detection rate is 30% (ranging from 0.9% \nto 82.7% on the programs studied). When the sampling rate is set to 100% (i.e., Pacer detects all possible \ndynamic races), the average execution slowdown is a factor of 12. State-of-the-art dynamic race detection \ntechniques such as FastTrack and Pacer are too expensive to be turned on all the time in deployed systems. \nMoreover, when sampling is used to drive overhead down to a tolerable level, e.g., less than 100%, the \nnumber of detected data race drops signi.cantly. In this paper, we introduce an optimization approach \nthat eliminates the need to monitor a large number of objects and shared accesses to .elds of those objects \nfor race detection. The proposed optimization is based on the notion of sta\u00adtionary .eld introduced by \nUnkel and Lam [43]. A stationary .eld is a .eld that is written during the initialization period and \nafter the .eld has been read, there are no more write operations. We extend the de.nition of stationary \nto de\u00ad.ne stationary objects. The key insight that motivates our work is that a race occurs when two \naccesses to a shared variable are not correctly synchronized, and at least one ac\u00adcess is a write [11, \n26]. Because stationary objects are not written after escaping, they cannot be involved in races. We \nde.ne a dynamic analysis to determine whether an object is stationary and couple it with the FastTrack \nalgorithm where processing of read operations is disabled when an object is stationary. We implemented \nthis analysis on top of the Pacer s code base in Jikes RVM and explored its effectiveness in re\u00adducing \nthe race detection cost of the FastTrack algorithm implemented as part of Pacer. Note that in the remain\u00adder \nof this paper, our evaluation of FastTrack is based on Pacer s implementation of the algorithm. Since \nthe overhead reduction corresponds directly to the reduction in opera\u00adtions processed, we expect a similar \nreduction in overhead by using stationary-object analysis in combination with the RoadRunner-based FastTrack \nimplementation [21]. Additionally, we evaluated the ability of our optimization to increase detection \nof races by Pacer at low sampling rates. We also implemented an additional LiteRace-like optimiza\u00adtion \n[30] that disables stationary object analysis on hot methods and explore its effects on overhead and \nrace detec\u00adtion effectiveness. We show, through experimental evalua\u00adtion using 6 multithreaded Java benchmarks, \nthat optimizing dynamic data race detection in this way is effective in reduc\u00ading the average overhead \nof FastTrack by 55% and increas\u00ading the effectiveness of race detection with a 50% overhead budget by \nnearly a factor of 6 over Pacer. The key contributions of the paper lie in (1) the design of a lightweight \ndynamic analysis that can eliminate the need to monitor a large number of read accesses for precise data \nrace detection, (2) an evaluation of the potential overhead reduction that can be achieved by coupling \nthis analysis with state-of-the-art race detection approaches, and (3) an evaluation of the potential \nimprovement in the detection of data races that can be achieved at very low overhead rates by coupling \nthe analysis with Pacer. 2. Motivation and Overview For much of the previous decade, researchers in dynamic \ndata race detection have distinguished two classes of tech\u00adniques with different strengths. Lockset-based \ntechniques, such as Eraser [39] and its descendants [15, 19, 33, 46], at\u00adtempt to ensure that all reads \nand writes are guarded by some locking protocol (i.e., the acquisition and release of a moni\u00adtor). Such \ntechniques are generally regarded as ef.cient (i.e., incurring low runtime overhead) but imprecise (i.e., \nreport\u00ading false races). In contrast, vector-clock-based techniques, such as DJIT+ [35] and its descendants \n[11, 20], track the relative order of read and write operations on .elds of indi\u00advidual objects. They \nhave the advantage of being precise, but they are less ef.cient. Through a careful analysis of the most \ncommonly exe\u00adcuted processing performed by vector clock techniques, the FastTrack [20] technique has \nbridged the gap between these techniques allowing precise data race detection to be per\u00adformed at roughly \nthe cost of lockset-based techniques. Even with these advances, the cost of dynamic data race detection \nremains very high on average FastTrack results in over\u00adhead of 850% across a range of programs [20]. \nTo see why overhead can be so signi.cant, consider the simple illustrative example in Figure 1. The program \nhas two static instances of class Datum which hold a value, v, that is operated on through two method \ncalls. The programmer has synchronized the cinc() method to protect against data races, but has failed \nto synchronize isReady(). Two instances of the SimpleRacer thread are allocated and started. Each thread \niterates and if the s datum is ready, then every hundredth iteration the n datum is operated on and tested. \nChecking for data races with a tool like FastTrack in\u00advolves instrumenting the program to monitor all \nlock re\u00adlated operations, e.g., the implicit enter and exit moni\u00adtors performed when cinc() is called, \nand all read and write operations, e.g., each call to cinc() involves two reads and one write of v. Including \nthe writes that are per\u00ad public class SimpleRacer extends Thread {static Datum s = new Datum(); static \nDatum n = new Datum(); public static void main(String[] args) {new SimpleRacer (). start (); new SimpleRacer \n(). start (); } public void run () {for (int i= 0; i <100000; i ++){if (s.isReady() &#38;&#38; (i % 100 \n== 0)) { n. cinc(i ); if (n.isReady()) { ... } } } }} class Datum {int v= 1; synchronized void cinc \n( int x) { v=(x == v) ?v+1 : v; } boolean isReady () { return v != 0; }} Figure 1. Simple Data Race \nexample formed during initialization of the static Datum .elds, a run of SimpleRacer.main() involves \n206000 reads, 2002 writes, and 2000 monitor enter and exits. These 210002 op\u00aderations cause the execution \nof monitoring code, which can sometimes be costly as is the case with the vector clock operations required \nto monitor locking operations. Running FastTrack on the above program detects a num\u00adber of data races. \nFor example, a read-write race is detected between the read in isReady(), on n, and the write in cinc(). \nWhile useful, the fact that this analysis incurs an overhead of 323% for this small program with just \na few shared objects demonstrates that the broad applicability of even state-of-the-art data race detectors \nis limited. 2.1 Further Optimization of Race Detection While the example considered here is small, it \ndoes resem\u00adble more realistic multi-threaded Java programs in the preva\u00adlence of read operations which \nhave a strong in.uence on the cost of data race detection. In a broad study of multi\u00adthreaded Java programs \n[20], reads comprise the vast major\u00adity (82%) of operations that must be monitored for precise race detection. \nTechniques like FastTrack focus on optimizing the pro\u00adcessing of the common case read and write operations, \nby replacing expensive vector clocks with a more ef.cient data structure. In certain situations the processing \nof read oper\u00adations can be skipped entirely. For example, most data race detectors for Java skip the \nprocessing of reads of final .elds. This will not result in a loss of data race detection since all writes \nto final .elds are con.ned to construc\u00adtor calls and, thus, only read operations are possible from multiple \nthreads. Unfortunately, it has been shown across a range of programs that relatively few .elds (never \nmore than 20%) are declared final [43] and, more importantly for data race detection, reads of final \n.elds appear to be quite infrequent (on average less than 3%). This limits the effec\u00adtiveness of this \noptimization. Final .elds are rather restrictive since they require .elds to be written in constructor \ncalls [34]. In multi\u00adthreaded programs it is possible for a thread allocating an object to perform non-trivial \ncomputation to initialize what amount to read-only .elds. If this initialization occurs out\u00adside the \nconstructor, then the .eld cannot be declared .nal. If the initialization is complete before the object \nbecomes thread shared, then conceptually skipping the processing of reads for data race detection should \nbe possible. What is needed is a means of determining that objects have this ac\u00adcess pattern as we show \nin the next section the concept of stationary .elds introduced by Unkel and Lam can be adapted to do \njust that. To illustrate the potential bene.ts of this optimization, re\u00adconsider the example from Figure \n1. The v .eld of Datum s is initialized to 1, but cinc() can change its value, and therefore, it cannot \nbe declared as final. In the SimpleRacer thread run() methods there are no calls to cinc() on s and, \nthus, no writes to s.v are performed after it is initialized. The program executes 200000 calls to s.isReady(); \n100000 in each thread. This results in 200000 reads of s.v, none of which can ever be involved in a data \nrace. If it were possible to skip processing of the read operations on s.v, that would eliminate processing \nof 95% of the operations that need to be monitored for data race detection on the program. 2.2 Challenges \nand Opportunities In principle, this sounds straightforward, but several chal\u00adlenges must be overcome \nto realize this optimization in the context of modern data race detection algorithms. First, we must \nenable and disable the processing of read operations on a per object basis. Doing this ef.ciently is \nnot possible using an instrumentation approach; RoadRunner\u00adbased FastTrack is implemented through instrumentation. \nAs we discuss in Section 3, our approach uses per object meta-data encoded in the VM s object structure \nto control the processing of the race detection algorithms. Second, we must detect when an object s .eld \nwill only be read during the portion of the object s lifetime when it is thread-shared. We could use \na static analysis, such as Unkel and Lam s stationary .eld analysis [43], but instead, as we discuss \nin Section 3, our approach uses an ef.cient dynamic analysis to determine object .elds that are read\u00adonly \nwhen shared. This analysis sets the per object meta-data that controls data race algorithm processing. \n Third, since we use a dynamic analysis to determine read\u00adonly object .elds we must account for the fact \nthat such an analysis cannot know the future access pattern on the object. We achieve this by designing \nan optimistic analysis that assumes each object is read-only once it escapes its creating thread and \nthen reclassi.es an object once a write is observed. While ef.cient, the weakness of this approach is \nthat it creates a window in a program trace within which data races may not be detected. We discuss the \nimpact of this on data race detection in Section 3. As we demonstrate, this optimization strategy can \nwork with essentially any object-based data race detection ap\u00adproach. It can be applied to signi.cantly \nreduce the over\u00adhead of data race detection. It can also be coupled with exist\u00ading sampling-based data \nrace detection techniques to signi.\u00adcantly improve the number of data races that can be detected when \nmonitoring at very overheads, e.g., below 100%. We explore this in detail in Section 4. 3. Stationary-Object \nOptimization for Race Detection Unkel and Lam introduced the concept of stationary .elds as a generalization \nof .nal .elds. The de.nition of stationary .elds extends that of .nal .eld by allowing a stationary .eld \nto have multiple writes across multiple methods as long as these write operations happen before all read \noperations. A .nal .eld, on the other hand, is written only once during execution [34]. They then proposed \nan automatic inference approach to statically detect these stationary .elds [43]. The approach monitors \nread and write operations to each .eld during ini\u00adtialization. It then analyzes whether a .eld is written \naf\u00adter initialization; if it is, that particular .eld becomes non\u00adstationary. To reduce analysis overhead, \nthey make a sim\u00adplifying assumption that an object initialization occurs be\u00adfore that object s reference \nis stored into any object [43]. Af\u00adter the reference is stored, the object is referred to as lost. In \ntheir implementation, lost objects are identi.ed by monitor\u00ading putfield bytecode [42]. In terms of the \nrelationship between lost objects and method-escaping objects, lost ob\u00adjects are only a subset of method-escaping \nobjects because the de.nition of lost does not account for any reference re\u00adturns at the end of a method \ncall. Furthermore, a subset of lost objects may be thread-escaping in multi-threaded appli\u00adcations. The \nresult of their empirical study using 26 benchmark programs showed that stationary .elds are prevalent \nin Java programs. The percentage of stationary reference-type .elds ranges from 44% to 59% when both \napplications and li\u00adbraries are considered. For primitive-type .elds, the percent\u00adage of stationary-.eld \nis greater than 30% in each of the evaluated benchmarks. Two key insights from this study are applicable \nto dynamic race detection in general: 1. There is no need to monitor for races before an object is lost \nbecause the object is still thread local. Note that Unkel and Lam use the notion of lost to indicate \nthe end of initialization. However, from the data race detection point of view, lost also indicates that \nan object may no longer be thread-local and can participate in races. 2. Races cannot occur on stationary \n.elds because they are read-only after they have become lost. As a reminder, in order for data race to \noccur, at least one concurrent access must be a write.  These insights tell us that monitoring only \nnon-stationary .elds should be suf.cient for race detection. Next, we ex\u00adplain some of the key concepts \nand describe how this insight can be applied to existing dynamic race detection approaches such as FastTrack. \n3.1 Major Concepts There are three major concepts that are essential for this work: FastTrack, stationary \nobject, and three categories of objects that are used as part of the stationary object analysis. FastTrack. \nIn vector clock-based race detection mecha\u00adnisms, each vector clock (VC) and VC operation incur O(n) \ntime and space overheads, where n is the number of threads, respectively (see Section 6 for more information \nabout vec\u00adtor clock-based race detection). In FastTrack, the write vec\u00adtor clock is replaced with an \nepoch a lightweight repre\u00adsentation for recording the last write performed on a .eld that contains the \nsingle clock value, c, at which the write occurred and the thread that performed the write, t. Updat\u00ading \nan epoch and comparing an epoch to the general vector clock are O(1)-time operations. In addition, FastTrack \ncan use epochs to replace vector clocks in most of the read op\u00aderations. As such, FastTrack is an order \nof magnitude faster than a traditional vector clock-based race detector [20] and 2.3 times faster than \nDJIT+, a VC-based race detector for C++ [20, 36]. Stationary Object. We extend the de.nition of the term \nstationary to objects. That is, a stationary object is an object that contains only stationary .elds. \nIf there is at least one .eld in the object that is not stationary, the object is considered non-stationary. \nThis new de.nition allows us to control race detection monitoring at the object-level instead of the \n.eld-level. While object-level monitoring is a coarser monitoring granularity (e.g., if an object has \nmultiple .elds but only one .eld is non-stationary, any read/write access to this object must still be \nmonitored for races), it eases the implementation of the mechanism to enable or disable the monitoring \nprocess. Categorizing Objects. Because our approach only monitors objects for races when they have become \nnon-stationary, we .rst need to record each object s status. An object s status can be either initial, \nlost, or non-stationary; initial and lost objects are interpreted as being stationary. Every object is \nset to initial upon creation. Once the reference to an object is assigned to a .eld in another object, \nits status changes to lost. Note that this is the de.nition of lost introduced by Unkel and Lam [43]. \nIf a .eld in a lost object is written, then its object s status changes to non\u00adstationary. Previous work \nhas shown that there are several ways to record object meta-data. We develop our proposed technique inside \na JVM so our approach embeds meta-data in the object s structure, an approach similar to that used in \nQVM and other work to maintain runtime information as part of dynamic analysis [3, 11, 24].  3.2 Supporting \nStationary Object Analysis Dynamic data race detection involves monitoring operations related to locking \nas well as reads and writes of memory locations from different threads. Monitoring Lock Usage. Our approach \nmonitors lock usage information, such as monitor enter and monitor exit operations, inside the JVM [11, \n45]. The captured infor\u00admation is then used to perform race detection and manage vector clocks in a manner \nthat is identical to existing race detection algorithms. That is, the vector clock for a lock is updated \nwhen a thread acquires the lock, and the clock for a thread is incremented when the thread releases the \nlock. Conceptually, if a safe determination of which objects are stationary were performed, then lock \noperations on those ob\u00adjects would not need to be performed. This might be done, for example, via a static \nanalysis that determines that all in\u00adstances of a class are stationary. We use a dynamic analysis that \noptimistically determines whether objects are stationary and then reverts to full data race processing \nwhen it is de\u00adtermined that an object is non-stationary. Consequently, we prefer a safe treatment of \nlock operations and monitor them fully for race detection. Since lock operations are relatively rare \n(3.2% in the FastTrack study), the performance penalty for this decision is modest. Monitoring Reads \nand Writes. We implemented our mech\u00adanism as read-and write-barriers. The stationary object anal\u00adysis \ncode as well as race detection code is injected into the processing of various bytecodes such as putfield \nand getfield, which perform write and read operations, re\u00adspectively, on objects. Algorithm 1 ReadMonitor() \nInput: objRef, objField 1: if objRef.status == nonStationary { 2: checkRaceWrite-Read(objRef.objField, \ncurrentThread) 3: updateReadVC(objRef.objField, currentThread) 4: } Algorithm 1 describes the process \nto monitor for races after a read operation. In the FastTrack algorithm, a read op\u00aderation requires a \ncheck with previous writes on that vari\u00adable for races; the operation is simply shown as function checkRaceWrite-Read \nin the algorithm (line 2). Next, FastTrack updates the read component of the vector clock of that particular \nthread. The operation is shown as func\u00adtion updateReadVC (line 3) [20]. Note that these basic VC operations \nare clearly described in [11, 20]. Because our technique only monitors for races when an object becomes \nnon-stationary, it must check the object s status (the code for this check is highlighted in gray) for \neach read operation. If the status is non-stationary, race detection code is executed. Algorithm 2 PrimitiveWriteMonitor() \nInput: objRef, objField, primitiveValue 1: if objRef.status == lost 2: objRef.status = nonStationary \n3: 4: if objRef.status == nonStationary {checkRaceWrite-Read(objRef.objField, currentThread) 5: checkRaceRead-Write(objRef.objField, \ncurrentThread) 6: updateWriteVC(objRef.objField, currentThread) 7: } Because our algorithm keeps track \nof lost objects, our analysis needs to distinguish between writes of primitive data and writes of reference \ndata. Algorithm 2 describes the steps in our proposed algorithm to monitor for races after primitive-typed \ndata, primitiveValue, is written to a .eld, ob\u00adjField, of an object, objRef. Again, the code to support \nsta\u00adtionary object analysis is highlighted in gray. The unhigh\u00adlighted lines show the generic race detection \noperations that must be performed after a write. First, our analysis checks the status of the written-to \nob\u00adject. If it is lost, then the write operation causes the object s status to change to non-stationary \n(line 1 and 2). When the status is non-stationary (line 3), the race detection monitor\u00ading code (line \n4 to 6) is executed. When reference-type data is written to a .eld in an ob\u00adject, additional analysis \nto track lost objects is needed. In Algorithm 3, lines 3 to 9 are exactly the same as those in Al\u00adgorithm \n2. However, lines 1 and 2 are needed to change the object s status of referenceValue from initial to \nlost because the write operation makes the object pointed to by reference-Value accessible from objRef. \n 3.3 Implementation We implemented our stationary-object analysis on top of Pacer, a sampling-based race \ndetection technique based on FastTrack [10]. Pacer implements the FastTrack algorithm inside Jikes RVM \n3.1.0, a high performance meta-circular Java Virtual Machine (JVM) [23]. In addition to implement\u00ading \nthe FastTrack algorithm, Pacer is also capable of per\u00adAlgorithm 3 ReferenceWriteMonitor() Input: objRef, \nobjField, referenceValue 1: if referenceValue.status == initial 2: referenceValue.status = lost 3: if \nobjRef.status == lost 4: objRef.status = nonStationary 5: 6: if objRef.status == nonStationary {checkRaceWrite-Read(objRef.objField, \ncurrentThread) 7: checkRaceRead-Write(objRef.objField, currentThread) 8: updateWriteVC(objRef.objField, \ncurrentThread) 9: } forming sampling in order to control the runtime overhead of race detection. We \nwill also use this sampling feature in our performance evaluation. Next, we describe some key com\u00adponents \nin our implementation. Metadata. To record the status of an object (i.e., initial, lost, non-stationary), \nwe used two bits from the object s header .eld in RVM. Using these two bits does not incur additional \nstorage space, but requires masking and unmasking opera\u00adtions. We also explored an alternative approach \nto add one extra word per object to record status information. This ap\u00adproach eliminates the masking \nand unmasking operations, but increases space overhead by one word per object, which can affect heap \nusage and GC performance. Our investiga\u00adtion revealed that the bit stealing design performs slightly \nbetter than the latter approach. Instrumentation. To detect status transitions, we instru\u00admented all \nwrite operations at runtime. We took advantage of the existing write barrier infrastructure in Jikes \nRVM. There are two kinds of write barriers, primitive type and reference type. Primitive write barriers \ncapture writes to primitive\u00adtyped .elds. On the other hand, reference write barriers cap\u00adture writes \nto reference-typed .elds. Since the mechanism to process objects and arrays is similar, we do not differentiate \nbetween objects and arrays in our discussion. We also modi\u00ad.ed the read-barrier mechanism in Pacer to \ncheck an object s status before executing the race detection code. As shown in Algorithm 3, there are \ntwo kinds of status transitions in stationary-object analysis that must be detected at runtime: Transition \n1: initial . lost Transition 2: lost . non-stationary The reference-type write barriers have been implemented \nto detect both transitions. Once a reference is written to a host object in the heap, the referenced \nobject is marked as lost. The status of the host object also changes to non\u00adstationary if and only if \nthe current status of the host object is lost. On the other hand, the primitive-type write barrier only \ndetects Transition 2. Once a .eld is written, the host object is marked as non-stationary if and only \nif its current status is lost. The write-barrier code executes right before the actual write happens. \n There are two compilers in Jikes RVM: baseline and op\u00adtimizing. Every method is initially compiled by \nthe baseline compiler prior to its .rst execution. Later, if the method be\u00adcomes hot, the optimizing \ncompiler recompiles the method with more optimizations. Our system can be con.gured to apply instrumentation \nrelated to stationary-object analysis to the baseline, the optimizing, or both compilers. Disabling in\u00adstrumentation \nin the optimizing compiler allows us to realize a form of optimized data race detection that mimics the \nintu\u00adition of LiteRace [30] races in frequently executed code are rare, whereas races in cold code are \nmore prevalent. In Section 4, we report the result of using two con.gurations: one that enables instrumentation \nin both compilers and an\u00adother that enables instrumentation only in the baseline com\u00adpiler. Enabling/Disabling \nRace Detection. Pacer s implementa\u00adtion of FastTrack adapts all read/write operations to update and compare \nvector clocks. We built our stationary-object analysis on top of Pacer. In this implementation, each \ntime a read or write operation occurs, our system checks the sta\u00adtus of the host object. If its status \nis initial or lost, our sys\u00adtem does not execute the race detection code. Otherwise, it performs race \ndetection. Our implementation can also work with Pacer s existing sampling feature, which can be en\u00adabled \nor disabled at the end of each garbage collection cy\u00adcle. Next, we describe the possible impacts of our \nstationary\u00adobject analysis and report our experimental result that quan\u00adtify these impacts. 3.4 Effects \non Race Detection Coverage As shown in the three algorithms, our approach incurs a small overhead to \nperform a status check for each of ini\u00adtial or lost object and full race detection overhead for non\u00adstationary \nobjects. This is much different than FastTrack, in which it performs race detection analysis and vector \nclock updates on every object. While this can result in a signi.cant saving, it does come at a cost of \nmissing a particular type of race that occurs at a particular time. Next, we describe the ability of \nour ap\u00adproach to detect Write-Write, Read-Write, and Write-Read races and explain why our approach misses \na particular kind of race. We also report the result of comparing the effective\u00adness of our race detection \nagainst that of FastTrack. Detecting Write-Write Races. One key step of stationary object analysis is \ndetecting a write operation on a lost ob\u00adject. When that occurs, the object s status changes to non\u00adstationary \nand from this point forward, race detection is en\u00adabled on this object. As such, our technique can detect \nany write-write race that occurs in a particular program execu\u00adtion. Detecting Write-Read Races. When \na read operation is performed on a non-stationary object, the .rst step of race detection is to check \nif the read races with prior writes. Since we turn on race detection when write operations are performed \non lost and non-stationary objects, our system already maintains suf.cient information on these objects \nto detect races. As such, our technique can detect any write\u00adread race that occurs in a particular program \nexecution. Detecting Read-Write Races. During normal race detection when a write operation is performed \non a lost object, a check with prior reads is performed. However, because we do not monitor read operations \nfor initial or lost objects, our system does not have suf.cient information to detect the .rst instance \nof read-write race when an object is in the lost state. As such, the .rst instance of a read-write race \non an object goes undetected in our system. However, if the same type of race occurs on the same object \nlater on, our system would be able to detect it because by then the object has already become non-stationary, \nan object state in which full race detection monitoring is enabled. Next, we quantify the extent to which \nour optimization results in undetected races. Quantifying Undetected Races. We conducted an experi\u00adment \nto quantify the number of races that goes undetected in our approach when compared to those detected \nby the Fast-Track implementation in Pacer. Table 1 describes a set of six benchmarks, which are commonly \nused by researchers to evaluate Java systems. Three are from the DaCapo 2006 benchmark suite (eclipse, \nhsqldb, and xalan) with two additional benchmarks from the DaCapo-9.12-bach suite (avrora and sun.ow) \n[4]. The three from the 2006 suite were used in the evaluation of Pacer. Note that some benchmarks in \nthe 2009 suite overlap with those in the 2006 suite. In addition, not all benchmarks in the 2009 suite \ncan run on our version of Jikes RVM with Pacer. We also attempted to obtain the source code of pseudo\u00adjbb2000, \nwhich was also used to evaluate Pacer. Unfortu\u00adnately, we were not able to do so; as such, we used a \nnewer version called pseudojbb2005, which is SPECjbb2005 that has been modi.ed to generate predictable \nworkload in each run [40]. We ran each benchmark 50 times and identi.ed races that have been detected \nin these 50 runs. This is necessary because races occur non-deterministically, and therefore, a large \nnumber of runs are needed to detect most of the possi\u00adble races. We also chose 50 runs to replicate the \nexperiment used to evaluate the performance of Pacer. Detected races are reported in Columns 2 and 3 \nin Ta\u00adble 2. Note that we used the same methodology as that used by the authors of Pacer, in which we \nreport races that occur over 25 times. Our approach misses 5 out of 116 races de\u00adtected by FastTrack. \nFour of the missed races are in eclipse and one is in xalan; no races are missed in the other four benchmarks. \nThus, relative to FastTrack one must judge our Benchmark Description Number of Threads avrora Discrete \nevent simulator of a sensor network (DaCapo 2009). 27 eclipse Executes some of non-GUI jdt performance \ntests for Eclipse (DaCapo 2006). 16 hsqldb Execute a number of transactions against a model of a banking \napplication (DaCapo 2006). 402 pseudojbb A program emulating 3-tier system (a modi.ed SPECjbb2005). 17 \nsun.ow A multi-threaded global illumination rendering system (DaCapo 2009). 5 xalan Transforms XML documents \ninto HTML (DaCapo 2006). 9 Table 1. Basic description of each benchmark. optimization as somewhat lossy \n note that it retains the precision of reported races. From the programmer s point of view, one important \nsource of information that is used to .x races is the ac\u00adtual source of the reported data races. This \ninformation is presented in a race report as bytecode indices within meth\u00adods. In some applications, \nwe observed that a source can participate in many races. Columns 4 and 5 in Table 2 re\u00adport identi.ed \nsources. As shown in the table, eclipse is the only benchmark for which our approach misses some of the \nsources (3). Note that while our approach did not detect one race in xalan, it could identify all sources \nof data races. When one is willing to sacri.ce some race detection for a reduction in the overhead of \nruntime monitoring, as is done in Pacer, the fact that our optimization is lossy has less impact. In \nthat setting, one must study the cost-bene.t of the technique, i.e., how fault detection varies with \noverhead, in which Section 4 discusses. Benchmark Detected Races FastTrack SO Identi.ed Sources FastTrack \nSO avrora 12 12 10 10 eclipse 27 23 32 29 hsqldb 23 23 28 28 pseudojbb 22 22 21 21 sun.ow 13 13 20 20 \nxalan 19 18 36 36  Table 2. Comparing the number of detected races and de\u00adtected bytecodes that cause \nraces (FastTrack versus our ap\u00adproach). 3.5 Reducing Monitored Objects and Operations Table 3 reports \nthe number of objects that an implementation of FastTrack monitors ( All Objects ), the number of objects \nthat remain stationary throughout the program execution ( Stationary Objects ), and the number of objects \nthat are determined to be non-stationary ( Non-Stationary Objects ). The percentage of all objects that \nare monitored when using the Stationary-object Optimization (SO) is reported in Fig\u00adure 2; these are \nthe non-stationary objects. There are four applications that must monitor fewer than 30% of the total \nnumber of objects, with pseudojbb monitoring less than 2%. The two remaining have signi.cantly more non-stationary \nobjects with avrora having just under 88%. While a reduction in the number of objects that requires \nmonitoring can provide a sense of the potential savings in race detection cost, a reduction in the number \nof moni\u00adtored operations ultimately determines the overhead. Table 4 shows the counts of read and write \noperations for an imple\u00admentation of FastTrack and for non-stationary objects using our SO. As expected, \nthe reductions due to the SO lie pri\u00admarily in the eliminated monitoring of read operations on stationary \nobjects. We also see a slight reduction in the num\u00adber of monitored write operations. We can achieve \nthis re\u00adduction because SO does not monitor any write to an object that is still in the initial state. \nFigure 3 illustrates the percentage of FastTrack opera\u00adtions that require monitoring under SO. There \nare four ap\u00adplications that must monitor fewer than 70% of monitored operations in an implementation \nof FastTrack with hsqldb monitoring about 40%. Three out of four applications (pseu\u00addojbb, sun.ow, and \nxalan) also have the largest percentage of stationary objects. However, for eclipse the SO eliminates \nthe need to monitor nearly 90% of the objects, and yet it still needs to monitor 71% of read/write operations. \nThis result shows that read operations are not distributed evenly among objects. In fact, a large number \nof objects that we stop mon\u00aditoring may not have many read/write operations. Next, we evaluate the impacts \nof the reduction in monitored opera\u00adtions on runtime performance. Benchmark All Objects Stationary Objects \nNon-Stationary Objects avrora 301796 37013 (12.26%) 264783 eclipse 1416852 1237967 (87.37%) 178885 hsqldb \n134959 48923 (36.25%) 86036 pseudojbb 8246421 8152388 (98.86%) 94033 sun.ow 2286384 2113066 (92.42%) \n173318 xalan 135852 97791 (71.98%) 38061 Table 3. Analysis of object demographics. The percentage of \nSO objects of all objects is reported in parentheses for each application. 4. Performance Evaluation \nIn this section, we evaluate the runtime performance of SO against that of the implementation of FastTrack \nin Pacer. As mentioned previously in Section 3.3, our approach can perform instrumentation in the baseline \ncompiler, optimiz\u00ading compiler, and both. As such, we present two versions of Figure 3. Percentage of \noperations that must be monitored in SO.   SO: the .rst version performs instrumentation in both com\u00adpilers \n(SO) and the second version performs instrumenta\u00adtion only in the baseline compiler (SOn). That is, there \nis no instrumentation to support stationary-object analysis when methods become hot and are recompiled \nby the optimizing compiler. We then evaluate the performance of these two ver\u00adsions and compare the race \ndetection effectiveness of SOn against that of SO. Lastly, we introduce SOs, which is based on SOn and \nincorporates the sampling feature of Pacer. One important objective of Pacer is to perform low-overhead \nrace detec\u00adtion in deployed systems. As shown in their paper, Pacer is able to detect races while maintaining \n86% runtime over\u00adhead. However, the sampling rate required to achieve this low overhead is 3% of all \nread/write operations which limits race detection effectiveness. We compare the race detection effectiveness \nof SOs against that of Pacer by maintaining .xed runtime overheads of 50%, 70%, 85% and 100%. We also \ndiscuss why applying the stationary-object optimization can increase the effectiveness of sampling-based \nrace detec\u00adtion systems such as Pacer. Benchmark FastTrack Reads (\u00d7106) Non-Stationary Reads (\u00d7106) \nFastTrack Writes (\u00d7106) Non-Stationary Writes (\u00d7106) avrora 25.85 20.37 (78.78%) 2.01 2.00 eclipse 63.41 \n40.65 (64.09%) 18.13 18.04 hsqldb 12.99 4.17 (32.11%) 1.90 1.87 pseudojbb 4.08 2.06 (50.51%) 1.34 1.33 \nsun.ow 9.76 6.80 (69.67%) 0.270 0.269 xalan 8.86 5.40 (61.03%) 1.47 1.45 Table 4. Comparing read and \nwrite operations between FastTrack and our approach. Note that we also report the percentage of Non-Stationary \nReads over FastTrack Reads for each application in parentheses. In terms of experimental methodology, \nwe executed each of the 6 benchmarks 10 times for each of the data race detection systems. The average \nperformance is reported. 4.1 Performance of SO Tables 3 and 4 show that the proposed SO can substantially \nreduce the numbers of objects and operations that must be monitored, respectively. The reduced monitoring \nefforts re\u00adsult in execution overhead reductions over that of FastTrack as reported in Table 5. On average, \nthe overhead of SO is 72% of that of Fast-Track (see gray bars in Figure 4). The lowest overhead of 60% \nof FastTrack s is achieved in hsqldb. We also see that in sun.ow the overhead is as high as 81% of FastTrack \ns. In all, the overhead ranges from 60% to 82% of FastTrack s. Also notice that the reduction percentage \nfor each bench\u00admark correlates well with the number of operations that has been reduced by SO; that is, \nthe overhead reduction percent\u00adage is close to the operation reduction percentage. Slowdown Factor (\u00d7) \nBenchmark F astT rackP acer SO SOn avrora 5.1 4.5 4.2 eclipse 21.0 16.8 8.2 hsqldb 12.2 7.3 3.8 pseudojbb \n7.7 5.1 4.3 sun.ow 29.2 24.1 13.1 xalan 11.6 7.1 2.6 average 13.8 10.3 5.9  Table 5. Comparing the slowdown \nfactor of the implemen\u00adtation of FastTrack in Pacer (F astT rackP acer), SO, and SOn over the execution \ntime of RVM with no race detec\u00adtion. For example, xalan running on F astT rackP acer is 11.6 times slower \nthan running on RVM with no race de\u00adtection.  4.2 Performance of SOn In this con.guration, we further \nreduce the number of moni\u00adtored operations by not having the optimizing compiler per\u00adform any instrumentation \nto support stationary-object analy-Figure 4. Overhead of SO and SOn normalized against that of Pacer \ns implementation of FastTrack.  sis or race detection. There are two main insights for explor\u00ading this \ncon.guration. 1. Based on our race reports, we noticed that all types of races occur repeatedly; many \nraces occur several thou\u00adsand times in a run. As such, it is possible that monitoring only a small window \nof operations would be suf.cient to uncover most if not all types of races. 2. Work by Marino et al. \nsuggests that data races are likely to occur when a thread is executing a cold (infrequently accessed) \nregion in the program [30]. Their experimen\u00adtal result indicated that if they use this observation to \nguide a sampling-based race detector, it can detect over 70% of data races.  Our approach of only enabling \ninstrumentation in the baseline compiler exploits these two insights by (i) creating a monitoring window \nbased on the time a method executes as unoptimized object code, and (ii) focusing on monitoring for data \nraces in cold regions. Figure 5 compares the race detection effectiveness of SOn to those of SO and an \nim\u00adplementation of FastTrack. Notice that when our approaches miss detecting races, we report the numbers \nof detected races over the number of all detected races by Pacer s implementa\u00adtion of FastTrack. For \nexample, SOn detects 18 races while FastTrack detects 27 races or 18 in eclipse. 27  Figure 5. Comparing \nthe number of missed races in SOn with that of SO normalizing with the number of races de\u00adtected by FastTrack. \nAs shown in the .gure, SOn still detects over 90% of races in four out of six applications. In the worst \nperform\u00ading application, eclipse, SOn still detects 67% of all races detected by Pacer s implementation \nof FastTrack. It also de\u00adtects over 84% of races in xalan. Based on this result, this ap\u00adproach still \nprovides good race detection coverage especially in a low-overhead race detection system that is expected \nto miss some races (e.g., sampling-based race detection). Figure 4 also reports the average overhead \nof SOn nor\u00admalized against that of the implementation of FastTrack in Pacer (see black bars). The average \noverhead is 46% of that of Pacer s implementation of FastTrack. The major reason for the smaller overhead \nis due to the number of monitored operations that have not been injected by the optimizing compiler. \nWith SO, the average reduction in the number of operations is 30%. SOn can further increase this reduction \npercentage to 55%. That is, SOn monitors less than half of the operations monitored by FastTrack while \nstill detecting 90% of the races.  4.3 Performance of SOs One interesting feature of Pacer is its ability \nto guarantee proportionality when sampling is used. As shown by Pacer, sampling can signi.cantly reduce \nthe runtime overhead to a point where race detection is possible in deployed sys\u00adtems [11]. Because we \nimplement our dynamic stationary\u00adobject analysis in Pacer, we can also utilize this feature as a way \nto reduce overhead of SOn by controlling the sampling rate. In this section, we report the result of \nour experiment to evaluate the suitability of using SOn in deployed environ\u00adments. Our methodology applies \nPacer s sampling mecha\u00adnism to SOn we call the resulting technique SOs. We then observe the number of \ndetected races for a particular over\u00adhead budget (i.e., 50%, 70%, 85%, and 100%). We then com\u00adpare the \nnumber of detected races for each benchmark for SOs and Pacer and report the results in Figure 6. It \nis worth keeping in mind that the overhead of the sam\u00adpling mechanism in Pacer is around 30%; it is impossible \nto reduce monitoring overhead below that threshold. Because SOs also incurs additional overhead for mechanisms \nto sup\u00adport stationary-object analysis, the overhead of SOs without turning on race-detection is already \nat 35%. As such, we set our lowest budgeted overhead at 50%. As shown in the .gure, SOs can detect more \nraces than Pacer in .ve out of six benchmarks when the overhead is set below 100%. For pseudojbb, all \nraces originated from one commonly used class. As such, both Pacer and SOs can detect over 75% of the \nraces with low sampling rates. Also notice that SOs can detect nearly the same number of races as that \nof Pacer in pseudojbb (with a difference of one fewer race or less). Another interesting benchmark is \nsun.ow. Pacer cannot consistently detect races until the overhead budget is set to 500% (not shown in \nthe graph). At this overhead, it can detect 1.7 races on average while SOs can detect 10.7 races on average. \nOne key characteristic that makes SOs more successful is the reduced set of objects, and read and write \noperations, that must be sampled. Sun.ow is by far the most expensive application for Pacer to execute. \nIt incurs 29 times slowdown when compared to RVM without race detection (see Table 5). As such, it can \nonly sample at a very low rate to maintain 100% or less overhead. On the other hand, when the operations \nthat cannot participate in races have been culled by our approach, a low sampling rate has a much better \nchance of catching race-inducing operations. As an example, Pacer can only sample about 3% of the operations \nin sun.ow to maintain 85% overhead. On the other hand, a sampling rate in SO that can maintain the same \noverhead is as effective as a sampling rate of 9% in Pacer. That is, in order for Pacer to detect the \nsame number of races as that of SO, it needs to sample at 9%. Another interesting point is that SOs is \neffective at the lowest overhead budget. As shown in Figure 7, SOs can detect on average a factor of \nsix more races than Pacer when the overhead budget is 50%. As the overhead budget increases, this factor \nbecomes smaller. At 100% overhead, SOs detects more races than Pacer by a factor of 2. If we increase \nthe budgeted overhead to 500% or more, the numbers of detected races between the two approaches begin \nto converge. 5. Discussion and Future Work Data races occurs when two concurrent accesses to a shared \nresources are not correctly synchronized, and one of the accesses is a write. Based on this de.nition, \nthere are at least three possible optimizations that can be applied to reduce the race detection operations. \nFirst, an analysis that can dynamically detect write operations can help direct the detection efforts \nto objects that have been written to and eliminate most of the monitoring efforts on objects that are \n (a) avrora (b) eclipse (c) hsqldb (d) pseudojbb (e) sun.ow (f) xalan   Figure 6. Comparing the effectiveness \nof SOs and Pacer in detecting races within low overhead budgets. only read from. This optimization strategy \nis the main focus of this work. Second, we can also focus on dynamically detecting objects that are accessible \nby multiple threads. Obviously, races cannot happen on thread-local objects. To support this, an integration \nof a dynamic thread-escaping analysis tech\u00adniques [14, 27] with VC-based race detection techniques such \nas FastTrack is needed. In this approach, the optimiza\u00adtion opportunity is in concentrating the detection \neffort on objects that are thread-shared. At the present time, coming up with precise and low overhead \ndynamic thread-escaping analyses is still a research challenge. Furthermore, additional investigation \nof the data sharing behaviors among objects is needed. In the case that the number of thread-shared objects \nis smaller than that of non-stationary objects in an appli\u00adcation, it is possible that greater overhead \nreduction can be achieved. As a reminder, thread escaping objects are only a small subset of lost objects. \n Third, the .rst two techniques can be combined to re\u00adduce the number of objects that must be monitored. \nAt the .rst level, dynamic thread-escaping analysis is performed. In effect, this replaces the dynamic \ntracking of lost objects in our approach. The objects that have been identi.ed as thread escaping are \nmonitored to see if they eventually be\u00adcome non-stationary. Non-stationary objects are then moni\u00adtored \nfor races. We leave these two possible optimizations as future work. In addition, in our recent work \n[37] we focused on the general problem of monitoring properties speci.ed as .nite\u00adstate automata and \nthe optimization of monitor instrumenta\u00adFigure 7. Comparing race detection effectiveness between SOs \nand Pacer.  tion in loops. We developed conditions under which a pre.x of the loop iteration space can \nbe unrolled. The unrolled pre\u00ad.x was instrumented while the remaining iterations of the loop had their \ninstrumentation removed. This loop optimiza\u00adtion was able to reduce the number of operations that re\u00adquired \nmonitoring by several orders of magnitude across a set of DaCapo benchmarks. We believe this technique \ncan be applied to optimizing data race detection, by replacing the monitoring of a number of reads generated \nby a loop with the monitoring of a single read operation. 6. Related Work In this section, we describe \nrepresentative work in three ar\u00adeas that is related to our work. These three areas are appli\u00adcations \nof stationary .eld information, race detection, and optimizing runtime monitoring especially with sampling. \n6.1 Stationary Fields As we discussed, Unkel and Lam [43] presents the notion of stationary .elds to \ndescribe .elds on which all writes happen before reads. Our proposed approach is based on this notion \nwith a broader scope to include objects in addition to .elds. Rogers et al. [38] extend the Java language \nto express a .eld as stationary when some constraints are satis.ed. With this extension, the JVM can \naccess information about stationary .elds for runtime optimization. They use class loading as a case \nstudy. The evaluation result shows it can achieve 1.67% to 3.90% speedup on their experimental subjects. \nWork by Bronson et al. [12] uses stationary .eld infor\u00admation to optimize strongly isolated Software \nTransactional Memory (STM). They use static analysis to identify station\u00adary .elds in a program, and \nthen use the results to help im\u00adprove STM performance by eliminating memory barriers on stationary .elds. \nLoginov et al. [29] treat stationary .elds in the same way as .nal .elds in the veri.cation of dereference \nsafety in Java programs. To the best of our knowledge, there is no existing work on race detection optimization \nwith sta\u00adtionary .eld information.  6.2 Race Detection Numerous techniques have been presented on race \ndetec\u00adtion. FastTrack [20] and Pacer [11] are the most closely re\u00adlated work ours and we have done extensive \ncomparisons in Section 3. As such, we only compare our approach to other related race detection work \nin this section. Race detection, in general, can be broadly categorized into two approaches: static and \ndynamic race detection. Static race detection. Model checking has been applied to detect races for over \na decade [22, 25]. Model checking provides precise results with no false reporting; however it can suffer \nfrom state explosion, and therefore, does not scale well. Other static race detection techniques [15, \n32, 44] can scale to large systems, but they are not precise; that is they can provide false positives. \nFurthermore, they often have dif\u00ad.culties dealing with re.ection and native methods [43]. As such, our \napproach is instead based on dynamic analysis be\u00adcause we need to have precision in stationary object \nidenti\u00ad.cation. Furthermore, our approach is built on top of a dy\u00adnamic race detector. Dynamic race detection. \nThere are at least two common dynamic race detection approaches: one is based on vec\u00adtor clocks and the \nother is based on locksets. These two ap\u00adproaches have been used individually as well as together to \ndetect races. Typical lockset algorithms enforce the locking discipline that every shared variable is \nprotected by some locks and a lock is held by a thread whenever it accesses the variable. Eraser [39] \nis one of the earliest race detection sys\u00adtems based on locksets. It is common for lockset algorithms \nto generate false positives, but they have much lower execu\u00adtion overhead than vector clock-based approaches. \nA vector clock-based race detector constructs the happens\u00adbefore relation on program statements. It pays \nparticular attention to all accesses to shared resources and synchro\u00adnization primitives such as locks. \nGenerically, the algorithm maintains logical time vectors for all shared data and records when they were \nlast accessed. An example of VC-based al\u00adgorithm is DJIT+ which is used to detect races in concur\u00adrent \nC++ programs [35, 36]. One of the main overheads for VC-based detectors is comparing vector clock entries. \nThis is an O(n) time operation where n represents the number of threads. As programs become more thread \nintensive, the overhead increases. FastTrack [20], LiteRace [30] and Pacer [11] are all based on vector \nclocks. As mentioned in Sections 2 and 3, the main contribution of FastTrack is the reduction in the \nVC storage space and operation time from O(n) to O(1). As such, FastTrack can maintain precision while \nreducing the overhead to be about the same as that of a lockset-based approach. LiteRace can also reduce \noverhead without compromis\u00ading too much detection coverage by exploiting an insight that races are more \nlikely to exist among infrequently executed code. Their technique gradually reduces the sampling rates \nas the code become hotter and maintains high sampling rates for cold code. We adapt a variation of this \ntechnique by exploiting the compiler infrastructure in Jikes RVM to perform instrumentation in cold code \nand less instrumen\u00adtation in hot code. Another distinction of our work is that LiteRace performs of.ine \nanalysis while our approach per\u00adform analysis on-line. There are also techniques that combine VC and \nlocksets to achieve higher precision at lower cost. As an example, MultiRace combines both approaches \nto detect races in C++ programs [36]. RaceTrack uses the lockset-based approach for checking locking \ndiscipline but then also applies the VC\u00adbased approach to determine access orders. This approach can \nsigni.cantly reduce the occurrence of false race reports while maintaining 2x to 3x execution overhead \n[46].  6.3 Optimizing runtime monitoring There is a long history of work on optimizing runtime mon\u00aditoring. \nThe vast majority of this work has focused on mon\u00aditors aimed at checking properties of individual program \nstates, e.g., assertions, array bounds checks [9, 31]. A more recent trend has looked at reducing the \ncost of monitoring properties related to sequences of program states (or ac\u00adtions), e.g., data races, \ntypestate [41]. Since data races can be speci.ed as a simple form of sequencing property, we discuss \nrecent approaches to reducing the overhead of se\u00adquencing properties. Generally speaking, there are two \nmain approaches that have been explored to reduce monitoring overhead: using static analysis to determine \ninstrumentation that can be safely removed, and using sampling to select a subset of instrumentation \nto insert in the program. Static Analysis. Over the last several years, there have been two groups exploring \nthe use of static analysis for reducing the cost of monitoring typestate properties one can think of \nthese as any property that can be described as a .nite state automaton. In a pair of papers, Eric Bodden \nand colleagues developed a staged analysis approach [5, 7]. Early stages involve .ow-insensitive analyses \nthat exploit information about the program statements and data that are referenced in the property, whereas \nlater .ow-sensitive analyses relate the structure of property automaton to paths in the program control \n.ow graph to drop instrumentation. These techniques have been shown to be quite effective across a range \nof properties checked on the DaCapo benchmarks [4], but there is a set of expensive properties for which \nvery little overhead reduction is achieved by these techniques. In addition to the loop transformation \napproach described in Section 5, we have explored an additional .ow-sensitive analyses to reduce monitoring \noverhead. In [17], we calcu\u00adlate maximal control .ow regions within which each path has the same cumulative \neffect in driving transitions through the property automaton. Instrumentation in those regions is then \neliminated and a single summarizing property transition is inserted to capture the common cumulative \neffect. Adapt\u00ading this approach to the multi-threaded setting in which data race is applicable remains \nan open challenge. Sampling. There has been a large body of work on using sampling techniques to, for \nexample, choose a subset of assertions to enable in a program execution. Sampling can signi.cantly reduce \nthe overhead of runtime monitoring, but that bene.t comes with a reduction in fault detection. Sampling \nsequencing properties is much more subtle than sampling assertions. To preserve the precision of runtime \nmonitoring, one must sample sets of instrumentation that, when enabled, ensure that no false error reports \nwill be issued. One straightforward way to do this is to sample the set of objects that are monitored \nas is done in QVM [3]. QVM uses a randomized sampling approach, similar in spirit to Pacer. QVM is a \ncustomized VM that uses a bit in the object header to ef.ciently control instrumentation where the bit \nis set, using a biased coin .ip, when an object is allocated. Several researchers have exploited the \nstructure of the property to identify subsets of instrumentation that preserve some fault detection, \nbut offer potential overhead reduction. This general approach is taken, in very different ways, in [6] \nand [18]. Most work on optimizing the monitoring of sequencing properties performs the optimization either \nof.ine or at ob\u00adject creation time. Pacer is slightly different in that it mon\u00aditors some operations \nthroughout an object s lifetime and only samples a subset of remaining operations; it controls sampling \nat garbage collection time. Work by Xian et al. [45] also uses sampling to control the overhead of monitoring \nlock usage in large Java server applications. Their goal is to monitor lock usage and then process the \nusage information to guide thread scheduling to reduce lock contention. In this approach, sampling is \ncontrolled by thread creations; that is, more information is monitored during the initialization and \nthen less as the number of threads stabilizes. Another approach enables and disables instrumentation \nthroughout the program execution based on the structure of the property automaton [16]. The key observation \nof this work is that at certain points during the analysis of an FSA a particular class of operations \nresults in self-loop transitions and, thus, these operations can be ignored. We believe that this approach \nis also applicable to data race detection since multiple consecutive reads from a single thread need \nnot be explicitly monitored. 7. Conclusions Data races are subtle and dif.cult to detect errors that \narise during concurrent program execution. As of now, state-of\u00adthe-art techniques have shown that precise \nrace detection can be achieved, but at a cost of 8 times slowdown in program execution. In this paper, \nwe incorporate an optimization technique based on the stationary objects notion. Stationary objects are \nwritten early in their lifetimes and then become read-only afterward. As such, these objects can never \npar\u00adticipate in data races since they are never written. Based on this insight, we develop a methodology \nthat concentrates the monitoring effort on objects that can participate in races. Our experimental result \nshows that our proposed system only incurs an average overhead of 45% of that of an im\u00adplementation of \nFastTrack. Furthermore, when our approach is applied under tight overhead budgets (less than 100%), it \ncan detect up to a factor of 6 times more races than Pacer, a sampling-based race detector based on the \nFastTrack algo\u00adrithm. Acknowledgments This work is supported in part by the National Science Foun\u00addation \nthrough awards CNS-0720757 and CCF-0912566, the National Aeronautics and Space Administration under grant \nnumber NNX08AV20A, and by the Air Force Of.ce of Scienti.c Research through awards FA9550-09-1-0129 and \nFA9550-09-1-0687. We also thank the authors of Pacer who have made their implementation available to \nthe re\u00adsearch community and Stephen Blackburn for making Pseu\u00addoSPECjbb2005 available for us to use in \nthis work. References [1] M. Abadi, C. Flanagan, and S. N. Freund. Types for Safe Locking: Static Race \nDetection for Java. ACM Transactions on Programing Languages and Systems, 28:207 255, March 2006. [2] \nApache Software Foundation. Datarace on org.apache. catalina.loader.webappclassloader. https://issues.apache. \norg/bugzilla/show bug.cgi?id=37458. [3] M. Arnold, M. Vechev, and E. Yahav. QVM: An Ef.cient Runtime \nfor Detecting Defects in Deployed Systems. In Proceedings of the Conference on Object-Oriented Programming \nSystems Languages and Applications, pages 143 162, 2008. [4] S. M. Blackburn, R. Garner, C. Hoffmann, \nA. M. Khang, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Frampton, S. Z. Guyer, M. Hirzel, \nA. Hosking, M. Jump, H. Lee, J. Eliot, B. Moss, A. Phansalkar, D. Stefanovic,\u00b4 T. VanDrunen, D. von Dincklage, \nand B. Wiedermann. The DaCapo Benchmarks: Java Benchmarking Development and Analysis. In Proceedings \nof the ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA), \npages 169 190, Portland, Oregon, USA, 2006. [5] E. Bodden. Ef.cient Hybrid Typestate Analysis by Determining \nContinuation-Equivalent States. In Int l. Conf. on Soft. Eng., 2010. [6] E. Bodden, L. J. Hendren, P. \nLam, O. Lhot\u00b4 ak, and N. A. Naeem. Collaborative Runtime Veri.cation with Tracematches. In Works. on \nRuntime Verif., pages 22 37, March 2007. [7] E. Bodden, P. Lam, and L. Hendren. Finding Programming Errors \nEarlier by Evaluating Runtime Monitors Ahead-of-Time. In International Symposium on Foundation of Software \nEngineering, pages 36 47, New York, NY, USA, 2008. [8] E. Bodden, P. Lam, and L. J. Hendren. Clara: A \nframework for partially evaluating .nite-state runtime monitors ahead of time. In RV, pages 183 197, \nMalta, November 2010. [9] R. Bod\u00b4ik, R. Gupta, and V. Sarkar. ABCD: Eliminating Array Bounds Checks on \nDemand. In Proceedings of the Conference on Programming Language Design and Implementation, pages 321 \n333, 2000.  [10] M. Bond. Pacer: Proportional Detection of Data Races -ID: 2988434. http://sourceforge.net/tracker/?func=detail&#38; \naid=2988434&#38;group id=128805&#38;atid=723235. [11] M. D. Bond, K. E. Coons, and K. S. McKinley. PACER: \nProportional Detection of Data Races. In Proceedings of the Conference on Programming Language Design \nand Implementation, pages 255 268, Toronto, Ontario, Canada, June 2010. [12] N. G. Bronson, C. Kozyrakis, \nand K. Olukotun. Feedback-Directed Barrier Optimization in a Strongly Isolated STM. In Proceedings of \nthe 36th annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 09, pages 213 \n225, New York, NY, USA, 2009. ACM. [13] Canonical Ltd. Launchpad: data-races-implementation sql crash. \nhttps://bugs.launchpad.net/f-4d-cb/+bug/516622. [14] J.-D. Choi, M. Gupta, M. J. Serrano, V. C. Sreedhar, \nand S. P. Midkiff. Stack Allocation and Synchronization Optimizations for Java Using Escape Analysis. \nACM Transactions Programming Languages and Systems, 25:876 910, November 2003. [15] J.-D. Choi, K. Lee, \nA. Loginov, R. O Callahan, V. Sarkar, and M. Sridharan. Ef.cient and Precise Datarace Detection for Multithreaded \nObject-Oriented Programs. In Proceedings of the Conference on Programming Language Design and Implementation, \npages 258 269, Berlin, Germany, June 2002. [16] M. Dwyer, A. Kinneer, and S. Elbaum. Adaptive Online \nProgram Analysis. In Proceedings of the International Conference on Software Engineering, pages 220 229, \n2007. [17] M. Dwyer and R. Purandare. Residual dynamic typestate analysis. In Proceedings of the International \nConference on Automated Software Engineering, pages 124 133, 2007. [18] M. B. Dwyer, M. Diep, and S. \nElbaum. Reducing the cost of path property monitoring through sampling. In Int l. Conf. on Aut. Soft. \nEng., pages 228 237, 2008. [19] T. Elmas, S. Qadeer, and S. Tasiran. Goldilocks: A Race and Transaction-Aware \nJava Runtime. In Proceedings of the Conference on Programming Language Design and Implementation, pages \n245 255, San Diego, California, USA, June 2007. [20] C. Flanagan and S. N. Freund. FastTrack: Ef.cient \nand Precise Dynamic Race Detection. In Proceedings of the Conference on Programming Language Design \nand Implementation, pages 121 133, Dublin, Ireland, June 2009. [21] C. Flanagan and S. N. Freund. RoadRunner: \nDynamic Analysis Framework for Concurrent Programs. In Proceedings of the 9th ACM SIGPLAN-SIGSOFT workshop \non Program Analysis for Software Tools and Engineering, pages 1 8, Toronto, Ontario, Canada, 2010. ACM. \n[22] T. A. Henzinger, R. Jhala, and R. Majumdar. Race Checking by Context Inference. In Proceedings of \nthe ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 04, pages 1 13. ACM, \n2004. [23] Jikes RVM. Jikes research virtual machine. http://jikesrvm.org, 2011. [24] M. Jump, S. M. \nBlackburn, and K. S. McKinley. Dynamic object sampling for pretenuring. In Proceedings of the 4th International \nSymposium on Memory Management, pages 152 162, Vancouver, BC, Canada, 2004. [25] K. Kim, T. Yavuz-Kahveci, \nand B. A. Sanders. Precise Data Race Detection in a Relaxed Memory Model Using Heuristic-Based Model \nChecking. In Proceedings of the 2009 IEEE/ACM International Conference on Automated Software Engineering, \nASE 09, pages 495 499. IEEE Computer Society, 2009. [26] L. Lamport. Time, Clocks, and the Ordering of \nEvents in a Distributed System. Communications of the ACM, 21:558 565, July 1978. [27] K. Lee and S. \nP. Midkiff. A Two-Phase Escape Analysis for Parallel Java Programs. In Proceedings of the Conference \non Parallel Architectures and Compilation Techniques, pages 53 62, Seattle, Washington, USA, 2006. [28] \nLiang T. Chen. The Challenge of Race Conditions in Parallel Programming. http://developers.sun.com/solaris/articles/ \nraceconditions.html. [29] A. Loginov, E. Yahav, S. Chandra, S. Fink, N. Rinetzky, and M. Nanda. Verifying \nDereference Safety via Expanding-Scope Analysis. In Proceedings of the International Symposium on Software \nTesting and Analysis, ISSTA 08, pages 213 224, New York, NY, USA, 2008. ACM. [30] D. Marino, M. Musuvathi, \nand S. Narayanasamy. LiteRace: Effective Sampling for Lightweight Data-Race Detection. In Proceedings \nof the Conference on Programming Language Design and Implementation, pages 134 143, Dublin, Ireland, \nJune 2009. [31] S. P. Midkiff, J. E. Moreira, and M. Snir. Optimizing Array Reference Checking in Java \nPrograms. IBM Systems Journal, 37(3):409 453, 1998. [32] M. Naik, A. Aiken, and J. Whaley. Effective \nStatic Race Detection for Java. In Proceedings of the Conference on Programming Language Design and Implementation, \npages 308 319, Ottawa, Ontario, Canada, June 2006. [33] R. O Callahan and J.-D. Choi. Hybrid Dynamic \nData Race Detection. In Proceedings of the Symposium on Principles and Practice of Parallel Programming, \npages 167 178, San Diego, California, USA, 2003. [34] Oracle Corp. The java language speci.cation. http://java.sun. \ncom/docs/books/jls/, 2011. [35] E. Pozniansky and A. Schuster. Ef.cient On-the-Fly Data Race Detection \nin Multithreaded C++ Programs. In Proceedings of the ninth ACM SIGPLAN Symposium on Principles and Practice \nof Parallel Programming, pages 179 190, San Diego, California, USA, 2003. [36] E. Pozniansky and A. Schuster. \nMultiRace: Ef.cient on-the-.y Data Race Detection in Multithreaded C++ programs: Research Articles. Concurrency \nand Computation: Practice and Experience -Parallel and Distributed Systems: Testing and Debugging (PADTAD), \n19:327 340, March 2007. [37] R. Purandare, M. Dwyer, and S. Elbaum. Monitor Optimization via Stutter-Equivalent \nLoop Transformation. In Proceedings of the Conference on Object-Oriented Programming Systems Languages \nand Applications, pages 270 285, 2010. [38] I. Rogers, J. Zhao, C. Kirkham, and I. Watson. Constraint \nBased Optimization of Stationary Fields. In Proceedings of the International Symposium on Principles \nand Practice of Programming in Java, PPPJ 08, pages 95 104, New York, NY, USA, 2008. ACM. [39] S. Savage, \nM. Burrows, G. Nelson, P. Sobalvarro, and T. Anderson. Eraser: A Dynamic Data Race Detector for Multithreaded \nPrograms. ACM Transactions on Computer Systems, 15:391 411, November 1997. [40] Standard Performance \nEvaluation Corporation. SPECjbb2005. On-Line Documentation, 2005. http://www.spec.org/jbb2005. [41] R. \nE. Strom and S. Yemini. Typestate: A programming language concept for enhancing software reliability. \nIEEE Trans. Softw. Eng., 12(1):157 171, 1986. [42] C. Unkel. Stationary Fields in Object-Oriented Programs. \nPhD thesis, Stanford University, Stanford, CA, USA, 2009. [43] C. Unkel and M. S. Lam. Automatic Inference \nof Stationary Fields: A Generalization of Java s Final Fields. In Proceedings of the Symposium on Principles \nof Programming Languages, pages 183 195, San Francisco, California, USA, January 2008. [44] J. W. Voung, \nR. Jhala, and S. Lerner. RELAY: Static Race Detection on Millions of Lines of Code. In Proceedings of \nthe the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium \non The foundations of Software Engineering, pages 205 214, Dubrovnik, Croatia, 2007. [45] F. Xian, W. \nSrisa-an, and H. Jiang. Contention-Aware Scheduler: Unlocking Execution Parallelism in Multithreaded \nJava Programs. In Proceedings of the Conference on Object-Oriented Programming Systems Languages and \nApplications, pages 163 180, Nashville, TN, USA, October 2008. [46] Y. Yu, T. Rodeheffer, and W. Chen. \nRaceTrack: Ef.cient Detection of Data Race Conditions via Adaptive Tracking. In Proceedings of the ACM \nSymposium on Operating Systems Principles, pages 221 234, Brighton, United Kingdom, 2005.   \n\t\t\t", "proc_id": "2048066", "abstract": "<p>Data races are subtle and difficult to detect errors that arise during concurrent program execution. Traditional testing techniques fail to find these errors, but recent research has shown that targeted dynamic analysis techniques can be developed to precisely detect races (i.e., no false race reports are generated) that occur during program execution. Unfortunately, precise race detection is still too expensive to be used in practice. State-of-the-art techniques still slow down program execution by a factor of eight or more. In this paper, we incorporate an optimization technique based on the observation that many thread-shared objects are written early in their lifetimes and then become read-only for the remainder of their lifetimes; these are known as stationary objects. The main contribution of our work is the insight that once a stationary object becomes thread-shared, races cannot occur. Therefore, our proposed approach does not monitor access to these objects. As such, our system only incurs an average overhead of 45% of that of an implementation of FastTrack, a low-overhead dynamic race detector. We then compared the effectiveness of our approach to de- tect races in deployed environments with that of Pacer, a sampling based race detector based on FastTrack. We found that our approach can detect over five times more races than Pacer when we budget 50% for runtime overhead.</p>", "authors": [{"name": "Du Li", "author_profile_id": "81470644386", "affiliation": "University of Nebraska-Lincoln, Lincoln, NE, USA", "person_id": "P2839123", "email_address": "dli@cse.unl.edu", "orcid_id": ""}, {"name": "Witawas Srisa-an", "author_profile_id": "81100018125", "affiliation": "University of Nebraska-Lincoln, Lincoln, NE, USA", "person_id": "P2839124", "email_address": "witty@cse.unl.edu", "orcid_id": ""}, {"name": "Matthew B. Dwyer", "author_profile_id": "81100013564", "affiliation": "University of Nebraska-Lincoln, Lincoln, NE, USA", "person_id": "P2839125", "email_address": "dwyer@cse.unl.edu", "orcid_id": ""}], "doi_number": "10.1145/2048066.2048072", "year": "2011", "article_id": "2048072", "conference": "OOPSLA", "title": "SOS: saving time in dynamic race detection with stationary analysis", "url": "http://dl.acm.org/citation.cfm?id=2048072"}