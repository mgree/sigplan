{"article_publication_date": "10-22-2011", "fulltext": "\n Hybrid Partial Evaluation Amin Shali William R. Cook Department of Computer Science Department of Computer \nScience The University ofTexas at Austin The University ofTexas at Austin amshali@cs.utexas.edu wcook@cs.utexas.edu \nAbstract Hybrid partial evaluation (HPE) is a pragmatic approach to partial evaluation that borrows ideas \nfrom both online and of.ine partial evaluation. HPE performs of.ine-style spe\u00adcialization using an online \napproach without static binding time analysis. The goal of HPE is to provide a practical and predictable \nlevel of optimization for programmers, with an implementation strategy that .ts well within existing \ncom\u00adpilers or interpreters. HPE requires the programmer to spec\u00adify where partial evaluation should be \napplied. It provides no termination guarantee and reports errors in situations that vi\u00adolate simple binding \ntime rules, or have incorrect use of side effectsin compile-time code.We formalize HPE fora small imperative \nobject-oriented language and describe Civet,a straightforward implementation of HPE as a relatively sim\u00adple \nextension of a Java compiler. Code optimized by Civet performs as well as the output of a state-of-the-art \nof.ine partial evaluator. Categories and Subject Descriptors F.3.2 [Semantics of Programming Languages]:Partial \nevaluation General Terms Languages, Performance Keywords Partial Evaluation, Object-Oriented Languages, \nHybrid 1. Introduction Object-oriented systems are increasingly based on con.g\u00adurable frameworks and \nre.ection. These features are expen\u00adsive at runtime, and the costs can limit the ambitions of framework \ndevelopers in creating more powerful and gen\u00aderal frameworks. These costs, however, are often unneces\u00adsary \nbecause a particular program typically con.gures and uses the frameworks in a speci.c way. Con.guration \n.les, data-driven programming and more sophisticated forms of Permission to make digital or hard copies \nof all or part of this work for personal or classroomuseisgrantedwithout feeprovidedthat copies arenot \nmadeordistributed forpro.torcommercialadvantage andthatcopiesbearthisnoticeandthefullcitation onthe .rstpage.To \ncopy otherwise,to republish,topostonserversorto redistribute tolists, requirespriorspeci.cpermission \nand/ora fee. OOPSLA 11, October22 27,2011, Portland,Oregon,USA. Copyright c &#38;#169;2011ACM978-1-4503-0940-0/11/10. \n. .$10.00 model-driven development often involve dynamic interpre\u00adtation of large amounts of relatively \nstatic data [22].Avoid\u00ading the penalty of generality requires optimizations that cut across module boundaries \nto simplify the general framework operations with respect to the program-speci.c con.gura\u00adtion data. \nPartial evaluation is well suited to optimizing such pro\u00adgrams. A partial evaluator can specialize a \ngeneric frame\u00adwork in the context of the usage pattern in a particular pro\u00adgram. It can also optimize \nacross interfaces, allowing pro\u00adgrammers to write modular, general-purpose programs, with the assurance \nthat theywill be optimized automatically. In this paper we present hybrid partial evaluation (HPE), a \npragmatic approach to partial evaluation that is designed to be effective in existing object-oriented \nlanguages. Hybrid partial evaluation provides predictable and reliable optimiza\u00adtions, because the programmer \nexplicitly identi.es parts of the program that should be evaluated at compile time versus 1= 2 3 regex.execute(buffer); \n The CT expression tells the compiler to instantiate the Regex object at compile time. The execute method \nis a sim\u00adple, naive regular expression interpreter. When the execute methodisinvoked ona runtimebuffer, \nHPE inlines and spe\u00adcializes the interpreter on the speci.c pattern, resulting in a set of static methods \nto ef.ciently interpret the .nite state machine representing the regular expression. This example is \ndiscussed in more detail in Section 5.3. We describe hybrid partial evaluation in the context of a small \nimperative object-oriented language. Like online par\u00adtial evaluation, HPE does not perform binding time \nanalysis. The system supports polyvariant specialization of methods and classes, and specialization of \nre.ective operations. On the other hand, the kinds of specializations performed are similar to those \nperformed by an of.ine partial evaluator. The goals of HPE are predictability, ease of implementation, \nand suf.cient specialization to optimize common programs.  To achieve predictability, HPE requires programmer \nan\u00adnotations to indicate which objects should be instantiated at compile time, and HPE prohibits migration \nof compile-time objects to runtime. HPE has a simple check to ensure that executing imperative code at \ncompile time is consistent with the original semantics of the program. Hybrid partial eval\u00aduation rejects \nprograms with incorrect binding times, rather than silently generating inef.cient residual code. These \nre\u00adstrictions allow developers to understand and rely on the op\u00adtimizations performed by the partial \nevaluator. To simplify implementation, a Hybrid partial evaluator is derived from an interpreter (or \noperational semantics) and avoids static binding time analysis. In addition, HPE provides no termination \nguarantee. If the partial evaluating compiler takes too long, the programmer must terminate it just as \nany other program with an in.nite loop and rewrite the program to avoid the problem. Wehave implementedhybrid \npartialevaluation within the JastAdd Java compiler [9] and used it to optimize a range of Java programs. \nCompared to JSpec [25], an existing of.ine partialevaluatorforJava,hybrid partialevaluation generates \ncode that is as ef.cient as JSpec s residual code. Initial re\u00adsults show an average 6 times speedup of \nspecialized pro\u00adgrams. 2. A Miniature Object-Oriented Language A Miniature Object-Oriented Language (MOOL) \nis used to explain hybrid partial evaluation. MOOL is a dynamically typed imperative language based on \nJava [17]. It includes classes, static and non-static methods, mutable .elds, local variables, and re.ective \nmethod invocation. It does not in\u00adclude inheritance, interfaces, instanceof, static .elds, or non-local \ncontrol .ow constructs such as return, goto or ex\u00adceptions. All .elds are private and all methods are \npublic. We believe that MOOL is suf.cient to demonstrate the use of partial evaluation in real-world \nobject-oriented languages. A more complete implementation in a real Java compiler is described in Section \n4. 2.1 Syntax Figure 1 gives the syntax for MOOL. A MOOL program is a list of class de.nitions. As in \nScala, a class de.nition has a single constructor, whose arguments are listed after the class name. These \nconstructor arguments also become .elds of the object. The class contains a list of additional .elds, \nmethods, and an initialization expression. The .elds of a class are initialized to an unde.ned value. \nA method de.nition speci.es the formal parameters and an expression which is the body of the method. \nThe static modi.er identi.es the method as a class-level method, inde\u00adpendent of any instance. This usage \nshould not be confused with the traditional concept of static values in partial eval\u00aduation, which are \ncalled compile-time values in this pa\u00adper. The CT(e,e) and RT(e) expressions mark expressions as data \nv = null | vs | vn | vb | [v ] | C:. type Prog = CD data CD = class C(x) {var x; init{e} MD} data MD \n= mod m(x){e} data mod = static | method data op = + | -| * | / | == | != | < | > | % data e = v constant \nvalue | x variable | this self-reference | C class name | var x = e; e variable declaration | x := e \nassignment | e; e sequence | e op e binary operator | if e then e else e conditional | while e do e iteration \n| e.m(e) method invocation | invoke(e,e,e) re.ective method invocation | new C(e) constructor call | \nCT(e,e) execute at compile time | RT(e) execute at runtime | IsCT(e) tests for a compile-time value \nFigure 1. Syntax of MOOL compile time or runtime respectively. IsCT(e) is a boolean expression which \nis used to test whether or not an expression is compile time. Literal values are of types integer vn, \nboolean vb, string vs or list [v ]. Null is also a literal value. The domain of val\u00adues also include \nobject values, C:., as described in the next section. Expressions include imperative operations on values \nand statements that affect control .ow and the state: variable de.nitions, assignments, control constructs \nsuch as if and while loop, method calls, object creation and re.ection. Fig\u00adure2gives anexample program \nwrittenin MOOL syntax.It de.nes a Circle and a Main class which creates two Circle objects.  2.2 Notation \nAll the semantic de.nitions in this paper are written in Haskell [14], so they are executable. Literate \nHaskell [18] is used to render the de.nitions in more conventional style. One non-standard aspect of \nthe semantic de.nitions is the pervasive use of monads and Haskell s do notation to im\u00adplicitly pass \nstate through each de.nition in the interpreter. This implicit state is used for several purposes,but \nthe most  data p = v |.|.| v --concrete and abstract values .:: x . l --environment maps variables to \nlocations s :: l . p --store maps locations to values E[ \u00b7] \u00b7\u00b7 ::e . . . v . State (Prog,s,NameMap) v \nE[ v]].o = return v E[ e1 op e2 ] .o = do v1 .E[ e1 ] .o v2 .E[ e2 ] .o return op(v1 ,v2 ) E[ x] .o = \ndo ( ,s, ) . get return s(.(x)) E[ this] .o = return o E[ var x = e1 ; e2 ] .o = do v .E[ e1 ] .o [x \n.. l] . allocate [x .. v] E[ e2 ] ([x .. l]+ .)o E[ x := e] .o = do v .E[ e] .o update .(x) v return \nv E[ e1 ; e2 ] .o = do E[ e1 ] .o E[ e2 ] .o E[ if e1 then e2 else e3 ] .o = do b .E[ e1 ] .o case b \nof True .E[ e2 ]].o False .E[ e3 ] .o E[ while e1 do e2 ] .o = do E[ if e1 then (e2 ; while e1 do e2 \n) else null]].o E[ e.m(a)]].o = do C:. ' .E[ e] .o v . mapM(E[ \u00b7] .o) a (x){eb} . .ndMethod C m (length \na) [x .. l] . allocate [x .. v] E[ eb] ([x .. l]+ . ' )(C:. ' ) E[ invoke(e,em,a)] .o = do m .E[ em]].o \nE[ e.m(a)]].o E[ new C(a)] .o = do class C(x){f init{ec}} . .ndClass C v . mapM(E[ \u00b7] .o) a [x .. l] \n. allocate [x .. v] . ' . allocate [f .. .] E[ ec] ([x .. l]+ . ' )(C:. ' ) return C:. ' update l v = \ndo (P,s,.) . get put (P,(l,v): s,.) allocate = mapM(allocate1 ) allocate1 (x,v)= do (P,s,.) . get let \nl = length s put (P,(l,v): s,.) return (x,l) Figure 3. Full evaluation of MOOL expressions Figure 2. \nAn example program in MOOL syntax 1 2 3 4 5 6 7 8 9 10 11 12 13 = 14 = 15 16 17 }} familiar one is \nto pass a store representing the mapping of mutable locations to values which are created as an object\u00adoriented \nprogram is interpreted. While a complete discussion of monads is beyond the scope of this paper, we provide \na quick explanation of the notation used in this paper which should be suf.cient to understand the semantic \nde.nitions. At a high level, the semantic functions have the following form: command x y = do z . command \nx (y /2) put z if x > y then do a . command (x - 1) y return a else command y z Each line is either a \nbinding x . expression or an expression by itself. In either case, the expressions represent commands \nwhich may read or modify the implicit program state and produce a value, which is optionally bound to \nx.A command is just a function that is de.ned in the context of a hidden state. The .nal line in a do \nblock must either be a command, whose value is used for the value of the block, or a return statement \nwhich returns a speci.c value. The type of a state-based computation is speci.ed as a monadic type State \nS T where S is the type of the hidden state and T is the type of value produced. The hidden state can \nbe, for example, a single value, a .nite map of values, or a tuple of such types. Since most semantic \nfunctions do not directly involve the state, it is useful to hide this state using a monad. When the \nhidden state is needed, it can be read or written using two commands, get and put. For example, the following \nfunction ensures that the hidden state is at least n and returns the previous value of the hidden state. \nensure n = do x . get if x < n then do put n return x else return x The function ensure has type State \nInteger Integer, meaning that it has a hidden integer state variable, and also returns an integer. There \nare many papers and tutorials on monads which explain the details on the semantics and implementation \nof monads [28]. For the purposes of this paper, it is only necessary to understand that the store is \npassed through each line of a do block.  2.3 Semantics The semantics of MOOL is de.ned in Figure 3. \nIn the code, l refers to a location, x refers to a name, v refers to a value, and e and a are expressions. \nThe Haskell source code for HPE can be found at the following URL: http://www.cs.utexas.edu/~wcook/Civet/ \n An environment . maps variable or .eld names to loca\u00adtions. A store s maps locations to potentially \nabstract val\u00adues p. Abstract values v are described in the next section. Theyare included here so that \nthe full evaluator can have the same type signature as the partial evaluator. The . value for a variable \nmeans that the variable has not been assigned yet. An object value C:. is a pair where C is the name \nof the class that the object is instantiated from. The object has an environment .which contains the \nlocations of its .elds. The function E[ \u00b7] \u00b7\u00b7 is referred to as the full evalua\u00adtor to distinguish it \nfrom the partial evaluator de.ned in Section 3. This function E[ e] .o executes the program represented \nby an expression e in the context of an envi\u00adronment . and current object o. The full evaluator returns \na value and potentially modi.es the implicit state [28]. The implicit state has three components: the \nprogram, a store and a NameMap. The full evaluator only manipulates the store. The other components are \nincluded for consistency with the partial evaluator, which extends the program during evalua\u00adtion. The \n.rst two cases specify the behavior of value literals v and binary operators. The full evaluator applies \nthe binary operation op to its operands and returns the result, taking into account the type of values \nthat it receives with respect to the operation. The de.nition of op is omitted. The next three cases \nconcern variables, declarations, and assignment. All variables are bound to locations in the envi\u00adronment, \nand the locations are then looked up in the store. As mentioned in the previous section, get is a command \nwhich retrieves the program, the store and the NameMap in a tuple. All variables are assumed to be present \nin the environment, and their location de.ned in the store, otherwise an error is thrown.  A variable \ndeclaration var x = e1 ; e2 evaluates e1 to get a value, stores the value into a new location, and then \nevaluates e2 in an extended environment. The allocate func\u00adtion takes a list of name-value pairs [x .. \nv] and returns a list of name-location pairs [x .. l]. It updates the store so that each location contains \nthe corresponding value. Assignment x := e evaluates e and then updates the variable s location to the \nnew value. The update function gets the store and then adds a new (l,v) pair to the store to associate \nlocation l with value v. Evaluation of if and while expressions is standard. The evaluation of a method \ncall e.m(a) starts with eval\u00aduating the target expression e and all the arguments a. The evaluator then \n.nds the method m based on the class of the target object. It then evaluates the body of the method in \nan environment . ' which has the bindings for the actual param\u00adeters and the target object s .elds. The \nobject context o is set to the target object C:. ' . The invoke expression supports re.ective method \ninvo\u00adcation, where the method name is computed as a value rather than being explicit in the syntax of \nthe call. The expression e is the target of the re.ective call. em is an expression which evaluates to \nthe name of the method and a is the list of actual parameters. To evaluate a re.ective method invocation, \nthe semantics .rst evaluates the method name expression, then performs a normal method call using the \ncomputed name. The full evaluator evaluates the object creation expression new C(a) by .rst .nding the \nclass C. It then evaluates all the actual arguments of the class constructor and binds them to their \nnames in the environment. Then, it binds all the .elds of the class to the unde.ned value . and evaluates \nthe body of the constructor and returns an object C:. ' . An object s .elds are initialized when the \nfull evaluator evaluates the body of the constructor(init). 3. HybridPartial Evaluatorfor MOOL In this \nsection we de.ne a hybrid partial evaluator for MOOL. With partial evaluation, program execution is split \ninto two stages. The .rst stage, where partial evaluation is performed, is compile time. The output of \nthe compile-time stage is a modi.ed program, called residual code, which is executed in the runtime stage. \nValues that exist during the .rst phase are called compile-time values, while all other values are called \nruntime values. Thekey questionfor partialevaluationishowto identify what parts of a program should be \nevaluated at compile time. Hybrid partial evaluation is based on a few fundamental principles: A programmer \nidenti.es parts of the program to ex\u00adecute at compile time, creating compile-time values. Any subsequent \noperations that involve compile-time objects are executed at compile time, possibly creating more compile-time \nobjects. Every object exists either at compile time or runtime and cannot move between phases. On the \nother hand, primitive values (integers, strings, dates) are automatically moved between phases as needed. \n All variables are assigned values at compile time, but the value may be a concrete (compile-time) value \nor an abstract value representing partial information about the future actualvalueofthevariableat runtime.Avariable \ns status, as either compile-time or runtime, never changes. Compile-time variables are eliminated from \nthe program.  Methods and constructors are specialized on every com\u00adbination of speci.c compile-time \narguments that arise during partial evaluation. When a constructor is spe\u00adcialized, its class is split \ninto compile-time and runtime facets, in effect creating two partial objects that exist in different \nphases.  In the partial evaluator, concrete compile-time values are simply the normal values v, which \ncan be primitive values or objects that exist only at compile time. There are two kinds of abstract values: \nunknown values . and abstract values, v. A completely unknown value is represented by .. An abstract \nvalue v can be either a primitive constant that has been marked to exist at runtime, or a partial object \nC:..A partial object can specify just the class of a runtime object, or it can specify the class and \nsome of its .elds. The key point is that compile-time values force spe\u00adcialization when used as arguments \nto methods or con\u00adstructors, while abstract objects allow local propagation of compile-time information \nbut do not trigger specialization. For instance, in Figure 2, s1 is a compile-time circle object whereas \ns2 is an abstract runtime circle object, because only the value of its radius is marked to be known at \ncompile time. The type of hybrid partial evaluator, P[ \u00b7] \u00b7\u00b7, is given in Figure 4. A hybrid partial \nevaluator, like an online one, works very much like a full evaluator. However, during par\u00adtial evaluation, \nthe store may contain abstract (or approxi\u00admate) values ones represented by v. Operations on these abstract \nvalues are residualized to create code that executes at runtime, when the actual values are known. The \nresult of hybrid partial evaluation is an expression accompanied with a value, p, which may be a compile\u00adtime \nvalue or an abstraction of a runtime value (or .). The expression represents the residual code. The value \nis the information about the partially evaluated expression. This information can be as concrete as a \nconstant or as abstract as a . value. Online partial evaluators have traditionally been de.ned to return \nan residual expression or a compile\u00adtime value. Allowing both an expression and a value allows residual \ncode to be generated while also returning partial  information about the value computed by the residual \ncode. Partial evaluation of basic expressions is given in Figure 4. Partial evaluation of primitive value \nconstants always produces abstract values. This may seem strange, because constants are fully known at \ncompile time. However, if all constants were considered compile-time values, they would cause specialization \nwhenever theywere used, which would violate the principle that the programmer should indicate where specialization \nis to occur. Binary operators, e1 op e2 , return a compile-time value if either e1 or e2 partially evaluate \nto a compile-time value, otherwise return an abstract value. This rule follows the prin\u00ad ciple that operations \ninvolving compile-time values produce compile-time values. 3.1 Variable Declaration and Assignment \nFigure 4 also de.nes the hybrid partial evaluation of vari\u00adables, variable declarations and variable \nassignments. A variable is compile-time if it is assigned a compile-time value and it is runtime if it \nis a . or an approximate value, v. HPE binds all the variables in the environment whether or not theyare \ncompile-time. For variables, partial evaluator returns their value as the residual expression if they \nare compile-time. This is be\u00ad cause compile-time variables are eliminated from the resid\u00ad ual code. Otherwise, \nit returns a residual code which con\u00ad tains the name of the variable along with the abstract value stored \nfor that variable. A variable declaration var x = e; \u00b7 may introduce a compile-time or runtime variable. \nIf the partial evaluated value of e is a compile-time value, then the variable is de\u00ad .ned only at compile \ntime, and has no existence at runtime. Otherwise, the variable is a normal runtime variable de.ned in \nthe generated residual code. Partial evaluation of a variable assignment, x := e, de\u00ad pends on whether \nthe x is a compile-time or runtime vari\u00ad able. For a compile-time variable x, the expression e must evaluate \nto a value and the value of x is updated in the store. For runtime variables, residual code is returned \nfor the as\u00ad signment. A value . in the store for a variable means that the variable is a .eld and has \nnot been assigned yet. Thus, it can accept any value and partial evaluator updates its value in the store \naccordingly. When a variable has the value ., it means that we have no compile-time information about \nthe variable. Such variables cannot be updated with any other values except ..  3.2 Special Expressions \nThe special expression CT(e,e ' ) indicates which values ' should be created at compile time. If e is \nTrue, then e is evaluated at partial evaluation time using the full evalu\u00adator, to create a compile-time \nvalue. The result may be a primitive data type, or an object. The special expression, IsCT(e), evaluates \nto True when e is a compile-time value. RT(e) expression marks an expression as runtime. The par-P[ e1 \n; e2 ] .o = do ' (e1 ,p1 ).P[ e1 ] .o ' (e2 ,p2 ).P[ e2 ] .o '' return ([ e1 ; e2 ] ,p2 ) P[ if e1 then \ne2 else e3 ]].o = do ' (e1 ,p1 ).P[ e1 ] .o case p1 of True .P[ e2 ] .o False .P[ e3 ]].o ' else . checkStore \n.o (if e1 then \u00b7 else \u00b7) e2 e3 P[ while e1 do e2 ] .o = do ' (e1 ,p1 ).P[ e1 ] .o case p1 of True .P[ \ne2 ; while e1 do e2 ] .o False .P[ null]].o else . do sanitize . checkStore .o (while \u00b7 do \u00b7) e1 e2 checkStore \n.o f e2 e3 = do (P,store,.) . get -\u00ad capture the initial store (e ' 2 ,p2 ) . P[ e2 ] .o -\u00ad evaluate \nthe then branch ( ,s1 , ) . get -\u00ad snapshot the resulting store put (P,store,.) -\u00ad reset store to initial \nconditions (e ' 3 ,p3 ) . P[ e3 ] .o -\u00ad run the else branch ( ,s2 , ) . get -\u00ad snapshot the else store \ncmp . s1 = . s2 -\u00ad check that changes are consistent if cmp then -\u00ad success sanitize . -\u00ad erase abstract \nvalues '' return ([ f ee ] ,.) 23 else --report inconsistency inconsistentChangeError .s1 s2 Figure \n5. Partial evaluation of control .ow constructs tial evaluator does not do any evaluation on the expression, \ne, and simply returns the same expression as the residual code along with a . value.  3.3 Control Flow \nFigure 5 de.nes hybrid partial evaluation of control .ow statements. Sequences are straightforward. For \nan if-expression, if the condition is a compile\u00adtime value, then the partial evaluator selects the appropri\u00adate \nbranch for further evaluation, just like the full evaluator. When the condition is a runtime value, it \nis desirable to par\u00adtially evaluate both branches of the conditional. The problem is that branches may \nmake incompatible changes to the store,  data PV = (e,p)P[ x] .o = do ( ,s, ) . get P[ \u00b7] \u00b7\u00b7 ::e . . \n. v . State (Prog,s,NameMap) PV P[ v] .o = return ([ v] , v) P[ e1 op e2 ] .o = do ' (e1 ,p1 ) . P[ e1 \n] .o ' (e2 ,p2 ) . P[ e2 ] .o case (p1 ,p2 ) of (v1 ,v2 ) . let v = op(v1 ,v2 ) in return ([ v] ,v) (v1 \n, v2 ) . let v = op(v1 ,v2 ) in return ([ v] ,v) ( v1 ,v2 ) . let v = op(v1 ,v2 ) in return ([ v] ,v) \n ( v1 , v2 ) . let v = op(v1 ,v2 ) in return ([ v] , v) '' else . return ([ e op e ] ,.) 12 P[ this] \n.o = return ([ this] ,o) P[ CT(e,e ' )] .o = do '' ' v .E[[e ] .o --Error if e is not compile-time ' \nif v = True then do v .E[ e] .o --Error if e is not compile-time return ([ v] ,v) else P[ e] .o P[ IsCT(e)] \n.o = do ' (e ,p).P[ e] .o case p of v . return ([ True] ,True) else . return ([ False] ,False) P[ RT(e)]].o \n= do ' (e ,p).P[ e] .o return ([ e ' ] ,.)  case s(.(x)) of v . return ([ v] ,v) p . return ([ x] ,p) \n P[ var x = e1 ; e2 ] .o = do ' (e1 ,p1 ).P[[e1 ] .o [x .. l] . allocate [x .. p1 ] ' (e2 ,p2 ).P[[e2 \n] ([x .. l]+ .)o case p1 of ' v . return (e2 ,p2 ) '' else . return ([ var x = e1 ; e2 ] ,p2 ) P[ \nx := e] .o = do ( ,s, ) . get case s(.(x)) of v . do --compile-time variables not residualized ' v .E[ \ne] .o --Error if e is not compile-time ' update .(x) v return ([ v ' ] ,v ' )  v . do --abstract variable \nmust stay abstract ' (e ,p).P[ e] .o update .(x) p return ([ x := e ' ] ,p)  .. do --unknown runtime \nvalue ' (e ,p).P[ e] .o return ([ x := e ' ] ,.) .. do --variable is not yet de.ned ' (e ,p).P[ e] \n.o update .(x) p case p of --.rst assignment determines status of variable v . return ([ v] ,v) . return \n([ x := e ' ] ,.) Figure 4. Partial evaluation of basic values, variables, operators, variable declarations, \nand assignments 1 2 = 3 = 4 5 6 7 8 9 10 } Figure 6. The problematic example of anif-expression for \nthe partial evaluation so that it is not clear which modi.ed store should be used for the evaluation \nof the remainder of the program. This problemis illustratedin Figure6[20].In thisexam\u00adple, a is a runtime \nvariable. Thus, the partial evaluation of the if-condition, a<x, results in the expression a< 3, which \nis not a value. During runtime, only one branch must take place, in which case, the value of x after \nthe evaluation of if-expressionwouldbe9and thevalueof ycan be either 4or6 based on the branch taken. \nA polyvariant computation scheme [10] deals with this problem by partially evaluating both branches and \ninserting necessary assignments called explicators at the end of new residual branches. Meyer [20] proposed \na solution that joins the environments resulted from the two branches. In a se\u00admantics based on continuations, \nthe rest of the program is specialized separately for each branch [15, 23, 27]. However, this has the \npotential to duplicate large amounts of code. HPE has a pragmatic approach to this problem. The checkStore \nfunction (See Figure 5) evaluates both branches and then looks for inconsistencies in the state. It also \nsani\u00adtizes the store by converting all partially abstract values to .. If the resulting stores(s1 , s2 \n)are different with respect to the initial environment (.), HPE raises an error. Other\u00adwise, it continues \nwith the generation of the code for the if and partial evaluation of the rest of the program. The same \napproach is used for while expressions, except that the store is also sanitized at the top of the loop. \nWe have found that this pragmatic approach is suf.cient for manycommon pro\u00adgramming idioms, as shown \nin Section 4. For the example in Figure 6, the hybrid partial evaluator starts with the environment {x \n=3,y =4}. The .rst branch changes the environment to {x =9,y =6}. The partial evaluation of the second \nbranch results in {x =9,y =4}. The two branches make inconsistent changes to the environ\u00adment and therefore \nHPE raises an error.  3.4 Class Specialization andPartial Objects For an object creation expression, \nnew C(a), HPE special\u00adizes the class C if any of the parameters to the constructor call are compile-time. \nClass specialization is de.ned in Fig\u00adure7.For class specialization,the partialevaluator bindsthe actual \nparameters of the constructor in the environment. It then .nds if this class with such actual parameters \nhas been already specialized. The .ndMemoClass returns the name of the specialized class, if there is \none already, along with its class de.nition. Otherwise, it generates a new name and returns it with the \noriginal class de.nition. When the class has not been specialized, HPE specializes the body of the constructor \nin an environment containing the binding for the parameters, this and .elds. Fields are initial\u00adized \nto .. All the methods of the class are likewise special\u00adized. The new class and methods are added to \nthe program. The resulting residual code is an expression that instantiates the new class with anyremaining \nruntime parameters. Along with the residual code, HPE returns an abstract object which has the name of \nthe new class and the partial environment of the object. When the class C with those actual parameters \nhas been already specialized, thehybrid partialevaluatorevaluates the body of the constructor after allocating \nthe .elds and the this object in the store and returns an approximate object with the required residual \ncode.  3.5 Method Specialization HPE can specialize method calls o.m(a) on compile-time objects, which \nwere introduced in Section 3.1. Since a compile-time object is never residualized, its identity and .eld \nvalues exist only during partial evaluation. In this case, hybrid specialization may result infull evaluation \nof the call, or create a residual class method. The cases for method calls on compile-time objects are \nde.ned in Figure 8. If all the arguments to the method call are compile-time values, then the call is \nprocessed as a nor\u00admal method call. If zero or more of the method arguments are compile-time values, \nthen it must be specialized to create a new method in the residual program. Since the target ob\u00adject \ndoes not exist in the residual program, the new method must be static. The function S[[e] modi.er .o \nCm a (See Figure 9) creates a specialized version of a method. In this case the new method is marked \nas static. New methods are stored in a cache, so that the same specialization of a method is not generated \ntwice. The method specializer S[ e] modi.er .o Cm a binds all the parameters in the en\u00advironment and \npartially evaluates the method body. It then adds the method to the corresponding class and returns the \nresidual method call expression with runtime arguments. Program point specialization is a technique that \nis used to prevent the specializer from running into the in.nite loop of specializing a recursive function \n[1, 5, 13]. The hybrid partial evaluator uses the polyvariant specialization [4, 8, 24] strategy for \nprogram point specialization. It memoizes a call expression, e.m(a), so that it can be reused from other \ncall sites. It also memoizes object creation expres\u00adsions (constructor calls). Memoization is implemented \nin the .ndMemoCall and .ndMemoClass. The partial evaluator saves the name of either method or class along \nwith the ac\u00ad  P[ new C(a)] .o = do ' (a ,p '). mapM(P[ \u00b7]].o) a if any isCompileTime p ' then do memc \n. .ndMemoClass C p ' '  let (z,C ,class (x){f init{ec} m})= memc [x .. l] . allocate [x .. p '] ' let \nxd = getRuntimeNames x (a ,p ') ' let ad = getRuntimeExprs (a ,p ') . ' . allocate [f .. .] ' ' (e, \n).P[ ec] ([x .. l]+ . ' )( C :. ' ) c when (\u00ac z)(do ' m ' . mapM(M[ \u00b7] . ' ( C :. ' )) m ' f. getRuntimeFields \nf. ' ' '' addClass class C (xd){finit{e } m ' }) c ' ' return ([ new C (ad)] , C :. ' ) else do class \n( ){f init{ } } . .ndClass C . ' . allocate [f .. .] return ([ new C(a ' )] , C:. ' ) .ndMemoClass C \n[xs .. vs]= do (p,s,n) . get --n is NameMap case n(( C [xs .. vs])) of l,[C] . do cdef . .ndClass (C \n+ \"$\" + l) return True,C + \"$\" + l,cdef Nothing . do let l =(length n)+1 put (p,s,( C [xs .. vs],(l,[C])) \n: n) cdef . .ndClass C return False,C + \"$\" + l,cdef M[ modi.er m(x){e}] .o = do . ' . allocate [(x,.) \n| x . x] ' (e , ).P[ e] (.+ . ' )o ' return modi.er m(x){e } Figure 7. Partial evaluation of constructors \nfor partial ob\u00adjects tual parameters passed to that and the content of the store at the time of specialization. \nThese information are stored in the NameMap part of the state monad. Now consider the method call o.m(a) \nin which o is a partial object. The hybrid partial evaluator knows the class of a partial object. When \nsome of the actual parameters in the method call expression are compile-time values or objects, HPE specializes \nusing the function S and creates P[ e.m(a)]].o = do ' (e ,p).P[ e] .o ' (a ,p '). mapM(P[ \u00b7] .o) a case \np of C:. ' . do if all isCompileTime p ' then do (x){eb} . .ndMethod C m (length a) [x .. l] . allocate \n[x .. p ' ] v .E[ eb] ([x .. l]+ . ' )p return ([ v] ,v) else S[ C] static . ' . Cm (a '') ,p C:. ' . \n--target is an approximate object if any isCompileTime p ' then do ' ] method. ' pC m (a '' ) S[ e ,p \nelse ' return ([ e .m(a ' )] ,.) else . --target is unknown if any isCompileTime p ' then do ' ' m . \nspecializeAll .o m (a ,p ') ' let ad = getRuntimeExprs (a ,p ' ) '' return ([ e .m (ad)] ,.) else ' return \n([ e .m(a ' )] ,.) P[ invoke(e,em,a)] .o = do ' (e,p).P[ em] .o m ' case e of m m .P[[e.m(a)] .o else \n. do ' (e ,p ' ).P[[e] .o ' (a ,p '). mapM(P[ \u00b7] .o) a '' return ([ invoke(e ,e ,a ' )] ,.) m Figure \n8. Partial evaluation of method calls and re.ective method calls for partial objects a residual instance \nmethod. This is shown in Figure 8. When all of the parameters are runtime values, the partial evaluator \ngenerates a residual code for the method call. If the target of the call is not known and the partial \nevaluator has no information about it and some of the actual parameters are compile-time values, HPE \nspecializes the method call. Since the class of the target is not known, all the methods in all the classes \nwith the same name and the same number of the parameters are specialized. The specializeAll function \n.nds all the methods with the same name and the same number of parameters in all the classes. It then \npartially evaluates each method with a copyof the store. Thereafter, it checks all the stores resulting \nfrom the partial evaluation of  S[ e] modi.er .o Cm (a ' ,p ') = do ' (z,m , (x){eb}) . .ndMemoCall \nC m p ' ' let ad = getRuntimeExprs (a ,p ') when (\u00ac z)(do [x .. l] . allocate [x .. p '] ' (eb,p).P[ \neb] ([x .. l]+ .)o ' let xd = getRuntimeNames x (a ,p ') ' addMethod C modi.er m (xd) ' return ([ e.m \n(ad)] ,.) .ndMemoCall C m a = do mdef . .ndMethod C m (length a) (p,s,n) . get --n is the NameMap case \nn(( m (length a) a)) of l,cs . do if (elem C cs) then ' {eb}) return True,m + \"$\" + l,mdef else do put \n(p,s,( m (length a) a,(l,C : cs)) : n) return False,m + \"$\" + l,mdef Nothing . do let l =(length n)+1 \nput (p,s,( m (length a) a, (l,[C])) : n) return False,m + \"$\" + l,mdef Figure 9. Helper function for \npartial evaluation of method calls each method to make sure that partial evaluation of methods has not \ncaused anyinconsistencyin the state. When the target is unknown and none of the parameters are compile-time, \nHPE only generates a residual code. 3.5.1 Re.ective Calls Figure8also de.nesthe partialevaluationof \nre.ective calls. When the partial evaluation of em results in a string value, m, the name of the method \nto be called is known at compile time. Therefore partial evaluator can specialize the method using the \nspecialization process of a normal method call. Otherwise, when the name of the re.ective method call \nis kno it partially aluates the xpression and = \"\" obj.test(arglist);  1 2 3 4 5 6= 7= 8= 9 10 = \n11 12 13 14 15 16 17 }} 1 2 3 4 5 6 = 7 = 8 9 10 11 12 13 14 15 }} Figure 11. Exponentiation Function \nResidual Code   3.6 Examples In this section we give examples of MOOL programs and their generated \nresidual code. The .rst example is an integer exponentiation. This function works by squaring based on \nn n/2 n/2 the fact that when n is even x= x\u00d7 xand when nn-1 n is odd x= x \u00d7 x. Figure 10 de.nes the MOOL \nprogram which implements this function. Figure 11 gives the residual code for the power function when \nthe exponent has a compile-time value of 11. The power$1 is the residual function which takes only one \nparameter, the base of expo\u00adnentiation, and returns the 11th power of that. The next example is a regular \nexpression matcher pro\u00adgram. This program is based on the idea of using derivatives of a regular expression \npattern [3]. This way of constructing a regular expression matcher does not require using explicit automatas \n(NFA, DFA) or backtracking. Figure 12 de.nes the code for matching algorithm. In this code the regular \nex\u00adpression is a compile-time value. The input however is dy\u00adnamic. The partial evaluator specializes \nthe matching algo\u00adrithm and generates a new code which has no trace of the classes and function calls \non the input regular expression.  1 2 3 4 5 6 == 7= 8 9 10 11 12 13 14 15 16 = 17 = 18 = 19 20 }} \n Figure 12. Regular expression matcher  3.7 Discussion Hybrid partial evaluation does not guarantee \nthat all pro\u00adgrams which execute correctly by themselves can be par\u00adtiallyevaluatedto produce residual \ncode.In otherwords,hy\u00adbrid partialevaluation canfailevenif the program being ana\u00adlyzed is an otherwise \nvalid program. Unfortunately, the error cases are not completely explicit in the semantic evaluation \nfunctions. One important error, which can occur anywhere, is an attempt to create residual code that \ncontains an instan\u00adtiated compile-time object.F xample, the following code 1= 2 3= 4 5 System.out.println(r); \n The hybrid partial evaluator raises an error in this case, because the residual code [[(HashTable:.).get(readLine \n())] is invalid, as code cannot contain an instantiated compile-time object. The partial evaluator would \ntry to spe\u00adcialize the get method,but it cannot specialize system meth\u00ad 1 2 3 4 5 6= 7= 8 9 10 11 \n== 12 = 13 14 15 16 17 18 19 20 21 == 22 = 23 24 25 26 27 28 }} Figure 13. Regular expression matcher \nresidual code ods. HPE issues a compiler-error when processing the above code. It is possible to rewrite \nthis example to avoid the problem, by taking adv of compile-time information and 1= 2 3 4\" 5= 6 \n 7 8 System.out.println( o.get(test) ); In this version of the program, both o and test variables compile-time \nalues, which included in the resid\u00ad 1= 2 3 System.out.println( \"1\" );  4 5 6 7 8 System.out.println( \n\"9\" ); Conversely, the partial evaluator may also through errors if an expression is marked as CT but \ninvolves runtime data. These places are noted in Figure 4. 4. Civet:AHybridPartial EvaluatorforJava Wehave \nimplementedahybrid partialevaluator for theJava language, based on the semantics we explained in the \npre\u00advious section. This hybrid partial evaluator is called Civet1. For implementing Civet, we have extended \na Java compiler written using the JastAdd Compiler Compiler [9]. The mod\u00adular structure of JastAdd helped \nus easily extend the Java compiler. The Civet is about 4600 lines. It can be found at the following URL: \nhttp://www.cs.utexas.edu/~wcook/Civet/ Civet currently uses annotations to specify compile-time variables \nrather than a special expression CT, as in the se\u00admantics given here. In Civet, the speci.cation is given \nusing @CompileTime and @CompileTimeIf Java annotations. The @CompileTimeIf(other_var) annotation indicates \na condi\u00adtional situation where a variable is compile-time only if an\u00adother variable with the name other_var \nis also a compile\u00adtime variable. Civet follows the closest scope rule to .nd the other_var. It generates \npure Java code after partial evalua\u00adtion, which makes it easier for debugging and further analy\u00adsis. \nThere are several issues in the specialization of Java pro\u00adgrams. One issue is in the class specialization. \nWhen Civet specializes a class constructor, it creates a new class which is a subclass of the class being \nspecialized. It then copies the body of the super-class constructor to the subclass and then follows \nthe semantics. The problem arises when some .elds of the class are private. When the .elds are private \nthe new subclass cannot access them from within the constructor or methods. Moreover, because partial \nevaluator creates a new con\u00adstructor in the new generated class, it requires the original class to have \na default constructor. This is because the origi\u00adnal class might not have any constructor of the same \nparam\u00adeters as the new specialized one. Thus, it must have at least a default constructor so as the program \nbe able to create an object of the specialized type during runtime. In addition, a class cannot be .nal \nbecause it cannot be inherited from. These restrictions in Civet only applies to the classes which are \ngoing to be specialized. 1Civet is an animal that eats coffee beans and produces partially digested coffee \nberries which produce highly priced coffee. 5. Evaluation We evaluate the performance and scalability \nof Civet on samples from several sources. 5.1 JSpec Suite TheJSpectestsuiteis createdby Schultzetal.[25].Welist \nsome of the examples from this suite with a short descrip\u00adtion: FFT: Fast Fourier Transform. The compile-time \ninput for this case study is the size of radix which in our experiments are set to 16, 32 and 64.  Romberg: \nThis is an integration method. The compile\u00adtime input in this case study is the number of iteration whichis \nsetto2in ourexperiment.  Power: Power function, xn, where n is a natural number. The exponent is a compile-time \nvalue in this experiment.  Pipe: Function composition. The composition is .xed.  Visitor: Visitor pattern \nfor operations on a binary tree. The choice of operations is known at compile time.  Strategy: this \nis an image processing example using the strategy pattern. The speci.c operator is known at com\u00adpile \ntime.  ArithInt: This case study is a simple arithmetic expres\u00adsion interpreter.  5.1.1 Performance \nWe compare the performance of Civet with JSpec on bench\u00admarks from JSpec suite. We run Civet on the same \norigi\u00adnal programs with the same set of partial inputs in order to get specialized programs.We then, \nrun each specialized pro\u00adgram with the rest of inputs and measure the execution times. Each benchmark \nis run ten times and we take the average time of all the ten executions to represent the .nal reported \ntime. We run all the benchmarks on an Intel Core 2 Duo CPU P8400 2.26GHz machine with 2.8GiB of memory \nand running Ubuntu 10.04.We use the Sun JDK implementation ofJavaversion 1.6.0.We use no specialjava \ncommand line option for running benchmarks. Figure 14 compares execution time between JSpec and Civet \nfor all the case studies. Time is measured in millisec\u00adonds using the Java currentTimeMillis() call. \nThis .gure also shows the execution time of the original programs. Civet performs better than JSpec on \nall FFTs , ArithInt, Pipe,Vis\u00aditor and Strategy and it performs slightly worse on the rest. The average \nspeedup of JSpec on these examples is 5.19 and the average speedup of Civet is 5.7. We measured the number \nof lines generated by Civet on different case studies. The number of lines of code of the program would \nincrease after specialization because of method generation, loop unrolling etc. The number of lines of \ncode increase on almost all the examples is about 1.2 to 2 times the number of lines of code in the original. \nOn  CompileTime Example Java Civet Power 0.81 2.50 Romberg 0.82 2.55 Pipe 0.82 2.48 ArithInt 0.82 2.55 \nFFT 0.85 2.74 Visitor 0.83 2.59 Strategy 0.83 2.64 StateMachine 0.89 2.75 Pontis 0.96 3.09 Table 1. \nJava and Civet Compile Time comparison for all the examples FFT examples, however, due to a lot of loop \nunrolling, the increase factor goes up to 7.6 on FFT64. Moreover, we compared the bytecode size of the \ngenerated programs by JSpec and Civet. The bytecode size would increase for the same reasons the lines \nof code would. The average bytecode size increase on these case studies for Civet is 1.37, while it is \n1.39 for JSpec. Note that we could not generate any code with JSpec because the tool is not available. \nWe were only able to compile and run the generated code by JSpec.  5.1.2 CompileTimePerformance Table \n1 compares the compile time of Civet with that of Java on all the examples. The Civet compile time consists \nof code generation time and bytecode generation time. Same compiler options have been used for bytecode \ngeneration in both Civet and Java.  5.2 ModelTalk Case Study ModelTalk isa domain speci.c model driven \nframework [12]. It has an interpretive approach to model driven development. Since the execution is interpreter \nbased, it is a good target Table 2. The time comparison of regular expression match\u00ading between the state \nmachine before and after specialization and thefast Brics Automaton Program Time (ms) Original regex \nstate machine 1189 Specialized regex state machine 573 dk.brics.automaton regex library 816 for partialevaluation.We \nspecializeda Dynamic pricing sys\u00adtem called Pontis based on ModelTalk. The dynamic pricing system is \na system for calculating the prices of different products by applying a set of price promotions to each \nof them. The promotions are known at compile time while the products are known at runtime. The execution \ntime of the original system on a set of products for 2 \u00d7 106 iteration is 3153 ms, while the execution \ntime of the specialized version of the system using Civet is about 512 ms. This is a factor of 6 speedup. \nThis speedup is mainly gained by specializ\u00ading the re.ective method calls and turning them into normal \nmethod calls. Figure 15 gives some code taken from the Pontis exam\u00adple. Figure 16 gives the specialized \nversion of the code ex\u00adample. The original code has been partially evaluated with a compile-time list \nof price promotions. As shown in the Figure 16, the calcPromotionalPrice method call on the promotion \nobject has been turned into a static method call on the Promotion class. In addition, the re.ective method \ncalls in isEligible has been turned into a normal method call. The specialized method names have been \nappended by a$ and a number.  5.3 Regular Expression Case Study The motivation behind this case study \nis to show the success of the partial evaluation in the optimization of general pro\u00adgrams. This program \nis a pattern matching application using regular expressions. For the purpose of pattern matching of a \nregular expression we developed a simple and naive de\u00adterministic state machine library. This state machine \nlibrary simply tests the input and makes transitions. After consum\u00ading all of the input it reports a \nsuccessful match if it is in a .nal state. We compare the execution time of the original state\u00adbased \nmachine regular expression matcher with the spe\u00adcialized version of the state machine for detecting the \noc\u00adcurrence of this regular expression: (a | b)*(abb | (a + b)). We also compare the execution times \nagainst that of dk.brics.automaton [21]. Brics Automaton is a highly tuned automaton library which claimstodofastregularexpression \nmatching. Table2 shows theexecution time(in milliseconds)of the three programs for an input of length \n107 . Not surprisingly, the execution time of the specialized version of the state ma\u00adchine is less than \nthe original state machine for the men\u00ad  1 2 3_ 4= 5_ 6= 7= 8 9 10 11 12 13 14 _ 15 = 16 \n 17 = 18 = 19 20 21 22 23 24 _ 25 = 26 27 = 28 29 = 30 31 32 33 ...} Figure 15. Pontis \nSystem tioned regular expression. However, the execution time of the specialized version is also less \nthan that of Brics Automa\u00adton. This shows how partial evaluation can be used to gen\u00aderate ef.cient programs \nout of naive and general ones which can compete with highly tuned hand-written codes for the same functionality. \nFor the same reason we mentioned be\u00adfore, we could not compare our results with that of JSpec on this \ncase.  5.4 Scalability There are two important aspects to scalability of hybrid partial evaluation. \nOne is how much effort it requires to annotate the code for large programs. Second one is how much time \nit would take to specialize a program. To measure the .rst aspect of the scalability of our method, we \nde.ne and measure a factor called NOA/LOC. NOA is the number of annotations and LOC is the lines of code \nof the program. The NOA/LOC factor is the percent\u00adage of annotation with respect to the program size.We \nhave 1 2 3_ 4= 5= 6 7= 8 9 10 11 12 13 _ 14 = 15 16 = 17 18 = 19 20 21 22 23 24 _ 25 = 26 27 \n= 28 \" =  29 30 31 32 ...} Figure 16. Specialized Pontis System listed the NOA/LOC for all the examples \nin Table 3. The valueof thisfactor for allof theexamplesexcept the FFTis under %5 and their average is \n%1.67. This means that when using Civet, on average, we only need to annotate about %1.67 of the program \nregardless of the size of the program. This result is promising that we can expect almost the same constantfactorofeffort \nforeven larger programs. We investigated the reasons for high NOA/LOCfactor in the FFT example. In this \nexample there are many local and loop variables that must be tagged which increase the num\u00adber of annotations. \nCivet is an implementation of the seman\u00adticsofHPE.Itisfaithfultothe semanticsbutitdoesnotfully implement \nthe semantics. Thus, in some cases programmer needs to specify more prior to partial evaluation. The \nfull im\u00adplementation of the semantics in Civet is left as future work.  Example NOA LOC NOA/LOC Power \n2 116 1.72 Romberg 6 127 4.72 Pipe 3 149 2.01 ArithInt 2 176 1.13 FFT 35 185 18.9 Visitor 5 226 2.21 \nStrategy 4 362 1.10 StateMachine 1 325 0.30 Pontis 2 938 0.21 Table 3. Number Of Annotations (NOA), \nLines Of Code (LOC), andNOA/LOCfactor for all theexamples Time scalability, on the other hand, depends \non input and how much of the code is going to be affected by that input. For all the examples, the time \ntaken to specialize was less than a second for each. We anticipate that even for larger programs with \nmore than 100K lines of code, the time for partial evaluation would be linearly proportional to the code \nsize. 6. RelatedWork Partial evaluation has a long history. In this section we dis\u00adcuss the most relevant \nrelated work, speci.cally online par\u00adtial evaluation of imperative languages, and partial evalua\u00adtion \nof object-oriented languages. An online partial evaluator makes decisions about what to specialize during \nthe specialization process, while an of.ine partial evaluator makes all the decisions before specializa\u00adtion. \nRuf identi.es two ways in which online partial eval\u00aduators can produce better results than of.ine partial \nevalu\u00adators [23]. On one hand, of.ine partial evaluators must ap\u00adproximate the situations that can arise \nat runtime, so they are not as precise as is possible in an online setting. On the other hand, they also \ncannot identify commonalities between sit\u00aduations that depend on actual values of data. Hybrid partial \nevaluation supports the improvements identi.edby Ruf,but the focus of HPE is ease of use and implementation, \nnot bet\u00adter specialization. Since hybrid partial evaluation is guided by the programmer, the opportunities \nfor specialization are likewise limited. Hybrid partial evaluation uses an online strategy because we \nbelieve it is more direct and .ts within existing compil\u00aders. The approach has some potential disadvantages. \nOnline partial evaluation are often slower than of.ine partial evalua\u00adtors, because theymake complicated \ndecisions at specializa\u00adtion time, and often repeat the same analysis [24]. However, if specialization \ntime is a small part of the overall product development process, then specialization performance is not \na major issue. Programmer s ef.ciency, and ef.ciencyof the .nal software product are the most importantfactors. \nMeyer presents the semantics of online partial evaluator for a Pascal-like language [20]. The language \nis imperative and has binary and unary operations and control .ow struc\u00adtures, conditionals and loops. \nMeyer uses a continuation\u00adpassing semantics to implement state, but do not clone the continuation as \nsuggested by Ruf [23]. Meyer has a more complex treatment of conditionals than the one given here, in \nwhich the stores produced by the two conditional branches are merged. In practice, we have not found \na need for the more complex approach. Meyer provides a correctness proof of thisPascal-like language,but \nno practicalevaluation.We leave the correctness proof of the hybrid partial evaluation as future works. \nThere are some works on partial evaluation of object\u00adoriented languages such as Java [7, 19, 25, 26]. \nSchultz et al. [25] present a tool for automatic specialization of Java programs. Their tool is an of.ine \npartial evaluator. They show how partial evaluation can be used to reduce the over\u00adhead of object-oriented \nabstraction in generic programs [25]. Their tool does not support exceptions, multi-threading and re.ection. \nSimilarly, our methodology and tool do not offer anything for exceptions and multi-threading constructs \nyet. But we do have semantics and implementation for re.ection. Le Meur et al. [16] present a language \nwhich allows pro\u00adgrammers to provide speci.cations in order to guide the partial evaluator. The speci.cation \ntells the partial evalua\u00adtor how to propagate the compile-time data throughout the program. The ideas \nbehind their work and ours have simi\u00adlar roots. They use the programmer provided annotations to guide \nthe of.ine partial evaluation of a high level language which is similar to C. They have adapted the Tempo \n[6] partial evaluator so that it uses the provided speci.cations by programmers instead of the information \ngathered by the binding time analyzer. 7. Conclusion We presented a hybrid approach to partial evaluation \nof object-oriented languages, giving a formal de.nition of the technique for a miniature object-oriented \nlanguage, MOOL. In MOOL, programmer must specify the compile-time ex\u00adpressionsin programs. Thehybrid \npartialevaluator usesthe provided speci.cation to infer what parts of the code should be specialized. \nMoreover, it incorporates the speci.cation as seeds for exploiting opportunities for further specializations \nin other parts of the code. This hybrid approach supports method and class specialization, including \nspecialization of partial objects. It can also convert re.ective method calls into ordinary calls. However, \nit does not support self-application and therefore it can only provide the .rst of the three Futa\u00admura \nprojections [11]. We described how the approach was used to build a hy\u00adbrid partial evaluator for Java \ncalled Civet. While Civet is suf.cient to optimize a number of real-world examples, in the current prototype \nsome aspects of Java interfere with spe\u00adcialization. These include final and private modi.ers on declarations. \nThe burden of speci.cation is light. One goal of our work is to develop techniques that can be incorporated \ninto existing compilers. The entire Java partial evaluator took 4 person-monthstobuildasanextensiontoanexistingJava \ncompiler.  The system was evaluated on a number of examples, in\u00adcluding several Java programs written \nby other groups. The execution time of a small version of the Pontis dynamic pric\u00ading system, which uses \nmodel interpretation and re.ection, was reduced by a factor of 6 (1/6 of the original execution time). \nThe code generated by Civet performs as well and in some cases even better than the code generated by \na state\u00adof-the-art of.ine partial evaluator for Java, JSpec, which is based onTempo [6]. Civet also handles \nre.ection. Acknowledgments. This work was supported by the National Science Foundation under Grants #0811536 \nand #0724979. We thank Charles Consel, John Thywissen and Ben Delaware for their help and comments. References \n[1] Andersen, L.: Program Analysis and Specialization for the C Programming Language. Ph.D. thesis, University \nof Copen\u00adhagen (1994), DIKU Research Report 94/19 [2] Braux, M., Noy\u00e9, J.: Towards partially evaluating \nre.ection in Java. In: Symposium onPartial Evaluation and Semantics-Based Program Manipulation (PEPM). \npp. 2 11. ACM, New York, NY, USA (1999) [3]Brzozowski, J.A.: Derivativesof regularexpressions.J.ACM 11, \n481 494 (October 1964), http://doi.acm.org/10. 1145/321239.321249 [4] Bulyonkov, M.: A theoretical approach \nto polyvariant mixed computation. Partial Evaluation and Mixed Computation (PEMC)pp. 51 64 (1988) [5] \nConsel, C.: Polyvariant binding-time analysis for applica\u00adtive languages. In: Symposium on Partial Evaluation \nand Semantics-Based Program Manipulation (PEPM). pp. 66 77 (1993) [6] Consel, C., Hornof, L., Marlet, \nR., Muller, G., Thibault, S., Volanschi, E.N., Lawall, J., Noy\u00e9, J.: Tempo: specializing systems applications \nand beyond. ACM Comput. Surv. p. 19 (1998) [7] Dean, J., Chambers, C., Grove, D.: Identifying pro.table \nspe\u00adcialization in object-oriented languages. Symposium on Par\u00adtial Evaluation and Semantics-Based Program \nManipulation (PEPM) pp. 85 96 (1994) [8] Dussart, D., Bevers, E., Vlaminck, K.D.: Polyvariant con\u00adstructor \nspecialisation. In: Symposium on Partial Evaluation and Semantics-Based Program Manipulation (PEPM). \npp. 54 65 (1995) [9] Ekman,T., Hedin, G.: The JastAdd system modularexten\u00adsible compiler construction. \nSci. Comput. Program. 69(1-3), 14 26 (2007) [10] Ershov, A.P., Ostrovski,B.N.: Controlled mixed computation \nand its application to systematic development of language\u00adoriented parsers. In: The IFIP TC2/WG 2.1 Working \nConfer\u00adence on Program speci.cation and transformation. pp. 31 48. North-Holland Publishing Co. (1987) \n[11] Futamura, Y.: Partial evaluation of computation process -an approach to a compiler-compiler. Systems, \nComputers, Con\u00adtrols 2, 45 50 (1999) [12] Hen-Tov, A., Lorenz, D.H., Pinhasi, A., Schachter, L.: Mod\u00adeltalk: \nWheneverything isa domain-speci.c language. IEEE Softw. 26, 39 46 (July 2009) [13] Jones, N.D., Gomard, \nC.K., Sestoft, P.: Partial evaluation and automatic program generation. Prentice-Hall, Inc., Upper SaddleRiver, \nNJ, USA (1993) [14] Jones, S.P.: Haskell 98 Language and Libraries. Cambridge University Press (2003) \n[15] Lawall, J.L., Danvy, O.: Continuation-based partial evalua\u00adtion. SIGPLAN Lisp Pointers VII, 227 \n238 (July 1994) [16] Le Meur, A.F., Lawall, J.L.,Consel,C.: Specialization scenar\u00adios: A pragmatic approach \nto declaring program specializa\u00adtion. Higher Order Symbol.Comput. 17(1-2), 47 92 (2004) [17] Lindholm, \nT., Yellin, F.: Java(TM) Virtual Machine Speci.\u00adcation, The (2nd Edition). Prentice Hall PTR, 2 edn. \n(April 1999) [18] L\u00f6h, A.: lhs2tex. http://people.cs.uu.nl/andres/ lhs2tex/ [19] Marquard, M., Steensgaard, \nB.: Partial Evaluation of an Object-Oriented Imperative Language. Master s thesis, Uni\u00adversity ofCopenhagen \n(DIKU) (April 1992) [20] Meyer, U.: Correctness of on-line partial evaluation for a Pascal-like language. \nSci. Comput. Program. 34(1), 55 73 (1999) [21] M\u00f8ller, A.: Finite-state automata and regular expressions \nfor Java (2010), http://www.brics.dk/automaton/ [22] Poole, J.D.: Model-driven architecture: Vision, \nstandards and emerging technologies. In: ECOOP 2001,Workshop on Meta\u00admodeling and Adaptive Object Models \n(2001) [23]Ruf,E.,Weise,D.: Opportunitiesfor online partialevaluation. Tech. Rep. CSL-TR-92-516, Computer \nSystems Laboratory, Stanford University, Stanford, CA (April 1992) [24] Ruf, E.S.: Topics in online partial \nevaluation. Ph.D. thesis, Stanford University, Stanford, CA, USA (1993) [25] Schultz, U.P., Lawall, J.L., \nConsel, C.: Automatic program specialization for Java. ACM Trans. Program. Lang. Syst. 25(4), 452 499 \n(2003) [26] Schultz, U.P.: Partial evaluation for class-based object\u00adoriented languages. In: PADO 01: \nProceedings of the Sec\u00adond Symposium on Programs as Data Objects. pp. 173 197. Springer-Verlag, London, \nUK (2001) [27] Thiemann, P., Dussart, D.: Partial evaluation for higher-order languages with state (1996), \nunpublished manuscript [28] Wadler, P.: Monads for functional programming. In: Ad\u00advanced Functional Programming, \nFirst International Spring School on Advanced Functional Programming Techniques-TutorialText. pp. 24 \n52. Springer-Verlag, London,UK (1995)   \n\t\t\t", "proc_id": "2048066", "abstract": "<p>Hybrid partial evaluation (HPE) is a pragmatic approach to partial evaluation that borrows ideas from both online and offline partial evaluation. HPE performs offline-style specialization using an online approach without static binding time analysis. The goal of HPE is to provide a practical and predictable level of optimization for programmers, with an implementation strategy that fits well within existing compilers or interpreters. HPE requires the programmer to specify where partial evaluation should be applied. It provides no termination guarantee and reports errors in situations that violate simple binding time rules, or have incorrect use of side effects in compile-time code. We formalize HPE for a small imperative object-oriented language and describe Civet, a straightforward implementation of HPE as a relatively simple extension of a Java compiler. Code optimized by Civet performs as well as the output of a state-of-the-art offline partial evaluator.</p>", "authors": [{"name": "Amin Shali", "author_profile_id": "81100218429", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2839198", "email_address": "amshali@cs.utexas.edu", "orcid_id": ""}, {"name": "William R. Cook", "author_profile_id": "81406596033", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P2839199", "email_address": "wcook@cs.utexas.edu", "orcid_id": ""}], "doi_number": "10.1145/2048066.2048098", "year": "2011", "article_id": "2048098", "conference": "OOPSLA", "title": "Hybrid partial evaluation", "url": "http://dl.acm.org/citation.cfm?id=2048098"}