{"article_publication_date": "10-22-2011", "fulltext": "\n Asynchronous Assertions Edward E. Aftandilian Samuel Z. Guyer Martin Vechev Tufts University and Google \nTufts University ETH Zurich and IBM Research eaftan@cs.tufts.edu sguyer@cs.tufts.edu martin.vechev@gmail.com \n EranYahav * Technion,Israel yahave@cs.technion.ac.il Abstract Assertions areafamiliar and widely usedbug \ndetection tech\u00adnique.Traditional assertion checking, however, is performed synchronously, imposing its \nfull cost on the runtime of the program. As a result, many useful kinds of checks, such as data structure \ninvariants and heap analyses, are impractical because theylead to extreme slowdowns. We present a solution \nthat decouples assertion evalua\u00adtion from program execution: assertions are checked asyn\u00adchronously by \nseparate checking threads while the program continues to execute. Our technique guarantees that asyn\u00adchronous \nevaluation always produces the same result as syn\u00adchronous evaluation, even if the program concurrently \nmod\u00adi.es the program state. The checking threads evaluate each assertion on a consistent snapshot of \nthe program state as it existed at the moment the assertion started. We implemented our technique in \na system calledSTROBE, which supports asynchronous assertion checking in both single-and multi-threaded \nJava applications. STROBE runs inside the Java virtual machine and uses copy-on-write to construct snapshots \nincrementally, on-the-.y. Our system includes all necessary synchronization to support multiple concurrent \nchecking threads, and to prevent data races with the mainprogram threads.We .nd that asynchronous check\u00ading \nsigni.cantly outperforms synchronous checking, incur\u00adring tolerable overheads in the range of 10% to \n50% over no checking at all even for heavy-weight assertions that would otherwise result in crushing \nslowdowns. * Deloro fellow Permission to make digital or hard copies of all or part of this work for \npersonal or classroomuseisgrantedwithout feeprovidedthat copies arenot madeordistributed forpro.torcommercialadvantage \nandthatcopiesbearthisnoticeandthefullcitation onthe .rstpage.To copy otherwise,torepublish,topostonserversortoredistribute \ntolists,requirespriorspeci.cpermission and/ora fee. OOPSLA 11, October22 27,2011,Portland,Oregon,USA. \nCopyright c &#38;#169; 2011ACM978-1-4503-0940-0/11/10. . .$10.00 Categories and Subject Descriptors D.2.4[Software/Pro\u00adgram \nVeri.cation]: Assertion checkers; D.1.3[Concurrent Programming] General Terms Reliability,Performance, \nExperimentation Keywords Assertions, concurrent checking, heap snapshot, dynamic analysis, data structure \ninvariants 1. Introduction Assertions are a widely used technique for program mon\u00aditoring and bug detection. \nAssertions are easy to use programmers add them directly to their code and they provide a precise and \nreliable failsafe for critical program properties. The downside is that assertions are checked syn\u00adchronously, \nimposing their full cost directly on the run\u00adtime of the program. As a result programmers must take care \nnot to add assertions that are too frequent or too costly. This constraint severely limits the kinds \nof prop\u00aderties that can be checked using assertions, and existing code re.ects this limitation: it often \ncontains simple and cheap assertions, such as assert(p!=null),but almost never contains complex and expensive \nassertions, such as assert(redblack invariants(my tree)). This paper presents Asynchronous Assertions, \na new mechanism that supports ef.cient checking of complex as\u00adsertions, including heap properties and \ndata structure invari\u00adants. The central idea is to perform expensive checks con\u00adcurrently in separate \nthreads, allowing the application exe\u00adcution to continue unimpeded. The key problem we solve is how to \nensure that asynchronous evaluation produces the same result as synchronous evaluation, even if the applica\u00adtion \nproceeds to modify the program state while the check is running. Our solution is to run assertion checks \non a snapshot of the heap as it existed when the assertion was encountered. We introduce techniques to \nimplement the snapshot mech\u00adanism ef.ciently and to ensure the absence of race condi\u00adtions between the \napplication and the checking threads. No changes are needed to make assertions asynchronous: pro\u00adgrammers \nsimply identify the code that implements the as\u00adsertions, and our system automatically adds instrumentation \nthat reads from the snapshot and handles concurrency.  The programming model for handling asynchronous \nas\u00adsertion failures, however, is necessarily different. Although asynchronous assertions produce the \nsame result as syn\u00adchronous assertions, the result only becomes known at some later point in execution. \nTherefore we offer two methods for handlingfailures. The .rst is completely asynchronous: like a traditional \nassertion, a failure causes the program to stop, wherever execution happens to be at that point. The \nsecond interface is like a future: when an assertion starts it returns a handle that the application \ncode can use to inquire about the result of the assertion, or force synchronous evaluation. We implemented \nasynchronous assertions for Java in the Jikes RVM. Our implementation, called STROBE, works with single-and \nmulti-threaded applications and supports multi\u00adple concurrent assertions, each with its own snapshot. \nOn suitable hardware, assertions can be evaluated in parallel on separate CPU cores. Our implementation \nincludes several optimizations that reduce the cost of creating and managing snapshots. First, it uses \nper-object copy-on-write to snapshot only those objects that the application actually modi.es. Second, \nit never snap\u00adshots objects that are new since the start of the most recent check (since they do not \nexist in any snapshot). Finally, we share copies between snapshots whenever possible. Since existing \nprograms do not contain suitably complex assertions, we evaluate our system using a combination of micro-benchmarks \n(adopted from related work), and syn\u00adthetic assertions running on a more realistic benchmark. The synthetic \nassertions allow us to thoroughly explore the per\u00adformance space: we systematically vary the frequency \nand cost of assertions, and the number of checking threads. We .nd that asynchronous evaluation greatly \noutper\u00adform synchronous evaluation, as long as there are enough checking threads to keep up with the \nrate of new asser\u00adtions. With suf.cient resources our approach supports sig\u00adni.cantly higher checking \nworkloads for a given runtime overhead budget. Limiting the overhead to 20%, for ex\u00adample, six checker \nthreads can perform checks that would otherwise slow the program by a factor of 2.5 if evaluated synchronously.Witha \n30%overheadbudget, six threads can perform checks that would otherwise slow the program by a factor of \n4. With a 40% budget six checker threads can perform checks that would otherwise slow the program by \na factor of 6.5. The contributions of this paper are: Asynchronous Assertions, a new assertion checking \nmechanism that evaluates assertions concurrently with the application, while guaranteeing the same results \nas synchronous evaluation.  An ef.cient implementation of our technique in a system calledSTROBE built \non JikesRVM.  private boolean isOrdered() { Node n = head; while (n != null &#38;&#38; n.next != null){ \nif (n.data > n.next.data) return false; n = n.next; } return true; } Figure 1. Example assertion: \nunmodi.ed code to check whether a linked list is ordered. An evaluation of STROBE on different usage \nscenarios: a set of microbenchmarks with data structure invariant as\u00adsertions, and a well-known benchmark \nwith a synthetic assertion allowing us to systematically explore the per\u00adformance space. Our results \nindicate that STROBE works well in practice: it greatly outperforms synchronous checking, and can execute \na range of intensive assertion workloads with overheads ranging from 10% to 50%.  2. Overview In this \nsection, we show how to use STROBE to write and check a data structure invariant assertion asynchronously. \nWe describe the programming model and give code for a small example. A Use Case Suppose that we are implementing \nan ordered linked list, and we want to ensure the invariant that for any node in the list, node.data \n<= node.next.data. To check this invariant synchronously, we would write a checking method that is called \nbefore and after every pub\u00adlic method invocation on the data structure. This checking method appears \nin Fig. 1. Using Asynchronous Assertions With a large linked list, this invariant may take a long time \nto check, so it is a good candidate for asynchronous checking.Here we show how to convert it to an asynchronous \nassertion for use in STROBE. STROBE de.nes an interface, StrobeTask, which the user must implement to \nissue an asynchronous assertion. StrobeTask contains only one method, compute(), which the system will \ncall to compute the result of the check. The de.nition of StrobeTask is shown in Fig. 2. To convert our \nsynchronous ordering check to an asyn\u00adchronous one, we simply call the synchronous checking method in \nFig.1from inside the compute() method of an inner class that implements StrobeTask.We also tag this method \nwith a special annotation, @ConcurrentCheck, so the JVM knows it is meant to run concurrently. Code for \nthis inner class is shown in Fig. 2 (we assume that isOrdered() is declared inside the inner class). \nNote that the code inside compute() simply calls isOrdered(): no changes are needed to execute the check \nconcurrently; the STROBE system automatically handles all synchronization.  public interface StrobeTask \n{ public boolean compute(); } private class InvTask implements StrobeTask { @ConcurrentCheck public \nboolean compute() { return isOrdered(); } } Figure 2. Example assertion modi.ed to use the asyn\u00adchronous \nassertions StrobeTask interface. No changes to the core assertion check isOrdered() are necessary. When \nusing this asynchronous checking mechanism, we must choose what to do if the check fails (i.e, if the \nlist is unordered). STROBE provides two choices for how to han\u00addle check failures. One choice is to exit \nthe program im\u00admediately and inform the user that the check failed. This is analogous to traditional \nassertion checking. The seman\u00adtics are slightly different, however, because the program con\u00adtinues executing \nasynchronously and progresses beyond the point where the assertion is started. This model is useful in \ncases where a failed check would not result in catas\u00adtrophic side effects, but we want the program to \nhalt. In STROBE, this is implemented by issuing the check using the StrobeAssertion class (see Fig. 3). \nHowever, if itis crucial that the program not progress be\u00adyond a certain point if the check fails, STROBE \nprovides a future-like mechanism for the program to wait for the re\u00adsult of the asynchronous check before \nproceeding. When the check is issued, STROBE returns a handle to the result of the check, and calling \nthe get() method of the handle blocks the program until the result becomes available. Thus the user can \nseparate the initiation of the check from the point when the result is needed, allowing the system to \nex\u00adploit as much concurrency as possible. In STROBE, this is im\u00adplemented by issuing the check using \nthe StrobeFuture class (see Fig. 3). Note that in either case, the program is allowed to modify the data \nstructure as soon as the check is issued, even if the check has not completed yet. Because of STROBE \ns snapshot\u00adting mechanism, the check will return the same result as if the data structure had not been \nmodi.ed.  3. Snapshot semantics In this section we describe the semantics of our snapshot mechanism. \nWe present an abstract model of snapshots and use this model to describe our snapshot algorithms for \nboth single and multiple concurrent assertions. We show how these algorithms capture the state of the \nprogram at a par\u00adticular point without copying all of the objects.We also enu\u00admerate several optimizations \nthat further reduce the amount of state we need to preserve and cost of copying. We add synchronization \nwhere necessary to avoid race conditions StrobeAssertion sassertion = new StrobeAssertion(new InvTask()); \nsassertion.go(); (a) StrobeFuture sfuture = new StrobeFuture(new InvTask()); sfuture.go(); ... assert(sfuture.get()); \n(b) Figure 3. Using (a) StrobeAssertion and (b) StrobeFuture to issue the check. With StrobeAssertion, \nthe program will exit immedi\u00adately if the check returns false. With StrobeFuture, the system returns \na handle to the future result, and at a crucial point, the program can block and wait for the result \nby calling get(). between the application and the asynchronous assertions. Using our approach, we can \nsafely construct snapshots on\u00adthe-.y: the assertion code computes its result on a snapshot while the \napplication mutates the state. 3.1 Snapshot model A snapshot captures the state of the program at a \nmoment in time. Since our goal is to support complex checks, such as data structure invariants, our focus \nis on snapshotting the state of the heap. The heap consists of a set of objects containing both primitive \nvalues as well as references to other objects. We assume that objects are mutable, so it is necessary \nto preserve object states in order to construct a snapshot. We model heap mutability as a series of object \nversions: conceptually, each time an object is modi.ed a new version is created. Given an object o, oi \nrepresents the state of the ob\u00adject after i mutations. The most recent version is represented by the \nmapping current(o).In the application s code, a .eld access always retrieves its value from the current \n(most re\u00adcent) version: o.f is interpreted as current(o).f . A snapshot, then, is the set of object versions \nthat were current at the moment the snapshot is requested (in our case, the moment an asynchronous assertion \nis started). Our al\u00adgorithm is based on the observation that many of these ver\u00adsions will continue to \nbe current, as long as the application does not modify them. The only object versions we need to preserve \nare those that the application mutates after the start of the assertion check. In the discussion below \nwe refer ex\u00adplicitlytoversionsof objects,butin our implementation we preserve an object s state by copying \nit right before the write occurs (copy-on-write).Bymaking this operation atomic, an assertion can safely \naccess its snapshot, even if the applica\u00adtion changes the heap concurrently.  3.2 Single snapshot We \nstart with an algorithm that computes a single heap snap\u00adshot for a single asynchronous assertion. Initially, \nthere are no preserved versions of objects. Evaluating the assertion in this state is equivalent to traditional \nsynchronous evaluation. When an asynchronous assertion is encountered the system enables the following \nread and write behavior by atomically setting a global .ag active to true. The version of an object we \nwant to preserve is the ver\u00adsion that was current when the snapshot started. This ver\u00adsion will still \nbe the current version at the .rst write to the object (if any write occurs). So, at an application write \nwe .rst check to see if the given object already has a preserved version in the snapshot. If so, there \nis no extra work to do. If not, we keep a reference to that old version in a sepa\u00adrate mapping called \npreserved before allowing the write to proceed and produce a new version. A Boolean .ag called modif \nied records which objects have been preserved. At application write to object o: if active and !modif \nied(o) preserved(o) := current(o)= oi modif ied(o) := true write to o , current(o) := oi+1 The assertion \nchecking code accesses the snapshot by .rst determining whether to use the original object or the pre\u00adserved \nversion. A read of the form o.f is interpreted snapshot(o).f where: { preserved(o), modif ied(o)snapshot(o)= \ncurrent(o), otherwise. When an assertion completes, the assertion code sets the active .ag tofalse, and \nclears the preserved and modif ied data structures. 3.3 Guarantees We guarantee that when the assertion \ncode reads an object it sees either (a) the original object, if it has not been modi.ed since the time \nthe check started, or (b) a copy of the object that re.ects its state at that time, if it has been modi.ed. \nIn our implementation we ensure the absence of race con\u00additions by updating modif ied and preserved atomically. \nNo interleaving allows the assertion checker to see modi\u00ad.cations to the object that occur after it starts. \nOur synchro\u00adnization strategy is described in more detail in Section 4 (Implementation). Note, however, \nthat there can be races when multiple application threads start assertions without synchronizing with \neach other. Notice in the algorithm above that assertion checking code applies the snapshot mapping at \nevery.eld load. This algorithm avoids exposing direct references to preserved versions of objects, which \nis critical for both correctness and performance: Snapshots change dynamically. An object write in the \nap\u00adplication can occur in the middle of an assertion check, triggering a snapshot operation. Earlier \nassertion code might have read from the original object, but all subse\u00adquent accesses must be redirected \nto the snapshot.  Object identity is preserved. Hiding snapshot references is crucial for the correctness \nof code that relies on object identity (such as reference comparison and Identity- HashMap, which could \nbe destroyed if we allow a mix of references to the current and old versions of an object.  No reference \n.xup . We never need to .x object refer\u00adences in the running assertion code, since snapshot refer\u00adences \nare never held directly in local variables or stored in anydata structures.   3.4 Multiple snapshots \nMultiple concurrent asynchronous assertions can be trig\u00adgered either by a single thread issuing one assertion \nbefore another is completed, or by multiple application threads is\u00adsuing assertions concurrently.In either \ncase, each concurrent assertion needs its own snapshot, corresponding to the heap state at the time it \nstarted. The main problem we solve is determining, at a given ap\u00adplication write, which snapshots need \nto preserve the current objectversion and whichdo not.Again, thekeyobservation is that we only need to \npreserve an object the .rst time it is modi.ed with respect to anygiven snapshot. We start by introducing \nanepoch counter E: E is initially 0; the system increments E each time it starts executing a new asynchronous \nassertion. The epoch number serves as a unique identi.er for each dynamic check instance. The .ag active \nbecomes a set of .ags, one for each epoch, that indicates which checks are still running. Instead of \nsimply recording whether an object is modi.ed or not, we record in which epoch it was last modi.ed. We \nstore this information in a mapping modif iedAt(o). An object needs to be preserved for an assertion \nstarted at time Et if it was last modi.ed in an epoch before Et . Finally, we augment the preserved mapping \nto hold multiple object versions, one for each snapshot. At an application write to object o: for each \nassertion Et if active(Et ) and modif iedAt(o) <Et then preserved(o, Et ) := current(o)= oi modif iedAt(o) \n:= E write to o , current(o) := oi+1 Each assertionreadsfrom its snapshot, as necessary.A read of the \nform o.f in an active assertion instance Et is inter\u00adpreted snapshot(o, Et ).f where: { preserved(o, \nEt ), modif iedAt(o) = Etsnapshot(o, Et )= current(o), otherwise.  3.5 Optimizations void writeBarrier(Object \nsrc, Object target, The algorithms above construct relatively small snapshots, Offset offset) { consisting \nof only those objects that the application modi.es. int epoch = Snapshot.epoch; We further reduce the \ncost of constructing snapshots using if (Header.isCopyNeeded(src, epoch)) { two optimizations: // --Needs \nto be copied, we are the copier Skip new objects: We never need to preserve newly cre\u00adated objects. \nObjects created since the start of the most recent asynchronous assertion do not exist in any snap\u00adshot. \nWe can easily implement this optimization in our framework by initializing modif iedAt(o) to the current \nepoch value E for any newly allocated objects. This op\u00adtimization proves extremely valuable because it \nprevents unnecessary copying that would otherwise be triggered by frequent mutations in object constructors. \n Share object copies: At any given write, the snapshots that need to preserve the mutated object all \nneed the same version of that object (i.e., the current version). Since our implementation uses copying \nto preserve state, we can share one copy across all the snapshots that need it. This optimization also \nallows us to simplify the test for copying: at a write if modif iedAt(o) <E then at least one snapshot \nneeds a copyof object o.   4. Implementation In this section, we describe the implementation of the \nalgo\u00adrithms presented in Section 3. The two main challenges are (a) .nding an ef.cient way to store and \naccess snapshots, and (b) ensuring that snapshot management is free of data races. The system is implemented \nin Jikes RVM 3.1.1, the most recent stable release, and consists of three major com\u00adponents: Copying \nwrite barrier: When an assertion starts, STROBE activates a special write barrier in the application \ncode that constructs a snapshot of the program state.It copies objects as necessary to preserve the state \nand synchro\u00adnizes snapshot access with the checker threads.  Checker thread pool: Checker threads pick \nup assertions as they are issued andexecute them.Ifall checker threads arebusy, assertions block the \napplication thread until one is free.  Snapshot read barrier: Assertion checking code is written in \nregular Java, tagged with an annotation that the com\u00adpiler recognizes (see Fig. 2). The code is compiled \nwith a read barrier that returns values from object snapshots whenever they are present.  4.1 Snapshot \nstorage and management The primary goal of our design is to minimize the impact of snapshot management \non the performance of the appli\u00adcation threads. The last modi.cation time of an object (the modif iedAt \nvalue, expressed in terms of epoch number) // timestamp(src) == BEING_COPIED snapshotObject(src); // \n--Done; update timestamp to current epoch Header.setTimestamp(src, epoch); } // --Do the write (omitted: \nGC write barrier) src.toAddress().plus(offset).store(target); } Figure 4. Copy-on-write write barrier \nboolean isCopyNeeded(Object obj, int epoch) { int timestamp; do { // --Atomic read of current timestamp \ntimestamp = obj.prepareWord(EPOCH_POS); // --If in current epoch, nothing to do if (timestamp == epoch) \nreturn false; // --If someone else is copying, wait if (timestamp == BEING_COPIED) continue; // --...until \nCAS BEING_COPIED succeeds } while (!obj.attempt(timestamp, BEING_COPIED, EPOCH_POS)); return true; } \nFigure 5. Snapshot synchronization must be checked at every single write. To make this opera\u00adtionfast \nwe store the timestamp informationin anextraword added to the header of each object. Preserving the state \nof an object is accomplished by tak\u00ading a snapshot of it right before a write. Because this copy operation \noccurs in the application thread, we put signi.\u00adcant effort in reducing the cost of copying and eliminating \nunnecessary copies. Since the original object is mutated, all existing references to it continue to point \nto the most current version. No extra work is needed to maintain this informa\u00adtion (i.e., the current(o) \nmapping is a no-op.) Since we have a .xed pool of checker threads, much of the information about active \nassertions is identi.ed by the ID of the checker thread, not by the epoch number. With T checker threads \nwe will have at most T simultaneous snap\u00adshots, and therefore at most T copies of any given object. We \nstore this information (thepreserved mapping) in a per\u00adobject array of T references (one for each potential \nsnap\u00adshot), indexedbythreadID.Werefertoitasthe forwarding array.  4.2 Synchronization All snapshot \noperations, both reads and writes, work on a single object at a time. Therefore we can synchronize these \noperations on the modif iedAt word in the object header. We check and update this value using only atomic \noperations, and use two techniques to avoid race conditions. First, the write barrier stores a being \ncopied sentinel value in the modif iedAt wordduring copying. The sentinel value ensures that three operations \ncopying the object, up\u00addating the epoch timestamp, and performing the write occur as an atomic unit. \nThis avoids a potential race con\u00addition in which two application threads modify the same object, resulting \nin two snapshots, one of which is incor\u00adrect. Note that this situation does not necessarily represent \na race in the application if the two threads are updating dif\u00adferent .elds.Without synchronization it \nis possible for both threads to determine that the object must be copied (both see modif iedAt(o) <E). \nOne thread copies the object, installs the copyin the forwarding array, and performs its write. The second \nthread then copies the object again but this copy includes the write from the .rst thread, which should \nnot be visible to the checker. Second, we order these operations in such a way that the checker thread \ncannot see intermediate results: the write barrier only updates the timestamp after it has made the copy, \nbut before it applies the write. The read barrier might access the copy before it needs to, but it will \nnever see new values written to the object. To be safe, we also fully copy the object before installing \nits reference in the forwarding array. 4.3 Write barrier The write barrier is shown in Fig. 4 (slightly \nsimpli.ed from the actual code). All operations on the forwarding array (making or accessing copies) \nare synchronized using atomic operations on the object s timestamp. The write barrier .rst calls a method \nto determine if a copyis needed. The method isCopyNeeded() is shown in Fig. 5. It consists of a loop \nthat exits when either (a) the timestamp is current, so no copy is needed, or (b) the timestamp is older \nthan the current epoch, so a copy is needed. In case (b) the code writes a special sentinel value BEING \nCOPIED into the timestamp, which effectively locks the object. All other reads and writes are blocked \nuntil the sentinel is cleared. This code is compiled inline in the application.  4.4 Snapshot creation \nThe snapshot code, shownin Fig.6(slightly simpli.edfrom the actual code), is compiled out-of-line, since \nit is infre\u00adquent and relatively expensive. It .rst loads the forwarding array, creating one if necessary.It \nthen makes a copy of the object using an internalfast copy(the same mechanism used in the copyinggarbage \ncollectors).It installsa pointerto the copyin each slot of the forwarding array for which the corre\u00ad \nvoid snapshotObject(Object obj) { // --Get forwarding array; create if needed Object[] forwardArr = Header.getForwardingArray(obj); \n if (forwardArr == null){ forwardArr = new Object[NUM_CHECK_THREADS]; Header.setForwardingArray(obj, \nforwardArr); } // --Copy object Object copy = MemoryManager.copyObject(obj); // --Provide copy to each \nactive checker // that has not already copied it for (int t=0; t < NUM_CHECK_THREADS; t++) { if (isActiveCheck(t) \n&#38;&#38; forwardArr[t] == null) forwardArr[t] = copy; } } Figure 6. Copying code // --Returns the object \nto read from, // either the original or the copy Object readBarrier(Object obj) { // --Get forwarding \narray Object[] forwardArr = Header.getForwardingArray(obj) // --No forwarding array? return original \nif (forwardArr == null) return obj; else { // --Else load copy from forwarding array, // indexing by \nchecking thread ID Object copy = forwardArray[thisThread.checkerId]; // --No copy of this object? return \noriginal if (copy == null) return obj; else { // --...otherwise return copy (snapshot) return copy; \n} } } Figure 7. Read barrier sponding checker thread is (a) active and (b) has not already copied the \nobject (slot is null). Our system allocates all object copies and forwarding ar\u00adrays in the Java heap, \nwhich allows them to be automati\u00adcallyreclaimedbythegarbage collector.Our systemis com\u00adpletely independent \nof any speci.cgarbage collection algo\u00adrithm, we onlyrequire thegarbage collector to consider for\u00adwarding \narrays in its processing of the heap (this is the only change we made to the collector). When an assertion \ncom\u00adpletes, the checker nulls out all of the slots in the forwarding arrays corresponding to its thread \nID, eliminating the only references to the snapshot objects.Forwarding arrays arere\u00adclaimed when the \noriginal objects becomegarbage.  4.5 Read barrier Assertion checking code is compiled with a read barrier, \nshown in Fig. 7 (also slightly simpli.ed), that accesses the forwarding array as necessaryto read data \nfrom object snap\u00adshots. The read barrier .rst loads the forwarding array, and if the array is non-null, \nit uses the ID of the checker thread to index into the forwarding array and retrieve the copy be\u00adlonging \nto that snapshot.Ifeither the forwarding array or the copy is null, it indicates that the object has \nnot been copied, and the read barrier returns the current reference to the ob\u00adject, which may then be \nread.  5. Experimental Evaluation In this section we present an experimental evaluation of STROBE.The \nfocusofthisevaluationisnotonbug detection: our technique detects all the same errors that traditional \nsynchronous assertions would catch. Our goal is to explore the performance space of this technique in \norder to provide a sense of how well it works under a range of conditions. Our main .ndings are: Asynchronous \nchecking performs signi.cantly better than synchronous checking in almost all circumstances. Only when \nindividual checks are extremely brief does the overhead of concurrency overwhelm the bene.t.  Since \nassertions are independent, they parallelize per\u00adfectly. As long as there are enough checker threads \nto keep up with the demand, our technique slows over\u00adall runtime by 10% to 60%, depending on the assertion \nworkload.Bycomparison,evaluating the same assertions synchronously slows runtime by 1.25X to 8X.  When \nthere are not enough checker threads for the as\u00adsertion workload, the application must often wait for \nan available checker. At this point the slowdown begins to grow quicky, at a rate similar to synchronous \nevaluation.  The main source of overhead is creating and maintain\u00ading snapshots. We found, however, \nthat up to 1/3 of the overhead is due to other factors a combination of the cost of the extra words \nin the object header (one for the epoch, and one for the forwarding address) and possibly additional \npressure on the memorysystem.  Sharing object copies between snapshots signi.cantly reduces overhead. \nWithout this optimization, snapshot overheads would be approximately 50% higher.  5.1 Experimental \nset up We evaluate STROBE using two kinds of experiments: mi\u00adcrobenchmarks instrumented with data structure \ninvariant checks, and a real benchmark program (SPEC JBB2000), instrumented with synthetic assertions \nthat allow us to sys\u00adtematically vary the frequency and cost of the checks. Both sets of benchmarks are \nassertion-intensive, making them a challenge to execute ef.ciently. Figure 8. Typical results: Asynchronous \nevaluation has a low overhead as long as the assertion workload does not overwhelm the checker threads. \nint traverseAndCheck(Node n, Node p) { if (n == null) return 1; Node l = n.left; Node r = n.right; // \n--Recursive traversal: // get num of black nodes below us int lb = traverseAndCheck(l, n); int rb = \ntraverseAndCheck(r, n); // --Check that the tree is balanced if (lb != rb || lb== -1) return -1; // \n--Check that the tree is ordered Integer val = (Integer) n.key; if (l != nil &#38;&#38; val <= (Integer) \nl.key) return -1; if (r != nil &#38;&#38; val >= (Integer) r.key) return -1; // --Check colors: int c \n= n.color; if (c == RED &#38;&#38; (l.color != BLACK || r.color != BLACK)) return -1; // --Return total \nnum black nodes return lb + (n.color == BLACK ? 1 : 0); } Figure 9. An assertion procedure that performs \nrecursive checking of various safety properties on a red-black tree. Microbenchmarks. Our microbenchmarks \nexperiments replicatetheevaluationpresentedintheDittowork[13].We implemented two data structures: an \nordered linked list and a tree-map usingared-black tree.For each one, we addeda method that checks the \ndata structure invariants: Ordered linked list: check that link.next.prev == link and that elements \nare ordered.  TreeMap red-black tree: (a) make sure values are in order,  (b) check that all children \nof red nodes are black, and (c) make sure that all paths from the root to a leaf have the same number \nof black nodes. The code is shown in Fig. 9.  sal and access. We control the frequency of these assertions \nby selecting some fraction of them to perform. Methodology We compare three kinds of runs: asyn\u00adchronous \nassertions (with varying numbers of checking Normalized time 3 2 1 0 Number of checker threads threads), \nsynchronous assertions (stop and evaluate each assertion), and baseline (no assertions, no RVM modi.ca\u00adtions). \nOur primary measurement is overall application run\u00adtime.For asynchronous checks we also measure the number \nof objects copied during the run and the total number of bytes copied. Our system is GC-algorithm independent, \nand all experiments use the generational mark/sweep collector. For the microbenchmarks we run each test \n20 times and compute theaverage and con.dence interval.For theSPEC JBB experiments we run four iterations \nof the benchmark Figure 10. Ordered linked list: overhead versus number of and time the last iteration. \nThe differences we observe in checker threads for various list sizes. The checks are too runtimes between \nsynchronous and asynchronous checkingbrief to recoup the cost of synchronization and snapshotting. are \nso great that small perturbations in the execution do not affect our overall results. We .x the Java \nheap size to 120MB, which is approximately 2X the minimum. Normalized time 3 2 1 0 Number of checker \nthreads Figure 11. TreeMap (red-black tree): overhead versus num- All experiments were run on a 12-core \nmachine (dual six\u00adcore Xeon X5660 running at 2.8GHz) with 12GB of main memory running Ubuntu Linux kernel \n2.6.35. We limit the number of checker threads to 10, since we need1 or2 cores to run the application \nthreads.  5.2 Results: Microbenchmarks Eachrunof the microbenchmarkprogrambuilds oneof the two data \nstructures of a speci.c size and performs 1000 operations on it. Each operation is either an add,a remove, \nor an access. We perform the invariant checks before and after each add or remove. Operations are chosen \nat random so that 90% are accesses, 9% are adds, and 1% are removes. For each data structure, we ran \nexperiments with size berofcheckerthreadsforvarioustree sizes.Withmorethan 1,000, 10,000, 100,000 and \n1,000,000 elements. We varied .ve checker threads, asynchronous checks beat synchronous checks. SPEC \nJBB2000 SPEC JBB2000 [14] is a multithreaded benchmark that emulates a three-tier client-server system, \nwith the database replaced by an in-memory tree and clients replaced by driver threads. The system models \na company, with warehouses serving different districts and processing customer orders. In a single run, \nthe benchmark executes 70,000 transactions against its database. The runtime is 1.99 seconds in a completely \nunmodi.ed JikesRVM (no asser\u00adtions, no extra header words) running on our hardware. We added a synthetic \nassertion check on the main Com\u00adpanydata structure right before each transaction is processed (in TransactionManager.go()). \nThis synthetic asser\u00adtion allows us to systematically vary the frequency of asser\u00adtions and the amount \nof workperformed by each check. This assertion performs a bounded transitive closure on the object it \nis given, emulating a .xed amount of data structure traver\u00adthe numberof checkerthreadsfrom1 to12.Theresultsare \npresented in Figures 10 and 11. Time is normalized to the cost of the synchronous checks. We .nd that \nfor the list, the cost of the asynchronous mechanism (coordinating with the checker threads and building \nthe snapshots) overwhelms the relative simplicity of the computation. While performance improves with \nmore threads, we never signi.cantly improve upon synchronous checking.For theTreeMap, however, increasing \nthe number of threads improves performance substantially, particularly as the size of the data structure \nincreases.For all input sizes, we hit the break-even point at around .ve threads; using 12 threads reduces \nthe overhead of checking to within a small fraction of the baseline time for allbut the smallest input. \n 5.3 Results: SPEC JBB Our synthetic transitive closure assertion allows us to ex\u00adplore the performance \nspace of our technique by systemat\u00adically varying the assertion workload along two axes: fre\u00adquencyof \nchecks and cost of each check:  Perform 2800 checks Perform 2800 checks (zoom) 2.2 2  Normalized time \n1.2 2 1 1 Normalized time 1.8 1.6 1.4 Per-check cost (# objects traversed) Per-check cost (# objects \ntraversed) Figure 12. SPECJBB: Overhead of a .xed number (2800) of assertions for a range of costs, normalized \nto baseline (no assertions, unmodi.edRVM).Theoverheadof asynchronousevaluationgrowsslowlyaslongasthe \ncheckerthreadsis adequate for the assertion workload.Both graphs show the same data; right graph zooms \non the region where the threads are not saturated. Perform 5600 checks Perform 5600 checks (zoom) 2.2 \n 2 Normalized time Normalized time 1.2 4 2 1 1.8 1.6 1.4 Per-check cost (# objects traversed) Per-check \ncost (# objects traversed) Figure 13. SPECJBB: Overhead of a .xed number (5600) of assertions for a range \nof costs, normalized to baseline (no assertions, unmodi.edRVM). Leftgraphshowsall data;rightgraph highlightsthe \nunsaturatedregion(1Xto 2.2X). Frequency: We varythe number of checks from 700 per run (1 every100 transactions) \nto 21,000 per run (1 every 3 transactions).  Cost: We vary the cost by varying the fraction of the database \nthat each assertion traverses, measured in num\u00adber of objects visited from1 object to 30,000 objects. \n We run the program with synchronous checks and with asyn\u00adchronous checks using 2, 4, 6, 8, and 10 checker \nthreads. All times are normalized to the runtime of SPEC JBB with no assertions running on a completely \nunmodi.ed JikesRVM. This baseline run takes about about 1.99 seconds on our hardware con.guration. Because \nthese experiments gener\u00adate so much data we present slices in which we .x one axis of the workload (frequency \nor cost) and varythe other. Fix frequency, vary cost. Fig. 12 and Fig. 13 show the relative slowdown \nfor a .xed number of assertions (.xed frequency) over a range of assertion costs, comparing syn\u00adchronous \nchecking against asynchronous checking with2 to 10 threads. Each .gure consists of a pair of graphs of \nthe same data: the graph on the left shows all the data, the graph ontheright zoomsinonarangeoftheYaxisfrom1 \nto2.2. Both .gures show the same trends:  The overhead of synchronous checking grows veryrapidly as \nthe cost of the assertions (size of the traversal) in\u00adcreases from1 object to 30,000 objects.  The overhead \nof asynchronous checking grows relatively slowly until the checker threads become saturated, at which \npoint the overhead begins growing rapidly because the application must wait for an available checker \n the performance curve turns sharply up, with a slope similar to the synchronous con.guration.  With \na workload of 2800 assertions ( Fig. 12), 2 checker threads become saturated at an assertion cost of \n8000, while 4threads become saturated around 22,000.With 5600 asser\u00ad  Traverse 3000 objects per check \nTraverse 3000 objects per check (zoom) 2.2 2 Sync 2 threads 4 threads 6 threads 8 threads 10 threads \n      Figure 14. SPECJBB: Overhead of .xed-cost (traverse 3000 objects) assertions, over a range \nof assertion frequencies, normalizedto baseline(no assertions, unmodi.edRVM).Rightgraph zoomsinonthe \nunsaturatedregion(1Xto2.2X)       Sync 2 threads 4 threads 6 threads 8 threads 10 threads   \nNormalized time Normalized time 1.8 1.6 1.4 1.2 2 1 1 0 5000 10000 15000 20000 0 5000 10000 15000 20000 \nNumber of checks Number of checks Traverse 6000 objects per check Traverse 6000 objects per check (zoom) \n2.2 Sync 2 threads 4 threads 6 threads 8 threads 10 threads          Figure 15. SPECJBB: Overhead \nof .xed-cost (traverse 6000 objects) assertions, over a range of assertion frequencies, normalizedto \nbaseline(no assertions, unmodi.edRVM).Rightgraph zoomsinonthe unsaturatedregion(1Xto2.2X)      \n  Sync 2 threads 4 threads 6 threads 8 threads 10 threads   2 Normalized time Normalized time 1.8 \n1.6 1.4 4 1.2 2 1 0 5000 10000 15000 20000 0 5000 10000 15000 20000 Number of checks Number of checks \ntions(Fig. 13), all con.gurations eventually become satu\u00adrated when the cost of each assertion exceeds \n25,000 objects. The zoomed versions of these graphs (on the right) high\u00adlight the con.gurations where \nthe threads are not over\u00adloaded, and the main source of overhead is the snapshot mechanism. With 2800 \nassertions the overhead grows from lessthan10%toaround45%.With5600 assertionstheover\u00adhead grows from \n10% to 60% at the saturation point. Fix cost, vary frequency. Fig. 14 and Fig. 15 show the relative slowdown \nfor a .xed cost assertion (size of heap traversal) over a range of frequencies, comparing syn\u00adchronous \nchecking against asynchronous checking with2 to 10 threads. As above, each .gure consists of a pair of \ngraphs of the same data: the graph on the left shows all the data, the graph on the right zooms in on \na range of the Y axis from 1 to 2.2. These graphs show the same trends as the .xed-frequencygraphs: \n The overhead of synchronous checking grows veryrapidly as assertions become more frequent.  The overhead \nof asynchronous checking grows slowly as long as the checker threads can keep up with the rate of the \nassertions.  Witha 3000-object traversal( Fig. 14),2 checker threads become saturated at a frequency \nof 7000 assertions, while 4 threads become saturated around 15,000 assertions. With a 6000-object traversal(Fig. \n15), all con.gurations become saturated by the time we have 15,000 assertions, although 10 threads manage \ntokeep theoverhead under 80%. In the zoomed versions of these graphs (on the right), notice that increasing \nthe frequency of assertions causes overhead to grow more quickly than increasing the cost of each assertion \n(as shown in Fig. 12 and Fig. 13). The reason for this difference is that there is a per-assertion cost \nassociated with initiating and cleaning up a heap snapshot.  Perform 2800 checks Traverse 3000 objects \nper check 2.2  2 1.8 1.6 1.4 1.2 1 No sharing 4 threads Full 4 threads No sharing 10 threads Full 10 \nthreads          0 5000 10000 15000 20000 Per-check cost (# objects traversed) Number of checks \nPerform 2800 checks Traverse 3000 objects per check 2.2 2 1.8 1.6 1.4 1.2 1 Full 4 threads No snapshot \n4 threads Full 8 threads No snapshot 8 threads            0 5000 10000 15000 20000 Per-check \ncost (# objects traversed) Number of checks Effect of not sharing copies. One of the consequences of \nour snapshot algorithm is that in many cases multiple snaphots can share a single copy of an object. \nWhen an ob\u00adject is modi.ed, any assertion that started since the previ\u00adous modi.cation needs the same \nimage of that object. To measure the bene.t of this optimization we turned it off and compared this no-sharing \nversion to the full version of STROBE. Fig. 16 shows these results for a .xed frequency (2800 checks, \non the left) and a .xed cost (3000 object, on the right). As the assertion workload increases, the bene.t \nof sharing copies becomes signi.cant: sharing copies reduces overhead by 25% to 30% e.g., from an overhead \nof 70% (no sharing) to an overhead of 50% (with sharing). Lower bound: no snapshots. In order to explore \nthe lower bound of this technique we use a version of STROBEthat per\u00adforms asynchronous checking without \nheap snapshots. This version does not produce correct results (since assertions see the changing state \nof the heap), but allows us to eliminate the overhead of creating and maintaining snapshots. Fig. 17 \nshows the results for a .xed frequency(2800 checks, on the left) and a .xed cost (3000 object, on the \nright). Eliminat\u00ading the snapshot reduces the overhead signi.cantly, but not completely. We believe that \ntwo other factors contribute to overhead. First, we compare our system against a baseline that does not \ninclude extra header words eliminating these words reduces GC load. Second, asynchronous assertions \nplace additional demands on the machine s memorysystem, including the caches and memorybandwidth. Copying \ncosts and GC time. During each asynchronous run we count the total number of objects copied and the vol\u00adume \nin bytes for all snapshots. Fig. 18 shows the volume of bytes copied as a function of assertion frequency. \nThis cost ranges from 25,000 objects (2MB) for fast, infrequent checks up to 800,000 objects (70MB) for \nlong-running and frequent checks. Note that the graph .attens out as the num\u00adber of checks increases. \nThe reason is that under heavier as\u00adsertion workloads there are evaluations in-.ight at all times, so \nall writes to the heap are generating object copies.  Since object copying occurs in the write barrier \nin the application thread, it directly impacts overall runtime. In addition, the extra objects reside \nin the Java heap, increasing garbage collection time proportionally. On average, GC time increases by \n10% to 50% over synchronous evaluation. In our con.guration, however, GC time only accounts for 5% to \n10% of total runtime, so the impact is low. Under tighter memory constraints the extra memory used by \nsnapshots would likely have a bigger impact on runtime. In our lower bound experiment (described below) \nwe turned offsnapshots to measure this cost. 0 5000 10000 15000 20000 25000 Number of checks  6. Related \nWork Our workis related to a large body of previous work on pro\u00adgram checking. In this section, we brie.y \ndiscuss some of the related work on dynamic checking, usage of snapshots in concurrency, and other related \nruntime techniques such as futures, concurrentgarbage collection and software trans\u00adactions. No existing \ntechnique, however, supports complex dynamic checks evaluated at a speci.c point in the program with \nlow overhead and high accuracy. Future contracts Our work is closely related to recent work on future \ncontracts [7], a technique for concurrently checking behavioral software contracts in Scheme programs. \nThe authors propose (but only partially implement) a very different approach for handling mutations in \nthe store. They view a write by the main thread as a kind of synchronization, which blocks until the \nchecking thread has had a chance to read the old value (in effect, blocking the main thread un\u00adtil the \ncheck completes). This approach is unlikely to per\u00adform well for imperative languages, where mutations \nare frequent. Our approach is to copy the old state, allowing the main thread and the checker thread \nto proceed without blocking. Our infrastructure could be used for a more com\u00adplete, high-performance \nimplementation of future contracts that supports imperative languages, avoids unnecessarysyn\u00adchronization, \nand supports multiple concurrent assertions. Dynamic program checking Dynamic analysis avoids the main \nproblem with static analysis: by performing error checks on the actual concrete heap of a running program, \nit does not have to make conservative assumptions about potential program state. Our system addresses \nthe primary challenge of dynamic checking: runtime overhead. There are a number of existing approaches \nfor reducing the cost of dynamic checks. These techniques are orthogonal to ours, however: anyof them \ncould be combined with our system to obtain the bene.ts of both. The Ditto system speeds up invariant \nchecking by au\u00adtomatically incrementalizing the checking code [13]. The incremental checks are still \nquite expensive, however, and since they are run synchronously, signi.cantly slow program execution. \nThe QVM system provides a number of heap probes to check data structures, and manages the cost by re\u00adducing \nthe frequency of checking [2]. The Phalanx system attempts to reduce the cost of assertion checking by \nparal\u00adlelizing the queries. In both QVM and Phalanx, the queries are evaluated synchronously with respect \nto the application. Recent work has explored the idea of piggybacking heap checks on the garbage collector. \nIn the work by Aftandil\u00adian et al, [1], assertions are evaluated synchronously at a regularly scheduledgarbage \ncollection. Subsequentworkby Reichenbach et. al [12] investigates the class of assertions that can be \ncomputed with the same complexity as garbage collection. The two main limitations of this technique are \n(a) the kinds of checks it supports are limited by the GC algo\u00adrithm (in particular, the single-touch \nproperty), and (b) the frequency of checks is limited because they are evaluated only when a collection \noccurs. Concurrent program checking The SuperPin system [17] provides some of the same capabilities as \nours but through a completely different mechanism. SuperPin uses the fork system call to create a consistent \nsnapshot, which it uses to run an instrumented copyof the main program. As with other previous work, \nhowever, this system is focused on relatively low-level program analysis added as binaryinstrumentation, \nand performance is still too slow for production use (100\u00ad500% slowdown). Speck [11],FastTrack [10], \nandParExC [15] are all spec\u00adulativeexecution systems. Speck andParExC focus onlow\u00adlevel runtime checks \nsuch as array out-of-bounds and pointer deference checks.FastTrack enables speculative unsafe op\u00adtimizations, \nwhose correctness it checks by the unoptimized program on multiple processors. None of these systems \nare designed to check the high-level program properties we are interested in. Safe Futures for Java [18] \nprovides a safe implementa\u00adtion of futures in Java. They handle concurrency issues be\u00adtween the main \nprogram and the futures via many of the same mechanisms as our work: read and write barriers and objectversioning.However, \ntheir system does notworkwith multithreaded programs, and because their futures can write to the heap, \nthey must use a read barrier for all memory ac\u00adcesses. Our assertions cannot write to objects in the \nsnap\u00adshot, so we can avoid a read barrier in the program code and achieve better performance.  Transactional \nmemory Recently, there has been signi.\u00adcant amountofwork ontransactional memory [8].Inprin\u00adciple, it \nis possible to treat each assertion evaluation as a separate transaction, and let the STM detect con.ict. \nHow\u00adever, the problem with this approach would be that either the assertion or the program would be rolled \nback every time a con.ict occurs, which is highly likely for long-running as\u00adsertions that may touch \nlarge portions of the heap. Frequent rollbacks would render the system unusable (and restarting the application \nhas its own issues when it comes to side ef\u00adfects such as exceptions and I/O). Further, with our seman\u00adtics, \nrollbacks are unnecessary, as the assertion only needs to compute a result with respect to the state \nin which it was triggered. Concurrent Programming Models Recently, there has been an increased interest \nin new concurrent programming models [3, 6]. Essentially, in these models, revisions are used to ensure \nthat each process operates on its own local snapshot. When processes complete, their local snapshot changes \nare merged into the global state, or if their changes con.ict (i.e., if they modify the same memory location), \nei\u00adther a con.ict is declared and the program aborts [3] or in the case of more advanced con.ict resolution \nstrategies, the programmer can provide a merge function which is used to resolve these con.icts [6]. \nWe can think of our asyn\u00adchronous assertion model as a restricted form of concurrent revisions where \nthe asynchronous processes (the assertions) do not modify the heap and hence there is no need to perform \ncon.ict checking. Snapshot-based concurrent garbage collectors Copy-on\u00adwrite techniques for obtaining \nsnapshots have seen exten\u00adsive use in mark-and-sweep, snapshot-at-the-beginning con\u00adcurrent garbage collectors, \ni.e., [4, 5, 9, 16, 19]. Once the garbage collector starts working, it computes all reachable nodes in \nthe heap at the time the collector started by oper\u00adating on a snapshot maintained by a write barrier, \nas in our system. There are a few basic technical differences between snapshot collectors and this work. \nFirst, there is no need for multiple garbage collectors to be running at the same time computing the \nsame information. Usually, a new collector cycle is started after the previous one has ended.In contrast, \nit is sensible to have multiple assertions at the same time, and hence our system must support this scenario. \nSecond, collectors are computing a speci.c property: transitive clo\u00adsure from a set of roots. In our \ncase, each snapshot can be used to compute completely different assertions. Third, with concurrent collectors, \nthe program needs to intercept only heap reference modi.cations, while in our case, depending on whether \nthe assertion accesses primitive values in the heap, it may be desirable to snapshot their modi.cation \nas well.  7. Conclusions Assertions are a powerful and convenient tool for detecting bugs,buthavealways \nbeen limitedby thefact that the check\u00ading cost is paid for in application runtime. In this paper we show \nhow assertions can be checked asynchronously, greatly reducing checking overhead. Our technique enables \na much wider range of assertions, including complex heap checks and data structure invariants. We believe \nthat this approach will become even more appealing as modern processors con\u00adtinue to add CPU cores, providing \nample additional comput\u00ading power that can be devoted to making software run more reliably.  Acknowledgments \nThis work is supported by the National Science Foundation under grant CCF-1018038 and by IBM. Opinions, \ninterpre\u00adtations, conclusions, and recommendations expressed in this material are those of the authors \nand do not necessarily re\u00ad.ect those of the sponsors.  References [1] E. Aftandilian and S. Z. Guyer. \nGC Assertions: Using the Garbage Collector to Check Heap Properties. In ACM Con\u00adference onProgramming \nLanguages Design andImplementa\u00adtion, pages 235 244, 2009. [2] M. Arnold, M. Vechev, and E. Yahav. QVM: \nAn Ef.cient Runtime for Detecting Defects in Deployed Systems. In ACM Conference on Object-Oriented Programming \nSystems, Languages, and Applications, pages 143 162, 2008. [3] A.Aviram, S.-C.Weng, S.Hu, andB.Ford. \nEf.cient System-Enforced Deterministic Parallelism. In Proceedings of the 9th USENIX Conference on Operating \nSystems Design and Implementation, pages 1 16, 2010. [4] H. Azatchi, Y. Levanoni, H. Paz, and E. Petrank. \nAn On\u00adthe-.y Mark and Sweep Garbage Collector Based on Sliding Views. InACMConference on Object-OrientedProgramming \nSystems, Languages, and Applications, pages 269 281, 2003. [5]D.F.Bacon,P. Cheng, andV.T.Rajan.AReal-time \nGarbage Collector with Low Overhead and Consistent Utilization. In ACM Symposium on the Principles of \nProgramming Lan\u00adguages, pages 285 298, 2003. [6] S. Burckhardt, A. Baldassin, and D. Leijen. Concurrent \nProgramming with Revisions and Isolation Types. In ACM Conference on Object-Oriented Programming Systems, \nLan\u00adguages, and Applications, pages 691 707, 2010. [7] C.Dimoulas,R.Pucella, andM. Felleisen. Future \nContracts. In Proceedings of the 11th ACM SIGPLAN Conference on Principles and Practice of Declarative \nProgramming, pages 195 206, 2009.  [8]T.Harris,J. Larus, andR.Rajwar. TransactionalMemory, 2nd edition.Morgan \nandClaypoolPublishers, 2010. [9] R. Jones and R. Lins. Garbage Collection. John Wiley and Sons, 1996. \n[10]K.Kelsey,T.Bai,C.Ding, andC. Zhang.FastTrack:ASoft\u00adware System for SpeculativeProgram Optimization. \nIn Inter\u00adnational Symposium on Code Generation and Optimization, pages 157 168, 2009. [11] E. B. Nightingale, \nD. Peek, P. M. Chen, and J. Flinn. Par\u00adallelizing security checks on commodity hardware. In ACM Conference \non Architectural Support for Programming Lan\u00adguages and Operating Systems, pages 308 318, 2008. [12] \nC. Reichenbach, N. Immerman, Y. Smaragdakis, E. E. Af\u00adtandilian, and S. Z. Guyer. What Can the GC Compute \nEf\u00ad.ciently?: A Language for Heap Assertions at GC Time. In ACM Conference on Object-Oriented Programming \nSystems, Languages, and Applications, pages 256 269, 2010. [13] A. Shankar and R. Bod\u00b4ik. DITTO: Automatic \nIncremental\u00adizationofData StructureInvariant Checks(inJava).In ACM Conference on Programming Languages \nDesign and Imple\u00admentation, pages 310 319, 2007. [14] SPECjbb2000 Documentation. StandardPerformance \nEvalu\u00adation Corporation, release 1.01 edition, 2001. [15] M.S \u00a8usskraut, S.Weigert, U. Schiffel,T.Knauth,M. \nNowack, D.B.Brum, andC. Fetzer. Speculation forParallelizingRun\u00adtime Checks. In Proceedings of the 11th \nInternational Sym\u00adposium on Stabilization, Safety, and Security of Distributed Systems, pages 698 710, \n2009. [16] M. T. Vechev, E. Yahav, and D. F. Bacon. Correctness-Preserving Derivation of Concurrent Garbage \nCollection Al\u00adgorithms. In ACM Conference on Programming Languages Design andImplementation, pages 341 \n353, 2006. [17] S. Wallace and K. Hazelwood. SuperPin: Parallelizing Dy\u00adnamic Instrumentation for Real-Time \nPerformance. In Inter\u00adnational Symposium on Code Generation and Optimization, pages 209 220, 2007. [18] \nA. Welc, S. Jagannathan, and A. Hosking. Safe futures for Java. In ACM Conference on Object-Oriented \nProgramming Systems, Languages, and Applications, pages 439 453, 2005. [19] T. Yuasa. Real-time garbage \ncollection on general-purpose machines. Journal of Systems and Software, 11(3):181 198, 1990.  \n\t\t\t", "proc_id": "2048066", "abstract": "<p>Assertions are a familiar and widely used bug detection technique. Traditional assertion checking, however, is performed synchronously, imposing its full cost on the runtime of the program. As a result, many useful kinds of checks, such as data structure invariants and heap analyses, are impractical because they lead to extreme slowdowns. We present a solution that decouples assertion evaluation from program execution: assertions are checked asynchronously by separate checking threads while the program continues to execute. Our technique guarantees that asynchronous evaluation always produces the same result as synchronous evaluation, even if the program concurrently modifies the program state. The checking threads evaluate each assertion on a consistent snapshot of the program state as it existed at the moment the assertion started.</p> <p>We implemented our technique in a system called Strobe, which supports asynchronous assertion checking in both single-and multi-threaded Java applications. Strobe runs inside the Java virtual machine and uses copy-on-write to construct snapshots incrementally, on-the-fly. Our system includes all necessary synchronization to support multiple concurrent checking threads, and to prevent data races with the main program threads. We find that asynchronous checking significantly outperforms synchronous checking, incurring tolerable overheads -- in the range of 10% to 50% over no checking at all -- even for heavy-weight assertions that would otherwise result in crushing slowdowns.</p>", "authors": [{"name": "Edward E. Aftandilian", "author_profile_id": "81350584830", "affiliation": "Tufts University and Google, Mountain View, CA, USA", "person_id": "P2839180", "email_address": "eaftan@cs.tufts.edu", "orcid_id": ""}, {"name": "Samuel Z. Guyer", "author_profile_id": "81332502517", "affiliation": "Tufts University, Medford, MA, USA", "person_id": "P2839181", "email_address": "sguyer@cs.tufts.edu", "orcid_id": ""}, {"name": "Martin Vechev", "author_profile_id": "81100269652", "affiliation": "ETH Zurich and IBM Research, Zurich, Switzerland", "person_id": "P2839182", "email_address": "martin.vechev@gmail.com", "orcid_id": ""}, {"name": "Eran Yahav", "author_profile_id": "81100285431", "affiliation": "Computer Science, Haifa, Israel", "person_id": "P2839183", "email_address": "yahave@cs.technion.ac.il", "orcid_id": ""}], "doi_number": "10.1145/2048066.2048090", "year": "2011", "article_id": "2048090", "conference": "OOPSLA", "title": "Asynchronous assertions", "url": "http://dl.acm.org/citation.cfm?id=2048090"}