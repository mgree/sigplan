{"article_publication_date": "10-22-2011", "fulltext": "\n JIT Compilation Policy for Modern Machines Prasad A.Kulkarni Department of Electrical Engineering and \nComputer Science, University of Kansas prasadk@ku.edu Abstract Dynamic or Just-in-Time (JIT) compilation \nis crucial to achieve acceptable performance for applications (written in managed languages, such as \nJava and C#) distributed as intermediate language binary codes for a virtual machine (VM) architecture. \nSince it occurs at runtime, JIT compila\u00adtion needs to carefully tune its compilation policy to make effective \ndecisions regarding if and when to compile dif\u00adferent program regions to achieve the best overall program \nperformance. Past research has extensively tuned JIT com\u00adpilation policies,but mainly for VMs witha single \ncompiler thread and for execution on single-processor machines. This work is driven by the need to explore \nthe most effec\u00adtive JIT compilation strategies in their modern operational environment, where (a) processors \nhave evolved from single to multi/many cores, and (b) VMs provide support for mul\u00adtiple concurrent compiler \nthreads. Our results con.rm that changing if and when methods are compiled have signi.\u00adcant performance \nimpacts. We construct several novel con\u00ad.gurations in the HotSpot JVM to facilitate this study. The new \ncon.gurations are necessitated by modern Java bench\u00admarks that impede traditional static whole-program \ndiscov\u00adery, analysis and annotation, and are required for simulating future many-core hardware that is \nnot yet widely available. We study the effects on performance of increasing compiler aggressiveness for \nVMs with multiple compiler threads run\u00adning on existing single/multi-core and future many-core ma\u00adchines. \nOur results indicate that although more aggressive JIT compilation policies show no bene.ts on single-core \nma\u00adchines, these can often improve program performance for multi/many-core machines. However, accurately \nprioritizing JIT method compilations is crucial to realize such bene.ts. Permission to make digital or \nhard copies of all or part of this work for personal or classroomuseisgrantedwithout feeprovidedthat \ncopies arenot madeordistributed forpro.torcommercialadvantage andthatcopiesbearthisnoticeandthefullcitation \nonthe .rstpage.To copy otherwise,to republish,topostonserversorto redistribute tolists, requirespriorspeci.cpermission \nand/ora fee. OOPSLA 11, October22 27,2011, Portland,Oregon,USA. Copyright c &#38;#169; 2011ACM978-1-4503-0940-0/11/10. \n. .$10.00 Categories and Subject Descriptors D.3.4[Programming Languages]: Processors Optimizations, \nRun-time environ\u00adments, Compilers General Terms Languages, Performance Keywords virtual machines, dynamic \ncompilation, multi\u00adcore, Java 1. Introduction Managed languages such as Java [11] and C# [26] support \nthe compile-once, run-anywhere model for code genera\u00adtion and distribution. This model allows the generation \nof programs that can be portably distributed and executed on anydevice equipped with the corresponding \nvirtual machine (VM). The portability constraint limits the format of the dis\u00adtributed program to a form \nthat is independent of any spe\u00adci.c processor architecture. Since the program binary format does not \nmatch the native architecture, VMs have to employ either interpretation or dynamic compilation before \nexecut\u00ading the program. However, interpreted execution is inher\u00adently slow, which makes dynamic or Just-in-Time \n(JIT) com\u00adpilation essential to achieve ef.cient runtime performance for such applications. By operating \nat runtime, JIT compilation contributes to the overall execution time of the application and, if per\u00adformed \ninjudiciously, may result in further worsening the execution or response time of the program. Therefore, \nJIT compilation policies need to carefully tune if and when dif\u00adferent program regions are compiled to \nachieve the best pro\u00adgram performance. In addition to if and when, how to com\u00adpile program regions is \nalso an important component of any compilation policy. However, in contrast to the previous two components, \nthe issue of how to compile program regions is not unique to dynamic compilation, as can be attested \nby the presence of multiple optimization levels in GCC, and the wide body of research in pro.le-driven \ncompilation [8, 12] and optimization phase ordering/selection [15, 33] for static compilers. Also, the \ndefault OpenJDK HotSpot VM used in our experiments only supports a single compilation level. Consequently, \nwe do not consider the issue of how to com\u00adpile anyfurther in this work. The technique of selective compilation \nwas invented by researchers to address the issues of if and when to com\u00adpile program methods during dynamic \ncompilation [4, 18, 24, 28]. However, research on JIT compilation policies em\u00adploying the above theories \nhave primarily been conducted on single-processor machines and for VMs with a single com\u00adpiler thread. \nAs a result, existing JIT compilation policies that attempt to improve program ef.ciency while minimiz\u00ading \napplication pause times and interference are typically quite conservative.  Recent years have witnessed \na major paradigm shift in microprocessor design from high-clock frequency single\u00adcore machines to processors \nthat now integrate multiple cores on a single chip. Moreover, hardware researchers and processor manufacturers \nexpect to continuously scale the number of cores available in future processor genera\u00adtions [1]. Thus, \nmodern architectures allow the possibility of running the compiler thread(s) on a separate core(s) to \nmin\u00adimize interference with the application thread. Virtual ma\u00adchine developers are also responding to \nthis change in their hardware environment by making the compiler thread-safe, and allowing the user to \nsimultaneously initiate multiple concurrent compiler threads. Such evolution in the hardware and VM contexts \nmay demand radically different JIT compi\u00adlation policies to achieve the most effective overall program \nperformance. Consequently, the objective of this research is to investi\u00adgate and develop new JIT compilation \nstrategies to realize the best performance on existing single/multi-core proces\u00adsors and future many-core \nmachines for VMs with multiple compiler threads. Unfortunately, experimental constraints makeitdif.cultto \nreadily achieve this objective.Forexam\u00adple, one constraint is imposed by modern Java benchmarks that \nimpede static whole program discovery and analysis. Also, the commonly heralded many-core machines are \nnot widely available just yet. We overcome such constraints by designing and constructing novel VM experimental \ncon.g\u00adurations to conduct this work. We induce continuous pro\u00adgressive increases in the aggressiveness \nof JIT compilation strategies, as well as in the number of concurrent compiler threads and analyze their \neffect on average program perfor\u00admance. Thus, the major contributions of this research work are the following: \n1. We present the novel VM con.gurations we develop to overcome the constraints imposed by modern Java \nbench\u00admarks and unavailable many-core hardware during our exploration of effective JIT compilation policies. \n2.We quantify the impactof altering if and when meth\u00adods are compiled on application performance. 3. \nWe demonstrate the effect of multiple compiler threads on average program performance for single-core \nma\u00adchines. 4. We explain the impact of different JIT compilation strate\u00adgies on available multi-core \nand future many-core ma\u00adchines.  5. We identify and show the bene.t of prioritizing method compiles \non program performance with different JIT compilation policies for modern hardware. The rest of the paper \nis organized as follows. In the next section, we present background information and related work regarding \nexisting JIT compilation policies. We de\u00adscribe our benchmark suite and general experimental setup in \nSection 3. In Section 4, we validate the impact of varying if and when methods are compiled on program \nperfor\u00admance. Our experiments exploring different JIT compilation strategies for VMs with multiple compiler \nthreads on single\u00adcore machines are described in Section 5. In Section 6, we present results that explore \nthe most effective JIT policies for multi-core machines.We describe the resultsof our novel experimental \ncon.guration to study compilation policies for future many-core machinesin Section7.Weexplain the im\u00adpact \nof prioritizing method compiles in Section 8. Finally, we describe avenues for future work and present \nour conclu\u00adsions from this study in Sections9 and 10 respectively.  2. Background and RelatedWork Several \nresearchers have explored the effects of conducting compilation at runtime on overall program performance \nand application pause times. The ParcPlace Smalltalk VM [9] followed by the Self-93 VM [18] pioneered \nmany of the adaptive optimization techniques employed in current vir\u00adtual machines, including selective \ncompilation with multi\u00adple compiler threads on single-core machines.For such ma\u00adchines, the total program \nrun-time includes the application run-time as well as the compilation time. Therefore, aggres\u00adsive compilations \nhave the potential of degrading program performance by increasing the compilation time. The tech\u00adnique \nof selective compilation was invented by researchers to address this issue with dynamic compilation [4, \n18, 24, 28]. This technique is based on the observation that most applications spend a large majority \nof their execution time in a small portion of the code [4, 7, 20]. Selective compila\u00adtion uses online \npro.ling to detect this subset of hot meth\u00adods to compile at program startup, and thus limits the over\u00adhead \nof JIT compilation while still deriving the most perfor\u00admance bene.t at runtime. Most current VMs employ \nselec\u00adtive compilation with a staged emulation model [16]. With this model, each method is initially \ninterpreted or compiled with a fast non-optimizing compiler at program start to im\u00adprove application \nresponse time. Later, the virtual machine attempts to determine the subset of hot methods to selec\u00adtively \ncompile, and then compiles them at higher levels of optimization to achieve better program performance. \nUnfortunately, selecting the hot methods to compile re\u00adquires future program execution information, which \nis hard to accurately predict [27]. In the absence of anybetter strat\u00adegy, most existing JIT compilers \nemploy a simple predic\u00adtion model that estimates that frequently executed current hot methods will also \nremain hot in the future [2, 13, 21].  Online pro.ling is used to detect these current hot methods. \nThe most popular online pro.ling approaches are based on instrumentation counters [16, 18, 21], interrupt-timer-based \nsampling [2], or a combination of the two methods [13]. Pro\u00ad.ling using counters requires the virtual \nmachine to count the number of invocations and loop back-edges for each method. Sampling is used to periodically \ninterrupt the ap\u00adplication execution and update a counter for the method(s) on top of the stack. The \nmethod/loop is sent for compilation if the respective method counters exceed a .xed threshold. Finding \nthe correct threshold value for each compilation stage is crucial to achieve good startup performance \nfor ap\u00adplications running in a virtual machine. Setting a higher than ideal compilation threshold may \ncause the virtual machine to be too conservative in sending methods for compilation, reducing program \nperformance by denying hot methods a chance for optimization. In contrast, a compiler with a very low \ncompilation threshold may compile too many methods, increasing compilation overhead. High compilation \nover\u00adhead may negatively impact overall program performance on single-core machines. Therefore, most \nperformance-aware JIT compilers experiment with many different threshold values for each compiler stage \nto determine the one that achieves the best performance over a large benchmark suite. The theoretical \nbasis for tuning compiler thresholds is provided by the ski-renting principle [10, 19], which states \nthat to minimize the worst-case damage of online compila\u00adtion, a method should only be compiled after \nit has been in\u00adterpreted a suf.cient number of times so as to already offset the compilation overhead \n[27]. By this principle, a (slower) compiler with more/better optimization phases will require a higher \ncompilation threshold to achieve the best overall pro\u00adgram performance in a virtual machine. Resource \nconstraints force existing JIT compilation poli\u00adcies to make several tradeoffs regarding which methods \nare compiled/optimized at what stage of program execution. Thus, selective compilation is employed to \nlimit the total time spent by the compiler thread at the cost of potentially lower application thread \nperformance. Additionally, online pro.ling (used to select hot methods to compile) causes de\u00adlays in \nmaking the compilation decisions at program startup. The .rst component of this delay is caused by the \nVM wait\u00ading for the method counters to reach the compilation thresh\u00adold before deeming the method as \nhot and queuing it for compilation. The secondfactor contributing to the compila\u00adtion delay occurs as \neach compilation request waits in the compiler queue to be serviced by a free compiler thread. Restricting \nmethod compiles and the delay in optimizing hot methods results in poor application startup performance \nas the program spends more time executing in unoptimized code [14, 22, 25]. Researchers have suggested \nstrategies to address the .rst delay component for online pro.ling. Krintz and Calder ex\u00adplored mechanisms \nthat employ of.ine pro.ling and class\u00ad.le annotation to send hot methods to compile early [22, 23]. However, \nsuch mechanisms require an additional pro.ling pass, and are therefore not generally applicable. Namjoshi \nand Kulkarni propose a technique that can dynamically de\u00adtermine loop iteration bounds to predict future \nhot meth\u00adods and send them to compile earlier [27]. Their suggested implementation requires additional \ncomputational resources to run their more expensive pro.ling stage. Gu and Ver\u00adbruggee use online phase \ndetection to more accurately es\u00adtimate recompilation levels for different hot methods to save redundant \ncompilation overheads and produce better code faster [14]. Researchers have also explored techniques \nto address the second component of the compilation delay that happens due to the backup and wait time \nin the method compila\u00adtion queue. IBM s J9 virtual machine uses thread priorities to increase the priority \nof the compiler thread on operat\u00ading systems, such as AIX and Windows, that provide sup\u00adport for user-level \nthread priorities [31]. Another technique attempts to increase the CPU utilization for the compiler thread \nto providefaster service to the queued compilation re\u00adquests [17, 25]. However, the proposed thread-priority \nbased implementations for these approaches can be dif.cult to pro\u00advide in all existing operating systems. \nJikes RVM provides a priority-queue implementation to reduce the delay for the hotter methods,but this \nstudy onlyevaluates their one strat\u00adegy on single-core machines [3]. Most relevant to our work is the \nfact that the studies de\u00adscribed above have been typically targeted for single-core machines. There exist \nvery few studies that explore JIT com\u00adpilation issues for multi-core machines. Krintz et al. inves\u00adtigated \nthe impact of background compilation in a separate thread to reduce the overhead of dynamic compilation \n[24]. However, this technique uses a single compiler thread and also employs of.ine pro.ling to determine \nand prioritize hot methods to compile. Kulkarni et al. brie.y discuss per\u00adforming parallel compilation \non multiple compiler threads to exploit the additional processing resources available on multi-core machines, \nbut do not provide any experimen\u00adtal results [25]. A few existing virtual machines, such as Sun s HotSpot \nserver VM [28] and the Azul VM (derived from HotSpot), support multiple compiler threads,butdo not present \nany discussions on ideal compilation strategies for multi-core machines. Consequently, research is sorely \nlack\u00ading in understanding dynamic compilation issues and evalu\u00adating potential JIT compilation strategies \nin the presence of multiple compiler threads on current and future multi-core and many-core machines. \nIn this paper, we investigate issues for dynamic compilation on modern machines and compare potential \nstrategies with existing techniques.  3. Experimental Framework The research presented in this paper \nis performed using the server version of the Sun/Oracle s HotSpot java virtual  SPECjvm98 SPECjvm2008 \nDaCapo-9.12-bach Name #Methods Name #Methods Name #Methods 201 compress 100 201 compress 10 202 jess \n100 202 jess 10 205 raytrace 100 205 raytrace 10 209 db 100 209 db 10 213 javac 100 213 javac 10 222 \nmpegaudio 100 222 mpegaudio 10 227 mtrt 100 227 mtrt 10 228 jack 100 228 jack 10 517 514 778 759 657 \n639 512 515 1239 1211 659 674 658 666 736 734 compiler.compiler compiler.sun.ow compress crypto.aes crypto.rsa \ncrypto.signverify mpegaudio scimark.fft.small scimark.lu.small scimark.monte carlo scimark.sor.small \nscimark.sparse.small serial sun.ow xml.transform xml.validation 3195 avrora default 3082 avrora small \n960 batik default 1186 batik small 960 eclipse default 1042 eclipse small 959 fop default 859 fop small \n735 h2 default 707 h2 small 715 jython default 717 jython small 1121 luindex default 2015 luindex small \n2592 lusearch default 1794 lusearch small pmd default pmd small sun.ow default sun.ow small tomcat default \ntomcat small xalan default xalan small 1849 1844 4366 3747 11145 5461 4245 4601 2154 2142 3547 2070 1689 \n1425 1192 1303 3881 3058 1874 1826 9286 9189 2296 2277 Table 1. Benchmarks used in our experiments machines \n(build 1.7.0-ea-b24) [28]. The latest development code for the HotSpot VM is available through Sun s \nOpen-JDK initiative. The HotSpot VM uses interpretation at the start of program execution. It then employs \na counter-based pro.ling mechanism, and uses the sum of a method s invo\u00adcation and loop back-edge counters \nto detect and promote hot methods for compilation.We call the sum of these coun\u00adters as the execution \ncount of the method. Methods/loops are determined to be hot if the corresponding method execu\u00adtion count \nexceeds a .xed threshold. The tasks of detecting hot methods and dispatching them for compilation are \nper\u00adformed at every method call (for whole-method compiles) and loop iteration (for on-stack-replacement \ncompiles). The HotSpot server VM allows the creation of an arbitrary num\u00adber of compiler threads, as \nspeci.ed on the command-line. The experiments in this paper were conducted using all the benchmarks from \nthree different benchmark suites, SPEC jvm98 [30], SPEC jvm2008 (startup) [29] and DaCapo\u00ad9.12-bach [5]. \nWe employ two inputs (10 and 100) for benchmarks in the SPECjvm98 suite, two inputs (small and default) \nfor the DaCapo benchmarks, and a single input (startup) for benchmarks in the SPECjvm2008 suite, result\u00ading \nin 56 benchmark/input pairs.Two benchmarks from the DaCapo benchmark suite, tradebeans and tradesoap, \ndid not always run correctly with the default version of the HotSpot VM, so these benchmarks were excluded \nfrom our set. Ta\u00adble1 lists the name and the number of invoked methods for each benchmark in our suite. \nAll our experiments were performed on a cluster of 8-core Intel Xeon 2.833GHz processors. All machines \nuse Fedora Linux as the operating system. We disable seven of the eight available cores (including hyperthreading) \nto run our single-core experiments. Our multi-core experiments utilize all available cores (without hyperthreading). \nMore speci.c variations made to the hardware con.guration are explained in the respective sections. Each \nbenchmark is run in isolation to prevent interference from other user programs. Finally, to account for \ninherent timing variations during the benchmark runs, all the performance results in this paper report \nthe average over 10 runs for each benchmark-con.guration pair.  4. Tradeoffs of If and When to Compile \nExisting JIT compilation policies tuned for single-core ma\u00adchines limit the number of methods compiled \nto reduce the time spent doing compilations, while achieving the best overall program performance. Additionally, \nthe process of .nding the set of hot methods to compile and the time spent by such methods in the compiler \nqueue due to possible queue back-ups further delays compilations. Thus, although com\u00adpiling/optimizing \nall program methods at their earliest op\u00adportunity can likely allow more ef.cient application thread \nexecution, existing JIT compilation policies bound by re\u00ad  (a) (b) Figure 1. Understanding the effect \nof(if to perform) JIT compilation on program performance. source constraints cannot achieve this ideal. \nThe recent and future availability of more abundant computing resources can enable more aggressive JIT \ncompilation policies and im\u00adprove application performance. However, before exploring new policies, in \nthis section we .rst attempt to quantify the potential bene.t of compiling more program methods early. \nWe develop a unique VM framework to conduct our ex\u00adperiments in this section. This framework provides \ntwo com\u00adplementary capabilities. From the VM s point of view, our framework enables the VM to ef.ciently \ndetect important program points as they are reached during execution. At the same time, from the executing \nprogram s point of view, it allows the program running within the virtual machine to call-on the enclosing \nVM to perform certain tasks at speci.c points during execution. Our framework employs Soot [32] to annotate \nspeci.c user-de.ned program points statically. Currently, we only allow annotations at the level of individ\u00adual \nmethods. Our updated VM is able to detect these an\u00adnotations on every such method invocation and perform \nthe desired actions. Of course, we also need to implement the support to perform these actions in our \nmodi.ed VM. We found this capability to be extremely useful in several stud\u00adies throughout this work. \n 4.1 Bene.t of Dynamic Compilation(If to Compile?) Executing native code (produced by compilation/optimization \nin a JVM) has been observed in earlier works to be much more ef.cient than interpreted execution. Therefore, \nincreas\u00ading the fraction of compiled code is likely to result in more ef.cient program execution. However, \nnot all methods con\u00adtribute equally to performance improvement. Selective com\u00adpilation in existing VMs \nexploits this observation to com\u00adpile the most frequently executed program sections that are expected \nto produce the most performance bene.t. Thus, any additional compilation may only produce diminishing \nreturns. In this section we attempt to quantify the bene.t of more aggressive compilation that may be \nenabled by modern machines.We accomplish this goalby studying theeffectof varying the selective compilation \nthreshold on steady-state program performance. The VM compiles all methods with execution counts that \nexceed the selected threshold. The har\u00adness of all our benchmark suites allows each benchmark to be iterated \nmultiple times in the same VM run. We dis\u00adable background compilation to force all hot methods to be \ncompiled in the .rst iteration itself. The execution time of the .fth benchmark iteration is measured \nas its steady-state time. Thus, the steady-state con.guration ignores the compi\u00adlation overhead allowing \nus to explore the best-case scenario where the presence of abundant hardware resources causes compilations \nto be effectively free.We are notaware of any previous study to investigate the goals as stated here. \nOur experimental con.guration conducts an initial of.ine run to collect method execution counts for every \nbenchmark in our set.For each benchmark, the following measurement run executes the program over several \nstages, with a few pro\u00adgram iterations per stage, in a single VM run. Each succes\u00adsive stage in our modi.ed \nHotSpot VM lowers the compi\u00adlation threshold and compiles additional methods (over the previous stage) \nwith of.ine execution counts that exceed the new lower threshold.We employ our new VM capability de\u00adscribed \nearlier to enable the VM to detect the start of ev\u00adery benchmark iteration during the same VM run. The \nVM uses this detection to determine the end of the current stage, collect steady-state performance numbers \nfor that stage, and then release the additional program methods for compila\u00adtion to start the next stage. \nThus, the .rst stage compiles no methods, and all methods are compiled by the .nal stage in a single \nVM run. Each intermediate stage compiles succes\u00adsively more program methods. Each stage consists of suf.\u00adcient \nnumber of program iterations to compile all released methods. The .nal iteration in each stage performs \nno com\u00adpilations and provides a measure of the benchmark perfor\u00admance at the end of that stage. Figure \n1(a) shows the average improvement in program performance compared to interpreted execution averaged \nover all our benchmarks. The X-axis indicates the compile threshold used at each stage. At every stage, \nmethods that have an of.ine execution count greater than the stage com\u00adFigure 2. Performance bene.t of \ncompiling thesame set of hot methods early. The default threshold is 10,000.  pile threshold are sent \nfor compilation. Figure 1(b) shows the percentage of methods compiled at each stage, averaged over all \n56 benchmark-input pairs in our set. Thus, we can see that JIT compilation of all program methods achieves \na dramatic performance improvement over interpretation, achieving program execution in about 9% of the \ninterpreta\u00adtion time, on average. As expected, most of the performance gain is obtained by compiling \na very small fraction of the total executed methods. Indeed, the default HotSpot VM se\u00adlective compilation \nthreshold of 10,000 results in compiling about 15% of the methods and reduces execution time to around \n13% of interpretation time. Moreover, it is important to note that although the added performance improvement \nof compiling all program methods does not seem signi.\u00adcant compared to interpretation time, it results \nin over 30% more ef.cient program execution compared to the default VM con.guration (with threshold 10,000) \nas the baseline.  4.2 Bene.t of Early Compilation(When to Compile?) Several researchers have made the \nobservation that compil\u00ading methods early improves program ef.ciency since the program execution spends \nless time in interpreted or unop\u00adtimized code [14, 27]. In this section we report the bene\u00ad.t in average \napplication performance for our benchmark programs by compiling the hot methods early. Our results in \nthis section con.rm the observations made by other re\u00adsearchers regarding the bene.ts of early compilation \n(with different/fewer benchmarks), and are presented here for completeness. For these experiments we \nemploy an of.ine pro.ling run to .rst determine the set of hot methods that are compiled by the default \nVM con.guration (threshold 10,000). Our setup compiles the same methods early by initiating their compila\u00adtionsatlower \nmethodexecution counts.Past studiesto mea\u00adsure early compilation bene.t used static method-level an\u00adnotations \nto indicate the hot methods to the VM for compi\u00adlation [22, 27]. However, the issues of re.ection and \nruntime generation of classes make it dif.cult to statically discover and annotate all hot methods in \nnewer Java benchmarks [6]. Therefore, we again employour new VM capability for these experiments. Each \nVM run invokes two benchmark itera\u00adtions. The .rst iteration does not perform any compilations, but is \nonly used to discover and load all program methods. The VM detects the end of the .rst iteration and \nmarks the set of hot methods at this point before initiating the next iter\u00adation. Measuring the application \ntime of the second iteration provides the actual program performance. Figure 2 illustrates the bene.ts \nof early compilation on program performance, averaged over all our 56 benchmark\u00adinput combinations. We \n.nd that early compilation of hot methods can improve performance by over 20% for our set of benchmarks. \nThus, our results in this section show that the proper selection of if and when to compile program methods \ncan have a signi.cant in.uence on performance.  5. JIT compilation on Single-Core Machines In this section \nwe .rst explore the selective compilation threshold that achieves the best average performance with our \nset of benchmarks for a VM with one compiler thread executing on a single-core machine. This threshold \nserves as the baseline for the remaining experiments in this paper. Additionally, several modern VMs \nare now equipped with the ability to spawn multiple simultaneous compiler threads. Our second study in \nthis section evaluates the impact of mul\u00adtiple compiler threads on program performance for machines with \na single processor. 5.1 Compilation Threshold with Single Compiler Thread By virtue of sharing the same \ncomputation resources, the ap\u00adplication and compiler threads share a complex relationship for a VM running \non a single-core machine. Thus, a high se\u00adlective compile threshold may achieve poor overall program \nperformance by spending too much time executing in non\u00adoptimized code resulting in poor application thread \ntime. By contrast, a lower than ideal compile threshold may also pro\u00adduce poor performance by spending \ntoo long in the compiler thread. Therefore, the compiler thresholds need to be care\u00adfully tuned to achieve \nthe most ef.cient average program ex\u00adecution on single-core machines over several benchmarks. VM developers \noften experiment with several different compile threshold values to .nd the one that achieves the best \noverall program performance for their set of bench\u00admark programs. We perform a similar experiment to \ndeter\u00admine the ideal compilation threshold with a single compiler thread on our set of benchmarks. These \nresults are presented in Figure 3(a), which plots the ratio of the average overall program performance \nat different compile thresholds com\u00adpared to the average program performance at the threshold of 10,000, \nwhich is the default compilation threshold for the HotSpot server VM. Not surprisingly, we can see this \ndefault threshold performs very well on our set of benchmarks, but a slightly higher compile threshold \nof 15,000 achieves the best overall performance for our benchmark set.  (a) (b) Figure 3. Effect of \ndifferent compilation thresholds on average benchmark performance on single-core processors It is also \ninteresting to note that performance worsens at both high and low compile thresholds. In order to better \nin\u00adterpret these results, we plot the graph in Figure 3(b) that shows the break-down of the overall program \nexecution time in terms of the ratios of the application and compiler thread times at different thresholds \nto their respective times at the compile threshold of 10,000, averaged over all benchmark programs. Thus, \nwe can see that high thresholds(> 15,000) compile less and degrade performance by not providing an opportunity \nto the VM to compile several important program methods. In contrast, the compiler thread times increase \nwith lower compilation thresholds(< 15,000) as more methods are sent for compilation. We expected this \nincreased com\u00adpilation to improve application thread performance. How\u00adever, the behavior of the application \nthread times at low com\u00adpile thresholds is less intuitive. On further analysis we found that although \nJIT compilation policies with lower thresholds send more methods to compile, this increase also grows \nthe length of the compiler queue. The .ood of less important program methods delays the compilation of \nthe most critical methods, resulting in the non-intuitive degradation in appli\u00adcation thread performance \nobserved in Figure 3(b) for the lower thresholds. Due to its superior performance, we select the compile \nthreshold of 15,000 as the baseline for our re\u00admaining experiments in this paper.  5.2 Effect of Multiple \nCompiler Threads on Single-Core Machines To the best of our knowledge, the effect of multiple compiler \nthreads on overall program performance on a single-core machine has never been previously discussed. \nIn this section we conduct such a study and present our observations. For each compiler threshold, a \nseparate plot in Figure 4(a) compares the average overall program performance with multiple compiler \nthreads to the average performance with a single compiler thread at that same threshold. Intuitively, \na greater number of compiler threads should be able to re\u00adduce the method compilation queue delay, which \nis the time spent between sending a method to compile and generat\u00ading optimized code. Indeed, we notice \nprogram performance improvements for small number of compiler threads (2 4), but the bene.ts do not seem \nto hold with increasing number of such threads(>4). We further analyzed the performance degradations \nwith more compiler threads and noticed an in\u00adcrease in the overall compiler thread times in these cases. \nThis increase suggests that several methods that were queued for compilation,but never got compiled before \nprogram ter\u00admination with a single compiler thread are now compiled as we provide more resources to the \nVM compiler compo\u00adnent. Unfortunately, many of these methods contribute little to improving program performance. \nAt the same time, the increased compiler activity increases compilation overhead. Consequently, the potential \nimprovement in application per\u00adformance achieved by more compilations seems unable to recover the additional \ntime spent by the compiler thread, re\u00adsulting in a net loss in overall program performance. Figure 4(b) \ncompares the average overall program perfor\u00admance in each case to the average performance of a baseline \ncon.guration with a single compiler thread at a threshold of 15,000. Remember, that the baseline con.guration \nused is the one that achieves the best average performance with a single compiler thread. These results \nreveal the best com\u00adpiler policy on single-core machines with multiple compiler threads. Thus, we can \nsee that the more aggressive thresh\u00adolds perform quite poorly in relation to our selected base\u00adline (with \nany number of compiler threads). Our analysis .nds higher compiler aggressiveness to send more program \nmethods for compilation, which includes methods that may not make substantial contributions to performance \nimprove\u00adment(cold methods). Additionally, the default HotSpot VM uses a simple FIFO (.rst-in .rst-out) \ncompilation queue, and compiles methods in the same order in which they are sent. Consequently, the cold \nmethods delay the compilation of the really important hot methods relative to the application thread, \nproducing the resultant loss in performance. Thus, this observation suggests that implementing a priority-queue \nto order compilations may enable more aggressive compila\u00adtion thresholds to achieve better performances. \nWe explore  (a) (b) Figure 4. Effect of multiple compiler threads on single-core program performance. \nThe discrete measured thread points are plotted equi-distantly on the x-axis. the effect of prioritized \nmethod compiles on program per\u00adformance in further detail in Section 8. In the absence of a strategy \nto appropriately prioritize method compiles, our results indicate that there may be no need to change \ncom\u00adpiler thresholds with more compiler threads on single-core machines. However, a small increase in \nthe number of com\u00adpiler threads generally improves performance by reducing the compilation queue delay. \n  6. JIT Compilation on Multi-Core Machines Dynamic JIT compilation on single-processor machines has \nto be conservative to manage the compilation overhead at runtime. Modern multi-core machines provide \nthe opportu\u00adnity to spawn multiple compiler threads and run them con\u00adcurrently on separate (free) processor \ncores, while not in\u00adterrupting the application thread(s). As such, it is a com\u00admon perception that a \nmore aggressive compilation policyis likely to achieve better application thread and overall pro\u00adgram \nperformance on multi-core machines for VMs with multiple compiler threads. Aggressiveness, in this context, \ncan imply compiling early or compiling more methods by lowering the compile threshold. In this section, \nwe report the impact of varying JIT compilation aggressiveness on pro\u00adgram performance for multi-core \nmachines. Our experimental setup controls the aggressiveness of distinct JIT compilation policies by \nvarying the selective compilation threshold. Lowering the compilation threshold can bene.t program performance \nin two ways: (a) by com\u00adpiling a greater percentage of the program code, and (b) by sending methods to \ncompile early. Thus controlling the com\u00adpile threshold enables us to simultaneously control both our \nvariables ( if and when ) forexploring the impactof com\u00adpilation policyaggressiveness on program performance.We \nexplore the effect of several compilation thresholds, from the selected baseline threshold of 15,000 \nto a very aggressive threshold of 50. At the same time, we also alter the num\u00adber of spawned concurrent \ncompiler threads. More compiler threads will typically have the effect of compiling methods early relative \nto the application thread.Wevary the number of simultaneously active compiler threads in our experiment \nfrom 1 to 100. The experiments are conducted on a cluster of identical 8-core machines withhyperthreading \ndisabled. Figure 5 illustrates the results of our experiments. For each indicated compile threshold, \na corresponding line-plot in Figure 5(a) shows the ratio of the program performance with different number \nof compiler threads to the program performance with a single compiler thread at that same threshold, \naveraged over our 56 benchmark-input pairs. Thus, we can see that increasing the number of compiler threads \nimproves application performance at all compile thresholds. Additionally, con.gurations with more aggres\u00adsive \ncompilation thresholds derive a greater bene.t in pro\u00adgram performance from more compiler threads. At \nthe same time, the relative gain in program performance does seem to taper off with each additional compiler \nthread. Moreover, higher compilation thresholds need fewer compiler threads to reach their maximum achievable \nprogram performance. These results are expected since a greater number of com\u00adpiler threads only bene.t \nperformance as long as there is work to do for those additional threads. More aggressive thresholds send \na greater number of methods to compile and therefore continue deriving performance bene.ts with more \ncompiler threads. It is also interesting to note that there is almost no further performance improvement \nfor anylevel of compiler aggressiveness after about seven compiler threads. We believe that this result \nis a consequence of our hard\u00adware setup that uses processors with eight distinct cores.We explore this \nresult further in Section 7. Figure 5(b) compares all the program performances (with different thresholds \nand different number of compiler threads) to a single baseline program performance. The se\u00adlected baseline \nis the program performance with a single compiler thread at the threshold of 15,000. We can see that \nin the best case (con.guration with threshold 5,000 and 7 compiler threads) the combination of increased \ncompiler  (a) (b) Figure 5. Effect of multiple compiler threads on multi-core application performance \naggressiveness with more compiler threads improves perfor\u00admance by about 17%, on average, over our baseline. \nHow\u00adever, about 10% of that improvement is obtained by simply reducing the compilation queue delay that \nis realized by increasing the number of compiler threads at the baseline (15,000) threshold. Thus, the \nhigher compiler aggressive\u00adness achieved by lowering the selective compilation thresh\u00adold seems to offer \nrelatively modest bene.ts over the base\u00adline compilation threshold employed by the default compiler policy \non single-core machines. Another interesting observation that can be made from the plots in Figure 5(b) \nis that aggressive compilation poli\u00adcies require more compiler threads (implying greater com\u00adputational \nresources) to achieve good program performance. Indeed, our most aggressive compiler threshold of 50 \nper\u00adforms extremely poorly in relation to the baseline threshold, and never improves upon the conservative \nbaseline thresh\u00adold even with a large number of compiler threads. This result seems to correspond with \nour observations from the last sec\u00adtion regarding the effect of cold program methods .ooding the queue \nat aggressive compile thresholds and delaying the compilation of hotter methods. We study different priority \nqueue implementations to alleviate this issue in Section 8.  7. JIT Compilation on Many-Core Machines \nOur observations regarding aggressive JIT compilation poli\u00adcies on modern multi-core machines in the \nlast section were limited by our existing 8-core processor based hardware. In future years, architects \nand chip developers are expect\u00ading and planning a continuously increasing number of cores in modern microprocessors. \nIt is possible that our conclu\u00adsions regarding JIT compilation policies may change with the availability \nof more abundant hardware resources. How\u00adever, processors with a large number of cores (or many\u00adcores) \nare not easily available just yet. Therefore, in this section, we construct a unique experimental con.guration \nto conduct experiments that investigate JIT compilation strate\u00adgies for such future many-core machines. \nOur novel experimental setup simulates many-core VM behavior using a single processor/core. To construct \nthis setup, we .rst update our HotSpot VM to report the category of each operating system thread that \nit creates (such as, application, compiler, garbage-collector, etc.), and to also report the creation \nor deletion of any VM/program thread at runtime. Next, we modify the harness of all our benchmark suites \nto not only report the overall program execution time, but to also provide a break-down of the time consumed \nby each individual VM thread. We use the /proc .le-system interface provided by the Linux operating system \nto obtain individual thread times, and employ the JNI interface to access this platform-speci.c OS feature \nfrom within a Java program. Finally, we also use the thread-processor-af.nity interface methods provided \nby the Linux OS to enable our VM to choose the set of processor cores that are eligible to run each VM \nthread. Thus, on each new thread creation, the VM is now able to assign the processor af.nity of the \nnew VM thread (based on its category) to the set of processors speci.ed by the user on the command-line. \nWe use this facility to constrain all application and compiler threads in a VM to run on a single processor \ncore. Our experimental setup to evaluate the behavior of many\u00adcore (with unlimited cores) application \nexecution on a single-core machine is illustrated in Figure 6. Figure 6(a) shows a snapshot of one possible \nVM execution order with multiple compiler threads, with each thread running on a dis\u00adtinct core of a \nmany-core machine. Our experimental setup employs the OS thread af.nity interface to force all applica\u00adtion \nand compiler threads to run on a single core, and relies on the OS round-robin thread scheduling to achieve \na corre\u00adsponding thread execution order that is shown in Figure 6(b). It is important to note that JIT \ncompilations in our simulation of many-core VM execution (on single-core machine) occur at about the \nsame time relative to the application thread as on a physical many-core machine. 1 Now, on a many-core \nmachine, where each compiler thread runs on its own dis\u00ad 1We also constrain most of our benchmark programs \nto spawn a single application thread.   Application Compiler  Thread Thread (a) Multi-core execution \nCore1 Core2 Core3 Core4  (b) Single-core simulation of multi-core execution Figure 6. Simulation of \nmulti-core VM execution on single-core processor tinct core concurrently with the application thread, \nthe total program run-time is equal to the application thread run-time alone, as understood from Figure \n6(a). Therefore, our abil\u00adity to precisely measure individual application thread times in our single-core \nsimulation enables us to realistically em\u00adulate an environment where each thread has access to its own \ncore. This framework allows us to study the behavior of different JIT compilation strategies with any \nnumber of compiler threads running on separate cores on future many\u00adcore hardware. We now employ our \nnew experimental setup to perform the same experiments as done in the last section. Figures 7(a) and \n(b) show the results of these experiments and plot the application thread times with varying number of \ncompiler threads and compiler aggressiveness. These plots corre\u00adspond with the graphs illustrated in \nFigures 5(a) and (b) respectively. We can see that the trends in these results are mostly consistent \nwith our observations from the last sec\u00adtion. This similarity con.rms the accuracy of our simple simulation \nmodel to study JIT compilation policies on many\u00adcore machines, in spite of the potential differences \nbetween inter-core communication, cache models and other low-level microarchitectural effects. The primary \ndistinction between the two sets of results occurs for larger number of com\u00adpiler threads. More precisely, \nunlike the plots in Figure 5(a), Figure 7(a) shows that application thread performance for aggressive \ncompiler thresholds continues gaining improve\u00adments beyond a small number of compiler threads. Thus the \nlack of performance bene.ts beyond about 7-10 com\u00adpiler threads in the last section is, in fact, caused \ndue to the limitations of the underlying 8-core hardware. This re\u00adsult shows the utility of our novel \nsetup to investigate VM properties for future many-core machines. These results also show that even 100 \nactive compiler threads are unable to substantially improve program performance for aggressive compiler \nthresholds beyond the performance obtained by the conservative single-core JIT compilation threshold. \n  8. Effect of Priority-Based Compiler Queue The existing HotSpot VM employs a FIFO compiler queue as \nthe communication interface between the application and compiler threads. Thus, methods sent for compilation \nby the application thread are placed in the compiler queue (and serviced by the compiler thread) in their \norder of arrival. Our results in the earlier sections suggest that the relatively poor performance achieved \nby the aggressive JIT compilation policies may be an artifact of the FIFO compiler queue that cannot \nadequately prioritize the compilations by actual hotness levels of application methods. Therefore, in \nthis section, we explore and measure the potential of different priority queue implementations to improve \nthe performance obtained by different JIT compilation strategies. 8.1 Ideal Priority-Based Compiler \nQueue First, we attempt to understand the performance impact of an ideal strategy for ordering method \ncompilations. An ideal compilation strategy should be able to precisely determine the actual hotness \nlevel of all methods send to compile, and always compile them in that order. Unfortunately, such an ideal \nstrategy requires knowledge of future program behav\u00adior, which is very dif.cult to determine or obtain. \nIn lieu of such information, we devise a compilation strategy that prioritizes method compiles based \non their total execution countsover an earlier pro.le run.With this strategy, the com\u00adpiler thread always \nselects and compiles the method with the highest pro.led execution counts from the available candi\u00addates \nin the compiler queue.We call this our ideal compila\u00adtion strategy. We do note that even our ideal pro.le-driven \nstrategy may not achieve the actual best results because the candidate method with the highest hotness \nlevel may still not  (a) (b) Figure 7. Effect of multiple compiler threads on many-core application \nperformance be the best method to compile at that point during program execution. To the best of our \nknowledge, this is the .rst at\u00adtempt at studying a potentially ideal priority queue scheme in the context \nof JIT compilation. Thus, our ideal priority-queue strategy requires a pro.le\u00adrun of every benchmark \nto determine its method hotness counts. For maximum ef.ciency, of.ine pro.ling necessi\u00adtates using method-level \nannotations to indicate the mea\u00adsured hotness levels to the VM. However, as mentioned earlier, issues \nwith re.ection and runtime method creation makes accurate and complete method annotations very dif\u00ad.cult, \nespecially for newer Java benchmarks. Therefore, we again employ the novel VM capability we developed \nto al\u00adlow the virtual machine to detect speci.c points of interest during a program run. Our experimental \nsetup runs two iter\u00adations for every benchmark program. The .rst iteration per\u00adforms no compilations, \nbut records the execution counts of each method. As a side-effect this initial iteration also dis\u00adcovers \nand loads all necessary program methods. The VM detects the end of the .rst iteration and uses this indicator \nto mark all hot methods with a rank based on their execution counts collected by the VM during the .rst \niteration. The VM then re-enables compilations for the next iteration. The second (and .nal) iteration \nemploys a priority queue to sort methods sent for compilation by the application thread in descending \norder of their attached ranks. For maximum ef\u00ad.ciency, we implement our sorted priority queue as a binary \ntree. 8.1.1 Single-Core Machine Con.guration Figure8compares the performance results of our ideal com\u00adpiler \npriority queue and the default FIFO priority queue im\u00adplementations for single-core machines. Figure \n8(a) plots the average performance ratio with the FIFO priority queue for different VM compile thresholds \nand different number of compiler threads with the baseline single compiler thread, 15,000 threshold VM \nperformance, averaged over our 56 benchmark-input pairs. These measurements vary slightly from earlier \nresults shown for the similar con.guration in Figure 4(b). This variation is due to the different experimen\u00adtal \ncon.guration adopted in this section that causes some methods (mainly from the benchmark harness and \nthe Java library) that are hot only in the .rst benchmark iteration of every run to not be compiled. \nIt is more relevant to note that the results with our new con.guration still show the same performance \ntrends as discussed in Section 5.2. Figure 8(b) presents the results of VM runs with our ideal priority \nqueue implementation compared to the same default FIFO priority queue implementation with a single compiler \nthread and a threshold of 15,000. The graph illustrates that accurate assignment of method priorities \nallows the higher compile thresholds to also achieve good average program performance for small number \nof compiler threads. As de\u00adscribed in Section 5.2, initiating a greater number of com\u00adpiler threads on \nsingle-core machines results in compiling methods that are otherwise left uncompiled (in the com\u00adpiler \nqueue) upon program termination with fewer compiler threads. The resulting increase in the compilation \noverhead is not suf.ciently compensated by the improved application ef.ciency, resulting in a net loss \nin overall performance. This effect persists regardless of the method priority algorithm employed. We \ndo see that accurately ordering the method compiles enables the VM with our ideal priority queue im\u00adplementation \nto obtain slightly better performance than the best achieved with the FIFO queue.  8.1.2 Many-Core Machine \nCon.guration Figure 9 compares the performance results of using our ideal compiler priority queue with \nthe baseline VM that uses the default FIFO-based compiler queue implementation for many-core machines. \nFigure 9(a) plots the average perfor\u00admance ratio with the default FIFO priority queue. Again, these measurements \nvary slightly from earlier results for the similar con.guration in Figure 7(b) due to the different ex\u00adperimental \ncon.guration adopted in this section. We also note that results with this con.guration still show the \nsame performance trends as discussed in Section 6.  (a) FIFO-priority (b) Ideal Priority Figure 8. \nComparison of ideal compiler priority queue implementation with baseline FIFO compiler queue for single-core \nmachine con.guration  (a) FIFO-priority (b) Ideal Priority Figure 9. Comparison of ideal compiler priority \nqueue implementation with baseline FIFO compiler queue for many-core machine con.guration Figure 9(b) \ndisplays the performance ratio of the VM runs with our ideal priority-based compiler queue implementa\u00adtion \nwith the baseline VM performance (15,000 threshold, single compiler thread, FIFO compiler queue) that \nwas also used in Figure 9(a). These results show several interesting trends. First, appropriately sorting \nmethod compiles signif\u00adicantly bene.ts program performance at all threshold lev\u00adels. At the same time, \nthe performance bene.ts are more prominent for aggressive compile thresholds. This behav\u00adior is logical \nsince more aggressive thresholds are more likely to .ood the queue with low-priority compiles that de\u00adlay \nthe compilation of the hotter methods with the FIFO queue. Second, the best average benchmark performance \nwith our ideal priority queue for every threshold plot is achieved with a smaller number of compiler \nthreads, espe\u00adcially for the more aggressive compiler thresholds. This re\u00adsult shows that our ideal priority \nqueue does realize its goal of compiling the hotter methods before the cold methods. The later lower \npriority method compilations seem to not make a major impact on program performance. Finally, we can \nalso conclude that using a good priority compiler queue allows more aggressive compilation policies (that \ncompile a greater fraction of the program early) to improve perfor\u00admance over a less aggressive strategy \non multi/many-core machines. Moreover, a small number of compiler threads is generally suf.cient to achieve \nthe best average application thread performance. Overall, the best aggressive compilation policy improves \nperformance by about 30% over the base\u00adline, and by about 11% over the best performance achieved by the \ndefault single-core compilation threshold of 15,000.  8.2 Heuristic Priority-Based Compiler Queue Our \nideal priority queue strategy requires of.ine pro.le in\u00adformation to correctly order method compilations \nand im\u00adprove VM performance. However, collecting of.ine pro\u00adgram pro.les is often cumbersome and may \nbe infeasible to obtain in many cases. Additionally, method compile pri\u00adorities provided by of.ine pro.ling \nmay be invalidated if the input/environment during the actual program run varies from that used during \nthe pro.ling run. Therefore, it may be important to .nd techniques that can assess method priori\u00adties \ndynamically during every program run. However it may be dif.cult to obtain comparable performance results \nusing a completely online strategy. An online strategy can only see past program behavior. Additionally, \nthe more aggres\u00adsive JIT compilation policies make their hotness decisions earlier, giving any online \nstrategy an even reduced opportu\u00adnity to accurately access method priorities. The default FIFO queue \nmechanism uses a heuristic that assigns method prior\u00adities based on their order of arrival. As part of \nthis work, we experimented with a few other (and arguably more complex) schemes to assign dynamic method \npriorities.  In this section we describe the priority scheme that achieved our best results. This scheme \nuses a new global counter in addition to the counter used to hold the execution counts for each method. \nThis global counter accumulates the execution counts of all methods from the start of each run. The value \nof this global counter is recorded in a new .eld (say, X) in every method header on the .rst invocation \nof that method. A method is still sent to compile when its normal execution counter exceeds the speci.ed \ncompilation threshold. However, now before insertion into the compile queue, the method priority is calculated \nas: method execution count P riority = (1) current global count - X Thus, by the scheme, methods that \nattain their hotness promptly after their .rst invocation and have become hot in the more recent past \nare likely to be assigned a higher priority for compilation. We use the same binary-tree based implementation \nas employed earlier. Figures 10 and 11 display the application thread perfor\u00admance of our best dynamic \npriority queue implementation compared to the corresponding baseline performance (with FIFO-based compiler \nqueue at the threshold of 15,000 with one compiler thread) for single-core and many-core ma\u00adchines respectively. \nThus, for both these graphs, we can see that the performance achieved by our new dynamic priority Figure \n11. Comparison of our best heuristic dynamic com\u00adpiler priority queue implementation with baseline FIFO \ncompiler queue for many-core machine con.guration scheme is better than that achieved by the FIFO compiler \nqueue at most measured points,but does not match the ben\u00ade.t of the ideal priority scheme. We are actively \nexploring other heuristic techniques to more accurately assign method priorities dynamically at runtime. \n  9. FutureWork This work presents several interesting avenues for future re\u00adsearch. First, this work \nshows that the availability of abun\u00addant computation resources in future machines enables the possibility \nof program performance improvement by early compilation of a greater fraction of the program. With the \ndevelopment of pro.le-driven optimization phases, future work will have to consider the effect of early \ncompilation on the amount of collected pro.le information and result\u00ading impact on generated code. Additionally, \nresearchers may also need to explore the interaction of increased compiler activity with garbage collection. \nIncreased native code pro\u00adduced by aggressive JIT compilation can raise memory pres\u00adsure and garbage \ncollection overheads, which may then af\u00adfect program non-determinism due to the increased pause times \nassociated with garbage collections. Second, in this paper we explored some priority queue implementations \nthat may be more suitable with aggressive compilation policies. We plan to continue our search for better \nmethod prioritiza\u00adtion schemes, as well as possibly allowing the method prior\u00adities to be re-evaluated \neven after enqueuing, which was not considered in this work. Third, this work restricts the JIT compilation \npolicy exploration to if and when methods are compiled at the same optimization level, but did not allow \ncontrolling how to perform compilation in different cases. In the future, we plan to also study increasing \ncompiler aggres\u00adsiveness by optimizing at higher compilation levels in a VM that provides robust support \nfor tiered compilation. Finally, we are currently conducting similar experiments in other vir\u00adtual machines \n(JikesRVM) to see if our conclusions from this work hold across different VMs.  10. Conclusions Modern \nprocessors are expected to continue integrating in\u00adcreasing number of cores in future chips. The goal \nof this work was to explore the potential performance bene.t of more aggressive JIT compilation policies \nfor current and fu\u00adture multi/many-core machines and with newer virtual ma\u00adchines that support multiple \nsimultaneous compiler threads. We .rst discover that compiling more and/or compiling early can signi.cantly \nimprove performance compared to that achieved by the default HotSpot VM. However, these improvements \nfade in comparison to that already obtained by the default JIT basedVMover pure interpretation.We be\u00adlieve \nthat these results will allow VM developers and users to assess if the maximum additional bene.t of compiling \nmore program methods early is worth the increased computation and memory resources necessary to generate \nand maintain the corresponding native code. An important contribution of this work is the develop\u00admentofseveralnovelVM \ncon.gurationstofacilitate ourex\u00adperiments. On single-core machines, we .nd that the same compilation \nthreshold achieves the best overall program per\u00adformance with a single and multiple compiler threads, \nand regardless of the priority queue algorithm that is used for the compiler queue. Our results on multi-core \nand many-core machines .nd that although modern multi-core and many\u00adcore hardware can enable more aggressive \nJIT compilation policies, and more aggressive policies can produce bene.ts to performance, achieving \nsuch bene.ts requires accurate as\u00adsignment of method priorities. Finding dynamic online al\u00adgorithms to \nassign such accurate method priorities is still an open research question. Thus, as we enter the new \nera of multi/many-core machines with increasing number of cores with every processor generation, we expect \nthis research to assist VM developers to make more informed decisions re\u00adgarding how to design and implement \nthe best possible JIT compilation policies to achieve the best application perfor\u00admance.  Acknowledgments \nWe thank the anonymous reviewers for their constructive comments and suggestions. This research was supported \nin part by NSF CAREER award CNS-0953268.  References [1] International technology roadmap for semiconductors. \naccessed from http://www.itrs.net/Links/2009ITRS/Home2009.htm, 2008\u00ad 09. [2] M. Arnold, S. Fink, D. Grove, \nM. Hind, and P. F. Sweeney. Adaptive optimization in the Jalapeno JVM. In Proceedings of the 15th ACM \nSIGPLAN conference on Object-oriented programming, systems, languages, and applications, pages 47 65, \n2000. [3] M. Arnold, S. Fink, D. Grove, M. Hind, and P. F. Sweeney. Adaptive optimization in the Jalapeo \nJVM: The controller s analytical model. In Proceedingsof the3rdACMWorkshop on Feedback Directed and Dynamic \nOptimization (FDDO 00), December 2000. [4] M. Arnold,S. Fink,D. Grove,M. Hind, andP.F. Sweeney.A surveyof \nadaptive optimization in virtual machines. Proceed\u00adings of the IEEE, 92(2):449 466, February 2005. [5]S.M. \nBlackburn,R. Garner,C.Hoffmann,A.M.Khang,K.S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Frampton, \nS. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss,B. Moss,A. Phansalkar,D. Stefanovi\u00b4c,T.VanDrunen, \nD. von Dincklage, and B. Wiedermann. The DaCapo bench\u00admarks: Java benchmarking development and analysis. \nIn Pro\u00adceedings of the 21st annual ACM SIGPLAN conference on Object-oriented programming systems, languages, \nand appli\u00adcations, OOPSLA 06, pages 169 190, 2006. [6] E.Bodden, A. Sewe, J. Sinschek, H. Oueslati, and \nM. Mezini. Taming re.ection: Aiding static analysis in the presence of re\u00ad.ection and custom class loaders. \nIn ICSE 11: International Conference on Software Engineering, May 2011. [7] D. Bruening and E. Duesterwald. \nExploring optimal compi\u00adlation unit shapes for an embedded just-in-time compiler. In 3rd ACM Workshop \non Feedback-Directed and Dynamic Op\u00adtimization, pages 13 20, 2000. [8]P.P.Chang,S.A. Mahlke, andW. meiW. \nHwu. Using pro.le information to assist classic code optimizations. Software Practice and Experience, \n21:1301 1321, 1991. [9] L.P. Deutsch and A. M. Schiffman. Ef.cient implementation of the smalltalk-80 \nsystem. In POPL 84: Proceedings of the 11th ACM SIGACT-SIGPLAN symposium on Principles of programming \nlanguages, pages 297 302, New York, NY, USA, 1984.ACM. ISBN 0-89791-125-3. [10] M. X. Goemans. Advanced \nalgorithms. Technical Report MIT/LCS/RSS-27, 1994. [11] J. Gosling, B. Joy, G. Steele, and G. Bracha. \nThe Java(TM) Language Speci.cation (3rd Edition). Prentice Hall, third edition, June 14 2005. [12] S. \nL. Graham, P. B. Kessler, and M. K. Mckusick. Gprof: A call graph execution pro.ler. SIGPLAN Notices, \n17(6):120 126, 1982. [13] N. Grcevski, A. Kielstra, K. Stoodley, M. Stoodley, and V. Sundaresan. Java \njust-in-time compiler and virtual machine improvements for server and middleware applications. In Pro\u00adceedings \nof the conference on Virtual Machine Research And Technology Symposium, pages 12 12, 2004. [14] D. Gu \nand C.Verbrugge. Phase-based adaptive recompilation ina JVM. In Proceedings of the 6th IEEE/ACM symposium \non Codegeneration and optimization, CGO 08, pages 24 34, 2008. [15] M. Haneda, P. M. W. Knijnenburg, \nand H. A. G. Wijshoff. Generating new general compiler optimization settings. In ICS 05: Proceedings \nof the 19th Annual International Con\u00adference on Supercomputing, pages 161 168, 2005. ISBN 1\u00ad59593-167-8. \n [16] G. J. Hansen. Adaptive systems for the dynamic run-time optimization of programs. PhD thesis, \nCarnegie-Mellon Univ., Pittsburgh,PA, 1974. [17] T. Harris. Controlling run-time compilation. In IEEE \nWork\u00adshop on Programming Languages for Real-Time Industrial Applications, pages 75 84, Dec. 1998. [18] \nU. H \u00a8and D. Ungar. Reconciling responsiveness with olzle performance in pure object-oriented languages. \nACM Trans\u00adactions on Programming Language Systems, 18(4):355 400, 1996. ISSN 0164-0925. [19] R. M. Karp. \nOn-line algorithms versus off-line algorithms: How much is it worth to know the future? In Proceedings \nof the IFIP World Computer Congress on Algorithms, Software, Architecture -Information Processing, Vol \n1, pages 416 429, 1992. [20] D. E. Knuth. An empirical study of Fortran programs. Soft\u00adware: Practice \nand Experience, 1(2):105 133, 1971. [21]T. Kotzmann, C.Wimmer, H.M\u00a8ock,ossenb \u00a8T. Rodriguez, K. Russell, \nand D. Cox. Design of the Java HotSpotTMclient compiler for Java 6. ACM Trans. Archit. Code Optim., 5(1): \n1 32, 2008. [22] C. Krintz. Coupling on-line and off-line pro.le information to improve program performance. \nIn CGO 03: Proceedings of the international symposium on Codegeneration and opti\u00admization, pages 69 78,Washington, \nDC, USA, 2003. [23] C. Krintz andB. Calder. Using annotations to reduce dynamic optimization time. In \nProceedings of theACMSIGPLAN 2001 conference on Programming language design and implemen\u00adtation, pages \n156 167, 2001. [24] C. Krintz, D. Grove, V. Sarkar, and B. Calder. Reducing the overhead of dynamic compilation. \nSoftware: Practice and Experience, 31(8):717 738, December 2000. [25] P. Kulkarni, M. Arnold, and M. \nHind. Dynamic compilation: the bene.ts of early investing. In VEE 07: Proceedings of the3rdinternational \nconferenceonVirtualexecutionenviron\u00adments, pages 94 104, 2007. [26] Microsoft. MicrosoftC# Language Speci.cations. \nMicrosoft Press, .rst edition, April 25 2001. [27] M. A. Namjoshi and P. A. Kulkarni. Novel online pro.ling \nfor virtual machines. In VEE 10: Proceedings of the 6th ACM SIGPLAN/SIGOPS international conference on \nVirtual execution environments, pages 133 144, 2010. ISBN 978-1\u00ad60558-910-7. [28] M.Paleczny,C.Vick, \nandC.Click. TheJava HotSpotTMserver compiler. In JVM 01: Proceedings of the 2001 Symposium on JavaTMVirtual \nMachine ResearchandTechnology Symposium, pages 1 12, Berkeley,CA, USA, 2001. USENIX Association. [29] \nSPEC2008. SPEC JVM2008 benchmarks. http://www.spec.org/jvm2008/, 2008. [30] SPEC98. SPEC JVM98 benchmarks. \nhttp://www.spec.org/jvm98/, 1998. [31] V. Sundaresan, D. Maier, P. Ramarao, and M. Stoodley. Ex\u00adperiences \nwith multi-threading and dynamic class loading in a Java just-in-time compiler. In Proceedings of the \nInternational Symposium on Code Generation and Optimization,CGO 06, pages 87 97, 2006. [32]R. Vall\u00b4ee-Rai,P. \nCo, E. Gagnon, L. Hendren, P. Lam, and V. Sundaresan. Soot -a Java bytecode optimization frame\u00adwork. \nIn CASCON 99: Proceedings of the 1999 conference of theCentre for Advanced Studies on Collaborativeresearch, \npage 13, 1999. [33] D. L. Whit.eld and M. L. Soffa. An approach for exploring code improving transformations. \nACM Transactions on Pro\u00adgramming Languages and Systems, 19(6):1053 1084, 1997.  \n\t\t\t", "proc_id": "2048066", "abstract": "<p>Dynamic or Just-in-Time (JIT) compilation is crucial to achieve acceptable performance for applications (written in managed languages, such as Java and C#) distributed as intermediate language binary codes for a virtual machine (VM) architecture. Since it occurs at runtime, JIT compilation needs to carefully tune its compilation policy to make effective decisions regarding 'if' and 'when' to compile different program regions to achieve the best overall program performance. Past research has extensively tuned JIT compilation policies, but mainly for VMs with a single compiler thread and for execution on single-processor machines.</p> <p>This work is driven by the need to explore the most effective JIT compilation strategies in their modern operational environment, where (a) processors have evolved from single to multi/many cores, and (b) VMs provide support for multiple concurrent compiler threads. Our results confirm that changing 'if' and 'when' methods are compiled have significant performance impacts. We construct several novel configurations in the HotSpot JVM to facilitate this study. The new configurations are necessitated by modern Java benchmarks that impede traditional static whole-program discovery, analysis and annotation, and are required for simulating future many-core hardware that is not yet widely available. We study the effects on performance of increasing compiler aggressiveness for VMs with multiple compiler threads running on existing single/multi-core and future many-core machines. Our results indicate that although more aggressive JIT compilation policies show no benefits on single-core machines, these can often improve program performance for multi/many-core machines. However, accurately prioritizing JIT method compilations is crucial to realize such benefits.</p>", "authors": [{"name": "Prasad A. Kulkarni", "author_profile_id": "81100633789", "affiliation": "University of Kansas, Lawrence, KS, USA", "person_id": "P2839266", "email_address": "prasadk@ku.edu", "orcid_id": ""}], "doi_number": "10.1145/2048066.2048126", "year": "2011", "article_id": "2048126", "conference": "OOPSLA", "title": "JIT compilation policy for modern machines", "url": "http://dl.acm.org/citation.cfm?id=2048126"}