{"article_publication_date": "10-22-2011", "fulltext": "\n AC: Composable Asynchronous IO for Native Languages Tim Harris Mart\u00b4in Abadi . Rebecca Isaacs Ross McIlroy \nMicrosoft Research, Cambridge Microsoft Research, SiliconValley University of California, Santa Cruz. \nColl` ege de France. tharris@microsoft.com abadi@microsoft.com risaacs@microsoft.com rmcilroy@microsoft.com \nAbstract This paper introduces AC, a set of language constructs for composable asynchronous IO in native \nlanguages such as C/C++. Unlike traditional synchronous IO interfaces, AC lets a thread issue multiple \nIO requests so that they can be serviced concurrently, and so that long-latency opera\u00adtions can be overlapped \nwith computation. Unlike tradi\u00adtional asynchronous IO interfaces, AC retains a sequential style of programming \nwithout requiring code to use multi\u00adple threads, and without requiring code to be stack-ripped into chainsof \ncallbacks.ACprovides an async statement to identify opportunities for IO operations to be issued concur\u00adrently, \na do..finish block that waits until any enclosed async work is complete, and a cancel statement that \nrequests cancellation of un.nished IO within an enclosing do..finish.We give an operational semantics \nfor a core language.We describe andevaluate implementations that are integrated with message passing \non the Barrel.sh research OS, and integrated with asynchronous .le and network IO on MicrosoftWindows.We \nshow thatACoffers comparable performance to existing C/C++ interfaces for asynchronous IO, while providing \na simpler programming model. Categories and Subject Descriptors D.1.3[Programming Techniques]: Concurrent \nProgramming; D.3.3 [Program\u00adming Languages]: Language Constructs and Features Input/output; D.4.4[Operating \nSystems]: Communications Management Message sending General Terms Languages, Performance 1. Introduction \nIn the future, processors are likely to provide a heteroge\u00adneous mix of core types without hardware cache \ncoherence across a whole machine. In the Barrel.sh project we are in\u00advestigating how to design an operating \nsystem (OS) for this Permission to make digital or hard copies of all or part of this work for personal \nor classroomuseisgrantedwithout feeprovidedthat copies arenot madeordistributed forpro.torcommercialadvantage \nandthatcopiesbearthisnoticeandthefullcitation onthe .rstpage.To copy otherwise,to republish,topostonserversorto \nredistribute tolists, requirespriorspeci.cpermission and/ora fee. OOPSLA 11, October22 27,2011, Portland,Oregon,USA. \nCopyright c &#38;#169;2011ACM978-1-4503-0940-0/11/10. . .$10.00 kind of hardware, in which we can no \nlonger rely on tradi\u00adtional shared-memory within the OS [4]. The approach we are taking is to construct \nthe OS around separate per-core kernels, and to use message passing for communication between system \nprocesses running on dif\u00adferent cores. Other contemporary OS research projects take a similar approach \n[38]. Ourhypothesis is that systemsbuilt on message passing can be mapped to a wide variety of pro\u00adcessor \narchitectures without large-scale re-implementation. Using message passing lets us accommodate machines \nwith heterogeneous core types, and machines without cache\u00adcoherence; we can map message passing operations \nonto specialized messaging instructions [18, 34], and we can map them onto shared-memorybuffers on current \nhardware [4]. However, it is dif.cult to write scalable low-level soft\u00adware using message passing. Existing \nsystems focus either on ease-of-programming (by providing simple synchronous send/receive operations), \nor on performance (typically by providing asynchronous operations that execute a callback function once \na message has been sent or received). The same tension exists in IO interfaces more generally [27, 35]. \nForexample, the MicrosoftWindows APIs require software to choose between synchronous operations which \nallow only one concurrent IO request per thread, and complex asyn\u00adchronous operations which allow multiple \nIO requests. We believe that the inevitable and disruptive evolution of hardware to non-cache-coherent, \nheterogeneous, multi-core systems makes support for asynchronous IO in low-level languages such as C/C++ \nboth essential and timely. In this paper we introduceAC( Asynchronous C ),a new approach to writing programs \nusing asynchronous IO (AIO). ACprovides a lightweight form of AIO that can be added in\u00adcrementally to \nsoftware, without the use of callbacks, events, or multiple threads. Our overall approach is for the \nprogrammer to start out with simple synchronous IO operations, and to use new language constructs to \nidentify opportunities for the lan\u00adguage runtime system to start multiple IO operations asyn\u00adchronously. \nAs a running example, consider a Lookup function that sends a message to a name-service process, and \nthen receives back an address that the name maps to. Figure 1 shows this function written using Barrel.sh \ns callback-based interface. void Lookup(NSChannel_t *c, char *name) { OnRecvLookupResponse(c, &#38;ResponseHandler); \n// Store state needed by send handler c->st = name; OnSend(c, &#38;SendHandler); } void ResponseHandler(NSChannel_t \n*c, int addr) { printf(\"Got response %d\\n\", addr); } void SendHandler(NSChannel_t *c) { if (OnSendLookupRequest(c, \n(char*)(c->st)) == BUSY) { OnSend(c, &#38;SendHandler); }} Figure 1. Querying a set of name server using \nBarrel.sh s callback-based interface for message passing. The Lookup function takes a reference to a \nchannel (c). The function registers a ResponseHandler callback to execute when a LookupResponse reply \nis received. It then registers a SendHandler callback to execute when channel c has space for the outgoing \nmessage. (Many hard\u00adware implementations of message passing provide bounded\u00adsize message channels, and \nso it can be impossible to send a message immediately.) In addition, Lookup needs to record name in a \ntemporary data structure so that it is available to SendHandler. The On* functions are generated automat\u00adically \nfrom an interface de.nition for the NSChannel t channel. With AC, the lookup example becomes a single \nfunc\u00adtion using synchronous Send/Recv operations: (We omit some details to do with cancellation of un.nished \nIO opera\u00adtions; we return to cancellation in Section 2.) // Caution: functions ending in AC may block \n void LookupAC(NSChannel_t *c, char *name) { int addr; SendLookupRequestAC(c, name); RecvLookupResponseAC(c, \n&#38;addr); printf(\"Got response %d\\n\", addr); } Compared with the callback-based implementation, \nthis LookupAC function is clearly much simpler: it avoids the need for stack-ripping [3] in which the \nlogical .ow be\u00adtween operations is split across a series of callbacks. AC leads to a form of composability \nthat is lost with stack\u00adripping. A function can simply call into other functions using AC, and it can \nstart multiple AC operations concur\u00adrently.For instance, to communicate with two name servers, one can \nwrite: void TwinLookupAC(NSChannel_t *c1, NSChannel_t *c2, char *name) { do { async LookupAC(c1, \nname); // S1 async LookupAC(c2, name); // S2 } finish; printf(\"Got both responses\\n\"); // S3 } The \nasync at statement S1 indicates that execution can continue to statement S2 if the .rst lookup needs \nto block. The do..finish construct indicates that execution cannot continue to statement S3 until both \nS1 and S2 have been executed to completion. Throughout AC, we keep the abstractions used for asyn\u00adchrony \nseparate from the abstractions used for parallel pro\u00adgramming; code remains single-threaded unless the \npro\u00adgrammer explicitly introduces parallelism. The async and do..finish constructs are solely there to \nidentify op\u00adportunities for multiple messages to be issued concurrently; unlike the async construct in \nX10 [7], our async does not introduce parallelism. Consequently, manyof our exam\u00adples can be written \nwith no concurrency-control beyond the block-structured synchronization of do..finish. We make a number \nof additional contributions beyond the core designofAC.We introducea new block-structured cancellation \nmechanism. This approach to cancellation pro\u00advides a modular way for a program to start asynchrony op\u00aderations \nand then to cancel them if they have not yet com\u00adpleted; e.g., adding a timeout around a function that \nis called. In TwinLookupAC, cancellation could be used to abandon one lookup as soon as the other lookup \nis complete. In con\u00adtrast to our approach, traditional cancellation mechanisms are directed at individual \nIO operations [1], or at groups of operations on the same .le, or at a complete thread (e.g., alerting \nin Modula-2+ [5]). We introduceACin more detail in Section 2. In Section3 we present a formal operational \nsemantics for a core lan\u00adguage modelingAC, including cancellation.Wegive the se\u00admantics and discuss properties \nthat it satis.es. Section4describes two implementations ofAC. The .rst implementation uses a modi.ed \nClang/LLVM tool-chain to add the AC operations to C/C++. The second implemen\u00adtation operates with Clang, \nor with GCC, and de.nes the AC constructs using a combination of macros and existing C/C++ extensions \nprovided by these compilers. The second implementation has slightly higher overheads than the .rst. In \nSection 5 we look at the performance of implemen\u00adtations that are integrated with message passing on \nBar\u00adrel.sh, and also at implementations that are integrated with asynchronous IO on Microsoft Windows. \nIn each case, AC achieves most of the performance of manually written stack\u00adripped code while providing \na programming model that is comparable to basic synchronous IO (and comparable to the recent C# and F#-based \nabstractions for performing asyn\u00adchronousIO [32]).We discuss relatedwork and concludein Sections6and \n7. 2. Composable Asynchronous IO In this section we introduce AC informally. We continue with the example \nof a name-service lookup from the intro\u00adduction.We use it to illustrate the behavior ofACoperations in \nmore detail, and to motivate our design choices. Throughout this section our design choices are moti\u00advated \nby providing two properties. First, a serial elision property: if the IO operations in a piece of software \ncom\u00ad int LookupAllAC(NSChannel_t *cs[], int nc, char *name, int *addr) { bool seen_first = false; int \nfirst_addr; do { for (int i = 0; i < nc; i++) { async { if (LookupOneAC(cs[i], name, addr) == OK) { \n if (!seen_first) { seen_first = true; first_addr = *addr; } else { assert(*addr == first_addr); } } \n} } } finish; return OK; } Figure 2. Querying a set of name servers concurrently, checking that theyall \nreturn the same result. plete without needing to block, then the software behaves as though the AC extensions \nwere removed. Second, a syn\u00adchronous elision property: removing the AC constructs leaves a correct program \nusing ordinary synchronous opera\u00adtions. Conversely, taking a synchronous program and adding these constructs \nproduces a program using asynchronous IO. We believe both properties are valuable in simplifying the \nincremental adaptation of existing applications to use asynchrony (although, of course, care is still \nneeded to de\u00adtermine exactly which IO requests can be issued at the same time). In this section we focus \non examples based on message passing on Barrel.sh.In this setting, theACsend/receive op\u00aderations block \nuntil an outgoing message has been buffered in a channel, or until an incoming message has been removed \nfrom a channel. Unlike the message passing operations in languages such as CSP [17], theACsend/receive \noperations do not synchronize with one another. Channels operate be\u00adtween pairs of processes in a single \nmachine. They provide reliable, ordered delivery of messages. The sole kind offail\u00adure is that a channel \nis abruptly disconnected when the pro\u00adcess on one end terminates without closing the channel; this failure \nis signaled out-of-band to the other process, so error handling code does not feature in the examples \nhere. It is straightforward to write functions such as LookupAC from the introduction: synchronous message \npassing avoids the complexity of callback-based interfaces. However, it also loses the bene.ts: we can \nno longer perform multiple send/receive operations concurrently, we can no longer per\u00adform computation \nwhile waiting for IO operations to com\u00adplete, and we cannot abandon waiting for an IO operation once \nwe have started it. AC addresses the problems by providing the async and do..finish constructs to allow \nmultiple IO operations to be issued (Section 2.1), and providing the cancel construct for block-structured \ncancellation of waiting (Section 2.2). 2.1 The async and do..finish Constructs The async and do..finish \nconstructs provide a mech\u00adanism to switch away from an operation if it blocks, and to resume itsexecution \nafterit unblocks. Figure2gives anex\u00adample, expanding the earlier LookupAC function to consult a series \nof servers and to report an error if the results dif\u00adfer. The LookupOneAC function performs a single \nlookup, returning the resulting address. The LookupAllAC func\u00adtion takes an array of channels, and makes \na series of calls to LookupOneAC to perform each lookup. The async within the loop indicates that execution \ncan continue to the next iteration if a given LookupOneAC call blocks, and the do..finish indicates that \nexecution must block at finish until all of the async work is done. The example satis.es the synchronous \nelision property: if the new con\u00adstructs are ignored, then it becomes a simple sequential look up on \neach server in turn. There are a number of design choices: Starting work asynchronously. First, what \ncode runs when reaching a statement async S e.g., S itself, or the contin\u00aduation of the async S statement \n(as in AME [19]), or are they interleaved(asinX10[7])?InAC,execution proceeds immediately into S, without \nintroducing parallel execution. This feature follows both from the serial elision property, and from \nour conceptual desire tokeep separate the support for asynchronyand parallelism. A consequence of this \ndesign choice is that, in Figure 2, the code inside the async statement can simply read i to obtain the \nchannel to work on: the code inside the async statement runs directly at the start of each loop iteration \nbefore i is modi.ed by the next execution of the loop header. The example also exploits the fact that \nasync does not introduce parallelism: when LookupOneAC returns, there is no need for synchronization \non the accesses to the local variables result, first result, or seen first.We do not need, for instance, \nto introduce locking on these variables, or to use futures to communicate values from LookupOneAC to \nits caller. If a local variable is declared within an async statement, then it is private to each invocation \nof this statement (unlike the example in Figure 2 where the variables are shared be\u00adtween the invocations \nof the async statements). Blocking within asynchronous work. The next design choice is what happens when \ncode within async S blocks. In AC, when S .rst blocks, execution resumes at the con\u00adtinuation of the \nasync statement. In this respect async can be seen as catching the blocking of the code within it, and \nproviding the surrounding code with an opportunity to start additional IO operations, or to do computation \ninstead. In Figure 2, the continuation of the async statement is the loop header which proceeds to the \nnext iteration. When calling a function that might block, the program\u00admer needs to anticipate the possibility \nthat other code may int LookupFirstAC(NSChannel_t *cs[], int nc, char *name, int *addr) { bool seen_first \n= false; queries: do { for (int i = 0; i < nc &#38;&#38; !seen_first; i++) { async { if (LookupOneAC(cs[i], \nname, addr) == OK) { seen_first = true; cancel queries; } } } } finish; return (seen_first ? OK : CANCELLED); \n } Figure 3. Querying a set of name servers concurrently, and returning the .rst reply. run before the \ncallee returns. We follow a convention that all possibly-blocking functions have an AC suf.x on their \nname. This convention is true for primitive send/receive op\u00aderations, and for examples such as LookupAllAC.Follow\u00ading \nthis convention ensures that a caller is aware that execu\u00adtion might switch to elsewhere in the thread \nwhile waiting. For example, in Figure 2, the value of local variable i may be updated while a call to \nLookupOneAC is blocked, so if the original value is needed then it should be saved before the call. Our \nconvention of highlighting AC operations corre\u00adsponds to rules from atomic by default programming mod\u00adels \nsuch as AME [2, 19] and TIC [30] that operations that are not atomic should include annotations at the \nfunction s de.nition, and at each call-site. Our convention could be en\u00adforced by static checks, if desired. \nA simple, conservative, approach would be to issue a warning if an AC function is called from a non-AC \nfunction. Synchronization. The .nal design choice is how to syn\u00adchronize with async operations. The do..finish \ncon\u00adstruct provides this form of synchronization: execution does not proceed past the do..finish until \nall of the asyn\u00adchronous work started inside it has completed. In Figure 2 the do..finish requires that \nall of the LookupOneAC calls have .nished before LookupAllAC can return. From the point of view of LookupAllAC \ns caller, blocking at the end ofa do..finish is the same as blocking at an IO operation: the call can \nbe placed within an async, and other work can be started if the call blocks (e.g., a different LookupAllAC \nfor some other name). Rules for starting asynchronous work. An async state\u00adment must occur statically \nwithin do..finish. It is incor\u00adrect to write unbalanced code such as: void StartAsync(int x) { async \nf(x); } This design choice follows from our focus on implemen\u00adtations for systems software in C/C++. \nWith predictable lifetimes for data used for synchronization: (i) a cactus\u00adstack [16] can be used, rather \nthan requiring a more general heap-allocated structure, and(ii)as usual, a callee can safely access stack-allocated \ndata passed to it, irrespectively of whether or not anyof the calls on the stack are asynchronous. (CILK \nhas a similar rule in that a function implicitly syn\u00adchronizes with anyparallel work that it has spawned \n[13].) Integration with threads. Although async does not in\u00adtroduce parallelism, our implementations \nare nevertheless integrated with OS threads. This integration enables scenar\u00adios where a multi-threaded \nserver handles connections to dif\u00adferent clients in different threads, or where a function starts a thread \nexplicitly to perform work after the function returns (such as a variant of StartAsync, above). The runtime \nsystem provides concurrency-control primi\u00adtives such as mutexes and condition variables. These prim\u00aditives \ncan be used between pieces of async work in the same OS thread, or between different OS threads. Blocking \non concurrency-control primitives is handled in exactly the same way as blocking on IO: the OS thread \ns execution can switch to a different piece of work. This work can either be the continuation of an enclosing \nasync statement, or it can bea pieceofwork that has become unblocked.Work retains af.nity to the OS thread \nthat started it. The primitive mes\u00adsage send/receive operations are themselves thread-safe. 2.2 Cancellation \nThe async and do..finish constructs let the program\u00admer start multiple IO operations, and they let the \nprogram\u00admer overlap computation with communication. However, these constructs do not recover all of the \nexpressiveness of the low-level callback-based APIs; in particular, we also wish to be able to stop waiting \nfor an IO operation once we have started it. AC provides a cancel command to allow a program to stop \nwaiting for an IO operation. Cancellation is somewhat analogous to thread interruption in Java: it causes \noperations that are blocked on IO to be unblocked. Figure 3 shows how cancellation can be used to write \na LookupFirstAC function that queries a set of name servers, returns the .rst response, and then cancels \nthe re\u00admaining queries: the loop is within a do..finish la\u00adbeled queries , and a cancel queries command \nis executed when the .rst response is received. Cancella\u00adtion causes any blocked LookupOneAC calls within \nthe do..finish to become unblocked, and then to return CANCELLED. The do..finish block behaves as usual: \nonce all of the async work started within it has .nished, execution can proceed to the end of LookupFirstAC. \nWhen used with a label, cancel must occur statically within the do..finish block that the label identi.es. \nIf cancel is used without a label then it refers to the closest statically enclosing do..finish block. \nIt is an error for cancel to occur without a statically enclosing do..finish block This requirement makes \nit clear ex\u00adactly which block of operations is being cancelled: one can\u00ad int LookupWithTimeoutAC(NSChannel_t \n*cs[], int nc, char *name, int *addr, int t) { int result; timeout: do { async { result = LookupFirstAC(cs, \nnc, name, addr); cancel timeout; } async { SleepAC(t); cancel timeout; } } finish; return result; \n } Figure 4. Addinga timeout around anexistingACfunction. not call into one function and have it poison \nthe caller s function unexpectedly by using cancellation internally. Semantics of cancellation. Care \nis needed when cancella\u00adtion involves operations with side-effects. Even for a read\u00adonly operation such \nas LookupOneAC, there is a question of the state of the channel after cancellation. For example, what \nwill happen if cancellation occurs after a message has been sent, but before a response has been received? \nWhat will happen if a response subsequently arrives can it be confused with the response to a different \nmessage? Both on Barrel.sh and on MicrosoftWindows, we follow a convention that we term exact cancellation \n: upon can\u00adcellation then either(i)a call returns CANCELLED, without appearing to perform the requested \noperation, or(ii)the op\u00aderation is performed and the function returns OK. In particu\u00adlar, an OK result \nmay be seen, even after executing cancel, if an IO operation was completed by a device concurrently with \ncancellation being requested by software. This convention represents a division of work between the application \nprogrammer and the implementer of the IO library: the IO library guarantees exact cancellation in its \nown functions, but the application programmer is responsi\u00adble for providing exact cancellation in the \nfunctions that they write. The programmer must shoulder this responsibility be\u00adcause the correct behavior \ndepends on the semantics of the operations that they are writing e.g., whether or not a com\u00adpensating \noperation must be performed and, if so, exactly what. To allow compensating code to be written without \nit\u00adself being cancelled, AC lets functions be marked non\u00adcancellable and, on Barrel.sh, we provide non-cancellable \nvariants of all of the message passing primitives. In Sec\u00adtion 4 we show how these non-cancellable primitives \nare themselves implementedover theAC runtime system. Composable cancellation. Consider the example in \nFig\u00adure 4 of adding a timeout to a LookupFirstAC call. The .rst async starts the LookupFirstAC request. \nThe sec\u00adond async starts a timer. Whichever operation completes .rst attempts to cancel the other. This \nblock-structured ap\u00adproach lets programs use cancellation in a composable way: the cancellation triggered \nin LookupWithTimeoutAC propagates into both async branches (and recursively into their callees, unless \nthese are non-cancellable). Unlike systems that target cancellation requests at indi\u00advidual operations,AC \nletsa caller cancela setof operations without being able to name them individually. Note that, in the \nLookupWithTimeoutAC function, the return value is always taken from LookupFirstAC. There are three cases \nto consider in checking that this re\u00adturn value is correct. First, if LookupFirstAC returns OK, then \nexact cancellation semantics mean that the lookup has been performed and the result can be passed back \nas usual. Second, if the SleepAC timeout expires and can\u00adcels LookupFirstAC, then the resulting CANCELLED \nre\u00adturn value is correct. Finally, if LookupWithTimeoutAC is itself cancelled by its caller, then the \nresult of the call to LookupFirstAC determines the overall result of the LookupWithTimeoutAC operation. \n 3. Operational Semantics In this section we de.ne an operational semantics for a core language modeling \nasync, do..finish and cancel (Figure 5). The aim is to de.ne precisely their interaction. For instance, \nexactly when execution can switch between one piece of code and another, and exactly how execution proceeds \nat the point when a cancel command is executed (e.g., if new IO is subsequently issued, or if further \nasync commands are run). We start from a simple imperative language with global mutablevariables.We modelIOvia \nsend/recv operations on message channels. The semantics of message channels (which we de.ne below) are \nbased on those of the Barrel.sh OS.For simplicity, we treat only the special caseof cancel without a \nlabel. Since we focus on the behavior of the AC constructs, we keep the remainder of the language simple: \nwe omit functions; channels carry only integer values; all names are global; and variable names are distinct \nfrom chan\u00adnel names. The constructs for boolean conditionals BExp and nu\u00admerical expressions NExp are \nconventional. The symbol x ranges over variable names, r ranges over message channel names, and v ranges \nover values. A store s is a mapping fromvariable names tovalues, andabuffer state \u00df is a map\u00adping from \nchannel names to lists of values that represent a channel sbuffered contents. Commands. C and D range \nover commands. Many are conventional: skip, assignment, sequencing, conditionals, and while. The command \nasync C models the async construct. The command pool f CS generalizes the do..finish construct, representing \na pool of commands (multi-set CS )that are eligible to continue within the do..finish. The .ag f indicates \nwhether the do..finish is active, or whether it has been cancelled. The source construct do C De.nitions \n b . BExp = ... C,D . Com = F e . NExp = ... | x := e x . Var | C; D r . Chan | if bthen C else D v . \nValue = ... | while b do C s . Store = Var . Value | async C \u00df . Buffers = Chan . [Value] | pool (ACTV \n| CNCL) CS | cancel E = [] |E; C F . FinalCom = skip | pool f E ::CS | try IO else D | IO EC = EC; C \n | pool ACTV EC::CS IO . IOCom = send e to r | pool CNCL E::CS | recv x from r Top-level transitions \n(s, , pool f CS ). (s ' , ,C ' )(s, \u00df, C).(s ' ,\u00df ' ,C ' ) ' (T-Eval) (s, \u00df, pool f CS ).(s ,\u00df,C ' \n) \u00df(r)= vs pushleft (s(e),vs,vs ' ) \u00df(r)= vs popright(vs,vs ' ,v) (T-Send) (T-Recv) (s, \u00df, E[ send e \nto r ]).(s, \u00df[r .vs ' ], E[ skip ])(s, \u00df, E[ recv x from r ]).(s[x .v],\u00df[r .vs ' ], E[ skip ]) ' (s, \n\u00df, E[ IO ]).(s ' ,\u00df , E[ skip ]) (T-Try-IO) (s, \u00df, EC[ try IO else D ]).(s, \u00df, EC[ D ]) (T-Try-Cancel) \n(s, \u00df, E[ try IO else D ]).(s ' ,\u00df ' , E[ skip ])  Big-step evaluation of commands F . FinalCom '' \n(s, pool f CS ,C). (s ' , pool f CS ,C ' ) (Final) (s, p,x := e).(s[x .s(e)], p, skip) (Assign) (s, \np,F). (s, p,F) ' ''' '' (s, p,C). (s ' ,p , skip)(s ' ,p ,D). (s '' ,p ,D ' ) (s, p,C). (s ' ,p ,C ' \n) C skip = (Seq-1) (Seq-2) '''' ' ''' (s, p,C; D). (s ,p ,D ) (s, p,C; D). (s,p ,C ; D) ' ' s(b)= true \n(s, p,C). (s ' ,p ,C ' ) s(b)= false (s, p,D). (s ' ,p ,D ' ) (If-1) (If-2) '' '' (s, p, if b then C \nelse D). (s,p ,C ' ) (s, p, if b then C else D). (s,p ,D ' ) ' s(b)= true (s, p,C; while b do C). (s \n' ,p ,C ' ) s(b)= false (While-1) (While-2) (s, p, while b do C). (s ' ,p ' ,C ' ) (s, p, while b do \nC). (s, p, skip) ' ''' (s, p,C). (s ' ,p , skip) (s, pool f CS ,C). (s ' , pool f CS ,C ' ) C = skip \n(Async-1) (Async-2) '' '''' (s, p, async C). (s,p , skip)(s, pool f CS , async C). (s, pool fC ::CS , \nskip) '' ' (s, pool f CS ,C). (s ' , pool f CS ,C ' ) C skip = (s, p, pool f \u00d8) . (s, p, skip) (Pool-1) \n(Pool-2) ' '' (s, p, pool fC::CS ). (s, p, pool fC ::CS ' ) ' ' ' '''' ) (s, pool f CS ,C). (s ' , pool \nf CS , skip)(s ' , p, pool f CS ' ). (s '' ,p ,C '''' '' ) (Pool-3) (s, p, pool fC::CS ). (s ,p ,C (s, \npool f CS , cancel).(s, pool CNCL CS , skip) (Cancel) Figure 5. Operational semantics. finish is syntactic \nsugar for pool ACTV {C} and, intu-ceives a value from channel r and stores it in variable x. The itively, \nthe multi-set CS is used to accumulate asynchronous send/recv operations model non-cancellable IO. Can\u00adwork \nthat is started within a given do..finish. The com-cellable IO is modeled by a try IO else D command \nmand cancel triggers cancellation of the enclosing pool. where IO ranges over send/recv operations. D \nis a can- The command send e to r sends the value of expres-cellation action which is executed if the \nIO operation is can\u00adsion e on channel r. The command recv x from r re\u00ad celled. D might, for instance, \nupdate a variable to indicate that cancellation has occurred. Finally, we require that a program initially \nhas the form pool ACTV {C}. This requirement ensures that the notion of enclosing pool is always de.ned \nwithin the body of the program C. Top-level transitions. We de.ne a transition relation. be\u00adtween states \n\\s, \u00df, C).We call these top-level transitions , and each step either models the execution of a piece \nof C until it next blocks, or it models an IO operation or the can\u00adcellation of an IO operation. Execution \ntherefore proceeds as a series of . transitions, interspersing computation and IO. The rule (T-Eval) \nmodels execution of a command via the big-step relation . (de.ned below). Note that the rule takes the \nentire program as a command, rather than extracting part of it from a context. The rules ensure that \nthe top-level command is either a pool (if execution is not yet complete), or that it has been reduced \nto skip (in which case no further applications of (T-Eval) can occur). The states for the . transitions \ninclude a current pool component in place of the messagebuffers \u00df.In thehypothesisof(T-Eval) we leave \nthe current pool blank ( ) because that component of the state is not accessed when the command itself \nis a pool, as in the caseof(T-Eval).Formally, the blank  canbe replaced with an arbitrary pool (even \ntwo different pools on the two sides of thehypothesis). The remaining four top-level transition rules \nmodel IO and cancellation of IO. We de.ne these rules in terms of execution contexts E and cancelled-execution \ncontexts EC. Within an ordinary execution context, the hole [] can oc\u00adcur on the left hand side of sequencing, \nand at any com\u00admand within a pool (we write C::CS to decompose a pool by selecting an arbitrary element \nC from it, leaving the re\u00admainder CS ).Withina cancelled-execution context, the hole must occur within \na cancelled pool (either directly, or with intermediate non-cancelled pools). (T-Send) selects a send \ncommand in an execution con\u00adtext, and pushes the value being sent onto the left hand end of the message \nbuffer named by r. We de.ne the relation ' pushleft (e, vs,vs ' ) to be true iff the list vs is obtained \nby pushing e on the left hand end of vs. (T-Recv) selects a recv command in an execution context, and \nremoves the value be\u00ading received from the right hand end of the message buffer ' named by r. The relation \npopright (vs,vs ,v ' ) is true iff the ' list vs can be decomposed by taking v from the right and leaving \nvs ' . Hence, this rule can apply only when vs is non\u00adempty. (T-Try-IO) allows an IO command to be performed \nwithin a try statement in an execution context. The try is discarded if the IO completes. Finally, (T-Try-Cancel) \nal\u00adlows a try IO else D command to be reduced to D if it occurs within a cancelled-execution context. \nEvaluation of commands. We de.ne a big-step struc\u00adtural operational semantics for commands. A transition \n\\s, p,C). \\s ' ,p ' ,C ' ) means that command C en\u00adclosed by pool p with variable state s evaluates to \nleave ' command C ' , with modi.ed pool p and state s ' . The pool may be modi.ed, for instance, by \nadding commands to it if C spawns asynchronous work that blocks. The . transition relation embodies a \nbig-step semantics: it models the complete execution of C until it is .nished ' (C = skip), or until \nC next blocks. This design cap\u00adtures our decision tokeep theAC constructs for controlling asynchrony \nseparate from constructs for parallel execution: a small-step semantics would need a mechanism to prevent \ninterleaving between multiple pieces of work that have been started asynchronously. (An earlier small-step \nversion of our semantics attempted to control interleaving by marking a designated active command ; however, \nit was cumbersome to ensure that the marker was moved in a way that provided the serial elision property.) \nIn the de.nition of ., the rule (Final) handles skip, try, send, and recv. No further evaluation is possible \nfor these .nal commands: execution is complete in the case of skip, and has blocked in the other cases. \nThe rule (Assign) handles assignment, by updating the state and leaving skip. The rule (Seq-1) handles \nsequencing when the .rst com\u00admand in the sequence evaluates to skip. The rule (Seq-2) handles sequencing \nwhen the .rst command blocks; the se\u00adquence as a whole blocks. The rules (If-1), (If-2), (While-1) and \n(While-2) are conventional. The rule (Async-1) handles async commands that run to completion: async C \nruns to completion if C does. This rule re.ects our design decision to run the body of an async command \nbefore running its continuation, and helps to provide the serial elision property. The rule (Async-2) \nhandles async C commands where C blocks: C runs asfar as C ' , this remainder is then put into the pool, \nand async C as a whole evaluates to skip instead of blocking. There are three rules for pools. The .rst \n(Pool-1) reduces a pool that has emptied to skip. The second (Pool-2) takes a command C from a pool and \nevaluates C until it blocks ' (leaving C =skip)and is put back into the pool. The third (Pool-3) takes \na command C from a pool, evaluates it to completion (leaving skip), and then continues evaluating the \nmodi.ed pool. Collectively, these rules allow a top-level transition under (T-Eval) to execute any of \nthe commands from within a set of nested pools. The .nal rule is (Cancel); a cancel command simply sets \nthe .ag on the current pool to be CNCL. Properties. We brie.y state properties of the semantics (for \nbrevity, we omit the proofs, which are typically routine inductions on derivations): ' If \\s, p, pool \nf CS ). \\s ' ,p ' ,C ') then p = p . That is, evaluating one pool has no effect on the surround\u00ading pool, \neither in terms of cancellation or the addition or removal of commands. This property is why we omit \na sur\u00adrounding poolin thehypothesisof(T-Eval).  Let ae(C) be the asynchronous elision of command C, \napplied recursively to commands and leaving them un\u00adchanged except that ae(async C)= ae(C). If com\u00admands \nCS do not include send or recv operations and \\s, \u00df, pool f CS ).\\s ' ,\u00df ' ,C ' ) then there is a transi\u00adtion \n\\s, \u00df, ae(pool f CS )).\\s ' ,\u00df ' , ae(C ' )). That is, the use of async does not affect the behavior \nof a program that does not block; this follows our informal serial elision property from the introduction. \n Let ce(C) be the cancellation elision of command C, applied recursively to commands and leaving them \nunchanged except that ce(cancel)= skip and that ce(pool f CS )= ce(pool CNCL CS ). If commands CS do \nnot include try (i.e., they are non-cancellable) and \\s, \u00df, pool f CS ).\\s ' ,\u00df ' ,C ' ) then there is \na transi\u00adtion \\s, \u00df, ce(pool f CS )).\\s ' ,\u00df ' , ce(C ' )) That is, the use of cancel does not affect \nthe behavior of a pro\u00adgram in which the IO operations are non-cancellable.   4. Implementation In this \nsection we discuss our implementations of AC. We discuss how the core language features are built via \na mod\u00adi.ed compiler (Section 4.1) or via C/C++ macros (Sec\u00adtion 4.2). Finally, we show how to integrate \ncallback-based asynchronous IO withAC (Section 4.3). 4.1 Clang/LLVM Implementation Our .rst implementation \nis based on the Clang/LLVM tool-chain (v2.7). We de-sugar async code blocks into async calls to compiler-generated \nfunctions. We do this de-sugaring by translating the contents of the async state\u00adment into an LLVM code \nblock (a form of closure added in LLVM as an extension to C). At runtime, the implementation of do..finish \nand async is based on a cactus stack with branches of the stack representing async operations that have \nstartedbut not yet completed. In our workloads, many async calls complete without blocking (e.g., because \na channel already contains a message when a receive operation is executed). Therefore, we defer as much \nbookkeeping work as possible until an async call actually does block (much as with lazy task creation \n[26] in which the creation of a thread is deferred until an idle processor is available). In particular, \nwe do not update any runtime system data structures when making an async call, and we allow the callee \nto execute on the same stack as the caller (rather than requiring a stack switch). To illustrate this \ntechnique, consider the following example: void main(void) { do { async as1(); } finish; } Figure 6(a) \nshows the initial state of the runtime sys\u00adtem within the do..finish block. Associated with each thread \nis a run queue of atomic work items (AWIs), which Thread Finish block (FB) Stack 1 Run queue Current \nFB  (a) Initial execution within main: the FB structure is used to implement a do..finish block and \nis stack-allocated. Thread Finish block (FB) Stack 1 Run queue Current FB CComEn ACTV ount = pletion \nAWI closing 0 FB First Last  (b)Within an async call to as1: the existing stack is used. Thread Finish \nblock (FB) Stack 1 Run queuemain as1 AWI1 Current FB stub Stack 2 CComEn ACTV ount = pletion AWI closing \n1 FB First Last  (c) If as1 blocks then main s execution is resumed on a fresh stack (Stack 2), and \nthe return address from as1 is updated. Thread Finish block (FB) Stack 1 Run queue main as1 AWI1 Current \nFB stub CComEn ACTV ount = pletion AWI closing 1 FB First Last  (d) Execution reaches the end of the \ndo..finish. Thread Finish block (FB) Stack 1 Run queuemain as1 AWI1 Current FB stub CComEn ACTV ount \n= pletionclosing 1 AWI FB First Last  (e) AWI1 is resumed, and added to the run queue. Thread Finish \nblock (FB) Stack 1 Run queueCurrent FB CComEn ACTV ount = pletion AWI closing 0 FB First Last  (f) \nThe do..finish block runs to completion. Figure 6. Runtime system data structures. Changes are shaded \nat each step. represent pieces of work that are ready to run when the thread becomes idle. Concretely, \nan AWI is simply a saved program counter, a stack-pointer, and a thread ID for the thread that created \nthe AWI. To reduce locking overheads, the run queue is structured as a pair of doubly linked lists, one \nthat is accessed without concurrency-control by the thread itself, and a second that is accessed by other \nthreads (e.g., when anAWI incrementsa semaphore, then the thread running that AWI may need to the access \nthe run queue for anAWI thatwas blocked on the semaphore). In addition to the run queue, each thread \nhas a current FB that identi.es the do..finish block that it is within. Each FB (Finish Block) structure \nis stack-allocated in the frame where the do..finish block is entered; the se\u00admantics of do..finish mean \nthat this function can re\u00adturn only once the block is complete. The FB has a can\u00adcelled/active .ag (initially \nACTV), a pointer to the FB struc\u00adture for the dynamically enclosing FB, a count of the number of asynchronous \ncalls that have been startedbut not yet .n\u00adished,a reference toa special completionAWI (which we describe \nbelow), and a doubly-linked-list holding(i) func\u00adtions to execute if the FB is cancelled, and(ii)FBs \nfor any do..finish blocks dynamically nested within this one. In the .gure, the list is empty. In the \nexample, execution starts with an async call to as1 (Figure 6(b)). A new stack frame is allocated in \nthe usual way; if as1 were to return normally then execution would simply continue after the asynchronous \ncall. However, if as1 blocks (Figure 6(c)), then the runtime system (i) increments the count of blocked \nitems in the enclosing FB, (ii) allocates a new AWI representing the blockedwork, placing thisAWIattheendofthe \nstack frame for as1, and(iii)walks the stack to .nd the closest enclosing call site (if any) corresponding \nto an async call whose continuation has not been resumed. A compiler-generated table of return addresses \nis used to identify async calls. If there is an async call then the return address from the callee s \nstack frame is rewritten to go to a stub function (de\u00adscribed below), and a new stack is allocated for \nthe caller. In our implementations we reserve 1MB of virtual address space for each stack, and within \nthis space we lazily allo\u00adcate 4KB pages of physical memory using a guard page. In the .gure, Stack2is \nallocatedandexecution resumes within main onthenew stack.Toallowexecutiontomove between stacks, a new \ncalling convention is used for asynchronous calls:(i) all registers are treated as caller-save at an \nasyn\u00adchronous call site, and (ii) a frame pointer is used for all functions containing asynchronous calls. \nThe .rst rule al\u00adlows execution to resume after the call without needing to recover values for callee-save \nregisters, and the second rule allows the resumed caller to execute on a discontiguous stack from the \noriginal call (e.g., in Figure 6(c)) by restoring the original frame pointerbut usinga fresh stack pointer. \nIf a function blocks when there are no async calls then execution continues by resuming an AWI from the \ncurrent thread s run queue. If the run queue itself is empty then exe\u00adcution blocks for an asynchronous \nIO operation to complete. In the example, execution continues in main and reaches the end of the do..finish \n(Figure 6(d)). At this point the runtime system checks whether(i)the FB has any async calls which are \nnot yet complete (i.e., count=0), and(ii)if the count is zero, whether execution is on the original stack \nthat entered the do..finish. In this case the count on the current FB is non-zero, so execution blocks. \nFigure 6(e) shows the situation when the IO performed within as1 has completed: the suspended AWI is \nadded to the run queue, and is resumed by the thread. The func\u00ad // Scheduling void Suspend(awi_t **xp); \nvoid SuspendUnlock(awi_t **xp, spinlock_t *l); void Schedule(awi_t *x); void Yield(); void YieldTo(awi_t \n*x); // Cancellation bool IsCancelled(); void AddCancelItem(cancel_item_t *ci, fn_t fn, void *arg); \nvoid RemoveCancelItem(cancel_item_t *ci); Figure 7. Low-level API for integrating asynchronous IO operations. \ntion as1 then completes, and returns to the stub func\u00adtion linked to the stack in Figure 6(c). The stub \nfunction re-examines the count .eld to check whether as1 was the last outstanding async function for \nthat FB: in this case the count is decremented to 0, and execution resumes outside the do..finish back \non Stack1 (Figure 6(f)). The completion AWI .eld is not used in this example. Its role is to ensure that \nexecution leaves a do..finish block on the same stack that entered it (in this case Stack 1). If the \nwork running on the original stack .nishes when the current FB s count is still non-zero then the completionAWI \nis initialized for the work immediately after the finish. Then, when the count reaches zero on another \nstack, execu\u00adtion is transferred to the completionAWI and hence back to the original stack. 4.2 Macro-Based \nImplementation In addition to our compiler-based implementation, we have developed an implementation \nbased on C/C++ macros that exploits existing extensions for de.ning nested functions. This implementation \nlets us use AC on platforms that are not supported by LLVM (e.g., the Beehive FPGA-based processor [34]). \nComparing the two implementations also lets us assess the advantages and disadvantages of including language \nfeatures to support asynchronous IO. There are two differences from the Clang/LLVM imple\u00admentation: First, \nsyntactically, the macro-based implemen\u00adtation uses ASYNC(X) to express an async statement con\u00adtaining \nstatements X, DO FINISH(X) for a do..finish containing X, and DO FINISH (lbl,X) for a block with label \nlbl. The DO FINISH macros de.ne blocks that start and end with calls to the AC runtime system. The ASYNC \nmacro de.nes a nested function that contains the contents of the async statement, and then it calls the \nAC runtime system to execute the nested function. The second difference is that the macro-based imple\u00admentation \ndoes not produce the compiler-generated tables to let us walk the stack, when blocking, to identify async \ncalls. We therefore investigated two alternative approaches at async calls:(i)eagerly allocatinga stack \nwhen making the async call; or(ii)pushing an explicit marker onto the stack during an async call, to \nenable lazy allocation of the stack only if the async call blocks. Eager allocation is rel\u00adatively simple \nto implement, however, as we show in Sec\u00ad Top half: synchronous AC functions, e.g. LookupResponseAC \nBottom half: callbacks from message system, e.g. LookupResponseBH Figure 8. IntegratingACwith callback-based \nmessages. tion 5, it incurs a performance cost of around 110 cycles per async call. Macro-based lazy \nallocation allows stack allocation itself to be made lazy, but still requires some ea\u00adger bookkeeping \nto initialize anAWI for the call s continua\u00adtion, and it requires an additional level of indirection \non each async call. It adds around 30 cycles overhead per async call, when compared with the compiler-integrated \nlazy im\u00adplementation.  4.3 Integrating Callback-Based IO withAC The AC runtime system provides a set \nof functions through which asynchronous IO operations interact with the new language constructs; these \nprovide a way to adapt existing callback-based abstractions to a form where they can be invoked fromAC. \nFigure7 shows the operations: Scheduling. The .rst set of operations is used to control scheduling ofAWIs. \nSuspend(xp) ends the currentAWI, and initializes *xp witha pointer toa newAWI for the con\u00adtinuation of \nthe Suspend call. In practice the AWI is al\u00adlocated in the stack frame of the Suspend call, as in Fig\u00adure \n6(c). SuspendUnlock is the same as Suspend, ex\u00adcept that a given spinlock is released after blocking \n(we illus\u00adtrate its use below). Schedule(x) adds the AWI pointed to by x to the run queue of the thread \nto which the AWI belongs. Yield ends the current AWI, and adds the con\u00adtinuation of the Yield immediately \nback to the run queue of the current thread. Finally, YieldTo(x) is a directed yield: If x belongs to \nthe current thread, then the continu\u00adation of YieldTo is put on the run queue, and execution proceeds \nimmediately to theAWI to which x refers. If x be\u00adlongs to a different thread, then YieldTo(x) is equivalent \nto Schedule(x). Cancellation. The second set of operations in Figure7 in\u00adteracts with cancellation. This \nbasic abstraction is a cancel\u00adlation item which is a callback function to be run when can\u00adcellation is \ntriggered. These callbacks are registered when cancellable operations are started, and de-registered \nwhen cancellable operations complete. The cancellation items are stored on the doubly-linked-list held \nin the FB structure for the enclosing do..finish block. These callbacks are run when the cancel statement \nis executed. Example. We have developed versions of AC for mes\u00adsage passing on Barrel.sh, and for asynchronous \nIO more enum { EMPTY, BH_WAITING, TH_WAITING, TH_CANCELLED } rx_state; typedef struct { spinlock_t \nspinlock; // Lock to protect other fields enum rx_state state; // Receiver record state ac_lock_t bh_lock; \n// Lock to order BH execution ac_lock_t th_lock; // Lock to order TH execution awi_t *rx_awi; // Saved \nTH context int addr; // Message payload } LookupResponse_t; // Bottom-half function to execute on incoming \nmessage: static void LookupResponseBH(NSChannel_t *c, int addr) { LookupResponse_t *r = ...; LockNAC(&#38;r->bh_lock); \n// Wait for previous BH to complete SpinlockAcquire(&#38;r->spinlock); r->addr = addr; if (r->state \n== EMPTY) { // No top-half waiting  r->state = BH_WAITING; SpinlockRelease(&#38;r->delivery_lock); } \nelse { // Pass control to top-half YieldTo(r->rx_awi); }} // AC top-half function to receive a message: \n int LookupResponseAC(NSChannel_t *c, int *addr) { LookupResponse_t *r = ...; int result = OK; // Wait \nfor previous TH to complete if (LockAC(&#38;(r->th_lock)) == CANCELLED) return CANCELLED; SpinlockAcquire(&#38;r->spinlock); \n if (r->state == EMPTY) { // No BH present: wait r->state = TH_WAITING; cancel_item_t ci; AddCancelItem(&#38;ci, \n&#38;CancelRecv, r); SuspendUnlock(&#38;r->rx_awi, &#38;r->spinlock); // Resumed here after delivery \nor cancellation RemoveCancelItem(&#38;ci); if (r->state == TH_CANCELLED) { result = CANCELLED; // We \nwere cancelled goto done; }} *addr = r->addr; // Extract message contents Unlock(&#38;r->bh_lock); // \nAllow next BH callback  done: r->state = EMPTY; SpinlockRelease(&#38;r->spinlock); Unlock(&#38;(r->th_lock)); \n// Allow next TH operation return result; } static void CancelRecv(LookupResponse_t *r) { SpinlockAcquire(&#38;r->spinlock); \nif (r->state == TH_WAITING) { r->state = TH_CANCELLED; Schedule(r->rx_awi); } else { SpinlockRelease(&#38;r->spinlock); \n}} Figure 9. Interfacing Barrel.sh callbacks withAC. generally on Microsoft Windows. For brevity we \nfocus on receiving a message on Barrel.sh, showing how the syn\u00adchronous AC operation is built over the \ncallback-based in\u00adterface sketched in the introduction. Other functions follow a similar pattern. Figure \n8 shows the overall approach. For each message channel, we record a buffered message and a state. These \nare updated by a bottom-half function that runs as a call\u00adback, anda top-half function that runs asa \nblockingAC operation. The callback waits until the buffer is empty, and then deposits the next message. \nThe top-half function waits untila messageisavailablein thebuffer. Figure 9 shows a simpli.ed version \nof the implementa\u00adtion (the logic follows the full version, but we use shorter names, and omit some casts \nand function parameters). The LookupResponse t structure provides the buffering. A spinlock protects \naccess to the other .elds. The state .eld records whether buffered data is waiting from a bottom\u00adhalf \nfunction (BH WAITING), whether a top-half function is blocked waiting for data (TH WAITING), or whether \na top-half function has just been cancelled(TH CANCELLED). Two locks serialize executions of the top-half \nand bottom\u00adhalf handlers, allowing only one of each kind to execute at any given time on a given buffer. \nThe rx awi .eld stores the saved context when a top-half function waits. The addr .eld carries the buffered \nmessage payload (in this case the address returned from the name-service lookup). LookupResponseBH is \nthe example bottom-half func\u00adtion. It waits on the bottom-half lock, and then updates the buffered state. \nIt uses a directed YieldTo to transfer exe\u00adcution directly to the top-half, if one was waiting. LookupResponseAC \nis the example top-half function. Itwaitsonthe top-half lock, consumesabuffered messageif present, and \notherwise marks the state as TH WAITING be\u00adfore suspending itself. If cancellation occurs while the top\u00adhalf \nis waiting, then the CancelRecv function is executed. This function tests whether or not a message has \nbeen de\u00adlivered. If no message was delivered, then CancelRecv updates the state to TH CANCELLED and then \nresumes the top-half code (note that the spinlock is held from within CancelRecv to the end of the top-half \nfunction ensuring that the state is reset to EMPTY before the next message can be delivered).  5. Performance \nEvaluation In this section weevaluate the performanceofAC.We .rst look at microbenchmarks to show the \noverhead of individ\u00adual AC operations (Section 5.1). We then measure the per\u00adformanceofAC using largerexamples \non Barrel.sh and on Microsoft Windows. On Barrel.sh, we use AC in the im\u00adplementation of a low-level \ncapability management system (Section5.2).On MicrosoftWindows,weuseACina series of IO-intensive applications \n(Section 5.3). We use an AMD64 machine with 4 quad-core proces\u00adsors (Sections 5.1 and 5.2), and an HP \nworkstation with an Intel Core 2 Duo processor (Section 5.3). All results use optimized code(-O2). We \nvalidated that our modi.ed compiler s performance is consistent with the baseline com\u00adpiler and with \ngcc 4.3.4. Experiments are typically run with 10 000 iterations, using the .rst 9000 as warm-up and re\u00adporting \nresults from the .nal 1000. In each case we con\u00ad.rmed that this delayavoided start-upeffects.We report \nme\u00addian values, and give 5-95%-ile ranges for any results with signi.cant variance. 5.1 Microbenchmarks \nWe compared the performance of(i)a normal function call, (ii)an async call to an empty function, and(iii) \nan async call to a function that yields i.e., blocking, and then imme\u00addiately unblocking. We examined \nthe Clang/LLVM-based implementation which uses lazy bookkeeping, and the two macro-based implementations. \nThe test makes calls in a tight loop, and we measured the cycles needed per call: Call Async Yield Lazy, \ncompiler-integrated 8 10 245 Lazy, macros 8 44 269 Eager, macros 8 120 247 This kind of low-level timing \nis inevitably affected by the processor implementation and compilation details: the re\u00adsults con.rm, \nhowever, that compiler-integrated lazy book\u00adkeeping allows async to be used with very low overhead when \nthe callee does not block, and that performing book\u00adkeeping lazily does not harm performance if a callee \ndoes subsequently block. The lazy, macro-based implementation performs slightly less well than the compiler-integrated \nim\u00adplementation. This result re.ects an additional level of indi\u00adrection that the macro-based implementation \nintroduces on each asynchronous call. We measured the performanceofa ping-pong microbench\u00admark between \nprocesses on different cores. We used the compiler-integrated implementationofAC. The results show the \ntime from sending a message from one core, until the corresponding response is received back on the same \ncore: Round trip latency/ cycles Callback-based API 1121 AC one side 1198 AC both sides 1274 AC withoutYieldTo \n1437 MPI (HPC-Pack 2008 SDK) 2780 We compared .ve implementations. Callback-based API uses the existing \nBarrel.sh callback-based messaging li\u00adbrary. This library provides a callback-based API which is built \nover shared memory on conventional systems, and which is implemented over hardware message passing on \nsystems such as the Intel SCC [20], The AC results show the cost of using AC on one or both sides of \nthe ping-pong test. The difference is less than 15% over the callback-based API.Tracing the code, the \nse\u00adquence of operations performed is essentially the same in the callback-based and AC variants: the \nuse of YieldTo stitches a bottom-half callback function directly to the top-half AC receive operation \nthat was waiting. Replacing YieldTo with a non-directed Schedule leads to a 1437\u00adcycle total cost. For \ncomparison we also ran an analogous shared-memory MPI ping-pong test on identical hardware using Microsoft \nHPC-Pack 2008, and found it to be over twice asexpensive asACboth sides.   (a) Low-latencycon.guration, \nunbounded spinning. (b) Default con.guration, brief spinning before pre-emption. Figure 10. Capability \nre-typing benchmark. 5.2 Capability Management on Barrel.sh Our second test uses AC within Barrel.sh. \nThe OS uses capabilities to control access to physical resources. Posses\u00adsion of a capability on a core \nconfers the right to perform a set of operations on the underlying resource without syn\u00adchronization \nwith other cores. The OS nodes use a 2-phase commit protocol to ensure that management operations on \ncapabilities are performed in a consistent order across all cores. This protocolis an ideal usage scenario \nforAC:itisa performance-critical part of the OS, where easily understood and maintainable code is desirable \nto deal with the complex\u00adity. Figure 10 shows the time to perform a capability opera\u00adtion. The protocol \ninvolves an initiating core sending mes\u00adsages to all the other cores, waiting for responses, and then \nsending a result back to the other cores. The .rst set of re\u00adsults, Figure 10(a), show an arti.cial con.guration \nin which processes spin without bound while waiting for incoming messages. This con.guration lets us \nfocus on the best-case performance of different implementations (in practice the OS would preempt processes \nwhen they have no incoming messages). We show four implementations. Seq uses synchronous communication: \nthe initiator contacts each other core in turn, waiting for a response before moving on. The implementa\u00adtionis \nsimplebut performanceis poor. Event istheexist\u00ading Barrel.sh implementation using manual stack-ripping: \nit comprises 19 callback functions which use5 different kinds of temporary data structure. It gives the \nbest performance, at the cost of code clarity in managing intermediate state. Async uses AC and follows \nthe structure of Seq while adding async statements to interact with each core (it uses a single function, \nand no temporary structures). Batch uses AC, but restructures the communication to send a batch of messages \nfollowed by waiting for a batch of responses. Both of these AC versions perform much better than Seq \nand scale similarly to Event . In Figure 10(b) we con.gure the system to preempt pro\u00adcesses while waiting \nfor incoming messages. Performance of Seq is much worse because a receiver is often not running when \na message arrives (note the log scale). The Event , Async and Batch implementations are indistin\u00adguishable: \nthe implementations using AC provide the same performance as the callback-based implementation, while \navoiding the need for manual stack-ripping.  5.3 IO on MicrosoftWindows We integratedAC with theexisting \nasynchronous IOfacili\u00adties on MicrosoftWindows. Disk workload. Our .rst test program is a synthetic disk \nworkload, modeling the behavior of a software RAID sys\u00adtem. The test can be con.gured to use Windows \nasyn\u00adchronous IO directly, or to use AC, or to use basic syn\u00adchronous IO. The test issues random reads \nto two Intel 25-M solid-state storage devices (SSDs), con.gured as RAID0, each with sustained read throughput \nof up to 250MB/s (we ran otherworkloads,but omit them for brevity because they showed similar trends \nin the performance of the different im\u00adplementations). The AC version uses ReadFileAC, keep\u00ading track \nof the number of requests that have been issued, and blocking when a limit is reached. Tracking IOs lets \nus control the depth of the pipeline of concurrent requests ex\u00adposed to the disk subsystem. The AIO implementation \nuses the callback-based IO interfaces directly; as in the exam\u00adple in the introduction, the AIO implementation \nneeds to be stack-ripped manually. Figure 11 shows the results for 4k and 64k IO block sizes respectively. \nTheACand AIO implementations achieve sim\u00adilar throughput. The implementation using synchronous IO is \nsubstantially slower. We compared the CPU consumption of the AC and AIO implementations. This experiment \nforms a sanity check thatAC s throughputdoesnot comeattheexpenseofvastly greater CPU consumption. For \n4k transfers the overhead ranges from 5.4% to 11.8%, while for 64k transfers we measuredupto9.8% moreCPUcycles(usermode+kernel \nmode) used by AC. As the pipeline depth increases the number of passes through the AC scheduler loop \ndecreases 20000 15000 10000 64K 4K 64K AC AIO Sync 4K Native:\u00a0AC Native:\u00a0AIO Managed F# C# AC\u00a0&#38;\u00a0AIO \n Throughput\u00a0MB/s CPU\u00a0time\u00a0ms/s Quotes\u00a0/s 5000 0 0 5000 10000 15000 20000 Clients (a) Throughput. 1 2 \n3 4 5 6 7 8 910 Pipeline depth\u00a0/\u00a02^x 1250 1000 750 500 Native:\u00a0AC Native:\u00a0AIO Managed F# C# AC\u00a0&#38;\u00a0AIO \n Figure 11. MicrosoftWindows random accessworkload. because each pass handles multiple completed requests. \nThis 250 mitigatingfactor meant that for 64k reads and 1024-request pipelines, we actually observed a \nlower CPU cost (-3.7%) forAC. Stock quote server. Our .nal test program is the stock quote server program \nused to illustrate the features in re\u00adcent version of the .NET framework for asynchronous pro\u00adgramming \n[32]. The server sends one message per second to a variable number of clients. We ran the server and \nclients on separate cores on the same machine. We increased the number of connections until system limits \nwere reached.We compared the performance of four single-core server im\u00adplementations: (i) an AC implementation, \n(ii) a C imple\u00admentation using asynchronous IO,(iii)a C# implementation using asynchronous IO, and(iv)an \nF# implementation us\u00ading asynchronous IO. TheAC, C#, and F# implementations all avoid stack-ripping; \nthe C implementation is written as stack-ripped callbacks that run in response to IO completion events. \nFigure 12(a) shows the throughput of the different im\u00adplementations, measuring the number of clients \nactually ser\u00adviced per second, as the number of client connections in\u00adcreases. TheAC implementation scales \nas well as the stack\u00adripped AIO implementation: for a server running on a sin\u00adgle core, both scale to \naround 18 000 clients (at which point system limits on network connections are reached). In con\u00adtrast, \nthe F# and C# clients are saturated at around 10 000 and8000 clients respectively. Figure 12(b) shows \nthe CPU consumption of the different implementations, measuring the milliseconds of CPU time consumed \nby the server process per second of elapsed time. The AC and AIO implementations have similar CPU con\u00adsumption, \nless than 1/5 of the consumption of the C# and F# implementations at 10 000 clients. We compared the \nperformance of these single-core server implementations with the performance of a server using multiple \nco-operating threads and synchronous IO. The multi-threaded server saturated at 4500 clients per core, \nsubstantially less than the18000 clients handledby theAC and AIO implementations. This difference in \nperformance 0 0 5000 10000 15000 20000 Clients (b) CPU consumption. Figure 12. Stock-quote server benchmark. \n was due to the synchronous IO operations performing more kernel-mode work than the asynchronous operations. \nWe examined why the F# and C# implementations differ in performance from the AC and AIO implementations. \nAll of these implementations are ultimately built on the same asynchronous IO interfaces to the OS kernel, \nand the dif\u00adferent performance comes from the user-mode parts of the implementations. There were two \nmain factors which con\u00adtributed approximately equally. First, the F# and C# imple\u00admentations use heap-allocated \ntemporary data structures to record information about pending IO operations. Allocating these adds to \npressure on the GC. Second, the F# and C# implementations rely heavily on pinning data buffers in memory \nso that the buffers are not moved by the GC. Pin\u00adning introduced additional work allocating and de-allocating \nthe GCHandle structures that are used to pin objects.  6. RelatedWork Our techniques build on many areas \nof related work; we structure this discussion around(i)frameworks for perform\u00ading asynchronous IO, (ii) \nimplementations of abstractions for parallel programming, (iii) languages based on mes\u00adsage passing, \nand(iv) techniques for cancellation of asyn\u00adchronous IO. Frameworks for asynchronous IO. The merits of \nthread\u00adbased and callback-based programming models are fre\u00adquently revisited. Lauer and Needham observed \nthat partic\u00adular forms of these models can be seen as duals: a program written in one model is essentially \nidentical to a program written in the other [23]. Ousterhout argued that threads are a bad idea for most \npurposes (in terms of using them cor\u00adrectly, as well as performance) [27]. Adya et al. argued that the \nidea of threads con.ates many related notions and there is value in using cooperative task management \nwithout manual stack management [3]; AC is inspired by this argu\u00adment, and keeps management of asynchronous \nIO within a thread separate from management of parallel work. Based on related arguments, von Behren \net al. suggested that many criticisms of threads were really due to the poor performance of early implementations \n[35]. Several techniques simplify asynchronous IO without re\u00admoving manual stack-ripping. Dabek et al. \ns libasync library helps manage event handlers state, and provides concurrency-control between handlers \n[9]. Elmeleegy et al. propose that asynchronous IO interfaces should operate syn\u00adchronously if a given \ncall can complete immediately [11]. Cunningham and Kohler show how to restructure asyn\u00adchronous IO interfaces \nto help link related operations [8]. Our work differs from these in avoiding stack-ripping. Grand central \ndispatch (GCD) schedules tasks within an application over thread pools(http://developer. apple.com/technologies/mac/snowleopard/ \ngcd.html).Typically, tasks run to completion and are de\u00ad.ned as a form of closure in Objective C. Manual \nstack\u00adripping can be mitigated by nesting one closure within an\u00adother (capturing the outer closure s \nvariables). Several systems allow asynchronous IO programs to be written without stack-ripping. Protothreads \nprovides a system for programming embedded systems in a threaded style [10]. Each thread is a single \nfunction that is split into a series of event handlers. Fischer et al. use a more gen\u00aderal version of \nthis idea in TaskJava [12], allowing callees towait forevents.A manual annotation causes theTaskJava \ncompiler to replace a method s body with a switch statement enabling it to be restarted at intermediate \npoints; variable accesses are replaced with accesses to state records in the heap. Srinivasan and Mycroft \nuse such transformations in the implementation of Kilim, an actor-based framework for Java [31]. We modify \nthe runtime system to avoid the need for this kind of transformation. Haller and Odersky s Scala Actors \n[15] combine thread\u00adbased and event-based programming models; code can block using a receive operation, \nor it can register an event handler using a react operation. Tame provides a set of C++ abstractions \nfor writing asyn\u00adchronous IO in a thread-like style [22]. A thread can block within a function call; \nthe call returns immediately, storing the contents of designated local variables into heap struc\u00adtures.Tame \nprovides callback-based synchronization primi\u00adtives and uses reference counting to manage temporary stor\u00adage. \nCLARITY supports a thread-like model with nonblock\u00ading calls and a monitor-like synchronization mechanism \n[6]. As with an async call, execution proceeds to the continua\u00adtion of a nonblocking call if the callee \nblocks. We integrate cancellation, and provide block-structured synchronization. CPC [21] uses a compiler \nthat transforms code to con\u00adtinuation passing style (CPS) to support large numbers of threads: threads \ncomprise a dynamic chain of heap-allocated suspension records.AsinAC anIO library provides integra\u00adtion \nwith asynchronous IO operations exposed by the OS. AC avoids the need for CPS transformation, and adds \nlan\u00adguage constructs for creating, synchronizing, and cancelling asynchronous work. Li and Zdancewic \ncombine callback-based and thread\u00adbased communication abstractions in GHC Haskell [25]. Thread-based \noperations are written in a monadic style to provide sequencing. A scheduler forces each thread s work \nto be evaluated up to the point of the next IO operation. Vouillon describes Lwt, an implementation of \ncooperative threads for OCaml [37]. Lwt provides primitive threads that perform individual AIO operations, \nalong with a bind op\u00aderator to chain these primitives together. Syme et al. provide an asynchronous modality \nin the F# language [32]. A value of type Async<T> is a compu\u00adtation that can be run asynchronously and \nproduce a value of type T. Control-.ow syntax from the core F# language can be used to structure these \nasynchronous computations. Version4 of the Microsoft .NET Framework supports asyn\u00adchronous IO without \nmanual stack-ripping(http://www. microsoft.com/events/pdc/ session FT09). Func\u00adtions that execute asynchronously \nmust include an async modi.er in their signature and have a Task<T> return type; their execution can \nthen be suspended and resumed using heap-allocated temporary objects for the suspended state. In contrast,AC \nallows code performing asynchronous IO to be compiled as usual and uses temporary data directly on the \nstack for managing asynchronous work; this leads to better performance, as we illustrated in Section \n5. Threads and parallel programming Although wekeep the AC abstractions separate from those for expressing \nparal\u00adlelism, our design and implementationbuilds on techniques for parallel programming.Wegain concurrency-control \nsim\u00adpli.cations by applying these techniques to computations within a single thread (e.g., we keep information \nabout the continuations of async calls implicit in a thread s stack be\u00adcause these are accessed only \nby that thread itself). Mohr introduced the use of lazy task creation [26], deferring cre\u00adation of a \nnew thread to execute a computation until a spare processor is available. Our Clang/LLVM implementation \nde\u00adfers creating a separate stack until a callee blocks. Gold\u00adstein introduced a taxonomy of techniques \nfor lightweight threads [14]. Our handling of async calls is akin to lazy disconnect in Goldstein s terminology. \nCILK [13] imple\u00admentations have used separate clones of functions to include or omit synchronization; \nwe do not use cloning because our sequential model reduces the amount of synchronization in-volved.AsinAC, \nCILK-4 usesa cactus-stack. CILK-5 uses heap-allocated frames. StackThreads/MP provides a form of async \ncall in which the callee can be stolen by an idle processor [33]. Stealing is co-operative (the victim \nis responsible for sus\u00adpending the current work of the callee). StackThreads/MP multiplexes frames from \nmultiple threads over a single stack; new frames are allocated at the top of the stack, but holes that \nappear are not .lled. As inAC, the Capriccio system of von Behren et al. [36] multiplexes IO-intensive \nworkloads on a single OS thread. It provides a traditional thread-based programming model whereas AC \nprovides block-structured constructs for synchronizing and cancelling asynchronous IO. The X10 language \nprovides async and finish con\u00adstructs, which partly inspired our design [7]. In X10, async creates work \nfor parallel processors. X10 s constructs would not provide, for example, the serial elision property \nof AC. Lee andPalsberg de.ne an operational semantics for Feath\u00aderweight X10 [24] using small-step transitions \nthat can inter\u00adleave work from parallel threads. AME provides a program\u00adming model based on serializable \natomic actions. Executing async C creates a new atomic action that will run C after the current atomic \naction [19]. Sivaramakrishnan et al. describe a form of lightweight threading known as parasitic threads \n[29].Parasitic threads are multiplexed over host threads, with multiple parasites us\u00ading the same host \nstack at the same time.A combination of static analysis and dynamic checking is used to prevent col\u00adlisions \nbetween frames from different parasites. We could apply these techniques to further reduce the cost of \nallocat\u00ading stacks inAC. Message-based languages. Hoare s CSP [17] has inspired numerous language designs. \nUnlike CSP, our core language provides buffered send/receive operations as primitives and omits an alt \n-style operation to send/receive on exactly one of a set of alternatives. Our design re.ects the primitives \navailable in the OSes that we target. Typical OS interfaces do not provide exactly-one semantics because \nmultiple re\u00adquests could complete concurrently on different devices. A programmer usingAC canbuild an \nalt -style operation via an additional software layer. As in AC, the Alef [39] and Go (golang.org) lan\u00adguages \nboth provide message passing operations within an imperative setting. Alef supports cooperative scheduling \nof coroutines as they block on communication operations. Go introduces a goroutine abstraction; these \nare multiplexed over OS threads (so different routines can run in paral\u00adlel), but a segmented-stack implementation \nis used. AC fo\u00adcuses just on structuring asynchronous IO operations within a single thread, rather than \nusing multiple OS threads. This choice lets us retain a sequential programming model. Concurrent with \nour work, Ziarek et al. developed a sys\u00adtem for composable asynchronous events [40], building on the \n.rst-class event abstraction of Concurrent ML [28]. Ziarek et al. s asynchronous events encapsulate the \nim\u00adplicit thread creation associated with an asynchronous ac\u00adtion within an event structure, thus enabling \ncomposable construction of asynchronous protocols. Cancellation. AC s block-structured approach to cancella\u00adtion \nis distinct from previous work. Modula-2+ [5] provides an alert mechanism that causes an exception to \nbe raised in another thread if that thread is blocked at a synchronization operation. Java provides a \nsimilar mechanism. POSIX de\u00ad.nes a notion of cancellation points at which one thread s work may be cancelled \nby another thread [1]. Typically, these are blocking system calls. In addition, POSIX asyn\u00adchronous IO \nprovides a aio cancel operation to cancel either a single speci.ed asynchronous IO operation, or to cancel \nall operations on a given .le. Windows provides a cancellation token abstraction; a token can be passed \nto an asynchronous IO operation when it is started, and cancelling a token cancels all asynchronous requests \nassociated with it. 7. Conclusion AC provides IO with performance comparable to native callback-based \nasynchronous interfaces while retaining the composable programming style of synchronous operations. Our \noverall thesis is that asynchronous IO should be sup\u00adported by using abstractions such as async, do..finish \nand cancel to describe the sources of asynchrony within an ordinary sequential program rather than by \nthe usual technique of developing a new, alternative set of IO inter\u00adfaces based around explicit events \nor callbacks. Our results show thatAC can match the performance of callback-based interfaces. The Barrel.sh \nresearch OS, including AC, is available from http://barrelfish.org.  Acknowledgements We would like \nto thank Zach Anderson, Mahesh Balakrish\u00adnan,G\u00b4erard Berry, Andrew Birrell, Miguel Castro, Austin Donnelly, \nAleksandar Dragojevi \u00b4 c, Vladimir Gajinov, Steven Hand, Orion Hodson, Suresh Jagannathan, Butler Lampson, \nSimon Peyton Jones, Gordon Plotkin, Chandu Thekkath, and the anonymous reviewers for feedback on earlier \ndrafts of this paper. References [1] POSIX 1003.1-2008. The Open Group, 2008. http://www.opengroup.org/onlinepubs/ \n9699919799/toc.htm. [2] M. Abadi. Automatic mutual exclusion and atomicity checks. In Concurrency, Graphs \nand Models: Essays Dedicated to Ugo Montanari on the Occasion of His 65th Birthday, pages 510 526. Springer-Verlag, \n2008. [3] A. Adya, J. Howell, M. Theimer, W. J. Bolosky, and J. R. Douceur. Cooperative task management \nwithout manual stack management. In USENIX-02: Proc. 2002 Annual Technical Conference, pages 289 302, \n2002.  [4] A. Baumann, P. Barham, P.-E. Dagand, T. Harris, R. Isaacs, S. Peter,T. Roscoe, A. Sch\u00a8 The \nupbach, and A. Singhania. multikernel: a new OS architecture for scalable multicore sys\u00ad tems. In SOSP \n09: Proc. 22nd Symposium on Operating Sys\u00ad tems Principles, pages 29 44, 2009. [5] A. Birrell, J. Guttag, \nJ. Horning, and R. Levin. Synchroniza\u00adtion primitives for a multiprocessor: a formal speci.cation. In \nSOSP 87: Proc. 11th Symposium on Operating Systems Prin\u00adciples, pages 94 102, 1987. [6] P. Chandrasekaran, \nC. L. Conway, J. M. Joy, and S.K. Ra\u00adjamani. Programming asynchronous layers with CLARITY. In ESEC-FSE \n07: Proc. 6th European Software Engineering Conference &#38; Symposium on the Foundations of Software \nEn\u00adgineering, pages 65 74, 2007. [7]P. Charles,C. Grothoff,V. Saraswat,C. Donawa,A. Kielstra, K. Ebcioglu, \nC. von Praun, and V. Sarkar. X10: an object\u00adoriented approach to non-uniform cluster computing. In OOP-SLA \n05: Proc. 20th Conference on Object-Oriented Program\u00adming, Systems, Languages, and Applications, pages \n519 538, 2005. [8] R. Cunningham and E. Kohler. Making events less slippery with eel. In HotOS 05: Proc. \n10th Conference on Hot Topics in Operating Systems, 2005. [9]F. Dabek, N. Zeldovich, F. Kaashoek, D. \nMazi`eres, and R. Morris. Event-driven programming for robust software. In Proc. 10th ACM SIGOPS European \nWorkshop, pages 186 189, 2002. [10] A. Dunkels, O. Schmidt, T. Voigt, and M. Ali. Pro\u00adtothreads: simplifying \nevent-driven programming of memory\u00adconstrained embedded systems. In SenSys 06: Proc. 4th Con\u00adference \non Embedded Networked Sensor Systems, pages 29 42, 2006. [11] K. Elmeleegy, A. Chanda, A. L. Cox, and \nW. Zwaenepoel. Lazy asynchronous I/O for event-driven servers. In USENIX\u00ad 04: Proc. 2004 Annual Technical \nConference, pages 21 21, 2004. [12] J. Fischer, R. Majumdar, and T. Millstein. Tasks: language support \nfor event-driven programming. In PEPM 07: Proc. 2007 Symposium on Partial Evaluation and Semantics-Based \nProgram Manipulation, pages 134 143, 2007. [13] M. Frigo, C.E. Leiserson, and K.H.Randall. The implementa\u00adtion \nof the Cilk-5 multithreaded language. In PLDI 98: Proc. 1998 Conference on Programming Language Design \nand Im\u00adplementation, pages 212 223, 1998. [14] S. C. Goldstein. Lazy Threads Compiler and Runtime Struc\u00adtures \nfor Fine-Grained Parallel Programming. PhD thesis, University of California Berkeley, Berkeley, 1997. \n[15] P. Haller and M. Odersky. Scala actors: Unifying thread-based and event-based programming. Theor. \nComput. Sci., 410(2\u00ad3):202 220, 2009. [16] E. A. Hauck and B. A. Dent. Burroughs B6500/B7500 stack mechanism. \nIn AFIPS 68: Proc. of the Spring Joint Computer Conference, pages 245 251, 1968. [17] C. A. R. Hoare. \nCommunicating sequential processes. Com\u00admun. ACM, 21(8):666 677, 1978. [18] Intel Corporation. Single-chip \ncloud computer. http://techresearch.intel.com/articles/ Tera-Scale/1826.htm, December 2009. [19] M. Isard \nand A. Birrell. Automatic mutual exclusion. In HotOS 07: Proc. 11th Workshop on Hot Topics in Operating \nSystems, 2007. [20] J. Howard et al. A 48-core IA-32 message-passing processor withDVFS in 45nm CMOS. \nIn ISSCC 10: Proc. Solid-State Circuits Conference, pages 108 109, 2010. [21] G. Kerneis and J. Chroboczek. \nCPC: programming with a massive number of lightweight threads. In PLACES 11: Proc. Workshop on Programming \nLanguage Approaches to Concurrency and Communication-Centric Software, 2011. [22] M. Krohn, E. Kohler, \nand M. F. Kaashoek. Events can make sense. In USENIX-07: Proc. 2007 Annual Technical Confer\u00adence, pages \n1 14, 2007. [23] H.C. Lauer and R. M. Needham. On the duality of operating system structures. In Proc. \n2nd International Symposium on Operating Systems, IRIA, 1978. [24] J.K. Lee andJ.Palsberg. Featherweight \nX10:a core calculus for async-.nish parallelism. In PPoPP 10: Proc. 15th Sym\u00adposium on Principles and \nPractice of Parallel Programming, pages 25 36, 2010. [25] P. Li and S. Zdancewic. Combining events and \nthreads for scalable network services implementation and evalua\u00adtion of monadic, application-level concurrency \nprimitives. In PLDI 07: Proc. 2007 Conference on Programming Language Design and Implementation, pages \n189 199, 2007. [26] E. Mohr, D. A. Kranz, and R. H. Halstead, Jr. Lazy task creation:Atechnique for increasing \nthe granularity of parallel programs. IEEE Trans. Parallel Distrib. Syst., 2:264 280, 1991. [27] J. Ousterhout. \nWhythreads are a bad idea (for most purposes). Presentation given at the 1996 Usenix Annual Technical \nCon\u00adference. [28] J. H. Reppy. Concurrent Programming in ML. Cambridge University Press,Cambridge, England, \n1999. [29] K. C. Sivaramakrishnan, L. Ziarek, R. Prasad, and S. Jagan\u00adnathan. Lightweight asynchrony \nusing parasitic threads. In DAMP 10: Proc. 2010 Workshop on Declarative Aspects of Multicore Programming, \n2010. [30]Y. Smaragdakis,A.Kay,R.Behrends,andM.Young. Trans\u00adactions with isolation and cooperation. In \nOOPSLA 07: Proc. 22nd Conference on Object Oriented Programming Systems and Applications, pages 191 210, \n2007. [31] S. Srinivasan and A. Mycroft. Kilim: Isolation-typed actors for Java. In ECOOP 08: Proc. 22nd \nEuropean Conference on Object-Oriented Programming, pages 104 128, 2008. [32] D. Syme, T. Petricek, and \nD. Lomov. The F# asynchronous programming model. In PADL 11: Proc. 13th International Symposium on Practical \nAspects of Declarative Languages, 2011. [33] K. Taura, K. Tabata, and A. Yonezawa. StackThreads/MP: integrating \nfutures into calling standards. In PPoPP 99: Proc. 7th Symposium on Principles and Practice of Parallel \nProgramming, pages 60 71, 1999. [34] C. Thacker. Beehive: A many-core computer for FPGAs (v5). MSR Silicon \nValley, January 2010. http://projects. csail.mit.edu/beehive/BeehiveV5.pdf. [35] R. von Behren, J. Condit, \nand E. Brewer. Why events are a bad idea (for high-concurrency servers). In HotOS 03: Proc. 9th Conference \non Hot Topics in Operating Systems, 2003. [36] R. von Behren, J. Condit, F. Zhou, G. C. Necula, and E. \nBrewer. Capriccio: scalable threads for internet services. In SOSP 03: Proc. 19th Symposium on Operating \nSystems Principles, pages 268 281, 2003. [37] J. Vouillon. Lwt: a cooperative thread library. In ML 08: \nProc. 2008 Workshop on ML, pages 3 12, 2008. [38] D. Wentzlaff, C. Gruenwald III, N. Beckmann, K. Modzelewski, \nA. Belay, L. Youseff, J. Miller, and A. Agarwal. An operating system for multicore and clouds: Mechanisms \nand implementation. In SOCC 10: Proc. 2010 Symposium on Cloud Computing, pages 3 14, June 2010. [39]P.Winterbottom. \nAlef language reference manual. Technical report, Bell Labs, 1995. [40] L. Ziarek, K. C. Sivaramakrishnan, \nand S. Jagannathan. Com\u00adposable asynchronous events. In PLDI 11: Proc. 2011 Con\u00adference on Programming \nLanguage Design and Implementa\u00adtion, pages 628 639, June 2011.  \n\t\t\t", "proc_id": "2048066", "abstract": "<p>This paper introduces AC, a set of language constructs for composable asynchronous IO in native languages such as C/C++. Unlike traditional synchronous IO interfaces, AC lets a thread issue multiple IO requests so that they can be serviced concurrently, and so that long-latency operations can be overlapped with computation. Unlike traditional asynchronous IO interfaces, AC retains a sequential style of programming without requiring code to use multiple threads, and without requiring code to be \"stack-ripped\" into chains of callbacks. AC provides an \"async\" statement to identify opportunities for IO operations to be issued concurrently, a \"do..finish\" block that waits until any enclosed \"async\" work is complete, and a \"cancel\" statement that requests cancellation of unfinished IO within an enclosing \"do..finish\". We give an operational semantics for a core language. We describe and evaluate implementations that are integrated with message passing on the Barrelfish research OS, and integrated with asynchronous file and network IO on Microsoft Windows. We show that AC offers comparable performance to existing C/C++ interfaces for asynchronous IO, while providing a simpler programming model.</p>", "authors": [{"name": "Tim Harris", "author_profile_id": "81406593835", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P2839294", "email_address": "tharris@microsoft.com", "orcid_id": ""}, {"name": "Martin Abadi", "author_profile_id": "81100547147", "affiliation": "Microsoft Research, Mountain View, CA, USA", "person_id": "P2839295", "email_address": "abadi@microsoft.com", "orcid_id": ""}, {"name": "Rebecca Isaacs", "author_profile_id": "81100494933", "affiliation": "Microsoft Research, Mountain View, CA, USA", "person_id": "P2839296", "email_address": "risaacs@microsoft.com", "orcid_id": ""}, {"name": "Ross McIlroy", "author_profile_id": "81351606978", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P2839297", "email_address": "rmcilroy@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/2048066.2048134", "year": "2011", "article_id": "2048134", "conference": "OOPSLA", "title": "AC: composable asynchronous IO for native languages", "url": "http://dl.acm.org/citation.cfm?id=2048134"}