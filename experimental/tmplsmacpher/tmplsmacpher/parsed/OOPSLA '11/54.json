{"article_publication_date": "10-22-2011", "fulltext": "\n Backstage Java Making a Difference in Metaprogramming Zachary Palmer The Johns Hopkins University zachary.palmer@jhu.edu \nAbstract We propose Backstage Java (BSJ), a Java language exten\u00adsion which allows algorithmic, contextually-aware \ngenera\u00adtion and transformation of code. BSJ explicitly and con\u00adcisely represents design patterns and \nother encodings by em\u00adploying compile-time metaprogramming: a practice in which the programmer writes \ninstructions which are executed over the program s AST during compilation. While compile-time metaprogramming \nhas been successfully used in functional languages such as Template Haskell, a number of language properties \n(scope, syntactic structure, mutation, etc.) have thus far prevented this theory from translating to \nthe im\u00adperative world. BSJ uses the novel approach of difference\u00adbased metaprogramming to provide an \nimperative program\u00adming style amenable to the Java community and to enforce that metaprograms are consistent \nand semantically unam\u00adbiguous. To make the feasibility of BSJ metaprogramming evident, we have developed \na compiler implementation and numerous working code examples. Categories and Subject Descriptors D.3.3 \n[Programming Languages]: Language Constructs and Features General Terms Languages, Design Keywords Java, \nmetaprogramming, macros, design pat\u00adterns, software merging, difference-based metaprogramming 1. Introduction \nWhen selecting features for a programming language, it s impossible to keep everyone happy. Inevitably, \na program\u00admer will want for an abstraction which would make the im\u00adplementation of a program much easier, \nmore concise, and more maintainable. When such abstractions are not provided by the language, programmers \nresort to implementing each case manually. Design patterns in Java are one example of Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA 11, October 22 27, \n2011, Portland, Oregon, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0940-0/11/10. . . $10.00 Scott \nF. Smith The Johns Hopkins University scott@jhu.edu this strategy: while each pattern describes a solution \nto a problem abstractly, each instance of a design pattern in code must be rei.ed with context-speci.c \ninformation [6]. This manual implementation is tedious, however, and macro systems are often employed \nto reduce its mainte\u00adnance burden. One simple example is the token sequence replacement system such as \nin C preprocessor macros. But such macro systems have many well-known .aws: because operations occur \non the token level, for instance, macros which produce low-precedence operators at a call site with high-precedence \noperators can introduce subtle bugs. More advanced generative techniques can be seen in C++ templates \nand Scheme macros. C++ templates, while origi\u00adnally intended for type and function de.nitions, are Turing\u00adcomplete \n[23] and can be used as a compile-time code gen\u00aderation language. Because this was never the intended \nuse of the system [16], the resulting templates have an obtuse and unintuitive syntax. Scheme macros \noperate by AST substi\u00adtution (unlike most macro systems) and have a much more tractable syntax. Indeed, \nlanguage extensions have been con\u00adstructed in Scheme using the macro system. One weakness of all of the \naforementioned systems is the absence of contextual information at the call site. Object\u00adoriented languages \nsuch as Java require changes to multiple AST subtrees to express more complex properties (e.g., that \na given class of objects is ordered by a speci.c member .eld). OJ [21] is a Java language extension which \npermits the de.nition of modi.ers which abstract the notion of design patterns. The OJ compiler provides \na meta-object protocol (MOP) which executes code associated with these modi.ers at compile time, allowing \nit to effect non-local changes: alterations to the AST in positions other than that of the call site \nitself. This form of ad hoc abstraction allows for greater semantic meaning than any statically-typed \nmacro system, permitting the generation of well-typed proxies, adapters, and other common design patterns. \nUnfortunately, OJ is very permissive in this regard; it is not immediately clear from the call site which \nportions of code could be affected. A keyword modifying a local vari\u00adable, for instance, could make modi.cations \nto any AST node, including those contained in other compilation units. This behavior could easily lead \nto code with confusing side\u00adeffects. While the imperative programming community ex\u00adpects to write code \nin the style of mutation, this mutation must be managable and well-understood.  The primary weakness \nof OJ, however, is that of metapro\u00adgram execution order. If two transformations operate over the same \nregion of code, changing their execution order may change the resulting AST. OJ does not clearly de.ne \nits ex\u00adpansion order, meaning that an OJ program may have mul\u00adtiple valid meanings. This form of nondeterminism \nis unac\u00adceptable from a compiler. The functional programming community has seen sig\u00adni.cant bene.ts from \nthe more disciplined technique of compile-time metaprogramming as a means of ad hoc ab\u00adstraction. In \nlanguages such as MacroML [7] and Template Haskell [18], Scheme-like code generation is reconciled with \na static type system. Compile-time metaprograms may also inspect de.nitions which are in scope at the \ncall site, pro\u00adviding valuable contextual information. Determinism is en\u00adforced by forbidding non-local \nchanges and by executing metaprograms in a prede.ned order dictated by syntactic structure. But this \ntheory is non-trivial to apply to imper\u00adative and object-oriented languages like Java for precisely that \nreason: expressing non-trivial facts about Java classes in an imperative style is not possible without \nnon-local changes (as in the ordering example mentioned above). We introduce Backstage Java (BSJ), a \nlanguage which brings the sophistication of compile-time metaprogramming to Java. BSJ metaprograms have \nthe following properties: (a) Non-local changes are effected without incurring con\u00adfusing side-effects \n (b) Execution order is dependency-driven to retain deter\u00adminism in light of non-locality (c) Con.icts \nbetween independent metaprograms are auto\u00admatically detected  To achieve the above, BSJ uses a difference-based \nmetapro\u00adgramming approach which, to our knowledge, is novel in metaprogramming literature. Rather than \nviewing metapro\u00adgrams as program transformations, we view them as trans\u00adformation generators: the AST \nis instrumented to record an edit script of all changes which are made to it in a strategy similar to \noperation-based merging [11, 12]. Then, rather than executing each metaprogram against a single AST in \nturn, the BSJ compiler prepares a different input AST for each metaprogram. That input AST contains only \nthose changes in the edit scripts of the metaprogram s de\u00adpendencies, guaranteeing that the metaprogram \ncannot see changes applied by metaprograms on which it does not de\u00adpend. Metaprogram con.icts are detected \nwhen two edit scripts fail to merge over the same AST. This metaprogramming model has several advantages. \nNon-local changes, necessary for metaprogramming in an imperative style, are possible. The input for \neach metapro\u00adgram is understood simply in terms of its declaration, mak\u00ad 1 #import static com.example.bsj.Utils.*; \n2 public class Person { 3 private String givenName; 4 private String middleName; 5 private String surname; \n6 [: 7 generateComparedBy(context, 8 <:surname:>, <:givenName:>, <:middleName:>); 9 :] 10 } Figure 1. \nComparable BSJ Example ing metaprogram semantics much clearer. Order of execu\u00adtion may be controlled \nbut is inferred by default, allow\u00ading .exibility without placing unnecessary burdens on the metaprogrammer. \nIn the event of ambiguity, the system can easily identify the pair of metaprograms involved and the AST \nsubtree on which they disagree. This paper describes the design, semantics, and imple\u00admentation of BSJ. \nSection 2 provides brief discussions of im\u00adplementation challenges and solutions. Section 3 describes \nhow non-local changes are made safe by the implementa\u00adtion of a metaprogram edit script algebra and con.ict \nde\u00adtection system (which is proven correct in Appendix A of [13]). Section 4 details BSJ quasiquoting \nsyntax and the use of a type family to disambiguate it. Section 5 discusses the BSJ language speci.cation \nand the compiler reference im\u00adplementation. We conclude with an analysis of related work in Section 6 \nand a discussion of future research in Section 7. 2. Overview To discuss our difference-based metaprogramming \nmodel, we will provide source examples in BSJ. Sections 2.1 and 2.2 provide a general introduction to \nBSJ syntax; Section 2.3 introduces difference-based metaprogramming and high\u00adlights its importance. The \nremainder of the overview is de\u00advoted to explaining other ambiguities which must be re\u00adsolved in BSJ \nand outlining our solutions to them. 2.1 Basic Execution Semantics Figure 1 presents a class in BSJ \nwhich contains three string .elds representing a person s names. A metaprogram ap\u00adpears in this class \nwhich makes the class comparable .rst by surname, then by given name, and .nally by middle name. A utility \nmethod is used to abstract the concept of a lexico\u00adgraphical class ordering; this method can be seen \nin Figure 2. Java code equivalent to Figure 1 can be seen in Figure 3 The delimiters [: (line 6) and \n:] (line 9) of Figure 1 mark the beginning and end of an explicit BSJ metaprogram. The intervening lines \nform the body of the metaprogram (lines 7 and 8). The compilation process strips the metaprograms from \nthe AST before they are executed, leaving behind a single AST leaf node called an anchor which is provided \nto the metaprogram as input. During compilation, the statements in the metaprogram s body are executed. \nIn the case of the metaprogram in Fig\u00adure 1, this will result in the addition of a compareTo method \n 1 public class Utils { 2 public static void generateComparedBy(Context<?,?> context, 3 IdentifierNode... \nvars) { 4 ClassDeclarationNode n = context.getAnchor(). 5 getNearestAncestorOfType(ClassDeclarationNode.class); \n6 BsjNodeFactory factory = context.getFactory(); 7 BlockStatementListNode list = 8 factory.makeBlockStatementListNode(); \n9 list.add(<:int c;:>); 10 for (IdentifierNode var : vars) { 11 list.add(<:c = this.:var.deepCopy(factory):. \n~~12 compareTo(other.:var:);:>); ~~ 13 list.add(<:if (c != 0) return c;:>); 14 } 15 list.add(<:return \n0;:>); 16 n.getBody().getMembers().addLast(<: 17 public int compareTo(Person other) { :list:} ~~ 18 \n:>); 19 n.getImplementsClause().addLast(<: Comparable 20 <:n.getIdentifier().deepCopy(factory):> :>); \n21 } 22 } ~~ Figure 2. BSJ Utility Class 1 public class Person implements Comparable<Person> { 2 private \nString givenName; 3 private String middleName; 4 private String surname; 5 public int compareTo(Person \nother) { 6 int c; 7 c= this.surname.compareTo(other.surname); 8 if (c != 0) return c; 9 c= this.givenName.compareTo(other.givenName); \n 10 if (c != 0) return c; 11 c= this.givenName.compareTo(other.middleName); 12 if (c != 0) return c; \n13 return 0; 14 } 15 } Figure 3. Comparable Java Example to the metaprogram s class. The environment \nin which the metaprogram is executed includes a binding for the variable context (used on line 7), which \nis a reference allowing ac\u00adcess to the metaprogram s anchor, the node factory, and other metaprogramming \nfacilities. The delimiters <: and :> denote a code literal (quasiquote) and allow metaprograms to express \nASTs in the form of a code fragments. These code literals appear on line 8 of Fig\u00adure 1 as well as in \nseveral places in Figure 2. In the latter .gure, the delimiters : and :are splicing operators and ~~ \npermit the code literal to be used as a template which is then instantiated by metaprogram expressions. \nIn this case, the arguments passed to the generateComparedBy method on line 8 of Figure 1 will replace \nthe splices on lines 8 and 9 of Figure 2, generating one AST representing an assignment to a variable \nc for each identi.er speci.ed in the arguments. BSJ AST nodes can access their parent nodes.1 This per\u00admits \nthe metaprogram in Figure 1 to obtain a reference to the class declaration in which it is contained. \nThis is crit\u00adical for the behavior of generateComparedBy because it must insert a compareTo implementation \ninto the class body as well as a type in the implements clause. It is in this 1 For this to be possible, \neach node object in the AST must be unique. This motivates the deepCopy(factory) constructions in Figure \n2. 1 public class Example { 2 [: 3 // next statement produces an error! 4 context.getAnchor().getNearestAncestorOfType( \n5 CompilationUnitNode.class).getTypeDecls().add( 6 <:class Extra {}:>); 7 :] 8 } Figure 4. Limiting \nthe Scope of Change fashion that BSJ permits non-local changes to be inserted at well-de.ned positions \nin the AST. This is a necessity in a Java-like language as some semantic facts (such as the comparability \nof a class) must affect multiple subtrees of the AST consistently. In the example code in Figure 3, both \nthe implements clause on line 1 and the compareTo de.ni\u00adtion starting on line 4 were added by a single \nmetaprogram. In contrast, the simplest and most convenient macro system approach would require two cooperating \nmacros, resulting in information duplication as well as the opportunity for the two macros to become \nout of sync. To prevent metaprograms from being dif.cult to under\u00adstand, they are limited to affecting \nonly the declaration in which they appear. In Figure 4, for example, the metapro\u00adgram at line 2 attempts \nto insert a new top-level class into the same .le as the Example class. Because the metaprogram is positioned \ninside of the Example class, it is unable to af\u00adfect the compilation unit outside of its declaration. \nMetapro\u00adgrams are also forbidden from modifying compilation units other than the one in which they appear, \nalthough it is possi\u00adble to insert new compilation units into an existing package.  2.2 Execution Order \nOrder of execution is an important consideration in any metaprogramming environment but is especially \ncritical when admitting non-local changes. Figure 5 demonstrates the importance of execution order. Each \nmetaprogram at\u00adtempts to insert a statement at the beginning of the method. Without execution ordering, \nthe meaning of the method is ambiguous: at runtime, it may print either BA or AB de\u00adpending on the order \nin which the transformations executed. Any such case in which the order of metaprogram execution is unspeci.ed \nbut would change the resulting AST is known as a metaprogram con.ict. This particular case is known as \na dual-write con.ict because the metaprograms are con.icting over the semantics of their write operations. \nLanguages such as Scheme and Template Haskell use a simple mechanism for the order of metaprogram execution: \nmetaprograms are executed in the order in which they ap\u00adpear in the AST. This is intuitive in functional \nlanguages, as this is the direction in which scoped bindings .ow. By contrast, many constructs in the \nJava language (such as non\u00adinitializing declarations in the body of a type) have no rele\u00advant ordering; \nassigning meaning to the order of these dec\u00adlarations would be confusing and unintuitive. Furthermore, \nit may be undesirable; a programmer may wish the .rst  1 public class SimpleConflict { 2 public void \nfoo() { 3 [: 4 // #depends a; /* uncomment to resolve conflict */ 5 context.getPeers().add(0, <:System.out.print(\"A\");:>); \n6 :] 7 [: 8 // #target a; /* uncomment to resolve conflict */ 9 context.getPeers().add(0, <:System.out.print(\"B\");:>); \n 10 :] 11 } 12 } Figure 5. Simple Con.ict 1 class X{ 2 [: 3 /* For each class defined in this compilation \nunit, adds a 4 * field to this class of the same name but lower-cased. */ 5 // #depends foo; /* uncomment \nto include y field in X */ 6 \u00b7\u00b7\u00b7 7 :] 8 } 9 [: 10 #target foo; 11 context.addAfter(<:class Y{}:>); 12 \n:] Figure 6. Apparent Read-Write Con.ict Example metaprogram in Figure 5 to be able to see and react \nto the changes made by the second metaprogram (or even by a metaprogram in another compilation unit). \nIn BSJ, the programmer may resolve the con.ict in Figure 5 by explicitly specifying an ordering between \nthe metaprograms; uncommenting the .rst line of each metapro\u00adgram would be suf.cient. The preamble clause \n#target a indicates that the metaprogram is a member of the target named a; the preamble clause #depends \na indicates that the metaprogram should wait until all metaprograms in tar\u00adget a have executed. While \nthis dependency-driven ordering of execution is a valuable tool, it is not a complete solution. In practice, \nlarge numbers of metaprograms can appear in an object program and each metaprogram may have subtle side \neffects; thus, we cannot expect the metaprogrammer to identify con.icts manually. The BSJ compiler provides \na con.ict detection system (described in Section 3) which guarantees that any BSJ code which does not \nhave exactly one valid Java equiv\u00adalent will produce a compilation error. This feature is nec\u00adessary \nfor the scalability of the language and frees up the programmer to focus on developing the object program. \n 2.3 Difference-Based Metaprogramming Two categories of potential con.ict other than dual-write con.icts \nexist: read-write con.icts and injection con.icts. Injection con.icts are outlined in Section 2.5 and \ndiscussed in depth in Section 3.5. An example of an apparent read\u00adwrite con.ict, on the other hand, appears \nin Figure 6. The semantics of the .rst metaprogram are explained in a com\u00adment for the sake of simplicity. \nIn previous examples we have presented, it is suf.cient to execute each metaprogram over the original \nAST in turn; dual-write con.icts could be detected by noticing when one metaprogram writes to the same \nAST node as another. In Figure 6, however, this is not true. If we execute the top metaprogram .rst, \nthe body of X contains one variable dec\u00adlaration (x); otherwise, it contains two (x and y). In neither \ncase do we see a dual-write con.ict, but the output would still be ambiguous if the code were allowed \nto compile. A previous iteration of BSJ attempted to solve this prob\u00adlem by monitoring the behavior of \nmetaprograms, produc\u00ading an error if a metaprogram reads a variable that another metaprogram changed. \nIn our experience, however, the con\u00adstraints describing what a metaprogram considers signi.cant are quite \ncomplex; often, a metaprogram would iterate over a list (such as the body of a class declaration) and \nonly act on those elements which were .elds. Because the con.ict detection system was unable to determine \nthat the non-.eld elements were not used, this led to numerous false con.icts. Instead, BSJ solves this \nproblem by using difference\u00adbased metaprogramming. Instead of executing each of the metaprograms in Figure \n6 over the same AST in some se\u00adquence, we execute each over a copy of that AST. The AST is instrumented \nto produce an edit script: a description of the changes that the metaprogram made. Software merging techniques \nare later used to combine these edit scripts and produce the .nal program. Because each metaprogram exe\u00adcutes \nover a copy of the original AST, neither metaprogram can see the changes created by the other. In our \nexample, the system would always generate code in which X had a sin\u00adgle member .eld (x). The AST provided \nto a metaprogram re.ects the edit scripts from that metaprogram s dependen\u00adcies; thus, the programmer \ncould choose to generate code in which X has the member .elds x and y by uncommenting the #depends clause, \nmaking the .rst metaprogram depend upon the second. This approach has two profound advantages. First, \nread\u00adwrite con.icts are impossible in this system: by de.nition, a metaprogram can only observe changes \napplied by its depen\u00addencies. Second, reasoning about metaprograms becomes considerably easier. The behavior \nof a metaprogram can now be understood strictly in terms of its declaration and those of its dependencies; \nit is not necessary to consider any other code to understand the effect that a metaprogram will have. \nIt is possible using this approach that a programmer may misunderstand the semantics of the program in \nFigure 6, ex\u00adpecting it to result in a class with two member .elds. While this potential for confusion \nexists, we view the small learn\u00ading curve introduced by the dependency system s semantics as worth the \nconsiderable advantages described above.  2.4 Meta-Annotations The explicit metaprogram syntax witnessed \nthus far (delim\u00adited by the [: and :] operators) is suitable for individual metaprograms. But a metaprogrammer \noften wishes to ab\u00adstract over these metaprograms (as well as their dependen\u00ad  1 public class AckermannFunction \n{ 2 public static final AckermannFunction SINGLETON = 3 new AckermannFunction(); 4 private AckermannFunction() \n{} 5 private static class EvaluateCacheKey { 6 private BigInteger m; 7 private BigInteger n; 8 \u00b7\u00b7\u00b7 36 \n} 37 private Map<EvaluateCacheKey, BigInteger> evaluateCache = 38 new HashMap<EvaluateCacheKey, BigInteger>(); \n39 public BigInteger evaluate(BigInteger m, BigInteger n) { 40 final EvaluteCacheKey key = new EvaluateCacheKey(m, \nn); 41 \u00b7\u00b7\u00b7 46 return result; 47 } 48 public BigInteger calculateEvaluate(BigInteger m, 49 BigInteger \nn) { 50 if (m.compare(BigInteger.ZERO) < 0 || 51 n.compare(BigInteger.ZERO) < 0) 52 throw new ArithmeticException(\"Undefined\"); \n53 if (m.equals(BigInteger.ZERO)) 54 return n.add(BigInteger.ONE); 55 if (n.equals(BigInteger.ZERO)) \n56 return evaluate(m.subtract(BigInteger.ONE), 1); 57 return evaluate(m.subtract(BigInteger.ONE), 58 \nevaluate(m, n.subtract(BigInteger.ONE))); 59 } 60 } (a) Abbreviated Java Source 1 @@MakeSingleton 2 \npublic class AckermannFunction { 3 @@Memoized @@BigIntegerOperatorOverloading 4 public BigInteger evaluate(BigInteger \nm, BigInteger n) { 5 if (m < 0 || n < 0) 6 throw new ArithmeticException(\"Undefined\"); 7 if (m == 0) \nreturn n + 1; 8 if (n == 0) return evaluate(m -1, 1); 9 return evaluate(m -1, evaluate(m, n -1)); 10 \n} 11 } (b) BSJ Source Figure 7. Ackermann Function cies) to represent general coding concepts. For this \npurpose, BSJ includes meta-annotations. Recall that Java annotations are constructs pre.xed with @ which \nmay appear as modi.ers on declarations. In gen\u00aderal, annotations have no semantic meaning; instead, pre\u00adprocessors \nor re.ective code are expected to react to them. BSJ meta-annotations are similar but are used by the \nBSJ compiler and are not available at runtime. We use the pre.x @@ for disambiguation. BSJ also permits \nmeta-annotations to represent metaprograms, encouraging a declarative metapro\u00adgramming style. We introduce \nmeta-annotations with a simple example: the task of writing a class to calculate the well-known Ack\u00adermann \nfunction. This function grows quickly in some cases, so we will use BigInteger to represent its inputs \nand re\u00adsults. Calculation of the Ackermann function is expensive, so we will use memoization for performance. \nAn abbreviated version of a Java source code solution ap\u00adpears in Figure 7a. The full source is sixty \nlines. By com\u00adparison, the BSJ implementation of this same routine ap\u00adpears in Figure 7b. The latter \nvariation is more concise and more readable than its Java counterpart; the patterns used in 1 #import \nedu.jhu.cs.bsj.stdlib.metaannotations.*; 2 @@GenerateEqualsAndHashCode 3 @@GenerateToString 4 @@ComparedBy({<:rank:>,<:suit:>}) \n5 @@GenerateConstructorFromProperties 6 public class Card { 7 public enum Rank { TWO, ..., KING, ACE \n} 8 public enum Suit { CLUBS, DIAMONDS, HEARTS, SPADES } 9 @@Property(readOnly=true) private Rank rank; \n 10 @@Property(readOnly=true) private Suit suit; 11 } Figure 8. BSJ Playing Card Class 1 public class \nProperty 2 extends AbstractBsjMetaprogramMetaAnnotation { 3 public Property() { 4 super(Arrays.asList(\"property\"), \nArrays.<String>asList()); 5 } 6 protected void execute(Context... context) { 7 /* code here to insert \ngetters and setters */ \u00b7\u00b7\u00b7 8 } 9 private boolean readOnly = false; 10 @BsjMetaAnnotationElementGetter \n11 public boolean getReadOnly() { return this.readOnly; } 12 @BsjMetaAnnotationElementSetter 13 public \nvoid setReadOnly(boolean r) { this.readOnly = r; } 14 @Override public void complete() { } 15 } Figure \n9. @@GenerateConstructorFromProperties the code (singleton and memoization) are explicitly repre\u00adsented \nand existing Java syntax is semantically extended to make BigInteger operations more legible. The BSJ \nstan\u00addard libraries, utilized in these .gures, provides de.nitions of the meta-annotations such as @@Memoized. \nBSJ program\u00admers are encouraged to de.ne their own meta-annotations for domain-speci.c patterns or other \nsimilar uses. Meta-annotations also generalize over targets and depen\u00addencies. Consider the playing card \nclass shown in Figure 8. The metaprograms which generate the getters for proper\u00adties (on lines 9 and \n10) must execute before the metapro\u00adgram which generates the constructor (on line 5). This de\u00adpendency \nis declared in the meta-annotations de.nitions, reducing clutter at the call site. Meta-annotations are \nde.ned by creating an implemen\u00adtation of the interface BsjMetaprogramMetaAnnotation which speci.es methods \nde.ning the metaprogram s targets, dependencies, and execution behavior. Meta-annotations ex\u00adecute in \nthe same fashion as explicit metaprograms and obey the same con.ict detection rules. For an example, \nconsider the abbreviated de.nition of @@Property appearing in Figure 9. This meta-annotation abstracts \nthe Java property idiom: the creation of getter and setter methods for a .eld. The arguments to the super \ncon\u00adstructor specify that each use of this meta-annotation is a member of the property target; this allows \nother metapro\u00adgrams to depend on this meta-annotation.  2.5 Metaprogram Injection Because BSJ metaprograms \ncan insert nodes into the AST, they can create and insert new metaprograms. This re\u00adsults in a very natural \nexpression of complex pattern def\u00ad  1 @@MakeSingleton 2 public class AckermannFunction { 3 @@GenerateEqualsAndHashCode \n@@GenerateConstructorFromProperties 4 private static class EvaluateCacheKey { 5 @@Property(readOnly=true) \nprivate BigInteger m; 6 @@Property(readOnly=true) private BigInteger n; 7 } 8 @@Memoized @@BigIntegerOperatorOverloading \n9 public BigInteger evaluate(BigInteger m, BigInteger n) { \u00b7\u00b7\u00b7 } 10 \u00b7\u00b7\u00b7 11 } Figure 10. Ackermann Function \n-Memoize Expansion 1 [: 2 #target x; 3 context.addAfter(<: [: #target y; :] :>); 4 :] 5 [: #target y; \n:] 6 [: #depends y; :] Figure 11. Injection Con.ict Example initions. For example, consider the Ackermann \nimplemen\u00adtation in Figure 7b. The @@Memoized meta-annotation is responsible for much of the generated \ncode because it must create a data structure representing the cache key: a tuple of two BigIntegers. \nIf the compiler expands the @@Memoized meta-annotation .rst, the AST would then re\u00adsemble Figure 10. \n(@@Memoized is italicized to indicate that its metaprogram has executed.) The newly-inserted code uses \nmeta-annotations to de.ne the cache key data structure. The process of adding new metaprograms during \nthe ex\u00adecution of a metaprogram is termed metaprogram injection. Injection is common among metaprogramming \nsystems but introduces complications for a dependency system. For ex\u00adample, consider the program in Figure \n11. The top metapro\u00adgram injects a metaprogram in target y; the bottom metapro\u00adgram depends on target \ny. If the metaprograms execute from top to bottom, everything is .ne; we will conclude that the injected \nmetaprogram should run before the bottom one. But at the beginning of compilation, it would also be le\u00adgal \nfor the bottom metaprogram to execute before the top one; after all, the top metaprogram is not in target \ny and the injected metaprogram is not yet present. After executing the bottom metaprogram, we would execute \nthe top metapro\u00adgram only to discover that the target y is no longer satis.ed! To remain consistent, \nthe compiler must produce an error not only when such an event occurs, but when such an event could have \noccurred; that is, even if we executed the top metaprogram .rst, we must eventually realize that the \npo\u00adtential for an injection con.ict existed and produce an error. Our technique for doing this is described \nin Section 3.5.  2.6 Code Literal Disambiguation A simple example of code literals is demonstrated in \nFig\u00adure 12a: the sole line uses code literal syntax to create an AST representing a variable declaration. \nThe code in Fig\u00adure 12b shows an equivalent expression using a BSJ node factory. As in other languages \nwith quasiquoting, the code literal form is much more readable. 1 LocalVariableDeclarationNode n1 = \n<: int x = 0; :>; (a) With Code Literals 1 LocalVariableDeclarationNode n2 = 2 factory.makeLocalVariableDeclarationNode( \n3 factory.makePrimitiveTypeNode(PrimitiveType.INT), 4 factory.makeVariableDeclaratorListNode( 5 factory.makeVariableDeclaratorNode( \n6 factory.makeIdentifierNode(\"x\"), 7 factory.makeIntLiteralNode(0)))); (b) Without Code Literals Figure \n12. With and Without Code Literals While code literals are clearly desirable, the complexity of the Java \ngrammar makes parsing code literals dif.cult. The code literal shown in Figure 12a has more than one \ninterpretation: it could be a local variable declaration, a class member .eld, or an interface constant. \nMetaprogramming environments often address this problem either by providing different quasiquoting syntax \nfor each form [2, 18, 22] or by restricting the forms that can be used [10, 27]. Unfortunately, BSJ would \nneed dozens of different quasiquoting forms; the singleton token sequence x could represent an identi.er, \nan enum constant declaration, or fourteen other parses. It has been shown [3] that this problem can be \nsolved by using the type context of the surrounding metaprogram code to disambiguate the code literal. \nIn this approach, each of the possible parses is lifted into metaprogram code that con\u00adstructs the indicated \nAST. This forest of parses is then type\u00adchecked and, if exactly one parse successfully typechecks, it \nis taken as the meaning of the code literal. BSJ uses a similar approach but defers the lifting until \nafter typechecking is complete. Code literals are represented by a type family which directly represents \nthe ambiguity in the parse. This technique more directly integrates with the original language s type \nsystem and provides opportunities for lazy evaluation and other performance optimizations. Section 4 \ndescribes this process in detail. 3. Edit Scripts and Con.icts In this section, we characterize difference-based \nmetapro\u00adgramming and de.ne its semantics. We observe that tra\u00additional metaprograms are perceived as \nfunctions convert\u00ading one object program to another. That is, suppose P to be the set of all programs \n.; then traditional metaprograms . are viewed as having the type P . P. The metapro\u00adgrams .1,...,.n are \nthen composed over an initial input program ., producing the resulting program .'. This also means, however, \nthat each .i receives as its input the result of .1,...,.i-1 executed over ., which leads to the possi\u00adbility \nof the read-write con.icts discussed in Section 2.3. In a difference-based metaprogramming environment \nsuch as BSJ, however, we separate metaprogram logic into two parts: analysis and modi.cation. Analysis \nlogic involves the metaprogram examining the object program to make de\u00adcisions about what actions to \ntake; modi.cation logic in\u00advolves taking action and changing the object program. A  BSJ metaprogram \nf represents the analysis logic and has the type P . .P, where .P is the set of all edit scripts \u00af d. \nAn edit script represents the modi.cation logic as a se\u00adries of transformations d1,...,dn which are performed \nover a program. We de.ne a function .(d, .)= . ' which ap\u00adplies the transformation of an edit script \nelement d to a pro\u00adgram ., resulting in a program . '. For convenience, we de\u00ad.ne .(\u00af= \u00b7\u00b7 .(d1,.))). \nClearly, . has the type d, .) .(dn, (\u00b7 P . P if d is .xed. But unlike a traditional metaprogram, . can \nonly perform write operations based on the edit script element; it would not inspect the object program \nor make any decisions during its application. Edit scripts are generated by providing a speci.c object \nprogram as input to each metaprogram f which re.ects f s dependencies.. While the full discussion of \ndependencies is deferred until Section 3.1, we can informally de.ne the de\u00adpendencies of f as the set \nof metaprograms which partici\u00adpate in targets on which f depends (and the dependencies of those metaprograms, \nrecursively). We model the AST nodes representing the original source code as being inserted by an origin \nmetaprogram on which all other metaprograms depend. The input to f is then .(d\u00afn, (\u00b7\u00b7\u00b7 .(d\u00af1, \u00d8))) where \n\u00d8 represents an empty AST, d\u00afi is the edit script produced by fi, and f1 is the origin metaprogram. Once \nthe edit scripts d\u00afi for each metaprogram fi has been calculated, we apply them to the original program \n. to obtain the resulting program . '. To do so, we must select an order of application. We always do \nso in a fashion that observes the dependencies that each metaprogram has declared. De.nition 3.1. Given \nmetaprograms {f1,...,fn}, an or\u00addering of these metaprograms k\u00af= k1,...,kn is some per\u00admutation of the \nintegers 1,...,n. The ordering k\u00afis respect\u00adful iff, for any metaprogram fj which depends on a target \ncontaining fi, the value i preceeds the value j in k\u00af. We then determine the .nal object program . ' \nby calcu\u00adlating .(d\u00afkn , (\u00b7\u00b7\u00b7 .(d\u00afk1 , \u00d8))) using a respectful ordering k\u00af. Our key objective is to ensure \nthat all BSJ programs are unambiguous: each BSJ program either corresponds to ex\u00adactly one output program \nor it produces a compilation error. Since the ordering in which the metaprograms edit scripts are composed \nis selected arbitrarily by the compiler (such that it preserves declared dependencies), we must ensure \nthat it has no impact on the output; every respectful order\u00ading should produce the same result. In pursuit \nof this, we provide a formal de.nition of a metaprogram con.ict be\u00adlow. This de.nition uses a concept \nof program equivalence; we de.ne program equivalence to resolve a special case in Section 3.4, but a \nreader may safely proceed by assuming equivalence (~ =) to be identity until then. De.nition 3.2. Let \nf and f ' be two metaprograms in a compilation of a program . involving n metaprograms. Let \u00afd\u00af' d and \nbe the edit scripts produced by those metapro\u00ad \u00af grams, respectively. Let k be any respectful ordering \nof the n metaprograms. A con.ict exists if there exists any other respectful ordering k\u00af' of the n metaprograms \nsuch that dkn , (\u00b7\u00b7\u00b7 dk1 , \u00d8))) . .(d\u00afk(, (\u00b7\u00b7\u00b7 dk(, \u00d8))). .(\u00af.(\u00afn .(\u00af1 We separate con.icts into the \nthree categories discussed in Section 2. We specify an edit script algebra for modeling difference-based \nmetaprogramming execution in Section 3.3 and show that this metaprogramming model makes read\u00adwrite con.icts \nimpossible. We then describe a merge oper\u00adation in Section 3.4; this operation simultaneously performs \nthe composition of a series of edit scripts and analyzes them to determine if any dual-write con.icts \nexist. Section 3.5 de\u00adscribes injection con.icts in detail and provides a graph anal\u00adysis suf.cient to \ndetect them. 3.1 The Dependency Graph For purposes of execution ordering and con.ict detection, metaprograms \nand their targets are organized into a bipar\u00adtite dependency graph. Each metaprogram is assigned a unique \nidentity; we use the terms M1, M2, etc. to range over metaprogram identities and the terms a, b, etc. \nto range over metaprogram targets. Because the input for a metapro\u00adgram f is de.ned in terms of the output \nof its dependencies, those dependencies will always be executed prior to f. In effect, the dependency \ngraph de.nes a partial order over the metaprograms which is used to determine order of execu\u00adtion. Formally, \nwe de.ne a dependency graph as follows: De.nition 3.3. A dependency graph G = (M, T, EM ,ET ), where \nM is a .nite set of metaprogram nodes, T is a set of target nodes, EM is a set of directed edges from \nmetapro\u00adgram nodes to target nodes, and ET is a set of directed edges from target nodes to metaprogram \nnodes. Each edge in EM and in ET is either an explicit edge or an implicit edge. An acyclic dependency \ngraph is said to be well-formed. Executing a metaprogram from a dependency graph which is not well-formed \neventually becomes impossible without violating at least one dependency constraint; as a result, the \nconstruction of such dependency graphs results in a compile error. Hereafter, all discussion of dependency \ngraphs will assume that they are well-formed. To facilitate this discussion, we turn to the contrived \nex\u00adample shown in Figure 13. This source .le contains seven metaprograms, all of which perform no operations \nwhen ex\u00adecuted (as they contain no statements). The #target and #depends clauses declare execution order. \nThis order is en\u00adforced by constructing a dependency graph G as shown in Figure 14. Metaprograms themselves \nare shown as square nodes in the graph; metaprogram targets are shown as cir\u00adcles. This graph de.nes \na number of facts about execution order. We can see, for instance, that M6 should execute after M3 (because \na path exists from M6 to M3). We formalize metaprogram dependencies with the following de.nition.  1 \n[: #target a; :] // metaprogram 1 2 [: #target a; :] // metaprogram 2 3 [: #target a, b; :] // metaprogram \n3 4 [: #target c; #depends a; :] // metaprogram 4 5 [: #target c; #depends b; :] // metaprogram 5 6 [: \n#depends c; :] // metaprogram 6 7 [: :] // metaprogram 7 Figure 13. Execution Order Example the programmer \nto express ordering constraints between metaprograms, we must also be able to detect con.icts when ordering \nconstraints are missing. The following sections demonstrate how this is accomplished.  3.2 Edit Script \nAlgebra As stated above, a metaprogram s logic can be separated into analysis and modi.cation. The objective \nof an edit script (d\u00af:.P) is to distill the modi.cation logic of a given metaprogram over a known input \nprogram separated from its analysis logic. This edit script is then applied to the original program along \nwith the edit scripts of other metaprograms to produce the .nal output. Figure 14. Example Dependency \nGraph In difference-based metaprogramming, we model metapro\u00ad ' De.nition 3.4. Let M and M be metaprograms \nin a depen\u00adgrams as having type P . .P. But BSJ, a difference-based ' dency graph G. M depends on M (equiv., \nM M') if a metaprogramming environment, has syntax that allows pro\u00adpath exists in the dependency graph \nfrom M to M'. Other\u00adgrammers to directly modify the AST; this behavior corre\u00ad ' / wise, M does not depend \non M (equiv., M M'). We write ' '' M M- to represent M M . M = M and we write sponds to the type P . \nPin our algebraic notation. The BSJ compiler reference implementation resolves this issue by ' M M' ). \nM /to represent \u00ac(M- - executing metaprograms over heavily instrumented ASTs. '' M is ordered with \nrespect to M (equiv., M and M are These ASTs capture the behavior of the BSJ metaprogram '' ') if M M \nor if M M. Any two ordered, M M metaprograms which are not ordered are unordered (equiv., M /'). We write \nM- M M M  by recording each mutation event; a sequence of such events composes the programmatic representation \nof an edit script. In this fashion, the BSJ reference implementation uses the ' ' ' . M = M to represent \nM ' ' ). and we write M /to represent \u00ac(M- M M - We also reason about dependencies over targets. Given \n algebra described here to drive its compilation process. Figure 15 describes the syntax of our edit \nscript algebra. any target t in a dependency graph, M depends on target t This algebra is language-agnostic, \nbut we relate it to BSJ if a path exists in the dependency graph from M to t. M is throughout this section \nto provide practical examples and a member of target t (equiv., M . t) if a path exists in the appeal \nto intuition. The grammar uses the notation k . v dependency graph from t to M. to denote a sequence \nk1 . v1,...,kn . vn. We use this notation to re.ect the embedding of sequences within Based on this de.nition, \nit should be evident that any respectful ordering of a set of metaprograms is a topological sort of its \ndependency graph. Any metaprogram which does not declare any dependen\u00adcies implicitly depends on the \ntarget a, the only member of which is the origin metaprogram Ma. We use Ma to repre\u00adsent the start of \ncompilation. Intuitively, Ma can be seen as the metaprogram which loads the initial sources for compi\u00adlation. \nThe edges leading into and out of a are all implicit, the meaning of which is discussed below in Section \n3.5. The dependency graph is monotonically increasing dur\u00ading compilation. This is because metaprograms \ncan create and insert other metaprograms into the AST (a process we term metaprogram injection); each \nnew metaprogram ap\u00adpears in the dependency graph after its injector terminates. Metaprogram injection \nis the motivation for implicit edges and is discussed in Section 3.5. As indicated above, a com\u00adpile \nerror occurs if such an injection introduces a depen\u00addency graph cycle. The de.nition of the dependency \ngraph permits a metapro\u00adgrammer to express an explicit ordering between any two metaprograms. The bipartite \nnature of the graph and the ex\u00adistence of targets allows metaprograms to be grouped as a form of indirection. \nWhile the dependency graph permits ' other sequences; for instance, k . v, k ' . v denotes the ' sequence \nk1 . v1,...,kn . vn,k ' . v . Node nonces, labels, native immutable values, and metapro\u00adgram identi.ers \nmay have any coherent form. In the case of BSJ, for instance, u represents values of types such as String, \nint, or the API-speci.c BsjSourceLocation. In this algebra, values include native immutables, node nonces, \nrecords, and lists. We treat records as maps, using K . v . R to denote that a mapping exists in a map \nand using R[K . v ] to denote map substitution. Our algebra seeks to represent object programs as struc\u00adtured \ndata; the most common way to do so is in the form of an abstract syntax tree. We choose a somewhat unusual \nrepresentation of this syntax tree: each node is mapped via a nonce to its structural representation. \nThis can be viewed as an AST in which the children of each node are boxed refer\u00adences. In our algebra, \nevery edit script only affects one AST node at a time; the tree-structured relationship between the nodes \nis semantically irrelevant. As a result, this record en\u00adcoding considerably simpli.es our semantics. \nFor clarity, an example visualization of a simpli.ed BSJ AST in this record encoding appears in Figure \n16. Our representations of AST nodes in the algebra are divided into two categories: record nodes and \nlist nodes.  . l u M K ::= R ::= S ::= 1 . ::= . . ::= L ::= v ::= v ::= l | . {K . v } {M} . | . | \n< 1 (., M, S) [..] . | u | R | L node nonces labels native immutable values metaprogram identi.ers record \nlabels records metaprogram sets list nonces list element lists values Record nodes are constructs which \nare described by a .xed number of mappings from property labels to values. For ex\u00adample, nonces .a, .b, \nand .d in Figure 16 all refer to record nodes; .a, for instance, has the properties id and body. By contrast, \nlist nodes are AST nodes whose sole purpose is to contain a variable number of child nodes in a speci.c \n'' order. The nonces .c and .e in Figure 16 refer to list nodes. List nodes are distinct entities in \norder to prevent false positives in the con.ict detection system which would be invoked by the simplistic \nrepresentation of lists as a doubly\u00adlinked series of record nodes. This is discussed in detail when we \npresent the algebra s semantics in Section 3.3. Our algebra describes each list element as a three-tuple. \nThe .rst element in this tuple is a list nonce , which is either a node nonce (indicating the position \nof a node in the list) or a marker representing the beginning (.) or end (<) of the list. The tuple also \ncontains the ID of the metaprogram optional value that inserted the node and a set of metaprograms which \nhave deleted the element. The action of removing a node from a list simply marks its element as deleted \nfor reasons that, as v | b\u00b0d ::= R .(l = v) record node creation + L . | ..l . v record assignment | \n. : . + .1list add-before | + list node creation 1 | . : . ' . list add-after | . : . . list removal \nd ::= M > \u00b0d edit script element e ::= v | de expression Figure 15. Edit Script Algebra Syntax above, \nwill become clear in Section 3.3. In light of the above structure, we de.ne the formal rep\u00adresentation \nof a program as follows: De.nition 3.5. A program . = {. . v } where, for all mappings . . v , either \nv = {l . v '} (for record nodes) . or v =[.] (for list nodes). As an example, the AST in Figure 16b is \nencoded as the record shown in Figure 16c. Every edit script in the algebra consists of at most six types \nof edit script elements. Each edit script element is annotated with the ID of the metaprogram which produced \nit, although we often elide this pre.x in cases where it is unimportant. That is, if it is irrelevant \nthat M >\u00b0d was created .a . id . .b body . .c .b . identi.er . \"X\" .c . [(e, M, S), (.d, M, S), (.e, \nM, S), (<, M, S)] .d . id . .d( type . .d(( .d( . identi.er . \"x\" .d(( . type . INT .e . id . .e( \nbody . .e(( .e( . identi.er . \"foo\" .e(( . [(e, M, S), (<, M, S)] by metaprogram M, we simply write \n\u00b0d instead. The record and list node creation elements have the effect of mapping new nodes into a program. \nThe record node cre\u00ad ation element accepts as input a series of initial mappings. The list node creation \nelement does not require such map\u00adpings; newly created list nodes are always initialized to con\u00adtain \ntwo elements. The .rst element of a new list node con\u00ad tains the beginning marker; the second contains \nthe ending marker. These markers are always present in a list to guara\u00ad tee further list operations some \npoints of reference. The record assignment element changes a mapping in a speci.c record node. The newly-mapped \nvalue is always an optional value; as a result, it may be represented by b. Two types of list addition \nelement exist: add-before and 1 public class X{ 2 private int x; 3 public void foo() { } 4 } (a) Example \nSource .a class  .c .b  body X  .e .d .eld method .d   .d .e int foo body add-after. All additions \nto a list are speci.ed relative to an (c) Record Encoding (b) Simpli.ed Example AST element which already \nexists in the list. This is the primary motivation for the beginning and end markers included in every \nlist: such markers guarantee that list addition has a Figure 16. Example Record Encoding reference point \neven in an empty list. Our choice of notation is intended to re.ect the operation being performed. The \n 1 public class EditScriptExample { 2 private int foo() {} 3 [: 4 BsjNodeFactory factory = context.getFactory(); \n5 for (MethodDeclarationNode m : context.getPeers(). 6 filterByType(MethodDeclarationNode.class)) { 7 \nMethodDeclarationNode m2 = m.deepCopy(factory); 8 m2.setIdentifier(factory.makeIdentifierNode( 9 m2.getIdentifier().getIdentifier()+\"A\")); \n 10 context.addAfter(m2); 11 } 12 :] 13 [: 14 BsjNodeFactory factory = context.getFactory(); 15 for (MethodDeclarationNode \nm : context.getPeers(). 16 filterByType(MethodDeclarationNode.class)) { 17 MethodDeclarationNode m2 = \nm.deepCopy(factory); 18 m2.setIdentifier(factory.makeIdentifierNode( 19 m2.getIdentifier().getIdentifier()+\"B\")); \n20 context.addAfter(m2); 21 } 22 :] 23 } Figure 17. Edit Script Example Code . . . (identi.er = fooA) \ncreate identi.er create empty body \u00af d M1 a the case in which each BSJ metaprogram in Figure 17 is exe\u00adcuted \nover its original AST. The .rst metaprogram produces method fooA and the second metaprogram produces \nmethod fooB. Because neither metaprogram can see the method pro\u00adduced by the other, neither fooBA nor \nfooAB would be cre\u00adated. These facts are represented algebraically by the edit scripts in Figure 18: \nd\u00afM1 represents the behavior of the .rst metaprogram and d\u00afM2 represents the behavior of the second. \nIf we had desired the fooAB method in Figure 17, we could simply make the second metaprogram in our example \ndepend upon the .rst. When the second metaprogram exe\u00adcuted, it would be able to see the changes applied \nby the .rst metaprogram and react accordingly. This is not a con.ict be\u00adcause a dependency exists between \nthe two metaprograms; as a result, every respectful ordering will ensure that the .rst metaprogram executes \nbefore the second. Gathering edit scripts instead of executing the metapro\u00adgram directly over a changed \ntree trivially obviates read\u00adwrite con.icts: because a metaprogram s input only includes the scripts \nfrom its dependencies, it cannot see the effects of R .a L . ' .c : . '' + < add fooA to class them. \nBut the mere gathering of edit scripts does not prevent a dual-write con.icts. Dual-write con.icts are \ncaptured in the R .b(identi.er = fooB) +++ + R . '' (id = .a, body = . ' ) create fooA method a a unordered \nmetaprograms and is therefore unable to react to . . . . . create identi.er form of merge failures as \ndescribed in the next section. create empty body \u00af d M2 .c : . '' b + < add fooB to class This section \nde.nes the semantics of the edit script algebra. We relate operations that BSJ metaprograms can perform \nFigure 18. Example Edit Scripts on a node to edit script elements (d). We also describe the ++ L . ' \nb  3.3 Edit Script Semantics R . '' (id = .b, body = . ' ) create fooB method b b . . arrow in a list \naddition routine always points towards the evaluation semantics . (as in d(.) . . ') for applying an \n1 newly inserted element and away from the reference point. . ' . '' 1 . '' edit script element to a \nprogram. indicates that . 'For instance, . was inserted + : When a node is created in a BSJ metaprogram, \nthe node into the list . immediately before the element containingfactory generates an appropriate edit \nscript element repre\u00ad (which may be a beginning or end marker). On the other . '' ' . ' indicates that \n. ' 1 senting node creation. Any method invocations which alter hand, . 1 was inserted after that node \n(such as a property setter or a list addition) gen\u00ad. ''. The removal element s notation : the element \ncontainingerate edit script elements to capture the modi.cation logic mirrors that of the addition elements; \nwhile the addition elements show the arrow originating from the bottom of the line, the list removal \nelement s arrow points in that direction. As an example of the edit script algebra in use, we pro\u00advide \nthe simple program in Figure 17. Both metaprograms in the .gure perform similar operations. The .rst \ncreates a copy of every method in the class, suf.xing A onto the method name. The second metaprogram \nsuf.xes B instead. In a traditional metaprogramming environment, we would always see methods foo, fooA, \nand fooB. However, we would also see either fooBA or fooAB depending on the metaprograms execution order. \nThis is an example of how a traditional metaprogramming model produces a read-write con.ict: the metaprogram \nwhich is executed last is basing its behavior on the metaprogram which is executed .rst even though the \ntwo metaprograms are unordered. In a difference-based metaprogramming environment, however, each metaprogram \nis executed independently over a copy of the program to calculate its edit script. Consider of those \nactions. Because every child of a BSJ node is ei\u00adther itself a node or is an immutable value, all changes \nto the tree will occur through the AST API; thus, every change is recorded in the form of an edit script \nelement. List nodes in the BSJ API may be changed either through the addition or removal of their child \nelements. Removal is speci.ed in terms of the child to remove. Addition is spec\u00adi.ed in terms of a reference \nchild (which is already in the list), the new child to add, and a direction (before or af\u00adter). The java.util.List \ninterface is implemented in the API over list nodes, but the implementation translates such calls to \na series of these primitives; for instance, an invo\u00adcation of List.add generates an edit script element \nof the form . : . ' + <. We do this to map the relatively full\u00adfeatured Java List interface onto our \nalgebra. In our expe\u00adrience, metaprograms operating over an AST s list are con\u00adcerned with relative operations \n(such as insert print state\u00adment before variable assignment ) rather than with absolute operations (such \nas insert print statement at index 5 ).  RECORD NODE CREATION RULE . . . .v}] . . ' v/.[. .{l . (+ v)) \n. . . ' R .(l = LIST NODE CREATION RULE . . . ., M, \u00d8), (<, M, \u00d8)]] . . ' v/.[. . [( L .) . . . ' (M \n> + RECORD ASSIGNMENT RULE . . R . ..[. . R[l . v ]] . . ' (..l . v ) . . . ' LIST ADD BEFORE RULE .3 \n1 Record assignment is simplistic compared to the other rules in this algebra. We locate the record corresponding \nto the nonce for which the assignment is taking place. In that record, we substitute the label s current \nmapping for one which re.ects the new value. We then substitute the resulting record into the program \nto obtain our new program. The list addition rules appear somewhat more complex. Addition to a list always \noccurs relative to another element which is already in the list. This is the motivation for the begin( \n)andend(<) elements: because they are always present in the list, they provide available reference points \neven if the list is empty. Addition before the begin element or after the end element are, of course, \nprohibited. Each = list cell is a triple composed of the list nonce it represents, ..' ...'' ] ,.3, \n..3 = S(.3, M, L) ' ..' ...'' ] ' =[, (.2, M, \u00d8),.3,.[.1 . L .3) . . . ' .3 1 11 .1 . L . . L =[ the \nmetaprogram responsible for inserting it, and a set of ] . . ' metaprograms which have marked it as deleted. \nBecause every list operation uses a list nonce as a refer\u00ad ence point, that list nonce must uniquely \nidentify a cell in L (M > .1 : .2 + LIST ADD AFTER RULE 1 the list for the metaprogram applying the \noperation. To do = < . ' 1 so, we de.ne the search function S: ....'' ] . ' .3, ., M, L) ..3 = S(.3, \nM, L) ' ..' ...'' ] ' =[,.3, (.2, M, \u00d8),.[.1 . L .3 11 .1 . L . . L =[ . , ' De.nition 3.7. | S( , M \n, S): L = ] . . ' . L . iff {(' ..M'' . S.M /'' } = {.}. - M M- M ' .2) . . . ' (M > .1 : The intuition \nof the S function is to provide a view of the list consistent with the dependencies of metaprogram M. \nAny elements added by metaprograms that M can see will not be considered by the search. Any elements \nadded by a metaprogram that M can see but removed by a metaprogram that M cannot see will still be considered. \nThis is necessary to ensure that the metaprogram cannot observe any list op\u00aderations performed by other \nmetaprograms which are not its dependencies; otherwise, a read-write con.ict would be pos\u00adsible. For \nexample, suppose that metaprogram M1 adds an ele\u00adment .i to a list; that M2 M1 and M2 removes the ele\u00adment \nfrom the list; and that M3 M1 and M4 M2. In this case, the list would contain a cell (.i, M1, {M2}). \nBe\u00adcause M4 depends on M2, it should not see the element in the list. Because M3 depends on M1 but not \non M2, it should see the element in the list. We must be able to satisfy both of these conditions at \nthe same time. This is the purpose of the S function: because the only deleting metaprogram of the cell \nis M2 and because M3 / M2, the cell is not consid\u00adered deleted for M3. Similarly, we use the inserting \nmetapro\u00adgram s identi.er to guarantee that some other metaprogram M5 which is not ordered with these \nother metaprograms can\u00adnot see the element in the list (because M5 / M1). In light of the above, both \nlist addition operations are fairly simple. We locate the list structure in the program and we locate \nthe appropriate cell in the list. We then de.ne a new list with the new cell in the appropriate location \nand substitute it back into the original program. The list removal rule works in much the same way, but \nit does not actually remove the cell from the list; it is the pervue of each metaprogram to decide (by \nuse of the S function) whether or LIST REMOVE RULE .1 . L . . .' ..' ...'' ] .2 =(.2, M , S) = S(.2, \nM, L) L =[,.2, ' ..' ' ..'' ] ' L =[, (.2, M , S .{M}),.[.1 . L ] . . ' (M > .1 : . .2) . . . ' RECURSIVE \nAPPLICATION RULE VALUE RULE d ' e . . d. . . ' d (d ' e) . . ' v . v Figure 19. Edit Script Semantics \nApplication of edit script elements to programs is de.ned in terms of the big-step semantics in Figure \n19. The evalu\u00adation relation (.) relates algebraic expressions to their val\u00adues. Expressions include \nedit script application; values in\u00adclude object programs. The . function is de.ned in terms of this algebra: \nDe.nition 3.6. .(d, .)= . ' iff d. . . ' . These semantics make use of a list search function S de.ned \nin the discussion below. Certain properties of this algebra are worth observing. First, recall that programs \n. are merely mappings R from nonces to node structures. As a result, each nonce added by the creation \nrules must be unique. This property is enforced by the rules themselves as they will not overwrite a \nmapping for an existing node; thus, any sequence of edit script ele\u00adments applied to a program which \ncontains two creations of the same nonce will not evaluate.  \u00b7\u00b7\u00b7 creation of code literal expression \nRECORD ASSIGNMENT CONFLICT RULE ' v = v R .a(\u00b7\u00b7\u00b7 ) create print method invocation M > + ' M > .c : ' \n.a add method invocation to body ..l . v ..l . v ABCRDD EFORE ONFLICT ULE 1 \u00b7\u00b7\u00b7 creation of code literal \nexpression ' .(.2) .(.2' ) M R .b(\u00b7\u00b7\u00b7 ) create print method invocation > + .3 .1 : . ' .3 1 .1 : .2 \n+ + ' > .c : ' .b add method invocation to body M 2 1 Figure 20. Simple Con.ict Edit Scriptlets ADD \nAFTER CONFLICT RULE .(.2) .(.2' ) .3 .3 1 not each removal applies, so the removal rule simply updates \n' . ' 2 ' .2 .1 :.1 : the deletion set for that cell.  3.4 Merging Edit Scripts While read-write con.icts \nare obviated by the extraction of edit scripts as described in Section 3.2, dual-write con.icts are still \npossible. The con.ict shown in Figure 5, for in\u00adstance, is a type of dual-write con.ict. The relevant \nportions of the edit scripts are shown in Figure 20. In these scriptlets, .c is taken to be the nonce \nof the method body and .a and .b are taken to be the nonces of the code literal expressions. In light \nof the semantics of edit scripts described in Fig\u00adure 19, it is quite clear that these metaprograms are \nin con\u00ad.ict: their execution order will affect the ordering of .a and .b in the .nal program. But the \nvery similar edit scripts pre\u00adsented in Figure 18 are not in con.ict. The order in which they are executed \nwill affect the ordering of the methods in the resulting program s class declaration but, unlike state\u00adments \nin a method, that ordering is not signi.cant in Java. Complicating matters is the fact that this ordering \nsignif\u00adicance is not a property of the list itself; it is a property of the node in the list. In Java, \nfor instance, the ordering of el\u00adements in the body of a class declaration is largely insignif\u00adicant: \na method can appear before or after another method without affecting the semantics of the program. But \nthe or\u00addering of some of those elements may matter: the ordering of initializers is signi.cant. Our algebra \naccommodates this node-based signi.cance in ordering by introducing the order-dependence function .. \nThis function is simply an abstract .xed predicate over node nonces. When the algebra is applied to a \nspeci.c language, the . predicate should match those nodes whose order in a list is signi.cant. UNORDERED \nCREATION CONFLICT RULE L .. . d ' R .(l . v ) . d = + d = + d d ' Figure 21. Con.ict Semantics ' . ' \n. . L . . . . . L . . Further, E = ..' ...' .' {: L | .j =(. ' , M, \u00d8)} = {: L | .j =(. ' , M, \u00d8)}. ..' \n. Finally, for all (,. '' ) . E \u00d7 E, if .(. ' ) . .(. '' ), then .. '' ' . ' appears before .in L iff \nit also does in L . d ~d\u00af' For any two edit scripts d\u00afand d\u00af', the expression \u00af= indicates that .. . \nP.(.(\u00af=(.(\u00af d, .)) ~d ' ,.)). For convenience, we use d\u00af(d\u00af' = d\u00af' (\u00af .) ~d.) to denote that 1 .(d, \n.\u00af(d\u00af' ,.)) ~d ' ,.(\u00af = .(\u00afd, .)). Intuitively, the above de.nition states that two programs are equivalent \nas long as they are identical except for the relative ordering of order-independent elements in their \nlists. Using the above de.nitions, we can now combine the edit scripts produced by each metaprogram. \nDual-write con.icts are detected by de.ning the element con.ict relation ( ); we de.ne this relation \nas the least symmetric relation following the rules shown in Figure 21. These rules use the notation \n. . d, which indicates that . appears in the element d. For instance, . . (. : . . ' ) but . '' ./(. \n: . . ' ). We then wish to use this element con.ict relation to deter\u00admine whether or not two edit scripts \ncan be composed with\u00adout ambiguity. First, we de.ne a predicate which describes whether or not two edit \nscripts are mergable. \u00afd\u00af' De.nition 3.10. Two edit scripts d and are mergable '' (equiv., d\u00af?d\u00af') iff \n.(M>d, M >d ' ) . d\u00af\u00d7d\u00af' - M.\u00ac(d .M De.nition 3.8. A node represented by the nonce . is order-d ' ). \ndependent iff .(.). For convenience, we say that the nonce is order-depdendent if the node is order-dependent. \nThe Intuitively, two edit scripts are mergable if (1) the order order-dependence of a node is constant. \nin which they should be concatenated is .xed because of the dependency graph or (2) the composition of \nthe two edit Our de.nition of order-dependence now allows us to scripts commutes up to equivalence. specify \nthe equivalence relation between programs: 1 ?makes use of the element con.ict relation de.ned in Figure \n21. ThisDe.nition 3.9. Two programs . = {. . v } and . ' = latter relation holds in the cases in which \ndual-write con.icts ~ {. . v '} are equivalent (equiv., . = . ') iff all of the can occur. Node creation \nbetween unordered metaprograms,following are true: for example, only causes a con.ict when they attempt \nto . . R . . . . . R . . ' create nodes using the same nonce. In practice, this should As described \nabove, the mergable relation  never occur; the BSJ compiler guarantees that every AST node in a compilation \nis given a unique ID. List insertion between unordered metaprograms only con.icts when the lists and \nreference points are the same and both elements are ordered. This ordering exception is made to ensure \nthat two edit script elements are consid\u00adered non-con.icting as long as the programs they produce Figure \n22. Example Injection Con.ict structural), available information about the transformation are equivalent \n(even if their ASTs are distinct). Making this exception for lists considerably improves the programming \nexperience of languages such as BSJ, as it allows metapro\u00adgrammers to focus on the semantics (rather \nthan the syntax) of the object program. Removal of a node from a list never causes a con.ict be\u00adcause \nit can always be merged. If two metaprograms remove the same element from a list, the merge of those \noperations should simply remove that element from the list. process (state-based, changed-based, or operation-based), \nand con.ict detection strategy (ad-hoc, con.ict tables, con\u00ad.ict sets, etc.). The algebra presented here \nrepresents pro\u00adgrams syntactically and the merge operator describes an operation-based merge over edit \nscript elements. The ele\u00adment con.ict relation corresponds to a simple con.ict table.  3.5 Injection \nCon.icts Metaprogram injection, discussed in Section 2.5, gives rise 1 11 which successfully combines \ntwo edit scripts if and only if they are mergable. to a particularly eldritch problem known as an injection \ncon\u00ad d and d ' dd ' d ?d ' \u00af \u00af \u00af  \u00af \u00af \u00af We then de.ne the merge operator .ict. An injection con.ict \noccurs when a metaprogram in-De.nition 3.11. The merge between two edit scriptsjected into the AST could \nresult in violating a previously\u00ad (equiv. is de.ned as: satis.ed dependency constraint. Like other con.icts, \nthe 11 d ' If \u00ac(d ? d \u00af\u00af \u00af\u00af ,d 1' ,...,d ' m iff = d1,...,dn presence of an injection con.ict in the \ndependency graph d ' ), then this merge is said to fail. Our key objective, as stated at the beginning \nof Section 3, causes a compilation error. Figure 22 contains a dependency graph with an injec\u00ad 111 \u00af\u00af \n is that to ensure that a compilation only produces an output tion con.ict. At the start of compilation, \nthree metaprograms (,and )areknowntoexist; doesnotyetexist programwheneveryrespectfulorderingofmetaprogramsis \nMMMM,1234 \u00af equivalent. We state this objective as Theorem 1: and none of the dashed or dotted lines \nare present. This graph \u00af demonstrates that M3 depends on target t and therefore must Theorem 1. Given \nmetaprograms Ma, M1,..., Mn in a de\u00ad k of {M2, M3, M1}, and {M2, M1, M3}. da dk1 \u00b7 dkn not execute until \nafter M2 executes. There are three exe\u00ad da,d1,..., duced by those metaprograms. If any respectful ordering \n\u00af\u00af\u00afdn pendency graph G, letbe the edit scripts pro\u00ad cution orders that observe that constraint: {M1, \nM2, M3}, these metaprograms successfully merge \u00b7\u00b7 , Presume that M1, when executed, adds M4 to the depen\u00ad \n\u00af k ' of these metaprograms pro\u00adduces an equivalent object program. then every respectful ordering dency \ngraph. Also presume that M4 declares that it is a mem\u00ad ber of target t. This information is represented \nby the dotted A proof of this theorem appears in Appendix A of [13]. portions of Figure 22. In this \ncase, M3 should not run until Once all metaprograms have been executed and their edit after M4 runs. \nSince M4 cannot run until it is created by M1, scripts have been produced, the compiler chooses a respect-we \ncan see that M3 should not run until M1 runs. This in\u00ad \u00af k and computes . By Theorem 1 above, every such \nre\u00ad ful ordering of metaprogram edit scriptsvalidates the execution order {M2, M3, M1}, but we cannot \n11 \u00af d* \u00b7 dkn know this until compilation is partially complete; if we had spectful ordering produces \nan equivalent program. If the initially chosen that execution order, we will .nd ourselves \u00af\u00afdk1 = \u00b7\u00b7 \nmerge is successful, the resulting \u00af d* nal AST and the result is serialized into Java source code for \ncompilation. If this merge is unsuccessful, a compile-time error is generated and compilation halts. \nWe have thus accomplished our key objective. The BSJ compiler follows the algebra above and this algebra \nensures that its behavior is always deterministic: if no element con\u00ad.ict is found during the merge of \na given respectful ordering of edit scripts, then every respectful ordering produces the same program \n(up to equivalence). As a result, the program\u00admer can take successful compilation to mean that the BSJ \nprogram has exactly one meaning. We can relate the merge operator to software merging, which can be categorized \nin several different ways [12]: the program representation (textual, syntactic, semantic, or is applied \nto the origi-inserting M4 after M3 has already executed! Furthermore, we cannot simply detect when such \nan ordering is chosen and produce a compile error; we must produce a compile er\u00adror if any legal execution \norders (including those we are not running) become invalid during the process of compilation. Otherwise, \nan arbitrary execution order decision by the com\u00adpiler determines whether compilation succeeds or fails \nand we no longer have unambiguous compilation. Recall from De.nition 3.3 that all edges in the depen\u00addency \ngraph are either explicit or implicit. Edges represent\u00ading declared dependencies are always explicit. \nIn the case of metaprogram injection, however, an implicit target is created which corresponds to the \ninjecting metaprogram. The in\u00adjected metaprogram then gains an implicit dependency upon that target and \nthe injecting program implicitly becomes a member of it. This models the fact that the injected metapro\u00adgram \n(such as M4) cannot execute until after the injecting metaprogram (such as M1) is .nished.  Next, we \nmust de.ne the condition which prevents an in\u00adjection con.ict between two nodes. This condition is termed \nan injection dependency and is de.ned below. Note that in\u00adjection dependencies are only de.ned over a \nwell-formed de\u00adpendency graph. De.nition 3.12. Let the following path-like relations be de.ned between \nnodes in a dependency graph G. M M': A path exists from M to M' in G which consists entirely of explicit \nedges. . M.M': A path exists from M to M' in G which consists of an implicit edge from M to some target \nand an implicit ' edge from that target to M . M /. M': An injection dependency exists between M and \n' M in G: for each metaprogram M in G, let S .= . M ' .' /. {M.| .. .}. Then, MM' iff (. M M' ).(|SM| \n> MM '' '' /. 0 ..M . SM, M M' ). /. ' The de.nition of MM identi.es the conditions neces\u00adsary to ensure \nthat the ordering information present in the dependency graph was already present before injection. The \n.rst term of the conjunction indicates that no new informa\u00ad ' tion is introduced if M and M were already \nordered. The second term expresses a constraint meant to handle cases of recursive injection: no new \nordering is introduced if we explicitly depend upon whatever our injector depends upon (or whatever those \nmetaprograms depend upon, recursively). This recursion is clearly well-founded for a well-formed de\u00adpendency \ngraph as such graphs are acyclic. We now de.ne an injection con.ict as follows: De.nition 3.13. An injection \ncon.ict exists from M over ' '' M with the nodes in SM( iff |SM( | > 0 and .M . /. '' S M( , \u00acMM Intuitively, \nDe.nition 3.13 reads as follows: if any metapro\u00ad ' gram M depends on another metaprogram M and that ' \nmetaprogram M was generated (directly or indirectly) by some metaprograms in SM( , then M must not be \na candidate ' for execution until M exists. We ensure that M is not ex\u00ad ' ecuted until M exists by ensuring \nthat M cannot run until '' after some M . SM( runs. For example, consider Figure 22. We can now see that \nan injection con.ict exists from M3 over M4 with M1. We have that SM4 = {M1} and so |SM4 | > 0; we also \nhave /. that \u00acM3 M1 because \u00acM3 M1 and because M3 is not an injected metaprogram (meaning that |SM3 | \n=0). We have thus reached our goal of detecting injection con.icts independent of the chosen execution \norder. Also, the phrasing of the injection con.ict conveys a solution which can be communicated to the \nprogrammer: if M has an injection con.ict over M' with SM(( , then the con.ict can be resolved by explicitly \ndeclaring any dependency such that '' '' MM for M . SM( . While the BSJ reference implementation treats \nan injec\u00adtion con.ict as an error, we observe that this is not strictly necessary. In cases in which \nwe chose an execution order that triggered the con.ict, our difference-based metaprogram\u00adming model allows \nus to simply recompute the edit scripts for any affected metaprograms and their dependents. Con\u00adsider, \nfor instance, the case in which we have the graph in Figure 22 and we chose the execution order {M2, \nM3, M1}. Upon executing M1 and discovering the injection con.ict, it would be possible to prepare another \ninput AST for M3 (this time including the edit script from M4) and recompute its edit script, discarding \nthe old one. In effect, we would then have the execution order {M2, M1, M4, M3}. This would not be possible \nin a traditional metaprogramming model, as it would not be possible in the general case to undo the changes \na metaprogram made to the AST. The BSJ refer\u00adence implementation does not include this feature we be\u00adlieve \nthat the metaprogrammer would wish to .x the incon\u00adsistency but this solution helps to illustrate the \nnature of injection con.icts.  3.6 Restrictions Our compiler reference implementation uses the edit \nscript algebra to ensure unambiguous output (although a proof of correctness of the reference implementation \nis clearly be\u00adyond the scope of this paper). This property of unambiguity relies upon the compiler s \nability to isolate metaprograms from each other. Because BSJ metaprograms are capable of escaping the \nJVM in several ways (I/O, JNI, etc.), per\u00adfect con.ict identi.cation would require signi.cant informa\u00adtion \n.ow instrumentation from the JVM and underlying op\u00aderating system. In order to make implementation tractable \nand prevent excessive restrictions, two sacri.ces were made. These represent potential false negatives \nin the BSJ con.ict detection system, so metaprogrammers should observe them with care: Unordered metaprograms \nmust never communicate. This includes all forms of communication. For instance, a metaprogram must not \nwrite to a .le that another metaprogram reads or use the same global variables that another metaprogram \nuses. Metaprograms may not use any external resource to obtain access to AST nodes. The creation of new \nnodes must be done via the node factory provided by the metaprogram s context; access to existing nodes \nmust be obtained by following references from the metapro\u00adgram s anchor. These two restrictions prove \neasy to follow in practice; accidental violation, for instance, does not appear to be a concern. Pending \nfurther experience, we accept these restric\u00adtions in exchange for the con.ict detection behavior that \nthey provide.  4. Code Literals As discussed in Section 2.6, BSJ provides a quasiquoting syntax known \nas a code literal. Code literals permit a very readable and terse form of AST construction. Unfortunately, \nthe meaning of some code literals can be dif.cult to ascer\u00adtain. The literal <:x:>, for instance, could \nbe interpreted as an identi.er, a simple name, a singleton list of type refer\u00adences (as in an implements \nclause), or any of thirteen other meanings. A parser would normally distinguish based on its internal \nstate but, since this code has been removed from its context, this is not possible. Previous work has \nexplored the problem of correctly in\u00adferring the type of the code literal. MetaAspectJ [9] uses guess-parsing \n: parse rules are tried in order and the .rst match is used. Unfortunately, when multiple rules match, \nthe values corresponding to those parses which were not chosen cannot be expressed. A more elegant approach \nexists in [3]. This approach involves lifting the code (translating object program code to a metaprogram \nAST which creates it) into a set of construction forms and then eliminates those forms which do not successfully \ntypecheck. If exactly one form typechecks correctly, this form is used as the meaning of the object program \ncode fragment. BSJ uses a solution similar to that of [3] but defers the lifting of code until after \ntypechecking is complete. Instead, the code literal is directly represented as a family of types in the \nBSJ type system. This has two effects. First, it provides opportunities for improving the performance \nof the disam\u00adbiguation process: BSJ does not need to parse or lift code literal productions that it knows \nwill not successfully type\u00adcheck. Second, it becomes clearer the impact that the code literals will have \non the semantics of the metaprogram in which they are used. We begin this section by introducing selection \ntypes, the family of types which represents code literals in the BSJ language. We then explain the evaluation \nprocess for code literals. Finally, we provide an analysis of the properties of the code literal model \nof quasiquoting. 4.1 Selection Types BSJ introduces a new type family over those it inherits from Java: \nselection types. Selection types are similar to Java s intersection types in that they are used in a \nvery constrained fashion and are impossible to represent explicitly using the language s syntax. BSJ \nprogrammers should generally not require a deep understanding of selection types. A selection type is \nformed over a bag of types. We use the notation {A,B}&#38; to represent the selection type between A \nand B. This selection type contains all selection bags which contain a value of type A and a value of \ntype B. We use the notation {x,y}&#38; to denote the selection bag of the values x SELECTION BAG TYPE \nRULE G f e1 : t1 \u00b7\u00b7\u00b7 G f en : tn G f{e1,. . . ,en}&#38; : {t1,. . . ,tn}&#38; SELECTION TYPE REORDERING \nRULE .(k . v) . m, (k ' . v ' ) . m.(k = k ' . v = v ' ) '' t1 = t \u00b7\u00b7\u00b7 tn = t m[1] m[n] '' }&#38; ~}&#38; \n{t1,. . . ,tn= {t1,. . . ,t n EQUIVALENCE RULE '' ~'' t ~ e : te = e = t e : t SELECTION TYPE PROJECTION \nRULE ' .!k.tk <: t ' G f{t1,. . . ,tn}&#38; t Figure 23. Selection Type Rules and y; if x : A and y : \nB, then {x,y}&#38; : {A,B}&#38;. Because bags are unordered, {A,B}&#38; = {B,A}&#38; and {x,y}&#38; = \n{y,x}&#38;. Selection types are not reference types and are not related via subtyping. The type rules \nfor selection types, presented in Figure 23, are similar to those of record types in most languages. \nUn\u00adlike record types, selection types are unlabeled, making tra\u00additional projection impossible. Projection \nfrom a selection bag is performed implicitly: via the selection conversion. We write A B to indicate \nthat type A can be selection\u00adconverted to type B. The Selection Type Projection Rule al\u00ad ' lows a selection \ntype to be converted to another type t if exactly one of its component types is a subtype of t '. The \nselection conversion is legal in the conversion contexts of assignment, method invocation, and casting.2 \nThe choice of notation for selection types was inspired by the additive conjunction from linear logic. \nAn additive con\u00adjunction represents an alternative occurrence of resources, the choice of which belongs \nto the consumer. In this case, the selection type is analogous to the resources and the pro\u00adgrammer is \nthe consumer. The selection conversion is an in\u00adference mechanism for determining the choice of resource \non the programmer s behalf.  4.2 Evaluating Code Literals We can use selection types to capture the \nmeaning of code literals. This is demonstrated by the equivalences de.ned in Figure 24 which use the \nnotation from the de.nition below. De.nition 4.1. The following notation is used in Figure 24. R is the \nset of all parse rules: a set of functions which accept a sequence of tokens and produce a selection \nbag of AST node values. Each element is of the form rp, where p is the set of output types for the rule \nr. 2 Chapter 5 of The Java Language Speci.cation [8] provides a complete de.nition of conversions and \nconversion contexts in the Java language.  CODE LITERAL EQUIVALENCE RULE + G f <:c:> ~. v}&#38;= {rp(c): \nrp . R . rp(c) PARSE EXECUTION TYPE RULE '' rp(c) . v . t t<: t +vTt . p G f rp(c): t Figure 24. Code \nLiteral Rules 1 LocalVariableDeclarationNode n1 = <: TypeNode t = <: 5 :>; :>; 2 LocalVariableDeclarationNode \nn2 = <: int x = y; :>; Figure 25. Nested Code Literal Example rp(c) is used to describe the processing \nof the token sequence c by the parse rule rp. This is an evaluation which is performed by the compiler \nand so can be used to affect the static typing of object program expressions.  xT  . t is used to indicate \nthat x has the runtime type t . This is distinct from x : t in that the latter expresses a statically \nprovable relationship in the object program. The prior expresses a dynamically proven relationship in \nthe metaprogram. + e . v is used to indicate that metaprogram expression e evaluates to metaprogram expression \nv at metaprogram runtime. The Code Literal Equivalence Rule in Figure 24 is used to specify a selection \nbag to which the code literal is equivalent. If there exists exactly one value in the selection bag which \nhas a type corresponding to the expected type in the code literal s context, the Selection Type Projection \nRule would project that value, making the code literal expression equiv\u00adalent to it. To accommodate these \nsemantics, the reference implementation lifts the projected value into an expression which will, when \nexecuted, produce that value. This expres\u00adsion then replaces the code literal in the AST after type\u00adchecking \nis complete. This is to say that, after the process of lifting is complete, the code in Figure 12a will \nbe replaced by the code in Figure 12b. BSJ code literals are not typechecked across multiple stages. \nConsider the code in Figure 25. The inner code lit\u00aderal on line 1 contains an expression which appears \nto be in error; there seems to be no context into which that code can be inserted without causing a type \nerror (because an integer literal is not a type). In line 2, however, we create an AST which expresses \nthe instantiation of a variable x and its ini\u00adtialization to the value of y. Unlike some metaprogramming \nlanguages, BSJ cannot guarantee in which scope the gener\u00adated code will be used; this is based on the \nruntime seman\u00adtics of the metaprogram. For this reason, it is impossible to know at metaprogram compile \ntime if the code literal will be inserted into a context where the type of y will be assignable to int \n(or even if y will be bound!). Likewise, it would be VariableNode identi.er SpliceNode IdentifierNode \nexpression VariableAccessNode Figure 26. <::vartype:x:> splicing as TypeNode ~~ VariableNode  identi.er \n UnparameterizedTypeNode IdentifierNode name SpliceNode expression VariableAccessNode Figure 27. <::vartype:x:> \nsplicing as NameNode ~~ incorrect to assume that the name TypeNode in the .rst line is bound to the BSJ \nAST type of that name. While BSJ cannot perform n-stage typechecking of metaprograms, this does not appear \nto be a concern in prac\u00adtice. Metaprograms are executed by the compiler, meaning that any errors of this \nnature will be detected before a binary object program is produced.  4.3 Code Splicing Code literals \nin BSJ permit splicing. As with quasiquotes in LISP or Scheme, splicing allows the value of a metaprogram \nAST expression to be used in literal code. This is modeled in the BSJ AST by typing each node reference \nas a disjoint union between its expected type and the type SpliceNode; for instance, SimpleNameNode has \na reference which is effectively of type IdentifierNode . SpliceNode.3 Consider the code literal <::vartype:x:> \nin the ~~ context of a variable declaration. The expression vartype refers to a variable declared in \nthe context of the metapro\u00adgram containing the code literal. The splice clearly repre\u00adsents the type \nof the variable; the token x is the identi.er to which it is bound (such as int x). Evaluating that code \nliteral produces the AST in Figure 26. Unfortunately, splicing is not this simple. The AST we produced \nin Figure 26 assumes that the splice expres\u00adsion is a TypeNode, the type of the type property for a VariableNode. \nFigure 27 shows the AST that would be constructed if vartype was bound to a SimpleNameNode. Thus, the \nAST that is built depends upon the metaprogram scope in which we interpret the splice. To address this \nproblem without introducing grammar ambiguity, we introduce a parameter to the splice grammar rule and \nuse this parameter in a semantic predicate [14] determining whether or not the rule can be accepted. \nThe argument we provide is a set of types in the form t - {t1 . \u00b7 \u00b7\u00b7 . tn}. If, in the context of the \nmetaprogram, the expression which appears in the splice is not of a type which is assignable to the argument, \nthe splice does not parse. 3 Java s type system does not support a general disjoint union type. In speci.c \ncases such as this one, however, they can be encoded.  Type ::= PrimitiveType | ReferenceType | Splice(TypeNode \n-{PrimitiveTypeNode . ReferenceTypeNode}) ReferenceType ::= UnparamType | \u00b7 \u00b7\u00b7 | Splice(ReferenceTypeNode \n- {UnparameterizedTypeNode .\u00b7 \u00b7\u00b7}) UnparamType ::= Name | Splice(UnparameterizedTypeNode) Name ::= Identi.er \n| Name . Identi.er |Splice(NameNode) Identi.er ::= Identi.erToken | Splice(IdentifierNode) Figure 28. \nSplice Grammar Rule Example For instance, consider the abbreviated grammar rules for types which appear \nin Figure 28. Because ReferenceTypeNode is a subtype of TypeNode, the Type rule ignores splices of type \nReferenceTypeNode and allows the ReferenceType rule to capture them instead. Because UnparameterizedTypeNode \nand NameNode are not subtypes, this precaution is not necessary for Unparam-Type. This approach permits \nthe parsing of code literals to disambiguate splices by using the metaprogram type environment.  4.4 \nAnalysis There are two key effects of code literals compared with the approach outlined in [3] which \nwe believe to be of interest. First, because we have deferred lifting the code literal until after typechecking, \nwe are able to exploit performance opti\u00admizations which were not previously available. For instance, \nconsider the assignment expression IdentifierNode i = <:x:>. Rather than evaluating each parse of the \nliteral im\u00ad ' mediately, we can wait until a selection conversion tt and evaluate only those parse rules \nwhich are compatible with t. This prevents the unnecessary parsing and lifting which would inevitably \nbe eliminated by the typechecking process. Additionally, the semantic impact of the BSJ code literal \nis more evident. Consider the following method signatures: String foo(A a, B b); int foo(B b, A a); If \nsome variable c of a node type C exists which is a subtype of both A and B, \u00a715.12.2.5 of [8] indicates \nthat the method invocation String s = foo(c,c) is ambiguous (because it is not clear which overloading \nis intended). If c : {C}&#38; , then this is also true with code literals. [3], however, gener\u00adalizes \ndisambiguation up to statements when quasiquoting is used and would thus select the .rst method signature \nabove (as its return type satis.es the assignment). This disconti\u00adnuity arises because the disambiguation \ntechnique used in [3] does not match the one speci.ed by the Java language. BSJ resolves this issue by \nintegrating selection types into the conversion rules in the host language s type system. 5. Implementation \nWe have developed a BSJ compiler reference implementa\u00adtion consisting of 54,000 lines of source and 193,000 \nlines of generated code. This generated code largely represents the numerous design patterns which appear \nthroughout the BSJ compiler (underscoring the need for compile-time metapro\u00adgramming in Java). The implementation \nis comprised of three parts. The .rst is the BSJ API, which all BSJ compiler implementations are expected \nto meet; it includes diagnostic interfaces, utilities, and over 200 types of AST nodes. The AST type \nhierarchy was structured to ensure that as many errors as possible are caught by the Java type system. \nThe second part of the compiler project is the reference implementation of the API. This implementation \nsupports the full Java language and, while not yet complete, is capa\u00adble of operating correctly on all \nof the examples in this paper. We have developed a Java typechecker, allowing metapro\u00adgrams to be aware \nof and sensitive to type declarations. The typechecker evaluates lazily; metaprograms tend to type\u00adcheck \nonly part of the AST at a time, making the lazy design considerably more ef.cient. The third part of \nthe project is a set of BSJ standard li\u00adbraries, which includes meta-annotations such as @@Memoized and \n@@BigIntegerOperatorOverloading shown in Fig\u00adure 7b. It also currently includes meta-annotations imple\u00admenting \ndesign patterns such as Builder, Observer, and Proxy as well as useful code manipulations such as loop \nunrolling and method delegation. 6. Related Work To our knowledge, no previous work exists which models \nmetaprogramming using the difference-based technique we have described. However, the designs of this \nmodel and of BSJ draw heavily from the work listed below. Template Haskell BSJ was largely inspired by \nexisting compile-time metaprogramming literature [7, 18] and other theoretical metaprogramming work [17, \n24]. In many ways, BSJ is most similar to Template Haskell: metaprograms use an embedded syntax, have \na clearly-de.ned execution order, and have access to declarations in scope at the call site. Unlike Template \nHaskell, however, BSJ allows non-local changes as discussed in Section 2.1. Non-local changes are critical \nfor expressing complex Java abstractions (such as @@ComparedBy) without duplication of logic. Template \nHaskell, on the other hand, restricts the programmer to in\u00adserting code into the metaprogram s position \nin the AST. Template Haskell provides n-stage typechecking: a metapro\u00adgram code fragment [|x|] cannot \nbe constructed unless the identi.er x is bound by the object program in the scope where the metaprogram. \nBSJ cannot provide n-stage type\u00adchecking because non-local changes make identifying the bindings of a \ncode literal undecidable. We consider this tradeoff acceptable because any resulting typechecking er\u00adrors \nwill manifest at object program compilation time, al\u00adlowing the programmer to address them accordingly. \n Scheme Scheme and BSJ both treat code fragments as simple ASTs. Scheme macros only expand in-place, \nhow\u00adever, and have the concern of variable hygiene prevent\u00ading global names used in macros from being \nlocally shad\u00adowed which is addressed by built-in tools like gensym. BSJ metaprograms share the concern \nof variable hygiene but, since metaprograms may inspect their environemnts, it is possible to determine \nwhich variables are bound in scope through use of simple library functions. Scheme has been used to demonstrate \nthe value of ab\u00adstracting design patterns using metaprogramming [26]. BSJ introduces this philosophy \nto the Java language using an an\u00adnotation syntax which is more amenable to the Java commu\u00adnity. BSJ metaprograms \nare also somewhat simpler to use than Scheme macros for non-generative purposes such as static analysis. \nGroovy and OJ Groovy [5] and OJ [21] are Java-like languages which allow compile-time metaprogramming \nthrough meta-object protocols. OJ programmers write metapro\u00adgramming modules which specify new declaration-modifying \nkeywords. Groovy is a dynamically typed Java language derivative which uses annotations to drive AST \ntransforma\u00adtions (similar to BSJ meta-annotations). Both Groovy and OJ provide MOPs which allow some \nform of non-local changes. However, neither language is capable of detecting con.icts if they occur; \nthus, they admit ambiguous programs which are not detected at compile-time, a quite undesirable property. \nMetaAspectJ MetaAspectJ [9] is a compile-time metapro\u00adgramming system for the AspectJ language, a Java \nlan\u00adguage extension for aspect-oriented programming. Unlike the other languages listed here, MetaAspectJ \nattempts to perform inference over a signi.cant number of quasiquot\u00ading forms. Unlike BSJ, quasiquotes \nin MetaAspectJ are dis\u00adambiguated using a simple type system; it is unclear from the paper whether this \ntype system would be suf.cient to disambiguate BSJ code literals. MetaAspectJ also permits annotation-driven \ntransformations of ASTs but, like Groovy and OJ, does not detect con.icts between metaprograms. OpenC++ \nOpenC++ [4] is a C++ language extension quite similar to OJ: the programmer may use the provided MOP \nto enhance the syntax of the language. These new syntac\u00adtic constructs are de.ned with handlers which \nspecify AST transformations. OpenC++ programs are not ambiguous, but this is not by virtue of con.ict \ndetection; like Scheme, trans\u00adformations are only permitted to expand in place, disallow\u00ading non-local \nchanges. ROSE The ROSE compiler infrastructure [15] is unique in that all of its program transformations \nmust have a total ordering. Rather than assembling metaprogram fragments which are embedded in the object \nprogram source, ROSE requires the metaprogrammer to write a single metaprogram which executes all transformations \nin sequence. This tech\u00adnique applies to a different set of domains; while ROSE coordinates large, sweeping \nchanges across a source base, BSJ s inline syntax is more suitable for abstracting design patterns and \nother descriptive code properties. Stratego Stratego/XT [25] is a framework which abstracts the task \nof building program transformation systems, pro\u00adviding a language for specifying source-to-source transfor\u00admations. \nWhile Stratego is a very general system, it is tar\u00adgeted toward more localized transformations than that \nof BSJ. It also assumes that the transformation pipeline can be expressed as a composition sequence, \nmaking it presently unsuitable for difference-based metaprogramming. Runtime Metaprogramming Mint [27], \nMetaOCaml [19] and MetaML [20] are runtime metaprogramming extensions of Java, OCaml, and ML (respectively). \nRuntime metapro\u00adgramming eases the process of generating code based on runtime input (such as by inlining \nan input matrix into an im\u00adage transformation routine for performance). The user then lifts the generated \ncode into the current runtime. While not directly related to BSJ, runtime metaprogramming systems are \nbased on like principles. 7. Conclusions We have explored difference-based metaprogramming, a technique \nwhich permits a metaprogrammer to effect non\u00adlocal changes without losing the crcitical guarantee of \nun\u00adambiguous compilation. We presented an algebra to de.ne the semantics of this programming technique \nand related it to our reference implementation of BSJ, a Java language extension for difference-based \nmetaprogramming. We also demonstrated a technique by which the meaning of code fragments in metaprograms \ncan be inferred by introducing a type family based on linear logic. BSJ metaprograms are easier to understand \nand maintain than their equivalent Java counterparts due to BSJ s terse and expressive syntax. We ensure \nthat non-local changes do not introduce am\u00adbiguity by treating metaprograms as transformation genera\u00adtors: \nrather than executing each metaprogram in turn over the same object program, we use the metaprograms \nto produce edit scripts. These edit scripts are then merged and, in the event of a successful merge, \nare applied to the original ob\u00adject program to produce the .nal result. A successful merge implies that \nany legal ordering of the edit scripts we select will have the same effect; a merge failure indicates \nthat two metaprograms are in con.ict. A proof of these property ap\u00adpears in Appendix A of [13]. We also \ndemonstrate a variation on the disambiguation technique described in [3]. We defer lifting of object \npro\u00adgram code until after typechecking, a technique that permits us further opportunities for optimization \nand that, in BSJ, in\u00adtegrates more smoothly into the Java language speci.cation.  7.1 Future Work As \ndiscussed in Section 3.4, the edit script algebra presented here is strictly of a syntactic nature; it \nhas no support for representing semantic information. Techniques for semantic software merging have already \nbeen developed [12], but it remains to be seen how those techniques would apply in a difference-based \nmetaprogramming environment. BSJ metaprograms are currently quite verbose and we are investigating remedies \nfor this problem. The BSJ standard libraries may be expanded to include meta-annotations rep\u00adresenting \ndifference-based metaprogramming-speci.c de\u00adsign patterns; syntactic sugar should prove helpful in cases \nin which such libraries are insuf.cient. BSJ metaprograms must also use explicit type coercion on AST \nnodes as they inspect their environments; further extensions to the BSJ type system could prevent the \nneed for these coercions. The call sites for BSJ always include explicit delimiter syntax. While this \nconveniently emphasizes that the code may be changed at compile time, it prevents elegant con\u00adstruction \nof language extensions in BSJ. A syntax rewriter front-end (similar to Stratego [25] or Maya [1]) would \nbe useful; this would permit new syntactic constructs to be rei\u00ad.ed as metaprograms in BSJ. This would \nalso ensure that no two syntax extensions encodings con.ict with each other. Before BSJ can achieve widespread \nadoption, signi.cant library development is necessary. While part of the attraction of compile-time metaprogramming \nis the ability to express domain-speci.c encodings, BSJ programmers would bene.t considerably from a \nrich set of general metaprogramming tools and prepared meta-annotations. BSJ will also require an IDE \ncomparable to those available to Java programmers; to this end, we have begun development of a BSJ plugin \nfor Eclipse. This project poses several questions: how should metaprograms be debugged? How are metaprograms \neffects visualized? How do we automate refactoring when some of the target code is generated? Acknowledgments \nThis work would not have been possible without the ef\u00adforts of several of our colleagues. Harisanker \nMenon toler\u00adated many impromptu discussions on the topic. Joseph Riley helped with the core implementation \nof the compiler; Uday Garikipati and Nathan Krasnopoler contributed to the BSJ standard library. An anonymous \nPLDI reviewer s feedback led to our investigation of the difference-based approach. References [1] J. \nBaker and W. C. Hsieh. Maya: Multiple-dispatch syntax extension in Java. In PLDI, pages 270 281, 2002. \n[2] D. Batory, B. Lofaso, and Y. Smaragdakis. JTS: Tools for implementing domain-speci.c languages. Software \nReuse, International Conference on, 0:143, 1998. [3] M. Bravenboer, R. Vermaas, J. Vinju, and E. Visser. \nGener\u00adalized type-based disambiguation of meta programs with con\u00ad crete object syntax. In Proceedings \nof the Fourth International Conference on Generative Programming and Component En\u00adgineering (GPCE05), \nvolume 3676 of Lecture Notes in Com\u00adputer Science, pages 157 172. Springer, 2005. [4] S. Chiba. A metaobject \nprotocol for C++, 1995. [5] Codehaus Foundation. Groovy -building AST guide, May 2010. http://groovy.codehaus.org/Building+AST+ \nGuide. [6] E. Gamma, R. Helm, R. Johnson, and J. M. Vlissides. De\u00adsign Patterns: Elements of Reusable \nObject-Oriented Soft\u00adware. Addison-Wesley Professional, 1 edition, November 1994. [7] S. E. Ganz, A. \nSabry, and W. Taha. Macros as multi\u00adstage computations: Type-safe, generative, binding macros in MacroML. \nIn MacroML. In the International Conference on Functional Programming (ICFP 01, pages 74 85. ACM Press, \n2001. [8] J. Gosling, B. Joy, G. Steele, and G. Bracha. The Java Lan\u00adguage Speci.cation, Third Edition. \nAddison-Wesley Long\u00adman, Amsterdam, 3 edition, June 2005. [9] S. S. Huang, D. Zook, and Y. Smaragdakis. \nDomain-speci.c languages and program generation with Meta-AspectJ. ACM Trans. Softw. Eng. Methodol., \n18:6:1 6:32, November 2008. [10] S. Kamin, L. Clausen, and A. Jarvis. Jumbo: Run-time code generation \nfor Java and its applications. In CGO 03: Pro\u00adceedings of the international symposium on Code generation \nand optimization, pages 48 56, Washington, DC, USA, 2003. IEEE Computer Society. [11] E. Lippe and N. \nvan Oosterom. Operation-based merging. SIGSOFT Softw. Eng. Notes, 17:78 87, November 1992. [12] T. Mens. \nA state-of-the-art survey on software merging. IEEE Trans. Softw. Eng., 28:449 462, May 2002. [13] Z. \nPalmer and S. F. Smith. Backstage Java: Making a differ\u00adence in metaprogramming. OOPSLA 11, 2011. ACM \nDigital Library supplemental material. [14] T. J. Parr and R. W. Quong. Adding semantic and syntactic \npredicates to LL(k): pred-LL(k). In In Computational Com\u00adplexity, pages 263 277. Springer-Verlag, 1994. \n[15] D. J. Quinlan. ROSE: Compiler support for object-oriented frameworks. Parallel Processing Letters, \n10(2/3):215 226, 2000. [16] A. D. Robison. Impact of economics on compiler optimiza\u00adtion. In Proceedings \nof the 2001 joint ACM-ISCOPE confer\u00adence on Java Grande, JGI 01, pages 1 10, New York, NY, USA, 2001. \nACM. [17] T. Sheard. Accomplishments and research challenges in meta\u00adprogramming. In SAIG 2001: Proceedings \nof the Second In\u00adternational Workshop on Semantics, Applications, and Imple\u00admentation of Program Generation, \npages 2 44, London, UK, 2001. Springer-Verlag. [18] T. Sheard and S. P. Jones. Template meta-programming \nfor Haskell. In ACM SIGPLAN Haskell Workshop 02, pages 1 16. ACM Press, 2002.  [19] W. Taha and et. \nal. MetaOCaml: A compiled, type-safe multi\u00adstage programming language. http://www.metaocaml. org/. [20] \nW. Taha and T. Sheard. MetaML and multi-stage program\u00adming with explicit annotations. Theor. Comput. \nSci., 248(1-2): 211 242, 2000. [21] M. Tatsubori and S. Chiba. Programming support of design patterns \nwith compile-time re.ection, 1998. [22] L. Tratt. Compile-time meta-programming in a dynamically typed \noo language. In Proceedings of the 2005 symposium on Dynamic languages, DLS 05, pages 49 63, New York, \nNY, USA, 2005. ACM. [23] T. L. Veldhuizen. C++ templates are turing complete. Techni\u00adcal report, 2003. \n[24] T. L. Veldhuizen. Tradeoffs in metaprogramming. In PEPM 06: Proceedings of the 2006 ACM SIGPLAN \nsymposium on Partial evaluation and semantics-based program manipula\u00adtion, pages 150 159, New York, NY, \nUSA, 2006. ACM. [25] E. Visser. Program transformation with Stratego/XT: Rules, strategies, tools, and \nsystems in StrategoXT 0.9, 2004. [26] D. von Dincklage. Making patterns explicit with metapro\u00adgramming. \nIn GPCE 03: Proceedings of the 2nd interna\u00adtional conference on Generative programming and compo\u00adnent \nengineering, pages 287 306, New York, NY, USA, 2003. Springer-Verlag New York, Inc. [27] E. Westbrook, \nM. Ricken, J. Inoue, Y. Yao, T. Abdelatif, and W. Taha. Mint: Java multi-stage programming using weak \nseparability. In ACM SIGPLAN 2010 Conference on Programming Language Design and Implementation (PLDI \n10), June 2010.    \n\t\t\t", "proc_id": "2048066", "abstract": "<p>We propose Backstage Java (BSJ), a Java language extension which allows algorithmic, contextually-aware generation and transformation of code. BSJ explicitly and concisely represents design patterns and other encodings by employing compile-time metaprogramming: a practice in which the programmer writes instructions which are executed over the program's AST during compilation. While compile-time metaprogramming has been successfully used in functional languages such as Template Haskell, a number of language properties (scope, syntactic structure, mutation, etc.) have thus far prevented this theory from translating to the imperative world. BSJ uses the novel approach of difference-based metaprogramming to provide an imperative programming style amenable to the Java community and to enforce that metaprograms are consistent and semantically unambiguous. To make the feasibility of BSJ metaprogramming evident, we have developed a compiler implementation and numerous working code examples.</p>", "authors": [{"name": "Zachary Palmer", "author_profile_id": "81490696629", "affiliation": "The Johns Hopkins University, Baltimore, MD, USA", "person_id": "P2839301", "email_address": "zachary.palmer@jhu.edu", "orcid_id": ""}, {"name": "Scott F. Smith", "author_profile_id": "81542994156", "affiliation": "The Johns Hopkins University, Baltimore, MD, USA", "person_id": "P2839302", "email_address": "scott@jhu.edu", "orcid_id": ""}], "doi_number": "10.1145/2048066.2048137", "year": "2011", "article_id": "2048137", "conference": "OOPSLA", "title": "Backstage Java: making a difference in metaprogramming", "url": "http://dl.acm.org/citation.cfm?id=2048137"}