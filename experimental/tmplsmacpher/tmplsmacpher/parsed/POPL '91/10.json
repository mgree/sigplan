{"article_publication_date": "01-03-1991", "fulltext": "\n The Complexity of Type Inference for Higher-Order Typed Lambda Calculi Courant Fritz Henglein Institute \nof Mathematical New York University New York, N.Y. 10012 and Sciences Harry G. ikfairsonf Computer Science \nDepartment Brandeis University Waltham, Massachusetts 02254 Computer Science Department Utrecht University \n3508 TB Utrecht The Netherlands Abstract We analyze the computational complexity of type inference for \nuntyped A.terms in the second-order polymorphic typed ~-calculus (l z) invented by Gi\u00adrard and Reynolds, \nas well as higher-order extensions F3, F4, . . . . Fw proposed by Girard. We prove that recognizing the \nF2-typable terms requires exponential time, and for Fw the problem is nonelementary. We show as well \na sequence of lower bounds on recogniz\u00ading the Fk-typable terms, where the bound for Fk+l is exponentially \nlarger than that for Fk. The lower bounds are based on generic simulation of Turing Machines, where computation \nis simulated at the expression and type level simultaneously. Non\u00adaccepting computations are mapped to \nnon-normalizing reduction sequences, and hence non-typable terms. The accepting computations are mapped \nto typable terms, where higher-order types encode reduction sequences, and first-order types encode the \nentire computation as a circuit, based on a unification simulation of Boolean logic. A primary technical \ntool in this reduction is the composition of polymorphic functions having different domains and ranges. \n*Supported in part by Office of Naval Research grant NOO14-9O-J-111O t Supported by grants from Texas \nInstruments and fmrr the Tyson Foundation. Permission to copy without fee all or part of this material \nis granted provided that the copies are not made or distributed for direct commercial advantage, the \nACM copyright notice and the title of the publication and ha date appear, and notice is given that copying \nis by permission of the Association for Computing Machinery. To copy other\u00adwise, or to republish, requires \na fee and/or specific permission. @ 1990 ACM 089791-419-8/90/0012/01 19 $1.50 119 These results are the \nfirst nontrivial lower bounds on type inference for the Girard/Reynolds system as well as its higher-order \nextensions. We hope that the analy\u00ad sis provides important combinatorial insights which will prove useful \nin the ultimate resolution of the complexity of the type inference problem. 1 Introduction One of the \noutstanding open problems in programming language theory and type theory is the decidability of type \ninference for the second order polymorphic typed A\u00adcalculus invented by Jean-Yves Girard [Gir72] and \nJohn Reynolds [Rey74]. More precisely, does there exist an effective procedure which, given an untyped \nA-term, can decide whether the term is typable in the Girard/Rey\u00adnolds system? If so, and the term is \ntypable, can the algorithm produce the required type information? While this decision problem remains \ntantalizingly open, we present techniques which can be used to prove significant lower bounds on the \ncomplexity of type infer\u00adence for the Girard/R,eynolds system, also called F2, as well as higher-order \nextensions F3, F4, ., , , FU proposed by Girard. In particular, we show that recognizing the F2-typable \nterms requires exponential time, and for Fw the problem is nonelementary. We show as well a se\u00adquence \nof lower bounds on recognizing the Pk-typable terms. k integer, where the bound for Fk+l is exponen\u00adtially \nlarger than that for f k. These results are the first nontrivial lower bounds on type inference for the \nGirard/Reynolds system as well as its higher-order extensions. We hope that the analY\u00adsis provides important \ncombinatorial insights which will prove useful in the ultimate resolution of the complexity of the type \ninference problem. The problem of type inference is one of both theo\u00adretical and practical interest. \nFollowing the insights of Landin [Lan66], Strachey [Str73], Penrosel, and others, the untyped ~-calculus \nhas long been recognized as not merely Turing-complete, but a syntactically natural foundation for the \ndesign of programming languages. The process of /?-reduction is a simulation of compu\u00adtation and function \ncall, while normal forms simulate final returned answers. Types augment programming languages with addi\u00adtional \nguarantees about resultant computational behav\u00adior. For instance, static typing as in Pascal requires \nexplicit typing by the programmer, but allows all type checking to occur at compile time, with the guarantee \nthat no compiled program will go wrong at run time due to type mismatches. The price paid for this guaran\u00adtee \nis a loss of parametric polymorphism ( code reuse ), so that programs designed for abstract data types \nmust be recoded for each type on which they are used. As an example, the computation of the identity \nfunction 1(z) = z is certainly data-independent, yet its real\u00adization in Pascal demands identical code \nwith different type declarations for the identity function on integers, booleans, arrays of length 10 \nof characters, etc. all this redundancy merely to please the compiler. A powerful extension to this methodology \nwas pro\u00adposed by Robin Milner, namely a theory of type poly\u00admorphism for achieving code reuse, while \nretaining the benefits of strong typing. He gave an algorithm which, presented with an untyped program, \ncould construct the most general type information (known as the princi\u00adpa/ type [Hin69, DM82]) for the \nprogram [Mi178]. These insights are implemented in the ML programming lan\u00adguage [HMT90] as well as a \nvariety of other functional languages [HW88, Tur85]. The principal type of an ML program provides an \nimportant functional specifi\u00adcation of the program, describing how it can be used by other programs; \nas such, types are useful as specifi\u00adcations, and to facilitate incremental compilation. The ML module \nsystem is an elegant realization of these basic intuitions. The ML language is not merely an example \nof suc\u00adcessful software engineering. It is also an important departure point and testbed in our theoretical \nexam\u00adination of type inference: studying type inference for ML has provided important insights. The Core \nML language comprising typed ~-calculus with polymor\u00adphism (as embodied in let) enjoys the strong normaL \nization property: typable programs are guaranteed to 1In his 1977 Turing Award lecture, Dana Scott mentions \nthat it was physicist Roger Penrose who pointed Strachey in the direction of the A-calculus as a useful \ndevice for de\u00adscribing programming language semantics [SC077]. terminate2. Reconstructing the type of \nan (untyped) ML expression is thus in essence the synthesis of a ter\u00admination proof. Of special interest \nhere is the fact that typable ML expressions are, modulo synt attic sugar, a nontrivial subset of the \nA-terms typable in F2, F3,. . . . Fw. Fur\u00adthermore, all of these type systems enjoy strong normal\u00adization. \nSince kterms typable in Fk are also t ypable in Fk+l, we may regard the higher-order type systems as \nmore and more powerful expression languages in which to encode termination proofs. It is natural to expect \nthat greater expressiveness may facilitate the extrac\u00adtion of stronger lower bounds; proving lower bounds \non type inference for FW should at least be easier than for F2. We note, however, that FU is not ~ust \nan esoteric variation on F2, since it has been proposed as the math\u00adematical foundation for a new generation \nof typed func\u00adtional programming languages, in particular Cardelli s language Quest [Car89] and the LEAP \nproject at CMU [PL89]. The lower bounds presented here are all generic re\u00adductions, where an arbitrary \nTM M with input x of length n is simulated by a A-term VM,Z, such that M accepts z in time ~(n) iff VM,. \nis typable. In con\u00adstructing strong lower bounds, the challenge is to en\u00adcode as rapidly increasing an \n~(n) as possible, while constraining the transducer reducing M and x to QM, Z to run in logarithmic space. \nBy the time hierarchy the\u00adorem [HS65, HU79], these complexity-class relativized hardness bounds translate \n(via diagonalization argu\u00adments) to nonrelativized bounds. For instance, the DTIME[2 ]-hardness bound \nfor typability in F2 implies a Q(cn) lower bound for some constant c > 1. The structure of WM,G is basically \na consequence of the fol\u00adlowing proposition [KMM90]: Proposition 1.1 Given a strongly normalizing A-term \nE, the problem of determining whether the normal form of E is first-order typab(e is DTIME[f (n)] -hard, \nfor any total recursive function f(n). Proof. (Sketch) Given a TM M halting in f(n) steps on input z \nof length n, construct a )i-term 6 encoding the transition function of M, so that if y codes a machine \nID, (6 y) /?-reduces to a A-term en\u00adcoding the ID after a state transition. Let ~ be the Church-numeral \nencoding of f, E be the Church nu\u00admeral for n, and IDO be the encoding of the initial ID. Consider the \ntyping of the normal form of E \u00ad~ R 6 IDO D ~(n) 6 IDO D df( ) IDo. The normal form of As a consequence, \nML is in practice augmented with a set of typed fixpoint operators, 13 codes a machine ID after ~(n) \ntransitions; construct E to force a mistyping in the case of nonacceptance. w The fundamental contribution \nof this paper is to de\u00adtail what is absent from this proof sketch, strengthening the statement of the \nproposition to concern the typabil\u00adity of E (instead of its normal form) in the various sys\u00adtems Fk, \nwhile weakening the proposition by restricting the possible asymptotic growth of ~(n).3 The remainder \nof the paper gives these details, mixed with some short tutorials on the type systems under study, where \nwe have forgone the formality of infer\u00adence rules in preference for intuition. In Section 2, we briefly \noutline F2, the second order polymorphic typed A-calculus, and in Section 3 we present an exposition \nof the DTIME[2n~]-hardness bound for typability in F2. In Section 4, we provide a description of the \nsystems F3, F4, ..., Fu generalizing Fz, with emphasis on the significance of kinds in these systems. \nIn Section 5 we outline the nonelementary lower bound on typability for FW, and show the connections \nbetween this bound and related lower bounds for the Fk. our tutorial ma\u00adterial follows the presentation \nof [PDM89], which we enthusiastically recommend to anyone desiring a read\u00adable introduction to programming \nin higher-order typed A-calculi. 2 The second order polymor\u00adphic typed A-calculus (Fz) F2 is best introduced \nby canonical example: the identity function. In Fz, we write the typed polymorphic iden\u00adtity function4 \nas Id ~ Aa: *. Ax:cY.x. The Ax.x should be familiar; the Aa: * denotes abstraction over types5. For instance, \ngiven a type Int encoding integers, we can represent the identity function for integers as: Id [Int] \nE (As: *. Ax:a.x) [Int] B-~x:lnt.x The b indicates @reduction at the type level, where Int is substituted \nfor free occurrences of cr. Given a type Bool encoding Boolean values, we may similarly write Id [Bool] \nto get the identity function for booleans. In short, Id is a polymorphic function which may be parametrized \nwith a given type to derive an identity function for that type. We write the type of Id as 3Observe that \nthese type systems preserve typings under /3-reduction. 4 For clarity, we show expression variables in \nboldface and type variables in itaiic when both occur in the same expression. 5For the moment, we consider \nthe x to be syntactic sugar, though in generalizations of FZ this will not be so. ld G Aa: *.CY+ a, where \nA (sometimes written as V) represents universal quantification over types. Church numerals may be typed \nin a similar fashion: ~ E As:*.M:cx + (1 .~X:~.X i = Aa: *.Af:a + a. Ax:a.fx 2 G ACY: *.Af:a + a.~x:a.f(fx) \n... The type of all Church numerals is IntzAa: *.(a + a)+ a+ a. In the untyped Lcalculus, we realize \nthe exponent nm by reducing the expression (Aj.k.~~x) (A~.k.~nZ) to normal form. This reduction can be \ntyped in F2: A&#38;*.(Ri [/3+ /8])(fi ~]) E Afl: *. ((AcK *.Af:a + a.~x:a.fmx) [~ + ~]) ((As: *.&#38;a \n+ ody:a.gny) [B]) D A@*. (Af:(p + @ + p + /3. Ax:/3 + J3.fmx) (Ag:p + /3. Ay:p.gny) D A/3: *.~X:~ + /?. \n(Ag:/3 + /3. Ay:o.gny)~x D AB: *.~X:~ + ~. (Ag:p + p. Ay:p.gny)~- (Ay :p.xny) b A~: *.~X:~ + ~. (Ag:/? \n+ /3. Ay:/?.gny)~- (Jy :/3,xn2y) ... D A/3: *.~X:~ + ~. ~y:~.Xnmy. Observe that the normal form is also \nof type lnt.6 Church numerals are merely polymorphic functions which compose other functions having the \nsame domain and range, while exponentiation is just a higher-order mechanism for constructing such function \ncomposers. What happens when we want to compose a function having a different domain and range? We will \nshow that the answer to this question is crucial to the devel\u00adopment of lower bounds. 6Here, we allow \na-renaming of A-bound variables at the type level. 3 An exponential lower bound Example 3.1 on F2 type \ninference 3.1 Paradise lost: lessons learned from ML It has been know for some time that type inference \nfor the simply-typed (first-order) ~-calculus can be solved in polynomial time. A simple and elegant \nexposition of this fact can be found in [Wan87], where a syntax\u00ad directed algorithm is given that transforms \nan untyped A-term into a linear sized set of type equations of the form X =YandX =Y+ Z,suchthat thesolu\u00ad \ntion of the equations (via unification [Rob65, PW78]) determines the principal type of the term, In progressing \nfrom this language to ML, it is neces\u00adsary to understand the effect of quantification over type variables \non the complexity of type inference. Natu\u00adrally, this insight is also crucial in the case of F2. The \nprogress in understanding ML quantification and type inference is primarily due to two straightforward \nobser\u00advations. The first, given in [Mit90]7, is that the fol\u00adlowing inference rule for let preserves \nexactly the type judgments for closed terms usually derived using the quantification rules: Because TO \nand ~1 are first-order types, this alternate inference rule is a classic instance of quantifier elimina\u00adtion. \nIn the spirit of the Curry-Howard propositions\u00adas-types analogy, it also acts as a sort of cut elimina\u00adtion, \npreserving propositional theorems at the expense of greatly enlarging the size of the proofs. The added \ncombinatorial insight comes from that fact that type inference can be completely reduced to first-order \nuni\u00adfication. The second observation, due to Paris Kanellakis and John Mitchell, is that let can be used \nto com\u00adpose functions an exponential number of times with a polynomial-length formula [KM89]: 71n this \nsurvey, the rule is attributed to Albert Meyer. However, it appears as well in the thesis of Luis Damas \n[Dam85], and in fact a question about it cau be found in the 1985 postgraduate examination in computing \nat Edinburgh University [Edi88]. The above expression let-reduces to Ay. j 2 y, where the occurence oft \nis polymorphic. The significance of this polymorphism is exploited in the lower bound of [Mai90, KM M90], \nwhere it is shown that recognizing typable ML expressions can be solved in DTIME[2n], and is DTIME[2 \n~]-hard for every inte\u00adger k >1 under logspace reductions The lower bound is a generic reduction: it \nproceeds by using types to encode TM IDs, and constructing a A-term simulating the transition function \nat the type level. The type of (Q Illo), where lDO is a ~-term whose type encodes the initial ID of the \nTM, and the transition function is sub\u00adstituted for ~, then encodes the state of the machine after 2nk \nstate transitions. A mistyping is forced in the case of a final rejecting state, The circuitry of the \nTM is effected through taking the simulation of Boolean logic by first-order unification found in [DKM84], \nand real\u00adizing the Boolean gadgets found there by the types of l-terms. In its nascent state, the ML \nlower bound is useless to bound the complexity of F2 type inference. The proof of machine accepts iff \nML formula types is made by a straightforward appeal to the simple logic of first-order unification, \nwhere in the case of a rejecting computa\u00adtion, it is obvious how to force a mistyping. To fur\u00adther claim \nthat there is no F2 typing is far from clear, since F2 types do not admit naive quantifier elimina\u00adtion, \nhence first-order arguments are too weak. Prov\u00ading that strongly normalizing terms are not Fz-typable \nis very difficult: as evidence, we point merely to the tremendous effort of Giannini and Ronchi dells \nRocca [GR88] in their identifying a single, simple, strongly normalizing term which is not F2-typable. \n 3.2 Paradise regained: an F2 lower bound The force of the ML argument can be regained, how\u00adever, by \nchanging the simulation of Boolean logic from that found in [DKM84] to the classic simulation in the \n~-calculus. For example, we type the Boolean values An alternate proof is found in [KTU90]. as: We remark \nthat this encoding is not Girard s inductive\u00adtype definition of Boolean values; observe simply that true \nand false have different types, while in Girard s construction, the Boolean values are both terms of \ntype Acr:*. cr* m + a. By using the ~classic logic, the ML proof can be simplified, with the added bonus \nthat the simulation of TM computation is carried out (as before) on the type level, but mirrored exactly \nat the value level. For in\u00adstance, the ML typings of the classical simulations of conjunction and disjunction \nproduce the correct terms as outputs, and also the correct Boolean types as de\u00adscribed above. Values \nof expressions are immaterial to the ML type checker, which computes only their types; the proof of [Mai90] \ngoes to great lengths to exploit this point. Restoring the duality between values and types is one of \nthe key ideas in the F2 bound. A Boolean value A is computed (via @reduction) which answers the question \nDid the TM accept its input? ; this term is used in the expression ~ R (.kr.zz)(A (k.z) (~y.yy)) Observe \nthat if A D fake, then W b (Ax.zx)(Ay.yy). By the simple appeal to Girard s strong normalization theorem \nfor F2 [Gir72, GLT89], we then know that if the TM rejects its input, Q is not typable. What re\u00admains \nis to show that if the TM accepts, then W can be typed. We must in this case look more carefully at the \nstructure of the term A. 3.3 Encoding Turing Machines by lambda terms Given a deterministic TM M, we \nshow how to encode the transition function of M as a A-term 6 such that if ID is a A-term encoding a \nconfiguration of M, and ID is the next configuration of M coded as a J-term, then IS ID Dp H? . We call \nthis a simulation at the value level. The encoding also yields a very compact and simple proof of the \nDTIME[2 k]-hardness bound ior recognizing ML-typable terms. Let M have finite states Q = {ql, . . . . \ngk} with ini\u00ad tial state ql and final states F C Q; tape alphabet C = {cl, . . . . cl} with blank symbol \n)5 = c1; tape head movements D = {dl, d2, d3} (left, no movement, right); and transition map d: Q x C \n-Q x C x D. A config\u00aduration (ID) of M is a triple (q, L, R) E QxC xC giving the state and contents \nof the left and right hand sides of the tape; we thus define the transition function of AI by the usual \nextension of 13. We assume that the TM never writes a blank, that it does not move its tape head iff \nit reads a blank, and that it never runs off the left end of the tape. We represent the finite sets Q, \nC, D, and Bool = {true, fake} by projection functions. Given a finite set @={e~, ..., e$ }, we code e! \nby the ~-term d; z Aiv1.Ax2. . . .Axk.xi. A k-iuple E = (eI, ..., ek) is coded by the J-term ~z.~el \n. . .e~; note ~d~ Dp ei. A /ist [xl, . . . . xk] denotes the tuple (*1, (82, . . . . (Xk,nil) . . .)), \nwhere nil E A2..Z. A function m: Ek + F with finite domain can then be coded as the tuple 77i= (m(el), \n. . ..rn(ek)). so that Hid: bp m(ei). When the finite domain of a function is the product of several \nfinite sets (as in 8), we realize the function in its curried form. The coding of the )-term 6 is simplified \nby using a notation for pattern matching on tuples. If tis a k-tuple, we write (xl, .... z~) = t; e for \nt(kcl. ..Axk. e). For example, fst can be defined as At.(xl, X2) = t; X1. We allow nesting of patterns, \ne.g., ((xl, zz), y, (a, zz)) = e; e means (z, y, z) = e; (X1,*2) = 2; (~1,~2) = z; e . We represent a \nTM ID by a tuple (q, L, R), where L-[ll, . . ., /m] and R E [rl, . . . . rn] are lists coding the left \nand right contents of the tape; we assume the tape head is reading rl, and /1 is the cell contents to \nthe immediate left, Given all these technicalities, the transition function of M has a very simple encoding: \n6 s MD. (g, (/, L), (r, R)) = ID; (q , c , d ) = d gr; d (q , L, (~, (c , R))) (q , (~, L), (c , (}, \nW)} (q , (c , (~, L)), ~) Note that (q , c , d ) codes the state, symbol written, and head direction \nfor the next machine configuration, as computed by 8; d is then used as a projection func\u00adtion to choose \nthe ~-term coding the next configuration. Because no value is used more than once, no side\u00adeffecting \nof type variables occurs, and the equivalent of the fanout gates of [Mai90, KMM90] is not necessary. \n 3.4 Encoding Turing Machines by types The simple encoding 6 of the transition function is ty\u00ad pable \nin ML; moreover, it has the following property: Lemma 3.2 Let ID and ID be A-terms coding succes\u00adsive \nconfigurations of M, and let u and u be their re\u00ad spective first-order principal types. Then C$ID bp \nID , and 61D E u . Furthermore, if ~Dk a s a ~-term with principal type ok coding the state of M after \nk transi\u00adtions from ID, then (Id) ID bp ~Dk, and (16) ID E Ok. The Lemma states that the computation \nof Al is sim\u00adulated not only at the vatue level~but also at the type level. Observe that the typing of \nk 6 is rank 2. Corollary 3.3 Let E ~ (Jf.~(~. . .(~f) . . .)) 6 IDO, where there are m occurances of \n~, and Ill. codes an initial ID of M. Then E has the same norms! form and rank 1? type as (~ti) IDO. \nProof. (sketch) Let T~ be the rank 2 principal type of ~~i_~ype the m occurrences of Z, from left to \nright, as 2m 2m 2 ~ ~2 -1 r -+7-,T T2 --+ T ,T1 + T . 1 .,., w Theorem 3.4 Recognizing the lambda terms \ntypable in F2 is DTIME[2n ]-hard for any integer k ~ 1 under logspace reduction. Proof. Assume that F \n= {qP+l, . . . . q~} C Q are the accepting states of A4. Consider A s (q, L,R) D (Af.Z(Z. . .(~f) . . \n.)) 6 IDO; q false . false true . . . true where ~ occurs n~ times, the first p arguments of q are false \nand the remaining k p arguments are true. If M accepts input z after exactly 2n steps, then A /3\u00adreduces \nto true. By Lemma 3.2 and Corollary 3.3, the A-expression A has principal type ACY: *.A~: *.cr + ~ -+ \na, so that WM, &#38; ~ (~Z.ZZ)(A (1.c.z) (J,y.vv)) i. typable in rank 3. If M rejects z, then A ~-reduces \nto Ax. Ay.y, and consequently TM,Z reduces to (Ax. xx)(Jy, yy), By Girard s strong normalization theorem \n[Gir72, GLT89], VM,C is not F2-typable. It is easily seen that ~~,z can be const rutted in logarithmic \nspace from M and z. m The A-expression E we use for simulating M on x has a rank 2 typing in F2 whenever \nit has an F2-typing. Since rank 2 Girard/Reynolds typability is equivalent to ML typability [KT89], which \nis DEXPTIME-complete, this result is the best we can achieve without resort\u00ading to higher-rank typings. \nNote that a slight varia\u00adtion of the representation WM,Z gives a compact and simple proof of DEXPTIME-hardness \nfor recognizing ML-typable terms. Corollary 3.5 (Fixed type inference) Let r be an ar\u00adbitrary but fixed \nF2 type. Then the problem of recogniz\u00ading the lambda terms which can be given the F2 type r is also DTIME[2n~]-hard \nfor any integer k > 1 under logspace reduction.  4 An overview of F3, F4, . . . . F. The F2 lower bound \ngiven above has two parts: (1) a simulation of the transition function of an arbitrary TM by a closed \nA-term; and (2) a method for compos\u00ading the transition function an exponential number of times. The analogous \nML bound stops at exponential because of ML s limited ability to (polymorphically) compose arbitrary \nfunctions. No such limit is appar\u00adent in F2 or its higher-order extensions, so a natural place to strengthen \nthe F2 bound is to improve the function composition realized in (2) and thus turn the crank (of the transition \nfunction) faster. Note that the crank of Example 3.1 is (without syntactic sugar) merely the A-term which \nhas the same power as the term E in Corollary 3.3. Might there be more powerful typable reduction sequences \nin the systems Fk? We show this program can be carried out in FU to derive a nonelementary lower bound. \nRelated super\u00adexponential bounds can be proven for the F~ so that re~ognizing typable A-terms of length \nn requires ~~ (n) time, where fk(n) is an exponential stack of 2s grow\u00ading linearly with k, and n on \ntop of the stack. Before describing these lower bounds in more detail, we pro\u00advide a brief overview of \nthe type systems F3, F4, ., ., FW. 4.1 Kinds and abstraction over func\u00adtions on types  In the first-order \ntyped A-calculus, the type language is made up of type variables, and a binary function + mapping a pair \nof types to a type. In F2, we add uni\u00adversal quantification, but only over type variables. The higher-order \nsystems F3, F4, . . . . FW are designed to al\u00adlow abstraction and quantification as well over functions \non types, with varying degrees of freedom. Let * denote the kind of types that may be gener\u00adated in F2: \nwe could describe the functionality of (a curried) + as --+ c x a x ~ x, where + is a higher\u00adorder version \nof + describing functions from types to types. If we now introduce A-abstraction at the type level, imitating \nits existence at the expression level, we can describe other functions on types, for example: This expressiveness \nadds considerable power to the type language. Its practical need is apparent in trying to give a meaning \nto List when parametrizing the identity function as ki [List Int] we want List to be a higher\u00adorder type \n(i.e., one of kind * + *) which maps a type (Int) to a type (List-lnt). A logical example of the need \nfor higher-order types is found in the intuitionistic pro\u00adgram for the disjunction of propositions (types) \np and q: PV qE Ar: *.(p -r) e (q~ r) -+ r. (We consider p V q to be of kind * it is also a proposition.) \nBy ab\u00adstracting over p and q, in a higher-order system we may write: V ~ ~p:*. ~q:*. Ar:*. (p + r) + \n(q + r) + r. To use such definitions, a-renaming and ~-reduction are introduced at the type level. The \ntype systems Fk differ in the degree to which they allow higher-order type abstraction. In F2, no such \n~-abstraction is allowed, and all types have kind *. In F3, A-abstraction is allowed only over types \nof kind *, and in Fk+l abstraction is allowed only over types of kinds found in Fk. In Fu, there are \nno such restric\u00adtions. We can describe the kinds ~k allowed in Fk by a grammar: K2 ::= * Kt+l ::= El \nI K!* KL+I Kw ::= * [KW+K.  5 Type inference for Fw is nonelementary To derive a nonelementary bound, \nwe show how to type the A-term C 6 IDO, where c E (Af.Az.f2z)(Agn .Ayn.g;zJn) (~gn-l.~yn-l.g: -,yn-l) \no ( J90.AYO.9;YO), and S and IDO code the tramition funct,ion and initial ID of a TM, as in Section \n3. The method we describe for typing C makes very broad assumptions about the reductions caused by 6, \nand thus provides a general technique for composing functions. Observe that C 6 ~DCI b (~yl .~y0.f(n+2)yo) \n6 ~Do b 6@(n+2)ID0, where the function @ is defined as 0(0) = 1, @(t + 1) = 2@(~). The technical challenge \nis to type C so that yl gets the type of 6, and y. the type of IDO. The term C codes repeated exponentiation \nas in Example 3.1, except that the function 6 being composed does not have the same domain and range. \nTo understand how to compose functions with different domains and ranges, we have to examine the type \nof 6 more closely; we abstract its structure as: 6 c AV1:*.AV2:*. . . .AvT:*. Z(vl, vz, . . ..vr )+?Z(v,, \nv2,..., vr). Proposition 5.1 ~(vl, V2, . . . . v,) is a substitution in\u00ad stance oj%?(wl, v.q, . . .Izvr). \n Proof. They both encode TM IDs, and so are unifi\u00ad able. The (circuitry of the unification logic exists \non the ~ side, which induces structure on the (~ side. - We now represent the type of 6 by using higher\u00adorder \ntype constructors. Divide the type variables V={vl,. ... W} into disjoint sets VI = {VI, . . . . Vp} \nand V. = {VP+l, . . ., Vp+g=r } ~ w here the output vari\u00adables V. appear in ~(vl, V2, . . . . w.), and \nthe intermedi\u00adate variables VI form the complement. We can then de\u00adfine an ID-constructor makeID as a \nfunction on types: make-ID E AX1:*, AX2: *. . . .Axq: *. R(zl, x2, . . ..zq) E *9+1, where we use the \nabbreviation xl s x, Xa+l ~ * + *Q, and 7? is ~ restricted to the output variables. Lemma 5.2 There exist \ntype functions 17i E * +1, 1< i < q, such that the type of 6 can be represented as: 6 E AVI:*.AV2: * \n. . .. AVT. *. (make-ID (r, Vlv, ~.. v.) (r2v1v2... vr) ... (rqV1V2...Vr)) + make-ID VP+l VP+Z . . . \nVP+q. Proof. By first-order unification and Proposition 5.1. We remark that the functions 17i encode \nwhat we have called (TM circuitry. m How is 6 composed polymorphicatiy, namely the equivalent of ML \ns let 62 = MD.6(6 ID)? In ML, the type of ?i2 is realized by first-order unification; we sim\u00adulate this \nusing the functions I i. 1 ?s Proposition 5.3 The A-term 62 can be giwen the Fw \u00adtype Observe that the \noutput variables WP+l, . . . . VP+* in the type of 6 have been instantiated so that vP+i = r~ vi . v;. \nThe primed variables form a second floor of circuitry, while make-ID puts a roof on the type struc\u00adtures \ngenerated by the variables and the ri. Repeated composition yields a giant directed acyclic graph, where \nthe depth of the dag (i.e., the number of floors) is lin\u00adearly proportional to the degree of composition. \n 5.1 Higher-order type data structures We now show how A-abstraction and application at the type ievel \ncan be used to manufacture huge dags repre\u00adsenting the t-fold composition of 6. The existence of A at \nthe type level allows the construction of such ab\u00adstract data structures. The basic idea is the following: \nwe construct a cer\u00adtain A-term I _ at the type level which represents the type of the j-fold composition \nof 6, where the kind ~ of T does not depend on j. We then define a function map: K +-K such that map \n~ represents the type of the (.7 -i-I)-fold composition of 6. Because the domain and range (both kinds) \nof map are identical, we can at the type level engage in conventional function composi\u00adtion tricks that \nwould not work at the expression level. For instance, we can define E(K*K)+K*K and write ~map D ~7: \nK.map(map(map(map 7))). The coding of the type map is not pretty, but its use is quite elegant. The \nfundamental data structure manip\u00adulated by map is called a pair. A pair has two parts: a prototype, and \na variabie list. A prototype is a ~-term of the form AZ1:*.AZ2: *.... Axq: *. A@: *q+@+l. @ dl~zdgdl \n@ The d ~ di are just dummy type variables to pad the kind, and the ~i are types involving some set \nVi, ..., vPt of type variables, xl, . . . . x., and --+, so each ~i is of kind *. We imagine the 4i to \nbe the dag under construction, so that make-ID 41 . . q$qwould form a suitable ,C, given type variables \nfor the xi. A variable list is a A-term of the form Azl: *.AX2: *. . . ~Azq: *. A@: *q+@+l. Qflfz tqvl \n %t, where the ji are the output variables of the dag ul\u00ad timately to be constructed, and the vi are \na list of variables to be used during the construction. The Azi\u00ad bindings are padding. A pair is a A-term \nof the form ~~:K + K + K .~ PV G(K + K =+K ) + K , where P is a prototype and V is a variable list \n(both of kind K ). Because of the kind identity, fst and snd are definable on pairs, as is projection \nof types of kind * in the pair. The A-term map maps pairs to pairs, where the new pair is one composition \nstep closer to the ultimate t\u00adfold composition, as represented by the prototype. The definition of map \nis tedious and is postponed to the fi\u00adnal version of the paper; it involves straightforward list processing \non pairs, where the type variables in the vari\u00adable list are repeatedly shifted cyclically and retrieved \nas the floors are built. We also define a A-term z which takes a final pair and produces a first-order \ntype of the t-fold composition of 6. 5.2 Composing map Now comes the elegant and truly fun part: we \nuse the <crank c = (Af.Az.f2z)(J9n .~Yn.9:Yn) (Agn_,.Ayn-,.g: -~yn-l) . (J90. JYO.98YO), (at the expression \nlevel) to compose map @(n+2) times. The dag gets constructed at a speed controlled by the reduction sequence \nof C to normal form. Suppressing kinds for readability, we recursively define a set of types used to \ntype C: Go{ao} -Amap.(A~.Z(maP T) + ZT) -+ (Ar.Z(aomap ~) ~ Zr) G1{cY1} s Aao.Go{ao} -+ Go{alaO} s AaO.~O{aO} \n-+ Amap. (A~.Z(map ~) + ZT) -+ (A~.X(alaOmap T) a zr) ~~+l{a~+l} a Aa~.G~{a~}+g~{a~+la~} Lemma 5.4 For \neach O < i < n, ~gi.~yi.g~yi can be typed as ~~{~}, where ~S ~u.~r.uzr is a type having the same kind \nas ~i. Proof. For~go.Ayo.g~yo, wehave the typing Amap. Jg: A~.Z(map ~) A ZT. AT. Jy: Z(map(map r)) ~ \nZ(2mapr). g [r] (g [map ~] y) and for Jgi+l .Ayi+l .g~+lyi+l, i > 0, we have the typing Aai. ~g:~i{ai} \n= A~i_l.~i_l{~i_l} + ~i_.l{~i~i_l}. Acw_l. Ay: g&#38;l{a&#38;l}d g [C&#38;@i-1] (g [ai_l] y) Lemma 5.5 \nIn the term C , Af./kz.f2z E G.{z} + G.-I{2} -+ Gn_l{m}. Theorem 5.6 The term C (the crank ) has typing \nC S (Af .k.f 2X)(~gn.~yn.g~Yn) (~gn_l~Yn_lg~_lYn.1)[2 (Agn-2JYn.2g~_2 Yn_2)[~ (~g~_3~Yn-3g~_3Yn-3)[Z \n... (%(1 .~Y() .giYo),  We now briefly sketch how this typing for C can be used to type C 6 IDO. We \ntake the type and parame\u00ad trize it with the definition of map, and then show that 6 E (Ar.Z(map r) + \nXT). Next, parametrize this term over an initial pair r., abstracting over all the variables Vj appearing \nin the pair. By then parameterizing the Vj with (huge) first-order types pj, we simulate the uni\u00ad fication \nprocess of ML, matching IDO with a suitable parameterization z. We then have: M F (Ad:* .Avl:+. 0. .Avg+Pt: \n*. C[map]6[~o]) [WIIPII  [P,+PJ (~Do[d) The type of M codes the state of the TM after @(n+ 2) state \ntransitions; we extract the accepting state A (known by assumption to be coded true), and type the term \n(Az.zz)(A(Ac. z)(Ay.yy)) (details to be given in the full paper). We then have our nonelement ary bound: \nTIleorem 5.7 Recognizing the lambda terms of length n typable in FW is DTIME[@(n~)]-hard for any integer \nk >1 under logspace reduction, where m(o) = 1, @(t+ 1) = 2@(t). Corollary 5.8 Recognizing the lambda \nterms of length n typable in Fk is DTIME[!k_4(n)] -hard under /ogspace reduction, where ~o(n) = n, ~~+~(n) \n= 2~k(n). We remark only that the -4 reflects the kind overhead of building pairs.  6 Discussion; Open \nproblems We have provided the first lower bounds on type in\u00adference for the Girard/Reynolds system Fz \nand the extensions F3, F4, . . . . Fw. The lower bounds involve generic simulation of Turing Machines, \nwhere computa\u00adtion is simulated at the expression and type level simul\u00adtaneously. Non-accepting computations \nare mapped to non-normalizing reduction sequences, and hence non-typable terms. The accepting computations \nare mapped to t ypable terms, where higher-order types en\u00adcode the reduction sequences, and first-order \ntypes en\u00adcode the entire computation as a circuit, based on a uni\u00adfication simulation of Boolean logic. \nOur lower bounds employ combinatorial techniques which we hope will be useful in the ultimate resolution \nof the F2 type inference problem, particularly the idea of composing polymor\u00adphic functions with different \ndomains and ranges. Even if our bounds are weak (if the F2 problem is undecidable, they certainly are!), \nthe analysis puts for\u00adward a certain program; it remains to be seen how far that program can be pushed. \nWhile the higher-order systems are of genuine interest, it is F2 which occu\u00adpies center stage: in particular, \nwe would like to know if the techniques of the higher-order lower bounds can be lowered to F2, somehow \nusing the F2 ranks to simulate the expressiveness we have obtained from the kinds in F3, F4, . . . . \nFW. The computational power of the kinds includes not merely higher-order quantifica\u00adtion, but more importantly \n,f-reduction at the type level. Generic simulation is a natural setting for lower bounds, particularly \nwhen the complexity classes are superexponential, and there are no <known difficult problems on which \nto base reductions. It seems equally natural that the type information added to an (un\u00adtyped) term is \nof a length proportional to the time com\u00adplexity of the TM being simulated. Furthermore, the program \nof generic simulation generalizes nicely, as ex\u00adpressed in the slogan, how fast can the crank (of the \ntransition function) be turned? : better lower bounds can be proven by analyzing different cranks. We \nob\u00adserve in particular that the typing outlined in Section 5 was discovered by studying the reduction \nsequence of the untyped term C to normal form, and constructing the type as an encoding of that sequence. \nThis analysis suggests an examination of F2 types, particularly in the light of the strong normalization \ntheorem, as encodings of reduction sequences. We should observe as well the pitfalls of the method, or \nat least the hurdles which wait to be surmounted. The cranks described are all strongly normalizing in \na manner such that we will never get an undecidability result. As long as we pursue bounds for F2 based \non expressiveness of the type language, we are constrained by the strong normalization theorem, and the \nrepre\u00ad sentation theorem (that the representable integer func\u00ad tions are those provably total in second \norder Peano Arithmetic) [Gir72, GLT89]. We have some idea how to get around the first hurdle, but are \ndone in by the second. Does it seem possible that the representation theorem would allow reduction sequences \nof function\u00ad ally unbounded length on typable terms? We conclude with a final caveat lector. The lower \nbound we have proven for Fti is unlikely to be improved further by naively trying a better (crank, unless \nthe foundation of the simulation is changed substantially. The explanation of this limitation is that \nthe type lan\u00adguage of FW is fundamentally the first-order typed A\u00adcalculus with a single type constant \n(*). The dualit y approach forces reductions at the expression level to match those at the type level, \nand a result of Schwicten\u00adberg [Sch82] indicates that our construction is using the type language at \nits maximum capacity. Encouraged and excited as we are to have made progress on these open questions \nin programming language theory, the hard work may have only just begun. Acknowledgements. The results \nof Section 3 were reported earlier in [Hen90]. For their encouragement, suggestions and criticisms, we \nthank Paris Kanellakis, Georg Kreisel, Daniel Leivant, Angus Macintyre, Jon Riecke, and Rick Statman. \nThe second author wishes to acknowledge the generosity of the Computer Science Department at UC Santa \nBarbara, the Music Academy of the West, and the Cate School of Carpenteria, for their hospitality during \nhis visit to Santa Barbara in the summer of 1990.  References [Car89] L. Cardelli. Typeful programming. \nLec\u00adture Notes for the IFIP Advanced Seminar on Formal Methods in Programming Lan\u00adguage Semantics, RIO \nde Janeiro, Brazil, 1989. See also SRC Report 45, Digital Equipment Corporation. [Dam85] L. Damas. Type \nassignment in program\u00adming languages. Ph. D. dissertation, CST\u00ad33-85, Computer Science Department, Ed\u00adinburgh \nUniversity, 1985. [DM82] L. Damas and R. Milner. Principal type schemes for functional programs. In 9\u00adth \nACM Symposium on Principles of Programming Languages, pp. 207-212, January 1982. [DKM84] C. Dwork, P. \nKanellakis, aild J. C. Mitchell. On the sequential nature of unifi\u00adcation. Journal of Logic Programming \n1:35-50, 1984. [Edi88] Edinburgh University. Postgraduate Ex\u00adamination Questions in Computation The\u00adory, \n1978 1988. Laboratory for Founda\u00adtions of Computer Science, Report ECS\u00adLFCS-88-64. [GR88] P. Giannini \nand S. Ronchi Della Rocca. Characterization of typings in polymor\u00adphic type discipline. In Proceedings \nof the 3-rd IEEE Symposium on Logic in Computer Science, pp. 61 70, July 1988. [Gir72] [GLT89] [HMT90] \n[HS65] [Hen90] [Hin69] [HU79] [HW88] [KM89] [KMM90] [KTU90] J.-Y. Girard. Interpretation Fonc-on Trees \nin Algebra and Program\u00adtionelle et Elimination des Coupures de ming, May 1990. (See also Boston Uni\u00adl \nArithmetique d Ordre Superieur. Thkse versity Technical Report, October 1989). de Doctorat d Et at, University \nde Paris [KT89] A. J. Kfoury and J. Tiuryn. Type recon-VII, 1972. struction in jinite rank fragments \nof the J.-Y. Girard, Y. Lafont, and P. Taylor. second-order lambda calculus. Technical Proofs and Types. \nCambridge Univer-Report BUCS 89-011, Boston University, sity Press, 1989. October 1989. Also in Proceedings \nof the 5-th IEEE Symposium on Logic R. Harper, R. Milner, M. Tofte. The Def\u00ad in Computer Science, pp. \n2 11, June inition of Standard ML. MIT Press, 1990. 1990. [Lan66] P. Landin. The next 700 programming \nlan- J. Hartmanis and R. E. Stearns. On the guages. Communications of the ACM computational complexity \nof algorithms. 9(3): 157-166. Transactions of the American Math\u00adematical Society 117, pp. 285 306. [Mai90] \nH. G, Mairson. Deciding ML typability is complete for deterministic exponential F. Henglein. A lower \nbound for full poly\u00ad time. In Proceedings of the 17-th morphic type inference: Girard/ Reynolds ACM \nSymposium on the Principles typability is DEXPTIME-hard. University of Programming Languages, pp. 382 \nof Utrecht, Technical Report RUU-CS-90\u00ad 401, January 1990. 14, April 1990. [Mi178] R. Milner. A theory \nof type polymorphism R. Hindley. The principal type scheme of in programming. Journal of Computer an \nobject in combinatory logic. Transac-and System Sciences 17, pp. 348 375, tions of the American Mathematical \n1978. Society 146:29-60, 1969. [Mit90] J. C. Mitchell. Type systems for program- J. E. Hopcroft and J. \nD. Unman. Intro-ming languages. To appear as a chapter duction to Automata Theory, Lan\u00ad in the Handbook \nof Theoretical Com\u00adguages, and Computation. Addison put er Science, van Leeuwen et al., eds. Wesley, \n1979. North-Holland, 1990. P. Hudak and P. L. Wadler, editors. Re-[PW78] M. S. Paterson and M. N. Wegman. \nLinear port on the functional programming lan-unification. Journal of Computer and guage Haske//. Yale \nUniversity Technical System Sciences 16, pp. 158-167, 1978. Report YALEU/DCS/RR656, 1988. [PDM89] B. \nPierce, S. Dietzen, and S. Michaylov. P, C. Kanellakis and J. C. Mitchell. Programming in higher-order \ntyped lambda Polymorphic unification and ML typing. calculi. Technical Report CMU-CS-89- Brown University \nTechnical Report CS-111, Carnegie Mellon University, March 89-40, August 1989. Also in Proceed-1989. \nings of the 16-th ACM Symposium [PL89] F. Pfenning and P. Lee. LEAP: a lan\u00ad on the Principles of Programming \nguage with eval and polymorphism. TAP- Languages, pp. 105-115, January 1989. SOFT 1989: Proceedings of \nthe In- P. C. Kanellakis, H. G. Mairson, and J. ternational Joint Conference on The- C. Mitchell. Unification \nand ML type re-ory and Practice in Software Devel\u00adconstruction. In Computational Logic: opment, Barcelona, \nSpain. See also CMU Essays in Honor of Alan Robinson, Ergo Report 88-065. ed. J.-L. Lassez and G. Plotkin. \nMIT [Rey74] J. C. Reynolds. Towards a theory of typePress, 1990. structure. In Proceedings of the Paris \n A. J. Kfoury, J. Tiuryn, and P. Urzyczyn. Colloquium on Programming, Lecture ML typability is DEXPTIME-complete. \nNotes in Computer Science 19, Springer Proceedings of the 15-th Colloquium Verlag, pp. 408-425, 1974. \n[Rob65] J. A. Robinson, A machine oriented logic based on the resolution principle. Journal of the ACM \n12(1):23 41, 1965. [Sch82] H. Schwictenberg. ization in the lus. The L. C omp!ezit y of norms!\u00adpure typed \nlambda calcu-E. J. Brouwer Cente\u00ad nary Symposium, D. van Daalen (eds.), Holland, 1982. A. S. Troelstra \nand pp. 453-457. North\u00ad [SC077] D. Scott. Logic and guages. Communications 20(9):634-641, 1977. programming \nof the lan-ACM [Str73] C. Strachey. The varieties of programming language. Technical Monograph PRG\u00ad10, \nProgramming Research Group, Oxford University, 1973. [Tur85] D. A. Turner. Miranda: A non-strict func\u00adtional \nlanguage with polymorphic types. In IFIP International Conference on Functional Programming and Com\u00adputer \nArchitecture, Nancy, Lecture Notes in Computer Science 201, pp. 1-16, Springer-Verlag, 1985. [Wan87] \nM. Wand. A simple algorithm for type inference. Fundament maticae 10 (1987). and proof a Infor\u00ad  \n\t\t\t", "proc_id": "99583", "abstract": "", "authors": [{"name": "Fritz Henglein", "author_profile_id": "81100104232", "affiliation": "Courant Institute of Mathematical Sciences, New York University, New York, N.Y. and Computer Science Department, Utrecht University, 3508 TB Utrecht, The Netherlands", "person_id": "PP39027309", "email_address": "", "orcid_id": ""}, {"name": "Harry G. Mairson", "author_profile_id": "81100061196", "affiliation": "Computer Science Department, Brandeis University, Waltham, Massachusetts", "person_id": "P107959", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/99583.99602", "year": "1991", "article_id": "99602", "conference": "POPL", "title": "The complexity of type inference for higher-order lambda calculi", "url": "http://dl.acm.org/citation.cfm?id=99602"}