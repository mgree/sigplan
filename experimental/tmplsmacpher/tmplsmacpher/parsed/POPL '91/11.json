{"article_publication_date": "01-03-1991", "fulltext": "\n A Record Based on Symmetric Robert Harper Carnegie Mellon Abstract Type systems for operations on extensible \nrecords form a foundation for statically typed languages address\u00ading some aspects of object oriented \nprogramming and database applications. A number of primitive oper\u00ad ations have been proposed: extending \na record with a new field, overwriting an existing field, removing a field, and various kinds of concatenation, \nWe show here that a record calculus based on a symmetric concatena\u00adtion operator, where two records may \nbe concatenated only if they have no overlapping fields, also captures the types of many other useful \nprimitive record operations. Mergeability constraints are expressed directly using explicit annotations \non type variables and constrained second-order type quantification instead of a rule of sub\u00adsumpt ion; \nwe argue that the resulting system is more straightforward than subsumption-based alternatives.  Introduction \nCardelli [2, 3] observed that certain aspects of inher\u00aditance in object-oriented languages can be understood \nin terms of inclusion relations among record types in a typed A-calculus. These inclusions are defined \nformally as a subtype relation: a type t is a subtype of t , writ\u00adten t < t , if any member of t may \nsafely be used in a context where a member of t is expected. The fact that the type of an expression \nmay always be promoted to a supertype is captured by the rule of subsumption: G1-eet Gtt <t Permission \nto copy without fee all or part of this material is granted provided that the copies are not made or \ndistributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand its date appear, and notice is given that copying is by permission of the Association for Computing \nMachinery. To COPYother\u00adwise, or to republish, requires a fee and/or specific permission.  Calculus \nConcatenation Benjamin Pierce University Cardelli and Wegner [6] extended this idea to a pow\u00aderful second-order \ntype system combining Cardelli s or\u00addering on record types with type quantification [9, 22] using techniques \ndeveloped by Mitchell [16]. Wand [24, 25] analyzed the concept of record polymorphism in the context \nof ML type inference and introduced the notion of row variables, which allow types to be given to terms \ninvolving a natural record extension op\u00aderator. This work was refined by Jategaonkar and Mitchell [13, \n14] and Stansifer [23]. R4my [19] introduced the notion of positive and neg\u00adative information about record \nfields and the intuition that increasing either positive or negative information specifying that fields \nare either definitely present or definitely absent gives more refined types. This in\u00adtuition, formalized \nas an appropriate extension to the kind system, plus the restriction that the set of field la\u00adbels is \nfinite, enabled him to use ordinary unification as in ML [8] to do type inference for programs involving \nextensible records. Both Wand [27] and R4my [20, 21] later extended this system to infinite label sets. \nMore recently, Cardelli and Mitchell [4, 5] discovered an elegant calculus of primitive record operations \ncom\u00ad bining bounded quantification with positive and neg~ tive information about fields and generalizing \nCardelli s original subtype ordering on fixed-length records. In this system, the preorder on types is \nused to encode both positive and negative information. For example, record extensions like e Il=e ( e \nextended with value e at label 1 ) are only well formed when the field be\u00ad ing added is not already present; \nto prevent run time type errors, the typing rule for extension must ensure that this is the case. Cardelli \nand Mitchell express this constraint in terms of the preorder by requiring that e has some type r that \nis a subtype of a type lacking l. The restriction operator \\ is used to increase negative information; \nfor example, if r is the record type {11 :t 1}, then r\\12 is a subtype of r. In an earlier report [11], \nwe set out to represent posi\u00adtive and negative information as directly as possible, us\u00ading explicit constraints \non record type variables rather than encoding constraints in a preorder structure on types. For example, \nthis system expresses the well\u00adtypedness constraint on e ll=e as e has type r and r lacks 1, where the \njudgement form r lacks 1 is ax\u00adiomatized explicitly. The result is a somewhat simpler but more verbose \nsystem with no rule of subsumption, where genericity over record types arises solely from constrained \nquantification of type variables: a quanti\u00adfied type Va lacks L-has L+ :T+. t can be instanti\u00adated with \nany record type r such that r s set of fields is disjoint from L and includes each 1~ :ti in L+ :T+. \nThis line of development essentially amounts to reverse\u00adengineering Cardelli and Mitchell s system back \ntoward R6my s. in fact, during the early stages of their work Cardelli and Mitchell independently developed \na similar system by extending the kind system of the polymorphic A-calculus along the lines suggested \nby R4my. Other useful ways of manipulating records are pro\u00advided by the merge or concatenate operator \n11, which combines the fields of two existing records. There are several forms of the merge operator, \ndistinguished by what happens when the records el and e2 k a merge expression el j \\ez have one or more \nfields in common. The asymmetric merge operator gives preference to the values from ez. The symmetric \nmerge operator disal\u00adlows merge expressions where the fields of el and e2 are not guaranteed to be disjoint. \nThe recursive merge com\u00adputes the values of common fields by recursively merging their values in el and \ne2. Of these, the symmetric vari\u00adant seems to us to be the most useful, since it makes the finest distinct \nions. This is the version we assume in the present paper, except where explicitly indicated. A restricted \nform of merging can be defined directly. For example, {ll:tl, 12:t2} II {13:t3, 14:t4} can be rewritten \nsimply as {ll:tl, 12:t2, 13:t3, 14:t4}. But in general when the types of el and e2 may involve variables \n typechecking with II requires a substantial increase in the complexity of the type system. To en\u00adsure \nthat ~x:a. ~y:b. (xl Iy) k well typed, we need to guarantee that the type variables a and b are never \nin\u00adst ant i at ed to types with overlapping fields. This con\u00addition cannot be stated in terms of the \nprevious forms of positive and negative information ( has and lacks constraints), but must be provided \nexplicitly by anno\u00adtating type variables and quantifiers with compatibikty constraints. Once this information \nis provided for type variables, we can define what it means for two arbitrary types rl and rz to be compatible, \nwritten T1 # rz. The merge expression el I le2 is then well typed when el G rl, e2 E r2, and rl # r2. \nThe type of this expression is the merge type r~llrz. Wand [27] studied type inference for an extension \nof ML with an asymmetric merge operator and showed how to encode class definitions similar to those found \nin object-oriented programming languages in this cal\u00adculus. The asymmetric merge operation has the advan\u00adtage \nthat compatibility constraints are not necessary: any two records may be merged, with the rightmost one \noverriding. On the other hand, the use of symmet\u00adric merge allows the type checker to detect inadvertent \nclashes of labels, which can be useful in practice. Both systems have the property that the type checker \nmust keep track of which component of a merge has a given field, leading to problems in type reconstruction. \nOhori and Buneman studied type inference for object\u00adoriented programming [17] and for database program\u00adming \nlanguages [18] another promising application area for record type systems. In their work on database \nprogramming languages they consider a type system in\u00adcluding records and sets, with operations such as \nre\u00adlational join chosen to support database applications. To perform ML-like type inference for this \nlanguage, they introduce the notion of a conditional type scheme, in which a type variable may be constrained \nto range over records possessing certain components. These con\u00adstraints are similar to the has constraints \ndiscussed above. (They also used another form of constraint per\u00adtinant to the relational join and projection \noperations.) In their work on object-oriented programming, they consider a form of record update operation \nin which a value of a given field may be overridden. Once again, their notion of conditional type scheme \nplays a central role. They also consider extensions to support object\u00adoriented programming constructs \nsimilar to those sug\u00adgested by Wand. In order to support inheritance, they introduce an ad hoc form of \nsubsumption in connection with (self and an additional form of condition on con\u00additional type schemes. \nCardelli and Mitchell sketched several increasingly ambitious formulations of recursive record concatena\u00adtion \nas extensions to their calculus of operations on records [5]. The most powerful of these requires the \nno\u00adtion of constrained, multiply-bounded quantification, where a finite set of type variables is bound \nsimultane\u00adously, with each constrained to be a subtype of some given type and certain subsets constrained \nto be com\u00adpatible. For example, a function that takes two compat\u00adible records xl and X2, where xl has \nat least a field 11 of type Int and X2 has at least a field 12 of type Int, and returns the result of \nmerging xl and x2, can be written A(al ~ {11 : Int}, a2 < {12 : Int}, a1#a2), ~xl:a~. Axz:az. xl I 1x2 \n(altering their concrete syntax slightly). In the present paper, we study a record calculus All based \non a more straightforward formulation of con\u00adstrained quantification. In All, each record type variable \nin a context G has a list of compatibility assumptions R, where the elements of R are record types and \na#R as\u00adserts that a#ri for each ri c R. The constrained type abstraction operator Aa#R. e adds the assumption \na#R to the context used to typecheck e, A type application e [r] must check that r satisfies all of the \nconstraints on the quantifier. For example, the function mentioned above can be defined in Al I as follows: \n Aal#ll:Int, 12:Int. Aaz#al, ll:Int, 12:Int. ~xl:alllll:Int. ~x2:a21112:Int. xl II X2. Similarly, a \nfunction that accepts any record not al\u00adready possessing an I. field and adds the field 1=5 can be written: \nAa#l. ~x:a. x [[ 1=5 e Va#l. a + (a II l: Int). A function that accepts any record with an 1 field and \noverrides it with the field 1=5 can also be expressed: Ab. Aa#l. ~x:(alll:b). (x\\l) It 1=5 e Vb. b a#l. \n(alll:b) + (a II l:Int) (Unlike the calculi of R6my, Wand, and Cardelli and Mitchell, Al I is unable \nto express the function that takes any record and gives it an 1 field with value 5.) These examples underscore \nan important point: the form of constraint used in All can only be used to express negative information \nabout record type variables. The function above takes two type variables, each of which lacks the appropriate \nfield. To form the types expected for the records xl and x2 on the two J-abstractions, the missing fields \nare merged back into al and a2. This kind of transformation from mixed positive and negative constraints \non quantifiers to pure negative constraints can be carried out mechanically. The use of constrained type \nvariables here has a very similar flavor to Wand s treatment of merging with row variables [27]. In fact, \nwe adopt the same point of view as Wand with regard to subsumption: rather than intro\u00adduce a preorder \non types that includes record extension as a special case, we prefer to use a form of quantifica\u00adtion \nto capture the possible extensions of a record type and use type application to choose the appropriate \nex\u00adtension for a given context. However, in contrast to Wand, we are dealing with an explicitly-typed, \nsecond\u00adorder calculus with a symmetric, rather than asymmet\u00adric, merge operator, This leads to a somewhat \ndifferent overall flavor, as we shall illustrate below. Our central claim is that the straightforward \nformulw tion of constrained quantification embodied in All may be viewed as primary, in the sense that \nmost of the examples motivating row variables, bounded quantifi\u00adcation, and Cardelli and Mitchell s bounded \nquantifica\u00adtion with positive and negative information can be ex\u00adpressed in a calculus based on this \nform of constrained quantifier, with no need for additional mechanisms like subsumption. In Section 2, \nwe define the syntax and typing rules of All and briefly sketch a proof of the decidability of type\u00adchecking. \nSection 3 illustrates the expressiveness of the system by translating an object-oriented programming \nexample from Wand and showing how to encode one of the motivating examples for F-bounded quantification \nin AI I. Section 4 offers concluding remarks. A complete listing of the typing rules for All appears \nin Appendix A. The full version of the paper [10] includes more detailed proofs, several additional examples, \nand a discussion of avenues for future research. 2 Definition and Properties of All 2.1 Syntax This section \nintroduces some notational conventions and defines the concrete syntax of All. The metavariable t and \nu range over types; r, and s range over record types; p ranges over primitive types; a and b range over \nrecord type variables; R and S range over finite sequences of record types; e and f range over terms; \nx ranges over variables; 1 ranges over field labels. Types: .. t .. primitive I :I+tz function space \nI k a#R. t constrained quantification Ir record type Record types: .. r .. record type variable I ;mpty \nempty record I l:t single-field record I r\\l restriction I r~ llrz merge  The record types are those \nbuilt up from record type variables, tipt y, and single-field records by applications of merge and restriction. \nOrdinary type quantification is omitted from this presentation, but could be added by considering general \ntype variables and an associated quantifier. Terms: .. e .. variable I ;x:t. e abstraction I e~ez application \nI empty empty record I l=e single-field record I e\\l restriction I el II ez merge I e.1 selection I Aa#R. \ne constrained type abstraction I e[r] constrained type application Free and bound variables are defined \nin the usual way; in the case of type quantification and abstraction, the Tl, a#R, T2 ok TI, a#R, T2 \nF a record T F t type T F l:t record T i-r record r.1~ T E r\\l record T ok T F Empty record Tl_rl#r2 \nT 1-rl II r2 record Figure 1: Selected formation rules for record types variable a is not considered \nbound in the constraint list R. Terms and types are identified up to renaming of bound variables. The \nnotation [t/a]t denotes capture\u00adavoiding substitution oft for free occurrences of a in t ; similarly, \n[e/x] e denotes capture-avoiding substitution of e for free occurrences of x in e . The metavariable \nT ranges over type contexts finite sequences of declarations of the form a#R with no type variable declared \ntwice. The met avariable G ranges over term contexts finite sequences of declarations of the form x \n:t with no variable mentioned twice. If 1 is a label and r is a well-formed record type, then r. 1 is \ndefined to be the type associated with label 1 in r, if any. We write r. 1 T for r. 1 is undefined and \nr.1 ~ for r.1 is defined. 2.2 Typing Rules The ~ II calculus is defined by a collection of inference \nrules for deriving typing and formation judgments, compatibility judgments, and equivalence judgments. \nA representative selection of the rules of All appears in Figures 1 5; the complete set appears in Appendix \nA. For the most part the formulation of All proceeds along standard lines; we discuss here only those \naspects that are particular to handling extensible records. The formation rules for record types are \nsummarized in Figure 1. The two most interesting cases are the rules for restriction and merge. The restriction \nr\\l is well formed in T if r is well formed in T and r -1 is defined. In particular, no expression of \nthe form a\\l, where a is a variable, is ever well formed, since a -1 is never defined. This reflects \nthe fact that compatibility constraints on a variable a are negative in character and cannot be used \nto postulate that all instances of a have any particular fields, only that they lack certain fields, \nT; G1-eet T; GFl=eel:t T; G1-ecr r-1.j T; Gke\\lcr\\l Tt-Gok T ; G F empty e Empty T; G1-elerl T; Gbe2er2 \nTFr1#r2 T; G1-e.ler_l T,a#R; G1-e et T ;G k Aa#R. e E Va#R. t T; GFee Va#R. t Tkr#R T ; G F e[r] e [r/a]t \nFigure 2: Selected typing rules It also implies that if r\\l is a well-formed record ex\u00adpression, then \nthe restriction may be eliminated (see the discussion of type equivalence below). A merge rl I Irz is \nwell-formed in T if rl and rz are well-formed in T, and, morover, rl and r2 are compatible in T (see \nbelow). A selection of the typing rules for terms appears in Figure 2. The empty record is always well-formed. \nA single-field record l=e has type l:t in T if e has type t in T. The restriction e\\l has type r\\l in \nT provided that e has type r in T and r _ 1 J: we may restrict only on a field that e actually possesses. \nThe merge el I le2 has type rl I Irz in T provided that el has type rl in T and e2 has type r2 in T and \nrl and r2 are compatible in T. In other words, we may not merge two records unless they are non-overlapping; \nto achieve the effect of overriding, it is necessary to restrict on the fields to be overridden before \nforming the merge. The selection e.1 has type r-lin Tif e has type rin T andr.1~, By the definition of \nr _l, the type of e.1 is unique (up to equivalence) if it well-formed. The abstraction Aa#R. e has type \nda#R. t provided that e has type t in T, a#R, which also entails that R is a well-formed constraint set \nin T. It is important to realize that the constraint list R cannot be replaced by a single record type \nr, for two related reasons. First, it is necessary to postulate that a variable be compatible with a \nnumber of different record types. For example, Tbr#s r-r s-s Tkr #s T1-r#s Tks#r Tkr#l:t T k t type T1-r#l:tt \nT1, a#R, Tz ok r~e R T1, a#R, T2 E a#r~ T 1-r#(slllsz) Tkr#si Ttsl#sz TFr#sl T1-r#sz T 1-r# (sIIIsz) \n T F r record T F r# Empty Figure 3: Selected compatibility rules if we are to merge a variable a with \nthe base records I. :t and l :t , then a must be constrained to be compat\u00adible with both of these records, \nwhich is to say that all inst antes of a must not contain 1 or 11 fields, Second, the constraint list \nR cannot be collapsed into a single record type consisting of the merge of the component record types \nri of R because the records in R need not themselves be mutually compatible. The type application e[r] \nis well formed in T if e has type Va#R. t in T, r is a record in T, and r is com\u00adpatible with each element \nof R (relative to T). In other words, r must satisfy the constraints associated with the quantifier in \norder for the type application to be sensi\u00adble. When this is the case, the type of e[r] is [r/a]t, as \nusual. It will turn out that the formulation of the system ensures that if r satisfies the constraints \nin R relative to T, then r is a record type in T. To support general parametric polymorphism, we would \nhave to ex\u00adtend the system with a separate form of quantifier that quantifies over all types. We omit \nthis extension for the sake of simplicity. The compatibility relation (see Figure 3) plays a cen\u00adtral \nrole in Al 1. Informally, T 1-r # s holds iff r and s are mergeable, that is, iff r lacks every field \npossessed by rl@pty N r rl II (rz\\lrs) N (rlllrz) II rs rl llr2. ~rz Ilrl r\\l\\l -r\\l \\l (l:t)\\l N Empty \nrl .11 Va#R. t w Va#R . t! Figure 4: Selected type equivalence rules r, (r , R) -r , (r, R) Empty, RN \nR (r11]r2), R~rl, (rz, R) r,(r, R)N r, R l:t, R N l:t , R Figure 5: Selected constraint list equivalence \nrules s and s lacks every field possessed by r. The definition is made relative to a context T since \nthe compatibility for a type variable a is determined by the constraint set associated with a in T. It \nfollows from this informal de\u00adscription that compatibility is symmetric, respects type equivalence, and \nis insensitive to the types ascribed to fields of a record. In particular, l:t is compatible with l :t \niff 1 is different from 1 . Equivalence of types (Figure 4) is defined as an equiv\u00adalence relation compatible \nwith all type-forming con\u00adstructors, such that the merge operation is commutative and associative and \nhas EIIIpt y as unit. Field restriction operations eliminate fields in the expected way. Con\u00adstraint \nlist equivalence (Figure 5) is important due to the presence of constraint lists on quantified types. \nBe\u00adsides the equivalences induced by equivalence of types, we identify constraint lists that differ only \nin the order and multiplicity down of merge of constraints types and the and allow elimination for of \nthe break-Empty. 2.3 Properties In this section we sketch a proof of the decidability of type checking \nfor }11. Due to space limitations, we give only a brief overview of the development. A more de\u00adtailed \naccount appears in the full paper. The proof proceeds largely along standard lines: type checking is \nreduced to checking equivalence and com\u00adpatibility of types by way of a syntax-directed set of type synthesis \nrules. Equivalence of well-formed types is established using Huet s method of confluence mod-U1O an equivalence \nrelation [12]. The main idea is to handle the associative and commutative rules for merge types and the \npermutation and idempotency equations for constraints lists by segregating the proper reduc\u00adtions from \nthe pure equations, so that the equiva\u00adlence problem is reduced to checking a simple form of equivalence \nof normal forms. Compatiblit y checking is based on a simple characterization of normal forms of record \ntypes and constraint lists, with the main com\u00adplications stemming from the need to take account of all \nof the consequences of assuming that a variable is compatible with a complex record type. Emptyllr + \nr r 11Empty + r l:t\\l + Empty (rll s)\\l + (r\\l) II s ifr-1~ (r II s)\\l + rll (s\\l) if s-1~ PI!o>R + P)u, \nR Empty, R + R l:t, R + l,R Figure 6: Proper reduction rules 2.3.1 Type and Constraint List Equivalence \nAs a technical convenience in the presentation of the type checking algorithm, we extend constraint lists \nto admit bare labels. The metavariable @ is used to range over type variables and bare labels; the metavari\u00adables \np and u are used to range over types and bare labels. We extend the relation T t\u00adr # R to constraint \nlists by defining T E r # 1, R to mean T 1\u00adr # R and T F r # l:t for any well-formed type t. Let + denote \nthe least reflexive, transitive relation containing the relation given in Figure 6 (compatibly extended \nto all type constructors); let w denote the least congruence containing the relation given in Figure \n7. r\\l\\l w rlls%sllr rll(sllt)w(rlls)llt r\\l \\l Theorem terms is 2.3.1,1: confluent The modulo restriction \nw. of+ to well-typed ~,~,R w ~,R Corollary 2.3.1.2: 1. If r and s are well-formed records, there exist \nr and s in normal form r and s ++ s and rt z S1. then such r ~ that s iff r + Figure P,o, 7: R w Pure \na,p, R equivalences 2. If t and u are well-formed there exist t and u such and t G u . types, then t \nthat t + t and s u u iff + u 136 3. If R and S are well-formed constraint lists, then R x S iff there \nexist R and S such that R + R and S+ S and R % st. Corollary 2.3.1.3: The relation N is decidable for \nwell-formed expressions. If r is a well-formed record, let r* denote one of its normal forms computed \nby applying the + rules in some canonical order; similarly for types and constraint lists. Theorem 2.3.1.4: \n1. Let r be a well-formed record type. Then r* has the form al lla2 II ... lla~ [Ill:tl [1... Illk:tk \nup to associativit y and commutativity of I], where the ai s are distinct variables, the lj s are distinct \nlabels, the tj s are in normal form, and n and k are greater than or equal to O (when both are O, the \nnormal form is Empty), 2. Let R be a well-formed constraint list. Then R* has the form al, ..., an, \n11, .,. ,l~ where the ai s are all distinct, the lj s are all dis\u00adtinct, and n and k are greater than \nor equal to O. (That is, R* is a list of variables and labels in some order.) Note that as a consequence, \na well-formed nor\u00ad mal form is restriction-free, This implies that every well-formed record expression \nreduces to a well-formed restriction-free record expression. 2.3.2 Compatibility Checking The compatibility \nchecking algorithm is presented aa a collection of inference rules for deriving judgments of the form \nT F r #= s where r and s are restriction-free, well-formed record types. The rules appear in Figure 8. \nTo prove that these rules define an algorithm for com\u00adpatibility checking, we show that they are sound \nand complete with respect to the declarative formulation, and that we may effectively decide whether \nor not a derivation exists in accordance with these rules. The soundness and completeness of the algorithm \nare stated by the following theorem: T \\ r #-Empty T k Empty #= r Tksl #*r Tbs2 #-r T l--(sl II S2) #= \nr T1-r#-sl T1-r#=s2 T h r#= (sl IIs2) acS* Tl, a#R, T2,b#S, T3 F a #* b acS* Tl, a#R, T2,b#S, T3 h b \n#= a lGR* T1,a#R, Tz F a#= l:t lcR* Tl,a#R, T2k l:t #> a Figure 8: Algorithmic compatibility rules Theorem \n2.3.2.1: 1.IfT1-rrecord andT1-r record andThr#= r , then T !--r # r . Conversely, if T t-r # s, then \nT 1-r* #+ s*. 2.1f T h rrecordand T 1-Rokand T H r#=R, then T k r # R. Conversely, if T 1-r # R,then \nT h r* #*R*, The decidability of the algorithmic formulation fol\u00adlows from the fact that it is almost \nsyntax-directed : although some rules overlap, either choice leads to the same conclusion.  2.3.3 Type \nSynthesis The type checking algorithm for Jll is given in terms of a type synthesis procedure that constructs \na canoni\u00ad cal type for a given expression in a given context. This procedure is described by a formal \nsystem for deriving judgments of the form T ; G 1-e + t, together with a number of auxiliary judgments \nof a similar form. As with the compatibility checker, we show that this for\u00admal system defines a type \nchecking algorithm by proving that it is sound and complete with respect to the defi\u00adnition of Al I and \nthat we may effectively decide whether 137 Tl, a#R, T2 b a a record T 1-rl ~ record T F rz &#38; record \nTkr1#*r2 T F rl llr2 a record T; Ghe111e2=+r1\\lr2 T; Gke~Va#R. t T 1-r a record TFr #=R T ; G h e[r] \na [r/a]t Figure 9: Selected type synthesis rules or not a derivation exists, A representative set of \nrules from the definition of the type synthesis algorithm is given in Figure 9. The soundness and completeness \nof the algorithm are stated by the following theorem: Theorem 2.3.3.1: (Soundness) If 1-T ok and T t-r \na record, then T h r record. If; Tok andTEt ~ type, then TFttype. If t-Tok and TER~ok, then T l-Rok. \nIf Tt-G ok and T; GEe+-t, then T; GEee t. (Completeness) If T 1-r record, then T f r ~ record. If T F \nt type, then T t-t ~ type. If TFRok, then T!--R~ok. If Tt-eet, then The* ttforsomet{suchthat t -t. For \ndecidability, we have only to note that the rele\u00advant inst antes of compatibility and conversion checking \nare decidable, and that the rules are syntax-directed.  Examples One motivation for studying record \ncalculi is the poten\u00adtial application to typed object-oriented programming, as suggested by Cardelli \n[2] and Wand [27] and further developed by a number of authors [1, 7, 17]. In par\u00adticular, Wand has demonstrated \nthat a simple form of object-oriented programming may be expressed in a lan\u00adguage with record concatenation \nand recursive types, and the members of the ABEL group at HP Labs have intro duced an extension oft he \nnot ion of bounded quan\u00adtification, known as F-bounded quantification, in order to capture certain object-oriented \nidioms. We consider here two examples, one taken from Wand, the other from Canning, et al. (Further examples \nare presented in the full version [10].) We need to work in an extension of Al 1, called Al 1~, that \nincludes full polymorphism (quantification over all types, not just record types), a fixed point operator \nat all functional types, and recursive types. Of these, only recursive types present any difficulties. \nRecursive types are written K a. t(a), where t(a) is an arbitrary type ex\u00adpression possibly involving \nthe variable a. Type equiv\u00adalence for Al 1~ is defined by considering a recursive type pa. t(a) as denoting \nthe (possibly infinite) regular tree obtained by unrolling the recursion and applying the equivalences \non type expressions given in Appendix A, Although this description of type equivalence is suffi\u00adcient \nfor the examples to follow, it should be empha\u00adsized that we have not studied the decidability of type \nequivalence; the decidabilit y of type checking for AI IM remains open. Here is a simple example from \nWand [26], illustrat\u00ad ing the use of record extension Define the class A to be to model inherit ante. \nJx:int. Aa#sum, n. Aself :(allsnm:int sum=(x + self Iln:int). .n) with type int * Va#sum, n. (allsum:int \nI [n:int) A (sum: int). Here x is a parameter of the ation: when A is instantiated, becomes a hidden \ncomponent class the of instantiation value supplied the new object. oper\u00adfor x The row variable a is \na placeholder for any fields that maybe added by subclasses of A. The parameter self provides a name \nwithin the new instance of A for the instance itself, which is supplied at instantiation time using the \nfixed point operator. As it stands, the class A cannot actually be instanti\u00adated since it lacks a method \nfor n. Define the class B to be a subclass of A with a method for n: Ay:int. Aa#sum, n. Aself :(allsum:int \nIln:int). A(5)[a](self) II n=y with type int -+ Va#sum, n. (a[lsum:int I In:int) a (sum:int Iln:int). \n We may now instantiate B by writing, for example, B(3) [Empty] e sum:int I In:int ~ smn:int \\ In:int, \nso that (fix(B(3)[Empty] )).sum = 8. We may also define a class C that extends A with a method for n \nand a method for m Ay:int. Aa#sum, n, m Aself :(allsum:intlln:int Ilm:int). A(5)[al Im:int](self ) II \nn=y II m=10. The instantiation expression f ix(C(3) [Empt y] ) results in an object with sum and n fields \nagreeing with B and with an additional m field whose value is 10. Our second example illustrates the \nflexibility of con\u00adstrained quantification by showing that the motivating examples of F-bounded quantification \nmay readily be expressed in the pure Al 1~ calculus. Members of the ABEL group have argued persua\u00adsively \nthat bounded quantification does not provide the same degree of flexibility in the presence of recur\u00adsive \ntypes as it does for non-recursive types [1, 7]. They consider two classes of situations in which problems \narise, one when the recursion variable occurs negatively, the other when it occurs positively. To deal \nwith these problems, they propose an extended notion, called F\u00adbounded quantification, where the pure \nbounded quan\u00adtifier of the form Va < r. t is generalized to the form Va < F(a). t, where F is a function \nfrom types to types. For example, in the class of situations where the re\u00adcursion variable appears in \nnegative positions, Canning et al. show that the pure type system of Cardelli and Wegner [6] does not \nallow functions to be applied to a variety of values for which they make semantic sense. Consider the \ntype PartialOrder = ppo. {leq : po+Bool} and assume we are given a function for comput\u00ading the minimum \nof two values of any subclass of PartialOrder: min e Va < PartialOrder. a+-a+a. One of the types that \nwe would like to be able to pass to min is Number = p num. {leq : num~Bool, other: t}. But by the usual \nrule for subtyping on recursive types, it is not the case that Number < Parti.alOrder. F-bounded quantification \ncan be used to redefine min so that it can be applied to elements of Number as well as PartialOrder. \nDefine a type function FPartialOrder(t) = {leq : t~Bool} and check that Number < FPart ialOrder(Number). \nNow write min = Aa < FPartialOrder(a). Ax:a. Jy:a. if x.leq(y) then x else y e da < FPartialOrder(a). \na+a+a. The same intention to express nin so that it can be applied generically to members of any claes \npossessing at least an leq operation mapping another member of the same class to a truth value can be \nrealized directly in A1lU. We write: min G Va#leq. pb. (a II leq:b~Bool) a pb. (a I I leq:b~Bool) ~ pb. \n(a I I leq:b~Bool) Number = p num. (leq:num-Bool II other:t) five c Number. To type the application \nmin five five we need to restrict away the leq field from Number: min [Number\\leql fi,ve five. The \ntype application is well formed because Number\\leq lacks an leq field, To apply this term to five, we \nneed to know that Number w p b. (Number\\leq) II leq:b+Bool. Unrolling the definition of Number and applying \nthe rule for elimination of restriction operations, this reduces to showing Number w p b. (other: [Number/num]t) \nII leq:b+Bool.  But these type expressions have the same infinite un\u00adrolling and hence are equal under \nour interpretation of recursive types. This argument may be made precise by considering a definition \nof type equivalence similar to the definition of bisimulation equivalence in CCS [15]. To establish the \nabove equivalence, it suffices to show that it is consistent to assume that it holds, where the consistency \nconstraints ensure, for example, that two records are equal only if they have the same fields and corresponding \nfields are equal. 4 Conclusions The decision to annotate quantifiers with purely positive information, \nwith purely negative information, or with a mixture of positive and negative information is an im\u00adportant \npoint of variation among calculi of record oper\u00adations. Ordinary bounded quantification [6], F-bounded \nquantification [1], and the systems of Ohori and Bune\u00adman [17, 18] are positive-information systems. \nCardelli and Mit chell s calculus [4, 5] and our earlier symmetric system [11] are mixed posit ive and \nnegative. Wand 2S system of row variables [27] and Al I are pure negative\u00adi_nformation systems. The differences \namong these classes of systems are particularly clear in the presence of recursive types. In positive-information \nsystems, something like F-bounded quantification seems to be required. In the negative set\u00adting we do \nnot need an analogue of F-bounded quantifi\u00ad cation, since we can explicitly quantify over the rest of \nthe fields in a record type. This leads to the observation that, in mixed systems like Cardelli and Mitchell \ns, the A.5 Well-formed types negative-information fragment can be used to directly T ok express the examples \nmotivating F-bounded quantifica- T 1-p type tion. Indeed, the construction given in Section 3 can be \nT 1-tltype T t-tz type carried out almost verbatim in Cardelli and Mitchell s T 1-tl+tz type calculus. \nT,a#R P t type T F Va#R. t type  5 Acknowledgements T 1-r record We are grateful for productive discussions \nwith Val T 1-r type Breazu-Tannen, Peter Buneman, Luca Cardelli, Carl Gunter, Frank Pfenning, Didier \nR6my, and John A.6 Well-formed record types Reynolds. T1, a#R, Tz ok Tl, a#R, Tz E a recordThis research \nwas sponsored in part by the Office of Naval Research and in part by the Defense Advanced T b t type \nResearch Projects Agency (DARPA), monitored by the T 1-l:t record Office of Naval Research under Contract \nNOOO14-84-K- T E r record r.1~ 0415, ARPA Order No. 5404. T E r\\l record T ok  A Complete Typing Rules \nT E Empty record Tt-r1#r2 A.1 Judgement Forms T b rl II rz record Well-formed type context: T ok Well-formed \nterm context: T1-Gok  A.7 Constraint list satisfaction Well-formed type: T k t type Well-formed record \ntype: T F r record T t-r record Well-formed constraint list: TERok T1-r#o Constraint list satisfaction: \nT1--r#R TEr#ri Tkr#R Compatible types: TErl#rz Ti-r#r~, R Equivalent types: tl ~ tz Ecluivalent constraint \nsets: RI -Rz Well-formed term: T; GFeet A.8 Compatibility T1-r#s r-r s~s  A.2 Well-formed type contexts \nTErl #s O ok Tkr#s Tks#r TERok TEr#l:t T 1-t type T, a#R ok T1-r#l:t T1, a#R, T2 ok r~~R  A.3 Well-formed \nconstraint lists T ok Tt-ook T t-r# (s11]s2) I l-r #s: T E r record TFRok T t-r,Rok TFsl#sz Tkr#sl \nT1-r#sz T 1-r# (SIIISZ)  A.4 Well-formed term contexts 1 #1 T 1-l:t record T 1-l :t record T1-ook T \nE l:t# l :t T ok Tt-Gok T b t type T 1-r record T 1-G,x:t ok T k r # Empty A.9 Constraint list equivalence \nRNR R-R R .w R RNR R z R RNR ~ -R-R r~r r,R wr~,R r, (r , R) N r , (r, R) Empty, RN R (rlllr~),R~r~,(rZ,R) \nr, (r, R)w r, R l:t, R -l:t , R  A.10 Type equivalence rllEmpty w r rl II (rzllrs) ~ (rlllrz) 11rs rl \n1{rz ~ rz 11rl r\\l\\l N r\\l \\l (l:t)\\l * Empty rl .11 (rlllrz)\\l ~ (r~\\lllr~~ A. 11 Type equivalence (congruence) \nt~t t -t l:t-l:t 141 r-r r\\l N rl\\l rl Nrj rz-r~ rl [lr2 ~r~ Ilri  A.12 Well-typed terms T; G1-eet \nT E t type t-t T; Gke~t T 1-Gl, x:t, Gz ok T;Gl,x:t, G2~ X 6 t T; G,x:t Feet T;G 1-~x:t. e E t+t T; Gi-el \nE t+t T;Gbez~t T; G1-ele2 et T; G~eet T; G1-l=eel:t T; G1-eer r.l J, T; G1-e\\ler\\l T1-Gok T ; G k empty \ne Empty T; G1-elerl T;G1-ezerz T1-rl#rQ T;G 1-elllez G rlllrz T; GEeer r-l J. T; G1--e.ler.l T,a#R; GF \ne E t T ; G 1-Aa#R.e e Va#R. t T; G1-e~Va#R. t TEr#R T;G E e[r] E [r/a]t  References [1] Peter Canning, \nWilliam Cook, Walter Hill, Walter Olthoff, and John Mitchell. F-bounded quantifica\u00adtion for object-oriented \nprogramming. In Fourth Inter\u00adnational Conference on Functional Programming Lan\u00adguages and Computer Architecture, \npages 273-280, September 1989. [2] Luca Cardelli. A semantics of multiple inheritance. In G. Kakn, D. \nMacQueen, and G. Plotkin, editors, Se\u00admantics of Data Types, volume 173 of Lecture Notes in Computer \nScience, pages 51 67. Springer-Verlag, 1984. [3] Luca Cardelli, A semantics of multiple inheritance. \nin\u00adformation and Computation, 76:138-164, 1988. [4] Luca Cardelli and John Mitchell. Operations on records \n(summary). In M. Main, A. Melton, M. Mislove, and D. Schmidt, editors, Proceedings of Fifth International \nConference on Mathematical Foundations of Programm\u00ading Language Semantics, volume 442 of Lecture Notes \nin COmputer Science, pages 22 52, Tulane University, New Orleans, March 1989. Springer Verlag. To appear \nin Mathematical Structures in Computer Science. [5] Luca Cardelli md John C. Mitchell. Operations on \nrecords. Research Report 48, Digit al Equipment Cor\u00adporation, Systems Research Center, August 1989. [6] \nLuca Cardelli and Peter Wegner. On understanding types, data abstraction, and polymorphism. Computing \nSurveys, 17(4), December 1985. [7] William R. Cook, Walter L. HiU, and Peter S. Can\u00adning. Inheritance \nis not subtyping. In Seventeenth An\u00adnual ACM Symposium on Principles of Programming Languages, pages \n125 135, San Francisco, CA, January 1990. [8] Luis Damas and Robin Milner. Principal type schemes for \nfunctional programs. In Proceedings of the 9th A CM Symposium on Principles of Programming Languages, \npages 207 212, 1982. [9] Jean-Yves Girard. Interpretation fonctioneiie et elimination des coupures de \nl arithm6tique d ordre .wpe% ieur. PhD thesis, Universitr5 Paris VII, 1972. [10] Robert Harper and Benjamin \nPierce. A record calculus based on symmetric concatenation. Technical Report CMU-CS-90-157, Carnegie \nMellon University, August 1990. [Ii] Robert W. Harper and Benjamin C. Pierce. Exten\u00adsible records without \nsubsumption. TechnicaJ Report CMU-CS-9O-1O2, School of Computer Science, Carnegie Melon University, Feburary \n1990. [12] G6rard Huet. Confluent reductions: Abstract prop\u00aderties and applications to term rewriting \nsystems. Journal of the Association for Computing Machinery, 27(4):797-821, October 1980. [13] Lalita \nA. Jategaonkar. ML with extended pattern matching and subtypes. Master s thesis, MIT, August 1989. [14] \nLalita A. Jategaonkar and John C. Mitchell. ML with extended pattern matching and subtypes (preliminary \nversion). In Proceedings of the ACM Conference on Lisp and Functional Programming, pages 198-211, Snow\u00adbird, \nUtah, July 1988. [15] Robin Milner. A CaJculus of Communicating Sy~tems. Springer-Verlag, LNCS 92, 1980. \n[16] John C. Mitchell. Coercion and type inference (sum\u00admary). In Proc. Ilth ACM Symp. on Principles \nof Pro. gramming Languages, pages 175 185, January 1984, [17] Atsushi Ohori and Peter Buneman. Static \ntype infer\u00ad ence for parametric classes. In OOPSLA 89: Object-Oriented Programming Systems, Languages, \nand Appli\u00adcation ns, Conference Proceedings, pages 445 456, Otto\u00adber 1989. [18] Atsushi Ohori and Peter \nBuneman. Type inference in a database programming language. In 1988A CM Confer\u00adence on Lisp and Functional \nProgramming, pages 174 183, Snowbird, Utah, July 1989. Revised manuscript, September, 1988. [19] Didier \nR6my. Typechecking records and variants in a natural extension of ML. In Proceedings of the Sixteenth \nAnnual ACM Symposium on Principles of Program\u00adming Languages, Austin, pages 242 249. ACM, January 1989. \n[20] Didier R6my. Aig&#38;bres Touffues. Application au Typage Polymorphe des Objets Enregistrements \nclans les Lan\u00adgages Fonctionnek. PhD thesis, Universit6 Paris VII, 1990. [21] Didier R6my. Typechecking \nrecords in a natural exten\u00adsion of ML. Submitted to TOPLAS, June 1990. [22] John Reynolds. Towards a \ntheory oft ype structure, In Proc. co~loque sur la Programmation, pages 408-425, New York, 1974. Springer-Verlag \nLNCS 19. [23] Ryan Stansifer. Type inference with subtypes. In Pro\u00adceedings of the Fifteenth ACM Symposium \non Principles of Programming Languages, pages 88 97, San Diego, CA, January 1988. [24] Mitchell Wand. \nComplete type inference for simple ob\u00ad jects. In Proceedings of the IEEE Symposium on Logic in Computer \nScience, Ithaca, NY, June 1987. [25] Mitchell Wand. Corrigendum: Complete type inference for simple \nobjects. In Proceedings of the IEEE Sympo\u00adsium on Logic in Computer Science, 1988. [26] Mitchell Wand. \nType inference for objects with instance variables and inherit ante. Technical Report NU-CCS\u00ad89-2, College \nof Computer Science, Northeastern Uni\u00adversity, November 1988. [27] Mitchell Wand. Type inference for \nrecord concatena\u00adtion and multiple inheritance. In Fourth Annual IEEE symposium on Logic in Computer \nScience, pages 92-97, Pacific Grove, CA, June 1989. \n\t\t\t", "proc_id": "99583", "abstract": "", "authors": [{"name": "Robert Harper", "author_profile_id": "81100140064", "affiliation": "Carnegie Mellon University", "person_id": "PP39029370", "email_address": "", "orcid_id": ""}, {"name": "Benjamin Pierce", "author_profile_id": "81100303310", "affiliation": "Carnegie Mellon University", "person_id": "P28925", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/99583.99603", "year": "1991", "article_id": "99603", "conference": "POPL", "title": "A record calculus based on symmetric concatenation", "url": "http://dl.acm.org/citation.cfm?id=99603"}