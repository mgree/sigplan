{"article_publication_date": "01-03-1991", "fulltext": "\n Macros That Work William Clinger Jonathan Rees Department of Computer Science Artificial Intelligence \nLaboratory University of Oregon Massachusetts Institute of Technology Abstract This paper describes \na modified form of Kohlbecker s algo\u00adrithm for reliably hygienic (capture-free) macro expansion in block-structured \nlanguages, where macros are source-to\u00adsource transformations specified using a high-level pattern language. \nUnlike previous algorithms, the modified algo\u00adrithm runs in linear instead of quadratic time, copies \nfew constants, does not assume that syntactic keywords (e.g. if) are reserved words, and allows 10CSJ(scoped) \nmacros to refer to lexical variables in a referentially transparent manner. Syntactic closures have been \nadvanced as an alternative to hygienic macro expansion. The problem with syntactic closures is that they \nare inherently low-level and therefore difficult to use correctly, especially when syntactic keywords \nare not reserved. It is impossible to construct a pattern\u00adbased, automatically hygienic macro system \non top of syn\u00adtactic closures because the pattern interpreter must be able to determine the syntactic \nrole of an identifier (in order to close it in the correct syntactic environment) before macro expansion \nhas made that role apparent. Kohlbecker s algorithm maybe viewed as a book-keeping technique for deferring \nsuch decisions until macro expansion is locally complete. Building on that insight, this paper uni\u00adfies \nand extends the competing paradigms of hygienic macro expansion and syntactic closures to obtain an algorithm \nthat combines the benefits of both. Several prototypes of a complete macro system for Scheme have been \nbased on the algorithm presented here. 1 Introduction A macro is a source-to-source program transformation \nspec\u00adified by programmers using a high-level pattern language. Macros add a useful degree of synt attic \nextensibility to a programming language, and provide a convenient way to abbreviate common programming \nidioms. Macros are a prominent component of several popular programming languages, including C [7] and \nCommon Lisp [II]. The macro systems provided by these languages suf\u00adfer from various problems that make \nit difficult and in many cases impossible to write macros that work correctly regard\u00adless of the context \nin which the macros are used. It is widely Permission to copy without fee all or part of this material \nis granted provided that the copies are not made or distributed for direct commercial advantage, the \nACM copyright notice and the title of the publication and its date appear, and notice is given that copying \nis by permission of the Association for Computing Machioery. To copy other\u00adwise, or to republish, requires \na fee and/or specific permission. 01990 ACM 089791-419-8/90/0012/0155 $1.50 believed that these problems \nresult from the very nature of macro processing, so that macros are an inherently unreli\u00adable feature \nof programming languages [2]. That is not so. A macro system based upon the algo\u00adrithm described in this \npaper allows reliable macros to be writ ten, and is simple to use. The algorithm is nearly as fast as \nalgorithms in current use. This introduction illustrates several problems common to existing macro systems, \nusing examples written in C and Scheme [10]. With one exception, all of these problems are solved automatically \nand reliably by the algorithm presented in this paper. The original preprocessor for C allowed the body \nof a macro definition to be an arbitrary sequence of characters. It was therefore possible for a macro \nto expand into part of a token. For example, #define foo salad printf (foo bar ) ; would expand into \nprintf ( salad bar ) ;. We may say that this macro processor failed to respect the integrity of lexical \ntokens. This behavior caused so many problems that it has been banished from ANSI C except when special \nop\u00aderators are used for the specific purpose of violating the integrity of lexical tokens. Similar problems \narise in macro systems that allow the body of a macro to expand into an arbitrary sequence of tokens. \nFor example, #clef ine discriminant (a ,b, c) b*b-4*a*c 2*discrinihmnt (x-y ,x+y, x-y) *5 expands into \n2*x+y*x+y-4*x-y*x-y*5, which is then parsed as (2*x) +(y*x)+y-(4*x)-(y*x)-(y*5) instead of the more plausible \n2* (x+y)*(x+y)-4* (x-y) *(x-y )*5 . We may say that systems such as the ANSI C preprocessor fad to respect \nthe structure of expressions. Experienced programmers know they must defend against this problem by placing \nparentheses around the macro body and around all uses of macro parameters, as in #clef ine discriminant \n(a ,b, c) ( (b)*(b) -4* (a)*(c)) This convention is not enforced by the C language, however, so the author \nof a macro who neglects this precaution is likely to create subtle bugs in programs that use the macro. \nAnother problem with the discriminsnt macro occurs when the actual parameter for b is an expression that \nhas a side effect, as in discriminant (3,x--,2). Of the problems listed in this introduction, the inappropriate \nduplication of side effects is the only one that is not solved automatically by our algorithm. One can \nargue that actual parameter expressions should not have side effects, but this argument runs counter \nto the C culture. In a fully block-structured language such as Scheme, the author of a macro can defend \nagainst actual parameters with side effects by introducing a local variable that is initialized to the \nvalue obtained by referencing the macro parameter. In the syntax we adopt for this paper, which differs \nslightly from syntax that has been proposed for Scheme [3], a correct version of the discriminant macro \ncan be defined by (define-syntax discriminsnt (syntax-rules ((discrirninant ?a ?b ?c) => (let ((temp \n?b)) (-(*ternpternp) (* 4 ?a?c)))))) Unfortunately there is no equivalent to this macro in C, since \nblocks are not permitted as expressions. From the above example we see that macros must be able to introduce \nlocal variables. Local variables, however, make macros vulnerable to accidental conflicts of names, as \nin #define swap(v,w) {i-nt temp=(v); \\ (v) = (w); (w) = temp;l int temp = thermometer; if (temp < lo_temp) \nswap(temp, lo_temp); Here the if statement neuer exchanges the values of temp and lo-temp, because of \nan accidental name clash. The macro writer s usual defense is to use an obscure name and hope that it \nwill not be used by a client of the macro: #define swap(v,w) {int __temp_obscure_name=(v); \\ (v) = (w); \n(w) = --temp.obscure.name;} Even if the macro writer is careful to choose an obscure name, this defense \nis less than reliable. For example, the macro may be used within some other use of a macro whose author \nhappened to choose the same obscure name. This problem can beespecially perplexing to authors of recursive \nmacros. The most troublesome name clashes arise not from vari\u00ad ables local to a macro, but from the very \ncommon case of a macro that needs to refer to a global variable or procedure: #define complain(msg) print.error(msg); \nif (printer_brokeno) { char *print_error = The printer is brolren ; complain(print_error) ; } Here the \nname given to the error message conflicts with the name of the procedure that prints the message. In \nthis ex\u00ad ample the compiler will report a type error, but program\u00ad mers are not always so lucky. In most \nmacro systems there is no good way to work around this problem. Programs would become less readable if \nobscure names were chosen for global variables and pro\u00adcedures, and the author of a macro probably does \nnot have the right to choose those names anyway. Requiring theclient of each macro to be aware of the \nnames that occur free in the macro would defeat the purpose of macros as syntactic abstractions. Theexamples \nabove show that at least twoclasses of in\u00adadvertent name conflicts can recreated by microprocessors that \nfail to respect the con-elation between bindings ond uses of names. One class involves macros that introduce \nbound (local) variables. Another class involves macros that contain free references to variables or procedures. \nHygienic macro expansion [8]isa technology that main\u00adtains the correlation between bindings and uses \nof names, while respecting the structure of tokens and expressions. The main problem with hygienic macro \nexpansion has been that the algorithms have required O(n2 )time, wheren isthe time required by naive \nmacro expansion asin C or Common Lisp. Although this is the worst case, it sometimes occurs in practice. \nThe purpose of this paper is to build on Kohlbecker s algorithm for hygienic macro expansion by incorporating \nideas developed within the framework of syntactic closures [I]. Our result is inefficient and more complete \nsolution to the problems of macro processing. Our algorithm runs in O(n) time and solves several additional \nproblems associ\u00adated with local (scoped) macros that had not been addressed by hygienic macro expansion. \nIn particular, our algorithm supports referentially transparent local macros as described below. If macros \ncan be declared within the scope of lexical vari\u00ad ables, awin Common Lisp, then aseemingly new set of \nprob\u00ad lems arises. We would like for free variables that occur on the right hand side of a rewriting \nrule for a macro to be resolved in the lexical environment of the macro definition instead of being resolved \nin the lexical environment of the use of the macro, Using let-syntaxto declare local macros, for example, \nit would be nice if (let-syntax ((first (syntax-rules {(first ?x) => (car ?x)))) (second (syntax-rules \n((second ?x) => (car (cdr ?x)))))) (let ((car duesenberg )) (let-syntax ((classic (syntax-rules ((classic) \n=> car)))) (let ((car yugo )) (let-syntax ((affordable (syntax-rules ((affordable) > car)))) (let ((cars \n(list (classic) (affordable)))) (list (second cars) (first cars)))))))) could be made to evaluate to \n( yugo duesenberg]i). This would be the case if the references to car that are introduced by the first, \nsecond, classic, and affordable macros re\u00adferred in each case to the car variable within whose scope \nthe macro was defined. In other words, this example would evaluate to ( yugo Duesenberg )i flocalmacros \nwere ref\u00aderentially transparent. Our algorithm supports referentially transparent local macros. We should \nnote that these macros may not be refer\u00adentirdly transparent in the traditional sense because of side \neffects and other problems caused by the programming lan\u00adguage whose syntax they extend, but we blame \nthe language for this and say that the macros themselves are referentially transparent. Now consider \nthe following Scheme code: (clef ine-syntax push (syntax-rules ((push ?V ?x) => (set! ?X (corm ?V ?x))))) \n (let ((pros (list cheap fast )) (cons (list))) (push unreliable cons)) It is easy to see that the \ncons procedure referred to within the macro body is different from the cons variable within whose scope \nthe macro is used. Through its reliance on the meaning of the syntactic keyword set !, the push macro \nalso illustrates yet a third class of inadvertent name conflicts. If synt attic keywords are not reserved, \nthen the push macro might be used within the scope of a local variable or macro named set!. We can now \nidentify four classes of capturing problems. The first class involves inadvertent capturing by bound \nvari\u00adables introduced by a macro. The second class involves the inadvertent capture of free variable \nreferences introduced by a macro. The third is like the first, but involves inadver\u00adtent capturing by \nbindings of syntactic keywords (i.e. local macros) introduced by a macro. The fourth is like the sec\u00adond, \nbut involves the inadvertent capture of references to syntactic keywords introduced by a macro. Syntactic \nclosures [1] have been advanced as an alterna\u00adtive to hygienic macro expansion. Syntactic closures can \nbe used to eliminate all four classes of capturing problems, and can support referentially transparent \nlocal macros as well. Whythen havewe bothered to develop anew algorithm for hygienic macro expansion, \nwhen synt attic closures also run in linear time and solve all the problems that are solved by our algorithm? \nThe problem with syntactic closures is that they do not permit macros to be defined using the kind of \nhigh-level pat\u00ad tern language that is used in C and isproposed for Scheme [6]. The difficulty is that \na pattern interpreter that uses syn\u00ad tactic closures must be able to determine the syntactic role of \nan identifier (to know whether to close over it, and if so to know the correct syntactic environment) \nbefore macro ex\u00ad ~ansion has made that role armarent. Consider asirndified ~orm of the let macro, whic~ \nintroduces lclcal variab~es: (define-syntax let (syntax-rules ((let ((?name ?val)) ?body) => ((lambda \n(?name) ?body) ?val)))) When this macro is used, the ?val expression must be closed in the syntactic \nenvironment of the use, but the ?body can\u00adnot simply be closedin the syntactic environment of the use \nbecause its references to ?name must be left free. The pat\u00adtern interpreter cannot make this distinction \nunaided until the lambda expression is expanded, and even then it must somehow remember that the bound \nvariable of the lambda expression came from the original source code and must therefore be permitted \nto capture the references that oc\u00adcur in ?body. Recall from the swap example that a reliable env = identifier \n+ denotation denotation = special+ macro + identifier special = {lambda, le%yntaz} macro = (pattern x \nrewrite)+ X env ident c env lookup E envxidentifier -+ denotation bind c env x identifier xdenotation-env \ndivert ~ env xenv-env loolcup(iderzt, x) = x iookup(bind(e, z,v), x) = v Iookup(bind(e, z,v), y) = tookup(e, \ny) ifz#y divert (evident) = e diver-t(e, bind(e , z,u)) = bind(divert(e, e ), z,v) Figure I: Syntactic \nenvironments. macro system must not permit bound variables introduced by macro expansion to capture such \nreferences. Kohlbecker s algorithm can be viewed as a book-keeping technique for deferring all such decisions \nabout the syntactic roles of identifiers until macro expansion is locally complete andhasmade those roles \nevident. Our algorithm is therefore based on Kohlbecker s but incorporates the idea of syntactic environments, \ntaken from the work on syntactic closures, in order to achieve referentially transparent local macros. \nThe question arises: Don t thecapturing problems occur simply because we use names instead of pointers, \nand trees instead of dags? If we first parsed completely before do\u00ading macro expansion, could we not \nreplace all occurrences of names by pointers to symbol table entries and thereby eliminate the capturing \nproblems? The answer is no. One of the most important uses of macros is to provide syntactically convenient \nbinding ab\u00adstractions. Thedistinction between binding occurrences and other uses of identifiers should \nbe determined by a particu\u00ad lar syntactic abstraction, not predetermined by the parser. Therefore, even \nif we were to parse actual parameters into expression trees before macro expansion, the macro proces\u00adsor \nstill could not reliably distinguish bindings from uses and correlate them until macro expansion is performed. \nConsider an analogy from lambda calculus. In reducing an expression to normal form by textual substitution, \nit is sometimes necessary to rename variables as part of a beta reduction. It doesn t work to perform \nall the (naive) beta re\u00ad ductions first, without renaming, and then to perform all the necessary alpha \nconversions; by then it is too late. Nor does it work to do all the alpha conversions first, because \nbeta re\u00adductions introduce new opportunities for name clashes. The renamings must be interleaved with \nthe (naive) beta reduc\u00adtions, which is the reason why the notion of substitution required by the non-naive \nbeta rule is so complicated. The same situation holds for macro expansions. It does not work to simply \nexpand all macro calls and then rename variables, nor can the renamings be performed before ex\u00adpansion. \nThe two processes must be interleaved in an ap\u00adlookup (e, x) E identifier [variable references] e E x \n+ lookup (e, x) lookup (e, ko) = lambda bind (e, x, x ) 1-E ~ E (where x is a fresh identifier) ~rocedure \nabstractions] et-(ko (x) E) -(lambda (x ) E ) ~rocedure calls] eh (Eo EI) + (E{ Ej) lookup (e, ko ) = \nlet-syntax bind (e,k,(r, e))+E~ E [macro abstractions] et-(ko ((k T)) E) ~E lookup (e, k) = (r, e ) transcribe \n((k . ..). ~,e, e ) = (E, e ) e. E~E~E [macro calls] et-(k .,.)-+E Figure 2: The modified Kohlbecker \nalgorithm. match (E, ir, eU~~,edef ) = norrmtch transcribe (E, r , e~.e, ed.f ) = (E , e } transcribe \n(E, ((m, p), r ), ev,e, ed.f ) = (E , e ) match (E, r, euse, edef) = a rewrite (p, a, edef ) = (E , enew) \ntranscribe (E, ((T, p), r ), euse, e~ef) = (E , diuert(e~se, eme~)) transcribe (E, ( ), evse, e~.f) \nis an error. Figure 3: Definition of transcribe (E, r, e~se, e~,~). propriate manner. A correct and efficient \nrealization of this The reason that previous algorithms for hygienic macro interleaving is our primary \ncontribution. expansion are quadratic in time is that they expand each use of a macro by performing a \nnaive expansion followed by an extra scan of the expanded code to find and paint (i.e. 2 The algorithm \nrename, or time-stamp) the newly introduced identifiers. If macros expand into uses of still other macros \nwith more or Our algorithm avoids inadvertent captures by guaranteeing less the same actual parameters, \nwhich often happens, then the following hygiene condition: large fragments of code may be scanned anew \neach time 1. It is impossible to write a high-level macro that inserts a macro is expanded. Naive macro \nexpansion would scan a binding that can capture references other than those each fragment of code only \nonce, when the fragment is itself inserted by the macro. expanded. Our algorithm runs in linear time \nbecause it finds the 2. It is impossible to write a high-level macro that inserts newly introduced identifiers \nby scanning the rewrite rules, a reference that can be captured by bindings other and paints these identifiers \nas they are introduced during than those inserted by the macro. macro expansion. The algorithm therefore \nscans the ex\u00ad  panded code but once, for the purpose of completing the These two properties can be taken \nas the defining prop\u00ad recursive expansion of the code tree, just as in the naive erties of hygienic macro \nexpansion. The hygiene condition macro expansion algorithm. The newly introduced identi\u00adis quite strong, \nand it is sometimes necessary to write non\u00ad fiers can in fact be determined by scanning the rewrite rules \nhygienic macros; for example, the while construct in C im\u00ad at macro definition time, but this does not \naffect the asymp\u00adplicitly binds break, so if while were implemented as a totic complexity of the algorithm. \nmacro then it would have to be allowed to capture refer- The more fundamental difference between our \nalgorithm ences to break that it did not insert. We here ignore the oc\u00ad and previous algorithms lies \nin the book-keeping needed to casional need to escape from hygiene; we have implemented support referentially \ntransparent local macros. The syn\u00ada compatible low-level macro system in which non-hygienic tactic environments \nmanipulated by this book-keeping are macros can be written. shown in Figure 1. These are essentially \nthe same as the en\u00advironments used by syntactic closures, but the book-keepiug performed by our algorithm \nallows it to defer decisions that involve the syntactic roles of identifiers, The overall structure of \nthe algorithm is shown formally in Figure 2 for the lambda calculus subset of Scheme, ex\u00adtended by macro \ncalls and a restricted form of let-syntax. ,(eFE+El,> The notation indicates that E is the completely \nmacro-expanded expression that results from ex\u00adpanding E in the syntactic environment e. For this simple \nlanguage the initial syntactic environment ein~t is bind(bind(ident, lambda, lambda), let-syntax, let-syntax). \nThe variables bound by a procedure abstraction are re\u00adnamed to avoid shadowing outer variables. Identifiers \nthat denote variable references must therefore be renamed as well. Procedure calls are straightforward \n(but would be less so if expressions were allowed to expand into syntactic keywords; we have implemented \nthis both ways). The rule for macro abstractions is also straightforward: the body is macro-expanded \nin a syntactic environment in which the syntactic keyword bound by the abstraction denotes the macro \nobtained from the transformation function ~ (a set of rewrite rules) by closing r in the syntactic environment \nof the macro definition. The rule for macro calls is subtle. The macro call is tran\u00adscribed using the \ntransformation function r obtained from the macro ~eing called, the syntactic environment of the call, \nand the syntactic environment in which the macro was defined. This transcription yields not only a new \nexpression E but a new syntactic environment e in which to complete the macro expansion. The key fact \nabout algorithms for hygienic macro expansion is that any identifiers introduced by the macro are renamed, \nso the macro can only intro\u00adduce fresh identifiers. The new syntactic environment binds these fresh identifiers \nto the denotations of the correspond\u00ading original identifiers in the syntactic environment of the macro \ndefinition. These will be the ultimate denotations of the fresh identifiers unless subsequent macro expansion \nex\u00adposes an intervening procedure abstraction that binds them. Since the identifiers were fresh, any \nsuch binding must have been introduced by the same macro call that introduced the references. Hence the \nhygiene condition will be satisfied. Figure 3 defines the transcribe function in terms of match and rewrite. \nThe transcribe function simply loops through each rewrite rule ~ => p until it finds one whose pattern \nx matches the macro call. It then rewrites the macro call according to p and adds new bindings for any \nidentifiers introduced by the rewrite to the syntactic environment of the use. Actually, rather than \nmatching the entire macro call to the pattern, it is sufficient to match only the tail (or actual parameters \n) of the call against the tail ( formal parame\u00adters ) of the pattern. This complication is not reflected \nin Figure 3. The match function (Figure 4) delivers a substitution m mapping pattern variables to components \nof the input ex\u00ad pression. It is quite conventional except for one important wrinkle: Matching an identifier \nz in the macro use against a literal identifier y in the pattern succeeds if and only if lookup (e~,~, \nZ) = lookup (e~ef, y). This implies that identi\u00ad fiers in patterns are lexically scoped: bindbngs that \nintervene between the definition and use of a macro may cause match failure, match (E, ?v, ea,e, edef) \n= {?v w E} Zookup(edef, x ) = lookup (eu,e, x) match (x,x , etis., edef) = {} match(Eljrl,evSe,e~ef) \n= ai, i = lj...,~ u~ #nomatch, i=l, . . ..n rnatch((E1 . .. E~). (TI ...~n),euse,e~e~) =aI U.. .Ua~ match \n(E, m, e~se, e&#38;f) = nornatch, if the other rules are not applicable Figure 4: Definition of match \n(E, T, eu,e, edef). WXJde (p, U, = W)! 15def)(?%wde (p, ~ ), %3 where U =au{zl% z;,..., $nw x:> } xl, \n..., z n are all the identifiers that occur in p, Z4~.. . Z; are fresh identifiers, e~eW = bind( . . \n. bind(ident, z~, dl) . . ..z~. dn), and dj = Zooktip(edef, z:) for i = 1,. . .,n. rewrite (?v, a) = \na(?v) rewrite (x, a) = a(x) rewrite ((rl . .. Tn). U) = (E; . .. E~). where E: = rewrite (~~, a), i = \n1, . . . . n. Figure 5: Definition of rewrite (p, a, ede~) For simplicity, the definition of match in \nFigure 4 as\u00adsumes that no pattern variable is duplicated. The rewrite function (Figure 5) rewrites the \nmacro call using the substitution a generated by the matcher. It is also responsible for choosing the \nfresh identifiers that replace those that appear in the output pattern and establishing their proper \ndenotations. transcribe uses divert to add these new bhdlngs to the environment in which the macro output \nis expanded. Given constant-time operations on environments, this al\u00adgorithm takes O(n) time, where n \nis the time required by naive macro expansion. 3 Examples To make the examples easier to follow, we ll \nassume that let is understood primitively by the expansion algorithm, in a manner similar to lambda. \nThe initial environment e~~~tthus has a nontrivial binding for the identifier let in addition to lambda \nand let -synt ax. Example 1. Consider the problem of expanding the following expression in the initial \nsyntactic environment: (let-syntax ((push (syntax-rules ((push ?v ?X) => (set! ?X (cons ?v ?x)))))) (let \n((pros (list cheap fast )) (cons (list))) (push unreliable cons))) The rule for macro abstractions applies, \nbecause Zookup(eanzt, let-syntax) = let-syntax. The next step is to expand the body of the let-syntax \nexpression in an augmented syntactic environment el c btnd(einit, push, (r, einit )) where T=((( ?V ?x), \n(set! ?x (cons ?v ?x)))) The pattern is ( ?V ?x), rather than (push ?V ?x), be\u00ad cause the rule will only \nbe examined when the fact that the head of the form denotes the push macrois already appar\u00adent. Thus \nthere is never a need to match the head of the pattern with thehead of the expression to be expanded. \nThe initializersin the let expression expand to them\u00ad selves, because el k list ~ list. (Recall that \neanat, and therefore e] as well, is based on the identity environment ident. ) Next we expand the body \nof the let expressionin the augmented environment ez = birzd(bind(el, cons,cons. I),pros,pros.1) where \npros. 1 and cons. 1 are fresh identifiers. In ez, the identifier push denotes the macro (~, e~n~t), so \nthe rule for macro calls applies to the push expression. We now compute transcribe((push unreliable cons), \nr,ez, e~n~t) ~ consists of only one rule, which matches the input: match (( unreliable cons), ( ?V ?x), \nez, ei~it) = {?V I-4 II unreliable , ?x= cons} Note that match made no use of its two environment ar\u00ad \nguments, because the pattern ( ?V ?x) didn t contain any identifiers. The cond example below gives a \nsituation in which these environments are used. Now we compute the replacement expression: rewrite((set \n! ?X (cons ?v ?x)), {?v~ unreliable , ?x~cons}, %d) = ((set! .2 cons (cons.2 unreliable cons)), e,) \nwhere e3 =bind(bind(ident,s et!. 2, set!), cons.2,cons) and set ! .2 and cons. 2 are fresh identifiers. \ntranscribe now delivers the rewritten expression together with an environ\u00adment e4 = divert (ez, eq) = \nbind(bind(e2,set! .2,set!),cons .2,cons) that gives bindings to use in expanding the replacement ex\u00adpression. \nThe environmente4 takes set! .2 to set!, cons.2 to cons, and cons to cons.1, so e~ t-(set! .2 cons (cons.2 \nWnreliable!f cons)) - (set! cons.1 (cons unxeli.able cons.1)) The final result is (let ((pros.1 (list \ncheap fast )) (cons.1 (list))) (set! cons.1 (cons unreliable cons.1))) Example .2. This example illustrates \nreliable reference to local variables that are in scope where the macro is defined. (let ((x outer )) \n(let-syntax ((m (syntax-rules ((m) =>x)))) (let ((x inner )) (m)))) To expand this expression in eznz$, \na fresh identifier x.1 is chosen to replace the outer x, and the 1 et -syntax expression is expanded \nin the syntactic environment el = bind(einit, x,x. 1) This leads to expanding the inner let expression \ninthesyn\u00ad tactic environment ez = b~~d(el,m, (((( ),x)), cl)) Finally a fresh identifer x.2 is chosen \nto replace the inner x, and (m) is expanded in the syntactic environment e3 = bind(e2, x,x.2) Now trcmscribe \n((m), (((( )), x)), es, el) = (x.3, bind(ea, x.3)x.1)) where x.3 is a fresh identifer introduced for \nthe right-hand side of the rewrite rule for the macro m. The denotation of x.3 tion, is the denotation \nof which is x.1. The x final in the expa environment nsionis of m s defini\u00ad (let ((x.1 (let ((x.2 X.1)) \n outer )) inner )) Example 3. This example illustrates lexical scoping of con\u00adstant identifiers that \noccur in the left-hand side of rewrite rules. Following [9], we adopt the use of an ellipsis token . \n. . as part of the syntax of patterns, not as a meta-notation in\u00addicating that something has been elided \nfrom this example. (define-syntax cond (syntax-rules ((cond) > #f) ((cond (else ?result . ..) ?clause \n. ..) => (begin ?result . ..)) ((cond (?test) ?clause . ..) > (Or ?test (cond ?clause . ..))) ((cond \n(? test ?result . ..) ?clause . ..) => (if ?test (begin ?result . ..) (cond ?clause . ..))))) The second \npattern for this macro contains a fixed identifier else. This will only match a given identifer z in \na use of cond if the denotation of x in the environment of use matches the denotation of else in the \nenvironment ofcond)s definition. Typically xiselse and is self-denotingin both environments. However, \nconsider the following: (let ((else #f)) (cond (#f 3) (else 4) (#t 5)) ) Expanding this expression requires \ncalculating ~~tch(else,else,euse,edef) where lookup (ev~~, else) = else.1, Zookup(edej,else) = else. \nThus match (else, else, eu~e, edef) = nornatch and the final expansion is (let (if ((else.1 #f (if #f)) \n(begin 3) else.1 (if #t (begin (begin 4) 5) #f)))) Integration issues We emphasize that our algorithm \nis suitable for use with any block-structured language, and does not dependon the representation ofprograms \naslistsin Schenle. Scheme s rep\u00adresentation is especially convenient, however. This section explains \nhow the algorithm can be made to work with less convenient representations. The simplicity of the match \nfunction defined in Figure 4 results from the regularity of a Cambridge Polish syntax. For Algol-like \nsyntaxes the matcher could be much more complicated. To avoid such complications, a macro system may \neschew complex patterns and may specify a fixed syntax for macro calls. Our algorithm must understand \nthe structure of the source program, so Algol-like syntaxes require that the algo\u00adrithm be integrated \nwith a parser. If the :macro language is sufficiently restricted, then it may be possible to parse the \ninput program completely before macro expansion is per\u00adformed. Iftheactual parameters ofamacro call need \nto be transmitted to the macro in unparsed form, however, then parsing will have to be interleaved with \nthe macro expansion algorithm. For the algorithm to work at all, the parser must be able to locate the \nend of any macro definition or macro use. If parentheses are used to surround the a,ctual parameters \nof a macro call, for example, then mismatched parentheses within an actual parameter cannot be tolerated \nunless they are somehow marked as such, perhaps by an escape charac\u00adter. This is a fundamental limitation \non the generality of the syntactic transformations that can be described using a macro system based on \nour algorithm. This is not a particularly burdensome limitation. For example, it is possible to design \na hygienic macro system for C that allows the for construct to be described as a macro. Experience with \nmacros in Lisp and related languages has shown that macros are most useful when local variables can be \nintroduced in any statement or expression context. Most Algol-like languages are not fully block-structured \nin this sense. C, for example, does not admit blocks as expres\u00adsions, while Pascal and Modula-2 do not \neven admit blocks as statements. Fortunately this particular shortcoming can usually be overcome by the \nmacro processor. Macros can be written as though the language admits blocks in all sensible contexts, \nand the macro processor itself can be responsible for replacing these blocks by their bodies while lifting \nall local declarations to the head of the procedure body within which the declarations appear. In our \nalgorithm, the matcher compares an identifier in the pattern against an identifier in the input by compar\u00ading \ntheir denotations. This makes it difficult to use such a sophistical ed matcher in languages such as \nCommon Lisp, where an identifier may denote many different things at once, and where the overloading \nis resolved by syntactic context. The problem is that the matcher cannot reliably determine the syntactic \ncontext in which the identifier will ultimately appear. One solution is to ban identifiers from patterns. \nAnother is to resolve the overloading by relying on declarations provided by the author of the macro. \n5 Previous work, current status, future work The problems with naive macro expansion have been recog\u00adnized \nfor many years, as have the traditional work-arounds [2]. The capturing problems that afflict macro systems \nfor block-structured languages were first solved by Kohlbecker s work on hygienic macro expansion. Bawd \nen and Rees then proposed syntactic closures [I] es a more general and efficient but lower-level solution. \nOur algorithm unifies and extends this recent research, most of which has been directed toward the goal \nof developing a reliable macro system for Scheme. At the 1988 meeting of the Scheme Report authors at \nSnowbird, Utah, a macro committee was charged with de\u00ad veloping a hygienic macro facility akin to extend-syntax \n[5] but based on syntactic closures. Chris Hanson implemented a prototype and discovered that an implementation \nbased on syntactic closures must determine the syntactic roles of some identifiers before macro expansion \nbased on textual pattern matching can make those roles apparent [6]. Clinger ob\u00ad served that Kohlbecker \ns algorithm amounts to a technique for delaying this determination, and proposed a linear-time version \nof Kohlbecker s algorithm. Rees married syntactic closures to the modified Kohlbecker s algorithm and \nimple\u00ad mented it all, twice. Bob Hieb found some bugs in the first implementation and proposed fixes. \nA high-level macro system similar to that described here is currently implemented on top of a compatible \nlow-level system that is not described in this paper. Bob Hieb and Kent Dybvig have redesigned this low-level \nsystem to make it more abstract and easier to use, and have constructed yet another implementation. It \nis expected that both the high-level and low-level macro facilities will be described in a future report \non Scheme [3], Some problems remain. The algorithm we have described treats identifiers uniformly, but \nidentifiers in Scheme are lex\u00ad ically indistinguishable from symbols that appear in con\u00ad stants. Consequently \nany symbols introduced by a macro will be renamed just as if they were identifiers, and must therefore \nbe reverted after macro expansion has revealed that they are part of a constant. This means that constants \nintroduced by a macro may have to be copied. In this respect our algorithm improves upon Kohlbecker s, \nwhich copied all constants, but is still not ideal. More significantly, the pattern variables used to \ndefine macros might be lexically indistinguishable from identifiers and symbols. In order for macros \nthat define other macros to remain referentially transparent, pattern variables must not be reverted \nto their original names even though they are represented as symbols in our existing implementation. We \nare not completely certain that this refinement eliminates all problems with macros that define other \nmacros. One project we intend to pursue is to integrate our al\u00adgorithm with a module system for Scheme \nsuch as that de\u00adscribed in [4]. For example, it should be possible for a mod\u00adule to export a macro without \nalso having to export bindings needed by the macro s expansions. An obvious application for this research \nis to develop better macro facilities for other block-structured languages such as Modula-2. [II] Guy \nL. Steele Common Lisp: Digital Press, Jr. The Lcwsguage. second edition 1990. Acknowledgements The authors \nthank an anonymous member of the program committee who helped us to write the introduction. Jim O Toole \nand Mark Sheldon provided helpful comments on drafts of the paper. References [1] Alan Bawdenand Jonathan \nSyntactic closures. 1988 ACM Conference on gramming, pages 86 95. Rees. Lisp and Functional Pro\u00ad [2] \nP. J. Brown. Macro Processors and Techniques for Portable Soft\u00ad ware. Wiley, 1974. [3] William Clinger \nand Jonathan Rees, editors. Revised* report on the algorithmic language Scheme. University of Oregon \nTechnical Report CIS-TR-90-02, to appear. [4] Pavel Curtis and James Rauen. A module system for Scheme. \n1990 ACM Conference on Lisp gramming, pages 13 19. and Functional Pr-o\u00ad [5] R. Kent Dybvig. The Scheme \nProgramming Prentice-Hall, 1987. Language. [6] Chris Hanson. Personal communication. [7] Samuel P. Harbison \nand Guy C: A Reference Manual. Prentice-Hall, second edition L. Steele 1987. Jr. [8] Eugene Kohlbecker, \nDaniel Felleisen, and Bruce Dubs. Hygienic macro expansion. 1986 ACM Conference on gramming, pages 151 \n159. P, Lisp Friedman, Matthias and Functional Pro\u00ad [9] Eugene E. Kohlbecker Jr. Syntactic extensions \nin the programming language Lisp. Technical report no. 199, Indiana University Computer Science Department, \n1986. [10] Jonathan Revised3 SIGPLAN A. Rees and William Clinger, editors. report on the algorithmic \nlanguage Scheme. Notices 21(12), pages 37-79, 1986. \n\t\t\t", "proc_id": "99583", "abstract": "", "authors": [{"name": "William Clinger", "author_profile_id": "81100543143", "affiliation": "Department of Computer Science, University of Oregon", "person_id": "PP40028429", "email_address": "", "orcid_id": ""}, {"name": "Jonathan Rees", "author_profile_id": "81408597616", "affiliation": "Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA", "person_id": "PP14274211", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/99583.99607", "year": "1991", "article_id": "99607", "conference": "POPL", "title": "Macros that work", "url": "http://dl.acm.org/citation.cfm?id=99607"}