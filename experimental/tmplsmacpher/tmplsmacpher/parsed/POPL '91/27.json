{"article_publication_date": "01-03-1991", "fulltext": "\n Modeling Concurrency with Geometry Vaughan Pratt ~ Computer Science Department Stanford University Stanford, \nCA 943o5 pratt @cs.st anford.edu Abstract The phenomena of branching time and true or noninter\u00adleaving \nconcurrency find their respective homes in au\u00adtomata and schedules. But these two models of compu\u00adtation \nare formally equivalent via Birkhoff duality, an equivalence we expound on here in tutorial detail. So \nwhy should these phenomena prefer one over the other? We identify dimension as the culprit: l-dimensional \nau\u00adtomata are skeletons permitting only interleaving con\u00adcurrency, whereas true n-fold concurrency resides \nin transitions of dimension n. The truly concurrent au\u00ad tomaton dual to a schedule is not a skeletal \ndistributive lattice but a solid one! We introduce true nondeter\u00adminism and define it as monoidal homotopy; \nfrom this perspective nondeterminism in ordinary automata arises from forking and joining creating nontrivial \nhomotopy, The automaton dual to a poset schedule is simply con\u00adnected whereas that dual to an event structure \nschedule need not be, according to monoidal homotopy though not to group homotopy. We conclude with a \nformal defi\u00adnition of higher dimensional automaton as an n-complex or n-category, whose two essential \naxioms are associa\u00adtivity of concatenation within dimension and an inter\u00adchange principle between dimensions. \n1 Background A central problem in the semantics of imperative com\u00adputation is the construction of convenient \nmodels of computation embodying the apparent aspects of both branching time and true or noninterleaving \nor causal t This work was supported by the National Science Foundation under grant number CCR-8814921. \nPermission to copy without fee all or part of this material is granted provided that the copies are not \nmade or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand its date appear, and notice is given that copying is by permission of the Association for Computing \nMachinery, To copy other\u00adwise , or to republish, requires a fee and/or specific permission, @ 1990 ACM \n089791419-8/90/0012/031 1 $1.50 concurrency. Milner [Mi180] haa made a convincing case for includ\u00ading \nthe timing of nondeterministic choices in any com\u00adprehensive model of computation, distinguishing linear \ntime (all choices made at the outset) from branching time (choices made on-the-fly to take into account \nthe latest information). Park s notion of bisimulation equiv\u00adalence [Par81] has emerged as a particularly \nfine equiv\u00adalence of labeled transition systems, though not so fine as to abandon the idempotence of \nchoice. Two recent comprehensive yet complementary accounts are given by Bergstra and Klop [BK89] and \ntheir student van Glabbeek [Gla90], with the latter also addressing true concurrency in more detail. \nThe most natural computational setting for branch\u00ading time would appear to be transition systems or state \nautomata, where the branching is naturally represented by that of the automaton. These may be unrolled \nto yield synchronization trees so aa not to represent other information. However Nielsen, Plotkin, and \nWinskel have defined event structures as an extension of sched\u00adules with a conflict relation to represent \nbranching time, about which we will have more to say later. Lamport [Lam86] and independently the present \nau\u00adthor argue against the interleaving model of concurrency on the ground that exactly what is interleaved \ndepends on which events of a process one takes to be atomic [Pra86, p.37]. When a supposedly atomic action \nis re\u00adfined, which from a pragmatic viewpoint can be taken to mean looked at more closely to reveal its \nsubstruc\u00adture, the interleaving model can be seen not to have in\u00adterleaved the subactions, having been \nforced to commit itself in advance to a particular level of granularity. This failure to interleave subactions \nis characteristic not of true concurrency but rather of mutual exclusion, Thus in an interleaving model \nthe truly concurrent execution of two atomic events cannot be distinguished from the mutually exclusive \nexecution of those events. Castellano et al [CDP87] formalize this intuition with a simple example showing \nthat interleaving semantics is not preserved under refinement (where refinement is de\u00adfined as substitution \nof a complex behavior for an atomic behavior), but that partial order semantics is so pre\u00adserved. The \nnatural computational setting for true concur\u00adrency is that of schedules or partially ordered sets of \nevents. If branching time can be moved from automata to schedules [NP W81], can true concurrency go the \nother way? Van Glabbeek and Goltz [vGG89] strengthen the re\u00adsult of Castellano et al in several ways. \nFirst they give a stronger example to show that step semantics (a form of concurrency intermediate between \ninterleaving and partial orders, permitting multiple but synchronized ac\u00adtions at each clock tick) is, \nlike interleaving semantics, not preserved under refinement. Then they extend the linear time result \nof [CDP87] to encompass branching time. Finally they point to ST-bisimulation, a delight\u00adfully simple \nextension of the notion of Petri net mark\u00ading due to van Glabbeek and Vaandrager [GV87] that is preserved \nby refinement yet supports branching time, as an example of a semantics that models true concurrency \nand furthermore treats branching time, all without re\u00adquiring partial orders. Now ST-bisimulation comes \nwithin striking distance of the problem we just posed of moving true concur\u00adrency to the automaton model. \nHowever Petri nets are neither schedules nor automata, but a symmetric combi\u00adnation of both, in that \nPetri nets alternate the vertices of schedules, as transitions, with the vertices of automata, as places. \nThe main contribution of this paper is a geometric model of concurrency. This model completes the pas\u00adsage \nof true concurrency to automata by redefining the schedule aspects of a Petri net, namely its transitions \nrepresented in Petri nets as vertices, as higher dimen\u00adsional transitions of an automaton! This also \nyields a model that is in our opinion mathematically more at\u00adtractive than Petri nets, certainly those \nwith unbounded place capacities. There are two side contributions. One is a much needed tutorial on the \nduality of schedules and au\u00adtomata around which our introduction has revolved and which continues to \nplay a role in the sequel. The other is the application of n-categories or n-complexes to con\u00adcurrency \ntheory, as a formal model of higher dimensional automaton, for which we contend they are more natu\u00adrally \nadapted than other extant algebraic structures.l 1Among other recent applications of so-called Australian \ncate\u00adgory theory to concurrency is an application of enriched categories to the abstract modeling of \ntime a la Floyd-Warshall, presented to a category audience [C CMP89]. We regret not having had the OPPOrtunity \nto present this at POPL-88 or POPL-89.  2 A Geometric Model of Com\u00adput at ion Our thesis is that both \nbranching time and true con\u00adcurrency can be described together in a single geomet\u00adric model. Branching \ntime is represented literally by branching of geometric objects, exactly as one would picture it. In \nparticular we treat a transition system as a one-dimensional space consisting of edges (its tran\u00adsitions) \nmeeting and branching at vertices (its states). True concurrency is represented by dimension: an n\u00addimensional \ncell (element of space) is used to represent the concurrent execution of n sequential processes, and \nits boundaries represent the starting or halting of some of those processes. Our geometric view is closely \nrelated on the one hand to ST-bisimulation [vGG89], and on the other to Pa\u00adpadimitriou s geometrical \nmodel for database concur\u00adrency control [Pap86, chap.6]. To be cryptically succinct, we propose to extend \ninter\u00adleaving concurrency to true concurrency by filling holes, and then to extend true concurrency to \nbranching time by putting some of those holes back. So what is a hole? Consider two automata, each hav\u00ading \ntwo states and one transition and accepting the re\u00adspective regular sets a and b, each consisting of \none unit-Iength string. With interleaving concurrency the con\u00adcurrent execution of these two automata \nis their prod\u00aduct, a square whose four sides represent four transitions, accepting the regular set ab \n+ ba as in Figure B four pages hence. This automaton contains a hole, namely the interior of the square. \nTo formalize this, embed the automaton, treated aa a graph, in the Euclidean (real) plane. For definiteness \nlocate its states at the lattice points (O, O), (1, O), (O, 1), and (1, 1) (the corners of the unit square \n[0, 1]2; y is oriented negatively in l? ). Take the initial state to be the origin, and take the four \ntransitions to be the four sides of this square. The hole is then the interior of the square. To fill \nthe hole, take the interior of the square, a surface, as the ninth component of this product automa\u00adton. \nThe four vertices, qua states, and the four edges, qua transitions, comprise the other eight cells of \nwhat we shall refer to as a cell complex. These nine cells represent the nine possible states of the \nconcurrent automaton. Four states are completely idle (states in the usual sense), four have one constituent \nautomat on active, and one has both constituents active. This last may be described as a two-dimensional \nor su\u00adperficial transition. It provides a notion of joint tran\u00adsition of two processes. Van Glabbeek \nand Vaandrager [GV87] have in\u00adtroduced ST-bisimulation, in which not only places (Stellen) of Petri nets \nbut transitions ( ?kansitionen, whence ST) are marked in a state (an assignment of tokens to vertices). \n(Itisextraordinary that this simple andintuitively clear extension of the notion of Petri net state has \nnot been proposed before!) The relationship with ST-bisimulation may be easily seen by consider\u00ading the \ncorresponding example for Petri nets. As usual a one-transition automaton becomes a Petri net simply \nby converting its transition from an edge to a vertex and adding two edges to represent respectively \nthe pre-event or input arc and postevent or output arc, each incident on the one transition. The concurrence \nof two such nets is smaller) than that of the corresponding automata, being just their juxtaposition, \nhaving for its vertices not the cartesian product of the vertices of the underlying nets as was the case \nfor the automata but rather their disjoint union. If we mark the initial place of each of the two compo\u00adnents \nof this juxt aposition and then play the usual to\u00adken game, we obtain four possible markings of places, \ncorresponding to the four vertices of the square au\u00adtomaton. If however we extend the token game as in \nST-bisimulation to permit transitions to be marked, we obtain an additional four markings each involving \none transition (the four edges of the square), together with a single marking involving both (the interior \nof the square), completing the promised correspondence. There are three trivial generalizations we can \nmake immediately. First we may increase the number of au\u00ad tomata executing concurrently. With three \nautomata we obtain a cube in the obvious way, with four a 4\u00ad cube, etc. We refer to the d-dimensional \nelements of such a complex as d-cells, with O-cells or points corre\u00ad sponding to the old notion of state, \nl-cells or edges the old notion of transition, and the higher-dimensional cells constituting a new notion \nof concurrent transition. Second, we may let the i-th automaton, for O < i < d, run for mi transitions, \nprovided its graph forms a chain so that it accepts just one string, of length mi. Our unit cube then \nexpands to a larger complex of size Hi mi. Third, we may label transitions. If we associate alpha\u00adbet \n~i with the i-th sequential automaton for O ~ i < d, we may label its edges in the standard way for automata. \nTo extend this to higher dimensions we require for each subset of this set of c1alphabets the alphabet \nformed as the product of that subset, yielding 2d alphabets. Each n-cell is then labeled with an n-tuple \nof labels from the appropriate alphabet, namely that corresponding to the subset of automata whose activity \nis represented by the cell. All completely quiescent states (O-cells) are labeled with the unique O-tuple, \nindicating the absence of activ\u00adity. l-cells are labeled with I-tuples, as in an ordinary automaton. \n2-cells are labeled with pairs (a, b) indicat\u00ading the joint execution of transitions a and b, and so \non for higher dimensions. Less trivial is the next generalization, which imposes order constraints. \nFor any two transitions of different automata we may require that one not start until the other has finished, \na precedence constraint. We shall call such a collection of constraints a schedule, the term used in \n(inter alia) the Macintosh world for PERT charts or pomsets. With this generalization the second trivial \ngeneraliza\u00adtion now becomes redundant, since we can achieve the effect of a sequential automaton having \nm transitions by using m concurrent one-transition automata constrained to execute in a specified sequential \norder. To simplify the model we therefore withdraw generalization two. This restricts our basic automata \nto single-transition automata, more conventionally called events. We may now describe each precedence \nconstraint as holding be\u00adtween such events i and j, without having to further specify a particular transition \nwithin each event. These constraints, which we write as i < j, then amount to a partial ordering of the \nset (or multiset in the labeled case) of d events. We saw already that the square (2-cube) had nine cells. \nMore generally the d-cube has 3d cells. The num\u00adber three arises ss the possible states of an event: \ninitial, transition, final, or O, T, 1 for short. Each cell can then be identified as a d-tuple over \n{O, T, 1} = 3. The stan\u00addard interpretation of i < j is to exclude all cells save those whose j-th event \nis O or whose i-th event is 1. In place of {O, T, 1} we may take the unit interval [0, 1] on the real \nline, whose interior (O, 1) corresponds to T alone and whose endpoints are the correspondingly named \nelements of {O, T, 1}, Then the d-cube becomes the unit cube [0, l]d in d-dimensional Euclidean space \nRd, having a continuum of points rather than just 3d. Now one quite reasonable interpretation of i < \nj is to restrict to the polyhedral subspace of the cube consisting of those points whose i-th coordinate \nis greater than their j-th coordinate. This corresponds to permitting events i and j to run concurrently \nbut without letting j get ahead of i. For any partial ordering of events this subspace is convex and \ncan be easily shown to have volume k/d! where k is the number of linearization of the partial order, \nbeing the (essentially) disjoint union of k tetrahedral one per linearization. However this is not the \nproper analog in Rd of sub\u00ad spaces of 3d, since it cuts faces into tetrahedral. The appropriate real-valued \nanalog further restricts the sub\u00ad space to those points such that either the j-th coordinate is O or \nthe i-th coordinate is 1. But this is exactly how we expressed the condition for 3d. In fact i < j was \nin\u00ad terpreted without mentioning T at all, being expressed solely in terms of the initial and final states \nof an event, regardless of what structure we impart to its interior. Unlike the interpretation of i < \nj in the previous para\u00ad graph, the subspace of Rd given by the standard inter\u00ad pretation is not convex. \nHowever, as will be seen to be important shortly in our approach to nondeterminism, it cent ains no holes. \n Schedule-Automaton Duality With this last generalization we have passed from un\u00adscheduled to scheduled \nactivity, the latter being the essence of the pomset model [Gra81, Pra82]. From a mathematical perspective \nwe have passed (at least in the finite case) from the Birkhoff-Stone duality between sets (of events, \nas points of a finite discrete topologi\u00adcal space) and Boolean algebras (of states) to the much richer \nBirkhoff duality between posets (still of events) and distributive lattices (still of states). The Birkhoff \nduality is becoming better known in the CS community of late. However there remains consid\u00aderable confusion \nin both the mathematical and CS lit\u00aderature over the difference between Birkhoff duality and Stone duality, \nperpetrated in our opinion by an unwar\u00adranted enthusiasm for topological methods to the ex\u00ad clusion of \ncombinatorial. It is very helpful to see these distinctions clearly when working with our geometrical \nmodel of concurrency. Hence we give here an overview of this duality and its application to concurrency, \nSequential computers alternately work during a tran\u00adsition and then rest up at a state. This scenario \nis con\u00adventionally rendered as a graph whose vertices represent either transitions or states. If transitions \nthen we have a PERT chart or schedule, and the edges of the graph denote precedence relations, possibly \nlabeled with dura\u00adtions indicating bounds on the time from one transition to the next. If states then \nwe have a machine or au\u00adtomaton whose edges are transitions from state to state, possibly labeled with \nattributes of the transition. But which picture is the right one? The Petri net answer is neither: transitions \nand st ates should be granted equal rights by both being vertices. These then serve aa respectively the \nconjunctive and dis\u00adjunctive elements of an intriguing logic of concurrency. The duality theory answer \nis both: for at least a cer\u00adtain class S of schedules and class A of automata they depict the same scene \nbecause S and A are equivalent. Not isomorphic, which would imply a 1-1 correspon\u00addence between the elements \nof S and A, but equivalent in the sense of a 1-1 correspondence between the isomor\u00ad phism classes ofs \nand A. (This is exactly the category theoretic notion of equivalence.) Here is a simple special case \nof this equivalence. A finite schedule S that is just an unordered set of n jobs (transitions) to be \ndone in parallel is very easy to compile into an automaton. The automaton is just the power set 2s, drawn \nin the standard way with the empty set at bottom as the start state and S at top as the final state, \nand edges between just those sets differing by exactly one job, with that job labeling that edge. For \nthe automaton to be in state Y means that the set of jobs done thus far is Y. This is the Hasse diagram. \nof its lattice, i.e. the smallest DAG whose transitive closure is the inclusion order ~ between subsets. \nThis lattice is of course a Boolean algebra, meaning a distributive lattice wit h a complement operation. \nIt is helpful to regard the states of the automaton as 2n bit vectors of length n, with bit z being 1 \nin state Y just when job x has run by the time that state is reached. Then the set operations Y U Z and \nY n Z are bit vector operations such that in each bit position they are just V and A. Recompilation is \ntraditionally harder than compila\u00ad tion, but in this case recompilation is just as easy as compilation. \nGiven such an automaton A, form its power automaton 2A, consist ing of certain sets of states of A. Now \nif an automaton were simply a set of states, 2A would mean the power set of A. But that would be huge \nand fortunately wrong. The right way to form the power widget 2W of a widget W is to take all widget \nmaps from W to 2. This works provided there s a sensible way to construe 2 as a widget. The automaton \nA is a lattice, and luckily the poset 2 is schizophrenic enough to be also the lattice O < 1 of truth \nvalues. Hence we take for 2A all lattice maps (homo\u00admorphisms) from A = 2 s to 2, meaning functions that \npreserve the lattice structure, i.e. f(fJ) = O, ~(S) = 1, !(Y u Z) = $(Y) V ~(Z), and ~(Y rl Z) = j(Y) \nA ~(Z). It can be easily seen that preserving this much implies preserving complement as well, so these \nare also Boolean algebra maps. So what maps does this give us? One function that satisfies the desired \nconditions above is the predicate ~c that tells of each state whether job z has run yet. But looking \nat A as 2m bit vectors, this is just the function that watches bit x, As long aa bit z works reliably, \nwhen Y U Z is formed bit z will appear to be computing YZ V Z., and dually for n. But this is what the \nabove conditions require. So these functions are lattice maps. They are in fact the n projections of \n2X onto 2, 2X being the product of n copies of 2. That they are different can be seen by their behavior \non singleton states. Hence these maps form a set isomorphic to X, that is, having cardinality IX 1. That \nit is only isomorphic and not equal is why the duality is only an equivalence and not an isomorphism! \nAnd these are all the lattice maps there are from A to 2. For ~ can t be O on every singleton or it \nwould make ~(S) = O, S being finite. But ~ can t be 1 on two or more singletons since that would make \n~(o) = 1. So ~ must be 1 on exactly one singleton {~}. But now ~({~} ny) = $({~}) A ~(Y) = ~(Y) whence \n~(Y) = 1 exactly when z c Y, making ~ = ~Z. But the theorem is that recompilation back to sched\u00ad ules \nworks for an isomorphism class of automata, so we aren t allowed to refer to states as singletons per \nse. However this is no problem: we can spot the singletons by context as being just those states immediately \nfol\u00adlowing the start state, namely the atoms of the Boolean algebra. So we revise the above argument \nto work for all automata isomorphic to 2s by substituting atom for singleton. So we now have a 1-1 correspondence \nbetween all iso\u00admorphism classes of finite sets and some set of isomor\u00adphism classes of finite Boolean \nalgebras. But the reader well knows (though it is some work to prove) that every finite Boolean algebra \nis isomorphic to the power set of some finite set, and so we have the promised equivalence. But this \nvery special case of Birkhoff-Stone duality is as boring as the natural numbers, since the finite sets \nfall into isomorphism classes according solely to their car\u00addinality n, one class per number, and correspondingly \nthere is just one isomorphism class of Boolean algebras of cardinality 2n. So the picture so far is that \nif schedules are just un\u00adordered sets of jobs, there is, up to isomorphism, just one schedule of each \nsize n and one matching automa\u00adton of size 2n. This duality can now be spiced up in two essentially \northogonal ways, a combinatorial one due to G, Birkhoff [Bir35] and a topological one due to M. Stone \n[Sto36]. Remarkably, that these ways were orthogonal passed un\u00ad noticed until pointed out by H. Priestley \nin 1970 [Pri70]. Keeping everything finite, Birkhoff duality generalizes the discrete schedules to partially \nordered schedules, and generalizes the automata to distributive lattices. On the other hand, keeping \nthe automata Boolean, Stone dual\u00adity generalizes everything to the infinite case. In order to allow every \nBoolean algebra to be viewed as the com\u00adpilation of some schedule Stone generalizes schedules of jobs \nto schedules of sets of jobs called (nowadays) Stone spaces. Instead of running individual jobs one must \nnow run sets of jobs at a time, and only in those combina\u00adtions that are permitted. The automaton produced \nby compiling such a schedule will now be a proper Boolean subalgebra of the power set of the set of all \njobs in the schedule, due to the schedule restrictions eliminating some states, e.g. those containing \nonly finitely many jobs. Stone did extend his Boolean duality to distributive lattices [Sto37], but purely \ntopologically rather than via the more natural blend of order and topology devised by Priestley. As Rota \nput it, Stone s representation theorem of 1936 for distributive lattices closely imitated his representation \ntheorem for Boolean algebras, and as a consequence turned out to be too contrived. [Rot73] Priestley \nsimply equips the schedule with both Birkhoff s partial order and Stone s topology to make it a partially \nordered Stone space, a set bearing two struc\u00adtures, that of a partial order and that of a topology, Stone \ns in this case. The partial order deals with the absence of complement ation, generalizing Boolean alge\u00adbras \nto distributive lattices, and dually on the schedule side, sets to posets. The Stone topology, which \nresides on the schedule side, caters to the phenomenon whereby a countably infinite Boolean algebra, \nand by the same token a distributive lattice, can have a countably infinite subalgebra not isomorphic \nto its parent, by forbidding those combinations of jobs (i.e. subsets of X) corre\u00adsponding to missing \nelements of said subalgebra. Thus Birkhoff s and Stone s halves of this beautiful duality theory are \nessentially independent. Both halves have potential computational significance. Birkhoff du\u00adalit y is \nrelevant to scheduling, the main thrust of this paper. Stone duality is relevant to continuous situa\u00adtions, \ne.g. parallel solutions to stock-cutting problems where the regions can get arbitrarily small without \never becoming points. It may also prove fruitful in reasoning about large systems where the number of \njobs makes it uneconomical or infeasible for a scheduler to deal with individual jobs, forcing it to \nbatch them, the chief diffi\u00adculty here being that of translating the logic of infinity down to large \nbut finite numbers. For our geometry-of-concurrency purposes however we currently have no application \nfor Stone duality. In this paper we focus on schedules structured by a par\u00adtial order, and hence on Birkhoff \nduality, a finite and pleasantly combinatorial phenomenon.2 Finite posets are far less boring than finite \nsets. Whereas the number of isomorphism classes of sets of each cardinality goes 1, 1, 1, 1, 1, 1,1,. \n. . the correspond\u00ad ing sequence for posets goes 1,2,5, 16,63,318,2045, . . .. So when you are scheduling \n7 jobs, there are 2045 differ\u00ad ent ways to schedule them, one of which is the discrete order, no precedence \nconstraints, at one extreme and another of which is the linear order (this is only up to isomorphism, \nor we would have 7! linear orders) at the other. Despite this enormously richer software library (and \nthis is before we ve labeled the vertices to say what each job does, being only up to isomorphism), the \nstory about schedules and automata remains almost completely un\u00adchanged! To compile S form A = 2s. To \ndecompile A back again form S = 2A. It will become clear shortly that these definitions as they stand \nare time reversing in both directions. We couldn t see this before because sets and Boolean alge\u00ad bras \nare both isomorphic to their duals. We fix this by reversing the input to each exponentiation. Thus 2some \nsay topology&#38;Odd become pointless, others that it al\u00adwaj-a wm. f oinmm~, che fa$her of combinatorial \ntopology, said of Cantor s Mengenlehre that it was a disease from which later generations would regard \nthemselves as having recovered. It is a sporting bet that we will recover sooner from the internal com\u00adbustion \nengine. we actually compile with 2s0 and decompile with 2A , where XOP denotes the order dual of X. Remarkably, \nnothing about our reasoning for un\u00adordered schedules needs be changed until we get to the matter of whether \nthere are any other maps besides the ~X s. The arguments involving singletons are no longer sound, because \nthere may now be fewer singletons, in the extreme case only one if some job has to go first. But we achieve \nthe same effect by taking, for each x, the state {yly < x} (a so-called principal order ideal because \nit is generated by one element, z), clearly in A. This state is the earliest moment at which z could \nhave run. To make this abstract (remember, we claim only an equivalence, not an isomorphism), the analog \nof atom is now obtained by noticing that these states are exactly those that aren t the union, or rather \njoin since this is going to be for lattices, of two smaller states, i.e. they are join-irreducible. The \nstates we ve picked can t be so represented because x has to be in one of them and there is no smaller \nsuch state. Those we left out are not principal and hence have at least two maximal elements, in which \ncase they can be represented as the union of the principal order ideals generated by each of their maximal \nelements. We now observe that our f. s are all distinct because each first becomes true at its own join-irreducible \nstate. Furthermore when we compare the f. s coordinatewise by inclusion we find f. ~ fg (which we can \nread as if x has happened then y has happened ) just when y ~ x in S. So this ordering of the fz s coincides \nwith the original order on S, showing that 2A is isomorphic to the original poset S. This equivalence \nof the classes of finite posets and finite distributive lattices is actually a contravariant equivalence \nof categories. This means that the corre\u00adspondence between posets and lattices extends to their maps, \nwith contravariant meaning that correspond\u00ading arrows go in opposite directions, i.e. the poset map f \n: P + q corresponds to a lattice map f : q -+ p between the corresponding lattices. The adjacent figure \ncontains two diagrams, one in the category of finite posets, on the left, the other on the right in the \ncategory of finite distributive lattices. Each diagram has seven objects A through G, primed on the right. \nThe six poset maps on the left, numbered 1 through 6, go down while the corresponding lattice maps on \nthe right go up. Object A is a one-job schedule while A is the corre\u00adsponding one-transition automaton. \nThe map 1 : A ~ B is an inclusion which adds job b while the correspond\u00ading map 1 : B ~ A is a projection, \nprojecting out b. 2 : B + C is an augmentation of the discrete order in B to a linear order in C. This \nconstraints knocks out the bottom left corner of B , represented by an inclu\u00adsion 2{ : C { + B . (71 \nis the top and right edges of B), straightened out. Now a new element c is added in on the left; the \nrelevant piece of the diagram is a coproduct E whose inclusions are maps 3 and 4. The dual of a co\u00adproduct \nis a product; 3 : E ~ C projects out c while 4 : E ~ D projects out a and b. Now 5 augments with a ~ \nc, again knocking out a corner. Finally 6 adds two new elements, d after b and e spliced in between a \n and c. A ~ -?Po Oa A +1 1 1. Q--a-o 5 tb   ? -- 0 F t c 6 t &#38; --ob--d 1 1 One may well imagine \nthat distributive lattices would be harder to visualize than Boolean algebras. This need not be so. The \nkey to visualizing a distributive lattice 2s0 is to interpret the precedence constraints of S in 2s0 \n. What each constraint z ~ y does is to delete all states violating that constraint, namely those containing \ny but not z. The remaining states retain their original positions, preserving the geometry of the cube. \nThus a finite distributive lattice is simply an eroded cube. One immediate application of dualities of \nthis kind is that it maps colimits to limits in passing from schedules to automata. This follows from \nthe manner in which du\u00ad ality is obtained as the exponentiation DX, for a suitable dualizing object D, \nin the category of posets, yielding for example D +v = D x Dy. Casley et al [CCMP89] outline a language \nfor concurrency a number of whose operations are describable as colimits in a category of schedules; \nthese are therefore carried to the correspond\u00ad ing limits in the dual situation. The language is defined \nfor schedules having various notions of time, such as real-valued time3, set-valued time, and causal-accidental \ntime, with posets having merely truth-valued (O and 1) time. Event Structures. The next generalization \ntakes us to the event structure model [NPW81].4 Here we specify asymmetric irreflex\u00adivebinary relation \ni#j on events, whose meaning is that not both ofi and jmayrun. In the presence ofschedul\u00ading we require \nthat i#j and j < k imply i#k, that is, conflict is a persistent condition. An event structure is then \nsuch a set (V,<, #), V being the set of events. The effect of the scheduling order < was to erode the \ncorresponding automaton by deleting certain cells, con\u00adverting it from a cube or Boolean algebra to a \ndistribu\u00adtive lattice. (Every finite distributive lattice arises in this way.) The effect of conflict \n# is to further erode the automaton, this time only from the top down (a consequence of the persistence \nof conflict), deleting just those cells such that for some i#j neither the i-th nor j-th component of \nthat cell is O, corresponding to states in which both i and j are either running or have halted5. In \nthese generalizations the filled-in holes of a given distributive lattice have not themselves added any \nin\u00adformation, since they can be reconstructed from the distributive lattice by first passing to its dual \nposet, taking this to be a scheduling of events, and construct\u00ading the filled-in lattice from the poset \nby the procedure given above, as a subspace of either 3d or Rd as desired. However event structures currently \nprovide the largest known class of schedules to date that we are aware of for which this holds.  Monoidal \nHomotopy We now define a preliminary notion of monoidal homo\u00adtopy and use it as the basis for a definition \nof true nondeterminism. It is expected that a more formal no\u00adtion of monoidal homotopy will be able to \nbe baked on the n-complex model of higher dimensional automata presented in the concluding section. A \nfinite distributive lattice is both confluent and simply-connect ed in the following sense. Given any \ntwo (ascending) paths in the lattice (defined as just the ver\u00adtices they pass through, the edges can \nbe inferred), the 3Infinit esimally fine int erleaving looks like true concurrency un\u00adtil one notices \nit is taking time L1 or z + y. Truly concurrent real time requires only Lm or max(z, y), a theme developed \nin future work. 4AS Girard [Girsfi lmti noticed to good effect in developing the notion of coherent space, \nthis generalization can be made inde\u00adpendently of the preceding one. 5Without schedfing these are Girrmd \ns coherent spaces, or rather coherent algebras if we adhere to the dualit y theorists nam\u00ading convention \nfor such dualities. lattice property uniquely determines two vertices, re\u00adspective y the meet and join \nof the union of those paths, in turn determining (not uniquely) extensions of the paths to those points \nto give them a common beginning and end, this being confluence. And the distributivity property uniquely \ndetermines the appropriate filling-in of the holes in the lattice, yielding a simply-connected space \nthrough which the two paths may be continuously deformed into each other in the intuitively obvious way, \nprovided we regard this space as Euclidean, i.e. a subset of Rd rather than 3d. By suitably defining \nthe discrete analog of continuous deformation we may achieve the same effect in 3d, addressed below, \nbut for now our in\u00adtuition with Euclidean space will suffice. In topological language, any two paths \nwith common endpoints in such a simply-connected space are auto\u00admatically homot epic, an equivalence \nrelation on paths [Bro88, Whi49, Whi78]. They become nonhomotopic when a hole appears somewhere in the \nspace between them to inhibit their deformation into one another. Homotopy is ordinarily studied for \nspaces the move\u00adments in which form a group under composition, where homotopy is inhibited only by holes. \nThe typical irre\u00adversibility of computation however calls for a monoid. This in turn calls for a generalization \nof the notion of homotopy from group-homotopy to monoid-homotopy, leading to other ways of inhibiting \nhomotopy. For now we settle for the following stopgap notion, defined only for our present setting of \ndistributive lattices. Given two ascending paths p, q in a distributive lattice L having common endpoints, \nand given a subspace of the Euclidean fill-in of this lattice, we say that p and q are group-hornotopic \nwith respect to X when they are homotopic in X in the standard sense of topology. Given two ascending \npaths p, q not necessarily having common endpoints, we say that p and q are monoid-homotopic with respect \nto X when they extend to paths that are group-homotopic with respect to X. This generalizes homotopy \nby permitting paths with\u00adout common endpoints, the application of which will be apparent shortly. Henceforth \nby homotopic we shall mean monoid-homotopic. We think of decisions involving choices between paths as \nessential just when the paths are not homotopic, and hence of filled-in distributive lattices as deterministic \nor choiceness automata. Nondeterminism is the condition in which there exist paths not homotopic to each \nother; we think of the choice between nonhomotopic paths as an essential decision. Conflict introduces \nnondeterminism into distributive lattices, by selectively destroying confluence in the for\u00adward (upward) \ndirection, by making notches in the top of an automaton. Two paths on opposite sides of such a notch \nare committed to their respective sides and cannot be extended upward to group-homotopic paths, there \nbeing no join to extend to; hence they are not homotopic in our broader sense. (Since the effect of persistence \nis to limit notching to the top} making such an automaton an order ideal of the distributive lattice \nit was obtained from, it follows that for conflict it would make no substantial difference if we restricted \nthe defi\u00adnit ion of monoid-homot op y j ust to paths with common beginnings, since any two paths can \nbe extended to have a common beginning.) 6 Benefits of a Geometric Model The biggest advantage for us \nof this geometric perspec\u00adtive is that it makes the duality of schedules and au\u00adtomata more convincing. \nIf by leaving two events un\u00adordered we have supposedly represented their true con\u00adcurrency, how do we \nthen explain the automaton dual to this discrete poset, namely the four-state four-transition square \nalready discussed? The latter is ezactly the au\u00adtomaton one would expect the interleaving model to pro\u00adduce! \nOne answer to this puzzle is to say that such a square always indicates true concurrency, and to rep\u00adresent \nij + ji (namely the mutual exclusion of i and j) by not letting the ij and ji branches rejoin when done. \nOur answer is instead to fill in the square to indicate true concurrency and simply leave it hollow to \nindicate mutual exclusion. We see this approach as having the following benefits. (i) Naturality. Lines, \nsurfaces, and volumes, attached to each other in possibly branching ways, are familiar and easily visualized \nconcepts, requiring relatively little mathematical sophistication to at least begin to appre\u00adciate. (ii) \nFlexibility. A greater variety of situations may now be represented. For example we now can choose whether \nij and ji are to rejoin immediately, a little later, or never. For reason (iii) (complexity) we will \nin general prefer the first, but we may on occasion find it meaningful to rip upwards a little or a long \nway. (iii) Complexity. An m x n rectangle contains only rnn squares but (m; ) paths (between adjacent \nlattice points) from start to end. Even if we associate informa\u00adtion with every square (e.g. by forbidding \nsome), the geometric representation of this information is of poly\u00adnomial size in the sides whereas the \ninterleaving repre\u00adsentation, in terms of the paths, is of exponential size. (iv) Continuity. Tearing \na picture into little strips is an inherently discontinuous operation. Decomposing a d-dimensional space \nas a set of paths through it is somewhat akin to identifying a TV picture with its one\u00addimensional representation \nas a sequence of scan lines. A TV serviceman who never saw a screen but only the scan lines laid end \nto end may find this perspective nat\u00adural, but certainly not a viewer. We programmers tend to be more \nlike servicemen than viewers. Years of thinking about individual in\u00adstruction sequences have conditioned \nus to believe that the sequence is the correct object of study. If instead we were to assemble many such \nsequences, properly aligned, into a single picture, the resulting shapes that would ma\u00adterialize would \nmake it much easier to reason about our processes. (v) Algebraic structure. Geometry is an alge\u00adbraically \nmature subject, and we are optimistic that some of this algebra will rub off on our geometrically based \nmodel of computation. Thus far we have in fact elicited some algebraic structure, but mainly from that \nof event structures via duality. We are presently work\u00ading on replacing this convenient but limited derivation \nwith an elementary development of homology based on monoids instead of groups to yield what we feel will \nbe a more comprehensive and convincing algebrizat ion. To be more precise, we base it not exactly on \nmonoids but rather on their generalization to n-categories [Ehr63] fol\u00adlowing roughly the lines of Street \n[Str87], as more ap\u00adpropriately expressing the dimensional aspect.  7 Extensions of Event Struc\u00adtures \nDespite the fact that event structures were introduced more than a decade ago [Win80], there have been \nno fur\u00adther generalizations of event structures where the dual\u00adity has been maintained. Yet there are \nmany phenomena of computation each describable with a suitable exten\u00adsion of this model, some of which \nwe give now. Thus far we have been able to make these extensions only on the algebra or automaton side \nof the duality, where the higher-dimensional cells are described explicitly. The role of the cells in \nmaking these extensions may once again be made inessential, albeit almost certainly still convenient, \nif a suitable extension of the duality can be found, a problem we return to later. Although event structures \nthemselves reside on the topology side of the duality, the completeness of the duality up to this point \npermits us to extend starting from either side. All extensions considered here will be to the algebra \nor automaton side, where the nature of the higher-dimensional cells, of dimension two and up, is clear. \nMutual Exclusion. The mutual exclusion of events and j is the condition that i and j not overlap. In \nST\u00adbisimulation terms it is the naturally expressed condi\u00adtion that in no state are transitions i and \nj both marked. The corresponding requirement for the geometric model is of course that no cell exist \nwhose i-th and j-th compo\u00adnents are both T (for the discrete or 3d model) or both in the open interval \n(O, 1) (for the Euclidean model). As defined here mutual exclusion is not persistent. We may have i#j \nand j < k without i#k since k may not need the resource that i and j are presumably competing for. After \ni and j are done, in whichever order, the two branches of the computation may rejoin, corresponding to \nthe rest of the computation not remembering the or\u00adder, A persistent version of the mutual exclusion \nof i and j can be defined using two copies of each of i and j, arranged as ij + ji, with each of the \ntwo events of ij in conflict with each of the two events of ji. Persistence of conflict means that the \ncommitment to one of ij or ji is permanent; two paths making this decision differently cannot subsequently \nrejoin. This brings us to the question, to persist or not to persist? One advantage of persistence is \nthat it permits our geometrical model to be dispensed with. However to the extent that geometry offers \nthe several benefits we claimed earlier, all of which are compromised more or less seriously by insisting \non persistence, this is at the same time a serious disadvantage of persistence. For example persistence \ndestroys the complexity ad\u00advantage of geometry. If the computation keeps splitting into alternatives \nwithout ever rejoining, its size grows exponentially. Rejoining permits a much smaller model of a given \ncomputation when there is much branching. (The dauntingly many alternative parallel universes of science \nfiction may similarly be dramatically reduced in number, say to around 10120 as a match for the number \nof particles in any one such universe.) It is also particularly distressing to see a local mutual exclusion \nrequirement, which we can represent with just a small hole, be blown up into a giant tear in the fabric \nof the computation simply due to the requirement of persistence. For these and similar reasons we prefer \nnot to insist on persistence, and to permit the expression of nonde\u00adterminism not only by absence of \nconfluence (the status quo) but also by the presence of holes even where con\u00adfluence is possible (our \nproposed extension to the status quo) . Communication. Consider a rectangle representing two processes \nX and Y running in parallel. A commu\u00adnication from X to Y consists of a transmission T by X and a receipt \nR by Y. These two events together determine a point in the rectangle, which we may think of as the communication. \nTaking this point as the ori\u00adgin, divide the rectangle into four quadrants. Think\u00ading for the moment \nin terms of computations being one-dimensional paths, a particular computation path passes through three \nof these, avoiding the quadrant in which the message would have been received be\u00adfore it was transmitted. \nThe middle quadrant the path passes through, diagonally opposite the excluded quad\u00adrant, represents the \nperiod during which the message is in transit. The effect of many communications is to erode the upper \nleft (early X and late Y) and lower right (late X and early Y) regions of the rectangle, creating two \njagged boundaries each representing the places where one process must wait for messages from the other. \nThe boundaries are suggestive of teeth, suggesting the whim\u00adsical term jaws of communication. We refer \nto the space between the jaws as the communication corridor. In the interior of the corridor there is \nno waiting for messages; computation may flow unimpeded. As the rate of exchange of messages increases \nthe cor\u00adridor narrows (the jaws close). If this corridor were a tube with liquid flowing through it, \nwe would expect such narrowing to impede the flow. In fact we see just such an effect, attributable to \nthe high cost of commu\u00adnication. But we need not think of a computation as a specific path through the \ncorridor, we can broaden it to reflect our ignorance of its exact position, just as we would do for the \ntrajectory of a car on a highway, the accuracy of which depends on the application. In the limit we may \nthink of the whole corridor as the computation. If it contains no holes or failures of confluence (i.e. \npersis\u00adtent conflicts) we regard it as a deterministic computa\u00adtion. Otherwise it is nondeterministic, \nwith the essence of the nondeterminism residing in homotopy classes (the equivalence classes of paths \ninduced by homotopy). The concern of branching time is then with the details of just where the homotopy \nclasses paste together, since pasted regions represent regions preceding (or follow\u00ading) where the classes \ndiverge (or converge). Synchro\u00adnization trees are the one-dimensional case of this where words are pasted \ntogether along a common initial seg\u00adment, a one-dimensional pasting. In general pasting can take place \nnot just along curves but across surfaces and through volumes etc. The pasting need not necessarily be \nthe maximal such, otherwise branching time would convey no information not already in linear time. At \na fork earlier decisions correspond to earlier suspension of pasting, and dually at a join. 8 Directed \nCell Complexes and n-Dimensional Automata Thus far the discussion of geometry has relied on an informal \nintuition about geometry which might be char\u00adacterized as pastings of fragments of Euclidean space oriented \nsomehow to represent the irreversibility of com\u00adputation. This intuition is formalized in the following \nnotion of higher dimensional automaton. A sequential automaton or transition system is a graph6 whose \nvertices denote states and whose edges de\u00adnote transitions. One vertex q. is distinguished as the start \nstate and a set F of vertices constitutes the final states. The edges are labeled with elements of a \nset Z. The linear-time meaning of this automaton is defined in terms of paths in the graph, each determining \nan ele\u00adment of Z*. The automaton accepts those elements of Z* that are determined by some path from q. \nto a state in F. Two such automata are linear-time-equivalent or trace-equivalent when they accept the \nsame subset of z . In geometric terms such an automaton is a one\u00addimensional cell complex whose one-dimensional \ncells or l-cells are its transitions and whose O-cells are its states. We would like a model whose definition \nreduces in the l-dimensional case to the above combinatorial notion of directed graph, and which captures \nthe geometric intu\u00aditions of the foregoing discussions. Algebraic topology offers a range of models to \nselect from, such as CW-complexes and simplicial complexes. But as far as we have been able to tell, \nall the extant notions of cell complex in algebraic topology assume re\u00adversible geometry too early in \ntheir development, and depend too heavily on structural properties of groups, to permit their easy adaptation \nto the irreversible case. We would be delighted to have a pointer to a counterexam\u00adple. The following \nnotion of higher dimensional automa\u00adton takes its inspiration not from algebraic topology but instead \nfrom the geometry of n-categories [Ehr63]. Ordinarily we define an automaton w an edge-labeled graph, \nand define its operation in terms of the paths in that graph and the operation of path concatenation. \nHowever we could just as well start with the paths and dispense with the underlying graph. When passing \nfrom discrete to continuous automata, whose every state tran\u00ad sition can be decomposed as a concatenation \nof shorter transitions, this is in fact necessary since they have no suitable underlying graph. For qualitatively \ndifferent reasons we shall similarly not start from the underlying graph when passing from one-dimensional \nto higher-dimensional automata. The problem is not that suitable underlying graphs cannot exist, as with \ncontinuous automata, but that a suitable notion of n-graph has proved elusive, and only halfway\u00ad decent \nnotions have emerged to date. The most success\u00ad ful of these would appear to be M. Johnmn ~ notion of \npasting diagram [Joh87]. However it seems to us that his definition presently requires both simplification \nand generalization in order to constitute a workable notion of n-graph. Hence as an interim measure we \ndefine an n-complex to be an n-category, with the eventual goal of redefining it so that it refers to \nthe underlying n-graph 6We allow multiple edges from one vertex to another. In some circles the term \nMultigraph is used to distinguish these from the kind where E ~ V2. when that notion is fully operational. \nProceeding top-down, we first define the notion of concurrent automaton in terms of that of complex, \npro\u00advide a motivational interlude, then define complex. An n-automaton A = (Q, Z, 6, S, T) consists of \nn\u00adcomplexes Q and X, an n-map 6 : Q -+ Z, and subsets S, T of (the underlying set of) Q. The m-language \nac\u00ad cepted by A is the subset of Z consisting of those 6(z) for z in Q such that Sin(z) c S and tin(x) \nc T where Sm, tm are the m-th boundary operators of Q. Before defining complexes let us touch ground \nmo\u00ad mentarily. Our 5-tuple definition parallels the tra\u00ad ditional definition of an automaton as (Q, \nE, 6, qo, F) [HU79], consisting of state set Q, symbol set E, tran\u00adsition function 6, start state q., \nand final state set F, along with the usual definition of accepted language. With the following adjustments \nthe traditional defini\u00adtion matches ours in the case n = 1, m = O. View the transitions defined by traditional \n&#38; as a pair (E, 6) where E is a set of unlabeled edges and 6 : E ~ X labels them. Rename Q to V for \nvertices, move E in with V to form a graph (V, E) and recycle Q as Q = (V, E). Now revamp E as a l-graph \nwith one vertex and with edge set old Z. Interpret 6 : Q e Z as the obvious graph map. Finally replace \n(Q, Z, 6) by (Q*, Z*, 6*) where Q* is the set of paths in Q, Z* is as always the free monoid on Z, and \n6* : Q* -+ Z* is the corresponding extension of 6 : Q -+ E from paths of length 1 to all paths. Take \nS = {qo} and T = F. This gives us the desired l-automaton (Q*, X , 6*, S, T). We then rename Q, D, 6 \none more time so as to dispense with the * s. This is the translation of a standard automaton into our \nframework. We now continue with our top-down definitions. Fol\u00adlowing Street [Str87], we define an n-complex \nin terms of l-complexes and 2-complexes. An n-complex, or small n-category, is a set bearing the structure \nof n l-complexes Co, . . . . Cn -1, such that for all i < j, (Cl, Cj) is a 2-complex. It remains to define \ni-complex for i ~ 2. In the follow\u00ading the s, t,* terminology is taken from Street [Str87]; we have taken \nsome liberties with the wording of his definition but not its content. Note that this definition of a \nl-complex is as a homogeneous category, namely one where the object-morphism distinction is not made; \nthe objects can be recovered as any of either the range or fixpoints of either s or t,or as the identities \nof *. Homogeneity simplifies the extension to n-categories. A l-complex C = (P,s, t, *) consists of a \nset P of (ab\u00adstract) paths, two boundary operations s, t:P~ P, and a binary operation * : P~ ~ P of path \nconcatena\u00adtion. The domain P~s P2 of x is the set of consecutive pairs (z, y) in P2, namely those for \nwhich tz = sy. Fur\u00adthermore the following conditions must be satisfied. (i) s(P) = t(P) ~~ Po, constituting \nthe O-ceils of C, while PI = P, the l-cells of C. (So P. ~ PI = P.) (ii) z ~ P. implies sz = z = tz. \n(Hence s and t are idempotent, and st = t = tt, ss = s= ts.) (iii) For all (z, y) c P~, S(Z * y) = s(z) \nand t(z*y)= t(y). (iv) (Identities.) z c P. implies for all (z, y) in P~, zxy=y, and forall(y, ~) in \nP~, yxx=y. (v) (Associativity.) For all (~, y) and (y, .z) in P~, z*(y*z)=(z*y) *z.  A %complez C = \n(P, so, to, *o, sl, tl, *l) is a pair (CO, Cl) of l-complexes CO = (P, so, to, *0), Cl = (P, s,, tl, \n*1) on a common set P such that (i) P. ~ PI where Pi = si(P), the set of i-cells. Pz = P (everything \nis a 2-cell). (Hence sltl = tl but sotl = so,and P. ~ P1QP2 = P.) (ii) (Interchange.) (wxlc)xo(yxlz) \n= (wxoy)xl(xxoz) when all terms are defined.  Referring to our definition of n-complex (co,..., C.-1) \nthen reveals it in more detail to be a structure C = (F , sO, iO, *o, . . .,sn_~, ~n_l, *n_l) every pair \n(C~, Cj ) of which for i < j is a 2-complex. Evi\u00addently Po~Pl~. ..~Pn=P. An n-map or n-functor of n-complexes \nC, C is a ho\u00admomorphism; equivalently, a function ~ : P -+ P be\u00adtween their underlying sets such that \nf : Ci ~ C: is a functor for O < i < n (i.e. on the l-complex at each dimension). It is intuitively clear \nthat associativity is the essential axiom of concatenation in one dimensional irreversible geometry. \nThe straightforward extension of this to two dimensions is that a matrix can be formed as a column of \nrows, and that vertical composition of columns is asso\u00adciative, and dually it can be formed as a row \nof columns, with horizontal composition of rows being associative. But there is more to it than that. \nThe same ma\u00adtrix can be assembled row by row or column by column, While this has the same flavor as associativity, \nit is not formal associativity in the sense that vertical compo\u00adsition of columns or horizontal composition \nof rows is associative. We therefore require a separate axiom from associativity. This is the function \nof the interchange law in irreversible geometry. An example of a 2-complex is a polygonal decomposi\u00adtion \nof a simply connected region of the Euclidean plane R2, The edges of the decomposition form a directed \nacyclic graph having a single source vertex and a single sink vertex, as hence do the edges of any of \nthe poly\u00adgons. This partitions every boundary of a polygon x into halves S1 ~ and t1z,start and terminal, \nboth lead\u00ading from a common source so% to a common sink toz. If two polygons share an edge then that \nedge must be\u00ad long to the start of one and the terminal of the other. It may be verified that any two \nsuch polygons z, y for which ti~ = Siy for z O or 1 together form a polygon meeting these conditions. \n(Under these conditions the two halves of the boundary of a polygon may touch re\u00adpeatedly, but if the \nwhole region is 2-connected no cut point they can never cross.) Hence the set of all sim\u00adply connected \npolygons that can be assembled from the elementary polygons of the decomposition constitutes a 2-complex \nunder the compositions z *O y and z *1 y. The interchange law is evidently sound in this model. What \nis less obvious is that it is complete in the sense that any two ways of assembling a polygon from elemen\u00adtary \npolygons (which will take the form of two terms in the language consisting of constants naming polygons \nand the two compositions) can be proved to give the same polygon using just the two associativity axioms \n(one for each composition) and the interchange axiom under the standard rules of equational logic. This \nwas claimed by Kelly and Street [KS74], and was more re\u00adcently extended by John Power to all n-complexes \n(to appear). The idea of the proof for n = 2 is that if w xl x and y xl z denote the same polygon x, \nwith source S = sox and sink T = tox, then each term partitions that polygon via a cut from S to T. If \nthese two cuts do not cross each other then they bound a region w n z or z n y with source S and sink \nT leaving two outside re\u00adgions of the polygon with that source and sink, and one then proves equality \nof those regions separately by in\u00adduction, completing with one application of associativity for xl. Otherwise \nseveral island regions are produced, and interchange can then be used to represent each of these regions \nas one region from S to T by extending it out to S and T with l-cells, and then concluding with applications \nof associativity of *I. This shows that n-complexes capture the essence of ordinary geometry of cells, \nt bough without its reversibil\u00adity, ruled out here by directing all edges and surfaces. (This is in contrast \nto orienting them, where a direction is specified but each edge has an inverse. ) As the ear\u00adlier sections \nargue informally, it is just such irreversible cellular geometry that is needed for a geometric model \nof concurrency. This completes the definition of higher dimensional automaton and the acceptance criterion \nmost closely corresponding to language acceptance, This induces a congruence on the class of such automata. \nWe leave the further study of this model and associated congruence and the pursuit of other acceptance \ncriteria and congru\u00adences to subsequent communications.  References [Bir35] G. Birkhoff. On the combination \nof subal\u00ad gebras. Proc. Cambridge Phil. Sot, 29:441 464, 1935, [BK89] J .A. Bergstra and J.W. Klop. \nProcess theory based on bisimulation semantics. [Bro88] [CCMP89] [CDP87] [Ehr63] [Gir87] [G1a90] [Gra81] \n[GV87] [HU79] [Joh87] [1{S74] [Lam86] In Proc. REX School/Workshop on Linear Time, Branching Time and \nPartial Order in Logics and Models for Concurrency, pages 50-122, Noordwijkerhout, The Netherlands, 1989. \nSpringer-Verlag. R. Brown. Topology: A geometric account of generai topology, homotopy types and the \nfundamental groupoid. Halsted Press, New York, 1988. R.T Casley, R.F. Crew, J. Meseguer, and V.R. Pratt. \nTemporal structures. In Proc. Conf. on Category Theory and Com\u00adputer Science, .LNCS, Manchester, Septem\u00adber \n1989. Springer-Verlag. Revised version to appear in Math. Structures in Comp. Sci., 1:1. L. Castellano, \nG. De Michelis, and L. Pomello. Concurrency vs interleaving: an instructive example. Bulletin of the \nEATCS, 31:12-15, February 1987. C. Ehresmann. Categories structures. Ann. Sci. Ecole Norm. Sup., 80:349-425, \n1963.  .Jean-Yves Girard. Linear logic. Theoretical Computer Science, 50:1-102, 1987. R.J. van Glabbeek. \nComparative concur\u00adrency semantics and refinement of actions. PhD thesis, Vrije Univ., Amsterdam, 1990. \n J. Grabowski. On partial languages. Funda\u00admental Informaticae, lV.2:427 498, 1981. R.J. van Glabbeek \nand F.W. Vaandrager. Petri net models for algebraic theories of concurrency. In Proc. PARLE, II, LNCS \n259, pages 224-242. Springer-Verlag, 1987.  J.E. Hopcroft and J.D. Unman. Introduc\u00adtion to Automata \nTheory, Languages, and Computation. Addison-Wesley, 1979. M. Johnson. Pasting Diagrams in n-  Categories \nwith Applications to Coherence Theorems and Categories of Paths. Pm thesis, Dept. of Pure Mathematics, \nSydney University, October 1987. G.M. Kelly and R. Street. Review of the elements of 2-categories, In \nLNM 420. Springer-Verlag, 1974. L. Lamport. On interprocess communi\u00adcation. Distributed Computing, 1:77-101, \n1986.  [Mi180] [NPW81] [Pap86] [Par81] [Pra82] [Pra86] [Pri70] [Rot73] [Sto36] [sto37] [Str87] [vGG89] \n[Whi49] [Whi78] [Win80] R. Milner. Calculus of Communicating Be\u00adhavior, LNCS 92. Springer-Verlag, 1980. \nM. Nielsen, G. Plotkin, and G. Winskel. Petri nets, event structures, and domains, part I. Theoretical \nComputer Science, 13, 1981. C. Papadimitriou. The Theory of Database Control. Computer Science Press, \n1986. D. Park. Concurrency and automata on in\u00adfinite sequences. In Proc. Theoretical Com\u00adputer Science, \nLNCS 104, pages 167-183. Springer-Verlag, 1981. V.R. Pratt. On the composition of pro\u00adcesses. In Proceedings \nof the Ninth Annual ACM Symposium on Principles of Program\u00adming Languages, January 1982. V.R. Pratt. \nModeling concurrency with par\u00adtiaI orders. International Journal of Parallel Programming, 15(1):33-71, \nFebruary 1986.  H.A. Priestley. Representation of distribu\u00adtive lattices. Bull. London Math. Sot., 2:186-190, \n1970. G.-C. Rota. The valuation ring of a dis\u00adtributive lattice. In Proc. Univ. of Houston Lattice Theory \nConf. Dept. of Math., Univ. of Houston, 1973. M. Stone. The theory of representations for Boolean algebras. \nTrans. Amer. Math. Sot., 40:37-111, 1936. M. Stone. Topological representations of distributive lattices \nand brouwerian logics. ~asopis Pt%t. Math., 67:1-25, 1937. R. Street. The algebra of oriented sim\u00adplexes. \nJournal of Pure and Applied Algebra, 49:283-335, 1987. R. van Glabbeek and U. Goltz. Partial order semantics \nfor refinement of actions neither necessary nor always sufficient but appro\u00adpriate when used with care. \nBulletin of the EAT(X , 38:154 163, June 1989. J .H.C Whitehead. Combinatorial homotopy I. Bull. Amer. \nMath. Sot., 55:213-245,1949.  G.W Whitehead. Elements of Homotopy Theory. Springer-Verlag, 1978. G. \nWinskel. Events in Computation. PhD thesis, Dept. of Computer Science, Univer\u00adsity of Edinburgh, 1980. \n   \n\t\t\t", "proc_id": "99583", "abstract": "", "authors": [{"name": "Vaughn Pratt", "author_profile_id": "81332522064", "affiliation": "Computer Science Department, Stanford University, Stanford, CA", "person_id": "PP31093066", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/99583.99625", "year": "1991", "article_id": "99625", "conference": "POPL", "title": "Modeling concurrency with geometry", "url": "http://dl.acm.org/citation.cfm?id=99625"}