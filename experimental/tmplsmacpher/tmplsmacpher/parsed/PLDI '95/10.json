{"article_publication_date": "06-01-1995", "fulltext": "\n A Type-Based Compiler for Standard ML Zhong Shao* Andrew W. Appelt Yale University Princeton University \nAbstract Compile-time type information should be valuable in ef\u00adficient compilation of statically typed \nfunctional languages such as Standard ML. But how should type-directed compi\u00adlation work in real compilers, \nand how much performance gain will type-based optimization yield? In order to sup\u00adport more efficient \ndata representations and gain more ex\u00adperience about type-directed compilation, we have imple\u00admented \na new type-based middle end and back end for the Standard ML of New Jersey compiler. We describe the \nbasic design of the new compiler, Identify a number of practical issues, and then compare the performance \nof our new compiler with the old non-type-based compiler. Our measurement shows that a combination of \nseveral simple type-based optimlzations reduces heap allocation by 36%: and improves the already-efficient \ncode generated by the old non-type-based compiler by about 1!)70 on a DECsta\u00adtion 5000. 1 Introduction \nCompilers for languages with run-time type checking, such as Lisp and Srnalltalk, must often use compilation \nstrategies that are oblivious to the actual types of program variables, simply because no type information \n1s available at compile time. For statically typed languages such as Standard ML (SML) [19], there is \nsufficient type information at compile time to guarantee that primltlve operators WI1l never be ap\u00adplied \nto values of the wrong type. But, because of SML s parametric polymorphism, there are still contexts \nin which *Address Department of Computer Science, Yale Umvers]ty, 51 Prospect Street, New Haven, CT 06520-8285 \nEmad address shao-zhongtlcs. yale eclu tAd&#38;~~~ Department of Computer Science, Princeton Unlver\u00adslty, \n35 Olden Street, Prtnceton, NJ 08544-2087 Email address aPPel@cs .prlncetOn. edu Permission to copy without \nfee all or patt of this material is granted provided that the copies are not made or distributed for \ndirect commercial advantage, the ACM copyright notice and the title of the publication and its date appear, \nand notice is given that copying is by permission of the Association of Computing Machinery.To copy otherwise, \nor to republish, requires a fee and/or specific permission. SIGPLAN 95La JoHa, CA USA 0 1995 ACM 0-89791 \n-697 -2/95/0006 ...$3.50 the types of (polymorphic) variables are unknown. The pro\u00adgram can still manipulate \nthese values without inspecting their internal representation, as long as the size of every variable \nis known. The usual solution is to discard all the static type information and adopt the approach used \nfor dy\u00adnamically typed languages (e.g., Lisp), that is, to represent all program variables using standard \nboxed representations, This means that every variable, function closure, and func\u00adtion parameter, is \nrepresented in exactly one word. If the natural representation of a value (such as a floating-point number) \ndoes not fit mto one word, the value is boxed (i.e., allocated on the heap) and the pointer to this boxed \nobject is used instead. This is inefficient. Leroy [15] has recently presented a representation anal\u00adysis \ntechnique that does not always require variables be boxed in one word. In his scheme, data objects whose \ntypes are not polymorphic can be represented in multiple words or in machine registers; only those variables \nthat have polymorphic types must use boxed representations. When polymorphic functions are applied to \nmonomorphic values, the compiler automatically inserts appropriate coercions (if necessary) to convert \npolymorphic functions from one rep\u00ad resentation to another. For example, m the following ML code: fun \nquad (f, x) = (f(f(f (f(x))))) funhx=x*x*0.50 +x* 0.87 +1.3 val res = h(3. 14) + h(3.84) + quad(h, 1.05) \nhere quad is a polymorphic function with type da!, (((a + a) * cl) + a); all of the four calls to j inside \nquad must use the standard calling convention passing x in a general-purpose regis\u00adter. On the other \nhand, h 1s a monomorphic function with type real + real, so every monomorphic application of h (such \nas h(3. 14) and h(3,84)) can use a more efficient calling convention passing x in a floating-point register. \nWhen h is passed to the polymorphic function quad (e.g., in quad(h, 1.05)), h must be wrapped to use \nthe standard calling convention so that ~ wdl be called correctly lnslde quad. Suppose fwrap and funwrap \nare the primitive op\u00aderations to box and unbox floating point numbers, then the compiler will wrap h \ninto h : h = (Ay.fwrap(h(funwrap( y)))); the actual function application quad(h, 1.05) is imple\u00admented \nas funwrap(quad(h , f wrap(l .05))). Representation analysis enables many interesting type\u00adbased compiler \noptimization. But since no existing com\u00adpiler has fully implemented representation analysis for the complete \nSML language, many practical implementation issues are still unclear. For example, while Leroy [15] has \nshown in detail how to insert coercions for core-ML, he does not address the issues in the ML module \nsys\u00adtem [19, 17], that is, how to insert coercions for functor application and signature matching. Propagating \ntype in\u00adformation into the middle end and back end of the compiler can also incur large compilation overhead \nif it is not done carefully, because all the intermediate olptimizations must preserve type consistency. \nThe major contributions of our work are: Our new compiler is the first type-based compiler for the entire \nStandard ML language. We extend Leroy s representation analysis to the SML module language to support \nmodule-level abstractions and functor applications. We improve compilation speed and code size by using \npartial types at module boundaries, by statically hash\u00adconsing lambda types, and by memorizing coercions. \nWe evaluate the utility of minimum ~ping deri} a\u00adtions [7] a method for eliminating unnecessary wrapper \nfunctions introduced by representation anal\u00adysis. We show how the type annotations can be simplified \nin successive phases of the compiler, and how repre\u00adsentation analysis can interact with the Continuation-Passing \nStyle [24, 3] used by the SML/NJ compiler s optimizer [5, 3]. We compare representation analysis with \nthe crude (but effective) known-function parameter specializa\u00adtion implemented by Kranz [14]. Our measurements \nshow that a combination of sev\u00aderal type-based optimization reduces heap allocation by 36%, and improves \nthe already-efficient code gen\u00aderated by the old non-type-based compiler by about 19Y0. We have previously \nreported a 14% speedup using new closure representations for accessing vari\u00adables [23]; the two optimization \ntogether yield a 28 70 speedup.  2 Data Representations One important benefit of type-directed compilation \nis to al\u00adlow data objects with specialized types to use more efficient data representations. In this \nsection, we explain in detail what the standard boxed representations are, and what other more efficient \nalternatives one can use in type-based com\u00adpilers. Non-type-based compilers for polymorphic languages, \nsuch as the old SML/NJ compiler [5], must use the standard boxed representations for all data objects. \nPrimitive types such as integers and reals are always tagged or boxed; every argument and result of a \nfunction, and every field of a clo\u00adsure or a record, must be either a tagged integer or a pointer to \nother objects that use the standard boxed representations. For example, in Figure 1a, the value z is \na four-element record containing both real numbers and strings; each field of z must be boxed separately \nbefore being put into the top-level record. Similarly, y is a record containing only real numbers, but \neach field still has to be separately boxed under standard boxed representations. We would like to use \nmore efficient data representations, so that values such as z and y can be represented more efficiently, \nas shown in Figure 1b. But the intermixing of pointers and non-pointers (inside x) requires a complicated \nobject-descriptor for the garbage collector, so we will re\u00adorder the fields to put all unboxed fields \nahead of boxed fields (see Figure 1c); the descriptor for this kind of object is just two short integers: \none indicating the length of the unboxed part, another indicating the length of the boxed part. For recursive \ndata types such as list z in Figure 2, the standard boxed representation will box each element of z, \nas shown in Figure 2a. More efficient data representations are also possible: if we know z has type (real \n* real) list, z can be represented more compactly as shown in Figure 2b or Figure 2c. The major problem \nwith these representations is that when z is passed to a polymorphic function such as Unzip: fun unzip \n1 = let fun h((a, b)::r, u,w) = h(r, a::u, b::w) I h([], u,u) = (rev u, rev w) in h(l, [l, [l) end  \nthe list z needs to be coerced from the more efficient rep\u00adresentations (shown in Figure 2b and 2c) into \nthe standard boxed representation (shown in Figure 1a). This coercion can be very expensive because its \ncost is proportional to the length of the list. There are two solutions to solve this problem: . One \napproach proposed by Leroy [ 15] is to use standard boxed representations for all recursive data\u00adtype \nobjects. In other words, even though we know And this cost M not necessarily amofi]zed, if the function \ntakes time subhnear m the length of the hst. val x = (4.51, hello , 3.14, world ) val y = (%51, 3.14, \n2.87) x x 4.51 3.14 4.51 3.14 hello world hello world 7?Z m Y Y 4.51 3.14 2,87 Y 7 4,51 3.14 2.87 \n4.51 2.87 (c) flat rep with reordering fields 3.14 (b) flat unboxed representations% (a) standard boxed \nrepresentations Figure 1: Standard boxed representations vs. Flat unboxed representations val z = [(4.51, \n3.14), (4.51, 2.33), .... (7.81, 3.45)] (a)I o   z +\\l I I 2,33 7.81 3,45 z (b) z I ,,1\\ 4,,1oI \ni bmzl (c) ~  451 3.14 4,51 2.33 7.81 3.45 0 Figure ~: Recursive data type: (a) standard boxed representations \n(b-c) flat unboxed representations Standard l.m Source Program lcxIcal analyslsandsyntact]canalysls \n ---------------r=+==m Raw AbStI_aCt Syntax elabolat]ouof themoduleandco]e language type reference and \ntype checking m]tumum typing derivations --------------Eb&#38;l Abstract SWts% (AbSYn) . . . . . . . \n. ~ semantic ObjeCtS ~d ~es msertmg coerc]ons for representation malysls i translating AbsynmtoLEXPw!thLTY \n...............  Lsntbda Translator mhnmg pnmmve operations compdzmonof patternmatches + I Wped Lsmbda \nLan@.mge (LEXP)---------------- EW~Pes Lw representimonsfor records and concrete datatypes conveltmg \nLEXP mto CPSwith CTY  ---------------E*I argument-passing conventions for function calls I Continuation-Passing \nStyle (CPS)---------------CPS Types (CTY) contractions eta-reductmns. beta-reductions __.___. __... \n__~*l ,,// ::;: cla.wc dataflow opt]m?zatjons uncurrying. inhne expansions. Ioop-unrolhng , Continuation-Passing \nStyle (CPS)------ ,, 4 closure strategies and representations closure Converter ----E + Closure-Passing \nstyle (cLO)-------- register spdhng and allocation . . . . . . . . ..-~.l machme code scheduling and \ngeneration t I Target Binary Mschine Code Figure 3: Overview of the new type-based SML/NJ compiler z \nhas type (real * real) list, we still represent z as 3 Front-End Issues shown in Figure 2a, with each \ncar cell pointing to an object that uses standard boxed representation. For The Standard ML of New Jersey \ncompiler is composed example, if pairs such as (4. 51,3. 14) are normally of several phases, as shown \nin Figure 3. The Elabora\u00adrepresented as flat real vectors, when they are being tor/Type-checker produces \ntyped abstract syntax (Absyn), added to (or fetched from) a list, they must be coerced which is almost \nunchanged from previous versions of the from flat representations to (or from) standard boxed compiler \n[5], except that we annotate each occurrence of a representations. The type-based compiler described \nin polymorphic variable or data constructor with its type in\u00adthis paper also uses this approach. The \nLEXP language stantiation at each use, inferred by the type checker. The described later in Section 4.1 \nhas a special lambda type front end must also remember the details of each module\u00adcalled RBOXEDty to \nexpress this requirement. level (structure or functor) abstraction and instantiation in order to do module-level \ntype-based analysis. For example, in the following core-ML program, Another approach proposed by 13.arper \nand Mor\u00adrisett [ 12] would allow recursive data types to use fun square (x :real) =x*x more efficient \nrepresentations as shown in Figure 2b fun sumsquare (1 : real list) = and 2c, In their scheme, types \nare passed as argu\u00adlet funh ([], s : real) = s ments to polymorphic routines in order to determine I \nh (a::r, s) = h(r, a+s)the representation of an object. For example, when in h(map square 1, 0.0) z is \npassed to unzip, a type descriptor is also passed end to indicate how to extract each car field. Because \nthe descriptor has to be interpreted at runtime at each the standard hbrary function map (on lists) has \npolymorphic function call, it is not clear how efficient this approach type would be in practice (see \nSection 7). VaV,d.(o + ,6) -(a /ist + ~ list);  structure S = signature SIG functor F(A : SIG) = struct \ntype t = real sig type t struct val r = A.f(A.p) val p=3.0 val p :t end fun fx=(x, p) val f : t->(t *t) \nval q = 4.0 end structure W = F(S) end (a) structure (b) signature (c) functor and functor application \nFigure4: Front endlssues m the module language structure declaration signature matching abstraction declaration \nML code structure S = . . structure U : SIG = S abstraction V : SIG = S f s type S.f: da. O+(a* real) \nU.f: real +(real *real) V.f: t-+(t*t) p s type S.p: real Up: real V.p: t Figure5: Signature matching \nis transparent butabstraction rnatchingis opaque the Elctboratorflype-checker will annotate map with \nthis polymorphic type, plus its Instantiation (real + real) + (real list + real list). Similarly, the \npolymorphic data constructor, :: , is also annotated with its original polymorphic type do. (a * o list) \n+ a list, plus its instantiation (real *real list) --+ real list. To correctly support type-directed \ncompilation for the entree SML language, all type abstractions and type in\u00adstantiation in the module \nsystem must also be carefully recorded. In ML, basic modules (structures in Figure 4a) are encapsulated \nenvironments; module interfaces (signa\u00adtures in Figure 4b) associate specifications with component names, \nand are used to both describe and constrain struc\u00adtures. Parameterized modules (functors in Figure 4c) \nare functions from structures to structures. A functor s argu\u00adment is specified by a signature and the \nresult is given by a structure expression, which may optionally be constrained by a result signature. \nAbstraction and instantiation may occur in signature matching (Figure 5), abstraction declaration (Figure \n5), functor application (see Figure 4c), and functor signature matching (used by higher-order modules \n[25, 17]). We use the example in Figure 4 and 5 to show what must be recorded in the Absyn during elaboration: \no Signature matching checks that a structure fulfills the constraints specified by a signature, and creates \na new instantiation structw-e that is arestrlcted view of the original structure. The elaboration phase \ngenerates a dzinningf unction that specifies all the visible compo\u00adnents, their types (or thinning functions \nif they are substructures) in the original structure, and their new types in the instantiation structure, \nIn Figure 5, U is bound to the result of matching structure S against signature SIG. Signature matching \nin ML is transpar\u00adent [18, 16, 11], so f andpinthe instantiation structure Uhave type real +(real* real) \nand real. The new types andtheirold typesin structures (also shown in Figure5) will rerecorded inthe \nthinning function. Abstraction is similar to signature matching; but matching for abstraction is opaque \n[18, 16, 11]. In addition to the thinning function, the elaboration phase also remembers the result signature. \nIn Figure 5, V is an abstraction of structure S on signature SIG. V re\u00admembers the thinning function \ngenerated when doing signature matching of S against SIG, plus the actual signature SIG. During the elaboration \nof this abstrac\u00adtion, the typeof f in S da.a+(a *real) is first instantiated into real + (real *real) \nin signature matching, and then abstracted into t4(t*t). Each functor application must remember its argument \nthinning function and its actual instantiation functor. In Figure 4c, functor F takes SIG as its argument \nsig\u00adnature, and returns a body structure that contains a value declaration ~; the type of r is A.t*A. \nt. When F is apphed to structure S, S ls first matched against the argument signature SIGto get the actual \nargument instance, say S ; the elaborator then reconstructs the result structure W by applying F to S \n. The com\u00adponent in il has type (real *real). The front end records: (1) thethinmngf unctiongenerated \nwhen Sis matched against SIG, (2) the actual instantiation ofF, which has S as its zu-gument and TV as \nits result. Functor signatures are essentially types of functors. Given afunctor signature FSIG defined \nas funsig FSIG (X: ASIG) = RSIG, and a functor F, elaborating functor signature match\u00ading functor G \n: FSIG = F is equivalent to elaborate the functor declaration functor G(X: ASIG) : RSIG = F(X). Therefore, \nfor each functor signature matching, the elaborator records everything occurring in functor ap\u00adplication \nF(X) plus the thinning function generated for matching F(X) against the result signature RSIG. Minimum \ntyping derivation Similar to the Damas-Milner type assignment algorithm W [10], the old ElaboratorYT~pe-checker \nin our compiler infers the most general type schemes for all SML programs. As a result, local variables \nare always assigned the most general polymorphic types even though they are not used polymorphically. \nFor example, fun f(u,v) = let fun g(x, y, z) = ((x=y) andalso (Y=Z)) in g(u*2.0, V*3.0, U+v) end function \njhas type real * real --+ bool, the let-bound function gisassigned a polymorphic type: Va.(Q*Q*a)4 bool \nwhere Q is an equality type variable. Elut g is only used monomorphically with type (real * real * real)+ \nbool, To avoid coercion between polymorphic and mono morphic objects, we have implemented a minimum typ\u00ading \nderivation phase in our new Elaborator~jpe-checker to give all local variables least polymorphic types. \nThe derivation is done after the elaboration so that it is only applied to type-correct programs. Our \nalgorithm, which is similar to Bj@ner s algorithm M [7], does a bottom-up traversal of the Absyn. During \nthe traversal, we mark all non-exported variables: let-bound variables and those that are hidden by signature \nmatching. Then, for each marked polymorphic variable v, we gather all of its actual type in\u00adstantiations, \nsay TI. . . . . Tn, and ItaSSlgII ?J a new type the least general type scheme that generalizes ~]. . \n. rn. The new type assigned to o is propagated into t) s declaration d, constraining other variables \nreferenced by d. In the previous example, the let-bound function g is con\u00adstrained by a new type assignment \n(real * real * real) --+ bool, so the == operator can be implemented as the primitive equality function \non real numbers, which is much more ef\u00adficient than the polymorphic equality operator. Moreover, because \ng is no longer polymorphic, no coercion is neces\u00adsary when applied to monomorphic values. 4 Translation \ninto LEXP The middle end of our compiler translates the Absyn into a simple typed lambda language called \nLEXP. During the translation, all the static semantic objects in Absyn, includ\u00ading types, signatures, \nstructures, and functors, are translated into simple lambda types (LTY); coercions are inserted at each \nabstraction and instantiation site (marked by the front end) to correctly support representation analysis. \nIn this section, we explain the details of our translation algorithm, and present solutions to several \npractical implementation problems. 4.1 The typed lambda language LEXP The typed call-by-value lambda \nlanguage LEXP is very similar to the untyped lambda languages[3, sec. 4,7] used in previous versions \nof the compiler: it contains lambda, application, constants, tuple and selection operators (i.e., RECORD \nand SELECT), and so on. But now it is a typed language[22], with types LTY described by this simple set \nof constructors: datatype lty = INTty I REALt y I RECORDty of lty list I ARROWty of lty * lty I BOXEDt \ny I RBOXEDty  A lambda type LTY can be a primitive numeric type (INTty or REALty); a record type RE03Rllty[tl, \ntz, . ..1 whose fields have type t1,t2,.... a function type ARROWty(t, s) from t to s; or a boxed pointer \ntype. There are two kinds of boxed types. BOXEDty is a one\u00adword pointer to an object (such as a record) \nwhose fields may or may not be boxed. RBOXEDty is a one-word pointer to a recursively boxed object whose \ncomponents are always recursively boxed; such objects use the standard boxed rep\u00adresentations that are \noften used in a non-type-based ML compiler. Section 4.3 discusses how and where recursive boxing is necessary. \nOur typed lambda language is a simply typed lambda cal\u00adculus. Every function formal parameter is annotated \nby an LTY. Prim-ops and the exception-RAISE operator are also type-annotated. Types of other expressions \n(function appli\u00adcation, record construction and selection) can be calculated bottom-up from the types \nof the subexpressions. To han\u00addle polymorphism, we introduce two new LEXP operators: WRAP(t. e) that \nboxes an evaluated expression e of type t into exactly one word; and UNWRAP(t, e) that unboxes an expression \ne into type t. In ML, a let-bound variable can be polymorphic: but each use is treated as an instance \nof the type scheme. We treat this as a coercion, and we define a compilation func\u00adtion coerce that produces \nthe right combination of WRAP and UNWRAP operators. our coerce is similar to Leroy s w rap and unwrap \n[15]; but ours does not require that one type be an instantiation of the other. This generalization is \nuse\u00adful in translating the ML module language into the LEXP language. 4.2 The Definition of Coerce Coerce \nis a compile-time operation; given two LTYs t] and t2,coerce (t], t2) returns a coercion function that \ncoerces one lexp with type t 1 into another lexp with type tz. o If tl and tJ are equivalent, no coercion \nis necessary, coerce (t 1, t?) returns the identity function. e If one of t] and t2 is BOXEDty, this \nrequires coerc\u00ading an arbitrary unboxed object into a pointer (or vice versa); the coercion here is a \nprimitive WRAP or UNWRAP operation, written as coerce (BOXEDty. tJ = Ae.uNwRAUtze)and coerce (tl, BOXEDty) \n= Ae.WRAP(tl, e). . If one of t]and tzisRBOxEDty,thisWulres coerc\u00ading an arbitrary unboxed object into \na pointer (or vice versa); moreover, the object Itself must be coerced Into the standard boxed representation \n(or vice versa); this coercion is similar to the recursive >vrapping opera\u00adtions defined by Leroy [15]. \nIt is defined as coerce (RBOXEDty. td = coem(dup(t~),td and coerce(tl, RBOXEDt y) = coerce(tl, dup(t] \n)), where the dup operation is defined as follows: dup(RECORDty[~l , ., xn]) = RECORDty[RBOXEDty, .... \nRBOXEDty] dup(ARROWty(z] , ZJ)) = ARROWty(RBOXEDty. RBOXEDty) dup(z) = BOXEDty. for all other LTY z o \nIf t]and t2 are record type, i.e., tl = RECORDty[al, . . . . a~] and t2= RECORDty[rl , . . . . m], we \nfirst build a hst of coercions [c], . . . . c~l for every record field where c, = coerce (a,, T-,) for \ni = 1, . . . . n. Assume v is a new lambda variable that corresponds to the original record, then the \nfield of the new record is f, = c,(SELECT(L. v)); the coercion of expression e from tl to t2 is (Av : \nBOXEDty. RECORD[jl. . . . . ~n])e. o If t] and t2are function type, i.e., t] = ARROWty(al, rl) and \nt2 = ARROWty(a~ . 7 2), 122 we first build the coercions Ca and Cr for the argu\u00adment and the result, \nthat is, Ca = coerce (a2, al) and CT = coerce (r]. rz); then assume u and v me two new lambda variables, \nthe coercion of expression E from tlto t2 is Au : az.(~v : BOXEDty. Cb(tI))(E(Ca(IL))).  4.3 Translating \nstatic semantic objects into LTY The Absyn is translated into the lambda language LEXP through a simple \ntop-down traversal of the Absyn tree. Dur\u00ading the traversal, all static semantic objects and types used \nin Absyn are translated into LTYs. A signature or structure object s is translated into RECORDty where \neach field is the LTY translated from the corresponding component in s; a functor object 1s translated \ninto ARROWty with the argument signature being the argument LTY, and the body structure being the result \nLTY. The translation of an ML type t into LTY is done using the algorithm described in Figure 6 (see \nfunction ty21ty for the pseudo code). fun ty21ty(t) = (mark all type variables in t that ever appear \nin a constructor type; return lty(t)) fun lty(Va.a) = lty(a) I lty({ll :Tl, . . . . in :Tn}) = RECORDty \n[lty(~l) , , lty(~n)] I lty( m + r?) = ARROWty(lty(~]) ,lty(~z)) \\ lty(int) = INTty I lty(bool) = INTty \nI lty (unit) = INTty I Ity(real) = REALty I lty(a) = if CI is a marked type vartable then RBOXEDty else \nBOXEDty I lty (t)= if the constructor type t IS r]gld then BOXEDty else RBOXEDty Figure 6: Translating \nML type into LTY (pseudo code) More specifically, given a type t, the translation algo\u00adrithm ty21ty divides \nthe type variables in tinto two cate\u00adgories: e Those that ever appear in constructor types, z such as \n&#38; in type (a*Q list) + a list, and ~ in type (D ref *D) + unit; they are translated into RBOXEDty \n(the need for this 1s explained in Section 2); e All other type variables, such as v in v * ~ + ~; they \nare translated into BOXEDty; Record type constructors and function type constructors ( ~ ) are not counted \nhere A polymorphic type Val.. .b an.T is translated by ignor\u00ading all quantifications. The arrow type \nconstructor + for functions is translated into ARROWty; the record type con\u00adstructor is translated into \nRECORDty, with its fields ordered properly. All rigid constructor types,~ such as string, CYlist, and \n(real * real) ref, are translated into BOXEDt y. All flexible constructor types are translated into RBOXEDty. \nType abstraction One main challenge in doing module-level representation anal ysis is to deal with flexible \nconstructor type (also called type abstraction). For example, in the following ML pro\u00adgram, signature \nSIG = sig type a t val p :real t val f : at->>at end functor F(S : SIG) = struct datatype a foo = FOO \nof a S.t val r = S.f(S. p) fun g (FOOx) = [x] end t is a flexible type constructor (with arity 1) that \nwill not be instantiated until functor F is applied. Simple repre\u00adsentation analysis [15] would run into \ntwo problems when compiling F s body: At the function application S.f(S.p), since S.f is poly\u00admorphic \nand S.p is monomorphic, a coercion must be inserted here; but the detail of this coercion is not known \nbecause it depends on the actual instan\u00adtiation of t. For example, if a t is instantiated into a * a \nwhen F is applied, S. f has to be un\u00adwrapped from type ( ) a * a) ->, ( a * a) into type (real * real) \n-> (real * real). . Function g puts the variable z of type ) a t into a list. This requires recursive \nwrapping (see Section 2). But because t is unknown, this recursive coercion is also unknown. We solve \nthese two problems by forcing all objects with flexible type to use the standard boxed representations \n(i.e., as RBOXEDty) and by properly coercing all structure com\u00adponents (including values, functions, \nand data constructor injections and projections) from the abstract types into their actual instantiation \n(during functor application). In the previous example, the body of functor F references several identifiers \ndefined in the argument signature SIG. Following the SML Definition and Commentary [ 19, 18], all type \nconstructor names defined as type speciticatlons in signatures are fk~}b/e; all other type constructor \nnames are ngtd Because S.t is flexible (i.e., abstract) inside F, the identifier S.p has LTY &#38;= \nRBOXEDty and the identifier S.f has LTY ltf= ARROWt y (RBOXEDt y , BOXEDt y) . Because .$.fand S.p are \nalready recursively boxed, no co\u00adercion is necessary when S.f is applied to S,p. Similarly, the projection \nof data constructor FOO used in the body of F has type a foo > a St; its corre\u00adsponding LTY is /tc= ARROWt \ny (BOXEDt y , RBOXEDt y) , that is, the value carried by FOO (i.e., the argument of function g) is already \nrecursively boxed, therefore, no recursive coercion is needed when putting z into a list. When F is applied \nto the following structure A, structure A = struct type a t = Ja * ~a val p = (3.0,3.0) fun fx=x end \nstructure T = F(A) first, the argument structure is matched against the sig\u00ad nature SIG via abstraction \nmatching, producing a structure A that precisely matches SIG; the components p and f are coerced to LTY \nltP and ltfin A . Then, F is applied to this abstract structure A , produce another abstract structure \nthe functor body T . Finally, T is coerced back to the more concrete structure T; for example, T . r \nwhich has LTY RBOXEDty is coerced into a record (T.r) that has LTY RECORDty [REALty, REALty] , the projection \nof data constructor Tf. FOO which has LTY ltc is coerced into a projection (for T.FOO) that has LTY ARROWty(BOXEDty \n,RECORDty [BOXEDty , BOXEDty] ) . Here, coercions ofprojections and injections for data con\u00adstructors \ncan be implemented by recording the origin type lt. with T.FOO or by using abstract value constructors \npro\u00adposed by Aitken and Reppy [1]. 4.4 Translating Absyninto LEXP Now that we have explalned how to \ntranslate static seman\u00adtic objects into LTY and how to coerce from one LTY to another, the translation \nof Absyn into LEXP is straightfor\u00adward. Coercions (built from WRAP and UNWRAP) preinserted at each use \nof a polymorphic variable, and at module-level signature matching. polymorphic variables: Given a polymorphic \nvariable w in Absyn, the front end has annotated every use of ~~ with itspolymorphic type aplus its actual \ninstantiation T. Assume that o and ~ are translated into LTYs s and t,variable v is then translated into \nthe LEXP expression coerce (s, t)(v). polymorphic data constructors: Polymorphic data con\u00adstructors \nare treated like polymorphic variables; co\u00adercions are applied to data constructor injections and projections. \nprimitive operators: Polymorphic prim-ops whose imple\u00admentations are known at compile time can be spe\u00adcialized \nbased on their actual type instantiation. For example, polymorphic equality, if used monomorphi\u00adcally, \ncan be translated into primitive equality; integer assignments and updates can use unboxed update.~ signature \nmatching: Suppose structure S is matched against signature SIG, and U is the result instantia\u00adtion structure; \nthen the thinning function generated by the front end is translated into a coercion c, which fetches \nevery component from S, and coerces it to the type specified in U. If S is denoted by u, then the translation \nof this signature matching is simply c(v). abstraction: Abstraction is translated in the same way as \nsignature matching, except that the result c(v) must also be coerced into the LTY for the signature SIG. \nAssume that the LTYs for U and SIG are respectively u and s, then the abstraction of structure S under \nSIG is (coerce (u, s))(c(v)). functor application: Suppose the argument signature of functor F is SIG \nand F is applied to structure S. The front end has recorded the thinning function for match\u00ading S against \nSIG and the actual functor instance F) for F. As before, assume the result of matching S against SIG \nis c(v), and F is denoted by the LEXP expression j, and the LTYs for F and F are respec\u00adtively s and \nt, then the LEXP expression for F is f = (coerce (s, t))(f), and functor application F(S) is translated \ninto APP(f , c(v)).  4.5 Other practical issues Because of large LTYs and excessive coercion code, a \nnaive implementation of the translation algorithm can lead to large LEXP expressions and extremely slow \ncompilation. TINs problem is severe for programs that contain many functor applications and large structure \nand signature expressions. Since coerce (s. t) is an identity function in the common case that s = t, \nwe can improve the performance of the compiler by optimizing the implementation of coerce with 41n order \nto support generat]orml garbage collection [26], most com\u00adpilers must do some bookkeeping at each update \nso that the pointers from older generation to youngest generaoon are correctly ldenafied. U/lbared updare \nIS a special operator that assigns a non-pointer value mto a refer\u00adence cell, such updates cannot cause \nolder generations to point to newer ones, so no bookkeeping IS necessary an extra test: coerce (s, t) \n= ifs=t then Aj. j else structural induction But how can s = t be tested efficiently? We use global \nstatic hash-consing to optimize the representation for lambda types; hash-consed structures can be tested \nfor equality in constant time, and hash-consing reduces space usage for shared data structures. This \noptimization was crucial for the efficient compila\u00adtion of functor applications: without hash-consing, \na one\u00adline functor application (whose parameter is a reference to a complicated, separately defined signature) \ncould take tens of minutes and tens of extra megabytes to compile; with hash-consing, functor apphcation \nis practically tmmediate. Also, general space usage of the compiler 1s less with hash\u00adconsing, as the \nstatic representations of different functors can share structure. Management of a global hash-cons table \n1s not com\u00adpletely trivial; we would like to delete stale data from the table, but how do we know what \nis stale ? We use weak pointers (pointers that the garbage collector ignores when tracing live data and \nthat are invalidated when the object pointed to is collected), a special feature supported by SML/NJ; \nthis is effective, though it seems a bit clumsy. Naive translation of static semantic objects may also \ndrag in large LTYs that are mostly useless. For example, to compile (Compiler .Control .CG. calleesaves \n:= 3; Compiler. AllocProf reset()) we need to know only that variable calleesaves has type int, and \nvariable reset has type unit -unit, However, our translation algorithm will have to include the type \nof structure Compiler which may contain hundreds of com\u00adponents. So we extend our lambda type notation \nwith the following new constructs: datatype lty = ...... I GRECty of (int * lty) list I SREcORDty of \nlty list Here, SRECORDty is same as RECORDty except that it is used particularly for module constructs \n(i.e., structures). The LTY GRECty 1s used to type external structures such as the Compiler structure \nabove; a GRECty specifies a sub\u00adset of record fields (and their corresponding LTYs) that are Interesting \nto the current compilation unit. The LTYs for all external structure identifiers are inferred during \nthe Lambda Translation phase rather than be]ng translated from their corresponding static semantic objects. \nFor example, the LTY for structure Compiler in the above example WI1l be lt comp: lt ..mP = /tcirL),ltaltOC)] \nwhere GRECty[(3, (7, ltct,.l = GRECty[(O, GRECty[(43,1NTty) ])] and ltalzOC = GRECty[(O, ARROWty(INTty,INTty) \n)]. Here, we assume that Control and AllocProf are the 3rd and 7th fields of Compiler, CG is the Oth \nfield of Control, calleesaves is the 43nd field of CG, and reset is the Oth field of AllocProf. We also \nsave code size and compilation time by sharing coercion code between equivalent pairs of LTYs, using \na table to memo-ize the coerce (s, t) function. Coercions in\u00adtroduced in the coerce procedure are normally \ninlined in the CPS optimization phase, because they are applied just once. Shared coercions are often \nnot inlined, because they can cause excessive code explosion. Because shared coercions can be more expensive \nthan normal irdined coercions, we only use this hashing approach for coercions between mod\u00adule objects. \nThis compromise works quite well in practice, because it is often the large module objects that are causing \nthe excessive coercion code problem. Since module-level coercions are not executed often, the generated \ncode is not noticeably slower.  5 Typed CPS Back End Standard ML of New Jersey uses continuation-passing \nstyle (CPS) as its intermediate representation for program opti\u00admization, The LEXP language is converted \ninto a CPS notation (ce.xp) that makes flow of control explicit. CPS [24, 14] and its use in the SML/NJ \ncompiler [4, 3] have been described in the literature. Previous versions of SMLINJ 5 have used an untyped \nCPS language. But now we propagate some very simple type annotations into CPS. Each variable in the CPS \nlan\u00adguage is annotated, at its binding occurrence, with a CPS type (CTY). The CTYS are very simple: datatype \ncty = INTt I PTRt of lnt option I FUNt I FLTt I CNTt  so they are very easy and cheap for the lback \nend to main\u00adtai n. A CPS variable can be a tagged integer (INTt), a pointer to a record of length k (PTRt \n( SOME k)), a pointer to a record of unknown length (PTRt (NONE) ), a floating-pointer number (FLTt), \na function (FUNt), or a continuation (CNTt). The translation frm LTY to CTY is straight-forward: fun \nlty2cty lt = case lt of INTty => INTt REALty => FLTt I BOXEDty > PTRt (NONE) I RBOXEDty => PTRt (NONE) \nI ARROWty _ => FUNt I RECORDty 1 > PTRt (S13ME(length 1)) Because the CPS conversion phase has made implemen\u00adtation \ndecisions for records and functions, the CTY is no longer concerned with the details of RECORDty and \nARROWty. We augment the set of CPS prim-ops with specific wrapper/unwrapper operations for integers (i.e., \niwrap and iunwrap), floating-point numbers (i.e., fwrap and funwrap), and pointers (i.e., wrap and unwrap). \nFor ex\u00adample, fwrap boxes a floating-point number, producing a pointer, and funwrap is the inverse operation. \nFor m-bit integers represented in an n-bit word with an (n m)-bit tag, iwrap could apply the tag (by \nshifting and OR-ing), and iunwrap could remove it. For integers represented by boxing, then iwrap could \nheap-allocate a boxed integer. 5.1 CPS conversion The overall structure and algorithm of our CPS conversion \nphase is almost same as the one described by Appel [3, Ch. 5]. The conversion function takes two arguments: \nan LEXP expression E and a continuation function c of type value + cexp; and returns a Cl% expression \nas the result. But now, during the conversion process we gather the LTY information for each LEXP expression, \nand maintain an LTY environment for all CPS variables. The LTYs are used to make implementation decisions \nfor records and function calls, and are also translated into CTYS to annotate CPS variables. The CPS-conversion \nphase decides how to represent each record, and encodes its decisions in the CPS operation se\u00adquences \nit emits, Converting LEXP records is the most in\u00adteresting case, Given an LEXP expression RECORD[ul, \nUZ, .... Un], suppose the LTY for each U1 is t,(i= 1, .... n), we can represent the record using any \nof the layouts shown in Figures 1: with every field boxed and every integer tagged (Figure la), using \nflat records of reals (y in Figure lb), with mixed boxed and unboxed fields (z in Figure 1b), or with \nsegregated boxedhrnboxed fields (Figure 1c). The transla\u00adtion of SELECT expressions must correspond to \nthe layout convention used for records. CPS conversion also decides the argument-passing con\u00advention \nfor all function calls and returns. In ML, each function has exactly one argument, but this argument \nis of\u00adten an n-tuple. In most cases, we would like to pass the n components in registers. The previous \nSML/NJ compilers could spread the arguments into registers only when caller and callee were in the same \ncompilation unit, and the call sites were not obscured by passing functions as arguments. The new, type-based \ncompiler can use register arguments based on type information. If the type of ~ s argument is RECORDt \ny[tl . . . . . t~]. and n is not so large that the register bank will be exhausted,6 we pass all components \nin regis\u00ad ters (unlike LEXP, CPS does have multi-argument func\u00adtions). Similarly, a function that returns \nan n-tuple value up to version O 93, released in 1993 We currently use a threshold of n < 10 on 32-register \nRISC rnachmes. will be translated using a n-argument continuation function, for suitably small n, Finally, \nthe prlmitlve coercion operations, WRAP(t,e) and UPJWRAP(t,e), are converted into corresponding CPS primi\u00adtive \noperations. Based on whether t 1s INTty, REALty, or other pointer types, WRAP and UNWRAP are translated \ninto iwrap and iunwrap, fwrap and funwrap, or wrap and unwrap. 5.2 Optimization and closure conversion \nWhen the CPS conversion phase is finished, the compiler has made most of the implementation decisions \nfor all pro\u00adgram features and objects: structures and functors are com\u00adpiled into records and functions; \npolymorphic functions are coerced properly lf they are being used less polymorphi\u00adcally; pattern matches \nare compiled into switch statements; concrete data types are compiled into tagged data records or constants; \nrecords are laid out appropriately based on their types; and the function calllng conventions are mostly \ndecided The optimizer of the SML/NJ compiler operates on the CPS intermediate representation. Optimization \nphases are almost unchanged, except that they must correctly propa\u00ad gate the CTYS, which is simple to \ndo; CPS optimization are naturally type-consistent. Besides those described by Appel [3], two new CPS \noptimization are performed: pairs of wrapper and unwrapper operations are cancelled; and record copying \noperations of the form let val (x,y) =am (x,y) end can be eliminated, since now we know the size of a \nat compile time. To represent environments for higher-order functions with nested scope, the compiler \nuses our new space\u00adefficient closure conversion algorlthm [23]. Previously, this phase had to discover \nwhich functions are continuations by dataflow analysis [6]: now the information is manifest in the CTYS. \nWhen the closure analysis phase must build heap records for closure enwronments, it can use all the record \nrepresen\u00adtations shown in Figure 1. The closure conversion algorithm 1s very cautious about optimizing \ntransformations that extend the lifetime of variables, since this can cause a kind of memory leak [23, \n3]. The CTY information allows the lifetime of integers (and other constant-size variables) to be safely \nextended. a useful benefit.  6 Performance Evaluation Type-directed compilation should support much \nmore ef\u00adficient data representations In order to find out how much performance gain we can get for different \ntype-based op\u00adtlmlzatlons, we have measured the performance of six dif\u00adferent compilers on twelve SML \nbenchmarks (described in Shao [22]). Among these twelve benchmarks, MBrot, Nu\u00adcleic, Simple, Ray, and \nBHut involve intensive floating\u00adpoint operations; Sieve and KB-Comp frequently use first\u00adclass continuations \nor exceptions; VLIW and KB-Comp make heavy use of higher-order functions. The average size of these benchmarks \nis 1820 lines of SML source code. The six compilers we use are all simple variations of the Standard \nML of New Jersey compiler version 1.032, All of these compilers use the new closure conversion al\u00adgorithm \n[23] and with three general purpose callee-save registers [6], and all use tagged 31-bit integer representa\u00adtions. \nOther aspects of these compilers are close to those described by Appel [3]. sml.nrp A non-type-based \ncompiler, No type information is propagated beyond the elaboration phase, Data uses standard boxed representations. \nFunctions take one argument and return one result. sml.fag The sml.nrp compiler with the argument battening \noptimization [14, 3]. If the call sites of a function are known at compile time, lts n-tuple argument \ncan be flattened and passed in n registers. This compiler is similar to SML/NJ 0.93 [3]. sml.rep The \nnew type-based compiler that supports very basic representation analysis (on records). Floating point \nnumbers still use boxed representations. Hash\u00adconsing of LTY s (Section 4.5) is not used (had not yet \nbeen implemented) in this version, sml.mtd The sml.rep compiler plus the implementation of minimum typing \nderivations. sml.ffb The sml.mtd compiler plus support of unboxed floating point numbers. Function call \nand return pass floating-point arguments in floating-point regis\u00adters. Records of floats are represented \nflat, as In Figure 1b.7 Records that contain both boxed and un\u00adboxed values are still represented as \ntwo layers, with each unboxed value being boxed separately. sml.fp3 The sml.ffb compiler, but with three \nfloatlng-point callee-save registers [22]. All measurements are done on a DEC5000/240 worksta\u00adtion with \n128 megabytes of memory, using the methodology described in Shao s Ph.D. thesis[22], In Figure 7 we show \nthe execution time of all the benchmarks using the above six compilers, using sml.nrp as the baseline \nvalue. Fig\u00adure 8 compares execution time, heap allocation, code size, and compile time (based on the \naverage ratios of all twelve benchmarks). We can draw the following conclusions from these comparisons: \n7Unfofiunately, the SML/NJ version 1 032 still uses the old runtlme system [2] Reals are not always dlgned \nproperly, so memory fetch (or store) of a floatmg-pomt number must be Implemented using two smgle\u00adword \nmemor-yload (memory-store) InstructIons 1.2--1.2 d ;1.o-0 0a%**oao. 0 m o a o 0 a o -1.0  %0 W@e %@A- \n: ~o ** %~ u *@ 4 * W&#38; * : 0.8- Oq *Q -0.8 Oa 0 : t 0.6- -0.6 A e 0.4- 0.4 : t o sml,nrp * \nsml.mtd ~ 0.2 sml.fag o sml.ffb 0.2 {1 * sml.rep ~ sml.fp3 m 0.0 0.0 BHut Boyer Sieve KB-C Lexgen \nYacc Life Simple Ray VLIW MBrot Nucleic Average lFigure7: Acomparison ofexecution time Program sml.nrp \nsml.fag sml.rep sml.mtd sml.ffb sml.fp3 (base) (ratio) (ratio) (ratio) (ratio) (ratio) Execution time \n1.00 0.95 0.89 0.83 0.77 0.81 Heap allocation 1.00 0.90 0.70 0.66 0.58 0.63 Code size 1.00 0.98 0.97 \n0.97 0.99 1.01 E Compilation time 1.00 1.04 1.06 1.09 1.10 1.17 Figure8: Summary comparisons ofresource \nusage The type-based compilers perform uniformly better CPS contractions. The only significant speedup \nof than older compilers that do not support representa-the sml.mtd compiler over sml.rep is from the \nLife tion analysis. The sml.ffb compiler gets nearly 19% benchmark where with MTD, the (slow) polymorphic \nspeedup in execution time and decreases the total heap equality in a tight loop (testing membership of \nan ele\u00adallocation by 36$Z0 (on average) over Ithe older SML/NJ ment in a set) is successfully transformed \ninto a (fast) compiler (i.e., sml.fag) that uses uniform standard monomorphic equality operator and the \nprogram runs boxed representations. This comes with an average 10 times faster. of 670 increase in the \ncompilation time. The generated code size remains about the same. 7 Related Work and Conclusion The \nsimple, non-type-based argument flattening opti\u00ad mization in the sml.fag compiler gives a useful 5% \nRepresentation analysis, proposed and implemented by speedup. Leroy [15] (for ML-like languages) and \nPeyton Jones and Launchbury [20] (for Haskell-like languages), allows data The sml.rep compiler, which \nsupports passing ar\u00adobjects whose types are not polymorphic to use more efft\u00ad gument in registers (but \nnot floating-point registers), cient unboxed representations. Peyton Jones and Launch\u00ad only improves \nthe performance of the non-typed-based bury s approach [20] requires extending the language (i.e., sml.fag \ncompiler by about 6%. It does decrease heap Haskell) with a new set of unboxed monomorphic types; allocation \nby an impressive 2090. the programmer has to explicitly write boxing coercions Minimum typing derivations \nwere intended to elimi-when passing unboxed monomorphic values to polymor\u00adnate coercions; but most of \nthe coercions eliminated phic functions. Leroy s [15] approach is more attractive by MTD would have been \neliminated anyway by because it requires no language extension or user interven\u00ad tion. The work described \nin this paper is an extension and implementation of Leroy s techniques for the entire SML language. We \nconcentrate on practical issues of implement\u00ading type-directed compilation such as interaction with ML \nmodule system and efficient propagation of type informa\u00adtion through many rounds of compiler transformations \nand optimizations. Many people have worked on eliminating unnecessary wrapper functions introduced by \nrepresentation analysis. Both Peyton Jones [20] and Poulsen [21] let the programmer to tag some types \nwith a boxity annotation, and then stat\u00adically determine when to use boxed representations. Hen\u00adglein \nand Jorgensen [13] present a term-rewriting method that translates a program with many coercions into \none that contains a formally optimal set of coercions. Neither technique appears easy to extend to the \nSML module lan\u00adguage. We use minimum typing derivations [7] to decrease the degree of polymorphism for \nall local and hidden func\u00adtions. This is very easy to extend to the module system. Our approach may achieve \nalmost the same result as for\u00admally optimal unboxing. And we have shown that simple dataflow optimization \n(canceling wraplunwrap pairs in the CPS back end) is almost as effective as type-theory-based wrapper \nelimination. Type specialization or customization [9, 8] is another way to transform polymorphic functions \ninto monomorphic ones. Specialization can also be applied to parameterized modules (i.e., functors), \njust as generic modules are imple\u00admented in Ada and Modula-3. Because of the potential code explosion \nproblem, the compiler must do static analysis to decide when and where to do specialization. Our type-based \ncompiler uses coercions rather than specializations; how\u00adever, because our CPS optimizer [3] always inline-expands \nsmall functions, small and local polymorphic functions still end up being specialized in our compiler. \nWe believe that a combination of representation analysis and type special\u00adization would achieve the best \nperformance, and we intend to explore this in the future. Harper and Morrisett [12] have recently proposed \na type\u00adbased compilation framework called compiling with inten\u00adtional type analysis for the core-ML language. \nThey use a typed lambda calculus with explicit type abstractions and type applications as the intermediate \nlanguage. Their scheme avoids recursive coercions by passing explicit type descriptors whenever a monomorphic \nvalue is passed to a polymorphic function. Since they have not implemented their scheme yet, it is unclear \nhow well it would behave in practice. Because their proposal only addresses the core-ML language, we \nstill do not know how easily their scheme can be extended to the SML module language. We believe that \ntype-based compilation techniques will be widely used in compiling statically typed languages such as \nML in the future. The beauty of type-based representa\u00adtion analysis is that it places no burdens on the \nuser: the source Ianguage does not change, programmers do not need to write coercions, and separate compilation \nworks cleanly because interfaces are speficied using types. By implementing a fully working type-based \ncompiler for the entire SML language, we have gained experience with type-directed compilation, and solved \nmany practical prob\u00adlems involved in the implementations. Our performance evaluation shows that type-based \ncompilation techniques can achieve significant speedups on a range of benchmarks. Acknowledgments We \nwould like to thank John Reppy, Sheng Llang, and Patrick Sansom for comments on an early version of this \npaper. This research is supported in part by National Sci\u00adence Foundation Grants CCR-9002786, CCR-9200790, \nand CCR-9501624.  References [1] William E. Aitken and John H. Reppy. Abstract value con\u00adstructors: \nSymbolic constants for Standard ML. Technical Report TR 92-1290, Department of Computer Science, Cor\u00adnell \nUniversity, June 1992. A shorter version appears in the proceedings of the ACM SIGPLAN Workshop on ML \nand its Applications, 1992, [2] Andrew W. Appel. A r-trntlme system, Lisp and $wrbolic Computation, 3(4):343-80, \n1990. [3] Andrew W. Appel. Compiling with Continuations. Cam\u00adbridge University Press, 1992. [4] Andrew \nW. Appel and Trevor Jim. Continuation-passing, closure-passing style. In Sixteenth ACM Symp. on Princi\u00adples \nof Programming Languages, pages 293 302, New York, 1989. ACM Press. [5] Andrew W, Appel and David B. \nMacQueen. Standard ML of New Jersey. In Martin Wirsing, editor. Third Irrt 1 Symp. on Prog. Lang. Implementation \nand Logic Programming, pages 1 13, New York, August 1991. Springer-Verlag. [6] Andrew W. Appel and Zhong \nShao. Callee-save registers in continuation-passing style. Lisp and Symbolic Computation, 5:189-219, \nSeptember 1992. [7] Nikolaj S. Bjomer. Minimial typing derivations. In ACM SIGPLAN Workshop on ML and \nits Applications, pages 120 126, June 1994. [8] Craig Chambers. The Design and Implementation of the \nSELF Compiler, an Optimizing Compiler for Object-Oriented Programming Languages. PhD thesis, Stanford \nUniversity, Stanford, California, March 1992. Tech Reporr STAN-CS\u00ad92-1420. [9] Craig Chambers and David \nUngar. Customization: Opti\u00admizing compiler technology for SELF, a dynamically-typed object-oriented programming \nlanguage. In Proc. ACM SIG-PLAN 89 Confi on Prog. Lang, Design and Implementation, pages 146 160, New \nYork. July 1989. ACM Press. [10] Luis Damas and Robin Milner. Principal type-schemes for functional programs. \nIn Ninth ACM Symposium on Princi\u00adples of Programming Languages, pages 207 12, New York, 1982. ACM Press. \n [11 ] Robert Harper and Mark Lillibridge. A type-theoretic ap\u00adproach to higher-order modules with sharing. \nIn Tt~ enty Firsr An~71udACM .$ymp. on Principles of Prog. Languages. pages 1 23-137, New York, Jan 1994, \nACM Press. [12] Robert Harper and Greg Morrisett. Compiling polymorphism using intenslonal type analysls. \nIn T\\\\ enty-second Annual ACM S)tnp. on Principles of Prog, Languages, pages 130 141, New York, Jan 1995, \nACM Press, [13 ] Fritz Henglein and Jesper Jorgensen. Formally optimal box\u00ad ing. In Proc. 21st Annual \nACM SIGPLAN-SIGACT SYnZp. on Prmcip/es of Programnrmg Languages, pages 213-226. ACM Press, 1994, [14] \nDavid Kranz. ORBIT: An optunlzing compiler for Scheme PhD thesis, Yale Umversity, New Haven, CT, 1987. \n[15] Xavier Leroy. Unboxed objects and polymorphic typing. In Nineteenth Annual ACM Symp. on Principles \nof Prog. Lan\u00adguages, pages 177-188, New York, January 1992. ACM Press. [16] Xavier Leroy. Mamfest types, \nmodules, and separate com\u00adpilation. In T}t en~ First Annual A CM Symp. on Principles of Prog. Languages, \npages 109 1 22, New York, Jan 1994. ACM Press. [17] Dawd B. MacQueen and Mads Tofte. A semantics for \nhigher-order functors. In Proc. European Symposium on Pro\u00adgramming (ESOP 94), pages 409-423, April 1994. \n[18] Robin Milner and Mads Tofte. Commentary on Standard ML. MIT Press, Cambridge, Massachusetts, 1991. \n[19] Robin Milner, Mads Tofte, and Robert Harper. The Defini\u00adtion of Standard ML. MIT Press, Cambridge, \nMA, 1990. [20] Simon L. Peyton Jones and John Launchbury. Unboxed values as first class citizens in a \nnon-strict functional lan\u00adguage, In The F/lb International Conference on Functional Programming Languages \nand Compltter Architecture, pages 636-666, New York, August 1991. ACM Press. [21 ] Eigil Poulsen. Representation \nanalysls for efficient imple\u00admentation of polymorphism. Master s thesis, DIKU, Uni\u00adversity of Copenhagen, \n1993. [22] Zhong Shao. Compiling Standard ML for Ejj5cient Execu\u00adtion on Modern Machines. PhD thesis, \nPrinceton University, Princeton, NJ, November 1994. Tech Report CS-TR-475-94. [23] Zhong Shao and Andrew \nW. Appel. Space-efficient closure representations. In Proc. 1994A CM Conf on Lisp and Func\u00adtional Programming, \npages 150 1 61. ACM Press, 1994. [24] Guy L. Steele. Rabbit: a compiler for Scheme. Technical Report \nAI-TR-474, MIT, Cambridge. MA, 1978. [25] Mads Tofte. Prmclpal signatures for higher-order program modules. \nIn Nineteenth Annual ACM Symp. on Principles of Prog. Languages, pages 189 1 99, New York, Jan 1992. \nACM Press. [26] Dawd M. Ungar. The Design and Ei alua[ion of a High Per\u00ad formance Smalltalk System. MIT \nPress, Cambridge, MA, 1986.   \n\t\t\t", "proc_id": "207110", "abstract": "<p>Compile-time type information should be valuable in efficient compilation of statically typed functional languages such as Standard ML. But how should type-directed compilation work in real compilers, and how much performance gain will type-based optimizations yield? In order to support more efficient data representations and gain more experience about type-directed compilation, we have implemented a new type-based middle end and back end for the Standard ML of New Jersey compiler. We describe the basic design of the new compiler, identify a number of practical issues, and then compare the performance of our new compiler with the old non-type-based compiler. Our measurement shows that a combination of several simple type-based optimizations reduces heap allocation by 36%; and  improves the already-efficient code generated by the old non-type-based compiler by about 19% on a DECstation 500.</p>", "authors": [{"name": "Zhong Shao", "author_profile_id": "81351597965", "affiliation": "Department of Computer Science, Yale University, 51 Prospect Street, New Haven, CT", "person_id": "PP14127817", "email_address": "", "orcid_id": ""}, {"name": "Andrew W. Appel", "author_profile_id": "81100498630", "affiliation": "Department of Computer Science, Princeton University, 35 Olden Street, Princeton, NJ", "person_id": "PP14174176", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/207110.207123", "year": "1995", "article_id": "207123", "conference": "PLDI", "title": "A type-based compiler for standard ML", "url": "http://dl.acm.org/citation.cfm?id=207123"}