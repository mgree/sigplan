{"article_publication_date": "06-01-1995", "fulltext": "\n Implementation of the Data-flow Synchronous Language ~IGNAL Pascalin Amagb&#38;gnort ~oic E3estmrci \nI?aul ~e ~uetmic e-mail: {PascalinAmagbegnon,Lo phone: icBesnard,PaulLeguernic ( 33)-99-84-74-.36 RLsA-mRIA \n)@irisa.fr Campus &#38; Beaulieu 350412 l?t3nnes CEDEX FRANCE Abstract This paper presents the techniques \nused for the compilation of the data-flow, synchronous language SIGNAL. The key feature of the compiler \nis that it performs formal calculus on systems of boolean equations. The originality of the imple\u00ad mentation \nof the compiler lies in the use of a tree structure to solve the equations. Introduction Traditionally, \nreal-time systems have been programmed in imperative asynchronous languages like ADA, OCCANt or C together \nwith some operating system facilities. But these tools are not satisfactory as there is considerable \nneed of provably correct software and as systems become more and more complex. To remedy the insufficiencies \nof the current took, the $yrt\u00adchronous paradigm has been proposed and developed in[4]. Its main hypothesis \nis that a) operators react instantaneously with their inputs (computations have zero duration), b) time \nis just a succession of events (no explicit reference to a notion of physical time), The validity of \nthe synchrony assumption is thoroughly discussed in [5]. Let us point out briefl y, some advantages a \nprogrammer can get from this simplifying hy\u00adpothesis. The assumption that an operator (e.g an adder) \ncomputes its outputs simultaneously with the occurrences of its inputs is a very useful approximation \nin many fields. As an example in the field of hardware synthesis, logic gates are supposed to compute \ntheir outputs synchronously in the first approx\u00adimation. It makes the design of a circuit simple. Then, \nPermission to copy without fee all or part of this material is granted provided that the copies are not \nmade or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand its date appear, and notice is given that copying is by permission of the Association of Computing \nMachinery.To copy otherwise, or to republish, requires a fee and/or specific permission. SIGPLAN 95La \nJolla, CA USA Q 1995 ACM 0-89791 -697-2/95/0006 ...$3.50 propagation time is taken into account and the \nmaximum clock frequency Mowed is calculated. Such a separation between pure functionality and execution \ntime is now possi\u00adble in software with synchronous tanguages: the programmer specifies a functionality \nof the program and the compiler of a synchronous language handles execution lime on a particular target \nprocessor. The second assumption of the synchronous paradigm (no physical time) provides the programmer \nwith a framework in which he/she can handle uniformly real-time constraints, As a matter of fact, real-time \nconstraints are not always ex\u00adpressed in terms of mini-or micro-seconds. The statement the train must \nstop within 30 meters is a real-time con\u00adstraim just as the train must stop within 30 seconds . In a \nframework like ADA which possesses a notion of time only in terms of seconds (and not in terms of meters), \nthose con\u00adstraints will not be handtcd with similar programs. Hence the usefulness of the second synchrony \nhypothesis. Four languages are built upon this synchronous paradigm: they differ mostly in the programming \nstyle they of\u00adfer. ~STEREL[7] is ~ imperative synchronous language. SIGNAL[61 and LUSTREII 11 are data-flow \nlanguages. Finally in ARGOS[21], systems are specified with parallel and hier\u00adarchical automata. A summary \nof the synchronous approach can be found in [14]. This paper presents the techniques used in the compilation \nof the SIGNAL kmguage which k a data-flow kmguage. In this language, systems are specified with equations \nover syn\u00adchronized screams. The dechirative style of SIGNAL provides the programmer with the nice high-level \ncons~cts needed to describe a real-time system in terms of operators network, differential/difference \nequations. But, the higher the level of the kmguage, the bigger the chatlenge to construct a compiler \nable to generate efficient executable code by using a reason\u00adable amount of computing resources (memory, \ncpu-time). SIGNAL S compilation is based on an abstract interpretation of each statement as a system \nof boolean equations. These equa\u00adtions express the synchronizations in the program. The com\u00adpiler solves \na system of boolean equations for each program in order to a) check the consistency of the synchronizations, \nand, b) generate efficient code (silicon[3], sequential[20], parallel [9]). In this paper, we mainly \nreport the techniques used to an\u00adalyze the boolean equations. In Section 2 we present the language SIGNAU \nthe basic objects, the boolean equations and the dependency graph associated to each SIGNAL pl-o\u00adgram. \nSection 3 puts the emphasis on the system of boolean equations and introduces a hierarchical representation \nfor it. FinaMy we conclude with some experimental results which demonstrate the effectiveness of our \napproach. 2 The SIGNALlanguage In this section, we present the basic objects of the Emgtsage. We use \nsequences to describe the semantics of the statements. See [6] for more details on formal semantics of \nSIGNAL 2.1 Signals and clocks Signals. A signal X is a sequence (Xi )ieI of values chosen in a domain \nD (the type of the signal). Integer, boolean, real are examples of signal types. The time index 1 is \na totally ordered set of instaius. We are interested in a discrete time model. So, instamts are taken \nin a denumerable set. M any given instant t, a signal maybe present or absenl depending on whether or \nnot, the instant under consideration belongs to 1; a signal carries a value only when it is present. \nClocks. The set of instants at which a signal is present is its clock. So, the clock of a signal (X~ \n)t ~1 is its time index 1. Two signals always present at the same instants are said to be synchronous: \nthey have the same clock. Thus, the clock of a signal X is the equivalence cla.s~of X for the synchrony \nrela[ion: in that sense it is denoted X. Notation. Following [S], the set theoretic operators for clocks, \nwhich are sets, are denoted A (intersection), V (union) and \\ (set difference). We use <OP> to denote \none of the three operators, 2.2 The kernel of SIGNAL A statement in SIGNAL is an equation on signals; \nit is catled a process. We give here the kernel operators; the full language features other operators \nwhich can be rewritten in terms of these kernel operators. Functional expressions. The operators (e.g \n+, , *, and) defined on basic data types (e.g booleans, integers) are canonically extended to sequences \nand consequently to signais. Let ~ be such an operator of arity n and let (X1,) K1,..., (X.,),CI be n \nsequences with the same time index 1. The equation vtEI, Yt=f(xlt, . . ..xnt) is written in SIGNAL (see \nFigure 1) Y := f(xl ,,. . ,Xn) The signals involved in that equation are required to have the same time \nindex 1: they must be synchronous. Thus, the definition of the sign~ Y implies the following equation \non the clocks: P= Z=. .=Y. Reference to past values. We reference past values of a discrete signal \nwith the $ operator, The SIGNAL process Zx := X $ 1initvo is the representation of the following equation \non the se\u00adquences (Xt )tEI and (ZXt )teI defined on the same index 1: We 1,ZXt =Xt-l and ZXl =V. ~ere \nagain, 2X is by definition synchronous with X: Z X = X. A timing diagram for this operator is depicted \non Figure 2. DownsampIing. Given a signal U and a boolean-valued sig\u00adnal C (sometimes termed condition), \nthe process x := U whenc defines the signal x which carries the same value as u when both U and C are \npresent, and, C carries the value true. Before giving a formal definition of X, let m introduce some \nnotations we will use frequently. We denote [c] = the set of instants at which C carries the value true \n[Ye] = the set of instants at which c carries the vatue ~alse When a boolean-valued signal occurs, it \ncarries either the value true or the value false. So the pair ([C ], [-@]) defines a partition of ~ (the \nclock of C). This can be represented by: [c] v[-m] = e (1) { [C] A [-@] = 6) where ~ denotes the null \nclock, the empty set of instants. W5th this notation, the signal X : = U wk?II c is tk Se\u00adquence such \nthati ~ = O ~ [c] the time index, the clock VtEg, xt=ut { (X* )jef can be viewed as a subsequence of \n(Ut )t<o. See Figure 3 for a timing diagram. Deterministic merge. Given two signals U andv, the process \nX : = U default V defines the signal which carries the same value as U when U is present, or the same \nvalue as V when U is absent. R is Figure 3: X :. U whenc absent when both U and V are absent. It merges \nthe ftovw U and V and puts a priority on u, A timing diagram is depicted on Figure 4. More formally: \nXt is well ctefine~ for a!: t ~ 1, since any instam in ~ belongs either to U or to V \\ U. Composition \nof processes. The elementary processes we have presented till now may be composed with the com\u00admutative \nand associative operator ~ . From an equational point of view, this operator is the union of two systems \nof equations. For example the S1~ML process of the system: (1 Zx :=X$1 [x := Zx+l! 1) 2.3 Extended language \nFor convenience, the full language SIGNAL offers many de\u00adrived operators; they can be expressed in terms \nof the kernel operators. Here are some of them: the operator event: syntactically, the clock ~ of a \nsignat X is written event X; in fact, it is an abbreviation for the boolean signal defined by evtmt x \n: = (X = x); it is synchronous with x and carries the value~rue each time it occurs; thus it can be identified \nwith X the clock of x;  the unary when: for a condition C, the signaJ when C is an abbreviation for \nC when C; this signat carries the  Figure 2:ZX := X $ 1 init vo Figure 4: x : = u defauit v value true \neach time it is present, and is synchronous with the clock [C ] which is the set of instants when the \nsignal C is present and carries the value true: so the signal when c and the clock [C ] can be unified; \nb similarly, the signal when ( not c ) can be identified with the clock [-@]; o the process synchro {XI \n, . . . . Xn } in Srcmrm s syntax specifies the equality of the ciocks of its operands i.e the equation \n~ = X2 = ., . == X-.. 2.4 System of boolean equations It appears clearly that a system of boolean equations \nlies under each SIGNAL process. We hinted that during the pre\u00adsentation of the Icemel of SIGNAL. We recapitulate \nthese equations in Table 1. At this stage, the main difference between SIGNAL and the classical data-flow \nlanguages [16] [25] is that in SIGNAL we manipulate synchronized data-flow by means of clocks. The main \npurpose of synchronized data-i-low is that all the syn\u00adchronizations (expressed in terms of equations \nover clocks] should be completely handled at compile time. For more details, see [17]. 2.5 Conditional \ndependency graph A data dependency is associated with each process. A pro\u00ad cess is compiled into a graph \nrepresenting the dependencies between signals. The edge X ~ Y connecting X and Y means that at each instant \nof the clock k, Y s value de\u00adpends on X s value. Such a graph is constructed from the elementary processes \nas shown in Table 2. -1 signat process Y:= f(xlf. ... xn) Zx:= X$l X:= U default V Y;. X whenc clock \nCatcuhls additional equations Y=xl=. .o=xn Fx=z 2=GVP ?=i A[c] [c] v [TG ]= 5 [C]A [+]= ~ Table 1: From \nSIGNAL operators to boolean equations x:= f(xl, . . ..xn) V i=l. ..?l, XiLX Zx:= X$l no dependency c \nX:. U whenc U-J2X X:= Wdefault V u 6 +x ?\\@ v I For each ]C- qc] 1 condition C c -5 [lC] .. For each \nsignal X 22X Table 2: From SIGNAL operators to a conditional dependency graph 2.6 Description of the \ngenerated code Sequential code generation from the conditional dependency graph follows a very simple \nscheme thoroughly described in [19]. Each sigmd is implemented by a variable. Since a signal carries \na value only when it is present (ioe it s clock is present), in the genera[ed code, access (read or write) \nto the variable that implements a signal is guarded by a test on the presence of the signal. Moreover, \nthe assignment of the value of a variable to another variable is guarded by the clock that labels the \ndependency between the two variables. As an example, consider the process X := u default V. The signal \nXmerges the signals U and V with a priority to U. The dependency graph of that process is G F\\G u xi \n  v and the code generated is: i f present(~) then i f present(~) then x :=/l endi f i f present(fi \n\\ 6) then X;=v endi f endi f In that piece of code, we write if present(0) to test if the instant under \nconsideration belongs to the clock ~. In the following paragraphs we will detail how the compiler implements \nthe test of a clock s presence. 3 Solving the system of boolean equa\u00adtions 3.1 Resolution; the needs \nThe goat of the compiler is to check the consistency of the synchronizations expressed by the system \nof equations and to generate executable code for various architectures [3, 20]. From the conditional \ndependency graph and the code gener\u00adation scheme, we can figure out what the needs are in terms of resolution. \n2 The dependency, ~ x X requires that, at any given instant, before the vatue of a signal X is computed, \na test be made on the presence/~bsence of X; that is, the pres\u00adence/absence of its clock X. So there \nis a need for a reso\u00adlution method that will allow to efficiently check at run-time the presence of all \nthe clocks which are related by a system of equations. The choice made in the SIGNAL compiler is to transform \nthe system of equations into a list of explicit definitions; that is, the compiler identifies in the \nsystem a set of clock variables (thefree variables) in terms of which the other clocks are expressed. \nThis explicitization is achieved by means of triangularization; that is, a transformation of the system \nof equations into a se~ of equalities of the form ki = ki ~<op>kiz such that the clock-to-clock dependency \ngraph (the edges Ici~ ~ ki z /ciz) be an acyclic graph (a partial order). So, the presence/absence of \nki at run-time, can be quickly deduced from the presence/absence of kil and kiz where kil and k;z are \nsubterms which the com\u00adpiler tries to share with other clocks in order to yield efficient code. Not only \ndoes a triangularization compute the order in which clocks must be evaluated, but it also exhibits the \nfree vari\u00adables of the system. It is important that the free variables be determined because they are \nthe ones that the environment of the real-time system must provide as inputs to the program. So, if they \nwere not statically computed, there would be a need for tests at run-time to check the consistency of \nthe in\u00ad puts; that overhead would make efficiency more difficuh 10 achieve. The problem of transforming \na system of boolean equations into an explicit system is NP-hard [12]. So [he algorithm implemented in \nthe compiler does not seek completeness, It is rather a heuristic aimed at fast compilation of commonly \nencountered systems of equations. Hence some correct SI~-NAL programs may be rejected because the compiler \nfails to produce the explicit form of their clock equations. Currently, the trianguhrization is carried \nout in the compiler through an arborescent representation of the equations. Before gc~ing into details \non the representation, we give the main ideas of the strategy that lies under it. 3.2 Strategy of resolution \nA triangular system of equations is progressively constructed from the original system (see Table 1). \nAn equation of the form k = ,41<op>k~ is oriented (we note k := kq<op>k~) in order to consider the clock \nformula kl <op>kz as the ~eti\u00adnition of the clock variable k, D.ming this process, an orien\u00adtation of \nsome equations may not be triviatly possible. There are two reasons for that. 1, The equation under consideration \nis of the form k n kl <op>k2 but there is already a definition of the variable k. In this case, a rewriting \ncan be performed to verify that the formula kl <op>kz is equivalent to the previous definition of k, \n2. It is an equation of the form k = kl <op>kz but an orientation would induce a cycle in the clock-to-clock \ndependency graph. In this case, an attempt can be made [O rewrite the formula kl <op>kz and break the \ncycle. Note that an equation of the form kl <OP> kz = hl <op;~ hz can be brought to the two previous \ncases by the insertion of a new variable h and by writing h == kl <op>k2 and h = Itl <op>h2: first orient \nthe equations and then prove the equivalence. At the end of this process the program is said to be tempo\u00adrally \nincorrect if there are some equations whose orientation induces a cycle or if there are some non-proved \nequalities. Hence a canonical rewriting system is needed to check the equivalence of two clock formulas \n(which are boolean for\u00admulas), Although this strategy cannot triangukirize an arbitrary s,ys\u00adtem of equations, \nit is very efficient in compiling common SIGNAL programs that implement realistic systems. 3.3 Example \nWe give in this section, an example of SIGNAL program. The purpose of this example is to illustrate the \nkind of rewriting the compiler has to perform. The reader interested in real\u00ad istic programs written \nin SIGNAL is referred to [2] for the 167 programming of a production cell controller, andto[18] for \na speech processing system. Consider a SIGNAL program catled PROCESSJ.LARM which must compute a boolean-valued \nsignal ALARM from 3 boolean-valued signals (say sensors) BRAKE, STOP-OK, LIMIT-REACHED. Here is an informal \nSpeCifiCatiO~ of the behavior: . the sensor BRAKE is true if the brakes of the train are activated; \ne STOP.OK is Wue if the train is StOppd; . LIMI TREACHED is true if the train goes beyond some limit \nit should not normally surpass; o ALARM must be true if the train has not stopped before the limit. \nA possib~e implementation of PROCESS_ALARM is the fol\u00adlowing SIGNAL equation ALARM : = BRAKE and L IMI \nT-REACHED and ( not STOP.OK) In that equation, all the signals are required to have the same clock~AL~M \n= BR~I<E = LIiWIT-R~ACHED = STOP-OK). This means that at each instant (a reaction of the program). all \nthe sensors are sampled and the vatue of ALARM is COmpLttd. Let us imagine a more sophisticated version \nof that progr,am: a sensor is sampled only when its value is necessary. We can think of this as an improvement \nmade by a programmer in order to reduce the communications with the execution environment of the program. \nThe sensors LIMI T_REAcHED and STOP-OK need to be sampled only during a braking action. And the sensor \nBRAKE needs to be sampled only when no braking is going on. So, we introduce a state v,ariable BRAKING_STATE \nas shown of figure 5. Let us now focus on the clock equations that lies under this program. If we denote \nfOr short BRAKING-STATE by c, BRAKING_NEXT_STATE by C , BRAKE by D, STOP.-OK by cl, LIMIT.REACHED by \nC2 and ALARM by C3 we hawx g= ~ (1) c = [g v[cl]v e (2) [c] =c~= @ (3) yq yD (4) [ C3=C1=6 (5) Lines \n(1), (3), (4) and (5) specify equalities of variables. For such equations, we choose one variable which \nwill replace the others when they are referenced. By replacing @ by ~ in (2] we have Figure 5: Source \ncode of process Alarm (1 BRAKING.STAT E := t3RAKINGJJEXT_STATE $ 1 % m.ernorize thenex~ state I BRAKINGdJEXT_STATE \n:= ( tme when BRAKE) default % enter lhe brakitl,g slale ( fake when STOP.OK) default % leave t he braking \nstale BRAKING-STATE % may in ~heprevious slate 1 synchro {when BRAKINGSTA!KZ, STOP-OK, LIMITREACHED} \n% sample M braking state 1 synchro {when ( not BRAKING-STATE) , BRAKE} % sample when nol in braking stale \nI ALARM :. LIMITR.EAC!HED and ( not STOP_OK) % the brake need no longer be checked 1) the system of \nequations, We present here the main ideas. Partition tree. Consider the boo~am-va.lued signal C of the \nprevious exam\u00adple and its clock G. According to Ihe properties described In the previous sections, the \npair ([C], [lC]) is a partition of Co Such a partition is represented by the tree in Figure 6. Since \nany clock can be partitioned by a condition, this basic tree can grow as its nodes are partitioned. Figure \n7 represents the pmtition tree of the example PROCESUMLARM of the All the equations of the system can \nbe trivially oriented from previous section, In such a tree, an edge between a parent right to left except \nfor equation (6). Indeed, the, variable node and a child node captures the inclusion of the child in \nits ~ appears in both sides of the equation; so, an orientation parent, The root may bean arbitmy formula \nbut the internal would induce a cycle. To break that cycle, let us use the nodes are partitions. extra \nknowledge (not appment in the system) we have about boolean valued signals: the clock [Cl] is included \nin ~: this Forest of clocks. As any clock formula cm be partitioned, is mainly due m the fact that ([Cl], \n[7C1] ) is a partition of the formulas originating from a SIGNAL program can bethe clock a. Similarly \n[C] c 5. Since a = [C] we have grouped into partition trees; this set of trees is called a~oresf [Cl] \n~ ~ and consequently [Cl] V ~ can be rewritten into of clocks. TWthin this forest, some trees may be \none-node ~. A similar argument shows that [D] ~ D Q [7C] ~ ~ trees; these are clocks that have not been \npartitioned in the and [D] V ~ = ~. Then the formula [D] V [Cl] V @ can be original SIGNAL program. rewritten \ninto ~. Finally the equation (6) beeomes ~ = &#38; which is trivially true and deleted from the system. \nFusion of clock trees. In the forest of clocks, let T and T In order to obtain the triangular form of \nthe system of equa\u00adbe 2 trees with roots r and k such that a) k be defined by a tions, the compiler must \nperform rewriting in respect to the formula kl <op>kz, b) kl and kz belong to the tree T; which inclusion \nrelation among clocks. That is why a speciat tree means that the operands of the root k are in the tree \nT. We representation has been introduced in the compiler to repre\u00ad carry out afusion of T into T by inserting \nk into the tree T sent efficiently part of this inclusion relation. as depicted in Figure 8. In Figure \n8 we point out a particular Note that in the previous example, the variable 6 cannot be node h of the \ntree T. h is the branching of the nodes kl ,and computed by an expression in the program: it is a free \nvariable k2; it is the first common ancestor of the 2 nodes. T is now a exhibited by the compilation. \nThis means that the exeeution subtree of the merge tree !l ~ . The fusion of 2 partition trees environment \nmust provide ii as an input to the program. This yields a more generaJ tree we call clock o-ee. can be \nrephrased as: the specification does not determine The main idea of the insertion of the formula kl <op>k2 \nthe pace at which the sensors must be sampled . Should is that it is inserted under the branching of \nits operands, they be sampled every meter or every mini-second, it is a at the <right hand side . This \ninsertion procedure has two choice of the environment; it is not a real feature of the alarm interesting \nfeatures: a) it preserves the triangularity of the functionality. system of equations, b)it optimizes \nthe code generated by nesting if-then-else control structures. 3.4 Hierarchical representation of Triangularity \npreservation. During a depth first search the equations (dfs) of the tree T from left to right , the \nnodes /cl and kz To meet the requirements presented above, an arborescent are visited before the node \nk = /cl <op> kz; it means that the organization of the formulas has been defined in [8]. R ordering that \nmakes the system be trianguiw is embodied in speeds up the rewriting and it captures the triangularity \nof the tree. AA [c,] [-c,] Figure 6: Basic partition tree Figure 7 : A hierarchical partitioning Figure \n8: Fusion of trees Code optimization. A partition tree can be viewed as the representation of an inclusion \nrelation. In a partition tree, a node is included in its parent. And more generally, a node is inchtded \nin its ancestors. In Figure 8 the clock k = kl <op>kj is included in the clock h. As a matter of fact, \nh being an ancestor of both kl and k2, we have kl ~ h and kz ~ h. Consequently all of the 3 formulas \nkl v k2, kl A k2 and kl \\ k2 denoted kl<op;>kz <areincluded in h. That is, the clock tree resulting \nfrom a fusion of 2 trees represents an inclusion relation. On the example PROCESSJiLARM. we have shown \nthe usefulness of the inclusion relation for the rewriting. Now let us show how it can help in optimizing \nthe code generated. The nesting of ij-then-else structures for code optimization is based on the remark \nthat, if h and k are 2 clocks such that h ~ k, then for an instant t, the following implication holds: \nt@ k =+ t @ h. In other words, if the test tG k fails. there is no need to test if tc h,Thus, code generation \ncan take advantage of the inclusion relation between clocks. For example in Figure 9, code a is more \nefficient than code b. As reported in [19] this kind of improvement carI yield a code which runs 300% \nfaster for some SIGNAL programs. Arborescent resolution We give herein three steps the algorithm of resolution, \n 1. Take a tree T in the forest and attempt to rewrite its root kin away that will make the operands \nof k belong to the same tree T. If this succeeds, the root formula of T can be inserted into T as described \nin 3.4 without disturbing the trianguhwity of T. 2. Realize the fusion of T and T to yield a tree T \nas described above. After the fusion of T and T , a formula which had one operand in T and the other \none in T now has its 2 operands in the tree T . So, the fusion of T and T may lead to more fusions; that \nis the purpose of step 3. 3. Do step 1 and step 2 till the rewriting rules of step 1 no longer apply. \n  Step 1 is implemented using a notion of p-depfh resolution thoroughly presented in [81. To put it \nroughly, the user of the compiler can set an integer parameter p, this parameter code a. if present(k) \n~lzen do-something-k if present(h) then do-something-h endif endif code b. if present(k) then do-so \nmelhing-k endif if present(h) then do-something-h endif Figure 9: Nesting if-then-else control structures \n [+3] A is the maximum depth of the syntactic trees of the formu\u00adlas manipulated during the rewriting. \nSetting a limit to the formulas, solves the duration and termination problems com\u00admonly encountered in \nrewriting systems. Step 2 is a simple tree manipulation. It raises though a question of canonicity that \nwe illustrate on the following example. Example. Consider again the tree in Figure 7 (redrawn in Figure \n10 without some nodes which are not relevant for the current context) and consider the formulas kl and \nkz which are roots of some trees (not drawn). k~ and kz are defined respectively by [Cl] v [II] and [Cl] \nV [lD]. Recall that the main idea of the fusion of a tree T into a tree T is that root r~ of Tl is inserted \ninto T under the branching of its operands. Following that idea, the insertion of k] and k! yields the \ntree depicted in Figure 11. Now consider the formula k = kl A )+2. The same argument would trivially \nplace k w a child of r (see Figure 12). But k can be rewritkm into another expression, Applying axioms \nof booleam algebra and using the inclusion relations embodied in clock trees atlow to rewrite k as [Gl] \nA [Cz]. The branching of [Cl] and [Cz] being [C ], k can be placed under [C] (see Figure 12). As the \ncode generation is based cm if-~hen-else nesting, the insertion of k under [C] yields much more efficient \ncode. Canonical factorization. The previous example shows that it is important to insert a formula under \nthe deepest possible parent. So we developed an insertion algorithm which op\u00adtimizes the depth. Our algorithm \nhas an important feature: among the potential parents of the formula, it chooses the T Figure 11: insertion \nof formulas one with the greatest depth; and we show in [11 that such a parent is unique. That feature \nmakes our tree structure a canonical form. The algorithm is not detailed here but the main concepts are \ngiven below: 0 a BDD (Binary Decision Diagram [101) is associated to each clock, thus the tree of clocks \nis transformed into a tree Of BDDs: 0 the problem mulated as factorizing of finding a parent a boolean \nfor fun a formula ction; is refor\u00ad * factorization are carried out by takhg advantage of the specific \nproperties of our tree, 4 Related work meeffort to generate code from a data-flow synchronous language \nhas also been undertaken for the LUSmE language. The compilation of LUSTRE produces an automaton; it \noffers as an option, a trade-off between response time and size of generated code, The automaton may \nbe a one-state and one-transition automa\u00ad ton. The transition is fired at each reaction of the program. \nIt is labelled with a set of equations to be evaluated in order to compute the outputs. This style is \ntermed single-loop code. generation scheme. SIGNAL S compilation produces the same k O  Figure 12: \nBest insa-tkm sample number BDD EDD SIGNAL of T&#38;BDD characteristic chmac. funco programs variables \nfunction after T&#38;BDll nodes time nodes time nodes time STOPWATCH 1318 61893 27.07s unable-cpu unable-cpu \nWATCH 785 34753 14.67s unable-cpu unable-cpu ALARM 465 3428 2.19s tmable-mem unable-cpu CHRONO 282 1548 \n0.92s unable-mem 422975 409.09s SUPERVISOR 202 425 0.45s unable-cpu 226472 146.32s PACE MAKER 96 50 0.10s \n53610 I 160.50s 582 0.36s ROBOT 99 36 0.27s unable-cpu 415 0.31s unable -cpu: computation was unable \nto terminate within the 40mn time limit. zmable-mem: computation was unable to terminate within the 200MB \nmemory limit. Figure 13: Compmisons kind of automaton. The major difference is that in SIGNAL, to be \nsimulated. the code generated is improved by the nesting of &#38;hen-else control structmes which has \nbeen made possible by our clock inclusion tree. To our knowledge no such hierarchical inclu-S Conclusion \nsion information has been used in LUST REimprove to the In this paper we have presented the data-flow \noriented Em\u00ad code generated. guage SIGNAL and we have given an overview of the booleam As reported in \n[151 for LUSTRE and in [221 for the ES IHWL techniques used for its compilation. These techniques have \nsynchronous hmguage. the efficiency of the code generated been successfully implemented and we give here \nsome ex\u00ad can be improved by the production of a partially explclred perimental results. automaton: that \nis, the compiler may pick some boolean Figure 13 shows the amount of computing resources required variables \nand simulate statically their evolution. This static for the compilation of sample SIGNAL programs. To \nshow the simulation yields a bigger automaton than the one of the effectiveness of our arborescent representation, \nwe compare single-loop style. But in this case, the set of equations eval\u00adthree representations of boolean \nsystems of equations. uated at each reaction is smaller since the simulated boolean variables need not \nbe computed any longer. So the code Tree and BDD (T&#38;BDD): a tree structure together with is bigger \nand runs faster. The problem with this style of a BDD canonical form as presented earlier in this paper. \ngeneration is that, in the worst case, the automaton grows ex\u00adponentiiltly with the number of simulated \nboolean variables. BDD characteristicfunction: the whole system of equa-Hence the need of heuristics \nto cleverly select the variables tions is represented by a single BDD; a system of equa\u00ad tions over n \nboolean variables can be viewed as a subset of {0, 1}n. Hence it. can be given a representation in the \nform of a characteristic function. This representa\u00adtion of subsets of {0, 1] is very common in the fieM \nof hardware verification and silicon compilation [1 3, 24]. To solve exactly boolean equations, there \nis a complete algorithm which runs polynomially in the size of this BDD (see [12]). In order to justify \nour non-complete ,atgorithm, we show that very often in practical cases, this BDD is too big to be computed. \nBDD characteristic function after T&#38;9DD: the original system of equations is transformed by a T&#38;BDD \ninto a tree (which is still a system of equations); then a Bm chmacteristic function is constructed. \nThe &#38;lfference between this system and the original one, is that some variables may be (and very \noften are) eliminated due to their equivalence with other variables. So, the trizmgu\u00adhrized system has \nless variables. The representations are compared in terms of memory (num\u00adber of BDD nodes) and time ( \nUnix user-time). The measures are conducted on a SUN4/Spare 10 with 64MEt main mem\u00adory. Manipulations \nof BDDs use a UC Berkeley BDD package. [23]. For the experimentation we set a 200MB virtual memory limit \nand a 40mn cpu time limit. As it is Shown On the table ~~, most of the measures that in\u00advolve a characteristic \nfunction were unable to compute within the resource limits. It appears clearly that characteristic func\u00adtions \nare impractical. Acknowledgements The authors would like to thank the Committee members for their careful \nreview and helpful comments. References [1] T. Amagbegnon, L. Besnax!, and P. IA Guernic. Ar\u00adboresceru \nCanonical Form of Etoolean Expressions. In\u00adternal publication 826, IRIS A, May 1994. [2] T. P. Amagbegnon, \nP. L. Guemic, H. Marchand, and E. Rutten. SIGNAL the specification of a generic, veri\u00adfied production \ncell controller. In T. L. In C. Lewerentz, editor, Case Study Production Cell A Comparative Study in \nFormal Software Developrnen~, Lecture Notes in Computer Science, Springer-Verlag, 1995.891. [3] M. Belhadj. \nUsing VHDL for link to synthesis tools. In North Atlantic Test Workshop, Nlmes, France, June 1994. A. \nBenveniste and G. Beny, Special section on an\u00adother look al real-time programming. Proceedings of the \nIEEE, 79(9); 1268 1336, September 1991. A, Benveniste and G. Beny. The synchronous approach to reactive \nand real-time systems. Proceedings of the IEEE, 79(9): 1270-1282, September 1991. A. Benveniste and P. \nLe Guernic. A denotational the\u00adory of synchronous communicating systems. Resemch Report 685, INRIA, Rocquencourt, \nJune 1987. G. Berry and G. Gonthier. The ESTEREL synchronous programming language: design, semantics, \nimplemen\u00adtation. Science of Computer Programming, 87 152, 1992. [8] L. Besnard, Compilation de SIGNAL: \nhorloges, dZpen\u00addances. environnement. PhD thesis, Universit6 de Rennes 1, France, Septembre 1992. [91 \n1?.Etoumai, C. Lavarenne, P. Le Guernic, 0. MaffeK, and Y. Sorel. Interface SIGNAL-SynDEx. Research report \n2206, INRIA France, Rennes, March 1994. [10] R. E. Bryant. Graph-based algorithms for boolean func\u00adtion \nmanipulation. IEEE Transactions on computers, C-35(8):677-691, August 1986. [11] P. Caspi, D. FMaud, \nN. Halbwachs, and J. A. Plaice. LUSTRE: a deckwative language for programming syn\u00adchronous systems, In \n14th ACM Symposium on I rinci\u00adples of Programming Languages, pages 178 188, Mu\u00adnich, 1987. [12] 0, Coudert. \nSIAM: Une Boile d Outils Pour la Preuve .Formelle de Syst2mes S@entiels. PhD thesis, Ecole Nationale \nSup6rieure des T616communications, France, 1991. [13] B. Dutertre. Specification et preuve de systt?mes \ndy\u00adnamiques. PhD thesis, Universit6 de Rennes 1, France, D6cembre 1992, [14] N. Halbwachs. Synchronous \nprogramming of reactive systems, Kluwer, 1993. [15] N. FIatbwachs, P. Raymond, and C. Ratel. Generating \nefficient code from data-tlow programs. In J. Maluszyn\u00adski and M. Wxsing, editors, , page . Springer \nVerlag, August 1991. LNCS 528. [16] G. Kahn. The semantics of a simple language for parat-Iel programming. \nIn J. L. Rosenfeld, editor, Information Processing 74, pages 471-475, North-Holland, 19 74. [17] P. Le \nGuemic and T. Gautier. Data-flow to von neu\u00admann: the SIGNAL approach. In J. Gaudiot and L. Bit, editors, \nAdvanced topics in data-$ow comput\u00ading, pages 413-438, Prentice Hall, 1991. [18] C. Le Maire, R. Andre-Obrecht, \nand P. Le Guernic. A new reaI-time synchronous programming approach to continuous speech recognition. \nIEEE transactions on Automatic Control, 1990. [19] O. Maffei s. Ordonnancements de graphes de~oes syn\u00adchronies; \nApplication d SIGNAL. PhD thesis, University de Rennes 1, France, Jan. 1993. [20] O. Maffeis, B. Ch6ron, \nand P. Le (luernic. Trans@r\u00admations du Graphe des programmed SIGNAL. Research report 1574, KNRIA France, \nRennes, January 1992. [21] F, Maraninchi. Argonaute graphicat description, se\u00admantics and verification \nof reactive systems by using a process algebra. In J. Sifakis, editor, Automatic Verifi\u00adcation Methods \nfor Finite-stale Systems, pages 38-53, Springer-Verlag, 1989. LN(X 407. [22] F. Mignard. Compilation \ndu langageEsterel en sysk%te d kquations boolt%nes. PhD thesis, Ecole des Mines de Paris, France, 1994. \n[23] E. M. Sentovich, S. K. J., L. L., M. C., M. R., A. Sal\u00addanha, H. Savoj, P. R. Stephan, R. K. 13rayton, \nand A. Sangiovanni-Vicentelli. S1S: A System form Se\u00adquential Circuit Synthesis. Research report UCWERL \nM92/41, UCB, 1992. [24] H. J. Touati, H. Savoy, R. Brayton, B. Lin, and A. Sangiovanni-Vicentelli, Implicit \nstate enumeration of finite state machines using bdd s. In IEEE conference on Computer-Aided Design, \npages 130 1 33, 1990, [25] W. W. Wadge and E. A. Ashcroft. LUCID, the Dataflow Programming Language. \nAcademic Press, 198.5.  \n\t\t\t", "proc_id": "207110", "abstract": "<p>This paper presents the techniques used for the compilation of the data-flow, synchronous language SIGNAL. The key feature of the compiler is that it performs formal calculus on systems of boolean equations. The originality of the implementation of the compiler lies in the use of a tree structure to solve the equations.</p>", "authors": [{"name": "Pascalin Amagb&#233;gnon", "author_profile_id": "81100437556", "affiliation": "IRSA-INRIA, Campus de Beaulieu, 35042 Rennes Cedex, France", "person_id": "P219741", "email_address": "", "orcid_id": ""}, {"name": "Lo&#239;c Besnard", "author_profile_id": "81100211833", "affiliation": "IRSA-INRIA, Campus de Beaulieu, 35042 Rennes Cedex, France", "person_id": "P172896", "email_address": "", "orcid_id": ""}, {"name": "Paul Le Guernic", "author_profile_id": "81100335673", "affiliation": "IRSA-INRIA, Campus de Beaulieu, 35042 Rennes Cedex, France", "person_id": "P221711", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/207110.207134", "year": "1995", "article_id": "207134", "conference": "PLDI", "title": "Implementation of the data-flow synchronous language SIGNAL", "url": "http://dl.acm.org/citation.cfm?id=207134"}