{"article_publication_date": "06-01-1995", "fulltext": "\n Better Static Memory Management: Improving Region-Based Analysis of Higher-Order Languages (Extended \nAbstract) Alexander Aiken Manuel Fahndrich Raph Levient Computer Science Division University of California, \nBerkeley+ Abstract Static memory management replaces runtime garbage collec\u00adtion with compile-time annotations \nthat make all memory al\u00adlocation and deallocation explicit in a program. We improve upon the Tofte/Talpin \nregion-based scheme for compile-time memory management [TT94]. In the Tofte/Talpin approach, all values, \nincluding closures, are stored in regions. Region lifetimes coincide with lexical scope, thus forming \na runtime stack of regions and eliminating the need for garbage col\u00adlection. We relax the requirement \nthat region lifetimes be lexical. Rather, regions are allocated late and deallocated as early as possible \nby explicit memory operations. The place\u00adment of allocation and deallocation annotations is determined \nby solving a system of constraints that expresses all possible annotations. Experiments show that our \napproach reduces memory requirements significantly, in some cases asymptot\u00adically. 1 Introduction In \na recent paper, Tofte and Talpin propose a novel method for memory management in typed, higher-order \nlanguages [TT94]. In their scheme, runtime memory is partitioned into regions. Every computed value is \nstored in some region. Re\u00adgions themselves are allocated and deallocated according to a stack discipline \nakin to the standard implementation of ac\u00adtivation records in procedural languages and similar to that \nof [RM88]. The assignment of values to regions is decided stat\u00adically by the compiler and the program \nis annotated to include *SupportedinpartbyanNSFNYI award. t s pp~rfedby anNSFgraduateresewchfellowship. \n~Authors address:ComputerScienceDivision,SodaHall, Universityof California, Berkeley,CA 94720-1776. Email: \n{aiken, manuel, raph}@cs . berkeley. edu URL: http: [[kiwi cs . berkeley. edu/-nogc Permission to copy \nwithout fee all or part of this material is granted provided that the copies are not made or distributed \nfor direct commercial advantage, the ACM copyright notice and the title of the publication and its date \nappear, and notice is given that copying is by permission of the Association of Computing Machinery.To \ncopy othetwise, or to republish, requires a fee and/or specific permission. SIGPLAN 95La Jolla, CA USA \n0 1995 ACM 0-89791 -697-2/95/0006 ...$3.50 operations for managing regions. Thus, there is no need for \na garbage collector all memory allocation and deallocation is statically specified in the program, The \nsystem in [TT94] makes surprisingly economical use of memory. However, it is usually possible to do signifi\u00adcantly \nbetter and in some cases dramatically better than the Tofte/Talpin algorithm. In this paper, we present \nan extension to the Tofte/Talpin system that removes the restriction that re\u00adgions be stack allocated, \nso that regions may have arbitrar\u00adily overlapping extent. Preliminary experimental results sup\u00adport our \napproach. Programs transformed using our analysis typically use significantly less (by a constant factor) \nmem\u00adory than the same program annotated with the Tofte/Talpin system alone. We have also found that for \nsome common programming idioms the improvement in memory usage is asymptotic. The memory behavior is \nnever worse than the memory behavior of the same program annotated using the Tofte/Talpin algorithm. \nIt is an open question to what degree static decisions about memory management are an effective substitute \nfor runtime garbage collection. Our results do not resolve this question, but we do show that static \nmemory management can be sig\u00adnificantly better than previously demonstrated. Much previ\u00adous work has \nfocussed on reducing, rather than eliminating, garbage collection [HJ90, Deu90]. The primary motivation \nfor static memory management put forth in [TT94] is to re\u00adduce the amount of memory required to run general \nfunc\u00adtional programs efficiently. Two other applications interest us. First, the pauses in execution \ncaused by garbage collec\u00adtion pose a difficulty for programs with real-time constraints. While there \nhas been substantial work on real-time garbage collection [DLM+78, N093], we find the simpler model of \nhaving no garbage collector at all appealing and worth inves\u00adtigation. Second, most programs written \ntoday are not written in garbage-collected applicative languages, but rather in pro\u00adcedural languages \nwith programmer-specified memory man\u00adagement. A serious barrier to using applicative languages is that \nthey do not always inter-operate easily with procedu\u00adral languages. The interoperability problem is due \nin part to the gap between the two memory management models. We expect that implementations of applicative \nlanguages with static memory management would make writing components of large systems in applicative \nlanguages more attractive. Our approach to static memory management is best illus\u00adtrated with an example. \nWe present the example informally; the formal presentation begins in Section 2. Consider the fol\u00adlowing \nsimple program, taken from [TT94]: (letz= (2,3) in~y. (fstz, ~) end) 5 The source language is a conventional \ntyped, call-by-value lambda calculus; it is essentially the applicative subset of ML [MTH90]. The annotated \nTofte/Talpin system is: program produced by the Example 1.1 letregion p4, p5 in Ietregion p6 in let~ \n= (2~~2,3~~6)0~4 (Ag. (fst z,y)Qpl)@p~ end in end end 5 Qp3 There are two kinds of annotations: letregion \np i.n e binds a new region to the region variable p. The scope of p is the expression e, Upon completion \nof the evaluation of e, the region bound to p and any values it contains are deallo\u00adcated. The expression \ne(lp evaluates e and writes the result in p. All values includlng integers, pairs, and closures\u00adare stored \nin some region.1 Note that certain region variables appear free in the expression; they refer to regions \nneeded to hold the result of evaluation. The regions introduced by a 1e tregi on are local to the computation \nand are deallo\u00adcated when evaluation of the 1 e tregi on completes. The solid lines in Figure lC depict \nthe lifetimes of regions with respect to the sequence of memory accesses performed by the annotated program \nabove. Operationally, evah~at\u00ading the function application first allocates the regions bound to p4, p5, \nand p6. Next the integer 2 is stored (in the re\u00adgion bound to pz), then the integer 3 (in pal), the pair \nz (in P4), and the closure AY. . . . (in p5). At this point, the inner letregion is complete and p6 is \ndeallocated. Evaluating the argument of the function application stores the integer 5 (in p3). Finally, \nevaluating the application itself requires re\u00adtrieving the closure (from P5), retrieving the first component \nof z (from p4), and constructing another pair (in pI ). In the Tofte/Talpin system, the let region construct \ncombines the introduction of a region, region allocation, and region deallocation. In our system, we \nseparate these three operations. For us, 1 et ~egi on just introduces a new, l(ex\u00adically scoped, region \nvariable bound to an unallocated re\u00adgion. The operation al loc_bef ore p e allocates space for the region \nbound to p before evaluating e, and the operation f ree.af t er p e deallocates space assigned to the \nregion bound top after evaluating e. The operations f reebe f ore and al 1 oc.a f t er are defined analogously. \nThe problem we address is: given a program annotated by the Tofte/Talpin system, produce a completion \nthat adds allo\u00adcation/deallocation operations on region variables. Figure 1a 1We axsumesmatl integers \nnre boxed to make the presentation simple and uniform. In practice, smatl integers can be unboxed. shows \nthe most conservative legal completion of the exam\u00adple program. Each region is allocated immediately \nupon en\u00adtering and deallocated just before exiting the region s scope; this program has the same region \nlifetimes as the Tofte/Talpin annotated program above. The alloclrefore p and free-aft er p annotations \nmaybe attached to any program point in the scope of p, so long as the region bound to p actu\u00adally is \nallocated where it is used. In addition, for correctness it is important that a region be allocated only \nonce and deallo\u00adcated only once during its lifetime. Within these parameters there are many legal completions. \nFigure 1b shows the com\u00adpletion computed by our algorithm. There is one new opera\u00adtion f ree-app. In \nan application el e2, the region contain\u00ading the closure can be freed after both el and e2 are evaluated \nbut before the function body itself is evaluated. This point is not immediately before or after the evaluation \nof any expres\u00adsion, so we introduce f ree-app to denote freeing a region at this point. The dotted lines \nin Figure Ic depict the lifetimes of re\u00adgions under our completion. This particular completion is optimal \nspace for a value is allocated at the last possible moment (immediately prior to the first use of the \nregion) and deallocated at the earliest possible moment (immediately af\u00adter the last use of the region). \nFor example, the value 30p6 is deallocated immediately after it is created, which is cor\u00adrect because \nthere are no uses of the value. While an optimal completion does not always exist, this example does \nillustrate some characteristic features of our algorithm. For example, space for a pair ideally is allocated \nonly after both compo\u00adnents of the pair have been evaluated the last point before the pair itself is \nconstructed. Similarly, at the last use of a function its closure is deallocated after the closure has \nbeen fetched from memory but before the function body is eval\u00aduated. These properties are not special \ncases they follow from the general approach we adopt. For any given program, our method produces a system \nof constraints characterizing all completions. Each solution of the constraints corresponds to a valid \ncompletion. The con\u00adstraints rely on knowledge of the sequence of reads and writes to regions. Thus, \nthe constraints are defined over the pro\u00adgram s control flow. However, because of higher order func\u00adtions, \ninferring control flow from the syntactic form of the program is difficult. A well-known solution to \nthis problem is closure analysis [Ses92], which gives a useful approxima\u00adtion to the set of possible \nclosures at every application. Our algorithm consists of two phases. We begin with the Tofte/Talpin annotation \nof a program. In the first phase, an extended closure analysis computes the set of closures that may \nresult from evacuating each expression in every possi\u00adble region environment (Section 3). In the second \nphase, lo\u00adcal constraints are generated from the (expression, region en\u00advironment) pairs (Section 4). \nThese constraints express facts about regions that must hold at a given program point in a given context. \nFor example, if an expression e accesses a region z, there are constraints such as z must be allocated \nsometime before the evaluation of e and z must be deallo\u00adcated sometime after the evaluation of e. letregionp4, \np5 in alloc J2eforep4 free.afterpd alloc_beforeps free.afterps letregionpG in alloC_befoKepb free.afterpfi \nIetx = (2~pz,3~pG)@pd in (Ay. (fst z,y)@pl)@p5 end end 5@p3 end (a) The example with explicit region \nallocation/deallocation operations. letregion p4, p5 in free.app p5 ~etregion p6 in let ~ = (2@p2, allot.afterpd \nalloc_before pG free.after pd 3@pG)@p4 in allot-before p5 (Ay. ( free_after p4 fst z,y) @pI ) @p5 end \nend 5@p3 end (b) The example with the optimal explicit region allocation/deallocation operations. .,. \n. p6 .................. P5 ............ .!.,.. .................. P4 operation write write write \nwrite write read read write value 2 3 x (apair) ~y 5 Ay x pair region pz p6 P4 P5 P3 P5 P4 PI region \nlifetimes in program (a) .................................... region lifetimes in program (b) (c) Graph \nof region lifetimes with respect to the sequence of memory operations. Figure 1: An example comparing \nstack vs. non-stack region allocation. A novel aspect of our algorithm arises in the resolution of the \nconstraints. As one might expect, solving the constraints yields an annotation of the program, but finding \na solution is not straightforward. Some program points will be, in fact, un\u00adder constrained. For example, \nin the program in Figure 1, the initial constraints specify that the region bound to P5 must be allocated \nwhen Ay . . . is evaluated, but there is no constraint on the status of the region bound to p5 prior \nto the evaluation of Jy. That is, we must choose whether ps is allocated prior to the evaluation of ~y \nor not there are legal completions in both scenarios. Given the choice, we prefer that P5 not be al\u00adlocated \nearlier to minimize memory usage; this choice forces the completion al loc_be f ore p5 Ay . . .. Adding \nthe con\u00adstraint that p5 is unallocated prior to evaluation of Ay affects the legal completion in other \nparts of the program. Thus, our algorithm alternates between finding choice points and constraint resolution \nuntil a completion has been constructed. This structure is unusual among program analysis algorithms \nand may be of independent interest. An outline of the soundness proof is presented in Section 5. Detailed \ndiscussion and measurements of the behavior of our algorithm are presented in Section 6. Section 7 concludes \nwith a discussion of practical issues.  2 Definitions The input to our analysis is a program annotated \nby the Tofte/Talpin algorithm. The syntax of such programs is e ::= x IAx.e@pl el e~ I f[~]@p I let x \n= elin e2 end I letrec f[@](z)Qp = el in e2 end I letregionp ine end Other operations, such as pairing \nand selection, are omit\u00adted for brevity. The language includes region polymorphic functions functions \nthat take regions as arguments. Region polymorphism allows each invocation of a recursive function to \noperate on different regions, which is important for achiev\u00ading good separation of region lifetimes [TT94]. \nThe Tofte/Talpin annotations are derived using a rlon\u00adstandard type system. A type is a pair (r, p), \nwhere 7-indi\u00adcates the kind of value (integer, function, etc.) and p refers to the region where values \nof the type are stored. The determi\u00adnation of region scope is made by tracking the effect of an ex\u00adpression, \nwhich is the set of regions the expression may read or write when evaluated, Types are defined by the \nfollowing grammar: T ::= intlp%fl ::= (T, p) P An object of the form ~.p is called an arrow eflect: \nit is the effect of applying a function of type p <v p . The e. is an effect variable which names the \neffect and is useful for type inference purposes. To the base language we add operations to allocate \nand free regions: .. e .. . . . \\ alloc_beforepe I allot.afterp e I freebefore p e I free-after p e \n\\ free.app p el e, The operational semantics of this language derives facts of the form s,n, rke-+a, \nst which is read in stores, environment n, and region environ\u00adment r the expression e evaluates to store \naddress a and new store s . The structures of the operational semantics are: RegionState = unallocated \n+ deallocated + (Offset 4 Clos + RegClos) Store = Region ~ RegionState Clos = Lam x Env x RegEnv RegClos \n= RegionVar* x Lam x Env x RegEnv Env = Var ~ Region x Offset RegEnv = RegionVar ~ Region A store contains \na set of regions .ZI, X2, . . .. A region has one of three states: it is unallocated, deallocated, or \nit is al\u00adlocated, in which case it is a function from integer offsets 01,02, . . . within the region \nto storable values. A region can hold values only if it is allocated. Note that regions are not of fixed \nsize a region potentially holds any number of val\u00adues, A region environment maps region variables pl, \npj, . . . to regions. A vector of region variables is written $. In this small language, the only storable \nvalues are ordi\u00adnary closures and region polymorphic closures. Ordinary closures have the form (Ar.e@p, \nn, r), where Ax,e@p is the function, n is the closure s environment, and r is the closure s region environment. \nA region polymorphic closure has addi\u00adtional region parameters. The set of kr.e@p terms is Lam; the @p \nannotation is elided when it is clear from context or unneeded. Figure 2 gives the operational semantics. \nAn address is a (region, o~set) pair. Given an address a = (z, o), we gener\u00adally abbreviate s(z) (o) \nby s(a). All maps (e.g., environment, store, etc.) in the semantics are finite. The set Dom(f) is the \ndomain of map f. The map ~[z + v] is map j modified at argument z to give v. Finally, ~ Ix is map ~ with \nthe domain restricted to X. The semantics in Figure 2 enforces two important restric\u00adtions on regions, \nFirst, the semantics forbids operations on a region that is not allocated; reads or writes to unallo\u00adcated/deallocated \nregions are errors. Second, every region in\u00adtroduced by a 1 e t regi on progresses through three stages: \nit is initially unallocated. then allocated, and finally deallo\u00adcated. For example, the [ALLOCBEFORE] \nrule allocates a previously unallocated region before the evaluation of an ex\u00adpression. Only one representative \nof each of the allocation and deallocation operations is presented in the semantics; the others are defined \nanalogously. An example illustrates the (LETRECj and [REGAPP] rules. Consider the following program: \nExample 2.1 letregion pI, p2, p3 in let i = l@pl, j = 2@pz in letrec f[p5, p6] (k : (int, p5)) @p3 = \nletregion p7 in (k+ (1~~7)) ~P6 end in (.f[~l,/74]~~0 ~ + ~[P2,p4]~p0 j) ~p4 end end end In this program, \nnested let and letregion constructs are abbreviated. To make the example interesting, we use con\u00adstructs \noutside the minimal language presented above. The expression i@p stores integer i in the region bound \nto p; the expression (el + e2) @p stores the sum of el and ez in the region bound top. Region allocationldeallocation \noperations are omitted for clarity. In Example 2.1, letrec ~[ps, pG] ( k ) ~ps = . . . stores a new region \npolymorphic closure at a fresh address a in the region bound to p3. Next, the expression (~(pl, p4] @p. \ni + f[Pz, m] @@o~) @P4 iS evaluated in an environment~ where n(~) = a. A region application f[pl, p4] \n@p. creates an or\u00addinary closure (stored at the region bound to po) with formal region parameters ps \nand pG bound to the region vahtes of pl and p4 respectively. When applied to the argument i (in pI ), \nthe result is stored in p4. The closure resulting from f [PZ, PA] expects its argument in p2 instead. \nRegion polymorphism al\u00adlows the function f to take arguments and return results in different regions \nin different contexts. n(z) =a [VAR] s,n, rt-x-+a, s n(f) = a s(a) = (~, Ax.e, no, ro) o g Do?n(s(?fp \n))) a = (r(p ), o) [REGAPP] c = (Az.e, no, roIF+-T(7)]) s,n, T} f[@ ]@p + a , s[a +c] o@ Dom(s(7-(p))) \na=(r(p), o) [ABS] s,n, r } h.e@p -+ a,s[a + (Ax.e, n,r)] s,n, rtel+al, sl sl, n,r Fe2+a2, s2 .sZ(al) \n= (k.e, no,ro) [APP] .sZ,no[z +cu3],T-o Fe--+ a3, s3 s,n,~}elez+as,ss s,n, ~t-el--+al, sl sl,n[w+al],~l-ez \n+ az,sz [LET] s,n, rkletx=e1ine2 end -+a2, s2 0$2 Do7n(s(T(p))) n = n[f +-(r(p), o)] [LETREC]s[(r(p), \no) + (ji , Ax. el, n , r)], n , r F e2 + a, s s,n, r } letrec ~[~](z)@p = el in ez + a,s .z $ Dom(s) \nso = s [Z 4--unallocated so, n,r[p+z]+e-+al, sl [LETREGION] S1(z) = deallocated s,n, r t-letregionp \nine + al,sll~omt~) r(p) =z s(z) = unallocated so = S[z + {}] [ALLOCBEFOREJ so, n,rt-e+al, sl s,n, r + \nallot-beforep e -+ al, sl s,n, rte+al, sl ?-(p) = z S1 (z) is allocated S2 = S1[.z + deallocated  s,n, \nr F free-a fterpe A al, s2 Figure 2: Operational semantics. 178 3 Extended Closure Analysis pletions. \nSecond, the completion of a function body depends [z]R = [d Rim(.) [k.e @p] R = {(k.e @ p, R)} [e, ez] \nR for each (Axe Q p, R ) E [cl] R [e] R ~ [el e2] R [e2] R ~ [z] R [let z=el ine2[ R = [ez]R [el] R \n~ [Y] R [letrec j[pI,.. .,h](~)~p=el ine2JR = [ez] R [fb! . . .P~] @P :[ R = {(~xe @ P > (%(f))kh + W)])} \nwhere letrecj[pl, . . ..pn](x)@p = e . . . [letregion p in en R = [e] R[p + c] where c is a color not \nin R Figure 3: Region-based closure analysis. strongly on the context in which the function is used; \ni.e., de-In reasoning about the memory behavior of a program, it termining legal completions requires \na global program analy\u00adis necessary to know the order of program reads and writes sis. Third, to obtain \naccurate completions, we require precise of memory. Closure analysis approximates execution order aliasing \ninformation. Approximate or may-alias information in higher-order programs [Shi88, Ses92]. However, closure \ndoes not permit the allocation or deallocation of a region. analysis alone is not sufficient for our \npurposes, because of Our solution to these problems is to distinguish for each problems with state polymorphism \nand region aliasing (see expression e the region environments in which e can be eval\u00adbelow). Imprecision \nin state polymorphism gives poor com-uated. We define [e] R to be the set of values to which e may pletions, \nbut failure to detect aliasing may result in unsound evaluate in region environment R. Including region \nenviron\u00adcompletions. ments makes region aliasing explicit in the analysis. Since Consider again the program \nin Example 2.1. Note that, the only values are closures, [e] R is represented by sets of within the body \nof the function f, the + operation is always abstract closures { (kc.e @p, R )}, which intuitively denotes \nthe last use of the value k in p5. Thus, it is safe to deallocate closures with function kr.e and region \nenvironment R . the region bound to P5 inside the body off after the sum: Since each let region introduces \na region, the set of re\u00adgion environments is infinite, We use a finite abstraction of Ietrec f[~5,~6](k) \n~ ~3 = letregion p7 in region environments, mapping region variables to colors. A free-afterp5 ((k + \n(1 ~ p7)) @ p6) end . . . color stands for a set of runtime regions. An abstract region environment \nR has a very special property: R maps two re-Now consider the two uses of j in the body of the let rec \nin Example 2.1. With this completion, the region bound to PI. is gion variables to the same color iff \nthey are bound to the same region at runtime. Thus, an abstract region environment pre\u00adallocated (not \nshown) when ~ [pl, p4] a is evaluated, and deal\u00adlocated when ~[p2, p4] b is evaluated. Thus, to permit \nthis serves the region aliasing structure of the underlying region completion the analysis of ~ must \nbe polymorphic in the state environment. (unallocated, allocated, or deallocated) of the region bouncl \nto The extended closure analysis is given in Figure 3. Fol-PI. If the analysis requires that the region \nbound to pl be in lowing [PS92], the analysis is presented as a system of con\u00adthe same state at all uses \nof ~, then in the body of ~, the saline straints; any solution of the constraints is sound. We assume \nregion (now bound to p5 ) cannot be deallocated. that program variables are renamed as necessary so that \neach Region aliasing occurs when two region variables in the variable is identified with a unique binding. \nWe write Vis(x) same scope are bound to the same region value. There is no for the set of region variables \nin scope at Ietrec z[~](y) =, aliasing in Example 2.1 as written. However, if the expres-let z =, orkc. \nsion f [pa, m] is replaced by ~ [PZ, PZ], then region paranle-The rule for letregion introduces a new \ncolor c not ters p5 and pG of ~ are bound to the same region. In this sce-already occurring in R. A distinct \ncolor is chosen because nario, it is incorrect to deallocate the region bound to p5 as letregion allocates \na fresh region, distinct from all exist\u00adshown above, since the result of the call to ~ (stored in the \ning regions. To make the analysis deterministic, colors are same region, but bound to Pci) is deallocated \neven though it ordered and the minimal color is selected. There can be no is used later. This example \nillustrates three points. First, re-more colors than the maximum number of region variables gion aliasing \nmust be considered in determining legal com-in scope at any point in the program. Thus, the set of abstract \nregion environments is finite, which ensures that the closure constraints have a finite solution. From \nthe extended closure analysis, it is possible to derive an ordering on program points. For example, in \nan applica\u00adtion el e2 within region environment R, first el is evaluated, then ez, and finally one of \nthe closures in [e] R. This ordering plays a central role in computing completions. 4 Completions Legal \ncompletions with explicit allocatiotddeallocation oper\u00adations are expressed as a system of constraints. \nThis section describes the constraint language, constraint generation, and constraint resolution, Constraint \ngeneration is a function of the input expression, the Tofte/Talpin types, and the result of the extended \nclosure analysis. 4.1 Definitions At each program point, every region in scope is in one of three states: \nunallocated (U), allocated (A), or deallocated (D). With each program point, abstract region environment, \nand color is associated a state variable ranging over {V, A, D}. State variables record the state of \neach region in the range of an abstract region environment at a program point. State vari\u00adables are associated \nwith regions (colors) rather than region variables because region variables may be aliased. Since the \nevaluation of an expression e may allocate/deallocate re\u00adgions, a region state may be different before \nand after the evaluation of e. Thus, there are program points in and out for each expression e. We group \nstate variables together into state vectors S; ~ and ~B associated with every exPression e and region \nenvironment R. We refer to state variables by indexing state vectors with a color c, as in S~,R [c]. \nConstraints are placed on individual state variables in a state vector. There are three kinds of constraints: \n(1) alloca\u00ad tion constraints, (2) choice constraints, and (3) equality con\u00ad straints: ~=A (1) (31, cp, \ns2)a (2) (%, %,s2)d s~= S2 (3) Allocation constraints are placed at program points where values are read \nfrom or written to a region; they express that a region must be allocated at this point. Choice constraints \nare either allocation triples or deallo\u00ad cation triples. An allocation triple expresses a relationship \nbetween two state variables S1, sz and a boolean variable CP: (C, +( S,= UAS, =A))A(TCP+S, =S2) The boolean \nCPencodes whether or not the associated region is to be allocated at program point p. If CP= true the \nregion state prior to the allocation point is U and afterwards A, i.e. allocation. If CP = false, then \nthe state prior is equal to the state after, i.e. no allocation. This approach is similar in spirit to \nthe coercions of [Hen92]. The definition of deallocation triples is analogous: Finally, equality constraints \nexpress that the state of a re\u00adgion is the same at two program points. 4.2 Constraint Generation Constraint \ngeneration produces all constraints necessary to guarantee that regions are allocated when they are accessed. \nThis task involves placing allocation constraints wherever re\u00adgions are read or written, as well as linking \nthe in and out states of each subexpression with the corresponding program points in the enclosing expression. \nChoice constraints are in\u00adtroduced at possible allocation or deallocation points and link the region \nstates before and after the choice point. What are the possible allocation and deallocation points? Every \nprogram point is a potential allocation or deallocation point for region variables that appear in the \noverall effect at that program point. Recall that the effect of e is the set of region variables possibly \nread or written during evaluation of e. The overall effect of an expression e is defined to be the arrow-effect \n(see Section 2) of the enclosing abstraction plus any let region-bound variables inside the abstraction \nand in scope at e. We restrict the set of regions allowed to change state (be allocated or deallocated) \non entry or exit of e to be regions in the overall effect of e. This restriction is crucial to the correctness \nof our system. A potential allo\u00adcation (resp. deallocation) point is indicated by the syntax a.lloC_bef \nore CPe (resp. f ree~ef ore CPe), where CP is the boolean variable associated with the allocation (resp. \ndeallocation) point. Prior to constraint generation, all poten\u00ad tial alloc_before, free.after expressions \nare added to the input program. We briefly explain the constraint generation rules in Fig\u00ad ure 4. Constraints \nare generated as a function of the in and out state vectors of each expression e, the current abstract \nregion environment R, and the overall effect ~0 at e. The notation R(p) is the pointwise union of R(p) \nfor p 6 w giving the set of colors in an effect. The rule for variables says that the state of regions \nin the overall effect is unchanged by a vari\u00adable reference. No allocation constraint is needed, because \nno regions are read or written. In the abstraction rule, we place an allocation constraint on the region \nwhere the closure is written. Furthermore, as in the variable rule, the states of all regions in the \noverall effect are the same on input and output of the abstraction expression. The color C.,R in the \nletregion rule is the color chosen for p by the extended closure analysis in the same context. Regions \nmay change state only at potential allocation and deallocation points. The al 1 oc-.be f ore rule connects \nthe states of regions bound to p between the input states of e and el with an allocation triple. The \nstate of all other re\u00adgions cannot change. A key point is that allocation triples generated from the \nsame potential allocation point, but in dif\u00adferent region environment contexts, share the same boolean \n e = Ax.el@p --+ Sfl,~[R(p)] = A and Vc 6 R(pO). S;,~[c] = S~~[c] e = f[~ ]@p --+ S;, JR(p )] = A S;,~[R(p)] \n= A, where (T, p) is the type of ~ de c l?(po). S;,R[C] = ~R[c] e=ele.2 --+ Vc G R(pO). S~,~ [c] = S~l \n,R[C] Vc e R(y90). ~;,~[c] = S:2,R[C] let (V1 c~$&#38;2, p) be the type of el S~,JR(p)] = A for all (ku.eo, \nR ) E [cl] R, with type (pj ~ P!, p) B = R(p) = R (q ) C=R(pO) B Vc s B. Y;;,~ [c] = fl;o,RI [c] A %:,RI \n[c] = %:R[c] VCEC. W .2,R[C] = SyR[c] e=letx=elinez Vc c R(p.). S~,~[c] = S;l,RIC] Vc E R(wO). ~;,~[C] \n= S$2,R[C] b c E R(po). ~;,R[C] = S~R[c] e = letrec f[j71(z)@p = el in ez e = letregionp inel R = R[p \n+-c,,R] S;l,R, [G?,R] = u ~;,~, [c@] = ~ Vc ~ R(pO). L&#38;[c] = S;l,R, [C] Vc e R(po). S&#38;,RJ [c] \n= S~~[c] e = allocJ3efore p ce el Vc C (R(wO) {R(p)}). s~,~[c] = S~l ,~[c] Vc ~ R(po). ~;,R[c] = ~~[c] \n(S$JR(p)], C,, S:l,~[R(p)])@ e = free-after p Ceel Vc C R(yO). S;,R[C] = s~l,~[c] Vc C (R(pO) R(p)). \n~;,R[c] = s;~[c] (S~,~[R(p)], C., S~~[R(p)]), Figure 4: Constraint generation rules. 56,1 ~6,2 = A s6,3 \ns6,4p6 S5,1 S5,2 S5,3 S5,4 = A .s5,5 s5,6 = A S5,7 $5,sP5 S4,1 S4,2 S4,3 = A S4,4 S4,5 s4,6 s4,7 = A \ns4,8P4 operation write write write write write read read write value 2 3 x (apair) Ay 5 Ay x pair region \nP2 p6 p4 P5 P3 P5 P4 PI Table 1: Example constraint resolution. 181 variable, which guarantees that the \ncompletion is valid in all contexts, Allocation/deallocation choice points for dif\u00adferent region variables \nare sequentialized to ensure that if two region variables are aliased (i.e. they map to the same color \nin the abstract region environment), at most one alloca\u00adtion/deallocation point is chosen. The application \nrule is the most difficult. The key idea is that at runtime, the regions in the arrow-effect of the function \nexpression el (call this set E), are the same as the regions in the effect of the closure. Therefore, \nthe states of regions in E in the caller s context prior to evaluation of the function body match the \nstates of regions in Eon entry to the function (and similarly on return). In the abstract region environments \nof the caller and callee, the colors of the effect of the call (set B) are equal, justifying equality \nconstraints between state vari\u00adables at the call site and in the input vector of the function body (similarly \non output). These equality constraints model the flow of regions from the caller into the function body \nand back. All regions a function touches appear in the function s effect. It is thus sufficient to place \nthe equality constraints only on state variables corresponding to colors from B. Other regions in the \ncaller s context (set C) are not touched in the the function body; the function is state-polymorphic \nin these regions. The set of possible closures in an application of a given region environment is computed \nby the extended clo\u00adsure analysis. For brevity, we do not describe the handling of quantified effect \nvariables (for details see [AFL95]). 4.3 Constraint Resolution In general, the constraint system has \nmultiple solutions. For example, the state of a region after the last use is unspecified. We may place \nthe point of deallocation of such a region any\u00adwhere after its last use, but obviously we prefer the \nfirst pos\u00adsible program point. The choice of whereto allocate (ordeal\u00adlocate) a region affects the states \nof regions in other parts of the program. Therefore, it is necessary to iterate solving con\u00adstraints \nand choosing allocationldeallocation points based on the partial solutions. Recall Example 1.1. Consider \np5 and the control flow path from the point PI, where the lambda abstraction is stored in the region \nbound to p5, to the point pz, where it is retrieved to perform the application. Clearly the region bound \nto PS must be allocated both at P1 and PZ. Because the language semantics forbid the region to change \nfrom the deallocated state to the allocated state, we can conclude that on all control paths from PI \nto PZ, it must be allocated. The constraints are simple first-order formulas for which resolution algorithms \nare well-known. There is, however, the issue of deciding which solution to choose; clearly some completions \nare better than others. We illustrate our resolu\u00ad tion algorithm with an example. Refer again to the \nexample in Figure 1. Table 1 shows the state variables associated with PA,p,5,PG. Assume that we have \nadded allocation triples between all consecutive pro\u00adgram points for colors bound by p4 p6, with associated \nboolean variables Ci,j, meaning a possible allocation of pi just after state s~,l. Table 1 contains \nexplicit allocation constraints on states where regions are accessed. We must have SS,5 = A because it \nlies on an execution path between two states where the re\u00adgion bound tops is allocated. The same holds \nfor $Lt,&#38;b. We also set all allocation choice points cG,z 4, cs,d g, and cA,&#38;s to false, because \nthe regions must be allocated before these program points are reached. At this point we have proven all \nfacts derivable from the initial constraints-nothing forces other states to be unallocated, allocated, \nor deallocated. We can now choose to set any boolean variable CPof an allocation triple (sl, CP,s2)a \nto true, if the variable Cpis not constrained. Among the possible choices, we are particularly interested \nin allocation points lying on the border of an unconstrained state and an allocated state, i.e., allocation \ntriples (sl, CP,S2) ~ where: S1 is unconstrained A S2 = A By the definition of an allocation triple, \nchoosing CP = true forces S1 = U, The state U is propagated to earlier program points, since the region \ncan be in no other state there. In the example, we choose C5,3 = true, set S5,3 = U, and propa\u00adgate U \nbackwards through S5,2 1 to the 1 et region for p5. Similarly, we choose Ctj,l = true and cd,z = true. \nIn general, given a constraint system C, we first prove all facts CEs=Xand CFs#Ximpliedby C. If C~s=X \nand C Y s # X, then we are free to choose eithers = X ors # X. This procedure repeats, proving facts \nand making choices, until a complete solution is constructed. Any solution of the constraints specifies \na completion of the program, where allocate/deallocate operations are added for the boolean variables \nCPthat are true in the solution. The constraints have a trivial solution, obtained by choosing for each \nregion the first allocation choice point and the last deal\u00adlocation choice point inside the corresponding \nlet region. This most conservative completion has exactly the same memory behavior as the original Tofte/Talpin \nprogram (e.g. Figure la).  5 Soundness This section states a soundness theorem for our system and sketches \nthe proof. The soundness theorem is formulated as follows. Assume that s, r, n K e ~ a, s , and assume \nthat [e] R = V is the result of the extended closure analysis fore, where R is an abstraction of the \nregion environment r. As\u00adsume further that the regions of the overall effect pO mapped by r in store \ns are initially in the states given by S;,R. The theorem shows that the evaluation of e leaves these \nregions in the states specified by CR. To prove this theorem we first state the relationship betwe&#38;n \nthe concrete semantics and our abstraction. For the proof concrete regions in the operational semantics \nare colored the same way as in the extended clo\u00adsure analysis. We use capital letters for abstract entities \nand lowercase letters for concrete entities, ZCdenotes a concrete region with color c,s is a concrete \nstore, and S : StateVar s {U, A, D} is the solution of the constraints. We say a concrete region environment \nr satisfies an ab\u00adstract region environment R if they have the same domain and aliasing structure. T \nsat R ~;f Dom(R) = Dom(r) A R(p) =R(p ) -r(p) =r(p )A R(p)=c e r(p)=zc A store .sand address a satisfy \na set of abstract values V, if V contains an abstraction of the concrete value stored at address a in \ns, and the environment of the concrete closure satisfies the extended closure analysis [.]. s,a sat V \nAf address ais allocated ins =+ s(a) = (~z.e, r , n )A il(k-z.e, R ) e V s.t, s,r , n sat R , [.] A \nstore s, concrete region environmentr, and concrete value environment n satisfy an abstract region envircm\u00adment \nRand theextended closure analysis [.], ifthe region environments match and for every variable z in the \nconcrete environment, [z] R contains an abstraction satisfying the concrete value. s,r, nsat R,[. ]%f \nrsat RA V(z e Dom(n))3R s.t. (Rl~O~(~,) = R A s, n(z) sat [z] R ) A store s and a concrete region .zCwith \ncolor c satisfy a state variable Se,R [c] if the state of the region ,zCin the stores corresponds to \nthe solution for S,,R [c]. def S,Zc sat se,R) CE .zC c Dom(s) =+ state(s, ZC) = S(Se,R[c]) Finally, \na states and concrete region environment r sati:sfy an abstract region environment R, state vector S.,R, \nand ef\u00adfect set p if T and R match and the states of all regions in p match the solution of the constraints \nfor Se,R. s,r sat R, Se,R, p ~f p ~ Dom(R) A rsat RA V(p e p) $, r(p) sat S,jR, R(p)  The soundness \nof our analysis is summarized by Theo\u00adrem 5.1. Theorem 5.1 Given that s,r, n~e+a, s [e]R=V s,r, nsat \nR,[. j s,r sat RjS~R, pO we conclude s ,asat V .s , T sat R, ye ~, pO The proof is by induction on the \nstructure of e and is included in the full version of the paper [AFL95]. 6 Implementation and Experiments \nWe have implemented our algorithm in Standard ML [MTH90]. Our system is built on top of an implementation \nof the system described in [TT93, TT94], generously pro\u00advided to us by Mads Tofte. The implementation \nis extended with numbers, pairs, lists, and conditionals, so that non\u00adtrivial programs can be tested. \nFor each source program, we first use the Tofte/Talpin system to region annotate the program. We then \ncompute the extended closure analysis (Section 3). The next step adds allocation and deallocation choice \npoints and generates the allocation constraints (Sec\u00adtion 4). The constraints are solved and the solution \nis used to complete the source program, transforming selected choice points into allocation/deallocation \noperations, and removing the rest. Our annotations are orthogonal to the storage mode anal\u00ad ysis mentioned \nin [TT94] and described in more detail in [Tof94]. Thus, the target programs contain both storage mode \nannotations and the allocation annotations described in this paper. On the other hand, our analysis subsumes \nthe op\u00adtimization described in Appendix B of [TT94], so that opti\u00admization is disabled in our system. \nSummary performance measures are in Table 2. We have not measured carefully the time required to compute \nour analysis, but our method ap\u00adpears to scale as well as the Tofte/Talpin system. All of the examples \nwe have tried are analyzed in a matter of seconds by our system on a standard workstation. The target \nprograms were run on an instrumented inter\u00adpreter, also written in Standard ML/NJ. In addition to the \ndata above, we also gather complete memory traces, which we present as graphs depicting memory usage \nover time. While we have tested our system on many programs, nei\u00adther the size of our benchmarks nor \nthe size of our benchmark suite is large enough to draw meaningful statistical conclu\u00adsions. Instead, \nwe present representative examples of three typical patterns of behavior we have identified. A number \nof programs show asymptotic improvement over the Tofte/Talpin system. One example given in their paper \n(due to Appel [App92]), has 0(rz2 ) space complexity. Our completion of this program exhibits O(n) space \ncom\u00adplexity (Figure 5). In this program, our analysis is able to deallocate a recursive function s parameter \nbefore function evaluation completes. Because the Tofte/Talpin system en\u00adforces a stack discipline, it \ncannot reclaim function parame\u00adters that become dead part way through the activation of a function. Another \ntypical pattern is that our system has the same asymptotic space complexity as Tofte/Talpin, but with \na con\u00adstant factor improvement. Representative examples include Quicksort, Fibonacci, and Randlist. The \nmemory usage graphs are shown in Figures 6, 7, and 8, respectively. The measurements for the graphs were \nmade using smaller inputs than the experiments in Table 2; smaller problem sizes yield more readable \ngraphs. The Quicksort graph (Figure 6) has a curious feature: at times the memory usage drops below the \namount needed to store the list ! Our measurements count only heap memory Appel(100) Quicksort(500) Fibonacci(6) \nRandlist(25) Fac(lO) A-F-L T-T A-F-L T-T A-F-L T-T A-F-L T-T A-F-L T-T 25 (1) 208 1111 112 1520 15 20 \n12 90 25 (2) 81915 81915 45694 45694 190 190 289 289 66 66 (3) 101814 101814 65266 65266 190 190 363 \n363 66 66 (4) 306 20709 2509 8078 10 14 85 161 14 14 (5) 1 115021502 1 1 7777 1 1 (1) Maximum number \nof regions allocated (unit: 1 region) (2) Total number of region allocations (3) Total number of value \nallocations (4) Maximum number of storable values held (unit: 1 SV) (5) Number of values stored in \nthe final memory (unit: 1 SV)   Table 2: Summary of results, APpeI fibonacci 16 Tofte/Talpin, max = \n279 300 - A-F-L, max = 36 ------\u00ad 14 8 250 = 12 ~ .-c 200- 10 0 .!2 8 150 : 6 g 100 \u00ad24 50 - Ii I \n0 01 0 200 400 600 800 1000 1200 0 20 40 60 80 100 120 140 160 180 200 Time Time Figure 5: Memory usage \nin Appel example [App92] Figure 7: Memory usage in Fibonacci example (n = lU) (recursive$bonacci of 6). \n quick randlist 700 180 TofteiTalpin, max = 161 A-F-L, max = 85 ------\u00ad 600 160 A 140 \u00ad500 120 400 \n100 300 80\u00ad 60 200 40 b ,,w+\u00ad 100 20 #e,,. .. .-- v I n 0 o 500 1000 1500 2000 2500 3000 3500 4000 \n0 50 100 150 200 250 300 350 400 Time Time Figure 6: Memory usage in Quicksort example Figure 8: Memory \nusage in Randlist example (sort 50 element list of random integers). (generate 25 element list of random \nintegers}. usage, The evaluation stack is not counted, a measurement methodology consistent with [TT94]. \nQuicksort is not un\u00adusual in this behavior. The program recursively traverses its input list, stores \nthe contents on the evaluation stack, frees the list cells when it reaches the end, and builds up the \noutput list upon return. In the third class of programs our system has nearly the same memory behavior \nas Tofte/Talpin (e.g., the factorial function). This case arises most often when the Tofte/T alpin annotation \nis either already the best possible or very con\u00adservative. Conservative annotations distinguish few regions. \nBecause values in regions must be deallocated together, hav\u00ading fewer regions results in coarser annotations. \nOf course, the memory behavior of a program annotated using our algo\u00adrithm is never worse than that of \nthe same program annota~ted using the Tofte/Talpin algorithm. Our system is accessible for remote experimentation \nthrough the World Wide Web at: h.ktp: //kiwi . cs .~erlceley. edu/-nogc  7 Discussion and Conclusions \nIt remains an open question whether our system is a practi\u00adcal approach to memory management. The complexity \nof the extended closure analysis is worst-case exponential time. In practice, we have found it to be \nof comparable complexity to the Tofte/Talpin system, but we do not as yet have enough experience to judge \nwhether this holds in general. The ccm\u00adstraint generation and constraint solving portions of our arlal\u00adysis \nboth run in low-order polynomial time. A separate is\u00adsue is that the global nature of our analysis presents \nserious problems for separate compilation, which we leave as fu\u00adture work. Finally, we have found that \nstatic memory allo\u00adcation is very sensitive to the form of the program. Often, a small change to the \nprogram, such as copying one value, makes a dramatic difference in the quality of the completion. Thus, \nfor this approach to memory management to be prac\u00adtical, feedback to programmers about the nature of \nthe com\u00adpletion will be important. Our system does do a good job of finding very fine-grain, and often \nsurprising, memory management strategies. Re\u00admoving the stack allocation restriction in the Tofte/Talpin \nsystem allows regions to be freed early and allocated late. The result is that programs often require \nsignificantly less memory (in some cases asymptotically less) than when an\u00adnotated using the Tofte/Talpin \nsystem alone.  References [AFL95] Alexander Aiken, Manuel Fahndrich, and Raph Levien. Better static \nmemory management: Improving region-based analysis of higher-order languages. Tech\u00adnical Report CSD-95-866, \nUC Berkeley, April 1995, [App92] Andrew W. Appel. Compiling with Continuations. Cambridge University \nPress, 1992. [Deu90] Alain Deutsch. On determining lifetime and alias\u00ading of dynamically allocated data \nin higher-order func\u00adtional specifications. In Proc. of the 17th Annual ACM Symposium on Principles of \nProgramming Lunguages, pages 157-168, January 1990. [DLM+78] Edsger W. Dijkstra, Leslie Lamport, A.J. \nMar\u00adtin, C.S. Scholten, and E.F.M. Steffens. On-the-fly garbage collection: An exercise in cooperation. \nCom\u00admunications of the ACM, 21(11 ):966 975, November 1978. [Hen92] Fritz Henglein. Global tagging optimization \nby type inference. In Proc. of the 1992 ACM Conference on Lisp and Functional Programming, pages 205 \n2 15, hdy 1992. [HJ90] Geoff W. Hamilton and Simon B. Jones. Compile\u00adtime garbage collection by necessity \nanalysis. In Proc. of the 1990 Glasgow Workshop on Functional Program\u00adming, pages 66 70, August 1990. \n[MTH90] Robin Milner, Mads Tofte, and Robert Harper. The Definition of Standard ML. MIT Press, 1990. \n[N093] Scott Nettles and James O Toole. Real-time repli\u00adcation garbage collection. In Proc. SIGPLAN 93 \nCon\u00adference on Programming Lunguage Design and Imple\u00admentation, pages 2 17 226, June 1993. [PS92] Jens \nPalsberg and Michael I. Schwartzbach. Safety analysis versus type inference. Information Processing Letters, \n43(4): 175 1 80, September 1992. [RM88] Cristina Ruggieri and Thomas P. Murtagh. Lifetime analysis of \ndynamically allocated objects. In Proc. of the 15th Annual ACM Symposium on Principles of Pro\u00adgramming \nL.unguages, pages 285 293, January 1988. Ses92] Peter Sestoft. Analysis and Eficient Implementa\u00adtion \nof Functional Programs. PhD dissertation, Univer\u00adsity of Copenhagen, Department of Computer Science, \n1992. Shi88] Olin Shivers. Control flow analysis in Scheme. In Proc. SIGPLAN 88 Conference on Programming \nLanguage Design and Implementation, pages 164-174, June 1988. [Tof94] Mads Tofte. Storage mode analysis. \nPersonal com\u00admunication, October 1994. TT93] Mads Tofte and Jean-Pierre Talpin. A theory of stack allocation \nin polymorphically typed languages. Tech\u00adnical Report 93/1 5, Department of Computer Science, University \nof Copenhagen, July 1993. TT94] Mads Tofte and Jean-Pierre Talpin. Implementation of the typed call-by-value \nA-calculus using a stack of re\u00adgions. In Proc. of the 21st Annual ACM Symposium on Principles of Programming \nLanguages, pages 188 201, January 1994.  \n\t\t\t", "proc_id": "207110", "abstract": "<p>Static memory management replaces runtime garbage collection with compile-time annotations that make all memory allocation and deallocation explicit in a program. We improve upon the Tofte/Talpin region-based scheme for compile-time memory management[TT94]. In the Tofte/Talpin approach, all values, including closures, are stored in regions. Region lifetimes coincide with lexical scope, thus forming a runtime stack of regions and eliminating the need for garbage collection. We relax the requirement that region lifetimes be lexical. Rather, regions are allocated late and deallocated as early as possible by explicit memory operations. The placement of allocation and deallocation annotations is determined by solving a system of constraints that expresses all possible annotations. Experiments show that our approach reduces memory requirements significantly, in some cases asymptotically.</p>", "authors": [{"name": "Alexander Aiken", "author_profile_id": "81100399954", "affiliation": "Computer Science Division, Soda Hall, University of California, Berkeley, CA", "person_id": "P13911", "email_address": "", "orcid_id": ""}, {"name": "Manuel F&#228;hndrich", "author_profile_id": "81100288438", "affiliation": "Computer Science Division, Soda Hall, University of California, Berkeley, CA", "person_id": "P187043", "email_address": "", "orcid_id": ""}, {"name": "Raph Levien", "author_profile_id": "81100417436", "affiliation": "Computer Science Division, Soda Hall, University of California, Berkeley, CA", "person_id": "PP35029145", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/207110.207137", "year": "1995", "article_id": "207137", "conference": "PLDI", "title": "Better static memory management: improving region-based analysis of higher-order languages", "url": "http://dl.acm.org/citation.cfm?id=207137"}