{"article_publication_date": "06-01-1995", "fulltext": "\n Garbage Collection using a Dynamic Threatening Boundary David A. Barrett and Benjamin G. Zorn Department \nof Computer Science Campus Box #430 University of Collorado, Boulder 80309-0430 {barrett,zorn}@cs.Colorado.EDU \nAbstract Generational techniques have been very successful in reducing the impact of garbage collection \nalgorithms upon the perfor\u00admance of programs. However, all generational algorithms oc\u00ad casionally promote \nobjects that later become garbage, resulting in an accumulation of garbage in older generations. Reclaim\u00ading \nthis tenured garbage without resorting to collecting the entire heap is a difficult problem. In this \npaper, we describe a mechanism that extends existing generational collection al\u00adgorithms by allowing \nthem to reclaim tenured garbage more effectively, In particular, our dynamic threatening bound ary mechanism \ndivides memory into two spaces, one for short\u00adlived, and another for long-lived objects. Unlike previous \nwork, our collection mechanism can dynamically adjust the boundary between these two spaces either forward \nor back\u00adward in time, essentially allowing data to become untenured. We describe an implementation of \nthe dynamic threatening boundary mechanism and quantify its associated costs. We also describe a policy \nfor setting the threatening boundary and evaluate its performance relative to existing generational col\u00adlection \nalgorithms. Our results show that a policy that uses the dynamic threatening boundary mechanism is effective \nat reclaiming tenured garbage. htroduction Garbage collection is an effective programming language fea\u00ad \nture that has been used for many years in numerous languages. One successful enhancement to garbage collection \nalgorithms is the use of generational garbage collection [14]. By exploit\u00ad ing the empirical property \nthat the probability of a given object being garbage is higher for recently allocated objects than for \nolder objects [2, 10, 19, 21], generational collectors improve reference locality and collector efficiency \nby avoiding tracing older objects during most scavenges, The success of gener\u00ad ational collection algorithms \nis evinced by their commercial implementations in language environments that require auto\u00ad matic storage \nreclamation [1, 9]. Permission to copy without fee all or part of this material is granted provided that \nthe copies are not made or distributed for direct commercial advantage, the ACM copyright notice and \nthe title of the publication and its date appear, and notice is given that copying is by permission of \nthe Association of Computing Machinery.To copy otherwise, or to republish, requires a fee and/or specific \npermission. SIGPLAN 95La Jolla, CA USA @ 1995 ACM 0-89791 -697-2/95/0006,,, $3.50 Despite their success, \ngenerational collectors suffer from the tenured garbugeproblem. Specifically, all such algorithms occasionally \npromote objects that eventually become tenured garbage. Tenured garbage eventually needs to be reclaimed \nin some way, otherwise it will cause excessive memory con\u00ad sumption and an associated degradation in \nperformance due to decreased reference locality. The simplest solution to this problem is to occasionally \ncol\u00adlect all the older objects at a time when a long pause, possibly accompanied by many page faults, \nwill not be too disruptive. Another solution is to set the garbage collector s promotion threshold (i.e., \nthe age at which objects are promoted) to a fixed value that minimizes the tenured garbage. Unfortunately, \nboth identifying acceptable times for long pauses, and iden\u00adtifying an appropriate promotion threshold, \nvaries from one program run to the next and even during the lifetime of a single program, As a result, \nUngar and Jackson propose a method called~eedback mediation (FM) [17], which provides a partial solution \nto this problem by adjusting the promotion threshold for old objects based upon a pause-time constraint \nand ob\u00ad ject lifetime demographics. Their collector reduces tenured garbage by reducing the rate of object \npromotion. However, once objects are promoted using their method, the problem of reclaiming them still \nremains. In this paper, we describe a mechanism that extends ex\u00adisting generational collection algorithms \nby allowing them to reclaim tenured garbage more effectively. In particular, our Dy\u00adnamic Threatening \nBoundary (DTs) mechanism divides mem\u00adory into two spaces, one for short-fived, and another for long\u00adlived \nobjects. Unlike previous work, our collection mechanism can dynamically adjust the boundary between these \ntwo spaces either forward or backward in time, essentially allowing data to become untenured. To implement \nthe DTB mechanism, all pointers that point forward-in-time must be recorded in the remembered set, unlike \nstandard generational collectors, where only forward-in-time pointers that cross the generation boundaries \nare recorded. In this paper, we measure the overhead of maintaining the DTB remembered set and the cost \nof processing it during collection. Our measurements of allocation-intensive C programs indi\u00adcate that \nthe space overhead of the DTB ranges from 4-15% of the maximum storage required by the program, while \nthe CPU overhead of maintaining the DTB ranges from O-7% of total execution time (as measured by the \nnumber of instruc\u00adtions executed). We feel that the techniques proposed will be most successful in two \nclassesof languages: languages where pointers tend to account for a small fraction of the total mem\u00ad \nory allocated, and languages where most pointers do not point forward-in-time (i.e., where programs perform \nfew destructive update operations, such as Standard ML). Our measurements in Section 5 indicate that \nC may belong in the first category. Once the dynamic threatening boundary mechanism is available, it \nprovides significant flexibility to the collector im\u00ad plementation and clearly separates issues of policy \nfrom imple\u00ad mentation. In this paper, we investigate one policy, using the DTB mechanism, that attempts \nto reduce a program s tenured garbage. Our policy extends Ungar and Jackson s feedback mediation policy \nby taking advantage of the flexibility pro\u00ad vided by the DTB. Our results show that this policy is more \nsuccessful than feedback mediation at reducing tenured gar\u00ad bage and results in smaller program heaps \nwhen such tenured garbage exists, even when the additional space overhead of maintaining the DTB is taken \ninto account. 2 Related Work Generational algorithms [14, 15, 16] have proven successful at reducing \nthe pause times and page fault rate of garbage col\u00adlection [4, 6, 16]. Our work is based upon a formalization \ndeveloped by Demers et al [6]. Their generational Collec\u00adtor II used a threatening boundary to divide \nmemory into a threatened space for new objects, and an immune space for old objects, which were collected \nless frequently. To com\u00adpare against non-generational algorithms, their collector mod\u00adeled only classic \ngenerational collection by always setting the threatening boundary to the time of the previous collection, \nMore recently, these authors have received a software patent covering their ideas [18]. Our algorithm \nexpands upon theirs by using a new policy that dynamically adjusts the threaten\u00ading boundary to limit \nresource consumption. Furthermore, we quantify the cost of a dynamic threatening boundary and also quantify \nthe benefits in a collector that uses it. One important policy for all generational collectors is when \nto promote objects from threatened space to immune space. Typically objects are promoted only after a \nfixed number of collections, specified as one of the tuning parameters made available to the application \nprogrammer. Ungar and Jack\u00adson [17] found that object lifetime distributions vary from one program to \nthe next and often change as a program executes, showing that a fixed-age promotion policy will often \nbe in\u00adappropriate. Instead, their feedback mediation collector pro\u00admoted a number of objects only when \na pause-time constraint was exceeded. Their simulations showed feedback mediation was successful at limiting \npause times and indicated how mem\u00adory usage increased as the pause-time constraint was reduced. This \nincreased memory use, called tenured garbage, is caused by premature promotion of objects into the immune \nspace when the collector must maintain a given pause-time. Unlike their algorithm, ours reduces tenured \ngarbage by allowing objects to be demoted back into threatened space later when the collector pause-time \nfalls. Wilson and Moher s Opportunistic Collector [ 19] allocates objects created since the last collection \nin chronological order in memory. By selecting an appropriate address, only objects allocated since a \nspecific time may be selected for promotion. However, once their collector has reclaimed objects from \nthis new-object area, a different promotion policy must be followed because surviving objects are no \nlonger in chronological order. Our algorithm preserves the object s allocation time for all objects, \nnot just new ones, so ours may select ages among the surviving objects as well. Like generational collection, \nour algorithm uses age as an indicator of when objects are most likely to die, When age is not a reliable \nindicator of garbage other methods must be used, Hudson and Moss [13] describe a mature object space \nthat is collected incrementally based upon object connectivity rather than age. Likewise, Hayes [1 O] \nshows that when certain key objects die, they may indicate other unused ones as well. Like generational \ncollectors, ours could eliminate objects from age\u00ad based collection by promoting them to mature or key \nobject space, where they would be collected by other algorithms once they age enough. The DTB mechanism \nwe describe is an extreme case of a collection implementation that allows multiple generations (e.g., \n[5, 12]). As the number of generations grows to the number of live objects, the two concepts merge. From \nthis per\u00ad spective, our proposed collection policy (DTBd~) represents a policy to select which generation \nto coIlect. This previ\u00ad ous work has not quantified the overhead of maintaining large numbers of generations, \neither in terms of CPU cost or memory overhead. 3 The Dynamic Threatening Boundary Collector In this \nsection we describe the DTB mechanism and a policy for a collector that uses the it to reduce tenured \ngarbage. We first describe how it provides the capability to dynamically ad\u00adjust the boundary between \nold and new objects based upon the object allocation time. Next, we describe the new implemen\u00adtation \nissues raised by our mechanism. Then we discuss how the threatening boundary selection policy influences \ntenured garbage and pause times. Finally, we describe one policy that makes use of the DTB mechanism \nto trade available pause time for reduced tenured garbage. 3.1 The Dynamic Threatening Boundary Mechanism \nDemers et al [6] have provided a useful formal framework for modeling generational garbage collection \nalgorithms. As mentioned, their model partitions the object space into threat\u00adened and immune sets. Threatened \nobjects are those that the collector traces to find unreachable objects and reclaim them. Immune objects \nare ones that will not be traced on this collec\u00adtion. The selection criteria for these sets distinguishes \nvarious collection algorithms. Consider how a traditional generational collector selects its threatened \nand immune sets. The threatened set contains those objects that have survived fewer than a specified \nnumber of collections typically one or two [1, 9, 19]. The root objects and ali objects in older generations \nare immune. The threaten\u00ading boundary divides the young threatened objects from the old immune objects. \nEach time the garbage collector is invoked, its policy sets the threatening boundary to the time of the \nkth previous collection, where k is a small integer constant. Scav\u00adenging the kth older generation corresponds \nto temporarily choosing a threatening boundary to the age corresponding to the kth previous generation \nboundary. Generation boundaries simply constrain the set of allowable threatening boundaries. Our mechanism \neliminates generation boundaries. Instead, an explicit threatening boundaty is established at the begin\u00adning \nof each collection. This boundary allows the collector to be much more flexible in choosing policies \nfor selecting the threatened set, Generation O root c threatened mmune youn h I Age . . \\ Generation \n1 / old !J!J ,.Tf ,1 \\\\ 1.. , J I ,J:*.J k K root #\u00ad----\u00ad---\u00adn-r(1\u00ad1 ----\u00ad . . . . . . . . . . . . . \n. . :B n Figure 1: Dynamic Threatening Boundary vs Generations. -,I ne generational collector above \ndivides memory into two generations, one young and one old. A dynamic threatening boundmy collector adjusts \na threatening bomrdsuy that may move between scavenges, say from TEW j to TBm. Objects are shown ordered \nby birth time for exposition only; the actuat implementation may maintain object locations in any order. \nFigure 1 illustrates how the dynamic threatening boundary collector compares with other generational \ncollectors. This figure shows a memory space divided into two generations. Age proceeds from youngest \nobjects at the top of the page tctthe oldest at the bottom, whereas birth time increases in the olther \ndirection. Objects (in rectangles) are labeled in sequence by age. Arrows (labeled in lowercase), indicate \npointers between objects; heavy arrows indicate forward-in-time pointers. For a generational collector, \nonly pointer ~ must be re\u00adcorded by the remembered set for Generation O because other\u00adwise object F would \nbe incorrectly deallocated by a scavenge of Generation 0, While the garbage objects B and E wo,uld be \nscavenged, objects I, J, and F would no~ they are tenured garbage. Object F illustrates the phenomenon \nof nepotism: itremains alive even though it is threatened and unreachable because the tenured garbage \npoints to it. Notice that once promoted, tenured garbage requires a complete scavenge of its generation \nto be reclaimed, in this case, Generation 1. A non-generational collector always collects all generations \n;md so would collect all the garbage objects (B, E, F, 1, and .7) at the cost of tracing the entire memory \nspace. For a dynamic threatening boundary collector, a threat\u00adening boundary (shown by a dashed line \nat TBn_l ), divides the memory into threatened and immune spaces. Because the threatening boundary can \nbe changed at the beginning of each scavenge, all forward-in-time pointers must be maintained in a single \nremembered set (pointers a, d, k, and t). At scav\u00adenge time only pointers that cross the threatening \nboundary are traced (pointer d). On a later scavenge, the collector is free to set the new threatening \nboundary to any desired time, say at TBn. Unlike the generational collector, objects 1, .J and F become \nuntenured, and will be reclaimed. Object K remains alive because pointer k references it from the remembered \nset. 3.2 Implementing the DTB Mechanism In this section, we describe the implementation of the DTB mechanism. \nFirst, we state our assumptions; next we describe the implementation at a high level; and finally we \ndiscuss aspects of the implementation that are different from existing generational mechanisms. For the \npurpose of this discussion, we assume that we are implementing the DTB mechanism in the context of a \nnon\u00adcopying algorithm. This implies that objects are not relocated when collected and that the birth \ntime of an object cannot be encoded in its address (as is the case in most copying algo\u00adrithms). Thus, \nwe assume that every object has a birth time field associated with it that is set when the obiect is \nallocated and never modified. We also assume that a dat~ structure exists (the remembered set, which \nwe describe in detail below), that indicates the location of every forward-in-time pointer. That is, \nevery pointer stored in an object, 01, that points to an object, 02, such that the birth time of ol is \nless than the birth time of o~ (oz is younger than 01). To understand how the DTB mechanism works, suppose \nthat we are about to do a garbage collection and some policy has determined some specific threatening \nboundary. First, we augment the normal root set (i.e., registers and stack) with some of the elements \nin the remembered set. Specifically, we scan the remembered set and find all elements of it such that \nthe forward-in-time pointer from the set points from an object born before the threatening boundary to \nan object born after the threatening boundary, The augmented root set now contains pointers to all objects \nin the threatened set that are reachable from the root set or immune set. We transitively traverse these \nroots marking all reachable objects in the threatened set. To complete the collection, we must then sweep \nthe entire memory searching for unmarked objects that have a birth time later than the current threatening \nboundary, In practice, such a sweep can be deferred [20], reducing its performance impact. The remembered \nset is maintained by the write barrier. In particular, when a pointer is written into an object, the \nbirth time of the object being stored into and the birth time of the object being pointed to must be \ncompared. If the store creates a forward-in-time pointer, then its location must be recorded in the remembered \nset. The implementation of a dynamic threatening boundary mechanism relies mostly upon technology already \navailable for other generational collectors. Here we describe new imple\u00admentation issues raised by our \nmechanism and how they affect performance, These issues are maintaining object birth times, the effect \nof the remembered set on memory consumption, the write barrier, and scavenging. Object birth times must \nbe available in order to determine the threatened set and to allow the write barrier to maintain the \nremembered set. The most straightforward implemen\u00adtation maintains a word per object. In environments \nwhere many small objects are allocated, objects may be co-located into pages (or areas) sharing the same \nbirth time, Birth time may be chosen to be any appropriate metric of the granularity desired. One metric \ncorresponding closely to existing gener\u00adational collectors is the number of collections preceding the \nobject allocation, A finer grained metric might be the total number of bytes allocated before the object \nwas allocated. Typically, a remembered set is maintained for each gen\u00aderation except the oldest; since \nour mechanism has only two generations, and the boundary between them moves, it uses a single remembered \nset instead. Generational collectors record only forward-in-time pointers that cross generation boundaries \nwhereas ours records all forward-in-time pointers. Our remem\u00adbered set is larger; we show how much larger \nin Section 5. An inline write barrier maybe used to filter each eligible store instruction and insert \nforward-in-time pointers into a hash table. Eligible store instructions are those that can be statically \nexamined as possibly storing a pointer into the heap, For exam\u00adple, on the DEC Alpha under OSF1, we assume \nthat stores to displacements from the stack pointer or to unaligned addresses are ineligible and do not \nrequire inline filtering, Eligible stores must compare the birth time of the source and target objects. \nIf the target exceeds the source birth time, then the effective address of the store is inserted into \nthe remembered set. Our algorithm performs this remembered set insertion more often than other generational \ncollectors since we insert all forward\u00adin-time pointers rather than just those that cross the threatening \nboundary. We show examples of how much more in Section 5. Like all generational collectors, each element \nof the re\u00admembered set must be examined as an additional root during each scavenge. Our remembered set \nis larger, and we must perform an additional test to ensure we only trace objects that are born after \nthe current threatening boundary. In Section 5 we show how much our mechanism would increase CPU com\u00adpared \nto a traditional generational collector. 3.3 How Policies Affect Collector Performance The choice of \nthe threatening boundary affects both the CPU time spent scavenging and the memory wasted by tenured \ngar\u00adbage. For a given collection interval, a young threatening boundary results in short trace times \nat the expense of more tenured garbage. An older threatening boundary wastes more CPU time tracing more \nof the live objects, but saves memory because older unreachable objects are reclaimed sooner. Figure \n2 shows how these values are related. The vertical axis is storage consumed (in bytes) and the horizontal \naxis is execution time (CPU instructions executed). Consider how a full garbage collection behaves. Periodically, \nat time ti, a scavenge is triggered. The collector traces all the live storage and reclaims the rest. \nFor example, at time tl, lkfeml bytes of storage were in use before the scavenge; the collector traced \nl%acel bytes, which included all the live bytes L1. All the re\u00admaining bytes were reclaimed as shown \nby the curve dropping vertically to L 1 A generational collector scavenging at time tm-Iwould only trace \nobjects born after a fixed-age threatening boundary TBn-1. This results in shorter pause times due to \nless storage traced, Tracen_l, at the cost of more storage surviving, Sri-l. The difference between S~-1 \nand Ln 1 is the tenured garbage. At time tm,the dynamic threatening boundary mechanism must select a \nthreatening boundary TB~ before initiating scav\u00adenge n, The farther back in time TBm is, the more storage \nwill be traced, and the more garbage reclaimed. 3.4 A Policy to Reduce Tenured Garbage: DTBd~ Here we \ndescribe additional assumptions made in our imple\u00admentation and the specific details of our DTBdg policy. \nWe as\u00adsume that garbage collection is triggered by a fixed amount of allocation (e.g., after 1 megabyte \nof allocation). Conceptually, the new data allocated since the last collection is considered to be in \nthe nursery; although in a non-copying collector such data will not be contiguous. We assume that the \nnursery is always collected in all the algorithms we consider. Thus, what differentiates the threatening \nboundary selection policies we consider is what, in addition to the nursery, is collected. A non-generational \ncollector always collects all data, which corresponds to selecting the threatening boundary to be O at \nevery collection. We call such a collector FULL, and note that FULL never tenures any garbage. A fixed-age \ngenerational collector promotes all objects that survive k collections, where k is a fixed value. If \nk = 1, (i.e., the FIXED1 policy used in our results) then this policy corresponds to tenuring objects \nas soon as they survive the nursery. If k > 1, then this choice corresponds to setting the threatening \nboundary a fixed distance backward in time. Feedback mediation (or FM) is more sophisticated than a fixed-age \npolicy. Instead of blindly setting the threatening boundary a fixed distance in the past, feedback mediation \nonly advances the threatening boundary when a pause-time con\u00adstraint (as defined by the number of bytes \nthat are traced] is exceeded. In particular, if the current scavenge traces more bytes than a specified \nmaximum, Trace~az, the threatening boundary is advanced, otherwise it is not and no objects are pro\u00admoted. \nTo advance the threatening boundary, the FM algorithm maintains a table of object demographics as it \nscavenges. The table classifies the currently scavenged objects by birth time into categories (or birth-time \nregions) and identities how many bytes of objects are alive in each birth-time region. When the threatening \nboundary must be advanced, this table is scanned backwards starting at the current time. The scan accumulates \nthe number of live bytes in each region until Tracem.= bytes is reached. This point determines where \nthe new threatening boundary is set. In feedback mediation, demographics data are not preserved from \none scavenge to the next, and information about objects born before the current threatening boundary \nare neither available nor used. We seek a policy that reduces tenured garbage more ef\u00adfectively than \nfeedback mediation, Our policy, Dmda (DTB demographic) attempts to do this by using the ability of the \nmechanism to dynamically adjust the threatening boundary to any desired value. The policy attempts to \nmeet two goals: con\u00adtrol pause times and minimize tenured garbage. Like feedback mediation, the policy \nattempts to meet the first goal by explic\u00aditly adjusting the threatening boundary forward to reduce pause \ntimes when it traces more than Tracem.= bytes. However, in Memm,X Memn DTB(t) -Dynamic Threatening Boundary \n---------Full(t) -Full Collection --  L(t) -live data Mem .l I Scavenge I Time Memory I I Trace \n~X  m~ Te .....-..  I Trace \u00ad~ , L(t)  ,, I I Execution Time t * TBn.l tn., TBn t  Figure ~: Garbage \nCollector Memory Use. A non-generational full garbage collector collects all garbage at periodic intervals \nas shown by curve Fall fnfling to cnrve L at time tm. Like any generatiottat collector, the dynamic threatening \nboundary mechanism savestracing time by following curve DTB leaving some tenured garbage above the Full \ncurve. Notice that DTB reduced tenured garbage after time tmby selecting Z BW to trace older objects \nthan TBn-1did at time tn_1. order to meet the second goal more effectively than feedback mediation it \nmoves the boundary backward in time when it traces fewer than Tracem~= bytes. To do this adjustment, \nit preserves demographic information from one collection to the next and uses it in the same manner as \nfeedback mediation, but without the constraint against moving the boundary backward. Our policy has a \ncouple of additional refinements. First, it attempts to predict how much data in the nursery will survive \nby estimating that the nursery survival rate will not change at the next collection. Therefore, it increments \nthe sum obtained from the backward demographic scan by the number of bytes surviving from the nursery \nduring the last scavenge. Second, it attempts to avoid repetitive tracing of long-lived clumps of old \nobjects (the so-called pig-irr-[he-python). When it exct:eds Tracem.= as a result of moving the threatening \nboundary backward to a given value, it does not select that (or an older) boundary again at the next \nscavenge. Each unsuccessful, at\u00adtempt to collect the clump doubles the intervening time until the next \nattempt on that clump. l%gure 3 illustrates how the threatening boundary, TJBn, is selected at time tm. \nEach of the birth-time regions A -D contains objects still alive at time tnthat were born between collections \nat times tiand t~-I(for integer i = 1 ton). Because region E has never been collected, the first refinement \nuses D s vahre as a prediction. The new threatening boundary, TBn, is set to the oldest value that does \nnot exceed Z racema. = 100 kilobytes (e.g., E -I-D+ C = 30+30+25 = 85< 100). TB*-, illustrates a previous \nthreatening boundary that was selected z collections ago as a result of the second refi,ne\u00admen~ collection \nof the long-lived region, A, was previously attempted, but resulted in too much storage being traced. \nMethods We are interested in comparing the relative performance of different garbage collection algorithms \nin terms of CPU and TBn.x TBn TBn.I I mem~ 30 3040 { 2s 25 /w /- ! [\\:1I I I o A 1 B 1.-3C (n.2D (n., \nE (n Bti Tune Figure 3: Threatening Boundary Demographics. The numbers underneath each curve show the \ntotal storage traced by previous col\u00adlections for each of the birth-time regions A D. Each region contains \nobjects born between collections (t~_ I to t~, i = 1 ton) that arc live at time tn.Region E, to be traced, \nusesthe previous collection s vatue, D, as an estimate. At time tn. the D rBdgcollector moves threat\u00adening \nboundary backward from TBn_ 1 to TBm by using the oIdest boundary such that the total traced area is \nless than Tracema= = 100 kilobytes (E+ D + C = 30+30+25= 85< 100). memory overhead, tenured garbage, \nand bytes traced. In or\u00adder to determine the effectiveness of the dynamic threatening boundary mechanism \nand the DTBd9 policy, we instrumented a set of five allocation-intensive C programs using ATOM [8], The \nprograms are described in detail in Table 1 in Appendix A. We used memory allocation and deallocation \nevents in these programs to drive a simulation of the different garbage collec\u00adtion algorithms. The output \nfrom the simulation consisted of memory and CPU usage patterns that were then processed to produce performance \ndata. We simulated each of four garbage collection algorithms: full collection (FuLL), fixed-age generational \n(FfxEDl), feed\u00adback mediation (FM), and our collector policy (DTBdg ). Scav\u00adenges were triggered after \nevery 1 million bytes of allocation and Trace~aa was set to 100 thousand bytes. In order to determine \nthe CPU costs of our DTB mechanism, we wrote a program for the DEC Alpha that instrumented each of the \napplications and recorded the dynamic store frequency for various types of stores. Specifically, we distinguished \nbe\u00adtween store instructions that can create pointers in the heap (which must be checked), and those that \ncannot (e.g. unaligned or stack pointer register displacements). The exact store check overhead incurred \nfor any collector depends highly upon the architectures of the processor, oper\u00adating system, and collector \nimplementation. We modelled the cost of an inline write-barrier for a non-copying conservative collector \nas might be used in a C or C++ environment. We assumed that a value can be checked to see if it is a \nforward\u00adin-time pointer in 20 instructions, and if it is, that it takes 20 more to be inserted into the \nremembered set. (Hosking used 21 instructions to implement the store check on the MIPS R2000[11 ]). The \nactual cost may vary significantly from our 20 instruction overhead, depending on the data structure \nused to lookup the descriptor for an object given a pointer that points inside it. For example, in version \n4.0 of the Boehm-Weiser conservative collector [3], the store check would require two such Iookups that \nwould typically require 13 instructions each. Because the total store check overhead is directly proportional \nto the estimated cost of a single check, it is a simple matter to scale our store check CPU overhead \nestimates accordingly. Note that in any case, all generational collectors will incur this overhead, To \nmodel the CPU overhead, we measured total instruc\u00adtions, total stores, eligible stores, and forward-in-time \nstores, We assumed that each entry in the remembered set required 20 instructions to be processed by \nthe garbage collector during each scavenge. To determine the memory required by the remembered set for \nthe DTB mechanism, we measured the maximum number of live bytes, pointers, and forward-in-time pointers, \nfor each application. We assumed that each remembered set entry re\u00adquired two pointer slots of eight \nbytes each (as on the DEC Alpha), one for the address updated, and one for a hash link. Other tradeoffs \nmay be made to improve memory or time per\u00adformance as appropriate. For the purposes of comparison, we \nassumed other generational collectors had a remembered set size of zero, incurred no costs to update \nit, and that our col\u00adlector s remembered set was at the application s maximum at each scavenge. To determine \nthe overhead for maintaining the birth times, we measured the maximum number of live objects and multiplied \nby eight bytes per object. To take into account memory fragmentation, the simulator allocated and deallo\u00adcated \ndummy objects in a separate process using the GNU malloc/free routines as the simulation proceeded. We \nchose GNU malloc because it is among the most space-efficient allo\u00adcation packages for C [7]. The maximum \nheap size was then recorded for each application, 5 Results In this section, we investigate the costs \nof implementing the dy\u00adnamic threatening boundary mechanism and the performance Of OUr ~TBdg pOliCY. \n5.1 The Cost of the Dynamic Threatening Boundary Mechanism As we have mentioned, a dynamic threatening \nboundary mech\u00adanism is similar to that of aconventional generational collector, except that it must maintain \na remembered set of all forward\u00adin-time pointers. We investigate the overhead of creating and maintaining \nthat set in this section. In Figure 4, we show the overhead of the store check, up\u00addating the remembered \nset (RS Insert), and scanning that set (RS Scan) during each collection. The numbers in the figure are \nshown in Table 2 and derived from the measurements con\u00adtained in Table 3 in the Appendix. The store check \noverhead for an inline write barrier (Store Check) will be the same for DTB as it is for any generational \ncollector. Clearly this portion of the total overhead can benefit from further optimization such as identifying \ninitializing store instructions. Such opti\u00admization would benefit a generational algorithm and our DTB \nalgorithm equally. As the figure shows, the additional over\u00adhead associated with maintaining the write \nbarrier (RS Insert) and scanning the larger remembered sets (RS Scan) programs ranges from O?ZOto 7~o \nof total program execution time. Figure 5 shows the space overhead of maintaining all forward-in-time \npointers in the remembered set and storing fine grain birth times for each object. The numbers for this \nfigure are in Table 4 and are derived from Table 5 in the Ap\u00adpendix. Both the birth field overhead and \nthe remembered set overhead vary widely across the applications but range from 4% to 15% of total memory \nconsumption. GAWK and CFRAC overheads are dominated by the birth-time field because they have mostly \nsmall objects and low pointer density. ESPRESSO and S1S have much higher pointer density, so remembered \nsets dominate their overhead. Because we are assuming a non-copying collector, we con\u00adservatively assume \nthat an 8-byte birth field is included with each object. In practice, only several hundred distinct birth\u00adtime \nvalues are probably necessary at any time, and so this information could be encoded in many fewer bits \n(e.g., by mapping object addresses to an array of bytes). Because FM also collects and uses object demographic \ninformation, it also requires such birth-time fields. In a copying collector, more efficient methods \nof encoding birth information are also possi\u00adble. By co-locating objects of the same age on the same \npage (or sub-page), the 8-byte overhead would be incurred per page instead of per object. Such an approach \ncould suffer memory loss from internal fragmentation, however. 5.2 Evaluation of DTBd9 Policy In this \nsection, we evahrate the effectiveness of the Dmdg pol\u00adicy in reclaiming tenured garbage and compare \nit to three other collection algorithms. We first consider total memory use, then tenured garbage reclamation, \nits effect on pause times, and fi\u00adnally, the total amount of data traced. Note that we considered the \nfixed costs of maintaining the write barrier and scanning the remembered sets for the mechanism in the \nprevious section; here we evaluate one specific policy. 5.2.1 Memory Benefits We first look at the memory \nrequired by each of the differ\u00adent collectors in Figures 6 and 7. In Figure 6 we evaluate 1\u00ad [ Cfrac \nEspressal Gawk Ghost Sis Figured: CPU Overhead of the DmMechmism. Maintainin]; theremembemd set forgenerationd \ncollectors incurs CPUoverhead fromthme sources: filtering ateachstow (Sto~Check), insetting fowud-in-time \npointem intothe ~memberedset (RSInse~), andaccessingthe ~membered setduring each scavenge(RS Scan). The \nfigumshows theaddititJnd overhead foreach asapercentage oftotaIins~ctions. l%e largest overhead is from \nthe store check, which isidenticd for both Dmmdany (~thergenerational collector that usesainlinewfitebtier. \nForcomparison, we assume that a generational collector incurs no additional cost for scanning or updating \nthe remembered set.  !==== M\u00ad m I:: ;l m ,,,::,%., , 1 1 ,.,, ~~ .. . .  .!-- I,., .:.,,,,;, ,, .. \n,, II, ,,,,,, -, , ,,.,, ~ ,,,,.. f. , , J,, ,, , ,,,,,, L-L Cfrac EspressO Gawk Ghost Sis Figure 5: \nMemory Overhead of the D ra Mechanism. Dm]incurs memory overhead for maintaining all fosward-in-time \npointersin the remembered setandabirth-time field foreachobject. Thepercentage ofmmimum memo~consumed \nfincluding fragmentation) is shown, h--l FI  Cfrac Espresso Gawk Ghost Sis Figure 6: Maximum Memory \nUse (Relative to FM) The maximum memory used by each collector for each application is shown. For easier \ncomparison between applications, all values were normalized by dividing them by the maximum memory consumed \nby FM for each program. For DTBdg the memory overhead shown in Figure 5 is included. 3000 Full [ Fixed \n [ DTB(dg) :; Cfrac Espresso Gawk Ghost Sis Wlgure 7: Mean Tenured Garbage The figure shows the mean \namount of garbage that was tenured by each of the different collection algorithms during program execution \nfor the FM and DTBd~ collectors. FULL has no tenured garbage by definition. 3 Fixed _ DFM -mDTB(da) F \nI\u00ad f:;: , .~. ,,, ,:,+ ,,. ., *;:,., .,., ;.;, ,* .... 4 ,*.. H} ,. [ 0 Cfrac Espresso Gswk Ghost \n6is Figure 8: PauseTimes The figure shows the value corresponding to the 90th percentile pause time as \nmeasured by ratio of total bytes traced to a ff mace~a= value of 100,000 bytes. FULL (not shown) has \npause times off the chart (see Table 8 in the Appendix).   1.6r 1.4 0.2 0 Cfrac Espreseo Gawk Ghost \nSis Figure9: Total Bytes Traced This figure shows the cumulative total of all bytes traced by each collector \nduring the lifetime of each program. FULL is not shown because it was off the scale in all cases (see \nTable 9 in the Appendix). collector performance with respect to maximum memory used (including fragmentation). \nDmdg saved significant amounts of memory for ESPRESSO and GHOST even after the effects of the remembered \nset and birth time overheads from Figure 5 have been included. SIS still had a modest improvement even \nthough it had the largest memory overhead due to its high pointer density. Notice also that DTBd9 incurs \nonly a minor cost in CFRAC and GAWK where no collector distinguished itself. Figure 7 shows how tenured \ngarbage affected total memory use. CFRAC and GAWK do not generate significant amounts of tenured garbage \n(see also Table 7 in the appendix). Thus, there was no opportunity for either FM or DTBdg to recover \nmuch. For ESPRESSO and GHOST, however, tenured garbage was a significant portion of average memory use \n(50 %0and 30% respectively for FtXEDl; 33~0 and 18% for FM). Observe how DTBdg s maximum memory use savings \nwere roughly proportional to the proportion of tenured garbage. S1S had 22% tenured garbage for FM, but \nthe savings were reduced by the 14% memory overhead of DTB (see Figure 5). When tenured garbage was present \nto a significant degree, our policy was able to collect much of it. 5.2.2 Object Tracing Costs We now \ndiscuss the costs incurred as a result of collecting the tenured garbage. Figure 8 shows the 90th percentile \npause times in the test programs (as defined by bytes traced). FULL is not shown because it had pause \ntimes off the chart. The values for FM and DTBdg are much Iower than FULL, showing the benefits of generational \ngarbage collection. In SIS, the generational poIicies were not as effective at controlling pause times \nthan they were in other programs, but they still saved 76% off the 90th percentile pause-time of FULL \n(not shown). From the figure, we also see what impact moving back the threatening boundary had on pause \ntimes. In particular, DTBdg was higher than FM and both were higher than FtXED 1. As expected, the largest \nincrease in pause times for DTBdg occurred for the same applications that had the greatest recovery of \ntenured garbage and were roughly proportional to the tenured garbage reclaimed. 5.2.3 Data Traced Finally, \nwe consider the amount of work done (e.g., time spent) tracing data in the different collectors. Garbage \ncollectors trade reduced memory consumption for added object tracing over\u00adhead, Consider that FULL would \nbe completely off the scale in Figure 9, and compare the FLXED1 collector in Figure 9 with the FULL and \nFIXED 1 collectors in Figure 6. FULL always traces all objects, and thus has the lowest memory consumption \nand the traces the most bytes, On the other hand, FIXED1 tenures objects after just one collection, and \nthus has the lowest tracing overhead but uses the most memory of the two. If tracing over\u00adhead was the \nsole concern of users, the FtXEDl policy would be the obvious choice because it has the lowest overhead. \nUnfor\u00adtunately, this algorithm has the property that tenured garbage accumulates (e.g., quite rapidly \nin ESPRESSOand GHOST) and its memory consumption is large, which motivates accepting the higher tracing \noverheads and pause-time overheads of FM and DTBdg . 6 Summary Generational garbage collection algorithms \nall occasionally promote objects that eventually become garbage, Reclaiming such tenured garbage is problematic, \nbecause in many imple\u00admentations it requires collecting the entire heap. We present the concept of a \ndynamic threatening bound\u00adary mechanism, which extends existing generational collection techniques. Unlike \nprevious work, we describe a mechanism that can dynamically adjust the boundary between tenured and untenured \ndata either forward or backward in time, essentially allowing data to become untenured at any time. We \ndescribe an implementation of the dynamic threatening boundary mechanism and quantify its costs using \nmeasure\u00adments of allocation-intensive C programs. The central over\u00adhead of the dynamic threatening boundary \nis the CPU and memory costs required to maintain and scan a set indicating the location of all forward-in-time \npointers. Our measurements show that maintaining this set adds 4-1 5% to the total space required by \nthe program. Furthermore, we find that the CPU costs of maintaining and scanning this set add from O-7% \nto the total execution time of the program over the costs of a conventional generational collection algorithm. \nWe feel that implementing the dynamic threatening boundary mechanism is feasible in languages where programs \noften exhibit a low pointer density (e.g., as our measurements show, C) and in languages in which few \nforward-in-time pointers are created (e.g., Standard ML). The dynamic threatening boundary mechanism \nis flexible and clearly separates issues of policy from implementation, We describe one policy, DTBdg, \nfor setting the threatening bound\u00adary based on an extension of Ungar and Jackson s feedback mediation \ncollector. Because it attempts to reclaim tenured garbage, the DTBdg policy requires longer pause times \nand traces more bytes than feedback mediation. However, our results show the DTB@ policy, which uses \na dynamic threat\u00adening boundary mechanism, is effective at reclaiming tenured garbage. In the future, \nwe plan to imp~ement the DTB mechanism and carefully quantify its costs. We also plan to explore other \nthreatening boundary selection policies in addition to the DTBd~ policy evaluated here. Finally, we are \ninterested in more carefully investigating the cost of implementing the write barrier in a conservative \nnon-copying generational collector. Acknowledgements We would like to thank Hans Boehm, Urs Holzle, Robert \nRorschach, and David Ungar for making substantive contri\u00adbutions to the paper. We also thank the anonymous \nreferees for their insightful comments. This work was funded in part by NSF grant No. CCR-9404669 and \nDigital Equipment Corp. External Research Grant Number 1580. References [14] Henry Lieberman and Carl \nHewitt. A real-time garbage [1] Apple Computer Inc. Macintosh Common Lisp Rqfer\u00adersce, version 2 edition, \n1992, pages 631-637. [2] David A. Barrett and Benjamin G. Zom. Using lifetime predictors to improve memory \nallocation performance. In ACM SIGPLAN Symposium on Programming Lzm\u00adguage Design and Implementation, \npages 187-196, Al\u00adbuquerque, New Mexico, June 1993. [3] H. Boehm and M. Weiser. Garbage collection in \nan un\u00adcooperative environment, Software Practice and Experi\u00adence, pages 807-820, September 1988. [4] \nHans-J, Boehm, Alan J, Demers, and Scott Shenker, Mostly parallel garbage collection. In ACM SIGPLAN \nSymposium on Programming Lunguage Design and Im\u00adplementation, pages 157-164, June 1991, Toronto, On\u00adtario, \nCanada. [5] Patrick Caudill and Allen Wirfs-Brock. A third gener\u00adation Smalltalk-80 implementation. In \nNormam Mey\u00adrowitz, editor, OOPSLA 86 Conference Proceedings, pages 119-130, Portland, OR, September 1986. \nACM. [6] Alan Demers, Mark Weiser, Barry Hayes, Hans Boelhm, Daniel Bobrow, and Scott Shenker. Combining \ngenera\u00adtional and conservative garbage collection: Framework and implementations. In Conference Record \nof the Sev\u00adenteenth ACM Symposium on Principles of Programming Languages, pages 261-269, January 1990. \n[7] David Detlefs, AI Dosser, and Benjamin Zom. Memory allocation costs in large C and C++ programs. \nSojiware Practice and Experience, 24(6):527-542, June 1994, [8] Digital Equipment Corporation. ATOM Reference \nMcm\u00adual, December 1993. [9] Franz Inc. Allegro CL User Guide, Version 4.1, revision 2 edition, March \n1992. Chapter 15: Garbage Collection. [10] Barry Hayes. Using key object opportunism to collect old objects. \nhr ACM SIGPL.4N 1991 Conference on Object Oriented Programming Systems, Languages and Appli\u00adcations (OOPSLA \n91), pages 3346, Phoenix, Arizona, October 1991. ACM Press. [11] Antony L, Hosking and Richard L. Hudson. \nRemem\u00adbered sets can also play cards. In 00PSLA 93 Work\u00adshop on Garbage Collection in Object-Oriented \nSyste,ms, Washington, D. C,, September 1993. [12] R. L. Hudson, J. E. B. Moss, and A. Diwan. A language \nindependent garbage collector toolkit, Technical Repot-t COINS TR 91-47, University of Massachusetts, \nAmherst, MA, September 1991. [13] Richard L. Hudson and J. Eliot B. Moss. Incremental collection of mature \nobjects. In Proceedings of the In\u00adternational Workshop on Memory Management, pages 388-403, St. Malo, \nFrance, September 1992. Springer-Verlag Lecture Notes in Computer Science vol. 637. collector based on \nthe lifetimes of objects. Communica\u00adtions of the ACM, 26(6):419429, June 1983. [15] David A. Moon. Garbage \ncollection in a large Lisp sys\u00adtem. In Conference Record of the 1984 ACM Symposium on LISP and Functional \nProgramming, pages 235-246, Austin, Texas, August 1984. [16] David Ungar. Generation scavenging: A non-disruptive \nhigh performance storage reclamation algorithm. In SIG-SOFT/SIGPLAN Practical Programming Environments \nConference, pages 157 1 67, April 1984. [17] David Ungar and Frank Jackson. An adaptive tenuring policy \nfor generation scavengers. ACM Transactions on Programming Languages and Systems, 14(1): 1-27, Jan\u00aduary \n1992, [18] Mark D. Weiser, Alan J. Demers, Daniel G. Bobrow, and Barry Hayes, Method and system for reclaiming \nunreferenced computer memory space. United States Patent No. 5,321,834, June 1994. [19] Paul R. Wilson \nand Thomas G. Moher. Design of the opportunistic garbage collector. In ACM SIGPLAN 1989 Conference on \nObject Oriented Programming Systems, Languages and Applications (OOPSL4 89), pages 23\u00ad35, New Orleans, \nLouisiana, October 1989. [20] Benjamin Zom. Comparing mark-and-sweep and stop\u00adand-copy garbage collection. \nIn 1990 ACM Confer\u00adence on Lisp and Functional Programming, pages 87-98, Nice, France, June 1990. [21 \n] Benjamin Zom and Dirk Grunwald. Empirical measure\u00adments of six allocation-intensive C programs. ACM \nSIG-PLAN Notices, 27(12):71-80, December 1992. A Program Information Proor2m I 1,ines I Descr-btiort \n. .. . .. ... ----- CFRAC 6000 Cfrac is a program that factors large integers using the continued fraction \nmethod. The input was a 28-digit number that was the product of two primes, ESPRESSO 15500 Espresso, \nversion 2.3, is a logic optimization program. The input used was the largest example provided with the \nrelease code. GAWK 8500 GNU Awk, version 2.11, is a publicly available interpreter for the AWK report \nand extraction language, The input script formatted words in a dictionary. GHOST 29500 GhostScript, version \n2.6.1, is a publicly available interpreter for the PostScript page-description language. The input was \na large PhD thesis. This execution of GhostScript did not run as interactive applications as it is often \nused, but instead were executed with the NODISPLAY option that simply forces the interpretation of the \nPostScript program without displaying the results. SIS 172000 S1S, Release 1.1, is a tool for sythesis \nof synchronous and asynchronous circuits. It includes a number of capabilities such as state minimization \nand optimization. The input used in the ntn was one of the examples provided with the release (mcnc9 \nl/cse.blif). The operation performed was an attempt to reduce the depth of the circuit (speed-up). Table \n1: General information about the test programs. Store RS RS Total Check(%) Insert(%) Scan(%) CPU(%) CFRAC \n3.17 0.00 0.04 3.21 ESPRESSO 11.97 3.07 1.48 16.53 GAWK 50.39 3.04 0.10 53.53 GHOST 36.23 2.54 0.70 39.48 \nSIS 25.23 3.20 3.46 31.90 Table 2: CPU Overhead of the DTB Mechanism. The table indicates sources of \noverhead in conventional generational collector and DTS mechanism based on an inhne write barrier. All \nvalues m percentage of total execution time as measured by counting instructions. Store Check shows the \noverhead for checking for forward-in-time pointer stores; RS Insert shows the time to insert such pointers \ninto the remembered set, and RS Scan shows the overhead during scavenging. Total Store Filter Forward \nBarrier CPU Program Instr. Instr. Instr. Instr. Instr. Overhead (lo ) (%) (%) (%) (10 ) (%) CFRAC 1471 \n6.55 0.16 0.000 47 3.2 ESPRESSO 2362 5.24 0.60 0.154 355 15.0 GAWK 1731 9.26 2.52 0.152 925 53.4 GHOST \n1646 7.39 1.81 0.127 638 38.8 S1S 487 6.35 1.26 0.160 139 28.4 Table 3: Raw Data for CPU Overhead Computation. \nTo determine CPU overhead, the data above was collected. All percentages given are percentages of total \ninstmctions executed. The FMer Instr. cohrrnrr shows the percentage of total instmctions executed (Total \nInstr) that require a filter to check for forward-in-time pointers. This percentage is small compared \nto the store instruction percentage (Store Instr.), which is itself a small percentage of totat instructions. \nForward hrstr. shows the percentage of total instructions that required a forward-in-time pointer to \nbe inserted into the remembered set. A model assuming 20 instructions for the filter, and 20 instructions \nfor updating the remembered set predicts that a total of Barrier Instr. instructions wilI be required. \nThe CPU overhead is computed from the ratio of Barrier Instr. to Total Instr. For ESPRESSO: 2362 X (0.0060X \n20+ .00154X 20) = 355,.15 = 356/2362. Max. Max. Rem. Birth Memory Program Heap Size Live Data Set Time \nOverhead (KBytes) (KBytes) (%) (%) (%) CFRAC 1536 123 1.21 4.39 5.60 ESPRESSO 1900 339 7.73 1.80 9.54 \nGAWK 8944 4720 0.06 10.43 10,49 GHOST 3684 1401 2.36 1.21 3.57 SIS 2928 672 9.76 4.99 14.76 Table 4: \nMemory Overhead of the DT B Mechanism. This table shows the additional memory required to maintain the \nremembered set and per-object birth times in the DTB mechanism. Max. Live Data is the maximum amount \nof live data used by the program at any time. Maximum Heap Size is Max. Live Data plus memory fragmentation \noverhead. Rem. Set indicates the ratio of space required for the remembered set to Maximum Heap Size \nfor the D ra mechanism. Birth Time is the same ratio but for including a birth time field for each object. \nMemory Overhead is the total additional memory required for the DTSSmechanism (Rem. Set% + Birth Time \n%). Total Max. Max. Max. Max. Max. Memory % Program Allocated Heap Size Lhe Data Live Live Rem. Set Overhead \nPointers (KBytes) (KBytes) (KByles) Objects Pointers (Pointers) (%) in Heap CFRAC 21183 1536 123 8624 \n3149 1189 5.60 20.04 ESPRESSO 181883 1900 :339 4387 21451 9403 9.54 49.44 GAWK 235027 8944 4720 119403 \n1453 371 10.49 0.24 GHosT 101402 3684 1401 5697 35993 5562 3.57 20.07 S1S 45032 2928 672 18718 35884 \n18291 14.76 41.73 l abk 5: Raw Data for Memory Overhead Computation. To determine memory overhead, the \ndata above was collected. The memory overhead is modeled as maximum size of the remembered set (Max. \nRem. Set) divided by the Max. Heap Size assuming two eight-byte pointers are required for each remembered \nset element. For ESPRESSO,= 100 x (9403 x 16)/(1900x 1024). Max. Live Objects is used to compute the \nmemory 0.8 overhead for the per-object Birth Ttme fieId in Table 4 by assuming eight bytes per object. \nThe pointer density (7o Pointers in Heap) is the ratio of Maximum Live Pointers in the heap to Maximum \nL]ve Data expressed as a percentage assuming eight bytes per pointer. As the pointer density increases, \nso does the remembered set size and the corresponding overhead. FM (Kbytes) FIXED1 FM DTBdg Program Max \nMean Max Mean Max Mean Max Mean Max Mean CFRAC 1536 1478 1.00 1.00 1.01 1,00 1.00 1.00 1.06 1.00 ESPRESSO \n4108 2649 0.42 0.62 2.00 1.99 1.00 1.00 0.51 0.60 GAWK 8944 5237 1.00 1.00 1.08 1.06 1.00 1.00 GHOST \n35484 4032 0.62 0.75 1.51 1.35 1.00 1,00  =Ea=1= STs 3712 I 2745 7mi-im-1.24 1.15 1.00 1.00 0.91 I 0.88 \nI Table 6: Maximum and Mean Memory Consumed (Relative to FM). Each column shows the memory requirements \nof the different collectors measured, The first column shows absolute memory consumption of FM. Subsequent \ncolumns am normnhzed by dividing by this value. The DWi~ column includes the memory overhead shown in \nTable 4. E FULL FIXED 1 FM DTBd9 Program (Kbytes) (Kbytes) (Kbytes) (Kbytes) CFRAC O.clo 3.04 0.04 0.04 \nESPRESSO O.clo 2651.50 877.49 92.56 GAWK 0.00 253.03 0.03 0.03 GHOST 0.00 1680.11 734.07 84.11 Sls O.C1O \n941.76 618.45 344.16 Table 7: Mean Tenured Garbage, The table shows the average amount of garbage that \nwas tenured by each of the different collection algorithms druing the lifetime of the program. FULLcannot \ngenerate tenured garbage. GHOST 100000 II 13.36 ] SIS 100000 II 6.54 I Table8: 90th Percentile PauseTimes \n(Relative to Tr-ace~==). Wchcolumn first column shows thevahreofTrszce~az. Subsequent columns menomalized \nFM FULL Program KBYTES CFRAC 1529 1,29 ESPRESSO 6588 4.69 GAWK 21721 26.64 GHOST 5616 20.83 SIS 3767 \n6.93 1.03 I 1.30 I 1.69 2.25 I 2.25 ] 2.59  shows the90th percentile pause times foreachprogram row. \nThe bydividingby this value. FIXED1 FM DTB 0.08 1.00 1,00 0.58 1.00 1.19 0.23 1.00 1,00 0.79 1.00 1.54 \n0.66 1,00 1,58 Table9: Total Data Traced (Relative to N). The Wkilobytes column shows thenumberofkilobytes \ntraced bythe~co1lector. Subsequent rows show the relative performance of the other collectors, \n\t\t\t", "proc_id": "207110", "abstract": "<p>Generational techniques have been very successful in reducing the impact of garbage collection algorithms upon the performance of programs. However, all generational algorithms occasionally promote objects that later become garbage, resulting in an accumulation of garbage in older generations. Reclaiming this <italic>tenured</italic> garbage without resorting to collecting the entire heap is a difficult problem. In this paper, we describe a mechanism that extends existing generational collection algorithms by allowing them to reclaim tenured garbage more effectively. In particular, our <italic>dynamic threatening boundary</italic> mechanism divides memory into two spaces, one for shortlived, and another for long-lived objects. Unlike previous work, our collection mechanism can  dynamically adjust the boundary between these two spaces either forward or backward in time, essentially allowing data to become untenured. We describe an implementation of the dynamic threatening boundary mechanism and quantify its associated costs. We also describe a policy for setting the threatening boundary and evaluate its performance relative to existing generational collection algorithms. Our results show that a policy that uses the dynamic threatening boundary mechanism is effective at reclaiming tenured garbage.</p>", "authors": [{"name": "David A. Barrett", "author_profile_id": "81392612783", "affiliation": "Department of Computer Science, Campus Box #430, University of Colorado, Boulder", "person_id": "PP39038584", "email_address": "", "orcid_id": ""}, {"name": "Benjamin G. Zorn", "author_profile_id": "81100190820", "affiliation": "Department of Computer Science, Campus Box #430, University of Colorado, Boulder", "person_id": "P28972", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/207110.207164", "year": "1995", "article_id": "207164", "conference": "PLDI", "title": "Garbage collection using a dynamic threatening boundary", "url": "http://dl.acm.org/citation.cfm?id=207164"}