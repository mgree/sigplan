{"article_publication_date": "06-01-1995", "fulltext": "\n Flow-Sensitive InterProcedural Constant Propagation Paul R. Carini* Abstract We present a flow-sensitive \ninterprocedural constant propagation algorithm, which sttpports recursion while only performing one flow-sensitive \nanalysis of each pro\u00ad cedure. We present experimental results which show that this method finds substantially \nmore constants than previous methods andisefficient in practice. Reintro\u00ad duce new metrics for evaluating \ninterprocedural constant propagation algorithms which measure the number of in\u00ad terprocedural constant \nvalues that are propagated. We use these metrics to provide further experimental results for our algorithm. \n 1 Introduction Program analysis has struggled with the tradeoff between modularization and optimization \nin many forms. Interpro\u00adcedural analysis (IPA) is a well-known technique which can be used to bridge \nthe gap across procedure boundaries. The popularity of object-oriented languages, such as C++, increases \nthe opportunity for, and the value of, interproce\u00addural analysis and transformations. Constant propagation \nidentifies constant definitions of variables and propagates the constant values to the uses of those \nobjects. InterProcedural constant propagation (ICP) propagates the constant values of variables across \nprocedure boundaries [9, IO, 20, 16, 22]. This may lead to more precise data-flow information, which \ncan help improve the precision of other analyses, as well as enable other program transformations to \ngenerate more efficient code. Flow-sensitive interprocedural algorithms consider in\u00adtraprocedural control \nflow and are, in general, more precise, but less efficient, than flow-insensitive algorithms [4, 19], \nwhich do not consider intraprocedural control flow informa\u00adtion during the analysis. Flow-sensitive interprocedural \ncon\u00adstant propagation relies upon a flow-sensitive intraprocedural constant propagation method to identify \nconstants, and then propagates these constants interprocedurally. In this paper *IBM T.J. Watson Research \nCenter, P,O.Box 704 Yorktown Heights, NY 10598, carini@watson.ibm.com *Department of Mathematics and \nComputer Science, State University of New York at New Paltz, New Paltz, NY 12561, and IBM T.J. Watson \nResearch Center, hindr@mcs.newpaltz.edu Permission to copy without fee all or part of this material is \n granted provided that the copies are not made or distributed for direct commercial advantage, the ACM \ncopyright notice and the title of the publication and its date appear, and notice is given that copying \nis by permission of the Association of Computing Machinery.To copy otherwise, or to republish, requires \na fee and/or specific permission. SIGPLAN 95La JoHa, CA USA 0 1995 ACM 0-89791 -697-2/95/0006 ...$3.50 \nMichael Hindt mailno { subl (0); } sub:f:~{ if(fl ~=O) ~lsey = 1; y=o; sub2(y, 4, fl , X); } sub2(f2, \nf3, f4, f5) { . ..= f2+f3+f4+f5. } -HOD FORMALPARAMETERCONSTANTS FLO ti.SENSITIVE fl , f2, m, f4, f5 \nFLOW-INSENSITIVE fl, f3, f4 E LITE~AL fl, f3 INTT!A fl, f3, fs PASf~THROUGH fl, f3, f4, f5 POLYNOMIAL \nfl, f3, f4, f5 E Figure 1: Example Program and Precision Comparison we introduce a flow-sensitive interprocedural \nconstant prop\u00adagation method. In addition to the flow-sensitive method, this paper also describes a flow-insensitive \nalgorithm, which our flow-sensitive method utilizes when call graph cycles exist. The combination of \nthese two methods enables us to approach the precision of an iterative flow-sensitive inter\u00adprocedural \nanalysis, without requiring more than one flow\u00adsensitive analysis of each procedure. Our algorithms propa\u00adgate \nboth formal parameters and global variables, and were designecl to support multiple languages, including \nC and C++. These algorithms have been implemented in a Fortran 90 re\u00adsearch prototype compiler. We present \nmeasurements of the effectiveness of each technique and contrast these with results previously described \nin the literature. We also suggest metrics that characterize the effectiwmess of interprocedural constant \npropagation. These metrics are a true reflection of the number of interprocedural constant values that \nare propagated. Our results show that the flow-sensitive method discovers and propagates more constants \nthan the flow-insensitive method alone, with little extra colmpile-time cost. Consider Figure 1, which \nillustrates the difference be\u00adtween flow-sensitive and flow-insensitive constant propaga\u00ad 1, Collect \nIPA inputs 2. Construct the Program Call Graph 3. Perform Interprocedural Aliasing (Pointer and Reference \nParameter) 4. Compute Interprocedural Mod and Ref 5. Perform Interprocedural Constant Propagation \n6. Perform Reverse Topological Traversal  Figure 2: Compilation Model Overview tion for formal parameters. \nBy inspecting the call site ar\u00adgument information and propagating this information to the called routine, \na flow-insensitive algorithm can detect that the values of parameters f 1, f 3, and f 4 are constant. \nDeter\u00admining that f 2 and f 5 are also constant requires an analysis of the intraprocedural control flow \nof subl. In particular, x and y must be the same constant on all paths from the entry of subl to the \ncall of sub2. Since f 1 has the constant value O, the path containing y = O is not executed. Fig\u00adure \n1 also specifies the constants that would be found by the various jwnp, ~unctions used in [16]. These \ntechniques are discussed in Section 5. Compilation Model In addition to intraprocedural analyses, our \ncompiler per\u00adforms a number of interprocedural analyses. Our compilation model provides an IPA collection \nphase, during which each procedure in the program is visited and the IPA inputs are collected and saved \nfor later use. This information includes such items as procedure names and formal parameters, pro\u00adcedure \ncall sites and arguments, global variables which are immediately modified or referenced, and an intermediate \nrep\u00adresentation of the procedure. Figure 2 illustrates the steps of the com~ilation model. Af;er the \ncomplete program has been visited (the model includes a provision for handling missing procedures), the \nin\u00adterprocedural analysis phase begins by constructing the pro\u00adgram call graph (PCG). An interprocedural \nalias analysis is then performed, which includes both reference parameter and pointer-induced alias analyses. \nThis is followed by a phase that includes the computation of interprocedural MOD and REF information \n[4, 12, 6], which is implemented as a flow-insensitive traversal of the PCG. This computation re\u00adlies \nupon the IPA inputs that are initially collected, as well as the previously computed alias information. \nNext, interprocedural constant propagation is per\u00adformed, which uses the interprocedural MOD and REF \nin\u00adformation along with the IPA inputs. The interprocedural constant propagation consists of two separate \nstep;, the com\u00adputation of interprocedural constants, and the transformation of a program representation \nto reflect these constants. The final phase of interprocedural analysis is a reverse topological traversal \n(backward walk) of the PCG. During this traversal each procedure (node) is visited once. The intermediate \nrepresentation of each procedure is first restored to memory, and optional procedure inlining and cloning \nmay be performed. These transformations have the output of inter-procedural constant propagation available \nto them. At this stage, the intermediate representation is transformed to reflect the results of interprocedural \nconstant propagation, other traditional analyses and transformations are performed, upward exposed use \nis computed and saved, and final code is generated. 3 Method In this section we provide a description \nof our analysis meth\u00adods. We describe the intraprocedural constant propagation algorithm we employ, and \nthen describe the two variations of interprocedural constant propagation: flow-insensitive and flow-sensitive. \nBoth algorithms presented here only propa\u00adgate constants in the forward direction. However, they can \nbe extended to propagate returned constants. Our prototype performs intraprocedural constant prop\u00adagation \nby default. The routine is an implementation of the Sparse Conditional Constant (SCC) algorithm of Weg\u00adman \nand Zadeck [22], and is built upon an implementation of SSA [13] data-flow analysis. This is an optimistic \nalgorithm that discards unreachable code during the propagation, which may permit the identification \nof additional constants. An interprocedural constant propagation method (flow\u00adinsensitive or flow-sensitive) \nmay optionally be performed. If interprocedural constants are identified, these constants are propagated \nto the entry point of the procedure where they are constant during the backward walk of the compiler. \nThis propagation is equivalent to adding an assignment statement for each constant variable at the beginning \nof the procedure where it is constant. Assignment statements are created only for those variables that \nare referenced in that procedure. 3.1 Flow-Insensitive Interprocedural Constant Propagation The flow-insensitive \nmethod is performed in a forward tra\u00adversal of the PCG, after interprocedural MOD and REF in\u00adformation \nhas been computed, For ease of implementation, globals are treated separately from parameters. The flow-insensitive \nmethod for formal parameters, shown in Figure 3, is an optimistic data-flow algorithm in that all formal \nparameters are initialized to T. It collects and propagates immediate call site constants to their called \nproce\u00addures. If a formal is found to be constant, and is subsequently passed to another formal at a call \nsite without being modified in its procedure (directly or indirectly via any call site), this constant \nis also propagated, and the relationship between the formals is recorded in a set calledfi~ind. To handle \ncycles in the PCG, a work list is used to keep track of formals that are constant, but are lowered (in \nthe lattice algebra sense) at a later time. When processing a constant argument, if the corresponding \nformal is T, the formal is marked as constant. The flow-insensitive algorithm for global variables. given \nin Figure 3, identifies global constants by visiting any global initializations (i.e. Fortran block data) \nand recording those variables that are initialized to a constant on a list. Global variables that are \nmodified anywhere in the program (i.e. those on the procedure MOD list for the main procedure) are removed \nfrom this list. The remaining variables on the list are constant for the entire program. These global \nconstants are propagated to every procedure, but constant definitions are only created for a variable \nthat is immediately referenced in a procedure. procedure meet(~omat, new.value) ovig.value = formal \nformal = formal A new-value if orig-value # L and format = J-then add all fpk to the worklist, such \nthat (fowrtal, fpk) c fp-bind end if end meet procedure insenso I* First process globals *1 Collect initial \nconstants from block data, removing those that are modified in the program for each procedure, p, in \nthe program for each constant global variable, c if p references c, (i.e., c G Ref (p)) then propagate \nc into p end if end loop end loop 1 Then process formal parameters *1 Initialize formal parameters to \nT; worklist, and fp.-bind to empty for each procedure, p, in the PCG in a forward topological traversal \n for each call site, CS, in p for each argument, w-g, at cs Let ~pl be the corresponding formal parameter \nin the called procedure. if arg is an immediate constant or a global constant meet(fpl, /3TfJ) else \nif arg is a formal parameter of p, fpO, that is currently marked as constant and is not modified (directly \nor indirectly) by p add (fpO, fpl) to fp-bind meet(~pl, fpO) else meet(~pl, 1) end if end loop  end \nloop end loop P Pairs on the worklist represent pass-through .formal parameters that were constant and \nthen were lowered to 1. *1 while worklist is not empty remove (f pl, f p2) pair if fp2 is not 1 then \n setfp2 to1 add all fpk to the worklist, such that (fp2, jpk) E fp.bind end if end loop end insens Figure \n3: Flow-Insensitive ICP for Formal Parameters and Global Variables Our flow-insensitive method is similar \nto the Pass\u00adthrcwglz parameter forward jump function method[ 10, 16]. They differ in that the pass-through \nmethod applies a flow\u00adsensitive intraprocedural constant jump function before the interprocedural solution \nis computed. Thus the pass-through method may identify more constants to interprocedurally propagate. \nOur flow-insensitive method defers the appli\u00adcation of the intraprocedural constant propagation routine \nuntil the backward traversal of the PCG, just prior to code generation, 3.2 Flow-Sensitive Interprocedural \nConstant Propagation The flow-sensitive constant propagation algorithm makes use of a flow-sensitive \nintraprocedural method. Although any in\u00adtraprocedural method can be employed, our implementation uses \nthe SCC algorithm of Wegman and Zadeck[22], The flow-sensitive method is performed in one forward traversal \nof the PCG, after procedure MOD and REF information have been computed. This processing of the PCG includes \nthe performance of intraprocedural constant propagation as each procedure is visited. A major characteristic \nof our algorithm is the interleaving of the intraprocedural and interprocedural phases. This algorithm \nis similar to ones previously described for interprocedural data-flow analysis[2] and interprocedural \nalias analysis[ 11, 8]. As a flow-sensitive intraprocedural analysis can be ex\u00adpensive, it is only performed \nonce per procedure, i.e. there is no iteration during the flow-sensitive analysis. If a PCG has cycles \n(back edges), then an optimistic flow-sensitive interprocedural algorithm with one iteration of the PCG \ncould give an incorrect solution[9]. We address this issue by performing a flow-insensitive analysis \nprior to the flow\u00adsensitive analysis, only if there are cycles in the PCG. Dur\u00ading the flow-sensitive \nanalysis, if a call site edge has not been processed before the called procedure (i.e. it is a back edge), \nwe use the solution obtained by the flow-insensitive inter\u00adprocedural constant propagation method for \nthis edge. We use this same method to compute procedure USE information in one reverse topological traversal \nof the PCG, where REF information is used for back edges. Figure 4 presents our flow-sensitive algorithm \nfor formal parameters and global variables. Global variables are handled in a similar manner. The method \nfirst examines block data and identifies the variables that are assigned constant values by entering \nthem on a list. This list is then provided as input to the intraprocedural con\u00adstant propagation algorithm \nfor the entry point of the main procedure. The intraprocedural algorithm propagates global constants \nto call sites. If the global variable is referenced in the called procedure, or in any procedure which \nis called by that procedure it is propagated interprocedurally. This is determined from the procedure \nREF information. (The flow-sensitive procedure USE information has not yet been computed.) The referenced \nvariable is then added to the list of constants for that call site. When a procedure is processed, the \nlist of constants for each call site that invokes the proce\u00addure is inspected, and a meet is performed. \nIf a back edge exists, the flow-insensitive global solution for the back edge is used. The ratio of the \nnumber of back edges to the total number of edges can be used as a measure of the flow\u00adinsensitiveness \nof our solution. When this ratio is zero, i.e. no back edges exist, the same results as a flow-sensitive \nit\u00aderative solution (that does not propagate returned constants) are achieved, without requiring iteration. \nAs the ratio of back edges to forward edges appraoches one, more flow\u00adinsensitive information is utilized. \nIn the limit that all edges are back edges and the ratio is one, the flow-sensitive method achieves the \nsame results as the flow-insensitive solution. For intermediate ratio values, a result is achieved which \nis between the two limiting solutions. Even though we adopt a more conservative flow-insensitive solution \nfor back edges, our method still benefits from a flow-sensitive intraproce\u00addural analysis of each procedure. \nReturned constants can be accommodated by extending our flow-sensitive method to include one additional \ntopolog\u00adical traversal of the PCG which is performed in the reverse direction. During this traversal, \na second flow-sensitive in\u00adtraprocedural analysis of each procedure is performed to iden\u00adtify the procedure \ns set of returned constant parameters and global variables that are propagated to the invoking call site. \nA flow-insensitive solution can be precomputed and used for back edges in this traversal.  4 Results \nSince this paper describes the behavior of interproce\u00addural constant propagation, we have tried to distinguish \nthe interprocedural effects from the intraprocedural ones. We measure the number of constant candidates \nthat are inter\u00adprocedurally propagated at each call site, and the number of interprocedural constants \nthat are found to hold at the entry of a procedure. While the second metric is the main focus of this \npaper, the first metric is also important. The identification of constant candidates can be useful for \nother optimizations, such as procedure inlining and cloning. These results in\u00adclude both constant formal \nparameters and global variables. The metrics eliminate the duplicate counting that can occur if a constant \ninterprocedural value is propagated to a vari\u00adable that is referenced multiple times within a procedure. \nA global variable that is propagated to multiple procedures will be counted once for each procedure that \nit is propagated to. We only propagate scalar variables, although we have observed that at least one \nbenchmark would benefit from the propagation of constant array values. These results do not include the \npropagation of return constants, since the implementation of this feature has not yet been completed. \nOur measurements were made on the Fortran subset of the SPECfp92 benchmarks[3] (except 047.TOMCATV, which \nhas no call sites), and the 030.matrix300 program from the first SPEC suite[21 ], See [7, 17] for an \nanalysis of interprocedural aspects of the Fortran subset of the first SPEC suite. The Fortran SPEC benchmarks \nare all written in Fortran77, which does not support recursion as a language feature. None of these benchmarks \nhave back edges in the PCG. Table 1 presents one metric, the number of call site constant candidates \nthat are interprocedurally propagated. We report the number of constant actual arguments and the number \nof constant global candidates for each method, The first column reports the total number of arguments \nin each program. The column labeled IMM reports the number of immediate or literal constant arguments. \nThe first column that is labeled FI reports the number of arguments found to be constant by the flow-insensitive \ninterprocedural method. Perform flow.insens for formal parameters, recording the constant status of each \nargument lnkialiZf2 i311formal parameters to T Collect initial constants from block data as an imaginary \ncall to main For each procedure, p, in a forward topological traversal of the PCG For each call site \nof p If all arguments corresponding to a particular formal parameter of p are the same constant propagate \nthe constant to the formal parameter of p end if if a global is the same constant on each call to p \npropagate the global constant top end if 1 Use$ow-insensitive information ifa calling procedure has not \nbeen processed. *I end loop Perform a flow-sensitive intraprocedural constant propagation on p If a constant \nis used as an argument Record the argument as constant I* This will discard the$ow-insensitive solution \nfor this argument. *I end if if a global constant at a call site is in the Ref set for the callled procedure \nthen Record the global as constant at this call site end if end loop Figure 4: Flow-Sensitive ICP for \nFormal Parameters and Global Variables CALL SITIECONSTANT CANDIDATES ARGUMENTS PROGRAM ARG IMM PCT FI \nPCT.~ 013. SPICE2G6 2983 384 13% 384 13% 430 14% o 533 302 015.DODUC 483 39 8% 39 8% 43 9% o 1 1 030, \nMATRIx300 178 25 14~o 25 14% 110 62% o 0 0 034. MDLJDP2 195 11 6% 11 6% 11 6% 16 69 38 039.wAvE5 676 \n30 4% 32 5% 49 7% 74 249 231 048,0RA o -1677 077. MDLJSP2 195 11 6% 11 6 %0 11 6 %0 o 0 0 078.swM256 \no -0 0 0 089. SU2COR 644 110 17% 110 17% 110 17% o 0 0 090. HYDR02D 197 28 14% 28 14% 28 14% o 1 1 093.NAsA7 \n104 33 32% 33 32% 45 43% o 3 3 094.ITPPP 103 17 17% 17 17% 21 20% o 8 4  TOTAL 5758 688 11.9% 690 12.0% \n858 14.9% 106 871 587 Table 1: Interprocedural Call Site Constant Candidates in the SPEC Benchmarks The \nfirst column that is labeled FS reports the number of arguments found to be constant by the flow-sensitive \ninter\u00adprocedural method. The adjacent columns report the results as a percentage of the number of arguments. \nThe last row records the totals for all of the benchmarks. The flow-insensitive method only finds 2 additional \ncon\u00adstant arguments in 1 benchmark. Any increase from the flow\u00adinsensitive method results from the pass-through \nof constant immediate values, few of which are expected. The flow\u00adsensitive method finds 168 additional \nconstant arguments in 6 benchmarks, which are 2.9% of the total number of argu\u00adments, and 24910more than \nthe flow-insensitive method. - In Table 1, the second column that is labeled FI lists the number of global \nconstants that are initialized in a block data subprogram, and represents the number of candidates considered \nfor propagation by the flow-insensitive algorithm. The second column that is labeled FS reports the number \nof global constants that reach the call site and are referenced in the called procedure (directly or \nindirectly), using the flow\u00adsensitive method. The column labeled VIS reports the number of global constants \nthat are visible in the calling procedure, using the flow-sensitive method. The difference between these \ntwo measurements represents the number of invisible global constants that are passed at a call site. \nTable 2 presents a second metric, the number of inter\u00adprocedurally propagated constants that are found \nto hold at the entry of a procedure, The column labeled FP reports the number of formal parameters in \neach benchmark. The first column that is labeled FI reports the number of for\u00admal parameters found to \nbe constant by the flow-insensitive interprocedural method. The first column that is labeled FS reports \nthe number of formal parameters found to be constant by the flow-sensitive interprocedural method. The \nadjacent columns report the results as a percentage of the number of formal parameters. The last row \nrecords the totals for all of the benchmarks. In order for a formal to be detected as constant, all cor\u00adresponding \narguments must have the same constant value. The flow-insensitive method finds 49 constant formal para\u00admeters \nin 10 benchmarks, which are 4.7q0 of the total. The flow-sensitive method finds 76 constant formal parameters, \nwhich are 7.3 -ZOof the total. The flow-sensitive method finds 27 additional constant formal parameters, \nin 3 benchmarks, which are 2.6% of the total number of formal parameters, and 55% more than the flow-insensitive \nmethod. Table 2 also reports the number of global constants in\u00adterprocedurally propagated by the flow-insensitive \nand flow\u00adsensitive methods. The column labeled Procs lists the num\u00adber of procedures in each program \nthat are reachable from the main procedure, including the main procedure. The second column that is labeled \nFI reports the total number of global constants, found with the flow-insensitive analysis, that occur \nat the beginning of a procedure and are referenced directly in that procedure. This amounts to a count \nof the number of constants that are initialized in a block data subprogram and not defined elsewhere \nin the program. The first column that is labeled FS reports the total number of global constants, found \nwith the flow-sensitive analysis, that occur at the beginning of a procedure and are referenced directly \nin that procedure. The flow-insensitive method finds 56 global constants in these benchmarks, which is \ngreater than the number of constant formal parameters that it discovers (49). The flow\u00adsensitive method \nfinds 175 global constants in the same benchmarks, which is more than twice the number of con\u00adstant formal \nparameters that it discovers. The flow-sensitive method finds more than three times the number of global \nconstants than the flow-insensitive method. Our metrics are based on the count of the number of interprocedural \nconstants that are propagated to and used by each procedure, rather than counting the total number of \nconstant substitutions. These metrics eliminate possible distortion by counting each interprocedural \nconstant that is propagated to a procedure and referenced, only once, regard\u00adless of the number of references \nwithin a procedure. Sub\u00adstitutions that arise purely from intraprocedural propagation are not counted. \nAn advantage of this metric is that it is inde\u00adpendent of any intraprocedural constant propagation method. \nWe wish to emphasize that our flow-sensitive interprocedural constant propagation method can use any \nflow-sensitive in\u00adtraprocedural constant propagation method. Obviously, the number of constants that \nare propagated by our flow-sensitive method is dependent upon the intraprocedural method used. Our implementation \noptionally propagates floating point constants. We have found that the propagation of float\u00ading point \nconstants does provide a measurable improvement in the performance of certain programs, including some \nof the SPEC benchmarks. The results reported in this section include the propagation of floating point \nconstants. The elimination of floating point constant propagation mainly causes a reduction in the number \nof global constants that are propagated. All of the global constants found by the ftow\u00adinsensitive method \nare floating point constants. 105 of the 175 global constants discovered by the flow-sensitive method \nare floating point constants. In addition, the flow-sensitive method discovers 12 constant floating point \narguments. Even without the propagation of floating point numbers, the flow\u00adsensitive method still discovers \namx-oxirnatelv the same num \u00adber of global constants as form~l parameter constants. The remaining numbers \ndo not change, nor do the comparisons. We have also measured the compilation time for both of our interprocedural \nconstant propagation methods. The flow-sensitive method increases the analysis phase of the compilation \nby 50910over the flow-insensitive method. This result is consistent over all of the benchmarks. Since \nthe analysis phase contributes only a small fraction of the overall compilation time, the increase in \nthe overall compilation time is typically small (< 170). 5 Discussion The most closely related work \nis that of Grove and Tor\u00adczon [16]. They use the number of intraprocedural substi\u00adtutions as the metric \nfor measuring the effectiveness of the interprocedural constant propagation methods. This method was \noriginally suggested by Metzger and Stroud [20] and is useful for assessing the overall effect of constant \npropagation. However, this metric makes it difficult to distinguish inter\u00adprocedural and intraprocedural \neffects. Since we are more interested in the interprocedural effects, we suggest that a more appropriate \nmeasure of the effectiveness of interpro\u00adcedural constant propagation can be obtained by measuring the \nnumber of constant formal parameters and the number of constant globals that are propagated to each procedure. \nThese are the constant values that are propagated interprocedurally. Table 3 presents our results for \nthose first release SPEC benchmarks that were reported by Grove and Torczon. In INTERPROCEDURAL PROPAGATEDCONSTANTS \nFORMAL PARAMETERS PROGRAM FP FI PCT FS  aizi!%d 013. SPICE2G6 307 4 1% 4 1% 120 0 45 015. DODUC 133 \n 2 29t0 2 2% 41 0 1 030. MATRIx300 32 2. 6% 15 ~~i ~o 5 0 0 034. MDLJDP2 40 3 8% 3 8% 36 38 40 039.wAvE5 \n258 5 2% 9 3% 79 0 61 048.oRA o - 3 18 23 077.MDLJSP2 40 3 8% 3 8% 35 0 0 078.swM256 o - 8 0 0 089. SU2COR \n57 4 7% 4 7% 25 0 0 090. HYDR02D 42 7 17% 7 L7% 40 0 0 093.NAsA7 64 15 23% 22 :~dyo 23 0 0 094. FPPPP \n70 4 6% 7 I o% 13 0 2 TOTAL 1043 49 4.7% 76 7.3% 402 56 175 Table2: Inte~rocedural Propagated Constants \ninthe SPECBenchmarks CALL SITE CONSTANT CANDIDATES ARGUMENTS PROGRAM ARG IMM F CT FI pc~ O15.DOtIuc \n483 39 8% 39 8% 39 8% o 0 0 020.NAsA7 97 33 34% 33 34% 42 43% o 0 0 030. MATRIx300 178 25 14% 25 14% \n110 62% o 0 0 042. FPPPP 103 17 17% 17 17% 21 20% o 8 4 TOTAL 761 114 15.0% 114 15.0% 212 27.8% o 8 4 \nTable 3: InterProcedural Call Site Constant Candidates INTERPROCEDURAL PROPAGATED (CONSTANTS PROGRAM \nFP FI ORMAL~ ~~ = 015.DODUC 133 2 2% 2 2% 41 0 0 020. NAsA7 57 15 26% 19 33% 17 0 0 030. MATRIx300 32 \n2 6% 15 47% 5 0 0 042.FPPPP 70 4 6% 7 1o% 13 0 2 TOTAL 292 38 13.0% 43 14.7% 76 0 2 Table4: InterProcedural \nPropagated Constants lNTRAPROCEDURAL SUBSTITUTIONS PROGRAM POLYNOMIAL \\ FI FS 015. DODUC 287 288 288 \n020. NAsA7 336 205 344 030. MATRIx300 138 14 250 042. FPPPP 56 25 79 TOTAL 817 532 961 Table5: Comparison \nof Intraprocedural Substitutions order to provide a better comparison, these results do not include the \npropagation of floating point constants. We only include measurements for procedures that are reachable \nfrom the main procedure, whereas the results presented in [16] include measurements for all procedures \n[15]. Table 4 indicates that the flow-insensitive method does not find any global constants in these \nbenchmarks, The flow\u00adsensitive method only finds two global constants in 1 bench\u00admark. Most global variables \nare not constant at each call site. Note that few globals were considered as candidates for propagation. \nOur method for selecting and propagating global constants creates a sparse list of global variable con\u00adstant \ncandidates at each call site. The implementation of Grove and Torczon builds a jump function for every \nglobal variable at each procedure [15], We have also measured the number of substitutions per\u00adformed \nby the intraprocedural method for these benchmarks. Since we do not propagate return constants, we have \nused the NO Return Jump Function results of Grove and Torczon in the column labeled POLYNOMIAL of Figure \n5. For these benchmarks, there was no difference between the polynomial and pass-through results. Both \nthe polynomial and pass\u00adthrough jump functions use the flow-sensitive lntraproce\u00addural Constant Jump \nFunction to identify additional con\u00adstants before the interprocedural solution is computed. How\u00adever, \nboth the polynomial and pass-through jump functions may not identify some constants, as illustrated in \nFigure 1. The results of our flow-insensitive method are clearly infe\u00adrior to the no return polynomial \njump function results. This is not surprising since the flow-insensitive method only consid\u00aders literal \nconstants as candidates, combined with the pass\u00adthrough effect, On the other hand, our flow-sensitive \nmethod discovers 17.67. more constants than the polynomial or pass-through methods in these benchmarks. \nWe achieve the same num\u00adber of constant substitutions for both the flow-insensitive and flow-sensitive \ninterprocedural constant propagation methods on the 015.DODUC benchmark. This is also the benchmark where \nour results are about the same as the polynomial jump function result. The flow-sensitive method obtains \nsignifi\u00adcantly better results than the flow-insensitive method on the remaining three benchmarks. The \nflow-sensitive method also obtains better results than the polynomial jump function on these same benchmarks. \nRelated Work Wegman and Zadeck [22] present several intraprocedural constant propagation techniques, \none of which (SCC) we employ intraprocedurally. They describe how to extend their algorithms interprocedurally, \nby using procedure integration to increase the effects of constants that are propagated. This extension \nwould capture the effect of return constants, but may not be efficient, in practice. No experimental \nresults are presented. Callahan, Cooper, Kennedy, and Torczon [ 10] describe a method based on jump functions, \nwhich summarize the value of an argument based on the formal parameters of the routine containing the \ncall site, They describe several possible jump functions, with a precision/cost tradeoff. All but the \nliteral jump function include an intraprocedural component that is flow-sensitive. After the jump functions \nare computed, an interprocedural propagation step is performed to propagate constants to each routine. \nGrove and Torczon [16] present experimental numbers for various jump functions based on the number of \nconstants that are substituted intraprocedurally. It is not clear how globals can be efficiently handled \nin this framework. The creation of a jump function for each global variable for each call site can add \nsubstantial overhead. Their method does not handle call graph cycles [15], but does propagate return \nconstants. Burke and Cytron [9] discuss interprocedural constant propagation in high-level terms in the \ncontext of data depen\u00addence analysis. They suggest a pessimistic flow-sensitive interprocedural algorithm \nthat can be modeled as the solu\u00adtion of an incremental intraprocedural problem. Their algo\u00adrithm does \nnot support recursion but does support static call graph cycles, and the propagation of return constants. \nNo experimental results are given. Allen, Burke, Charles, Cytron, and Ferrante [1] de\u00adscribe a flow-insensitive \ninterprocedural algorithm for con\u00adstant propagation of formal parameters, based on the bindings of formal \nparameters. It detects immediate argument con\u00adstants and the transitive effect of passing their corresponding \nparameters as arguments. They do not handle return con\u00adstants and their program model does not include \nprograms that are recursive. No experimental results are given. Metzger and Stroud [20] implemented a \nform of the Callahan, Cooper, Kennedy, and Torczon interprocedural constant propagation algorithm to \nhelp aid procedure cloning. Their results suggest that goal-directed procedure cloning based on constant \npropagation can substantially increase the number of interprocedural constants. Binkley [5] suggests \nan interprocedural constant prop\u00adagation algorithm based on the system dependence graph, a variation \nof the program dependence graph [14, 18]. He utilizes symbolic execution and live-code analysis, but \ndoes not report experimental results. 7 Conclusions This paper describes a flow-sensitive algorithm for \nperform\u00ading interprocedural constant propagation. The algorithm sup\u00adports recursion, while only performing \none flow-sensitive analysis of each routine. Experimental results were pre\u00adsented that show that this \nmethod finds substantially more constants than previous results and is efficient in practice. We have \nalso introduced new metrics for evaluating inter\u00adprocedural constant propagation algorithms which are \nbased on the constant values that are interprocedurally propagated. The number of call site candidates \nand interprocedural con\u00adstants provide better indications of the success achieved by ICP. We have used \nthese metrics to provide measurements of the SPEC benchmarks for our algorithms.  Acknowledgements We \nare grateful to Fran Allen for insisting that we examine this problem, and for her support. We acknowledge \nuse\u00adful discussions with Fran Allen, Michael Burke, Jong-K)eok Choi, Rajeev Gulati and Yong-fong Lee \nduring the initiation of this effort. We thank Yong-fong Lee for his assistance with the implementation \nof floating point support. We thank Dan Grove for providing additional details of his experiment, We \nare grateful to Michael Burke, John Field, Dan Grove, Roger Hoover, Yong-fong Lee, Ganesan Ramalingam, \nHarini Srinivasan, Laureen Treaty, and Ken Zadeck for suggested improvements to earlier drafts of this \npaper. References [1] Frances Allen, Michael Burke, Philippe Charles, Ron Cytron, and Jeanne Ferrante. \nAn overview of the ptran analysis system for multiprocessing. .lournal of Paral\u00adlel and Distributed Computing, \n5(5):617-640, 1988. [2] Frances E. Allen. InterProcedural data flow analysis. Proc. IFIP Congress 74, \npages 398-402, 1974. [3] Subra Balan and Walter Bays editors. Spec announces new benchmark suites cint92 \nand cfp92. Technical report, Systems Performance Evaluation Cooperative, March 1992. SPEC Newsletter, \nVolume4, Issue 1. [4] John Banning. An efficient way to find the side ef\u00adfects of procedure calls and \nthe aliases of variables. 6th Annual ACM Symposium on the Principles of Program\u00adming Languages, pages \n29-41, January 1979, [5] David Binkley. InterProcedural constant propagation using dependence graphs \nand a data-flow model. In International Conference on Compiler Construction, 1994. [6] Michael Burke. \nAn interval-based approach to exlnaus\u00adtive and incremental interprocedural data-flow analy\u00adsis. ACM Transactions \non Programming Languages and Systems, 12(3):341 395, July 1990. [7] Michael Burke and Paul Carini. Compile-Time \nMea\u00adsurements of InterProcedural Data-Sharing in FOR-TRAN Programs, RC 1738976684, IBM T.J. Watson Research \nCenter, November 1991. [8] Michael Burke, Paul Carini, Jong-Deok Choi, and Michael Hind. Flow-insensitive \ninterprocedural alias analysis in the presence of pointers. In K. Pingali, U. Banerjee, D. Gelemter, \nA. Nicolau, and D. Padua, editors, Lecture Notes in Computer Science, 892, pages 234-250. Springer-Verlag, \n1995. Proceedings from the 7th International Workshop on Languages and Compil\u00adersfor Parallel Computing. \nExtended version published as Research Report RC 19546, IBM T. J. Watson Re\u00adsearch Center, September, \n1994. [9] Michael Burke and Ron Cytron. InterProcedural de\u00adpendence analysis and parallelization. In \nSIGPLAN 86 Symposium on Compiler Construction, pages 162 1 75. ACM, July 1986. [10] David Callahan, Keith \nD. Cooper, Ken Kennedy, and Linda Torczon. InterProcedural constant propagation. In SIGPLAN 86 Symposium \non Compiler Construction, pages 152 161, July 1986. [11] Jcmg-Deok Choi, Michael Burke, and Paul Carini. \nEf\u00adficient flow-sensitive interprocedural computation of pointer-induces aliases and side effects. In \n20th Annual ACM SIGACT-SIGPLAN Symposium on the Principles oj Programming Languages, pages 232 245, January \n1993. [12] Keith Cooper and Ken Kennedy. Efficient computa\u00adtion of flow insensitive interprocedural summary \nin\u00adformation. In SIGPLAN 84 Symposium on Compiler Construction, pages 247-258, June 1984. SIGPLAN Notices, \nVol 19, No 6. [13] Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. \nEfficiently comput\u00ading static single assignment form and the control de\u00adpendence graph. ACM Transactions \non Programming Languages and Systems, October 1991. [14] Jeanne Ferrante, Karl J. Ottenstein, and Joe \nWarren. The program dependence graph and its use in optimiza\u00adtion. ACM Transactions on Programming Languages \nand Systems, 9(3):3 19 349, July 1987. [15] Dan Grove. Private Communication, October 1994. [16] D/an \nGrove and Linda Torczon. InterProcedural con\u00adstant propagation: A study of jump function implemen\u00adtations. \nIn SIGPLAIV 93 Conference on Programming Language Design and Implementation, pages 90-99, June 1993. \nSIGPLAN Notices 286. [17] Michael Hind, Michael Burke, Paul Carini, and Sam Midkiff. A comparison of \ninterprocedural array analy\u00adsis methods. Scientific Programming, 3:255 27 1,1994. [18] D. J. Kuck, R. \nH. Kuhn, D. A. Padua, B. Leasure, and Michael Wolfe. Dependence graphs and compiler optimization. In \n8th Annual ACM Symposium on the Principles ofProgramming Languages, pages 207 2 18, 1981. [19] T.J. Marlowe, \nB.G. Ryder, and M.G. Burke. Defining flc~w-sensitivity in data flow problems. In Preparation, 1995. [20] \nR. Metzger and S. Stroud. InterProcedural constant propagation: An empirical study. ACM Letters on Pro\u00adgramming \nLanguages and Systems, 2(1-4), 1993. [21] Joseph Uniejewski. Spec benchmark suite: Designed for today \ns advanced systems. Technical report, Sys\u00adtems Performance Evualation Cooperative, Fall 1989. SF EC Newsletter, \nVolume 1, Issue 1. [22] Mark N. Wegman and F. Kenneth Zadeck. Con\u00adstant propagation with conditional \nbranches. ACM Transactions on Programming Languages and Systems, 13(2):181-210, 1991.  \n\t\t\t", "proc_id": "207110", "abstract": "<p>We present a flow-sensitive interprocedural constant propagation algorithm, which supports recursion while only performing one flow-sensitive analysis of each procedure. We present experimental results which show that this method finds substantially more constants than previous methods and is efficient in practice. We introduce new metrics for evaluating interprocedural constant propagation algorithms which measure the number of interprocedural constant values that are propagated. We use these metrics to provide further experimental results for our algorithm.</p>", "authors": [{"name": "Paul R. Carini", "author_profile_id": "81100615742", "affiliation": "IBM T.J. Watson Research Center, P.O. Box 704, Yorktown Heights, NY", "person_id": "P221032", "email_address": "", "orcid_id": ""}, {"name": "Michael Hind", "author_profile_id": "81339504521", "affiliation": "Department of Mathematics and Computer Science, State University of New York at New Paltz, New Paltz, NY and IBM T.J. Watson Research Center", "person_id": "PP43124515", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/207110.207113", "year": "1995", "article_id": "207113", "conference": "PLDI", "title": "Flow-sensitive interprocedural constant propagation", "url": "http://dl.acm.org/citation.cfm?id=207113"}