{"article_publication_date": "06-01-1995", "fulltext": "\n The Power of Assignment Motion Jens Knoop Olliver Ruthing Bernhard Steffen Universitat Passau * CAU \nKielt Universitat Passau * knoop@fmi.uni-passa u.de or@informatik. uni-kiel.d400.de steffen@fmi. uni-passau.de \nAbstract Assignment motion (AM) and expression motion (EM) are the basis of powerful and at the first \nsight incompa\u00adrable techniques for removing partially redundant code from a program. Whereas AM aims \nat the elimination of complete assignments, a transformation which is al\u00adways desirable, the more flexible \nEM requires tempo\u00adraries to remove partial redundancies. Based on the observation that a simple program \ntransformation en\u00adhances AM to subsume EM, we develop an algorithm that for the first time captures all \nsecond order effects between AM and EM transformations. Under usual structural restrictions, the worst \ncase time complexity of our algorithm is essentially quadratic, a fact whlich explains the promising \nexperience with our implemen\u00adtation. Topics: data flow analysis, program optimization, partially redundant \nassignment and expression elimina\u00adtion, code motion, assignment motion, bit-vector data flow analyses. \n1 Motivation A major source for improving the run-time efficiency of a program is to avoid unnecessary \nrecomputations iind reexecutions of values (expressions) and instructions (assignments), as it is illustrated \nin Figure 1 ancl 2, respectively. * Fakultat ff.ir Mathematik und Informatik, Universitat Pas\u00adsau, Innstra13e \n33, D-94032 Passau, Germany. tInstitut fur Informatik und Praktische Mathernatik, Christian-Albrechts-Universitat, \nPreuf3erstraf3e 1-9, D-24105 Kiel, Germany. Permission to copy without fee all or part of this material \nis granted provided that the copies are not made or distributed for direct commercial advantage, the \nACM copyright notice and the title of the publication and its date appear, and notice is given that copying \nis by permission of the Association of Computing Machinery.To copy otherwise, or to republish, requires \na fee and/or s~ecific Permission. SIGPLAN 95~a Jolla, CA USA 0 1995 ACM 0-89791 -697-2/95/0006 ...$3.50 \nFigure 1 shows how to avoid the unnecessary recom\u00adputations of a + b in node 2 and 3 by initializing \na new temporary h in node 1 and replacing the original occurrences of a + b by h. This is known as partially \nredundant expression elimination (PREE) or as expres\u00adsion motion (EM) for short (cf. [4, 9, 11, 16, 18, \n20]). a) b) 1 1 h:=a+b 2 z,=a+b 3 x,=a+b 2 z:=h 3 x.=h x := a+b y:=x+y x := h y:= x+ 4 Out(.r,y,z) 4 \nOld(.r,y,<) @ @ Figure 1: Expression Motion (EM) Figure 2 shows how to avoid the unnecessary reexe\u00adcution \nof x:= a + b in node 3 of the loop by hoisting the occurrences of x:= a+ b in node 2 and 3 to node 1. \nIn analogy to PREE this technique is called partially redundant assignment elimination (PRAE) or simply \nassignment motion (AM) (cf. [7]). 4 b) 1 1 x,=a+b 2 z:=a+b 3 x:= a+b y:= x+y 2 z:=a+b 3 x.=a+b y = .x+y \n4 mfx,y) 4 OUf(x,y) @ * Figure 2: Assignment Motion (AM) Note that the program transformations of Figure \n1 and 2 are incomparable. However, after the simple program transformation illustrated in Figure 3(a), \nAM subsumes EM. In fact, applying AM to the program of Figure 3(a) results in the one of Figure 3(b). \nWe exploit this observation for the construction of an b] 1 hl :=c+d 1 B 1 h= a+b .r,=h 2 ;.~;+b 3 \\:: \n~+b Z,=h 23 y = .T+y y,=x+y h=a+b x=h 4 out(x,y>z) Our(x,y>z) @ Figure 3: Uniform EM &#38; AM aggressive \nand uniform algorithm capturing all second order effects between EM and AM transformations, In fact, \ntransformed programs are expression optimal in the following sense:l each execution requires at most \nas many expression evaluations as its counterpart in any other program resulting from some arbitrary \ncom\u00adbination of AM and EM transformations. Besides expression optimality, costs for assignments are a \nmajor concern, in particular, as EM introduces assignments to temporaries. This is taken care of by the \nfinal jlush phase of our algorithm, which eliminates all unnecessary assignments to temporaries introduced \nduring the redundancy elimination phase. 1.1 The Running Example The example of Figure 4 illustrates \nthe power of our algorithm, which is unique in performing the optimiza\u00adtion displayed in Figure 5. 1 \ny:=c+d I J 2 X+.2> y+i ? 3 y:=c+d X:=y+z i;=i+x x:= y+z 4 x:=c+d out(i,x,y) D Figure 4: The Running Example \n This optimization is achieved by our algorithm in the following steps: It eliminates the assignment \ny:= c+ d in node 3, which is redundant with respect to the cor\u00adresponding assignment of node 1. Additionally, \nit ini\u00adtializes a temporary hl in block 1 by c + d and a temporary h2 in block 1 and 3 by x + z and replaces \nthe original occurrences of c + d in node 1 and 4 by hl, and the original occurrence of x + z in node \n2 by 1Expression optimality is called computational optimality in [16, 18]. 234 y :=hl h2 := X+2 x:= \ny+z 2 h2>y+i? 3 i =i+x M:=x+.z h Figure 5: The Power of Uniform EM &#38; AM h2. Note that this suspends \nthe blockade of the assign\u00adment c:= y + z in the loop. Thus, as a second order effect the assignment \nx:= y + z can now be removed from the loop by simultaneously hoisting it with the corresponding assignment \nof node 4 to node 1, Note that our algorithm does not touch the assign\u00adment i := i +x in node 3 and the \ncomputations of y + i and i + x in nodes 2 and 3, respectively, which cannot be moved profitably.  1.2 \nSeparate Effects It is worth noting that standard techniques for EM and AM fail to achieve the optimization \nof Figure 5. In particular, they fail to eliminate the most signifi\u00adcant inefficiency in the program \nof Figure 4, the loop invariant assignment x:= y + z in node 3, which is blocked by the assignment to \ny in node 3 and the use of z in the Boolean expression controlling the loop it\u00aderation. This is illustrated \nin Figure 6(a) and 6(b), which display the separate effects of EM and AM to the program of Figure 4, \nrespectively. a) b) 1 y:= c+d 2 .2+2.> y+i ? 3 ::=y+z 1..= 1+X s Figure 6: The Separate Effects of EM \nand AM  1.3 The Algorithm The systematic treatment of second order effects as between the expression \nx + z and the assignments y:= c + d and z:= y + z in the example of Figure 4 is an important feature \nof our algorithm, which for the first time captures all second order effects between AM and EM in three \nsteps: 1. Initialization: Introducing temporaries 2. Assignment Motion: Eliminating partially redun\u00addant \nassignments 3. Final Flush: Eliminating unnecessary initializa\u00adtions of temporaries  The first step \nreplaces every assignment z:= t by the sequence of ht:= t;z:= ht, where ht is a new tempor\u00adary that is \nassociated with the term t.2This enhances AM to cover EM. The second step moves all assignments as far \nas pos\u00adsible in the opposite direction of the control flow to their earliest safe program points. This \nmaximizes the potential of redundant assignments, which are sub\u00adsequently eliminated. The third step \nis a transformation in the spirit of the laz~ code motion (lcm) transformation of [16, 1.8]. Essentially, \nit flushes all assignments to temporaries introduced in the first step that do not contribute to the \nelimination of a partial redundancy. Our algorithm works for arbitrary control flow struc\u00adtures and elegantly \nsolves the problem of distinguishing between profitable code motion across loop structures and fatal \ncode motion into loops (cf. [2]). This is illus\u00adtrated in the example of Figure 7(a), which contains \ntwo loop constructs, one of which is even irreducible. b) 2 x. 2 x=,,, 3 x:. y+2 4 0 :{.) 3 x,=y+z 4 \nour(x) ) 5 5   +331 7 6 6 X,= Y+2 + 7 X.=Y+Z 8 9 x= y+z 10 11 .r:=y+z 12 out(x) 12 [-J @ Figure 7: \nIllustrating the Treatment of Loops 2A similar step was suggested in [3] in order to separate the effects \nof moving stores from the effects of moving expression. Figure 7(b) shows that our algorithm moves the \npar\u00adtially redundant assignments of node 7, 9, and 11 to node 6. Thereby, the assignment of node 11 is \nmoved across the irreducible loop construct. It is worth noting that the assignment in node 6 is still \npartially redun\u00addant. However, the elimination of this partially redun\u00addant assignment would require \nto move z:= y + z into the first loop, which would dramatically impair some program executions. 1.4 Related \nWork In contrast to EM, which has thoroughly been stud\u00adied in program optimization (cf. [2, 4, 8, 9, \n10, 11, 16, 18, 20]), AM has yet been investigated rarely. The most relevant papers on this subject are \nby Dhamd\u00adhere [5, 6, 7]. Most similar to the assignment motion step of our algorithm is the algorithm \nof [7], where an extension of EM to AM is presented. In contrast to our approach, however, Dhamdhere \ns algorithm heuris\u00adtically restricts assignment hoistings to immediately profitable ones, i.e., to hoistings \nwhich eliminate a par\u00adtially redundant assignment. This restriction prohibits optimal transformation \nresults. E.g., the partially re\u00addundant assignment z:= y + z at node 4 in the simple example of Figure \n8 remains in the program, as the blocking preceding assignment a:= z+ y cannot prof\u00aditably be hoisted. \nIn contrast, after suspending the blockade of z:= y + z by hoisting the assignment of a := x+ y to node \n2 and 3, which is displayed in Figure 9(a), our algorithm yields the result of Figure 9(b). 11 2 x:= \ny+z 3[ a:=x+y 4 x := y+z out(a,x) 1 Figure 8: No Effect of Restricted AM a) b) 9 11 x:= y+z 3 a:= X+Y \n~ x:= y+z 3 a:= x+y 2 a ;= x+y .%;= y+z a := x+y x:= y+z x:= y+z 4 Out(a,x) 4 Out(a,x) e Figure 9: The \nEffect of Unrestricted AM In [5, 6] Dhamdhere presents an application of as\u00ad signment hoisting and sinking \ntechniques to register assignment. This, however, does not contribute to the general problem of eliminating \npartially redundant as\u00adsignments. Structure of the Paper After the preliminary Section 2, Section 3 presents \nthe central notions of our approach and establishes the es\u00adsential features of eliminating partially \nredundant as\u00adsignments and expressions. Subsequently, Section 4 sketches the second order effects between \nEM and AM, and develops our algorithm, which is illustrated in full detail by means of the running example \nof Figure 4. Additionally, a complexity estimation of the algorithm is given. Section 5 presents the \noptimality result of our algorithm, and Section 6 discusses pragmatic aspects of its implementation. \nFinally, Section 7 cent ains our conclusions, and the Appendix presents the equation systems specifying \nthe data flow analyses of our algo\u00adrit hm.  2 Preliminaries We consider variables v E V, terms t c T, \nand di\u00ad rected flow graphs G = (N, E,s, e) with node set N and edge set E. Nodes n c N represent basic \nblocks of instructions, edges (m, n) c E the nondeterministic branching structure of G, and s and e the \nunique start node and end node of G, which are assumed not to possess any predecessors and successors, \nrespec\u00adtively. Additionally, succ(n)=~f { m [ (n, m) E E } and pred(n) df { m I (m, n) E E } denote the \nset of all im\u00admediate successors and predecessors of a node n, re\u00adspectively. A path p in G is a sequence \nof nodes (n,,..., n~), where V 1 S i < k, n~+l s succ(ni), and P [m, n] denotes the set of all finite \npaths from m to n, Every node n e N is assumed to lie on a path from s to e. Instructions are assignment \nstatements of the form v := t including the empty statement skip,3 write state\u00adments of the form out(. \n..), and Boolean expressions representing the branching condition of branch nodes, i.e., of nodes having \nmore than one successor. An assignment (expression) pattern Q (E) is a string of the form v := t (t). \nAs usual (cf. [20]), we assume that t contains at most one operator symbol. The rea\u00adsonability of this \nassumption, which simplifies the pre\u00adsentation of our algorithm, is discussed in more detail in Section \n6. Moreover, we assume that every expres\u00adsion pattern s is non-trivial, i.e. contains exactly one operator \nsymbol, and is associated with a unique tem\u00adporary h., which is used for storing the value of e in sIn \nparticular, assignments of the form x:= x are identified with skip, order to eliminate partially redundant \noccurrences of E. Given a program G, ST denotes the set of all ex\u00adpression patterns occurring in G, and \nAP the set of all assignment patterns which is enriched by the set of all assignment patterns of the \nform h. := e and v:= he for all e ~ SP occurring on the right hand side of an assignment with left hand \nside variable v. Moreover, for all programs G, paths p E P[s, e], and patterns @ E AP Ut?.P, let $$#(pG) \ndenote the number of occurrences of the pattern @ on p in G. 2.1 Critical Edges It is well-known that \ncode motion transformations can be blocked by critical edges of a flow graph, i.e., by edges leading \nfrom a node with more than one successor to a node with more than one predecessor (cf. [4, 9, 16, 17, \n18, 19]),  a)+ / b) 1 x:=a+b 2 1 x:=a+b 2 v S*, r--ri -, ,~ ~=-a~b-l 3 x.=a+b 3 % Figure 10: Critical \nEdges In Figure 10(a) the assignment x:= a + b at node 3 is partially redundant with respect to the assignment \nat node 1. However, this partially redundant assign\u00adment cannot safely be eliminated by moving it to \nits predecessors, because this may introduce a new assign\u00adment on a path leaving node 2 on the right \nbranch. On the other hand, it can safely be eliminated after in\u00adserting a synthetic node S2,3 in the \ncritical edge (2, 3), as illustrated in Figure 10(b). In the following, we therefore restrict our attention \nto programs where every critical edge has been split by inserting a synthetic node.  3 Assignment Motion \nConceptually, assignment motion stands for any se\u00ad quence of e assignment hoistings and redundant assignment \neliminations as formally defined below. Definition 3.1 (Assignment Hoisting) Let Q = x:= t be an assignment \npattern. An assign\u00adment hoisting for a is a program transformation that  eliminates some occurrences \nof a,  inserts instances of Q at the entry or exit of some basic blocks from which a basic block with \nan elim\u00adinated occurrence of Q is reachable.  In order to be admissible, assignment hoistings must \nbe semantics preserving. Obviously, the hoisting of an assignment pattern a = x:= tis blocked by an instruc\u00adtion \nthat modifies an operand of t or  uses or modifies the variable z.  Thus, we define: Definition \n3.2 (Admissible Assign. Hoisting) An assignment hoisting for a is admissible, ifl it sat\u00adisfies the following \ntwo conditions: 1. The removed assignments are substituted, i.e., ev\u00ader~ program path leading from s \nto an elimination site of Q contains an insertion site of a that is not followed by an instruction which \nblocks a. 2. The inserted assignments are justified, i.e., everg program path leading from an insertion \nsite of a to e contains an elimination site of Q which is not preceded by an instruction that blocks \na.  Definition 3.3 (Assignment Elimination) An assignment elimination for Q is a program trans\u00adformation \nthat eliminates some original occurrences of Q in the argument program. Like the hoisting also the elimination \nof assignments must be admissible. This leads to the notion of re\u00addundant assignments. An occurrence \nof an assignment pattern a s z := t in a basic block n is redundant, if every path from s to n goes through \na basic block m containing another occurrence of a, and neither z nor an operand of t is modified between \nthe two oc\u00adcurrences, Definition 3.4 (Redundant Assign. Elim.) A redundant assignment elimination for \nan assignment pattern a is an assignment elimination for a, where some redundant occurrences of Q are \neliminated. It is worth noting that admissible assignment hoist\u00adings and redundant assignment eliminations \npreserve the program semantics. This is in contrast to assign\u00adment eliminations based on dead code elimination \n(cf. [12, 19]), In fact, eliminating dead assignments may change the semantics of the program by reducing \nthe potential of run-time errors.4 4Think e.g. of an overflow or a division by zero caused by the evaluation \nof the right hand side term of an eliminated assignment. Definition 3.5 (Assignment Motion) Assignment \nmotion AM is an arbitrary sequence of admissible assignment hoistings and redundant assign\u00adment eliminations. \n 3.1 The Universe In the following we will write G FEM G or G kAM G if the flow graph G results from \nG from applying an expression motion transformation (see Figure 1 for il\u00adlustration, and e.g. [18] for \ndetails), or from applying an assignment motion transformation, i.e., from ap\u00adplying an admissible assignment \nhoisting or redundant assignment elimination, respectively (see Figure 2 for illustration). Moreover, \nlet F =~ bE~ U ~AM. For a given flow graph G we denote the universe of programs resulting from an arbitrary \ninterleaving of expression and assignment motions by g=~f{G / GI-*G } Important for our optimality result \nis the following property of l-, which holds due to identifying assign\u00adments of the form he := he by \nskip. Lemma 3.6 (Local Confluence of l-) t-is locally confluent, i, e, if GI F Gz and GI F G3 for some \nprogram GI E G then there is a program G4 e g such that Gz I-* G~ and Gs l- Gd. 3.2 Optimality Central \nfor comparing the quality of different programs of the universe g are standards of comparison that are \ntypically given in terms of preorders, i.e. relations that are reflexive and transitive but not antisymmetric. \nIt is worth noting that due to the absence of antisymmetry in a preorder ~ also programs that are quite \ndifferent at first sight are similar in terms of this order, where similarity is given by its core N \n=W ~ fl ~. A preorder ~ on L7 induces two notions of optimality for a program G of ~, First, G is ~-optimal, \nif it is better than any other program of Q, and it is rela\u00adtivel~ ~-optimal, if it cannot be improved \nfurther by means of admissible expression and assignment motion transformations. Definition 3.7 (Optimalit \ny &#38; Relative Opt.) A program G c G is 1. relatively ~-optimal, ifl VG ~~.G F G + G ~G ,  2. ~-optimal, \nif VG E~, G ~ G .   For our algorithm we are considering three preorders which reflect the different \noptimization goals it covers: Primary Goal: Avoiding unnecessary recompu\u00adtations of expressions. Secondary \nGoals: Avoiding unnecessary reexecutions of assign\u00adments.  Avoiding unnecessary assignments to and \nun\u00adnecessarily long lifetimes of temporaries.  The corresponding preorders are given below: Definition \n3.8 (Optimization Preorders) Let G , G E g. Then we define: 1. G is expression-better than G\\ , in signs \nG,, C _ezP G , if and only if Vp c P[S, e] YE C ~P. E#(PGf) < &#38;#(PG ) 2. G is assignment-better than \nG , in signs G La, G , if and only if dp E p~s,(?] V ~ E AP. CY#(PG) < ~#(PGH) 3. G is temporary-better \nthan G , in signs G,, C  titmP G , if and only if any lifetime range of a temporay hc used in G is contained \nin a corre\u00adsponding lifetime range of G .5  4 The Algorithm In this section we present our algorithm \nfor the redundancy-and temporary-optimal elimination of partially redundant assignments and expressions. \nWe first give an overview of the algorithm, and subse\u00adquently describe the relevant steps in more detail \nil\u00adlustrating them by means of the running example of Figure 4, which we recall below. 1 y:=c+d 2 X+Z \n>y+i ? 3 Y:= c+d x:= y+z i ,= i+x v X:=y+z x:=c+d out(i,x,y)m Figure 11: The Running Example 5L~fetzme \nranges are paths between an assignment to he and its first subsequent use. See [18] for details. 4.1 \nOverview The global algorithm consists of three main procedures: a procedure rae for the elimination \nof redundant assignments,  a procedure aht for assignment hoistings, and  . a procedure lcm for the \nelimination of unnecessary assignments to temporaries which are organized in three phases: 1. Initialization: \nIntroducing temporaries 2. Assignment Motion: Eliminating partially redun\u00addant assignments 3. Final \nFlush: Eliminating unnecessary initializa\u00adtions of temporaries  The initialization phase decomposes \nevery assignment occurring in the program in an initialization of a uniquely determined temporary and \na use of this tem\u00adporary in the original assignment. As mentioned already this simple transformation \nenhances AM to cover EM. The assignment motion phase, subsequently, which is the main phase of our global \nalgorithm, is com\u00adposed of the rae-and aht-procedure, which are applied until the program stabilizes. \nThe concluding final flush phase is an application of essentially the lcm-procedure of [18], and eliminates \nall unnecessary assignments to temporaries introduced in the initialization phase. Convention: In the \nfollowing we denote the program that results from applying our global algorithm to G by GGIObAlg, and \nthe intermediate programs result\u00ading from the initialization and the assignment motion phase by G1nit \nand G~.,MOt, respectively,  4.2 The Initialization Phase The initialization phase replaces every assignment \nz:= t by the assignment sequence ht := t; a:= ht, where ht is the unique temporary associated with term \nt.Obviously, this transformation is an admissible ex\u00adpression motion. Moreover, it enhances AM to cover \nEM. We have:6 Lemma 4.1 (Initialization Phase Lemma) 1. G1n~t~~ 2. Let Gt, G E ~ such that GIn~t l- \nG I-EM G . Then we have: G FAM G ,  Applied to our running example the initialization phase comes up \nwith the program of Figure 12: 6Remember that assignments of the form he := hs are iden\u00adtified with skip. \n . I-iG-a ljl:==f;d 3 u) 114 :=h;+z .\u00ad h5:= i+x i :=h5 h4 := Y+Z4 x :=h4 M:= c+d X :=hl out(i,x, y) A \n Figure 12: The Effect of the Initialization Phase  4.3 The Assignment Motion Phase The assignment motion \nphase is concerned with the elimination of partially redundant assignments in the program resulting from \nthe initialization phase. Con\u00adceptually, this is achieved in two steps: (1) Moving the assignments as \nfar as possible in the opposite direc\u00adtion of the control flow to their earliest safe execu\u00adtion points, \nand (2) eliminating redundant occurrences of assignments. Though this is very closely in spirit to EM, \nAM is more intricate, because it induces sec\u00adond order effects. In fact, both the hoisting and the elimination \nof assignments usually enable the hoisting and elimination of occurrences of other assignment pat\u00adterns, \nThis is in contrast to the hoisting and replace\u00adment of expressions, which is free of interdependencies \nbetween different expression patterns. In AM, however, we are faced with the following mutual dependencies, \nwhich have been illustrated already by the motivating examples of Section 1: Hoisting-Elimination Effects \n Hoisting-Hoisting Effects  Elimination-Hoisting Effects  Elimination-Elimination Effects  The assignment \nmotion phase overcomes all of thlese second order effects by means of exhaustive hoisting and elimination \nsteps: The procedures rae and aht are applied until the program stabilizes. In the following we discuss \nthese procedures in more detail. 4.3.1 Redundant Assignment Elimination The elimination of redundant \nassignments is based on a forwards directed bit-vector data flow arlal\u00adysis [1, 13], which is specified \nin Table 2, where N-REDUNDANT,(a) (or X-REDUNDANT,(a)) means that assignment pattern a is redundant at \nthe entry (or exit) of instruction L. After having computed the greatest solution of the equation system \nspecified in Table 2, the corresponding program transformation is very simple: The Elimination Step: \nProcess every basic block by successively eliminating all assignments which are redundant immediately \nbefore them, i.e., redundant at their entry.  4.3.2 Assignment Hoisting The program analysis of this \nstep determines how far an assignment can be hoisted from its original lo\u00adcation to earlier program points, \nwhile maintaining the program semantics. In fact, this analysis is dual to the delayability analysis \nof the partial dead code elimination algorithm of [19], which was designed to determine how far an assignment \ncan be sunk from its original location to later program points, while maintaining the program semantics. \nTable 1 presents the hoistability analysis in a bit-vector format, where each bit corresponds to an assignment \npattern occur\u00adring in the program, Here, N-HOISTABLEn and X-HOISTABLEn intuitively mean that some hoist\u00ading \ncandidates of a can be moved to the entry or the exit of basic block n, respectively, where a hoisting \ncan\u00addidate is an occurrence of an assignment x:= tinside a basic block which is not blocked, i.e., neither \npreceded by a modification of an operand of t nor by a modifi\u00adcation or a usage of Z. This is illustrated \nin Figure 13. Note that in the set of occurrences of an assignment pattern in a basic block at most the \nfirst one is a can\u00addidate for global hoisting, because every occurrence is blocked at least by the preceding \none. x:=(j a:=d y,:= iwb y:=a+b x:=3*y x:=3*y a:=c a:=c y:= a+b y:= a+b   ElEl Hoisting Candidate \nFigure 13: Hoisting Candidates of g:= CL+ b The greatest solution of the equation system dis\u00adplayed \nin Table 1 characterizes the program points, where instances of the assignment pattern a must be inserted, \nby means of the insertion predicates N-INSERT and X-INSERT. The subsequent pro\u00adgram transformation is \nagain very simple, because it can easily be shown that all assignment patterns that must be inserted \nat a particular program point are in\u00ad dependent and can therefore be placed in an arbitrary order: The \nInsertion Step: Process every basic block by successively inserting in\u00adstances of every assignment pattern \na at the entry (or exit) of n if N-INSERT.(Q) (or X-INSERT.(a)) is satisfied, and simult aneousiy remove \nall hoisting candidates.7 It is easy to see that the program resulting from the assignment motion phase \nsatisfies: Lemma 4.2 (AM-Phase Lemma) 1. ~AssMot Gg 2, ~AssMot is relatively assignment-optimal in ~, \ni.e. relatively ~ -optimal ass Moreover, as an immediate consequence of Lemma 4.1 (2), Lemma 4.2(2), \nand the exhaustive introduction of temporaries during the initialization phase, we have: Corollary 4.3 \n(AM-Phase Corollary) GA~,~Oi is relatively expression-optimal in ~, i.e. relatively K -optimal. ezp \nApplied to the program of Figure 12 the assignment motion phase terminates with the program of Figure \n14: 1 m h2 := X+2 hs := y+i ha:= Y+Z x:=h4 2 h2 >h3 ? 3 h5:= i+x i:=h5 h2 := X+Z h3:= y+i ?3 m Figure \n14: The Effect of the AM-Phase 4.4 The Final Flush Phase Intuitively, the final flush phase moves the \noccurrences of all assignment patterns of the form hg := s to their 7Due to edge splitting there are \nno insertions at the entry of join nodes. latest safe execution points, and eliminates all occur\u00adrences \nwhose left hand side is used at most once im\u00admediately after their occurrence. The following lemma states \nthree important properties of this transforma\u00adtion. First, it stays within the program universe ~. Second, \nit guarantees relative temporary-optimality, which can be proved along the lines of the lifetime optimality \nTheorem of [18], and third it preserves the optimization of the assignment motion phase. Lemma 4.4 (Final \nFlush Phase Lemma) 1. GGlo&#38;@ 6 g 2. G~lobAlg is relatively temporary-optimal,  i.e. relatively \n~ ~mP-optimal 3. (a) G~lObAlg is relatively assignment-optimal, i.e. relatively ~a88 -optimal Essentially, \nin the final program assignments to tem\u00adporaries are only present, if they are jt.%ified by the elimination \nof a partial redundancy. This guaranty is a central feature of the lazy code motion procedure of [16, \n18], which distinguishes it from all previous algo\u00adrithms for EM. This property carries over to the final \nflush phase of our algorithm, which is realized by a variant of the lazy code motion procedure of [18], \na straightforward adap\u00adtion of the original procedure to our current situation. Similar to the original \nprocedure it is based on two uni-directional bitvector data flow analyses computing delay able program \npoints, where an initialization is us\u00adable8 (cf. Table 3). Applying this procedure to the program of \nFigure 14 yields the desired program of Figure 15: 1 hi:= c+d y:=hl h2 := X+2 x:=y+z 2 h2>y+g? 3 i:= \ni+.x w:= x-l-z m  L&#38;l Figure 15: The Effect of the Final Flush 8EssentiallY, an initialization \nis wdde, if it k used twice on some program continuation. This analysis replaces the less intu\u00aditive \nisokdion analysis of [16, 18]. 4.5 Complexity of the Algorithm The termination of the initialization \nphase is obvious as it only replaces the original assignments by a se\u00adquence of two assignments. Also \nthe termination of the final flush phase is obvious as it consists of the single application of the lcrr-procedure. \nThe assignment ]mo\u00adtion phase, finally, terminates as soon as both steps it is composed of, namely the \ntotally redundant assi~gn\u00adment elimination and the assignment hoisting, leave the program invariant. \nIn the case of totally redun\u00addant assignment elimination this simply means that no further assignments \nare eliminated, and in the case of assignment hoisting this holds, if every basic bloclc n satisfies \nN-INSERT. = LOC-HOISTABLEn and X-INSERT. = false. The complexity of the initialization phase is trivially \nlinear in the program size. For structured programs the final flush phase is almost linear in the program \nsize, since the efficient bitvector techniques of [14, 15, 21] become applicable for solving the uni-directional \ndata flow analyses the km-transformation is based on. In the unstructured case, it is quadratic. The \nsame esti\u00admation holds for a single application of the assignment hoisting and elimination procedure \nof the assignment motion phase. As for the partial dead code elimination algorithm of [19], the number \nof applications of these procedures is at most quadratic in the program size, but linear for realistic \nprograms. Thus, the worst case time complexity of the global algorithm ranges from second order for realistic \nstructured programs to fourth order for the completely unrestricted worst case. 5 Results As already \nstated in Lemma 4.4(1), we have: Theorem 5.1 (&#38;WK!CheSS) GG1.bAlg E ~ Our main results, however, \nstate that the primary goal, namely avoiding unnecessary recomputations of expres\u00adsions, is compatible \nwith a (in a sense best possible) treatment of the secondary goals. Theorem 5.2 (Expression-Optimality) \nGclObAl~ is expression-optimal in ~, i.e., it requires at most as many expression evaluations at run-time \nthan any other program that can be obtained via EM and AM transformations. Proof: The relative expression-optimality \nof G~iob AZ9 is already guaranteed by Lemma 4.4 (3b) and Corollary 4.3. Moreover, according to Lemma \n4.4(3b), it suffices to prove the full expression-optimalit y of GAssiwot to complete the proof. This \ncan be done along the lines of [19]. The point is that 1-contains ~eZP-improving transformations only, \ni.e. Together with the local confluence of !-(cp. Lemma 3.6), we easily conclude that different relatively \nexpression-optimal programs in ~ are equivalent up to N.ZP. Now, the fact that every program in ~ is \ndom\u00adinated (wrt ~eZP) by a relatively expression-optimal one completes the proof. 0 Besides expression-optimality, \ncosts for assignments are a major concern, in particular, as EM introduces assignments to temporaries. \nThe following two the\u00adorems establish the corresponding relative optimality of our algorithm. As it will \nbe argued below, this is the best we can hope for. First we have by means of Lemma 4.2(2): Theorem 5.3 \n(Relative Assignment-Optim.) GcxobAlg is relatively assignment-optimal in G, i.e., it is impossible to \ndecrease the number of assignments required by Gcn0bA19 at run-time by means of EM and AM transformations. \nMoreover, as guaranteed by means of Lemma 4.4(2), the final flush phase of our algorithm eliminates all \nun\u00adnecessary assignments to temporaries: Theorem 5.4 (Relative Temporary-Optim.) GaobAlg as relatively \ntemporary-optimal in !7, i. e. it is impossible to decrease the number of assignments to temporaries \nor the length of temporary lifetimes in Gcw~bAlg by a corresponding assignment sinking. The following \nexample demonstrates that expression\u00adoptimality, and relative assignment-and temporary\u00adoptimality as \nachieved by our algorithm is the best we can hope for: The program of Figure 16 can be transformed into \ntwo expression-optimal programs (see Figure 17(a) and (b)) that are incomparable in both the number of \nassignment executions and the lifetime ranges of temporaries. In Figure 17(a) there are four assignments \non the path (1,3,4,6) as well as on the path (2, 3,4, 6). In Figure 17(b) this ratio amounts to three \nby five, and both solutions cannot further be im\u00adproved wrt 2 . A similar investigation reveals that \nalso the lifeti~~s of temporaries are incomparable in these solution programs. G %agmatics The economical \nuse of temporaries as guaranteed by the final flush phase of our algorithm does not only Whereas EM results \nin the program of Figure 19(a) when applied to the program of Figure 18(a), it gets stuck with the program \nof Figure 19(b) in the 3\u00adaddress case , where the expression t + c is not loop lW invariant, and therefore \ncannot be removed from the loop for safety reasons. 4 5 x:= a) b) *6 x:= a+b &#38; Figure 16: Full \nAssignment-and Temporary- Optimality is Impossible b) w 2 h :=a+b h,=c+d b,=h1 a:= c+d a;= hh =a+b 3 \n@3 5 x:=4 5 x= 4 6 x:=a+b a:=h @ 6 S@x=h v v Figure 17: Incomparable Solutions improve on previous \nalgorithms, it also justifies a tech\u00adnical assumption commonly made by EM-algorithms: argument programs \nare given in 3-address form, i.e., the right hand side terms of assignments contain at most one operator \nsymbol. Though this assumption is uncritical in that all assignments can be canonically decomposed into \nsequences of assignments of this form along the inductive structure of terms (cf. [18]) or a special \nnaming discipline [2], this decomposition may block subsequent transformations. This is illustrated in \nFigure 18(a) displaying a program whose 3-address decomposition is shown in Figure 18(b). Figure 18: \nComplex Expressions vs. 3-Address Code 1 h:= a+b+c 1 hl := a+b &#38; &#38; t:= hl2 x:=~ 2 hz := t+c X \n:= hz * 3 Figure 19: The Effect of Standard EM Usually, this problem is dealt with by interleaving EM \nwith copy propagation (CP) (cf. [9]). This results in the program of Figure 20(a). In contrast, the final \nflush phase of our algorithm guarantees the result dis\u00adplayed in Figure 20(b), which is better than the \npro\u00adgrams given in Figures 19(a) and 20(a). In fact, the final flush phase justifies the 3-address assumption \nin that it guarantees as least as good results after the cor\u00adresponding transformation. 1 hl := a+b 1 \nt:=a+b h2 :=hl+c x := t+c d d Figure 20: Comparing the Effects of EM &#38; CP and Uniform EM &#38; AM \n7 Conclusions We have presented a new, modular and aggressive al\u00adgorithm for the expression-optimal elimination \nof par\u00adtially redundant expressions and assignments in a pro\u00adgram. This algorithm is unique in that it \nfor the first time captures all second order effects due to the mu\u00adtual dependencies between expression \nand assignment hoisting, and the elimination of totally redundant ex\u00adpressions and assignments. The complexity \nof this algorithm ranges from second order for realistic structured programs to fourth order [10] for \nthe completely unrestricted worst case, Thus, as other aggressive methods, our algorithm should typi\u00ad \ncally be employed for structured programs or for the optimization of time-critical sections of code of \nmode\u00ad rate size. Alternatively, one may limit the number of allowed hoisting and elimination steps heuristically. \n[11] References [12] [1] A. V. Aho, R. Sethi, and J. D. Unman. Compd\u00aders: Principles, Techniques and \nTools. Addison- Wesley, 1985. [2] P. Briggs and K. D. Cooper. Effective partial redundancy elimination. \nIn Proc. ACM SIG\u00ad [13] PLAN Conference on Programming Language De\u00adsign and Implementation 9d, volume \n29,6 of ACM SIGPLAN Notices, pages 159-170, Orlando, FL,  [14] June 1994. [3] R. Cytron, A. Lowry, and \nF. K, Zadeck. Code mo\u00adtion of control structures in high-level languages.  [15] In Conj. Record of the \nl~h ACM Symposium on the Principles of Programming Languages, pa,ges 70-85, St. Petersburg, Florida, \nJanuary 1986. [4] D. M. Dhamdhere. A fast algorithm for code [16] movement optimization. ACM SIGPLAN \nNotices, 23(10):172 -180, 1988. [5] D. M. Dhamdhere, Register assignment using code placement techniques. \nJournal of Computer Lan\u00adguages, 13(2):75 -93, 1988.  [17] [6] D. M. Dhamdhere. A usually linear algorithm \nfor register assignment using edge placement of lc}ad and store instructions. Journal of Computer Lan\u00ad \n [18] guages, 15(2):83 -94, 1990. [7] D. M, Dhamdhere. Practical adaptation of the global optimization \nalgorithm of Morel and Ren\u00advoise. ACM Transactions on Programming Lan\u00ad [19] guages and Systems, 13(2):291 \n-294, 1991. Tech\u00adnical Correspondence.  [8] D. M. Dhamdhere and H. Patil. An elimination al\u00adgorithm \nfor bidirectional data flow problems using edge placement. ACM Transactions on Program-[20] ming Languages \nand Systems, 15(2) :312-336, April 1993. [9] D. M. Dhamdhere, B. K, Rosen, and F. K. Zadeck. [21] How \nto analyze large programs efficiently and in\u00adformatively. In Proc. ACM SICPLAN Conference on Programming \nLanguage Design and Implemen \u00adtation 92, volume 27,7 of A CM SIGPLAN Notices, pages 212-223, San Francisco, \nCA, June 1992, K.-H. Drechsler and M. P. Stadel. A solution to a problem with Morel and Renvoise s Global \noptimization by suppression of partial redundan\u00adcies . ACM Transactions on Programming Lan\u00adguages and \nSystems, 10(4):635 -640, 1988. Tech\u00adnical Correspondence. K.-H. Drechsler and M. P. Stadel. A variation \nof Knoop, Riithing and Steffen s lazy code motion. ACM SIGPLAN Notices, 28(5):29 -38, 1993. L. Feigen, \nD. Klappholz, R. Casazza, and X. Xue, The revival transformation. In Conf, Record of the 21nd ACM Symposium \non the Principles of Pro\u00adgramming Languages, pages 421 434, Portland, Oregon, January 1994. M. S. Hecht. \nFlow Analysis of Computer Pro\u00adgrams. Elsevier, North-Holland, 1977, J. B. Kam and J. D. Unman. Global \ndata flow analysis and iterative algorithms. Journal of the ACM, 23(1):158 -171, 1976. K. Kennedy. Node \nlistings applied to data flow analysis. In L onf. Record of the ,Yd ACM Sgm\u00adposium on the Principles \nof Programming Lan\u00adguages, pages 10-21, Palo Alto, CA, 1975. J. Knoop, O. Ruthing, and B. Steffen. Lazy \ncode motion. In Proc. ACM SIGPLAN Conference on Programming Language Design and Implementa\u00adtion 92, volume \n27,7 of ACM SIGPLAN Notices, pages 224-234, San Francisco, CA, June 1992. J. Knoop, O. Ruthing, and B. \nSteffen. Lazy strength reduction. Journal of Programming Lan\u00adguages, 1(1):71-91, 1993. J. Knoop, 0, Riithing, \nand B. Steffen. Optimal code motion: Theory and practice. ACM Trans\u00adactions on Programming Languages \nand Systems, 16(4):1117-1155, 1994. J. Knoop, O. Ruthing, and B. Steffen. Partial dead code elimination. \nIn Proc. ACM SYGPLAN Con\u00adference on Programming Language Design and lm\u00adplementation 9d, volume 29,6 of \nACM SIGPLAN Notices, pages 147-158, Orlando, FL, June 1994. E. Morel and C. Renvoise. Global optimization \nby suppression of partial redundancies. Communica\u00adtions of the ACM, 22(2):96 -103, 1979, R. E. Tarjan. \nApplications of path compression on balanced trees. Journal of the ACM, 26(4):690 -715, 1979. The Assignment \nMotion Phase: a) Hosting Assignments Local Predicates: (Let a = v:= t = AT ) LO C-HOISTABLEn (a): There \nis a hoisting candidate of a in n.  LO C-B LO CKED~ (a): The hoisting of Q is blocked by some instruction \nof n.  The Hoistability Analysis: N-HOISTABLE. df LOC-HOISTABLE. + X-HOISTABLEn * LOC-BLOCKEDn false \nif n=e X-HOISTABLEn (ff ~ N-HOISTABLEm otherwise { Insertion Points: N-INSERT. =4 N-HOISTABLE; X-HOISTABLE; \n*E m~pred(n) X-INSERT. =~f X-HOISTABLE; * LOC-BLOCKED. Table 1: Hoistability Analysis and Insertion \nPoints ~N-H OISTABLE* and X-HO IS TABLE* denote the greatest solution of the equation system for hoistability. \n The Assignment Motion Phase: b) Eliminating Redundant Assignments Local Predicates: (Let a G w:= t c \nAP such that v is not an operand of t.Let s denote the first instruction of s.) e EXECUTED, (a): Instruction \nL is an assignment of the pattern a. o AS S-TRANSP, (a): Instruction 1 is transparent for a, i.e., neither \nv nor any operand of t is modified by L. The Redundancy Analysis: ( false if L=S N-REDUNDANT, df ~ \nX-REDUNDANT~ otherwise i i~pred(~) X-REDUNDANT, df ASS-TRANSP, * (EXECUTED, + N-REDUNDANT,) Table 2: \nRedundant Assignment Analysis a The analysis is employed at the instruction level. This, however, is \nonly for the ease of presentation. In fact, it can straightforward be modified to work on basic blocks. \nThe Final Flush Phase Local Predicates: (Let h, be the temporary for some s c &#38;P. Let s denote the \nfirst instruction of s.) IS-INST (he): Instruction L is an instance of he:= e.  USED~ (h~): Instruction \nL uses he.  BLOCKED (he): Instruction L blocks he :=. e.  The Delayabilit y Analysis: false if L=S \nN-DELAYABLEL = ~ X-DELAYABLE, otherwise { TEpred(L) X-DELAYABLE, = IS-INST, -t-N-DELAYABLE, * USED, \n* BLOCKED, The Usability Analysis: N-USABLE USED, + IS-INST, * X-USABLE, . X-USABLE N-USABLE, x ZCSWC(L) \n Computing Latestness: (No data flow analysis!) N-LATEST, =~f N-DELAYABLE; * (USED, + BLOCKED,) X-LATEST, \n=~f X-DELAYABLE; * ~ N-DELAYABLE; ZGSUCC(L) Initi<Jization Points: Insert instance of a N-INIT, =d~ N-LATEST, \n* X-USABLE; X-INIT, =~f X-LATEST, Reconstruction points: Reconstruct original usage of t instead of h \nRECONSTRUCT, =~ USED, * N-INIT, * X-USABLE; Table 3: Eliminating Unnecessary Assignments to Temporaries \naN-DE LAYABLE* and X-DELAYABLE* (N-USABLE* and X-USABLE*) denote the greatest solution of the equation \nsystem for delayability (usability).  \n\t\t\t", "proc_id": "207110", "abstract": "<p><italic>Assignment motion (AM)</italic> and <italic>expression motion (EM)</italic> are the basis of powerful and at the first sight incomparable techniques for removing partially redundant code from a program. Whereas AM aims at the elimination of complete assignments, a transformation which is always desirable, the more flexible EM requires temporaries to remove partial redundancies. Based on the observation that a simple program transformation enhances AM to subsume EM, we develop an algorithm that for the first time captures all second order effects between AM and EM transformations. Under usual structural restrictions, the worst case time complexity of our algorithm is essentially quadratic, a fact which explains the promising experience with our implementation.</p>", "authors": [{"name": "Jens Knoop", "author_profile_id": "81100197024", "affiliation": "Fakult&#228;t f&#252;r Mathematik und Informatik, Universit&#228;t Passau, Innstra&#946;e 33, D-94032 Passau, Germany", "person_id": "PP40024734", "email_address": "", "orcid_id": ""}, {"name": "Oliver R&#252;thing", "author_profile_id": "81100258003", "affiliation": "Institut f&#252;r Informatik und Praktische Mathematik, Christian-Albrechts-Universit&#228;t, Preu&#946;erstra&#946;e, 1-9, D-24105, Kiel, Germany", "person_id": "PP31092541", "email_address": "", "orcid_id": ""}, {"name": "Bernhard Steffen", "author_profile_id": "81100210663", "affiliation": "Fakult&#228;t f&#252;r Mathematik und Informatik, Universit&#228;t Passau, Innstra&#946;e 33, D-94032 Passau, Germany", "person_id": "PP40024876", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/207110.207150", "year": "1995", "article_id": "207150", "conference": "PLDI", "title": "The power of assignment motion", "url": "http://dl.acm.org/citation.cfm?id=207150"}