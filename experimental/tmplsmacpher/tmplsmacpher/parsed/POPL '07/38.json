{"article_publication_date": "01-17-2007", "fulltext": "\n A Semantics-Based Approach to Malware Detection * Mila Dalla Preda Mihai Christodorescu and Somesh \nJha Saumya Debray Dipartimento di Informatica, Department of Computer Science, Department of Computer \nScience, University of Verona, University of Wisconsin, Madison, WI University of Arizona, Tucson, AZ \nStrada le Grazie 15, 37134 Verona, Italy. 53706, USA. 85721, USA. dallapre@sci.univr.it {mihai,jha}@cs.wisc.edu \ndebray@cs.arizona.edu Abstract Malware detection is a crucial aspect of software security. Cur\u00adrent \nmalware detectors work by checking for signatures, which attempt to capture (syntactic) characteristics \nof the machine-level byte sequence of the malware. This reliance on a syntactic approach makes such detectors \nvulnerable to code obfuscations, increasingly used by malware writers, that alter syntactic properties \nof the mal\u00adware byte sequence without signi.cantly affecting their execution behavior. This paper takes \nthe position that the key to malware identi.\u00adcation lies in their semantics. It proposes a semantics-based \nframe\u00adwork for reasoning about malware detectors and proving properties such as soundness and completeness \nof these detectors. Our ap\u00adproach uses a trace semantics to characterize the behaviors of mal\u00adware as \nwell as the program being checked for infection, and uses abstract interpretation to hide irrelevant \naspects of these behav\u00adiors. As a concrete application of our approach, we show that the semantics-aware \nmalware detector proposed by Christodorescu et al. is complete with respect to a number of common obfuscations \nused by malware writers. Categories and Subject Descriptors F.3.1 [Theory of Computa\u00adtion]: Specifying \nand Verifying and Reasoning about Programs. Mechanical veri.cation. [Malware Detection] General Terms \nSecurity, Languages, Theory, Veri.cation Keywords malware detection, obfuscation, trace semantics, ab\u00adstract \ninterpretation. * The work of M. Dalla Preda was partially supported by the MUR project InterAbstract \nand by the FIRB project Abstract Interpretation and Model Checking for the veri.cation of embedded systems \n. The work of M. Christodorescu and S. Jha was supported in part by the Na\u00adtional Science Foundation \nunder grants CNS-0448476 and CNS-0627501. The work of S. Debray was supported in part by the National \nScience Foun\u00addation under grants EIA-0080123, CCR-0113633, and CNS-0410918. The views and conclusions \ncontained herein are those of the authors and should not be interpreted as necessarily representing the \nof.cial policies or endorsements, either expressed or implied, of the above government agen\u00adcies or the \nU.S. Government. Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. POPL 07 January 17 19, 2007, Nice, France. Copyright c . 2007 ACM 1-59593-575-4/07/0001. . . $5.00 \n1. Introduction Malware is a program with malicious intent that has the potential to harm the machine \non which it executes or the network over which it communicates. A malware detector identi.es malware. \nA misuse malware detector (or, alternately, a signature-based malware de\u00adtector) uses a list of signatures \n(traditionally known as a signature database [22]). For example, if part of a program matches a signa\u00adture \nin the database, the program is labeled as malware [26]. Mis\u00aduse malware detectors low false-positive \nrate and ease of use have led to their widespread deployment. Other approaches for identi\u00adfying malware \nhave not proved practical as they suffer from high false positive rates (e.g., anomaly detection using \nstatistical meth\u00adods [19, 20]) or can only provide a post-infection forensic capabil\u00adity (e.g., correlation \nof network events to detect propagation after infection [15]). Malware writers continuously test the \nlimits of malware detec\u00adtors in an attempt to discover ways to evade detection. This leads to an ongoing \ngame of one-upmanship [23], where malware writers .nd new ways to create undetected malware, and where \nresearchers design new signature-based techniques for detecting such evasive malware. This co-evolution \nis a result of the theoretical undecid\u00adability of malware detection [2,5]. This means that, in the currently \naccepted model of computation, no ideal malware detector exists. The only achievable goal in this scenario \nis to design better detec\u00adtion techniques that jump ahead of evasion techniques and make the malware \nwriter s task harder. Attackers have resorted to program obfuscation for evading malware detectors. Of \ncourse, attackers have the choice of creat\u00ading new malware from scratch, but that does not appear to \nbe a favored tactic [25]. Program obfuscation transforms a program, ei\u00adther manually or automatically, \nby inserting new code or modify\u00ading existing code to make understanding and detection harder, at the \nsame time preserving the malicious behavior. Obfuscation transfor\u00admations can easily defeat signature-based \ndetection mechanisms. If a signature describes a certain sequence of instructions [26], then those instructions \ncan be reordered or replaced with equivalent in\u00adstructions [29, 30]. Such obfuscations are especially \napplicable on CISC architectures, such as the Intel IA-32 [16], where the instruc\u00adtion set is rich and \nmany instructions have overlapping semantics. If a signature describes a certain distribution of instructions \nin the program, insertion of junk code [17, 27, 30] that acts as a nop so as not to modify the program \nbehavior can defeat frequency-based signatures. If a signature identi.es some of the read-only data of \na program, packing or encryption with varying keys [13, 24] can effectively hide the relevant data. Therefore, \nan important require\u00adment of a robust malware detection technique is to handle obfusca\u00adtion transformations. \nProgram semantics provides a formal model of program behav\u00adior. Therefore addressing the malware-detection \nproblem from a se\u00admantic point of view could lead to a more robust detection system. Preliminary work \nby Christodorescu et al. [4] and Kinder et al. [18] on a formal approach to malware detection con.rms \nthe potential bene.ts of a semantics-based approach to malware detection. The goal of this paper is to \nprovide a formal semantics-based frame\u00adwork that can be used by security researchers to reason about \nand evaluate the resilience of malware detectors to various kinds of ob\u00adfuscation transformations. This \npaper makes the following speci.c contributions: We present a formal de.nition of what it means for \na detector to be sound and complete with respect to a class of obfuscations. We also provide a framework \nwhich can be used by malware\u00addetection researchers to prove that their detector is complete with-respect-to \na class of obfuscations. As an integral part of the formal framework, we provide a trace semantics to \ncharac\u00adterize the program and malware behaviors, using abstract inter\u00adpretation to hide irrelevant aspects \nof these behaviors.  We show our formal framework in action by proving that the semantic-aware malware \ndetector AMD proposed by Christo\u00addorescu et al. [4] is complete with respect to some common obfuscations \nused by malware writers. The soundness of AMD was proved in [4].   2. Preliminaries Let P be the set \nof programs. An obfuscation is a program trans\u00adformer, O :P . P. Code reordering and variable renaming \nare two common obfuscations. The set of all obfuscations is denoted by O. A malware detector is D :P \n\u00d7 P .{0, 1}: D(P, M)=1 means that P is infected with M or with an obfuscated variant of M. Our treatment \nof malware detectors is focused on detecting variants of existing malware. When a program P is infected \nwith a malware M, we write M.. P . Intuitively, a malware detector is sound if it never erroneously claims \nthat a program is infected, i.e., there are no false positives, and it is complete if it always detects \nprograms that are infected, i.e., there are no false negatives. More formally, these properties can be \nde.ned as follows: DEFINITION 1 (Soundness and Completeness). A malware detec\u00adtor D is complete for an \nobfuscation O. O if and only if .M . P, O(M).. P . D(P, M)=1. A malware detector D is sound for an obfuscation \nO. O if and only if .M . P, D(P, M)= 1.O(M).. P . Note that this de.nition of soundness and completeness \ncan be ap\u00adplied to a deobfuscator as well. In other words, our de.nitions are not tied to the concept \nof malware detection. Most malware detec\u00adtors are built on top of other static-analysis techniques for \nproblems that are hard or undecidable. For example, most malware detec\u00adtors [4,18] that are based on \nstatic analysis assume that the control\u00ad.ow graph for an executable can be extracted. As shown by re\u00adsearchers \n[21], simply disassembling an executable can be quite tricky. Therefore, we want to introduce the notion \nof relative sound\u00adness and completeness with respect to algorithms that a detector uses. In other words, \nwe want to prove that a malware detector is sound or complete with respect to a class of obfuscations \nif the static-analysis algorithms that the detector uses are perfect. DEFINITION 2 (Oracle). An oracle \nis an algorithm over programs. For example, a CFG oracle is an algorithm that takes a program as an input \nand produces its control-.ow graph. DOR denotes a detector that uses a set of oracles OR.1 For example, \nlet ORCFG be a static-analysis oracle that given an exe\u00adcutable provides a perfect control-.ow graph \nfor it. A detector that uses the oracle ORCFG is denoted as DORCFG . In the de.nitions and proofs in \nthe rest of the paper we assume that oracles that a detector uses are perfect. DEFINITION 3 (Soundness \nand completeness relative to oracles). A malware detector DOR is complete with respect to an obfusca\u00adtion \nO,if DOR is complete for that obfuscation O when all oracles in the set OR are perfect. Soundness of \na detector DOR can be de.ned in a similar manner. 2.1 A Framework for Proving Soundness and Completeness \nof Malware Detectors When a new malware detection algorithm is proposed, one of the criteria of evaluation \nis its resilience to obfuscations. Unfortunately, identifying the classes of obfuscations for which a \ndetector is re\u00adsilient can be a complex and error-prone task. A large number of obfuscation schemes exist, \nboth from the malware world and from the intellectual-property protection industry. Furthermore, obfusca\u00adtions \nand detectors are de.ned using different languages (e.g., pro\u00adgram transformation vs program analysis), \ncomplicating the task of comparing one against the other. We present a framework for proving soundness \nand complete\u00adness of malware detectors in the presence of obfuscations. This framework operates on programs \ndescribed through their execu\u00adtion traces thus, program trace semantics is the building block of our \nframework. Both obfuscations and detectors can be elegantly expressed as operations on traces (as we \ndescribe in Section 3 and Section 4). In this framework, we propose the following two step proof strategy \nfor showing that a detector is sound or complete with respect to an obfuscation or a class of obfuscations. \n1. [Step 1] Relating the two worlds. Let DOR be a detector that uses a set of oracles OR. Assume that \nwe are given a program P and malware M.Let S .P . and S .M. be the set of traces corresponding to P and \nM, respec\u00adtively. In Section 3 we describe a detector DTr which works in the semantic world of traces. \nWe then prove that if the oracles in OR are perfect, the two detectors are equivalent, i.e, for all P \nand M in P, DOR(P, M)=1iff DTr (S .P . , S .M.)=1. In other words, this step shows the equivalence of \nthe two worlds: the concrete world of programs and the semantic world of traces. 2. [Step 2] Proving \nsoundness and completeness in the se\u00admantic world.  After step 1, we prove the desired property (e.g., \ncompleteness) about the trace-based detector DTr , with respect to the chosen class of obfuscations. \nIn this step, the detector s effects on the trace semantics are compared to the effects of obfuscation \non the trace semantics. This also allows us to evaluate the detector against whole classes of obfuscations, \nas long as the obfusca\u00adtions have similar effects on the trace semantics. The requirement for equivalence \nin step 1 above might be too strong if only one of completeness or soundness is desired. For example, \nif the goal is to prove only completeness of a malware detector DOR, then it is suf.cient to .nd a trace-based \ndetector that classi.es only malware and malware variants in the same way as DOR. Then, if the trace-based \ndetector is complete, so is DOR . 1 We assume that detector D can query an oracle from the set OR,and \nthe query is answered perfectly and in O(1) time. These types of relative completeness and soundness \nresults are common in cryptography. Syntax:Syntactic Categories: E ::= n | X | E1 op E2 (op .{+,-,*,/,...}) \nn.N (integers) B ::= true | false | E1 <E2 X .X (variable names) |\u00acB1 | B1 &#38;&#38; B2 L .L (labels) \nA ::= X := D | skip | assign(L,X) E .E (integer expressions) C ::= L: A .L. (unconditional actions) \nB .B (Boolean expressions) | L: B .{LT ,LF } (conditional jumps) A.A (actions) P ::= P(C) D .E .(A \u00d7P(L)) \n(assignment r-values) C .C (commands) P .P (programs)  Semantics: Value Domains: ARITHMETIC EXPRESSIONS \nB = {true,false} (truth values) E : A \u00d7X .Z. .(A \u00d7P(L)) n. Z (integers) E .n. . = n. .E= X .L. (environments) \nE .X. . = m(.(X)) where . =(.,m) m .M= L .Z .(A \u00d7P(L)) (memory) E .E1 op E2. . = if (E .E1. . .Z and \nE .E2. . .Z) . .X = E\u00d7M (execution contexts) then E .E1. . op E .E2. .; else . S= C \u00d7X (program states) \nBOOLEAN EXPRESSIONS B : B \u00d7X .B. B .true. . = true B .false . . = false B .E1 <E2. . = if (E .E1. . \n.Z and E .E2. . .Z) then E .E1. .< E .E2. .; else . B .\u00acB. . = if (B .B. . .B) then \u00acB .B. .; else . \nB .B1 &#38;&#38; B2. . = if (B .B1. . .B and B .B2. . .B) then B .B1. ..B .B2. .; else . ACTIONS A : \nA \u00d7X .X A .skip. . = . D if D .A \u00d7P(L)A .X := D. . =(.,m.) where . =(.,m),m= m[.(X) .d],and d = E .D. \n(.,m) if D .E A .assign(L.,X). . =(..,m) where . =(.,m) and .. = .[X . L.] COMMANDS The semantic function \nC :S .P(S) effectively speci.es the transition relation between states. Here, lab .C. denotes the label \nfor the command C, i.e., lab .L: A.L.. = Land lab .L: B .{LT ,LF }. = L. C .L: A .L.. . = {(C,..) | \n.. = A .A. .,lab .C. = L. ,.act .C. : suc .C..= m.(L.)} where .. =(..,m.) LT if B .B. . = true C .L: \nB .{LT ,LF }. . = {(C,.) | lab .C. = } LF if B .B. . = false Figure 1. A simple programming language. \n Labels: lab .L: A .L.. = L lab .L: B .{LT ,LF }. = L lab .P. = {lab .C. |C .P} Successors of a command: \nsuc .L: A.L.. = L. suc .L: B .{LT ,LF }. = {LT ,LF }  Action of a command: act .L : A .L2. = A Variables: \nvar .L1 : A.L2. = var .A. var .P. = C.P var .C. var .A. = {variables occuring in A} Memory locations \nused by a program: Luse .L : A.L.. = Luse .A. Luse .P. = Luse .C. C.P Luse .A. = {locations occuring \nin A}..(var .A.) Commands in sequences of program states: cmd .{(C1,.1),...,(Ck,.k)}. = {C1,...,Ck} \nFigure 2. Auxiliary functions for the language of Figure 1.  2.2 Abstract Interpretation The basic \nidea of abstract interpretation is that program behavior at different levels of abstraction is an approximation \nof its formal semantics [8, 9]. The (concrete) semantics of a program is com\u00adputed on the (concrete) \ndomain . C, = C . , i.e., a complete lattice which models the values computed by programs. The partial \nor\u00addering = C models relative precision: c1 = C c2 means that c1 is more precise (concrete) than c2. \nApproximation is encoded by an abstract domain . A, = A. , i.e., a complete lattice, that represents \nsome approximation properties on concrete objects. Also in the abstract domain the ordering relation \n= A denotes relative preci\u00adsion. As usual abstract domains are speci.ed by Galois connec\u00adtions [8, 9]. \nTwo complete lattices C and A form a Galois con\u00ad . .- nection (C, a, ., A), also denoted C -.A, when \nthe func\u00ad a tions a : C . A and . : A . C form an adjunction, namely . a . A, . c . C : a(c) = A a . \nc = C .(a) where a(.) is the left(right) adjoint of .(a). a and . are called, respectively, abstraction \nand concretization maps. A tuple (C, a, ., A) is a Ga\u00adlois connection iff a is additive iff . is co-additive. \nThis means that whenever we have an additive(co-additive) function f between two domains we can always \nbuild a Galois connection by considering the right(left) adjoint map induced by f. Given two Galois con\u00adnections \n(C, a1,.1,A1) and (A1,a2,.2,A2), their composition (C, a2 .a1,.1 ..2,A2) is a Galois connection. (C, \na, ., A) spec\u00ad . i.es a Galois insertion, denoted C .- A, if each element of A -. a. is an abstraction \nof a concrete element in C, namely (C, a, ., A) is a Galois insertion iff a is surjective iff . is injective. \nAbstract domains can be related to each other w.r.t. their relative degree of precision. We say that \nan abstraction a1 : C . A1 is more con\u00adcrete then a2 : C . A2, i.e., A2 is more abstract than A1,if .c \n.C : .1(a1(c)) =C .2(a2(c)). 2.3 Programming Language The language we consider is a simple extension \nof the one in\u00adtroduced by Cousot and Cousot [10], the main difference being the ability of programs to \ngenerate code dynamically (this facil\u00adity is added to accommodate certain kinds of malware obfusca\u00adtions \nwhere the payload is unpacked and decrypted at runtime). The syntax and semantics of our language are \ngiven in Figure 1. Given a set S,we use S. to denote the set S .{.},where .de\u00adnotes an unde.ned value.2 \nCommands can be either conditional or unconditional. A conditional command at a label L has the form \nL : B .{LT ,LF }, where B is a Boolean expression and LT (respectively, LF ) is the label of the command \nto execute when B evaluates to true (respectively, false); an unconditional com\u00admand at a label L is \nof the form L : A . L1, where A is an action and L1 the label of the command to be executed next. A variable \ncan be unde.ned (.), or it can store either an integer or a (appropriately encoded) pair (A, S) . A \u00d7P(L). \nA program consists of an initial set of commands together with all the com\u00admands that are reachable through \nexecution from the initial set. In other words, if Pinit denotes the initial set of commands, then . \n. * .. P = cmd C (C, .) , where we extend C to C.Pinit ..X a set of program states, C (S)= s.S C (s). \nSince each com\u00admand explicitly mentions its successors, the program need not to maintain an explicit \nsequence of commands. This de.nition allows us to represent programs that generate code dynamically. \nAn environment . .E maps variables in dom(.) . X to memory locations L.. Given a program P we denote \nwith E(P) its environments, i.e. if . .E(P) then dom(.)= var .P..Let .[X . L] denote environment . where \nlabel L is assigned to variable X.The memory is represented as a function m : L . Z. .(A \u00d7P(L)).Let m[L \n. D] denote memory m where element D is stored at location L. When considering a program P, wedenotewith \nM(P) the set of program memories, namely if m .M(P) then dom(m)= Luse .P.. Thismeansthat m .M(P) is de.ned \non the set of memory locations that are affected by the execution of program P (excluding the memory \nlocations storing the initial commands of P). The behavior of a command when it is executed depends on \nits execution context, i.e., the environment and memory in which it is executed. The set of execution \ncontexts is given by X = E\u00d7M.A program state is a pair (C, .) where C is the next command that has to \nbe executed in the execution context .. S= C \u00d7X denotes the set of all possible states. Given a state \ns .S, the semantic function C (s) gives the set of possible successor states of s;in other words, C :S \n.P(S) de.nes the transition relation between states. Let S(P)= P \u00d7X(P) be the set of states of a program \nP,then we can specify the transition relation C .P. :S(P) .P(S(P)) on program P as: C .P. (C, .)= (C.,..) \n.(C.,..) .C (C, .),C. .P, and ., .. .X(P) . 2 We abuse notation and use . to denote unde.ned values of \ndifferent types, since the type of an unde.ned value is usually clear from the context. Let A * denote \nthe Kleene closure of a set A, i.e., the set of .nite sequences over A.A trace s .S * is a sequence of \nstates s1...sn of length |s|= 0 such that for all i .[1,n): si .C (si-1).The .nite partial traces semantics \nS .P. . S * of program P is the least .xpoint of the function F: F .P. (T)= S(P) .{ss .s|s . .C .P. (s),s \n.s .T} where T is a set of traces, namely S .P. = lfp.F .P..The set of all partial trace semantics, ordered \nby set inclusion, forms a complete lattice. Finally, we use the following notation. Given a function \nf : A .B and a set S .A,we use f|S to denote the restriction of function f to elements in S nA,and f \n. S to denote the restriction of function f to elements not in S, namely to A . S.  3. Semantics-Based \nMalware Detection Intuitively, a program P is infected by a malware M if (part of) P s execution behavior \nis similar to that of M. In order to detect the presence of a malicious behavior from a malware M in \na program P, therefore, we need to check whether there is a part (a restriction) of S .P. that matches \n(in a sense that will be made precise) S .M.. In the following we show how program restriction as well \nas semantic matching are actually appropriate abstractions of program semantics, in the abstract interpretation \nsense. The process of considering only a portion of program semantics can be seen as an abstraction. \nA subset of a program P s labels (i.e., commands) labr .P. . lab .P. characterizes a restriction of program \nP. In particular, let varr .P. and Luser .P. denote, respectively, the set of variables occurring in \nthe restriction and the set of memory locations used:  varr .P. = {var .C. |lab .C. .labr .P.}  Luser \n.P. = {Luse .C. |lab .C. .labr .P.}. The set of labels labr .P. induces a restriction on environment \nand memory maps. Given . .E(P) and m .M(P),let .r = .|varr.P. and m r = m|Luser.P. denote the restricted \nset of environments and memories induced by the restricted set of labels labr .P..Let Sr =(C, (.r,mr)) \n.lab .C. .labr .P. be the set of restrected program states. De.ne ar :S * . S * that propagates restriction \nlabr .P. on a given a trace s = (C1, (.1,m1))s.: . . . if s = . r ar(s)= (C1, (.r 1,m1))ar(s.) if lab \n.C1. .labr .P. . ar(s.) otherwise Given a function f : A .B we denote, by a slight abuse of no\u00adtation, \nits pointwise extension on powerset as f : P(A) .P(B), where f(X)= {f(x)|x . X}. Note that the pointwise \nexten\u00adsion is additive. Therefore, the function ar : P(S * ) . P(S * r) is an abstraction that discards \ninformation outside the restriction labr .P.. Moreover ar is surjective and de.nes a Galois insertion: \n.r .P(S * ), ...-..P(S * r), ...Let ar(S .P.) be the restricted -. ar semantics of program P. Observe \nthat program behavior is expressed by the effects that program execution has on environment and memory. \nConsider a transformation ae :S * .X * that, given a trace s, discards from s all information about the \ncommands that are executed, retaining only information about changes to the environment and effects on \nmemory during execution: . if s = . ae(s)= .1ae(s.) if s =(C1,.1)s. Two traces are considered to be similar \nif they are the same under ae, i.e., if they have the same sequence of effects on the restrictions of \nthe environment and memory de.ned by labr .P.. This seman\u00adtic matching relation between program traces \nis the basis of our ap\u00adproach to malware detection. The additive function ae : P(S * ) . P(X * ) abstracts \nfrom the trace semantics of a program and de.nes .e a Galois insertion: .P(S * ),...-..P(X * ),... -. \nae Let us say that a malware is a vanilla malware if no obfuscating transformations have been applied \nto it. The following de.nition provides a semantic characterization of the presence of a vanilla malware \nM in a program P in terms of the semantic abstractions ar and ae. DEFINITION 4. A program P is infected \nby a vanilla malware M, i.e., M.. P, if: .labr .P. . P(lab.P.): ae(S .M.) . ae(ar(S .P.)). A semantic \nmalware detector is a system that veri.es the presence of a malware in a program by checking the truth \nof the inclusion relation of the above de.nition. In this de.nition, the program exhibits behaviors that, \nunder the restricted semantics, match all of the behaviors of the vanilla malware. We will later consider \na weaker notion of malware infection, where only some (not all) behaviors of the malware are present \nin the program (Section 5).  4. Obfuscated Malware To prevent detection malware writers usually obfuscate \nthe mali\u00adcious code. Thus, a robust malware detector needs to handle possi\u00adbly obfuscated versions of \na malware. While obfuscation may mod\u00adify the original code, the obfuscated code has to be equivalent \n(up to some notion of equivalence) to the original one. Given an ob\u00adfuscating transformation O : P . \nP on programs and a suitable abstract domain A, we de.ne an abstraction a : P(X * ) . Athat discards \nthe details changed by the obfuscation while preserving the maliciousness of the program. Thus, different \nobfuscated ver\u00adsions of a program are equivalent up to a. ae. Hence, in order to verify program infection, \nwe check whether there exists a seman\u00adtic program restriction that matches the malware behavior up to \na, formally if: . labr .P. . P(lab .P.): a(ae(S .M.)) . a(ae(ar(S .P.))). Here ar(S .P.) is the restricted \nsemantics for P; ae(ar(S .P.)) retains only the environment-memory traces from the restricted semantics; \nand afurther discards any effects due to the obfuscation O. We then check that the resulting set of environment-memory \ntraces contains all of the environment-memory traces from the malware semantics, with obfuscation effects \nabstracted away via a. EXAMPLE 1. Let us consider the fragment of program P that com\u00adputes the factorial \nof variable X and its obfuscation O(P) ob\u00adtained inserting commands that do not affect the execution \ncontext (at labels L2 and LF +1 in the example). P O(P ) L1 : F := 1 .L2 L1 : F := 1 .L2 L2 :(X =1) .{LT \n,LF } L2 : F := F \u00d72 -F .L3 LF : X := X -1 .LF +1 L3 :(X =1) .{LT ,LF }LF +1 : F := F \u00d7X .L2 LF : X := \nX -1 .LF +1 LT : ... LF +1 : X := X \u00d71 .LF +2 LF +2 : F := F \u00d7X .L3 LT : .... A suitable abstraction \nhere is the one that observes modi.cations in the execution context, namely a((.1,m1)(.2,m2)...(.n,mn)) \nreturns a((.2,m2)...(.n,mn)) if (.1 = .2) . (m1 = m2) and (.1,m1)a((.2,m2)...(.n,mn)) otherwise. 4.1 \nSoundness vs Completeness The extent to which a semantic malware detector is able to dis\u00adcriminate between \ninfected and uninfected code, and therefore the balance between any false positives and any false negatives \nit may incur, depends on the abstraction function a. We can provide se\u00admantic characterizations of the \nnotions of soundness and complete\u00adness, introduced in De.nition 1, as follows: DEFINITION 5. A semantic \nmalware detector on ais complete for aset O of transformations if and only if .O . O: .labr .P. . P(lab \n.P.): O(M) .. P . a(ae(S .M.)) . a(ae(ar(S .P.))) A semantic malware detector on ais sound for a set \nO of transfor\u00admations if and only if: .labr .P. . P(lab .P.): .O . O : . a(ae(S .M.)) . a(ae(ar(S .P.))) \nO(M) .. P. It is interesting to observe that, considering an obfuscating transfor\u00admation O, completeness \nis guaranteed when abstraction a is pre\u00adserved by obfuscation O, namely when .P . P : a(ae(S .P.)) = \na(ae(S .O(P).)). THEOREM 1. If a is preserved by the transformation O then the semantic malware detector \non ais complete for O. However, the preservation condition of Theorem 1 is too weak to imply soundness \nof the semantic malware detector. As an ex\u00adample let us consider the abstraction a. = .X.. that loses \nall information. It is clear that a. is preserved by every obfuscating transformation, and the semantic \nmalware detector on a. classi.es every program as infected by every malware. Unfortunately we do not \nhave a result analogous to Theorem 1 that provides a property of athat characterizes soundness of the \nsemantic malware detector. However, given an abstraction a, we characterize the set of trans\u00adformations \nfor which ais sound. THEOREM 2. Given an abstraction a, consider the set O of trans\u00adformations such that: \n.P,T . P: (a(ae(S .T.)) . a(ae(S .P.))) . (.O . O : ae(S .O .T..) . ae(S .P.)). Then, a semantic malware \ndetector on ais sound for O.  4.2 A Semantic Classi.cation of Obfuscations Obfuscating transformations \ncan be classi.ed according to their effects on program semantics. Given s,t . A * for some set A, let \ns. tdenote that sis a subsequence of t, i.e., if s= s1s2 ...sn then tis of the form ...s1 ...s2 ...sn \n.... 4.2.1 Conservative Obfuscations An obfuscation O : P . P is a conservative obfuscation if .s . S \n.P. ,.d . S .O(P). such that: ae(s) . ae(d).Let Oc denote the set of conservative obfuscating transformations. \nWhen dealing with conservative obfuscations we have that a trace d of a program P presents a malicious \nbehavior M,ifthere is a malware trace s . S .M. whose environment-memory evo\u00adlution is contained in the \nenvironment-memory evolution of d, namely if ae(s) . ae(d). Let us de.ne the abstraction ac : ** * P(X \n) . (X. P(X )) that, given an environment-memory sequence s .X * and a set S . P(X * ), returns the elements \nt . S that are subtraces of s: ac[S](s)= S n SubSeq(s) where SubSeq(s)= {t|t . s} denotes the set of \nall subsequences of s.For any S . P(X * ), the additive function ac[S] de.nes a Ga\u00ad .c[S] lois connection: \n.P(X * ), .. .--. .P(X * ), ... The abstrac\u00ad ac[S] tion ac turns out to be a suitable approximation when \ndealing with conservative obfuscations. In fact the semantic malware detector on ac[ae(S .M.)] is complete \nand sound for the class of conservative obfuscations Oc. THEOREM 3. Considering a vanilla malware M we \nhave that .Oc . Oc such that Oc(M) .. P iff . labr .P . . P(lab .P .) such that: ac[ae(S .M.)](ae(S .M.)) \n. ac[ae(S .M.)](ae(ar(S .P .))). Many obfuscating transformations commonly used by malware writers are \nconservative; a partial list of such conservative obfus\u00adcations is given below. It follows that Theorem \n3 is applicable to a signi.cant class of malware-obfuscation transformations. Code reordering. This \ntransformation, commonly used to avoid signature matching detection, changes the order in which com\u00admands \nare written, while maintaining the execution order through the insertion of unconditional jumps.  Opaque \npredicate insertion. This program transformation con\u00adfuses the original control .ow of the program by \ninserting opaque predicates, i.e., a predicate whose value is known a pri\u00adori to a program transformation \nbut is dif.cult to determine by examining the transformed program [7].  Semantic NOP insertion. This \ntransformation inserts commands that are irrelevant with respect to the program semantics.  Substitution \nof Equivalent Commands. This program transfor\u00admation replaces a single command with an equivalent one, \nwith the goal of thwarting signature matching.  The following result shows that the composition of conservative \nobfuscations is a conservative obfuscation. Thus, when more than one conservative obfuscation is applied, \nit can be handled as a single conservative obfuscation. LEMMA 1. Given O1, O2 . Oc then O1 .O2 . Oc. \nGiven a variable X, the semantics of p2(X) is the label expressed by p2(m(.(X))), in particular p2(n)= \n., while p2(A, S)= S. Given a variable X,let Dec(X) denote the execution of a set of commands that decrypts \nthe value stored in the memory location .(X). The obfuscations are as follows: L2 : skip . L4 and L5 \n: skip . Lc are inserted by code reordering; LN : X := X+ 3 . LN1 and LN1 : X := X - 3 . LT represent \nsemantic nop insertion, and LO : P T .{LN ,Lk} true opaque predicate in\u00adsertion. It can be shown that \nac[ae(S .M.)](ae(S .Oc(M).)) = ac[ae(S .M.)](ae(S .M.)), i.e., our semantics-based approach is able to \nsee through the obfuscations and identify O(M) as matching the malware M.  4.2.2 Non-Conservative Obfuscations \nA non-conservative transformation modi.es the program semantics in such a way that the original environment-memory \ntraces are not present any more. A possible way to tackle these transformations is to identify the set \nof all possible modi.cations induced by a non\u00adconservative obfuscation, and .x, when possible, a canonical \none. In this way the abstraction would reduce the original semantics to the canonical version before \nchecking malware infection. Another possible approach comes from Theorem 1 that states that if a is preserved \nby O then the semantic malware detector on a is complete w.r.t. O. Recall that, given a program transformation \nO : P . P, it is possible to systematically derive the most concrete abstraction preserved by O [12]. \nThis systematic methodology can be used in presence of non-conservative obfuscations in order to derive \na complete semantic malware detector when it is not easy to identify a canonical abstraction. Moreover \nin Section 5 we show how it is possible to handle a class of non-conservative obfuscations through a \nfurther abstraction of the malware semantics. In the following we consider a non-conservative transformation, \nknown as variable renaming, and propose a canonical abstraction that leads to a sound and complete semantic \nmalware detector. Variable Renaming Variable renaming is a simple obfuscating transformation, often used \nto prevent signature matching, that re\u00adplaces the names of variables with some different new names. As\u00adsuming \nthat every environment function associates variable VL to memory location L, allows us to reason on variable \nrenaming also in the case of compiled code, where variable names have disap\u00adpeared. Let Ov : P \u00d7 . . \nP denote the obfuscating transforma\u00adtion that, given a program P , renames its variables according to \na mapping p . .,where p : var .P . . Names is a bijective function that relates the name of each program \nvariable to its new name. .. C .. EXAMPLE 2. Let us consider a fragment of malware M presenting .C. . \nP : lab .C. = lab .C.. the decryption loop used by polymorphic viruses. Such a fragment writes, starting \nfrom memory location B, the decryption of memory suc .C. = suc .C. Ov(P, p)= .. act .C. = act .C.. [X/p(X)] \nlocations starting at location A and then executes the decrypted instructions. Let Oc(M) be a conservative \nobfuscation of M: M Oc(M) L1 : assign(LB ,B) .L2 L1 : assign(LB ,B) .L2 L2 : assign(LA,A) .Lc L2 : skip \n.L4 Lc : cond(A) .{LT ,LF } Lc : cond(A) .{LO,LF }LT : B := Dec(A) .LT1 L4 : assign(LA,A) .L5 LT1 : assign(p2(B),B) \n.LT2 L5 : skip .Lc LT2 : assign(p2(A),A) .LC LO : PT .{LN ,Lk}LF : skip .LB LN : X := X -3 .LN1 LN1 : \nX := X +3 .LT LT : B := Dec(A) .LT1 LT1 : assign(p2(B),B) .LT2 LT2 : assign(p2(A),A) .Lc Lk : ... LF \n: skip .LB where A[X/p(X)] represents action A where each variable name X is replaced by p(X). Recall \nthat the matching relation between program traces considers the abstraction ae of traces, thus it is \ninteresting to observe that: ae(S .Ov(P, p).)= av[p](ae(S .P .)) where av :. . (X * .X * ) is de.ned \nas: av[p]((.1,m1) ...(.n,mn)) = (.1 .p-1 ,m1) ...(.n .p-1 ,mn). In order to deal with variable renaming \nobfuscation we introduce the notion of canonical variable renaming p.. The idea of canon\u00adical mappings \nis that there exists a renaming p : var .P . . var .Q. that transforms program P into program Q, namely \nsuch that Ov(P, p)= Q,iff av [p.](ae(S .Q.)) = av[p.](ae(S .P .)). This means that a program Q is a renamed \nversion of program P \u00af Input: A list of context sequences Z, with Z.ae(S .P .). Output: A list Rename[Z] \nthat associates canonical variable Vi to the variable in the list position i. Rename[Z]= List(hd(Z\u00af)) \n\u00af Z= tl(Z\u00af) while (Z\u00af=.\u00d8) do trace = List(hd(Z\u00af)) while (trace . = \u00d8) do if (hd(trace) ..Rename[Z]) then \nRename[Z]= Rename[Z]: hd(trace) end trace = tl(trace) end \u00af Z= tl(Z\u00af) end Algorithm 1: Canonical renaming \nof variables. iff Q and P are indistinguishable after canonical renaming. In the following we de.ne a \npossible canonical renaming for the variables of a given a program. Let {Vi}i.N be a set of canonical \nvariable names. The set L of memory locations is an ordered set with ordering relation =L. With a slight \nabuse of notation we denote with =L also the lexicograph\u00adical order induced by =L on sequences of memory \nlocations. Let us de.ne the ordering =S over traces S * where, given s, d .S * , s =S d if |s|=|d|or \n|s|= |d|and lab(s1)lab(s2)...lab(sn) =L lab(d1)lab(d2)...lab(dn),where lab(.., C.)= lab .C.. It is clear \nthat, given a program P, the ordering =S on its traces induces an or\u00adder on the set Z = ae(S .P .) of \nits environment-memory traces, i.e., given s, d . S .P . : s =S d . ae(s) =Z ae(d).By de.nition, the \nset of variables assigned in Z is exactly var .P ., therefore a canonical renaming p P : var .P . .{Vi}i.N,is \nsuch that ae(S .Ov .P, p P ..)= av[ pP ](Z).Let Z\u00afdenote the list of environment-memory traces of Z= \nae(S .P .) ordered following the order de.ned above. Let B be a list, then hd(B) returns the .rst element \nof the list, tl(B) returns list B without the .rst ele\u00adment, B : e (e : B) is the list resulting by inserting \nelement e at the end (beginning) of B, B[i] returns the i-th element of the list, and e .B means that \ne is an element of B. Note that program ex\u00adecution starts from the uninitialized environment .uninit \n= .X.., and that each command assigns at most one variable. Let def (.) denote the set of variables that \nhave de.ned (i.e., non-.)values in an environment .. This means that considering s .X * we have that \ndef (.i-1) .def (.i),and if def (.i-1) .def (.i) then def (.i)= def (.i-1) .{X}where X . X is the new \nvariable assigned to memory location .i(X).Given s .X *, let us de.ne List(s) as the list of variables \nin s ordered according to their as\u00adsignment time. Formally, let s =(.1,m1)(.2,m2)...(.n,mn)= (.1,m1)s \n.: . . . if s = . List(s)= X : List(s .) if def (s2) . def (s1)= {X} . List(s .) if def (s2) . def (s1)= \n\u00d8 Given Z = ae(S .P .) we rename its variables following the canonical renaming p.P : var .P . .{Vi}i.N \nthat associates the new canonical name Vi to the variable of P in the i-th position in the list Rename[Z] \nde.ned in Algorithm 1. Thus, the canonical renaming p.P : var .P . .{Vi}i.N is de.ned as follows: p.P \n(X)= Vi .Rename[Z][i]= X (1) The following result is necessary to prove that the mapping p.P de.ned in \nEquation (1) is a canonical renaming. LEMMA 2. Given two programs P, Q . P let Z = ae(S .P .) and Y= \nae(S .Q.). The followings hold: av[p.P ](Z)= av[p.Q](Y) ..p : var .P . . var .Q. : av[p](Z)= Y  (.p \n: var .P . .var .Q. : av[p](Z)= Y) and (av[p](s)= t .(Z\u00af[i]= s and Y[i]= t)) .av[p.P ](Z)= av [p.Q](Y) \n Let ..denote a set of canonical variable renaming, the additive function av :... (P(X * ) . P(Xc * \n)),where Xc denotes execution contexts where environments are de.ned on canoni\u00adcal variables, is an approximation \nthat abstracts from the names of variables. Thus, we have the following Galois connection: .v [. .] .P(X \n* ), .. .--. .P(Xc * ), ... The following result, where av[. .] p.M and p.Pr denote respectively the \ncanonical rename of the mal\u00adware variables and of restricted program variables, shows that the semantic \nmalware detector on av [. .] is complete and sound for variable renaming. THEOREM 4. .p : Ov(M, p) ..P \niff .labr .P . .P(lab .P .): av[p.M ](ae(S .M.)) .av[p.Pr ](ae(ar(S .P .))).  4.3 Composition In general \na malware uses multiple obfuscating transformations concurrently to prevent detection, therefore we have \nto consider the composition of non-conservative obfuscations (Lemma 1 re\u00adgards composition of conservative \nobfuscations). Investigating the relation between abstractions a1 and a2, that are complete(sound) respectively \nfor obfuscations O1 and O2, and the abstraction that is complete(sound) for their compositions, i.e. \nfor {O1 .O2, O2 . O1}, we have obtained the following result. THEOREM 5. Given two abstractions a1 and \na2 and two obfusca\u00adtions O1 and O2 then: 1 if the semantic malware detector on a1 is complete for O1, \nthe semantic malware detector on a2 is complete for O2, and a1 .a2 = a2 .a1, then the semantic malware \ndetector on a1 .a2 is complete for {O1 .O2, O2 .O1}; 2 if the semantic malware detector on a1 is sound \nfor O1,the se\u00ad mantic malware detector on a2 is sound for O2, and a1(X) . a1(Y ) . X . Y , then the semantic \nmalware detector on a1 .a2 is sound for O1 .O2. Thus, in order to propagate completeness through composition \nO1 .O2 and O2 .O1 the corresponding abstractions have to be independent. On the other side, in order \nto propagate soundness through composition O1 .O2 the abstraction a1, corresponding to the last applied \nobfuscation, has to be an order-embedding, namely a1 has to be both order-preserving and order-re.ecting, \ni.e., a1(X) .a1(Y ) .X .Y . Observe that, when composing a non-conservative obfuscation O, for which \nthe semantic malware detector on aO is complete, with a conservative obfuscation Oc, the commutation \ncondition of point 1 is satis.ed if and only if (ae(s) .ae(d)) .aO(ae(s)) .aO(ae(d)). EXAMPLE 3. Let \nus consider Ov(Oc(M),p) obtained by obfus\u00adcating the portion of malware M in Example 2 through variable \nrenaming and some conservative obfuscations: Ov(Oc(M),p) L1 : assign(D,LB ) .L2 L2 : skip .L4 Lc : cond(E) \n.{LO,LF }L4 : assign(E,LA) .L5 L5 : skip .Lc LO : PT .{LT ,Lk}LT : D := Dec(E) .LT1 LT1 : assign(p2(D),D) \n.LT2 LT2 : assign(p2(E),E) .Lc Lk : ... LF : ... where p(B)= D, p(A)= E. It is possible to show that: \nac[av[..](ae(S .M.))) . .](ae(S .M.)](av [. ac[av [..](ae(ar(S .Oc(M),p).)))). .](ae(S .M.))](av[.v(O \nNamely, given the abstractions ac and av on which, by de.nition, the semantic malware detector is complete \nrespectively for Oc and Ov, the semantic malware detector on ac .av is complete for the composition Ov \n.Oc.  5. Further Malware Abstractions De.nition 4 characterizes the presence of malware M in a program \nP as the existence of a restriction labr .P . . P(lab .P .) such that ae(S .M.) . ae(ar(S .P .)). This \nmeans that program P is infected by malware M if P matches all malware behaviors. This notion of malware \ninfection can be weakened in two different ways. First, we can abstract the malware traces eliminating \nthe states that are not relevant to determine maliciousness, and then check if program P matches this \nsimpli.ed behavior. Second, we can require program P to match a proper subset of malicious behaviors. \nFurthermore these two notions of malware infection can be combined by requiring program P to match the \ninteresting states of the interesting behaviors of the malware. It is clear that a deeper understanding \nof the malware behavior is necessary in order to identify both the set of interesting states and the \nset of interesting behaviors. Interesting States. Assume that we have an oracle that, given a malware \nM, returns the set of its interesting states. These states could be selected based on a security policy, \nfor example, the states could represent the result of network operations. This means that, in order to \nverify if P is infected by M, we have to check whether the malicious sequences of interesting states \nare present in P .Let us de.ne the trace transformation aInt(M) :S * .S * that considers only the interesting \nstates in a given trace s = s1s.: . . . if s = . aInt(M)(s)= s1aInt(M)(s.) if s1 .Int(M) . aInt(M)(s.) \notherwise The following de.nition characterizes the presence of malware M in terms of its interesting \nstates, i.e., through abstraction aInt(M). DEFINITION 6. A program P is infected by a vanilla malware \nM with interesting states Int(M), i.e., M..Int(M) P ,if .labr .P . . P(lab .P .) such that: aInt(M)(S \n.M.) .aInt(M)(ar(S .P .)). Thus we can weaken the standard notion of conservative transfor\u00admation by \nsaying that O : P . P is conservative w.r.t. Int(M) if .s . S .M. , .d . S .O(P ). such that aInt(M)(s)= \naInt(M)(d). When program infection is characterized by De.nition 6, the se\u00admantic malware detector on \naInt(M) is complete and sound for the obfuscating transformations that are conservative w.r.t. Int(M \n). THEOREM 6. Let Int(M) be the set of interesting states of a vanilla malware M, then there exists an \nobfuscation O conser\u00advative w.r.t. Int(M) such that O(M) ..Int(M) P iff .labr .P . . P(lab .P .) such \nthat: aInt(M)(S .M.) .aInt(M)(ar(S .P .)). It is clear that transformations that are non-conservative \nmay be conservative w.r.t. Int(M), meaning that knowing the set of interesting states of a malware allows \nus to handle also some non\u00adconservative obfuscations. For example the abstraction aInt(M) allows the \nsemantic malware detector to deal with reordering of independent instructions, as the following example \nshows. EXAMPLE 4. Let us consider the malware M and its obfuscation O(M) obtained by reordering independent \ninstructions. M O(M) L1 : A1 .L2 L1 : A1 .L2 L2 : A2 .L3 L2 : A3 .L3 L3 : A3 .L4 L3 : A2 .L4 L4 : A4 \n.L5 L4 : A4 .L5 L5 : A5 .L6 L5 : A5 .L6 In the above example A2 and A3 are independent, meaning that \nA .A2. (A .A3. (., m)) = A .A3. (A .A2. (., m)). Consider\u00ading malware M, we have the trace s = s1s2s3s4s5 \nwhere: -s1 = .L1 : A1 .L2, (., m)., -s5 = .L5 : A5 .L6, (A .A4. (A .A3. (A .A2. (A .A1. (., m)))))., \nwhile considering the obfuscated version, we have the trace d = d1d2d3d4d5,where: -d1 = .L1 : A1 .L2, \n(., m)., -d5 = .L5 : A5 .L6, (A .A4. (A .A2. (A .A3. (A .A1. (., m))))).. Let Int(M)= {s1,s5}.Then aInt(M)(s)= \ns1s5 as well as aInt(M)(d)= d1d5, which concludes the example. It is obvious that d1 = s1, moreover d5 \n= s5 follows from the independence of A2 and A3. Interesting Behaviors. Assume we have an oracle that \ngiven a malware M returns the set T . S .M. of its behaviors that characterize the maliciousness of M. \nThus, in order to verify if P is infected by M, we check whether program P matches the malicious behaviors \nT . The following de.nition characterizes the presence of malware M in terms of its interesting behaviors \nT . DEFINITION 7. A program P is infected by a vanilla malware M with interesting behaviors T .S .M., \ni.e., M..T P if: .labr .P . .P(lab .P .): ae(T ) .ae(ar(S .P .)). It is interesting to observe that, \nwhen program infection is charac\u00adterized by De.nition 7, all the results obtained in Section 4 still \nhold if we replace S .M. with T . Clearly the two abstractions can be composed. In this case a program \nP is infected by a malware M if there exists a pro\u00adgram restriction that matches the set of interesting \nsequences of states obtained abstracting the interesting behaviors of the malware, i.e., .labr .P . . \nP(lab .P .): ae(aInt(M)(T )) . ae(aInt(M)(ar(S .P .))). To conclude, we present a matching relation based \non (interest\u00ading) program actions rather than environment-memory evolutions. In this case we consider \nthe syntactic information contained in pro\u00adgram states. The main difference with purely syntactic approaches \nis the ability of observing actions in their execution order and not in the order in which they appear \nin the code. Obfuscation Completeness of AMD Code reordering Yes Semantic-nop insertion Yes Substitution \nof equivalent commands No Variable renaming Yes Table 1. List of obfuscations considered by the semantics-aware \nmalware detection algorithm, and the results of our completeness analysis. Interesting Actions. Sometimes \na malicious behavior can be characterized in terms of the execution of a sequence of bad ac\u00adtions. Assume \nwe have an oracle that given a malware M returns the set Bad . act .M. of actions capturing the essence \nof the malicious behaviour. In this case, in order to verify if program P is infected by malware M, we \ncheck whether the execution sequences of bad actions of the malware match the ones of the program. DEFINITION \n8. A program P is infected by a vanilla malware M with bad actions Bad, i.e., M..Bad P if: .labr .P. \n. P(lab .P.): aa(S .M.) . aa(ar(S .P.)) Where, given the set Bad . act .M. of bad actions, the abstrac\u00adtion \naa returns the sequence of malicious actions executed by each trace. Formally, given a trace s = s1s.: \n. . . if s = . aa(s)= A1aa(s.) if A1 . Bad . aa(s.) otherwise Even if this abstraction considers syntactic \ninformation (program actions), it is able to deal with some sort of obfuscations. In fact considering \nthe sequence of malicious actions in a trace it observes actions in their execution order, and not in \nthe order in which they are written in the code. Thus, ignoring for example unconditional jumps, it is \nable to deal with code reordering.  6. Case Study: Completeness of Semantics-Aware Malware Detector \nAMD An algorithm called semantics-aware malware detection was pro\u00adposed by Christodorescu, Jha, Seshia, \nSong, and Bryant [4]. This approach to malware detection uses instruction semantics to iden\u00adtify malicious \nbehavior in a program, even when obfuscated. The obfuscations considered in [4] are from the set of conser\u00advative \nobfuscations, together with variable renaming. The paper proved the algorithm to be oracle-sound, so \nwe focus in this sec\u00adtion on proving its oracle-completeness using our abstraction-based framework. The \nlist of obfuscations we consider (shown in Table 1) is based on the list described in the semantics-aware \nmalware de\u00adtection paper. Description of the Algorithm The semantics-aware malware de\u00ad tection algorithm \nAMD matches a program against a template de\u00ad .. x T For our language the control-.ow graph (CFG) can \nbe easily con\u00adstructed as follows: For each command C . C, create a CFG node annotated with that command, \nvlab.C. . Correspondingly, we write C.v. to denote the command at CFG node v.  For each command C = \nL1 : A . S,where S . P(L),and for each label L2 . S, create a CFG edge (vL1 ,vL2 ).  Consider a path \n. through the CFG from node v1 to node vk, . = v1 . ... . vk. There is a corresponding sequence of com\u00admands \nin the program P, written P|. = {C1,...,Ck}.Then we can express the set of states possible after executing \nthe sequence of commands P|. as C k .P|.. (C1,(.,m)), by extending the transi\u00adtion relation C to a set \nof states, such that C : P(S) . P(S).Let us de.ne the following basic functions: mem .(C,(.,m)). = m \nenv .(C,.,m)). = . The algorithm takes as inputs the CFG for the template, GT = (VT ,ET ), and the binary \n.le for the program, File .P.. For each path .in GT , the algorithm proceeds in two steps: 1. Identify \na one-to-one map from template nodes in the path .to program nodes, \u00b5. : VT . VP . A template node n \nT can match a program node n P if the top\u00adlevel operators in their actions are identical. This map induces \namap .. : from variables at a template XT \u00d7 VT . XP node to variables at the corresponding program node, \nsuch that when renaming the variables in the template command Cn T according to the map .., we obtain \nthe program command . . .. .. Cn P = Cn T [X/.. X,nT ]. This step makes use of the CFG oracle ORCFG that \nreturns the control-.ow graph of a program P,given P s binary-.le representation File .P.. 2. Check whether \nthe program preserves the def-use dependencies that are true on the template path .. For each pair of \ntemplate nodes m T , n T on the path .,and CT for each template variable x T de.ned in act m andusedin \nCT TT act n ,let . be a program path \u00b5(v1 ) . ... . \u00b5(vk ), TT TT where m . v1 . ... . vk . n is part \nof the path . in the template CFG. . is therefore a program path connecting the program CFG node corresponding \nto m T with the program CFG node corresponding to n T . We denote by . .. ... T|. = Cm T ,C1 T ,...,CkT \n,C n T the sequence of commands corresponding to the template path .. The def-use preservation check \ncan be expressed formally as follows: ...E,.m.M,.s. C k ,(.,m) .P|.. \u00b5. : vC T 1 scribing the malicious \nbehavior. If a match is successful, the pro- A (.,m)= ,vC T 1 gram exhibits the malicious behavior of \nthe template. Both the tem\u00ad .. x T plate and the program are represented as control-.ow graphs during \nA (env.s. ,mem.s.) .,vC Tn the operation of AMD . The algorithm AMD attempts to .nd a subset of the \nprogram P that matches the commands in the malware M, possibly after renaming of variables and locations \nused in the subset of P.Fur\u00adthermore, AMD checks that any def-use relationship that holds in the malware \nalso holds in the program, across program paths that connect consecutive commands in the subset. A control-.ow \ngraph G =(V,E) is a graph with the vertex set V representing program commands, and edge set E represent\u00ading \ncontrol-.ow transitions from one command to its successor(s). This check is implemented in AMD as a query \nto a semantic\u00adnop oracle ORSNop . The semantic-nop oracle determines whether the value of a variable \nX before the execution of a code sequence . . P is equal to the value of a variable Y after the execution \nof .. The semantics-aware malware detector AMD makes use of two oracles, ORCFG and ORSNop , described \nin Table 2. Thus AMD = DOR, for the set of oracles OR = {ORCFG,ORSNop }. Our goal is then to verify whether \nAMD is OR-complete with respect to Oracle Notation CFG oracle ORCFG (File .P .) Returns the control-.ow \ngraph of the program P ,given its binary-.le representation File .P .. Semantic-nop oracle ORSNop(., \nX, Y ) Determines whether the value of variable X before the execution of code sequence . . P is equal \nto the value of variable Y after the execution of .. Table 2. Oracles used by the semantics-aware malware \ndetection algorithm AMD . Notation: P . P,X,Y . var .P . ,. . P . the obfuscations from Table 1. Since \nthree of those obfuscations (code reordering, semantic-nop insertion, and substitution of equiv\u00adalent \ncommands) are conservative, we only need to check OR\u00adcompleteness of AMD for each individual obfuscation. \nWe would then know (from Lemma 1) if AMD is also OR-complete with re\u00adspect to any combination of these \nobfuscations. We follow the proof strategy proposed in Section 2.1. First, in step 1 below, we develop \na trace-based detector DTr based on an abstraction a,and show that DOR = AMD and DTr are equivalent. \nThis equivalence of detectors holds only if the oracles in OR are perfect. Then, in step 2, we show that \nDTr is complete w.r.t. the obfuscations of interest. Step 1: Design an Equivalent Trace-Based Detector \nWe can model the algorithm for semantics-aware malware detection using two abstractions, aSAMD and aAct. \nThe abstraction a that char\u00adacterizes the trace-based detector DTr is the composition of these two abstractions, \na = aAct.aSAMD . We will show that DTr is equivalent AMD = DOR, when the oracles in OR are perfect. The \nabstraction aSAMD , whenappliedtoa trace s . S .P ., s =(C1. , (.1. ,m . 1)) ... (Cn. , (.. ,m . )), \nto a set of variable maps nn {pi}, and a set of location maps {.i}, returns an abstract trace: aSAMD \n(s, {pi}, {.i})=(C1, (.1,m1)) ... (Cn, (.n,mn)) if .i, 1 = i = n : act .Ci. = act .Ci.. [X/pi(X)] . lab \n.Ci. = .i(lab .Ci..) . suc .Ci. = .i(suc .Ci..) . .i = .. i . pi -1 . mi = mi . . .i -1 . Otherwise, \nif the condition does not hold, aSAMD (s, {pi}, {.i})= ..Amap pi : var .P . . X renames program variables \nsuch that they match malware variables, while a map .i : lab .P . . L reassigns program memory locations \nto match malware memory locations. The abstraction aAct simply strips all labels from the com\u00admands in \na trace s =(C1, (.1,m1))s., as follows: . aAct(s)= . (act .C1. , (.1,m1))aAct(s.) if s = . otherwise \n DEFINITION 9(a-Semantic Malware Detector). An a-semantic malware detector is a malware detector on the \nabstraction a, i.e., it classi.es the program P as infected by a malware M, M.. P , if .labr .P . . P(lab \n.P .): a(S .M.) . a(ar(S .P .)). By this de.nition, a semantic malware detector (from De.nition 4) is \na special instance of the a-semantic malware detector, for a = ae.Thenlet DTr be a (aAct.aSAMD )-semantic \nmalware detector. PROPOSITION 1. The semantics-aware malware detector algo\u00adrithm AMD is equivalent to \nthe (aAct.aSAMD )-semantic mal\u00adware detector DTr .In other words, .P, M . P, we have that AMD (P, M)= \nDTr (S .P . , S .M.). The proof has two parts, to show that AMD (P, M)=1 . DTr (S .P . , S .M.)=1, and \nthen to show the reverse. For the .rst implication, it is suf.cient to show that for any path . in the \nCFG of M and the path . in the CFG of P , such that . and . are found as related by the algorithm AMD \n, the corresponding traces are equal when abstracted by aAct.aSAMD . The proof for the second implication \nproceeds by showing that any two traces s . S .M. and d . S .P ., that are equal when abstracted by aAct.aSAMD \n, have corresponding paths through the CFGs of M and P , respectively, such that these paths satisfy \nthe conditions in the algorithm AMD . Both parts of the proof depend on the oracles used by AMD to be \nperfect. Now we can de.ne the operation of the semantics-aware mal\u00adware detector in terms of its effect \non the trace semantics of a pro\u00adgram P . DEFINITION 10 (Semantics-Aware Malware Detection). Apro\u00adgram \nP is infected by a vanilla malware M,i.e. M.. P , if: .labr .P . . P(lab .P .), {pi}i=1, {.i}i=1 : aAct(aSAMD \n(S .M. , {pi}, {.i})) . aAct(aSAMD (ar(S .P .), {pi}, {.i})). Step 2: Prove Completeness of the Trace-Based \nDetector We are interested in .nding out which classes of obfuscations are handled by a semantics-aware \nmalware detector. We check the validity of the completeness condition expressed in De.nition 5. In other \nwords, if the program is infected with an obfuscated variant of the malware, then the semantics-aware \ndetector should return 1. PROPOSITION 2. A semantics-aware malware detector is complete on aSAMD w.r.t. \nthe code-reordering obfuscation OJ : . ..labr .P . . P(lab .P . , {pi}i=1, {.i}i=1 : OJ (M) .. P . aAct(aSAMD \n(S .M. , {pi}, {.i})) . . aAct(aSAMD (ar(S .P .), {pi}, {.i})) The code-reordering obfuscation inserts \nskip commands into the program and changes the labels of existing commands. The restriction ar eliminates \nthe inserted skip commands, while the aAct abstraction allows for trace comparison while ignoring command \nlabels. Thus, the detector DTr is OR-complete w.r.t. the code-reordering obfuscation. Similar proofs \ncon.rm that DTr is OR-complete w.r.t. variable renaming and semantic-nop insertion. PROPOSITION 3. A \nsemantics-aware malware detector is complete on aSAMD w.r.t. the variable-renaming obfuscation Ov. PROPOSITION \n4. A semantics-aware malware detector is complete on aSAMD w.r.t. the semantic-nop insertion obfuscation \nON . Additionally, DTr is OR-complete on aSAMD w.r.t. a limited version of substitution of equivalent \ncommands, when the com\u00admands in the original malware M are not substituted with equiv\u00adalent commands. \nUnfortunately, DTr is not OR-complete w.r.t. all conservative obfuscations, as the following result illustrates. \nPROPOSITION 5. A semantics-aware malware detector is not com\u00adplete on aSAMD w.r.t. all conservative obfuscations \nOc . Oc. The cause for this incompleteness is the fact that the abstraction applied by DTr still preserves \nsome of the actions from the pro\u00adgram. Consider an instance of the substitution of equivalent com\u00admands \nobfuscating transformation OI that substitutes the action of at least one command for each path through \nthe malware (i.e., S .M. nS .OI (M). = \u00d8). For example, the transformation could modify the command at \nM s start label. Such an obfuscation, be\u00adcause it affects at least one action of M on every path through \nthe program P = OI (M), will defeat the detector.  7. Related Work There is a considerable body of literature \non existing techniques for malware detection: Szor gives an excellent summary [26]. Code obfuscation \nhas been extensively studied in the context of protecting intellectual property. The goal of these techniques \nis to make reverse engineering of code harder [3, 6, 7, 11, 12, 21]. Cryp\u00adtographers are also pursuing \nresearch on the question of possibility of obfuscation [1, 14, 28]. To our knowledge, we are not aware \nof existing research on formal approaches to obfuscation in the con\u00adtext of malware detection. 8. Conclusions \nand Future Work Malware detectors have traditionally relied upon syntactic ap\u00adproaches, typically based \non signature-matching. While such ap\u00adproaches are simple, they are easily defeated by obfuscations. To \naddress this problem, this paper presents a semantics-based frame\u00adwork within which one can specify what \nit means for a malware detector to be sound and/or complete, and reason about the com\u00adpleteness of malware \ndetectors with respect to various classes of obfuscations. As a concrete application, we have shown that \na semantics-aware malware detector proposed by Christodorescu et al. is complete with respect to some \ncommonly used malware ob\u00adfuscations. Given an obfuscating transformation O, we assumed that the abstraction \naO is provided by the malware detector designer. We are currently investigating how to design a systematic \n(ideally au\u00adtomatic) methodology for deriving an abstraction aO that leads to a sound and complete semantic \nmalware detector. We observed that if the abstraction aO is preserved by the obfuscation O then the malware \ndetection is complete, i.e. no false negatives. However, preservation is not enough to eliminate false \npositives. Hence, an interesting research task consists in characterizing the set of se\u00admantic abstractions \nthat prevents false positives. For future work in designing malware detectors, an area of great promise \nis that of detectors that focus on interesting actions. De\u00adpending on the execution environment, certain \nstates are reachable only through particular actions. For example, system calls are the only way for \na program to interact with OS-mediated resources such as .les and network connections. If the malware \nis character\u00adized by actions that lead to program states in an unique, unambigu\u00adous way, then all applicable \nobfuscation transformations are con\u00adservative. As we showed, a semantic malware detector that is both \nsound and complete for a class of conservative obfuscations exists, if an appropriate abstraction can \nbe designed. In practice, such an abstraction cannot be precisely computed a future research task is \nto .nd suitable approximations that minimize false positives while preserving completeness. One further \nstep would be to investigate whether and how model checking techniques can be applied to detect malware. \nSome works along this line already exist [18]. Observe that the abstraction a, actually de.nes a set \nof program traces that are equivalent up to O. In model checking, sets of program traces are represented \nby for\u00admulae of some linear/branching temporal logic. Hence, we aim at de.ning a temporal logic whose \nformulae are able to express nor\u00admal forms of obfuscations together with operators for composing them. \nThis would allow to use standard model checking algorithms to detect malware in programs. This could \nbe a possible direction to follow in order to develop a practical tool for malware detection based on \nour semantic model. We expect this semantics-based tool to be signi.cantly more precise than existing \nvirus scanners. Acknowledgments We would like to thank Roberto Giacobazzi and the anonymous ref\u00aderees \nfor their constructive comments and suggestions that helped us in improving this work.   References \n[1] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan, and K. Yang. On the (im)possibility \nof obfuscating programs. In Advances in Cryptology (CRYPTO 01), volume 2139 of Lecture Notes in Computer \nScience, pages 1 18, Santa Barbara, CA, USA, Aug. 19 23, 2001. Springer Berlin / Heidelberg. [2] D. \nChess and S. White. An undetectable computer virus. In Proceedings of the 2000 Virus Bulletin Conference \n(VB2000), Orlando, FL, USA, Sept. 27 29, 2000. Virus Bulletin. [3] S. Chow, Y. Gu, H. Johnson, and V. \nZakharov. An approach to the obfuscation of control-.ow of sequential computer programs. In G. Davida \nand Y. Frankel, editors, Proceedings of the 4th International Information Security Conference (ISC 01), \nvolume 2200 of Lecture Notes in Computer Science, pages 144 155, Malaga, Spain, Oct. 1 3, 2001. Springer \nBerlin / Heidelberg. [4] M. Christodorescu, S. Jha, S. A. Seshia, D. Song, and R. E. Bryant. Semantics-aware \nmalware detection. In Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&#38;P 05), pages \n32 46, Oakland, CA, USA, May 8 11, 2005. IEEE Computer Society. [5] F. B. Cohen. Computer viruses: Theory \nand experiments. Computers and Security, 6:22 35, 1987. [6] C. Collberg, C. Thomborson, and D. Low. A \ntaxonomy of obfuscating transformations. Technical Report 148, Department of Computer Sciences, The University \nof Auckland, July 1997. [7] C. Collberg, C. Thomborson, and D. Low. Manufacturing cheap, resilient, and \nstealthy opaque constructs. In Proceedings of the 25th ACM SIGPLAN SIGACT Symposium on Principles of \nProgramming Languages (POPL 98), pages 184 196, San Diego, CA, USA, Jan. 19 21, 1998. ACM Press. [8] \nP. Cousot and R. Cousot. Abstract interpretation: A uni.ed lattice model for static analysis of programs \nby construction of approximation of .xed points. In Proceedings of the 4th ACM SIGPLAN SIGACT Symposium \non Principles of Programming Languages (POPL 77), pages 238 252, Los Angeles, CA, USA, Jan. 17 19, 1977. \nACM Press. [9] P. Cousot and R. Cousot. Systematic design of program analysis frameworks. In Proceedings \nof the 6th ACM SIGPLAN SIGACT Symposium on Principles of Programming Languages (POPL 79), pages 269 282, \nSan Antonio, TX, USA, Jan. 29 31, 1979. ACM Press. [10] P. Cousot and R. Cousot. Systematic design of \nprogram transforma\u00adtion frameworks by abstract interpretation. In Proceedings of the 29th ACM SIGPLAN \nSIGACT Symposium on Principles of Programming Languages (POPL 02), pages 178 190, Portland, OR, USA, \nJan. 16 18, 2002. ACM Press. [11] M. Dalla Preda and R. Giacobazzi. Control code obfuscation by abstract \ninterpretation. In Proceedings of the 3rd IEEE Interna\u00adtional Conference on Software Engineeering and \nFormal Methods (SEFM 05), pages 301 310, Koblenz, Germany, Sept. 5 9, 2005. IEEE Computer Society. [12] \nM. Dalla Preda and R. Giacobazzi. Semantic-based code obfuscation by abstract interpretation. In Proceedings \nof the 32nd International Colloquium on Automata, Languages and Programming (ICALP 05), volume 3580 of \nLecture Notes in Computer Science, pages 1325 1336, Lisboa, Portugal, July 11 15, 2005. Springer Berlin \n/ Heidel\u00adberg. [13] T. Detristan, T. Ulenspiegel, Y. Malcom, and M. S. von Underduk. Polymorphic shellcode \nengine using spectrum analysis. Phrack, 11(61):published online at http://www.phrack.org (last accessed \non Jan. 16, 2004), Aug. 2003. [14] S. Goldwasser and Y. T. Kalai. On the impossibility of obfuscation \nwith auxiliary input. In Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science \n(FOCS 05), pages 553 562, Washington, DC, USA, Oct. 22 25, 2005. IEEE Computer Society. [15] A. Gupta \nand R. Sekar. An approach for detecting self-propagating email using anomaly detection. In G. Vigna, \nE. Jonsson, and C. Kruegel, editors, Proceedings of the 6th International Symposium on Recent Advances \nin Intrusion Detection (RAID 03), volume 2820 of Lecture Notes in Computer Science, pages 55 72, Pittsburgh, \nPA, USA, Sept. 8 10, 2003. Springer Berlin / Heidelberg. [16] Intel Corporation. IA-32 Intel Architecture \nSoftware Developer s Manual. [17] M. Jordan. Dealing with metamorphism. Virus Bulletin, pages 4 6, Oct. \n2002. [18] J. Kinder, S. Katzenbeisser, C. Schallhart, and H. Veith. Detecting malicious code by model \nchecking. In K. Julisch and C. Kr\u00a8ugel, editors, Proceedings of the 2nd International Conference on Intrusion \nand Malware Detection and Vulnerability Assessment (DIMVA 05), volume 3548 of Lecture Notes in Computer \nScience, pages 174 187, Vienna, Austria, July 7 8, 2005. Springer Berlin / Heidelberg. [19] J. Z. Kolter \nand M. A. Maloof. Learning to detect malicious executables in the wild. In Proceedings of the 10th ACM \nSIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 04), pages 470 478, Seattle, \nWA, USA, Aug. 22 25, 2004. ACM Press. [20] W.-J. Li, K. Wang, S. J. Stolfo, and B. Herzog. Fileprints: \nIdentifying .le types by n-gram analysis. In Proceedings of the 6th Annual IEEE Systems, Man, and Cybernetics \n(SMC) Workshop on Information Assurance (IAW 05), pages 64 71, West Point, NY, June 15 17, 2005. United \nStates Military Academy. [21] C. Linn and S. Debray. Obfuscation of executable code to improve resistance \nto static disassembly. In Proceedings of the 10th ACM Conference on Computer and Communications Security \n(CCS 03), pages 290 299, Washington, DC, USA, Oct. 27 30, 2003. ACM Press. [22] P. Morley. Processing \nvirus collections. In Proceedings of the 2001 Virus Bulletin Conference (VB2001), pages 129 134, Prague, \nCzech Republic, Sept. 27 28, 2001. Virus Bulletin. [23] C. Nachenberg. Computer virus-antivirus coevolution. \nCommunica\u00adtions of the ACM, 40(1):46 51, Jan. 1997. [24] Rajaat. Polymorphism. 29A Magazine, 1(3), 1999. \n[25] Symantec Corporation. Symantec Internet Security Threat Report: Trends for January 06 June 06, volume \nX. Symantec Corporation, Sept. 25, 2006. [26] P. Sz\u00a8or. The Art of Computer Virus Research and Defense. \nAddison-Wesley Professional, 2005. [27] P. Sz\u00a8or and P. Ferrie. Hunting for metamorphic. In Proceedings \nof the 2001 Virus Bulletin Conference (VB2001), pages 123 144, Prague, Czech Republic, Sept. 27 28, \n2001. Virus Bulletin. [28] H. Wee. On obfuscating point functions. In Proceedings of the 37th Annual \nACM Symposium on Theory of Computing (STOC 05), pages 523 532, Baltimore, MD, USA, May 21 24, 2005. ACM \nPress. [29] z0mbie. Automated reverse engineering: Mistfall engine. Published online at http://www.madchat.org//vxdevl/papers/ \nvxers/Z0mbie/autorev.txt (last accessed on Sep. 29, 2006). [30] z0mbie. Real permutating engine. Published \nonline at http: //vx.netlux.org/vx.php?id=er05 (last accessed on Sep. 29, 2006). \n\t\t\t", "proc_id": "1190216", "abstract": "Malware detection is a crucial aspect of software security. Current malware detectors work by checking for \"signatures,\" which attempt to capture (syntactic) characteristics of the machine-level byte sequence of the malware. This reliance on a syntactic approach makes such detectors vulnerable to code obfuscations, increasingly used by malware writers, that alter syntactic properties of the malware byte sequence without significantly affecting their execution behavior.This paper takes the position that the key to malware identification lies in their semantics. It proposes a semantics-based framework for reasoning about malware detectors and proving properties such as soundness and completeness of these detectors. Our approach uses a trace semantics to characterize the behaviors of malware as well as the program being checked for infection, and uses abstract interpretation to \"hide\" irrelevant aspects of these behaviors. As a concrete application of our approach, we show that the semantics-aware malware detector proposed by Christodorescu <i>et al.</i> is complete with respect to a number of common obfuscations used by malware writers.", "authors": [{"name": "Mila Dalla Preda", "author_profile_id": "81322503658", "affiliation": "University of Verona, Verona, Italy", "person_id": "PP39057170", "email_address": "", "orcid_id": ""}, {"name": "Mihai Christodorescu", "author_profile_id": "81100382745", "affiliation": "University of Wisconsin, Madison, WI", "person_id": "PP36027647", "email_address": "", "orcid_id": ""}, {"name": "Somesh Jha", "author_profile_id": "81100352621", "affiliation": "University of Wisconsin, Madison, WI", "person_id": "PP14126181", "email_address": "", "orcid_id": ""}, {"name": "Saumya Debray", "author_profile_id": "81100148240", "affiliation": "University of Arizona, Tucson, AZ", "person_id": "P260626", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1190216.1190270", "year": "2007", "article_id": "1190270", "conference": "POPL", "title": "A semantics-based approach to malware detection", "url": "http://dl.acm.org/citation.cfm?id=1190270"}