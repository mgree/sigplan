{"article_publication_date": "01-17-2007", "fulltext": "\n Modular Type Classes Derek Dreyer Robert Harper Manuel M.T. Chakravarty Toyota Technological Institute \nat Chicago Carnegie Mellon University University of New South Wales dreyer@tti-c.org rwh@cs.cmu.edu chak@cse.unsw.edu.au \n Abstract ML modules and Haskell type classes have proven to be highly ef\u00adfective tools for program structuring. \nModules emphasize explicit con.guration of program components and the use of data abstrac\u00adtion. Type \nclasses emphasize implicit program construction and ad hoc polymorphism. In this paper, we show how the \nimplicitly\u00adtyped style of type class programming may be supported within the framework of an explicitly-typed \nmodule language by viewing type classes as a particular mode of use of modules. This view of\u00adfers a harmonious \nintegration of modules and type classes, where type class features, such as class hierarchies and associated \ntypes, arise naturally as uses of existing module-language constructs, such as module hierarchies and \ntype components. In addition, program\u00admers have explicit control over which type class instances are \navail\u00adable for use by type inference in a given scope. We formalize our approach as a Harper-Stone-style \nelaboration relation, and provide a sound type inference algorithm as a guide to implementation. Categories \nand Subject Descriptors D.3.1 [Programming Lan\u00adguages]: Formal De.nitions and Theory; D.3.3 [Programming \nLanguages]: Language Constructs and Features Polymorphism, Modules; F.3.3 [Logics and Meanings of Programs]: \nStudies of Program Constructs Type structure General Terms Design, Languages, Theory Keywords Type classes, \nmodules, type inference, type systems 1. Introduction The ML module system [17] and the Haskell type \nclass system [23, 19] have proved, through more than 15 years of practical experi\u00adence and theoretical \nanalysis, to be effective linguistic tools for structuring programs. Each provides the means of specifying \nthe functionality of program components, abstracting programs over such speci.cations, and instantiating \nprograms with speci.c real\u00adizations of the speci.cations on which they depend. In ML such speci.cations \nare called signatures, abstraction is achieved through functors, and instantiation is achieved by functor \napplication to structures that implement these signatures. In Haskell such spec\u00adi.cations are called \ntype classes, abstraction is achieved through constrained polymorphism, and instantiation is achieved \nthrough Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior specific permission and/or a fee. POPL \n07 January 17 19, 2007, Nice, France. Copyright c . 2007 ACM 1-59593-575-4/07/0001. . . $5.00. polymorphic \ninstantiation with instances of type classes. There is a clear correspondence between the highlighted \nconcepts (see [24]), and consequently modules and type classes are sometimes regarded as opposing approaches \nto language design. We show that there is no opposition. Rather, type classes and modules are complemen\u00adtary \naspects of a comprehensive framework of modularity. Perhaps the most signi.cant difference is the mode \nof use of the two concepts. The Haskell type class system is primarily intended to support ad hoc polymorphism \nin the context of a parametrically polymorphic language. It emphasizes the implicit inference of class \nconstraints and automatic construction of instances during overload resolution, which makes it convenient \nto use in many common cases, but does not facilitate more general purposes of modular programming. Moreover, \nthe emphasis on automatic generation of instances imposes inherent limitations on expressiveness most \nimportantly, there can be at most one instance of a type class at any particular type. In contrast, the \nML module system is designed to support the structuring of programs by forming hierarchies of components \nand imposing abstraction boundaries both client-side abstraction, via functors, and implementor-side \nabstraction, via signature ascription (aka sealing). The module system emphasizes explicit manipula\u00adtion \nof modules in the program, which makes it more .exible and general than the type class mechanism. Modules \nmay be ascribed multiple signatures that reveal varying amounts of type informa\u00adtion, signatures may \nbe implemented by many modules, and neither modules nor signatures are restricted to have the rigid form \nthat Haskell s instances and classes have. On the other hand, ML lacks support for implicit module generation \nand ad hoc polymorphism, features which experience with Haskell has shown to be convenient and desirable. \nThere have been many proposals to increase the expressive\u00adness of the original type class system as proposed \nby Wadler and Blott [23], including constructor classes [15], functional dependen\u00adcies [12], named instances \n[16], and associated types [2, 1]. These may all be seen as adding functionality to the Haskell class \nsystem that mirrors aspects of the ML module system, while retaining the implicit style of usage of type \nclasses. However, these (and other) extensions tend to complicate the type class system without allevi\u00adating \nthe underlying need for a more expressive module system. In fact, there are ways in which the Haskell \ntype class mech\u00adanism impedes modularity. To support implicit instance genera\u00adtion while ensuring coherence \nof inference, Haskell insists that instances of type classes be drawn from a global set of instance declarations; \nin particular, instances are implicitly exported and imported, which puts their availability beyond programmer \ncon\u00adtrol. This can be quite inconvenient for many type classes there is more than one useful instance \nof the class at a particular type, and the appropriate choice of instance depends on the context in which \nan overloaded operator is used. Hence, the Haskell Prelude must provide many functions in two versions: \none using type classes and the other an explicit function argument e.g., sort and sortBy. In this paper \nwe take a different tack. Rather than bolster the expressiveness of type classes, we instead propose \nthat a more sen\u00adsible approach to combining the bene.ts of type classes and mod\u00adules is to start with \nmodules as the fundamental concept, and then recover type classes as a particular mode of use of modularity. \nWe retain the advantages of a fully expressive explicit module system, while also offering the conveniences \nof implicit type class program\u00adming, particularly the integration of ad hoc and parametric poly\u00admorphism. \nMoreover, the proposed design provides a clean separa\u00adtion between the de.nition of instances and their \navailability for use during type inference. This offers localization of instance scoping, enhanced readability, \nand the potential for instances to be compiled separately from their uses. The result is a harmonious \nintegration of modules and type classes that provides the best features of both approaches in a single, \nconsistent framework. The elegance of our approach stems from the observation that type class features, \nsuch as class hierarchies and associated types, arise naturally as uses of existing module-language constructs, \nsuch as module hierarchies and type components. In summary, this paper makes the following contributions: \n We present a smooth integration of type classes and mod\u00adules that provides a foundation for future work \non incorpo\u00adrating type classes into ML and a proper module system into Haskell. We give an intuition \nof the integration of type classes into ML in Section 2.  We highlight some interesting design issues \nthat arose while developing the interpretation of type classes in terms of mod\u00adules (Section 3).  We \nspecify the semantics of an extended module language that supports type classes. We formalize its elaboration \n(in the style of Harper and Stone [9]) into an explicitly-typed module type system. We also generalize \nDamas and Milner s Algorithm W [3] to an inference algorithm for modular type classes that we have proved \nsound with respect to the elab\u00adoration semantics. Due to space limitations, Section 4 only sketches the \nmost salient and unusual features of our formal\u00adization. For the full formalization of our language, \ntogether with expanded technical discussion and theorem statements, we refer the reader to our companion \ntechnical report [7].  Our elaboration translation demonstrates that modules can serve as evidence in \nthe sense of Jones [14]. Compared to the customary use of dictionary records as evidence, modules offer \na cleaner way of handling extensions to the basic type class mechanism such as associated types. In addition, \nfor the application to type classes, the use of modules as evidence makes clear that the construction \nof evidence respects the phase distinction [8], i.e., it is based solely on compile-time information, \nnot run-time information. We conclude in Section 5 with further discussion of related work.  2. Modular \nType Classes: An Overview In this section we summarize our approach to representing the main mechanisms \nof a Haskell-style type class system within the context of an ML-style module system. For readability, \nwe employ ML-like syntax for our examples, although the formal design we describe later is syntactically \nmore austere and leaves a number of (largely super.cial) aspects of an actual ML extension to future \nwork. 2.1 Classes are signatures, instances are modules A type class in Haskell is essentially an interface \ndescribing a set of operations whose types mention a distinguished abstract type vari\u00adable known as the \nclass parameter. It is natural therefore to repre\u00adsent a class in the module setting as a signature (i.e., \nan interface) with a distinguished type component (representing the class param\u00adeter). In particular, \nwe insist that the distinguished type component be named t . It may be followed by any number of other \ntype, value, or substructure components. We call such a signature a class signature, speci.cally an atomic \nclass signature (in contrast to the composite ones that we describe below in Section 2.3.) For exam\u00adple, \nthe class of equality types is represented by the atomic class signature EQ, de.ned as follows: signature \nEQ = sig type t val eq :t *t ->bool end Note that class signatures like EQ are just ordinary ML signatures \nof a certain speci.ed form. Correspondingly, an instance of a type class is represented by a module. \nA monomorphic instance of a type class is represented by a structure, and a polymorphic instance is represented \nby a functor. For example, we can encode an int instance of the equality class as a structure whose signature \nis EQ where type t = int: structure EqInt = struct type t =int val eq = Int.eq end As in Haskell, the \ninstance for a compound type t(t1,...,tn) is composed from instances of its component types, t1,...,tn,bya \nfunctor, Eq t, associated with its outermost type constructor, t.For example, here is an instance of \nequality for product types t1 * t2: functor EqProd (X : EQ, Y : EQ) = struct type t =X.t * Y.t fun eq \n((x1,y1), (x2, y2)) = X.eq(x1,x2) andalso Y.eq(y1,y2) end There is an evident correspondence with Haskell \ninstance decla\u00adrations, but rather than use Horn clause logic programs to specify closure conditions, \nwe instead use functional programs (in the form of functors). From the EqInt and EqProd modules we can \nconstruct an instance, say, of signature EQ where type t=int*int: structure EqII = EqProd(EqInt,EqInt) \n Of course, one of the main reasons for using type classes in the .rst place is so that we don t have \nto write this functor application manually it corresponds to the process known as dictionary con\u00adstruction \nin Haskell and can be performed automatically, behind the scenes, during type inference. In particular, \nsuch automatic functor application may occur in the elaboration of expressions that ap\u00adpear to be values, \nsuch as when a variable undergoes polymorphic instantiation (see below). Consequently, it is important \nthat the ap\u00adplication of an instance functor does not engender any computa\u00adtional effects, such as I/O \nor non-termination. We therefore require that instance functors be total in the sense that their bodies \nsatisfy something akin to ML s value restriction. This restriction appears necessary in order to ensure \npredictable program behavior. 2.2 Separating the de.nition of an instance from its use In Haskell, an \ninstance becomes immediately available for use by the type inference engine as soon as it is declared. \nAs a conse\u00adquence, due to the implicit global importing and exporting of in\u00adstances, there can only ever \nbe a single instance of a class at a cer\u00adtain type in one program. This is often a nuisance and leads \nto awk\u00adward workarounds. Proposals such as named instances [16] have attempted to alleviate this problem, \nbut have not been generally ac\u00adcepted. In contrast, our reconstruction of type classes in terms of mod\u00adules \nprovides a natural solution to this dilemma. Speci.cally, we require that an instance module only become \navailable for use by the inference engine after it has been nominated for this purpose explicitly by \na using declaration. This separates the de.nition of an instance from its adoption as a canonical instance, \nthus facili\u00adtating modular decomposition and constraining inference to make use only of a clearly speci.ed \nset of instances. For example, the declaration using EqInt, EqProd in mod nominates the two instance \nmodules de.ned earlier as available for canonical instance generation during elaboration of the module \nmod . The typing rule for using demands that EqInt and EqProd not overlap with any instances that have \nalready been adopted as canonical. (A precise de.nition of overlapping instances is given in Section \n3.2.) In both our language and Haskell, canonical instance genera\u00adtion is implicitly invoked whenever \noverloading is resolved. In our language, we additionally provide a mechanism canon(sig ) by which the \nprogrammer can explicitly request the canonical instance module implementing the class signature sig \n.1 At whatever point within mod instance generation occurs, it will employ only those instances that \nhave been adopted as canonical in that scope.  2.3 Class hierarchies via module hierarchies In Haskell, \none can extend a class A with additional operations to form a class B, at which point A is called a superclass \nof B. Class hierarchies arise in the module setting naturally from module hierarchies. This is easiest \nto illustrate by example. Suppose we want to de.ne a class called ORD, which extends the EQ class with \na lt operation. We can do this by .rst de.ning an atomic class LT that only supports lt, and then de.ning \nORD as a composite of EQ and LT: signature ORD = sig structure E : EQ structure L : LT sharing type E.t \n= L.t end The sharing speci.cation makes explicit that ORD is providing two different interpretations \nof the same type, as an equality type and as an ordered type. ORD is an example of what we call a composite \nclass signature, i.e., a signature consisting of a collection of atomic signatures bound to submodules \nwhose names are arbitrary. Instances of composite class signatures are not written by the programmer \ndirectly, but rather are composed automatically by the inference engine from the instances for their \natomic signature parts. For example, if we want to write instances of ORD for int and the * type constructor, \nwhat we do instead is to write instances of LT: structure LtInt = struct type t= int val lt = Int.lt \nend functor LtProd (X : ORD, Y : LT) = struct type t = X.E.t * Y.t fun lt ((x1,y1), (x2,y2)) = X.L.lt(x1,x2) \norelse (X.E.eq(x1,x2) andalso Y.L.lt(y1,y2)) end Note that LtProd requires its .rst argument to be an \ninstance of ORD, not LT. This is because the implementation of lt in the body 1 This feature is particularly \nuseful in conjunction with our support for associated types; see Section 2.5. of the functor depends \non having both equality and ordering on the type X.E.t so that it can implement a lexicographic ordering \non X.E.t * Y.t.For Y.t, only the lt operation is needed. Now, let us assume these instances are made \ncanonical (via the using declaration) in a certain scope. Then, during typechecking, if the inference \nengine demands a canonical module of signature ORD where type E.t = int * int, it will be computed to \nbe struct structure E = EqProd(EqInt,EqInt) structure L = LtProd(struct structure E = EqInt structure \nL = LtInt end, LtInt) end The fundamental reason that we do not allow instances for ORD to be adopted \ndirectly is that we wish to prevent the in\u00adstances for ORD from having any overlap with existing instances \nthat may have been adopted for EQ. If one were to de.ne an in\u00adstance for ORD where type E.t = int directly, \none would im\u00adplicitly provide an instance for EQ where type t = int through its E substructure; and if \none tried to adopt such an ORD instance as canonical, it would overlap with any existing canonical instance \nof EQ where type t = int. Under our approach, this sort of overlap is avoided. Moreover, the code one \nwrites is ultimately very similar to the code one would write in Haskell (except that it is expressed \nentirely in terms of existing ML constructs). In particular, the instance declaration for ORD at int \nin Haskell is only permitted to provide a de.nition for the new operations (namely, lt) that are present \nin ORD but not in EQ. In other words, an instance declaration for ORD in Haskell is precisely what we \nwould call an instance of LT. 2.4 Constrained polymorphism via functors Under the Harper-Stone interpretation \nof Standard ML (hereafter, HS) [9], polymorphic functions in the external (source) language are elaborated \ninto functors in an internal module type system. Speci.cally, a polymorphic value is viewed as a functor \nthat takes a module consisting only of type components (representing the polymorphic type variables) \nas its argument and returns a module consisting of a single value component as its result. The HS semantics \nsupports the concept of equality polymor\u00adphism found in Standard ML by simply extending the class of \nsig\u00adnatures over which polymorphic functions may be abstracted to in\u00adclude the EQ signature de.ned above. \nFor example, in the internal module type system of HS, the ad hoc polymorphic equality func\u00adtion is represented \nby the functor functor eq (X:EQ) :> [[ X.t * X.t -> bool]] = [X.eq] where the brackets notation describes \na module with a single value component. Polymorphic instantiation at a type t consists of com\u00adputing \na canonical instance of EQ where type t = t,as de\u00adscribed above, applying the functor eq to it, and extracting \nthe value component of the resulting module. The present proposal is essentially a generalization of \nthe HS treatment of equality polymorphism to arbitrary type classes. A functor that abstracts over a \nmodule representing an instance of a type class is reminiscent of the notion of a quali.ed type [11], \nexcept that we make use of the familiar concept of a functor from the ML module system, rather than introduce \na new mechanism solely to support ad hoc polymorphism. Of course, the programmer need not write the eq \nfunctor manu\u00adally. Our external language provides an overload mechanism, and the elaborator will generate \nthe above functor automatically when the programmer writes val eq = overload eq from EQ Note that there \nis no need to bind the polymorphic function returned by the overload mechanism to the name eq; it can \nbe called anything. In practice, it may be useful to be able to overload all the components of a class \nsignature at once by writing overload SIG as syntactic sugar for a sequence of overload s for the individual \ncomponents of the signature. The following are some examples of elaboration in the presence of the overloaded \neq function: using EqInt, EqProd in ...eq((2,3),(4,5))... r ...Val(eq(EqProd(EqInt,EqInt))) ((2,3),(4,5))... \nfun refl y = eq(y,y) r functor refl (X : EQ) :> [[ X.t -> bool]] = [fn y => Val(eq(X)) (y,y)] (Note: \nthe Val operator seen here is the mechanism in our internal module type system by which a value of type \nt is extracted from a module of signature [[ t ]] .) Our language also allows for the possibility that \nthe programmer may wish to work with explicitly polymorphic functions in addition to implicit overloaded \nones. In particular, by writing functor Refl = explicit (refl : (X : EQ) -> sig val it : X.t -> bool \nend) we convert the polymorphic function refl into an explicit functor Refl. The programmer can then \napply it to an arbitrary module ar\u00adgument of signature EQ and project out the it component of the re\u00adsult. \nThe reason we require a signature annotation on the explicit construct is that the implicitly-typed refl \nmay be declaratively as\u00adcribed many different signatures. Whenever refl is used, type in\u00adference will \ncompute the appropriate instance arguments for it re\u00adgardless of the particular signature it has been \nascribed. However, since it is the programmer who applies Refl, she needs to know exactly what shape \nRefl s module argument is expected to have. We also provide an implicit construct to coerce explicit \nfunc\u00adtors into implicit ones. (See the technical report [7] for details.)  2.5 Associated types arise \nnaturally The experience with type classes in Haskell quickly led to the de\u00adsire for type classes with \nmore than one class parameter. However, these multi-parameter type classes are not generally very useful \nun\u00adless dependencies between the parameters can be expressed. This led in turn to the proposal of functional \ndependencies [12] and more recently associated types [2, 1] for Haskell. An associated type is a type \ncomponent provided by a class that is not the distinguished type component (class parameter). The associated \ntypes of a class do not play a role in determining the canonical instance of a class at a certain type \nthat is solely determined by the identity of the distinguished type. Modular type classes immediately \nsupport associated types as additional type components of a class signature. An illustrative example \nis provided by a class of collection types: signature COLLECTS = sig type t type elem val empty : t val \ninsert :elem *t ->t val member : elem * t -> bool val toList : t -> elem list end The distinguished \ntype t represents the collection type and the associated type component elem represents the type of elements. \nAn instance for lists, where the elements are required to support equality for the membership test, would \nbe de.ned as follows: functor CollectsList (X : EQ) = struct type t = X.t list type elem = X.t val empty \n= [] fun insert (x, L) = x::L fun member (x, []) = raise NotInCollection | member (x, y::L) = X.eq (x,y) \norelse member (x,L) fun toList L = L end When using classes with associated types, it is common to need \nto place some constraints on the identities of the associated types. For example, suppose we write the \nfollowing: val toList = overload toList from COLLECTS fun sumColl C = sum (toList C) The sumColl function \ndoes not care what type of collection C is, so long as its element type is int. Correspondingly, the \nelaborator will assign sumColl the polymorphic type (i.e., functor signature) (X : COLLECTS where type \nelem = int) -> [[ X.t -> int]] Note that the constraint on the type X.elem is expressed com\u00adpletely naturally \nusing ML s existing where type mechanism, which is just syntactic sugar for the transparent realization \nof an abstract type component in a signature. In contrast, the extension to handle associated type synonyms \nin Haskell [1] requires an ad\u00additional mechanism called equality constraints in order to handle functions \nlike sumColl. As Chakravarty et al. [1] have demonstrated, it is useful in certain circumstances to be \nable to compute (statically) the identity of an associated type assoc in the canonical instance of a \ntype class SIG at a given type t . This is achieved in our setting via the canon(sig ) construct, which \nwe introduced above as a way of explicitly computing a canonical instance. In particular, we can write \ncanon(SIG where type t = t ).assoc which constructs the canonical instance of SIG at t and then projects \nthe assoc type from it.2 In the associated type extension to Haskell, one would instead write assoc(t \n). While the ML syntax here is clearly less compact, there is a good reason for it. Speci.cally, the \nHaskell syntax only makes sense because Haskell ties each associated type name in the pro\u00adgram to a single \nclass (in this case, assoc wouldbe tiedto SIG). In contrast, in our setting, it is .ne for several different \nclass signa\u00adtures to have an associated type component called assoc.  3. Design Considerations In this \nsection we examine some of the more subtle points in the design of modular type classes and explain our \napproach to handling them. 3.1 Coherence in the presence of scoped instances The using mechanism described \nin the introduction separates the de.nition of instance functors from their adoption as canonical 2 Note \nthat, due to the principle of phase separation in the ML module system [8], the identity of the assoc \ntype here can be determined purely statically, and elaboration does not actually need to construct the \ndynamic parts of canon(SIG where type t = t). instances. It also raises questions of coherence stemming \nfrom the nondeterministic nature of polymorphic type inference. Sup\u00adpose EqInt1 and EqInt2 are two observably \ndistinct instances of EQ where type t = int. Consider the following code: structure A = using EqInt1 \nin struct ...fun f x = eq(x,x)... end structure B = using EqInt2 in struct ...val y = A.f(3)... end \nThe type inference algorithm is free to resolve the meaning of this program in two incompatible ways. \nOn the one hand, it may choose to treat A.f as polymorphic over the class EQ; in this case, the ap\u00adplication \nA.f(3) demands an instance of EQ where type t=int, which can only be resolved by EqInt2. On the other \nhand, type in\u00adference is free to assign the type int -> bool to A.f at the point where f is de.ned, in \nwhich case the demand for an instance of EQ can only be met by EqInt1. These are both valid typings, \nbut they lead to observably different behavior. An unattractive solution is to insist on a speci.c algorithm \nfor type inference that arbitrarily chooses one resolution over another, but this sacri.ces the elegant, \ndeclarative nature of a Hindley\u00adMilner-style type system and, worse, imposes a speci.c resolution policy \nthat may not be desired in practice. Instead, we prefer to take a different approach, which is to put \nthe decision under program\u00admer control, permitting either outcome at her discretion. We could achieve \nthis by insisting that the scope of a using declaration be given an explicit signature, so that in the \nabove example the pro\u00adgrammer would have to specify whether A.f is to be polymorphic or monomorphic. \nHowever, this approach is awkward for nested using declarations, forcing repeated speci.cations of the \nsame in\u00adformation. Instead we propose that the using declaration be con.ned to an outer (or top-level) \nlayer that consists only of module declarations, whose signatures are typically speci.ed in any case. \nAll core-level terms appear in the inner layer, where type inference proceeds without restriction, but \nno using clauses are allowed. Thus, the set of permissible instances is .xed in any inner context, but \nmay vary across outer contexts. At the boundary of the two layers, a type or signature annotation is \nrequired. This ensures that the scope of a using declaration is explicitly typed without effecting duplication \nof annotations. The programmer who wishes to ignore type classes simply con.nes herself to the inner \nlevel, with no restrictions; only the use of type classes demands attention be paid to the distinction. \n 3.2 Overlapping instances To ensure coherence of type inference, the set of available instances in \nany context must be non-overlapping. Roughly speaking, this means that there should only be one way to \ncompute the canonical instance of any given class at any given type. There is considerable leeway, though, \nin determining the precise de.nition of overlap, and indeed this remains a subject of debate in the Haskell \ncommu\u00adnity. For the purposes of this paper we follow the guidelines used in Haskell 98. In particular, \nwe insist that there be one instance per type constructor, so that instance resolution proceeds by a \nsimple inductive analysis of the structure of the instance type, composing instance functors to obtain \nthe desired result. However, in the modular approach suggested here, there is an additional complication. \nJust as a module may satisfy several dif\u00adferent signatures, so a single module may qualify as an instance \nof several different type classes. For example, the module struct type t = int; fun f(x:t) = x end may \nbe seen as an instance of the class sig type t; val f: t-> tend and also of the class sig type t; valf \n:t -> intend. Thus, to check if two instances A and B (with the same t com\u00adponent) are non-overlapping, \nwe need to ensure that the set of all classes to which A could belong is disjoint from the set of all \nclasses to which B could also belong. A simple, but practical, criterion to ensure this is to de.ne two \ninstances to be non-overlapping iff either (1) they differ on their distinguished t component, so that \nno overlap is possible, or (2) in the case that they have the same t component, that they be struc\u00adturally \ndissimilar, which we de.ne to mean that their components do not all have the same names and appear in \nthe same order. While other, more re.ned de.nitions are possible, we opt here for sim\u00adplicity until evidence \nof the need for a more permissive criterion is available. 3.3 Unconstrained type components in class \nsignatures In order to support ordinary ML-style polymorphism, we need a way to include unconstrained \ntype components in a class signa\u00adture. We could use the class signature sig type t end for this purpose. \nHowever, since our policy is that the only canonical in\u00adstances of atomic class signatures are those \nthat have been ex\u00adplicitly adopted as canonical by a using declaration, this would amount to treating \nsig type t end as a special case. We choose instead to allow composite class signatures to con\u00adtain arbitrary \nunconstrained type components, so long as they are named something other than t. For example, under our \napproach, the divergent function fun fx =f x can be assigned the polymorphic type (X : sig type a; type \nb end) -> [[ X.a -> X.b]] (The choice of the particular names a and b here is arbitrary.) In our formal \nsystem, we refer to the union of the t components and the unconstrained components of a class signature \nS as the parameters of S . 3.4 Multi-parameter and constructor classes Two extensions to Wadler &#38; \nBlott s [23] type class system that have received considerable attention are multi-parameter type classes \nand constructor classes. We have chosen not to cover these exten\u00adsions in this paper. Concerning multi-parameter \nclasses, most uses of them require functional dependencies [12], which when rewrit\u00adten to use associated \ntypes (which we support), turn into single\u00adparameter classes. Hence, we expect the need for multi-parameter \nclasses to be greatly diminished in our case. As for constructor classes, we see no fundamental problems \nin supporting them in an extension of our framework since type components of ML modules may have higher \nkind. However, we view them as an orthogonal extension, and thus have opted to omit them in the interest \nof a clearer and more compact presentation.  4. Formal System In this section, we will give a brief \nsketch of our type-theoretic for\u00admalization of modular type classes, highlighting its most distinctive \nfeatures. For full details, see the companion technical report [7]. 4.1 Declarative elaboration semantics \nFollowing Harper and Stone [9], we de.ne our language of modular type classes using an elaboration semantics,in \nwhich external lan\u00adguage (EL) source programs are interpreted by translation into an internal language \n(IL) type system. The elaboration translation is syntax-directed, but it is also nondeterministic with \nrespect to poly\u00admorphic generalization and instantiation. This style of de.nition is the standard method \nof giving meanings to programs involving type classes, although in the context of Haskell it is often \nreferred to as evidence translation [14]. The IL we use is a simpli.ed variant of the type system for \nmodules given in Dreyer s thesis [4], which in turn is based on the higher-order module calculus of Dreyer, \nCrary and Harper [6]. For de.ning the semantics of type classes, the most salient feature of this IL \nis that it distinguishes between two kinds of functors (and functor signatures): total and partial. Total \nfunctor signatures, written .X:S1.S2, classify functors with argument signature S1 and result signature \nS2, whose bodies are judged syntactically to be free of computational effects. Partial functor signatures, \nwritten .X:S1.S2, classify functors whose bodies may contain effects. In general, since ML is not purely \nfunctional, ML functors may be partial. However, as we explained in Section 2.1, we require that instance \nfunctors be total in order to ensure predictable program behavior at points of polymorphic instantiation. \n(A technical aside: the notation S2 for the result signature of a total functor indicates that it is \nrequired syntactically to be transparent. This restriction is demanded by Dreyer et al. s treatment of \ndata abstraction as a computational effect, but it is in no way a hindrance functors corresponding to \nHaskell instances are naturally transparent.) As for our external language, we have already described \nmost of its novel constructs informally in Section 2. One feature of our EL that we have not discussed \nis its mechanism for inducing polymorphic generalization. Traditionally, generalization is per\u00adformed \nimplicitly as part of typechecking a term-level let con\u00adstruct, let x=exp1 in exp2 (hence the name let-polymorphism). \nAf\u00adter typechecking exp1, the principal type scheme of exp1 is gener\u00adalized into a polymorphic type (or \npolytype), to which x is bound during the typechecking of exp2. As explained in Section 2.4, polymorphic \ntypes are modeled in our language as a special case of functor signatures in which the argument has a \nclass signature and the result signature speci\u00ad.es a single value component. Thus, instead of tying generaliza\u00adtion \nto let, we opt instead to induce it via an orthogonal construct [exp] that coerces an EL core term exp \ninto a module, thereby generalizing its monotype (i.e., type) into a polytype (i.e., functor signature). \nLikewise, polymorphic instantiation occurs implicitly when a module path P a module variable X followedbyzeroor \nmore component projections is used as a core-language expres\u00adsion. Under this approach, traditional let-polymorphism \nis modeled as a composition of the generalizing [exp] and a non-generalizing let-construct let X=mod \nin exp. In particular, the let-polymorphic let x=exp1 in exp2 is encodable as let X=[exp1] in {x . X}exp2. \nFollowing Harper and Stone, the main translation judgments in our elaboration semantics all have the \nform T; G f EL-phrase r IL-phrase : IL-classi.er Here, EL-phrase and IL-phrase range over EL and IL modules, \nterms and type constructors, and IL-classi.er ranges correspond\u00adingly over IL signatures, types and kinds. \nWe design the inference rules so that the output IL-phrase is guaranteed to have the output IL-classi.er \nin the IL type system. The context G may contain bind\u00adings of type variables ato kinds K, term variables \nxto types t,and module variables X to signatures S. The novel element in this judg\u00adment form is T, which \nis a set of paths to structures and functors that are to be considered canonical instances within EL-phrase.We \ncall T the canonical instance set. Most of the rules in our elaboration semantics are similar to corresponding \nrules in the Harper-Stone semantics, and thus do not interact with the canonical instance set T. There \nare three major rules that do. One is the rule for the using mechanism, which has the effect of adding \na given path to T (under the condition that it does not overlap with any instance modules already in \nT). Most of the work in formalizing this rule is in specifying what it means for two instances to overlap. \nSee the technical report for details [7]. Two other rules that interact with T are those for polymorphic \ngeneralization and instantiation. Rule 1 formalizes the polymorphic instantiation that occurs when a \nmodule path P is used as a term: G f P: .X:S.[[t]] G f S = ST;G fcan V : S (1) T; G f P r Val(P(V)): \nt[V/X] The .rst premise checks that P is in fact a polymorphic value (rep\u00adresented as a total functor). \nInstantiation then consists of .nding the canonical instance module of the class signature S to which \nP will be applied. Since the parameters of S are abstract, the choice of which instance module is nondeterministic. \nConsequently, the second premise picks a transparent signature S that is a subtype of S, meaning that \nit realizes the parameters of S with some choices t1,...,tn. (Signature subtyping, a common judgment \nin module type systems, is de.ned formally in [7].) Lastly, the third premise computes the canonical \nIL module V of signature S using the canonical module judgment T; G fcan V : S. Note that all of this \nis done in terms of module and signature judgments, without ever explicitly mentioning the instantiating \ntypes t1,...,tn! The canonical module judgment T; G fcan V : S is straightfor\u00adward to de.ne. In short, \na composite instance module is canoni\u00adcal if all its atomic instance components are canonical; an atomic \ninstance module is canonical if it is either a canonical instance structure (from the set T) or the result \nof applying a canonical in\u00adstance functor from T to a canonical argument. Canonical modules may also \ncontain arbitrary unconstrained type components (named something other than t, as per the discussion \nin Section 3.3). Rule 2 formalizes polymorphic generalization for [exp]: X . FV(exp)G fclass X:S r T' \nT,T';G,X:S f exp r v : t (2) T; G f [exp] r .X:S.[v]: .X:S.[[t]] One can view this rule as guessing \na polymorphic type .X:S.[[t]] to assign to exp. Suppose that S is an atomic class signature like EQ. \nIn order to see whether exp can be elaborated with this type, we add the class constraint X:S to the \ncontext and make it a canonical instance of the signature S where type t = X.t (by adding X to T) before \ntypechecking exp. The last step is critical: if X is not added to T, then the canonical module judgment \nwill have no way of knowing that X is the canonical module of signature S where type t = X.t at polymorphic \ninstantiation time. However, in the case that S is a composite class, the elaborator does not permit \nX to be added directly to the instance set T. To simplify the formalization of other judgments, we require \nall the instance structures in T to have atomic signature. Thus, in general we need a way of parsing \nthe class constraint X:S in order to produce a set of paths T' (all of which are rooted at X)that represent \nthe atomic instance modules contained within X. This class parsing is achieved via the class elaboration \njudg\u00adment G fclass X:S r T' used in the second premise of Rule 2. For example, if S were the composite \nclass ORD from Section 2.3, then T' would be the set {X.E,X.L}. In the case that there are multi\u00adple \npaths in X to atomic instances of the same signature, T' will include exactly one. (It doesn t matter \nwhich one, since X repre\u00adsents a canonical instance module, and the fcan judgment guaran\u00adtees that any \ntwo submodules of a canonical module that have the same transparent signature must be the same module \nvalue.) The class elaboration judgment also checks that S is a valid class signature. A signature is \nconsidered a valid class signature if it is a collection of unconstrained type components and atomic \ninstance components (whose .rst component is t), in which the unconstrained and t components i.e., the \nparameters of S are all abstract (although possibly, as in the case of ORD, subject to type sharing constraints). \nThe requirement that the parameters of S be abstract ensures that the instances in the set T ' all concern \nabstract type components of the freshly chosen variable X,which in turn guarantees that the instances \nin T ' do not overlap with any instances in the input instance set T. 4.2 Type inference algorithm The \nelaboration semantics sketched above is nondeterministic, and hence is not directly implementable without \nbacktracking. In order to guide implementation, we therefore also provide a type inference algorithm \nin the style of Algorithm W[3]. This section describes some highlights of our algorithm. Following Damas \nand Milner, we thread through the inference rules a substitution d whose domain consists of uni.cation \nvari\u00adables, denoted by bold a. In addition, polymorphic instantiation in the presence of type classes \ngenerates constraints, which we de\u00adnote S. Constraints are sets of X:S bindings, in which the X s do \nnot appear free in the S s. Each X:S represents a demand generated by the algorithm for a canonical module \nof signature S to be sub\u00adstituted for X in the term or module that is output by elaboration. For example, \nthe inference judgment for terms has the form T; G fexp .e : t/(S; d), where everything to the left of \nthe . is input to the algorithm and everything to the right of the .is output. Rule 3 is the inference \nrule for polymorphic instantiation: G fP:..X:S.[[t]] S . .a.S G,X:S ft .t ' (3) T; G fP .Val(P(X)): t \n' /(X:S; id) Given a path P of polymorphic signature .X:S.[[t]], the second premise uses the auxiliary \njudgment S . .a.S to generate fresh uni.cation variables a corresponding to the abstract type com\u00adponents \nof S. It then applies P to an unknown canonical module X of signature S, and projects out the value component. \nThis in turn effects a demand for X:S in the output constraint. For exam\u00adple, if S were the class EQ, \nthen the output constraint would be X: EQ where type t = a.(Note:the :. judgment used in the .rst premise \nindicates .X:S.[[t]] is the normal form signature of P, and the last premise normalizes t so that references \nto type com\u00adponents of X become references to the corresponding a.) As type inference uncovers the identity \nof certain uni.cation variables, it becomes possible (and at certain points necessary) to eliminate some \nof the constraints amassed in S through a process we call constraint normalization. This process takes \nzero or more steps of constraint reduction until the input constraint has been converted to a normal \nform in which all residual constraints are instances of atomic classes at uni.cation variables. The normaliza\u00adtion \njudgment has the form T; G fS1 .(S2; s; d),where s is a module substitution whose domain is that of S1. \nThe relation be\u00adtween the input and output of normalization is summarized by the following invariant: \nIf T; G fS1 .(S2; s; d), then .X:S .S1. T,dom(S2); dG,S2 fcan sX: dS. That is, if we treat the domain \nof the normalized constraint S2 as a set of canonical instances, then from those instances together with \nthe canonical instances already in T, the substitution s shows how to construct canonical modules to \nsatisfy all the demands of the original constraint S1 (subject to type substitution d). To make this \nconcrete, suppose T contains the EqInt and EqProd instance modules given in Section 2.1, and suppose \nthat S1 is X: EQ where type t = int * a. Then the normalized S2 would be Y: EQ where type t = a, and \nthe substitution s would map X to EqProd(EqInt,Y). (In this case, d would simply be the identity substitution \nid.) The constraint normalization algorithm may be viewed as a backchaining implementation of the canonical \nmodule judgment. It is essentially a combination of Haskell-style context reduction (aka simpli.cation) \nand constraint improvement [10], except that it is formalized entirely in terms of modules and signatures. \n 4.3 Soundness We have proven that our inference algorithm is sound with respect to the elaboration semantics. \nFor space reasons, we collect the main results here and refer the reader to the companion techni\u00adcal \nreport [7] for the full statement of the soundness theorem and its auxiliary de.nitions, including the \nprecise meaning of the theo\u00adrem s preconditions. Theorem (Soundness) . T, G '' Suppose (T; G) is valid \nfor inference, T ' f d : dG, f(T ' ;G ' ) ok,and .X:S .S. T ' ;G ' fcan s ' X: d ' S. Then: 1. If T; \nG fexp .e : t/(S; d), '' ' then T ' ;G ' fexp r sde : dt. 2. If T; G fmod .M:S/(S; d), then T ' ;G ' \nfmod r s ' d ' M: d ' S.  Consider part 1. Informally, T, G and exp are inputs. If type inference on \nexp succeeds, it produces an IL term e, along with a constraint S and a substitution d. If in any future \nworld (T ' ;G ' ) the constraint S can be solved by substitutions s ' and d ' ,then exp will declaratively \nelaborate to s ' d ' e in that world. The theorem statement for modules (part 2) is analogous. 4.4 Incompleteness \nWhile the inference algorithm is sound, it is not complete, for rea\u00adsons that arise independently of \nthe present work. One source of in\u00adcompleteness is inherited from Haskell and concerns a fundamental \nproblem with type classes, namely the problem of ambiguity [14]. The canonical example uses the following \ntwo signatures: signature SHOW = sig type t val show : t -> string end signature READ = sig type t val \nread : string -> t end val show = overload show from SHOW val read = overload read from READ Given this \noverloading, the expression show (read (\"1\")) is ambiguous, as the result type of read and argument type \nof show are completely unconstrained. This is problematic because, de\u00adpending on the available canonical \ninstances, two or more valid elaborations with observably different behaviour may exist. Hence, ambiguous \nprograms need to be rejected. This can be done easily during inference, but for inference to be complete \nthe complete\u00adness theorem has to be formulated in such a way that ambiguous programs are excluded from \nconsideration. We have avoided this issue here entirely in the interest of a clearer presentation. Another \nsource of incompleteness is inherited from ML, and arises from the interaction between modules and type \ninference. Consider the following Standard ML program: functor F(X : sig type t end) = struct val f = \n(print \"Hello\"; fn x => x) end structure Y1 = F(struct type t = int end) structure Y2 = F(struct type \nt = bool end) val z1 = Y1.f(3) val z2 = Y2.f(true) The binding of f in F is chosen to have an effect, \nso that it cannot be given a polymorphic type. This raises the question of what sig\u00adnature should be \nassigned to F. According to the De.nition of Stan\u00addard ML [18] (and the HS semantics as well), the above \nprogram is well-typed because f may be assigned the type X.t -> X.t, which is consistent with both subsequent \nuses of F. But in order to .gure this out, a compiler would have to do a form of higher\u00adorder uni.cation \nonce we leave the scope of X.t, the uni.cation variable in the type of f should be skolemized over X.t. \nAs a result, nearly all existing implementations of Standard ML reject this program, as do we. (The only \none that accepts it is MLton, but MLton also accepts similar programs that the De.nition rejects [5].) \nThis example points out that the interactions between type inference and modules are still not fully \nunderstood, and merit further investigation beyond the scope of this paper.  5. Related Work Type classes \nin Haskell. Since Wadler and Blott s seminal pa\u00adper [23], the basic system of type classes has been extended \nin a number of ways. Of these, Jones framework of quali.ed types [11] and the resulting generalizations \nto constructor classes [15], multi\u00adparameter type classes, and functional dependencies [12] are the most \nwidely used. We discussed the option of supporting multi\u00adparameter and constructor classes in the modular \nsetting in Sec\u00adtion 3.4. Instead of functional dependencies, we support associated types, as they arise \nnaturally from type components in modules. Achieving a separation between instance declaration and in\u00adstance \nadoption, so that instance declarations need not have global scope, is still an open problem in the Haskell \nsetting. There exists an experimental proposal by Kahl and Scheffczyk [16] that is moti\u00advated by a comparison \nwith ML modules. Their basic idea is to al\u00adlow constrained polymorphic functions to be given explicit \ninstance arguments instead of having their instance arguments computed au\u00adtomatically. We support this \nfunctionality by providing the ability to coerce back and forth between polymorphic functions and func\u00adtors, \nthe latter of which may be given explicit module arguments (Section 2.4). Moreover, we permit different \ninstances of the same signature to be made canonical in different scopes, which Kahl and Scheffczyk do \nnot. Comparing type classes and modules. The only formal compari\u00adson between ML modules and Haskell type \nclasses is by Wehr [24]. He formalizes a translation from type classes to modules and vice versa, proves \nthat both translations are type-preserving, and uses the translations as the basis for a comparison of \nthe expressive\u00adness of the language features. Wehr concludes that his encoding can help Haskell programmers \nto emulate certain aspects of mod\u00adules in Haskell, but that the module encoding of type classes in ML \nis too heavyweight to be used for realistic programs. Not surpris\u00adingly, Wehr s encoding of type classes \nas modules uses signatures for classes and modules for instances, as we do. In fact, his transla\u00adtion \ncan be regarded as an elaboration from a Haskell core language to a fragment of ML. However, the fundamental \ndifference between our work and his is that he performs elaboration in the non-modular context of Haskell, \nwhereas we demonstrate how to perform elab\u00adoration and type inference in the modular context of ML. Type \nclasses for ML. Schneider [20] has proposed to extend ML with type classes as a feature independent of \nmodules. This leads to signi.cant duplication of mechanism and a number of techni\u00adcal problems, which \nwe avoid by expressing type classes via mod\u00adules. More recently, Siek and Lumsdaine [22] have described \na language FG that integrates concepts, which are closely related to type classes, into System F. However, \nFG does not support type inference. Siek s thesis [21] de.nes a related language G,which supports inference \nfor type applications, but not type abstractions. Concepts in G are treated as a distinct construct, \nunrelated to mod\u00adules, and G does not support parameterized modules (i.e., functors). Parameterized signatures. \nJones [13] has proposed a way of supporting modular programming in a Haskell-like language, in which \na signature is encoded as a record type parameterized over the abstract type components of the signature. \nHowever, he does not consider the interaction with type classes.  Acknowledgments We thank Stefan Wehr \nfor stimulating discussions on ways of representing type classes with modules. References [1] Manuel \nM. T. Chakravarty, Gabriele Keller, and Simon Peyton Jones. Associated type synonyms. In ICFP 05. [2] \nManuel M. T. Chakravarty, Gabriele Keller, Simon Peyton Jones, and Simon Marlow. Associated types with \nclass. In POPL 05. [3] Luis Damas and Robin Milner. Principal type schemes for functional programs. In \nPOPL 82. [4] Derek Dreyer. Understanding and Evolving the ML Module System. PhD thesis, Carnegie Mellon \nUniversity, Pittsburgh, PA, May 2005. [5] Derek Dreyer and Matthias Blume. Principal type schemes for \nmodular programs. Technical Report TR-2006-08, University of Chicago Comp. Sci. Dept., October 2006. \n[6] Derek Dreyer, Karl Crary, and Robert Harper. A type system for higher-order modules. In POPL 03. \n[7] Derek Dreyer, Robert Harper, Manuel M.T. Chakravarty, and Gabriele Keller. Modular type classes. \nTechnical Report TR-2006\u00ad09, University of Chicago Comp. Sci. Dept., October 2006. [8] Robert Harper, \nJohn C. Mitchell, and Eugenio Moggi. Higher-order modules and the phase distinction. In POPL 90. [9] \nRobert Harper and Chris Stone. A type-theoretic interpretation of Standard ML. In G. Plotkin, C. Stirling, \nand M. Tofte, editors, Proof, Language, and Interaction: Essays in Honor of Robin Milner.MIT Press, 2000. \n[10] Mark P. Jones. Simplifying and improving qualified types. In FPCA 95. [11] Mark P. Jones. A theory \nof qualified types. In ESOP 92. [12] Mark P. Jones. Type classes with functional dependencies. In ESOP \n00. [13] Mark P. Jones. Using parameterized signatures to express modular structure. In POPL 96. [14] \nMark P. Jones. Qualified Types: Theory and Practice.Cambridge University Press, 1994. [15] Mark P. Jones. \nA system of constructor classes: Overloading and implicit higher-order polymorphism. Journal of Functional \nProgramming, 5(1), 1995. [16] Wolfram Kahl and Jan Scheffczyk. Named instances for Haskell type classes. \nIn Haskell Workshop, 2001. [17] David MacQueen. Modules for Standard ML. In LFP 84. [18] Robin Milner, \nMads Tofte, Robert Harper, and David MacQueen. The Definition of Standard ML (Revised). MIT Press, 1997. \n[19] Simon Peyton Jones et al. Haskell 98 language and libraries: the revised report. Journal of Functional \nProgramming, 13(1), 2003. [20] Gerhard Schneider. ML mit Typklassen. Master s thesis, June 2000. [21] \nJeremy Siek. A Language for Generic Programming. PhD thesis, Indiana University, August 2005. [22] Jeremy \nSiek and Andrew Lumsdaine. Essential language support for generic programming. In PLDI 05. [23] P. Wadler \nand S. Blott. How to make ad-hoc polymorphism less ad-hoc. In POPL 89. [24] Stefan Wehr. ML modules and \nHaskell type classes: A constructive comparison. Master s thesis, Albert-Ludwigs-Universit\u00a8at Freiburg, \nInstitut f\u00a8ur Informatik, 2005.  \n\t\t\t", "proc_id": "1190216", "abstract": "ML modules and Haskell type classes have proven to be highly effective tools for program structuring. Modules emphasize explicit configuration of program components and the use of data abstraction. Type classes emphasize implicit program construction and <i>ad hoc</i> polymorphism. In this paper, we show how the implicitly-typed style of type class programming may be supported within the framework of an explicitly-typed module language by viewing type classes as a particular mode of use of modules. This view offers a harmonious integration of modules and type classes, where type class features, such as class hierarchies and associated types, arise naturally as uses of existing module-language constructs, such as module hierarchies and type components. In addition, programmers have explicit control over which type class instances are available for use by type inference in a given scope. We formalize our approach as a Harper-Stone-style elaboration relation, and provide a sound type inference algorithm as a guide to implementation.", "authors": [{"name": "Derek Dreyer", "author_profile_id": "81100381796", "affiliation": "Toyota Technological Institute at Chicago", "person_id": "P414177", "email_address": "", "orcid_id": ""}, {"name": "Robert Harper", "author_profile_id": "81100140064", "affiliation": "Carnegie Mellon University", "person_id": "PP39029368", "email_address": "", "orcid_id": ""}, {"name": "Manuel M. T. Chakravarty", "author_profile_id": "81408595395", "affiliation": "University of New South Wales", "person_id": "P187027", "email_address": "", "orcid_id": ""}, {"name": "Gabriele Keller", "author_profile_id": "81100011375", "affiliation": "University of New South Wales", "person_id": "PP39023133", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1190216.1190229", "year": "2007", "article_id": "1190229", "conference": "POPL", "title": "Modular type classes", "url": "http://dl.acm.org/citation.cfm?id=1190229"}