{"article_publication_date": "01-17-2007", "fulltext": "\n JavaScript Instrumentation for Browser Security Dachuan Yu Ajay Chander Nayeem Islam Igor Serikov DoCoMo \nCommunications Laboratories USA, Inc. {yu,chander,nayeem,iserikov}@docomolabs-usa.com Abstract It is \nwell recognized that JavaScript can be exploited to launch browser-based security attacks. We propose \nto battle such attacks using program instrumentation. Untrusted JavaScript code goes through a rewriting \nprocess which identi.es relevant operations, modi.es questionable behaviors, and prompts the user (a \nweb page viewer) for decisions on how to proceed when appropriate. Our so\u00adlution is parametric with respect \nto the security policy the policy is implemented separately from the rewriting, and the same rewrit\u00ading \nprocess is carried out regardless of which policy is in use. Be\u00adsides providing a rigorous account of \nthe correctness of our solu\u00adtion, we also discuss practical issues including policy management and prototype \nexperiments. A useful by-product of our work is an operational semantics of a core subset of JavaScript, \nwhere code embedded in (HTML) documents may generate further document pieces (with new code embedded) \nat runtime, yielding a form of self-modifying code. Categories and Subject Descriptors D.3.1 [Programming \nLan\u00adguages]: Formal De.nitions and Theory; F.3.1 [Logics and Mean\u00adings of Programs]: Specifying and Verifying \nand Reasoning about Programs; F.3.2 [Logics and Meanings of Programs]: Semantics of Programming Languages \nOperational Semantics General Terms Languages, Security, Theory Keywords JavaScript, program instrumentation, \nedit automata, web browser 1. Introduction JavaScript [4] is a scripting language designed for enhancing \nweb pages. JavaScript programs are deployed in HTML documents and are interpreted by all major web browsers. \nThey provide useful client-side computation facilities and access to the client system, making web pages \nmore engaging, interactive, and responsive. Unfortunately, the power and ubiquity of JavaScript has also \nbeen exploited to launch various browser-based attacks. On the one hand, there have been criminally serious \nattacks that steal sensitive user information, using, for example, techniques such as cross-site scripting \n(XSS) [11] and phishing [3]. On the other hand, there have been relatively benign annoyances which degrade \nthe web-sur.ng experience, such as popping up advertising windows and altering browser con.gurations. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n07 January 17 19, 2007, Nice, France Copyright c . 2007 ACM 1-59593-575-4/07/0001. . . $5.00. Aiming \nto thwart various attacks launched through JavaScript, we propose to regulate the behavior of untrusted \nJavaScript code using program instrumentation. Incoming script goes through a rewriting process which \nidenti.es and modi.es questionable op\u00aderations. At runtime, the modi.ed script will perform necessary \nsecurity checks and potentially generate user prompts, which are guided by a customizable security policy. \nScript that violates the policy will either be rewritten to respect the policy or stopped at runtime \nbefore the violation occurs unless the user decides to allow it. Compared with existing browser-security \ntools, which typically target speci.c attacks only, our approach enables a uni.ed frame\u00adwork that enforces \nvarious security policies with the same underly\u00ading mechanism. Although program instrumentation has been \nstudied before, its application to JavaScript and browser security raises some interest\u00ading issues. First, \nJavaScript has an interesting execution model where code, embedded in HTML documents, produces further \nHTML docu\u00adments when executed. The produced HTML documents may also have code embedded in them. This \ngives rise to a form of self\u00admodifying code which we refer to as higher-order script (as in script that \ngenerates other script). Higher-order script provides much expressiveness and is commonly used in many \nmajor web\u00adsites. Unfortunately, it can also be exploited to circumvent a na\u00a8ive rewriting mechanism. \nPrevious work [20, 1] on the formal se\u00admantics of JavaScript subsets did not consider higher-order script, \nwhich limits its applicability. This work provides a rigorous charac\u00adterization of higher-order script \nusing an operational semantics of a subset of JavaScript that we call CoreScript. It is therefore a useful \nstep toward understanding some tricky behaviors of JavaScript and preventing sophisticated exploits that \nemploy higher-order script. Next, we present the instrumentation of CoreScript programs as a set of formal \nrewriting rules. The rewriting is performed fully syn\u00adtactically, even in the presence of higher-order \nscript whose content is unknown statically. The runtime behavior of the instrumented code is con.ned \nby a security policy, in the sense that it calls a policy interface for bookkeeping and security checking \nfor relevant operations. We show that our instrumentation is sound by proving that the observable security \nevents in the execution of instrumented code respect the security policy. We encode security policies \nusing edit automata [10]. In partic\u00adular, we make use of a policy interface for achieving a separation \nbetween policy management and the rewriting mechanism, iden\u00adtify what it takes for an edit automaton \nto re.ect a sensible policy, and give a simple de.nition of policy combination that provably satis.es \nsome basic requirements so as to be meaningful for our instrumentation. The presentation and formal reasoning \nin this paper is based on an idealistic language CoreScript, which re.ects the core fea\u00adtures of JavaScript. \nNonetheless, our techniques are applicable to the actual JavaScript language. There are some interesting \nissues when extending CoreScript instrumentation to support the com\u00adplete JavaScript language. We discuss \nhow we have addressed those issues, thus bridging the gap between the CoreScript theory and its embodiment \nas a realistic security tool. We also describe a proto\u00adtype implementation and some deployment experiments, \nwhich are based on the actual HTML and JavaScript. We point out that the goal of this work is to explore \nprovably safe protection against malicious client-side JavaScript code, as\u00adsuming a correct browser implementation. \nThis work is potentially also useful as a protection mechanism for temporarily patching se\u00adcurity holes. \nHowever, no strong guarantee can be made without assuming that the browser interprets JavaScript code \ncorrectly. The remainder of this paper is organized as follows. Section 2 provides background on JavaScript \nand browser security, outlines the dif.culties and our approach, and compares with related work. Section \n3 models CoreScript. Sections 4 and 5 present our policy framework and instrumentation method for regulating \nCoreScript. Section 6 bridges the gap between CoreScript and JavaScript. We describe our implementation \nand experiments in Sections 7 and 8, and conclude in Section 9.  2. Background 2.1 JavaScript Basics \nand Attacks JavaScript is a popular tool for building web pages. JavaScript pro\u00adgrams are essentially \na form of mobile code embedded in HTML documents and executed on client machines. With help of the Document \nObject Model (DOM) [9] and other browser features, JavaScript programs can obtain restricted access to \nthe client sys\u00adtem and improve the functionality and appearance of web pages. As is the case with other \nforms of mobile code, JavaScript programs introduce potential security vulnerabilities and loopholes \nfor malicious parties to exploit. As a simple example, JavaScript is often used to open a new window \non the client. This feature provides a degree of control beyond that offered by plain HTML alone, allowing \nthe new window to have customized size, position, and chromes (e.g., menu, tool bar, status bar). Unfortunately, \nthis feature has been heavily exploited to generate annoying pop-ups of undesirable contents, some of \nwhich are dif.cult to control manually from a web user s point of view (e.g., window-control buttons \nout of screen boundary, instant respawning when a window is closed). More seriously, this feature has \nalso been exploited for launching phishing attacks [3], where key information about the origin of the \nweb page is hidden from users (e.g., a hidden location bar), and false information assembled to trick \nusers into believing malicious contents (e.g., a fake location bar). As another example, JavaScript is \noften used to store and retrieve useful information (e.g., a password to a web service) on the client \nmachine as a cookie. Such information is some\u00adtimes sensitive, therefore the browser restricts access \nto cook\u00adies based on the origin of web pages. For instance, JavaScript code from attacker.com will not \nbe able to read a cookie set by mybank.com. Unfortunately, many web applications exhibit cross-site scripting \n(XSS) [11] vulnerabilities, where a malicious piece of script can be injected into a web page produced \nby a vulnerable server application. The browser interprets the injected script as if it were truly intended \nby the server application as benign code. As a result, the browser s origin-based protection is circum\u00advented, \nand the malicious script may obtain access to the cookie set by the vulnerable application. In general, \nJavaScript has been exploited to launch a wide range of attacks. A simple web search will reveal more \ndetails on this. The situation is potentially worse than for other forms of mobile code, e.g., application \ndownloading, because the user may not realize that loading web pages entails the execution of untrusted \ncode. <html> <head>...</head> <body> <p> <script> var name=parseName(document.cookie); document.write(\"Greetings, \n\" + name + \"!\"); </script> It is <em>great</em> to see you! </p> </body> </html> html  Figure 1. Script \nembedded in an HTML document  2.2 Dif.culties and our Approach We observe that many JavaScript vulnerabilities \nand threats can be addressed using program instrumentation. Properly inserted secu\u00adrity checks and dialogue \nwarnings can be used to identify and re\u00adveal to users potentially malicious behaviors. The extra computa\u00adtion \noverhead is usually acceptable, because JavaScript additions to web pages are typically small in size, \nand performance is not a major concern for most web pages in the context of user interac\u00adtivity. Although \nthe execution of JavaScript programs may follow complex control .ows due to the interaction with users \nas well as with other documents (e.g., in another window or frame), this is less of a concern for program \ninstrumentation, because only very local analysis of the code is required. Nonetheless, there remain \nsome dif.culties when applying ex\u00adisting program instrumentation techniques directly to JavaScript. Execution \nmodel The execution model of JavaScript is quite dif\u00adferent from that of other programming languages. \nA typical pro\u00adgramming language takes input and produces output, possibly with some side effects produced \nduring the execution. In the case of JavaScript, the program itself is embedded inside the output be\u00ading \ncomputed. Figure 1 shows an example of a piece of script embedded in an HTML document. This script uses \na function parseName (de.nition not shown) to obtain a user name from the cookie (document.cookie), and \nthen calls a DOM API document.write to update the script node with some text. Our CoreScript re.ects \nthis execution model. CoreScript pro\u00adgrams are embedded in some tree-structured documents corre\u00adsponding \nto HTML documents. In the operational semantics of CoreScript, script pieces are interpreted and replaced \nwith the pro\u00adduced document pieces. The interpretation stops when no active script is present in the \nentire document. Higher-order script The document pieces produced by JavaScript code at runtime could \ncontain further JavaScript code. For example, Script fragment: var i = 1; document.write(\"<script> i=2; \ndocument.write(i); </scr\" + \"ipt>\" + i); Output: 21 Script fragment: var i = 1; document.write(\"<script> \ni=2; document.write(i); </scr\" + \"ipt>\"); document.write(i); Output: 22 Figure 2. Execution order of \nhigher-order script ... ...  Execution ... ... ... ...  Figure 3. Instrumentation of higher-order \nscript the above DOM API document.write allows not only plain\u00adtext arguments, but also arbitrary HTML-document \narguments that could possibly contain script nodes. These runtime-generated script nodes, when interpreted, \nmay in turn produce more runtime\u00adgenerated script nodes. In fact, in.nite rounds of script generation \ncan be programmed. The behavior of an HTML document with higher-order script is sometimes hard to understand. \nFor instance, the code fragments in Figure 2 appear to be similar, but produce different results. In \nthis example, there are implicit conversions from integers to strings, + is string concatenation, and \nthe closing tag </script> of the embedded script is intentionally separated so that the parser will not \nmisunderstand it as a delimiter for the outer script fragment. The evaluation and execution order of \nhigher-order script is not clearly speci.ed in the language speci.cation [4]. It is therefore useful \nto have a rigorous account as in CoreScript. More importantly, higher-order script complicates instrumenta\u00adtion, \nbecause the instrumentation process cannot effectively iden\u00adtify all security events before the execution \nof the code some events are embedded in string arguments which may not be ap\u00adparent until runtime, such \nas computation results, user input, and documents loaded from a URL. In addition, there are many ways \nto obfuscate such embedded script against analyses and .lters, e.g., by a special encoding of some tag \ncharacters [8]. We handle the instrumentation of higher-order script through an extra level of indirection, \nas demonstrated in Figure 3. During the instrumentation, explicit security events such as load(url) will \nbe directly rewritten with code that performs pertinent secu\u00adrity checks and user warnings (abstracted \nas safe-load(url)). However, further events may be hidden in the generated script doc. Without inspecting \nthe content of doc, which is a hardship stat\u00adically, we feed doc verbatim to some special code instr.This \nspecial code, when executed at runtime, will call back to the in\u00adstrumentation process to perform the \nnecessary inspection on the evaluation result of doc. Such a treatment essentially delays some of the \ninstrumentation tasks until runtime, making it happen on demand. We point out that the special code and \nother components of the instrumentation can be implemented either by changing the JavaScript interpreter \nin the browser or by using carefully written (but regular) JavaScript code which cannot be circumvented. \nPolicies and usability issues Some previous work [5] on program instrumentation for safety and security \nconsiders policies in the form of security automata [17], which stop program execution at runtime when \na violation is detected. In the case of JavaScript pro\u00adgrams, it is sometimes dif.cult to exactly characterize \nviolations. For instance, suppose a web page tries to load a document from a different domain. This may \nbe either an expected redirection or a symptom of an XSS attack. In such a situation, it is usually desir\u00adable \nto present pertinent information to the user for their discretion. Our approach often modi.es script \nto prompt the user about suspicious behaviors, as opposed to stopping the execution right away. When \nappropriate (e.g., for out-of-boundary windows), we also carefully change the semantics of the code (e.g., \nby wrap\u00adping the position arguments). We use edit automata [10], which are more expressive than security \nautomata, to represent such poli\u00adcies. Naturally, our theorems for the correctness of the instrumen\u00adtation \nare formulated with respect to edit automata. Due to the wide use of JavaScript, it is dif.cult to provide \na .xed set of policies for all situations. Thus, the ability to support customized policies is much desirable \nthere should be no change to the rewriting mechanisms when accommodating a new policy. We perform the \nsame kind of rewriting regardless of the speci.cs of the policy; the rewriting produces code that refers \nto the policy through a .xed policy interface. Furthermore, JavaScript and browser security is a mixture \nof many loosely coupled questions. A useful policy is hence typically a combination of multiple component \npolicies. We take a simpli.ed approach to policy combination, which is less expressive than some previous \nwork [2], but effective for our desired protections. The implementation of policy management can be carried \nout in a manner similar to the case of the special code for handling higher\u00adorder script, either by changing \nthe JavaScript interpreter or by using regular JavaScript code. In the latter case, special care must \nbe taken to ensure that the implementation cannot be circumvented. Finally, we note that CoreScript is \nonly a subset of JavaScript. This is necessary for better understanding the formal aspects and correctness \nof the approach. The generic treatment is also useful for potential application to other problem domains. \nExtending the solution to the entire JavaScript language or other implementations of ECMAScript [4] is \nmostly straightforward, but there are a few nontrivial aspects that deserve attention. We will discuss \nextensions and further issues in a later section.  2.3 Related Work Browser security solutions JavaScript, \nDOM, and web browsers provide some basic security protections. Amongst the commonly used are sandboxing, \nsame-origin policy, and signed scripting. Ad\u00additional security extensions and coding styles are sometimes \nap\u00adplied, such as the XPCNativeWrapper [12] that con.nes the access to certain methods and properties \nof untrusted objects. These only provide limited (coarse-grained) protections. There remain many opportunities \nfor attacks, even if these protections are perfectly im\u00adplemented. Representative example attacks that \nare not prevented by these include XSS, phishing, and resource abuse. There have been also many separate \nbrowser security tools de\u00adveloped, such as pop-up blockers and SpoofGuard [3]. These sep\u00adarate solutions \nonly provide protection against speci.c categories of attacks. In practice, it is sometimes dif.cult \nto deploy multiple solutions all together. In addition, there are many attacks that are outside of the \nrange of protection of existing tools. Nonetheless, ideas and heuristics used in these tools are likely \nto be helpful for constructing useful security policies for instrumentation. The above protection mechanisms \nare all deployed on the client side. Server-side protection has also been studied, especially in the \ncontext of command injection attacks [11, 18, 24]. The goal is to help well-intended programmers build \nweb applications that are free of certain vulnerabilities, rather than to protect clients from malicious \ncode. Formal studies on JavaScript Existing work on formalizing JavaScript [20, 1] has focused on helping \nprogrammers write good code, as opposed to thwarting malicious exploits. On the technical front, the \ntreatment of JavaScript programs used the conventional model, rather than as separate fragments embedded \nin HTML doc\u00aduments. Previous work also does not address the challenges posed by higher-order script. \nProgram instrumentation Program instrumentation has been much studied [22, 6, 5, 23, 15]. As detailed \nin the previous sec\u00adtion, we extend program instrumentation in several ways to handle JavaScript, higher-order \nscript, and some pragmatic policy issues. In addition, we provide end-to-end proofs on the correctness \nof our method: (1) instrumented programs will satisfy the security policy; (2) behavior of programs which \nsatisfy the security policy will not be changed by the instrumentation. In constract, previous study \n[17, 10] on automata-based security policies did not address the integration of automata with programming \nlanguages.  3. CoreScript We now model our subset of JavaScript CoreScript. In particu\u00adlar, we give \nan operational semantics for CoreScript, focusing on higher-order script and its embedding in documents. \nObjects are omitted from this model, because they are orthogonal and have been carefully studied [20, \n1]. Adding objects presents no addi\u00adtional dif.culties for instrumentation. 3.1 Syntax The syntax of \nCoreScript is given in Figure 4. In this .gure, the symbols [] are used as meta-parentheses, rather than \nas part of the CoreScript syntax. A complete world W is a 4-tuple (S,.,B,C). The .rst ele\u00adment S, a document \nbank, is a mapping from URLs lto documents D; this corresponds to the Internet. The second element .,a \nvari\u00adable bank, maps global variables xto documents D, and functions f to script programs P with formal \nparameters .x. The third ele\u00adment B, a browser, consists of possibly multiple windows; each window has \na handle hfor ease of reference, a document D as the content, and a domain name dmarking the origin of \nthe document. The fourth element C, a cookie bank, maps domain names to cook\u00adies in the form of documents \n(each domain has its own cookie). We use strings to model domain names d,paths p, and handles h.A URL \nl is a pair of a domain name d and a path p. We assume an implicit conversion between URLs and strings. \nDocuments D correspond to HTML documents. In JavaScript, all kinds of documents are embedded as strings \nusing HTML tags such as <script> and <em>. They are treated uniformly as strings by all program constructs, \nbut are parsed differently than plain strings when interpreted. Documents in CoreScript re.ect this, \nexcept that we make different kinds of documents syntactically different, rendering the parsing implicit. \nA document is in either one of three syntactic forms: a plain string (string), a piece of (World) W ::= \n(S, .,B,C) (Document Bank) S ::= {[l = D] * } (Variable Bank) . ::= {[x = D] * , [f =(.x)P ] * } (Browser) \nB ::= {[h = D . d] * } (Cookie Bank) C ::= {[d = D] * } (URL) l ::= d.p (Domain) d ::= string (Path) \np ::= string (Handle) h ::= string (Document) D ::= string | js P | F .D (V alueDocument) Dv ::= string \n| F .Dv (Format) F ::= jux | p | em | b | i | h1 | h2 | ... (Script) P ::= skip | x= E | P ; P | if E \nthen P else P | while E do P | f( .E) | act(A) | write(E) (Expression) E ::= x | D | op( .E) (Action) \nA ::= . | newWin(x, E) | closeWin(E) | loadURL(E) | readCki(x) | writeCki(E) | secOp( .E) (Value Action) \nAv ::= . | newWin( ,D) | closeWin(D) | loadURL(D) | readCki( ) | writeCki(D) | secOp( .D)  Figure 4. \nCoreScript syntax script (js P ), or a formatted document made up of a vector of sub\u00addocuments (F D.). \nValue documents Dv are documents that contain no script. We list a few common HTML format tags in the \nsyntax as F , and introduce a new tag jux for the juxtaposition of multiple documents (this simpli.es \nthe presentation of the semantics). The script programs P are mostly made up of common con\u00adtrol constructs, \nincluding no-op, assignment, sequencing, condi\u00adtional, while-loop, and function call. In addition, actions \nact(A) are security-relevant operations that our instrumentation identi.es and rewrites. Furthermore, \nhigher-order script is supported using write(E),where E evaluates at runtime to a document that may contain \nfurther script. Expressions E include variables x, documents D, and other op\u00aderations op(E.).Here we \nuse op to abstract over all operations that are free of side-effects, such as string concatenation and \ncompari\u00adson. We do not explicitly model booleans, instead simulating them with special documents (strings) \nfalse and true. A few actions A are modeled explicitly for demonstration pur\u00adposes. newWin(x, E) creates \na new window with E as the con\u00adtent document; a fresh handle is assigned to the new window and stored \nin x. closeWin(E) closes the window which has handle E. loadURL(E) directs the current window to load \na new docu\u00adment from the URL E. readCki(x) reads the cookie of the current domain into x. writeCki(E) \nwrites E into the cookie of the cur\u00adrent domain. All other potential actions are abstracted as a generic \nsecOp(E.). Value actions Av are actions with document arguments only. Some arguments to actions are variables \nfor storing results such as window handles or cookie contents. They are replaced with in value actions, \nbecause they do not affect the instrumentation.  3.2 Operational Semantics We present the semantics \nof expressions in a big-step style in Fig\u00adure 5. At runtime, expressions evaluate to documents, but not \nnec\u00ad . . E . D . . x . .(x) . . D . D . . .E . .D . . op( .E) . op( .D) (1) (2) (3) . . A . Av . . . \n. . . . E . D . . newWin(x, E) . newWin( ,D) . . E . D . . closeWin(E) . closeWin(D) . . E . D . . loadURL(E) \n. loadURL(D) . . readCki(x) . readCki( ) . . E . D . . writeCki(E) . writeCki(D) . . .E . .D . . secOp( \n.E) . secOp( .D) (4) (5) (6) (7) (8) (9) (10) Figure 5. Expression and action evaluation in CoreScript \nessarily value documents. As Rule (2) shows, D is not inspected for embedded script during expression \nevaluation. In Rule (3), we use op to refer to the corresponding meta-level computation of op. Actions \nare evaluated to value actions as shown in the same .gure. This process only computes the arguments of \nthe actions, but does not actually perform the actions. Take Rule (9) as an example. The argument E is \nevaluated to D, but the cookie bank is not yet updated. It is also worth noting that, as indicated by \nthe same rule, a cookie may be written using any document D, including a document with script embedded. \nTherefore, a program may store embedded script in a cookie for later use. Our instrumentation will be \nsound under this behavior. We present the execution of a world in a small-step style in Fig\u00adure 6. This \nis more intuitive when considering the security actions performed along with the execution, as well as \ntheir instrumenta\u00adtion. Rules (11) and (12) de.ne a multi-step relation. They refer to a single step \nrelation as de.ned by Rule (13). This single step relation is non-deterministic, re.ecting that any window \ncould advance its content document at any time. Finally, Rule (14) uniformly advances the document in \nthe window of handle h, with help of some macros de.ned in Figure 7. The macro focus identi.es the focus \nof the execution. It tra\u00adverses a document and locates the left-most script component. The macro stepDoc \ncomputes an appropriate document for the next step, assuming that the focus of the argument document \nwill be executed. The focus and stepDoc cases on value documents (e.g., strings) are unde.ned. This indicates \nthat nothing in value docu\u00adments can be executed. If nothing can be executed in the entire document, \nthen the execution terminates. If D = then focus(D)= and stepDoc(D, .)= js P where P .{skip,x= E, act(A)} \nP e (empty string) js write(E) write(E) D where . .E .D js P1; P2 focus(js P1) jux D (js P2) where D \n= stepDoc(js P1,.) js if E then P1 else P2 if E then P1 else P2 js P1 if . .E .true js P2 if . .E .false \njs while E do P while E do P js if E then (P; while E do P) else skip js f( .E) f( .E) js P[ .D/.x] where \n. . .E . .D and .(f)=(.x)P F .DvD. .D where D. is not a value document focus(D.) F .Dv D.. .D where D.. \n= stepDoc(D.,.) focus(D)= P stepDoc(D, .)= D. If P = then step(P, h, (S, .,B,C)) = act(.) (S,., adv(B,h, \n.), C) act(newWin(x,E)) (S,.{x = h.}, B.{h. = D .d} ,C) where . .E .d.p B. = adv(B,h, .) S(d.p)= D h. \nis fresh act(closeWin(E)) (S,., B. -{h.}, C) where . .E .h. B. = adv(B,h, .) act(loadURL(E)) (S,., B{h \n= D .d}, C) where . .E .d.p S(d.p)= D act(readCki(x)) (S,.{x = C(d)},adv(B,h, .), C) where B(h)= D .d \nact(writeCki(E)) (S,., adv(B,h, .), C{d = D }) where . .E .D B(h)= D .d act(secOp( .E)) ... x= E (S,.{x \n= D}, adv(B,h, .), C) where . .E .D other P (S,., adv(B,h, .), C) step(P, h, W)= W. where adv(B,h, \n.)= B{h = stepDoc(D, .) .d} if B(h)= D .d Figure 7. Helper functions of CoreScript semantics W . * W. \n: Av (11) W . * W : . W . W. : Av W. . * W.. A.v : (12) W . * W.. : AvA.v W . W. : Av i={1...n} W =(S, \n.,B,C) B = {hi = Di .di}Pick any j : hj .W . W. : Av (13) W . W. : Av h .W . W. : Av B(h)= D .d focus(D)= \nP step(P, h, (S,.,B,C)) = W j Av 1 if P= act(A) and . .A .A1 v Av = . if P=.act(A) (14) h .(S,.,B,C) \n. W : Av Figure 6. World execution in CoreScript The macro step computes the step transition on worlds. \nSup\u00adpose we wish to make a step transition on world W by advancing the document in window h, and suppose \nthe focus computation of the document in window h is P. The result world after the step transition would \nbe step(P, h, W). When de.ning step, the helper adv(B,h, .) makes use of stepDoc to advance the document \nin window h. It is worth noting that the semantics dictates the evaluation order for higher-order script, \nthus the two examples in Figure 2 are naturally explained. Take write(op(E.)); P as an example. CoreScript \nevaluates all Ei before executing the script embedded in any of them, explaining the behavior of the \n.rst script fragment in Figure 2. P is executed after the script generated by write(op(E.)) has .nished \nexecution, explaining the second.  4. Security Policies The simple set of actions in CoreScript can \nalready be exploited to launch browser-based attacks. For instance, one can open an unlim\u00adited number \nof windows (think pop-ups) and send sensitive cookie information to untrusted parties (think XSS). Various \nsecurity poli\u00adcies can be designed to counter these attacks. In our solution, policy management and code \nrewriting are two separate modules. Policies can be designed without knowledge of the rewriting process. \nA policy designer must ensure that the poli\u00adcies adequately re.ect the desired protections. On the enforcement \nside, the rewriting process accesses the policy through a policy in\u00adterface. The same rewriting mechanism \nis used for all policies. This section describes the policy framework and presents the policy interface \nthat the code rewriting of the next section uses. ..A. q .{accept state} (15) (Q,q, d).. d(q, A)=(q \n.,A)(Q, q.,d).A. d (q,A)=(q ,A ) d (q,A)=(q ,A) d (q,A)=(q,A) (16) (Q,q, d).AA. Figure 9. Edit automata \nas diagrams (17) ... .. ..A..A.. d(q, A)=(q .,A.)(Q,q.,d).A..A.. (18) (Q, q, d).AA..A.A.. Figure 8. Policy \nsatisfaction and action editing 4.1 Policy Representation Policies .are expressed as edit automata [10]. \nAn edit automaton is a triple (Q,q0,d),where Q is a .nite or countably in.nite set of states, q0 . Q \nis the initial state (or current state), and d is the complete transition function that has the form \nd : Q *A . Q *A (the symbol A is reused here to denote the set of actions in CoreScript). Note that d \nmay specify insertion, replacement, and suppression of actions, where suppression is handled by discarding \nthe input action and producing an output action of .. We require d(q, .)=(q, .)so that policies are deterministic. \nFigure 8 de.nes the meaning of a policy in terms of policy satisfaction (whether an action sequence is \nallowed) and action editing (how to rewrite an action sequence). Rules (15) and (16) de.ne the satisfaction \nof a policy . on an action sequence A.. Intuitively, ..A.if and only if when feeding A.into the automaton \nof ., the automaton performs no modi.cation to the actions, and stops at the end of the action sequence \nin a state that signals acceptance. In the remainder of this paper, we assume that every state is an \naccept state for simplicity, although it is trivial to relax this assumption. Rules (17) and (18) de.ne \nhow a policy .transforms an action sequence A.into another action sequence A... Intuitively, ..A.. A.. \nif and only if when feeding A.into the automaton of .,the automaton produces A... Not all edit automata \nrepresent sensible policies. For instance, an edit automaton may convert action A1 into A2 and A2 into \nA1.It is unclear how an instrumentation mechanism should act under this policy, because even the recommended \nreplacement action does not satisfy the policy. Therefore, it is useful to de.ne the consistency of policies. \nDe.nition 1 (Policy Consistency) A policy .=(Q, q0,d)is consistent if and only if d(q, A)=(q .,A.)implies \nd(q, A.)=(q .,A.)for any q, q . , A and A. . Theorem 1 (Sound Advice) Suppose .is consistent. If ..A..A..,then \n..A... An inconsistent policy re.ects an error in policy design. Syntac\u00adtically, it is easy to convert \nan inconsistent policy into a consistent one: when the policy suggests a replacement action A. for an \ninput action A under state q, we update the policy to also accept action A. under state q. More accurately, \nif d(q, A)=(q .,A.),then we make sure d(q, A.)=(q .,A.). However, semantically, it is up to the pol\u00adicy \ndesigner to decide whether the updated policy is the intended one, especially in the case of con.icting \nupdates. For instance, in close close Figure 10. Automaton for a pop-up policy the above example, the \ninconsistent policy may have already de\u00ad.ned d(q, A.)=(q ..,A..). We use consistent policies to guide \nour instrumentation, and policy consistency will serve as an assumption of our correctness theorems. \nInternally, a policy module maintains all states relevant to the edit automaton of the policy, including \na current state and a complete transition function. Externally, the same policy module exposes the following \ninterface to the rewriting process: Action review: check(A). This action review interface takes an input \naction as argument, advances the internal state of the automaton, and carries out a replacement action \naccording to the transition function. 4.2 Policy Examples The above policy framework is effective in \nidentifying realistic JavaScript attacks and providing useful feedback to the user. We now demonstrate \nthis with examples. For ease of reading, we present edit automata as diagrams (Fig\u00adure 9). To build a \ndiagram from an edit automaton, we .rst create a node for every element of the state set. The node representing \nthe starting state is marked with a special edge into the node. If the state transition function maps \n(q, A)into (q .,A.), we add an edge from the node of q to the node of q ., and mark the edge with A/A..For \nconciseness, we use A to serve as a shorthand of A/A.Ifthe state transition is trivial (performing no \nchange to an input pair of state and action), we may omit that edge. Conversely, if a diagram does not \nexplicitly specify an edge from state q with action A,there is an implicit A/A edge from the node of \nq to itself. Figure 10 presents a policy for restricting the number of popup windows. The start state \nis pop0. State transition on (pop0,close) is trivial (implicit). State transitions from the states with \nactions other than open and close are also trivial (implicit). This policy essentially ignores new window \nopening actions when there are already two pop-ups. Figure 11 presents a policy for restricting the (potential) \ntrans\u00admission of cookie information. The start state is send-to-any.In state send-to-origin, network \nrequests are handled with a safe ver\u00adsion of the loading action called safe-loadURL. In this policy, \nstate transitions on (send-to-any, loadURL(l)), (send-to-any, safe\u00adloadURL), (send-to-origin, readCookie), \n(send-to-origin, safe\u00adloadURL) are trivial (implicit). State transitions from the states with actions \nother than reading, loading, and safe loading are also triv\u00adial (implicit). Essentially, this policy \nputs no restriction on loading before the cookie is read, but permits only safe loading afterwards. \nloadURL(l)/safe-loadURL(l)  readCookie  Figure 11. Automaton for a cookie policy The implementation \nof the safe loading safe-loadURL performs necessary checks on the domain of the URL and asks the user \nwhether to proceed with the loading if the domain of the URL does not match the origin of the document. \nWe point out that, if desirable, a replacement action such as safe-loadURL may obtain information from \nthe current state of the automaton and perform specialized security checks and user prompts. Its implementation \nis part of the policy module, and therefore does not affect the rewrit\u00ading process. For now, it suf.ces \nto understand the implementation of safe actions as trusted and uncircumventable safe actions are implemented \ncorrectly, and malicious script cannot overwrite their implementation.  4.3 Policy Combination In practice, \nthere are many different kinds of attacks. Naturally, there can be many different policies, each protecting \nagainst one kind of attack. Therefore, it is useful to combine multiple (without loss of generality, \ntwo) policies into one, which in turn guides the rewriting process. For a policy combination (.1 . .2 \n=.) to be meaningful, it is sensible to require the following two conditions. 1. Safe combination: Suppose \n.1 and .2 are consistent. For all .2 . .1 . .2 . . A,.1 . .Aif and only if .Aand .A. 2. Consistent combination:If \n.1 and .2 are consistent, then .1 . .2 is consistent.  We give a de.nition of policy combination which \nrespects these requirements. Given two edit automata .1 =({pi|i =0...n},p0,d1) and .2 =({qj |j =0...m},q0,d2),we \nde.ne: .1 . .2 =({piqj |i =0...n,j =0...m},p0q0,d) 8 > (plqk,A.) if d1(pi,A)=(pl,A.) > > < and d2(qj,A.)=(qk,A.) \nwhere d(piqj ,A)= (plqk,A.) else if d2(qj ,A)=(qk,A.) > > > and d1(pi,A.)=(pl,A.) : (piqj ,.) otherwise \nIntuitively, the combined policy simulates both component poli\u00adcies at the same time. When the .rst policy \nsuggests an action that is agreed by the second policy, the combined policy takes that ac\u00adtion. If not, \nit tries to see if the suggestion of the second policy is agreed by the .rst policy. In the worst case \nthat neither of the above two holds, the combined policy suppresses the action. There is a combinatorial \ngrowth in the number of states after the combina\u00adtion. This does not pose a problem for an implementation, \nbecause a policy module may maintain separate state variables and transi\u00adtion functions for the component \npolicies, yielding a linear growth in the policy representation. Based on the same reason, the above \nde.nition extends naturally to support countably .nite-state com\u00adponent policies. It is easy to check \nthat this de.nition of combination satis.es the above safety and consistency requirements. Nonetheless, \nwe point out that there exist other sensible de.nitions of combination that also satisfy the same requirements. \nFor example, the above de.\u00adnition prefers the .rst policy over the seond. A similar de.nition that prefers \nthe second is also sensible. Furthermore, a more sophis\u00adticated combination may attempt to resolve con.icts \nby recursively feeding suggested actions into the automata, whereas the above simply gives up after the \n.rst try. Note that the requirement of safe combination only talks about acceptable action sequences, \nnot about replacement actions. In general, related study on policy combination [16, 2] may provide some \nalternatives. Based on our experience, the above de.nition of combination seems to work well in practice. \nMany policies in our experiments, such as the two examples shown earlier, are orthogonal to each other \nin the sense that they deal with separate sets of actions. Their combination using the above de.nition \nis straightforward as expected. Our unorthogonal policies do not suggest contradicting replacement actions. \nWe suspect that if two policies are con.icting (i.e., the otherwise case in the above de.nition), it \nis likely a design error, and divine intervention from the policy designer would be best.  5. CoreScript \nInstrumentation Given the policy module and its interface in the previous sec\u00adtion, the instrumentation \nof CoreScript becomes a straightforward syntax-directed rewriting process. We now present the rewriting \nand its correctness. The task of the rewriting process is to traverse the document tree and redirect \nall actions through the policy module. Whenever an action act(A)is identi.ed, we redirect it to the action \ninter\u00adface check(A), trusting that the policy module will carry out an appropriate replacement action \nat runtime. For higher-order script write(E), we feed the document argument E verbatim to a spe\u00adcial \ninterface instr(E), whose implementation will call back to the rewriting process at runtime after E is \nevaluated. In this section, we organize the above two interfaces as two new CoreScript instructions for \nthe rewriting process to use. In particular, we extend the syntax of CoreScript as follows. (Script) \nP ::=... | instr(E)| check(A) The details of the rewriting are given in Figure 12. Its simplicity is \nobvious no knowledge is required on the meaning or the im\u00adplementation of the two new instructions. The \nnontrivial tasks are performed by Rules (19) and (20), where the new instructions are used to replace \nruntime code generation and actions. All other rules simply propagate the rewriting results. We give \nthe rewriting cases for the two new instructions in Rule (24), which allows the rewrit\u00ading to work on \ncode that calls the two interfaces. We also de.ne the rewriting on world W and its four components. In \nan imple\u00admentation, some components (e.g., the document bank S) will be instrumented on demand (e.g., \nwhen loaded). We give the semantics of the two new instructions so as to rea\u00adson about the correctness \nof the instrumentation. For instr(E), the purpose is to mark script generation and delay the instrumenta\u00adtion \nuntil runtime. Therefore, its operational semantics should eval\u00aduate the argument expression and feed \nit through the rewriting pro\u00adcess. The following de.nitions capture exactly that. focus(js instr(E))=instr(E) \nstepDoc(js instr(E),.)=.(D) where .. E . D (33) step(instr(E),h,(S,.,B,C))=(S,.,adv(B,h,.),C) Recall \nthat advis de.ned in Figure 7. The operational semantics rules for other language constructs remain the \nsame under the addition of instr.The focus and step function cases de.ned above .t in well with Rule \n(14), which makes a step on a document given a speci.c window handle. .(P)=P. (19) .(write(E))=instr(E) \n(20) .(act(A))=check(A) (21) .(P1;P2)=.(P1);.(P2) (22) .(if E then P1 else P2)=if E then .(P1)else .(P2) \n(23) .(while E do P)=while E do .(P) P .{skip,x=E,f(E.),instr(E),check(A)} (24) .(P)=P .(D)=D. (25) \n.(string)=string (26) .(js P)=js .(P) .(D.)=D.. (27) .(F D.)=F D.. .(S)=S(28) .({(l =D)*})={(l =.(D))*} \n.(.)=.. ** .({[x =D],[f =(.x)P]*})={[x =.(D)],[f =(.x).(P)]*} (29) .(B)=B. (30) .({(h =D .d)*})={(h =.(D).d)*} \n(31) .(C)=C. .({[d =D]*})={[d =.(D)]*} .(W)=W. (32) .((S,.,B,C))=(.(S),.(.),.(B),.(C)) Figure 12. Syntax-directed \nrewriting An inspection of Rule (33) will show that the rewriting process . is called at run time after \nevaluting E to D. The execution of . always terminates, producing an instrumented document. In this instrumented \ndocument, there is potentially further hidden script marked by further instr. Such hidden script will \nbe rewritten later when it is generated. We de.ne the semantics of check(A)in a similar fashion using \nthe following de.nitions. focus(js check(A))=check(A) stepDoc(js check(A),.)=. (34) step(check(A),h,(S,.,B,C))=unde.ned \n The focus case for check(A)is trivially check(A)itself. The execution of check(A)will consume check(A)entirely \nand leave no further document piece for the next step, hence the stepDoc case. The step case is unde.ned, \nbecause we will never refer to this case in the updated operational semantics. With the addition of check, \nthe program execution is connected to the policy module. Therefore, in the updated operational seman\u00adtics, \nwe need to take into account the internal state of the pol\u00adicy module (the state of the edit automaton). \nWe extend the pre\u00advious reduction relations of CoreScript in Figure 13, where the new formations of the \nreduction relations explicitly specify the au\u00ad v .d (W,q). * (W. ,q .):A. .d (W,q). * (W,q):. (35) v \n.). * (W.. .d (W,q). (W. ,q .):A.d (W. ,q ,q ..):A. (W.. ..v .d (W,q). * ,q ):AA.v (36) .d (W,q). (W. \n,q .):Av =Di . di}i={1...n} W =(S,.,B,C) B ={hi .v (37) Pick any j : hj .d (W,q). (W. ,q .):Av .d (W,q). \n(W. ,q ):A h .d (W,q). (W. ,q .):Av B(h)=D . d focus(D)=.check(A) h. (S,.,B,C). W :Av v (38) h .d ((S,.,B,C),q). \n(W,q):A B(h)=D . d focus(D)=check(A) vv .v .. A. A1 d(q,A1 )=(q ,A) step(act(Av),h,(S,.,B,C))=W v h .d \n((S,.,B,C),q). (W,q.):A(39) Figure 13. World execution in CoreScript with policy module tomaton transition \nfunction (d) and the automaton states (q and q .). Similar to the previous semantics, the multi-step \nrelation de\u00ad.ned by Rules (35) and (36) is a re.exive and trasitive closure of a non-deterministic step \nrelation de.ned by Rule (37). This non\u00addeterministic step relation is de.ned with help of a determinstic \nstep relation, which we call document advance. Document advance is de.ned by Rules (38) and (39). When \nthe focus of the document is not a call to check, the old document advance relation (de.ned in Rule (14)) \nis used, and the automaton state remains unchanged. When the focus is a call to check,the automaton state \nis updated and the replacement action is produced according to the transition function, and the world \ncomponents are updated using the step case of act(Av)because the replacement action Av is carried out \ninstead of the original action A. We have now completed the updated semantics. Essentially, a policy \ninstance is executed alongside the program execution the current state of the policy instance is updated \nin correspondence with the actions of the program. 5.1 Correctness Theorems We present the correctness \nof the instrumentation as two theorems soundness and transparency [10]. Soundness states that instru\u00admented \ncode will respect the policy. Transparency states that the instrumentation will not affect the behavior \nof code that already re\u00adspects the policy. The intuition behind these correctness theorems is straightforward, \nsince our instrumentation feeds all actions through the policy module for suggestions. Soundness holds \nbecause the suggested actions always satisfy the policy due to policy consis\u00adtency. Transparency holds \nbecause the suggested actions would be identical to the input actions if the input actions already satisfy \nthe policy. In what follows, we establish these two theorems with a sequence of lemmas. First, we introduce \na notion of orthodoxy. De.nition 2 (Orthodoxy) W (or S, ., B, C, D, P) is orthodox if it has no occurrence \nof act(A)or write(E). It is easy to see that our instrumentation produces orthodox results, as in the \nfollowing lemma. Lemma 1 (Instrumentation Orthodoxy) .(P), .(D), .(C), .(B), .(.), .(S),and .(W)are orthodox. \nProof sketch: By simultaneous induction on the structures of P and D. By case analysis on the structures \nof C, B, ., S,and W. . We show that orthodoxy is preserved by the step relation, as follows. Lemma 2 \n(Orthodoxy Preservation) If W is orthodox and W.. .d (W,q). (,q ):Av,then W. is orthodox. Proof sketch: \nBy de.nition of the step relation (.), with induction on the structure of documents. The case of executing \nwrite(E) is no possible because W is orthodox. In the case of executing instr(E), the operational semantics \nproduces an instrumented document to replace the focus node. Orthodoxy thus follows from Lemma 1. In \nall other cases, the operational semantics may obtain document pieces from other program components, \nwhich are ortho\u00addox by assumption. . The execution of an orthodox world always respects the policy, as \narticulated below. Lemma 3 (Policy Satisfaction) Suppose .=(Q,q,d)is W.. consistent. If W is orthodox \nand .d (W,q). (,q ):Av,then d(q,Av)=(q .,Av). Proof sketch: By case analysis on the step relation (.). \nIn the case of executing check(A), by inversion on Rule (39), d(q,A1 v)= .vv.v (q ,A). The expected result \nd(q,A)=(q ,A)follows directly from the de.nition of policy consistency. In all other cases, by in\u00adversion \non Rule (38), q =q .. By further inversion on Rule (14), we get Av =.(the case of executing act(A)is \nnot possible because W is orthodox). d(q,.)=(q,.)because of the deterministic re\u00adquirement on policies. \n. The soundness theorem follows naturally from these lemmas. Theorem 2 (Soundness) Suppose .=(Q,q,d)is \nconsistent. If W...v W is orthodox and .d (W,q). * (,q ):A.v,then .. A. Proof sketch: By structural induction \non the multi-step relation (. *). The base case of zero step and empty output action is trivial. In the \ninductive case, there exists W1, q1 and A1 v such that .d (W,q) . (W1,q1): A1v , .d (W1,q1) . * (W. ,q \n.): A.v.,and .vv .vv A= A1 Av.. By Lemma 3, d(q,A)=(q1,A). (Q,q1,d)is consistent by assumption and de.nition \nof policy consistency. W1 is orthodox by Lemma 2. By induction hypothesis, (Q,q1,d) . A.v.. By de.nition \nof policy satisfaction, .. A.v. . From the instrumentation s perspective, it is desirable to estab\u00adlish \nthat .(W)is safe given any W. This follows as a corollary of Theorem 2, because .(W)is orthodox by Lemma \n1. To formulate the transparency theorem, we use the multi-step relation de.ned in Section 3 before the \ninstrumentation extension. This re.ects the intuition that incoming script should be a sensible CoreScript \n(or JavaScript) program without knowledge about the policy module. We .rst introduce a lock step lemma \nto relate the single-step execution of instrumented code with the single-step execution of the original \ncode in the case where the original code satis.es the policy. Lemma 4 (Lock step) If W . W. :Av and \nv d(q,Av)=(q .,Av),then .d (.(W),q). (.(W.),q .):A. Proof sketch: By de.nition of the step relation (.), \nwith induction on the structure of documents. The focus of .(W)refers to a tree node in correspondence \nwith the focus of W. In the case that write(E)is the focus of W, instr(E)will be the focus of .(W). The \noperational semantics of write and instr carry out a similar evaluation on the argument E, except that \ninstr(E)uses an instrumented variable environment and returns an instrumented result document. The output \naction Av is . in both cases. We can construct the derivation of .d (.(W),q) . (.(W.),q .):Av by: (i) \nfollowing Rule (37) and choosing the same handle h as used for obtaining W . W. : Av; (ii) following \nRule (38), which refers back to the old single-step relation h . .(W) . .(W.): Av; then (iii) following \nthe derivation of v h . W . W. : Aused for obtaining W . W. : Av, with various components replaced with \nthe instrumented version. In the case that act(A) is the focus of W, check(A) will be the focus of .(W). \nact and check both produce an empty string to replace the focus tree node. The operational semantics \nof act(A)will evaluate Ato Av (Rule (14)). The operational seman\u00adtics of check(A)will evaluate Ato Av \nand feed Av to the policy (Rule (39)). By assumption, d(q,Av)=(q .,Av). Therefore, act and check will \nproduce the same output action in this case. The operational semantics of check(A)will further apply \nthe macro step to act(Av)to update the world components. Therefore, fur\u00adther derivations of the two reductions \nfollow the same structure. In all other cases, W and .(W) will be executing the same instructions. The \nderivation of the instrumented reduction follows that of the original reduction. . The transparency theorem \nfollows naturally from the lock step lemma. Theorem 3 (Transparency) If W . * W. :A.v and (Q,q,d). A.v,then \n.d (.(W),q). * (.(W.),q .):A.v. Proof sketch: By structural induction on the multi-step relation (. *). \nThe base case of zero step and emtpy output action is trivial. In the inductive case, there exists W1 \nand A1 v such that W . v . * W. ..vv . W1 :A1, W1 :Av.,and A=A1Av.. By assumption (Q,q,d) . A.v and de.nition \nof policy satisfaction, there exists vv . q1 such that d(q,A1 )=(q1,A1 ) and (Q,q1,d) . Av..By v Lemma \n4, .d (.(W),q) . (.(W.),q1): A1 . By induction W.. hypothesis, .d (.(W1),q1). * (.(),q ):A.v.. By Rule \n(36), W.v .d (.(W),q). * (.(),q .):A.. . In the above transparency theorem, the original world W does \nnot refer to the instrumentation and policy interfaces, re.ecting that incoming script is written in \nregular JavaScript. We can also formulate a variant of the transparency theorem to allow incoming script \nthat refers to the instrumentation and policy interfaces, as follows. Theorem 4 (Extended Transparency) \nIf W... .d (W,q). * (,q ):A.v and (Q,q,d). Av,then W..v .d (.(W),q). * (.(),q ):A.. This theorem allows \nW to be unorthodox W may contain a mixture of write, act, instr and check. The proof of this theorem \nrequires a similarly extended lock-step lemma. The proof extension is straightforward, because on the \ntwo new cases allowed by this theorem (instr and check), the rewriting is essentially an identity function. \n  6. Discussions We have modeled CoreScript as a core language for client-side scripting. Its distinguishing \nfeatures include the embedding of script in documents, the generation of new script at runtime, and distinguishing \nsecurity-relevant actions. CoreScript abstracts away some speci.c details of JavaScript so that the ideas \nare applica\u00adble to other browser-based scripting languages. Nonetheless, any practical realization of \nthe approach will have to tackle some more language-speci.c details. First, CoreScript supports the \nembedding of code in a docu\u00adment tree using js nodes. Such a treatment is adapted from the use of <script> \ntags in JavaScript (Figure 1 provided an ex\u00adample). Beyond the <script> tags, there are many other ways \nfor embedding script in an HTML document. Some common places where script could occur include images \n(e.g., <IMG SRC=...>), frames (e.g., <IFRAME SRC=...>), XML (e.g., <XML SRC=...>, tables (e.g., <TABLE \nBACKGROUND=...>), and body back\u00adground (e.g., <BODY BACKGROUND=...>. Furthermore, script can also be \nembedded in a large number of event handlers (e.g., onActivate(), onClick(), onLoad(), onUnload(), ...). \nA realization of our approach must also identify and rewrite such embedded script. Second, CoreScript \nmakes use of write(E) to generate script at runtime. This is a uni.ed view on several related functions, \ninclud\u00ading eval in the JavaScript core language and window.execScript, document.write, document.writeln \nin the DOM. These functions all take string arguments. eval evaluates a string as a JavaScript statement \nor expression and returns the result. In con\u00adtrast, window.execScript executes one or more script state\u00adments \nbut returns no values. CoreScript s treatment on higher-order script is expressive enough for these two. \nHowever, document.write and document.writeln are more challenging. These two functions send strings as \ndocument fragments to be displayed in their windows, where the document fragments could have script embedded. \nInterestingly, these docu\u00adment fragments do not have to be complete document tree nodes. Instead, they \ncan be pieced together with other strings to form a complete node, as demonstrated in the following examples. \n<script> document.write(\"<scr\"); document.write(\"ipt> malic\"); vari = 1; document.write(\"ious code; </sc\"); \ndocument.write(\"ript>\"); </script> <script> document.write(\"<scr\");</script>ipt> malicious code </script> \n Each of the above write would appear to produce harmless text to a na\u00a8ive .lter. To avoid such loopholes \nwhen applying Core-Script instrumentation, one possibility is to piece together gener\u00adated document fragments \nbefore feeding them into the rewriting process of the next stage. This must be done with care to avoid \nchanging the semantics of the code (recall Figure 2). Observing that the expressiveness of producing \nnew script as broken-up fragments does not seem to be useful in well-intended programs, a better so\u00adlution \nmight be to simply disrupt the generation of ungrammatical script pieces. As an example, Su and Wassermann \n[18] use meta\u00adcharacters to delimit user input syntactically and prevent command injection attacks. A \nsimilar technique can be applied here to delimit generated document pieces implicitly and prevent the \nabove kind of attacks (the generated document pieces <scr and ipt> will  D' instr(E) .(D') .(D') JavaScript \nDv D .(D) Interpreter (Browser) check(A) A' Policy Module (. ) Figure 14. Implementation architecture \nno longer be pieced together to form a script tag, if they are gener\u00adated in two separate document.write \nstatements). CoreScript does not provide a means to modify the content of a document in arbitrary ways, \nbecause a write(E) node gener\u00adates a new node to be positioned at the exact same place in the document \ntree. The DOM provides other means for modifying a document. For instance, a document could be modi.ed \nthrough the innerHTML, innerText, outerHTML, outerText,and nodeValue properties of any element. These \nare not covered in the CoreScript model. Nonetheless, an extension is conceiv\u00adable, where the mechanisms \nfor runtime script generation speci.es which node in the document tree is to be updated. The instrumenta\u00adtion \nmethod remains the same, because it does not matter where the generated script is located, as long as \nit is rewritten appropriately to go through the policy interface. Lastly, CoreScript includes some simple \nactions for demon\u00adstration purposes. A realization would accommodate many other actions pertinent to \nattacks and protections. Some relevant DOM APIs include those for manipulating cookies, windows, network \nusage, clipboard, and user interface elements. In addition, it is use\u00adful to introduce implicit actions \nfor some event handlers. For in\u00adstance, the undead window attack below could be prevented by disallowing \nwindow opening inside an onUnload event. <html> <head> <script type=\"text/javascript\"> function respawn(){ \n window.open(\"URL/undead.html\") } </script> </head> <body onunload=\"respawn()\"> Content of undead.html \n</body> </html>  7. Implementation As shown in Figure 14, our implementation extends a browser with \nthree small modules one for the syntactic code rewriting (.), one for interpreting the special instruction \n(instr), and another for im\u00adplementing the security policy (.). Under our instrumentation, a browser \ndoes not interpret a document D directly. Instead, it inter\u00adprets a rewritten version .(D) produced by \nthe rewriting module. Upon encountering a special instruction instr(E), the implemen\u00adtation of instr \nevaluates the expression E and sends the result\u00ading document D. through the rewriting module. The result \nof the rewriting .(D.) is directed back to the browser for further inter\u00adpretation. Upon a call to the \npolicy interface check(A), the policy module advances the state of the automaton and provides a replace\u00adment \naction A. . In our prototype, the rewriting module is implemented in Java, with help of ANTLR [13] for \nparsing JavaScript code. We parse HTML documents into abstract syntax trees (ASTs), perform rewriting \non the ASTs, and generate instrumented JavaScript code and HTML documents from the ASTs. We set up the \nbrowser to use this rewriting module as a proxy for all HTTP requests. An obvious way to implement the \nspecial instruction is to mod\u00adify the JavaScript interpreter in a browser according to the oper\u00adational \nsemantics given by Rule (33) in Section 5. After the in\u00adterpreter parses a document piece out of the \nstring argument (ab\u00adstracted by the evaluation relation in Rule (33)), the rewriting module is invoked. \nThe interpretation resumes afterwards with the rewritten document piece. Although the above is straightforward, \nit requires changing the implementation of the browser. In our prototype, we opted for an implementation \nwithin the regular JavaScript language itself, where instr is implemented as a JavaScript function. The \ncall-by-value nature of JavaScript functions evaluates the argument expression before executing the function \nbody, which naturally provides the expected semantics. We make use of the XMLHttpRequest ob\u00adject [21] \n(popularly known as part of the Ajax [7] approach) to call the Java rewriting module from inside JavaScript \ncode. Although convenient, this approach is not as robust as that of modifying the JavaScript interpreter, \nbecause it is more vulnerable to malicious exploits. As discussed in Section 6, JavaScript pro\u00advides \nsome form of self-modifying code, e.g., through innerHTML. This presents a possibility for malicious \nscript to overwrite the im\u00adplementation of instr,if instr is implemented in JavaScript and interpreted \ntogether with incoming documents. Additional code inspection is needed to protect against such exploits, \nwhich makes the implementation dependent on some idiosyncrasies of the JavaScript language. Therefore, \nit may be more desirable to modify the interpreter when facing a different tradeoff. Similar implementation \nchoices apply to the policy module. For example, one can implement the policy module as an add-on to \nthe browser with the expected policy interface. In our prototype, we implemented the policy module also \nin regular JavaScript check is implemented as a regular JavaScript function and calls to check are regular \nfunction calls with properly encoded arguments that re.ect the actions being inspected. The body of the \ncheck function carries out the replacement actions, which are typically the original actions with checked \narguments and/or inserted user prompts. The above protection concerns for instr against malicious exploits \nthrough self-modifying code also applies here. We emphasize that our prototype enforces policies per \ndocu\u00adment cluster. A browser may simultaneously hold multiple win\u00addows. Some of these windows can communicate \nwith each other (e.g., a window and its pop-up, if the pop-up holds a document from the same origin); \nwe consider these as being in the same clus\u00adter. We give each cluster its own policy instance in the \nform of a JavaScript object, and give all windows in the same cluster a refer\u00adence to the cluster s policy \ninstance, which is properly set up when windows are created or documents are loaded. This does not affect \nthe essence of the instrumentation, therefore we have elided its formal treatment (our CoreScript model \nonly concerns a single cluster; our formal instrumentation only refers to a single policy instance). \nNonetheless, the per-cluster enforcement is necessary for expressing practical policies. On the one hand, \ndocuments from different clusters should not share the same policy instance, so that the behavior of \none document would not affect what an unrelated document is allowed to do (e.g., two unrelated windows \nmay each have their own quota of pop-ups). On the other hand, documents from the same cluster must share \nthe same policy instance to prevent malicious exploits (e.g., an attack may conduct relevant actions \nin separate documents in the same cluster). 8. Experiments We implemented some simple but useful policies \nin the context of resource usage and secrecy, and tested the prototype with them on a number of web pages, \nincluding malicious or exploited pages from the real world, well-intended pages which might raise false \npositives, random popular pages, and some pages specially written to explore the boundaries of existing \ntools. Here we focus on two policies for demonstration purposes. The .rst relates to controlling pop-up \nwindows. Whereas many pop-up blockers have been developed and deployed, they only provide a limited degree \nof customization. Typically, the choices upon a pop-up are either to always allow, to allow once and \nask again, or to disallow. In comparison, our tool is more .exible in the sense that it allows customization \non the number of pop-ups allowed (see Figure 10) as well as the size, position and chrome visibility. \nThe second relates to controlling cookie information. Whereas browsers allow a webpage to access a cookie \nonly if the cookie was set by the same domain, web pages with XSS vulnerabilities are still subject to \ncookie-stealing attacks (Section 2.1). We tried a simple policy which warns the user (and asks whether \nto proceed) if a webpage is sending network requests to a different domain after accessing the cookie \n(see Figure 11, where safe-loadULR is implemented to check domain conformance and prompt the user for \ndecisions). We injected cookie-stealing script into some XSS\u00advulnerable web pages [14]. Our tool successfully \nraised warnings before the cookies were sent out. To the authors knowledge, no existing tool provides \nclient-side protection for such web pages. We also tried the same cookie policy on some popular web pages \nfor online banking, online shopping and web-based emails. We speci.cally looked for those that involved \nboth cookie access and redirection to other domains, aiming to learn about false pos\u00aditives (in this \ncase, these would be false warnings which users can easily dismiss). Only few tested pages exhibited \npolicy-violating behaviors, and they were all from online shopping sites. The viola\u00adtion happened because \n(1) the cookie is accessed for login and/or shopping cart operations; (2) redirection to other domains \nhap\u00adpened when browsing external links, which are sometimes provided on product description pages. In \ncontrast, none of the online bank\u00ading or web-based email pages tested presented policy-violating be\u00adhaviors. \nSome of them did not use cookies for storing login infor\u00admation at all. Others performed redirection \nbefore handling cook\u00adies. This, in retrospection, is reasonable if the cookie is used to store login \ninformation. Redirection after cookie access would happen if a website sets a cookie from one domain \nbut handles login from another, a questionable behavior on its own. We did not measure the performance \nof the prototype, because JavaScript additions to web pages are usually small and the instru\u00admentation \noverhead is unlikely to be noticeable given the nature of web pages. Indeed, we did not notice any performance \ndifference between the original and the instrumented web pages. For the same reason, our prototype does \nnot perform optimizations, even though it is possible to avoid certain checks by some analysis on the \ncode. We point out that these preliminary experiments aim at demon\u00adstrating the effectiveness of our \ninstrumentation method and its po\u00adtential in the context of browser security. A thorough policy in\u00advestigation \nand use-case study is outside the scope of this paper. Nonetheless, we are actively investigating policy \nissues and exper\u00adimenting with the latest attacks. For example, a simple policy that warns against all \nredirections would have likely identi.ed the re\u00adcent Yahoo Mail Worm attack [19] and therefore helped \ncontrol its damage. For a realistic deployment, customized policies that are speci.cally based on different \ndomain names (e.g., black and white lists) would also be useful. These are supported by our prototype, \nbut not discussed due to space constraints. 9. Conclusion JavaScript is widely employed to enhance web \npages with client\u00adside computation. Unfortunately, as a popular (and perceptually silent) form of mobile \ncode, JavaScript has also been much ex\u00adploited by malicious parties to launch browser-based attacks. \nWhereas modern browsers and separate security tools provide cer\u00adtain basic protections, there are still \nmany attacks at large. It is useful to have a common and extensible framework that regulates the behavior \nof untrusted JavaScript code from the perspective of the JavaScript language, rather than from that of \nspeci.c attacks only. This paper presents a provably correct method for instrumenting JavaScript code \nfor browser security. It re.ects the application and adaptation of a few interesting language theories \nand techniques. We characterize the relevant features of JavaScript in a core lan\u00adguage and give it an \noperational semantics addressing its different execution model. Due to the presence of higher-order script, \nthe conventional method of instrumentation cannot effectively identify and rewrite all relevant code. \nWe resolve this issue by embedding callbacks in the instrumented code, so that further rewriting on runtime-generated \nscript can be carried out on demand. We use edit automata to express security policies, and present some \nsimple consistency criterion and combination method for policy manage\u00adment. A policy interface separates \nthe policy implementation from the rewriting mechanism, facilitating policy extension, upgrade and customization. \nThis paper has focused on describing our approach and prov\u00ading its correctness. It is organized in a \ngeneric context so that the ideas are applicable to related questions. Our experiments are car\u00adried out \nwith the actual JavaScript language, where the prototype implementation also tackles a few language-speci.c \nissues such as the dynamic binding and rebinding of properties and methods. We plan to document the implementation \naspects separately. Current experiments show much promise on the effectiveness of the instru\u00admentation \nmethod, although further investigation is needed on the practical aspects of deployment, particularly \nin the area of policy design and customization.  Acknowledgments We wish to thank Zhong Shao and the \nanonymous referees for their helpful comments. References [1] C. Anderson, P. Giannini, and S. Drossopoulou. \nTowards type inference for JavaScript. In Proc. 19th European Conference on Object-Oriented Programming, \npages 429 452, Glasgow, UK, July 2005. [2] L. Bauer, J. Ligatti, and D. Walker. Composing security policies \nwith Polymer. In Proc. 2005 ACM Conference on Programming Language Design and Implementation, pages 305 \n314, Chicago, IL, June 2005. [3] N. Chou, R. Ledesma, Y. Teraguchi, D. Boneh, and J. C. Mitchell. Client-side \ndefense against web-based identity theft. In Proc. 11th Annual Network and Distributed System Security \nSymposium,San Diego, CA, Feb. 2004. [4] ECMA International. ECMAScript language speci.cation. Stardard \nECMA-262, 3rd Edition, http://www.ecma-international. org/publications/files/ECMA-ST/Ecma-262.pdf, Dec. \n1999. [5] U. Erlingsson and F. B. Schneider. SASI enforcement of security policies: A retrospective. \nIn Proc. 1999 New Security Paradigms Workshop, pages 87 95, Caledon Hills, Ontario, Canada, Sept. 1999. \n[6] D. Evans and A. Twyman. Flexible policy-directed code safety. In Proc. 20th IEEE Symposium on Security \nand Privacy, pages 32 47, Oakland, CA, May 1999. [7] J. J. Garrett. Ajax: A new approach to web applications. \nAdaptive Path essay, http://www.adaptivepath.com/ publications/essays/archives/000385.php,Feb. 2005. \n [8] R. Hansen. XSS cheat sheet. Appendix of OWASP 2.0 Guide, http://ha.ckers.org/xss.html, Apr. 2005. \n [9] A. L. Hors, P. L. Hegaret, L. W. ad Gavin Nicol, J. Robie, M. Champion, and S. Byrne. Document Object \nModel (DOM) level 3 core speci.cation. W3C candidate recommendation, http://www. w3.org/TR/2003/CR-DOM-Level-3-Core-20031107/, \nNov. 2003. [10] J. Ligatti, L. Bauer, and D. Walker. Edit automata: Enforcement mechanisms for run-time \nsecurity policies. International Journal of Information Security, 4(2):2 16, Feb. 2005. [11] G. A. D. \nLucca, A. R. Fasolino, M. Mastoianni, and P. Tramontana. Identifying cross-site scripting vulnerabilities \nin web applications. In Proc. 6th IEEE International Workshop on Web Site Evolution, pages 71 80, Washington, \nDC, 2004. [12] MozillaZine. XPCNativeWrapper. MozillaZine Knowledge Base, http://kb.mozillazine.org/XPCNativeWrapper, \n2006. [13] T. Parr et al.. ANTLR reference manual. Reference manual, http://www.antlr.org/, Jan. 2005. \n[14] Point Blank Security. The XSS blacklists. http://www. pointblanksecurity.com/xss/ and http://www. \npointblanksecurity.com/xss/xss2.php, 2002 2005. [15] A. Rudys and D. S. Wallach. Termination in language-based \nsystems. ACM Transactions on Information and System Security, 5(2):138 168, May 2002. [16] J. H. Saltzer \nand M. D. Schroeder. The protection of information in computer systems. Proceeding of the IEEE, 63(9):1278 \n1308, Sept. 1975. [17] F. B. Schneider. Enforceable security policies. Transactions on Information and \nSystem Security, 3(1):30 50, Feb. 2000. [18] Z. Su and G. Wassermann. The essence of command injection \nattacks in web applications. In Proc. 33rd ACM Symposium on Principles of Programming Languages, pages \n372 382, Charleston, SC, Jan. 2006. [19] Symantec Corp. JS.Yamanner@m. Symantec Security Response, http://www.symantec.com/security_response/ \nwriteup.jsp?docid=2006-061211-4111-99, June 2006. [20] P. Thiemann. Towards a type system for analyzing \nJavaScript programs. In Proc. 14th European Symposium on Programming, pages 408 422, Edinburgh, UK, Apr. \n2005. [21] A. van Kesteren and D. Jackson. The XMLHttpRequest object. W3C working draft, http://www.w3.org/TR/XMLHttpRequest/, \n2006. [22] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham. Ef.cient software-based fault isolation. \nIn Proc. 14th ACM Symposium on Operating Systems Principles, pages 203 216, Asheville, NC, 1993. [23] \nD. Walker. A type system for expressive security policies. In Proc. 27th ACM Symposium on Principles \nof Programming Languages, pages 254 267, Boston, MA, 2000. [24] Y. Xie and A. Aiken. Static detection \nof security vulnerabilities in scripting languages. In Proc. 15th USENIX Security Symposium, Vancouver, \nB.C., Canada, July 2006.  \n\t\t\t", "proc_id": "1190216", "abstract": "It is well recognized that JavaScript can be exploited to launch browser-based security attacks. We propose to battle such attacks using program instrumentation. Untrusted JavaScript code goes through a rewriting process which identifies relevant operations, modifies questionable behaviors, and prompts the user (a web page viewer) for decisions on how to proceed when appropriate. Our solution is parametric with respect to the security policy-the policy is implemented separately from the rewriting, and the same rewriting process is carried out regardless of which policy is in use. Be-sides providing a rigorous account of the correctness of our solution, we also discuss practical issues including policy management and prototype experiments. A useful by-product of our work is an operational semantics of a core subset of JavaScript, where code embedded in (HTML) documents may generate further document pieces (with new code embedded) at runtime, yielding a form of self-modifying code.", "authors": [{"name": "Dachuan Yu", "author_profile_id": "81350591150", "affiliation": "DoCoMo Communications Laboratories USA, Inc.", "person_id": "PP28019431", "email_address": "", "orcid_id": ""}, {"name": "Ajay Chander", "author_profile_id": "81339492940", "affiliation": "DoCoMo Communications Laboratories USA, Inc.", "person_id": "PP39060054", "email_address": "", "orcid_id": ""}, {"name": "Nayeem Islam", "author_profile_id": "81332506182", "affiliation": "DoCoMo Communications Laboratories USA, Inc.", "person_id": "PP36033856", "email_address": "", "orcid_id": ""}, {"name": "Igor Serikov", "author_profile_id": "81350594439", "affiliation": "DoCoMo Communications Laboratories USA, Inc.", "person_id": "P831282", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1190216.1190252", "year": "2007", "article_id": "1190252", "conference": "POPL", "title": "JavaScript instrumentation for browser security", "url": "http://dl.acm.org/citation.cfm?id=1190252"}