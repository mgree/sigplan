{"article_publication_date": "01-17-2007", "fulltext": "\n Conditional Must Not Aliasing for Static Race Detection Mayur Naik Alex Aiken Computer Science Department \nStanford University {mhn,aiken}@cs.stanford.edu Abstract Race detection algorithms for multi-threaded \nprograms using the common lock-based synchronization idiom must correlate locks with the memory locations \nthey guard. The heart of a proof of race freedom is showing that if two locks are distinct, then the \nmemory locations they guard are also distinct. This is an example of a general property we call conditional \nmust not aliasing: Under the assumption that two objects are not aliased, prove that two other objects \nare not aliased. This paper introduces and gives an algorithm for conditional must not alias analysis \nand discusses experimental results for sound race detection of Java programs. Categories and Subject \nDescriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation Reliability General Terms Experimentation, \nReliability, Veri.cation Keywords static race detection, Java, synchronization, concur\u00adrency, multi-threading \n1. Introduction A multi-threaded program contains a race if two threads can ac\u00adcess the same memory location \nwithout ordering constraints en\u00adforced between them and at least one of those accesses is a write. Races \noften imply serious violations of program invariants and are notoriously dif.cult to .nd in debugging \nand testing. Proving race freedom the absence of races is thus valuable in improving the reliability \nof multi-threaded programs. Most approaches to proving race freedom involve checking the lock-based synchronization \nidiom [3, 4, 15, 16, 22, 36, 39]. Locking requires that any pair of potentially simultaneous accesses \nto a location m from different threads be guarded by a lock l, meaning that each thread must hold lock \nl while accessing m. Because at most one thread can hold lock l at any instant, there are no races on \nmif the locking discipline is used correctly. A challenge in proving race freedom in the presence of \nlocks lies in the apparent need for a form of must alias analysis. Consider the following pseudo-code \nexample: Thread 1: sync(l1) { ... write location m1 ... } Thread 2: sync(l2) { ... write location m2 \n... } Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n07 January 17 19, 2007, Nice, France. Copyright c &#38;#169; 2007 ACM 1-59593-575-4/07/0001. . . $5.00 \nHere sync is Java s lexically-scoped locking construct. The lock argument to sync is acquired before \nentering the block and released on exiting the block. Consider the two memory accesses in this example, \nand suppose that it is possible that m1 = m2 at run-time, i.e., m1 and m2 may alias. To show that the \naccesses cannot race, it suf.ces to show that l1 and l2 always refer to the same lock at run-time, i.e., \nl1 and l2 must alias. In previous work [33], we presented a static race detection tech\u00adnique for Java \nemploying a series of static analyses to successively prune an initial over-estimate of the set of races \nto a relatively small set of potential races. The analysis of locks used is an approxima\u00adtion based on \na may alias analysis to check whether a pair of locks held during a pair of accesses might be the same. \nThis approxima\u00adtion, while effective at bug-.nding, does not perform the needed must alias analysis and \ncannot prove race freedom. It merely parti\u00adtions races into likely and unlikely races. While the likely \nraces are in practice almost always real races, the set of unlikely races has a high false positive rate \nand it is dif.cult to know how many real races it contains (if any) without considerable manual labor. \nIn this paper, we present a new approach to sound race detection in the presence of locks. The key idea \nis that instead of attacking the problem directly using a must alias analysis, we reformulate the question \nthat must be solved in terms of a dual must not alias analysis problem. Consider once more the example \nabove. Instead of starting with the locations accessed and reasoning about the locks, we start with the \nlocks and try to reason about the locations. If we assume that locks l1 and l2 cannot be the same (we \nassume the locks must not alias) then it suf.ces to show that the locations m1 and m2 are not the same \n(we prove the locations must not alias). Intuitively, if whenever two locks are different their guarded \nlocations must be different, then there are no races. Note that in the case where the two locks must \nalias there is nothing to prove accesses to their guarded locations cannot race in any case. This approach \nto proving race freedom is an example of a conditional must not alias query: DEFINITION 1.1. Let e1 and \ne2 be abstract memory locations (e.g., program expressions with associated context sensitive informa\u00adtion). \nA must not alias fact is a pair (e1,e2) asserting e1 and e2 cannot refer to the same run-time memory \nlocation. Let P be a program and Aand Bbe sets of must not alias facts. A conditional must not alias \nsentence A fP B means that in program P, under the assumption that the must not alias facts in Ahold, \nthe must not alias facts in B must hold. We use the example in Figure 1 to illustrate the idea of must \nnot alias analysis in the context of race detection. This example has three parts shown in three columns. \nThe code in the .rst column allocates an array object h1 and executes a loop, each iteration of which \nputs a fresh object h2, whose .eld f points to another fresh object h3, into the array. Next, the code \nin the second column exe\u00adcutes a loop, each iteration of which spawns a thread that accesses .eld g of \nan object h3 through .eld f of a non-deterministically chosen array element object h2. Left unspeci.ed \nis the lock L that is acquired; several choices for L are given in the third column. Consider the case \nwhere L = a: the lock is acquired on the entire array. This situation represents a coarse-grain locking \nstyle that uses global, uniquely named locks; in particular, each such lock is created at an allocation \nsite that executes exactly once. Some previous sound lock checking systems rely on such single execution \nallocation sites for locks [5]. From the point of view of conditional must not aliasing this case is \nuncomplicated. Consider two syncs in different iterations of the second loop. Since the assumption that \nthey acquire different locks is false (they always acquire the same lock), we can conclude that whenever \nthe locks are different the guarded accesses are distinct and the program is race free. Now consider \nthe case where L = x.f. This case represents the extreme of .ne-grain locking, and again reasoning using \ncondi\u00adtional must not aliasing to prove race freedom is straightforward. If two syncs in different iterations \nof the second loop acquire differ\u00adent locks, then the locations of their g .elds must be different and \nthe code is race free. The subtlest case is medium-grain locking represented by the case L = x. Each \niteration of the loop holds a lock on object x,but the potential race is on .eld g of a different object \nx.f.The key to showing this example is race free lies in observing that x.f is only reachable through \nx and therefore locking x is suf.cient to guard against races on .elds of x.f. Thus, if in two different \niterations of the loop the x objects are different, then the x.f objects (and hence the locations of \ntheir g .elds) must also be different and the code is race free. All three of these locking styles (coarse-, \nmedium-, and .ne\u00adgrain) occur frequently in real programs. Note that a common theme in the informal arguments \ngiven above is the ability to rea\u00adson about different locks acquired at the same syntactic point, as \nalluded to in phrases such as if two syncs in different iterations ... . The medium-grain locking case \nhas the additional dif.culty of reasoning about correlated objects, such as the fact that in the .rst \nloop, .eld f of each new h2 object points to a unique h3 ob\u00adject allocated in the same loop iteration. \nWe develop a type and effect system that tracks the needed correlations between objects. Section 2 introduces \na small language we use for the formal de\u00advelopment and Section 3 introduces the type and effect system \nand gives a proof of its soundness. To concisely represent must not aliasing facts, we use a separate \nobject reachability analysis we call disjoint reachability analysis (Section 4). Let H be the set of \nall allocation sites in the program; we de.ne a function DR .2H .2H such that if h .DR(H), then any object \no allocated at site h is reachable by following one or more .eld dereferences from at most one of any \ntwo distinct objects o1 and o2 allocated at sites h1,h2 .H. Note that we require o1 .= o2, but we allow \nh1 = h2. In the example in Figure 1, we have h3 . DR({h2}). Figure 2 gives a pictorial view of how disjoint \nreachability analysis is used to prove race freedom. In Figure 2, P (e) is the points-to set of e, i.e., \nthe set of allocation sites at which e may be allocated. Let x and y be locks and x.e1.f and y.e2.f be \ntwo accesses to instance .eld f.Now, P (x.e1) nP (y.e2) is the set of may aliases of x.e1 and y.e2 the \nset of objects on which there is a potential race. If this set is contained in DR(P (x) .P (y)), however, \nthen whenever x and y are distinct objects it is guaranteed that x.e1 and y.e2 are distinct objects and \nno races are possible. We have implemented the type and effect system and disjoint reachability analysis \nin Chord (Section 5), a static race detector for Java and performed a number of experiments on complete \nJava applications (see Section 6). The main empirical result is that our sound race detector eliminates \nalmost all of the false positives in a= new h1[N]; while (*) {Choices for L: for (i= 0; i <N; i++) { \nx=a[*]; a a[i] = new h2; fork {x a[i].f = new h3; sync (L) {x.f } x.f.g = *; }}} Figure 1. Example program. \n P (x.e1) P (y.e2) (P (x.e1) n P (y.e2)) . DR(P (x) . P (y)) . (f is race-free) Figure 2. Proving race \nfreedom via conditional must not aliasing. our previous work; the false positives remaining, at least \nin these benchmarks, are the result of engineering shortcomings that are straightforward to remove with \nadditional effort. In particular, the large category of unlikely races is almost completely eliminated. \nSigni.cantly, the number of races found in these benchmarks in\u00adcreases from 122 using our old unsound \napproach of considering only likely races to 202 using our new sound algorithm. Thus, a number of the \nformer unlikely races turn out to be real races that we did not notice with our previous technique. In \nsummary, the main contributions of this paper are: We introduce conditional must not aliasing, a property \nthat is useful in formulating static race detection and may be of independent interest. Conditional must \nnot aliasing is different from standard may aliasing precisely in that it is conditional; instead of \ncomputing must not aliasing facts that always hold, we compute must not aliasing facts that only hold \nassuming other must not aliasing facts, allowing a more re.ned treatment of the relationship between \nlocks and the locations they guard.  We introduce disjoint reachability analysis, a program analy\u00adsis \nuseful for computing conditional must not alias properties. Disjoint reachability analysis is also a \ncheaper, and likely more scalable (but less precise) alternative to some recent decision procedures for \nveri.cation of pointer-based data structures. Fur\u00adther discussion is included with related work (Section \n7).  We have implemented conditional must not aliasing using a disjoint reachability analysis in Chord, \na static race checker [33]. On the benchmarks we have studied, this system has few false positives and, \nbecause it is designed to be sound, should have no false negatives (modulo some standard unsound assumptions \ndiscussed in Section 5).   2. Language In this section, we present the abstract syntax and operational \nse\u00admantics of a sequential WHILE language that we use in subsequent sections to formalize our approach \nto conditional must not aliasing. 2.1 Syntax The abstract syntax of the language is given in Figure 3. \nA program has a .xed set of variables V with global scope and a single object type with instance .elds \nF. We label each object allocation site in the program with a unique h . H and we label each loop with \na unique integer w .W. There are no threads; conditional must not aliasing is not a multi-threading property \nand the presentation is simplest in a single-threaded language. (variable) x,y . V (instance .eld) f \n. F (object allocation site) h . H (loop identi.er) w . W s ::= x= null | x= new h | x= y | x= y.f | \nx.f = y |s1 ; s2 | if (*) then s1 else s2 | whilew (*) do s Figure 3. Abstract syntax. (loop iteration) \nN 3 i ::= 0 | 1 | 2 | ... (loop vector) p . W .N (non-null object) O 3 o\u00af::= (p,h) (object) O. 3 o ::= \no\u00af|.(environment) . . V .O. (heap) s . (O \u00d7F) .O. (heap effect) C ::= \u00d8| C .{o\u00af1 C o\u00af2} (p,h).p p (p,h).h \nh Figure 4. Semantic domains.  2.2 Semantics We next develop an operational semantics for the WHILE \nlanguage in Figure 3. Figure 4 de.nes the semantic domains. Recall that one goal is to track reachability \nproperties of objects (e.g., the exam\u00adple in Figure 1). Reasoning about object reachability requires \nrea\u00adsoning about how data structures are built, which means reason\u00ading about the times when objects are \nallocated and linked to one another. A loop vector p, which is a tuple of non-negative inte\u00adgers, tracks \nhow many times each loop in a program has executed; each element of p is a counter, and the iteration \ncount of a loop whilew (*) do s in the program is p(w) (treating the tuple p as a map from indices to \nelements of p). Objects are uniquely identi\u00ad.ed as pairs (p,h)of a loop vector p recording the time (in \nloop execution counts) when the object was allocated and its allocation site h. Abstractions of the loop \nvector (Section 3) will allow us to estimate the relative time in terms of the number of loop iterations \nwhen two distinct objects are allocated. Environments and heaps are standard. An environment maps variable \nnames to objects in the heap, and a heap records for each object what object (or null) is in each .eld. \nA heap effect o\u00af1 C o\u00af2 records that at some point in the execution, object o\u00af2 was reachable in one \nstep via a .eld dereference from object o\u00af1. Figure 5 presents a big-step operational semantics for our \nlan\u00adguage. Judgments have the form ''' s,W,p,.,s . p,.,s,C Each step of execution begins with the statement \nsto be executed, the set W of all loops lexically enclosing s, and the current loop vector p, environment \n., and heap s. Note that W records which loops are currently executing while p records the execution \ncount of all loops in the program and not just of loops currently active. Since loops may execute as \npart of a step of execution the semantics must record a new loop vector as well as an updated environment \nand heap. Thus, a step of execution terminates with a .nal loop vector p', environment .', and heap s', \nplus the heap effects C. (loop iteration abstr.) NT 3 i ::= 0 | 1 |T (loop vector abstr.) . . W .NT \n (obj. alloc. site abstr.) HT 3 h ::= h |T(non-null type) T 3 t\u00af::= (.,h ) (type) T. 3 t ::= t\u00af|.(type \nenvironment) G . V .T. (heap effect abstr.) K ::= \u00d8| K .{t\u00af1 . t\u00af2} (.,h ).. . (.,h ).h h  Figure 6. \nTypes. We explain the most interesting rules in Figure 5. Rule (2), which creates a new object, does \nnot simply use the current loop vector as the time stamp recorded in the object. Instead, counters for \nloops not in W (i.e., those not currently executing) are set to 0, giving a way to determine later whether \nor not a particular loop was executing when the object was allocated.1 While this property is not exploited \nin the instrumented operational semantics, it is used in the abstractions discussed in Section 3. Assigning \nto a .eld of an object (Rule (5)) generates a heap effect recording the reachability between the two \nobjects involved in the assignment. Finally, con\u00adsider Rules (9) and (10), which give the semantics of \nwhile state\u00adments. Loops execute a non-deterministic number of times, which saves us the trouble of de.ning \nhow loop termination conditions (as well as the predicates of if statements, see Rules (6) and (7)) are \nevaluated. Also note that when a loop executes an additional time (Rule (10)) the appropriate loop counter \nis incremented. We conclude this section with a small example, which is a simpli.ed version of the program \nin Figure 1. EXAMPLE 2.1. while1 (*) do {x= new h1;y= new h2;x.f =y }If the loop executes one time, the \nroot of the derivation tree is: while1 ...,\u00d8,(0),[x ..,y ..],[] f (1),[x.\u00af o2],[\u00aff.\u00afo2.f \u00afo2} o1,y.\u00afo1. \no2,\u00af..],{o1 C \u00af where o\u00af1 = ((1),h1)and o\u00af2 = ((1),h2)and [] is the empty heap.  3. Type and Effect \nSystem The syntax of types and effects is shown in Figure 6. Types and effects are parallel with the \nde.nitions in Figure 4, but the seman\u00adtics are signi.cantly different. Before proceeding with the formal \ndevelopment, we provide an informal explanation. Objects have types (.,h )recording information about \nwhen and where they were allocated. The main purpose of the type sys\u00adtem is to compute abstract heap \neffects such as (.1,h 1).(.2,h 2). As in the operational semantics, the effect implies an object of type \n(.2,h 2)is reachable from an object of type (.1,h 1)in a single step via a .eld dereference. In a type, \nloop iterations are abstracted as 0, 1, or T.If .1(w)=0, then loop w was not executing when the object \nwith that type was allocated (similarly for .2(w)). If .1(w)= Tthen nothing is known about the iteration \nof loop win which the object was allocated (and similarly for .2(w)). In either case nothing is known \nabout the relative time at which objects of the two types were allocated. However, if .1(w)=.2(w)=1, \nthen the type system guarantees the two objects were allocated in the same iteration of loop w. This \nproperty allows us to show con\u00additional must not aliasing: intuitively, if (.1,h 1)reaches (.2,h 2) and \nthey were allocated in the same iteration, then objects of type 1 The allocation site could also be used \nto determine the set of lexically enclosing loops; using W is clearer if less economical. x= null,W,p,.,s \n. p,.[x..],s,\u00d8 (1) x= new h,W,p,.,s . p,.[x.\u00afo.f1 ..,...,\u00afn ..],\u00d8 [\u00af= (.w(if w .W then p(w) else 0),h)] \no],s[\u00afo.fo.(2) x= y,W,p,.,s . p,.[x..(y)],s,\u00d8 (3) x= y.f,W,p,.,s . p,.[x.s(\u00afo.f)],s,\u00d8 if .(y)=\u00afo (4) \n\u00bbj {o\u00af1 C o\u00af2} if o2 =\u00afo2 x.f = y,W,p,.,s . p,.,s[\u00afo1.f .o2],C if .(x)=\u00afo1 .(y)= o2 and C = (5) \u00d8 if \no2 = . s1,W,p,.,s . p ' ,. ' ,s ' ,C s2,W,p,.,s . p ' ,. ' ,s ' ,C (6) (7) if (*) s1 else s2,W,p,.,s \n. p',.',s',C if (*) s1 else s2,W,p,.,s . p',.',s',C s1,W,p,.,s . p ' ,. ' ,s ' ,C1 s2,W,p ' ,. ' ,s ' \n. p '' ,. '' ,s '' ,C2 (8) s1; s2,W,p,.,s . p'',.'',s'',C1 .C2 whilew (*) do s,W,p,.,s . p,.,s,\u00d8 (9) \n''' ''' '''''' s,W .{w},p[w .p(w)+ 1],.,s . p ,. ,s ,C1 whilew (*) do s,W,p ,. ,s . p ,. ,s ,C2 (10) \n'''',s'',C1 .C2 whilew (*) do s,W,p,.,s . p,. Figure 5. Instrumented operational semantics. o . t . \n(o = .) . (o =\u00afo . t =\u00aft . o\u00af. t\u00af) o\u00af. \u00af. o.p(w) . t..(w)) . (\u00aft. t (.w . W :\u00af\u00afo.h . \u00afh) i . i . (i =0 \n. i =0) . (i> 0 . i =1) . ( i = T) h . h . (h = h ) . (h = T) (a) Object abstraction. C . K ..(\u00afo1 . \no\u00af2) . C : .(\u00aft1 .t\u00af2) . K :(\u00afo1,o\u00af2) . (\u00aft1,t\u00af2) 8 < (1) o\u00af1 . t\u00af1 (\u00afo1,o\u00af2) . (\u00aft1,t\u00af2) .. (2) o\u00af2 \n. t\u00af2 : . (3) .w . W :((\u00aft1..(w)=1 . t\u00af2..(w)= 1) . o\u00af1.p(w)=\u00afo2.p(w)) (b) Heap effect abstraction. \n8 (1) .w . W : p(w) . .(w) > > < . (2) .x . V : .(x) . G(x) W f (p, .) . (., G) . j > (a).(w)=1 . p(w)= \nk > : . (3) .w . W : .k . N : . (b) .x . V :((.(x)=\u00aft \u00af\u00af o . G(x)=\u00af. t..(w)= 1) . o.p(w)= k) (c) Environment \nabstraction. Figure 7. Abstraction. (.1,h1)allocated in different iterations must reach different ob\u00ad \n jects of type (.2,h2). This discussion is made precise in Figure 7, which de.nes an abstraction relation \n.stating when types and abstract heap effects abstract objects and concrete heap effects, respectively. \nThe third clause of sub-.gure (b) requires that the iteration counts in position w of the concrete loop \nvectors of two objects match if the values in position w of the abstract loop vectors of their types \nare 1. Likewise, the third clause of sub-.gure (c) requires that iteration counts in position w of the \nconcrete loop vectors of all objects in environment . match if the values in position w of the abstract \nloop vectors of their types in environment G are 1. Thus, in both abstract heap effects and type environments, \nany two types with a 1 in position w of their abstract loop vectors always abstract objects allocated \nin the same concrete, but unknown, iteration of loop w. Before we can give the type rules we need two \noperations on type environments. The join of type environments is point\u00adwise. Nulls are absorbed, and \nif either loop iterations or allocation sites fail to match, the result is T in the appropriate position. \nThe second operation handles the increment of loop vectors; in a whilew (*) do s statement, if the value \nin position w of the loop vector is 1, it is incremented to Twhen the loop iterates. DEFINITION 3.1. \n(Join of Environments) (G1 U G2)(x) =G1(x) U G2(x) 8 < t1 if t2 = . t1 U t2 = t2 if t1 = . : t\u00af1 U t\u00af2 \nif t1 =\u00aft1 . t2 =\u00aft2 t\u00af1 U t\u00af2 = (t\u00af1.. U t\u00af2..,t\u00af1.h U t\u00af2.h) (.1 U .2)(w)=.1(w) U .2(w) j i1 if i1 \n= i2 i1 U i2 = T otherwise j h 1 if h 1 = h 2 h1 U h 2 = T otherwise DEFINITION 3.2. (Loopback Environment) \nGw+(x) =G(x)w+ tw+\u00af= t..w+ t. (\u00af,\u00afh) .w+ = . j ' T if w = w . .(w)=1 ' .w+(w )= .(w ' ) otherwise The \nupper bound of two types implicitly de.nes a type lattice, which is ordered pointwise on loop vectors \nand allocation sites. Integers and allocation sites are all less than T and incomparable to each other. \nThe maximal type is then a loop vector of all T elements and a T allocation site; the minimal element \nis the type ., and since any program has a .nite number of loops and allocation sites, the type lattice \nis also .nite. The type rules are given in Figure 8. These rules are parallel with the operational semantics \nin Figure 5 and for brevity we point out only a few interesting features. Rule (12) puts 0 s in the loop \nvector positions of newly allocated objects for any loops that are not executing, just as in Rule (2) \nof Figure 5. The only use of W is to distinguish active from inactive loops; loop vector positions of \nactive loops take their value from the current loop vector ..Rule (14) gives no information about heap \nreads, which is sound, but overly conservative in practice. We discuss improvements in Sec\u00adtion 5, which \nwe omit from the formal development for simplicity. The most interesting rule, Rule (18), has three important \naspects. First, the condition .(w)=0.re.ects that loop vectors for objects allocated inside loop w should \nnot be 0 at position w (and Rule (12) already guarantees objects allocated outside loop w have a0 at \nposition w). Second, the fact that the environment Gis the same before and after the loop re.ects that \nany conclusion must be valid for any number of executions of the loop that is, the entire loop may be \nexecuted multiple times (e.g., if it is nested inside of another loop) and the environment Gmust be an \ninvariant for all of those executions. For example, a proof W,.,G f whilew ... :G,K where G=[x .((...,1,...),h1),y \n.((...,1,...),h2)]im\u00adplies that if the loop ever starts execution in an environment where x and y were \nallocated in the same iteration of some earlier exe\u00adcution of the loop (e.g., because this loop is nested \ninside another loop), then the loop terminates with xand y assigned objects from the same loop iteration. \nNote that the .nal concrete loop iteration associated with x and y may be different than the initial \none; the value 1 in both types only requires that the concrete loop iterations of xand y be equal before \nand after the loop, but the loop may as\u00adsign new objects to x and y from the same iteration and maintain \nthis property. Third and .nally, any objects in the environment at the start of a loop iteration must \nbe carried over from previous it\u00aderations. Thus, the body sof loop wis checked in the environment Gw+, \nwhich ensures that objects in the environment at the start of a new iteration are not 1in the w th component \nof their loop vector; .(w), however, can be 1, which allows any objects s allocates to be recognized \nas allocated together in the same iteration.  As an aside, for a single loop the only correlation this \ntype system can recognize is when objects are allocated and linked in the same iteration of the loop \n(Rule (15)). By adding more abstract loop vector values (i.e., 2,3,4, ...) and adjusting de.nitions (e.g., \nDe.nition 3.2) the system can be extended to recognize when a value is allocated in one iteration and \nlinked to an object allocated in the next iteration, or two iterations later, and so on. However, so \nfar we have not found this extra power necessary, at least for race detection, and so we have presented \nand implemented the simpler system. Much more important is correctly handling multiple nested (and non-nested) \nloops and this is the focus of our system. We are now ready to state the type preservation lemma. Ap\u00adpendix \nA gives a proof of the key cases. LEMMA 3.3. (Type Preservation) If s,W,p,.,s . p ' ,. ' ,s ' ,C and \nW,.,G f s :G ' ,K and W f (p,.) (.,G) then W f (p ' ,. ' ) (.,G ' )and CK. Recall that the purpose of \nthe type system is to compute a set of heap effect abstractions, which we use in disjoint reachability \nanal\u00adysis (Section 4). We use type preservation to prove the soundness of heap effect abstraction. COROLLARY \n3.4. (Soundness of Heap Effect Abstraction) If s,\u00d8,.w.0,.x..,[] . p,.,s,C and \u00d8,.,G f s :G ' ,K then \nCK. Proof. From Figure 7(c), we have \u00d8f (.w.0,.x..) (.,G). It follows from Lemma 3.3 that CK. D Returning \nto Example 2.1 at the end of Section 2, the type system can prove: \u00d8,(1),G f while1 ... :G,{t\u00af1 t\u00af2} \nwhere G=[x. t\u00af1,y . t\u00af2], t\u00af1 =((1),h1),and t\u00af2 =((1),h2) EXAMPLE 3.5. Consider the following nested \nloop, with two pos\u00adsible statements (A) and (B) for the body of the inner loop: while1 (*) do x= new \nh1; while2 (*) do y= new h2; (A)x.f=y OR (B)y.f=x Statement (A) abstracts a typical programming pattern \nfor contain\u00aders: the outer object x controls access to objects y allocated in an inner loop (in realistic \nexamples all y s would be retained in e.g., a list). With statement (A), the type system can prove: \u00d8,(1,1),Gf \nwhile1 ... :G{t\u00af1 t\u00af2} where G=[x. t\u00af1,y . t\u00af2], t\u00af1 =((1,0),h1),and t\u00af2 =((1,1),h2) Statement (B) abstracts \nanother common pattern where many ob\u00adjects allocated in the inner loop point to a single object allocated \nin the outer loop (e.g., parent or root pointers in tree data structures). Using statement (B), the type \nsystem can prove: \u00d8,(1,1),Gf while1 ... :G{t\u00af2 t\u00af1} where G=[x. t\u00af1,y . t\u00af2], t\u00af1 =((1,0),h1),and t\u00af2 \n=((1,1),h2)  4. Disjoint Reachability Analysis In this section, we present disjoint reachability analysis, \nan object reachability analysis used to compute conditional must not aliasing facts. We .rst formalize \nthe notion of object reachability embod\u00adiedinthe disjoint reachability property. We then present disjoint \nreachability analysis which uses the heap effect abstraction K of a well-typed program to approximate \nthe disjoint reachability prop\u00aderty. Finally, we prove the disjoint reachability analysis sound with \nrespect to the disjoint reachability property. Consider the concrete heap effect C of a program execution; \nC contains an effect (\u00afo1 C o\u00af2)if and only if some instance .eld f of object o\u00af1 was assigned object \no\u00af2 during execution (recall Section 2.2). The (non-re.exive) transitive closure of C is C+ = S n=1 Cn,where \nCn is: DEFINITION 4.1. (Closure of C) 1. C1 =C o3). Cn+1 2. If (\u00afo1 C o\u00af2). Cn and (\u00afo2 C o\u00af3). C then \n(\u00afo1 C \u00af. If (\u00afo1 C o\u00af2) . Cn,then o\u00af2 may be reachable from o\u00af1 by n .eld dereferences. The disjoint \nreachability property is given in the .rst equation in Figure 9. It says that h . DRC (H) if and W, \n., G f x =null :G[x ..], \u00d8 (11)  W, ., G f x =new h :G[x .(. ' ,h)], \u00d8 . ' =.w.(if w .W then .(w)else \n0) (12) W, ., G f x =y :G[x .G(y)], \u00d8 (13) W, ., G f x =y.f :G[x .(.w.T, T)], \u00d8 (14) \u00bbj {t\u00af1 t\u00af2} if \nG(x)=\u00aft1 and G(y)=\u00aft2 W, ., G f x.f =y :G,K K =(15) \u00d8 otherwise ' ''' W, ., G f s1 :G,K1 W, ., G f s2 \n:G ,K2 W, ., G f s1 :G1,K1 W, ., G f s2 :G2,K2 (16) (17) W, ., G f s1; s2 :G'',K1 .K2 W, ., G f if (*)then \ns1 else s2 :G1 UG2,K1 .K2 W .{w}, ., Gw+ f s :G,K [.(w).=0] (18) W, ., G f whilew (*)do s :G,K Figure \n8. Type rules. h .DRC (H) . 0 @ \u00afo1.h .H . (\u00afo1 \u00afo2.h .H . (\u00afo2 \u00afo).C+ \u00afo).C+ \u00afo.h =h . . . \u00afo1 =\u00afo2 \n1 A h .DRK (H) . 0 B B B B B @ (\u00aft1 \u00aft3).K+ (\u00aft2 \u00aft4).K+ \u00aft3 ~\u00aft4 \u00aft3. h,\u00aft4. h .{h,T} . . . . \u00aft1. h \n=T. \u00aft2. h =T. 0 B @ \u00aft1. h .H . \u00aft2. h .H \u00ab . 2 6 4 . . \u00aft1 =\u00aft2 \u00aft1 < T .w .W :(\u00aft1..(w)=1. \u00aft3..(w)=\u00aft4..(w)=1) \n3 7 5 1 C A 1 C C C C C A Figure 9. Disjoint reachability property and disjoint reachability analysis. \nonly if no object o\u00afallocated at site h is reachable by one or more .eld dereferences from distinct objects \no\u00af1 and o\u00af2 allocated at (not necessarily distinct) sites in H. Before de.ning disjoint reachability \nanalysis we need two def\u00adinitions. We say t\u00af1 is compatible with t\u00af2, written t\u00af1 ~t\u00af2,if they agree \nin all components where neither is T: t\u00af1 ~t\u00af2 . (t\u00af1.h =\u00aft2.h . t\u00af1.h =T. t\u00af2.h =T) . .w .W :(t\u00af1..(w)=\u00aft2..(w).t\u00af1..(w)=T.t\u00af2..(w)=T) \nWe say a type t\u00afis less than Tif no component of t\u00afis T: t<\u00afT. (t.\u00af w .W :(t..(w) h=T) .. \u00af=T) To de.ne \ndisjoint reachability analysis, we de.ne a transitive clo\u00adsure K+ of K analogous to the transitive closure \nof C. Because the abstract effects in K may correspond to many concrete effects, the transitive closure \nof K is more involved than the transitive closure of C. Consider two effects (\u00aft1 t\u00af2)and (\u00aft3 t\u00af4).If \nt\u00af2 ~t\u00af3 then t\u00af2 and t\u00af3 may abstract the same object and there is some transitive relationship between \nt\u00af1 and t\u00af4. Simple transitivity is sound in all but one case: If t\u00af1..(w)=1=t\u00af4..(w)and either t\u00af2..(w)=1.or \nt\u00af3..(w) ., then we cannot conclude that \u00aft4 are al\u00ad =1t1 and \u00aflocated in the same iteration of loop \nw. In this case it is sound to replace t\u00af4..(w) by T, ensuring that there is no information about the \nrelative allocation times with respect to loop w.We de- S .ne K+ = n=1 Kn,where Kn is: DEFINITION 4.2. \n(Closure of K) 1. K1 =K t5).Kn+1 2. If (\u00aft1 t\u00af2).Kn and (\u00aft3 t\u00af4).K then (\u00aft1 \u00af provided t\u00af2 ~t\u00af3 and \n (a) t\u00af5.h =\u00aft4.h (b) .w .W : 8 < T if t\u00af1..(w)=1 . t\u00af4..(w)=1. t\u00af5..(w)= t2..(w).t3..(w).) (\u00af=1 . \u00af=1 \n: t\u00af4..(w) otherwise The following lemma proves soundness of K+ with respect to C+ . Kn LEMMA 4.3. If \nCK then Cn . Proof. [sketch] By induction on n, and using the de.nition of CK in Figure 7(b) and De.nitions \n4.1 and 4.2 of Cn and Kn , respectively. We omit the details. D The second equation of Figure 9 de.nes \ndisjoint reachability analysis. The idea is that the test h .DRK (H)is a suf.cient con\u00addition to show \nthat h . DRC (H),where CK. The quanti.\u00adcation enforces that the test hold for every pair of effects t\u00af1 \nt\u00af3 and t\u00af2 t\u00af4 in K+.Now, t\u00af1 and t\u00af2 correspond to o\u00af1 and o\u00af2 in the de.nition of the disjoint reachability \nproperty. The types t\u00af3 and t\u00af4 may abstract the same object if t\u00af3 ~t\u00af4, so these two types play the \nrole of o\u00afin the disjoint reachability property. Finally, for the pair of effects to be relevant to the \ndisjoint reachability test, both t\u00af3.h and t\u00af4.h must be either h or T. If these four conditions are \nsatis.ed, then the pair of effects is relevant to the disjoint reachability test. Intuitively, the test \nmust now check that whenever t\u00af3 and t\u00af4 are the same that t\u00af1 and t\u00af2 are also the same, which is done \nby the right-hand side of the .rst implication. If either t\u00af1.h or t\u00af2.h is Tthen the test fails; in \nthis case t\u00af1 and t\u00af2 stand for objects allocated at any allocation site and we can never guarantee the \nobjects they represent are equal. Otherwise, if either t\u00af1.h and t\u00af2.h are concrete allocation sites \nbut not in the set H then this pair of effects does not affect whether the disjoint reachability property \nholds or not. Finally if t\u00af1.h and t\u00af2.h are both in H (we are now discussing the right-hand side of \nthe second implication), then we require two things. First, t\u00af1 and t\u00af2 must correspond to the same concrete \nobject, which is enforced by requiring the types to be equal t\u00af1 =\u00aft2 andthat theyhave notop elements \nt\u00af1 < T (because, again, a top element in the loop vector would also allow the type to correspond to \nmore than one runtime object and hence the concrete objects corresponding to the two types could not \nbe shown to always be equal). The other condition, which is enforced by the last clause, is that whenever \nt\u00af1..(w)=1 (and therefore t\u00af2..(w)=1), we have t\u00af3..(w)=\u00aft4..(w)=1, which guarantees that distinct t\u00af1 \n(t\u00af2) objects (i.e., allocated in different loop iterations) reach different t\u00af3 (t\u00af4) objects. The following \ntheorem states the soundness of disjoint reacha\u00adbility analysis. THEOREM 4.4. (Soundness of Disjoint \nReachability Analysis) If CK and h. DRK (H)then h . DRC (H). Proof. [sketch] From Lemma 4.3, using the \nde.nition of CK in Figure 7(b) and the de.nitions of DRK and DRC in Figure 9. We omit the details. D \nRecall from the end of Section 3 that the type and effect system derives the heap effect K = {((1),h1) \n((1),h2)} for Exam\u00adple 2.1. In this simple example K+ = K. The single effect says that every object allocated \nat h2 is pointed to by an object allo\u00adcated at h1 in the same loop iteration; therefore h2 . DRK ({h1}) \nusing the analysis in Figure 9. Now consider the nested loops in Example 3.5. Using statement (A), we \nhave K ={((1,0),h1)((1,1),h2) and again K+ =K. Because the right side of this ef\u00adfect has a 1 in every \nposition where the left side has a 1 and the left side has no T elements, this effect says that every \nobject allocated in the inner loop is pointed to by at most one object allocated in the outer loop; thus \nh2 . DRK ({h1}). Finally, using statement (B), we have K ={((1,1),h2) ((1,0),h1) and K+ =K. Because the \nleft side of this effect has a 1 in a position where the right side has a 0, we can infer that multiple \nobjects allocated in loop 2 at h2 may point to an object allocated at h1 outside of loop 2. Thus h1 .. \nDRK ({h2}).  5. Implementation We have implemented conditional must not alias analysis using dis\u00adjoint \nreachability analysis in Chord, a static race detection system for Java. In this section, we present \nthe architecture of Chord and discuss extensions to the formalisms presented so far to handle a realistic \nlanguage like Java. Before beginning, we should explain the claim that our system is sound. Unfortunately, \nthe term sound is used rather loosely in the current literature; generally speaking, works refer to their \nalgorithm as sound if it is designed to be sound under a widely used set of assumptions, and we have \nadopted this convention. We ignore the effects of re.ection, dynamic loading, and native methods; these \nassumptions are standard for Java. In this paper we also elide checking races on accesses in constructors \nand class initializers (a standard assumption for static race detection), but this limitation is to make \ncomparison with experiments in previous work direct; Chord as described here can handle the analysis \nof constructors and class initializers with adequate precision. 5.1 Chord Architecture Chord consists \nof two phases each of which comprises a series of stages. The .rst phase centers around a context-sensitive \nmay alias analysis while the second is based on conditional must not alias analysis. 5.1.1 Context-Sensitive \nMay Alias Analysis Phase This phase consists of a series of .ve stages, called original, reach\u00adable, \naliasing, escaping,and may-happen-in-parallel. These stages are similar, but not identical, to the stages \nused in our earlier un\u00adsound race detector [33]. All stages work on six-tuples of the form (t1,c1,e1,t2,c2,e2) \nwhere e1 and e2 are expressions that may race (i.e., accesses to instance .elds, static .elds or array \nelements2)and t1,c1,t2,c2 are contexts in the sense of the context-sensitive may alias analysis around \nwhich this phase is centered. Our implementation uses k\u00adobject-sensitive may alias analysis [28, 32] \nand is parameterized by k. We .nd it necessary to distinguish two different kinds of contexts to gain \nadequate precision: c1 is the calling context of the method m containing e1.In k-object sensitivity, \nthe calling context of a method m is the allocation context of m s this parameter. For instance, if k \n= 1than the context is simply the allocation site of this.If m is a static method, which lacks the this \nparameter, the calling context is a distinguished context called [32].  t1 is the thread context of \ne1. The thread context is the calling context of the starting method of the thread that executes e1.In \nJava, this method is either the main method (in the case of the implicitly created main thread) or the \nstart() method of class java.lang.Thread (in the case of any other thread). Thus, in k-object sensitivity, \nthe thread context is either (since main is a static method) or the allocation context of the start method \ns this parameter.  t2 and c2 are similarly the thread and calling contexts of e2.  The may alias analysis \nphase begins with the original stage which considers every type-compatible pair of accesses e1 and e2 \nin every possible calling and thread context to be a possible race (where at least one of the accesses \nis a write). The goal of each of the next four stages in this phase is to rule out some pairs of accesses \nfrom the set of possible races. Very brie.y, these stages work as follows. Let . =(t1,c1,e1,t2,c2,e2)beasix-tupleasabove: \n Reachable: Not all thread and calling context combinations represent actual executions. This stage retains \n. as a possible race only if there is a path in the program s context-sensitive call graph from the entry \npoint of the thread starting method in context t1 to the program point of e1 in context c1 (and similarly \nfor t2, c2, e2). This stage is context-sensitive.  Aliasing: There can be a race between two accesses \nonly if they access the same memory location, that is, if the accesses may alias. This stage retains \n.as a possible race only if e1 in context c1 may aliases e2 in context c2. This stage is also context\u00adsensitive. \n Escaping: A memory location can be subject to a race only if it is thread-shared. This stage retains \n. only if a thread-escape analysis shows that e1 in context c1 may escape the thread in which it was \nallocated (and similarly for c2,e2). The analysis is context-and .ow-sensitive and more precise than \nthe one used in our previous work [33].  May-happen-in-parallel: Two accesses can race only if they \ncan happen in parallel. This stage retains .only if it is possible that e1 and e2 in their corresponding \nthread and calling contexts can execute at the same time. Unlike most other may-happen\u00adin-parallel analyses, \nours is oblivious to locks. The most im\u00adportant role of this .ow-and context-sensitive stage is to ana\u00adlyze \nthe thread spawning structure of the program. This stage is not present in our previous work; together \nwith the improved thread-escape analysis, this stage enables us to eliminate the  2 Our implementation \ndoes not separate array elements all elements of an array are collapsed to a single abstract location. \nhand annotations used in [33] the system presented here re\u00adquires no annotations. 5.1.2 Conditional \nMust Not Alias Analysis Phase This phase consists of a series of three stages, called global-lock, local-lock,and \nlocal-thread, that rule out additional pairs of ac\u00adcesses from the set of possible races that survive \nthe .rst phase. All three stages are based on the concept of conditional must not aliasing but differ \noperationally. Let . =(t1,c1,e1,t2,c2,e2)be a six-tuple as in the .rst phase: Global-lock: This stage \nrules out accesses guarded by global, uniquely named locks (see Section 1 for an example). Java pro\u00adgrammers \nnot only create such locks explicitly but also use such locks created by the virtual machine, for instance, \nby using static synchronized methods or by synchronizing on the class .eld of an object. This stage does \nnot use disjoint reach\u00adability analysis since it does not need to track object reachabil\u00adity: it merely \nchecks that some global lock is held along every path in the program s context-sensitive call graph from \nthe entry point of the thread starting method in context t1 to the program point of e1 in context c1, \nand that the same global lock is held similarly for t2,c2,e2.  Local-lock: This stage rules out accesses \nguarded by non-global locks. It determines whether along each pair of paths in the program s context-sensitive \ncall graph from the entry points of the thread starting methods in contexts t1 and t2 to the program \npoints of e1 in context c1 and e2 in context c2, respectively, some pair of locks e3 and e4 is held in \ncontexts c3 and c4, respectively, such that e3 and e4 are pre.xes of e1 and e2, respectively, and:  \n(P(e1,c1)n P(e2,c2)). DRK (P(e3,c3). P(e4,c4)) where P(e,c)denotes the points-to set of ein context c, \nK is the heap effect abstraction of the given program, and by e is apre.x of e ' , we mean e ' is obtained \nby one or more .eld dereferences from e. The soundness of our disjoint reachability analysis coupled \nwith the soundness of our points-to analysis guarantees that, whenever locks e3 and e4 are distinct, \naccesses e1 and e2 are also distinct and therefore race-free. Local-thread: This stage rules out thread-local \naccesses using the following variation on conditional must not alias analysis: if whenever two threads \nare distinct, then two expressions in those threads must refer to distinct locations, then those expressions \ncannot race. If neither t1 nor t2 is the . context, then the thread starting method of both threads is \nthe start method (as opposed to the main method), and we do the check as in the local-lock stage except \nthat we substitute the start methods this parameters for the locks (e3 and e4), and require the thread \ncontexts t1 and t2 be c3 and c4, respectively. The same correctness argument applies: whenever threads \ne3 and e4 are distinct, accesses e1 and e2 are distinct and therefore race-free.  5.2 Extensions Our \npresentation thus far has ignored some issues that are impor\u00adtant in implementing our algorithm for a \nrealistic programming lan\u00adguage. One such issue is the treatment of .eld reads; consider the following \nexample: 1. x.f=y 2. ... no writes to aliases of x.f ... 3. z=x.f  According to Rule 14 of Figure \n8 the information for z on line 3 is (.w.T,T)); i.e., no useful information is known for z. Unfortunately, \nthis rule is too coarse in practice, as there are situations similar to the one given above in realistic \nprograms. To improve the precision of the analysis we compute .ow\u00adsensitive must alias information for \n.elds, e.g., after line 3 we want to know that z =y (with y s allocation site and loop information). \nThe approach we use is a standard (but interprocedural) data.ow algorithm to track must alias facts on \nnames of the form x.f.g.h...; there are similar algorithms in the literature [10]. This extension also \nintroduces a new problem for a race detec\u00adtion algorithm that aims to be sound. Consider the read again \non line 3 above. The conclusion that z =y on line 3 is only valid if line 2 contains no writes to aliases \nof x.f and also no other thread writes an alias of x.f. It is not surprising that a .ow-sensitive com\u00adputation \nmust reason about potential races, but it does lead to a recursively de.ned notion of race detection, \nas computing the set of races now depends on knowing the set of races to begin with. We use a standard \niterative approach: initially we run race detection as\u00adsuming the set of races Rin the program is empty. \nAny discovered races are added to R and the entire algorithm is repeated; races in R are used to kill \nmust alias data.ow facts where appropriate (so if x.f on line 3 is part of some race in R, then the assignment \non line 3 yields (.w.T,T) for z). The entire process repeats until R reaches a .xed point.  6. Experiments \nIn this section, we evaluate our implementation on a suite of four multi-threaded Java programs and provide \na detailed comparison with our previous work [33].3 Figure 10 shows, for each program in our benchmark \nsuite, the number of application and library classes and lines of Java source code in the call graph \ncomputed using k\u00adobject-sensitive alias analysis, the value of kused, the total running time of Chord, \nand a brief description of the program. Figure 11 shows the results of the .rst phase of our imple\u00admentation. \nColumns (A) and (B) show the number of six-tuples (t1,c1,e1,t2,c2,e2)and the number of pairs (e1,e2)in \nthe set of possible races at the end of the .rst (original)and last (may\u00adhappen-in-parallel) stages, \nrespectively, of this phase.4 For com\u00adparison with our earlier race checker [33], we partition the lat\u00adter \nsix-tuples and pairs into likely and unlikely races: a six-tuple (t1,c1,e1,t2,c2,e2) retained after the \nmay-happen-in-parallel stage is an unlikely race if and only if either of the following holds: t1 = \nt2, in which case it is most likely a thread-local pair of accesses, or  along every pair of paths in \nthe program s context-sensitive call graph from the entry points of the thread starting methods in contexts \nt1 and t2 to the program points of e1 and e2 in contexts c1 and c2, respectively, some pair of locks \ne3 and e4 is held in contexts c3 and c4, respectively, such that P(e3,c3)= P(e4,c4)={h}, that is, their \npoints-to sets are singleton and equal, in which case it is most likely a pair of accesses guarded by \na common lock.  Notice that both the above checks use may alias information to approximate must alias \ninformation. The approximation is effective for bug-.nding in our earlier race checker: the user can \nchoose to inspect only the small number of likely races that survive both the above checks. However, \nthe approximation is also unsound and can result in false negatives buried in the large number of unlikely \nraces 3 We have not yet attempted the largest benchmarks used in our previous work [33], but we believe \nthis algorithm can scale to those programs. 4 The pairs count is the number of unique pairs of expressions \nappearing in all six-tuples in many cases the same expressions have races in multiple contexts. app \nclasses lib classes app LOC lib LOC k time brief description philo 2 423 84 110,582 1 3m14s Dining Philosophers \nProblem solver elevator 5 425 531 111,147 1 5m43s A real-time discrete event simulator tsp 4 426 706 \n110,954 1 3m21s Traveling Salesman Problem solver from ETH ftp 118 478 21897 116,026 2 7m21s Apache FTP \nServer Figure 10. Benchmark characteristics.  that are uninspected. For instance, the .rst check (t1 \n= t2)prevents any race between a pair of threads spawned at the same allocation site from being reported \nas a likely race. Likewise, the second check does not do a disjoint reachability analysis style check \nto determine whether the same object accessed by e1 and e2 is reachable from distinct locks allocated \nat site h. While our earlier race checker stops at the end of the .rst phase and presents the likely \nraces to the user, our current race checker does not differentiate between likely and unlikely races \nand proceeds to perform the second phase on all possible races retained at the end of the .rst phase. \nThe results of the second phase are shown in Figure 12. Column (C) shows the number of possible races \nretained after applying the global-lock stage to the results of the .rst phase, while Column (D) shows \nthe number of possible races retained after the combined application of the local\u00adlock and local-thread \nstages to the results of the global-lock stage. We present the results for these two stages combined \nsince they are similar (they both employ disjoint reachability analysis), but Figure 13 shows the number \nof possible races retained after the global-lock stage that were proven to be guarded by a non-global \nlock (Column (F)) and proven to be thread-local (Column (G)) by these two stages. Column (H) shows the \nnet effectiveness of our disjoint reachability analysis. Notice that the numbers of six-tuples in Columns \n(F) and (G) may not add up to those in Column (H) since certain six-tuples may be proven to be both, \nguarded by a non-global lock and thread-local. This may happen if application code creates and manipulates \nthread-local data using library classes like java.util.Vector and java.io.* that use synchronization \nextensively to ensure thread-safety of multi-threaded clients. Pairs (as opposed to six-tuples) of accesses \nare even more likely to .gure in both columns, since reusable code is polymorphic in calling/thread context, \nwith accesses in such code being guarded by a lock in one calling/thread context and thread-local in \nanother. The effectiveness of the global-lock stage is evident in the results for tsp and ftp.The tsp \nbenchmark exclusively uses global locks: the number of pairs retained reduces from 494 to 140 in the \nglobal-lock stage, and from 140 to 30 in the local-thread stage, but no pairs are eliminated in the local-lock \nstage. The ftp benchmark also uses global locks heavily, though they are primarily in the library code \nexercised by this benchmark. The effectiveness of disjoint reachability analysis is clear in the results \nfor all four programs: 30 of the 33 pairs surviving after the global-lock stage for philo are proven \nthread-local (the remain\u00ading 3 are real races), while the majority of such surviving pairs for elevator \nand tsp are proven guarded by a non-global lock. Fi\u00adnally, many pairs are proven both guarded by a non-global \nlock and thread-local for ftp because this program creates and manipulates thread-local data using extensively \nsynchronized library classes. Finally, the effectiveness of the conditional must not alias phase is illustrated \nin the number of real races and false alarms reported in Column (D) in Figure 12, as compared to those \nresulting from the likely races produced by the .rst phase, shown in Column (E) in Figure 12. Our new \nalgorithm found a total of 202 real races (count\u00ading pairs) in all four benchmarks; using likely races \n.nds only 122, showing that our sound system can .nd signi.cantly more races in real programs. The number \nof false alarms is generally larger in our new race checker; 115 total false positives of 317 reports \nis a 36% false positive rate. Most of the false positives in our new algorithm are the result of engineering \nshortcomings that are straightforward to remove with additional effort. Notice that the large numbers \nof unlikely races reported in Column (B) in Figure 11 that were left uninspected in our earlier work \nare almost completely eliminated. Signi.cantly, 80 of these unlikely races turn out to be real races, \na fact that is witnessed by the increase in the numbers of real races reported in Column (D) over those \nin Column (E) in Figure 12.  7. Related Work In this section we very brie.y survey the large literature \non race detection (including dynamic techniques, static techniques, and work on checking atomicity) and \nthe considerably smaller literature on problems related to conditional must not alias analysis. We begin \nby noting that our notion of loop vectors harkens back to the ideas of iteration space and dependence \ndistance in work on vectorizing compilers. Loop vectors are points in the iteration space of the program, \nand our algorithm can be thought of as tracking dependent statements of distance 0 (i.e., in the same \niteration). We are not aware of any deeper connections to the large literature on program parallelization; \nour focus is on linked data structures and locking while parallelizing compilers focus primarily on array \nreferences. 7.1 Dynamic Race Detection To the extent that race detection is currently used in practice, \nprac\u00adtical race detectors are primarily dynamic. The most popular form of dynamic race detection is the \nlockset algorithm as exempli\u00ad.ed by the Eraser tool [40]. Recent work has greatly improved the order-of-magnitude \nslowdowns of the original implementations [2, 43, 44] to the point that runtime overhead is generally \nmuch less than 50% [5]. Other recent work has combined approaches based on Lamport s happens-before relation \n[1, 7, 8, 11, 26, 31, 38, 41] with the lockset algorithm to mitigate the disadvantages of each [12, 23, \n34, 35, 47]. Dynamic race detection suffers from the well-known problems of every dynamic analysis, namely \nthat .rst it cannot be used with a partial, open program (such as a library) and second even when a closed \nprogram is available dynamic checking is dependent on having adequate input. Note that the lockset algorithm \nonly depends on the set of locks held for each location and not the order in which locks are held, so \na strength of the lockset algorithm is that it does not require a particular interleaving of thread executions \nto occur to detect races. But, for example, no dynamic race detector can .nd races in code that is not \nexecuted at all.  7.2 Static Race Detection Static race detection offers the promise of being able to \n.nd races before programs are run or, in the case of libraries, even before they are fully written. Given \nthe non-deterministic nature of races, the advantages of static analysis would seem greater for race \ndetec\u00adtion than many other program veri.cation problems. The history of static race detection has seen \nconsiderable theoretical progress using a variety of approaches (.ow-insensitive type systems [3, 4, \n15, 16, 22, 36, 39], .ow-sensitive versions of the static lockset al\u00adgorithm [6, 13, 42], or path sensitive \nmodel checkers [25, 37]) but until recently techniques were not known that scaled with suf.cient precision \nto .nd large numbers of bugs in realistic programs. (A) after original stage (B) after may-happen-in-parallel \nstage likely unlikely total hexts pairs hexts pairs hexts pairs hexts pairs philo 123344 926 0 0 35 35 \n35 35 elevator 55680 662 0 0 320 305 320 305 tsp 298045 3379 4 4 490 490 494 494 ftp 97661557 55039 352 \n156 3733 1624 4085 1628 Figure 11. Results for phase 1: Context-sensitive may alias analysis.  (C) after \nglobal-lock stage (D) after (local-lock + local-thread)stages (E) classi.cation of likely races real \nraces false alarms total real races false alarms hexts pairs hexts pairs hexts pairs hexts pairs hexts \npairs hexts pairs philo 33 33 3 3 0 0 3 3 0 0 0 0 elevator 320 305 0 0 0 0 0 0 0 0 0 0 tsp 140 140 12 \n12 18 18 30 30 0 0 4 4 ftp 2780 1147 761 187 258 97 1019 284 297 122 55 34 Figure 12. Results for phase \n2: Conditional must not alias analysis.  (F) proven local-lock (G) proven local-thread (H) proven race-free \nhexts pairs hexts pairs hexts pairs philo 30 30 0 0 30 30 elevator 52 37 268 268 320 305 tsp 0 0 110 \n110 110 110 ftp 1398 613 1156 577 1761 863 Figure 13. Effectiveness of disjoint reachability analysis. \n Our own previous work, outlined in Section 5, scales reasonably well and .nds many bugs in both open \nand closed programs [33]. Earlier work by Choi et al. [6] took the same basic approach, but found that \nscalability problems hampered effectiveness, probably because the idea of k-object-sensitive analysis \ndid not exist then. As discussed in Section 1, however, the .nal lock analysis phase of [33] is unsound, \nusing a cheaper may alias analysis to decide when two abstract locks represent the same concrete lock, \na prob\u00adlem requiring must alias analysis. Our desire to remove this limita\u00adtion is the inspiration for \nthis paper. Instead of modifying the origi\u00adnal algorithm to use must alias information to show when two \nlocks are the same, we instead have chosen to focus on the dual prob\u00adlem of showing when two locks are \ndifferent. To carry out sound race detection, however, we must show that if two locks are differ\u00adent \nthen they protect different locations, which leads directly to the more general de.nition of conditional \nmust not alias analysis. Con\u00additional must not alias analysis requires considerably deeper analy\u00adsis \nof the heap and correspondingly of how the heap is constructed than traditional alias analyses distinguishing \nmultiple objects al\u00adlocated at the same site is crucial, as is maintaining correlations between objects \nthat are allocated and linked together.  7.3 Other Analysis Approaches Disjoint reachability for data \nstructures (e.g., proving that two lists constructed of separate elements are disjoint) is an old problem. \nAlgorithms in this area range from .ow-sensitive approximations of heap shape ([9] is an early example) \nto very powerful decision procedures [27, 30]. Our notion of disjoint reachability is less precise (e.g., \nit is .ow-insensitive) but easier to scale to large programs and gives good results for race detection. \nOwnership types express the idea that among all pointers to an object, one is often special in that it \nhas more operations than other pointers. In the context of race detection, ownership can be used to prove \nencapsulation (that an object is the exclusive access to another object), which in turn can prove conditional \nmust not alias\u00ading facts: if two objects are distinct, any objects they encapsulate must be distinct. \nThere are algorithms for inferring ownership [24] and encapsulation [21] and ownership types have been \nexploited in race detectors [3]. While encapsulation is suf.cient to prove con\u00additional must not aliasing, \nit is not necessary. Roughly speaking, ownership/encapsulation are properties of how an object is con\u00adstructed, \nwhile conditional must not aliasing also considers the spe\u00adci.c pointers through which an object is used; \nthis more re.ned treatment can fully automatically check race freedom for objects that are not encapsulated \nand without ownership types. Another related approach is that a correlation exists between two objects \nif they are used consistently together [36]. For race detection, correlation means a particular lock \nis always used to guard a particular location. Correlation analysis infers which locks always guard which \nlocations. Our approach does not require locks and locations to be correlated; because each potentially \nracing pair of expressions is handled separately, different locks may be used to prove race freedom for \nthe same expression in different pairs. 7.4 Atomicity Checking Much recent work on veri.cation of concurrent \nprograms has fo\u00adcused on checking atomicity rather than race freedom [2, 14, 17 20, 39, 45, 46]. Atomicity \nis arguably a simpler and more natu\u00adral property for programmers and experimental work suggests that \nprogrammers most often use locks to achieve atomicity. Regardless of whether future languages rely primarily \non atomicity or lock\u00ading, however, checking race freedom will be an important prob\u00adlem: existing concurrent \nlanguages will continue to use lock-based synchronization idioms heavily, and many algorithms for checking \natomicity (in particular, those based on Lipton s theory of reduction [29]) reduce to checking race freedom. \n  8. Conclusions We have introduced conditional must not aliasing and shown its application to static \nrace detection. We have also presented dis\u00adjoint reachability analysis, an object reachability analysis \nthat is useful for computing conditional must not alias facts. We have im\u00adplemented conditional must \nnot alias analysis using disjoint reacha\u00adbility analysis in Chord, a static race checker for Java, and \napplied it to a suite of Java programs. The resulting system is fully automatic, reasonably ef.cient, \nand produces relatively few false positives. Acknowledgments We thank the anonymous POPL reviewers for \ninsightful comments. This research was supported in part by NSF grants CCF-0430378 and CNS-0509558, a \ngift from Intel, and a Microsoft fellowship.  A. Proof of Type Preservation We state a useful fact of \nenvironment abstraction (Figure 7(c)) that is needed in proving type preservation. FACT A.1. (Loopset \nWeakening) If W f (p,.) (.,G)and W ' .W then W ' f(p,.) (.,G). Proof. [of Type Preservation] By induction \non the structure of '' ' the derivation of s,W,p,.,s . p ,. ,s ,C. There are 10 cases depending on which \none of rules (1) (10) in Figure 5 was used last in the derivation. For brevity, we only provide the proof \nfor the two most interesting cases. 1. Rule (5). We have s = x.f = y. There are two sub-cases depending \nupon whether .(y)is null or non-null. We only prove the latter more interesting sub-case. We have: (a): \n.(x)=\u00afo1 and .(y)=\u00afo2 and (b): s,W,p,.,s . p,.,s[\u00afo1.f .o\u00af2],{o\u00af1 C o\u00af2}. From s =x.f =y and hypothesis \nW,.,Gfs :G ' ,K of the lemma and rule (15) in Figure 8, we have: (c): W,.,G f s :G,K where: j {t\u00af1 t\u00af2} \nif G(x)=\u00aft1 and G(y)=\u00aft2 K = \u00d8 otherwise We need to prove: (A): W f(p,.) (.,G)and (B): {o\u00af1 C o\u00af2}. K. \nThe proof of (A) is trivial since (A) is one of the hypotheses of the lemma. To prove (B), it suf.ces \nto prove (see Figure 7(b)): (d): .(\u00aft1 t\u00af2).K :(o\u00af1,o\u00af2).(\u00aft1,t\u00af2). Proof of (d): From hypothesis W \nf (p,.) (.,G) of the lemma, we have (see item (2) and item (3)(b) in Figure 7(c)): (e): .z .V : .(z) \nG(z)and (f): .w . W : .k . N : .z . V :((.(z)=\u00afo . G(z)= t\u00af. \u00afw)=1) . \u00afw)=k). t..(o.p( From (a) and \n(e), we have (see defn. of ot in Figure 7(a)): (g): G(x)=\u00aft1 and G(y)=\u00aft2 and (h): o\u00af1 t\u00af1 and o\u00af2 t\u00af2. \nFrom (c) and (g), we have: (i): K ={t\u00af1 t\u00af2}. From (f) and (a) and (g), we have: (j): .w .W : .k .N :((t\u00af1..(w)=1 \n. o\u00af1.p(w)=k) .(\u00aft2..(w)=1 . o\u00af2.p(w)=k)). From (h) and (j), we have (k): (\u00afo1,o\u00af2) . (\u00aft1,t\u00af2)(see Figure \n7(b)). From (i) and (k), we have (d). 2. Rule (10). We have s =whilew (*)do s ' and ' ''' (a): s ,W .{w},p[w \n.p(w)+1],.,s .p ,. ,s ,C1 and ''' '''''' (b): s,W,p ,. ,s .p ,. ,s ,C2. From s =whilew (*)do s ' and \nhypothesis W,.,Gfs :G ' ,K of the lemma and rule (18) in Figure 8, we have: (c): W,.,G f s :G,K and (d): \nW .{w},.,Gw+ f s ' :G,K and (e): .(w).=0. We need to prove: '' '' (A): W f(p ,. ) (.,G)and (B): (C1 \n.C2) K. From hypothesis W f(p,.) (.,G)of thelemma, wehave (see Figure 7(c)): ' '' (f): .w .W :p(w ) .(w \n)and (g): .x . V :.(x) G(x)and (h): .w ' .W : .k ' .N : ' '' (.(w )=1 . p(w )=k ). (.x .V :((.(x)=\u00aft \n. \u00afw ' o . G(x)=\u00aft..()=1) . \u00afw '' )) o.p()=k We will .rst prove: (i): W .{w}f (p[w .p(w)+1],.) (.,Gw+). \nFrom Figure 7(c), this requires proving: (i.1): .w ' .W .{w}: p[w .p(w)+1](w ' ) .(w ' ) (i.2): .x .V \n: .(x)Gw+(x) (i.3): .w ' .W : .k ' .N : ' '' (.(w )=1 . (p[w .p(w)+1])(w )=k ). o . Gw+t . \u00af' (.x .V \n:((.(x)=\u00af(x)=\u00aft..(w )=1) . \u00afw ' )=k ' )). o.p( Proof of (i.1): From (e), we have (j): .(w)=1 . .(w)=T. \nFrom (p(w)+1)> 0and (j), we have (k): (p(w)+1) .(w) (see defn. of i i in Figure 7(a)). From (f) and (k), \nwe have (i.1). Proof of (i.2): Immediate from (g) and defn. 3.2 of Gw+ and the defn. of ot in Figure \n7(a). Proof of (i.3): It suf.ces to prove: (l): .k .N : (.(w)=1 . (p[w .p(w)+1])(w)=k). w+(  (.x .V \n:((.(x)=\u00afo . Gx)=\u00aft . \u00afw)=1) . t..( \u00afw)=k)). o.p( since we will have (i.3) from (h) and (l). Proof of \n(l): Choose k =(p[w .p(w)+1])(w)whence we have (m): .(w)=1 . (p[w .p(w)+1])(w)=k.Also, from defn. 3.2 \nof Gw+,we have .x . V :(Gw+(x)=\u00aft . \u00afw) =1) whence we trivially have (n): .x . V : t..(. w+( ((.(x)=\u00afx)=\u00aft..(w)=1) \n. \u00af o . Gt . \u00afo.p(w)= k).From (m) and (n),we have (l). We now prove (A) and (B). From (a) and (d) and \n(i) and the induction hypothesis, we have (o): W .{w}f (p ' ,. ' ) (.,G) and (p): C1 K. From (o) and \nFact A.1, we have (q): W f (p ' ,. ' ) (.,G). From (b) and (c) and (q) and the induction hypothesis, \nwe have (A) and (r): C2 K.From (p) and (r), we have (B) (see Figure 7(b)). D  References [1] S. Adve, \nM. Hill, B. Miller, and R. Netzer. Detecting data races on weak memory systems. In Proceedings of ISCA \n91, pages 234 243, 1991. [2] R. Agarwal, A. Sasturkar, Wang L, and S. Stoller. Optimized run-time race \ndetection and atomicity checking using partial discovered types. In Proceedings of ASE 05, pages 233 \n242, 2005. [3] C. Boyapati, R. Lee, and M. Rinard. Ownership types for safe pro\u00adgramming: Preventing \ndata races and deadlocks. In Proceedings of OOPSLA 02, pages 211 230, 2002. [4] C. Boyapati and M. Rinard. \nA parameterized type system for race-free Java programs. In Proceedings of OOPSLA 01, pages 56 69, 2001. \n[5] J. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, and M. Sridha\u00adran. Ef.cient and precise datarace \ndetection for multithreaded object\u00adoriented programs. In Proceedings of PLDI 02, pages 258 269, 2002. \n[6] J. Choi, A. Loginov, and V. Sarkar. Static datarace analysis for multithreaded object-oriented programs. \nTechnical Report RC22146, IBM Research, 2001. [7] J. Choi, B. Miller, and R. Netzer. Techniques for debugging \nparallel programs with .owback analysis. ACM TOPLAS, 13(4):491 530, 1991. [8] M. Christiaens and K. Brosschere. \nTRaDe: A topological approach to on-the-.y race detection in Java programs. In Proceedings of JVM 01, \npages 105 116, 2001. [9] P. Cousot and R. Cousot. Static determination of dynamic properties of generalized \ntype unions. In Language Design for Reliable Software, pages 77 94, 1977. [10] M. Das, S. Lerner, and \nM. Seigle. ESP: Path-sensitive program veri.cation in polynomial time. In Proceedings of PLDI 02, pages \n57 68, 2002. [11] A. Dinning and E. Schonberg. An empirical comparison of moni\u00adtoring algorithms for \naccess anomaly detection. In Proceedings of PPoPP 90, pages 1 10, 1990. [12] A. Dinning and E. Schonberg. \nDetecting access anomalies in programs with critical sections. In Proceedings of PADD 91, pages 85 96, \n1991. [13] D. Engler and K. Ashcraft. RacerX: Effective, static detection of race conditions and deadlocks. \nIn Proceedings of SOSP 03, pages 237 252, 2003. [14] C. Flanagan. Verifying commit-atomicity using model-checking. \nIn Proceedings of SPIN 04, pages 252 266, 2004. [15] C. Flanagan and M. Abadi. Types for safe locking. \nIn Proceedings of ESOP 99, pages 91 108, 1999. [16] C. Flanagan and S. Freund. Type-based race detection \nfor Java. In Proceedings of PLDI 00, pages 219 232, 2000. [17] C. Flanagan and S. Freund. Atomizer: a \ndynamic atomicity checker for multithreaded programs. In Proceedings of POPL 04, pages 256 267, 2004. \n[18] C. Flanagan, S. Freund, and M. Lifshin. Type inference for atomicity. In Proceedings of TLDI 05, \npages 47 58, 2005. [19] C. Flanagan and S. Qadeer. A type and effect system for atomicity. In Proceedings \nof PLDI 03, pages 338 349, 2003. [20] C. Flanagan and S. Qadeer. Types for atomicity. In Proceedings \nof TLDI 03, pages 1 12, 2003. [21] S. Ghemawat, K. Randall, and D. Scales. Field analysis: Getting useful \nand low-cost interprocedural information. In Proceedings of PLDI 00, pages 334 344, 2000. [22] D. Grossman. \nType-safe multithreading in Cyclone. In Proceedings of TLDI 03, pages 13 25, 2003. [23] J. Harrow. Runtime \nchecking of multithreaded applications with visual threads. In Proceedings of SPIN 00, pages 331 342, \n2000. [24] D. Heine and M. Lam. A practical .ow-sensitive and context-sensitive C and C++ memory leak \ndetector. In Proceedings of PLDI 03, pages 168 181, 2003. [25] T. Henzinger, R. Jhala, and R. Majumdar. \nRace checking by context inference. In Proceedings of PLDI 04, pages 1 13, 2004. [26] L. Lamport. Time, \nclocks, and the ordering of events in a distributed system. CACM, 21(7):558 565, 1978. [27] T. Lev-Ami, \nN. Immerman, T. Reps, S. Sagiv, S. Srivastava, and G. Yorsh. Simulating reachability using .rst-order \nlogic with appli\u00adcations to veri.cation of linked data structures. In Proceedings of CADE 05, pages 99 \n115, 2005. [28] O. Lhot\u00b4ak and L. Hendren. Context-sensitive points-to analysis: is it worth it? In Proceedings \nof CC 06, 2006. [29] R. Lipton. Reduction: A method of proving properties of parallel programs. CACM, \n18(12):717 721, 1975. [30] S. McPeak and G. Necula. Data structure speci.cations via local equality axioms. \nIn Proceedings of CAV 05, pages 476 490, 2005. [31] J. Mellor-Crummey. On-the-.y detection of data races \nfor programs with nested fork-join parallelism. In Proceedings of SC 91, pages 24 35, 1991. [32] A. Milanova, \nA. Rountev, and B. Ryder. Parameterized object sensi\u00adtivity for points-to and side-effect analyses for \nJava. In Proceedings of ISSTA 02, pages 1 11, 2002. [33] M. Naik, A. Aiken, and J. Whaley. Effective \nstatic race detection for Java. In Proceedings of PLDI 06, pages 308 319, 2006. [34] R. O Callahan and \nJ. Choi. Hybrid dynamic data race detection. In Proceedings of PPoPP 03, pages 167 178, 2003. [35] E. \nPozniansky and A. Schuster. Ef.cient on-the-.y data race detection in multithreaded C++ programs. In \nProceedings of PPoPP 03, pages 179 190, 2003. [36] P. Pratikakis, J. Foster, and M. Hicks. LOCKSMITH: \nContext\u00adsensitive correlation analysis for race detection. In Proceedings of PLDI 06, pages 320 331, \n2006. [37] S. Qadeer and D. Wu. KISS: Keep it simple and sequential. In Proceedings of PLDI 04, pages \n14 24, 2004. [38] M. Ronsse and K. Bosschere. RecPlay: A fully integrated practical record/replay system. \nACM TOCS, 17(2):133 152, 1999. [39] A. Sasturkar, R. Agarwal, L. Wang, and S. Stoller. Automated type-based \nanalysis of data races and atomicity. In Proceedings of PPoPP 05, pages 83 94, 2005. [40] S. Savage, \nM. Burrows, G. Nelson, P. Sobalvarro, and T. Anderson. Eraser: A dynamic data race detector for multi-threaded \nprograms. In Proceedings of SOSP 97, pages 27 37, 1997. [41] E. Schonberg. On-the-.y detection of access \nanomalies. In Proceed\u00adings of PLDI 89, pages 285 297, 1989. [42] N. Sterling. WARLOCK -a static data \nrace analysis tool. In Proceed\u00adings of the Usenix Winter 1993 Technical Conference, pages 97 106, 1993. \n[43] C. von Praun and T. Gross. Object race detection. In Proceedings of OOPSLA 01, pages 70 82, 2001. \n[44] C. von Praun and T. Gross. Static con.ict analysis for multi-threaded object-oriented programs. \nIn Proceedings of PLDI 03, pages 115 128, 2003. [45] L. Wang and S. Stoller. Static analysis of atomicity \nfor programs with non-blocking synchronization. In Proceedings of PPoPP 05, pages 61 71, 2005. [46] L. \nWang and S. Stoller. Runtime analysis of atomicity for multi\u00adthreaded programs. IEEE TSE, 32(2):93 110, \n2006. [47] Y. Yu, T. Rodeheffer, and W. Chen. RaceTrack: Ef.cient detection of data race conditions via \nadaptive tracking. In Proceedings of SOSP 05, pages 221 234, 2005. \n\t\t\t", "proc_id": "1190216", "abstract": "Race detection algorithms for multi-threaded programs using the common lock-based synchronization idiom must correlate locks with the memory locations they guard. The heart of a proof of race freedom is showing that if two locks are distinct, then the memory locations they guard are also distinct. This is an example of a general property we call <i>conditional must not aliasing</i>: Under the assumption that two objects are not aliased, prove that two other objects are not aliased. This paper introduces and gives an algorithm for conditional must not alias analysis and discusses experimental results for sound race detection of Java programs.", "authors": [{"name": "Mayur Naik", "author_profile_id": "81100223912", "affiliation": "Stanford University", "person_id": "P195415", "email_address": "", "orcid_id": ""}, {"name": "Alex Aiken", "author_profile_id": "81100399954", "affiliation": "Stanford University", "person_id": "PP39041079", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1190216.1190265", "year": "2007", "article_id": "1190265", "conference": "POPL", "title": "Conditional must not aliasing for static race detection", "url": "http://dl.acm.org/citation.cfm?id=1190265"}