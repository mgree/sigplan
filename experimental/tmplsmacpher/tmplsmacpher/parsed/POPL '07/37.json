{"article_publication_date": "01-17-2007", "fulltext": "\n Geometry of Synthesis Astructured approach to VLSI design Dan R. Ghica University of Birmingham drg@cs.bham.ac.uk \nAbstract We propose a new technique for hardware synthesis from higher\u00adorder functional languages with \nimperative features based on Reynolds s Syntactic Control of Interference. The restriction on contraction \nin the type system is useful for managing the thorny issueof sharingofphysical circuits.We usea semantic \nmodel in\u00adspired by game semantics and the geometry of interaction, and express it directly as a certain \nclass of digital circuits that form a cartesian, monoidal-closed category.A soundness resultisgiven, \nwhich is also a correctness result for the compilation technique. Categories and Subject Descriptors \nF.3.2 [Semantics of Pro\u00adgramming Languages]: Denotational semantics; B.7.1[Types and Design Styles]: \nVLSI General Terms Design, Languages, Theory Keywords Syntactic Control of Interference, Geometry of \nInter\u00adaction,game semantics, synthesis 1. Introduction In this paper we propose a new technique for VLSI \ndesign that allows the synthesis of digital circuit speci.cations from a generic, higher-order functional \nprogramming language with imperative features. The main innovative feature of this technique is the use \nof a se\u00admantic model inspired by and related to game semantics [3, 11] and Geometryof Interaction [10],a \nsemantic model that canbeex\u00adpressed directly as a certain class of digital circuits. This source of inspirationis \nacknowledged,but the paperis self-contained andfa\u00admiliarity with these two topics is not required. On \nthe contrary, this paper could serve as a motivating introduction to their theoretical considerations. \nAnother innovation is the choice of the programming language, Basic Syntactic Control of Interference \n(bSCI) [19, 16]. It is an Algol-like language [20] with af.ne typing. This turns out to be a highly suitable \nlanguage for two reasons. First, the af.ne type system is a precise tool for the control of sharing of \nresources in the programming language, an issue which is highly relevant in the context of hardware synthesis. \nSecond, the call-by-name procedure mechanism of Algol does not require closures and can be, therefore, \nsynthesised inexpensively. Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page.To \ncopyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. POPL 07 January 17 19, 2007, Nice, France. Copyright c &#38;#169; 2007ACM 1-59593-575-4/07/0001... \n$5.00. We present a class of digital circuits which we call handshake circuits, and which are shown \nto form a closed monoidal category, and therefore provide the appropriate structure for interpreting \nthe af.ne featuresofthe language.Wethenshowhowa further re.ned class of circuits which we call simple-handshake \ncircuits forms a Cartesian sub-category of the previous, and therefore has the right structure for the \ninterpretation of products. This feature is needed for modelling sharing of resources in the language.We \nshow that this model of bSCI is sound relative to an operational de.nition of the language.Thisisalsoaproofof \ncorrectnessforthe synthesisof digital circuits from bSCI programs. The most striking feature of this \nsynthesis technique is the simplic\u00adity of the resulting circuitry. Abstraction and application are syn\u00adthesised \nsimply as wiring of the circuit representing the body of the function to that of the argument. Some of \nthe other operations, such as sequential composition, assignment and dereferencing of variables reduce \nalso to wiring. The rest of the constructs of the language require only a handful of basic circuits. \nAn important issue in hardware synthesis is that of concurrency. Because hardware is naturally concurrent, \nthe implementation of concurrent programs is no more expensive than that of sequen\u00adtialprograms. ConcurrencyintheframeworkofbSCIdoesnotal\u00adlow \nshared-variable inter-process communication, and we examine several pragmatic options for overcoming \nthis limitation. Some of these techniques are potentially unsound. As a proof of concept, we have implemented \na prototype compiler from bSCItoVerilog speci.cationsof VLSI circuits, basedona naive realisation of \nhandshake circuits. 2. The base language The issue of physical resource has long been recognised as crucial \nin current approaches to programming languages. This notion most commonly refers to memory locations, \nespecially in conjunction withheap management,butinits most general instanceit refersto anycomputationally \nand logically meaningful interaction between software and the underlying machinery. Managing the use \nof re\u00adsources in programs, through type systems and logics, has been an active area of research for some \ntime. The importance of resource management in hardware synthesis be\u00adcomesparamount. Synthesis,inits \npurest form, representsa com\u00adplete shift from the logical realm of software to the physical world of \ncircuitry. Every sub-term ofthe program, when synthesised, be\u00adcomesaphysical resource which mustbe managed. \nPhysical resources, unlike their logical counterparts, cannot be as easily created, duplicated and especially \nshared. This last point is painfully obvious in writing programs that deal with dynamic mem\u00adory. Writing \nsuch programs correctly is dif.cult precisely because ofthesubtleissuesthatariseinsharingphysical resources,memory \nlocations in this case. In synthesis, as every sub-term of a program becomes a physical entity, every \nprogram interaction, more pre\u00adcisely every procedure call, involves some potentially dangerous sharing \nof circuitry. These considerations motivate our choice of Basic SCI (bSCI) [16, Sec. 7.1].We.rst introduce \nthis language, then we showadifferent but equivalent presentation intended to make the issues related \nto sharing even more explicit. The primitive types of the language are commands, memory cells and (boolean) \nexpressions: s ::= com | cell | exp. The static nature of hardware forces us to use a bounded data type. \nFor simplicity we only deal with booleans, but bounded integers can be added in a straightforward way. \nAdditionally, the language contains function types and products: . ::= s | . \u00d7 .' | . . .. What is peculiar \nabout the types above is that pairs of terms may share identi.ersbut functions may not share identi.ers \nwith their arguments.Thisismadeexplicitbythe following typing rules(also known as the af.ne .-calculus). \nTerms have types, described by typing judgments of the formG f M : ., where G= x1 : .1,...xn : .n is \na variable type assignment, M is a term and . the type of the term. Identity G f M : . Weakening x : \n. f x : . G,x : .' f M : . G,x : .' f M : . . Introduction G f .x.M : .' . . G f F : .' . . . f M : .' \n. Elimination G, . f FM : . G f M : .' G f N : . \u00d7 Introduction G f(M, N) : .' \u00d7 . The language also \ncontains a number of (functional) constants for state manipulation and (structured) control. 1: exp constant \n0: exp constant skip : com no-op asg : cell \u00d7 exp . com assignment der : cell . exp dereferencing seq \n: com \u00d7 com . com sequencing seq : com \u00d7 exp . exp sequencing with boolean op : exp \u00d7 exp . exp logical \noperations if : exp \u00d7 com \u00d7 com . com branching while : exp \u00d7 com . com iteration newvar :(cell . com) \n. com local variable newvar :(cell . exp) . exp local variable. Product has syntactic precedence over \narrow, which associates to the right. This functionalised syntax may seem peculiar but a more conventional \nsyntax can be readily encoded into it. For now we are omitting parallel composition of commands and recursion,but \nwe shall consider themin later sections. 2.1 Operational semantics We call termsG f M : . semi-closed \nif all free identi.ers are of type cell. The operational semantics of the language is given by a big-step \nrule of theform M, s . T,s' where M is a semi-closed term, s : dom G .{0, 1} a state and T a terminal \n(0, 1, skip, lambda abstraction). '' B, s . b, s' V, s' . v, sasg(V, B),s . skip, (s'' | v . b) ' V,s \n. v, s '' der V . s(v),s ' C, s . skip,sM,s' . T,s'' seq(C, M),s . T,s'' M, s . (v . 0) . T,s' . (v . \nb) newvar(.v.M),s . T,s' B1,s . b1,s1 B2,s1 . b2,s2 b = b1 op b2 op(B1,B2),s . b, s2 B, s . b, s' Mi,s' \n. i, s'' if(B, M1,M0),s . T,s'' ' B, s . 0,s ' while(B, C),s . skip,s ' '' ''' B, s . 1,sC,s' . skip,swhile(B, \nC),s'' . skip,s ''' while(B, C),s . skip,s M, s . .x.M',s [M'' MM'',s . M'/x],s If a term has no free \nvariables we sayit is closed. If for a closed term M, \u00d8. T, \u00d8 we write M .. 3. Acategory of digital circuits \nWe give a denotational semantics for bSCI in terms of digital circuits. The semanticsis directly inspiredby \nthegame-semantic model for similar languages [4], especially in its automata-theoretic formulation [9]. \nThere are, however important distinctions between the game and digital-circuit semantics, which will \nbe discussed later. We consider the common conceptual model of (especially asyn\u00adchronous) VLSI circuits \nas being de.ned by an interface and by behaviour. The interface is a set of ports, designated either \nas in\u00adput or output. Ports consume (produce) signals, which are called inputs (outputs). The behaviour \nof a circuit is de.ned by the way it produces outputs in response to the inputs coming from its en\u00advironment.Two \ncircuits with the same interface and the same be\u00adhaviour are considered equal. An input port can be connected \nto an output port by a wire, wich propagates the signal after a non\u00adzero bounded delay. The notions above \nshould be intuitive and it will help the presentation to maintain a certain level of informality about \nthem. Full formalisations using CSP-like process calculi are quite standard [27],butwould make this presentation \nmore opaque fora minimumgainin rigour.We will present sucha full formali\u00adsation elsewhere. Ahandshake \ncircuit (HC) is a digital circuit where each port has twolabels: r(equest) and a(cknowledgement), i(nput) \nand o(output) (P, l:P .{i, o}\u00d7{r, a}).By convention, we draw such circuits with the r-ports on the left \nand a-ports on the right; we will denote the input/output polarity by arrows.  .\u00af We writeA(i) = p \n. P | l(p) .{ir, ia} and so on. Wede.neaclosed-monoidal categoryofHCsinthe followingway: Objects are \nsets of ports with polarities as de.ned above.  Morphisms f : A . B are circuits with sets of ports: \n (i)(o)(i)(o)(i)(o) f= Al B, f= Al B, (r)(r)(r)(a)(a)(a) f= Al B, f= Al B. Composition of HCs f : A \n. B and g : B . C is the circuit g . f : A . C de.ned by connecting f and g in the following way:  Note \nthat the ports labeled by B become internal channels and are no longer part of the interface. Identity \nisa HC idA : A2 . A1 (we use tags 1 and 2 to distinguish between argument ports and result ports) of \nthe following shape:  PROPOSITION 1. HCs form a category. Proof: Composition is well de.ned, by inspectingthe \ndiagram.  Composition is associative. f . (g . h)=(f . g) . h as they are both equal to the circuit \nin Fig. 1.  Identity is an idempotent. The diagram for f . id shows that immediately (straightening \nthe wires):   id . f has a similar diagram. Figure 1. Associativity We call the category of handshake \ncircuitsHC. The monoidal structureis de.nedbythe functor -.- de.ned by:  The unit object I is the empty \nset of ports.  On objects, (A . B)(x) = A(x) l B(x) where x .{i, o, r, a}.  On morphisms f . g : A \n. C . B . D is   PROPOSITION 2. HC with . and I is a monoidal category. The closed structure is de.ned \nas follows: On objects, let (i)(o)(i)(o)(i)(o) (A . B)= Al B, (A . B)= Al B, (r)(r)(r)(a)(a)(a) (A . \nB)= Al B, (A . B)= Al B. For each A, B let the evaluation morphism evalA,B : A1 . (A2 . B1) . B2 be \nthe circuit:  PROPOSITION 3. HC with -.-, I, -.-, eval-,- isamonoidal closed category. Proof: The universal \nproperty property that forevery morphism f : A . X . B there exists an unique morphism h : X . A . B \nsuch that f = evalA,B . (idA . h) is immediate from the diagram of the composition on the right-hand \nside:  It is obvious, after straightening the wires, that the only h that can satisfy the equality is \nf itself, with appropriately relabeled ports, and is unique. This relabeling is infact the currying isomorphism \n.(-). The category HC is similar to other diagram-based models of monoidal closed categories, for example \nin quantum computa\u00adtion [2]. Note that the axioms for a monoidal closed category are satis.ed in a purely \nstructural way, by considering only the ports and the wirings. The behaviour of the circuits is not important \nup to this point, as it is safe to assume that structurally equal circuits are also behaviourally equal. \n3.1 Cartesian product To model bSCI we also need a notion of product.We will .nd a sub-category of HC \nfor which: the unit of the monoidal product is a terminal object;  for each object there is a diagonal \nmorphism.  It is known that such categories have Cartesian products [17]. DEFINITION 4 (Diagonal). For \nan object Z in a monoidal cate\u00adgory where the unit is terminal, a diagonal is a morphism dZ : Z . Z . \nZ suchthat the diagram below commutes: Z / /  id///// id /dZ /// t I . Z ~= Z - !.id Z . Z id.- !Z \n. I = Z Structurally, this means that the circuits in this sub-category need to satisfy the following \nequations:  In words, all circuits which are morphisms to I should be equiva\u00adlent to a circuit with \nno (open) ports: I does not have ports by de\u00adsigns, and the circuits associated with the domain are left \ndiscon\u00adnected. Adiagonal dA : A . A1 \u00d7 A2 with the ports associated with A1 disconnected (by composition \nwith !)should behave like the identity idA : A . A2 (similarly for A2).For these equations to hold, the \nbehaviour of the circuits becomes relevant. Let dA : A . A1 \u00d7 A2 be de.ned by the circuit  That behaves \nin the following way: 1. after an input on a port associated with Ai remember the value of i and produce \nan output on the equivalent port associated with A 2. after an output on a port associated with A produce \nan output on the equivalent port associated with the memorised i.  It is obvious that the diagonal construction \nis not well de.ned for all HCs. What happens, for example, if two consecutive inputs arrive from the \ntwo distinct components? Below we will identify a restricted classofHCs,for whichthebehaviourofthe diagonalis \nwell de.ned, and which form a Cartesian sub-category of HC. Before we can prove this lemma we need the \nfollowing de.nition. DEFINITION 5. For object A there is a designated set of input requests IA called \ninitial, suchthat: IA.B = IA\u00d7B = IA l IB  IA.B = IB . DEFINITION 6. We say that a circuit is asimple-handshake \ncircuit (SHC) if it satis.es the following conditions: 1. input and output actions must alternate; 2. \nrequests and acknowledgments must be well-nested; 3. the outermost request is on an initial port; 4. \nthere must be no consecutive actions on a given request port without having an intervening action on \nthe acknowledgment port with the same label.  Well-nesting is the same property that well-formed languages \nof brackets satisfy, with the request (acknowledgment, respectively) on a port with a given label being \nseen as an open (closed, respec\u00adtively) bracket with that label. Note that the assumptions above are \nboth about the circuits them\u00adselves and about the environment in whichthe circuits operate. PROPOSITION \n7. Simple-handshakecircuits formaCartesian sub\u00adcategory of HC. Proof: The identity is SHC: The .rst signal \nmust be on A1(ir), by Def. 6.3. The following signal is on A2(or), as Def. 6.1 assumes no other inputs \noccur before it. After this interaction, there are two possibilities: (ir)(or)(ia) A, followed by A(by \nDef. 6.1), then by A(by 21 1 Def. 6.2) and A2(oa) (by Def. 6.1). This interaction can repeat (by Def. \n6.2), followed by (ia)(oa) a signal on A2 , propagated to A1 , After which the whole cycle can start \nagain. We need to show that the composition of SHCs is well de.ned, i.e. the result is also a SHC. Consider \na SHC of shape f : A . B. If we tag anyactions of the circuit with A(ir),A(oa),A(or),A(ia), B(ir),B(oa),B(or),B(ia) \nthen the restrictions on the behaviour of the circuit mean that any trace of actions associated with \nf must belongtothe language representedbythis automaton:  ASHCg : B . C has similar traces with appropriately \nchanged labels. The composed circuit g . f : A . C has traces in the composite language given as in Fig. \n2. Condition 3 in Def. 6 is satis.ed because it is satis.ed by g. Note that the actions associated with \nB are not externally observ\u00adable since theyare no longer ports of the circuit (hence the i/o labels indicateonlythe \nrelative directionofthe action),buttheyoccuron internal channels. Thisproves that condition1in Def.6is \npreserved by composition, and it shows us the general shape of the resulting behaviour. Figure 2. Composition \nof SHC For the other conditions, we need to make an additional argument: from the shape of the resulting \nlanguage we can see that if we project it on the language associated with f (i.e. we remove all other \nsymbols) we must get a string in that language; if we project it on the language associated with g we \nmust get a string in the iterated closure of the language. If the composite language violates conditions \n2 or 4 then the projected languages will violate the conditions, which is a contradiction. The monoidal \nclosed structure is inherited from HC, we only need to show that the product is well de.ned. The diagonal \nmorphism and the projections are SHCs (indeed, the very idea of SHCs was intended to accommodate the \ndiagonal morphism!). The unit I is terminal because all circuits of shape A . I are equivalent and inactive \nbecause there is no initial input request port.We denote such morphisms with !: A . I. Weneed to showthat(id.!).dA \n= (!.id).dA = idA . The circuit for the compositionis shownin Fig.3.We can see that this simply equates \nto relabeling all A1 ports and hiding or blocking the A2 ports. d then propagates the actions between \nthe corresponding A and A1 ports, just like the identity. The SHC restrictions ensures that d is always \nwell-behaved. D The projections are p0 = id.!: A0 \u00d7A1 . A0 and p1 =!.id : A0 \u00d7 A1 . A1. We will refer \nto the Cartesian, monoidal-closed category of simple handshakecircuits as SHC. It offers all the necessary \nstructure that is required to interpret bSCI. 4. Interpreting bSCI Types of bSCI are interpreted by objects \nin the categorySHC.For the base types, the interpretations are: [com] ={R . (ir),D . (oa)}  Figure \n3. Projections [exp ={Q . (ir),T . (oa),F . (oa)} [cell] ={WT . (ir),WF . (ir),Q . (ir),D . (oa), T \n. (oa),F . (oa)}. with I[coml = {R},I[expl = {Q},I[celll = {W T, W F, Q}.For other types, the interpretations \nare: ' ''' [. . . ] = [.] . [. ], [. \u00d7 . ] = [.] \u00d7 [. ]. Thereaderfamiliarwithgame semanticswillnotethatthenotionof \nport inaHC correspondstothatofa move ingame semantics. An action on a port corresponds to a move occurrence. \nTermsx1 : .1,...,xn : .n f M : . are interpreted by morphisms O [x1:.1,...,xn:.nIM:.l - ---------------- \n[.i] . [.]. 1=i=n The constants of the language are interpreted by the following circuits:  Intuitively,the \nconstant1(0, respectively)is interpretedby imme\u00addiately responding to an input request on the (only such) \nportQ with an action on portT(F, respectively). The command skip is in\u00adterpretedbyimmediately respondingtothe \nrequest.Suchbehaviour can be most simply interpreted by wires alone. These are proper SHC circuits because \nDef. 6.1 guarantees that the input signal will propagate to the output before the next input signal will \noccur. Assignment has the following interpretation:  Intuitively, an action on R3, indicating the beginning \nof execution, leads to an evaluation of the second argument (output request on Q2) which, by Def. 6.2, \nmust followed by an acknowledgment on T2 (F2, respectively) if the value of the expression is 1 (0, respectively). \nThe next output request is write true , WT, ( write false , WF, respectively) into the .rst argument \nvariable. Once the write operation is acknowledged, D1, the assignment acknowledges completion, D3. The \nports that manage reading from the variable (Q1, T1, F1) are not used in the assignment. Dereferencing, \nin contrast, ignores the ports writingto the variable and simply relays the read request and the acknowledged \nvalue:  Another functional constant which can be interpreted by wiring only is sequential composition \n Intuitively, running the sequential composition is done as follows: send a run request (R1) to the \n.rst argument. When the .rst argu\u00adment acknowledges completion (D1) senda run request (R2) to the second \nargument. When it completes (D2) the sequential composi\u00adtion acknowledges termination (D3). In order \nto interpret branching and iteration we need an auxiliary JOIN circuit withtwo inputsI1,I2 andone outputO. \nIts behaviour issimplytorelayanyactiononI1orI2toO.We denotethis circuit by . Branching is: An acknowledgment \nof true (T1) from the guard of the branching triggers the second argument(R2), whereasafalse (F1) triggers \nthe third argument (R3). The branch acknowledges termination (D4) when either of the command arguments \nterminates (D2, D3). Note that the SHC rules prevent D3 responding to R2 or D2 to R3.For iteration we \nuse:   Atrue (T1) acknowledgment from the guard executes the body of theloop(R2) whereasafalse(F1) \nterminatestheloop(D3). For logical operators we assume the existence of circuits of shape  thatproduceoutputonT(respectivelyF)ifandonlyifthelasttwo \ninputs were on ports X1 and Y2 and op(x1,y2)=1 (respectively 0); after it produces the output OP must \nrevert to its initial state. Note that circuit OP needs to be stateful, since its inputs are not simultaneous \nand need to be remembered. Also note that this aux\u00adiliary circuit is not itself SHC. The interpretation \nof logical operator op in the language is the following:  Above we use the same JOIN circuit whichwas \nused for branching and iteration. Its role is to propagate anyof T1 or F1 input signals to Q2. Finally, \nthe local state is interpreted by the circuit The circuit CELL above is a two-state memory cell: If the \ninput is onWT1( writetrue )itgoesto state1,ifitisWF1( writefalse ) itgoesto state0.Thenit producesoutputonD1.AfteraQrequestit \nproducesT1ifitisin state1,F1ifitisin state0.AninputontheS port resets the circuit to its initial state. \nThis behaviour is speci.ed by the following (Mealy-style) automaton:   The structuralelements of bSCI \nare interpreted in the standard way in the category SHC: [x : . f x : . = id[.l [G,x : . ' f M : . = \n[G f M : .] . p1 [G f .x.M : . ' . . = .([G,x : . ' f M : .]) `\u00b4 [G, . f FM : . = eval . [. f M:. ' ] \n. [G f F :. ' ..] `\u00b4 [G f(M, N) : . \u00d7 . ' ] = [G f M:.] . [.(G f N:. ' )] . d[Gl, where .(G f N : . \n' ) is the syntactic operation of substituting all free variables from G with fresh ones. We can state \nthat: LEMMA 8. The interpretations of bSCI constants areSHC circuits. The following propertyis not requiredof \nSHCs,butit holds for all circuits introduced sofar: PROPOSITION 9 (Reset). For any SHC[G f M : .] the \ninternal stateofthecircuitbeforean initialinputrequestisthesameasafter the .nal output request. Proof: \nImmediate, by structural induction on the syntax of M. D We show that this compilation technique is \ncorrect through the following soundness theorem. THEOREM 10 (Soundness). If M : com isaclosed term andM \n. then [M : com] is equivalent to [skip : com]. Thisisan immediate corollaryofamore general following \nLemma. Wesay thataCELL is in stateBifaQinput requestwould produce aBoutput acknowledgment.We write CELLB \nfor a cell which is in initial state B. LEMMA 11. If G f M : s, s .{exp, com} is a semi-closed term then \nfor all states s : dom G . B if M, s . c, s ' then circuit `\u00b4 CELLB1 .\u00b7\u00b7\u00b7. CELLBn is equivalent to [c \n: s][G f M : s] . 1 n and it leaves CELLj in state Bj ' , where dom s = {x1,...,xn}and s(xi)= Bi,s ' \n(xi)= Bi' . Proof: The proof is by structural induction on the evaluation rules in the operational semantics. \nAbstraction, application, product and projection rules hold because of the structuralproperties of SHC. \nMost constructshave routine proofs.We illustrate the proof for the case of sequential composition of \ncommands. The rule is ' '' '' C, s . skip,s C,s . skip,s seq(C, C ' ),s . skip,s '' The interpretation \nof the sequential composition in state s is the following circuit:  We apply the inductionhypothesis \nonC and obtain the equivalent circuit,but with memory cellsin new state Bi' .  We then apply the inductionhypothesisonC \n' and obtain  This proves the inductive step for sequential composition, as this '' (i). circuit is \nequivalent to skip and leaves the each cell i in state s In the case of the local-variable binder: M, \ns . (v . 0) . T,s ' . (v . b) newvar(.v.M),s . T,s ' we can see that both thehypothesis and the conclusion \nturn out to be modelled by the same circuit:  We also sketchout the case of iteration, which is more \ninteresting. The rules for iteration are: B, s . 0,s ' while(B, C),s . skip,s ' ' '' '' ''' B, s . \n1,s C,s ' . skip,s while(B, C),s . skip,s ''' while(B, C),s . skip,s Let us sketch the interpretation \nof iteration in state s:  The reset property (Prop. 9) ensures that we can rewrite the circuit as below, \nwithout changing its behaviour(d here shares four copies of an identi.er):  The equivalent circuit above \nis actually [G f if(B, seq(C, while(B, C))) : com]. Thisleadstoan immediateproofbyapplyingthe inductionhypoth\u00adesis. \nD The soundness resultisaproofof correctnessforthe compilerfrom bSCI to SHCs. 5. Concurrency 5.1 Safe \nconcurrency The language bSCI also hasaconstruct for concurrent composition of commands, which we shall \nconsider now: par : com . com . com. The contrast between its type and the type of sequential compo\u00adsition(com \n\u00d7 com . com)re.ects the restriction that the two arguments may not share identi.ers. The operational \nsemantics for this rule is C1,s1 . skip,s 1 ' C2,s2 . skip,s 2 ' par C1 C2,s1 . s2 . skip,s 1 ' . s2 \n' Where by s . s ' we mean the union of two function with disjoint domains.Therulemakesitexplicitthatthetwo \ncommands operate on disjoint stores. The circuit for [par : com . com . com] is: Where the auxiliary \ncircuit C produces output after both input ports have received data (the behaviour of a Mueller C-element). \n  We can see that the circuit above is not a simple handshake cir\u00adcuit, because it sends two output \nsignals (R1, R2) without anyin\u00adtervening input. The semantic model is still sound, and therefore the \ncompileris still correct,but the characterisationof circuits and their environments is more complex and \nwill not be given here. Concurrencyis very important for hardware synthesis. Computers, even multi-processor \nversions, are essentially sequential devices, andtheexecutionof concurrent programsraisesvarious theoretical \nand engineering challenges. In contrast, hardware is inherently concurrent and, as we can see from the \ncircuit above, the synthesis of the parallel execution operator does not raise anydif.culties. In fact, \nit is as easy to synthesise concurrent version of the logical operators as well: op|| : exp . exp . exp \n synthesised as  Notethattheconcurrentversionofthe operatorisevensimplerthan the sequential version. \n 5.2 Unsafe concurrency The bSCI type system prevents race conditionsby preventing shar\u00ading of identi.ers \nbetween concurrent sub-programs. In compila\u00adtion and execution the dangerous consequence of sharing vari\u00adables \nin concurrent contexts is that of race conditions: the value storedinavariableis not well determined.Forexample, \nshared\u00advariable concurrency is commonly modelled so that programs such as x := 1; (x :=7 || x := x - \n3) may leave variable x, non\u00addeterministically, withvalues4,7, oreven-2 (e.g.[6]). More re\u00adalistic analyses \nthat take into account low-level concurrency is\u00adsues [22] show that in suchprograms x may end up with \nany value at all. If race conditions have dire consequences in programs, theyhave even more severe consequences \nin synthesis, because they affect not justvariablesbut whole terms! Consider forexample the (unty\u00adpable) \nterm for .c : com.par c c. It would lead to the synthesis of circuit  The initial input request on R3 \nwill lead to two simultaneous input requests on dcom, which is illegal, so the behaviour of d is unde\u00ad.ned, \ntherefore the behaviourof the entireprogramis unde.ned! However, programs that cannot be typed do not \nnecessarily have race conditions, and programs that have race conditions are not necessarily misbehaved! \nConsider, for example, the synthesis of .c : com..d : com.(c; d) || (d; c) which is both untypeable \nand it can introduce race conditions between circuits bound to c and d.  However, as it can be seen \nin the circuit, if c and d are bound to circuits that do not, in turn, share variables and c and d have \nequal input/output delays (or are somehow synchronised) then the diagonals dc,dd will function correctly \nand the circuit will behave correctly. The signi.cant additional expressivity of shared-variable concur\u00adrency \nover safe concurrencyprobably justi.es allowing it in the language even at the risk ofunde.ned behaviour \nin the presence of racing conditions. The onus for correctness will lay heavier on the programmer. Perhaps \nresource-management logics could be help\u00adful in this regard [18]. It is also possible to .nd a middle \nway between totally unsafe and totally safe concurrency.Forexample, the diagonal morphism could be safely \nsynthesised to function as a semaphore: if two input requests arrive simultaneously one of them would \nhave to wait until the .rst input receives its acknowledgment. This, of course, would restrict the amount \nof overall concurrency in the presence of race conditions by replacing it with nondeterminism. This solution \nwould also require much more sophisticated and expensive implementations of the diagonal morphism. 5.3 \nMore on af.ne typing In the previous section we have seen that concurrency raises im\u00adportant issues, \nand that af.ne typing is only one of the possible solutions.Itisasafeandelegant solution,butatthecostofgreatly \nreduced expressiveness, thus not entirely satisfactory. So whyis af.ne typing really needed? The most \nseriousproblem to handle in synthesis, perhaps unsur\u00admountable, is that of nested function self-application, \nas it involves subtle interleavings of inputs and output on the same physical cir\u00adcuit. Consider this \nterm (known as a Kiersetead term): .f :(com . com) . com.f(.x : com.f(.y : com.x)) This term does not \nhave af.ne typing. If we apply the synthesis procedure and straighten all the loops in the wiring we \nobtain the following circuit:  We label the ports of the diagonal circuit that shares the two occur\u00adrences \nof f :(com . com) . com with numbers indicating the order in which various inputs and outputs are triggered. \n(The suc\u00adcessionofevents2,3isallowedanditwill happenif f the function is applied to a term that is non-strict.) \nThe problem is that output requests2 and6 occur on the same port without any intervening acknowledgment. \nThis is a fundamental violation of the SHC or DHC requirementsandwillleadto unde.nedbehaviourinthecir\u00adcuit. \nAlso,ifevent7 occursitis impossibleto tell whetheritisan acknowledgment for2 or for6. Unlike the problems \nrelated to concurrency, which can have prag\u00admatic solutions that make sense at least from an engineeringpoint \nof view, this seems to be a fundamental dif.culty. The question is open whether af.ne typing is not too \nstrict, since there are terms with nested self-application (e.g. .f.f(f(skip)))that seem to lead to well-behaved \ncircuits. Finally, if one wishes to relax the constraints of the typing system for concurrencybut not \nfor nested self-application it is possible to replace the new-variable binder newvar :(cell . com) . \ncom withafamilyof new-variable binders newvarn :(cell . \u00b7 \u00b7\u00b7 . cell . com) . com, that bind n distinct \nvariable-identi.ers in (possibly concurrent) contexts to the same physical memory cell. This trick can \nalso allow the introduction of semaphores (which must be shared between concurrent contexts) without \nbreaking the af.ne typing rules. The behaviour is the usual one for a memory cell if the read and write \nrequests do not race, and some arbitrary behaviour if there are race conditions.Forexample, the (Mealy-style) \nautomaton below illustrates such behaviour for a CELL circuit used to implement [newvar 2 :(cell1 . cell2 \n. com) . com: The transitions that correspond to race conditions are highlighted. 6. Recursion The restrictions \nof the type system together with the .nite-state restriction on the circuits allow only for limited forms \nof recursion: mutual ground-type tail-recursion. The recursion construct is rec. :(. . .) . ., where \n. ::= s | . \u00d7 .. Informally, tail-recursion means that the recursive call must occur last in the bodyof \ntheprocedure. Thiseffectively reduces the re\u00adcursion to iteration.We will not formalise the notion of \ntail recur\u00adsion,butwillonlymakean informalargumentforthe soundnessof the recursion circuit:  The ground \ntype restriction ensures that each type has only input (or output) requests (or acknowledgments). Intuitively, \nthe recursive callisfromR1toR2andthe tail-returnisfromA2toA3;itisatail return because termination of \nthe argument results in immediate termination of the recursion operator, rather than a return to the \ncalling function. We can see how this recursion operator, applied to the circuit for b : exp,c : com \nf .x.if(b, seq(c, x), skip) givesacircuitequivalentto iteration(the grayed-outwiresarenever active): \n Recursion is guaranteed to be sound only when applied to closed terms. Informally, the argument for \nthe soundness of the recursion operator is similar to that for the soundness of the iteration rule: the \nresetruleallowsustomakeacopyofthe circuitbeing iteratedover, and we can apply the inductionhypothesis \non the resulting, equiv\u00adalent circuit. In the diagram below, note that a general recursion operator (not \ntail recursive) would return (the output port marked with an outline arrow) into the previous instance \nof the circuit rep\u00adresentingthebodyofthe function, ratherthanmakeaglobal return. Also note that it is \nimportant that the duplicated circuit does not have open ports.  An example of term that leads to unsound \nrecursion is b : exp,c : com f .x.if(b, par(c, x), skip), as it can lead to a race condition on the \nportassociated with c. It is an open question what kind of more expressive recursion operators are compatible \nwith hardware synthesis. 7. Hardware synthesis For actual synthesis,the de.nitionofHCs needstobe re.ned.We \nneedtode.newhat constitutesasignalonaportand implementthe d, CELL, OP and JOIN circuits accordingly. \nHCs can be designed to be either synchronous or asynchronous; in the former case they only need to be \nlocally synchronous, i.e. HCs can be composed without requiring a global clock. This class ofcircuits \nis especially well suited for compositional designs, and their comparativeadvan\u00adtages and disadvantages \nare well studied [23]. We will take a naive and straightforward approach, re.ning the notion of action \non port P to a voltage transition along P . This naiveapproachhasa seriesof well-documented disadvantages[26] \n(it requires a circuit to remember the state of each input, which is extravagantly expensive) but it \nis functionally correct, and it givesaproof-of-conceptforthe technique.The circuitshavelocally synchronous \ndesigns. Wemakeone simple optimisation in the representation of ports that dealwithbooleandata(TandF,WTandWF). \nInsteadofusingtwo data ports we use one data port (BD, WD) and onecontrol port (BC, WC). The data port \nindicates thevalue and thevoltage transition on the control port indicates an action. This is less expensive \nand can be extended to integers in a simple way. AnaiveVerilog implementation forJOIN is: module hsJoin(I1, \nI2, O, clock); input I1, I2, clock; output O; reg I1p, I2p, O; always @(posedge clock) begin if (I1p \n!= I1) begin O <= !O; I1p <= I1; end if (I2p != I2) begin O <= !O; I2p <= I2; end end endmodule AnaiveVerilog \nimplementation forand is: module hsAnd(BD1, BC1, BD2, BC2, BD, BC, clock); input BD1, BC1, BD2, BC2, \nclock; output BD, BC; reg BC1p, BC2p, BC, BD; always @(posedge clock) begin if (BC1 != BC1p) begin BC1p \n<= BC1; BD <= BD1; end if (BC2 != BC2p) begin BC2p <= BC2; BC <= !BC; BD <= BD &#38;&#38; BD2; end end \nendmodule Other logical and arithmetic operations are similarby replacing the .nal and operation(&#38;&#38;)with \nthe desired operation. AnaiveVerilog implementation forCELL is: module hsCell(WD, WC, D, Q, BD, BC, S, \nclock); input WD, WC, Q, S, clock; output D, BD, BC; reg WCp, Qp, Sp, D, BC, BD; always @(posedge clock) \nbegin if (WC != WCp) begin WC <= WCp; BD <= WD; D <= !D end if (Q != Qp) begin Q <= Qp; BC <= !BC; end \nend endmodule Ford each type requires a different implementation, we only show the simplest one, for \ncom. module hsDiagCom(R, D, R1, D1, R2, D2, clock) output R, D1, D2, clock; input D, R1, R2; reg R1p, \nR2p, Dp, R, D1, D2, state; always @(posedge clock) begin if (R1p != R1) begin state <= 1; R1p <= R1; \nR <= !R; end if (R2p != R2) begin state <= 0; R2p <= R2; R <= !R; end if (D != Dp &#38;&#38; state) begin \nDp <= D; D1 <= !D1; end if (D != Dp &#38;&#38; !state) begin Dp <= D; D2 <= !D2; end end endmodule These \ncircuits have the advantage that theydo not need initialisa\u00adtion, often a problem in hardware design. \nFor realistic implementation it is required to use cleverer and more ef.cient re.nements for actions, \nsuch as multi-phase encodings as well as various optimisations [26]. Wehave implementeda prototype compilerfrom \nbSCItoVerilog using this technique.Forexample, the circuit synthesised for pro\u00adgram .f..g..x.f(g(x)); \ng(f(x)) has block-schematic and tech\u00adnology schematics as in Fig. 4. The two larger block circuits are \ndiagonals for com . com and the smaller block circuits are the diagonal for com and the implementation \nof skip (it only contains wires).Verilog synthesis has beenexecuted using the Xilinx ISE package. 8. \nRelated work Compilation techniques usually rely on operational semantic ideas, but denotational-based \ntechniques have been proposed before, e.g. Reynolds s work on compiling Algol using functor cate\u00adgories \n[21]. Although the two underlying models have little in common, dissimilarity re.ected by the target \narchitecture, one of the principal objectives is shared, providing a compelling and ac\u00adcessible computational \nintuition of the essential features of the semantic model. The category of simple-handshake circuits \nis obviously related to and inspiredbythe ideaof strategyingame semantics[3,11],the notion of action \nwe use corresponds to that of move occurrence and the notion of port to that of move. The main technical \ndiffer\u00adence is thatgame models are usually targeted towards de.nability results, ensuring that all semantic \nobjects correspond to terms. This requires tighter constraints on what is considered acceptable be\u00adhaviour \nof the environment and also more precise descriptions of whatisthe possible behaviourofa program.Manyof \nthese consid\u00aderations are not relevant if the aim is soundness only. Although no precise connections \nare drawn in this work, there are obvious parallels between our circuit semantics and work on ab\u00adstract \nmachines based ongame semantics (such as the Token Ab\u00adstract Machine [8]) and Geometry of Interaction \n[13]. The empha\u00adsisofthispaperismore practicalthough.Weaimedfora technique that starts with a (fairly \nrealistic) programming language and ends with VLSI-synthesisable circuitry. However, a closer inspection \nof these connection may be useful from an applied point of view, es\u00adpecially in regards to devising less \nrestrictive type systems for the programming language. Even more closely related in this sense is Mackie \ns work on com\u00adpiling functional programs using ideas from the Geometry of In\u00adteraction [12, 13]. Also, \nAbramsky s recent work on structural approaches to reversible computation [1] and quantum computa\u00adtion \n[2] shares similar aims, although theyall lookat different target architectures. There is a vast amount \nof literature concerning hardware synthe\u00adsis from higher-level languages. One of the most successful \nap\u00adproaches is Mycroft and Sharp s work on statically allocated func\u00adtional languages [14,15].Thislineofwork \nuses fundamentallydif\u00adferent techniques than ours,butit shares an identical aim.Itwould be a useful exercise \nto compare circuits synthesised from similar programs using these two techniques. Mostofthe restofthework \nconcerning higher-levelsynthesis tech\u00adniques is not directly comparable to this approach, as it involves \neither structural layout techniques (such as Lava [5]), design lan\u00adguages based on process calculi (such \nas Balsa [25]) or lower-level languages more similar in spirit to hardware description language (such \nas Haendel-C [7] or SystemC [24]). Acknowledgments Guy McCusker and Peter O Hearn made im\u00adportant observations \nregarding an earlier draft of this work. Alan Mycroft patiently explained the drawbacks of the one-phase \nhan\u00adshake protocol.QianyiZhangandXuWangprovidedmuch needed guidance and help in using digital design \ntools. I gratefully ac\u00adknowledge their contributions to this work. References [1] ABRAMSKY, S. A structural \napproach to reversible computation. Theor. Comput. Sci. 347,3(2005), 441 464. [2] ABRAMSKY, S., AND COECKE, \nB. A categorical semantics of quantum protocols. In LICS (2004), pp. 415 425. [3] ABRAMSKY, S., JAGADEESAN, \nR., AND MALACARIA, P. Full abstraction for PCF. Inf. Comput. 163,2(2000), 409 470. [4] ABRAMSKY, S., \nAND MCCUSKER, G. Linearity, sharing and state:a fully abstractgame semantics for idealized algol with \nactive expressions. Electr. Notes Theor. Comput. Sci.3 (1996). [5]BJESSE,P.,CLAESSEN,K.,SHEERAN,M., \nAND SINGH,S. Lava: hardware design in haskell. In ICFP 98: Proceedings of the third ACM SIGPLAN international \nconference on Functional programming (NewYork,NY, USA, 1998),ACM Press, pp. 174 184. [6] BROOKES, S. \nD. Full abstraction for a shared variable parallel language. In LICS (1993), pp. 98 109. [7] CELOXICA. \nHandel-C Reference Manual. http://www.celoxica. com. [8]DANOS,V.,HERBELIN,H., AND REGNIER,L. Game semantics&#38; \nabstract machines. In LICS (1996), pp. 394 405. [9] GHICA, D. R., AND MCCUSKER, G. Reasoning about idealized \nAlgol using regular languages. In ICALP (2000), pp. 103 115. [10]GIRARD,J.-Y. Geometryof interaction \n(abstract). In CONCUR (1994), p. 1. [11]HYLAND,J.M.E., AND ONG,C.-H.L. On full abstraction for PCF: I, \nII, and III. Inf. Comput. 163,2(2000), 285 408. [12] MACKIE,I. The Geometry of Implementation. PhD thesis, \nImperial College, University of London, 1994. [13]MACKIE,I. The geometryof interaction machine.In POPL \n(1995), pp. 198 208. [14] MYCROFT, A., AND SHARP, R. A statically allocated parallel functional language. \nIn ICALP (2000), pp. 37 48. [15] MYCROFT, A., AND SHARP, R. Higher-level techniques for hardware description \nand synthesis. STTT4,3(2003), 271 297. [16]O HEARN,P.W. Onbunched typing. J. Funct. Program. 13,4 (2003), \n747 796. [17] O HEARN, P. W., POWER, J., TAKEYAMA, M., AND TENNENT, R.D. Syntactic controlof interference \nrevisited. Theor. Comput. Sci. 228, 1-2 (1999), 211 252. [18] O HEARN, P. W., AND PYM, D. J. The logic \nof bunched implications. Bulletinof SymbolicLogic5,2(1999), 215 244. [19]REYNOLDS,J.C. Syntactic controlof \ninterference.In POPL (1978), pp. 39 46. [20] REYNOLDS, J. C. The essence of Algol. In Proceedings of \nthe 1981 International Symposium on Algorithmic Languages (1981), North-Holland, pp. 345 372. [21] REYNOLDS,J.C. \nUsingfunctor categories to generate intermediate code. In POPL (1995), pp. 25 36. [22]REYNOLDS,J.C.Towarda \ngrainless semanticsfor shared-variable concurrency. In FSTTCS (2004), pp. 35 48. [23] SHAPIRO, D. M. \nGlobally-asynchronous locally-synchronous systems. PhD thesis, Stanford University, 1984. [24] SYNOPSYS \nINC. SystemC Reference Manual. http://www. systemc.org. [25] THE UNIVERSITY OF MANCHESTER ADVANCED PROCESSOR \nTECHNOLOGIES. BALSA Reference Manual. http://www.cs. manchester.ac.uk/apt/projects/tools/balsa/. [26] \nVAN BERKEL, K. Handshake circuits: An intermediary between communicating processes and VLSI. PhD thesis,Technische \nUniv., Eindhoven (Netherlands)., 1992. [27] VAN BERKEL, K., KESSELS, J., RONCKEN, M., SAEIJS, R., AND \nSCHALIJ, F. The VLSI-programming language Tangram and its translation into handshake circuits. In EURO-DAC \n91: Proceedings of the conference on European design automation (Los Alamitos, CA, USA, 1991), IEEE Computer \nSociety Press, pp. 384 389.  Figure 4. Schematics   \n\t\t\t", "proc_id": "1190216", "abstract": "We propose a new technique for hardware synthesis from higher-order functional languages with imperative features based on Reynolds's <i>Syntactic Control of Interference</i>. The restriction on contraction in the type system is useful for managing the thorny issue of sharing of physical circuits. We use a semantic model inspired by game semantics and the geometry of interaction, and express it directly as a certain class of digital circuits that form a cartesian, monoidal-closed category. A soundness result is given, which is also a correctness result for the compilation technique.", "authors": [{"name": "Dan R. Ghica", "author_profile_id": "81100060125", "affiliation": "University of Birmingham", "person_id": "P58037", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1190216.1190269", "year": "2007", "article_id": "1190269", "conference": "POPL", "title": "Geometry of synthesis: a structured approach to VLSI design", "url": "http://dl.acm.org/citation.cfm?id=1190269"}