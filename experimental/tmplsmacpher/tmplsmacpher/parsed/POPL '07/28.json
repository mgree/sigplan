{"article_publication_date": "01-17-2007", "fulltext": "\n Proving That Programs Eventually Do Something Good Byron Cook Alexey Gotsman Andreas Podelski Microsoft \nResearch University of Cambridge University of Freiburg bycook@microsoft.com Alexey.Gotsman@cl.cam.ac.uk \npodelski@informatik.uni-freiburg.de Andrey Rybalchenko Moshe Y. Vardi EPFL and MPI-Saarbr\u00a8ucken Rice \nUniversity rybal@mpi-sb.mpg.de vardi@cs.rice.edu Abstract In recent years we have seen great progress \nmade in the area of au\u00adtomatic source-level static analysis tools. However, most of today s program veri.cation \ntools are limited to properties that guarantee the absence of bad events (safety properties). Until now \nno for\u00admal software analysis tool has provided fully automatic support for proving properties that ensure \nthat good events eventually happen (liveness properties). In this paper we present such a tool, which \nhandles liveness properties of large systems written in C. Liveness properties are described in an extension \nof the speci.cation lan\u00adguage used in the SDV system. We have used the tool to automat\u00adically prove critical \nliveness properties of Windows device drivers and found several previously unknown liveness bugs. Categories \nand Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; F.3.1 [Logics and \nMeanings of Programs]: Specifying and Verifying and Reasoning about Pro\u00adgrams General Terms Veri.cation, \nReliability, Languages Keywords Formal Veri.cation, Software Model Checking, Live\u00adness, Termination 1. \nIntroduction As computer systems become ubiquitous, expectations of system dependability are rising. \nTo address the need for improved software quality, practitioners are now beginning to use static analysis \nand automatic formal veri.cation tools. However, most of software veri.cation tools are currently limited \nto safety properties [2, 3] (see Section 5 for discussion). No software analysis tool offers fully automatic \nscalable support for the remaining set of properties: liveness properties. Consider Static Driver Veri.er \n(SDV) [5, 26] as an example. SDV is packaged with 60 safety speci.cations that are automati\u00adcally proved \nof the device driver to which SDV is being applied. Many of these properties specify temporal connections \nbetween Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n07 January 17 19, 2007, Nice, France. Copyright c . 2007 ACM 1-59593-575-4/07/0001. . . $5.00 Windows \nkernel APIs that acquire resources and APIs that release resources. For example: A device driver should \nnever call KeReleaseSpinlock unless it has already called KeAcquireSpinlock. This is a safety property \nfor the reason that any counterexample to the property will be a .nite execution through the device driver \ncode. We can think of safety properties as guaranteeing that speci\u00ad.ed bad events will not happen (i.e. \ncalling KeReleaseSpinlock before calling KeAcquireSpinlock). Note that SDV cannot check the equally important \nrelated liveness property: If a driver calls KeAcquireSpinlock then it must eventu\u00ad ally make a call \nto KeReleaseSpinlock. A counterexample to this property may not be .nite thus making it a liveness property. \nMore precisely, a counterexample to the prop\u00aderty is a program trace in which KeAcquireSpinlock is called \nbut it is not followed by a call to KeReleaseSpinlock. This trace may be .nite (reaching termination) \nor in.nite. We can think of liveness properties as ensuring that certain good things will eventually \nhap\u00adpen (i.e. that KeReleaseSpinlock will eventually be called in the case that a call to KeAcquireSpinlock \noccurs). Liveness properties are much harder to prove than safety prop\u00aderties. Consider, for example, \na sequence of calls to functions: f();g();h(); . It is easy to prove that the function f is al\u00adways called \nbefore h: in this case we need only to look at the struc\u00adture of the control-.ow graph. It is much harder \nto prove that h is eventually called after f: we.rst havetoprove thetermination of g. In fact, in many \ncases, we must prove several safety properties in order to prove a single liveness property. Unfortunately, \nto practi\u00adtioners liveness is as important as safety. As one co-author learned while spending two years \nwith the Windows kernel team: Formal veri.cation experts have been taught to think only in terms of \nsafety properties: liveness properties are considered too hard.  Non-experts in formal veri.cation (i.e. \nprogrammers that write software that needs to be veri.ed) think equally in terms of both liveness and \nsafety.  In this paper we describe a new algorithm which automati\u00adcally constructs correctness proofs \nfor liveness properties of soft\u00adware systems. The algorithm has been implemented as an extension to the \nTERMINATOR tool, which is a fully automatic termination prover for software [15]. Properties are described \nin a new spec\u00adi.cation language, which is an extension to the safety-property\u00adonly language used by SDV. \nWhen given a property description and a program, TERMINATOR attempts to construct a correctness proof. \nIf a proof is found, then the property is guaranteed to hold. Conversely, if the proof fails, a potential \ncounterexample is pro\u00adduced. If the counterexample is a non-terminating execution, then it is presented \nvia a .nite description, to enable the programmer to analyze it. Our prototype tool represents the .rst \nknown liveness prover to handle large systems written in C. The tool is interprocedu\u00adral, path-sensitive, \nand context-sensitive. It supports in.nite-state programs with arbitrary nesting of loops and recursive \nfunctions, pointer-aliasing and side-effects, function-pointers, etc. The tool s scalability leverages \nrecent advances in program termination anal\u00adysis (e.g. [7, 10, 11, 13, 14, 15]). Following the automata-theoretic \nframework for program veri\u00ad.cation [31], our algorithm takes a liveness property and a program and constructs \nan equivalent fair termination problem (termination under a set of fairness constraints, a formal de.nition \nwill be given later). The novel contributions of the paper include: An extension to SDV s language for \nspecifying liveness prop\u00aderties (Section 2).  A method for checking fair termination of programs (Sec\u00adtion \n3).  Experimental results that demonstrate the viability of our ap\u00adproach to industrial software (Section \n4).   2. Specifying liveness properties In this section we describe a language for specifying liveness \nand safety properties of software systems. The language is an extension of SLIC [6], which is used to \nspecify temporal safety properties in SDV [5]. SLIC is designed to specify API-usage rules for client\u00adcode \n(like Windows device drivers and their use of the Windows Driver Model API as described in [5]). For \nthis reason it was designed such that programmers do not need to modify or annotate source code the code \nis typically not available when writing the speci.cation. Checking liveness can be reduced to checking \nfair termina\u00adtion [31]. Therefore, we .rst de.ne a minimal language for speci.\u00adcation of fair termination \nproperties, which is essentially a language for de.ning Streett automata. In Section 3 we describe an \nalgorithm for checking properties in this language. While the language can express all .-regular properties \n[32], using it to specify liveness properties of real code is awkward since most of such properties have \na response .avor. To overcome this problem, in Section 2.4 we introduce auxiliary statements (set and \nunset) that are helpful to concisely specify response requirements. 2.1 Syntax The syntax of the speci.cation \nlanguage is de.ned in Figure 1. A speci.cation describes an automaton that accepts program ex\u00adecutions \nthat satisfy the desired property. It consists of three basic parts: A state structure declaration. The \nstate structure de.nes a set of state variables that are maintained by the automaton represent\u00ading the \nspeci.cation during its execution. The variables can be of any scalar C type or pointer. Alistof transfer \nfunctions. Transfer functions de.ne transitions taken by the automaton as API operations are invoked \nand re\u00adturn. Each transfer function has two parts: a pattern speci.ca\u00adtion and a statement block that \nde.nes the transfer function body. A pattern speci.cation usually has two parts: a proce\u00addure identi.er \nid (i.e. the name of the API procedure) and one of two basic event types (event): entry, exit.These events \nidentify the program points in the named procedure immedi\u00adately before its .rst statement and immediately \nbefore it returns control to the caller. The any pattern can be used to trigger the event throughout \nthe code. The body of a transfer function is written in a simple imperative C-like language. One important \ncontrol construct is missing from the statements used in speci\u00ad.cations: loops. This means that transfer \nfunctions always ter\u00adminate. A list of fairness constraints. The fairness constraints are given as pairs \nof Boolean expressions inside of the scope of the fairness keyword. Each Boolean expression is guarded \nby a pattern. Fairness constraints are an extension of SLIC, and can be used to rule out counterexamples \nin which the environment is not fair . An example of a fairness constraint is the following: whenever \nfunction foo is called in.nitely often then it returns a value distinct from 0in.nitely many times . \nWe say that a non-terminating path satis.es a fairness constraint if and only if either the .rst Boolean \nexpression succeeds (i.e. it is invoked and evaluates to true) only .nitely often or the second Boolean \nexpression succeeds in.nitely often. A non-terminating execu\u00adtion can be a counterexample only if it \nsatis.es all of the fair\u00adness constraints given. Informally, we think of a speci.cation as a monitor \nthat is executed along with the program. Safety properties are expressed using the error statement, which \nexplicitly signals that an unsafe state has been reached (i.e. a safety property has been violated). \nA computation of the program does not satisfy the speci.cation if either error is called during the computation, \nor the computation does not terminate and satis.es all the fairness constraints. Note that an empty speci.cation \nspeci.es program termination. The function nondet() is used to specify non-deterministic value introduction. \nThat is, nondet() returns an arbitrary value. A proof of the conformance of a program to the speci.cation \nshould then take any valuation into account. The expression sub-language (expr) is the pure expression \nlan\u00adguage of C, without state update operators (++, --, etc.), pointer arithmetic, or the address-of \noperator (&#38;). Dereferencing pointers via *and -> is allowed. The identi.ers in this language are \nof sev\u00aderal forms: regular C-style identi.ers behave as expected, the $int identi.ers are used to refer \nto the function s formal parameters, and the identi.er $return is used to refer to the return value, \nwhich is accessible at the exit event.  2.2 Semantics We treat programs as fair discrete systems [23], \nwhere fairness re\u00adquirements are given in terms of sets of program states. A program P =(S,T,T,C)consists \nof: S: a set of states;  T: a set of initial states such that T.S;  T: a .nite set of transitions \nsuch that each transition t .T is associated with a transition relation .t .S\u00d7S;  C = {(p1,q1),...,(pm,qm)}: \na set of compassion require\u00adments, such that pi,qi .Sfor each i.{1,...,m}.  Transitions in this de.nition \nintuitively correspond to program statements. A computation s is a maximal sequence of states s1,s2,... \nsuch that s1 is an initial state, i.e. s1 .T, and for each i = 1there exists a transition t .T such that \nsi goes to si+1 under .t , i.e. (si,si+1)..t . A computation s =s1,s2,... satis.es the set of compassion \nrequirements Cwhen for each (p,q).Ceither s contains only .nitelymanypositions i such that si .p,or s \ncontains in.nitely many positions jsuch that sj .q. For example, a computation sat\u00ad Elements of syntax \nDescription state A speci.cation consists of a state structure, and a list of S ::= transF un+ transfer \nfunction de.nitions together with fairness con\u00ad fairness+ straints state ::= state {fieldDecl+ } A state \nstructure is a list of .eld declarations fieldDecl ::= ctype id = expr; A .eld has a C type, an identi.er \nand an initialization expression transF un ::= pattern stmt A transfer function consists of a pattern \nand a statement pattern event stmt ::= ::= ::= id . event |any entry |exit id = expr; Assignment statement \nchoose |||||::= stmt; stmt if ( choose ) stmt [ else stmt ] error(); return [ expr ]; {stmt }nondet() \nSafety property violation Return from the transfer function Non-deterministic choice expr id fairness \n|::= ::= ||::= expr id |expr op expr |\u00b7\u00b7\u00b7 C identifier $int $return fairness {pattern {expr }pattern \n{ expr }} Pure expression sub-language of C Refers to state elements or program variables $i refers to \nith formal parameter Return value of a function Fairness constraint Figure 1. Syntax of the speci.cation \nlanguage. is.es the compassion requirement (where pc denotes the program counter) (pc =foo.entry, pc \n=foo.exit . $return ) if =0whenever function foo is called in.nitely often then it in.nitely often returns \na value distinct from 0.Acomputation isfairifit satis.es all compassion requirements of the program. \nWe say that a program is fair terminating if it does not admit any in.nite fair computation. In order \nto prove that a speci.cation holds of a given program, we instrument the speci.cation into the program. \nThat is, we tra\u00adverse the input program and .nd all program locations in which the patterns described \nin the speci.cation can be triggered. A new program called the instrumented program is produced in which \nthe code found in the transfer functions is inserted to the original program. Formally, this constructs \nthe product of the original pro\u00adgram with the automaton representing the speci.cation [31]. In our implementation \nwe also perform a pointer analysis in order to con\u00adstructs an over-approximation of all the potential \npointer aliasing relationships. This allows us to statically .nd function-call events when functions \nare called by pointer. Bodies of transfer function are inserted into the program as they are given in \nthe speci.cation. The variables mentioned in the state structure become global variables in the program. \nFor each expression ei,where i =1,2, in a fairness constraint from the speci.cation and at each location \nwhere the corresponding pattern can be triggered we insert the code if (ei) { L: skip; } , where L is \na fresh label. The fairness constraints in the speci.cation are translated to compassion requirements \non the instrumented program (that can also be viewed as a fair discrete system). For each fairness con\u00adstraint \nwe introduce a compassion requirement (pc =L1 . .... Lk, pc =M1 ..... Ml) where L1,...,Lk, respectively, \nM1,...,Ml are the labels introduced during the instrumentation for the .rst, respectively, second expression \nof the fairness constraint. To prove that a program does not violate the speci.cation we need to prove \nthat the instrumented program can never make a call to the error function and that it is fair terminating. \nThe former can be done using existing techniques. An algorithm for checking the latter is presented in \nSection 3. state {} fairness { // First Boolean expression: succeeds // on every return from IoCreateDevice \nIoCreateDevice.exit { 1 } // Second Boolean expression: succeeds // if IoCreateDevice returns // something \nother than // STATUS_OBJ_NAME_COLLISION IoCreateDevice.exit { $return != STATUS_OBJ_NAME_COLLISION } \n} Figure 2. A speci.cation of termination under a fairness con\u00adstraint stating that if a program calls \nIoCreateDevice enough times then it will eventually return a value not equal to STATUS OBJ NAME COLLISION. \n 2.3 A simple example Consider the example speci.cation in Figure 2. As it was noted before, the empty \nspeci.cation state {} speci.es the termi\u00adnation of the program. Figure 2 speci.es an instance of fair \nter\u00admination. Recall that fairness constraints in our speci.cation lan\u00adguage come as pairs of Boolean \nexpressions guarded by pat\u00adterns. In this case, the .rst Boolean expression always succeeds whenever \nthe function IoCreateDevice returns. The second Boolean expression does not succeed when IoCreateDevice \nre\u00adturns STATUS OBJ NAME COLLISION. This particular constraint is saying: Ignore non-terminating program \nexecutions in which IoCreateDevice from some point on always returns STATUS OBJ NAME COLLISION. In other \nwords, a program satis.es this speci.cation if it terminates provided that whenever we continue to call \nIoCreateDevice repeatedly, it will eventually return a value other than STATUS OBJ NAME COLLISION. Functions \nused during the translation Fairness constraint Transfer functions void set() { if (q == NONE) { if (nondet()) \n{ q = PENDING; } } } void unset() { if (q == PENDING) { q = MATCHED; } } fairness { any{ 1} any { q == \nPENDING } } main.entry { q = NONE; } main.exit { if (q == PENDING) { error(); } } Figure 3. Auxiliary \nconstructs for specifying response-style liveness properties. 2.4 Auxiliary constructs Most of the frequently \nspeci.ed liveness properties have a response .avor and are awkward to specify with the minimalistic language \ndescribed in Section 2.1. To make their speci.cation easier we in\u00adtroduce auxiliary constructs the functions \nset and unset,which can be used in the speci.cation s transfer functions. Their intended meaning is that \nwhen the property calls set then an execution through the property in which unset is never called represents \na liveness violation. More precisely, a program satis.es a speci.ca\u00adtion with set and unset if andonlyif \nerror is never called in the instrumented program and there is no computation of the instru\u00admented program \nthat (i) satis.es all compassion requirements, (ii) contains a call to set, and (iii) contains no calls \nto unset after the last call to set. This corresponds to the validity of the LTL formula G ((pc = set.entry) \n. F (pc = unset.entry)) under the compassion requirements. A speci.cation containing set and unset can \nbe translated to a speci.cation in the language of Section 2.1 using an application of the automata-theoretic \nframework for program veri.cation [31]. Namely, we translate the negation of the LTL formula above into \naB\u00a8uchi automaton and construct the synchronous product of the program and the automaton. Toward this \nend we introduce an extra variable q into our program denoting the state of the automaton and assume \nde.ned three constants representing the states of the automaton NONE, PENDING,and MATCHED. Initially \nq = NONE and the state PENDING is accepting. We then de.ne set and unset as is shown in Figure 3 and \nadd the fairness condition and transfer functions from Figure 3 to the speci.cation. The fairness constraint \nexcludes in.nite computations satisfying conditions (ii) and (iii) above. To exclude .nite computations \nsatisfying (ii) and (iii) we call error when the program terminates in the case when there is a pending \nset call. The original program satis.es the speci.cation if and only if it satis.es the transformed speci.cation, \ni.e. if the instrumented program is safe and fair terminating. 2.5 Using response requirements and state \nWe provide an example that shows how speci.cations can use set/unset and maintain internal state. It \nis based on a speci.cation of how a device driver is supposed to modify the processor s inter\u00adrupt request \nlevel (IRQL) that controls which kinds of interrupts are to be delivered. Two functions are involved: \nKeRaiseIrql(x, p) state { int irql = -1; } KeRaiseIrql.entry { if (irql == -1) { irql = KeGetCurrentIrql(); \nset(); } } KeLowerIrql.entry { if ($1 == irql &#38;&#38; irql > -1) { unset(); } irql = -1; } Figure \n4. A liveness property involving the Windows kernel APIs KeRaiseIrql and KeLowerIrql. The macro KeGetCurrentIrql \nrefers to a variable in the OS environment model. raises the IRQL to the value of x andwritesthe oldIRQLvalue \nto the location in memory pointed to by p; KeLowerIrql(y) lowers the IRQL to y. A driver must match these \noperations correctly: if it raises the IRQL then it must subsequently lower it back to the orig\u00adinal \nvalue. Note that it is a fatal (safety) error to call KeLowerIrql using y that was not returned by the \nimmediately preceding call to KeRaiseIrql. Figure 4 shows how this speci.cation is modeled in our lan\u00adguage. \nThis example demonstrates the usage of the state structure, which in this case contains an integer variable \nirql that stores the IRQL-value at the time of the call to KeRaiseIrql.Two trans\u00adfer functions are included \nin the speci.cation: one calling set if KeRaiseIrql is called (with a few side conditions), the other \ncall\u00ading unset only if KeLowerIrql is called appropriately. If the code the speci.cation of which we \nare writing uses the function IoCreateDevice, we might add the fairness clause from Figure 2 to the speci.cation \nin Figure 4 to restrict the behavior of this function. 2.6 Combining liveness and safety Speci.cations \ncan contain both liveness and safety properties. In the case of Figure 5, we have a safety property mixed \ntogether with the liveness property from Figure 4. TERMINATOR will search for at least one violation \nof the properties, either of safety or liveness. state { int irql = -1; } KeRaiseIrql.entry { if ($1 \n<= KeGetCurrentIrql()) { error(); } if (irql == -1) { irql = KeGetCurrentIrql(); set(); } } KeLowerIrql.entry \n{ if ($1 >= KeGetCurrentIrql()) { error(); } if ($1 == irql &#38;&#38; irql > -1) { unset(); } irql = \n-1; } Figure 5. A speci.cation de.ning both liveness and safety prop\u00aderties involving the Windows kernel \nAPIs KeRaiseIrql and KeLowerIrql. The safety property in this case speci.es that KeRaiseIrql should not \nbeused tolower theIRQL, and KeLowerIrql should not be used to raise IRQL. 2.7 Discussion Temporal properties \ncan be speci.ed using temporal logics such as LTL [27]. However, such properties can also be speci.ed \nusing automata on in.nite words [32] (in fact, LTL is less expressive than such automata); see also [24]. \nTo extend the expressive power of LTL to that of automata on in.nite words, industrial languages, such \nas ForSpec [4] and PSL [1], add to LTL a layer of regular expressions. Logic-based speci.cations have \nthe advantage that they are eas\u00adily combined, composed, and can be used to express deeper prop\u00aderties \nof code. Automata-based speci.cations have the advantage they are more like computer programs and are \ntherefore easier for programmers to use. Speci.cations in SLIC, for example, can be viewed as automata \non .nite words. In this paper we are taking an automata-based approach to specifying temporal properties \nproperties in our language can be viewed as automata on in.nite words. We note that compilation techniques \ndescribed in [32] can be used to extend TERMINATOR to logic-based speci.cations. Set and unset make it \neasier to specify properties being in\u00adstances of response speci.cation pattern [18]. The same approach \nas was taken here can be used to add other speci.cation patterns to our language.  3. Verifying fair \ntermination In this section we describe a novel algorithm for checking fair termination of programs. \nThe approach we take is to use counterexample-guided re.nement for building fair termination ar\u00adguments \n(i.e., relations justifying that the program is fair termi\u00adnating). The algorithm is an extension of \nthe TERMINATOR al\u00adgorithm [14]. It adds support for fair termination using the proof rule proposed in \n[28], which separates reasoning about fairness and well-foundedness by using transition invariants [30]. \nAssume that the speci.cation to be checked has already been instrumented into the program and the problem \nof checking the conformance of the program to the liveness speci.cation has been reduced to a fair termination \nproblem as described in Section 2.2. We .x a program P =(S,T,T ,C)represented by a fair discrete system \nwith a (.nite) set of compassion requirements C.We want to check whether the program P terminates under \nthe compassion requirements C. 3.1 Counterexample-guided re.nement for fair termination First of all, \nwe introduce some auxiliary de.nitions. A binary relation R is well-founded if it does not admit any \nin.nite chains. We say that a relation T is disjunctively well-founded [30] if it is a .nite union T \n=T1 . .... Tn of well-founded relations. We remind the reader that a computation s is a maximal se\u00adquence \nof states s1,s2,... such that s1 is an initial state, and for each i = 1there exists a transition t .T \nsuch that si goes to si+1 under .t . A .nite segment si,si+1,...,sj of a computation where i<j is called \na computation segment. Note that all the states constituting a computation segment must be reachable \nfrom initial states. Following [28], we de.ne two auxiliary functions that map a set of states S to a \nset of compassion requirements: NoneC(S)={(p,q).C| S n p=\u00d8}, SomeC(S)={(p,q).C| S n q = \u00d8}. Let S be \nthe set of states that appear in a computation segment s. Then, NoneC(S)and SomeC(S)record the compassion \nrequire\u00adments from C that are ful.lled on the in.nite computation p ob\u00adtained by repeating sin.nitely \nmany times and pre.xing the result with a computation segment from an initial state of the program to \nthe starting state of s (we know that such a computation segment exists since all the states in s are \nthe reachable states of the pro\u00adgram P). NoneC(s)keeps track of the compassion requirements (p,q) that \nare ful.lled because pcontains only .nitely many states from p. SomeC(s) keeps track of the compassion \nrequirements (p,q) that are ful.lled because p contains in.nitely many states from q. Finally, let RC \n={(s1,sn+1)|. computation segment s =s1,...,sn+1. NoneC(s). SomeC(s)=C}. We call RC the fair binary reachability \nrelation. RC consists of all the pairs of starting and ending states of (.nite) computation segments \nof the program P such that, if repeated as above, will give (in.nite) computations satisfying all the \ncompassion requirements from C. We remind the reader that all the states in a computation segment must \nbe reachable from the initial states so the states in RC are reachable from the initial states too. The \nfollowing adaptation of Theorem 3 from [28] forms the basis for our algorithm. THEOREM 1. The program \nP terminates under the compassion requirements C if and only if there exists a disjunctively well\u00adfounded \nrelation T such that RC . T. Theorem 1 says that to prove a program P fair terminating we have to cover \nits fair binary reachability relation by a .nite union of well-founded relations. We build such a relation \nT by iterative re.nement extending T each time a spurious counterexample is discovered. Instead of considering \none computation segment at a time we cover the set of computation segments resulting from the execution \nof a sequence of program statements as a whole. This is formalized in the following notions of path and \nfair path. We de.neapath p to be a .nite sequence of program transi\u00adtions. Given a path p = t1,...,tn,we \nsay that p is fair with respect to a compassion requirement (p,q) if some computation segment s = s1,...,sn+1 \nobtained by executing the statements input Program P Compassion requirements C begin T := \u00d8 repeat \nif exists path psuch that fair(p) and .p .T then if .p is well-founded by W then T := T .W else return \nCounterexample path p else return Fair termination argument T end. Figure 6. Incremental construction \nof a fair termination argument. The compassion requirements on the program specify when the predicate \nfair(p) holds for a path p. The existence of a fair ter\u00admination argument implies the validity of the \ngiven liveness prop\u00aderty under fairness constraints. The evaluation of the underlined if-expression is \nexplained in Section 3.2. The relation W can be computed using a ranking function synthesis engine, e.g., \n[29]. of p either does not visit any p-states or traverses some q-state. A path is fair, written as fair(p), \nif it is fair with respect to every compassion requirement in C. The algorithm for the construction of \na fair termination argu\u00adment is presented in Figure 6. The algorithm .rst performs a fair bi\u00adnary reachability \nanalysis to check whether the inclusion RC .T holds. Fair binary reachability analysis is described in \nSection 3.2. .p is the path relation, which is also de.ned in Section 3.2. If the subset inclusion holds \nthen, by Theorem 1, P terminates under the compassion requirements Cand we report fair termina\u00adtion. \nIn the case that the inclusion does not hold, a fair path p is produced such that .p . T. The algorithm \nthen checks if there exists a well-founded relation W (called a ranking relation) cover\u00ading .p. If such \na relation does not exist, prepresents a potential fair termination bug and the algorithm terminates. \nOtherwise, the rank\u00ading relation W is added to the set T. This ensures that the same path will not be \ndiscovered at the subsequent iterations of the algo\u00adrithm. The ranking relation W can be generated using \nany tool for ranking function synthesis [10, 11, 17, 29]. In practice W produced by these tools is usually \nsuf.cient for ruling out not only p,but also all the paths that are obtained by repeating p. 3.2 Binary \nreachability for fair termination The problem of checking fair binary reachability consists of check\u00ading \nthe inclusion RC .T for a program P with a set of compassion requirements C= {(p1,q1),...,(pm,qm)}and \na relation T.The solution we propose here is based on an extension of the procedure for solving binary \n(as opposed to ordinary unary ) reachability. Our extension takes into account the compassion requirements \nC. The key idea of the approach is to leverage the techniques from symbolic software model checking for \nsafety properties (e.g. [12, 20, 21]). Note that techniques are available for reducing check\u00ading of fair \ntermination to safety checking [31]. We use here another reduction which is more amenable to automated \nabstraction tech\u00adniques. Fair binary reachability analysis is performed by transform\u00ading the program \nP to a program P T , the set of reachable states of which represents the fair binary reachability relation \nof the original program. The inclusion RC . T holds if and only if the trans\u00adformed program satis.es \na certain safety property. If the safety property is violated, then the inclusion does not hold and the \ncoun\u00adterexample provided by the safety checker can be used to construct the path pin the underlined expression \nin Figure 6. We transform the program P to the program P T in the follow\u00ading way. Let V = {v1,...,vn,pc}be \nthe set of all program vari\u00adables in P including the program counter pc. The set of variables of the \nprogram P T contains V and the corresponding pre-versions v1,..., vn, pc. Besides, we introduce two Boolean \narrays in p P T and in q indexed by 1,...,m. Therefore, a state of can be represented by a tuple (s,r,in \np,in q),where s,r .S.The state (s,r,in p,in q)represents a computation segment starting with s andendingwith \nr.The variable in pj (respectively, in qj )istrue if and only if there is a state in the segment satisfying \npj (respec\u00adtively, qj). We assume that initially v = v and all elements of in p and in q are false. The \ntransformation is shown in Figure 7. To simplify the pre\u00adsentation, consider .rst the program P obtained \nusing the trans\u00adformation without the assignment to fair and the assert state\u00adment. At each state of \nthe program P we update the elements of in p and in q and we can also non-deterministically choose to \nstart recording a new computation segment. In this case we copy all the program variables to the corresponding \npre-variables and clear the contents of the arrays in p and in q. Let T be the set of initial states \nof the program P de.ned as above, S the set of states of P and post+ T) the set of states of P P ( reachable \nafter at least one step. The following theorem formally de.nes the meaning of the transformed program \ndescribed above. THEOREM 2. Suppose that in the program P there are no transi\u00adtions to the initial locations. \nThen post+ T) ={(s1,sn+1,in p,in q)| P ( .computation segment s = s1,...,sn+1. .j .{1,...,m}. (in pj \n= false .(pj ,qj ).None({s1,...,sn})) . (in qj = true .(pj,qj).Some({s1,...,sn}))}. Proof sketch. . . \nFor each state from the set on the left-hand side of the equality there exists a sequence of program \ntransitions of P leading to it from an initial state. We prove the inclusion by induction on the length \nof this sequence. . . For each computation segment from the set on the right\u00adhand side of the equality \nthere exists a sequence of program tran\u00adsitions of P leading from an initial state to the .rst state \nin the computation segment. We .rst prove the inclusion in the case when this sequence is empty. We then \nprove the general case by induction on the length of the computation segment. D The technical restriction \non the initial locations is due to the fact that we do not transform the initial statement of the program, \nand is inherited from the binary reachability analysis of [14]. Note that in Theorem 2 and in the rest \nof the paper we consider the sequence of operations resulting from the transformation of a statement \nof the original program as one statement (transition) of the transformed program. The states in computation \nsegments are reachable from the initial states of the original program and, therefore, the sets of states \nsand rin the theorem depend on T . To check whether the inclusion RC .T holdswehavetostop the reachability \ncomputation as soon as the current computation segment is fair and T is violated on it. The assert statement \nin the program transformation ensures this. Consider now the full trans\u00adformation shown in Figure 7 and \nthe corresponding program P T . The set of states of the program P T resulting from the transforma\u00adtion \nis S .{ERROR}(where ERROR is the state to which the program goes when an assert is violated) and the \ntransition relation is a  input P: program over variables v1, ..., vn, program counter pc, and initial \nlocation L0 {(p1,q1),...,(pm,qm)}: set of compassion requirements T: candidate fair termination argument \ngiven by an assertion over the program variables and their pre-versions v1, ..., vn, pc begin 1. Add \npre-variables to P: v1,..., vn, pc, 2. Add auxiliary variables to P: fair, in p1,..., in pm, in q1, \n..., in qm 3. Replace each statement (except for the one at the initial location L0)    with L: \nstmt;  L: fair = ((!p1 &#38;&#38; !in p1)|| q1 || in q1)&#38;&#38; ...  ((!pm &#38;&#38; !in pm)|| \nqm || in qm); assert(!fair || T); if (nondet()) { vi =vi;/* for each i .{1,...,n}*/ pc = L; in pi =0; \n/* for each i.{1,...,m}*/ in qi =0; /* for each i.{1,...,m}*/ } if (pi)in pi =1; /* for each i .{1,...,m}*/ \nif (qi)in qi =1; /* for each i .{1,...,m}*/ stmt; 4. Add initialization statements: pc = L0; v1 =v1; \n... vn = vn; end. Figure 7. Program transformation for checking fair binary reachability using a temporal \nsafety checker. nondet() represents nondetermin\u00adistic choice. ( subset of the transition relation of \nP . We denote with post+ T) P T the set of states of P reachable after at least one step. THEOREM 3. \nSuppose that in the program P there are no transi\u00adtions to the initial locations. Then the inclusion \nRC .T holds if and only if the state ERROR is not reachable in the program . PT P T Proof. If . Suppose \nthe contrary: ERROR is unreachable in and RC . T. Then there exists a computation segment s = s1,...,sn,sn+1 \nsuch that NoneC(s) . SomeC(s)= C and (s1,sn+1).T. For each j .{1,...,m}we de.ne ( 0 false, if (pj ,qj).NoneC({s1,...,sn}); \nin p = j true, otherwise and ( 0 true, if (pj ,qj ).SomeC({s1,...,sn}); in q = j false, otherwise. 0 \n( By Theorem 2 we have that (s1,sn+1,in p ,in q 0).post+ T). P P T Since ERROR is unreachable in , it \nis also the case that n+1,in p 0 ,in q 0).post+ T). Consider the execution of (s1,s ( P T P T PT starting \nfrom this state. As the program has no transitions to the initial location, the program counter in the \nstate sn+1 is dif\u00adferent from the initial location and so the next statements to execute will be the \nones in the auxiliary code shown in Figure 7. Taking into account the de.nition of in p 0 and in q 0 \nabove and the fact that NoneC(s) .SomeC(s)= Cone can see that fair will evaluate to true.But then since \n(s1,sn+1). T the assert will fail and,    ( hence, ERROR .post+ T), which contradicts our initial \nassump- P T tion. Only if . Again, suppose the contrary: RC . T and ERROR is reachable in P T . Since \nwe do not apply the transformation in Figure 7 to the initial location, it follows that there exists \na state 0 ( (s1,sn+1,in p ,in q 0).post+ T) such that (s1,sn+1).T P T andonthis state fair evaluates \nto true. Wehavethat post+ T) .post+ T) .{ERROR}, ( ( P T P  thus, (s1,sn+1,in p 0 ,in q 0).post+( T). \n P Then according to Theorem 2 there exists a computation seg\u00adment s = s1,...,sn,sn+1 such that for all \nj = {1,...,m} in p 0 = false .(pj ,qj ).None({s1,...,sn}) j and in q 0 = true .(pj ,qj ).Some({s1,...,sn}). \nj Since fair evaluates to true on (s1,sn+1,in p 0 ,in q 0),we have that NoneC(s).SomeC(s)= Cand, hence, \n(s1,sn+1).RC.But since RC .T it follows that (s1,sn+1).T, which contradicts a previously established \nfact. D It follows from Theorem 3 that to check fair binary reachabil- P T ity one can apply a temporal \nsafety checker on the program to prove the non-reachability of the location ERROR or generate a corresponding \ncounterexample. In the latter case the counterexam\u00adple returned by the safety checker is a lasso path, \ni.e. a sequence of program statements of the form t1,...,tn,...,tp,tn.The path    state {} PPBlockInits.entry \n{ set(); } PPUnblockInits.entry { unset(); } Figure 9. An example liveness property for the program fragment \nin Figure 8. tn,...,tp,tn becomes then the path pin the algorithm in Figure 6. The path relation corresponding \nto this path is de.ned as follows: .p = {(s2,s3)|.s1 .T. (s1,s2)..t1 .\u00b7\u00b7\u00b7..tn-1 .(s2,s3)..tn .\u00b7\u00b7\u00b7..tp \n}. P T Optimizations. The transformation of P into was presented above somewhat idealistically. In practice, \nit is suf.cient to instru\u00adment the code shown in Figure 7 only on cutpoints [19]; see [14] for details. \nAdditionally, program slicing techniques can be used to eliminate redundant assignments to variables \nadded during the transformation and sometimes the variables themselves. Example. Consider the code fragment \nfrom Figure 8. Imagine that we are trying to prove that whenever PPBlockInits is called, PPUnblockInits \nwill eventually be called (Figure 9) with the fairness constraint from Figure 2. Our implementation constructs \na disjunctively well-founded re\u00adlation T for each cutpoint in the program s control-.ow graph. Sup\u00adpose \nthat we are considering the cutpoint at location 3. While per\u00adforming fair binary reachability analysis, \nour extension to TERMI-NATOR would produce the code in Figure 10. We assume the fol\u00adlowing conditions: \n We have already translated set and unset away, instrumented the fairness constraints, and constructed \nthe analogous fair ter\u00admination problem. The compassion requirements on the result\u00ading program are (pc \n=6.1, pc =6.3) (corresponding to the fairness constraint from Figure 2) and (true, q =PENDING)(corresponding \nto the condition on set and unset). The variables in p1 and in q1 are used to represent the com\u00adpassion \nrequirement corresponding to the fairness constraint in Figure 2. The variables in p2 and in q2 correspond \nto the con\u00additions on set and unset, and hence the property in Figure 9 (the variable in p2 can be eliminated \nas explained below).  TERMINATOR has already has constructed a candidate fair ter\u00admination argument \nfor program location 3:  T(s,t). t(i)>s(i).t(i)<t(Pdolen) .s(Pdolen)=t(Pdolen). The differences between \nFigure 8 and Figure 10 are as follows: Lines INIT.1 INIT.5 initialize the state of the automaton q, \npre-variables, and variables for keeping track of compassion requirements.  Lines 0.1 0.5 and 19.1 19.3 \ncome from the property s transfer functions and in this case are just inlining of the code for set and \nunset from Figure 3.  Lines 6.1 6.4 update the auxiliary variables associated with the compassion requirement \ncorresponding to the fairness con\u00adstraint in Figure 2.  Lines 2.1 2.3 update the auxiliary variables \nassociated with the compassion requirement obtained from the condition on the set and unset. In principle \nthe updates should appear at each line in the new program. However, using live variables analysis, we \nremove many of them in q2 only needs to be evaluated before it is used. We have also removed in p2 since \nafter the simpli.cation of the Boolean expression in line 2.4 (see below) its value is not used in the \nprogram.  Line 2.6 executes a non-deterministic decision as to whether or not to take a snapshot of \nthe current state. Since this program is then passed to a temporal safety checker, this means that, given \nany valuations returned by nondet during numerous executions through this loop, if a bad set of valuations \nexists, the model checker will .nd it this gives us full coverage of the property.  Lines 2.7 2.10 copy \nthe current state into the auxiliary vari\u00adables and clear the contents of the variables for keeping track \nof compassion requirements. This has the effect of starting the recording of a new computation segment. \nAs an optimization we copy only variables that are used in the candidate fair termi\u00adnation argument. \n Lines 2.4 2.5 check the termination condition in the case when the compassion requirements are not \nbeing violated. We simpli\u00ad.ed the Boolean expression in line 2.4 using the fact that one of the Boolean \nexpressions in the compassion requirement for set and unset is just true. After this simpli.cation the \nvari\u00adable in p2 was not used in line 2.4 anymore, which allowed us to eliminate it.  Lines EXIT.1 EXIT.3 \ncheck the absence of terminating com\u00adputations violating the condition on set and unset.  TERMINATOR \nwill perform an in.nite-state reachability check on the code in Figure 8 to check that the assert cannot \nfail and error() cannot be called. If TERMINATOR can prove that this cannot be the case, then the liveness \ncondition is not violated at this cutpoint and the algorithm proceeds to attempt to prove that the fair \ntermination property is not violated at the next cutpoint. 3.3 Lazy treatment of fairness constraints \nThe number of fairness constraints that appear in properties of pro\u00adgrams with complex interaction with \nthe environment can be large. In many cases some of these constraints may not be required to prove the \nproperty. We observe that our abstraction-based algo\u00adrithm naturally exploits this fact, due to the following \nreasons. First, our encoding of fairness using Boolean variables that keep track of the ful.lment of \nthe constraints does not introduce a signi.cant in\u00adcrease in the program size. Second, by applying a \ncounterexample\u00adguided abstraction re.nement procedure based on predicate ab\u00adstraction to validate fair \ntermination arguments we only consider those fairness constraints that are relevant to the property. \nThis is ensured by predicate abstraction together with a re.nement proce\u00addure, which only tracks values \nof those variables that appear in the predicates that de.ne the abstraction.   4. Experimental results \nIn this section we describe the results from experiments with our implementation of the proposed algorithm \non Windows device drivers. In order to perform the experiments we have implemented the algorithm as an \nextension to the TERMINATOR termination prover [15], which uses SDV [5] as its underlying safety checker. \nTables 1 through 4 contain the statistics from these experiments. We used three liveness properties involving \nthe acquiring and re\u00adleasing of resources together with the fair termination property in Figure 2. The \nfairness constraint from Figure 2 was also used in the former three experiments (Tables 1 through 3). \nNote that Figure 8. Example code from a Windows device driver dispatch routine. The correct behavior \nof the code depends on the fairness constraint from Figure 2.   1 PPBlockInits(); 2 while (i < Pdolen) \n{ 3 DName = PPMakeDeviceName(lptName[i], PdoType, dcId[i], num); 4 if (!DName) { break; } 5 RtlInitUnicodeString(&#38;deviceName, \nDName); 6 status = IoCreateDevice(fdx->do, PDOSZ, &#38;deviceName, 0, 0, TRUE, Pdo[i]); 7 if (STATUS_SUCCESS \n!= status) { 8 Pdo[i] = NULL; 9 if (STATUS_OBJECT_NAME_COLLISION == status) { 10 ExFreePool(DName); 11 \nnum++; 12 continue; 13 } 14 break; 15 } else { 16 i++; 17 } 18 } 19 num = 0; 20 PPUnblockInits(); SDV \ns model of the driver s environment has a main function that non-deterministically decides to call one \nof the driver s dispatch routines meaning that, in the case of SDV, Figure 2 represents the termination \nof every dispatch routine within the device driver. We used a timeout threshold of 10,000 seconds and \na memory limit of one gigabyte. T/O in the tables means that timeout limit was exceeded. LOC denotes \nLines of code . During these experiments we found several previously unknown bugs. Note that, if the \nnumber of Bugs found is 0, then this means that TERMINATOR has found a proof that the driver does not \nviolate the speci.cation. The validity of the liveness properties that we checked on the device drivers \ndid not depend on signi.cant tracking of heap manipulations or bit-level operations, which caused false \nbugs in experiments with TERMINATOR [14]. This is why we have not obtained any false bugs in our experiments. \nWe note that techniques from [8] can be used to perform termination analysis in cases where accurate \ntracking of the heap is required for proving fair termination. The experimental results demonstrate that \nwe have .nally ob\u00adtained a method for checking liveness properties of real systems code. We believe that \nthe experience that we have had with Win\u00addows device drivers will match the results that users will have \nin other similar domains.  5. Related work Our proposed algorithm builds on a large body of formal founda\u00adtions, \nranging from the formalization of the semantics of programs by fair discrete systems [25] and the automata-theoretic \napproach to temporal veri.cation [31] to the more recent construction of .x\u00adpoint domains for abstract \ninterpretation with fairness [28]. We also use recent advances in the area of automatic termination analysis \n(e.g. [11, 14]). From these foundations we have developed (to the best of our knowledge) the .rst known \nfully automatic veri.cation tool for liveness properties of in.nite-state programs. The key difference \nbetween TERMINATOR and .nite-state model checkers that support liveness checking, e.g. SPIN [22], Bandera \n[16], and Java PathFinder [33], is that TERMINATOR em\u00adploys completely automatic abstraction, while the \nothers either ex\u00adplore the state space as-is (SPIN) or use user-provided and, hence, not automatic abstractions \n(Bandera). These tools will terminate with Out-Of-Memory for programs with in.nite or very large state \nspaces. Automatic abstraction provides effectiveness and ef.\u00adciency to overcome this limitation. The \nidea of using program transformations to convert liveness into safety is known in .nite-state model checking \n[9, 31]. Here we adapt these ideas to the context of in.nite-state systems. It is possible to approximate \na liveness property by a stronger safety property. One strategy is to bound the number of steps in which \nthe eventually-event must occur. This does not scale well to large numbers of events, and it is often \ndif.cult to decide which .nite number of steps should be taken. Another approach is to write a safety \nproperty that at least speci.es that the liveness property will not be violated by any terminating executions. \nThis is, in fact, what the developers of SDV do today: they construct a number of main.exit transfer \nfunctions in SLIC that check that the liveness property is not violated when the driver terminates. In \nthis case SDV will miss any violations to liveness properties that involve non-terminating executions. \n 6. Conclusion Since automatic safety property checking has only recently become a reality, automatic \nliveness proving for real code has been con\u00adsidered impossible. TERMINATOR is the .rst known tool to \nbreak through this liveness checking barrier. We have applied TERMINA-TOR to device drivers ranging in \nsizes from 1,000 to 20,000 LOC. The proposed algorithm takes advantage of recent advances in termination \nanalysis by converting the problem of liveness check\u00ading into fair termination checking. The scalability \nand support for real programming language features comes from the termination analysis. This paper has \nalso presented a language in which live\u00adness properties can be expressed. Through the use of examples \nwe have also demonstrated a set of liveness properties that should be checked on Windows device drivers. \nIn fact: over 1/3 of the safety speci.cations included in the today s SDV distribution have analogous \nand equally important liveness properties that should be checked. Similar properties will exist in other \nprogramming domains, such as Linux device drivers, embedded software, real-time systems, etc. Limitations. \nA few notes about limitations: As program termination is an undecidable problem, TERMINA-TOR s analysis \nis not guaranteed to terminate. Initialization INIT.1 INIT.2 INIT.3 INIT.4 INIT.5 q = NONE; pre_pc = \n1; pre_i = i; pre_Pdolen = Pdolen; in_p1 = in_q1 = in_q2 = 0; Body 0.1 0.2 0.3 0.4 0.5 1 2 2.1 2.2 2.3 \n2.4 2.5 2.6 2.7 2.8 2.9 2.10 2.11 3 4 5 6 6.1 ... if (q == NONE) { /* set() */ if (nondet()) { q = PENDING; \n} } PPBlockInits(); while (i < Pdolen) { if (q == PENDING) { in_q2 = 1; } fair = (!in_p1 || in_q1) &#38;&#38; \n((q == PENDING) || in_q2); assert(!fair || !(pre_pc == 3) || (i > pre_i &#38;&#38; i < Pdolen &#38;&#38; \npre_Pdolen == Pdolen)); if (nondet()) { pre_pc = 3; pre_i = i; pre_Pdolen = Pdolen; in_p1 = in_q1 = in_q2 \n= 0; } DName = PPMakeDeviceName(lptName[i], PdoType, dcId[i], num); if (!DName) { break; } RtlInitUnicodeString(&#38;deviceName, \nDName); status = IoCreateDevice(fdx->do, PDOSZ, &#38;deviceName, 0, 0, TRUE, Pdo[i]); in_p1 = 1; 6.2 \n6.3 6.4 7 8 9 10 11 12 13 14 15 16 17 18 19 19.1 19.2 19.3 20 if (status != STATUS_OBJECT_NAME_COLLISION) \n{ in_q1 = 1; } if (STATUS_SUCCESS != status) { Pdo[i] = NULL; if (STATUS_OBJECT_NAME_COLLISION == status) \n{ ExFreePool(DName); num++; continue; } break; } else { i++; } } num = 0; if (q == PENDING) { /* unset() \n*/ q = MATCHED; } PPUnblockInits(); ... Exit points EXIT.1 EXIT.2 EXIT.3 if (q == PENDING) { error(); \n} Figure 10. Code produced while performing fair binary reachability analysis on the code from Figure \n8. nondet() represents nondetermin\u00adistic choice.  Counterexamples are not guaranteed to be real counterexam-MINATOR \nmay return a proof of correctness when the code is ples. Our proposed algorithm attempts to prove that \nthe prop-not correct due to the fact that TERMINATOR s symbolic safety erty holds, not that it doesn \nt hold. checker assumes that integers are not bounded and that code is always being executed in a sequential \nsetting. For this rea\u00ad Thevalidityofproofsconstructedin TERMINATOR reliesonthe son the proof is restricted \nto sequential code in which over.ow soundness of the underlying safety checker. For example, TER\u00adcannot \noccur. Driver Time (seconds) LOC Bugs found 1 15 1K 1 2 314 7K 0 3 2344 15K 0 4 3122 20K 1 1R 16 1K 0 \n4R 3217 20K 0 Table 1. Checking entering and leaving critical regions. The property proved is the property \nin Figure 9 with KeEnterCriticalRegion and KeLeaveCriticalRegion substituted for PPBlockInits and PPUnblockInits \nrespec\u00adtively. The fairness constraint used is the one from Figure 2. The bugindriver 1 was known.The \nbugindriver 4 was not known before. Drivers 1R and 4R are repaired versions of driver 1 and 4 respectively. \nDriver Time (seconds) LOC Bugs found 1 23 1K 0 2 188 7K 0 3 271 15K 0 4 T/O 20K T/O Table 2. Checking \nacquiring and releasing of spin locks. The property being checked is the property in Figure 9 with KeAcquireSpinLock \nand KeReleaseSpinLock substituted for PPBlockInits and PPUnblockInits respectively. The fairness constraint \nused is displayed in Figure 2. Driver Time (seconds) LOC Bugs found 1 62 1K 5 2 N/A 7K N/A 3 N/A 15K \nN/A 4 T/O 20K T/O 1R 35 1K 0 Table 3. Checking modi.cations of IRQLs. The property being checked is \nthe one in displayed in Figure 4 together with the fair\u00adness constraint from Figure 2. The bugs in driver \n1 were known. Driver 1R is a repaired version of driver 1. Drivers 2 and 3 are marked as N/A because \nthey call neither KeRaiseIrql nor KeLowerIrql, the property is trivially true. Driver Time (seconds) \nLOC Bugs found 1 9 1K 0 2 129 7K 0 3 1463 15K 1 4 T/O 20K T/O Table 4. Checking the termination of driver \ndispatch routines under a fairness constraint. The fair termination property being checked is in Figure \n2. The main function in SDV s model of the driver s environment considers all possible calls to the driver \ns dis\u00adpatch routines meaning that Figure 2 represents the termination of every dispatch routine within \nthe device driver. The bug in driver 3 was previously unknown. As previously described, TERMINATOR uses \npointer analysis to over-approximate the pointer aliasing relationships during instrumentation. In some \ncases this over-approximation may lead to aliasing relationships that do not occur in the program, which \nmay result in false counterexamples being reported. In many cases false-aliasing relationships can be \nresolved later during binary reachability (as described in [14]), but not always.  Acknowledgments \nAndreas Podelski and Andrey Rybalchenko are supported in part by the German Research Foundation (DFG) \nas a part of the Transre\u00adgional Collaborative Research Center Automatic Veri.cation and Analysis of Complex \nSystems (SFB/TR 14 AVACS), by the Ger\u00adman Federal Ministry of Education and Research (BMBF) in the framework \nof the Verisoft project under grant 01 IS C38. Moshe Vardi is supported in part by NSF grants CCR-9988322, \nCCR-0124077, CCR-0311326, and ANI-0216467, by BSF grant 9800096, by Texas ATP grant 003604-0058-2003, \nand by a Guggenheim Fellowship. Part of this work was done while the au\u00adthor was visiting the Isaac Newton \nInstitute for Mathematical Sci\u00adence, as part of a Special Programme on Logic and Algorithms, as well \nas Microsoft Research, Cambridge, UK. References [1] ALBIN ET AL. Property speci.cation language reference \nmanual. Tech. Rep. Version 1.1, Accellera, 2004. [2] ALPERN,B., AND SCHNEIDER, F. De.ning liveness. Information \nprocessing letters 21 (1985), 181 185. [3] ALPERN,B., AND SCHNEIDER, F. Recognizing safety and liveness. \nDistributed computing 2 (1987), 117 126. [4] ARMONI,R., FIX,L., FLAISHER,A., GERTH,R., GINSBURG,B., KANZA,T., \nLANDVER,A., MADOR-HAIM,S., SINGERMAN,E., TIEMEYER,A., VARDI,M., AND ZBAR, Y. The ForSpec temporal logic: \nA new temporal property-speci.cation logic. In TACAS 02: Tools and Algorithms for the Construction and \nAnalysis of Systems (2002), vol. 2280 of LNCS, Springer-Verlag, pp. 296 311. [5] BALL,T., BOUNIMOVA,E., \nCOOK,B., LEVIN,V., LICHTENBERG, J., MCGARVEY,C., ONDRUSEK,B., RAJAMANI,S.K., AND USTUNER, A. Thorough \nstatic analysis of device drivers. In EuroSys 06: European Systems Conference (2006). [6] BALL,T., AND \nRAJAMANI, S. K. SLIC: A speci.cation language for interface checking (of C). Tech. Rep. MSR-TR-2001-21, \nMicrosoft Research, 2001. [7] BERDINE,J., CHAWDHARY,A., COOK,B., DISTEFANO,D., AND O HEARN, P. Variance \nanalyses from invariance analyses. In POPL 07: Principles of Programming Languages (2007), ACM Press. \n[8] BERDINE,J., COOK,B., DISTEFANO,D., AND O HEARN,P. Automatic termination proofs for programs with \nshape-shifting heaps. In CAV 06: Computer-Aided Veri.cation (2006), vol. 4144 of LNCS, Springer-Verlag, \npp. 386 400. [9] BIERE,A., ARTHO,C., AND SCHUPPAN, V. Liveness checking as safety checking. In FMICS \n02: Formal Methods for Industrial Critical Systems (2002), vol. 66(2) of ENTCS. [10] BRADLEY,A., MANNA,Z., \nAND SIPMA, H. Linear ranking with reachability. In CAV 05: Computer-Aided Veri.cation (2005), vol. 3576 \nof LNCS, Springer-Verlag, pp. 491 504. [11] BRADLEY,A., MANNA,Z., AND SIPMA, H. Termination of polynomial \nprograms. In VMCAI 05: Veri.cation, Model Checking, and Abstract Interpretation (2005), vol. 3385 of \nLNCS, Springer-Verlag, pp. 113 129. [12] COL\u00b4 URIBE, Generating .nite-state ON,M.A., AND T. E. abstractions \nof reactive systems using decision procedures. In CAV 98: Computer-Aided Veri.cation (1998), vol. 1427 \nof LNCS, Springer-Verlag, pp. 293 304. [13] COOK,B., PODELSKI,A., AND RYBALCHENKO,A. Abstraction re.nement \nfor termination. In SAS 05: Static Analysis Symposium (2005), vol. 3672 of LNCS, Springer-Verlag, pp. \n87 101. [14] COOK,B., PODELSKI,A., AND RYBALCHENKO,A. Termination proofs for systems code. In PLDI 06: \nProgramming Language Design and Implementation (2006), ACM Press, pp. 415 426. [15] COOK,B., PODELSKI,A., \nAND RYBALCHENKO,A. Terminator: Beyond safety. In CAV 06: Computer-Aided Veri.cation (2006), vol. 4144 \nof LNCS, Springer-Verlag, pp. 415 418. [16] CORBETT,J., DWYER,M., HATCLIFF,J., PASAREANU,C., ROBBY,LAUBACH,S., \nAND ZHENG, H. Bandera: Extracting .nite-state models from Java source code. In ICSE 00: Int. Conf. on \nSoftware Engineering (2000), IEEE Press, pp. 439 448. [17] COUSOT, P. Proving program invariance and \ntermination by parametric abstraction, Lagrangian relaxation and semide.nite programming. In VMCAI 05: \nVeri.cation, Model Checking, and Abstract Interpretation (2005), vol. 3385 of LNCS, Springer-Verlag, \npp. 1 24. [18] DWYER,M.B., AVRUNIN,G.S., AND CORBETT,J.C. Patterns in property speci.cations for .nite-state \nveri.cation. In ICSE 99: Int. Conf. on Software Engineering (1999), IEEE Press, pp. 411 420. [19] FLOYD, \nR. W. Assigning meanings to programs. In Mathematical Aspects of Computer Science (1967), J. T. Schwartz, \nEd., vol. 19 of Proceedings of Symposia in Applied Mathematics,American Mathematical Society, pp. 19 \n32. [20] GRAF,S., AND SA\u00a8IDI, H. Construction of abstract state graphs with PVS. In CAV 97: Computer-Aided \nVeri.cation (1997), vol. 1254 of LNCS, Springer-Verlag, pp. 72 83. [21] HENZINGER,T., JHALA,R., MAJUMDAR,R., \nAND SUTRE, G. Lazy abstraction. In POPL 02: Principles of Programming Languages (2002), ACM Press, pp. \n58 70. [22] HOLZMANN,G.J. The model checker SPIN. IEEE Transactions on Software Engineering 23, 5 (1997), \n279 295. [23] KESTEN,Y., PNUELI,A., AND RAVIV, L. Algorithmic veri.cation of linear temporal logic speci.cations. \nIn ICALP 98: Int. Colloq. on Automata, Languages and Programming (1998), vol. 1443 of LNCS, Springer-Verlag, \npp. 1 16. [24] KURSHAN,R. Computer Aided Veri.cation of Coordinating Processes. Princeton Univ. Press, \n1994. [25] MANNA,Z., AND PNUELI,A. The Temporal Logic of Reactive and Concurrent Systems: Speci.cation. \nSpringer-Verlag, Berlin, 1992. [26] MICROSOFT CORPORATION. Windows Static Driver Veri.er. Available at \nwww.microsoft.com/whdc/devtools/tools/SDV.mspx, July 2006. [27] PNUELI, A. The temporal logic of programs. \nIn Proc. 18th IEEE Symp. on Foundation of Computer Science (1977), pp. 46 57. [28] PNUELI,A., PODELSKI,A., \nAND RYBALCHENKO, A. Separating fairness and well-foundedness for the analysis of fair discrete systems. \nIn TACAS 05: Tools and Algorithms for the Construction and Analysis of Systems (2005), vol. 3440 of LNCS, \nSpringer-Verlag, pp. 124 139. [29] PODELSKI,A., AND RYBALCHENKO, A. A complete method for the synthesis \nof linear ranking functions. In VMCAI 04: Veri.cation, Model Checking, and Abstract Interpretation (2004), \nvol. 2937 of LNCS, Springer-Verlag, pp. 239 251. [30] PODELSKI,A., AND RYBALCHENKO, A. Transition invariants. \nIn LICS 04: Logic in Computer Science (2004), LNCS, IEEE Press, pp. 32 41. [31] VARDI, M. Veri.cation \nof concurrent programs the automata\u00adtheoretic framework. Annals of Pure and Applied Logic 51 (1991), \n79 98. [32] VARDI,M., AND WOLPER, P. Reasoning about in.nite computa\u00adtions. Information and Computation \n115, 1 (1994), 1 37. [33] VISSER,W., HAVELUND,K., BRAT,G., PARK,S., AND LERDA,F. Model checking programs. \nAutomated Software Engineering Journal 10, 2 (2003).  \n\t\t\t", "proc_id": "1190216", "abstract": "In recent years we have seen great progress made in the area of automatic source-level static analysis tools. However, most of today's program verification tools are limited to properties that guarantee the absence of bad events (<i>safety properties</i>). Until now no formal software analysis tool has provided fully automatic support for proving properties that ensure that good events eventually happen (<i>liveness properties</i>). In this paper we present such a tool, which handles liveness properties of large systems written in C. Liveness properties are described in an extension of the specification language used in the SDV system. We have used the tool to automatically prove critical liveness properties of Windows device drivers and found several previously unknown liveness bugs.", "authors": [{"name": "Byron Cook", "author_profile_id": "81323489213", "affiliation": "Microsoft Research", "person_id": "PP40031078", "email_address": "", "orcid_id": ""}, {"name": "Alexey Gotsman", "author_profile_id": "81322494535", "affiliation": "University of Cambridge", "person_id": "P831272", "email_address": "", "orcid_id": ""}, {"name": "Andreas Podelski", "author_profile_id": "81100130920", "affiliation": "University of Freiburg", "person_id": "PP39028940", "email_address": "", "orcid_id": ""}, {"name": "Andrey Rybalchenko", "author_profile_id": "81100483883", "affiliation": "EPFL and MPI-Saarbr&#252;cken", "person_id": "P688961", "email_address": "", "orcid_id": ""}, {"name": "Moshe Y. Vardi", "author_profile_id": "81100371692", "affiliation": "Rice University", "person_id": "P203106", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1190216.1190257", "year": "2007", "article_id": "1190257", "conference": "POPL", "title": "Proving that programs eventually do something good", "url": "http://dl.acm.org/citation.cfm?id=1190257"}