{"article_publication_date": "01-17-2007", "fulltext": "\n Program Veri.cation as Probabilistic Inference Sumit Gulwani Microsoft Research, Redmond sumitg@microsoft.com \n Abstract In this paper, we propose a new algorithm for proving the validity or invalidity of a pre/postcondition \npair for a program. The algorithm is motivated by the success of the algorithms for probabilistic in\u00adference \ndeveloped in the machine learning community for reason\u00ading in graphical models. The validity or invalidity \nproof consists of providing an invariant at each program point that can be locally veri.ed. The algorithm \nworks by iteratively randomly selecting a program point and updating the current abstract state representa\u00adtion \nto make it more locally consistent (with respect to the abstrac\u00adtions at the neighboring points). We \nshow that this simple algorithm has some interesting aspects: (a) It brings together the complemen\u00adtary \npowers of forward and backward analyses; (b) The algorithm has the ability to recover itself from excessive \nunder-approximation or over-approximation that it may make. (Because the algorithm does not distinguish \nbetween the forward and backward informa\u00adtion, the information could get both under-approximated and \nover\u00adapproximated at any step.) (c) The randomness in the algorithm ensures that the correct choice of \nupdates is eventually made as there is no single deterministic strategy that would provably work for \nany interesting class of programs. In our experiments we use this algorithm to produce the proof of correctness \nof a small (but non-trivial) example. In addition, we empirically illustrate several important properties \nof the algorithm. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program \nVeri.cation; F.3.1 [Logics and Meanings of Programs]: Specifying and Verifying and Reasoning about Pro\u00adgrams; \nG.3 [Mathematics of Computing]: Probability and Statis\u00adtics; I.2.6 [Computing Methodologies]: Arti.cial \nIntelligence General Terms Algorithms, Theory, Veri.cation Keywords Program Veri.cation, Forward and \nBackward Analy\u00adsis, Over and Under Approximation, Automated Recovery, Ma\u00adchine Learning, Belief Networks, \nFactor Graphs, Probabilistic In\u00adference, Markov Chain Monte Carlo, Gibbs Sampling 1. Introduction The \nprogram veri.cation problem is to verify the Hoare triple, (fpre ,P,fpost ),where fpre and fpost are \nthe precondition and postcondition respectively of program P. The Hoare triple is said to be valid if \nfor all program states satisfying fpre , whenever the Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 07 January 17 19, 2007, Nice, France. Copyright c &#38;#169; \n2007 ACM 1-59593-575-4/07/0001. . . $5.00. Nebojsa Jojic Microsoft Research, Redmond jojic@microsoft.com \nprogram P terminates, it does so in a state that satis.es fpost .A proof of validity of the Hoare triple \n(fpre ,P,fpost ) can be in the form of an invariant at each program point such that the invariants can \nbe easily veri.ed locally. A proof of invalidity of the Hoare triple (fpre ,P,fpost ) can be in the form \nof the proof of validity of the Hoare triple (f.,P,\u00acfpost ) for some f.that is consistent pre pre with \nfpre . (In this formalism for proof of invalidity, we assume that the end of program P is reached during \nall executions of the program.) In this paper, we describe how probabilistic inference tech\u00adniques, heavily \nstudied in the machine learning community, can be used to discover the invariants at each program point \nthat constitute either a proof of validity or a proof of invalidity of a given Hoare triple. The algorithm \nworks by running in parallel the search for validity proof and invalidity proof of the Hoare triple. \nThe proof search routine starts by initializing the state abstractions (potential invariants) at all \nprogram points to anything (e.g., .). It then it\u00aderatively chooses a random program point p whose abstract \nstate representation is locally inconsistent, and updates it to make it less locally inconsistent. To \nbe more precise, the state abstraction at p is chosen randomly from the abstract domain, with probability \nin\u00adversely proportional to its local inconsistency. The local inconsis\u00adtency of the state abstraction \nat a program point is a monotonic measure of the set of program states that are not consistent with the \nstate abstraction at the neighboring program points. The proof search routine stops when these abstractions \nare all locally con\u00adsistent in which case they constitute program invariants that prove either validity \nor invalidity of the Hoare triple (depending on what de.nition of consistency was used for the program \ns entry and exit points). This algorithm is described formally in Section 3. The above proof discovery \nalgorithm, though simple, has some interesting aspects to it. The algorithm combines the complementary \npowers of both for\u00adward and backward analysis by bringing information from both forward and backward \ndirections at each program point. We de\u00ad.ne the local inconsistency of an abstract representation of \npos\u00adsible program states at a program point as a measure of the set of program states that are not consistent \nwith the state abstrac\u00adtions at neighboring program points (as opposed to considering only the immediate \npredecessor program points, which would constitute a forward analysis, or as opposed to considering only \nthe immediate successor program points, which would result in only a backward .ow of information). Result \nof this is that effectively, the forward analysis uses the information from the backward analysis to \nguide its over-approximation, while the backward analysis uses the information from the forward analy\u00adsis \nto guide its under-approximation.  Even though bringing information from both forward and back\u00adward \ndirections yields a more re.ned choice of abstractions, these abstractions may not be the right ones. \nHowever, our al\u00adgorithm places much less burden on the optimality of these  choices since it offers \nchances of recovery at each step. This is because it does not distinguish between the information brought \nin by the forward analysis or the backward analysis, and as a re\u00adsult, the information can get both over-approximated \nor under\u00adapproximated in any step. Contrast this with a traditional for\u00adward analysis in which the information \nat any program point gets weakened in successive updates. Hence, once the informa\u00adtion computed at a \nprogram point overapproximates the invari\u00adants required at that point to establish the postcondition, \nthe postcondition cannot be established. 1 The inference procedure is based on smooth real-valued cost \nfunctions, rather than binary costs (where invariants are either considered to be in agreement or not). \nThis could be thought of as giving the algorithm partial credit for its guesses, and thus providing it \nwith more information about which direction to take in order to further improve the invariants. However, \namong the possible choices that have approximately equal bene.ts, the algorithm chooses randomly. Thus, \nour algorithm falls into the category of sampling techniques studied extensively in [20]. The above aspects \nare discussed in more detail in Section 5 with examples of parts of the proof search that we saw in our \nexperi\u00adments. The algorithm we introduce here is a form of a Gibbs sampling technique, which is one of \nthe probabilistic inference techniques used in machine learning [20]. Many machine learning problems \nare concerned with the discovery of hidden quantities at nodes of a graph that satisfy given constraints, \nand so the machine learning community has developed a number of such inference algorithms, which can \nboth be deterministic and randomized. In this paper, we de.ne program veri.cation in a way that allows \nmost of these tech\u00adniques to be applied to this problem, as well. For this purpose, we introduce the \nnovel notion of an inconsistency measure for any ab\u00adstract domain Athat is equipped with a partial order \n..An in\u00adconsistency measure Mfor Ais any function from ordered pairs (f, f )of elements from Ato [0, \n1]that is monotonically increas\u00ading in its .rst argument f, monotonically decreasing in its second argument \nf ,and 0 iff f . f . We use this measure to de.ne the local inconsistency of a program point s set of \nreachable states (which belongs to A) with respect to the sets of reachable states at neighboring program \npoints. Given these local measures, we can pose the problem of program invariant inference as inference \nin probabilistic graphical models. The particular inference algorithm we use in this paper uses the inconsistency \nmeasure to give pref\u00aderence to those potential invariants that minimize the local incon\u00adsistency. A large \nclass of new algorithms for program veri.cation can bene.t from a real-valued measure of inconsistency, \nas it can be used as a measure of the progress of the algorithm. We implemented our algorithm for programs \nthat have linear as\u00adsignments and whose conditional predicates have the form of dif\u00adference constraints. \nWe chose the abstract domain for representing invariants to be the set of boolean formulas over difference \ncon\u00adstraints. In the spirit of Occam s razor principle, the formulas are of bounded size, thus biasing \nthe search towards simpler proofs. We tested the algorithm on a small non-trivial example program with \npre/postcondition pair. We show that our tool can consistently solve this problem in .nite time, whereas \nthe brute force search would be infeasible. 1 Similarly, in a traditional backward analysis the information \nat any pro\u00adgram point gets strengthened in successive updates. Hence, once the oblig\u00adation computed at \na program point underapproximates the invariants that are true at that program point under the precondition, \nthe validity of the pre/postcondition pair cannot be established. 2. Notation Let Abe some abstract \ndomain, whose elements represent sets of program states. Let . :A.2S be the concretization function that \nrelates the abstract domain and the concrete domain, i.e., for any element f .A, .(f)gives the set of \nall program states represented by f.Let .and .represent the usual bottom and top elements in the abstract \ndomain, i.e., .(.)= \u00d8and .(.)=S. We say that an abstract element f is stronger than f (denoted by f .f \n)if .(f) . .(f ). We also say that f holds at program point p to denote that .(f)is an over-approximation \nof the set of program states that are possible at p. We use the notation pentry and pexit to denote the \nprogram s entry and exit point. For simplicity, we assume (without loss of any generality) that there \nare no self loops on any program node. We use the notation fi to denote the latest choice of the abstract \nelement (made by our algorithm) at program point pi. Given fi for all program points pi, and any program \npoint pk other than pentry,let Post(pk )denote the set of (strongest) abstract elements such that for \nany element f . Post(pk ), wehavethe following property: If for all immediate predecessors pj of pk, \nfj holds at pj,then f holds at pk. Similarly, given fi for all program points pi, and any program point \npk other than pexit,let Pre(pk ) denote the set of (weakest) abstract elements such that for any element \nf .Pre(pk ), we have the following property: If f holds at pk, then for all immediate successors pj of \npk, fj holds at pj . For notational convenience, we say that: def def Post(pentry)= . and Pre(pexit)= \n. Since there are no self-loops on any program node, any program point pk is not its own immediate successor \nor predecessor. Hence, the de.nitions of Post(pk )and Pre(pk )are well-formed. We use the notation Post(pk \n).f to denote that f .f for some f . Post(pk ). Similarly, we sometimes use the notation f .Pre(pk ) \nto denote that f .f for some f .Pre(pk ). An inconsistency measure on the abstract domain A is any function \nthat maps ordered pairs of elements from Ato [0, 1]and has the following properties for any elements \nf,f ,f .Athat satisfy f .f . M(f, f )=0.  M(f, f )=M(f ,f ).  M(f ,f )=M(f ,f).  Observe that an \ninconsistency measure M (which satis.es the above properties) provides a natural measure of how much \nincon\u00adsistent is the relationship f .f for any ordered pair (f, f ). Given fi for all program points \npi, and an inconsistency mea\u00adsure M,we de.ne the local inconsistency of f at pk to be the following quantity: \nL(f, pk)= Min {M(f ,f) | f .Post(pk )}+ Min {M(f, f ) | f .Pre(pk )} Given fi for all program points \npi, we say that f is locally consis\u00adtent at pk when Post(pk ).f and f .Pre(pk ) Observe that given fi \nfor all program points pi,and forany in\u00adconsistency measure M, the following property holds: f is locally \nconsistent at pk iff L(f, pk)=0.  3. Algorithm In this section, we describe the learning based semi-algorithm \nfor producing a proof of validity or invalidity of the Hoare triple FindProof(P,\u00df)= 1 For all program \npoints pi, initialize fi :=.; 2 While penalty of any program point is non-zero: 3 Choose program point \npk .{pi | \u00df(fi ,pi ) =0} uniformly at random. -\u00df(f,pk ) 4 Choose f.A with probability proportional to \ne . 5 Update fk :=f; 6 Output( Proof found. ); 7 For all program points pk, output( Invariant at , pk, \n is , fk); Decide((fpre ,P,fpost ))= 1 Let \u00dfV and \u00dfI be the penalty functions as defined in Section \n3.1. 2 In parallel execute: [ FindProof(P,\u00dfV )I FindProof(P,\u00dfI )]; Figure 1. The machine learning based \nsemi-algorithm for producing a proof of validity or invalidity of the Hoare triple (fpre ,P,fpost ). \n(fpre ,P,fpost ). The proof of validity consists of providing an ab\u00adstract element fi at each program \npoint pi such that: A1. fentry =fpre . A2. fexit =fpost . A3. fi is locally consistent at pi. The proof \nof invalidity consists of providing an abstract element fi at each program point pi such that: B1. .(fentry)n.(fpre \n) \u00d8(i.e., fentry is consistent with fpre =). B2. fexit =\u00acfpost . B3. fi is locally consistent at pi. \nNote that in the above formalism for proof of invalidity of the Hoare triple, we make the assumption \nthat the program point pexit is reachable in all program executions. (Alternatively, the proof of invalidity \nmay consist of providing a concrete program state s such that the execution of the program in state s \nreaches program point pexit, and in such a state that satis.es \u00acfpost . Such a counter\u00ad example may be \nproduced from fentry by selecting a concrete pro\u00ad gram state s from .(fentry)and checking whether program \npoint pexit is reached when the program is executed in s. If not, then the process of .nding a new s \n. .(fentry), or the initial process of .nding a new set of invariants at each program point that satisfy \nProperties B1-B3 is repeated.) Henceforth, we assume that our task is to .nd a set of invariants at each \nprogram point such that either properties A1-A3 are satis.ed, or properties B1-B3 are satis.ed. We assume \nthat we are given an abstract domain A(with . as the concretization function that relates the abstract \ndomain with the concrete domain) such that all invariants in the proofs are expressible in this abstract \ndomain A. In particular, fpre .A and fpost .A. Our algorithm is also parameterized by some inconsistency \nmeasure M(as de.ned in Section 2) associated with A, which gives a numeric measure of how much is the \npartial order relationship (.) not satis.ed between two given elements of A. The pseudo-code for the \nlearning algorithm is described in Fig\u00ad ure 3. The procedure Decide((fpre ,P,fpost )runs the process \nof .nding the proof of validity of the Hoare triple (fpre ,P,fpost ) (FindProof(P,\u00dfV )) in parallel with \nthe process of .nding the proof of its invalidity (FindProof(P,\u00dfI )). Each of these processes use the \nsame algorithm FindProof, but invoked with different penalty functions \u00dfV and \u00dfI . \u00dfV enforces the constraints \ndescribed in properties A1-A3 on the invariants, while \u00dfI enforces the con\u00ad straints described in properties \nB1-B3 on the invariants. The FindProof algorithm works by initializing the abstract el\u00ad ements at all \nprogram points to anything (e.g., .). It then iteratively chooses a random program point pk whose abstract \nelement fk is locally inconsistent, and updates fk to make it less locally incon\u00adsistent. To be more \nprecise, fk is chosen randomly with probability inversely proportional to the exponent of its penalty \nat pk.Given fi for all program points pi, the penalty of an abstract element fat a program point pk is \na non-negative number, which measures unac\u00adceptability of fat pk. The penalty function is the only deterministic \npart of the algorithm, and should be carefully designed to guide the learning algorithm towards the solution. \n 3.1 Penalty Function The penalty function should have the following properties. A1. Soundness: When \nthe penalty of abstract elements at all pro\u00ad gram points has been reduced to 0, then the collection of \ninvari\u00ad ants at those program points constitutes a valid proof. A2. Monotonicity: The penalty function \nshould assign a greater penalty to abstract elements that are more locally inconsistent. Property A1 \nis essential for correctness of the algorithm, while property A2 is important for faster convergence \nof the algorithm. Hence, for any inconsistency measure Mon A, we can de.ne a valid penalty function (which \nsatis.es properties A1 and A2) for proving the validity of the Hoare triple (fpre ,P,fpost )as follows. \n\u00dfV (f,pentry)=0,if f=fpre =8, otherwise (1) \u00dfV (f,pexit)=0,if f=fpost =8, otherwise (2) \u00dfV (f,pk )=N \n\u00d7L(f,pk) Note that Equation 1 and Equation 2 enforce the constraint that the abstract elements at the \nprogram points pentry and pexit must be fpre and fpost respectively. N denotes a large constant. It is \neasy to see that a bigger value of N increases likelihood of selection of abstract elements that minimize \npenalty, and hence may result in faster con\u00advergence. However, a smaller value of N mayalso result infaster \nconvergence in two ways: (a) by decreasing the time required to get out of local minima (if the algorithm \never gets stuck there), (b) by increasing the gradient of change. (This is equivalent of widen\u00ading/narrowing \nin standard abstract interpretation terminology [3].) Hence, the choice of N should ideally be determined \nby perform\u00ading experiments. The function Lis the local inconsistency measure (as de.ned in Section 2), \nwhich is a function of the inconsistency measure Massociated with the abstract domain A. Similarly, we \ncan de.ne a valid penalty function (which satis.es properties A1 and A2) for proving the invalidity of \nthe Hoare triple (fpre ,P, fpost ) (assuming that the end of the P is always reached) as follows: \u00dfI \n(f, pentry)= 8,if .(f) n .(fpre )= \u00d8 (3) = N \u00d7 L(f, pentry),otherwise \u00dfI (f, pexit)=0,if f = \u00acfpost = \n8, otherwise (4) \u00dfI (f, pk )= N \u00d7 L(f, pk) Equation 3 enforces the constraint that there is .exibility \nin choos\u00ading the abstract element at pentry only if it is consistent with fpre , i.e., the intersection \nof the sets .(f) and .(fpre ) is non-empty. Equation 4 enforces the constraint that the abstract element \nat pexit must be \u00acfpost .  4. Derivation and the properties of the algorithm In this section, we derive \nthe algorithm described above by .rst posing the program veri.cation problem as a case of inference in \nprobabilistic graphical models, and then turning to one of the sim\u00adplest probabilistic inference techniques \n Gibbs sampling to per\u00adform inference. Properties of this algorithm have been extensively studied in \nthe literature, e.g., [20]. As discussed above, a program invariant we are searching for is a set {f \nk} which satis.es the constraints imposed by the pro\u00adgram instructions. Inference of program invariants \ncan therefore be viewed as optimization of the level to which these constraints are satis.ed. For example, \nif the abstraction is expressive enough, and the program is correct (the precondition of the program \nindeed im\u00adplies the postcondition of the program), then all the constraints im\u00adposed by program instructions \nwill be fully satis.ed by the optimal set {f k}. 4.1 Discovery of program invariants through probabilistic \ninference Instead of a binary treatment of the constraint satisfaction (satis.ed or unsatis.ed), we \nconstruct a real-valued function f(f0,f1, ..., fK ) which attains a maximum value at the program invariant \n{f k}, i.e., f(f 0,f 1, ..., f K ) = max f(f0,f1, ..., fK ). (5) Clearly, one such function would assign \nzero to any combination of expressions that does not satisfy the program constraints, and one to true \nprogram invariants (of which there could be several, depending on the abstraction). However, as was indicated \nin the previous section, and as will be discussed further later, in many optimization techniques, it \nis important that the combinations {fk}which only partially satisfy the constraints are assigned a non-zero \nvalue corresponding to the level of constraint violation. We can use the structure of the program to \nwrite the satisfac\u00adtion function f as a product of factors fi associated with different program nodes. \nEach of these factors is a function of the appro\u00adpriate set of variables describing the abstract elements \nbefore and after the program node. We will denote by Fi the set containing the appropriate pre-and post-execution \nstates for the i-th factor, each associated with the appropriate program node. Then, we de.ne . f(f0,f1, \n..., fK )= fi(Fi), (6) i and de.ne each of the factors fi(Fi) so that they reach their maximum when the \nset of abstract elements in Fi are consistent with the node between them. The graph consists of a number \nof variables (in our case these variables describe abstract elements fk for different program points \npk), and factors fi whose product de.nes a global function of these variables. The algorithm of the previous \nsection is using factors fi which drop exponentially with the constraint violation penalty: -a(Fi) fi(Fi)= \ne (7) where a(Fi) is de.ned to be sum of the inconsistencies of the elements of Fi multiplied by N. For \nexample, Figure 2 shows how to visualize the structure of such functions as a factor graph [18] for the \nprogram shown in Figure 3(a). We have F8 = {f5,f7,f8},and a(F8)= N \u00d7 (M(f5,f8)+ M(f7,f8)). (This is because \nf8 is a join node, which enforces the constraint that f5 . f8 and f7 . f8.) Given this function, we can \nformulate several interesting tasks within the framework of inference in probabilistic graphical mod\u00adels. \nFirst, we can normalize the function f by dividing it by a con\u00adstant Z (often called a partition function), \nso that the sum over all possible combinations of expressions fk within the abstraction of interest is \nequal to one, i.e., ... Z = f1.A ... f(f0,f1, ..., fK ). This leads to f0.A fK .A a probability distribution \nfunction 1 p(f0,f1, ..., fK )= f(f0,f1, ..., fK ), (8) Z whose sum over all possible combinations of \nexpressions fk is in\u00addeed equal to one, and whose maximum is still at the same optimal set {f k} (or \na set of optima if there are more than one such set). We can think of (one or more) optimal expression \ncombinations f 0, ..., f K as very likely under this probability distribution. In this paper we are especially \ninterested in the case where some of the program states fk are given while others are hidden. For example, \nthe given states could be program asserts, including the program pre-condition and post-condition (entry \nand exit beliefs). We will denote by FG the given states and by FH the hidden states. Some interesting \nquestions that probabilistic inference techniques can be employed to answer include: What is the most \nlikely set of unobserved program states FH if we are already given some states FG, e.g., FG = {fentry,fexit}. \nIn other words, what is arg max p(FH |FG), where p(FH |FG) denotes the conditional probability distrib\u00adution \nover the abstract representations over program states in FH ?  What are the other likely combinations \nof expressions for FH given FG, or in other words, can we draw several samples from p(FH |FG)?2  Note \nthat answers to these two questions (as well as other probabilistic inference goals) are related. For \nexample, if we can sample from the conditional distribution, then we are likely to come across the most \nlikely states {f k} sooner rather than later. Thus, a search for the optimal state can be performed by \nsampling. In fact, if all combinations of expressions {fk} that fully satisfy the constraints have the \ntotal probability ps under the distribution p, then the probability of not discovering one of these combinations \nwhen asinglesampleis drawn from p is (1 - ps), and the chance of missing it in n steps is (1 - ps)n. \nTherefore, the probability 2 Drawing a sample from a distribution refers to any randomized algo\u00adrithm \nwhich can produce many samples ft , ..., ft , so that the fraction of 1K times a certain combination \nf1, ..., fK is achieved is expected to be equal . T to p(f1, ..., fK ), i.e., limT .8 t=1[(ft , ..., \nftK )=(f1, ..., fK )] = 1 p(f1, ..., fK ), with [] denoting and indicator function, which is equal to \none when the equality is satis.ed and zero otherwise. Clearly such an algo\u00adrithm is going to be more \nlikely to produce samples with high probability under the distribution p. of missing the solution will \ndrop exponentially as more and more samples are taken, and the speed of the drop will depend on the level \nof the penalty for constraint violation, as this penalty controls the probability of program invariants \nsatisfying the constraints. Over the last couple of decades, the machine learning commu\u00adnity has been \ndeveloping general techniques for probabilistic infer\u00adence that use the structure of the graphical model \nto optimize the performance. These techniques include, for example, belief prop\u00adagation, variational \ntechniques, and sampling techniques. Each of these techniques has interesting provable and empirically \ndiscov\u00adered properties, well documented in, among other places, some of the papers we refer to in this \npaper. Some of these algorithms are meant to estimate (or maximize) probabilities and not draw sam\u00adples, \nand as such they are often deterministic, but may get stuck in a local minimum of the optimization criterion. \nFor a comparison of several inference techniques on a simple visual example, see, for example [9]). \n 4.2 Gibbs sampling The algorithm described in the previous section is a form of one of the simplest \nprobabilistic inference techniques, known as Gibbs sampling which, like many other probabilistic inference \ntech\u00adniques, has .rst been developed by physicists to compute the dis\u00adtribution over states of a physical \nsystem (see references in [20]). We use this technique to draw samples from a distribution over the program \nstates at different program points p(f1, ..., fk), un\u00adder the constraint that the boundary states at \nprogram asserts (or just the beginning and the end) are equal to the given expressions in FG. In other \nwords, we sample from the conditional distribu\u00adtion p(FH |FG). We stop this process once we reach the \nprogram invariant {f k}which maximizes our satisfaction function f.As discussed above, since the combinations \nof program states {fk}with higher levels of constraint satisfaction f are more likely than the ones with \nless satisfaction (by construction of p), this process should generally attain the maximum of f much \nsooner than a brute force search for a program invariant. The Gibbs sampling algorithm consist of iteratively \nupdating each of the expressions fk while keeping others .xed. To make the discussion more concrete, \nand without lack of generality, we assume for the rest of this section that we are given the program \ns entry state fentry and exit state fK = fexit, and we need to .nd the rest of the expressions f1, ..., \nfK-1 that satisfy f0 and fK , just as in the algorithm in Figure 1. The process is started from an arbitrary \ninitialization of f1, ..., fK-1. Then, a series of updates is performed. In each update, one of the current \nexpressions fj, j .{2, 3, ..., K -1}is replaced by a sample from the conditional distribution p(fj|f1, \n..., fj-1,fj+1, ..., fK }. It is easily shown that, 1 . p(fj|f1, ..., fj-1,fj+1, ..., fK }= fi(Fi), (9) \nZj i|fj .Fi where Zj is a scaling constant that normalizes the product of factors involving the expression \nfj . Using the factors of the form Equation 7, we get: . 1 - a(Fi) p(fj|f1, ..., fj-1,fj+1, ..., fK } \n= e i|fj .Fi Zj 1 -\u00df(fj,pj ) = e, (10) Zj where \u00df is the penalty function described in the previous section. \nComputing this function given the program states at neighboring points is simple, and we can think of \nthis step as satisfying with high probability the requirement that the belief about the state of the \nprogram at a program point should be sandwiched between the appropriate pre-and post-conditions of the \nneighboring instruc\u00adtions, which only depend on the current belief about the state of the small number \nof neighboring program points. One appealing property of Gibbs sampling is that, under the assumption \nthat the current sample ft 1, ..., ft has been drawn K-1 from the desired distribution p(f1, ..., fK-1|f0,fK \n), replacing one of the expressions ftj by a sample ftj +1 drawn from the con\u00additional distribution p(fj|f1, \n..., fj-1,fj+1, ..., fK }will also re\u00adsult in the new updated sample ft 1, ..., ftj-1,ft+1,fjt +1, ..., \nft jK-1 drawn from the target distribution p(f1, ..., fK-1|f0,fK ). This means that the desired distribution \nis a stationary distri\u00adbution of this process, i.e., if at any given time the process starts producing \nsamples from the desired distribution, it will continue to do so. In addition, it has been shown that \nas long as the distribu\u00adtion p is non-zero everywhere, this process will indeed reach this .xed distribution \n[20], regardless of how the states are initialized. After that point, and usually even earlier, the most \nlikely con.gu\u00ad ration of expressions f 2, ..., f K-1 is likely to be reached, with the probability of \nmissing the solution dropping exponentially as more and more samples are taken. If the constraint violation \npenalties are high, the probability of sampling a true program invariant will be higher, and the speed \nof convergence faster. But, on the other hand, if many combinations of program states are highly penal\u00adized, \nthe sampling process may get trapped -the samples can get isolated by zero probability regions around \nthem, making it dif.cult to suf.ciently improve them to cross into the regions of the space of the combinations \nof program states which satisfy the program constraints even better. Some of the properties of the Gibbs \nsampling algorithm studied in the machine learning literature are rather intuitive. For instance, since \nthe updates are incremental, it is bene.cial to use smooth target functions (f and p, which are equivalent \nin terms of their maxima as they differ only by a constant scaling factor). In addi\u00adtion, in order to \nguarantee that the procedure can reach all possible combinations of program states expressible in the \nabstraction do\u00admain, we should not assign zero probability to any combination of the expressions fk. \nThis is why the factors fi should be crafted so that fi .[E, 1]3, and so that the expressions that differ \na little have similar values, with the ones better satisfying the constraint having higher values, and \nthe ones fully satisfying it having the highest value of 1. Therefore, it is important to use penalties \na, \u00df that are smooth and .nite to guarantee that the sampling process will in\u00addeed traverse the space \nof possible program states fast enough and avoid getting stuck far from the solution.  5. Discussion \nIn this section, we discuss several interesting aspects of the sim\u00adple learning based algorithm. For \nthis purpose, we consider the program shown in Figure 3 with its pre/postcondition pair, as an example. \nWe .rst show why several existing techniques (with the exception of a recently proposed technique) fail \nto work well on this example program. We then discuss the interesting aspects of our algorithm that enable \nit to reason about this example. 5.1 Limitations of Other Techniques Reasoning about the validity of \nthe program in Figure 3 requires discovering the following invariants at program point p2: (x =50 . y \n= 50) . (x< 50 . x = y) . (x =100) A simple forward abstract interpretation [3] based analysis over the \npolyhedron abstract domain will fail to validate the example 3 Equivalently, penalties a and \u00df should \nbe zero or positive, but .nite f1 f3 f4 f6 f5 f7 f8  Figure 2. Factor graph of the program shown \nin Figure 3(a). program since it only computes invariants that are conjunctions of linear inequalities \n[6]. Recently, Gulavani and Rajamani have proposed a technique [11] based on counterexample driven re.nement \nfor abstract interpreta\u00adtion that can compute disjunctive invariants like the ones required for the example \nprogram [11]. The key idea of their technique is to keep track of precision losses during forward .xed-point \ncom\u00adputation, and do a precise backward propagation from the error to either con.rm the error as a true \nerror, or to use re.nement tech\u00adniques (in particular, replacing a widen operation by a disjunction) \nso as to avoid the false error. The key to discovering the invariant x< 50 .x = yis to realize that when \nthe false branch of the if-condition is entered for the .rst time, then the value of xis 50. However, \ntheir re.nement technique would only allow for discov\u00adering that when the false branch of the if-condition \nis entered for the .rst time then x=k,in the kth stage of their re.nement loop (for k=50). Hence, their \ntechnique will take 50 re.nement stages to discover the loop invariant x=50 .x= y, which is required \nto prove the correctness (and if this constant 50 were larger, it would a take a proportionally larger \nnumber of re.nement steps). How\u00adever, interestingly enough, their approach is able to work well on a \nmodi.cation of this example, in which all constants are replaced by symbolic constants. Predicate abstraction \n[10] techniques based on counter-example driven re.nement (like SLAM [1], BLAST [15], or [2]) are also \nable to discover such disjunctive invariants like the ones required for the example program. However, \nthe success of these tools on a given problem is contingent on being able to .nd the right predi\u00adcates. \nFor the example program, these tools would go into a pred\u00adicate re.nement loop discovering unnecessary \npredicates x =1, x=2, x=3, and so on, one by one. The number of re.nement steps required for this particular \nexample would be 100, (and po\u00adtentially in.nite, if these constants were larger or were symbolic constants). \nRecently, Jhala and McMillan have proposed a predicate re.ne\u00adment approach based on interpolants [16], \nwherein the search of interpolants is restricted to a richer class of languages in succes\u00adsive stages \nof their algorithm. The choice of the languages Lk that they suggest involves all predicates that contain \nnumeric constants no larger in absolute value than kfrom the constants that already occur in the program. \nSince the predicates required to prove the correctness of the example program belong to L1, their technique \nwill be able to prove the correctness of the example program.  5.2 Interesting Aspects of the Algorithm \nNote that predicate abstraction techniques, for a given set of pred\u00adicates, compute invariants that are \narbitrary boolean combination of the given set of predicates. However, an alternative thing to do would \nbe to restrict the size of the formulas as opposed to restrict\u00ading the set of predicates. The issue that \narises with such an alter\u00adnative is how to choose between the huge number of solutions that .t in the \nrestricted size. We resolve this issue by performing both forward and backward analysis at the point \nwhere the abstract ele\u00adment is to be updated, instead of just performing a forward-only or backward-only \nanalysis. More formally, we compute both weak\u00adest precondition Pre(p) and strongest postcondition Post(p) \nat the point pto be updated. We then choose a random solution fthat minimizes the inconsistency of the \nrelationships Post(p) .fand f.Pre(p) 4 (since there may not be one with same level of in\u00adconsistency). \nThis simple idea has several interesting aspects to it, which enable it to discover the proof of validity \nof the example pro\u00adgram. We elaborate on these interesting aspects below, by taking as examples parts \nof proof searches generated by an implementation of our algorithm. In our examples, we consider the abstract \ndomain Ato consist of all boolean formulas that involve at most 3 clauses (conjuncts), with each clause \nbeing a disjunction of at most 2 dif\u00adference constraints. Combination of Forward and Backward Analyses \nThe generic framework of our learning-based algorithm allows for combining the complementary powers of \nforward and backward analyses in a simple manner to obtain a strictly more precise analysis. While updating \nfk, our algorithm involves computing both Post(pk ) and Pre(pk ). Post(pk ) represents the forward .ow \nof information from the immediate predecessors of pk, while Pre(pk ) represents the backward .ow of information \nfrom the immediate successors of pk. A forward analysis would simply consider the set Post(pk ) and use \nsome heuristic to choose some abstract element f .Asuch that Post(pk ) .f. Our framework allows the forward \nanalysis to guide its choice of fby giving more preference to choices fsuch that the inconsistency of \nf .Pre(pk ) is minimized. Similarly, a backward analysis, which only considers Pre(pk ), can also use \nimmediate guidance from Post(pk ) in our framework. For example, consider the program shown in Figure \n3. Suppose f8 is to be updated, and the abstract elements (which in this case are boolean formulas) at \nneighboring points of p8 are as follows: 5 f5 =(x=0) .(x=50) .(y= 50) f7 =(x=51) .(x=100) .(x= y) f2 \n=(x<100 .y= 100) The above selection of abstract elements at program points p5, p7,and p2 would also \narise if two rounds of forward analysis and 4 More formally, the inconsistency of Post(p) . f means the \nminimum of the inconsistencies of f . f (i.e., M(f ,f))for any f . Post(p). Similarly, the inconsistency \nof f . Pre(p) means the minimum of the inconsistencies of f . f (i.e., M(f, f ))for any f . Post(p). \n5 For a discussion on how the predicate x=y is discovered by our algorithm, see the discussion under \nthe heading Random Choices on Page 8. : x = 0 Ipre Sentry y := 50;  Program Point Invariant p0 x=0 \np1 (y= 50) .(x=0) p2 (y=50 .x=50) .(y= x.x<50) .(y= 100 .x<100) p3 (y=50 .x=50) .(y= x.x<50) .(y=99 .x<99) \np4 (y= 50) .(x<50) p5 (y= 50) .(x<51) p6 (x=50) .(y= x.x<50) .(y=99 .x<99) p7 (x>50) .(y= x.x<51) .(y= \n100 .x<100) p8 (y=50 .x=50) .(y= x.x<50) .(y= 100 .x<100) p9 y= 100 (b) Proof of validity. Program \nInvariant Point p0 x=100 p1 (x=100) .(y= 50) .(y-x=-1) p2 (x=100) .(y-x=1 .y= 100) p3 false p4 false \np5 false p6 false p7 false p8 false p9 y= 100 (a) Program (c) Proof of invalidity when precondition \nfpre is changed to true. Figure 3. (a) shows an example program with pre and post conditions. (b) describes \nthe proof of validity, which consists of invariants at each program point such that the invariants can \nbe locally veri.ed. (c) describes the proof of invalidity when precondition fpre is changed to true. \ntwo rounds of backward analysis have been performed around the loop. Note that Post(p8 ) and Pre(p8 ) \ncan be represented by the following formulas: 6 Post(p8 ):(x=0 .x=50 .y= 50) . (x=51 .x=100 .x= y) Pre(p8 \n):(x<100 .y= 100) Observe that Post(p8 ) is equivalent to the following formula in conjunctive normal \nform, where each of the clauses is non\u00adredundant. 7 (x=100) . (x=50 .x= y) . (x=0) . (y=50 .x=51) Note \nthat we have .xed the abstract domain Ato consist of Boolean formulas involving at most 3 clauses, with \neach clause being a disjunction of at most 2 difference constraints. Dropping any one of the above 4 \nclauses yields an optimal over-approximation to Post(p8 ) that is an element of A. However, note that \nthe .rst 6 Technically, Post(p8 )and Pre(p8 )are sets of abstract elements. Hence, more formally, this \nmeans that any maximally strong formula that belongs to the abstract domain A and is implied by the formula \ncorresponding to Post(p8 )belongs to Post(p8 ). Similarly, any minimally strong formula that belongs \nto the abstract domain A and implies the formula correspond\u00ading to Pre(p8 )belongs to Pre(p8 ). 7 The \nclause y =50. x =y is redundant since it it implied by the conjunction of the given 4clauses. two clauses \nx = 100 and (x = 50 .x = y) are required to prove Pre(p8 ). Hence, taking this guidance from Pre(p8 ),the \nforward analysis should include the .rst two clauses in its over\u00adapproximation of Post(p8 ). This is \nwhat our algorithm also does. No distinction between Forward and Backward Information One way to combine \nforward and backward analyses is to maintain the following two separate pieces of information at each \nprogram point, and use them to guide each other. Forward information: Over-approximation of program \nstates that result when the program is executed under precondition. This is computed by the forward analysis. \n Backward information: Under-approximation of program states that ensure that the program will terminate \nin a state satisfying the postcondition. This is computed by the backward analysis.  The over-approximation \nprocess may take guidance from the back\u00adward information to ensure that the over-approximation at a pro\u00adgram \npoint is not weaker than the under-approximation computed at that point. (Similarly, the under-approximation \nprocess may take guidance from the forward information to ensure that the under\u00adapproximation computed \nat a program point is not stronger than the over-approximation computed at that point.) If these constraints \ncannot be met, they signal the presence of an excessive over\u00adapproximation or excessive under-approximation \nat some program point, which needs to be .xed. By excessive over-approximation, we mean that the invariants \ncomputed are weaker than those that are necessary to prove the postcondition. (Similarly, by excessive \nunder-approximation, we mean that the obligations that need to be established are stronger than what \nis indeed true of the pro\u00adgram under precondition.) Unless the excessive nature of the over\u00adapproximation \nor under-approximation information is .xed, the forward or backward analysis cannot prove the validity \nof the pre/postcondition pair. The main issue however is to .gure out the program points where this happened. \nWe can only design heuristics for this purpose, which may work well for some examples and may not work \nwell for other examples. Our technique addresses this issue in an interesting manner. Observe that if \nthere is no excessive over-approximation (with respect to precondition) and no excessive under-approximation \n(with respect to postcondition), then the under-approximation information is a valid over-approximation \n(assuming that the pre/postcondition pair is valid). Similarly, if there is no excessive under-approximation, \nthen the over-approximation information is a valid under-approximation. To summarize, when no mistake \noccurs (i.e., both the under-approximation and the over-approximation are not excessive) the under-approximation \nis an over-approximation, and the over-approximation is an under-approximation. Then, why distinguish \nthe two? Our technique thus maintains one piece of in\u00adformation at each program point, which is its guess \nfor the correct invariant (= unexcessive over-approximation = unexcessive under\u00adapproximation) at that \nprogram point. Now, this guess may actually be the correct invariant (i.e., it is established by the \nprecondition and is enough to establish the postcondition), or it may be an exces\u00adsive over-approximation \n(i.e., weaker than the invariant required to establish the postcondition) or an excessive under-approximation \n(i.e., it may be stronger than what is true when the precondition holds). The challenge now is that we \ndo not really know which of this is true. The only thing that we know is whether or not these guesses \nare consistent with the neighboring guesses. However, cor\u00adrections automatically creep in as the algorithm \nmakes progress trying to make the guesses more consistent with their neighbors, wherein the guesses can \nget strengthened as well as weakened. Contrast this with the above case where the forward and backward \ninformation is kept separate. In that case, inconsistency is in the form of the over-approximation getting \nweaker than the under\u00adapproximation (however, each of the two pieces of information are individually \nconsistent with the corresponding information at the neighboring nodes). But when an inconsistency is \ndetected, it has to be .xed before a proof can be discovered. It is also interesting to contrast our \ntechnique (which maintains one piece of information at each program point) with the backward\u00adonly technique \n(which also maintain only one piece of information at each program point). Note that if in the backward \nanalysis, the under-approximation becomes excessive (i.e., stronger than what is really true about the \nprogram at that point given the precondition), validity of pre/postcondition pair cannot be established. \nCompara\u00adtively, if the information computed by our technique is an exces\u00adsive under-approximation, it \nwill have a chance of recovery (i.e., it has the potential to get strengthened by forward .ow of infor\u00admation, \nwhich does not happen in a backward-only analysis). A similar comparison holds with the forward-only \ntechnique. As an example, we discuss below how the invariant x<50 . x = ygets discovered at program point \np2 after it is excessively under-approximated to x = yat some stage, in one of the proof searches seen \nin our experiments. The following is a snapshot of the formulas that were found at some step during the \nproof search. f1 =(x=0) . (y= 50) f2 =(x= y) . (x<100 . y= 100) f3 = f6 =(x<99 . y= 99) . (x=98 . y= \n98) f4 =(x<99 . y= 100) . (x=98 . y= 99) f5 = f7 = f8 =(x<100 . y= 100) . (x=99 . y= 99) Snapshot 1 Observe \nthat the above snapshot at program points p3,p4,p5,p6, and p7 makes sense from a backward analysis point \nof view, wherein, if the postcondition y= 100 is pushed backward through the loop two times, we get the \nabove con.guration. The above value of f2 is an under-approximation of Pre(p2 ),which is (x=99 . y= 99) \n. (x=98 . y= 98) . (x<100 . y= 100). However, it is an excessive under-approximation since x = yis not \nalways true at p2. Now, if this were a pure backward analy\u00adsis, then the validity of the program cannot \nbe established after Pre(p2 ) is under-approximated to the above value of f2.Onthe contrary, our algorithm \nis able to recover from such an excessive under-approximation because the information at a program point \ngets updated from both forward and backward directions (which results in weakening and strengthening \nof the information respec\u00adtively). In this particular case, our algorithm chooses to update f8,f7,f6,f3 \n(but not f5 and f4) which changes the above snap\u00adshot as follows (This can still be seen as backward \npropagation of information from f2). f1 =(x=0) . (y= 50) f2 =(x= y) . (x<100 . y= 100) f3 =(x<50 . x= \ny) . (x<99 . y= 99) f4 =(x<99 . y= 100) . (x=98 . y= 99) f5 =(x<100 . y= 100) . (x=99 . y= 99) f6 =(x= \ny) . (x<99 . y= 99) f7 = f8 =(x= y) . (x<100 . y= 100) Snapshot 2 Observe that Pre(p2 ) now is (x = 100 \n. x< 50 . x = y) . (x< 100 . y = 100). Now, the algorithm (randomly) decides to update f2 and detects \nthat it is inconsistent from the forward direction, but it can be made consistent in both directions \nby updating it to: f2 =(x<50 . x= y) . (x<100 . y= 100) Note that the discovery of invariant x<50 . x= \nyat p2 is crucial in order to validate the program. There are two crucial things to observe as to how \nthe algorithm discovered x< 50 . x = yat p2 in the above instance. Observe that f5 and hence f4 did not \nget updated, and that the algorithm tried to weaken f2 to make it more consistent in the forward direction, \nand was able to .nd something that made it fully consistent in both directions. Random choices An important \naspect of the algorithm is that it makes some random choices. One of the random choices that the algorithm \nmakes is to decide which program point to update. Observe that in the above proof search instance, if \nf4 also got updated at the same time when f8,f7,f6 and f3 got updated between snapshot 1 and 2,the algorithm \nmight have chosen something else for f2 because then it would not have been possible to choose anything \nfor f2 that makes it consistent in both directions. There is no clear strategy to decide in which order \nto update the program points. Hence, randomness plays an important role here. However, the interesting \nthing is that the chances of such inci\u00addents happening, though small, are not rare. For example, another \nsequence of updates that we saw in another proof search in pro\u00adducing the invariant (x<51 . x= y) at \nprogram point p2 after snapshot 1 is as follows. The formulas f4 and f5 get updated with the forward \ninformation from f3. Then, f3,f6 and f7 get updated : true Ipre Sentry x := 0; m := 0; S1 S2 False \nSexit : (mz0 B n\u00b7 0) A Ipost (m<n B n\u00b70) S6 S7 S8  (a) Program (b) Proof of validity Program Point \nInvariant p0 true p1 (x=0) .(m=0) p2 (x=0 .n=0) .(m=0 .n=0) .(m<n.n=0) p3 (x=0 .n=0) .(m=0 .n=0) .(m<n.n=0) \np4 (x=0 .n=0) .(m<n.n=0) p5 (x=-1 .n=0) .(m=0 .n=0) .(m<n.n=0) p6 (x=-1 .n=0) .(m=0 .n=0) .(m<n.n=0) \np7 (x=-1 .n=0) .(m=0 .n=0) .(m<n.n=0) p8 (x=0 .n=0) .(m=0 .n=0) .(m<n.n=0) p9 (m=0 .n=0) .(m<n.n=0) \nFigure 4. (a) shows an example program with pre and post conditions. (b) describes the proof of correctness, \nwhich consists of invariants at each program point such that the invariants can be locally veri.ed. based \non the forward information from f2. This results in the fol\u00adlowing snapshot: f1 =(x=0) .(y= 50) f2 =(x= \ny) .(x<100 .y= 100) f3 =(x<100) .(x= y) f4 =(x<50) f5 =(x<51) f6 =(x=50) .(x<100) .(x= y) f7 =(x=51) \n.(x<101) .(x= y) Now, f8 is updated to the following formula to minimize its local inconsistency at p8 \n(which is a function of f5, f7,and f2): (x<51 .x= y) .(x<101) This is followed by f2 getting updated \nto f8 to minimize the local inconsistency. The crucial point in the above sequence of updates is that \nf4 and f6 get updated from choice of f3 before f3 gets updated from choice of f2. The other random choice \nthat the algorithm makes is in choos\u00ading the abstract element at a given program point pk. It is possible \nthat there are several abstract elements that are locally consistent at pk, but some of those choices \nmay be better than the others. For example, consider the following snapshot that arose in one of the \nproof searches in our experiments. f1 =(x=0) .(y= 50) f3 =(x<99 .y= 99) .(x=98 .y= 98) . (x=97 .y= 97) \nf8 =(x<100 .y= 100) .(x=99 .y= 99) . Pre(p2 ) can be represented by the following formula: (x<100 .y= \n100) .(x<97 .x>99 .x= y) Note that we have .xed the abstract domain Ato consist of Boolean formulas involving \nat most 3 clauses, with each clause being a disjunction of at most 2 difference constraints. Hence, dropping \nany one or more of the disjuncts from the clause (x<97 .x> 99 .x= y) would satisfy the size restriction. \nHowever, guidance from Post(p2 ) suggests that x<97 must be included to minimize the inconsistency. Thus, \nthe following 3 are good choices for f2. Choice 1 :(x<100 .y= 100) .(x<97) Choice 2 :(x<100 .y= 100) \n.(x<97 .x>99) Choice 3 :(x<100 .y= 100) .(x<97 .x= y) Choice 3 is better than the other two choices since \nit yields the important predicate x= yrequired later to discover the invariant x<50 .x= y. Since there \nis no clear strategy what to choose, randomness plays a crucial role here.   6. Case Study: Boolean \nCombinations of Difference Constraints We implemented the learning algorithm for programs P whose assignment \nstatements s and conditional predicates p have the following form: s : x:= e p : x= e | x= e | x<e | \nx>e | x=e | x=e e : c | y+ c  Here xand yrefer to some integer program variables, while crefers to \nsome integer constant. The predicates pas de.ned above are also (x=98 .y= 98) called difference constraints. \nWe chose the abstract domain Awhose elements are boolean combinations of difference constraints among \nprogram variables. In particular, for computational reasons, we restricted the abstract domain A to include \nboolean formulas with a speci.c template, namely boolean formulas that when expressed in a conjunctive \nnormal form have at most m conjuncts, and each conjunct having at most n disjuncts, each of which is \na difference constraint (also referred to as m \u00d7n). In our experiments that are described in Section \n6.1, we chose m .{3, 4, 5} and n .{2, 3}.Such a template choice is also justi.ed by the fact that most \nprograms are correct for simple reasons, and their proof of validity is expressible using some appropriate \nsmall representation. We used the following inconsistency measure on the above abstract domain A. The \ninconsistency of M(f, f ) is the sum of the inconsistencies of M(f, Ci) for each clause Ci in f ,divided \nby the total number of clauses in f . mm ..1 M(f, Ci)= \u00d7M(f, Ci) m i=1 i=1 The inconsistency M(f, Ci) \nis proportional to the number of disjuncts Dj in the disjunctive normal form of f that do not imply clause \nCi. kk ..1 M( Dj,Ci)= \u00d7M(Dj ,Ci) k j=1 j=1 The inconsistency of M(Dj,Ci) is de.ned to be 0 or 1 depend\u00ading \non whether Dj .Ci or not respectively. We implemented Line 4 in the FindProof procedure as fol\u00adlows. \nWe considered the set of abstract elements that minimize the penalty at program point pk (given Post(pk \n) and Pre(pk ))and chose an element randomly from it. However, in order to expe\u00addite the convergence \nprocess, we implemented a simple version of widening and narrowing, which can be regarded as choosing \nab\u00adstract elements that do not minimize the penalty with a lesser prob\u00adability. 6.1 Experiments We have \nbuilt a prototype tool in C called Magic8. We describe our preliminary experience with this tool on the \ntwo programs shown in Figure 3 and Figure 4. We do not know of any current tool that can automatically \ngenerate the proof of validity of the example in Figure 3. The program in Figure 4 was chosen as a contrasting \nexample -its structure resembles very closely to that of the program in Figure 3, but it is easier to \nvalidate, and has been used as a motivating example for some existing veri.cation techniques [11, 19]. \nFigure 5 contains histograms of the numbers of updates over different runs of our tool on these programs. \nFor different algorithm parameters, we ran our tool 200 times and recorded average number of updates \nper program point needed to discover the invariant. The .gures show histograms of the number of updates \nover the 200 tests: the y-axis shows the number of runs that ended up in the average number of runs within \nthe boundaries of the bin centered at the values on the x-axis. Proof of validity of example in Figure \n3 We .rst ran our tool on the program shown in Figure 3(a) with the constants 50 and 100 replaced by \nthe bigger constants 5000 and 10000 respectively. We chose the size of boolean formulas over difference \nconstraints as 4 \u00d7 3 (i.e., at most 4 clauses, with each clause having at most 3 disjuncts in the CNF \nrepresentation). Our tool is successfully able to generate the proof of validity of this example. One \nsuch 8 Magic is an acronym for Machine-learning based Automatic Generation of Invariants in Code proof \nis shown in Figure 3(b). The chart in Figure 5 shows the average number of updates (per program point) \nrequired to discover the proof of validity over 200 different runs of the algorithm. For example, the \n.rst dark bin in Figure 5(a) has 105 of the 200 tests and is centered at 150 updates per program point, \nwhich means that around 50% of cases needed around 150 updates before the program invariant is found, \non the other hand 38 of the 200 tests needed between 200 and 300 updates before convergence. The graph \nshows that it is unlikely to have to run the tool for longer than 500 updates per program point before \ndiscovering the invariant. Incremental proof of validity At the end of each of the 200 runs of the tool \nin the above case, we changed the program slightly (we replaced occurrences of the constant 5000 by 6000) \nand continued the algorithm (with its current state of formulas fk at each program point pk) to discover \nthe proof of validity of the modi.ed program. Observe that the modi.ed program requires a small change \nin the proof of validity. The goal of this experiment was to illustrate that the algorithm is smart enough \nto converge faster if starting from a partially correct proof as opposed to starting from scratch. This \nis indeed what we .nd experimentally: the gray histogram shows the distribution of the number of additional \nupdates the tool needed to re.ne the invariant. On average, the 200 tests starting from scratch required \n235 updates per program point to discover the invariant, but recovering from a small program change required \non average additional 195 updates. The trend is statistically signi.cant (p< 10-3). Effect of program \nconstants One way to discover the proof of validity is to run the program fully, i.e. to run through \nthe program loops until all the termination conditions are ful.lled and the end of program is reached. \nHowever, our algorithm always .nds true invariants in a manner different than this. To show this, we \nrerun the tool 200 times using a smaller constants (this time using the constants 50 and 100, as is the \ncase in the program shown in Figure 3(a)) as shown in loop termination conditions to see how this would \naffect the program. The distributions over the number of updates did not differ signi.cantly between \nthe two cases. In fact, under a randomized pairing, we found that the veri.cation of the program with \nthe larger constant terminated faster than that of the one with a smaller constant in 101 out of 200 \ntests. This agrees with our visual inspection of the results which show qualitatively the same invariants \nfound in both cases (only the constants are different), but it also indicates that the tool is highly \nunlikely to go through the entire loop before getting a clue about what an invariant should be. Changing \ntemplate of boolean formulas Next, in Figure 5(b), we compare the number of updates per program point \nfor the tools that use different size of the abstract representation fk at each program point. The dark \nhistogram is the same as in (b), while the gray his\u00adtogram corresponds to the tests with larger representation \n(5 \u00d73), and the white histogram corresponds to the smaller representation (3 \u00d72). The important conclusion \nis that using tight representa\u00adtion (of exactly the right size), reduces the tool s ability to reach \nall possible expression combinations. When the representation is larger, then the extra room effectively \nsmoothes the probability dis\u00adtribution by making it possible to express the invariant in multiple redundant \nways. Proof of validity of example in Figure 4 To illustrate that the algorithm performance will depend \non the dif.culty of the program, we also ran our algorithm on second veri.cation problem, known to be \nveri.able by other techniques [11, 19]. Figure 5(c) shows the histogram of the number of updates for \nthis problem. Even though the number of program points is the same, and the tool s settings 140 200 \n100 120 150 60 80# tests 100# tests 20 40 50 150 250 350 450 550 650 750 850 950 0 # updates per program \npoint (a): Proof/Incremental Proof of Validity of program in Figure 3 0 150 250 350 450 550 650 750 850 \n950 # updates per program point (b): Different sizes of boolean formulas  10 20 30 40 50 60 70 80 100 \n200 300 400 500 600 700 800 900 # updates per program point #updates per program point (c) Validity proof \nof program in Figure 3 (d) Invalidity proof of program in Figure 4 Figure 5. The distribution over the \nnumber of updates in the Gibbs sampling algorithm before the program invariant is discovered. Dark bins \nin (a) show the histogram over the runs that all used a slightly enlarged representation than necessary \n(4 \u00d7 3 instead of 3\u00d72, which is suf.cient to represent invariants. This version converges the fastest \namong the ones we tried. The gray bins in (a) show how many updates are typically necessary to change \nthe found invariant into a new one that satisfy a slightly changed program. Since the invariant does \nnot change signi.cantly, the number of updates per program point is lower than it is when the sampling \nis started from scratch. In (b) we illustrate the effect of the limit on the size of the abstract representation \nto program convergence. Gray denotes lot of extra room (5 \u00d7 3), black denotes some extra room (4 \u00d7 3), \nand white denotes tight space (3 \u00d7 2). In (c) we show the update histogram for solving the second veri.cation \nproblem, and in (d) the update histogram for solving the invalidity problem. were the same, this problem \nis easier, and the algorithm discovers the invariant much faster. Proof of Invalidity of Example 1 Finally, \nin Figure 5(d), we illustrate the performance on the invalidity proof of the program in Figure 3 when \nits precondition is changed to true. Thisisto show that our tool works equally for discovering proofs \nof invalidity as well proofs of validity (under the assumption that the program terminates on all inputs). \nFigure 3(c) shows one of the proofs of invalidity generated by our tool. In a different invalidity proof, \nthe tool even generated the weakest condition x = 51 at pentry.  7. Related Work The idea of applying \nmachine learning techniques in programming languages has been used recently, though for the different \nproblem of discovering small programs given input-output pairs [17]. In this paper, we use machine learning \ntechniques for the problem of program veri.cation. Combination of Forward and Backward Analyses Cousot \nand Cousot proposed a technique to combine forward and backward analyses by re.ning the over-approximation \nof the intersections of precondition and negated postcondition by an iterative forward and backward analysis \n[4, 5]. Dill and Wong Toi proposed a dif\u00adferent kind of forward-backward combination that consists of \ncom\u00adputing separate upper-approximation and lower-approximation of precondition and postcondition respectively \n[8]. Leino and Lo\u00adgozzo also combine the forward inference procedure with the goal\u00addriven nature of going \nbackward by invoking the forward analysis along infeasible error traces reported during a backward analysis \nin the hope of generating stronger loop invariants to rule out those traces [19]. We have a different \nkind of forward and backward com\u00adbination in which we do not distinguish between the forward and backward \ninformation, and information .ows in both forward and backward directions in each step of the algorithm. \nPredicate abstraction with counter-example guided re.nement This technique involves using a model-checker \nto compute an over\u00adapproximation of a set of reachable states of a program using boolean formulas over \na given set of predicates. If this set of reach\u00adable states intersects with the set of error states, \nthe model-checker provides a counter-example. A theorem prover is then used to check the validity of \nthat counter-example. If the counter-example is found to be invalid, the proof of invalidity provides \nadditional predicates that should be considered to avoid this counterexample next time. The process is \nthen repeated with these new set of pred\u00adicates. There are some interesting differences between this \ntechnique of predicate abstraction with counter-example guided re.nement and our technique. Computation \nof reachable states can be regarded as a forward analysis, while counter-example discovery and its feedback \nto re.ne the set of predicates can be regarded as a backward analysis. However, this forward analysis \nand backward analysis happens in two different phases. Our forward and backward analysis is more tightly \nintegrated and happens in one phase, thus providing an immediate feedback. Predicate abstraction is limited \nto computing invariants using a given set of predicates inside a .xed iteration. However, our technique \nis not limited to considering a .xed set of predi\u00adcates during any step. The only restriction is that \nthe invariant at any program point should come from some language whose elements can be represented .nitely. \nFor example, in our im\u00adplementation, we choose this language to consider all Boolean formulas with bounded \nnumber of clauses, with each clause be\u00ading a disjunction of bounded number of difference constraints. \nSuch a choice of language in our technique has the ability to consider the space of all predicates (but \nboolean formulas of bounded size) as opposed to predicate abstraction, which con\u00adsiders a .xed set of \npredicates (but arbitrary boolean formulas over them). Interpolants Line 4 in the procedure FindProof \nin our algorithm involves choosing an abstract element f .Aat program point p, such that f is likely \nto be least inconsistent with f and f , .. where f = f and f = f . More formally, this f.Post(p) f.Pre(p) \nmeans that we want to .nd f such that the set of program states that violate f .f or f .f is minimal. \n9 We refer to such a process as the sandwich step. The sandwich step in our algorithm can be viewed as \na gener\u00adalization of the well-known interpolant procedure in theorem prov\u00ading. Given a pair of formulas \n(f1,f3)such that f1 .f3,an inter\u00adpolant for (f1,f3)consists of a formula f2 such that f1 . f2, f2 . f3,and \nf2 .L(f1) nL(f3). The Craig interpolation lemma [7] states that an interpolant always exists when f1 \nand f3 are formulas in .rst-order logic. The sandwich step in our algorithm generalizes the interpolant \nproblem in several dimensions in the context of abstract computa\u00adtion over programs. Instead of enforcing \nthat f2 .L(f1) nL(f3), the sandwich step imposes the constraint that f2 .A, for any given language A. \nFurthermore, the sandwich step does not insist that the inputs f1 and f3 satisfy f1 .f3. The immediate \nconsequence of (either of) these generalizations is that the existence of f2 such that f1 .f2 and f2 \n.f3 is no longer guaranteed, even when f1 and f3 are formulas in .rst-order logic. However, the sandwich \nstep in\u00adsists on .nding a formula f2 that .ts as best as possible between f1 and f3, i.e., the number \nof program states that violate f1 .f3 or f3 .f2 is minimal. Jhala and McMillan have recently proposed \na predicate re.ne\u00adment [16] approach based on interpolants, wherein the search of interpolants is restricted \nto a richer class of languages in successive stages of their algorithm. This is similar to one of the \ngeneraliza\u00adtions of the interpolant problem mentioned above, wherein f2 is constrained to belong to A. \nHowever, the choice of the languages suggested in Jhala and McMillan s work is quite different from the \nlanguage Athat we use in our implementation. Their language Lk involves predicates that contain numeric \nconstants no larger in ab\u00adsolute value than k from the constants that already occur in the program. However, \nthe choice of the language used in our implementa\u00adtion places restrictions on the size of the boolean \nformulas, which is motivated by the fact that most programs are usually correct for simple reasons that \ncan be expressed using some small represen\u00adtation. It would be interesting to consider the intersection \nof these languages for faster convergence. 9 In other words, the following set of program states is minimal: \n(.(f) - .(f )) . (.(f ) - .(f )) Our choice of languages however raises the important issue of how to \nchoose between several solutions f2 that are equally consistent with f1 and f3 (i.e, the number of program \nstates that violate f1 . f3 or f3 . f2 is same for all of them) and .t within the space restriction of \nthe language A. The strategy that we use in our implementation is to choose solutions f2 that are more \nclose to f1 (i.e, the number of program states that violate f2 . f1 is small) or f3 (i.e., the number \nof program states that violate f3 . f2 is small). The former choice has the effect of a forward analysis \nthat is guided by the backward information, while the latter choice has the effect of a backward analysis \nthat is guided by the forward information. However, the biggest difference with Jhala and McMillan s \nwork is that their work is an instance of predicate abstraction. Their approach involves computing interpolants \n(which can also be seen as combination of forward and backward analysis) only during the predicate-re.nement \nstep, which happens in every alternative phase after performing the standard reachability computation. \nOn the other hand, our algorithm performs the sandwiching procedure (which is a combination of forward \nand backward analysis) at each step. Probabilistic Algorithms Gulwani and Necula developed a prob\u00adabilistic \ntechnique for program analysis (called random interpre\u00adtation [12 14]) that combines the complementary \nstrengths of ab\u00adstract interpretation and random testing. This technique involves computing and manipulating \nprogram invariants ef.ciently by rep\u00adresenting them by a small random sample of the set of program states \nthat they represent (as opposed to manipulating program in\u00advariants symbolically). However, there are \nsome differences worth\u00admentioning with the probabilistic technique described in this paper: (a) Random \nInterpretation terminates in a bounded time, but may output incorrect program invariants with a (in.nitesimally) \nsmall probability. On the other hand, the technique described in this pa\u00adper always outputs the correct \nanswer, but may take long to execute. (b) Random Interpretation is a forward technique that is used \nto dis\u00adcover program properties. The technique described in this paper is a combination of forward and \nbackward analyses and is used to discover the proof of correctness of a given pre/postcondition pair. \n  8. Conclusion and Future Work In this paper, we have described a simple probabilistic inference algorithm \nthat searches for proofs of validity or invalidity of given Hoare triples. The algorithm works by randomly \nchoosing a pro\u00adgram point and randomly updating its guess for the invariant at that point to make it \nless inconsistent with the neighboring guesses un\u00adtil a valid proof is found. This simple algorithm combines \nforward and backward analyses in a novel manner. Furthermore, we pose the invariant inference problem \nas infer\u00adence in probabilistic graphical models, which allows for a large class of other probabilistic \ninference techniques to be applied to program veri.cation. To this end, we have introduced the notion \nof an inconsistency measure for an abstract domain equipped with a partial order. This measure can be \nused to create a probability dis\u00adtribution over the program states, described by a graphical model amenable \nto various probabilistic inference techniques (e.g., the ones reviewed in [9, 20]). It is important to \nnote that, even though the problem is re-formulated as an inference of hidden variables in a probability \nmodel, many inference algorithms used in machine learning are deterministic, and also new classes of \ndeterministic algorithms can be developed to leverage the real-valued inconsis\u00adtency measures to search \nfor proofs of validity or invalidity. These measures can be an effective measure of algorithm progress. \nOur algorithm is based on one of the simplest sampling ap\u00adproaches, but a plethora of other related sampling \nalgorithms is reviewed in [20]. Possible extensions of this work include discovering invariants that \ninvolve pointer variables, and performing an interprocedural analysis by learning procedure summaries. \nIt would also be inter\u00adesting to experiment with the techniques described in this paper to learn invariants \nin richer abstract domains such as .rst order logic invariants, which would be useful to reason about \nprograms with arrays. 9. Acknowledgments We thank Vladimir Jojic for general discussions on applying \nma\u00adchine learning techniques to reason about programs.  References [1] T. Ball and S. K. Rajamani. \nThe slam project: debugging system software via static analysis. In POPL, pages 1 3, 2002. [2] S. Chaki, \nE. Clarke, A. Groce, S. Jha, and H. Veith. Modular veri.cation of software components in C. In ICSE, \npages 385 395. IEEE Computer Society, May 2003. [3] P. Cousot and R. Cousot. Abstract interpretation: \nA uni.ed lattice model for static analysis of programs by construction or approximation of .xpoints. \nIn 4th ACM Symposium on POPL, pages 234 252, 1977. [4] P. Cousot and R. Cousot. Abstract interpretation \nand application to logic programs. Journal of Logic Programming, 13(2 3):103 179, July 1992. [5] P. Cousot \nand R. Cousot. Re.ning model checking by abstract interpretation. Automated Software Engineering: An \nInternational Journal, 6(1):69 95, Jan. 1999. [6] P. Cousot and N. Halbwachs. Automatic discovery of \nlinear restraints among variables of a program. In 5th ACM Symposium on POPL, pages 84 97, 1978. [7] \nW. Craig. Three uses of the Herbrand-Genzen theorem in relating model theory and proof theory. Journal \nof Symbolic Logic, 22:269 285, 1957. [8] D. Dill and H. Wong-Toi. Veri.cation of real-time systems by \nsuccessive over and under approximation. Lecture Notes in Computer Science, 939, 1995. [9] B. J. Frey \nand N. Jojic. A comparison of algorithms for inference and learning in probabilistic graphical models. \nIEEE Trans. Pattern Analysis and Machine Intelligence, 27(9):1392 1416, 2005. [10] S. Graf and H. Saidi. \nConstruction of abstract state graphs with PVS. In CAV, pages 72 83, 1997. [11] B. Gulavani and S. Rajamani. \nCounterexample driven re.nement for abstract interpretaion. In TACAS, volume 3920 of LNCS, pages 474 \n488. Springer, Mar. 2006. [12] S. Gulwani and G. C. Necula. Discovering af.ne equalities using random \ninterpretation. In 30th ACM Symposium on POPL, pages 74 84. ACM, Jan. 2003. [13] S. Gulwani and G. C. \nNecula. Global value numbering using random interpretation. In 31st ACM Symposium on POPL, pages 342 \n352, Jan. 2004. [14] S. Gulwani and G. C. Necula. Precise interprocedural analysis using random interpretation. \nIn 32nd ACM Symposium on POPL, pages 324 337, Jan. 2005. [15] T. A. Henzinger, R. Jhala, R. Majumdar, \nand G. Sutre. Lazy abstraction. In POPL, pages 58 70, 2002. [16] R. Jhala and K. L. McMillan. A practical \nand complete approach to predicate re.nement. In H. Hermanns and J. Palsberg, editors, TACAS, volume \n3920, pages 459 473. Springer, 2006. [17] V. Jojic, S. Gulwani, and N. Jojic. Probabilistic inference \nof programs from input/output examples. (MSR-TR-2006-103), July 2006. [18] F. R. Kschischang, B. J. Frey, \nand H.-A. Loeliger. Factor graphs and the sum-product algorithm. IEEE Trans. Information Theory, 47(2):7 \n47, 2001. [19] K. R. M. Leino and F. Logozzo. Loop invariants on demand. In APLAS, volume 3780 of Lecture \nNotes in Computer Science, pages 119 134. Springer, 2005. [20] R. Neal. Probabilistic inference using \nmarkov chain monte carlo methods. Technical Report CRG-TR-93-1, University of Toronto, Sept. 1993. \n\t\t\t", "proc_id": "1190216", "abstract": "In this paper, we propose a new algorithm for proving the validity or invalidity of a pre/postcondition pair for a program. The algorithm is motivated by the success of the algorithms for probabilistic inference developed in the machine learning community for reasoning in graphical models. The validity or invalidity proof consists of providing an invariant at each program point that can be locally verified. The algorithm works by iteratively randomly selecting a program point and updating the current abstract state representation to make it more locally consistent (with respect to the abstractions at the neighboring points). We show that this simple algorithm has some interesting aspects: (a) It brings together the complementary powers of forward and backward analyses; (b) The algorithm has the ability to recover itself from excessive under-approximation or over-approximation that it may make. (Because the algorithm does not distinguish between the forward and backward information, the information could get both under-approximated and over-approximated at any step.) (c) The randomness in the algorithm ensures that the correct choice of updates is eventually made as there is no single deterministic strategy that would provably work for any interesting class of programs. In our experiments we use this algorithm to produce the proof of correctness of a small (but non-trivial) example. In addition, we empirically illustrate several important properties of the algorithm.", "authors": [{"name": "Sumit Gulwani", "author_profile_id": "81100315615", "affiliation": "Microsoft Research, Redmond", "person_id": "PP14115174", "email_address": "", "orcid_id": ""}, {"name": "Nebojsa Jojic", "author_profile_id": "81100118141", "affiliation": "Microsoft Research, Redmond", "person_id": "PP43116491", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1190216.1190258", "year": "2007", "article_id": "1190258", "conference": "POPL", "title": "Program verification as probabilistic inference", "url": "http://dl.acm.org/citation.cfm?id=1190258"}