{"article_publication_date": "05-01-2001", "fulltext": "\n ESP: A Language for Programmable Devices Sanjeev Kumar, Yitzhak Mandelbaum, Xiang Yu, and Kai Li Princeton \nUniversity (sku mar, yitz h akm ,xyu, li) @ cs. princeton, edu ABSTRACT This paper presents the design \nand implementation of Event- driven State-machines Programming (ESP)--a language for programmable devices. \nIn traditional languages, like C, us- ing event-driven state-machines forces a tradeoff that re-quires \ngiving up ease of development and reliability to achieve IJlg}l p~,ti~rlnallc~, ESP is designed to provide \nall of these three properties simult.aneously. ESP provides a comprehensive set of teatures to support \ndevelopment of compact and modular programs. The ESP compiler compiles the programs into two targets---a \nC file that can be used to generate efficient firmware for the device; and a specification that can be \nused by a verifier like SPIN to extensively test the firmware. As a case study, we reimplemented VMMC \nfirmware that runs on Myrinet network interface cards using ESP. We found that ESP simplifies the task \nof programming with event-driven state machines. It, required an order of magni- I~:,;~ i~'~\\{'l !lilt'> \n,,I t l,~l{' [lUItl liB' [)l'('\\'iOIl~ iill[)]elll(qll,&#38;tioli, \\.Ve also fbund that model-checking \nverifiers like SPIN can be used to effectively debug the firmware. Finally, our mea, surements indicate \nthat the perfbrmance overhead of using ESP i~ relat, ively small. 1. INTRODUCTION Concurrency is a convenient \nway of structuring firmware for programmable devices. These devices tend to have lim- ited CPU and memory \nresources and have to deliver high performance. For these systems, the low overhead of event- driven \nstate machines often makes them the only choice tbr ~'xpl~ssi|ig coJicuiq'ellcy. Their low overhead is \nachieved by .~upporting only the bare minimum functionality needed to write these programs. However, \nthis makes an already diffi- cur task of writing reliable concurrent programs even more challenging. \nThe result is hard-to-read code with hard-to- find bugs resulting from race conditions. The VMMC firmware \n[10] for Myrinet network interface Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor profit or commercial advan- tage and that copies bear this notice and the full citation on the first \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspecific permission and/or a fee. PLD/2001 6/O1 Snowbird, Utah, USA &#38;#169; 2001 ACM ISBN 1-58113-414-2/01106...$5.00 \n cards was implemented using event-driven state machines in C. Our experience was that while good perfbrmance \ncould be achieved with this approach, the source code was hard to maintain and debug. The implementation \ninvolved around 15600 lines of C code. Even after several years of debugging, race conditions cause the \nsystem to crash occasionally. ESP was designed to meet the following goals, First, the language should \nprovide constructs to write concise modu- lar programs. Second, the language should permit the use of \nsoftware verification tools like SPIN [14] so that the con- current programs can be tested thoroughly. \nFinally, the lan- guage should permit aggressive compile time optimizations to provide low overhead. \nESP has a number of language features that allow devel- opment of fast and reliable concurrent programs. \nConcur-rent programs are expressed concisely using processes and channels. In addition, pattern matching \non channels allows an object to be dispatched transparently to multiple pro- cesses. A flexible external \ninterface allows ESP code to in- teract seamlessly with C code. Finally, a novel memory management scheme \nallows an efficient and verifiably safe management of dynamic data. We reimplemented the VMMC firmware \non Myrinet net- work interface cards using ESP. We found that the firmware can be programmed with significantly \nfe.wer lines of code. in addition, since the C code is used only to perfbrm simple operations, all the \ncomplexity is localized to a small portion of the code (about 300 lines in our implementation). This \nis a significant improvement over the earlier implementation where the complex interactions were scattered \nover the en- tire C code (15600 lines). The SPIN verifier wens used to develop and extensively test the \nVMMC firmware. Since, developing code on the network card often slow and painstaking, parts of the system \nwere developed and debugged entirely using the SPIN simulator. SPIN was also used to exhaustively verify \nthe memory safety of the firmware. Once the properties to be checked by the verifier are specified, they \ncan be rechecked with little effort as the system evolves. The ESP compiler generates efficient firmware. \nWe used microbenchmarks to measure the worst-ease performance overhead in the firmware. Based on earlier \napplication stud- ies [17, 5], we expect the impact of the extra performance overhead to be relatively \nsmall. The rest o[ the paper is organized as tbllows. Section 2 presents the motivation for a new language. \nSection 3 de- scriber our three goals and our approach. The next three sections (Sections 4, 5 &#38; \n6) describe how ESP meets each of the three goals. Section 4 provides the design of the ESP language. \nSection 5 describes how the SPIN model-checking verifier can be used to develop and test ESP programs. \nSec- tion 6 shows how the ESP compiler generates eMcient code and presents some performance measurements. \nSection 7 describes the related work. Finally, Section 8 presents out\" conclusions. 2. MOTIVATION Devices \nlike network cards and hard disks of'te~ include a programmable processor and memory (Figure 1). This \nal- lows the devices to provide sophisticated features in tfirmware. For instance, disk can support aggressive \ndisk head sehedul- ing algorithms in firmware. Bus Network Figure 1: Programmable Devices The firmware \nfor programmable devices is often programmed using concurrency. Concurrent programs have multiple threads \nof' control that coordinate with each other to periorm a smgle task. The multiple threads of control \nprovide a convenient way of keeping track of multiple contexts in the firmware. In these situations, \nconcurrency is way of structuring a pro- gram that runs on a single processor. Concurrent programs can \nbe written using a variety of constructs like user-level threads or event-driven state ma-chines. They \ndiffer in the amount of functionality provided and the overhead involved. However, the programmable de- \nvices tend to have fairly limited CPU and memory resources. Since these systems need to deliver high \nperformance, the tow overhead of event-driven state machines make them the only choice. In this paper, \nwe describe a language called ESP that can be used to implement firmware for programmable devices. We \nwere motivated by our experience with implementing the VMMC firmware. We use VMMC firmware as a case \nstudy to evaluate the ESP language. In this section, we start with a description of VMMC. Then we examine \nthe problems with event-driven state machines programming in traditional languages like C and motivate \nthe need for a new language for writing firmware for programmable devices. 2.1 Case Study: VMMC Firmware \nThe VMMC architecture delivers high-performance on Ci- gabit networks by using sophisticated network \ncards. It al- lows data to be directly sent to and from the application memory (thereby avoiding memory \ncopies) without involw ing the operating system (thereby avoiding system call over- head). The operating \nsystem is usually involved only during connection setup and disconnect. The current VMMC implementation \nuses the Myrinet NeL- work Interface Cards. The card has a programmable 33- MHz LANai4.1 processor, 1-Mbyte \nSRAM mernory and 3 DMAs to transfer data---to and from the host memory; to send data out onto the network; \nand to receive data. from the network. The card has a number of control registers including a status \nregister that needs to be polled to check for data arrival, watchdog timers and DMA status.  Main Processor \n Network Interface Card   Network Figure 2: VMMC Software Architecture: The shaded regions are the \nVMMC components. The VMMC software (Figure 2) has 3 components: a li-brary that links to the application; \na device driver that is used mainly during connection setup and disconnect; and firmware that runs on \nthe network card. Most of the soft- ware complexity is concentrated in the firmware code which was implemented \nusing event-driven state machines in C. The entue system was developed over several years and most of \nthe bugs encountered were located in the firmware. Our goal is to replace the firmware using the ESP \nlanguage. 2.2 Implementing Firmware in C Event-driven state machines provide the bare mimmum functionality \nnecessary to write concurrent programs--the ability to block in a particular state and to be woken up \nwhen a particular event occurs. This makes them fairly difficult to program with. We illustrate event-driven \nstate- machines programming in C with an example. The C codp fragment ~s presented in Appendix A and \nis illustrated m Figure 3. A program consists of multiple state-machines. For each state in a state \nmachine, a handler is provided for every event that is expected while in that state. When art event occurs, \nthe corresponding handler is invoked. The handler processes the event, transitions to a different state \nand blocks by re- turning from the handler. All the state machines share a single stack. There are several \nproblems with this approach. First, the code becomes very hard to read because the code gets frag- mented \nacross several handlers. Second, since the stack is shared, all the values that are needed later [lave \nto be saved explicitly in global variables before a handler blocks. So data is passed between han-dlers \nthrough global variables (e,g. pAddr, sendData). In addition, global variables are also used by state \nmachines to communicate with each other (e.g. reqSM2), it is very In#in/| jr event UserReqexecute handleReqO~ \nJ Finally, hand-optimized fast paths are often built into the system to speed up certain requests. These \nfast paths rely on global information like the state of the various state ma- chines and their data structures \nand violate every abstrac- tion boundary. For instance, in VMMC firmware, a par- ticular fast path is \ntaken if the network DMA is free and    wai%\u00a3'a [ event DMAFreeexecute fetchDataO @ O @  vent SM2Ready \nexecute syncSM201 \u00ae Figure 3: Programming in C. The code is presented in Appendix A. A state machine \nis specified using a set of handlers. For each state in a state machine, a list of (event,handler) pairs \nhas to be provided. When an event occurs~ the corresponding handler is invoked. A handler is a C function \ntakes no argu-ments and returns void. hard to get the right synchronization to keep from clobber- ing \ndata.. Third. memory to allocate buffers for the data has to be managed explicitly. In a concurrent setting, \nthis is hard to implement correctly when data is used by several state machines before it is eventually \nfreed. Depending on the tuning, a different state machine might be the last one to use the data. and, \ntherefore, be responsible for freeing. When necessary, explicit reference counts have to be maintained. \nII is easy to overlook the need for adding reference counts bo some data structures and introduce tricky \nallocation bugs lhat a.re hard t,o find. Fourth, functions are an inappropriate abstraction mecha- nism \nfor programming with state machines. This is because a state machine can block only by returning fi'om \na han-dler. As the firmware evolves, there might be a need to block within a flmction that is not a handler. \nFor instance, in our original implementation, the function translateAddr was implemented as a simple \ntable lookup. However, as the firmware evolved, the table became a cache of transla- tions and the entire \ntable was moved to the host memory. This meant that if' there was a miss m the translation cache, the \ntranslation had to be DMAed from the host memory. But if tile DMA was not available, it would need to \nblock. This required extensive rewrite of the code and addition of more states to the state machine. \nIn general, the amount of rewrite is proportional to the nesting depth of the function that wants to \nblock. Fifth, union data.types are used extensively in these sys- tems to encode different possible requests. \nSo, a lot of handlers have a switch statement to deal with different re- quests. For instance, an application \ncould request for a mes- sage to be sent SendReq or to update the virtual to physical translation UpdateReq. \nSince these requests are handled by the same handler handleReq, their code had to be colocated even when \nit; makes more sense for these to be implemented m separate modules. A dzspatchmechanism supported by \nthe language would simplify the implementation. no other request is currently being processed (this requires \nlooking at the state of multiple DMAs). In addition, the fast path code updates global variables used \nfor retransmis- sion and might have to update the state of several state machines. These fast paths complicate \nthe already complex state-machine code even further. ESP aims to address these problems without incurring \ntoo much performance penalty. As we shall see, the ESP code corresponding to the C code (Figure 3) can \nbe written much more succinctly and readably (Appendix B). 3. GOALS AND APPROACH ESP is a language designed \nto support event-driven State- machines programming. It has the following goals: Ease of development \nTo aid programming, the language should permit the concurrency to be expressed simply. It should also \nprovide support for modularity, dynamic memory management and a flexible interface to C. Permit extensive \ntesting Concurrent programs often suf- fer from hard-to-find race conditions and deadlock. ESP should \nsupport the use of software verifiers so that the programs can be tested extensively. Cur-rently, ESP \nuses the SPIN verifier. SPIN [14] is a flexible and powerful verification system designed to verify correctness \nof software systems. It uses model- checking to explore the staLe-space of the system. Low performance \npenalty These concurrent programs are designed to be run on a single processor. To have low performance \noverhead, concurrent programs in ESP should permit aggressive cornpile time optimizations. In traditional \nlanguages, like C. using event-driven state- machines forces a tradeoff that requires giving up ease \nof de- velopment and reliability to achieve high performance. ESP is designed to provide all of these \nthree properties simulta- neously. To meet these design goals, the ESP language is designed so that it \ncan not only be used to generate an executable but also be translated into specification that can be \nused by the SPIN verifier (Figure 4). The ESP compiler takes an ESP program (pgm.ESP) and generates 2 \nfiles. The gen- erated C file (pgm. C) can then be compiled together with the C code provided by the \nuser (help.C) to generate the executable. The programmer-supplied C code implements simple device-specific \nfunctionality like accessing device reg- isters. The SPIN file (pgra. SPIN) generated by the ESP com-piler \ncan be used together with programmer-supplied SPIN code (test. SPIN) to verify different properties of \nthe sys- tem. The programmer-supplied SPIN code generates exter- nal events such as network message arrival \nas well as spec- ifies tile properties to be verified. Different properties of the system can be verified \nby using pgra. SPIN together with different test.SPIN files. Generate Firmware Figure 4: Shaded regions \nare 4. EVENT-DRIVEN STATE-MACHINES PRO- GRAMMING (ESP) LANGUAGE ESP is based on the CSP [13] language \nand has a C-style syntax. ESP supports Event-driven State-machines Programming. The basic components \nof the language are processes and channels. Each process represents a sequential flow of control in a \nconcurrent program. Processes commu- nicate with each other by sending messages on channels. All the \nprocesses and channels are static and known at compile time. Appendix B presents the implementation of \nthe example (Section 2.2) in ESP. In this section, we will use fragments from that code to illustrate \nthe various language features. 4.1 Types, Expressions and Statements ESP supports basic types like int \nand bool as well as mutable and immutable versions of complex datatypes like record, union and array.1 \nTypes can be declared as follows: type sendT = record of { dest: int, vAddr; int, size: int} type updateT \n= record of { vhddr: int, pAddr: int} type userT = union of { send: sendT, update: updateT, ...} ESP \ndoes not provide any global variables. All variables have to be initialized at declaration time (New \nvariable dec- laration is indicated with a $ prefix). Types do not, have to be specified when they can \nbe deduced (ESP does a simple type inferencing on a per statement basis). For instance: 8i: int = 7; \n// Declare Variable i = 45; // Update Variable $j = 36; // Type inferred ESP provides the common imperative \nconstructs like if-then-else statements and while loops. However, it does not provide reeursive data \ntypes or functions. Reeursive data types are not supported because they cannot be trans- lated easily \ninto the specification language of the SPIN veri- fier. Functions are not supported because processes \nprovide a more appropriate abstraction mechanism in a concurrent setting (Section 4.3). 4.2 Channels \nCommunication over channels are synehronous--a sender has to be attempting a send (using the out construct) \ncon- currently with a receiver attempting to receive (using the in t A # prefix indicates a mutable data \nstructure. Run SPIN Verifier code provided by the user construct) on a channel before the message can \nbe success- fully transferred over the channel. Consequently, both -in and out are blocking operations. \nUsing synchronous char> nels has several benefits. First, they simplily reasoning about message ordering, \nespecially when processes can have complex interactions. Second, they can be implemented more efficiently \nthan buffered channels. When buffering is required, it can be implemented explicitly by the program- \nmer. Finally, buffered channels increa-~e the size of ~tatp- space that has to be explored during verification. \nThe alt construct allows a process to wait on the z'n,/o'u,t readiness of multiple channels I~lowe\\'er, \nf'or each ext'cul irm of an alt statement, only the actions associated with a single channel are performed. \nIn the case where multiple channels are ready, a single channel is selected. The channel selec- tion \nalgorithm need not be fair (it may favor performance critical channels), but must prevent starvation \n[20]. The %l- lowing is a code fragment from a process that implements a FIFO queue. The macros FULL, \nEMPTY and INCR have the expected functionality. The first alternative accepts new messages and inserts \nthem at the tail of the queue The sec- ond alternative sends the message at the head of the queue and \nthen removes it from the queue. Note that the first alternative is disabled when the buffer is full and \nsecond is disabled when the buffer is empty. while { alt { case( !FULL, in( ehanl, Q[tl]) { INCR(tl); \n} case( !EMPTY, out( ehan2, Q[hd])) { INCR(hd); } } } One of the features of the language is the use \nof pattern matching to support dispatch. Pattern-matching is used m languages like ML to provide more \nexpressive switch state- ments. ESP uses it to support dispatch. Patterns have the same syntax as the \none used for a.lloca.ting uni(ms awl records. They can be differentiated based on their' pc~sil ~cm in \na statement. They are considered a pattern when they occur in an lvalue position and cause allocation \nwhen they occur in a rval~e position. $sr: sendT = { 7, 54677, 1024}; Surf: userT = { send I> sr}; Sur2: \nuserT = { send l> { 5, lO000, 5i2}}; { send I> { $dest, SvAddr, $size}}: userT = $ur2; In the above \ncode, the first line initializes sr to a newly allocated record. The second line initializes url to a \nnewly allocated union with a valid send field 2 that points to the record in sr. The third line initializes \nur2 to a newly allo- cated union with a valid send field that points to a newly allocated record. The \nfourth line has a pattern on the left hand side and pattern matching causes variables dest, vAddr and \nsize to be initialized to 5, 10000 and 512 respectively Patterns can be specified in an in operation. \nFor example, consider process A performs in( userKeqC, { send i> { Sdest, $vAddr, $size}}); tO accept \nonly send requests while a process B pertbrms in( userReqC, { update I> { $vAddr, $pAddr}}); to accept \nonly update requests. When process C performs out( userReqC, req) ; the object will be delivered to process \nA or B depending on which pattern it matches. This frees the process C from try- ing to figure out the \nappropriate processes and sending the message to that process. To support this functionality effi- cmntly, \nESP requires that; all the patterns used on a channel have to be disjoint and exhaustive--an object has \nto match exactly one pattern. In addition, each pattern can be used by (me process only So. although \na channel can have mul- tiple readers and writers, a channel together with a pattern defint,,~ a port \nwhich can have nmltiple writers but only a single reader. Objects sent over' channels are passed by value. \nSince there are no global variables, this ensures that processes can communicate only by sending messages \nover channels. To support this efficiently, ESP allows only immutable ob- jects t.o be sent over channels \nThis applies not only to the ob.lect specified in the out operation but also to all objects recursively \npointed to by that object. A cast operation allows casting an immutable object into a llml.ablc objecl \nand vice versa. Semantically, the cast op- eration causes a new object to be allocated and the corre- \nspondillg values to copied into the new object. However, the compiler can avoid creating a new object \nin a number of cases. For instance, if the compiler can determine that the object being cast is no longer \nused afterwards, it can reuse that object and avoid allocation.  4.3 Processes Processes in ESP implement \nstate machines--each loca.- t, ion in the process where it can block implicitly represents a state in \nthe state machine. process add5 { while(true) { in( chanl, $i); out( ehem2, 5.+5) ; }} The above process \nrepresents a state machine with 2 states. The first state is when it is blocked waiting on an in opera- \ntion on channel chanl and the second when it is blocked on an owe operation on channel chart2. Processes \nin ESP are lightweight in that they do not need a stack to run This is because ESP does not support \nfunc- tions, allowing the local variables of a process to be allocated eExactly one field of a union \nhas to be valid in the static region. Thus a context switch only requires sav- ing the current location \nin one process and jumping to the saved location in another. In ESP, the processes are used to support \nabstraction-- functions are not supported. For example, consider the fol- lowing code fragment from a \nprocess which implements a page table which maps virtual addresses into physical ad- dresses (Appendix \nB). The mapping is maintained in the array table. When it receives a request to translate virtual address \nto physical address, it uses the virtual address to lookup the mapping and sends a reply back to the \nrequest- ing process. The ret specifies the process making the re-quest so that the reply can be directed \nback to that process. The second case accepts requests to update the mapping and updates the table. alt \n{ case( in( ptReqC, { $ret, $vAddr})) { // Request to lookup a mapping out( ptReplyC, { ret, table[vAddr]});} \ncase( in( userReqC, { update I> { $vAddr, $pAddr}})) { // l~eqaes~ to ~,pdale a rr~appin 9 table [vAddr] \n= pAddr;  } } To mimic the behavior of functions that expect return values, a pair of out and in operations. \nFor instance: 3 out( ptReqC, { @, vAddr}); in( ptReplyC, { @, $pAddr}); On the other hand, functions \nthat do not expect a return value can be modeled using an out operation out( userReqC, { update I> { \nvAddr, pAddr}}); ESP processes are a more appropriate abstraction mech- anism than functions in a concurrent \nsetting because an ESP process can block on an event, while allowing such be- havior in a function cannot \nbe done without a stack (Sec- tion 2.2). In addition, the process abstraction allows flexi- bility in \nscheduling computation. For instance, if no return values are expected (see last example), the code to \nupdate the table can be delayed until later. 4.4 Memory Management Memory allocation bugs are often \nthe hardest to find espe- cially in the context of concurrent programming. However, supporting automatic \nmemory management usually involves too much overhead (both in terms of space and time). On the other \nhand, explicit memory management with malloc and :free are hard to program correctly with. ESP provides \na novel explicit management scheme to al- low efficient but bug free memory management. The key observation \nis that memory bugs are hard to find because memory safety is, usually, a global property of a concurrent \nprogram--memory safety cannot be inferred by looking only at a part of the program. To rectify this, \nESP is designed to make memory satety a local property of each process. When objects are sent over channels, \ndeep copies of the objects are delivered to the receiving process. 4 Hence, there :~ is a constant different \nfbr each process (a process id). J'I'his is true only semantically. The implementation never has to actually \ncopy the object. is no overlap between the objects accessible to different pro- cesses. Therefore, each \nprocess is responsible for managing its own objects. Bugs in the other processes do not effect it. ESP \nprovides a reference counting interface to manage memory. ~ At allocation time, ~ the reference count \nis set, to 1. ESP also provides 2 primitives (link a.nd unlink) to ma- nipulate the reference counts. \nThe link primitive increases the reference count of the object while the unlink decreases the reference \ncount of the object. If this causes the refer- ence count of an object to become 0, it frees the object \nand recursively invokes unlink on the objects pointed by it, ESP is designed so that link and unlink \nare the only source of unsafeness in language. However, since the un-safeness is local to each process, \nthe SPIN verifier can be used to verify safety of each process separately. This makes it less vulnerable \nto state-explosion in the verifier. In fact, the SPIN verifier was able to verify the safety of all pro- \ne(,sses llsed to impiernent th(, VMMC firmware fairly easily (Section 5.3).  4.5 External InterNee The \nfirmware implementation has to deal with special reg- isters, volatile memory and layout of packets sent/received \non the network. ESP addresses this by providing an external interface to interact with C code. In addition, \nthe specification derived from the ESP code has to interact with some programmer provided SPIN code during \nverification (Figure 4). ESP provides a single external interface for both SPIN and C code. It uses the \nchannel mechanism to support external interfaces. This is different f?om the traditional approaches of \neither allowing C code to be directly embedded in the program [6, 2] or allowing functions that are implemented \nexternally to be called [3, 8]. Using channels to provide external interfaces has a num- ber of advantages. \nFirst, ESP processes often block on ex- ternal events like arrival of user request or network pack-ets. \nUsing channels allows a process to use the existing con- structs to block on external events. Second, \nexternal code can also use the same dispatch mechanism built into chan- nels through pattern-matching \nFinally. it prc~mc~tes mnd,- laritv. For instance, if retransmission is no longer required, the retransmismon \nprocesses can be dropped and the chan- nels used to interact can be converted into external channels. \nOther processes that were using these channels are not ef- fected because they cannot tell the difference \nbetween an external channel and a regular channel. A channel can be declared to have an external reader \nor writer but not both. For example: channel usargeqC: aserT // External C writer interface userReq( \nout userReqC) { Send( { Send I> { Sdest, SvAddr, Ssize}), Update( { Update I> Snew}), } defines a \nchannel with a external writer. The $ prefix in the pattern indicates a parameter to be passed to the \nC function. 5The inability of reference counting to deal with cycles poses no problems to ESP because \nit does not have circular data structures. sobjects received over channels are treated as newly allo- \ncated objects. Interface to C. To support a synchronoll~ (2 inkerthc'e. ESP requires two types of functions \nto be provided. The first, type has a \"IsReady\" suffix and returns whether the channel has data. to send/receive. \nThe second type of func- tion is called after the first one ha..~ indicated it it i.~ l'(,nd\\ to communicate \nSo. in the previolls example, the f'o)lowin\u00a2 ~unctions have to be provided by the programmer. int UserReqIsReady( \nvoid); void UserReqSend( int *dest, int *vAddr, int *size); void UserReqUpdate( int **new); UserReqIsReacly \nshould return 0 when it has nothing to send. When it has something to send, it returns a integer that \nspecifies which one of the patterns is ready. A separate t~lrlclio~ has to b<' provided {7~r each o['/llc, \npc( t.c,ill~ ~;1~,, i fled The use o[' patlerns in Ibis coHtext serves 2 pmlp~ses. First, it supports \ndispatch on external channels. Second. it minimizes the amount of allocation and manipulation of ESP \ndata structures that has to be done in C. For instance, by specifying the entire pattern in UsergeqSend, \nthere is no need for that function to allocate any ESP data. structure. UserReqUpdate, on the other hand, \nwill have to allocate, cor- rectly initialize and return an ESP record. This can not only introduce allocation \nbugs in the system but also move the allocation beyond the reach of the ESP compllet, ~lhelebl,, preventing \nthe allocation from being optimized away. External in channels diftbr [i'om external out eham~el m 2 \nways. First, the IsReady flmction just returns whether or not the channel is willing to accept data. \nThen any writer on that channel can write to it. In addition, it does not need to pass pointers since \nthe parameters will not be modified. So, all the parameters have one less level of indirection. SPIN \nInterface. Since SPIN has support for channels, ex- ternal SPIN code can interact directly with SPIN \nby reading and writing to the appropriate channels.  4.6 Case Study: VMMC Firmware ~\\c have remLplemented \nthe V.XiM(5 Ill mwarc using i:;51 ~. The implementation supports most o[ the VMMC hmction- ality (only \nthe redirection feature is currently not supported) The earlier implementation included about 15600 lines \nof C code (Around 1100 of these lines were used to implement the fast paths)/ The new implementation \nusing ESP uses 500 lines of ESP code (200 lines of declarations + 300 lines of process code) together \nwith around 3000 lines of C code. s The C code is used to implement simple tasks like initialization, \ninitial- ing DMA, packet marshalling and unmarshalling and shared data structures with code r, nnin~ \ncm the heft prnco~snr (in the library and the driver). All the complex sta.tu ma.chmte interactions are \nrestricted to the ESP code which uses 7 pro- cesses and 17 channels. This is a significant improvement \nover the earlier implementation where the complex interac- tions were spread throughout the 15600 lines \nof hard-to-read code. 7To make a fair comparison, we counted only those lines of tile earlier implementation \nthat correspond to functionality implemented in the new VMMC implementation using E~P sESP currently \ndoes not provide any support for fast paths.   5. D'EVELOPING AND TESTING USING A not keep track \nof the states already visited and could ex-VERIFIER plore some states multiple times while never exploring \nsome other states. However, the simulation mode in SPIN usually We have a working prototype of the ESP \ncompiler, it generates both C code that can be compiled into firmware as discovers most bugs in the system. \nMost simulators are de- signed to accurately mimic the system being simulated. So, well a.s a specification \nthat can be used by the SPIN verifier hard to find bugs that occur infrequently on the real system (Figure \n4). In this section, we start with a description of also occur infrequently on the simulators. The SPIN \nsimu- the SPIN model checker. We then describe how ESP code is translated into SPIN specification. Finally, \nwe present our experience with using the SPIN model checker to develop and extensively test the VMMC \nfirmware. 5.1 SPIN Model Checking Verifier Model checking is a technique for verifying a system com- \nposed o1 c(mcurrerlt finite-state machines. Cliven a. concur- rein, finite-state system, a model checker \nexplores all possible interleaved executions of the state machines and checks if the property being verified \nholds. A global state in the system ~s a snapshot of the entire system at a particular point of execution. \nThe state space of the system is the set of all the global states reachable from the initial global state. \nSince the state space of such systems is finite, the model checkers can, in principle, exhaustively explore \nthe entire state space. The advantage of using model checking is that it is auto- |lia.ti(:. Given a \nspecification for the system and the prop- erty to be verified, model checkers automatically explore \nthe slat~, space lf a violatiol, of the, property is discover~,d, il can produce an execution sequence \nthat causes the violation and thereby helps in finding the bug. The disadvantage is that the state space \nto be explored is exponential in the number of processes and the amount of memory used (for variables \nand data structures). So the resources.required (CPI r as well as memory resources) by the model checker \nto explore the entire state space can quickly grow beyond the capacity of modern machines. SPIN [14]. \nit is a flexible and powerful model checker de- signed for software systems. SPIN supports high-level \nfea- tures like processes, rendezvous channels, arrays and records. Most other verifiers target hardware \nsystems and provide a fairly different specification language. Although ESP can be translated into these \nlanguages, additional state would have to be introduced to implement features like the rendezvous channels \nusing primitives provided in that specification lan- gua.ge. \"I'hi~ would make the ~tate explosion problem \nworse. In addition, the semantic information lost during transla- tion would make it harder for the verifiers \nto optimize the state-space search. SPIN supports checking for deadlocks and verifying simple properties \nspecified using assertions. More complex proper- ties, like, absence of starvation, can be specified \nusing Linear Temporal Logic (LTL). SPIN is an on-the-fly model checker and does not build the global \nstate machine before it can start checking for the property to be verified. So, in cases where the state \nspace is too big to be explored completely, it can do partial ~earche~. It provlde~ 3 dilferent modes \ntot state-space explo- ration. The entire state space is explored in the exhaustive mode. For larger \nsystems state spaces, tile bit-state hash- ing mode performs a partial search using significantly less \nmemory. The simulation mode explores single execution sequence ill tile state space. A random choice \nIs made be- tween the posstble next states at each stage. Since it does lator is different in that it \nmakes a random choice at each stage and is, therefore, more effective in discovering bugs.  5.2 Translating \nESP into SPIN Specifications The ESP code can be translated into the SPIN specifica- tion at various \nstages of the compilation process. The ESP compiler does this very early--right after type checking--for \nseveral reasons, First, the SPIN specification language does not support pointers. So, the translation \nis much more diffi- cult at the latter stage because it would require the compiler to carry some of the \ntype information through the transfor- mations on the intermediate representations. Second, the addition \nof temporary variables during the compilation in- creases the size of the state space that must be explored. \nThe one disadvantage is that any bugs introduced by the compiler cannot be caught by the verifier. The \nbESP compiler generates SPIN specification that can instantiate multiple copies of the ESP program. This \nis achieved easily in SPIN by using an array of every data structure. Then each instance can access its \ndata by using its instantiation id. The ability to run multiple copies of a ESP program under SPIN allows \none to mimic a setup where the firmware on multiple machines are communicating with each other. The translation \ninto SPIN specification is fairly straight- forward with a few exceptions. These stem from the lack of \npointers and dynamic allocations. While ESP allows the size of the arrays to be determined at run time, \nSPIN requires it to be specified at compile time. This problem is addressed by using arrays of a fixed \nmaximum size. This size can be specified per type. Another problem arising from the lack of pointers \nin SPIN is dealing with mutable data types. For instance, $al: #array of int = #{ 5 -> 0 .... }; // \nAllocate $a2 = al; // Copy pointer $a213] = 7; // Update Here, an update to a2 has to be visible to al. \nSince, SPIN does not support pointers, different memory is allocated for al and a2 and an assignment \ncauses the entire structure to be copied. This causes a problem with mutable data structures because \nan update to one structure a2 has to be visible in the other al. We address this by assigning an objectId \nto all objects at allocation time. So, when objects get copied, the objectId also gets copied. Later, \nwhen a structure is updated, we update the all structures with the same objectId. Although, this may \nappear very inefficient, it does not increase the state-space that has to be explored and, therefbre, \ndoes not significantly impact the verifiability ol the system. Memory safety of each individual process \ncan be verified independently using the verifier (Section 4.4). To verify memory safety, we maintain \na table that maps the objec- lid of the objects to reference count. Before each object access, the compiler \ninserts an assertion to verify that the object is live. The objectId is reclaimed when the reference \ncount falls to 0 and the object is freed. One positive side- effect of having to use fixed size reference \ncount table is that the verifier can often catch memory leaks. This is because a memory leak can cause \nthe system to run out of objectIds during verification, 5.3 Case Study: VMMC Firmware The motivation \nfor using a verifier is to allow more ex-tensive testing than achievable with conventional methods. In \nthe earlier VMMC implementation, we encountered new bugs every time we tried a different class of applications \nor ran it on a bigger cluster. The state-space exploration performed by verifiers allows more extensive \ntesting. We used SPIN throughout the development process. Tra- ditionally, model checking is used to \nfind hard-to-find bugs in working systems. However, since developing firmware on the network interface \ncard involves a slow and painstaking process, we used the SPIN simulator to implement and de- bug it. \nOnce debugged, the firmware can be ported to the network interface card with little effort. As explained \nearlier (Figure 4), the programmer has to supply some test code (test.SPIN) for each property to be checked. \nThe code not only specifies the property to be verified but also simulates external events such as network \nmessage arrival. The test code is usually less than 100 lines each. Once written, these can be made part \nof the testing suite and used to recheck the system whenever changes are made to it. We have successfully \nused the SPIN verifier in a number of situations. They include: Development of Retransmission Protocol. \nThe retrans- mission protocol (a simple sliding window protocol with pig- gyback acknowledgement) was \ndeveloped entirely using the SPIN simulator. The SPIN test code used was 65 lines. Once debugged, the \nretransmission protocol was compiled into the firmware. It ran successfully on the network card without \nencountering any new bugs. The retransmission protocol in the earlier implementation required about 10 \ndays to get a working version. Since we developed our code using SPIN, it required 2 days. Checking Memory \nSafety. Since memory safety is a lo- cal property of each process, each process can be checked separately \nfor memory safety. To verify the memory safety of the biggest process in the firmware required 40 lines \nof test code. The entire state space was 2251 states and could be explored using exhaustive search mode \nin the SPIN veri- tier. It took 0.5 second to complete and required 2.2 Mbytes of memory. It should be \nnoted that an exhaustive search would not only catch all the memory safety bugs but also some memory \nleaks. The result is a safe system that does not incur the overhead of garbage collection. The firmware \nhad been debugged by the time our memory safety verifier was developed. So we ran the verifier on an \nearlier version of the system that had a bug. The bug was identified by the verifier. We also introduced \na variety of memory allocation bugs that access data. that was already freed or introduce memory leaks. \nThe verifier was able to find the bug in every case. State-space explosion prevented us from checking \nfor system- wide properties like absence of deadlocks. We are currently working on extracting more abstract \nmodels so thal the state-space search is more tractable. This hags allowed us to find several bugs in \nthe firmware that, can cause dead-locks [15]. 6. GENERATING EFFICIENT FIRMWARE As described earlier (Figure \n4), the ESP compiler uses C as baekend and generates C code thatcan be used to gener- ate the firmware. \nIn this section, we describe the ESP com- piler and then compare the performance of the new VMMC implementation \nusing ESP with the earlier implementation. 6.1 ESP Compiler Processes. The ESP compiler requires the \nentire program for compilation. It, does whole-program analysis and gen-erates one big C function that \nimplements the entire con-current program. One approach is t,o treat each process a~s an automaton and \nt,o combine them to generate one large automaton [3, 18]. Although this approach provides zero-overhead \ncontext switching, it can result in exponential growth in code size [11]. The ESP compiler takes a simpler \nap-proach. It generates the code for the processes separately and context, switches between them. Since \nthese processes are essentially state machines, the stack does not. have t,o be saved during a context \nswitch---only the program counter needs to be saved and restored. This has a fairly low over- head and \ninvolves only a few instructions. The generated code has an idle loop that polls for mes- sages on external \nchannels. When a message is available, it: checks to see if a process is waiting for that message. If \nthere is, it restarts that process by .jumping to the location where the process was blocked. The process \nthen executes till it reaches a synchronization point. If one or more processes are blocked waiting to \nsynchronize, it picks one randomly and completes the message transfer. At this point, both the syn- chronizing \nprocesses can continue executing. ESP currently uses a simple stack-based scheduling policy. This schedul- \ning policy picks one of these two processes to continue ex-ecution and adds the other one to the ready \nqueue (queue of processes that are waiting to execute). The processes are executed non-preemptively. \nWhen the running process eventually blocks, the next process in the ready queue is ex- ecuted. This is \nrepeated till there are no more processes to run and the program returns to the idle loop. The ESP compiler \nperforms some of tlw *radii irma] ~1~I i- mizations like copy propagation and dead code elimination on \neach process separately be[ore combining them to gen- erate the C code. Although, the C compiler also \nperIbrms these optimizations, the semantic information lost when the processes are combined to generate \nthe C code makes it hard for the C compiler to perfbrm these optimizations effectively. Channels. One \nway of implementing channeIs is to have a set of queues (one lbr each pattern used on the channel) that \nwriters can wait on. 9 This approach makes (,,lt fairly expensive. This is because, before blocking on \nan air state-ment, tile process has to be added to nmltiple queues (one for each case in the alt). When \nit is later unblocked, it has to 9Although there can be multiple readers on a channel, there can only \nbe one reader per-pattern on a channel. So a queue is not needed for the readers. be removed from all \nthese queues (which can require look- ing through the queue since it might be in the middle of the queue). \nThe ESP compiler takes a different approach. It uses a bit-mask per process--one bit tbr every channel \nthe process may block on. Blocking at an all statement requires simply setting the right bit mask for \nthe process, while unblocking requires zeroing out all the bits. This approach can have two problems. \nFirst, checking if a channel has a writer now requires checking the bit masks of multiple processes (as \nop- posed to just checking the corresponding queue). However, since each process uses only a. few bits \n(much fewer than 32), the bit masks for several processes can be colocated on a sin- gle integer at compile \ntime. Colocating the right processes can reduce the number of different masks to be checked to 1 or 2. \nSecond, we lose the FIFO ordering of the queues, and extra effort must be made to avoid introducing starvation. \nI h~wever, most of the t, ime only one other process is waiting. No extra overhead is incurred in the \ncommon case. Another simple optimization that helps agt'sperformance is postponing as much computation \nas possible until after the rendezvous. For instance, if an object has to be allo- cated before being \nsent over the channel, the allocation is postponed so that the allocation does not happen if one of the \nother alternatives succeeds. Messages on channels. Semantically, messages sent. over the channels require \ndeep copies to be handed to the re-ceiving processes However. the implementation can simply increment \nthe reference count of the objects to be sent over channel and just send pointers to those objects. This \nworks because only immutable objects can be sent over channels. The ESP compiler also avoids some unnecessary \nallocation associated with pattern matching. For instance, if a process wants to send more that one value \nover a channel, it has to put, it in a record. If the receiving process is using a pattern to access \nthe components, the compiler can avoid allocating the record. This is possible because the static design \nof the language allows the compiler to look at all the patterns being used to receive messages on a channel \nalong with all lh(, sell(lets oll tlla.t chanllel.   6.2 Case Study: VMMC Firmware b'igure 5 compares \nthe perlbrmance of the earlier VMMC implementa~tion (vmmcOrig) with the performance of the new implementation \nusing ESP (vmmcESP) using 3 mi- crobenchmarks. In addition, we also present the perfor-mance of the earlier \nimplementation with the fast paths dis- abled (vmmcOrigNoFastPaths). The ESP implementation currently \ndoes not implement fast paths. The first microbenchmark measures the latency of mes- sages of different \nsizes between applications running on 2 chllerent, machum~. This ~s measured by running a sim-ple pingpong \napplication that send messages back and forth between 2 machines. Figure 5(a) shows that vmrncESP is \naround ~wme as slow as vmmcOmg fbr 4 byte messages and 38 % slower for 4 Kbyte messages. However, vmracESP \nis only 35 % slower than vramcOrQNoFastPathsin the worst case (for 64 byte messages) but has comparable \nperformance for 4 byte and 4 Kbyte messages. The second microbenchmark measures the bandwidth be- tween \ntwo machines for different message sizes. In this case, an application running on one machine continuously \nsends 140-- vmmcESP 120 ----~-vmmcOrig ,)5 --4--vmmcOrigNoFastPaths / o 100-- 80-- 60-- .z 40-- . 20 \n-E F _ .,.0_ _ O_ _ 0 _ ....0.. _ .D----- 0 I I I I I I I I I I 8 16 32 64 128 256 512 IK 2K 4K Message \nSize (in bytes) (a) Latency I00 -- vmmcESP - -o-vmmcOrig ~1: ~ ~:: =til 80----+-vmmcOrigNoFastPaths / \n~'~----~ 60-- 40-- 20-- 0 i. ' \"7~--~\" ,\"i ,' ~ ~ , ~ , , ,\" s\" \" J 8 16 32 64 128 256 512 IK 2K 4K 8K \n16K 32K 64K Message Size (in bytes) (b) One Way Bandwidth 100-----o--vmmcESP -~-vmmcOrig p.,,. \u00f7 -\u00b1 \n80---4-vmmcOrigNoFastPaths //~_...~j..:Q\" ~-\"~  ////~/ - 60-- 40-- .S 7 20-- 0 [ ~ T I I I I I I I \nI I I I 4 8 16 32 64 128 256 512 IK 2K 4K SK 16R 32K 64K Message Size (in bytes) (C) Bidirectional Bandwidth \n Figure 5: Microbenchmarks Performance. The graphs have some discontinuities at the 32/64 byte boundary \nas well as at 4/8Kbyte boundary. The for-mer is because small messages of 32 bytes and less are handled \nseparately as a special case. The latter is because the page size is zlKbytes. data of particular size \nto the second machine which sin> ply receives it. Figure 5(b) shows that vmmcESP delivers 41% less bandwidth \nas vmmcOri 9 for 1 Kbyte messages and 14 % for 64 Kbyte messages. However, vmmcESP is only 25 % slower \nthan vmmcOrigNoFastPaths for 1 Kbyte messages and 12 % for 64 Kbyte messages. The final microbenchmark \nmeasures the total bandwidth between two machines for different message sizes in a dif-ferent scenario. \nIn this case, applications on two machines continuously send data to each other simultaneously. Fig-ure \n5(c) shows that vmmcESP delivers 23 % less bandwidth as vmmcOri 9 for 1 Kbyte messages but similar performance \nfor 64 Kbyte messages. Also, vmmcESP is 20 % slower than vmmcOrigNoFastPaths for 1 Kbyte messages but \nsim- ilar performance for 64 Kbyte messages. The microbenchmark performance shows that vmmcESP performs \nsignificantly worse that vmmcOrig in certain cases (latency of small messages). However, most of the \nperfor- mance difference is due to the brittle fast paths. Also, the performance difference is significantly \nless in the bidirec-tional bandwidth microbenchmark where the firmware has to deal with messages arriving \non the network as well as the host at the same time. In the other two microbenchmark, the firmware has \nto deal with only one type of message at a given instant. The microbenchmarks represent the worst case \nscenario. The impact of the performance difference on real applica- tions should be much smaller [17, \n5] for a number of reasons. First, the vmmcOr'ig numbers represent the performance of some hand-optimized \nfast paths in the system. These fast paths tend to be fairly brittle and applications often fall off \nthe fast path. While some applications [16] (which re-peatedly send very large messages) that have very \nsimple communication patterns benefit from the fast paths, a lot of applications do not. SVM applications \n[4] experience a lot of contention in the network and the actual latency mea- sured by the different \napplications varied between 3 times to 10 times slower than the microbenchmarks numbers for small messages. \nSo, for most applications, the vmmcOr'igNo-FastPaths is a more accurate representative than vmrncOri \n9 when comparing performance with vmmcESP. Second, the microbenchmarks represent applications that spend \n100 \u00b070 of their time communicating, while most real applications spend only a fraction of their time \ncommuni- cating and are, thereibre, less sensitive to firmware perfor- mance [17, 51. Finally, we plan \nto implement more aggressive optimiza- tions that should decrease the performance gap. For in- stance, \ndata-flow analysis is currently perl0rmed on a pet' process basis. We plan to extend data-flow analysis \nacross processes. 7. RELATED WORK Devices are usually programmed using event-driven state machines in \nlanguages like C, and sometimes, in assembly. We are not aware of any other high-level language for pro- \ngramming network devices. Concurrency Theory. A number of languages like CSP [13] and Squeak [61 have \nbeen designed to gain better under-standing of concurrent programming. Both of these lan-guages support \nprocesses communicating with each other. However, they were not designed with efficient implementa- t;ion \nin mind, Concurrent Languages. A number of languages like CML [191. Java [1] and OCCAM [20] support concurrency. \nCML [191 provides first-class synchronous operations. OC(:;AM [20] was designed to implement concurrent \nprograrn;~ that nm on a parallel machine. Java [1}, like most other program-mint languages, provides \nuser-level threads to express con- currency. All these systems are fairly expressive and hard to be compiled \nefficiently for devices. Code Generation+Verification. A number of other lan-guages [3, 8, 2] have taken \na similar' approach of generating efficient executables as well as specifications that can be used by \na verifier. However, they differ from ESP significantly. Esterel [3] was designed to model the control \nof synchronous hardware and has been used recently to efficiently impl~,- ment a subset of TCP protocol \n{7]. It adopts the s:l/.,.-chronous hypothes~s--the reaction to an external event is instantaneous--and \nensures that every reaction has a unique, and therefore, deterministic reaction. This makes the pro- \ngrams easier to analyze and debug. The esterel programs can be compiled to generate both soft:ware and \nhardware m> plementations. However, using esterel to implement device firmware has several drawbacks. \nFirst. the reactions are not instantaneous in practice. For instance, if a DMA becomes available while \nan event was being processed, it cannot be used to process the current event. The \"DMA available\" event \nwould be registered on the next clock tick and woHld be then available for rise. This results in inefficient \nuse of the DMA. Second, the synchronous hypothesis brces some con- straints on valid programs. For instance, \nevery iteration of a loop has to have a \"time consuming\" operation like signal emission. In addition, \nthis constraint has to be w~rifiable by the compiler. This disallows simple loops that initialize an \narray. Finally, the language is designed to encode only the control portion of the program. The data \nhandling has to be performed externally using the C interface. This forces some of the complex tasks \nincluding memory management to be implemented in C. Teapot [8] is a language fbr writing coherence protocols \nthat can generate efficient protocols as well as \\'erifly cor- rectness. It uses a state machine to keep \ntrack of the state of a coherence unit (a cache line or a page). The state ma-chine is specified using \na set of handlers similar to the C interface described in Section 2.2. However. they use con- tinuations \nto reduce the number states that the programmer has to deal with. While this approach works well when \nap- plied to coherence protocol, it suffers fbr some of the same problems described in Section 2.2 when \nused to irnplen,ent device firmware. Teapot Mso does not provide any support for complex datatypes and \ndynamic memory management Promela++ [2] is a language designed I.o mlplemcnt la.y.- ered network protocols. \nThe adjacent layers communicate using FIFO queues. Although, the layered framework works well for writing \nnetwork protocols, they are too restrictive for writing firmware code where the different modules have \nmuch more complex interactions. Also, they do riot provide any support for dynamic memory management. \nSoftware Testing. Some systems [12, 9] have been suc-cessful in finding bugs in existing software written \nm tra.d> tional languages like C. Verisoft [121 does this by modifying the scheduler of the concurrent \nsystem to do a state-space exploration. Meta-level Compilation [9] attempts to verify s.ystem-specffic \ninvariants at compile ume. However, these systems do not, simplify the task of writing concurrent pro- \ngralub. 8. CONCLUSIONS We have presented the design and implementation of ESP-,- a language for programmable \ndevices. ESP has a number of language features that allow development of compact and modular concurrent \nprograms. ESP programs can be devel- oped and debugged using the SPIN model-checking verifier. The compiler \nautomatically generates SPIN specifications from ESP programs. Once debugged, ESP programs can be compiled \ninto efficient firmware that runs on the pro- grammable device, We have reimplemented VMMC firmware for \nthe Myrinet network interlace cards using ESP. Our main conclusions are the following' * Programnfing \nevent-driven state machines can be lairly easy with the right language support. We found that the firmware \ncan be programmed with significantly fewer lines of code. In addition, since C eode is used only to perform \nsimple operation&#38; all the complexity is localized to a small portion of the code (about 300 lines \nin our implementation). This is a significant improve- ment over the earlier implementation where complex \nlUbetaCblOllb were scatbered over the entire G program (15600 lines). \u00ae Model-checking verifiers like \nSPIN can be used to ex- t, ensivety test the firmware. However, state-space ex-plosion limits the size \nof the models that can be checked. SPIN was used to develop and debug a retransmission protocol. The \nnew implementation took around 2 days (compared to the earlier implementation which took around 10 days). \nSPIN was also used to exhaustively check the memory safety on the firmware. \u00ae The performance overhead \nof using ESP is relatively small. Our microbenchmarks measurements indicate that most of the per[brmance \ndifference with the ear- lier implen~entation of VMMC is due to brittle fast, paths that rarely benefit \napplications. Based on ear- lier application studies [17, 5], we expect the impact of the ext, ra performance \noverhead to be relatively small. 9. ACKNOWLEDGEMENTS We would like to thank Rudrajit Samant, a, Tammo \nSpalink, Daniel Wang, Dirk Balfanz and the anonymous reviewer whose comments have helped improve the \npaper. 10. REFERENCES [11 K. Arnold. J. Gosling, and D. Holmes. The Java Progra,mmm9 Language, Thwd Edition. \n Addison-Wesley Publications, 2000. [2] A. Basu, T. yon Eicken, and G. Morrisett. Promela++. A language \nfor correct and efficient protocol construction. In Infocom, 1998. [3! G Berry and G. Gonthier The ESTEREL \nsynchronous programming language : design, semantics, implementation. Science of Computer Prvgrammzng, \n19(2), 1992. [4] A. Bilas, C. Liao, and J. Singh. Using network interface support to avoid asynchronous \nprotocol processing in shared virtual memory systems. In International Symposium on Computer Architecture, \nJune 1999. [5] A. Bilas and J. P. Singh. The effects of' communication parameters on end performance \nof shared virtual memory clusters, in SC97 cor~ference, Nov 1997. [6] L. Cardelli and R. Pike. Squeak: \na language for communicating with mice. Computer Graphics, 19(3):199-204, July 1985. [7] C. Castelluccia, \nW. Dabbous, and S. O'Malley. Generating efficient protocol code from an abstract specification. In SIGCOMM, \n1996. [8] S. Chandra, B. E. Richards, and J. R. Larus. Teapot: Language support for writing memory coherence \nprotocols. In Programming Language Design and Implementation, 1996. [9] A. Chou. B. Chelf. D. Engler. \nand M. Heinrich. Using mete-level compilation to check flash protocol code. In Architectural Support \n)br Programming Languages and Operating Systems, 2000. [10] C. Dubnicki, A. Bilas, Y. Chen, S. Damianakis, \nand K. Li. VMMC-2: efficient support for reliable, connection-oriented communication, tn Proceedings \nof Hot Interconnects, Aug. 1997.  [11] S. A. Edwards. Compiling esterel into sequential code. Ill Design \nAuto'rnat~on Confer'ence, 2000. [12] P. Godefroid. Model checking for programming languages using VeriSoft. \nIn Principles of Programming Languages, Paris, Prance, 1997. [13] C. A. R. Hoare. Communicating sequential \nprocesses. Communications of the A CM, 21(8):666-677, Aug. 1978. [14] G. J. Holzmann. The SPIN model \nchecker. IEEE Transaction on Software Engineering, 23(5):279-295, May 1997. [15] S. Kumar. ESP: A language \nfor programmable devices. Ph.D. thesis, Dept. of Computer Science, Princeton University, In Preparation. \n[16] K. Li, H. Chen, Y. Chen, D. W. Clark, P. Cook, S. Damianakis, C. Essl, A. Finkelstein, T. Funkhouser, \n A. Klein, Z. Liu, E. Praun, R. Samanta, B. Shedd, J. P. Singh, G. Tzanetakis, and J. Zheng. Early experiences \nand challenges in building and using a scalable disptay wall system. IEEE Computer Graphics and Applications, \n20(4):671-680, 2000.  [171 t~. P. Martin, A. M. Vahdat, D. E. Culler, and T. E. Anderson. Effects of \ncommunication latency, overhead, and bandwidth in a cluster architecture. In International Symposium \non Computer Architecture, 1997. [18] T. A. Proebsting and S. A. Watterson. Filter fasion. In Principles \nof Programming Languages, 1996. [19] J. Reppy. Concurrent Programming in ML. Cambridge University Press, \n1999. [20] B. SGS-Thomson Microelect, ronics. OCCAM 2.1 Reference Manual. 1995. 319  APPENDIX A. C \nEXAMPLE We present a code fragment that illustrates the task of' programming with event-driven state \nmachines in C. It uses a typical event-driven state-machines programming interface in C which includes \nthe following functions: setHandler(sm,s,e,f) Sets function fro be the handler for event e when the state \nmachine sm is in state s. setState(sm,s) Moves state machine sm to state s. isState(sm,s) Checks if state \nmachine sm is in state s. deliverEvent(sm,e) Deliver event e to state machine sin. The C code fragment \npresented in this section implements the following functionality. The state machine sgl is respon- sible \nfor handling requests from applications. On receiving a request to send data, it DMAs the data from the \nusers mem- ory onto the network card and hands it over to state machine SM2 (which is responsible for \nsending it over the network). Then, Sgl waits for the next request. While processing the send request., \nSM1 might need t.o block if the DMA is busy or if SM2 is not ready to accept the request. During initialization, \nthe handlers for different events are set up and the state machine is initially in state Waitgeq. When \na request from the user arrivers (event UserReq). the corresponding handler handleReq is triggered. Since \nthe user specifies virtual address of the data, it is first translated into physical address by calling \nfunction translateAddr that performs a table lookup. Then, it checks if the DMA is available. If it is, \nit calls fetchData directly. Otherwise, it sets the state of the state machine SM1 to WaitForDMA and \nblocks. In this case, fetchData will be called when the DMA becomes available (because it is the handler) \nWhen fetchData is invoked, it DMAs the data from the applications memory onto the network card by calling \ndmaData (). Then, it checks to see if the state machine SM2 is ready to accept data. If it is, it calls \nsyncSM2 directly. Otherwise, it sets the state of the state machine SM1 to WaitSM2 and blocks. In this \ncase, syncSM2 will be called when SM2 is finally ready to accept data. When syncSM2 is invoked, the request \nis handed over to SM2 by updating global variable reqSM2. Then an event SM1Ready is delivered to SM2. \nThis will eventually cause the corresponding handler in sg2 to be invoked. Finally, it sets the state \nof SM1 to waitReq and waits for the next request. enum SCateMachineT { SM1, SM2 .... }; enum StateT { \nWaitgeq, WaitDMA, WaitSM2, WaitSMl, ,,.}; enum EventT { UserReq, DMAFree, SM2Ready, SMIReady .... }; \nenum UserReqT { SendReq, UpdateKeq .... }; ReqSMl *reqSMl ; ReqSM2 *reqSM2; int pAddr, *sendData; maln() \n{ \"// Initiab:ze state 'machine SM1 setHandler( SMI, WaitReq, UserReq, handleReq); setHandler( SM1, \nWaitDMA, DMAFree, fetchData) ; setHandlsr( SMI, WaitSM2, SM2Ready, syncSM2) ; setState( SMI, WaitReq); \n// [nitial State void h~ndleReq() { // Req Aas armved switch (reqSMl->type) { case SendReq: pAddr = \ntr~islateAddr( reqSMl->vAddr); if (dmaIsFree()) fetchData(); else setState( SMi, WaitForDMA);  return; \n// Block State machine ease UpdateReq: updateAddrTrans( reqSMl->vAddr, reqSMl->pAddr); } void fetchData() \n{ // DMA ~s available sendData = dmaData( pAddr, reqSMi->size); if (isState(SM2,WaitSM1)) syncSM2(); \nelse setState( SMi, WaitSM2); } void syncSM2() { // SM2 is ready for next Teques~ reqSM2->data = sendData; \nreqSM2->dest = reqSMl->dest; deliverEvent( SM2, SMiReady); setState( SMI, WaitReq); // Wazt ~r r~ex~ \n~wquesf } B. ESP EXAMPLE This section presents ESP code fragment that is used to illustrate different \naspects of the ESP language throughout this paper. It implements some of the same functionality described \nin Appendix A. type dataT = array of int type sendT = record of { dest: int, vAddr: int, size: int} type \nupdateT = record of { vAddr: int, pAddr: int} type userT = union of { send: sendT, update: updateT .... \n} channel ptReqC: record of { ret: int, vAddr: int} channel ptReplyC: record of { ret: int, pAddr: int} \nchannel dmaReqC: record of { ret: int, pAddr: int, size: int} channel dmaDataC: record of { ret: int, \ndata: dataT} channel SM2C: record of { dest: int, data: dataT} channel userReqC: userT // Ezternal (aka \nO) writer process pageTable { // virtual to physical address \"mappzn9 Stable: #array of int = #{ TABLE_SIZE \n-> 0, ... }; while (true) { air { case( in( ptKeqC, { $ret, $vAddr})) { // Request to lookup a mapping \nout( ptReplyC, { ret, table[vAddr]}); } case( in( userReqC, { update t> { $vtddr, $pAddr}})) { // Request \nto update a mapping table [vAddr] = pAddr; } } } } process SM1 { while (true) { in( userReqC, { send \nI> { $dest, $vAddr, $slze}}); out( ptReqC, { @, vAddr}); in( ptReplyC, { @, $pAddr}); out( dmaReqC, { \n@, pAddr, size}); in( dmaDataC, { @, $sendData}); out( SM2C, { dest, sendData}); unlink( sendData); \n }  \n\t\t\t", "proc_id": "378795", "abstract": "<p>This paper presents the design and implementation of Event-driven State-machines Programming (ESP)&#8212;a language for programmable devices. In traditional languages, like C, using event-driven state-machine forces a tradeoff that requires giving up ease of development and reliability to achieve high performance. ESP is designed to provide all of these three properties simultaneously.</p><p>ESP provides a comprehensive set of features to support development of compact and modular programs. The ESP compiler compiles the programs into two targets&#8212;a C file that can be used to generate efficient firmware for the device; and a specification that can be used by a verifier like SPlN to extensively test the firmware.</p><p>As a case study, we reimplemented VMMC firmware that runs on Myrinet network interface cards using ESP. We found that ESP simplifies the task of programming with event-driven state machines. It required an order of magnitude fewer lines of code than the previous implementation. We also found that model-checking verifiers like SPIN can be used to effectively debug the firmware. Finally, our measurements indicate that the performance overhead of using ESP is relatively small.</p>", "authors": [{"name": "Sanjeev Kumar", "author_profile_id": "81331496914", "affiliation": "Princeton University", "person_id": "PP31039836", "email_address": "", "orcid_id": ""}, {"name": "Yitzhak Mandelbaum", "author_profile_id": "81100175667", "affiliation": "Princeton University", "person_id": "PP14071519", "email_address": "", "orcid_id": ""}, {"name": "Xiang Yu", "author_profile_id": "81100471962", "affiliation": "Princeton University", "person_id": "PP39044380", "email_address": "", "orcid_id": ""}, {"name": "Kai Li", "author_profile_id": "81100475927", "affiliation": "Princeton University", "person_id": "PP39044582", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/378795.378862", "year": "2001", "article_id": "378862", "conference": "PLDI", "title": "ESP: a language for programmable devices", "url": "http://dl.acm.org/citation.cfm?id=378862"}