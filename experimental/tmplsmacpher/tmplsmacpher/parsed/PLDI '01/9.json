{"article_publication_date": "05-01-2001", "fulltext": "\n Heap Profiling for Space-Efficient Java Ran Shaham Elliot K. Kolodner Mooly Sagiv TeI-Aviv University \nand IBM Haifa Research TeI-Aviv University IBM Haifa Research Laboratory sagiv@ math.tau.ac.il Laboratory \n kolodner@il.ibm.com rans@ math.tau.ac.il ABSTRACT We present a heap-profiling tool for exploring the \npotential for space savings in Java programs. The output of the tool is used to direct rewriting of application \nsource code in a way that allows more timely garbage collection (GC) of objects, thus saving space. The \nrewriting can also avoid allocating some objects that are never used. The tool measures the difference \nbetween the actual collec- tion time and the potential earliest collection time of objects for a Java \napplication. This time difference indicates poten- tial savings. Then the tool sorts the allocation sites \nin the application source code according to the accumulated po- tential space saving for the objects \nallocated at the sites. A programmer can investigate the source code surrounding the sites with the highest \nsavings to find opportunities for code rewriting that could save space. Our experience shows that in \nmany cases simple code rewriting leads to actual space savings and in some cases also to improvements \nin program runtime. Experimental results using the tool and manually rewriting code show average space \nsavings of 18% for the SPECjvm98 benchmark suite. Results for other benchmarks are also promising. We \nhave also classified the program transfor- mations that we have used and argue that in many cases improvements \ncan be achieved by an optimizing compiler. Keywords Compilers, garbage collection, Java, memory management, \nprofiling, program analysis 1. INTRODUCTION GC does not (and in general cannot) collect all the garbage \nthat a program produces. Typically, GC collects objects that are no longer reachable from a set of root \nreferences. However, there are some objects that the program never accesses again, even though they are \nreachable. This is il- Permission to make digital or herd copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for profit or \ncommercial advan-tage and that copies bear this notice and the full citation on the first page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission \nand/or a fee. PLDI 2001 6/01 Snowbird, Utah, USA &#38;#169; 2001 ACM ISBN 1-58113-414-2/01/06...$5.00 \n 1 I drag time [ creation last-use unreachable Figure 1: The lifetime of an object. lustrated pictorially \nin Figure 1. As shown in Figure 1, and following R6jemo and Runci- man [21], we refer to the time interval \nfrom the last use of an object until it becomes unreachable (and thus can be col- lected by a reachability-based \nGC [28]) as the object's drag time and to object itself as a dragged object. Drag time mea- sures a potential \nfor space savings independent of the actual GC method or GC implementation. For a previous paper [25] \nwe measured the drag time for objects and tried to characterize the dragged objects. The results showed \na potential for space savings from 23% to 74% for the SPECjvm98 benchmark suite if objects could be collected \nat their last use. In this paper, we describe a prototype tool based on drag measurements that is aimed \nto help in actual reduction of space. Applying our tool, we are in fact able to save on average 18% of \nthe space for the SPECjvm98 benchmarks. Our measurements show an average of the potential space savings \nwhen GC is performed on the entire heap. The actual savings will depend on factors such as the size of \nthe heap (which influences the frequency of GC) and the type of GC (e.g., generational GC). Since our \ntechniques reduce the set of reachable objects, space savings are expected for all JVMs employing reachability-based \nGC. 1.1 Drag Reduction Tool The tool acts in two phases: (i) measure the dragged objects, and (ii) analyze \nthe results and produce a list of allocation sites of dragged objects sorted by their potential space \nsav- ings. For the first on-line phase, we instrumented Sun's JVM 1.2 [13] in order to measure dragged \nobjects. Specifically, we record at regular intervals (i) the objects reachable at the end of the interval \nand (ii) the objects that are also used subsequent to the interval. We call the former the reachable \nobjects and the latter the in-use objects. Our goal is reducing the size of the reachable heap at every \nsampling point, by reclaiming reachable objects that are not in-use. Thus, as a second off-line phase, \nwe partition the dragged objects according to their allocation site, and for each allocation site we \nsum the drag space-time product of every dragged object. The drag space-time product, or drag for short, \nis the product of the size of the object and the time the object is reachable but not in-use. Allocation \nsites having a large drag suggest a potential for significant space savings. Therefore, our tool sorts \nallocation sites according to their drag. 1.2 Reducing the Drag Our off-line profiler tool can be used \neither directly by a pro- grammer or to produce input for a profile-based optimizer. Currently, we use \nthe tool to direct manual code inspec- tion to the allocation sites having a large drag. Examining these \nsites we have found that three kinds of simple correct- ness preserving program transformations have \nbeen effective in achieving space savings: (i) explicitly assigning null to a dead reference to an object, \n(ii) removal of dead code, and (iii) lazy allocation of objects. These program transforma- tions cannot \nharm the space consumption of a program, and in most cases save space. In Section 5 we describe the static \ninformation that is needed in order to infer that the transformations can be automati- cally conducted. \nNot all of the transformations need to be performed on the source code; instead, some could be imple- \nmented in the runt;me of the JVM, e.g., using stack-maps to maintain liveness information [1]. In order \nto reduce the cost of analyses, which in many cases involve whole program analysis, our profiling tool \ncan be used to guide the analyzer to the parts of the code that are \"drag-hot\". The tool was applied \nto nine benchmarks. Although we were not familiar with the code of these benchmarks, it took us just \na few hours to understand the results produced by the tool and to rewrite the code. Also, only few lines \nof code had to be rewritten. Of course, we believe that an application programmer using our tool on his \nown code could do a better job, both in terms of speed (of rewriting) and more importantly in terms of \nspace (reduction of drag). Code rewriting for the benchmarks we considered reduces the total drag by \n51% on average, leading to an average space saving of 15%. In some cases the runt;me cost is also reduced. \nThis is mainly due to: (i) GC is invoked less fre- quently and (ii) allocation and initialization are \navoided for objects that are never used. 1.3 Related Work RSjemo and Runciman performed similar measurements \nfor Haskell, a lazy functional language [21]. They demonstrate how to save space by rewriting the code \nof one benchmark, a Haskell compiler. However, their rewritings are based on a deep understanding of \nthe code. Other tools for memory profiling [23, 19] show the heap configuration and alloca- tion frequency; \nthey also help in tracking memory leaks by allowing the heap to be inspected at points during the ex- \necution of the program. As noted by Serrano and Boehm [23], tracking memory leaks by inspecting dragged \nobjects is orthogonal to tracking leaks by inspecting the heap during the course of execution. Automatic \ntechniques aimed at reclaiming more storage in- clude integrating liveness analysis and GC [1] and compile- \ntime GC. Agesen et al. [1] integrate liveness analysis of local reference variables with CC, so that \nreference variables with no future use (i.e~, dead references) are not regarded as part of the root set. \nIn an earlier paper [24], we show how to integrate liveness analysis for arrays of references with GC, \nso dead array elements are not regarded as part of the root set. Turning to compiler;me GC, most work \nhas been done for functional languages [2, 15, 8, 16]. However, escape anal- ysis [3, 27], which is in \nsome sense a special case of compile- time GC, has been recently applied to Java. Experimental results \nin [3] show an average speedup of 21% using escape analysis to stack allocate objects. 1.4 Outline of \nthe Rest of this Paper The remainder of the paper is as follows. Section 2 describes our prototype tool. \nSection 3 presents the framework of the experiment. In Section 4 results are discussed. Section 5 describes \nthe static information necessary to automatically apply space savings transformations. We conclude in \nSec- tion 6. 2. THE TOOL The heap-profiling tool consists of two phases. In the first phase, an instrumented \nJVM runs a Java application and outputs information on dragged objects to a file. This is the same instrumentation \nreported in our previous work [25]. The second phase.analyzes the file, producing a list of al- location \nsites sorted by their potential for drag reduction. We found that it is best to have information regarding \nthe nested allocation site of a dragged object, i.e., the call chain leading to the allocation. 2.1 The \nInstrumented JVM At a high level we associate a time field with every object in order to record drag \ninformation. On every use of an ob- ject, we record the current time in its field. Thus, the field always \nholds the time at which the object was last used. In order to approximate the time at which an object \nbecomes unreachable, we frequently trigger GC; thus when an object is collected, its drag time is calculated \nas the difference be- tween the approximated time it becomes unreachable (i.e., its collection time) \nand the time it was last used. We mea- sure time in bytes allocated since the beginning of program execution, \nassuming that all uses of an object in the interval between consecutive garbage collection cycles are \nperformed at the beginning of the interval. The instrumented JVM is based on Sun's JVM 1.2 (aka clas- \nsic JVM). Its memory system uses indirect pointers to ob- jects (\"handles\"), thus objects can be relocated \neasily during GC. Below we provide greater detail on our instrumentation.    2.1.1 Implementation \nWe attach a trailer to every object to keep track of our profiling information. We do not count the space \ntaken for this trailer in our data. The information in an object's trailer is written to a log file upon \nreclamation of the object or upon program termination. An object's trailer fields include its creation \ntime, its last use time, its length in bytes, its nested allocation site and its nested last-use site. \nThe length includes the header and the alignment (i.e., the bytes that were skipped in order to allocate \nthe object on an 8 byte boundary), but excludes the handle and the trailer. Object information is updated \nupon the following events: Object Creation The creation time, length and nested al- location site are \nset. The level of nesting can be set in order to tradeoff more accurate information and speed. Object \nUse The last use time and nested last use site are set. The following events constitute an object use: \n(1) getting field information (e.g., via getfield byte-code), (2) setting field information (e.g., via \nput:field bytecode), (3) invoking a method on that object (e.g., via invokevirtual bytecode) (4) entering \nor exiting a monitor on that object (via monitorenter, monitorexit bytecodes) and (5) derefencing a handle \nto that object. The last item is relevant for native code, since manip- ulating a Java object in native \ncode is done through a handle to the Java object. After every 100 KB of allocation we trigger a deep \nGC (a larger interval yields less precise results). A deep GC con- sists of the following steps: (1) \nGC, (2) run finalizers for all objects waiting for finalization, (3) GC. Forcing finaliza- tion ensures \ninstant reclamation of all unreachable objects and removes a source of non-determinism (since finalization \nwould otherwise occur in a separate thread). When an ob- ject is freed, we log all of the information \ncollected in its trailer. When the program terminates, we perform a last deep GC and then we log information \nfor all objects that still remain in the heap. The rules for the collection of Class objects are not \nthe same as for regular objects. Thus, we exclude them and the spe- cial objects reachable from them \n(e.g., constant pool strings and per-class security-model objects) from our reports. 2.2 Drag Reporting \nThe second phase analyzes the information written to the log file by the first phase. The drag of an \nobject is the product of the size of the ob- ject and the time the object is reachable and not in-use. \nWe partition the dragged objects into groups according to their nested allocation site, associating with \neach group the sum of the drag for all objects allocated at its site. Some-times an allocation site is \nused in many contexts and a large drag may be distributed among several smaller drag groups when partitioning \nsolely according to nested allocation site. Thus, we also do a coarse-grained partition according to \nthe allocation site. Sometimes the site at which a dragged object was last used (hereafter, called last-use \nsite) may hint at the code rewrit- the last-use site may hint at the program point where a ref- erence \nto that object becomes dead. Thus, we also partition dragged objects according to nested allocation site \nand last- use site. In Euler benchmark (see Table 1), the last-use site is used to determine which reference \nvariable prevents an object from being reclaimed. A special case for a dragged object is an object that \nis never used. We partition these never-used objects according to nested allocation site and according \nto allocation site. Our experience so far suggests that a large drag caused by never- used objects is \na \"sure bet\" for code rewriting. Graphs showing the amount of heap memory in-use and the amount reachable \nover time can also be produced as reported in our previous work [25]. These are useful for visualizing \nthe overall memory usage of an application. 3. APPLYING THE TOOL We applied the drag reduction tool to \nsample Java pro-grams to determine the allocation sites in those programs contributing the most to the \ndrag. Then we carefully an- alyzed the source code around those sites in order to find program transformations \nthat reduce the drag. Interest-ingly, we found out that a very shallow understanding of the program suffices \nto reduce a significant part of the drag. Moreover, future-optimizing compilers may be able to auto- \nmatically conduct these transformations (see Section 5). In this section we describe the drag reducing \nprogram trans- formations and how we used the tool to direct the choice of the proper transformations. \n3.1 The Benchmark Programs Specifically, we applied the tool to nine sample Java pro- grams. We list \nthe programs in Table 1. The second and third columns show the total number of application classes and \nthe total number of application source code statements, respectively. JDK classes and general SPEC classes \nshared by all SPECjvm98 benchmarks are not included in Table 1. There are 32 general SPEC classes having \ntotal of 3173 source code statements. We employed five of the benchmarks from the SPECjvm98 benchmark \nsuite [26]. We do not consider compress or mpegaudio because they do not use significant amounts of heap \nmemory. Another two benchmarks were taken from Java Grande benchmark suite [12]. The last two bench- \nmarks are internal IBM tools. 3.2 Reducing the Drag The code was manually investigated in order to determine \nthe reasons for drag. Since we were unfamiliar with the code of the sample programs, we employed JAN \n[20], a tool for analyzing and understanding Java programs. We used two kinds of information provided \nby JAN: (i) the class hier- archy graph, and (ii) the program call graph. This kind of information is \nalso provided by many other Java compilers and analysis tools. ing strategy best-suited for reducing \nits drag. For example, We used the class hierarchy graph for accelerating source if a dragged object \nremains reachable due to dead references, browsing, e.g., locating overloaded methods. We used the ~Benchmark \nCla Classes[ Stmts Short Description %~v'&#38;C 176 12345 java compiler 3 512 database simulation 56 \n5106 parser generator I aytrace 25 1479 raytracer of a picture j3ss 151 4567 expert system shell 12C \n15 880 financial simulation uler 5 726 Euler equations solver 38 2505 web indexing naiyzer 258 35489 \nmutability analyzer Table 1: The benchmark programs. program call graph to check the applicability and \nvalidity of program transformations. For example, assigning null to a dead reference variable requires \ninspection of every possible use of that variable. Using the program call graph, we can check that some \nuses of the variable, which appear in the source code, do not actually occur at runtime, e.g., if the \ngraph shows that the method is never invoked. Source transformations were applied only after a thorough \ninspection of the source code and validation that the trans- formation was applicable using the program \ncall graph. We also checked that the original and revised benchmarks pro- duce identical results on several \ninputs. In order to measure the effect of code rewriting on the running times of the pro- grams, the \noriginal and revised versions were invoked and their running times also compared. The code of the benchmarks \nas well as selected classes of the JDK itself were rewritten using the code rewriting strategies discussed \nbelow in Section 3.3. The tool was reapplied to the revised code in order to measure the resulting drag, \nand determine the actual space savings. Sometimes, the results revealed more opportunities for drag reduction; \nin that case, another cycle of code rewriting and applying the tool took place. 3.3 Code Rewriting Strategies \nSurprisingly enough (at least for us), it appears that a few simple code rewriting techniques suffice \nfor reducing much of the drag. The first technique is simply assigning the null value to a reference \nthat is no longer in use. This reference may be a local variable, an instance field, a static field, \nor an element within an array of references. The second technique is removing dead code, i.e., code that \nhas no effect on the result of the program. Our main interest is in dead code that produces dragged objects. \nThe third technique is delaying the allocation of an object until its first use; thus, avoiding memory \nconsumption for objects that are never used. In Section 5 we discuss how these code rewriting techniques \ncan be replaced by automatic means. 3.3.1 Assigning Null In many cases a dragged object remains reachable \nafter its last use due to a dead reference. We inspect the code for all possible uses, identify the places \nwhere the reference be- comes no longer used, and insert a statement assigning null to that reference. \nThe details depend on the kind of variable containing the reference. For a local reference variable we \ninspect the containing method for possible uses. For an instance field we inspect the code according \nto visibility modifiers of the field, e.g., for a private field we inspect only the code of the containing \nclass. Sometimes the program call graph is used to determine the context for a possible use. As noted \nearlier, we use program call graph information to invalidate possible uses in unreachable methods. For \narrays of objects we have found cases where an element becomes dead. For almost all cases the array is \nbeing used to implement a data type similar to a Java vector and an element is being removed from the \narray [24]. Our tool provides information about the last line of code at which an object is used. This \nhelps to find the place in the code where the object is no longer in use. 3.3.2 Dead Code Removal Dead \ncode [18] does not affect the result of the program. Us- ing a feature of the tool showing objects that \nare allocated but never used, we find allocation sites where all objects are never-used. These never-used \nobjects may be referenced by local variables, instance variables and array elements of type reference. \nWe eliminate the allocation of these objects. This optimization is not always possible as it also removes \nthe invocation of the constructors for these objects. We must guarantee that the constructor is the only \ncode that refer- ences the object and that the constructor has no influence on the rest of the program, \ne.g., it does not update other objects or static variables and it cannot throw an exception for which \nthere may be a handler in the surrounding code. 3.3.3 Lazy Allocation Using the same feature of the tool \ndescribed above, we have found allocation sites that produce many never-used objects. If these objects \nare big contributors to the drag, then we change the code to allocate them lazily. In particular, we \neliminate the original allocation of the object and the vari- able that would have referenced the object \nremains null or is assigned null. Then, at every possible first use of the object, there is a test to \ncheck whether the variable is still null. If so, the object is allocated. We find possible first uses \nin the source code by employing the program call graph. In general determining that postponing the allocation \nof an object does not change program semantics is hard. Thus, we only employ this transformation for \nthe easy cases. In par- titular, the constructor may not depend on program state, e.g., it must have \nno parameters or parameters that are con- stant and it may not read program state (for example, access \na static variable) in its body. Also, the constructor may not throw exceptions for which there may be \nhandlers in the surrounding code. For all of the objects for which we ap- plied this transformation, \nthe only possible exception was 0ffr_0F.NEI~I01~\u00a5 for the allocation itself; thus, we only had to check \nthat there were no handlers for 0ffr_0F_I4EMORY in the program. Lazy allocation may add runtime overhead \nfor the checks at every possible first use. Thus, there is a risk that it could be detrimental for some \nprogram inputs, and care needs to be taken to apply it only when most of the objects allocated at the \ndragged allocation site are never-used. Nevertheless, this transformation has a lot of potential for \nreducing space and drag. We used it for just one of the benchmarks, j aek.  3.4 Putting It All Together \nGiven the output of the drag-profiling tool we need to de- termine which program transformation to apply. \nOur ex-perience shows that the first step is to find the method and the reference variable on which attention \nshould be fo- cused. We choose a nested allocation site with high drag. The bottom level is likely to \nbe an allocation site in JDK or other library code, e.g., allocating a character array in java.util.String. \nWe follow the call chain upwards look- ing for the first place in application code where a reference \nto the allocated object (or to an object containing the al- located object) is stored in a variable. \nWe call this place the anchor allocation site. We call the variable the anchor variable. Our experience \nsuggests that the second step is to employ the output of the tool to investigate the lifetime charac- \nteristics of dragged objects at the anchor allocation site. In particular, the tool outputs the drag \nsize due to objects allo- cated at a given anchor allocation site without any recorded use (the last \nuse time is zero). The tool also partitions the dragged objects at that anchor allocation site according \nto their drag time, in-use time, and collection time. We have identified the following patterns of behavior: \n1. All of the drag at the site is due to objects that are never-used. In some cases the only use of an \nobject may be in its constructor and its in-use time is very short; we also consider these as objects \nthat were never used. 2. Most of dragged objects at the site are never-used. 3. Most of dragged objects \nat the site have a large drag. 4. The variance of the drag for the objects at the site is high.  Based \non the lifetime pattern at the anchor allocation site, one of the drag reducing program transformations \nmight be applicable. The first pattern suggests the dead code removal trmmformation. The second pattern \nsuggests the lazy al- location transformation. The third pattern suggests that assigning null (to a dead \nreference) is the most applicable transformation. The fourth pattern suggests that there may be no program \ntransformation that might help. For example there may be a large repository of objects as in the db benchmark. \nA query on the repository leads to a use of an object. How-ever, each query accesses only a small number \nof objects and the queries are spread out over the whole application. Nevertheless the repository and \nall objects in it need to be kept as the exact queries cannot be predicted in advance. These patterns \ndo not cover all of the possibilities. How-ever, most repeated more than once and we found them to be \nuseful for finding applicable program transformations. Below we provide examples from the benchmark programs \nfor each of the transformations and try to relate them to the patterns. Sometimes, when applying these \ntransforma- tions, the value of the anchor variable is assigned to other variables. These variables also \nhave to be considered when applying the transformation. 3.4.1 Assigning Null In juru the largest drag \nfor an allocation site is 25.94MB 2. Character arrays of 100K elements are allocated at this site and \nassigned to a local variable. Each of these arrays is in-use for 200KB of allocation and then in-drag \nfor another 200KB until it becomes unreachable. Assigning null to this local variable after its last \nuse eliminates this drag and leads to a 33% reduction in total drag for juru. The drag time of these \nobjects is short, but the objects are large so these ob- jects contribute significantly to the drag space-time \nproduct. This fits the third pattern. 3.4.2 Dead Code Removal In raytrace benchmark there are 17 allocation \nsites with the same behavior: an object is allocated and assigned to an array element; the object's last \nuse occurs during its ini- tialization, which is done in its constructor. Thus, all objects allocated \nat these sites are considered never-used. Each of these allocation sites contributes 4.77MB 2 to the \ndrag. This behavior fits the first pattern and we apply the dead code removal transformation. With the \nhelp of the program call graph, we verify that these objects referenced by the array elements are never \naccessed outside their constructors. We also verify that the construc- tors do not have any side effects. \nThus, the code for the allocation of these objects can be removed. This leads to a 45% reduction in total \ndrag. 3.4.3 Lazy Allocation In the jack benchmark, the three allocation sites producing the largest \ndrag are all in the same constructor. More than 97% of the drag for these three allocation sites is due \nto objects that are never-used. This behavior fits the second pattern and we apply the lazy allocation \ntransformation. We turn to the constructor's code. One Vector and two HashTable objects are allocated \nat the allocation sites. Ref- erences to each of these data structures are assigned to in- stance fields. \nThese instance fields have package visibility, i.e., they are visible to all package members. Thus, we \nscan the package for possible uses. It turns out that all uses of these instance fields occur in their \ncontaining class. We eliminate the allocations and before every possible first use of one of the instance \nfields, we add a test to check whether the allocation has already been done. If not, the allocation is \nperformed. 4. RESULTS We present the results of applying our heap profiling tool to the benchmark applications: \nthe savings in space and the savings in time. JAVAC JAC K ,4 0 .~ 'i 5O 100 150 1.4 1.2 1 0.8 0.6 0.4 \n0.2 0 o I ~ 100 t ~ ~-~ 150 fl.AY'I-RAC E JESS 3.5 3 2.5 2 O5 \"13 0 50 100 1.4 1,2 1 0.8 0.6 0.4 0.2 \nG o 50 lOO 15o 200 ! EULER MC . 80 60 40 20 0 50 100 150 200 250 0 50 100 150 2CX~ 250 JURU ANALYZER \n1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0,2 0 50 100 150 200 250 300 350 3.5 3 2.5 2 1.5 1 0.5 0 O 50 t OO 150 \n200 250 Figure 2: Original reachable/in-use heap size vs. revised reachable/in-use heap size. X-axis \ndenotes allocation time in MB. Y-axis denotes size in MB. Benchmark Program j avac jack raytrace jess \n euler mc i juru i analyzer Benchmark Reduced Program Reachable Integral (M Byte 2) j avac 340.99 \njack 47.92 raytrace 540.97 jess 561.68 euler 7320.18 mc 7043.01 juru 314.9 analyzer 859.85 Reduced In-Use \nReachable Integral Integral (M Byte 2) (MByte 2) 566.49 937.09 50.58 82.24 127.47 220.59 74.01 231.91 \n1421 1459.64 10969.61 11010.44 159.83 210.92 196.19 409.84 Original In-Use Reachable Integral Integral \n(M Byte 2) (M Byte ~) 656.19 1015.4 57.07 141.93 128.42 317.62 73.67 260.86 1424.34 1574.28 11310.73 \n11747.09 159.83 236.86 195.9 482.46 Drag Space Saving Saving Ratio Ratio (%) (%) 21.8 7.71 70.34 42.06 \n51.28 30.55 15.47 11.2 76.46 7.28 i68.82 6.27 33.68 10.95 25.34 15.05 Table 2: Drag and Space Savings \nfor original inputs. Original Space Reachable Saving Integral Ratio (M Byte 2) (~o) 353;36 3.5 61.39 \n21.94 755.84 28.43 591.09 4.98 7725.46 5.25 7513.95 6.27 351.76 10.48 1051.57 18.23 Table 3: Drag and \nSpace Savings for alternate in-puts. 4.1 Space Savings For each of the benchmarks Figure 2 shows graphs \nof the the reachable heap size (sum of the sizes of the reachable objects) and the in-use heap size (sum \nof the sizes of the in- use objects) before and after the rewriting of the code. The black line shows \nthe reachable size and the thin gray line the in-use size before rewriting. The area between these two \nlines is the initial drag. The white line shows the reachable size and the thick gray line the in-use \nsize after rewriting. (In most cases the thick gray line and the thin gray line coincide and cannot be \ndifferentiated.) The area between the black line and the white line is the space that is saved by the \noptimizations. Looking at the graphs for SPECjvm98 benchmarks, we see that the size of the reachable \nheap is reduced for j avac and jack. Moreover, the reachable and in-use object size lines for the optimized \nversion occur \"earlier\" in the graph than for the original run. This is due to the elimination of some \nunnecessary allocation. For raytrace the size of the reachable heap is reduced by an almost constant \nsize, and the in-use object size remains the same. This is due to the fact that close to 1MB of allocation \nof long-lived never-used objects has been eliminated. How-ever, there is practically no shift in the \ngraph since 1MB is less than 1% of the total number of bytes allocated during a run. There is a potential \nfor drag reduction by rewriting some of the JDK code. We demonstrate drag reduction due to JDK rewriting \nin jess benchmark. In principal, JDK rewriting is applicable for all of the benchmarks. The size of the \nreach- able heap for jess is reduced by a constant size, similarly to raytraee. The graph for db is not \nshown. There are no space savings for this benchmark. Turning to the other benchmarks, for suler the \nsize of the reachable heap for the original run has a constant size, be- cause all allocations are done \nin advance. By assigning null to dead references we were able to reduce most of the drag (76% of it), \nand the optimized heap size almost coincides with the in-use object size. In mc the size of the reduced \nreachable heap is even below the size of original in-use object size. This is due to the fact that many \nallocations are eliminated. In juru there is a constant reduction in the reachable heap size. juru acts \nin cycles, with the same reduction on every cycle. Lastly, for the analyzer benchmark the size of the \nreachable heap is reduced only after allocating the first 78MB in the program. This occurs because objects \nused for the first part of computation (first 78MB of allocation) are not needed later in the computation. \nIn Table 2, we show measurements of the drag reduction and the total space savings. Following Agesen \net al. [1] we mea- sure the space-time products for the reachable and in-use object size (we call these \nproducts integrals as they are the area under the reachable and in-use graphs respectively). The ratio \nbetween the reduced reachable integral and the original reachable integral captures the average space \nsav- ings. The original drag is the difference between original reach- able and in-use integrals. The \namount of drag reduction is the difference between the original reachable integral and reduced reachable \nintegral. Drag savings is computed as the ratio between the amount of reduced drag and the original drag. \nThe average space savings for all the benchmarks (including db) is 14% and the average drag savings is \n51%. In mc the size of the reduced reachable heap is tess than the size of the original in-use objects. \nThis leads to 168% savings of drag, since we saved even more than the original drag. We also ran each \nbenchmark on an input other than the one initially analyzed by the tool. Results are shown in Ta- ble \n3. For raytrace, euler, mc, juru and analyzer space saving results were similar to the ones reported \nfor the ini- tial input. For javac, jack and jess some space is saved, although less than the amount \nof space saved for the initial input. We believe that this shows that the transformations work for multiple \ninputs, noting that the approximation of the amount of space savings in general should be based on measurements \nfor a set of inputs. We informed the developers of juru and analyzer of our results. These developers \nwill be integrating our suggested rewritings into future versions of their code. Interestingly, we also \nnoted that later versions of jack application, which is now called javacc [11], use similar rewritings \nto the ones we suggest. 4.2 Runtime Savings The measurements were done on a 400MHz Pentium-II CPU with \n128MB main memory running Windows NT 4.0 on several JVMs including IBM JVM 1.3 [10] and Sun HotSpot Client \n1.3 [14]. For the SPECjvm98 benchmarks, juru and analyzer we used a 32MB initial heap size and a 48MB \nmaximum heap size. For euler and mc we used a 64MB initial heap size and a 96MB maximum heap size. Each \nreported result is the average of 10 runs. Table 4 shows the runtime savings for the optimized bench- \nmarks. We choose to show runtime results for Sun HotSpot client since it uses a generational GC [28]. \nA generational GC delays the collection of some unreachable objects in or- der to get better performance. \nThus, the potential benefit for saving drag time for an object is decreased. Nevertheless, the average \nruntime for all of the benchmarks (including db) is reduced by 1.07%. Speedups are due to two factors:(i) \nallocation savings, saving both allocation and constructor time and (ii) GC is invoked less frequently. \n5. STATIC ANALYSIS ALGORITHMS In this section, we discuss the kind of program analysis al- gorithms necessary \nto automate our space savings program transformations. In the future, we hope to implement these algorithms. \nOur goal is to find analyses that are cheap yet provide sufficient information to do the transformations. \nIn our discussion we provide examples chosen from the man- ual transformations we did on the benchmarks. \nTable 5 shows the transformations used for each benchmark, the space saved for each transformation, and \nthe static anal- ysis technique that might be used to achieve the savings automatically. We believe that \ndemand analysis [6, 22] may be useful in this context. This would allow starting the analysis from Table \n4: Runtime Savings. Sun HotSpot 1.3 Client Benchmark Reduced Original Runtime Program Runtime (sec.) \nRuntlme (sec.) Saving(%) javac 26.569 26.538 -0.12 jack 14.961 15.11 0.99 raytrace 16.07 16.452 2.32 \njess 11.868 12.116 2.05 euler 42.772 43.605 1.91 mc 34.154 34.884 2.09 juru 23.51 23.69 0.76 analyzer \nI 15.958 15.898~ -0.38 allocation sites with large drag as obtained by our tool. There are many potential \nprogram analyses that could be useful and our discussion is by no means complete. Specifi- cally we consider \nthe following program analysis issues: Datafow analyses (Section 5.1). We consider coarse- grained analysis \nthat provides sufficient information. \u00ae Analyzing references versus analyzing arrays of refer- ences, \nwhich is considerably more complex (Section 5.2). \u00ae The code granularity of analysis (Section 5.3). Here, \nwe tried to pick the smallest unit of code that can be analyzed separately. Dependencies on call graphs \n(Section 5.4). The pres- ence of virtual function invocations and uncalled meth- ods greatly affects \nthe results; call graph information shows the methods that may actually be used.  Exception analysis \n(Section 5.5). Java's precise ex- ception model [7, Chapter 11] forbids certain program transformations. \n We also make certain simplifying assumptions about the an- alyzed code, which are satisfied by the \nbenchmarks we con- sidered. We assume that all the code for an application is available, and it does \nnot include refection or multithread- ing (which can be handled conservatively by methods not described \nhere). 5.I The Dataflow Analysis Problem We found four kinds of useful dataflow information: Usage-analysis \nFinding variables that are set using side- effect free expressions, but never used. This helps to find \nassignment statements that can be safely elimi- nated. Indirect-usage analysis The main idea is that \nan object is never-used if none of its references is ever derefer- nced. Liveness-analysis Identifying \nprogram locations where a reference has no future use, i.e., it is set before being Benchmark Rewriting \nReference ! Drag Program Strategy Kinds Saving(%) javac code removal protected ] 21.8 jack lazy allocation \npackage ] 70.34 raytrace code removal private arraY ' 45.01 assigning null private 6.27 jess assigning \nnull private array 2.7 code removal public static final 1.68 (JDK rewrite) code removal private static \n11.09 euler assigning null package array 76.46 mc code removal local variable + 119.95 private assigning \nnull private array 48.87 j uru assigning null local variable 33.68 analyzer assigning null local variable \n+ 25.34 private static Table 5: Summary of Rewritings. Expected Analysis indirect-usage rain. code insertion \nI array liveness (R)i liveness (R) array liveness usage usage (R) array liveness indirect-usage (R) ' \narray liveness liveness ..... liveness used on every execution path. This information can be passed to \nGC, as done in Agesen et al. [1], so that the root set is reduced at runtime. Alternatively, the program \ncan be transformed to assign null to dead references. Minimal-code insertion This analysis helps to \ndetermine where lazy allocation could be used. It is similar in spirit to code motion, e.g., see [4]. \n Two examples of the benefits of usage-analysis are shown in Table 5. We describe one of them here. In \nthe locale class of the JDK, a static variable is declared for every possible locale. These variables \nare assigned with newly allocated locale objects. The code of a benchmark (along with JDK classes) can \nbe analyzed for usage of these static variables and those, which are never-used, can be eliminated. This \nsaves the allocation of the corresponding locale object. Two examples of the benefits of indirect usage-analysis \nare shown in Table 5. We describe one of them here. In a class in j avac a string is allocated and assigned \nto an instance field. The field is never used except for assigning its value to other reference variables. \nThese variables are never used; thus, the allocation of the string can be saved. We see that in analyzer, \nliveness analysis for local variables together with liveness analysis for a private static variable lead \nto a 25% reduction in drag. Minimal code insertion is employed for lazy allocation. It is used to approximate \nthe possible first use of an object. At first, possible references to that object are identified us- \ning alias analysis [5, 9]. Then, possible uses of a reference are identified using use-def chains [18]. \nFinally, the code for lazy allocating the object is inserted before every possible use. Minimal code \ninsertion is achieved by analyzing the places where such code is inserted in a PRE [17, 4] fashion. In \ngeneral this type of transformation could lead to longer running times for the programs; thus, it must \nbe applied judiciously. We employed it for jack with good results; run- time results show an improvement \nof close to 1%. 5.2 Simple References vs. Arrays of Refer- ences An array of references represents a \nset of references, whereas a reference variable represents a single reference. Moreover, the address \nof an array element also depends on a subscript variable that is computed at execution time. Thus, analysis \nfor array variables, e.g., liveness, is harder than analysis for simple variables. In jess a dynamic \nvector-like array of references is maintained. After removing the logically last element from this array, \nthat element has no future use. Interestingly, the original code tries to handle this case of a dead \nelement, but it does not handle it completely. Array liveness analysis [24] can detect this case. This \nstresses the need for an automatic solution. 5.3 Analysis Granularity The cheapest analyses handle small \ncode units, e.g., Agesen et al. [1] perform liveness analysis one method at a time. This analysis would \nsuffice to reduce the drag in juru by 34%. However, there are cases in other benchmarks, e.g., for liveness \nof an instance field, where whole program inter- procedural analysis would be required since non-local \ninfor- mation must be considered. We are also investigating variants of interprocedural analysis limited \nto a smaller code unit, e.g., a set of classes, but do not report on it here. 5.4 Dependencies on Call \nGraphs Considering the call graph can reduce the amount of code that needs to be analyzed, thus leading \nto more accurate results. In particular, the call graph shows the methods that are never called (unreachable \nmethods) and can be used to reduce the set of possible targets for a virtual call site. In Table 5, we \nmark usage of call graph dependencies by (R). In raytrace there is an instance field of a class that \nis not used outside of the constructor, except for a get method that returns the value of the field. \nThe call graph shows that the get method is never invoked. 5\u00b05 Dependencies on Exception Analysis The \nprecise exception model of Java requires careful analysis in order to enable the movement of code or \nthe removal of code. Our transformations involve code removal, thus the removed code must be analyzed \nfor the exceptions that it can throw. Then, the rest of the code must be analyzed to verify that none \nof these exceptions could be caught by an exception handler. 6. CONCLUSIONS AND FUTURE WORK In this paper, \nwe presented a useful profiling tool for investi- gating tmap memory behavior of Java programs and saving \nspace. Our experiments indicated that it is quite easy to use the tool in order to reduce the space without \na deep understanding of the application. We have also identified ways in which optimizing compilers could \nautomatically achieve most of these benefits. In the future we hope to develop feasible compiler algorithms \nthat can achieve part of these savings. 7. REFERENCES [1] 0. Agesen, D. Detlefs, and E. Moss. Garbage \nCollection and Local Variable Type-Precision and Liveness in Java Virtual Machines. In SIGPLAN Conf. \non Prog. Lang. Design and Impl., pages 269-279, June 1998. [2] J. M. Barth. Shifting garbage collection \noverhead to compile time. Commun. ACM, 20(7):513-518, 1977. [3] B. Blanchet. Escape analysis for object \noriented languages, application to Java tm. In Conf. on Object-Oriented Prog. Syst., Lang. and Appl., \nDenver, 1998. [4] R. Bodik, R. Gupta, and M. L. Sofia. Complete removal of redundant expressions. ACM \nSIGPLAN Notices, 33(5):1-14, May 1998. [5] A. Deutsch. Semantic models and abstract interpretation for \ninductive data structures and pointers. In Proc. of ACM Symposium on Partial Evaluation and Semantics-Based \nProgram Manipulation, PEPM'95, pages 226-228, New York, NY, June 1995. ACM Press. [6] E. Duesterwald, \nR. Gupta, and M. Sofia. A practical framework for demand driven interprocedural data flow analysis. In \nTrans. on Prog. Lang. and Syst., 1998. [7] J. Gosling, B. Joy, and G. Steele. The Java Language Specification. \nThe Java Series. Addison-Wesely, 1996. [8] G. W. Hamilton. Compile-time garbage collection for lazy functional \nlanguages. In Memory Management, International Workshop IWMM 95, 1995. [9] M. Hind and A. Pioli. Which \npointer analysis should I use? In Int. Syrup. on Soft. Test. and Anal., 2000. [10] IBM JDK 1.3. Available \nat http://www.ibm.com/java. [11] JavaCC - The Java Parser Generator. Available at http://www.metamata.com/javacc. \n[12] Java Grande Benchmark Suite. Available at http://www.epcc.ed.ac.uk/j avagrande. [13] Sun JDK 1.2. \nAvailable at http://java.sun.com/j2se. [14] Sun HotSpot Client 1.3. Available at http://java.sun.com/products/hotspot. \n[15] T. P. Jensen and T. Mogensen. A backward analysis for compile-time garbage collection. In European \nSyrup. on Prog., pages 227-239, 1990. [16] R. Jones. Garbage Collection. Algorithms for Automatic Dynamic \nMemory Management. John Wiley and Sons, 1999. [17] J. Knoop, O. Riithing, and B. Steffen. Optimal code \nmotion: Theory and practice. ACM Transactions on Programming Languages and Systems, 16(4):1117-1155, \nJuly 1994. [18] S. Muchnick. Advanced Compiler Design and Implementation. Morgan Kanfmann, 1997. [19] \nW. D. Panw and G. Sevitski. Visualizing reference patterns for solving memory leaks in java. In ECOOP'99, \npages 116-134, Lisbon, Portugal, 1999. [20] S. Porat, B. Mendelson, and I. Shapira. Sharpening globM \nstatic analysis to cope with java. In CASCON, 1998. [21] N. Rbjemo and C. Runciman. Lag, drag, void \nand use--heap profiling and space-efficient compilation revisited. In Proceedings of the 1996 ACM SIGPLAN \nInt. Conf. on Func. Prog., pages 34-41, Philadelphia, Pennsylvania, 24-26 May 1996. [22] M. Sagiv, T. \nReps, and S. Horwitz. Precise interprocedural dataflow analysis with applications to constant propagation. \nTheor. Comp. Sci., 167:131-170, 1996. [23] M. Serrano and H.-J. Boehm. Understanding memory allocation \nof scheme programs. In International Conference on Functional Programming, pages 245-256, 2000. [24] \nR. Shaham, E. K. Kolodner, and M. Sagiv. Automatic removal of array memory leaks in java. In Int. Conf. \non Comp. Construct. Springer, Apr. 2000. [25] R. Shaham, E. K. Kolodner, and M. Sagiv. On the effectiveness \nof GC in java. In Int. Syrup. on Memory Management. ACM, Oct. 2000. [26] SPECjvm98. Standard Performance \nEvaluation Corporation (SPEC), Fairfax, VA, 1998. AvMlable at http://www.spec.org/osg/jvm98/. [27] J. \nWhaley and M. Rinard. Compositional pointer and escape analysis for java programs. In Conf. on Object-Oriented \nProg. Syst., Lang. and Appl., 1998. [28] P. R. Wilson. Uniprocessor garbage collection techniques. In \nMemory Management, International Workshop IWMM, Sept. 1992.    \n\t\t\t", "proc_id": "378795", "abstract": "<p>We present a heap-profiling tool for exploring the potential for space savings in Java programs. The output of the tool is used to direct rewriting of application source code in a way that allows more timely garbage collection (GC) of objects, thus saving space. The rewriting can also avoid allocating some objects that are never used.</p><p>The tool measures the difference between the actual collection time and the potential earliest collection time of objects for a Java application. This time difference indicates potential savings. Then the tool sorts the allocation sites in the application source code according to the accumulated potential space saving for the objects allocated at the sites. A programmer can investigate the source code surrounding the sites with the highest savings to find opportunities for code rewriting that could save space. Our experience shows that in many cases simple code rewriting leads to actual space savings and in some cases also to improvements in program runtime.</p><p>Experimental results using the tool and manually rewriting code show average space savings of 18% for the SPECjvm98 benchmark suite. Results for other benchmarks are also promising. We have also classified the program transformations that we have used and argue that in many cases improvements can be achieved by an optimizing compiler.</p>", "authors": [{"name": "Ran Shaham", "author_profile_id": "81100105142", "affiliation": "Tel-Aviv University and IBM Haifa Research Laboratory", "person_id": "PP31027338", "email_address": "", "orcid_id": ""}, {"name": "Elliot K. Kolodner", "author_profile_id": "81100522094", "affiliation": "IBM Haifa Research Laboratory", "person_id": "PP14181233", "email_address": "", "orcid_id": ""}, {"name": "Mooly Sagiv", "author_profile_id": "81100150928", "affiliation": "Tel-Aviv University", "person_id": "PP39029858", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/378795.378820", "year": "2001", "article_id": "378820", "conference": "PLDI", "title": "Heap profiling for space-efficient Java", "url": "http://dl.acm.org/citation.cfm?id=378820"}