{"article_publication_date": "05-01-2001", "fulltext": "\n Demand-Driven Pointer Analysis Nevin Heintze Oiivier Tardieu Research, Agere Systems Ecole Des Mines, \nParis (formerly Lucent Technologies' Microelectronics Division) olivier. 1~ardieu~mines. org nch&#38;#169;agere, \ntom  ABSTRACT Known algorithms for pointer analysis are \"global\" in the sense that they perform an exhaustive \nanalysis of a pro-gram or program component. In this paper we introduce a demand-driven approach for \npointer analysis. Specifically, we describe a demand-driven flow-insensitive, subset-based, context-insensitive \npoints-to analysis. Given a list of pointer variables (a query), our analysis performs just enough com- \nputation to determine the points-to sets for these query vari- ables. Using deductive reachability formulations \nof both the exhaustive and the demand-driven analyses, we prove that our algorithm is correct. We also \nshow that our analysis is optimal in the sense that it does not do more work than necessary. We illustrate \nthe feasibility and efficiency of our analysis with an implementation of demand-driven points-to analysis \nfor computing the call-graphs of C programs with function pointers. The performance of our system varies \nsubstantially across benchmarks -the main factor is how much of the points-to graph must be computed \nto deter- mine the call-graph. For some benchmarks, only a small part of the points-to graph is needed \n(e.g povray, emacs and gcc), and here we see more than a 10x speedup. For other benchmarks (e.g. burlap \nand gimp), we need to compute most (> 95%) of the points-to graph, and here the demand- driven algorithm \nis considerably slower, because using the demand-driven algorithm is a slow method of computing the full \npoints-to graph. 1. INTRODUCTION 1.1 Pointer analyses In programming languages like C, pointers introduce \nalias- ing: different data access paths may denote the same run- time location [1]. While aliasing is \nvery convenient for rep- resenting sharing and cycles in complex datastructures, it interferes with data-flow \nanalysis and program optimiza- tion. To address this problem, many program analyses have been developed \nthat compute the sets of variables to which a pointer may point; these sets are called points4o sets \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advan-tage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior specific permission and/or a fee. PLDI \n2001 6/01 Snowbird, Utah, USA &#38;#169; .2001 ACM ISBN 1-58113-414-2/01/06...$5.00 [2]. Such analyses \nare said to perform may-alias analysis of pointers [1] or simply pointer analysis. Recent work on pointer \nanalysis has focused on efficiency [3, 4, 5], tradeoffs between efficiency and accuracy (e.g. the choice \nof a subset-based [6] or unification-based [7] analysis [8, 9]) or on the cost and benefits of context-sensitivity \nand polymorphism [10, 11]. Techniques for incremental analy- ses have been proposed, so that small modifications \nof the source code require only small recomputation [9, 15]. Al- though these methods can reduce the \ncost of typical end-to- end applications of pointer analyses, in the end they perform an exhaustive analysis \ni.e. they compute the points-to sets for the entire program considered, and cannot utilize a given query \nto limit the computation. In this paper we consider the use of demand-driven tech- niques to reduce the \neffective cost of points-to analysis. It is natural to ask: why do we need demand-driven points- to analysis \n-aren't the current points-to systems already fast enough? For example, unification based systems with \nprecision enhancements can perform exhaustive analyses ot multi-million lines in about a minute or two \n[9], and subset- based analyses can perform exhaustive analyses of about a million lines in a few seconds \n[16]. One answer is that any improvement in speed (and especially space) is welcome - points-to analysis \nis still too slow and takes too much space for many applications. Another issue is that the fast points-to \nanalysis systems implemented tc date have all required substantial implementation effort with innovative \ntechniques and/or sophisticated data-structures. One promise of the demand-driven approach is that we \ncan build small light-weight points-to analyses systems from sim- ple, maintainable, easy-to-implement \n(or borrow) building blocks, and yet obtain satisfactory performance and accu-racy on large programs. \nOur view is that the most important applications of demand- driven points-to analysis are in the development \nof context. sensitive points-to analysis. We see demand-driven points. to analysis as an important building \nblock for constructing efficient, accurate, context-sensitive points-to analysis fol multi-million line \nprograms. It is well known that aggressive duplication of contexts can lead to prohibitive performance \ndegradation for a context-sensitive analysis. By restricting attention to contexts that are relevant \nto a particular query a demand-driven analysis could potentially support muc~ more aggressive context-duplication \n(and flow-duplication) policies e.g. beyond the polymorphic points-to analysis con- sidered in [11]. \nMoreover, we expect that aggressive context- duplication will improve the query-independence of the points- \nto graph, and that degenerate behavior, where one query requires computation of the entire points-to \ngraph, will be much less likely. As a first step towards demand-driven points-to analysis, we shall restrict \nour attention in this paper to context-insensitive, flow-insensitive, Andersen-style points-to anal- \nysis. To simplify our presentation, we start with a mini-real subset of C. In this setting, points-to \nanalysis can be described by a simple set of deduction rules that define a points-to relation. Each statement \nof the program is trans- lated into either a fact or a deduction rule. Figure 1 gives a program and the \ncorresponding deduction system. Using this system, we can derive \"p may point to x\" from fact (1) and \nrule (2). We present this analysis in more details in Section 2. 1.2 Demand-driven analyses A demand-driven \nalgorithm is an algorithm that is struc- tured around answering queries. The central design criteria \nof such algorithms is: perform only computation that con-tributes to answering the given query. By eliminating \nunnec- essary computation (w.r.t. a given query), significant time and space savings can be achieved. \nThe use of demand- driven techniques for program analysis was introduced by [12]. Many analysis applications \ncan be very naturally for- mulated around the notion of queries -typically we do not require all information \nabout all program pieces, but instead we only need some portion of it. For example, building the call \ngraph of a C program only requires the points-to sets of function pointer variables, a small subset of \nthe set of pointer variables. [12] introduces a method for the construction of precise demand-driven \nalgorithms for a class of dataltow analyses. As an application of their method, they introduce a demand- \ndriven analysis for copy constant propagation. Their query language consists of a fact and a program \npoint. For ex- ample, if line 42 of a program contained the assignment x = exp, then we might ask the \nquery \"is x the constant 5 immediately after line 42?\". The algorithm would reply true if exp was the \nconstant 5. It would reply false if exp was a constant other than 5. If exp was the variable y, then \nit would recursively call itself on the query \"is y the constant 5 immediately before line 427\". In the \ncase of copy constant propagation, the answer to any query is either trivial (can be obtained by just \nlooking at the current instruction) or else there is an equivalent query if we go one ~ step backward \nin the execution of the program. Thus, it is possible to check the truth value of a given query by executing \nthe program in \"reverse mode\". 1.3 Demand-driven pointer analyses Consider Figure 1 and the query \"what \nmay p point to?\". A demand-driven analysis might proceed as follows: (1) to determine what p points to, \nwe process the assignment p=q and initiate a new query \"what may q point to?\"; (2) to find what q points \nto, we process q=~x and determine that q may point may to x; (3) returning to \"what may p point to?\", \nwe re-process p=q and determine that since q may point to x, p may point to x. Note that we have not \nconsidered the assignment r=~x, which is irrelevant to the query at hand. The purpose of this work is \nto study the feasibility of a demand-driven pointer analysis -too see if it is possible and if it is \npractical. To the best of our knowledge nei- ther has been done before, and moreover, this problem ap- \npears to fall outside the scope of [12]. The generic con-struction described in [12] is restricted to \ncertain classes of interprocedural data-flow problems. Quoting from [12]: \"If the problem's flow functions \nare distributive, the derived demand algorithms provide as precise information as the corresponding exhaustive \nanalysis.\" In other words, if the flow functions are not distributive, the demand-driven anal- ysis might \nreturn results that are less accurate than the ex- haustive analysis. Again quoting from [12]: \"Copy \nconstant propagation is a distributive version of the non-distributive constant propagation analysis \nwith expression evaluation.\" Thus, the method cannot handle general constant propa-gation. Concretely \nsuppose that line 42 of a program is z = x + y, and we have the query \"is z the constant 5 after line \n42\". This query cannot be expressed using con- junctions of independent queries about x and y immediately \nbefore line 42. Pointer analysis is even more problematic. Suppose that line 43 contains the assignment \n*u = *v. The query \"p may point to x after line 43\" is equivalent to the disjunction of queries \"p may \npoint to x before line 43\" or \"u may point to p and there exists a variable t such that v may point to \nt and t may point to x, before line 43\". As we try to backtrack in the execution of a program, the queries \nwe have to deal with become more and more complex. In contrast, in a copy constant propagation analysis, \nthey can be expressed in a very simple manner. The kind of reason- ing by equivalences implicit in the \napproach of [12] is clearly inadequate for addressing problems such as general constant propagation or \npointer analysis. Our approach is different, and is not based on equivalences of queries before and after \nstatements. Instead, we separate the notion of query and answer: in our setting a query can have the \nform \"what may x point to?\" and answers have the form \"x may point to y\". Central to our work is a complete \nredesign of the deduction rules for aliasing analysis in which conditions are added to the rules to ensure \nthat we always derive something that is relevant to the pending query. We also add deduction rules to \nintroduce new queries, as illustrated in Figure 2. We remark that this example is a very trivial one. \nAs we shall see when we present our analysis in Section 3, we must enrich the query language to add queries \nof the form \"which variable may point to x?\". This is essential for obtaining a true demand-driven analysis, \nand for our optimality results. In Section 4 we show that our analysis is equivalent to the exhaustive \nanalysis in the following sense: the results it com- putes for a query are exactly what an exhaustive \nanalysis would compute for that query. In Section 5 we establish an optimality result: the answer to \na query depends on all program components processed by our demand-driven algo- rithm in the sense that \nif one of the processed components were to change, it could potentially change the results of the query. \nThe remainder of the paper addresses practicality: int x, *p, *q, *r; Rules: q = ~x; (1) q may point \nto x. p = q; (2) For any variable v, if q may point to v then p may point to v. r = ~x; (3) r may point \nto x. Figure 1: Rules for an exhaustive pointer analysis. \u00b1nt x, *p, *q, *r; Some rules (incomplete \nlist): q = ~x; If we want to know what q may point to then q may point to x. If we want to knnow what \np may point to, then we need to know what q may point to. p = q;  If we want to know what p may point \nto, for any variable v, if q may point to v then p may point to v. r = ~x; If we want to know what r \nmay point to then r may point to x. Figure 2: l:tules for a demand-drlven pointer analysis. what is the \noverhead of the demand-driven algorithm, and can the demand-driven algorithm result in significant anal- \nysis savings e.g. can we answer interesting queries without inspecting the entire program. To this end, \nwe have designed and implemented two demand-driven call-graph analyses for C (described in Section 6). \nWe present benchmark results in Section 7. 2. ANDERSEN'S POINTER ANALYSIS To simplify our presentation, \nwe consider a tiny language consisting of primitive assignments involving just the oper- ations * and \n~z. (We note that nested uses of * and &#38; or statements such as *x=*y can be reduced using temporary \nvariables. ) A programs is a finite set of assignments A: A ::---x=y I *x=y I x=*y [ x=g~y We use a, \nb, ..., x, y, z to denote program variables; p and q are typically pointer variables. We write var(P) \nto denote the set of variables in P. Our representation of programs ignores control constructs and statement \norder. To define context-insensitive flow-insensitive aliasing analysis, we con- struct deduction rules \nfrom a program as specified in Figure 3. The binary relation \u00a2--+. has domain var(P) x var(P). Intuitively, \nx ~ y means that x may point to y during an execution of P. In the first rule, the side condition \"if \nx=ky in P\" indicates that there is an instance of this rule for each occurrence of an assignment of the \nform x=ky in P. The side conditions in the other rules are similarly interpreted. The last rule deals \nwith assignments of the form *x=y. It states that for any z and u, if \"x may point to z\" and \"y may point \nto u\" then \"z may point to u'. The pointer analysis can now be defined as: x may point to y if we can \nderive x '-+ y. The exhaustive analysis computation proceeds by finding all of the points-to relations \nthat can be derived from the deduction rules. 3. DEMAND-DRIVEN ANALYSIS In exhaustive pointer analysis, \nwe compute the points-to sets of all program variables. To define a demand-driven pointer analysis, we \nmust first establish the query language. In this paper we use queries of the form \"what may p point to?\". \nAn alternative might be to use queries of the form \"may p point to x?', however this appears to be less \nuseful for compiler or software engineering applications. 3.1 A First Attempt As we have seen in Figure \n2, answering a query such a \"what may p point to?\" can necessitate answering anothe query \"what may q \npoint to?\". More generally, just a points-to relations are accumulated during the exhaustiv pointer analysis, \nthe demand-driven analysis accumulate both points-to relations and queries. We shall write p~--+ for \n\"what may p point to?\", and any points-to relation \u00a2 the form p ~ z is called an answer for p ~---+ \n(we sometime say p~--~z answers pc_.+. ). Figure 4 presents a first attemp at adding queries to the deduction \nrules for pointer analysi~ quantifiers axe implicit. Consider the rule corresponding t the assigmnent \nx=g~y. This rule says if we have the quer: \"what may x point to?\", then we may derive \"x may poin to \ny\". Given one or more initial queries, demand-driven computs tion proceeds by finding all points-to relations \n(and queries that can be derived from the deduction rules and the initie queries. For the example of \nFigure 2 with the initial quer: p~-+-, we derive p ~ x, q \u00a2-4 x, p~-+. and q\u00a2-+.. This in cludes an additional \nquery (\"what may q point to?\") an, the points-to information for p and q. Importantly, noth ing is derived \nabout r. Thus, this new set of rules produce a strictly better result than the exhaustive analysis, in \nth sense that less points-to relations are derived. However, a fundamental inefficiency arises with these \nsimpl rules. Consider the rules corresponding to *x=y, and sup pose we have the query \"what may z point \nto ?'. Now, i x may point to z and y may point to u, then z may poin to u. The problem is that in order \nto determine whethe x points to z, we have to initiate the query \"what may point to?\" (this reasoning \nstep is capture by rule (,)). Non computing the points-to set for x is much more than we ac tually require \n-in this case we just need to know whethe z is in the points-to set for x. This kind of reasoning cm \nlead to useless computation, as illustrated by Figure 5. Il this example, the query \"what may p point \nto?\" leads t, the points-to relation \"w may point to r\" which is irrelevan to the initial query. In contrast \n\"w may point to p\" and \"~ may point to x\" are relevant results for the query - withou them the analysis \nis not correct. We present a formalizatio~ of the notion of \"relevant\" when we discuss optimality i~ \nSection 5. x ~ y if x=~y in P. In this example... int x, *p, *q, *r; y~-+zVZ, if x=y in P. q = &#38;x; \nxc-+z p = q; y'--+z z,-.--~u r = ~x; Vz, Yu, x ~ u if x=*y in P. ...there axe three rules: Vz, Vu, x,--+z \ny~----~u if *x=y in P . . . . z,..-.-~u q~-.~x ; Vz, q'----~z p~.--~z ' r~.....~x Figure 3: Deduction \nrules for Andersen's pointer analysis. x~..-~. if x=g~y in P. x'-+y y~. x~. x~z z~. y ~ z x ~. if x=*y \nin P. ~: if *x=y in P. y~.+. / / if x=y in P. y~z z~u x~. x~z y~u z~. y~--+z x\u00a2.-.~ x~u z~u x\u00a2--+z \n Figure 4: Deduction rules for a partial demand-driven pointer analysis. 3.2 Fully demand-driven analysis \nTo avoid the inefficiencies discussed in the last section, we introduce a new kind of query of the form \n\"what variables may point to p?\", denoted .,---~p. Any points-to relation of form z ,-~p is an answer \nfor p,--+.. Now, when we have a query \"what may p point to?\", we generate the query \"what variables may \npoint top?\". Then, if we find that x may point to p, and there is an assignment of the form *x=y, then \nwe generate the query \"what may y point to?\", and use results from that query to update the points-to \nrelation for p. The full rules are detailed in Figure 6. The main changes axe the addition of the rule \n(+) and rules to answer queries of the form \u00a2--+p. There axe now 15 rules, and no facts -i.e. every \nrule has a hypothesis. In other words, these rules axe \"fully demar~d-driven'. Returning to the example \nfrom Figure 5, we show two derivat, ions using the fully demand-driven rules in Figure 7. The first derivation \nshows how, given the query \"what can p point to\" (p,--+-), we can derive that p ~ x. The second derivation \nshows how, given the query \"what variables may point to x\" (.,--~x), we can derive that r,---.~x: We \ncan also derive that p'-+x and q,--~x from ,--+z; these are not shown in Figure 7. 4. EQUIVALENCE The \nresults that we establish in this section and the next are for a single initial query; however they can \nbe easily adapted to deal with multiple queries in a single computa- tion. We first prove that the demand-driven \npointer analysis is equivalent to the exhaustive pointer analysis. Specifically, we will show (a) when \ngiven the query x,----~., the demand- driven analysis computes x ,-~ y iff the exhaustive analysis computes \nx '--+ y, and (b) when given the query .~--+x, the demand-driven analysis computes x ~ y iff the exhaustive \nanalysis computes x ~ y. We use t-\u00a2~(p) x ~ y to denote that x ~ y can be derived from the set of rules \nassociated with the program P in the exhaustive framework. We use Q I-d(p) x ~ y to denote when x ~ y \ncan be derived from the query Q using the set of rules associated with the program P in the demand-driven \nframework. We write t-~ and F-,~ when the program P is clear from context. ~If a'-+ ba x'-+y then I-~ \nx~-.-~y LEMMA 1. [If .\u00a2-...}a ~d Xc'-'4\"Y then t-'e~ x'---~y Proof: We proceed by induction on the proof \nof Q t-d X ~ y where Q is either a'-+. or .'--~a. The last used rule can be one of the eight rules that \nadd a new points-to relation. Each of these rules reduces to a rule of the exhaustive anedysis with less \nhypotheses, as described in Figure 8. Let's suppose Q t'-d y,---.~x is derived using the rule z\u00a2---~.~ \nu'..-~.y .\u00a2-+y ~ *z=u. In this case we know Q t-d z ~ X and Q t-a u ~ y. By the induction hypothesis \nwe have t--e~ z ~-+ x and t'-e~ u ~ y. We can apply the rule ~ ~Y*z=u of the exhaustive framework, and \nconclude that ~e~ x ~ y. Other cases are similar. If b~ x,--~y then x~----~ kd X'.-~y LEMMA 2. If I\"ex \nx ~ y then ~ y I-d X ~ y  Proof: We proceed by induction on the proof of t-e~ x \u00a2--~y. Depending on \nthe last rule involved in this proof, we split the problem in four cases. In each case we have to prove \nboth parts of the lemma. We show one of these proofs here. The complete proof can be found in Appendix \nA. If the last rule used is z ~ x u ~ y,z=u, x,-.+y let's prove that x,--~, t--~ x,-+y. 27 Query: p~-~. \nq = ~x; Derived: p,-+. ,we-+ , w'-+ p, wc-+ r, q\"+ , q'-+ x,p~-+ x w = ~p; Points-to relations derived: \nw ~-+ p, w '-+ r, q ~ x, p ~ x W = &#38;r; *w = q; Optimal demand-driven analysis: w ~-+ p, q ~ x, p \n'-+ x Figure 5: Inefficiency of the partial demand-driven framework. (+) x~\" y~. .~x x~y '~y y~z x~\" \n.~X Z~\" if x=*y in P. y~z Z~U X~\" x~u x~. ] y~z z~u .~u x ~ y .~y x~y f if x=~y in P. x ~ u x~z z~\" y~\" \n y~. x~z y~u z~\" z~u if *x=y in P. y~z x~\" ifx=y in P. y~u .~u x~z y~z .~z x~z y~u .~u x~z Zc....~.U \n Figure 6: Deduction rules for the demand-driven pointer analysis. pc.....+. int x, *p, q = ~x; w = &#38;p; \nw = &#38;r; *w = q; *q, *r, **w; ~-+P w=~p wc-+p p,_+. q'-+\" qc-+ x .~.-.+x --q=&#38;x q ,-+ x . ~-+ \nx ~U\u00a2--~. wc.->r *wfq q=~x pc--~x *wfq w=~r rc...~ x pc..+. \"~-+ p wf~pw'-+ p ~ X q~ x ^P'~='x P ~\"'~\" \n*w=q .~ *Wffiq Figure 7: Two derivations. x\u00a2-+. xf~y --+ x=~y z~--+u u~--.~y x,--.> z,.-+u uc-+yx=,z \nx\"+Y xc-+Y xc--~Y x=*z ---+ x~-+Y \"\u00a2\"+Yx=~y ~ x=~y zc-+u uc--~y \"\u00a2-+Yx=*z ~ z'---~u u'-+yx=,z x~--+y \nx,-+y x~-+y x,-+y zc..-+y x,..-+, zc-.+x u'---~y x \u00a2'-+\" zc'--~x x=z ---+ zc'+Yxfz *zfu ) u~'+Y*zfu xc-+y \nx'-+y x'-+y x\u00a2--+y zc-+y .'---~yx= z __4 z~-+Yx= z z\u00a2---~x uc-+y .c--.+y,zfu > z'-+x u\u00a2-.--~y,zfu x~--~y \nx,-+y x~-+y xc--~Y Figure 8: Reduction of the rules of the demand-driven analysis to rules of the exhaustive \nanalysis. x ~--+. bd ~ x is derived using rule ~\" ~ x ~-d Z ~ X by induction since t--e, z ~ x. x,---~. \n~-d Z'-+X. x'-+-}-a U'--~. using rule z~, ,~. *Z=ll u ~...~. u'--~\" ~-d u'--~y by induction since ~-~, \nu'->y. x'---~. ~-d U'-+ y. X\u00a2-+ ~d X'--+y using rule z~ u~u ~:*z=u. x'--~.y B Combining Lemmas 1 and \n2 proves: i#z~. ~d THEOREM 1. [}-e~ X\"-'~y iff \"'--ty F-d X\"-~y 5. OPTIMALITY We first show optimality \nw.r.t, answers: the demand-driven analysis computes a points-to relation only if that relation is an \nanswer to some query (initial or derived). if a,-+. bd ~ Y then either a,---t, f-d X'---->. or a'---~\" \n}-d '--~Y LEMMA 3. If ,--+a }-d x'--ty then either  \"--+a }-d X'-+. or .,----~a bd .'-+y  This lemma \nis immediate from Figure 8, which shows that for each of the eight rules with conclusion x ~ y, either \nx,---~ or ~ y appears as a hypothesis. Intuitively, it proves that the demand-driven analysis computes \nat most the answers to all initial and derived queries This is dual to Theorem 1, which states that the \nanalysis computes at least the answers to all initial and intermediate queries; hence, the analysis computes \nexactly the answers to all queries Lemma 3 effectively proves that the demand-driven analysis is optimal \nprovided that the set of queries generated during the analysis is optimal But what does it mean for the \nset of derived queries to be optimal? Intuitively, we want to show is that answers to the derived queries \nare needed to correctly answer the initial query. We first discuss queries of the form q,--+.. Consider \nFigure 9 (for brevity, we omit ,-+p and ~----~ q in the derived queries) In the first example, the \nderived query q'---+ is clearly neces- sary to answer p ~-->., since we need to look at assignments \nto q in order to discover that q '---+ x and therefore that p ~ x. However, in the second example the \nusefulness of q'-+- is less clear, since the points-to set for q is empty, and so the query q,--->- does \nnot in fact contribute to answers for p,-4.. Of course, there is no way to know this in advanace. To \ncorrectly answer p,->., we must look for answers to q,--~. i.e. we have to inspect those parts of the \nprogram that are relevant to q'--~., such as assignments q = ~x. More gen- erally, the set of derived \nqueries can be viewed as a slice (a subset) of a program This slice represents the parts of P that the \ndemand-driven algorithm inspects as it tries to answer Q. As we have illustrated, we sometimes inspect \na part of the program only to find that in the end it does not contribute to the initial query Intuitively, \nif we could not have predicted this outcome until we actually inspected that part of the program, then \nsuch an inspection was necessary to obtain correct results. In the third example in Figure 9, the usefulness \nof the query q'-+. is again unclear, since the answers to q~-->, do not lead to new answers for p,-->-. \nHowever, suppose that assign-meats q=&#38;u and w=&#38;x were added to the program. These additions generate \np ~ x, a new answer to p'-~.. Hence q,-+. is indeed needed, because it is this query that prompts us \nto look for potential assignments to q, and without look- ing for such assignments, we might miss answers \nfor p,--+.. We formalize these intuitions using ideas borrowed from pro- gram slicing. In program slicing, \nthe value of a program variable is said to depend on some program component if changing that component \ncould change the variable's value. Similarly, we shall define that a query Q is relevant to query I for \nprogram P if extending the program at Q (i.e. adding assignments that change Q) can change the answers \nto p.1 It remains to define what we mean by \"extending the pro- gram at Q\". As the third example in \nFigure 9 shows, for a query like q,--~., we might need to add more than one assignment to affect a change \nto the answers for I. Clearly, these assign- ments cannot be arbitrary: they must at least change the \nanswers to the intermediate query. However, even more re- strictions are needed. For example, let P be \nthe program {p = &#38;x}, let I be pc--+, and Q be q,-4.. Now, consider extending the program with assignments \nq=~p, p=~r. This changes the answers to both Q and I, and yet Q is not needed to correctly answer I. \nThe main problem in this ex- ample is the assignment p=~r, which directly modifies the points-to set \nof p, effectively bypassing the query q,-4-. To avoid this problem, we require that program extensions \nmust use new variables (in addition to the variable in Q). Recall that a points-to relation x ,-t y answers \nx'-+. and ~ y. Now, given a program P, initial query I and a derived query Q of the form q,---~., define \nthat Q is relevant 2 to I if there exists a program extension PQ such that (i) PQ contains only the variable \nq and new variables, (ii) q only appears in assignments of form q .... , and (iii) there is a points-to \nrelation that answers I and is derivable from P U PQ but not from P alone. Condition (ii) is key: it \nsays that the only direct change we can make to P using PQ is to change what q can point to; we cannot \ndirectly change any other component/variable of P. Next, consider queries of the form .,-+ q. Intuitively, \nsuch a query is relevant to initial query I if we can extend the pro- gram in such a way that we change \nthe answers to ~ q, and in the process alter the answers to I. Again, we may need to add more than one \nassignment. For example, consider the program p--*x, initial query p,--+, and derived query '--~x To \nshow that ~ x is relevant to pc_+., we need to construct a program like r=~x, *r=y, y=~z. As before, \n1More generally, we could consider arbitrary changes to P at Q, in- stead of just additions. This change \nwould not alter the notion of optimality obtained; it would however add complexity to the follow- ing \ndefinitions. 2In the definition of relevant, we could add the condition \"there is a points-to relation \nthat answers Q and is derivable from P U PQ but not from P alone\"; this turns out co be redundant 29 \n1: int x, *p, *q; 2: int x, *p, *q; 3: int *p, **q; 4: int x, y, *p; q = gx; r = ~y; /* q = kx; */ P \n= *q; p = q; /* q = ~; */ p = q; q = ~x; /* ~ = ~x; */ p = q; Query: p,--+. Query: p~-+. Query: p'-~. \nQuery: p,-+. Derived: ~p ~--+., q \u00a2_~., ~'~ Derived: ~p ~__+. Why? Derived: ~p~_+., q~_+., [ qc-+ x, \np~-+ x Derived: p'-+ . , q\u00a2-+ . [ q\u00a2-+ . [ q~-+ x, p~-+ x Figure 9: Ambiguity of the notion of optimality \nfor queries. we must constrain program extensions to use only new vari- ables (in addition to the variable \nin the query). Given a program P, initial query I and a derived query Q of the form ~ q, define that \nQ is relevant to I if there exists a program extension PQ such that (i) PQ contains only the variable \nq and new variables, (ii) q only appears in assignments of form .... &#38;q, and (iii) there is a points-to \nrelation that answers I and is derivable from P U PQ but not from P along. Again condition (ii) is key: \nit says that the only direct change we can make to P using PQ is to change what vari- ables point to \nq; we cannot directly change any other com- ponent/variable of P. We now define that a demand-driven \nanalysis is optimal if it only generates relevant queries i.e. for all programs P, all queries derivable \nfrom an initial query I are relevant to I. THEOREM 2. I-d(p) is optimal: for all initial queries I and \nprograms P~ if I ~d(p) Q then Q is relevant to I. The proof of this result appears in Appendix B. The \nbasic strategy is as follows: for each program P, initial query I and intermediate query Q generated, \nwe inductively construct a program extension PQ that extends P at Q. We note that the proof in Appendix \nB in fact uses a strengthened induction hypothesis c.f. the statement of Theorem 2. Returning to the \nprograms in Figure 9, when we apply the construction to program two with the query q~-+., we would build \nan extension of the form q=&#38;x. Applying the con-struction to program three with the query q\u00a2--+, \nwould yield q=~w, w=kx. Finally, consider the fourth program. Clearly the query r~----~- is not needed \nto compute p~--+., and the demand-driven algorithm ignores the assignment to r. It is easy to check that \nre-+ is not relevant to pc_+. according to the above definitions. However, suppose that we were to weaken \nthe notion of program extension used to define op- timality, and admit an extension that adds the assignment \np=r to the fourth program. Then, according to this mod- ified definition, the query r,--~-would in fact \nbe relevant to the initial query p~---~.. This shows why the restrictions on program extension are important. \nIn particular, if we attempt to simplify the definition of optimality and admit arbitrary program extensions, \nthen, in essence, all queries become relevant and the definition of optimality becomes meaningless. We \nremark that an earlier draft of this paper attempted to simplify the definition of optimality in exactly \nthis (erroneous) way. 6. APPLICATION We apply our demand-driven analysis to the problem of com- puting \nthe call graph of a C program: our implementation computes a safe approximation of the possible functions \nthat may be called from each call-site in a program. In the ab- sence of function pointers, this is trivial \nto compute. How-ever with function pointers we must perform may-alias anal- ysis of the program in order \nto obtain a safe approximation of the program's runtime behavior. One approach is to per- form a full \npointer analysis of the program, but this can be expensive. Alternatively, we may try to handle the common \ncases such as the use of callback functions as parameters o[ function calls. Although they are cheaper \nto run, such cus- tom analyses are easy to break. For example, what if the callback function is a member \nof a structure? A \"one-level\" pointer analysis would crash on the following piece of code (excerpted \nfrom povray): int Iteration_HCompl (VECTOR, FRACTAL *); \u00b0..  void SetUp_FractaI(FRACTAL *Fractal) { \n... Fractal->Itera~ion_Method = Iteration_HCompl; ... }  Our approach is to use demand-driven pointer \nanalysis. The rationale for this approach is that in a typical program there axe relatively few function \npointers, compared to many multi-purpose pointers. Thus the call graph problem ap- pears likely to benefit \nfrom a demand-driven approach. 6.1 Implementation The starting point of our implementation is an already \nex- isting system described in [15, 16]. This system implements an exhaustive pointer analysis for C \nprograms. It consists of three components. The first component is a compiler which translates each module \nof a preprocessed C code into an \"object file\", which is a highly indexed database of state- ments of \nthe kind we defined in Section 2. It is written in SML using the CKit frontend [13]. The second compo- \nnent is a linker that combines the databases into a single object file. The third component reads this \nobject file and performs pointer analysis. Both the linker and analyzer axe implemented in C. This architecture, \ncalled CLA, as well as the core of the analyzer axe described in more details in [15]. This baseline \nimplementation deals with full C includ- ing structs, unions, arrays and function call/return (includ- \ning indirect calls).. Support for many of these features is based on simple syntactic transformations \nin the compiler part of the system. Structs/unions axe handled in a field- based manner (we generate \na new variable for each field of a struct definition, and then map each access of that field to the variable), \narrays are handled in an index-independent manner (we essentially ignore the index component of sub expressions), \nfunctions are handled by introducing standard-ized naming conventions for function arguments and returns, \nwhich are linked together by the linker, and indirect function calls are handled by using the same naming \nconvention, but the linking happens during analysis as function pointers are discovered -see [15, 16] \nfor further details on the treatment of structs and functions. In order to implement our call graph analysis \nwe reuse the compiler, the linker and many modules of the analyzer, espe-cially the set implementation \nused to build the sets of points-to relations during the analysis. The main modification to the base \ninfrastructure is that we add some additional infor-mation about call-sites and function pointers to \nthe object files. In summary, the object files contain information about variables (we consider functions \nas variables), assignments (x=g~y,*x=y...), function pointers, call-sites (A calls B where A is a function \nand B a function or a function pointer), as well as various indexes to navigate through these object \nfiles. The call graph analyzer proceeds as follows: it computes the demand-driven pointer analysis of \nthe input program where the queries are all call-sites that are not known functions. In essence, if we \nhave a call *x(el,... , en), then we will add the initial query x ~----~-. 6.2 Exhaustive algorithm \nFigure 10 describes a basic algorithm for our baseline ex-haustive analysis implementation [16]. We use \nX to denote the points-to set for the program variable x (and similarly Y for y etc.). The exhaustive \nalgorithm has two phases. In the first phase, the static phase, we initialize the points-to graph by \nloading all primitive points-to relations (i.e. rela-tions such as x ~ y corresponding to a program assignment \nx=&#38;y). In the second phase, called the dynamic phase, we iteratively build the closure of this graph \nunder the deriva-tion rules associated with the assignments of the program. This central component of \nthis system is a very efficient im-plementation of sets. In addition, the CLA architecture is used to \nload the object file on demand and reduce space utilization. 6.3 Demand-driven algorithm Given a program \nand a collection of queries, our aim is to find an efficient way to compute the queries and points-to \nrelations that are derivable from the rules presented in Fig-ure 6. To this end, we observe that the \nrules ~' and ~ '~ are independent of any particular assignment. . t...9 ~ Thus, we can merge them into \nthe other rules. As a result, we obtain the modified rules in Figure 11. These modified rules axe equivalent \nto the rules in Figure 6 if we assume the following property about the initial queries: if x~--~ is an \ninitial query, then so is ~ x. In other words, the input queries must be closed under the (+) rule. During \nthe demand-driven algorithm, a program variable v can be in one of three states: (1) We have queries \nv~--+, and .'--+v. (2) We just have the query .,--+v. (3) There is currently no query about v.  I \nLOC [Program Primitive Non-triv (preproc) i Variables Assignments Call-sites nethack 44.1K 3856 10402 \n11 burlap 74.6K i 6859 19022 15 vortex 170.3K 11395 34126 15 emacs 93.5K 12587 36603 103 povray 175.5K \n12570 40280 108 gcc 199.8K 18749 69715 138 gimp 7486.7K 131552 344156 5964 Table 1: Benchmarks. We \nuse X' to denote {v : v E X and .,--+v} i.e. the \"tracked\" variables in X. Using this notation, the algorithm \nfor demand-driven pointer analysis is described on Figure 12. We remark that the property X I C X is \nimplicit in the algorithm. We refer to this algorithm as the two-set algorithm, since it keeps two sets \nX and X' for a program variable x. We also define an algorithm that is potentially more efficient than \nthe two-set algorithm, but sacrifices optimality. This algorithm maintains just one set per variable, \nand so we call it the one-set algorithm. In other words, whereas the two-set algorithms maintain two \nsets X and X' corresponding to variable x, the one-set algorithm only maintains X. Thus, during execution, \nwe may have to rebuild X' from X, which in principle is an expensive operation. The one-set algo-rithm \nreduces this cost by using X in place of X' whenever using X ~would require nested iterations over sets. \nThe one-set algorithm is strictly less demand-driven that the two-set , algorithm. Let E, D2 and D1 be \nrespectively the points-to relation (i.e. a set of elements of the form x ~ y) computed by the exhaustive \nalgorithm, the two-set algorithm and one-set algorithm respectively. These sets are related as follows: \nD2 C D1 C E. In other words, D1 provides an exact an-swer to the query but manipulates a potentially \nlarger set of points-to relations than D2. We shall see that in most cases D1 and D2 differ little in \nsize. 7. RESULTS We compare the three algorithms -the exhaustive algo-rithm, the two-set algorithm and \nthe one-set algorithm -on the problem of computing the possible functions that may be called from each \ncall-site. The benchmarks we use are described in Table 1. The first six benchmarks were obtained from \nthe authors of [4], the last one by the au-thors of [5]. The columns report the number of lines of preprocessed \ncode, the number of program variables (ex-cluding temporary variables introduced when mapping C code \ninto primitive assignments), the number of primitive assignments, and the number of non-trivial call-sites \nrespec-tively. A call-site is non-trivial if it doesn't involve a call to a known function. Introducing \nfresh variables as necessary, we transform each non-trivial call-site into an expression of form *x(el,... \nmen), and generate the initial query x'--+.. Each benchmark is run with the entire set of initial queries \nfor that benchmark i.e. we run the analysis on all initial queries at once. Table 2 summarizes our results, \nobtained using a single pro-cessor of an 8 processor 250MHz MIPS R10000 machine with 4GB of memory. For \neach algorithm and each benchmark, 31 For each assignment of the form x=&#38;y insert y in X (we note \nX for the points-to set of x). Repeat: for each assignment of the form x=y insert the elements of Y \nin X. for each assignment of the form *x=y, for each variable v in X, insert the elements of Y in V. \nfor each assignment of the form x=*y, tbr each variable v in Y, insert the elements of V in X. Until \na no change. Figure 10: Algorithm for the exhaustive pointer analysis. x~y y~. .~y if x=~y in P. \"~Y \ny~z x~. ifx=yinP. x~y .~x x~z y~z .~z x~z .~x x~. x~z z~. y~. .~y y~. .by y~z x~. x~z y~u z~. z~u z \n~. \"~ z if x=*y in P. if *x=y in P. y~z z~u x~. y~u .~u y~z z~u .~u x~z y~u .~u x~u .~x z~u .~z Figure \n11: Deduction rules for the demand-driven pointer analysis after inllning. For each query of the form \nx ~---+., add the query ~ x. Repeat: for each x=g~y: if x,----~, then insert y in X. if ~ y then insert \ny in X' and add ,--+ x. for each x=y: if x,-+. then add y,-+., -,--+y. if x'----~, then insert all elements \nof Y in X. if Y' not empty then insert all elements of Y' in X' and add ~ x. for each x=*y: if x,--+, \nthen add y,--+, and .,--~y. if x,--~- then for each z in Y, add z,--+, and .,--+z. if x ~----~ -then \nfor each z in Y, insert all elements of Z in X. for each z in Y', if Z' not empty then insert all elements \nof Z' in X' and add .'---~x. for each *x=y: for each z in X', if z~--~, then y,--+, and .,--~y. for each \nz in X ~, if z \u00a2--~. then insert all elements of Y in Z. if Y~ not empty then add x ~---~- and - ~ x. \nif Y' not empty then for each z in X, insert all elements of Y' in Z' and add .'--+z. Until no change. \nFigure 12: Algorithm for the two-set demand-driven pointer analysis. Exhaustive analysis II One-set \nalgorithm Two-set algorithm count utime I cycles count [ utime cycles count utime cycles nethack 7248 \n0.01s ~ 4.4M 26 I 0.00s 1.9M 26 0.00s 1.9M burlap 201240 0.10s 29.5M 195567 0.60s 231.1M 195297 1.94s \n684.6M vortex 392785 0.24s 74.4M 23 0.01s 5.8M 23 0.01s 5.8M emacs 11232360 1.25s i 396.4M 106 0.01s \n5.4M 106 0.01s 5.4M povray 141541 0.12s 35.9M 61 0.01s 4.5M 61 0.01s 4.5M gcc 123826 0.31s l18.1M 44 \n0.00s 3.7M 44 0.01s 3.7M gimp 15298727 1.83s 485.6M 14715288 23.18s 5038.5M 14707976 69.77s 10591.6M \n Table 2: Results. 32 we report three numbers. The first is the sum of the sizes of the points-to sets \nfor all program objects in the original program (this excludes the points-to sets of temporary vari- \nables introduced during the analysis; we do not include the count of queries generated by the algorithm). \nThe second is the user times as reported by ssusage when our system is compiled using cc -0fast. Since \nthese numbers are very small we report a third number which is the total computed cycles as reported \nby pixie when our system is compiled by cc -03 (we cannot run pixie with cc -0fast compilation). For \nburlap and gimp, the demand-driven analysis turns out to essentially require an analysis of the entire \nprogram. Thus the demand-driven algorithms are much slower than our optimized algorithm and they require \nmore memory (this slow down represents the administrative overheads inher- ent in the demand-driven approach, \nand the fact that the demand-driven analysis is not tuned to perform an exhaus- tive analysis). In the \ncase of 9imp, the exhaustive analysis requires about 12MB, the one-set demand-driven analysis about 20MB \nand the two-set implementation 23MB. In the remaining five cases, we obtain very significant speedups \nranging from 8 to 60, with the exception of the nethack benchmark which is too small to show any major \nimprove- ment. These five benchmarks consume less that 5MB and almost all of this is statically allocated. \nWe note that the two-set algorithm, while more expensive, does not provide a significant improvement \nin the size of the set of answers computed. This has been confirmed by other experiments not reported \nhere. 8. DISCUSSION We have developed a demand-driven technique for context- insensitive, flow-insensitive \nAndersen-style points-to analy- sis, established its correctness, and shown that it is optimal in the \nsense that we take maximum advantage of the ini- tial queries to reduce the work performed by the analysis. \nWe have also implemented this algorithm to understand the administrative overheads of the demand-driven \napproach, and to study variations that trade optimality for simpler demand-driven mechanisms. Our results \nindicate that the administrative overheads of the demand-driven algorithm are substantial -sometimes \nup to a factor of 30 or more, although they can be greatly reduced by trading optimality for overhead. \nIn practice, for the call- graph problem investigated in the paper, we see two kinds of behavior: either \nthe demand-driven approach leads to very substantial reduction in the points-to relations that must be \ncomputed (< 1%), or else the demand-driven approach does not help, and we essentially need to compute \nthe en- tire points-to graph (> 95%). In the former case, we see significant performance advantages; \nin the latter case, since we are essentially computing the entire points-to graph, we see large performance \ndegradation. We conjecture that for many compiler optimization problems, if the demand-driven analysis \ntakes a long time, then we will probably finish up computing most of the the points-to graph, and further, \nthe call-site sets will probably be large and not very useful. This suggests using a strategy of running \nthe demand-driven ap- proach with a time-out mechanism, and if the timeout is reached, assuming worst \ncase information about call-sites (which we argue is what would probably be returned if we'd allowed \nthe analysis to complete). As discussed in Section 1, we see the greatest benefit of demand-driven techniques \nin the development of context- sensitive points-to analysis. In addition, we expect that context-sensitivity \nwill significantly reduce the likelihood of the degenerate behavior of demand-driven analysis we have \njust observed in some benchmarks. Acknowledgements: Thanks to Andreas Podelski and the anonymous referees \nfor their comments, and to Satish Chan- dra and Jeff Foster for access to their respective systems and \nbenchmarks. 9. REFERENCES [1] A. Deutsch, \"Interprocedural May-Alias Analysis for Pointers: Beyond-k \nlimiting\", PLDI 1994. [2] M. Emami, R. Ghiya and L. Hendren, \"Context-Sensitive Interprocedural Points-to \nAnalysis in the Presence of Function Pointers\", PLDI 1994. [3] M. Fahndrich, J. Foster, Z. Su and A. \nAiken, \"Partial Online Cycle Elimination in Inclusion Constraint Graphs\", PLDI 1998. [4] A. Rountev and \nS. Chandra, \"Off-line Variable Substitution for Scaling Points-to Analysis\", PLDI 2000. [5] Z. Su, M. \nFahndrich and A. Aiken, \"Projection Merging: Reducing Redundancies in Inclusion Constraint Graphs\", POPL \n2000. [6] L. Andersen, \"Program Analysis and Specialization for the C Programming Language\", PhD. thesis, \nDIKU, University of Copenhagen, May 1994, DIKU report 94/19. [7] B. Steensgaard, \"Points-to Analysis \nin Almost Linear Time\", POPL 1996. [8] M. Shapiro and S. Horwitz, \"Fast and Accurate Flow-Insensitive \nPoints-To Analysis\", POPL 1997. [9] M. Das, \"Unification-Based Pointer Analysis with Directional Assignments\", \nPLDI 2000. [10] E. Ruf, \"Context-insensitive alias analysis reconsidered\", PLDI 1995. [11] J. Foster, \nM. Fahndrich and A. Aiken, \"Polymorphic versus Monomorphic Flow-insensitive Points-to Analysis for C\", \nSAS 2000. [12] E. Duesterwald, R. Gupta and M. Sofia, \"Demand-driven Computation of Interprocedural Data \nflow\", POPL 1995. [13] S. Chandra, N. Heintze, D. MacQueen, D. Oliva and M. Sift, \"ckit: an extensible \nC frontend in ML\", available as an SML/NJ library. [14] \"Programming Languages -C', ISO/IEC 9899:1990, \nInternation Standard, 1990. [15] N. Heintze, \"Analysis of Large Code Bases: The Compile-Link-Analyze \nModel\", unpublished report, November 1999. [16] N. Heintze, O. Tardieu, \"Ultra-fast Pointer Analysis \nusing CLA: A Million Lines of C Code in a Second\", PLDI 2001 (this volume). Appendix A: Equivalence \nProof If ~ x'-+y then x,--~. ~'d x'---~y We prove Lemma 2: If ~e~ x'---~y then .'-+y ~-d X'-+y The proof \nis by induction on the derivation b~ x ,-+ y. We consider four cases, based on the last rule used in \nthe derivation. 33 Rule x=&#38;y. xc--~y x'---~. - ~d x ~ y is derived using rule ~y~-+\" X--~ y. ' ~ \ny ~-d X ~ y is derived using rule ~-~x=~y. Rule z ~ y x=z. xc-+y x\u00a2-~ I-d z~--+ is derived using rule \n~. x-z. z ~---~. ~d z ~-~ y by induction since ~-e~ z ~ y. x'-+. t-d z---~y. x'-+. t-d xc---~y using \nthe rule z~yXc_~.y~. X =z, ~ y t-d z ~ y is obtained by induction since Fez z ~ y. ~ y Pd x ~ y using \nthe rule z~yx\"'-~y\"~Y x=z. Rule z~--~u u~-~yx=.z\" x~--~y x~---+ t--d z~----~, is derived using rule \n*~'z~.X--*z. z ~--~. t-d z ~ u by induction since t-ex z ~ u. x\u00a2'\"~\" ~-d Zc-+U. X~--+ Fd u'-+. using \nrule ~ ' x=*z. u,-+. bd u\"-~y by induction since be, u~-+y. x\u00a2'~\" ~d u,--~y. x\u00a2--~ t-d x~--+y using \nthe rule ,~u ~ \u00a2._.~.y ,~. u~y X=$Z* \"-+y bd u~----~y is obtained by induction since F~ u~.+y. \"~--~y \n~d \"L+u using rule u,-~y -~y ~ u ~d Z ~-~ U by induction since he~ z ~-~ u. \u00a2-.~y I-- d Z \u00a2c-..~. U. \n '-.--~y t\"d x'--~y using the rule z~ u~y \"~Yx=*z.  wc-..~.y Rule Z~-+x u~-+Y*z=u. xc--~y x ~----~- \n~d ~ x is derived using rule ~\" ~ x Fd z ~ x by induction since ~-e~ z ~ x. X~'-'~\" ~-d Zc\"-'~'X x'---+, \nt-d u'---~, using rule ~ ' *z=u. u'-+. t-d u'--+y by induction since t--~ u'-..~y. x--+. I-d u~--.+y. \nx\"-.~. I-d x'--.~y using the rule z~ u~yx'....+y ~. SZmU ,--4y ~ u,--~y is obtained by induction since \nt--~ u~---~y. -'---~y bd z~--+ - using rule u,-,y \"~Y*z=a z'---~ t'-d z ~ x by induction since ~e~ z \n~ x.  \"-~y I-d z'--~x.  ~---~y Fd x'-~y using the rule z~ u~v .~v  Appendix B: Proof of Optimality \n(Theorem 2) Let P be a program, V be the variables in P, x a variable of P and z a new variable (x ~ \nV, z ~ V). We prove the following induction hypothesis (IH), for all y ~ V: (i) If x'--~- t'-d y'--+- \nthen Su\u00a2 V and a program P~ s.t. x~--+ Fa(pup~u{v=a~}) xc.--~z and VA var(P~) = ~. (ii) If x,-+. t-d \n.,-+ythenSu~VandaprogramQ~s.t. X\u00a2--~ \" ~d(pUQYuU{u=&#38;y}) Xc\"'9\"Z and V n var(Q~) = O  We proceed \nby structural induction on the proof of x \u00a2---~ Fd y\u00a2--4, or x~-+. t-d \"~--~y. There are eight cases: \n1. x _= y: In this case, x~-+ Fd(PU{w=&#38;z}) xc-=~'z, aJld s u ~ z and P~ _= q} proves IH. 2. The \nlast rule is Y'--~\" . By IH, there exist v \u00a2 V an  \u00a2--4 y Pvy such that x\u00a2.-4 ~d(PUPvYU{y=,.,zv}) X \n~ Z and V 1 var(P~) = 0. Let Qv u ~ P~ U {*u = w, w = &#38;v} whet w is a new variable. x~--~. Fd(pUp,~u{y=~,) \n) x-+z by IH. t--e~(pup~u@=~}) x'--~ z. by Thm 1. yc--~V ~ex(PUPvY) Xc-~ Z. since the only rule for y \n= &#38;v is ~--'T' ~({*u=w,w=&#38;v,~=&#38;y}) yc.-+v. t%~(puP~u{.u=w,w=~v,~=&#38;~} ) x~--~z by last \n2 lines. ~-ex(PUQYuU{u=~y}) X ~ Z. x~'-+\" Fd(Puq~u{~=~}) X~--~Z by Thm 1 Consequently, there exist u \n\u00a2 V and Q~ such tha X\u00a2---> I-d(PUQYuU{u=~y}) X ~ Z and V M var(QVu) = The arguments for the remaining \ncases are similar: w outline the main construction in each case. 3. The last rule is y \u00a2--~a ~ a. Apply \nthe inductio: \u00a2--~ y hypothesis to \u00a2----~a and let Q~ be the program ob tained, where v is a new variable. \nNow, define Q~ t be Q a U {v = .u}, and by using yc--+a we can prove It for \u00a2--~ y. a '----~ - 4. Rule \ny\u00a2_~. a=y. Define P~ to be p a (the result of ap plying IH to a \"-+. ). a \u00a2.-.4. 5. Rule a=*y. Define \nPu v to be P~U{u = ~v}, whet y,.-~ P~ is the result of applying IH to a ~---~.. 6. Rule b~\"+Y a\u00a2'-~\" \na=*b. DefineP~ tobeP~ (theresul y \u00a2--~ of applying IH to a'----~. ).  7. Rule a ~ b ~ b.y=a. Define \nPu ~ to be Q~ (the resul y ~--~. of applying IH to ~ b).  8. Rule a'+b b~-'~\"*a=y. Define P~ to be \nPu b (the resul  y,---~. of applying IH to b'---~. ). For each program P, each initial query of the \nform \"wha may x point to?\" and each intermediate query that can bq derived from the initial query, we \nhave show how to build al extension P' such that in PUP' we have \"x may point to z\" where z being a new \nvariable. Moreover, in this extension any new points-to relation that can be derived about x, ha.. to \nbe derived through the intermediate query. We want the same result for initial queries of the forts \"which \nvariable may point to x?\". Let P be a program V the set of variables of P, x a variable of P and z a \nnet variable (x E V, z ~ V). Again using induction, we car prove, Vy E V: (i) If -~--~x ~-d Y'---~\" then \nBu \u00a2 V and a program Pu~ s.| ~--~x ~d(VuP$u.{~=a~})z~--~x and VM var(Pg) = O0 (ii) If .'-+x Fd \"\u00a2-+y \nthen 3u ~ V and a program Q~ s.t  \"c-\"~'X ~d(PUQuYU{u=&#38;y}) Zc'->X and Y n var(Q~) --0 If x --= \ny then u ~ z and Q~ .~ 0 are solutions Otherwise we apply the previous construction. [~  \n\t\t\t", "proc_id": "378795", "abstract": "<p>Known algorithms for pointer analysis are &#8220;global&#8221; in the sense that they perform an exhaustive analysis of a program or program component. In this paper we introduce a demand-driven approach for pointer analysis. Specifically, we describe a <i>demand-driven</i> flow-insensitive, subset-based, con text-insensitive points-to analysis. Given a list of pointer variables (a query), our analysis performs just enough computation to determine the points-to sets for these query variables. Using deductive reachability formulations of both the exhaustive and the demand-driven analyses, we prove that our algorithm is correct. We also show that our analysis is optimal in the sense that it does not do more work than necessary. We illustrate the feasibility and efficiency of our analysis with an implementation of demand-driven points-to analysis for computing the call-graphs of C programs with function pointers. The performance of our system varies substantially across benchmarks - the main factor is how much of the points-to graph must be computed to determine the call-graph. For some benchmarks, only a small part of the points-to graph is needed (e.g <i>pouray emacs</i> and <i>gcc</i>), and here we see more than a 10x speedup. For other benchmarks (e.g. <i>burlap</i> and <i>gimp</i>), we need to compute most (> 95%) of the points-to graph, and here the demand-driven algorithm is considerably slower, because using the demand-driven algorithm is a slow method of computing the full points-to graph.</p>", "authors": [{"name": "Nevin Heintze", "author_profile_id": "81100251839", "affiliation": "Research, A gere Systems, Lucent Technologies, Microelectronics Division", "person_id": "P208265", "email_address": "", "orcid_id": ""}, {"name": "Olivier Tardieu", "author_profile_id": "81100366768", "affiliation": "Ecole Des Mines, Paris", "person_id": "PP28003137", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/378795.378802", "year": "2001", "article_id": "378802", "conference": "PLDI", "title": "Demand-driven pointer analysis", "url": "http://dl.acm.org/citation.cfm?id=378802"}