{"article_publication_date": "05-01-2001", "fulltext": "\n Java without the Coffee Breaks: A Nonintrusive iVlultiprocessor GarbageCNlector David R Bacon Clement \nR. Attanasio Han B. Lee V.T. Rajah Stephen Smith IBM T.J. Watson Research Center ABSTRACT The deployment \nof Java as a concurrent programming language has created a critical need for high-performance, concurrent, \nand incre- mental multiprocessor garbage collection. We present the Recycler, a fully concurrent pure \nreference counting garbage collector that we have implemented in the Jalapefio Java virtual machine running \non shared memory multiprocessors. While a variety ofmultiprocessor collectors have been proposed and \nsome have been implemented, experimental data is limited and there is little quantitative basis for comparison \nbetween different al- gorithms. We present measurements of the Recycler and compare it against a non-concurrent \nbut parallel load-balancing mark-and- sweep collector (that we also implemented in Jalapefio), and eval- \nuate the classical tradeoff between response time and throughput. When processor or memory resources \nare limited, the Recycler runs at about 90% of the speed of the mark-and-sweep collector. However, with \nan extra processor to run collection and with a mod- erate amount of memory headroom, the Recycler is \nable to operate without ever blocking the mutators and achieves a maximum mea- sured mutator delay of \nonly 2.6 milliseconds for our benchmarks. End-to-end execution time is usually within 5%. 1. INTRODUCTION \nIn this paper we present a new multiprocessor garbage collector that achieves maximum measured pause \ntimes of 2.6 milliseconds over a set of eleven benchmark programs that perform significant amounts of \nmemory allocation. Our collector, the Recycler,is novel in a number of respects: In normal operation, \nthe mutators are only very loosely syn- chronized with the collector, allowing very low pause times; \n It is a pure concurrent reference counting collector; no global tracing is performed to collect cyclic \ngarbage; and  Cyclic garbage is collected using a new concurrent cycle de- tection algorithm that traces \ncycles locally.  Work done at IBM. Current address: Department of Computer Science, University of Colorado, \nBoulder, CO 80309.  Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for profit or \ncommercial advan-tage and that copies bear this notice and the full citation on the first page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission \nand/or a fee. PLDI 2001 6101 Snowbird, Utah, USA &#38;#169; 2001 ACM ISBN 1-58113-414-2/01/06... $5.00 \nIn addition, we have implemented a non-concurrent (\"stop-the- world\") parallel load-balancing mark-and-sweep \ncollector, and in this paper we provide comparative measurements of two very dif- ferent approaches to \nmultiprocessor garbage collection, for the first time quantitatively illustrating the possible tradeoffs. \nThe Recycler uses a new concurrent reference counting algo- rithm which is similar to that of Deutsch \nand Bobrow [ 13] but main- tains the invariant that objects whose reference count drops to zero can be \ncollected, and therefore avoids the need for ancillary tables. The concurrent cycle collector is the \nfirst fully concurrent algo- rithm for the detection and collection of cyclic garbage in a ref- erence \ncounted system. It is based on a new synchronous algo- rithm derived from the cyclic reference counting \nalgorithm of Lins [23]. Our algorithm reduces asymptotic complexity from O(n 2) to O(n), and also significantly \nreduces the constant factors. When the system runs too low on memory, or when mutators exhaust their \ntrace buffer space, the Recycler forces the mutators to wait until it has freed memory to satisfy their \nallocation requests or processed some trace buffers. The Recycler is implemented in Jalapefio [1], a \nnew Java virtual machine and compiler being developed at the IBM T.J. Watson Re- search Center. The \nentire system, including the collector itself, is written in Java (extended with unsafe primitives for \nmanipulating raw memory). In concurrently published work, we provide detailed pseudo- code for the cycle \ncollection algorithm and a proof of correctness based on an abstract graph induced by the stream of increment \nand decrement operations [5]. This paper concentrates on describing the system as a whole, and on the \ncomparative measurements. The rest of this paper is organized as follows: Section 2 presents our algorithm \nfor concurrent reference counting. Section 3 presents the synchronous algorithm for collecting cyclic \ngarbage; Section 4 extends this algorithm to handle concurrent mutators. Section 5 describes the implementation, \nand Section 6 describes the paral- lel mark-and-sweep collector. Section 7 presents measurements of the \nrunning system and a comparison between the two garbage col- lectors. Section 8 describes related work \nand is followed by our conclusions. 2. REFERENCE COUNTING COLLECTOR In this section we describe the reference-counting \ngarbage col- lection algorithm, for the time being ignoring the disposition of cyclic garbage which will \nnot be detected. Our collector shares some characteristics with the Deutsch-Bobrow algorithm and its \ndescendants [l 3, 29, 12], as discussed in Section 8. The Recycler is a producer-consumer system: the \nmutators pro- duce operations on reference counts, which arc placed into buffers and periodically turned \nover to the collector, which runs on its own CPU1 CPU2 CPU3 (colLector) inc dec inc dec inc dec Figure \n1: The Concurrent Reference Counting Collector. Ar- rows represent the execution of the CPUs; bubbles \nare inter- ruptions by the collector. Increment and decrement operations are accumulated by each CPU \ninto a buffer. At the end of epoch 8, the collector, running on CPU 3, will process all increments through \nepoch 8 and all decrements through epoch 7. processor. The collector is single-threaded, and is the only \nthread in the system which is allowed to modify the reference count fields of objects. The operation \nof the collector is shown in Figure 1. During muta- tor operation, updates to the stacks are not reference-counted. \nOnly heap updates are reference-counted, and those operations are de- ferred with a write barrier by \nstoring the addresses of objects whose counts must be adjusted into mutation buffers, which contain in-crements \nor decrements. Objects are allocated with a reference count of 1, and a corresponding decrement operation \nis immedi- ately written into the mutation buffer; in this manner, temporary objects never stored into \nthe heap are collected quickly. Time is divided into epochs, which are separated by collections which \ncomprise each processor briefly running its collector thread. Epoch boundaries are staggered; the only \nrestriction being that all processors must participate in one collection before the next col- lection \ncan begin. Periodically, some event will trigger a collection cycle: either because a certain amount \nof memory has been allocated, or because a mutation buffer is full, or because a timer has expired. In \nnormal operation, none of these triggers will cause the mutator to block; however, they will schedule \nthe collector thread to run on the first processor. On the first processor when the collector thread \nwakes up it scans the stacks of its local threads, and places the addresses of objects in the stack into \na stack buffer. It then increments its local epoch number, allocates a new mutation buffer, and schedules \nthe collec- tor thread on the next processor to run. Finally, it dispatches to the thread that was interrupted \nby collection. The collector thread performs these same operations for each processor until it reaches \nthe last processor. The last processor ac- tually performs the work of collection. The last processor \nscans the stacks of its local threads into a stack buffer. Then it processes increments: the reference \ncount of each object addressed in the stack buffer for the current epoch computed by each processor is \nincremented. Then the mutation buffer for each processor for the current epoch is scanned, and the increment \noperations it contains are performed. To avoid race conditions that might cause the collector to pro- \ncess a decrement before the corresponding increment has been pro- cessed, not only must we process the \nincrement operations first, but we must process the decrement operations one epoch behind. So the last \nprocessor scans the stack buffers of the previous epoch, and decrements the reference counts of objects \nthat they address, and then processes the mutation buffers of the previous epoch, per- forming the decrement \noperations. During the decrement phase, any object whose reference count drops to 0 is immediately freed, \nand the reference counts of objects it points to are recursively decremented. Finally, the stack and \nmutation buffers of the previous epoch are returned to the buffer pool, and the epoch number is incremented. \nThe collection has finished and all processors have joined the new epoch, and now any processor can trigger \nthe next collection phase.  2.1 Optimization of Stack Scanning A problem with the algorithm as we have \ndescribed it is that the stack of each thread is scanned for each epoch, even if the thread has been \nidle. As a result, the pause times will increase with the number of total threads in the system, and \nthe collector will use- lessly perform complementary increment and decrement operations in every collection \non the objects referenced from the stacks of idle threads. We now describe a refinement of the algorithm \nwhich eliminates this inefficiency; the refined algorithm is the one we have actually implemented. Instead \nof a per-processor stack buffer, there are stack buffers for each thread, as well as a flag to keep track \nof whether the thread has been active in the current epoch. When the collector runs on a processor, instead \nof scanning the stacks of all threads, it only scans the stacks of active threads. When buffer processing \noccurs on the last processor, the col- lector iterates over all threads, and if the thread was active \nin the current epoch, it processes the stack buffer and increments each object it refers to. If the thread \nwas inactive, it does not perform any increments; instead, the stack buffer of the previous epoch is \npromoted and becomes the stack buffer of the current epoch. The collector then scans the mutation buffer \nof each processor for the current epoch, and performs the increment operations. Then the collector iterates \nover all of the threads again, and if a thread has a stack buffer for the previous epoch, the objects \nreferred to are decremented. Note that if the thread was idle, its stack buffer of the previous epoch \nwill have been promoted in the increment phase, and no decrements will be performed for the idle thread. \n Finally, the decrements of the mutation buffers of the previous epoch are performed, and the collection \ncompletes as before. A natural refinement is to apply this optimization to unchanged poNons of the thread \nstack, so that the entire stack is not reseanned each time for deeply recursive programs. This is equivalent \nto the ' generational stack collection technique of Cheng et al [9]; so far we have not implemented this \noptimization since our benchmarks are not deeply recursive. 2.2 Parallelization Our collector is concurrent \n(it operates simultaneously with the mutators) but not parallel (the actual work of collection is only \nper- formed on the distinguished last CPU). The scalability of the col- Color Meaning Black In use or \nfree Gray Possible member of cycle White Member of garbage cycle Purple Possible root of cycle Green \nAcyclic Red Candidate cycle undergoing E-computation Orange Candidate cycle awaiting epoch boundary \nTable 1: Object Colorings for Cycle Collection. Orange and Red are only used by the concurrent cycle \ncollector. lector is therefore limited by how well the collector processor can keep up with the mutator \nprocessors. Our design point was for one collector CPU to be able to handle about 3 mutator CPU's, so \nthat for four-processor chip multiprocessors (CMPs) one CPU would be dedicated to collection. It is possible \nto parallelize our algorithm, particularly the refer- ence counting described in this section. Most straightforwardly, \nwork could be partitioned by address, with different processors handling reference count updates for \ndifferent address ranges. If these were the same address ranges out of which those proces- sors allocated \nmemory, locality would tend to be good except when there was a lot of thread migration due to load imbalance. \nA scheme which is in many ways simpler and would have bet- ter load balance, would be to straightforwardly \nparallelize the ref- erence count updates and use fetch-and-add operations to ensure atomicity on the \nreference count word. The problem is that now all operations on the reference count field will incur \na synchronization overhead. These solutions only address the problem of reference counting; cycle collection, \nwhich is discussed in Sections 3 and 4 is harder to parallelize, although it would be possible to use \nthe techniques in this paper for a local \"cluster\" of processors and then use tech- niques borrowed from \nthe distributed computing community to col- lect inter-cluster cycles [28]. 3. SYNCHRONOUS CYCLE COLLECTION \nSince the early 1960's when both mark-and-sweep [26] and ref- erence counting [ 11 ] were first proposed \nfor automatic garbage col- lection, a deficiency of many collectors based on reference counting has been \ntheir inability to collect cyclic garbage. Solutions to this problem have ranged from placing the responsibility \nfor breaking cycles on the programmer, to providing special programming ab- stractions [6] to using an \ninfrequent mark-and-sweep collector as a backup to the reference counting collector [ 12]. In passing, \nit should be noted that cycles can be problematic for tracing collectors as well. Cyclic garbage greatly \nincreases the false retention effects in conservative collectors, sometimes to unaccept- able levels \n[7]. Cycles can also disturb generational collectors by causing large amounts of dead data to be moved \ninto the \"old\" gen- , eration. Finally, cycles can cause poor performance for the train algorithm by \nrequiring cars to be moved multiple times. We now expand the algorithm of the previous section to handle \ncyclic garbage. Following our philosophy of using a pure reference- counting approach, rather than a \nhybrid of reference-counting and tracing, we find cyclic garbage by performing localized cycle de- tection. \nIn this section we describe a synchronous \"stop the world\" cycle collector so that the concerns raised \nby concurrent mutator activity can be factored out. In Section 4 we extend the algorithm to handle dec>O \n\"b,--.--\" ~ Z~ -.~.._. _/   t,. %\\ 15\u00b0\u00b0 ,.~ V'~ ~o\\ / .~,o,'\u00b0/ ',.._.2,,' >\",._../ Figure 2: State \ntransition graph for cycle collection. concurrent mutation. First of all, we observe that some objects \nare inherently acyclic, and we speculate that they will comprise the majority of objects in many applications. \nTherefore, if we can avoid cycle collection for inherently acyclic objects, we will significantly reduce \nthe over- head of cycle collection. Some classes can be statically determined to be acyclic: those that \ncontain only scalars and references to final acyclic classes (that is, classes that are acyclic and may \nnot be subelassed), and arrays of final acyclic classes. In Java, an important special case of the latter \ngroup are arrays of scalars. In the Recycler, part of the reference counting field in each object is \nreserved for cycle collection, which uses a coloring scheme as detailed in Table 1. An object is colored \ngreen at object creation time if the class of the object is statically determined to be acyclic. Note \nthat for static compilation, the class graph could be an- alyzed to determine which classes are acyclic. \nHowever, in the presence of dynamic class loading our more restrictive formulation must be used, since \nan acyclic class could later be subclassed with a cyclic class. For those objects that are potentially \ncyclic, we use a technique first decsribed by Christopher [10] in which garbage cycles are identified \nby tentatively subtracting internal references, and observ- ing whether the resulting structure has regions \nwith zero reference count. Our algorithm is based variant of the coloring algorithm pro- posed by Martinez \net al [25] and extended by Lins [23]. An ex- cellent description of the latter algorithm is contained \nin the book by Jones and Lins [20]; we will briefly describe our algorithm and highlight the differences \nwith Lins' algorithm. The basic approach is based on the fact that a live cycle must contain at least \none object with a reference count of two or more. Therefore, whenever a reference count is decremented \nto a non- zero value, we record the pointer in a root buffer and color the object purple, meaning that \nit is a potential root of a garbage cy- cle. We also set a buffered flag in the object to ensure that \nwe do not record the pointer in the root buffer more than once. The state transition graph for our algorithm \nis shown in Figure 2. Optimistically, we hope that eventually the potential root will ei- ther become \ngarbage (by its reference count dropping to zero) or will become linked to some other live structure, \ncausing its refer- ence count to increase again, at which point we re-color it black. In either of these \ncases, we know that the object is not part of a 94  Ikooi Buff\u00b0, ] ./\" ,/ \\ Figure 3: Example of compound \ncycle that causes Lins' algo- rithm to exhibit quadratic complexity. garbage cycle. Periodically, we \nprocess the root buffer. The data structures rooted by those objects that are still purple are traversed, \nand the reference counts due to internal pointers are subtracted, with the objects traversed marked gray \nindicating that they are candidates for garbage cycle removal (inherently acyclic -green- objects are \nnot marked or traversed). This is the marking phase of the algo- rithm. A garbage cycle will have only \ninternal pointers, and therefore subtracting the counts due to internal pointers will cause the refer- \nence counts in the cycle to drop to zero. A second traversal start- ing from the once-purple roots finds \nsuch objects and colors them white. This is the scanning phase of the algorithm. Gray objects whose reference \ncount is non-zero are colored black, along with all objects reachable from them. In the process, the \nreference counts are restored, in a process called unscanning (or \"scan black\" in Jones and Lins' book). \nFinally, the white objects are swept into the free list, the refer- ence counts of green objects they \nrefer to are decremented, and the root buffer is cleared. This is the collection phase of the algorithm. \nLins' algorithm performs the mark, scan, and collect Phases to- gether for each candidate root in turn. \nUnfortunately, this makes the algorithm O(n 2) in the worst case, as for example in the cycle shown in \nFigure 3. His algorithm will perform a complete scan from each of the candidate roots until it arrives \nat the final root, at which point the cycle will be collected. Lins' algorithm also does not use a buffered \nflag, and may therefore consider the same root multiple times. Our algorithm performs each phase in its \nentirety for all of the roots, and is therefore linear in the size of the object graph-O(N+ E) -since \nthe mark, scan, and collect phases each traverse at worst each object and each pointer. In the worst \ncase our algorithm would traverse the entire heap 3 times. In practice, we observe far less memory traversal, \nsince we eliminate consideration of green nodes, and many candidate roots become garbage before they \nare scanned. 4. CONCURRENT CYCLE COLLECTION In this section we briefly describe the concurrent cycle \ncollector. A fuller description of the details of the algorithm, including de- tailed pseudo-code and \na formal proof of correctness, is presented in concurrently published work [5]. The concurrent cycle \ncollection algorithm is somewhat more com- plex than the synchronous algorithm. As with other concurrent \ngarbage collection algorithms, we must contend with the fact that the object graph may be modified while \nis is being scanned by the collector. In addition the reference counts may be as much as two epochs out \nof date. Our algorithm relies on the stability property of garbage: once an object becomes garbage, it \ncan not cease being garbage. The basic approach is to use the sequential algorithm of the previous section \nto find what appear to be garbage cycles. We then perform two validation tests to ensure that the garbage \ncycles were not detected erroneously due to concurrent mutator activity. An important characteristic \nof our algorithm is that the validation tests are relatively simple and are independent of the algorithm \nused to detect the candidate cycles. This greatly simplifies the proof of correctness. Since we can not \nrely on being able to re-trace the same graph in order to restore reference counts that have been subtracted \ndue to internal pointers, we instead maintain two reference counts for each object: one is the true reference \ncount (usually just called the RC), and the other is the cyclic rej~rence count (or CRC). Both counts, \nthe color, and the buffered flag are stored in a single 32-bit word in the object header. The RC and \nCRC are each 12 bits plus an overflow bit. When the overflow bit is set, the excess count is stored in \na hash table. In practice this hash table never contains more than a few entries. The algorithm proceeds \nin a similar manner to the synchronous algorithm, except that when an object is marked gray its cyclic \nref- erence count is initialized to its true reference count, and hence- forward the algorithm operates \nonly on the cyclic reference count, leaving the true reference count unchanged. However, in the col-lect \nphase instead of marking white objects black and freeing them, we instead mark them orange (as shown \nin the transition graph in Figure 2) and place them in a cycle buffbr. Different cycles are delineated \nby nulls. 4.1 Safety Tests So far we have simply used a synchronous cycle collection algo- rithm in \na concurrent setting, without any synchronization between the mutators and the collector. Therefore, \nsome of the cycles found may not really be garbage. To prevent collection of live data, we perform two \nvalidation steps: one to verify the number of exter- nal references into the cycle; and a second, to \ncheck for concurrent addition of references into the cycle which would make it live. The ~-test checks \nfor external references to a cycle, and pro- ceeds as follows: for each cycle, set the cyclic reference \ncount (CRC) of each object to its true reference count (RC). Then fol- low the pointers from each of \nthe objects in the cycle, subtracting one from the CRC of each reached object. Finally, take the sum \nof the CRC's of each object in the cycle, This sum is the total number of external references into the \ncycle. If it is zero, then the cycle is garbage provided that no additional edges were concurrently added \ninto the cycle. An important feature of the Z-test is that it operates on a fixed set of nodes; it does \nnot rely on following pointers within the objects to elaborate the set, since those pointers are subject \nto concurrent mutation. This is the key insight of the S-test. The A-test runs after the next epoch and \nchecks for concur- rent modification to the cycle. It scans the objects in each cycle and checks whether \nthey are still orange (if their reference count changed, they would have been recolored). If all objects \nin a cycle are still orange, and it has passed the external reference test, then 95 the cycle is garbage \nand is collected. Note that it is not necessary to wait to observe the effect of con- current decrement \noperations, since they only reduce the external reference count of the cycle. 4.2 Liveness So far we \nhave described an algorithm that is safe -it does not collect reachable data, by virtue of the two validation \ntests. How- ever, we must also demonstrate liveness - that all garbage is col- lected. Acyclic garbage \nis handled by the basic reference counting tech- nique of Section 2. Roots of cyclic garbage are entered \ninto the root buffer by the process described in the previous section for the sequential algorithm. The \nconcurrent variant of the sequential al- gorithm then searches for dead cycles from those roots, If there \nis no concurrent mutation, the synchronous algorithm will find garbage due to the stability proper~ of \ngarbage. If a cycle is identified as garbage but fails either of the validation tests, then its root \n(the first object in the buffer) and any members that have been colored purple due to decrements are \nentered into the root buffer and reconsidered during the next cycle collection. This ensures that any \ncycle abandoned due to concurrent mutation is correctly reconsidered. The only other possible case is \nthat the sequential algorithm does not find a garbage cycle due to concurrent mutation, and therefore \nnever enters it into consideration by the validation tests. However, in that case, the concurrent modification \nwill subsequently be visi- ble to the collector as a decrement, which will introduce the object in question \ninto the set of possible roots, which is then considered correctly. 4.3 Collection of Cycles To collect \nthe cycles, we process the cycle buffer in reverse or- der. To see why this is necessary, consider Figure \n3. The concurrent algorithm will consider each of the objects as a separate cycle, and if we collected \nthe cycles in the same order they appeared in the buffer, we would only collect the rightmost cycle on \neach succes- sive epoch, which is clearly unacceptable. By collecting the cycles in reverse order, and \ndecrementing both the RC and CRC fields of any objects referenced by collected ob- jects, by the time \nwe reach the earlier, dependent cycle, its external reference count will have dropped to zero, and it \ncan be collected. We observe that ifa cycle is collected, then the external reference count (ERC) of \nany dependent cycles can be updated by subtracting the number of edges from the collected cycle to the \ndependent cy- cle. Since the collected cycle is garbage, it is not possible that those edges were subject \nto concurrent mutation, and it is not necessary to re-compute the ERC. Therefore, if the ERC of the dependent \ncy- cle reaches zero, and it passes the A-test, then it is also a garbage cycle and can be collected. \nThere are also certain types of dependent graphs not detected in a single epoch by our algorithm that \nwould be detected if a fully general SCC algorithm were run. However, such an algorithm may require constructing \na supergraph as large as the original object graph, and once again we believe the likelihood of such \ndata struc- tures in practice is very low. 4.4 Isolated Markings Since the algorithm for finding candidate \ncycles is coloring ob- jects concurrently with the execution of the mutators, it is possible that the \nmutators can cut an edge that causes arbitrary gray or white subgraphs to be isolated from the collector. \nThese subgraphs could later \"fool\" the algorithm into producing an incorrect result. We handle this problem \nby always recoloring the reachable graph of a gray or white object to black when its reference count \nis incre- mented or decremented (in the case of a decrement, the root object is colored purple and considered \nas a root). This means ttmt the colors will always be properly reset after at most two epochs. In the \nmeantime, false positives are handled by the validation tests. False negatives are not an issue since \nthe objects are in- herently live (because they have been concurrently mutated), and any garbage cycles \ninvolving concurrent decrements will be found when the object is recolored purple and added to the root \nbuffer.  5. IMPLEMENTATION The Recycler is implemented in Jalapefio [1], a Java virtual ma- chine written \nin Java and extended with unsafe primitives that are available only to the virtual machine. Jalapefio \nuses safe points -rather than interrupting threads with asynchronous signals, each thread periodically \nchecks a bit in a condition register that indi- cates that the runtime system wishes to gain control. \nThis design significantly simplifies garbage collection. Implementing the garbage collector in Java creates \na number of its own problems: the memory allocator must bootstrap itself; the collector must avoid any \nallocation and must make sure it does not prematurely collect its own intemal data structures. All information \nrequired by the reference counting collector is stored in one extra word in the object header. We are \nimplementing other object model optimizations that in most cases will eliminate this per-object overhead. \nThe Recycler is an exact collector, and makes use of the object and stack reference maps generated for \nuse with the mark-and- sweep collector. 5.1 Memory Allocator Since long allocation times must be treated \nas mutator pauses, the design of the memory allocator is crucial. The design of the al- locator also \nstrongly affects the amount of work that can be shifted to the collection processor; the more concurrent \naccess to the allo- cation structures is possible, the better. We currently use an allocator which is \nless than ideal for the Recycler; it was adapted from the non-copying parallel mark-and- sweep collector \ndescribed in the next section. Using the termi- nology of Wilson et al [31], small objects are allocated \nfrom per- processor segregated free lists built from 16 KB pages divided into fixed-size blocks. Large \nobjects are allocated out of 4 KB blocks with a first-fit strategy.  6. THE PARALLEL COLLECTOR In this \nsection we briefly describe the parallel non-copying mark- and-sweep collector with which the Recycler \nwill be compared. Each processor has an associated collector thread. Collection is initiated by scheduling \neach collector thread to be the next dis- patched thread on its processor, and commences when all proces- \nsors are executing their respective collector threads (implying that all mutator threads are stopped). \nThe parallel collector threads start by zeroing the mark arrays for their assigned pages, and then marking \nall objects reachable from roots (references in global static variables and in mutator stacks). The Jalapefio \nscheduler ensures that all suspended threads are at safe points, and the Jalapefio compilers generate \nstack maps for the safe points identifying the location of references within stack frames. This allows \nthe collector threads to quickly and exactly scan the stacks of the mutator threads and find the live \nobject refer- ences. Program 20 l.compress 202dess 205.raytrace 209.db 213.ja;\u00a2ac ............... Java \nbytecode compiler 222.mpeg~gdi9 MPEG coder/decoder 227.mtrt Multithreaded ray tracer 228.jack Parser \ngenerator specjbb 1.0 TPC-C style workload Ja!apefio Jalapefio compiler Description Compression Java \nexpert system shell Ray tracer Database Applic. Size Threads Obj Alloc Obj Free Byte Alloc objAcyclic \nI Incs[ Decs 18KB 1 0.15M 0.13M 240 MB 11 KB 1 17.4 M 17.2 M 686 MB 57 KB 1 13.4M 13.1M 361 MB 90% 3.59M \n16.3M 10 KB 1 6.6M 5.9M 193 MB 10% 67.0M 66.7M 688 KB 1 16.1M 14.1M 195 MB 51% 41.6M 51.8M 120 KB 1 0.30M \n0.27M 25 MB 76% 12.1 M 6.70M 571 KB 2 14.0M 13.5M 381 MB 90% 4.5M 17.3 M 131 KB 1 16.8M 16.4M 715 MB \n81% 16.8 M 33.0M 821 KB 3 33.3 M 33.0M 1034 MB 59% 52.4M 84.5 M 1378 KB 1 t9.6M 18.4M 676 MB 7%i 62.6M \n65.6M ggauss ...... Cyclic tomare test (synth.) 8 KB 1 32.4M 32.0M 1163 MB <1%1 56.9M 77.2M Table 2: \nBenchmarks and their overall characteristics. The benchmarks include the complete SPEC suite and represent \na wide range of application characteristics. While tracing reachable objects, multiple collector threads \nmay attempt to concurrently mark the same object, so marking is per- formed with an atomic operation. \nA thread which succeeds in marking a reached object places a pointer to it in a local work buffer of \nobjects to be scanned. After marking the roots, each collector thread scans the objects in its work buffer, \npossibly marking addi- tional objects and generating additional work buffer entries. In order to balance \nthe load among the parallel collector threads, collector threads generating excessive work buffer entries \nput work buffers into a shared queue of work buffers. Collector threads ex- hausting their local work \nbuffer request additional buffers from the shared queue of work buffers. Garbage collection is complete \nwhen all local buffers are empty and there are no buffers remaining in the shared pool. At the end of \ncollection the mark arrays have marked entries for blocks containing live objects, and unmarked enttries \nfor blocks available for allocation. If all blocks in a page are available, then the page is returned \nto the shared pool of ftee heap pages, and can be reassigned to another processor, possibly for a different \nblock size. Collector threads complete the collection process by yielding the processor, thus allowing \nthe waiting mutator threads to be dis- patched. The design target for this collector is multiprocessor \nservers with large main memories. When compiled with the Jalapefio optimiz- ing compiler, this collector \nwas able to garbage collect a 1 GB heap with millions of live objects in under 200 milliseconds on a \n12- processor PowerPC-based server. This statistic should give some indication that we are not comparing \nthe Recycler against an easy target.  7. MEASUREMENTS The Recycler is a fairly radical design for a \ngarbage collector. We now present measurements showing how well various aspects of the design work. \nThe Recycler is optimized to minimize response time, while the mark-and-sweep collector is optimized \nto maximize throughput. We present measurements of both systems that illustrate this clas- sical tradeoff \nin the context of multiprocessor garbage collection. All tests were run on a 24 processor IBM RS/6000 \nModel $80 with 50 GB of RAM. Each processor is a 64-bit PowerPC RS64 III CPU running at 450 MHz with \n128 KB split L1 caches and an 8 MB unified L2 cache. The machine runs the IBM AIX 4.3.2 Unix operating \nsystem. 7.1 Benchmarks Table 2 summarizes the benchmarks we have used. Our bench- marks consist of the \nfull suite of SPEC benchmarks (including SPECjbb); the Jalapefio optimizing compiler compiling itself; \nand ggaus s, a synthetic benchmark designed as a \"torture test\" for the cycle collector: it does nothing \nbut create cyclic garbage, using a Gaussian distribution of neighbors to create a smooth distribution \nof random graphs. SPEC benchmarks were run with \"size 100\" for exactly two it- erations, and the entire \nrun, including time to JIT the application, was counted. We performed two types of measurements: response \ntime ori- ented and throughput oriented. Since our collector is targeting re- sponse time, most of the \nmeasurements presented are for the former category For response time measurements, we ran the benchmarks \nwith one more CPU than there are threads. For throughput measure- ments, we measured the benchmarks running \non a single processor. The first scenario is typical for response time critical applications (multiprocessor \nworkstations, soft real-time systems, etc.) The sec- ond scenario is typical of multiprogrammed multiprocessor \nservers. Table 2 summarizes the benchmarks and shows the number of objects allocated and freed by each \nprogram; the difference is due to the fact that some objects are not collected before the virtual machine \nshuts down. It also shows the number of bytes requested over the course of each program's execution. \nTo get a broad overview of the demands each program will place on the Recyeler, we show the number of \nincrement and decrement operations performed, as well as the percentage of objects created that are acyclic \naccording to our very simple test performed at class resolution time. These measurements confirm our \nbasic hypothe- ses: the number of reference count operations per objects is usually small (between 2 \nand 6), so that reference counting will be efficient -the exceptions are db and mpegaudio, which perform \nabout 20 and 60 mutations per object, respectively. The effect of these mutation rates will be seen in \nsubsequent measurements. The number of acyclic objects varies widely, indicating that the system may \nbe vulnerable to poor performance for applications where it can not avoid checking for cycles on many \ncandidate roots. In practice this turns out not to be a problem. 7.2 Application Performance Our collector \nhas a new and unusual design, and there are ob- vious questions about its overhead and applicability \nin practice. EF- 0.6 ~0.4 ' \u00b00, | o 100% 90% 8O% 70% 60% 5O% 40% 30% 20% 10% 0%, i i _ [] Free N Va \ndate -- [] Collect -- [] Scan ._ ~ Mark Purge [[2Increment [] Decrement m ......................... m \n_ m ~ M m _ _ ~ w Figure 4: Relative Speed of the Reeyeler compared to the Paral- lel Mark-and-Sweep \nCollector. In the multiproeessing environ- ment the Recycler offers much lower pause times while remain- \ning competitive with Mark-and-Sweep in end-to-end execution time. While these will be addressed below \nin more detail, we believe that the ultimate measure of a garbage collector is, How well does the application \nperform? When we undertook this work, our goal was to develop a con- current garbage collector that only \nsuffered from rare pauses of un- der 10 milliseconds, while achieving performance within 95% of a tuned \nconventional garbage collector. Figure 4 shows how well we have succeeded. It shows the speed of applications \nrunning with the Recycler relative to the speed of the same applications running with the parallel mark-and-sweep \ncollector. The \"multiprocessing\" bar shows the response time ori- ented measurement, where an extra processor \nis allocated to run the collector; the \"uniprocessing\" bar shows the throughput oriented measurement, \nwhere the collector runs on the same processor as the mutator(s). For our design point, namely the multiprocessor \nenvironment, all but two of the benchmarks run within about 95% of the speed of the baseline (mark-and-sweep). \nThe exceptions are j es s and j avac. For three out of eleven benchmarks, the Recycler even provides \na moderate application speedup. In a single processor environment, performance generally drops off by \n5 to 10%, since the work of the collector is no longer be- ing overlapped with the mutators. However, \nthe performance of j ess and j avac is quite poor in this environment. Subsequent sections will investigate \nthe characteristics that lead to this perfor- mance problem. Depending on ones' point of view, the Recycler \ncan be viewed as having successfully extracted parallelism from the application and distributed it to \nanother processor; or as having introduced a significant overhead into the collection process. However, \nwe believe that there is a significant body of users who will appreciate the benefits provided by the \nRecycler, while being willing to pay the associated cost in extra resources. Technology trends such as \nchip multiprocessing (CMP) may favor this as well. Figure 5: Collection Time Breakdown. The time devoted \nto various phases varies widely depending on the characteristics of the program. CPU by the Recycler. \nThis is work that is overlapped with the mutators in the multiprocessing case, and these measurements \nare from the multiprocessing runs. For most applications, the majority of time is spent processing decrements \nin the mutation buffers. Decrement processing includes not only adjustments to the reference count and \ncolor of the object itself, but the cost of freeing the object if its reference count drops to zero. \nFreeing may be recursive. The memory allocator is largely code shared with the parallel mark-and-sweep \ncollector, and is not necessarily optimized for the reference counting approach. Considerable speedups \nare probably possible in the decrement processing and freeing. A smaller but still significant portion \nof the time is spent in ap- plying mutation buffer increments. The mpegaudio application spend almost \nall of its collector time in increment and decrement processing. This is because it performs a very high \nrate of data structure mutation, while containing data that is almost all deter- mined to be acyclic \nby the class loader. The Purge phase removes and frees objects in the root buffer whose reference counts \nhave dropped to zero. If the size of the root buffer is sufficiently reduced and enough memory is available, \ncycle collection may be deferred until another epoch. Purging is a relatively small cost, except for \njess and ggauss. The Mark and Scan phases perform approximately complemen- tary operations and take roughly \nthe same amount of time. The Mark phase colors objects gray starting from a candidate root, and subtracts \ninternal reference counts. The Scan phase traverses the gray nodes and either recolors them black and \nrestores their refer- ence counts or else identifies them as candidate cycle elements by coloring them \nwhite. The performance problems with j avac are largely due to the fact that it has a large live data \nset which is frequently mutated, causing pointers into it to be considered as roots. These then cause \nthe large live data set to be traversed, even though this leads to no garbage being collected: it spends \nover 50% of its time in Mark and Scan. Only three benchmarks, namely compress, j alapefio and  7.3 Collector \nCosts qgaus s, actually spend a significant amount of time actually col- Figure 5 shows the distribution \nof time spent on the collector lecting cyclic garbage. The case of compress is particularly inter- 98 \nConcurrent Reference Counting (The Recycler) Program Epochs I PauseTime I Pause I Coll. I Elap. Max. \nI Avg. Gap Time Time compress I 41 1.0 ms 0.5 ms 53 ms 1.3 s 238 s jess 93 2.2 ms 1.1 ms 120 ms 63.4s \n136s ray[race 101 1.1 ms 0.7 ms 84 ms 25.2 s 99 s db 215 1.0 ms 0.5 ms 136ms 73.5 s 183 s javac 182 2.3 \nms 0.9 ms 285 ms 104.1s 147 s mpegaudio 2i 0.7 ms 0.5 ms 36 ms 4.2 s 271 s mtrt 66 2.2 ms 0.6 ms 150 \nms 22.9 s 74 s jack 153 1.3ms 0.7ms 122ms 31.1s 147s specjbb 72 1.3 ms 0.5 ms 493 ms 136.7 s (2103) ja!apefio \n330 2.6 ms 0.6ms 192 ms 93.9 s 154 s ggauss 405 0.5 ms 0.2 ms 22~2 ms 99.8 s 282 s Parallel Mark-and-Sweep \n  oc] Max I co,, I E,ap Pause Time Time 7 186 ms 1.2 s 242 s 24 237 ms 5.2 s 110 s 9 374 ms 2.7 s 93 \ns 4 414 ms 1.1 s 180 s 12 531 ms 2.8 s 129 s 4 172 ms 0.7 s 274 s l0 530 ms 4.0 s 72 s 23 190 ms 4.1 \ns 144 s 6 l127msl 4.7s (2351) 4 162 ms 0.6 s 287 s 24 171 ms 3.7 s 271 s  Table 3: Response Time. Maximum \npause time is 2.7 milliseconds while the elapsed time is generally within 5% of Mark-and-Sweep. The smallest \ngap between pauses is 36 ms, and is usually much larger. Program Buffe..l___r. Space (KB) Possible Roots \n(M..~ Mutation I Root }l Possible[Buff, [ Roots compress 128 131 0.40 0.03 0.01 jess t920 1180 54.3 9.36 \n0.23 raytrace 416 393 3.40 42.i 0.27 db 896 131 60.8 3.8 3.8 javac 1792 524 38.5 9.1 4.5 mpegaudio 43616 \n131 6.42 0.07 0.01 mtrt 992 786 4.2 0.96 0.56 jack 448 131 16.6 0.85 0.20 spe~bb 4832 660 51:3 6.9 2.8 \nj~apefio 1280 655 53.8 11.1 6.9 ggaus s 1568 393 51.4 18.8 7.7 Table 4: Effects of Buffering. The buffer \nrequirements are small, and filtering significantly reduces the roots that must be considered for cycle \ncollection (see also Figure 6). esting: it uses many large buffers (roughly 1 MB in size), which are \nreferenced by cyclic structures which eventually become garbage. While the amount of mutation and the \nnumber of objects is small, the Recycler performs all zeroing of large objects (since this would otherwise \nbe counted as a mutator pause), and this is counted as part of the Free phase. This accounts for compress \nrunning faster under the Recycler: we have paraUelized block zeroing[ 7.4 Response Time While we have \nshown that the Recycler is very quite competitive with the mark-and-sweep collector in end-to-end execution \ntimes, the Recycler must also meet stringent timing requirements. Table 3 provides details on both pause \ntimes and end-to-end ex- ecution times for the benchmarks running under both the Recycler and the parallel \nmark-and-sweep collector. The benchmarks are be- ing run in our standard response time oriented framework: \nthere is one more processor than there are mutator threads. The longest measured delay was 2.6 ms for \nthe j alapefio bench- mark. The longest type of delay occurs when an allocation on the first processor \nmust fetch a new block and triggers a new epoch, which immediately causes the collector thread to run, \nscan the stack of the mutator threads, and switch the mutation buffers, On return from I 7- -1 [3 ROOTS \n7 Unbulfered IB Freed 50% 111 Repeat 40% 111 -- ! Accyclic _ 20% ~ 0% I ~ ~ Figure 6: Root Filtering \n the collector, the allocator must still fetch a newly freed block of memory and format it. Therefore \nthe maximum delay experienced by the application is usually when calling the allocator, and that delay \nis slightly more than the maximum epoch boundary pause. Maximum pause time is only part of the story, \nhowever. It is also necessary that mutator pauses occur infrequently enough that the mutator can achieve \nuseful work without constant interruptions. Cheng and Blelloch [8] have formalized this notion for his \nin- cremental collector as maximum mutator utilization, which is the fraction of time the mutator is \nguaranteed to be able to run within a given time quantum. This is a natural measure for a highly in- \nterleaved collector like theirs which interrupts the mutator at every allocation point, but is less relevant \nfor our collector which nor- mally only interrupts the mutator infrequently at epoch boundaries. We provide \na measurement of the smallest time between pauses (\"Pause Gap\"), which ranges from 36 ms for mpeqaud\u00b1o \nto al- most halfa second for specjbb. Thus for mpeqaudio, the mu- tator may be interrupted for as much \nas 0.7 ms, but it will then run for at least 36 ms. Interestingly, the programs with shorter pause gaps \nalso seem to have shorter maximum pause times. As a result, the mutator Program Epochs Roots Cycles Found \nReN. Trace/ ] M&#38;S Checked Coil. Aborted Traced Alloc . Traced compress 41 6,067 101 0 123,739 0.84 \n1,800,816 jess 93 226,707 0 0 14,870,730 0.85 8,558,011 ray~ace 101 270,900 3 1 35,611,945 2.64 4,009,684 \ndb 275 3,791,011 0 0 83,056,779 12.49 2,004,687 javac 182 4,520,382 3,874 3 168,570,902 10.45 4,550,773 \nmpegaudio 21 9,638 0 0 176,634 0,58 1,065,008 mtrt 66 273,109 13 0 114,054,072 0:78 4,217,820 jack 154 \n199,827 701 0 1,783,240 0.10 6,651,059 spe~bb 72 2,786,822 0 0 96,338,266 2.98 4,081,266 jalapefio 330 \n6,938,814 388,945 7 50,389,369 2.57 1,463,823 ggauss 405 7,666,111. 2691302 0 28,970,954 0.89 5,851,686 \n Table 5: Cycle Collection. Many applications check a large number of roots without finding much cyclic \ngarbage, and race conditions leading to aborted cycles are rare. The number of references that have to \nbe traced by the two collectors vary widely depending on the program. utilization remains good across \na spectrum of applications. Although the Recycler spends far more time performing collec- tion than the \nmark-and-sweep collector, this collection time is al- most completely overlapped with the mutators. We \nare investigat- ing ways to reduce this overhead, including both algorithmic [4] and implementation improvements. \nThe specj bb benchmark performs a variable amount of work for a given time period, so its throughput \nscores are shown in paren- theses. Our maximum pause time of 2.6 ms is two orders of magnitude shorter \nthan that reported by Doligez and Leroy [16] and by Nettles and O'Toole [27], both for a concurrent dialect \nof ML. While pro- cessor speeds have increased significantly in the last seven years, memory systems \nhave progressed far less rapidly. We believe our system represents a substantial increase in real performance; \nhow- ever, only \"head-to-head\" implementations will tell. Our work is a beginning in this direction. \n 7.5 Buffering The Recycler makes use of five kinds of buffers of object refer- ences: mutation buffers, \nstack buffers, root buffers, cycle buffers, and mark stacks. The four buffer types have been described \nin the algorithm section; mark stacks are used to express the implicit re- cursion of the marking procedures \nexplicitly, thereby avoiding pro- cedure calls and extra space overhead. All five types of buffers consumes \nmemory, and it is clearly un- desirable for the garbage collector to consume memory. In practice, only \nthe mutation and root buffers turn out to be of significant size. The thread stacks never have more than \na few hundred object ref- erences, so the stack buffers are of negligible size (although they could become \na factor on a system with large numbers of threads, or for applications which are deeply recursive). \nTable 4 shows the instantaneous maximum buffer space utiliza- tion (\"high water mark\") for both mutation \nbuffers and root buffers. Mutation buffer consumption is reasonable, with the exception of mpegaudio, \nwhich uses 43 MB (!) of mutation buffer space. This is a direct result of the very high per-object mutation \nrate reflected in the measurements in Table 2, showing that mpegaudio per- forms about 60 mutations per \nallocated object. We are implementing some preprocessing strategies which should reduce the buffer consumption \nby about a factor of 2. We also have not yet tuned the feedback algorithm between the mutators and the \ncollector, which should further reduce buffer consumption. In par- ticular, we hope to take advantage \nof Jalapefio's dynamic profiling, feedback, and optimization system [3] to improve space consump- tion \nfor programs like rapegaudio. Table 4 also shows the effectiveness of our strategies for reduc- ing the \nnumber of objects that must be traced by the cycle collector. Every decrement that does not actually \nflee an object potentially leaves behind cyclic garbage, and must therefore be traced. The number of \nsuch decrements is shown (\"Possible\"), as well as the number that are actually placed in the buffer (\"Buffered\"), \nand the number that are left in the buffer after purging (\"Roots\"). Purging checks for objects that have \nbeen modified while the collector waits to process the buffer; objects whose reference count has been \nincre- mented are live and can be removed from consideration as roots, and objects whose reference count \nhas been decremented to zero are garbage and can be freed. While the number of possible candidate roots \nis high (as many as 60 million for db), the combination of the various filtering strate- gies is highly \neffective, reducing the number of possible roots by at least a factor of seven. Only ggaus s, our synthetic \ncycle genera- tor, requires a large fraction of roots to be buffered. While filtering is highly successful, \nFigure 6 shows that no one technique is responsible for its success. On average, about 40% of possible \nroots are excluded from consideration because the are acyclic, while another 30% are eliminated because \nthey are already in the root buffer (\"Repeat\"). The balance between these two fac- tors varies considerably \nbetween applications, but on balance the two filtering techniques remove about 70% of all candidate roots \nbefore they are ever put in the root buffer. Another 10% or so are freed during root buffer purging, \nbecause a concurrent mutator has decremented the reference count of the object to zero while it was in \nthe buffer. Surprisingly, the number of objects in the buffer whose reference count is incremented, al- \nlowing them to be removed (\"Unbuffered\") is very small and often zero. Finally, between 1 and 15% of \nthe possible roots are left for the cycle collection algorithm to traverse, looking for garbage cycles. \nThus the filtering techniques are a key component of making the cycle collection algorithm viable in \npractice.  7.6 Cycle Collection Table 5 summarizes the operation of the concurrent cycle collec- tion \nalgorithm. There were a number of surprising results. First of all, despite the large number of roots \nconsidered, the number Reference Counting Mark-and,Sweep Program Heap Epochs I Coll. Elapsed GCs Coll. \nElapsed Size I Time Time Time Time compress 64 MB 46 1.3 s 247 s 7 1.1 s 236 s j'ess 64 MB 116 44.1 s \n166 s 19 4.2 s 108 s raytrace 64 MB 195 15.3 s 108 s 9 2.5 s 94 s db 64 MB 276 33.7 s 207 s 4 1.2 s 178 \ns javac 64 MB 234 11 i.8 s 249 s 12 2.9 s 127 s ....mpegaudio 64 MB 31 4.8 s 296 s 3 0.5 s 274 s mtrt \n64 MB 157 17.2 s 115 s 10 3.6 s 99 s jack 64 MB 191 21.7 s 158 s 20 3.7 s 141 s specjbb 72 MB 85 25.2 \ns (70~) 5 1.9 s (841) jalapefio 256 MB 289 48.3 s 186 s 4 1.1 s 163 ggauss 40 MB 516 65.1 s 327 s 40 \n6.2 s 273 s Table 6: Throughput. Unlike the previous tables, the programs are run on a single processor. \nEven on a single processor the throughput of the Recycler is reasonable for most applications. of garbage \ncycles found was usually quite low. Cyclic garbage was 8. RELATED WORK significant in j alape~.o and \nour torture test, ggauss. It was also While numerous concurrent, multiprocessor garbage collectors significant \nin compress, although the numbers do not show it: for general-purpose programming languages have been \ndescribed multi-megabyte buffers hang from cyclic data structures in corn- in the literature [i2, 14, \n16, 18, 19, 21, 22, 24, 29, 30], the number pro s s, so the application runs out of memory if those 101 \ncycles that have been implemented is quite small and of these, only a few are not collected in a timely \nmanner, actually run on a multiprucessor [2, 12, 18, 16, 17, 27]. Note that j avac, which spends over \n50% of its garbage collec- DeTreville's work on garbage collectors for Modula-2+ on the tion time searching \nfor cyclic garbage to collect, actually collects DEC Firefly workstation [12] is the only comparative \nevaluation less than 4,000 cycles. This explains j avac's poor performance of multiprocessor garbage \ncollection techniques. His algorithm is in the single processor environment. based on Rovner's reference \ncounting collector [29] backed by a The number of cycles aborted due to concurrent mutation was concurrent \ntracing collector for cyclic garbage. Unfortunately, de- smaller than we expected, but these invalidations \nonly come into spite having implemented a great variety of collectors, he only pro- play when race conditions \nfool the cycle detection algorithm. vides a qualitative comparison. Nevertheless, our findings agree \nFinally, Table 5 compares the number of references that must with DeTreville's in that he found reference \ncounting to be highly be followed by the concurrent reference counting (\"Refs. Traced\") effective for \na general-purpose programming language on a multi- and the parallel mark-and-sweep (\"M&#38;S Traced\") \ncollectors. The processor. reference counting collector has an advantage in that it only traces The Recycler \ndiffers in its use of cycle collection instead of a locally from potential roots, but has a disadvantage \nin that the al- backup mark-and-sweep collector. The Recycler also uses atomic gorithm requires three \npasses over the subgraph. Furthermore, if exchange operations when updating heap pointers to avoid race \nthe root of a large data structure is entered into the root buffer fre- conditions leading to lost reference \ncount updates; DeTreville's im- quently and high mutation rates force frequent epoch boundaries, plementation \nrequired the user to avoid race conditions and was the same live data structure might be traversed multiple \ntimes. therefore unsafe. In this category, there is no clear winner. Each type of garbage Huelsbergen \nand Winterbottom [19] describe a concurrent al- collection sometimes performs one to two orders of magnitude \nmore gorithm (VCGC) that is used in the Inferno system to back up tracing than the other. To calibrate \nthe amount of tracing per- a reference counting collector. They report that reference count- formed, \n\"Trace/Alloc\" shows the number of references traced per ing collects 98% of data; our measurements for \nJava show that the allocated object for the reference counting collector. proportion of cyclic garbage \nis often small but varies greatly. The only measurements provided for VCGC were on a uniprocessor for \nSML/NJ, so it is difficult to make meaningful comparisons. 7.7 Throughput The only other concurrent, \nmultiprocessor collector for Java that we know of is the work of Domani et al [17]. This is a generational \nIn the previous section we measured our collectors in an envi- collector based on the work of Doligez \net al [16, 15], for which ronment suited to response time; we now measure them in an envi- generations \nwere shown to sometimes provide significant improve- ronment suited to throughput. Table 6 shows the \nresults of running ments in throughput. No response time measurements were pro- our benchmarks on a single \nprocessor. The mark-and-sweep col- vided. lector suffers somewhat since it is no longer performing collection \nThe other implemented concurrent multiprocessor collectors [2, in parallel. 18, 16, 27] are all tracing-based \nalgorithms for concurrent variants However, in this environment, the lower overhead of the mark- of ML, \nand generally have significantly longer maximum pause and-sweep collector dominates the equation, and \nit outperforms the times than our collector. In addition, ML produces large amounts the Recycler, sometimes \nby a significant margin. of immutable data, thereby simplifying the collection process. Of course, the \nRecycler is not designed to run in a single-threaded The collector of Huelsbergen and Larus [18] for \nML achieved environment; nevertheless, it provides a basis for comparing the in- maximum pause times \nof 20 ms in 1993, but only for two small herent overhead of the two approaches in terms of overall work \nbenchmarks (Quicksort and Knuth-Bendix). Their collector re- performed. quires a read barrier for mutable \nobjects that relies on processor consistency to avoid locking objects while they are being forwarded. \n Read barriers, even without synchronization instructions, are gen- erally considered impractical for \nimperative languages [20], and on weakly ordered multiprocessors their barrier would require syn- chronization \non every access to a mutable object, so it is not clear that the algorithm is practical either for imperative \nlanguages or for the current generation of multiprocessor machines. In concurrently published work, Cheng \nand Blelloch [8] describe a parallel, concurrent, and incremental collector for SML. They take a much \ndifferent approach, essentially trying to solve the prob- lem of making a compacting garbage collector \nmeet stringent time bounds. Their approach requires such overheads as duplicating mu- mble fields, which \nwe did not consider acceptable in our collector. On the other hand, their collector is scalable while \nours is not. 8.1 Reference Counting The Recycler shares with Deutsch and Bobrow's Deferred Refer- ence \nCounting algorithm [ 13] the observation that reference count- ing stack assignments is prohibitive, \nand that periodic scanning of the stack can be used to avoid direct counting of stack references. Th \ne principal difference is the manner in which the stack references are handled. Deferred Reference Counting \nbreaks the invariant that zero-count objects are garbage, and requires the maintenance of a Zero Count \nTable (ZCT) which is reconciled against the scanned stack references. The ZCT adds Overhead to the collection, \nbecause it must be scanned to find garbage. The Recycler defers counting by processing all decrements \none epoch behind increments, and by its use of stack buffers. The result is a simpler algorithm without \nthe additional storage or scanning re- quired by the ZCT, albeit at the expense &#38;additional buffer \nspace. 8.2 Cycle Collection As described in Section 3, our cycle collection algorithm is de- rived from \nthe synchronous algorithm devised by Martinez et al [25] and extended by Lins to lazily scan for cyclic \ngarbage [23, 20]. Our synchronous variant differs in a number of important respects: its complexity is \nlinear rather than quadratic; it avoids placing a root in the root buffer more than once per epoch; and \nit greatly reduces overhead by not considering inherently acyclic structures. Lins has presented a concurrent \ncycle collection algorithm [24] based on his synchronous algorithm. Unlike the Recycler, Lins does not \nuse a separate reference count for the cycle collector; in- stead he relies on processor-supported asymmetric \nlocking primi- tives to prevent concurrent mutation to the graph. His scheme has, to our knowledge, never \nbeen implemented. The Reeyeler's concurrent cycle collector could in the worst case require space proportional \nto the number of objects (if it finds a cy- cle consisting of all allocated objects). This is not directly \ncompa- rable to concurrent tracing collectors, which push modified pointers onto a stack that must be \nprocessed before the algorithm completes. Since the same pointer can be pushed multiple times, the worst \ncase complexity appears as bad or worse than the Recycler's. In prac- tice, each algorithm requires a \nmoderate amount of buffer memory. 9. CONCLUSIONS We have presented the Recycler, a concurrent multiprocessor \ngarbage collector for Java implemented in Java. The Recycler com- prises novel algorithms for concurrent \nreference counting and cycle collection. Over a set of eleven benchmark programs including the full SPEC \nbenchmark suite, the Recycler achieves maximum mea- sured application pause times of 2.6 milliseconds, \nabout two orders of magnitude shorter than the best previously published results. We have measured the \nRecycler against an highly tuned non- concurrent but parallel mark-and-sweep garbage collector. When \nresources are scarce, the throughput-oriented design of the mark- and-sweep collector yields superior \nexecution times. But with an extra processor and some extra memory headroom, the Recycler runs without \never blocking the mutators, and achieves maximum pauses that are about 100 times shorter without sacrificing \nend-to- end execution time. The Recycler uses a novel concurrent algorithm for detecting cyclic garbage, \nand is the first demonstration of a purely refer- ence counted garbage collector for a mainstream programming \nlan- guage. It is competitive with the best concurrent tracing-based col- lectors. We believe these quantitative \nreductions will create a qualitative change in the way garbage collected languages are perceived, pro- \ngrammed, and employed. Acknowledgements We thank Anthony Cocchi, Jong Choi, Alex Dupuy, David Grove, \nChet Murthy, and Mark Wegman for providing helpful feedback at various stages of this project. Mike Burke \nand Mark Mergen provided moral support. David Grove also provided invaluable help with the optimizer. \nThe anonymous referees provided very detailed and thoughtful feedback which has greatly improved the \nquality of the paper, as has its shepherd, Wilson Hsieh. Rob Strom suggested the method we employed for \ndetecting dead cycles. Kathryn McKinley stimulated this work with her talk on a sophisticated generational \ncollector, convincing us (despite her best efforts) of the viability of reference counting for garbage \ncol- lection. 10. REFERENCES [1] ALPERN, B., ET AL. Implementing Jalapefio in Java. In ConJbrence on \nObject-Oriented Programming, Systems, Lan- guages, and Applications (Oct. 1999). SIGPLAN Notices, 34, \n   10, 314-324. [2] APPEL, A. W., ELLIS, J. R., AND LI, K. Real-time con- current collection on stock \nmultiprocessors. In Proceedings of the SIGPLAN Conference on Programming Language De- sign and Implementation \n(Atlanta, Georgia, June 1988), ACM Press, New York, New York. SIGPLANNotices, 23, 7 (July), 11-20. [3] \nARNOLD, M., FINK, S., GROVE, D., M.HIND, AND SWEENEY, P. Adaptive optimization in the Jalapefio JVM. \npp. 47-65. [4] BACON, D. F., KOLODNER, H., NATHANIEL, R., PE-TRANK, E., AND RAJAN, V. T. Strongly-connected \ncom- ponent algorithms for concurrent cycle collection. Tech. rep., IBM T.J. Watson Research Center and \nIBM Haifa Scientific Center, Apr. 2001. [5] BACON, D. F., AND RA.IAN, V. T. Concurrent cycle collec- \ntion in reference counted systems. In European Conference on Object-Oriented Programming (Budapest, Hungary, \nJune 2001), J. L. Knudsen, Ed., vol. 2072 of Lecture Notes in Com- puter Science, Springer-Verlag. [6] \nBOBROW, D. G. Managing re-entrant structures using ref- erence counts. ACM Trans. Program. Lang. Syst. \n2, 3 (July 1980), 269-273. [71 BOEHM, H. Personal communication. Hewlett-Packard Lab- oratories, 2000. \n[8] CHENG, P., AND BLELLOCH, G. A parallel, real-time garbage collector. In Proc. of\" the SIGPLAN Conference \non Programming Language Design and Implementation (Snow-bird, Utah, June 2001). SIGPLANNotices, 36, 5 \n(May). [9] CHENG, P., HARPER, R., AND LEE, P. Generational stack collection and profile-driven pretenuring. \nIn Proc. of the Con- ference on Programming Language Design and Implementa- tion (June 1998). SIGPLANNotices, \n33, 6, 162-173. [10] CHRISTOPHER, T. W. Reference count garbage collection. Software - Practice and \nExperience 14, 6 (June 1984), 503-- 507. [11] COLLINS, G. E. A method for overlapping and erasure of \nlists. Commun. ACM3, 12 (Dec. 1960), 655--657. [12] DETREVILLE, J. Experience with concurrent garbage \ncollec- tors for Modula-2+. Tech. Rep. 64, DEC Systems Research Center, Aug. 1990. [13] DEUTSCH, L. P., \nAND BOBROW, D. G. An efficient in- cremental automatic garbage collector. Commun. ACM 19, 7 (July 1976), \n522-526. [14] DIJKSTRA, E. W., LAMPORT, L., MARTIN, A. J., SCHOLTEN, C. S., AND STEFFENS, E. F. M. On-the-fly \ngarbage collection: An exercise in cooperation. In Hierar-chies andlnterfaces, E L. Bauer et al., Eds., \nvol. 46 of Lecture Notes in Computer Science. 1976, pp. 43--56. [15] DOLIGEZ, D., AND GONTHIER, G. Portable, \nunobtru-sive garbage collection for multiprocessor systems. In Conf. Record of the Twenty-First ACM Symposium \non Principles of Programming Languages (Jan. 1994), pp. 70--83. [16] DOLIGEZ, D., AND LEROY, X. A concurrent \ngenerational garbage collector for a multi-threaded implementation of ML. In Conf Record of the Twentieth \nACM Symposium on Princi- ples of Programming Languages (Jan. 1993), pp. 113--123, [17] DOMANI, T., KOLODNER, \nE. K., AND PETRANK, E. A generational on-the-fly garbage collector for Java. In Proc. of the SIGPLAN \nConference on Programming Language Design and Implementation (June 2000). SIGPLAN Notices, 35, 6, 274--284. \n[18] HUELSBERGEN, L., AND LARUS, J. R. A concurrent copying garbage collector for languages that distinguish \n(ira)mutable data. In Proc. of the Fourth ACM Symposium on Principles and Practice of Parallel Programming \n(May 1993). SIGPLANNotices, 28, 7 (July), 73-.-82. [19] HUELSBERGEN, L., AND WINTERBOTTOM, P. Very con- \ncurrent mark-&#38;-sweep garbage collection without fine-grain synchronization. In Proc. of the ACM SIGPLAN \nlnternational Symposium on Memory Management (Mar. 1999). SIGPLAN Notices, 34, 3, 166-174. [20] JONES, \nR., AND LINS, R. Garbage Collection. John Wiley and Sons, 1996. [21] KUNG, H. T., AND SONG, S. W. An \nefficient parallel garbage collection system and its correctness proof. In IEEE Symposium on Foundations \nof Computer Science (1977), pp. 120--131. [22] LAMPORT, L. Garbage collection with multiple processes: \nan exercise in parallelism. In Proc. of the 1976 International Conference on Parallel Processing (1976), \npp. 50--54. [23] LINS, R. D. Cyclic reference counting with lazy mark-scan. Inf. Process. Lett. 44, 4 \n(Dec. 1992), 215-220, [24] LINS, R. D. A multi-processor shared memory architecture for parallel cyclic \nreference counting. Microprocessing and Microprogramming 35, 1-5 (Sept. 1992), 563-568. Proceed-ings \nof the 18th EUROMICRO Conference (Paris, France). [25] MARTfNEZ,A. D., WACHENCHAUZER,R., AND LINS, R. \nD. Cyclic reference counting with local mark-scan. Inf Process. Lett. 34, 1 (1990), 31-35. [26] MCCARTHY, \nJ. Recursive functions of symbolic expressions and their computation by machine. Commun. ACM 3 (1960), \n184-195. [27] NETTLES, S., AND O'TOOLE, J. Real-time garbage collec- tion. In Proc. of the SIGPLAN Conference \non Programming Language Design and Implementation (June 1993). SIGPLAN Notices, 28, 6, 217-226. [28] \nRODRIGUES, H. C. C. D., AND JONES, R. E. Cyclic dis- tributed garbage collection with group merger. In \nProc. of the TweO~h European Conference on Object-Oriented Program- ming (Brussels, July 1998), E. Jul, \nEd., vol. 1445 of Lecture Notes in Computer Science, Springer-Verlag, pp. 249-273. [29] ROVNER, P. On \nadding garbage collection and runtime types to a strongly-typed, statically-checked, concurrent language. \nTech. Rep. CSL-84--7, Xerox Palo Alto Research Center, July 1985. [30] STEELE, G. L. Multiprocessing \ncompactifying garbage col- lection. Commun. ACM 18, 9 (Sept. 1975), 495-508. [31] WILSON, P. R., JOHNSTONE, \nM. S., NEELY, M., AND BOLES, D. Dynamic storage allocation: A survey and critical review. In Proceedings \nof lnternational Workshop on Memory Management (Sept. 1995).  \n\t\t\t", "proc_id": "378795", "abstract": "<p>The deployment of Java as a concurrent programming language has created a critical need for high-performance, concurrent, and incremental multiprocessor garbage collection. We present the <i>Recycler</i>, a fully concurrent pure reference counting garbage collector that we have implemented in the Jalape&#241;o Java virtual machine running on shared memory multiprocessors.</p><p>While a variety of multiprocessor collectors have been proposed and some have been implemented, experimental data is limited and there is little quantitative basis for comparison between different algorithms. We present measurements of the Recycler and compare it against a non-concurrent but parallel load-balancing mark-and-sweep collector (that we also implemented in Jalape&#241;o), and evaluate the classical tradeoff between response time and throughput.</p><p>When processor or memory resources are limited, the Recycler runs at about 90% of the speed of the mark-and-sweep collector. However, with an extra processor to run collection and with a moderate amount of memory headroom, the Recycler is able to operate without ever blocking the mutators and achieves a maximum measured mutator delay of only 2.6 milliseconds for our benchmarks. End-to-end execution time is usually within 5%.</p>", "authors": [{"name": "David F. Bacon", "author_profile_id": "81100628167", "affiliation": "IBM T.J. Watson Research Center", "person_id": "P60470", "email_address": "", "orcid_id": ""}, {"name": "Clement R. Attanasio", "author_profile_id": "81100186222", "affiliation": "IBM T.J. Watson Research Center", "person_id": "PP14074704", "email_address": "", "orcid_id": ""}, {"name": "Han B. Lee", "author_profile_id": "81450595125", "affiliation": "Department of Computer Science, University of Colorado, Boulder, CO", "person_id": "P334803", "email_address": "", "orcid_id": ""}, {"name": "V. T. Rajan", "author_profile_id": "81331502483", "affiliation": "IBM T.J. Watson Research Center", "person_id": "PP43115622", "email_address": "", "orcid_id": ""}, {"name": "Stephen Smith", "author_profile_id": "81332528255", "affiliation": "IBM T.J. Watson Research Center", "person_id": "PP31026049", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/378795.378819", "year": "2001", "article_id": "378819", "conference": "PLDI", "title": "Java without the coffee breaks: a nonintrusive multiprocessor garbage collector", "url": "http://dl.acm.org/citation.cfm?id=378819"}