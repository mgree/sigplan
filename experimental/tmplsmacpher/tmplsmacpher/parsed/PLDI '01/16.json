{"article_publication_date": "05-01-2001", "fulltext": "\n Timestamped Whole Program Path Representation and its Applications Youtao Zhang Rajiv Gupta Department \nof Computer Science The University of Arizona Tucson, Arizona 85721 ABSTRACT A whole program path (WPP) \nis a complete control flow trace of a program's execution. Recently Larus [18] showed that although WPP \nis expected to be very large (lOfts of MBytes), it can be greatly compressed (to 10's of MBytes) and \ntherefore saved for future analysis. While the compres- sion algorithm proposed by Larus is highly effective, \nthe compression is accompanied with a loss in the ease with which subsets of information can be accessed. \nIn particular, path traces pertaining to a particularj function cannot gen- erally be obtained without \nexamining the entire compressed WPP representation. To solve this problem we advocate the application \nof compaction techniques aimed at provid- ing easy access to path traces on a per function basis. We \npresent a WPP compaction algorithm in which the WPP is broken into path traces corresponding to individual \nfunc- tion cMls. All of the path traces for a given function are stored together as a block. Ability \nto construct the complete WPP from individual path traces is preserved by maintain- ing a dynamic call \ngraph. The compaction is achieved by eliminating redundant path traces that result from different calls \nto a function and by replacing a sequence of static basic block ids that correspond to a dynamic basic \nblock by a sin- gle id. We transform a compacted WPP representation into a timestamped WPP (TWPP) representation \nin which the path traces are organized from the perspective of dynamic basic blocks. TWPP representation \nalso offers additional opportunities for compaction. Experiments show that our algorithm compacts the \nWPPs by factors ranging from 7 to 64. At the same time informa- tion is organized in a highly accessible \nform which speeds up the responses to queries requesting the path traces of a given function by over \n3 orders of magnitude. *Supported by DARPA award no. F29601-00-1-0183 and National Science Foundation \ngrants CCR-0096122, EIA-9806525, and CCR-9996362 to the University of Arizona. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for profit or commercial advan-tage and that copies bear this \nnotice and the full citation on the first page. To copy otherwise, to republish, to post on servers or \nto redistribute to lists, requires prior specific permission and/or a fee. PLDI 2001 6/01 Snowbird, Utah, \nUSA &#38;#169; 2001 ACM ISBN 1-58113-414-2/01/06... $5.00 1. INTRODUCTION Profile data, in the form \nof basic block and edge profiles, has been extensively used for guiding the application of per- formance \nimproving code transformations including global instruction scheduling [11]. Till recently it was believed \nthat collecting path profiles is too expensive. However, Ball and Larus [4] showed that cost of acyclic \npath profiling is merely double the cost of collecting edge profiles. Encouraged by this result, Larus \n[18] further demonstrated that collecting a whole program path (WPP), which is the complete control flow \ntrace of a program's execution, is also feasible. This is because, although a WPP is typically very large \n(100's of MBytes), it can be greatly compressed (to 10's of MBytes) and therefore saved for future analysis. \nWhile the compression algorithm proposed by Larus is highly effective, the compression is accompanied \nwith a loss of ease in accessibility to information. For example, path traces pertaining to a particular \nfunction cannot generally be ob- tained without examining the entire compressed WPP rep- resentation. \nThis is a serious drawback because typically an application using the WPP can be expected to make a series \nof requests for profile data for individual functions, that is, each request is only for a small subset \nof the overall infor- mation contained in a WPP. Repeated extraction operations to satisfy these requests \nare likely to result in high analysis time costs. Therefore it is important to design a representa- tion \nfrom which path traces of individual functions can be rapidly accessed. We believe that the above loss \nof accessibility is a natu-ral consequence of treating the entire control flow trace as a single data \nstream during compression. As a result the information corresponding to a given function is scattered \nthrough out the compressed trace and can in general be lo- cated only by examining the entire compressed \ntrace. In order to solve this problem we advocate the application of compaction techniques which are \naimed at simultaneously reducing the size of the WPP and providing easy access to subsets of information \nwithin the WPP. We present one such WPP compaction algorithm in this paper. In this algorithm the WPP \nis broken into path traces corresponding to indi- vidual function calls and all of the path traces for \na given function are stored together as a block. Therefore informa- tion regarding a specific function \ncan be readily accessed. In order to ensure that the complete WPP can be recon- structed from individual \npath traces, a dynamic call graph which links the path traces together is also maintained. The compaction \nof WPPs is achieved by compacting the path traces using two techniques. First we eliminate dupli- cate \npath traces that result from different calls to the same function. This technique is very effective and \nresulted in re- ductions in the sizes of WPPs by a factors ranging from 5.66 to 9.5 in our experiments. \nThis is because although many functions are called numerous times, they tend to follow one of a small \nsubset of paths through the function body. For example, in a WPP collected from executing g\u00a2\u00a2 we found \nthat function _rtx_equal_p was called 355189 times but it generated only 35 unique path traces. The second \ntechnique we employ replaces a sequence of static basic block ids, that correspond to a dynamic basic \nblock, by a single id. A dy- namic basic block belonging to a path trace is a sequence of static basic \nblocks that is always entered from the first block and exited from the last block in the path trace. \nSince dynamic basic blocks often appear inside loops, they can be repeated many times in a path trace. \nThus, replacing them by a single id can significantly reduce the size of the WPP. We typically observed \nreductions by factors ranging from 1.35 to 4.24 using this technique in our experiments. While compacted \nWPPs provide easy access to information, they still do not represent path traces in a form that is suit- \nable for analysis which is performed from the perspective of basic blocks. In particular, we consider \na class of ap- plications that perform data flow analysis on the program and utilize the WPP information \nto gather data flow facts, including frequencies of data flow facts [20, 7, 13, 14, 15], which can be \nobserved to hold during the program execution represented by the WPP. Applications that fall in this \ncate- gory include identification of hot data flow facts for profile- guided code optimizers (static \nand dynamic) as well as de- bugging aids (dynamic slicing and currency determination algorithms). We \nrefer to such analysis as profile-limited data flow analysis. To address the above issue, we transform \na compacted WPP representation into a timestamped WPP (TWPP) represen- tation in which the trace information \nis organized from the perspective of dynamic basic blocks since data flow analysis is carried out from \nthe perspective of dynamic basic blocks. We demonstrate that TWPPs can be conveniently used by applications \nthat need to perform profile-limited data flow analysis including profile-guided optimizers and dynamic \nde- bugging algorithms. The TWPP representation also offers opportunities for compaction leading to compacted \nTWPPs with sizes that are significantly smaller than that of com. pacted WPPs. Compaction opportunity \narises because when a sequence of timestamp values are used to identify the po- sitions in a path trace \ncorresponding to a block's execution, often these sequences form an arithmetic series which can be represented \ncompactly. Our experiments indicate that the size of a compacted TWPP is often much smaller than that \nof a compacted WPP. In summary the contributions of this paper are as follows: We replace the compression \nstrategy proposed by Larus [18] by a compaction strategy which is also effective in reducing WPP sizes. \nMoreover compacted WPPs or-ganize trace information in an accessible form which allows quick access to \npath traces of any given func- tion. [Section 2] , We propose the timestamped WPP (TWPP) represen- tation \nwhich organizes trace information from the per- spective of dynamic basic blocks. This form is highly \nsuitable for applications that use WPPs to perform profile-limited data flow analysis. [Section 2] \u00ae \nOverall the above techniques were observed to com-pact the original traces by factors ranging from 7 \nto 64 and at the same time speedups of over 3 orders of magnitude was observed in responding to queries \nre-questing the path traces of a given function. Our tech- niques also compares favorably with Larus's \ntechnique for compressing WPPs. [Section 3] \u00ae Finally we present demand-driven algorithms for profile- \nlimited data flow analysis and illustrate their use in two applications: code optimizers and debugging \ntools. [Section 4]  2. COMPACTION ALGORITHM As mentioned earlier, a whole program path (WPP) is a complete \ncontrol flow trace of a program execution. Con-sider the program and a sample WPP shown in Figure 1. \nThe WPP shows that the loop in main iterates 5 times and in each iteration the function f is called. \nThe loop in func- tion :f iterates 3 times for each call. Looking at the WPP for a small program we observe \ntwo things: WPPs for real applications can be expected to be quite large (e.g., 100's of MBytes) and \nin its current linear form WPP is difficult to use (e.g., in order to extract trace information for a \nsubpath in main or function :f, we must examine the entire WPP). Next we present a step by step transformation \nof the above WPP to achieve two goals: compaction of the WPP to re- duce memory requirements and organization \nof the WPP information for faster access to path traces of individual functions. Partitioning WPP into \npath traces. We partition the WPP into path traces corresponding to in- dividual function calls and all \nof the path traces for a given function are stored together as a block. Therefore informa- tion regarding \na specific function can be readily accessed. In order to ensure that the complete WPP can be recon- structed \nfrom individual path traces, a dynamic call graph (DCG) which links the path traces together is also \nmain- tained. Figure 2 shows this representation of the WPP for our example program. Clearly from this \nrepresentation the WPP form of Figure 1 can be easily constructed. More im- portantly one can rapidly \nsearch for occurrences of a given path (intraprocedural or interprocedural). The path traces of interest \nare located and then examined for desired infbr- mation. To search for an occurrence of a path in main \nwe need to only examine 0ne-sixth of the total trace in Figure 2. Eliminating redundant path traces. \nThe WPP can be greatly reduced in size by eliminatin9 du- plicate path traces generated by different \ncalls to the same function. In Figure 2, corresponding to the 5 calls to func- tion :f, there are only \ntwo unique path traces. Therefore the WPP representation can be transformed to eliminate redundant path \ntraces as shown in Figure 3. This technique is very effective because although many functions are called \nnumerous times, they tend to follow one of a small sub- set of paths through the function body. For example, \nin a WPP collected from executing gcc we found that function _rtx_equal_p was called 355189 times but \nit generated only 35 unique path traces. fo main CD main( 1.2.3.f(1.2.7.8.9.6.2,7.8.9.6.2.7.8.9.6. IO) \nA. 2.3.f(1.2.7.8.9.6.2.7.g.9.6.2.Tg.9,6.10)A.2.3.f(t .2.3.4.5.5.2.3.4..5.6.2.3.4.5.6.10).4. 2.3.f(1.2.7.8.9.6.2.7.8.9.6.2.7.8.9.6.10).4. \n2.3.ff 1.2.3.4.5.6.2.3.4.5.6.2.3 A.5.6.10k4.6~ Figure 1: An uncompacted WPP. DCG Path Traces I ......................... \n~ 1.2.7.8.9.6.2.7.8.9.6.2.7.8.9.6.10 I Figure 2: WPP organized using the DCG. DCG PathTraces ~ ' ........... \n12'4 6 4 4 ........ ........ '.'.'.\".'.'.\" ..... :::::::::::::::::::: 1.2.7.8.9.6.2.7.8.9.6.2.7.8.9.6.10 \n] Figure 3: WPP after redundant path trace removal. Creating dictionaries of dynamic basic blocks. Another \ntechnique that we employ replaces a sequence of static basic block ids that correspond to a dynamic basic \nblockby a single id. A dynamic basic block (DBB) belonging to a path trace is a sequence of static basic \nblocks that is always entered from the first block and exited from the last block in the path trace. \nSince DBBs can often appear inside loops, they are often repeated many times in a path trace. Thus, replacing \nthem by a single id can significantly reduce the size of the WPP. Each path trace is processed as follows: \na dictionary of DBBs is created by constructing a dynamic control flow graph and finding chains of static \nblocks representing DBBs in it. Each DBB is assigned the block id of the first static block in it and \naccordingly the path trace is modified by deleting all but the first id in each occurrence of a DBB. \nOnce all compacted path traces and dictionaries are ob-tained, duplicate path traces and dictionaries \nare also elim- inated. In this transformed form, each node in the dynamic call graph has an associated \ntuple (t, d) where t is a path trace and d is a dictionary. Figure 4 shows the chains of static basic \nblocks that form dynamic basic blocks for the three path traces in Figure 3. After creating dictionaries \nand compacting path traces, we are left with one path trace and two dictionaries for function :f as shown \nin Figure 5. fo f0 CD main C&#38;#169; G3 1.2,3,4.Z3.4.2.3A.. 1.2.3.4,5.6.2.3.4, l .'2.7.8.9.6.2.7.8. \n2.3.4.2.3.4,2.3.4.5 5.6,2.3.4.5.6.10 9.6.2.7,8.9.6.10 Figure 4: DBBs and dynamic control flow graphs. \nDCG Path Traces DBB Dictionaries ~ _ ~ ill.2.2.,. .2.0I I 12.3.4 I &#38;#169; &#38;#169; (D GD &#38;#169; \n....... : ................................ ..................... 'iiiiiiiiiiiiiiiiiiiiiiiiiii!iiiiiiiiiiiiiiiiii!iiii! \n .... ..................................................... ; ....................... \u00a3, Figure 5: WPP \nafter creating dictionaries of DBBs. Timestamped WPP representation. In the WPP representation described \nso far the execution trace of a given function invocation is represented by a se- quence of basic blocks \nvisited during its execution. While such a path trace representation is adequate for identifying hot \npaths through a program, it is not the most appropri- ate for performing data flow analysis. Since profile-limited \ndata flow analysis is carried out from the perspective of basic blocks, it is more appropriate to organize \nthe traces from the perspective of dynamic basic blocks. Next we describe the timestamped WPP (TWPP) \nrepresentation which achieves this goal. The execution of the function can be viewed from the per- spective \nof time steps, where each time step corresponds to the execution of a dynamic basic block. Therefore \na path trace for a function call in WPP representation can be viewed as a mapping between time steps, \nor timestamps, and dynamic basic blocks. In contrast, the TWPPs rep-resent a mapping between dynamic \nbasic blocks and an or- dered sets of timestamps. Let T, B, and \"P(T) denote the set of timestamps, set \nof dynamic basic blocks, and the power set of timestamps associated with the path trace of a given function \ncall f. A path trace in WPP and TWPP forms is represented by the following mappings: WPPPath'IYace/: \nT ~ B TWPPPathTracey : B ~ P(T)  Consider the WPP of Figure 5. The WPP trace 1.2.2.2.2.2.6 corresponds \nto the following T ~/3 mapping: {1 ~ 2, 2 2, 3 --~ 2, 4 ~ 2, 5 ~ 2, 6 -~ 2, 7 ~ 6}. When transformed \nto TWPP form it is represented by the following B ~ P(T) mapping: {1 ~ {1}, 2 ~ {2,3,4,5,6}, 6 ~ {7}}. \nThe complete uncompacted TWPP for this example is shown in Figure 6. DCG Path Traces DBB Dictionaries \n.......... ! .............................. ]i .................  !! I l,t 1 l a * ~] i ............................. \ni ..+ ...~ .................... ~.-i ..... ................................................... i ....~ \n.......................... i ~ ............................................................ : ............................... \n! Figure 6: TWPP form. Compacting TWPP path traces. The path traces in TWPP form can be further compacted \nbecause often a subsequence of timestamp values correspond- ing a dynamic basic block forms an arithmetic \nseries. This situation arises particularly when the same path within a loop body is traversed repeatedly \nduring different loop it- erations. The subsequences that form arithmetic series are compacted yielding \na sequence of entries which are of the following form: l (singleton), l : h (l.l+ 1.l+2...h, i.e., series \nwith step 1), or l : h : s (I.l + s.l + 2s...h, i.e., series with step s). As we can see, depending upon \nits form, an entry is represented using one, two or three positive integer values. We store the timestaanps \ncorresponding to a block merely as a sequence of integers. For correct interpretation of the information \nwe need to encode the boundaries that separate the variable length entries. This information is encoded \nin the signs (+ or -) of the values and therefore it does not require any increase in the size of the \npath trace. In partic- ular, the last number in a each entry is stored as a negative number. By using \nthe sign to encode the end of an entry we limit the largest timestamp value that is available to us since \nwe can no longer use unsigned integers. However, our experience with the benchmarks considered shows \nthat the timestamp value does not overflow because individual path traces are much smaller than the complete \nWPP. Notice that the sequence of timestamps assigned to dynamic basic block 2 in Figure 6 form an arithmetic \nseries since block DCG Path Traces DBB Dictionaries ...................................... ; ............................ \n] B 1 I2 6 [ T[;11.2:-4, I \"51 ................................................. ~--...:......................... \ni..,; ........................................................................................... ! \n Figure 7: Compacted TWPP. 2 is executed repeatedly during successive loop iterations. Theretbre the \nTWPP can be compacted into: {1 ~ {-1}, 2 ~ {2 : -6}, 6 ~ {-7}}. Notice that the last number in each sequence \nis a negative number. The complete com- pacted form of TWPP for our running example is shown in Figure \n7. Compacting the DCG. The dynamic call gral~hS resulting from executions of large application programs \ncan also be quite large. Therefore in addition to compacting the path traces, we also compress the DCG. \nFor this purpose we considered the popular dictionary based approaches proposed by Ziv and Lempel [28, \n29]. In particular, we used Welch's variation of Ziv and Lempel's adaptive dictionary based technique \nwhich is also referred to as the LZW algorithm [26]. 3. EXPERIMENTAL RESULTS We have implemented the \nalgorithm described in the pre- ceding section and used it to compact WPPs for several benchmark programs \nfrom the SPECint95 suite. The origi- nal WPPs used in the experiments were generated using the Trimaran \ncompiler infrastructure [24]. A WPP consists of two parts: the dynamic call graph (DCG) and the individ- \nual traces for function calls (which we will collectively refer to as the WPP traces). The sizes of WPPs \nused in our ex- periments are shown in Table 1. The experiments are aimed at studying the effectiveness \nof our compaction techniques in reducing memory requirements and the effectiveness of organization of \nthe WPP information for faster access. Program DCG WPP Total ..... (M B) traces ,/MB) size (MB.). 9.99.go \n6.0 170.0 176:0 126.gcc 34:7 489.5 524.2 130. li 8.6 78.3 84.9 132.ijpeg 1.7 266.9 268.6 1:,.34. per1 \n3.4 41.5 ..... 44.9 Table 1= Sample input traces used in the experi-ments. Compaction study. Table 2 \nshows the sizes of the WPP traces in their various forms. As we can see, the three compacting transforma- \ntions, removal of redundant path traces, creation of DBB dictionaries, and transformation to compacted \nTWPP form are all very effective in reducing the WPP trace size. The 183 WPP trace after Compacted OWPP \n/ Program Redundancy Dictionary TWPP trace CTWPP removal -MB creation-MB -MB 099.go 27.0 (x6.30) 17.1 \n(xl.58) 17.6 (x0.97) 9.7 126.gee 86.5 (x5.66) 50.8 (xl.70) 32.9 (xl.54) 14.9 130.ii 8.5 (x9,2 .) 5.3 \n(xl:60) 1.1 (x4.81) 71.2 132.ijpeg 28.1 (x9.~0) 20.8 (xl.35) 5.7 (x3.65) 46.8 134.per1 7.2 (x5.7}) 1.7 \n(x4.24) 0.02 (x85.0) 2075.... Table 2: WPP trace compaction due to various transformations. Program Compacted \nCompacted TWPP (MB) ] Total Compaction DCG (MB) Traces I Dictionaries I (MB) factor 099.go 6.6 17.6 2.3 \n26.5 7 126.gee 13.8 32.9 4.9 51.6 10 130.1i 5.3 1.1 0.04 6.4 13 132.ijpeg 1.0 5.7 0.6 7.3 37 134.perl \n0.7 0.02 0.02 0.7 64 Table 3: Overall compaction factor. ratio of the sizes of original WPP traces (OWPP) \nand com-pacted TWPP traces (CTWPP) gives us the compression factor which varies from 9.7 to 2075 for \nour sample traces. The sizes of the WPP traces after each of the three trans-formations as well as the \ncompression factors corresponding to each of the transformations are also shown separately in parenthesis \nin Table 2. The results show that each of the transformations-is an important source of compaction. A \nlarge factor of size reduction comes from removing redun-dant (duplicate) path traces (5.66 -9.50). The \nreason for this large reduction becomes clear when we examine the data in Figure 8. This figure gives \nthe percentage of total func-tion calls (plotted along Y-axis) that can be attributed to functions with \nat most N unique path traces (N is plotted along the X-axis). For 130.1i, 132.ijpeg, and 134.perl programs \n57-80% of all function calls are attributable to functions with at most 5 unique path traces. For 126. \ngcc and 099. go over 50% of function calls are attributable to functions with at most 25 and 50 unique \ntraces respectively. Given that the number of function calls made during the runs of these benchmarks \nwere in hundreds of thousands, we can see that the degree of redundancy in path traces is very high. \n80 j/f 60 /.-/ ,,j 40  / __o o ...... 134.perl f 0 0 100 200 300 Number of unique trsces Figure 8: \nTrace redundancy. The creation of dictionaries results in compaction of WPP traces by factors ranging \nfrom 1.35 to 4.24. The conversion into compacted TWPP form results in further reductions. For four out \nof five benchmarks, compacted TWPP traces provide reductions in the sizes of WPP traces by factors ranging \nfrom 1.55 to 85. The only case in which compacted TWPP trace is slightly larger is the 099. go program \nwhere the compacted TWPP trace was 3% larger than compacted WPP trace prior to its conversion to TWPP \nform. These results are very encouraging because not only is the TWPP representation suitable for profile-limited \ndata flow analysis, it is also compact. The breakdown of different components of a WPP and the overall \ncompaction factors for the complete WPP (DCG + WPP trace) are given in the Table 3. For the sample WPPs \nused in these experiments the overall WPP compaction fac-tor ranges from 7 to 64. Access time study. \nTo study the impact of reductions in the WPP size on the speed with which the path traces can be accessed, \nwe con-ducted an experiment which measured the time it took to extract the path traces corresponding \nto a single function from the complete WPP. The speedups we can expect resalt from two sources. First \ndue to the compaction of the WPP we have to read through a smaller file. Second we organize the contents \nof the file to allow faster access. Followed by the dynamic call graph, the path traces (including dictionaries) \nof the most frequently called function are stored first and that of least frequently called function \nare stored last. By remembering the position of information for each function in the file, and storing \nit as a header in the compacted TWPP file, we can access the path traces for individual functions rapidly. \nTable 4 shows the times taken to extract a function's trace in the following scenarios: extraction from \nuncompacted file (column U); and extraction from compacted file (column C). Both the average and maximum \ntimes for U and C are given. On art average the access times are reduced by over 3 orders of magnitude. \nProgram _]~]-::avg'U(m\u00a7] max ]avg.C/mSm)ax_~ Speedup ) ....  c/c(avg.)] 099.g0 ~033 83s3 8 143s ::193 \nt 126.gcc 22879 29672 6 528 i32.~jpeg -~ 7615 11447 6 258 1269  130.1i -~390 3263 2 124 ~4 s 134.perl \n1303 ' 1873 0.2 3 Table 4: Extraction times for a single function. Larus ' s Sequitur based compression \nalgorithm. We have also implemented Larus's compression algorithm which is based upon Sequitur [19]. \nThis algorithm produces the compressed WPP representation which is in the form of a grammar that generates \na single string - the original trace. We compared the Sequitur generated grammar representa- tion with \nthe TWPPs generated using our approach in two ways: their sizes and the access times to individual function \ntraces. The results of this comparison are shown in Table 5. On an average, the total size of the grammar \nproduced by Se- quitur is smaller than the corresponding size of the com-pacted TWPP by a factor of 3.92. \nNow lets consider the time it takes to extract the trace corresponding to a single function from the \ncomplete compacted trace. The extraction of a function's trace from the Sequitur generated grammar essentially \nrequires two steps: reading in the grammar and then processing it to generate a subgrammar corresponding \nto the functions trace. The total time taken for extraction, and the times for each of the steps, are \nshown in Table 5. These numbers represent averages over all functions present in the respective programs. \nThese times range from 10's to 1000's of milliseconds. In contrast, the TWPP is so orga- nized that we \ncan locate and extract the trace in few (< 10) milliseconds. The access times for Sequitur grammars are \ngreater than access times of TWPPs by factors ranging from 89 to 553. In summary, although TWPPs are \nlarger in size by an average factor of 3.92, they provide access times that are lower by an average factor \nof 309. These experiments simply show that the two representations embody design decisions with different \nspace time trade-offs. Program I Compacted\"size [ Extraction time I Sequitur TWPP Sequiturr (ms) TWPP \n(MB) ] (MS). [read+process=total ~ms) 099.g0 8.4 26.5 622 + 1315 = 1937 8 126.gcc 11.2 51.6 898 + 2423 \n=3321 6' 132.ijp~g 0:7 ..... 6.4 .... 544'+ 1650 = 2194 6 130.1i 7'~8 ' 7.3 47 + 132 = 179 2 .... 134.per1 \n0.4 0.7 . 29 + 30 ---- 59 0.2 Table 5: Compacted trace sizes and extraction times. Apart from the different \nsize and access time characteristics, the two representations also impact on the design of analysis algorithms \nthat will use them. While Larus's techniques is suitable for analysis of hot paths (i.e., collection \nof data flow facts that hold along frequently executed paths), our repre- sentation is suitable for collecting \nhot data flow facts (data flow facts that hold frequently at various program points). One of the advantages \nof our approach is that TWPPs are in the form required for profile-limited analysis. In contrast the \ncompressed WPPs produced by Sequitur require some amount of preprocessing before they can be used by \nan ap- plication. In the next section we demonstrate the use of TWPPs in carrying out profile-limited \ndata flow analysis.  4. PROFILE-LIMITED DATA FLOW Next we present a systematic approach for profile-limited \ndata flow analysis which is aimed at answering data flow queries with respect to a given WPP. Examples \nof such queries are: does a data flow ]ac~ hold? or how often does a data flow fact hold at a program \npoint? with respect to a given WPP. Such analysis is useful for profile-guided compile-time optimization \nof programs [2, 7, 3, 11, 23, 13, 14, 15], dynamic optimization of programs [3, 6] (here the profile \nrepresents a partial execution history of the program which is used to optimize the remainder of the \nprogram's execution), and debugging of programs [10, 17, 1]. The analysis we present focuses on gathering \nhot data ~low facts that hold during the execution of frequently called functions. Such analysis can \nbe used to clone and create a specialized (optimized) copy of the function. For this anal- ysis, we do \nnot need access to the entire TWPP but only a subset of information corresponding to the function under \nconsideration. In particular, we use a timestamp annotated dynamic control flow graph for the given path \ntrace which is described below. 4.1 Timestamp annotated dynamic CFG This representation consists of the \ndynamic control flow graph in which DBBs are annotated with timestamp vec-tors. This representation is \nquite adequate for data flow analysis because we can trace the WPP using the times- tamp vectors associated \nwith the dynamic basic blocks and limit the exploration of only those control subpaths that appear as \npart of the WPP during data flow analysis. The following characteristics make this proposed representation \nparticularly attractive for profile-limited data flow analysis. First it allows efficient backward and \nforward traversal of the path trace starting from any arbitrary point in the path trace. A timestamp \nand program point pair (t, n) together specify a particular point in the path trace. The preceding point \nis (t -1, m) where m is the predecessor of n in the dynamic control flow graph labeled with timestamp \nt -1. Similarly the succeeding point is (t+l, s) where s is a succes- sor of n in the dynamic control \nflow graph which is labeled with timestamp t + 1. Second it allows efficient simultaneous traversals \nof multiple subpaths in the path trace. A vector of timestamps at a pro- gram point ('~, n) can be used \nto represent multiple traversal points. Each element in the vector can be incremented or decremented \nand resulting timestamps can be matched with timestamps of predecessors and successors to continue si- \nmultaneous traversal along multiple subpaths. Compaction of tirnestamps directly attributes to the e~ciency \nof traver- sals. For example consider a series of timestamps repre-sented by (2:20:2) in our representation. \nA simple incre- ment/decrement resulting in (3:21:2)/(1:I9:2) corresponds to simultaneous forward/backward \ntraversal along 10 sub- paths in the path trace. An indicator of the relative costs of profile-limited \nanalysis and traditional static analysis are the cumulative sizes of static and dynamic fiowgraphs (see \nTable 6). ~Ve compared the total number of nodes (N) and edges (E) in the static and dynamic flow graphs. \nFor a given function multiple dynamic flow graphs can result because of multiple unique traces associated \nwith it. The nodes and edges in all of these graphs were counted in computing the cumulative size of \nthe dynamic flow graphs. From the results in Table 6 we can see that the number of nodes and edges in \nthe dynamic graphs axe typically much smaller than those in the static graphs. However, the cost of profile-limited \nanalysis is also dependent upon the size of timestamp vector associated with each node. Average size \nof the timestamp vector is shown in the last column of Table 6 (the value in parenthesis is the size \nof the vector before compaction - the results show that timestamp vector is significantly reduced in \nsize using our compaction technique). In summary, the data in Table 6 indicates that while, as expected, \nprofile-limited analysis is more expensive than static analysis, it has a reasonable cost. Program ] \nStaticFG I DynamicFG N' 1 ,,E ~N I ~E ] avg. I'~[ .O99.g0 10823 16236 4739 16591 11.9 (15.7) 126.gcc \n66571 104379 8838 20012 14.0 (33.1) 130.1i 2701 3536 265 289 51.2 (410.3) 132.ijpeg 57i8 ! 8105 754 1213 \n18.1 (109.7) 134.per1 13117 19539 501 674 3.9 (616.8) Table 6: Sizes of static and dynamic flow graphs. \n  4.2 Demand-driven analysis It is natural to formulate profile-limited analysis in a demand- driven \nfashion [9, 21]. This is because the applications of profile-limited analysis request information incrementally. \nFor example, during debugging a user typically makes a re- quest for the dynamic slice corresponding \nto only one vari- able at a fixed program point (i.e., we only need to com- pute subset of data flow \ninformation for subset of program points). Similarly during profile-guided or dynamic code optimization, \nsubset of profile-limited data flow information may be requested by the optimizer for subset of program \npoints in hot regions of the program [6]. Queries for profile-limited data flow. A profile-limited data \nflow query is of the form < T, n >a, where n is a node, T is a subset of timestamps for n in the path \ntrace, i.e., T C T(n), and d is the data flow fact of interest. This query represents a request for determining \nwhether or not d holds true prior to n's executions corre- sponding to timestamp values in T. Therefore \nthe query < T(n), n >d determines the data flow solution correspond- ing to all executions of n in a \ngiven path trace. The solution to this query allows us to determine if d always holds true, never holds \ntrue, and holds true sometimes for the given path trace. In fact solving such queries allows us to deter- \nmine the frequency with which d holds true with respect to the given path trace [20, 7, 13, 14, 15]. \n Query propagation. We consider profile-limited demand-driven backwardpropa- gation of queries for GEN-KILL \nproblems because they arise both during code optimization and debugging. For simplic- ity, we consider \nthe analysis of intraprocedural paths. How-ever, in analyzing these paths we will take into account the \neffects of any function calls that a path trace may contain. Our techniques can be easily extended to \nhandle interproce- dural paths by analyzing path traces of multiple functions in concert and propagating \nqueries along interprocedural paths [9]. The demand-driven propagation begins at a point n when the query \n< T, n >a is raised. For GEN-KILL pr%blems it is appropriate to propagate a timestamp vector, T, which \ncontains one slot for every timestamp, or more precisely, for every entry in the compacted TWPP path \ntrace. The propa- gation should be viewed as simultaneous (or parallel) search for data flow solutions \ncorresponding to each timestamp in T. Each slot in \"T is initialized to the timestamp value(s) to which \nit corresponds. The propagation of this 'T begins at n. We must ensure that query propagation is consistent \nwith the path trace under consideration. As discussed earlier in this section, this goal is easily accomplished \nusing the times- tamp annotated dynamic control flow graph representation. It is possible to correctly \nmanipulate the timestamp vector during propagation such that the timestamps in the vector are propagated \nonly to the appropriate predecessors. When a node that answers the query (true or false) with respect \nto a particular timestamp is encountered, the propagation on behalf of that timestamp ceases. Otherwise \nequivalent queries are generated and propagated along the path trace. The query < T, n > represents the \nsearch for dynamic GEN- KILL points correspor~ding to timestamps of n for which slots were created in \nT. For carrying out the propagation we must first compute dynamic GEN-KILL sets (i.e, sets wrt to a given \nTWPP) for a data flow fact d which are denoted as DGENn d and DKILLdn. Although n is a dy- namic basic \nblock, to simplify the presentation we assume that n contains a single statement. If node n contains \na call to function f, then the traces for calls made by the n's instances corresponding to T(n) axe examined. \nThe set GEN](T(n)) (KILL~ (T(n))) contains the subset of times- tamps from T(n) for which call to function \nf generates (kills) d. If node n simply contains a statement, the dy- namic sets are computed from the \nstatic GEN and KILL sets for node n denoted below as SGENn and SKILLs. { GEN~(T(n)) ifncallsf DGEN~ = \nT(n) elseif d 6 SGENn q) otherwise { KILL~(T(n)) ifncallsf DKILLdn ---- T(n) el~eif d e SKILLn \u00a2 otherwise \n..... Now let us consider query propagation. The timestamp val- ues in '~ axe each decremented by 1 \nduring every step of backward propagation. Only those resulting timestamp val- ues which are present \nin T(m), where m is a predecessor node, are propagated to m. At m the query for a times- tamp may be \nresolved as true Oft E DGENd~) or as false (if t E DKILLdm). If it is not resolved, then the above process \nis repeated starting with the decrementing of the timestamp and propagation continues. It should be noted \nthat only a subset of slots may be relevant for a given predecessor node; thus the other slots will contain \na null value denoted by 1. The above rules are stated precisely below and are further illustrated by \nexample applications discussed in the subse- quent sections. Propagation of < U,n > N--oration: T/7 -\u00a2 \nis a timestamp vector st _(~/W')/= if (T)i E 7-' then (U)/ else \u00b1. Slots in T resolved as true are slots \nin vectors U (T-1) / DGEN~ which do not contain k. ~nEpred(n) Slots in U resolved as false are slots \nin vectors (\u00a2 - ) / DKILLdm which do not contain .1.. raepred(n) Queries propagated for unresolved slots \nin [_J < (:- f) / (T(m) -DGENa~-DgInLam),m > mEpred(n) 4.3 Applications In this section we illustrate \nthe use of timestamp annotated dynamic CFG and the demand driven analysis described in the preceding \nsection. 4.3.1 Profile-guided Optimization A profile-guided optimizer identifies data flow facts that \naxe observed to hold for hot regions of the code and exploits them to generate highly optimized code. \nThis approach has been shown to be effective for variety of optimization tasks [7, 3, 11, 23, 13, 14, \n15]. Both non-speculative [22, 16] and speculative [14, 15, 7] transformations have been developed for \nspecialization of code along hot program paths. In this section we illustrate the use of profile-limited \nanalysis in profile-guided optimization. Consider a load instruction which is executed frequently and \noften causes cache misses to occur. In order to reduce the number of times this in- struction is executed, \nwe would like to determine the degree of redundancy in this instruction, that is, how often is the load \nis redundant because the loaded value is already avail- able in some register. Rough estimate of the \nfrequency of the data flow fact, the load is redundant, can be estimated using techniques based upon \nedge frequencies [20, 5, 7, 8] or acyclic path profiles [4, 13, 14, 15]. However, to obtain a precise \nvalue of degree of redundancy we require the use of an analysis based upon WPPs such as the profile-limited \nanalysis. Let us assume that we are interested in computing the de- gree of redundancy present in the \nload instruction in node 4 (4_Load) of the example shown in Figure 9. This load is redundant due to the \nload in node 1 (l_Load) as long as we arrive at it without visiting node 6 which contains a killing store \n(6_Store). Let us assume that the loop is executed 100 times during which it follows the given path trace. \nIf we simply consider the execution frequencies of the nodes we cannot determine the degree of redundancy. \nWe know that 4_Load executes 60 times, 1.Load executes 100 times, and 6_Store executes 40 times. However, \nfrom these frequencies we cannot tell how often l_Load is killed by 6_Store prior to reaching 4_Load. \nWhile bounds on the degree of redundancy can be computed using techniques in [5, 8], precise degree of \nredundancy cannot always be found. On the other hand if we make use of profile-limited analysis which \nexploits the timestamps labeling the nodes, we can easily determine that 4_Load is always redundant for \nthe given path trace. This information can be used by the optimizer to transform the program using code \nmotion and/or restructuring [22, 16, 14, 7]. The query propagation that identifies that the redundancy \ncount for 4_Load is 60, that is, degree of redundancy is 100%, is also shown in Figure 9. As we can see, \nthe degree of redundancy has been computed using a single backward pass through the loop body and only \n6 queries were gener- ated in this process. This example illustrates the benefit.,; of demand-driven \nanalysis and compaction of the timestamps. Although the loop executes for 100 iterations, demand-driven \nanalysis begins by considering the 60 iterations during which 4_Load is executed. Instead of dealing \nwith each of the 60 timestamps of 4..Load individually, we are able to effi-ciently manipulate the compacted \ntimestamps collectively during query propagation. This is analogous to the manner in which many array \ndata flow analysis techniques achieve efficiency by propagating ranges representing array sections, as \nopposed to propagating individual array elements [12, 27]. I--> 1:496:5 Load ]~ <[4:299:5],4> 2-->2:297:5 \n<[3: lig:51,3> <[203:298:51,7> <12,197:51,2> <1~2:297 51,2 3-->3:198:5 7-->203:498:5 <11:196:51,1> \n<[201:2~:51,| > 4-- GEN GEN (fr~,= 40) (freq.= 20) WPP: (L2.3,4.5)~0 (I.2.7.4.5)^20 (1.6.7.5)~10 Figure \n9: Detecting dynamic load redundancy. 4.3.2 Program Debugging During debugging the user typically interrupts \nprogram ex- ecution and requests information specific to that particular program execution. The TWPP \ncorresponding to partial program execution up to the breakpoint can be quite useful in accurately answering \nuser queries. There are two spe- cific debugging problems that can use profile-limited anal- ysis: dynamic \nslicing and dynamic currency determination during symbolic debugging of optimized code. Dynamic program \nslicing. Static backward program slicing was first proposed by Weiser as a debugging aid [25]. An even \nmore precise form of slic- ing, called dynamic slicing was proposed by Korel and Laski [17]. Most recently \nAgrawal and Horgan [1] developed three dynamic slicing algorithms which trade-off precision in the computed \nslice with the time it takes to compute the slice. Each of these algorithms constructs a different specialized \nprogram dependence graph (PDG) to capture the depen- dences exercised in a given execution. A backward \ntraver- sal over the graph is used to compute ~he dynamic slice as a transitive closure over data and \ncontrol dependences. Each of the above dynamic slicing algorithms can be imple- mented using one common \nrepresentation, the timestamped dynamic control flow graph, and thus we can avoid con-structing specialized \ngraphs suggested in [1]. Next we describe the implementations of the three dynamic slicing algorithms \nin [1] and show how they can implemented using our approach. We will illustrate these algorithms using \nthe example program and its execution history shown in Figure 10. Approach 1: This method marks all executed \nnodes in the PDG during the execution. The backward traversal to iden- tify the statements in the dynamic \nslice is allowed to visit only the marked nodes. These marked nodes are essentially the nodes with non-empty \ntimestamp sets in our TWPP representation. Therefore in our implementation the back- ward traversal of \na query through the timestamp annotated CFG is allowed to traverse only nodes that have a non-empty timestamp \nset. When a dependence is identified under such a traversal, the statement at which the dependence origi- \nnates is added to the dynamic slice. In our example, all statements are executed. Therefore the dynamic \nslice is the same as a static slice, which contains all nodes except node 10. Approach 2: This method \nmarks all executed edges in the PDG during the execution. The backward traversal to iden- tify the statements \nin the dynamic slice is allowed to only traverse marked edges. Our backward analysis uses times- tamps \nto find dependences can carry out a similar traversal by ensuring that an edge from node n to node m \nis traversed only if the query at node rn contains timestamp t and the timestamp t -1 is associated with \nnode n. More over since this algorithm does not distinguish between different times- tamps corresponding \nto a node, when a dependence is found, and new queries are generated at a node, all timestamps of that \nnode are included in the newly generated query for fur- ther propagation. In the example, we will be \nable to get the dynamic slice which inlcudes all nodes except node 3 and 10. Approach 3: This method \nduplicates executed node and its dependence edges during the execution so that it can dis- tinguish between \nthe instances of a given statement. This expanded graph is traversed to find the precise dynamic slice. \nOur backward analysis uses timestamps to find de- pendences and when a dependence is found we only a \nsingle timestamp is added to the newly generated queries. In other words we identify the precise instance \nof the assignment (for data dependence) and predicate (for control dependence) which is the source of \nthe dependence and generate queries only for the corresponding instances of variables that are read by \nthe assignment or predicate. In our example, note that although statements 8 and 3 are executed, they \nare not included in the slice because the value of Z at 13 depends only upon the values of Y and J computed \nby statements 7 and 1L The detailed propagation of queries for the three algorithms are shown in Figure \n11. The queries of the form < T,n >v where 7\" is the timestamp vector, n is the node at which the query \nis to be evaluated, and V is the variable whose definition is to be found. Therefore, a request for a \nslice on Z at line 14 is translated into the query < [30], 14 >z. In case of the first algorithm the \ntimestamp is not needed and therefore the query has the form <., 14 >z. All queries generated axe given \nin the first column of Figure 11. The updated slice after the processing of a query is given in the corresponding \nentry of the second column and the type of dependence (control or data) that caused the addition of a \nstatement to the slice is also indicated. 1 -+ 1 read N 2-+2 I----1 3-+3 J=0 4-+4:28:8 whileI< Ndo 5-+5:21:8 \nreadX 6 -+ 6 : 22 : 8 if X < 0 then 7 -+ 7,23 Y ----ffl(X) 8 -+ 15 else Y = f2(X) 9 -+ 8 : 24 : 8 Z = \nf3(Y) 10-+ 9 : 25 : 8 write Z 11-+10:26:8 J =1 12-+ 11:27:8 I--I+l endwhile 13--+29 Z=Z+J 14 -+ 30 breakpoint \n- request slice for Z Input: (N = 3, X = -4, 3, -2) WPP: 1.2.3.4.5.6.7.9.10.11.12 4.5.6.8.9.10.11.12 \n4.5.6.7.9.10.11.12 4.13.14 Figure 10: Dynamic slicing example Finally the worst case time complexity \nof our implementa-tion is the same as that of Agrawal and Horgan's algorithm. Primary cost of both algorithms \ncomes from processing the control flow trace. Our algorithm must examine the entire trace to compute \nthe TWPP path trace representation while their algorithm must examine the trace to construct a dy- namic \ndependence graph. The main difference between the two approaches is as follows. Agrawal et al. compute \nall dy- namic dependences first and construct a graph using which any dynamic slice request can be processed \nusing a simple traversal. In contrast our approach computes relevant de- pendences for slicing requests \nupon demand (like Weiser's algorithm [25]). Since the same dependences may be rele- vant to different \nslicing requests, their recomputation must be avoided by caching the computed dependences. In other words \nour approach builds the dynamic dependence graph incrementally as slicing requests are processed. Dynamic \ncurrency determination. Profile-limited analysis can be used to address the problem of dynamic currency \ndetermination. The user carries out debugging from the perspective of an unoptimized program; however, \nthe code being executed is an optimized version of the program. Therefore when the user requests the \nvalue of some variable at a breakpoint, the value of the variable may or may not be current, that is, \nit may or may not correspond to the value that would have been observed by executing the unoptimized \nprogram. As shown in [10], timestamping of basic block executions is needed for dynamic currency de- \ntermination. The timestamp annotated dynamic flow graph is therefore adequate for solving this problem. \nApproach l:Slicing request: < *, 14 >~ Query Slice Dependence < *,14> Z {14} < *,13 >Z < *,13 >j {13,14} \ndata < *,4 >Z < *,4 >d< *,4 >i< *,4 >N {4,13,14} control < *, 3 >Z < *' 3 >1< *, 3 >N < *, 12 >Z< *, \n12 >j< *, 12 >i< *, 12 >N {3,4,12,13,14} data < *,2 >Z< *,2 >N< *,11 >Z< *,11 >i< *,11 >N {2,3,4,11,12,13,14} \ndata < *, 1 >Z < *, i0 >Z < *, 10 >i< *, 1O >N { 1,2,3,4 ,i 1,12)i3,14} data < *,9 >y< *,9 >1< *,9 >N \n{ 1,2,3~4,9,11,12)13,14} data < *,8 >X < *,8 >i\u00a2~ *,S >N < *,7 >X < *,7 >i< *,7 >N { 1,2,3,4,7,8,9,11 \n,I 2,13,14} data < *,6 >X< *,6 >i< *,6 >N {I,2,8,4,6,7,8,9,11,12,13,14} data,control <2 *,5 >i< *,5 >N \n{1,2,3,4,5,6,7,8,9,11,12,13,14~ data < *~4 >(< *,4 >M { 1,2,3,4,5)6,7,8,9,11,12,13,14~ solved querlea \nApproach 2: Slicing request: < [301, 14 >~ Query Slice Dependence < [30], 14 >Z {14} < [29],18 >Z< [29], \n13 >j {13,14) data < [28],4 >Z< [28], 4 >j< [4 : 28 : 8],4 >i< [4 : 28 : 8],4 >24 {4,13,14} control [27], \n12 >Z < [27], 12 >j< [3],3 >i< [11 : 27 : 8], 12 >i< [3],3 >N < Ell : 27 : 8]) 12 >N {4,13,13,14} data \n< [26], 11 >Z < [10 : 26 : 8], II >/< [2],2 >N < [10 : 26 : 8], ii >N {2,4,11,12,13)14} data < {26], \nI0 >z < [9 : 25 : 8}, 1o >i< [9 ~ 25 : 8], io >N {1,2,4,11,12,13,14} data < [8 : 24 : 8],9 >y< [8 : 24 \n: 8],9 >i< [8 : 24 : 8],9 >N { 1,2,4,9,11,12,13,14} data < [7,23], 7 >X < [15],8 >X< [7,23], 7 >i< [15], \n8 >i< [7,23], 7 >N< [15],8 >N { 1,2,4,7)8,9,11)I 2,13,14} data < [6 : 22 : 8],6 >/< [6 : 22 : 8],6 >1< \n[6 : 22 : 8],6 >N { 1,2,4,6,7,8,9,11,12,13~14} data,control < [5 : 21 : 8],5 >/< [5 : 21 : 8],8 >N {1,2,4,5,6,7,8,9,11,12,18,14} \ndata < [4 : 23 : 8],4 >i< [4 : 28 : 3],4 >N {1,2,4,5,6,7,8,9,11,12,13,14} solved queries Approach 3: \nSlicing request: < [30], 14 >~ Query Slice Dependence < [30], 14 >z (14} < [29], 13 >z < [29], 18 >j \n{13,14} data < [28],4 >Z< [28l, 13 >j< [28],4 >i< [28],4 >N {4,13,14) control < [27], 12 >Z< [27], 12 \n>j< [27], 12 >1< [27], 12 >N {4,12,i3,i4} data ~ 26],11 >Z< [26], 11 >i< [26], 11 >N {4,11,12,13,14} \ndata [25], 10 >Z< [25],10 >1< [25], I0 >N {4,11,12,13,14} data < [24],9 >y< [24],9 >l< [241,9 >N {4,9,11,12,13,14} \ndata < [23], 7 >X< [23],7 >i< [23], 7 >N {4,7,9,I 1,12,13,14} data < [22],6 >X < [22],6 >i< [22],6 >N \n{4,6,7,9,11,12,13,14} control < [3],8 >1< [3],3 >N { 2,4,5,6,7,9,11,12,13,14} data < [2I, 2 > N { 1,2,4,5,6,7,9.11,12,13,14} \ndata Figure 11: Implementing Agrawal and Horgan's dynamic slicing algorithms. The example in Figure 12 \nillustrates currency determina- \u00ae We presented profile-limited data flow analysis for GEN- tion. Assuming \nthat block 2 contains the last use of the KILL problems and demonstrated its application to value of \nvariable X, the second assignment to X in block 1 data flow frequency analysis for profile-guided opti- \ncan be moved to block 2 by the partial dead code elimination mization as well as debugging of programs. \noptimization. During the execution of the optimized code the user may request the value of X at a breakpoint \nplaced I )in block 3. Depending upon the path taken to arrive at the breakpoint the value of X may or \nmay not be current. X=. The WPP captures the path history and therefore allows ] ..= us to make the correct \nassertions as shown in Figure 12. The determination requires propagating a query to locate the definition \nof X that reaches block 3 and then ensuring that this is the same definition that would have provided \nthe value of X in the unoptimized code. 5. CONCLUDING REMARKS Before optimization After optimization. \n In this paper we have demonstrated the following. i * WPPs can be compacted without compromising acces- \ni sibility to profile data. The proposed techniques of redundant path trace elimination and dynamic \nbasic block dictionary creation effectively compact the WPP without compromising accessibility. 2-->99 \n..= 4-->99 * An organization of trace information based upon the dynamic call graph and timestamped dynamic \nbasic blocks is particularly appropriate for performing profile-limited   3 --> I00 ~ \\~----~> 100 \n data flow analysis. This representation is compact and breakpoint breakpoint provides rapid access to \npath traces of a given function. X is current, x is non-current. * Overall our techniques were observed \nto compact the original traces by factors ranging from 7 to 64 and at Figure 12: Detecting dynamic currency. \nthe same time speedups of over 3 orders of magnitude were observed in responses to queries requesting \nall of the trace information of a given function. 189 ..........~.... 6. REFERENCES [14] R. Gupta, \nD. Berson, and J.Z. Fang, \"Path Profile [1] H. Agrawal and J.R. Horgan, \"Dynamic Program Slicing,\" A \nCM SIGPLAN Conference on Programming Language Design and Implementation, pages 246-256, White Plains, \nNY, June 1990. [2] G. Ammons and J.R. Larus, \"Improving Data Flow Analysis with Path Profiles,\" ACM SIGPLAN \nConference on Programming Language Design and Implementation, pages 72-84, Montreal, Canada, 1998. [3] \nV. Bala, E. Duesterwald, and S. Banerjia, \"Dynamo: A Transparent Runtime Optimization System,\" ACM SIGPLAN \nConference on PTvgramming Language Design and Implementation, pages 1-12, Vancouver, Canada, June 2000. \n[4] T. Ball and J. Larus, \"Efficient Path Profiling,\" 29th Annual IEEE/ACM International Symposium on \nMicroarchitecture, pages 46-57, Paris, France, 1996. [5] T. Ball, P. Mataga, and M. Sagiv, \"Edge Profiling \nVersus Path Profiling: the Showdown,\" 25th ACM SIGPLAN-SIGA CT Symposium on Principles of Programming \nLanguages, pages 134-148, San Diego, CA, 1998. [6] R. Bodik, R. Gupta, and V. Sarkar, \"ABCD: Eliminating \nArray Bounds Checks on Demand,\" ACM SIGPLAN Conference on Programming Language Design and Implementation, \npages 321-333, Vancouver B.C., Canada, June 2000. [7] R. Bodik, R. Gupta, and M.L. Sofia, \"Complete Removal \nof Redundant Expressions,\" ACM SIGPLAN Conference on Programming Language Design and Implementation, \npages 1-14, Montreal, Canada, June 1998. [8] R. Bodik, R. Gupta, and M.L. Sofia, \"Load Reuse Analysis: \nDesign and Evaluation,\" ACM SIGPLAN Conference on Programming Language Design and Implementation, pages \n64-76, Atlanta, Georgia, May 1999. [9] E. Duesterwald, R. Gupta, and M.L. Sofia, \"Demand-Driven Computation \nof Interprocedural Data Flow,\" A CM Transactions on Programming Languages and Systems, Vol. 19, No. 6, \npages 992-1030, November 1997. [10] D.M. Dhamdhere and K.V. Sankaranarayanan, \"Dynamic Currency Determination \nin Optimized Programs,\" A CM Transactions on Programming Languages and Systems, Vol.. 20, No. 6, pages \n1111-1130, November 1998. [11] J.A. Fisher, \"Trace Scheduling: A Technique for Global Microcode Compaction,\" \nIEEE Transactions on Computers, C-30:478-490, 1981. [12] T. Gross and P. Steenkiste, \"Structured Dataflow \nAnalysis for Arrays and its use in an Optimizing Compiler,\" Software - Practice and Experience, Vol. \n20, No. 2, pages 133-155, Feb. 1990. [13] R. Gupta, D.A. Berson, and J.Z. Fang, \"Path Profile Guided \nPartial Dead Code Elimination using Predication,\" International Conference on Parallel Architecture and \nCompilation Techniques, San Francisco, CA, 1997, Guided Partial Redundancy Elimination Using Speculation,\" \nIEEE International Conference on Computer Languages, pages 230-239, Chicago, Illinois, May 1998. [15] \nR. Gupta, D. Berson, and J.Z. Fang, \"Resource-Sensitive Profile-Directed Data Flow Anaty~ds for Code \nOptimization,\" 30th Annual IEEE/A CM International Symposium on Microarchitecture, pages 558-568, Research \nTriangle Park, North Carolina, December 1997. [16] J. Knoop, O. Ruthing, and B. Stefien, \"Optimal Code \nMotion: Theory and Practice,\" ACM ~D'ansactions on Programming Languages and Systems, Vol. 16, No. 4, \npages 1117-1155, 1994. [17] B. Korel and J. Laski, \"Dynamic Program Slicing,\" ~aformation Processing \nLetters, 29:155-163, October 1988. [18] J. Larus, \"Whole Program Paths,\" ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 259-269, Atlanta, GA, May 1999. [19] C. G. Nevil-Manning and \nI.H. Witten, \"Linear-time, Incremental Hierarchy Inference for Compression,\" Data Compression Conference, \nSnowbird, Utah, IEEE Computer Society, pages 3-11, 1997. [20] G. Ramalingam, \"Data Flow Frequency Analysis,\" \nACM SIGPLAN Conference on Programming Language Design and Implementation, pages 267-277, Philadelphia, \nPA, May 1996. [21] T. Reps, S. Horwitz, and M. Sagiv, \"Precise Interprocedural Data Flow Analysis via \nGraph Reachability,\" 22nd ACM Symposium on Principles of Programming Languages, pages 49-61, 1995. [22] \nB. Stefien, \"Property Oriented Expansion,\" International Static Analysis Symposium, LNCS 11~5, Springer \nVerlag, pages 22-41, Germany, September 1996. [23] M. Smith, \"Better Global Scheduling Using Path Profiles,\" \n31th Annual IEEE/A CM International Symposium on Microarchitecture, pages 115-126, Dallas, Texas, Nov.-Dec. \n1997. [24] The Trimaran Compiler Research Infrastructure. Tutorial Notes, November 1997. [25] M. Weiser, \n\"Program Slicing,\" IEEE Transactions on Software Engineering, SE-10(4):352-357, July 1984. [26] T.A. \nWelch, \"A Technique for High-Performance Data Compression,\" IEEE Computer, pages 8-14, June 1984. [27] \nX. Yuan, R. Gupta, and R. Melhem, \"Demand-Driven Data Flow Analysis for Communication Optimization,\" \nParallel Processing Letters, Vol. 7, No. 4, pages 359-370, December 1997. [28] J. Ziv and A. Lempel, \n\"A Universal Algorithm for Data Compression,\" IEEE Transactions on Information Theory, Vol. 23, No. 3, \npages 337-343, May 1977. [29] J. Ziv and A. Lempel, \"Compression of Individual Sequences via Variable-Rate \nCoding,\" IEEE Transactions on Information Theory, Vol. 24, No. 5, pages 530-536, September 1978.  \n\t\t\t", "proc_id": "378795", "abstract": "<p>A <i>whole program path</i> (WPP) is a complete control flow trace of a program's execution. Recently Larus [18] showed that although WPP is expected to be very large (100's of MBytes), it can be greatly compressed (to 10's of MBytes) and therefore saved for future analysis. While the compression algorithm proposed by Larus is highly effective, the compression is accompanied with a loss in the ease with which subsets of information can be accessed. In particular, path traces pertaining to a particular function cannot generally be obtained without examining the entire compressed WPP representation. To solve this problem we advocate the application of <i>compaction</i> techniques aimed at providing easy access to path traces on a per function basis.</p><p>We present a WPP compaction algorithm in which the WPP is broken in to <i>path traces</i> corresponding to individual function calls. All of the path traces for a given function are stored together as a block. Ability to construct the complete WPP from individual path traces is preserved by maintaining a <i>dynamic call graph</i>. The compaction is achieved by eliminating <i>redundant path traces</i> that result from different calls to a function and by replacing a sequence of static basic block ids that correspond to a <i>dynamic basic block</i> by a single id. We transform a compacted WPP representation into a <i>timestamped</i> WPP (TWPP) representation in which the path traces are organized from the perspective of dynamic basic blocks. TWPP representation also offers additional opportunities for compaction.</p><p>Experiments show that our algorithm compacts the WPPs by factors ranging from 7 to 64. At the same time information is organized in a highly accessible form which speeds up the responses to queries requesting the path traces of a given function by over 3 orders of magnitude.</p>", "authors": [{"name": "Youtao Zhang", "author_profile_id": "81100126819", "affiliation": "Department of Computer Science, The University of Arizona, T ucson, Arizona", "person_id": "PP15023478", "email_address": "", "orcid_id": ""}, {"name": "Rajiv Gupta", "author_profile_id": "81100027751", "affiliation": "Department of Computer Science, The University of Arizona, T ucson, Arizona", "person_id": "PP43126354", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/378795.378835", "year": "2001", "article_id": "378835", "conference": "PLDI", "title": "Timestamped whole program path representation and its applications", "url": "http://dl.acm.org/citation.cfm?id=378835"}