{"article_publication_date": "10-01-1973", "fulltext": "\n Advice on Structuring Compilers and Proving Them Correct t . Permission to make digital or hard copies \nof part or all of this work or personal or classroom use is granted without fee provided that copies \nare not made or distributed for profit or commercial advantage and that copies bear this notice and the \nfull citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute \nto lists, requires prior specific permission and/or a fee.&#38;#169; 1973 ACM 0-12345-678-9 $5.00 F. \nLockwood Morris Syracuse University The purpose of this paper is to advise an approach (and to support \nthat advice by discussion of an example) towards achieving a goal first announced by John McCarthy: that \ncompilers for higher-level programming languages should be made completely trust\u00adworthy by proving their \ncorrectness. The author believes that the compiler-correctness Problem can be made much less cfeneral \nand better-structured than the unrestricted ~ro\u00adgram-correctness problem; to d; so will of course entail \nrestricting what a compil~r may be. The essence of the present advice is that a proof of compiler correctness \nshould be the proof that a diagram of the form source target compile language -language . LT Y source \ntarget semantics semantics @Q i1 source target -decode meanings ~ meanings M 6u  commutes. (The symbols \nin the diagram refer to the example to be given below.) It is of course not very startling to regard \na compiler as a function assigning target language programs to source language programs; however, the \nrest of the diagram does have a non\u00ad vacuous content: it insists that semantics should be an actual function \nassigning defi\u00ad nite mathematical objects ( meanings ) to programs--usually partial functions of some \nfairly complicated type. That is, it rejects interpretive forms of semantic definition, such as those \nprovided by the Vienna definition method, or by sets of reduction rules of some form, which only provide \nfor any given pair of program and input data some prescrip\u00adtion for finding the output (if any). The \nbottom, decoding side of the diagram is merely an allowance for the highly probable eventuality that \nthe meanings of target lan\u00adguage programs are not identical with, but only represent in some adequate \nway the mean\u00adings of the source language programs from which they were compiled. There i.s one crucial \nelaboration to what has just been said: it is further advised that the corners of the diagram should \nbe made not merely sets but algebras and that the arrows should be homomorphi.sms. Specifically, heterogeneous \n(universal) algebras, as defined in (l), seem to be the appropriate tool. Brieflyr a heterogeneous algebra \nhas a number of sets of elements of different types, its phyla, which are connected bV a family OE operations, \neach taking a f~nlte number of arguments of specified types and producing a result of specified type. \nFor a homomorphism to exist between two hetero\u00adgeneous algebras, their operations must have corresponding \nargument and result types under a suitable pairwise correspondence of the phvla, and for a set of functions \nbetween the corresponding phyla to constitute a homomorphism, it must respect the operations in the same \nway as does a conventional homomorphism, e.g. of groups. That is, a homomor\u00adphism ~: A+A-of heterogeneous \nalgebras, where S, T, . . . , U, V are any phyla of A, S , T>, . . ..ti ~ V the corresponding phyla of \n~ , and where O: SXTX. ..XU+V, o : s xT x. ..x IJ +v are any corresponding operations of A and of A , \nmust satisfy the equation o(o(s,t, . . . ru)) = O-(o(s), o(t),. ..o(u)) Y Work supported by ARPA contract \nno. DAHC04-72-C-OO03. for all SES, teT, . . . . UEU. Sets SO@, TocT, . . . . UOCU are said to be generating \nsets for A if every element of every phylum is a f~nite combifiation of elements of SO, TO,-, UO. The \nbulk of the present paper will be devoted to putting some flesh on the maxims just given by applying \nthem to the statement and partial proof of,a simple compiler cor\u00ad rectness problem. We begin at once \nby introducing an example programming language. (No claim whatever will be made for it as a well-designed \nlanguage; it is intended merely to comprise an assortment of familiar features which the author thinks \nhe knows how to describe algebraically. ) To give an intuitive idea of what is modelled, we present first \na possible concrete syntax for our language. Similarities between this syntax and those of other Algol-like \nlanguages are intended to be helpful rather than misleading. <St> :;= continuel <var> :=<ae>lif <be> \nthen <st> else <st>lwhile <be> do <st> (empty, assignm~t, con~onal, ~iterat~tatemeiiEs) <se> ::= <const> \nlval<var> l~ae>+<ae~l <st>res<ae>llet <var> be cae> in <se> (a~hmetic expressions, ~ incl~ng com~und \nst~ements and blocks with initialized declarations, wh~ch are both made to deliver values) <be> ::= <se> \n= caejl(fbe>Afbe>) (Boolean expressions) <var> and <const> are simply distinguishable sets, which for \ntypographical convenience we will refer to henceforward as Var and Const. We can abstractly characterize \nthe heterogeneous algebra L which is to model our example language merely by decreeing that it is to \nbe a word algebra, i.e. one in which no equalities hold save between identically-constructed ~cts, and \nby naming its phyla, specifying the generating sets, and giving the types of its operations. In modelling \na programming language by a heterogeneous algebra, it appears there will generally be need\u00aded one phylum \nfor each (abstract) syntactic phrase class. In conformity with this prin\u00adciple, we take ~ to have four \nphyla: Var, Stat, Aexp, Bexp with, respectively, the following generating sets: var, {continue}, Const, \n{}. There are nine operations (whose names we borrow from the corresponding bits of concrete syntax) \nof the following types: val: Var + Aexp ~ : Var x Aexp + Stat while-do: Bexp x Stat + Stat =e~else: \nBexp x Stat x Stat + Stat . res: Stat x Aexp + Aexp ~Bexp X Bexp + Bexp =: Aexp x Aexp + Bexp +: Aexp \nX Aexp + Aexp let-be-in: Var x Aexp x Aexp + Aexp.  We next proceed to an algebraic specification of \nsemantics for ~, that is to the definition of an algebra ~ of meanings and of a homomorphism ~: L+M. \nWe first note that it would be irrelevant to our present purpose to commit ourse~v~s to a particular \nsystem of arithmetic values. We shall merely assume that they constitute a set A, that there is a given \ndenotation function Value: Const+A, and a given operation Plus: AxA+A (in a practical example there would \nof course be many such operations taking various num\u00adbers of arguments); and we shall, where appropriate, \nassume that the target machine which we develop has the requisite abilities to store elements of A and \nto perform Plus. This evasion conforms to the usual practice in leaving details of numerical range and \nopera\u00adtions to the implementation . As we shall have to assign meanings to phrases with free variables, \nit behooves us to define a type environment : Env = (Var~A) of partial functions assigning values to \nvariables, and to make all our meanings functions of environments. In fact we can also take environments \nto be the entities affected by assignment (although this dodge would not work for languages with a more \ndeveloped ref\u00aderence concept, in which creation of assignable places was not co-extensive with declara\u00adtion \nof variables) . We therefore take the four phyla of ~ to be sets of elements of the following types: \nVar, Env$Env, Env~(A x Env), Env$(2_ X Env) ( 2_ denotes the two-element set of truth-values). We have \nstill to define the operations in ~, and the effect of + on the generating sets of L. It is a fundamental \nresult of universal algebra that when we have done so we will hav~ specified the homomorphism $ uniquely, \nand moreover, in case the domain is a word algebra (as L is) that any so specified $ actually exists \n(see, for example, (2) where this result is called the unique extension lemma ) . As a concession to \nreadabil\u00adity, we shall combine the specifications of $ and of the M-operations in a conventional style \nof recursive function definition, following the not~tion of (3). Observe in par titular the use of the \nnotation * for a special form of composition: if q: X+(X XY) , x +(Y+Z) , thenP: P*q df ax.p(q(x) l)(q(x)2). \nThe semantics: $[v] = v for vsVar @[continue](e) = e for esEnv (here and subsequently) $[~value(cl ,e \nfor ccConst :~v~r~l(e) = e(~[vj),e := = (AaAe.Aw.w=@[vJl+a,e (w))*@lIr] @[while q d&#38;sl = y(~f. (~b.b+f \n+[sl,ae.e) $[ql )(Q) (here Y is the minimal fixpoint combinator, fl: Env~Env is the totally undefined \nfunction) $Iif q then S1 else S21 = (Ab.b+@[s11,@1s21) *@[ql 0[s ~rl(e) = @[rl(@[sl (e)) ~[qlAq2] = \n(Ab.b+@Kq2Jl, (Ae.false,e)) *@[qlJl 01rl=r21 = (Aal. (la2Ae.al=a2,e) *@[r21 )*@[rll 4[r1+r21 = (Aal. \n(la2Ae.al+a2,e) *@[r21 )*O[rll @[let v be r ~ ~ r21 = (Aal~el. ((la21e2.a2,(~w.w=@ [vl+e1(w),e2 (w))) \n*@[r21) (AW.W=~[vl!+a ~,el(w)))*@[rll. Note well that although the definition of b (and others to follow) \nreads like a pro\u00ad gram in a ligh level language, and may be so interpreted, yet it must be a program \nof a rigidly restricted kind if it is to define a homomorphism. Each line of the definition (save those \ndefining 4 outright on the 9eneratin9 sets) is sPecifYin9 an OPeration in !!. It follows that each @(O(s,t \n,.. .,u)) must be defined to depend solely upon $(s) , $(t), . ..) $(u), and not upon any other functions \nof s,t, . . ..u. We now turn to the definition of a target language ~ for our example, and of a com\u00ad \npiling homomorphism y: L+!. Note in passing, by way of motivation, that a straightforward syntax-directed \ncompirer i.n the real world does bear a coarse resemblance to a program for computing a homomorphism: \ni.t follows the phrase structure of its input, and (unlike an interpreter) gets done with any finite \nprogram in a finite, indeed roughly linear, amount of time. Roughly speaking, the programs of ~ will \nbe flowcharts, to be interpreted (to no one s surprise) on a stack machine; the operations of T will \nbe ones which stitch flowcharts together into bigger flowcharts. Two difflcult~~s arise, however. The \nfirst is caused by the existance of ~-phrases with free variables -we cannot expect to compile such phrases \ninto runnable flowcharts. Our solution here is similar to that used to define the semantics of L: we \nintroduce a set of symbol tables or maps . Map = (Var ~N) one-to-one (it will turn out that the natural-number \nvalues of maps will represent distances down from the top of the stack) , and we will make each phylum \nof T be a set of functions from Map to some suitable class of flowcharts. The second difficulty arises \nquite generally in translating from one (:anguage represented by an) algebra to another: in general the \ngiven second algebra WJ.11 not be a homomorphic image of the first; wha~ 1s required 1s to construct, \nor derive -see the discussion of derived operations ~n (2) -the operations of the actual target algebra \nfrom the given operations by composition and the use of constant operands. In our case, realism demands \nthat we define an underlying flowchart algebra T , not biased towards he compilation of ~-programsr and \nthen derive the operations of ~=~ compounds of ~-oPera\u00adtions. We make the following rather mysterious \ndefinition of ~: 1) For every finite set D, there is a separate phylum of T , which we may call the D-flow\u00adcharts. \nThe intuitive idea is that elements of D label po~~ts in each D-flowchart at which it may be attached \nto others. In particular there will be a phyl~ of {S,H}-flow\u00adcharts (S for %.tart , H fOr halt ) with \none entry point and one exit p:lnt. Note that s and H are not meant for variables of anY kind. but simply \nas two part~cular ob]ects the nineteenth and eighth letters of the alphabet. For any three sets D, E, \nF and any three functions d: D+~J e: E+~, f: F+~, there iS 2) a binary operation O of T producing an \nF-flowchart from a D-flowchart and an E-flowchart. Intuitively O works by~ollapsing into one point each \nset of points of the D-and E\u00ad flowcharts whose labels map to a sin91e inte9er# and then relabeling some \nof these cQl\u00adlapsed points with the elements of F to give an F-flowchar~. (~is used merely as a,con\u00advenient \nlarge-enough set.) For example, end-to-end composition of {S,H}-flowcharts Is given by 01, defined as \nfollows: fl(s) = all(s) = O fl(H) = el(H) = 2 dl(H) = cl(s) = 1 (The actual numeric values on the right \nare PlainlY 9ivin9 no useful information; we will suppress them from here on.) The author would be the \nfirst to agree that the ~o-opera\u00ad tions are cumbersome and peculiar. They have the merit, however, of \npermitting the cre\u00ad ation of flowcharts with loops. 3) To contains at least the following pri.miti.ve \nflowcharts, or inskruct~ons : For each ns~, {s,H}-flowcharts Ln (for loading the nth stack element \nto the top of the stack) and Stn (for removing the top of stack and storing it n positions down); for \neach aeA, an {S,H}-flowChart Limma ( load j.mmediate _ for putting a on the stack); one special {S,H}-floWchart \nAdd (for replacing the top two stack elements by their sum) i one special {StT,F}-floWchart Equal (for \ndeleting the top two stack elements and exiting at T if they were equal, otherwise at F) . There are \nalso empty flowcharts having all their labels at the same point. For the phyla of our derived target \nlanguagemT, homologous with ~, we will take Var again, two sets of partial functions of type (Map+~S!,H}-flowcharts) \nto correspond to stat and Aexpr and one set of partial functions of type (Mapl{S,T,F}-flowcharts) to.correspond \nto Bexp. We may now proceed, in the same style as for @ and ~, to give recurs~ve equa-L+T and of the \noperations tions defining the effect both of the compiling homomorphism Y: _ _ in T. The remaining definitions \nof needed ~-operat~ons are collected at the end. We make one auxiliary definition: Push(m) (v) = m(v)+l \nfor mcMap, vcVar. Now the compiler: y[vn = v for vsVar Y[continueD (m) = the empty {S,H}-flowchart for \nmcMap (here and subsequently) for cEConst [c](m) = i%alue(c) y[val v](m) = L m(v) Y[v:=rl (m) = Ol(y[rl(m),Stm(v)) \nY[while q ~ s](m) = 02 (y[q](m),y[s] (m)) y[if _ q then sl _else s2](rn) = 04 (03 (y[ql(rn) ry[sll(rn)) \n,y[s21(rn)) y[s res r](m) = Ol(y[sl (m),y[rl (m)) y[q1~q21 (m) = 05 (y1qll(m),y[q21 (m)) y[rl=r2] (m) \n= 01 (Y[rln(m),01(Y[r2] (push (m)),Equal)) Y[rl+r21 (m) = Ol(y[rll (m) ,01(y[r21 (push (m))/Add)) y[let \nv rl k r2](m) = 01 (Y[rll(m),O1 (y[r21(Xw.w=v+0 ,Push(m) (w)),sto)) ~ (This is a trick: St. has the \neffect of deleting the stack element below the top one.) We now define but we append pictures of their \nintended effects for those 02-0 who understandably mayno? wish to puzzle out the equations: : f2(S) = \nd2(S) = e2(H) 02 f2(H) = d2(F) e2(S) = d2(T) : f3(X) = d3(s) 03 f3(Y) = d3(F) e3(S) = d3(T) f3(Z) = \ne3(H) s : f4(S) = d4(X) 04 &#38;q 2 1 f4(H) = d4(Z) = e4(H) H e4(S) = d4(Y) (03 produces {X,Y,Z}-flowcharts, \nwhich are immediately consumed by 04) : f5(S) = d5(S) s 05 f5(F) = d5(F) = e5(F) q e5(S) = d5(T) f5(T) \n= e5(T) qz &#38; We next turn to the description of LIO, the algebra of meanings for T . Intuitively \nspeaking, we want to interpret our flowcharts by running them on a machiii~ whose set of Statesr ~, COrlS.i.Sts \nof the stackstl of elements of A, that is of all finite sequences with values in A. (For OEZ, we will \nconsider o(O) to be the top stack element; and so on down. ) For each phylum of D-flowcharts, we take \nits phylum of meanings to consist of binary relations from DxZ to itself. (We denote the set of all such \nrelations by (DxX-+ DxZ)) . Thus , intuitively, the meaning of a flowchart will tell us just what <i~itial \nstate, final state> pairs it can compute from each entrance to each exit. (The omission of any formal \ndistinction between entrances and exits is perhaps unnatural, but seems to facilitate the treatment.) \nCorresponding to each T!o-operation O: D-flowcharts x E-flowcharts + F-flowcharts determined by functions \nd,e,f, we decree an operation Q of go, Q: (D Z -XDXZ)X(EXZ -XEXX) + (FxZ +F Z) defined as follows: _l \n-1 -1 Q(R1,R2) =7fXI; (d XI;R;dXI ue XI;R2;eXI)+;f xI. Here x, ;, U, 1, + denote respectively relational \nCartesian product, composition, union, converse, and ancestral, and I denotes the identity relation on \nZ. The imtui-ti.ve content of this formula is that to compute i.n a flowchart sewn together from pieces \ni.s to compute by turns in the pieces, jumping back and forth as often as one pleases at the stitches.t \nIn particular, we denote by Ql,. ..,Q5 the ~-Operations corresponding to 01, . . . ,05 in l? -0 By way \nof apology fox the mysteriousness of T and U , it may be said that they are intended to conform to an \nalgebraic model of flow -8 harts %nd machines introduced by Lanolin in (4) and further developed in (5) \n. In that model, individual flowcharts, and the ma\u00ad chines on which they run, are viewed as algebras \nof a special type; meanings (relations computed by flowcharts running on any machine) are given by a \nuniform algebraic Product operation. In (5) , explicit constructions on flowchart-algebras are defined, \ncorrespond\u00ad ing pretty closely to the T -operations of the present paper, and a formula essentially equivalent \nto that postula$d above as giving the connection between the T -operations and the LIO-operations is \nthere derived from the properties of the algebra~ ~ product. Having defined the operations in ~, we may \nnow specify a semantic homomorphism $.: T +U merely by giving its effect on the generating sets of T \nthat is on the indi\u00adv~du~!/ flstructions. We do so as follows (for brevity, let a.a d? note the result \nof pre\u00adfixing the element a to the stack a). + 0(Ln) :X,O ~Y,T iff X= S&#38;Y=H&#38;T=On.u ~O(Stn): X,~+Y,T \n=X= S &#38; Y=H &#38; ~i=oi+l(i#n) &#38; Cn= 60 $O(Lima): X,o *Y,r iff X=S&#38;Y= H&#38;T=a-u $O(Add): \nX,O WY,T iff X = S &#38; Y = H &#38; o = a~-a ~.p &#38; T = Plus(uo,ul) p $O(Equal): X,CTHY,T iffX = \nS &#38; o = CrO.OloT &#38; (Y =T &#38; UO == ul-or Y=F &#38; IJO #ul) +O(empty {S,H}-flowcha~: x,a Wy,T \niff x = s &#38; Y= H &#38; o = T It is now possible to define the algebra u which is to form the lower \nright-hand corner of our compiler correctness diagram, to~ether with the target semantic homomor\u00adphism \n$. Evidently the elements of U must follow those of ~ in being functions of symbol tables -to be precise \nwe have the f~llowing for the types of the members of the four phyla of ~: Var Map$({S,H}~Z -X {S,H}XZ) \nMap~({S,H}XZ 4 {S,H}XZ) Map~({S,T,F}XZ --x {5,T,F}xZ). We of course want ~ to reflect the action of the \nunderlying flowcharts-to-meanings homomorphism IJI . That is, we can define the desired effect of ~, \nconsidered simply as a mapping, by th~ equations l)(v) =V for vcVar ~(p)(m) = *o(p(m)) for mcMap, pc \nany other ~-phylum. That this function ~ actually is a homomorphism: T+U for an appropriate choice of \nopera\u00ad tions in U is a fact of universal algebra, stated for homogeneous algebras in (2) under the name \nhomomorphismof restrictions lemma . It is convenient to display the necessary ~-operations in the form \nof a recursive definition of the composite IJOY. (Note that we are constructing both T and U to be epimorphic \nimages of L under y and ~oy, so that this form of definition is Indeed complete.) In fact, we can ~btain \nthe definition of +DY mechanically from that of y by simply replacing each T constant Inst by ~ (Inst) \n, each O. by Q. , and each y by Qoy; however we reproduce the ~esult here for refe~ence: ++E-Z6E$EFG-fiG?E-EG;FiT-E5-73i;-----------we \nshould take ----------------------* here rather than + ~-7Z~ ------------------e. make all rela\u00adtions \nreflexive; to do-so would merely complicate some formulas below. l)oy[vn = v V y[continuel (m) = 40 (empty{S,H}7flowchart) \nV071cl(d = oo(~i~alue(c)) +Oy[tivlb) = Oo(Lm(v)) +Oy[v:=rl (m) = Q1(+Oy[r] (m),40(Stm(v))) +OY1while \nq &#38;sI(m) = Q2($0y[ql (m), $ y[sl (m)) +oy[~ q then SL else s21(m) = Q4(Q3(V0Y[qll (m) ,~ ylIs11(m)),$0ylIs2R \n(m)) Yoy[s res r](m) = Q1(40y[sl (m),VOylrl (m)) V Y1qlAq21tm) = Q5(+0y[qll (m),$0y[q21 (m)) Y0y[r1=r21(m) \n= Ql(+OY[rll (m),Ql(+ y[r21 (Push(m) ,Vo(Equal))) 00y[rl+r21 (m) = Ql(40Y1r11 (m),Q1(V y[r21 (push(m) \n+O(AM))) ~oy[let v be r ~ ~ r21(m) = Ql(VOYIIrll (m), Ql(~.y(r2] (Aw.w=v-?O,Push (m) (w)),40(StO))) It \nis now necessary to define the fourth side of the compiler correctness diagram, translating between source-and \ntarget-language meanings. It proves more convenient to define an encoding function &#38;:M+~ than one \nin the opposite direction; it will then be necessary as a final step in proving correctness to show that \nE has a decoding inverse, 6:U+M, at least for programs without free variables, which are the only ones \nwe really ex~e~t to be able to run. We will define E simply as a family of mappings (one per phylti); \nthe proof that s is in fact a homomorphism will constitute the main (inductive) part of the correctness \nproof. To get an intuitive grasp of the behavior of E, it is necessary to realize that stacks in the \nimplementation contain two kinds of entry: values of variab~es and anonymous intermediate results. Thus \ngivenrfor example, a function s: Env+Env in the statement phylum of M, we want E(S) to be such that -once \nprovided with a symbol table telling which stack ~ositions represent the current environment -it will \nchange these just as s does but will leave all other positions unchanged. We encapsulate this notion \nby defining an auxiliary function for changing a stack to bring it into agreement with an environment: \nChange(e,rn,o) = Ai.isrange (m)+eom-l (i), ai (for esEnv, m.sMap, oeZ). It is now not too difficult to \nwrite the necessary four equations defining e: E(v) =V for vs Var c(s) (m) (S,IS) = H, Change(s(u.m) \n,m,o) for s&#38;Im$(Stat) e(r) (m) (S,u)= (kaAe.H,a\u00b0Change (e,m,a) )*r(uom) for reIm@(Aexp) e(q) (m) \n(S,0) = (~bke. (b+T,F) , Change (e,m,o))*q(oOm) for qeImO(Bexp) The peculiar formal parameter notation \n(S,5) is meant to indicate that E(S) (m) and the like are partial functions (strictly speaki.ngr they \nmust be considered as the correspond\u00ading relations to make all the types fit) which are defined only \nwhen the first component of the argument is the letter S. A t this point, although nothing has as yet \nbeen proved, the main goal of the paper has been acc~mplished: to-carry ou~ in deka~l the modelling of \na compiler correctness problem within algebra, in what the author believes to be a natural manner. To \nactually carry through the correctness proof, which we shall do here only in part, is to prove the equation \nEo$ =l)oy . i he necessary proof has been structured for us by our algebraic approach; namely we have \nin the first place to show that we have not merely a function but a homomorphism E:M*U ~ that is that \ns respects each of the nine operations of ~; and in the second place to show directly that the diagram \ncommutes for the elements of the generating sets of L. It will then follow by the unique extension lemma \nthat c.~ and ~.y,agreeing on the gen~rating sets, must be the same homomorphism. If we wished to eschew \nalgebraic terminology{ we could call these two parts the inductive and base steps of a proof by structural \ninduction (but note, this is an induction on the structure of source programs, not of computations) . \nAfter proving that the diagram commutes, we must still show that for a program p without free variables \nwe actually can invert s, and recover I#I(p) from VOy(p) . Proving commutativity which was only carried \nalong For c&#38;Const, it is easy to notational convention used relation-valued function for the generating \nfor bookkeeping discover from the in defining s, that sets is not purposes, we definitions, both so@@3 \nhard. have taking and For the phylum Var, trivially 6041[V]=V=+OY[V]. advantage of the $OYICI work out \nto the Xm.l(S,a).H, Value(c) a Similarly, the definitions yield immediately that co$[continuel = VOy[continuel \n= ~m.~(Sj~) H~~ This completes the base of the induction. shall The inductive carry out part of here \nonly the for proof verifying the operations &#38; that and E res:=. pects the operations of ~ -we For \nval we can homomorph~s involved arbitrary vcVar: in fact are check identities commutitivity on Var. directly, \nWe compute since from we the know that definitions, all the for so$[val v] = e(ke.e(v),e) . lm. k(S,c$).H, \n(aom) (v) change(u m,m,a) = ).m.L(S,u) .H, (uOm)(v) u and IJOY[VaJ vJ=V(Am.Lm(v)) which is the km x(s \nu) same thing. H om(v) u For :=, what we have to prove (for vSIar,rcAexp) is the equation S.+[v:=rj \n= +.y[v:=r] under the assumption YOylrl = soo[rl which may be rewritten, from the definitions of E and \n~, as the assumption $OY[r] = ~m.~(S,o) .(~aXe.H,a-Change (e,m,a))*$[rl(aOm) . We may begin by expanding \nthe left-hand side: eof$[v:=rll = :( (Aake.Aw.w=wa,e (w) )*@[rD) . km.A(S,o).H, Change ((AaAe.Aw.w=wa,e \n(w) )*$[r](oOm),m,u). Starting now from the other end, we work out what 4 Y[v:=rl comes to. By giving \nsome attention to the action of QII it is not difficult to see that we have, for meMaP: ~oy[v:=r](m):X,o \nI--+ Y,T iff X=S&#38;Y=H&#38;~ y[r]:S,a -H,a-p &#38;T=(Ai.i=m(v)+a,Pi) . But this amounts (taking note \nof what $Oy[r] does) to $oy[v:=rl=Am.A (S,u) .H, (Aa~e.Ai.i=m(v)+a,Change (e,m,a) (i))*@[r](u m) which, \nconsidering the definition of Change, we maY rewrite as ~oy[v:=r]=Am.A (S,o).H, Change((AaAe. lw.w=v+a,e \n(w))*@[rl (uom) ,m,a) and this, as we have seen, is just C $[v:=rn. Supposing the proof that SOO = $OY \ncomplete, we now examine the special case of runnable programs -those containing no free variables, and \nbelonging, we assume, to the phylum Aexp. Consider such a program p, and let e denote the empty (completely \nun\u00addefined) environment, m the empty symbol table, and c tfle empty stack. Then the answer we are after \nby runningop is $(p) (e )-in fact just the fxrsk component of this. for the second component will be \neoagain. $ut our statement of commutatlvlty tells us that we can compile the flowchart Y(P) (mo) , run \nit on the target machine starting at (S,C) and come out wikh (laAe.H,a G)*$(p) (eo), just in case $(p) \n(eo) is defined-that is, with the desired element of A as the only stack element. The omitted parts of \nthe correctness proof which has been prepared for and begun above appear to offer no particular difficulty, \nsave possibly in the case of the while statement, where Y will have to be either proven (by showing its \nargument to be a continuous ox else defined to be equivalent in this application to Plainly, however, \nthe proof would be quite tedious when written out . To some extent this appears inevitable, since the \ndefinitions of the compiler and of the two semantic functions can hardly be made very much shorter than \nthey are, and :Z i~i~(FTx7Tk~~~a ) yet any prcGf must appeal to every syllable of these definitions. \nThere is a pressing need for notational improvements and, if reliable proofs are to be produced, for \na sufficiently expressive (and preferably partly automated) formal system to carry them out in. The present \npaper, aside from its insistence on homomorphisms everywhere, is basically unsystematic in its approach; \nthe aim has been to uncover some of the mathe matical facts underlying the correctness of compilers. \nThe author hopes that efforts such as this one will complement the endeavors of the system-builders, \nsuch as Milner s LCF , applied to a compiler-correctness problem in (6), and also Hitchcock and Park \ns (7); designing good proving languages should be easier if one has an idea first of what one will want \nto say in them. References (1) G. Birkhoff and J.D. Lipson, Heterogeneous Algebras , J. Combinatorial \n Theory-8_, pp. 115-133 (1970). (2) R. M. Burstall and P. J. Lanolin, Programs and Their Proofs: an Algebraic \nApproach , Machine Intelligence &#38; (1969) . (3) D. Scott and C. Stracheyr Towards a Mathematical \nSemantics for Computer Languages , Programming Research Group Monograph PRG-6, Oxford Computing Laboratory \n(1971). (4) P. J. Landin, A Program-Machine Symmetric Automata Theory , Machine Intelligence ~ (1970). \n (5) F. L. Morris, Correctness of Translations of Programming Languages , Stanford Computer Science Memo \nCS 72-303 (1972) . (6) R. Milner and R. Weyhrauch, Proving Compiler Correctness in a Mechanized Logic \n, Machine Intelligence ~ (1972). (7) P. Hitchcock and D. Park, Induction Rules and Proofs of Termination \n, Proc. Colloques IRIA Theorie des automates des langages et de la Programmation. Rocquenc~urt , France, \nJuly 1972.  \n\t\t\t", "proc_id": "512927", "abstract": "The purpose of this paper is to advise an approach (and to support that advice by discussion of an example) towards achieving a goal first announced by John McCarthy: that compilers for higher-level programming languages should be made completely trustworthy by proving their correctness. The author believes that the compiler-correctness problem can be made much less general and better-structured than the unrestricted program-correctness problem; to do so will of course entail restricting what a compiler may be.", "authors": [{"name": "F. Lockwood Morris", "author_profile_id": "81100135014", "affiliation": "Syracuse University", "person_id": "PP14057945", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512927.512941", "year": "1973", "article_id": "512941", "conference": "POPL", "title": "Advice on structuring compilers and proving them correct", "url": "http://dl.acm.org/citation.cfm?id=512941"}