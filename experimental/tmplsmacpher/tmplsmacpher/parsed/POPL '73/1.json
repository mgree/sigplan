{"article_publication_date": "10-01-1973", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1973 ACM 0-12345-678-9 $5.00 STRICT DETERMINISTIC VERSUSLR(0) PARSING* (Extended Abstract) by Matthew \nM, Geller and Michael A. Harrison University of California at Berkeley INTRODUCTION Recently strict deterministic \ngrammars and languages have been introduced [9,10,11]. This family of languages is quite fundamental \nin the study of the mathematical properties of deterministic languages and in dealing with some classical \nfamilies of grammars such as LR(k) and bounded right context grammars [7,8,14]. These grammars are closely \nrelated to LR(0) grammars [1,12,13,14], in fact each strict deterministic grammar is also LR(0). In the \npresent paper, we consider the question of how to parse strict deterministic gramnars. We introduce part \nof a more general theory called character\u00adistic LR(k) parsing . This actually produces parsers which \nare tuned to the characteristics of a particular family of grammars. We apply the theory to the family \nof strict deterministic grammars and we get parsers which are as fast as canonical LR(k) parsers but \nare substantially smaller. They are not necessarily minimal but we postpone any discussion ofminimality \nto the sequel . The techniques used in the present discussion are quite aeneral [51. For instance. the \nstudy in [3] is s;milar ii ;pirit to our technique. The optimization techniques for LR(k) parsers in \n[2] do not work in the case k = O without modification. After modifying those methods for k = O, it can \nbe shown that our parsers cannot be produced by those techniques. This fact has its positive asDect in \nthat our ~arsers mav be smaller and its negative aspect in ~hat error-detection may be delayed. The present \npaper is divided into the present introduction and three sections. In the remainder of this introduction, \nsome basic definitions of strict deterministic and LR(k) parsing are given. We have tried to follow [1] \nas much as possible in order to minimize the amount of new material to be absorbed. The order of the \nresults is the order needed to prove that the character\u00adistic parser works, In Section III, we apply \nthe theory of Section II to strict deterministic parsing. A simple example shows that the new parsers \ncan be unfoundedly smaller than the canonical LR(0) parser. * Research supported by NSF GJ 474. The present \npaper is meant to be an extended abstract and no proofs are included. The rest of the introduction is \nconcerned with notational conventions for the technical concepts needed. Let X beaset. A artition of \nX is a collection rr= {X1 ,X2,... +-of nonempty mutually disjoint subsets Xi ~ X such that X = $JXi. \nSubsets Xi are called blocks of partitio; n. We write X/~ for the partition induced by an equivalence \nrelation = and a modm for the equivalence relation induced by a partition n. We also need to deal with \nrelations. When X and Y are sets then any set pCX x Y is a relation (between X and Y). Le~ p~XX Y and \no~YxZ. We define pu = {(x,z)l xpyoz for some y}, and, if X =Y, PO = {(x,x)1 x e X} (the diagonal), n+l \nP = PnPy n Loy P* = U pn (the reflexive and n>(J transitive closu;e of p), P+ = P*P (the transitive closure \nof p). Next, we need the usual grammatical concepts. Definition A context-free grammar (hereafter a G \nis a 4-tuple QQ!!!.@ G = <V~,P,S> where V and z are two alphabets, XC V (letters in Z and in N = V -Z \nare ~alled terminals and nonterminals respectively), S e N and P is a finite relation, pCNxV* (the set \nof productions).( ) (1) Let X and Y be sets of words. Let XY = {xylxeX,yeY} where xy is the concatenation \nof x and Y. Define XO = {A} where A is j+l the null word. For each i~O, define X= xix and X* =i~o X1. \nLet X+ = X*X and fl denote the empty ~et. If x is a word, let Lg(x) Definition Let G = (V L,P,S) be a \ncontext free grammar. We define a relation *C V*X V* as follows. For any a,B, e V * a *B iff a = o.1Acx2, \nand A+ $ is in P for some Ae N 6 = al%~2 and al, a2, Bl e V*. In particular, if al eX* or a2 e X* we \nwrite a~L B or a -R B respectively. Any a e V* is called a &#38;anon ical) sentential formiff S+*a (S~fia). \nThe language generated by G is the language L(G) ={weZ*l S**w}. We need the formal concept of a parse. \nLet G = (V,Z,P,S) be a context free gramnar and suppose that S = aO~al ~ o-~an eX*. If for each i, O:i \n< n, cxi =a~Aixi, = a;L3ixi where a;,~i e V*, xi eZ*, Ai e N, ai+l and pi =Ai+Bi is in P then P=PO . \n. . Pn-l is said to be a canonical derivation and o+= Pn-l ,.. Po is said to be canonical parse. We often \nwrite P ~% in this case. In dealing with parsers, we also need the idea of a handle . Definition Let \nG = (V~,P,S) be a context free grammar and let ye V*. A handle of y is an ordered pair (p, i) where p \ne P and i >0 such that there exist A e N; a, B e V*, and w e Z* such that (i) S~ctAw~a6w=Y (ii) p is \nA+B  (iii) i =Lg(a6) Some special terminology is needed for dealing with strings and alphabets. For \nany alphabet V, we write VA = V U {A}. In this notation, V:= {aeV*l !Lg(a):k} Let u, B e V* be two strings. \nThen a is a ~\u00adfix (suffix) of @ iff a = By (6 = ya) for some GV*; when y # A, a is a roper Prefix (proper \nsuffix) of i3. For any ~~0 n)a (o.(n)) is the prefix (suffix) of a with length min(!l.g(a),n). Finally, \nwe say that a language L CZ* is prefix-free if a e L and c@ e L impl~es @= A. [(1) Continued ..] denote \nthe length of x which is the number of occurrences of letters in x. We define the transpose function \non strings inductively by AT =A and (xa)T = ax for each xeE*, aeZ. Section I. STRICT DETERMINISTICAND \nLR(k) GRAMMARS The strict deterministic grammars and languages were introduced in [9]. This family has \nbeen studied in its own right and because of its applications to other problems in the parsing of deterministic \nlanguages [9,10,11]. Before giving any details we will need the formal definitions of this family of \ngrammars. Definition Let G = (V,Z,P,S) be a context free granunar and let T be a partition of the set \nV of terminal and nonterminal letters of G. Such a partition m is called strict iff 1. zem, and Forany \nA,A eNand a,6,6 eV* if ~ +af3, A +CXB and A ~ A (mod IT) then either (i) both f3, 6 #A and(z) (l)B: (l)~! \n(modm) or (ii) !3=6 =Aand A= A . Definition A context free grammar G = (V~,P,S) is called strict deterministic \niff there exists a strict partition m of V. A language L is called a strict deterministic language iff \nL = L(G) for some strict deterministic grammar G. Example The gramnar shown below generates parenthesized \narithmetic expressions. The granrnar is strict deterministic with respect to IT = {X, {E}, {T, ,T2}, \n{F, $F2YF3}I. s : \\EE E 1 2 I F2 1 + lTl I F3 2 + 1T2 + (E+ a+ 1 a*F,+ (E* L + (E) I a) 3 Many properties \nof strict deterministic languages have been discovered [9,10,11]. We mention here only one result from \n[9]. Theorem 1.1 A language is strict deterministic if and only if it is deterministic and prefix free. \nIt is our intention to compare strict deterministic with LR parsing. To do so, we need the formal definition \nof LR(k) grammars. As we shall see, not all definitions of these grammars are equivalent. Nowwe give \nour definition of LR(k) grammars. Definition Let k~O and G = (V,Z,P,S) be a 3) reduced( context free \ngrammar such that S ~ S (2) Recall that 1) B denotes the first letter of 6.  (3) .A context free grammar \nG=(V,X,p,S) is\u00ad  ~P=Oorf or any A A V we have ~fse~~e w for some u,B e V* and w e E*. is impossible \nin G. G is LR(k) iff (i) For each w, w , xe Z* and for each y, a, a , B, !3 in V*. If (ii) s~~w~a~w=yw. \nThat is, yw has handle (A + B,l.g(@)) and (iii) S~a A x~a 6 X = YW . That is, yw has handle (A + G ,!,g(o \n6 )) and (iv) k)w= k)w . Then (v) (A+ B,!Lg(af3)) = (A + B ,Lg(cx B )). The conclusion in the definition, \nthat is (v), has several clear implications. 1) By the definition of equality of ordered pairs, we have \nA=A , B= B , and !Lg(c16) = ,Lg(u f3 ). (L9(Y))U!61 = (~9(@))a161 2) y= = (L9(a i3 ))a161 = C% $ . Thus \ny = aE3=IY, B . 3) Since B=6 , from 2) wehave a=a 4) a @ x =yw implies 0, B x = o. B w implies x = w \n. The above definition essentially agrees with the original definition [14]. This definition does not \nagree with the definition used in [1]. The definition from [I] is now reproduced. Definition Let k LO \nand G = (V~, P,S) be a reduced context free grammar. Define an au mented (V,U{S }, X, PU{S +S }, s W2!?UN. \nG = -e S is a new symbol not in v. G is said to be an ALR(k) grammar (~ugmented LR(k) grammar) if G is \nLR(k). The following result, taken from [5,6], summarizes the relationship between these two concepts. \nTheorem 1.2 Let G = (V,X, P,S) be a reduced context free gramnar without any derivations of the form \nS$s. (a) Let k~l. Then G is LR(k) if and only if G is ALR(k). (b) Let k = O. If G is ALR(0) then G is \nLR(0). (c) There exist grammars which are LR(0) and which are not ALR(0).  A simple example of the \nkind of grarmnar mentioned in (c) is the following: S+Sala A characterization of these grammars which \nare ALR(k) is given in [5]. Our next result establishes the relationshi~ between strict deterministic \nlanguages and LR(0) languages. Theorem 1.3 (a) Every reduced strict deterministic grammar is an LR(0) \ngrammar. (b) There are LR(0) grammars which are not strict deterministic.  (c) L is an ALR(0) language \nif and only if L is strict deterministic.  Thus we have adopted the wider definition of LR(k) and it \nhas the consequence that there are LR(0) grammars which are not strict determin\u00adistic. It should be mentioned \nthat the reasons for the choice of the ALR definition in [1] are that the full family of LR(k) languages \nare obtained for k ~ 1 and that the canonical LR parsing algorithm [14] can be proven to work without \nmodification. We shall have to modify the canonical parsing algorithm in the case k = O as it does not \nwork correctly. In summary, the treatment in [1] is consistent; for the class of grammars considered, \nthe parsing algorithm works. This is not the case in [14]. Here we choose the wider class of LR grammars \n(used in [5,6,7,8,10,12,13,14]) and givea parsing algorithm for the full set of grammars. Section II. \nCHARACTERISTIC LR PARSING. In the present section, we introduce characteristic LR(k) parsing . This will \nbe done by a chain of definitions. Most of these parallel the development of Knuth s LR(k) parser as \npresented in [1]. That parser is often referred to as the canonical LR(k) parser . We shall briefly comment \non the changes as we proceed. The main idea is to modify the items required to take into account the \nspecial characteristics of the grammars considered. In the following section, we shall do this for strict \ndeterministic grammars. In the near future, other applications of this theory will be presented. In our \ncalculations, we shall need the FIRSTk(a) function which computes roughly the first k terminals which \nare derived from a, Definition Let G = (V, Z, P, S) be a reduced context free grammar, u e V*, and let \nk>O. FIRSTk(a) = {x I a~w, w eX*, and x = (k)wl. As in the canonical theory of LR(k) parsing, we need \nitems. Definition Let G = (V,Z, P, S) be a context free grammar and let k >0. For any j31,132 e V*, \nAeN, uex[ and A+ f31132 in P, we say that (A+ B,-62, u) is an LR(k) item. Next, we present what appears \nto be a non\u00addeterministic algorithm [4] for calculating characteristic sets of items. Algorithm 2.1. \n= G=d(VLP,S) a context free grammar, , an yeV*. Q!Q!Q v;(y), a set of items for y. Method (1) To construct \nV; (A) (a) if, for some a e V*, S+a jsin P, add (S+ .a, A) to v; (A). (b) if, for some A, Be N; a,B e \nV*; u eZ*, we have (A+ .Bau) is in Vc (A), and B+B is in P, then for all x kuch that x e FIRSTk(au) , \nadd (B +.6, X) to J: (A). (c) Optionally if for some A e N, f3e V*, u e Z;, we have A+@ in P, add (A+ \ncR, u) to Vi (A). (d) Repeat (b) until nothing new can be added to V; (A). (2) To construct v~(xl>...xi) \nfor some i~l, Xje V for l~j~i. (a) if for somea, 6eV*,Ae N,XieV, ueZ*  (A-+ CYSXii3,u) is in Vk(X1,... \nX1)l) then aud (A+aXi 6, u) to Vk(Xl,...Xi). (b) if for some A, Lie N, a, B, ~e V*, ueZ* (A+a.BB, u) \nhas been placed in v~(xl,...xi) and B+6 isin P, then for all x e First, add (B+ .6, x) to Vk(Xl,... Xi). \n(c) Optionally if for some Ae N, !3eV*, ueZ~, we have A + D in P, add (A+ SL3,u) to V;(A). (d) Repeat \n(b) until nothing new can be added to V~(Xl,. ..Xi). We have called the algorithm nondeterministic because \nof the optional addition of items in l.c. and 2.c. In fact, we shall specify which items should be added \nin constructing parsers for certain families of grammars. We use the term character\u00adistic because the \nchoices made are determined by the characteristics of the families of grammars. It is possible to express \nthe characteristic items as obtained above, by a parameterized algorithm but the formalism is cumbersome. \nIt will become clear that for any sequence of choices, the resulting algorithm is deterministic. It \nis convenient to use the goto function of [1]. Definition Let G = (VZ,P,S) be a context free gramnar, \nk~O, and let ye V*. For XeV, and any V;, define goto (V:, X) V~(YX). Next, an algorithm is given which \ncomputes collections of items. Alqorithm 2.2 Context free grammar G = (VL,P,S) and !%% oiput (4) Sc=.s&#38;k \n, ={V~(y)#!31yeV*l Method Initially -SC is empty (1) Place V;(A) in Sc . The set V;(A) is initially unmarked. \n (2) If a set of items A in Sc is unmarked  (a) compute, for each X e V, goto (A,X). If goto (A,X) + \n0 , add goto (A,X) to SC asan unmarked set of items. (b) Mark A. (3) Repeat step (2) until all sets of \nitems in Sc are marked. Next, we need the function EFFk. This function computes all strings of length \nk whose derivations do not involve replacing a leading variable by A. Definition Let G = (VZ,P,S) be \na reduced context free grammar, and let k LO . We say w e EFFk(a), for some w e FIRSTk(a), a e V* if \nand only if there exist @e V*, x e X* such that (i) f+ ~ wx where B# Awx for any A eN, or (ii) a=wx. \nOur next task is to associate sets of tables with our sets of items. Definition Let G = (VL,P,S) be \na reduced context free grammar and let k LO. Let -SC= $,k be the collection of sets of items computed \nby Algorithm 2. For each A e .SC, we define T = T(A), the table associated with A, as a pair of functions \n(fTY gT) defined below. Moreover, let T~=T(V~ ({A})), (1) T> the parsing action function, is a map from \nxl into {error, shift} U {reduce p 1P e P} .-.------. --x--\u00adand is defined by cases (a) fT(u) = ~~~~~ \nif for some Ble V*, 62e V+, veZ*, A eN, we have (A+ B1062, v) in A and u e EFFk(i32v). (b) fT(u) = reduce \np if for some 6 e V*, ---a-- AeN (A+&#38;,u)eA and P is A+6 where peP. (4) To avoid the proliferation \nof subscripts, we write Sc as an abbreviation for Sc G,k (2) 9T V into the set of tables or error(a) \nif z =A then (z, YT, p) 1 error maw ---.-For each X e V (b) if z #A then we write z = az!~---\u00adae~, z \ne Z*. (a) gT(X) T(goto(A,X)) if goto (A,X) # 0. (bl) If gT(a) = error then  .--az (b) gT(X) = error \nifgoto (A,X) =0. (az , yT, p) l error  (bz) If gT(a) # ~~~~~--then Finally, let ~ =T~ ~ = {T(A)I A e.Sc}. \n, (aZ , YT, P) \\ (z 3yagT(a)! P) It is also important that our tables are That is, in step b2, we shift \nthe next character consistent in the following sense. of the input onto the stack and also stack the \ntable determined by the topmost symbol and the Definition Let G = (V,Z,P,S) be a reduced input. context \nfree grammar and k ~0. Then the characteristic LR(k) tables associated with 2. If fT((k)z) = reduce p \nwhere p = A + @. G, k, and c are consistent if for every ------V*; y e V*, there does not exist A, B \ne N; D,B1,B2e In this case, we wish to pop 2,P,g(f3) symbols. Idhen we do so, let T be the table we uncover \n. u, v e z*; u e EFFk(i32v) and distinct items More precisely, define yT = y T y where (A+6s, u) and \n(B +131.62, v) in V;(y). Lg(y ) = 2 Lg(6) . Next, we must describe the characteristic (a) If T =To, A= \nS,andz= A then LR(k) parser to be used. This parser is similar (z, YT, P) l accept and we print pp as \nthe to the same given in [1,14]. It is a -----\u00ad parse. deterministic pushdown transducer whose moves \ndepend on the LR(k) tables used. The differences (b) If case (a) does not hold and between our model \nand [1] are that: (1) the tables are different and (2) the reduce moves have been gT = error then (z,y \np) l error. .z..---...--\u00admodified to allow for the parsing of LR(0) grammars. (c) If neither case (a) \nnor case (b) holds then Since our parser is a variation of that in [1], (Z, Y T Y ,P) I (Z, y T AgT, \n(A), PP). we shall describe it informally. An ID of the In case 2(c), we remove the coded form of B, \nparser is written as (z, y, p) where replace it by its immediate ancestor A, compute(i) z e Z* is the \ncontents of the (as yet the next table needed, and add p to the output. unread) input (ii) ye To(VTc)* \nis the contents of the 3. If fT((k)z) = error then (z,yT, p) l error. pushdown store. The top is assumed \nto be at the Finally, let 1: ( IA) be the (reflexive) right. transitive closure of \\ (iii) p e P* is \nthe contents of the output The parser we have just defined is an extensiontape. of the canonical LR(k) \nparser and this relation-The initial ID is defined to be (z, To, A). ship will now be explored, It is \nnecessary to establish certain facts about canonical LR(k)We are now ready to give a more formal parsing \nbefore the characteristic LR(k) parserdescription of our characteristic LR(k) parser. can be proven to \nwork. Definition Let G = (V,Z,P,S) be a reduced An important notion is the following type ofcontext free \ngrammar and k ~0. Let Tc be a string. set of consistent characteristic LR(k) tables. Definition Let G \n= (V,Z,P,S) be a context free The characteristic LR(k) parser, Jc= J;,k grammar. yeV* \u00adis defined to \nbe the device described above h se if exist s e ~ , a iab e %$%; G there LZ,6, aid V beA e~e 75? move \nfunction , 1-is defined as follows: that S ~ CLAW~ @W Suppose J is in ID (z, YT, p) where and y is a \nprefix of c@. TeTc, zez*, and peP*. It is also necessary to mention a simpler 1. If fT(k(z)) = shift \nthen . ..-..- but equivalent concept. [5,6]. Definition Let G = (V, Z,P,S) be a context free grammar. \nY e V* is a valid prefix of G if there (5) Since this device is a pushdown like auto- Xist 9 ~2 e * A \ne e * Uch that mation with ID (z, y, pi), its move will depend on the state , the FIRSTk letters of \nz, i.e. k) z ,and the topmost symbol of the push-Thus, a valid prefix is a viable prefix which down \nstore. includes all of a . concerned with some special items. Definition Let G = (V,Z,P,S) be a context \nfree grammar and k~O. For 61,62 e V*; W,U e z*, A eN; (A+610R2, u) is a valid LR(k) item for CY,61 if \nthere exists a derivation in G. s; ~w~ @,~2w, with U=(k)w. Now we need to have the canonical LR(k) tables. \nThese can be obtained by specializing Algorithm 2.1 to the case in which no additional items are added \nin steps l(c) and 2(c). Let us call this the co case. Then we write Vk(y) instead of V~O(y). The following \ntheorem tells us what Algorithm 2.1 computes in this special case. Theorem 2.1 Let G = (V,Z,P,S) be a \nreduced context free grammar, y e V*, and k > 0. An item is in Vk(y) after application of Algorithm 2.1 \n(with no additions in steps l(c) and 2(c)) if and only if that item is valid for y. Notation. In the \ncanonical case, we write co s = sG,k. Next, we relate S to viable prefixes Theorem 2.2 Let G = (V, X,P,S) \nbe a context co free grammar and let k~O. S = SG,k {vk(y)l y is a viable prefix of G}. Moreover, Algorithm \n2.2 computes S. The following result is also important in the canonical theory. Theorem 2.3 Let G = \n(V,Z,P,S) be a context free grammar and k~O. G is LR(k) if and only if each of the elements of the canonical \ncollection of sets of LR(k) items is consistent. Continuing with our notational conventions, we write \nT ={T(A) I A e S} as the canonical collection of LR(k) tables of G. Then our co characteristic parser \nJ =JG,k reduces to a canonical LR(k) parser for G. The parser J is almost the conventional parser [1] \nexcept that it has been extended to handle the case k = O properly and the grammar has not been augmented. \nThere is still the issue as to whether it works correctly. That issue is the subject of the next two \ntheorems. Theorem 2.4 Let G= (V,.X,P,S) bean LR(k) grammar, k LO, and let J be the canonical LR(k) parser \nfor G. Then for all xe L(G) (x, TO,A) 1~ ?I~I~p~ and print out PT when o The previous theorem asserts \nthat the parser correctly parses all x e L(G). For those x@ L(G), we must see that J stops and moreover \nstops in the error I.D. Theorem 2.5 Let G= (V,Z,P,S) bean LR(k) grammar, k~O, and let J be the canonical \nLR(k) parser for G. Then for all x @L(G), (x, TO, A) IL ww ~~ . Since the proof that characteristic \nLR(k) parsing works depends on the corresponding proof for canonical parsinq, we can now prove that characteristic \nLR(k) parsing works. This requires a Lemmawhich relates the two approaches. Lemma2.1 Let G = (V,Z.P,S) \nbe a context free grammar, k>0 and y eV* (a) Vk(y) S ~(y) (b) If we xl, T= T(Vk(Y)), and  Tc = T(V:(Y)) \nimpl ies f~c(w) = T(w) (iii) For all XeV, if gTc(X) = w~~~ Nowwe can prove that characteristic LR(k) \nparsing works. Theorem 2.6 Let G = (V, Z,P,S) be an LR(k) grammar, k ~0, and let Jc be a characteristic \nLR(k) parser for G. Then for all xc L(G) , accept prints (x, T;J) 1A ------~and out p where Q.x Corollary. \nLet G = (V,Z,P,S) bean LR(k) grammar, k~O, be a character\u00ad and let ;,k istic LR(k) parser for G. Then \nfor x e z*, (x, T;, A) IL ~s:sQ if and only if x e L(G). Next we must deal with the case when x # L(G). \nTheorem 2.7 Let G= (V,X,P,S) bean LR(k) grammar, k~O, without A-rules, and let be a characteristic LR(k) \nparser for G, J:,. with consistent tables. Suppose that for some x e x*, we have x @ L(G). Then (x, \nT:, A) IA ~~~~~. Section III. STRICT DETERMINISTIC PARSING We now indicate a new parsing algorithm for \nstrict deterministic grammars. An algorithm was given in [10] for this purpose. That algorithm is a rather \nstraightforward method that utilizes the basic definition of strict deterministic grammars. The present \nalgorithm is uniformly superior in that it is faster and results in smaller parsers. Notational Convention. \nLet G = (V, Z,P, S) be a context free grammar with strict partition n. If Ae N, we write ~={A I A =A \nmodn}. Our first definition is of a suitable prefix of a block of a partition. Definition Let G = (V,Z,P,S) \nbe a context free grammar and let V ~ V. We say that ye V* is a suitable prefix of V if there exist some \nAeV , k3e V*, A+6in P,andy is a prefix of B. The next definition is designed to describe the contents \nof the pushdown during parsing. Definition Let G = (V,Z,P,S) be a strict deterministic grammar with partition \nr. We may say y e V* is a valid strict deterministic prefix of G if there exist yl,. ..,Yn e V*; AO=S, \nA,,. ..,An , eN; n >1 such that y = l~~ ~ $ita~~~ prefiX of A o, where Ao= s YIA1 Y2A2 is a suitable \nprefix of $ yn is a suitable prefix of $-1. The first result begins to relate valid strict deterministic \nprefixes to prefixes. Lemma3.1 Let G = (V,Z,P,S) be a strict deterministic grammar, and let m be a strict \npartition on V. If y e V* is a valid prefix of G, then y is a valid strict deterministic prefix of G. \nOur next result is a generalization of Theorem 2.3 of [9]. Theorem 3.1 Let G = (V,Z,P,S) be a strict \ndeterministic grammar and let n be a strict partition on V. Let Ao,A~,A1,A; ,.. .,An,A~$ ~ N, Ai=A: for \n0<+ <n, aieV* for 0zi <n. Then in P we cannot have productions o Ai al 1 A; a2 A +A a n-1 nn An A6 \na. When n = O, the sequence reduces to A. +A~ cxo, Our next theorem is somewhat technical and says that, \nin some sense, a representation of a string into suitable prefixes is unique up to trailing A s. This \nresult is somewhat related to the Left-Part Theorem of [10], but the present context is more general. \nTheorem 3.2 Let G = (V, Z,P, S) be a strict deterministic grammar, and let IT be a strict partition on \nV. Suppose there exist y,ylY1,. .. >yn,y; ,y~.,y~ e V*; l  An-l i .. Al-l N; LnZlY where y=yT ... \nyn and y y! ... y; such that YIA1 is a suitable prefix of ~o, where ~o=~ Y2A2 is a suitable prefix \nof $ yn is a suitable prefix of An , and Y:A; is a suitable prefix of /T~, where Y; is a suitable-prefix \nof Am-l Then Yi = Y{ for l~i<n, Ai =A! for l~i <n-l, and for n+l <~ <M. Y:=A1 Our special algorithm \nTor parsing strict deterministic grammars requires items also. Definition Let G = (V,Z,P,S) be a strict \ndeterministic grammar with strict partition m on V. Then for A e N, a,f3, ,B, e V*, A+ LB. c IL in P. \n(A+ B1.62,A) is a valid strict determin\u00adistic item for a if there exist yl,. ..,yn e v*; such that a=yl \n. ..Y l  An-l N; ?-O n and ylAl is a suitable prefix of Ao, where /T. = 5 Y2AZ is a suitable prefix \nof Xl ynAn is a Suitaile prefix of An-l is a suitable prefix of $, with $ En =1. Note that the second \ncomponent is always A. The following result relates valid strict deterministic items to valid LR(0) items. \nLemma3.2 Let G = (V,Z,P,S) be a strict deterministic grammar and n be a strict partition of v. If for \nsome Ae N,a, &#38;,&#38; eV*. (A + 6,.62, A) is a valid LR(~) item for uB,, then it is also a valid strict \ndeterministic ite~ for c&#38;. Lemma3.3 Let G = (V,Z,P,S) be a strict det~rministic grammar. For every \nvalid strict deterministic prefix in G there corresponds at least one strict deterministic item. The \nnext result shows that the strict deterministic tables are consistent. Theorem 3.3 Let G = (V, Z,P, S) \nbe a strict deterministic grammar and let m-be a strict partition on G. Let A, A e N; Y, !32,!3~ e V*, \n 6,,61 e V+yand let y be a valid strict deter\u00administic prefix of G. Then if (A+ B1,62, A) is a valid \nstrict deterministic item for y, and if (A + 1$.6;, A) is a valid strict determin\u00ad istic item for y , \nthen A=A and 61 6i. %i%%?%s;;tg$;a! i;~s)r b~~~~~~~~t partition on G. Let a,L3,6 1,62 e V*; A, A e N. \nThen for C@ a valid strict deterministic prefix of G, if (A+ L3 ,A~ndis a valid strict deterministic \nitem for c@, (A +B1. i32, A) is a valid strict deterministic item for cxB, then (A+ (1., A) = (A + 61.62, \nA) For any y e V*, we wish to construct the set of valid strict deterministic items for y. This is accomplished \nby the following algorithm. Algorithm 3.1 G = (V,E,P,S), a strict deterministic!!QQ grammar with strict \npartition n and y e V* where y = Xl ... Xn, Xi e V, for some n~O, and 1 <i <n. w(y) = v; (y) Q!QA!l \nMethod (1) To construct W(A), (a) If for some ae V*, S+a is in P, add (S + -a, A) to W(A).  (b) If for \nsome A, Be N, a, f3e V*, we have (A+ .Ba,A) is in W(A) and B+ B is in P, add (B +.L3, A) to W (A).  \n(c) If for some Ae~ and aeV*, we have A+a is in P, add (A+ a, A) to W(A) (d) Go back to (b) unless nothing \nnew can be added to W(A). (2) To construct W(X1 . . . Xi), Xj eV for l~j~i, 721.  (a) If for some a,f3e \nV*, Ae N, Xj eV (A+a. Xi6, A) is in W(X1 . . . Xi-l) then add (A+aXi.B,A) to w(xl ,... xi).  (b) If \nfor some A, BeN; a, f3, 6eV* if (A+a .BB, A) has been placed in W(X1 . . . Xi).  and B+6 isin P, add \n(B + .6, A) to W(X1 ... xi). (c) If for some A, B, CeN, a,B,&#38;e V*, if (A+a.BB, A) has been placed \nin xi) and (f+ +U. BB, A) has been placed W(XI ... in W(X1 ... yi) and for some C ~ B, C+6 is in P, add \n(C + .6, A) to W(X1 ... Xi) (d) Go back to (b) unless nothing new can be added to W(X1 . . . Xi). We \nhope that the formalism of the preceding algorithm does not obscure the basic idea which is quite simple. \nThe idea is that when an item (B+ .6, A) is to be added fn the completer phase of the canonical algorithm, \none adds all items (B + .Y, A) where B z B mod ~. Next, we must show that the algorithm works. Theorem \n3.4 Let G = (V,X,P,S) be a strict deterministic grammar, and let y e V* be a valid strict deterministic \nprefix of G. Then an item is in W(Y) after application of our algorithm if and only if that item is a \nvalid strict deterministic item for y. Since the sets of items obtained from Alqorithm 3.1 are another \ninstance of character\u00adistic LR(k) items, we may speak of the associat\u00aded tables and the associated family \nc, s= G,O It is important to note that the tables that one gets by using Algorithm 3.1 are all consistent. \nTheorem 3.5 If G is a strict deterministic arammar then the ables obtained from the items ~roduced by \nAlgorithm 3.1 are consistent. Now we can invoke the theorems of Section II to prove that the characteristic \nparser which is based on the valid strict deterministic items actually works. Let us call this characteristic \nparser f c1 = G,O Theorem 3.6 Let G = (V,Z,P,S) be a strict deterministic grammar, and let m be a strict \nJ c1 partition on v. Then in the strict deterministic characteristic g~rser for G under partition cm, \nfor$ll x e L(G), (X, TO, A) l ~+QR!&#38; and the parser prints out p when SF and for all x # L(G). (x, \nT~, A) I* error Thus, we now have a parser for strict deterministic grammars. To see how good a parser \nthis is, we can easily compare it with the standard LR(0) parser for the same grammar. It is easy to \nsee that both parsers take the same time to process a string in L(G). As far as space is concerned, our \nparser is smaller. The followinq theorem gives very precise information. Theorem 3.7 Let G = (V,Z,P,S) \nbe a strict deterministic grammar under strict partition IT = {xi}. The size of our parser c, J is ISC1] \n=l+X]em (number ofnon-A suitable prefixes of Xi) Now that we know the size of our new parser, it must \nbe compared to the size of an LR(0) parser for a strict deterministic grammar G. The following concept \nis needed. Definition Let G = (V, Z,P, S) be a reduced strict deterministic grammar. Define the deterministic \nweak partition -c on V as -c={B ~,nln~O, yeV*}UZ. We define the sets B of -r where y e V*, y,n n ~ O \nas follows: A variable A e N is in B if and only if there exist y,n Y1, ... ,Yn+, e V*; A AeN 1  n \nsuch that (i) y=yl...yn (ii) ylA1 is a suitable prefix of {Ao}  where {Ao} = {S} Y2A2 is a suitable \nprefix of {Al} ynAn is a suitable prefix of {An-l} yn+l is a suitable prefix of {An} and (iii) An=A Note \nthat -c is a weak partition of V, that a family of subsets of V such that every ~s~ V is in some subset \nof T. Also note that {S} is alWaYS a subset of any such T. The deterministic weak partition T may be \neffectively computed. Our next result relates weak partitions with strict partitions. Lemma3.4 Let G \n= (V,Z,P,S) be a strict deterministic arammar and let T be the deterministic ~eak partition on V. If-m \nis any strict partition on V then -c refines m, that isif A = A modm then A~A mod~. Now we can give an \nexact formula for the size of the canonical LR(0) parser of any strict deterministic grammar. Theorem \n3.8 Let G = (V,Z,P,S) be a strict deterministic grammar and let T be the deterministic weak partition \non V. The size of the canonical LR(0) parser co. Jco J is ISl = 1+ Y (number of G,O B;T non-A suitable \nprefixes of B). Corollary Let G = (V,X,P,S) be a strict deterministic grarmnar and IT any strict partition \nc1 on G. If J is the parser of G (of Theorems 3.6 and 3.7) and J co is as in Theorem 3.8, we have lJcl\\ \n~ lJcOl The previous corollary justifies our assertion that the present parsers are an improvement over \ncanonical LR(0) parsers. Theorem 3.8 is not true for arbitrary LR(0) grammars. For that case, one presently \nhas only the bounds given in [12,13]. Let us consider an example which compares the size of our strict \ndeterministic parser with the LR(0) parser. Let Gm,n = (V,X,P,S) where z = {a,aills ii n}, V = XU{S,Aill~ifin}, \nand P contains S + aiAi for l~i~n. Ai+amAi I ai for l~i~n. The minimal strict partition on G is n = {z, \n{S}, {A1,. ..,An}} The number of tables in the parser is (by Theorem 3.7) l+2n+(2n+m) = ~+4n+m We can \ncalculate the size of the LR(0) parser by Theorem 3.8 and one finds that the size is l+3n+n(m+l)=l+4n+ \nnm. Thus the difference in size is m(n-1). We shall now fix m = n = 2 and exhibit the parsers. The grammar \nis now: 1. s+ alAl 2.  s + a2A2 3. Al+ aaA1 Al+ al 4. 5. AZ+ aaA2 A2+ az 6. and m= {x, {S}, {,4,, \nAZ}}. First we list the items for the strict deterministic parser. The items circled were items that \nwere added to the canonical LR(0) tables. For the sake of comparison, we generate the canonical LR(0) \nparser. s+ A, + aa.A, s+ al 1 6s+ a2A2 o alAl s+ A2+ aa.A2 o s+ az 2 a2A2 Al + .aaA1 a .aA2 7 2+ s+ \nal Al 6 Al+ .al A, + .aaA, s+ al Al A2 + .aaA2 Al + .aaA1 8 2+ a2 A,+ .a, 1 A2+ .a2 1 Al+ .al Al + aa.A1 \nII A2+ .aaA1 A,+ aaA,. 9 1 + .aaA2 7 Al+ .al .a2 s + a2 A2 A2 + .aaA2 L ------------1 A2 + aaA2 2 8 A2+ \n.a.2 A2 + aa.A2 s+ 2 al 1 .aaA s + a2 A2 lo A2+ 2 3 s+ hAl A2+ .a2 A2 + .aaA2 Al+ al\u00ad 3 A2+ .a2 A, + \na.aA, 9 4 aaA1 11 Al+ Al + .aaA1 A2 + 4 a2 Al+ al. Al + .a, 5 aaA2s 12 2+ II----------- A, + a.aA 1 \n5 A2 + a. aA2 1 o s + a2A2 We have found 13 sets which corresponds to l+4n+nm =1+13+4=13 By our formula \n4n+m+l =8+2+1=11 The classic LR(0) parser is shown below: The corresponding tables are as follows where \nf al al a 1 2 s T1 l-2 Ti = T(Ai). .. 9 T5 4 3 f shift al a2 a 1 2s ----- 8 7 6 2 reduce 1shift o .----- \n1 9 3 shift shift ..... 9 1 . ---- 3 4 5 2 4 reduce 1 reduce 4 -e ---\u00ad 2 ------ 5 reduce 4 reduce 2 \n...... 3 ------ 6 reduce 6 shift ..... 1o 4 ------ 7 shift reduce 6 5 ----- 6 8 shift shift ----- 5 \n4 11 6 ----- 3 4 5 7 8 9 shift reduce 3 8 7 12 ..,----\u00ad 7 ------ 1 o reduce 5 reduce 3 ...... 8 -....-.. \n11 shift reduce 5 .-.--\u00ad 9 ----- 1o 12 reduce 2 T -..z-.-THE CANONICAL LR(0) PARSERFOR 2,210 THE STRICT \nD ERMINISTIC PARSERFOR G2 z , ACKNOWLEDGEMENT We wish to thank Professor S.L. Graham for a number of \nstimulating conversations. REFERENCES 1. Aho, A.V. and Unman, J.D. , The Theory of of Parsin g, Translating, \nand Compiling, Vols. I and II, Prentice Hall, Englewood Cliffs, New Jersey, 1972, and 1973. 2. Aho, \nA.V. and Unman, J.D. , Optimization of LR(k) Parsers , Journal of Computer and System Sciences, Vol. \n6, pp 573-602, 1972. 3. El Djabri, N., Extending the LR Parsing Technique to Some Non-LR Grammars , \nTechnical Report TR-121, Computer Science Laboratory, Princeton University, 1973. 4. Floyd, R.W., NondeterministicA \nlgorithms , Journal of the Association for Computing Machinery, Vol. 14, pp 636-644, 1967. 5. Geller, \nM.M., Characteristic LR(k) Parsing , Ph.D. Thesis (in preparation), Computer Science Department, University \nof California, 8erkeley, 1973. 6. Geller, M.M. and Harrison, M.A., Characterizations of LR(0) Languages \n, Fourteenth Annual Symposium on Switch\u00ading and Automata Theory, 1973. 7. Graham, S.L., Extended Precedence, \nBounded Right Context Languages and Determin\u00adistic Languages , Proceedings of Symposium on Switching \nand Automata Theory, pp 175-180, 1970. 8. Graham, S.L., Precedence Languages and Bounded Right Context \nLanguages , Ph.D. Thesis and Techpiral Report CS-71 --233, Department of Lomputer Science, Stanford University, \n1970. 9. Harrison, M.A., and Havel, I.M., strict Deterministic Grammars , Journal of Computer and Systems \nScience, Vol. 7 pp 237-277, 1973. 10. Harrison, M.A., and Havel, I.M., On the Parsing of Deterministic \nLanguages , submitted for publication. 11. Harrison, M.A., and Havel, I.M., f/eal-tinle Strict Deterministic \nLanguages , SIAM Journal of Computing, Vol. 1, pp 333\u00ad 12. Kemp, R., LR(k) Analysatoren , Technical \nReport A73/02, Mathematisches Institut und Institut ftir Angemandte Mathematik, Universitat des Saarlandes, \nSaarbrucken, Germany, 1973. 13. Kemp, R., An Estimation of the Set of States of the Minimal LR(0)-Acceptor \n, in Automata, Languages and Programmin~,  (M. Nivat, editor) North Holland Publish\u00ading Co., Amsterdam, \npp 563-574, 1973. 14, Knuth, D,E., On the Translation of Languages from Left to Right , Information and \nControl, \\!ol. 8, pp 607-639, 1965.  \n\t\t\t", "proc_id": "512927", "abstract": "Recently strict deterministic grammars and languages have been introduced [9,10,11]. This family of languages is quite fundamental in the study of the mathematical properties of deterministic languages and in dealing with some classical families of grammars such as LR(k) and bounded right context grammars [7,8,14]. These grammars are closely related to LR(0) grammars [1,12,13,14], in fact each strict deterministic grammar is also LR(0). In the present paper, we consider the question of how to parse strict deterministic grammars. We introduce part of a more general theory called \"characteristic LR(k) parsing\". This actually produces parsers which are tuned to the characteristics of a particular family of grammars. We apply the theory to the family of strict deterministic grammars and we get parsers which are as fast as canonical LR(k) parsers but are substantially smaller. They are not necessarily minimal but we postpone any discussion of minimality to the sequel.The techniques used in the present discussion are quite general [5]. For instance, the study in [3] is similar in spirit to our technique. The optimization techniques for LR(k) parsers in [2] do not work in the case k = 0 without modification. After modifying those methods for k = 0, it can be shown that our parsers cannot be produced by those techniques. This fact has its positive aspect in that our parsers may be smaller and its negative aspect in that error detection may be delayed.The present paper is divided into the present introduction and three sections. In the remainder of this introduction, some basic definitions of strict deterministic and LR(k) parsing are given. We have tried to follow [1] as much as possible in order to minimize the amount of new material to be absorbed. The order of the results is the order needed to prove that the characteristic parser works. In Section III, we apply the theory of Section II to strict deterministic parsing. A simple example shows that the new parsers can be unboundedly smaller than the canonical LR(0) parser.The present paper is meant to be an extended abstract and no proofs are included.The rest of the introduction is concerned with notational conventions for the technical concepts needed.", "authors": [{"name": "Matthew M. Geller", "author_profile_id": "81536880156", "affiliation": "University of California, Berkeley", "person_id": "P348463", "email_address": "", "orcid_id": ""}, {"name": "Michael A. Harrison", "author_profile_id": "81100011116", "affiliation": "University of California, Berkeley", "person_id": "PP14016859", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512927.512929", "year": "1973", "article_id": "512929", "conference": "POPL", "title": "Strict deterministic versus LR(0) parsing", "url": "http://dl.acm.org/citation.cfm?id=512929"}