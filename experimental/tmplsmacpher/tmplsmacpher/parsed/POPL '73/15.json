{"article_publication_date": "10-01-1973", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1973 ACM 0-12345-678-9 $5.00 REASONING ABOUT PROGRAMS* by Richard J. Waldinger Karl N. Levitt Stanford \nResearch Institute Menlo Park, California Problems worthy of attack Prove their worth by hitting back. \nPiet Hein ABSTRACT that could prove theorems about programs; his pro\u00adgram proved an interesting class \nof theorems and This paper describes a theorem pro er that was very fast. Peter Deutsch [1973] has recently \nembodies knowledge about programming constructs, written a system for interactive program writing such \nas numbers, arrays, lists, and expressions. that can also prove things about programs. It is The program \ncan reason about these concepts and is perhaps not as fast as King s system, but it can used as part \nof a program verification system that prove more interesting theorems. S. Igarashi, uses the Floyd-Naur \nexplication of program seman-R. London,and D. Luckham [1973] have recently ap\u00adtics. It is implemented \nin the QA4 language; the plied a resolution theorem prover to program verifi-QA4 system allows many bits \nof strategic knowledge, cation, and their results are impressive also. each expressed as a small program, \nto be coordi-They can verify such programs as Hoare s [1961] nated so that a program stands forward when \nit is FIND . Their system does little actual resolution relevant to the problem at hand. The language \nal-and a lot of simplification and reasoning about lows clear, concise representation of this sort of \nequality. A program devised by Boyer and Moore knowledge. The QA4 system also has special facili-[1973] \ncan prove difficult theorems about LISP pro\u00adties for dealing with commutative functions, or-grams. dering \nrelations, and equivalence relations; these features are heavily used in this deductive system. Thus \n, there is no shortage of interesting work The program interrogates the user and asks his ad-related \nto our own. The special characteristic of vice in the course of a proof. Verifications have our own system \nis that it is markedly concise, read\u00adbeen found for Hoare s FIND program, a real-number able, and easy \nto change and apply to new subject division algorithm, and some sort programs, as well areas. as for \nmany simpler algorithms. Additional theo \u00adreins have been proved about a pattern matcher and Our deductive \nsystem is one part of a program a version of Robinson s unification algorithm. verifier. The other part \nof the program verifier constructs theorems called verification conditions; the deductive system proves \nthem. The verification I INTRODUCTION AND BACKGROUND condition generator [Elspas et al., 1973] is written \nin BBN-LISP [Teitelman et al., 1971], and the deduc- This paper describes a computer program that tive \nsystem is written in QA4 [Rulifson et al,, 1972]. proves theorems about programs. Proving theorems This \npaper focuses on the deductive system but gives about programs is of practical importance because examples \nof verification condition generation as it helps certify that they are correct. Instead of well. testing \na program on test cases, which may allow some bugs to remain, we can try to prove mathemati-In writing \nour deductive system, we were moti\u00adcally that it behaves as we expect. We hope future vated by several \ngoals. First , the system should systems that reason about programs and understand be able to find proofs; \nit should have enough deduc\u00adhow they work will help us to write and change pro-tive power to prove, within \na comfortable time and grams. space, the theorems being considered. Also, these proofs should be at the \nlevel of an informal demon-Many programs have done this sort of reasoning. stration in a mathematical \ntextbook. This means James King [1969]T developed a program verifier that the difficulty in following \none line to the next in any proof should be small enough that the * The research reported herein was \nsupported in part by the National Science Foundation, under Grant GJ-36146, and in part by the Advanced \nResearch Projects Agency, under Contract DAHC04-72-C-OO08. t References are listed alphabetically at \nthe end of the paper. proof is understandable, yet large enough not to be trivial. Furthermore , the \nstrategies the system uses in searching for a proof should be strategies that we find natural. Not only \nshould the tactics that eventually lead to the proof be ones we might use in proving the statement by \nhand, but also the false starts the system makes should be ones we might make ourselves. We do not want \nthe system to rely on blind search; the trace of an attempted so\u00adlution should make interesting reading, \nIn addition to the requirement that proofs be readable, the rules the system uses in going from one line \nto the next should be easy to read and un\u00adderstand. We should be able to look at a rule and see what \nit does. Also , it should be easy to change old rules and add new rules, The user of a program verifier \nis likely to introduce new con\u00adcepts. We want to be able to tell the deductive system how these structures \nbehave and to have the system reason effectively about new symbols. Gi v\u00ading the system new information \nshould be possible without knowing how the system works, and certainly without reprogramming the system. \nFurthermore, the addition of new information should not prohibi\u00adtively degrade the performance of the \nsystem. The system is intended to evolve with use. As we apply the system to new problems, we are forced \nto give the system new information and, perhaps, to generalize some old information. These changes are \nincorporated into the system, which may then be bet\u00adter able to solve new problems. Since the system \nis easy to extend and gener\u00adalize, we do not worry about the completeness or generality of any particular \nversion of the system It is powerful enough to solve the class of prob\u00adlems on which it has been trained, \nand it can be easily changed when necessary. These considerations played a part in the de\u00adsign of the \nprogramming system called QA4, as well as in the construction of our deductive system, which is written \nIn the QA4 language. Some of the techniques described below are embedded in the f2A4 system Itself; others \nare expressed as parts of the deductive system. II A SAMPLE PROGRAM THAT FINDS TRE LARGEST ELEMENT OF \nAN ARRAY Before we explain how the system is structured or implemented, let us first look at a sample \nof some deductions performed by our system, This ex\u00adample will give a better idea of the SUbJeCt domain \nof the inference system and of the sort of reason\u00ading we have to do. It will also give a better pic\u00adture \nof the process of generating a verification condition (Floyd [1967]). 1I - No 9i MAX<AIII ? E Yes LOC \n-+ I MAX + AII] @ 1 FIGURE 1 FINDING This program track of the the location sertion at C in dex the some \nthe Suppose we are given the annotated program shown in Figure 1 to compute the largest element in an \narray and its location. .................. . O<N :. .,... ........ .... ... ,,, ..... . . ,. ..,... \n.......... .. ....... . .... : MAX = AILOCI ; AA IO] < MAX, A[ll < MAX,. .. : , A[l] <MAX ;AO<LOC<[<N \n. ........ .... ........ ......... ....... . I. .... .,.,,,,.., .......... c C around the loop and \nback point E. C around the loop and hack point F. the array for MAX. ellipsis suitable To prove system \nprogram can . The . The . The to . The to searches largest of this says that between Although notation \nanalogues, assertions decomposes path from path from path from C through path from C through F THE MAXIMUM \nOF AN ARRAY through element element. MAX is O and I ( . it be decomposed B C ....................... \n... . ..... :AIOI < MAX, AINI < MAX: : A MAX = AI LOC] :AO~LOC<N ........... ,,, ., ............... ..... \n TA-740522-8 the array, keeping it has seen so far The intermediate the largest element and that LOC \nis the our language does not permit . . ), we have Introduced which are discussed later. about a complex \nprogram, into simple paths. This into four simple paths: to C. to D. and as\u00ad in\u00ad Notice that the author \nof this program has put The behavior of the deductive system in this assertions not only at the START \nand HALT nodes of problem is typical of its approach to many problems. the program, but also at the intermediate \npoint C. The goal, (6), is broken into two subgoals: He has done this so that the straight-line paths \ncan be verified in the same way that a simple pro-AIO] <AII+l] A . . . AII] sA[l+l] (7) gram is. For \ninstance, the path that begins at C, travels around the loop through E, and returns to and C, can he \nregarded as a simple, straight-line pro\u00adgram with the assertion at C as both its start as-AII+l] sAII+l] \n. (8) sertion and its halt assertion. lhe assertion at C has been cleverly chosen to be true when the \nloop The second subgoal, (8), is immediately is entered, to remain true whenever control trav-seen to \nbe true. The first subgoal, (7), is easily els around the loop and returns to C, and to be derived from \n(2) and (5). strong enough to allow the assertion at D to be proved when control leaves the loop and \nthe program Now let us look at the path from C to D. We halts. (The choice of suitable internal assertions \nwill assume the assertion at C is true and will can be an intellectually exacting task; some heuris-prove \nthe assertion at D. We will look at the first tic methods have been proposed that will work in conjunct \nof the assertion at D. Our verification this and many other examples (Elspas et al. [1972], condition \ngenerator gives us the following statement Wegbreit [1973], Katz and Manna [1973]). to prove: If all \nthe straight-line paths of the program MAX = AILOC] A (9) are shown to be correctly described by the \ngiven as\u00adsertions, and if the program can be shown to termi-AIO]SMAX A... AAII]sMAXA (lo) nate (this \nmust be done separately), then we can conclude that the program is indeed correct, at O<LOCSISNA (11) \nleast with respect to the programmer s final asser\u00adtion. N<I+12 (12) Although there are many paths in \nthe decompo-AIo]<MAXA. .. AA[N]< MAX A . (13) sition of a program, typically most of the paths are easy \nto verify. For this program, we examine The reasoning required for this proof is a little two of the \npaths. more subtle and less typical than the previous deduc\u00ad tion. When the system learns that N < 1+1 \n(12), it Fxrst , suppose we Want to demonstrate that if immediately concludes that N+l S 1+1, since N \nand I the assertion at point C is true when control are integers. It further deduces that N s 1. Since \npasses through C, then the assertion at C will it already knows that I < N (11), it concludes that still \nbe true if control passes around the loop and N=I. The goal (13) it reduces to proving is that returns \nagain to C. We will restrict our attention I = N, which it now knows. to the case in which the test MAX \n< AII]? is true; in this case, control passes through E. Further-This deduction is atypical because it \ninvolves more, we will try to prove only that the second con-a lot of reasoning forward from assumptions \nand not junct of the assertion at C remains true. Our veri-much reasoning backward from goals. However, \nboth fication condition generator gives us the following of these proofs are typical of the behavior \nof the statement to prove: system at large because of their strong use of the properties of equality \nand the ordering relations. MAX = AILOC] A (1) The QA4 system incorporates enough of the com\u00adAIo]s MAX, \n. . .. A[I~<hL4XA (2) mon techniques of theorem proving and problem solv\u00ading that our inference system \nneeds no general o<LOC51SNA (3) problem-solving knowledge, but only some knowledge about numbers, arrays, \nand other structures. The -I (N < 1+1) A (4) following sections show how the QA4 language allows that \nknowledge to be represented. MAX <AII+l] 2 (5) AIo] sAII+l], . . . . AII+l] sAII+l] . (6) III THE QA4 \nLANGUAGE This statement is actually represented as five sep-A. Pattern Matching and the Goal Mechanism \narate hypotheses and a goal to be deduced from these hypotheses. The deductive system is made up of many \nsmall functions or programs. Each of these programs knows one fact and the use for that fact. The QA4 \nprogramming language is designed so that all these programs can be coordinated; when a problem is pro\u00adposed \nto the system, the functions that are relevent to the problem stand forward. A program has the form (LAMBDA \n(pattern)(body)) . Part of the knowledge of what the program can be used for is expressed in the pattern. \nWhen a func\u00adtion is applied to an argument, the pattern is matched against that argument. The unbound \nvari\u00adables in the pattern are bound to the appropriate subexpressions of the argument, and the body of \nthe program is evaluated with respect to those new bind\u00adings. For example, the program REVTUP . (LAMBDA \n(TUpLE -x -Y) (TUpLE $Y $x)) has pattern ( IUPLE +X +Y) and body (TUPLE $Y $X), The prefix + means that \nthe variable is to be given a new binding. The prefix $ means that the variable s old binding is to be \nused. When REVTUP is applied to (TUPLE A B), the pattern (TUPLE -X *Y) is matched against (TUPLE A B). \nThe variable X is bound to A, and the variable Y is bound to B. The body (TUPLE $Y $X) is evaluated with \nrespect to these bindings, giving (TUPLE B A). On the other hand, if a function is applied to an argument \nand the pattern of that function does not match the argument, a condition known as fail\u00adure occurs. At \nmany points in the execution of a program, the system makes an arbitrary choice be\u00adtween alternatives. \nFailure initiates a backing up to the most recent choice and the choice of another alternative. The mismatching \nof patterns is only one of the ways in which failure can occur in a pro\u00adgram. We have yet to explain \nhow a program stands for\u00adward when it is relevant. In the above example, the function was called by name, \nmuch as it is in a con\u00adventional programming language, But it is also pos\u00adsible to make an argument available \nto any applica\u00adble program in a specified class. This is done by means of the goal mechanism. When we \nsay (OOAL (goalclass)(argument)), we assume that the goal class IS a tuple of names of functions. We \nare making that argument available to the entire class of functions. The pattern of each of those functions \nis matched in turn against the argument. If the match is successful, the function is applied to that \nargument. If the function re\u00ad turns a value, that value is returned as the value of the goal statement. \nOn the other hand, if a failure occurs in evaluating the function, back\u00ad tracking occurs, the next function \nin the goal class is tried, and the process is repeated, If none of the functions in the goal class succeed, \nthe entire goal statement fails, For example, in our deductive system, one of the goal classes is called \nEQRULES, the rules used for proving equalities. One of these rules is EQTIMESDIVIDE = (LAMBDA (EQ -w \n(TIMEs (DIVIDES -x -y) +2)) (GOAL $EQRULES (EQ (TIMES $y $W)(TIMES $x $z)))) . This rule states that \nto prove W = (X/Y) *Z, we should try to prove Y*W = X*Z. The rule has the pat tern (EQ -w (TIMEs (DIVIDES \n-x -Y) -z)) . If we execute (GOAL $EQRULES (EQ A (TIMES (DIVIDES BC)D))) [i.e., we want to prove A = \n(B/c) *D], the system will try all the EQRULES until it comes to EQTIMESDIVIDE. It will find that the \npattern of EQTIMESDIVIDE matches this argument, binding W to A, XtoB, YtoC, andZto D. Then it will evaluate \nthe body of this function; I.e., it will try (GOAL $EQRULES (EQ (TIMES .4 C) ( I ImS B D))) . If it fails \nto prove (EQ (TIMES A C) (TIMES B D)), it will try to apply the remaining EQRULES to the original argument, \n(EQ A (TIMES (DIVIDES B D) D)). The goal statement is an example of the pattern\u00addirected function invocation \npopularized by Hewitt in PLANNER [1971]. The net effect of this mechanism is that it en\u00adables the user \nto write his programs in terms of what he wants done, without needing to specify how he wants to do it. \nFurthermore, at any point, he can add new rules to EQRULES or any other goal class, thus increasing the \npower of the system with little effort. B. Some Sample Rules The deductive system is a collection of \nrules represented as small programs. One rule was given in the preceding section; two more rules are \npre\u00adsented here. The first rule is EQSIMP = (LAMBDA (EQ *X +Y) (pROG (DECLARE) (i3ETQ -x ($ SIMPONE $x)) \n(GOAL $EQRULES (EQ $x $Y))) BACKTRACK) . This rule says that to prove A and B are equal, sim\u00adplify A \nand then prove that the simplified A is equal to B. This rule, a member of EQRULES, has the pattern (EQ \n+X -Y). SIMPONE, the name of the simpli\u00adfier, will fail if its argument cannot be simplified. In that \ncase, EQSIMP will also fail. EQSIMP can ac\u00adtually simplify the right side of an equality, as well as \nthe left, as explained in the next section. The second rule is m3uBm..4cT1 . (LAMBDA (-F (SUBTRACT -x \n-Y) -2) (GOAL $lNEQUALITIES ($F $X (PLUS $Y $Z)))) . This rule says that to prove X-Y s Z, try to prove \nx < Y+z. It belongs to the goal class INEQUALITIES and is thus used not only for the predicate LTQ, but \nalso for LT, GT, and GTQ. The variable F is bound to the appropriate predicate symbol. c. Demons The \ngoal mechanism is used for reasoning back\u00adward from a goal. However, sometimes we want to rea\u00adson forward \nfrom an assertion. For example, suppose that whenever an assertion of the form X 2 Y is made, we want \nto assert Y G X as well. We do this by a QA4 mechanism known as the demon. A demon is imagined to be \na spirit that inhab\u00adits a hiding place, waiting until some specified event occurs, at which time it appears, \nperforms some action, and vanishes again. We have put sev\u00aderal demons in the system, each watching for \na dif\u00adferent condition. The demon we use above watches for assertions of the form X Z Y and makes the \nas\u00adsertion Y s X. The user of the system can create his own demons. However, once they are created, there \nis no way to get rid of them. D. Representations To as great an extent as possible, we have cho\u00adsen representations \nthat model the semantics of the concepts we use so as to make our deductions shorter and easier. For \nexample, our language has data structures especially intended to eliminate the need for certain inferences. \nIn addition to tuples, which are like the familiar lists of the li.st\u00ad processing languages, we have \nthe finite sets of con\u00adventional mathematics and bags, which are unordered tuples or, equivalently, sets \nwith multiple occur\u00adrences of the same element. (Bags are called multi\u00adsets by Knuth [1969], who outlines \nmany of their properties.) Furthermore, we allow arbitrary expres\u00adsions to have property lists in the \nsame way that atoms can have property lists in LISP [McCarthy et al., 1962] . These data structures are \nuseful in the model\u00ading of equivalence relations, ordering relations, and arithmetic functions. For instance, \nif the addi\u00ad tion of numbers and the multiplication of numbers are each represented by a function of \ntwo arguments, then it becomes necessary to use numerous applica\u00adtions of the commutative and associative \nlaws to prove anything about the number system. However, in QA4 all functions take only one argument, \nbut this argument can be a tuple, set, or bag, as well as any other expression. Functions of multiple \narguments can be represented by a function defined on tuples. However, a function that is commutative \nand associa\u00adtive, such as PLUS, is defined on bags. The expres\u00adsion (PLUS A 2 B) really means (PLUS (BAG \nA 2 B)). Recall that bags are unordered; the system cannot distinguish between (BAG A 2 B) and (BAG 2 \nA B). Consequently, the expressions (PLUS A 2 B) and (PLUS 2 A B) are identically equal in our system. \nThis makes the commutative law for addition redundant and, in fact, inexpressible in the language. Most \nneeds for the associative law are also avoided. The logical function AND has the property that, for instance, \n(AND A A B) = (AND A B). The number of occurrences of an argument does not affect its value. AND takes \na set as its argument. (sETA A B) and (SET A B) are indistinguishable. Therefore, (AND A A B) and (AND \nA B) are identical, and a state\u00ad ment of their equality is unnecessary. Some func\u00adtions that take sets \nas arguments are AND, OR, EQ, and GCD (greatest common divisor). When a new fact is asserted to our system, \nthe value TRUE is placed on the property list of that fact. If at some later time we want to know if \nthat fact is true, we simply look on its property list. However, certain facts are given special han\u00addling \nin addition. For example, if we tell the sys\u00adtem that certain expressions are equal, we form a set of \nthose expressions. On the property list of each expression, we place a pointer to that set. For instance, \nif we tell the system (ASSERT (EQ A B C)), the system stores the following: A Bc EQEQ EQ w (SET A BC) \nTA-740522-6 If we then discover any of these expressions to be equal to still another expression, the \nsystem adds the new expression to the previously formed set and puts the set on the property list of \nthe new expres\u00adsion as well, For instance, if we say (ASSERT (EQ B D)), our structure is changed to the \nfollowing: ABc D (SET A BC D) TA-740522-7 The transitivity, symmetry, and reflexivity of equal\u00adity are \nthus implicit in our representation. If we ask the system whether A and D are equal (by evalua\u00adting (ISREL? \n(EQ A D))), the system knows immediately by looking at the property list of A or D. Ordering relations \nare stored using the property list mechanism. If we know that some expression A is less than B, we place \na pointer to B on the property list of A: LT A B. If we learn that B is less than C, we put a pointer \nto C on the property list of B: LT LT A B c. If we then ask the system if A is less than C, it will search \nalong the pointers in the appropriate way to answer affirmatively. The transitive law is built into this \nrepresentation. The system knows about LT (<), GT (>), LTQ (s), GTQ (>), EQ (=), NEQ (#), and how these \nrelations interact. E. Contexts When we are trying to prove an implication of the form A ?B, it is natural \nto want to prove B un\u00adder the hypothesis that A is true. Our assumption of the truth of A holds only \nas long as we are try\u00ading to prove B; after tbe proof of B is complete, we want to forget that we have \nassumed A. For this and other reasons, the QA4 language contains a context mechanism. All assertions \nare made with respect to a context, either implicitly or explicitly. For any context, we can create an \narbitrary number of lower contexts. A query made with respect to a context will have access to all assertions \nmade with respect to higher contexts but not to any assertions made with respect to any other contexts. \nFor instance, suppose we are trying toprove i<j2i+1sjwith respect to some context CO. We may have already \nmade some as\u00adsertions in context Co. We establish a lower context Cl and assert i < j with respect to \nCl. Then we try to prove i + 1 < j with respect to Cl. When proving i + 1s j, weknowi <j, as well as \nall the asser\u00adtions we knew previously in Co. When the proof of B is complete, we may have other statements \nto prove in co. In doing these proofs, we will know all the as\u00adsertions in Co and also, perhaps, the \nassertion i <j ~i + 1< j, but we will not know i < J because it was asserted with respect to a lower \ncontext. F. User Interaction Sometimes our rules ask us whether they should continue or fail. This allows \nus to cut off lines of reasoning that we know in advance to be fruitless. If we make a mistake in answering \nthe question, we may cause the system to fail when it could have suc\u00adceeded. However, we never cause \nthe system to find a false or erroneous proof. In addition to these mechanisms, which are built into \nthe language processor, we have developed some notations that make it easier to discuss programming constructs; \nthese notations are interpreted by the deductive system. IV NOTATIONS In speaking about the program to \nfind the maxi\u00admum element of an array, we found it convenient to use the ellipsis notation ( ... ). We \nhave not in\u00adtroduced this notation into our language; however, we have found ways of getting around its \nabsence. A. TUPA, SETA, BAGA Let A he a one-dimensional array and I and J be integers. Then (TUPA A I \nJ) is the tuple (TUPLE AII], AII+l], . . . . A[J]). If I > J, then (TupA A I J) is the empty tuple. (SETA \nA I J) and (BAGA A I J) are the corre\u00adspending bag and set. To state that an array is sorted between \nO and N, we use (LW (TTJPA A o N)) . To state that an array A is the same in contents be\u00adtween O and \nN as the initial array AO, although these contents may have been permuted, we use (EQ (BAGA A o N) (BAGA \n.40 0 N)) . B. The Strip Operator Let Xbe a set or bag, X = (SET Xl, .... Xn), or X=(BAG X1, . . . . \nXn). Then (L~ (STRIP X) Y) means X1sYand . . . XnSY. To state that MAX is greater than or equal to any \nelement in an array A between I and J, we use (LN (f5TRIp (BAGA A I J)) MAX) . Th s is perhaps not quite \nas clear as 4[1] < MAX, AII+l] < MAX, .... A[J] < MAX , (BAGA (STRIP (BAG B C D))) but we prefer (i+u) \n[(I it <U to Au< J) 2A[u] <MAX] . belongs IIIus, Y for P/Q. plays the becomes a role better of the and \ninterval better [Y, Y+D). approximation The STRIP operator theses from expressions: is also used to remove \nparen\u00ad is (BAGAB cD) We will eventually need two distinct operators, one to act as a quantifier and \none to remove paren\u00adtheses, but the single operator STRIP has played both roles so far. c. Access and \nChange Arrays cannot be treated as functions because their contents can be changed, whereas functions \ndo not change their definitions. Thus, while f(x) is likely to mean the same thing for the same value \nof x at different times, A[x] is not. We overcome this difficulty by adopting McCarthy and Painter s \n[1967] functions ACCESS and CHANGE in our explication of the array concept: (ACCESS A I) means AII]. \n(CHANGE A I T) means the array A after the assignment statement AII] ~ T has been executed. We do not \npropose that ACCESS and CHANGE be used in writing programs or assertions; we do find that they make reasoning \nabout arrays simpler, as King sus\u00adpected they would. The next sections show examples of some fairly difficult \nproblems solved by the deductive system. v THE REAL NUMBER QUOTIENT ALGORITHM Very little work has been \ndone to prove things about programs that work on the real numbers of the floating point numbers, although \nthere is no reason to believe such proofs could not be done. Figure 2 shows , for inStanCe, a program \n(Wensley [1958]) to compute an approximate quotient Y of real numbers P and Q, where O < P < Q. This \nis an interesting and computationally plausible algorithm. It uses only addition, subtraction, and division \nby two, and it computes a new significant bit of the quotient with each iteration. The algorithm can \nbe understood in the follow\u00ading way. At the beginning of each iteration, P/Q belongs to the interval \n[Y, Y+D). It is determined whether P/Q belongs to the left half or the right half of the interval. Y \nand D are adjusted so that in the new iteration, the half-interval to which Y +..... .... ............ \n . . :A=Q,Y 2*B =Q*D : m iPi Y:Q: Ei :Y*Q<P ....................  w , :..,.... . ... I 4 No t I I Y+D12 \nA*A+B  I--E&#38;J Y+ [y TA-740522-9 FIGURE 2 THE WENSLEY DIVISION ALGORITHM We will consider here \nonly one path through this program, i.e. , the path around the loop that follows the right branch of \nthe test P < A+B. We will prove only one assertion: P <Y*Q + D*Q. Our verification condition generator \nsupplies us with the following hypotheses: A=Q*Y , (14) 2*B = Q*D , (15) P< Y* Q+D*Q , (16) Y*Qs P, (17) \nl(DCE), (18) P<A+B . (19) The goal is to prove from these hypotheses that P <Q*Y + Q*(D/2) . (20) These \nhypotheses and the goal were constructed in a manner precisely analogous to the generation of the condition \nfor the previous example of computing the maximum of an array. The proof goes as follows. After an abortive \nattempt at using the assertion (16) , the system tries to show that the conclusion follows from (19). \nIt therefore tries to show that A+B < Q*Y + Q*(D/2) . (21) This goal is broken into the following two: \nA < Q*Y (22) B < Q*(D/2) . (23) Goal (22) follows from (14), whereas (23) reduces to (15). VI A PATTERN \nMATCHER As an experiment in the incorporation of new knowledge into the system, we performed the partial \nverification of a simple pattern matcher and a re\u00adcursive version of the unification algorithm [Robinson, \n1965]. These algorithms were of special interest to us because they involve concepts we have actually \nused in the implementation of the QA4 pro\u00adgram itself. They are thus in some sense realistic, although \nneither of these programs appears literally in the QA4 code. The subject domain is as follows. We assume \nthat expressions are LISP S-expres\u00adsions [McCarthy, 1962]; for example, (F X (G A B)) is an expression. \nAtomic elements are designated as either constant or variable, and they can be dis\u00adtinguished by the \nuse of the predicates const and var. Here we use A, B, C, F, and G as constants and U, V, W Y, and Z \nas variables: 9 var(X) is true . const(A) is true var(A) is false var((X Y)) is false. A substitution \nreplaces some of the variables of an expression by terms. Substitutions are repre\u00adsented as lists of \ndotted pairs. ((x . A) (Y . (F G))) is a substitution. Varsubst(s,e) is the re\u00adsult of making substitutions \nin expression e. If S is ((x .A) (Y. (GB))) , and eis (FXA(YB)) , then varsuhst(s,e,) is (FAA ((GB) B)) \n. The LISP functions car, cdr, list, and atom can be used to manipulate expressions. The empty substitu\u00adtion \nis denoted by EMPTY and has no effect on an ex\u00adpression. An operation (compose) called the compo\u00adsition \nof substitutions, defined by Robinson [1965], has the following property: varsubst(compose(sl, s2) e) \n= varsubst(sl, varsubst(s2, e)) . The problem of pattern matching is defined as follows: Given two expressions \ncalled the pattern and the argument, find a substitution for the vari\u00adables of the pattern that makes \nit identical to the argument. For example, if pat is (x(YAB)X) , and arg is (D(CAB)D) , then match(pat \narg) is ((x .D) (Y .C)) . If there : s no substitution that makes the pat\u00adtern identical to the argument, \nwe want the pattern matcher to return the distinguished atom NOMATCH. Thus , if pat is (X YX) and arg \nis (A BC), then match(pat, arg) . NOMATCH, since we cannot expect to be matched against both A and C. \nFor simplicity, we assume that the argument con\u00adtains no variables. A LISP-like program to perform the \nmatch might be match(pat, arg) = prog ((ml m2) if const(pat) then (if eq(pat, arg) then return(EMPTY) \nelse return(NOMATCH) If var(pat) then return (list (cons (pat, arg))) if atom(arg) then return(NOhL4TCH) \nml * match(car(pat), car(arg)) if ml . NOMATCH then return(NOMATCH) m2 = match(varsubst(ml, cdr(pat)), \ncdr(arg)) if m2 . NOMATCH then return(NOhL4TCH) return (compose (m2, ml)) . The program does the appropriate \nthing in the case of atOmiC patterns or arguments, and it applies itself recursively to the left and \nright halves of the expressions in the nonatomic case. The program applies the substitution found in \nmatching the left halves of the expressions into the right half of the pattern before it is matched so \nas to avoid having the same variable matched against different terms. We have proved several facts about \na version of this program, but we focus our attention here on one of them: If the program does not return \nNOMATCH, then the match it finds actually does satisfy the desired condition; i.e., that substituting \nthe match into the pattern makes it identical to the argument. We will further restrict ourselves to \nthe case in which both of the arguments are nonatomic, i.e. , in which control passes through the final \nreturn of the program. For this example, the verification condi\u00adtion was constructed by hand, although \nit could just as well have been one of many produced by the gen\u00aderator program. In generating verification \nconditions for re\u00adcursive programs, we handle recursive calls analo\u00adgously to the way we handle loops \nin iterative pro\u00adgrams. whatever assertion we are trying to prove about the program is assumed to be \ntrue for the re\u00adcursive call to the program. For example, for this program, we have proved that match(pat, \narg) # NOMATCH ~ varsubst(match(pat, arg), pat) = arg ,  This assertion plays the role of the halt assertion \nof an iterative program. We can assume the asser\u00adtion to be true of the recursive calls; these asser\u00adtions \nwould have been made by the verification condi\u00ad tion generator. To abbreviate, let ml = match(car(pat), \ncar(arg)) and m2 = match(varsubst(ml, car(pat)), cdr(arg)). Then our inductive hypotheses are ml # NOM.ATCH \n2 (25) varsubst(ml, car(pat)) = car(arg) . (the program works for the car of the pattern) and m2 # NOhL4TCH \n2 (26) varsubst(m2, varsubst(ml, cdr(pat)) = cdr(arg) (the program works for the instantiated cdr of \nthe pattern). The verification condition generator would split each of these implications into two cases; \nwe will consider only the caee in which the conclusions of both these implications are true, i.e. , that \nthe recursive calls to the pattern matcher succeed in finding both matches. We know hy our assumption \nthat constexp ( arg) (27) (the argument contains no variables). This is one of the input assertions for \nthe program. By the path we have taken through tbe program, we know that 1 const(pat) (28) (the pattern \nis not a constant). 1 var(pat) (29) (the pattern is not a variable). m atom(arg) (30) (the argument \nis not an atom). The goal is to prove varsubst(compose(m2, ml), pat) = arg . (31) The proof produced \nby the system proceeds as follows. The goal is split into two subgoals: varsubst(compose(m2, ml), car(pat)) \n= car(arg) (32) and varsubst(compose(m2, ml), cdr(pat)) = cdr(arg) ;33) The first goal is simplified \nto varsubst(m2, varsubst(ml, car(pat)) = car(arg). Since varsubst(ml, car(pat)) = car(arg) by (25), this \nsim\u00ad plifies to varsubst(m2, car(arg)) = car(arg) . Since arg contains no variables, neither does car(arg) \n. Thus , the goal simplifies to car(arg) = car(arg) . The proof of (33) is even simpler: varsubst compose(m2, \nml), cdr(pat)) simplifies to varsubst(m2, (varsubst(ml, cdr(pat)))) . We know by our hypothesis in (26) \nthat varsubst(m2, varsubst(ml, cdr(pat)) = cdr(arg) , and this completes the proof. This proof required \nnot only that we add new rules describing the concepts involved, but also that we extend certain of our \nolder capabilities, particularly our ability to simplify expressions using known equalities. We worked \nnearly a week before the system was able to do this proof . However, once the proof was completed , the \neffort necessary to enable the sys\u00adtem to do the proof of the unification algorithm was minimal . The \nlatter proof, though longer than this one, did not require much additional Intellectual capacity on the \npart of the deductive system. We do not show that proof here because it is similar to the pattern matcher \nproof, but we include the pro\u00adgram and the assertion we proved about it. VII THE UNIFICATION ALGORI iTiM \nThe problem of unification is similar to that of pattern matching except that we allow both argu\u00adments \nto contain variables. We expect the algorlthm to find a substitution that makes the two arguments identical \nwhen it is applied to both, if such a sub\u00adstitution exists. For example, if x is (F U A) and yis(FBV), \nthen unify(x, y) is ((U.B) (V-A)), where U and V are variables and A, B, and F are con\u00adstants. A simple \nprogram to unify x and y is unify (x, y) = prog( (ml m2) if x=y then return(EMPTY) if var(x) then return(if \noccursin(x, y) then NOMATCH else list (cons(x, Y))) if var(y) then return(if occursin(y, x) then NOMATCH \nelse list (cons(y, x))) if atom(x) then return(NOMATCH) if atom(y) then return(NOMATCH) ml * unify(car(x), \ncar(y)) if ml.NOMATCH then return(NOMATCH) m2 -unify(varsubst(ml, cdr(x)), varsubst(ml, cdr(y))) if m2=NOMATCH \nthen return(NOMATCH) return(c0mp0se(m2, ml))) . The predicate occursin(u, v) tests if u occurs in v. \nThis program is a recursive, list-oriented version of Robinson s iterative, string-oriented pro\u00adgram. \nAgain, we have verified only the longest path of the program, not the entire program. Furthermore , we \nhave proved not the strongest possible statement about this program, but only that unify(x,y) # NOMATCH \n2 varsubst(unify(x,y) , X) = varsubst(unify(x,y), y) . VIII THE FIND PROGRAM The program FIND, described \nby Hoare [1961] is intended to rearrange an array A so that all the ele\u00adments to the left of a certain \nindex F are less than or equal to A[F], and all those to the right of F are greater than or equal to \nA[F]. In other words, the relation (STRIP (BAGA A 1 F-l)) s A[F] z (STRIp (BAGA A F+I, NN)) should hold \nwhen the prO\u00adgram halts. For instance, if F is NN+2, then A[F] is the median of the array. The function \nis useful In computing percentl.les and is fairly complex. Hoare remarks that a sorting program would \nachieve the same purpose but would usually require much more time; the conditions for FIND are much weaker \nin that, for example, the elements to the left of F need not be sorted themselves, as long as none of \nthem are greater than A[F]. The general strategy of the program FIND is to move small elements to the \nleft and large ele\u00adments to the right. These relative size categories are defined as being less than \nor not less than an arbitrary array element. The algorithm scans the array from left to right looking \nfor a large ele\u00adment; when it finds one, it scans from right to left looking for a small element. When \nit finds one, it exchanges the large element and the small element it has already found, -and the scan \nfrom the left con\u00adtinues where it left off until the next large element is found, and so on. When the \nscan from the left and the scan from the right meet somewhere in the middle, they define a split in the \narray. We can then show that all the elements to the left of the split are small and all those to the \nright are large. The index F can be either to the left or to the right of the split, but suppose it is \nto the left. I%en the elements to the right of the split can re\u00admain where they are; they are the largest \nelements in the array, and the element that will ultimately be in position F is to the left of the split. \nWe then disregard the right portion of the array and repeat the process with the split as the upper bound \nof the array and with a refined definition of large and small. We will eventually find a new split; suppose \nthis split is to the left of F. We can then leave in place the elements of the array to the left of the \nsplit and work only with the elements to the right; we readjust the left bound of the array to occur \nat the split, and we repeat the process. Thus, the left and right bounds of the array move closer and \ncloser together, but they always have F between them. Finally, they meet at F, and the algorithm halts. \nThe flow chart shown in Figure 3 follows Hoare s algorithm closely. In this program, I is the pointer \nfor the left-to-right scan, J is the pointer for the right-to-left scan, M and N are the lower and upper \nbounds of the middle portion of the array, and R is the value used to discriminate between small and \nlarge array elements. Hoare [1971] provided an in\u00adformal manual proof of the correctness of his pro\u00adgram. \nIgarashi, London, and Luckham [1973] and Deutsch [1973] have produced machine proofs. The proof we obtained \nrequired a minimal number (three) of intermediate assertions; however, one of the veri\u00adfication conditions \nproduced was quite difficult to prove. This condition corresponds to the statement that the elements \nto the right of the right boundary dominate the elements to its left after an exchange is performed and \na new right boundary is established. We present a sketch of that proof below. A. Assertions for FIND \nThe input assertion qs for FIND is I<F<NN, A=AP . T The second statement assures us that the array START \nis indeed a rearrangement of the initial array. The intermediate assertion ql is .... . ~s lsM<F.sN<NN \n Mel (STRIp (BAGA A 1 M-1)) s (sTRIp (BAGA A MNN)) N+NN (STRIP (BAGA A I N)) s (STRIP (BAGA A N+l NN)) \n(BAGAA I M) . (BAGAAP 1m)) . q3 ..........l_ T This assertion is reached whenever a new bound on the \nmiddle section of the array is established. r M<N No The assertion q2 is ? l<MsF<NsNN (STRIP (BAGA A \n1 M-l)) s (STRIP (BAGA A M NN)) Yes e (STRIp (BAGA A I N)) s (STRIP (BAGA A N+l NN)) R +-A[F] MsI I+M \nJ<N (STRIp (BAGA A 1 I-I)) z R J4-N ? s (STRIp (BAGA A J+l NN)) (BAGAA 1NN) = (BAGAAP 1NN) .  l_._-_J \ne The assertion q3 is the same as the assertion No q2, with the additional conjunct R<AII] . E ....... \n. B. The Proof All but one of the verification conditions for this program were proved fairly easily. \nThe one difficult condition corresponds to the path begin\u00adning at q3 that follows the heavy line and \nfinally ends at q 1 The verification condition generator supplied us with the following hypotheses: l<MsFsNsNN \n(34) 1 (STRIp (smIp (BAGA (BAGA A A I I M-1)) N)) s < (STRIP (BAGA A M NN)) (35) (STRIP (BAGA A N+I NN)) \n(36) . M< I (37) TA-740522-1O JsN (38) FIGURE 3 THE FIND PROGRAM (STRIP (BAGA A 1 s (STRIp (BAGA I-I)) \nA J+l < R NN)) (39) The array it in the after we AP is the initial input assertion have modified A. version \nso that of A; we we can refer define to it R < AII] (BAGA AP 1 NN) = (BAGA A 1 NN) \\ (40) (41) (42) The \noutput assertion qH is (43) (STRIp (BAGA A 1 F-I)) < A[F~ g (STRIP (BAGA A F+I, NN)) (BAGA A I m) . (BAGA \nAP 1 NN) . F< J-l. (44) (45) The interesting consequence for this path is (STRIP (BAGA A 1 J-l)) (46) \ns (STRIP (BAGA A (J-1)+1 NN)) where A = (EXCBANGE A I J) , the array that results when elements ALI] \nand A[J] are interchanged in A. The proof sketched below roughly parallels the proof produced by the \ninference system. The (J-1)+1 term in the goal (46), is simplified to J, giving the goal (sTRIp (BAGA \nA 1 J-1)) s (STRIp (BAGA A J NN)) . (47) The difficulty in the proof arises from the uncer\u00ad tainty \nabout whether J s I. We are reasoning about an array segment, and it is not clear whether that segment \nis affected by the exchange or not. Hand analysis of the hypotheses (43) and (44) reveals that I=Jor \nI=J-1. The value of a term like (BAGA (EXCHANGE A I J) 1 J-1) depends on which pos\u00adsibility is actually \nthe case. The system simplifies the term into (IF J SI THEN (BAGA A 1 J-1) ELSE (BAG (STRIP (BAGA A 1 \nI-1)) A[J] (STRIP (BAGAA 1+1 J-l)))) . Intuitively, if J < I, then both I and J are outside the bounds \nof the array segment, whereas if I < J, then the array segment loses AII] but gains A[J]. Similarly, \nthe term (BAGA (EXCRANGE A I J) J NN) is simplified into (IF J<ITHEN(BAGAAJNN) ELSE (BAG (STRIP (BAGA \nA J J-l)) AII] (STRIP (BAGA A J+l m)))) . Note that (BAGA A J J-1) is empty; the ELSE clause is then \n(BAG A(I] (STRIP (BAGA AJ+l NN))) . Our goal can thus be reduced to showing that (IF J s I THEN (STRIP \n(BAGA A 1 J-I)) ELSE (STRIP (BAG (STRIP (BAGA A 1 I-1)) ArJ] (sTRIP (BAGAA 1+1 J-l))))) < (IF J s I THEN \n(sTRIp (BAGA A J NN)) ELSE (STRIP (BAG AII] (sTRIp (BAGA A J+l NN))))) . (48) The system approaches \nthe conditional expression by creating two contexts: In one context, J S I holds, and in the other, I \n< J is true, In the first context we must prove that (STRIP (BAGAA 1 J-1)) s (STRIP (BAGAA J NN)) . (49) \n In the second context, the statement to be proved is (STRIP (BAG (i3TRIP (BAGAA I I-1)) A[J] (STRIP \n(BAGA A 1+1 J-l)))) 5 (sTsIp (BAG AII] (STRIP (BAGAA J+l NN)))) . (50) Note that in the first context, \nJ = I by (43). In working on (49), (BAGA A J NN) is expa nded to (BAG A[J] (STRIP (BAGA A J+l N N))). \nThus, (49) breaks into two subgoals : (STRIP (BAGAA 1 J-I)) sA[J] (51) and (STRIp (BAGA A 1 J-1)) 5 \n(STRIP (BAGA A J+l NN)) . (52) Since I = J, (51) follows from (39) and (40), and (52) fOllOWS from (39) \nalone. Work on the goal (50) proceeds in the second con\u00adtext, in which I g J. Since J-1 s 1+1 (11), we \nknow (BAGA A 1+1 J-1) is empty. The inequality (50) may thus be broken into four Inequalities: (STRIP \n(BAGAA 1 1-1)) sAII] , (53) (STRIP (BAGA A 1 I-I)) s (STRIP (BAGA A J+l NN)) , (54) A[J] <AII] , (55) \nand A[J] g (STRIp (BAGA A J+l NN) (56) (53) follows from hypotheses 39) and (40). Goal (54) follows from \n(39). Goal (55) follows from (42) and (40) . Goal (56) follows from (42) and (39). This completes the \nproof.  This proof is the longest achieved by our deduc\u00adtive system so far. SUMMARY OF RESULTS Complete \nproofs have been found of the correct\u00adness of the following algorithms: Finding the largest element of \nan array Finding the quotient of two real numbers . Hoare s FIND program . The Euclidean algorithm for \nfinding the greatest common divisor The exponentiation program from King s thesis Integer quotient and \nremainder Integer multiplication by repeated addition . The factorial. Theorems have been proved about \ntbe following algorithms : . The pattern matcher. Unification. Exchanging two array elements (the theorem \nis that tbe bag of the contents of the array is unchanged). c King~s exchange sort. We believe the system \nnow has the power to do all of King s problem set except tbe linear inequali\u00adties problem, which is not \nreally a proof about an algorithm. X FUTURE PLANS We are currently applying the verifier to more and \nmore complex programs in a variety of subject do\u00admains. We are continuously being forced to add new rules \nand occasionally to generalize old ones, a spe\u00adcial purpose rule that worked for one problem may not \nwork for the next. The deductive system is implemented In the QA4 language. Although QA4 is ideally suited \nfor ex\u00adpressing our rules, it is an experimental system evaluated by an interpreter and is written In \nLISP; furthermore, it uses space Inefficiently. R. Reboh and E. Sacerdoti are In the process of integrating \nQA4 into BBN-LISP to produce a system known as CILISP [Reboh and Sacerdoti, 1973]. OLISP programs will \nbe LISP programs that can be evaluated by the LISP in\u00adterpreter or even compiled. Furthermore, QLISP \nis much more conservative m its use of space. We ex\u00adpect that this system will be considerably faster \nand more compact than the existing system. Our deductive system is already being translated into QLISP. \nQA4 subtly encourages its users to write depth\u00adfirst search strategies, since it implements the goal \nmechanism by means of backtracking. The deductive system uses depth-first search, and for the most part, \nthis has been the proper thing to do. There have been times, however, when we have felt the need for \nsomething more discriminating. Suppose, for example, we are trying to prove an expression of the form \nX=y. We can do this by trying to simplify x and then proving that the simplified x is equal to y, or \nwe can try to find some assertion a = b and prove x = a and y =b. In the current system, we must ex\u00adhaust \none possibility before trying another, whereas we would like to be able to switch back and forth be\u00adtween \ndifferent approaches, giving more attention to the one that currently seems to be making the best process. \nFinally, we hope to apply this work to the auto\u00admatic construction of programs. It seems inevitable that \nif we know how to reason about programs, that reasoning should be able to help us In the process of forming \nor changing a program. Rather than taking a hand written and hand-debugged program to a veri\u00ad fier for \napproval, we hope to collaborate with a system that will play an active role in the creation of the algorithm. \n ACKNOWLEDGMENTS The work on program verification was done in close collaboration with Bernie Elspas. \nThe work on QA4 was done in collaboration with Jeff Rulifson and Jan Derksen. Irene Greif wrote the first \nversion of the simplifier. Jeff Rulifson encouraged us to write this paper and suggested its format. \nRich Fikes has helped with design modification and debugging of QA4. Bert Raphael read the manuscript \nand suggested many improvements. This work has benefitted from our con\u00adversations with Cordell Green, \nPeter Neumann, Earl Sacerdoti, Rend Reboh, Mark Stickel, and Steve Crocker. Many members of the Artificial \nIntelligence Center and Computer Science Group at SRI helped with support and criticism. REFERENCES \nBoyer, R. S., and J. S. Moore, Proving Theorems about LISP Functions, Proc. IJCAI-73 (to appear August \n1973). Deutsch, P., An Interactive Program Verifier, Ph.D. Thesis, University of California, Berkeley, \nCalifornia (1973). Elspas, B., M. W. Green, K. N. Levitt, and R. J. Waldinger, Research in Interactive \nProgram-Proving Techniques, SRI Project 8398, Phase II, Stanford Research Institute, Menlo Park, California \n(May 1972) . 181 Elspas, B., K. N. Levitt, and R. J. waldimzer, Design of an Interactive System for Verification \nof Computer Programs, SRI Project 8398, Ph ase III, Stanford Research Institute, Menlo Park, California \n(July 1973). Floyd, R. W. , Assigning Meanings to Programs, Proc. American Mathematical Society Symp. \nin Applied Mathematics, Vol. 19, pp. 19-31 (1967). Hewitt, C., Description and Theoretical Analysis (Using \nSchemata) of PLANNER! A Language for Prov\u00ading Theorems and Manipulating Models in a Robot, Ph.D. Thesis, \nMassachusetts Institute of Technology, Cambridge, Massachusetts (1971). Hoare, C.A.R., Algorithm 65, \nFIND, CACM, Vol. 4, No. 7, p. 321 (1961). An Axiomatic Basis for Computer Program\u00adming, CACM, Vol. 12, \nNo. 10, p. 576 (1969). Proof of a Program: FIND, =, vol. 14, No. 1, p. 39 (1971). Igarashi, S. , R. London, \nand D. Luckham, AutOmatic Verification of Programs I: A Logical Basis and Implementation (tentative title), \nStanford Univer\u00adsity, Stanford, California (to appear 1973). Katz, S. M., and Z. Manna, A Heuristic \nApproach to Program Verification, Proc. IJCAI-73 (to appear August 1973). King, J. C., A Program Verifier, \nPh.D. Thesis, Carnegie-Mellon University, Pittsburgh, Pennsyl\u00advania (1969). Knuth, D., The Art of Computer \nProgramming, Vol. 1: Fundamental Algorithms (Addison-Wesley Publishing Company, Reading, Massachusetts, \n1968). , The Art of Computer Programming, Vol. 2: Seminumerical Algorithms (Addison-Wesley Publishing \nCompany, Reading, Massachusetts, 1969). McCarthy, J., et al., LISP 1.5 Programmer s Manual (MIT Press, \nCambridge, Massachusetts, 1962). McCarthy, J., and J. A. Painter, Correctness of a Compiler for Arithmetic \nExpressions, Proc. American Mathematical Society Symp. in Applied Mathematics, Vol. 19, pp. 33-41 (1967). \nNaur, P., Proof of Algorithms by General Snapshots, ~, Vol. 6, pp. 310-316 (1966). Rehoh, R., and E. \nSacerdoti, Preliminary QLISP Manual, Technical Note, Artificial Intelligence Center , Stanford Research \nInstitute, Menlo Park, California (to appear 1973), Robinson, J. A., A Machine Oriented Logic Based on \nthe Resolution Principle, JACM, Vol. 12, No. 1, pp. 23-41 (1965). Rulifson, J. F., J. A. Derksen, and \nR. J. walclimzer, QA4: A Procedural Calculus for Intuitive Reason\u00ading, Technical Note 73, Artificial \nIntelligence Center, Stanford Research Institute, Menlo park, California (1972). Teitelman, W., et al,, \nBBN-LISP TENEX Reference Manual, Bolt, Beranek, and Newman, Incorporated, Cambridge, Massachusetts (1971). \nvon Neumann, J. , Collected Works, Vol. 5, PP. 91-99 (1963) . Wegbreit, B., Heuristic Methods for Mechanically \nDeriving Inductive Assertions, Proc. International Joint Conference on Artificial Intelligence, Stan\u00adford \nResearch Institute, Menlo Park, California (to appear August 1973). Wensley, J. H., A Class of Non-Analytical \nIterative Processes, Computer Journal, Vol. 1, pp. 163-167 (1958) . 182 \n\t\t\t", "proc_id": "512927", "abstract": "This paper describes a theorem prover that embodies knowledge about programming constructs, such as numbers, arrays, lists, and expressions. The program can reason about these concepts and is used as part of a program verification system that uses the Floyd-Naur explication of program semantics. It is implemented in the QA4 language; the QA4 system allows many bits of strategic knowledge, each expressed as a small program, to be coordinated so that a program stands forward when it is relevant to the problem at hand. The language allows clear, concise representation of this sort of knowledge. The QA4 system also has special facilities for dealing with commutative functions, ordering relations, and equivalence relations; these features are heavily used in this deductive system. The program interrogates the user and asks his advice in the course of a proof. Verifications have been found for Hoare's FIND program, a real-number division algorithm, and some sort programs, as well as for many simpler algorithms. Additional theorems have been proved about a pattern matcher and a version of Robinson's unification algorithm.", "authors": [{"name": "Richard J. Waldinger", "author_profile_id": "81100002572", "affiliation": "Stanford Research Institute, Menlo Park, California", "person_id": "P243223", "email_address": "", "orcid_id": ""}, {"name": "Karl N. Levitt", "author_profile_id": "81100471282", "affiliation": "Stanford Research Institute, Menlo Park, California", "person_id": "P157213", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512927.512943", "year": "1973", "article_id": "512943", "conference": "POPL", "title": "Reasoning about programs", "url": "http://dl.acm.org/citation.cfm?id=512943"}