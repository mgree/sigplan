{"article_publication_date": "10-01-1973", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1973 ACM 0-12345-678-9 $5.00 ANALYSIS OF A SIMPLE ALGQRITHM FOR GLOBAL DATA FLOW PROBLEMS? by 14atkhew \nS. Hecht Jeffrey D. Unman Princeton University Princeton, New Jersey 08540 Abstract There is an ordering \nof the nodes of a flow graph G which topoloqically sorts the dominance relation and can be found in O(edges) \nsteps. This ordering is the re\u00adverse of the order in which a node is last visited while growing any depth-first \nspan\u00adning tree of G. Moreover, if G is reduc\u00adible, then this ordering topologically sorts the dag of \nGo Thus, for a reduc\u00adible flow graph (rfg) there is a simple algorithm to compute the dominators of each \nnode in O(edges) bit vector steps. The main result of this paper relates two parameters of an rfg. If \nG is reduc\u00adible, d is the largest number of back edges found in any cycle-free path in G, and k is the \nlength of the interval de\u00adrived sequence of G, then k~d. From this result it follows that there is a \nvery simple bit propagation algorithm (indeed, the obvious one) which also uses the above ordering, and \nis at least as good as the interval algorithm for solving all known global data flow problems such as \navail\u00adable expressions and live variables. Key words and Phrases: code optimi\u00adzation, flow graph, reducibility, \ninterval analysis, dominance, depth-first spanning tree, global data flow analysis, available expressions, \nlive variables. I. Introduction when analyzing computer programs for code improvement [A1] , there is \na class of problems, each of which can be solved in ? This work was supported by NSF grant GJ-1052. \nessentially the same manner. These prob\u00ad lems, called global data flow analysis problems, involve the \nlocal collection of information which is distributed throughout the program. Some examples of global \nflow analysis problems are available expres\u00ad sions of [c] and [Ul] , live variables [Kc] , reaching \ndefinitions of [A2] and [A3], and very busy variables [S]. There are several general algorithms to \nsolve such problems. The interval approach ([A2], [A3], [AC], [C], [Ke], [S] and [AU]) collects infor\u00admation \nby partitioning the flow graph of the program into subgraphs called intervals, replacing each interval \nby a single node containing the local information within that interval, and continuing to define such \ninterval partitions until the graph becomes a single node itself, at which time global information is \npropagated locally by reversing the reduction process. Another approach ([VI ? ,[U1] and [Kil propagates \ninformation in an obvious manner until all the required information is collected; that is, until the \nprocess con\u00adverges. We shall show that this second approach (with a suitable node ordering) is no worse \nthan the interval approach! Prior to presenting the main result and the algorithm, we review part of \nthe theory of reducible flow graphs. T In 1961 v.A. vyssotsky [v] implemented this kind of flow analysis \n(and presumably the obvious algorithm) in a Bell Labora\u00adtories 7090 FORTRAN II compiler--for strict\u00adly \ndiagnostic purposes. II. Background A flow graph is a triple G= (N,E,nO), where: (a) N is a finite set \nof nodes. (b) E is a subset of NxN called the =. The edge (x,y) enters node y and leaves node x. We say \nthat x is a prede\u00adcessor of y, and y is a successor of x. A ~ from xl to \\ is a sequence of nodes (x \n,. . . ,~) such that (Xi,Xi+l) is 1 in E for l~i<k. The path lenqth of (xl, . ...\\) isk-1. Ifxl=\\, the \npath is a cycle. (c) Node nO in N is the initial node. There is a path from nO to every node. INTERVALS \nLet G be a flow graph and h a node of G. The interval with header h, denotedby IJhJ, is defined as follows: \n(a) Place h in I(h). (b) If m is a node not yet in I(h), m is not the initial node, and all edges entering \nm leave nodes in I(h) , add m to I (h) . (c) Repeat step (b) until no more nodes can be-added t; I(h). \n It should be observed that although m in (b) above may not be well-defined, I(h) does not depend on \nthe order in which candi\u00addates for m are chosen. A candidate at one iteration of (b) will, if it is not \nchosen, still be a candidate at the next iteration. It is well known that a flow graph can be uniquely \npartitioned into disjoint in\u00adtervals, and that this process takes time proportional to the number of \nedges in the flow graph [A2]. If G is a flow graph, then the de\u00adrived flow qraph of G, denoted by ~, \nis defined as follows: (a) The nodes of I(G) are the inter\u00advals of G. (b) There is an edge from the \nnode representing interval J to that representi\u00adng K if there is any edge from a node in J to the header \nof K, and J#K. (c) The initial node of I(G) is I(nO) .  The sequence G=GO,G1,. ..,Gk is called the \nderived sequence for G if Gi-l-l =I(Gi), k-1 #Gk, and I(Gk) =Gk. Gk is called the limit flow graph of \nG. A flow graph G is called reducible (an rfg) if and only if its limit flow graph is a single node \nwith no edge (hence\u00ad forth called the trivial flow qraph). Other\u00adwise, it is called nonreducible. T~ \nAND T2 Let G= (N,E,nO) be a flow graph and let (w,w) be an edge of G. Transformation T1 is removal of \nthis edge. Let y not be the initial node and have a single predecessor, x. Transformation ~ ~s the replacement \nof x, y, and (x,y) by a sxngle node z. Predecessors of x become predecessors of z. Successors of x or \ny become successors of z. There is an edge (zjz) if and only if there was formerly an edge (y,x) or (x,x). \n(Whenever T2 is ap\u00adplied as described here, we say that x consumes y.) There are two results from [HeUl] \nwhich interest us. First, if T1 and T2 are applied to a flow graph until no longer poseible, then a unique \nflow graph results, independent of the sequence of applications of T~ and T2 actually chosen. Second, \na flow graph is reducible by intervals if and only if repeated application of T1 and T2 yields the trivial \nflow graph. DOMINANCE AND REGIONS If x and y are two distinct nodes ina flow graph G, then x dominates \ny if every path in G from its initial node to y con\u00adtains x ([P] and [LM]). Let G= (N,E,nO) be a flow \ngraph, let N1~N, let El~E, and let m be in N1. We say R= (N1,El,m) is a reqion of G with header m if \nin every path xl,...;%, where X1=nO and ~ is inNl, there is some i <k such that (a) xi=m; and (b) Xi+l \n,...,~ are inN1: and (c) (xi,xi+l), (xi+1,xi+2) ,...,  (\\_l,<) are in El That is, access to every node \nin the region is through the header only. As we proceed to apply T1 and T2 to a flow graph, each edge \nof an intermediate graph represents a set of edges and each node represents a set of nodes and edges \nin a natural way. We say that each node and edge in the original flow graph represents itself. If T~ \nis applied to node w with edge (w,w), then the resulting node represents what node w and edge (w,w) represented. \nIf T2 is applied to x and y, with edge (xjy) eliminated, then the resulting node z rePresents what X, \ny, and (x,y) represented. In addition, if two edges (x,u) and (y,u) are replaced by a single edge (z,u) \n, then (z,u) represents what (x,u) and (Y,u) represented. The two lemmas which follow appear in [U2] \n. Lemma 1: (a) Let z be a node con\u00adstructed during the reduction of some flow graph G. If z represents \nedge (x,y) of G, then x and y are represented by z. (b) Let w and x be (not necessarily distinct) nodes \nconstructed during the re\u00adduction of G, and let e be the edge con\u00adstructed from w to x. If e represents \n (Y,z) of G, then y is represented by w and Z by X. (c) In any graph formed while reduc\u00ading G, all nodes \nand edges represent dis\u00adjoint sets of objects (nodes and edges).  Lemma 2: Let G= (N,E,nO) be an rf9~ \nand let NICN and E CE be a set of nodes l and edges represented by a single node at some stage of the \nreduction of G. Then there is a (unique) node m in N1 such that (Nl,E1,m) is a region of G with header \nm. PARSES AND BACKWARD EDGES Since T1 and T2 may be applied to an rfg in different sequences, it becomes \nnecessary to discuss specific sequencesof applications of T1 and T2. Informally, a parse of an rfg is \na list of the reduc\u00adtions made (TI or T2) and the regions to which they apply. Formally, a parse n of \nan rfg G= (N,E,nO) is a sequence of the form (T1,u,v,S) or (T2,u,v,w,S), where u, v, and w are names \nof nodes and S is a set of edges. We define the parse of an rfg re\u00adcursively as follows: (a) A single \nnode with no edge has only the empty sequence as its parse. (b) If G (which may not be the orig\u00adinal \nflow graph in a sequence of reductions) is reduced to G by an application of T1 to node u, and the resulting \nnode is named v in G , then (T1,u,v,S) followed by a parse of G is a parse of G , where S is the set \nof edges represented by the edge (u,u) elimi\u00adnated from G . (c) If G is reduced to G by an ap\u00adplication \nof T2 to nodes u and v (with u consuming v) , and the resulting node is called w, then (T2,u,v,w,S) followed \nby a parse of G is a parse of G , where S is the set of edges represented by the edge (u,v) in G . (d) \nIn both (b) and (c) above, repre\u00adsentation in G carries over to G . That is, whatever an object represents \ni-n G is also represented by that object in G , ex\u00adcept for those changes in representation caused by \nthe particular transformation  (Tl or T2) currently being applied. Let Gbe an rfg and let v be a parse \nof G. We say that an edge of G is a back\u00adward edqe with respect to n if it appears in set S of an entry \n(T1,u,v,S) of n and a forward edqe otherwise. The next two results appear in [HeU2]. Lemma 3: The backward \nedges of an rfg are unique. Lemma 4: Edge (x,y) is a backward edge of an rfg if and only if x=y or y \ndominates x. DEPTH-FIRST SPANNING TREES A depth-first spanning tree (DFST) of a flow graph G is a directed, \nrooted, ordered spanning tree grown by Algorithm A [Tl] . Alqorithm A: DFST of a flow graph. Flow graph \nG with n nodes. -: ~: (1) DFST of G. (2) A num\u00adbering of the nodes from 1 to n (i.e., ENDORSER , for \neach node m) indicating the order in which each node was last visited. Method: Al. The root of the DFST \nis the initial node of G. Let this node be the node m which is visited first in StepA2. i+l. A2 . [Visit \nnode m.] If node m has a suc\u00ad~ssor x not already on the DFST, select x as the right-most son of m found \nso far in the spanning tree. If this step is success\u00adfull, node x becomes the node m to be visited next \nby repeating Step A2. If there is no such x, go to Step A3. ~: Let m be the node being visited ENDORSER \ne i. i-i + 1. If m is the root, then halt. Otherwise, climb down the DFSTone node toward the root and \nvisit this node again by returning to Step A2. D If (u,v) is an edge in a DFST, then u is the father \nof v and v is the son of u. The ancestor and descendant relations are _-- the transitive closures of \nthe father and son relations. Let G= (N,E,nO) be a flow graph and let T= (N,E ) be a DFST of G. The \nedges in E-E fall into three classes (a) Edges which run from anc~stors to descendants we call forward \nedqes.? (b) Edges which run from descendants to ancestors or from a node to itself we call back edges. \n (c) Edges which run between nodes which are unrelated by the ancestor-de\u00adscendant relation we call cross \nedges.  The notion of to the right ina DFST has only been defined for nodes with the same father. We \nextend it by saying that if x is to the right of y, then all of x s descendants are to the right of all \nof y s descendants. Thus, if (u,v) is a cross edge of a DFST, then u is to the right ofv. Lemma 5: [HeU2] \nThe backward edges of an rfg G are exactly the back edges of any DFST for G. III. Node Ordering and aDominatorAlqorithm \nLet Tbe aDFST of a flow graph G with n nodes. We consider two orderings of the nodes of G. (a) ENDORDER--as \ndefined in Algo\u00adrithm A. (b) rENDORDER--where rENDORDER(x) = n+l-ENDORDER(x) , for each node x. ( rEND-ORDER \nis the reverse of ENDORSER. )  We define the daq of an rfq G to be G minus all of its back edges [HeU2]. \nT Do not confuse this definition of for\u00adward edges in a DFST with the previous one for edges in an rfg. \nThey are not necessarily the same, and context should distinguish which one is meant. Lemma 6: The partial \norder definedby the dag of an rfg is a subset of the total order defined by rENDORDER. Proof: Let G be \nan rfg, let G be the dag of G, and let T be any DFST of G. It suffices to show that if there is a path \nin G from the initial node to node y which includes node x, with x#y, then rENDORDER(x) frENDORDER(y). \nSuppose, in contradiction, that there are two distinct nodes x and y such that there is a path in G \nfrom the initial node to y which includes x, and rEND- ORDER(X) >rENDORDER(y). Then, END- ORDER(X) KENDORDER(Y). \nThat is, Y is last visited after x is last visited while grow\u00ad ing T. Either y is an ancestor of x, \nor y is to the right of xin T. If yis anan\u00adcestor of x, then G contains a cycle. This is impossible. \nConsequently, y is to the right of x. The path from x to y must go through a common ancestor of x and \ny [Tl], so there would again be a cycle in G . u If i is a predecessor of j in an rfg, then either (ijj) \nis a back edge or a for\u00adward edge of an rfg. If it is a back edge, then either j dominates i or i=j (Lemma \n4) , and thus, i cannot dominate j. If (i,j) is a forward edge of an rfg, then rENDORD\u00adER(i) KrENDORDER(j). \nThis is exactly the property of rENDORDER which Algorithm B uses. Alqorithm B: Computes a set DOM(m) \n, the dominators of m, for each node m. Reducible flow graph G= (N,E,=~Nl=n. The nodes are numbered from \n1 to n by rENDORDER according to some DFST for G. Refer to each node by its number. output : Sets DOM(j) \nl~j~n, where i is in DOM(j) if and only if I dominates j. Method: B1. Initia~~y, IX3M(1) 1#1, and DOM(j) \n+N~r j#l. B2. For each node j =2,3,. ..,n in turn, ~M(j) is replaced by the intersection of [(k) lJDOM(k)] \nover all predecessors k of j such that k <j. O Theorem 1: Algorithm B is correct. That is, after Algorithm \nB terminates, i is in @M(j) if and only if i dominates j. Proof: Let G be an rfg. We proceed by induction \non j. Inductive Hypothesis: After process\u00ading node j, i is in DOM(j) if and only ifi dominates j. Basis: \n(j=l). Trivially trUe. Xnduction Step: (j>l). Assume the inductive hypothesis for all k <j, and con\u00adsider \nthe case for j. If i dominates j, then surely i domi\u00ad nates every predecessor of j which is not i itself. \nThus, i is in DOM(j). Now, suppose i is in ~M(j), but i does not dominate j. Then there is a cycle\u00adfree \npath from the initial node to j which does not pass through i. Let k be the node on the path immediately \nbefore j. By Lemma 4, (k,j) cannot be a back edge, elSe j would dominate k or k=j, and the path would \nhave a cycle. Thus, (k,j) is a for\u00ad ward edge, and rENDORDER(k) KrENDORDER(j). As i#k, and i does not \ndominate k, we have by the inductive hypothesis that i is not in (k) UDOM(k) , and hence, not in DoM(j). \nO If we implement the DOM sets by bit vectors, then+Algorithm B requires O(e) bit vector steps. This \nfollows because in a flow graph with e edges at most e bit vec\u00adtor intersections are computed in Step \nB2. Also, the node ordering (rENDORDER) assum\u00aded as input can be computed in O(e) steps [Tl] . In [AU] \n, Aho and Unman present an O(ne) step algorithm to compute dominators. Purdom and Moore s algorithm [PM] \nhas the same time bound. Allen and Cocke [AC] suggest breadth\u00adfirst ordering of then odes to compute \ndominators of an arbitrary graph, but their algorithm (which is similar to Algo\u00adrithm B) may require \nmore than one pass through the nodes. Earnest et al [EBA] present an algori\u00adthm which establishes an \ninterval ordering (similar to rENDORDER, but takes more than O(e) steps. Aho, Hopcroft and Unman [AHU] \nhave an O(e loge) step algorithm to find direct dominators i.n an rfg. In [T2], Tarjan presents an algorithm \nfor determini\u00adng direct dominators i.n O(e +n logn) steps. T we shall always distinguish between steps \nand bit vector steps when discuss\u00ading complexity. This distinction is important. Before leaving this \nsection, we prove another result about rENDORDER. Lemma 7: If x dominates y, the rENDORDER(x) < rENDORDER(y). \nProof: Let G be a flow graph in which x dominates y, and let T be any DFST of G. Since any path from \nthe initial node to y must include x, x is reached before y while growing T. Thus, x is on the backward \npath in T from y to the initial node. That is, ENDORDER(Y) ZENDORDER(X) and rENDORDER(x) < rENDORDER(y). \n~ Note that Lemma 7 is not just a corol\u00adlary of Lemma 6. Lemma 7 applies to non\u00adreducible as well as \nreducible flow graphs. IV. The Main ReSUlt Following several lemmas, we establish the main result of \nthis paper. Definition: The depth of an rfg G is the largest number of back edges found in any cycle-free \npath in G. Definition: Let G be a flow graph, let I(G) be the derived flow graph of G, and let G be G \nminus all of its self-loops, where a self-loop is an edge from a node to itself. We define the lenqth \nk of the de\u00ad rived sequence of G to be O if G is the trivial flow graph, otherwise that k#O such that \n(a) GO=G (b) Gi+l= I(Gi), i~o, (c) Gk is the limit flow graph of G, and (d) Gk#Gk_l. Lemma 8: Let G \nbe an rfg and let G be G at some intermediate stage of its re\u00adduction by T1 and T2. If there is a path \nfrom node u to node v in G , then there exist nodes w and x in G such that w and x are respectively represented \nby nodes u and v in G and there is a path from w to x inG. Proof: Let n be any parse of G which yields \nG at some intermediate stage. The lemma is an easy induction on the number of steps of n taken to reach \nG . I J Lemma 9: Let G be an rfg. Nodes en\u00adtered by back edges in G head intervals in G. Proof: The lemma \nis obvious for self\u00adloops. so, let (m,h) be a back edge in G , and suppose m$h. Thus, h dommates m by \nLemma 4. If h is the initial node, the lemma follows. NOW consider where h is not the initial node. Suppose, \nin contradiction, that h does not head an interval in G. Since h must be in some interval, let it be \nin interval K with header k. First, we note that every interval is also a region by Lemma 2. If m is \nnot in K, then K is not a region because conditions (b) and (c) of the definition of region are violated. \nThu S , m is in K. As (m,h) is an edge, m must be added to K before h is. But then there is a path from \nthe initial node to k and thence to m which does not pass through h. This would contradict the assumption \nthat h dominates m. o Lemma 10: If u dominates v in an rfg G> u heads an interval in G, J is the inter\u00adval \ncontaining v, and I(u) #J, then I(u) dominates J in I(G). Proof: Neither T1 nor T2 creates any new paths \nbetween nodes. Thu S , if I(u) did not dominate J, then u would not dominate v. o The following lemma \nis essential for theorem which follows. Lemma 11: Let d be the depth of an rfg G, let d be the depth \nof I(G), and sup\u00adpose G+I(G). Ifd>d , then d=d +1. Proof: Assume all the hypotheses and let P be any \ncycle-free path in G from pl to pk containing d back edges. We shall think of P as an ordered sequence \nof edges p= ((P1,P2), (P2,P3), . . ..(Pl.Pk)k) ), where the j-th edge in P is (p.,p. Let -J ]+1) (Xi,Si) \nbe the i-th back edge in P, l~i~d. That is, (Xl,sl) is the edge with the least m such that (pm,pm+l) \nis a back edge, and if the i-th back edge is (pn,pn+l) , then the (i+l)-st back edge is the edge with \nthe least m>n such that (pm,pm+l) is a back edge. See Figure 1. Let S=(sil (Xi,Si ) is a back edge inP). \nSinCe P is cycle-free, each s in S is dis\u00adtinct. Thus, lSl=d. Let So=pl. First we show that Si+l dominates \ns i for O~i~d-1. Pick your favorite Si+l from S. We know that s dominates Xi+l i+l because (Xi+l,Si+l \n) is a back edge (Lemma 4), and we know that there is a path Q from s i 06 o end . . . . d k &#38; 9 \nd-1 ~ b b d #* xi+2 * b x.1 * * 2 : . PI begin x 1 Fiqure 1. A cycle-free path in an rfg from PI \nto pk containing d>O back edges. to x in P which does not pass through i+l s, Suppose, in contradiction, \nthat s 1+1 i+l does not dominate si. Then, there is a path R from the initial node to Si not con\u00adtaining \nSi+l. But by concatenating paths R and Q we have a path to x not contain\u00ad i+l ing s This contradicts \nthe fact that i+l s i+l dominates Xi+l. Thus, Si+l dominates s ,. 1 Now we claim that all back edges \nin P, except the first one, are represented by themselves in I(G) and are back edges in I(G) . That is, \nan edge in G represented by an edge in I(G) still exists as an edge in I(G) , whereas an edge in G repre\u00adsented \nby a node in I(G) does not. To show this, it suffices to show that in I(G) the node representing the \ninterval J (con\u00adtaining s i+l) dominates, and is thus dis\u00ad tinct from, the node representing interval \nK (containing Xi+l ), where O~i~d-1, and that the first back edge is represented by a node in I(G). Since \nP is cycle-free, it follows that the i-th and (i+l)-st back edges are dis\u00adtinct and si#si+l. Thus by \nLemma 9, Jand the interval L containing s< are distinct intervals of G. Furthermor&#38;, J dominates \nin I(G), because s i+l dominates Si i.n G (lemma 10). See Figure 2. back J Fiqure 2. Intervals J, K andL \nof Lemma 11. If K=L, then (Xi+l,Si+l) represents itself in I(G) because it is an inter\u00adinterval edge. \nAIso, it is a back edge in I(G) by Lemmas 10 and 4. Now suppose that K+L, that is, Xi+l is not in L. \nCertainly, K#J due to the forward path from Si to Xi+l in P. Thu S, J dominates K by Lemma 10. Hence, \n(x i+l ,s i+l) represents itself in I(G) be\u00ad cause it is an inter-interval edge. Also , it is a back \nedge in I(G) by Lemma 4. Finally, if the first back edge repre\u00ad sents itself in I(G) , then d =d, which \ncontradicts the assumption d>d . n Theorem 2: (MAIN THEOREM) If G iS an rfg with depth d and derived \nsequence length k, then k~d. Proof: By induction on k. Basis: (k=O). G is the trivial flow graph. Thus, \nd=O. Hence, k>d. Induction Step: (k>O). Assume the inductive hypothesis for k-1, and consider an rfg \nG with derived sequence of length k and depth d. Let d be the depth of I(G). Case 1: d>d . Thus, d=d \n+1 by Lemma 11. BY the inductive hypothesis, k-l~d . Thus, k-l~d-1, or k~d. Case 2: d=d . BY the inductive \nhy\u00adpothe~-1 ~d . Thus, k~k-l~d =d, or k~d. Case 3: d<d . This case cannot occur because T1 and T2, in \ntheir transformation of G to I(G) , do not create paths between nodes in I(G) which did not already exist \n(Lemma 8). Hence, the back edges of I(G) are a subset of those of G. n The significance of Theorem 2 \nis that, although the interval analysis algorithm must take about 2ke bit vector steps to solve a global \nflow analysis problem for an rfg with e edges [AU] , there exists an ob\u00advious bit propagation algorithm \nto solve such problems in about de bit vector steps. (We pick up the coefficient 2 in the inter\u00adval approach \nbecause, in addition to reduc\u00ad ing the rfg to a single node, known algo\u00ad rithms ([A21, [A31, [AUI, [C],[SI \nand [Kel) reverse the interval process to propagate global information locally.) Figure 3 shows an rfg \nwith k= 3 and d=l. Moreover, this rfg can be extended in an obvious way so that k is arbitrarily large, \nyet d remains 1. Thus, there may be a dramatic decrease in the time required to solve global data flow \nanalysis problems using the simple bit propagation algorithm, when compared to the interval algorithm. \nIn any event, the algorithm of [Ul] and [Ki] cannot be worse than interval analysis, and must be.regarded \nas superior for its slmpllclty. binary operator.) d Let .$:N+2 . If an expression r=A8B I G2=I(G1) G1=I(GO) \no G3=I(G2) GO=G Fiqure 3. Flow graph G with d=l and k=3. v. Solution of Two Global Flow Analysis Problems \nAVAILABLE EXPRESSIONS (From [C] and [Ul].) An expression such as A+B is avail\u00ad able at a point p in a \nflow graph if every sequence of branches which the program may take to p causes A+B to have been computed \nafter the last computation of A or B. If we can determine the set of available ex\u00adpressions at entrance \nto the nodes of a flow graph, then we know which expressions have already been computed prior to each \nnode. Thus, we may be able to eliminate the redundant computation of some expres\u00adsions within each node. \nLet d be the set of expressions com\u00adputed in a flow graph G= (N,E,nO). 6 Let ~:N~2 . we interpret %(x) \nas the set of expressions which are killed in node x. Informally, expression AOB is killed if either \nA or B is defined within node x, (The symbol 0 indicates a generic is in A(x) , then we imagine that \nr is qenerated within node x, and that neither A nor B is subsequently defined. Let AEIN(x) and AEOUT(X), \nfor each node x, be respectively the set of expres\u00adsions available at entrance to and at exit from node \nx. The fundamental relationships which enable us to compute AEIN(x) for each node x are: ~. AEIN(nO) \n=0. ~. For x#nO, AEIN(x) is the inter\u00adsection of AEOUT(Y) over all predecessors y of x. ~. AEOUT(X) = \n[AEIN(x)-K(x)] ~~(x), for each node x. AE4 . Since AEI-3 do not necessarily have ~nique solution for \nAEIN(n), we want the largest solution. The algorithm which follows is a bit vector algorithm and similar \nto those in [Ul] and [Ki], except for the node ordering. We distinguish between sets and bit vectors \nby using AEIN for sets and AEin for bit vectors. Alqorithm C: Computes bit vectors AEin(m) for each \nnode m. =: (1) F1OW graph G=(N,E,nO), INI =n. The nodes are numbered from 1 to n by reversing the time \nof last visit in a DFST of G (i.e., rENDORDER). Refer to each node by its number. (2) Bit vectors KILL(j) \nand GEN(j), l~j~n, where the i-th bit of KILL(j) (resp. GEN(j)) is 1 if and only if the i-th expression \nis in ~(j) (resp. ~(j)) . All bit vectors have length p, where p is the number of expressions. output \n: Bit vectors AEin(j), l~j~n. Method: Cl. Initially, AEin(j) +a~l l s, for 2~j~=, and AEin(l) +all 0 \ns. C2 . Do Step C3 for j =1,2,. ..,n in order. % any bit changes for any j, repeat Step2. Otherwise, \nhalt. C3 . Set AEin(j) equal to the bitwise prod\u00ad~t of [AEin(k) A lKILL(k)] VGEN(k) ,twhere T Here, the \nsymbols A, vandl stand for the AND (bitwise product) , OR (bitwise sum) and NOT (bitwise complement) \nfunctions, respec\u00ad .. tlvely. k ranges over all predecessors of node j.~ LIVE VARIABLES (From~e]. ) A \npath in a flow graph is called defi\u00ad niton-clear with respect to a variable V i-f there is no definition \nof V on that path. A variable V is live at a point p in a flow graph if there is a definition-clear path \nfor v from I? to a use of V. That is, V is live if its current value might be used before V is redefined. \nHaving deter\u00ad mined the set of live variables at exit from each node in a flow graph, we can use this \ninformation for (among other things) register allocation --we can determine when a value should be kept \nin a register be\u00ad cause of a subsequent use. Let k be the set of variables occur\u00adring in a flow graph \nG= (N,E,nO). u Let ~:N-42 . (3(x), the clear of x, is the set of variables which are not de\u00adfined in \nnode x. u Let h:N-2 . b(x) is the set of variables which have exposed uses in node x, i.e., those variables \nwith a definition\u00ad clear path from the entry of node x to a use within node x. Let LVOUT(X) and LVIN(X) \n, for each node x, be the set of variables live at exit from and on entrance to node x. The fundamental \nrelationships which enable us to compute LVOUT(X) for each node x are: LV1. For each exit node w in \nG (i.e., w has% successors), LVOUT(W) =@. ~. For x not an exit node, LVOUT(X) is the union of LVIN(y) \nover all successors y of x. LV3. LVIN(X) = [LVOUT(X) fI~(X)] ~h(X), for e% node x. LV4. Since LV1-3 \ndo not necessarily have a unique solution for LVOUT(X) , we want the smallest such solution. Let LVout \nbe the bit vector for set LVOO. Alqorithm D: Computes bit vectors LVout(m) for each node m. (1) F~OW \ngraph G= (N,E,nO),,Nl .- The nodes are numbered from 1 to n by the time of last visit in a DFST ofG (i.e., \nENHY3RDER. Refer to each node by its number. (2) Bit vectors CLEAR(j) and XUSE(j), l~j~n, where the \ni-th bit of CLEAR(j) (resp. XUSE(j)) is I if and only if the i-th variable is in ~(j) (resp. b(j)). All \nbit vectors have length q, where q is the number of variables. QQ?2?E: Bit vectors LVout(j), l~j~n. Method: \nD1. Initially, LVout(j) all O s, for l~j~=. D2. Do Step D3 for j =~,2, . . ..n in order. ~ any bit changes \nfor any j, repeat StepD2. Otherwise, halt. D3. Set LVout(j) equal to the bitwise sum ~ [LVout(k) A CLEAR(k)] \nVXUSE(k) , where k ranges over all successors of node j. H VI. Analysis The termination and correctness \nof Algorithms C and D follow directly from [Ul] and [Ki]. We focus on the complexity. Lemma 12: Any cycle-free \npath in an rfg G beginning with the initial node is monotonically increasing by rENDORDER. Proof: Any \nsuch path contains no back edges by the proof of Lemma 11, and, thus, is a path in the dag of G. rENDORDER \ntopologically sorts the dag of G (Lemma 6). o Theorem 3: Step C2 of Algorithm C is executed at most d+2 \ntimes for an rfg G. Proof: A O propagates from its point of origin --a kill or the initial node-\u00adto the \nplace where it is needed in d+l iterations if it must propagate along a path P of d back edges. It takes \none iter\u00adation for a O to arrive at the tail of the first back edge of P. This follows since all edges \nto this point are forward or cross edges. The numbers along the path must be in increasing sequence by \nLemma 12. After this point, it takes one iteration for a O to climb up each back edge in P to the tail \nof the next back edge, by the same argument. Hence, we need at most d+l iterations to propagate information \nplus one more to detect that there are no further changes. D Theorem 4: Step D2 of Algorithm D is executed \nat most d+2 times for an rfg G. Proof: A 1 indicating a use propa\u00adgates backward along a cycle-free path \nto a 91ven point in d + 1 iterations if there are d back edges in the path from the point to the use. \nIt takes one iteration for al to reach the head of the d-th back edge in [A2] F.E. Allen, control I?1ow \nAnalysis, such a path. As in Theorem 3, we prove SIGPLAN Notices, Vol. 5, No. 7, this by noting that \nforward and cross 1-19, July 1970. PP. edges under ENDORDER go from higher to low\u00ader numbered nodes. \nAn additional iteration [A3] F,E. Allen, A Basis for Program enables us to reach the head of each suc-Optimization; \n~. IFIP Conf. ceeding back edge. rl 71, North Holland Publishing Co., Amsterdam, 1971. VII. Conclusions \n[AC] F.E. Allen and J. Cocke, Graph- There is an ordering of the nodes of Theoretic Constructs for Program \na flow graph G which (i) topologically Control Flow Analysis, IBM Re\u00adsorts the dominance relation of \nG, search Report RC 3923, T.J. Watson Research Center, Yorktown Heights,(ii) topologically sorts the \ndaq of G N.Y. , JUIY 1972. if G is reducible, and (iii) can be found in O(e) steps. [c] J. Cocke, Global \ncommon subexpres\u00ad sion Elimination, SIGPLAN Notices, As a direct consequence, we can compute vol. 5, \nNo. 7, Pp. 20-24, Ju1y197Q the dominators of each node in a reducible flow graph in O(e) bit vector steps. \n[EBA] C.P. Earnest, K.G. Balke, and J. Anderson, Analysis of Graphs by Also, we have analyzed a simple \nbit Ordering of Nodes, JACM, Vol. 19, propagation approach for solving global No. 1, pp. 23-42, Jan. \n1972. data flow analysis problems which is simple to describe, understand, and program. This [HeU~] M.S. \nHecht and J.D. Unman, F1ow approach requires at most (d+2)e bit vec-Graph Reducibility, SIAM J. tor steps, \nwhereas the interval approach computin~, Vol. 1, No. 2, pp. 188\u00adrequires at most 2ke bit vector steps \nplus 202, June 1972. bookkeeping for intervals, where k and d, with k>d, are parameters of the rfg. [HeU2] \nM.S. Hecht and J.D. Unman, charac\u00ad terizations of Reducible Flow Moreover, although node splitting Graphs, \nTR-118, Computer Science is necessary when using the interval ap-Laboratory, Electrical Eng. Dept., proach \non non-reducible flow graphs, the Princeton Univ., Jan. 1973. simple bit propagation approach works on \nnon-reducible flow graphs directly with no [HoU] J.E. Hopcroft and J.D. Unman, An such modification! \nn logn Algorithm for Detecting Re\u00adducible Graphs, Proc. 6th Annual *** Princeton Conf. on Information \nSciences and Systems, pp. 119-122, References March 197~ [AHU] A.V. Aho, J.E. Hopcroft and J.D. [Kc] \nK. Kennedy, A Global Flow Analysis U1 lman, On Finding Lowest Common Algorithm, International ~. Ancestors \nin Trees, Proc. 5th computer Math., vol. 3, pp. 5-15, Annual ACM Symposium on Theory of Dec. 1971. \n Computinq, Austin, Texas, pp. 253\u00ad 265, May 1973. [Ki] G.A. Kildall, Global Expression Optimization \nat Compile Time, in [AU] A.V. Aho and J.D. Unman, The this proceedings, Oct. 1973. Theorv of Parsing, \nTransla~n and Compiling: Vol. II -Compilinq, [LM] E.S. Lowry and C.W. Medlock, Ob-Prentice Hall, Englewood \nCliffs, ject code Optimization, CACM, N.J., 1973. vol. 12, No. 1, pp. 13-22, Jan. 1969. [Al F.E. Allen, \nProgram Optimization, [P R.T. Presser, Applications of .Annual Review Automatic Proqram- Boolean Matrices \nto the Analysis 5, Pergamon Press, New of Flow Diagrams, PrOc. Easternm> vol. York, 1969. Joint Computer \nConf. , Spartan Books, New york~ PP. 133-~38> Dec. 1959. [ PM] P.W. Purdom and E.F. diate predominators \nGraph, CACM, VO~. PP. 777-778, August Moore, Imme\u00adin a Directed 15, No. 8, 1972. [s] M. Schaefer, ~ of \nGlobal Flow  Prentice Hall, N.J., 1973. Mathematical Analysis, Englewood Theory to appear, cliffs, [T1-] \nR.E. Tarjan, Depth-First and Linear Graph Algorithms, ~. Computinq, Vol. ~, No. 146-160, June 1972. Search \nSIAM 2, pp. [T2] R.E. Tarjan, Finding Dominators in Directed Graphs, to appear in Proc. 7th Annual Princeton \nConf. ~ Information Sciences and Sys\u00adtems, March 1973. [T3] R.E. Tarjan, Reducibility, ACM SymP osium \n~, Austin, May 1973. Testing Flow Graph Proc. 5th Annual on Theory of Comput\u00ad Texas, pp. ?%-107 , [Ul] \nJ.D. U~lman, Fast Algorithms for the Elimination of Common Subex\u00adpressions, TR-L06,, Computer Science \nLaboratory, Dept. of Elec\u00adtrical Eng., Princeton Univ. , March 1972. [U2] J.D. Unman, the Elimination \npressions, on Switchinq E. 161-176, A Proc. . and ~. Fast Algorithm of Common Subex\u00ad13th Symposium Automata \nTheory, 1972. for [v] V.A. tion Vyssotsky, of June 7, private 1973. conununica\u00ad \n\t\t\t", "proc_id": "512927", "abstract": "There is an ordering of the nodes of a flow graph G which topologically sorts the dominance relation and can be found in 0(edges) steps. This ordering is the reverse of the order in which a node is last visited while growing any depth-first spanning tree of G. Moreover, if G is reducible, then this ordering topologically sorts the \"dag\" of G. Thus, for a reducible flow graph (rfg) there is a simple algorithm to compute the dominators of each node in 0(edges) bit vector steps.The main result of this paper relates two parameters of an rfg. If G is reducible, d is the largest number of back edges found in any cycle-free path in G, and k is the length of the interval derived sequence of G, then k&#8805;d. From this result it follows that there is a very simple bit propagation algorithm (indeed, the obvious one) which also uses the above ordering, and is at least as good as the interval algorithm for solving all known global data flow problems such as \"available expressions\" and \"live variables.\"", "authors": [{"name": "Matthew S. Hecht", "author_profile_id": "81100631147", "affiliation": "Princeton University, Princeton, New Jersey", "person_id": "PP39051585", "email_address": "", "orcid_id": ""}, {"name": "Jeffrey D. Ullman", "author_profile_id": "81100314798", "affiliation": "Princeton University, Princeton, New Jersey", "person_id": "PP39037330", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512927.512946", "year": "1973", "article_id": "512946", "conference": "POPL", "title": "Analysis of a simple algorithm for global data flow problems", "url": "http://dl.acm.org/citation.cfm?id=512946"}