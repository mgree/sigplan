{"article_publication_date": "10-01-2007", "fulltext": "\n Inductive Reasoning about Effectful DataTypes Andrzej Filinski Kristian St\u00f8vring DIKU, University of \nCopenhagen, Denmark DAIMI, University of Aarhus, Denmark andrzej@diku.dk kss@daimi.au.dk Abstract We \npresent a pair of reasoning principles, de.nition and proof by rigid induction, which can be seen as \nproper generalizations of lazy-datatype induction to monadic effects other than partial\u00adity. We further \nshow how these principles can be integrated into logical-relations arguments, and obtain as a particular \ninstance a general and principled proof that the success-stream and failure\u00adcontinuation models of backtracking \nare equivalent. As another ap\u00adplication, we present a monadic model of general search trees, not necessarily \ntraversed depth-.rst. The results are applicable to both lazy and eager languages, and we emphasize this \nby presenting most examples in both Haskell and SML. Categories and Subject Descriptors D.1.1[ProgrammingTech\u00adniques]: \nApplicative (functional) programming; F.3.2[Semantics of Programming Languages]: Denotational semantics \nGeneral Terms Languages, Theory Keywords monads, recursive types, equational reasoning, logical relations, \nabstract effects, streams, backtracking 1. Introduction Consider the SML type of lists: datatype a list \n= Nil | Cons of a * a list Although this is an instance of a general recursive data type, we frequently \nthink of it as an inductive, set-theoretic de.nition.We can then de.ne functions on lists by structural \ninduction: fun append Nil l = l | append (Cons (h,t)) l = Cons h (append t l) fun rev Nil l = l | rev \n(Cons (h,t)) l = rev t (Cons (h,l)) fun reverse l = rev l Nil We can also reason about such functionsby \nstructural induction on theirarguments.Forexample,toverify that append is associative, i.e., that for \nall list-typed values l1, l2, and l3, append (append l1 l2) l3 = append l1 (append l2 l3) , we use the \nclauses of the function de.nition as valid equational axioms, and proceed by induction over l1, checking \nthe equation Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page.To copyotherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP \n07 October 1 3, 2007, Freiburg, Germany. Copyright c&#38;#169; 2007ACM 978-1-59593-815-2/07/0010... $5.00 \nfor l1 = Nil and l1 = Cons (h,t) with the inductionhypothesis that the equation holds for t. Similarly, \nwe can prove that reverse is aninvolution.We start by proving, by induction on l1, that reverse (rev \nl1 l2) = rev l2 l1 (1) from which reverse (reverse l) = reverse (rev l Nil) = rev Nil l = l. Consider \nnow the analogous de.nitions in Haskell, where lists can be partial and/or in.nite. The principle of \nlazy-list induction (Reade 1989, Section 8.5) says that that when reasoning about lazy lists, one must \nconsider, in addition to the proper constructors, the case of an unde.ned value, usually written O or \n.. For associativity of append, the extra casel1 = . goes through easily,with both sides equal to .;but \nfor Equation (1) withl1 = . and l2 = Cons 0 Nil, we get reverse (rev . (Cons 0 Nil)) = reverse . = . \n= Cons 0 . = rev (Cons 0 Nil) . which is just as well, since reverse is evidently not an involution on \nin.nite lists. The problem with in.nite lists is actually a bit subtler than just checking the .-case:Forexample, \nthe predicate P (l) ..n :: Int. take nl = l holds for all .nite(even .-terminated) lists,but still not \nfor in.nite ones. Domain-theoretically, the problem is that this predicate is not chain-complete: knowing \nthat it holds for all elements in an ascending chain does not guarantee that it holds of the supremum \nof the chain.We say thata predicate P is admissible if P (.) and P is chain-complete.We thenhave Theorem \n1.1 (informal). Let P be an admissible predicate on the type List t . If P (Nil), and .h, t. P (t) . \nP (Cons ht), then .l. P (l). (Note that the condition P (.) is part of the de.nition of admis\u00adsibility, \nrather than another pseudo-constructor case; this view will prove useful later,when we consider effects \nother than divergence.) Fortunately, we rarely need to verify admissibility by explicit appealtoits de.nition.Itisfairlyeasytoseethatif \nterms e1 and e2 with free variables x, y1,...,yn are strict in x, then the predicate P (x) ..y1,...,yn.e1 \n= e2 is admissible. This codi.es three important properties of admissi\u00adble predicates: (1) equality (i.e., \nthe diagonal predicate on t \u00d7 t) is admissible; (2) inverse images by strict functions of admissible \npredicates are admissible; and (3) arbitrary intersections (conjunc\u00adtions) of admissible predicates are \nadmissible. Further, an easy way to see that a function is strict in an argu\u00adment is when it induces \non that argument. Indeed, the problem with (1) was that the induction on the right-hand side was not \non l1. Consider .nally the generalization to streams, where produc\u00ading the next stream element(Cons or \nNil)may involve arbitrary computation, includingbut not limited to I/O.We can still easily de.ne an append \nfunction for such streams,but can we be sure it remains associative,eveninthe presenceofeffects embeddedinthe \nstreams? Equally importantly, can we (once the proper framework is in place) show it with effort comparable \nto proving the original append associative, i.e., merely verify the two constructor cases, and check \nthat the associativity equationisbuiltupinaway that admits the induction principle? In the remainder \nof the paper we present such a framework, based on a category-theoretical generalization of strictness: \nthe notion of monad-algebramorphisms,which we callrigid functions. Strict functions are then precisely \nthose that are rigid with respect to the lifting monad.We show how an associated induction principle \nallows us to both de.ne rigid functions on streams and similar data types, and prove properties about \nthem. We consider both the domain-theoretic foundations, and how they are re.ected in reasoning about \nML and Haskell programs. As an application of the setup, we show how to relate several models of backtracking \nsearch, based on solution streams, suc\u00adcess/failure continuations, and decision trees. In particular,we \ngen\u00aderalize the main resultofWand andVaillancourt (2004), which re\u00adlates the former two models in the \nspecial case where the underly\u00ading effect is just partiality. 2. Equational reasoning 2.1 Domain-theoreticfoundations \nWe develop the basic results in the setting of the categoryCpo of .-cpos and (total) continuous functions. \nLet us brie.y recall some standard de.nitions: De.nition 2.1. Amonad is a triple T\u00af=(T,., *), where T \nmaps cpos to cpos, and . : A . TA and * : TA \u00d7 (A . TB) . TB are functionfamilies satisfying .a*f = fa \n(2) t*. = t (3) (t*f) *g = t* (.f.f a*g) . (4) An alternative presentation de.nesa monad asa triple (T, \n., \u00b5) where T is an endofunctor, and . and \u00b5 are natural transformations satisfying a few additional \nequations. The two formulations are equivalent: T (f)= .t.t * (. . f), \u00b5 = .t.t * id;and conversely, \nt*f = \u00b5.T (f). The lifting monad takes T .A = A.,.. a = LaJ, . *. f = ., and LaJ *. f = f(a). De.nition \n2.2. A monad morphism from (T, ., *) to (T ',.',*') isafamilyof functions . : TA . T 'A, satisfying ' \n. (.a)= .a (5) ' . (t*f)= .t*(. . f) . (6) Monad morphisms can be used to model inclusion or lifting \nof behaviors from one monad to a more general one. De.nition 2.3. An algebra for a functor F is a pair \n(X, .), where . : FX . X is called the structure of the algebra. An algebra for a monad (T,., *) must \nalso satisfy a few equations, relating . to . and *.For readability, it is often convenient to say instead \nthat a monad algebra is a pair D =(D, w*), where the functionfamily w* : TA \u00d7 (A . D) . D satis.es equations \nsimilar to those for *: .a w*f = fa (7) (t*f ) w*g = t w* (.a.f a w*g) . (8) Again the formulations are \nequivalent: we can take .(t)= t w* idD,and converselytw*f = .(t*(.a..(fa))) = .(T (f)(t)). AcpoD is pointed \n(i.e., hasaleast element .D)precisely when it canbeextendedtoan algebraforthe lifting monad,byastructure \n. : D..D. One easily sees that this . mustbe uniqueifitexistsat all. In the alternative formulation, \nw* determines the strictextension of a function f : A . D to .l.l w*f : A. . D. Proposition 2.4. There \nare canonical ways to construct algebras for a monad (T,., *): For any cpo A,(TA, *) is the free algebra \non A.  For algebras D 1 =(D1, w*1) and D 2 =(D2, w*2) we form the  product algebra D 1 \u00d7 D 2 =(D1 \u00d7 \nD2, w*\u00d7) where t w*\u00d7 f = (t w*1 (p1 . f ),t w*2 (p2 . f)). For any cpo B and algebra D =(D, w*), we form \nthe func\u00adtion algebra B D ([B . D], w*. f . = *.), where t w= .b.t w* (.a.f ab). De.nition 2.5. An algebra \nmorphism or rigid function between T\u00af-algebras (D, w*) and (D', w*') isafunction h : D.D' satisfying \nthat, for all cpos A, t . TA, and f : A . D, ' h (t w*f )= t w*(h . f ) . (9) We writeh :(D, w*) -(D', \nw*') when this is the case. \u00af When T is lifting, a rigid function is precisely one that is strict, i.e. \nsatis.es that h(.D)= .D, . Such functions may be moved in\u00adside an evaluation-forcing construct. In general, \nrigid functions can be thought of as those that perform their arguments computations before anyother. \nProposition 2.6. The following are valid principles for construct\u00ading rigid functions: D - - - 1. id \n: D;and iff : D1 D2 and g : D2 D3, then g . f : D 1 -D 3. 2. For any (D, w*) and f : A.D,.t.t w*f :(TA, \n*) -(D, w*). 3. pi : D1 \u00d7 D2 -Di; and if each fi : D -Di, then .d. (f1(d),f2(d)) : D -D 1 \u00d7 D 2.  . \n f : D' . 4. For each b . B, .g.g b :(B D) -D;and if (B .D) satis.es that for each b . B, .d'.f(d') b \n: D ' -D , then f : D ' -(B D). . Wealsosaythatafunctionof multipleargumentsisrigidinone of them, when \nit is rigid (in the original sense) for all values of the other arguments. (A function can be rigid in \nmore than one of its \u00af arguments, if T is a commutative monad, such as lifting, read-only state,orcomplexity.)ByProp.2.6(4),thisisequivalentto \nrequiring that the corresponding curried function into the function algebra is rigid. \u00af Depending on \nthe speci.c monad T , there may be additional principlesfor constructingrigidfunctions.Forexample,inamonad \nmodeling idempotent effects (such as divergence, TA = A.), ' the computation-duplicating function .t.t \n* .a.t * .a'..(a, a): TA . T (A \u00d7 A) is rigid; and in one modeling discardable ef\u00adfects (such as read-only \nstate, TA = S . A), the function .t.t * .a..() : TA . T 1 is rigid. The more functions that are rigid, \nthe stronger the equational reasoning principles we shall ob\u00adtain in the following. Finally, there is \na close relationship between monad algebras and monad morphisms: Proposition 2.7. Let T\u00af=(T, ., *) and \nT\u00af' =(T ',.',*') be monads. If for every A, (T A, wA) is a T\u00af'-algebra, and for every *' *'*'.t'.tA . \n: T 'A . TA is a monad morphism. In this situation, f : A . TB, .t.t * f :(T A, wA) -(T B, wB), then \n. = ' w*' \u00afT\u00af' we say that the monad T is layered over . Proof. Straightforward calculation, using the \nmonad-morphism and monad-algebra laws. 2.2 Reasoning about programs 2.2.1 Metalanguage Togetacoherent \naccountof reasoningaboutbothSMLandHaskell programs with computational effects, it is convenient to concep\u00adtually \nexpress both languages in terms of a common computa\u00adtional metalanguage. In this way, we abstract from \nconcrete syn\u00adtax, as well as from the differences between lazy/strict evaluation, classes/modules, and \nmonad-parameterization/effect-re.nement. Our metalanguage, a slightly simpli.ed variant of the Multi-Monadic \nMetaLanguage M3L (Filinski 2007), is essentially the monadic metalanguage of Moggi (1991), extended with \nthe FPC\u00adstyle general recursive types (Fiore and Plotkin 1994), and a little syntactic supportfor talking \nabout algebrasforacollectionof mon\u00adads. Its types are parameterized over a set of effect names e: t ::= \n1 | t1 \u00d7 t2 | t1 + t2 | \u00b5a.t | a | s s ::= Tet | t . s | s1 \u00d7 s2 s-types are called computational, and \nwill denote monad algebras. Note that most conventional base types are de.nable in the meta\u00adlanguage, \ne.g., Nat = \u00b5a.1+ a. The terms are parameterized over a set of potentially polymor\u00adphic constants ca \na, which must be type-instantiated at each use: M ::= x | cat | () | (M1,M2) | fst(M) | snd(M) | inl(M) \n| inr(M) | case(M, x1.M1,x2.M2) | in\u00b5a.t M | out\u00b5a.t M | .xt .M | M1 M2 | \u00b5x s.M | valeM | lete x . M1.M2 \nThe typing relation, G f M : t , is de.ned in the obvious way. Note that term-level recursion, \u00b5x s.M, \nis only allowed at s-types. We will occasionally omit the type tags, and use a straightforward pattern-matching \nnotation for fst and snd. We write e . s when s is a product or function space of Te-types, in which \ncase we can de.ne a generalized let, glete s x . M1.M2, allowing M2 : s, by induction on s: glete = x \n. M1.M2 Tet x . M1.M2 lete gletet. s x . M1.M2 = .at .gletse x . M1.M2 a glete x . M1.M2 = s1\u00d7 s2 (glete \nx . M1. fst(M2), glete x . M1. snd(M2)) s1 s2 This corresponds to the w*-formulation of a monad algebra; \nequiva\u00adlently,we can de.neatermfamily gluees : Tes.s corresponding to the ..As notedin Def. 2.3, theyare \ninterde.nable: glete = gluee (lete x . M1.vale M2) s x . M1.M2 s gluees = Tes . glete .ts x . t. x For \nthe denotational semantics of types, let. map typevariables in .= {a1, ..., an} to cpos, and for every \neffect name e, let T\u00afe =(T e,.e,*e) beamonad layeredover lifting. Thentoevery t with free typevariablesin \n., we associatea cpo [ t] .;andtoevery s with e . s,a T\u00afe-algebra [ s] a .: [ a] . = .(a) [ 1]]. = 1= \n{()} [ t1 \u00d7 t2] . =[ t1] . \u00d7 [ t2] . [ t1 + t2] . =[ t1] . +[ t2] . [ s] . = D where (D, w*)= [ s] . \na [ \u00b5a.t ] . = m. X] \u00b5X.[ t ] .[a= {fa.t m | m . [ t [\u00b5a.t/a]]].} [ Tet ] a . =(T e[ t ] .,*e) [ s1 \u00d7 \ns2] a . =[ s1] a . \u00d7 [ s2] a . [ t . s] a . [ s] a . =[ t ] . . To properly give the semantics of \u00b5-types, \nwe actually need functorial actions of all type constructors, which for Te-types can be derived from \n.e and *e. Once this scaffolding is removed, however, the above set of equations remains. Q We also take \n[ G]] = [ G(x)]];then forG f M : t, x. dom G we de.ne [ M] : [ G]] . [ t] as usual.We take complete programs \nto be closed terms of observable type, typically excluding function spaces and some effect types. When \nthe set of base effects only contains partiality, the proof of computational adequacy, i.e., that the \ndenotation of a complete program agrees with that program s observable operational behavior, is also \nstandard (Fiore and Plotkin 1994); the extensions to most other common base effects are also straightforward.(Wewill \ncover programmer-de.ned effects in Sec\u00adtion 3.) As a standard consequence of adequacyand composition\u00adality \nof the semantics, we have that [ M] = [ M ' ] guarantees that M and M ' are observationally indistinguishable. \n 2.2.2 Embedding functional programming languages Asubstantial fragment of core SML can be straightforwardly \nem\u00adbeddedinthe metalanguage.However,to obtainstronger reasoning principles, the conceptual embedding \n.|- |1 of types and terms is expressed for an effect-annotated source language, where a func\u00adtion type \nwritten as t1 ->(*e*) t2 in the code is translated as .|t1|1 . Te.|t2|1. Unannotated function arrows \nt1->t2 (only al\u00adlowed when t2 is itself a well-formed function type, or a product of such types) are \ntranslated as simply .|t1|1 ..|t2|1.Terms of such type must be manifestly pure functions. The embedding \nof Haskell is a bit more problematical. The translationofanyHaskelltype shouldbeas-typeover the partiality \neffect (i.e., a pointed type), which for sum types is ensured by adding an extra lifting T. around their \ntranslations. However, to ensure that, e.g., the syntactic state monad does indeed denote a proper monad, \nwe require the .-conversionlawtobevalid;and this is not the case for full Haskell, when observations \nof termination at functional types are allowed (at the top level, or using seq). We shall disallow such \nobservations, allowing us to consider a slightly stricter , PCF-like semantics of the resulting Haskell \nfragment, where meanings of function types are not further lifted. Forexpressing monadsand algebrasinHaskellandML,wede\u00ad.ne \nsome basic infrastructure in Figures 1 2. The Haskell classdef\u00adinitions of monads, algebras, and layering \nare straightforward tran\u00adscriptions of the mathematical/metalanguage constructions. Note, however, that \nwe cannot add the free algebra as a class instance; instead, we will need to add it explicitly for every \ntype isomorphic (by newtype)to the free algebra. InML, monad layeringisexpressed somewhatdifferently. \nFirst, lacking the overloading notation, it is more convenient to work with the glue-rather thanthe glet-formulation \nof algebras. Also, monad-transformer de.nitions are not explicitly parameterized overthe base effect; \nrather, all effects are considered as subeffects of the language s native notion of effects. This is \nparticularly use\u00adful when the native effect is universal, as in the SML/NJ dialect, whose .rst-class \ncontinuations allow any syntactically de.nable monadic effect to be so embedded. Such an imperative realization \nof monadic effects in shown in Figure 3, adapted from Filinski (1999) for the case of a single layer \nof de.ned effects. Brie.y, reflect converts a transparent, monadic-type representation of an effect into \nits opaque, imperative counterpart, while reify con\u00adverts an imperative computation back toa pure data \ntype.We use this implementation for concrete programming examples, but we stress that it is not essential: \nabsent a native-embedding facility, one can also write client programs explicitly in monadic style, like \nin Haskell. --class Monad m where --return ::a->ma --(>>=) ::ma-> (a->mb)->mb class (Monad m) => MonAlg \nm b where (>>>=) ::m a->(a -> b) ->b --overlaps with others --instance (Monad m) => MonAlg m (m a) where \n--(>>>=) = (>>=) instance (Monad m, MonAlg m d) => MonAlg m (z -> d) where t>>>=f=\\z->t >>>= \\a-> faz \ninstance (Monad m, MonAlg m d1, MonAlg m d2) => MonAlg m (d1,d2) where t >>>= f = (t >>>= (fst . f), \nt >>>= (snd . f)) class (Monad m, Monad (t m)) => MonadT m t where lift :: ma -> tm a Figure 1. Monads \nand algebras in Haskell type d glue = (unit ->(*m*) d) -> d signature MONAD = sig type a t val unit : \na -> a t val bind : at*( a -> b t)-> b t val glue : a t glue end; fun glue_m t=fn() => t()() fun glue_f \n(g: t glue): ( a -> t) glue = fnt => fna=> g(fn ()=> t () a) fun glue_p (g1: t1 glue, g2: t2 glue): ( \nt1 * t2) glue = fnt => (g1 (#1 ot), g2(#2 ot)) Figure 2. Monads and algebras in SML  2.3 Minimal invariance \nConsider an SML data type of effectful streams: datatype a stream_ = Nil | Cons of a * a stream withtype \na stream = unit ->(*e*) a stream_ Streams of type a stream are effectful since functions of type unit \n-> a stream can perform computational effects, includ\u00ading divergence, when called. Suppose that these \nunderlying effects \u00af are modeled by a monad T =(T, ., *). Then, in order to give a domain-theoretic model \nof the type a stream, we need for each cpo A, a cpo Str (A) such that Str (A) ~ = T (1 + A \u00d7 Str (A)) \n. Inotherwords,weneedtosolvea(covariant)domain equation.A solution is given by the interpretation of \nthe open metalanguage \u00af type Te(\u00b5a.1+ a0 \u00d7 Tea) when Te is interpreted as T and a0 is interpreted as \nA. But in order to prove properties about elements of Str (A) by induction, it is not enough to know \nthat Str (A) is any solution to the domain equation above. The standard methods for solving domain equations, \nincluding the one used to interpret our metalanguage, produce solutions that also satisfyaso\u00adcalled minimal \ninvariance condition, and this condition gives rise to general induction and co-induction principles \n(Pitts 1996). In this article we investigate consequences of minimal invariance for solutions of covariant \ndomain equations involving monads, such as the one for effectful streams above. signature RMONAD = sig \ninclude MONAD val reflect : a t ->(*t*) a val reify : (unit ->(*t*) a) -> a t end; functor Represent \n(M : MONAD) : RMONAD = struct open M SMLofNJ.Cont val mk : exn M.t cont option ref = ref NONE fun abort \nx = let val SOME k = !mk in throw k x end fun reset t = let val m=!mk val r = callcc (fn k => (mk := \nSOME k; abort (t ()))) inmk:=m; r end fun shift h = callcc (fn k => abort (h (fn v => reset (fn () => \nthrow k v)))) fun reflect m = shift (fn k => M.bind (m, fn a => M.glue (fn () => k a))) fun reify t \n= let exception D of a in M.glue (fn () => M.bind (reset (fn () => M.unit (D (t ()))), fn (D d) => M.unit \nd)) end end; Figure 3. Monadic re.ection in SML/NJ (condensed) De.nition 2.8. Let T\u00af=(T, ., *) be a monad \nlayered over the lifting monad, and let F : Cpo . Cpo be a locally continuous functor.A minimal T -invariantfor \nF isa cpo TC together with an isomorphism i : F (TC) . C satisfying that TC.TC -1 .x(.g.T (i . F (g) \n. i)) = idTC . (10) (The least .xed-point is well-de.ned since TC is pointed whenever \u00af T is layered \nover the lifting monad.) In the example with effectful streams, take FX =1+ A \u00d7 X. If (T C, i) is a minimal \nT -invariant for F , then C ~= F (TC)= 1+A\u00d7TC and hence TC ~ = T (1+A\u00d7TC). Therefore TC satis\u00ad.es the \ndomain equation for effectful streams above. Furthermore, the minimal invariance condition (10) is that \nthe SML function f givenby fun f s () = (case s () of Nil => (fn () => Nil) | Cons (a, s ) => (fn () \n=> Cons (a, f s ))) () denotes the domain-theoretic identity function on streams. Intu\u00aditively,thisisanextensionality \nproperty:aneffectful streamis com\u00adpletely characterized by what happens if you try to access its ele\u00adments \nnumber 1, 2,... . That is whyeffectful streams are amenable to a variant of structural induction. \u00af One \ncan show that for all T and F as in De.nition 2.8, a minimal T -invariant for F exists.Wedo not need \nthat generalfact. In the next section we will, however, see that interpretations of certain metalanguage \ntypes are minimal T -invariants for suitable functors. Remark. In categorical terms, De.nition 2.8 is \nequivalent to saying that TC is an initial F -and-T\u00af -algebra in Cpo (see Section 2.6). Based on that \nobservation, a categorical formulation of the induc\u00adtion principle shown in Section 2.5 can be developed \nand proved ina relatively straightforwardway. Indeed, theinduction principle is a variant of the one \npresented by Lehmann and Smyth (1981, Section 5.2) and by Crole and Pitts (1992): instead of considering \nF -algebras we consider F -and-T\u00af-algebras. 2.4 Effectful data types The effectful data types consist \nof the following subset of metalan\u00adguage types: d ::= 1 | d1 \u00d7 d2 | d1 + d2 | Ted | \u00b5a.d | a Notice that \nsuch types contain no function arrows. Consequently, all occurrences of type variables are strictly positive. \nWe aim towards deriving induction principles for data types of the form Te(\u00b5a.d[Tea/a]). As an example, \nthe type Str (a0) = Te(\u00b5a.1+ a0 \u00d7 Tea) of effectful streams has that form, taking d =1+ a0 \u00d7 a. For the \npurpose of deriving induction principles for effectful data types, an importantfactis that eacheffectful \ndata typegives risetoa functor.Forexample, considerthetype d =1 \u00d7 a.For any cpo A, let F (A)=[ d] [am.A] \n=1 \u00d7 A. If now f : A1 . A2 is a continuous function,thenwecanina naturalway de.nea function F (f)= [ \nd] d([a .. f]) : F (A1) . F (A2) by F (f)(u, a1)= (u, f(a1)). More generally, for d containing n free \ntypevariables we de.ne a functor [ d] d of n arguments. First,afew de.nitions.Fora .nite setof typevariables \n., let [ .]] bethe setof maps fromvariablesin . to cpos. Furthermore, for ., . ' . [ .]], the notation \n. : . . . ' means that . is a map from variables in . to continuous functions such that .(a): .(a) . \n. ' (a) for all a in .. The identity map id. : . . . has id.(a)= id.(a) for all a, and for .1 : . . . \n' : . . . '' and .2 : . ' . . '', the composition .2 . .1 is de.ned pointwise. Proposition 2.9. Let ., \n. ' . [ .]] and . : . . . '. For every effectful data type d with free type variables in ., there exists \na functor [ d] d : Cpo. . Cpo with [ d] d(.)= [ d] . and suchthat [ a] d(.)= .(a) [ 1]]d(.)= id1 [ d1 \n\u00d7 d2] d(.)= .(d1,d2). ([[d1] d(.) d1, [ d2] d(.) d2) j . d inl (d1). inl ([[d1] d(.) d1) [ d1 + d2] (.)= \n.d. case d of inr (d2). inr ([ d2] d(.) d2) [ Ted] d(.)= T e([[d] d(.)) = .tT e[ d] . .t*e .d. .e([[d] \nd(.) d) [ \u00b5a.d ' ] d(.)= h where h is the unique function satisfying h = fa.d, . [ d ' ] d(.[a .. h]) \n. f-1 . a.d, Furthermore, [ d] d is compositional in the following sense: [ d1[d2/a]]]d . =[ d1] d .[am.[ \nd2] .] [ d1[d2/a]]]d(.)= [ d1] d(.[a .. [ d2] d(.)]) . Proof sketch. Notice that [ d] d(.) cannot be \nde.ned by a simple induction on d, since it is not clear that there exists a (unique) function satisfying \nthe requirement on [ \u00b5a.d ' ] d(.) above. Instead, the existence of [ d] d must be argued directly from \nproperties of the functors [ t ] f in Filinski (2007, Fig. 6) used to construct the interpretations of \ntypes in the .rst place. Some notation: Let pCpo be the Kleisli category of Cpo with respect to the lifting \nmonad (equivalently, the category of cpos and partial continuous functions).Fora total function f : A \n. B, let f = .. . f : A . B. be its inclusion in pCpo. Since all type variable occurrences in d are strictly \npositive, one can show that the functor [ d] f is essentially a covariant functor from pCpo. to pCpo. \nThe functorial action of [ \u00b5a.d ' ] f is then the least .xed-point q of a certain operator on partial \nfunctions; we need the fact that q is actually the unique .xed-point of that operator. This can be shown \nusing the minimal-invariant property of the domain [ \u00b5a.d ' ] . and the associated isomorphism. One then \nshows that the result of applying [ d] f to total func\u00adtions . is itself a total function: [ d] f (.)= \nf for some (unique) function f. Now de.ne [ d] d(.) as the unique function f such that [ d] f (.)= f \n. The desired equations for [ d] d(.) then fol\u00adlow directly from the de.nition of [ d] f and from the \nuniqueness property for [ \u00b5a.d ' ] f mentioned above. Similarly, functoriality and compositionality of \n[ d] d follow from the analogous properties of [ d] f . Spelling out thefact that [ d] d is a functor, \nwe have [ d] d(id.)= id[ d] . [ d] d(.1 . .2)= [ d] d(.1) . [ d] d(.2) . Recall that we aim towards deriving \ninduction principles for data types of the form Te(\u00b5a.d[Tea/a]).To that end we need to know that the \ninterpretation of such a type is a minimal T e-invariant for a certain functor F. derived from the type \nd. Let in the following d be a data type with free type variables in . .{a}.For each . . [ .]] we de.nea \n(one-argument) functor F. by partially applying [ d] d to . such that only a varies: Lemma 2.10. Let \n. . [ .]]. Then F. : Cpo . Cpo de.ned by F.(X)= [ d] .[am.X] F.(f)= [ d] d(id.[a .. f]) is a functor. \nProof. Immediate from thefact that [ d] d is a functor. Forexample,inthe casefor streamswehavethatd = \n1+a0 \u00d7a and hence .= {a0}. For every .xed cpo A, the lemma above = F str gives a functor F str such that \nF str(X) = 1+ A \u00d7 X, A [a0m.A] A and for f : X .Y ,the functionFA str(f ) : 1+ A\u00d7X .1+A\u00d7Y is given by \nj . F str inl (). inl() A (f)(m) = case m of . (11) inr (a, x). inr (a, f(x)) The interpretation of the \ntype Te(\u00b5a.d[Tea/a]) with respect to . is a minimal T e-invariant for F.: Lemma 2.11. Let d0 = \u00b5a.d[Tea/a], \nlet C =[ d0] ., and let i :[ d[Ted0/a]]]. . [ d0] . be the associated isomorphism. Furthermore, let F. \nbe as in Lemma 2.10. Then (T eC, i) is a minimal T e-invariant for F.. Proof. Let g be any.xed-point \nof the function .gT eC.T eC .T e(i . F.(g) . i-1) . We show that g = idT eC . De.ne h = i . F.(g) . i-1. \nThen T e(h)= g by the .xed-point property of g. Now observe that F.(g)= [ d] d(id.[a .. g])= [ d] d(id.[a \n.. T e(h)]) =[ d[Tea/a]]]d(id.[a .. h]) by compositionality of [ d] d. But then h = i . [ d[Tea/a]]]d(id.[a \n.. h]) . i-1 satis.es the de.ning property of [ \u00b5a.d[Tea/a]]]d(id.). Henceby uniqueness, and by the fact \nthat [ \u00b5a.d[Tea/a]]]d is a functor, h =[ \u00b5a.d[Tea/a]]]d(id.)= idC . Finally, since T e is a functor, \ng = T e(h)= T e(idC )= idT eC . Returning to the example with effectful streams, let CA = [ \u00b5a.1+ a0 \n\u00d7 Tea] [a0m.A], and let i : 1+ A \u00d7 T eCA . CA be the associated isomorphism. Then de.ne Str (A)= [ Str \n(a0)]][a0m.A] = T eCA . The lemma above gives that (Str (A),i) is a minimal T e-invariant for FA str \n. In the metalanguage, we can de.ne terms vnil : Str (a0) and vcons : a0 \u00d7 Str (a0) . Str (a0) by vnil \n= vale in\u00b5a.1+a0\u00d7Tea(inl(())) vcons = .p. vale in\u00b5a.1+a0\u00d7Tea(inr(p)) . Takingvnil =[ vnil] [a0m.A] and \nvcons =[ vcons] [a0m.A], we get vnil . Str (A) and vcons . A \u00d7 Str (A) . Str (A) such that vnil = .e(i(inl())) \nvcons(a, s)= .e(i(inr(a, s)) . 2.5 Proofby rigid induction We now develop a principle for carrying out \ngeneral proofs on in\u00adduction on effectful data types, with the explicit goal that the re\u00adsulting proofs \nare almost identical to textbook structural induction proofs. The key is to factor out the treatment \nof effects into an effect-speci.c notion of admissibility, which leaves the main proof obligations essentially \nunmodi.ed from the pure case. 2.5.1 T -admissibility We start by de.ning a notion of a well-behaved subset \nP of a \u00af general T -algebra (D, w*). This amounts to requiring not only that that P . D is a sub-cpo \n(i.e., that the order relation on D is also a complete partial order on P )but also a sub-algebra (i.e., \nthat the \u00af inclusion function is also a T -algebra morphism): \u00af De.nition 2.12. Let (D, w*) be a T -algebra, \nA subset P of D is T -admissible (with respect to w*) if it is chain-complete and satis.es the following \ncondition: For every cpoE, continuous function g : E . D whose range is a subset of P , and element t \nof TE, the element t w*g belongs to P . We will not mentionw* explicitly when it is clear from the context. \nIn particular, when T\u00afis lifting, the only elements of TE = E. are . and LeJ. Since .w*g = .D, and LeJw*g \n= g(e),a predicate on a pointed cpo D is lift-admissible precisely when it is chain-complete and pointed, \ni.e., admissible in the sense of the Introduction. The standard principles for constructing admissible \npredicates generalize naturally to T -admissible ones: Proposition 2.13. 1. The equality relation, P \n= {(d1,d2) . D \u00d7 D | d1 = d2} on (D, w*) \u00d7 (D, w*) is T -admissible. 2. If P ' isaT -admissible predicate \non (D ' , w* ' ) and h :(D, w*). (D ' , w* ' ) isa rigid continuousfunction, then thepredicate P = {d \n. D | h(d) . P ' } is T -admissible on (D, w*). 3. If (Pj )j.J is an arbitrary family of T -admissible \npredicates on  T (D, w*), then P = j.J Pj is also T -admissible on (D, w*). Proof. Straightforward calculations. \nIn particular,anypredicate of the form P = {x |.y.f1(x, y)= f2(x, y)}, where f1 and f2 are continuous \nand rigid in their .rst arguments, is T -admissible. 2.5.2 F -closure Next, we de.ne a criterion generalizing \nthat a subset of a data type is closed under constructor applications: De.nition 2.14. Let (T C, i) be \na minimal T -invariant for F . Notice that then . . i is a function from F (TC) to TC.Asubset P of TC \nis F -closed if it satis.es the following condition: For every cpoE, continuous function g : E . TC whose \nrange is a subset of P , and element m of FE, the element (. . i)(F (g) m)) belongs to P . In the case \nwhere F is derived from a simple sum-of-products type d, the closure condition can be expressed in terms \nof the data type constructors.Forexample, let us consider streams (recalling that FA str(X)=1+ A \u00d7 X): \nProposition 2.15. AsubsetP . Str (A) is F str-closed precisely A when it satis.es: 1. The element vnil \nbelongs to P . 2. For every a in A and s in P , the element vcons (a, s) belongs to P .  Proof. First, \nlet g : E . Str (A) be such that .e . E. g(e) . P , and let m . FA strE =1+ A \u00d7 E;we must then show that \n(.e . i)(FA str(g) m) . P. (i (F str For m = inl (), .eA (g) (inl ()))) = .e (i (inl ())) = vnil . P \nby condition (1); and for m = inr (a, e), we have .e (i (F str A (g) (inr (a, e)))) = .e (i (inr(a, g(e)))) \n= vcons (a, g(e)) . P by condition (2) and the assumption on g. Conversely,assume that P is F str-closed.TakeE \n= P (viewed A as a discrete cpo), and g as the (trivially continuous) inclusion function. Then we get \nvnil . P by considering m = inl(), and vcons (a, s) . P using m = inr(a, s). The generalization to other \nsum-of-products data type construc\u00adtors F is evident. When F involves effects and/or recursion, how\u00adever, \nwe will need the formulation in terms of the functorial action on generators g.We will see an example \nin Section 2.8. 2.5.3 Proof principle We can now prove the main theorem, an abstract proof principle: \nTheorem 2.16(Proofby rigid induction). Let (T C, i) be a min\u00adimal T -invariant for F . Assume that P \nis a subset of TC that is both T -admissible and F -closed. Then P is the entire set TC. Proof. First \nwe show that .TC . P .For this, apply the condition in De.nition 2.12 with E = \u00d8 and g = \u00d8 (the empty \nfunction from \u00d8 to TC): for every t . T \u00d8 we have t*g . P . In particular \u00af .T \u00d8 *g . P . But since the \nmonad T =(T, ., *) is layered over lifting, * is strict in its .rst argument, so .T \u00d8 *g = .TC . We now \naim to showby .xed-point induction and the minimal\u00adinvariance condition (10) that idTC belongs to the \nset Q = {e : TC . TC |.t . T C. e(t) . P } . This implies that P = TC, which ends the proof. First, Q \nis chain-complete since P is. Also, by the argument in the beginning of the proof, .t. .TC . Q. Finally, \nassume that e . Q: we now show that then T (i . F (e) . i-1) . Q. Let t . TC;we must show that the element \nT (i . F (e) . i-1)(t)= t* (. . i . F (e) . i-1) belongs to P . Since P is T -admissible, it suf.ces \nto show that the range of the function . . i . F (e) . i-1 is a subset of P . But this follows from thefact \nthat P is F -closed, taking g = e in the condition in De.nition 2.14. In conclusion, by .xed-point induction \nand minimal invariance (10), idTC . Q. Together with Lemma 2.11, Theorem 2.16 immediatelygives an induction \nprinciple for data types of the form Te(\u00b5a.d[Tea/a]). In particular, for effectful streams, the rigid-induction \nprinci\u00adple, together with the observation after Def. 2.12 (instantiating F str T -admissibility for lifting) \nand Prop. 2.15 (characterizing \u00adclosure in terms of the stream constructors), properly generalizes Theorem \n1.1 from the Introduction to arbitrary effects. As an example of reasoning by rigid induction, suppose \nthat append : Str (A) . Str (A) . Str (A) is a function that is rigid in its .rst argument and satis.es \nappend vnil s = s (12) append (vcons (a, s1)) s2 = vcons (a, append s1 s2) . (13) (We will seein the \nnext section that thereinfactexistsexactly one such function.)Wewanttoshowthatforall s . Str (A), including \neffectful and/or in.nite streams, append s vnil = s. (14) Let P . Str (A) be the set of streams s for \nwhich (14) does hold. By the remark after Prop. 2.13 and the assumption that append is rigid, P is T \ne-admissible;andbyequations(12)and(13),itclearly contains s = vnil and s = vcons (a, s ' ) when s ' . \nP , so P is F str A -closed by Prop. 2.15. Thus, by Theorem 2.16, P is all of Str (A), i.e., equation \n(14) holds universally.  2.6 De.nitionby rigid induction As a consequence of proof by rigid induction, \nwe also obtain a convenient principle for de.ning rigid functionsby induction. Theorem 2.17 (De.nition \nby rigid induction). Let (T C, i) be a minimal T -invariant for F .For every T\u00af-algebra (D, w*) and every \nk : FD . D, the function foldF (k): TC . D de.ned by \u00ae foldF (k) = .x(.f..t.t w* (k . F (f) . i-1)) \u00ae \nis the unique rigid function f from (T C, *) to (D, w*) suchthat .m . F (TC).f(.(i(m))) = k(F (f)(m)) \n. (15) Proof. Bythe .xed-pointequation, f = foldF (k) evidently satis\u00ad \u00ae .es that f(t)= t w* (k . F (f) \n. i-1) . Prop. 2.6(2) then immediately tells us that f is rigid; and f(.(i(m))) = .(i(m)) w* (k . F (f) \n. i-1) = k(F (f)(i-1(i(m)))) = k(F (f)(m)) as required. Moreover, suppose f ' is another rigid function \nsatis\u00adfying (15). Let P = {t . TC | f (t)= f ' (t)}; we want to show that P is all of TC. By Prop. 2.13, \nP is T -admissible, so by Theorem 2.16, it suf.ces to show that P is F -closed. So sup\u00adpose g : E . TC \nsatis.es .e . E.g(e) . P , i.e., f . g = f ' . g. Then f . (. . i) . F (g)= k . F (f) . F (g)= k . F \n(f . g) = k . F (f ' . g)= \u00b7\u00b7\u00b7 = f ' . (. . i) . F (g) . So for all m . FE, (. . i)(F (g)m) . P , as \nrequired. Again, for streams, the de.nition can be expressed more read\u00adably in terms of the constructors: \n\u00af Corollary 2.18. Let (D, w*) be a T e-algebra, b . D, and g : A \u00d7 D . D. Then the function sfold \u00ae bg \n: Str (A) . D de.ned by sfold\u00ae bg j .\u00ab inl ().b = .x .f..t.t w* .c. case i-1(c) of inr (a, s).g(a,f s) \nis the unique f :(Str (A),*e) -(D, w*) suchthat f (vnil)= b (16) f(vcons(a, s)) = g(a, f(s)) . (17) Proof. \nFollows from Theorem 2.17,bytakingk : (1+A\u00d7D).D as j . inl ().b k(m) = case m of inr (a, d).g(a, d) and \nrecalling the de.nition of F str(f) from (11). A Note howwe are specifying f on (top-level) pure elements \nonly; rigidity determinesitsvalueonall other ones.However, b and g are \u00af allowed to contain arbitrary \nT e-effects; and there is no requirement that g be rigid, or even strict, in its second argument. The \nfunction sfold\u00ae can be straightforwardly de.ned in the metalanguage: for es, take a0\u00d7s.s = sfolds bs \ng \u00b5f Str (a0).s ..s.glete s c . s. case(out\u00b5a.1+a0\u00d7Tea(c), (). b, (a, s).g (a,f s)) Then [ sfolds] \u00d8 \n= sfold\u00ae where (D, w*)= [ s] a[a0m.A]. As an example, we can de.ne the stream-concatenating append function \nfrom the previous section.Taking append s1 s2 = sfoldStr (a) s2 vcons s1 we get append =[ append] \u00d8 = \n.s1. .s2. sfold e s2 vcons s1. It then follows directly from (16) and (17) that append satis\u00ad.es (12) \nand (13), respectively. Also, by Corollary 2.18, the func\u00adtion .s1. sfold e s2 vcons s1 is rigid for \neach .xed s2. Thus, by Prop. 2.6(4), append :(Str (A),*e) -Str (A) ). . (Str (A),*e (In the following, \nwe shall generally omittheobvious metalan\u00adguage term xyz whose denotation is the semantic object xyz.) \nUniqueness primarily allows us to talk about the rigid function satisfying equations (16) and (17), instead \nof merely the least one. However, we can also use it to reason about general equivalence. For example, \nto show that append s1 (append s2 s3)= append (append s1 s2) s3 , (18) let s2 and s3 be given, and take \nb = append s2 s3 and g = vcons. Then there can be at most one rigid function f satisfying f (vnil)= append \ns2 s3 f(vcons (a, s)) = vcons (a, f(s)) . But it follows directly from the append equations that both \nfl = .s. append s (append s2 s3) and fr = .s. append (append ss2) s3 satisfy the conditions. Since both \nare rigid, theymust be the same function, so fl(s1)= fr(s1), i.e., (18) holds. Wecould of course also \nhavede.nedappend using higher-order iteration: taking (D, w*)= Str (A) ), . (Str (A),*e append ' = sfold\u00ae \n(.s2.s2)(.(a, h)..s2. vcons (a, h s2)) . Since append ' is also rigid and evidently satis.es Equations \n(12\u00ad13), it must be equal to the previously de.ned append. Note, however, that the uniqueness is only \namong rigid func\u00adtions.Forexample, considertherigid function f : Str (A).Str (A) determinedby f(vnil \n)= f(vcons (a, s)) = .Str (A) . Can we show that f(s)= .Str (A) for all s . Str (A)? Clearly f ' (s)= \n.Str (A) also satis.es the equations. When T\u00afe models a non-control effect, such as state(TX = S . (X \n\u00d7 S).), f ' is easily seen to be rigid, and hence indeed equal to f. But for other effects, such asexceptions(TX \n=(X + E).), f ' is not rigid; and indeed, a stream starting with an exception-raising computation is \nmapped to itself by f,but to . by f ' . Finally, it is not important that de.nitions by rigid induction \nbe expressed explicitly through sfold. For example, we can use a more general primitive-recursion schema: \nfor b . D and h : A \u00d7 D \u00d7 Str (A) . D, we recursively de.ne r : Str (A) . D by: j . inl ().b r(s)= s \nw* .c.case i-1(c) of ' '' . inr (a, s ).h(a, r(s ),s ) (In particular,we geta constant-time tail-functionby \nletting h sim\u00adply return its last argument.) By uniqueness, r must be equivalent to(but moreef.cientthan)the \ndirectly sfold-de.nable function that returnsacopyofitsargument togetherwiththeresult,allowingthe combining \nfunction g access to both. 2.7 The stream monad transformer Using the function append de.ned in the \nprevious section, we can de.ne a monad structure on effectful streams. First, the unit of the stream \nmonad: .Str a = vcons(a, vnil ) . (19) The bind function of the stream monad is de.ned by rigid induc\u00adtion, \nsimilarly to the de.nition of append : s*Str h = sfold e vnil (.(a, d).append (ha) d) s. Then *Str is \nrigid in its left argument, and satis.es vnil *Str h = vnil (20) Str Str (vcons(a, s)) *h = append (ha)(s*h) \n. (21) Now we aim towards showing that (Str,.Str ,*Str ) is actually a monad, i.e., that .Str and *Str \nsatisfy the three monad laws. The proof is virtually identical to the .nite-list case, since the relevant \nfunctions are all rigid by construction. We have already established that(Str (A), append , vnil ) forma \nmonoid (12, 14, 18).We will also need that, for s1,s2 . Str (A) and f : A . Str (B), Str Str Str (append \ns1 s2) *f = append (s1 *f)(s2 *f) . (22) The proof is again by rigid induction on s1, using (18). Proposition \n2.19. The families of continuous functions .Str and *Str satisfy the three monad laws from De.nition \n2.1. Hence (Str,.Str ,*Str ) is a monad. Proof. Equation (2) follows directly from (14). Equations (3) \nand(4)areshownbyrigid inductionon t,using Equation (22). The relevant subsets of Str (A) are T e-admissible \nby construction. Finally, Proposition 2.7 implies that the resulting stream monad \u00af is layered over T \ne. In Haskell terminology, we have de.ned a stream monad transformer. The ML and Haskell counterparts \nof the de.nitions above can be seen in Figures 4 5.  2.8 Streams as a data type constructor Recall that \nStr (A)= [ Str (a0)]][a0m.A]. By Proposition 2.9, the stream cpo constructor Str can therefore be extended \nto a functor by taking Str (f )= [ Str (a0)]]d([a0 .. f]). As could be expected, Str (f) is the function \nthat maps f over its input stream: Proposition 2.20. Let f : A1 . A2. The function Str (f) is the unique \nrigid function g :(Str (A1),*e) . (Str (A2),*e) satisfying g(vnil )= vnil and g(vcons(a, s)) = vcons(f(a),g(s)). \nProof. It follows directly from the de.nition of Str (f) that Str (f) is rigid (by Proposition 2.6(2)) \nand that it satis.es the requirements on g above. Therefore Corollary 2.18 implies that Str (f) is the \nunique rigid function satisfying these requirements. Remark. In the previous section we extended Str \nto a monad (Str,.Str ,*Str ). Since every monad is also a functor, we have an ' alternativeextension \nof Str toafunctor,namely Str(f)= .s.s*Str (.Str . f). But the proposition above implies that the two \nresulting functors are identical: Str(f)= Str' (f). Let map f = Str (f)= [ Str (a0)]]d([a0 .. f]). Thefact \nthat [ d] d isa functor for all d immediatelygivesa map fusion lawfor effectful streams: map (f . g)=(map \nf ) . (map g). As another exampleofproofbyrigid induction,weshowthat, additionally,the following map-fold \nfusion law holds: data Stream_ m a = Nil | Cons a (StreamT m a) newtype StreamT m a = ST { rST :: m (Stream_ \nm a) } instance Monad m => MonAlg m (StreamT m b) where t >>>=f =ST(t>>= \\a -> rST(f a)) instance Monad \nm => MonadT m StreamT where lift m = m >>>= return vnil :: Monad m => StreamT m a vnil = ST (return Nil) \nvcons :: Monad m => a -> StreamT m a -> StreamT m a vcons a s = ST (return (Cons a s)) sfold :: (Monad \nm, MonAlg m d) => d->(a ->d -> d)->StreamT ma ->d sfold b gs= rST s >>>=\\s->case sof Nil ->b Cons as-> \nga(sfold b gs) append :: Monad m => StreamT m a -> StreamT m a -> StreamT m a append s1 s2 = sfold s2 \nvcons s1 append :: Monad m => StreamT m a -> StreamT m a -> StreamT m a append = sfold (\\s2 -> s2) (\\a \n-> \\h -> \\s2 -> vcons a (h s2)) instance Monad m => Monad (StreamT m) where return a = vcons a vnil t \n>>= f = sfold vnil (\\a -> \\d -> append (f a) d) t Figure 4. Streams in Haskell datatype a stream_ = Nil \n| Cons of a * a stream withtype a stream = unit ->(*m*) a stream_ val glue_stream : a stream glue = glue_m \n val vnil = fn () => Nil fun vcons (a,s) = fn () => Cons (a,s) fun sfold glb gs=gl (fn ()=> case s()of \nNil => b | Cons (h,s) => g (h, sfold gl b g s)) fun append s1 s2 = sfold glue_stream s2 vcons s1 val \nappend = (* ignoring value restriction *) sfold (glue_f glue_stream) (fn s2 => s2) (fn (a, h) => fn s2 \n=> vcons (a, h s2)) structure StreamM : MONAD = struct type a t = a stream fun unit a = vcons (a, vnil) \nval glue = glue_stream fun bind (t,f) = sfold glue vnil (fn (a,d) => append (f a) d) t end Figure 5. \nStreams in SML \u00af Proposition 2.21. Let (D, w*) be a T -algebra, and let b . D, f : A1 . A2, g : A2 \u00d7 \nD . D, and s . Str (A1). Then sfold \u00ae bg (map fs)= sfold\u00ae b (.(a1,d).g(f (a1),d)) s. Proof. By rigid \ninduction on s. The relevant predicate on s is T e-admissible since the functions map f and sfold\u00ae bg \nand sfold\u00ae b (.(a1,d).g(f(a1),d)) are rigid. These fusion laws will be used in Section 4.4. 3. Relational \nreasoning Equational reasoning suf.ces for many purposes,but when prov\u00ading properties of higher-order \nfunctions, one must usually gener\u00adalize to logical relations, because the relationships are nolonger \nexpressible as simple equations. When the programs also involve recursive, and especially re.exive types, \nhowever, the natural spec\u00adi.cationof the relationfamily also becomes circular, and one must carefully \nexploit how the recursive domains were constructed in the .rst place to make sure that the desired relations \neven exist (Reynolds 1974; Pitts 1996; Filinski 2007). We will not go into the technical details here, \nconcentrating instead on demonstrating how the equational results from the previous section can be applied \nin such a relational setting. The setup is that we want to treat an effect as an abstract data type, \nwith a monad and its proper operations seen as a mod\u00adule implementing an interface.We can then talk about \ncontextual equivalence of two such modules as substitutability in all pro\u00adgrams respecting the abstraction \nboundary, i.e., not manipulating the monadic values directly, but always going through the inter\u00adface. \nThe monad-representation operators of Figure3are one par\u00adticular instance of this: here the operations \nreflect and reify actually fully expose the monad type up to (observational) isomor\u00adphism; nevertheless, \nthis still leaves room for radically different im\u00adplementations. In this section, we will show two further \ninstances of showing different implementations of an effect-ADT equivalent. To formalize implementations \nof effects, it is convenient to talk of a signature S of effect names and constants. The semantics of \nour metalanguageisgiven with respecttoa base signature S0, rep\u00adresenting a .xed programming language. \nIf a program is written over a larger signature than S0, it also needs a realization F of the extensions, \ni.e., de.nitions of the additional effects and constants, so that the expanded program M[F] can be executed; \nthis corre\u00adsponds to simple module linking, or instantiation of overloaded constants.Weuse F.c = M to \nde.ne constantsin realizations.(We sometimes write cx = M for c = .x.M,but never recursively.) For de.ning \nnew effects, we introduce the following: De.nition 3.1. A formal monad over an effect e0 consists of \na type constructor sT (\u00b7) such that e0 sT (a), and closed terms M. : a . sT (a) and M : sT (a) \u00d7 (a . \nsT (a ' )) . sT (a ' ). Semantically, we say that such a formal monad denotes a (proper) monad if the \ndenotations of the terms (with type vari\u00adables interpreted as arbitrary cpos) satisfy the monad laws \nand the layering condition from Prop. 2.7. Syntactically,arealization containinganeffect de.nition F.e \n= (sT ,M.,M ) can be used to eliminate types and terms associated with the effect: (Tet )[F] = sT (t \n[F]) (vale M)[F] = M. (M[F]) (lete x . M1.M2)[F] = M (M1[F], .x.M2[F]) One can check that the meaning \nof a program linked with a formal monad agrees with the meaning of the program in an interpretationextended \nwith that monad s denotation.For relating two different monadic implementations of an effect, we introduce: \nDe.nition 3.2. An admissible relation R between two cpos A and A ' is a chain-complete subset of A \u00d7 \nA ', i.e., satisfying that if for all i . ., (ai,ai' ) . R, then also ( F i ai, F i ai' ) . R.We write \nARel(A, A ' ) for the set of all such relations. De.nition 3.3. A relational action R for a pair of monads \n(T1,.1,*1) and (T2,.2,*2) maps relations R . ARel(A1,A2) to R(R) . ARel(T1A1,T2A2), satisfying that 1. \n(.T1A1 , .T2A2 ) .R(R). 2. If (a, a ' ) . R then (.1 a, .2 a ' ) .R(R). 3. If (t, t ' ) .R(R) and for \nall (a, a ' ) . R, (f(a),f ' (a ' )) . R(S), then (t*1 f, t ' *2 f ' ) .R(S).  Let there now be given \ntwo realizations F1 and F2 of S, and for every e . S, a relational action Re for the monads denoted by \nF1.e and F2.e.We can then show: Proposition 3.4. Let . be a relation map for .1,.2 . [ .]],i.e., for \nall a . ...(a) . ARel(.1(a),.2(a)). Then for every type t , with effect names from S, and FTV (t) . ., \nthere exists a relation (~.t ) . ARel([[t[F1]]], [ t[F2]]]) suchthat: a ~a a '' . (a, a ) . .(a) u ~1 \nu ' . true ' '' p ~t1\u00d7t2 p . p1(p) ~t1 p1(p ) . p2(p) ~t2 p2(p ) '' '' s ~t1+t2 s . (.a ~t1 a .s = inl(a) \n. s = inl(a )) . ' '' (.a ~t2 a .s = inr(a) . s = inr(a )) ' ''' f ~t.s f ..a ~t a .f a ~s fa t ~Tet \nt ' . (t, t ' ) .Re(~t ) '-1 -1 ' m ~\u00b5a.t m . fa.t (m) ~t[\u00b5a.t/a] fa.t (m ) (Since . remains .xed, we \nhave omitted it, to avoid clutter.) Proof sketch. Again, the last clause prevents us from simply de.n\u00ading \nthe relation ~t by induction on t . Instead, existence and uniqueness of the relationfamily must once \nmore be argued from the minimal-invariant property of the recursive-type interpretations (Pitts 1996), \nexploiting the conditions on relational actions of ef\u00adfects (Filinski 2007). We require that for observable \ntypes o, a ~o a ' . a = a ' , and that for any(c : t) . S0, [ c] \u00d8~t [ c] \u00d8;this is usually easily checked.For \nthe de.ned constants andeffects, we take: De.nition 3.5. Realizations F1, F2 :S are related by relational\u00adactionfamily \n(Re)e.S if for every (ca: t ) . S;. [ a.] ; a .1,.2 and . . ARel(.1,.2), [ F1.c] .1 ~.t [ F2.c] .2 . \nTheorem 3.6 (Fundamental Lemma). Let F1 and F2 be related realizations, and for every (x : t ) . G, .(x) \n~.t . ' (x). Then for every G fS M : t , [ M[F1]]].1 . ~.t [ M[F2]]].2 . ' . Proof. By induction on M \n, with most cases standard.For the case \u00b5x s.M ' we use .xed-point induction, exploiting that the relation \n~s is admissible and pointed; the cases for in and out are imme\u00addiate from the characterization of ~\u00b5a.t \n;and the ones forval and let follow from the de.nition of relational actions. In particular, if we can \n.nd a relational action for the monads underlying two realizations of an effect-ADT, such that their \noper\u00adations are related, the two realizations are observationally indistin\u00adguishable. Candidate relational \nactions are often easy to construct: Proposition 3.7. The following are valid principles for construct\u00ading \nmonadic relational actions: 1. Syntactic. If the effect e is de.ned by the same formal monad [am.R] (sT \n(\u00b7),M.,M ) in both F1 and F2, then R(R)=(~) sT (a) is a relational action for the corresponding monads. \n\u00af\u00af' \u00af\u00af' 2. Inverse image. If .1 : T1 . T1 and .2 : T2 . T2 are monad \u00af\u00af morphisms, and R ' is a relational \naction for T1 ' and T2' , then R(R)= {(t1,t2) | (.1 t1,.2 t2) .R ' (R)} is a relational \u00af\u00af action for \nT1 and T2. \u00af\u00af 3. Intersection. If Rj.J are all relational actions for T1 and T2, T then so is R(R)= j.J \nRj (R). Proof. Each part follows easily: 1. R(R) is admissiblebyconstruction, and relates the denotations \nof M. and M* by the Fundamental Lemma. 2. R(R) is admissible by being an inverse image by strict con\u00adtinuous \nfunctions of another admissible relation, and relates the unit and bind functions because of the monad-morphism \nlaws. 3. Straightforward.  4. Application: relating nondeterministic-search monad transformers As a \npractical example of using the techniques, we present two instances of relating implementations of an \nabstract data type, in the context of backtracking search. The .rst one is the well-known, but surprisinglytrickyto \nformalize, relationship between success\u00adstreamandfailure-continuation modelsof depth-.rst backtracking. \nThe second is about relating the higher-level abstraction of search trees and traversal strategies to \nsolution streams. 4.1 Relating streams and 2-continuations 4.1.1 The 2-continuation monad In formal models \nof backtracking (notably for embedding Pro\u00adlog in functional languages), a frequent alternative to the \nnatural solution-stream approach is a representation of computations with successandfailure continuations.Thismodelcanbe \nseenasastan\u00addard continuation monad,but with the answer type itself beinga continuation-computation type. \nThe outer , success continuation is thus effectively itself written in continuation-passing style, and \nisinvoked on each solution and the inner ,failure continuation. (Sometimesthefailure continuationisleft \nimplicitasthe normal call stack.Asequenceof answersis then represented asa seriesof calls to the success \ncontinuation, with the return values ignored. Ultimately, such answers must therefore be recorded using \nsome computational effect, such as interactive I/O.) When R is a computational type with e R, we de.ne \nthe formal R-continuation monad over e by Cont(a) = (a . R) . R Cont a.R unita a = .k.ka Cont a,.R a \nbinda,a, (t, f) = .k.t (.a.fak) Note that when e R, then also e Cont(t). Analogously, we can ful.ll the \ncondition on R bytaking R = (1. S). S for some S with e S. Since thefailure continuation takes no meaningful \nargument, we will actually simplify this to just R = S . S. The Haskell and ML representations of the \ngeneral continuation monad are shown in Figures 6 7. 4.1.2 Backtracking operations In the presentation \nofWand andVaillancourt (2004), the abstract effect of backtracking, BT, can be thought of as having a \nsignature with the following operations: bfaila : TBTa BTBTBT bdisja : Ta . Ta . Ta answers : TBT o . \nStr (o) bfail and bdisj representfailure and nondeterministic choice, re\u00adspectively. answers is the implicit \noperation turning a backtrack\u00ading computation howeveritis implemented intoanobservable stream of answers \nof some .xed observable type o. In the stream-based realization FBT Str , we directly take BT Str Str \nFStr.BT = (Str (\u00b7), unit, bind) BT FStr.bfail = vnil BT FStr.bdisj s1 s2 = append s1 s2 BT FStr.answers \ns = s newtype MonAlg m r => ContT rma=CT{rCT ::(a-> r )-> r } instance (Monad m, MonAlg m r) => MonAlg \nm (ContT r m a) where t >>>= f = CT (t >>>= \\a -> rCT (f a)) instance Monad m => Monad (ContT r m) where \nreturn a =CT(\\k->k a) m >>= f=CT (\\k -> rCT m(\\a ->rCT (fa) k)) instance (Monad m, MonAlg m r) => MonadT \nm (ContT r) where lift m = m >>>= return Figure 6. Continuations in Haskell functor Cont (type r val \nglue_r : r glue) : MONAD = struct type a t=( a ->r)->r fun unit a= fn k=>k a fun bind (t, f) =fnk =>t(fn \na => fa k) fun glue t = glue_f glue_r t end; Figure 7. Continuations in SML For the 2-continuation monad, \nwe choose the inner answer type S as Str (o), i.e., R = Str (o) . Str (o) We can then take BT Cont Cont \nFCont.BT = (Cont(\u00b7), unit, bind) BT FCont.bfail = .k..c.c BT FCont.bdisj u1 u2 = .k..c.u1 k (u2 kc) BT \nFCont.answers u = u (.a..s. vcons (a, s)) vnil (Note that only the last operation depends on the above \nchoice of the type S). The corresponding code is shown in Figures 8 9. To relate the two realizations,we \n.rst de.ne a function stoc : Str (A) . Cont (A) by rigid induction; stoc vnil kc = c (23) stoc (vcons \n(h, t)) kc = kh (stoc tkc) (24) (stoc isof courseexplicitly de.nableinthe metalanguage,butwe do not rely \non this.) Lemma 4.1. stoc (append s1 s2) kc = stoc s1 k (stoc s2 kc). Proof. Straightforward rigid induction \non s1. Lemma 4.2. stoc is a monad morphism from streams to continua\u00adtions. Proof. Equation (5) follows \ndirectly from (23) and (24); (6) is shownby rigid induction on the stream t, using Lemma 4.1. Lemma 4.3. \nstoc s (.a..s ' . vcons (a, s ' )) vnil = s, s . Str (o) . Proof. Straightforward rigid induction on \ns. We now use the equations shown above to establish the rela\u00adtional correspondence. Proposition 4.4. \nThe realizations FBT Cont are related, and Str and FBT hence observationally equivalent in all well-typed \ncontexts. Proof. Since stoc is a monad morphism (Lemma 4.2), as is the identity on Cont (A),byProp. 3.7(1,2), \nwe can de.ne the relational action of BT as an inverse image of the syntactic Cont(a)-relation: def s \n~TBTa u .. stoc s ~Cont(a) u type Obs = String class (Monad m) => BTT m t where bfail :: t m a bdisj \n::tma ->tm a->tma answers :: t m Obs -> StreamT m Obs instance (Monad m) => BTT m StreamT where bfail \n= vnil bdisj = append answers s = s type SAns m = StreamT m Obs -> StreamT m Obs instance (Monad m) => \nBTT m (ContT (SAns m)) where bfail = CT(\\k ->\\c-> c) bdisj g1g2 =CT(\\k -> \\c-> rCTg1 k(rCT g2 kc)) answers \nu = rCT u vcons vnil Figure 8. Backtracking in Haskell type obs = string signature BT = sig val bfail \n: unit ->(*bt*) a val bdisj : (unit ->(*bt*) a) -> (unit ->(*bt*) a) ->(*bt*) a val answers : (unit -> \n(*bt*) obs) -> obs stream end; structure StreamBT : BT = struct structure SR = Represent(StreamM) open \nSR fun bfail () = reflect vnil fun bdisj t1 t2 = reflect (append (reify t1) (reify t2)) fun answers t \n= reify t end; type r = obs stream -> obs stream val glue_r : r glue = glue_f glue_stream structure ContM \n= Cont (type r = r val glue_r = glue_r); structure ContBT : BT = struct structure CR = Represent(ContM) \nopen CR fun bfail () = reflect (fn k => fn c => c) fun bdisj t1 t2 = reflect (fn k => fn c => reify t1 \nk (reify t2 k c)) fun answers t = reify t (fn a => fn c => vcons(a,c)) vnil end; Figure 9. Backtracking \nin SML We must now check that the constants are related. The case for bfail is effectively a degenerate \nvariant of bdisj, so let us only considerthelatter.Lookingatitstype,andexpandingthe de.nition of ~ for \nfunction types (twice), suppose stoc s1 ~Cont(a) u1 and stoc s2 ~Cont(a) u2;we must show that stoc ([[FBT \nCont.bdisj] u1 u2 . Str.bdisj] s1 s2) ~Cont(a) [ FBT (25) Butby Lemma 4.1 on the LHS, BT stoc ([[FStr.bdisj] \ns1 s2)= stoc (append s1 s2) = .k..c.stoc s1 k (stoc s2 kc) BT = [ FCont.bdisj] (stoc s1)(stoc s2) and \nhence (25) follows from the Fundamental Lemma for the term FBT Cont.bdisj. (Note that we did not even \nhave to expand ~Cont(a).) Finally, for answer extraction, suppose s ~TBT o u, i.e., stoc s ~Cont(o) u;we \nmust show that BT BT [ FStr.answers] s ~Str (o) [ FCont.answers] u. (26) Using Lemma 4.3 on the LHS, \ndfpick :: (Monad m, MonadT m t, BTT m t) => [a] -> t m a dfpick [] = bfail dfpick (h:t) = bdisj (return \nh) (dfpick t) instance MonAlg IO (IO a) where (>>>=) = (>>=) printStream :: StreamT IO String -> IO () \nprintStream = sfold (return ()) (\\a -> \\d -> putStr (a ++ \"!\\n\") >> d) evens :: StreamT IO Int --or ContT \n(SAns IO) IO Int evens = do x1 <-dfpick [3,4,5] () <-lift (putStr (\"x1=\" ++ show x1 ++ \"? \")) x2 <-dfpick \n[5,6,7] () <-lift (putStr (\"x2=\" ++ show x2 ++ \"? \")) let v =x1* x2 () <-if v mod 2 == 1 then bfail else \nreturn () return v printevens :: IO () printevens = printStream (answers (evens >>= (return . show))) \nFigure 10. Tracing example in Haskell open StreamBT; (* or ContBT *) fun dfpick [] = bfail () | dfpick \n(h::t) = bdisj (fn () => h) (fn () => dfpick t) fun printstream s = sfold glue_m (fn () => ()) (fn (s, \nd) => fn () => (print (s ^ \"!\\n\"); d ())) s () fun evens () = let val x1 = dfpick [3,4,5] val () = print \n(\"x1=\" ^ Int.toString x1 ^ \"? \") val x2 = dfpick [5,6,7] val () = print (\"x2=\" ^ Int.toString x2 ^ \"? \n\") val v= x1 *x2 val () = if v mod 2 = 1 then bfail() else () inv end fun printevens () = printstream \n(answers (fn () => Int.toString (evens ()))) Figure 11. Tracing example in SML x1=3? x2=5? x2=6? 18! \nx2=7? x1=4? x2=5? 20! x2=6? 24! x2=7? 28! x1=5? x2=5? x2=6? 30! x2=7? Figure 12. Output from printevens \nBT '' [ FStr.answers] s = s = stoc s (.a..s .vcons (a, s )) vnil BT = [ FCont.answers] (stoc s) so (26) \nfollows from Theorem 3.6 for the term FBT Cont.answers. Note that the theorem also applies directly to \nbacktracking lay\u00adered above some other effect, such as I/O. Effectful operations in the underlying monad \nare still represented in the stream, even if they do not ultimately lead to solutions. For example, in \nFig\u00adures 10 12, we show how tracing output gets embedded in the an\u00adswer stream,sothatwhenthe latteriseventually \nprinted,theoutput elements are properly interleaved with the computations leading up to them. The output \nis identical for the ML and Haskell versions, data Tree_ m a = Leaf a | Node [TreeT m a] newtype TreeT \nma=TT{rTT :: m(Tree_ ma) } instance Monad m => MonAlg m (TreeT m b) where t >>>= f = TT (t >>= \\a -> \nrTT (f a)) vleaf :: Monad m => a -> TreeT m a vleaf a = TT (return (Leaf a)) vnode :: Monad m => [TreeT \nm a] -> TreeT m a vnode l = TT (return (Node l)) tfold :: (Monad m, MonAlg m d) => (a->d) -> ([d] -> \nd) -> TreeT m a-> d tfold fn t= rTT t>>>=\\m->case mof Leaf a -> fa Node l -> n (map (tfold f n) l) instance \nMonad m => Monad (TreeT m) where return a = vleaf a t >>= f = tfold f vnode t pick :: Monad m => [a] \n-> TreeT m a pick l = vnode (map return l) catstr :: Monad m => [StreamT m a] -> StreamT m a catstr = \nfoldr append vnil ttos :: Monad m => TreeT m a -> StreamT m a ttos = tfold return catstr Figure 13. Trees \nin Haskell (SML version is analogous) and for the stream-based and 2-continuation based implementations \nof backtracking.  4.2 Relating trees and streams We now consider a higher-level interface for backtracking, \nwhich allows the programmer to de.ne alternative search strategies. The keyconcept is thetree monad transformer \npresented next; it allows one to construct potentially effectful search trees. 4.2.1 The tree monad transformer \nConsider the metalanguage type Tree(a0) = Te(\u00b5a. a0 + List(Tea)) where List(a)= \u00b5a ' . 1+ a \u00d7 a '. For \nevery cpo A, de.ne CA =[ \u00b5a. a0 + List(Tea)]][a0m.A] and Tree (A)= [ Tree(a0)]][a0m.A] = T eCA . Then \nTree (A) isadomainofeffectful, .nitely-branching treeswith leaves from A. Also, let List (A)= [ List(a0)]][a0m.A] \nand let i : A + List (Tree (A)) . CA be the isomorphism associated with CA. Then de.ne constructors vleaf \n. A . Tree (A) and vnode . List (Tree (A)) . Tree (A) by vleaf a = .e(i(inl a)) vnode l = .e(i(inr l)) \n. The type Tree(a0) has the form Te(\u00b5a.d[Tea/a]) consid\u00adered in Section 2.4, de.ning d = a0 + List(a). \nTherefore, in order to derive an induction principle for effectful trees (elements of Tree (A)), we need \nto consider the de.nition of [ d] d . First, the type List(a) gives rise to a functor in a : let List \n(f)= map f =[ List(a)]]d([a .. f]). One can show that List isinfacta .nite list functor: List (X) is \nthe cpo of .nite lists with elements from X, and List (f) is indeed thefamiliar map function that applies \nf to each element of its argument. Proposition 4.5. Let P be a T e-admissible subset of Tree (A). Suppose \nthat P satis.es the following conditions: 1. For every a in A, the element vleaf a belongs to P . 2. \nFor every cpo E, continuous function g : E . Tree (A) such that the range of g is a subset of P , and \nl . List (E), the element vnode(map gl) belongs to P .  Then P is the entire set Tree (A). Proof. ByLemma \n2.10 we obtainafunctorF tree with F tree(X)= AA [ d] [a0m.A,am.X] = A + List (X) and F tree d A (f)= \n[ d] ([a0 .. idA,a .. f]) = idA + List (f). In order to apply Theorem 2.16 we must check that P is FA \ntree\u00adclosed. But this is easily seen to be equivalent to the two conditions on P above. Remark. Using \nthefact that List is a .nite list functor, condition (2) in the above proposition can be reformulated \nin a more natural\u00adlookingway:For all t1,...,tn in P ,the elementvnode[t1,...,tn] belongs to P . One advantage \nof the formulation in the proposition is that it generalizes to in.nitely branching trees (see Section \n4.4). The principle for de.nitionby inductiongivenby Theorem 2.17 is: Proposition 4.6. Let (D, w*) beaT \ne-algebra, let g1 : A .D, and g2 : List (D) . D. Then the function tfold \u00ae g1 g2 : Tree (A) . D de.ned \nby tfold \u00ae g1 g2 j .\u00ab inl a. g1(a) = .x .f..t.t w* .c. case i-1(c) of inr l. g2(map fl) is the unique \nf :(Tree (A),*e) -(D, w*) suchthat f(vleaf a)= g1(a) f(vnode l)= g2(map fl) . Like for streams, the function \ntfold is de.nable by a term in our metalanguage. Forexample, we can de.neafunctionttos .attening an effectful \ntree to an effectful stream in depth-.rst order: catstr = foldr append vnil . List (Str (A)) . Str (A) \nttos = tfold e .Str catstr . Tree (A) . Str (A) (Here foldr is thefamiliar fold right function on lists.)AHaskell \nimplementation is shown in Figure 13; the SML implementation is similar.However,theHaskellversion actually \nimplements in.nitely branching effectful trees; we return to this point in Section 4.4. Monad structure \nWeuse Proposition4.6to de.neamonad struc\u00ad ,*Tree ture (Tree,.Tree ) on effectful trees, similarly to \nwhat we did for effectful streams: Tree .a = vleaf a Tree t*h = tfold e h vnode t Then *Tree is rigid \n(in its .rst argument) and satis.es (vleaf a) *Tree h = ha Tree Tree (vnode l) *h = vnode(map (.t.t*h) \nl) . Proposition 4.7. The families of continuous functions .Tree and *Tree satisfy the three monad laws \nof De.nition 2.1. Hence ,*Tree (Tree,.Tree ) is a monad. Proof. Similar to the corresponding proof for \nstreams,but simpler. Equation (2) is a simple calculation, while Equations (3) and (4) follow directly \nby rigid induction on t (Proposition 4.5), using one of the functor laws for List:map (f .g)=(map f) \n.(map g). As for streams, Proposition 2.7 implies that the resulting tree ,*Tree monad (Tree,.Tree ) \nis layered over T\u00afe. In Haskell termi\u00adnology, we have de.ned a tree monad transformer. Since the tree \nmonad transformer can be layered on top of monad transformers for stateandexceptioneffects, one canin \nparticular useitto imple\u00adment search strategies that terminate early aftera certain numberof backtracking \noperations, or search strategies such as branch-and\u00adbound that depend on search-global state which is \nnot restored on backtracking. 4.2.2 Search operations We consider the signature of the abstract search \neffect ND to contain two operations: picka : List(a) . TNDa collecta : TNDa . Str (a) The .rst one expresses \na nondeterministic choice between the val\u00adues in a list (with en empty list representing failure); the \nsecond produces a stream of all successful answers from a nondeterminis\u00adtic computation. Note that, in \ngeneral, it need not be the case that pick [a]= .a: a choice point with only one alternative may be observably \ndifferent from a completely pure computation. Wecan implement this abstract effect with tworealizations: \none based on search trees, and one based on solution streams: ND Tree Tree FTree.ND = (Tree(\u00b7), unit, \nbind) ND Tree FTree.pick l = vnode (map unitl) FND Tree.collect r = ttos r ND Str Str FStr .ND = (Str \n(\u00b7), unit, bind) ND FStr .pick l = foldr vcons vnil l ND FStr .collect s = s In the tree-based one, a \npick is represented as a choice node with trivial computationsin the branches; the collect performs a \ndepth\u00ad.rst traversal of the tree. In the stream-based representation, pick immediately converts the list \nof choices to a stream of answers, making collect trivial. Although (as we will show), the observable \nnet effect is the same, the tree-based representation also makes it possible for collect to use traversals \nother than ttos, while the stream-based one commits to depth-.rst already at the choice point. Lemma \n4.8. ttos is a monad morphism from trees to streams. Proof. By rigid induction on trees (Proposition \n4.5). One needs the following lemma, which follows from Equation (22) by induction on the .nite list \nl:(catstr l)*S f = catstr (map (.s.s *S f) l). Lemma 4.9. For alll . List (A), ttos (vnode (map .Tree \nl)) = foldr vcons vnil l. Proof. Straightforwardveri.cation,usingthe map/fold fusionlaws for .nite lists. \nProposition 4.10. Therealizations FND Str areobservation- Tree and FND ally equivalent. Proof. Like for \nstreams, we de.ne the relational action of ND as an inverse image: t ~TNDa s . ttos t ~Str (a) s. That \nthe realizations of pick are related follows from Lemma 4.9 and the Fundamental Lemma for FND Str .pick;and \nthe case forcollect follows directly from the de.nition.  4.3 Breadth-.rst traversal The Prolog-style \ndepth-.rst search semantics embodied in the stream and 2-continuation models of backtracking is not appro\u00adpriate \nfor all programming tasks.Fora programmer, the main ad\u00advantage of programming to the ND API rather than \nthe BT one, is that the former retains the possibility of other tree traversal orders. Here we consider \nthe example of breadth-.rst search. In order to implement breadth-.rst search using the search tree model \nwe simply need to construct a stream that represents a traversal of the effectful search tree in breadth-.rst \norder. This can be done with a standard algorithm that uses a queue of subtrees. Alternatively, one can \nde.ne breadth-.rst traversal compositionally, using the general tfold function derived from Proposition \n4.6; the Haskell code is shown in Figure 14. The resulting de.nition can actually be seen as the refunctionalized \ncounterpart (Danvy and Millikin 2007) of the standard algorithm. The idea is to use a recursive type \nto allow one to process all children of a node in advance when .rst encounteringthem. Hofmann(1993)analyzesavariantduetoTofte \nthat uses a similar idea. As an example of a programming task that admits a natural solution by breadth-.rst \nbacktracking, consider the problem of constructing a stream of all untyped, closed .-terms, up to a\u00adequivalence. \nThe solution, in Haskell and SML, is shownin Fig\u00adures 15 and 16; in both cases, terms contains the desired \nstream, which can be inspected lazily. 4.4 In.nitely branching effectful trees Strictly speaking (no \npun intended), the Haskell implementation of TreesinFigure13isnotquitefaithfultothe metalanguageversion, \nbecause it is expressed using the native Haskell data type of (lazy) lists, and thus more accurately \ncorresponds to in.nitely branching effectful trees. It turns out that the development in the previous \nsections goes through when substituting lazy lists for eager lists. Instead of Tree(a0), consider the \ntype Tree ' (a0)= \u00b5a. a0 + Str (Tea). In Section 2.8 it was shown that the functorial action of Str (a) \nis a map function on streams. Therefore, we obtain induction principles for Tree ' completely similar \nto those for Tree (Propo\u00adsitions 4.5 and 4.6), except that map is now the map function on streams instead \nof lists. Furthermore, if we takethe effect in the def\u00adinition of Str (\u00b7) to be lifting, we obtain precisely \nthe data type of Haskell s lazy lists. The development in the previous sections then goes through mostly \nas before, using the fusion laws for streams from Section 2.8. In effect, one uses rigid induction on \nstreams instead of structural induction on lists.  4.5 Other models of backtracking There exist a number \nof other models of backtracking and search strategies related to monads in the literature (Wand and Vaillan\u00adcourt \n2004; Danvy et al. 2002; Hughes 1995; Hinze 2000; Kiselyov et al. 2005). Spivey(2006) gives a general \ncategorical account of search strategies based on monads, including one based on .nitely branching trees \nanalogous to our Tree,but without embedded ef\u00adfects.Withtheexceptionofthe modelsofWandandVaillancourt \n(2004), these models have not been investigated in terms of object languages with formal semantics.We \nhope that the techniques pre\u00adsented in this article could be useful in such a formalization. 5. Conclusions \nWithalittle care, the well-known induction principles for reasoning about algebraic data types scale \nto settings where the data values contain embedded computational effects, not necessarily limited to \npartiality. Moreover, such reasoning extends smoothly to pro\u00adgrams with higher-order and re.exivetypes: \nalthough the reasoning framework will generally have to be relational, most concrete veri\u00ad.cations still \nboildowntofamiliar equational reasoningby induc\u00adtion. In particular, we have systematized and generalized \nthe result ofWand andVaillancourt about relating the solution-stream and2\u00ad data Rec m a=Fun{ rFun ::[Rec \nma] -> StreamT ma} instance Monad m => MonAlg m (Rec m a) where t >>>= f = Fun (t >>>= (rFun . f)) bfs_aux \n:: Monad m => [Rec m a] -> StreamT m a bfs_aux [] = vnil bfs_aux (Fun f : fs) = f fs bfs :: Monad m => \nTreeT m a -> StreamT m a bfs t = bfs_aux [f] where f = tfold (\\a -> Fun (\\fs -> vcons a (bfs_aux fs))) \n(\\fs -> Fun (\\fs -> bfs_aux (fs ++ fs ))) t Figure 14. Breadth-.rst search in Haskell (SML is analogous) \ndata Term = Var String | App Term Term | Lam String Term deriving Show genTerm :: (Monad m) => TreeT \nm Term genTerm = gen [] where gen vs = pick [do x <-pick vs; return (Var x), do t1 <-gen vs; t2 <-gen \nvs; return (App t1 t2), let v = \"x\" ++ show (length vs) in do t <-gen (v:vs); return (Lam v t)] >>= id \nterms :: Monad m => StreamT m Term terms = bfs genTerm Figure 15. Lambda-term generation in Haskell datatype \nterm = Var of string | App of term * term | Lam of string * term structure N = Represent(TreeM); fun \nrpick l = N.reflect (pick l) fun rbfs t = bfs (N.reify t) fun genTerm () = let fun gen vs = rpick [fn \n() => Var (rpick vs), fn () => App (gen vs, gen vs), fn ()=>let val v= \"x\" ^ Int.toString (length vs) \nin Lam(v, gen (v :: vs)) end] () in gen [] end val terms : term stream = rbfs genTerm Figure 16. Lambda-term \ngeneration in SML continuation models of depth-.rst backtracking, and sketched how more general search \nstrategies can .t into the framework. More broadly,we believeour results illustrate that the category\u00adtheoretical \nfoundations of monads and related concepts provide a rich source of reasoning principles for effectful \nfunctional pro\u00adgrams, whether the monadic structure is explicit as in Haskell, or only implicit, as in \nmost ML programs. Functional programs should be easy to reason about, and proofs by structural induction \non data types are even presented in most introductory functional\u00adprogramming texts.We hope to have shown \nthat these reasoning techniques remain valid and easy to use even in imperative func\u00adtional settings. \nIn the examples, we have concentrated on backtracking mod\u00adels atop some existing notion of computation, \nsuch as partiality or I/O, which represents persistent effects that should not be undone or disappear \non backtracking. An equally important technique is to layer further monadic effects on top of backtracking, \nsuch as state-based destructive uni.cation, as found in most realistic Pro\u00adlog implementations. Monadic \nlayering allows us to separate con\u00adcerns, decoupling the underlying search strategy from higher-level \ncomputations using choice as a black-box abstraction. This is cur\u00adrently work in progress, and we hope \nto report on it at a later time. However, we believe the concept of rigid induction is a powerful yet \neasy-to-use principle in its own right, and represents a useful addition to the functional programmer \ns toolbox. Acknowledgments We thank the anonymous reviewers for comments and suggestions that helped \nimprove the presentation. References RoyL. Crole and Andrew M. Pitts. New foundations for .xpoint computa\u00adtions: \nFIX-hyperdoctrines and the FIX-logic. Information and Compu\u00adtation, 98:171 210, 1992. Olivier Danvy andKevin \nMillikin. Refunctionalization atwork. BRICS Research Report RS-07-7, Department of Computer Science, \nUniversity of Aarhus, 2007. Olivier Danvy, Bernd Grobauer, and Morten Rhiger. Aunifying approach to goal-directed \nevaluation. New Generation Computing, 20(1):53 73, 2002. ISSN 0288-3635. Andrzej Filinski. Representing \nlayered monads. In Proceedings of the 26th ACM Symposium on Principles of Programming Languages, pages \n175 188, San Antonio,Texas, January 1999.ACM Press. Andrzej Filinski. On the relations between monadic \nsemantics. Theoretical Computer Science, 375(1):41 75, 2007. Marcelo Fiore and Gordon D. Plotkin. An \naxiomatisation of computation\u00adally adequate domain theoretic models of FPC. In Proceedings of the Ninth \nSymposium on Logic in Computer Science, pages 92 102,Paris, France, 1994. Ralf Hinze. Deriving backtracking \nmonad transformers. In ICFP 00: Pro\u00adceedings of the 5th International Conference on Functional program\u00adming, \npages 186 197.ACM Press, 2000. Martin Hofmann. Non strictly positive datatypes for breadth .rst search. \nTYPES Forum posting, 1993. Available from http://www.seas. upenn.edu/~sweirich/types/archive/1993/msg00027.html. \nJohn Hughes. The design of a pretty-printing library. In Advanced Func\u00adtional Programming,First International \nSpring School, volume 925 of LNCS, pages 53 96, 1995. Oleg Kiselyov, Chung-chieh Shan, Daniel P. Friedman, \nand Amr Sabry. Backtracking, interleaving, and terminating monad transformers. In ICFP 05: Proceedings \nof the 10th International conference on Func\u00adtional programming, pages 192 203.ACM Press, 2005. Daniel \nJ. Lehmann and Michael B. Smyth. Algebraic speci.cation of data types:Asynthetic approach. Mathematical \nSystems Theory, 14:97 139, 1981. Eugenio Moggi. Notions of computation and monads. Information and Computation, \n93(1):55 92, July 1991. Andrew M. Pitts. Relational properties of domains. Information and Computation, \n127:66 90, 1996. Chris Reade. Elements of Functional Programming. AddisonWesley,1989. John C. Reynolds. \nOn the relation between direct and continuation seman\u00adtics. In 2nd Colloquium on Automata, Languages \nand Programming, volume 14 of LNCS, pages 141 156, Saarbr\u00a8ucken, Germany, July 1974. Michael Spivey. \nAlgebras for combinatorial search. In Workshop on Math\u00adematically Structured Functional Programming, \nKuressaare, Estonia, July 2006. Mitchell Wand and Dale Vaillancourt. Relating models of backtracking. \nIn ICFP 04: Proceedings of the 9thInternational conference on Func\u00adtional programming, pages 54 65.ACM \nPress, 2004.  \n\t\t\t", "proc_id": "1291151", "abstract": "<p>We present a pair of reasoning principles, <i>definition</i> and <i>proof</i> by <i>rigid induction</i>, which can be seen as proper generalizations of lazy-datatype induction to monadic effects other than partiality. We further show how these principles can be integrated into logical-relations arguments, and obtain as a particular instance a general and principled proof that the success-stream and failure-continuation models of backtracking are equivalent. As another application, we present a monadic model of general search trees, not necessarily traversed depth-first. The results are applicable to both lazy and eager languages, and we emphasize this by presenting most examples in both Haskell and SML.</p>", "authors": [{"name": "Andrzej Filinski", "author_profile_id": "81100252096", "affiliation": "University of Copenhagen, Copenhagen, Denmark", "person_id": "PP39034562", "email_address": "", "orcid_id": ""}, {"name": "Kristian St&#248;vring", "author_profile_id": "81318496592", "affiliation": "University of Aarhus, Aarhus, Denmark", "person_id": "P808408", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1291151.1291168", "year": "2007", "article_id": "1291168", "conference": "ICFP", "title": "Inductive reasoning about effectful data types", "url": "http://dl.acm.org/citation.cfm?id=1291168"}