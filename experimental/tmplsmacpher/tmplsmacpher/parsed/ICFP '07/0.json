{"article_publication_date": "10-01-2007", "fulltext": "\n Ott: Effective Tool Support for the Working Semanticist Peter Sewell. Francesco Zappa Nardelli Scott \nOwens. Gilles Peskine. Thomas Ridge. Susmit Sarkar. sa. Rok Strni. .University of Cambridge INRIA http://www.cl.cam.ac.uk/users/pes20/ott \nAbstract It is rare to give a semantic de.nition of a full-scale programminglanguage, despite the many \npotential bene.ts. Partly this is becausethe available metalanguages for expressing semantics usuallyeither \nLATEX for informal mathematics, or the formal mathematics of a proof assistant make it much harder than \nnecessary to workwith large de.nitions. We present a metalanguage speci.cally designed for this prob\u00adlem, \nand a tool, ott, that sanity-checks such de.nitions and com\u00adpiles them into proof assistant code for \nCoq, HOL, Isabelle, and (inprogress) Twelf, together with LATEX code for production-qualitytypesetting, \nand OCaml boilerplate. The main innovations are: (1)metalanguage design to make de.nitions concise, and \neasy to readand edit; (2) an expressive but intuitive metalanguage for specify\u00ading binding structures; \nand (3) compilation to proof assistant code. This has been tested in substantial case studies, including \nmod\u00adular speci.cations of calculi from the TAPL text, a LightweightJava with Java JSR 277/294 module \nsystem proposals, and a largefragment of OCaml (around 306 rules), with machine proofs of var\u00adious soundness \nresults. Our aim with this work is to enable a phasechange: making it feasible to work routinely, without \nheroic effort,with rigorous semantic de.nitions of realistic languages. Categories and Subject Descriptors \nD.3.1 [Programming Lan\u00adguages]: Formal De.nitions and Theory General Terms Languages, Theory, Veri.cation, \nStandardization 1. Introduction Problem Writing a precise semantic de.nition of a full-scaleprogramming \nlanguage is a challenging task that has been doneonly rarely, despite the many potential bene.ts. Indeed, \nStandardML remains, 17 years after publication, the shining example of alanguage that is de.ned precisely \nand is at all widely used (Milneret al. 1990). Even languages such as Haskell (Peyton Jones 2003)and \nOCaml (Leroy et al. 2005), though designed by PL researchersand in large part based on mathematical papers, \nrely on prosedescriptions. Precise semantic de.nitions are rare for several reasons, but one important \nreason is that the metalanguages that are available for ex\u00adpressing semantic de.nitions are not designed \nfor this application,making it much harder than necessary to work with large de.ni\u00adtions. There are two \nmain choices for a metalanguage: Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. (1) Informal mathematics, expressed in LATEX (by far the most common \noption). (2) Formalised mathematics, in the language of a proof assistantsuch as Coq, HOL, Isabelle, \nor Twelf (Coq; HOL; Isabelle;Twelf).  For a small calculus either can be used without much dif.culty.A \nfull language de.nition, however, might easily be 100 pages or10 000 lines. At this scale the syntactic \noverhead of LATEX markupbecomes very signi.cant, getting in the way of simply reading andwriting the \nde.nition source. The absence of automatic checkingof sanity properties becomes a severe problem in \nour experi\u00adence with the Acute language (Sewell et al. 2004), just keeping alarge de.nition internally \nsyntactically consistent during develop\u00adment is hard, and informal proof becomes quite unreliable. Further,there \nis no support for relating the de.nition to an implementation,either for generating parts of an implementation, \nor for testing con\u00adformance. Accidental errors are almost inescapable (Kahrs 1993;Rossberg 2001). Proof \nassistants help with automatic checking, but come withtheir own problems. The sources of de.nitions are \nstill clutteredwith syntactic noise, non-trivial encodings are often needed (e.g. to deal with subgrammars \nand binding, and to work around limita\u00adtions of the available polymorphism and inductive de.nition sup\u00adport), \nand facilities for parsing and pretty printing terms of thesource language are limited. Typesetting of \nde.nitions is supportedonly partially and only in some proof assistants, so one may havethe problem of \nmaintaining machine-readable and human-readableversions of the speci.cation, and keeping them in sync. \nMoreover,each proof assistant has its own (steep) learning curve, the commu\u00adnity is partitioned into \nschools (few people are .uent in more thanone), and one has to commit to a particular proof assistant \nfrom theoutset of a project. A more subtle consequence of the limitations of the availablemetalanguages \nis that they obstruct re-use of de.nitions across thecommunity, even of small calculi. Research groups \neach have theirown private LATEX macros and idioms to build on a publishedcalculus, one would typically \nre-typeset it (possibly introducingminor hopefully-inessential changes in the process). Proof assistantde.nitions \nare more often made available (e.g. in the Archive ofFormal Proofs (AFP)), but are speci.c to a single \nproof assistant.Both styles of de.nition make it hard to compose semantics in amodular way, from fragments. \nThe Dream What, then, is the ideal? We would like to have a metalanguage that is designed for the working \nsemanticist, support\u00ading common notations that have been developed over the years. Inan email or working \nnote one might write grammars for languageswith complex binding structures, for example t ::= | let p \n= t in t bind binders(p) in t p ::= ICFP 07, October 1 3, 2007, Freiburg, Germany. | x binders = x Copyright \n. 2007 ACM 978-1-59593-815-2/07/0010. . . $5.00. | { l1=p1,...,ln=pn } binders = binders(p1 ... pn) \nc and informal semantic rules, for example as below. G |-t1:T1 ... G |-tn:Tn G |-{l1=t1,...,ln=tn} : \n{l1:T1,...,ln:Tn} These are intuitively clear, concise, and easy to read and edit.Sadly, they lack both \nthe precision of proof assistant de.nitionsand the production-quality typesetting of LATEX but one mighthope \nthat only a modicum of information need be added to makethem precise, and to automatically compile them \nto both targets. Contribution We realize this dream: we describe a metalan\u00adguage speci.cally designed \nfor writing semantic de.nitions, anda tool, ott, that sanity-checks such de.nitions and compiles theminto \nproof assistant code, LATEX code for production-quality type\u00adsetting, and OCaml boilerplate for implementations. \nThe main in\u00adnovations are: Metalanguage design to make de.nitions concise and easy toread and edit (\u00a72). \nThe metalanguage lets one specify the syn\u00adtax of an object language, together with rules de.ning inductiverelations, \nfor semantic judgements. Making these easy to expressdemands rather different syntactic choices to those \nof typical pro\u00adgramming languages. The tool builds parsers and pretty-printers forsymbolic and concrete \nterms of the object language.  An expressive metalanguage (but one that remains simple andintuitive) \nfor specifying binding (\u00a73). Nontrivial object lan\u00adguages often involve complex forms of binding: not \njust the sin\u00adgle binders of lambda terms, which have received much attention,but also structured patterns, \nmultiple mutually recursive let def\u00adinitions, or-patterns, dependent record patterns, etc. We introduce \na metalanguage that can express all these but that remains close toinformal practice. We give this two \ninterpretations. Firstly, we de\u00ad.ne substitution and free variable functions for a fully concrete representation, \nnot quotiented by alpha equivalence. This is not ap\u00adpropriate for all examples, but suf.ces for surprisingly \nmany cases(including those below), and is what the tool currently implements.Secondly, we de.ne alpha \nequivalence and capture-avoiding substi\u00adtution for arbitrary binding speci.cations, clarifying several \nissues.Implementing this is future work, but we prove (on paper) that un\u00adder usable conditions the two \nnotions of substitution coincide.  Compilation to proof assistant code (\u00a74). From a single de.ni\u00adtion \nin the metalanguage, the ott tool can generate proof assistantde.nitions in Coq, HOL, Isabelle, and (in \nprogress) Twelf. Thesecan then be used as a basis for formal proof and (where the proofassistant permits) \ncode extraction and animation.  This compilation deals with the syntactic idiosyncrasies of thedifferent \ntargets and, more fundamentally, encodes features thatare not directly translatable into each target. \nThe main issues are:dependency analysis; support for common list idioms; generationand use of subgrammar \npredicates; generation of substitution andfree variable functions; (for Isabelle) a tuple encoding for \nmutuallyprimitive recursive functions, with auxiliary function de.nitionsfor nested pattern matching \nand for nested list types; (for Coqand Twelf) generation of auxiliary list types for the syntax andsemantics; \n(for Coq) generation of useful induction principles whenusing native lists; (for HOL) a stronger de.nition \nlibrary, and (forTwelf) translation of functions into relations. We aim to generate well-formed and idiomatic \nde.nitions, with\u00adout dangling proof obligations, and in good taste as a basis for userproof development. \nSubstantial case studies (\u00a75). The usefulness of the ott meta\u00adlanguage and tool has been tested in several \ncase studies. We havede.ned type systems and operational semantics for: metavar termvar, x ::= {{ com \nterm variable }} {{ isa string}} {{ coq nat}} {{ hol string}} {{ coq-equality }} {{ ocaml int}} {{ lex \nalphanum }} {{ tex \\mathit{[[termvar]]} }} grammar t :: t_ ::= {{ com term }} | x :: :: Var {{ com variable}} \n|\\x.t :: ::Lam(+bind xin t+){{ com lambda }} |tt :: ::App {{ com app }} | ( t ) :: M :: Paren {{ icho \n[[t]] }} | { t / x } t :: M :: Tsub {{ icho (tsubst_t [[t]] [[x]] [[t ]])}} v :: v_ ::= {{ com value \n}} |\\x.t :: ::Lam {{ com lambda }} terminals :: terminals_ ::= | \\ :: :: lambda {{ tex \\lambda }} | --> \n:: :: red {{ tex \\longrightarrow }} subrules v <:: t substitutions single t x :: tsubst defns Jop :: \n ::= defn t1 --> t2 :: ::reduce:: {{ com [[t1]] reduces to [[t2]]}} by --------------------------:: \nax_app (\\x.t12) v2 --> {v2/x}t12 t1 --> t1 --------------:: ctx_app_fun t1 t --> t1 t t1 --> t1 --------------:: \nctx_app_arg v t1 --> v t1 Figure 1. A small ott source .le, for an untyped CBV lambdacalculus, with \ndata for Coq, HOL, Isabelle, LATEX, and OCaml. (1) small lambda calculi: simply typed (*) and with ML \npolymor\u00adphism, both call-by-value (CBV); (2) systems from TAPL (Pierce 2002) including booleans, naturals,functions, \nbase types, units, seq, ascription, lets, .x, products,sums, tuples, records, and variants; (*) (3) \nthe path-based module system of Leroy (1996), with a termlanguage and operational semantics based on \nOwens and Flatt(2006); (4) a language for rely-guarantee and separation logic Vafeiadisand Parkinson \n(2007); (*) (5) formalisation of the core ott binding speci.cations; (6) Lightweight Java (LJ), a small \nimperative fragment of Java; (*) (7) formalisations of Java module system proposals, based on JSR277/294 \n(including LJ, around 140 semantic rules); and (8) a large core of OCaml, including record and datatype \nde.nitions(around 306 semantic rules). (*)  For the starred systems soundness results have been proved \norare well in progress, in one or more proof assistants. The TAPLand LJ examples show that a very simple \nform of modular seman\u00adtics provided by ott can be effective those TAPL features are de.ned in separate \n.les, roughly following the structure of the Tin\u00adkerType repository used to build the original text (Levin \nand Pierce2003). Most of the examples were not done by the tool developers,and (4 8) were primarily driven \nby other research goals, so we can make a reasonable preliminary assessment of the user experience.So \nfar it is positive. For small calculi it is easy to get started with thetool, and even for large de.nitions \nsuch as (7) and (8) one can fo\u00adcus on the semantic content rather than the LATEX or proof assistantmarkup. \nThe proof assistant representations we generate are rea\u00adsonably uniform, which should enable the development \nof reusableproof tactics, libraries, and idioms, speci.c to each proof assistant.Whilst we provide a \ncommon language for semantic de.nitions, wedo not aim to do the same for proofs. This paper describes \nthe key ideas underlying the ott metalan\u00adguage; it is not a user guide but that, along with the tool \nitselfand a number of examples, is available on the web (Sewell andZappa Nardelli 2007). User feedback \nis very welcome. There is along history of related work in this area, discussed in \u00a76, and we conclude \nin \u00a77.  2. Overview and Metalanguage Design In this section we give an overview of the metalanguage \nand tool,including its syntax and type structure. 2.1 A small example We begin with the example in Fig. \n1, which is a complete ott source .le for an untyped CBV lambda calculus, including the in\u00adformation \nrequired to generate proof assistant de.nitions in Coq,HOL and Isabelle, OCaml boilerplate, and LATEX. \nThe typeset LATEX is shown in Fig. 2. This is a very small example, suf.cing to illus\u00adtrate some of the \nissues but not the key problems of dealing withthe scale and complexity of a full language (or even a \nnontrivialcalculus) which are our main motivation. We comment on those aswe go, and invite the reader \nto imagine the development for theirfavorite programming language or calculus in parallel. Core First \nconsider Fig. 1 but ignore the data within {{ }} and (+ +), and the terminals block. At the top of the \n.gure,the metavar declaration introduces metavariables termvar (with synonym x), for term variables. \nThe following grammar introduces grammars for terms, with nonterminal root t, and for values v: t :: \nt_ ::= |x :: ::Var |\\x.t :: ::Lam |tt :: ::App |(t) ::M ::Paren | {t /x }t :: M :: Tsub v :: v_ ::= |\\x.t \n:: ::Lam This speci.es the concrete syntax of object-language terms, the ab\u00adstract syntax representations \nfor proof-assistant mathematics, and the syntax of symbolic terms to be used in semantic rules. The ter\u00adminals \nof the grammar (\\ .() {} /-->) are inferred, as those to\u00adkens that cannot be lexed as metavariables or \nnonterminals, avoid\u00ading the need to specify them explicitly. Turn now to the defns block at the bottom \nof the .gure. Thisintroduces a mutually recursive collection of judgments, here just asingle judgement \nt1 --> t2 for the reduction relation, de.ned bythree rules. Consider the innocent-looking CBV beta rule: \n--------------------------:: ax_app (\\x.t12) v2 --> {v2/x}t12 Here the conclusion is a term of the syntactic \nform of the judgementbeing de.ned, t1 --> t2. Its two subterms (\\x.t12) v2 and {v2/x}t12 are symbolic \nterms for the t grammar, not concreteterms of the object language. They involve some object-language \nconstructors (instances of the Lam and App productions of the t grammar), just as concrete terms would, \nbut also: termvar, x term variable t ::= term | x variable | . x . t bind x in t lambda | t t. app v \n::= value | . x . t lambda t1 -. t2 t1 reduces to t2 AX APP ( . x . t12 ) v2 -. { v2 / x } t12 t1 -. \nt. 1 CTX APP FUN t1 t -. t1 . t t1 -. t. 1 CTX APP ARG vt1 -. vt1 . Figure 2. LATEX output generated \nfrom the Fig. 1 source .le mention symbolic metavariables (x) and nonterminals (t12 and v2), built from \nthe metavariable and nonterminal roots (x, t, and v) by appending structured suf.xes here just numbers; \n depend on a subtype relationship between v and t (declared bythe subrules v <:: t, and checked by the \ntool) to allow v2 to appear in a position where a term of type t is expected; and  involve syntax for \nparentheses and substitution. The concretesyntax for these is given by the Paren and Tsub productions \nof the t grammar, but these are metaproductions (.agged M ), for which we do not want abstract syntax \nconstructors.  The ax app rule does not have any premises, but the other two rules do, e.g. t1 --> t1 \n--------------:: ctx_app_arg v t1 --> v t1 Here the premises are instances of the judgement being de.ned,but \nin general they may be symbolic terms of a formula grammarthat includes all judgement forms by default, \nbut can also containarbitrary user-de.ned formula productions, for side-conditions. This core information \nis already a well-formed ott source .le that can be processed by the tool, sanity-checking the de.nitions,and \ndefault typeset output can be generated. Proof assistant code To generate proof assistant code we .rstneed \nto specify the proof assistant representations ranged over bymetavariables: the isa , coq and hol annotations \nof the metavar block specify that the Isabelle, Coq and HOL string, nat and string types be used. For \nCoq the coq-equality generates anequality decidability lemma and proof script for the type. The proof \nassistant representation of abstract syntax is thengenerated from the grammar. For a very simple example, \nthe Coqcompilation for t generates a free type with three constructors: Inductive t : Set := t_Var : \ntermvar -> t | t_Lam : termvar -> t -> t |t_App :t-> t->t. The general case, rather more complex than \nthis, is discussed in \u00a74, but for now note that the metaproductions do not give rise to proofassistant \nconstructors. Instead, the user can specify an arbitrarytranslation for each. These translations ( homs \n) give clauses of E . e1 : t1 ... E . en : tn E . .eld name1 : t . t1 ... E . .eld namen : t . tn 1 \n, ... , t E . typeconstr name . . ( t ) typeconstr namet = l typeconstr name . 1 . m } ; ... ; .eld \nname . : kind { .eld name.eld name1 ... .eld namen PERMUTES .eld name1 ... .eld name . m length ( e1 \n) ... ( en ) v 1 JTE RECORD CONSTR E .{ .eld name1 = e1 ; ... ; .eld namen = en } : t E|-e1:t1 ... E|-en \n:tn E |-field name1 : t->t1 ... E |-field namen : t->tn t = (t1 , ..., tl ) typeconstr name E |-typeconstr \nname gives typeconstr name:kind {field name1 ; ...; field namem } field name1...field namen PERMUTES \nfield name1 ...field namem length (e1)...(en)>=1 --------------------------------------------------------------------------:: \nrecord constr E |-{field name1=e1; ...; field namen=en} : t Figure 3. A sample OCaml semantic rule, in \nLATEX and ott source forms functions from symbolic terms to the character string of generatedproof-assistant \ncode. In this example, the {{ icho [[t]] }} hom for the Paren production says that (t) should be translated \ninto just the translation of t, whereas the {{ icho (tsubst t [[t]] [[x]] [[t ]])}} hom for Tsub says \nthat {t/x}t should be translated into the proof-assistant application of tsubst t to the translations \nof t, x, and t . The (admittedly terse) icho speci\u00ad.es that these translations should be done uniformly \nfor Isabelle,Coq, HOL, and OCaml output, and one can also specify differenttranslations for each. The \ntsubst t mentioned in the hom for Tsub above is a proofassistant identi.er for a function that calculates \nsubstitution over terms, automatically generated by the substitutions declara\u00adtion. We return in \u00a73 to \nwhat this does, and to the meaning of thebinding speci.cation (+ bind x in t+) in the Lam production. \nHoms can also be used to specify proof assistant types for nonterminals, in cases where one wants a speci.c \nproof assistanttype expression rather than a type freely generated from the syntax. Tuned typesetting \nTo .ne-tune the generated LATEX, to producethe output of Fig. 2, the user can add various data: (1) the \n{{ tex \\mathit{[[termvar]]} }} in the metavar declaration, speci\u00adfying that termvars be typeset in math \nitalic; (2) the terminals grammar, overriding the default typesetting for terminals \\ and --> by . and \n-.; and (3) {{ com ...}} comments, annotating pro\u00adductions and judgements. One can also write tex OCaml \nboilerplate The tool can also generate OCaml boiler\u00adplate: type de.nitions for the abstract syntax, and \nfunctions for sub\u00adstitution etc. (but not the judgments). To do this one need specifyonly the OCaml representation \nof metavariables, by the ocaml hom in the metavar block, and OCaml homs for metaproductions, herealready \nincluded in the uniform icho homs.  2.2 List forms For an example that is rather more typical of a large-scale \nseman\u00adtics, consider the record typing rule shown in the top half of Fig. 3,taken from our OCaml fragment \nde.nition. The .rst, second, andfourth premises are uses of judgement forms; the other premisesare uses \nof formula productions with meanings de.ned by homs.The rule also involves several list forms, indicated \nwith dots ... , as is common in informal mathematics. Lists are ubiquitous in pro\u00adgramming language syntax, \nand this informal notation is widelyused for good reasons, being concise and clear. We therefore sup\u00adport \nit directly in the metalanguage, making it precise so that wecan generate proof assistant de.nition clauses, \ntogether with theLATEX shown. The bottom half of Fig. 3 shows the source text for that rule note the \nclose correspondance to the typeset version, making it easyto read and edit. Looking at it more closely, \nwe see index variables n, m, and l occuring in suf.xes. There are symbolic nonterminalsand metavariables \nindexed in three different ranges: e., t., and .eld name. are indexed from 1 to n, .eld name. is indexed \nannotations to override the default . . . . is indexed 1 to l. To parse list forms involvingin F<: one \nmight wish to typeset term abstractions with . and type dots, the tool .nds subterms which can be antiuni.ed \nby abstractingabstractions with ., and .ne-tune the spacing, writing productions out components of suf.xes. \nWith direct support for lists, we need also direct support for |\\x:T.t ::::Lam symbolic terms involving \nlist projection and concatenation, e.g. in {{ tex \\lambda [[x]] \\mathord{:} [[T]]. \\, [[t]] }} the rules \nbelow (taken from a different case study). |\\X<:T.t ::::TLam {{ tex \\Lambda [[X]] \\mathord{<:} [[T]]. \n\\, [[t]] }} PROJ 1 = typesetting at the level of productions, not just tokens. For example,from 1 to \nm, and t . . { l} . l-. vj v1 , .., l =vn jn to typeset terms such as (\\X<:T11.\\x:X.t12) [T2] as (.X \n<:T11..x:X . t12 )[ T2 ]. These annotations de.ne clauses . t -. t REC of functions from symbolic terms \nto the character string of gen\u00ad { l1 = erated LATEX, overriding the built-in default clause. Similarly, \none -. { l1 = can control typesetting of symbolic metavariable and nonterminal Lastly, one sometimes \nwants to write list comprehensions rather . . . 1 , .., l, l1 , .., l .. v1 , .., lm = vm , l = t , \nltt 1 = = n n ... } v1 , .., lm = vm , l = tt . } = t 1 = n n roots, e.g. to typeset a nonterminal \nroot G as .. than dots, for compactness or as a matter of general style. WeConcrete terms To fully specify \nthe concrete syntax of the support comprehensions of several forms, e.g. with explicit index i object \nlanguage one need only add de.nitions for the lexical formof variables, concrete instances of metavariables, \nwith the {{ lex alphanum alphanum}} hom in the metavar block. Here alphanum is a built\u00ad PROJ . . t \n. lj : Tj Other types commonly used in semantics, e.g. .nite maps or sets,can often be described with \nthis list syntax in conjunction with typeand metaproduction homs to specify the proof assistant representa\u00adtion. \n 2.3 Syntactic Design Some interlinked design choices keep the metalanguage general butsyntactically \nlightweight. Issues of concrete syntax are often bestavoided in semantic research, tending to lead to \nheated and un\u00adproductive debate. In designing a usable metalanguage, however,providing a lightweight \nsyntax is important, just as it is in design\u00ading a usable programming language. We aim to let the workingsemanticist \nfocus on the content of their de.nitions without beingblinded by markup, inferring data that can reasonable \nbe inferredwhile retaining enough redundancy that the tool can do useful errorchecking of the de.nitions. \nFurther, the community has developed avariety of well-chosen concise notations; we support some (thoughnot \nall) of these. The tradeoffs are rather different from those forconventional programming language syntax. \nThere are no built-in assumptions on the structure of the math\u00adematical de.nitions (e.g., we do not assume \nthat object languageshave a syntactic category of expressions, or a small-step reductionrelation). Instead, \nthe tool supports de.nitions of arbitrary syntaxand of inductive relations over it. Syntax de.nitions \ninclude the fullsyntax of the symbolic terms used in rules (e.g. with metaproduc\u00adtions for whatever syntax \nis desired for substitution). Judgementscan likewise have arbitrary syntax, as can formulae. The tool \naccepts arbitrary context-free grammars, so the userneed not go through the contortions required to make \na non\u00adambiguous grammar (e.g. for yacc). Abstract syntax grammars,considered concretely, are often ambiguous, \nbut the symbolic termsused in rules are generally rather small, so this ambiguity rarelyarises in practice. \nWhere it does, we let the user resolve it withproduction-name annotations in terms. The tool .nds all \nparses ofsymbolic terms, .agging errors where there are multiple possibili\u00adties. It uses scannerless \nmemoized CPS d parser combinators, tak\u00ading ideas from Johnson (1995), which is simple and suf.cientlyef.cient. \nNaming conventions for symbolic nonterminals and metavari\u00adables are rigidly enforced they must be composed \nof one of theirroots and a suf.x. This makes many minor errors detectable, makesit possible to lex the \nsuf.xes, and makes parsing much less ambigu\u00adous. 2.4 Work.ow To make the ott tool more usable in realistic \nwork.ows, we have had to attend to some conceptually straightforward but pragmati\u00adcally important engineering \nissues. We mention a few to give the.avour: Both LATEX and proof assistant .les can be .ltered, replacing \nde\u00adlimited ott-syntax symbolic terms (or concrete term examples)in documents, e.g. [[(\\x.x x) x --> t]], \nby their LATEX or proof assistant rendering. Additionally, LATEX and proof as\u00adsistant code can be embedded \nwithin an ott source .le (andsimilarly .ltered). Typesetting style is indirected, so that it canbe controlled \nby rede.ning LATEX commands.  The generated LATEX is factored into LATEX commands for in\u00addividual rules, \nthe rules of individual defn s, etc., up to thecomplete de.nition, so that parts or all of the de.nition \ncan bequoted in other documents.  The proof assistants each have their own support, more-or-lesselaborate, \nfor fancy syntax. For Isabelle the tool can generatethese declarations from an ott source grammar, so \nthat they  can be used in proof scripts and in the displayed goals duringinteractive proof. We support \ncommon pre.xes for rule names and productionnames (e.g. the t in Fig. 1), and allow synonyms for nonter\u00adminal \nand metavariable roots (e.g. if one wanted S, T , and U to range over a grammar of types).  3. Binding \nSpeci.cations and Substitution How to deal with binding, and the accompanying notions of substi\u00adtution \nand free variables, is a key question in formalised program\u00adming language semantics. It involves two \nissues: one needs to .xon a class of binding structures being dealt with, and one needsproof-assistant \nrepresentations for them. The latter has been the subject of considerable attention, withrepresentation \ntechniques based on names, De Bruijn indices,higher-order abstract syntax (HOAS), locally nameless terms, \nnom\u00adinal sets, and so forth, in various proof assistants. The annotatedbibliography by Chargu\u00b4eraud (2006) \ncollects around 40 papers onthis, and it was a central focus of the POPLmark challenge (Ay\u00addemir et al. \n2005). Almost all of this work, however, deals only with the simplestclass of binding structures, the \nsingle binders we saw in the lambda abstraction production of the \u00a72 example: t ::= | . x . t bind x \nin t lambda in which a single variable binds in a single subterm. Realistic pro\u00adgramming languages often \nhave much more complex binding struc\u00adtures, e.g. structured patterns, multiple mutually recursive let \ndef\u00adinitions, comprehensions, or-patterns, and dependent record pat\u00adterns. We therefore turn our attention \nto the potential range of bind\u00ading structures. 3.1 The ott binding metalanguage: syntax We introduce \na novel metalanguage for specifying binding struc\u00adtures, expressive enough to cover all the above but \nremaining sim\u00adple and intuitive. It comprises two forms of annotation on produc\u00adtions. The .rst, bind \nmse in nonterm, lets one specify that vari\u00adables bind in nonterminals of the production, as in the lambda \npro\u00adduction above. Here mse is a metavariable set expression, e.g. in that lambda production just the \nsingleton metavariable x of the pro\u00adduction. A variable can bind in multiple nonterminals, as in the \nex\u00adample of a simple recursive let below. t ::= | let rec f = t in t. bind f in t . bind f in t More \ncomplex examples require one to collect together sets ofvariables. For example, the grammar below has \nstructured patterns,with a let p = t in t. production in which all the binders of the pattern p bind \nin the continuation t. . t ::= | x | ( t1 , t2 ) | let p = t in t. bind binders(p) in t. p ::= | binders \n= {}| x binders = x | ( p1 , p2 ) binders = binders(p1) . binders(p2) This is expressed with the second \nform of annotation: user-de.nedauxiliary functions such as the binders above. This is an auxiliaryfunction \nde.ned over the p grammar that identi.es a set of vari\u00adables to be used in the bind annotation on the \nlet production. The syntax of a precise fragment of the binding metalanguageis given in Fig. 4, where \nwe have used ott to de.ne part of the ott metalanguage. A simple type system (not shown) enforcessanity \nproperties, e.g. that each auxiliary function is only appliedto nonterminals that it is de.ned over, \nand that metavariable set expressions are well-sorted. Further to that fragment, the tool supports binding \nfor the listforms of \u00a72.2. Metavariable set expressions can include lists ofmetavariables and auxiliary \nfunctions applied to lists of nontermi\u00adnals, e.g. as in the record patterns below. p ::= | x b = x |{ \nl1 = p1 , .., ln = pn } b = b(p1..pn ) This suf.ces to express the binding structure of almost all the \nnat\u00adural examples we have come across, including de.nitions of mutu\u00adally recursive functions with multiple \nclauses for each, Join calcu\u00adlus de.nitions (Fournet et al. 1996), dependent record patterns, andmany \nothers. Given a binding speci.cation, the tool can generate substitutionfunctions automatically. Fig. \n1 contained the block: substitutions single t x :: tsubst which causes ott to generate proof-assistant \nfunctions for singlesubstitution of term variables x by terms t over all (non-subtype) types of the grammar \n here just t, so a function named tsubst t is generated. Multiple substitutions can also be generated, \nand thereis similar machinery for free variable functions.  3.2 The ott binding metalanguage: semantics \nWe give meaning to these binding speci.cations in two ways. The fully concrete representation The .rst \nsemantics (and theonly one that is currently supported by the tool) is what we term a fully concrete \nrepresentation. Perhaps surprisingly, a reasonablywide range of programming language de.nitions can be \nexpressedsatisfactorily without introducing alpha equivalence. In typical call\u00adby-value or call-by-name \nlanguages, there is no reduction underterm variable binders. The substitutions that arise therefore onlysubstitute \nclosed terms, so there is no danger of capture. The fullyconcrete representation uses abstract syntax \nterms with concretevariable names, as in the example Coq type t of \u00a72.1 (Fig. 5 givesa general grammar \nof such concrete abstract syntax terms, casts).Substitution is de.ned so as to not substitute for bound \nvariables within their scopes, but without using any renaming. Continuingthe \u00a72.1 example, ott generates \nCoq code essentially as below. Fixpoint tsubst_t (t2:t)(x1:termvar)(t2:t){struct t2}:t := match t2 with \n| (t_Var x) => (if eq_termvar x x1 then t2 else (t_Var x)) | (t_Lam x t1) => t_Lam x (if eq_termvar x1 \nx) then t1 else (tsubst_t t2 x1 t1)) | (t_App t1 t ) => t_App (tsubst_t t2 x1 t1) (tsubst_t t2 x1 t ) \nend. Doing this in the general case highlights a subtlety: when substi\u00adtuting (e.g.) ts for xs, the only \noccurrences of x that are substi\u00adtutable are those in instances of productions of the t grammar that \ncomprise just a singleton x (e.g. here the Var production), as onlythere will the result be obviously \ntype correct. Other occurrences, e.g. the x in the Lam production, or the x in the pattern grammarsabove, \nare not substitutable, and, correspondingly, should not ap\u00adpear in the results of free variable functions. \nIn natural examples metavars metavarroot, mvr nontermroot, ntr terminal, t auxfn, f prodname, pn variable, \nvar grammar metavar, mv ::= | metavarroot su.x nonterm, nt ::= | nontermroot su.x element, e ::= | terminal \n| metavar | nonterm metavar set expression, mse ::= | metavar | auxfn(nonterm) . | mse union mse| {} \nbindspec, bs ::= | bind mse in nonterm | auxfn = mse prod, p ::= | | element1 .. elementm :: :: prodname \n(+ bs1 .. bsn +) rule, r ::= | nontermroot :: ::= prod1 .. prodm grammar rules, g ::= | grammar rule1 \n.. rulem Figure 4. Mini-Ott in Ott: the binding speci.cation metalanguage concrete abstract syntax term, \ncast ::= | var : mvr | prodname ( cast1 , .., castm ) Figure 5. Mini-Ott in Ott: concrete abstract syntax \nterms one might expect all such occurrences to be bound at some point inthe grammar. A precise de.nition \nof this fully concrete representation is avail\u00adable for the Mini-Ott of Fig. 4, including de.nitions \nof substitutionand free variables over the general concrete abstract syntax termsof Fig. 5 (Sewell and \nZappa Nardelli 2007), but for lack of spacewe do not include it here. Alpha equivalence The fully concrete \nrepresentation suf.cesfor the case studies we describe here (notably including the OCamlfragment), but \nsometimes alpha equivalence really is needed e.g. where there is substitution under binders, for dependent \ntype environments1, or for compositional reasoning about terms. Wehave therefore de.ned notions of alpha \nequivalence and capture\u00adavoiding substitution over concrete abstract syntax terms, again foran arbitrary \nMini-Ott object language and binding speci.cation.These de.nitions are again precise, in Ott-Isabelle/HOL, \nand areavailable on the web (Sewell and Zappa Nardelli 2007). Here weexplain just the key points by two \nexamples. 1 The POPLmark F<: example is nicely expressible in ott as far as LATEX output goes, but its \ndependent type environments would require explicit alpha conversion in the rules to capture the intended \nsemantics using the fully concrete representation. First, consider the OCaml or-patterns2 p1 | p2, e.g. \nwith a pat\u00adtern grammar p ::= | x b = x | ( p1 , p2 ) b = b(p1) . b(p2) | p1 | p2 b = b(p1) . b(p2) | \nNone b = {} | Some p b = b(p) This would be subject to the conditions (captured in type rules)that for \na pair pattern ( p1 , p2 ) the two subpatterns have disjointdomain, whereas for an or-pattern p1 | p2 \nthey have equal domainand types. One can then write example terms such as that below. let (( None , Some \nx ) | ( Some x , None )) = y in ( x , x ) Here there is no simple notion of binding occurrence . Instead,one \nshould think of the two occurrences of x in the pattern, and the two occurrences of x in the continuation, \nas all liable to alpha-varytogether. This can be captured by de.ning, inductively on concreteabstract \nsyntax terms cast, partial equivalence relations ecast over the occurrences of variables within them. \nIn the example it wouldrelate all four occurrences of x to each other, as below, but leave y unrelated. \nlet (( None , Some x ) | ( Some x , None )) = y in ( x , x ) Given this, one can de.ne two terms to be \nalpha equivalent if theirequivalence classes of occurrences can be freshly renamed to makethem identical. \nFor the second example, consider a system such as F<: with type environments . as below. . ::= | ., X \n<:T | ., x:T In setting up such a system, it is common to treat the terms andtypes up to alpha equivalence. \nThere is then a technical choiceabout whether the judgements are also taken up to alpha equiva\u00adlence: \nin typing judgements . . t : T , one can either treat . con\u00adcretely or declare the domain of . to bind \nin t and in T . Supposeone takes the second approach, and further has each element of . (X<: T or x : \nT ) binding (X or x) in the succeeding elements.(All these options can be expressed in the ott bindspec \nmetalan\u00adguage.) For a complete judgement such as ., X <:Top, Y<:X . X , x:X ,y:Y . y x : X it is then \neasy to see what the binding structure is, and we can depictthe ecast as below. ., X <:Top, Y<:X . X \n, x:X ,y:Y . y x : X For that type environment in isolation, however, i.e. ., X <:Top, Y<:X . X , x:X \n,y:Y while in some sense the X <: Top binds in the tail, it must not be alpha-varied that only becomes \npossible when it is put inthe complete context of a judgement. Our de.nitions capture thisphenomenon \nby de.ning for each term cast not just an ecast rela\u00adtion for closed binding but also a similar ocast \npartial equivalencerelation for open binding, relating occurrences which potentially may alpha-vary together \nif this term is placed in a larger, binding,context. The ocast is not directly involved in the de.nition \nof alpha 2 Similar binding occurs in the Join calculus, where a join de.nition may mention the bound \nnames arbitrarily often on the left. equivalence, but is (compositionally) used to calculate the ecast \n. It is shown for this example below. ., X <:Top, Y<:X . X , x:X ,y:Y Nontrivial open binding also occurs \nin languages with dependentpatterns, e.g. those with pattern matching for existential types. We increase \ncon.dence in these de.nitions by proving a theo\u00adrem that, under reasonable conditions, substitution of \nclosed terms in the fully concrete representation coincides with capture-avoidingsubstitution for our \nnotion of alpha equivalence for arbitrary bind\u00ading speci.cations. The conditions involve the types of \nthe desiredsubstitution and the auxiliary functions present to a .rst approx\u00adimation, that the types \nof substitutions (e.g. t for x), are distinctfrom the domains and results of auxiliary functions (e.g. \nbinders, collecting, from patterns p, variables x). In the absence of a widelyaccepted alternative class \nof binding speci.cations, there is no wayto even formulate correctness of that notion in general, but \nforspeci.c examples one can show that it coincides with a standardrepresentation. We did that (a routine \nexercise), for the untypedlambda calculus. At present both of these are hand proofs, thoughabove mechanized \nde.nitions we aim to mechanize them in due course. Generating proof assistant code that respects this \nnotion of alphaequivalence, for arbitrary binding speci.cations, is a substantialquestion for future \nwork. It could be addressed directly, in whichcase one has to understand how to generalise the existing \nproofassistant representations, and what kind of induction schemes toproduce, or via a uniform translation \ninto single binders perhapsintroducing proof-assistant binders at each bindmse point in thegrammar. \nA more tractable (but still rather expressive) subclass ofbinding speci.cations can be obtained by simple \nstatic conditionsthat guarantee that there is no open binding.  4. Compilation to Proof Assistant Code \nOur compilation generates proof-assistant de.nitions: of types; offunctions, for subgrammar predicates, \nfor the binding auxiliariesof \u00a73, for single and multiple substitution, and for free variables;and of \nrelations, for the semantic judgements. We generate well\u00adformed proof assistant code, without dangling \nproof obligations,and try also to make it idiomatic for each proof assistant, to providea good basis \nfor mechanized proof. All this is for Coq, HOL, and Isabelle/HOL, and work on compilation to Twelf is \nin progress. 4.1 Types Each metavariable declaration gives rise simply to a proof assistanttype abbreviation, \nfor example types termvar = \"string\" in the Isabelle generated from Fig. 1. For each nonterminal root \nofthe user s grammar, if (a) it is a maximal element of the subruleorder, and (b) no type hom has been \nspeci.ed, then we generate afree type with a constructor for each non-meta production of thegrammar (as \nin the simple \u00a72.1 example of t). Nonterminal rootswith type homs give rise to type abbreviations. Nonterminal \nrootsthat are not maximal, e.g. the v of Fig. 1, are represented using thetype generated for the (unique) \nmaximal element above them. Forthese we also generate and use subgrammar predicates that carveout the \nrelevant part of that type, as discussed below. In general there may be a complex pattern of mutual recursionamong \nthese types. Coq, HOL and Isabelle all support mutuallyrecursive type de.nitions (with Inductive, Hol_datatype, \nand datatype respectively), but it is desirable to make each mutually recursive block as small as possible, \nto simplify the resulting induc\u00adtion principle. Accordingly, we topologically sort the rules accord\u00ading \nto a dependency order, generating mutually recursive blocksfor each connected component and inserting \nany (singleton) typeabbreviations where they .t. We also have to choose a representation for productions \ninvolv\u00ading list forms. For example, for a language with records one mightwrite metavar label, l ::= {{ \nhol string }} {{ coq nat }} indexvar index, n ::= {{ hol num }} {{ coq nat }} grammar t :: E_ ::= |{l1=t1, \n..,ln=tn} ::::record In HOL and Isabelle we represent these simply with contructorswhose argument types \ninvolve proof-assistant native list types, e.g. val _ = Hol_datatype t = E_record of (label#t) list ; \nFor Coq, however, we provide two alternatives: one can either usenative lists or lists can be translated \naway, depending on taste. In theformer case we generate an appropriate induction principle usingnested \n.xpoints, as the default principle produced by Coq is tooweak to be useful. In the latter case we synthesise \nan additionaltype for each type of lists-of-tuples that arises in the grammar. Inthe example, we need \na type of lists of pairs of a label and a t: Inductive list_label_t : Set := Nil_list_label_t : list_label_t \n| Cons_list_label_t : label -> t -> list_label_t -> list_label_t witht :Set:= E_record : list_label_t \n-> t . These are included in the topological sort, and utility functions, e.g. to make and unmake lists, \nare synthesised. A similar translationwill be needed for Twelf, as it has no polymorphic list type. We \nalsogenerate, on request, default Coq proofs that there is a decidableequality on various types. 4.2 \nFunctions The generated functions are de.ned by pattern-matching and re\u00adcursion. The patterns are generated \nby building canonical symbolicterms from the productions of the grammar. The recursion is es\u00adsentially \nprimitive recursion: for Coq we produce Fixpoints or Definitions as appropriate; for HOL we use an ottDefine \nvari\u00adant of the Define package; and for Isabelle we produce primrecs. In general we have to deal both \nwith the type dependency (the topo\u00adlogically sorted mutually recursive types described above) and withfunction \ndependency for subgrammar predicates and bindingauxiliaries we may have multiple mutually recursive \nfunctions overthe same type. Subgrammar Predicates We generate subgrammar predicatesto carve out the \nsubsets of each free proof assistant type (fromthe maximal elements of the subrule order) that represent \nthe non\u00adfree rules of the grammar. The non-free grammar rules are theleast subset of the rules that either \n(1) occur on the left of asubrule (<::) declaration, or (2) have a (non-meta) production thatmentions \na non-free rule. Note that these can include rules that are maximal elements of the subrule order, e.g. \nif an expressiongrammar included a production involving packaged values. Thesubgrammar predicate for \na type is de.ned by pattern matchingover constructors of the maximal type above it for each non\u00admeta \nproduction of the maximal type it calculates a disjunction overall the productions of the lower type \nthat are subproductions of it,invoking other subrule predicates as appropriate. Binding Auxiliaries These \nfunctions calculate the intuitive fullyconcrete interpretations of auxiliary functions de.ned in bindspecs,as \nin \u00a73.2, giving proof assistant sets or lists, of metavariables ornonterminals, over each type for which \nthe auxiliary is de.ned. Substitutions and free variables The generated substitutionfunctions also walk \nover the structure of the free proof assistanttypes. For each production, for each occurrence of a nonterminal \nnt within it, we .rst calculate the things (of whatever type is inquestion) binding in that nt, i.e. \nthose that should be removed from the domain of any substitution pushed down into it. In simple cases \nthese are just the interpretation of the mse . (of the right type) from any bind mse . in nt of the production. \nThe substitution functionclause for a production is then of one of two forms: either (1) theproduction \ncomprises a single element, of the metavariable that weare substituting for, and this is within the rule \nof the nonterminalthat it is being replaced by, or (2) all other cases. For (1) the ele\u00adment is compared \nwith the domain of the substitution, and replacedby the corresponding value from the range if it is found. \nFor (2)the substitution functions are mapped over the subelements, hav\u00ading .rst removed any bound things \nfrom the domain of the substi\u00adtution. (Substitution does not descend through nonterminals withtype homs, \nas they may be arbitrarily complex, so these shouldgenerally only be used at upper levels of a syntax, \ne.g. to use .\u00adnite maps for type environments.) The fully concrete interpretationalso lets us de.ne substitution \nfor nonterminals, e.g. to substitute for compound identi.ers such as a dot-form M.x. This is all done \nsimilarly, but with differences in detail, for single and for multi\u00adple substitutions, and for the corresponding \nfree variable functions.For all these we simplify the generated functions by using the de\u00adpendency analysis \nof the syntax, only propagating recursive callswhere needed. Dealing with the proof assistants Each proof \nassistant intro\u00adduced its own further dif.culties. Leaving aside the purely syntacticidiosyncrasies (which \nare far from trivial, but not very interesting): For Coq, when translating lists away, generation of \nfunctionsover productions that involve list types must respect that transla\u00adtion. We therefore generate \nauxiliary functions that recurse overthose list types. Coq also needs an exact dependency analysis. For \nHOL, the standard Define package tries an automatic ter\u00admination proof. This does not suf.ce for all \ncases of our gener\u00adated functions involving list types, so we developed an ottDefine variant, with stronger \nsupport for proving termination of de.nitionsinvolving list operators. For Isabelle, we chose the primrec \npackage, to avoid any dan\u00adger of leaving dangling proof obligations, and because our func\u00adtions are all \nintuitively primitive recursive. Unfortunately, in thereleased (Isabelle2005) version, primrec does not \nsupport de.ni\u00adtions involving several mutually recursive functions over the sametype. For these we generate \nsingle functions calculating tuples ofresults, de.ne the intended functions as projections of these, \nandgenerate lemmas (and simple proof scripts) characterising them interms of the intended de.nitions. \nFurther, it does not support pat\u00adtern matching involving nested constructors. We therefore generateauxiliary \nfunctions for productions with embedded list types. Is\u00adabelle tuples are treated as iterated pairs, so \nwe do the same forproductions with tuples of size 3 or more. Isabelle also requires afunction de.nition \nfor each recursive type. In the case where thereare multiple uses of the same type (e.g. several uses \nof t list in different productions) all the functions we wish to generate needidentical auxiliaries, \nso identical copies must be generated. In retro\u00adspect, the choice to use primrec is debatable, and it \nhas been sug\u00adgested that future versions of Isabelle will have a more robust def\u00adinition package for \ngeneral functions, which should subsume someof the above.  4.3 Relations The semantic relations are \nde.ned with the proof-assistant induc\u00adtive relations packages, Inductive, Hol_reln, and inductive, respectively. \nEach defns block gives rise to a potentially mutu\u00ad symterm, st ::= | stnb | nonterm symterm node body, \nstnb ::= | prodname ( ste1 , .., stem ) symterm element, ste ::= | st | metavar | var : mvr Figure 6. \nMini-Ott in Ott: symbolic terms ally recursive de.nition of each defn inside it (it seems clearer notto \ndo a topological sort here). De.nition rules are expressed inter\u00adnally with symbolic terms. We give a \nsimpli.ed grammar thereofin Fig. 6, omitting the symbolic terms for list forms. A symbolic term st for \na nonterminal root is either an explicit nonterminal ora node, the latter labelled with a production \nname and containinga list of symterm elements, which in turn are either symbolicterms, metavariables, \nor variables. Each de.nition rule gives riseto an implicational clause, essentially that the premises \n(ott sym\u00adbolic terms of the formula grammar) imply the conclusion (an ott symbolic term of whichever \njudgement is being de.ned). Symbolicterms are compiled in several different ways: Nodes of non-meta \nproductions are output as applications of the appropriate proof-assistant constructor (and, for a subrule, \npromoted to the corresponding constructor of a maximal rule).  Nodes of meta productions are transformed \nwith the user\u00adspeci.ed homomorphism.  Nodes of judgement forms are represented as applications of the \nde.ned relation in Coq and HOL, and as set-membership assertions in Isabelle.  Further, for each nonterminal \nof a non-free grammar rule, e.g. a us\u00adage of v where v<::t, an additional premise invoking the gener\u00adated \nsubrule predicate for the non-free rule is added, e.g. is_v v . For Coq and HOL, explicit quanti.ers \nare introduced for all vari\u00adables mentioned in the rule. Supporting list forms requires some additional \nanalysis. Forexample, consider the record typing rule below. . . t0 :T0 .. . . tn-1 :Tn-1 TY RCD . .{ \nl0 =t0 , .., ln-1 =tn-1 }:{ l0 :T0 , .., ln-1 :Tn-1 } We analyse the symbolic terms in the premises and \nconclusionto identify lists of nonterminals and metavariables with the samebounds here t0..tn-1, T0..Tn-1, \nand l0..ln-1 all have bounds 0..n - 1. To make the fact that they have the same length im\u00admediate in \nthe generated code, we introduce a single proof as\u00adsistant variable for each such collection, with appropriate \npro\u00adjections and list maps/foralls at the usage points. For exam\u00adple, the HOL for the above is essentially \nas follows, with an l_t_Typ_list : (label#t#Typ) list. (* Ty_Rcd *) !(l_t_Typ_list:(label#t#Typ) list) \n(G:G) . (EVERY (\\b.b) (MAP (\\(l_,t_,Typ_). (Ty G t_ Typ_)) l_t_Typ_list)) ==> (Ty G (E_record (MAP (\\(l_,t_,Typ_). \n(l_,t_)) l_t_Typ_list)) (T_Rec (MAP (\\(l_,t_,Typ_). (l_,Typ_)) l_t_Typ_list))) This seems to be a better \nidiom for later proof development than thealternative of three different list variables coupled with \nassertionsthat they have the same length. The HOL code for the REC rules we saw in \u00a72.2 is below note \nthe list-lifted usage of the is_v_of_t predicate, and the list appends (++) in the conclusion. (* reduce_Rec \n*) !(l _t _list:(label#t) list) (l_v_list:(label#t) list) (l:label) (t:t) (t :t) . ((EVERY (\\(l_,v_). \nis_v_of_t v_) l_v_list) /\\ (( reduce t t ))) ==> (( reduce (t_Rec (l_v_list ++ [(l,t)] ++ l _t _list)) \n(t_Rec (l_v_list ++ [(l,t )] ++ l _t _list)))) For the PROJ typing rule we need a speci.c projection \n(the HOL EL) to pick out the j th element: (* Ty_Proj *) !(l_Typ_list:(label#Typ) list) (j:index) (G:G) \n(t:t) . ((( Ty G t (T_Rec (l_Typ_list)) ))) ==> (( Ty G (t_Proj t ((\\ (l_,Typ_) . l_) (EL j l_Typ_list))) \n((\\ (l_,Typ_) . Typ_) (EL j l_Typ_list)))) For Coq, when translating away lists, we have to introduce \nyetmore list types for these proof assistant variables, in addition tothe obvious translation of symbolic \nterms, and, more substantially,to introduce additional inductive relation de.nitions to induct over them. \nAs outlined here, the analysis and code generation performed by ott is reasonably complex (the tool is \naround 17 000 lines ofOCaml). It is therefore quite possible that the generated code isnot what is intended, \neither because of soundness bugs in the tool(though none such are known at present) or through misunderstand\u00ading \nof its semantics, and one should not treat the tool as part of atrusted chain it is necessary in principle \nto look over the gen\u00aderated de.nitions. In any proof effort, however, one will have tobecome intimately \nfamiliar with those de.nitions in any case, sowe do not regard this as a problem.  5. Case Studies \nOur primary goal is to provide effective tool support for the work\u00ading semanticist. Assessing whether \nthis has been achieved needssubstantial case studies. Accordingly, we have speci.ed variouslanguages \nin ott, de.ning their type systems and operational se\u00admantics, as below. System rules LATEX Coq HOL Isabelle \ndefnmt defn mt defn mt untyped CBV lambda (Fig. 1) 3 . .. .. .. simply typed CBV lambda 6 ML polymorphism \n22 . .. .. .. TAPL full simple 63 POPLmark F<: with records 48 . Leroy JFP96 module system 67 .. . .. \nRG-Sep language 22 2 Mini-Ott-in-Ott 55 LJ: Lightweight Java 34 .. (3) LJAM: Java Module System 140 .. \n... 1 OCaml fragment 306 1 see below. 2 hand proofs. 3 in progress. These range in scale from toy calculi \nto a large fragment of OCaml.They also vary in kind: some are post-facto formalizations of ex\u00adisting \nsystems, and some use ott as a tool in the service of other research goals. For most we use the tool \nto generate de.nitions in one or more of Coq, HOL, and Isabelle, indicated by the ticks inthe defn columns \nbelow, together with the typeset LATEX. We have tested whether these de.nitions form a good basis for \nmechanizedproof by machine-checked proofs of metatheoretic results (gener\u00adally type preservation and \nprogress), indicated by ticks in the mt grammar t :: Tm ::= {{ com terms: }} |letx=tint ::::Let (+bind \nxin t +) {{ com let binding }} defns Jop :: ::= defn t --> t :: :: red :: E {{ com Evaluation }} by \n -----------------------------:: LetV let x=v1 in t2 --> [x|->v1]t2 t1 --> t1 ----------------------------------:: \nLet let x=t1 in t2 --> let x=t1 in t2 defns Jtype :: ::= defn G |-t : T :: :: typing :: T {{ com \nTyping }} by G |-t1:T1 G,x:T1 |-t2:T2 ------------------------:: Let G |-let x=t1 in t2 : T2 Figure \n7. An ott source .le for the let fragment of TAPL columns below. The rules column gives the number of \nseman\u00adtic rules in each system, as a crude measure of its complexity. Thesources, generated code, and \nproof scripts for most of these systemsare available (Sewell and Zappa Nardelli 2007). TAPL full simple \nThis covers most of the simple features, upto variants, from TAPL (Pierce 2002). It demonstrates the \nutil\u00adity of a very simple form of modularity provided by ott, allow\u00ading clauses of grammars and semantic \nrelations to be split be\u00adtween .les. The original TAPL languages were produced using Tin\u00adkerType (Levin \nand Pierce 2003) to compose features and checkfor con.icts. Here we build a system, similar to the TinkerType \nsys-fullsimple, from ott source .les that correspond roughlyto the various TinkerType components, each \nwith syntax and se\u00admantic rules for a single feature. The ott source for let is shown in Fig. 7, to which \nwe add: bool, bool typing, nat, nat typing, arrow typing, basety, unit, seq, ascribe, product, sum, fix, \ntuple, and variant, togther with infrastructure common, common index, common labels, and common typing. \nIt also proved easy to largely reproduce the TAPL visual styleand (though we did no proof) to add subtyping. \nLeroy JFP96 module system This formalizes the path-based type system of Leroy (1996, \u00a74), extended with \na term languageand an operational semantics. RG-Sep language This is a concurrent while language used \nforongoing work combining Rely-Guarantee reasoning with Separa\u00adtion Logic, de.ned and proved sound by \nVafeiadis and Parkinson(2007). Mini-Ott-in-Ott This precisely de.nes the ott binding speci\u00ad.cations (without \nlist forms) with their fully concrete representa\u00adtion and alpha equivalence. The metatheory here is a \nproof that forclosed substitutions the two coincide. To date only a hand proof hasbeen completed; we \nplan to mechanize it in due course. LJ and LJAM LJ, by Strnisa and Parkinson, is an imperative. fragment \nof Java. LJAM extends that (again using ott modularity)with a formalization of the core part of JSR-277 \nand a proposalfor JSR-294, which together form a proposal for a Java modulesystem (Strnisa et al. 2007).. \nOCaml fragment This covers a substantial core of OCaml to a .rst approximation, all except subtyping, \nobjects, and mod\u00adules. Notable features that are handled are: ML-style polymor\u00adphism; pattern matching; \nmutable references; .niteness of the in\u00adteger type; generative de.nitions of record and variant types; \nandgenerative exception de.nitions. It does not cover much of the stan\u00addard library, mutable records, \narrays, pattern matching guards, la\u00adbels, polymorphic variants, objects, or modules. We have tried to \nmake our de.nition mirror the behaviour of the OCaml system rather closely. The OCaml manual (Leroy et \nal.2005) de.nes the syntax with a BNF; our syntax is based on that.It describes the semantics in prose; \nour semantics is based on acombination of that and our experience with the language. Experience Our experience \nwith these examples has been verypositive. The tool does make it easy to work with these de.nitions,allowing \none to focus on the content rather than the proof assistantor LATEX markup. We have not had to hand-edit \nthe Ott output. For our most substantial example, the OCaml fragment, we haveproved type preservation \nand progress for the expression language,all machine-checked in HOL. The need for alpha-equivalence\u00adaware \nreasoning arises only for type variables and type schemes.We use a de Bruijn encoding of type variables \nto support the for\u00admal proof effort. Since Ott does not currently support the automaticgeneration of \nsuch representations, we deal directly with the indexshifting functions in the Ott source. This proof \neffort has taken onlyaround 3 man-months, and the preceeding de.nition effort was onlyanother few man-weeks. \nCompared with our previous experiencesthis is remarkably lightweight: it has been possible to develop \nthisas an example, rather than requiring a major research project inits own right. Apart from ott, the \nwork has been aided by HOL spowerful .rst-order reasoning automation and its inductive de.ni\u00adtion package, \nand by the use of the concrete representation. 6. Related Work As Strachey (1966) writes in the Proceedings \nof the .rst IFIPWorking Conference, Formal Language Description Languages: A programming language is \na rather large body of newand somewhat arbitrary mathematical notation introducedin the hope of making \nthe problem of controlling computingmachines somewhat simpler. and the problem of dealing precisely with \nthis notation, with theneed for machine support in doing so, has spawned an extensiveliterature, of which \nwe touch only on the most related points. The proof assistants that we build on, Coq, HOL, Isabelle, \nandTwelf, are perhaps the most directly related work (Coq; HOL; Is\u00adabelle; Twelf). Ever since original \nLCF (Milner 1972), one of themain intended applications of these and related systems has beenreasoning \nabout programs and programming languages, and theyhave been vastly improved over the years to make this \npossible. Re\u00adcently they have been used for a variety of substantial languages,including for example \nthe verifying compiler work of Blazy et al.(2006) (Coq), a C expression semantics by Norrish (1999) (HOL),work \non Java by Klein and Nipkow (2006) (Isabelle), and an inter\u00adnal language for SML by Lee et al. (2007) \n(Twelf). They are, how\u00adever, all more-or-less general-purpose tools by adding front-endsupport that \nis speci.c to the problem of de.ning programming lan\u00adguage syntax and semantics, we believe ott can signi.cantly \neasethe problems of working with large language de.nitions. Several projects have aimed at automatically \ngenerating pro\u00adgramming environments and/or compilers from language descrip\u00adtions, including early work \non the Synthesiser Generator (Repsand Teitelbaum 1984). Kahn s CENTAUR system (Borras et al.1988) supported \nnatural-semantics descriptions in the TYPOL lan\u00adguage, compiling them to Prolog for execution, together \nwith arich user interface including an editor, and a language METALto de.ne abstract and concrete syntax \n(Terrasse (1995) also con\u00adsidered compilation of TYPOL to Coq). Related work by Klint(1993) and colleagues \nproduced the ASF+SDF Meta-environment.Here SDF provides rich support for de.ning syntax, while ASF al\u00adlows \nfor de.nitions in an algebraic speci.cation style. Again it isa programming environment, with a generic \nsyntax-directed edi\u00adtor. The ERGO Support System (Lee et al. 1988) also had a stronguser-interface component, \nbut targeted (among others) ADT-OBJand .Prolog. Mosses s work on Action Semantics and ModularSOS (Mosses \n2002) has been supported by various tools, but makesstrong assumptions on the form of the semantic relations \nbeing de\u00ad.ned. Moving closer in goals to ott, ClaReT (Boulton 1997) tooka sophisticated description of \nsyntax and pretty printing, and a de\u00adnotational semantics, and generated HOL de.nitions. In contrast \nto the programming environments above, ott is a more lightweight stand-alone tool for de.nitions, designed \nto .tin with existing editing, LATEX and proof-assistant work.ows andrequiring less initial investment \nand commitment to use. (Its sup\u00adport for production parsing and pretty printing is less developedthan \nseveral of the above, however.) Moreover, in contrast to CEN-TAUR and to research on automatic compiler \ngeneration, ott is not focussed on producing executable de.nitions one can de\u00ad.ne arbitrary semantic \nrelations which may or may not be algorith\u00admic. The generality of these arbitrary inductive relation \nde.nitionsmeans that ott should be well-suited to much present-day seman\u00adtics work, for type systems \nand/or operational semantics. PLTredex (Matthews et al. 2004) is a domain-speci.c languagefor expressing \nreduction relation de.nitions and animating them.It is currently being used on a full-language scale, \nfor an R6RSScheme de.nition (Findler and Matthews 2007), but is by de\u00adsign restricted to animation of \nreduction semantics. The Ruler sys\u00adtem (Dijkstra and Swierstra 2006) provides a language for express\u00ading \ntype rules, generating LATEX and implementations but not proofassistant de.nitions, used for a Haskell-like \nlanguage. Turning to direct support for binding, Twelf is suited to HOASrepresentations. FreshML (Shinwell \net al. 2003), Alpha Prolog (Ch\u00adeney and Urban 2004) and MLSOS (Lakin and Pitts 2007) both usenominal \nlogic-and functional programming approaches, the lattertwo with a view to prototyping of semantics. C.ml \n(Pottier 2006)is the most substantial other work we are aware of that introduces a large and precisely \nde.ned class of binding speci.cations, fromwhich it generates OCaml code for type de.nitions and substitu\u00adtions. \nTypes can be annotated with sets of atom sorts, with occur\u00adrences of atoms of those sorts treated as \nbinding within them. inner and outer annotations let one specify that subterms are either insideor outside \nan enclosing binder. This seems to us less intuitive thanthe ott binding speci.cations. We conjecture \nthat the two have mutually incomparable expressiveness. Representing binding within proof assistants \nwas a key aspectof the POPLmark challenge (Aydemir et al. 2005), and severalcomparisons have been produced, \nincluding those of Aydemir et al.(2007) and Berghofer and Urban (2006). Owens (1995) discussespattern \nbinding using locally nameless representations in Isabelle. The work on concise concrete syntax by Tse \nand Zdancewic(2006) has similar lightweight syntax de.nition goals to ott, tak\u00ading a concise description \nof a grammar but producing the conven\u00adtional object-language parsing and pretty printing tools. It is \ninteresting to contrast our OCaml fragment example withattempts to verify aspects of the SML De.nition. \nEarly attempts,by Syme (1993), VanInwegen (1996), and Gunter and Maharaj(1995), faced severe dif.culties, \nboth from the mathematical styleof the De.nition and the limitations of HOL at the time whereas, using \nott and HOL 4, we have found our example reasonably straightforward. Lee et al. (2007) take a rather \ndifferent approach.They factor their (Twelf) de.nition into an internal language, and(yet to appear) \na substantial elaboration from a source languageto that. They thus deal with a much more sophisticated \ntype theory(aimed at supporting source features that we do not cover, includingmodules), so the proof \neffort is hard to compare, but their semantic rules are further removed from source-language programs. \n 7. Conclusion Summary We have introduced the ott metalanguage and toolfor expressing semantics, incorporating \nmetalanguage design tomake de.nitions easy to read and edit, a novel and expressivemetalanguage for expressing \nbinding, and compilation to multipleproof assistants. We hope that this work will enable a phase change: \nfrom thecurrent state, in which working with fully-rigorous de.nitions ofreal programming languages requires \nheroic effort, to a world inwhich that is routine. The ott tool can be used in several different ways. \nMost sim\u00adply, it can aid informal LATEX mathematics, permitting de.nitions,and terms in proofs and exposition, \nto be written without syntac\u00adtic noise. By parsing (and so sort-checking) this input it quicklycatches \na range of simple errors, e.g. inconsistent use of judgementforms. There is then a smooth path to fully-rigorous \nproof assis\u00adtant de.nitions: those ott de.nitions can be annotated with the additional information required \nto generate proof assistant code. Ingeneral one may also want to restructure the de.nitions to suit theformalization. \nOur experience so far suggests this is not a majorissue, and hence that one can avoid early commitment \nto a par\u00adticular proof assistant. The tool can be used at different scales: itaims to be suf.ciently \nlightweight to be used for small calculi, butit is also designed and engineered with the pragmatics of \nworkingwith full-scale programming languages in mind. Our case studiessuggest that it achieves both goals. \nFurthermore, we hope it willmake it easy to re-use de.nitions of calculi and languages, andalso fragments \nthereof, across the community. Widely accepted defacto standard de.nitions would make it possible to \ndiscuss pro\u00adposed changes to existing languages in terms of changes to thosede.nitions, rather than solely \nin terms of toy calculi. Future work There are many interesting directions for futurework. First, while \nthe fully concrete representation of binding issurprisingly widely applicable, it is far from expressing \nall onewould like to do. We plan to explore proof assistant representationsfor arbitrary binding speci.cations, \nas outlined in \u00a73.2. Another mathematical question is to consider in what sense the de.nitions ott generates \nfor the different target proof assistants have the samemeaning. This is intuitively plausible, but the \ntargets are based ondifferent logics, so it is far from trivial. The Twelf code generation remains to \nbe completed, and a num\u00adber of other features would be useful: support for function de.ni\u00adtions (not \njust inductive relations); support for contexts, with auto\u00admatically generated context application and \ncomposition functions;support for generating multiple overlapping languages from a sin\u00adgle source (e.g. \nsugared and non-sugared); and generation of pro\u00adduction parsers. With more experience using the tool, \nwe aim also to polishthe generated proof-assistant de.nitions and improve the availableproof automation \n for example, to make proof scripts less depen\u00addent on the precise structure and ordering of the de.nitions. \nBeing able to easily generate de.ntions for multiple proof as\u00adsistants also opens up new possibilities \nfor (semi-)automaticallytesting conformance between semantic de.nitions and produc\u00adtion implementations, \nabove the various proof assistant support for proof search, tactic-based symbolic evaluation, code extractionfrom \nproofs, and code generation from de.nitions. Finally, we look forward to further experience and user \nfeed\u00adback from the tool. Acknowledgements We thank the other members of the POPLmark team, especially \nBenjamin Pierce, Stephanie Weirich and Steve Zdancewic, for interesting discussions on this work, James \nLeifer for comments on a draft, our early adopters for user feedback, and Keith Wansbrough, Matthew Fairbairn \nand Tom Wilkie for their work on various ott predecessors. We acknowledge the support of EPSRC grants \nGR/T11715 and EP/C510712, and a Royal Society University Research Fellowship (Sewell).  References \nAFP. The archive of formal proofs. http://afp.sf.net. B. Aydemir, A. Chargu\u00b4 eraud, B. C. Pierce, R. \nPollack, and S. Weirich. Engineering formal metatheory, 2007. http://www.chargueraud. org/arthur/research/2007/binders/. \nB. E. Aydemir, A. Bohannon, M. Fairbairn, J. N. Foster, B. C. Pierce, P. Sewell, D. Vytiniotis, G. Washburn, \nS. Weirich, and S. Zdancewic.Mechanized metatheory for the masses: The POPLmark Challenge. InProc. TPHOLs, \nLNCS 3603, 2005. S. Berghofer and C. Urban. A head-to-head comparison of de Bruijn indices and names. \nIn Proc. Int. Workshop on Logical Frameworks and Meta-Languages: Theory and Practice, pages 46 59, 2006. \nS. Blazy, Z. Dargaye, and X. Leroy. Formal veri.cation of a C compiler front-end. In Int. Symp. on Formal \nMethods, LNCS 2085, 2006. P. Borras, D. Clement, T. Despeyroux, J. Incerpi, G. Kahn, B. Lang, and V. \nPascual. Centaur: the system. In Proc. SDE 3, pages 14 24, 1988. R. J. Boulton. A tool to support formal \nreasoning about computer lan\u00adguages. In Proc. TACAS, LNCS 1217, pages 81 95, 1997. A. Chargu\u00b4eraud. Annotated \nbibliography for formalization of lambda-calculus and type theory. http://fling-l.seas. upenn.edu/.plclub/cgi-bin/poplmark/index.php?title= \nAnnotated Bibliography, July 2006. J. Cheney and C. Urban. Alpha-Prolog: A logic programming language \nwith names, binding and alpha-equivalence. In Proc. ICLP, LNCS 3132, pages 269 283, 2004. Coq. The Coq \nproof assistant, v.8.0. http://coq.inria.fr/. A. Dijkstra and S. D. Swierstra. Ruler: Programming type \nrules. In Proc. Functional and Logic Programming, LNCS 3945, 2006. R. B. Findler and J. Matthews. Revised5.92 \nreport on the algorithmic language Scheme, Chapter 10, Formal Semantics, Jan. 2007. C. Fournet, G. Gonthier, \nJ.-J. L\u00b4evy, L. Maranget, and D. R\u00b4emy. A calculus of mobile agents. In Proc. CONCUR 96, LNCS 1119, 1996. \nE. Gunter and S. Maharaj. Studying the ML module system in HOL. The Computer Journal: Special Issue on \nTheorem Proving in Higher Order Logics, 1995. HOL. The HOL 4 system, Kananaskis-3 release. http://hol. \nsourceforge.net/. Isabelle. Isabelle 2005. http://isabelle.in.tum.de/. M. Johnson. Memoization in top-down \nparsing. Comput. Linguist., 21(3): 405 417, 1995. S. Kahrs. Mistakes and ambiguities in the de.nition \nof Standard ML. Technical Report ECS-LFCS-93-257, University of Edinburgh, 1993. G. Klein and T. Nipkow. \nA machine-checked model for a Java-like lan\u00adguage, virtual machine, and compiler. TOPLAS, 28(4):619 695, \n2006. P. Klint. A meta-environment for generating programming environments.ACM Trans. on Soft. Eng. and \nMethodology, 2(2):176 201, April 1993. M. R. Lakin and A. M. Pitts. A metalanguage for structural operational \nsemantics. In Symposium on Trends in Functional Programming, 2007. D. K. Lee, K. Crary, and R. Harper. \nTowards a mechanized metatheory of Standard ML. In Proc. POPL, January 2007. P. Lee, F. Pfenning, G. \nRollins, and W. Scherlis. The Ergo Support System: An integrated set of tools for prototyping integrated \nenvironments. InProc. SDE 3, 1988. X. Leroy. A syntactic theory of type generativity and sharing. Journal \nof Functional Programming, 6(5):667 698, 1996. X. Leroy et al. The Objective Caml system release 3.09 \ndocumentation and user s manual, Oct. 2005. M. Y. Levin and B. C. Pierce. Tinkertype: A language for \nplaying with formal systems. Journal of Functional Programming, 13(2), Mar. 2003. J. Matthews, R. B. \nFindler, M. Flatt, and M. Felleisen. A visual environment for developing context-sensitive term rewriting \nsystems. In Proc. RTA, 2004. R. Milner. Implementation and applications of Scott s logic for computable \nfunctions. In Proc. ACM conference on Proving assertions about pro\u00adgrams, pages 1 6, 1972. R. Milner, \nM. Tofte, and R. Harper. The De.nition of Standard ML. MIT Press, 1990. P. D. Mosses. Pragmatics of Modular \nSOS. In Proc. AMAST, LNCS 2442, pages 21 40, 2002. M. Norrish. Deterministic expressions in C. In Proc. \n8th ESOP (ETAPS), LNCS 1576, pages 147 161, 1999. C. Owens. Coding binding and substitution explicitly \nin Isabelle. In Proceedings of the First Isabelle Users Workshop, pages 36 52, 1995. S. Owens and M. \nFlatt. From structures and functors to modules and units. In Proc. ICFP, 2006. S. Peyton Jones, editor. \nHaskell 98 Language and Libraries. The Revised Report. CUP, 2003. B. C. Pierce. Types and Programming \nLanguages. MIT Press, 2002. F. Pottier. An overview of C.ml. In ACM Workshop on ML, ENTCS 148(2), pages \n27 52, Mar. 2006. T. Reps and T. Teitelbaum. The synthesizer generator. In Proc. SDE 1, pages 42 48, \n1984. A. Rossberg. Defects in the revised de.nition of Standard ML. Technicalreport, Saarland University, \n2001. Updated 2007/01/22. P. Sewell and F. Zappa Nardelli. Ott, 2007. http://www.cl.cam.ac.uk/ users/pes20/ott/. \nP. Sewell, J. J. Leifer, K. Wansbrough, M. Allen-Williams, F. Zappa Nardelli, P. Habouzit, and V. Vafeiadis. \nAcute: High\u00adlevel programming language design for distributed computation. design rationale and language \nde.nition. Technical Report UCAM-CL-TR\u00ad605, University of Cambridge Computer Laboratory, Oct. 2004. See \nalso the ICFP 05 paper. M. R. Shinwell, A. M. Pitts, and M. J. Gabbay. FreshML: Programming with binders \nmade simple. In Proc. ICFP, 2003. C. Strachey. Towards a formal semantics. In Formal Language Description \nLanguages for Computer Programming. North Holland, 1966. R. Strnisa, P. Sewell, and M. Parkinson.. The \nJava Module System: core design and semantic de.nition. In Proc. OOPSLA, 2007. To appear. D. Syme. Reasoning \nwith the formal de.nition of Standard ML in HOL. InTPHOLs, LNCS 780, pages 43 59, 1993. D. Terrasse. \nEncoding Natural Semantics in Coq. In Proc. AMAST, LNCS 936, pages 230 244, 1995. S. Tse and S. Zdancewic. \nConcise concrete syntax, 2006. Submitted. http://www.cis.upenn.edu/.stse/javac. Twelf. Twelf 1.5. http://www.cs.cmu.edu/.twelf/. \nV. Vafeiadis and M. Parkinson. A marriage of rely/guarantee and separation logic. In Proc. CONCUR, 2007. \nM. VanInwegen. The Machine-Assisted Proof of Programming Language Properties. PhD thesis, Univ. of Pennsylvania, \n1996. Computer and Information Science Tech Report MS-CIS-96-31. \n\t\t\t", "proc_id": "1291151", "abstract": "<p>It is rare to give a semantic definition of a full-scale programming language, despite the many potential benefits. Partly this is because the available <i>metalanguages</i> for expressing semantics - usually either L<sup>&lt;scp&gt;a&lt;/scp&gt;</sup>T<sub>E</sub>X for informal mathematics, or the formal mathematics of a proof assistant - make it much harder than necessary to work with large definitions.</p> <p>We present a metalanguage specifically designed for this problem, and a tool, ott, that sanity-checks such definitions and compiles them into proof assistant code for Coq, HOL, Isabelle, and (in progress) Twelf, together with L<sup>&lt;scp&gt;a&lt;/scp&gt;</sup>T<sub>E</sub>X code for production-quality typesetting, and OCaml boilerplate. The main innovations are:(1) metalanguage design to make definitions concise, and easy to read and edit;(2) an expressive but intuitive metalanguage for specifying binding structures; and (3) compilation to proof assistant code.</p> <p>This has been tested in substantial case studies, including modular specifications of calculi from the TAPL text, a Lightweight Java with Java JSR 277/294 module system proposals, and a large fragment of OCaml (around 306 rules), with machine proofs of various soundness results. Our aim with this work is to enable a phase change: making it feasible to work routinely, without heroic effort, with rigorous semantic definitions of realistic languages.</p>", "authors": [{"name": "Peter Sewell", "author_profile_id": "81100511814", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "PP14177906", "email_address": "", "orcid_id": ""}, {"name": "Francesco Zappa Nardelli", "author_profile_id": "81100512653", "affiliation": "INRIA, Rocquencourt, France", "person_id": "PP38032228", "email_address": "", "orcid_id": ""}, {"name": "Scott Owens", "author_profile_id": "81337492133", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "PP37043683", "email_address": "", "orcid_id": ""}, {"name": "Gilles Peskine", "author_profile_id": "81337492671", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "PP37043738", "email_address": "", "orcid_id": ""}, {"name": "Thomas Ridge", "author_profile_id": "81322504917", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P900688", "email_address": "", "orcid_id": ""}, {"name": "Susmit Sarkar", "author_profile_id": "81392603911", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P900687", "email_address": "", "orcid_id": ""}, {"name": "Rok Strni&#353;a", "author_profile_id": "81318491338", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P806635", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1291151.1291155", "year": "2007", "article_id": "1291155", "conference": "ICFP", "title": "Ott: effective tool support for the working semanticist", "url": "http://dl.acm.org/citation.cfm?id=1291155"}