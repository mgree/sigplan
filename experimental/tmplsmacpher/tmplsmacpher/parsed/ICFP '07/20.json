{"article_publication_date": "10-01-2007", "fulltext": "\n Experience Report: Using Functional Programming to Manage a Linux Distribution Clifford Beshers David \nFox Jeremy Shaw Linspire, Inc. {cli.|david|jeremy}@linspire.com Abstract We report on our experience \nusing functional programming lan\u00adguages in the development of a commercial GNU/Linux distribu\u00adtion, discussing \nfeatures of several signi.cant systems: hardware detection and system con.guration; OS installer CD creation; \npack\u00adage compilation and management. Static typing helps compensate for the lack of a complete testing \nlab and helps us be effective with a very small team. Most importantly, we believe that going beyond \nmerely using functional languages to using purely functional de\u00adsigns really helps to create simple, \neffective tools. Categories and Subject Descriptors K.8.3 [Personal Comput\u00ading]: Management/Maintenance; \nD.1.1 [Programming Techniques]: Applicative (Functional) Programming; D.4.9 [Operating Sys\u00adtems]: Systems \nPrograms and Utilities 1. Introduction Linspire, Inc. makes a Linux distribution targeted to the general \nconsumer. The operating system installer is simple and fast with almost no options, the desktop is precon.gured \nwith a small, rep\u00adresentative set of applications, and is precon.gured to open every common .letype found \non the internet with a suitable program. An automated hardware detector takes care of most system con.gura\u00adtion. \nCNR, a client program that connects to a web-based software repository, allows the user to install applications \nwith a single click. Our goal is to tailor GNU/Linux to provide general desktop com\u00adputing to those with \nlittle or no knowledge of shells, compilers, kernels, drivers and packages. Most open source projects \ntake a very different approach. They aim for the maximum in .exibility, assuming users have a good grasp \nof the computing architecture and are willing to spend signif\u00adicant time customizing their software con.gurations. \nThis is espe\u00adcially noticeable when something goes wrong and some program will spit out a cryptic message \nin an obscure log .le about contact\u00ading your system administrator. Our goal is to get to the point where \nno system administrator is needed. Desktop computers should become more like appliances with no need \nto service the core software. To that end, we use functional programming languages and general functional \nmethods to improve our ef.ciency and reliability. Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. ICFP 07, October 1 3, 2007, Freiburg, Germany. Copyright c &#38;#169; \n2007 ACM 978-1-59593-815-2/07/0010. . . $5.00 The use of functional programming at Linspire was the choice \nof a few key developers in the operating systems group, mostly to build internal development tools, but \nwe have also bene.tted from using functional languages in the hardware detection and system con.guration \nsoftware. In fact, at one time we put much of the O Caml run-time into the initial ramdisk, the minimal \n.lesystem used by the kernel during the boot process. Where others have chosen shell programming or scripting \nin Perl and Python, we have chosen either O Caml or Haskell, with all ongoing work in Haskell. We have \nnot done any formal work with software metrics, but none of us will volunteer for work in any other language, \nalthough we still occasionally create small shell scripts because that idiom is so ingrained. Some of \nthe biggest engineering challenges in this project in\u00adclude: con.guring a Linux system without any input \nfrom the user;  building OS installer CD images;  integrating parallel development streams, our own \nand those of the upstream developer(s);  managing multiple software repositories and their derivatives. \n In each of these projects, we have seen direct bene.ts from us\u00ading functional languages, but we have \nalso had to work hard to de\u00advelop new styles of system programming, both to replace the con\u00advenience \nof shells and to extend the rigor of functional program\u00adming out to the .le system. Fortunately, more \nthan just providing good language features, functional methods have provided patterns for solutions at \nthe broader scope of .le and package management. We have taken the lessons learned in functional programming \nand extended them outward.  2. Functional Development Toolchain The next natural question is whether \nthe hard work of developing new programming styles has been worth the effort. To evaluate this, we must \n.rst introduce our main applications in more detail. We use functional programming in many small tasks, \nbut there are three large applications that are central to our operation: the autobuilder creates new \npackage archives by checking out source packages, assembling clean chroot environments with all the nec\u00adessary \nbuild dependencies, compiling all packages affected by re\u00adcent changes, and then uploading the new package \narchive to a cen\u00adtral server; the CD builder creates an ISO 9660 CD image that can be booted directly \nfrom CD (live) and used to install our operating system. Each run of the CD builder fetches roughly 600 \npackages, unpacks them, then repacks the resulting tree into a compressed loopback .le, which is in turn \nwrapped up in a CD image; the hard\u00adware detector (or just detector) runs as the operating system boots, \nnotices any changes in hardware con.guration, and updates driver and system con.guration .les accordingly. \nThe autobuilder is the newest and is written in Haskell. The CD builder and the detector are written \nin O Caml, largely because we did not feel that Haskell was ready at the time they were started. Our \ndevelopment cycle depends heavily on all three applica\u00adtions. All developers build packages with the \nautobuilder and most are then pulled in by the CD builder and our testers install the OS on a variety \nof hardware, where the detector con.gures the drivers. Thus, both the speed and reliability of these \napplications is impor\u00adtant to us, since any failure blocks the work of the entire group. Additionally, \nour customers rely directly on the robustness of the detector, because it stands between them and a functioning \ndesktop environment. The CD image takes over half an hour to make and perhaps .f\u00adteen minutes to burn \nand install, putting a signi.cant pause between development and testing. We do have shortcuts to this \nprocess, but ultimately we have to test everything just as the user experiences it. There is nothing \nmore demoralizing than waiting this long only to discover a syntax error in a shell script has broken \nthe build. We know because our OS installer application is a C++ GUI that in\u00advokes two shell scripts \nto do the installation. Originally small and easy to manage, these scripts have grown large and cumbersome, \nand the smallest change in them can cause widespread failures. A bug in the detector can have the same \ndetrimental impact, but O Caml s static typing helps .lter out many obvious errors. Also, the authors \nsplit their time between developing these tools and working on other operating system features. Fixing \none of these applications when it is blocking everyone s work is quite stressful. We use functional programming \nlanguages and techniques to build them because we believe it gives us the best chance of avoiding breakdowns. \nOur motto has become, The right way is the fast way. Failures in the development chain do not just slow \nus down, they are very demoralizing. Whenever we get a pause in the action, we put the time into applying \nfunctional methods to make our tools more reliable. We have not attempted to make any careful measurements \nof the time and cost bene.ts, as that is never part of our project plan. Ultimately, we are charged by \nmanagement with the job of creating an unusual Linux distribution with a very small group, we (speci.cally, \nthe authors) chose functional programming as the best means of leveraging our experience. Other engineers \nat our company questioned our choice as being non-standard, requiring re-implementation of existing solutions, \nand hard for others to understand and maintain. The discussion was ultimately ended by our CEO, who judged \nthat we should use whatever tools we deemed appropriate, because our group had always delivered the requested \nproducts on time. We conclude that functional programming is certainly no worse than other approaches \nand the authors are .rmly convinced that it is better and gaining ground. The rest of this section is \ndevoted to demonstrating speci.c functional techniques that we use to im\u00adprove the effectiveness and \nreliability of our code. 2.1 Language Features Our application of functional programming has been quite \ndifferent to the typical use. Mostly, we have written what amount to large scripts, reading in some extended \nstate from the .le system and building a new object to be placed back on the .le system, often invoking \nmany external programs in the process. Most textbooks on functional programming end where our work begins, \nso we must break a lot of trail. As a result, we have made many mistakes and some of our programs have \nbeen hard to read, hard to use and completely unreliable. Merely using functional languages does not \nmagically ensure any kind of program quality. instaneShow DebVersion where show (DebVersion s_) =s instaneEq \nDebVersion where (DebVersion _ v1) == (DebVersion _ v2) = v1== v2 instaneOrd DebVersion where compare \n(DebVersion _ v1) (DebVersion _ v2) = compare v1 v2 Figure 1. De.ning Eq and Ord instances of DebVersion \nTo be sure, we have bene.tted directly from many of the oft\u00adtouted features of functional programming. \nHaskell s type class mechanism is one of our favorites. Type classes allow us to ex\u00adtend families of \nfunctions to support new data types we create. For example, the Eq classes provides functions for testing \nequality, and the Ord classes provides functions for testing ordering. We created a new data type, DebVersion, \nwhich represents a Debian version number. The Debian version policy is extremely complicated (Jack\u00adson \nand Schwarz 1996), requiring roughly 250 lines of Haskell to implement a parser and comparison function. \nHowever, once we have added Eq and Ord instances for DebVersion, we can use a wealth of library functions \nwithout writing any additional code. This includes simple functions, such as >=, more complex func\u00adtions, \nsuch as sort, and entirely functional data structure libraries, such as dictionary library Data.Map. \nIn Haskell, there is no pref\u00aderential treatment of standard data-types over user de.ned types. So, we \ncan use our new DebVersion data as naturally as Int or String. Adding Show gives us the visible parts \nof the type, which can be trivially used with the standard Haskell library functions: Note that we have \nnot made DebVersion a type synonym for String, as is done with FilePath in the Haskell libraries. Debian \nencodes all of its meta-data as strings in RFC822, the mail header format, making it very easy to mistake \none type for another. Our goal is always to make our types as speci.c as possible, so that we never inadvertently \nuse values in the wrong way, such as comparing DebVersion values with a standard String comparison. Our \noriginal implementation was an external call to the Debian dpkg command, something like this: debian_compare \nv1 v2 = do system (\"dpkg --compare-versions \" ++ v1++ \"lt \" ++ v2) While this did have the advantage \nof being quick to implement, it could be mistakenly applied to strings that were not actually Debian \nversion numbers, it required the IO monad even though it is effectively a pure function, and the implementation \nhas the wrong type to use with functions that require Eq and Ord. All these limitations can be overcome: \nreplacing the inputs with amorespeci.c DebVersion type with the strings embedded inside, using a lower \nlevel process creation command that does not invoke a shell, using unsafePerformIO to take it out of \nthe IO monad, and adding code to convert the process return status into the Ordering value. This is exactly \nthe approach taken in (Goerzen 2006) when implementing this function. The interfaces for our implementation \nand Goerzen s are effectively identical and both are quite reliable. The remaining differences represent \na tradeoff in speed (ours) versus standardization (Goerzen s ensures exact compatibility with Debian \ns implementation.) However, the larger problem remains. When interfacing with shell programs, it is natural \nto want to use shell idioms, which are concise and ubiquitous. The use of dpkg above makes good sense. \nBut in reviewing our own code, we found the following fragments in the same (O Caml) source .le, only \na few lines from each other: lettouch file = Sh.run (\"touch \" ^ file) letfname = \"tmp/.status.empty\" \nin let_= Sh.run (\"cat /dev/null >\" ^ fname) in fname These are not exactly equivalent (touch won t zero \nout the .le), but our usage indicates that we were thinking they were at the time. Both of these could \nhave been better written using native O Caml. Clearly the old ways die hard. It takes discipline to avoid \ncode like this, and experience and a non-trivial understanding of Haskell s type and IO system to produce \ncode like DebVersion, especially under time pressure. In the following sections we give examples of programming \nstyles that we are adopting to make systems programming enjoy the same rigor as in-memory code while \nbeing as convenient to use as shell idioms. 2.2 Expressing computations on .les The CD builder started \nout life as a shell script. After several iterations it grew too large and hard to read, so we rewrote \nit in O Caml. In the process, we started developing a style for scripting that looked more functional. \nWe observed that the shell implementation was full of com\u00admands with their output directed to temporary \n.les. These .les linked all the computations together, but there was no infrastruc\u00adture that recognized \nand exploited that information. In the O Caml rewrite, we adopted a convention of passing in the temporary \n.le name as the .rst argument to a function and having that function return that name (or perhaps a new \n.lepath derived from the given) as the result. For example, this function packs a .le tree into a SquashFS \nimage .le: letcreate_squashfs image_path tree = lettmpfile = \"squashfs.out\" in letcmd = \"chroot \" ^ tree \n^ \" mksquashfs . \" ^ tmpfile ^ \" ; mv \" ^ (tree ^/^ tmpfile) ^ \" \" ^ image_path in let_= Sh.run cmd in \nimage_path The reliance on untyped shell calls is still present in this code, but the encapsulation \nrepresents an important improvement. Instead of a linear series of actions with implicit connections, \nwe now could write functions with let statements linking external computations together, but which looked \nlike pure functional programming: letmake_cd cd_image tree = letsquashfs_name = \"live.squashfs\" in letsquashfs_image \n= create_squashfs squashfs_name tree in ... cd_image This small change provided an important psychological \nshift away from shell scripting and towards functional programming. Not only was this form more readable, \nthe code was now in a form where it was easier to apply lessons learned and adapted from the functional \nprogramming literature. Our goal was to optimize the run time and, taking a lesson from static type checking, \nminimize the time it took to .nd obvious .aws. To do that, we needed to split operations into multiple \nparts and reorder them. Having the data dependencies represented in the let statements was a great help, \nas the compiler would complain if a reordering was invalid. For example, we originally installed packages \nin several phases, each time running Debian s apt program to do all the work. We re\u00adalized that each \nof these phases really had three steps: dependency checking; package download; and package installation. \napt does support doing those operations independently, but it is not triv\u00adial to do so and quite a bit \nof information must be stored in .les and passed between each invocation. It was only after moving to \nO Caml that we actually succeeding in doing so. The time to build CD images was reduced by about thirty \nmin\u00adutes, which was almost half, but even more importantly, missing packages or broken package dependencies, \nwhich are the most common errors, now caused the build to fail almost immediately. Still, we looked for \nmore concise expressions and more reliabil\u00adity. The expressions in the previous section are only loosely \ntyped and the nested let statements all begin to look alike after a while. We started work on an improved \nstyle, this time in Haskell, trying to leverage the enhanced power and readability of the IO monad. The \nresult was the DualForm class. 2.3 DualForm The DualForm type is the beginnings of a replacement for \nthe convenience of shell pipes with type-safe monadic operations that encapsulate the mechanics of moving \ndata between memory and disk. They are containers that provide their contents on demand in the form requested \n(disk or memory) and functions of the form (DualForm a) . IO (DualForm b) can be bound (>>=) together \nto form complex computations. The source is shown in Figure 2. There are two ways to create a DualForm \nvalue: from a FilePath (newDFFromFP); or from a value in memory (newDFFromValue). Regardless of which \nform was used during construction, the con\u00adtents of that DualForm may be retrieved as a value in memory \n(asValue) or as an object on disk (asFile). Any transfer required between memory and disk is handled \nby the DualForm functions using IORefsand the FileFormat class. This transfer happens only once, when \nthe value is .rst demanded in the form that was not used during construction. All types contained in \nDualForms must support the FileFormat operations toFF and fromFF. These are roughly the equivalent of \nRead and Show, but an alternate interface is provided for .exibility. In addition, all FilePaths are \nbe wrapped in the File type, which uses phantom typing to keep track of the type of the .le s contents. \nImagine that you have several operations to perform on an image .le, some of which are done with other \nprograms, some of which are native Haskell functions. If each of these operations is lifted to the DualForm,using \nasFile and asValue as appropriate to get values in the form they need, then you can compose them together \nseamlessly using bind. For example, you might have: newDFFromFile imageFile >>= rotate 90 >>= darken \n>>= (asFile newImageFile) We are still experimenting with this type of composition, but so far it seems \nelegant and easy to use. Once we build some serious examples, we expect we will be able to deploy it \nwidely in our autobuilder.  2.4 Working with Processes To avoid using untyped shell calls, we need good \nnative tools for working with processes and it is essential that these tools be able to deal with data \nlazily. For example, the autobuilder must fork compilation processes and .lter the entire output. The \nDebian package infrastructure can be challenging to work with, because it is a large, loosely-de.ned \ndata structure spread across many .les with a wide variety of data formats to parse and interpret. Reading \nall this information into memory at once simply does not work. ... importqualified Data.ByteString as \nB dataDualForm a= DualForm (IORef (Maybe FilePath)) (IORef (Maybe a)) lassFileFormat a where toFF :: \na. String fromFF :: String .a data File a= File FilePath derivingShow asFile::(FileFormat a) => FilePath \n. DualForm a . IO (File a) asFile baseName (DualForm fpRef vRef) = domfp . readIORef fpRef asemfp of \n(Just fp) . return (File fp) Nothing . domv . readIORef vRef asemv of Nothing . error \"empty DualForm\" \n(Just v) . let fp = baseName in dowriteFile fp (toFF v) writeIORef fpRef (Just fp) return (File fp) newDFFromFP \n:: (FileFormat a) => FilePath . IO (DualForm a) newDFFromFP fp = dofpRef . newIORef (Just fp) vRef . \nnewIORef Nothing return $ DualForm fpRef vRef asValue :: (FileFormat a) => DualForm a. IO a newDFFromValue \n:: (FileFormat a) =>a . IO (DualForm a) Figure 2. Source for the DualForm class. Functions asValue and \nnewDFFromValue were omitted due to space constraints, but have similar forms to asFile and newDFFromFP \nrespectively. Unfortunately, working with POSIX processes can be tricky. A process will block if either \nthe stdout or stderr buffers become full, therefore one cannot blindly wait for a return code while ignoring \nthe output. For the same reason, if the process requires input, one cannot simply write all the data \nto stdin and then read the output. Writes and reads must alternate on demand. Also, stdout and stderr \nhave no explicit synchronization between them, so if these channels are read independently, there is \nno way to correlate the error messages with the normal output. These pitfalls are much easier to encounter \nwhen processing the output lazily, a very useful thing when dealing with large data.les. Our lazyRun \ntries to safely capture stdout, stderr, and the process return code in a time correlated manner, while \nfeeding stdin. The source code for lazyRun is shown in Figure 3, with ex\u00adample usage shown in main. Although \nthis style is very useful, we went through several iterations of this code and we are still not 100% \nsure that it will never block. At the very least, many invo\u00adcations may exhaust all the available .le \ndescriptors. We continue to search for a way to manage the resources required elegantly and ef.ciently. \n... importqualified Data.ByteString as B importqualified Data.ByteString.Lazy as L --Process returns \n[Output], with one Result at the end dataOutput str = Stdout str | StdoutEOF | Stderr str | StderrEOF \n| Result ExitCode lazyRun :: [B.ByteString]. Process . IO [Output B.ByteString] lazyRun input (inh, outh, \nerrh, pid) = dochan . newChan --:: IO (Chan Output) forkIO $ L.hPut inh (L.fromChunks input) forkIO $ \nrh Stdout StdoutEOF outh chan forkIO $ rh Stderr StderrEOF errh chan forkIO $ getResult pid chan getChanContents \nchan whererh = readHandle getResult ph chan = waitForProcess ph >>= writeChan chan \u00b7 Result bufSize = \n100 --largest chunk to be read at once readHandle :: (B.ByteString . Output B.ByteString) . Output B.ByteString \n . Handle . Chan (Output B.ByteString) . IO ()  readHandle constr eofConstr h chan = loop catch (const \n$ writeChan chan eofConstr) where loop = dor . hWaitForInput h (-1) aser of False . doputStrLn \"found \neof\" writeChan chan eofConstr True . doc. B.hGetNonBlocking h bufSize writeChan chan (constr c) yield \nloop --lazily turn the output channel into a output list getChanContents :: Chan (Output str) . IO [Output \nstr] getChanContents ch = loop (False, False, False) where uIO = unsafeInterleaveIO loop (True, True, \nTrue) = return [] loop s@(out, err, res) = uIO (dox . readChan ch letstatus = asex of (Result _) . (out, \nerr, True) StdoutEOF .(True, err, res) StderrEOF . (out, True, res) _.s xs . loop status return (x:xs)) \nmain = runInteractiveCommand \"./generator 100\" >>= lazyRun [] >>= mapM_ (putStrLn \u00b7 show) Figure 3. Excerpted \ncode for lazyRun, which feeds a process and lazily returns the output in a time correlated manner. test \n:: DryRunIO () test = doname . dr \"guest\" $ do putStr \"What is your name? \" >> hFlush stdout getLine \nio $ putStrLn $ \"Hello, \" ++ name Figure 4. An example use of the DryRunIO Monad. newt.peDryRunIO a= \nDryRunIO { runDryRunIO :: ReaderT Bool IO a} deriving(Monad, MonadIO, MonadFix, Functor, MonadReader \nBool) --mark an IO action that should always be run io :: IO a. DryRunIO a io = liftIO --Mark an IO action \nthat should be faked during a dry run. --First arg. is the value to return instead of performing the \naction. dr ::a . IO a. DryRunIO a dr def action = dodr. ask ifdr thenreturn def elseliftIO action --turn \na DryRunIO into IO run :: Bool . DryRunIO a. IO a run dryRun action = (runReaderT (runDryRunIO action)) \ndryRun Figure 5. Excerpted source code for the dry run IO monad.  2.5 Dry Run IO Monad When creating \nnew data structures on disk on machines with live data, it is often useful to do a dry run, .rst, i.e., \nshow the steps that would modify the state on disk, but not actually execute them. In our orginal implementation, \nthe dryrun .ag was explicitly passed into each function, with test dryrun = ... . Each function was expected \nto check the state of the dry run .ag before doing any IO. Unfortunately, this policy was easy to miss \nfor someone unfamiliar with the code, a fact that became clear when our distribution man\u00adagement software \nstarted sending emails about new packages being available for download when in fact, they were not. The \nemail no\u00adti.cation was a new feature and was not wrapped with the dry run conditional, so it executed \neven when all other operations did not. The DryRunIO monad (Figure 5) helps avoid this problem by requiring \nthe user to explicitly mark each IO action explicitly with one of the following: io :: IO a. DryRunIO \na dr :: a. IO a. DryRunIO a io always executes the given action, dr does so conditionally based on the \ncommand line .ag. The .rst argument to dr is returned during a dry run instead of performing the IO action. \nIf you forget to mark an action with either io or dr, the program will not compile. Figure 4 shows an \nexample, which asks the user for their name, defaulting to guest during a dry run. 2.6 Option (Maybe) \nin the Detector The job of the hardware detector is to ensure that the operating system boots and is \ncon.gured correctly, regardless of context. We want users to be able to move a disk drive from one machine \nto an\u00adother and have the operating system boot and be con.gured com\u00adpletely automatically. Since the \nnumber of con.gurations of per\u00adsonal computers in the world is effectively in.nite, this is a dif.\u00adcult \nand error prone task. We have already mentioned the bene.ts of static typing for this application, but \nwe feel it also worth mention\u00ading the extensive use of the Option type (the equivalent of Maybe in Haskell.) \nBecause users generally cannot debug the system con.guration problems, we provide a script that collects \na snapshot of the system con.guration and uploads it to a server for analysis. Such a script is worthless \nunless the operating system comes up to the point where a user can run it, so the detector s job is to \ncon.gure as much as possible, never failing completely unless it absolutely cannot .nd a solution. But \nas you poke around a Linux system, you will .nd exceptions everywhere. One of our favorite examples is \nthat many .ash devices have FAT .lesystems on them with no partition table at all. The results from probing \nsuch a device varies widely with the tool used, but often results in a long list of highly unlikely partition \ntypes. The detector must recognize such situations and calmly explore other alternatives. For this task, \nthe Option type is invaluable. Over half the source .les in the detector use the Option type. Having \ngood language support for converting error prone operations into total functions has helped us make the \ndetector more robust.  3. Broader Functional Design We have created programs that have no stateful \nvariables and yet they remain woefully imperative. The cause: management of disk memory is handled very \ndifferently than that of volatile RAM. Programming languages and operating systems provide a great deal \nof support for ensuring that processes are well behaved in memory, but on disk the programmer is left \nto fend for himself. Consider the following code fragment from our autobuilder: replaceFile path text \n= doesFileExist path >>= (flip when) (removeFile path) >> writeFile path text This function is a stunning \nexample of the contrast between the state of functional programming in memory and on disk. Monadic composition \nand higher order functions make this elegant and clear. And yet it implements what is effectively untyped \nmanual memory management with the .le system. There are real reasons to trap for errors in disk I/O, \nespecially on removable devices, but most errors in .le I/O occur because of trying to write over existing \n.les or into non-existent directories or because of ownership and permission con.icts. Essentially, these \nare the result of poor memory management. If .le systems were purely functional, like the data structures \ndescribed in (Okasaki 1998), then we should be able to extend the elegant functional programming style \nto encompass both levels of store. An excellent example of purely functional structures on disk is the \nincremental .le backup procedure described in (Rubel 2004). Using only the Unix tools cp, rsync and rm, \nthis procedure shares unchanged .les between immutable trees. The initial backup sim\u00adply copies the entire \nsource tree to the archive. All subsequent runs .rst make a copy of the most recent tree in the archive, \nhard link\u00ading all .les so that only the directories really get copied. Then the new source tree is copied \nover the new backup tree with rsync --delete which replaces .les that have changed, but leaves the hard \nlinks in place for unmodi.ed .les. This kind of minimalism works very well in practice. Restoring a tree \nis simply done by copying it back from the archive. When disk space gets short, simply garbage collect \nby removing the oldest backup trees. No special tools or formats are required, no extra training needed. \nWe make use of this and other similar techniques in the design of our package management system. In general, \nwe are trying to extend and reuse the functional techniques as much as possible, so that anyone can learn \nthe concepts quite quickly. As discussed below, we have not completely succeeded in this yet, because \nof the reality of dealing with existing imperative sys\u00adtems, but we can say de.nitively that the presentation \nof these con\u00adcepts to our staff (including developers, testers and management) was welcomed with a huge \nsigh of relief. Everyone was quite glad to get away from the complexity of our previous implementations. \n3.1 Functional Package Management The autobuilder s job is to work from a list of source packages (stored \nin a variety of locations and formats) to compile a new repository of binary packages that is complete \nand correct. Just as with a language compiler, our goal was to treat all output of the autobuilder as \nimmutable, with all changes being made to the input speci.cation. A similar approach can be seen in (Dolstra \n2006). Obviously, rebuilding thousands of packages from scratch is not necessary on each run, so the \nautobuilder uses the previous repository as a cache, but all details of that mechanism should be encapsulated \nwithin the autobuilder itself. Our previous generation of the autobuilder was designed around Debian \ns methods of package management. In their system, all packages are built using the latest repository \nas a source of build dependencies (packages required to be installed in order to build your package) \nand the results are then merged in with the rest of the packages, replacing the old state. Groups of \npackages deemed suf\u00ad.ciently bug free are then moved in groups to another, more stable repository. To \ndo this safely, both build and run-time dependencies should be satis.ed after the move. Ideally, the \nresulting collection could be built completely from source to produce the identical result, but we have \nfound this not to be the case with Debian s repositories. Another problem is that these operations are \nhard to roll back, which is often quite useful when a bug crops up that will take a long time to .x or \nthat is deemed un.xable before release. With our new design, promotion and roll back are easy: you simply \nedit the list of source packages and set the version to be the one you want, then run the autobuilder. \nDeletion is similarly easy. Again, other than the autobuilder itself, this requires no special tools \nor training.  4. Ongoing Work Unfortunately, as of this writing, the autobuilder code does not match \nthe design described in the previous section. The implemen\u00adtation drifted from the design under the pressure \nof time and be\u00adcause of the complexity of the problem. We found it very dif.cult to maintain a functional \nstyle while working with the Debian ar\u00adchitecture, which is large, complicated and organically grown. \nAl\u00adthough our code is purely functional, the resulting data structures on disk are not, because the temptation \nto optimize early in the face of such large costs is great. We feel that we are close to a good set of \nfeatures for good systems programming (DualForm, DryRunIO, lazyRun)and that a little more experimentation \nwill give us an embedded language that supported the functionality in Haskell that will let us drop the \nuse of shells and make completely. In that case, the autobuilder will be our .rst candidate for a revamp. \nWe expect to be able to shorten our code, improve its readability signi.cantly, and make the autobuilder \nboth far more robust and easy to use. At that point, it should be an excellent place to test out ideas \nfor a purely functional .le system. 5. Conclusions We have been using functional programming in this \nproject when\u00adever possible for over .ve years. The systems we have built con\u00adtinue to run and we feel \nthat we have realized many of the oft re\u00adpeated bene.ts of functional programming, though they do require \nadaption to our circumstances.. For OS development, it is dif.cult to test all possible code paths due \nto the variety of hardware involved. Static typing eliminates a lot of bugs at compile time that we would \nnot be able to catch using runtime tests. The static type system also makes it easier for developers \nto modify a piece of the code with out having to understand the entire system .rst. This is important \nbecause developers work on a lot of different things, and aren t just focused on a single application. \nIn general, we continually have to .ght against code that is 90% correct. If it breaks down one in ten \ntimes, the bene.ts of automation are lost. Better to take the time to write test cases, code carefully \nand make sure the results are easily understood by fellow developers. Reducing cognitive load on developers \nis particularly important when dealing with GNU/Linux, which is a very large, heteroge\u00adneous and quickly \nchanging code base. Static typing and Haskell s attention to readability really help with this. We have \nall experi\u00adenced the feeling that our Haskell code is the easiest to return to after being away working \non another problem. Furthermore, it helps to have a single methodology to pull from at all levels of \ndesign and programming. Two-level languages, where you drop to programming in C when your program slows \ndown, seem unwieldy to us now. Thinking functionally from start to .nish helps us gain traction. The \nauthors are all in agreement that we bene.t greatly from using functional programming and have every \nintention of contin\u00aduing with it. In particular, we feel that if we succeed in building the embedded \nlanguage described above, it would help reduce the tan\u00adgle that always seems to happen in the IO monad \nand would really elevate Haskell to a great systems programming language.  References Eelco Dolstra. \nThe Purely Functional Software Deployment Model.PhD thesis, Faculty of Science, Utrecht, The Netherlands, \nJanuary 2006. John Goerzen. Missingh. hackage.haskell.org, 2006. Ian Jackson and Christian Schwarz. Debian \npolicy manual. debian.org/doc/debian-policy, 1996. Chris Okasaki. Purely Functional Data Structures. \nCam\u00ad bridge University Press, Cambridge, UK, 1998. URL citeseer.ist.psu.edu/okasaki98purely.html. Mike \nRubel. Easy automated snapshot-style backups with linux and rsync. mikerubel.org/computers/rsync snapshots/, \n2004.  \n\t\t\t", "proc_id": "1291151", "abstract": "<p>We report on our experience using functional programming languages in the development of a commercial GNU/Linux distribution, discussing features of several significant systems: hardware detection and system configuration; OS installer CD creation; package compilation and management. Static typing helps compensate for the lack of a complete testing lab and helps us be effective with a very small team. Most importantly, we believe that going beyond merely using functional languages to using purely functional <i>designs</i> really helps to create simple, effective tools.</p>", "authors": [{"name": "Clifford Beshers", "author_profile_id": "81100487674", "affiliation": "Linspire, Inc., San Diego, CA", "person_id": "PP37041610", "email_address": "", "orcid_id": ""}, {"name": "David Fox", "author_profile_id": "81539166456", "affiliation": "Linspire, Inc., San Diego, CA", "person_id": "PP37042302", "email_address": "", "orcid_id": ""}, {"name": "Jeremy Shaw", "author_profile_id": "81337493448", "affiliation": "Linspire, Inc., San Diego, CA", "person_id": "P900679", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1291151.1291184", "year": "2007", "article_id": "1291184", "conference": "ICFP", "title": "Experience report: using functional programming to manage a linux distribution", "url": "http://dl.acm.org/citation.cfm?id=1291184"}