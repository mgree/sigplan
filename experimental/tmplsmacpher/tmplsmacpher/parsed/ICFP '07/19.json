{"article_publication_date": "10-01-2007", "fulltext": "\n Evaluating High-Level Distributed Language Constructs Jan H. Nystr\u00a8om Phil W. Trinder David J. King \nErlang Consulting Heriot-Watt University Praxis High Integrity Systems jan@erlang-consulting.com P.W.Trinder@hw.ac.uk \nDavid.King@praxis-his.com Abstract The paper investigates the impact of high level distributed pro\u00adgramming \nlanguage constructs on the engineering of realistic soft\u00adware components. Based on reengineering two \nnon-trivial telecoms components, we compare two high-level distributed functional lan\u00adguages, ERLANG \nand GdH, with conventional distributed technolo\u00adgies C++/CORBA and C++/UDP. We investigate several aspects \nof high-level distributed lan\u00adguages including the impact on code size of high-level constructs. We identify \nthree language constructs that primarily contribute to the reduction in application size and quantify \ntheir impact. We pro\u00advide the .rst evidence based on analysis of a substantial system to support the \nwidely-held supposition that high-level constructs re\u00adduce programming effort associated with specifying \ndistributed co\u00adordination. We investigate whether a language with sophisticated high-level fault tolerance \ncan produce suitably robust components, and both measure and analyse the additional programming effort \nneeded to introduce robustness. Finally, we investigate some im\u00adplications of a range of type systems \nfor engineering distributed software. Categories and Subject Descriptors D.1.1 [Functional Program\u00adming]; \nD.3.3 [Language Constructs and Features]: Concurrent Programming Structures; D.1.3 [Concurrent Programming]: \nDis\u00adtributed Programming; C.2.4 [Distributed Systems]: Distributed Applications General Terms Languages, \nDesign, Measurement Keywords Programming Languages, Distributed Programming, Erlang, Haskell 1. Introduction \nThere has been sustained interest in constructing high-level dis\u00adtributed languages, e.g. Kali Scheme \n(Cejtin et al. 1995), Facile (Gi\u00adacalone et al. 1989), OZ (Haridi et al. 1997), ERLANG (Armstrong et \nal. 1996) and Glasgow distributed Haskell (GdH) (Pointon et al. 2000). Like other language designers, \ndistributed language design\u00aders propose new constructs and demonstrate them on small exem\u00adplars. However \na realistic assessment of a construct, and especially one intended for large scale distribution, must \nbe based on substan\u00adtial realistic exemplars. This paper investigates the impact of high level distributed \nlan\u00adguage constructs on the engineering of realistic software. Unlike Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 07 October 1 3, 2007, Freiburg, Germany. \nCopyright c . 2007 ACM 978-1-59593-815-2/07/0010. . . $5.00 the numerous programming language comparisons \nbased on se\u00adquential kernel benchmarks, e.g. (Language Shootout; OO Lan\u00adguage Comparison), we base our \nevaluation on two distributed components, where distributed coordination, and especially robust\u00adness, \nis a key aspect. Moreover, rather than being benchmark ker\u00adnels, the components are substantial and form \npart of telecom prod\u00aducts. Earlier work has compared ERLANG and C++/CORBA for dis\u00adtributed telecoms software \nengineering, focusing on distributed softwarerequirements: robustness,productivity, performance, func\u00adtionality, \ninteroperability and practicality (Nystr\u00a8om et al.). The re\u00adsults demonstrate that the high level ERLANG \ncomponents meet the functional requirements, and hence can be reasonably com\u00adpared with the existing \nC++ based implementations. Here we focus on the impact of high-level programming lan\u00adguage constructs \non the construction of realistic distributed soft\u00adware. Thehigh-levellanguagesare ERLANG,anindustrial-strength \nlanguage with high-level distributed coordination and advanced fault tolerance mechanisms (Armstrong \net al. 1996), and Glasgow distributed Haskell (GdH) a research language with very high-level distributed \ncoordination (Pointon et al. 2000). Our research strategy is to reengineer two telecoms components in \nERLANG and GdH and make comparative measurements with the existing implementations using conventional \ndistributed tech\u00adnology, i.e. C++ combined with CORBA and with communication libraries. The .rst component \nis a medium-scale (15K line) Dis\u00adpatch Call Controller (DCC) (Lillie 1999) (Section 4.2). The sec\u00adond \nis a smaller (3K line) Data Mobility (DM) component that is closely integrated with .ve other components \nof a base radio net\u00adwork (Section 4.3). Comparing programming languages, and especially sophisti\u00adcated \ndistributed languages, is a challenging task. There are nu\u00admerous dimensions that could be investigated \nand and each study must necessarily choose a small number to focus on. In this study we investigate the \nfollowing research questions. Q1 Do high-level distributed language constructs reduce appli\u00adcation size? \nSoftware size is crucial as shorter programs are faster to produce and easier to maintain. Our investigation \ncom\u00adpares the sizes and functionalities of implementations of two telecoms components in the high-level \nGdH and ERLANG with conventional implementations in C++/CORBA and C++/UDP (Section 5). Q2 What high-level \ndistributed language constructs impact ap\u00adplication size? Our investigation quanti.es the impact of lan\u00adguage \nconstructs such as garbage collection, high-level commu\u00adnication and advanced fault tolerance on code \nsize (Section 6). Q3 What is the impact of high-level coordination? In theory a language with high-level \ncoordination reduces the program\u00adming effort of specifying coordination. We report what we be\u00adlieve is \nthe .rst investigation of this hypothesis in the context of realistic distributed components, and cover \nboth ERLANG and GdH (Section 7). Q4 What is the impact of sophisticated fault tolerance con\u00adstructs, \nand what are the costs of introducing robustness? Weinvestigatehowreadily ERLANG,alanguagewithadvanced \nhigh-level fault tolerance, can produce suitably robust compo\u00adnents. We further measure the cost of introducing \nrobustness in the context of realistic distributed components by measuring both the DM and two versions \nof the DCC, one with, and one without, fault tolerance (Section 8). Q5 What are some of the impacts of \nthe type systems on dis\u00adtributed software engineering? The languages in our study have very different \ntype systems: ERLANG is dynamically typed, C++ has weak static typing with parametric and subtyp\u00ading \npolymorphism, and GdH is strongly typed with Hindley-Milner and parametric polymorphism. We investigate \nsome of the implications of these type systems on the construction of a substantial distributed component, \nmeasuring the numbers of type declarations and the frequency of dynamic type checking (Section 9). 2. \nRelated Work Popular programming language comparisons are inappropriate for distributed languages. There \nare few distributed language com\u00adparisons and they typically compare performance rather than lan\u00adguage, \ne.g. the Hartstone distributed benchmark measures real\u00adtime performance (Kamenoff and Weiderman 1999). \nThere are numerous language comparisons, some general e.g. (Language Shootout), some comparing within \na paradigm e.g. object-oriented languages (OO Language Comparison) and others comparing paradigms, e.g. \nscripting versus general purpose languages (Prechelt 2000). Some of the comparisons incorporate hundreds \nof lan\u00adguages, and some distributed languages, e.g. ERLANG, have con\u00adtributed to the comparisons. However \nthe great majority of bench\u00admark programs are sequential and are necessarily small kernels of larger \napplications, and hence not a good basis for comparing languages intended for engineering large-scale \ndistributed systems. In contrast this paper analyses the impacts of distributed language constructs, \ne.g. fault tolerance, on the engineering of two substan\u00adtial distributed product components. Evaluating \ndistributed functional languages (DFLs) with sub\u00adstantial real applications is challenging. Most DFLs \nlike Kali Scheme (Cejtin et al. 1995), Facile (Giacalone et al. 1989), OZ (Haridi et al. 1997), and GdH \n(Pointon et al. 2000) are research languages and are demonstrated on relatively small virtual applications. \nVir\u00adtual applications are only used for measurement, and not for a practical purpose. Our study is unusual \nin comparing, inter alia, ERLANG and GdH using substantial real distributed product com\u00adponents. Comparing \ndistributed languages, and especially DFLs, is chal\u00adlenging. DFLs require a sophisticated implementation \nto man\u00adage distributed coordination, and as research languages most DFL implementations are relatively \nimmature. For example a lan\u00adguage may only be available as a prototype on a speci.c hard\u00adware/operating \nsystem platform. Some small scale comparisons have been undertaken, e.g. (Pointon et al. 2001) compare \nEden, GdH and Java/RMI using small kernels. We use larger components and compare four distributed technologies: \nthe ERLANG and GdH DFLs, and C++ with CORBA (Object Management Group (OMG) 2004) and C++ with UDP (Postel \n1980). Other studies have compared ERLANG with other distributed language technologies. Ericsson have \nundertaken some unpub\u00adlished comparative studies. A published study addresses research question Q1 in \nthis paper, i.e. the reduction in application size. The study is based on the development of the AXD301 \nATM switch with more than 1M source lines of code (SLOC) and reports that the ERLANG systems have between \n4 and 10 times less code than C/C++, Java or PLEX (Wiger 2001). This is in agreement with the results \nwe report in Section 5. Our study goes beyond these ear\u00adlier studies by making a systematic investigation \nof the impact of speci.c distributed language constructs as outlined by the research questions in the \nprevious section. Earlier work has thoroughly investigated the fault tolerance of the ERLANG DCC (Nystr\u00a8om \net al. 2005), and compared ERLANG, but not GdH, with C++/CORBA and C++/UDP for distributed soft\u00adware \nengineering (Nystr\u00a8om et al.). The latter work compares the robustness, productivity, performance, functionality, \ninteroperabil\u00adity and practicality of the technologies. The results demonstrate that the ERLANG components \nmeet the corresponding functional requirements, and hence are an appropriate basis for the language analysis \nreported in sections 5 9. 3. Distributed Language Technologies Distributed coordination can be speci.ed \nat a range of levels of abstraction. At the lowest level the programmer explicitly places computations \nand resources at named locations and arranges com\u00admunication and synchronisation between them. Such low-level \nco\u00adordination, e.g. send/receive or wait/signal can be viewed as equally harmful for coordination as \ngoto is for algorithms (Gor\u00adlatch 2004). Higher level distribution technologies reduce the pro\u00adgramming \neffort to specify coordination, and this section brie.y outlines the distributed technologies used in \nour study. C++ is a sequential language, and like many other sequential languages is commonly combined \nwith distribution technologies to construct distributed systems. The two distribution technologies used \nfor the telecoms components measured here are CORBA and the UDP and ICI communication libraries. 3.1 \nLow-Level Distribution: UDP and ICI Constructing a distributed system using a low-level communica\u00adtion \nlibrary typically entails explicitly spawning operating system processes and managing communication between \nthem. Often data must be explicitly marshalled and unmarshalled. There are numer\u00adous protocols at different \nlevels of abstraction, and the protocols are supported by libraries in many programming languages. Both \nthe UDP and ICI protocols used in our study are low-level. The User Datagram Protocol (UDP) is a core \ninternet protocol, and en\u00adables components to send short messages, or datagrams, over sock\u00adets (Postel \n1980). UDP is relatively fast as, unlike TCP, it does not provide reliable or ordered datagram delivery. \nthat uses message passing via shared memory. Interprocess Communication Interface (ICI) is a proprietary \nMotorola protocol for inter process commu\u00adnication that uses message passing via shared memory. 3.2 \nMid-Level Distribution: CORBA CORBA, Common Object Request Broker Architecture, wraps a sequential component \ninto an object containing information about the capabilities of the component and how to call it (Object \nMan\u00adagement Group (OMG) 2004). The wrapped objects can be called from other programs or CORBA objects \nacross a network. CORBA uses an interface de.nition language (IDL) to specify the interfaces that objects \nwill present to the world. CORBA then speci.es a map\u00adping from IDL to a speci.c implementation language \nlike C++ or Java. CORBA provides mid-level distributed coordination by pro\u00adviding a language and platform \nneutral remote procedure call. In addition CORBA de.nes common services such as transactions and security. \n 3.3 Higher-Level Functional Distribution A number of distributed functional languages have been con\u00adstructed \nwith a range of models of distributed coordination, as outlined in the previous section. With the exception \nof ERLANG, almost all are research languages used to investigate high-level dis\u00adtributed coordination \nintegrated with the language. The following sections brie.y outline the DFLs used in our study. 3.4 \nHigh-Level Distribution: ERLANG ERLANG is a DFL originally developed in Ericsson for construct\u00ading highly \nreliable telecom systems (Armstrong et al. 1996). The language has integrated distribution, including \n.rst-class processes, advanced fault tolerance mechanisms, automatic storage manage\u00adment i.e. garbage \ncollection, soft real-time support, and sophisti\u00adcated availability support e.g. hot-loading hardware \nand software upgrades into a running system. ERLANG has several general features that facilitate the \ncon\u00adstruction of large distributed real-time systems. The module sys\u00adtem allows the structuring of very \nlarge programs into conceptually manageable units. ERLANG supports single-assignment variables, and has \nan explicit notion of time, enabling it to support soft real\u00adtime applications, i.e. where response times \nare in the order of mil\u00adliseconds. ERLANG has been used by a number of companies to construct a wide \nrange of applications, primarily in the telecoms sector, but increasingly in other sectors, e.g. banking. \nExamples include the .rst implementation of GPRS for standard packet data in GSM sys\u00adtems (Granbohm and \nWiklund 1999), and the Intelligent Network Service Creation Environment (Hinde 2000). The largest applica\u00adtion \nto date is the AXD 301 scalable and robust backbone ATM switch (Blau et al. 1999), currently utilising \nup to 288 Processing Elements (PEs). The code comprises over 1.7 million lines of new ERLANG code (Armstrong \n2003, p.6), 300K lines of mostly-reused C and 8K lines of Java, developed by a team peaking at 50 software \nengineers (Wiger 2000). 3.4.1 Fault Tolerance The ERLANG reliability philosophy is to separate the functionality \nand error-handling concerns. That is, the programmer writes sim\u00adple code for the successful case that \nmay fail, raising an exception. The key to this let it fail ethos is that the language incorporates .rst \nclass processes that can fail without damaging other processes. True processes, while common in operating \nsystems, are extremely unusual in production programming languages. A common reason for a failure is \na timeout and the exception raised may be handled within a process by an exception handler, or by a monitoring \npro\u00adcess. Figure 1. ERLANG/C DM Supervision Tree The monitoring of one process by another is suf.ciently \ncom\u00admon that it is encapsulated by the supervisor behaviour (Armstrong 2003). An ERLANG behaviour is \na high-level distributed coordi\u00adnation abstraction. In the supervisor behaviour the supervising, or parent, \nprocess spawns child processes and declares a number of coordination aspects. An important aspect is \nthe action to perform in the event of a failure, e.g. restart the child process, kill the child process, \nkill all the child processes. A second important aspect is the frequency of failures to be tolerated, \ne.g. one per hour. As the supervised processes may supervise other processes, a supervision tree can \nbe constructed. Figure 1 shows the supervision tree for the ERLANG/C DM component described in Section \n4.3. In this tree, Supervisor 2 will restart either of the ERLANG receiver or transmitter processes at \nmost once an hour. Supervisor 1 will fail gracefully if supervisor 2 fails or either of the C drivers \nfail, re.ecting the fact that it has no way of restartingthe Cdrivers. This supervision tree provides \nmuch of the DM robustness, and is less than 10 source lines of code. sz_dme_dmtx:cast(device_info) Figure \n2. ERLANG DM Communication In addition to supervision behaviours, ERLANG provides other sophisticated \nfault tolerance and dynamic recon.guration capabil\u00adities, although these are not demonstrated here. First \nclass pro\u00adcesses make it easy for ERLANG programs to recon.gure them\u00adselves dynamically, e.g. to restructure \nin the event of a hardware failure, or to utlilise new hardware that becomes available. For ex\u00adample \n(Nystr\u00a8om et al.) illustrates how the DCC throughput scales near-linearly when processors are added or \nremoved. Moreover, software upgrades can be hot loaded , i.e. installed without stop\u00adping the executing \nprogram. The code replacement mechanism cru\u00adcially relies on the ERLANG runtime system dynamically linking \nto the latest version of a module, which can be upgraded during exe\u00adcution. 3.4.2 High-Level Communication \nCommunication between ERLANG processes is high-level asyn\u00adchronous message passing. The communication \nmechanisms pro\u00advide automatic data marshalling, error detection, communication and synchronisation. Figure \n2 and Figure 3 give a dramatic com\u00adparison of the same communication in ERLANG and in C++ with ICI. An \nERLANG cast is a point-to-point send primitive, and device info is a data structure describing the device \nstatus that is automatically marshalled for communication. The details of the C++ version are unimportant, \nother than to observe that it contains considerable amounts of data marshalling and defensive code, e.g. \nlines 32-38 detect and report an error. The ERLANG version cru\u00adcially relies on automatic error detection, \nand that the failure will be handled elsewhere, most probably by a supervising process. 3.4.3 Automatic \nMemory Management Like many modern programming languages, ERLANG provides au\u00adtomatic memory management, \nsupported by garbage collection. This both relieves the programmer from specifying a signi.cant and awkward \naspect of the program, and improves reliability by guaranteeing safe storage management and reducing \nspace leaks. ERLANG programs typically contain no explicit storage manage\u00adment, and hence there is none \nin Figure 2. In contrast, lines 9 and 13 of the C++ code in Figure 3 calculate a size and allocate an \nobject of that size. 3.4.4 Pragmatics To aid rapid application development ERLANG is supplied with the \nOpen Telecom Platform (OTP) libraries (Torstendahl 1997). The 1void DataMobilityRxProcessor::processUnsupVer(void) \n2{ 3 MSG_PTR msg_buf_ptr; 4 MM_DEVICE_INFO_MSG *msg_ptr; 5 RETURN_STATUS ret_status; 6 UINT16 msg_size; \n7 8 // Determine size of ici message 9 msg_size = sizeof( MM_DEVICE_INFO_MSG); 10 11 // Create ICI message \nobject to send to DMTX so it 12 // sends a Device Info message to Q1 and Q2 clients 13 IciMsg ici_msg_object( \nMM_DEVICE_INFO_OPC, ICI_DMTX_TASK_ID, msg_size); 15 // Retrieve ICI message buffer pointer 16 msg_buf_ptr \n= ici_msg_object.getIciMsgBufPtr(); 17 18 // Typecast pntr (void *) => (MM_DEVICE_INFO_MSG *) 19 msg_ptr \n= (MM_DEVICE_INFO_MSG *)msg_buf_ptr; 20 21 // Populate message buffer 22 SET_MM_DEVICE_INFO_DEVICE_TYPE( \nmsg_ptr, SERVER); 23 SET_MM_DEVICE_INFO_NUM_VER_SUPPORTED( 24 msg_ptr, NUM_VER_SUPPORTED); 25 SET_MM_DEVICE_INFO_FIRST_SUP_PROTO_VERS( \n26 msg_ptr, PROTO_VERSION_ONE); 27 28 // Send message to the DMTX task 29 ret_status = m_ici_io_ptr->send(&#38;ici_msg_object); \n30 31 // Check that message was sent successfully 32 if (ret_status != SUCCESS) 33 { 34 // Report problem \nwhen sending ICI message 35 sz_err_msg( 36 MAJOR, SZ_ERR_MSG_ERR_OPCODE, __FILE__, __LINE__, 37 \"DataMobilityRx \nprocessUnsupVer: failure sending \" 38 \" device info message to DMTX\"); 39 } Figure 3. C++/ICI DM Communication \nOTP include, inter alia, libraries, design principles, and produc\u00adtivity, pro.ling and debugging tools. \nA compiler (Johansson et al. 2003) and a bytecode interpreter are both available as open source for ERLANG. \n 3.5 Very High-Level Distribution: GdH Glasgow distributed Haskell (GdH) is a research language with \nvery high-level distributed coordination. It was designed to inves\u00adtigate the construction of reliable \ndistributed applications in high\u00adlevel languages. Haskell (Peterson et al. 1997) is the de facto stan\u00addard \nnon-strict functional language and the GdH implementation is based on the Glasgow Haskell Compiler, one \nof the best implemen\u00adtations available. GdH combines features of two other variants of Haskell, Glasgow \nparallel Haskell (Trinder et al. 1998) and Concur\u00adrent Haskell, with some additional constructs (Pointon \net al. 2000). GdH has the following features. It supports both parallel dis\u00adtributed computation using \ntwo classes of thread: stateless threads and stateful I/O threads. Processing Elements (PEs) are identi.ed \nby a PEId so that a program can use resources unique to a PE, like a data source or a GUI interacting \nwith a user. Both remote procedure call and remote evaluation distribution paradigms are supported. Synchronous \nremote procedure call (RPC) is provided by the revalIO primitive: revalIO :: IO a -> PEId -> IO a A \nthread executing revalIO work p dispatches the computation work to be performed on location p and blocks \nuntil the result is returned. Asynchronous remote evaluation is provided by the rforkIO primitive: rforkIO \n:: IO () -> PEId -> IO ThreadId Analogous to forkIO in Concurrent Haskell, a thread executing rforkio \nwork p creates a thread on location p to execute the computation work, returns the ThreadId and continues \nto execute. As in Concurrent Haskell some communication and synchroni\u00adsation is implicit: a thread may \nshare variables with other threads that may reside on this or other PEs. However other communication \nand synchronisation is explicit: stateful threads can read and write mutable variables, or MVars. MVars \nare polymorphic semaphores, i.e. an MVar may contain a value of any type, and threads must synchronise \nto read (get) or write (put) them, e.g. a thread read\u00ading an MVar is blocked until a value has been written \nto it. In GdH the MVars are distributed, i.e. reading and writing threads may re\u00adside on different PEs: \nthe read or write operation, and associated response are implicitly conveyed in messages between the \nPEs. Higher-level constructs, like channels between threads on dif\u00adferent PEs, are constructed by abstracting \nover distributed MVars. Fault tolerance is provided by distributed exception handling, e.g. an exception \ncan be raised on one PE and handled on another. GdH supports very high-level distributed coordination \nin sev\u00aderal ways. The programmer need only explicitly locate key stateful objects, and the location of \nthe large majority of stateless objects in a program remains implicit. The communication and synchronisa\u00adtion \nassociated with these objects is entirely implicit and managed by the sophisticated language implementation. \nMoreover, stateful computations are concisely expressed using abstractions like chan\u00adnels and higher-order \nmonadic functions. For example a monadic map that distributes an action to a sequence of locations effectively \nperforms a sequence of remote procedure calls: mapM (\\p -> (revalIO work p)) pes  4. Basis of Comparison \nThis section outlines the challenges posed by engineering of tele\u00adcom software and describes the DCC \nand DM telecom components that are reengineered as the basis of our comparison between the distributed \nlanguages. The ERLANG and C++ DMs and DCCs have the same functionality to a very good approximation, \nand the GdH DCC has very similar functionality but is less generic. The algo\u00adrithms and coordination \nstructures are very similar in the C++ and ERLANG DMs, but vary signi.cantly in the DCC implementations. \n4.1 Distributed Telecoms Software The telecoms sector is rapidly growing, with new devices and technologies \nappearing almost daily. This adds to the complexity of telecoms systems, which by their very nature have \na distributed architecture, an array of different hardware, operating systems, networks, and application \nsoftware. Rapid development and high levels of reliability and availability are key requirements. Telecoms \nproviders aspire to 99.999% availability, which equates to little more than 5 minutes downtime a year, \nbut this is rarely achieved. The rapid production of robust telecoms software raises the following technical \nchallenges. Higher Level Programming: us\u00ading high level programming paradigms in application development \nreleases the programmer from dealing with awkward, low level, technical issues such as memory management \nand communication details. Correctness: telecoms systems are typically too large for the correctness \nto be shown using formal proof. Hence, the impor\u00adtance of thorough testing that typically consumes more \nthan 50% of the software development effort. Additionally, abstraction can help with correctness, since \nit is easier to demonstrate properties or model check, if the speci.cation or implementation is given \nin a high-level formal notation. Fault tolerance: most downtime is caused not by hardware faults, but \nby system and application software failure. Recovering from a software crash, or processor failure, improves \navailability. Maintainability: which includes both debugging existing systems, and adding new features. \n Currently many distributed telecoms systems are implemented in C with SDL on real-time operating systems. \nSDL is a high level graphical language based on state machine that is used to specify coordination (Olsen \net al. 1997). The trends are to use C++/CORBA, JAVA/RMI and UML 2.0 state machines. There is considerable \ninterest in applying higher level techniques. One such technique is model driven software engineering, \nand UML 2.0 State Machines are a common model. Similarly, high level distributed programming languages \nare attractive because of the potential to reduce development time, and improve reliability and maintainabil\u00adity. \nClearly the implementation technology must also meet the other functional requirements of telecom applications, \ne.g. real-time re\u00adquirements. 4.2 Dispatch Call Controller (DCC) The .rst component reengineered is \na prototype dispatch call sys\u00adtem developed at Motorola Labs in Illinois (Lillie 1999). Dispatch call \nprocessing is a prevalent feature of many wireless communi\u00adcation systems and entails transmitting call \ncontent and managing handovers between radio cells. Managing the call processing with a distributed paradigm \nenables throughput to be scaled as system usage grows, with work dynamically distributed to the resources \navailable. The requirements for the DCC model are derived from the technical report by Lillie (Lillie \n1999) and from a set of func\u00adtional requirements (Rittle 1998). The DCC requires the following functionality. \nIt must provide dynamic scalability, i.e. the ability to adapt to use additional re\u00adsources while the \nsystem is running. It must reclaim resources to enable continuous execution, i.e. ensure that once a \nservice instance has terminated, all of its resources are reclaimed. It must be fault tolerant, and in \nparticular provide continued service despite fail\u00adures. It must meet soft real time performance criteria, \ni.e. call man\u00adagement mustn t interrupt the call. For the purpose of the study we use a model of the \nDCC service that only deals with regular voice point-to-point calls and hand-offs between the base radio \nstations. More complete descriptions of the systems measured are available in (Nystr\u00a8om et al. 2005). \nThe DCC service comprises two distinct parts, the subscribers of the system generating traf.c and the \n.xed-end terminating the service. Subscribers are simulated by two processes: one that sets up the call \nand generates simulated voice traf.c, and another that simulates subscriber roaming by issuing hand-off \nmessages to the .xed-end notifying it that the subscriber is now associated with a new base radio station. \nThe .xed-end is simulated by a service dealing with both hand-offs and call requests. The DCC software \ntest platform comprises the subsystems de\u00adscribed below and the overall architecture is shown in Figure \n4. The hardware platform is a 32-node Beowulf cluster. Test Management Responsible for starting and controlling \nthe System Management and Traf.c Generator subsystems dur\u00ading the test. The Test Manager will also inject \nthe faults into the non-testing subsystems. Traf.c Generator The Traf.c Generator sends a sequence of \ncalls to the Service Port and acts as a sink for all messages from service instances to caller. Processing \nElement Figure 4. ERLANG DCC Architecture System Management Responsible for starting, stopping and man\u00adagement \nof the Service Port and the worker nodes. The Sys\u00adtem Management subsystem is also responsible for restarting \nthe Service Port for any worker that fails. Service Port The Port is responsible for starting and maintaining \nall the interfaces used by the services to communicate with the Workers and relays calls from the subscribers \nof the services to the Worker responsible for Service Admission acting as gate\u00adkeeper. Worker There are \none or more Worker subsystems in the system and they are responsible for executing of the dispatch call \nhan\u00addlers. One of the workers is the designated leader of the work\u00aders and is responsible for admission \ncontrol and distribution of calls between the available Workers. The leader is elected, and re-elected \nafter a failure, using a standard protocol. 4.3 Data Mobility Server (DM) UDP RM Lang. C++ IDL Total \nRatio C++/CORBA ERLANG GdH 13906 83 13989 2143 335 42 6 1 Table 1. DCC Code Sizes (SLOC) DM description \navoids using precise product names, and some de\u00adtails are made abstract to preserve commercial con.dentiality. \nBoth the RCS and DM were developed by Motorola as part of an existing product that follows an international \nstandard. The abstract DM architecture is shown in Figure 5, where PZ is a participating zone manager, \nRM is a resource manager, CM is a con.guration manager, and IHLR is an individual home location register. \nKey aspects of the architecture are as follows. The DM has two main components a receiver (DM Rx) and \na transmitter (DM Tx). The DM communicates with data mobility devices us\u00ading UDP, and with .ve other \ncomponents of the RCS using ICI. For brevity this is termed the C++/UDP implementation in the re\u00admainder \nof the paper. The DM has not been implemented in GdH, but two ERLANG DM implementations have been constructed, \none purely in ER-LANG, and an ERLANG/C implementation that reuses some C DM libraries thus allowing the \nmeasurement of interoperation costs. Key aspects of the ERLANG DM architectures are as follows. There \nare four primary components: DME Rx and DME Tx are ERLANG receiver/transmitter processes and DME Rx-drv \nand DME Tx-drv are C receiver/transmitter drivers. The architecture combines Unix processes, C threads, \nand ERLANG processes. The ERLANG DMs interoperate with the same C RCS test harness as the C++ DM.  \n5. Application Size This section investigates the impact of high-level distribution on application size \nby comparing the sizes of the DCC and DM com\u00adponents in ERLANG and GdH with the existing C++/CORBA and \nC++/UDP implementations. The signi.cance of software size is well established: shorter programs are faster \nto produce (Jones 1986; Prechelt 2000), and hence programmers working in higher level languages are more \nproductive. The reduced development time crucially reduces time to market for the product. Moreover, \nshorter programs are easier to maintain, which is important as more than 50% of programming effort is \nexpended on mainte\u00adnance (Jones 1986). The metric we use for software size is logical source lines of \ncode (SLOC). There are numerous software complexity metrics, e.g. McCabe s cyclomatic complexity (McCabe \n1976), and a good survey is available in (Fenton and P.eeger 1998). Indeed McCabe s cyclomatic complexity \nis a Motorola corporate standard but is unavailable for either the DCC or the DM in isolation. SLOC has \nthe advantages of simplicity, relatively wide use, and enabling cross-paradigm comparisons, in this case \nto compare functional and object-oriented programs. 5.1 Dispatch Call Controller The sizes of the C++, \nERLANG and GdH DCC implementations are reported in Table 1, together with the ratios between the sizes. \nThe ERLANG implementation is a seventh of the size, and the GdH implementation is 1/42nd of the size, \nof the C++/CORBA implementation. While the language features contributing to the size differences are \ndiscussed in the following section, Table 2 exhibits additional factors contributing to the size differential. \nThe table distinguishes between the testing component, the generic and reusable platform component, and \nthe speci.c DCC service component of the im-    Lang. C++/CORBA ERLANG GdH SLOC % No. SLOC % No. \nSLOC % No. Reusable Platform Speci.c Service Mod 13544 81% 30 445 3% 5 Mod 1996 52% 22 147 4% 1 Mod 305 \n67% 4 30 7% 1 Appln. Total Testing Stats Total 13989 35 868 6% 1 14857 100% 36 2143 23 1687 44% 9 3830 \n100% 32 335 5 119 26% 1 454 100% 6 Table 2. DCC Functional Analysis (SLOC) Lang. C/C++ ERLANG Total \nRatio C++ ERLANG/C ERLANG 3101 247 616 398 3101 863 398 7.8 2.2 1 Table 3. DM Code Sizes (SLOC) plementations. \nWhile all three implementations substantially meet the DCC functional requirements, the GdH implementation \nis less generic. That is, additional effort would be required to adapt it to meet similar functional \nrequirements, and this is re.ected in the rel\u00adatively large service component. Secondly, while testing \nis a crucial part of application development, the sizes of the DCC testing com\u00adponents should not be \ncompared as the three DCC implementations have not been tested to the same level. That is, the C++/CORBA \nand GdH implementations have been lightly tested, whereas the ERLANG implementation has been substantially \ntested. 5.2 Data Mobility Server The sizes of the C++ and ERLANG DM are reported in Table 3, and depicted \nin Figure 6. As for the DCC, the pure ERLANG DM implementation is signi.cantly smaller than the C++/UDP \nimple\u00admentation. Even the interoperating ERLANG/C implementation is 3.6 times smaller than the C++/UDP \nimplementation. Both ERLANG DM implementations are smaller despite pro\u00adviding additional fault tolerant \nfunctionality not included in the C++/UDP implementation. Section 8 discusses the resilience of the ERLANG \nDMs, but the issue in this section is that the mechanism is automatic and does not require signi.cant \nprogramming effort. Figure 6. DM Source Code Sizes  5.3 Size Discussion TheGdH DCCisfarsmallerthanboththe \nERLANG andC++/CORBA DCCs re.ecting the very high level speci.cations of both computa\u00adtion and distributed \ncoordination. The ERLANG DCC and DM are Table 4. C++ DM Code Proportions Code Type C++ Code RCS C libraries \nApplication 19.2% 12.1% Defensive 25.3% 24.2% Communication 22.1% 5.6% Memory management 11.3% 7.1% Type \ndeclarations 11.2% 11.6% De.nes 1.1% 23.6% Includes 8.1% 8.6% Process management 1.9% 7.1%  Figure 7. \nDM Source Code Analysis Code Type ERLANG Total ERLANG/C Total ERL./C ERLANG Part ERL./C C Part Application \nDefensive Communication Memory Mgmnt Type Decls De.nes Includes Process Mgmnt 62.2% 0.5% 15.1% 0.0% 4.9% \n5.4% 2.4% 9.5% 61.8% 1.7% 10.2% 3.2% 6.1% 5.7% 5.7% 5.6% 69.0% 0.0% 10.9% 0.0% 5.2% 7.0% 2.4% 5.5% 43.7% \n6.1% 8.5% 11.3% 8.5% 2.4% 13.8% 5.7% Table 5. ERLANG DM Code Proportions less than 1/6th of the size \nof the corresponding C++ implementa\u00adtions re.ecting its high-level coordination. The ERLANG result is \nconsistent with other measurements (Wiger 2001), and with devel\u00adoper folklore in companies like Ericsson, \nT-Mobile and Nortel. We conclude that high-level distributed language constructs reduce the application \nsize of realistic components. Moreover the GdH DCC results suggest that very high-level distribution \nconstructs reduce application size still further. The following section investigates the language constructs \nthat contribute to the size reduction.  6. Language Feature Impact This section attributes size reductions \nto speci.c language features by analysing the DM component code. With a total of 19K lines of code, the \nDCC is too large to analyse conveniently. Figure 7 and Tables 5 and 4 compare the C++ and ERLANG DM code. \nFor simplicity the following discussion compares the C++ DM only with the pure ERLANG DM. When interpreting \nthe percentages in theseresults,thereadershouldrecallthatthe ERLANG DMis1/7th of the size of the C++ \nDM. The results show that the primary language features contributing to the reduction in code size are \nas follows. -ERLANG s sophisticated fault tolerance mechanisms mean that the programmer can code for \nthe successful case. Hence, there is far less defensive code in the ERLANG implementation: 0.5% as opposed \nto 25.3% -ERLANG s high-level communication greatly reduces the ef\u00adfort of specifying communication, \ne.g. buffering, marshalling and error-checking: 15.1% as opposed to 23.9%. -ERLANG s garbage collection \ngreatly reduces the memory management coding effort: 11.6% as opposed to 0%. Of crucial importance to \nproduct development teams, much of the code that is omitted from the ERLANG implementation is technically \nchallenging, e.g. memory management and defensive code are notoriously hard to get correct and to test. \nPart SLOC Percentage Modules C++/CORBA 2812 19% 13 ERLANG 881 23% 9 GdH 44 10% 4 Table 6. DCC Coordination \nCode Sizes ERLANG DCC ERLANG FT DCC Size Increase Part SLOC %ageMod. SLOC %age Mod. SLOC %age Mod. Total \n3830 100% 32 4882 100% 38 27% 19% Platform 1996 52% 22 2994 61% 26 50% 9% 18% Service 147 4% 1 147 3% \n1 0% -1% 0% Testing 1687 44% 9 1741 36% 11 3% -8% 22% Coord. 881 23% 9 1933 40% 28 119% 17%210% Table \n7. Originaland Fault Tolerant ERLANG DCCCodeAnalysis 7. Coordination Code Size This section investigates \nthe hypothesis that a language with high\u00adlevel coordination reduces the amount of coordination that the \nprogrammer must specify. While the hypothesis is widely believed, as far as we know this is the .rst \nevidence for a realistic, i.e. 15K line software component. Table 6reportstheamountofcoordinationcodeinthe \nERLANG, GdH and C++/CORBA DCC implementations. The measurements exclude declarations for coordination. \nWhile the percentage coordi\u00adnation for C++/CORBA and ERLANG is similar: 23% and 19%, the amount of code \nis signi.cantly less, i.e. 881 SLOC as opposed to 2812. The very high-level coordination constructs in \nGdH outlined in section 3.5 reduce the coordination speci.cation cost still further to just 10% or 44 \nSLOC. We conclude that, as expected, high-level coordination constructs reduce the amount of coordination \nthat the programmer must specify, and that very high-level constructs re\u00adduce it yet further. 8. Cost \nof Adding Fault Tolerance This section investigates the cost of adding robustness to a realistic distributed \nsystem using a language with sophisticated fault toler\u00adance. Our investigation uses the ERLANG fault \ntolerance mecha\u00adnisms outlined in section 3.4. The C++/UDP DM includes 25.3% defensive code (Table 4), \nand our Motorola collaborators assure us that this is relatively low for telecoms components. In contrast \nthe ERLANG DM includes just 0.5% defensive code (Table 5). Moreover, we have elsewhere demonstratedthatthe \nERLANG DMis resilient: sustaining through\u00adput at extreme loads and automatically recovering when load \ndrops. In contrast the C++/UDP DM fails catastrophically when over\u00adloaded (Nystr\u00a8om et al., 2005). Of \ncourse the C++ DM could be Part    Lines of Code ERLANG FT 164 C++ 3574 24% GdH 137 30% Table 8. \nType Declarations reengineered to be resilient, typically by declining excess requests, and also to recover. \nHowever this would make the program even larger, more complex, and harder to validate. To quantify the \ncost of adding fault tolerance we have con\u00adstructed a second, fault tolerant DCC, the ERLANGFT DCC. We \nhave elsewhere demonstrated that the ERLANGFT DCC exhibits high levels of availability: remaining available \ndespite repeated and multiple hardware and software failures, and dynamic recon\u00ad.gurability: with throughput \nscaling near-linearly when resources are added or removed (Nystr\u00a8om et al.). As the C++/CORBA DCC is \nnot fault tolerant it is compared for size with the original ER-LANG DCC version in Table 1. The sizes \nand functions of the ERLANGFT and original ER-LANG DCCs are reported in Table 7, where the last line \ncompares the sizes of the coordination functionality in each implementation. The 8th column of the table \nshow that there is a modest 27% in\u00adcrease in total application size, and that most of the increase is \nin the reusable platform (50%). The last row of the table shows that there is a dramatic increase in \nthe amount of coordination code (119%), moreover the coordination code has become pervasive, increasing \nby 210% from just 9 out of 32 modules in the original ERLANG DCC to 28 out of 38 modules in the ERLANGFT \nDCC. We conclude that distributed languages with sophisticated fault tolerance, like ERLANG, greatly \nfacilitate the construction of ro\u00adbust, i.e. resilient, highly-available and dynamically-recon.gurable, \nsystems. Moreover robustness is introduced for a modest cost: an increase in total application size of \n0.5% for the DM and 27% for the DCC. The additional fault tolerance code primarily speci.es coordination, \nand coordination becomes pervasive in the applica\u00adtion. 9. Type System Impacts Distributed software places \ndemands on the type system: compo\u00adnents of a distributed system must typically be separately typed, of\u00adten \nstatically, while messages between components must be dynam\u00adically typed. The languages in our study \nhave very different type systems. ERLANG is dynamically typed. C++ has static types with subtyping polymorphism \nthrough the multiple-inheritance class system, and compile-time parametric polymorphism through tem\u00adplates, \nbut allows programs to circumvent the type system almost arbitrarily. GdH is strongly statically typed \nwith Hindley-Milner and parametric polymorphism. This section investigates some of the impacts of the \ndifferent type systems on realistic distributed software. Table 8 reports the number of type declarations \nin each of the DCC implementations. The dynamic typing in ERLANG means that it contains very few declarations, \njust 3%. In contrast the C++ DCC contains the greatest number of type declarations, 3574, and a far higher \npercentage than in ERLANG. This represents both the static typing, and limited use of type inference \nin C++. Finally, the ta\u00adble shows that while the GdH DCC contains relatively few type declarations, just \n137, these represent the highest percentage of the code, 30%. Many of the GdH type declarations could \nbe inferred and hence are not necessary, but are often included as a program\u00adming discipline. It is commonly \nbelieved that the additional safety, static checking, and self documentation provided by strong static \ntyping more than compensate for this substantial overhead. Part Lines of Code Percentage total 4882 \n100% dynamic tests 687 14% Table 9. ERLANG FT DCC Dynamic Type Tests Table 9 reports the number of dynamic \ntype checks in the ER-LANG FT DCC. It reveals a signi.cant proportion of dynamic type tests, with one \nsource line in 7 making a type test. We suggest that this is typical of other distributed components. \nOf course some of the dynamic checks are necessary, and we further argue that the computational overhead \nof the additional dynamic type checks is unlikely to materially impact the performance of distributed \ncom\u00adponents. This is because distributed components are almost invari\u00adably coordination, rather than \ncompute, bounded. Our contention is borne out by experiment, e.g. (Nystr\u00a8om et al.) shows that de\u00adspite \nsigni.cantly slower sequential execution speed, lightweight process management enables the pure ERLANG \nDM to outperform the C++ DM: delivering twice the throughput and reducing round\u00adtrip time by a factor \nof 3. 10. Conclusions 10.1 Summary We have investigated the impact of high level distributed pro\u00adgramming \nlanguage constructs on the engineering of two tele\u00adcoms software components: a DM and a DCC. Our investigation \ncompares GdH, a language with very high-level distribution, and ERLANG, a language with high-level distribution, \nwith conven\u00adtional distributed technologies: mid-level C++/CORBA and low\u00adlevel C++/UDP. The ERLANG and \nC++ DMs and DCCs have the same functionality to a very good approximation, and the GdH DCC has very similar \nfunctionality but is less generic. The algo\u00adrithms and coordination structures are very similar in the \nC++ and ERLANG DMs, but vary signi.cantly in the DCC implementations. Let us return to the research questions \nfrom the introduction. Q1 Do high-level distributed language constructs reduce appli\u00adcation size? Re.ecting \nits high-level distribution, the ERLANG DCC and DM are less than 1/6th of the size of the C++ DM. The \nERLANG result is consistent with other measurements (Wiger 2001), and with developer folklore. We conclude \nthat high-level distribution language constructs signi.cantly reduce the appli\u00adcation size of realistic \ncomponents. With very high level coordi\u00adnation, the GdH DCC is far smaller than both the ERLANG and C++/CORBA \nDCCs and this suggests that very high-level dis\u00adtribution constructs reduce application still further \n(Section 5). Q2 What high-level distributed language constructs impact ap\u00adplication size? Our investigation \nidenti.ed three primary high\u00adlevel language constructs that reduce distributed programming effort: sophisticated \nfault tolerance case saves 27%, high-level communications save 22%, and automatic memory manage\u00adment \nsaves a further 11% (Section 6). Q3 What is the impact of high-level coordination? While the per\u00adcentage \nof coordination code in the ERLANG and C++/CORBA DCCs is similar, approximately 20%, the amount of code \nis sig\u00adni.cantly less: 881 SLOC as opposed to 2812. The very high\u00adlevel coordination constructs in GdH \nreduce the coordination speci.cation cost dramatically further to just 10%. We conclude that, as expected, \nhigh-level coordination constructs reduce the amount of coordination that the programmer must specify, \nand that very high-level constructs reduce it yet further (Section 7). Q4 What is the impact of sophisticated \nfault tolerance con\u00adstructs, and what are the costs of introducing robustness? Robustness is introduced \nfor a modest cost using advanced fault tolerance. The C++/UDP DM includes 25.3% defensive code and yet \nfails to provide key robustness capabilities, e.g. resilience to overload. In contrast, the ERLANG DM \nincludes just 0.5% defensive code and provides additional robustness, in\u00adcluding resilience. Adding fault \ntolerance increases the size of the DCC by just 27%, and much of the additional effort is ex\u00adpended in \nthe reusable platform (50%). Signi.cantly, almost all of the additional code is coordination, i.e. an \nadditional 119%, and coordination becomes pervasive throughout the application, appearing in 28 out of \n38 modules (Section 8). Q5 What are some of the impacts of the type systems on dis\u00adtributed software \nengineering? The DCC in dynamically\u00adtyped ERLANG requires relatively few type declarations, just 3%, \nbut induces substantial numbers of dynamic type checks, i.e. 1 source line in 7. The DCC in statically-typed \nC++ requires the greatest number of type declarations, 3574 (24%), re.ecting both static typing and limited \ntype inference. The DCC in GdH, re.ecting the common idiom of Hindley-Milner polymorphism, contains the \nthe greatest percentage of type declarations, 30%, yet the least number of type declarations (Section \n9). 10.2 Discussion It can be argued from the results in Sections 5-7 that a language with very high-level \ndistribution, like GdH, gives the greatest ben\u00ade.ts for distributed software development. These results \nshould, however, be viewed with some caution. GdH is a research language and lacks a production-quality \nimplementation. More signi.cantly, GdH s distributed paradigm is limited in a number of ways. GdH uses \na distributed virtual shared-memory model, so distributed per\u00adformance will not scale as well as a distributed-memory \nmodel like ERLANG. GdH has conventional fault tolerance using distributed exceptions, where other languages \nincluding ERLANG have more advanced models. GdH supports only closed systems: i.e. while an arbitrary \nnumber of processes can be created on an arbitrary number of processors, all of the distributed processes \nare part of a single program and no new programs nor new processors can be added (or removed). Finally, \nGdH is lazy and hence it s harder to statically predict component performance, often a crucial aspect \nof distributed systems. We conclude that high-level distributed language constructs can aid the rapid \nproduction of realistic robust systems. Moreover, we have presented some evidence that very high-level \ndistributed lan\u00adguage constructs further aid the rapid production of realistic sys\u00adtems. The high-level \nconstructs dramatically reduce application size, thereby reducing development time and aiding maintenance. \nSophisticated fault tolerance, high-level communication and auto\u00admated memory management are major contributions \nto reducing the development effort. High level constructs greatly reduce the amount of coordination the \nprogrammer must specify, and very high-level constructs reduce it dramatically. Robustness is intro\u00adduced \nfor a modest cost using sophisticated fault tolerance. In ongoing work we are working with a product \ngroup within Motorola to reengineer a substantial distributed system in ER-LANG. We are also investigating \na generic toolkit for constructing ERLANG wrappers to make existing components written in conven\u00adtional \nlanguages robust and scalable. Acknowledgments We gratefully acknowledge research funding from the UK \nEPSRC (GR/R88137) and from Motorola UK Research Labs. References J. Armstrong. Making reliable distributed \nsystems in the presence of soft\u00adware errors. PhD thesis, Department of Microelectronics and Informa\u00adtion \nTechnology, Royal Institute of Technology, Stockholm , Sweden, December 2003. J. Armstrong, R. Virding, \nC. Wikstr\u00a8om, and M. Williams. Concurrent Programming in ERLANG. Prentice Hall, 2nd edition, 1996. S. \nBlau, J. Rooth, J. Axell, F. Hellstrand, M. Buhrgard, T. Westin, and G. Wicklund. AXD 301: A new generation \nATM switching system. Computer Networks, 31(6):559 582, 1999. H. Cejtin, S. Jagganathan, and R. Kelsey. \nHigher-order distributed objects. ACM Trans. On Programming Languages and Systems (TOPLAS), 17 (1), September \n1995. N.E. Fenton and S.L P.eeger. Software Metrics: A Rigorous and Practical Approach. PWS, 1998. ISBN \n0534-95429-1. P. Giacalone, P. Mishra, and S. Prasad. Facile: a symmetric integration of concurrent \nand functional programming. In Tapsoft89, LNCS 352, pages 181 209. Springer-Verlag, 1989. S. Gorlatch. \nSend-receive considered harmful: Myths and realities of message passing. ACM Transactions on Programming \nLan\u00adguages and Systems, 26(1):47 56, 2004. ISSN 0164-0925. doi: http://doi.acm.org/10.1145/963778.963780. \n H. Granbohm and J. Wiklund. GPRS -General Packet Radio Service. Ericsson Review, (2), 1999. S. Haridi, \nP. Van Roy, and G. Smolka. An overview of the design of Distributed Oz. In Proceedings of the Second \nInternational Symposium on Parallel Symbolic Computation (PASCO 97), pages 176 187, Maui, Hawaii, USA, \nJuly 1997. ACM Press. S. Hinde. Use of ERLANG/OTP as a Service Creation Tool for IN Services. In Proceedings \nof the 6th International ERLANG/OTP Users Confer\u00adence (EUC 00). Ericsson Utvecklings AB, 2000. E. Johansson, \nM. Pettersson, K. Sagonas, and T. Lindgren. The develop\u00adment of the HiPE system: Design and experience \nreport. Software Tools for Technology Transfer, 4(4):421 436, August 2003. C. Jones. Programming Productivity. \nMcGraw-Hill, 1986.  N.I. Kamenoff and N.H. Weiderman. Hartstone distributed benchmark: Requirements \nand de.nitions. In Proceedings of the 12th Real Time Systems Symposium, pages 199 208, San Antonio, Texas, \nUSA, 1999. IEEE. Language Shootout. The Computer Language Shootout Benchmarks. WWW page, July 2006. URL \n http://shootout.alioth.debian.org/. R. Lillie. Implementing dynamic scalability in a distributed processing \nenvironment. Technical report, Motorola Labs, Shaumburg, Illinois, 1999. McCabe. A complexity measure. \nIEEE Transactions on Software Engi\u00adneering, 2:308 320, 1976. J.H. Nystr\u00a8om, P.W. Trinder, and D.J. King. \nHigh-level Distribution for the Rapid Production of Robust Telecoms Software: Comparing C++ and ERLANG. \nConcurrency and Computation: Practice and Experience. To Appear. J.H. Nystr\u00a8om, P.W. Trinder, and D.J. \nKing. Are High-level Languages suit\u00adable for Robust Telecoms Software? In Proceedings of the 24th Interna\u00adtional \nConference, SAFECOMP 2005, volume LNCS 3688, pages 275  288. Springer-Verlag, 2005. Object Management \nGroup (OMG). CORBA 3: The Common Object Request Broker Architecture: Core Speci.cation. Standard, 2004. \nURL www.omg.org/docs/formal/04-03-12.pdf. A. Olsen, O. R\u00e6rgemand, B. M\u00f8ller-Pedersen, R. Reed, and J. \nR. W. Smith. Systems Engineering Using SDL-92. Elsevier, 1997. OO Language Comparison. Object-Oriented \nLanguages: A Comparison. WWW page, July 2006. URL archive.eiffel.com/doc/manuals/technology/ oo comparison/page.html. \n J. Peterson, K. Hammond, et al. Report on the Programming Language Haskell (Version 1.4), April 1997. \nR.F. Pointon, P.W. Trinder, and H-W. Loidl. The Design and Implemen\u00adtation of Glasgow distributed Haskell. \nIn Proceedings of the Inter\u00adnational Workshop on Implementing Functional Languages (IFL 00), LNCS 2011, \npages 101 116, Aachen, Germany, September 2000. R.F. Pointon, S. Priebe, H-W. Loidl, R. Loogen, and \nP.W. Trinder. Func\u00adtional vs Object-Oriented Distributed Languages. In Eurocast 01, LNCS 2178, pages \n642 656, Canary Islands, Spain, February 2001. Springer-Verlag LNCS 2178.  J Postel. User Datagram Protocol. \nTechnical report, Internet Engineering Task Force (IETF), RFC 768, 1980. L. Prechelt. An empirical comparison \nof seven programming languages. Computer, 33(10):23 29, 2000. L. Rittle. Distributed Dispatch Architecture \nProject (Functional Require\u00adments). Technical report, Land Mobile Products Sector Research, Shaumburg, \nIllinois, 1998. S. Torstendahl. Open Telecom Platform. Ericsson Review, 75(1):14 23, 1997. P.W. Trinder, \nK. Hammond, H-W. Loidl, and S.L. Peyton Jones. Algorithm + Strategy = Parallelism. Journal of Functional \nProgramming, 8(1):23 60, January 1998. U. Wiger. Industrial-Strength Functional Programming: Experiences \nwith the Ericsson AXD301 Project. In Proceedings of the International Workshop on Implementing Functional \nLanguages (IFL 00), Aachen, Germany, September 2000. Presentation Only. U. Wiger. Four-Fold Increase \nin Productivity and Quality. In Proceedings of the International Workshop Formal Design of Safety Critical \nEmbedded Systems (FemSYS 01), 2001.     \n\t\t\t", "proc_id": "1291151", "abstract": "<p>The paper investigates the impact of high level distributed programming language constructs on the engineering of realistic software components. Based on reengineering two non-trivial telecoms components, we compare two high-level distributed functional languages, Erlang and GdH, with conventional distributed technologies C++/CORBA and C++/UDP.</p> <p>We investigate several aspects of high-level distributed languages including the impact on code size of high-level constructs. We identify three language constructs that primarily contribute to the reduction in application size and quantify their impact. We provide the first evidence based on analysis of a substantial system to support the widely-held supposition that high-level constructs reduce programming effort associated with specifying distributed coordination. We investigate whether a language with sophisticated high-level fault tolerance can produce suitably robust components, and both measure and analyse the additional programming effort needed to introduce robustness. Finally, we investigate some implications of a range of type systems for engineering distributed software.</p>", "authors": [{"name": "Jan Nystr&#246;m", "author_profile_id": "81100144253", "affiliation": "Erlang Consulting, Uppsala, Sweden", "person_id": "PP37043666", "email_address": "", "orcid_id": ""}, {"name": "Phil Trinder", "author_profile_id": "81100457538", "affiliation": "Heriot-Watt University, Edinburgh, Scotland UK", "person_id": "PP39068386", "email_address": "", "orcid_id": ""}, {"name": "David King", "author_profile_id": "81100194254", "affiliation": "Praxis High Integrity System, Bath, United Kingdom", "person_id": "PP37042834", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1291151.1291182", "year": "2007", "article_id": "1291182", "conference": "ICFP", "title": "Evaluating high-level distributed language constructs", "url": "http://dl.acm.org/citation.cfm?id=1291182"}