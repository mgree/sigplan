{"article_publication_date": "10-01-2007", "fulltext": "\n Type-safe Higher-order Channels in ML-like Languages* SungwooPark Pohang Universityof Science andTechnology \nRepublic ofKorea gla@postech.ac.kr Abstract Asameansof transmittingnotonlydatabutalsocode encapsulated \nwithin functions, higher-order channels provide an advanced form of task parallelism in parallel computations. \nIn the presence of mutable references, however, theypose a safety problem because references may be transmitted \nto remote threads where they are no longer valid. This paper presents an ML-like parallel language with \ntype\u00adsafe higher-order channels. By type safety, we mean that no value written to a channel contains \nreferences, or equivalently, that no reference escapes via a channelfrom the thread where it is created. \nThe type system uses a typing judgment that is capable of deciding whether the value to which a term \nevaluates contains references or not. The use of such a typing judgment also makes it easy to achieve \nanother desirable feature of channels, channel locality,that associatesevery channelwithauniquethreadforservingallvalues \naddressed to it. Our type system permits mutable references in sequential com\u00adputations and also ensures \nthat mutable references never interfere with parallel computations. Thus it provides both .exibility \nin se\u00adquential programming and ease of implementing parallel computa\u00adtions. Categories and Subject Descriptors \nD.3.1[Formal De.nitions and Theory]: Semantics, Syntax General Terms Languages Keywords Higher-order \nchannels, Channel locality,Parallel lan\u00adguages, Distributed languages 1. Introduction The advent of multicore \nprocessors and the impending demise of free lunch (Sutter 2005) have changed the conventional wisdom \non computer hardware (Asanovic et al. 2006). There is little room for increasing clock frequencywhile \nincreasing hardware parallelism is now the only viable way of improving processor performance. Sucha \nradical changeinthe trendof computer hardwarehasrevi\u00adtalized research on language support for parallel \nprogramming, as * Thisworkwas supportedby theKorea Science and EngineeringFounda-tion(KOSEF) grant fundedby \ntheKoreagovernment (MOST) (No. R01\u00ad2007-000-11087-0) and POSTECH BSRI research fund-2007. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page.To copyotherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 07, October 1 3, 2007, \nFreiburg, Germany. Copyright c &#38;#169; 2007ACM 978-1-59593-815-2/07/0010...$5.00 evidenced by recent \nparallel languages such as X10 (Charles et al. 2005),Fortress (Allan et al. 2007), Chapel (Cray Inc. \n2005), Data Parallel Haskell (Chakravarty et al. 2007), and Manticore (Fluet et al. 2007). Depending \non the granularity of parallel computations, paral\u00adlel programming models are divided into data parallelism \nor task parallelism. Data parallelism applies an independent operation to each element of a collection \nof homogeneous data and often re\u00adsults in massive parallel computations.Asimple case of data par\u00adallelism \nis .at data parallelism in which the independent opera\u00adtion is sequential.A more sophisticated model \ncalled nested data parallelism (Blelloch 1996) allows the independent operation it\u00adselftobea parallel \ncomputation.Task parallelismexecutes coop\u00aderative threads in parallel which communicate via shared mem\u00adory \nor channels in order to perform synchronization. The use of shared memory simpli.es programming tasks, \nespecially if a high\u00adlevel abstraction such as software transactional memory (Shavit and Touitou 1995) \nis provided, but it entails the memory con\u00adsistency problem. The use of channels empirically requires \nmore effort than programming with shared memory (Hochstein et al. 2005),butit eliminates the memory consistencyproblem. \nThis paper is primarily concerned with an extension of an ML\u00adlike language, i.e., a call-by-value functional \nlanguage with muta\u00adble references, that offers task parallelism with higher-order chan\u00adnels (but without \nshared memory). Higher-order channels transmit not only data, such as integers and channel names,but \nalso pieces of code encapsulated within functions. The capability to transmit code between threads opens \na new range of communication con\u00adstructs such as futures, remote evaluation, code on demand, and hot \ncode replacement. Because of the similarity between task parallelism in parallel computations and process \nparallelism in distributed computations, ourtargetlanguagecanalsobethoughtofasa distributedlanguage in \nwhich processes share no global memory and communicate only via higher-order channels. Thus, although \nour work primarily aims at designing higher-order channels for parallel languages, it can be equally \napplied to distributed languages. 1.1 Type-safe higher-order channels The main problem with higher-order \nchannels is that in the pres\u00adence of mutable references, code containing references may travel between \nthreads,butin the absenceof shared memory, a reference created by a thread cannot be dereferenced at \nanother thread. Pre\u00advious parallel or distributed languages with a similar programming model avoid this \nproblem by dispensing with mutable references altogether, as in the parallel language Manticore (Fluet \net al. 2007), or by designing the runtime system so as to create copies of heap cells whenever their \nreferences are transmitted, as in the distributed languagesFacile (Knabe 1995) and JoCAML(Fournetetal. \n2003). This paper takes a different approach by developing type-safe higher-order channels. The type \nsystem ensures that no reference escapesfromthe threadwhereitis createdsothatallvalues written to channels \nremain valid even after being transmitted to remote threads.Tobe speci.c, suppose thata threadisexecutinga \nchannel write a!M where a is a channel for a certain type A and M is a term of the same type A. Evaluating \nM yields a value V which is then transmitted to another thread executing a channel read a ?. Type safety \nof channels means thatV contains no references and that V is valid at both threads regardless of its \ntype A. Conventional type systems, however, are inadequate to guaran\u00adtee type safety of channels. The \ncrux of the problem is that a typi\u00adcal typing judgment M : A does not indicate whether the result of \nevaluating M contains references or not.Forexample,a term (.v :int. .x: int.x + v)0 of type int . int \nevaluatestoavalue containingno reference,but another term (.r : ref int. .x :int.x +!r)(ref 0) of the \nsame type evaluates to a value containing a reference. In order to guarantee type safety of channels, \ntherefore, we need at least two kinds of typing judgments: an ordinary typing judgment asserting that \na given term evaluates to a value that may contain references, or a local value, and another stronger \ntyping judgment asserting that a given term evaluates to a value containing no refer\u00adences, or a global \nvalue. Ourworkis basedonthetype systeminourpreviouswork(Park 2006) which uses two typing judgments to \ndistinguish between lo\u00adcal values and global values in the context of distributed compu\u00adtations.We simplifythetype \nsystemby combiningthetwo typing judgments into a single typing judgment M : A@L where L is a lo\u00adcality \nindicating whether the value to which M evaluates is local (L = L)or global(L = G). The connection between \ntwo localities G and L is establishedbya new construct box M and a modal type DA such that M : A@G implies \nbox M : DA@L (i.e., if M evalu\u00adates to a global value of type A, then box M has type DA). Now a channel \nwrite a ! M typechecks only if M : A@G holds.Asa result, a channel read a? always returnsa globalvalue \nand thus a ?: A@G automatically holds. 1.2 Channel locality The type system developed for higher-order \nchannels makes it easy to achieve an important feature of task parallelism, channel locality, which states \nthatevery channelis associated witha unique threadfor readingoffallvalues senttoit. Channel localityobviates \nthe need for a sophisticated mechanism in the runtime system for dynamically determining the destination \nof each value written to a channel. Most of the previous approaches to enforcing channel local\u00adity (Fournet \net al. 1996; Amadio 1997; Yoshida and Hennessy 1999; Schmitt and Stefani 2003) have been developed for \ncalculi for concurrent processes based on the pi-calculus. We .nd that these approaches are dif.cult \nto apply to our setting which uses as a base language the simply-typed lambda calculus with mutable references \ninstead of the pi-calculus or its variant. The main idea for achieving channel locality in our work is \nto split channels into two kinds, read channels and write channels, and treat read channels as localvaluesbut \nwrite channels as global values.new(A),a construct for creating channels for type A,evalu\u00ad r wr ates \nto a pair of read channel a and write channel a such that a accepts only those values written to a w \n. Since a r is alocal value, channel reads from a r are allowed only at the thread where a r is created. \nChannel writes to a w are, however, allowed at anythread because a w isaglobalvalue. Thusapairof a r \nand a w can open uni\u00addirectional communications from anythread to the thread to which a r belongs. It \nis easy to classify read channels as local values and write channels as global values. First we assign \ndifferent types, namely read channel types and write channel types, to read channels and write channels, \nrespectively. Then we treat read channel types like reference types so that read channels cannot be part \nof a global value,but de.ne write channel types as primitive types whoseval\u00adues are all inherently global \n(like integers).For this reason, our de\u00adcision to distinguish between read channels and write channels \nhas a different motivation from previous work in which read channels and write channels are also distinguished, \nbut channel locality is not enforced (Odersky1995) or enforced only syntactically (Zhang and Potter 2002). \n 1.3 Contributions We develop an ML-like parallel language.PC b which features type\u00adsafe higher-order \nchannels with channel locality. Its type system in\u00adheritsfromthetype systemof(Park2006)the abilityto \ndistinguish between local values and global values. Its operational semantics models parallel computations \nwhere multiple threads communicate via higher-order channels. Channel locality is a direct consequence \nof assigningdifferenttypestoread channelsandwrite channels.To the best of our knowledge, type-safe higher-order \nchannels in the presence of mutable references have not been investigated. Although .PC b deals primarily \nwith type safety for task paral\u00adlelism, providing type safety for data parallelism is also straight\u00adforward \nby virtue of its ability to distinguish between local values and globalvalues.Asanexample, consideraparallelmap \nconstruct mapP which applies a function f to each element of an array in parallel. By requiring that \nf be a global value so that child threads share no references, we can prevent mapP from running into \nthe memory consistencyproblem. In this regard, .PC b serves as a uni\u00ad.ed framework for achieving type \nsafety for both data parallelism and task parallelism when mutable references are allowed. Removing mutable \nreferences simpli.es the implementation of a parallel language because lack of mutable references implies \nautomatic data separation in parallel computations. For example, Manticore (Fluet et al. 2007) excludes \nmutable references in its base language (a subset of Standard ML) in order to simplify its implementation. \nParallel dialects of Haskell, such as pH (Nikhil and Arvind 2001) and Data Parallel Haskell (Chakravarty \net al. 2007), also bene.t from lack of mutable references. In comparison, .PC b permits mutable referencesin \nsequential computations,but its type system ensures that mutable references never interfere with parallel \ncomputations. Thus the type system of .PCwins us both b .exibility in sequential programming and ease \nof implementing parallel computations.  1.4 Organization of the paper Section2 presents the base language \n.b for our work. Although the type system differentiates global values from local values, .b is just \na sequential language to which global values are of no use. Hence we develop a parallel operational semantics \nfor modeling parallel computations. Section 3 presents the resultant language .P b which comes with a \nnew construct spawn M for creating new threads. Section4extends .P b with new constructs for higher-order \nchannels to obtain .PC b . Section5illustrateshowto implementvari\u00adous communication constructs in .PC \nb such as futures, bidirectional communications, shared references, remoteevaluation, code on de\u00admand, \nand hot code replacement. Section 6 discusses two exten\u00adsions of .PC b (including type safety for data \nparallelism). Section7 discusses relatedwork and Section8concludes. type A, B, C ::= unit | A . A | \nA \u00d7 A | A+A | ref A | D A primitive type P term M, N ::= x | .x : A. M | MM | (M, M) | fst M | snd M \n| inl M | inr M | case M of inl x . M | inr x . M | () | .x x :A. M | ref M | !M | M := M | l | box M \n| letbox x = M in M value V ::= () | .x: A. M | (V,V ) | inl V | inr V | l | box M locality L ::= G \n| L typing context G ::= \u00b7| G,x : A@L store . ::= \u00b7| ., l . V store typing . ::= \u00b7| .,l . A Figure 1. \nAbstract syntax for .b 2. Base language .D This section presents the base language .b which is a reformu\u00adlation \nof the call-by-value language with modal types DA in our previous work (Park 2006). In the previous work, \nwe use two sep\u00adarate typing judgments to distinguish between local values (which may contain references) \nand global values (which contains no ref\u00aderences): an ordinary typing judgment M : A to mean that M eval\u00aduates \nto a local value, and a stronger typing judgment M ~ A to mean that M evaluatesto globalvalue.We combinethetwo \ntyping judgments intoasingle typing judgment M : A@L wherealocality L, either L or G, indicates whether \nM evaluates to a local value or a global value. The simpli.cation of typing judgments is essential to \nmaintaining the complexity of the type system at a manageable level. For example, the introduction of \nsum types requires eight new typing rules in the type system of (Park 2006) whereas the base language \n.b here uses only three typing rules. 2.1 De.nition of .b Figure 1 shows the abstract syntax for .b \nwhich is based on the simply-typed .-calculus with product types A \u00d7 A, sum types A+A, reference types \nref A, and the .xed point construct .x x:A. M.(We will de.ne the set of primitive types later.) ref M \nallocates a fresh reference, !M dereferences an existing reference, and M := N assignsa newvalue toa \nreference.A location l, of type ref A,isavalue fora reference.A new construct box M has a modal type \nDA, and another new construct letbox x = M in N expects M to be of type DA. Weuseatyping judgmentG | \n. f M : A@L to mean that under typing context G and store typing ., term M evaluates to a value of type \nA with locality L. The resultant value is local if L = L and global if L = G. (That is, L means here \nonly and G everywhere. )Abinding x : A@L inatyping context G means that x holds a local value of type \nA if L = L, or a global value of type A if L = G.Astore . maps locations to values, and a store typing \n. maps locationsto typesof thesevalues.We assume a relation G < L to re.ect thefact thata globalvalue \nmaybe used asa local value,but not viceversa. Figure2showsthetype systemof .b. The rule Var uses L = \nL' to mean either L = L' or L < L'. The rules .I through Loc are all derived from typing rules in the \nsimply-typed .-calculus by annotating each typing judgment withalocality L. Each of the rules \u00d7I, \u00d7EL, \nand \u00d7ER for product types uses the same unspeci.ed locality L in its premise and conclusion. Note that \nthese rules make sense only under the call-by-value semantics where (M, N) is a value only when both \nM and N are also values. If (M, N) is considered as a value for any two terms M and N, for example, all \nthese rules become incorrect when L = G. Similarly the rules +IL,+IR, and+E for sum types make sense \nonly under the call-by\u00advalue semantics. The modality D has an introduction rule DI which states that \nM in box M alwaysevaluatestoa globalvalue.The conclusionofthe rule DI uses a locality L because box M \nitself may not be a global value if M contains references.Forexample,if l is a location of type ref int, \nbox !l is not a global value although it has a modal type Dint. The elimination rule DE uses an unspeci.ed \nlocality L in the conclusion because M in letbox x = M in N does not specify whether N evaluatestoalocalvalueora \nglobalvalue.That is, regardless of the type of M, the value to which N evaluates can still be either \nlocal or global. The rule GVal is the main rule for connecting the two localities L and G. Its premise \nuses the following de.nition of GG which extracts bindings for variables holding global values from G: \nGG = {x : A@G | x : A@G . G} Then the premise GG |\u00b7f V : A@L states that V isavalue that uses no local \nvalues (because of GG)and no references (because of an empty store typing); hence V is a mobile value. \nSince V is already avalue andthus requires no furtherevaluation, we may say that V evaluates to a global \nvalue, which is expressed in the conclusion G | . f V : A@G. The rule Prim uses the notion of primitive \ntype to provide another way to connect the two localities L and G. A type is primitiveifallitsvalues \nare inherently mobile.Forexample, unit is a primitive type because its only value, (), typechecks under \nany typing context and store typing, as shown in the rule Unit. (Other examples of primitive types would \nbe int for integers and bool for booleanvalues.)Formally we de.ne primitive types as follows: De.nition \n2.1. P is a primitive type if G | . f V : P@L implies GG |\u00b7f V : P@L. Then terms of primitive types always \nevaluate to mobile values, and G | . f M : P@L automatically implies G | . f M : P@G as shown in the \nrule Prim. Under the type system in Figure 2, the rule Unit justi.es the use of unit as a primitive type. \nIn addition, P1 \u00d7 P2 and P1 +P2 are primitive types if both P1 and P2 are primitive types, since values \nof product type P1 \u00d7 P2 have the form (V1,V2), and values of sum type P1 +P2 have the form inl V or inr \nV . Thus we use the following set of primitive types for .b: primitive type P ::= unit | P \u00d7 P | P +P \nProposition 2.2 justi.es the relation G < L. Proposition 2.2. G | . f M : A@G The rule Global is admissible. \nG | . f M : A@L x : A@L . G L = L ' G,x : A@L | . f M : B@L G | . f M : A . B@L G | . f N : A@L Var \n.I .E G | . f x : A@L' G | . f .x: A. M : A . B@L G | . f MN : B@L G,x : A@L | . f M : A@L G | . f M \n: A@L Unit Fix Ref G | . f () : unit@L G | . f .x x:A. M : A@L G | . f ref M : ref A@L G | . f M : ref \nA@L G | . f M : ref A@L G | . f N : A@L .(l)= A Drf Asn Loc G | . f !M : A@L G | . f M := N : unit@L \nG | . f l : ref A@L G | . f M : A@L G | . f M : B@L G | . f M : A \u00d7 B@L G | . f M : A \u00d7 B@L \u00d7I \u00d7EL \u00d7ER \nG | . f (M, N): A \u00d7 B@L G | . f fst M : A@L G | . f snd M : B@L G,x : A@L' | . f N : C@L G | . f M : \nA@L G | . f M : B@L G | . f M : A+B@L' G,x ' : B@L' | . f N ' : C@L +IL +IR +E G | . f inl M : A+B@L \nG | . f inr M : A+B@L G | . f case M of inl x . N | inr x ' . N ' : C@L G | . f M : A@G G | . f M : DA@L \nG,x : A@G | . f N : C@L DI DE G | . f box M : DA@L G | . f letbox x = M in N : C@L GG |\u00b7f V : A@L G | \n. f M : P@L GVal Prim G | . f V : A@G G | . f M : P@G Figure 2. Type system of.b evaluation context f \n::= [] | fM | Vf | (f, M) | (V, f) | fst f | snd f |inl f | inr f | case f of inl x . M | inr x . M ref \nf | !f | f := M | V := f | (.x: A. M) V .x x :A. M letbox x = box V in M fresh l . dom(.) .\u00df .\u00df .\u00df letbox \nx = f in M | letbox x = box f in M [V /x]M fst (V, V ' ) [.x x : A. M/x]M snd (V, V ' ) [V /x]M case \ninl V of inl x . M | inr x ' . M ' case inr V of inl x . M | inr x ' . M ' M .\u00df M ' f[ M] | . . f[ M \n' ] | . R\u00df Ref .(l) = V Drf .\u00df .\u00df .\u00df .\u00df V V ' [V /x]M [V /x ' ]M Asn ' f[ ref V ] | . . f[ l] | ., l \n. Vf[ !l] | . . f[ V ] | .f[ l := V ] | . . f[ ()]] | [l . V ]. Figure 3. Operational semantics for .b \nFigure 3 shows the operational semantics for .b. It uses a reduction judgment M | . . M ' | . ' which \nmeans that term M with store . reduces to term M ' with store . '.A \u00df-reduction M .\u00df M ' uses a capture-avoiding \nsubstitution [N/x]M de.ned in a standard way. f[ M] .lls the hole [] in evaluation context f with term \nM. [l . V ]. replaces l . V ' in store . by l . V . .(l) denotes the value to which l is mapped under \n.; dom(.) denotes the set of locations mapped under .. Since letbox x = box f in N is an evaluation context, \nletbox x = box M in N furtherevaluates M so as to substitute the resultant value for x in N, even though \nbox M is already a value. Thus letbox x = M ' in N .rst evaluates M ' to identify how to obtainavaluetobe \nsubstitutedfor x, and then obtains such a value by evaluating M, if M ' evaluates to box M. Since M evaluates \nto a global value, all occurrences of x in N become bound to a global value, as required by the rules \nDE.  2.2 Type safety of.b The proof of type safety of .b needs a store typing judgment . f . okay which \nmeans that store . conforms to store typing .. .(l) denotes the type to which l is mapped under .;dom(.) \ndenotes the set of locations mapped under .. for every l . dom(.) dom(.) = dom(.) \u00b7| . f .(l) : .(l) \n @L Store . f . okay The proof of progress (Theorem 2.3) uses a canonical forms lemma, as usual. The \nproof of type preservation (Theorem 2.6) uses a substitution theorem (Theorem 2.4). It also uses Lemma \n2.5 whose proof uses the de.nition of primitive types (De.nition 2.1). Theorem 2.3 (Progress). Suppose \n\u00b7| . f M : A@L. Then either: (1) M is a value, or (2) for any store . suchthat . f . okay, there exist \nsome term M ' and store . ' suchthat M | . . M ' | . ' . Theorem 2.4 (Substitution). If G | . f N : A@L, \nthen G,x : A@L | . f M : C@L implies G | . f [N/x]M : C@L. If GG |\u00b7f V : A@L, then G,x : A@G | . f M \n: C@L implies G | . f [V/x]M : C@L. term M ::= \u00b7\u00b7\u00b7 | spawn M evaluation context f ::= \u00b7\u00b7\u00b7 | spawn f | \nspawn box f thread . con.guration p ::= \u00b7| p, {M | . @ .}con.guration typing . ::= \u00b7| .,. : A G | . f \nM : D(unit . A)@L Spawn G | . f spawn M : unit@L for each {M | . @ .}. p, there exist A. , .. such that \ndom(.) = dom(p) . : A. . . .. f . okay \u00b7| .. f M : A. @L Conf. f p okay M | . . M ' | . ' Red p, {M | \n. @ .}. p, {M ' | . ' @ .} fresh . ' Spawn p, {f[ spawn box V ] | . @ .}. p, {f[ ()]] | . @ .}, {V () \n|\u00b7 @ . ' } Figure 4. De.nition of .P b Lemma 2.5. If \u00b7| . f V : A@G, then \u00b7|\u00b7f V : A@L. Proof. Byinduction \non the structure of the proof of\u00b7| . f V : A@G. We need to consider the rulesPrim, GVal, \u00d7I,+IL, and+IR. \nIn the case of the rule Prim,\u00b7| . f V : A@L holds where A isaprimitive type, and \u00b7|\u00b7f V : A@L follows \nby De.nition 2.1. Theorem 2.6 (Type preservation). Suppose \u00b7| . f M : A@L,. f . okay,andM | . . M ' | \n. ' . Then there exists a store typing . ' such that \u00b7| . ' f M ' : A@L, . . . ', and . ' f . ' okay. \n3. .P D with a parallel operational semantics Although its type system uses localities and modal types \nto differ\u00adentiate global values from local values, .b is just a base language for sequential computations \nto which global values are of no use. That is, its operational semantics focuses only on the sequential \ncomputation at a hypothetical thread and there is no way to ex\u00adploit global values for communications \nbetween threads. This sec\u00adtionextends .b withaparallel operational semantics which models multiplethreads \nrunning concurrently(but not communicating with each other yet). The resultant language is called .P \nb. Figure4 shows the de.nition for .P b b. At the syntax level, .P augments .b with a new construct spawn \nM whose typing rule Spawn requires M to be of type D(unit . A). spawn M starts a fresh thread with an \nempty store by evaluating a term obtained as follows. Firstitevaluates M to obtain box M '. Thenitevaluatesthe \ninner term M ' (as indicatedbytheevaluation context spawn box f) to obtain . : unit.M '' (or a similar \nform of thunk). Since box M ' has type D(unit . A), M ' evaluates to a global value, which means that \n. : unit.M '' contains no references. Therefore it is safe to evaluate (. : unit.M '' ) () at a fresh \nthread with an empty store, which effectively starts to evaluate M '' at the fresh thread. In a realistic \nlanguage, we could use syntactic sugar spawnT {M}de.ned as spawn box . : unit.M in orderto startafresh \nthreadby evaluating M without such intervening evaluations: GG |\u00b7f M : A@L SpawnTerm G | . f spawnT {M} \n: unit@L Note that the premise GG |\u00b7f M : A@L implies G | . f box . : unit.M : D(unit . A). @L Acon.guration \np, as an unordered set, represents the state of a parallel computation by associating each thread . with \na term M being evaluated at . and a store . allocated at ., written as {M | . @ .}.Acon.guration typing \n. records the type of the termbeingevaluatedateach thread.Thetypesystemof .P b uses the sametyping judgment \nas .b,except thatit also usesacon.guration typing judgment . f p okay to mean that con.guration p has \ncon.guration typing .. The rule Conf may be regarded as the de.nition of the con.guration typing judgment, \nwhere dom(.) and dom(p) denote the set of threads in . and p, respectively. Note that for each thread \n. such that {M | . @ .}. p, it infers a store typing .. by typechecking all locations present in M and \n.. The parallel operational semantics uses a con.guration transi\u00adtion judgment p . p ' to mean that con.guration \np reduces (by the rule Red)or evolves (by the rule Spawn)to con.guration p ' . The rule Red says that \na parallel computation consists primarily of sequential computations performed at individual threads. \nThe rule Spawn starts a new thread . ' by evaluating V (). Since box V guarantees that V is a global \nvalue, it is safe to evaluate V () with an empty store at . '. Note that a con.guration transition is \nnon-deterministic because a con.guration may choose an arbitrary thread to which either rule is applied. \nType safety of .b P consists of con.guration progress (Theo\u00adrem 3.1) and con.guration typing preservation \n(Theorem 3.2). It is a corollary of type safety of .PC to be presented in the next sec\u00ad b tion. Theorem \n3.1 (Con.guration progress). Suppose . f p okay. Then either: (1) p consists only of {V | . @ .}, or \n (2) there exists p ' suchthat p . p ' .  Theorem 3.2 (Con.guration typing preservation). Suppose . \nf p okay and p . p '. Then thereexistsacon.guration typing . ' suchthat . . . ' and . ' f p ' okay. .PC \n4. with higher-order channels D This section extends .P b . b with higher-order channels to obtain .PC \nIn order to achieve channel locality, .PC splits channels into two b kinds: read channels and write channels. \nA read channel a r is assigned a read channel type (A)r , and is treated as a local value so that it \ncannot escape the thread at which it is created.A write channel a w is assigned a write channel type \n(A)w , and is treated as a global value so that it can be transmitted to another thread. Since values \nwritten to write channels travel between threads, they cannot be local values. That is, only global values \nare allowed to be written to write channels, and consequently all values read from read channels are \nalso global. Figure 5 shows the de.nition for .PC of b . A read channel a r type (A)r receives a global \nvalue of type A from its corresponding write channel a w via a channel read a r ?.A write channel a w \nof type (A)w transmitsaglobalvalue V of type A to its corresponding read channel a r viaachannel write \na w !V .Anewconstruct new(A)dynamically createsapairofread channel a r and write channel a w w rr to \nopen unidirectional communications from a to a . a . A in a read channel typing Fr means that a r has \ntype (A)r ;similarly a w . A in a write channel typing Fw means that a w has type (A)w . The type system \nof .PC uses a read channel typing Fr and a b write channel typing Fw in each typing judgment: G | Fw \n;Fr ;. f M : A@L type A ::= \u00b7\u00b7\u00b7 |(A)r |(A)w term M ::= \u00b7\u00b7\u00b7 | new(A) | a r | a w | M ? | M ! M value \nV ::= \u00b7\u00b7\u00b7 | a r | a w evaluation context f ::= \u00b7\u00b7\u00b7 | f? | f!M | V ! f read channel typing ::= \u00b7| Fr ,a \nr . A Fr Fw write channel typing ::= \u00b7| Fw ,a w . A GG | Fw ; \u00b7; \u00b7f V : A@L GVal New G | Fw ;Fr ;. \nf V : A@G G | Fw ;Fr ;. f new(A) : (A)r \u00d7(A)w @L a r . A . Fr a w . A . Fw r ChanR w ChanW G | Fw ;Fr \n;. f a : (A)r G | Fw ;Fr ;. f a : (A)w @L @L G | Fw ;Fr ;. f M : (A)r G | Fw ;Fr ;. f M : (A)w G | Fw \n;Fr ;. f N : A@G @L @L R?(L = G or L = L) W! G | Fw ;Fr ;. f M ?: A@L G | Fw ;Fr ;. f M ! N : unit@L \nfor every l . dom(.) dom(.) = dom(.) \u00b7| Fw ;Fr ;. f .(l) : .(l) @L Store Fw ;Fr ;. f . okay for each \n{M | . @ .}. p, there exist A. , Fr . , .. such that . : A. . . Fw ;Fr . ;.. f . okay if . = . ' , dom(.) \n= dom(p) \u00b7| Fw ;F. r ;.. f M : A. @L F. r n F. r ' = \u00d8 Conf Fw ;. f p okay fresh (a r ,a w ) New rw \nSync p, {f[ new(A)] | . @ .}. p, {f[ a ?]] | . @ .}, {f ' [ a ! V ] | . ' @ . ' }. rw p, {f[ (a ,a )]] \n| . @ .} p, {f[ V ] | . @ .}, {f ' [ ()]] | . ' @ . ' } Figure 5. De.nition of .PC b All the previous \ntyping rules are extended in a straightforward way by adding Fr and Fw to each typing judgment. The onlyexception \nis the rule GVal whose premise(GG | Fw ; \u00b7; \u00b7f V : A@L)uses an empty read channel typing because read \nchannels are local values. Accordingly we rede.ne primitive types as follows: De.nition 4.1. P is a primitive \ntype if and only if G | Fw ;Fr ;. f V : P@L implies GG | Fw ; \u00b7; \u00b7f V : P@L. Under the new de.nition \nof primitive types, a write channel type (A)w becomes a primitive type (see the rule ChanW): primitive \ntype P ::= \u00b7\u00b7\u00b7 |(A)w The rule R? uses an unspeci.ed locality L in the conclusion so that Proposition \n2.2 continues to hold. The rule W! says that channel writes accept only global values. The rule Store \nuses an extended store typing judgment Fw ;Fr ;. f . okay to check that store . conforms to store typing \n. under Fr and Fw . The rule Conf is of particular importance in .PC because it b veri.es channel locality \nin a given con.guration. Note that an extended con.guration typing judgment Fw ;. f p okay shares a write \nchannel typing Fw for all threads (because write channels are globalvalues),but does not assumea speci.c \nread channel typing. Instead, for each thread . such that {M | . @ .}. p, it infers a unique read channel \ntyping Fr . ,in additiontoastore typing .. ,by typechecking all read channels present in M and .. The \nuniqueness of Fr . for each thread ., as stated in the third premise, implies that no two threads share \ncommon read channels, and thus amounts to channel locality in p. The parallel operational semantics uses \nthe same con.guration transition judgment p . p ' as in .bP . The premise of the rule New means that \nread channel a r and write channel a w are unique across the entire set of threads. The rule Sync says \nthat a channel read a r ? and a channel write a w ! V occur synchronously. (An asynchronous version of \n.PC would require a different parallel b operational semantics, but the same type system would continue \nto work.) As with .P b, type safety of .PC consists of con.guration b progress (Theorem 4.3) and con.guration \ntyping preservation (Theorem 4.5). Proofs of Theorems 4.3 and 4.5 use type safety for .PC sequential \ncomputations in (Propositions 4.2 and 4.4). Note b that in Theorem 4.5, a con.guration transition p . \np ' preserves channel locality because of the use of extended con.guration typ\u00ading judgments. Proposition \n4.2 (Progress). Suppose \u00b7| Fw ;Fr ;. f M : A@L. Then either: (1) M is a value, (2) M = f[ new(A)] , \n(3) M = f[ a r ?]], (4) M = f[ a w ! V ] ,  (5) M = f[ spawn box V ] , or (6) for any store . such \nthat Fw ;Fr ;. f . okay, there exist some term M ' and store . ' suchthat M | . . M ' | . ' . Theorem \n4.3 (Con.guration progress). Suppose Fw ;. f p okay. Then either: (1) p consists only of {V | . @ .}, \n{f[ a r ?]] | . @ .}, {f[ a w !V ] | . @ .}, or  (2) there exists p ' suchthat p . p ' .  Proposition \n4.4 (Type preservation). Suppose \u00b7| Fw ;Fr ;. f M : A@L, Fw ;Fr ;. f . okay, and M | . . M ' | . '. Then \nthere exists a store typing . ' such that ' f . ' \u00b7| Fw ;Fr ;. ' f M : A@L, . . . ', and Fw ;Fr ;. ' \nokay. Theorem 4.5 (Con.guration typing preservation). Suppose Fw ;. f p okay and p . p ' . Then there \nexist a write channel typing F 'w and a con.guration typing . ' suchthat Fw . F 'w , . . . ', and F 'w \n;. ' f p ' okay. 5. Examples This section presents examples of implementing various commu\u00adnication constructs \nin .PC b : futures, bidirectional communications, shared references, remote evaluation, code on demand, \nand hot code replacement. Throughout the examples, we use the following syntactic sugar: let x = M in \nN = (.x: .N) M let (x, y)= M in N = let z = M in let x = fst z in let y = snd z in N let rec x = M in \nN = let x = .x x : .M in N We also use syntactic sugarspawnT {M} de.ned in Section 3. 5.1 Futures Afuture \n(Halstead, Jr. 1985) is a communication construct which can be thought of as a pointer to a thread. After \nthe thread .nishes its computation, the pointer may be dereferenced to obtain the result. Below we simulate \nfutures using read channels. In order to create a future, we .rst need to evaluate a term M at a fresh \nthread. Since M is to be evaluated at a remote thread, it must contain no references.We implement the \nfuture with a read channel a r such that the result of evaluating M is written to the corresponding write \nchannel a w . Since a channel write entails a communication between threads, M mustevaluatetoaglobalvalue \n(in accordance with the rule W!). Hence future, our construct for futures, expects a value of type DDA, \nsay box box M, and returns a read channel of type (A)r to which the result of evaluating M is sent: future \n: DDA .(A)r @G future = .x : DDA. letbox x ' = x in let (yr,yw)= new(A) in ' letbox yw = box yw in let \n= spawnT {letbox z = x ' in y ' ! z} in w yr 5.2 Bidirectional communications Communications from a \nchild thread back to its parent thread are easy to implement because write channels are global values \n we start the child threadbyevaluatingaterm containing write channels whose correspondingread channelsbelongtotheparent \nthread.For communications in the other direction, however, the child thread needstosomehowreturnawrite \nchanneltothe parent thread, which can be done only via another write channel originating from the parent \nthread. Thus, in order to receive a write channel of type (A)w from a child thread, the parent thread \ncreates a pair of read channel a r of type ((A)w )r and write channel a w of type ((A)w )w . Then the \nchild thread is passed a w , through which a write channel of type (A)w is sent to the parent thread. \nWe design spawn BI, our construct for bidirectional commu\u00adnications (or for unidirectional communications \nfrom a parent thread to a child thread), in such a way that given a value of type D((A)r . C), say box \n.xr :(A)r .M, it creates a child thread evaluating M with xr bound toa readchannel a r of type (A)r and \nreturns a corresponding write channel a w to the parent thread: spawn BI : D((A)r . C) .(A)w @G BI spawn \n= .z : D((A)r . C). let (xr,xw)= new((A)w ) in letbox xw ' = box xw in letbox z ' = z in let = spawnT \n{ let (yr,yw)= new(A) in let = x ' w !yw in z ' yr } in xr ? Note thatby the rule Sync, the channel write \nx ' blocks the w ! yw child thread until it synchronizes with the corresponding channel read xr ?. Thus \nthe evaluation of z ' yr, the core of the child thread, may not start immediately after new(A) returns \na pair of read and write channels. To start the evaluation of z ' yr immediately, the child thread could \ndelegate the channel write to another newthread. In general, a channel write M !N canbe replacedby the \nfollowing term which spawns a new thread for performing the channel write and returns immediately (unlessanevaluationof \nM or N gets stuck with a channel read or a channel write): letbox xM = box M in letbox xN = box N in \nspawnT {xM !xN } The same idea can be applied to all instances of channel writes in the examples below. \n 5.3 Shared references We implement a shared reference for typeA as a thread with two components: a read \nchannel of type ((A)w +A)r , as an interface, and a global value of type A, as its current content. Any \nthread may requestthe current contentofthe referenceby sendingavalue inl a w (of type (A)w +A)to the \nread channel, in which case the current content is written back to a w .To update the content of the \nreference,it sendsavalue inr V (also of type (A)w +A)to the read channel, in which case the current content \nis updated with a new value V . As an illustration, we use spawn BI to create a shared reference for \ntype int initialized with a value of 0: let cellw = BI spawn box .cellr :((int)w +int)r . let rec f = \n.n : int. case cellr ? of inl chw . let = chw !n in fn | inr v . fv in f 0 Then we use a write channel \nin cellw to implement get, of type unit . int, for requesting the current content of the reference and \nset, of type int . unit, for updating the content of the reference; note that each call to get creates \na fresh pair of read channel and write channel: letbox cell ' = box cellw in w letbox get = box . :unit. \nlet (xr,xw)= new(int) in let = cell ' !(inl xw) in w xr ? in letbox set = box .n : int. cell w ' !(inr \nn) in (get, set) Since both get and set are globalvalues,theymaybe presentatany thread,which meansthatthe \nreferencecanbesharedbyall threads. 5.4 Remote evaluation Remote evaluation (Stamos and Gifford 1990) \nis a mechanism for exploitingasetof servicesexportedbyaserverina.exibleway.A client sends to the server \na program whose execution by the server may invoke these services. That is, it sends not arguments for \nthese services but a program utilizing these services. We demonstrate howto implement remoteevaluationin \n.PC b witha server providing a service for calculating the successor of an integer. We use a write channel \nof type(int \u00d7(int)w )w as an interface to the service. The idea is that the service responds to (n, a \nw ) written to the write channel by writing n +1 back to a w .A call to spawn BI with the following global \nvalue Vservice as an argument starts the service and returns its interface: Vservice : D((int \u00d7(int)w \n)r . unit) @G Vservice = box .sr :(int \u00d7(int)w )r . let rec f = . : unit. let (n, ch)= sr ? in let = \nch !(n + 1) in f () in f () The following term starts the server and returns its interface which is a \nwrite channel reqof type ((int \u00d7(int)w )w . unit)w . w Since reqw is a global value, any client can use \nthe service by sending a global value .s : (int \u00d7(int)w )w .M, upon receiving which the server binds \ns tothe interfacetothe serviceandevaluates M: let reqw = BI spawn box .reqr : ((int \u00d7(int)w )w . unit)r \n. let sw = spawn BI Vservice in let rec f = . : unit. let =(reqr ?) sw in f () in f () Here is an example \nof a client which calculates the successor of the successor of 0. Note that it sends a global value f \nto the server only once while the server invokes the service twice. The client waits for the result by \nperforming a channel read cr ?. let (cr,cw)= new(int) in letbox cw ' = box cw in letbox f = box .s :(int \n\u00d7(int)w )w . let (chr, chw)= new(int) in let = s !(0, chw) in let = s !(chr ?, chw) in let = c ' !(chr \n?) in w () in let = reqw ! f in cr ?  5.5 Code on demand Codeon demandisthe opposite mechanismof remoteevaluationin \nthata client candownload code froma code server insteadof send\u00ading code to a remote server. As an example, \nwe implement a code server which, upon request, returns the globalvalue Vservice of type D((int \u00d7(int)w \n)r . unit) given in Section 5.4. It expects from a client a write channel of type (D((int \u00d7(int)w )r \n. unit))w , to which Vservice is sent back: let reqw = BI spawn box .req: ((D((int \u00d7(int)w )r . unit))w \n)r . r let rec f = . : unit. let =(reqr ?)! Vservice in f () in f () The following client downloads \nVservice and starts the service for its own use: let (cr,cw)= new(b((int\u00d7(int)w )r .unit)) in let = reqw \n! cw in BI (cr let sw = spawn ?) in let (chr, chw)= new(int) in let = sw !(0, chw) in chr ?  5.6 Hot \ncode replacement The capability to transmit code between threads enables us to implement a server whose \ncode can be replaced at runtime without stopping it. The following term starts a server which accepts \na pair of integer n and write channel ch and writes to ch the result of applyinga certain function f \nto n. Initially f isgiven as an identity function,but we can change the behavior of the server at runtime \nby performing a channel write sw !(inr fnew ) for a certain global value fnew of type int . int. let \nsw = BI spawn box .sr :((int \u00d7(int)w )+(int . int))r . let rec loop = .f : int . int. case sr ? of inl \n(n, ch) . let = ch !(fn) in loop f | inr fnew . loop fnew in loop (.x:int.x) 6. Extensions to .PC D This \nsection discusses two extensions to .PC b . As it is routine to incorporate these extensions into the \nde.nition of .PC b , we only sketch the main ideas and omit the details. 6.1 Local threads Consider two \nread channels a r 1 and a r 2 (of the same type (A)r ) belonging to different threads .1 and .2, respectively. \na r 1 wishes to forward every incoming message V to a2 r with a channel write ww r a2 !V where a2 is \na write channel corresponding to a2. (As write w channels are global values, we assume that a2 has already \nbeen transmitted to thread .1.) An easy solution is to call the following rw construct forward with arguments \na1 and a2 at thread .1: forward : (A)r . ((A)w . unit) @G forward = .x : (A)r . .y :(A)w . let rec f \n= . : unit. let = y !(x?) in f () in f () The problem with such a call to forward is that thread .1 goes \ninto an in.nite loop and degenerates to a trivial thread that only repeats a channel read x ? followed \nby a channel write y !(x?). Hence a better solution would be to spawn a separate thread with a rw callto \nthe following construct forward ' with arguments a1 and a2 : forward ' : (A)r . ((A)w . unit)@G forward \n' = .x: (A)r . .y : (A)w . letbox x ' = box x in (* does not typecheck*) letbox y ' = box y in spawnT \n{ let rec f = . : unit. let = y ' !(x ' ?) in f () in f ()} Unfortunately forward ' fails to typecheck \nbecause a read channel of type (A)r cannot be a global value. Instead of spawning an ordinary thread, \ntherefore, we spawn a rw local thread that starts by evaluating forward a1 a2 . The underly\u00ading assumptionisthatathread \nconsistsofoneor morelocal threads running concurrently which share both the storeandreadchannels. (There \narises the memory consistency problem, but it is a sepa\u00adrate issue.) Hence both references and read channels \ncan be part ofa termfor creatinganew local thread.In otherwords,asfaras creating local threads is concerned, \nboth references and read chan\u00adnels canbe regarded as globalvalues.Wedo not,however, allow communicationsof \nread channelseven between local threads, since the syntax for a channel write a w ! V does not indicate \nwhether the corresponding read channel a r resides at the same thread (in which case V may be another \nread channel) or at a remote thread (in which case V may not be another read channel). Thus channel writesstillexpectglobalvalueswhichdonot \nincluderead channels. Fournetetal.(1996)makeasimilar assumptionintheirstudyofthe distributed join-calculus: \nevery channel has a unique re.exive so\u00adlution, corresponding to a thread in .PC b , which may run multiple \nprocesses, corresponding to local threads in .PC b ;all these processes can interact with anymessage \naddressed to the channel. We introduce a new constructlthread {M} for creating a local thread that starts \nby evaluating M: term M ::= \u00b7\u00b7\u00b7 | lthread {M} Since local threads running at the same thread share references \nand read channels, lthread {M} typechecks whenever M typechecks: G | Fw ;Fr ;. f M : A@L LThread G | \nFw ;Fr ;. f lthread {M} : unit@L Now that a thread may run multiple local threads, the state of a thread \n. is represented by {M1, \u00b7\u00b7\u00b7 ,Mn | . @ .} where each term Mi, 1 = i = n, is being evaluated by a local \nthread. All the previous rules for con.guration transitions are ex\u00adtended in a straightforward way by \nrewriting {M | . @ .} as {M, M1, \u00b7\u00b7\u00b7 ,Mn | . @ .}. An exception is the rule Spawn which createsafresh \nthread consistingonlyofasingle local thread, as shown in Figure 6. A new rule Sync ' accounts for a channel \nread and a channel write occurring synchronously within the same thread .. Another new rule LThread evaluates \nlthread {M} to creates a fresh local thread. Now we rewrite forward by exploiting lthread: forward = \n.x: (A)r . .y : (A)w . lthread { let rec f = . : unit. let = y !(x?) in f () in f () } Another application \nof lthread is to simulate channels not subject to channel locality, i.e., channels that can be read from \nand written to at any thread. The idea is the same as in implementing shared references in Section 5.3 \nexcept that each channel read from cellr starts a new local thread. Here is an example of creating such \na channel for type int.We call read for channel reads and write for channel writes, both of which are \nglobal values and thus can be sharedby all threads. let cellw = BI spawn box .cellr :((int)w +int)r . \nlet (cr,cw)= new(int) in let rec f = . :unit. case cellr ? of inl chw . lthread {chw !(cr ?)} | inr v \n. lthread {cw !v} in f () letbox cell w ' = box cellw in letbox read = box . :unit. let (xr,xw)= new(int) \nin let = cell w ' !(inl xw) in xr ? in letbox write = box .x :int. cell w ' !(inr x) in (read, write) \n  6.2 Type-safe data parallelism The characteristic feature of the type system of .PC is to be able \nto b decide whether a given term evaluates to a global value or a local value. We can exploit this feature \nto provide type safety for data parallelism in .PC b , as illustrated below. Consider a parallel map \nconstruct mapP which applies a func\u00adtion f to each element of an array e in parallel: mapP fe The parent \nthread evaluating mapP fe spawns multiple child threads each of which applies f to an element of e.In \nordertoavoid the memory consistencyproblem, we require that f do not inherit references from the parent \nthread (because f may attempt to update such references). On the other hand, in order to provide more \n.exibility in programming, we allow f to allocate new references, which cannot be transmitted between \nchild threads and thus are safe to use. Checking if f satis.es the above two conditions is simple: we \njust test whether f is a global value or not. Note that although child threads do not share writable \ndata, they can still share read\u00adonly data because variables bound to global values can serve as shared \nread-only data. That is, if a binding x : A@G is available at the parent thread, all child threads may \nread variable x to obtain a global value. Aglobal valuef, however, does not protect against write chan\u00adnelsbeing \nsharedbychild threads.Aneasy solutionisto introduce another locality G* with a relation G* < G and the \nfollowing typ\u00ading rule GG* |\u00b7; \u00b7; \u00b7f V : A@L GVal ' G | Fw ;Fr ;. f V : A@G* where GG* = {x : A@G* | \nx : A@G* . G}. New constructs and types for G* can be designed in an analogous way to those for G. Then \na typing judgment f : A@G* ensures that f contains neither references nor write channels. 7. Related \nwork 7.1 Mutablereferencesin parallel or distributed languages As there is no de.nitive standard for \nshared memory model in par\u00adallel or distributed languages, different policies for mutable ref\u00aderences \nor similar constructs have been proposed. X10 (Charles et al. 2005) permits remote mutable variables \nbelonging to remote threads,but accessingthe contentsofa remote mutablevariable re\u00adsults in a runtime \nexception. Fortress (Allan et al. 2007) permits fresh . ' Spawn p, {f[ spawn box V ] ,M1, \u00b7\u00b7\u00b7 ,Mn | \n. @ .}. p, {f[ ()]],M1, \u00b7\u00b7\u00b7 ,Mn | . @ .}, {V () |\u00b7 @ . ' } rw Sync ' p, {f[ a ?]],f ' [ a !V ] ,M1, \u00b7\u00b7\u00b7 \n,Mn | . @ .}. p, {f[ V ] ,f ' [ ()]],M1, \u00b7\u00b7\u00b7 ,Mn | . @ .} LThread p, {f[ lthread {M}] ,M1, \u00b7\u00b7\u00b7 ,Mn | \n. @ .}. p, {f[ ()]], M, M1, \u00b7\u00b7\u00b7 ,Mn | . @ .} Figure 6. Con.guration transition rules for local threads \nshared objects accessibletoevery thread,butatthe costof implic\u00aditly maintaining the sharedness (either \nlocal or shared)of every object.Titanium (Hil.ngeretal. 2005), whichextendsJava,takes a different approachby \nallowing shared memory,but also distin\u00adguishing between local references and global references at the \ntype level.UPC (El-Ghazawietal.2003),whichextendsC,takesasim\u00adilar approach by using two kinds of pointers: \nprivate pointers and global pointers.Facile (Knabe1995)and JoCAML(Fournetetal. 2003) dispense with remote \nreferences by sending copies of heap cells whenever their references are transmitted to remote threads. \nErlang (Armstrong 1997) and Manticore (Fluet et al. 2007) do not use mutable references at all. .PC is \nsimilartoFacileand JoCAMLinthatitpermits mutable b referencesbut assumesno shared memory(andalsointhatitisa \ndialect of ML). The main difference is that Facile and JoCAML rely on the runtime systemtoavoid remote \nreferences whereas .PC b relies on the type system to forestall remote references.  7.2 Channel locality \nThe issue of channel locality has been studied mainly for the pi\u00adcalculus and its relatives. Amadio (1997) \ndevelops a type system for a fragment of the pi-calculus in which typing judgments use channels linearly \nto ensure channel locality. The distributed join\u00adcalculus(Fournetetal. 1996) assumesa syntactic restrictionto \nen\u00adforce channel locality. Speci.cally it considers only syntactically well-formed DRCHAMs (distributed \nre.exive chemical machines) in whichevery channelis de.nedinat most one RCHAM (re.exive chemical machine), \nwhereaDRCHAM correspondstoacon.gura\u00adtion and a RCHAM to a thread in .PC b . Schmitt and Stefani (2003) \npresentahigher-orderversionofthe distributedjoincalculus which usesapolymorphictypesystemto guaranteethatthe \ndestinationfor each message is uniquelydetermined. It achieves channel locality in a slightly different \nsense than in .PC because, for example, a b message may be intercepted before reaching its destination. \nThe dynamic join-calculus (Schmitt 2002) achieves channel locality in a similarvein,in whichthe destinationfora \nmessageis determined according to its current position. Yoshida and Hennessy (1999) present a calculus \nsimilar to.PC b in that it uses a type system to enforce channel locality. It combines the call-by-value \nlambda calculus and a higher-order extension of the pi-calculus, and allows processes themselves to be \ntransmitted via channels. The type system introduces sendable types whoseval\u00adues can be transmitted between \nprocesses without destroying chan\u00adnel locality, and exploits a subtyping relation to enforce channel \nlocality. The type system, however, is not a general solution appli\u00adcableto our settingfortworeasons. \nFirst thereisasemantic restric\u00adtions on function types which severely limits the generality of the calculus: \nfor a function type t . s, if s is sendable, t must also be sendable, in which case t . s is also automatically \nregarded as sendable. In our setting, such a restriction means, for example, that no term of type ref \nint . int or (int)r . int is even allowed and thatevery functionof type int . int must be global, neither \nof which is the case in .PC b . Second the type system ignores the call\u00adby-value semanticsof the underlying \nlambdacalculus. Speci.cally it includes a typing rule (TERMl)assigninga sendable type to a term whenever \nit typechecks under a typing context using sendable types only. In our setting, the typing rule would \ncorrespond to the following rule whichfails to comply with the call-by-value seman\u00adtics: GG | Fw ; \u00b7; \n\u00b7f M : A@L (wrong) G | Fw ;Fr ;. f M : A@G In comparison, .PC b imposes no syntactic or semantic restriction \non function types and properly accounts for the call-by-value seman\u00adtics in the presence of mutable references. \n 7.3 Splitting channels The idea of using two kinds of channels, namely read channels and write channels \n(or input channels and output channels), is not new. For example, the type system of (Pierce and Sangiorgi \n1993) can effectively distinguish between read channels and write channels because every channel is assigned \na tag indicating its usage (read, write, or both). The polarized pi-calculus of (Odersky1995) syn\u00adtactically \ndistinguishes between read channels and write channels. In the polarized pi-calculus, using read channels \nfor channel writes or write channels for channel reads results in no reaction with other processes. The \npolar pi-calculus of (Zhang and Potter 2002) also syntactically distinguishes between read channels and \nwrite chan\u00adnels with an additional requirement that only write channels can be transmitted via channels. \n.PC is, however, different from previous work in that it assigns b different types to different kinds \nof channels and exploits these types, instead of the syntax, to enforce channel locality. In fact, such \nnotions as local values, global values, and primitive types, all established in the base language .b, \nhave naturally led to the main idea for achieving channel locality in .PC b . Thus our decision to distinguish \nbetween read channels and write channels has a different motivation from previous work. 7.4 Modal typesfor \nparallel and distributed computations There are a few distributed languages (Murphyet al. 2004; Jia and \nWalker 2004) whose type systems are based on the spatial inter\u00adpretation of modal logic. Murphy et al. \n(2004) use the necessity modality . inmodaltypesforglobal termswhichcanbeevaluated at anynode in the \nnetwork, and the possibility modality . in modal types for references to local resources belonging to \ncertain nodes. Jia andWalker (2004) use . for the same purpose,but . in modal types for terms that can \nbe evaluated at certain nodes. Our earlier work(Park 2006) is the .rst departure from the typical spatial \ninterpretation of modal logic in that it uses a new modality D to focus on globalvalues rather than global \nterms. (See (Park 2006) for a discussion on logical properties of the modality D.For example, DA . A \nand DA . DDA are both inhabited, but D(A . B) . DA . DB is uninhabited if we ignore non\u00adterminating terms.) \nOur present work adds communication con\u00adstructs for higher-order channels,thereby providing improved \n.ex\u00adibility in programming for parallel and distributed computations. 8. Conclusion and future work We \npresent an ML-like parallel language.PC which features type\u00ad b safe higher-order channels with channel \nlocality. Sequential pro\u00adgramming in .PC may exploit mutable references as usual, since b the type system \nensures that mutable references never interfere with parallel computations. Thus implementing the parallel \noperational semantics of .PC b is no more complicated than implementinga sim\u00adilar parallel language without \nmutable references. Our long-termgoalistobuilda programmingsystemthatsup\u00adports three levels of parallelism \nwithin a uni.ed framework. At the highest level,it implements distributed computations taking place in \na network of nodes. Each node performs a stand-alone compu\u00adtation and also communicates with other nodes \nvia higher-order channels. (Hence there is no distributed shared memory.) The next level implements task \nparallelism with higher-order channels as in .PC b . Thus a stand-alone computation at a node actually \nconsists of multiple threads running in parallel. At the lowest level, multi\u00adple local threads with shared \nmemory run within each thread.Task parallelism with shared memory as well as data parallelism can be \nimplemented at this level. Then the type system of .PC can be ex\u00ad b tended to provide type safety at \nall the three levels. Acknowledgments The author is grateful to Hyeonseung Im and anonymous reviewers \nfor their helpful comments. References Eric Allan,David Chase,Joe Hallet,VictorLuchangco, Jan-Willem \nMaessen, Sukyoung Ryu, Guy L. Steele Jr., and Sam Tobin-Hochstadt. The Fortress language speci.cation \nversion 1.0beta. Technical report, Sun Microsystems Inc., March 2007. Roberto Amadio. An asynchronous \nmodel of locality,failure, and process mobility. In Proceedings of the 2nd International Con\u00adference \non Coordination Languages and Models, LNCS 1282, pages 374 391. Springer-Verlag, 1997. Joe Armstrong. \nThe development of Erlang. In Proceedings of the SecondACM SIGPLAN International Conference on Functional \nProgramming, pages 196 203.ACM Press, 1997. Krste Asanovic, Ras Bodik, Bryan Christopher Catanzaro, Joseph \nGebis,Parry Husbands,KurtKeutzer,DavidPatterson,William Plishker, John Shalf, Samuel Williams, and Katherine \nYelick. The landscape of parallel computing research: A view from berkeley. Technical Report UCB/EECS-2006-183, \nEECS De\u00adpartment, University of California, Berkeley, December 2006. Guy Blelloch. Programming parallel \nalgorithms. Communications of theACM, 39(3):85 97, 1996. Manuel Chakravarty, Roman Leshchinskiy, Simon \nPeyton Jones, Gabriele Keller, and Simon Marlow. Data Parallel Haskell: a status report. In Proceedings \nof theACM SIGPLANWorkshop on Declarative Aspects of Multicore Programming, pages 11 18, 2007. Philippe \nCharles, Christian Grothoff,Vijay Saraswat, Christopher Donawa, Allan Kielstra,Kemal Ebcioglu, Christophvon \nPraun, and Vivek Sarkar. X10: an object-oriented approach to non\u00aduniform cluster computing. In Proceedings \nof the 20th ACM SIGPLAN Conference on Object-Oriented Programming, Sys\u00adtems, Languages, and Applications, \npages 519 538, 2005. Cray Inc. The Chapel language speci.cationversion 0.4.Technical report, February \n2005. Tarek El-Ghazawi,William Carlson, and Jesse Draper. UPC lan\u00adguage speci.cations, v1.1.1, October \n2003. Matthew Fluet, Mike Rainey, John Reppy, Adam Shaw, andYingqi Xiao. Manticore:A heterogeneous parallel \nlanguage. In Pro\u00adceedings of the ACM SIGPLAN Workshop on Declarative As\u00adpects of Multicore Programming, \npages 25 32, 2007. C\u00b4edric Fournet, Georges Gonthier, Jean-Jacques L\u00b4evy, Luc Maranget, and DidierR\u00b4emy. \nA calculus of mobile agents. In CONCUR: 7th International Conference on Concurrency The\u00adory, LNCS 1119, \npages 406 421. Springer, 1996. C\u00b4Fournet, Fabrice Le Fessant, Luc Maranget, and Alan edric Schmitt. JoCaml: \na language for concurrent distributed and mo\u00adbile programming. In Johan Jeuring and Simon Peyton Jones, \neditors, Advanced Functional Programming, 4th International School, 2002, volume 2638 of Lecture Notes \nin Computer Sci\u00adence, pages 129 158. Springer-Verlag, 2003. Robert Halstead, Jr. MULTILISP: a language \nfor concurrent sym\u00adbolic computation. ACM Transactions on Programming Lan\u00adguages and Systems, 7(4):501 \n538, 1985. Paul Hil.nger, Dan Bonachea, Kaushik Datta, David Gay, Susan Graham, Benjamin Liblit, GeoffreyPike, \nJimmy Su, and Kather\u00adineYelick. Titanium language reference manual,version 2.19. Technical Report UCB/EECS-2005-15, \nEECS Department, Uni\u00adversity of California, Berkeley, November 2005. Lorin Hochstein, Jeff Carver, Forrest \nShull, Sima Asgari, Victor Basili, Jeffrey Hollingsworth, and Marvin Zelkowitz. Parallel programmer productivity:A \ncase study of novice parallel pro\u00adgrammers. In Proceedings of the 2005ACM/IEEE Conference on Supercomputing, \npage 35. IEEE Computer Society, 2005. LiminJiaandDavidWalker. Modalproofsas distributed programs (extended \nabstract). In Proceedings of the European Symposium on Programming, LNCS 2986, pages 219 233. Springer, \n2004. Frederick Knabe. Language Support for Mobile Agents. PhD the\u00adsis, Department of Computer Science, \nCarnegie Mellon Univer\u00adsity, 1995. Tom Murphy, VII, Karl Crary, Robert Harper, and Frank Pfenning. Asymmetric \nmodal lambda calculus for distributed computing. In Proceedings of the 19th IEEE Symposium on Logic in \nCom\u00adputer Science. IEEE Press, 2004. R. Nikhil and Arvind. Implicit parallel programming in pH. Mor\u00adgan \nKaufmann, 2001. Martin Odersky. Polarized name passing. In Proceedings of the 15th Conference on Foundations \nof Software Technology and Theoretical Computer Science, LNCS 1026,pages 324 337. Springer-Verlag, 1995. \nSungwooPark.Amodal language for the safetyof mobilevalues. In NaokiKobayashi, editor, Proceedings of \nthe 4th Asian Sym\u00adposium on Programming Languages and Systems, LNCS 4279, pages 217 233. Springer, 2006. \nBenjamin Pierce and Davide Sangiorgi. Typing and subtyping for mobile processes. In Proceedings of the \n8th Annual IEEE Sym\u00adposium on Logic in Computer Science, pages 376 385, 1993. Alan Schmitt. Safe dynamic \nbinding in the join calculus. In TCS 02: Proceedings of the IFIP 17thWorld Computer Congress -TC1 Stream/2nd \nIFIP International Conference on Theoretical Computer Science, pages 563 575. Kluwer, B.V., 2002. Alan \nSchmitt and Jean-BernardStefani. The M-calculus: a higher\u00adorder distributed process calculus. In Proceedings \nof the 30th ACM SIGPLAN-SIGACT Symposium on Principles of Program\u00adming Languages, pages 50 61.ACM Press, \n2003. Nir Shavit and DanTouitou. Software transactional memory. In Proceedingsof the fourteenthACM symposium \non Principlesof Distributed Computing, pages 204 213.ACM Press, 1995. James Stamos and David Gifford. \nRemote evaluation. ACM Transactions on Programming Languages and Systems, 12(4): 537 564, 1990. Herb \nSutter. The free lunch is over: a fundamental turn toward concurrency in software. Dr. Dobb s Journal, \n30(3), March 2005. NobukoYoshidaand MatthewHennessy. Subtypingand localityin distributed higher order \nprocesses (extended abstract). In CON-CUR: 10th International Conference on Concurrency Theory, LNCS \n1664, pages 557 572. Springer-Verlag, 1999. Xiaogang Zhang and John Potter. Responsive bisimulation. \nIn Proceedings of the 2nd IFIP International Conference on Theo\u00adretical Computer Science, pages 601 612. \nKluwer, B.V., 2002.    \n\t\t\t", "proc_id": "1291151", "abstract": "<p>As a means of transmitting not only data but also code encapsulated within functions, higher-order channels provide an advanced form of task parallelism in parallel computations. In the presence of mutable references, however, they pose a safety problem because references may be transmitted to remote threads where they are no longer valid.</p> <p>This paper presents an ML-like parallel language with <i>type-safe</i> higher-order channels. By type safety, we mean that no value written to a channel contains references, or equivalently, that no reference escapes via a channel from the thread where it is created. The type system uses a typing judgment that is capable of deciding whether the value to which a term evaluates contains references or not. The use of such a typing judgment also makes it easy to achieve another desirable feature of channels, <i>channel locality</i>, that associates every channel with a unique thread for serving all values addressed to it.</p> <p>Our type system permits mutable references in sequential computations and also ensures that mutable references never interfere with parallel computations. Thus it provides both flexibility in sequential programming and ease of implementing parallel computations.</p>", "authors": [{"name": "Sungwoo Park", "author_profile_id": "81100161164", "affiliation": "Pohang University of Science and Technology, Pohang, South Korea", "person_id": "PP37043834", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1291151.1291181", "year": "2007", "article_id": "1291181", "conference": "ICFP", "title": "Type-safe higher-order channels in ML-like languages", "url": "http://dl.acm.org/citation.cfm?id=1291181"}