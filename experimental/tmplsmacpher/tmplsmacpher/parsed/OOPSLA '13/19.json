{"article_publication_date": "10-29-2013", "fulltext": "\n Veselin Raychev ETH Z\u00a8 urich veselin.raychev@inf.ethz.ch Refactoring with Synthesis Max Sch\u00e4fer Nanyang \nTechnological University schaefer@ntu.edu.sg Martin Vechev ETH Z\u00a8 urich martin.vechev@inf.ethz.ch Manu \nSridharan IBM T.J. Watson Research Center msridhar@us.ibm.com Abstract Refactoring has become an integral \npart of modern software development, with wide support in popular integrated devel\u00adopment environments \n(IDEs). Modern IDEs provide a .xed set of supported refactorings, listed in a refactoring menu. But with \nIDEs supporting more and more refactorings, it is becoming increasingly dif.cult for programmers to discover \nand memorize all their names and meanings. Also, since the set of refactorings is hard-coded, if a programmer \nwants to achieve a slightly different code transformation, she has to either apply a (possibly non-obvious) \nsequence of several built-in refactorings, or just perform the transformation by hand. We propose a novel \napproach to refactoring, based on synthesis from examples, which addresses these limitations. With our \nsystem, the programmer need not worry how to invoke individual refactorings or the order in which to \napply them. Instead, a transformation is achieved via three simple steps: the programmer .rst indicates \nthe start of a code refactoring phase; then she performs some of the desired code changes manually; and \n.nally, she asks the tool to complete the refactoring. Our system completes the refactoring by .rst extracting \nthe difference between the starting program and the modi\u00ad.ed version, and then synthesizing a sequence \nof refactor\u00adings that achieves (at least) the desired changes. To enable scalable synthesis, we introduce \nlocal refactorings, which allow for .rst discovering a refactoring sequence on small Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. Copyrights for components of this work owned by others \nthan ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post \non servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Request permissions \nfrom permissions@acm.org. OOPSLA 13, October 29 31, 2013, Indianapolis, Indiana, USA. Copyright c &#38;#169; \n2013 ACM 978-1-4503-2374-1/13/10. . . $15.00. http://dx.doi.org/10.1145/2509136.2509544 program fragments \nand then extrapolating it to a full refac\u00adtoring sequence. We implemented our approach as an Eclipse \nplug-in, with an architecture that is easily extendable with new refactor\u00adings. The experimental results \nare encouraging: with only minimal user input, the synthesizer was able to quickly dis\u00adcover complex \nrefactoring sequences for several challenging realistic examples. Categories and Subject Descriptors \nD.2.6 [Programming Environments]: Integrated environments; Eclipse Keywords Refactoring; Synthesis 1. \nIntroduction Software refactoring improves the structure of existing code through behavior-preserving \ntransformations, themselves called refactorings. Since it was .rst formally described twenty years ago \n[8, 22], refactoring has become an im\u00adportant part of modern software development, and is a staple of \nagile software development techniques such as Extreme Programming [2]. While originally conceived as \na manual activity, it did not take long for the .rst refactoring tools to appear [26] that of\u00adfered support \nfor automating simple refactoring transforma\u00adtions. Since then refactoring support has become de rigueur \nin interactive development environments (IDEs) for object\u00adoriented languages. In particular, all major \nJava IDEs such as Eclipse [4], IntelliJ IDEA [12] and NetBeans [21] come with built-in support for many \nrefactorings. Recent studies, however, have shown that these refactor\u00ading tools are severely underused \n[19, 36]: while program\u00admers do refactor frequently, they perform up to 90% of refac\u00adtorings by hand, \neven where tool support is available. One major issue identi.ed by these studies is poor discoverabil\u00adity: \nin order to initiate an automated refactoring, the pro\u00adgrammer has to select it by name from a menu1 \nor use a 1 In Eclipse 4.2, this menu has 23 entries.  corresponding keyboard shortcut, requiring the \nprogrammer to not only know which refactoring transformations the IDE supports but also to memorize their \nnames. A second obsta\u00adcle is the complexity of the user interface for some refactor\u00adings, which are controlled \nby complex con.guration dialogs that disrupt the programmer s work.ow. To alleviate these problems, several \nresearchers have pro\u00adposed novel user interface paradigms for refactoring tools: Lee et al. [16] present \na system where refactorings are initi\u00adated by drag-and-drop gestures, whereas BeneFactor [7] and WitchDoctor \n[5] are tools for refactoring autocompletion that observe a programmer s editing operations and try to \ndiscover editing patterns suggestive of refactorings. When such a pattern is discovered, the programmer \nis offered the choice of completing the refactoring task using the built-in refactoring tool. These tools \nmake it easier to apply individual refactorings already supported by the IDE. However, many very natu\u00adral \nrefactoring transformations do not straightforwardly map to these built-in refactorings. For example, \nthe EX T R AC T ME T H O D refactoring implementations of present-day IDEs provide no control over the \nset of parameters to be pro\u00advided by the extracted method. As we shall discuss further in Section 2, \nthis means that programmers sometimes have to perform a non-trivial sequence of auxiliary refactorings \nin order for the method extraction to yield the required re\u00adsult. This is tedious, particularly if some \nrefactoring late in the sequence fails unexpectedly (e.g., due to a violated pre-condition) and the programmer \nhas to undo the previ\u00adous steps one by one. Even discovering the right sequence of refactorings to perform \nis often non-trivial, and the program\u00admer may ultimately fall back to performing the refactoring by hand. \nWe propose a novel interface for invoking automated refactorings based on synthesis from examples (for \na recent survey, see [9]). In our approach, a developer performs an automated refactoring using the following \nprocess: 1. Click a Start Refactoring button, thereby indicating the program Pi whose semantics should \nbe preserved by the refactoring. 2. Manually perform a few of the edits for the desired refac\u00adtoring, \nresulting in a program Pm. 3. Click a Complete button, at which point the tool takes as input the two \nexamples Pi and Pm and attempts to discover a sequence of automated refactorings that, when applied to \nPi, yields a program that includes the edits introduced in Pm over Pi.  This refactoring interface, \nwhich we have implemented in an Eclipse plugin called RESY N T H, provides a number of advantages over \ntraditional approaches where the user needs to .gure out which (sequence of) refactorings to invoke: \n The user is freed from remembering a different menu item or keyboard shortcut for each supported refactoring; \ninstead, all refactorings are exposed through a simple, uni.ed interface.2  Applying a transformation \nrequiring a sequence of refac\u00adtorings becomes much easier, as the tool discovers the (possibly non-obvious) \nsequence for the user. Also, the tool ensures that all refactorings in the sequence will suc\u00adceed before \napplying any of them, removing the burden of having to undo earlier refactorings if a later one fails. \n Similarly, performing a set of related refactorings where the order is unimportant (e.g., renaming \nboth a .eld and its accessor methods) is simpli.ed, since the refactorings are applied as a unit.  For \na refactoring developer, adding a new refactoring no longer requires cluttering the user interface with \nanother menu item.  The heart of RESY N T H is a search strategy for discover\u00ading appropriate refactoring \nsequences based on a small num\u00adber of user edits. A na\u00efve brute-force search is ineffective for even \nthe smallest programs. Instead, R ESY N T H takes the following approach: 1. Program entities that were \nnot edited by the user are discarded to narrow the search space. 2. Over this pruned program, an A* \nsearch [11] is per\u00adformed to discover refactoring sequences, guided by a heuristic function that minimizes \nedit distance and ex\u00adpression distance from the user edits. 3. After a solution is discovered that works \nfor the pruned program, RESY N T H attempts to execute the discovered sequences of Eclipse refactorings \non the full program.  While BeneFactor and WitchDoctor also infer refactor\u00adings from user edits, they \ndiffer from our system in that (1) they do not require the user to indicate a refactoring is occur\u00adring \nand (2) they cannot perform transformations requiring a sequence of refactorings. While (1) can be an \nadvantage for novice users, requiring the user to indicate the start of the refactoring enables the tool \nto discover more complex sequences, and allows for performing several independent refactorings atomically. \nRESY N T H is architected in a manner that eases the pro\u00adcess of adding new refactorings. Beyond standard \nrefactor\u00ading functionality, RESY N T H only requires that each refactor\u00ading provide a successors function \nto enumerate the possible ways to apply the refactoring to a given pruned program, thereby de.ning the \nsearch space. Adding a successors function is straightforward in most cases, and otherwise refactoring \nimplementors need not be concerned about de\u00adtails of the refactoring search. 2 Of course, the alternative \ninterface could also be used in conjunction with standard menu items.  To assess the effectiveness of \nour search strategy, we evaluated RESY N T H on a set of synthetic benchmarks and on real example refactorings \ncollected from Stack Over.ow3 and other sources. We show that our search techniques are signi.cantly \nmore effective than alternate approaches, and can handle many challenging real-world examples. Main Contributions \nThe contributions of this paper are: A new interface for refactoring tools, where the user indicates \nthe desired transformation with example edits and the tool synthesizes a sequence of refactorings that \ninclude the edits.  A novel technique for synthesizing refactoring sequences via heuristic search over \npruned programs.  An implementation RESY N T H, whose architecture mini\u00admizes the effort required to \nadd new refactorings.  An initial evaluation of RESY N T H, showing it can syn\u00adthesize complex refactoring \nsequences for real examples.  Our paper is organized as follows. Section 2 gives a de\u00adtailed example \nto motivate our techniques. Then, Section 3 presents our core search techniques in detail. Section 4 \nde\u00adtails the design and implementation of our tool RESY N T H, and Section 5 presents our experimental \nevaluation. Finally, Section 6 discusses related work, and Section 7 concludes. 2. Overview Modern Java \nIDEs such as Eclipse, NetBeans or IntelliJ IDEA offer a large number of built-in refactorings that can \nbe activated through a menu or a keyboard shortcut. The precise set of supported refactorings differs \nbetween IDEs, but usually includes a set of core refactorings such as EX T R AC T ME T H O D or EN C \nA P S U L AT E FI E L D, many of them originally implemented in the Smalltalk Refactoring Browser [26]. \nThis set of refactorings, however, is .xed, and does not di\u00adrectly accommodate some fairly simple transformations. \nAs an example, consider the method extraction problem shown in Fig. 1, which is taken from Fowler s well-known \nbook on refactoring [6]. The original program, a fragment of a class representing an account, is given \non the left. As shown in the refactored program on the right, we want to extract lines 6 and 7 into a \nnew method printDetails(). Crucially, how\u00adever, the expression getOutstanding() on line 8 should not \nbe extracted into the new method, but passed as a parameter instead. This refactoring cannot be performed \nin one step using the refactoring tools of Eclipse, NetBeans or IntelliJ, since their implementations \nof EX T R AC T ME T H O D do not permit the programmer to control the set of parameters of the ex\u00adtracted \nmethod, which is instead determined automatically by examining the program s data .ow. 3 http://stackoverflow.com \nThe transformation can be achieved by composing two refactorings. First, the two statements including \nthe ex\u00adpression to be passed as a parameter are extracted into a printDetails() method: 40 private void \nprintDetails() { 41 System.out.println(\"name: \" + name); 42 System.out.println(\"outstanding: \" + 43 getOutstanding()); \n44 } Then, the I N T RO D U C E PA R A M E T E R refactoring is applied to the getOutstanding() call, \nyielding the desired result. However, IN T RO D U C E PA R A M E T E R is not widely known [36], and, \nat least in Eclipse, its implementation is buggier than more popular refactorings. Another alternative \nis to decompose the refactoring into three steps. First, we extract the expression to be passed as a \nparameter into a local variable outstanding inside printOwing(), as follows: 45 void printOwing() { \n46 printBanner(); 47 double outstanding = getOutstanding(); 48 System.out.println(\"name: \" + name); 49 \nSystem.out.println(\"outstanding: \" + 50 outstanding); 51 } Then, we extract lines 48 50 into the printDetails() \nmethod. Since outstanding is used by, but not de.ned in, the code to be extracted, it will be turned \ninto a parameter to printDetails(), as desired. Finally, we can apply IN L I N E LO C A L to outstanding, \nachieving the desired program from Figure 1(b).4 Vakilian et al. [35] found that this latter sequence \nof refac\u00adtorings is quite frequently performed in practice, suggesting that programmers often need to \nperform complex refactor\u00adings that exceed the capabilities of current refactoring en\u00adgines, forcing them \nto manually compose several refactor\u00adings in order to achieve a single transformation. While EX T R AC \nT LO C A L is more widely known than IN T RO D U C E PA R A M E T E R [36], its use in this situation \nis highly non-obvious and indeed somewhat counter-intuitive, since its effect is later partially undone \nby an inlining. This requires the programmer to plan ahead to compensate for limitations of the refactoring \ntool. Abadi et al. [1] conducted a case study using Eclipse s built-in refactorings to conduct a complex \nrefactoring, and found that only three out of 13 uses of EX T R AC T ME T H O D could be automatically \nperformed by Eclipse. They suggest improving Eclipse s implementation of EX T R AC T ME T H O D to provide \nmore .ne-grained control over the code to extract 4 In fact, this approach does not quite work in either \nEclipse, NetBeans or IntelliJ, since their implementations of E X T R AC T LO C A L always put the declaration \nof the extracted local variable on the line immediately preceding the extraction site, so outstanding \nends up after line 48 and has to be moved manually before the refactoring can continue.  1 public class \nAccount { 2 private String name; 3 4 void printOwing() { 5 printBanner(); System.out.println(\"name: \n\" + name); System.out.println(\"outstanding: \" + 8 getOutstanding()); 9 } 10 11 private double getOutstanding() \n{ 12 //... 13 } 14 15 private void printBanner() { 16 //... 17 } 18 } (a) 19 public class Account { \n20 private String name; 21 22 void printOwing() { 23 printBanner(); 24 printDetails( getOutstanding()); \n25 } 26 27 private void printDetails(double outstanding) { 28 System.out.println(\"name: \" + name); 29 \nSystem.out.println(\"amount: \" + outstanding); 30 } 31 32 private double getOutstanding() { 33 //... \n34 } 35 36 private void printBanner() { 37 //... 38 } 39 } (b) Figure 1. Example of a complicated refactoring \nthat cannot be achieved in a single step in current IDEs; changes highlighted. and the parameters of \nthe extracted method, but recent re\u00adsearch [35] suggests that such an improved (and invariably much more \ncomplex) refactoring tool would not necessarily be very popular, since programmers seem to favor compo\u00adsition \n(of several simple refactorings) over con.guration (of one complex refactoring). Our approach We propose \na radically different approach to solving this problem: instead of having to memorize what individual \nrefactorings do and .gure out how to compose them to achieve complex transformations, the programmer \ncan perform some of the desired changes by hand, and then use a tool to automatically search for a suitable \nsequence of refactorings that performs (at least) those changes. With our approach, a programmer could \nachieve the refactoring of Fig. 1 quite easily. After indicating to the tool that a refactoring is beginning, \nthe user would just man\u00adually replace lines 6 and 7 with the desired method call printDetails(getOutstanding()). \nAt this point, of course, the program does not compile any more, since the method printDetails has not \nbeen de.ned yet. But, based on this simple edit, our tool RESY N T H can determine the sequence of refactorings \nneeded to refactor the original program into the form in Fig. 1(b). Note that existing tools like Bene-Factor \n[7] and WitchDoctor [5] cannot handle this example based on the edit above: they require the user to \nknow a sequence of refactorings to apply. The same interface can, of course, also be used for trans\u00adformations \nthat can be achieved by a single refactoring (dis\u00adcussed further in Section 5). In such cases, RESY N \nT H has the advantage of providing a uni.ed interface that frees the programmer from having to memorize \nrefactoring names and their associated keyboard shortcuts or menu items. There are many real-world examples \nbesides that of Figure 1 in which a desired transformation can be ac\u00adcomplished by applying a non-obvious \nsequence of basic refactorings. For instance, previous work [25, 32] has dis\u00adcussed swapping two names, \ne.g., transforming .eld declara\u00adtions String s1; String s2; to String s2; String s1;, changing uses of \ns1 and s2 appropriately. One cannot apply the R E NA M E refactoring to .rst change s1 to s2 or vice\u00adversa, \nsince a name con.ict arises. With our approach, one simply swaps the names in the .eld declarations manually, \nand the tool discovers a sequence of three RE NA M E refactor\u00adings to complete the transformation: s1 \nto tmp, s2 to s1, and .nally tmp to s2. As with the previous example, this refactor\u00ading sequence is non-obvious, \nbut with RESY N T H, the user is freed from worrying about the details. In Section 5, we show that RESY \nN T H was able to handle several challenging real-world examples, including these. 3. Approach In this \nsection, we discuss our approach to synthesizing refactoring sequences in detail. We formalize the problem, \nintroduce the notion of local refactoring, describe the syn\u00adthesis algorithm, and prove some of its key \nproperties.  3.1 Setting A refactoring r . R = P rog \u00d7 P S -P rog is a partial function which takes \nas input a program and a sequence of parameters and returns a transformed program. The function is partial \nbecause the input program may not satisfy pre\u00adconditions required for the transformation to be behavior\u00adpreserving. \nThe set of parameters varies among refactorings. For example, a R E NA M E refactoring takes two parameters: \na program entity e to be renamed and the new name for e. The types of parameters are not important here; \nthey will be discussed further in Section 4. An invocation of a refactoring function is denoted as r(P, \nps) where each argument in ps belongs to P S . Sequence of Refactorings We often use the term se\u00adquence \nof refactorings to stand for a sequence of invoca\u00adtions of refactoring functions. Formally, a .nite sequence \nof refactorings rn(P ) of length n > 0 invoked with particular arguments is de.ned as: r n(P, ps1, ..., \npsn) = rn(...(r2(r1(P, ps1), ps2)..., psn) The problem addressed by our synthesis procedure can now be \nstated informally as follows: Given an initial program Pi and a modi.ed program Pm, the goal of the synthesizer \nis to discover a se\u00adquence of refactorings Pf = rn(Pi, ps1, ..., psn) (for some n > 0) that preserves \nall changes intro\u00adduced in Pm over Pi. To solve this problem, a synthesizer must .nd both: i) which refactorings \nto use and ii) which arguments to pass to the refactorings of step i). Key Challenge A na\u00efve approach \nto the above problem would be to apply refactorings in sequence directly to Pi, searching for a sequence \ncontaining the changes in Pm. Unfortunately, this approach performs poorly, due to the need to repeatedly \ntransform and check preconditions on the entire input program. We observed that applying a single Eclipse \nrefactoring to even a small program took roughly half a second (consistent with previous work [5]), making \na search among thousands of refactoring sequences infeasible in practice. While in principle the Eclipse \nrefactorings could be fur\u00adther optimized, precondition checking for many refactorings such as renaming \nis an inherently global problem that needs to take the whole program (including external libraries it \nde\u00adpends on) into account, thus limiting the potential speedup. Furthermore, given the current architecture \nof Eclipse s refactoring engine, applying two refactorings in a row in\u00advariably entails changing the \nprogram at a textual level and reparsing affected compilation units, which would further slow down search. \nThe key challenge, then, is how to speed the search pro\u00adcess suf.ciently to discover realistic refactoring \nsequences in reasonable amounts of time. Solution Outline Next, we discuss our solution. We .rst discuss \nhow to capture changes between two programs. Then, we discuss local refactorings, an important compo\u00adnent \nof our approach. A local refactoring restricts a refactor\u00ading to a program fragment, enabling the search \nto consider only the changed parts of a program instead of an entire program, which is key to scalability. \nWe then present our search algorithm, based on local refactorings, and .nally we discuss the overall \nguarantees provided by the synthesizer. 3.2 Capturing Program Change We de.ne T (P ) to be the abstract \nsyntax tree (AST) of program P . For programs with multiple .les, we create one tree with a root node \nthat joins the ASTs of all .les. Given trees T1 and T2, we de.ne the following tree operations: T1 \\ \nT2 is a tree where each full path in T1 which does not occur in T2 is kept.  T1 . T2 is true iff every \nrooted path in T1 is a rooted path in T2.  A rooted path is a path from the root of tree T to any node \nin T , and a full path is a rooted path which ends in a leaf. A program change is a pair (ci, cm) where \nci is a subtree of T (Pi) and cm is a subtree of T (Pm). Intuitively, (ci, cm) means that the tree ci \nfrom T (Pi) was changed to the tree cm of T (Pm). In terms of the previously-de.ned tree opera\u00adtions, \n(ci, cm) = (T (Pi) \\ T (Pm), T (Pm) \\ T (Pi)). A program Pf is said to preserve a change (ci, cm) if \ncm . T (Pf ). Note that ci and cm need not be syntactically\u00advalid program ASTs since they may be missing \nsubtrees that did not change between Pi and Pm. Example Consider the two expressions Pi = x * y + 7 and \nPm = f() + 7, whose ASTs are shown in Fig. 3. As de.ned above, ci is the tree x*y+ and cm is the tree \nf()+, illustrated as dashed circles in the .gure. In this example, neither ci nor cm are well-formed \nASTs, since they miss the right-hand operand of +, which is identical in both programs. In what follows, \nwe write P for T (P ) to avoid notational clutter. So for instance, a change (ci, cm) is written as (Pi \n\\ Pm, Pm \\ Pi) and preservation as cm . Pf . Now that we have de.ned the notion of a program change, \nwe can re-state our goal formally: Given an initial program Pi and a modi.ed program Pm, the goal of \nthe synthesizer is to discover a se\u00adquence of refactoring invocations (for some n > 0) Pf = rn(Pi, ps1, \n..., psn) such that cm . Pf .  3.3 Local Refactoring The concept of a local refactoring is key to the \npracticality of our synthesis approach. A local refactoring enjoys the  Figure 2. Synthesis Steps \nFigure 3. Two ASTs and the change (ci, cm) between them. The change is captured with dotted lines. following \nbene.ts: i) it can operate on a small portion of the program instead of the entire program; ii) it can \nperform fewer pre-condition checks that those performed by a full refactoring; iii) it works directly \non trees and hence does not need to parse and generate code. For a given refactoring r, we denote a corresponding \nlocal refactoring as rl. A local refactoring rl is de.ned as follows: rl : T ree \u00d7 P S -T ree That is, \nrl is a partial function which takes as input a tree, a sequence of parameters and returns a tree. Similarly \nto the full refactoring r, the function is partial because the input may not always satisfy certain pre-conditions \nrequired for the function to .re. The difference from the de.nition of a full refactoring is the use \nof trees instead of programs. Sequences of local refactorings are de.ned similarly to se\u00adquences of full \nrefactorings de.ned earlier. Extraction Function Given an invocation of a local refac\u00adtoring, we often \nneed to obtain a corresponding invocation of a full refactoring. Therefore, for each local refactoring \nfunc\u00adtion rl, we associate a corresponding extraction function: \u00b5rl : P S . P S Then, given a local refactoring \ninvocation rl(t, ps), the [ function \u00b5rl (ps) computes a new sequence of arguments psto be passed to \nthe full refactoring r. Typically \u00b5rl is the identity function, but we allow each implementation of a \nlocal refactoring to decide what function it needs. For a local refactoring to be useful in synthesis, \nit needs to satisfy the following condition w.r.t a full refactoring. De.nition 3.1 (Correct Local Refactoring). \nA local refac\u00adtoring rl is correct w.r.t its corresponding full refactoring r iff .P . P rog, f . T ree, \nps . P S : f . P . f[ = rl(f, ps) . P [ = r(P, \u00b5rl (ps)) . f[ . P [ Fig. 4 gives the intuition for the \nde.nition: a local refactoring is cor\u00adrect w.r.t. a full refactoring unless both are enabled and the \nresult of the local refactoring is not included in the result of the full one. Note that depending on \nthe de.nition of the extraction function \u00b5 there could Figure 4. Lo\u00ad be many different local refactorings \ncal refactoring rl that are correct with respect to its correctness corresponding full refactoring r. \n 3.4 Modular Synthesis We next describe the three steps of the synthesis process. These steps are also \nillustrated in Fig. 2. Step 1: Extract Change The result of this step is a program change (ci, cm) = \n(Pi \\ Pm, Pm \\ Pi) (as de.ned in Sec\u00adtion 3.2). Since we need only the change, we do not need to ex\u00adplicitly \nconstruct the entire ASTs Pi and Pm. Indeed, if we compare the trees of Pi and Pm and eliminate the common \nparts between them, this would eliminates classes, meth\u00adods, type de.nitions, statements and expressions \nthat remain unchanged between the two programs. This means that for large programs, we need not compare \nunmodi.ed compila\u00adtion units. Then, we construct the ASTs P[and P[which i m include only the modi.ed \ncompilation units and compute the program change by using the formula (Pi[\\ P[, P[\\ Pi[). m m Step 2: \nSynthesize Local Refactoring Sequence We next describe how we compute a local refactoring sequence. The \ngoal of this step can be stated as follows: Given a program change (ci, cm), the goal of the syn\u00ad thesizer \nis to discover a sequence of local refactoring  n invocations t = r(ci, ps1, ..., psn) (where n > 0) \nl such that cm = t. We assume that at each step in the search, there is a .nite set of (refactoring, \ninput) pairs that apply to the current tree. Some work may be required to compute this .nite set, as \nrefactorings can have unbounded inputs (like the new name input for RE NA M E); we describe how our implementation \nhandles this issue in Section 4. A na\u00efve solution to our search problem would be to use breadth-.rst \nsearch, which will .nd the shortest possible refactoring sequence (assuming the aformentioned .nitiza\u00adtion). \nHowever, our experiments indicate that such a search rarely scales beyond sequences of more than four \nrefactor\u00adings, as the search space grows exponentially in the length of the desired sequence. Instead, \nwe employ an A*-based search [11]. A* itera\u00adtively computes a distance function d from the initial tree \nci to every other generated tree. Our distance function is sim\u00adply the length of the current (partial) \nrefactoring sequence. To speed up the search, A* also uses a heuristic function h that estimates the \ndistance from each tree to the target tree cm. At every step, the tree t with minimal d(ci, t) + h(t) \nis processed. The successors of t, i.e., the results of applying all possible local refactorings to t \n(a .nite set, as discussed above), are added to the set of candidates, and the search continues. Heuristic \nfunctions First, we de.ne a correct heuristic function. De.nition 3.2 (Correct Heuristic Function). A \nheuristic function is correct if it satis.es the following properties: .t . T ree, h(t) = 0, and  If \nt = cm then h(t) = 0  We propose the following correct heuristic functions: 1. h1(t) is the edit distance \nbetween t and cm: this is the minimum number of node renames, leaf node inserts or leaf node deletes \nrequired to get to the tree cm from the tree t. 2. h2(t) is the expression distance between t and cm: \nthis is the number of program expressions present in one of the trees which are not present in the other \none. This function ignores parts of programs which are not valid expressions. For example the statement \nx=y+1 consists of the expressions x=y+1, x, y+1, y and 1. If t consists of the statement x=y+1 and cm \nof x=z+1, then h2(t) = 6, because t contains x=y+1, y+1 and y which are not present in cm, and cm contains \nx=z+1, z+1 and z which are not present in t.  A consistent heuristic function is a correct function \nwhich also satis.es the property .t1, t2, h(t1) = d(t1, t2) + h(t2). If a consistent heuristic function \nis provided, the A* algo\u00adrithm will always .nd the shortest possible sequences [11]. However, building \nsuch a heuristic function is dependent on the available local refactorings and hence would require change \neach time a new local refactoring is added. The heuristic function that we choose is not consistent, \nbut is correct, which is suf.cient for our optimality guaran\u00adtees (discussed later) and does not affect \nthe correctness of the produced local sequence. The heuristic function is used only to improve the speed \nof the search and decrease the number of explored trees. In our implementation, we con\u00adstructed several \nheuristic functions by building different lin\u00adear combinations h(t) = a1h1(t) + a2h2(t) and tuning the \ncorresponding constants a1 and a2. Section 5 presents results with different choices for a1 and a2. Step \n3: Extrapolate to a Sequence of Full Refactorings n Once a local refactoring sequence r(ci, ps1, ..., \npsn) is l computed, the .nal step is to extrapolate from that sequence and obtain a sequence of full \nrefactorings. The sequence of full refactorings is obtained by applying the extraction function to each \nlocal refactoring in the local refactoring se\u00adquence. That is, for the full refactoring sequence we obtain \nn rn(Pi, \u00b5rl1 (ps1), ..., \u00b5rln (psn)). However, rmay not ac\u00adtually be feasible, since local refactorings \nmay ignore some of the pre-conditions which are checked in the sequence of full refactorings. If the \nsequence of full refactorings is infea\u00adsible, our algorithm searches for a different local refactoring \nsequence and repeats the process. Otherwise, we obtain the desired program Pf (from the sequence of full \nrefactorings).  3.5 Guarantees We next discuss the two main guarantees provided by our approach. First \nwe show that the synthesizer produces a refactoring sequence which satis.es our objective (that is, correctness). \nFurther, we also prove a property of optimality. The fact that our synthesizer achieves the correctness \nobjective is also illustrated in Step 3 of Fig. 2, that is, with cm . Pf . We prove this below. Lemma \n3.3 (Correctness of Synthesis). For any sequence of full refactorings Pf = rn(Pi, ps1, ..., psn) produced \nby the synthesizer, cm . Pf . n Proof. Let r(ci, . . .) be the local refactoring sequence pro\u00ad l duced \nin Step 2 of the algorithm, from which the given full refactoring sequence rn(Pi, . . .) was obtained. \nHere we do not list the arguments to avoid clutter and use . . . instead. The proof proceeds by induction. \nFor the induction k hypothesis assume that for some k < n, r(ci, . . .) . l rk(Pi, . . .) where the sequence \nrk(Pi, . . .) is obtained from k the sequence r(ci, . . .). We need to prove that the tree l k+1 r (ci, \n. . .) . rk+1(Pi, . . .). From the requirement that l each local refactoring is correct (De.nition 3.1) \nit fol\u00ad k lows that rlk+1 (rl (ci, . . .), . . .) . rk+1(rk(Pi, . . .), . . .). n Then, using induction \nwe have proven that r(ci, . . .) . l rn(Pi, . . .). Step 2 of the local refactoring synthesis termi\u00ad \n n nates only if r(ci, . . .) = cm. Hence, by substitution it l follows that cm . rn(Pi, . . .) proving \nour objective. Next, we de.ne a notion of optimality: De.nition 3.4 (Optimality). Pf = rn(P, ps1, ..., \npsn) if: n = 1 and P = Pf , or n > 1 and for all i, 0 = i < n - 1, ro . R, pso . P S , it is the case \nthat ro(ri(P, ps1, ..., psi), pso)= Pf . Intuitively, the above de.nition of optimality says that we \ncannot replace a suf.x of the refactoring sequence with another refactoring and obtain the same result. \nFor example, a sequence of two rename refactorings where the .rst one renames method A to B and the second \none renames B to C is not optimal, because that sequence can be replaced by a single refactoring that \nrenames A directly to C. A consequence of the above de.nition is that if a sequence is optimal and correct, \nit means that no pre.x of the sequence is correct. For example, if the sequence of refactorings a\u00b7b\u00b7c \nis optimal and correct, it means that neither a nor a \u00b7 b can solve the problem, that is, no shorter \ncorrect pre.x exists. Lemma 3.5 (Optimality of Synthesis). A refactoring se\u00adquence rn(P, ps1, ..., psn) \nproduced by the synthesizer is optimal if for all i, 1 = i < n, \u00b5rli is a bijection. Proof. First, we \nwill show that the local refactoring se\u00adquence produced by A* is optimal. If the sequence cm = n r(ci, \nps1, ..., psn) was not optimal, then .j, 1 = j < n - 1 l and a local refactoring rlo with parameters \npso . P S , such that rlo (rj(ci, ps1, ..., psj ), pso) = cm. Let cP = l rj (ci, ps1, ..., psj). Because \ncm = rlo (cP , pso), cm is a l successor of cP . cP was processed in A* before cm and its computed distance \nfunction is d(ci, cP ) = j. Because all successors of cP are added when cP is processed and cm is a successor \nof cP , then n = d(ci, cm) = j + 1, which means j = n - 1, which contradicts the non-optimality of n \nr(ci, ...). l Next, assume that rn(P, ps1, ..., psn) is produced by n using \u00b5rli (i . [1, n]) from r(ci, \nps1, ..., psn) and is l not optimal. This means that .j, 1 = j < n - 1 and a refactoring ro . R with \nparameters pso . P S , such that ro(rj(P, ps1, ..., psj ), pso) = Pf . Because for all i, 1 = i < n, \n\u00b5rli is a bijection, we must be able to ob\u00adtain ro(rj (P, ps1, ..., psj ), pso) from a local sequence \nrlo (rj (ci, ps1, ..., psj ), pso) = cm, but this contradicts to l n the optimality of r(ci, ps1, ..., \npsn). l Our optimality guarantee shows that the sequence of refactorings which we produce cannot be trivially \nshortened. This is important as it ensures that we do not produce redun\u00addant or unnecessary steps and \nthat our diverse solutions are not trivially reducible to the same solution. Example Let us illustrate \nthe steps described in Fig. 2 on the simple example in Fig. 5. For readability, the example contains \nonly a single refactoring. Here, the user provides an initial program Pi that computes the area of a \ntriangle using Heron s formula. The variable T stores the perimeters divided by two and then the square \nof the area is computed in s. Assume that the user wants to rename the variable T to p by changing some \nplaces where T is mentioned to p. The changes are in the program Pm (Pm does not compile). Given Pi and \nPm, in step 1 the algorithm extracts the change and produces the two trees ci and cm. In step 2, a local \nrefactoring sequence is synthesized. In this example, the sequence consists of a single local rename. \nThat is, only the occurrences T in the tree ci have their names changed to p resulting in the tree cm. \nIn step 3, the discovered local refac\u00adtoring sequence is applied on the full program. As a result, Pf \nis a program where all occurrences of T are renamed to p. Note that only in this step, we can check if \nthe rename is actually feasible. For instance, had the name p already been used as a name of another \nvariable, then this step would fail. When the rename refactoring is implemented as a local refactoring, \nit does not perform the check that the new name (e.g. p in our example) does not con.ict with names outside \nof the local tree, but this check is performed in the full refac\u00adtoring. Indeed, if we .nd a local refactoring \nsequence and its corresponding full refactoring sequence succeeds, then as shown earlier, the edits performed \nby the user are preserved (Lemma 3.3) and that the produced sequence cannot be triv\u00adially shortened (Lemma \n3.5). 4. Implementation We have implemented the approach from Section 3 in a tool called RESY N T H. \nThe tool is built as a plug-in for Eclipse 4.2 [4]. Here we discuss how we designed RESY N T H to minimize \nthe work needed to add new refactorings to the tool, and we present other salient implementation details. \n 4.1 Architecture RESY N T H consists of a core refactoring search engine that invokes individual automated \nrefactorings through a simple, uniform API. Beyond the standard functionality required of an automated \nrefactoring (i.e., the ability to apply the refac\u00adtoring to a program and detect pre-condition violations), \nRESY N T H also requires that each full refactoring imple\u00adments its corresponding local refactoring as \ndescribed ear\u00adlier. Recall that each local refactoring takes a number of ar\u00adguments as input. Conceptually, \nhaving an external search process choose those arguments violates modularity, as the search engine would \nneed to know the meaning of each in\u00addividual refactoring (in order to chose suitable arguments). Therefore, \nwe require the developer to de.ne a successors function associated with that local refactoring. The search \nengine simply invokes the function successors on all avail\u00adable refactorings to enumerate the search \nspace.  3. perform the sequence (rename T to p) on the full program s = T*(T-a)*(T-b)*(T-c); s = p*(p-a)*(T-b)*(T-c); \ns = p*(p-a)*(p-b)*(p-c); return Math.sqrt(s); return Math.sqrt(s); return Math.sqrt(s); 1. compute ci \n= Pi \\ Pm . ci . Pi and cm = Pm \\ Pi . cm . Pm cm . Pf by Lemma 3.3 ci : cm : =T*(T-)* 2. synthesize \nsequence: local rename T to p =p*(p-)* Figure 5. Example of synthesizing a refactoring sequence. Initially \n(stage 0), the user performs part of the rename (the user change is highlighted in both programs). Then \nci and cm are computed (stage 1). Then, a sequence of one local rename is discovered (stage 2). Finally, \nthe rename is applied to the full program (stage 3). Similar to a local refactoring, the successors function \ntakes as input a tree. However, it produces a set of trees as output, by invoking the corresponding local \nrefactoring with a set of possible arguments on the input tree. More formally, the successors function \ntakes two parameters as input: i) the tree Ti representing the current local search state to be explored \nfrom, and ii) the target tree cm (see Section 3.2). Given these parameters, successors must return a \n.nite set of pairs (To, args), where To is a successor tree obtained by applying a local refactoring \nto Ti with arguments args (e.g., the original and new names for a RE NA M E refactoring). We keep the \nset of arguments args in the returned pair in order to compute the full local refactoring sequence when \nthe target tree cm is reached. The minimal additional functionality that RESY N T H re\u00adquires of local \nrefactorings makes adding new local refactor\u00adings to RESY N T H relatively easy. In particular, refactoring \nimplementors need not concern themselves with details of how the search space is explored; this aspect \nis handled en\u00adtirely within the core engine, using the techniques described in Section 3.4. Instead, \nthey only need to specify what is the space to be searched, via the successors function. Certain decisions \nmade within the successors function of each refactoring may require some tuning. For refactor\u00adings with \nunbounded inputs (e.g., RE NA M E, which can take an arbitrary string as a new name), there can be an \nin.nite number of successors for a given tree. In such cases, the refactoring implementor must decide \nwhat .nite subset of the possible successors should be returned by successors (discussion of how our \nimplemented refactorings handle this issue is described in Section 4.2). The amount of pre\u00adcondition \nchecking to be performed within successors is also left to the refactoring implementor. In our experience, \nwe found that performing aggressive pre-condition checking during successor computation was worthwhile, \nto reduce the size of the search space and to discover violations cheaply during local refactoring whenever \npossible. To implement local refactorings ef.ciently, the input trees to successors include symbol information \nfor all names, e.g., whether a name references a local variable, a .eld, a method, or some other entity. \nThis information is useful dur\u00ading local pre-condition checking inside refactorings, e.g., to detect \nname con.icts. The initial information is computed from program Pi, and each refactoring must preserve \nthe in\u00adformation appropriately for each successor tree it produces. To further simplify the task of implementing \nsuccessor functions, we provide utility functions that operate on trees and perform the following basic \nmodi.cations: 1. Replace all occurences of a given symbol by a new tree. 2. Replace a node of the tree \nby a new subtree. 3. Insert a new statement in a tree. 4. Delete a statement from a tree.  Note that \nour trees are immutable, so these modi.cations ac\u00adtually produce new trees. These utilities were used \nacross the refactorings we have implemented thus far, and we believe they will be useful for implementing \nother refactorings as well. We now brie.y compare our architecture to that of Witch-Doctor [5]. Like \nRESY N T H, WitchDoctor also aims to make it easy to integrate new Eclipse refactorings into its search. \nTo support a new refactoring in WitchDoctor, its effects have to be described using declarative rules \nthat match changes in the AST. While this allows more high-level speci.cations than our successors function, \nit requires the AST result\u00ading from the refactoring to be known already. This is true in WitchDoctor, \nwhere only a single refactoring application is detected at a time, but not in RESY N T H, where a refactoring \nmay create an intermediate AST that is further changed by other refactorings before resulting in the \n.nal AST. Our ap\u00adproach thus is more powerful, but requires a bit more work to integrate a new refactoring. \n  4.2 Implementation Details RESY N T H currently includes implementations of successors functions \nfor RE NA M E, IN L I N E ME T H O D, EX T R AC T ME T H O D, IN L I N E LO C A L, and EX T R AC T LO \nC A L. 5 Together, the refactorings above covered many of the in\u00adteresting refactoring sequences we observed \nin real-world examples. Similar to the WitchDoctor system [5], our refac\u00adtorings currently rely on underlying \nEclipse refactoring im\u00adplementations to perform full refactorings. As discussed in previous work [5], \nthe Eclipse refactorings have not been en\u00adgineered to run quickly in scenarios like these and our exper\u00adiments \ncon.rm that each Eclipse refactoring needs around half a second to run. In a from-scratch implementation, \nmore code could be shared between the lightweight local refactor\u00adings and the full refactoring, and global \npre-condition check\u00ading could be optimized in a manner that could speed up the overall search. As discussed \nin Section 4.1, our refactoring implemen\u00adtations are required to .nitize a potentially-in.nite set of \nsuccessors in their successors functions. For RE NA M E, we limited the set of new names for an identi.er \nto the name present at the same tree node in the .nal tree cm or one ad\u00additional fresh temporary name. \nThe temporary name is use\u00adful for cases where the refactoring sequence requires names to be swapped. \nBecause multiple name swaps can be com\u00adposed sequentially, one temporary name is suf.cient. The EX T \nR AC T LO C A L and EX T R AC T ME T H O D refactorings al\u00adways use a deterministically-generated name \nfor the new lo\u00adcal variable or method: if needed, a subsequent RE NA M E refactoring can used to match \nthe user s desired name. RESY N T H contains around 3100 lines of Java code, the majority of which is \nthe engine, the plugin and the evaluation code. Only 750 of the code lines are the local refactorings. \nExample We brie.y illustrate the work needed to add the IN L I N E LO C A L refactoring. First we implement \nthe successors function. Recall that the successors function takes a tree Ti and returns a .nite set \nof pairs (To, args). For the IN L I N E LO C A L refactoring, each local variable dec\u00adlaration v with \nan initializer expression e in Ti produces one successor tree. Since Ti is a .nite tree, the number of \nsuc\u00adcessors is .nite. Each successor tree is computed as follows: 1. Let s be the resolved symbol of \nthe variable v. First, we replace all nodes in Ti that resolve to the symbol s with the expression e. \nThis replacement is in fact done via a utility method provided by RESY N T H. 2. Second, we delete the \nstatement that declared the vari\u00adable.6  5 We also extended Eclipse s implementation of this refactoring \nwith an additional parameter that determines the position at which to declare the new local variable \nto avoid the problem mentioned in Section 2. 6 Java allows several variable declarations per statement, \nbut our local trees use slightly modi.ed ASTs where each variable declaration is a separate statement. \nThen, the produced tree is one successor To of Ti and the set of corresponding arguments args to To is \nonly the variable v. When we need to execute the full refactoring, we are given a program P , such that \nTi . P and the arguments of the local refactoring args = v. To execute the full refac\u00adtoring, all we \nneed to do is .nd the AST node of the variable declaration v in P , and to call the InlineTempRefactoring \nEclipse refactoring with this AST node as a parameter.  4.3 Limitations Our current prototype has several \nlimitations. Currently, we do not formally prove that our local refactorings perform edits that are consistent \nwith the full Eclipse refactorings. Rather than verifying each local refactoring separately, in the future, \nwe envision that the full refactoring is imple\u00admented in a way which enables one to derive a correct-by\u00adconstruction \nlocal refactoring from it. Also, some of our local refactorings do not currently han\u00addle the whole functionality \nof the full refactorings (for the proof-of-concept, we focused on the most common cases). For example, \nour local I N L I N E ME T H O D refactoring does not inline statements that are outside of the local \ntree. Due to this limitation, in some test cases, RESY N T H does not .nd the desired refactoring sequence, \nbut .nds a similar alter\u00adnative one. This limitation can be avoided if the user edits include the deletion \nof the inlined function. 5. Evaluation In this section, we present an initial evaluation of the RESY \nN T H tool. We .rst illustrate simple edits that we successfully used to perform individual refactorings \nwith RESY N T H. We then show that RESY N T H was able to syn\u00adthesize complex refactoring sequences required \nfor several real-world examples. Furthermore, we show that the search strategy used by RESY N T H performed \nbetter than alternate strategies, both on real examples and on a synthetic bench\u00admark suite.7 Finally, \nwe performed a small user study to see how programmers like the basic idea of synthesis-based refactoring, \nand to obtain feedback on RESY N T H and sug\u00adgestions for improvements. 5.1 Individual Refactorings \nAs discussed in Section 4, RESY N T H currently includes im\u00adplementations of .ve refactorings that are \ncommonly imple\u00admented in modern IDEs. Since they are frequently used, IDEs often make these refactorings \neasy to invoke; e.g., Eclipse assigns each of them a direct keyboard shortcut. Nevertheless, RESY N T \nH provides an advantage when ap\u00adplying these refactorings individually, as they can all be invoked through \na uniform interface. We con.rmed that 7 All results were obtained on a 64-bit Ubuntu 12.04 machine with \na 4-core 3.5GHz Core i7 2700k processor and 16GB of RAM, running under Eclipse 4.2 with a 4GB maximum \nheap.  Example steps Source EN CAPS U LAT E DOW N C AST EX T R AC T ME T H O D (advanced) DE C O M P \nO S E CO N DI TI O NAL IN TRODU C E FO REI G N ME T H O D REPL AC E TE M P WIT H QU ERY REPL AC E PAR \nA M E T ER WIT H ME T H OD SWA P FI EL DS SWA P FI EL D AN D PA R A ME T E R IN TRODU C E PA R A M E \nT ER 3 4 6 2 3 3 3 3 6 literature [6] literature [6] literature [6] literature [6] literature [6] literature \n[6] literature [32] literature [25] Stack Over.ow9 Table 1. Realistic examples used to test RESY N T \nH. RESY N T H could successfully perform individual refactor\u00adings when given the following edits (performed \nbetween pressing the Start and Complete buttons): Rename An entity x (method, .eld, or local variable) \ncan be renamed by editing the declaration of x or any reference to use the new name. Inline Local A local \nvariable can be inlined simply by delet\u00ading its declaration. Inline Method Similarly, a method m can \nbe inlined at all sites by deleting m. Extract Local To extract an expression e into a local x, one simply \nreplaces e with x. Extract Method With Holes To extract an expression e into a new method m, the user \ncan replace e with an invocation of m, where the invocation includes the de\u00adsired parameters for m. The \n.nal k statements in m can be extracted in a similar fashion.8 Note that, as described in Section 2, \nthis refactoring is more general than the standard E X T R AC T ME T H O D, as it gives the user very \n.ne-grained control over which expressions to pass as arguments to m. Hence, a refactoring sequence may \nbe required to handle these edits. Of course, a developer must learn that the edits outlined above will \naccomplish the desired refactorings before she can use them. However, we believe the edits are fairly \nintu\u00aditive, as they are a subset of the edits required to perform the refactorings manually. The simplicity \nof the edits, along with having a uniform interface instead of separate menu items / keyboard shortcuts \nfor each refactoring, could ease the pro\u00adcess of applying these refactorings in practice.  5.2 Refactoring \nSequences Benchmarks To test RESY N T H s effectiveness for synthe\u00adsizing refactoring sequences, we collected \na set of examples that require a non-trivial refactoring sequence to achieve the 8 We have not yet implemented \nsupport in our local refactoring for extract\u00ad ing multiple contiguous statements from the middle of a \nmethod. 9 http://stackoverflow.com/questions/10121374/ referencing-callee-when-refactoring-in-eclipse \nuser s desired transformation. The examples are listed in Ta\u00adble 1, along with information on where the \nexample was ob\u00adtained. The .rst .ve examples are transformations presented in Fowler [6] that are not \nimplemented in Eclipse, but can be accomplished via a sequence of the refactorings we have implemented. \nWe also include two examples of name swap\u00adping refactorings that have appeared in the literature [25, \n32], each of which requires a non-obvious introduction of a tem\u00adporary name in the refactoring sequence. \nFinally, the IN T RO -D U C E PA R A M E T E R example, found online, can be achieved via a complex sequence \nof six of our implemented refactor\u00adings. While Eclipse provides an implementation of IN T RO -D U C E \nPA R A M E T E R, it fails to handle this example. The E X-T R AC T ME T H O D (advanced) and SWA P FI \nE L D S examples were previously discussed in Section 2. Four other examples from Fowler s book could \nbe com\u00adposed from additional Eclipse refactorings for which we have not yet implemented local refactorings. \nWe also generated a suite of random benchmarks to per\u00adform further stress testing of RESY N T H, as follows. \nFor each benchmark, we .rst generated a Java class C containing a sequence of static .eld declarations \nfollowed by a sequence of static methods. Each static method returns a random ex\u00adpression e, generated \nby using binary operators to combine constants, local variable and .eld references, and method in\u00advocations \nup to some depth. Given C, we then generated an edited version C[ by performing a random sequence of \nedits like those described in Section 5.1 to induce individual refac\u00adtorings. Each (C, C [) pair is a \nbenchmark that tests whether RESY N T H can discover a sequence of refactorings on C that preserves the \nedits in C[. For our experiments, we generated 100 such benchmark inputs, with .ve .elds, .ve methods, \nand expression depth of three for C, and two random edits to produce C[. We found these parameters to \ncreate bench\u00admarks that were somewhat more challenging than our real examples (see below), while still \nremaining realistic. All of our benchmarks (real and synthetic) are available online at http://www.srl.inf.ethz.ch/resynth.php. \nSuccess Rate Table 2 shows results from applying RESY N T H to our real-world and synthetic benchmarks. \nRESY N T H suc\u00adcessfully generated a refactoring sequence for all but two of the real-world examples \nand for 84% of the synthetic exam\u00adples. We bounded the search to a maximum of 20,000 trees for these \nresults; we explore different bounds shortly. From each explored tree, we run the successors function, \nwhich returns multiple successor trees and effectively explores a higher number of refactorings than \nthe number of trees. On average applying a full Eclipse refactoring takes about 0.5 seconds and as we \nexplore thousands (1296 for our real world tests) of refactorings in order to discover the desired sequence, \nhad we performed the search with full refactorings instead of local refactorings, the process would have \ntaken at least 10 minutes, clearly an undesirable response time when performing interactive edits.  \nDataset Metric Real Synthetic Number of tests 9 100 Avg. number of trees searched 87 3752 Avg. number \nof successors in a search 1296 105310 Avg. search time 0.014s 1.629s Avg. Eclipse refactoring time 2.953s \n1.654s Refactoring sequence length 1 refactoring 0 2 2 refactorings 1 45 3 refactorings 5 7 4 refactorings \n1 15 5 refactorings 0 3 6 refactorings 2 2 7 refactorings 0 9 8 refactorings 0 0 9 refactorings 0 1 Failure \nto .nd sequence after 20000 searched trees 0 16 Table 2. Results for our refactoring sequence search. \nThe A* heuristic function weights (see Section 3.4) were a1 = 0.125 and a2 = 0.25. The two real-world \nexamples for which RESY N T H did not .nd the sequence from Fowler s book were EN C A P -S U L AT E DOW \nN C A S T and RE P L AC E PA R A M E T E R WI T H ME T H O D. This is due to a limitation (see Section \n4.3) in our successors function for IN L I N E ME T H O D. It did, how\u00adever, .nd another valid refactoring \nsequence that matches the same edits. As shown by the mean search time and mean number of trees searched, \nthe synthetic examples were signi.cantly more challenging than the real-world examples on average. Also \nnote that the time required to apply the full Eclipse refactorings after the sequence was discovered \nwas roughly equal to the entire search time for synthetic benchmarks, and much larger than the search \ntime for real examples, indicating the need for local refactorings. Out of the 16 examples that we fail \nto solve, nine re\u00adquire minimum 11 steps to accomplish, four tests require minimum 9 steps and three \ntests require minimum 7 steps. These are examples where the A* search would need to ex\u00adplore more than \n20000 trees until it can .nd a refactoring sequence. Overall, the scalability results for our technique \nare quite encouraging. Table 3 shows how our success rate on synthetic bench\u00admarks is affected by the \nsearch bound. Increasing the search space leads to a slightly lower failure rate, but it also sig\u00adni.cantly \nincreases the average search time. Further testing with users is required to discover an appropriate \nbound in practice. Alternate Search Strategies We tested alternate strategies for searching for refactoring \nsequences by tuning the coef.\u00adcients for the heuristic function h(t) = a1h1(t) + a2h2(t),  Metric Search \nspace limit (# trees) 20,000 100,000 500,000 Num. failed tests 16 15 9 Avg. number of searched trees \n3752 15900 64392 Avg. search time 1.629s 7.802s 34.473s Table 3. Success rate on synthetic benchmarks \nwith differ\u00adent search bounds. Tested with a1 = 0.125 and a2 = 0.25. described previously in Section \n3.4. Note that setting a1 = 0 and a2 = 0 disables the heuristic function, making the A* search perform \na straightforward breadth-.rst search. Results for different values of a1 and a2 with a search budget \nof 20,000 trees appear in Table 4. The a1 and a2 val\u00adues we chose for our other experiments are in bold, \nalong with the best values in the other columns. The na\u00efve breadth\u00ad.rst search (a1 = a2 = 0) fails for \n2 of the real examples and 32 of the random tests, corresponding to the tests requiring four or more \nrefactoring steps. A linear combination of h1 and h2 performs better than using each of the heuristic \nfunc\u00adtions alone, for both real examples and the synthetic tests. In RESY N T H, we selected a1 = 0.125 \nand a2 = 0.25 as these values had best results on the real tests and close to the best results on the \nsynthetic tests.  5.3 User Study Although RESY N T H is currently a research prototype and somewhat \nunpolished, we conducted a small, informal user study to gauge how useful programmers .nd the concept \nof refactoring with synthesis, and to get some feedback on how to improve our tool. We recruited six \nparticipants: two undergraduate stu\u00addents, three graduate students, and one professional. All of the \nparticipants had prior experience with Java programming (between one and .ve years), and all of them \nwere familiar with Eclipse. One of them was a pro.cient user of Eclipse s built-in refactoring tools, \nwhile the other participants had little to no experience with tool-supported refactoring. After a brief \ndemonstration of RESY N T H, we gave each participant a set of three refactoring tasks based on examples \nfrom Fowler s textbook [6], and asked them to complete the tasks using either R ESY N T H, Eclipse s \nbuilt-in refactorings, or manual editing.10 For one of the tasks (Task 3), RESY N T H cannot, in fact, \n.nd the desired solution, but comes up with a slightly different solution. Four of our participants were \nable to complete all three tasks using R ESY N T H, and two of them failed on one of the tasks (though \nnot on the same one): one of them tried to manually compose the transformation out of individual small \nrefactorings, but became confused and ultimately gave up; the other participant was unable to .nd the \nright manual edits to perform. In the future, we will investigate improve\u00ad 10 A complete description \nof the tasks is available at http://www.srl. inf.ethz.ch/resynth.php.  Search Parameters Real Examples \nSynthetic Tests Edit Expr. distance distance weight weight a1 a2 Num. Avg. failed num. tests searched \ntrees Num. Avg. failed num. tests searched trees 0.000 0.000 2 5306 32 6943 0.000 0.125 1 3076 26 5373 \n0.000 0.250 0 184 26 5348 0.000 0.500 0 119 24 4537 0.000 1.000 1 2350 16 3316 0.125 0.000 0 1248 25 \n5065 0.125 0.125 0 115 19 4642 0.125 0.250 0 87 16 3752 0.125 0.500 0 122 15 3396 0.125 1.000 0 1154 \n14 3243 0.250 0.000 0 291 21 4456 0.250 0.125 0 281 18 3885 0.250 0.250 1 223 18 3694 0.250 0.500 1 153 \n17 3485 0.250 1.000 1 623 14 3516 0.500 0.000 2 358 26 4481 0.500 0.125 1 189 23 4401 0.500 0.250 1 158 \n22 4274 0.500 0.500 1 158 20 4114 0.500 1.000 1 465 18 4092 1.000 0.000 2 3033 24 4704 1.000 0.125 1 \n641 24 4796 1.000 0.250 1 637 25 4786 1.000 0.500 1 477 26 4704 1.000 1.000 1 768 22 4490 Table 4. Search \nspace with different parameters of the heuristic function for the A* search (When a1 = a2 = 0, the search \nis a breadth-.rst search.) ments to our search techniques and user interface to reduce the number of \ncases where intuitive edits do not lead to the desired solution. Only two participants noticed that the \nsolution found by RESY N T H for Task 3 was not quite the expected solution, but one of them thought \nthe alternative solution was good enough. After they had .nished the tasks, we asked the partici\u00adpants \nwhether they thought a tool like RESY N T H could be useful, and what improvements they would like to \nsee. Four participants responded that they did .nd it useful, although one of them quali.ed his response \nby saying that he would not trust the tool on a complex code base. This was because during the experiment \nhe discovered a bug in the Eclipse im\u00adplementation of IN L I N E LO C A L VA R I A B L E, which led him \nto doubt the reliability of Eclipse s built-in refactoring tools on which RESY N T H is built. Of the \ntwo participants who were not convinced of the usefulness of RESY N T H, one was not comfortable with \nthe idea of performing long sequences of refactorings in one go and instead preferred to compose refactorings \nby hand, while the other was already very fa\u00admiliar with the Eclipse refactoring tools and did not see \nthe need for another tool. Finally, the participants suggested three improvements: (1) handling uncompilable \ncode; (2) eliminating the Start Refactoring button; (3) adding support for more refactor\u00adings. The third \nsuggestion is, in principle, quite easy to implement by writing local equivalents for more built-in Eclipse \nrefactorings. The .rst suggestion could be addressed by using a more robust error-correcting parser, \nthough it re\u00admains to be seen whether this would adversely affect the quality of refactoring suggestions. \nThe second suggestion is more dif.cult to accommodate. The participant explained that it was easy to \nforget to click the Start Refactoring button before initiating a refactoring, which is similar to the \nlate awareness dilemma described by Ge et al. [7]. The participant suggested that instead of setting \nan explicit checkpoint, the IDE should try to infer a likely checkpoint, such as the last version of \nthe program that compiled. Given that another participant speci.cally asked for support for refactoring \nuncompilable programs, however, it seems unlikely that this heuristic would suit all users equally well. \nWhile it is impossible to generalize from a study with such a limited number of participants, we think \nthat our results show that the idea of synthesis-based refactoring has promise, and with further improvements \na tool like RESY N T H could usefully complement the built-in Eclipse refactoring tools. 6. Related Work \nIn this section, we discuss some of the more closely related work in the areas of program refactoring \nand synthesis. Refactoring The idea of refactoring catalogs that list com\u00admonly used refactoring operations \nand specify their behavior already appeared in Opdyke s thesis [22], one of the earli\u00adest works in the \n.eld. Another in.uential refactoring cata\u00adlog was compiled by Fowler in his book on refactoring for Java \n[6]. Refactoring tools in current Java IDEs still tend to follow this catalog in the repertoire of refactorings \nthey offer and the names assigned to them. However, Murphy-Hill et al. [19] found in a landmark study \non refactoring practices that while programmers refac\u00adtor frequently, about 90% of refactorings are performed \nby hand, even where tool support is available. These numbers were con.rmed in a recent, more detailed \nstudy by Negara et al. [20]. To make refactoring tools more attractive to pro\u00adgrammers, some authors \nproposed user-interface improve\u00adments [18], but even such improved tools still suffer from discoverability \nissues: the programmer may not know that an automated implementation is available for a refactoring they \nperform by hand, or they may start a manual refactor\u00ading before remembering that tool support is available. \nTo address these issues, Ge et al. [7] and Foster et al. [5] proposed systems that observe a programmer \ns editing op\u00aderations and try to discover editing patterns suggestive of refactorings. If they discover \nsuch a pattern, the user is of\u00adfered the choice of completing the refactoring task using a refactoring \ntool. Similarly, Lee et al. [16] advocate an approach in which refactoring operations can be initiated \nthrough drag-and-drop gestures.  In contrast to our work, all these systems can only detect and suggest \napplications of a single refactoring. Negara et al. [20] provide evidence to suggest that pro\u00adgrammers \noften perform several refactorings in sequence to achieve a single transformation. Vakilian et al. [35] \nfurther show that programmers do this even if there is tool sup\u00adport for a single, larger refactoring \nthat would perform this transformation in one go, preferring the higher level of pre\u00addictability and \ncontrol afforded by step-by-step refactorings. Our approach gives the programmer full .exibility: they \ncan either only perform a small set of edits and use RESY N T H to perform the associated small-scale \nrefactoring, or perform more edits and let RESY N T H infer a sequence of refactor\u00adings to achieve a \nlarge-scale transformation. Even more .exibility is achieved by languages for script\u00ading refactorings \nsuch as JunGL [39] or Jackpot [15], which allow programmers to implement their own custom refactor\u00adings. \nGiven the effort involved in learning a new language and API, however, it seems unlikely that any but \nthe most determined developers will use such systems on a regular basis. Currently, RESY N T H is built \non top of the refactorings provided by Eclipse JDT. This means that it will some\u00adtimes fail to infer \na sequence of refactorings if some inter\u00admediate step cannot be performed using the available refac\u00adtorings. \nThis problem could be alleviated by instead bas\u00ading RESY N T H on more .ne-grained transformations as \npro\u00adposed in the literature [25, 27]. Steimann et al. [31, 32] take a more radical approach which abolishes \nthe notion of individual atomic refactorings altogether. Instead, a given program s static semantics \n(name binding, overriding, accessibility, etc.) is encoded as a set of constraints such that any program \nthat ful.lls the same constraints must be semantically equivalent to the original program. Refactoring \nis then simply a search problem in the space of all programs satisfying the same constraints. While their \napproach is appealing for its simplicity and generality, it has only been shown to work for a very restricted \nset of refactorings (essentially, refactorings for renaming and mov\u00ading program elements). In contrast \nto BeneFactor, Witch-Doctor or RESY N T H, this approach cannot be implemented on top of an existing \nrefactoring tool and instead requires a complete reimplementation of the entire refactoring engine. In \na slightly different context, several researchers have considered the problem of detecting refactorings \nor other forms of systematic code changes from program revision histories to better understand program \nevolution [13, 24, 41], and to adapt clients of evolving frameworks and libraries [3, 33, 42]. Vermolen \net al. [40] consider the same problem in a modeling setting, where models need to be migrated when their \nmetamodel changes. Since the goal of these approaches is to infer completed refactorings, they can assume \nthat all edits arising from the refactorings have already been per\u00adformed. RESY N T H, on the other hand, \nassumes that the user only performed some edits by hand, and that further edits may be needed to complete \nthe intended refactorings, which leads to a much larger search space. Synthesis There has long been signi.cant \ninterest in us\u00ading program synthesis techniques aimed to simplify various software development tasks. \nFor a recent survey see Gul\u00adwani [9]. Here we describe the techniques that are most closely related to \nour work, focusing on techniques for pro\u00adgram completion. Prospector [17] introduced a synthesis procedure \nwhere given an input type I and output type O, the tool statically discovers (by examining the API speci.cations) \na sequence of API calls which, starting from an I object, produce an O object. PARSEWeb [34] addresses \nthe same problem, but its search is guided by existing source code mined from the web, which helps eliminate \nmany undesirable API se\u00adquences. More recent work [10, 23] searches for suitable ex\u00adpressions of a given \ntype at a particular program, considering more of the program context around that point. These sys\u00adtems \nrely on good ranking algorithms to handle large num\u00adbers of potentially-suitable expressions. In constrast \nto the aformentioned static approaches, MatchMaker [43] synthe\u00adsizes code based on observed API usage \nin dynamic execu\u00adtions of real-world programs. The concept of starting with partial programs and com\u00adpleting \nthem has recently been explored in various synthesis works. The sketching approach [28] takes as input \na program with holes (a sketch ), where the user speci.es a space of possible expressions which can be \nused to .ll the holes. The synthesizer then searches for correct program completions (completions which \nsatisfy a given property). The idea has been applied to various application domains including bit\u00adciphers \n[30] and concurrency [29]. In the context of concur\u00adrency, recent work has also devised ways to infer \nvarious synchronization constructs in the context of concurrent pro\u00adgramming. Examples include atomic \nsections [38], memory fences [14] and conditional critical regions [37]. These ap\u00adproaches complete an \nexisting concurrent program that may be potentially incorrect. Similarly to the above works, our work \ncan also be seen as solving an instance of the program completion problem. Here, our objective is to \ncomplete an intermediate program Pm into another program Pf , such that Pf is a refactoring of Pi. In \nsome sense, Pi serves as the speci.cation for our search in the sense that Pi and Pf should be seman\u00adtically \nequivalent. However, unlike the previous work, we do not aim to complete Pm into Pf directly such an \nap\u00adproach would require partial refactoring transformations to complete the edits performed by the user, \nand it would be quite dif.cult to even enumerate the space of such trans\u00adformations. Our synthesizer \ndoes not make any attempt to complete Pm, but instead begins its search from the spec\u00adi.cation Pi, using \nthe intermediate program Pm to decide when the search has been successful.  We believe that there are \nmany interesting future direc\u00adtions in combining ideas from the .elds of refactoring and synthesis. For \ninstance, suppose that our approach cannot .nd a refactoring sequence from Pi to Pm. An interesting direction \nhere would be to allow Pm to represent not a sin\u00adgle program but a partial program which symbolically \nrepre\u00adsents a set of programs (e.g. a sketch). Then, the synthesizer would try to discover a refactoring \nsequence starting from Pi where the result would be correct if it contains any of the programs symbolically \nrepresented by Pm. If such a refac\u00adtoring sequence is discovered, it would still be an accept\u00adable solution \n(if it passes the global pre-conditions). This approach would give the user more freedom in expressing \nthe partial changes to the program Pi. In addition, in terms of the synthesis algorithm, an interesting \ndirection could be in formulating the problem as a logical formula and then us\u00ading an SMT solver to perform \nthe search. 7. Conclusion and Future Work We have presented a new approach to automated refactoring, \ninspired by synthesis from examples. In our approach, the user describes a desired transformation by \nperforming some of the required edits on an initial program Pi, and the syn\u00adthesizer searches for a sequence \nof refactorings of Pi that in\u00adcludes the edits. We described a search strategy based on the concept of \nlocal refactoring combined with a tuned heuris\u00adtic search. We implemented our techniques in a tool called \nRESY N T H and showed that it can already handle challeng\u00ading real-world examples. In future work, we \nplan to: i) implement more local refac\u00adtorings in RESY N T H and further optimize its search tech\u00adniques, \nii) add a user interface for rejecting a proposed refac\u00adtoring sequence and continuing the search (the \ntool already has the option to display the discovered sequence to the user), iii) handling code which \ndoes not compile, and iv) generalize our approach to transformations beyond refac\u00adtoring, e.g., generation \nof boilerplate code: modern Java IDEs include many such transformations, and our techniques could further \nease their usage. References [1] ABAD I , A., ET T I NGER , R., AN D FELDM A N , Y. A. Re\u00adapproaching \nthe Refactoring Rubicon. In WRT (2008). [2] BE C K, K., A N D AND R E S , C. Extreme Programming Ex\u00adplained: \nEmbrace Change (2nd Edition). Addison-Wesley Professional, 2004. [3] DIG, D., CO M E RTO G L U , C., \nMAR INOV, D., AND JOHN S O N , R. Automated Detection of Refactorings in Evolving Compo\u00adnents. In ECOOP \n(2006). [4] Eclipse 4.2. http://www.eclipse.org/eclipse4. [5] FOSTE R , S. R., GR ISWO L D , W. G., AND \nLER N E R, S. WitchDoctor: IDE Support for Real-time Auto-completion of Refactorings. In ICSE (2012). \n[6] FOWL E R, M. Refactoring: Improving the Design of Existing Code. Addison Wesley, 2000. [7] GE, X., \nDUBO SE , Q. L., A N D MUR P H Y-HI L L, E. R. Rec\u00adonciling Manual and Automatic Refactoring. In ICSE \n(2012). [8] GRI S WOL D, W. G. Program Restructuring as an Aid to Soft\u00adware Maintenance. Ph.D. thesis, \nUniversity of Washington, 1991. [9] GU LWAN I , S. Dimensions in program synthesis. In ACM PPDP (2010). \n[10] GV E RO , T., KU NC A K , V., KU R A J , I., A N D PISK AC , R. On Complete Completion using Types \nand Weights. Tech. Rep. 182807, EPFL, 2012. [11] HA RT, P. E., NI LSS O N , N. J., A N D RA P H AE L \n, B. A formal basis for the heuristic determination of minimum cost paths. In IEEE Transactions on Systems \nScience and Cybernetics (1968), IEEE, pp. 100 107. [12] IntelliJ IDEA 12 Community Edition. http://www. \njetbrains.com/idea. [13] KIM, M., NOT KI N , D., AN D GROSSM A N , D. Automatic Inference of Structural \nChanges for Matching Across Program Versions. In ICSE (2007). [14] KU P E RSTE IN , M., VE CH EV, M., \nA N D YA H AV, E. Automatic inference of memory fences. ACM SIGACT News (2012). [15] LAHO DA, J., BE \n.C KA , J., A ND RUI J S , R. B. Custom CI .Declarative Refactoring in NetBeans. In WRT (2012). [16] \nLE E , Y. Y., CHEN, N., AND JOHN S O N , R. E. Drag-and-Drop Refactoring: Intuitive and Ef.cient Program \nTransformation. In ICSE (2013). [17] MAN D E LI N , D., XU, L., BO D\u00cd K , R., A N D KIM EL MAN , D. Jungloid \nmining: helping to navigate the API jungle. In ACM PLDI (2005). [18] MUR P H Y-HI L L, E. R., A ND BLACK, \nA. P. Breaking the Barriers to Successful Refactoring: Observations and Tools for Extract Method. In \nICSE (2008). [19] MUR P H Y-HI L L, E. R., PAR N IN, C., AND BL AC K , A. P. How We Refactor, and How \nWe Know It. TSE 38, 1 (2012). [20] NE G A RA, S., CH E N , N., VA K IL I A N , M., JO HNSO N , R. E., \nA N D DIG , D. A Comparative Study of Manual and Auto\u00admated Refactorings. In ECOOP (2013). [21] NetBeans \n7.0.1. http://netbeans.org.  [22] OP DYKE, W. F. Refactoring Object-Oriented Frameworks. Ph.D. thesis, \nUniversity of Illinois at Urbana-Champaign, 1992. [23] PE RE L M A N, D., GU LWANI , S., BAL L , T., \nA N D GRO S SMA N , D. Type-directed completion of partial expressions. In ACM PLDI (2012). [24] PRET \nE , K., RAC H ATA SUM R IT, N., SUDA N, N., A N D KI M , M. Template-based Reconstruction of Complex \nRefactorings. In ICSM (2010). [25] REI CH ENBAC H , C., CO U G H L IN, D., AND DI WAN , A. Pro\u00adgram Metamorphosis. \nIn ECOOP (2009). [26] RO B E RT S , D., BR ANT, J., A N D JO H N S O N, R. E. A Refac\u00adtoring Tool for \nSmalltalk. TAPOS 3, 4 (1997). [27] SCH \u00c4 F E R , M., VE R BA ER E , M., EK M A N, T., A N D DE MO O R, \nO. Stepping Stones over the Refactoring Rubicon Lightweight Language Extensions to Easily Realise Refactorings. \nIn ECOOP (2009). [28] SO L A R -LEZ AMA , A. The sketching approach to program synthesis. In APLAS (2009). \n[29] SO L A R -LEZ AMA , A., JONES, C. G., A N D BO D IK , R. Sketching concurrent data structures. In \nACM PLDI (2008). [30] SO L A R -LEZ AMA , A., TA N CAU , L., BODI K , R., SE S H I A , S., A N D SA RASWAT, \nV. Combinatorial sketching for .nite programs. SIGOPS Oper. Syst. Rev. (2006). [31] ST E I M ANN , F., \nKO L L EE, C., A N D VON PI L G RI M , J. A Refactoring Constraint Language and Its Application to Eiffel. \nIn ECOOP (2011). [32] ST E I M ANN , F., A N D VO N PI L G RI M , J. Refactorings Without Names. In ASE \n(2012). [33] TAN EJA , K., DIG, D., A N D XI E , T. Automated Detection of API Refactorings in Libraries. \nIn ASE (2007). [34] THUM M A L A P E N TA, S., A ND XI E, T. Parseweb: a program\u00admer assistant for reusing \nopen source code on the web. In ACM/IEEE ASE (2007). [35] VA KI LI A N , M., CH E N , N., MO G HADDAM, \nR. Z., NE GAR A , S., A N D JOH N S O N , R. E. A Compositional Paradigm of Automating Refactorings. \nIn ECOOP (2013). [36] VA KI LI A N , M., CH E N , N., NEG A R A, S., RA J K U MAR , B. A., BA I L E Y, \nB. P., A ND JO HNS O N , R. E. Use, Disuse, and Misuse of Automated Refactorings. In ICSE (2012). [37] \nVE C HE V, M., YAHAV, E., AND YO R S H , G. Inferring syn\u00adchronization under limited observability. In \nTACAS (2009). [38] VE C HE V, M., YA HAV, E., A N D YO RSH , G. Abstraction\u00adguided synthesis of synchronization. \nIn ACM POPL (2010). [39] VE R BA ER E , M., ETTI N G E R , R., A ND D E MO OR , O. JunGL: A Scripting \nLanguage for Refactoring. In ICSE (2006). [40] VE R MOL E N , S., WAC H S MUTH, G., A ND VI S S E R, \nE. Recon\u00adstructing Complex Metamodel Evolution. In SLE (2011). [41] WE ISSGER B E R, P., A ND DI E H \nL , S. Identifying Refactorings from Source-Code Changes. In ASE (2006). [42] XING, Z., A ND ST RO U \nLI A , E. API-Evolution Support with Diff-CatchUp. TSE 33, 12 (2007). [43] YE S S E N OV, K., XU, Z., \nA N D SO L A R -LEZ AMA , A. Data\u00addriven synthesis for object-oriented frameworks. In ACM OOPSLA (2011). \n   \n\t\t\t", "proc_id": "2509136", "abstract": "<p>Refactoring has become an integral part of modern software development, with wide support in popular integrated development environments (IDEs). Modern IDEs provide a fixed set of supported refactorings, listed in a refactoring menu. But with IDEs supporting more and more refactorings, it is becoming increasingly difficult for programmers to discover and memorize all their names and meanings. Also, since the set of refactorings is hard-coded, if a programmer wants to achieve a slightly different code transformation, she has to either apply a (possibly non-obvious) sequence of several built-in refactorings, or just perform the transformation by hand.</p> <p>We propose a novel approach to refactoring, based on synthesis from examples, which addresses these limitations. With our system, the programmer need not worry how to invoke individual refactorings or the order in which to apply them. Instead, a transformation is achieved via three simple steps: the programmer first indicates the start of a code refactoring phase; then she performs some of the desired code changes manually; and finally, she asks the tool to complete the refactoring.</p> <p>Our system completes the refactoring by first extracting the difference between the starting program and the modified version, and then synthesizing a <i>sequence</i> of refactorings that achieves (at least) the desired changes. To enable scalable synthesis, we introduce <i>local refactorings</i>, which allow for first discovering a refactoring sequence on small program fragments and then extrapolating it to a full refactoring sequence.</p> <p>We implemented our approach as an Eclipse plug-in, with an architecture that is easily extendable with new refactorings. The experimental results are encouraging: with only minimal user input, the synthesizer was able to quickly discover complex refactoring sequences for several challenging realistic examples.</p>", "authors": [{"name": "Veselin Raychev", "author_profile_id": "81474700236", "affiliation": "ETH Z&#252;rich, Z&#252;rich, Switzerland", "person_id": "P4290371", "email_address": "veselin.raychev@inf.ethz.ch", "orcid_id": ""}, {"name": "Max Sch&#228;fer", "author_profile_id": "81381592942", "affiliation": "Nanyang Technological University, Singapore, Singapore", "person_id": "P4290372", "email_address": "schaefer@ntu.edu.sg", "orcid_id": ""}, {"name": "Manu Sridharan", "author_profile_id": "81548007966", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY, USA", "person_id": "P4290373", "email_address": "msridhar@us.ibm.com", "orcid_id": ""}, {"name": "Martin Vechev", "author_profile_id": "81100269652", "affiliation": "ETH Z&#252;rich, Z&#252;rich, Switzerland", "person_id": "P4290374", "email_address": "martin.vechev@inf.ethz.ch", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509544", "year": "2013", "article_id": "2509544", "conference": "OOPSLA", "title": "Refactoring with synthesis", "url": "http://dl.acm.org/citation.cfm?id=2509544"}