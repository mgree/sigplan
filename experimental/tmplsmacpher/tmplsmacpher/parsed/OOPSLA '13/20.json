{"article_publication_date": "10-29-2013", "fulltext": "\n Bottle Graphs: Visualizing Scalability Bottlenecks in Multi-Threaded Applications Kristof Du Bois Jennifer \nB. Sartor Stijn Eyerman Lieven Eeckhout Ghent University, Belgium {kristof.dubois,jennifer.sartor,stijn.eyerman,leeckhou}@elis.UGent.be \n Abstract Understanding and analyzing multi-threaded program per\u00adformance and scalability is far from \ntrivial, which severely complicates parallel software development and optimiza\u00adtion. In this paper, we \npresent bottle graphs, a powerful analysis tool that visualizes multi-threaded program perfor\u00admance, \nin regards to both per-thread parallelism and execu\u00adtion time. Each thread is represented as a box, with \nits height equal to the share of that thread in the total program exe\u00adcution time, its width equal to \nits parallelism, and its area equal to its total running time. The boxes of all threads are stacked upon \neach other, leading to a stack with height equal to the total program execution time. Bottle graphs show \nex\u00adactly how scalable each thread is, and thus guide optimiza\u00adtion towards those threads that have a \nsmaller parallel com\u00adponent (narrower), and a larger share of the total execution time (taller), i.e. \nto the neck of the bottle. Using light-weight OS modules, we calculate bottle graphs for unmodi.ed multi-threaded \nprograms running on real processors with an average overhead of 0.68%. To demonstrate their utility, \nwe do an extensive analysis of 12 Java benchmarks running on top of the Jikes JVM, which in\u00adtroduces \nmany JVM service threads. We not only reveal and explain scalability limitations of several well-known \nJava benchmarks; we also analyze the reasons why the garbage collector itself does not scale, and in \nfact performs optimally with two collector threads for all benchmarks, regardless of the number of application \nthreads. Finally, we compare the scalability of Jikes versus the OpenJDK JVM. We demon\u00adstrate how useful \nand intuitive bottle graphs are as a tool to analyze scalability and help optimize multi-threaded appli\u00adcations. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. Copyrights for components of \nthis work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, \nor republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. Request permissions from permissions@acm.org. OOPSLA 13, October 29 31, 2013, Indianapolis, Indiana, \nUSA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2374-1/13/10. . . $15.00. http://dx.doi.org/10.1145/2509136.2509529 \n Figure 1. Example of a bottle graph: The lusearch DaCapo benchmark with 4 application threads (QueryX), \na main thread that performs initialization, and garbage collection threads running on Jikes JVM. Categories \nand Subject Descriptors D.2.8 [Software En\u00adgineering]: Metrics Performance Measures Keywords Performance \nAnalysis, Multicore, Java, Bottle\u00adnecks 1. Introduction Analyzing the performance of multi-threaded applications \non today s multicore hardware is challenging. While pro\u00adcessors have advanced in terms of providing performance \ncounters and other tools to help analyze performance, the reasons scalability is limited are hard to \ntease apart. In par\u00adticular, the interaction of threads in multi-threaded applica\u00adtions is complex: some \nthreads perform sequentially for a period of time, others are stalled with no work to do, and synchronization \nbehavior makes some threads wait on locks or barriers. Many papers have demonstrated the inability of \nmulti-threaded programs to scale well, but studying the root causes of scalability bottlenecks is challenging. \nPrevious re\u00adsearch has not analyzed scalability on a per-thread basis, or not suggested speci.c threads \nfor performance optimization that give the greatest potential for improvement (or those that are most \nimbalanced).  We propose bottle graphs as an intuitive performance analysis tool that visualizes scalability \nbottlenecks in multi\u00adthreaded applications. Bottle graphs are stacked bar graphs, where the height along \nthe y-axis is the total application ex\u00adecution time, see Figure 1 for an example. The stacked bar represents \neach thread as a box: the height is the thread s share of the total program execution time; the width \nis the number of parallel threads that this thread runs concurrently with, including itself; and the \nbox area is the thread s total running time. The center of the x-axis is zero, and thus paral\u00adlelism \nis symmetric, reported on both the left and right sides of the zero-axis. We stack threads boxes, sorting \nthreads by their parallelism, with widest boxes (threads with higher par\u00adallelism) shown at the bottom \nand narrower boxes at the top of the total application bar graph yielding a bottle-shaped graph, hence \nthe name bottle graph. Bottle graphs provide a new way to analyze multi\u00adthreaded application performance \nalong the axes of execu\u00adtion time and parallelism. Bottle graphs visualize how scal\u00adable real applications \nare, and which threads have a larger to\u00adtal running time (total box area), which threads have limited \nparallelism (narrow boxes), and which threads contribute signi.cantly to execution time (tall boxes). \nThreads that rep\u00adresent scalability bottlenecks show up as narrow and tall boxes around the neck of the \nbottle graph. Bottle graphs thus quickly point software writers and optimizers to the threads with the \ngreatest optimization potential. We measure bottle graphs of real applications running on real hardware \nthrough operating system support using light\u00adweight Linux kernel modules. The OS naturally knows what \nthreads are running at a given time, and when threads are created, destroyed, or scheduled in and out. \nWhen a thread is scheduled in or out, a kernel module is triggered to update per-thread counters keeping \ntrack of both the total thread running time, and number of concurrently running threads. Using kernel \nmodules, our bottle measurements incur very little overhead (0.68% on average), require no recompilation \nof the kernel, and require no modi.cations to applications or hardware. To demonstrate the power of bottle \ngraphs as an analy\u00adsis and optimization tool, we perform an experimental study of 12 single-and multi-threaded \nbenchmarks written in Java, both from the DaCapo suite and pseudoJBB from SPEC. The benchmarks run on \ntop of the Jikes Research Virtual Ma\u00adchine on real hardware. Because the applications run on top of a \nruntime execution environment, even single-threaded benchmarks have extra Java virtual machine (JVM) \nservice threads, and thus we can analyze not only the application, but also JVM performance and scalability. \nThe work most related to ours is IBM s WAIT tool [2], which also analyzes the performance and scalability \nof multi-threaded Java programs. However, bottle graphs reveal much more information at a much lower \noverhead. Because WAIT samples threads state, it gathers information only at particular points in time, \nwhile our tool aggregates our met\u00adrics at every thread status (active or inactive) change with\u00adout loss \nof information. In order to approach bottle graph s amount of information, WAIT must sample more frequently, \nthus incurring an order of magnitude more overhead. Bottle graphs visualize performance per thread, allowing \nfor easy grouping of thread categories (i.e., for thread pools or ap\u00adplication versus garbage collection \nthreads). Furthermore, WAIT can only analyze Java application threads, while our OS modules facilitate \nbottle graph creation for any multi\u00adthreaded program, including analysis of underlying Java vir\u00adtual \nmachine threads. In our comprehensive study of Java applications, we vary the number of application threads, \nnumber of garbage collec\u00adtion threads, and heap size. We analyze performance differ\u00adences between benchmark \niterations, and study the scalabil\u00adity of JVM service threads in conjunction with application threads. \nWe .nd sometimes surprising insights: a) counter to the common intuition that one should set the number \nof collection threads equal to the number of cores or the num\u00adber of application threads, we .nd that \nJikes performs opti\u00admally with two collector threads, both with single and multi\u00adthreaded benchmarks, \nregardless of the number of applica\u00adtion threads or heap size; b) when increasing the number of application \nthreads, or increasing the number of collec\u00adtion threads, the amount of garbage collection work also \nincreases; c) although application time decreases when in\u00adcreasing the number of application threads, \nthe amount of work the application performs also increases, thus showing that these applications are \nlimited in their scalability. Furthermore, we analyze why there is multi-threaded im\u00adbalance in one well-known \nbenchmark, pmd, as the bottle graph reveals that one application thread is tall and nar\u00adrow, while others \nare much better parallelized. Analysis re\u00adveals that this is due to input .le imbalance, and we sug\u00adgest \nopportunities to improve both performance and scala\u00adbility. Finally, because we .nd that Jikes garbage \ncollec\u00adtor has limited scalability, we compare Jikes behavior with that of OpenJDK. We reveal that increasing \nthe number of garbage collector threads in Jikes leads to signi.cantly more synchronization activity \nthan for OpenJDK s garbage collec\u00adtor. OpenJDK s collector does scale to larger thread counts than Jikes, \noffering good performance for up to 8 collection threads. However, collection work still increases as \nwe in\u00adcrease either application thread or collector thread count. In summary, bottle graphs are a powerful \nand intuitive way to visualize parallel performance. They facilitate fast analysis of scalability bottlenecks, \nand help target optimiza\u00adtion to the threads most limited in parallelism, or those slow\u00ading down the \ntotal execution the most. Such tools are criti\u00adcal as we move forward in the multicore era to ef.ciently \nuse hardware resources while running multi-threaded appli\u00adcations.  2. Bottle Graphs This section introduces \nour novel contribution of bottle graphs, such as the example in Figure 1. A bottle graph con\u00adsists of \nmultiple boxes, with different heights and widths, stacked on top of each other. The total height of \nthe stack is the total running time of the application. Each box rep\u00adresents a thread. The height of \neach box can be interpreted as the share of that thread in the total execution time. The width of each \nbox represents the amount of parallelism that that thread exploits, i.e., the average number of threads \nthat run concurrently with that thread, including itself. The area of each box is the total running time \nof that thread. The boxes are stacked by decreasing width, i.e., the widest at the bottom and the narrowest \nat the top, and they are centered, which makes the resulting graph look like a (two-dimensional) bottle. \nAs a design choice, we center the graph around a vertical parallelism line of zero, making the graph \nsymmetric. The amount of parallelism can be read either left or right from this line, e.g., a thread \nwith a paral\u00adlelism of 2 has a box that stretches to 2 on both sides of the parallelism axis. The example \nbottle graph in Figure 1 represents a multi\u00adthreaded Java program, namely the DaCapo lusearch bench\u00admark \nrunning with Jikes RVM on an 8-core Intel processor (see Section 3 for a detailed description of the \nexperimental setup). This program takes 3.28 seconds to execute. There are 7 threads with visible bottle \ngraph boxes, each having a different execution time share and different parallelism. The bottom four \nboxes represent application threads with a parallelism of approximately 4, and there is a main thread \nthat performs benchmark initialization that has limited par\u00adallelism. There are two garbage collection \n(GC) threads, but the one with limited execution time share is a GC initializa\u00adtion thread, while the \nother GC thread that performs stop\u00adthe-world collection has a parallelism of only 1, because it runs \nalone. Bottle graphs are an insightful way of visualizing multi\u00adthreaded program performance. Looking \nat the width of the boxes shows how well a program is parallelized. Threads that have low parallelism \nand have a large share in the total execution time appear as a large neck on the bottle, which shows \nthat they are a performance bottleneck. Bottle graphs thus naturally point to the most fruitful directions \nfor ef.\u00adciently optimizing a multi-threaded program. The next sec\u00adtion de.nes the two dimensions of the \nboxes. In Section 2.2, we explain how we measure unmodi.ed programs running on existing processors in \norder to construct bottle graphs. 2.1 De.ning Box Dimensions Each box in the bottle graph has two dimensions, \nthe height and the width, representing the thread s share in the total execution time and parallelism, \nrespectively. 2.1.1 Quantifying a thread s execution time share Attributing shares of the total execution \ntime to each of the threads in a multi-threaded program is not trivial. One cannot simply take the individual \nexecution times of each of the threads, because their sum is larger than the program s execution time \ndue to the fact that threads run in parallel. Individual execution times also do not account for variations \nin parallelism: threads that have low parallelism contribute more to the total execution time than threads \nwith high parallelism. To account for this effect, we de.ne the share each thread has in the total execution \ntime (or the height of the boxes) as its individual execution time divided by the number of threads that \nare running concurrently (including itself), as proposed in our previous work [7]. So, if n threads run \nconcurrently, they each get accounted one nth of their execution time. Of course, the number of threads \nthat run in parallel with a speci.c thread is not constant. While a thread is running, other threads \ncan be created or destroyed or scheduled in or out by the operating system. To cope with this behavior, \nwe divide the total execution time into intervals. The intervals are delimited by events that cause a \nthread to activate (cre\u00adation or scheduling in) or deactivate (destruction/joining or scheduling out). \nAs a result, the number of active threads is constant in each interval. Then we calculate the share of \nthe active threads in each interval as the interval time divided by the number of active threads. Inactive \nthreads do not get accounted any share. The .nal share of the total execution time of each thread is \nthen the sum of the shares over all intervals for which that thread was active. The sum of all threads \nshares equals the total execution time. We formalize the time share accounting in the follow\u00ading way. \nAssume ti is the duration of interval i, ri is the number of running threads in that interval, and Ri \nis the set containing the thread IDs of the running threads (therefore |Ri| = ri). Then the total share \nof thread j equals Sj =ti . (1) ri .i:j.Ri The execution time share of a thread is the height of its \nbox in the bottle graph. Therefore, the sum of all box heights, or the height of the total graph, is \nthe total program execution time.  2.1.2 Quantifying a thread s parallelism The other dimension of the \ngraph the width of the boxes represents the amount of parallelism of that thread, or the number of threads \nthat are co-running with that thread, including itself. A thread that runs alone has a parallelism of \none, while threads that run concurrently with n - 1 other threads have a parallelism of n. Due to the \nfact that the amount of parallelism changes over time, this number can also be a rational number.  The \ncalculation of the execution time share already incor\u00adporates the amount of parallelism by dividing the \nexecution time by the number of concurrent threads. We de.ne paral\u00adlelism as the time a thread is active \n(its individual running time) divided by its execution time share. Formally, the par\u00adallelism of thread \nj is calculated as ti ti .i:j.Ri .i:j.Ri Pj == , (2) ti Sj .i:j.Ri ri whereti is the sum of all interval \ntimes where .i:j.Ri thread j is active, which is its individual running time. Equation 2 in fact calculates \nthe weighted harmonic mean of the number of concurrent threads, i.e., the harmonic mean of ri weighted \nby the interval times ti. It is therefore truly the average number of concurrent threads for that speci.c \nthread. We choose harmonic mean because metrics that are inversely proportional to time (e.g., IPC or \nparallelism) should be averaged using the harmonic mean while those proportional to time (e.g., CPI) \nshould be averaged using the arithmetic mean [14]. Another interesting result from this de.nition of \nparal\u00adlelism is that the execution time share multiplied by the par\u00adallelism Sj \u00d7Pj equals the individual \nrunning time of the thread, or in bottle graph terms: the height multiplied by the width, i.e., the area \nof the box, equals the running time of a thread. If we consider the running time of a thread as a mea\u00adsure \nof the amount of work a thread performs, then we can interpret the area of a box in the bottle graph \nas that thread s work. Due to parallelism (the width of the box), a thread s impact on execution time \n(the height of the box) is reduced. This bottle graph design enhances their intuitiveness a lot of information \ncan be seen in one visualization and quickly facilitates targeted optimization. Reducing the amount \nof work (area) of a thread that has a narrow box will result in a higher total program execution time \n(height) re\u00adduction compared to reducing the work for a wide box. The impact of a thread on program execution \ntime can also be reduced by increasing its parallelism, which increases the width of the box and therefore \ndecreases its height, while the area (amount of work) remains the same.  2.2 Measuring Bottle Graph \nInputs Now that we have de.ned how the bottle graphs are con\u00adstructed, we design a tool that measures \nthe values in order to construct a bottle graph of an application running on an actual processor. The \ntool needs to detect: 1. The number of active threads, to calculate the ri values. 2. The IDs of the \nactive threads, to know which threads should be accounted time shares. 3. Events that cause a thread \nto activate and deactivate, to delimit intervals. 4. A timer that can measure the duration of intervals, \nto get the ti numbers.  The operating system (OS) is a natural place to construct our tool, as it already \nkeeps track of thread creation, destruc\u00adtion, and scheduling, and has .ne-grained timing capabili\u00adties. \nWe build a tool to gather the necessary information to construct bottle graphs using kernel modules with \nLinux ver\u00adsions 2.6 and 3.0. The kernel modules are loaded using a script that requires root privileges. \nCommunication with the modules (e.g., for communicating the name of the process that should be monitored) \nis done using writes and reads in the /proc directory. We use kernel modules to intercept sys\u00adtem calls \nthat perform thread creation and destruction, that schedule threads in and out, and that do synchronization \nwith futex (which implements thread yielding). Our tool keeps track of the IDs of active threads and \nthe timestamp of inter\u00adval boundaries. Our modules also keep track of two counters per thread: one to \naccumulate the running time of the thread (i.e., the total time it is active) and the other to accumulate \nthe execution time share (i.e., the running time divided by the number of concurrent threads). A kernel \nmodule is triggered upon a (de)activation call, and updates state and thread counters in the following \nway. The module obtains the current timestamp, and by subtract\u00ading the previous timestamp from it, determines \nthe execu\u00adtion time of the interval that just ended. It adds that time to the running time counter of \nall threads that were running in the past interval. It also divides that interval s time by the number \nof active threads, and adds the result to the time share counters of the active threads. Subsequently, \nthe mod\u00adule changes the set of running threads according to the infor\u00admation attached to the call (thread \nactivation or deactivation, and thread ID), and adapts the number of active threads. It also records \nthe current timestamp as the beginning of the next interval. When the OS receives a signal from software, \nthe two counters for each thread are written out, and this in\u00adformation is read by a script that generates \nthe bottle graphs. There are several advantages of using kernel modules to measure bottle graph components: \n1. The program under study does not need to be changed; the tool works with unmodi.ed program binaries. \n 2. The modules can be loaded dynamically; there is no need to recompile the kernel. 3. We can make \nuse of a nanosecond resolution timer, which enables capturing very short active or inactive periods. \nWe used ktime get and veri.ed in /proc/timer list that it has nanoscale resolution. 4. In contrast with \nsampling, our kernel modules continu\u00adously monitor all threads states accurately, and aggre\u00adgate metric \ncalculations online without loss of informa\u00adtion. 5. The extra overhead is limited, because the calculations \nare simple and need to be done only on thread creation and scheduling operations. On average, we measure \nan average 0.68% increase in program execution time com\u00ad   pared to disabling the kernel modules, with \na maximum of 1.11%, see Table 1 for per-benchmark overhead num\u00adbers. Discussion of design decisions. \nIn the design of our tool and experiments, we have made some methodological deci\u00adsions, which do not \nlimit the expressiveness of bottle graphs. We keep track of only synchronization events caused by fu\u00adtex, \nand thus our tool does not take into account busy waiting in spin loops, or interference between threads \nin shared hard\u00adware resources (e.g., in the shared cache and in the memory bus and banks). Threading \nlibraries are designed to avoid long active spinning loops and yield threads if the expected waiting \ntime is more than a few cycles, so we expect this to have no visible impact on the bottle graphs. Interference \nin hardware resources is a low-level effect that is less related to the characterization of the amount \nof parallelism in a multi\u00adthreaded program. When a thread performs I/O behavior, the OS schedules out \nthat thread. Thus, we choose not to track I/O system calls in our kernel modules because most I/O be\u00adhavior \nis already accounted for as inactive. Furthermore, we provide suf.cient hardware contexts in our hardware \nsetup, i.e., at least as many as the maximum number of runnable threads. We thus ensure that threads \nare only scheduled in and out due to synchronization events, and factor out the im\u00adpact of scheduling \ndue to time sharing a hardware context. If the number of hardware contexts were less than the number \nof runnable threads, the bottle graph s measured parallelism would be determined more by the machine \nthan by the ap\u00adplication characteristics. In the majority of our results, we read out our cumulative \nthread statistics, including running time and execution time share, at the end of the program run. We \nthen construct bottle graphs that summarize the behavior of the entire application execution on a per-thread \nbasis. However, our tool can be given a signal at any time to output, and optionally reset, thread counters, \nso that bottle graphs can be constructed throughout the program run. Thus, bottle graphs can be used \nto explore phase behavior of threads within a program run (as we do in Section 5), or analyze particular \nsections of code for scalability bottlenecks. Furthermore, while our OS modules keep track of counters \nper-thread, in the case of thread pools, the bottle graph scripts could be modi.ed to group separate \nthreads into one component, if desired. Both execution time share and parallelism are de.ned such that \nit is mathematically sound to aggregate thread components. 3. Methodology Now that we have introduced \nthe novel and intuitive con\u00adcept of bottle graphs, we perform experiments on unmod\u00adi.ed applications \nrunning on real hardware to demonstrate the usefulness of bottle graphs. While bottle graphs can be used \nto analyze any multi-threaded program, in this paper we chose to analyze managed language applications. \nNot only are managed languages widely used in the community, but Table 1. Evaluated benchmarks and kernel \nmodule over\u00adhead. ST=single-threaded, MT=multi-threaded. Benchmark Suite Version ST/MT Overhead antlr \nDaCapo 2006 ST 0.40% bloat DaCapo 2006 ST 0.64% eclipse DaCapo 2006 ST 0.70% fop DaCapo 2006 ST 0.20% \njython DaCapo 2009 ST 0.80% luindex DaCapo 2009 ST 1.00% avrora DaCapo 2009 MT 1.11% lusearch DaCapo \n2009 MT 0.32% pmd DaCapo 2009 MT 0.44% pseudoJBB SPEC 2005 MT 0.90% sun.ow DaCapo 2009 MT 0.03% xalan \nDaCapo 2009 MT 0.91% they also provide the added complexity of runtime service threads that manage memory \nand do dynamic compilation alongside the application. Thus, we can analyze both appli\u00adcation and service \nthread performance and scalability using our visualization tool. We evaluate Java benchmarks, see Table \n1, from the Da-Capo benchmark suite [4] and one from the SPEC 2005 benchmark suite, pseudoJBB, which \nis modi.ed from its original version to do a .xed amount of work instead of run for a .xed amount of \ntime [19]. There are 6 single\u00adthreaded (ST) and 6 multi-threaded (MT) benchmarks.1 Al\u00adthough bottle graphs \nare designed for multi-threaded appli\u00adcations, it is interesting to analyze the interaction between a \nsingle-threaded application and the Java virtual machine (JVM) threads. We use the default input set, \nunless men\u00adtioned otherwise. For our experiments, we vary the number of application threads (2, 4 and \n8 for the multi-threaded applications) and garbage collector threads (1, 2, 4 and 8). We experiment with \ndifferent heap sizes (as multiples from the minimum size that each benchmark can run in), but we present \nresults with two times the minimum to keep the heap size fairly small in order to exercise the garbage \ncollector frequently so as to evaluate its time and parallelism components. We run the benchmarks for \n15 iterations, and collect bottle graphs for every iteration individually, but present main results for \nthe 13th iteration to show stable behavior. We performed our experiments on an Intel Xeon E5\u00ad2650L server, \nconsisting of 2 sockets, each with 8 cores, run\u00adning a 64-bit 3.2.37 Linux kernel. Each socket has a \n20 MB LLC, shared by the 8 cores. For our setup, we found that the number of concurrent threads rarely \nexceeds 8, with a max\u00adimum of 9 (due to a dynamic compilation thread). There\u00adfore, we only use one socket \nin our experiments with Hy\u00ad 1 Although eclipse spawns multiple threads, we found that the JavaIndex\u00ading \nthread is the only running thread for most of the time, so we categorize it as a single-threaded application. \n perThreading enabled, which leads to 16 available hardware contexts. This setup avoids data traversing \nsocket bound\u00adaries, which could have an impact on performance that is hardware related, as demonstrated \nin [18]. The availability of 16 hardware contexts does not trigger the OS to schedule out threads other \nthan for synchronization or I/O. We run all of our benchmarks on Jikes Research Vir\u00adtual Machine version \n3.12 [1]. We use the default best\u00adperforming garbage collector (GC) on Jikes, the stop-the\u00adworld parallel \ngenerational Immix collector [3]. In addition to evaluating the Jikes RVM in Sections 4 and 5, we also \ncompare with the OpenJDK JVM version 1.6 [17] in Sec\u00adtion 6. We use their throughput-oriented parallel \ncollector (also stop-the-world) in both the young and old generations. It should be noted that OpenJDK \ns compacting old gener\u00adation has a different layout than Jikes old generation, and thus will have a different \nimpact on both the application and collector performance. Because we use a stop-the-world collector, \nwe can divide the execution of a benchmark into application and collec\u00adtion phases. Application and GC \nthreads never run concur\u00adrently; therefore, the application and GC thread components in the bottle graph \ncan be analyzed in isolation. For exam\u00adple, the total height of all application thread boxes is the to\u00adtal \napplication running time, and the same holds for the GC threads. Also, because the collector never runs \nconcurrently with other threads, the parallelism of the GC boxes is the parallelism of the collector \nitself. However, an interesting avenue for future work is to analyze the scalability of Java applications \nrunning with a concurrent collector. 4. Jikes RVM and Benchmark Analysis By varying the number of application \nthreads, GC threads, heap size, and collecting results over many iterations, we have generated over 2,000 \nbottle graphs. We describe the main .ndings from this study in this section, together with a few bottle \ngraphs that show interesting behavior. We refer the interested reader to the additional supporting material \nfor all bottle graphs generated during this study, available at http://users.elis.ugent.be/~kdubois/bottle_ \ngraphs_oopsla2013. We .rst de.ne some terminology that will be used to de\u00adscribe the bottle graphs we \ngathered for Java. Application work is the sum of all active execution times of all appli\u00adcation threads \n(excluding JVM threads), i.e., the total area of all application thread boxes.2 Likewise, we de.ne appli\u00adcation \ntime as the sum of all execution time shares of all application threads, i.e., the total height of the \napplication thread boxes. Along the same lines, we de.ne garbage col\u00ad 2 We classify the MainThread as \npart of the application. The MainThread does some initialization and then calls the main method of the \napplication. For single-threaded applications, all of the work is done in this MainThread. For multi-threaded \napplications, it does some initialization and then spawns the application threads. lection work as the \nsum of all GC threads active execution times, i.e., the total area of all GC thread boxes, and garbage \ncollection time as the sum of all GC threads execution time shares, i.e., the total height of the GC \nthread boxes. We will discuss collector and application performance and their impact on each other in \nSections 4.2 and 4.3, but we .rst show and analyze bottle graphs for all benchmarks in the next section \n(at the steady-state 13th iteration). In Section 4.4, we also analyze the impact of the optimizing compiler \nby comparing the .rst and later iterations. 4.1 Benchmark Overview Figure 2 shows bottle graphs for \nall evaluated benchmarks (only the threads that have a visible component in the bot\u00adtle graph are shown). \nAll graphs have two GC threads, and for the multi-threaded applications, we use four applica\u00adtion threads. \nIn general, turquoise boxes represent Jikes MainThread which calls the application s main method. GC \nthread boxes are always presented in brown (including the GC controller thread, which explains the third \nGC box that appears in some graphs), while the dynamic compiler (called Organizer) is always presented \nin dark green. Application thread colors vary per graph. We found that all other JVM threads have negligible \nimpact on execution time, and thus are not visible in the bottle graphs. These graphs show the intuitiveness \nand insightfulness of bottle graphs. Single-threaded benchmarks can be easily identi.ed as having a single \nlarge component with a paral\u00adlelism of one. The graph of eclipse clearly shows that it be\u00adhaves as a \nsingle-threaded application, as the JavaIndexing thread dominates performance, although it spawns multiple \nthreads. Apart from the application and GC threads, antlr also has a visible Organizer thread, which \nis the only other JVM thread that was visible in all of our graphs. This thread has a parallelism of \ntwo, meaning that the JVM compiler always runs with one other thread, the MainThread in this case. Because \nit has a small running time, it does not have much impact on the parallelism of the main thread. When \nwe look at the multi-threaded benchmarks, we see that for lusearch, pseudoJBB, sun.ow and xalan, the \nap\u00adplication threads have a parallelism of four, meaning that these benchmarks scale well to four threads. \nPseudoJBB has a rather large sequential component (in the MainThread), compared to the others. PseudoJBB \ndoes more initializa\u00adtion before it spawns the application threads, one per ware\u00adhouse, to perform the \nwork. Avrora is different in that it spawns six threads instead of four. This benchmark sim\u00adulates a \nnetwork of microcontrollers, and every microcon\u00adtroller is simulated by one thread. Therefore, the number \nof threads spawned by avrora depends on the input, and the de\u00adfault input has six microcontrollers. The \nbottle graph reveals that the parallelism of avrora s application threads is limited to 2.4, although \nthere are six threads and 16 available hard\u00adware contexts. Avrora uses .ne-grained synchronization to \naccurately model the communication between the microcon\u00ad  (a) antlr (b) avrora (c) bloat (d) eclipse \n(e) fop (f) jython (g) luindex (h) lusearch (i) pseudoJBB (j) pmd (k) sun.ow (l) xalan     Figure \n2. Bottle graphs for all benchmarks for the 13th iteration with 2 GC threads. Multi-threaded applications \nare run with 4 application threads. (a) 1 GC thread (b) 2 GC threads (c) 4 GC threads (d) 8 GC threads \n Figure 3. Xalan: scaling of GC threads with 4 application threads. Figure 4. Xalan: scaling of application \nthreads with 2 GC threads. trollers, which reduces the exploited parallelism. This prob\u00adlem could potentially \nbe solved by simulating close-by mi\u00adcrocontrollers in one thread, instead of one thread per micro\u00adcontroller, \nwhich will reduce the synchronization between the threads. Pmd is another interesting case: three of \nthe four threads have a parallelism of more than three, but one thread has much lower parallelism and \na much larger share of the execution time (PmdThread1). Pmd has an imbalance prob\u00adlem between its application \nthreads. In Section 5, we analyze bottle graphs at various times within pmd s run to help elab\u00adorate \non the cause of this parallelism limitation and provide suggestions to improve balance. Although two \nGC threads are used in these experiments, the average parallelism of garbage collection is around 1.4. \nThe next section explores varying the number of threads, and elaborates on the impact of the number of \nGC and application threads on garbage collector performance.  4.2 Garbage Collection Performance Analysis \nWe now explore what the bottle graphs reveal about garbage collection performance, while varying the \nnumbers of appli\u00adcation and collection threads. We analyze in depth the vari\u00adation in the amount of garbage \ncollection time (sum of GC box heights) and work (sum of GC box areas). Figures 3 and 4 show bottle graphs \nfor xalan with increasing num\u00adber of GC threads (Figure 3) and increasing number of ap\u00adplication threads \n(Figure 4). We include only the xalan re\u00adsults here because of space constraints; this benchmark has \nrepresentative behavior with respect to collection. Figure 5 shows the average collection work (a) and \ntime (b) for all multi-threaded benchmarks, as a function of the number of GC threads and the number \nof application threads.3 The val\u00adues are normalized to the con.guration with 2 application threads and \n1 GC thread. Figure 6 shows the same data for the single-threaded benchmarks, obviously without the di\u00admension \nof the number of application threads. We make the following observations: Collection work increases with \nan increasing number of collection threads. When the number of GC threads in\u00adcreases, the total collection \nwork increases, i.e., the sum of the running times of all GC threads increases, see Figures 5 (a) and \n6. For xalan, total collection work which equals the total area of all GC thread boxes increases by 73% \nfrom 1 to 8 GC threads (see Figure 3). For all multi-threaded bench\u00ad 3 We exclude the numbers for avrora \nand pseudoJBB for Figures 5, 7, 8, 9, 15, and 16. For these benchmarks, it is impossible to vary the \nnumber of application threads independently from the problem size.  (a) Garbage collection work (b) \nGarbage collection time Figure 5. Average garbage collection work (a) and time (b) as a function of \napplication and GC thread count (multi-threaded applications). Numbers are normalized to the 2 application \nand 1 GC thread con.guration. Collection work increases with increasing GC thread count and increasing \napplication thread count, and 2 GC threads results in minimum collection time for all application thread \ncounts. marks, there is an increase of 120% (averaged over all ap\u00adplication thread counts), and 198% \nfor the single-threaded benchmarks. There are a number of reasons for this behavior. First, more threads \nincur more synchronization overhead, i.e., ex\u00adtra code to perform synchronization due to GC threads ac\u00adcessing \nshared data. Figure 16 in Section 6 (Jikes line) shows that the number of futex calls signi.cantly increases \nas the number of GC threads increases. Second, because garbage collection is a very data-intensive process \nand the last-level cache (LLC) is shared by all cores, more GC threads will lead to more interference \nmisses in the LLC, leading to a larger running time. Figure 7 shows the number of LLC cache misses as \na function of the number of GC threads and the number of application threads for all multi-threaded ap\u00adplications, \nnormalized to the 2 application, 1 GC thread con\u00ad.guration. The number of LLC cache misses increases \nsig\u00adni.cantly when the number of GC threads increases (more than 2.5 times for 8 GC threads compared \nto 1 GC thread), which raises the total execution time of the GC threads. Collection work increases with \nan increasing number of application threads. There is an increase in the amount of time garbage collection \nthreads are actively running (or their total work), as we go to larger application thread counts. For \nxalan, collection work increases by 60% if the number of ap\u00adplication threads is increased from 2 to \n8 (see Figure 4). For all multi-threaded benchmarks, we see an average increase of 47% (over all GC thread-counts), \nin Figure 5 (a). To ex\u00adplain this behavior, we refer to Figure 8, which shows the average number of collections \nthat occurred during the exe\u00adcution of the multi-threaded benchmarks,4 again as a func\u00adtion of the number \nof GC and application threads. When in\u00ad 4 We exclude pmd from this graph, because due to its imbalance, \nonly one thread is running during a signi.cant portion of its execution time. Since this portion increases \nwith the number of application threads, the number of collections decreases, while we see an increase \nfor all other benchmarks.    Figure 8. Average number of collections as a function of application \nand GC thread count (multi-threaded applica\u00adtions). Numbers are normalized to the 2 application and 1 \nGC thread con.guration. creasing the number of GC threads, the number of collec\u00adtions does not increase. \nHowever, the number of application threads has a clear impact on the number of collections: the more \napplication threads, the more collections. The intuition behind this observation is that more threads \ngenerate more live data in a .xed amount of time (because Jikes has thread\u00adlocal allocation where every \nthread gets its own chunk of memory to allocate into), so the heap .lls up faster compared to having \nfewer application threads. The more collections, the more collection work that needs to be done. 2 GC \nthreads are optimal regardless of the number of ap\u00adplication threads. Figures 5 (b) and 6 show that garbage \ncollection time is minimal for two GC threads in Jikes, even for lower and higher application thread \ncounts. Although the amount of work increases when the number of GC threads is increased from 1 to 2, \ncollector parallelism is also increased (from 1 to 1.5), leading to a lower net collection time. When \nthe number of GC threads is further increased to 4 and 8, par\u00adallelism increases only slightly (to 1.7 \nand 1.8, respectively), and does not compensate for the extra amount of work, lead\u00ading to a net increase \nin collection time. Although we present results here for only two times the minimum heap size, we found \ntwo GC threads to be optimal for other heap sizes as well.  4.3 Application Performance Analysis We \nanalyze changes in the application time and work as we vary the number of application threads, which \nseem to suf\u00adfer less from limited parallelism than the garbage collector. Figure 9 shows the application \nexecution time (excluding garbage collection time) and work as a function of the num\u00adber of application \nthreads (for the multi-threaded applica\u00adtions), keeping the GC threads at two. Numbers are normal\u00adized \nto those for two application threads. Application time decreases with an increasing number of application \nthreads, but the decrease is limited because ap\u00adplication work increases due to the overheads of paral\u00adlelism. \nWhen the application thread count is increased, ap- Figure 9. Average application work and time as a \nfunction of application thread count (multi-threaded applications). Numbers are normalized to the 2 application \nthread con.g\u00aduration. Application time decreases with increasing applica\u00adtion thread count, but the decrease \nis limited because appli\u00adcation work increases with more application threads. plication time does decrease, \nbut not proportionally to the number of threads. Compared to two application threads, execution time \ndecreases with a factor of 1.4 for four ap\u00adplication threads and 1.9 for 8 threads. Part of the reason \nthis decrease is not higher is the limited parallelism (aver\u00adage application parallelism equals 1.9, \n3.1 and 4.7, for 2, 4 and 8 application threads, respectively). However, this does not fully cover the \nsmaller application speedup: from 2 to 8 application threads, parallelism is increased by a factor of \n2.5, while execution time is reduced by a factor of only 1.9. This difference is explained by the fact \nthat application work also increases with the number of application threads, see Figure 9. This increase \nis due to synchronization over\u00adhead (the number of futex calls for the application increases from 1.5 \nto 4.7 calls per ms when the number of application threads increases from 2 to 8) and an increasing number \nof LLC misses due to more interference (see also Figure 7). In\u00adcreasing the number of application threads \nleads to more ap\u00adplication work and increased parallelism, resulting in a net reduced execution time, \nbut due to the extra overhead, the execution time reduction is smaller than the thread count in\u00adcrease. \n 4.4 Compiler Performance Analysis Lastly, while generating our bottle graphs across many benchmark \niterations, we noticed the difference between startup and steady state behavior discussed in detail in \nJava methodology research [4]. Figure 10 shows the bottle graphs of one single-threaded benchmark, jython, \nduring the .rst, 9th and 11th iterations. During the .rst iteration, we see a large overall execution \ntime, and a large (one second) time share for the Organizer thread. This JVM service thread performs \ndynamic compilation concurrently with the appli\u00adcation (it has a parallelism of two), and thus is very \nactive in the .rst iteration, but is much more minimal in iteration nine.  (a) First iteration (a) 9th \niteration (b) 11th iteration Iteration nine has a reduced execution time because the Java source code \nis now optimized and the benchmark is running more at steady-state. However, the bottle graph for iteration \n11 shows an increased Organizer thread component. This behavior is speci.c to this benchmark; other applications \nsee the Organizer box disappear in all higher iterations. Jython is different in that it dynamically \ninterprets python source code into bytecode, and then runs it. Jython actually runs a benchmark within \nitself, and Jikes continues to optimize the generated bytecode with the optimizing compiler at various \niterations, because the compiler is probabilistic and is trig\u00adgered unpredictably. Thus, bottle graphs \nare also useful for seeing program and JVM variations between iterations. 5. Solving the Poor Scaling \nof Pmd We have analyzed the performance of both Java applications and Jikes RVM s service threads using \nbottle graphs. As shown in Figure 2, and discussed in Section 4.1, pmd has one thread that has signi.cantly \nlimited parallelism. We now analyze this bottleneck and propose suggestions on how to .x pmd s scalability \nproblem. Figure 11 shows the bottle graphs for pmd for 2, 4 and 8 application threads, while keeping \nthe collection threads at two and using the default input set. With two applica\u00adtion threads, the left \ngraph shows these threads have approx\u00adimately the same height and width (a parallelism close to two). \nHowever, for 4 and 8 threads, pmd clearly has an im\u00adbalance issue: there is one thread that has less \nparallelism and a larger execution time share than the other threads. To understand the cause, we gathered \nbottle graphs at sev\u00aderal time intervals (every 0.5 seconds) within the 13th iter\u00adation of the benchmark, \nrunning with 2 GC and 8 applica\u00adtion threads, shown in Figure 12. We see that after the .rst 0.5 seconds, \nalthough there is some variation, the applica\u00adtion threads are still fairly balanced in regards to parallelism. \nStarting from after the second time interval, one application thread has limited parallelism and a larger \nshare of execu\u00adtion time (PmdThread7). After one second of execution, that same thread continues to run \nalone while all other applica\u00adtion threads have .nished their work. Pmd is a (Java) source code analyzer, \nand .nds unused variables, empty catch blocks, unnecessary object creation, etc. It takes as input a \nlist of source code .les to be pro\u00adcessed. The default DaCapo input for pmd is a part of the source code \n.les of pmd itself. There is also a large input set, which analyzes all of the pmd source code .les. \nInter\u00adnally, pmd is parallelized using a work stealing approach. All .les are put in a queue, and the \nthreads pick the next un\u00adprocessed .le from the queue when they .nish processing a .le. Compared to static \nwork partitioning, work stealing normally improves balance, because one thread can process a large job, \nwhile another thread processes many small jobs. Imbalance can only occur when one or a few jobs have \nsuch a large process time that there are not enough other small jobs to be run in parallel. This is exactly \nthe case for the de\u00adfault input set of pmd. There are 220 .les, with an average size of 3.8 KB. However, \nthere is one .le that is 240 KB, which is around 63 times larger than the average. Therefore, the thread \nthat picks that .le will always have a larger exe\u00adcution time than the other threads, and there are not \nenough other .les to keep the other threads concurrently busy. This problem is partly solved when using \nthe large input set, which also has the same big .le, but there are 570 .les in total, so more .les can \nbe processed concurrently with the big .le. Figures 13(a) (c) show the bottle graphs for the large input \nset with 2, 4 and 8 application threads. The imbalance problem is solved for 2 and 4 application threads, \nbut is still present for 8 threads (although less pronounced compared to the default input set). The \nmore threads there are, the more other jobs are needed to run concurrently with the large job. Figure \n13(d) shows the bottle graph for 8 threads and the large input set excluding that one big .le, which \nleads to a balanced execution.  (a) 2 Application threads (b) 4 Application threads (c) 8 Application \nthreads (a) 2 Application threads (b) 4 Application threads   (c) 8 Application threads (d) 8 Application \nthreads w/o biggest .le We can conclude that users of pmd should make sure that there is no .le that \nis much larger than the others to prevent an imbalanced, and therefore inef.cient, execution. The bal\u00adance \ncan also be improved by making the scheduler in pmd more intelligent. For example, the .les to be processed \ncan be ordered by decreasing .le size, such that big .les are pro\u00adcessed .rst and not after a bunch of \nsmaller .les. In that case, there are more small .les left for the other threads, and bal\u00adance is improved. \nAnother, probably more intrusive, solution is to provide the ability to split a single .le across multiple \nthreads. Apart from imbalance, there is also a problem of limited parallelism in pmd. Figure 13(d) shows \nthat the parallelism of 8 application threads is only 3.5. We looked into the code and found a synchronized \nmap data structure that is shared between threads and guarded by one lock. Reducing the time the lock \nis held and/or using .ne-grained locking should improve parallelism, and therefore performance, for pmd. \n6. Comparing Jikes to OpenJDK In Section 4 we analyzed the performance of the garbage collector and the \napplication with Jikes RVM. We made two novel observations: collector parallelism is limited, leading \nto an optimal GC thread count of 2, and that the number of GC threads and the number of application threads \nhave an impact on the amount of collection work. We present here a similar analysis on the OpenJDK virtual \nmachine, revealing that OpenJDK s garbage collector scales better than in Jikes, bene.ting from up to \n8 GC threads. However, we .nd that collection work still increases with the number of application threads \nand GC threads. Figure 14 shows the bottle graphs for pseudoJBB with 4 application threads on OpenJDK, \nwith an increasing GC thread count. We chose pseudoJBB graphs here because they are most illustrative \nof collector behavior, but other benchmarks have similar behavior. It is immediately clear that GC scales \nmuch better for OpenJDK than for Jikes. The average collection parallelism across all multi-threaded \nbenchmarks is 1, 1.9, 3.3 and 4.5, for 1, 2, 4 and 8 GC threads, respectively. This parallelism is substantially \nlarger than the 1.8 parallelism for 8 GC threads on Jikes. We further investigate the performance of \nOpenJDK by viewing its collection work and time as a function of GC and application thread count in Figure \n15. We present aver\u00adage collection work (a) and time (b) for the multi-threaded benchmarks normalized \nto the 1 GC and 2 application thread con.guration (contrasted with Figure 5). We con.rm that OpenJDK \nscales better than Jikes by seeing that collection  (a) 1 GC thread (b) 2 GC threads (c) 4 GC threads \n(d) 8 GC threads  application thread count. time decreases with an increasing number of GC threads in \nFigure 15(b). There is less synchronization during garbage collection in OpenJDK compared to Jikes, as \nevident in Fig\u00adure 16 which shows the number of futex calls per unit of time as a function of the number \nof GC threads. Although the number of futex calls also increases with increasing GC thread count, the \nincrease is much smaller for OpenJDK than for Jikes. For OpenJDK, we found 4 GC threads to be optimal \nwith either 2 or 4 applications threads, and 8 GC threads optimal for 8 application threads. Garbage \ncollection on OpenJDK scales better than for Jikes RVM, but we observe that collector time slightly increases \nor does not decrease much between 4 and 8 GC threads, which suggests that garbage collection scaling \non OpenJDK saturates at 4 to 8 GC threads. This is in line with the .ndings in [10], where the authors \nobserve a decrease in collection time when the number of GC threads is increased from 1 to 6, but an \nincrease when the number of GC threads is increased to 12 and more. Our two other observations for Jikes, \nnamely that collec\u00adtion work increases with GC thread count and application thread count, still hold \nfor OpenJDK. Figure 15(a) for Open-JDK looks very similar to Figure 5(a) for Jikes. While we have observed \nin both JVMs a saturation point in the utility of increasing the parallelism of garbage collection threads, \nwe still .nd that inter-thread synchronization has a signi.\u00adcant impact on garbage collection performance. \n  7. Related Work We now describe related work in performance visualization and Java parallelism analysis. \nWe detail one particularly related visualization tool called WAIT in Section 7.1.1. 7.1 Performance \nVisualization Software developers heavily rely on tools for guiding where to optimize code. Commercial \nofferings, such as Intel VTune Ampli.er XE [12], Sun Studio Performance Analyzer [13], and PGPROF from \nthe Portland Group [20] use hardware performance counters and sampling to derive where time is spent, \nand point the software developer to places in the source code to focus optimization. Additional features \nof\u00adfered include suggestions for potential tuning opportuni\u00adties, collecting lock and wait behavior, \nvisualization of run\u00adning and waiting threads over time, etc. The key feature of these tools is that \nthey provide fairly detailed analysis at .ne granularity in small functions and individual lines of code. \nRecent work focused on minimizing the overhead even further, enabling the analysis of very small code \nregions, such as critical sections [6]. Other related work [16] pro\u00adposes a simple and intuitive representation, \ncalled Parallel Block Vectors (PBV), which map serial and parallel phases to static code. Other research \nproposes the Kremlin tool, which analyzes sequential programs to recommend sections of code that would \nget the most speedup from paralleliza\u00adtion [9]. All of these approaches strive at providing .ne\u00adgrained \nperformance insight. Unfortunately, none of these approaches provide a simple and intuitive visualization \nand understanding of gross performance scalability bottlenecks in multi-threaded applications, as bottle \ngraphs do and which is needed by software developers to guide optimization. Some recent work in performance \nvisualization focused on capturing and visualizing gross performance scalability trends in multi-threaded \napplications running on multicore hardware, but do not guide the programmer on where to fo\u00adcus optimization. \nSpeedup stacks [8] present an analysis of the causes of why an application does not achieve perfect scalability, \ncomparing achieved speedup of a multi-threaded program versus ideal speedup. Speedup stacks measure the \nimpact of synchronization and interference in shared hard\u00adware resources, and attribute the gap between \nachieved and ideal speedup to the different possible performance delim\u00aditers. By doing so, speedup stacks \neasily point to scala\u00adbility limiters, but present no data on which thread could be the cause, and do \nnot suggest how to overcome these scalability limitations. Bottle graphs, on the other hand, provide \ndetailed information on per-thread synchronization events, showing where optimization effort should be \ntar\u00adgeted, namely at the narrowest and tallest thread(s) in the graph. In our most recent work, we presented \ncriticality stacks [7], which display per-thread contributions to total program performance. Criticality \nstacks focus on synchro\u00adnization only, and do not incorporate parallelism as bottle graphs do. Moreover, \nthis work requires hardware modi.\u00adcations and, while it points out thread imbalances, it does not suggest \nhow much gain could be achieved by making a particular thread better able to co-execute with other threads. \n 7.1.1 Comparison to IBM WAIT IBM WAIT5 [2] is a performance visualization tool for di\u00adagnosing performance \nand scalability bottlenecks in Java programs, particularly server workloads. It uses a light\u00adweight pro.ler \nthat collects samples of information about each thread at regular points in time (con.gurable through \na sampling rate parameter). WAIT records information on each thread s status (active, waiting or idle), \nlocks (held or waiting for), and where in the code the thread is execut\u00ading. This data is used to construct \na graph that visualizes the threads status over time (x-axis), each bar showing a sample point. The bar \ns height is the total number of threads for that sample, and the bar is color-coded by thread sta\u00adtus. \nFigure 17 shows the output of WAIT for pmd running on OpenJDK with 8 application threads and 2 GC threads \nduring the 13th iteration using a 1 second sampling rate, where CPU denotes active threads, and Lock \ndenotes inac\u00adtive threads. Information about code position and locks can be retrieved by clicking on \nthe bars in the timeline. While WAIT is a powerful analysis tool for Java pro\u00adgrams, it has some limitations. \nFirst, it can be applied only to Java application threads, not to parallel programs written in other \nlanguages or to Java virtual machine service threads, both of which can be analyzed easily with our bottle \ngraphs because we use OS modules. Second, WAIT is sampling\u00adbased, and thus collects a snapshot of information \nonly at speci.c program points, with increasing overhead with .ner\u00adgranularity sampling. To demonstrate \nthis, Figure 17 shows results for pmd using at the lowest default sampling period value of 1 second. \nWAIT only collects 3 samples, which sug\u00adgest that there is only one active (CPU) thread during the ex\u00adecution. \nWe lowered the sampling rate to 50 milliseconds by 5 https://wait.ibm.com/  modifying WAIT s scripts, \nand produced the more detailed graph in Figure 18 which reveals that the number of active threads varies \nover time. However, the overhead of using the 1 second versus 50 millisecond sampling period jumps from \n0.87% to 16.62%, an order of magnitude larger than for our tool. In contrast, bottle graphs contain much \nmore information for lower overhead. Our OS modules are continually mon\u00aditoring every thread status change, \nand aggregating our ex\u00adecution time share and parallelism metrics at all times in a multi-threaded program \nrun, on a per-thread basis. For roughly the same overhead, we contrast Figure 12 showing bottle graphs \nat various times in a run of pmd with Figure 17 showing WAIT s three thread samples. WAIT s visual repre\u00adsentation \nmakes it hard to know that one of pmd s threads is a bottleneck throughout the run. In the end, pmd s \nparallel imbalance due to input imbalance is dif.cult to detect with\u00adout analyzing the source code and \ninput. In conclusion, bot\u00adtle graphs visualization of scalability per-thread facilitates grouping by \ncategory (such as for thread pools or garbage collection threads) in order to analyze the group s execution \ntime share, parallelism, or work to pinpoint parallelism im\u00adbalances.  7.2 Java Parallelism Analysis \nAnalyzing Java performance and parallelism has become an active area of research recently. Most of these \nstudies use custom-built analyzers to measure speci.c characteristics of interest. For example, Kalibera \net al. [15] analyze concur\u00adrency, memory sharing and synchronization behavior of the DaCapo benchmark \nsuite. They provide concurrency met\u00adrics and analyze the applications in-depth, focusing on in\u00adherent \napplication characteristics. They do not provide a vi\u00adsual analysis tool to measure and quantify performance \nand scalability, and reveal bottlenecks on real hardware as we do. Researchers recently analyzed the \nscalability problems of the garbage collector in the OpenJDK JVM [10]. They also con.rm that the total \ncollection times increase with the num\u00adber of collector threads, without providing a visualization tool. \nThey did follow-on work to optimize scalability at large thread-counts for the parallel stop-the-world \ngarbage collec\u00adtion in OpenJDK [11]. Similarly, Chen et al. [5] analyzed scalability issues in the OpenJDK \nJVM, and provided ex\u00adplanations at the hardware level by measuring cache misses, DTLB misses, pipeline \nmisses, and cache-to-cache transfers. They also explored the sizing of the young generation and measured \nthe bene.ts of thread-local allocation. They did not, however, vary the number of collection threads \nor ex\u00adplore the scalability limitations of the parallel collector it\u00adself, or how it interacts with the \napplication, as we do in this paper. 8. Conclusions We have presented bottle graphs, an intuitive and \nuseful tool for visualizing multi-threaded application performance, an\u00adalyzing scalability bottlenecks, \nand targeting optimization. Bottle graphs represent each thread as a box, showing its execution time \nshare (height), parallelism (width), and to\u00adtal running time (area). The total height of the bottle graph \nwhen these boxes are stacked on top of each other is the total application execution time. Because we \nplace threads with the largest parallelism on the bottom, the neck of the bottle graph points to threads \nthat offer the most potential for optimization, i.e. those with limited parallelism and large execution \ntime share. We have built light-weight OS modules to calculate the components of bottle graphs for unmodi.ed \nparallel pro\u00adgrams running on real hardware, with minimal overhead. Then we have used bottle graphs to \nanalyze a set of 12 Java benchmarks, revealing scalability limitations in several well-known applications \nand suggesting optimizations. We have also used bottle graphs to analyze Jikes JVM service threads, revealing \nvery limited parallelism when increasing the number of garbage collection threads beyond two due to extra \nsynchronization activity. We have compared this to OpenJDK s garbage collector which scales much better \nfor our thread counts. Bottle graphs are a powerful visualization tool that is necessary for tackling \nmulti-threaded application bottlenecks in modern multicore hardware.  Acknowledgments We thank the anonymous \nreviewers for their constructive and insightful feedback. Stijn Eyerman is supported through a postdoctoral \nfellowship by the Research Foundation Flan\u00adders (FWO). Additional support is provided by the FWO project \nG.0179.10N, the UGent-BOF project 01Z04109 and the European Research Council under the European Com\u00admunity \ns Seventh Framework Programme (FP7/2007-2013) / ERC Grant agreement no. 259295. A. Appendix See http://users.elis.ugent.be/~kdubois/bottle_ \ngraphs_oopsla2013/ for more bottle graphs. This website also contains the OS modules tool to measure \nthe data to construct bottle graphs. References [1] B. Alpern, C. R. Attanasio, A. Cocchi, D. Lieber, \nS. Smith, T. Ngo, J. J. Barton, S. F. Hummel, J. C. Sheperd, and M. Mer\u00adgen. Implementing Jalape no in \nJava. In Proceedings of the Annual ACM SIGPLAN Conference on Object-Oriented Pro\u00adgramming, Systems, Languages \nand Applications (OOPSLA), pages 314 324, Nov. 1999. [2] E. Altman, M. Arnold, S. Fink, and N. Mitchell. \nPerformance analysis of idle programs. In Proceedings of the Annual ACM SIGPLAN Conference on Object-Oriented \nProgramming, Sys\u00adtems, Languages and Applications (OOPSLA), pages 739 753, Oct. 2010. [3] S. M. Blackburn \nand K. S. McKinley. Immix: A mark-region garbage collector with space ef.ciency, fast collection, and \nmutator performance. In Proceedings of the Annual ACM SIGPLAN Conference on Programming Language Design \nand Implementation (PLDI), pages 22 32, June 2008. [4] S. M. Blackburn, R. Garner, C. Hoffmann, A. M. \nKhan, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Frampton, S. Z. Guyer, M. Hirzel, A. L. Hosking, \nM. Jump, H. B. Lee, J. Moss, A. Phansalkar, D. Stefanovic, T. VanDrunen, D. von Dincklage, and B. Wiedermann. \nThe DaCapo benchmarks: Java benchmarking development and analysis. In Proceedings of the Annual ACM SIGPLAN \nConference on Object-Oriented Programming, Systems, Languages and Applications (OOP-SLA), pages 169 190, \nOct. 2006. [5] K.-Y. Chen, J. M. Chang, and T.-W. Hou. Multithreading in Java: Performance and scalability \non multicore systems. IEEE Transactions on Computers, 60(11):1521 1534, Nov. 2011. [6] J. Demme and S. \nSethumadhavan. Rapid identication of ar\u00adchitectural bottlenecks via precise event counting. In Pro\u00adceedings \nof the Annual International Symposium on Computer Architecture (ISCA), pages 353 364, June 2011. [7] \nK. Du Bois, S. Eyerman, J. B. Sartor, and L. Eeckhout. Criti\u00adcality stacks: Identifying critical threads \nin parallel programs using synchronization behavior. In Proceedings of the Annual International Symposium \non Computer Architecture (ISCA), pages 511 522, June 2013. [8] S. Eyerman, K. Du Bois, and L. Eeckhout. \nSpeedup stacks: Identifying scaling bottlenecks in multi-threaded applications. In Proceedings of the \nInternational Symposium on Perfor\u00admance Analysis of Software and Systems (ISPASS), pages 145 155, Apr. \n2012. [9] S. Garcia, D. Jeon, C. M. Louie, and M. B. Taylor. Kremlin: Rethinking and rebooting gprof \nfor the multicore age. In Proceedings of the Annual ACM SIGPLAN Conference on Programming Language Design \nand Implementation (PLDI), pages 458 469, June 2011. [10] L. Gidra, G. Thomas, J. Sopena, and M. Shapiro. \nAssessing the scalability of garbage collectors on many cores. ACM SIGOPS: Operating Systems Review, \n45(3), Dec. 2011. [11] L. Gidra, G. Thomas, J. Sopena, and M. Shapiro. A study of the scalability of \nstop-the-world garbage collectors on multi\u00adcore. In Proceedings of the International Conference on Ar\u00adchitectural \nSupport for Programming Languages and Operat\u00ading Systems (ASPLOS), pages 229 240, Mar. 2013. [12] Intel. \nIntel VTuneTM Ampli.er XE 2011. http://software.intel.com/en-us/articles/intel-vtune-ampli.er\u00adxe/. [13] \nM. Itzkowitz and Y. Maruyama. HPC pro.ling with the Sun StudioTM performance tools. In Tools for High \nPerformance Computing 2009, pages 67 93. Springer, 2010. [14] L. K. John. More on .nding a single number \nto indicate overall performance of a benchmark suite. ACM SIGARCH Computer Architecture News, 32(4):1 \n14, Sept. 2004. [15] T. Kalibera, M. Mole, R. Jones, and J. Vitek. A black\u00adbox approach to understanding \nconcurrency in DaCapo. In Proceedings of the Annual ACM SIGPLAN Conference on Object-Oriented Programming, \nSystems, Languages and Ap\u00adplications (OOPSLA), pages 335 354, Oct. 2012. [16] M. Kambadur, K. Tang, and \nM. A. Kim. Harmony: Collection and analysis of parallel block vectors. In Proceedings of the Annual International \nSymposium on Computer Architecture (ISCA), pages 452 463, June 2012. [17] OpenJDK. OpenJDK (Implementation \nof the Java SE 6 Speci\u00ad.cation), Version 1.6. Oracle, 2006. URL http://openjdk. java.net/projects/jdk6/. \n[18] J. B. Sartor and L. Eeckhout. Exploring multi-threaded Java application performance on multicore \nhardware. In Proceed\u00adings of the Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, \nLanguages and Applica\u00adtions (OOPSLA), pages 281 296, Oct. 2012. [19] SPEC. SPECjbb2005 (Java Server Benchmark), \nRelease 1.07. Standard Performance Evaluation Corporation, 2006. URL http://www.spec.org/jbb2005. [20] \nSTMicroelectronics. PGProf: parallel pro.ling for scientists and engineers. http://www.pgroup.com/products/pgprof.htm, \n2011.   \n\t\t\t", "proc_id": "2509136", "abstract": "<p>Understanding and analyzing multi-threaded program performance and scalability is far from trivial, which severely complicates parallel software development and optimization. In this paper, we present bottle graphs, a powerful analysis tool that visualizes multi-threaded program performance, in regards to both per-thread parallelism and execution time. Each thread is represented as a box, with its height equal to the share of that thread in the total program execution time, its width equal to its parallelism, and its area equal to its total running time. The boxes of all threads are stacked upon each other, leading to a stack with height equal to the total program execution time. Bottle graphs show exactly how scalable each thread is, and thus guide optimization towards those threads that have a smaller parallel component (narrower), and a larger share of the total execution time (taller), i.e. to the 'neck' of the bottle.</p> <p>Using light-weight OS modules, we calculate bottle graphs for unmodified multi-threaded programs running on real processors with an average overhead of 0.68%. To demonstrate their utility, we do an extensive analysis of 12 Java benchmarks running on top of the Jikes JVM, which introduces many JVM service threads. We not only reveal and explain scalability limitations of several well-known Java benchmarks; we also analyze the reasons why the garbage collector itself does not scale, and in fact performs optimally with two collector threads for all benchmarks, regardless of the number of application threads. Finally, we compare the scalability of Jikes versus the OpenJDK JVM. We demonstrate how useful and intuitive bottle graphs are as a tool to analyze scalability and help optimize multi-threaded applications.</p>", "authors": [{"name": "Kristof Du Bois", "author_profile_id": "81481650917", "affiliation": "Ghent University, Ghent, Belgium", "person_id": "P4290375", "email_address": "kristof.dubois@elis.UGent.be", "orcid_id": ""}, {"name": "Jennifer B. Sartor", "author_profile_id": "81100262404", "affiliation": "Ghent University, Ghent, Belgium", "person_id": "P4290376", "email_address": "jennifer.sartor@elis.UGent.be", "orcid_id": ""}, {"name": "Stijn Eyerman", "author_profile_id": "81313482306", "affiliation": "Ghent University, Ghent, Belgium", "person_id": "P4290377", "email_address": "stijn.eyerman@elis.UGent.be", "orcid_id": ""}, {"name": "Lieven Eeckhout", "author_profile_id": "81330490198", "affiliation": "Ghent University, Ghent, Belgium", "person_id": "P4290378", "email_address": "leeckhou@elis.UGent.be", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509529", "year": "2013", "article_id": "2509529", "conference": "OOPSLA", "title": "Bottle graphs: visualizing scalability bottlenecks in multi-threaded applications", "url": "http://dl.acm.org/citation.cfm?id=2509529"}