{"article_publication_date": "10-29-2013", "fulltext": "\n Ef.cient Context Sensitivity for Dynamic Analyses via Calling Context Uptrees and Customized Memory \nManagement * Jipeng Huang Michael D. Bond Ohio State University {huangjip,mikebond}@cse.ohio-state.edu \n Abstract State-of-the-art dynamic bug detectors such as data race and memory leak detectors report program \nlocations that are likely causes of bugs. However, programmers need more than static program locations \nto understand the behavior of increasingly complex and concurrent software. Dynamic calling context provides \nadditional information, but it is expensive to record calling context frequently, e.g., at ev\u00adery read \nand write. Context-sensitive dynamic analyses can build and maintain a calling context tree (CCT) to \ntrack call\u00ading context but in order to reuse existing nodes, CCT-based approaches require an expensive \nlookup. This paper introduces a new approach for context sensi\u00adtivity that avoids this expensive lookup. \nThe approach uses a new data structure called the calling context uptree (CCU) that adds low overhead \nby avoiding the lookup and instead allocating a new node for each context. A key contribution is that \nthe approach can mitigate the costs of allocating many nodes by extending tracing garbage collection \n(GC): GC col\u00adlects unused CCU nodes naturally and ef.ciently, and we extend GC to merge duplicate nodes \nlazily. We implement our CCU-based approach in a high-perfor\u00admance Java virtual machine and integrate \nit with a staleness\u00adbased memory leak detector and happens-before data race detector, so they can report \ncontext-sensitive program lo\u00adcations that cause bugs. We show that the CCU-based ap\u00adproach, in concert \nwith an extended GC, provides a com\u00adpelling alternative to CCT-based approaches for adding con\u00adtext sensitivity \nto dynamic analyses. * This material is based upon work supported by the National Science Foundation \nunder Grants CAREER-1253703 and CSR-1218695. Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. Copyrights for components of this work owned by others than the author(s) must be honored. \nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. Request permissions from permissions@acm.org. \nOOPSLA 13, October 29 31, 2013, Indianapolis, Indiana, USA. Copyright is held by the owner/author(s). \nPublication rights licensed to ACM. ACM 978-1-4503-2374-1/13/10. . . $15.00. http://dx.doi.org/10.1145/2509136.2509510 \nCategories and Subject Descriptors D.3.4 [Programming Languages]: Processors Compilers, Debuggers, Memory \nmanagement, Run-time environments Keywords calling context; context sensitivity; dynamic analysis; leak \ndetection; race detection; garbage collection 1. Introduction To provide more functionality and to scale \nwith hardware that provides more instead of faster cores, software is be\u00adcoming increasingly complex \nand concurrent. These trends make it harder to write correct programs and to reproduce, .nd, diagnose, \nand .x bugs in existing programs. Dynamic program analysis helps developers make soft\u00adware more reliable \nby identifying errors and their likely causes. For example, data race detectors track the program locations \nthat last accessed each variable [14, 21, 22, 33, 43]. When they detect a data race, they can thus report \nthe two program locations involved in the data race: the program lo\u00adcation that last accessed the variable, \nas well as the current program location. Other dynamic analyses such as mem\u00adory leak detection [15, 18, \n38], dynamic slicing [1, 55], and atomicity violation detection [23, 32] track program loca\u00adtions in \norder to report likely bug causes. To .nd and di\u00adagnose bugs that do not manifest during testing, dynamic \nanalyses must run in production settings, where minimizing overhead is the key constraint. In order to \nsave time and space, almost all dynamic pro\u00adgram analyses track static program locations, e.g., a method \nand line number. However, static locations are often not enough to understand what the program was doing \nat that point. Static locations are increasingly inadequate as soft\u00adware becomes more complex and concurrent. \nIn complex, object-oriented software with many small, virtual methods, a static program location is often \ninvoked from many unre\u00adlated contexts. Modern software consists of integrated com\u00adponents written by \nmany developers, which complicates this guessing game. In concurrent programs, a bug s cause and manifestation \nmight execute on different threads, increasing the challenge of determining program behavior from a static \nlocation.  [* = org.eclipse] *.ui.internal.NavigationHistory.createEntry():527 *.ui.internal.NavigationHistory.addEntry():307 \n*.ui.internal.NavigationHistory.access$9():291 *.ui.internal.NavigationHistory$2.run():160 ... 13 call \nsites omitted ... *.compare.internal.CompareUIPlugin.compareResultOK():474 *.compare.internal.CompareUIPlugin.openCompareEditor():427 \n*.compare.CompareUI.openCompareEditorOnPage():138 *.compare.internal.CompareAction.run():36 *.compare.internal.BaseCompareAction.run():26 \nleakdiff.Harness$1.run():89 ... 23 call sites omitted ... *.core.launcher.Main.main():948 Figure 1. A \ncalling context from a leak in the Eclipse IDE. Context sensitivity. By looking only at static sites, \ndevel\u00adopers may not know what (or how or why) their programs are doing. They need more information than \na static pro\u00adgram location to understand what the program was doing. They need to know the dynamic calling \ncontext: the list of active call sites, similar to an exception stack trace.1 Developers are already \naccustomed to getting a stack trace upon failure or when a bug is detected, to help them understand what \nthe program was doing when it failed. Ob\u00adtaining the stack trace at these points is straightforward: \nthe runtime system simply walks the current thread s call stack. Overhead is not a concern because walking \nthe stack occurs only once. To understand bugs, developers not only need to know the calling context \nof program failures they need to know the calling context of bug causes. For example, developers need \nto know the calling context of the .rst of two accesses in\u00advolved in a data race, and they need to know \nthe calling con\u00adtext of a site that is leaking memory. Reporting these prior program locations calling \ncontexts is challenging. Since it is impossible to predict which accesses calling contexts might need \nto be reported later, dynamic analysis must record call\u00ading context frequently, e.g., at every program \nread and write. The Java benchmark SPECjbb2000 has a site (static pro\u00adgram location) that some leak detectors \nwill pinpoint as a probable leak cause. However, this site can be invoked from 34 statically possible \ncallers. Similarly, the Eclipse IDE has a memory leak that occurs in Eclipse s NavigationHistory class, \nbut the calling context is needed in order to determine that the call stack includes a class CompareUIPlugin \nthat in\u00addicates that the leak is called by comparing two code trees. Figure 1 shows (an abridged version \nof) this calling context; Section 6 has more details. Prior approaches. While most analyses record and \nreport only static program locations, some prior work captures call\u00ading context but either has serious \nlimitations or adds high space and time overheads, limiting its applicability. Walk\u00ad 1 Prior work on \nstatic analysis considers other forms of context sensitivity that includes object allocation sites and \ntypes [34, 45]. ing the stack whenever context is needed is expensive unless it is rare [16, 24, 37, \n44, 50]. Recent approaches reconstruct calling context when needed from limited information that is cheap \nto collect, but these techniques are often probabilistic; their accuracy does not scale well with program \ncomplexity; they are unsuitable for bug detection analyses; and/or they cannot handle virtual method \ndispatch and dynamic class loading [13, 28, 35, 48]. Notably, precise calling context en\u00adcoding (PCCE) \n[48] provides ef.cient calling context encod\u00ading and pro.ling but cannot handle bug detection analyses, \nvirtual method dispatch, or dynamic class loading. Dynamic analysis can build and maintain each thread \ns current position in a calling context tree (CCT), in which each node represents a distinct calling \ncontext [3, 42, 46, 56]. Each CCT node maintains a mapping from child sites to child (i.e., callee) contexts. \nThis mapping can be imple\u00admented in various ways, such as a hash table since the map\u00adping is sparse, \nor as a list if the number of child sites is relatively small. Dynamic analysis thus frequently performs \na nontrivial lookup to .nd the corresponding child con\u00adtext node, if any, which slows programs by two \nor more times [3, 42, 46]. Contributions. This paper proposes a novel approach for maintaining the calling \ncontext at run time and adding con\u00adtext sensitivity to dynamic analyses ef.ciently. Whereas a CCT-based \napproach looks up and reuses existing calling context nodes, our approach always allocates a new node. \nMaking this approach ef.cient requires two main contribu\u00adtions. First, we introduce a new data structure \ncalled the call\u00ading context uptree (CCU) that supports allocating new nodes, instead of reusing existing \nnodes, ef.ciently. Second, we ex\u00adtend tracing garbage collection (GC) to support ef.cient col\u00adlection \nof unused nodes and lazy merging of duplicate nodes (nodes representing the same context). This approach \navoids relying on static analysis of the call graph, and it naturally supports dynamic class loading \nand virtual method dispatch. We implement our CCU-based approach in a high-perfor\u00admance research JVM \nand integrate it into two dynamic bug detection analyses a staleness-based memory leak detector and a \nhappens-before race detector that track objects last access sites to report likely bug causes. We show \nthat our approach provides dynamic context sensitivity to the leak detector by adding 28 or 67% average \noverhead (relative to baseline program execution), depending on how leaf sites are stored, and to the \nrace detector by adding 37% overhead. We show that our approach outperforms a comparable CCT\u00adbased implementation. \nThese results suggest that the CCU\u00adbased approach offers a compelling new direction for adding ef.cient \ncontext sensitivity to dynamic analyses. While our CCU-based approach outperforms the CCT-based approach, \nwe believe the larger takeaway is the counterintuitive result that the CCU-based approach can provide \ncontext sensitivity ef.ciently, demonstrating a promising direction for future work to improve performance \nfurther.  2. Background Dynamic analyses such as memory leak and data race de\u00adtectors keep track of \nprogram locations that allocated or last accessed program variables. This paper refers to such analyses \nas client analyses. A client analysis instruments program locations that we call client sites. Which \nsites are client sites depends on the client analysis. For example, in a typical data race detector, \nall program loads and stores to potentially shared memory are client sites. A client analy\u00adsis records \nclient sites in per-variable client metadata. This metadata might be implemented by adding extra word(s) \nto object headers or by adding shadow memory [36]. A client analysis that records only client sites is \ncontext insensitive, while a client analysis that records client sites with their call\u00ading context is \ncontext sensitive. In this paper, dynamic calling context is (1) a client site plus (2) the set of active \ncall sites. A (call or client) site consists of a method and a bytecode index:2 class Site { Method method; \nint bytecodeIndex; } In Figure 1, the .rst site, NavigationHistory.createEntry(): 527, is the client \nsite, and the other sites are call sites. It is challenging to add ef.cient context sensitivity to dy\u00adnamic \nanalyses. Dynamic analyses such as bug detectors typically execute client sites frequently (e.g., they \nrecord a site for every program memory access), so that if and when they detect a bug related to a memory \nlocation, they can report an associated site. A na\u00a8ive analysis that frequently records calling context \nwhich can be dozens of call sites long will add high time and space overhead. Another chal\u00adlenge is handling \ntwo common language features: dynamic class loading, which grows the static call graph as the pro\u00adgram \nexecutes, and virtual method dispatch, which compli\u00adcates instrumenting calls. 2.1 The Calling Context \nTree Ammons et al. introduce the calling context tree (CCT), in which each node represents a distinct \ncalling context exe\u00adcuted by the program [3, 42, 46, 56]. Each node points to its existing child nodes: \nclass CCTNode { Site site ; Map<Site,CCTNode> childMap; } As mentioned earlier, the site can be a call \nsite or a client site. Each node maintains a map childMap from child sites to child nodes; a child node \nrepresents a child (callee) calling context of the current node, and a child site is the site of 2 Sites \nuse bytecode indices because they uniquely identify bytecodes, un\u00adlike line numbers. Throughout the paper, \nwe show line numbers for calling contexts because they are more intuitive when examining source code. \na child node. The child map enables dynamic analysis to reuse an existing context node, if any, at a \ncall or client site. Reusing existing nodes is important because programs execute many more dynamic than \ndistinct contexts [16]. Inherent to this design is that each node has pointers pointing down to it child \nnodes, in order to reuse existing nodes. Direct mapping is impractical because a call site may have many \nstatically possible child sites: a call site may stat\u00adically call several virtual methods, and each of \nthese meth\u00adods may contain many call and client sites. Furthermore, the number of statically possible \nchild sites grows over time due to dynamic class loading. Ef.cient implementations must use a sparse \nmapping implementation such as a hash table, or potentially a list if relatively few distinct child sites \nex\u00adecute. Existing CCT-based dynamic analyses thus require a nontrivial lookup at essentially every call \nand/or client site, slowing programs by two or more times [3, 42, 46]. Figure 2 shows an example program \nwritten in Java-like pseudocode. Suppose the client analysis wants to record the last access (load or \nstore) to each object. The call site main():16 has four statically possible child sites: A.m():4, A.m():5, \nB.m():10, and B.m():11. Note that the child sites are, by de.nition, the call sites and client sites \ninside the possible callees (A.m() and B.m()). Similarly, call site B.m():11 has two statically possible \nchild sites, A.m():4 and A.m():5. We assume line 18 (...) performs additional work. Figure 3 shows the \nCCT that a CCT-based dynamic anal\u00adysis would allocate for the example program in Figure 2. Ovals represent \nCCT nodes; shaded nodes are client site nodes, while other nodes are call site nodes. Squares repre\u00adsent \nheap objects that are instances of class A, B, or X (x1 x3 are instances of X numbered by allocation \norder). Down edges point from CCT nodes to their children, and up edges point from per-object client \nmetadata (e.g., object headers) to CCT nodes; the client metadata records the last access to each object. \nThe edge from A.m():5 to ... represents extra CCT nodes created by globalSet.add(). The signi.cance of \nthis call is that x1 and x3 escape and are thus still alive at line 18. The program accesses x1 and x3 \n.rst at B.m():10 . main():16 and then at A.m():4 . B.m():11 . main():16. Nonetheless, the context B.m():10 \n. main():16 remains in the CCT. Similarly, x2 dies quickly (indicated with dashed lines) because A.m():5 \ndoes not add x2 to globalSet; nonetheless, the last-access context A.m():4 . main():16 survives because \nit is reachable from the tree root. This pa\u00adper refers to nodes that are no longer used by client analyses \nas irrelevant nodes. Our new CCU-based approach relies on most context nodes becoming irrelevant (unreachable) \nfairly quickly so that tracing-based garbage collection (GC) can collect them. The CCT can also support \nGC of irrelevant  1 class X { boolean .ag ; } // defaults to false 2 class A { 3 m(X x) { 4 if (x..ag) \n{ /* client site */ 5 globalSet . add(x) ; /* call 6 } 7 } } 8 class B extends A { 9 m(X x) { site \n*/ 10 x..ag = true; /* client site */ 11 super.m(x) ; /* call site */ 12 } } 13 main() { 14 A a = new \nA(); B b = new B(); 15 for (A tmp : {b, a , b}) { 16 tmp.m(new X()); /* call site */ 17 } 18 . . . 19 \n} Figure 2. Example program written in Java pseudocode. Client sites are loads and stores. Each client \nor call site is annotated. Figure 3. Calling context tree (CCT) corresponding to Figure 2. Ovals represent \nCCT nodes; shaded nodes are client site nodes, and others are call site nodes. Squares represent program \nobjects. nodes using weak references [26], e.g., by using a weak hash map for child nodes and also maintaining \nparent pointers.3 The more critical problem with the CCT is that nodes can have many statically possible \nchild contexts, which can grow over time, so .nding a child context in the child map requires a relatively \nexpensive indirect lookup at each program call. Our approach addresses this problem, as well as how to \ndelete irrelevant nodes. 3 Client analyses that pro.le all contexts will not have irrelevant nodes. The \nCCT (without weak child references) is well suited for such analyses, while our CCU-based approach, which \nrelies on irrelevant nodes, is not.  2.2 Alternatives to CCT-Based Approaches Recent work encodes the \ncalling context as a value or values. Some techniques trade accuracy for performance, but their accuracy \ndoes not scale well with program complexity [13, 28, 35]. In contrast, precise calling context encoding \n(PCCE) losslessly encodes each calling context as an integer value or values [48]. While PCCE provides \nef.cient encoding and pro.ling of contexts, it is not well suited to bug detection analyses, which need \nto encode program locations as per\u00advariable metadata, since PCCE represents contexts with a variable \nnumber of integers. Furthermore, PCCE relies on numbering a statically known call graph and instrumenting \ncall edges with statically unique targets, so it inherently cannot handle dynamic class loading nor virtual \nmethod dispatch, limiting its applicability. Section 7 discusses these techniques in more detail. 3. \nA New Approach for Dynamic Context Sensitivity This section introduces an approach based on a new data \nstructure called the calling context uptree (CCU). Each node points up to its parent instead of down \nto its children: class CCUNode { Site site ; CCUNode parent; } Because CCU nodes do not point to their \nchildren, a node s callee context nodes are not accessible from it, making it essentially impossible \nto reuse existing nodes to represent reoccurring contexts. However, allocating new nodes is fast. This \nsection presents an approach for dynamic context sensitivity that uses the CCU and extends garbage collection \n(GC). We .rst describe how dynamic analysis constructs CCU nodes, and then how to extend GC to collect \nirrelevant nodes and merge duplicate nodes. 3.1 Constructing the CCU A CCU-based analysis must allocate, \nat a minimum, CCU nodes to represent the context of every client site (e.g., ev\u00adery read and write). \nAn analysis can construct CCU nodes eagerly or lazily. Eager construction allocates a node at ev\u00adery \ncall site and passes the node as an extra, implicit call parameter. In the example below, caller and \ncallee are names of methods that each take an additional parameter: caller (..., ccuNode) { ... // program \ncall site callee (..., new CCUNode(callSite, ccuNode)); ... } At every client site, eager construction \nallocates a new node from the client site and parent node, and uses it in an analysis-speci.c way such \nas storing the node in an accessed object s header (o.metadata):  o.metadata = new CCUNode(clientSite, \nccuNode); read o . f ; // client site In contrast, lazy construction allocates CCU nodes only at client \nsites: o.metadata = new CCUNode(clientSite, getNode()); read o . f ; // client site The internal, implementation-speci.c \nfunction getNode() walks the stack and allocates CCU nodes recursively until it .nds a stack frame for \nwhich the CCU node has already been constructed.4 Section 4.1 describes how our implementation stores \npointers to CCU nodes on stack frames and uses method return addresses to represent sites ef.ciently. \nEager and lazy construction are not unique to a CCU\u00adbased approach. A CCT-based approach may also construct \nnodes lazily or eagerly [50, 56]. CCU-and CCT-based ap\u00adproaches will each look up the same number of \nnodes; the key difference is that looking up a CCU node means allo\u00adcating a new node, whereas looking \nup a CCT node means searching for an existing node to reuse. We focus on lazy construction because it \nscales well with the client analysis: it constructs nodes only for the calling contexts of client sites, \nnot for all calling contexts.  3.2 Collecting Irrelevant Nodes Because CCU nodes point only up to their \nparents, trac\u00ading GC naturally collects irrelevant nodes (nodes that are transitively unreachable and \nthus are no longer used by the client analysis). In fact, the CCU relies on GC to collect the plethora \nof nodes that become irrelevant quickly. Tracing GC is well suited to collecting CCU nodes because tracing \nis proportional to the live nodes, not the (more numerous) dead nodes [30]. Example CCU. Figure 5 shows \nthe CCU after executing the (instrumented) code in Figure 2. The contexts B.m():10 . main():16 and A.m():4 \n. main():16 are irrelevant since x1 and x3 s last access changed, and x2 died. We represent these nodes \nwith dashed lines to show that GC collects them automatically once they become unreachable.  3.3 Merging \nDuplicate Nodes While GC naturally collects irrelevant CCU nodes, duplicate nodes (nodes representing \nthe same calling context) can still add signi.cant space overhead in a CCU-based approach. In contrast, \nthe CCT disallows duplicate nodes by always reusing existing nodes. As our results show, the CCT s ap\u00adproach \nessentially wastes time reusing nodes because many duplicate nodes become irrelevant quickly. 4 We note \nthat the CCU and CCT both naturally handle recursive call sites because each CCU node represents one \ndynamic call site or client site. Figure 4. Calling context tree (CCT) corresponding to Figure 2. (Exact \ncopy of Figure 3, for comparison purposes.)  Figure 6. Calling context uptree (CCU) corresponding to \nFig\u00adure 2, after merging of duplicate nodes. Irrelevant nodes have also been garbage collected. Down \narrows (dashed) represent child map pointers; after merging, all surviving nodes have child maps. Other \nformatting is same as in Figure 3.  To balance space and time, our CCU-based approach pe\u00adriodically \nmerges duplicate nodes so that each relevant con\u00adtext is represented by just one merged node. The goal \nof merging is to determine, for each node, its merged node which may be the node itself or a different \nnode and redi\u00adrect all incoming pointers to the merged node. Our merging algorithm piggybacks on tracing \nGC, which already traverses all objects. Merging is not suitable for non\u00adtracing GC such as reference \ncounting, although ef.cient reference-counting algorithms still trace young objects [11], providing an \nopportunity for merging duplicate nodes. Looking up merged nodes. To merge duplicate nodes, our implementation \nneeds to support looking up existing merged nodes based on node equality. Two nodes are equal if their \nsites are the same and their parent nodes are equal (or both null). We add to each merged node a map \nfrom its child sites to existing child nodes: class MergedCCUNode extends CCUNode { Map<Site,CCUNode> \nchildMap; } A merged node needs a child map to enable looking up the the unique (merged) node for each \nchild node. Section 4.3 explains how our implementation uses different memory spaces for unmerged and \nmerged nodes, in order to support adding the childMap .eld only for merged nodes. Both the CCU and CCT \nmaintain child maps, but the CCT maintains a child map for every node; a merged CCU node is essentially \nthe same as a CCT node that has a parent pointer. The CCU avoids the cost of updating the child map for \nthe (many) irrelevant nodes that become unreachable between their allocation and the next GC, as supported \nby our results. GC typically traces (i.e., marks live and possibly moves) an object o before tracing \nobjects referenced by o [25]. This tracing order is not well suited to merging, which needs to determine \na node s merged node based on the node s merged parent. We modify GC tracing to trace each CCU node s \nparent before tracing the node itself. Figure 7 presents pseudocode that extends GC tracing to merge \nduplicate nodes by identifying a node s merged node and redirecting the node s incoming pointers to the \nmerged node. GC calls traceAndMerge, instead of its regular tracing function traceObject, when tracing \nCCU nodes. traceAnd-Merge .rst recursively traces and merges the parent node, which returns the merged \nparent node. It then checks for an existing merged node for node. If no merged node exists, node is the \nmerged node, so traceAndMerge performs reg\u00adular GC tracing on it (marking it live and copying it if ap\u00adplicable) \nand adds it to the parent s child map as the merged child. Section 4.3 describes how this algorithm applies \nto CCU nodes in both copying and non-moving spaces. Example CCU after merging. Figure 6 shows the CCU \nfrom Figure 5 after merging executes as part of GC, which 1 // Transitive closure : 2 while (! workList \n. isEmpty()) { // initialized w/root objs 3 ObjectReference obj = workList.pop(); 4 for (Address slot \n: getReferenceSlots ( obj ) ) { 5 slot . store ( traceObject ( slot . loadObjectReference () )) ; 6 } \n7 } 8 ObjectReference traceObject (ObjectReference obj ) { 9 if (isCCUNode(obj)) { 10 return traceAndMerge(obj); \n11 } 12 if (! alreadyTraced( obj) ) { 13 // .rst trace this node 14 obj = markLiveAndPossiblyCopy(obj); \n15 // trace outgoing pointers later 16 workList . push(obj) ; 17 } 18 return obj ; 19 } 20 CCUNode traceAndMerge(CCUNode \nnode) { 21 // .rst trace and merge the parent 22 if (! alreadyTraced(node.parent) ) { 23 node.parent \n= traceAndMerge(node.parent); 24 } 25 // then trace and merge this node 26 mergedNode = node.parent.childMap.get(node.site); \n27 if (mergedNode == null) { 28 node = markLiveAndPossiblyCopy(node); 29 // now node is the merged node \n30 node.parent . childMap.put(node. site , node); 31 return node; 32 } 33 return mergedNode; 34 } Figure \n7. Pseudocode showing how we modify GC tracing to trace and merge CCU nodes. The transitive closure traces \neach heap object. Normally, an object is traced before its referenced ob\u00adjects (traceObject). A CCU node \nis traced after tracing its par\u00adent (traceAndMerge). Fine-grained synchronization (not shown) ensures \natomicity of lines 26 30. Nodes without parents are not merged (not shown). also collects irrelevant \nnodes. Each relevant context is repre\u00adsented by one merged node. 4. Challenges for an Ef.cient Implementation \nThe main challenge in implementing a CCU-based approach for dynamic context sensitivity is that it allocates \nmany nodes. Node allocation takes time, increases cache pres\u00adsure, and increases GC frequency and workload. \nWalking the stack to support lazy construction also adds time overhead for both the CCU and the CCT. \nThis section describes how our implementation addresses these challenges: optimiza\u00adtions for constructing \nCCU nodes, merging duplicate nodes, and integrating with two bug detection clients.  We implement our \nCCU-based approach in Jikes RVM 3.1.1, a high-performance research Java virtual machine (JVM) [2] that \nprovides performance competitive with com\u00admercial JVMs.5 Our implementation is publicly available on \nthe Jikes RVM Research Archive.6 The CCU-based approach and optimizations could be im\u00adplemented in many \nexisting managed language VMs that have the requisite features: tracing GC and support for intro\u00adspection \nof both the stack and dynamically compiled method metadata. One could potentially even adapt the approach \nto a language such as C or C++ that uses explicit memory man\u00adagement, e.g., by providing specialized \nGC and merging of CCU nodes, and keeping track of pointers from ordinary heap objects to CCU nodes, since \nthese pointers would be the roots of the transitive closure of CCU nodes. 4.1 Optimizing CCU Nodes Although \nCCU nodes and sites can be represented as objects as described in Section 3, objects have headers that \nwould bloat the code and add overhead to node construction. This section describes how we try to make \nCCU nodes and sites as lightweight as possible. Using return addresses as sites. Each CCU node has two \n.elds: its site and parent node. One option for represent\u00ading the site is to assign each static site \n(method and byte\u00adcode index) a unique identi.er. When compiling each call site and client site, the dynamic \ncompiler would compute the identi.er and insert instrumentation to construct a CCU node using the identi.er. \nHowever, this option would not work well with lazy node construction (Section 3.1) because callee methods \nare responsible for constructing nodes for caller call sites. For example, when call site B.m():11 in \nFig\u00adure 2 calls method A.m(), instrumentation in A.m() needs to construct the node for the call site \nB.m():11. Instrumenta\u00adtion at B.m():11 could potentially pass the site identi.er to A.m(), but this would \nadd overhead, sacri.cing much of the bene.t of lazy construction. Our implementation addresses this challenge \nby repre\u00adsenting sites using the return address of the caller call site. The return address of the caller \ncall site is already available on the current stack frame (for use by a return instruction). A return \naddress maps to a speci.c caller call site, and the VM already provides methods to decode an instruction \npointer to a caller call site, e.g., to support exception handling. Decoding return addresses is slow \ncompared to allocating nodes but decoding occurs only when reporting call sites to programmers, which \nis already expensive and infrequent. To enable the VM to always decode a return address to its unique \nsite, we modify the VM to prevent collection of unused compiled methods and their metadata.7 5 http://dacapo.anu.edu.au/regression/perf/9.12-bach.html \n6 http://www.jikesrvm.org/Research+Archive 7 We .nd that disabling collection of unused methods does \nnot noticeably degrade performance (results not shown). The VM recompiles methods adaptively [5] and \ncompiles some static sites multiple times by inlining methods and unrolling loops, so multiple return \naddresses may map to the same call site. Our implementation computes node equality using a node s return \naddress, which may inhibit merging somewhat since two nodes with the same site and parent cannot be merged \nif their sites are represented by different return addresses. Raw node objects. Our implementation supports \nCCU nodes being pure Java objects. Java objects have a header for type information, locking, and garbage \ncollection (GC); the header in Jikes RVM is two words by default. Since dy\u00adnamic analyses allocate CCU \nnodes frequently, the cost of the header is signi.cant in terms of cache footprint, space overhead, and \nheader initialization time. Our implementation thus also supports using raw mem\u00adory for CCU nodes without \nheaders. We have implemented custom memory spaces that support raw CCU nodes: a copy\u00ading space and a \nmark-sweep space. When GC traces nodes in these spaces, it calls our custom tracing code. The evaluation \nuses raw nodes since they offer better performance.  4.2 Optimizing CCU Instrumentation This section \ndescribes how the implementation avoids walk\u00ading the stack and reuses nodes whenever possible. Optimizing \nlazy construction. Whenever our implementa\u00adtion constructs a CCU node representing a method s caller \ncontext (i.e., the calling context not including the current call or client site), it stores a pointer \nto the node in a slot in the method s stack frame. This behavior enables reusing CCU nodes constructed \nfor existing stack frames and en\u00adables walking the stack until a stack frame is found that has already \nconstructed its caller context node. We modify the optimizing compiler to introduce a new local variable \nin each method that holds the method s caller context node, to avoid looking on the current stack frame \nin the common case. This local variable starts as null; instru\u00admentation initializes it at the method \ns .rst client site. The method getNode() constructs nodes lazily by walking the stack until it .nds an \nalready-constructed node. Client sites in loops execute multiple times with the same calling context. \nWe modify the compiler to perform a spe\u00adcialized form of loop-invariant code motion that moves the construction \nof client sites before the loop pre-header and lets each dynamic client site use the same node. The com\u00adpiler \nonly performs this optimization if the loop pre-header executes less frequently than the client site \nin the loop (based on existing edge pro.ling). Since this optimization applies only to client sites, \nnot call sites, it bene.ts only the leak de\u00adtection experiments that use client site nodes (Section 5.3). \nThe following pseudocode shows how the local variable and hoisting optimizations work:  foo () { CCUNode \ncallerNode = null; // foo s caller context ... // Hoisted instrumentation : if ( callerNode == null) \n{ callerNode = getNode(); } CCUNode csNode = new CCUNode(clientSite, callerNode); ... for (...) { o \n. metadata = csNode; read o . f ; // client site ... } } Inlined call sites. To reduce call overhead \nand increase optimization scope, the VM inlines small methods and hot call sites. An inlined call site \nrepresents multiple call sites. Our implementation constructs just one CCU node for each non-inlined \ncall site in an inlined method. Return addresses naturally represent inlined call sites, and the VM provides \nfunctionality to decode the call sites that make up a return address for an inlined call site.  4.3 \nMerging Duplicate Nodes Section 3.3 described an algorithm for merging duplicate nodes, a key optimization \nbecause our approach allocates many duplicate nodes, some of which remain reachable. Our implementation \nsupports two types of merging. In-place merging merges nodes in a (non-moving) mark-sweep space. Because \nnodes cannot be moved, all nodes in the space must include the childMap .eld in case they become merged \nnodes. Copy-based merging copies merged nodes into a mark\u00adsweep space, which naturally contains only \nmerged nodes. Copy-based merging has two advantages. First, nodes in the copy space, which are numerous \nand often duplicates, do not need the extra childMap .eld. Second, copy-based merging limits fragmentation \nbetter than in-place merging, since copy-based merging copies only merged nodes into the fragmentation-prone \nmark-sweep space. Regardless of the type of merging, our implementation always uses a con.guration with \none copy node space and one mark-sweep node space. It allocates nodes into the copy space, which is fast \nsince it uses bump-pointer allo\u00adcation [8]. GC copies surviving nodes to the mark-sweep space, which \noffers better space and time performance for long-lived nodes. The mark-sweep space is always a mature \nspace, i.e., it is traced only during full-heap GCs. The copy space may be a mature space or nursery \nspace, i.e., traced only during nursery GCs. We have found that if the copy node space is a nurs\u00adery \nspace, then our implementation adds high overhead due to generational write barriers, which track new \npointers from mature to nursery objects in order to support high\u00adperformance generational GC [10, 53]. \nFor our leak and race detectors, any assignment of a CCU node into an object header requires a generational \nwrite barrier, and this barrier needs to record the pointer in a remembered set if the node is old [10, \n53]. Thus, all of our experiments use a mature copy space that is collected only during full-heap GCs. \nImplementing the child map. Merged nodes have an extra .eld childMap that maps child sites to child nodes. \nIn our implementation, the child map is a hash-based map that uses an array of buckets ; each bucket \nis a linked list of nodes. To construct a lightweight linked list, each merged node has an extra .eld \nnext that points to the next node in the list. Our implementation piggybacks on parallel GC to per\u00adform \nmerging when nodes are copied from the copy node space to the mark-sweep node space. Searching for a \nchild node does not require synchronization, except for a load fence to ensure a happens-before edge \nfrom insertions. How\u00adever, if a node is not found, it must be inserted in the appro\u00adpriate bucket s list, \nwhich requires synchronization to ensure atomicity with respect to another thread adding the same or \na different node to the same bucket. The implementation .rst uses atomic operations to lock the bucket \nto ensure exclu\u00adsive access. Then it searches the bucket s list again to make sure the node is not already \nin the list. Finally it inserts the node and unlocks the bucket. Child nodes should be allowed to die \nif they are not referenced transitively by client metadata via node parent pointers. Otherwise all merged \nnodes will be transitively reachable from child maps, so they will not be collected by GC. The implementation \nsupports treating each child map reference like a weak reference [26] by tracing the map only at the \nend of regular tracing, and removing any nodes from the map that have not been marked live. We also implement \nand evaluate an alternative that retains all merged nodes and thus avoids tracing merged nodes.  4.4 \nIntegrating with Client Analyses Memory leak detector. State-of-the-art leak detectors track the sites \nthat allocated and/or last accessed each memory location, in order to report the sites associated with \nleaked memory to programmers [15, 18, 52]. We have implemented a leak detector that detects leaks by \ninferring that stale (not recently used) objects are likely leaks [15, 18, 41, 52]. We have implemented \na staleness-based leak detector that tracks staleness by instrumenting each load of an object ref\u00aderence \nto mark the referenced object as not stale [17]. It also updates the target object s last-use site at \neach refer\u00adence load, making it a challenging CCU-based client. The leak detector supports both context-insensitive \nand context\u00adsensitive modes. The context-insensitive detector adds a word to each object header to store \nthe last-use client site. The context-sensitive detector supports two options: (1) one header word for \nthe client site and another word pointing to a CCU node representing the caller context, or (2) one header \nword that points to a CCU node representing the en\u00adtire context, i.e., including the client site.  Data \nrace detector. Happens-before race detectors detect data races by identifying two con.icting accesses \nthat are not ordered by synchronization [14, 19, 22, 33, 39, 49, 54]. A race detector typically tracks \nthe sites that last read and wrote each .eld or array element. When the detector detects a data race, \nit reports both the prior access(es) stored for the racy variable, and the current program location. \nTo report the calling context of the current program location, the runtime system simply walks the call \nstack. Reporting the calling context of the prior access(es) requires recording the context of each access. \nWe have integrated CCU with Pacer, a publicly avail\u00adable sampling-based happens-before race detector \nimple\u00admented in Jikes RVM [14]. Pacer maintains per-.eld meta\u00addata in each object s header. This metadata \nalready stores the (context-insensitive) sites that last wrote and read each .eld. These are the client \nsites. We modify the implementation to store the CCU node representing the caller context of each client \nsite. Given the client site and its caller context, Pacer can report the full calling context. At a 100% \nsampling rate, Pacer is functionally equivalent to FastTrack [22]. We primarily evaluate FastTrack (Pacer \nat 100%), which is a challenging client because it instru\u00adments a signi.cant fraction of all reads and \nwrites. Pacer and FastTrack are able to skip race detection analysis for accesses that occur within the \nsame epoch (synchronization\u00adfree region) as the prior access. The implementation does not record the \nCCU node in such same epoch cases. 5. Quantitative Evaluation This section primarily evaluates the time \nand space that CCU-and CCT-based approaches add to two client analyses: data race and memory leak detectors. \nIt also evaluates a worst-case client and measures how much the CCU-based approach relies on GC. 5.1 \nMethodology Implementing the CCT. For comparison purposes, we have also implemented support for CCT-based, \ncontext\u00adsensitive analysis. In the CCT, every node has a child map. To keep the comparison as close as \npossible, our CCT nodes are also raw nodes and represent their child maps in the same way as CCU nodes, \nand they use the same ef.cient lazy construction as CCU nodes. One limitation of our eval\u00aduation is the \npossibility that the CCT underperforms its po\u00adtential because of a suboptimal implementation. We note \nthat child maps are sparse by design, so most lookups hit on the .rst attempt, so unimplemented optimizations, \nsuch as using inline caching and using a map from caller call site to per\u00adcallee arrays indexed by call \nsites, are unlikely to improve performance signi.cantly. Con.guring the child map. Both the CCU-and CCT\u00adbased \napproaches use child maps: each CCT node has a child map, while only merged CCU nodes have child maps. \nGC can treat these child node references like weak refer\u00adences [26], reducing space but potentially slowing \nexecution by tracing more nodes and allocating and/or copying more nodes; or GC can treat child node \nreferences like strong ref\u00aderences, in which case our implementation safely elides trac\u00ading of child \nnodes. Our evaluation explores this tradeoff by comparing four con.gurations: CCU with weak child references: \nBy using weak child references, GC collects all irrelevant nodes, both un\u00admerged and merged. For this \ncon.guration, we explore several merging strategies: no merging, in-place merging, and copy merging. \nWe .nd that copy merging provides the best overall performance by eliminating duplicate nodes and limiting \nfragmentation.  CCU with strong child references: In this con.guration, GC collects irrelevant nodes \nthat have not been merged, but it does not collect irrelevant merged nodes, allowing GC to avoid tracing \nmerged nodes altogether since their child and parent references always point to other merged nodes. This \ncon.guration uses copy merging since it pro\u00advides the best performance.  CCT with weak child references: \nIn this con.guration, GC collects all irrelevant nodes since it treats child map references like weak \nreferences. To limit fragmentation, this con.guration uses a multi-space strategy similar to copy merging \nit allocates nodes into a copy space and copies surviving nodes into a mark-sweep space except GC performs \nno merging, since CCT nodes are merged at allocation time.  CCT with strong child references: In this \ncon.guration, strong child references keep all nodes live, and nodes get merged at allocation time, so \nGC cannot collect any nodes. This con.guration thus allocates all nodes into an immortal space.  Benchmarks. \nIn our experiments, Jikes RVM executes the DaCapo Benchmarks [9] (version 2006-10-MR2) and a .xed-workload \nversion of SPECjbb2000 called pseudo\u00adjbb [47]. We evaluate the leak and race detectors on all benchmarks \nexcept bloat because its run-to-run variability is unusually high (even without our modi.ed JVM), making \nit dif.cult to produce high-con.dence results. We execute the large workloads for all benchmarks, except \nwe execute the medium workload for hsqldb with the race detector since the large workload runs out of \nmemory, even without context sensitivity. Experimental setup. We build a high-performance con.g\u00aduration \nof Jikes RVM (FastAdaptive) that optimizes the VM and adaptively optimizes the application as it runs. \nWe run the race detector with Jikes RVM s default generational Im\u00admix collector [12] (GenImmix), and \nthe leak detector with a generational mark-sweep collector (GenMS) since its object model leaves a few \nbits available for the leak detector to use to compute staleness.  To account for run-to-run variability \ndue to dynamic opti\u00admization guided by timer-based sampling, we execute 15 tri\u00adals for each measurement \nand take the median, which min\u00adimizes effects of machine noise. We also show show 95% con.dence intervals \ncentered at the mean, which typically differs little from the median. We let the VM choose its own heap \nsize adaptively because the client analyses, especially race detection, add high space overhead. For \nplots of space overhead versus time, we show just one trial since averaging such plots is not straightforward \nand might unrealistically hide overhead peaks. Platform. Our experiments execute on a 4-core Intel i5 \n3.3-GHz system with 4 GB memory running Linux 2.6.32.  5.2 Key Questions Our evaluation aims to address \nthe following questions: Can the CCU-based approach avoid the vast majority of the expensive lookups \nperformed by a CCT-based ap\u00adproach? Our results show the vast majority of child map lookups are eliminated \nand replaced by allocations of CCU nodes (e.g., Table 1).  Is it cheaper to allocate a CCU node than \nto look up a CCT node? Our results show that each CCT lookup is replaced with roughly one CCU allocation \n(Table 1), and the CCU-based approach on average provides signif\u00adicantly better time performance than \nthe CCT-based ap\u00adproach (Figures 8, 9, 12).  Can GC and lazy merging of duplicate nodes provide competitive \nspace overhead for the CCU-based ap\u00adproach? These features allow duplicate CCU nodes to be merged and \nunreachable nodes to be collected, so the CCU adds space overhead comparable to the CCT (Ta\u00adble 2 and \nFigure 11).  Can the overall performance of a CCU-based approach be competitive with or better than \na CCT-based ap\u00adproach? On average and across nearly all experiments, the CCU-based approach provides \nsigni.cantly better time performance and similar space performance to the CCT-based approach (Figures \n8, 9, 11, 12 and Table 2).  How do the context-sensitive sites reported by leak and race detectors compare \nto context-insensitive sites? The context-sensitive sites provide signi.cantly more infor\u00admation about \ndynamic behavior (Section 6).  Next we evaluate the performance of CCU-based approaches and compare \nto CCT-based approaches. We always evaluate using a client analysis because the approaches add zero overhead \nwithout a client, due to lazy construction. AllocaCCU tions CCT Hash lookups CCU CCT DCS LVA LVAF antlr \nchart eclipse fop hsqldb jython luindex lusearch pmd xalan pseudojbb 329.8 387.3 4561.0 42.4 490.8 3551.0 \n1068.3 1331.8 1645.1 6242.2 995.8 3.4 0.4 68.5 0.2 4.5 4.1 0.4 0.8 12.8 24.2 0.2 0.2 329.0 5.5 380.0 \n8.3 4546.0 0.3 41.1 17.3 546.0 0.2 3535.6 0.4 1066.4 5.5 1305.0 6.3 1635.4 8.6 6198.6 15.7 996.3 86% \n71% 88% 85% 100% 79% 84% 85% 90% 92% 92% 96% 98% 98% 80% 98% 99% 99% 90% 99% 96% 99% 14% 29% 11% 8% 9% \n20% 19% 14% 9% 8% 8% Table 1. Nodes allocated and hash lookups performed for the CCU-and CCT-based approaches \n(all in millions). The last three columns report how often client sites bene.t from optimizations.  \n5.3 Memory Leak Detection This section evaluates the performance of our memory leak detector that tracks \nthe last-use (i.e., last read) sites of all objects (Section 4.4). We experiment with two CCU/CCT con.gurations. \nThe .rst stores a pointer to a CCU or CCT node in each object s header that represents the last-use site \ns calling context, including a node for its client site. The second con.guration stores a node representing \nthe last-use site s calling context not including the client site, and it uses a second header word for \nan identi.er representing the client site. We say the .rst con.guration uses client site nodes, and the \nsecond con.guration does not. Client site nodes can potentially reduce space overhead since (1) program \nlocation can be recorded in just one word of client metadata (instead of two) and (2) multiple client \nmetadata can point to the same client site node after merging. Client site nodes stress CCU and CCT performance \nmore, since more nodes are constructed or looked up. Run-time characteristics. Table 1 shows run-time \nstatis\u00adtics for the con.guration that uses client site nodes; all num\u00adbers are in millions. These results \nuse the CCU with weak child references and CCT with strong child references; we expect weak versus strong \nreferences to have a modest im\u00adpact on these results. Allocations is the number of nodes al\u00adlocated. \nThe CCU-based approach allocates roughly 2 3 or\u00adders of magnitude more nodes than the CCT-based approach. \nHowever, the CCU-based approach performs about the same factor fewer Hash lookups than the CCT-based \napproach, in\u00addicating that the vast majority of CCU nodes become un\u00adreachable before they can be merged. \nThe last three columns are for the CCU-based approach (results for the CCT-based approach are similar). \nDynamic client sites (DCS) is the fraction of nodes allocated for client sites (rather than call sites). \nLocal variable attempts (LVA) is the fraction of DCS that use the local variable optimization from Section \n4.2. Values are close to 100% because all optimized code uses this optimization; some cold methods are \nnot compiled by the optimizing compiler. Local variable attempt failure (LVAF) is the fraction of LVA \nthat the local  (a) CCU and CCT con.gurations allocate client site nodes. (b) CCU and CCT con.gurations \nstore client sites in object headers. Figure 8. Normalized execution time for leak detection (a) using \nclient site nodes and (b) with client sites in object headers. The graphs compare context-insensitive \nleak detection and CCU-and CCT-based context sensitivity. Bars 3 5 in each group use the CCU (with weak \nchild references) without merging and with two merging algorithms. Sub-bars are GC time. node variable \nis null often only about 10% of the time, suggesting that using the local node variable is a worthwhile \noptimization. Time overhead. Figure 8 shows the normalized applica\u00adtion time of various leak detection \ncon.gurations. All bars are normalized to unmodi.ed Jikes RVM (Base). The Leak detection only con.guration \nrecords context-insensitive sites and adds 18% overhead on average to record last-use sites and track \nobject staleness. The four Leak det + CCU con\u00ad.gurations construct CCU nodes to represent the context \nof each last-use site. The .rst three CCU con.gurations use weak strong child references and either do \nnot merge du\u00adplicate nodes, or use copy or in-place merging; the fourth CCU con.guration uses copy merging \nwith strong child ref\u00aderences. Figure 8(a) corresponds to the con.guration that uses client site nodes. \nCCU-based context sensitivity adds 67 72% overhead over context-insensitive leak detection, de\u00adpending \non the merging con.guration and the child refer\u00adence type. CCT-based context sensitivity adds substantially \nmore overhead 123 or 127% depending on the child refer\u00adence type because the cost of looking up or constructing \neach node is substantially higher for the CCT than for the CCU. Figure 8(b) shows overhead for storing \nthe client site in object headers. CCU-based context sensitivity adds only 28 31% overhead on average \nover context-insensitive leak detection, depending on the merging con.guration and the child reference \ntype. Using the CCT instead of the CCU adds on average 46 or 48% overhead over context-insensitve leak \ndetection, depending on the child reference type. For the CCU-based approach, using strong child refer\u00adences \nhas no signi.cant impact on performance, with similar results across all benchmarks (1% less overhead \non average than using weak reference with copy merging). This result is not surprising since only longer-lived \nnodes have child ref\u00aderences, so most child references remain live in any case. The CCT-based approach \nbene.ts more (2 4%, relative to baseline execution), since the cost of creating new nodes is greater: \nallocating a node that is not found on lookup re\u00adquires repeating the lookup in a small critical section. \n In both con.gurations, across all benchmarks, the CCU\u00adbased approach (with copy merging) performs about \nthe same as, or signi.cantly better than, the CCT-based ap\u00adproach. For some programs, such as jython \nand luindex, the CCU-based approach drastically outperforms the CCT\u00adbased approach. Merging has little \neffect on time overhead, although we show next that it reduces space overhead signi.cantly. Merg\u00ading \ns time bene.t is modest since (1) merging adds its own GC overhead and (2) our experiments let the JVM \ngrow the heap automatically, so the extra memory pressure without merging does not necessarily lead to \nmore frequent GC. In both con.gurations, the CCU-based approach adds high overhead to hsqldb, with much \nof it due to GC (sub\u00adbars are GC time). Unsurprisingly, hsqldb, which we show allocates signi.cantly \nmore CCU nodes than the other pro\u00adgrams, bene.ts the most from merging of duplicate nodes. Figure 8(a) \ns results include hoisting of client site node allocation out of hot loops (Section 4.2). Without this \nop\u00adtimization, the CCU-and CCT-based approaches perfor\u00admance degrades by 15% and 66%, respectively (results \nnot shown). The CCT-based approach is helped more by this op\u00adtimization because its hash lookup at each \nclient site is more expensive than the CCU-based approach s node allocation. The CCU-based approach adds \nextra GC overhead due to both (1) increasing the allocation rate, which triggers GC more frequently, \nand (2) increasing the GC workload from transitively reachable CCU nodes. We estimate the contri\u00adbution \nof each cause by executing a con.guration of CCU\u00adbased leak detection (with client site nodes) without \nstor\u00ading CCU pointers into per-object metadata, which measures the allocation rate increase but not the \nworkload increase. We .nd that the GC overhead of this con.guration is 15%, whereas Figure 8(a) shows \nthe full CCU con.guration in\u00adcurs 20% GC overhead (both relative to context-insensitive leak detection). \nWe conclude that the majority (about three\u00adquarters) of GC overhead comes from the allocation rate in\u00adcrease, \nand the rest comes from the GC workload increase. Space overhead. Table 2 shows the average live memory \nadded for CCU and CCT nodes by measuring the total mem\u00adory consumed by the node space after each full-heap \nGC and reporting the average across the execution. Table 2(a) uses client site nodes, and Table 2(b) \ndoes not (i.e., same as Figures 8(a) and 8(b), respectively). The results indicate that merging duplicate \nnodes is sometimes critical to avoid high space overhead. Copy merging in particular improves memory \noverhead signi.cantly. We have determined that both merging algorithms perform similarly in terms of \nthe number of merged nodes, but In-place merging has higher space overhead because it fragments the heap \nsigni.cantly and adds two words for every node (one for the childMap and one for the next pointer; Section \n4.3), not just merged nodes. CCU Weak w/merging: CCU CCT None In-place Copy Strong Weak Strong antlr \n1,675 1,318 1,241 1,286 1,239 24,347 chart 33,299 16,088 1,222 1,259 1,187 1,594 eclipse 56,324 30,708 \n3,481 8,441 3,315 283,313 fop 2,048 1,955 1,197 1,210 1,185 1,214 hsqldb 59,796 32,840 1,283 1,287 1,402 \n10,304 jython 3,499 3,466 2,932 3,090 3,103 48,878 luindex 2,822 1,708 1,602 1,676 1,605 10,972 lusearch \n44,644 33,143 1,994 2,044 1,656 6,598 pmd 40,348 12,386 1,662 2,246 1,532 62,239 xalan 62,382 36,924 \n4,309 26,880 3,803 146,239 pseudojbb 41,091 26,264 2,754 2,775 2,780 980 (a) CCU and CCT con.gurations \nallocate client site nodes. CCU Weak w/merging: CCU CCT None In-place Copy Strong Weak Strong antlr 1,355 \n1,256 1,209 1,198 1,197 4,791 chart 17,520 8,186 1,187 1,191 1,174 665 eclipse 26,336 21,404 2,993 3,245 \n2,988 59,640 fop 1,637 1,785 1,172 1,172 1,166 288 hsqldb 43,705 25,763 1,248 1,246 1,267 2,055 jython \n2,941 3,032 2,723 2,735 2,834 17,142 luindex 1,902 1,653 1,594 1,608 1,604 1,880 lusearch 21,246 16,418 \n1,505 1,531 1,417 2,534 pmd 15,243 7,815 1,469 1,727 1,425 10,130 xalan 22,341 7,115 3,293 3,740 3,194 \n32,044 pseudojbb 18,058 11,432 2,644 2,657 2,723 312 (b) CCU and CCT con.gurations store client sites \nin object headers. Table 2. Memory consumed by CCU and CCT nodes, in KB, for context-sensitive leak detection \nwith (a) client sites stored in nodes and (b) with client sites stored in object headers. The .rst three \nCCU con.gurations use weak child references. CCU Strong uses copy merging but avoids tracing merged nodes. \nCCT Weak mimics copy merging by allocating into a copy space and copying to a mark-sweep space. CCT Strong \nuses an immortal space. For the CCU, Strong child references do not add much space overhead over weak \nreferences using copy merging, since only longer-lived nodes get merged. Weak references do reduce space \noverhead in a few cases, e.g., xalan with client site nodes. Weak references are more important for the \nCCT; using strong references leads to high space overhead in several cases because irrelevant nodes are \nnever collected. Weak references add more space overhead than strong refer\u00adences in a few cases (pseudojbb \nin both tables; chart and fop in Table 2(b)) because weak references lead to fragmentation in the mark-sweep \nnode space.  5.4 Data Race Detection This section evaluates the overhead of the context-sensitive race \ndetector that records context-sensitive sites at reads and writes. The race detector does not allocate \nclient site nodes and instead uses a separate word per .eld and array element for the context-insensitive \nclient site (Section 4.4). Time overhead. Figure 9 shows the run-time overhead that race detection adds \nto programs. Context-insensitive race de\u00adtection slows programs by about 7.8X on average, which  Figure \n9. Time overhead of race detection with and without CCU-and CCT-based context sensitivity. Sub-bars are \nGC time. (a) eclipse (b) hsqldb (c) lusearch (d) xalan (e) pseudojbb Figure 10. Normalized execution \ntime of race detection, with and without CCU-based context sensitivity, at various sampling rates (0%, \n5%, 10%, 25%, 50%, 100%). matches prior results for the FastTrack and Pacer implemen\u00adtations [14, 22]. \nCCU-based context sensitivity with merging (with weak child references) adds 37% average overhead, relative \nto original program execution time, over context\u00adinsensitive race detection, while CCU-based context \nsensi\u00adtivity with strong child references adds 40% average over\u00adhead. CCT-based context sensitivity with \nstrong child ref\u00aderences adds 61% average overhead while CCT-based con\u00adtext sensitivity with weak child \nreferences adds 62% average overhead over context-insensitive race detection. If we con\u00adsider only the \nmultithreaded benchmarks (eclipse, hsqldb, lusearch, xalan, and pseudojbb), the CCU-based approach adds \n61% and 60% (weak and strong child references, re\u00adspectively), while the CCT adds 96% and 79% (weak and \nstrong child references, respectively). . We further break down the overhead for the multithreaded benchmarks \ninto three parts (results not shown): stack walk\u00ading adds about 20% overhead (relative to original program \nexecution); storing CCU nodes into metadata adds about 10%; and allocation and GC of nodes add about \n20%. We evaluate the overhead of the CCU-based race detec\u00adtor at different sampling rates, in order to \ndetect how well a CCU-based approach s overhead scales with the client anal\u00adysis. Sampling-based race \ndetection samples a fraction of reads and writes equal to the sampling rate, so a lower sam\u00adpling rate \nshould yield a less-demanding client analysis. Fig\u00adure 10 shows how the amount of additional overhead \nadded by the CCU-based approach scales approximately linearly with the sampling rate. This behavior is \nwhat we expect since our implementation constructs CCU nodes lazily at client sites (Section 3.1). We \nalso measured (but do not show) time overhead across sampling rates for the CCT, which also scales well \nbecause it uses lazy construction. Space overhead. Figure 11 shows the memory used by CCU and CCT nodes \nacross an execution. We omit CCU with strong child references since its space overhead is sim\u00adilar to \nCCU with weak child references (e.g., Table 2). Time is normalized to the length of each execution. Each \npoint represents the live CCU or CCT memory at the end of a full-heap GC. Race det + CCU w/o merging, \nwhich con\u00adstructs CCU nodes but does not merge duplicate nodes, clearly shows the need for merging. By \nmerging duplicate nodes, the space overhead added by the CCU is reduced sub\u00adstantially. Furthermore, \nwhereas CCU space overhead grows  (a) eclipse (b) hsqldb (c) lusearch (d) xalan (e) pseudojbb over \ntime without merging (which is unsurprising since these programs total live memory also grows over time), \nmerging keeps CCU space overhead fairly constant over time. The CCU with copy merging provides space \noverhead similar to, or signi.cantly lower than, the CCT with both strong and weak child references. \n 5.5 Evaluating a Worst-Case Client Since our leak detector instruments only reference reads and our \nrace detector avoids instrumenting reads and writes for same epoch cases (Section 4.4), we evaluate a \nsimple, plausible worst case for CCU-and CCT-based analyses: in\u00adstrumenting every read and write to record \nthe last-access site in per-object metadata. To keep the context-insensitive client simple and its overhead \nlow, this client s instrumenta\u00adtion does not perform any synchronization. Our evaluation excludes lusearch \nbecause it crashes for unknown reasons with context-insensitive instrumentation. We execute the medium \nworkload for eclipse because the CCT-based con.guration runs out of memory on the large workload. We \nexperiment with con.gurations with and with\u00adout client site nodes, as for the leak detector (Section \n5.3). Figures 12(a) and 12(b) show the normalized application time with and without client site nodes, \nrespectively. The Context insensitive con.guration records context-insensitive sites and adds about 8% \noverhead on average. The CCU and CCT con.gurations are the same as the weak reference con.gurations from \nFigure 8. When the CCU and CCT construct client site nodes (Fig\u00adure 12(a)), CCU-based context sensitivity \nadds 140 145% overhead, depending on the merging con.guration and weak versus strong child references. \nCCT-based context sensitiv\u00adity adds substantially more overhead 356 and 358% on av\u00aderage for strong child \nreference and weak child reference, respectively because the cost of looking up or construct\u00ading each \nnode is substantially higher for the CCT than for the CCU. For con.gurations that store client sites \nin object headers (Figure 12(b)), CCU-based context sensitivity adds 49 52% overhead on average to leak \ndetection, depending on the merging con.guration and child reference type. The CCT-based approach adds \n77% overhead on average.   CCU CCU CCT Weak Strong Immortal Weak Strong antlr 1,203 1,220 145,575 1,194 \n4,591 chart 1,176 1,189 258,242 1,174 647 eclipse 2,679 2,690 28,390 2,664 1,305 fop 1,171 1,171 18,484 \n1,168 272 hsqldb 1,251 1,245 180,469 1,269 3,289 jython 2,670 2,675 293,213 2,726 12,306 luindex 1,595 \n1,615 527,197 1,604 1,821 lusearch 1,434 1,532 477,792 1,418 2,199 pmd 1,476 1,738 403,116 1,429 9,558 \nxalan 2,982 3,073 266,059 2,944 10,342 pseudojbb 2,644 2,646 216,943 2,732 327 Table 3. Memory consumed \nby CCU and CCT nodes, in KB, for context-sensitive leak detection without client site nodes. CCU Im\u00admortal \nis the immortal CCU-based approach, and the other columns are the same as Table 2(b); CCU Weak uses copy \nmerging.  5.6 Reliance on Tracing GC The CCU-based approach avoids the cost of looking up ex\u00adisting \ncalling context nodes, but it allocates substantially more nodes than a CCT-based approach that reuses \nnodes. This section evaluates how much the CCU-based approach relies on tracing GC to collect irrelevant \nnodes by dis\u00adabling GC of irrelevant nodes.8 Implementation and methodology. We have implemented an alternative \nimmortal CCU-based approach that allo\u00adcates CCU nodes into an immortal space that GC does not trace, \nsaving GC time but using extra heap memory and trig\u00adgering GC more frequently. This approach is thus \nrelated to our CCT-based approach with strong child references, which also allocates nodes into an immortal \nspace that GC does not trace. The immortal CCU-based approach runs out of memory for several benchmarks \nwhen used with the leak detection client, especially when using client site nodes, so we use a con.guration \nwithout client site nodes. Some programs still run out of memory with the large workload size; we use \nthe small size for eclipse and medium size for jython and xalan. Space overhead. Table 3 shows the live \nmemory used by CCU and CCT nodes, by measuring the memory consumed by the node space(s) at each full-heap \nGC and reporting the average across the execution. The results are similar to Table 2(b), except that \nTable 3 adds the immortal CCU\u00adbased approach. The immortal CCU-based approach uses 1 2 orders of magnitude \nmore memory than the other CCU\u00adand CCT-based approaches that use GC, including even the CCT with strong \nchild references. Time overhead. We .nd that the immortal CCU-based ap\u00adproach actually improves the time \nperformance slightly over 8 We considered implementing a variant that allocates CCU nodes and does not \ncollect irrelevant nodes, but merges duplicate nodes. However, this variant and the standard CCT-based \napproach should perform similarly since they each merge every allocated node. the tracing-baed CCU-based \napproaches: by 2% on average, relative to baseline execution time (results not shown). This improvement \ncomes from reducing GC time, since immortal CCU nodes are not traced or merged. The results indicate \nthat the CCU-based approach relies on tracing GC to collect irrelevant nodes which increase space overhead \ndrastically if not collected or merged. Although irrelevant nodes increase memory pressure, GC time does \nnot increase signi.cantly in our experiments since they allow the heap size to grow automatically.  \n5.7 Summary of Quantitative Evaluation In summary, the CCU-based approach almost always out\u00adperforms \nthe CCT-based approach in terms of time and per\u00adforms comparably in terms of space. More signi.cantly, \nthis result demonstrates the potential of the CCU-based approach which might seem counterintuitive at \n.rst to provide dynamic context sensitivity ef.ciently. 6. Evaluating Context Sensitivity While this \npaper mainly evaluates performance, this section evaluates whether context sensitivity provides useful \ninfor\u00admation to bug reports. Qualitatively Evaluating Context-Sensitive Leaky Sites We .rst qualitatively \nevaluate two real leaks that were re\u00adproduced and evaluated by prior work [15, 31]: one in SPECjbb2000 \n[47] and one in Eclipse.9 Our reported leaky sites do not exactly match those from the prior staleness\u00adbased \nleak detector that evaluated the same leaks [15] be\u00adcause our detector updates an object s staleness \nand last-use site when a reference to the object is loaded [17], instead of when the object itself is \nmodi.ed. SPECjbb2000 leak. The SPECjbb2000 leak occurs be\u00adcause the program adds but does not correctly \nremove .n\u00adished orders from an order list. Researchers from IBM and Intel discovered the leak .x, which \ninvolves replacing a call to spec.jbb.District.removeOldestOrder() with logic to properly remove .nished \norders [15]. Our context-sensitive leak detector reports the following context as a last-use site for \na growing number of stale objects: <4> spec.jbb.infra.Factory.Container.deallocObject():352 <34> spec.jbb.infra.Factory.Factory.deleteEntity():659 \n<1> spec.jbb.District.removeOldestOrder():285 <1> spec.jbb.DeliveryTransaction.process():201 <1> spec.jbb.DeliveryHandler.handleDelivery():103 \n <2> spec.jbb.DeliveryTransaction.queue():363 <1> spec.jbb.TransactionManager.go():449 <1> spec.jbb.JBBmain.run():173 \n The numbers in brackets (e.g., <34>) indicate the number of static call sites that can potentially \ncall each method (based on analyzing the source with the Eclipse IDE). This 9 http://www.eclipse.org \n gives a sense of how nontrivial the context is, i.e., how hard it might be for developers to guess \nthe context from a context-insensitive site. In this case, developers need to .nd DeliveryTransaction.process():201, \nwhich will likely require a lot of work because Factory.deleteEntity() has 34 callers. However, in our \nexperiments, the client site actually consists of the .rst three call sites due to method inlining by \nthe optimizing compiler, from which it is relatively easy to .nd the buggy site. Eclipse leak. Eclipse \nbug #115789 leaks memory when a recursive difference is performed between two source trees.10 Repeatedly \ncomparing the source tree leads to a growing leak. Prior work shows that the leak occurs in a NavigationHistory \ncomponent that enables navigating back to prior editor windows, but does not properly release old state \n[15]. Our leak detector reports one last-use site in NavigationHistory, shown in Figure 1.11 This calling \ncon\u00adtext illustrates how comparing source trees in Eclipse ul\u00adtimately leads to stale last-use sites \nin NavigationHistory. The elided call sites are other Eclipse internal methods. We note that the leak \n.x involves changing NavigationHistory, so the context-insensitive site is useful by itself. On the other \nhand, code tree comparisons cause the leak, so devel\u00adopers might .nd the connection between CompareUI.open-CompareEditorOnPage() \nand NavigationHistory useful for understanding the leak. In any case, this example shows that context-sensitive \nsites can provide signi.cantly more infor\u00admation to developers for highly object-oriented programs. As \nin prior work, our implementation reports a few other last-use sites (for both leaks) for a growing number \nof stale objects, but these sites are not directly related to the bug .x, so we do not evaluate their \ncontexts. Quantitatively Evaluating Context-Sensitive Racy Sites To avoid spending substantial time understanding \nreported data races, we have only quantitatively (not qualitatively) evaluated the calling contexts reported \nby the race detector. Table 4 shows the number of prior racy accesses reported by the race detector (reporting \na race involves reporting a prior access and the current access). The .rst two columns com\u00adpare the number \nof context-insensitive and context-sensitive prior accesses; for three programs, context sensitivity \nyields more distinct prior accesses. Dynamic races (last column) vary greatly across the programs. We \nhave evaluated the possibility that adding context sensitivity with the CCU or CCT could impact the number \nof races reported (results not shown). However, the number of distinct and dynamic races reported do \nnot vary signi.cantly across con.gurations: the 95% con.dence intervals always 10 https://bugs.eclipse.org/bugs/show_bug.cgi?id=115789 \n11 Prior work reports this site and another in NavigationHistory [15]. This difference is due to the \ndiffering instrumentation strategies described earlier. Distinct Dynamic Context Context insensitive \nsensitive eclipse 41 59 667,230 hsqldb 9 22 336 lusearch 81 81 21,035,554 xalan 11 14 138 pseudojbb 21 \n21 920,462 Table 4. Distinct, prior context-insensitive accesses and context\u00adsensitive accesses. The \nlast column is dynamic data races reported. 6-10 16-20 26-30 36-40 46-50 1-5 11-15 21-25 31-35 41-45 \n51-55 eclipse 17 4 2 9 2 3 5 7 4 3 3 hsqldb 10 4 8 0 0 0 0 0 0 0 0 lusearch 35 15 31 0 0 0 0 0 0 0 0 \nxalan 44 0 0 2 4 0 0 0 0 0 pseudojbb 20 1 0 0 0 0 0 0 0 0 0 Table 5. Histogram showing the depth (in \ncall sites) of context\u00adsensitive sites reported by the race detector. overlap except in one case, which \nis not signi.cant given the number of independent comparisons involved. Table 5 is a histogram showing \nthe depths, in terms of number of sites, of distinct, context-sensitive prior racy ac\u00adcesses. Many contexts, \nespecially for eclipse, are dozens of sites long, suggesting the potential for calling contexts to provide \nsigni.cantly more information to developers than static program locations. 7. Related Work Section 2.1 \ncompared our CCU-based approach with a CCT\u00adbased approach. This section discusses other alternatives \nfor providing dynamic context sensitivity, plus other related topics. Walking the stack. Client analyses \ncan simply walk the entire call stack at each client site [16, 24, 37, 44, 50, 56], which is expensive \nwhen client sites execute frequently. Stack-walking approaches typically store nodes in a CCT for space \nef.ciency. Prior work walks the stack until it en\u00adcounters a stack frame that has already looked up its \nCCT node [50, 56], which is equivalent to lazy construction of the CCT (Section 3.1). Reconstructing \ncalling context. Recent work introduces several approaches that represent calling contexts as integer \nvalues and reconstruct calling contexts from these values on demand. Ultimately, mapping contexts to \nvalues is challeng\u00ading because the number of statically possible calling con\u00adtexts easily exceeds 264 \nfor real, complex programs not in\u00adcluding recursion, which leads to in.nitely many statically possible \ncontexts. Sumner et al. introduce precise calling context encoding (PCCE), which represents each calling \ncontext with a unique integer value [48]. Instrumentation at each call site incre\u00admentally computes the \ncurrent calling context s value. PCCE computes these increments at compile time by applying the Ball \nLarus intraprocedural path pro.ling algorithm [7] to the call graph.12 This algorithm also enables ef.cient \nrecon\u00adstruction of a calling context from its value.  While PCCE enables ef.cient encoding and pro.ling \nof calling contexts, it is fundamentally solving different prob\u00adlems than our CCU-based approach. First, \nPCCE is not well suited to providing context sensitivity for bug detection anal\u00adyses. To handle the challenge \nof many statically possible paths, PCCE represents a single context with a variable num\u00adber of integers. \nWe believe that supporting variable-sized, per-object metadata would add signi.cant overhead to a client, \nbut the PCCE paper does not evaluate any clients [48]. Second, PCCE is inherently unable to handle dynamic \nclass loading and virtual method dispatch, limiting its ap\u00adplicability. PCCE relies on knowing the static \ncall graph at compile time in order to number the call graph using the Ball Larus algorithm, which is \nnot possible under dynamic class loading. PCCE relies on instrumenting call edges ef.\u00adciently, but instrumenting \nvirtual method calls incurs extra costs [40]. PCCE handles indirect calls (e.g., indirect calls via method \npointers in C) by adding an integer to the stack of integers that represent context, which is reasonable \nif in\u00addirect calls are rare, but would add high time and space over\u00adhead if used to handle the uncertainty \nintroduced by dynamic class loading and virtual method dispatch. Breadcrumbs handles dynamic class loading \nand virtual method dispatch, and it maps each calling context to a sin\u00adgle integer word [13]. It computes \na probabilistically unique value for each calling context by computing an incremen\u00adtal hash function \nat each call site [16]. Because the num\u00adber of statically possible contexts greatly exceeds both 264 \nand the number of dynamically executed contexts, Bread\u00adcrumbs also records some dynamic information the \ncon\u00adtext values observed at cold call sites in order to help guide reconstruction of contexts. Nonetheless, \nreconstruction of contexts is complex, may take seconds, and may fail to re\u00adconstruct the correct context. \nBreadcrumbs thus provides a time accuracy tradeoff, since collecting more dynamic in\u00adformation provides \nbetter reconstruction accuracy. Mytkowicz et al. and Inoue and Nakatani propose to re\u00adconstruct contexts \nfrom existing run-time values such as pro\u00adgram counters and stack depth [28, 35]. These approaches add \nvirtually no overhead, but the values they use have signi.cantly less entropy than Breadcrumbs probabilisti\u00adcally \nunique values. To reduce value con.icts between stack depths, Mytkowicz et al. pad the call stack based \non pro.l\u00ading, which helps accuracy somewhat but not enough to scale to complex programs with many distinct \ncalling contexts. Other approaches. A call tree constructs a new node for every dynamic call [3], but \neach call tree node maintains 12 Wiedermann also applies Ball Larus path pro.ling to the call graph but \ndoes not handle recursion nor the number of paths exceeding the integer size [51]. pointers to its child \nnodes, making it expensive to construct nodes and dif.cult for GC to collect irrelevant nodes (since \nall nodes remain reachable). Analyses can build and main\u00adtain a dynamic call graph, which maintains only \none node per static call site, losing the ability to reconstruct client sites calling contexts [40]. \nRecent work pro.les all contexts using a CCT-based, VM-independent approach, but the technique focuses \non portability and minimizing space overhead and adds higher overhead than high-performance CCT pro.lers \n[42]. Recent work proposes an alternative to the CCT in which contexts are bounded to depth k to save \nspace and increase utility compared to an in.nite-depth CCT [6]. This approach still requires an expensive \nhash lookup like the CCT. Prior work uses sampling and data mining to trade ac\u00adcuracy for lower overhead \nwhen collecting calling con\u00adtexts [20, 27, 56]. This tradeoff is worthwhile for deter\u00admining hot program \nbehavior for performance optimization. However, cold program behavior is critical for bug detec\u00adtion \n[18, 33]. Hash consing merges equivalent objects [4], and prior work uses hash consing to compact dynamic \ncall trees [29]. The CCU-and CCT-based approaches are essentially per\u00adforming hash consing of nodes: \nthe CCT performs hash con\u00adsing eagerly, and the CCU performs hash consing lazily. 8. Conclusion Growing \ncomplexity and concurrency mean that static pro\u00adgram location is not enough to help programmers understand \ndynamic program behavior. This paper presents a new ap\u00adproach for providing context sensitivity to dynamic \nanaly\u00adses, especially bug detectors that report bug causes. Calling context uptree (CCU) nodes cannot \nbe reused but are fast to construct. Tracing garbage collection and a lazy merging al\u00adgorithm are key \ncomponents that keep space overhead low. We demonstrate a CCU-based approach s potential to out\u00adperform \na CCT-based approach when adding context sensi\u00adtivity to bug detection analyses, offering an appealing \ndirec\u00adtion for future work on context-sensitive dynamic analysis. Acknowledgments We thank Daniel Frampton, \nSam Guyer, Kathryn McKin\u00adley, Feng Qin, and Nasko Rountev for valuable discus\u00adsions, ideas, and support. \nThanks to Swarnendu Biswas, Todd Mytkowicz, Nasko Rountev, Aritra Sengupta, Xiangyu Zhang, and the anonymous \nreviewers for helpful feedback on the text; and to Man Cao, Aritra Sengupta, and Minjia Zhang for help \nwith the artifact evaluation submission.  References [1] H. Agrawal and J. R. Horgan. Dynamic Program \nSlicing. In ACM Conference on Programming Language Design and Implementation, pages 246 256, 1990. [2] \nB. Alpern, S. Augart, S. M. Blackburn, M. Butrico, A. Cocchi, P. Cheng, J. Dolby, S. Fink, D. Grove, \nM. Hind, K. S. McKin\u00adley, M. Mergen, J. E. B. Moss, T. Ngo, and V. Sarkar. The Jikes Research Virtual \nMachine Project: Building an Open-Source Research Community. IBM Systems Journal, 44:399 417, 2005. [3] \nG. Ammons, T. Ball, and J. R. Larus. Exploiting Hardware Performance Counters with Flow and Context Sensitive \nPro\u00ad.ling. In ACM Conference on Programming Language Design and Implementation, pages 85 96, 1997. [4] \nA. W. Appel and M. J. R. Goncalves. Hash-Consing Garbage Collection. Technical Report TR-412-93, Princeton \nUniver\u00adsity, 1993. [5] M. Arnold, S. J. Fink, D. Grove, M. Hind, and P. F. Sweeney. Adaptive Optimization \nin the Jalape no JVM. In ACM Confer\u00adence on Object-Oriented Programming, Systems, Languages, and Applications, \npages 47 65, 2000. [6] G. Ausiello, C. Demetrescu, I. Finocchi, and D. Firmani. k-Calling Context Pro.ling. \nIn ACM Conference on Object-Oriented Programming, Systems, Languages, and Applica\u00adtions, pages 867 878, \n2012. [7] T. Ball and J. R. Larus. Ef.cient Path Pro.ling. In IEEE/ACM International Symposium on Microarchitecture, \npages 46 57, 1996. [8] S. M. Blackburn, P. Cheng, and K. S. McKinley. Myths and Realities: The Performance \nImpact of Garbage Collection. In ACM SIGMETRICS Joint International Conference on Mea\u00adsurement and Modeling \nof Computer Systems, pages 25 36, 2004. [9] S. M. Blackburn, R. Garner, C. Hoffman, A. M. Khan, K. S. \nMcKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Framp\u00adton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, \nH. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4c, T. VanDrunen, D. von Dincklage, and B. Wiedermann. \nThe DaCapo Bench\u00admarks: Java Benchmarking Development and Analysis. In ACM Conference on Object-Oriented \nProgramming, Systems, Languages, and Applications, pages 169 190, 2006. [10] S. M. Blackburn and A. L. \nHosking. Barriers: Friend or Foe? In ACM International Symposium on Memory Management, pages 143 151, \n2004. [11] S. M. Blackburn and K. S. McKinley. Ulterior Reference Counting: Fast Garbage Collection Without \na Long Wait. In ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications, \npages 344 358, 2003. [12] S. M. Blackburn and K. S. McKinley. Immix: A Mark-Region Garbage Collector \nwith Space Ef.ciency, Fast Collection, and Mutator Performance. In ACM Conference on Programming Language \nDesign and Implementation, pages 22 32, 2008. [13] M. D. Bond, G. Z. Baker, and S. Z. Guyer. Breadcrumbs: \nEf\u00ad.cient Context Sensitivity for Dynamic Bug Detection Anal\u00adyses. In ACM Conference on Programming Language \nDesign and Implementation, pages 13 24, 2010. [14] M. D. Bond, K. E. Coons, and K. S. McKinley. Pacer: \nProportional Detection of Data Races. In ACM Conference on Programming Language Design and Implementation, \npages 255 268, 2010. [15] M. D. Bond and K. S. McKinley. Bell: Bit-Encoding Online Memory Leak Detection. \nIn ACM International Conference on Architectural Support for Programming Languages and Operating Systems, \npages 61 72, 2006. [16] M. D. Bond and K. S. McKinley. Probabilistic Calling Con\u00adtext. In ACM Conference \non Object-Oriented Programming, Systems, Languages, and Applications, pages 97 112, 2007. [17] M. D. \nBond and K. S. McKinley. Leak Pruning. In ACM International Conference on Architectural Support for Pro\u00adgramming \nLanguages and Operating Systems, pages 277 288, 2009. [18] T. M. Chilimbi and M. Hauswirth. Low-Overhead \nMem\u00adory Leak Detection Using Adaptive Statistical Pro.ling. In ACM International Conference on Architectural \nSupport for Programming Languages and Operating Systems, pages 156 164, 2004. [19] J.-D. Choi, K. Lee, \nA. Loginov, R. O Callahan, V. Sarkar, and M. Sridharan. Ef.cient and Precise Datarace Detection for Multithreaded \nObject-Oriented Programs. In ACM Confer\u00adence on Programming Language Design and Implementation, pages \n258 269, 2002. [20] D. C. D Elia, C. Demetrescu, and I. Finocchi. Mining Hot Calling Contexts in Small \nSpace. In ACM Conference on Programming Language Design and Implementation, pages 516 527, 2011. [21] \nT. Elmas, S. Qadeer, and S. Tasiran. Goldilocks: A Race and Transaction-Aware Java Runtime. In ACM Conference \non Programming Language Design and Implementation, pages 245 255, 2007. [22] C. Flanagan and S. N. Freund. \nFastTrack: Ef.cient and Precise Dynamic Race Detection. In ACM Conference on Program\u00adming Language Design \nand Implementation, pages 121 133, 2009. [23] C. Flanagan, S. N. Freund, and J. Yi. Velodrome: A Sound \nand Complete Dynamic Atomicity Checker for Multithreaded Programs. In ACM Conference on Programming Language \nDesign and Implementation, pages 293 303, 2008. [24] N. Froyd, J. Mellor-Crummey, and R. Fowler. Low-Overhead \nCall Path Pro.ling of Unmodi.ed, Optimized Code. In ACM International Conference on Supercomputing, pages \n81 90, 2005. [25] R. Garner, S. M. Blackburn, and D. Frampton. Effective Prefetch for Mark-Sweep Garbage \nCollection. In ACM Inter\u00adnational Symposium on Memory Management, pages 43 54, 2007. [26] B. Goetz. Plugging \nmemory leaks with weak refer\u00adences, 2005. http://www-128.ibm.com/developerworks/ java/library/j-jtp11225/. \n[27] K. Hazelwood and D. Grove. Adaptive Online Context-Sensitive Inlining. In IEEE/ACM International \nSymposium on Code Generation and Optimization, pages 253 264, 2003.  [28] H. Inoue and T. Nakatani. \nHow a Java VM can get more from a Hardware Performance Monitor. In ACM Conference on Object-Oriented \nProgramming, Systems, Languages, and Applications, pages 137 154, 2009. [29] D. F. Jerding, J. T. Stasko, \nand T. Ball. Visualizing Interactions in Program Executions. In ACM International Conference on Software \nEngineering, pages 360 370, 1997. [30] R. Jones and R. Lins. Garbage Collection: Algorithms for Automatic \nDynamic Memory Management. John Wiley &#38; Sons, Inc., New York, NY, USA, 1996. [31] M. Jump and K. \nS. McKinley. Cork: Dynamic Memory Leak Detection for Garbage-Collected Languages. In ACM Symposium on \nPrinciples of Programming Languages, pages 31 38, 2007. [32] S. Lu, J. Tucek, F. Qin, and Y. Zhou. AVIO: \nDetecting Atomicity Violations via Access-Interleaving Invariants. In ACM International Conference on \nArchitectural Support for Programming Languages and Operating Systems, pages 37 48, 2006. [33] D. Marino, \nM. Musuvathi, and S. Narayanasamy. LiteRace: Effective Sampling for Lightweight Data-Race Detection. \nIn ACM Conference on Programming Language Design and Im\u00adplementation, pages 134 143, 2009. [34] A. Milanova, \nA. Rountev, and B. G. Ryder. Parameterized Object Sensitivity for Points-to and Side-Effect Analyses \nfor Java. In ACM International Symposium on Software Testing and Analysis, pages 1 11, 2002. [35] T. \nMytkowicz, D. Coughlin, and A. Diwan. Inferred Call Path Pro.ling. In ACM Conference on Object-Oriented \nProgram\u00adming, Systems, Languages, and Applications, pages 175 190, 2009. [36] N. Nethercote and J. Seward. \nHow to Shadow Every Byte of Memory Used by a Program. In ACM/USENIX International Conference on Virtual \nExecution Environments, pages 65 74, 2007. [37] N. Nethercote and J. Seward. Valgrind: A Framework for \nHeavyweight Dynamic Binary Instrumentation. In ACM Con\u00adference on Programming Language Design and Implementa\u00adtion, \npages 89 100, 2007. [38] G. Novark, E. D. Berger, and B. G. Zorn. Ef.ciently and Pre\u00adcisely Locating \nMemory Leaks and Bloat. In ACM Confer\u00adence on Programming Language Design and Implementation, pages 397 \n407, 2009. [39] E. Pozniansky and A. Schuster. MultiRace: Ef.cient On-the-Fly Data Race Detection in \nMultithreaded C++ Pro\u00adgrams. Concurrency and Computation: Practice &#38; Experi\u00adence, 19(3):327 340, \n2007. [40] F. Qian and L. Hendren. Towards Dynamic Interprocedural Analysis in JVMs. In USENIX Symposium \non Virtual Machine Research and Technology, pages 139 150, 2004. [41] F. Qin, S. Lu, and Y. Zhou. SafeMem: \nExploiting ECC-Memory for Detecting Memory Leaks and Memory Corrup\u00adtion During Production Runs. In International \nSymposium on High-Performance Computer Architecture, pages 291 302, 2005. [42] A. Sarimbekov, A. Sewe, \nW. Binder, P. Moret, M. Schoeberl, and M. Mezini. Portable and Accurate Collection of Calling\u00adContext-Sensitive \nBytecode Metrics for the Java Virtual Ma\u00adchine. In ACM International Conference on Principles and Practice \nof Programming in Java, pages 11 20, 2011. [43] S. Savage, M. Burrows, G. Nelson, P. Sobalvarro, and \nT. An\u00adderson. Eraser: A Dynamic Data Race Detector for Multi-Threaded Programs. In ACM Symposium on Operating \nSys\u00adtems Principles, pages 27 37, 1997. [44] J. Seward and N. Nethercote. Using Valgrind to Detect Un\u00adde.ned \nValue Errors with Bit-Precision. In USENIX Annual Technical Conference, pages 17 30, 2005. [45] Y. Smaragdakis, \nM. Bravenboer, and O. Lhot\u00b4ak. Pick Your Contexts Well: Understanding Object-Sensitivity. In ACM Symposium \non Principles of Programming Languages, pages 17 30, 2011. [46] J. M. Spivey. Fast, Accurate Call Graph \nPro.ling. Softw. Pract. Exper., 34(3):249 264, 2004. [47] Standard Performance Evaluation Corporation. \nSPECjbb2000 Documentation, release 1.01 edition, 2001. [48] W. N. Sumner, Y. Zheng, D. Weeratunge, and \nX. Zhang. Precise Calling Context Encoding. In ACM International Conference on Software Engineering, \npages 525 534, 2010. [49] C. von Praun and T. R. Gross. Object Race Detection. In ACM Conference on Object-Oriented \nProgramming, Systems, Languages, and Applications, pages 70 82, 2001. [50] J. Whaley. A Portable Sampling-Based \nPro.ler for Java Vir\u00adtual Machines. In ACM Conference on Java Grande, pages 78 87, 2000. [51] B. Wiedermann. \nKnow your Place: Selectively Executing Statements Based on Context. Technical Report TR-07-38, University \nof Texas at Austin, 2007. [52] G. Xu and A. Rountev. Precise Memory Leak Detection for Java Software \nUsing Container Pro.ling. In ACM Interna\u00adtional Conference on Software Engineering, pages 151 160, 2008. \n[53] X. Yang, S. M. Blackburn, D. Frampton, and A. L. Hosking. Barriers Reconsidered, Friendlier Still! \nIn ACM International Symposium on Memory Management, pages 37 48, 2012. [54] Y. Yu, T. Rodeheffer, and \nW. Chen. RaceTrack: Ef.cient Detection of Data Race Conditions via Adaptive Tracking. In ACM Symposium \non Operating Systems Principles, pages 221 234, 2005. [55] X. Zhang, N. Gupta, and R. Gupta. Pruning \nDynamic Slices with Con.dence. In ACM Conference on Programming Lan\u00adguage Design and Implementation, \npages 169 180, 2006. [56] X. Zhuang, M. J. Serrano, H. W. Cain, and J.-D. Choi. Ac\u00adcurate, Ef.cient, \nand Adaptive Calling Context Pro.ling. In ACM Conference on Programming Language Design and Im\u00adplementation, \npages 263 271, 2006.    \n\t\t\t", "proc_id": "2509136", "abstract": "<p>State-of-the-art dynamic bug detectors such as data race and memory leak detectors report program locations that are likely causes of bugs. However, programmers need more than <i>static</i> program locations to understand the behavior of increasingly complex and concurrent software. <i>Dynamic calling context</i> provides additional information, but it is expensive to record calling context frequently, e.g., at every read and write. Context-sensitive dynamic analyses can build and maintain a calling context tree (CCT) to track calling context--but in order to reuse existing nodes, CCT-based approaches require an expensive lookup.</p> <p>This paper introduces a new approach for context sensitivity that avoids this expensive lookup. The approach uses a new data structure called the <i>calling context uptree</i> (CCU) that adds low overhead by avoiding the lookup and instead allocating a new node for each context. A key contribution is that the approach can mitigate the costs of allocating many nodes by extending tracing garbage collection (GC): GC collects unused CCU nodes naturally and efficiently, and we extend GC to merge duplicate nodes lazily.</p> <p>We implement our CCU-based approach in a high-performance Java virtual machine and integrate it with a staleness-based memory leak detector and happens-before data race detector, so they can report context-sensitive program locations that cause bugs. We show that the CCU-based approach, in concert with an extended GC, provides a compelling alternative to CCT-based approaches for adding context sensitivity to dynamic analyses.</p>", "authors": [{"name": "Jipeng Huang", "author_profile_id": "83358714957", "affiliation": "The Ohio State University, Columbus, OH, USA", "person_id": "P4290312", "email_address": "huangjip@cse.ohio-state.edu", "orcid_id": ""}, {"name": "Michael D. Bond", "author_profile_id": "81100148693", "affiliation": "The Ohio State University, Columbus, OH, USA", "person_id": "P4290313", "email_address": "mikebond@cse.ohio-state.edu", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509510", "year": "2013", "article_id": "2509510", "conference": "OOPSLA", "title": "Efficient context sensitivity for dynamic analyses via calling context uptrees and customized memory management", "url": "http://dl.acm.org/citation.cfm?id=2509510"}