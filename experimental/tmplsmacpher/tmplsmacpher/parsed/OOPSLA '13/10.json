{"article_publication_date": "10-29-2013", "fulltext": "\n Instant Pickles: Generating Object-Oriented Pickler Combinators for Fast and Extensible Serialization \n Heather Miller Philipp Haller EPFL, Switzerland Typesafe, Inc. heather.miller@ep..ch philipp.haller@typesafe.com \n Abstract As more applications migrate to the cloud, and as big data edges into even more production \nenvironments, the perfor\u00admance and simplicity of exchanging data between compute nodes/devices is increasing \nin importance. An issue central to distributed programming, yet often under-considered, is serialization \nor pickling, i.e., persisting runtime objects by converting them into a binary or text representation. \nPick\u00adler combinators are a popular approach from functional pro\u00adgramming; their composability alleviates \nsome of the tedium of writing pickling code by hand, but they don t translate well to object-oriented \nprogramming due to qualities like open class hierarchies and subtyping polymorphism. Furthermore, both \nfunctional pickler combinators and popular, Java-based serialization frameworks tend to be tied to a \nspecific pickle format, leaving programmers with no choice of how their data is persisted. In this paper, \nwe present object-oriented pickler combinators and a framework for generating them at compile-time, called \nscala/pickling, designed to be the default serialization mechanism of the Scala programming language. \nThe static generation of OO picklers enables sig\u00adnificant performance improvements, outperforming Java \nand Kryo in most of our benchmarks. In addition to high perfor\u00admance and the need for little to no boilerplate, \nour frame\u00adwork is extensible: using the type class pattern, users can provide both (1) custom, easily \ninterchangeable pickle for\u00admats and (2) custom picklers, to override the default behav\u00adior of the pickling \nframework. In benchmarks, we compare scala/pickling with other popular industrial frameworks, and present \nresults on time, memory usage, and size when pick\u00adling/unpickling a number of data types used in real-world, \nlarge-scale distributed applications and frameworks. Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for profit or commercial advantage and that copies bear this notice and the full \ncitation on the first page. Copyrights for components of this work owned by others than ACM must be honored. \nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute \nto lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \nOOPSLA 13, October 29 31, 2013, Indianapolis, Indiana, USA. Copyright &#38;#169; 2013 ACM 978-1-4503-2374-1/13/10 \n$15.00. http://dx.doi.org/10.1145/2509136.2509547 Eugene Burmako Martin Odersky EPFL, Switzerland EPFL, \nSwitzerland eugene.burmako@ep..ch martin.odersky@ep..ch  Categories and Subject Descriptors D.3.2 [Programming \nLanguages]: Language Classifications multiparadigm lan\u00adguages, object-oriented languages, applicative \n(functional) languages; D.3.3 [Programming Languages]: Language Constructs and Features input/output \nKeywords Serialization, pickling, meta-programming, dis\u00adtributed programming, Scala 1. Introduction With \nthe growing trend towards cloud computing and mo\u00adbile applications, distributed programming has entered \nthe mainstream. As more and more traditional applications mi\u00adgrate to the cloud, the demand for interoperability \nbetween different services is at an all-time high, and is increasing. At the center of it all is communication. \nWhether we consider a cluster of commodity machines churning through a massive data-parallel job, or \na smartphone interacting with a social network, all are distributed jobs, and all share the need to communicate \nin various ways, in many formats, even within the same application. A central aspect to this communication \nthat has received surprisingly little attention in the literature is the need to seri\u00adalize, or pickle \nobjects,i.e., to persist in-memory data by con\u00adverting them to a binary, text, or some other representation. \nAs more and more applications evolve the need to communi\u00adcate with different machines, providing abstractions \nand con\u00adstructs for easy-to-use, typesafe, and performant serialization is more important than ever. \nOn the JVM, serialization has long been acknowledged as having a high overhead [7, 41], with some estimates \npur\u00adporting object serialization to account for 25-65% of the cost of remote method invocation, and which \ngo on to ob\u00adserve that the cost of serialization grows with growing object structures up to 50% [18, \n27]. Due to the prohibitive cost of using Java Serialization in high-performance distributed applications, \nmany frameworks for distributed computing, like Akka [37], Spark [42], SCADS [3], and others, pro\u00advide \nsupport for higher-performance alternative frameworks such as Google s Protocol Buffers [13], Apache \nAvro [1], or Kryo [21]. However, the higher efficiency typically comes at the cost of weaker or no type \nsafety, a fixed serialization for\u00admat, more restrictions placed on the objects to-be-serialized, or only \nrudimentary language integration. This paper takes a step towards more principled open pro\u00adgramming \nthrough a new foundation for pickling in object\u00adoriented languages. We present object-oriented picklers \nand scala/pickling, a framework for their generation either at run\u00adtime or at compile time. The introduced \nnotion of object\u00adoriented pickler combinators extends pickler combinators known from functional programming \n[17] with support for object-oriented concepts such as subtyping, mix-in composi\u00adtion, and object identity \nin the face of cyclic object graphs. In contrast to pure functional-style pickler combinators, we em\u00adploy \nstatic, type-based meta programming to compose pick\u00adlers at compile time. The resulting picklers are \nefficient, since the pickling code is generated statically as much as possible, avoiding the overhead \nof runtime reflection [9, 12]. Furthermore, the presented pickling framework is exten\u00adsible in several \nimportant ways. First, building on an object\u00adoriented type-class-like mechanism [8], our approach en\u00adables \nretroactively adding pickling support to existing, un\u00admodified types. Second, our framework provides \npluggable pickle formats which decouple type checking and pickler composition from the lower-level aspects \nof data formatting. This means that the type safety guarantees provided by type\u00adspecialized picklers \nare portable in the sense that they carry over to different pickle formats. The design of our framework \nhas been guided by the following principles: Ease of use. The programming interface aims to require \nas little pickling boilerplate as possible. Thanks to dedi\u00adcated support by the underlying virtual machine, \nJava s serialization [25] requires only little boilerplate, which mainstream Java developers have come \nto expect. Our framework aims to be usable in production environments, and must, therefore, be able to \nintegrate with existing sys\u00adtems with minimal changes.  Performance. The generated picklers should be \nefficient enough so as to enable their use in high-performance dis\u00adtributed, big data , and cloud applications. \nOne factor driving practitioners away from Java s default serializa\u00adtion mechanism is its high runtime \noverhead compared to alternatives such as Kryo, Google s Protocol Buffers or Apache s Avro serialization \nframework. However, such alternative frameworks offer only minimal language in\u00adtegration.  Extensibility. \nIt should be possible to add pickling sup\u00adport to existing types retroactively. This resolves a com\u00admon \nissue in Java-style serialization frameworks where classes have to be marked as serializable upfront, \ncom\u00adplicating unanticipated change. Furthermore, type-class\u00adlike extensibility enables pickling also \nfor types provided by the underlying runtime environment (including built\u00adin types), or types of third-party \nlibraries.  Pluggable Pickle Formats. It should be possible to eas\u00adily swap target pickle formats, \nor for users to provide their own customized format. It is not uncommon for a distributed application \nto require multiple formats for ex\u00adchanging data, for example an efficient binary format for exchanging \nsystem messages, or JSON format for pub\u00adlishing feeds. Type-class-like extensibility makes it pos\u00adsible \nfor users to define their own pickle format, and to easily swap it in at the use-site.  Type safety. \nPicklers should be type safe through (a) type specialization and (b) dynamic type checks when un\u00adpickling \nto transition unpickled objects into the statically\u00adtyped world at a well-defined program point.  Robust \nsupport for object-orientation. Concepts such as subtyping and mix-in composition are used very com\u00admonly \nto define regular object types in object-oriented languages. Since our framework does without a sepa\u00adrate \ndata type description language (e.g., a schema), it is important that regular type definitions are sufficient \nto describe the types to-be-pickled. The Liskov substitu\u00adtion principle is used as a guidance surrounding \nthe sub\u00adstitutability of both objects to-be-pickled and first-class picklers. Our approach is also general, \nsupporting object graphs with cycles.  1.1 Selected Related Work Some OO languages like Java and runtime \nenvironments like the JVM or .NET provide serialization for arbitrary types, provided entirely by the \nunderlying virtual machine. While this approach is very convenient for the programmer, there are also \nseveral issues: (a) the pickling format cannot be exchanged (Java), (b) serialization relies on runtime \nreflec\u00adtion which hits performance, and (c) existing classes that do not extend a special marker interface \nare not serializ\u00adable, which often causes oversights resulting in software en\u00adgineering costs. In functional \nlanguages, pickler combina\u00adtors [10, 17] can reduce the effort of manually writing pick\u00adling and unpickling \nfunctions to a large extent. However, existing approaches do not support object-oriented concepts such \nas subtyping polymorphism. Moreover, it is not clear whether local type inference as required in OO languages \nwould yield a comparable degree of conciseness, acceptable to programmers used to Java-style serialization. \nNonetheless, our approach builds on pickler combinators, capitalizing on their powerful composability. \nOur approach of retrofitting existing types with pickling support builds on implicits in Scala [8] and \nis reminiscent of other type-class-like mechanisms, such as JavaGI [40] or C++ Concepts [29]. Additionally, \nin an effort to further reduce the boilerplate required to define or compose picklers using existing \npick\u00adlers, we present a framework for automatically generating picklers for compound types based on picklers \nfor their com\u00adponent types. Given the close relationship of our implicit picklers to type classes, this \ngeneration mechanism is related to Haskell s deriving mechanism [19]. One of the main dif\u00adferences is \nthat our mechanism is faithful to subtyping. So far, our mechanism is specialized for pickling; an extension \nto a generic mechanism for composing type class instances is left for future work. We discuss other \nrelated work in Section 7.  1.2 Contributions This paper makes the following contributions: An extension \nto pickler combinators, well-known in func\u00adtional programming, to support the core concepts of object-oriented \nprogramming, namely subtyping poly\u00admorphism, open class hierarchies, and object identity.  A framework \nbased on object-oriented pickler combi\u00adnators which (a) enables retrofitting existing types with pickling \nsupport, (b) supports automatically generating picklers at compile time and at runtime, (c) supports \nplug\u00adgable pickle formats, and (d) does not require changes to the host language or the underlying virtual \nmachine.  A complete implementation of the presented approach in and for Scala.1  An experimental evaluation \ncomparing the performance of our framework with Java serialization and Kryo on a number of data types \nused in real-world, large-scale distributed applications and frameworks.   2. Overview and Usage 2.1 \nBasic Usage Scala/pickling was designed so as to require as little boiler\u00adplate from the programmer as \npossible. For that reason, pick\u00adling or unpickling an object obj of type Obj requires simply, import \nscala.pickling._ val pickle = obj.pickle val obj2 = pickle.unpickle[Obj] Here, the import statement \nimports scala/pickling, the method pickle triggers static pickler generation, and the method unpickle \ntriggers static unpickler generation, where unpickle is parameterized on obj s precise type Obj. Note \nthat not every type has a pickle method; it is implemented as an extension method using an implicit conversion. \nThis implicit conversion is imported into scope as a member of the scala.pickling package. Implicit conversions. \nImplicit conversions can be thought of as methods which can be implicitly invoked based upon their type, \nand whether or not they are present in implicit scope. Implicit conversions carry the implicit keyword \nbe\u00adfore their declaration. The pickle method is provided using the following implicit conversion (slightly \nsimplified): 1 See http://github.com/scala/pickling/ implicit def PickleOps[T](picklee: T) = new PickleOps[T](picklee) \n class PickleOps[T](picklee: T) { def pickle: Pickle = ...  ... } In a nutshell, the above implicit \nconversion is implicitly invoked, passing object obj as an argument, whenever the pickle method is invoked \non obj. The above example can be written in a form where all invocations of implicit methods are explicit, \nas follows: val pickle = PickleOps[Obj](obj).pickle val obj2 = pickle.unpickle[Obj] Optionally, a user \ncan import a PickleFormat. By default, our framework provides a Scala Binary Format, an efficient representation \nbased on arrays of bytes, though the frame\u00adwork provides other formats which can easily be imported, \nincluding a JSON format. Furthermore, users can easily ex\u00adtend the framework by providing their own PickleFormats \n(see Section 4.3.1). Typically, the framework generates the required pickler itself inline in the compiled \ncode, using the PickleFormat in scope. In the case of JSON, for example, this amounts to the generation \nof string concatenation code and field accessors for getting runtime values, all of which is inlined, \ngenerally resulting in high performance (see Section 6). In rare cases, however, it is necessary to fall \nback to run\u00adtime picklers which use runtime reflection to access the state that is being pickled and \nunpickled. For example, a runtime pickler is used when pickling instances of a generic subclass of the \nstatic class type to-be-pickled. Using scala/pickling, it s also possible to pickle and un\u00adpickle subtypes, \neven if the pickle and unpickle methods are called using supertypes of the type to-be-pickled. For exam\u00adple, \nabstract class Person { def name: String } case class Firefighter(name: String, since: Int) extends \nPerson val ff: Person = Firefighter(\"Jim\", 2005) val pickle = ff.pickle val ff2 = pickle.unpickle[Person] \n In the above example, the runtime type of ff2 will cor\u00adrectly be Firefighter. This perhaps raises an \nimportant concern what if the type that is passed as a type argument to method unpickle is incorrect? \nIn this case, the framework will fail with a runtime exception at the call site of unpickle.This is an \nimprovement over other frameworks, which have less type information available at runtime, resulting in \nwrongly unpickled objects often propagating to other areas of the program before an exception is thrown. \n Scala/pickling is also able to unpickle values of static type Any.Scala s pattern-matching syntax can \nmake unpickling on less-specific types quite convenient, for example: pickle.unpickle[Any] match { case \nFirefighter(n, _) => println(n) case _ => println(\"not a Firefighter\") } Beyond dealing with subtypes, \nour pickling framework supports pickling/unpickling most Scala types, including generics, case classes, \nand singleton objects. Passing a type argument to pickle, whether inferred or explicit, which is an unsupported \ntype leads to a compile-time error. This avoids a common problem in Java-style serialization where non\u00adserializable \ntypes are only discovered at runtime, in gen\u00aderal. Function types, however, are not yet supported, and \nare planned future work.  2.2 Advanced Usage @pickleable Annotation. To handle subtyping correctly, \nthe pickling framework generates dispatch code which dele\u00adgates to a pickler specialized for the runtime \ntype of the ob\u00adject to-be-pickled, or, if the runtime type is unknown, which is to be expected in the \npresence of separate compilation, to a generic, but slower, runtime pickler. For better performance, \nscala/pickling additionally pro\u00advides an annotation which, at compile-time, inserts a runtime type test \nto check whether the runtime class extends a certain class/trait. In this case, a method that returns \nthe pickler spe\u00adcialized for that runtime class is called. If the class/trait has been annotated, the \nreturned pickler is guaranteed to have been generated statically. Furthermore, the @pickleable an\u00adnotation \n(implemented as a macro annotation) is expanded transitively in each subclass of the annotated class/trait. \nThis @pickleable annotation enables: library authors to guarantee to their clients that picklers for \nseparately-compiled subclasses are fully generated at compile-time;  faster picklers in general because \none need not worry about having to fallback on a runtime pickler.  For example, assume the following \nclass Person and its subclass Firefighter are defined in separately-compiled code. // Library code @pickleable \nclass Person(val name: String) // Client code class Firefighter(override val name: String, salary: \nInt) extends Person(name)  Note that class Person is annotated with the @pickleable annotation. @pickleable \nis a macro annotation which gener\u00adates additional methods for obtaining type-specialized pick\u00adlers (and \nunpicklers). With the @pickleable annotation ex\u00adpanded, the code for class Person looks roughly as follows: \nclass Person(val name: String) extends PickleableBase { def pickler: SPickler[_] = implicitly[SPickler[Person]] \n... } First, note that the supertypes of Person now addition\u00adally include the trait PickleableBase; \nit declares the abstract methods that the expansion of the macro annotation fills in with concrete methods. \nIn this case, a pickler method is generated which returns an SPickler[_]. 2 Note that the @pickleable \nannotation is defined in a way where pickler generation is triggered in both Person and its subclasses. \nHere, we obtain an instance of SPickler[Person] by means of implicits. The implicitly method, part of \nScala s standard library, is defined as follows: def implicitly[T](implicit e: T) = e Annotating the \nparameter (actually, the parameter list) us\u00ading the implicit keyword means that in an invocation of implicitly, \nthe implicit argument list may be omitted if, for each parameter of that list, there is exactly one value \nof the right type in the implicit scope.The implicit scope is an adap\u00adtation of the regular variable \nscope; imported implicits, or implicits declared in an enclosing scope are contained in the implicit \nscope of a method invocation. As a result, implicitly[T] returns the uniquely-defined implicit value \nof type T which is in scope at the invocation site. In the context of picklers, there might not be an \nimplicit value of type SPickler[Person] in scope (in fact, this is typi\u00adcally only the case with custom \npicklers). In that case, a suit\u00adable pickler instance is generated using a macro def. Macro defs. Macro \ndefs are methods that are transparently loaded by the compiler and executed (or expanded) during compilation. \nA macro is defined as if it is a normal method, but it is linked using the macro keyword to an additional \nmethod that operates on abstract syntax trees. def assert(x: Boolean, msg: String): Unit = macro assert_impl \ndef assert_impl(c: Context) (x: c.Expr[Boolean], msg: c.Expr[String]): c.Expr[Unit] = ...  In the above \nexample, the parameters of assert_impl are syntax trees, which the body of assert_impl operates on, 2 \nThe notation SPickler[_] is short for the existential type SPickler[t] for-Some { type t }. It is necessary \nhere, because picklers must be invariant in their type parameter, see Section 3.1.4. itself returning \nan AST of type Expr[Unit]. It is assert_impl that is expanded and evaluated at compile-time. Its result \nis then inlined at the call site of assert and the inlined result is typechecked. It is also important \nto note that implicit defs as described above can be implemented as macros. Scala/pickling provides an \nimplicit macro def returning picklers for arbitrary types. Slightly simplified, it is declared as follows: \nimplicit def genPickler[T]: SPickler[T] This macro def is expanded when invoking implicitly[SPickler[T]] \nif there is no implicit value of type SPickler[T] in scope. Custom Picklers. It is possible to use manually \nwritten picklers in place of generated picklers. Typical motivations for doing so are (a) improved performance \nthrough special\u00adization and optimization hints, and (b) custom pre-pickling and post-unpickling actions; \nsuch actions may be required to re-initialize an object correctly after unpickling. Creating custom picklers \nis greatly facilitated by modular composi\u00adtion using object-oriented pickler combinators. The design \nof these first-class object-oriented picklers and pickler com\u00adbinators is discussed in detail in the \nfollowing Section 3.  3. Object-Oriented Picklers In the first part of this section (3.1) we introduce \npicklers as first-class objects, and, using examples, motivate the con\u00adtracts that valid implementations \nmust guarantee. We demon\u00adstrate that the introduced picklers enable modular, object\u00adoriented pickler \ncombinators, i.e., methods for composing more complex picklers from simpler primitive picklers. In the \nsecond part of this section (3.2) we present a formal\u00adization of object-oriented picklers based on an \noperational semantics. 3.1 Picklers in Scala In scala/pickling, a static pickler for some type T is \nan instance of trait SPickler[T] which has a single abstract method, pickle: trait SPickler[T] { def \npickle(obj: T, builder: PBuilder): Unit } For a concrete type, say, class Person from Section 2, the \npickle method of an SPickler[Person] converts Person in\u00adstances to a pickled format, using a pickle builder \n(the builder parameter). Given this definition, picklers are type safe in the sense that a type-specialized \npickler can be applied only to values of the specialized type [10]. The pickled re\u00adsult is not returned \ndirectly; instead, it can be requested from the builder using its result() method. Example: val p = new \nPerson(\"Jack\") ... val personPickler = implicitly[SPickler[Person]] val builder = pickleFormat.createBuilder() \n personPickler.pickle(p, builder) val pickled: Pickle = builder.result()  In the above example, invoking \nimplicitly[SPickler[Person]] either returns a regular implicit value of type SPickler[Person] that is \nin scope, or, if it doesn t exist, triggers the (compile\u00adtime) generation of a type-specialized pickler \n(see Section 4). To use the pickler, it is also necessary to obtain a pickle builder of type PBuilder. \nSince pickle formats in scala/pick\u00adling are exchangeable (see Section 4.3.1), the pickle builder is provided \nby the specific pickle format, through builder factory methods. Thepickled result has type Pickle which \nwraps a concrete representation, such as a byte array (e.g., for binary formats) or a string (e.g., for \nJSON). The abstract Pickle trait is de\u00adfined as follows: trait Pickle { type ValueType type PickleFormatType \n<: PickleFormat val value: ValueType  ... } The type members ValueType and PickleFormatType abstract \nfrom the concrete representation type and the pickle for\u00admat type, respectively. For example, scala/pickling \ndefines a Pickle subclass for its default binary format as follows: case class BinaryPickle(value: Array[Byte]) \nextends Pickle { type ValueType = Array[Byte] type PickleFormatType = BinaryPickleFormat  override \ndef toString = ... } Analogous to a pickler, an unpickler for some type T is an instance of trait Unpickler[T] \nthat has a single abstract method unpickle; its (simplified) definition is as follows: trait Unpickler[T] \n{ def unpickle(reader: PReader): T } Similar to a pickler, an unpickler does not access pickled objects \ndirectly, but through the PReader interface, which is analogous to the PBuilder interface. A PReader \nis set up to read from a pickled object as follows. First, we need to obtain an instance of the pickle \nformat that was used to produce the pickled object; this format is either known beforehand, or it can \nbe selected using the PickleFormatType member of Pickle. The pickle format, in turn, has factory methods \nfor creating concrete PReader instances: val reader = pickleFormat.createReader(pickled) The obtained \nreader can then be passed to the unpickle method of a suitable Unpickler[T].Alternatively, a macro def \non trait Pickle can be invoked directly for unpickling: trait Pickle { ... def unpickle[T] = macro \n... } It is very common for an instance of SPickler[T] to also mix in Unpickler[T], thereby providing \nboth pickling and unpickling capabilities. 3.1.1 Pickling and Subtyping So far, we have introduced the \ntrait SPickler[T] to repre\u00adsent picklers that can pickle objects of type T. However, in the presence \nof subtyping and open class hierarchies provid\u00ading correct implementations of SPickler[T] is quite challeng\u00ading. \nFor example, how can an SPickler[Person] know how to pickle an arbitrary, unknown subclass of Person? \nRegard\u00adless of implementation challenges, picklers that handle arbi\u00adtrary subclasses are likely less \nefficient than more specialized picklers. To provide flexibility while enabling optimization op\u00adportunities, \nscala/pickling introduces two different traits for picklers: the introduced trait SPickler[T] is called \na static pickler; it does not have to support pickling of subclasses of T. In addition, the trait DPickler[T] \nis called a dynamic pick\u00adler; its contract requires that it is applicable also to subtypes of T. The \nfollowing section motivates the need for dynamic picklers, and shows how the introduced concepts enable \na flexible, object-oriented form of pickler combinators. 3.1.2 Modular Pickler Combinators This section \nexplores the composition of the pickler abstrac\u00adtions introduced in the previous section by means of \nan ex\u00adample. Consider a simple class Position with a field of type String and a field of type Person, \nrespectively: class Position(val title: String, val person: Person) To obtain a pickler for objects \nof type Position, ideally, existing picklers for type String and for type Person could be combined in \nsome way. However, note that the person field of a given instance of class Position could point to an \ninstance of a subclass of Person (assuming class Person is not final). Therefore, a modularly re-usable \npickler for type Person must be able to pickle all possible subtypes of Person. In this case, the contract \nof static picklers is too strict, it does not allow for subtyping. The contract of dynamic pick\u00adlers \non the other hand does allow for subtyping. As a result, dynamic picklers are necessary so as to enable \nmodular com\u00adposition in the presence of subtyping. Picklers for final class types like String, or for \nprimitive types like Int do not require support for subtyping. There\u00adfore, static picklers are sufficient \nto pickle these effectively final types. Compared to dynamic picklers, static picklers benefit from several \noptimizations.  3.1.3 Implementing Object-Oriented Picklers The main challenge when implementing OO \npicklers comes from the fact that a dynamic pickler for type T must be able to pickle objects of any \nsubtype of T. Thus, the implementation of a dynamic pickler for type T must, in general, dynamically \ndispatch on the runtime type of the object to-be-pickled to take into account all possible subtypes of \nT. Because of this dynamic dispatch, manually constructing dynamic picklers can be difficult. It is therefore \nimportant for a framework for object-oriented picklers to provide good support for realizing this form \nof dynamic dispatching. There are various ways across many different object\u00adoriented programming languages \nto handle subtypes of the pickler s static type: Data structures with shallow class hierarchies, such \nas lists or trees, often have few final leaf classes. As a result, manual dispatch code is typically \nsimple in such cases. For example, a manual pickler for Scala s List class does not even have to consider \nsubclasses.  Java-style runtime reflection can be used to provide a genericDPickler[Any] which supports \npickling objects of any type [25, 27]. Such a pickler can be used as a fallback to handle subtypes that \nare unknown to the pickling code; such subtypes must be handled in the presence of separate compilation. \nIn Section 4.4 we present Scala implemen\u00adtations of such a generic pickler.  Java-style annotation processing \nis commonly used to trigger the generation of additional methods in annotated class types. The purpose \nof generated methods for pick\u00adling would be to return a pickler or unpickler specialized for an annotated \nclass type. In C#, the Roslyn Project [22] allows augmenting class definitions based on the pres\u00adence \nof annotations.  Static meta programming [5, 34] enables generation of picklers at compile time. In \nSection 4 we present an ap\u00adproach for generating object-oriented picklers from regu\u00adlar (class) type \ndefinitions.  3.1.4 Supporting Unanticipated Evolution Given the fact that the type SPickler[T], as \nintroduced, has a type parameter T, it is reasonable to ask what the variance of T is. Ruling out covariance \nbecause of T s occurrence in a contravariant position as the type of a method parameter, it remains to \ndetermine whether T can be contravariant. For this, it is useful to consider the following scenario. \nAssumeT is declared to be contravariant, as in SPickler[-T]. Furthermore, assume the existence of a public, \nnon-final class C with a subclass D: class C {...} class D extends C {...} Initially, we might define \na generic pickler for C:  implicit val picklerC = new SPickler[C] { def pickle(obj: C): Pickle = { ... \n} } Because SPickler[T ] is contravariant in its type param\u00adeter, instances of D would be pickled using \npicklerC. There are several possible extensions that might be unanticipated initially: Because the implementation \ndetails of class D change, instances of D should be pickled using a dedicated pickler instead of picklerC. \n A subclass E of C is added which requires a dedicated pickler, since picklerC does not know how to \ninstantiate class E (since class E did not exist when picklerC was written).  In both cases it is necessary \nto add a new, dedicated pickler for either an existing subclass (D) or a new subclass (E) of C: implicit \nval picklerD = new SPickler[D] { ... } However, when pickling an instance of class D this new pickler, \npicklerD, would not get selected, even if the type of the object to-be-pickled is statically known to \nbe D. The reason is that SPickler[C] <: SPickler[D] because of con\u00adtravariance which means that picklerC \nis more specific than picklerD. As a result, according to Scala s implicit look-up rules picklerC is \nselected when an implicit object of type SPickler[D] is required. (Note that this is the case even if \npicklerD is declared in a scope that has higher precedence than the scope in which picklerC is declared.) \nWhile contravariant picklers do not support the two sce\u00adnarios for unanticipated extension outlined above, \ninvariant picklers do, in combination with type bounds. Assuming in\u00advariant picklers, we can define a \ngeneric method picklerC1 that returns picklers for all subtypes of class C: implicit def picklerC1[T \n<: C] = new SPickler[T] { def pickle(obj: T): Pickle = { ... } } With this pickler in scope, it is \nstill possible to define a more specific SPickler[D] (or SPickler[E]) as required: implicit val picklerD1 \n= new SPickler[D] { ... } However, the crucial difference is that now picklerD1 is selected when an \nobject of static type D is pickled, since picklerD1 is more specific than picklerC1. In summary, the \ncombination of invariant picklers and generics (with upper type bounds) is flexible enough to sup\u00adport \nsome important scenarios of unanticipated evolution. This is not possible with picklers that are contravariant. \nCon\u00adsequently, in scala/pickling the SPickler trait is invariant in its type parameter.  3.2 Formalization \nTo define picklers formally we use a standard approach based on an operational semantics for a core object-oriented \nlan- P ::= cdef t program cdef ::= class C extends D {f ld meth} class f ld ::= var f : C field meth \n::= def m(x : C) : D = e method t ::= let x = e in t let binding | x.f := y assignment | x variable e \n::= new C(x) instance creation | x.f selection | x.m(y) invocation | t term Figure 1: Core language \nsyntax. C, D are class names, f, m are .eld and method names, and x, y are names of variables and parameters, \nrespectively. H ::= \u00d8 | (H, r .-v) heap V ::= \u00d8 | (V, y .-r) environment (y =/dom(V )) v ::= o | p value \no ::= C(r) object p ::= (Cp, m, C ) pickler r = Ref Locs reference location Figure 2: Heaps, environments, \nobjects, and picklers. guage. Importantly, our goal is not a full formalization of a core language; \ninstead, we (only) aim to provide a pre\u00adcise definition of object-oriented picklers. Thus, our core language \nsimplifies our actual implementation language in several ways. Since our basic definitions are orthogonal \nto the type system of the host language, we limit types to non\u00adgeneric classes with at most one superclass. \nMoreover, the core language does not have first-class functions, or features like pattern matching. The \ncore language without picklers is a simplified version of a core language used in the formal development \nof a uniqueness type system for Scala [14]. Figure 1 shows the core language syntax. A program is a sequence \nof class definitions followed by a (main) term. (We use the common over-bar notation [16] for sequences.) \nWithout loss of generality, we use a form where all interme\u00addiate terms are named (A-normal form [11]). \nThe language does not support arbitrary mutable variables (cf. [28], Chap\u00adter 13); instead, only fields \nof objects can be (re-)assigned. We assume the existence of two pre-defined class types, AnyRef and Pickle. \nAll class hierarchies have AnyRef as their root. For the purpose of our core language, AnyRef is simply \na member-less class without a superclass. Pickle is the class type of objects that are the result of \npickling a regular object. We define the standard auxiliary functions mtype and mbody as follows. Let \ndef m(x : C) : D = e be a method defined in the most direct superclass of C that defines m. Then mbody(m, \nC ) = (x, e) and mtype(m, C ) = C -D. V (x) = rp H(rp) = (Cp, s, C ) V (x) = rp H(rp) = (Cp, d, C ) \nV (y) = r H(r) = C(_) V (y) = r H(r) = D(_) D <: C mbody(p, Cp) = (z, e) mbody(p, Cp) = (z, e) (R-Pickle-S) \n(R-Pickle-D) ' ' H, V, let x = x.p(y) in t H, V , let x = x.p(y) in t ' ' --H, (V , z .-r), let x = e \nin t --H, (V, z .-r), let x = e in t V (x) = r H(r) = C(_) V (y) = r1 . . . rn mbody(m, C ) = (x, e) \n (R-Invoke) ' H, V, let x = x.m(y) in t ' --H, (V , x .-r), let x = e in t Figure 3: Reduction rules \nfor pickling. 3.2.1 Dynamic semantics We use a small-step operational semantics to formalize the dynamic \nsemantics of our core language. Reduction rules are written in the form H, V , t --H ' , V ' , t ' . \nThat is, terms t are reduced in the context of a heap H and a variable environ\u00admentV .Figure 2 shows \ntheir syntax. A heap maps reference locations to values. In our core language, values can be ei\u00adther \nobjects or picklers. An object C(r) stores location ri in its i-th field. An environment maps variables \nto reference lo\u00adcations r. Note that we do not model explicit stack frames. Instead, method invocations \nare flattened by renaming the method parameters before binding them to their argument values in the environment \n(as in LJ [35]). A pickler is a tuple (Cp, m, C ) where Cp is a class that defines two methods p and \nu for pickling and unpickling an object of type C, respectively, where mtype(p, Cp) = C -Pickle and mtype(u, \nCp) = Pickle -C. The second component m = {s, d} is the pickler s mode; the operational semantics below \nexplains how the mode affects the applicability of a pickler in the presence of subtyping. As defined, \npicklers are first-class, since they are values just like objects. However, while picklers are regular \nobjects in our practical implementation, picklers are different from objects in the present formal model. \nThe reason is that a pick\u00adler has to contain a type tag indicating the types of objects that it can pickle \n(this is apparent in the rules of the operational semantics below); however, the alternative of adding \nparam\u00adeterized types (as in, e.g., FGJ [16]) is beyond the scope of the present paper. According to the \ngrammar in Figure 1, expressions are al\u00adways reduced in the context of a let-binding, except for field \nassignments. Each operand of an expression is a variable y that the environment maps to a reference location \nr.Since the environment is a .at list of variable bindings, let-bound vari\u00ad ' ables must be alpha-renamable: \nlet x = e in t = let x = ' e in [x ' /x]t where x =/F V (t). (We omit the definition of the F V function \nto obtain the free variables of a term, as it is standard [28].) In the following we explain the subset \nof the reduction rules suitable to formalize the properties of picklers. We start with the reduction \nrule for method invocations, since the reduction rules pertinent to picklers are variants of that rule. \nFigure 3 shows the reduction rules for pickling and un\u00adpickling an object. Rule (R-Pickle-S) is a refinement \nof rule (R-Invoke) for method invocations. When using a pickler x to pickle an object y such that the \npickler s mode is s (static), the type tag C of the pickler indicating the type of objects that it can \npickle must be equal to the dynamic class type of the object to-be-pickled (the object at location r). \nThis expresses the fact that a static pickler can only be applied to objects of a precise statically-known \ntype C, but not a subtype thereof. In contrast, rule (R-Pickle-D) shows the invocation of the pickling \nmethod p for a pickler with mode d (dynamic). In this case, the type tag C of the pickler must not be \nexactly equal to the dynamic type of the object to-be-pickled (the object at location r); it is only \nnecessary that D <: C. Property. The pickling and unpickling methods of a pick\u00adler must satisfy the property \nthat pickling followed by un\u00adpickling generates an object that is structurally equal to the original \nobject . The following definition captures this for\u00admally: ' Definition 3.1. Given variables x, x , y, \ny ', heaps H, H ', variable environments V, V ', and a term t such that V (y) = r H(r) = C(r) V (x) = \nrp H(rp) = (Cp, m, D) { D = C if m = s D <: C if m = d ' V ' (y ' ) = r and ' H, V, let x = x.u(x.p(y)) \nin t * '' --H ' , V ' , let x = y in t Thenr andr ' must be structurally equivalent in heap ' H ', written \nr =H' r .  Note that in the above definition we assume that refer\u00ad ' ences in heap H are not garbage \ncollected in heap H . The definition of structural equivalence is straight-forward. Definition 3.2. (Structural \nEquivalence) ' Two picklers rp, r are structurally equal in heap H, p ' written rp = H r iff p ' H(rp) \n= (Cp, m, C ) 1 H(r ) = (C ' , m ' , C ' ) = p p ' 1 C ' m = m ' 1 C <: C <: C (1) Two reference locations \nr, r ' are structurally equal in ' heap H, written r = H r iff H(r) = C(r) 1 H(r ' ) = C ' (p) = (2) \n' C <: C ' 1 C <: C 1 .ri = r, pi = p. ri = H pi Note that the above definition considers two picklers \nto be structurally equal even if their implementation classes Cp andC ' are different. In some sense, \nthis is consistent with our p practical implementation in the common case where picklers are only resolved \nusing implicits: Scala s implicit resolution enforces that an implicit pickler of a given type is uniquely \ndetermined.  3.3 Summary This section has introduced an object-oriented model of first\u00adclass picklers. \nObject-oriented picklers enable modular pick\u00adler combinators with support for subtyping, thereby extend\u00ading \na well-known approach in functional programming. The distinction between static and dynamic picklers \nenables op\u00adtimizations for final class types and primitive types. Object\u00adoriented picklers can be implemented \nusing various tech\u00adniques, such as manually written picklers, runtime reflection, or Java-style annotation \nprocessors. We argue that object\u00adoriented picklers should be invariant in their generic type pa\u00adrameter \nto allow for several scenarios of unanticipated evo\u00adlution. Finally, we provide a formalization of a \nsimple form of OO picklers.  4. Generating Object-Oriented Picklers An explicit goal of our framework \nis to require little to no boilerplate in client code, since practitioners are typically ac\u00adcustomed \nto serialization supported by the underlying run\u00adtime environment like in Java or .NET. Therefore, instead \nof requiring libraries or applications to supply manually written picklers for all pickled types, our \nframework provides a com\u00adponent for generating picklers based on their required static type. Importantly, \ncompile-time pickler generation enables ef\u00adficient picklers by generating as much pickling code as pos\u00adsible \nstatically (which corresponds to a partial evaluation of pickler combinators). Section 6 reports on the \nperformance improvements that our framework achieves using compile\u00adtime pickler generation, compared \nto picklers based on run\u00adtime reflection, as well as manually written picklers. 4.1 Overview Our framework \ngenerates type-specialized, object-oriented picklers using compile-time meta programming in the form \nof macros. Whenever a pickler for static type T is required but cannot be found in the implicit scope, \na macro is ex\u00adpanded which generates the required pickler step-by-step by: Obtaining a type descriptor \nfor the static type of the object to-be-pickled,  Building a static intermediate representation of the \nobject\u00adto-be-pickled, based on the type descriptor, and  Applying a pickler generation algorithm, driven \nby the static pickler representation.  In our Scala-based implementation, the static type de\u00adscriptor \nis generated automatically by the compiler, and passed as an implicit argument to the pickle extension \nmethod (see Section 2). As a result, such an implicit TypeTag1 does not require changing the invocation \nin most cases. (How\u00adever, it is impossible to generate a TypeTag automatically if the type or one of \nits components is abstract; in this case, an implicit TypeTag must be in scope.) Based on the type descriptor, \na static representation, or model, of the required pickler is built; we refer to this as the Intermediate \nRepresentation (IR). The IR specifies precisely the set of types for which our framework can generate \npick\u00adlers automatically. Furthermore, these IRs are composable. We additionally define a model for composing \nIRs, which is designed to capture the essence of Scala s object system as it relates to pickling. The \nmodel defines how the IR for a given type is composed from the IRs of the picklers of its supertypes. \nIn Scala, the composition of an IR for a class type is defined based on the linearization of its supertraits.2 \nThis model of inheritance is central to the generation framework, and is formally defined in the following \nSection 4.2 4.2 Model of Inheritance The goal of this section is to define the IR, which we ll denote \nY, of a static type T as it is used to generate a pickler for type T . We start by defining the syntax \nof the elements of the IR (see Def. 4.1). 1 TypeTags are part of the mainline Scala compiler since version \n2.10. They replace the earlier concept of Manifests, providing a faithful representation of Scala types \nat runtime. 2 Traits in Scala can be thought of as a more flexible form of Java-style interfaces that \nallow concrete members, and that support a form of multiple inheritance (mix-in composition) that is \nguaranteed to be safe based on a linearization order. Definition 4.1. (Elements of IR) We define the \nsyntax of values of the IR types. F ::= (fn, T ) Y ::= (T , Yopt, F ) Yopt ::= . | Y F represents a sequence \nof fields. We write X as shorthand for sequences, X1, . . . , Xn, and we write tu\u00adples(X1, . . . , Xn).fn \nis a string representing the name of the given field, and T is its type. Y represents the pickling information \nfor a class or some other object type. That is, an Y for type T contains all of the information required \nto pickle instances of type T , including all necessary static info for pickling its fields provided \nby F . Yopt is an optional Y; a missing Y is represented using .. In our implementation the IR types \nare represented using case classes. For example, the following case class represents Ys: case class ClassIR( \ntpe: Type, parent: ClassIR, fields: List[FieldIR] ) extends PickleIR We go on to define a number of \nuseful IR combinators, which form the basis of our model of inheritance. Definition 4.2. (IR Combinators \n-Type Definitions) We begin by defining the types of our combinators before we define the combinators \nthemselves. Type Definitions concat : (F, F ) * F extended : (T, T) * T linearization : T * T superIRs \n: T * T compose : T * T flatten : T * T We write function types X = Y , indicating a func\u00adtion from type \nX to type Y . The linearization function represents the host lan\u00adguage s semantics for the linearized \nchain of super\u00adtypes.3 3 For example, in Scala the linearization is defined for classes mixing in multiple \ntraits [23, 24]; in Java, the linearization function would simply return the chain of superclasses, not \nincluding the implemented interfaces. Definition 4.3. (IR Combinators -Function Defns)  Function Definitions \nconcat(f, g) = f, g extended(C, D) = (T , C, fields(T )) where D = (T , _, _) . T <: C.1 superIRs(T ) \n= [(S, ., fields(S)) | S E linearization(T )] compose(C) = reduce(superIRs(C.1), extended) {(C.1, C.2, \nconcat(C.3, flatten(C.2).3)), flatten(C) =if C.2 =.. C, otherwise The function concat takes two sequences \nas argu\u00adments. We denote concatenation of sequences using a comma. We introduce the concat function for \nclarity in the definition of flatten (see below); it is simply an alias for sequence concatenation. The \nfunction extended takes two Ys, C and D, and returns a new Y for the type of D such that C is regis\u00adtered \nas its super Y. Basically, extended is used to com\u00adbine a completed Y C with an incomplete Y D yielding \na completed Y for the same type as D. When combin\u00ading the Ys of a type s supertypes, the extended function \nis used for reducing the linearization sequence yielding a single completed Y. The function superIRs \ntakes a type T and returns a sequence of the IRs of T s supertypes in linearization order. The function \ncompose takes an Y C for a type C.1 and returns a new Y for type C.1 which is the compo\u00adsition of the \nIRs of all supertypes of C.1. The resulting Y is a chain of super IRs according to the linearization \norder of C.1. The function flatten, given an Y C produces a new Y that contains a concatenation of all \nthe fields of each nested Y. Given these combinators, the Y of a type T to-be-pickled is obtained using \nY = f latten(compose((T , ., [])). The above IR combinators have direct Scala implementa\u00adtions in scala/pickling. \nFor example, function superI Rs is implemented as follows: private val f3 = (c: C) => c.tpe.baseClasses \n.map(superSym => c.tpe.baseType(superSym)) .map(tp => ClassIR(tp, null, fields(tp)))  Here, method baseClasses \nreturns the collection of super\u00adclass symbols of type c.tpe in linearization order. Method baseType converts \neach symbol to a type which is, in turn, used to create a ClassIR instance. The semantics of the fields \nmethod is analogous to the above f ields function.  4.3 Pickler Generation Algorithm The pickler generation \nis driven by the IR (see Section 4.2) of a type to-be-pickled. We describe the generation algorithm in \ntwo steps. In the first step, we explain how to generate a pickler for static type T assuming that for \nthe dynamic type S of the object to-be-pickled, erasure(T ) =:= S. In the second step, we explain how \nto extend the generation to dynamic picklers which do not require this assumption. 4.3.1 Pickle Format \nThe pickling logic that we are going to generate contains calls to a pickle builder that is used to incrementally \nconstruct a pickle. Analogously, the unpickling logic contains calls to a pickle reader that is used \nto incrementally read a pickle. Importantly, the pickle format that determines the precise persisted \nrepresentation of a completed pickle is not fixed. Instead, the pickle format to be used is selected \nat compile time efficient binary formats, and JSON are just some ex\u00adamples. This selection is done via \nimplicit parameters which allows the format to be flexibly selected while providing a default binary \nformat which is used in case no other format is imported explicitly. The pickle format provides an interface \nwhich plays the role of a simple, lower-level backend . Besides a pickle template that is generated inline \nas part of the pickling logic, methods provided by pickle builders aim to do as little as possible to \nminimize runtime overhead. For example, the JSONPickleFormat included with scala/pickling simply uses \nan efficient string builder to concatenate JSON fragments (which are just strings) in order to assemble \na pickle. The interface provided by PickleFormat is simple: it ba\u00adsically consists of two methods (a) \nfor creating an empty builder, and (b) for creating a reader from a pickle:3 def createBuilder(): PBuilder \n def createReader(pickle: PickleType): PReader The createReader method takes a pickle of a specific \nPickleType (which is an abstract type member in our imple\u00admentation); this makes it possible to ensure \nthat, say, a pickle encapsulating a byte array is not erroneously attempted to be unpickled using the \nJSON pickle format. Moreover, pickle builders returned from createBuilder are guaranteed to pro\u00adduce \npickles of the right type. class PBuilder { def beginEntry(obj: Any): PBuilder def putField(n: String, \npfun: PBuilder => Unit): PBuilder def endEntry(): Unit def result(): Pickle } In the following we \nre going to show how the PBuilder interface is used by generated picklers; the PReader interface 3 In \nour actual implementation the createReader method takes an additional parameter which is a mirror used \nfor runtime reflection; it is omitted here for simplicity. is used by generated unpicklers in an analogous \nway. The above example summarizes a core subset of the interface of PBuilder that the presented generation \nalgorithm is going to use.4 The beginEntry method is used to indicate the start of a pickle for the argument \nobj. The field values of a class in\u00adstance are pickled using putField which expects both a field name \nand a lambda encapsulating the pickling logic for the object that the field points to. The endEntry method \nindicates the completion of a (partial) pickle of an object. Finally, in\u00advoking result returns the completed \nPickle instance. 4.3.2 Tree Generation The objective of the generation algorithm is to generate the \nbody of SPickler s pickle method: def pickle(obj: T, builder: PBuilder): Unit = ...  As mentioned previously, \nthe actual pickling logic is syn\u00adthesized based on the IR. Importantly, the IR determines which fields \nare pickled and how. A lot of the work is al\u00adready done when building the IR; therefore, the actual tree \ngeneration is rather simple: Emit builder.beginEntry(obj). For each field fld in the IR, emit builder.putField(${fld.name},b \n=> pbody) where ${fld.name} denotes the splicing of fld.name into the tree. pbody is the logic for pickling \nfld s value into the builder b, which is an alias of builder. pbody is generated as follows: 1. Emit \nthe field getter logic: val v: ${fld.tpe} = obj.${fld.name}.The expression ${fld.tpe} splices the type \nof fld into the generated tree; ${fld.name} splices the name of fld into the tree. 2. Recursively generate \nthe pickler for fld s type by emitting either val fldp = implicitly[DPickler[${fld.tpe}]] or val fldp \n= implicitly[SPickler[${fld.tpe}]], de\u00adpending on whether fld s type is effectively final or not. 3. \nEmit the logic for pickling v intob:fldp.pickle(v, b)  A practical implementation can easily be refined \nto sup\u00adport various extensions of this basic model. For example, support for avoiding pickling fields \nmarked as transient is easy with this model of generation such fields can simply be left out of the IR. \nOr, based on the static types of the pick\u00adlee and its fields, we can emit hints to the builder to enable \nvarious optimizations. For example, a field whose type T is effectively final, i.e., it cannot be extended, \ncan be optimized as follows: Instead of obtaining an implicit pickler of type DPickler[T], it is sufficient \nto obtain an implicit pickler of type SPickler[T], 4 It is not necessary that PBuilder is a class. In \nfact, in our Scala implemen\u00adtation it is a trait. In Java, it could be an interface. which is more efficient, \nsince it does not require a dy\u00adnamic dispatch step like DPickler[T] The field s type does not have to \nbe pickled, since it can be reconstructed from its owner s type. Pickler generation is compositional; \nfor example, the gen\u00aderated pickler for a class type with a field of type String re-uses the String pickler. \nThis is achieved by generating picklers for parts of an object type using invocations of the form implicitly[DPickler[T]]. \nThis means that if there is already an implicit value of type DPickler[T] in scope, it is used for pickling \nthe corresponding value. Since the lookup and binding of these implicit picklers is left to a mechanism \noutside of pickler generation, what s actually generated is a pickler combinator which returns a pickler \ncomposed of existing picklers for parts of the object to-be-pickled. More precisely, pickler generation \nprovides the following compos\u00adability property: Property 4.1. (Composability) A generated pickler p is \ncomposed of implicit picklers of the required types that are in scope at the point in the program where \np is generated. Since the picklers that are in scope at the point where a pickler is generated are under \nprogrammer control, it is pos\u00adsible to import manually written picklers which are trans\u00adparently picked \nup by the generated pickler. Our approach thus has the attractive property that it is an open-world ap\u00adproach, \nin which it is easy to add new custom picklers for selected types at exactly the desired places while \nintegrating cleanly with generated picklers.  4.3.3 Dispatch Generation So far, we have explained the \ngeneration of the pickling logic of static picklers. Dynamic picklers require an additional dispatch \nstep to make sure subtypes of the static type to-be\u00adpickled are pickled properly. The generation of a \nDPickler[T] is triggered by invoking implicitly[DPickler[T]] which tries to find an implicit of type \nDPickler[T] in the current implicit scope. Either there is already an implicit value of the right type \nin scope, or the only matching implicit is an implicit def provided by the pickling framework which gen\u00aderates \na DPickler[T] on-the-fly. The generated dispatch logic has the following shape: val clazz = if (picklee \n!= null) picklee.getClass else null val pickler = clazz match { case null => implicitly[SPickler[NullTpe]] \n case c1 if c1 == classOf[S1] => implicitly[SPickler[S1]] ... case cn if cn == classOf[Sn] => implicitly[SPickler[Sn]] \n case _ => genPickler(clazz) }  The types S1, . . . , Sn are known subtypes of the picklee s typeT .IfT \nis a sealed class or trait with final subclasses, this set of types is always known at compile time. \nHowever, in the presence of separate compilation it is, generally, possible that a picklee has an unknown \nruntime type; therefore, we include a default case (the last case in the pattern match) which dispatches \nto a runtime pickler that inspects the picklee using (runtime) reflection. If the static type T to be \npickled is annotated using the @pickleable annotation, all subclasses are guaranteed to ex\u00adtend the predefined \nPickleableBase interface trait. Conse\u00adquently, a more optimal dispatch can be generated in this case: \nval pickler = if (picklee != null) { val pbase = picklee.asInstanceOf[PickleableBase] pbase.pickler.asInstanceOf[SPickler[T]] \n } else implicitly[SPickler[NullTpe]]   4.4 Runtime Picklers One goal of our framework is to generate \nas much pickling code at compile time as possible. However, due to the in\u00adterplay of subclassing with \nboth separate compilation and generics, we provide a runtime fall back capability to han\u00addle the cases \nthat cannot be resolved at compile time. Subclassing and separate compilation A situation arises where \nit s impossible to statically know all possible sub\u00adclasses. In this case there are three options: (1) \nprovide a cus\u00adtom pickler, and (2) use an annotation which is described in Section 2.2. In the case where \nneither a custom pickler nor an annotation is provided, our framework can inspect the in\u00adstance to-be-pickled \nat runtime to obtain the pickling logic. This comes with some runtime overhead, but in Section 6 we present \nresults which suggest that this overhead is not neces\u00adsary in many cases. For the generation of runtime \npicklers our framework supports two possible strategies: Runtime interpretation of a type-specialized \npickler  Runtime compilation of a type-specialized pickler  Interpreted runtime picklers. If the runtime \ntype of an ob\u00adject is unknown at compile time, e.g., if its static type is Any, it is necessary to carry \nout the pickling based on inspecting the type of the object to-be-pickled at runtime. We call pick\u00adlers \noperating in this mode interpreted runtime picklers to emphasize the fact that the pickling code is not \npartially eval\u00aduated in this case. An interpreted pickler is created based on the runtime class of the \npicklee. From that runtime class, it is possible to obtain a runtime type descriptor: to build a static \nintermediate representation of the type (which describes all its fields with their types, etc.)  to \ndetermine in which way the picklee should be pickled (as a primitive or not). In case the picklee is \nof a primitive type, there are no fields to be pickled. Otherwise, the value and runtime type of each \nfield is obtained, so that it can be written to the pickle.  4.5 Generics and Arrays Subclassing and \ngenerics. The combination of subclass\u00ading and generics poses a similar problem to that introduced above \nin Section 4.4. For example, consider a generic class C, class C[T](val fld: T) { ... } A Pickler[C[T]] \nwill not be able to pickle the field fld if its static type is unknown. To support pickling instances \nof generic classes, our framework falls back to using runtime picklers for pickling fields of generic \ntype. So, when we have access to the runtime type of field fld, we can either look up an already-generated \npickler for that runtime type, or we can generate a suitable pickler dynamically. Arrays. Scala arrays \nare mapped to Java arrays; the two have the same runtime representation. However, there is one important \ndifference: Java arrays are covariant whereas Scala arrays are invariant. In particular, it is possible \nto pass arrays from Java code to Scala code. Thus, a class C with a field f of type Array[T] may have \nan instance at runtime that stores an Array[S] in field f where S is a subtype of T. Pickling fol\u00adlowed \nby unpickling must instantiate an Array[S]. Just like with other fields of non-final reference type, \nthis situation re\u00adquires writing the dynamic (array) type name to the pickle. This is possible, since \narray types are not erased on the JVM (unlike generic types). This allows instantiating an array with \nthe expected dynamic type upon unpickling. At the time of writing only support for primitive arrays has \nbeen imple\u00admented in scala/pickling.  4.6 Object Identity and Sharing Object identity enables the existence \nof complex object graphs, which themselves are a cornerstone of object-oriented programming. While in \nSection 6.7 we show that pickling flat object graphs is most common in big data applications, a general \npickling framework for use with an object-oriented language must not only support flat object graphs, \nit must also support cyclic object graphs. Supporting such cyclic object graphs in most object\u00adoriented \nlanguages, however, typically requires sophisticated runtime support, which is known to incur a significant \nper\u00adformance hit. This is due to the fact that pickling graphs with cycles requires tracking object identities \nat runtime, so that pickling terminates and unpickling can faithfully reconstruct the graph structure. \nTo avoid the overhead of tracking object identities unani\u00admously for all objects, runtime-based serialization \nframe\u00adworks like Java or Kryo have to employ reflective/introspec\u00adtive checks to detect whether identities \nare relevant.5 Scala/pickling, on the other hand, employs a hybrid compile-time/runtime approach. This \nmakes it possible to avoid the overhead of object identity tracking in cases where it is statically known \nto be safe, which we show in Section 6.7 is typically common in big data applications. The following \nSection 4.6.1 outlines how object identity is tracked in scala/pickling. It also explains how the man\u00adagement \nof object identities enables a sharing optimization. This sharing optimization is especially important \nfor persis\u00adtent data structures, which are commonly used in Scala. Sec\u00adtion 4.6.2 explains how compile-time \nanalysis is used to re\u00adduce the amount of runtime checking in cases where object graphs are statically \nknown to be acyclic. 4.6.1 Object Tracking During pickling, a pickler keeps track of all objects that \nare part of the (top-level) object to-be-pickled in a table. When\u00adever an object that s part of the object \ngraph is pickled, a hash code based on the identity of the object is computed. The pickler then looks \nup whether that object has already been pickled, in which case the table contains a unique integer ID \nas the entry s value. If the table does not contain an entry for the object, a unique ID is generated \nand inserted, and the object is pickled as usual. Otherwise, instead of pickling the object again, a \nspecial Ref object containing the integer ID is written to the pickle.6 During unpickling, the above \nprocess is reversed by maintaining a mapping7 from integer IDs to unpickled heap objects. This approach \nto dealing with object identities also en\u00adables sharing, an optimization which in some big data appli\u00adcations \ncan improve system throughput by reducing pickle size. Scala s immutable collections hierarchy is one \nexample of a set of data structures which are persistent, which means they make use of sharing. That \nis, object subgraphs which occur in multiple instances of a data structure can be shared which is more \nefficient than maintaining multiple copies of those subgraphs. Scala/pickling s management of object \nidentities benefits instances of such data structures as follows. First, it reduces the size of the computed \npickle, since instead of pickling the same object instance many times, compact references (Ref objects) \nare pickled. Second, pickling time also has the potential to be reduced, since shared objects have to \nbe pickled only once. 5 With Kryo, some of this overhead can be avoided when using custom, handwritten \nserializers. 6 Several strategies exist to avoid preventing pickled objects from being garbage collected. \nCurrently, for each top-level object to-be-pickled, a new hash table is created. 7 This can be made \nvery efficient by using a map implementation which is more efficient for integer-valued keys, such as \na resizable array.  4.6.2 Static Object Graph Analysis When generating a pickler for a given type T, \nthe IR is ana\u00adlyzed to determine whether the graph of objects of type T may contain cycles. Both T and \nthe types of T s fields are examined using a breadth-first traversal. Certain types are immediately excluded \nfrom the traversal, since they cannot be part of a cycle. Examples are primitive types, like Double, \nas well as certain immutable reference types that are final, like String. However, the static inspection \nof the IR additionally allows scala/pickling to traverse sealed class hierarchies. For example, consider \nthis small class hierarchy: final class Position(p: Person, title: String) sealed class Person(name: \nString, age: Int) final class Firefighter(name: String, age: Int, salary: Int) extends Person(name, \nage) final class Teacher(name: String, age: Int, subject: String) extends Person(name, age) In this \ncase, upon generating the pickler for class Position, it is detected that no cycles are possible in the \nobject graphs of instances of type Position. While Position s p field has a reference type, it cannot \ninduce cycles, since Person is a sealed class that has only final subclasses; furthermore, Person and \nits subclasses have only fields of primitive type. In addition to this analysis, our framework allows \nusers to disable all identity tracking programmatically (by importing an implicit value), in case it \nis known that the graphs of (all) pickled objects are acyclic. While this switch can boost performance, \nit also disables opportunities for sharing (see above), and may thus lead to larger pickles .  5. Implementation \nThe presented framework has been fully implemented in Scala. The object-oriented pickler combinators \npresented in Section 3, including their implicit selection and composi\u00adtion, can be implemented using \nstable versions of the stan\u00addard, open-source Scala distribution. The extension of our basic model with \nautomatic pickler generation has been im\u00adplemented using the experimental macros feature introduced in \nScala 2.10.0. Macros can be thought of as a more regularly structured, localized, and more stable alternative \nto com\u00adpiler plugins. To simplify tree generation, our implementa\u00adtion leverages a quasiquoting library \nfor Scala s macros [33].  6. Experimental Evaluation In this section we present first results of an \nexperimental evaluation of our pickling framework. Our goals are 1. to evaluate the performance of automatically-generated \npicklers, analyzing the memory usage compared to other serialization frameworks, and 2. to provide a \nsurvey of the properties of data types that are commonly used in distributed computing frameworks and \napplications.  In the process, we are going to evaluate the performance of our framework alongside \ntwo popular and industrially\u00adprominent serialization frameworks for the JVM, Java s na\u00adtive serialization, \nand Kryo.8 6.1 Experimental Setup The following benchmarks were run on a MacBook Pro with a 2.6 GHz Intel \nCore i7 processor with 16 GB of memory running Mac OS X version 10.8.4 and Oracle s Java HotSpot(TM) \n64-Bit Server VM version 1.6.0_51. In all cases we used the following configuration flags: -XX:MaxPermSize=512m \n-XX:+CMSClassUnloadingEnabled -XX:ReservedCodeCacheSize=192m -XX:+UseConcMarkSweepGC -Xms512m -Xmx2g. \nEach benchmark was run on a warmed-up JVM. The result shown is the median of 9 such warm runs. 6.2 Microbenchmark: \nCollections In the first microbenchmark, we evaluate the performance of our framework when pickling standard \ncollection types. We compare against three other serialization frameworks: Java s native serialization, \nKryo, and a combinator library of naive handwritten pickler combinators. All benchmarks are compiled \nand run using a current milestone of Scala version 2.10.3. The benchmark logic is very simple: an immutable \ncol\u00adlection of type Vector[Int] is created which is first pick\u00adled (or serialized) to a byte array, and \nthen unpickled. While List is the prototypical collection type used in Scala, we ulti\u00admately chose Vector \nas Scala s standard List type could not be serialized out-of-the-box using Kryo,9 because it is a re\u00adcursive \ntype in Scala. In order to use Scala s standard List type with Kryo, one must write a custom serializer, \nwhich would sidestep the objective of this benchmark, which is to compare the speed of generated picklers. \nThe results are shown in Figure 4 (a). As can be seen, Java is slower than the other frameworks. This \nis likely due to the expensive runtime cost of the JVM s calculation of the runtime transitive closure \nof the objects to be serialized. For 1,000,000 elements, Java finishes in 495ms while scala/pick\u00adling \nfinishes in 74ms, or a factor 6.6 faster. As can be seen, the performance of our prototype is clearly \nfaster than Kryo for small to moderate-sized collections; even though it re\u00admains faster throughout this \nbenchmark, the gap between Kryo and scala/pickling shrinks for larger collections. For a Vector[Int] \nwith 100,000 elements, Kryo v2 finishes in 36ms while scala/pickling finishes in 10ms a factor of 3.6 \nin favor of scala/pickling. Conversely, for a Vector of 1,000,000 elements, Kryo finishes in 84ms whereas \nscala/pickling fin\u00adishes in 74ms. This result clearly demonstrates the benefit of 8 We select Kryo and \nJava because, like scala/pickling, they both are au\u00adtomatic . That is, they require no schema or extra \ncompilation phases, as is the case for other frameworks such as Apache Avro and Google s Protocol Buffers. \n9 We register each class with Kryo, an optional step that improves perfor\u00admance.  Figure 4: Results \nfor pickling and unpickling an immutable Vector[Int] using different frameworks. Figure 4(a) shows the \nroundtrip pickle/unpickle time as the size of the Vector varies. Figure 4(b) shows the amount of free \nmemory available during pickling/unpickling as the size of the Vector varies. Figure 4(c) shows the pickled \nsize of Vector. our hybrid compile-time/runtime approach: while scala/pick\u00adling has to incur the overhead \nof tracking object identity in the case of general object graphs, in this case, the compile\u00adtime pickler \ngeneration is able to detect that object identity does not have to be tracked for the pickled data types. \nMore\u00adover, it is possible to provide a size hint to the pickle builder, enabling the use of a fixed-size \narray as the target for the pickled data. We have found that those two optimizations, which require the \nkind of static checking that scala/pickling is able to do, can lead to significant performance improve\u00adments. \nThe performance of manually written pickler combi\u00adnators, however, is still considerably better. This \nis likely due to the fact that pickler combinators require no runtime checks whatsoever pickler combinators \nare defined per type, and manually composed, requiring no such check. In principle, it should be possible \nto generate code that is as fast as these pickler combinators in the case where static picklers can be \ngenerated. Figure 4 (b) shows the corresponding memory usage; on the y-axis the value of System.freeMemory \nis shown. This plot reveals evidence of a key property of Kryo, namely (a) that its memory usage is quite \nhigh compared to other frameworks, and (b) that its serialization is stateful because of internal buffering. \nIn fact, when preparing these benchmarks we had to manually adjust Kryo buffer sizes several times to \navoid buffer overflows. It turns out the main reason for this is that Kryo reuses buffers whenever possible \nwhen serializing one object after the other. In many cases, the newly pickled ob\u00adject is simply appended \nat the current position in the exist\u00ading buffer which results in unexpected buffer growth. Our framework \ndoes not do any buffering which makes its be\u00adhavior very predictable, but does not necessarily maximize \nits performance. Finally, Figure 4 (c) shows the relative sizes of the seri\u00adalized data. For a Vector[Int] \nof 1,000,000 elements, Java required 10,322,966 bytes. As can be seen, all other frame\u00adworks perform \non par with another, requiring about 40% of the size of Java s binary format. Or, in order of largest \nto smallest; Kryo v1 -4,201,152 bytes; Kryo v2 -4,088,570 bytes; scala/pickling 4,000,031 bytes; and \nPickler Combina\u00adtors 4,000,004 bytes. 6.3 Wikipedia: Cyclic Object Graphs In the second benchmark, we \nevaluate the performance of our framework when pickling object graphs with cycles. Using real data from \nthe Wikipedia project, the benchmark builds a graph where nodes are Wikipedia articles and edges are \nreferences between articles. In this benchmark we compare against Java s native serialization and Kryo. \nOur objective was to measure the full round-trip time (pickling and un\u00adpickling) for all frameworks. \nHowever, Kryo consistently crashed in the unpickling phase despite several work-around attempts. Thus, \nwe include the results of two experiments: (1) pickle only , and (2) pickle and unpickle . The results \nFigure 5: Results for pickling/unpickling a partition of Wikipedia, represented as a graph with many \ncycles. Figure 6(a) shows a pickling benchmark across scala/pickling, Kryo, and Java. In Figure 6(b), \nresults for a roundtrip pickling/unpickling is shown. Here, Kryo is removed because it crashes during \nunpickling.  Figure 6: Results for pickling/unpickling evactor datatypes (numerous tiny messages represented \nas case classes containing primitive fields.) Figure 6(a) shows a benchmark which pickles/unpickles up \nto 10,000 evactor messages. Java runs out of memory at this point. Figure 6(b) removes Java and scales \nup the benchmark to more evactor events. show that Java s native serialization performs particularly \nwell in this benchmark. In the pickle only benchmark of Figure 5 between 12000 and 14000 nodes, Java \ntakes only between 7ms and 10ms, whereas scala/pickling takes around 15ms. Kryo performs significantly \nworse, with a time be\u00adtween 22ms and 24ms. In the pickle and unpickle bench\u00admark of Figure 5, the gap \nbetween Java and scala/pickling is similar to the pickle only case: Java takes between 15ms and 18ms, \nwhereas scala/pickling takes between 25ms and 28ms.  6.4 Microbenchmark: Evactor The Evactor benchmark \nevaluates the performance of pick\u00adling a large number of small objects (in this case, events ex\u00adchanged \nby actors). The benchmark creates a large number of events using the datatypes of the Evactor complex \nevent processor (see Section 6.4); all created events are inserted into a collection and then pickled, \nand finally unpickled. As the results in Figure 6 show, Java serialization struggles with extreme memory \nconsumption and crashes with an out\u00adof-memory error when a collection with more than 10000 Figure 7: \nResults for pickling/unpickling data points from an implementation of linear regression using Spark. \n events is pickled. Both Kryo and scala/pickling handle this very high number of events without issue. \nTo compare Kryo and scala/pickling more closely we did another experiment with an even higher number \nof events, this time leaving out Java. The results are shown on the right-hand side of Fig\u00adure 6. At \n40000 events, Kryo finishes after about 180ms, whereas scala/pickling finishes after about 144ms a perfor\u00admance \ngain of about 25%.  6.5 Microbenchmark: Spark Spark is a popular distributed in-memory collections ab\u00adstraction \nfor interactively manipulating big data. The Spark benchmark compares performance of scala/pickling, \nJava, and Kryo when pickling data types from Spark s implemen\u00adtation of linear regression. Over the course \nof the benchmark, frameworks pickle and unpickle an ArrayBuffer of data points that each consist of a \ndouble and an accompanying spark.util.Vector, which is a specialized wrapper over an array of 10 Doubles. \nHere we use a mutable buffer as a container for data elements instead of more typical lists and vectors \nfrom Scala s standard library, because that s the data structure of choice for Spark to inter\u00adnally partition \nand represent its data. The results are shown in Figure 7, with Java and Kryo running in comparable time \nand scala/pickling consistently outperforming both of them. For example, for a dataset of 40000 points, \nit takes Java 68ms and Kryo 86ms to perform a pickling/unpickling roundtrip, whereas scala/pickling com\u00adpletes \nin 28ms, a speedup of about 2.4x compared to Java and about 3.0x compared to Kryo.  6.6 Microbenchmark: \nGeoTrellis GeoTrellis [4] is a geographic data processing engine for high performance applications used \nby the US federal gov\u00adernment among others. Figure 8: Results for pickling/unpickling geotrellis datatypes \n(case classes and large primitive arrays). In this benchmark one of the main message classes used in \nGeoTrellis is pickled. The class is a simple case class con\u00adtaining a primitive array of integers (expected \nto be large). Figure 8 shows the time it takes to pickle and unpickle an instance of this case class \nvarying the size of the contained array. The plot shows that Java serialization performs, compared to \nKryo, surprisingly well in this benchmark, e.g., a roundtrip for 50000000 elements takes Java 406ms, \nwhereas Kryo is more than two times slower at 836ms. It is likely that mod\u00adern JVMs support arrays of \nprimitive types well, which is the dominating factor in this case. Scala/pickling is still signifi\u00adcantly \nfaster with 124ms, since the static type of the array is final, so that efficient array-pickling code \ncan be generated at compile time. 6.7 Data Types in Distributed Frameworks and Applications Figure 9 \nshows a summary of the most important data types used in popular distributed computing frameworks like \nSpark [42] and Storm [20]. The fully shaded circles in the table representing heavy use means either \n(a) a feature is used frequently in application-level data types or (b) a fea\u00adture is used frequently \nin data types that the framework reg\u00adisters with its underlying serialization system. Half-shaded circles \nin the table representing light use mean a feature is used only infrequently in the data types used in \napplications or registered by frameworks. We categorize the data types shown in this table into two groups. \nIn the first group at the top are distributed applications using data types suitable for distributed \nevent processing and message passing. We consider two representative open\u00adsource applications: GeoTrellis \nand Evactor. Both applica\u00adtions use Akka [37], an event-driven middleware for dis\u00adtributed message passing. \nHowever, the properties of the exchanged messages are markedly different. Messages in GeoTrellis typically \ncontain large amounts of geographic raster data, stored in arrays of primitives. Messages in Evac\u00adtor \nrepresent individual events which typically contain only a few values of primitive types. Both applications \nmake use of Scala s case classes which are most commonly used as message types in actor-based applications. \n The second group in the bottom half of Figure 9 con\u00adsists of distributed computing frameworks. What \nthis table suggests is that the majority of distributed computing frame\u00adworks and applications requires \npickling collections of vari\u00adous types. Interestingly, application-level data types tend to use arrays \nwith primitive element type; a sign that there is a great need to provide easier ways to process big \ndata efficiently. From the table it is also clear that case classes tend to be primarily of interest \nto application code whereas frameworks like Spark tend to prefer the use of simple col\u00adlections of primitive \ntype internally. What s more, the de\u00admand for pickling generics seems to be lower than the need to support \nsubtyping polymorphism (our framework supports both, though). At least in one case (Twitter s Chill [26]) \na framework explicitly serializes manifests, type descriptors for Scala types, which are superceded by \ntype tags. The shaded area (which groups heavily-used features across applications/frameworks) shows \nthat collections are often used in distributed code, in particular with primitive element types. This \nmotivates the choice of our collections micro benchmark.  7. Other Related Work Pickling in programming \nlanguages has a long history dat\u00ading back to CLU [15] and Modula-3 [6]. The most closely\u00adrelated contemporary \nwork is in two areas. First, pickling in object-oriented languages, for example, in Java (see the Java \nObject Serialization Specification [25]), in .NET, and in Python [38]; second, work on pickler combinators \nin func\u00adtional languages which we have already discussed in the in\u00adtroduction. The main difference of \nour framework compared to pickling, or serialization, in widespread OO languages is that our approach \ndoes not require special support by the un\u00adderlying runtime. In fact, the core concepts of object-oriented \npicklers as presented in this paper can be realized in most OO languages with generics. While work on \npickling is typically focused on finding op\u00adtimally compact representations for data [39], not all work \nhas focused only on distribution and persistence of ground values. Pickling has also been used to distribute \nand persist code to implement module systems [30, 32]. Similar to our approach, but in a non-OO context, \nAliceML s HOT pick\u00adles [31] are universal in the sense that any value can be pick\u00adled. While HOT pickles \nare deeply integrated into language and runtime, scala/pickling exists as a macro-based library, enabling \nfurther extensibility, e.g., user-defined pickle for\u00admats can be interchanged. There is a body of work \non maximizing sharing of runtime data structures [2, 10, 36] which we believe could be applied to the \npickler combinators presented in Section 3; however, a complete solution is beyond the scope of the present \npaper. 8. Conclusion and Future Work We have introduced a model of pickler combinators which supports \ncore concepts of object-oriented programming in\u00adcluding subtyping polymorphism with open class hierar\u00adchies. \nFurthermore, we have shown how this model can be augmented by a composable mechanism for static pickler \ngeneration which is effective in reducing boilerplate and in ensuring efficient pickling. Thanks to a \ndesign akin to an object-oriented variation of type classes known from functional programming, the presented \nframework enables retrofitting existing types and third-party libraries with pick\u00adling support. Experiments \nsuggest that static generation of pickler combinators can outperform state-of-the-art serial\u00adization \nframeworks and significantly reduce memory usage. In future work we plan to further optimize the pickler \ngeneration and to extend the framework with support for closures.  Acknowledgments We would like to \nthank the anonymous OOPSLA 2013 refer\u00adees for their thorough reviews and helpful suggestions which greatly \nimproved the quality of the paper. We are grateful to the artifact evaluation committee and the anonymous \narti\u00adfact referees for their detailed reviews of scala/pickling. We would particularly like to thank \nMatei Zaharia for several helpful conversations which inspired this vein of work. Fi\u00adnally, we would \nlike to thank Denys Shabalin for his work on quasiquotes for Scala which has helped simplify the code \nbase of scala/pickling considerably.  References [1] Apache. Avro\u00ae. http://avro.apache.org. Accessed: \n2013\u00ad08-11. [2] A. W. Appel and M. J. R. Gon\u00e7alves. Hash-consing garbage collection. Technical Report \nCS-TR-412-93, Princeton Uni\u00adversity, Computer Science Department, 1993. [3] M. Armbrust, A. Fox, D. A. \nPatterson, N. Lanham, B. Trushkowsky, J. Trutna, and H. Oh. SCADS: Scale\u00adindependent storage for social \ncomputing applications. In CIDR, 2009. [4] Azavea. GeoTrellis. http://www.azavea.com/products/ geotrellis/, \n2010. Accessed: 2013-08-11. [5] E. Burmako and M. Odersky. Scala macros, a technical report. In Third \nInternational Valentin Turchin Workshop on Meta\u00adcomputation, 2012. [6] L. Cardelli, J. E. Donahue, M. \nJ. Jordan, B. Kalsow, and G. Nelson. The modula-3 type system. In POPL, pages 202 212, 1989. [7] B. Carpenter, \nG. Fox, S. H. Ko, and S. Lim. Object serializa\u00adtion for marshalling data in a Java interface to MPI. \nIn Java Grande, pages 66 71, 1999. [8] B. C. d. S. Oliveira, A. Moors, and M. Odersky. Type classes as \nobjects and implicits. In OOPSLA, pages 341 360, 2010. [9] G. Dubochet. Embedded Domain-Specific Languages \nusing Libraries and Dynamic Metaprogramming. PhD thesis, EPFL, Switzerland, 2011. [10] M. Elsman. Type-specialized \nserialization with sharing. In Trends in Functional Programming, pages 47 62, 2005. [11] C. Flanagan, \nA. Sabry, B. F. Duba, and M. Felleisen. The essence of compiling with continuations. In PLDI, pages 237 \n247. 1993. [12] J. Gil and I. Maman. Whiteoak: introducing structural typing into Java. In G. E. Harris, \neditor, OOPSLA, pages 73 90, 2008. [13] Google. Protocol Buffers. https://code.google.com/p/ protobuf/, \n2008. Accessed: 2013-08-11. [14] P. Haller and M. Odersky. Capabilities for uniqueness and borrowing. \nIn T. D Hondt, editor, ECOOP, pages 354 378, 2010. [15] M. Herlihy and B. Liskov. A value transmission \nmethod for abstract data types. ACM Trans. Program. Lang. Syst, 4(4): 527 551, 1982. [16] A. Igarashi, \nB. C. Pierce, and P. Wadler. Featherweight Java: a minimal core calculus for Java and GJ. ACM Trans. \nProgram. Lang. Syst, 23(3):396 450, May 2001. [17] A. Kennedy. Pickler combinators. J. Funct. Program., \n14(6): 727 739, 2004. [18] J. Maassen, R. van Nieuwpoort, R. Veldema, H. E. Bal, and A.Plaat. An efficient \nimplementation of Java s remote method invocation. In PPOPP, pages 173 182, Aug. 1999. [19] J. P. Magalh\u00e3es, \nA. Dijkstra, J. Jeuring, and A. L\u00f6h. A generic deriving mechanism for Haskell. In J. Gibbons, ed\u00aditor, \nHaskell, pages 37 48, 2010. [20] Nathan Marz and James Xu and Jason Jackson et al. Storm. http://storm-project.net/, \n2012. Accessed: 2013-08-11. [21] Nathan Sweet et al. Kryo. https://code.google.com/p/kryo/. Accessed: \n2013-08-11. [22] K. Ng, M. Warren, P. Golde, and A. Hejlsberg. The Roslyn project: Exposing the C# and \nVB compiler s code analysis. http://msdn.microsoft.com/en-gb/hh500769, Sept. 2012. Ac\u00adcessed: 2013-08-11. \n[23] M. Odersky. Scala Language Specification. http: //www.scala-lang.org/files/archive/nightly/pdfs/ \nScalaReference.pdf, 2013. Accessed: 2013-08-11. [24] M. Odersky and M. Zenger. Scalable component abstractions. \nIn R. E. Johnson and R. P. Gabriel, editors, OOPSLA, pages 41 57, 2005. [25] Oracle, Inc. Java Object \nSerialization Specifica\u00adtion. http://docs.oracle.com/javase/7/docs/platform/ serialization/spec/serialTOC.html, \n2011. Accessed: 2013-08-11. [26] Oscar Boykin and Mike Gagnon and Sam Ritchie. Twitter Chill. https://github.com/twitter/chill, \n2012. Accessed: 2013-08-11. [27] M. Philippsen, B. Haumacher, and C. Nester. More efficient serialization \nand RMI for Java. Concurrency -Practice and Experience, 12(7):495 518, 2000. [28] B. C. Pierce. Types \nand Programming Languages. MIT Press, Cambridge, MA, 2002. [29] G. D. Reis and B. Stroustrup. Specifying \nC++ concepts. In J. G. Morrisett and S. L. P. Jones, editors, POPL, pages 295 308, 2006. [30] A. Rossberg. \nTyped open programming: a higher-order, typed approach to dynamic modularity and distribution. PhD thesis, \nSaarland University, 2007. [31] A. Rossberg, G. Tack, and L. Kornstaedt. Status report: HOT pickles, \nand how to serve them. In ML, pages 25 36, 2007. [32] P. V. Roy. Announcing the mozart programming system. \nSIG-PLAN Notices, 34(4):33 34, 1999. [33] D. Shabalin, E. Burmako, and M. Odersky. Quasiquotes for Scala. \nTechnical Report EPFL-REPORT-185242, EPFL, Switzerland, 2013. [34] K. Skalski. Syntax-extending and type-re.ecting \nmacros in an object-oriented language. Master s thesis, University of Warsaw, Poland, 2005. [35] R. Strnisa, \nP. Sewell, and M. J. Parkinson. The Java module system: core design and semantic definition. In OOPSLA, \npages 499 514, 2007. [36] G. Tack, L. Kornstaedt, and G. Smolka. Generic pickling and minimization. Electr. \nNotes Theor. Comput. Sci, 148(2):79 103, 2006. [37] Typesafe. Akka. http://akka.io/, 2009. Accessed: \n2013-08\u00ad 11. [38] G. van Rossum. Python programming language. In USENIX Annual Technical Conference. \nUSENIX, 2007. [39] D. Vytiniotis and A. J. Kennedy. Functional pearl: every bit counts. SIGPLAN Not., \n45(9):15 26, Sept. 2010. [40] S. Wehr and P. Thiemann. JavaGI: The interaction of type classes with interfaces \nand inheritance. ACM Trans. Program. Lang. Syst, 33(4):12, 2011. [41] M. Welsh and D. E. Culler. Jaguar: \nenabling efficient commu\u00adnication and I/O in Java. Concurrency -Practice and Experi\u00adence, 12(7), 2000. \n[42] M. Zaharia, M. Chowdhury, T. Das, A. Dave, M. McCauley, M. Franklin, S. Shenker, and I. Stoica. \nResilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing. In NSDI. \nUSENIX, 2012.  \n\t\t\t", "proc_id": "2509136", "abstract": "<p>As more applications migrate to the cloud, and as \"big data\" edges into even more production environments, the performance and simplicity of exchanging data between compute nodes/devices is increasing in importance. An issue central to distributed programming, yet often under-considered, is serialization or pickling, <i>i.e.</i>, persisting runtime objects by converting them into a binary or text representation. Pickler combinators are a popular approach from functional programming; their composability alleviates some of the tedium of writing pickling code by hand, but they don't translate well to object-oriented programming due to qualities like open class hierarchies and subtyping polymorphism. Furthermore, both functional pickler combinators and popular, Java-based serialization frameworks tend to be tied to a specific pickle format, leaving programmers with no choice of how their data is persisted. In this paper, we present object-oriented pickler combinators and a framework for generating them at compile-time, called <i>scala/pickling</i>, designed to be the default serialization mechanism of the Scala programming language. The static generation of OO picklers enables significant performance improvements, outperforming Java and Kryo in most of our benchmarks. In addition to high performance and the need for little to no boilerplate, our framework is extensible: using the type class pattern, users can provide both (1) custom, easily interchangeable pickle formats and (2) custom picklers, to override the default behavior of the pickling framework. In benchmarks, we compare scala/pickling with other popular industrial frameworks, and present results on time, memory usage, and size when pickling/unpickling a number of data types used in real-world, large-scale distributed applications and frameworks.</p>", "authors": [{"name": "Heather Miller", "author_profile_id": "81504682888", "affiliation": "EPFL, Lausanne, Switzerland", "person_id": "P4290332", "email_address": "heather.miller@epfl.ch", "orcid_id": ""}, {"name": "Philipp Haller", "author_profile_id": "81430665752", "affiliation": "Typesafe, Inc., Lausanne, Switzerland", "person_id": "P4290333", "email_address": "philipp.haller@typesafe.com", "orcid_id": ""}, {"name": "Eugene Burmako", "author_profile_id": "82458849957", "affiliation": "EPFL, Lausanne, Switzerland", "person_id": "P4290334", "email_address": "eugene.burmako@epfl.ch", "orcid_id": ""}, {"name": "Martin Odersky", "author_profile_id": "81100056476", "affiliation": "EPFL, Lausanne, Switzerland", "person_id": "P4290335", "email_address": "martin.odersky@epfl.ch", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509547", "year": "2013", "article_id": "2509547", "conference": "OOPSLA", "title": "Instant pickles: generating object-oriented pickler combinators for fast and extensible serialization", "url": "http://dl.acm.org/citation.cfm?id=2509547"}