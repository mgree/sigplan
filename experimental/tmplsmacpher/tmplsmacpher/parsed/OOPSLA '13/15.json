{"article_publication_date": "10-29-2013", "fulltext": "\n MrCrypt: Static Analysis for Secure Cloud Computations Sai Deep Tetali Mohsen Lesani Rupak Majumdar \nUC Los Angeles UC Los Angeles MPI-SWS saideep@cs.ucla.edu lesani@cs.ucla.edu rupak@mpi-sws.org Todd Millstein \nUC Los Angeles todd@cs.ucla.edu Abstract In a common use case for cloud computing, clients upload data \nand computation to servers that are managed by a third\u00adparty infrastructure provider. We describe MrCrypt, \na sys\u00adtem that provides data con.dentiality in this setting by exe\u00adcuting client computations on encrypted \ndata. MrCrypt stat\u00adically analyzes a program to identify the set of operations on each input data column, \nin order to select an appropriate homomorphic encryption scheme for that column, and then transforms \nthe program to operate over encrypted data. The encrypted data and transformed program are uploaded to \nthe server and executed as usual, and the result of the compu\u00adtation is decrypted on the client side. \nWe have implemented MrCrypt for Java and illustrate its practicality on three stan\u00addard benchmark suites \nfor the Hadoop MapReduce frame\u00adwork. We have also formalized the approach and proven sev\u00aderal soundness \nand security guarantees. Categories and Subject Descriptors D.2.7 [Software En\u00adgineering]: Distribution, \nMaintenance, and Enhancement Restructuring, reverse engineering, and reengineering; D.3.1 [Programming \nLanguages]: Formal De.nitions and Theory Keywords cloud computing; data con.dentiality; homo\u00admorphic \nencryption; encryption scheme inference 1. Introduction A common use case for cloud computing involves \nclients up\u00adloading data and computation to servers managed by third\u00adparty infrastructure providers. Since \nthe data and programs Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. Copyrights \nfor components of this work owned by others than the author(s) must be honored. Abstracting with credit \nis permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. Request permissions from permissions@acm.org. OOPSLA 13, October \n29 31, 2013, Indianapolis, Indiana, USA. Copyright is held by the owner/author(s). Publication rights \nlicensed to ACM. ACM 978-1-4503-2374-1/13/10. . . $15.00. http://dx.doi.org/10.1145/2509136.2509554 are \nno longer in an environment controlled by the client, private client data may be exposed to adversarial \nclients in the cloud server, either by accidental miscon.gurations or through malicious intent. Publicized \nincidents involving the loss of con.dentiality or integrity of customer data [20] only heighten these \nconcerns. The threat of potential violations to the con.dentiality and integrity of customer data is \na key barrier to the adoption of cloud computing based on third\u00adparty infrastructure providers. One way \nto alleviate these concerns is to store encrypted data on the cloud and decrypt it as needed during the \ncloud computation. However, this approach is insuf.cient to pro\u00adtect against adversaries who can potentially \nview the mem\u00adory contents of the server, for example a curious cloud ad\u00administrator or a malicious client \nrunning on the same ma\u00adchine. Therefore, all computations must be performed on the client side [22, 23], \nwhich severely reduces the attractive\u00adness of the cloud model. Theoretically, fully homomorphic encryption \nschemes [14, 34] offer the possibility of upload\u00ading and storing encrypted data on the cloud and performing \narbitrary operations on the encrypted data. Unfortunately, current implementations of fully homomorphic \nencryption schemes are still prohibitively expensive [15, 16]. In this paper we present MrCrypt, a system \nthat automat\u00adically transforms programs in order to enforce data con.\u00addentiality. Our key insight is \nthat many useful cloud compu\u00adtations only perform a small number of operations on each column of the \ndata. While fully homomorphic encryption is expensive, there are ef.cient encryption schemes that sup\u00adport \ncommon subsets of operations. Thus, instead of en\u00adcoding each column using a fully homomorphic encryption \nscheme, one can encrypt it using a more ef.cient scheme that supports only the necessary operations. \nFor example, suppose that the client program sums all the elements of a column. Instead of a fully homomorphic \nencryption scheme, one can encrypt the column using the Paillier cryptosys\u00adtem [29], which guarantees \nthat Paillier(x) \u00b7 Paillier(y) = Paillier(x + y)  for any x, y, where Paillier(x) denotes the encryption \nof x using the scheme, and the multiplication of the codewords on the left is modulo a public key. Thus \nto compute on the encrypted data, the program must simply take the product of all codewords. When the \nresult is decrypted on the client side, the sum of all the numbers is recovered. Similarly, the El Gamal \ncryptosystem [10] is homomorphic for multiplica\u00adtion: ElGamal(x) \u00b7 ElGamal(y) = ElGamal(x \u00b7 y) In this \nway, MrCrypt reduces the problem of securing cloud computations to that of identifying the subset of \nprim\u00aditive operations (such as addition, multiplication, equality checks, and order comparisons) performed \non each column of the input, in order to determine the most ef.cient encryp\u00adtion scheme that can be used \nfor the column. We have de\u00adveloped a static analysis to perform this task, which we call encryption scheme \ninference, on imperative programs. We formalize the problem and our solution as a variant of type quali.er \ninference [11], where each quali.er lattice element represents a particular homomorphic encryption scheme. \nWe have implemented MrCrypt for Java. Given a Java program and a lattice of encryption schemes, MrCrypt \n.rst performs encryption scheme inference to determine the most ef.cient scheme for each input data column, \nbased on the op\u00aderations performed by the program on that column. MrCrypt then performs a source-to-source \ntransformation of the pro\u00adgram to compute on the encrypted data rather than the orig\u00adinal plaintext. \nFinally, the transformed program can be sent to the cloud and run on an encrypted version of the original \ndata. In our experiments, we evaluate MrCrypt s practicality by applying it to Java programs that run \non the MapRe\u00adduce framework [9] in Hadoop1. MapReduce is a natural target because it is a popular programming \nmodel for cloud computing, and the Hadoop implementation of MapReduce is widely used. Further, many useful \nMapReduce programs require only a small number of operations on each data column and so .t the requirements \nof our approach. The transformed programs produced by MrCrypt are compliant Hadoop MapReduce programs \nand so can run directly on unmodi.ed Hadoop infrastructure in the cloud. We have evaluated MrCrypt on \nthree standard MapRe\u00adduce benchmark suites [1, 27, 31] and evaluated our system on large datasets (up \nto 50GB) provided with the PUMA benchmarks [1]. On 24 of 36 benchmarks, MrCrypt can identify encryption \nschemes to support the necessary func\u00adtionality without requiring fully homomorphic encryption. For the \nlarge dataset examples, encrypted execution takes 2.61 times as long on average as the plaintext versions \nand requires 3.92 times as much space for input data. However, ignoring one outlier benchmark, the benchmarks \ntake only 1 http://hadoop.apache.org/ 1.57 times as long on average as the plaintext versions and require \n2.88 times as much space. The closest related work to MrCrypt is CryptDB [32], a system that interposes \nbetween a trusted application and an untrusted database server. CryptDB dynamically rewrites each SQL \nquery generated by an application to work over homomorphically encrypted data. MrCrypt also relies on \nhomomorphic encryption for security, but in the setting of cloud computing, which demands several important \ndesign differences. Speci.cally, MrCrypt must perform encryption scheme inference statically, must rewrite \nan entire applica\u00adtion to work over encrypted data, and must be able to handle imperative Java code rather \nthan declarative SQL. We com\u00adpare with CryptDB and other related work in more detail in Section 7. Like \nCryptDB, MrCrypt only considers threats against data con.dentiality. In particular, MrCrypt does not \npro\u00advide guarantees of data integrity or completeness of results, which are orthogonal issues and topics \nfor future work. The rest of the paper is structured as follows. In the next section we provide necessary \nbackground on homomorphic encryption as well as the MapReduce programming model. Section 3 overviews \nMrCrypt and provides an illustrative ex\u00adample. In Section 4, we formalize the encryption scheme in\u00adference \nproblem and present soundness and security guaran\u00adtees. We explain our implementation in Section 5 and \npresent the evaluation results in Section 6. Finally, we present related work and conclusions. 2. Background \n 2.1 Homomorphic Encryption Schemes A (public-key) encryption scheme consists of three algo\u00adrithms (K, \nE, D) for key-generation, encryption, and de\u00adcryption. The key-generation procedure K is a randomized \nalgorithm that takes a security parameter . as input and out\u00adputs a secret key sk and public key pk. \nThe encryption pro\u00adcedure E is a randomized algorithm that takes pk and a plaintext m as input and outputs \na ciphertext .. The decryp\u00adtion procedure D takes sk and . as input and outputs the plaintext m, i.e., \nD(sk, E(pk, m)) = m. The computational complexity of all of these algorithms must be polynomial in .. \nGiven a binary operation f, an encryption scheme is homomorphic for f if there exists a (possibly randomized) \npolynomial-time algorithm Evalf , which takes as input the public key pk and a pair of ciphertexts (.1, \n.2) such that D(sk, Evalf (pk, .1, .2)) = f(D(sk, .1), D(sk, .2)) Informally, if .1 and .2 are respectively \nencryptions of plaintexts m1 and m2 under pk, then Evalf (pk, .1, .2) is an encryption of f(m1, m2) under \npk. For a set of operations F , an encryption scheme is homomorphic for F if it is homomorphic for each \nf . F . An encryption scheme is said to be fully homomorphic if it is homomorphic for {+, \u00d7}.   Figure \n1. A lattice of encryption schemes. It is easy to see that in this case, any polynomial-sized arithmetic \ncircuit can be evaluated purely on the ciphertext. In addition to homomorphic encryption schemes, we \nshall also consider encryption schemes with a related property in which the result of an operation can \nbe computed (in clear text) directly on the ciphertext: Evalf (pk, .1, .2) = f(D(sk, .1), D(sk, .2)) \nFor example, using a deterministic encryption scheme, one can check if two values are equal simply by \ncomparing the ciphertexts for equality, without requiring any information about the original values. \nIn the following, we abuse notation and call such encryption schemes homomorphic as well. Given a set \nof operations F, one can arrange encryption schemes in a partial order: an encryption scheme E1 is less \nthan a scheme E2 if E1 is homomorphic for F1 . F , E2 is homomorphic for F2 . F , and F2 . F1. A fully \nhomomor\u00adphic encryption scheme is the unique minimal element in this ordering, and a random encryption \nscheme is the maxi\u00admal element (it is not homomorphic for any operation). Typ\u00adically, one expects that \nencryption schemes higher in the ordering (i.e., supporting fewer operations) will have more ef.cient \nimplementations. MrCrypt s implementation is parameterized by a lattice of encryption schemes. Our experiments \nin Section 6 em\u00adploy several forms of encryption, which are shown as a lat\u00adtice in Figure 1 along with \nthe set of operations that each scheme supports. RAND (random) supports no homomor\u00adphic operations [40]; \nDE T (deterministic) supports equality testing [40]; OP (order-preserving) supports comparisons [5, 6]; \nAH (additive homomorphic) supports addition [29]; MH (multiplicative homomorphic) supports multiplication \n[10]; FH (fully homomorphic) supports all operations [14]. The DET and OP schemes produce their results \nin clear text, while the other schemes are homomorphic in the strict sense. Because fully homomorphic \nencryption is not cur\u00adrently practical, MrCrypt does not include an implementa\u00adtion of it, but we show \nthat it is rarely required in our bench\u00admark programs. Figure 2. Architecture of MrCrypt; solid boxes \nshow im\u00adplemented components .  2.2 MapReduce MapReduce [9] is a popular distributed programming model \nintroduced by Google for processing large data sets on clus\u00adters. In this model, the computation is divided \ninto three stages. The map stage invokes a user-de.ned map function in parallel over the data and produces \na list of intermediate key/value pairs. A shuf.e stage in the MapReduce frame\u00adwork then sorts all the \nresulting records based on the keys and groups together all values associated with the same key. Finally, \nthe reduce stage invokes a user-de.ned reduce func\u00adtion in parallel to combine the values associated \nwith each key in some fashion, typically producing just zero or one .\u00adnal values per key. Hadoop MapReduce \nis an open-source implementation of MapReduce that is widely used by both researchers and major corporations \n(e.g., Facebook, Twitter) to perform large-scale distributed computations. 3. Overview 3.1 MrCrypt Architecture \nand Threat Model The architecture of MrCrypt is shown in Figure 2. Given a Java program and a data set, \nMrCrypt performs static anal\u00adysis on the program to determine an encryption scheme for each input column, \nprogram variable, and program constant such that each program operation can be performed homo\u00admorphically \non encrypted data. We call this analysis en\u00adcryption scheme inference. The analysis .rst generates con\u00adstraints \nbased on how operations in the program are used, and then it solves the constraints to determine the \nmost ef\u00ad.cient (i.e., highest in the lattice) encryption scheme to use for each part of the program. \nNext the results of the encryption scheme inference are used to transform the program. Speci.cally, each \ncall to a primitive operation f in the program is replaced by a call to EvalE , where E is the encryption \nscheme inferred for the f arguments to f. Similarly, each program constant c is re\u00adplaced by its encrypted \nvalue EE (c), where E is the encryp\u00adtion scheme inferred for c. The data set is also encrypted according \nto the inferred encryption schemes on the client side.  Program 1 An example MapReduce program. 1 I \nn t e g e r m a p ( I n t e g e r e n t r y D a t e , I n t e g e r e n t r y M o n t h , I n t e g e \nr e n t r y Y e a r , I n t e g e r caloriesBurnt) { 2 i f ( e n t r y Y e a r > 2 0 1 2 ) 3 r e t u \nr n c a l o r i e s B u r n t ; 4 e l s e 5 return 0; 6 } 7 I n t e g e r r e d u c e ( L i s t < I n \nt e g e r > c a l o r i e s B u r n t L i s t ) { 8 Integer sum = 0; 9 f o r ( I n t e g e r c a l o \nr i e s B u r n t : c a l o r i e s B u r n t L i s t ) 10 s u m + = c a l o r i e s B u r n t ; 11 \nreturn sum ; 12 } Finally, the encrypted data and the transformed program are uploaded to the (untrusted) \nserver, where the program is executed. The result is sent back to the client, where it is decrypted. \nWe assume a passive (honest-but-curious) adversary model. That is, the adversary can view all the data \nuploaded to the server, the program that is uploaded, as well as the entire execution trace of the program. \nHowever, we assume that the adversary does not change the data, the program, or the result of the program \n(i.e., no integrity attacks). 3.2 Applications MrCrypt is potentially useful for any cloud computation, \nbut we expect it to be especially applicable to scenarios where a small set of computations are run iteratively \nover a large evolving data set. In these cases, the client-side encryption required by MrCrypt can be \nperformed incrementally as the data is generated, and the encryption costs are amortized over multiple \nruns of the cloud computations. A broad class of applications have these characteristics. For example, \nhealth-monitoring systems continuously up\u00adload vital statistics of a user to the cloud, where running \ncomputations are performed on the data to alert users or caregivers when certain conditions hold. Companies \nsuch as FitBit, Jawbone, and Nike have devices in the market which track several metrics such as distance \nwalked, calories burnt, and sleep patterns and upload them continuously to the cloud in order to compute \naggregates. As another exam\u00adple, these characteristics apply to sensor networks in which a distributed \nset of sensors continually upload data to the cloud in order to run analytics. 3.3 Example Program 1 \nis inspired by wireless .tness trackers. Users con\u00adtinually upload .tness information such as the number \nof calories burnt during a workout to the cloud. This program uses the MapReduce programming model to \ncompute the to\u00adtal number of calories burnt by a user since the beginning of the year 2013. This result \ncan be used further to compute statistics such as the average calories burnt per day. Every record includes \nthe number of calories burnt and the date as\u00adsociated with the event (given by year, month and day .elds). \nFor expository purposes we omit some implementation de\u00adtails required by MapReduce frameworks, for example \nthe need to parse input data from a .le and to produce key-value pairs as results. However, the example \nis illustrative of com\u00admon MapReduce use cases. The user-de.ned map function is executed on each row \nof the data, and it has the effect of producing all entries from the caloriesBurnt column for which the \nassociated entry year is greater than 2012. The MapReduce framework collects the values returned by the \nmap function invocations and passes the resulting list to the user-de.ned reduce function, which sums \nthe calories. Encryption Inference Consider our example in Program 1. For a variable x, let s(x) denote \nthe encryption scheme for x, and similarly for a constant c. When necessary to disambiguate, we subscript \na variable or constant with the name of the function in which it appears. From line 2, it is concluded \nthat s(entryYear) = s(2012) and that s(entryYear) should support at least >. From lines 3 and 5, s(caloriesBurntmap) \n= s(0map). From line 8, s(sum) = s(0reduce). From line 10, s(sum) = s(caloriesBurntreduce) and s(sum) \nshould support at least +. Finally, the seman\u00adtics of the MapReduce framework requires that the result \nfrom the map function must use the same encryption scheme as the data items in the argument list to the \nreduce func\u00adtion. Given the lattice of encryption schemes from Figure 1, the best solution to these constraints \nmaps s(entryYear) and s(2012) to OP , s(entryDate) and s(entryMonth) to RAND (since there are no constraints \non these variables), and everything else to AH. Given the results of encryption scheme inference, it \nis straightforward to produce the translated program that will be sent to the cloud along with the encrypted \ndata. The translated program for the example is shown in Program 2. First, the primitive > function is \nreplaced by the correspond\u00ading operation in the order-preserving encryption scheme, which we denote OP_GT, \nand similarly + is replaced by AH_PLUS. Second, each constant is replaced by an appropri\u00adately encrypted \nversion of that constant. For example, we use [[OP_E(2012)]] to denote the encrypted value of the con\u00adstant \n2012 under the order-preserving encryption scheme. Note that this value is computed statically and inserted \ninto the transformed program in place of the original constant.  3.4 Properties As described in the \nnext section, we have formalized the constraint generation phase of encryption scheme infer\u00adence. (The \nconstraints can be solved using well-known tech\u00adProgram 2 Translated Program  1 A H _ I n t e g e r \nm a p ( R A N D _ I n t e g e r e n t r y D a t e , R A N D _ I n t e g e r e n t r y M o n t h , O P \n_ I n t e g e r e n t r y Y e a r , A H _ I n t e g e r c a l o r i e s B u r n t ) { 2 i f ( O P _ G \nT ( e n t r y Y e a r , [ [ O P _ E ( 2 0 1 2 ) ] ] ) 3 r e t u r n c a l o r i e s B u r n t ; 4 e l \ns e 5 r e t u r n [ [ A H _ E ( 0 ) ] ] ; 6 } 7 A H _ I n t e g e r r e d u c e ( L i s t < A H _ I n \nt e g e r > c a l o r i e s B u r n t L i s t ) { 8 A H _ I n t e g e r s u m = [ [ A H _ E ( 0 ) ] \n] ; 9 f o r ( A H _ I n t e g e r c a l o r i e s B u r n t : c a l o r i e s B u r n t L i s t ) 10 \ns u m = A H _ P L U S ( s u m , c a l o r i e s B u r n t ) ; 11 return sum ; 12 } niques [11].) We have \nproven that the generated constraints are sound: any solution to the constraints ensures that an en\u00adcryption \nscheme is only asked to perform operations that it supports and that the operands to a homomorphic operation \nare encrypted with that same encryption scheme. We have also proven that the generated constraints are \ncomplete, so in particular they are compatible with the unique most ef.cient mapping that satis.es the \nabove properties, according to the given lattice. By design our approach never sends plaintext data or \npro\u00adgram constants to the server. Additionally, we can prove a strong security guarantee for MrCrypt. \nInformally, our re\u00adsult says that a polynomial-time adversary gets no advan\u00adtage by having access to \nthe transformed program and its (encrypted) inputs over and above having access to the en\u00adcrypted input \ndata alone. Therefore, the security guarantees of our framework are equivalent to those provided by the \nunderlying homomorphic encryption schemes. The semantic security of encryption schemes is formal\u00adized \nusing notions of indistinguishability [17]. Intuitively, these guarantees say that an adversary cannot \nrecover which one of two plaintexts a given ciphertext corresponds to, with better odds than .ipping \na fair coin. The RAND, AH, and MH schemes ensure this strong indistinguishability prop\u00aderty. The DE T \nand OP schemes provide weaker guaran\u00adtees. For example, given an input column encrypted with DE T , an \nattacker can easily determine whether two rows hold the same value or not. However, DE T satis.es a nat\u00adural \nweakening of indistinguishability ensuring that the re\u00adsults of such equality tests are the only things \nrevealed to an adversary. The situation for the OP scheme is analogous. While these schemes offer weaker \nguarantees, in practice us\u00ading them on data of high entropy provides a useful level of con.dentiality. \nWe show a multicast security result, follow\u00ading [2], that an adversary can learn no more facts about \nthe original input than can be learnt from the encryption of any individual input value (i.e., there \nis no additional security loss in our system). 4. Encryption Scheme Inference This section formally de.nes \nthe encryption scheme infer\u00adence problem on an extended simply-typed lambda calculus, formalizes our \nsolution to the problem, and proves various correctness and security properties of the approach. The \nfull formal details are available in a companion technical report [21]. Our formalism is parameterized \nby a set M of arithmetic operations and a set R of logical predicates, whose union we denote O. The formalism \nis also parameterized by a lattice L of encryption schemes, each of which supports some subset of the \noperations in O, with associated partial order .. We assume that if l1 . l2 and encryption scheme l2 \nsupports some operation . . O, then l1 also supports that operation. Also, for each operation . . O we \nassume there is a unique maximal element of L that supports ., which we denote l.. In our implementation, \nM = {+, \u00d7} and R = {<, =, >}. 4.1 Syntax The syntax of expressions is as follows: e ::= v | x | e1 e2 \n| e1 . e2 Program v ::= .x:..e | n | nl Value where . . O. Metavariable x ranges over variables and n \nover integer constants. The value nl denotes the value result\u00ading from encrypting integer n with the \nencryption scheme l. The set of types is de.ned as follows: . ::= . t Quali.ed Type . ::= l | . | . Quali.er \nt ::= I nt | a | . . . Type Types are quali.ed with a lattice element l, which tracks the encryption \nscheme used for each program expression. Metavariable . ranges over quali.er variables and a over type \nvariables. For uniformity we use . to denote the qual\u00adi.er for unencrypted data. Since any operation \nis supported on unencrypted data, . is extended such that .l . L : . . l.  4.2 Operational Semantics \nWe de.ne two operational semantics for the language: one for programs that expect plaintext inputs and \nanother for pro\u00adgrams that expect encrypted inputs. The former semantics models execution of the original \nprograms while the latter semantics models execution of those programs after being transformed by MrCrypt. \nThe reduction contexts for both semantics are standard and de.ned as follows: R ::= [ ] | R e | v R | \nR . e2 | v . R The plaintext and ciphertext operational semantics rela\u00adtions, respectively denoted .p \nand ., are shown in Fig\u00adures 3 and 4. We use [[.]] to denote the mathematical func\u00adtion corresponding \nto operation ., with the relational oper\u00ad  REL -TRA N S R MAT H -TR ANS 1 if (n [[.]] n\") AP P -TR \nA N S \" \"\" \"\" n [[.]] n= n. . M n= . . R R[(.x:..e) v] . R[e[x . v]] 0 if \u00ac(n [[.]] n\") R[n . n\"] .p \nR[n\"\"] \"\"] R[n . n\"] .p R[n Figure 3. Plaintext Operational Semantics Q-MATH-TR A N S Q-RE L -TR ANS \nR \" \"\" \") n [[.]] n= n. . M 1 if (n [[.]] n \"\" Q-AP P -TRAN S n = . . R l l. 0 if \u00ac(n [[.]] n\") R[(.x:..e) \nv] . R[e[x . v]] \" \"\" l l. R[nl . nl] . R[nl] \" \"\"] R[nl . nl] . R[n Figure 4. Ciphertext Operational \nSemantics ations in R returning the integer 1 to denote true and 0 to denote false. The plaintext semantics \nrequires the operands to a mathematical operation to be unencrypted. In contrast, the ciphertext semantics \nrequires the operands to a mathe\u00admatical operation . to be encrypted with the same encryp\u00adtion scheme \nl, requires that l supports ., and speci.es that the operations in M result in encrypted values.  4.3 \nTyping and Type Inference Figure 5 de.nes the typing judgment of the form G f e: ., where as usual the \ntype environment G maps variables to (quali.ed) types. The rules are mostly standard. The key new requirements \nare that the operands to an operation . have the same encryption scheme (quali.er) and that this encryption \nscheme supports the operation. The type quali.er for a lambda abstraction is . because we never encrypt \nfunctions (but rather just the numeric data manipulated by those functions). Finally, we formalize the \nencryption scheme inference problem as a form of type inference with quali.ers. We de.ne a judgment of \nthe form2 G f e: .; C where C is a set of constraints of the following form: C ::= {t1 = t2} | {.1 = \n.2} | {. l} | C1 . C2 We treat equality constraints of the form .1 t1 = .2 t2 as shorthand for the two \nconstraints {.1 = .2, t1 = t2}. The type inference rules are shown in Figure 6. The rules produce constraints \non the quali.ed types of all program expressions. A substitution s, which maps type and qual\u00adi.er variables \nto types and quali.ers, is a solution to con\u00adstraints C if s(c) is satis.ed for each c . C. A solution \nto the constraints produced by type inference therefore repre\u00adsents a solution to the encryption scheme \ninference problem: it determines the encryption scheme needed for each pro\u00adgram expression in order to \nmake the program typecheck. 2 In our technical report [21], the judgment also records the set of generated \ntype and quali.er variables, which is necessary for the formal proof of completeness; we elide this here \nfor presentation purposes. The constraints have a unique best solution (maximal in the lattice L) and \ncan be solved using standard techniques [11]. Note that while constants in our formalism are explicitly \nan\u00adnotated with their encryption scheme, this is no loss of gen\u00aderality since we can always model program \nconstants instead as extra parameters to the program.  4.4 Soundness Properties We have proven several \ncorrectness properties for our for\u00admalism. First, we have proven type soundness through the standard \nprogress and preservation style [42]: Lemma 1 (Progress). If \u00d8 f e: ., then either e is a value \" or \nthere is some e\" such that e . e. Lemma 2 (Preservation). If G f e: . and e . e\" then \" G f e: .. Type \nsoundness ensures that a well-typed program never gets stuck at run time, which in our setting implies \nthat an encryption scheme is only asked to perform operations that it supports and operations are always \napplied to operands that use the same encryption scheme. Second, we have proven that execution of a transformed \nprogram in the ciphertext semantics is equivalent to execu\u00adtion of the original program in the plaintext \nsemantics. Given an expression e we de.ne decr(e) to be the expression iden\u00adtical to e but with each \noccurrence of a value of the form nl replaced by n. Intuitively, decr(e) is the plaintext version of \ne. The following result formalizes this intuition. Theorem 1. 1. [Encryption Domain Soundness] If e . \ne\", then decr(e) .p decr(e\"). \" 2. [Encryption Domain Completeness] If \u00d8 f e1 : ., e= \"\" decr(e1) and \ne.p e, then there is some e2 such that 1 2 \" e1 . e2 and e= decr(e2). 2 Finally, we have proven that \nour type inference rules are sound and complete with respect to our typing rules, which means the generated \nconstraints are compatible with only and all valid types of the program.  Q-LA M G[x . .1] f e : .2 \nG f .x:.1.e: . (.1 . .2) Q-MATH \" \"\" G f e : . I nt G f e : . I nt . l. . . M \" \"\" G f e . e : . I nt \nQ-AP P G f e1 : . (.1 . .2) G f e2 : .1 G f e1 e2 : .2 Q-REL \" \"\" G f e : . I nt G f e : . I nt . l. \n. . R \" \"\" G f e . e : . I nt Q-INT-L G f nl : l I nt Q-IN T G f n: . I nt Q-VA R G(x) = . G f x: . \n Figure 5. Typing Rules Q-LA M -IN F Q-RE L -IN F G[x . .1] f e: .2; C . . R \" C = C . {. = ., a = .1 \n. .2} G f e1 : (.1 t1); C1 G f e2 : (.2 t2); C2 . , a fresh C = C1 . C2 . {.1 = .2, . = ., .1 l., t1 \n= t2 = I nt = a}\" . , a fresh G f .x:.1.e : (. a); C G f (e1 . e2) : (. a); C Q-AP P -IN F G f e1 : .1; \nC1 G f e2 : .2; C2 Q-VA R -IN F C = C1 . C2 . {.1 = . \" (.2 . (. a))} G(x) = . ., . \" , a \" fresh G \nf x: .; \u00d8 G f e1 e2 : (. a); C Q-IN T-L-IN F Q-MATH -IN F C = {. = l, a = I nt} . , a fresh . . M G f \nnl : (. a); C G f e1 : (.1 t1); C1 G f e2 : (.2 t2); C2 C = C1 . C2 . {.1 = .2 = . , . l., t1 = t2 = \nI nt = a} Q-IN T-IN F . , a fresh C = {. = ., a = I nt} ., a fresh G f (e1 . e2) : (. a); C G f n: (. \na); C Figure 6. Type Inference Rules Theorem 2. 1. [Soundness of Type Inference] If G f e: .; C and s \nis a solution to C, then s(G) f s(e) : s(.). 2. [Completeness of Type Inference] If G f e: .; C and there \nis a substitution s such that s(G) f s(e) : . \", then there is a solution s \" to C such that s \" (.) \n= . \" .  4.5 Security Guarantees We assume an honest-but-curious adversary model, where the server observes \nthe data, the program, and the program execution and can perform polynomial-time computation over the \nobservations. However, the server does not change the data or the computation. One caveat is that the \nserver should run in polynomial time in the size of the data and the input, but not in the potentially \nexponential program trace. If we allow the adversary to run in time polynomial in the program trace, \nit may be able to execute an exponentially long computation in the security parameter, and so to decrypt \nall the encrypted values trivially. We formalize our security guarantees in terms of indistin\u00adguishability \n[17]. Indistinguishability is formalized using an adversary A = (A1, A2), performing a sequence of two \n(po\u00adtentially randomized) polynomial-time algorithms. Initially keys (pk, sk) = K(.) are generated based \non a security parameter .. First, algorithm A1 takes as input the public key pk and outputs two plaintext \nmessages x0 and x1, to\u00adgether with some additional state information s. Next, a bit b . {0, 1} is chosen \nat random, and message xb is encrypted as a challenge ciphertext y using pk. Finally, algorithm A2 runs \non (y, s) and has to guess the bit b. The advantage of the adversary is de.ned as 1 Adv E (A) = Pr[A2(y, \ns) = b] - 2 where the random variables are distributed uniformly. An encryption scheme E = (K, E , D) \nsatis.es single\u00aduse indistinguishability against chosen plaintext attacks (IND-CPA) if for each adversary \nA we have that Adv E (A) is negligible (recall that a function f(n) is negligible if  1 |f(n)| < for \nall suf.ciently large n). Intuitively, poly (n) a polynomial-time adversary cannot identify the plaintext \nfrom a ciphertext with advantage signi.cantly better than that obtained by .ipping a coin. For example, \nit is known that the El Gamal and Paillier cryptosystems satisfy IND-CPA. Unfortunately, IND-CPA is too \nstrong a requirement for deterministic encryption schemes: for example, the adver\u00adsary can store the \nencryptions of x0 and x1 and compare the challenge ciphertext y against the stored ciphertexts. Simi\u00adlarly, \nIND-CPA is too strong for order-preserving schemes. Thus, one de.nes weaker notions of indistinguishability \nfor such schemes. We omit detailed de.nitions (see, e.g., [3, 5, 6]), but assume that each individual \nencryption scheme E has an associated indistinguishability property IND(E). In our context, we have a \nset of inputs x1, . . . , xn to the program and use possibly different encryption schemes E1, . . . , \nEn for them. We ask, given that each scheme Ei sat\u00adis.es IND(Ei), what we can guarantee about the full \nen\u00adcrypted data. To do this, we de.ne the notion of program\u00adindistinguishability for a tuple of encryption \nschemes (see our companion technical report [21] for full details). Intu\u00aditively, the adversary now chooses \ntwo sequences of plain\u00adtexts, according to possible restrictions placed by the IND conditions. Now one \nof the two is chosen at random and componentwise encoded using its encryption scheme. The adversary has \nto guess which of the two sequences was en\u00adcoded by looking at the encrypted vector. Notice that we do \nnot consider the encrypted program in the de.nition, since the adversary can perform an arbitrary polynomial\u00adtime \ncomputation; in particular, it can run the program for a polynomial number of steps. The following theorem \nrestates a result from [2]. Theorem 3. Given encryption schemes Ei satisfying IND(Ei) for i = 1, . . \n. , n, (E1, . . . , En) is program-indistinguishable. Thus, MrCrypt provides a security guarantee that \nis as strong as the individual encryption schemes used for each data item. 5. Implementation We have \nimplemented our encryption scheme inference and transformation algorithms for Java programs. 5.1 Encryption \nSchemes We brie.y describe the encryption schemes that are currently supported in MrCrypt. Since there \nis no ef.cient scheme for FH currently, our system throws an exception if FH is re\u00adquired. (Our experimental \nevaluation shows that this is rarely the case.) In general, we follow the security parameters from prior \nwork [32]. RAND is a probabilistic encryption scheme that guarantees IND-CPA but which does not support \nany operations on the encrypted data. We implement RAND using Blow.sh [39] for 32-bit integers and AES \n[8] for strings in CBC mode and with a random initialization vector. Blow.sh produces a 64\u00adbit ciphertext \nand AES outputs ciphertext as 128-bit blocks. DET is a deterministic encryption scheme: the same plain\u00adtext \ngenerates the same ciphertext. Thus, DE T allows checking for equality on the encrypted values. We make \nthe standard assumption that Blow.sh and AES block ciphers are pseudorandom permutations and use these \nencryption schemes in ECB mode. For values up to 64 and 128 bits, we use Blow.sh and AES respectively \nafter padding smaller plaintexts to at least 64 bits. For longer strings, we use AES with a variant of \nCMC mode [18] with a zero initial vector, as is done in CryptDB [32]. OP is an order-preserving encryption \nscheme that allows checking order relations between encrypted data items. We use the implementation of \nOP in CryptDB, which follows the algorithm in [5]. Since we only do order operations on 32-bit integers, \nwe use a ciphertext size of 64 bits for each value. AH allows performing addition on encrypted data. \nWe use CryptDB s implementation of the Paillier cryptosystem [29] to support AH. We generate 512 bits \nof ciphertext for each 32-bit value. MH allows performing multiplication on encrypted data. We use the \nEl Gamal cryptosystem [10] to support MH . We use 1024-bit ciphertext for each 32-bit integer.  5.2 \nEncryption Scheme Inference MrCrypt is built as an extension to the Polyglot compiler framework [26]. \nPolyglot is designed to allow language ex\u00adtensions and analysis tools to be written on top of a base \ncompiler for Java. MrCrypt is written in Scala and inter\u00adfaces with Polyglot s intermediate representation \nof the Java bytecode. The tool takes as input a Java program and an encryption-scheme lattice and outputs \na translated Java pro\u00adgram which runs on the encrypted domain. It uses Polyglot compiler s data.ow framework \nand soundly handles imper\u00adative updates, aliasing, and arbitrary Java control .ow in the standard way. \nWe omit them from the formalism to isolate the key novelties of our approach. We have extended our inference \nalgorithm in several ways to handle Java programs that employ the Hadoop MapReduce framework; most of \nthese extensions would also be useful in conjunction with other cloud computing frameworks. First, the \nuser-de.ned map function in Hadoop is given a portion of a .le representing the input data and must perform \ncustom processing based on the .le format to parse the data into columns. We require programmers to annotate \nthe parsing code so MrCrypt can understand which variables get values from which columns, which are identi\u00ad.ed \nby number. For example, the user should annotate the following statement, which gets the .fth .eld in \na line of input, with @getColumn(5):  x = L i b r a r y . s p l i t L i n e ( i n p u t ,  ) . g e \nt ( 5 ) ; Similarly, the statement that outputs x as the sixth .eld in a record should be annotated with \n@putColumn(6,x). Second, we have extended the inference algorithm to han\u00addle common data structures. \nThe map function returns a list of key-value pairs and the reduce function accepts a list of values as \nan argument. Further, programmers often use con\u00adtainer data structures such as hashmaps and hashsets \nto re\u00admove duplicates, order elements, etc. Our implementation recognizes these data structures by type \nand encrypts their elements rather than the data structures themselves. In gen\u00aderal our implementation \nuses a single logical variable for the purpose of encryption-scheme inference for a data struc\u00adture s \nelements, ensuring that all elements are encrypted with the same scheme. However, we introduce two logical \nvari\u00adables to handle lists of key-value pairs, so that keys and val\u00adues can use different encryption \nschemes from one another. We also require data structures to be annotated with the op\u00aderations they perform \non their elements, in order to preserve these operations in the encrypted domain. Speci.cally, the standard \nJava hashmap and hashset classes are annotated to require the equality operation on elements. Third, \nthe shuf.e phase of MapReduce sorts the inter\u00admediate keys produced by the map phase, thereby requir\u00ading \nsupport for order comparisons. However, in many cases the .nal output does not depend on the keys being \nsorted, instead just requiring that intermediate values be grouped by their key. Therefore, we allow \nprogrammers to anno\u00adtate that sorting is not required for correctness of the pro\u00adgram, allowing MrCrypt \nto choose deterministic encryption for the keys (which preserves equality, necessary for group\u00ading values \nby key) rather than order-preserving encryption. The shuf.e phase will be performed as usual by the Hadoop \nframework but will no longer guarantee that the underlying plaintext keys are in sorted order.  5.3 \nOptimizations In order to scale to large datasets, we implemented a number of optimizations to the translator \nand runtime which can be categorized as follows: Data serialization. Textual formats are very commonly \nused for MapReduce programs, with numbers represented as decimal strings. This encoding is highly inef.cient \nfor the mostly binary ciphertext data. Hence we use a binary serialization system, Avro3, to store ciphertext. \nTuning Hadoop framework parameters. We tune Hadoop framework parameters such as the number of simultane\u00adous \nmap and reduce tasks, heap size, RAM used for shuf\u00ad.e phase, total number of reduce tasks, block size \nfor the distributed .le system, etc. based on the hardware on which they run. This is a manual process \nwhich depends on the program, data size as well as the cluster resources. These 3 http://avro.apache.org \noptimizations apply equally well to both the plaintext and ci\u00adphertext programs as they have similar \ndata access patterns. Ef.cient encoding of constants. We implemented a simple optimization for the case \nwhen the map function emits con\u00adstant integer values. For example, in the standard MapRe\u00adduce implementation \nof word count the map function emits the tuple (w, 1) for every word w in the input, and the reduce function \nsums up the numbers in the second component of each tuple. While this is ef.cient in the plaintext, the \nAH ciphertext for the number 1 in the translated program is 512 bits long. This causes signi.cant slowdowns \nas the map s output is saved to the disk and read back and the entire data is kept in memory while sorting. \nOur tool applies an optimization whenever either a con\u00adstant integer value or a final variable initialized \nto an con\u00adstant integer value is emitted by the map function. The op\u00adtimization creates a dictionary \nin the translated program which associates symbols (represented by integers) with their ciphertexts. \nIn the word count example, the plain\u00adtext map function contains @putColumn(col0, word) and @putColumn(col1, \n1) for every word and the translated map function contains @putColumn(col1, S) and the re\u00adduce function \nhas access to the dictionary which maps S to the AH ciphertext of 1. 6. Evaluation This section describes \nthe experimental evaluation of Mr-Crypt. We have applied encryption scheme inference to all programs \nin three MapReduce benchmark suites, in order to illustrate the applicability of the approach. We have \nalso ex\u00adecuted programs from one of the three suites on a cluster at scale to determine the run-time \noverhead of executing on encrypted data. Finally, we have used a set of microbench\u00admarks to isolate the \nclient-side and server-side costs of en\u00adcryption. 6.1 Benchmark Programs The three benchmark suites \nare respectively listed in Tables 1, 2 and 3. For each benchmark, we list the number of source lines \nof code determined by the SLOCCount tool4 . PIGMIX25 is a set of 17 benchmark programs written for the \nPig framework, which provides a high-level language for writing large-scale data analysis programs called \nPig Latin [27]. The framework compiles Pig Latin scripts into MapRe\u00adduce programs and the runtime manages \nthe evaluation of these programs. The PIGMIX2 benchmarks each come with Pig Latin scripts as well as \nhand-written MapReduce pro\u00adgrams which the authors believe are ef.cient ways to ex\u00adecute the scripts. \nThe programs run on a dataset primarily comprised of two tables: the PageViews table has 9 columns and \nthe Users table has 6 columns. 4 http://www.dwheeler.com/sloccount/ 5 https://cwiki.apache.org/PIG/pigmix.html \n Pavlo et al. [31] compare the performance of parallel databases that accept SQL queries with equivalent \nMapRe\u00adduce programs. Their evaluation employs a standard word\u00adsearch task [9] along with .ve other MapReduce \nbench\u00admarks that perform various analytics queries6, which we hereafter refer to as the Brown suite. \nThe Purdue MapReduce Benchmarks (PUMA) Suite [1] contains 13 diverse MapReduce programs dealing with \ndif\u00adferent computational and data patterns. In addition to per\u00adforming encryption scheme inference, we \nalso run these benchmarks on the large datasets that are provided with the benchmarks: 50GB Wikipedia \ndocuments for the Word Count, Grep, Inverted Index, Term Vector, and Sequence Count benchmarks; 27GB \nmovies data for the Histogram Movies and Histogram Ratings benchmarks; and upwards of 28GB of synthetic \ndata for the rest of the benchmarks. We made a few modi.cations to the benchmarks to work around current \nlimitations of MrCrypt: The supported encryption schemes do not handle .oating\u00adpoint numbers, so we \nhave converted all benchmarks that use .oating-point numbers to instead use integers.  Our implementation \nof OP supports comparisons for in\u00adtegers but not for strings, necessitating modi.cations to three benchmarks. \nFirst, we modi.ed the Aggregate Vari\u00adant benchmark in the Brown suite to represent an IP ad\u00address as \nfour integers rather than a single string. Second, Self Join in the PUMA suite takes as input alphanumeri\u00adcally \nsorted text consisting of the string entryNum fol\u00adlowed by 10 digits. We modi.ed the input dataset to \nonly include the numbers. Finally, Tera Sort in the PUMA suite sorts a column for which the input data \nconsists of 10 random characters. We restrict the input data for this column to be populated by numeric \ncharacters.  Three benchmarks in PIGMIX2 L8, L15, and L17 compute an average over some columns, which \nrequires support for division. We modi.ed these benchmarks to instead return a pair of the sum and the \nelement count.   6.2 Experimental Setup The experiments were run on the compute cluster at Max Planck \nInstitute for Software Systems. The MapReduce computations were run on two Dell R910 rack servers each \nwith 4 Intel Xeon X7550 2GHz processors, 64 x 16GB Quad Rank RDIMMs memory and 174GB storage. Our experi\u00adments \nran on a total of 64 cores and had access to 1TB of RAM and 348GB of permanent storage. The machines \nwere a shared resource and were under light load from other re\u00adsearch projects. The Hadoop framework \nwas con.gured to run 60 map and reduce tasks in parallel across the 64 avail\u00adable computational units. \nIn addition we used four Dell R910 rack servers (each with 2 Intel Xeon X5650 2.66GHz processors, 48GB \nRAM 6 http://database.cs.brown.edu/projects/mapreduce-vs-dbms and 1TB hard disks) to host the distributed \n.le system. No MapReduce computations were run on these machines and they were only used to serve input \ndata and to store results. These machines were also a shared resource under regular load from other researchers. \n 6.3 Experimental Results We are interested in three key metrics: 1. Annotation burden: How much extra \nwork must the pro\u00adgrammer do to make the existing MapReduce programs run securely? 2. Inference effectiveness: \nDoes MrCrypt .nd the most ef\u00ad.cient encryption scheme? How often is fully homomor\u00adphic encryption required? \n 3. Time and space overhead: How much runtime and stor\u00adage cost does encrypted execution incur?  6.3.1 \nAnnotation Burden As mentioned in the implementation section, MrCrypt re\u00adquires programmers to annotate \nparsing code to correlate variables with the input columns from which they are read. Our simple getColumn \nand putColumn annotations were suf.cient to cover all of the .le formats used in the bench\u00admarks. The \nencryption inference can otherwise be accomplished without any user annotations. However, as mentioned \nearlier, we allow users to annotate the fact that keys in a MapReduce program s output need not be in \nsorted order. We found that sorting is unnecessary in 29 of the 36 benchmarks because the speci.cation \ndoes not require sorted output, so we in\u00adcluded the associated annotation for these programs. On average \nwe added 12 annotations to each benchmark, which amounts to 7% of the lines of code.  6.3.2 Encryption \nScheme Inference Since FH is inef.cient in practice, the utility of our tool depends on whether it is \nable to .nd ef.cient encryption schemes for real-world MapReduce programs. We present the results for \nthe three benchmark suites in Tables 1, 2 and 3. For each benchmark, we measure the source lines of code \nby using the SLOCCount tool7 along with the encryption schemes inferred for the input columns. For each \nencryption scheme the number of columns for which that scheme was inferred is mentioned in parenthesis. \nFor each benchmark, the analysis time was less than 1 second, and the entire compilation time (including \nanalysis and translation) was less than 5 seconds. On 24 of 36 benchmarks, MrCrypt can identify encryp\u00adtion \nschemes to support the necessary functionality without requiring fully homomorphic encryption. Hence \n66.7% of the programs can be executed securely through the system. 7 http://www.dwheeler.com/sloccount/ \n We also manually analyzed each benchmark to verify the correctness of these results. In the four cases \nof the PIGMIX2 suite where FH is re\u00adquired, the programs perform both equality and addition on the same \ncolumn of data, for example to obtain a sum of all distinct values in the column. One of the benchmarks \nin the Brown suite (UDF) invokes performs string operations that MrCrypt does not support, one (Search) \nrequires reg\u00adular expression evaluation, and the other benchmark (Join) performs a sort on data obtained \nby computing a sum over some column. We are not aware of any homomorphic en\u00adcryption scheme other than \nFH supporting both order com\u00adparisons and addition. In the PUMA suite, FH is required for regular-expression \nevaluation (Grep) and for computing cosine similarity (K-means and Classi.cation). Finally, MrCrypt determines \nthat two benchmarks in the PUMA suite require FH for intermediate data produced by the map function. \nFirst, Term Vector counts all occurrences of words in documents and sort them by their frequency. This \nis implemented by using the map function to output (doc-name, word, 1) for every word, and the reduce \nto sum up all the 1s for each word in a document and then sort the words using the sums. Hence the numbers \nare both summed up and compared for order which results in FH for that variable. However, since we need \nto use DET to encrypt the input words to preserve equality, the number of occurrences of each (encrypted) \nword is already being leaked to the adversary. Hence leaving the integers in plaintext would not entail \nany extra loss of con.dentiality, so in fact the benchmark can be executed securely without FH . Second, \nHistogram Movies uses the map function to cal\u00adculate the average rating of each movie rounded to the \nnear\u00adest 0.5. The reduce function then counts the number of movies with the same average rating. This \nfunctionality re\u00adquires addition, division, and rounding operations and hence requires FH . However, \nwe observe that we can refactor the benchmark into two different MapReduce programs to avoid FH . We \nrefer to these two programs as Histogram Movies 1 and Histogram Movies 2, and they are also listed in \nTa\u00adble 3. Histogram Movies 1 performs just the map phase of the original benchmark, with a trivial reduce, \noutputting the sum of all ratings of each movie along with their count. His\u00adtogram Movies 2 takes as \ninput the average rating of each movie and performs just the reduce phase of the original benchmark, \ncounting the number of movies with each av\u00aderage rating. MrCrypt infers encryption schemes for each of \nthese benchmarks that allows them to execute securely with\u00adout requiring FH . To achieve the functionality \nof the original Histogram Movies benchmark, the client must decrypt the AH cipher\u00adtext output from Histogram \nMovies 1, re-encrypt it to use DE T after computing the average and rounding it to the nearest 0.5 (and \nthen doubling it to make it an integer), and provide the resulting ciphertext as input to Histogram Movies \n2. While the client must perform some extra work, it does so on a small amount of data. On our input \ndataset, Histogram Movies 1 operates on 27GB of movie-rating data while Histogram Movies 2 only operates \non 4MB of data that results from summing those ratings per movie (Table 4).  6.3.3 Time and Space Overhead \nOur approach incurs two main sources of performance over\u00adhead, which we evaluate separately. Client-side \nOverhead The client-side overhead consists of the need to encrypt the input data before sending it to \nthe cloud and decrypt the output data from the computation. We evaluated this cost by measuring the time \ntaken for encrypt\u00ading and decrypting 500 random 32-bit integers. The OP , AH, and MH schemes take an \naverage of 10ms, 4ms, and 1.5ms to encrypt each integer, respectively, and less than 0.5ms per decryption. \nBlow.sh (the basis for RAND and DE T ) has much less overhead of 200ns for each encryp\u00adtion and decryption \noperation. Thus, for example, encrypt\u00ading one million data items with AH requires a bit more than one \nhour. However, in our target application domains the en\u00adcryption can be performed incrementally as data \nis gener\u00adated, and the encryption cost is amortized across multiple runs of the cloud computations. Server-side \nOverhead The server-side overhead consists of the need to perform homomorphic operations on encrypted \ndata rather than the original operations on the plaintext data. To isolate this overhead we developed \na set of microbench\u00admarks, each of which performs a single operation one mil\u00adlion times on the input \ndata. For each operation we have one version of the microbenchmark that accepts plaintext integers and \nanother version that uses the appropriate ho\u00admomorphic encryption scheme to operate on ciphertext. We \nuse a corpus of 10,000 32-bit integers and their correspond\u00ading ciphertexts as the input data. The performance \noverhead for encrypted execution is signi.cant: slowdowns of 2\u00d7 for DE T , 4\u00d7 for OP , 500\u00d7 for AH, and \n75\u00d7 for MH . Fortunately, the overheads on real MapReduce bench\u00admarks are much lower, since the homomorphic \noperations contribute only a small percentage of the overall time. To evaluate the overhead of encryption \non real-world data, we ran the PUMA benchmarks at scale on large data on a cluster. For each benchmark, \nwe report the runtime for the original program, and the runtime for the transformed program. We also \nreport the plaintext size and ciphertext size of the input data. We tabulate the results in Table 4. \nThe homomorphic operations add an insigni.cant over\u00adhead and the size of the ciphertext is the main factor \nin deter\u00admining the runtime of the translated programs. On average the translated programs take 2.61\u00d7 \nas long to execute as the original programs. However, Histogram Movies 1 is an out\u00adlier due to the need \nfor AH, which uses 512 bits of ciphertext for each 32-bit integer, on a large amount of data. Excluding \nthis benchmark the translated programs take an average of 1.57\u00d7 as long to execute as the original programs. \n In the three benchmarks where the program operating on ciphertext runs faster than the plaintext program \n(Adjacency List, Self Join, and Tera Sort), the speedup is due to using binary formats for encoding the \nencrypted numbers while the plaintext input uses a particularly inef.cient textual for\u00admat to encode \nnumbers. In these benchmarks, numbers are padded with zeros to keep the length of each column the same \nso as to make use of the built-in sorting algorithm in the shuf.e phase. Hence the number 1 would be \nrepresented as 0000000001. This approach uses 10 bytes to encode the range of 32-bit integers while the \nencrypted data uses at most 8 bytes to store the resulting 64-bit OP ciphertext. The bi\u00adnary format uses \nvariable-length encoding and hence might use fewer than 8 bytes in some cases. 6.4 Discussion Space Ef.ciency. \nEncryption schemes like AH require a signi.cant blowup in space, which has a direct impact on execution \ntime as well. We can reduce the overhead for Pal\u00ad lier encryption (our implementation of AH) using a \npacking optimization [13]. Avoiding Fully Homomorphic Encryption. We showed earlier how refactoring the \nHistogram Movies benchmark can make it amenable to our approach, and we believe there are additional \nopportunities along these lines. For example, four benchmarks that currently require FH require a sum \nof distinct elements functionality, which typically looks as follows: 1 I n t e g e r f ( L i s t < \nI n t e g e r > r e v e n u e s ) { 2 H a s h S e t < I n t e g e r > h s = n e w H a s h S e t < Integer \n>() ; 3 f o r ( I n t e g e r r : r e v e n u e s ) h s . a d d ( r ) ; 4 int sum = 0; 5 f o r ( I n \nt e g e r r : h s ) s u m + = r . i n t V a l u e ( ) ; 6 r e t u r n n e w I n t e g e r ( s u m ) ; \n7 } The revenues column has two operations performed on it: equality (from the hashset) and addition. \nHence our tool infers FH in this case. However, this program can be run securely by keeping two copies \nof the revenues column, one for equality and the other for addition, and keeping a correspondence between \nthem (we use the class P2 for pairs, along with associated operations, from the Java library fj8): 1 \nI n t e g e r f ( L i s t < I n t e g e r > e r e v e n u e s , 2 L i s t < I n t e g e r > a r e v e \nn u e s ) { 3 H a s h S e t < I n t e g e r > h s = n e w H a s h S e t < Integer >() ; 4 L i s t < I \nn t e g e r > d i s t i n c t s = l i s t ( ) ; 5 f o r ( P 2 < I n t e g e r , I n t e g e r > p : 6 \ne r e v e n u e s . z i p ( a r e v e n u e s ) ) { 7 i f ( ! h s . c o n t a i n s ( p . _ 1 ( ) ) ) \n{ 8 http://functionaljava.org/ 8 h s . a d d ( p . _ 1 ( ) ) ; 9 d i s t i n c t s . c o n s ( p . _ \n2 ( ) ) ; 10 } 11 } 12 int sum = 0; 13 f o r ( I n t e g e r r : d i s t i n c t s ) 14 s u m + = r . \ni n t V a l u e ( ) ; 15 r e t u r n n e w I n t e g e r ( s u m ) ; 16 } It would be interesting to \nexplore performing such prepro\u00adcessing automatically in order to extend the applicability of our approach. \n7. Related Work Computing over encrypted data. The problem of (fully) homomorphic encryption was posed \nby Rivest, Adleman, and Dertouzos [34], and the .rst fully homomorphic scheme was discovered by Gentry \n[14]. Implementations of Gentry s construction remains prohibitively expensive [16]. A more ef.cient \nencryption scheme [25] can perform unbounded additions but only a bounded number of multiplications. \nCryptographically secure multi-party computations are also theoretically possible for general circuit \nevaluation [37, 43]. Homomorphic encryption schemes have been proposed to protect data security in several \napplications including secure .nancial transactions [4], secure voting [19], and sensor networks [7]. \nAs discussed in Section 1, the work closest to our own is the CryptDB project [32], which uses homomorphic \nencryp\u00adtion to run queries securely on relational databases. CryptDB encrypts the data in all possible \nencryption schemes, layered on top of each other in a structure resembling our lattice. A trusted proxy \nstands between clients and the database system, analyzes the SQL queries on the .y, and decrypts the \nrelevant columns to the right encryption layers so that the query can be executed. The key difference \nbetween these two efforts is that MrCrypt performs static analy\u00adsis of imperative Java programs while \nCryptDB performs analysis on database queries and so is limited to computa\u00adtions that are expressible \nin pure SQL (i.e., no user-de.ned functions). Further, because MrCrypt has up-front access to the programs, \nit can statically determine the best en\u00adcryption schemes to use, avoiding the need to encrypt data with \nmultiple schemes and to employ a trusted proxy. How\u00adever, encrypting data with multiple schemes allows \nsome queries to be executed using CryptDB that cannot be han\u00addled by our system. Finally, we have formalized \nour ap\u00adproach and proven its correctness and security guarantees, while CryptDB provides only informal \nguarantees. Other work in the database community has used homo\u00admorphic encryption for particular kinds \nof queries. For ex\u00adample, SADS [33] allows encrypted text search and other work uses additive homomorphic \nschemes to support sum and average queries [13]. These systems do not support gen\u00aderal imperative computations. \n Benchmark Lines Of Code Encryption Schemes Inferred for Inputs L1 137 DET(2), RAND(7) L2 148 DET(1), \nRAND(8) L3 185 AH(1), DET(1), RAND(7) L4 141 DET(2), RAND(7) L5 169 DET(1), RAND(8) L6 139 DET(3), FH(1), \nRAND(5) L7 158 DET(1), OP(1), RAND(7) L8 170 AH(2), RAND(7) L9 196 OP(1), RAND(8) L10 245 OP(3), RAND(6) \nL11 184 DET(1), RAND(8) L12 218 AH(1), DET(3), OP(1), RAND(4) L13 182 DET(1), RAND(8) L14 183 DET(1), \nRAND(8) L15 188 DET(2), FH(2), RAND(5) L16 134 DET(1), FH(1), RAND(7) L17 259 FH(5), OP(20) Table 1. \nInference results on the PIGMIX2 benchmarks. Benchmark Lines of Code Encryption Schemes Inferred for \nInputs Search Select Aggregate Aggregate Variant Join UDF 109 71 99 162 518 58 FH(1) OP(1), RAND(2) AH(1), \nDET(1), RAND(7) AH(1), DET(3), RAND(7) AH(1), DET(2), FH(1), OP(1), RAND(4) AH(1), DET(1), FH(1), RAND(6) \n Table 2. Inference results on benchmarks from the Brown suite. Cryptographic schemes have been used \nto provide pri\u00advacy and integrity in systems running on untrusted servers [22, 23]. However, these systems \nhave so far required appli\u00adcation logic to be executed purely on the client. Our goal, on the other hand, \nis to enable computations to run directly on untrusted servers. It may be possible to incorporate ideas \nfrom these systems in order to augment our approach to guarantee integrity in addition to con.dentiality. \nMitchell et al. formalize a domain-speci.c language (DSL) whose type system ensures that programs can \nbe translated to run securely using either FH or secure mul\u00adtiparty computation [24]. They also describe \nan implemen\u00adtation of their DSL embedded in Haskell. This approach can potentially be more expressive \nthan ours but requires pro\u00adgrammers to write programs in a specialized language, while MrCrypt handles \nexisting Java programs with minimal code annotations. Finally, Mitchell et al. do not consider the use \nof partially homomorphic encryption schemes. Static and dynamic analysis for security. There is a large \nbody of work on static and dynamic techniques for enforcing security policies or for .nding security \nvulnerabilities. Most language-based approaches to enforcing con.dentiality are based on the notion of \nsecure information .ow [36]. These approaches are less applicable to the setting of cloud com\u00adputing, \nwhere the adversary can have direct access to the machine on which a computation is being performed. \nFor example, a common threat model in the context of secure information .ow assumes the adversary has \naccess only to the public inputs and outputs of a computation. Researchers have augmented traditional \ninformation-.ow type systems to reason about con.dentiality in the presence of cryptographic operations \n[12, 41], but these approaches require program\u00admers to manually employ cryptography in their programs. \nMrCrypt also leverages static analysis techniques, but for a different purpose to identify the most \nef.cient encryp\u00adtion schemes to use for each input column of data. As de\u00adscribed in our formalism, this \nanalysis is similar to tech\u00adniques for .ow-insensitive type quali.er inference [11, 28]. Computing in \nuntrusted environments. The Excalibur system [38] uses trusted platform modules (TPMs) to guar\u00adantee \nthat privileged cloud administrators cannot inspect or tamper with the contents of a VM. While this approach \npro\u00advides the same security guarantees as MrCrypt, it requires additional investment from the cloud companies \nto install Table 3. Inference results on the PUMA benchmark suite. An asterisk denotes that FH was inferred \nfor an intermediate variable in the benchmark. The Histogram Movies 1 and Histogram Movies 2 benchmarks \nwere created by us and are discussed in Section 6.3.2.  Benchmark Lines Of Code Encryption Schemes Inferred \nfor Inputs Word Count 88 DET(1) Inverted Index 126 DET(1) Term Vector* 187 DET(1) Self Join 136 OP(1) \nAdjacency List 157 OP(2) K-Means 428 DET(1), FH(1), OP(1) Classi.cation 228 DET(1), FH(1), OP(1) Histogram \nMovies* 132 AH(1), RAND(2) Histogram Movies 1 113 AH(1), RAND(2) Histogram Movies 2 98 AH(1), DET(1) \nHistogram Ratings 115 DET(1), RAND(2) Sequence Count 124 DET(1) Ranked Inverted Index 127 DET(4), OP(1) \nTera Sort 192 OP(1), RAND(1) Grep 55 FH(1) Benchmark Original Program Runtime (sec) Transformed Program \nRuntime (sec) Plaintext Size (GB) Ciphertext Size (GB) Word Count Inverted Index Term Vector Self Join \nAdjacency List Histogram Movies 1 Histogram Movies 2 Histogram Ratings Sequence Count Ranked Inverted \nIndex Tera Sort 528 395 556 252 823 138 22 214 492 305 1080 1064 658 1114 234 769 1801 32 427 1006 525 \n1062 50 50 50 28 28 27 0.004 27 50 37.8 28 79 79 79 26.1 26.5 388 0.067 36 79 60.3 26.9 Table 4. Performance \nresults on the PUMA benchmark suite special TPM chips on each node in the cloud and for man\u00adaging keys. \nCLAMP [30] prevents web servers from leaking sensitive user data by isolating code running on behalf \nof one user from that of other users. However, CLAMP does not protect user con.dentiality against honest-but-curious \ncloud administrators. Finally, work on differential privacy for MapReduce (e.g., [35]) is dual to our \nconcern: in that set\u00adting the server is trusted but information exposed to clients is minimized. 8. Conclusion \nData con.dentiality is a key challenge for shared comput\u00ading infrastructures such as cloud computing. \nWe have pre\u00adsented MrCrypt, a practical solution to ensure con.dentiality through the use of homomorphic \nencryption. MrCrypt performs a static analysis on Java programs to identify the most ef.cient homomorphic \nencryption scheme supporting the necessary operations on each column of input data, and it then automatically \nrewrites the program to exe\u00adcute on encrypted data. We have formalized the approach and proven strong \ncorrectness and security guarantees. Our experimental results on three Hadoop MapReduce bench\u00admark suites \nindicate that fully homomorphic encryption is unnecessary most of the time, and as a result a rewritten \npro\u00adgram provides strong con.dentiality guarantees while incur\u00adring only a modest execution-time slowdown. \nAcknowledgments We thank the anonymous reviewers for revision requests that signi.cantly improved the \npaper. We thank Christian Mickler for help with the MPI-SWS cluster. This work is supported in part by \nthe National Science Foundation under awards CCF-1048826 and CNS-1064997.  References [1] F. Ahmad, \nS. Lee, M. Thottethodi, and T. Vijaykumar. Puma: Purdue mapreduce benchmarks suite. Technical Report \nTR\u00adECE-12-11, School of Electrical and Computer Engineering, Purdue University, 2012. URL http://docs.lib.purdue. \nedu/ecetr/437/. [2] O. Baudron, D. Pointcheval, and J. Stern. Extended notions of security for multicast \npublic key cryptosystems. In ICALP 00, volume 1853 of Lecture Notes in Computer Science, pages 499 511. \nSpringer, 2000. [3] M. Bellare, T. Kohno, and C. Namprempre. Authenticated en\u00adcryption in ssh: provably \n.xing the ssh binary packet protocol. In CCS 02, pages 1 11. ACM, 2002. [4] M. Bellare, T. Ristenpart, \nP. Rogaway, and T. Stegers. Format\u00adpreserving encryption. In Selected Areas in Cryptography, volume 5867 \nof Lecture Notes in Computer Science, pages 295 312. Springer, 2009. [5] A. Boldyreva, N. Chenette, Y. \nLee, and A. O Neill. Order\u00adpreserving symmetric encryption. In EUROCRYPT, volume 5479 of Lecture Notes \nin Computer Science, pages 224 241. Springer, 2009. [6] A. Boldyreva, N. Chenette, and A. O Neill. Order-preserving \nencryption revisited: Improved security analysis and alterna\u00adtive solutions. In CRYPTO, volume 6841 of \nLecture Notes in Computer Science, pages 578 595. Springer, 2011. [7] C. Castelluccia, E. Mykletun, and \nG. Tsudik. Ef.cient ag\u00adgregation of encrypted data in wireless sensor networks. In Proceedings of the \nThe Second Annual International Con\u00adference on Mobile and Ubiquitous Systems: Networking and Services, \nMOBIQUITOUS 05, pages 109 117, Washington, DC, USA, 2005. IEEE Computer Society. [8] J. Daemen and V. \nRijmen. The design of Rijndael: AES-the advanced encryption standard. Springer, 2002. [9] J. Dean and \nS. Ghemawat. MapReduce: a .exible data pro\u00adcessing tool. Commun. ACM, 53(1):72 77, 2010. [10] T. ElGamal. \nA public-key cryptosystem and a signature scheme based on discrete logarithms. IEEE Transactions on Information \nTheory, 31(4):469 472, 1985. [11] J.S. Foster, R. Johnson, J. Kodumal, and A. Aiken. Flow\u00adinsensitive \ntype quali.ers. ACM Trans. Program. Lang. Syst., 28(6):1035 1087, November 2006. [12] C. Fournet, J. \nPlanul, and T. Rezk. Information-.ow types for homomorphic encryptions. In Proceedings of the 18th ACM \nconference on Computer and communications security, CCS 11, pages 351 360. ACM, 2011. [13] T. Ge and \nS. Zdonik. Answering aggregation queries in a secure system model. In Proceedings of the 33rd international \nconference on Very large data bases, pages 519 530. VLDB Endowment, 2007. [14] C. Gentry. Fully homomorphic \nencryption using ideal lattices. In STOC 09: Symposium on Theory of Computing. ACM, 2009. [15] C. Gentry. \nComputing arbitrary functions of encrypted data. Commun. ACM, 53(3):97 105, 2010. [16] C. Gentry and \nS. Halevi. Implementing Gentry s fully\u00adhomomorphic encryption scheme. In EUROCRYPT 11, vol\u00adume 6632 of \nLecture Notes in Computer Science, pages 129 148. Springer, 2011. [17] S. Goldwasser and S. Micali. Probabilistic \nencryption. J. Computer and Systems Sciences, 28:270 299, 1984. [18] S. Halevi and P. Rogaway. A tweakable \nenciphering mode. Advances in Cryptology-CRYPTO 2003, pages 482 499, 2003. [19] M. Hirt and K. Sako. \nEf.cient receipt-free voting based on homomorphic encryption. In Proceedings of the 19th interna\u00adtional \nconference on Theory and application of cryptographic techniques, EUROCRYPT 00, pages 539 556, Berlin, \nHei\u00addelberg, 2000. Springer-Verlag. [20] E. Kowalski. Insider threat study: Illicit cyber activity in \nthe information technology and telecommunications sector. Technical report, Technical report, U.S. Secret \nService and CMU, 2008. [21] M. Lesani, R. Majumdar, T. Millstein, and S. Tetali. MrCrypt: Static analysis \nfor secure cloud (technical re\u00adport). http://www.cs.ucla.edu/~lesani/downloads/ submission/MrCrypt.pdf. \n[22] J. Li, M. Krohn, D. Mazi`eres, and D. Shasha. Secure untrusted data repository (sundr). In OSDI \n04: Operating Systems Design and Implementation, pages 91 106. ACM, 2004. [23] P. Mahajan, S. Setty, \nS. Lee, A. Clement, L. Alvisi, M. Dahlin, and M. Wal.sh. Depot: Cloud storage with minimal trust. In \nOSDI 10: Operating Systems Design and Implementation. ACM, 2010. [24] J.C. Mitchell, R. Sharma, D. Stefan, \nand J. Zimmerman. Information-.ow control for programming on encrypted data. In Computer Security Foundations \nSymposium (CSF), 2012 IEEE 25th, pages 45 60. IEEE, 2012. [25] M. Naehrig, K. Lauter, and V. Vaikuntanathan. \nCan homomor\u00adphic encryption be practical? In Proceedings of the 3rd ACM workshop on Cloud computing security \nworkshop, CCSW 11, pages 113 124, New York, NY, USA, 2011. ACM. [26] N. Nystrom, M. Clarkson, and A. \nMyers. Polyglot: An exten\u00adsible compiler framework for java. In Compiler Construction, pages 138 152. \nSpringer, 2003. [27] C. Olston, B. Reed, U. Srivastava, R. Kumar, and A. Tomkins. Pig latin: a not-so-foreign \nlanguage for data processing. In Proceedings of the 2008 ACM SIGMOD international con\u00adference on Management \nof data, SIGMOD 08, pages 1099 1110, New York, NY, USA, 2008. ACM. [28] P. \u00d8rb\u00e6k and J. Palsberg. Trust \nin the .-calculus. Journal of Functional Programming, 7(6):557 591, November 1997. [29] P. Paillier. \nPublic-key cryptosystems based on composite degree residuosity classes. In EUROCRYPT 99: Theory and Applications \nof Cryptographic Techniques, 1999. [30] B. Parno, J.M. McCune, D. Wendlandt, D.G. Andersen, and A. Perrig. \nCLAMP: Practical prevention of large-scale data leaks. In Proceedings of the 2009 30th IEEE Symposium \non Security and Privacy, SP 09, pages 154 169, Washington, DC, USA, 2009. IEEE Computer Society.  [31] \nA. Pavlo, E. Paulson, A. Rasin, D.J. Abadi, D.J. DeWitt, S. Madden, and M. Stonebraker. A comparison \nof approaches to large-scale data analysis. In Proceedings of the 35th SIG-MOD international conference \non Management of data, pages 165 178. ACM, 2009. [32] R.A. Popa, C. Red.eld, N. Zeldovich, and H. Balakrishnan. \nCryptDB: protecting con.dentiality with encrypted query pro\u00adcessing. In Proceedings of the Twenty-Third \nACM Symposium on Operating Systems Principles, pages 85 100. ACM, 2011. [33] M. Raykova, B. Vo, S.M. \nBellovin, and T. Malkin. Secure anonymous database search. In CCSW 09: Cloud Computing Security Workshop, \npages 115 126. ACM, 2009. [34] R. Rivest, L. Adleman, and M.L. Dertouzos. On data banks and privacy homomorphisms. \nIn Foundations of Secure Com\u00adputation, pages 169 179. Academic Press, 1978. [35] I. Roy, S.T.V. Setty, \nA. Kilzer, V. Shmatikov, and E. Witchel. Airavat: Security and privacy for MapReduce. In NSDI, pages \n297 312. USENIX, 2010. [36] A. Sabelfeld and A.C. Myers. Language-based information\u00ad.ow security. IEEE \nJournal on Selected Areas in Communi\u00adcations, 21(1):5 19, 2003. [37] T. Sander, A. Young, and M. Yung. \nNon-interactive crypto\u00adcomputing for NC1 . In FOCS 99: Foundations of Computer Science. IEEE, 1999. [38] \nN. Santos, R. Rodrigues, K.P. Gummadi, and S. Saroiu. Policy-sealed data: A new abstraction for building \ntrusted cloud services. In Usenix Security Symposium. USENIX As\u00adsociation, 2012. [39] B. Schneier. Description \nof a new variable-length key, 64-bit block cipher (blow.sh). In Fast Software Encryption, pages 191 204. \nSpringer, 1994. [40] B. Schneier. Applied cryptography. Wiley, 2nd edition, 1996. [41] J.A. Vaughan. \nAuraconf: a uni.ed approach to authorization and con.dentiality. In Proceedings of the 7th ACM SIGPLAN \nworkshop on Types in language design and implementation, TLDI 11, pages 45 58, New York, NY, USA, 2011. \nACM. [42] A.K. Wright and M. Felleisen. A syntactic approach to type soundness. Information and Computation, \n115(1):38 94, 1994. [43] A. Yao. How to generate and exchange secrets. In FOCS 86: Foundations of Computer \nScience, pages 162 167. IEEE, 1986.     \n\t\t\t", "proc_id": "2509136", "abstract": "<p>In a common use case for cloud computing, clients upload data and computation to servers that are managed by a third-party infrastructure provider. We describe MrCrypt, a system that provides data confidentiality in this setting by executing client computations on encrypted data. MrCrypt statically analyzes a program to identify the set of operations on each input data column, in order to select an appropriate homomorphic encryption scheme for that column, and then transforms the program to operate over encrypted data. The encrypted data and transformed program are uploaded to the server and executed as usual, and the result of the computation is decrypted on the client side. We have implemented MrCrypt for Java and illustrate its practicality on three standard benchmark suites for the Hadoop MapReduce framework. We have also formalized the approach and proven several soundness and security guarantees.</p>", "authors": [{"name": "Sai Deep Tetali", "author_profile_id": "81453646997", "affiliation": "University of California, Los Angeles, Los Angeles, CA, USA", "person_id": "P4290353", "email_address": "saideep@cs.ucla.edu", "orcid_id": ""}, {"name": "Mohsen Lesani", "author_profile_id": "81481651756", "affiliation": "University of California, Los Angeles, Los Angeles, CA, USA", "person_id": "P4290354", "email_address": "lesani@cs.ucla.edu", "orcid_id": ""}, {"name": "Rupak Majumdar", "author_profile_id": "81100319213", "affiliation": "Max Planck Institute for Software Systems, Kaiserslautern, Germany", "person_id": "P4290355", "email_address": "rupak@mpi-sws.org", "orcid_id": ""}, {"name": "Todd Millstein", "author_profile_id": "81100018064", "affiliation": "University of California, Los Angeles, Los Angeles, CA, USA", "person_id": "P4290356", "email_address": "todd@cs.ucla.edu", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509554", "year": "2013", "article_id": "2509554", "conference": "OOPSLA", "title": "MrCrypt: static analysis for secure cloud computations", "url": "http://dl.acm.org/citation.cfm?id=2509554"}