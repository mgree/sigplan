{"article_publication_date": "10-29-2013", "fulltext": "\n Resurrector: A Tunable Object Lifetime Pro.ling Technique for Optimizing Real-World Programs Guoqing \nXu University of California, Irvine guoqingx@ics.uci.edu Abstract Modern object-oriented applications \ncommonly suffer from severe performance problems that need to be optimized away for increased ef.ciency \nand user satisfaction. Many existing optimization techniques (such as object pooling and pretenuring) \nrequire precise identi.cation of object life\u00adtimes. However, it is particularly challenging to obtain \nob\u00adject lifetimes both precisely and ef.ciently: precise pro.ling techniques such as Merlin introduce \nseveral hundred times slowdown even for small programs while ef.cient approxi\u00admation techniques often \nsacri.ce precision and produce less useful lifetime information. This paper presents a tunable pro.ling \ntechnique, called Resurrector, that explores the middle ground between high precision and high ef.ciency \nto .nd the precision-ef.ciency sweetspot for various liveness\u00adbased optimization techniques. Our evaluation \nshows that Resurrector is both more precise and more ef.cient than the GC-based approximation, and it \nis orders-of-magnitude faster than Merlin. To demonstrate Resurrector s usefulness, we have developed \nclient analyses to .nd allocation sites that create large data structures with disjoint lifetimes. By \ninspecting program source code and reusing data structures created from these allocation sites, we have \nachieved signif\u00adicant performance gains. We have also improved the preci\u00adsion of an existing optimization \ntechnique using the lifetime information collected by Resurrector. Categories and Subject Descriptors \nD.3.4 [Programming Languages]: Processors Memory management, optimiza\u00adtion, run-time environments; F.3.2 \n[Logics and Meaning of Programs]: Semantics of Programming Languages Program analysis Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. Copyrights for components of this work owned by others \nthan ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post \non servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Request permissions \nfrom permissions@acm.org. OOPSLA 13, October 29 31, 2013, Indianapolis, Indiana, USA. Copyright c &#38;#169; \n2013 ACM 978-1-4503-2374-1/13/10. . . $15.00. http://dx.doi.org/10.1145/2509136.2509512 General Terms \nLanguage, Measurements, Performance Keywords object lifetime information, memory manage\u00adment, performance \noptimization 1. Introduction Large-scale object-oriented programs commonly suffer from systemic performance \nproblems that have signi.cant impact on their scalability and real-world usefulness. Evidence sug\u00adgests \nthat these problems stem from a combination of the performance-oblivious design/implementation principles \nas well as large amounts of input data that need to be quickly processed [37, 55]. Runtime bloat exists \nthroughout the ex\u00adecution, making it dif.cult for the compiler to .nd and re\u00admove its performance penalty. \nTo attack the problem, vari\u00adous techniques [7, 7, 13, 15, 16, 21, 23, 25, 32, 35, 36, 43, 44, 48, 50, \n58] have been developed to help programmers detect and .x performance problems. Motivation One major \ncategory of these techniques (e.g., [7, 13, 16, 21, 25, 32, 48, 50, 58]) concerns the reduc\u00adtion of objects \nand data structures. Because object-oriented applications typically create and destroy large numbers \nof objects, creating, initializing, and destroying them consumes much execution time and memory space. \nFor example, in the white paper WebSphere Application Server Development Best Practices for Performance \nand Scalability [1], four of the eighteen best practices are instructions to avoid repeated creation \nof identical objects. One important observation that motivates these techniques is that in large-scale \napplications, objects created for different tasks (e.g., iterations of an event loop, database transactions, \netc.) often have disjoint lifetimes and can never be used simultaneously. Reusing existing ob\u00adjects and \ndata structures in the heap can often lead to sub\u00adstantial reductions of time and memory footprint. Key \nto any technique that attempts to reduce numbers of objects and their related computation is the precise \nun\u00adderstanding of object lifetimes. For example, object equality pro.ling (OEP) [32] needs object lifetimes \nto .nd merge\u00adable objects and our recent work from [50] can reuse data structures only if their lifetimes \ndo not overlap. Of particular interest is to know precisely the lifetimes of objects created by the same \nallocation site, because optimizations are of\u00adten performed at the allocation site level. For example, \nif the lifetimes of the objects created by an allocation site are com\u00adpletely disjoint, one single object \nwill be suf.cient through\u00adout the execution; if the allocation site is in a loop, it may be hoistable \n[58], or at least a singleton pattern can be ap\u00adplied to improve performance [7, 50]. In addition, existing \npretenuring techniques [10, 12, 14, 33] often rely on precise allocation-site-based lifetime pro.les \nto allocate likely long\u00adlived objects into an infrequently or never collected region. Recent work on \nHeadroom-based pretenuring [42] has found that pretenuring can bene.t more from .ner-grained lifetime \ninformation than from the simple estimation of long-lived objects.  Problems While such precise information \nabout object lifetimes is highly desirable, there does not exist any algo\u00adrithm that can compute it ef.ciently. \nA number of static analyses (such as [13, 16, 21, 22, 25, 48, 58]) have been developed to approximate \nobject lifetimes. However, static analysis usually does not perform well in the presence of large numbers \nof heap accesses that commonly exist in large\u00adscale programs. In addition, it often falls short in answering \nqueries that require dynamic information, such as how many run-time objects can be simultaneously live \nfor an allocation site, which is important for many optimization techniques. Merlin [26] is by far the \nmost precise dynamic object lifetime pro.ling (OLP) technique. It generates an object event trace and \nuses a backward pass to transitively re\u00adcover object death points. While Merlin can precisely com\u00adpute \nobject lifetime information, it suffers from tremendous run-time overhead that signi.cantly reduces its \nreal-world practicality. For example, our experiments show that Ele\u00adphant Tracks a recent implementation \nof the Merlin algo\u00adrithm [41] incurs an average 752.4\u00d7 slowdown during the execution of the DaCapo benchmarks \n[9] under small work\u00adloads. To improve scalability, approximations have been em\u00adployed to estimate object \nlifetimes. A common approxima\u00adtion is to use the GC point at which an object is collected as its death \npoint. However, GC may occur far behind the ac\u00adtual point at which the object becomes unreachable. Hence, \nsigni.cant imprecision may result, leading to reduced use\u00adfulness of the client analysis. Other work \nsuch as [50] devel\u00adops metrics to approximate lifetime information, which can also cause rather imprecise \nhandling. For example, all false positives reported by the reusable object analysis in [50] are due to \nthe imprecise approximation of object lifetimes. Our Proposal In this paper, we present a novel dy\u00adnamic \ntechnique, called Resurrector, that explores the mid\u00addle ground between high precision and high ef.ciency \nto .nd the precision-scalability sweetspot for various optimiza\u00adtion techniques. Resurrector s design \nis motivated by an im\u00adportant observation that the scalability bottleneck of a tra\u00additional OLP algorithm \n(such as Merlin) lies in the need to compute transitive closures on the dead objects (e.g., Mer\u00adlin s \nbackward pass). Resurrector improves ef.ciency by completely eliminating this need. Similarly to Merlin, \nRes\u00adurrector .rst identi.es the root dead objects whose refer\u00adence counts are zero. Instead of computing \ntransitive clo\u00adsures from them, Resurrector exploits object caching and reusing to .nd dead objects (transitively \nreachable from the roots) that have non-zero reference counts. Resurrector caches and reuses objects \nbased on their al\u00adlocation sites. Upon the execution of an allocation site, the Resurrector allocator \n.rst attempts to .nd an object that was previously created from the allocation site and that is cur\u00adrently \nunreachable. If the attempt fails, the regular object allocator is invoked to create a new object and \nResurrector caches it into a list for this allocation site. If such a dead ob\u00adject o is found, Resurrector \nrecords its death and returns it to the application. Resurrecting o will cause it to be reinitial\u00adized \n(by the object initializer), which automatically forces the dead objects pointed to by o to lose references \nand be\u00adcome unreachable. Hence, their death points can be detected by Resurrector as if they were root \ndead objects. These ob\u00adjects will be subsequently resurrected when their allocation sites are executed. \nThe resurrection process is repeated un\u00adtil all transitively dead objects under o in the object graph \nhave zero references. In other words, Resurrector resurrects dead objects and leverages the mutator execution \nto compute transitive closures, leading to elimination of an additional reachability analysis to identify \ndead objects. Information regarding the maximal number of objects whose lifetimes can overlap for an \nallocation site, as required by many of the aforementioned techniques, can be closely approximated by \nidentifying the maximal length of the cache list for the allo\u00adcation site during execution. The Resurrector \nalgorithm requires precise identi.cation of the point at which an object becomes unreachable in or\u00adder \nto determine whether this object is resurrectable. Count\u00ading only heap references does not suf.ce, because \nthe object may still be referenced by stack variables even if the number of its heap references is zero. \nTracking every stack and reg\u00adister update can be very expensive. To solve the problem, we develop an \nef.cient timestamp-based algorithm that enables Resurrector to identify a dead object soon after it becomes \nunreachable without relying on GC. Precision and Scalability Comparison A graphical comparison among \nthe precision and ef.ciency of Merlin, Resurrector, and the GC-based approximation is shown in Figure \n1. In general, Resurrector is much more precise than the GC-based approximation. For both Resurrector \nand the GC-based approximation, there is a delay between the death point of an object and the point at \nwhich its death is de\u00adtected. The delay incurred by Resurrector is often much shorter the death of the \nobject is detected within a very small number of executions of its allocation site, while, us\u00ading the \nGC-based approximation, the object s death cannot be detected until the next GC. In a large-scale application, \nthe execution frequency of an allocation site can be orders  Efficiency User-tunable cost and precision \n 6.7X for DaCapo- Resurrector small GC-based Merlin 752X for DaCapo\u00adsmall Precision Very imprecise Figure \n1. A precision-ef.ciency comparison among Merlin, Resurrector, and the GC-based approximation. of magnitude \nhigher than that of GC. Figure 2 uses a simple example to compare the object lifetimes collected by Resur\u00adrector \nand by the GC-based approach. We use Oi to denote the i-th object created by the allocation site, and \nA : Oi and D : Oi to denote the creation and death events of the object. For Resurrector, the death of \nobject Oi (created in the i-th iteration of the loop) is detected upon the next execution of the allocation \nsite (i.e., in the (i+ 1)-th iteration), while the GC-based approach has to wait until the next GC occurs. \nDuring our experiments, we found that Resurrector is much more ef.cient than Merlin and, in most cases, \neven more ef.cient than the GC-based approach. Resurrector does not need the heap reachability analysis \nused by Mer\u00adlin to identify dead objects; this task is being performed along with the mutator execution. \nIt is less obvious to see why Resurrector has better performance than the GC\u00adbased approach the primary \nreason is that the GC-based approach needs to .nd all unreachable objects from the heap and record their \ndeath during each GC, which incurs a heavy running time overhead; Resurrector, however, iden\u00adti.es death \npoints for most objects during the Mutator exe\u00adcution, and does not rely on GC to .nd unreachable objects \nand report death events. To further improve Resurrector s practicality, we use the number of objects \ncached for each allocation site as a tun\u00ading parameter to adjust Resurrector s precision and scala\u00adbility. \nThe more objects an allocation site caches, the more precise lifetime information Resurrector may produce \nand the higher overhead Resurrector may incur. We demonstrate, using experiments on real-world applications, \nthat Resur\u00adrector is precise in .nding optimization opportunities even when the threshold parameter is \nsmall, and yet it is ef.cient enough to be able to scale to large applications. Resurrector has immediate \nbene.t for all the existing op\u00adtimization techniques that require precise understandings of object lifetimes. \nTo demonstrate this bene.t, we have imple\u00admented a client analysis that uses the Resurrector-collected \nfor (int i = 0; i < N; i++) {O o = new O(); } Resurrector Iter#0 Iter#1 Iter#2 Iter#3 Iter#4 Iter#5 \nIter #  A:O0 A:O1 A:O2 A:O3 A:O4 A:O5 D:O0 D:O1 D:O2 D:O3 D:O4 Iter#0 Iter#1 Iter#2 Iter#3 Iter#i GC \n A:O0 A:O1 A:O2 A:O3 A:Oi D:O0 D:O1 GC.based Approximation D:Oi Figure 2. A graphical comparison between \nthe lifetime in\u00adformation collected by Resurrector and by the GC-based ap\u00adproach. data structures, we \nhave achieved signi.cant performance gains (e.g., speed up a large program by 5\u00d7). This experi\u00adence is \ndescribed in the 4 case studies in Section 5. Resurrec\u00adtor has also been used to improve the optimization \ntechnique in our previous work [50]. The results show that the Resur\u00adrector pro.les can signi.cantly \nreduce numbers of false pos\u00aditives. We have implemented Resurrector in Jikes RVM 3.1.3, a high performance \nresearch virtual machine written in Java, and successfully applied it to real-world applications. An \nevaluation of Resurrector on a set of 10 DaCapo programs (i.e., in its 2006 release) is described in \nSection 5. Vary\u00ading the tuning parameter in the range [1, 500] results in an overall 1.3\u00d7 6.0\u00d7 space \noverhead and 2.3\u00d7 13\u00d7 time overhead (under the DaCapo large workloads). Resurrec\u00adtor is publicly available \nat the Jikes RVM Research Archive (http://jikesrvm.org/Research+Archive). The contributions of this paper \nare: A novel lifetime pro.ling algorithm that supports user\u00adtunable precision and scalability;  an \nimplementation of this algorithm in the Jikes RVM that provides compiler and runtime system support to \nreuse objects and collect their lifetimes;  two client analyses that use this technique to identify \nlifetime-disjoint data structures;  an evaluation on a set of large-scale, real-world applica\u00adtions \nshowing that the precision of Resurrector is close to that of Merlin while it is orders of magnitude \nmore ef.cient than Merlin;  four case studies demonstrating that the Resurrector life\u00adtime information \ncan help programmers quickly identify reuse opportunities and .x problems for large perfor\u00admance gains. \n 2. Overview lifetime information to .nd large data structures that have This section presents an overview \nof the Resurrector OLP disjoint lifetimes. By inspecting and reusing the reported technique. Figure 3 \n(a) shows a simple program that keeps IC List: IC List: foo:1 1foo: 1 O18 1 :A[] O18 :A[] Cache list \nof bar: 2 bar: 4 rc:0 set:80set:40 alloc site 18 m:bar 13 String s = a.get(); get:2 1 class A{ 14 print(s); \nts:1 2 Object data; 1 get:0 1 2 21 15 } O20 20:A O20 O20 O20 O20 :A 3 A() { data = null; } 16 } 4 Object \nget() 5 { Object r = this.data; 17 A bar(int index){ 6 return r; } 18 A[] arr = new A[20]; 7 void set(Object \no) 19 for(int i = 0; i < 20; i++){ 8 { this.data = o; } 20 arr[i] = new A(); 9 } 21 arr[i].set 22 (new \nString( RES )); 10 void foo() { 23 } 11 for(int j = 0; j < 5; j++) { 24 return arr[index]; 21 12 A \na = bar(0); 25 } O22 20:String O22 :String (c) Heap snapshot right before the second (a) A simple program \nthat uses data structures invocation of bar returns  Figure 3. Asimple program and graphical illustrations \nof its run-time heap. creating and using data structures. Despite the simplicity of the program, these \ndata structures have multiple layers of objects; pro.ling their lifetimes using a traditional approach \n(such as Merlin) would require a reachability analysis that transitively identi.es the death point for \neach object from the root (e.g., the array of type A created at line 18). In this section, we show how \nResurrector eliminates the need to perform such a reachability analysis. As our focus is on the illustration \nof the basic idea, we assume the number of objects an allocation site can cache is unbounded. Figure \n3 (b) and (c) illustrate the two heap snapshots right before the .rst and the second invocation of method \nbar .nishes, respectively. Each run-time object is represented by j O, where i is the ID of its allocation \nsite and j indicates i that the object is the j-th object created by allocation site i. In this example, \nthe line number of an allocation site is used as its ID. Each solid arrow represents a reference edge \nand each dashed line represents an object cache list for an allocation site. For simplicity, we assume \nthis example has only one thread running, and thus, there is one cache list per allocation site. Tracking \nInformation As discussed in Section 1, when an allocation site is executed, Resurrector needs to know \nwhether there exists a cached object that is dead and resur\u00adrectable. To precisely track the death point \nfor each object, we associate with the object four pieces of tracking informa\u00adtion: its allocation site \nID (alloc ), its reference count (rc), the ID of the method where the object may be captured (m), and \na timestamp that records the invocation count (which will be discussed shortly) of m at the moment the \nobject .ows into m (ts ). Following the escape analysis terminol\u00adogy [13, 16, 21, 48], an object is captured \nin a method if it does not escape the method boundary. Reference count rc is used to identify when the \nobject becomes unreachable in the heap, while the method-related information (i.e., m and ts ) is used \nto .nd when the object loses all its stack references. Because tracking the updates of stack variables \ncan be very expensive, we take an ef.cient approach Resurrector con\u00adsiders the return point of the object \ns capturing method as the point at which the object loses all its stack references. While the object \nmay actually become unreachable from the stack earlier (e.g., when the execution leaves the control .ow \nregion in which its pointer variable is declared), this return point is often not far away and yet is \neasy to detect. Future work may consider to perform a precise static liveness anal\u00adysis to identify the \nliveness scope for each object, which can then be fed to the runtime system for improved lifetime pre\u00adcision. \nDetermining Object Lifetimes rc is incremented every time a reference of the object is assigned to a \nheap loca\u00adtion and is decremented every time its reference is removed from a heap location. This can \nbe easily done by instrument\u00ading heap loads and stores. To correctly identify the return point of the \nobject s capturing method, Resurrector main\u00adtains an invocation count (IC) for each method in the pro\u00adgram. \nIn particular, the IC of a method is incremented twice for each invocation of the method, once at the \nbeginning of the invocation and once at the end. Each method has its own counting system, and ICs of \ndifferent methods are counted independently of each other. For example, within the .rst execution of \nmethod bar, its IC is 1; during the period af\u00adter this invocation .nishes and before the next invocation \nstarts, its IC is 2. In this section, we focus our discussion on recursion-free programs; the handling \nof recursion and other advanced language features will be discussed shortly in Sec\u00adtion 3. Clearly, the \nIC of a method is always an odd number if it is on the call stack, and it is always an even number otherwise. \nObject o may .ow to a method on the stack and be cap\u00adtured there in the following three cases. First, \no is created and its reference is immediately written into a stack variable. In this case, o s m and \nts are assigned the ID of its creating method and the current IC of the method, respectively. Sec\u00adond, \no is returned from a callee to a caller. In this case, m  Figure 4. A Resurrector object in the heap. \nand ts may be updated with the method and IC information of the caller. Finally, a reference of the object \nis assigned to a stack variable through a heap load. In this case, m and ts may be updated with the corresponding \ninformation of the method invocation in which this load occurs. Note that o can be captured in a method \nonly if none of the callers of the method on the stack have a reference to it. Therefore, our goal is \nto keep track of the lowest method on the call stack where the object is referenced. To do this, before \nRes\u00adurrector updates o.m and o.ts , it always veri.es whether the (old) method recorded in o.m has returned. \nFor a recursion\u00adfree program, this veri.cation can be easily done by checking whether o.m s current IC \nis greater than o.ts . If o.m s cur\u00adrent IC is equal to o.ts (indicating that o.m is still on the call \nstack), o.m and o.ts do not need to be updated, because o.m must be lower than (i.e., a caller of) the \ncurrent method. Note that parameter passing is not tracked in Resurrector, because an object passed from \na caller to a callee can never be captured in the callee. Figure 4 illustrates a typical object in the \nResurrector execution. For each method on the stack, its current (per-method) IC is shown in the parentheses. \nThe object is referenced by three heap locations, and thus, its rc is 3. While it is referenced in four \nmethods, its m and ts record the invocation information of m1, which is the lowest method on the stack \namong them1. After the current invocation of m1 returns, m1 s IC must be at least 8, which will be greater \nthan the object s ts (7). It is easy to see that an object o is ready to be resurrected if o.m s IC is \ngreater than o.ts and o.rc is 0. Example To illustrate, consider the .rst invocation of method bar. The \ninitial m and ts for all objects created in bar are bar and 1, respectively. Allocation site 20 is executed \n20 times. At each time, the Resurrector allocator attempts to .nd a dead object from the cache list (for \nallocation site 20), that is, an object such that its reference count is 0 and its capturing method m \ns current IC is greater than its ts . Obviously, such an attempt fails because all the existing A objects \ncreated at line 20 have non-zero reference counts and their capturing method (bar) s IC is equal to their \nts , indicating that the method has not returned yet. Hence, a 1For clarity of presentation, we use the \nname of a method as its ID in the paper. fresh A object is created and stored in line 20 s cache list. \nAt the end of this invocation, the cache lists for both line 20 and line 22 have 20 objects, as shown \nin Figure 3 (a). Note that although O1 is passed into set, its m and ts are not 22 updated because bar \nis lower than set. Right before the the .rst invocation of bar .nishes, bar s IC becomes 2. Resurrector \n.nds the return object (O1 20 )and attempts to update its m and ts with, respectively, the ID of the \ncaller (foo)and the current IC of the caller (1). Before the update, it checks whether the method recorded \nin O1 20 .m has .nished. The attempt succeeds because bar s IC (2) is now greater than O1 20 .ts (1). \nNote that the objects reachable from O1 22 )are not updated at this moment because 20 (e.g., O1 they \ndo not .ow to the stack. O1 22 is updated later when line 13 is invoked its m is changed to foo (due \nto the return at line 6) and its ts is changed to 1 (i.e., foo s IC), as shown in Figure 3 (b). During \nbar s second invocation, the array (O1 cre\u00ad 18 ) ated in the previous invocation of bar is resurrected \nby Resurrector it is the only object on line 18 s cache list, its rc is 0, and its capturing method (bar) \ns current IC is 3, which is greater than its ts (1). Resurrector determines it is a dead object, and \nresurrects it by cleaning up its contents and returning it to the application. This resurrection point \nis recognized as the death point of the old O1 18 and the cre\u00adation point of the new O1 18 . The two \nevents are recorded in a trace if Resurrector s trace generation option is enabled. This point can be \nmuch earlier than the GC point at which the old O1 is collected (in a non-Resurrector execution), 18 \nwhich explains Resurrector s high precision over the GC\u00adbased approach in most cases. Cleaning up O1 \n18 s contents includes three steps: decre\u00admenting rc of each object it directly references, zeroing the \narray, and reinitializing its tracking information. Its m and ts now become bar and 3, respectively. \nAfter O1 is res\u00ad 18 20 O20 urrected, rc of all the 20 cached A objects (O1 be\u00ad 20 ) comes 0. Upon the \nexecution of line 20, Resurrector inspects object O1 20 is 20 , which is the .rst cached object on the \nlist. O1 not resurrectable although its rc is 0, its capturing method (foo) s current IC is equal to \nits ts . However, O2 is resur\u00ad 20 rectable, because it was captured in a .nished invocation of bar. This \ncan be seen from the fact that bar s current IC (3) is greater than O2 20 s ts (1). Subsequently, the \nresurrection of O2 20 decrements the ref\u00aderence count of O2 22 , making it resurrectable. It is resurrected \nwhen line 22 is executed. In the second invocation of bar, when the loop at line 19 terminates, 19 A \nobjects created in the previous invocation of bar have been reused and one new A object (O21 20 )has \nbeen created. Hence, line 20 s cache list now contains 21 objects, as shown in Figure 3 (b). Before bar \ns second invocation .nishes, O2 20 is about to be returned, and its m and ts are updated with foo and \n1, respectively (similarly to the update of O1 20 in the previous invocation).  It is easy to calculate \nthat at the moment the loop at line 11 terminates, there are totally 24 objects on line 20 s cache list. \nThis is very close to the actual number of objects that are needed simultaneously for allocation site \n20 (which is 20). The difference is due to the use of the return point of an object s capturing method \nas the point at which the object loses all stack references. For example, even if object O1 escapes to \nfoo, it will never be used after the .rst 20 iteration of the loop (at line 11) .nishes. Hence, it is \nactually resurrectable in the second invocation of bar. Understanding that O1 20 s lifetime is within \nthe .rst iteration of the loop requires a precise static liveness analysis, such as the one proposed \nin [28]. It is worth investigating, in the future work, how this technique can be incorporated into Resurrector \nand how much precision improvement may result from it. Note that if the GC-based approximation is used \nto compute this number, it is very likely that we will get 100 (if GC occurs after method foo returns). \n3. The Resurrector Pro.ling Technique This section presents the core technique of Resurrector. Res\u00adurrector \nsupports precise handling of all important features of Java, including multithreading, re.ection, recursion, \nand exception handling. We .rst describe our baseline algorithm (for programs without recursive methods \nand exceptions), and then we gradually modify the baseline algorithm to con\u00adsider more advanced language \nfeatures.  3.1 Preliminaries We begin by formalizing notions of operations, events, and execution traces. \nA program consists of a number of con\u00adcurrently executing threads, each with a thread identi.er t . Tid \n, and these threads call methods m . Mid , which manipulate (reference-typed) variables x . Var . A method \ncontains allocation sites a . Alloc , which create run-time objects o . Obj . An object o has a set of \n.elds f . F , each of which speci.es the offset of a location in o. An environ\u00adment . . Var . Obj . {null \n}maps each variable to the object it points to or a null value. Each o is associated with a 6-tuple tracking \ninformation (gid ,rc ,m,t,ts ,dm ): a global object ID gid . Nat , a heap reference count rc . Nat , \na method ID m . Mid , a thread ID t . Tid , a timestamp ts . Nat , and a death mark dm . {T, F }. gid \nuniquely identi.es the object during the whole execution. In a multi\u00adthreaded program, we use m and t \nto identify the capturing method of the object. The death mark dm is a boolean .ag, indicating whether \nthe death point of the object has already been recorded. Note that this tuple includes all the informa\u00adtion \nneeded by a client analysis. Various optimizations can be performed to reduce the unnecessary information \nto save space. Each method m has an invocation count vector IV : Tid . Nat , which records m s invocation \ncount in each thread in the system. The set of operations that a thread t can perform includes: new \n(t, a), which creates an object at allocation site a;  store(t, x1.f , x2) and load(t, x2, x1.f ), which, \nrespec\u00adtively, writes the (reference) value of x2 into and reads it from .eld f of the object referenced \nby x1;  enter(t, m)and exit(t, m), which enters and exits method m;  return (t, x), which returns the \nobject pointed to by x to the caller;  Note that an exit operation must be followed immedi\u00adately by \na return operation, which may or may not return any value. A thread t has a method stack S : Nat . Mid \n. A method m is pushed onto the stack when thread t enters it and is popped out when t exits it. Each \nallocation site a has an object cache list L : Nat . Obj per thread t. In other words, a maintains a \ncache list vector LV : Tid . L. Caching objects on a per-thread basis allows the concurrent execution \nof the dead object retrieval and resurrection; oth\u00aderwise, heavy synchronization has to be performed \nat each allocation site to guarantee thread safety. An object event e . Eve is generated when an object \nis created or when Resurrector determines the object is dead. In Resurrector, e is a triple (gts ,gid \n, ' A ' | ' D '), where gts . Nat is a global timestamp indicating when this event occurs. In the memory \nmanagement literature, bytes of allocation is often used as a metric to measure time. gid is the global \nID of the object and ' A ' ( ' D ' ) indicates that the event is an allocation (death) event. Resurrector \neventually collects a trace a of events, in ' D ' which the timestamp distance between the event and \nthe ' A ' event of the same object determines the lifetime of the object.  3.2 The Baseline Algorithm \nThis subsection describes the core Resurrector OLP algo\u00adrithm. Resurrector s analysis state includes: \nInvocation count map I : Mid . IV Method stack map T : Tid . S Alloc site cache map C : Alloc . LV Object \nevent trace a : e, a | o Resurrector s instrumentation semantics at the seven op\u00aderations are shown in \nAlgorithm 1 7, each of which reads and/or updates the analysis state. Algorithm 1 (that handles allocation \nsites) .rst retrieves the current method on the call stack of thread t (line 2), which will be used later \nto up\u00addate m and ts of the newly created object. As described in Section 2, Resurrector iterates through \na s cache list in t (de\u00adnoted as C(a)(t)) to .nd a dead object created previously by a (line 3 22). The \ncondition in line 6 shows Resurrector s criterion of selecting dead objects an object o is dead and resurrectable \nif o.rc is 0 and the invocation count of its cap\u00adturing method o.m in thread o.t (denoted as I(o.m)(o.t)) \nis  Algorithm 1: The modi.ed semantics of new (t, a). Algorithm 3: Instrumentation before load (t, x2, \nx1.f ). Input: Thread t, Allocation site a Output: New object ret 1 Object ret . null 2 Method currMet \n. T(t)0 3 foreach index i . [0, |C(a)(t)|) do 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \nif 24 25 26 27 28 29 30 31 32 /*Iterate through a s cache list in t*/ Object o . C(a)(t)i if o.rc = 0 \n. I(o.m)(o.t) > o.ts . (\u00acisArray(o). length(o)= requestedLength(a)) then /*Found a dead object*/ ret \n. o if o.dm = F then ' a .append(a, (globalTS(), o.gid , D ' )) else o.dm . F o.gid . newGID() o.rc . \n0 o.m . currMet o.t . t o.ts . I(currMet )(t) foreach reference-typed .eld f in o do ' Object o . o.f \n' if o = null then ' ' o .rc . o .rc - 1 break ret = null /*No object has been resurrected*/ then ret \n.allocNew() ret .gid . newGID() ret .rc . 0 ret .dm . F ret .m . currMet ret .t . t ret .ts . I(currMet \n)(t) Cache list l . C (a)(t) l . append(l, ret ) 33 else 34 /*move object ret to the end of the list \nC(a)(t)*/ ' 35 a .append(a, (globalTS(), ret .gid , A ' )) 36 zeroMemory(ret ) 37 return ret Algorithm \n2: Instrumentation before store (t, x1.f , x2). Input: Thread t, Field dereference expression x1 .f , \nvariable x2 1 Object o1 . .(x1 ) 2 Object o2 . .(x2 ) ' 3 Object o . o1 .f '' 4 if o null /*Update rc \nof o = */ then ' ' 5 o .rc . o .rc - 1 6 if o2 = null /*Update rc of o2 */ then 7 o2 .rc . o2 .rc + 1 \n greater than o.ts . In addition, if the allocation site creates an array, the requested array length \nmust be equal to o s length. Other than what has been described in Section 2, this algo\u00adrithm records \nan A event (line 35), indicating that a new object is created (regardless of whether it is a fresh new \nob\u00adject or it is a resurrected object). If a dead object is found and its death has not yet been recorded, \na D event is appended to the trace (line 10). Resurrector allows the user to spec\u00adify whether a trace \nis needed, because many client analyses Input: Thread t, Field dereference expression x1 .f , variable \nx2 1 Object o1 . .(x1 ) 2 Object o2 . o1 .f 3 if o2 = null then 4 if o2 .t = t . I(o2 .m)(o2 .t) = o2 \n.ts then 5 untrack(o2 ) 6 return 7 if I(o2 .m)(t) > o2 .ts then 8 Method currMet . T(t)0 9 o2 .t . t \n10 o2 .m . currMet 11 o2 .ts . I(currMet )(t) Algorithm 4: Instrumentation before enter(t, m). Input: \nThread t, Method m 1 Stack s . T(t) 2 s . push(s, m) 3 I(m)(t). I(m)(t)+ 1 4 /*Invariant: I(m)(t)must \nbe an odd number*/ Algorithm 5: Instrumentation before exit(t, m). Input: Thread t, Method m 1 Stack \ns . T(t) 2 s . pop(s) 3 I(m)(t). I(m)(t)+ 1 4 /*Invariant: I(m)(t)must be an even number*/ Algorithm \n6: Instrumentation before return(t, x). 1 2 3 4 5 6 Input: Thread t, Return variable x Object o . .(x) \nif o = null . I(o.m)(o.t) > o.ts then /*Update o s method info with the caller s info*/ Method caller \n. T(t)0 o.ts . I(caller )(t) o.m . caller (such as those discussed in Section 4) can be implemented \nwithout a trace. If the trace generation option is not selected, these events do not need to be recorded. \nAfter an object is resurrected, we move it to the end of the cache list (lines 34) to improve the performance \nof the next search. This is based on the observation that objects death order is often consis\u00adtent with \ntheir creation order. Resurrector s instrumentation at each store (shown in Al\u00adgorithm 2) updates reference \ncounts in expected ways. At each load (shown in Algorithm 3), Resurrector .rst checks whether the retrieved \nobject has stack references in differ\u00adent threads (line 4 6). The death point for an object refer\u00adenced \nsimultaneously from stacks of multiple threads can\u00adnot be precisely determined unless the object maintains \nper\u00adthread tracking information, which can be prohibitively ex\u00adpensive in large systems. Hence, Resurrector \nstops tracking the object (i.e., removes its tracking information) and re\u00adAlgorithm 7: The modi.ed garbage \ncollection seman\u00adtics.  Input: Heap h 1 foreach Object o . hdo 2 if \u00acreachable(o). (o.rc = 0 . I(o.m)(o.t) \n> o.ts )then 3 /*Record death for o*/ 4 if o.dm = F then ' D ' 5 a .append(a, (globalTS(), o.gid , )) \n6 if reachable(o)then 7 o.dm . T lies on GC to detect its death point. Note that this handling does not \nlead to signi.cant precision loss because (1) most heap objects are thread-local [19], and (2) none of \nthe exist\u00ading object-reduction-based optimization techniques (such as [7, 32, 50]) can optimize shared \nobjects. If o2 is not refer\u00adenced by multiple thread stacks, Resurrector updates its m and ts with the \ninformation of the current method invocation (line 8 11). Algorithm 4 and Algorithm 5 pushes and pops \nmethod m onto and out of t s method stack, respectively. Both al\u00adgorithms increment m s IC. Algorithm \n6 inspects the return object, and updates its m and ts with the corresponding in\u00adformation of the caller \n(if its old m has returned). Note that because the return of a method always comes after the exit of \nthe method (that increments the method s IC and pops the stack, as shown in Algorithm 5), when the return \nobject is inspected by Algorithm 6, the callee is treated as already returned (i.e., that is why the \ncaller is retrieved by T (t)0 ). Algorithm 7 shows our modi.cation of a tracing col\u00adlector. It is important \nto note that the modi.ed collector records death points not only for unreachable objects but also for \ncached objects that are ready to reuse. As such, an object s death point can be recorded either (1) when \nit is reused, or (2) when a GC occurs and the object is ready to reuse, or (3) when a GC occurs and the \nobject is un\u00adreachable, whichever event comes .rst. This guarantees that the Resurrector-collected lifetime \ninformation can never be worse than the lifetime information obtained from a GC. When the object s death \npoint is recorded, its death mark is set to T, which will prevent Resurrector from recording its death \nagain (upon its reuse). Its death mark is set back to F after it is reused (line 11 in Algorithm 1). \n 3.3 Algorithm Correctness In this subsection, we demonstrate the correctness of the Resurrector algorithm \nby showing that it preserves the se\u00admantics of the original program. We .rst show that any ob\u00adject resurrected \nby Resurrector is guaranteed to be a dead object that will no longer be used in the forward execution. \nPROPOSITION 1. (Heap Unreachability). If rc of an object is 0, there must not exist any heap location \nthat contains a reference to the object. This proposition is straightforward to see. PROPOSITION 2. (Correctness \nof the Return Point Detec\u00adtion). For each object o tracked by Resurrector, if I(o.m)(o.t)> o.ts , the \nmethod invocation o.m in which o is referenced must have returned. This is because o.ts captures the \nIC of the method o.m at the moment o is referenced in o.m. Because IC can change only at the entry or \nthe exit, I(o.m)(o.t) > o.ts implies that at least an exit operation has occurred on o.m in o.t (if o.m \nis not a recursive method). PROPOSITION 3. (Lowest Method on the Stack). For each object o tracked by \nResurrector, there must not exist any method that is lower than o.m on o.t s call stack and that contains \na variable referencing o. We prove this by contradiction. Suppose there exists a method n that is a caller \nof o.m and that has a reference to o. The reference of o can .ow to n only in three cases: (1) o is created \nin n, (2) o is returned to n from a callee (such as o.m), or (3) a load retrieves o from a heap location. \nIn case (1), o.m should be initialized with n. Since n has not returned, o.m can never be updated to \na callee of n; in case (2) and (3), similarly, o.m would have already been up\u00addated to n (at the return \noperation and the load operation, respectively). LEMMA 1. (Resurrection Soundness). An object chosen \nby Algorithm 1 for reuse must be a dead object. To prove the lemma, we consider heap and stack reach\u00adability \nseparately. At the moment object o is chosen by Al\u00adgorithm 1, o.rc must be 0, which implies that there \ndoes not exist any heap location that contains a reference to o (Propo\u00adsition 1). On the other hand, \ncondition I(o.m)(o.t) > o.ts implies that the lowest method invocation (on the call stack) in which o \nis referenced has .nished (Propositions 2 and 3). o must be captured in this method invocation because \nit escapes neither to the heap (otherwise o.rc would not have been 0) nor to the caller of this method \n(otherwise this lowest method would have been the caller). THEOREM 1. (Semantics Preservation). The Resurrector \nex\u00adecution preserves the semantics of a program. From Lemma 1, we know that an object resurrected by \nResurrector will never be used in the forward execution. If the allocation site creates an array, Resurrector \nreturns a dead array with exactly the same length. Since the contents of a dead object are removed before \nit is reused (line 32 in Algorithm 1), the application sees the object as if it were a freshly created \nobject.  3.4 De.ning a Tradeoff Framework The size of the cache list for each allocation site can be \nnat\u00adurally used as a tuning parameter to de.ne a tradeoff frame\u00adAlgorithm 8: Instrumentation before enter(t, \nm) that handles recursion.  Input: Thread t, Method m 1 Stack s . T(t) 2 s . push(s, m) 3 depth . D(m)(t) \n4 if depth = 0 then 5 I(m)(t). I(m)(t)+ 1 6 D(m)(t) . depth + 1 7 /*Invariant: I(m)(t)must be an odd \nnumber*/ Algorithm 9: Instrumentation before exit(t, m) that handles recursion. Input: Thread t, Method \nm 1 Stack s . T(t) 2 s . pop(s) 3 D(m)(t). D(m)(t)-1 4 if D(m)(t)= 0 then 5 I(m)(t). I(m)(t)+ 1 6 /*Invariant: \nI(m)(t)must be an even number*/ work between precision and scalability. This framework al\u00adlows for the \ntuning of Resurrector for different client anal\u00adyses that have different precision/scalability requirements. \nFor example, supporting longer cache lists at allocation sites would allow Resurrector to .nd more reusable \nobjects and thus produce more precise lifetime information. However, certain allocation sites can create \ngreat numbers of lifetime\u00adoverlapping objects; caching all of them may lead to signi.\u00adcant time and space \noverheads. Furthermore, these allocation sites are not likely to be optimizable; precisely tracking life\u00adtimes \nfor all of their objects may not produce much bene.t for a client optimization technique. When the number \nof objects on a cache list exceeds a user-speci.ed threshold parameter, we release the whole list so \nthat the cached objects can be garbage collected. Their collection points will be recognized as their \ndeath points. Note that if the threshold is 0, the lifetime information com\u00adputed by Resurrector is exactly \nthe same as that approxi\u00admated using GC. On the other hand, if the length of a cache list is unbounded, \nall objects created by the allocation site would be cached and thus, the precision of our lifetime in\u00adformation \ncan be very close to (but still lower than) that of Merlin s lifetime information. Of course, doing this \nsuffers from the same scalability problem as Merlin does and thus would not work for real-world programs. \nBecause most optimization techniques target allocation sites that create small numbers of lifetime-overlapping \nob\u00adjects, running Resurrector with a small threshold can of\u00adten provide suf.ciently precise information \nfor these tech\u00adniques. During our experiments, we have evaluated Resur\u00adrector with several different \nthreshold parameters; our re\u00adsults demonstrate that large optimization opportunities can be found even \nwhen the threshold value is very small.  3.5 Handling of Advanced Language Features This subsection \ndiscusses how we revise our baseline algo\u00adrithm to deal with advanced language features. 3.5.1 Recursion \nThe current IC-based scheme does not function properly in the presence of recursion. Naively incrementing \nthe IC of a method at its entry and exit can inappropriately direct Resur\u00adrector to resurrect live objects \ncreated by a recursive method invocation. To solve the problem, we maintain a recursion depth vector \nDV : Tid . Nat for each method, which records the recursion depth (RD) for the method in each thread. \nSuppose D maps each method m to its DV . Al\u00adgorithms 8 and 9 describe, respectively, our modi.ed algo\u00adrithms \nat the method entry and exit to properly handle re\u00adcursive invocations. Every time an enter(t, m)operation \nis encountered, Resurrector .rst checks if m s recursion depth count (denoted as D(m)(t)) is 0. m s IC \n(i.e., I(m)(t)) is incremented only if this is the .rst time m is pushed onto t s stack. Similarly, at \nan exit, m s IC is incremented only if the current invocation is the last invocation of m on t s stack. \nAll the recursive invocations of the same method share the same IC. D(m)(t)is incremented at each enter \nand decremented at each exit. Note that the other four algorithms are still correct af\u00adter the instrumentation \nat enter and exit is modi.ed. This is because an object created in any invocation of a recursive method \ncannot be resurrected until the .rst invocation of the method returns. However, this would increase the \ndelay (be\u00adtween an object s actual death point and the point at which Resurrector detects its death) \nand prevent Resurrector from quickly reusing a dead object. To solve the problem, we add one additional \n.eld rd in the tracking data of each object to record the recursion depth of its capturing method m. \nWhen\u00adever an object s method-related information (i.e., m, t, and ts )needs to be updated, its rd is \nupdated (to D(m)(t)) as well. Hence, whether its m has returned can be veri.ed by checking the following \nrelaxed condition C1: I(o.m)(o.t)> o.ts .D(o.m)(o.t)< o.rd (C1) This condition would allow Resurrector \nto quickly identify a dead object created in a .nished recursive invocation.  3.5.2 Exception handling \nResurrector modi.es an existing exception delivery algo\u00adrithm in Jikes RVM to appropriately update the \nIC and RD of each method involved in the exception delivery. Particu\u00adlarly, when an exception is thrown, \nthis existing algorithm walks the call stack to .nd the most recent method invoca\u00adtion that has an handler \nfor the exception. When this algo\u00adrithm is about to exit an invocation on the stack, Resurrector treats \nit as an exit event and performs the updates as shown in Algorithm 9. In the method that catches the \nexception, Resurrector performs a return operation (Algorithm 6) with the exception object being treated \nas the returned object.  3.5.3 Object cloning In Java, the clone method can be invoked on an object \no ' to create a new object o of the same type and perform a shallow copy of o s data .elds into o ' . \nResurrector treats a call site that invokes clone as a special allocation site. At the end of the cloning \nprocess, Resurrector inspects each reference-typed .eld in o ' ; if the .eld contains a non-null reference \nvalue, Resurrector retrieves the referenced object and increments its reference count. 3.5.4 Handling \nof multi-dimensional arrays Different JVMs may have different implementations of multi-dimensional arrays. \nIn Jikes RVM, each i-dimensional array of the form A[]. . .[] is implemented by maintain\u00ading and connecting \na number of one-dimensional arrays of type java.lang.Object and type A. Resurrector assigns the same \nallocation site ID to all of the arrays upon their creation and caches them into the same cache line. \nTheir ref\u00aderence counts are initialized appropriately based on the ref\u00aderence relationships among them. \nWhen the allocation site is executed again to create a new multi-dimensional array, Resurrector inspects \nall the cached one-dimensional arrays to .nd dead ones in order to assemble this new array. 3.5.5 Handling \nof arraycopy Since method arraycopy is implemented via native code, Resurrector needs to explicitly account \nfor its side effects. When objects in array a are copied into array b using arraycopy, Resurrector increments \ntheir reference counts so that these objects cannot be mistakenly resurrected. How\u00adever, a user-de.ned \nnative method may also write or read heap references; failing to model these effects may crash a program \nor introduce arbitrary behaviors. Future work may address this issue by developing low-level support \n(e.g., at the virtual memory level) to detect reads and writes per\u00adformed in native code.  3.5.6 Re.ection \nand recursive data structures Resurrector detects calls to method newInstance during compilation and \ntreats them as allocation sites. As with any other reference-counting-based algorithm, Resurrector cannot \nappropriately handle recursive data struc\u00adtures. Their reference counts are always non-zero, prevent\u00ading \nResurrector from correctly identifying their death points. In the current implementation, Resurrector \nleaves them to the garbage collector. Because they are always unreusable, their allocation sites cache \nlists will keep growing. When the number of objects on a cache list exceeds the threshold parameter, \nthe whole list will be released and garbage col\u00adlected. Future work needs to investigate how to incorporate \ntechniques such as trial deletion [4, 6, 46] into Resurrector to precisely handle recursive data structures. \nIt is also interest\u00ading to measure, in the future work, how much precision loss is due to Resurrector \ns inability of handling recursive data structures; in the current implementation, we do not have any \ninformation regarding whether or not the discarding of a cache list is caused by cycles. 4. Implementation \nand Clients We have implemented Resurrector on Jikes RVM 3.1.3 [27], a Java-in-Java Virtual Machine. \nTo demonstrate its useful\u00adness for optimizing programs, we have implemented two client analyses: one \nthat .nds allocation sites creating very few lifetime-overlapping objects and second that approxi\u00admates \nthe sizes of run-time data structures. These two analy\u00adses are then used to .nd optimization opportunities \nin large\u00adscale, real-world programs. 4.1 Implementation and Optimization For each tracked object o in \nResurrector, we create an ad\u00ad ' ditional metadata object o to store its tracking information. ' o is \nimplicitly referenced by o (in its header space) while o ' is explicitly referenced by o (in a .eld). \nResurrector caches ' o by adding o onto the cache list. This will prevent o from being garbage collected \n(after it becomes unreachable). Yet, ' if o is removed from the list (e.g., when Resurrector decides \n' to untrack o)and o becomes unreachable, both o and o will be appropriately garbage collected. We have \nmodi.ed both the baseline compiler and the op\u00adtimizing compiler of the Jikes RVM to perform the instru\u00admentation. \nInstrumentation code is added at each allocation site, each store, each load, and the entry, exit and \nreturn point of each method. The invocation count vector and the recur\u00adsion depth vector for each method \nare created as two new .elds of RVMMethod. The method stack S on each thread is implemented as an integer \narray and kept in a .eld of RVMThread. Cache lists for allocation sites are implemented as a list array \nand kept in a .eld of RVMThread. As described in Algorithm 7, the garbage collector is modi.ed in such \na way that it records a death event when (1) a resurrectable (live) object is traversed during the reach\u00adability \nanalysis or (2) an untracked object is collected. While this modi.cation has been done only in the Mark-and-Sweep \nGC, the algorithm can be easily implemented in all the other GCs. Optimizations Two major optimizations \nhave been per\u00adformed to reduce the time and space costs. First, since each thread may actually execute \nonly a small portion of alloca\u00adtion sites, it is not necessary to create cache lists for all al\u00adlocation \nsites in each thread. To optimize this case, Resur\u00adrector creates a cache list for an allocation site \nin a thread only when the allocation site is executed by the thread. Res\u00adurrector maintains a global \nindex array for each allocation site a that records, for each thread, the index of a s cache list in \nthe thread. This optimization signi.cantly reduces the number of cache lists that need to be created. \nSecond, for each object, its tracking .elds t and m can be combined into one single .eld addr i, that \ndirectly records the address of I(m)(t). Similarly, we use another .eld addr d to record the address \nof D(m)(t). As I(m)(t)and D(m)(t)are the most frequently accessed tracking data, this combination leads \nto more ef.cient retrieval of IC and RD.  4.2 Client Analyses Detecting Allocation Site Optimizability \nOne common piece of information required by many optimizations is the maximal number of lifetime-overlapping \nobjects needed by an allocation site. We develop a client analysis that computes this information by \nkeeping track of the maximal length of each cache list. Speci.cally, we maintain a max-length count for \neach allocation site; this count is checked every time a cache list for this allocation site (in a thread) \ngrows and it is updated when its value is smaller than the current list length. For an allocation site \nwhose cache list has been released (because its size has exceeded the threshold), its max-length is assigned \na very large number (e.g., the maximal value of integer). While the max-length for an allocation site \nis an (over-)approximation of its maximal number of overlapping objects, these two numbers can be very \nclose if the allocation site is frequently executed. Data Structure Size Approximation An important op\u00adtimizability \nmeasurement used in many optimization tech\u00adniques is the size of a data structure (i.e., the number of \nob\u00adjects reachable from its root). For example, if an allocation site always has one live object and \nthe data structure rooted at the object has a large size, signi.cant performance gain may result from \noptimizing this allocation site (e.g., cache the whole data structure so that the effort of recomputing \nits contents can be saved). We have implemented another client analysis in Resurrector to approximate \nthe size of the data structure rooted at an object when the object is allocated/res\u00adurrected. As it is \na common practice that most objects in a data structure are created and initialized in the constructor \nof its root object, we augment Resurrector to instrument the entry and exit of each constructor to calculate \nthe number of objects created in the constructor. Speci.cally, we maintain an object stack in each thread; \nan object on the stack indi\u00adcates that its constructor is currently being executed. Upon the creation/resurrection \nof an object o, we .rst retrieve each object r already on the object stack and increment its data structure \nsize. In other words, o is considered to be part of the data structure rooted at each such r. Next, we \npush o onto the stack. Upon the exit of its constructor, o is popped out of the stack. The reports of \nthese two client analyses are generated and used to understand the precision and usefulness of the in\u00adformation \ncollected by Resurrector. In particular, allocation sites are .rst sorted in ascending order of their \nmax-length counts. The top 100 allocation sites on this list are re-sorted in descending order of the \nmultiplication of their frequen\u00adcies and their (approximated) data structure sizes. We have manually \ninspected the .nal list to .nd optimization oppor\u00adtunities. 5. Evaluation Our benchmarks (shown in Table \n1) include 10 programs from the 2006 release of the DaCapo benchmark set. Res\u00adurrector encounters an \nerror when running eclipse, which is thus not included in our subjects. All experiments are ex\u00adecuted \non a quadcore machine with an Intel Xeon E5620 2.40GHz processor, running Linux 2.6.18. The maximal heap \nsize speci.ed for each program run is 2GB. The Jikes RVM con.guration for the experiments is FastAdaptive-MarkSweep, \nwhich speci.es the use of the optimizing com\u00adpiler and the Mark-and-Sweep garbage collector. Our imple\u00admentation \ndistinguishes objects created in the VM code and those created in the regular Java code; objects created \nby the VM are not tracked. 5.1 Resurrector Performance Time Overhead on DaCapo-small Table 1 reports \nvar\u00adious running time statistics collected from the executions of DaCapo small workloads. To compare \nResurrector with existing techniques, we have obtained and run Elephant Tracks [40, 41], which is the \nonly publicly available tool implementing the Merlin algorithm [26]. We have also im\u00adplemented a GC-based \nlifetime approximation technique on Jikes RVM 3.1.3. Instead of .nding every single dead object from \nthe heap and reporting its death during each GC (which may incur a signi.cant time overhead), our implementation \nof the GC-based approximation records the address of each tracked object upon its creation in a list, \nand traverses the list to check the reachability of each object at the end of each GC. Hence, our implementation \nwould incur higher space overhead but lower time overhead than the naive implemen\u00adtation (that needs \nto .nd all dead objects from heap blocks). We choose to report the running times of the small work\u00adloads \nin order to enable the comparison among Resurrec\u00adtor, Elephant Tracks, and the GC-based approximation. \nThe Merlin algorithm implemented in Elephant Tracks is very slow and generates extremely large trace \n.les (e.g., at the scale of dozens to hundreds of Gigabytes). We could not .nish running most of the \nbenchmarks for even default workloads within a reasonable amount of time and space. Sections (a), (b), \nand (c) in Table 1 report, respectively, the execution time information of Elephant Tracks, Jikes RVM \nwithout instrumentation, and the GC-based approxi\u00admation. Elephant Tracks is implemented based on JVMTI, \na native interface currently not supported by Jikes RVM. Hence, we have to run Elephant Tracks on HotSpot \n(version 1.6.0 27); the running times of the original HotSpot and Elephant Tracks are shown in columns \nTH and TET , respec\u00adtively. Elephant Tracks crashes during the running of bloat and chart; the numbers \nannotated with * are obtained from the experimental results in [40].  Bench (a) ET (HotSpot) (b) R \n(c) GCA (d) Resurrector (ml = 1, 10, 100, 200, 500, and 8) TH TET TR TG T1 T10 T100 T200 T500 T8 antlr \n0.48 169.8 (352.3) bloat 2.87 * 17336.2 (6036) * chart 2.96 * 19425.9 (6565) * fop 1.81 182.2 (100.6) \nhsqldb 0.87 261.9 (300.3) jython 0.32 1283.1 (4061.1) luindex 0.75 367.8 (487.2) lusearch 0.74 1334.1(1805.1) \npmd 1.19 37.9 (31.8) xalan 1.3 1578.6(1214.3) 0.41 1.03 2.12 1.04 0.66 0.70 0.55 0.79 0.52 0.47 1.79 \n(4.4) 12.33 (12.0) 6.90 (3.3) 4.97 (4.8) 3.51 (5.3) 9.23 (13.2) 2.23 (4.1) 12.3 (15.4) 2.62 (5.0) \n3.55 (7.5)  1.15 (2.9) 3.53 (3.4) 6.96 (3.3) 2.13 (2.0) 2.09 (3.2) 4.96 (7.1) 1.19 (2.2) 4.03 (5.1) \n1.15 (2.2) 1.49 (3.1) 1.45 (3.6) 4.46 (4.3) 7.60 (3.6) 2.08 (2.0) 2.61 (3.9) 4.86 (7.0) 2.73 (5.0) 4.46 \n(5.6) 2.39 (4.6) 1.72 (3.6) 1.26 (3.1) 3.60 (3.5) 7.06 (3.3) 1.94 (1.9) 2.20 (3.3)  6.04 (8.7) 2.46 \n(4.5) 4.40 (5.5) 1.07 (2.1) 1.71 (3.6) 1.08 (2.7) 3.45 (3.3) 8.72 (4.1) 2.00 (1.9) 2.14 (3.2) 6.03 (8.7) \n2.67 (4.9) 4.16 (5.2) 1.21 (2.3) 1.91 (4.0) 1.16 (2.9) 1.83 (4.5) 3.63 (3.5) 98.3 (95.3 7.8 (3.7) 137.3 \n(64.8) 2.34 (2.3) 12.35 (11.9) 2.16 (3.3) 106.2 (160.4) 6.07 (8.7) 271.5 (389.5) 2.69 (4.9) 22.59 (41.3) \n 3.82 (4.8) 32.63 (41.3)  1.20 (2.3) 4.52 (8.7)   1.87 (4.0) 2.80 (5.9) GeoMean 752.4\u00d7 6.7\u00d7 3.2\u00d7 \n4.4\u00d7 3.6\u00d7 3.7\u00d7 3.7\u00d7 40.2 \u00d7 Table 1. Running time statistics for DaCapo-small: Section (a) reports the \noriginal HotSpot (TH)and the Elephant Tracks (TET ) running times; Section (b) reports the original Jikes \nRVM running time; Section (c) reports the running time of the GC-based approximation; Sections (d) reports \nResurrector s running times for different cache list size thresholds; running time * is measured in \nseconds; overhead is measured in slowdown ratios shown in parentheses. Those numbers are taken from the \nexperimental results reported in [40]. We have run Resurrector with six different max-length parameters, \nincluding 1, 10, 100, 200, 500, and 8. ml = 8 means that the length of a cache list is unbounded and \ncache lists are never discarded. The slowdown information (in parentheses) under column Ti is obtained \nby calculating the ratios between the numbers in Ti and their correspond\u00ading numbers in TR. Similarly, \nthe slowdowns reported under column TET are obtained by calculating the ratios between the numbers in \nTET and those in TH. Although Elephant Tracks and Resurrector are executed on two different JVMs, it \nis clear to see that Elephant Tracks is orders of magni\u00adtude slower than both Resurrector and the GC-based \napprox\u00adimation. The .rst .ve con.gurations of Resurrector all have better performance than the GC-based \napproximation. How\u00adever, when the length of a cache list goes unbounded, the overhead increases dramatically. \nTime and Space Overhead on DaCapo-large To have a better understanding of Resurrector s scalability, \nwe have also conducted an experiment on the large workloads of Da-Capo. The results are summarized in \nFigure 5, Figure 6, and Figure 7, which show, respectively, the overall running time overheads, space \noverheads, and GC overheads for the GC\u00adbased approximation and the .rst .ve Resurrector con.g\u00adurations. \nNote that Elephant Tracks and Resurrector with ml = 8 are not included in this experiment due to the \nunreasonably long executions (e.g., more than .ve hours for most applications); they are not practical \nenough to be used to pro.le real-world long-running applications. Resur\u00adrector encounters out-of-virtual-space \nerrors2 when running chart, lusearch, and xalan with ml = 500;thus, the re\u00adsults for these three applications \nunder ml = 500 are miss\u00ading in the .gures. In each of the three .gures, bars represent overheads in times. \nThe space overhead is measured as the ratio between the peak heap consumption of the Resurrector execution \nand that of the regular execution, while the GC overhead 2This may be because Jikes RVM cannot handle \na virtual address space larger than 1.1 GB. ml Time OH (times) Space OH GC OH GC-based 1 10 100 200 500* \n17.0 4.9 5.1 5.4 5.7 6.5 2.1 1.7 2.6 3.7 3.3 3.9 7.2 2.0 2.9 3.3 3.2 3.4 Table 2. The geometric means \nof the time, space, and GC overheads for the GC-based approximation and .ve Res\u00adurrector con.gurations. \n* The overheads under ml = 500 are computed on seven applications (all except chart, lusearch, and xalan). \nis measured as the ratio between the total GC times of the two executions. It is clear to see from Figure \n5 and Figure 7 that the GC-based approximation has the largest overall time overhead and GC time overhead. \nThis is primarily because it needs to traverse all created objects during each GC to identify dead objects \nand report death events. Table 2 reports the geometric means of the time, space, and GC overheads for \nthese different con.gurations. Clearly, Resurrector is more ef.cient than the GC-based approximation; \nin addition, the higher the max-length parameter is, the more costly the execution is. When we compare \nthe performance of the .ve con.gurations, we .nd that, in many cases, there is no signi.cant performance \ndifference between them. This may be because most allocation sites in large applications have very small \nnumbers of lifetime-overlapping objects (as demonstrated shortly in this section), and thus, increasing \nml does not signi.cantly affect the overall running time of an application.  5.2 Resurrector Precision \nDeallocation Difference Ratio (DDR) We .rst de.ne a precision metric, called deallocation difference \nratio (DDR), that we have used to assess the precision of various OLP techniques. Because Merlin is the \nmost precise OLP tech\u00adnique, the goal of this experiment is to understand the pre\u00ad  140 120 100 80 60 \n40 20 0  GC 1 10 100 200 500 Figure 5. Resurrector overall running time overhead on DaCapo-large; the \nY-axis shows overheads in times. 12 10 8 GC 1 6 10 100 200 4 500 2 0  Figure 6. Resurrector space overhead \non DaCapo-large. cision gap between Resurrector and Merlin. However, Ele-not directly comparable the \nstandard Java libraries used by phant Tracks, the only publicly available implementation of HotSpot and \nby Jikes RVM are completely different, making Merlin, does not support Jikes RVM, and thus, lifetimes \na direct comparison meaningless. To mitigate the problem, collected from Elephant Tracks and from Resurrector \nare we use the lifetime information collected from Resurrector s 18 16 14 12 10 8 6 4 2 0  GC 1 10 \n100 200 500 Figure 7. Resurrector GC overhead on DaCapo-large. Bench DDRGC DDR1 DDR10 DDR100 DDR200 \nDDR500 #Itv antlr 90.0 74.4 72.1 46.9 28 20.9 16 bloat 99.2 54.0 43.3 24.2 21.6 14.6 49 chart 98.5 69.9 \n58.0 27.7 27.9 28.2 54 fop 94.6 44.4 24.8 27.4 12.3 5.5 6 hsqldb 124.7 76.0 59.2 53.1 54.9 8.6 16 jython \n96.3 72.1 70.0 60.0 56.1 43.6 62 luindex 100 93.8 93.6 93.5 93.1 92.7 17 lusearch 98.4 56.2 31.4 26.6 \n26.7 21.0 400 pmd 80.1 90.2 70.7 84.3 57.9 14.7 3 xalan 102.9 76.0 57.2 55.4 48.9 58.9 134 GeoMean 97.9 \n69.1 54.3 44.7 36.8 22.3 Table 3. Resurrector s precision measurements; column #Itv reports the number \nof 1MB allocation intervals during the execution of each application; other columns show the deallocation \ndifference ratios (DDRs) collected for the GC-based approximation and the .ve Resurrector con.gurations. \nml = 8con.guration as an approximation of Merlin s life\u00adtime information. Although the former is still \nless precise than the latter, their precision should be very close. We run each application under its \nsmall workload (in or\u00adder to obtain results for ml = 8)and divide an execution into a sequence of 1MB \nallocation intervals. We collect the number of objects that are reported as dead in each interval for \nthe GC-based approach and each Resurrector con.gura\u00adtion. For a con.guration ml = c, suppose sc is an \narray such that each element sc[i]contains the number of dead objects reported in interval i;s8 is the \ncorresponding array for con\u00ad.guration ml = 8. The precision measurement DDRc for con.guration c is de.ned \nas DDRc = Si.[0,|s8|)|sc[i]-s8[i]|*100/Si.[0,|s8|)s8[i] In other words, DDRc is used to measure the overall \ndif\u00adference in the numbers of dead objects reported between con.guration c and con.guration 8. The smaller \nDDRc is, the more precise lifetime information con.guration c pro\u00adduces. Note that DDRc may not necessarily \nbe smaller than 100. We often see DDRs greater than 100 if the differences between the two reports are \nvery big. Table 3 reports the DDRs for the GC-based approximation and the .ve con.g\u00adurations of Resurrector. \nIn general, Resurrector is more pre\u00adcise than the GC-based approach even under ml = 1, and the greater \nml is, the smaller its DDR is. For luindex, all the .ve Resurrector con.gurations cannot produce precise \nlifetime information. This is primarily because luindex is a text indexing tool. During execution, it \nkeeps adding books into its (in-memory) dictionary and then does text index\u00ading, which causes most of \nits allocation sites to have large numbers of lifetime-overlapping objects. It appears that even ml =500 \nis not big enough for most of the cache lists to hold objects until they can be resurrected.  Unitary \nAllocation Site Statistics Unitary allocation sites are those such that the lifetimes of the objects \nthey create are completely disjoint [22, 50]. Detecting such al\u00adlocation sites is important for many \noptimization tasks be\u00adcause objects created by them can be pre-allocated or easily reused. To demonstrate \nResurrector s ability of .nding uni\u00adtary allocation sites, we compare the numbers of unitary al\u00adlocation \nsites reported by the GC-based approach and Resur\u00adrector under con.guration ml = 1. The results are shown \nin Figure 8. Resurrector has identi.ed that an overall 72.7% of the total allocation sites executed are \nunitary while the cor\u00adresponding percentage reported by the GC-based approach is only 12.0%. We also \nuse the Resurrector lifetime information to gen\u00aderate a histogram of allocation sites (shown in Figure \n9), which gives an overview of the optimization opportunities that may exist in each program. The histogram \nis obtained from the con.guration ml = 100. On average, the percent\u00adages of the allocation sites that \nfall into categories ml = 1, ml = 5, and ml > 5 are 72.6%, 8.8%, and 11.1%, respec\u00adtively. The rest (9.5%) \nof the allocation sites have more than 100 lifetime-overlapping objects, and thus, their cache lists \nare discarded by Resurrector. These numbers clearly indicate that large opportunities exist in real-world \napplications; Res\u00adurrector can help either human experts or automated tools quickly .nd these opportunities. \n 5.3 Case Studies We have inspected the reports generated by the two client analyses discussed in Section \n4 for 4 DaCapo applications. In fact, we have looked at only a few top allocation sites whose max-length \nis 1 in each report, and modi.ed the source code to cache and reuse their created objects. We add a reset \nmethod in some classes when their objects are reused, reset (rather than the constructor) is called to \nreset their data content without reconstructing them. It takes us about 2 days to .nd the problems and \nimplement the .xes for these applications. More opportunities could have been found if we had had more \ntime. Performance statistics be\u00adfore and after the problem .xes are collected under a fast (FastAdaptiveImmix) \ncon.guration of Jikes RVM (where all compiler optimizations are enabled) with a 1G maximal heap size. \nHence, the performance improvements achieved are beyond the JIT s best effort. In order to avoid the \ncom\u00adpilation cost and the execution noise, each application has been run 5 times and the median of the \nrunning times is re\u00adported. The DaCapo pmd benchmark The .rst (most fre\u00adquently executed) allocation \nsite in our report is located in line 73 of class org.jaxen.expr. IdentitySet. This class im\u00adplements \nan IdentitySet (in which two objects a and b are considered equal only if a == b)by maintaining an inter\u00adnal \nJava HashSet and wrapping each element object into a wrapper object. Two wrapper objects are equal when \ntheir wrapped objects are the same. Adding wrapper objects into the HashSet prevents two different element \nobjects from be\u00ading recognized as equal even if calling their equals method returns true. This .rst allocation \nsite creates a wrapper object in method contains, which is used only to check whether a given object \nexits in the set. Because this set is often very large, a great number of wrapper objects have to be \ncreated and garbage collected. In fact, only this one allocation site (in one of the many methods in \nthis class) has created a total of 31,039,097 objects. We .x the problem by simply employing the JDK-provided \nIdentityHashMap, which uses identity equality when adding/retrieving elements. Fixing only this one problem \nhas led to a 5.4% total time reduction (from 11189 to 10589 msec), a 19.6% reduction on the num\u00adber of \nobjects (from 778744363 to 626260549), and a 6.7% space reduction (from 153136 to 144412KB). The number \nof GCs has been reduced from 90 to 82. The DaCapo xalan benchmark We implement sin\u00adgleton patterns for \na few top allocation sites in xalan s re\u00adports to reuse NumberFormatStringTokenizer, XPathParser, and \nCompiler objects. These objects are data processors as apposed to data to be processed; it is thus unnecessary \nto create them every time a new data item arrives. After these .xes, the program s running time has been \nreduced by 8.7% (from 13073 to 11933 msec). The peak memory consump\u00adtion and the number of objects have \nbeen reduced by 15.4% (from 244756 to 207064KB) and by 5.5% (from 317406559 to 299943157), respectively. \nThe DaCapo luindex benchmark The .rst allocation site reported is in line 165 of class org.apache.lucene.index. \nSegmentTermEnum. This allocation site takes a TermInfo object as input and clones a new one. Resurrector \nindicates that this allocation site creates a great number of objects whose lifetimes are all disjoint, \nwe simply make all cloned objects share one single instance throughout the execution. Note that the method \ncontaining the allocation site is invoked in a variety of contexts, and it would be very dif.cult for \na developer to obtain this information without Resurrector s precise object lifetime pro.les. This .x \nhas led to a 9.9% space reduction (from 50428 to 45888KB) and a 3.9% object reduction (from 84780111 \nto 81487862). The number of GC runs has been reduced from 78 to 72. No clear time reduction has been \nfound.  antlr bloat chart fop jython hsqldb luindex lusearch pmd xalan Figure 8. A comparison between \nthe percentages of allocation sites reported as unitary by the GC-based approach and by Resurrector under \nml = 1. antlr bloat chart jyt hon fop hsqldb luindex lusearch pmd xala n Figure 9. A histogram of allocation \nsites under con.guration ml whose max-length falls into a category. The DaCapo bloat benchmark Among \nthe top 20 re\u00adported allocation sites, 12 create String and StringBuffer ob\u00adjects in the toString method \nof various classes, such as Ex\u00adpression, Label, Block, etc. Previous work [53] has already found that \nthis method is invoked only to provide messages for assertions (for debugging purposes). The messages \nare generated regardless of whether these assertions succeed or = 100. Each bar represents the percentage \nof allocation sites fail. The rest of the report are allocation sites that create ob\u00adjects to implement \nvisitor patterns (e.g., to traverse various graphs). We modify the source code to implement two .xes. \nFirst, toString is called to generate a message only when an assertion fails. Second, singleton patterns \nare employed to create graph visitors. These .xes have led to a 5 \u00d7 (from 45099 to 8372 msec) running \ntime reduction, a 3.9 \u00d7 (from 1016816 to 257716KB) reduction on the peak memory con\u00adsumption, and a 4.8 \n\u00d7 (from 929345410 to 192934784) ob\u00adject reduction. This is by far the largest performance im\u00adprovement \nthat has been achieved by .xing performance problems in bloat.  Summary and Discussion The amount of \neffort we have spent on the report inspection and problem .xes is relatively small the performance gains \nare obtained from .xing only a few allocation sites, work that just scratches the surface. During the \ninspection of reports and development of .xes, we have classi.ed three categories of allocation sites \nthat of\u00adten create disjoint objects. These objects can be easily reused to improve performance. The .rst \ncategory of allocation sites creates event objects that are used only to notify listeners cer\u00adtain events \nhave occurred. For example, the No.1 allocation site in the report of chart creates SeriesChangeEvent \nobjects, and their lifetimes never overlap. In an event-driven system, there is often a great number \nof event objects and reusing them can sometimes signi.cantly reduce the allocation and garbage collection \neffort. The second category contains al\u00adlocation sites that create processor objects (as apposed to data \nobjects to be processed). The allocation sites that cre\u00adate tokenizer and parser objects in xalan as \nwell as those that create visitor objects in bloat are examples of this cate\u00adgory. In many cases, one \nsingle processor object is suf.cient to process a number of different data objects. In addition, a processor \nobject often holds a complicated data structure to do the processing, and thus, creating and constructing \nthe data structure many times is undesirable and can cause sig\u00adni.cant performance problems. The third \ncategory of alloca\u00adtion sites create StringBuffer objects. In Java, at each occur\u00adrence of string concatenation \n(e.g., using operator + ), the compiler automatically translates it into the use of String-Buffer (i.e., \ncreates StringBuffer objects and calls its append method). StringBuffer objects created at different \nstring con\u00adcatenations can never be simultaneously used. In fact, the fu\u00adture design of the Java compiler \nshould consider to employ singleton patterns when it compiles string concatenations.  5.4 Improving \nan Existing Technique Our previous work [50] develops a dynamic analysis to help programmers detect reusable \ndata structures based on their allocation sites. [50] gives a three-level reusability de.ni\u00adtion: if \nan allocation site creates all disjoint objects, the object instances can be reused; among the allocation \nsites whose instances are reusable, the second reusability level concerns whether the shapes of the created \ndata structures are always the same; the highest reusability level is data reusability that corresponds \nto allocation sites whose in\u00adstances are disjoint, and whose shapes and data contents are the same. Key \nto the success of this work is the pre\u00adcise identi.cation of allocation sites whose instances are reusable, \nwhich provides a basis for the other two (higher\u00adlevel) reusability detectors it is impossible to reuse \ndata structures that have the same data contents unless their life\u00adTable 4. False positives of the object \nlifetime approximation used in [50]. times are disjoint. [50] approximates instance reusability by computing, \nfor each allocation site, a ratio between the num\u00adber of its dead objects and the number of its live \nobjects at each GC (i.e., DL ratio). The higher this ratio is, the more likely it is that the lifetimes \nof its objects are disjoint. This approximation is rather imprecise and is the cause of all false positives \n(reported in Section 4.1 of [50]). We run the tool on the 4 benchmarks we have studied. For each benchmark, \nwe carefully inspect the top 20 reported al\u00adlocation sites, and Table 4 shows the number of false pos\u00aditives \nwe have found. An allocation site is considered as a false positive if either it is clearly not a problem \nor we could not develop a solution to reuse its objects. For example, luin\u00addex creates a great number \nof Token objects during the pars\u00ading of expressions. These objects are linked through their next .eld \nand any regular operation of the list can break a link and make many such objects become unreachable. \nThe allocation sites creating them often have big DL ratios while their objects are not truly reusable. \nWe modify the tool to force it to use the Resurrector object lifetime information. This has led to the \nelimination of all false positives. All of the 20 allocation sites in each of the new reports are sin\u00adgleton \nallocation sites, which can be easily understood and optimized by the developer. 6. Related Work While \nthere exists a large body of related work in dynamic analysis and memory management, this section focuses \non work that is closest to Resurrector. Reference Counting Reference counting (RC) is used widely in \nthe design of GC algorithms. A RC collector keeps track of the number of incoming references for each \nobject; when its reference count becomes 0, the object can be col\u00adlected [4 6, 17]. Because it is expensive \nto track stack and register updates, modern RC collectors introduce deferred reference counting [11, \n18] that computes reference counts periodically. When a RC collector collects the heap, it must enumerate \nthe stacks and registers. Different from all RC collectors, Resurrector takes an object-centric design, \nwhich identi.es dead objects based on the method invocation in\u00adformation recorded in each object and, \nhence, Resurrector does not rely on a reachability analysis to compute object liveness. As with other \nRC algorithms, Resurrector cannot .nd dead cycles [47]. Modern GC collectors add periodic trac\u00ading collection \nor perform trial deletion [4, 6, 46] to collect dead cycles. Trial deletion maintains a candidate set \ncontain\u00ading objects that lost a pointer, but whose count did not reach zero. The algorithm then iteratively \nperforms trial deletions on the objects in this set and those reachable from them. When all the reference \ncounts become zero, the objects form a dead cycle and can be reclaimed. The current implemen\u00adtation of \nResurrector leaves the detection of dead cycles to GC, while it is worth investigating in the future \nwork how to incorporate trial deletion into Resurrector to detect and reuse dead objects in cycles. \n Ef.cient implementation of a non-deferred RC algorithm in a modern object-oriented language such as \nC# has been extensively studied in recent work such as [28 30]. This work relies on a data.ow analysis \nperformed in the optimiz\u00ading compiler to insert updates to reference counts, so that redundant RC updates \ncan be eliminated and dead objects can quickly reclaimed. Unlike this line of work that uses static analysis \nto track stack references, Resurrector exploits a novel counting algorithm, which treats the method return \nas the point at which an object loses its stack references, trading off the immediacy of detecting dead \nobjects for ef.\u00adciency. GC-Related Techniques Pretenuring long-lived and im\u00admortal objects [10, 12, 14, \n33] into infrequently or never col\u00adlected regions reduces garbage collection costs signi.cantly. Other \ntechniques such as [31, 45, 49] propose to use object lifetime pro.les to improve GC performance in various \nas\u00adpects. Optimization of Runtime Bloat Software bloat analy\u00adsis [3, 36 39, 44, 50 58] attempts to .nd, \nremove, and pre\u00advent performance problems due to inef.ciencies in the code execution and the use of memory. \nPrior work [38, 39] pro\u00adposes metrics to provide performance assessment of use of data structures. Their \nobservation that a large portion of the heap is not used to store data is also con.rmed in our study. \nIn addition to measure memory usage, our work proposes optimizations speci.cally targeting the problems \nwe found and our experimental results show that these optimizations are very effective. Work by Dufour \net al. [20]uses a blended escape analysis to characterize and .nd excessive use of temporary data structures. \nBy approximating object lifetimes, the analysis has been shown to be useful in classifying the usage \nof newly created objects in the problematic areas. Shankar et al. propose Jolt [44], an approach that \nmakes aggressive method inlining decisions based on the identi.cation of regions that make extensive \nuse of temporary objects. Work by Xu et al. [53] detects memory bloat by pro.ling copy activities, and \ntheir later work [52] looks for high-cost-low-bene.t data structures to detect execution bloat. Escape \nanalysis [13, 16, 21, 48] detects objects whose lifetimes are within the lifetime of the method (or its \ncaller) that create the objects. Such objects can be allocated on the stack instead of on the heap. Gheorghioiu \net al. propose a static analysis [22] to identify unitary allocation sites whose instances are completely \ndisjoint so that these instances can be pre-allocated and reused. Free-me [25] is a static tech\u00adnique \nthat identi.es when objects become unreachable and inserts calls to free them. Recent work such as [7, \n58] uses static analysis to identify reusable data structures created in a loop. Object equality pro.ling \n(OEP) [32] is a technique that discovers opportunities for replacing a set of equiva\u00adlent object instances \nwith a single representative object to save space. Hash consing [2, 24] and memoization [8, 34] are major \ntechniques for reusing existing objects. They have been widely used in functional languages, such as \nLISP and ML. JOLT [44] is a dynamic technique that makes aggres\u00adsive method inlining decisions based \non the identi.cation of regions that contain the entire lifetimes of many temporary objects (i.e., they \nare created and captured). Work by Dufour et al. [20] uses a blended escape analysis to characterize \nand .nd excessive use of temporary data structures. Their major motivation of designing a blended analysis \nis that a pure dynamic analysis that can detect lifetimes of short-lived tem\u00adporary objects is too expensive. \nResurrector solves this scal\u00adability problem by caching and reusing dead objects. Note that all these \ndynamic optimization techniques require pre\u00adcise identi.cation of object lifetimes, and thus, all of \nthem may bene.t from the information pro.led by Resurrector. 7. Conclusions This paper presents a tunable \nobject lifetime pro.ling tech\u00adnique, called Resurrector, that attempts to .nd the sweetspot between precision \nand scalability by detecting and reusing dead objects during the mutator execution. It is much more precise \nthan a GC-based approximation and much more ef.\u00adcient than Merlin. Using the number of objects cached \nfor each allocation site as a parameter, Resurrector de.nes a tradeoff framework that allows the designer \nof a client anal\u00adysis to tune the precision of the lifetime information and the ef.ciency of computing \nit speci.cally for the require\u00adment of the analysis. We have implemented Resurrector in JikesRVM and \nsuccessfully run it on a set of large-scale, real-world applications. Our experimental results demon\u00adstrate \nthat the overhead incurred by Resurrector is reasonable and large optimization opportunities can be found \nusing the Resurrector-collected object lifetime information. Acknowledgments We would like to thank Brian \nDemsky for his helpful com\u00adments on an early draft of the paper. We also thank the anonymous reviewers \nfor their valuable and thorough com\u00adments. This material is based upon work supported by the National \nScience Foundation under grant CNS-1321179. References [1] Websphere application server development best \npractices for performance and scalability. http://www-3.ibm.com/software/ webservers/appserv/ws bestpractices.pdf. \n[2] J. R. Allen. Anatomy of LISP. McGraw-Hill, 1978.  [3] E. Altman, M. Arnold, S. Fink, and N. Mitchell. \nPerformance analysis of idle programs. In ACM SIGPLAN International Conference on Object-Oriented Programming, \nSystems, Lan\u00adguages, and Applications (OOPSLA), pages 739 753, 2010. [4] D. F. Bacon, C. R. Attanasio, \nH. B. Lee, V. T. Rajan, and S. Smith. Java without the coffee breaks: a nonintrusive multi\u00adprocessor \ngarbage collector. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), \npages 92 103, 2001. [5] D. F. Bacon, P. Cheng, and V. T. Rajan. A uni.ed theory of garbage collection. \nIn ACM SIGPLAN International Confer\u00adence on Object-Oriented Programming, Systems, Languages, and Applications \n(OOPSLA), pages 50 68, 2004. [6] D. F. Bacon and V. T. Rajan. Concurrent cycle collec\u00adtion in reference \ncounted systems. In European Conference on Object-Oriented Programming (ECOOP), pages 207 235, 2001. \n[7] S. Bhattacharya, M. Nanda, K. Gopinath, and M. Gupta. Reuse, recycle to de-bloat software. In European \nConference on Object-Oriented Programming (ECOOP), pages 408 432, 2011. [8] R. S. Bird. An introduction \nto the theory of lists. In Logic of Programming and Calculi of Discrete Design, pages 5 42, 1987. [9] \nS. M. Blackburn, R. Garner, C. Hoffman, A. M. Khan, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, \nD. Framp\u00adton, S. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4c, \nT. VanDrunen, D. von Dincklage, and B. Wiedermann. The DaCapo bench\u00admarks: Java benchmarking development \nand analysis. In ACM SIGPLAN International Conference on Object-Oriented Pro\u00adgramming, Systems, Languages, \nand Applications (OOPSLA), pages 169 190, 2006. [10] S. M. Blackburn, M. Hertz, K. S. Mckinley, J. E. \nB. Moss, and T. Yang. Pro.le-based pretenuring. ACM Transactions on Programming Languages and Systems, \n29(1), 2007. [11] S. M. Blackburn and K. S. McKinley. Ulterior reference counting: fast garbage collection \nwithout a long wait. In ACM SIGPLAN International Conference on Object-Oriented Pro\u00adgramming, Systems, \nLanguages, and Applications (OOPSLA), pages 344 358, 2003. [12] S. M. Blackburn, S. Singhai, M. Hertz, \nK. S. McKinely, and J. E. B. Moss. Pretenuring for Java. In ACM SIGPLAN Inter\u00adnational Conference on \nObject-Oriented Programming, Sys\u00adtems, Languages, and Applications (OOPSLA), pages 342 352, 2001. [13] \nB. Blanchet. Escape analysis for object-oriented languages. Applications to Java. In ACM SIGPLAN International \nConfer\u00adence on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA), pages 20 34, \n1999. [14] P. Cheng, R. Harper, and P. Lee. Generational stack collec\u00adtion and pro.le-driven pretenuring. \nIn ACM SIGPLAN Con\u00adference on Programming Language Design and Implementa\u00adtion (PLDI), pages 162 173, \n1998. [15] A. E. Chis, N. Mitchell, E. Schonberg, G. Sevitsky, P. O Sullivan, T. Parsons, and J. Murphy. \nPatterns of mem\u00ad ory inef.ciency. In European Conference on Object-Oriented Programming (ECOOP), pages \n383 407, 2011. [16] J. Choi, M. Gupta, M. Serrano, V. Sreedhar, and S. Midkiff. Escape analysis for Java. \nIn ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Lan\u00adguages, and Applications \n(OOPSLA), pages 1 19, 1999. [17] G. E. Collins. A method for overlapping and erasure of lists. Communications \nof the ACM, 3(12):655 657, Dec. 1960. [18] L. P. Deutsch and D. G. Bobrow. An ef.cient, incremental, \nautomatic garbage collector. Commun. ACM, 19(9):522 526, Sept. 1976. [19] T. Domani, G. Goldshtein, E. \nK. Kolodner, E. Lewis, E. Pe\u00adtrank, and D. Sheinwald. Thread-local heaps for Java. In International Symposium \non Memory Management (ISMM), pages 76 87, 2002. [20] B. Dufour, B. G. Ryder, and G. Sevitsky. A scalable \ntechnique for characterizing the usage of temporaries in framework\u00adintensive Java applications. In ACM \nSIGSOFT Interna\u00adtional Symposium on the Foundations of Software Engineer\u00ading (FSE), pages 59 70, 2008. \n[21] D. Gay and B. Steensgaard. Fast escape analysis and stack allocation for object-based programs. \nIn International Con\u00adference on Compiler Construction (CC), LNCS 1781, pages 82 93, 2000. [22] O. Gheorghioiu, \nA. Salcianu, and M. Rinard. Interprocedu\u00adral compatibility analysis for static object preallocation. \nIn ACM SIGPLAN-SIGACT Symposium on Principles of Pro\u00adgramming Languages (POPL), pages 273 284, 2003. \n[23] J. Gil and Y. Shimron. Smaller footprint for Java collections. In European Conference on Object-Oriented \nProgramming (ECOOP), pages 356 382, 2012. [24] E. Goto. Monocopy and associative algorithms in an extended \nlisp. Technical Report 74-03, Information Science Laboratory, University of Tokyo, 1974. [25] S. Z. Guyer, \nK. S. McKinley, and D. Frampton. Free-Me: a static analysis for automatic individual object reclamation. \nIn ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), pages 364 375, 2006. \n[26] M. Hertz, S. M. Blackburn, J. E. B. Moss, K. S. McKinley, and D. Stefanovi\u00b4c. Generating object \nlifetime traces with Merlin. ACM Transactions on Programming Languages and Systems, 28(3):476 516, 2006. \n[27] Jikes Research Virtual Machine. http://jikesrvm.org. [28] P. G. Joisha. Compiler optimizations for \nnondeferred refer\u00adence: counting garbage collection. In International Sympo\u00adsium on Memory Management \n(ISMM), pages 150 161, 2006. [29] P. G. Joisha. Overlooking roots: a framework for making nondeferred \nreference-counting garbage collection fast. In International Symposium on Memory Management (ISMM), pages \n141 158, 2007. [30] P. G. Joisha. A principled approach to nondeferred reference\u00adcounting garbage collection. \nIn VEE, pages 131 140, 2008. [31] R. Jones and C. Ryder. Garbage collection should be lifetime aware. \nIn International Workshop on Implementation, Com\u00adpilation, Optimization of Object-Oriented Languages, \nPro\u00adgrams and Systems (ICOOOLPS), 2006.  [32] D. Marinov and R. O Callahan. Object equality pro.ling. \nIn ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications \n(OOP-SLA), pages 313 325, 2003. [33] S. Marion, R. Jones, and C. Ryder. Decrypting the Java gene pool. \nIn International Symposium on Memory Management (ISMM), pages 67 78, 2007. [34] D. Michie. memo functions \nand machine learning. Nature, page 218, 1968. [35] N. Mitchell. The runtime structure of object ownership. \nIn European Conference on Object-Oriented Programming (ECOOP), pages 74 98, 2006. [36] N. Mitchell, E. \nSchonberg, and G. Sevitsky. Making sense of large heaps. In European Conference on Object-Oriented Programming \n(ECOOP), pages 77 97, 2009. [37] N. Mitchell, E. Schonberg, and G. Sevitsky. Four trends leading to Java \nruntime bloat. IEEE Software, 27(1):56 63, 2010. [38] N. Mitchell and G. Sevitsky. The causes of bloat, \nthe lim\u00adits of health. ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, \nLanguages, and Ap\u00adplications (OOPSLA), pages 245 260, 2007. [39] N. Mitchell, G. Sevitsky, and H. Srinivasan. \nModeling runtime behavior in framework-based applications. In European Con\u00adference on Object-Oriented \nProgramming (ECOOP), pages 429 451, 2006. [40] N. P. Ricci, S. Z. Guyer, and J. E. B. Moss. Elephant \ntracks: generating program traces with object death records. In Inter\u00adnational Conference on Principles \nand Practice of Program\u00adming in Java (PPPJ), pages 139 142, 2011. [41] N. P. Ricci, S. Z. Guyer, and \nJ. E. B. Moss. Elephant tracks: portable production of complete and precise GC traces. In International \nSymposium on Memory Management (ISMM), pages 109 118, 2013. [42] A. Sewe, D. Yuan, J. Sinschek, and M. \nMezini. Headroom\u00adbased pretenuring: dynamically pretenuring objects that live long enough . In International \nConference on Principles and Practice of Programming in Java (PPPJ), pages 29 38, 2011. [43] O. Shacham, \nM. Vechev, and E. Yahav. Chameleon: Adaptive selection of collections. In ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation (PLDI), pages 408 418, 2009. [44] A. Shankar, M. Arnold, and R. Bodik. \nJOLT: Lightweight dynamic analysis and removal of object churn. In ACM SIGPLAN International Conference \non Object-Oriented Pro\u00adgramming, Systems, Languages, and Applications (OOPSLA), pages 127 142, 2008. \n[45] J. Singer, G. Brown, I. Watson, and J. Cavazos. Intelligent selection of application-speci.c garbage \ncollectors. In Inter\u00ad national Symposium on Memory Management (ISMM), pages 91 102, 2007. [46] S. C. \nVestal. Garbage collection: an exercise in distributed, fault-tolerant programming. PhD thesis, Seattle, \nWA, USA, 1987. [47] J. Weizenbaum. Knotted list structures. Communications of the ACM, 5(3):161 165, \nMar. 1962. [48] J. Whaley and M. Rinard. Compositional pointer and escape analysis for Java programs. \nIn ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Lan\u00adguages, and Applications \n(OOPSLA), pages 187 206, 1999. [49] F. Xian, W. Srisa-an, and H. Jiang. Allocation-phase aware thread \nscheduling policies to improve garbage collection per\u00adformance. In International Symposium on Memory \nManage\u00adment (ISMM), pages 79 90, 2007. [50] G. Xu. Finding reusable data structures. In ACM SIG-PLAN \nInternational Conference on Object-Oriented Pro\u00adgramming, Systems, Languages, and Applications (OOPSLA), \npages 1017 1034, 2012. [51] G. Xu. CoCo: Sound and adaptive replacement of Java collec\u00adtions. In European \nConference on Object-Oriented Program\u00adming (ECOOP), pages 1 26, 2013. [52] G. Xu, M. Arnold, N. Mitchell, \nA. Rountev, E. Schonberg, and G. Sevitsky. Finding low-utility data structures. In ACM SIGPLAN Conference \non Programming Language Design and Implementation (PLDI), pages 174 186, 2010. [53] G. Xu, M. Arnold, \nN. Mitchell, A. Rountev, and G. Sevitsky. Go with the .ow: Pro.ling copies to .nd runtime bloat. In ACM \nSIGPLAN Conference on Programming Language De\u00adsign and Implementation (PLDI), pages 419 430, 2009. [54] \nG. Xu, M. D. Bond, F. Qin, and A. Rountev. LeakChaser: Helping programmers narrow down causes of memory \nleaks. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), pages 270 \n282, 2011. [55] G. Xu, N. Mitchell, M. Arnold, A. Rountev, and G. Sevitsky. Software bloat analysis: \nFinding, removing, and preventing performance problems in modern large-scale object-oriented applications. \nIn FSE/SDP Working Conference on the Future of Software Engineering Research (FoSER), pages 421 426, \n2010. [56] G. Xu and A. Rountev. Precise memory leak detection for Java software using container pro.ling. \nIn International Confer\u00adence on Software Engineering (ICSE), pages 151 160, 2008. [57] G. Xu and A. Rountev. \nDetecting inef.ciently-used containers to avoid bloat. In ACM SIGPLAN Conference on Program\u00adming Language \nDesign and Implementation (PLDI), pages 160 173, 2010. [58] G. Xu, D. Yan, and A. Rountev. Static detection \nof loop\u00adinvariant data structures. In European Conference on Object-Oriented Programming (ECOOP), pages \n738 763, 2012.    \n\t\t\t", "proc_id": "2509136", "abstract": "<p>Modern object-oriented applications commonly suffer from severe performance problems that need to be optimized away for increased efficiency and user satisfaction. Many existing optimization techniques (such as object pooling and pretenuring) require precise identification of object lifetimes. However, it is particularly challenging to obtain object lifetimes both precisely and efficiently: precise profiling techniques such as Merlin introduce several hundred times slowdown even for small programs while efficient approximation techniques often sacrifice precision and produce less useful lifetime information. This paper presents a tunable profiling technique, called <i>Resurrector</i>, that explores the middle ground between high precision and high efficiency to find the precision-efficiency sweetspot for various livenessbased optimization techniques. Our evaluation shows that Resurrector is both more precise and more efficient than the GC-based approximation, and it is orders-of-magnitude faster than Merlin. To demonstrate Resurrector's usefulness, we have developed client analyses to find allocation sites that create large data structures with disjoint lifetimes. By inspecting program source code and reusing data structures created from these allocation sites, we have achieved significant performance gains. We have also improved the precision of an existing optimization technique using the lifetime information collected by Resurrector.</p>", "authors": [{"name": "Guoqing Xu", "author_profile_id": "81350590981", "affiliation": "University of California, Irvine, Irvine, CA, USA", "person_id": "P4290321", "email_address": "guoqingx@ics.uci.edu", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509512", "year": "2013", "article_id": "2509512", "conference": "OOPSLA", "title": "Resurrector: a tunable object lifetime profiling technique for optimizing real-world programs", "url": "http://dl.acm.org/citation.cfm?id=2509512"}