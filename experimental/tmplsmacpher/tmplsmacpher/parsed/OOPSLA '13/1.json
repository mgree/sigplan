{"article_publication_date": "10-29-2013", "fulltext": "\n Steering Symbolic Execution to Less Traveled Paths You Li* Zhendong Su+ Linzhang Wang* Xuandong Li* \n*State Key Laboratory for Novel Software Technology Department of Computer Science and Technology Nanjing \nUniversity, Nanjing, 210023, China +University of California, Davis, USA leo86@seg.nju.edu.cn su@cs.ucdavis.edu \nlzwang@nju.edu.cn lxd@nju.edu.cn Abstract Symbolic execution is a promising testing and analysis methodology. \nIt systematically explores a program s execu\u00adtion space and can generate test cases with high coverage. \nOne signi.cant practical challenge for symbolic execution is how to effectively explore the enormous \nnumber of pro\u00adgram paths in real-world programs. Various heuristics have been proposed for guiding symbolic \nexecution, but they are generally inef.cient and ad-hoc. In this paper, we introduce a novel, uni.ed \nstrategy to guide symbolic execution to less ex\u00adplored parts of a program. Our key idea is to exploit \na speci.c type of path spectra, namely the length-n subpath program spectra, to systematically approximate \nfull path information for guiding path exploration. In particular, we use frequency distributions of \nexplored length-n subpaths to prioritize less traveled parts of the program to improve test coverage \nand error detection. We have implemented our general strategy in KLEE, a state-of-the-art symbolic execution \nengine. Evalu\u00adation results on the GNU Coreutils programs show that (1) varying the length n captures \nprogram-speci.c information and exhibits different degrees of effectiveness, and (2) our general approach \noutperforms traditional strategies in both coverage and error detection. Categories and Subject Descriptors \nD.2.4 [Software Engi\u00adneering]: Software/Program Veri.cation Reliability, Vali\u00addation; D.2.5 [Software \nEngineering]: Testing and Debu\u00adgging Symbolic execution Keywords less traveled, path spectra, symbolic \nexecution Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. Copyrights for components of \nthis work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, \nor republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. Request permissions from permissions@acm.org. OOPSLA 13, October 29 31, 2013, Indianapolis, Indiana, \nUSA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2374-1/13/10. . . $15.00. http://dx.doi.org/10.1145/2509136.2509553 \n1. Introduction Testing is one of the most important software validation techniques, and arguably the \nmost practical and widely\u00adused. However, traditional approaches, such as random test\u00ading [14, 19] and \nmanual testing, although useful, can be inef\u00ad fective [15, 25, 31]. Symbolic execution [10, 22] is another \nclassical technique for software testing and analysis. It can be used for systematically testing a program \nand test input generation with high coverage. Instead of using concrete in\u00adput, symbolic execution uses \nsymbolic values as input and explores a program s execution space. When symbolic exe\u00adcution encounters \na branch condition, it forks the execution state, following both branch directions and updating the cor\u00adresponding \npath constraints on the symbolic input. When it reaches a program exit or hits an error, the current \npath con\u00adstraint will be solved to .nd a concrete test case that drives program execution to this program \nlocation. However, in prac\u00adtice, a program may have a large or even in.nite number of paths because of \nconditionals, loops, and recursions. Thus, one key issue for making symbolic execution practical is how \nto guide it toward more pro.table paths. To this end, various strategies have been proposed to guide \nand optimize symbolic exploration [5, 7, 17, 24, 32]. However, these path guidance techniques for symbolic \nexecution are generally ineffective and ad-hoc. In this paper, we introduce a novel, uni.ed methodology \nto guide symbolic execution to explore programs more ef\u00adfectively. At the high-level, we aim to explore \nless traveled paths of a program as it can help improve test coverage and locate more defects. Although \nmost commonly adopted in practice, it is folklore that statement and branch coverage metrics may not \naccurately re.ect how thorough a program has been exercised by a set of test cases. The recent work on \nCsmith [33] gives more concrete evidence. Csmith is a ran\u00ad dom C program generation tool speci.cally \ndeveloped to .nd bugs in C compilers. The randomly generated C programs yield roughly the same statement \nand branch coverage as the test suites in the tested compilers (e.g., GCC and Clang/L-LVM), but they \ntriggered a few hundred new bugs in GCC and Clang/LLVM alone. Thus to measure less traveled , a more \n.exible and general notion is needed.  Our key conceptual idea is to adapt a variant of path coverage, \nthe length-n subpath coverage (where each subpath has n branches). Program pro.ling [4, 13, 27] has been \neffectively used to understand the behavior of a program. It can also be applied to measure test coverage \nusing different program spectra. We propose the use of length-n subpath spectra to uniformly measure \ncoverage and guide symbolic path exploration. Indeed, we use statistical analysis of already covered \nlength-n subpaths to systematically steer symbolic execution to not yet or less explored parts of the \nprogram. The use of length-n subpaths offers a natural spectrum of program coverage. One extreme is the \nnontrivial degenerative case of branch coverage, when n = 1. The other extreme maps to complete path \ncoverage, when n = 8 (i.e. unbounded). We propose to use length-n subpath spectra to help prioritize \nprogram paths for exploration. Different choices of n give a systematic coverage, and we show that they \nexhibit different, yet complementary bene.ts. In more detail, we maintain a priority queue P to store \nsubpath spectra information on the explored parts of the program. For an explored (sub)-path p = (s0, \ns1, . . . , sk), each si(0 = i = k) corresponds to a branch location and the direction taken in the execution. \nWe compute p s length\u00adn subpath fragments (i.e., n-grams ) and store each in P along with its frequency \ninformation. When we need to decide which pending paths to explore, we examine P and select a pending \npath p1 with the lowest frequency length-n subpath at its frontier. We terminate the path reaching the \nexit point or hitting an error. This process repeats until either the program has been fully explored, \nor we have reached a preset time limit or coverage threshold. We have implemented our general strategy \nin KLEE [7], a state-of-the-art symbolic execution tool. To evaluate the effectiveness of our strategy, \nwe ran KLEE on the GNU Coreutils programs [11] by varying the guidance strategies, including our own \nand the most common traditional strategies built into KLEE. We compared the quality of the generated \ntest cases by measuring their statement coverage and defect detection capabilities. The results show \nthat our strategy can guide symbolic execution to cover the program faster and .nd more bugs than the \nevaluated traditional strategies. In summary, we have the following key .ndings: 1) different choices \nof n exhibit different behavior and capture program\u00adspeci.c information; and 2) the proposed uni.ed strategy \nsigni.cantly outperforms the other strategies. In this paper, we make the following main contributions: \n We introduce the novel concept of using subpath program spectra as a uni.ed strategy to guide symbolic \nexecution and present the details on how to realize the strategy.  We implement the general strategy \nwithin KLEE and extensively evaluate its effectiveness against common traditional strategies.  (a) \nExample Program (b) Control Flow Figure 1. An example program. The rest of the paper is structured as \nfollows. Section 2 provides details on how to use length-n subpath program spectra to guide symbolic \nexecution. We also give necessary background on symbolic execution and use an example to illustrate the \nbene.ts of our approach. In Section 3, we de\u00ad scribe the implementation and evaluation of our approach. \nWe survey related work in Section 4 and conclude in Section 5. 2. Subpath-Guided Path Exploration This \nsection details our proposed path exploration strategy. We start with some necessary background on symbolic \nexe\u00adcution and path spectra. 2.1 Symbolic Execution Background The concept of symbolic execution [22] \nwas proposed by King in 1976. It is a practical testing and analysis approach that utilizes and combines \ntesting and program veri.ca\u00adtion. Recent years have witnessed an impressive amount of work [1, 5, 7, \n8, 17, 18, 24, 26, 32] on building practical symbolic execution techniques and tools for improving test \ninput generation and bug .nding. The key idea of symbolic execution is to substitute the actual data \nwith symbolic value as the input data. The corresponding program operations are replaced with symbolic \nexpressions, so the output of the pro\u00adgram can be represented as formulas on the symbolic input. To illustrate \nthe procedure of symbolic execution, we use the example program in Figure 1. At the entry point of the \nprogram, symbolic execution generates an original execution state ES. An execution state maintains 1) \nthe symbolic values (x and y), 2) the corresponding symbolic expressions (such as x = f(x) in s1), and \n3) symbolic path constraint PC of the input (such as x > y in s0), which can represent a speci.c path \nof the program. The symbolic execution engine then executes the program with ES. When it encounters a \nconditional statement if (e) s1 else s2 (such as s0 in the program), it generates a new execution state \nES . The new state ES copies all the information from ES, and the path constraints are updated accordingly: \nthe path constraint of ES is updated to PC . \u00ac(e), while the path constraint of ES is updated to PC . \n(e). Therefore, ES and ES can explore both sides of the conditional statement. As more and more execution \nstates are generated, different strategies are applied to decide which execution state is desirable to \nbe executed next at each fork (i.e., a conditional branch either from conditionals or loops in the source \nprogram).  During this process, a constraint solver is used to check the satis.ability of the path constraint \nin an execution state. If it is unsatis.able, the corresponding path is discarded from further exploration \nas it is infeasible. When an execution state reaches an exit point of the program or hits an error, the \npath exploration terminates and the corresponding path constraint is solved to .nd a concrete input, \nif any. Assuming the latest execution state is always selected, under the Depth-First Search (DFS) strategy, \nthe path s0s2s3s12s13s4 is the .rst case generated and the path constraint is \u00ac(x > y).\u00ac(x == 0), then \nthe constraint solver can generate a concrete input (1, 0) (i.e., x = 1 and y = 0). This input is typically \nequivalent to many other test cases following the same paths. When we execute the program with this concrete \ninput, it can repeat the same path as the execution state did originally via symbolic execution. However, \nin realistic programs, loops or recursion can lead to a large or even in.nite number of paths (in theory). \nIn most situations, one has to set a time limit on symbolic execution. Thus, it is important to guide \nsymbolic execution to select pro.table states to explore during its search. Consider KLEE, a state-of-the-art \nsymbolic execution engine. It has several built-in traditional search strategies [7]: Depth-First Search \n(DFS) always selects the latest ex\u00adecution state among all the states to explore next. This strategy \nhas little overhead in selecting a state, however, it typically explores fewer parts of the program and \ngets stuck when it encounters a tight loop a loop with few statements that iterates many times.  Random \nState Search (RSS) randomly selects a pending state to explore. This strategy can explore the program \nmore uniformly and avoid the situation with tight loops with a symbolic condition creating new states \nrapidly (fork bombing). The problem of RSS is that it may repeatedly generate test cases that have the \nsame effect as those generated earlier.  Random Path Selection (RPS) uses a binary execution tree to \nrecord the information on explored parts of the program, where the leaves are current states and the \ninternal nodes are the forks. It selects states by traversing the execution tree from the root and randomly \npicks a direction when it encounters a branch until it reaches a leaf. With this strategy, those states \nhigh up in the execution tree have greater chance to be chosen because these states have fewer constraints \nto satisfy and may be more likely to explore uncovered parts of the program. RPS can avoid the fork bombing \nproblem affecting RSS, but as RSS, it may also repeatedly generate similar test cases.  Coverage-Optimized \nSearch (COS) uses heuristics to compute which state has better chance to cover new code very soon. It \ncalculates a weight for the states to be chosen and selects a state w.r.t. the weight. Various factors, \nsuch as the minimum distance to an uncovered instruction and the query cost, are taken into account to \ncalculate the weight for each state. This strategy is not general and may not perform well for every \nprogram.  Using search heuristics, such as the ones above, is one possible approach to deal with the \nproblem of path explosion in symbolic execution. Traditional methods mostly perform blind, random search, \nthus cannot explore the program uni\u00adformly and thoroughly.  2.2 The Length-n Subpath Program Spectra \nTo effectively guide symbolic execution, we believe that the less traveled parts of the program are more \npro.table. Ex\u00adploring these parts can generate test cases with higher cov\u00aderage and better defection \ndetection capabilities. To capture which executions may lead to less traveled parts, we need to have \nmeans to approximate the behavior of the program. To this end, this paper proposes a novel application \nof program spectra to help approximate program behavior and guide path exploration. Program pro.ling \nhas been used to understand dynamic program behavior. It counts occurrences of different runtime events \nduring a program s execution [4]. These events can be paths, basic blocks, control-.ow edges, etc. Pro.ling \nbased on different types of events provides various program spectra that can help characterize the program \ns execution and provide signatures of a program s runtime behavior [27]. Below we list a few of the most \nwidely used program spectra: Branch Hit Spectra: Recording the executed conditional branches.  Branch \nCount Spectra: Recording the execution count for each conditional branch.  Complete Path Spectra: Recording \nthe complete paths that were explored.  Path Spectra: Recording the explored intraprocedural loop-free \npaths.   Path Count Spectra: Recording the executed count for each intraprocedural loop-free path. \nThe above pro.le information can be used in many ways, such as compiler optimizations [2, 3], regression \ntesting [20], coverage measuring, and many other applications that need to analyze program behavior. \nReps et al. [27] use path spec\u00ad tra to deal with the Year 2K Problem. They compared spectra from different \nruns of the same program to locate date-dependent computations. An empirical study [20] shows various \ntypes of spectra differences highly correlate with the exposure of regression faults. However, there \ndoes not exist a single program spectrum that can discover all program be\u00adhavior differences. Thus, using \ndifferent program spectra can help us understand a program s behavior more comprehen\u00adsively from different \naspects. From the above discussion, different program spectra pro\u00advide different perspectives to understand \na program s exe\u00adcution behavior. We can use program spectra to measure the effect of different test generation \ntechniques. Complete path coverage is a highly precise metric to measure the qual\u00adity of a test suite, \nhowever, it is impractical to obtain high coverage as we need a large number of test cases to cover possible \ncomplete paths, many times even in.nite. On the other hand, branch coverage, statement coverage or function \ncoverage are too shallow to accurately capture the effective\u00adness of test suites. The random C program \ngeneration tool Csmith [33] has been used to discover hundreds of new bugs in mainstream C compilers, \nsuch as GCC and Clang/LLVM. However, as the authors have noted, the generated test cases and the compilers \ntest suites are very similar with respect to the three coverage metrics mentioned above. To .ll the gap \nbetween complete path coverage and branch coverage, we adopt the concept of length-n subpath program \nspectra. It is a variant of complete path coverage. A complete path is a unique sequence of branch conditions \nfrom the entry of a program to its exit, and we can represent it as p = (s0, s1, . . . , sk) where each \nsi corresponds to a conditional branch (i.e., fork) and the branch direction taken in the program. We \nrepresent a length-n subpath as (si+1, si+2, . . . , si+n), which is a consecutive sub-sequence from \na complete path. By varying n, we obtain a spectrum of modeling precision. When n = 1, it degenerates \nto branch coverage. At the other extreme, we obtain complete path coverage when n = 8 (i.e., unbounded). \n 2.3 Subpath-Guided Search To measure which parts are less traveled , we propose to use length-n subpath. \nHowever, it is time-consuming to build the whole length-n subpath matrix during symbolic execution. Instead, \nwe use statistical analysis of the already covered length-n subpaths to decide which execution state(s) \nmay lead the path exploration to the less traveled parts. We call this general, uniform strategy Subpath-Guided \nSearch (SGS). Algorithm 1: Subpath-Guided Search Strategy (Part 1) Initialization: 1: PriorityQueue<pathSegmentCount> \nP; 2: Vector<executionState> ESVector; 3: executionState initialState; 4: Integer pathSegmentLength; \nBegin symbolicExecution: 5: ESVector.add(initialState); 6: while ESVector.size>0 I !TIME OUT do 7: executionState \nES = selectState(); 8: P[ES.p]++; 9: while ES.instructionType != FORK I EXIT &#38;&#38; !FoundError do \n10: ES.executeInstruction(); 11: end while 12: if ES.instructionType = EXIT I FoundError then 13: generateTestCase(); \n14: ESVector.remove(ES); 15: continue; 16: end if 17: if ES.instructionType = FORK then 18: instruction \nFr = ES.currentInstruction; 19: ES2 = new executionState(ES); 20: ES.newNode = Fr(T) 21: updatePathSegment(ES); \n22: if !P.contains(ES.p) then 23: P.add(ES.p,0); 24: end if 25: ES2.newNode = Fr(F); 26: updatePathSegment(ES2); \n27: if !P.contains(ES2.p) then 28: P.add(ES2.p,0); 29: end if 30: ESVector.add(ES2); 31: end if 32: end \nwhile End symbolicExecution The main algorithm is shown in Algorithm 1 &#38; Algo\u00ad rithm 2. We use a \nstructure e = (p, f ) for statistical analysis, where p is the subpath (of length n), f is the frequency \nof p in the explored parts of the program, which is calculated by counting the number of times that p \nhas been explored before. A priority queue P is maintained and the subpath with the lowest frequency \nis at the top of the queue. For each execution state ES, a corresponding subpath p is maintained, which \nis composed of the latest n branch conditions executed of ES. The execution state with the lowest count \nof p is selected to continue the symbolic execution (Algorithm 1, Line 7). We break ties, if any, at \nrandom. When an execution state ESk (ES in Algorithm 1) is picked, the frequency of the corresponding \nsubpath pk (ES.p in Algorithm 1, Line 8) is in\u00adcreased by 1. As described in Section 2.1, at every fork \npoint  Steps Pending Path Priority Queue Path to Pick Generate Case 1 1:s0t 2:s0f (*s0t,0),(*s0f ,0) \n2 2 1:s0t 2:s0f s8t 3:s0f s8f (*s0t,0),(*s8t,0),(*s8f ,0),(s0f ,1) 3 s0f s8f s4 3 1:s0t 2:s0f s8t (*s0t,0),(*s8t,0),(s8f \n,1),(s0f ,1) 2 4 1:s0t 2:s0f s8ts9t 3:s0f s8ts9f (*s0t,0),(*s9t,0),(*s9f ,0),(s8t,1), (s8f ,1),(s0f ,1) \n3 s0f s8ts9f s4 5 1:s0t 2:s0f s8ts9t (*s0t,0),(*s9t,0),(s9f ,1),(s8t,1), (s8f ,1),(s0f ,1) 2 s0f s8ts9ts10 \n6 1:s0t (*s0t,0),(s9t,1),(s9f ,1),(s8t,1), (s8f ,1),(s0f ,1) 1 7 1:s0ts5t 2:s0ts5f (*s5t,0),(*s5f ,0),(s0t,1),(s9t,1), \n(s9f ,1),(s8t,1),(s8f ,1),(s0f ,1) 2 8 1:s0ts5t 2:s0ts5f s8t 3:s0ts5f s8f (*s5t,0),(s5t,1),(s0t,1),(s9t,1), \n(s9f ,1),(*s8t,1),(*s8f ,1),(s0f ,1) 3 s0ts5ts6 9 1:s0ts5f s8t 2:s0ts5f s8f (s5t,1),(s5t,1),(s0t,1),(s9t,1), \n(s9f ,1),(*s8t,1),(*s8f ,1),(s0f ,1) 2 s0ts5f s8f s4 . . . . . . . . . . . . . . . 1 k is generated \n(Algorithm 1, 1 (ES2 in Algorithm 1, Line 19) will explore both sides of the fork, so we update the cor\u00ad \nresponding subpaths of ESk and ES 1 k to pk + F r(T ) and pk + F r(F ) (Algorithm 1, Lines 20 and 25). \nF r(x) denotes Algorithm 2: Subpath-Guided Search Strategy (Part 2) Begin selectState 1: Vector<executionState> \nselectSet; 2: for 0<i<ESVector.size() do 3: if P(ESVector[i].pathSegment)=P.lowest then a fork point \nF r with the direction it chooses, where x can be either T or F . If the length of the new subpath is \nlarger than n, the .rst branch condition will be removed (Algoritm 2, updatePathSegment). Then we check \nthe priority queue P . 4: selectSet.add(ESVector[i]); 5: end if 6: i++; 7: end for 8: Integer random \n= randomInteger() mod selectSet.size(); 9: return selectSet[random]; End selectState The new subpath \nwith a 0 count will be added to P if it has not been encountered earlier (Algorithm 1, Lines 23 and 28). \nAfter updating the priority queue, we pick a new execution state with the lowest count of p (Algoritm \n2, selectState). This process repeats until all the execution states have ter\u00adminated or the symbolic \nexploration times out. To illustrate the bene.ts of SGS, we use length-1 subpath to guide the symbolic \nexploration to generate test cases for the example 10: Begin updatePathSegment(executionState ES) 11: \nES.p.add(ES.newNode); 12: if ES.p.length > pathSegmentLength then 13: ES.p.removeFirstBranchCondition(); \n14: end if End updatePathSegment(executionState ES) program in Figure 1 and compare it with the depth-.rst \nsearch strategy. To have a fair comparison, we assume that our strat\u00adegy breaks ties by selecting the \nlatest execution state as DFS does. There are 7 complete paths in the example program. To generate test \ncases to cover all the statements, DFS needs to explore all 7 paths. The procedure of length-1 subpath \nguided search is shown in Table 1. Node sit represents a branch node si with the true direction taken, \nwhile sif denotes a branch node si taking the false direction. The column Pending Path records the corresponding \npaths of the unterminated execu\u00adTable 2. Length-2 subpath-guided search.  Steps Pending Path Priority \nQueue Path to Pick Generate Case 1 1:s0t 2:s0f (*s0t,0),(*s0f ,0) 2 2 1:s0t 2:s0f s8t 3:s0f s8f (*s0t,0),(*s0f \ns8t,0),(*s0f s8f ,0),(s0f ,1) 3 s0f s8f s4 3 1:s0t 2:s0f s8t (*s0t,0),(*s0f s8t,0),(s0f s8f ,1),(s0f \n,1) 2 4 1:s0t 2:s0f s8ts9t 3:s0f s8ts9f (*s0t,0),(*s8ts9t,0),(*s8ts9f ,0),(s0f s8t,1), (s0f s8f ,1),(s0f \n,1) 3 s0f s8ts9f s4 5 1:s0t 2:s0f s8ts9t (*s0t,0),(*s8ts9t,0),(s8ts9f ,1),(s0f s8t,1), (s0f s8f ,1),(s0f \n,1) 2 s0f s8ts9ts10 6 1:s0t (*s0t,0),(s8ts9t,1),(s8ts9f ,1),(s0f s8t,1), (s0f s8f ,1),(s0f ,1) 1 7 1:s0ts5t \n2:s0ts5f (*s0ts5t,0),(*s0ts5f ,0),(s8ts9t,1),(s8ts9f ,1), (s0f s8t,1),(s0f s8f ,1),(s0t,1),(s0f ,1) 2 \n8 1:s0ts5t 2:s0ts5f s8t 3:s0ts5f s8f (*s0ts5t,0),(*s5f s8t,0),(*s5f s8f ,0),(s8ts9t,1), (s8ts9f ,1),(s0f \ns8t,1),(s0f s8f ,1),(s0t,1), (s0f ,1) 3 s0ts5f s8f s4 9 1:s0ts5t 2:s0ts5f s8t (*s0ts5t,0),(*s5f s8t,0),(s5f \ns8f ,1),(s8ts9t,1), (s8ts9f ,1),(s0f s8t,1),(s0f s8f ,1),(s0t,1), (s0f ,1) 2 10 1:s0ts5t 2:s0ts5f s8ts9t \n3:s0ts5f s8ts9f (*s0ts5t,0),(s5f s8t,1),(s5f s8f ,1),(*s8ts9t,1), (*s8ts9f ,1),(s0f s8t,1),(s0f s8f ,1),(s0t,1), \n(s0f ,1) 3 s0ts5ts6 . . . . . . . . . . . . . . . tion states, the column Priority Queue shows the count \nand position changes of the length-1 subpath, the structure e = (p, f ) with a * in the priority queue \nindicates that there are unterminated execution states which have the correspond\u00ading subpath p. When \nan execution state reaches the exit of the program, the corresponding test case will be generated and \nshown in the rightmost column, then the execution state is terminated and removed from the pending path. \n In the .rst 7 steps, subpath-guided search has the same selection as DFS. Three test cases are generated, \nwhich cover all the sub-paths started from s8. Three unterminated execu\u00adtion states with the path s0ts5t, \ns0ts5f s8t and s0ts5f s8f can be chosen. In step 8, the branch condition s5t becomes the least traveled \npart compared to s8f and s8t, subpath-guided search then drives symbolic execution to explore that branch \nand the case with the path s0s5s6 is generated as the 4th case, while DFS will select the third execution \nstate. In step 9, for all the count of the length-1 subpath is 1, subpath-guided search selects the latest \nexecution and generates the test case for s0ts5ts8f s4. It takes only 5 cases to cover all the state\u00adments \nin the example program with the guidance of length-1 SGS. Different lengths can provide different effects \nfor path guidance. Table 2 shows the procedure of the length-2 SGS. Same as the length-1 SGS, the length-2 \nSGS generates 5 cases to cover all the statements, and the same selection in the .rst 7 steps. The length-2 \nSGS counts the frequencies of the length\u00ad2 sub-paths. In step 8, the execution state corresponding to \nthe path s0ts5f s8f is selected because the sub-path s5f s8f has never been explored before. On the other \nhand, in length\u00ad1 SGS, the sub-path s8f is explored, and the execution state corresponding to the path \ns0ts5t is selected. The length-2 SGS considers more contextual information, which guides symbolic execution \nto possibly explore moree directions in a program. We see that the length-2 SGS takes one extra step \nthan length-1 SGS to generate cases covering all statements of the example program. The subpath-guided \nsearch can also avoid the fork bomb\u00ad 1 ing problem, if we replace s11 with s11: while (a < 10) a++; , \nthe DFS strategy will keep creating new execution 1 states in s11 and lead to the starvation of the other \nstates. Conversely, in our strategy, when both conditions in s11 are executed once, it prefers those \nstates with a zero count of the corresponding subpath to the loop entrance. When all the zero count subpaths \nare explored, the loop entrance node will be explored again.  2.4 Discussions Subpaths with different \nlengths provide various program spec\u00adtra and conceptually capture different levels of less traveled program \nparts. In our approach, shorter subpaths are more similar to using a single branch condition, and thus \nmay guide symbolic execution to cover those uncovered statements with higher probabilities. However, \nshorter subpaths contain less contextual information of the explored parts, thus some ex\u00adecution states \nmay share the same corresponding subpaths. In this case, symbolic exploration may ignore some special \nexecution states that lead to particular program parts. On the other hand, longer subpaths may divide \nthe execution states with smaller granularity, but some redundant test cases may be generated. In the \nnext section, we empirically explore such trade-offs and show how to synergistically combine the bene.ts \nof different choices of n. 3. Evaluation and Analysis This section presents our evaluation and analysis \nof the pro\u00adposed strategy. It describes details of our evaluation design, setup, and results. In particular, \nwe show that, on realistic pro\u00adgrams, our strategy systematically captures program-speci.c information \nand exhibits varying levels of effectiveness with different choices of n, and it performs signi.cantly \nbetter than traditional strategies in terms of test coverage and error detection. 3.1 Evaluation Design \nand Setup We have implemented the proposed length-n subpath guided search in KLEE [7, 23], a state-of-the-art \nsymbolic execution engine built on top of the LLVM compiler infrastructure. KLEE can process a large \nnumber of concurrent states and has strong support for handling interactions with the external environment \n[9]. KLEE also provide different built-in search strategies, including traditional DFS, random state \nsearch, and some other heuristic search strategies. Adding our uni.ed search strategy to KLEE, we are \nable to directly compare their effectiveness and trade-offs in test case generation not on toy programs, \nbut realistic programs from GNU Coreutils. Research Questions. Through empirical analysis, we hope to \nanswer the following key research questions: (R1) What impact do different choices of n have? Can they \nbe effectively combined? (R2) How does our strategy compare with the traditional strategies? In particular, \nfor (R1), we aim to understand what different characteristics the test suites generated from different \nn s have in terms of coverage and error detection. We will also understand whether there is a uniformly \nbest n. As for (R2), we seek to understand how our strategy compares Program ELOC Mutant Program ELOC \nMutant base64 3989 1204 nohup 3875 basename 4026 356 od 4463 6762 cat 3953 paste 3837 1525 chcon 4343 \n1313 pathchk 3857 1078 chgrp 4278 672 pr 4626 cksum 3983 1066 printenv 3881 comm 3997 820 printf 4251 \n2745 csplit 8589 pwd 3969 cut 4195 2821 readlink 4154 284 date 5688 rm 4560 dd 4734 5450 rmdir 3892 454 \ndf 4314 seq 3927 dircolors 4093 1527 setuidgid 3878 548 dirname 3889 209 shuf 4508 du 5790 2168 sleep \n4199 381 echo 3884 split 4428 2169 env 3937 334 stat 4210 expand 3916 1144 stty 4718 expr 9565 2333 sum \n4068 954 factor 3896 sync 3919 89 false 3897 tail 4495 fmt 3860 tee 3966 593 fold 3891 1064 test 3577 \ngroups 4002 232 touch 4744 1660 head 4170 tr 4150 6640 id 4067 true 3888 join 4617 tsort 3856 1120 kill \n3919 tty 3847 link 3829 272 uname 3810 ln 4200 unexpand 3903 1336 logname 3902 102 uniq 4048 ls 6549 \nunlink 3865 186 mkdir 4213 408 uptime 3896 mk.fo 3959 343 users 3907 mknod 3840 868 wc 4075 2205 mktemp \n4101 whoami 3856 nice 4010 764 yes 3901 nl 10037 1591 Table 3. Test subjects from GNU Coreutils. to \ntraditional strategies also in terms of coverage and error detection. We have designed and ran a set \nof experiments to answer these questions. Evaluation Subjects. To measure the effectiveness of dif\u00adferent \nlength-n subpath guided search strategy. Following KLEE, we have selected GNU COREUTILS utilities as \nthe test subjects. They are the basic .le, shell and text manipula\u00adtion utilities on the GNU operating \nsystem [11]. The version of COREUTILS that we use is 6.11 (as from the tutorials from KLEE s website). \nAll the experiments were ran on a server with Intel(R) Xeon(R) X7542 CPU (18 cores, 2.67GHz). The operating \nsystem is Ubuntu 10.04. The programs we use are shown in Table 3. The column ELOC shows the size of the \nprograms in terms of the number of executable lines of code (ELOC). ELOC shows the total executable lines \nof the .nal executable we ran KLEE on after optimization. Because KLEE may invoke library code to execute \nsome parts of the program we test, we also include the library code when measuring the raw size of the \nprograms, again following KLEE [7]. From the table, we can see that the size for most programs ranges \nbetween 3K to 4K, while six programs have more then 5K lines. This statistical information shows that \nthe programs are not tiny, toy problems. In addition, we have applied mutant testing [12] to evaluate \nthe effectiveness of the strategies. The column mutant lists those programs selected for mutant testing \nand the corresponding number of mutants for each selected program.  Traditional Strategies. KLEE provides \nfour main search heuristics: Depth-First Search (DFS), Random State Search (RSS), Random Path Selection \n(RPS), and Non Uniform Random Search (NURS). NURS randomly selects states according to a given distribution \nbased on some properties. In our evaluation, we choose the following properties: whether it covers new \ninstructions (covnew), the depth (depth), the Instr-Count heuristic (icnt), and the minimum distance \nto an uncovered instruction (md2u). The NURS is interleaved with Random Path Selection (RPS), while the \ndefault heuristics used by KLEE are random-path interleaved with nurs:covnew. For subpath-guided search, \nwe choose the length to range over {1, 2, 4, 8} for comparison. We ran KLEE on each program with the \ncommand: ./run<program> --search-strategy --max-time 3600 --sym-args 0 3 10 --sym-files 2 8 The option \n--max-time 3600 sets the time limit to 3, 600 seconds. The option --sym-args 0 3 10 allows KLEE to replace \n0 to 3 command line arguments of the pro\u00adgram with at most length 10. The option --sym-files 2 8 tells \nKLEE to make at most 2 standard input symbolic .les with maximal length 8. It is noted that KLEE can \ngenerate test cases for those unterminated execution states after the time limit. However, for some strategies, \nthere are many unterminated states, which may consume much of the algo\u00adrithms time and lead to inaccurate \ntime limits. To be fair in our comparison, we ignore the test cases corresponding to un\u00adterminated execution \nstates and compare different strategies with the test cases generated within the given time limit.  \n3.2 Test Coverage Results Our .rst set of evaluations focuses on evaluating the test coverage (in particular \nstatement coverage) of the generated test cases under different search strategies. We use the tool gcov \nto compute the statement coverage information. It can be used in conjunction with GCC and generate executables \nto pro.le an instrumented program. KLEE provides a tool to replay the test cases on the corresponding \nexecutable and gcov can calculate statement coverage. When measuring coverage, we only consider the code \nin the program itself and do not include the library code since it is invoked from many programs to avoid \ncounting them multiple times. By default, KLEE generates one test case for each terminated path. However, \nfor larger programs, it is quite costly to compute and re-execute the test cases covering explored parts \nof the program. Since our goal is to measure statement coverage, we use the --only-output-states-covering-new \noption on the KLEE command line, so that KLEE only outputs test cases for the paths covering new instructions \nin the main utility code (or hit an error). We have selected 75 programs in COREUTILS for cover\u00adage comparison. \nTable 4 shows the result of the comparison. We show the distribution of the coverage under each search \nstrategy. In addition, the row Avg. shows the average cov\u00aderage information across all programs. The \nrow Best lists the total number of programs with best coverage (for ties, we count 1 for each). Result \n1: SGS yields higher coverage. From Table 4, we observe that subpath-guided search (SGS) performs better \nthan the other strategies, across all choices of n. The NURS strategies do not perform well. One possible \nexplanation is that we ignore the cases corresponding to unterminated states. The results demonstrate \nthe disadvantages of the random choices: sometimes they cannot drive the execution states to reach the \nexit to effectively generate test cases. The random path search (RPS) strategy has similar results as \nlength-8 (i.e., n = 8) subpath guided search, which shows that for the COREUTILS programs, length-8 subpaths \nseem long enough to approximate complete paths. Result 2: No uniform best n for SGS. We observe that \nal\u00adthough the length-2 subpath-guided search shows the best results compared to the other strategies \n(both the highest average coverage and the most number of highest covered programs), it is still not \nthe best uniform n for about half of the programs. Different subpath lengths exhibit different characteristics, \nso we need a method to unify the guidance of different lengths. As we discussed in Section 2, different \nlength subpaths pro.le different spectra of a program. They can provide dif\u00adferent understanding of a \nprogram s behavior and guide sym\u00adbolic execution to different parts of the program. Combining the results \nof SGS with different subpath lengths may pro\u00advide a more comprehensive exploration of the program. To \n.nd out the power of combining different lengths results, we ran KLEE on the benchmarks with the guidance \nof each length subpath for 15 minutes. We replayed the test suites individually and then combined all \nthe test cases to see their effects. Result 3: Combined SGS performs the best. Table 5 pre\u00ad sents the \ncoverage distribution of the individual subpath\u00adguided search and the combined strategy. We observe that \nindividual strategies can quickly achieve high statement  Cov. SGS n = 1 SGS n = 2 SGS n = 4 SGS n = \n8 RSS DFS RPS NURS covnew NURS depth NURS icnt NURS md2u 90-100% 18 18 21 13 14 11 17 11 16 11 11 80-90% \n4 12 9 10 5 3 9 3 4 5 4 70-80% 14 16 12 13 5 6 12 2 12 3 3 60-70% 17 11 12 15 12 11 12 4 14 5 6 60%\u00ad \n22 18 21 24 39 44 25 55 29 51 51 Avg.(%) 69.67 72.87 72.35 66.95 60.56 56.12 68.38 46.87 64.35 51.72 \n50.50 Best 25 38 29 24 20 16 23 14 21 14 15 Table 4. The coverage distribution of the COREUTILS programs \nunder the guidance of different search strategies. Cov. n = 1 n = 2 n = 4 n = 8 Com 90-100% 9 15 11 8 \n25 80-90% 10 13 12 12 10 70-80% 19 10 12 17 19 60-70% 9 11 8 10 9 60%\u00ad 28 26 31 28 12 A.Cov(%) 66.06 \n68.88 66.22 65.88 80.67 Best 24 27 25 23 57 Table 5. The coverage distribution of subpath guided-search \nwith 15 minutes time limit and the result of the combined cases. The row Best is the comparison result \nof the test cases generated with individual strategies under 60 minutes time limit, and the combined \ntest cases of those in 15 minutes. coverage and saturate, and the combined strategy in 15 minutes can \nalready outperform all the other strategies in KLEE, each with 60 minute time limit. The comparison results \nof the total number of best coverage among the individual strategies in 1 hour and the combined strategy \nin 15 minutes each are shown in the row Best . We can see that the combined strategy has the best coverage \nin almost 80% of the programs and the average coverage is also signi.cantly higher. We also examined \nthe speed to .nd test cases covering new statements or branches by tracing the number of terminated states \nwhen each test case is generated and replaying the cases one by one to see the trend of increasing coverage. \nIn some bigger programs, length-1 SGS terminates fewer execution states when generating new test cases \nthan the longer lengths. However, when the coverage reaches a certain level, it becomes dif.cult to .nd \nnew test cases, while the longer n s can still guide path exploration to .nd new test cases and ultimately \ngain higher coverage. Result 4: SGS yields more bug reports. When KLEE ex\u00adplored the programs, it also \nissued some bug reports. Table 6 summarizes this information from the .rst set of evaluations in Table \n4. There are four kinds of bugs reported [23]: Model: KLEE does not support certain program states. \nFor example, KLEE cannot support symbolic sizes to malloc.  Exec: Some problems prevented KLEE from \nexecuting the program, such as unknown instructions, a call to an invalid function pointer, or inlined \nassembly.  Ptr: Stores or loads of invalid memory locations.  External: KLEE failed when invoking external \nfunctions with symbolic arguments.  In Table 6, we only show the programs where different search strategies \nyielded bug reports. The Model, Exec, and External bugs may be resulted from imprecise modeling in KLEE. \nHowever, to illustrate that our strategy was able to trigger some issues while the other strategies did \nnot, we included all types of bugs in the table. We observe that subpath-guided search reported both \nmore bugs and more types of bugs than the other strategies. Below we list some test cases that our strategies \nreported bugs, but the other strategies did not: dir: Both SGS n = 1 and n = 2 generated a Ptr error. \nThe command line arguments A // -c (generated with n = 1) and -ccab A / (generated with n = 2) with a \nnull directory A caused an out-of-bound pointer error in the library readdir.c:33 from uclibc.  chcon: \nSGS n = 1 reported an External error. When we use the command line arguments - d ra=g , KLEE failed on \nan external call to fstatat() in the Coreutils library fts.c:1394.  shuf: Both SGS n = 1 and n = 2 generated \na Model error. KLEE reported that the command line arguments -i 03-7@ (with n = 1) and -i3-8 (with n \n= 2) need to malloc with a symbolic argument, while KLEE does not support and has to concretize the argument. \n test: SGS n = 2 reported an Exec execution error. KLEE cannot execute the program with the command \nline argu\u00adments -t +01 , which makes KLEE execute the function syscall() in the POSIX support code fd.c:901 \nwith symbolic arguments.    Table 6. Bug reports from KLEE. The types of bugs are: Model, Exec, Ptr, \nand External. An empty cell indicates that the corresponding strategy did not report any errors. Each \nnonempty cell has two numbers: the .rst for the number of reported error types, and the second for the \ntotal number of error reports. A cell with a * indicates that the corresponding search strategy performed \nbest in bug .nding. Programs Strategy SGS n = 1 SGS n = 2 SGS n = 4 SGS n = 8 DFS RSS RPS NURS covnew \nNURS depth NURS icnt NURS md2u chcon *1,1 chgrp 1,1 1,1 1,1 1,1 1,1 1,1 1,1 1,1 1,1 1,1 csplit *1,2 1,1 \n1,1 1,1 1,1 dir *2,1 *2,1 1,1 1,1 1,1 1,1 1,1 1,1 1,1 1,1 head *1,2 1,1 *1,2 *1,2 1,1 ls 1,1 *2,1 1,1 \n1,1 1,1 1,1 1,1 1,1 1,1 1,1 1,1 od 1,3 1,4 *1,8 *1,8 1,1 1,6 1,4 1,2 1,3 1,2 1,2 printf *1,1 *1,1 1,1 \nrm 1,1 1,1 *1,2 1,1 *1,2 1,1 1,1 1,1 1,1 1,1 shuf *2,1 *2,1 split 1,1 *1,2 *1,2 1,1 1,1 1,1 1,1 1,1 1,1 \n1,1 1,1 stat *2,1 1,1 *2,1 *2,1 1,1 *2,1 1,1 1,1 1,1 1,1 1,1 test *1,1 unexpand 1,1 1,1 1,1 1,1 1,1 1,1 \n1,1 1,1 The error reports from different search strategies indicate that our strategy were able to trigger \nsuch issues but the other strategies did not. We can also observe that the guidance under different subpath \nlengths may lead to different bug reports. Result 5: SGS has acceptable overhead. In this experi\u00adment, \nwe observed that each search strategy has quite similar total number of explored paths as the other strategies \non most programs. This indicates that the SGS strategy does not incur much time overhead. As for space \noverhead, KLEE ran out of memory and crashed for a few programs, mainly because the constraint solver \nconsumed too much memory. This happened for almost all the search strategies and may be attributed to \nsome speci.c paths of the programs. This means that our SGS strategy also has similar and acceptable \nspace overhead compared to the other strategies.  3.3 Mutation Testing Results To further compare the \nusefulness of the generated test cases under different search strategies, we applied mutation testing \n[12] to measure the quality of the generated test cases. In mutation testing, small changes are applied \nto a program P to generate a set of faulty programs called mutants. A test suite is then executed on \nthe original program and the mutants. If the test data can detect the mutated code, we say the test suite \nkills a mutant. The ability to .nd bugs of a test suite can be measured by the number of mutants it kills. \nWe used a state-of-the-art mutation testing tool for C MILU [21] to generate mutants for the programs \nin CORE-UTILS. 21 pre-de.ned mutation operators are applied to make simple replacements to the programs \nin COREUTILS, such as replacing ++ with  or > with < . Then we replayed the test cases generated under \neach search strategy on the original version and the mutants, compared their out\u00adputs to decide whether \na mutant was killed by the test suite. Some programs in COREUTILS do not produce output or their output \nis environment related (such as date and df), it is dif.cult to tell whether the different outputs between \noriginal code and a mutant is caused by the test suite we used. In this case, we picked 40 of the programs \nfor this mutant testing evaluation. Table 3 shows the programs we chose, and for each program, its corresponding \nnumber of mutants. Because the size of each program is different, MILU generated different number of \nmutants for each program, ranging between 100 to around 6K. The total number of the mutants is 57, 790. \nUnlike what we did in the statement coverage evaluation, test cases were generated for every terminated \nstate. This is because the distribution of the small changes in the program may need some speci.c paths \nto show their effects, not only those test cases for paths that hit new instructions or branches that \nlead to different outputs in the original code and the mutants. Because the evaluation results from Section \n3.2 show that the combined subpath-guided search strategy is the most effective in terms of statement \ncoverage, we also added the combined strategy to our mutant testing evaluation. The results are shown \nin Table 7. Since the number of mutants for the programs varies widely, we use three dimensions to present \nthe results. The column Total Kill denotes the total number of mutants killed by the test suite generated \nunder the corresponding search strategy. Because some programs have a large number of mutants killed \nwhile  Strategy Ave. Kill Rate Total Kill Best n = 1 26.00% 14529 14 n = 2 27.65% 16072 8 n = 4 26.04% \n14930 9 n = 8 26.96% 13951 8 Combined SGS 32.17% 19719 24 RSS 23.03% 12267 4 DFS 18.63% 9632 2 RPS 25.16% \n13349 6 covnew 19.58% 10211 2 depth 21.80% 11105 3 icnt 19.23% 9987 2 md2u 18.44% 9208 2 Table 7. Mutation \ntesting results. some others only have a few, the total number of killed mutants may skew the contribution \nfrom the programs with fewer killed mutants. Thus, we calculate the mutant kill rate for each program \nand show the average kill rate in column Ave.Kill Rate . Like what we did in the statement coverage evaluation, \nwe count, for each strategy, its number of the most killed mutants and show the result in column Best \n. Result 6: SGS kills more mutants. From the result, we can see that the subpath-guided search strategies \nperform better than the other strategies in KLEE. The combined subpath\u00adguided search kills the most mutants \nand has the highest average kill rate. It should be noted that in this evaluation that the combined search \nstrategy has the best killed number in about 60% of the programs we analyzed, which is signi.\u00adcantly \nlower than the corresponding result from the statement coverage evaluation (around 80%). One possible \nexplana\u00adtion for this result is that we generated test cases for every terminated execution state, which \ntook more time than only generating test cases covering new statements or branches. In the combined search, \neach strategy only ran for 15 min\u00adutes, and sometimes that is not long enough to explore more parts of \nthe program. Nonetheless, the SGS strategies and its combined version still outperforms all the other \nstrategies.  3.4 Discussions Our approach provides a general, uni.ed framework to sys\u00adtematically guide \nsymbolic execution using subpath program spectra. We can use a speci.c n for different purposes. If we \nwant to cover more parts of the program in a short amount of time, a small n (such as 1) can be the desirable \nchoice as it ignores much of the contextual information and can explore program paths with less conditional \nbranches at the very beginning. However, the limited contextual information cannot provide powerful guidance \nwhen the coverage reaches a certain level, while some speci.c parts of the program may need certain loop \nor iteration times to enter. In this case, a larger n will be a more suitable choice as we can explore \nthe program with more program speci.c information and thus cover the program more thoroughly. On the \nother hand, longer n s may also be prone to guide symbolic execution to redundantly explore some paths \nand reduce the ef.ciency and effectiveness of path exploration. The combined strategy using different \nlength n appears to be striking a good balance between ef.ciency and effectiveness. 4. Related Work We \nhave proposed a uni.ed technique to guide symbolic path exploration to tackle the problem of path explosion, \nwhich is a signi.cant challenge for symbolic execution because systematically executing all feasible \npaths in large programs is costly. This section surveys closely related work on this topic. Many techniques \nhave been proposed in the literature to handle the problem from different aspects: path guidance, path \npruning, and parallel execution. Path Guidance Techniques. Different search strategies have been proposed \nand used in symbolic or concolic test\u00ading. The EXE tool by Cadar et al. [8] employs a Best-First Search \nstrategy, which checks all execution states and picks the best one according to some heuristics. Hybrid \nConcolic Testing [24] is a technique proposed to interleave random testing with concolic execution to \nobtain a deep and wide exploration. The control-.ow guided search strategy [6] con\u00ad structs a weighted \ncontrol .ow graph (CFG), guiding the exploration to the nearest currently uncovered parts based on the \ndistance in the CFG when the concolic testing needs to choose branches to negate. The .tness-guided search \nstrat\u00adegy [32] calculates .tness values from explored paths to target predicates and .tness gains for \nthe branches to be .ipped, then selects proper paths and branches to cover the target predicates. SAGE \n[18] proposes a new search algo\u00ad rithm, generational search, to address the practical limitations of \npath explosion and imperfect symbolic execution. Similar to Best-First Search, generational search tests \nall children of each expanded execution, scores their entire runs and picks one with the top score to \nrun and check. The search strategy in Pex [30] shares some similarity to ours. It maintains an explored \nexecution tree and picks an outgoing branch every time. However, our strategy is more general and .exible \nas it provides a spectrum of techniques to guide path ex\u00adploration. We make decisions guided by more \ninformation from the explored paths, which provides better guidance. Our combined strategy also offers \na good balance of cost and effectiveness, and can be fruitfully incorporated in existing (directed) symbolic \nexecution engines. Path Pruning Techniques. There also exist techniques that address the path explosion \nproblem by path pruning. The RWset analysis technique [5] tracks the memory locations read and written \nby the program to determine whether a path can explore new program behavior. Those execution states that \nare deemed to produce the same effects as some already explored paths will be pruned to reduce the number \nof explored paths. The tool eXpress [29] introduces dynamic symbolic execution for regression test generation \nand prunes paths that do not expose behavioral differences while ex\u00adploring new program versions. The \nSMART [16] technique performs concolic testing compositionally by adapting in\u00adterprocedural static analysis. \nWhile these path pruning tech\u00adniques focus on avoiding redundant path explorations, our technique focuses \non guiding symbolic execution to explore more pro.table paths. These are complementary approaches to \ntackle the path explosion problem and may be fruitfully combined.  Parallel Symbolic Execution. Finally, \nthere are also com\u00adplementary parallel symbolic execution techniques [28] pro\u00ad posed to mitigate the \npath explosion problem in symbolic execution. They use simple static partition techniques to help divide \nthe symbolic execution tree and then in parallel ex\u00adplore the partitions utilizing multi-core machines \navailable from cloud or grid computing environments. 5. Conclusion and Future Work In this paper, we \nhave introduced a general, uni.ed frame\u00adwork to intelligently guide symbolic execution to improve test \ncoverage and error detection. Our key insight is to use length-n subpath program spectra to systematically \nsteer path exploration to less explored parts of a program. We have implemented our framework in a state-of-the-art \nsymbolic execution engine KLEE. Results on a large number of small to medium size real-world programs \nshow that our uni.ed search strategy can generate test cases with higher coverage in less time compared \nto common traditional strategies. We also show that the generated test cases can help locate more bugs. \nFinally, we have proposed a natural combination of the specialized strategies under different choices \nof n and show that it offers the best trade-offs of cost and effectiveness. We believe that our general \nframework can be incorporated in existing symbolic execution engines besides KLEE (such as Pex and JPF) \nand have potential applications in other soft\u00adware testing and analysis problems that require path-based \nanalysis. There are several interesting avenues for future work. First, we would like to explore how \nto effectively interleave our strategy with other strategies to more intelligently break ties among states \nwith same subpath frequencies. Second, we are also interested in investigating how to dynamically adjust \nn, for example, by tracking certain program properties. Once the current n cannot provide worthwhile \npro.t for its cost (determined by the properties we track), we may adjust n. Other promising directions \ninclude synergistic combinations with path pruning or parallel symbolic execution. Beyond symbolic execution, \nit would be interesting to apply the same concept to other testing and analysis problems, especially \nthose that rely on path analysis. Acknowledgments We thank the anonymous reviewers for constructive feedback \non earlier drafts of this paper. This research was supported in part by the National Natural Science \nFoundation of China (No. 91318301, 61170066, and 61021062), the National 863 High-Tech Program of China \n(No. 2012AA011205), and United States NSF Grants 0917392, 1117603 and 1319187. The information presented \nhere does not necessarily re.ect the position or the policy of the Government and no of.cial endorsement \nshould be inferred. References [1] S. Anand, C. S. P.areanu, and W. Visser. JPF SE: A sym\u00ad as.bolic execution \nextension to Java PathFinder. In Tools and Algorithms for the Construction and Analysis of Systems, pages \n134 138. Springer, 2007. [2] V. Bala, E. Duesterwald, and S. Banerjia. Transparent dynamic optimization: \nThe design and implementation of Dynamo. Technical report, Technical Report HPL-1999-78, Hewlett-Packard \nLaboratories, 1999. [3] V. Bala, E. Duesterwald, and S. Banerjia. Dynamo: a transpar\u00adent dynamic optimization \nsystem. In ACM SIGPLAN Confer\u00adence on Programming Language Design and Implementation, pages 1 12. ACM, \n2000. [4] T. Ball and J. Larus. Ef.cient path pro.ling. In ACM/IEEE International Symposium on Microarchitecture, \npages 46 57. IEEE Computer Society, 1996. [5] P. Boonstoppel, C. Cadar, and D. Engler. RWset: Attacking \npath explosion in constraint-based test generation. In Inter\u00adnational Conference on Tools and Algorithms \nfor the Con\u00adstruction and Analysis of Systems, pages 351 366. Springer, 2008. [6] J. Burnim and K. Sen. \nHeuristics for scalable dynamic test generation. In IEEE/ACM International Conference on Auto\u00admated Software \nEngineering, pages 443 446. IEEE Computer Society, 2008. [7] C. Cadar, D. Dunbar, and D. Engler. KLEE: \nUnassisted and automatic generation of high-coverage tests for complex systems programs. In USENIX Symposium \non Operating Systems Design and Implementation, pages 209 224, 2008. [8] C. Cadar, V. Ganesh, P. Pawlowski, \nD. Dill, and D. Engler. EXE: automatically generating inputs of death. ACM Transac\u00adtions on Information \nand System Security (TISSEC), 12(2):10, 2008. [9] C. Cadar, P. Godefroid, S. Khurshid, C. Pasareanu, \nK. Sen, N. Tillmann, and W. Visser. Symbolic execution for software testing in practice: preliminary \nassessment. In International Conference on Software Engineering, pages 1066 1071. IEEE, 2011. [10] L. \nA. Clarke. A system to generate test data and symbolically execute programs. IEEE Transactions on Software \nEngineer\u00ading, 2(3):215 222, 1976. [11] Coreutils -GNU core utilities. http://www.gnu.org/ software/coreutils/. \n [12] R. DeMillo, R. Lipton, and F. Sayward. Hints on test data selection: Help for the practicing programmer. \nComputer, 11(4):34 41, 1978. [13] E. Duesterwald and V. Bala. Software pro.ling for hot path prediction: \nLess is more. In International Conference on Architectural Support for Programming Languages and Operating \nSystems, pages 202 211. ACM, 2000. [14] J. W. Duran and S. C. Ntafos. An evaluation of random testing. \nIEEE Transactions on Software Engineering, 10(4):438 444, 1984. [15] R. Ferguson and B. Korel. The chaining \napproach for soft\u00adware test data generation. ACM Transactions on Software Engineering and Methodology \n(TOSEM), 5(1):63 86, 1996. [16] P. Godefroid. Compositional dynamic test generation. In ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, pages 47 54. ACM, 2007. [17] P. Godefroid, N. Klarlund, \nand K. Sen. DART: directed automated random testing. In ACM SIGPLAN Conference on Programming Language \nDesign and Implementation, pages 213 223. ACM, 2005. [18] P. Godefroid, M. Levin, D. Molnar, et al. Automated \nwhitebox fuzz testing. In Network and Distributed System Security Symposium. The Internet Society, 2008. \n[19] D. Hamlet and R. Taylor. Partition testing does not inspire con.dence [program testing]. IEEE Transactions \non Software Engineering, 16(12):1402 1411, 1990. [20] M. Harrold, G. Rothermel, K. Sayre, R. Wu, and \nL. Yi. An empirical investigation of the relationship between spectra differences and regression faults. \nSoftware Testing Veri.cation and Reliability, 10(3):171 194, 2000. [21] Y. Jia and M. Harman. Milu: A \ncustomizable, runtime\u00adoptimized higher order mutation testing tool for the full C language. In Testing: \nAcademia and Industry Conference -Practice And Research Techniques, pages 94 98. IEEE, 2008. [22] J. \nKing. Symbolic execution and program testing. Communi\u00adcations of the ACM, 19(7):385 394, 1976. [23] The \nKLEE symbolic virtual machine. http://klee.llvm. org/. [24] R. Majumdar and K. Sen. Hybrid concolic testing. \nIn International Conference on Software Engineering, pages 416 426. IEEE, 2007. [25] D. Marinov, A. Andoni, \nD. Daniliuc, S. Khurshid, and M. Ri\u00adnard. An evaluation of exhaustive testing for data structures. Technical \nreport, Technical Report MIT-LCS-TR-921, MIT CSAIL, Cambridge, MA, 2003. [26] C. S. P.areanu and W. Visser. \nVeri.cation of Java programs as.using symbolic execution and invariant generation. In Model Checking \nSoftware, pages 164 181. Springer, 2004. [27] T. Reps, T. Ball, M. Das, and J. Larus. The use of program \npro.ling for software maintenance with applications to the Year 2000 problem. In Joint Meeting of the \nEuropean Software Engineering Conference and the ACM SIGSOFT International Symposium on Foundations of \nSoftware Engineering, pages 432 449, 1997. [28] M. Staats and C. Pa.sa.reanu. Parallel symbolic execution \nfor structural test generation. In International Symposium on Software Testing and Analysis, pages 183 \n194. ACM, 2010. [29] K. Taneja, T. Xie, N. Tillmann, and J. de Halleux. eXpress: guided path exploration \nfor ef.cient regression test generation. In International Symposium on Software Testing and Analysis, \npages 1 11. ACM, 2011. [30] N. Tillmann and J. De Halleux. Pex white box test generation for .NET. Tests \nand Proofs, pages 134 153, 2008. [31] W. Visser, C. S. P.areanu, and R. Pel\u00b4as.anek. Test input genera\u00adtion \nfor Java containers using state matching. In International Symposium on Software Testing and Analysis, \npages 37 48. ACM, 2006. [32] T. Xie, N. Tillmann, J. de Halleux, and W. Schulte. Fitness\u00adguided path \nexploration in dynamic symbolic execution. In IEEE/IFIP International Conference on Dependable Systems \nand Networks, pages 359 368. IEEE, 2009. [33] X. Yang, Y. Chen, E. Eide, and J. Regehr. Finding and under\u00adstanding \nbugs in C compilers. In ACM SIGPLAN Conference on Programming Language Design and Implementation, pages \n283 294. ACM, 2012.   \n\t\t\t", "proc_id": "2509136", "abstract": "<p>Symbolic execution is a promising testing and analysis methodology. It systematically explores a program's execution space and can generate test cases with high coverage. One significant practical challenge for symbolic execution is how to effectively explore the enormous number of program paths in real-world programs. Various heuristics have been proposed for guiding symbolic execution, but they are generally inefficient and ad-hoc. In this paper, we introduce a novel, unified strategy to guide symbolic execution to less explored parts of a program. Our key idea is to exploit a specific type of path spectra, namely the <i>length-n subpath program spectra</i>, to systematically approximate full path information for guiding path exploration. In particular, we use frequency distributions of explored length-<i>n</i> subpaths to prioritize \"less traveled\" parts of the program to improve test coverage and error detection. We have implemented our general strategy in KLEE, a state-of-the-art symbolic execution engine. Evaluation results on the GNU Coreutils programs show that (1) varying the length <i>n</i> captures program-specific information and exhibits different degrees of effectiveness, and (2) our general approach outperforms traditional strategies in both coverage and error detection.</p>", "authors": [{"name": "You Li", "author_profile_id": "83358709657", "affiliation": "Nanjing University, Nanjing, China", "person_id": "P4290304", "email_address": "leo86@seg.nju.edu.cn", "orcid_id": ""}, {"name": "Zhendong Su", "author_profile_id": "81100108298", "affiliation": "University of California, Davis, Davis, CA, USA", "person_id": "P4290305", "email_address": "su@cs.ucdavis.edu", "orcid_id": ""}, {"name": "Linzhang Wang", "author_profile_id": "81408602738", "affiliation": "Nanjing University, Nanjing, China", "person_id": "P4290306", "email_address": "lzwang@nju.edu.cn", "orcid_id": ""}, {"name": "Xuandong Li", "author_profile_id": "81409596981", "affiliation": "Nanjing University, Nanjing, China", "person_id": "P4290307", "email_address": "lxd@nju.edu.cn", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509553", "year": "2013", "article_id": "2509553", "conference": "OOPSLA", "title": "Steering symbolic execution to less traveled paths", "url": "http://dl.acm.org/citation.cfm?id=2509553"}