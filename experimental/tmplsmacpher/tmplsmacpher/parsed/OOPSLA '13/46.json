{"article_publication_date": "10-29-2013", "fulltext": "\n On-the-.y Detection of Instability Problems in Floating-Point Program Execution Tao Bao Xiangyu Zhang \nDepartment of Computer Science, Purdue University {tbao, xyzhang}@cs.purdue.edu Abstract The machine \nrepresentation of .oating point values has lim\u00adited precision such that errors may be introduced during \nexecution. These errors may get propagated and magni.ed by the following operations, leading to instability \nproblems, e.g., control .ow path may be undesirably altered and faulty output may be emitted. In this \npaper, we develop an on\u00adthe-.y ef.cient monitoring technique that can predict if an execution is stable. \nThe technique does not explicitly com\u00adpute errors as doing so incurs high overhead. Instead, it de\u00adtects \npossible places where an error becomes substantially in.ated regarding the corresponding value, and then \ntags the value with one bit to denote that it has an in.ated error. It then tracks in.ation bit propagation, \ntaking care of opera\u00adtions that may cut off such propagation. It reports instability if any in.ation \nbit reaches a critical execution point, such as a predicate, where the in.ated error may induce substan\u00adtial \nexecution difference, such as different execution paths. Our experiment shows that with appropriate thresholds, \nthe technique can correctly detect that over 99.999996% of the inputs of all the programs we studied \nare stable while a tradi\u00adtional technique relying solely on in.ation detection mistak\u00adenly classi.es \nmajority of the inputs as unstable for some of the programs. Compared to the state of the art technique \nthat is based on high precision computation and causes several hundred times slowdown, our technique \nonly causes 7.91 times slowdown on average and can report all the true un\u00adstable executions with the \nappropriate thresholds. Categories and Subject Descriptors F.3.2 [Logics and Meanings of Programs]: Semantics \nof Programming Lan- Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. Copyrights \nfor components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. \nTo copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. Request permissions from permissions@acm.org. OOPSLA 13, October 29 31, 2013, \nIndianapolis, Indiana, USA. Copyright c &#38;#169; 2013 ACM 978-1-4503-2374-1/13/10. . . $15.00. http://dx.doi.org/10.1145/2509136.2509526 \n guages; D.2.5 [Software Engineering]: Testing and Debug\u00adging; G.1.0 [Numerical Analysis]: General Keywords \n.oating point representation; .oating point er\u00adrors; instability; continuity; discrete factors; sampling \n1. Introduction The machine representation of .oating point values has pre\u00adcision limitations. When a \nvalue cannot be precisely rep\u00adresented, an error is implicitly introduced. For instance, when reading \nan input number of 0.9997 into a 32-bit single precision variable, the best representable value is 0.999700009822 \n\u00b7 \u00b7\u00b7. We hence have an initial error of -0.000000009822 \u00b7 \u00b7\u00b7. When we add a very small value to a very \nlarge value, the small value may be too small to make a difference in the represented result, leading \nto an error. Such errors are propagated and accumulated, and eventually may lead to serious problems \nwhen they become comparable to the program values. During the Gulf War in 1991, the patriot missile s \nfailure to intercept an incoming missile, causing 28 casualties and around 100 injuries, was due to the \nloss of precision in com\u00adputation. As revealed in the U.S. Government Accountabil\u00adity Of.ce report [32], \nthe range gate s prediction of where the Scud will next appear is a function of the Scud s known velocity \nand the time of the last radar detection. The con\u00adversion of time from an integer to a real number cannot \nbe any more precise than 24 bits. This conversion results in a loss of precision causing a less accurate \ntime calculation. Consequently the predicated position drifted away from the target. Due to its importance, \nresearchers have developed vari\u00adous techniques to address the problem. Traditionally, error analysis \nis conducted on mathematical models [37]. How\u00ad ever, modern data processing uses more complex models \nand relies on computers and programs, rendering mathemat\u00adical analysis dif.cult. Interval arithmetic \n[29, 31] and af.ne arithmetic [10, 11, 13, 15] are program analysis that model errors as ranges or af.ne \nformulas to reason about stabil\u00adity. Program transformation was proposed to improve pre\u00adcision and stability \n[1, 4]. Abstract interpretation and theo\u00ad rem proving techniques [9, 16, 27] were developed to reason \nabout stability statically. Most existing techniques treat instability as bugs and fo\u00adcus on identifying \nbuggy statements so that developers can .x them. We observe that the input range in which a .oating point \nprogram is unstable is usually a very very small portion of the input domain. In other words, even a \nnaive implemen\u00adtation may work .ne in most cases. While this explains why many people are willing to \nstay with their unstable imple\u00admentations, it also suggests that using high precision com\u00adputation [4] \nor crafting a more stable implementation [36] may not pay off. With a traditional view of debugging, \none may argue that we should nonetheless .x an instability bug despite its low probability to occur. \nHowever, different from traditional functional bugs, we observe that instability bugs are fundamentally \ninevitable with the limited precision of the machine representation. Using high precision compu\u00adtation \nor more stable implementation could mitigate them, but unlikely .xes them completely (we will further \nelabo\u00adrate this observation in Section 2). Fortunately, compared to functional bugs, instability bugs \nare predictable. Evidence can be collected during a .oating point program execution to predict if the \nexecution is stable. Moreover, many existing techniques are too expensive to be used on-the-.y for real \nworld tasks. For example, the state of the art technique using high precision [4] causes 167 1016 times \nslowdown (i.e. the time-to-complete increased by 167 1016 times). Hence, we argue that to tackle instability \nproblems, in\u00adstead of following the traditional way of .nding and .x\u00ading bugs, we shall develop ef.cient \nprediction technique that runs together with the original program. Upon detect\u00ading a potentially unstable \nexecution, the execution should be automatically restarted with a higher precision. This ap\u00adproach avoids \npaying the substantial overhead of high preci\u00adsion computation for most inputs, and saves the human ef\u00adforts \nin developing more stable implementation, which may not be feasible in many cases. In this paper, we \ndevelop a stability predictor that is prac\u00adtically conservative, suf.ciently precise, and much more cost-effective \ncompared to using high precision libraries (HPL) [4]. The technique does not explicitly compute errors \nas doing so incurs high overhead. Instead, it detects possible places where an error becomes substantially \nin.ated regard\u00ading the corresponding value, and then tags the value with single bit to denote that it \nhas an in.ated error. It then tracks in.ation bit propagation, taking care of operations that may cut \noff such propagation. It reports instability if any in.ation bit reaches a critical execution point, \nsuch as a predicate, where the in.ated error may induce substantial execution difference, such as following \ndifferent execution paths. Our contributions are highlighted as follows.  Figure 1. Various code snippets \nthat compute z = (x - 1)4 . We analyze the characteristics of .oating point instability bugs and disclose \ntheir differences from functional bugs. Such differences serve as the basis of our work.  We propose \na novel online prediction technique. The technique approximates errors with single bits to al\u00adlow ef.cient \nrepresentation and propagation. Its low cost compared to existing techniques allows us to screen out \nstable executions, which are the most common cases, while its conservativeness allows us to still capture \nall the true instability problems in practice.  We study the completeness and the soundness of the technique. \n We have overcome a number of challenges when apply\u00ading the technique to real-world programs, including \nhan\u00addling speci.c .oating point programming patterns that could introduce a lot of false warnings, e.g. \nconvergence tests in iterative methods.  Our evaluation shows that the predictor is very effec\u00adtive. \nWith threshold tc=481, it can correctly determine over 99.999996% of the input space is stable with 691% \noverhead on average, which is 14 times cheaper than a high-precision-always system such as [4]. Even \nwith a more conservative threshold (tc=36), it can still correctly detect over 99.9997% of the input \nspace is stable. With tc=48, our technique reports instability for 7.5-93 times more inputs compared \nto the ground truth, due to its con\u00adservativeness, which however only counts as 1.5E-11% \u00ad3.3E-6% of \nthe input domain.  2. Motivation Consider the example in Fig.1(a). Mathematically, the code snippet \ncomputes z = (x - 1)4 (in its expanded form) and makes decision according to the result at line 4. Assume \nthat the input value is x = 1.84089642. In the ideal world, it produces z = 0.5000000112886329660976, \nand thus prints hit at the end. However, when we execute it on a 32-bit x86 machine, we get miss instead \nas some of the inter\u00admediate values cannot be precisely represented. The repre\u00adsentation errors get propagated \nand enlarged, and eventually falsify the branch outcome at line 4. A plausible solution is to use data \ntypes with higher precision as in Fig.1 (b), in which the previous single-precision variables are re.ned \nwith the 1 The meaning of the threshold will be de.ned in Section 5.  Figure 2. Problematic ranges for \nversions in Fig.1. double-precision type. The modi.ed program produces the expected result with the original \ninput. However, it pro\u00adduces wrong outputs with two other slightly different inputs x = 1.8408964152537146 \nand x = 1.8408964152537148. In fact, such unstable cases can always be found for any .nite precision. \nAnother solution is to devise a numerically stable ver\u00adsion of the underlying algorithm, as in Fig.1 \n(c). It pro\u00ad duces correct output for some inputs that induce wrong outputs in Fig.1 (a) and (b). For \ninstance, it produces the correct result for x = 1.8408964152537148. However, it remains problematic \nfor some other inputs including x = 1.8408964152537146. To further study the effect of these improvements \non precision, we execute the three versions with a large num\u00adber of input samples that are evenly distributed \nwithin the range from 0.0 to 2.0, with the interval of 1E-16. A sample run is considered problematic \nif its output differs from the ideal one that is emulated using the high precision library (HPL) [4]. \nWe then count the number of problematic cases. These numbers represent the precision of the corresponding \nversions. Fig.2 shows the results, with wave-lines represent\u00ad ing the problematic cases. Observe that \nthe majority of the problematic runs occur around the intersections of the curve y = (x -1)4 -0.5, which \nis the mathematical function of the predicate at line 4, and the x-axis. We zoom-in one of the two intersections, \nnamely [1.84,1.85]. Out of the 100,000 billion samples in this range, there are about 3 billion prob\u00adlematic \nsamples for the single-precision version in Fig.1 (a). The number gets down to 8 for the double-precision \nversion in Fig.1 (b). Two problematic cases are still observed with the stable approach in Fig.1(c). \nObservations. Based on the previous discussion, we sum\u00admarize the characteristics of the instability \nproblem as fol\u00adlows. The instability problem cannot be completely evaded by using more precise types \nor different implementations. Using more precise types implies higher overhead. De\u00adveloping a more stable \nimplementation requires in-depth understanding of the program and a lot of human efforts. In many cases, \nsuch more stable implementation may not be easily achievable. A .oating point program only suffers from \nthe instability problem for a very small input range. Consider Fig.2. Even the implementation with the \nlowest precision, i.e. case (a), only causes problems with the likelihood of 0.003% within the small \ninput sub-range [1.84,1.85]. It works properly for most inputs. This partially explains why there are \nso many unstable programs being used in reality. For example, we observe that four of the SPEC programs \nwe analyzed are unstable. Detailed results are presented in Section 8.2.  For a deterministic functional \nbug, a program must fail given the same failure inducing input. In contrast, given a particular input \nthat leads to instability in a .oating point program, we can evade the problem for the particular in\u00adput \nusing more precise data types and operations, which can be done automatically.  Instability problems \nare predictable. For example, a very straightforward sign of such problems is that some of the internal \ncomputations have a value very close to zero, such as the subtraction entailed by the comparison at line \n4 in Fig. 1.  Solution Overview. Hence, instead of testing/analyzing a program exhaustively to expose \npotential instability prob\u00adlems caused by representation errors and .xing them like .xing functional \nbugs, as advocated in existing work [4, 7, 10, 36], we propose to develop an ef.cient runtime detection \ntechnique to predict on-the-.y if an execution is stable in the presence of representation errors. If \nnot, the user could choose to restart the program execution with the high pre\u00adcision support. It avoids \nusing high precision all the time, which is very expensive, leveraging the observation that low precision \nsuf.ces most of the time. The basic idea is to monitor program execution and de\u00adtect instruction executions \nthat lead to substantial growth of relative error, i.e. the ratio between an error and its corre\u00adsponding \nvalue. Such detection is performed without explic\u00aditly computing errors because doing so is very expensive. \nInstead, it is approximated by observing the operand and re\u00adsult values of an operation, especially their \nexponents. Intu\u00aditively, if the operands have large exponents but the result has a small one and the \ndifferences exceed a threshold, we consider the relative error has encountered an in.ation. The subtraction \nat line 4 in Fig. 1 is an example for such oper\u00ad ations. In practice, these operations occur quite often \nwhile only very few of them really cause problems. In most cases, the in.ated relative errors are suppressed/masked \nduring ex\u00adecution such that they cannot cause any problems. For exam\u00adple, if a small value with an in.ated \nrelative error is added to a large value, the relative error is suppressed, because the relative error \nof the result returns to a very low level. Hence, our technique not only detects error in.ation, but \nalso tracks propagation of in.ated relative errors and checks if they can reach critical execution points, \ne.g. predicates, without be\u00ad 1. float x,y,z;  1. float x,z; 2. x=input (); 2. float A[10]={1.0, 2.0, \n...}; 3. y=f(x); 3. int i; 4. if (y>1.0) 4. x=input (); 5. z=x+1.0; 5. i=(int)f(x); else 6. z=A[i]*x; \n6. z=x-1.0; 7. output (z); 7. output (z); (a) (b) Figure 3. Discrete difference examples. ing suppressed. \nNote that when an in.ated error reaches a predicate, it may induce a different execution path, leading \nto undesirable outcome, as illustrated in the example. If our technique detects that an in.ated relative \nerror can reach any critical execution point, the execution is .agged as unstable. The technique provides \nthe capability of automat\u00adically switching to executing a high precision version of the program, which \nis automatically generated at compile time. 3. Problem De.nition Our goal is to develop a cost-effective \ntechnique to deter\u00admine if an execution is stable in the presence of representa\u00adtion errors. According \nto the previous discussion, representa\u00adtion errors are inevitable due to the limited precision in com\u00adputation. \nHowever, in most cases, they are not substantial enough to cause any problems. Therefore, we .rst need \nto de.ne the criterion when such errors become un-acceptable. In existing work [4, 10], this is usually \ndetermined by ob\u00ad serving .nal output errors. However, it remains dif.cult to determine how much output \ndifference should be considered un-acceptable. In this paper, we de.ne an execution is unstable if the \nactual execution (with limited precision) and the ideal exe\u00adcution (with in.nite precision) have discrete \ndifferences. Discrete differences are differences of discrete types, such as int and bool. Sample discrete \ndifferences include control .ow differences and array index differences. An ex\u00adecution is unstable if \nits control .ow in the actual world is different from that in the ideal world; or an array index gen\u00aderated \nby a type cast of a .oating point value has different values in the two worlds. The intuition is that \nif we con\u00adsider the output of an execution as a mathematical function over inputs, the function becomes \ndiscontinuous, or has dif\u00adferent continuous forms in the input space, due to discrete differences. Consider \nthe examples in Fig. 3. In (a), if y is very close to 1.0, the representation error may change the branch \noutcome so that the mathematical form of the output could be either z = x + 1.0 or z = x - 1.0. In (b), \nif f (x) is very close to 1.0, the representation error may cause i = 0 or i = 1. Consequently, the mathematical \nform of the output could be either z = 1.0 * x or z = 2.0 * x. Besides places that may have discrete \ndifferences, there are some mathematical functions that are intrinsically dis\u00adcontinuous so that small \ninput changes could also cause ar\u00adbitrarily large output changes. For instance, f = t an(x) is p discontinuous \nat x = -p 2 , 2 ,\u00b7\u00b7\u00b7. When x is around those val\u00adues, representation errors could cause substantial output \ndif\u00adferences. In practice, we observe that programmers usually insert predicates to guard these functions \nagainst discontin\u00aduous inputs, to avoid uncontrollable output variations. As a result, the discontinuity \nmanifests itself as discrete differ\u00adence of the predicate. Hence, our discussion will focus on discrete \ndifferences. The problem statement, however, implies expensive de\u00adtection techniques as it requires \ndetecting any changes in the discrete domain of a program execution. Next we introduce the concept of \ndiscrete factors so that we can simplify the problem statement to make it more tractable. Background: \nDiscrete Factors. Discrete factors are intro\u00adduced in [2] to model output discontinuity caused by exter\u00ad \nnal input uncertainty. A discrete factor is an operation that has .oating point values 2 as operands \nand produces a dis\u00adcrete value as result. Discrete factors are the interface be\u00adtween the continuous \nand the discrete domains. Since repre\u00adsentation errors originate from the continuous domain, they can \nonly cause discrete differences by inducing different dis\u00adcrete values at discrete factors. As a result, \nwe only need to monitor execution of discrete factors instead of all program artifacts with discrete \ntypes. Control .ow predicates that are relational operations of .oating point values are the dominant \ntype of discrete factor. Other discrete factor examples include type casts that cast a .oating point \nvalue to an integer, and discrete mathematical library functions, e.g. sign(). Most discrete factors \ncan be determined by the compiler statically. D Therefore, we have the following re.ned problem de.ni\u00adtion. \nWe consider an execution unstable if the errors of the .oating point operands at any discrete factor \nare large enough to induce a different discrete value. As such, we only need to detect discrete differences \nat discrete factors. 4. Floating Point Representation and Errors Representation precision limitations \nare the root cause of the instability problem. According to the standard of the 32-bit single precision \n.oating point format representation de.ned in IEEE 754 [20], a decimal value f is represented as follows. \nf = (1 - 2s) \u00d7 (1 + m \u00d7 2-23) \u00d7 2e-127 Variable s is the sign bit (zero or one), m is the signi.cand, \nwhich is also called mantissa, and e is the exponent. Fig. 4 shows this representation. Observe that \nthere are 8 exponent bits denoting the expo\u00adnent range [-127,128]. There are altogether 24 mantissa bits, \nincluding a hidden leading bit of 1 , so that any values that 2 To simplify discussion, we assume .oating \npoint a continuous type equiv\u00adalent to real type.  Figure 4. Float Point Representation. x, y, z: 32-bit \nsingle precision .oating point program variables so that their precision is limited by the format speci.cation. \nx: the precise value of x (with in.nite precision). .x: the error of x (with in.nite precision). .x: \nthe relative error of x. Table 1. De.nitions. require more signi.cand bits to represent cannot be precisely \nrepresented. During execution of a .oating point program, errors are generated and propagated as follows. \nFloating point con\u00adstants in the source code may not be precisely represented such that initial errors \nare introduced at compile time. At runtime, when .oating point values are loaded from .les or the standard \ninput, they are usually converted from strings so that representation errors may also be introduced. \nAs shown in Table 1, we denote the value of a variable x in the ideal world (with in.nite precision) \nas x. The symbol x also de\u00adnotes the value in the actual world (with error). Hence, we have x = x + . \nx. The initial errors are further propagated to the internal of program execution through operations. \nIn particular, the error of the result of an operation includes those inherited from the operands, and \nthe representation error of the result value itself. For example, assume two variables x and y with errors. \nz = x + y = (x + . x) + (y + . y) = (x + y) + ( . x + . y) (1) The sub-expression x + y denotes the addition \nin the ac\u00adtual world and . x +. y denotes the inheritance of the operand errors. Note that it is possible \nthat the results of the two sub\u00adexpressions themselves cannot be precisely represented so that further \nrepresentation errors are introduced. Explicitly monitoring errors requires representing and computing \nerrors that are usually in a very small scale, which is expensive. Therefore, we introduce the notion \nof relative error. De.nition 1. The relative error of a variable x, denoted by .x, is computed as |. \nx/x|. Given a discrete factor x > y, if the relative error of x - y is larger than 1.0, the factor may \nhave different discrete outcomes in the actual world and the ideal world. This is because the error of \nx - y is larger than x - y itself and may have a different sign. As such, the relational expression (x \n- y > 0) has a different boolean outcome. For a discrete factor i = (int )x, if the relative error of \nx - ( f l oat )i has a larger than 1.0 relative error, the factor may have different discrete outcomes \nas well. One can easily infer from the .oating point format rep\u00adresentation (Fig. 4) that an initial \nrelative error, i.e. the relative error of a constant or an input v, is bounded by 1/2(# of mantissa \nbits of v)-1 because the error is bounded by the value represented by the least mantissa bit. As we will \nshow later, .oating point operations except subtractions (or addi\u00adtions of operands with opposite signs) \nlead to no growth or very slow growth of relative errors. It is unlikely that they can grow so large \n(e.g. larger than 1) over time to induce discrete differences. Instead, most unstable executions have \ninvolved sudden in.ation of relative errors caused by sub\u00adtractions (or additions of operands with opposite \nsigns). According to the IEEE 754 standard, the result of an sub\u00adtraction/addition needs to be normalized \nby left-shifting, to remove the leading zeros after the operation. The relative er\u00adror inherited from \nthe operands thus get in.ated during this process. Assume a subtraction operation x - y. After the op\u00aderation, \nthe signi.cand bits are left-shifted by d bits, the rel\u00adative error inherited from the operands, (. x \n- . y)/(x - y) may very likely become 2d times larger than the relative er\u00adrors of x and y, because x \n- y is 2d times smaller than x or y, suggested by the left shifting. The d left-shifted bits are also \ncalled the cancelled bits [25]. Note that cancelled bits can be cost-effectively monitored by comparing \nthe exponents of the computation result and the larger operand, particularly, d = max(ex,ey) - ex-y, \nwith ex the exponent of x. An exam\u00adple can be found in Section 5. Therefore, our technique is based on \ndetecting in.ation of relative errors by monitoring cancelled bits of each oper\u00adation. 5. Propagation \nof Relative Errors Detecting relative error in.ation alone is not suf.cient. A simple approach that detects \noccurrences of cancella\u00adtion [25] reports instability for any execution of a few SPEC CFP programs according \nto our study. This is because can\u00adcellation is common even in stable executions. We observe that a lot \nof in.ated errors are not problematic because they are suppressed by other operations in the following \nexecu\u00adtion. For example, in 183.equake, a lot of cancellations originate from an expression c+=a-b inside \na loop when a and b are very close. However, the errors from a-b are always suppressed by the large value \nof c, i.e. the in.ated relative error by a-b becomes trivially small after the ad\u00addition with the large \nc. Hence, a key step in our technique is to monitor propagation of in.ated errors to determine if they \ncan be propagated to a discrete factor and cause discrete differences, without being suppressed. Due \nto the ef.ciency concern, we cannot afford comput\u00ading the true relative errors and monitoring their changes \ndur\u00ading execution. Instead, we develop a cost-effective algorithm to abstract the process. In particular, \nwe tag a value with an in.ation bit when we observe the relative error of the value is in.ated by cancellation. \nWe develop a set of rules to prop\u00adagate the in.ation bits. These rules respect the semantics re\u00adgarding \nrelative errors such that during an operation, a result value inherits the bit from its operand(s) if \nand only if the op\u00aderation does not suppress the error. In this case, the relative error of the result \nis comparable to that of the operand. Program P ::= s St mt s ::= s1; s2 | skip | x := e | x = f2i(y) \n| x = y f 0 | while x do s | if x then s1 else s2 | fail E x pr e ::= x | v | e1 o p e2 | sin(e) BinO \np o p ::= + | - | * | / Val ue v ::= n | r | b Var x . Id ent i f ier n . Z r . Real b . Boolean Figure \n5. Language Language. To facilitate formal discussion, we introduce a kernel language. The syntax is \npresented in Fig. 5. We model three kinds of discrete factors: the type cast from a .oat\u00ading point value \nto an integer f2i, relational operations that are normalized to y 1 0, with 1 denoting a relational oper\u00adator, \nand discrete mathematical library functions. We nor\u00admalize relational operations to study the real values \n(not the boolean values) involved in these expressions. Such val\u00adues are explicitly denoted by y after \nnormalization. For in\u00adstance, a conditional statement if t < 1.0 ... is normalized to y := t - 1.0; x \n= y < 0; if x . It allows us to explicitly reason about the value of y and its error. We model three \nkinds of values, i.e. integer, real, and boolean, and the commonly used binary operators. We model one \nmathematical function sin() to demonstrate how we handle library functions. Operational Semantics. The \nsemantics is presented in e ' Fig. 6. The expression rules have the form of s,G : e -, . e with store \ns and error store G. The error store indicates if a variable is holding a value with an in.ated relative \nerror, that is, the ratio between the actual error and the value is large. The resulting value of an \nevaluation is tagged with the in.ation bit. The evaluation of a variable yields the value from the store, \ntagged with the bit from the error store. The evaluation of a value yields the value itself tagged with \nF, meaning its relative error is small. The result of the addition of two values tagged with T (i.e., \nwith in.ated errors) is also tagged with T . Intuitively, if both operands have signi.cant errors, the \nresulting error of the addition is also signi.cant (Rule [ADD-TT]). According to Rule [ADD-TF], if one \noperand v1 is tagged with T and the other v2 tagged with F, the exponents of the two operands are compared. \nIf the exponent of v1, denoted as ev1 is much smaller than ev2 , particularly when their difference is \nlarger than a pre-de.ned threshold ts, the tag of the result value is set to F. Intuitively, this corresponds \nto when a value with an in.ated error is added to a much larger value with a E ::= E; s | [\u00b7]s | x := \n[\u00b7]e | if [\u00b7]e then s1 else s2 | [\u00b7]e o p e |v o p [\u00b7]e | x := f2i([\u00b7]e) | x := [\u00b7]e 1> 0 | sin([\u00b7]e) \n DE FI N I T I O N : St ore s : Var . Value E rrSt ore G : Var . Boolean ex,sx: the exponent, and the \nsign of x respectively. vb: b indicates if a value v carries an in.ated relative error. e EX P R E \nS S I O N RU L E S s, G : e -' . e e eF s,G : x -s, G : v . v . s(x)G(x) - T Te s,G : v1 + v. [ADD - \nTT] -(v1 + v2)T 2 T Fe s,G : v1 + v-(v1 + v2)b where b = \u00ac(ev2 - ev1 > ts) [ADD - TF] . 2 F Te s,G : \nv1 + v. where b = \u00ac(ev1 - ev2 > ts) [ADD - FT] -(v1 + v2)b 2 F Fe s,G : v1 + v. where b = (max(ev1 ,ev2 \n) - ev1+v2 > tc) -(v1 + v2)b 2 [ADD - FF] eb1 b2 s,G : v * v . where b3 = b1|b2 [MULTI] -(v1 * v2)b3 \n1 2 eb1 s,G : sin(vb) . 1 .where v1 = sin(v), and -v . T |cos(v) \u00b7 v /sin(v)| > 2tc b1 = F |cos(v) \u00b7 \nv /sin(v)| < 2-ts [SIN] . b otherwise s ' STAT E M E N T RU L E S s,G : s -,G' . s' ,s bs s s,G : x \n:= v- s, G : skip;s . s, G, s . s[x . v], G[x . b], skip -s s,G : x := f2i(vT ) - . s, G, fail s s,G \n: x := f2i(vF ) . s, G, fail if (ev - ev-(int )v > tc) - s s, G : x := f2i(vF ) - otherwise . s[x . (int \n)v], G[x . F], skip s s,G : x = vT f 0 . s, G, fail - s s,G : x = vF f 0 - . s[x . v f 0], G[x . F], \nskip s s, G : if bT then s1 else s2 -. s, G, fail s s,G : if T F then s1 else s2 - . s, G, s1 s s,G : \nif FF then s1 else s2 - . s, G, s2 s s,G : while x do s -. s, G, if x then s;while x do s else skip ,G' \n' GL O BA L RU L E S s,G, s . s' , s e s ' ' s, G : e -s,G : s . s', G',s . e- s,G, E[e]e . s,G,E[e']e \ns,G E[s]s . s',G', E[s']s [G-EXPR] [G-STMT] Figure 6. Operational Semantics trivial error, the in.ated \nerror is suppressed. Rule [ADD-FT] is similar. If both operands are tagged with F, we test if the addition \ncauses any cancelled bits. If the number of cancelled bits is larger than a pre-de.ned threshold tc, \nwe consider there is an in.ation of the relative error associated with the result value and tag the result \nwith T . In later sections, we will study the soundness and completeness of the semantic rules and the \neffect of threshold selection. Subtractions are handled in a way similar to additions and thus their \nrules are omitted. For multiplications, the tag of the result is the disjunc\u00adtion of the tags of the \noperands (Rule [MULTI]). Intuitively, multiplying a value v1 with a signi.cant error with another value \nv2 enlarges both the value and its error with the same factor and hence the relative error remains the \nsame. Divi\u00adsions are similarly handled. For the library function sin(), since the function behaves differently \nwith different inputs, i.e. sometimes small input statements Execution 1 Execution 2 op1(x, .x) op2(x, \n.x) result(x, .x) Rule op1(x, .x) op2(x, .x ) result(x, .x) Rule inv J (a): { ... 1 det=a[0]*c[0]; 0.00 \ninf -1.90 3E-17 -0.00 inf MULTI 2.92 0 7.58 4E-17 22.11 6E-17 MULTI 2 t1=a[1]*c[1]; 0.00 inf 0.00 inf \n0.00 inf MULTI 2.92 0 -7.58 4E-17 -22.11 5E-17 MULTI 3 det=det+t1; -0.00 inf 0.00 inf 0.00 inf ADD-TT \n22.11 6E-17 -22.11 5E-17 -1.4E-14 0.013 ADD-FF 4 t2=a[2]*c[2]; 1.46 0 1.90 2E-17 2.76 7E-17 MULTI 2.92 \n0 0.00 inf 0.00 inf MULTI 5 det=det+t2; 0.00 inf 2.76 7E-17 2.76 7E-17 ADD-TF -1.4E-14 0.013 0.00 inf \n-1.4E-14 0.013 ADD-TT 6 ... 7 vol=det/6; 2.76 7E-17 6.00 0 0.46 7E-17 MULTI -1.4E-14 0.013 6.00 0 -2.4E-15 \n0.013 MULTI 8 b1=(vol.0); 0.46 7E-17 0.00 F -2.4E-15 0.013 0.00 F 9 if(b1) report(); F F fail  } Table \n2. Two partial execution traces from 183.equake. Relative errors are detected and propagated according \nto the rules in Fig. 6. Shaded cell indicates that the variable carries an in.ated relative error. In \nExecution 1, relative errors get suppressed at line 5; while in Execution 2 in.ated errors are detected \nat line 3 then .ow to the discrete factor at line 9. errors induce large output changes whereas in other \ncases, large input errors induce trivial output differences, we have to tag the result differently based \non both the operand tag and the operand value. d sin(x) \u00d7 .sin(x) .x cos(x) \u00d7 (.x \u00d7 x) d x == = .sin(x) \nsin(x) sin(x) sin(x) From the above equation, we can observe that the in.ation of the relative error \nis .sin(x)/.x = cos(x) \u00b7 x/sin(x). Accord\u00ading to Rule [SIN], if the in.ation factor is larger than 2tc \n, which corresponds to having more than tc cancelled bits, the tag is set to T . Observe that in some \ncases, the in.ation factor can be smaller than 1 and close to 0, in such a case, it suppresses the operand \nerror instead. Therefore, if the fac\u00adtor is smaller than 2-ts , with ts the threshold for suppres\u00adsion \nin Rules [ADD-TF/FT], the tag is reset to F. For other cases, the operand tag is propagated to the result. \nWe han\u00addle other mathematical library functions in a similar fashion. Note that the input ranges that \ncause the different behav\u00adior can be pre-computed based on the thresholds so that we simply determine \nif the operand value falls in these ranges at runtime, without performing the expensive trigonometric \nfunction evaluations. For an assignment statement, the value is saved in the store and the corresponding \ntag is saved in the error store. If the assignment is a type cast, depending on the tag and the value, \nthe statement is evaluated differently. More speci.\u00adcally, if the .oating point operand is tagged with \nT , meaning that the relative error is signi.cant, discrete differences may be induced. Hence the execution \nis considered unstable. If the operand is tagged with F, but the value is very close to the boundary \nof a discrete value, which can be detected by observing the cancelled bits of (v-(int)v), discrete differences \nmay be induced and the execution is considered unstable. If the right-hand-side (RHS) of an assignment \nis a relational operation v 1 0, the execution is considered unstable if v is tagged with T . The predicate \nin a conditional statement is similarly handled. The global rules are standard. Example. Table 2 shows \nthe propagation of relative errors in part of 183.equake. The code snippet computes the deter\u00adminant \nd et for a given Jacobian matrix in a. Two separate ex\u00adecutions are presented. In Execution 1, some of \nthe values in array a have been tagged with T upon entering the function, denoted as shaded cells. For \nexample, a[0] and a[1] at lines 1 and 2, respectively, hold in.ated relative errors from previ\u00adous computation. \nSince their values are very small, the rela\u00adtive errors .a[i] are very large, in f in both cases (with \ndouble precision). As a result, the computation results at lines 1, 2, and 3 also carry in.ated errors, \nand thus are tagged with T as well according to Rules [MULTI] and [ADD-TT]. The errors get suppressed \nat line 5 because of Rule [ADD-TF], where the operand det tagged with T is added to a large value t2 \ntagged with F. In Execution 2, initially values in array a are all tagged with F. Cancelled bits are \ndetected during the computation at line 3 by Rule [ADD-FF]. The two operands and their relative errors \nare as follows3 . det = 22.1090526719999829..., with . det = 1.3E - 15. t1 = -22.109052671999997..., \nwith . t1 = -1.1E - 15. When performing d et + t1, there are 50 cancelled bits. The result is d et = \n-0.0000000000000142..., with . det = 1.8E - 16 and .det = . det /d et 0.013, which is roughly 250 times \nof the relative errors of the operands. Note that .d et * 250 0.068 and .t1 * 250 0.056. The in.ated \nerror is propagated afterwards, which even\u00adtually .ows into the discrete factor at line 9. The execution \nis hence considered unstable. 6. Soundness and Completeness In Section 3, we de.ne the problem as detecting \nif errors can induce discrete differences at discrete factors. In this section, we discuss the soundness \nand completeness of our method regarding the problem de.nition. Recall that we use in.ation bits to approximate \nsigni.cant relative errors. As a result of the approximation, the proposed technique is nei\u00ad 3 Note that \nour technique does not compute actual errors or relative errors. Here we present error values just for \nthe illustration purpose. ther sound nor complete. Next, we discuss the conditions that affect completeness \nand soundness. Note that we will show in Section 8 that with appropriate threshold settings, the technique \ndoes not miss detecting any unstable execu\u00adtions in practice, and the input subranges in which instability \nis detected are trivial compared to the whole input ranges. The discussion consists of two parts. The \n.rst one dis\u00adcusses the essence of cancelled bits and the second part dis\u00adcusses the propagation rules. \n 6.1 The Essence of Cancelled Bits Cancelled bits have been used as an indicator for instability in existing \nworks [4, 25], in which executions are considered unstable if there is any operation causing a large \nnumber of cancelled bits. However, this causes a lot of false warnings because a lot of in.ated errors \nare suppressed and thus do not cause any problems. Hence in our approach, we only use them to detect \nin.ation of relative errors, and we further track the propagation and suppression of in.ated errors. \nIn the following, we discuss a few issues critical to our method. I1: Cancelled Bits May not Mean Relative \nError In.a\u00adtion. Consider a subtraction x - y. The relative error of the result is |(. x - . y)/(x - \ny)|. The occurrence of d cancelled bits during the subtraction means that x - y is around 2d times smaller \nthan the maximum of x and y. If |. x - . y| has an exponent close to that of . x or . y, the result s \nrelative er\u00adror is around 2d times larger than that of the operand. How\u00adever, observe that if . x - . \ny is close to 2d times smaller than . x and . y, which is similar to having close to d cancelled bits \nif . x - . y were performed with .nite precision, the in.ation does not happen. In practice, the event \nof . x - . y being 2d times smaller is independent of the event of x - y having d cancelled bits, as \n. x and . y are mainly caused by precision limitations. It is hence unlikely these two events happen \nsi\u00admultaneously. However, we do observe this becomes problematic in some rare cases, particularly when \nx and y are semantically equivalent. It means x and y are computed from the same inputs, through the \nsame/equivalent sequences of operations, even though they may be computed separately. In this case, x \n= y and . x = . y. Our technique will detect a large number of cancelled bits caused by x - y. However, \nthere is no relative error in.ation. Fig. 7 shows one example from 187.facerec. It scans a large image \nto locate the part that is the most similar to a small image. The best .t position with the highest similarity \nis recorded in pos. The algorithm has two rounds. In the .rst round (lines 1-6) it iterates through each \nposition at a given stride and identi.es the best .t position. Then it performs the second scan (lines \n9-14) around the best position found in the .rst round, but at a smaller stride. During this process, \nit is likely that variables current and simil arit y have exactly the same value (and the same error) \nin the predicate at line 12, when pos identi.ed in the .rst /* first scan with grid spacing given by \nStep */ pos = (0, 0); similarity = 0.0; 1 for (LLY = StartY; LLY <= EndY; LLY += Step) { 2 for (LLX = \nStartX; LLX <= EndX; LLX += Step) { 3 current = GraphSimFct (LLX, LLY, ...); 4 if (current > similarity) \n{ 5 similarity = current; pos = (LLX, LLY); 6 } } } /* second scan around best position found previously \n*/ 7 StartY = pos(2)-((Step+1)/2); EndY = ...; 8 StartX = pos(1)-((Step+1)/2); EndX = ...; 9 for (LLY \n= StartY; LLY <= EndY; LLY += Scale) { 10 for (LLX = StartX; LLX <= EndX; LLX += Scale) { 11 current \n= GraphSimFct (LLX, LLY, ...); 12 if (current > similarity) { 13 similarity = current; pos = (LLX, LLY); \n14 } } } Figure 7. Pseudocode snippet from 187.facerec. round coincides with LLX and LLY at line 11. \nIn this case, current and simil arit y are semantically equivalent, as they are from the same inputs \nand go through the same sequence of operations. The cancellation does not lead to any relative error \nin.ation. Note that we cannot simply preclude all addition/subtrac\u00adtion operations that yield 0 because \nif x and y are not seman\u00adtically equivalent, x - y = 0 means large in.ation. In fact, this is the common \ncase. I2: Only Addition and Subtraction Can Cause In.ation. According to the operational semantics in \nFig. 6, we only de\u00ad tect cancelled bits in addition and subtraction operations. It is hence important \nto show that other binary operations can\u00adnot cause in.ation. In the following discussion, we assume two \nvariables x and y with the same sign, and .x = .y = t for simplicity. Note that .x = |. x/x|. For multiplication \nx * y, we have the following. x \u00b7 y = (x + . x) \u00b7 (y + . y) = x \u00b7 y + x \u00b7 . y + y \u00b7 . x + . x \u00b7 . y x\u00b7y \n-x\u00b7y x\u00b7. y+y\u00b7. x+. x \u00b7. y .x\u00b7y = | | = | | x\u00b7y x\u00b7y [1] .y .x x\u00b7. y . x . x \u00b7. y . y . x | + |y\u00b7 | | \n+ | | = | | + | | + | \u00b7 | x\u00b7y x\u00b7y x\u00b7y yx y x Observe that normally the sub-expression [1] in the above \nformula is orders of magnitude smaller than the other two sub-expressions and hence can be ignored. Moreover, \nsince .y .x | | = .y = t and | | = .y = t, we have y x .x\u00b7y .x + .y = 2t It shows that the growth \nof the relative error in multipli\u00adcation is normally bounded by a factor of 2. In practice, the growth \nis usually much smaller than 2. Consider division y/x, which can be rewritten as y*(1/x). 1 - 1 |x+. \nx x | x . x t .1/x = = | - 1| = | | |1 | (x + . x) (x + . x) 1 - t x  Note that since t is a very small \nnumber, usually slightly larger than 0, the growth factor of the relative error is a number slightly \nlarger than 1. Consider addition (of two operands with the same sign). |(x + . x + y + . y) - (x + y)| \n|. x + . y| .x+y = = = t |x + y| |x + y| The relative error does not grow. Therefore normally relative \nerrors can only get in.ated by subtractions (or additions of operands with different signs). Note that \neven in subtractions, if the two operands are not very close, in.ation does not happen either. I3: Unstable \nExecutions Always Involve In.ation In Practice. An important question is whether in.ation (i.e. evidenced \nby a large number of cancelled bits) is a neces\u00adsary condition of unstable execution. In theory, it is \nnot true as errors can gradually aggregate through operations and eventually become comparable to the \ncorresponding val\u00adues, leading to discrete differences. Such examples can be constructed. However, in \nthe programs we have studied, we haven t encountered any case in which an unstable execu\u00adtion is caused \nby incremental growth of errors (i.e. without the presence of in.ation)4. The reasons are as follows. \nThe growth of errors is usually very slow without in.ation based on our above discussion in I2. Moreover, \nerror aggregation may enlarge or diminish errors.  6.2 Soundness and Completeness of Propagation Rules \nThe semantic rules in Fig. 6 are unsound due to the approx\u00ad imation. For instance, upon the addition \nof two operands tagged with T , the result value is always tagged with T (Rule [ADD-TT]). If the two \noperands are semantically equivalent except that they have different signs, their errors will be ex\u00adactly \nthe same but with different signs. Consequently, they cancel each other out. However, this cannot be \ndetected by our approximation. Also, according to the rules for type cast and relational operations, \nwe consider an execution unstable if a T tag can reach a discrete factor. However, a signi.cant relative \nerror (as indicated by T ) does not necessarily induce any discrete difference. It also depends on the \nsigns of the actual error and the value. For instance, assume a value v in the actual world is slightly \nlarger than 0.0. A type cast to the integer domain gets 0. If . v has a positive sign, even though it \nis comparable to the value, it does not cause discrete dif\u00adference between the actual world and the ideal \nworld. Un\u00adfortunately, it is infeasible to track signs without computing explicit error values. In practice, \nthe completeness of our technique is largely affected by the conservativeness of the two thresholds tc \nand ts. Recall that tc decides the occurrence of in.ation and ts 4 We used the high precision library \n(HPL) to precisely compute the error for each value encountered during execution. For each discrete difference \nobserved by the HPL method, we could always backtrack to an inducing in.ation (with tc=48).  Figure \n8. An example for missing unstable execution. In the ideal world, a = 0, x = 0.5 and hence y = T , which \nis different from the actual world result in (b). However, our approximation cannot catch the instability \nproblem. Symbol 1.2 means the second sub-step in statement 1. determines if an in.ated error is suppressed \nwhen a smaller operand with T tag is added to a much larger operand. The two thresholds are currently \ncon.gured based on our experience. In Section 8, we study the effect of different threshold con.gurations \nempirically. Our experiment shows that when appropriate thresholds are set, our technique does not miss \nany unstable executions. However, since our technique only uses one bit to approx\u00adimate error related \ninformation for a value, there are cases in which even conservative thresholds fail to catch unstable \nex\u00adecutions. Consider the example in Figure 8. According to Rule [ADD-TF], the propagation is cut off \nat step 1.3 when the smaller value 0 with in.ation is added to the large value 1 without in.ation. As \na result, the execution is considered stable although y has a different boolean value from that in the \nideal world. The root cause is that the single in.ation bit is insuf.cient to model that the actual error \nis much larger than the value 0 at step 1.3. A scheme that tags a value with more bits and has more sophisticated \npropagation rules may mitigate this problem. We will leave it to our future work. In our empirical study, \nwe haven t encountered such cases. 7. Handling Practical Challenges A fundamental assumption of our technique \nis that an ex\u00adecution is unstable if errors can cause discrete differences. The intuition is that discrete \ndifferences leads to different forms of the output mathematical function such that output values have \ndiscontinuous differences. However, due to the .exibility of modern programming languages and the nature \nof certain computation, discrete differences may not always lead to discontinuous output differences. \n7.1 Continuous Cores Continuous core was de.ned in [2] as a program region (usu\u00ad ally a conditional statement \nand its branches) in which con\u00adtrol .ow variations do not cause output discontinuity. In our context, \nwe should not consider an execution unstable if er\u00adrors cause (discrete) control .ow differences inside \ncontinu\u00adous cores. Fig. 9 (a) shows a continuous core code snippet from [2]. It returns the maximum value \nof an array. Note that while [2] focuses on studying the effect of continuous cores on exter\u00adnal input \nuncertainty, we focus on their effect on execution 1 o = A[0] 10 if (x < y) 2 for i := 1 to c 11 o:=x/y \n3 if o < A[i] 12 else 4 o:=A[i]; 13 o:=y/x (a) (b) Figure 9. Continuous core examples. stability in \nthe presence of internal representation errors. In the former case, input errors are usually large enough \nto be representable, sometimes comparable to the input val\u00adues, whereas representation errors are introduced \nbecause they are not representable. In the example, assume an array A[0 - 2] = {1.0, 2.00000000001, 2.0}. \nObserve the com\u00adparison A[1] < A[2] at line 3 (in the second iteration of the loop with o = A[1]) in \nthe actual world. The subtraction A[1] - A[2] causes a large number of cancelled bits. The rel\u00adative \nerror is hence considered in.ated. It is propagated im\u00admediately to the predicate at line 3, which is \na discrete factor. Hence, according to our semantics, the execution is consid\u00adered unstable because a \ndifferent branch outcome may be taken in the ideal world. However, the execution is stable. Because even \nif the predicate has different branch outcomes in the two worlds, A[1] and A[2] are so close to each \nother that selecting either one has little effect on the rest of the execution. Particularly, The relative \nerror of the output value o is essentially |(A [2]- A[1])/A[1]| (assuming A[1] was selected in the actual \nworld), which is a very small value. Therefore, we shall suppress warnings inside the continuous core. \nFig. 9 (b) shows another example we have found in prac\u00ad tice. Assume x = 2.0 and y = 2.00000000000001 \nand their correspondences in the ideal world are x = 2.0000000000001 and y = 2.0. In the actual world, \nthe subtraction in line 10 has a large number of cancelled bits and the result is imme\u00addiately used in \nthe predicate. Hence, the execution is .agged unstable. In fact, the cancelled bits do correctly indicate \nthe control .ow differences between the actual world and the ideal world. However, the control .ow differences \nare not important for the rest of the execution. More particularly, in both worlds, the output o has \na value slightly smaller than 1. We use a pro.ling technique similar to that in [2] to iden\u00ad tify potential \ncontinuous core candidates. We manually in\u00adspect these candidates, which are in a small number (less \nthan 20 in the largest program and only a few on average) and have .xed coding patterns such as selecting \nthe maxi\u00admum/minimum value from a set. We annotate the true cores. During execution, our runtime takes \nthe annotations and sup\u00adpresses warnings inside the annotated regions.  7.2 Predicates in Convergence \nTests In practice, a lot of computation tasks are iterative. An it\u00aderative method is supposed to generate \na sequence of im\u00adproving approximate solutions that eventually converge. Ide\u00adally, an iterative algorithm \nmust be supported by a mathe\u00admatically rigorous convergence analysis; however, heuristic\u00ad 1 x=...; 2 \nrepeat { 3 old=x; 4 x=F(x); /* F() is the iterative function*/ 5 i++; 6 if (i>bound) exit(non-convergent); \n7 } until (|x-old|< t); Figure 10. Iterative algorithm example. based iterative methods are also common. \nIn the latter case, the methods may not converge. The implementation of an it\u00aderative algorithm must \nhave a termination predicate that usu\u00adally compares a value representing the solution generated by the \ncurrent iteration and the value by the previous iteration. If their difference is small enough, the procedure \nis consid\u00adered converged. If the algorithm is not provably convergent, a constant iteration bound is \nusually provided such that an execution is considered not converging if the solution differ\u00adence is still \nlarge when the iteration bound is reached. The code snippet in Fig. 10 abstracts such a template. Since \nthe termination threshold is usually a very small .oating point value, errors may induce different branch \nout\u00adcomes at the convergence test (e.g. line 7 in Fig. 10). If the algorithm is provably convergent, \nwhich can be inferred from the absence of an iteration bound from the program, we suppress any warnings \ngenerated at the convergence predi\u00adcate. Intuitively, assume the procedure terminates at the ith iteration \nin the actual world but at the (i + c)th iteration in the ideal world, with c a positive or negative \ninteger. The solutions in the two worlds do not differ much due to the iterative nature of the computation. \nIf the algorithm is not provably convergent, we have to take special care. We handle the following two \nsub-cases dif\u00adferently. Our discussion is based on the template in Fig. 10. If the (bound - 1)th instance \nof the convergence test is .agged unstable, i.e. the result of |x - old| - t is tagged with T , we consider \nthe execution unstable. Assume the predicate at line 7 takes the true branch in the ideal world (and \nhence the procedure terminates), the signi.cant er\u00adror may induce a different branch outcome in the actual \nworld (and hence the procedure gets to the (bound)th iteration and then fails to terminate at line 6). \nIn other words, the output has discrete difference (i.e. having a convergent solution vs. no solution). \nIt is similar when line 7 takes the else branch in the ideal world.  If the convergence test is detected \nto be unstable at the ith instance with i < bound - 1, we consider the execution stable and suppress \nthe warning. This is because although the signi.cant error may cause different branch outcomes at the \nparticular instance of line 7, the difference only leads to different iterations of computation, which \nonly cause continuous output differences.  While these are the prominent challenges we have en\u00adcountered \nwhen applying the technique to a set of real world programs, there may be others given the expressiveness \nof modern programming languages. 8. Evaluation We implement the predictor by performing source code \nin\u00adstrumentation on subject programs. We modify GCC-4.7.2 to instrument programs on GIMPLE IR. C/C++ \nand Fortran languages are naturally supported through the GCC fron\u00adtend. Instrumented binaries execute \nat their original preci\u00adsion, with the add-on runtime system that monitors relative error in.ation and \npropagation. Upon detecting an instability issue, the tool allows automatically switching to high preci\u00adsion. \nParticularly, programs are restarted with the high preci\u00adsion version which is statically generated by \nprogram trans\u00adformation in the compiler. We perform experiments to evaluate the ef.ciency and the effectiveness \nof our technique. We compare our technique with the state-of-the-art technique that relies on HPL [4], \nin which high precision values are stored in addition to original values, and side-by-side comparisons \nare performed to ensure execution stability. When implementing the HPL technique, we choose 128-bit quad \ndouble types as the HPL, which are slightly faster than using the GNU MPFR library as in [4]. In addition, \nwe also implement another instability pre\u00addictor that dynamically tracks the propagation of actual er\u00adrors \n(not relative error). It records the corresponding error for each .oating point variable, in the same \nprecision as the variable. Note that separating an error from its correspond\u00ading value allows us to precisely \nrepresent the error as their exponents are allowed to be substantially different. For each operation, \nwe compute the result error from the operand er\u00adrors and the representation error of the result value \nitself. Such computation is much cheaper than high precision oper\u00adations. Consider equation (1) in Section \n4. Upon the addition operation, the result error is the aggregation of . x + . y and the representation \nerror of x + y. However, the latter cannot be precisely computed as x + y is performed at normal pre\u00adcision. \nIt is hence over-approximated by the value denoted by the least signi.cand bit of the result value for \nsafety. This approach is therefore more ef.cient but less precise than the HPL technique. We call it \nthe approximate solution. The rea\u00adson we implemented this method and compared it with oth\u00aders is that \nit is the most straightforward optimization of the expensive HPL solution. Our experiments are performed \non an Intel Core-i7 2.80GHz machine with 8GB RAM. 8.1 Performance We evaluate the runtime overhead for \nthe aforementioned three approaches, HPL, approximate and the proposed pre\u00addictor. We use SPEC CFP 2000, \na biochemical data process\u00ading program deisotope from [2], and poly from the moti\u00advating example in Fig. \n2 (c), as the benchmark. We use the test input data set for SPEC programs except 191.fma3d. The execution \ntime for 191.fma3d was too short with the test input, leading to dif.culties in overhead measurement. \n Hence we used the larger training input for this program. The results are shown in Table 3. Column 2 \nshows the native execution time. Columns 3-4 present the results of HPL. Ob\u00adserve that the method is \nexpensive, causing 109 times slow down on average. Such overhead is lower than what was re\u00adported in \n[4]. Columns 5-6 show the results of the approximate ap\u00adproach that monitors errors. The average slowdown \nis 34 times, which is about 3 times faster than the HPL approach. The last two columns present the result \nby the proposed predictor. We collect the data with tc = 48. It incurs a slow\u00addown between 3.18 and 22.80, \nwith an average of 7.91. It is 14 times faster than HPL. One outlier is 172.mgrid, which degrades the \nperformance by over 20 times. Note that 172.mgrid also incurs large overhead in the HPL ap\u00adproach. The \nreason is that it is .oating point computation in\u00adtensive. Any instrumentation to the program introduces \nlarge performance penalty. Excluding this program, the average slowdown for the predictor is 6.84x. This \noffers more prac\u00adtical use than the HPL approach for on-the-.y detection of instability. program native \ntime HPL approximate ours time s/d time s/d time s/d 168.wupwise 1.46 106.69 73.08 41.69 28.55 9.50 \n6.51 171.swim 0.17 11.27 66.29 4.81 28.29 1.02 6.00 172.mgrid 1.96 855.14 436.30 88.38 45.09 44.69 22.80 \n173.applu 0.06 8.32 138.67 2.33 38.83 0.52 8.67 177.mesa 0.36 16.25 31.86 10.44 29.00 1.40 3.89 178.galgel \n0.56 46.73 83.45 18.92 33.79 4.63 8.27 179.art 0.37 15.97 43.16 5.77 15.59 2.97 8.03 183.equake 0.14 \n10.11 72.21 3.74 26.71 0.82 5.86 187.facerec 1.09 109.58 100.53 29.06 26.66 6.18 5.67 188.ammp 1.90 108.77 \n57.25 40.07 21.09 6.05 3.18 189.lucas 0.72 81.05 112.57 23.63 32.82 6.47 8.99 191.fma3d 11.97 1187.68 \n99.22 510.35 42.64 85.08 7.11 200.sixtrack 1.41 249.56 176.99 73.52 52.14 11.05 7.84 301.apsi 1.17 121.58 \n104.09 65.20 55.82 8.35 7.15 deisotope 0.02 0.50 33.00 0.39 19.50 0.13 8.67 AVERAGE 109.46 34.07 7.91 \n time is in seconds; s/d stands for slowdown. Table 3. Performance. Breakdown of Execution Time We further \ninvestigate the distribution of execution time for our predictor to understand the overhead of individual \npieces. The breakdown is mea\u00adsured by computing the differences between enabling and disabling each component \nin the predictor. The results are shown in Fig. 11. Tag propagation, colored in red, domi\u00ad nates the \nexecution time for the majority of the programs. It contributes to 35% to 70% of the whole execution. \nFor each .oating point operation, we have to compute the ad\u00addresses of the operand tags and the result \ntag, load the tags, and perform tag operation. The purple portion in each bar represents the time spent \non detecting error in.ation. The green portions include costs for error suppressions and oth\u00aders. 8.2 \nEffectiveness In this experiment, we compare the effectiveness of the dif\u00adferent approaches. We only \nreport results for the programs that have instability problems. For the other programs, all the three \napproaches correctly detect that they are stable. The experiment is similar to that in Fig. 2. We take \na large num\u00ad ber of samples in a small input sub-domain of each program. For each sample, we run the \nthree techniques to detect if it is stable. In HPL, if any discrete differences are observed at discrete \nfactors between the regular precision version and the high precision version, the execution is considered \nunstable. In the approximate approach, an execution is unstable if the .oating point values at discrete \nfactors could cause discrete differences when they are aggregated with the computed er\u00adrors.  For our \npredictor, we also present the results with differ\u00adent settings of threshold tc, which is the threshold \nfor decid\u00ading in.ation (Rule [ADD-FF]). The other threshold ts that detects suppressions (Rule [ADD-FT/TF]) \nis always set to 4. The results are not sensitive to ts and thus we omit the data regarding the different \nsettings of ts. The results are shown in Table 4. The second column shows the different methods/con.gurations. \nThe overall rows indicate the total samples collected and the sampling domain. These samples are selected \nin a very small range around the original input. The third column shows the num\u00adber of unstable samples. \nThe fourth column shows the per\u00adcentage of unstable samples over the total number of sam\u00adples. The last \ncolumn shows the unstable sample ranges. Some are not continuous, meaning the range may have sta\u00adble \nand unstable sub-ranges. We have the following observations. (1) Even SPEC pro\u00adgrams are unstable. Consider \ngalgel. In many samples, the high precision version produces results but the corre\u00adsponding regular precision \nversion fails to produce any re\u00adsults, or vice-versa. Note that the unstable samples reported by HPL \nare essentially true positives. (2) Our detector re\u00adports 7.5-93 times more problematic cases with the \nsetting of tc = 48, when compared with the ground truth (i.e. the re\u00adsults by HPL). However, the percentage \nof the reported cases over the entire input range is very very small. This implies in most cases (over \n99.999996%5), our technique can cor\u00adrectly predict that an execution is stable, with low overhead. (3) \nOur detector has comparable effectiveness as the approx\u00adimate approach with tc = 48. Note that the proposed \npredic\u00adtor is 5 times faster. (4) The number of false positives of our technique grows when tc decreases \nbecause it admits more in.ations. However, even with the most conservative setting, the percentage of \nthe unstable cases is still very small. Note that the maximum possible tc is 53 because there are 53 \nbits for the signi.cand in the representation of a double preci\u00adsion variable. (5) There are false negatives \nwhen tc gets close to the maximum. When having tc = 52 it misses some unstable cases for 187.facerec \nand poly. It also fails to capture some unstable cases for 178.galgel with tc greater than 48. Our detector \ndoes not miss any true posi\u00adtives with tc = 48. For programs other than 178.galgel, a more aggressive \nthreshold tc = 50 does not cause any false negatives. Observe that 178.galgel has a lot of unstable executions, \nwhich may suggest that one should use a more conservative setting when the number of warnings is high. \nContinuous core and convergence test annotations are im\u00adportant for our technique. For the .rst four \nprograms in Ta\u00adble 4, it always reports unstable for every execution, if there is no annotation of continuous \ncores. Convergence tests are commonly used in 178.galgel. Without the convergence test annotations, we \nreceive a lot of false warnings for this program. In both cases, all the false warnings are issued within \nsome continuous cores or right at some convergence test predicates. We have also evaluated a traditional \ntechnique that is solely based on cancelled bit detection [25]. The technique issues a warning whenever \na larger number of cancelled bits are detected. Our experiment shows that it always reports warnings \nfor all the executions (including the stable ones) of the .rst four programs in Table 4, even after we \nsuppress the warnings in continuous cores and convergence tests. This is because bit cancellation is \nvery common in programs. It may not be harmful unless the imprecise values are further used in critical \nplaces. 8.3 Tracing the Cause of Instability Issues We extend our predictor to trace the root cause \nof instability issues. The extension is straightforward. In addition to the in.ation bit, we also record \nand propagate the location that an error in.ation originates. For a binary operation with both operands \ntagged with T , we propagate the location record of the larger operand. In the future, we plan to develop \na set based implementation to propagate the records from both operands. When an instability issue arises, \nthe cause can be quickly identi.ed from its location record. We discuss one real-world example below. \n5 This lower bound is from galgel with tc = 48. The problematic range is only 3.28E - 6% of the input \nrange such that 99.999996% of the inputs are correctly predicated as stable. program approach # of cases \n% detected range equake HPL 3 3.00E-12% [0.8690799016130847, 0.8690799016130848] approx 158 1.58E-10% \n[0.8690799016130779, 0.8690799016130936] ours(tc=36) 1155972 1.16E-6% [0.8690799014974877, 0.8690799016130848] \nours(tc=40) 72247 7.22E-8% [0.8690799016058602, 0.8690799016130848] ours(tc=44) 4516 4.52E-9% [0.8690799016026333, \n0.8690799016130848] ours(tc=48) 279 2.79E-10% [0.8690799016130570, 0.8690799016130848] ours(tc=50) 71 \n7.10E-11% [0.8690799016130778, 0.8690799016130848] ours(tc=52) 20 2.00E-11% [0.8690799016130829, 0.8690799016130848] \noverall 1E+14 [0.8650, 0.8750] facerec HPL 849 8.49E-10% [0.596265750063108, 0.596265750064926] approx \n4217 4.22E-9% [0.596265750061204, 0.596265750066312] ours(tc=36) 59457611 5.95E-5% [0.596265720335802, \n0.596265779793411] ours(tc=40) 2716295 2.72E-6% [0.596265748204800, 0.596265751922657] ours(tc=44) 232165 \n2.32E-7% [0.596265749946110, 0.596265750181511] ours(tc=48) 12613 1.26E-8% [0.596265750056901, 0.596265750071028] \nours(tc=50) 2643 2.64E-9% [0.596265750062749, 0.596265750066600] ours(tc=52) 296 2.96E-10% [0.596265750063257, \n0.596265750065373] overall 1E+14 [0.5900, 0.6000] galgel HPL 57695 5.77E-8% [0.8184459012000007, 0.8184459012253359] \napprox 4797213 4.80E-6% [0.8184459002708479, 0.8184459022880854] ours(tc=36) 255406459 2.55E-4% [0.8184458871521804, \n0.8184459127084799] ours(tc=40) 126738078 1.27E-4% [0.8184458934897399, 0.8184459061871598] ours(tc=44) \n37972131 3.80E-5% [0.8184458998299998, 0.8184459039575860] ours(tc=48) 3278089 3.28E-6% [0.8184459002196792, \n0.8184459020723309] ours(tc=50) 1801215 1.90E-6% [0.8184459013178548, 0.8184459020723309] ours(tc=52) \n1233455 1.23E-6% [0.8184459019084903, 0.8184459020723309] overall 1E+14 [0.8184, 0.8185] deisotope HPL \n2 2.0E-12% [1.1156381266106556, 1.1156381266106557] approx 18 1.8E-11% [1.1156381266106556, 1.1156381266106573] \nours(tc=36) 167157 1.7E-7% [1.1156381265939401, 1.1156381266106557] ours(tc=40) 10447 1.0E-8% [1.1156381266096111, \n1.1156381266106557] ours(tc=44) 653 6.5E-10% [1.1156381266105905, 1.1156381266106557] ours(tc=48) 40 \n4.0E-11% [1.1156381266106518, 1.1156381266106557] ours(tc=50) 7 7.0E-12% [1.1156381266106551, 1.1156381266106557] \nours(tc=52) 5 5.0E-12% [1.1156381266106553, 1.1156381266106557] overall 1E+14 [1.1100, 1.1200] poly HPL \n2 2.0E-12% [1.8408964152537146, 1.8408964152537147] approx 211 2.1E-10% [1.8408964152537041, 1.8408964152537260] \nours(tc=36) 61177 6.1E-8% [1.8408964152506552, 1.8408964152567738] ours(tc=40) 3821 3.8E-9% [1.8408964152535234, \n1.8408964152539065] ours(tc=44) 235 2.4E-10% [1.8408964152537028, 1.8408964152537269] ours(tc=48) 15 \n1.5E-11% [1.8408964152537132, 1.8408964152537162] ours(tc=50) 2 2.0E-12% [1.8408964152537146, 1.8408964152537147] \nours(tc=52) 0 0.0% overall 1E+14 [1.8400, 1.8500] Table 4. Comparisons of the detected problematic ranges \nwith different predictors. following a detected range indicates that there are false negatives for the \ncurrent setting of tc. void nwtn() { void syshtn(Y, ...) { while (...) { double *H; 110 call Fname(Y, \n...); ... ... 62 H(i) = ...; /* d=DOT PRODUCT(Y,Y); */ 63 for (...) 122 for (...) { Y(i) = Y(i) -H(i); \n123 d += Y(i) * Y(i); } ... 124 if (d <eps2) { break; } } } } Figure 12. Pseudocode snippet from 178.galgel. \nFig. 12 shows a pseudocode snippet from 178.galgel. In one of the executions, the program produces a \ndifferent output from the one by HPL. The observed difference lies in the predicate outcome at line 124 \nin function nwtn(). The HPL version takes the true branch to jump out of the loop and continues, whereas \nthe regular version takes the false branch. Our predictor successfully reports an unstable run due to \nthe predicate at line 124. It shows variable d carries an in.ated error when comparing against e ps2. \nIn addition, it further indicates that the cause of the in.ation is due to the cancellation at line 63 \nin function syshtn() which was called earlier from line 110. We verify the cause of the issue by investigating \nthe com\u00adputations at line 63, where the elements of array Y get up\u00addated. Before performing the subtraction \nof Y (i)-H(i), nei\u00adther of them is tagged with T . Taking Y (7) and H(7) for ex\u00adample, Y (7)=-15.84869578667144, \nH(7)=-15.8486957866 7145 and the relative errors are both around 2.65E-9. Y (7) is tagged with T after \nthe subtraction, since 50 bits get can\u00adcelled. As a result, it has a value of Y (7)=2.88E-11, but the \nrelative error of Y (7) grows up to 0.003. Most other ele\u00adments in Y are also tagged with T similarly. \nFrom this point on, Y carries the in.ated errors in its following execution. When getting back to the \ncomputation of d at line 123, the in.ated errors eventually propagate from Y (i) to d. During this process, \nnone of the product Y (i) *Y (i) is large enough and tagged with F to suppress the in.ated errors. Upon \n.n\u00adishing the loop, .d =0.015, which is correctly captured by the T tag. Hence it triggers a warning \nat the predicate. With the help of the predictor, the cause of the instability is easily located. However, \nthe implementation around the cause is so complex that a more stable version may be dif.cult to con\u00adstruct, \nwhich supports our argument that online prediction plus on-demand precision hoisting is a more suitable \nsolu\u00adtion. 9. Limitations We propose to address the .oating point instability problem in a way different \nfrom traditional techniques. We use run\u00adtime prediction to determine if an execution is stable. For the \nvery few unstable executions, we allow the user to switch to running high precision versions on demand. \nHowever, as an initial step along this direction, our technique has a number of limitations. First of \nall, its requires setting two thresholds. While we were able to .nd a uniform con.guration for the programs \nwe have considered, it is unknown if the con.g\u00aduration is equally effective for other programs. Second, \nit requires the user to annotate continuous cores and conver\u00adgence test predicates. We argue that such \nannotations should become an integral part of the programming language sup\u00adport for applications that \nhave high demand for reliability. As such, it will allow programmers to annotate their own code during \ndevelopment. Advanced static analysis may also be developed to determine continuous cores and convergence \ntest predicates. Third, the current implementation has non\u00adtrivial overhead even though it is much faster \nthan the HPL solution and the approximate solution (Section 8). We no\u00ad tice that similar dynamic analyses \nthat propagate bits, such as dynamic information .ow tracking, may be much more ef.cient than our technique \n(e.g. only 6.2% overhead for server applications and 3.6 times overhead for SPEC pro\u00adgrams were reported \nin [34]). However, when we try to ap\u00ad ply similar optimizations, we encounter a number of unique challenges \nfor .oating point programs. For example, the in\u00adstruction pipeline behaves differently for integer and \n.oating point programs in the presence of instrumentation. We are working on addressing these problems. \n 10. Related Work The instability problem has been studied for a long time. The most prominent difference \nbetween our work and many ex\u00adisting works is that existing techniques treat it as a debugging problem. \nThey try to locate the unstable statements using various analysis, report them to the users, and hope \nthey will get .xed. However, our study shows that instability will not happen for most parts of the input \ndomain and they can be suppressed by higher precision. Hence, we aim to develop an ef.cient on-the-.y \npredictor to assure stability for most executions, and only switch to using high precision compu\u00adtation \nwhen necessary. Also, a key advance of our work is to leverage the concept of discrete factors to have \na more pre\u00adcise error reporting criterion that is critical for a low false positive rate. Interval arithmetic \n[29, 31] uses an error range to repre\u00ad sent a value. It updates ranges in a conservative way, leading \nto over-sized ranges. Hence, people further propose af.ne arithmetic [11, 13, 15] to represent errors \nas af.ne forms to allow better precision. However, they are very expensive and their goal is in-house \ntesting and debugging. The state of the art [10] has 3-5 orders of magnitude slow down and only supports \nsmall programs. Researchers have proposed using high precision library to precisely compute values and \nerrors during execution [1, 4]. In particular, the state-of-the-art [4] is a dynamic analysis that makes \nuse of a binary instrumenta\u00adtion engine to enhance a .oating point program on the .y to perform high \nprecision computation. That is, upon executing a single precision operation, the instrumentation executes \nthe corresponding high precision operation. The results of the two precision levels are compared to detect \npossible in\u00adstability issues. However, high precision operations are very expensive (e.g. [4] has 2 orders \nof magnitude slow down). In contrast, our predictor has only 7.91 times slowdown. And our precision loss \nis small in the picture of the whole input domain. Monte Carlo Arithmetic (MCA) exploits random\u00adness \nin .oating point arithmetic [33]. It executes a program multiple times by randomizing .oating point arithmetic \nop\u00aderators and operands. It studies roundoff errors statistically from the results. The CADNA library \n[22] performs stochas\u00ad tic estimations of errors also by randomly selecting rounding modes at each operation. \nWith randomization approach, it can miss instability problems in certain situations [23]. It is also \nexpensive (90x slowdown for SPEC with CADNA li\u00adbrary according to our experiment). In [25], a dynamic \ntech\u00ad nique detects instability by monitoring bit cancellations was proposed. It is very expensive and \nhas a large volume of false positives. There are also a large body of work on abstract interpre\u00adtation, \nSMT solving, model checking, and code perturbation to tackle the representation error problem [5, 9, \n12, 14, 16, 21, 27, 28, 30, 36]. Particularly, robustness analysis [7] tries to statically prove that \na .oating point program is free from instability problems. While it is quite successful in handling simple \nprograms, the mathematical complexity and the it\u00aderative nature of many real world .oating point programs \nare dif.cult to address by the technique. Moreover, as in\u00adstability problems are input dependent and \nrarely happen, dynamic analysis like ours have the advantage of allow run\u00adning the low precision program \nin most cases for ef.ciency and switching to high precision on demand. It is especially prefereable when \ncompletely .xing instability problems is dif.cult. There are some existing works focusing on external \ner\u00adrors. The error bounds for external errors are much larger compared to internal representation errors. \nProgram behav\u00adior may vary a lot within external input error bounds. Monte Carlo (MC) approaches are \nwidely used [19] in handling ex\u00ad ternal errors. White-box sampling [2] was recently proposed to reduce \nthe number of needed samples. It hashes discrete values at discrete factors and uses the resulting hash \nvalues to guide the sampling process. However, sampling cannot be applied in our context as representation \nerror bounds are too small to be representable without using higher precision. Static analysis has also \nbeen proposed to prove a program is continuous [6, 17, 26] or robust [7, 35] in the presence of input \nerrors. There are static analysis, symbolic execution, theorem proving, and model checking techniques \nthat focus on de\u00adtecting or proving the absence of logical .oating point bugs (e.g. divided-by-zero, \nover.ow, and under.ow) [3, 8, 18, 24]. Particularly, [3] features solving .oating point con\u00ad straints. \nThey are usually heavy-weight analysis and they focus on bug .nding in programs. These bugs are different \nfrom instability problems by nature. 11. Conclusion We develop an online technique to monitor and predict \n.oat\u00ading point program execution instability problems. We ob\u00adserve that in practice, only a very small \nportion of inputs can lead to unstable execution and hence the expensive high precision computation based \napproaches do not pay-off for most inputs. We formally de.ne an unstable execution as ex\u00adecution in which \nerrors cause discrete differences. The def\u00adinition allows us avoid explicitly computing errors, which \nis very expensive. Instead, we abstract in.ation of relative errors as one bit, monitor the propagation \nof such bits, and check if they can reach discrete factors. If so, the in.ated errors may induce discrete \ndifferences at these factors and hence the execution is .agged unstable. The key challenge is to detect \nplaces where the in.ation bit propagation is cut off, indicating the error is no longer in.ated compared \nto its value. We discuss the soundness and completeness of the technique and the practical challenges \nthat we have over\u00adcome. Our experiments show that the technique can cor\u00adrectly classify over 99.999996% \ninputs as stable with a spe\u00adci.c threshold setting (tc=48) while a traditional technique that solely \ndetects error in.ation mis-classi.es majority of inputs as unstable for some of the programs we studied. \nCompared to the state of the art high precision computa\u00adtion based approach, our technique is much more \nef.cient (with an average overhead reduction of 14 times) and can report all the unstable executions. \nDue to approximation, our technique classi.es 7.5-93 times more inputs as unsta\u00adble (tc=48), when compared \nto the ground truth. However, these inputs only count for 1.5E-11% -3.3E-6% of the in\u00adput domain. In \nother words, in majority cases, our technique has the same effect as the high precision approach. There\u00adfore, \nusers can use our technique to make prediction with a lower cost. For the very rare cases that are considered \nunsta\u00adble by our predictor, our technique provides the capability of automatically switching to high \nprecision. Acknowledgments This research is supported, in part, by the National Sci\u00adence Foundation (NSF) \nunder grants 0845870, 0916874 and 1320444. Any opinions, .ndings, and conclusions or recom\u00admendations \nin this paper are those of the authors and do not necessarily re.ect the views of NSF. References [1] \nDavid An, Ryan Blue, Michael Lam, Scott Piper, and Geoff Stoker. FPInst: Floating Point Error Analysis \nUsing Dyninst. 2008. [2] Tao Bao, Yunhui Zheng, and Xiangyu Zhang. White Box Sampling in Uncertain Data \nProcessing Enabled by Program Analysis. In OOPSLA 12. [3] Earl T. Barr, Thanh Vo, Vu Le, and Zhendong \nSu. Automatic Detection of Floating-Point Exceptions. In POPL 13.  [4] Florian Benz, Andreas Hildebrandt, \nand Sebastian Hack. A Dynamic Program Analysis to Find Floating-Point Accuracy Problems. In PLDI 12. \n[5] Sylvie Boldo and Jean-Christophe Filli atre. Formal Veri.ca\u00adtion of Floating-Point Programs. In ARITH \n07. [6] Swarat Chaudhuri, Sumit Gulwani, and Roberto Lublinerman. Continuity Analysis of Programs. In \nPOPL 10. [7] Swarat Chaudhuri, Sumit Gulwani, Roberto Lublinerman, and Sara Navidpour. Proving Programs \nRobust. In ESEC/FSE 11. [8] Patrick Cousot. Proving the Absence of Run-time Errors in Safety-Critical \nAvionics Code. In EMSOFT 07. [9] Patrick Cousot, Radhia Cousot, ome Feret, Laurent Jer Mauborgne, Antoine \nMin\u00b4 e, David Monniaux, and Xavier Ri\u00adval. The ASTR \u00b4In Programming Languages EE Analyzer. and Systems, \nProceedings of the 14th European Symposium on Programming, volume 3444 of Lecture Notes in Computer Science, \npages 21 30. Springer, 2005. [10] Eva Darulova and Viktor Kuncak. Trustworthy Numerical Computation in \nScala. In OOPSLA 11. [11] L. H. de Figueiredo and J. Stol.. Af.ne Arithmetic: Concepts and Applications. \nNumerical Algorithms, 37:147 158, 2004. [12] David Delmas, Eric Goubault, Sylvie Putot, Jean Souyris, \nKarim Tekkal, and Franck V\u00b4 edrine. Towards an Industrial Use of Fluctuat on Safety-Critical Avionics \nSoftware. In FMICS 09. [13] Claire F. Fang, Tsuhan Chen, and Rob A. Rutenbar. Floating-Point Error Analysis \nBased on Af.ne Arithmetic. In Proc. IEEE Int. Conf. on Acoust., Speech, and Signal Processing, pages \n561 564, 2003. [14] Eric Goubault. Static Analyses of the Precision of Floating-Point Operations. In \nSAS 01. [15] Eric Goubault and Sylvie Putot. Under-Approximations of Computations in Real Numbers Based \non Generalized Af.ne Arithmetic. In SAS 07. [16] Eric Goubault and Sylvie Putot. Static Analysis of Finite \nPrecision Computations. In VMCAI 11. [17] Dick Hamlet. Continuity in Software Systems. In ISSTA 02. [18] \nJohn R. Hauser. Handling Floating-Point Exceptions in Numeric Programs. ACM Trans. Program. Lang. Syst., \n18(2):139 174, March 1996. [19] J.C. Helton, J.D. Johnson, C.J. Sallaberry, and C.B. Storlie. Survey \nof Sampling-based Methods for Uncertainty and Sen\u00adsitivity Analysis. Reliability Engineering &#38; System \nSafety, 91(1011):1175 1209, 2006. [20] IEEE Task P754. IEEE 754-2008, Standard for Floating-Point Arithmetic. \nAugust 2008. [21] Bertrand Jeannet and Antoine Min e.\u00b4Apron: A Library of Numerical Abstract Domains \nfor Static Analysis. In CAV 09. [22] Fabienne Jzquel and Jean-Marie Chesneaux. CADNA: A Li\u00adbrary for \nEstimating Round-off Error Propagation. Computer Physics Communications, 178(12):933 955, 2008. [23] \nWilliam Kahan. How futile are mindless assessments of roundoff in .oating-point computation? 2006. [24] \nDaniel K \u00a8astner, Stephan Wilhelm, Stefana Nenova, Patrick Cousot, Radhia Cousot, J\u00b4er ome Feret, Antoine \nMin\u00b4e, Laurent Mauborgne, and Xavier Rival. Astr\u00b4ee: Proving the Absence of Runtime Errors. In ERTSS \n10, 2010. [25] Michael O. Lam, Jeffrey K. Hollingsworth, and G.W. Stew\u00adart. Dynamic Floating-Point Cancellation \nDetection. Parallel Computing, 39(3):146 155, 2013. [26] Rupak Majumdar and Indranil Saha. Symbolic \nRobustness Analysis. In RTSS 09. [27] Matthieu Martel. Propagation of Roundoff Errors in Finite Precision \nComputations: A Semantics Approach. In ESOP 02. [28] Matthieu Martel. An Overview of Semantics for the \nValida\u00adtion of Numerical Programs. In VMCAI 05. [29] Guillaume Melquiond and Cesar Munoz. Guaranteed \nProofs Using Interval Arithmetic. In ARITH 05. [30] David Monniaux. The Pitfalls of Verifying Floating-Point \nComputations. ACM Trans. Program. Lang. Syst., 30(3):12:1 12:41, May 2008. [31] R.E. Moore. Interval \nAnalysis. Prentice-Hall series in auto\u00admatic computation. Prentice-Hall, 1966. [32] U.S. General Accounting \nOf.ce. Patriot Missile Defense: Software Problem Led to System Failure at Dhahran, Saudi Arabia. GAO/IMTEC-92-26, \nFeb 1992. [33] D. S. Parker. Monte Carlo Arithmetic: Exploiting Random\u00adness in Floating-Point Arithmetic. \nTechnical Report CSD\u00ad970002, University of California, Los Angeles, 1997. [34] Feng Qin, Cheng Wang, \nZhenmin Li, Ho-seop Kim, Yuanyuan Zhou, and Youfeng Wu. LIFT: A Low-Overhead Practical Information Flow \nTracking System for Detecting Security Attacks. In MICRO 39. [35] Sriram Sankaranarayanan, Aleksandar \nChakarov, and Sumit Gulwani. Static Analysis for Probabilistic Programs: Inferring Whole Program Properties \nfrom Finitely Many Paths. In PLDI 13. [36] Enyi Tang, Earl Barr, Xuandong Li, and Zhendong Su. Per\u00adturbing \nNumerical Calculations for Statistical Analysis of Floating-Point Program (in)Stability. In ISSTA 10. \n[37] B. A. Worley. Deterministic Uncertainty Analysis. Technical Report ORNL-6428, Oak Ridge National \nLab. TN (USA), 1987.   \n\t\t\t", "proc_id": "2509136", "abstract": "<p>The machine representation of floating point values has limited precision such that errors may be introduced during execution. These errors may get propagated and magnified by the following operations, leading to instability problems, e.g., control flow path may be undesirably altered and faulty output may be emitted. In this paper, we develop an on-the-fly efficient monitoring technique that can predict if an execution is stable. The technique does not explicitly compute errors as doing so incurs high overhead. Instead, it detects possible places where an error becomes substantially inflated regarding the corresponding value, and then tags the value with one bit to denote that it has an inflated error. It then tracks inflation bit propagation, taking care of operations that may cut off such propagation. It reports instability if any inflation bit reaches a critical execution point, such as a predicate, where the inflated error may induce substantial execution difference, such as different execution paths. Our experiment shows that with appropriate thresholds, the technique can correctly detect that over 99.999996% of the inputs of all the programs we studied are stable while a traditional technique relying solely on inflation detection mistakenly classifies majority of the inputs as unstable for some of the programs. Compared to the state of the art technique that is based on high precision computation and causes several hundred times slowdown, our technique only causes 7.91 times slowdown on average and can report all the true unstable executions with the appropriate thresholds.</p>", "authors": [{"name": "Tao Bao", "author_profile_id": "81331488648", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P4290469", "email_address": "tbao@cs.purdue.edu", "orcid_id": ""}, {"name": "Xiangyu Zhang", "author_profile_id": "81384614270", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P4290470", "email_address": "xyzhang@cs.purdue.edu", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509526", "year": "2013", "article_id": "2509526", "conference": "OOPSLA", "title": "On-the-fly detection of instability problems in floating-point program execution", "url": "http://dl.acm.org/citation.cfm?id=2509526"}