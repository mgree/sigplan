{"article_publication_date": "10-29-2013", "fulltext": "\n Inductive Invariant Generation via Abductive Inference Isil Dillig Thomas Dillig Boyang Li Microsoft \nResearch Cambridge Department of Computer Science Department of Computer Science isdillig@microsoft.com \nUniversity College London College of William &#38; Mary t.dillig@ucl.ac.uk bli01@email.wm.edu Ken McMillan \nMicrosoft Research kenmcmil@microsoft.com Categories and Subject Descriptors F.3.1 [Logics and Meaning \nof Programs]: Specifying and Verifying and Rea\u00adsoning about Programs General Terms Languages, Veri.cation, \nAlgorithms, Ex\u00adperimentation Keywords Invariant Generation, abductive inference, static analysis Abstract \nThis paper presents a new method for generating inductive loop invariants that are expressible as boolean \ncombinations of linear integer constraints. The key idea underlying our technique is to perform a backtracking \nsearch that combines Hoare-style veri.cation condition generation with a logical abduction procedure \nbased on quanti.er elimination to spec\u00adulate candidate invariants. Starting with true, our method it\u00aderatively \nstrengthens loop invariants until they are inductive and strong enough to verify the program. A key feature \nof our technique is that it is lazy: It only infers those invariants that are necessary for verifying \nprogram correctness. Fur\u00adthermore, our technique can infer arbitrary boolean combi\u00adnations (including \ndisjunctions) of linear invariants. We have implemented the proposed approach in a tool called HO L A. \nOur experiments demonstrate that HO L A can infer interest- Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. Copyrights for components of this work owned by others than ACM must \nbe honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. Request permissions from \npermissions@acm.org. OOPSLA 13, October 29 31, 2013, Indianapolis, Indiana, USA. Copyright &#38;#169; \n2013 ACM 978-1-4503-2374-1/13/10. . . $15.00. chttp://dx.doi.org/10.1145/2509136.2509511 ing invariants \nthat are beyond the reach of existing state-of\u00adthe-art invariant generation tools. 1. Introduction The \nautomated inference of numeric loop invariants is a fundamental program analysis problem with important \napplications in software veri.cation, compiler optimiza\u00adtions, and program understanding. Prominent approaches \nfor automatic generation of loop invariants include abstract\u00adinterpretation [1 4], constraint-based techniques \n[5, 6], counterexample guided abstraction re.nement (CEGAR) [7, 8], and interpolation-based approaches \n[9 11]. In this paper, we present a new method for automatically generating inductive loop invariants \nwhich are expressible as boolean combinations of linear integer constraints over program variables. A \nloop invariant is said to be inductive if it is implied by the loop s precondition and is preserved in \neach iteration of the loop s body. Since the correctness of inductive loop invariants can be checked \nlocally given the loop precondition, inductive invariants play a key role in many program veri.cation \nsystems [12 14]. Our approach to loop invariant generation is intended mainly for program veri.cation. \nTherefore, similar to meth\u00adods like CEGAR, our goal is to lazily infer only those in\u00advariants that are \nnecessary for showing program correctness. Furthermore, we focus on numeric loop invariants in this pa\u00adper \nbecause such invariants play a crucial rule in many basic veri.cation tasks such as proving the absence \nof array-out\u00adof-bounds exceptions or buffer over.ows. A salient feature of our technique is that it can \nnaturally infer invariants that are arbitrary boolean combinations of linear integer constraints. Here, \nby linear integer constraints, we mean linear inequalities over integers as well as divisi\u00adbility predicates. \nFurthermore, the invariants inferred by our method can involve disjunctions and implications. For in\u00adstance, \nour technique is capable of inferring complex invari\u00adants that are expressible using the following formula: \n (x%2 = 0 . x + 2y < n) . (x%2 = 1 . x + 2y = n) Another advantage of our method is that it does not \nre\u00adquire users to specify a pre-de.ned syntactic template over which to express the invariants. For example, \nsome loop in\u00advariant inference techniques such as [5, 6] require the user to annotate a template describing \nthe shape of the invariants to be inferred such ax+by = c and then solve for the unknown parameters a, \nb, c. In contrast, our technique automatically infers the shape of the required invariants without requiring \nhints or annotation from the user. 1.1 Overview of the Approach The key idea underlying our approach \nto loop invariant inference is to perform a backtracking search that com\u00adbines Hoare-style program reasoning \nwith logical abduction, which is the inference of missing hypotheses for a given conclusion. Starting \nwith the weakest possible but always correct loop invariant true, our technique sets up veri.ca\u00adtion \nconditions whose validity guarantees the correctness of the program. If a veri.cation condition (VC) \nis invalid, our technique employs abductive inference to .x this in\u00advalid VC, which corresponds to the \nspeculation of a new loop invariant. The current speculation is used to strengthen the existing invariants, \nand new VCs are set up to check the correctness of the speculation. This process continues until either \nall the VCs become valid or we derive a contradiction. The former outcome means that we have found inductive \nloop invariants strong enough to show the correctness of the program and our algorithm terminates. The \nlatter outcome means that we have made a wrong speculation; therefore, we backtrack and try a different \ninference. In our approach, the generated veri.cation conditions are conjunctions of clauses of the form \n. . ., asserting the inductiveness of loop invariants and correctness of assertions in the program. Speci.cally, \nthe right hand side . of the implication is a goal we want to show, such as a loop post\u00adcondition. On \nthe other hand, the left-hand-side . encodes known facts about the program, such as already inferred \nloop invariants. Now, given an invalid clause . . . of the VC, our technique tries to .x this broken \nclause by strengthening the left-hand side of the implication. In particular, we want to infer a strengthening \n. of the current loop invariant . such that: 1. |= (. . .) . . 2. SAT(. . .)  Here, condition (1) states \nthat the strengthening . is suf.\u00adcient to make a particular clause of the VC valid. Condition (2) states \nthat the strengthening . must be consistent with the left-hand side ., since . encodes known (or speculated) \ninvariants about the program. The inference of a formula . satisfying these two requirements is an instance \nof logi\u00adcal abduction, as de.ned by Peirce [15]. Therefore, a main insight underlying our approach is \nthat logical abduction is useful for .nding suitable strengthenings of loop invariants that are suf.cient \nfor making the program s veri.cation con\u00addition valid. Now, while our inferred strengthening . .xes \nan invalid clause of the VC, it is nonetheless a speculation and may or may not correspond to a correct \nloop invariant. There\u00adfore, to ensure the soundness of our approach, our technique generates new VCs \nat every step encoding the correctness of all invariants, including .. Therefore, if . is an incorrect \nspeculation, the new VC will contain an invalid clause that needs to be .xed. If the algorithm reaches \na point where a given VC clause can no longer be .xed through abductive strengthening (for instance, \nwhen . . . is unsatis.able), this means we have made a wrong speculation and we must backtrack. On the \nother hand, if all VC clauses become valid, this means all of our speculations are correct. Thus, when \nthe algorithm terminates, we have identi.ed correct inductive loop invariants that are strong enough \nto show the correct\u00adness of the program. However, our technique does not have termination or completeness \nguarantees; it is indeed possible for the algorithm to diverge in an in.nite chain of specula\u00adtions. \nIn principle, this combination of Hoare-style VC gener\u00adation and logical abduction can be used to infer \nany class of invariants. However, since our algorithm for performing abduction is based on quanti.er \nelimination, this paper fo\u00adcuses only on the inference of loop invariants expressible in Presburger arithmetic. \n 1.2 Organization and Contributions The rest of this paper is organized as follows: Section 2 walks the \nreader through a small example illustrating how our technique infers loops invariants. Section 3 presents \na small imperative language that we use for the formal devel\u00adopment, and Section 4 presents the main \ninvariant inference algorithm. Section 5 discusses extensions to the basic algo\u00adrithm and describes our \nimplementation. Section 6 presents an experimental evaluation of our approach, comparing our tool H O \nL A with three other loop invariant generation tools. Finally, Sections 7 and 8 discuss related work \nand highlight future research directions. To summarize, this paper makes the following key contri\u00adbutions: \n We present a novel algorithm based on backtracking search for automatically inferring inductive loop \ninvari\u00adants that are expressible as boolean combinations of lin\u00adear integer constraints.  We show how \nHoare-style program reasoning and a log\u00adical abduction procedure based on quanti.er elimination can be \ncombined for linear invariant generation. To the best of our knowledge, this is the .rst application \nof log\u00ad   void foo(int .ag) { 1. int i, j, a, b; 2. a = 0; b = 0; j = 1; 3. if(.ag) i=0; else i=1; \n 4. while(*) [f] { 5. a++; b+=(j-i); i+=2; 6. if(i%2 == 0) j+=2; else j++; 7. } 8. if(.ag) assert(a==b); \n } Figure 1. Code example to illustrate our approach ical abduction for automatic generation of numeric \nloop invariants. We have implemented the proposed technique in a tool called HO L A and present a comparison \nbetween HO L A and other available state-of-the-art invariant generation tools, namely BLAST, InvGen, \nand Interproc. Our exper\u00adiments on a set of loop invariant generation benchmarks show that our approach \nis promising for advancing the state-of-the-art in numeric loop invariant generation. 2. Example Illustrating \nour Technique We illustrate the main ideas of our technique using the code example shown in Figure 1. \nHere, the annotation [f] next to the while loop at line 4 means that f is a placeholder variable representing \nan unknown invariant of this loop. Our goal in this section is to infer a concrete formula . for the \nplaceholder f such that . is both inductive as well as strong enough to prove the assertion at line 8. \nOur technique starts by instantiating the placeholder vari\u00adable f with the weakest possible but always \ncorrect loop in\u00advariant, namely true. Using Hoare-style reasoning, we then generate veri.cation conditions \nfor the program, which, in this case, yields: true . (.ag . a = b) This VC stipulates that the current \nloop invariant true is strong enough to imply the loop post-condition, which is .ag . a = b. Clearly, \nthis VC is not valid, therefore, we attempt to .x this broken VC by .nding an abductive strengthening \nf of the left-hand side such that: (true . f) . (.ag . a = b) There are many solutions to this abduction \nproblem, includ\u00ading the solutions \u00ac.ag, a = b, and .ag . a = b computed by our abduction algorithm. To \nkeep our discussion concise, let us start with the solution f = (.ag . a = b), which means (.ag . a = \nb) is our speculated loop invariant. We now proceed by generating new VCs that assert the correctness \nof our candidate invariant. This results in the generation of the following new VC: (.ag . a = b) . \n(.ag . (a + 1 = b + j - i)) This VC simply stipulates that our candidate invariant is in\u00adductive, as \nthe right-hand side of the implication is the weak\u00adest precondition of the candidate invariant. Unfortunately, \nhowever, the VC is again not valid; thus, we proceed to set up another abduction problem to .nd a suitable \nstrengthen\u00ading f of the loop invariant: (.ag . a = b . f) . (.ag . (a + 1 = b + j - i)) (*) Our algorithm \nfor performing abduction again computes several solutions, including \u00ac.ag, j = i + 1, and .ag . j = i \n+ 1. Now, suppose we initially pick a wrong solution, say j = i + 1. This means our new candidate loop \ninvariant is now j = i+1.(.ag . a = b). Since j = i+1 does not hold initially (i.e., the weakest precondition \nof j = i+ 1 .(.ag . a = b) with respect to lines 1-3 is invalid), we therefore reject this candidate \nand backtrack to our speculation from the previous level, namely .ag . a = b. Now, having backtracked \nto the previous decision level, we try another solution to our abduction problem from (*). Suppose that \nwe now choose the solution: f = (.ag . j = i + 1) Combining this strengthening with the existing invariant \n.ag . a = b, we now obtain the following candidate loop invariant: I = (.ag . (a = b . j = i + 1)) It \nturns out that this new speculation I is now correct, but, unfortunately, I is still not inductive because \nthe following VC clause asserting the inductiveness of I is not valid: (.ag . (a = b . j = i + 1)) . \n(.ag . (a + 1 = b + j - i . (i%2 = 0 . j = i + 1). (i%2 = 0 . i = j))) Here, note that the right-hand \nside of the outer-level im\u00adplication corresponds to the weakest precondition of I. To make this VC valid, \nwe now solve a .nal abduction problem to .nd yet another strengthening of I. In this case, one of the \nsolutions we obtain is .ag . i%2 = 0. Thus, we obtain a new candidate loop invariant I' by conjoining \nthis solution with I: I' = (.ag . (a = b . j = i + 1 . i%2 = 0)) At this point, the new VC becomes valid. \nIn other words, we have shown that I' is a correct inductive invariant strong enough to prove the assertion \nat line (8). 3. Language In this section, we give a simple imperative language that we use for formalizing \nour technique: Program p := s Statement s := skip | v := e | s1; s2 | choose s1 s2 | while C [f] do {s} \n| assert p | assume p Expression e := v | int | e1 + e2 | e * int | e%int Conditional C := e1 8 e2 (8 \n. {<, >, =}) | C1 . C2 | C1 . C2 | \u00acC In this language, programs consist of one or more state\u00adments. \nStatements include skip, assignments, sequencing, choose statements (which non-deterministically execute \ns1 or s2), while loops, assertions, and assumptions. Expressions include variables v, integer constants \nint, addition (e1 + e2), linear multiplication (e*int), and mod expressions e%int. Fi\u00adnally, conditionals \ncan be comparisons between expressions as well as logical conjunction, disjunction, and negation. Loops \nin this language are decorated with unique place\u00adholder formulas f which represent unknown loop invariants \nbut have no effect on the program semantics. For each place\u00adholder f, the goal of our technique is to \ninfer a concrete log\u00adical formula . such that . is both inductive as well as strong enough to imply the \nloop postcondition. In the remainder of the paper, we use the notation invs(p) to refer to all place\u00adholders \nf used in p. 4. Algorithm for Generating Inductive Loop Invariants Our algorithm I N VGE N for generating \ninductive loop invari\u00adants is shown in Figure 2. It takes as input a program p that we want to verify \nand outputs a mapping . from each place\u00adholder invariant f in p to an inductive loop invariant .. If \nwe cannot verify the program, then the algorithm returns the empty mapping \u00d8. As mentioned in Section \n1, our algorithm starts by initial\u00adizing each f to true and iteratively strengthens loop invari\u00adants \nuntil they become inductive and strong enough to verify the program. Thus, at line 1, we initialize . \nby mapping all placeholders fi to true. The iterative strengthening of loop invariants in . is performed \nby the recursive VE R I F Y pro\u00adcedure, also given in Figure 2. In the VE R I F Y procedure, the input \n. represents our cur\u00adrent set of speculated loop invariants. Using these candidate invariants ., we then \ninvoke a VCGE N procedure to com\u00adpute the weakest precondition . of program p as well as its VC . (line \n4). We defer discussion of the VCGE N proce\u00addure to Section 4.1. The generated VC . asserts that each \ncandidate invariant . in . is inductive and that it implies the loop postcondition. Speci.cally, the \ngenerated VC s are conjunctions of clauses of the form (\u00df .f) . .. Here, f is a procedure IN VGE N(p): \ninput: program p output: mapping . from each placeholder fi to a concrete loop invariant .i (1) (2) \nlet . = [fi . true | fi . invs(p)] . ' = VE R I F Y(p, .) (3) return . ' procedure V E R I F Y(p, .): \ninput: program p and mapping . output: new mapping . ' from each placeholder fi to a concrete loop invariant \n.i (4) (., .) = VCGE N(p, .) (5) if |= . return \u00d8 (6) if |= elim(.) return . (7) let .i . clauses(.) \nsuch that |= elim(.i) (8) (f, S ) = AB D U C E(.i) (9) for each .i . S  (10) . = .(f) . .i (11) . \n' = VE R I F Y(p, .[f . .]) (12) if . ' = \u00d8 return . ' (13) done (14) return \u00d8  Figure 2. The main \ninvariant generation algorithm placeholder for a potential strengthening of the current loop invariant. \nFormulas \u00df and . do not contain any placehold\u00aders and are generated using the candidate invariants given \nby .. If the VC . with all placeholders f replaced by true is valid, this means the current . is a solution \nto our veri.ca\u00adtion problem. Line 5 of V E R I F Y checks the validity of the program s weakest precondition \n.. If . is not valid, this means our can\u00addidate invariants given by . are not correct. In this case, \nwe return \u00d8 to indicate failure, which causes backtracking in the overall algorithm. Next, at line 6, \nwe check whether the cur\u00adrent VC . is valid. As mentioned before, . contains place\u00adholder variables f, \nwhich represent potential strengthenings of the current loop invariants. Therefore, to check the valid\u00adity \nof the VC, we need to replace all placeholders f with true. For this purpose, we use the notation elim(.) \nto indi\u00adcate the substitution of f with true in .. If elim(.) is valid, we have found a set . of inductive \nloop invariants strong enough to verify the program, and we therefore return . as our solution. On the \nother hand, if elim(.) is not valid, this means our current loop invariants are not strong enough, and \nwe need to strengthen them further. For this purpose, we select one invalid clause .i of the VC containing \none placeholder variable f and attempt to .x it. Speci.cally, recall that .i is (1)(2) ., . f skip \n: ., true ., . f v := e : .[e/v], true (3)(4) ., . f assert C : . . C, true ., . f assume C : C . ., \ntrue ., . f s2 : .2, .2 ., . f s1 : .1, .1 ., .2 f s1 : .1, .1 ., . f s2 : .2, .2 (5) (6) ., . f s1; \ns2 : .1, .1 . .2 ., . f choose s1 s2 : .1 . .2, .1 . .2 ., .(f) f s : . ' , . ' .1 = (\u00acC . .(f) . f) \n. . .2 = (C . .(f) . f) . . ' (7) ., . f while C [f] do {s} : .(f), .1 . .2 . . ' Figure 3. VC Generation \nof the form (\u00df . f) . . where \u00df and . do not contain any placeholders. To .x clause .i, we call the procedure \nAB D U C E to .nd a set S of suitable strengthenings for the left-hand side. As we will see in Section \n4.2, each .i . S is guaranteed to make .i valid, but .i may or may not be a valid invariant. Therefore, \nat line 11, we recursively invoke VE R I F Y to check the correctness of the speculated invariant. In \nthe recursive invocation, we add our current speculation .i to .. Speci.cally, since .i is a strengthening \nfor the current loop invariant .(f), we conjoin .i with the existing .(f) when making the recursive call \nto VE R I F Y. If VE R I F Y does not return \u00d8, this means we have found a suitable set of inductive \nloop invariants and return . ' as the solution. Of course, it is also possible that our current strengthen\u00ading \n.i does not lead to a valid proof; this is indicated by the recursive invocation of VE R I F Y returning \n\u00d8. In this case, we backtrack from our current speculation and try the next so\u00adlution to the abduction \nproblem de.ned by (. . f) . .. If we exhaust all abductive solutions without .nding a valid proof, our \ncurrent proof attempt has failed, and we therefore return \u00d8 to indicate failure. 4.1 VC Generation Our \nVC generation procedure VCGE N is presented as a set of inference rules in Figure 3. The rules produce \njudgments of the form: ., . f s : . ' , . Here, . is a candidate invariant represented as a mapping from \neach placeholder f to a formula .. The VC . is a conjunction of clauses of the form (\u00df . f) . . where \n\u00df, . are placeholder-free formulas and f is a placeholder representing a possible strengthening of the \ncurrent loop invariant. The meaning of this judgment is that, if elim(.) (the VC with all placeholders \nreplaced by true) is valid, then {. ' } s {.} is a valid Hoare triple. Rules (1)-(6) in Figure 3 describe \na standard weakest pre\u00adcondition computation; hence we omit the explanation for these rules. Since Rule \n(7) for while loops is non-standard, we only elaborate on this rule. For generating the VC and the weakest \nprecondition of the while loop, Rule (7) utilizes the current speculated in\u00advariants given by .. Speci.cally, \nthe weakest precondition for the while loop is .(f), which represents the current speculated invariant \nfor the loop. In the rule, . ' is the weak\u00adest precondition for the loop body s to establish the candi\u00addate \nloop invariant .(f). Clause .1 of the VC says that on loop exit, the candidate invariant .(f), strengthened \nwith f, implies the loop s post-condition .. Clause .2 of the VC says that executing the loop when f \nholds re-establishes the invariant .(f). In particular, if f is true, these are just the standard VC \ns for a while loop. The addition of the place\u00adholder f allows us to weaken the VC by adding an assump\u00adtion, \nwhich we obtain by abduction. TH E O R E M 1 (Soundness). If ., . f s : . ' , . is derivable and elim(.) \nis valid, then {.} s {. ' } is valid. PRO O F 1. The proof for rules (1)-(6) follow immediately from \nstandard Hoare logic; we only give the proof for rule (7). Assuming that elim(.1 . .2 . . ' ) is valid \nwe need to show: {.(f)} while C [f] do {s} {.} (1) By inductive hypothesis, we have {. ' } s {.(f)}. \nSince elim(.2) implies C..(f) . . ', we have {C..(f)} s {.(f)}by precondition strengthening. Using the \nstandard Hoare logic rule for while loops, we obtain: {.(f)} while C do {s} {.(f) . \u00acC} (2) Since elim(.1) \nis valid, we have \u00acC . .(f) . .. Finally, by applying postcondition weakening to (2), we obtain (1). \n 4.2 Generating Candidate Strengthenings via Abduction In this section, we describe an AB D U C E procedure \nfor .nd\u00ading possible strengthenings for the current candidate loop in\u00advariant. The procedure AB D U C \nE takes as input a VC clause of the form (. . f) . . where f is a placeholder and infers a strengthening \n. to plug in for f such that: 1. |= (. . .) . . 2. SAT(. . .)  One obvious -but not particularly useful-solution \nto this abduction problem is f = .. To see why . is not a useful so\u00adlution, consider the VC clause that \nasserts the inductiveness of some candidate invariant I for a loop with body s: I . C . wp(s, I ) Hence, \nin our setting, the abductive solution . corresponds to strengthening the current loop invariant I with \nits weakest precondition wp(s, I ). However, in general, wp(s, I ) is too weak of a strengthening and \ntypically leads to divergence. In fact, starting with the loop postcondition I and repeatedly conjoining \nit with wp(s, I ) is equivalent to unrolling the loop body! Therefore, we are interested in solutions \nto the abduction problem that are logically stronger than just the weakest pre\u00adcondition of the current \ninvariant. The main strengthening mechanism we will use here is quanti.er elimination. To see how we \ncan use quanti.er elimination to solve our abduction problem, we .rst observe that the entailment |= \n(. . .) . . can be rewritten as: . |= . . . Now, consider any subset of the free variables V of the formula \n. . .. Clearly, we have: .V. . . . |= . . . Therefore, any formula . that is logically equivalent to \n.V.. . . and that does not contradict . is a solution to our abduction problem. DE FI N I T I O N 1 . \n(Universal subset) We call a set of variables V a universal subset (US) of f with respect to . if the \nformula (.V.f) . . is satis.able. Hence, if V is a universal subset of . . f with respect to ., we can \nobtain a solution to our abduction problem by pro\u00adjecting out variables V from the formula . . f through \nuni\u00adversal quanti.er elimination in Presburger arithmetic. Fur\u00adthermore, empirically, it turns out that \nsolutions obtained in this way through quanti.er elimination are very useful can\u00addidates for auxiliary \nloop invariants. Intuitively, quanti.er procedure A B D U C E(.): input: formula . of the form . . f \n. . output: (f, S ) such that |= . . .i . . for every .i . S (1) let f = (. . f) . . (2) let . = {.} \n (3) let S = [ ] (4) while true  (5) V = MU S(. . . , .) (6) if V = \u00d8 then break (7) . = QE(.V .. . \n.) (8) S = S :: . (9) . = . . {\u00ac.} (10) done (11) return (f, S )  Figure 4. Algorithm for computing \nan ordered list S of solutions to abduction problem . . f . .. The procedure MU S(f, .) computes a maximum \nuniversal subset of f with respect to .. elimination is useful because it allows us to project out vari\u00adables \nthat are irrelevant and prevent the invariant from being inductive. EX A M P L E 1. To get some intuition \nabout why quanti.er elimination is useful for generating inductive invariants, consider the following \ncode example: int x = 0; int y = 0; while(x < n) { x = x+1; y = y+2; }assert(y >= n); Assuming the initial \nloop invariant is true, the generated VC is x = n . y = n, which does not correspond to an in\u00adductive \ninvariant. Now, if we project out n from this formula by universally quantifying n and applying quanti.er \nelimi\u00adnation, we obtain y = x, which is indeed an inductive loop invariant. Intuitively, here, quanti.er \nelimination allows us to generalize the last iteration of the loop to an inductive assertion. Based on \nthis observation, Figure 4 summarizes the full abduction algorithm that we use for generating candidate \nstrengthenings of the current loop invariant. Effectively, this algorithm generates all possible universal \nsubsets of . . . with respect to . and infers a candidate strengthening by projecting out all variables \nin that universal subset from our veri.cation condition. An important consideration in this algorithm \nis which universal subset to consider .rst. Speci.cally, since the invariant generation algorithm from \nFigure 2 performs a depth-.rst search, candidate strengthenings that are too weak can cause our algorithm \nto either take too long or, worse, diverge in an in.nite chain of speculations. On the other hand, if \nwe .rst try a strengthening that is too strong, this is often not a problem because the algorithm can \nquickly derive a contradiction and backtrack. ' Now, observe that for a pair of universal subsets U, \nU of some formula f, if U . U ', then .U.f logically implies .U ' .f. Hence, to generate stronger auxiliary \ninvariants be\u00adfore weaker ones, our abduction algorithm considers univer\u00adsal subsets in decreasing order \nof their cardinality. DE FI N I T I O N 2 . (Maximum universal subset) A universal subset U of f is a \nmaximum universal subset (MUS) if ' |U| = |U ' | for any other universal subset U of f. An algorithm \nfor computing maximum universal subsets of formulas is described in our earlier work [16]. We are now \nready to explain the full algorithm shown in Figure 4 for generating an ordered list S of candidate strengthenings. \nIn each iteration of the while loop, we com\u00adpute a maximum universal subset of . . . consistent with \nall constraints in set ., which initially only includes .. If there does not exist an MUS of . . . consistent \nwith all constraints in ., our algorithm terminates and returns S as a list of candidate strengthenings. \nHowever, if there exists an MUS V , we then obtain a new candidate invariant . by pro\u00adjecting out all \nvariables in V from the formula . . . using a quanti.er elimination procedure for Presburger arithmetic, \nsuch as Cooper s method [17]. Now, since we want to obtain a different MUS in the next iteration, we \nadd \u00ac. to .. This strategy ensures that the MUS obtained in the next iteration is different from previous \nones because V can no longer be an MUS consistent with \u00ac. = \u00ac(.V .(. . .)). Therefore, the list S computed \nby our AB D U C E procedure contains the set of auxiliary candidate invariants in decreasing order of \nlogical strength. Observe that the abduction algorithm we present here is not complete. That is, for \nan abduction problem de.ned by ., ., our method does not generate all possible formulas . such that . \n. . . . is valid. This is not surprising since there may be in.nitely many . that solve a given abduc\u00adtion \nproblem in Presburger arithmetic. Instead, our approach only computes those solutions that can be obtained \nthrough applying quanti.er elimination on the original formula. In our experimental evaluation (see Section \n6), there are some benchmarks where our technique is unsuccessful due to this source of incompleteness. \n5. Improvements and Extensions We have implemented the algorithm described in this pa\u00adper in a tool called \nHO L A 1 . HO L A currently works on the pointer-free fragment of the C language and uses the 1 HO L \nA stands for HOare Logic with Abduction SA I L front-end for converting C programs to an interme\u00addiate \nlanguage [18]. HO L A also utilizes the Mistral SMT solver [16, 19, 20] for determining satis.ability, \nperforming quanti.er elimination in Presburger arithmetic, and comput\u00ading maximum universal subsets. \nAn important difference between our implementation and the basic algorithm described in this paper is \nthat our imple\u00admentation performs a dual forwards and backwards analy\u00adsis rather than pure backwards \nreasoning. Speci.cally, while the algorithm described in this paper computes only weakest preconditions, \nour implementation simultaneously computes strongest postconditions and weakest preconditions. This combination \nof forwards and backwards reasoning has two signi.cant advantages. First, the computation of strongest \npostconditions allows us to obtain (overapproximate) loop preconditions which are then used to reject \nabductive solu\u00adtions that violate facts known to hold on loop entry. For ex\u00adample, if we know that x \n= 0 and y = 1 hold on loop entry, we can immediately reject the abductive speculation x = y since it \ncontradicts the loop precondition. Hence, the use of forward reasoning allows us to locally reject many \nwrong speculations and prevents unnecessary backtracking. A second important advantage of performing \nforwards reasoning is that it allows us to obtain stronger initial loop invariants than just the trivial \ninvariant true. Speci.cally, recall that the IN VGE N algorithm from Figure 2 initializes . to map each \nfi to true. Now, if we know that the loop precondition is P and that variables V are not modi.ed in the \nloop, then we can safely initialize the loop invariant to .V . P where V represents variables that may \nbe modi.ed in the loop. As an example, suppose that the precondition for some loop is x + y = n . y = \n0. If we know that y may be modi.ed in the loop, but x is de.nitely not modi.ed, then we can safely conclude \nthat x = n is an invariant of the loop by applying existential quanti.er elimination to the formula .y.(x \n+ y = n . y = 0). This strategy gives us a sound initial invariant that is better than just true and \ntherefore cuts down substantially on the number of search paths explored by our algorithm. Another improvement \nof our implementation over the ba\u00adsic algorithm is the lazy recomputation of veri.cation con\u00additions. \nSpeci.cally, recall that the VE R I F Y algorithm from Figure 2 recomputes the VC for the entire program \nin each recursive invocation, which is both expensive and unneces\u00adsary. In our implementation, we therefore \nonly recompute those clauses of the VC that could have changed due to strengthening a given loop invariant. \nFor example, if we strengthen the invariant of some loop L, this only changes the VC of L, loops that \nimmediately come before and af\u00adter L, loops in which L is nested, and loops that are nested inside L. \nBased on this observation, our implementation up\u00addates VCs locally rather than recomputing the VC for \nthe entire program. Our implementation also differs from the presentation in this paper in that it does \nnot eagerly generate all possi\u00adble solutions to an abduction problem (as was done in the AB D U C E algorithm \nfrom Figure 4). Speci.cally, our imple\u00admentation generates one abductive solution at a time and im\u00admediately \ntries to verify this speculation. A new abductive solution is generated lazily only when the previous \nspecula\u00adtion is wrong and forces backtracking to the previous deci\u00adsion level. 6. Experimental Evaluation \nTo evaluate the proposed technique, we compared our tool HO L A with three available state-of-the-art \ninvariant gen\u00aderation tools, namely BLAST [7], InvGen [5], and Inter\u00adproc [21]. Each of the three tools \nwe compared against rep\u00adresents a different family of invariant generation techniques: Interproc is based \non abstract interpretation and, in our ex\u00adperiments, we compared against the most expressive ab\u00adstract \ndomain implemented by Interproc, which is the re\u00adduced product of polyhedra and linear congruences abstract \ndomains. InvGen is a constraint-based invariant generator and solves for the unknown parameters of a \ngiven template of invariants. In our experiments, we used the default tem\u00adplates provided by InvGen. \nFinally, BLAST is a CEGAR\u00adbased model checker which uses Craig interpolation to gen\u00aderate candidate invariants \nfrom counterexamples. In our experimental evaluation, we used 46 loop invari\u00adant benchmarks, each containing \nat least one loop and at least one assertion. Some benchmarks contain nested loops or multiple sequential \nloops. 26 of our 46 benchmarks are ei\u00adther taken directly or adapted from other sources, including examples \nfrom other loop invariant generation papers [2, 22 31], the InvGen test suite [32], and the NECLA veri.cation \nbenchmarks [33]. The remaining 20 benchmarks are taken from the HO L A test suite. All benchmarks are \navailable from http://www.cs.wm.edu/ tdillig/oopsla13-benchmarks.tar.gz. In the experiments, our goal \nis to determine which of the tools can infer strong enough invariants suf.cient to verify all assertions \nin the program. While BLAST, InvGen, and HO L A can directly process assertions in the source code, Interproc \nonly outputs inferred invariants for each program point. Thus, for Interproc, we used an SMT solver to \ncheck whether the inferred invariants imply the safety of the asser\u00adtion. Figure 5 presents the results \nof our experimental evalua\u00adtion. These experiments were performed on an Intel i5 2.6 GHz CPU with 8 GB \nof memory. For each tool, V indicates that the tool was able to verify all assertions in the program, \nwhile ) denotes the opposite (i.e., either the tool did not ter\u00adminate or was unable to infer the necessary \ninvariants). The columns labeled Time next to the tool names indicate how long the tools took on each \nbenchmark in seconds. A dash ( ) in this column indicates that the tool did not terminate in 200 seconds. \n As Figure 5 shows, the proposed technique is quite effec\u00adtive at .nding strong enough invariants suf.cient \nto verify these benchmarks. Speci.cally, HO L A can verify 43 out of our 46 benchmarks and diverges on \nthree. As Figure 5 also indicates, HO L A can verify 13 benchmarks that cannot be proven by any other \ntool. In contrast, there are two bench\u00admarks that can be veri.ed by at least one other tool, but not \nby HO L A. Overall, HO L A has a success rate of 93.5% on these benchmarks while BLAST, InvGen, and Interproc \nhave a success rate of 43.5%, 47.8%, and 37.0% respectively.2 While HOLA performs overall better than \nthe other tools on these benchmarks, the set of invariants that can be in\u00adferred by H O L A is not a \nsuperset of those invariants that can be inferred by other approaches. Indeed, H O L A fails to verify \nbenchmark 19 which can be veri.ed by BLAST as well as benchmark 15 which can be veri.ed by all other \ntools. For these benchmarks, HOLA fails to .nd an induc\u00adtive invariant because the required invariant \ncan simply not be obtained by performing quanti.er elimination on the gen\u00aderated VCs. In principle, however, \na different algorithm for performing abduction could generate the required invariant. In contrast, HO \nL A can verify 13 benchmarks that no other tool can verify. Some of these benchmarks require disjunc\u00adtive \ninvariants and are therefore fundamentally beyond the capabilities of standard abstract interpretation \ntools such as Interproc. 3 InvGen fails to verify these benchmarks because the required invariants are \nsimply not in the vocabulary of the templates used by InvGen. In contrast, BLAST diverges on many of \nthese benchmarks since the interpolants com\u00adputed from counterexample traces do not generalize into in\u00adductive \ninvariants. We believe these results demonstrate that our new method complements existing techniques \nand ad\u00advances the state-of-the-art in loop invariant generation. Figure 6 presents more details about \nthe behavior of our algorithm on the experimental benchmarks. The column labeled Strengthenings shows \nthe minimum number of strengthening steps required for computing the .nal invari\u00adant. In contrast, the \ncolumn labeled Iterations shows the number of recursive calls made by our algorithm. Observe that if \nour search strategy is perfect (i.e., the .rst abductive solution always corresponds to a valid program \ninvariant), then the number of iterations should be exactly one greater than the number of strengthenings. \nTherefore, a high ra\u00adtio of strengthenings to iterations means that our algorithm immediately homes in \non the correct invariants. The col\u00adumn labeled Backtracks reports the total number of back\u00adtracking steps \nperformed by our algorithm. If the number of backtracking steps is high, this means we perform many unnecessary \nstrengthenings. 2 On the 26 benchmarks taken from external sources, HOLA has a success rate of 96.2% \nwhile BLAST, InvGen, and Interproc have success rates of 57.7%, 65.4%, and 50% respectively. 3 While \nsome of these benchmarks do not require disjunctive invariants, Interproc still fails due to widening. \n Name LOC BLAST Time(s) InvGen Time(s) Interproc Time(s) HO L A Time(s) Benchmark 21 V 0.10 V 0.14 V \n0.01 V 0.03 Benchmark 26 ) 0.08 ) 0.05 ) 0.01 V 0.32 Benchmark 22 V 0.46 V 0.20 ) 0.01 V 0.04 Benchmark \n21 V 1.22 ) 0.07 ) 0.01 V 0.03 Benchmark 27 )  V 0.21 V 0.01 V 0.06 Benchmark 28 ) 0.08 ) 0.06 ) 0.01 \nV 0.25 Benchmark 27 ) 3.09 V 0.22 V 0.01 V 0.56 Benchmark 30 ) 5.68 V 0.23 ) 0.01 V 0.59 Benchmark 49 \n)  V 0.34 V 0.01 V 0.06 Benchmark 30 ) 0.08 ) 0.06 ) 0.01 V 0.18 Benchmark 24 )  V 0.16 V 0.01 V 0.20 \nBenchmark 34 ) 7.94 )  ) 0.01 V 3.52 Benchmark 25 V 0.38 ) 0.20 V 0.01 V 0.38 Benchmark 26 V 1.14 V \n0.15 V 0.01 V 1.31 Benchmark 28 V 0.30 V 0.15 V 0.01 ) Benchmark 23 ) 1.13 V 0.13 V 0.01 V 0.12 Benchmark \n22 V 0.32 V 0.19 V 0.01 V 0.05 Benchmark 23 )  ) 12.05 ) 0.01 V 3.64 Benchmark 24 V 1.06 ) 0.08 ) 0.01 \n) Benchmark 33 V 2.11 ) 0.20 ) 0.01 V 2.29 Benchmark 39 ) 0.93 ) 0.04 V 0.01 V 1.55 Benchmark 26 ) 0.10 \n) 0.07 ) 0.01 V 0.23 Benchmark 20 )  V 0.16 ) 0.01 V 0.03 Benchmark 18 V 0.08 V 0.22 V 0.01 V 0.07 Benchmark \n33 V 0.51 V 4.63 ) 0.01 V 0.07 Benchmark 24 ) 0.07 ) 0.07 ) 0.01 V 0.08 Benchmark 23 V 0.14 V 0.21 V \n0.01 V 0.08 Benchmark 25 )  V 0.17 V 0.01 V 0.05 Benchmark 32 ) 0.08 ) 0.05 ) 0.01 V 0.37 Benchmark \n22 ) 0.55 V 0.12 ) 0.01 V 0.03 Benchmark 29 V 0.13 V 0.25 ) 0.01 V 0.25 Benchmark 24 V 0.11 ) 0.07 ) \n0.01 V 0.64 Benchmark 36 V 0.50 )  ) 0.01 V 0.10 Benchmark 23 ) 1.12 ) 0.05 ) 0.01 ) Benchmark 17 V \n0.15 ) 0.10 ) 0.01 V 0.09 Benchmark 71 ) 1.01 ) 0.09 ) 0.01 V 1.00 Benchmark 21 V 0.62 ) 0.14 ) 0.01 \nV 0.87 Benchmark 20 ) 0.14 ) 0.05 ) 0.01 V 0.32 Benchmark 62 V 0.27 V 0.28 V 0.01 V 0.40 Benchmark 30 \n) 0.86 ) 0.06 ) 0.01 V 0.94 Benchmark 25 ) 2.69 V 0.16 ) 0.01 V 0.53 Benchmark 37 ) 0.08 V 0.07 V 0.01 \nV 0.07 Benchmark 27 V 0.08 V 0.18 V 0.01 V 0.05 Benchmark 35 V 0.36 ) 0.22 ) 0.01 V 1.25 Benchmark 44 \n) 0.30 ) 0.11 ) 0.01 V 0.65 Benchmark 24 ) 0.12 ) 0.05 ) 0.01 V 0.18 Figure 5. Experimental results \nFigure 6. Statistics about algorithm and the benchmarks Name Strengthenings Iterations Backtracks # \nInvariants Disjunctive? Avg. Inv. Size Benchmark 2 3 0 1 no 2.0 Benchmark 3 4 0 1 no 5.0 Benchmark 0 \n1 0 3 yes 1.7 Benchmark 1 6 4 1 yes 2.0 Benchmark 2 3 0 1 no 2.0 Benchmark 4 5 0 2 yes 5.0 Benchmark \n2 14 11 1 yes 4.0 Benchmark 3 14 10 1 no 3.0 Benchmark 6 8 0 4 no 1.0 Benchmark 2 3 1 1 yes 5.0 Benchmark \n2 14 12 1 yes 4.0 Benchmark 7 74 68 2 yes 5.0 Benchmark 2 28 25 1 yes 8.0 Benchmark 2 29 26 1 no 5.0 \nBenchmark Benchmark 1 23 21 1 yes 2.0 Benchmark 7 7 2 2 no 2.0 Benchmark 2 234 226 1 no 4.0 Benchmark \nBenchmark 2 132 129 1 yes 1.5 Benchmark 2 3 0 1 yes 9.0 Benchmark 2 3 0 1 no 4.0 Benchmark 2 3 0 1 no \n3.0 Benchmark 2 3 0 2 no 1.7 Benchmark 4 5 0 2 no 2.0 Benchmark 6 8 0 2 yes 5.0 Benchmark 7 8 0 3 yes \n2.7 Benchmark 2 7 3 2 no 2.0 Benchmark 2 3 0 2 no 1.0 Benchmark 2 3 0 1 no 2.0 Benchmark 2 4 0 3 yes \n5.3 Benchmark 3 27 25 1 yes 11.0 Benchmark 6 7 0 3 no 1.7 Benchmark Benchmark 1 19 17 1 yes 3.0 Benchmark \n2 7 4 4 no 3.5 Benchmark 2 94 92 1 yes 2.0 Benchmark 2 17 14 1 yes 4.0 Benchmark 0 1 0 1 yes 11.0 Benchmark \n7 57 52 2 yes 3.0 Benchmark 3 4 0 1 yes 10.0 Benchmark 2 3 0 1 yes 5.0 Benchmark 1 2 0 1 no 3.0 Benchmark \n1 46 44 1 yes 6.0 Benchmark 10 11 0 3 yes 6.0 Benchmark 2 10 7 1 yes 4.0  According to the data from \nFigure 6, our algorithm takes an average of 22.4 iterations and 19.7 backtracking steps to compute the \n.nal invariants required for verifying the pro\u00adgram. For most benchmarks, the ratio of strengthenings \nto it\u00aderations is high, indicating that the algorithm quickly homes in on the correct invariant. However, \nfor some benchmarks, such as 18, 20, and 37, the strengthening to iteration ratio is low and the number \nof backtracking steps is high. This indi\u00adcates that our simple depth-.rst search strategy is sometimes \nineffective. That is, our algorithm always chooses strength\u00adening the current speculated invariant over \nexploring other speculations, but for some benchmarks, this simple strategy results in exploring many \ndead ends. This data indicates that the performance of our algorithm could be further improved by formulating \neffective heuristics to guide search space ex\u00adploration, which we leave as future work. The last three \ncolumns in Figure 6 give information about the computed invariants. The column labeled # Invariants gives \nthe number of non-trivial loop invariants required to verify the program. The column labaled Disjunctive? \nin\u00addicates whether the invariants computed by our algorithm involve disjunctions, and the last column \nindicates the aver\u00adage size of the computed invariants, measured in terms of the number of boolean connectives. \nAs this data shows, many of these benchmarks involve multiple non-trivial invariants, of\u00adten involving \ndisjunctions. 7. Related Work 7.1 Other Techniques for Loop Invariant Generation Existing techniques \nfor loop invariant generation include ab\u00adstract interpretation [1 4, 34], counterexample guided ab\u00adstraction \nre.nement (CEGAR) [7, 8, 35], constraint-based methods [5, 6, 36], guess-and-check approaches [37, 38], \nand techniques based on Craig interpolation [9 11, 39]. One dimension along which loop invariant generation \ntechniques can be characterized is lazy vs. eager approaches. Eager techniques, such as abstract interpretation \nand constraint\u00adbased methods, compute all possible invariants they can about the program, while lazy \ntechniques compute only those invariants that are necessary for showing the program s correctness. Similar \nto CEGAR and interpolation-based ap\u00adproaches, our technique is lazy: We strengthen loop invari\u00adants in \na demand-driven way only when stronger invariants are needed to verify the correctness of the program. \nAnother dimension in which invariant generation tech\u00adniques can be classi.ed is whether they infer invariants \nof a prede.ned syntactic shape, such as only equalities or con\u00adjunctions. For example, in abstract interpretation, \nthe choice of the abstract domain .xes the shape of the invariants to be inferred, such as octagons or \npolyhedra. Constraint-based approaches also .x a template (such as ax + \u00dfy = .) which syntactically restricts \nthe class of invariants that can be in\u00adferred. In contrast, the approach proposed in this paper does \nnot syntactically restrict the class of invariants to be inferred and can therefore discover linear invariants \nwith arbitrary boolean structure. Similar to many guess-and-check, CEGAR, and interpo\u00adlation approaches, \nour technique generates candidate invari\u00adants whose correctness must later be checked. For exam\u00adple, \nHoudini [37] uses syntactic clues to guess candidate invariants, and Daikon [38] utilizes observed run-time \nval\u00adues to generate guesses. CEGAR and interpolation-based ap\u00adproaches generate candidate invariants \nfrom counterexample traces in order to rule out at least the observed spurious trace. Our technique differs \nfrom all of these approaches in that our candidate invariants are, by construction, always suf.cient \nto show the correctness of some assertion in the program. In this sense, our technique is more goal directed \nthan ap\u00adproaches that speculate invariants. Similar to interpolation\u00adbased techniques, our approach is \ncompletely semantic and uses logical inference to compute candidate invariants. How\u00adever, a difference \nis that interpolation approaches generate invariants that are implied by underapproximations of the reachable \nstates, whereas here we speculate invariants that are consistent with an overapproximation of the reachable \nstates. The loop invariant generation method presented in [40] bears similarities to our technique. Like \nour approach, [40] also starts from assertions to be proven and generates in\u00adductive invariants by iteratively \nstrengthening an initial can\u00addidate invariant. The main difference between our method and [40] is the \nstrengthening mechanism: Here, the strength\u00adening is performed by applying abductive inference on in\u00advalid \nVCs. In contrast, the method of [40] repeatedly com\u00adputes the weakest precondition of the assertion through \nthe loop body and performs generalization by dropping predi\u00adcates that are not shared across loop iterations. \nFurthermore, unlike our approach, the inferred strengthenings may not be suf.cient to .x the VC even \nif they are inductive. Finally, since [40] is based on symbolic execution, it relies on ex\u00adact loop preconditions \nwhich may be overapproximate in our setting. Another approach related to the technique considered here \nis IC3 [22, 41, 42]. As in interpolation methods, in\u00adference in IC3 is geared to rule out counterexamples, \nwhich is not the case here. There is an interesting connection to our method, however. IC3 starts with \na known (time-bounded) fact f1 and infers a f2 that is inductive relative to f1. Here, we do the opposite. \nWe start with a conjecture f2 and infer by abduction a new conjecture f1, such that f2 is induc\u00adtive \nrelative to f1. A difference is that IC3 conservatively infers time-bounded facts, while we always speculate \nthat our abductive inferences are invariant, so we may have to backtrack. Some loop invariant generation \ntechniques, such as ab\u00adstract interpretation and constraint-based methods, are guar\u00adanteed to terminate, \nwhile others, such as CEGAR, can di\u00adverge. Similar to CEGAR, our technique also does not have termination \nguarantees: While we consider a .nite number of abductive strengthenings at each step, there is no bound \non the number of possible strengthenings; as a result, the al\u00adgorithm as presented in this paper may \ndiverge in an in.nite chain of speculations. However, it is easily possible to mod\u00adify our algorithm \nto guarantee termination, for example, by limiting the number of abductive strengthenings that may be \nperformed.  7.2 Use of Abduction in Program Veri.cation The concept of logical abduction, which was \noriginally pro\u00adposed by Peirce [15], has found a number of useful appli\u00adcations in program veri.cation. \nSpeci.cally, abduction has been used in modular shape analysis based on separation logic [43], for inferring \nmissing preconditions in the anal\u00adysis of logic programs [44], and for constructing underap\u00adproximations \nin quanti.ed logical domains [45]. All these techniques use different algorithms for performing abduc\u00adtion \nthan the one we consider here and apply logical abduc\u00adtion in the context of very different problem domains. \nTo the best of our knowledge, the only previous applica\u00adtion of abduction to invariant generation is \nin the context of resource invariant synthesis using separation logic [46]. For each lock in the program, \na resource invariant is an asser\u00adtion that holds whenever no thread has acquired that lock. The work \ndescribed in [46] uses bi-abductive inference in separation logic to infer such resource invariants. \nThere are several key differences between the work described in [46] and this paper. First, here, we \nconsider the problem of infer\u00adring Presburger arithmetic invariants whereas [46] considers resource invariants \nexpressible in separation logic. However, the present work cannot be viewed as simply applying that method \nto arithmetic invariants. Among many differences, [46] uses a .xed heap abstration function to compute \nbi\u00adabductive inferences and generates only one re.nement for a given counterexample. Using a .xed abstraction \nwould not work for our application domain because the heart of our approach is to generate a range of \nabductive inferences and construct the invariant by backtracking search. Our own recent work has applied \nabductive inference to the diagnosis of error reports generated by veri.cation tools [47] and the construction \nof circular compositional program proofs [48]. Speci.cally, [47] uses abductive infer\u00adence to generate \nqueries that are used to help users decide whether static analysis warnings correspond to real bugs or \nfalse alarms. Our recent work described in [48] uses abduc\u00adtion to decompose the program s proof of correctness \ninto small local lemmas, each of which are proven by a differ\u00adent tool or abstraction in a circular compositional \nmanner. The abduction algorithm we present in Section 4.2 is simi\u00adlar to the abduction algorithms used \nin [47, 48], but adapted for the purpose of generating candidate strengthenings. The main contribution \nof the present paper is to apply logical abduction in the context of automatic numeric invariant gen\u00aderation. \nTo the best of our knowledge, this is the .rst paper to demonstrate that a logical abduction procedure \nbased on quanti.er elimination is powerful for automatically inferring interesting numeric loop invariants. \n 8. Conclusion and Future Work In this paper, we have presented a new method for generating loop invariants \nthat are expressible in Presburger arithmetic. Our technique performs a backtracking search that combines \nHoare-style program reasoning with logical abduction based on quanti.er elimination to speculate candidate \ninvariants. The inferred loop invariants are iteratively strengthened un\u00adtil they are both inductive \nand strong enough to prove pro\u00adgram correctness. Experiments on a set of benchmarks taken from a variety \nof existing and new sources indicate that our approach is effective in practice and can infer invariants \nthat cannot be established by existing tools. In future work, we plan extend the applicability of the \napproach described in this paper by addressing two key issues: 1. Scalability: To make the proposed approach \nuseful for analyzing large, real-world programs, we believe it is necessary to reduce backtracking as \nmuch as possible. For this purpose, we plan to explore different search strategies than the simple depth-.rst \nstrategy considered in this paper. Furthermore, we plan to use underapproxi\u00admations for quickly ruling \nout wrong abductive specula\u00adtions. 2. Abduction in richer logical theories: While this paper only addresses \nnumeric invariant generation, making the proposed approach practical for real-world programs re\u00adquires \nreasoning about data structure invariants. Since such invariants are only expressible in richer logical \nthe\u00adories such as the theory of uninterpreted functions or the theory of arrays, we plan to explore abduction \nalgorithms for richer logics. Since such logics do not admit quanti.er elimination, abduction must be \nperformed either through sound, but approximate quanti.er elimination procedures such as [49] or through \ndomain-speci.c inference rules for a particular theory.  References [1] Cousot, P., Halbwachs, N.: \nAutomatic Discovery of Linear Restraints among Variables of a Program. In: POPL, ACM (1978) 84 96 [2] \nMin\u00b4 e, A.: The octagon abstract domain. Higher-Order and Symbolic Computation 19(1) (2006) 31 100 [3] \nCousot, P., Cousot, R.: Systematic design of program analysis frameworks. In: POPL, ACM (1979) 269 282 \n[4] Karr, M.: Af.ne relationships among variables of a program. A.I. (1976) 133 151 [5] Gupta, A., Rybalchenko, \nA.: Invgen: An ef.cient invariant generator. In: Computer Aided Veri.cation, Springer (2009) 634 640 \n [6] Col \u00b4on, M., Sankaranarayanan, S., Sipma, H.: Linear invariant generation using non-linear constraint \nsolving. In: Computer Aided Veri.cation, Springer (2003) 420 432 [7] Henzinger, T., Jhala, R., Majumdar, \nR., Sutre, G.: Software veri.cation with BLAST. In: International conference on Model checking software. \n(2003) 235 239 [8] Ball, T., Rajamani, S.: The slam toolkit. In: Computer aided veri.cation, Springer \n(2001) 260 264 [9] McMillan, K.: Lazy annotation for program testing and ver\u00adi.cation. In: Computer Aided \nVeri.cation, Springer (2010) 104 118 [10] Henzinger, T., Jhala, R., Majumdar, R., McMillan, K.: Ab\u00adstractions \nfrom proofs. ACM SIGPLAN Notices 39(1) (2004) 232 244 [11] McMillan, K.: Interpolation and sat-based \nmodel checking. In: Computer Aided Veri.cation, Springer (2003) 1 13 [12] Flanagan, C., Leino, K.R.M., \nLillibridge, M., Nelson, G., Saxe, J.B., Stata, R.: Extended static checking for java. In: Proceedings \nof the ACM SIGPLAN 2002 Conference on Pro\u00adgramming language design and implementation. PLDI 02, New York, \nNY, USA, ACM (2002) 234 245 [13] Leino, K.: Dafny: An automatic program veri.er for func\u00adtional correctness. \nIn: Logic for Programming, Arti.cial In\u00adtelligence, and Reasoning, Springer (2010) 348 370 [14] Barnett, \nM., yuh Evan Chang, B., Deline, R., Jacobs, B., Leino, K.R.: Boogie: A modular reusable veri.er for object\u00adoriented \nprograms. In: Formal Methods for Components and Objects: 4th International Symposium, FMCO 2005, volume \n4111 of Lecture Notes in Computer Science, Springer (2006) 364 387 [15] Peirce, C.: Collected papers \nof Charles Sanders Peirce. Belk\u00adnap Press (1932) [16] Dillig, I., Dillig, T., McMillan, K., Aiken, A.: \nMinimum satisfying assignments for SMT, CAV (2012) [17] Cooper, D.: Theorem proving in arithmetic without \nmultipli\u00adcation. Machine Intelligence 7(91-99) (1972) 300 [18] Dillig, I., Dillig, T., Aiken, A.: SAIL: \nStatic Analysis Inter\u00admediate Language. Stanford University Technical Report [19] Dillig, I., Dillig, \nT., Aiken, A.: Small formulas for large programs: On-line constraint simpli.cation in scalable static \nanalysis. SAS (2011) [20] Dillig, I., Dillig, T., Aiken, A.: Cuts from Proofs: A Complete and Practical \nTechnique for Solving Linear Inequalities over Integers. In: CAV. (2009) [21] Jeannet, B.: Interproc \nanalyzer for recursive pro\u00adgrams with numerical variables. http://pop-art. inrialpes. fr/interproc/interprocweb. \ncgi [22] Bradley, A.: Understanding IC3. Theory and Applications of Satis.ability Testing SAT 2012 (2012) \n1 14 [23] Gulwani, S., Srivastava, S., Venkatesan, R.: Program analysis as constraint solving. In: PLDI. \nVolume 43., ACM (2008) 281 292 [24] Jhala, R., McMillan, K.: A practical and complete approach to predicate \nre.nement. Tools and Algorithms for the Con\u00adstruction and Analysis of Systems (2006) 459 473 [25] Sharma, \nR., Nori, A., Aiken, A.: Interpolants as classi.ers. In: Computer Aided Veri.cation, Springer (2012) \n71 87 [26] Gulavani, B., Rajamani, S.: Counterexample driven re.ne\u00adment for abstract interpretation. \nTools and Algorithms for the Construction and Analysis of Systems (2006) 474 488 [27] Gulwani, S., Jojic, \nN.: Program veri.cation as probabilistic inference. In: ACM SIGPLAN Notices. Volume 42., ACM (2007) 277 \n289 [28] Gulavani, B., Chakraborty, S., Nori, A., Rajamani, S.: Au\u00adtomatically re.ning abstract interpretations. \nTACAS (2008) 443 458 [29] Beyer, D., Henzinger, T.A., Majumdar, R., Rybalchenko, A.: Path invariants. \nIn: Proceedings of the 2007 ACM SIGPLAN conference on Programming language design and implemen\u00adtation. \nPLDI 07, New York, NY, USA, ACM (2007) 300 309 [30] Bradley, A.R., Manna, Z.: Property-directed incremental \nin\u00advariant generation. Form. Asp. Comput. 20(4-5) (June 2008) 379 405 [31] Gulavani, B.S., Henzinger, \nT.A., Kannan, Y., Nori, A.V., Ra\u00adjamani, S.K.: Synergy: a new algorithm for property check\u00ading. In: Proceedings \nof the 14th ACM SIGSOFT interna\u00adtional symposium on Foundations of software engineering. SIGSOFT 06/FSE-14, \nNew York, NY, USA, ACM (2006) 117 127 [32] http://pub.ist.ac.at/ agupta/invgen/: InvGen tool [33] http://www.nec-labs.com/research/system/systems \nSAV\u00adwebsite/benchmarks.php: NECLABS NECLA veri.cation benchmarks [34] Laviron, V., Logozzo, F.: Subpolyhedra: \nA (more) scalable approach to infer linear inequalities. In: Veri.cation, Model Checking, and Abstract \nInterpretation, Springer (2009) 229 244 [35] Clarke, E., Grumberg, O., Jha, S., Lu, Y., Veith, H.: Counterexample-guided \nabstraction re.nement for symbolic model checking. J. ACM 50(5) (September 2003) 752 794 [36] Gulwani, \nS., Srivastava, S., Venkatesan, R.: Constraint-based invariant inference over predicate abstraction. \nIn: Veri.cation, Model Checking, and Abstract Interpretation, Springer (2009) 120 135 [37] Flanagan, \nC., Leino, K.: Houdini, an annotation assistant for esc/java. FME 2001: Formal Methods for Increasing \nSoftware Productivity (2001) 500 517 [38] Ernst, M., Perkins, J., Guo, P., McCamant, S., Pacheco, C., \nTschantz, M., Xiao, C.: The Daikon system for dynamic de\u00adtection of likely invariants. Science of Computer \nProgram\u00adming 69(1-3) (2007) 35 45 [39] McMillan, K.: Lazy abstraction with interpolants. In: Com\u00adputer \nAided Veri.cation, Springer (2006) 123 136 [40] P.areanu, C.S., Visser, W.: as.Veri.cation of java programs \nusing symbolic execution and invariant generation. In: SPIN Workshop on Model Checking Software. Springer \n(2004) 164 181 [41] Bradley, A.: Sat-based model checking without unrolling. In: Veri.cation, Model Checking, \nand Abstract Interpretation, Springer (2011) 70 87 [42] Somenzi, F., Bradley, A.: IC3: where monolithic \nand incre\u00admental meet. In: Proceedings of the International Conference on Formal Methods in Computer-Aided \nDesign, FMCAD Inc (2011) 3 8 [43] Calcagno, C., Distefano, D., O Hearn, P., Yang, H.: Composi\u00adtional \nshape analysis by means of bi-abduction. POPL 44(1) (2009) 289 300 [44] Giacobazzi, R.: Abductive analysis \nof modular logic pro\u00adgrams. In: Proceedings of the 1994 International Symposium on Logic programming, \nCiteseer (1994) 377 391 [45] Gulwani, S., McCloskey, B., Tiwari, A.: Lifting abstract interpreters to \nquanti.ed logical domains. In: POPL, ACM (2008) 235 246 [46] Calcagno, C., Distefano, D., Vafeiadis, \nV.: Bi-abductive resource invariant synthesis. In: Proceedings of the 7th Asian Symposium on Programming \nLanguages and Systems. APLAS 09, Berlin, Heidelberg, Springer-Verlag (2009) 259 274 [47] Dillig, I., \nDillig, T., Aiken, A.: Automated error diagno\u00adsis using abductive inference. In: Proceedings of the 33rd \nACM SIGPLAN conference on Programming Language De\u00adsign and Implementation. PLDI 12, New York, NY, USA, \nACM (2012) 181 192 [48] Li, B., Dillig, I., Dillig, T., McMillan, K., Sagiv, M.: Synthesis of circular \ncompositional program proofs via abduction. In: Proceedings of the 19th international conference on Tools \nand Algorithms for the Construction and Analysis of Systems. TACAS 13, Springer-Verlag (2013) 370 384 \n[49] Gulwani, S., Musuvathi, M.: Cover Algorithms. In: ESOP. (2008) 193 207   \n\t\t\t", "proc_id": "2509136", "abstract": "<p>This paper presents a new method for generating inductive loop invariants that are expressible as boolean combinations of linear integer constraints. The key idea underlying our technique is to perform a backtracking search that combines Hoare-style verification condition generation with a logical abduction procedure based on quantifier elimination to speculate candidate invariants. Starting with true, our method iteratively strengthens loop invariants until they are inductive and strong enough to verify the program. A key feature of our technique is that it is lazy: It only infers those invariants that are necessary for verifying program correctness. Furthermore, our technique can infer arbitrary boolean combinations (including disjunctions) of linear invariants. We have implemented the proposed approach in a tool called HOLA. Our experiments demonstrate that HOLA can infer interesting invariants that are beyond the reach of existing state-of-the-art invariant generation tools.</p>", "authors": [{"name": "Isil Dillig", "author_profile_id": "81331491247", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P4290393", "email_address": "isdillig@microsoft.com", "orcid_id": ""}, {"name": "Thomas Dillig", "author_profile_id": "81331491149", "affiliation": "University College London, London, United Kingdom", "person_id": "P4290394", "email_address": "t.dillig@ucl.ac.uk", "orcid_id": ""}, {"name": "Boyang Li", "author_profile_id": "81554275556", "affiliation": "College of William &#38; Mary, Williamsburg, VA, USA", "person_id": "P4290395", "email_address": "bli01@email.wm.edu", "orcid_id": ""}, {"name": "Ken McMillan", "author_profile_id": "81460649995", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P4290396", "email_address": "kenmcmil@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/2509136.2509511", "year": "2013", "article_id": "2509511", "conference": "OOPSLA", "title": "Inductive invariant generation via abductive inference", "url": "http://dl.acm.org/citation.cfm?id=2509511"}