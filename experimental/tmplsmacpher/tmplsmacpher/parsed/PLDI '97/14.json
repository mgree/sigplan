{"article_publication_date": "05-01-1997", "fulltext": "\n Efficient Procedure Mapping Using Cache Line Coloring Amir H. Hashemi David R. Kaeli Brad Calder Dept. \nof Electrical and Computer Engineering Dept. of Computer Science and Engineering Northeastern University \nUniversity of California, San Diego Boston, MA La Jolla, CA {ahashemi,kaeli}Oece.neu.edu calderQcs.ucsd.edu \n Abstract As the gap between memory and processor performance continues to widen, it becomes increasingly \nimportant to exploit cache memory eflectively. Both hardware and aoft-ware approaches can be explored \nto optimize cache per-formance. Hardware designers focus on cache organiza-tion issues, including replacement \npolicy, aaaociativity, line sire and the resulting cache access time. Software writ-ers use various optimization \ntechniques, including software prefetching, data scheduling and code reordering. Our fo- cus is on improving \nmemory usage through code reordering compiler techniques. In this paper we present a link-time procedure \nmap-ping algorithm which can significantly improve the eflec-tiveneas of the instruction cache. Our algorithm \nproduces an improvedpmgmm layout by performing a color mapping of procedures to cache lines, taking into \nconaidemtion the procedure size, cache size, cache line size, and call graph. We use cache line coloring \nto guide the procedure mapping, indicating which cache lines to avoid when placing a pro-cedure in the \nprogmm layout. Our algorithm reduces on avemge the instruction cache miss rote by 40% over the original \nmapping and by 17% over the mapping algorithm of Pettis and Hansen [lZ]. 1 Introduction The increasing \ngap between processor and main mem-ory speeds has forced computer designers to exploit cache memories. \nA cache is smaller than the main memory and, if properly managed, can hold a major part of the work- \ning set of a program [7]. The goal of memory subsys-tem designers is to improve the average memory access \ntime. Reducing the cache miss rate is one factor for im- proving memory access performance. Cache misses \noccur for a number of reasons: cold start, capacity, and colli- sions [13]. A number of cache line replacement \nalgorithms have been proposed to reduce the number of cache COIL sions [2, 14, 191. Instead of concentrating \non cache organization we con- centrate on the layout of a program on the memory space. Permission to \nmake digital/hard copy of part or all this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for profit or commercial advan-tage, the copyright notice, \nthe title of the publication and its date appear, and notice is given that copying is by permission of \nACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires \nprior specific permission and/or a fee. PLDI 97 Las Vegas, NV, USA 0 1997 ACM 0-89791-907~619710006...$3.50 \nBershad et.al. suggested remapping cache addresses dy- namically to avoid conflict misses in large direct-mapped \ncaches [3]. An alternative approach is to perform code repositioning at compile or link-time [4, 9, 11, \n12, 16, 201. The idea is to place frequently used sections of a program next to each other in the address \nspace, thereby reduc-ing the chances of cache conflicts while increasing spatial locality within the \nprogram. Code reordering algorithms for improved memory per- formance can span several different levels \nof granularity, from basic blocks, to loops, and to procedures. Research has shown that basic block reordering \nand procedure re-ordering can significantly improve a program s execution performance. Pettis and Hansen \n[12] found that the re-duction in execution time when using procedure reorder-ing was around So/o, and \nthe reduction in execution time for basic block reordering was around 12% on an HP-UX 825 architecture \nwith a 16K direct mapped unified cache. When both of the optimizations were applied together an average \nimprovement of 15% was achieved. The mapping algorithm we propose in this paper im- proves upon prior \nwork, particularly when a program s control flow graph is larger than the cache capacity. Since we are \ninterested in dealing with graphs that are larger than the target instruction cache, we concentrate our \ndis- cussion in this paper on reordering procedures. Even so, our algorithm can also be used with, and \ncan benefit from, basic block reordering and procedure splitting, as described later in $5. Our research \ndiffers from prior research in procedure reordering because our algorithm uses the cache size, cache \nline size, and the procedure size to perform a color mapping of cache lines to procedures. This color \nmapping allows our algorithm to intelligently place procedures in the layout by preserving color dependencies \nwith a procedure s parents and children in the call graph, resulting in fewer instruction cache conflicts. \nIn this paper we wiU describe our algorithm and demonstrate its merit. through trace-driven cache simula- \ntion. In $2 we describe our color mapping algorithm and compare our algorithm with prior work in code \nreordering. The methodology used to gather our results is described in $3. In 54 we provide quantitative \nresults using our im- proved procedure ordering algorithm. We then discuss im- plications and future \nwork for our algorithm in $5, and we summarize our contributions in $6. Procedure Mapping 2.1 Cache \nColoring Algorithm In this section we describe our procedure mapping algo- rithm. For the following description, \nwe will assume that the instruction cache is direct mapped (in $5 we discuss how to apply our algorithm \nto set-associative caches). The basic idea behind the algorithm is to treat the memory address space \nas two dimensional by breaking up the ad- dress space into pieces that are equivalent to the size of \nthe cache, and using the cache lines occupied by each proce- dure to guide the mapping. In contrast, \nprevious research has treated memory layout as a one dimensional address space. Employing a second dimension \nallows our algorithm to intelligently avoid cache conflicts when mapping a pro- cedure for the first \ntime, and it provides the ability to move procedures that have already been mapped in order to eliminate \nadditional conflicts as they arise. To avoid conflicts, we keep track of the colors each procedure is \nmapped to and a set of colors indicating which colors are currently unavailable to that procedure. We \nwill refer to this set of colors as the onauailob2e-set. For a given procedure, the unavailable-set of \ncolors rep resents the colors occupied (i.e., cache lines used) by all of the immediate parents and children \nof that procedure in the call graph, which have already been mapped to cache lines. Our algorithm uses \na call graph with weighted pro- cedure call edges for indicating the importance of mapping procedures \nnext to each other. The algorithm concen-trates on only eliminating first-generation cache conflicts, \nwhich are the conflicts between a procedure and the im- mediate parents and children of that procedure \nin the call graph. When mapping a procedure, our algorithm tries to avoid cache conflicts by avoiding \ncache line colors in its unavailable-set. Once a procedure has been mapped, a procedure can later be \nmoved to a new location with-out causing cache conflicts, as long as it does not move to a location (color) \nwhich is in its unavailable-set. Using the color mapping to place and move procedures in this way, guarantees \nthat the new location will not increase the number of first-generation conflicts for the procedures in \nthe call graph. One of the hurdles in a mapping algorithm where code is allowed to move after it has \nalready been mapped, is the problem of how to handle the empty space left behind by the moved procedures. \nIf possible, this gap should be filled since the program is laid out in a contiguous memory space. Therefore, \nmoving a procedure should be followed by filling the space left by the procedure with other pro- cedures, \notherwise this can result in a chain of relocations that are hard to manage. Studies of program behaviors \nshow that 10% to 30% of a program accounts for 90% of its execution time [6]. The rest of the code is \nrarely visited or not visited at all. Our al- gorithm takes advantage of this property by dividing each \nprogram into frequently visited (popular) and infrequently visited (unpopular) procedures. The unpopular \nprocedures are treated as fluff or glue, and are used to fill the empty space left behind by moved procedures \nin our algorithm. We will not worry about conflicts when positioning un-popular procedures, since these \nparts of a program do not significantly contribute to the number of first level cache conflicts. We will \nnow describe the details of our cache line coloring algorithm and use an example to demonstrate how to \nlay- out procedures. Figure 1 presents an example caIl graph, containing 7 procedures A through G, where \nnodes repre- sent procedures and the edges represent procedure calIs. Each edge contains a weight indicating \nhow many times that procedure was called. The Figure also contains a ta- ble indicating the number of \ncache lines each procedure occupies. In this example and algorithm description, we assume the instruction \ncache is direct mapped and con-tains only 4 cache lines. Figure 2 shows the steps taken by our algorithm \nin mapping the example call graph given in Figure 1. The cache is divided into a set of colors, one color \nfor each cache line. The four cache lines are given the colors red, green, blue, and yellow. In Figure \n2, the first column shows at each step which edge or procedure is being pro-cessed. The second column \nshows which of the four edge processing cases the current step corresponds to in our al- gorithm. The \nthird column shows the current mapping of the processed procedures and edges over the colored 4 block \n(line) cache space. The last column shows the changes to the unavailable-set of colors for the procedures \nbeing processed at each step. If a procedure spans multi- ple cache lines (as does C in our example), \nit will generate multiple mappable elements (e.g., Cl and C2), as is shown in Figure 2. Our algorithm \nmaintains three important pieces of state for each procedure: the number of cache lines (colors) needed \nto hold the procedure, the cache colors used to map the procedure, and the unavailable-set of colors \nwhich rep resents the cache lines where the procedure should not be mapped to. We do not actually store \nthe unavailable-set of colors. Instead, each procedure contains pointers to its parents and children \nin the call graph. The unavailable-set of colors is then constructed for a procedure as needed by unioning \nall the colors used to map each of the procedure s parents and children. A parent or child is only included \nin this unavailable-set if the edge joining the procedure to the parent or child has already been processed \nin the algorithm. Our algorithm starts by building a procedure call graph, similar to the one shown in \nFigure 1. Every proce- dure in the program is represented by a node in the graph, and each edge between \nnodes represents a procedure call Multiple call sites to the same procedure from a single pro- cedure \nare represented as a single edge in our call graph. The edge values represent the number of times each \nedge (i.e., call path) was traversed. The sum of the edge weights entering and exiting a node indicates \nthe number of incom- ing and outgoing procedure calls and this determines that procedure s popularity. \nAfter the call graph is built, the popularity of each procedure is considered. Based on popularity, the \ngraph is split into the popular procedures and edges and the un- popular procedures and edges. The popular \nprocedure set contains those procedures which are frequently a caller or a callee, and the popular edge \nset contains the frequently executed procedure call edges. The unpopular procedures and edges are those \nnot included in the above two popu- lar sets. Note, there is a difference between popular pro-cedures \nand time consuming procedures (procedures that consume a noticeable portion of a program s overall execu- \nFigure 1: Example call graph. Each node represents a procedure and each edge represents a procedure call. \nThe numbers associated with each edge indicates the number of times the procedure call was executed. \nThe table shows for each procedure how many cache lines is needed to hold the procedure. Steps in Color \nUnavailable- blue H yellow . MaDDing Algorithn Sets (1) E ---) C (100)  W,yL W,gL (2) A ---) B (90) \nI AIYL WW 1 It4blocksd (3) B --) C (80) II color conflict with C when placing D, so leave a space (4) \nC + D (70) Fill Space with (5)  unpopular G procedure A has color conflicts with E, so move A (6) \nA + E (40) AkgL Wwl Fill Space with (7) unpopular F Figure 2: Procedure mapping using cache line coloring. \nThe first column indicates the steps taken in our color mapping algorithm, and each edge and procedure \nprocessed at each step. The second column shows which of the four edge processing cases the current step \ncorresponds to in our algorithm. The third column shows the address space divided into sixes equal to \nthe instruction cache, and shows the mapping of the program at each step. The instruction cache contains \n4 lines labeled: red, green, blue, and yellow. The last column shows the unavailabksets as they are changed \nfor the procedures at each step in the algorithm. tion time). A time consuming procedure may be labeled \nunpopular because it rarely switches control flow to an-other procedure. If a procedure rarely switches \ncontrol flow, it is not as important to eliminate cache conflicts be- tween this procedure and the rest \nof the call graph. In the example in Figure 1, popular procedures are A, B, C, D, and E, and the unpopular \nprocedures are F and G since they are never executed. The popular edges are A + B, B -+ C, C + D, A --t \nE, and E + C, and the unpop- ular edges are E --* F and F -G. The algorithm then sorts the popular edges \nin descending order using the edge weights. The unpopular procedures are sorted by proce- dure size, \nand are used to fill in spaces created by our color mapping. After the program s popularity has been \ndecided, we process all of the popular edges starting with the most frequently executed and ending with \nthe least frequently executed. There are four possible cases when processing an edge in our algorithm. \nThe first case occurs when an edge connects two procedures that have not yet been mapped. In this case, \nthe two procedures are merged into a com-poundnode. The two procedures are placed next to each other \nin the layout and they are assigned cache line col- ors starting at an arbitrary color (position). Each \npro-cedure is assigned the number of cache line colors equal to (procedure s size in bytes)/(coche line \nsize in bytes). After the colors have been assigned, the unavailable-set for each procedure includes \nthe colors (cache lines) used by the other procedure at the other end of the call edge. The remaining \nthree cases encountered when processing an edge include: when the call edge links two procedures in two \ndifferent compound nodes, when the edge is between an unprocessed procedure and a procedure in a compound \nnode, and when the edge being processed is a call between two procedures in the same compound node. The \nfollow- ing four paragraphs discuss the details for the four edge processing cases in the algorithm. \nCase I: The first case, when an edge connects two un-mapped procedures, is shown in the first two steps \nof Fig- ure 2. The algorithm starts with the heaviest edge (most heavily traversed) in the call graph \ns set of popular edges, E -+ C, and forms a compound node E -C. This com-pound node is arbitrarily mapped \nto the cache line colors. The unavailable-set of colors for E now includes blue and yellow (the colors \nC maps to) and the unavailable-set for C now includes red and green (the colors E maps to). The second \nstep in Figure 2 processes the edge A + B between two unmapped procedures. The two procedures are com- \nbined into a compound node, and their unavailable-sets are shown in the Figure. Note that the unavailable-set \nfor A does not include colors red and green, even though there is an edge A --+ E in the call graph and \nnode E is mapped to the colors red and green. This is because the procedure s unavailable-set only includes \nparent and children proce-dures connected by edges that have been processed, and the edge A -E has not \nyet been processed. We chose this restriction since the unavailable-set of colors is used to restrict \nwhere to place procedures, and when placing a procedure, the procedure should only be restricted by the \nedges with the heaviest (most important) weights. Case II: The second case occurs when the edge be-ing \nprocessed connects two procedures in different com-pound nodes. For this case, the two compound nodes \nare merged together, concatenating the compound node that is shorter in length (number of procedures) \nto the larger compound node. This is shown in step 3 of Figure 2 for edge B + C, which combines two compound \nnodes E -C and A -B. The compound nodes both contain the same number of procedures, so we arbitrarily \nchoose A -B to be the smaller compound node. Our algorithm now de-cides where to map, and how to order, \nA -B since there are four possibilities: A -B -E -C, B -A -E -G, E -C -A -B and E -C -B -A. The first \ndecision to make is on which side of compound node E -C should A -B be placed. This is decided by taking \nthe shortest (distance lo proc in compound node) mod (cache size). For our example, the distance to C \nis used and is calculated to be the distance in the number of cache line colors from the middle of procedure \nC to each end of the compound node. From the mapping in step 1 of Figure 2, this distance is 1 cache \nline to the right of C in the compound node E-C and 3 cache lines to the left of C in compound node E-C. \nTherefore the algorithm decides to place A-B to the right of E -C. The (distance lo procedure) mod (cache \nsize) heuristic is used to increase the probability of being able to easily map the 2nd compound node \nto non-conflicting cache colors. Note, that placing A -B to the right of E -C produces a mapping where \nno cache conllicts oc-cur, whereas if we would had chosen to put A -B on the left side of E -C this would \nhave caused a cache coloring conflict. The next decision our algorithm makes is which order to place \nA-B, either E-C-A-B or E-C-B-A. This is decided by choosing the ordering so the two proce- dures connected \nby the edge being processed (i.e., B -+ C) are closest to each other in the program layout. Thus we arrive \nat a mapping of E -C -B -A. After this is de- cided, the algorithm makes sure that the two nodes for \nthe edge being processed, B and C, have no cache lines that conflict. This is done by comparing the colors \nused by C with the colors used by B. If there is a conflict, the smaller compound node is shifted away \nfrom the larger compound node until there is no longer a conflict. The space left in the mapping will \nbe filled with unpopular procedures. If a conflict cannot be avoided then the original location (placing \nB adjacent to C) is used. When the final po-sition for the smaller compound node is determined, the algorithm \ngoes through each procedure and updates the colors (cache lines) used by each procedure. Notice that \nthis changes the unavailable-set of colors: A s set of un-available colors changes to red and B s changes \nto green, blue and yellow. Case III: The third type of edge connects an un-mapped procedure and a procedure \nin a compound node. We process this case similarly to case II as described in the previous paragraph. \nIn this situation, the un-mapped procedure is placed on either end of the com-pound node, which side \nis decided by using the shortest (distance to procedure) mod (cache size) heuristic as de- scribed above. \nOnce a side is chosen, the cache line colors used by the newly mapped procedure are checked against the \ncolors used by its corresponding procedure in the com- pound node. If there is a conflict, space is inserted \nin the address space between the newly mapped procedure and the compound node until the newly mapped \nprocedure can be assigned colors which do not conflict. If this is not pos- sible, the procedure is left \nat its original position, adjacent to the compound node. Step 4 in Figure 2 shows this sce- nario. The \nalgorithm next processes edge C + D, where C is contained in a compound node and D has not yet been mapped. \nThe algorithm first decides on which side of the compound node to place D. Since both of the distances \nto the middle of C are the same (3 cache lines), the algorithm arbitrarily chooses a aide and D is placed \nto the left of the compound node. The colors used for D at this location are blue and yellow. This would \ncreate a conflict since those colors overlap with the colors used by C. Therefore the algorithm shifts \nD to the left until it finds a suitable location (if possible) where D no longer conflicts with C. This \nlocation for D is found at the colors red and green. This leaves a space in the compound node, as shown \nin step 4. If a space is created inside of a compound node, the space is filled with the largest unpopular \nprocedure which will fit. This is shown in step 5 of Figure 2, where the space created by shifting D \nis filled with the unpopular procedure G. Case IV: The fourth and final case to handle occurs when the \nedge being processed has both procedures be-longing to the same compound node. This is a very im- portant \ncase since the algorithm finally gets to use the unavailable-set to avoid cache conflicts. If the colors \nused by the two procedures of the edge overlap (conflict), then the procedure closest (in terms of cache \nlines) to either end of the compound node is moved past the end of the com- pound node, creating a space \nor gap in the compound node where it use to be located. This space will later be filled by an unpopular \nprocedure or procedures. The unavailable-set for the procedure that is moved past the end of the compound \nnode is updated to include the colors of the corresponding procedure left inside the compound node. The \nalgorithm then checks to see if the current colors used by the procedure conflict with any of its unavailable \ncol- ors. If there is a conflict, the procedure is shifted away from the compound node in the address \nspace until there is no longer a conflict with its unavailable-set of colors. If we are unable to find \na non-conflicting location for the procedure, the original location inside the compound node is used. \nThis final scenario is shown in step 6 in Figure 2, where the edge from A -+ E is processed and its two \npro- cedures are in the same compound node. In examining the colors used by both A and E, we see that \nthe two proce- dures colors conflict since they map to the same cache line (green). The algorithm tries \nto eliminate this conflict by choosing to move A, since it is the closest to an end of the compound node. \nThe algorithm moves A past the end of the compound node, mapping it to the color blue. When checking \nA s new mapping against its unavailable-set (red and green), no conflicts are found, so this is an acceptable \nlocation for procedure A. Using the unavailable-set in this way guarantees that previous mappings for \nA take prece- dence over the edge A -E, because those mappings were more important. Finally, since A \nwas moved in step 6, it created a space in the compound node, as shown in Fig- ure 2. After any space \nis made inside of a compound node, that gap is filled with a procedure(s) from the unpopular list. In \nour example, the remaining procedure F is used to fill the gap. We then arrive at the final mapping as \nshown in step 7, which has no first-generation cache conflicts. This process is repeated, until all of \nthe edges in the popular set have been processed. Any remaining proce-dures in the unpopular list are \nmapped using a simple depth-first traversal of the unpopular edges that join these unpopular procedures. \nThe final mapping can result in several disjoint compound nodes. These nodes are then ordered in the \nfinal layout, from the most frequently exe-cuted to the least frequently executed. 2.2 Comparison to \nPrevious Work There has been considerable work in the area of profile- driven program optimizations \nand procedure reordering. We now discuss relevant previous work and how it relates to our algorithm. \n2.2.1 Knowledge of Cache Size McFarling examined improving instruction cache perfor-mance by not caching \ninfrequently used instructions and by performing code reordering compiler optirnizations [ll]. His mapping \nalgorithm works at the basic block level and concentrates on laying out the code based on loop struc-tures \nin the program. The algorithm constructs a control flow graph with basic block, procedure, and loop nodes. \nIt then tries to partition the graph, concentrating on the loop nodes, so that the height of each partitioned \ntree (i.e., graph) is less than the size of the cache. If this is the case, then all of the nodes inside \nof the tree can be trivially mapped since they will not interfere with each other in the cache. If this \nis not the case, then some nodes in the mapping might conflict with others in the cache. The notion of \nwanting the mapped tree size smaller than the cache size also applies to our algorithm when we partition \nthe crdl graph into popular and unpopular proce-dures and edges. Partitioning the the call graph actually \nsplits the graph into several disjoint subgraphs comprised of the popular procedures and edges. This \nhas the effect of breaking the call graph into smaller, and more man-ageable, pieces. If the sum of all \nthe procedure sizes in a subgraph is smaller than the size of the instruction cache, then there will \nbe no conflicting colors when laying out all of the procedures in the subgraph and the mapping can be \ndone trivially as suggested by McFarling. The benefit of our algorithm over McFarling s is that instead \nof just taking into consideration the cache size we also take into consideration the exact cache lines \nused by each procedure in the mapping. This allows our algorithm to effectively eliminate first-generation \ncache conflicts, even when the popular subgraph size is larger than the instruction cache, by using the \ncolor mapping and the unavailable-set of col- ors. Torrellas, Xia and Daigle [20] (TXD) also described \nan algorithm for code layout for operating system inten-sive workloads. Their work takes into consideration \nthe size of the cache and the popularity of code. Their algo-rithm partitions the operating system code \ninto executed and non-executed parts at the basic block level. It then repeatedly creates sequences of \nbasic blocks from the ex- ecuted code. All the basic blocks with weights above a threshold value are \nremoved from the graph and put into a sequence, which is a list of basic blocks. All the basic blocks \nin a sequence are then layed out together in the ad- dress space. The threshold value is then lowered \nand the process is repeated until all the executed basic blocks have I - cache size ,I (4 blocks)  Figure \n3: Procedure mapping for a greedy depth-first traversal of the call graph. been put into sequences. Their \nalgorithm takes into con-sideration the cache size by mapping the most frequently executed sequence into \na special area in the cache. The rest of the sequences are then mapped to areas in the cache, avoiding \nthis special area. This creates gaps in the pro- gram layout which are then tilled by the non-executed \nba-sic blocks. The TXD algorithm is designed for mapping operating system code to increase performance, \nby keep- ing commonly used system code in the cache. Our algo- rithm is designed for application code \nand tries to eliminate as many first-generation conflicts as possible. These two goals are different \nand may require the use of different algo- rithms. The techniques used by TXD, which work well for operating \nsystem code, may not work as well to eliminate first-generation cache conflicts in application code. \nAs described in $2.1, our algorithm uses unpopular pro- cedures in a manner similar to how TXD uses non-executed \noperating system basic blocks. We use the unpopular code in an application to fill in spaces created \nwhen mapping procedures. The two approaches differ in that our algo-rithm uses the unpopular procedures \nto try to eliminate cache conflicts for all popular procedures by performing a color mapping that gives \npriority to the procedures that switch control flow most often. In comparison, TXD uses the non-executed \ncode to eliminate cache conflicts for only some of the popular basic blocks: the most frequently ex-ecuted \nsequence(s). Keeping track of the colors used by each procedure, and using the unavailable-set and unpop \nular procedures to eliminate as many conflicts as possible, makes our algorithm more general for eliminating \nfirst-generation conflicts. Another technique used by TXD, which works well for operating system code, \nbut may not work as well for appli- cation code, is recursively breaking up the basic blocks into sequences \nusing a threshold value. This technique does not take into consideration the connectivity of the basic \nblocks in the sequence. Therefore a sequence could be layed out together in the address space, with the \nbasic blocks having little or no temporal locality, and the basic blocks in one sequence could cause \nconflict misses with basic blocks in another sequence. For application code, our coloring algo- rithm \noffers better performance over a recursive threshold partitioning algorithm since we take into consideration \nthe connectivity of the graph. 2.2.2 Procedure Mapping Hwu and Chang described an algorithm for improving \nin- struction cache performance using inlining, basic block reordering, and procedure reordering compiler \noptimiza-tions [9]. Their algorithm builds a call graph with weighted call edges produced by profiling. \nFor the procedure re-ordering, their algorithm processes the call graph depth first, mapping the procedures \nto the address space in depth first order. Their depth-first traversal is guided by the edge weights \ndetermined by the profile, where a heavier edge is traversed (layed out) before an infrequently exe-cuted \nedge. In using the call graph shown in Figure 1, a depth-first traversal following the most frequently \nexe-cuted edges would traverse the edges in order of A -B, B + C, C + D, A + E, E + C, E + F, and F + \nG. Figure 3 represents the final mapping achieved by their algorithm. The drawback of this approach occurs \nwhen the depth-first traversal follows an unimportant path in the control flow graph, which will then \nlay out unpopular procedures before considering procedures on a more impor- tant path. This is seen in \nFigure 1 where their algorithm processes the edge C + D before the edge E + C. This can create significant \nfirst-generation cache conflicts in the calI graph, as seen by the conflict between procedures E and \nC in Figure 3. Pettis and Hansen [12]also described a number of tech- niques for improving code layout \nthat include: basic block reordering, procedure splitting, and procedure reordering. Their algorithm \nemploys a closest-is-best strategy to per- form procedure reordering. The reordering starts with the \nheaviest executed call edge in the program call graph. The two nodes connected by the heaviest edge will \nbe placed next to each other in the final link order. This is taken care of by merging the two nodes \ninto a chain. The remaining edges entering and exiting the chain node are coalesced. This process continues \nuntil the whole call graph is merged into chains which can no longer be merged. Figure 4 shows the key \npoints of the Pettis and Hansen [12] procedure mapping algorithm when processing the call graph in Fig- \nure 1. Their algorithm starts by processing edge E + C, merging nodes E and C into a chain E-C. This \nis followed by edge A + B, where A and B are merged into a chain A -B. The next edge to be processed \nis B + C. This brings the algorithm to the first point shown in Figure 4, which is how to merge the chains \nE -C and A-B. At this point their algorithm uses a closest-is-best heuristic, and chooses to place procedure \nB next to C, since the edge B + C has a stronger weight than A -+ E. The next edge to be processed is \nC + D. This means procedure D needs to be placed at the front or end of chain E -C -B -A. Figure 4 shows \nthat, no matter which side of the chain D is placed, a first-generation cache conflict will occur with \n Important points of decision in the Pettis and Hansen algorithm Chain E-C is placed next to B-A, since \nC-B satisfy the closest is best strategy (l)d@LC How to merge chains I I I I E-C and B-A? Where to add \n Figure 4: Procedure mapping for the Pettis and Hansen greedy algorithm. C. This illustrates the main \ndrawback of their approach, which is that the algorithm fails to monitor the chain size. Therefore, once \na chain becomes larger than the size of the instruction cache, the effectiveness of their closest-is-best \nstrategy and node merging strategy, decreases. In looking at the final mapping in Figure 4, we see that \nthe mapping has first-generation conflicts between procedures A and E, and procedures C and D. Our algorithm \nimproves on the Hwu and Chang and the Pettis and Hansen procedure reordering algorithms by keeping track \nof the cache lines (colors) used by each mapped procedure when performing the procedure map ping. This \nallows us to effectively map procedures, elimi-nating cache conflicts when the compound node size grows \nlarger than the instruction cache. Neither of their algo- rithms take into consideration the attributes \nof the cache, such as cache size, line size, and associativity. They also do not consider leaving spaces \nin their layout, which can be used to reduce the number of cache conflicts. As shown in Figure 2, when \nusing our color mapping algorithm, no first- generation cache conflicts occur for the call graph shown \nin Figure 1. In comparison, Figure 3 and Figure 4 show that both the Hwu and Chang and the Pettis and \nHansen algorithms suffer from first-generation cache conflicts for the reasons discussed above. 3 Methodology \nTo evaluate the performance of our algorithm, we modified gee version 2.7.2 to use our new procedure \nmapping rdgo- rithm when linking an application. This has restricted the type of applications we can \nexamine in this study to programs that can be compiled with gee. Therefore, the programs we examined \nare from the SPECInt95 suite, SPECInt92 suite, and three gnu applications. We used trace driven simulation \nto quantify the in- struction cache performance of our algorithm [lo]. The trace driven simulations were \nobtained using ATOM, an execution-driven simulation tool available from Digital Equipment Corporation \n[18]. ATOM allows instrumenta- tion of binaries on DEC Alpha processors and can produce the necessary \ninformation about the frequency of proce- dure calls, procedure sizes, and the program s control flow \ngraph. In our simulations we model a direct-mapped 8 kilobyte instruction cache with a 32 byte line size, \nsimilar to the size used for the DEC Alpha 21064 and DEC Alpha 21164 first-level instruction cache. Therefore, \nin our color mapping, the number of colors is equal to 256, which is equal to the number of direct mapped \ncache lines. Table 1 describes the static and dynamic attributes for the programs we studied. The first \ncolumn contains the program name, and the second column shows the input used to profile each program. \nThe third column shows the number of instructions traced for the input used. The fourth column shows \nthe size of each program in kilobytes, and the fifth column shows the number of static proce-dures in \nthe program. The next two columns show results for the popular procedures in the program as determined \nby our color mapping algorithm described in $2.1. The sixth column shows the percentage of the program \nthat contains only the popular procedures, and the seventh col- umn shows the percentage of static procedures \nwhich are considered popular. The final column shows the percent- age of the program which were unpopular \nprocedures used as filler to fill in spaces created in the color mapping (as de- scribed in $2.1). We \nused profile information to guide the partitioning of the program into popular and unpopular Table 1: \nMeasured attributes of traced programs. The input is used to both protile the program and gather performance \nresults. The attributes include the number of instructions traced when simulating the program, the executable \nsize of the program, and the number of static procedures in the program. Also shown is the percentage \nof the executable and the percentage of static procedures that the popular procedures account for after \npartitioning the program into popular and unpopular procedures when using the color mapping algorithm. \nThe last column shows the percentage of unpopular procedures in terms of the size of the executable that \nwere used a8 fluff (to fill in spaces) in the color mapping algorithm. parts. All the procedures and \nedges that account for less than 1% of the switches in control flow in the call graph are labeled as \nunpopular. We can see that by splitting each program into popular and unpopular sets, that the popular \nprocedures make up only 3% to 12% of the static executable size, and thii accounts for 4% to 21% of the \nstatic procedures in the program. Mapping these proce- dures correctly will eliminate most of the cache \nconflicts in the application for the inputs we examined. Results To evaluate the performance of our color \nmapping algo-rithm we also implemented the Pettis and Hansen alge rithm described in Section 52.2. Table \n2 shows the in- struction cache miss rates for the original program, the Pettis and Hansen algorithm, \nand our cache coloring al-gorithm. For the results shown, the same input used in Table 1 was used for \nboth profiling the program and gath- ering the results. The second column provides the cache miss ratio \nfor the Original program using the standard link order for the benchmark executables as specified in \nthe makefile provided with the programs. The next col- umn indicates the cache miss ratio after applying \nthe Pettis and Hansen (P&#38;q algorithm. The fourth column, labeled Color, refers to the new link order \nproduced by our cache color mapping algorithm. The next two columns show the percent reduction in the \ncache miss rate when using our algorithm in comparison to the original mapping and the P&#38;H mapping. \nThe last three columns show the number of instruction cache misses for tp original program, P&#38;H layout, \nand our color mapping. As seen in Table 2, when using the color mapping al-gorithm the miss rate of the \noriginal program is decreased on average by 37%, with reductions as high as 99% for gzip. In comparison \nto the P&#38;H algorithm our color map ping reduces the miss rate on average by 14%. The Table shows \nthat in comparison to P&#38;H our algorithm provides a substantial reduction in the cache miss rate for \nthe 4 pro- grams m88ksim, espresso, eqntott, and bison, provides a smaller improvement for per&#38; and \nhas approximately the same instruction cache miss ratio for li, flex, and gzip. Only averages are shown \nfor the miss rate columns, since the averages for the other columns in the table are not meaningful. \nOur algorithm performs better for programs like u88ksin, espresso, and bison because the size of the \npop ular call graph for these applications is larger than the size of the instruction cache. Thii allows \nour algorithm to fully exploit cache line coloring, arriving at a layout that significantly reduces the \nnumber of first-generation cache conflicts. For programs such as flex and gzip, the reason why our algorithm \nand the P&#38;H algorithm have approximately the same miss rate can be seen by looking at the parti- \ntioning part of our algorithm. Here, the program is parti- tioned into popular and unpopular procedures \nand edges. In performing this partitioning, these programs are split into disjoint subgraphs where most \nof the subgraphs are smaller than the size of the cache. Since these popular subgraphs easily fit within \nthe instruction cache, we can arbitrarily map their procedures. For example, gzip vis-its only a small \nnumber of very popular procedures when processing the input file gee-2.7.2.tax. This is seen in Table \n1, where the size of the popular procedures for gzip amount to only 10K (3% of the total executable sise), \nand the simulated instruction cache size we used is 8K. For ap plications where the popular subgraphs \nfit within the size of the instruction cache, our color mapping algorithm and the Pet&#38; and Hansen \nalgorithm will have similar perfor- mance. Table 2 shows that for eqntott, the instruction cache miss \nrate when applying the P&#38;H mapping is larger than the miss rate of the original mapping. This effect \noccurs for two reasons. One reason is the poor choice made by the P&#38;H algorithm when merging chains \nthat sum to a size larger than the instruction cache, creating cache con-flicts within the newly merged \nchain. The second resson is that both our algorithm and the P&#38;H algorithm only model first-generation \nconflicts in the call graphs. The call graph used in this study only models the frequency of procedure \ncalls between a procedure and its direct chil- dren. It does not model the temporal locality between \na procedure and aJl of the procedures that it can possibly reach in the call graph, and any of these \nreachable proce- dures can cause cache conflicts. This emphasizes the fact that finding an optimal mapping \nto minimize conflicts is NP-complete [ll]. In the next section we suggest further Average 1.9% 1 1.4% \nI 1.2% 11 I I I I-Cache Miss Rate Miss Rate Reduction Over # Instruction Cache Misses Program 0 * * \nngnal P&#38;H Color Orrgmal P&#38;H Orlgld P&#38;H Color li 1.4% 0.3% 0.3% 79% 0% 97,127,676 23,786,704 \n19,943,570 m88ksim 3.0% 1.7% 1.4% 53% 18% 838.249.456 475.008.025 391.183.079 Table 2: Instruction cache \nperformance for the Original mapping, Pettis and Hansen (P&#38;H) mapping, and our Color mapping algorithm. \nThe first three column shows the instruction cache miss rates. The next two columns show the percent \nreduction in the miss rates when using our Color mapping algorithm in comparison to the Original and \nP&#38;H procedure mapping. The last three columns show the number of instruction cache misses. Program \n- h m88ksim per1 espresso Table 3: Instruction cache performance using multiple inputs for the Original \nmapping, Pettis and Hansen (P&#38;H) mapping, and our Color mapping algorithm. In calculating the overall \naverage, a value for espresso is included only once, which is the average miss rate for espresso on all \nof the inputs shown. 4 0.0 05  8: i0.7 a s 0 25 p 0.6 9 Ii 2 p:: lb 0.3 1 ! I -03 0.6 0.1 0 0 \nIi mSSkaim ms Figure 5: Instructions issued per cycle for a single issue Figure 6: Instructions issued \nper cycle for a 4way is-architecture, with an 8K direct mapped instruction cache sue processor with an \n8K direct mapped instruction cache which has a 5 cycle cache miss penalty. which has a 10 cycle cache \nmiss penalty. optimizations to our algorithm in order to address misses beyond first-generation cache \nconflicts. The results in Table 2 are all gathered using the same input that was also used to profile \nthe program. An im- portant issue involving profiled-based optimizations is how well does a single input \ncapture the typical behavior of fu- ture runs of the program. Several researchers have inves- tigated \nthis problem and have found that programs have predictable behavior between different inputs [5, 8, 211. \nEven so, care must be taken when choosing the inputs to guide optimizations. In this vein, we took the \noptimized programs used to produce the results in Table 2 and ran them using different inputs. Table \n3 shows the cache miss rates for these programs using different inputs. For these different inputs, the \nresults show that the miss rate was reduce by 43% when comparing our color mapping algo- rithm to the \noriginal layout, and the reduction in miss rate for our algorithm when compared to P&#38;H was 20% on \naverage. In general, when examining different inputs our algorithm shows significant reductions in the \noriginal instruction cache miss ratios, while consistently showing an advantage over P&#38;H. To examine \nthe impact procedure reordering optimiza- tions have on the performance of these programs, Figures 5 \nand 6 show the estimated performance in instructions is-sued per cycle (IPC) for the original program, \nP&#38;H map ping, and our color algorithm for two different architec-tures. The higher the IPC the better. \nFor these results we assume each instruction takes one cycle to execute, and that the only pipeline stalls \nare due to misses in the in- struction cache. Figure 5 shows an estimate of perfor-mance using a single \nissue architecture with a small (5 cycle) first-level instruction cache miss penalty. Figure 6 shows \nan aggressive 4-way issue architecture with a larger (10 cycle) first-level instruction cache miss penalty. \nThe results in Figure 5 show that for a conservative architecture our color mapping algorithm increases \nthe IPC on average by 5% when compared to the original mapping, and by 1% when compared to P&#38;H. The \nresults in Figure 6 show that for a more aggressive architecture that our color mapping algorithm increases \nthe IPC on average by 26% when com- pared to the original mapping, and by 6% when compared to P&#38;H. \nOne issue to consider with our algorithm is that in or- der to avoid first-generation cache conflicts \nour color map ping will insert space into compound nodes as described in $2.1. This space is later filled \nwith unpopular proce-dures. This could possibly have two adverse effects. The first is, if no unpopular \nprocedure can be found when try- ing to fill a space, then this could result in an increase in the executable \nsize. For the programs we examined this was never an issue. Az seen in Table 1, on average only 8% of \nthe procedures were labeled as popular, leaving more than enough unpopular procedures to fill in any \ngaps that were created by the color mapping algorithm. The second effect is that the size of the working \nset of pages for the program may increase due to the algorithm filling spaces in the compound nodes with \nunpopular procedures. From our results we do not believe this will be an issue, but fur- ther investigation \nis needed. When performing the color mapping for the programs we examined, on average only 3K worth of \nunpopular procedures were used as filler and inserted into the popular color mapping, as seen in Table \n1. Since the average size for all of the popular procedures in a program was 33K, this increases the \nsize of the popular mapping section of the address space by only 8%. 5 Discussion and Future Work In \nthis section we discuss how to apply our color map ping algorithm to associative caches, describe how \nour al- gorithm can benefit from basic block reordering and proce- dure splitting, and describe future \nwork on how to improve the performance of our algorithm by using more informa-tion on temporal locality \nto guide the mapping. 5.1 Color Mapping for Associative Caches In this paper we only described our algorithm \nas ap plied to direct mapped caches and examined its perfor- mance for an 8K direct mapped instruction \ncache. Our algorithm can easily be applied to set-associative instruc-tion caches. To accomplish this, \nwe treat the associativ- ity of the cache as another dimension in the mapping of the address space. For \nassociative caches our algorithm breaks up the address space into chunks, equal in size to (the num6er \nof cache sets * the cache line size). There-fore, the number of sets represents the number of available \ncolors in the mapping. The color mapping algorithm can then be applied as described in $2.1, with only \na few minor changes. The algorithm changes slightly to keep track of the number of times each color (set) \nappears in the pro cedure s unavailable-set of colors. Therefore, mapping a procedure to a color (set) \ndoes not cause any conflicts as long as the number of times that color (set) appears in the unavailable-set \nof colors is less than the degree of associa- tivity of the cache. This effectively turns the unavailable- \nset into a multiset, which allows each color to appear in the set up to the associativity of the cache. \n5.2 Color Mapping with Basic Block Re-ordering and Procedure Splitting The results in $4 do not show \nthe full potential of our col- oring algorithm, since our algorithm can benefit from other code reordering \ntechniques such as basic block reordering and procedure splitting [9, 121. Our color mapping algo-rithm \ncan benefit from basic block reordering because once the basic blocks have been aligned and condensed \ninto the first part of the procedure, the cache line colors used by the frequently executed basic blocks \nare the only colors we have to worry about when performing the procedure map ping. Using basic block \nprofiling, each procedure would contain two sets of cache colors: those for the important portions of \nthe procedure, and those for the unimportant. Then the only basic blocks we need to worry about in the \nunavailable-set of colors are the important basic blocks Performing procedure splitting can also be used \nto im- prove the performance of our color mapping algorithm. This can be achieved by performing procedure \nsplitting to help reduce the coloring constraints between different procedures. For example, if half \nof a procedure X, Xl, calls a procedure Y, and the other half of the procedure X, X2, calls procedure \n2, then finding a location for X in the color mapping as described iu 92.1 will have to try to avoid \nthe colors used by both Y and Z. If procedure splitting is performed so that X is split into two separate \nprocedures X1 and X2, then this can help reduce the col- oring constraints on X. After procedure X is \nsplit into Xl and X2, the color mapping for Xl only needs to avoid colors used by X2 and E , and the \ncolor mapping for X2 needs to only avoid colors used by Xl and Z. This can help free up coloring constraints \nfor very large procedures and procedures that have a significant number of different call destinations. \n One could even extend the algorithm to perform the mapping and cache line coloring at the basic block \nlevel instead of the procedure level, and this is a topic of future research. 5.3 Using Improved Temporal \nLocality Data Our color mapping algorithm, as described in $2.1, concen- trates on eliminating conflicts \nbetween edges in the con-trol flow graph. For our results, these edges happen to be first-generation \ncache conflicts because the graph edges represent the call edges between a procedure and its di- rect \nparents and children. Our algorithm can easily be applied to more detailed forms of profile and trace \ninfor- mation by adding extra edges between procedures, treating these edges as a second set of constraint \nedges in the color mapping algorithm. These additional edges, with the ap- propriate weights, can then \nbe used in the unavailable-set of colors in order to further eliminate cache conflicts. The call graph \nand profiles we used to guide the map pings do not provide enough information to determine the temporal \nlocality for a depth greater than one proce- dure call (first-generation) in the graph. Even for first- \ngeneration misses, a call graph does not provide exact information about temporal locality. Therefore, \nour al-gorithm tries to remove the worse case number of first- generation misses. For example, in Figure \n1, we know that since the edge C + D was executed 70 times, that if C and D had overlapping cache lines, \nthen the call to D and the return to C could in the worst case cause ((70 + 70) * number of overlapping \ncache lines) misses. For future work, we will use control flow analysis of the program s structure to \nindicate if all the calls from C + D were done during one invocation of C or whether they were spread \nout over several invocations, similar to the control flow analysis used by McFarling [II]. We will also \nuse control flow analysis to determine how much of procedure C can actually overlap with procedure D \nfor each proce- dure call, so we only have to include those cache lines in D s unavailable-set of colors. \nThis will help provide more accurate temporal locality information for first-generation conflicts, but \nit does not provide the additional temporal locality information we would like for deeper paths in the \ncall graph. When profiling just the call edges, there is no way to get a good indication of temporal \nlocality for a path longer than one procedure call edge. For example, in Figure 1 we have no way of knowing \nfor the call edge C + D how many of the procedure calls to D came down the path through procedure B and \nhow many went through procedure E, nor do we know how much temporal locality there is be- tween B and \nD or E and D. Some of this information can be obtained by using fuIl path profiling, which would allow \none to know the frequency of each path [I, 221, al- though full path profiling still does not provide \noptimal temporal locality information. One way to obtain addi-tional information on temporal locality \nis to store the fuII trace of a program. Capturing, storing, and processing a full trace can be very \ntime and space consuming, but effi- cient techniques have been proposed to capture and pro- cess this \ninformation in a compact form, such as the gap model proposed by Quong [I5]. We plan on investigating \nthe use of full path profiling and the gap model with our color mapping algorithm in order to eliminate \nadditional cache conflicts for deeper paths in the call graph. 6 Conclusions The performance of the cache-based \nmemory system is crit- ical in today s processors. Research has shown that com-piler optimizations can \nsignificantly reduce this latency, and every opportunity should be taken by the compiler to do so. The \ncontribution of this paper is a new algorithm for procedure mapping which takes into consideration the \ncaIl graph, procedure size, cache size, and cache line size. An improved algorithm is achieved by keeping \ntrack of the cache lines (colors) used by each procedure as it is mapped, in order to avoid cache conflicts. \nThis color mapping al-lows our algorithm to intelligently place unmapped proce-dures, and to efficiently \nmove a procedure that has already been mapped, by preserving prior color dependencies with that procedure \ns parents and children in the call graph. This provides our main advantage over prior work, in that we \ncan accurately map procedures in a popular call graph even if the size of the graph is larger than the \nsize of the in- struction cache. This ability is very important, especially for applications which have \nlarge and complicated control flow graphs, which result in large instruction cache miss rates due to \nconflict misses. Another advantage of our al- gorithm is that we leave gaps in the layout which are filled \nby unpopular procedures, in order to reduce the number of cache conflicts. Our results show that we were \nable to reduce the cache miss rate on average by 40% over the original procedure mapping. In comparison \nto prior work, our algorithm reduced the cache miss rate on average 17% below that of the Pettis and \nHansen algorithm [12]. In this study we concentrated on applying our color mapping algorithm to procedure \nreordering. Our algo-rithm can be combined and benefit from other code re-ordering techniques such as \nbasic block reordering, taking into consideration looping structures, and procedure spbt- ting. These \nare topics of future research, along with ap-plying our algorithm to object oriented languages [6, 1 \n71. In this paper we also concentrated on the performance achieved using call edge profiles to guide \nthe optimizations in order to eliminate first-generation cache conflicts. We are currently investigating \nhow to apply our algorithm to use full path profiling and other trace collection techniques in order \nto collect improved temporal locality information. We are also currently examining how to apply our color \nmapping algorithm to statically formed call graphs using static program estimation. Acknowledgments We \nwould like to thank Amitabh Srivastava and Alan Eu- state for providing ATOM, which greatly simplified \nour work, and Jeffrey Dean, Alan Eustace, Nick Gloy, Waleed Meleis, Russell Quong, and the anonymous \nreviewers for providing useful suggestions and comments on this paper. Brad Calder was supported by Digital \nEquipment Corpo- ration s Western Research Lab. David Kaeli was supported by an NSF CAREER Program award \nNo. 9501172. Amir Hooshang Hashemi is currently at I-Kinetics, 17 New Eng- land Executive Park, Burlington, \nMA 01803. References (11 T. Ball and J. Larus. Efficient path profiling. In 29th International Symposium \non Microarchiteclure, December 1996. [2] L. BeIady. A study of replacement algorithms for a virtual- \nstorage computer. IBM Sysfems Journal, 5(2):78-101, 1966. [3] B.N. Be&#38;ad, D. Lee, T.H, Romer, and \nJ.B. Chen. Avoid- ing conflict misses dynamically in large direct-mapped caches. In Siz International \nConference on Archiiectural Suppori for Programming Languagea and Operating Sys-tems, pages 158-170, \nOctober 1994. [4] 8. Calder and D. Grunwald. Reducing branch costs via branch alignment. In Siz Zn2ernafional \nConference on Ar-chiteciural Support for Programming Languages and Op- erating Sgsfems, pages 242-251. \nACM, 1994. [S] B. Calder, D. Grunwald, and A. Srivastava. The pre-dictability of branches in libraries. \nIn 28th International Symposiam on Microarchitecture, pages 24-34, Ann Arbor, MI, November 1995. IEEE. \n[6] 8. Calder, D. GrunwaId, and B. Zorn. Quantifying behav-ioral differences between C and C++ programs. \nJournal of Programming Languages, 2(4), 1994. [7] P.J. Denning and S. C. Schwartz. Properties of the \nworking-set model. Communicaliona of the ACM, 15(3):191-198, March 1972. (81 J. A. Fisher and S. M. Freudenberger. \nPredicting con-ditional branch directions from previous runs of a pro- gram. In Proceedings of the Fifth \nInternational Conference on Archilectural Supporl for Programming Languages and Operating Systems (ASPLOS-V), \npages 85-95, Boston, Mass., October 1992. ACM. [S] W.W. Hwu and P.P. Chang. Achieving high instruction \ncache performance with an optimizing compiler. In 16th Annual International Symposium on Computer Architec-ture, \npages 242-251 ACM, 1989. [lo] D. Kaeli. Iasues in Trace-Driven Simulaiion. Lecture Notes in Computer \nScience No. 729, Performance Eval-uation of Computer and Communication Systems,L. Do-natielloand R. Nelson \neds., Springer-Verlag, 1993, pp. 224- 244., 1996. (111 S. McFarling. Program optimization for instruction \ncaches. In Proceedings of the Third International Conference on Architectural Sspporf jot Programming \nLanguages and Operating Systems (ASPLOS III), pages 183-191, April 1989. [12] K. Pettis and R.C. Hansen. \nProfile guided code position- ing. In Proceedings of the ACM SIGPLAN 90 Conference on Programming Language \nDesign and Implementalion, pages 16-27. ACM, ACM, June 1990. [13] S.A. Przybylski. Cache Design: A Performance-Directed \nApproach. Morgan Kaufmann, San Mateo, CA, 1990. [14] T.R. Puzak. Analysis of cache replacement-algorithms. \nPh.D. Dissertation, University of Massachusetts, Amherst MA, 1985. R.W. Quong. Expected I-cache miss \nrates via the gap model. In 2lst Annual International Symposium on Com-puter Architecture, pages 372-383, \nApril 1994. [I51 A.D. Samples and P.N. Hilfinger. Code reorganization for instructioncaches. Techical \nReport UCB/CSD 88/447, Oc- tober 1988. WI A. Sampoga. Architectural Implicalions of C and C+S Programming \nModels. MS Thesis, Northeastern University, August 1995. P71 A. Srivastava and A. Eustace. ATOM: A system \nfor build- ing customized program analysis tools. In Proceedings of the Conference on Programming Language \nDesign and Zm- plementalion, pages 196-205. ACM, 1994. PI [lS] J.G. Thompson. Efficient analysis of caching \nsystems. Ph.D. Dissertation, University of California, Berkeley, 1987. [20] J. TorreIIas, C. Xia, and \nR. Daigle. Optimizing instruction cache performance for operating system intensive work-loads. In Proceedings \nof the First International Sympo-sium on High-Performance Computer Architecture, pages 360-369, January \n1995. [21] D.W. Wall. Predicting program behavior using real or esti- mated profiles. In Proceedings \nof ihe ACM SIGPLAN 91 Conference on Programming Language Design and Imple-mentation, pages 59-70, Toronto, \nOntario, Canada, June 1991. [22] Cliff Young and Michael D. Smith. Improving the accu-racy of static \nbranch prediction using branch correlation. In Siz International Conference on Architeciural Sappori \nfor Programming Languages and Operating &#38;stems, pages 232-241, October 1994.  \n\t\t\t", "proc_id": "258915", "abstract": "As the gap between memory and processor performance continues to widen, it becomes increasingly important to exploit cache memory eflectively. Both hardware and aoftware approaches can be explored to optimize cache performance. Hardware designers focus on cache organization issues, including replacement policy, associativity, line size and the resulting cache access time. Software writers use various optimization techniques, including software prefetching, data scheduling and code reordering. Our focus is on improving memory usage through code reordering compiler techniques.In this paper we present a link-time procedure mapping algorithm which can significantly improve the eflectiveness of the instruction cache. Our algorithm produces an improved program layout by performing a color mapping of procedures to cache lines, taking into consideration the procedure size, cache size, cache line size, and call graph. We use cache line coloring to guide the procedure mapping, indicating which cache lines to avoid when placing a procedure in the program layout. Our algorithm reduces on average the instruction cache miss rate by 40% over the original mapping and by 17% over the mapping algorithm of Pettis and Hansen [12].", "authors": [{"name": "Amir H. Hashemi", "author_profile_id": "81547766456", "affiliation": "Dept. of Electrical and Computer Engineering, Northeastern University, Boston, MA", "person_id": "P16017", "email_address": "", "orcid_id": ""}, {"name": "David R. Kaeli", "author_profile_id": "81100454796", "affiliation": "Dept. of Electrical and Computer Engineering, Northeastern University, Boston, MA", "person_id": "P62249", "email_address": "", "orcid_id": ""}, {"name": "Brad Calder", "author_profile_id": "81100088945", "affiliation": "Dept. of Computer Science and Engineering, University of California, San Diego, La Jolla, CA", "person_id": "PP17000250", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258915.258931", "year": "1997", "article_id": "258931", "conference": "PLDI", "title": "Efficient procedure mapping using cache line coloring", "url": "http://dl.acm.org/citation.cfm?id=258931"}