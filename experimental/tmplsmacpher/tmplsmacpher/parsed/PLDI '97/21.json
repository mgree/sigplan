{"article_publication_date": "05-01-1997", "fulltext": "\n Program Analysis Using Binary Relations Adam Brooks Webber* ab-webberQwiu.edu Western Illinois University \nAbstract This paper presents a method called relational con-straint for finding binary relations among \nthe variables and constants of a program. The method constructs a table of binary relations and treats \nthe program as a collection of constraints on tuples of relations in the ta- ble. An experimental optimizer \ncalled Thinner uses this method to analyze programs of size n in O(n2) time. 1 Introduction In the analysis \nof programs, binary relations are an ex- traordinarily useful form of information. The (binary) relation \nof equality between two variables, or between a variable and a constant, is the key precondition for \na wide variety of optimizations. One class of these optimizations, the class of thinnings, was studied \nin [Web95]: it includes common subexpression elimina-tion, loop jamming, loop folding, dead code elimina-tion, \ncode sinking, loop invariant removal, and other, more exotic transformations. Loop guards and guards \non conditionals are commonly expressed as tests of bi- nary relations like =, #, and <; so being able \nto say something about the binary relations between variables allows an analyzer to reason about loop \ntermination and branch direction. This paper describes a method of program analysis called relational \ncon&#38;mint that concentrates on the bi- nary relations among the variables and constants of a program. \nThe method was developed for use in an op- timizer called Thinner. Program analysis was not the main \nthrust of the Thinner project, and was not dis-cussed in [Web95], which focused on a novel technique \nThin work was supported in part by NSF grant IRI-2001800. Permission to make digital/hard copy of part \nor all this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for profit or commercial advan-tage, the copyright notice, the title of the publication \nand its date appear, and notice is given that copying is by permission of ACM, inc. To copy otherwise, \nto republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or \na fee. PLDI 97 Las Vegas, NV, USA 0 1997 ACM 0-69791-907-6/97/0006...$3.50 for restructuring function \ndefinitions to allow interpro- cedural optimization of recursive calls. But Thinner, like most advanced \noptimizers, has a mundane need that cannot be ignored: the need for program analysis that is both detailed \nand fast. These two goals are, of course, at odds, and the concluding section this paper will re- turn \nto the question of striking a good bargain between detail and speed. The following example shows the \nkind of analysis Thinner performs. (This does not demonstrate Thin-ner s power to restructure recursive \nfunction definitions; it is only meant to show off the relational constraint analysis.) The reader is \ninvited to optimize the follow- ing function by hand before reading Thinner s solution. (defun g (a b) \n(let ((c (cons 1 a)) (d (cons 0 nil))) (let ((x (append c d)) (Y (wend b cl>) (equal x YNH The key precondition \nfor the optimization is a binary relation: the relation of equality between the output of the original \nfunction g and the Boolean constant false. A simple inductive proof by contradiction confirms this relation. \nList z is 1 . a e 0 and list 1 is b - 1 . a. Suppose z = y. Then lb1 A 1, a cannot be nil and its last \nelement must be 0. We also observe that if ai = 0 then ai-= 0 and so, by induction, all the elements \nof a must be 0. But if z = y the first element of a must be 1. By contradiction, z # y. Thinner uses \nno induction and no proofs by contra- diction. Nevertheless, it discovers and performs the ap- propriate \nsource-to-source optimization of function g:l (defun g (a b) false) This optimization took 0.18 seconds \nfor all stepe including anal-ysis. Run time wee measured on a Sun-4 workstation using the Lucid Common \nLisp function get-internal-runtime. The relational constraint method used by Thinner to discover the \nprecondition for this optimization is de- scribed below. At the end of the paper we will return to this \nexample and see how the method is applied. Relational T relations in the lattice). Next, we approximate \nthe program as a collection of con&#38;mints, functions that operate on tuples of rela- tions. For example, \nif a program contains itn addition a = b + c, we might want to strengthen the relations on (c,O) and \n(a, b), to reflect the fact that c = 0 _ a = b. These constraint functions will strengthen tuples of \nrelations monotonically, so that when f(n,~, . . . ,?A = (PI,~, . . . ,P,), we have Vippi + Ti. The program \nis approximated a~ a collec- tion of such constraints, each of which operates on a few of the relations \nin the table. Finally, we apply the constraint functions repeatedly to compute a fixpoint. The resulting \ntable of relations is the output of the method. The next few sections detail this method, answering the \nfollowing questions: How are relations represented? (Section 3) How are constraint functions represented \nand com- puted? (Section 4) How is a program approximated as a set of con- straints? (Section 5) How \nis the f&#38;point computed? (Section 6) What is the asymptotic complexity? (Section 7) In each section \nwe first describe the method in general, then examine Thinner s implementation in particular. A word \nabout abstract interpretation. This frame- work for describing methods for program analysis was pioneered \nby Cousot and Cousot; see [Cou96] for a re- cent survey. Relational constraint involves approximat- ing \na program using a set of constraints, then iterating those constraints until a fixpoint in a complete \nlattice is reached. This makes it quite natural to describe re-lational constraint in the language of \nabstract interpre-tation, and we mention a few important connections in the pages that follow. In general, \nhowever, our approach in this paper is implementation-oriented. In particular we make no attempt to connect \nthe constraints that approximate a program to a formal semantics for the language. 3 Representing relations \nThere is considerable freedom in the choice of a vocabu- lary of relations. To build a vocabulary of \nrelations, we begin with a small set X of ptimitiue binary relations on the values of objects. These \nprimitive relations must be a partition of the set of pairs of values, so that for any values a and b, \nthere is exactly one T E X for which arb. The primitive relations on values are used to build a lattice \nof expressible relations on objects. Any set R of primitive relations constitutes an expressible relation: \nif x and y are objects and i is some function that instanti-ates them to values, we define xRy as VtER \ni(s) T i(g). So an expressible relation is just a set of primitive re-lations, one of which must be satisfied; \neach subset of the set of primitive relations gives a different express-ible relation. The set X of all \nprimitives is the express- ible relation which is true of all pairs of objects, and the empty set is \nthe expressible relation which is never true; we ll call these relations T and I, respectively.2 By construction, \nsuch a vocabulary of expressible re lations is closed for conjunction, disjunction, and nega- tion. There \nis an obvious bit-coding of the expressible relations using 1x1 bits, one for each primitive relation \nin X. Disjunction, conjunction, and negation of rela- tions are straightforward bit operations requiring \ntime proportional to 1x1. The vocabularies of relations used in this paper sat-isfy an additional property: \nfor any relation R there ex-ists a relation Q such that aRb w bQa, and given R the reversed relation \nQ can be computed in time propor- tional to 1x1. This requirement can be avoided, but it does simplify \nthe implementation, and is easily achieved by including reversed versions of all the primitive re-lations \nin the set X. 3.1 Thinner implementation Thinner optimizes a strongly-typed language. There is no reason \nwhy the method could not construct binary relations on mixed-type pairs; but we decided that most From \na certain point of view the lattice of relations appears upside-down, since it is natural to think that \ninformation increases as you move up in a lattice. Not so in this case: information increases downward. \nExpressible relations are built from sets in such a way that the disjunction of relations (V), the union \nof the set6 (U) and least upper bound in the lattice (U) coincide. of the information we wanted was \nto be found in same- type pairs. Thinner therefore computes separate tables of binary relations, one \nfor pairs of each primitive type, and uses separate vocabularies of relations. Three of these vocabularies \nare shown below. 3.1.1 Integer relations In designing a vocabulary of relations on integers, we wanted \nto be able to represent relations commonly tested in programs: a < b, a = b, a > b. In addition, the \nopti- mizer needed to make inferences about the behavior of the final iteration of counting loops-for \nexample, the last a still < b when a is counting up by one-so we wanted a vocabulary that could also \nrepresent the pre- decessor and successor relations. These requirements led us to the following set of \nprimitive relations. Thinner s primitive relations on integer values a and b describe the sign of a: \na < 0, a = 0, or a > 0; the sign of b: b < 0, b = 0, or b > 0; and the difference of the magnitudes Ial \n- Jbl: (a) - (bl 5 -2, Ial - lb1 = -1, Ial - lb( = 0, Ial - lb1= 1, or Ial - Jbl 2 2. In lattice- theoretic \nterms, the relations are the reduced product of the lattices of signs for a and b and of the lattice \nof constants -2, -l,O, 1,2 for Ial -lbl; see [CMB+95] for a discussion of abstract interpretation with \nreduced products. The result is a partition of the set of pairs of integers into a set Xint of 29 primitive \nrelations. Table 1 shows these primitive relations and the notation we use for them. There are 22g subsets \nof Xi giving the same num- ber of expressible relations on imeger objects. For ex-ample, the equality \nrelation z = y is expressible as x{-- =O,OO=O, ++=O}y; the relation x = succ(y) is ex- pressible as x{-41,041, \n+O>l, ++>l}y. Difference of magnitudes, Ial - lbl: 5-2 z-1 =o =l 22 a<O,b<O --<2+ --<I --=o -->I -->2+ \na<O,b=O -O>l -0>2+ a<O,b>O -+<2+ -+<i -+=o -+>l -+>2+ a=O,b<O o-<2+ 041 a=O,b=O oo=o a=O,b>O 0+<2+ 0+<1 \n a>O,b<O +-<2+ +-<I +-=o +->l +->2+ a>O,b=O +0>1 +0>2+ a>O,b>O ++<2+ ++<i ++=o ++>I ++>2+ Table 1:Notation \nfor the primitive relations in Xint  3.1.2 List relations Naturally, we wanted to be able to represent \nequal-ity between lists. The Lisp-like language optimized by Thinner accomplishes list construction with \ncons and list traversal with cdr. So for list relations, we also wanted to be able to keep track of the \nrelation between a list and the same list with one element added or re moved from the head. These requirements \nled us to the following set of primitive relations. Thinner s primitive relations on lists a and b describe \nwhether the shorter is a suftix of the longer; whether the two lists have the same car; and the difference \nof the lengths Ial -lbl: Ial -lb1 5 -2, Ial -Ibl = -1, Ial - Ibl = 0, Ial - Ibl = 1, or Ial -Ib( 1 2. \nThis again is a reduced product of lattices, yielding a set Xlist of 19 primitive relations on lists. \nTable 2 shows these primitive relations and the notation we use for them. There are 21g subsets of Xnst \n, giving the same num-ber of expressible relations on lists. For example, if x is the cdr of a, and y \nis not empty, we have x{s<l, scCl)y. Table 2: The primitive relations in Xnst  3.1.3 Boolean relations \nHere, no approximation is required: the set of pairs of Boolean values has only four elements, so we \nuse a primitive relation for each one. This yields a set Xboo of four primitive relations named ff, ft, \ntf, and tt, with x ft y if and only if x = false and y = true, and so on. There are sixteen subsets of \nXboo , giving the same number of expressible relations on Booleans.  4 Representing constraints As \nhas already been stated, we will approximatethe program being analyzed as a collection of constraints, \nfunctions that operate on tuples of relations. The prob- lem of representing these constraints compactly \nand computingthem efficiently is addressed in thissection. Any k-tuple Q of expressible relations can \nbe thought of as representing a cube in the space of k-tuples of primitive relations: function Constrain(Q, \nS); Q is a tuple of expressible relations; S is a set of tuples of expressible relations; {(Tl,..., rdl \nA ri~Qi) Constrain(Q, S) returns a tuple of iE[l..k] expressible relations; The job of the constraint \nfunction is to strengthen the expressible relations in Q to eliminate inconsistent sub-cubes. To do this, \nwe represent each constraint as a set of k-tuples of expressible relations. This set represents a region \nof the space: the union of the cubes described by each tuple in the set. The inference procedure takes \nthe current tuple of relations Q and the constraint set S, and yields the smallest cube R containing \nthe intersec- tion of Q and 5 . Each relation in R is at least as strong as the corresponding relation \nin Q; if it s stronger, we ve gained information. For example: suppose our primitive relations on in- \ntegers are simply X = {<, 2). For any three integer variables 2, y and z in the program, the table of \nre- lations will include relations on the pairs (2, y), (y, z) and (z,z). Suppose that we have discovered \nthe triple of expressible relations Q = ((<}, { <}, T) for these three pairs. This triple represents \na cube in the space X x X x X: the cube containing the triples of primitive relations (<,<,<) and (<,<,>). \nObviously, the sec-ond of these is inconsistent; to eliminate it, our triple of expressible relations \nshould be strengthened to ((<II (<It (<I)* To accomplish that strengthening we need to apply a constraint \nthat encodes the transitivity properties of the primitive relations. Such a constraint should define \nthe region of consistent elements of the space, leaving out the two triples of primitive relations that \nviolate transi-tivity: (<, <, 2) and (>,L, <). The space of consistent elements is not itself a cube, \nbut can be represented as the union of cubes. It contains six triples of primitive relations, so it could \nbe represented as the union of six unit cubes. But it is more compact to represent it as the union of \nfour cubes-that is, as a set of four expressible relations: s = { (t<)> {<I, I<)), ({<l, e>,n (@I, l<ltT), \n(121, W, @}I 1 This set is a representation for the transitivity con-straint. The computation of the \ntransitivity constraint is simply the computation of the smallest cube that con-tains the intersection \nof Q and S, which is Constrain(Q,S) = ((<}, {<}, {<}). In lattice-theoretic terms, the computation of \nthe constrained tuple is just the computation of the greatest lower bound in a powerdomain built on a \nfinite domain. The function Constrain shown in Figure 1 implements this well-known method. begin R := \nthe tuple of I relations; for each tuple C in S begin I := Q A C (componentwise); if I does not contain \na I then R := R V I (componentwise) end; return R end; Figure 1: Constraint computation 4.1 Thinner \nimplementation Note that the Constrain function consists mainly of pairwise and s and or s of tuples \nof relations. Thin-ner s relations are bit-coded, as suggested above, and they fit in a 32-bit word, \nso this computation executes quickly. The constraint sets used by Thinner are all precom- piled; when \nThinner runs they are constants. (The next section describes the constraints that are used.) A con- straint \nset uses a union of cubes to define a region of tuple space; naturally, the constraint computation will \nbe fastest if the set is so constructed that the number of cubes is minimized. When the constraint sets \nused by Thinner are constructed, before Thinner runs, they are automatically reduced to minimal sets \nof cubes.  5 Choosing the constraints Now that we have a method for representing constraints, we can \nlook at the question of how to approximate a program using some collection of these constraints. FLe-lational \nconstraint is very flexible on this question: no matter what collection of correct constraints is used, \nthe method will terminate with correct results. Designing a method of approximating a program in terms \nof constraints, like designing a vocabulary of rela- tions, depends on the application: the language \nin ques- tion, the kind of information desired, and the amount of time available for analysis. With too \nfew constraints the method will provide uselessly weak results, while with too many the method will take \nprohibitively long. 5.1 Thinner implementation For the Thinner we settled on approximating a program \nof size n using 0(n2) constraints. These constraints are of four different kinds, as described below. \n5.1.1 Operator constraints An operator constraint is generated for each operator in the program. For \nsome operators this can constrain a single relation (a 1-tuple) in an obvious way: for in- stance, an \nabsolute value operator is approximated us-ing a constraint on the relation between its input and output. \nOther operators yield constraints on more com- plicated tuples, always including the relations among \nthe objects that are the operator s inputs and outputs, and sometimes including relations with critical \nconstants as well. For example, we decided to approximate each mul- tiplication operation x = y - z with \na constraint on sex- tuples: not only the relations on the pairs (x, y), (p,z) and (z,z), but also the \nrelations of each of z, y and z with the constant 1. This made the constraint for mul- tiplication more \npowerful since it could subsume facts about multiplicative identities. For example, if z = 1, we can \nconclude that x = y. (Note that our vocabulary of relations is expressive enough that the relation of \nan object with the constant 1 will tell whether the object is 0. This yields additional important identities.) \nTo accommodate this trick the constant 1 must al-ways be included in the collection of objects being \nana-lyzed, even if it does not explicitly occur in the program. The constants 0, true, false, and the \nempty list receive similar treatment. 5.1.2 Transitivity constraints The relations used in Thinner have \ntransitive proper-ties. When one relation is strengthened, we want to take advantage of transitivity \nto strengthen others, even when the objects in question are not neighbors in the data flow graph. Thinner \ntreats transitivity as a kind of triangle property: a restriction on the three binary relations among \nany three objects. For n objects there are n3 of these triangles. To keep the complexity down, Thinner \ninstalls transitivity constmints on certain interesting triples only, leaving most triples uncon-strained. \nA triple (a, b, c) is deemed interesting only if there is an operator constraint on (a, b), or if a is \na spe- cial constant like 0. Our experiments suggest that this captures many of the useful inferences \nthat occur when full transitivity is used, while requiring only 0(n2) con-straints. 5.1.3 List property \nconstraints When a program contains length, car or cons opera-tors, we will have one object that we know \nis the car or length of another object. List property constraints make sure that for any two lists a \nand b, the relation between a and b, the relation between car(a) and car(b), and the relation between \nlength(a) and length(b), are as strong as possible taken jointly. There is at most one such constraint \nfor each pair of lists. 5.1.4 Transparency constraints In the language optimized by Thinner, all functions \nare referentially transparent--given the same inputs, they produce the same outputs. lhaspanzncy constraints \nmake sure that the table of relations reflects this. There is one such constraint for each pair of calls \nto the same function. One could construct a custom transparency con-straint set for each operator, which \nin addition to trans- parency could reflect things like associativity (like or), bijectivity (like cons), \nor determination by any two of three values (like *). But we didn t do this for Thinner.  5.2 Handling \nloops We have so far avoided the question of loops. In fact, Thinner only examines program slices that \nare free of loops and branches. (These slices can be quite large and also numerous, since Thinner constructs \nthem by un-rolling loops, expanding function calls, and speculating about branch directions.) However, \nwe see no special difficulty in applying the method to single-assignment forms that contain +functions. \nFor each xi = $(x2, xa) in the program, and for each other object y in the program, we want the relation \non the pair (y,xl) to be the least upper bound of the re-lations on the pairs (y,xs) and (y,za). If the \nprogram contains n objects, this can be contrived using n con-straints for each 0 function. This still \nremains within our O(n2) bound on the number of constraints. Beyond this, no other modification is necessary. \nIn particular, the computation of the fixpoint discussed in the next section is unaffected. 5.3 Constructing \nthe sets Once the constraints have been designed, there still re-mains the problem of constructing the \nconstraint sets. This can be a non-trivial puzzle. For example, a transi- tivity constraint set is a \nset of cubes whose union is the space of all triples of primitive relations (71, ~2, ~3) for which there \nexist values a, b and c with arl b, brzc, and argc. This was not difficult to construct in our earlier \nexample with X = {<, >}, but it is another matter to construct it for larger vocabularies. Needless to \nsay, we wrote programs to aid in the construction of these constraint sets. Such programs are short but \nsometimes tricky little exercises. One detailed example is included in Appendix A.  6 Computing the \nfixpoint In the following description we will construct a table of relations that is always relationally \nsymmetric: the re-lation in the table for (x,~) is always the reverse of the relation for (v,z). It would \nalso be possible to main-tain only one triangle of the table, but doing so would complicate the creation \nof constraints. Most entries in the table of relations are initialized to T, indicating that nothing \nis known about the re-lation for that pair. But there are several exceptions. Relations can be at least \nas strong as equality along the diagonal; the relation between an object and a constant might start out \nstronger than the top relation (depend-ing on the vocabulary); and for the relation between two constants, \na single primitive relation can be computed immediately. We initialize a set of constraints waiting to \nbe com- puted: initially all constraints are in the set. Now loop while there are more constraints to \nbe computed: choose one, compute it, and update the table of re-lations; for any entry that got stronger, \nfind the con-straints that apply to that pair and add them to the set of those to be computed; and remove \nthe one we just performed. The algorithm is shown more formally in Figure 2. A key point is that we must \nbe able to find quickly the constraints that apply to any given pair. This is the purpose of the Con \ntable in RelationalConstraint. It gives, for any pair of objects, the set of all constraints that apply \nto that pair. It can be initialized by starting with a table of empty sets, and then adding each con-straint \nto the set for each pair to which that constraint applies. In the language of (CC92], RelationalConstraint \nis a chaotic iteration method. Such methods converge to the unique least fixpoint-in this case, to a \nunique weakest table of relations consistent with the constraints. It doesn t matter in what order constraints \nare selected at line 4: the final table will be the same. 6.1 Thinner implementation Although termination \nwith a unique final table is not sensitive to the order in which the constraints are ap-plied (and neither \nis the asymptotic worst-case analy-sis presented in the next section), the order does affect performance \nby a significant constant factor. Obviously it s a good idea to take big strengthening steps rather than \nsmall ones. In our application of the method in Thinner, we found two things that helped: . We experimented \nwith choosing the next constraint in LIFO, FIFO, and random order. Treating the collection of constraints \nas a queue gave the best performance, while treating it as a stack gave the worst. When a constraint \nis newly added, the pairs it constrains have usually changed only a little, and computing it immediately \nproduces a small gain. When a constraint is old, the pairs it con-strains have often changed quite a \nlot, and com-puting these constraints produces a larger gain. . We experimented with giving preference \nto tran-sitivity constraints, with giving preference to all other constraints, and with treating all \nconstraints equally. Leaving transitivity constraints for last gave the best performance, while doing \nthem first gave the worst. Transitivity constraints are much weaker than, for example, operator constraints, \nyielding strengthening in smaller steps. Making the right choices here improved the experimen- tal performance \nof the relational constraint method by about a factor of three. For simplicity we have been treating \nthe collection of strongest known relations (Rel) as one big table in-dexed by pairs of objects. As previously \nobserved, Thin-ner actually maintains separate tables of relations, one for each type. A more difficult \noptimization Thinner uses is to reason not about objects but about equiva-lence classes of objects. Whenever \na relation becomes as strong as equality, Thinner merges two equivalence classes and removes a row and \ncolumn from the tables.  7 Asymptotic analysis In analyzing the complexity of the method, we will use \nthe following definitions: n the number of objects in the program. c the number of constraints being \nused. a the maximum number of relations in any constrained tuple. e the maximum size of any expressible \nrelation (that is,   IXl)* s the maximum size of any constraint set. procedure RelationalConstraint(); \nCon is the table of sets of constraints, indexed by pairs of objects; Rel is the table of relations, \nindexed by pairs of objects; Todo is a set of constraints; begin 1 Initialize Con, Rel and Todo (with \nall constraints initially in Todo); 2 while more constraints in Todo do 3 begin 4 remove a constraint \nfrom Todo: S := constraint set, P := tuple of pairs constrained; 5 Q := the tuple giving the relation \nRel(i, j) for each (i,j) in P; 6 Q := Constrain(Q, S); 7 for each pair (i, j) in P and corresponding \nrelation r in Q 8 if T is stronger than ReZ(i, j) then 9 begin 10 Rel(i,j) := r; 11 Rel(j,i) := r reversed; \n12 Todo := Todo U Con(i, j) U Con(j, i) 13 end 14 end end; Figure 2: Relational constraint algorithm \nFirst, the Constrain function (Figure 1): the func-tion contains simple operations performed on tuples \nof relations. There are a relations in a tuple and each is of size e. The loop is executed once for each \nof the s tuples in the constraint set. The complete computation therefore requires O(sae) time. Now the \nRelationalConstraint procedure (Figure 2). Consider the critical operation on line 12. It is clear that \nwe can perform the unions for any particular iter-ation of line 12 in 0( I Con(i, j)l + I Con(j, i)l) \ntime. But how much time will be spent on line 12, in total? Any given constraint can appear as Con(i, \nj) or Con(j, i) on line 12, at most once for each time one of the a rela-tions it constrains is strengthened; \nand a relation can be strengthened at most e times before it reaches 1. So each constraint can appear \nas Con(i, j) or Con(j, i) on line 12, at most ae times. With c constraints, we have a bound of O(cue) \non the total time on line 12. This also gives us a bound on the number of itera tions of the loop on \nline 2: cue iterations. (This is a very pessimistic bound since it will often happen that when we decide \na constraint needs to be computed, that constraint will already be in Todo.) Excluding line 12, the complexity \nof one iteration of the loop body is dom- inated by the complexity of the Constrain computation on line \n6: O(sae). This gives us a total of O(a2e2cs) for the loop at line 2, including the O(cue) time for line \n12. Not yet included is the initialization at line 1. As-suming we can construct the initial relation \non a pair of objects in O(e) time, initializing the table of rela- tions requires O(n2e). Initializing \nthe Con table in-volves constructing a table of empty lists (O(n2) time) and then adding each constraint \nto the list for each pair it constrains (O(ca) time). Finally, initialiiing Todo re quires O(c) time, \nto add each constraint to the set. To-tal time for the initialization at line 1 is O(n2e + co). Total \ntime for the relational constraint algorithm is O(n2e + a2e2a). The implementation s vocabulary of primitive \nrela-tions determines e, while the implementation s method for translating programs into sets of constraints \ndeter-mines a and s. For example, in Thinner s implemen-tation, e = 29 (the size of the vocabulary of \nprimitive relations for integers), a = 6 (the number of pairs in the constraint Thinner constructs for \neach addition op-erator), and s = 210 (the size of Thinner s constraint set for transitivity on lists, \nalthough the average size of constraint sets used by Thinner is only about 10.) These values are determined \nwhen the analyzer is con- structed, and do not depend on the program being an-alyzed. So for any particular \nimplementation of rela- tional constraint, e, a and s may be taken as constant. Taking e, a and s as \nconstant, we have a complexity of O(n2 + c). Our implementation approximates each program with a number \nof constraints c = O(n2), so the complexity of the method as used in Thinner is O(n2). a b Figure 3: \nData flow graph  Completing the example We can now return to the example in the introduction, and show \nhow relational constraint discovers the key binary relation for that optimization. Figure 3 shows a data \nflow graph for the program in question. Thinner reasons about seven list objects: the inputs a and b, \nthe let variables c, d, x and y, and the empty list3 There are also three boolean objects: the output \nz and the boolean constants true and false. Finally, there are several integer objects: the lengths and \ncars of the lists, along with the integer constants 0 and 1. A table of relations from early in the process \nis shown in Table 3. (The integer relations are straightforward and are not shown in the table.) The \nrelations in Table 3 are those arrived at after the table has been initialized and the constraints for \nthe cons operators have been computed. Here to is the initial relation between the empty list and any \nlist, and ri is the relation established by cons between its input and output lists. Table 4 shows the \nfinal table of relations. The se-quence of constraints that led to this result is as follows. Integer \nrelations, not shown in the table, are developed by the cons vertices. These establish initially that \n1 is the car of c and 0 is the car of d, and that the length of d is the successor of the length of nil \n(that is, the length of d is 1). The list property constraint for c and d then yields the relation r4 \nshown in the table, which says (among other things) that c and d have different cars. The operator constraint \nfor the append that com-putes x constrains the relations on (c,d), (c,x), (d,s), (c, nil), (d, nil) and \n( x, nil). The constraint set for append reflects the fact that if the length of d is 1 and if c and \n3Actually, the empty integer list; the language Thinner operates on wea simple flat typed lists. d havedifferent \ncars, c cannot be a suffix of (append c d). (This is where that tricky proof is hiding-it s implicit \nin the constraint set for append.) So when this constraint is computed, we get the relation {ccl} be \ntween c and x shown in the table. It says that c is one shorter that z, that they have the same car, \nbut that c is not a suffix of 2. On the other hand, the append that computes y con- strains its tuple \nof relations to assert that c is a suflix of y (relation rs). Since c is a suffix of y and not a suEx \nof z, we conclude by transitivity that z and y cannot be equal; and the operator constraint on the equality \ntest settles the value of z. 9 Conclusion Our early sketches for Thinner s design showed a myste- rious \nbox labeled program analysis. This label was, of course, a bit delusional-one might as well write lots \nof computation or a miracle occurs. To get good performance from Thinner we had to design a special- \npurpose inference technique. We hope that relational constraint will be useful in other applications \nas well. Before developing relational constraint we first ex-plored several existing methods. We began \nwith a stan- dard technique of computing and comparing the normal forms of expressions. This provides \nuseful information about equalities, and is still used in the current Thin-ner, but was not nearly powerful \nenough by itself. See-ing how much more inferential power was required, we considered using some more \ngeneral-purpose inference system: perhaps a Prolog-style backward-chaining sys-tem, or something that \nfinds simple inductive proofs like Boyer and Moore s early system for proving the-orems about Lisp programs \n[BM75]. We performed experiments with a prototype of Thinner using a sim- ple backward-chaining inference \nengine. (The choice of the vocabulary of relations described above began with post-mortem examinations \nof proofs discovered by that prototype.) But now, although it was sufficiently pow-erful, it was far \ntoo slow. We found quite a few techniques in the literature for dealing with the integer variables of \nimperative pro-grams. Constant propagation is a time-honored tech-nique [WZ91]; it treats program variables \nindependently, without considering the relations between them. Cousot and Cousot extended this kind of \nanalysis to constant intervals [CC76]. Relations between integer variables have also been studied: the \nmethod of Karr [Kar76] develops a system of affine equations on a program s variables, and the linear \nrestraint analysis of Cousot and Halbwachs [CH78] develops a system of a6ine in-equalities. A strong \nmotivation in this area has been nil a b c d x y = nil TO To To 7-1 To To a rev(r0) = T ,rl T T T b \nrev(ro) T = T T T T rev(rO) rev(ri) T = T T T ii rev(q) T T T = T T X rev(ro) T TTT=T y rev(r0) T TTTT= \ntrue false z To = {sc=o, sc<2+, scq s<2+, SCl} Tl = {scq SCl} Table 3: Early the compiler-writer s \ndesire to vectorize loops automat- ically, which requires congruence analysis. In this vein are Granger \ns congruence analysis, which yields asser-tions of the form z = c[m] [G&#38;9] and, later, analysis of \ncongruence equalities, which yields a system of con- gruence equations [G&#38;l]. But these techniques \nare too specialized for use in Thinner, which needs to rea-son about a variety of data types, not just \nintegers. Many are also too expensive: congruence analysis is O(pd log2n) where p is the program size \nand n the number of integer variables, while linear restraint anal-ysis is exponential. In general, there \nis a large gap in the literature be-tween techniques that do not consider relations between variables \n(constant propagation, value numbering, nor-mal forms) and those that do. Crossing this gap has always \ninvolved paying a very high price in complexity. Relational constraint takes a place in the middle of \nthis gap, achieving a reasonable compromise between speed and accuracy. The relational constraint method \nshould be easy to parallelize. Since the order in which constraints are computed is largely irrelevant, \nthere is no reason why they cannot be computed in parallel. Updates to the table of relations are also \nunusually order-independent since relations grow stronger monotonically. Relational constraint can easily \nbe integrated with other methods of program analysis. For example, Thin-ner s program analyzer also uses \nthe normal forms of ex- pressions to gain information about equalities (although this was disabled for \nthe examples discussed above). Any such information can be recorded as a strengthen- ing in the table \nof relations, triggering the recomputa- tion of constraints in the usual way. Whenever part of an inference \ntask can be treated as constraining binary table of relations relations on a fixed collection of objects, \nand whenever part of that vocabulary of relations can be captured in a finite lattice, the relational \nconstraint method may be useful. A Constraint set construction In this appendix we present a detailed \nexample of con- straint set construction: the constraint that is applied by Thinner for each addition \noperator the source pro-gram. All the constraints used by Thinner are built, tested and reduced by similar \nmeans-although this ex-ample is one of most complex. We have already discussed how Thinner treats each \nmultiplication operation 2 = y . 2 as a constraint on sextuples of relations. The same trick is used \nfor addi- tion. Each addition operation c = a + b in the source program yields a constraint on six entries \nin the ta-ble of relations: the relations on the pairs (a, b), (b, c), (a,~), (a, l), (b, l), and (c, \n1). The constraint set Thin- ner needs is available to it as a constant at runtime. But before Thinner \nruns, this set must be carefully con-structed and tested. This construction takes place in three steps. \nWe first construct a set of all the possible sextuples of primitive integer relations, then test it by \nreconstructing it in a completely different way, and finally reduce it to a minimal set of cubes. A.1 \nConstructing the primitive tuples Thinner s vocabulary of primitive integer relations was shown in Table \n1. Our problem now is to identify all the sextuples of primitive integer relations (on the pairs nil \na 1 b Y nil T: {SC:i) T3 a b li X 2 true false z rev(r8) rev(ri) {sol} rev(r8) rev(r8) (s>2+) rev(r8) \nrev(r8) rev(r8) rev(q)  -l--L T5 T6 T? To   (CC11 T2 fg TIO rev(n0)  T2 = To -{SC O, SC<2+, SCd} \nT3 = To -{SC=o, SC<l} Tq = {=o, s>2+, s>l, >2+, >l) T5 = (c&#38;2+, s<2+, c<2+,<2+} Tg = To -{SC O} \nTy = T6 u {C<2+, Ccl} T8 = T4 u {SC=&#38; SC<&#38; SC>2+, SC>i, C>2+, C>i} Tg = T5 u {=o, C<l, (1, S<i} \nTIO = {c>l, C O, =o, c<2+, c<l, c2+, (1) Table 4: Final table of relations b,b), (hc), (a,~), (a, 11, \n(4 11, =d (G 1)) that could possibly occur when u, b and c are instantiated in agree- ment with c=a+b. \nTo identify the possible sextuples of primitive inte ger relations, we will start with the cases in which \nboth a and b are non-negative. In these cases there are four possible relations for (a, 1): relation \non (0,l) would be O+<l, the relation on (1,1) would be ++=O, the relation on (2,l) would be ++>l and \nfor any larger a, the rela- tion on (a, 1) would be ++>2+. There are the same four possible relations \nfor (b, l), so we get sixteen possible combinations of these two relations. Each such combi- nation fully \ndetermines the relations on (b, c), (a, c) and (c, l), and partially determines the relation on (a, b); \nTable 5 shows all 22 possibilities. For example, consider the first row of Table 5. In thii row the \nrelation on (o,l) and on (b,l) is O+Cl. This means that a = 0 and b = 0, so we must also have c = 0. \nThus, the relation on (b,c) must be OO=O, the relation on (a, c) must be OO=O, the relation on (c, 1) \nmust be O+<l, and the relation on (a, b) must be OO=O. Or consider the last row: in this case the relation \non (a, 1) and on (b, 1) is ++>2+, so we must have a 2 3 and b > 3, and therefore c 2 6. The relation \non (b, c) must be ++<2+, the relation on (a, c) must be ++<2+ and the relation on (c, 1) must be ++>2+. \nHowever, the relative magnitudes of a and b are unconstrained here, so the relation on (a, b) could be \nany one of the five shown. This only covers the cases in which a and b are both non-negative, and therefore \nc is also non-negativethe first of six possible combinations of signs, as follows: a b c 1. 20 20 20 \n 2. 10 50 50 3. 20 50 50 4. 50 20 20 5. 20 50 20 6. <O 20 50  Mercifully, there is no need to repeat \nthe previous exercise for all six cases: the results for the first can be altered methodically to give \nthe other five. Case 2, for example, merely negates u, b and c. The relations from Table 5 can be used \nagain, with appropriate sign changes. In cases 3 and 4, the sign of a differs from the signs of the other \ntwo operands. This seems like a new situ- ation. But the relations from Table 5 can still be used, by \nrearranging c = a + b as -b = u + -c. Arranged this way, the signs agree again, so we can use the same \ncollection of tuples but with the various positions of c and b exchanged, and appropriate sign changes. \n  0 OJ (a, 1) (b, 1) (b, 4 b-44 -0+x1 0+x1 oo=o oo=o OH1 oo=o 0+<1 ++=I) ++=o 0+<1 ++=o 0+<1 0+<1 \n0+<2+ 0+<2+ 0+<1 0+<2+ 0+<2+ tt=o to>1 ++=O ++=I) tt=o tt<1 tt=o tt>2+ tt<2+ tt>i tt=o tt>1 +0>2+ ++>1 \nt+> 1 t+>i +t> 1 tt=o tt>1 tt>2+ tt<2+ tt<2+ tt>2+ tt<1 tt<2+  tt>2+ +0>2+ tt>2+ tt>2+ tt>2+ tt>1 ++>2+ \ntt>2+ ++<2+ tt<1 +t=o tt>1 ++>2+  Table 5: Possible sextuples when c = a + b with a, b > 0 In cases \n5 and 6 it is the sign of b which differs from the signs of the other two operands. We can now rear- \nrange c = a + b as -a = -c + b. This makes the signs of all three agree again, so we can again use the \nsame collection of tuples, this time with the various positions of c and a exchanged, and appropriate \nsign changes. Collecting all 6 of these versions of our 22 sextuples gives a total of 109 sextuples primitive \nrelations-not 6 x 22 = 132 because some of the altered versions of our original 22 sextuples are repetitions. \nA.2 Testing the primitive tuples A much simpler, though less illuminating, way of con- structing a constraint \nset for addition is this: write a program that tries all possible combinations of a and b from some test \ndomain of integers, and collects the actual sextuples of primitive relations observed. This is exactly \nhow we test the constraint set generated in the previous section. Letting a and b vary over the do- main \nC-8,. . . , 8) (or any larger domain) generates ex-actly the same sextuples of primitive relations that \nwe constructed by the previous method. Constructing the same set of tuples of primitive relations in \ntwo different ways increased our confidence in the result. procedure Reduce(S); S is the constraint set \nto be reduced; begin while there exist tuples P E S and Q E S that differ in exactly one position do \nbegin let P and Q be any such pair of tuples in S; remove P and Q from S; addPvQtoS end end; Figure \n4: Constraint set reduction It is so much less onerous to generate tuples this way that one might be \ntempted to skip the previous method entirely. But consider the difficult debugging problem that would \nresult if an incomplete constraint set were used in the Thinner-if not all possible sextuples were found. \nIt would lead the method of constraints to make unsound inferences, which would be extremely difficult \nto trace back to their cause.4 It should in principle be possible to eliminate all such concerns by deriving \nconstraint sets from a formal se-mantics for the language. This might be an interesting direction to \nexplore for those inclined toward formal se mantics.  A.3 Minimizing the constraint set To make the \nmethod of constraints run as quickly as possible, we reduce each set of tuples of primitive rela-tions \nto a smaller set of tuples (using expressible rela-tions) before Thinner uses it. The method we use for \nthis reduction is shown in Figure 4. The constraint set that results is a local minimum, but not necessarily \na global one. However, this local minimum served well enough in Thinner that we did not attempt any further \nminimization. Applied to the constraint set for addition, this reduces our original set of 109 tuples \nto a set of 73.  References [BM75] Robert S. Boyer and J. Strother Moore. Proving theorems about LISP \nfunctions. Journal of the ACM, 22(1):12+144, Jan-uary 1975. If, on the other hand, we included eztra \ntuplas of primitive relations-tuples that cannot occur when a, bend c are instantiated in agreement with \nc = Q + b-the resulting inference would remain correct, although less complete. [CC761 [CC921 (CH78) \n[CMBt95] [Cou96] [Gra89] [GraSl]  [K=761 [Web951 W W Patrick Cousot and Radhia Cousot. Static determination \nof dynamic properties of pro- grams. In Proceedings of the 2nd Intema-tional Symposium on Programming, \n1976. Patrick Cousot and Radhia Cousot. Ab-stract interpretation and application to logic programs. The \nJournal of Logic Pro- gramming, 13(2):103-179, July 1992. Patrick Cousot and N. Halbwachs. Auto matic \ndiscovery of linear restraints among variables of a program. In Conference Record of the 5th ACM Symposium \non Prin-ciples of Pmgmmming Languages, 1978. Michael Cod&#38;h, Anne Mulkers, Maurice Bruynooghe, Maria \nGarcia de la Banda, and Manuel Hermenegildo. Improving ab-stract interpretations by combining do-mains. \nACM Dunsactions on Programming Languages and Systems, 17(1):28-44, Jan- uary 1995. Patrick ACM June Cousot. \nComputing 1996. Abstract Surveys, interpretation. 28(2):324-328, Philippe Granger. Static analysis of \narith- metical congruences. International Journal of Computer Mathematics, 30, 1989. Philippe Granger. \nStatic analysis of linear congruence equalities among variables of a program. In TAPSOFT 91 Proceedings \nof the International Joint Conference on The-oy and Pmctice of Software Development, pages 169-192. Springer-Verlag, \nApril 1991. Lecture Notes in Computer Science 493. M. Karr. Affine relationships among vari-ables of \na program. Acta Inform&#38;k, 6, 1976. Adam Brooks Webber. Optimization of functional programs by grammar \nthinning. ACM l kansactions on Programming Lan-guages and Systems, 17(2):293-339, March 1995. Mark N. \nWegman and F. Kenneth Zadeck. Constant propagation with conditional branches. ACM Bunsactions on Progmm-ming \nLanguages and Systems, 13(2):181-210, April 1991.  \n\t\t\t", "proc_id": "258915", "abstract": "This paper presents a method called <i>relational constraint</i> for finding binary relations among the variables and constants of a program. The method constructs a table of binary relations and treats the program as a collection of constraints on tuples of relations in the table. An experimental optimizer called Thinner uses this method to analyze programs of size <i>n</i> in <i>O</i>(<i>n</i><sup>2</sup>) time.", "authors": [{"name": "Adam Brooks Webber", "author_profile_id": "81100588057", "affiliation": "Westerm Illinois University", "person_id": "P10754", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258915.258938", "year": "1997", "article_id": "258938", "conference": "PLDI", "title": "Program analysis using binary relations", "url": "http://dl.acm.org/citation.cfm?id=258938"}