{"article_publication_date": "05-01-1997", "fulltext": "\n Interprocedural Conditional Branch Elimination+ RastislavBodik Rajiv Gupta Mary Lou Soffa Dept. of Computer \nScience University of Pittsburgh Pittsburgh, PA 15260 {bodik,gupta,soffa)Ocs.pitt.edu Abstract The existence \nof statically detectable correlation among con- ditional branches enables their elimination, an optimization \nthat has a number of benefits. This paper presents tech-niques to determine whether an interprocedural \nexecution path leading to a conditional branch exists along which the branch outcome is known at compile \ntime, and then to elim- inate the branch along this path through code restructuring. The technique consists \nof a demand driven interprocedural analysis that determines whether a specific branch outcome is correlated \nwith prior statements or branch outcomes. The optimization is performed using a code restructuring algo- \nrithm that replicates code to separate out the paths with correlation. When the correlated path is affected \nby a pro- cedure call, the restructuring is based on procedure entry splitting and esit splitting. The \nentry splitting transforma- tion creates multiple entries to a procedure, and the ezit splitting transformation \nallows a procedure to return control to one of several return points in the caller. Our technique is \nefficient in that the correlation detection is demand driven, thus avoiding exhaustive analysis of the \nentire program, and the restructuring never increases the number of operations along a path through an \ninter-procedural control flow graph. We describe the benefits of our inter-procedural branch ehm- ination \noptimization (ICBE). Our experimental results show that, for the same amount of code growth, the estimated \nre- duction in executed conditional branches is about 2.5 times higher with the ICBE optimization than \nwhen only intrapro- cedural conditional branch elimination is applied. Keywords: inter-procedural data \nflow analysis, conditional branch correlation, path-sensitive optimization, optimiza-tion of object-oriented \nlanguages. 1 Introduction Recent research in branch prediction [16, 24, 251, profiling [3], and the \nelimination of conditional branches [19] has re- ported the existence of significant amounts of correlation \namong conditional branches, presenting opportunities for optimizations. A conditional branch has static \ncorrelation along a path if its outcome can be determined along the path +Partially supported by National \nScience Foundation Presidential Young Investigator Award CCR9157371, a National Science Foun- dation \ngrant CCR9402226, and a grant from Hewlett-Packard to the Universityof Pittsburgh. Permission to make \ndigital/hard copy of part or all this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for profit or commercial advan-tage, the copyright notice, the \ntitle of the publication and its date appear, and notice is given that copying is by permission of ACM, \nInc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior \nspecific permission and/or a fee. PLDI 97 Las Vegas, NV, USA 0 1997 ACM 0-89791-907-8/9710006...$3.50 \nat compile time from prior statements or branch outcomes. Such a conditional branch is redundant along \nthe correlated path and can be eliminated by code restructuring. Elimina- tion of conditional branches \nhas a number of benefits, which are discussed in Section 6, including . enhancing instruction scheduling \nand software pipelin- iw, . improving speculative execution and hardware branch prediction, and . optimizing \nC++/Java virtual functions. Previous work on conditional branch elimination through static correlation \n[19] demonstrated substantial performance improvements despite its restricted focus on eliminating con- \nditionals within loops. Experimentally, we show that sub- stantia.Uy more static correlation is detected \nat compile time when programs are analyzed interprocedurally. Using pro- grams from the SPEC95 suite, \nwe discovered that interpro- cedural detection of correlation enables elimination of 3% to 18% of executed \nconditionals, which is a factor of about 2.5 improvement over strictly intraprocedural analysis. As il- \nlustrated below, this high correlation among branches when procedures are considered is due to the modular \nfashion in which we write procedures: . In a procedure, the value returned is often selected by an if-statement. \nThis value may again be checked by the caller. For example, consider a call to a procedure that removes \nan element from a linked list. The proce- dure tests whether the list is empty and, if so, returns nil. \nThe caller performs an identical test on the return value to determine if nil was returned. The later \ntest is fully correlated with the earlier one. . In order to keep the procedure interface simple by passing \nfew arguments, procedures frequently include checks on the parameters that are also performed by the \ncaller or even by previous calls to the same proce- dure. For example, procedures from the same library \nmodule may be called one after another, propagat- ing values. These procedures often perform correlated \ntests on the propagated values. With our optimiza- tion, the repeated testing can be eliminated. Conditional \nbranch elimination is a form of partial re dundancy elimination (PRE). However, the code motion techniques \nuseful for PRE of assignments [14, 51 do not suf- fice for removing conditional branches. To eliminate \na condi- tional, the control flow graph must be restructured in order to separate the correlated path \nfrom the rest of the paths [19]. After code replication isolates the correlated path, the conditional \non this path becomes fully redundant and can be removed. Procedures are traditionally viewed as inherently \nsingle-entry/single-exit regions of code which means that all paths through the procedure must pass through \nthe unique entry and exit points. To exploit interprocedural opportuni- ties for conditional branch elimination, \nthe correlated paths crossing procedure entry/exit must be isolated by splitting procedure entry/exit \nnodes. In this paper, we present a new optimization, lnter-procedural Conditional Branch Elimination \n(ICBE). The optimization consists of a demand-driven interprocedural static correlation analysis and \na code restructuring algo- rithm that uses the detected correlation to eliminate con- ditional branches. \nWe implemented the optimization and experimentally investigated the amount of inter-procedural correlation \ndetected and the benefits and costs of conditional branch elimination. Demand-driven interprocedural \ncorrelation analysis. Using the demand-driven data flow framework for distributed data flow problems \n[9], we developed a demand-driven cor- relation detection analysis algorithm. The analysis is in- ter-procedural \nand thus considers correlated paths spanning procedural boundaries, as welI as correlations that occur \nwithin the same procedure. In the analysis phase, given a conditional branch, a query propagation search \nis performed to find assertions on program variables that indicate the cor- relation along paths leading \nto the conditional. The exhaus- tive approach to analysis would naively determine at each node all existing \nassertions on program variables (including irrelevant ones), resulting in exponential worst-case analysis \ntime. Because our analysis is restricted to discovering use- ful assertions on relevant variables, we \nare able to achieve polynomial analysis time. If correlation is found along some path, code restructuring \nby path duplication is required to eliminate the conditional. Our analysis determines the up- per bound \non the amount of code duplication required to eliminate the conditional. If profile information is available, \nour analysis also provides an estimate of the reduction in the execution frequency of the conditional. \nThe above measures can be used to guide the optimizer in making a decision on whether and how to transform \nthe program to eliminate the conditional. Interprocedural restructuring. The correlated condi- tional \nis eliminated by path duplication, which separates paths with correlation from those where correlation \nwas not detected. Two approaches to inter-procedural elimination of branches can be used. The first is \nto inline procedures in- volved in the correlation and duplicate paths strictly within a procedure. We \npresent an alternative approach that incurs less code growth than inlining because only paths with cor- \nrelation are duplicated. Another advantage of our algorithm is that it enables optimizations of call \nsites where inlining is not possible [2]. The algorithm is based upon procedure entry splitting and exit \nsplitting. The entry splitting trans- formation creates multiple entries to a procedure through which \nthe procedure can be entered from different call sites. The exit splitting transformation allows a procedure \nto re- turn control to one of several return points in the caller in- stead of always returning control \nto the call site. Intuitively, entry splitting enables the elimination of inter-procedurally redundant \ncode in the callee, and exit splitting enables elim- ination in the caller. Our restructuring algorithm \nrestruc- tures a control flow graph such that the number of opera- tions in the control flow graph does \nnot increase along any path. After exit splitting, additional return addresses may need to be passed \nduring a procedure call. Within the scope of a procedure, our restructuring algorithm is similar to that \nof Mueller and Whalley [19], except that our restructuring techniques takes advantage of correlation \nthat spans nested loops. Our algorithm is able to create two versions of a loop, one for each known outcome \nof the conditional, enabling the elimination of the conditional in each loop version. Experimental evaluation. \nOur measurements performed on a set of application programs provide insight into the in- ter-procedural \ncorrelation that can be detected statically and its usability for compiler optimizations. We found that \nnot only the number of conditionals with some correlated paths greatly increases with inter-procedural \nanalysis, but also the effect of branch elimination is more significant because many short, frequently \ntaken inter-procedural correlated paths ex- ist. Since some correlated branches may need long analysis \ntimes to detect the correlation and also require extensive code replication, we developed and evaluated \nsimple heuris- tics that control the extent of the analysis and the amount of code growth due to ICBE. \nWe show that for the same code growth, ICBE removes significantly more executed condi- tional branches \nthan what is possible with the intraproce- dural conditional branch elimination optimization. lntraprocedural \nelimination of conditional branches in loops was developed by Mueller and Whalley [19]. We ex- tend their \ntechnique in several respects. First, we can detect and eliminate partial redundancy of branches in loop \nnests and across procedure boundaries. Second, even in the scope of a single procedure, our approach \nis more powerful because we can detect redundancy that is apparent by examining multiple basic blocks \nalong a path, as opposed to a redun- dancy due to a single basic block detected in their analysis. In \naddition, in our technique, the analysis cost and the code growth incurred due to program restructuring \ncan be con- trolled. Mueller and Whalley [18] also investigated avoiding unconditional jumps by code \nreplication. Krall [16] devel- oped code replication techniques to improve the accuracy of semi-static \nbranch prediction to the accuracy of dynamic prediction. This paper is organized as follows. The next \nsection presents an example to motivate the technique and gives the overview of ICBE. Section 3 presents \nthe algorithms and Section 4 presents our experimental results. Section 5 highlights the benefits of \nICBE.  2 An Example and Overview We illustrate ICBE on a small application program that usea the stdio \nGNU C library (gIibcl.99). The program is shown in Figure l(a). Function MAIN first opens a text file \nby a call to fopen and then iterates through each character in the file until EOF is reached. The characters \nare obtained by a call to fgetc, which returns a character from a buffer that is filled by calling fillbuf. \nFirst consider applying ICBE to optimize the conditional PO in MAIN. Since EOF equals -1, our demand \ndriven analy- sis algorithm raises the query (c = -1) at PO and propagates it backwards into function \nfgetc where the analysis quickIy terminates at nodes a, b, and c with answers TRUE, UNDEF, and FALSE, \nrespectively. The TRUE result at a means that along the path from node a to PO, the outcome of PO is \ntrue. (a) The source program. (b) After optimization of PO. (c) Elimination of Pl, P2, P3; exit splitting \non Rllbuf. Figure 2: h&#38;ring of optimized fgetc. Thus, PO is statically correlated along the path \nfrom a to PO. Node c fetches from the buffer an unsigned character with a non-negative value which resolves \nthe query to FALSE indi-cating that the outcome of PO is false. Thus, PO is statically correlated along \nthe path from node c to PO. Assuming for now that the code of function fillbuf is unavailable and noth- \ning is known about its return value, the query must resolve to UNDEF at the call site node b, meaning \nthat the behavior of PO cannot be determined along the path from node b to PO and thus it is not statically \ncorrelated along this path. From the analysis, the conditional PO is redundant along two out of three \npaths reaching it. Our optimization algorithm restructures the program by exit splitting to separate \nthe paths from node a to PO and from node c to PO. After the transformation, the conditional PO is bypassed \neach time, except when the buffer is refilled at node b (see Figure l(b)). Exit splitting is implemented \nby passing additional return addresses to the callee. Next, we optimize conditionals Pl, P2, and P3 in \nfunc- tion fgetc. The individual queries raised at these condi- tionals are all resolved in function \nfopen where the analysis reveals that either fp = NULL or fp # NULL A fp->magic = IOMAGIC holds. In either \ncase, all three conditionals are fully redundant (that is, they can be eliminated along all paths). Our \noptimizer splits the exit of fopen and the entry of fgetc to bypass these conditionals. The result is \nshown in Figure l(c). The statements in fgetc that are reachable only from its original entry can be \ndeleted if no other call site of this entry exists. When the code of fillbuf is available, propagation \nof the query raised at PO does not terminate at its call site but detects that fillbuf either returns \nEOF or an unsigned value, resolving the query to TRUE and FALSE, respectively. The resulting exit splitting \nof fill buf enables the complete elimi- nation of conditional PO, shown in Figure l(c). In the original \nloop, during each loop iteration five con- ditional branches are executed. After the optimization, only \none conditional remains. This optimization cannot be car- ried out by intraprocedural branch elimination \n[19]. The overhead of the optimization is passing two return addresses to fgetc. However, the additional \ninstructions related to ar- gument passing can be freely scheduled ahead of the proce- dure call because \nthey have no incoming data dependencies. Figure 1: The example program using the GNU C library. Furthermore, \nthe code size of procedure fgetc is reduced callsnedp procedure P allomer~lsiteofP Figure 3: Interprocedural \nCFG in call site normal form. which enables its inlining into MAIN, where the resulting loop can be \nefficiently pipelined (see Figure 2). We discuss the use of inlining further in Section 5. 3 The ICBE \nOptimization For each conditional branch considered, the ICBE optimiza- tion performs analysis followed \nby restructuring. First, the conditional is analyzed to detect correlated paths and to determine the \namount of code duplication required to elimi- nate the conditional. If correlation is found and the demands \non code growth are acceptable, the program is restructured to create paths along which the conditional \nand instructions that compute its predicate condition are eliminated. The analysis and restructuring \nalgorithms are explained in the following subsections. The interprocedural control flow graph (ICFG) \nused in the algorithm is a graph that combines CFGs of all program procedures by connecting procedure \nentries and exits with their calf sites as depicted in Figure 3. All edges in the fig- ure define the \npredecessor-successor relation for nodes. Each procedure can have multiple procedure entry nodes and \nmul- tiple procedure ezit nodes. The successors of a call site node are the procedure entry node and \nthe associated call site exit nodes. The analysis algorithm requires the ICFG to be in the norm41 call \nsite form, where a) each call site node has a single procedure entry successor and b) each call site \nexit node has exactly one call site predecessor and one pro- cedure exit predecessor. We assume that \nthe above nodes are dummy nodes with no program statements. 3.1 Interprocedural Correlation Detection \nOur analysis is demand-driven from a given conditional in the sense that only the nodes that may lie \non a correlated path are visited and only the relevant data flow information is computed. The analysis \nis initialized by raising a query at the conditional that corresponds to asking a question is the outcome \nof the conditional with the predicate (u relop c) known along some incoming paths? The form of the raised \nquery is (u relop c), where t! is a variable and c a constant. The query is then propagated from the \nconditional back- wards along all paths in the ICFG until it can be resolved on these paths. Resolving \na query at a node produces one of three answers: TRUE, FALSE, UNDEF. The first two an- swers indicate \nthat the path along which the query reached the node is correlated. TRUE means that the outcome of the \nconditional along the path is true and FALSE means the opposite. The UNDEF means that the outcome is \nunknown because the variable is assigned an unknown value. For resolving a query, we have identified \nfour sources of static correlation. First, a query is always resolved TRUE or FALSE at a node that assigns \na constant to the variable v from the query. The second source is a conditional branch that involves \nthe variable u. The assertions on variables that exist on the true and false out-edges of the conditional \nmay define the outcome of the predicate in the query. Note that a conditional correlates with itself \nif there is a path around a loop along which the query variable is not defined. The third source is a \ntype conversion from an unsigned to signed value, as in the example in Figure l(a). The result is always \nnon-negative, which may determine the branch pred- icate outcome. Last, after a pointer variable is dereferenced, \nits value is guaranteed to be non-zero; otherwise a segmen- tation fault would have occurred. During \nthe propagation, a copy assignment to the query variable may be encountered, e.g., v := w. When this \nhap pens, the query is modified to reflect this assignment before it continues to propagate. This simple \nform of symbolic back-substitution is essential to capture assignments to and from temporaries, common \nsubexpressions, procedure re-turn values, and parameter passing. As a consequence of this substitution, \nmultiple distinct queries can be raised at a single node. Our analysis can support more general sym- \nbolic back-substitution and is restricted only by the capa- bilities of symbolic manipulation available \nin the compiler. Since query propagation may not terminate under a gen- eral symbolic analysis, we stop \nquery propagation with the UNDEF answer when a sufficient number of nodes has been processed. After the \nanalysis terminates, the resolved queries are rolled back along the paths they traversed. The goal is \nto collect all resolved answers to each query raised at a node. Starting at the successors of nodes where \na query was re- solved, answers are propagated forward and merged by a set-union operation at control \nflow merge nodes. At any node, including the conditional itself, each query may have from one to all \nthree possible answers from {TRUE, FALSE, UNDEF}. For example, if the query raised at the condi- tional \nhas answers TRUE and FALSE, then there are some correlated paths leading to the conditional where the \nout- come is true, some correlated paths where it is false, and no paths along which it is unknown. Such \na conditional has full correlation. The demand-driven framework of [9] computes proce- dure summary nodes \non demand to improve the efficiency of interprocedural analysis. Since in our analysis the queries are \npropagated through procedures backwards, summary node entries are stored at procedure exit nodes and \nfor each query raised at the exit node we maintain: a) the answers resolved in the procedure, and b) \nthe corresponding queries at each entry of the procedure, if the query propagated all the way to the \nentry node. (Remember that the analysis is invoked on a restructured program in which procedures can \nhave multiple entries.) All queries raised at procedure exit nodes are used to compute summary nodes \nand are, there- fore, treated specially. When a summary node query reaches a procedure entry, it is not \npropagated to the callers, but resolved with the fourth kind of query answer, TRANS. This Analyze predicate \n(w relopc) in conditional branch node b 1 initialize Q[n] to {} at each node n 2 form the initial query \nqb = (D, rdOp, c, nil) 3 raiseXpIery(pred(b), qb) 4 while worklist is not empty do 5 remove pair (node \nn, query q) from worklist 6 case n is entry node of a procedure p: 7 if q is a summary node query then \nA[n,q] := TRANS; add q to q.sne.entrieJ[n] 8 else if n has no predecessors then A[n,q] := UNDEF 9 for \neach call site node predecessor m of entry node n do 10 if q is a summary node query for jth exit of \np then 11 if q.sne.gi, is raised at jth exit of m then raise-query(m,q) 12 else raise-query(m, q) 13 \nend for 14 case n is call site exit node: 15 let ez be the procedure exit predecessor of n 16 let m \nbe the call site predecessor of n and en the entry node invoked by m 17 if summary node entry sne[ez,q] \ndoes not exist then 18 let qdn be a copy of q 19 sne[ex, q] := (qsn, ez, 0); qSn.sne := sne[ez,q] 20 \nraise-query(ex, qSn) 21 else if sne[ex,q].entriegen] does not exist then 22 sne[ex,q].entries[en] := \n{} 23 raise-query(ex, sne[ez,q].qin) 24 end if  25 add A[ez, sne[ez,q].q,,] \\ {TRANS} to A[n, q] 26 \nfor each query q. in sne[ez, q].entries[en] do raise-query(m, qo) 27 otherwise : 28 answer := resolve(n, \nq) 29 if ansuIer E {TRUE, FALSE, UNDEF} then A[n, q] := {ansurer} 30 else for each m f Pred(n) do raise-query(m, \nsubstitute(n, q)) 31 end case 32 end while Procedure raise-query(node n, query q) 33 if q $! Q[n] then \nadd q to Q[n]; add pair (n,q) to worklist end Figure 4: The interprocedural static conelation analysis. \nanswer marks paths through the procedure along which the query was not resolved. The procedure is transparent \nalong such paths and the summary node lookup must propagate queries (backward) and collect answers (forward) \nacross caU sites of transparent procedures. Our analysis handles both call-by-value and call-by-reference \nparameters. The analysis algorithm is given in Figure 4. The algo- rithm computes summary nodes without \ninterrupting the anaIysis. Each query is a tuple (u, relop, c, sne), where sne is used by summary node \nqueries to keep a pointer to their summary node entries; for non-summary queries, this field is niL The \nsummary node entry for query q raised at exit node ex is a tuple sne[ex, q] = (qSn, ex,entries), where \nqSn is the summary node query raised on the procedure exit node ex and entrieden] is the set of queries \npropagated to a particu- lar entry node en. The analysis is started at line 3 by raising the initial \nquery at, the predecessor of the conditional to be analyzed. Line 4 terminates the analysis when no node \nwith an unresolved query remains. Lines 6-13 handle procedure entry nodes. Summary node queries are resolved \nhere to TRANS and are added to the summary node entry as having reached the particular entry node, as \ndescribed above. The non-summary query is propagated to aII caII sites of this en- try (lines 9 and 12). \nThe summary node query is propagated only when the computation of the summary node was initi- ated at \nthe exit of the call site (lines 9-11). Lines 14-26 pro- cess a caII site exit node n. Predecessors of \nn are determined according to Figure 3. If summary node lookup in line 17 fails, a new summary node entry \nis created and a summary node query qsn is raised. Lines 21-23 update the summary node after a previous \nsplit of a procedure entry/exit, node. Line 25 resolves the query based on the answers saved in the summary \nnode and line 26 propagates the query across the procedure when a transparent path through the procedure \nexists. Finally, any other kind of node may be a source of correlation (lines 27-30). Function resolve \nattempts to re- solve a query. If it fails, the query is propagated after it is back-substituted. The \nalgorithm for collecting the analysis answers by query rollback can be easily derived from the analysis \nalgorithm, and we omit it from this paper. During the rollback, the upper bound on the amount of code \nduplication required to optimize the conditional is A[(x=O.nil)l=/lJj A[lx=O.nil)]=(F) Alql:(r=O,wlJl=/U,Tr/ \n . .._..__.._......__............ snci:: ql. G, II: sncl:: ql, G. mnies~El=(tx4ml~} j P .: P ~.........__..._.................... \n F A -.......... .: A (a)our-program (b) analysis (-2) mmack Figure 5: An example of interprocedural \ncorrelation analysis. Figure 6: Intraprocedural restructuring. calculated by determining how many copies \nof each node must be created. Given a node with k answers to a query raised at that node, the node must \nbe split k-ways (k is at most 4). When the node hosts more than one query, then the number of copies \nneeded is bound by the cross product of answers to all queries raised at that node. The actual code growth \nis usually lower due to the fact that a node split on one query may separate answers to other queries \nraised at that node. We iIlustrate the analysis with an example in Figure 5. The four possible query \nzmswersare abbreviated in the fig-ure as T, F, U, and Tr, for query answers TRUE, FALSE, UNDEF, and TRANS. \nThe analysis of conditional node P is initiated by raising a query q : (x = 0, nil) at the pre-decessor \nof P (FigureS(b)). The entry nil signifies that the query does not compute a summary node entry. Since \nx is a global variable, it cannot be propagated across the intrapro-cedural edge (C, D). Instead, it \nis raised at the exit of pro-cedure f, where it initiates computation of a summary node entry sne 1. \nThe summary node entry is computed by raising a summary node query q1 : (x = 0, snei) at the procedure \nexit node G. The query is resolved at node F to UNDEF be-cause an unknown value is assigned to x. The \nnodes where a query is resolved are highlighted in the figure. The scope of the summary node is limited \nto the procedure and hence q1 is resolved at the procedure entry node to TRANS. Also, the query is recorded \nin the entries[G] field of the summary node entry. Whenever a summary node query reaches the procedure \nentry, a corresponding query is raised at the call site node. In our case, query q : (x = 0, niZ) is \nraised at node C. This query is subsequently resolved at nodes A and B to UNDEF and FALSE, respectively. \nThe analysis is followed by the rollback phase (Figure 5(c)). The answer for a query q is stored in A[q] \nand consists of all answers for q reaching the node. Note that the UNDEF answer for q at node D was propagated \nfrom node C through the TRANS answer of the summary node query. The foIlowing section and the exam-ple \nin Figure 7 show how the collected answers are used to restructure the ICFG.  3.2 CFG Restructuring \nThe restructuring of the ICFG is performed to isolate cor-related paths and then remove the correlated \nconditionals on these paths. The underlying technique is to split each node on which a query has multiple \nanswers so that each duplicate of the node can host a single answer. Intraprocedural Restructuring. Restructuring, \nwhen the correlation is not affected by a procedure call or return, is similar to that proposed by Mueller \nand Whalley [19] ex-cept that we handle correlations that cut across loop itera-tions. Restructuring \nproceeds in the forward direction start-ing from each node that hosts multiple answers to a query and \nat least on one of its predecessors hosts only a single answer. Figure 6 illustrates intraprocedural \nrestructuring VA VA    di FB FB cf? F.U P A F 1 after anaiysls - prccedu~ 13~4 node spin -canslbnodesptn \n- Figure 7: Interprocedural restructuring. that duplicates a loop; on the left is the source program, \nfollowed by the equivalent CFG labeled with the answers to the query raised at node P: x=0. Restructuring \nstarts at the loop header C and continues until every node hosts only a single query answer. At this \npoint, the correlated path has been separated. In the last step, after the conditional itself is split, \nthe copy of the conditional that hosts the TRUE or FALSE answer is redundant and is removed. Interprocedural \nRestructuring. Because of the repro sentation of the ICFG in our algorithm (see Figure 3), the splitting \nof the procedure entry and exit nodes does not re- quire special handling. Entry splitting occurs when \nthe cor- related path is entering the procedure through a procedure entry node. Entry splitting always \ninvolves call site split- ting. Ezit splitting occurs when a correlated path crosses a procedure exit \nnode. Exit splitting always involves splitting call site exit nodes and requires passing additional return \naddresses to the procedure. Figure 7 illustrates interpro- cedural restructuring. The nodes of the ICFG \nare labeled with answers to the queries raised in the analysis shown in Figure 5. The splitting process \nstarts by duplicating the call site node C, followed by splitting of the call site exit node D. Note \nthat after these two steps the node D , which corresponds to the call site node C , hosts a single answer, \nwhile the node D hosts two answers. After splitting of the procedure exit node G, node D can be split \nagain, resulting in each copy of D hosting a single answer, thus enabling the optimization of the conditional \nP. After the optimization of the conditional is complete, the graph must be converted to call site normal \nform, as defined previously. The last figure illustrates the converted graph. The restructuring algorithm \nis shown in Figure 8. The initial worklist is determined during the analysis phase. Be- fore a node n \nis split under a query q at line 7, it is verified at line 5 that all answers to q that are hosted at \nn are still present at some predecessor of n. The answers may have disappeared if n was previously split \non some other query and some predecessors have been disconnected from n. If an answer was removed at \nline 7, then the call to fix-edges removes edges so that only nodes hosting the same answer for a query \nare connected. The successors of n are added to the workhst when the node is split in order to continue \nsplitting in the forward direction, or when an answer was removed in order to adjust the answers and \nedges at succes- sors. Line 2 terminates the restructuring if there is no node that requires splitting, \nadjusting incident edges, or removing an answer to a query. Procedure split duplicates a node to create \na copy of the node for each answer hosted on the orig- inal node. Each new copy is added to the worklist \nbecause it may still need to be split under the remaining queries raised at the original node. Lines \n15 and 16 perform the actual elimination of the conditional; when the conditional is split under the \nquery that was initially raised on it, the copies hosting TRUE and FALSE answers are fully redundant \nand are removed.  3.3 Complexity and Safety The cost of the ICBE optimization is determined by the \nasymptotic complexity of the correlation analysis. Although the worst-case time complexity for the restructuring \nphase is exponential, it is only polynomial for the correlation anal- ysis. The cost of the analysis \ndominates because ICBE per- forms restructuring only when the required code growth is moderate, resulting \nin the size of the ICFG always remaining Restructure interprocedural CFG to eliminate branch node b \nbegin 1 let worklist be set of nodes n s.t. a query has multiple answers at n and a single answer at \nm E Pred(n) 2 while worklist is not empty do 3 remove a node n from worklist 4 for each query q from \nQ[n] do 5 remove from A[n,q] answers to q no longer hosted at predecessors of n 6 fix-edges(n, q) 7 if \nA[n,q] contains multiple answers then split(n,q) a if n was split or answer was removed from A[n,q] then \nadd Succ(n) to worklist 9 end for 10 end while 11 for each visited call site m do normalize m end Procedure \nsplit(node n, query q) 12 for each answer a from A[n,q] do 13 let n, be a duplicate of n including incident \nedges and Q[n], A[n, *I, sne[n, *] information 14 set A[n4,q] to {a}; add n, to urorlclist 15 if n = \nb and q = qb and a E (TRUE, FALSE} then 16 change n, into empty node and remove edges to false/true successors \n17 end if 18 Ax-edges(n,, q) 19 end for 20 remove n and edges incident on n end Procedure fix-edges(node \nn, query q) 21 remove each edge (m, n) s.t. n and m no longer host a common answer for q end Figure \n8: The interprocedural restructuring algorithm. within a constant factor of its original size. Let V \ndenote the number of program variables, P the number of conditional nodes, and N the total number of \nnodes in the ICFG. When the format of the analyzed predicate expressions is restricted to (uar refop \nconst), and only copy-assignment statements v := w are interpreted, at most V different queries can be \ncreated during the analysis of a single conditional. Con-sequently, at most V queries can be raised at \neach node. In addition, we also have to consider the summary node queries raised at each node. For each \nquery, multiple sum- mary node queries may be raised at each node, one for each exit of the relevant \nprocedure. Since conservative applica- tion of restructuring keeps the number of procedure exits within \nconstant bounds, O(NV) node-query pairs are in- serted into the worklist at line 33 during the analysis \nof each conditional. This results in O(PNV) cost to analyze all conditionals. We should point out that \nthe rollback al- gorithm is bound by the same cost. Even though the data flow problem of static branch \ncorrelation does not conserva- tively merge query answers at confluence nodes (but instead propagates \nforward their set-union), each query can have at most four possible answers. As a result, each node-query \npair needs to be updated at most four times during propa- gation of query answers. The analysis cost \ncan be reduced by caching at all nodes the results of all queries resolved in previous analyses. The \noverall number of queries is bound by 6VC, where 6 is the number of different relational operators and \nC the number of unique literals that appear in predicates of conditionals (C is typically a small number). \nThe cost with query caching is then O(CNV). However, maintaining the cache proved counterproductive in \nour implementation due to increased memory requirements. The ICBE optimization is safe because it never \nincreases the number of operations along any path in the ICFG. How- ever, argument lists of procedures \nwith split exits must be extended in order to communicate alternative return ad- dresses. It is highly \nlikely that eliminating a conditional at the expense of passing additional arguments is advantageous \nbecause return addresses are all compile-time constants and, having no incoming data dependences, argument \npassing in- structions can be scheduled more freely than conditionals. Furthermore, some of the return \naddresses may be unnec- essary at a procedure entry because not all procedure exits may be reachable \nfrom the entry (see Figure l(c)). Alter-natively, if some call site cannot take advantage of the split \nexits in the callee, an unmodified copy of the callee may be called from this call site, eliminating \nthe need to pass additional arguments. 4 Experiments Implementation. We implemented the analysis and \nrestructuring algorithms in our inter-procedural compiler that is based on the retargetable compiler \nICC described in [lo]. Our implementation considered the correlation of those con- ditionals that compared \na scalar variable (not a structure Benchmark source oroeram lines 1 099.go 29 246 124.m88ksim 19 915 \n129.compress 1 934 13o.li 7 597  procedures defined I librarv 372 11 252 35 24 6 357 26 Table 1: Benchmark \nprograms. Benchmark time [set] 1 memory [MB] 11 node-query pairs program overall analysis progreo I \nanalvsis II total I ner cond 099.g0 98.4 83.8 5 -. -, -. ,, ------, ---. - 124.m88ksim 56.1 40.0 67.3 \nI 1.9 Ii 236 252 I 168.8 t Table 2: The cost of correlation analysis. member) with a constant. Overall, \n45% of conditionals in the benchmark programs could be analyzed using this pat-tern. We implemented both \nan intraprocedural optimiza- tion, which used MOD and USE [7j procedure summary information at call sites, \nand the ICBE optimization that considered both intra- and interprocedural correlations. The analysis \nrecognized two sources of correlation: constant as-  signments and conditional branches. Benchmarks. \nThe experiments were performed on the in- teger SPEC95 suite. Since ICC does not generate correct code \nfor the 126 .gcc benchmark, we used ICC itself as a compiler benchmark program. The programs are character- \nized in Table 1. The number of procedures, both defined in the program as well as the library procedures \ncalled are given in the table. The correlation analysis did not analyze library procedures and thus assumed \nthe worst case behav- ior at their call sites. Each node in our representation corre-sponds to a dag \nof multiple operations and may be viewed as a high-level node. Therefore, the ratio of the number of \ncon- ditional nodes to the number of all nodes that are executable is higher than usually reported (last \n2 columns). Note that the number of all nodes in column 5 includes unexecutable label nodes. The dynamic \nprofile information was collected from the ref input set. Behavior of statically detectable correlation. \nWe first performed experiments to determine the amount of stati- cally detectable correlation for paths \nrestricted to a proce- dure and for paths that cross procedure boundaries. The topleft graph in Figure \n9 depicts the number of condition- als that exhibit some correlation; that is, those whose out- come \nis known along some, but not necessarily all, incoming paths. Using the total number of conditionals \nin a program as a base, the graph shows for each program the percentage of conditionals that were analyzable \nusing our implementa- tion, the percentage of conditionals that were found corre- lated using intraprocedural \nanalysis and the percentage that were found correlated using interprocedural analysis. The results show \nthat at least twice as many correlated branches are detected using interprocedural analysis than by using \nintraprocedural analysis. The topright graph presents the same information weighted by the execution \ncount of each conditional, showing that correlation is detected on condi- tionals that execute frequently. \nThe bottom two graphs in Figure 9 show the number of conditionals that had full correlation. The outcome \nof such conditionals is known along all paths and hence they can be completely eliminated; however code \nduplication might be necessary if both TRUE and FALSE correlations are discov- ered. Here, the benefit \nof interprocedural analysis is even more evident. If only fully correlated conditionals were to be optimized, \nthe programs would execute between 3% and 19% less conditionals, while intraprocedural analysis enables \nreduction of only up to 8%. The fact that more useful cor- relation exists when procedures are considered \nsupports our hypothesis that we write procedures in an isolated fashion with repeated computation in \nthe caller and callee. The branch elimination optimizer replicates code to elim- inate conditionals by \ncreating separate paths. Since the amount of code duplication increases with the distance be- tween the \ncorrelated branch and the source of the correla- tion, the extent of code duplication must be estimated \nbefore the interprocedural optimization is applied. Figure 10 plots the cost-benefit relationship for \neach correlated conditional. Each point in the graphs represents one conditional with a correlation. \nThe x-coordinate of the point is the number of nodes that are created due to code duplication when the \ncon- 11 nodes II all I cond 38 806 5 304 21 657 2 416 957 89 10 718 875 11 cond/prog [%] II static I \ndvnamlc I 21.4 29.0 16.5 30.9 13.5 20.9 12.9 26.7 Conditionals with correlation Conditionals with correlation \nstatic cam dynamic wunt Condii with full cofrelation Condiiionais with full correlation static count \ndvnamicm Figure 9: Characteristics of statically detectable branch correlation. ditional is eliminated. \nThe y-coordinate shows the amount of dynamic instances of conditionals that were avoided by the elimination \nof this conditional. A comparison with the intraprocedural results reveals that substantially more cor- \nrelation is detected when procedures are considered, as the full-correlation graphs in Figure 9 suggest. \nBut interpro- cedural correlation also requires more code duplication in many cases because the correlation \nmay span a large part of the call graph. However, the amount of frequently ex- ecuted correlated conditionals \nwith low duplication needs, positioned in the upper-left quadrant, has increased with in- terprocedural \nanalysis. These conditionals make ICBE more beneficial than intraprocedural elimination because with \nless code growth a higher reduction in eliminated banches can be achieved. We estimated the number of \neliminated dynamic instances of each optimized conditional from the execution counts of the nodes where \nthe analysis query was resolved. Eliminated Branches. The goal of eliminating only con- ditionals causing \nreasonable code growth is easily achieved in our approach, for ICBE optimizes conditionals one by one, \nperforming first the analysis and then the restructur- ing optimization for each conditional. The amount \nof code growth necessary to optimize the conditional is determined during the analysis phase, as described \nin Section 3.1. The restructuring phase is executed only if the number of new nodes that must be created \nis less than a predetermined limit. We optimized the benchmarks with various values of the per-conditional \nduplication limit. Each conditional was optimized only if the number of node duplicates required for \nits optimization did not increase N, where N ranged from 5 to 200. Figure 11 shows the amount of conditionals \neliminated and the incurred code growth. Each point in a graph corresponds to one duplication limit value. \nNote the different y-ranges in the bottom row. In this experiment, the analysis was terminated after \n1000 node-query pairs were examined (see line 5 in Figure 4) even though not all queries were resolved. \nSince in each pro- gram there are numerous conditionals that test global vari- ables, early termination \nof demand-driven analysis avoids far-reaching propagation of their queries and dramatically reduces the \nanalysis time. The early termination is made possible by demand-driven analysis. All queries remaining \nafter the analysis termination limit is reached are conser- vatively resolved to UNDEF. Terminating the \nanalysis af- ter 1000 nodes is sufficient to find correlated branches that require up to approximately \n300 duplicated nodes. Even though not all correlation is detected with early termina- tion, the missed \nopportunities are likely to be prohibitive due to high code duplication demands. Terminating the analysis \nearly thus seems to be a practical improvement. However, note that for some values of the duplication \nlimit, the interprocedural analysis may produce worse optimiza- tion for the 134.perl benchmark than \nits intraprocedural counterpart. The reason is that the analysis termination limit was reached by examining \nthe callees, missing the in- traprocedural opportunity. This problem can be alleviated by experimentally \nincreasing the analysis termination limit. Note that the results in Figure 9 and Figure 10 were com- \nputed with an infinite termination limit. We can conclude that: 1) for a given code increase, ICBE can \neliminate significantly more dynamic conditionals than its intraprocedural counterpart; 2) when more \ncode growth can be tolerated, ICBE offers opportunities for additional branch elimination; and 3) the \nper-conditional limit on code duplication is an effective way to control overall code growth. A better \nheuristic for deciding whether to apply the op timization would also consider the amount of conditionals \neliminated, as opposed to the incurred code growth alone, as was done in our experiments. Analysis Cost. \nThe analysis is the dominating component of ICBE s cost. The running time of the analysis that de- termined \nthe results in Figure 11 is given in Table 2. In the column labeled overall time, we give the time spent \nby the compiler in parsing, building the internal program rep intraprocedural intefprccedural code duplication \n[nodes] code duplication [nodes] Figure 10: Contribution to branch removal vs. code duplication requirements \nfor each correlated conditional. resentation and performing the correlation analysis. The third second \ncolumn gives the time to perform the analysis. The memory use listed in the analysis column indicates \nthe amount needed to store the queries and summary nodes. We compare it to the memory required for the \ninternal repre- sentation of the program, listed in the progrep column. The last two columns report the \nnumber of node-query pairs pro- cessed by the analysis, overall and per optimized conditional. 129.comp~ \nto 5 ---------:-------__ 1 . ..,S 10 .....J rm 0D $0 rm 124xn38ksim 13O.H $0 , . Figure 11: Reduction \nin executed conditional nodes vs. pro- gram code growth, for various values of the per-conditional code \nduplication limit.  5 Benefits of ICBE The primary benefit of ICBE is the reduction in the instruc- \ntion count (and the schedule length) through the elimination of correlated conditionals and the operations \nthat compute their predicate. In this section we discuss how both the cor- relation analysis and the \ninter-procedural restructuring can be applied in other areas of compiler optimization. Procedure inlining. \nMost inter-procedurally-visible op portunities for branch elimination can be exploited by inlin- ing \nand subsequent application of intraprocedural elimina- tion of conditionals [19]. However, without the \nknowledge of correlated paths in the call graph, the pre-pass inlining pro- cess must resort to exhaustive \ninlining, at least in the critical program regions. Short of folding alI procedures into a sin- gle, \nflat procedure, there is no guarantee that all statements involved in a correlation will end up within \nthe same pro- cedure, which is necessary to remove the branch. Clearly, pre-pass inlining incurs large \ncode growth. Inlining becomes more practical when it is directed by our inter-procedural correlation \nanalysis. After correlation of a branch is detected, the procedures involved in the cor- relation can \nbe merged by post-analysis inlining. Such a solution to ICBE may be desirable in an existing compiler \nwhere inlining and intraprocedural branch elimination are already supported. The code growth of post-analysis \ninlin- ing may be further lowered by performing full ICBE (with interprocedural restructuring), followed \nby partial inlining [12], in which only frequently executed paths through the optimized procedure are \ninlined. However, inlining of recur- sive, virtual, or library procedures may not be feasible. In this \ncase, our inter-procedural restructuring can be applied to carry out ICBE. Regardless of the exact ICBE \nscenario, the correlation analysis produces an upper bound on the code growth re- quired to eliminate \nthe conditional and, if profile informa- tion is available, provides also a profile-based estimate of \nthe cost-effectiveness of the optimization before it is applied. The inlining algorithm in [2] inlines \nprocedures one by one based on their execution rate until a code growth budget is exhausted. Our correlation \nanalysis can be used in the inliner to give procedures that generate correlation a higher priority so \nthat correlated branches can be removed after inlining [6, 81. Our restructuring algorithm can be used \nto eliminate correlated branches after the code growth budget for inlining has been exhausted because \nits code growth de- mands are smaller than those of inlining. Richardson and Ganapathi [23] observed \nthat the benefit of inlining comes mainly from eliminated procedure call overhead. Our anal- ysis is \nable to identify procedures whose inlining will cre- ate intraprocedural optimization opportunities for \nbranch removal. Dynamic dispatching of virtual procedures. Object-oriented languages complicate interprocedural \ncompilation because call sites invoking member procedures of polymor- phic types may transfer control \nto one of many procedures, depending upon the concrete type of the receiver object. Since such call sites \nrequire expensive dynamic dispatch- ing, methods for their elimination through concrete type inference \nhave been developed [l, 20, 211. In these meth- ods, demand-driven interprocedural analysis determines \nfor each call site the set of reaching concrete types. Subse-quent program restructuring separates out \npaths and clones procedures with the goal of creating call sites reached by a single type of the receiver. \nThere is an analogy between concrete type inference and our work in that both methods compute at optimizable \nnodes the set-union of all optimiza- tion opportunities and enable optimization by making the opportunities \nunique through path separation. While ICBE collects values of variables that determine branch outcomes, \ntype inference is interested in the types of receiver objects. With respect to the restructuring algorithms, \nhowever, our transformation is more powerful than cloning because exit splitting is able to separate \nout paths that cross the exit node, which cloning cannot achieve. The following para- graph describes \nhow entry/exit splitting is performed at dy- namic dispatch call sites. Our restructuring can prove valu- \nable for object-oriented languages because the cost of pass- ing additional return addresses is small \ncompared to that of a dynamic dispatch. While concrete type analysis is very successful in en- abling \ninlining at virtual calI sites, some call sites will still require dynamic dispatch. These call sites \nare, however, amenable to ICBE. Each procedure that may be invoked from a virtual call site can be independently \nanalyzed and optimized by entry/exit splitting. Optimizing in turn each possible callee will provide \nthe cumulative effect of entry/exit splitting in each callee with respect to the original call site. \nWhat results is a set of multiple call sites, each invoking some entry of each callee and returning to \nmultiple points in the caller. If any of the callees was left unoptimized, then all call sites invoke \nthe original entry and the procedure al- ways returns to the original return point in the caller. ICBE \nthus allows both optimized and unoptimized procedures to be called from a single call site. Fine-grain \ncomputer architectures. The elimination of conditional branches is especially important for wide- issue \nsuper-scalar and VLIW architectures, in which instruc- tions are pre-fetched and executed speculatively \nacross con- ditional branches based on predictions of their outcomes. With increasing processor parallelism, \nbranch density in the stream of instructions is becoming critical because expensive mechanisms are required \nto predict and issue multiple condi- tional branches in a single cycle [13]. Our experiments have shown \nthat between 3% and 18% of executed conditionals can be eliminated by ICBE, reducing branch density. \nA mispredicted branch stalls the processor for many cycles and pollutes the instruction cache. Research \nin correlation- based hardware branch prediction [25] shows that unpre- dictable branches exhibit correlation \nwith earlier branches. Some unpredictable branches can arguably be eliminated by ICBE. Consider, for \nexample, a procedure that removes an element from a linked list. When the average list length is low, \nthe conditional that tests for an empty list is unpre- dictable. Nevertheless, the test is correlated \nwith the condi- tional that tests the return value in the caller. Optimization of unpredictable branches \nhas an especially high payoff. ICBE can also be used to improve the effectiveness of software pipelining \n[17,22] by reducing the number of condi- tionals and other statements in the loop body, as illustrated \nby the example in Figure 2. Elimination of branches can significantly speed-up the loop schedule when \nconditionals that form recurrent cycles of control dependencies are elimi- nated. Branches testing a \nflag whose value is assigned within the loop are examples of such conditionals. Assisting hardware branch \nprediction. Run-time pre- diction schemes have been proposed that predict the out- come of a branch using \nits correlation with the last k branches [24]. Since the exact source of the correlation is not known, \nall k outcomes are maintained and used for prediction, slow- ing down the learning process of the predictor. \nIf the cor- relation is statically detectable, our analysis can provide the prediction hardware with \ndirections about which recent branch(es) should be used for prediction. Library procedures. Even when \nit is not possible to com- pile the library procedures together with the application pro- gram, we can \ntake advantage of correlation that crosses the application-library boundary. The library procedures can \nbe pre-split by optimization with respect to characteristic ap- plication programs and the summary nodes \ndescribing the resulting entry/exit splitting can be conveniently stored with the library interface for \nlater lookup during the optimization of the user program. For example, a separate exit from mal- lot \nwould exist that would be taken when the return value is NULL. Since a large portion of correlation exists \nacross calls to the same or related library procedures, the characteristic program may be as small as \nthe one in Figure 1. The orig- inal unoptimized procedure entry must be maintained for library procedures. \nWhen this entry is invoked, all proce- dure exits return control to the standard return address so that \ncompilers without ICBE can also use the library. Interprocedural optimizations. Because path separa- \ntion and entry/exit splitting eliminate control flow merge points, conservative merging of data flow \ninformation at procedure boundaries is reduced. As a result, other opti- mizations, such as procedure \ncloning, partial redundancy and dead code elimination, may be more effective following interprocedural \nrestructuring. The ICBE optimization can be used to optimize array bounds checks [15, 111 which typi- \ncally exhibit correlation. Finally, branch elimination can be used as a component of aggressive program \ntransformations, such as slicing-based partial dead code elimination [4]. 6 Acknowledgement We want \nto thank Mooly Sagiv for his help with prepar- ing the final version of this paper. The comments of the \nanonymous referees aided the presentation of this paper. References [1] Ole Agesen and Urs Hiilzle. Type \nfeedback vs. type inference: A comparison of optimization techniques for object-oriented languages. In \nOOPSLA 95 Conference Proceedings, pages 91-107, Austin, TX, 1995. [2] Andrew Ayers, Robert Gottheb, and \nRichard Schooler. Aggressive inlining. SIGPLA N Notices, 1997. Proceed-ings of the ACM SIGPLAN 97 Conference \non Pro-gramming Language Design and Implementation. [3] Thomas BaU and James R. Larua. Efficient path \npro- fihng. In 29th Annual IEEE/ACM International Sym-posium on Microarchitecture, Paris, fiance, 1996. \n[4] Rastislav Bod&#38; and Rajiv Gupta. Partial dead code elimination using slicing transformations. \nSIGPLAN Notices, 1997. Proceedings of the ACM SIGPLAN 97 Conference on Progmmming Language Design and \nIm-plementation. [S] Preston Briggs and Keith D. Cooper. Effective partial redundancy elimination. SIGPLAN \nNotices, 29(6):159 170, June 1994. Proceedinga of the ACM SIGPLAN 94 Conference on Progmmming Language \nDesign and Implementation. [6] Paul R. Carini. Automatic inlining. Technical Report IBM research Report \nRC-20286, IBM T.J. Watson Re- search Center, November 1995. [7] Keith D. Cooper and Ken Kennedy. Interprocedural \nside-effect analysis in linear time. SIGPLAN Notices, 23(7):574X, July 1988. Proceedings of the ACM SIG-PLAN \n88 Conference on Progmmming Language De-sign and Implementation. [8] Jack. W. Davidson and Anne. M. Holler. \nA study of a C function inhner. Software, Pmctice and Experience, 18(8):775-790, August 1988. [9] Evelyn \nDuesterwald, Rajiv Gupta, and Mary Lou Soffa. Demand-driven computation of interprocedural data flow. \nIn Conference Record of POPL 95: 22nd ACM SIGPLAN-SIGA CT Symposium on Principles of Pro-gramming Languages, \npages 37-48, San Francisco, Cal- ifornia, January 1995. [lo] Christopher W. Fraser and David R. Hanson. \nA retar-getable C compiler: deaign and implementation. Ben- jamin/Cummings, 1995. ISBN 0-8053-1670-l. \n[ll] Rajiv Gupta. A fresh look at optimizing array bound checking. SIGPLANNotices, 25(6):272-282, June \n1990. Proceedings of the ACM SIGPLAN 90 Conference on Programming Language Design and Implementation. \n[12] Richard E. Hank, Wen-mei W. Hwu, and B. Ramakr- ishna Rau. Region-based compilation: An introduc- \ntion and motivation. In 28th Annual IEEE/ACM Inter-national Symposium on Microarchitecture, Ann Arbor, \nMichigan, November 1995. [13] William Johnson. Superscalar Microprocessor Design. Prentice Ha&#38; 1991. \nISBN O-13-875634-1. [14] Jens Knoop, Oliver Riithing, and Bernhard Steffen. Lazy code motion. SIGPLAN \nNotices, 27(7):224-234, July 1992. Proceedings of the A CM SIGPLA N 92 Con- ference on Progmmming Language \nDesign and Imple-mentation. [15] Priyadarshan Kolte and Michael Wolfe. EIimination of redundant array \nsubscript range checks. SIGPLAN Notices, 30(6):270-278, June 1995. Proceedings of the ACM SIGPLAN 95 \nConference on Programming Lan-guage Design and Implementation. [16] Andreas KraII. Improving semi-static \nbranch predic- tion by code replication. SIGPLAN Noticea, 29(6):97- 106, June 1994. Proceedings of the \nACM SIGPLAN 94 Conference on Programming Language Design and Implementation. [17] Daniel M. Lavery and \nWen-mei W. Hwu. Module scheduling of loops in control-intensive non-numeric programs. In Proceedings \nof the 29th Annual Interna-tional Symposium on Microarchitecture, pages 126-137, Paris, fiance, December \n2-4, 1996. [18] Frank Mueller and David B. WhaIley. Avoiding uncon-ditional jumps by code replication. \nSIGPLAN Notices, 27(7):322-330, July 1992. Proceedings of the ACM SIG-PLAN 92 Conference on Progmmming \nLanguage De-aign and Implementation. [19] Frank Mueller and David B. WhaIIey. Avoiding con-ditional branches \nby code replication. SIGPLAN No-tices, 30(6):5646, June 1995. Proceedinga of the ACM SIGPLAN 95 Conference \non Progmmming Language Design and Implementation. [20] John Plevyak and Andrew A. Chien. Precise concrete \ntype inference for object-oriented languages. OOP-SLA 94, ACM SIGPLAN Notices, 29(10):324335, 1994. [21] \nJohn Plevyak and Andrew A. Chien. Type directed cloning for object-oriented programs. In Eighth An-nual \nWorkshop on Languagea ond Compilers for Por-ollel Computing, Lecture Notes in Computer Science, volume \n1033, pages 566-580, Columbus, Ohio, August 1995. [22] B. Ramakrishna Rau and C. D. Glaeser. Some schedul- \ning techniques and an easily schedulable horizontal ar- chitecture for high performance scientific computing. \nIn Proc. 14th Annuol Workshop on Microprogramming, pages 183-198, 1981. [23] Stephen Richardson and Mahadevan \nGanapathi. Inter- procedural analysis versus procedure integration. Zn-formotion Processing Letters, \n32(3):137-142, 1989. [24] Stuart Se&#38;rest, Chih-Chieh Lee, and Devor Mudge. Correlation and abasing \nin dynamic branch predictors. In Proceedings of the &#38;St-d Annuol Intemotional Sympo-sium on Computer \nArchitecture, pages 22-32, Philadel- phia, Pennsylvania, May 22-24, 1996. [25] Cliff Young, Nicolas Gloy, \nand Michael D. Smith. A comparative analysis of schemes for conelated branch prediction. In Intl. Symposium \non Computer Architec-ture, Italy, 1995.   \n\t\t\t", "proc_id": "258915", "abstract": "The existence of statically detectable correlation among conditional branches enables their elimination, an optimization that has a number of benefits. This paper presents techniques to determine whether an interprocedural execution path leading to a conditional branch exists along which the branch outcome is known at compile time, and then to eliminate the branch along this path through code restructuring. The technique consists of a demand driven interprocedural analysis that determines whether a specific branch outcome is correlated with prior statements or branch outcomes. The optimization is performed using a code restructuring algorithm that replicates code to separate out the paths with correlation. When the correlated path is affected by a procedure call, the restructuring is based on procedure <i>entry splitting and exit splitting</i>. The <i>entry splitting</i> transformation creates multiple entries to a procedure, and the <i>exit splitting</i> transformation allows a procedure to return control to one of several return points in the caller. Our technique is efficient in that the correlation detection is demand driven, thus avoiding exhaustive analysis of the entire program, and the restructuring never increases the number of operations along a path through an interprocedural control flow graph. We describe the benefits of our interprocedural branch elimination optimization (ICBE). Our experimental results show that, for the same amount of code growth, the estimated reduction in executed conditional branches is about 2.5 times higher with the ICBE optimization than when only intraprocedural conditional branch elimination is applied.", "authors": [{"name": "Rastislav Bod&#237;k", "author_profile_id": "81100033082", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "P239460", "email_address": "", "orcid_id": ""}, {"name": "Rajiv Gupta", "author_profile_id": "81100027751", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "PP39072720", "email_address": "", "orcid_id": ""}, {"name": "Mary Lou Soffa", "author_profile_id": "81452611636", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "PP39032772", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258915.258929", "year": "1997", "article_id": "258929", "conference": "PLDI", "title": "Interprocedural conditional branch elimination", "url": "http://dl.acm.org/citation.cfm?id=258929"}