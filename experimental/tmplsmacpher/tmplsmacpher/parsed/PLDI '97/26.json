{"article_publication_date": "05-01-1997", "fulltext": "\n Register Promotion in C Programs Keith D. Cooper and John Lu Department of Computer Science Rice University \n Houston, Texas 77005 Abstract The combination of pointers and pointer arithmetic in C makes the task \nof improving C programs somewhat more difficult than improving programs written in sim- pler languages \nlike Fortran. While much work has been published that focuses on the analysis of pointers, little has \nappeared that uses the results of such analysis to improve the code compiled for C. This paper examines \nthe problem of register promotion in C and presents experimental results showing that it can have dramatic \neffects on memory traflic. 1 Introduction The presence of pointer-valued variables in C has long been \nrecognized as an impediment to effective compile-time optimization. Pointers introduce a degree of un-certainty \ninto the results of static analysis. Pointer as-signments create multiple names for storage locations, \nwith the result that the compiler must avoid reordering stores to memory. Pointer arithmetic introduces \nfurther ambiguity; understanding the results of *(p+8) requires a detailed knowledge, at compile-time, \nof the run-time storage layout. In the case of values stored in the heap, such knowledge is tenuous at \nbest. This uncertainty, coupled with separate compilation, forces compilers to treat variables with potentially \nexposed addresses quite conservatively. As a result, C compilers often produce code that would appear \nnaive to a good assembly-level programmer. Recent attempts to address this problem have fo-cused on the \nproblem of analyzing the values that can be This material is based in part upon work supported by the \nTexas Advanced Technology Program under grant number 003604-015 and by DARPA through Army Contract DABT6595-C-0115. \nPermission to make digital/hard copy of part or all this work for personal or classroom use IS granted \nwithout fee provided that copies are not made or distributed for profit or commercial advan- tage, the \ncopyright notice, the title of the publication and its date appear, and notice is given that copying \nis by permission of ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute \nto lists, requires prior specific permission and/or a fee. PLDI 97 Las Vegas, NV, USA 0 1997 ACM 0-89791-907-6/9710006...$3.50 \ntaken on by pointer variables. The literature on pointer analysis has expanded greatly in recent years \n[M, 8,22, 5, 14,9, 12,6, 131. This paper presents a technique for using the results of pointer analysis \nto make the code generated by a C compiler run faster. We call the tech-nique register promotion; quite \nsimply, it uses the re-sults of pointer analysis to determine which scalar vari-ables can be safely kept \nin registers and rewrites the code to reflect those facts. To study the problems introduced by pointer \nvari-ables, we have built a pointer analyzer for our experi-mental compiler. It performs static analysis \nto derive information about which variables might be addressed by a specific pointer. To assess the value \nof register promotion, we implemented it and tested it using two forms of pointer analysis. The experimental \nresults sug-gest that register promotion can be quite effective at re-ducing memory traffic; they also \nshow that these results are relatively insensitive to the precision of the pointer analysis.  2 Background \nDuring translation, the compiler makes many decisions that determine the shape of the code that is even-tually \ngenerated. A particularly important decision re-lates to the storage of values; the compiler must deter-mine, \nfor each value, where it will reside at run-time. To simplify matters, we will assume that only two choices \nare possible: in memory and in a register. Since reg-isters are faster to read and write than memory, \nit is generally desirable to keep values in registers. Thus, modern RISC-style compilers try to keep \nas many values in registers as possible. This decision gets encoded into the shape of the intermediate \nlanguage (IL) generated for each statement, usually as an explicit assignment of a virtual register to \neach distinct value. Definitions target this register and uses refer to it directly. Of course, different \nlocations in memory, such as the heap and the stack, may have different properties and different costs. \nLoads Stores Purpose iLoad - immediate load a known constant value cLoad - constant load an invariant, \nbut unknown value sLoad sStore scalar load/store a value known to be scalar Load store general load/store \ngeneral form Table 1: Hierarchy of memory operations Situations can arise that prevent retention of \na value in a register across statement boundaries. For example, if multiple names exist for a value, \nit must be stored to memory after every definition and loaded from memory before each use. The presence \nof pointers introduces precisely this problem; in the absence of specific knowl-edge about the set of \nvariables that can be referenced by each pointer, the compiler is forced to treat references to any stooge \nthat the pointer might possibly address in this conservative fashion. In our compiler, like many other \nRISC-style compilers, this conservative treatment is enforced by inclusion in the intermediate code of \nex- plicit stores and loads for the values that cannot be enregistered safely. To improve this situation, \nthe com-piler can analyze the code to improve its knowledge, and use this information to promote some \nvalues from memory into registers. The IL for our research compiler contains several fea-tures that encode \ninformation to facilitate analysis and optimization of memory-based values. Each memory operation has \nan associated list of tags ; these are tex-tual names that identify the memory locations that can be \nused by the operation. Procedure calls have lists of modified tags and referenced tags to record their \nsum-mary side effects [7]. Finally, the IL contains a hierarchy of memory instructions that denote increasingly \nmore specific knowledge (see Table 1.) When it emits the IL, the front end encodes the best information \nit has into the tag field and the opcode. In many cases, however, it must behave conservatively and assume \nthat an opera-tion may reference any memory location. The informa-tion encoded in the tags is part of \nthe IL representation of the code and is available to every subsequent phase of compilation. The key \nto improving the quality of code generated for pointer-based operations is to improve the preci-sion \nof these tag sets. To achieve this, we implemented a pointer analyzer. It performs interprocedural data-flow \nanalysis to discern better information about the addresses that each pointer variable can contain. This \nknowledge can improve the compiled code in two ways. First, it lets the compiler shrink the tag sets \nof many loads and stores. This produces better results from sev-eral of the optimizations. Second, specific \ntransforma-tions can capitalize directly on the pointer information to rewrite the code in ways that \nclassical techniques can-not. This paper describes one such technique, register promotion. 3 Register \nPromotion Register promotion improves code by allowing a value that normally resides in memory to reside \nin a register for some portions of the code. This is done by identify- ing sections of the code in which \nit is safe to place the value in a register. Before entering such a section, the value is promoted (i.e. \nloaded) from its memory loca-tion to a register. Within the section, references to this value are rewritten \nto refer to the register. Upon exit from the section, the value is demoted (i.e. stored) to a memory \nlocation. The compiler performs promotion in the early phases of optimization (see 5 5). It rewrites \nthe IL to keep ad-ditional values in a register. However, subsequent ac-tions by the register allocator \ncan undo a promotion. At the time that promotion occurs, the compiler can-not accurately predict the \navailability of a register to hold the promoted value. If the register allocator dis-covers that demand \nfor registers exceeds supply, it must spill some values back to memory. The promoted val-ues compete \nfor registers on an equal footing with other values; nonetheless, some of them may get spilled. 3.1 The \nAlgorithm The algorithm that we have developed is relatively sim- ple. It proceeds as follows: 1. interpmceduml \nanalysis-The compiler performs an interprocedural analysis to disambiguate mem-ory references. The results \nare used to shrink the tag sets for references and procedure calls. 2. gather initial information-For \neach block b, the compiler computes two sets. BBXPLICITb con-tains all tags referenced by an explicit \nmemory operation in b. BABBIGUOUSb contains all tags referenced ambiguously in b, through procedure calls \nor pointer-based memory operations where the pointer contains multiple tags. 3. find loop structure-The \ncompiler computes dom-inator information to identify loop nests using an algorithm due to Lengauer and \nTarjan [15]. 4. analyze loop nests-For each loop 1, the compiler solves the equations shown in Figure \n1. The set  LJlXPLICITl = UBJiXPLICITb (1) bEI LAHBIGUOUS~ = UBAl4BIGUOUSb (2) W LJ'ROHOTABLQ = L_EXPLICITl \n(3) -LAHBIGUOUS~ LJ'ROHOTABLQ if 1 is an outermost loop L_LIFTl= (4 LPROBOTABLEJ-LPROnOTABLE,,,,,,djn~~~~(~) \n otherwise Figure 1: Equations for Register Promotion LSROHOTABLEIcontains the tags that may safely be \npromoted inside loop 1. rewrite the code-For each tag that is in some LPROHOTABLEI,a virtual register \nv is created. All references to the tag in loops for which the tag is promotable are converted to a copy \ninvolving v.~ promote the tag-A tag that has had its accesses rewritten to use a virtual register must \nbe loaded into its virtual register before entering the outer-most loop in which it is promotable. It \nalso must be stored to at the loop exits. The set of tags that needs to be loaded and stored around a \nloop 1 is in LLIFTi. The equations from Figure 1 merit some additional ex-planation. BBXpLXGXTb and B_ABBIGUOUSb \nare com-puted in a simple linear pass over each block. The pass must examine each operation and its tag \nset. Equa-tions (1) and (2) simply aggregate together the infor-mation for all the blocks in a loop. \nEquation (3) is solved once per loop; it computes the set of values that are only referenced explicitly \nin the loop. If a tag t is in LPROMOTABLElfor loop 1, the loop can be rewritten safely to keep the value \nassociated with t in a register. Finally, equation (4) ensures that a tag t is only loaded and stored \naround the outermost loop where it may be promoted. What have we accomplished? As presented, the al-gorithm \npromotes references to a scalar variable in a loop if all the references to the scalar variable in the \nloop are explicit. It does not promote references based on pointers that may point to multiple objects; \nneither does it promote array references. The promoted vari-ables are scalars that the compiler did not \nenregister be-cause it lacked the information to show that enregister-ing them was safe. Section 3.3 \ndiscusses one technique The copies are subject to coalescing by the register allocator [l]. It is quite \neffective at eliminating copies like these. for extending the domain of promotion to include some array \nand more pointer-based values. The algorithm only examines references inside loops; our implementa-tion \nof partial redundancy elimination[l7j uses memory tag information to achieve most of the effects of promo- \ntion in straight-line code. What does this algorithmcost? The cost of the inter-procedural analysis used \nto support register promotion varies with both the algorithm used and the desired pre-cision of the information \n(See Sections 4 and 5). The promotion algorithm itself runs efficiently. Its complex-ity is expressed \nas a function of the following variables that characterize a program. C code size T number of tags L \nnumber of loops X maximum number of exits in a loop B number of basic blocks E number of edges in CFG \nComputing BEXPLICIT and BABBIGUOUS takes a sim-ple pass over the code. In each block, it examines each \nstatement and, possibly, each tag set. This requires O(CT) time, worst case. The dominator algorithm \nused to find the loop structure can be implemented to re-quire O(Ea(E, B)) time, where a(E, B) is related \nto a functional inverse of Ackermann s function [15]. Com-puting L-EXPLICITand LAIIBIGUOUSrequires O(LBT) \ntime, while LSROMOTABLEand L-LIFTrequire O(LT) time. Rewriting the code requires O(C) time to con-vert \nmemory operations to copies, plus O(TLX) time to insert loads and stores at loop landing pads and loop \nexits. Thus, the overall time bound is O(CT + Ea(E, B) + LBT + LT + C + TLX), which simplifies to O(Ea(E, \nB) + T. (C + LB + LX)). In practice, it runs quite quickly. BO 1 SLD CC1 + rc 1 I I 4 I I Bl SST CC1 \nr0 Bl CP rO -+ rc JSR [Al JSR [Al -PLD CB 21 + ri PLD CB 21 + rl t-l I 4 4 B2 B2 SLD CA] + ra 4 4 B3 \nSST [Bl r2 -83 SST CBI r2 4 Register B4 JSR [Bl B4 Promotionb 4 B5 SLD CA] + r3 v B5 4 B6 B6 B7   4----Pl \n- I SST CA] ra B8 I t- B9 Fssr[clrc Loop Nest and Relevant Code Block Information Set 0 Bl B2 B3 B4 \nB5 B6 B7 B8 B9 B-EXPLICIT C B A BAIBIGUOUS ABZ B Figure 2: An Example for (i=O; i<DIM-X; i++) { B[i]=O; \nfor (j=O; j<DIM-Y; j++> ( B Gil +=A Gil Cjl ; 1 Originalcode Figure 3: Promoting 3.2 An Example To \nmake this discussion more concrete, consider the ex-ample shown in Figure 2. It shows a triply nested \nloop, along with some of the code that populates the loop. (The remaining code is assumed to have no \nimpact on the example.) The instructions are presented in an ab- stracted form; each shows its tag list \nfollowed by any relevant registers. The mnemonics have simple mean- ings. SST Scalar store SLD Scalar \nload CP Register copy PST Pointer-based store PLD Pointer-based load ElJSR Jump to subroutine The version \non the left shows the code before register promotion. The version on the right shows the results of register \npromotion. Notice that each loop has an explicit landing pad before its header and an explicit exit block. \nOur compiler automatically inserts landing pads and exits as part of constructing the control-flow graph; \nempty blocks are automatically removed after optimization. Loops are referred to by the block number \nof their headers. The tables at the bottom of the figure show the local information computed for the \nexample, B-EXPLICIT and B4RBIGUOUS, as well as the sets computed for the loops. The LSROXOTABLE and LLIFT \nsets concisely summa-rize the situation. The value associated with tag A is promotable in the two inner \nloops but not the outer loop. The JSR instruction in block Bl references A am- biguously, so it cannot \nbe promoted in that loop. The value associated with tag B is referenced ambiguously in loop B3; since \nit is not referenced in loop B5, no opportunity for promoting it exists. Finally, the value associated \nwith tag C is never referenced ambiguously. Since it is referenced in the outer loop (Bl), it is pro- \nmotable in that loop. The LLIFT set correctly shows for (i=O; i<DIH-X; i++) ( rb=O; for (j=O; j<DIM-Y; \nj++> { rb+=A [i] [j] ; 1 BCil=rb; 1 Transformedcode Array References that A should be promoted in \nB3 rather than B5 since loop B3 contains loop B5. When the compiler rewrites the code, it promotes C \nin loop Bl and A in loop B3. Thus, it inserts a scalar load of C into rc in loop Bl s landing pad (block \nBO) and a scalar store into loop Bl s exit block (B9). The store in block Bl becomes a copy into rc. \nTo promote A, it inserts a scalar load of A into ra in loop B3 s landing pad (B2), and a scalar store \ninto loop B3 s exit block (B8). The load in B5 becomes a copy out of ra. The other instructions remain \nunchanged. The net result is to replace the scalar load in the innermost loop with a copy operation and \na load/store pair two loops farther out. The scalar store in the outer loop is replaced with a copy operation \nand a load/store pair outside that loop. In many cases, the register allo cator can coalesce away these \ncopies.  3.3 Handling Pointer-based References The algorithm from Section 3.1 only promotes scalar variables \nthat are only explicitly referenced. Pointer-based loads and stores that may point to multiple lo cations \ncannot be modified. Consider, for example, the code shown on the left hand side of Figure 3. The in-ner \nloop uses a single value of BCil per iteration of the outer loop; since i does not change, the address \nof B Cil is invariant. Thus, the compiler should rewrite the code as shown on the right by promoting \nB Cil into a register rb. This eliminates a load before the reference to BCil in the inner loop and a \nstore after it. To achieve this, however, the compiler must recognize that BCil refers to the same location \nin each iteration of the inner-loop and that only one way to reference the code is possible in the inner \nloop. The analysis described earlier cannot do that. We developed another algorithm to promote some pointer-based \nreferences to multiple locations. In par-ticular, it finds memory references, P, where the base register, \nb, is invariant in a loop and the only accesses in the loop to the tags accessed by r are through the \ninvariant base register b. This algorithm relies on loop-invariant code motion to identify the loopinvariant \nbase registers and place the computation of these registers outside a loop. When it finds memory references \nsatis-fying these conditions, it promotes the reference into a register using the same rewriting scheme \nas before-a load before each loop entry, a store at each loop exit, and a copy at each reference. These \nconditions include the example from Figure 3. Anecdotally, the pointer-based promotion scheme is a success. \nWhen its conditions apply, it produces the code that might be expected of a good assembly pro-grammer. \nFor example, it produces a loop equivalent to the transformed code shown in Figure 3, after coalescing \nremoves the copy operations. In our suite of test pro-grams, however, the measured improvements were \nnot overwhelming when compared with scalar promotion. For total operations executed, pointer-based promotion \nhurt performance for one program and had no effect on nine others. The improvements in three of the other \nfour programs were less than 1% of the improvement due to scalar promotion. In fft, the only significant \nsuccess, pointer-based promotion was able to remove 48.3% more operations, 48.3% more stores, and 48.4% \nmore loads than scalar promotion was able to remove. This accounted for 0.41% of the stores and 0.34% \nof the loads in the execution of fft. The reason for this disap pointing performance may be that the \nrestrictions are too strict; it may be that the promotable pointer-based references in our collection \nof programs are relatively unimportant to performance. We intend to continue to investigate this set \nof problems. 3.4 Planned Improvements Our current register promoter misses some opportuni-ties. We are \ninterested in extending this work to in-crease its coverage of real programs. . The loopbased approach \nto analysis and transfor-mation causes the promoter to overlook situations that occur outside loop nests. \nThere should be many cases where it is profitable to promote val-ues to registers in straight-line code. \nIn our compiler, partial redundancy elimination catches many of these cases in straight-line code. It \nuses the tag fields to eliminate redundant loads. It must treat stores more conservatively. Extend-ing \nthe promoter could improve the behavior for these stores. . The array references handled by the scheme \nde-scribed in Section 3.3 catches a set of relatively simple cases. Some of the more complex examples \nrequire detailed dependence analysis or an equiva- lent technique to reason about conflicts with other \nreferences to the same array inside the loop [ll, 161. For example, Carr used dependence analy-sis to \ndetect consistent patterns of cross-iteration reuse in Fortran and to promote the correspond-ing values \ninto scalar temporaries that ended up in registers [2]. We are interested in expanding the set of array \nreferences promoted by the compiler. Our work to date has focussed on poor code that results from lack \nof information about the behavior of other procedures and pointer-based memory operations. As we delve \ndeeper into array promotion, we will need to improve our analysis of subscripts. As in any experimental \nstudy, examining the code that comes out of the compiler suggests additional areas of improvement. Further \ncases for improvement will sug-gest themselves as we continue this work. However, we must sound a note \nof caution. Regis-ter promotion increases the demand for registers-often called register pressure. As \nwe improve the promoter, we increase its ability to generate an intermediate code program that requires \nspilling in the register allocator. Carr discovered this effect in his work on scalar replace-ment in \nFortran [3]; beyond some point, the memory ac-cesses removed by the transformation were balanced by the \nspills added during register allocation. He adopted a bin-packing discipline to throttle the promotion \npro-cess. As we extend our work, we will undoubtedly en-counter the same problem and need a similar solution \nto moderate register pressure. 4 Our Approach to Analysis To test our ideas, we implemented two forms \nof inter- procedural analysis: interprocedural MOD/REF analysis and a points-to analysis. The results \nof analysis are used to limit the size of the tag sets for pointer-based memory operations and function \ncalls. The MOD/REF analyzer starts by limiting the tag sets of pointer-based memory operations in two \nways. First, only tags that have had their address taken are placed in the tag sets of pointer-based \nmemory oper-ations. The front end identifies these tags. To fur-ther limit the tag sets, it only places \nthe tag of a local variable into the tag sets of memory operations that appear in descendants of the \nfunction that creates the local variable. Indirect calls are conservatively assumed to target any addressed \nfunction. Once pointer-based memory operations are limited, the tag sets of function calls can be limited. \nA function call receives the tag set of the called function. A function s tag set is the union of the \nsets of tags that it uses or its descendants in the call graph use. To compute function tag sets, the \n 5 Experimental Results I Promam I Lines I Descriotion I i tSD 1 760 1 a travelinn salesman problem \nI indent allroots bc LO hiion b-97 geb 5955 215 7583 28553 10179 19842 7331 prettyprinter for C programs \npolynomial root-finder calculator language from GNU game DroPram from SPEC benchmarks LR(1) parser generator \ngraphics compression code from SPEC file compression program Figure 4: Program Descriptions algorithm \nidentifies the strongly-connected components (SCC)of the call-graph, and calculates the tag set of each \nSCC.Inside an WC, all the functions have identi-cal tag sets. Processing the sccs in reverse topological \norder ensures that the tag set of any called function not in the current scc has already been calculated.3 \nOur approach to pointer analysis is similar to Ruf s work [18]. We analyze the entire program at once. \nEach function is converted into SSA form. For each SSA name, the analyzer determines the set of tags \nto which it may point. This is done by initializing SSA names with the pointer values they may initially \nhave. Pointer values are propagated through the program using a worklist algorithm. Non-local memory \nis modeled with explicit names rather than representative names. Heap memory is modeled with a single \nname for each call-site that can generate a new heap address. The analysis is context-insensitive. The \neffects of recursion are approximated. Addressed locals of recursive functions are represented with a \nsingle name. Since this one name represents multiple locations, strong updates are not possible. Once \nthe analyzer has found a set of possible pointers for each pointer-based memory operation, it can calcu-late \na more restrictive set of tags for each pointer-based memory operation. MOD/REF analysis is then repeated, \nusing the new tag sets for the pointer based-memory op erations. This algorithm seems quite simple. The \nequations for MOD and FiEF are drastically simplified by C s lack of call-by-reference param-eters [7J. \nTo understand the impact of register promotion, we compiled 14 C programs using our laboratory compiler \n(see Figure 4). Four versions of each program were pre-pared, using the combinations of scalar promotion, \nno scalar promotion, MOD/REF analysis, and pointer anal-ysis. Each version was optimized with value numbering, \npartial redundancy elimination, constant propagation, loop invariant code motion, dead code elimination, \nreg-ister allocation, and a basic block cleaning pass. Each version was instrumented to record the total \nnumber of operations executed, stores executed, and loads exe-cuted. These results are shown in Figures \n5, 6, and 7. Note that these numbers are for whole programs, rather than individual procedures. The principal \neffect of register promotion is the re- moval of memory operations-stores and loads. The fig- ures for \ntotal operations executed show small improve- ments in some applications. Figures 6 and 7 provide a \nmore precise picture of the impact of promotion. In several of the applications, promotion removed a \nlarge fraction of the stores and many of the loads. In other applications, it found few, if any, opportunities. \nWhen it found opportunities, the promoter often made signif-icant improvements. If memory operations \ntake more cycles than other operations, as in many modern ma-chines, the positive impact of promotion \nwill be greater. In some cases, the net effect of promotion was a mi- nor performance degradation. Degradation \nwas caused by two effects, promoting rarely used or conditionally used values and increasing register \npressure. For ex-ample, in dhrystone, values were promoted in a loop that always executed once, and in \nbison, values were promoted that were only accessed on an error condi-tion. In water, register promotion \nwas able to promote twenty-eight values for one loop nest. Unfortunately, this caused the register allocator \nto spill values which resulted in a performance loss compared to no register promotion.4 Most of the \nimprovements were the result of global variables which are normally placed in memory being promoted to \nregisters. The results also show that the improved information derived from pointer analysis does not \ngreatly improve the results of register promotion. This does not war-rant a conclusion that pointer analysis \nis unprofitable; it does suggest that MOD/REF analysis is a good basis for evaluating the benefits of \nimproved analysis. For example, register promotion removed 2.8 million loads from one function in mlink. \nThis particular im-provement did not require the extra precision provided It might be expected that the \nallocator would simply spill some sub-set of the twenty-eight promoted values and avoid the actual perfor-mance \ndegradation. Our compiler uses a graph-coloring allocator [l]. These allocators are known to over-spill \nin tight situations. Program analysis without with difference % removed t=P modref 657067 657067 0 0.00 \npointer 651283 651283 0 0.00 L mlink modref 132386726 126902038 5484688 4.14 pointer 130108670 124562634 \n5546036 4.26 iit modref 12636489 12635955 534 0.00 nointer I 12575809 I 12558866 I 16943 I 0.13 n Y \npointer 12934445 12935195 -750 -0.01 indent modref 869492 865766 3726 0.43 pointer 869609 866171 3438 \n0.40 II allroots modref 1011 1011 0 0.00 nointer I 3344839 I 3345288 I ,1 Lmodref 1I 37071266 1 37071326 \nI1 -60 I1 0.00 II nointer I 37070488 I 37070548 I -60 I 0.00 II gzip(enc) modref 5813661 5712142 101519 \n1.75 pointer 5804903 5679946 124957 2.15 nzip(dec) modref 984570 1 984770 -200 -0.02 II--nointer I 984202I \n984257I -55 I -0.01 n Figure 5: Total Operations by pointer analysis; note, however, that pointer analysis \nis not promotable with just MOD/REF analysis. Pointer did enable other improvements in mlink. An example \nanalysis can discover that the stores through ~2 cannot where pointer analysis was required to promote \na value modify Tl, and thus Tl can be promoted. arose in fft. Finally, some of the improvement due to \nregister pro- motion was hidden because other passes in the opti- for (I = begin; I < end; I++) mizer \nachieve similar results. For example, loop invari- for (J = 0; J < N3; J++> ant code motion can remove \na load of a constant value for (K = 0; K < Ni; K++) out of a loop. Register promotion s main benefit \nseems c to be transforming multiple stores of a promoted vari- index3 = (I*NB+J)*Nl+K; able in a loop \nto a single store at the loop s exit, an index1 = (I*N3+J)*Ni*2+K; effect that other optimization passes \ncannot achieve. Tl = pow(X3Cindex31, (double) KT) ; X2 [indexi] = Tl * XiCindexil ;  6 Related Work \nX2 Cindexl+Nll = Tl * XlCindexl+Nll ; 3 The literature contains prior work that relates to our work \nin two broad categories: techniques that use im-Ti s address is taken elsewhere in this code. X2 is a \nproved analysis to enregister more values and methods pointer so the stores through it may modifyT1. \nThus Ti for disambiguating memory references in the presence The work on pointer analysis is somewhat \nperipheral of pointers. The goal of our work is to enregister values to this paper. Our effort has focussed \non discovering that the compiler placed in memory because it lacked ways to profit from pointer disambiguation. \nHowever, the information to safely place them in registers. When since pointer analysis has received \nso much attention in the algorithm discovers such a value, it allocates a new the literature, some comparisons \nwith previous work in virtual register and rewrites the code accordingly. This that arena are warranted. \nMany papers have described work is similar to Carr s work on scalar replacement techniques for discerning \ninformation about the side ef-in Fortran [2,4,3]. Carr developed a source-to-source fects of memory operations \nthrough pointer variables. translator that used dependence information to pro-Our work is based on points-to \nanalysis; earlier work, mote array elements that are reused across different it-like Landi and Ryder \n[13];, Choi, Burke, and Cytron [6]; erations of the loop. To force the value into a register, and Deutsch \n[B]cast the problem in an aliasing frame-he rewrote the code using a scalar temporary, subjecting work. \nAlgorithms for computing points-to informa-his results to the vagaries of subsequent optimization tion \nhave been described by Emami, Ghiya, and Hen-and register allocation. Our technique works from data-dren \n[12]; by Wilson and Lam [22]; aand by Ruf [18]. flow information rather than dependence and promotes \nSteensgaard showed a linear-time algorithm for per-a different set of references (scalar values and pointer \nforming a flow-insensitive points-to analysis by casting references based on loop invariant base registers). \n2142 it as a type-inference problem [20]. Other papers have tsp modref 51049 51049 0 0.00 lJ pointer \n51049 51049 0 0.00 mlink modref 5885109 2506412 3378697 57.41 I nointer I5885454 12358048 I 3527406I \nt fft Imodref 1036669 1036401 268 0.03 pointer 1016181 1007706 8475 0.83 clean modref pointer , ] 86889~~~~ \n86888 84035 84034 2854 2854 3.28J 3.28 caches im modref I 594474 594474 0 0.00 nointer I 594474 I 594474 \nI 01 0.00 Ii 1 , dhrystone modref 1 60012 60012 0 0.00 nointer I 56012 56012 0 0.00 Y water modref 1080062 \n1080060 2 0.00 pointer 1064672 1064605 67 0.01 indent modref 71302 68462 2840 3.98 nointer 71302 68462 \n2840 3.98 allroots modref 11 11 0 0.00 pointer 11 11 0 0.00 bc nointer modref I I 273916 273922 I I 249727 \n249732 I I 24189 24190 I I 8.83 H 8.83 .- , pointer 274718 199108 75610 27.52 gzip(dec) modref 17575 \n17389 186 1.06 pointer 17575 17243 332 1.89 Figure 6: Stores /I Program I analysis I without I with \n1 difference I % removed fl I dhrystone modref 62024 62024 0 0.00 pointer I 54024 54024 0 0.00 pointer \n838366 818341 20025 2.39 RO modref 1954619 1650736 303883 15.55 1 I I I nointer I 1877295 I 1573600 I \n303695 I 16.18 H , . I I I ~~~~-~ I bison I modref I 553970 I 553728 I 242 1 0.04 tl pointer I 552830 \nI 552588 I 242 I 0.04 H ysis. These numbers are not a general indictment of pointer analysis; they simply \nshow that increased pre-cision did not significantly change the results from our transformation. Little \nprior work compares the results obtained by using a fixed set of transformations with different precisions \nof program analysis. One notable exception is David Wall s work on available instruction level parallelism \n(ILP)[21]. Wall estimated available ILP under a set of five different assumptions for the quality of \nanalysis available in the compiler. His results suggest that increased precision in the analysis of pointers \ncan have a significant impact on the amount of ILPdiscov-ered by a compiler. Figure 7: Loads looked at \nthe problem of deriving better understanding analysis. The following table summarizes these differ- of \nthe shape of objects in the heap; two of the most ences. For parameter binding, the methods either \nprop recent are by Ghiya and Hendren [lo] and Sagiv, Reps, agate representative names or explicit names. \nThe heap and Wilhelm [19]. is either modeled as a single name or it is split on some Each of these techniques \nhas strengths and weak- criteria, like the call path that reaches the allocation nesses. We chose to \ncompute points-to rather than site or the specific call site causing the allocation. Fi- aliasing because \nwe felt that it more closely corresponds nally, they differ in the amount of information about to the \nproblem that we were addressing in the compiler. call paths that they associate with names. It also handles \nfunction pointers in a natural and useful way. Our work on transformations, to date, have not looked \ndeeply into the heap; thus, our analyzer uses the simple expedient of splitting the heap by allocation \nsite as opposed to the more precise techniques used in shape analysis. Within the literature on points-to \nanal- ysis, variations occur in the choice of approximation The experimental results shown in Section \n5 might techniques for modeling parameter binding, for model- be interpreted as showing the benefits \nthat can be ob- ing the heap, and for tracking path information during tained from increasing the precision \nof program anal-   Summary and Future Directions We have implemented a method for register promotion \nthat is loop-based. This method converts references to scalar values in memory to references to a register. \nWe have shown that this technique can have a substantial impact on memory traffic for whole programs \neven after register allocation. As memory references become more expensive this reduction in memory traffic \nwill become more important. Register promotion can increase register pressure. This, in turn, can cause \nthe register allocator to spill some values by inserting new loads and stores. These spill operations \nhurt performance; in some cases, this effect can lead to slower code than that obtained with-out register \npromotion. To guard against this problem, we may need to extend our promotion algorithm with an explicit \ndecision-making process that considers reg-ister pressure and frequency of use before promoting a value. \n Acknowledgments This work would not have been possible without the support of many people. The implementation \nwas built as part of the Massively Scalar Compiler Project at Rice; it relies on the work of everyone \nwho has con-tributed to that effort. Tim Harvey and Phillip Schielke played critical roles in extending \nthe software to support this work. The exposition of this work wan improved substantially by comments \nfrom members of the pro-gram committee for PLDI 97 and from Linda Torczon. Funding was provided by the \nState of Texas ATP prc+ gram and DARPA ITO. References PI Preston Briggs, Keith D. Cooper, and Linda \nTorc-zon. Improvements to graph coloring register allo-cation. ACM Tmnsactions on Ptvgmmming Lan-guages \nand Systems, 16(3):428-455, May 1994. David Callahan, Steve Carr, and Ken Kennedy. PI Improving register \nallocation for subscripted vari-ables. SIGPLAN Notices, 25(6):53-65, June 1990. Proceedings of the ACM \nSIGPLAN 90 Conference on Programming Language Design and Implemen- tation.  Steve Carr. Memory-Hiemrchy \nManagement. PhD [31 thesis, Rice University, Department of Computer Science, 1992. Steve Carr and Ken \nKennedy. PI in the presence of conditional nical Report TR92283, Rice November 1992. Scalar replacement \ncontrol flow. Tech-University, CRPC, [51 David R. Chase, Mark Wegman, and F. Kenneth Zadeck. Analysis \nof pointers and structures. SIG-PLAN Notices, 25(6):296-310, June 1990. Pmceed-ings of the ACM SIGPLAN \n90 Conference on Pro- gmmming Language Design and Implementation. Jong-Deok Choi, Michael Burke, and \nPaul Carini. PI Efficient flow-sensitive interprocedural computa-tion of pointer-induced aliases and \nside effects. In Conference Record of the Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Princi-ples \nof Prugmmming Languages, pages 232-245, Charleston, South Carolina, January 1993. Keith D. Cooper and \nKen Kennedy. Interprocedu-[71 ral side-effect analysis in linear time. SIGPLAN Notices, 23(7):57-66, \nJuly 1988. Proceedings of the ACM SIGPLAN 88 Conference on Pmgmmming Language Design and Implementation. \nAlain Deutsch. Interprocedural May-Alias analysis PI for pointers: Beyond k-limiting. SIGPLAN No-tices, \n29(6):230-241, June 1994. Proceedings of the ACM SIGPLAN 94 Conference on Pmgmmming Language Design and \nImplementation. Maryam Emami, Rakesh Ghiya, and Laurie Hen- PI dren. Context-sensitive interprocedural \npoints-to analysis in the presence of function pointers. SIG-PLAN Notices, 29(6):242-256, June 1994. \nRakesh Ghiya and Laurie J. Hendren. Is it a tree, WI a DAG, or a cyclic graph? a shape analysis for \nheap-directed pointers in c? Conference Recoil of the Fifteenth ACM Symposium on the Principles of Prwgmmming \nLanguages, pages 1-15, January 1996. [l l] Gina Goff, Ken Kennedy, and Chau-Wen Tseng. Practical dependence \ntesting. SIGPLAN Notices, 26(6):15-29, June 1991. Proceedings of the ACM SZGPLAN 91 Conference on Programming \nLan-guage Design and Implementation. [12] Joseph Hummel, Laurie J. Hendren, and Alexan-der Nicolau. A \ngeneral data dependence test for dynamic, pointer-based data structures. SIGPLAN Notices, 29(6):218-229, \nJune 1994. [13] William Landi and Barbara G. Ryder. A safe approximate algorithm for interprocedural \npointer aliasing. SIGPLAN Notices, 27(7):235-248, June 1992. [14] James R. Larus and Paul N. Hilfinger. \nDetect-ing conflicts between structure accesses. SIGPLAN Notices, 23(7):21-34, July 1988. Proceedings \nof the ACM SIGPLAN 88 Conference on Progmmming Language Design and Implementation. [15] Thomas Lengauer \nand Robert Endre Tarjan. A fast algorithm for finding dominators in a flow-graph. ACM Tmnsactions on \nProgramming Lun-guages and Systems, 1(1):121-141, July 1979. [16] Dror E. Maydan, John L. Hennessy, and \nMonica S. Lam. Efficient and exact data dependence anal-ysis. SZGPLAN Notices, 26(6):1-14, June 1991. \nProceedings of the ACM SIGPLAN 91 Conference on Pmgmmming Language Design and Implemen- tation. [17] \nEtienne Morel and Claude Renvoise. Global op timization by suppression of partial redundancies. Communications \nof the ACM, 22(2):96-103, Febru- ary 1979. [18] Erik Ruf. Context-insensitive alias analysis re- considered. \nSIGPLAN Notices, 30(6):13-22, June 1995. [19] Mooly Sagiv, Thomas Reps, and Reinhard Wil-helm. Solving \nshape-analysis problems in languages with destructive updating. Conference Record of the Fifteenth ACM \nSymposium on the Principles of Programming Languages, pages 16-31, January 1996. [20] Bjarne Steensgaard. \nPoints-to analysis in almost linear time. Conference Record of the Fifteenth ACM Symposium on the Principles \nof Progmm-ming Languages, pages 3141, January 1996. [21] David W. Wall. Limits of instruction-level paral-lelism. \nIn Proceedings of the Fourth International Conference on Architectural Support for Program- ming Languages \nand Operating Systems, pages 176-189, Santa Clara, California, 1991. [22] Robert P. Wilson and Monica \nS. Lam. Efficient context-sensitive pointer analysis for C programs. SIGPLAN Notices, 30(6):1-12, June \n1995.  \n\t\t\t", "proc_id": "258915", "abstract": "The combination of pointers and pointer arithmetic in C makes the task of improving C programs somewhat more difficult than improving programs written in simpler languages like Fortran. While much work has been published that focuses on the analysis of pointers, little has appeared that uses the results of such analysis to improve the code compiled for C. This paper examines the problem of register promotion in C and presents experimental results showing that it can have dramatic effects on memory traffic.", "authors": [{"name": "John Lu", "author_profile_id": "81100053454", "affiliation": "Department of Computer Science, Rice University, Houston, Texas", "person_id": "P144878", "email_address": "", "orcid_id": ""}, {"name": "Keith D. Cooper", "author_profile_id": "81100286556", "affiliation": "Department of Computer Science, Rice University, Houston, Texas", "person_id": "P158954", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258915.258943", "year": "1997", "article_id": "258943", "conference": "PLDI", "title": "Register promotion in C programs", "url": "http://dl.acm.org/citation.cfm?id=258943"}