{"article_publication_date": "05-01-1997", "fulltext": "\n tee: A System for Fast, Flexible, and High-level Dynamic Code Generation Massimiliano Poletto, Dawson \nR. Engler, and M. Frans Kaashoek {maxp, engler, kaashoek}@lcs.mit.edu Laboratory for Computer Science \nMassachusetts Institute of Technology Cambridge, MA 02 139 Abstract tee is a compiler that provides \nefficient and high-level access to dynamic code generation. It implements the C ( Tick-C ) program- ming \nlanguage, an extension of ANSI C that supports dynamic code generation [ 151. C gives power and flexibility \nin specifying dynam- ically generated code: whereas most other systems use annotations to denote run-time \ninvariants. C allows the programmer to specify and compose arbitrary expressions and statements at run \ntime. This degree of control is needed to efficiently implement some of the most important applications \nof dynamic code generation, such as just in time compilers [ 171 and efficient simulators [ 10, 48, 461. \nThe paper focuses on the techniques that allow tee to provide C s flexibility and expressiveness without \nsacrificing run-timecode generation efficiency. These techniques include fast register alloca- tion, \nefficient creation and composition of dynamic code specifica- tions, and link-time analysis to reduce \nthe size of dynamic code gen- erators. tee also implements two different dynamic code generation strategies, \ndesigned to address the tradeoff of dynamic compilation speed versus generated code quality. To characterize \nthe effects of dynamic compilation, we present performance measurements for eleven programs compiled \nusing tee. On these applications, we measured performance improvements of up to one order of magni- tude. \nTo encourage further experimentation and use of dynamic code generation, we are making the tee compiler \navailable in the public domain. This is, to our knowledge, the first high-level dynamic compilation system \nto be made available. 1 Introduction Dynamic code generation has recently attracted considerable interest. \nUnlike tee, current systems generally do not provide an interface to dynamic code generation that is \nboth flexible and easy to use. On one side, annotation-driven approaches allow the pro- grammer to communicate \nhigh-level hints about run-time invariants to the compiler, but provide relatively limited code specification \nThis research was suppolvd in put by the Advaacad Research Projects Agency under confracts NOCO1494-l-0985 \nand N66001-%-C-8522, aad by B NSF National Young lnvcsti~tor Award. Permission to make digital/hard copy \nof part or all this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for profit or commercial advan- tage, the copyright notice, the title of the \npublication and its date appear, and notice is given that copying is by permission of ACM, Inc. To copy \notherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission \nand/or a fee. PLDI 97 Las Vegas, NV, USA 0 1997 ACM 0-89791~907-6/9710006...$3.50 flexibility [ 1, 11, \n321. On the other, library-based approaches al- low flexible specification of code, but require programmers \nto work with a low-level representation [14. 191. This code specification flexibility is necessary to \nefficiently im- plement some of the most profitable applications of dynamic code generation, such as \njust in time compilers [ 171 aud efficient simu- lators [ 10,48.46], which require the composition of \narbitrary state- ments and expressions and the creation of routines with statically- unknown type signatures. \ntee aims to provide the ease of specifying dynamic cc&#38; at a high level while retaining the flexibility \nand ex- pressiveness of low-level systems. tee compiles the C programming language, an extension of ANSI \nC that provides mechanisms for specifying and dynamically composing arbitrary ANSI C expressions and \nstatements. Although code composition is powerful and relatively easy to use, it trun- cates control \nflow information, reducing the opportunity for static analysis. Hence, implementing C! efficiently is \nchallenging. tee ad- dresses this problem with several techniques, including algorithms for fast dynamic \nregister allocation, efficient creation and analysis of dynamic code specifications. and a link-time \nanalysis to reduce the size of dynamic code generators. In addition, tee implements two different dynamic \ncompilation strategies, designed to accommodate the tradeoff between the speed of code generation and \nthe quality of generated code. When compilation time must be minimized, dy- namic code generation and \nregister allocation are performed in one pass; when code quality is most important, the system dynamically \nconstructs and optimizes an intermediate representation prior to generating code. These solutions are \ninteresting in the context of dynamic com-pilation. Furthermore, some, such as a fast global register \nallocation algorithm, are also applicable to traditional, static compilers. To characterize the effects \nof these techniques, we present per- formance results for eleven programs compiled using tee. Our mea- \nsurements show that C programs employing dynamic code gener- ation are up to an order of magnitude faster \nthan their static ANSI C counterparts. Dynamic code generation has existed for a long time [7, 10, 12, \n16, 26, 29, 30, 36.40, 48.45, 461. Unfortunately, despite its utility, programmers have never had portable, \nhigh-level access to it, so it has remained a curiosity rather than a popular technique. One goal of \nthe C project is to provide a real system that can be used in day-to-day development and for further \nresearch on dynamic code generation. This objective has determined many of our tradeoffs. In terms of \nlanguage design, it led us to base our work on ANSI C and to keep our extensions within the spirit of \nC. In terms of implementation, it required that the compiler be publicly available and that it run on \na variety of different architectures. Attention to these constraints has allowed us to produce a robust, \nefficient, and high-level dynamic code generation system available for public use. The following section \ndescribes how our compiler relates to other systems. Section 3 gives a concise overview of tee s input \nlanguage, C. We discuss the basic architecture of tee in Section 4, details of its code generation strategies \nin Section 5, and experi- mental results in Section 6.   Related Work Dynamic code generation has a \nlong history [29]. It has been used to increase the performance of operating systems [2, 16, 39, 401, \nwindowing operations [36], dynamically typed languages [7, 12, 261, and simulators [48, 461. Many languages, \nsuch as most Lisp dialects [41. 431, Tel [35], and Per1 [47], provide an eval operation that allows code \nto be generated dynamically. This approach is extremely flexible but, unfortunately, comes at a high \nprice: since these languages are dynamically typed, little code generation cost can be pushed to compile \ntime. Keppel addressed some issues relevant to retargeting dynamic code generation in [28]. He developed \na portable system for modi- fying instruction spaces on a variety of machines. His system dealt with \nthe difficulties presented by caches and operating system re- strictions, but it did not address how \nto select and emit actual bi- nary instructions. Keppel, Eggers, and Henry [30] demonstrated that dynamic \ncode generation can be effective for several different applications. Leone and Lee [3 l] use programmer-supplied \nhints to perform compile-time specialization in a simple functional language. Re- cently, they have extended \ntheir compiler, FABIUS, to accept a functional subset of ML [32]. They achieve low code generation costs \nusing some of the techniques we independently derived for tee. C. however, provides the programmer with \na wider range of mechanisms for dynamic code generation. Additionally, C pro- vides support for dynamic \ncode generation in the context of ANSI C. a complex imperative language. Another interesting automatic \ncode generation system is Tempo [ 111, a general-purpose dynamic specializer for C. Like other au- tomatic \nsystems, it can be less flexible than C. For example, the scope of Tempo s optimizations is limited by \nthe usual challenges C presents to optimizing compilers (e.g., unrestricted aliasing). No performance \ndata is provided for Tempo, so it is difficult to compare the two implementations. The dynamic compilation \nproject at the University of Wash- ington also uses automatic compiler support for detecting run-time \nconstants [ 11. Their compiler employs programmer annotations to indicate some run-time constants; the \ncompiler computes what vari- ables are derived run-time constants. Published results seem to indi- cate \nthat it dynamically generates code up to an order of magnitude more slowly than tee but, since it is \nintegrated with the Multiflow optimizing compiler [33], we assume that the code it generates is superior \nin quality. In theory, the three systems described above can generate good code with relatively low overhead \nby moving almost all the work to static compilation. In such systems, the static compiler emits templates \nthat at run time are filled with appropriate values, opti- mized in relatively simple but effective ways, \nand emitted directly. In practice, however, only Leone and Lee [32] appear to generate code more quickly \nthan tee. Furthermore, improving performance in this way has a usability cost: no existing template-based \nsystem gives the programmer as much freedom and expressive power as C. C allows the user to dynamically \ncompose pieces of code in arbitrary ways, and can thus provide functionality not present in plain C. \nExisting template-based systems, by contrast, use dynamic compilation solely for its performance advantages, \nextending to run-time the applicability of traditional optimizations such as copy propagation and dead \ncode elimination. We build on work done by Engler, Hsieh, and Kaashoek [15]. They describe the C language \nand a prototype compiler for it. We provide the first real, high-performance implementation of C. Our \nimplementation uses an extension of VCODE [14], a fast, portable dynamic code generation system, as its \ntarget machine. 3 Language Overview This section briefly describes C in enough detail to provide con- \ntext for the tee compiler; a more complete discussion can be found in [ 15, 181. C extends ANSI C to \nsupport dynamic code generation. It introduces two unary operators, and f, and two postfix-declared \ntype constructors. Programmers use these extensions to denote code that should be generated at run time. \nThe units of code specification are ANSI C expressions, statements and variables. These specifica- tions, \ncreated dynamically at specification time, can be composed to build larger specifications or instantiated, \ncompiled at run time, to produce executable code. Just like ANSI C, C is lexically scoped and statically \ntyped. Dynamic code is specified using the (backquote, or tick ) op- erator. Backquote. applied to an \nexpression or compound statement indicates that code corresponding to that expression or statement should \nbe generated at run time. We refer to the resulting expression as a tick-expression. For example, the \ntick-expression 4 speci- fies code to generate the integer constant 4. The type of a specified expression \nor statement is a cspec type (for code specijication); the evaluation type of the CSP~C is the type of \nthe dynamic value of the code. For example, the type of the expression 4 is int cspec. Applying to a \ncompound statement produces an object of type void cspec. An evaluation type allows dynamic code to be \nstati- cally typed, enabling the compiler to do all type checking and some instruction selection at static \ncompile time. Dynamically generated lvalues are of VSpeC type (variable specificafion); their evaluation \ntype is the type of the lvalue. When flow of control passes a tick-expression, that expression is said \nto be specified. However, before the code can be executed, it must be compiled, or instantiated. This \noperation is performed by the compile special form, which takes a cspec and a type as an argument and \nreturns a function pointer having the corresponding return type. The following code fragment dynamically \nspecifies and then instantiates a hello world procedure: void cspec hello = 1 printf( hello world\\n ); \n1; /* Compile and call the result */ (*compile(hello, void))O; Dynamic code composition is central to \nC. References to ob- jects of cspec or vspec type appearing in the body of a tick-expression are automatically \nconverted to their corresponding eval- uation types and incorporated into the code of the cspec in which \nthey occur. For example, in the code below, compiling c has the same effect as compiling the cspec (4+5). \n/* Compose cl and c2. Compiling c yields code 4+5 */ int cspec cl = 4, cspec c2 = 5; int cspec c = (cl \n+ c2); The $ operator allows run-time constants to be incorporated into dynamic code. $ can appear only \nwithin a tick-expression; it evaluates its operand at specification time, and the resulting value is \nincorporated as a run-time constant into the containing cspec. 0 may be applied to any expression within \ndynamic code that is not of type cspec or vspec. The use of S is illustrated in the code fragment below. \n void (*fp)(void); int x = 1; /* Compile simple function to demonstrate binding via $ */ fp = compile( \n{ printf( Sx = %d, x = %d\\n , Sx, x); I, void); x = 14; (+fp)(); /* Invoke function: will print $x = \nI. x = 14 . */  C has many other features, including facilities to create local variables and parameters \nat run time, generate function calls with run-time determined numbers of arguments, and dynamically create \nlabels and jumps. These are implemented as special forms which the compiler translates to calls to a \nsmall library, reducing the number of actual language changes necessary for C. and facilitating changes \nin implementation and functionality. These and other features of C are described in depth in [ 15, 181. \n 4 Architecture The design of tee has been driven by three goals: providing flexibility to the programmer, \nminimizing the overhead of dynamic compilation, and generating high-quality code. Since many opti- mizations \non dynamic code can be profitably performed only at run time, improvements in code quality are generally \nobtained at the expense of greater code generation time. One way to generate good code with low overhead \nis to structure the system so that most opti- mizations can be performed statically [ 1, 11, 321, but \nin all existing systems this ability comes at the expense of language flexibility and expressiveness \n(furthermore, in practice, only Leone and Lee [32] appear to generate code more quickly than tee). C, \nby contrast, allows the user to dynamically compose arbitrary pieces of code, which makes static analysis \nof the dynamic code problematic. The following subsections give an overview of tee and discuss how tee \nachieves its goal of performance and flexibility. We de- scribe three important code generation phases: \nstatic compile time, dynamic specification time, and dynamic compile time. The sub- sequent section looks \nin detail at several of the optimizations and techniques we have developed to improve the performance \nof both dynamic code and the dynamic code generation process. 4.1 Overview The tee compiler is based \non ICC [23, 221, a terse and portable com- piler for ANSI C. ICC performs common sub-expression elimination \nwithin extended basic blocks and uses lburg [38] to find the lowest- cost implementation of a certain \nIR-level construct, but it performs few other optimizations. All parsing and semantic checking of dynamic \nexpressions oc- curs at static compile time. Semantic checks are performed at the level of dynamically \ngenerated expressions. For each cspec, tee performs type checking similarly to a traditional C compiler. \nIt also tracks goto statements and labels to ensure that a goto does not transfer control outside the \nbody of the containing cspec. Unlike traditional static compilers, tee uses two types of back ends to \ngenerate code. One is the static back end, which compiles the non-dynamic parts of C programs, and emits \neither native assembly code or C code suitable for compilation by a highly optimizing compiler. The other, \nreferred to as the dynamic back end, emits C code to generate dynamic code. Once produced by the dynamic \nback end, this code is in turn compiled by the static back end. This process is illustrated in Figure \n1. Since the tradeoff between code generation speed and code quality is so important, tee provides two \ndynamic back ends and corresponding run-time systems: the first emphasizes code genera- tion speed over \ncode quality, while the second inverts this tradeoff. c PW4-= I I tccbackend for dynamic cock tahckend \nfw stadc cc&#38; 1 Assembly or C Figure 1: Overview of the tee static compilation process.  4.2 Static \ncompilation During static compilation, every tick-expression is compiled to a code generating function \n(CGF), which is invoked at run time to generate code for dynamic expressions. This subsection briefly \nde- scribes the static compilation process and the abstract machine that tee uses for dynamic code generation. \nGenerating CGFs and Closures. All information necessary for dynamic compilation is maintained in CGFs \nand in dynamically- created closures. For each tick-expression, tee statically generates both its code \ngenerating function and the code to allocate and ini- tialize the corresponding closure. CGFs and closures \nare used to support tee s two-step approach to code generation. First, at specification time, the state \nof each tick-expression (i.e., addresses of free variables and values of run- time constants created \nusing S) is captured in a closure. Second, at dynamic compilation time, the code generating functions \nfor each tick-expression process the closures and produce executable code. Closures are necessary to \nreason about composition and out- of-order specification of dynamic code. Eliminating closures would \nrequire generating code as soon as a dynamic expression is specified. This is a poor solution, since \nit does not solve the problem of propagating information across cspecs, and it may require that code \nfragments be copied to contiguous memory. Cspecs are implemented by pointers to closures correspond- \ning to tick-expressions. Objects of type cspec are therefore im- plemented just like pointers: they have \nthe same size, alignment requirements, etc.. Closures are heap-allocated, but their allocation cost is \ngreatly reduced (down to a pointer increment, in the normal case) by using arenas [20]. For example, \nconsider the following code: int j, k; int apec i = 5; void cspec c = 1 return i+$j*k; 1;  tee implements \nthe assignments to these cspecs by assignments to corresponding pointers to closures: Acapec-t i = ((-closure0 \n= (~dosureO~t)-alloc~closure(4~~. (AosureO-tcgf = qfO), /* code gen func */ -tc-cspec-t c = ((-closure1 \n= (~closurelA)~alloc~closure(l6)), (-closurel-+cgf = qfl), /* code gen func */ (-closurel+cs-i = i), \n/* nested cspec */ (rlosurel+rcj = j), /* run-time const */ (-closurel+fv-k = &#38;k),/* free variable \n*/ (AC-cspec-tLclosure1); i s closure contains only a pointer to its code generating function. c, on \nthe other hand, has more dependencies on its environment: its closure also stores run-time constants, \npointers to free variables, and other information. tee s abstract machines. tee compiles dynamic code \nto two ab- stract machines based on the VCODE dynamic code generation sys- tem [14]. Using abstract machines \nrather than machine-specific back ends significantly simplifies the structure of tee, allowing it to \nignore many machine-specific details of dynamic code generation and to compile dynamic code in essentially \nthe same way for all the machines to which VCODE is ported (currently MIPS, SPARC, Alpha, and x86). While \nabstraction at this level implies some degra- dation in code quality, it has allowed us to build, with \nrelatively little effort, a system that works on two different architectures (SPARC and MIPS) and is \nbeing ported to the x86 (a complete port to the Alpha would require more significant changes to the internals \nof the static compilation portion of tee). As tee matures, we may add machine-specific back ends. Since \ntee preserves the features that make ICC retargetable, this process should not be difficult. The first \nof tee s abstract machines is the VCODE system it- self [141.VCODE provides an interface resembling that \nof an ideal- ized load/store RISC architecture; each instruction in this interface is a C macro which \nemits the corresponding instruction (or series of instructions) for the target architecture. VCODE'Skey \nfeature is that it generates code with low run-time overhead: as few as ten in- structions per generated \ninstruction in the best case. While VCODE generates code quickly, it only has access to local information \n(i.e., just information about one tick-expression), so the quality of the resulting code can frequently \nbe improved. The second abstract machine, ICODE,addresses this problem: it provides an extended instruction \nset and, prior to emitting code, builds up and then opti- mizes an intermediate representation of all \ncode for a dynamically specified function. Section 5 discusses these abstract machines in detail. The \nfol- lowing example, however, may help to visualize the contents of the CGFs and the interface to the \nabstract machines. The two func- tions below are the CGFs for the cspecs introduced in the previous section, \nfor the case of the ICODEback end: unsigned int qf0 (closureO-t c) ( -tc-vspec-t itmp0 = -tc-local (1-l); \n/* int temporary */ Lseti(itmpO.5); /* set it to 5 */ return itmp0; /* return the location */ void qfl \n(closurel-t +c) ( Atcvspec-t itmp0 = ~tchcal (I-1); /* some temporaries */ -tc-vspec-t itmpl = ~tchal \n(I-1); i-ldii (itmpl ,zero.c+fv-k); /* addr of k */ imulii (itmpl .itmpl ,c-+rc&#38; /* run-time const \nj */ /* now apply i s CC? to i s closure: cspec composition! */ itmp0 = (*c+cs-i+cgf)(c+cs-i); i-addi \n(itmpl ,itmpO,itmpl); i-reti (itmpl); it emit a return (not return a value) */ I -cgK) is very simple: \nit allocates a temporary storage location, generates code to store the value 5 into it, and returns the \nlocation. This is exactly the meaning of 5. On the other hand, -@I must do a little more work: the code \nthat it generates (1) loads the value stored at the address of free variable k into a register, (2) multiplies \nit by the value of the run-time constant j, (3) adds this to the dynamic value of i, and (4) returns \nthe result. Note that since i is a cspec, the code for the dynamic value of i is generated by calling \ni s code generating function. Static phases of dynamic code generation. Fast dynamic code generation \nrequires that most compilation work be done at static compile time. Thus, when optimizing code generation \nspeed over quality of generated code, tee performs as much instruction se-lection as possible statically. \nBoth instruction selection based on operand types and register allocation for temporaries and variables \nnot live across the reference to a cspec are done statically. Ad- ditionally, the intermediate representation \nof each tick-expression is processed by the common subexpression elimination and other local optimizations \nperformed by the ICC front end. tee also uses copt [Zl] to statically perform peephole optimizations \non the code generating macros used by CGFs. However, not all register allocation and instruction selection \ncan occur statically. For instance, it is not possible in general to stati- cally determine which vspecs \nor cspecs will be incorporated into another cspec when the program is executed. Hence, allocation of \nuser-defined dynamic lvalues (vspecs) and of results of composed cspecs must be performed dynamically. \nThe same is true of vari- ables or temporaries that live across references to other cspecs. Each read \nor write to one of these dynamically determined lvalues is enclosed in a conditional in the CGF: different \ncode is emitted at run time depending on whether the object is dynamically allocated to a register or \nto memory. Since the process of instruction selection is encoded in the body of the code generating function, \nit is quite inexpensive. Optimizing for code quality, on the other hand, involves a more significant \ndynamic code generation cost. In this case, the CGFs contain ICODE,instead of VCODE,macros, and tee does \nnot pre- compute much statically. Rather than emitting code directly, the KODE macros first build up \na simple intermediate representation; the ICODE run-time system then makes two passes over this rep- \nresentation to allocate registers and perform other optimizations before emitting code. Both ICODEand \nVCODE are discussed further in subsequent sections. Engineering: tee s two static back ends. ICC is not \nan optimiz- ing compiler. The assembly code emitted by its traditional static back ends is usually significantly \nslower (even three or more times slower) than that emitted by optimizing compilers such as gee or vendor \nC compilers. To improve the quality of static code emitted by tee, we have implemented a static back \nend that generates ANSI C from C source; this code can then be compiled by any optimizing compiler. ICC \nS traditional back ends can thus be used when static compilation must be fast (i.e., during development), \nand the C back end can be used when the performance of the code is critical.  4.3 Dynamic specification \ntime At dynamic specification time, the C run-time system collects in- formation about the environment \nof each tick-expression. This is a simple process, in which relevant portions of a tick-expression s \nenvironment are captured in a closure. An example appears in Sec- tion 4.2. The closure is heap-allocated \nand used to store four main types of information: (1) a function pointer to the statically gener- ated \nCGF for the tick-expression; (2) the values of run-time con-stants bound via the $ operator; (3) the \naddresses of free variables; (4) pointers to objects representing the code and variable specitica- tions \ncomposed inside the tick-expression. This information is used to create code during dynamic compilation. \n 4.4 Dynamic compilation Dynamic compilation, or instantiation, involves processing the pro- grammer \ns dynamic code specifications and producing executable code. We outline the mechanics of this process, \nand pay special attention to some partial evaluation mechanisms employed by the code generating functions. \nGenerating dynamic code. Dynamic compilation (or instantia- tion) for C is initiated by invoking the \ncompile special form on a cspec. Compile then invokes the code-generating function for the cspec on the \ncspec s closure, and the CGF performs most of the actual code generation. In terms of the previous example, \nthe code int ( f)() = compile(j, int); causes the run-time system to invoke closure1 -@(closure1 1. When \nthe CGF returns, compile links the resulting code, resets the information regarding dynamically generated \nlocals and param- eters, and returns a pointer to the generated code. We attempt to minimize poor cache \nbehavior by choosing the address of the be- ginning of the dynamic code randomly modulo the cache size. \nIn the case when multiple dynamic functions are generated and used together, it would not be very expensive \nto track the placement of dynamic code to attempt to improve cache performance. Dynamic compilation performs \nthe composition of cspecs (in-clusion of cspec b into the body of cspec a) into one final piece of code. \nThis is implemented simply by invoking b's CGF from within a s CGF. If b returns a value, the value s \nlocation is returned by its CGF, and can then be used by operations within the calling CGF. The problem \nof generating efficient code from composed cspecs is analogous to function inlining and inter-procedural \noptimization when all function calls occur through pointers. Performing some op- timizations on the dynamic \ncode after the order of composition of cspecs has been determined can significantly improve code qual- \nity. tee s ICODEback end addresses this issue by building up an intermediate representation and performing \nsome analyses prior to generating executable code. The VCODE back end, by contrast, opti- mizes for code \ngeneration speed: it generates code in just one pass, but can make poor spill decisions when there is \nsignificant register pressure. We describe both these systems in detail in Section 5. Automatic dynamic \npartial evaluation. Partial evaluation is the key optimization that makes dynamic compilation profitable. \ntee applies partial evaluation in three main ways. First, it folds run- time constants at instantiation \ntime. The code generating functions contain code to evaluate any parts of an expression consisting of \nstatic and run-time constants. The dynamically emitted instructions can then encode these values as immediates. \nSimilarly, tee performs strength reduction based on run-time constants: if an operand of an expensive \noperation (e.g., multi- plication or division) is a run-time constant, the CGF contains a fancier code-generation \nmacro than usual: rather than emitting a fixed sequence of instructions, it first checks the value of \nits immedi- ate operand, emitting different machine instructions at instantiation time depending on the \nvalue of this argument. Lastly, the code generating functions automatically perform some dynamic loop \nunrolling and dead code elimination based on run-time constants. For example, if the test of a loop or \nconditional is run-time invariant, or if a loop is bounded by run-time invariants, then the actual control \nflow can be performed only once, at instan- tiation time, producing straight-line code and often leading \nto dead code elimination. In addition, run-time constant information prop-agates down loop nesting levels: \nfor example, if a loop induction variable is bounded by run-time constants, and it is in turn used to \nbound a nested loop, then the induction variable of the nested loop is considered run-time constant too \n(for any given iteration of the nested loop). Our current implementation does not propagate run-time \nconstant information to discover additional run-time con-stants in a fully general manner, as done in \n[ 11. This restriction is mostly an engineering problem, since there is little framework for performing \nrelaxation analyses at static compile time within ICC. As an example of these optimizations, consider \nwriting code that computes the dot-product of a vector col with a run-time constant vector row. In this \ncase, it is possible to generate straight-line code in which the contents of row are hard-wired into \nthe instruction stream. One way to do this is to use C s facilities for code composition: void opec code; \nint cspec sum = 0; for (k = 0; k c n; k++) if (row[kl) sum = (sum + colI$kl*$row[kl); code = ( return \nsum; ); /* sum is a*b+c*d+... */ Alternatively, one can leverage the dynamic loop unrolling pro- vided \nby tee: { int k, sum = 0; for (k = 0; k c $n; k++) if (Prowlkl) sum = sum + colIkl*$row[k]; return sum; \n I. 1. k is bounded by run-time constants and is never assigned outside of the control expressions of \nthe for-statement, so it becomes a derived run-time constant. The resulting optimized code generating \nfunction appears below: @dosure-t c) ( int k; -tc-vspec-t itmp0 = -tc-local (1-l); /* int temporary */ \nfor (k = 0; k -z c-htcl; k++) ( If ((*((int*)c+rK!+k))) ( /* skip if row[&#38;]==O */ addpi(tmp0, c+coI, \n4*k); Idi(tmp0, zero, tmp0); mulii(tmp0, tmp0, (*((int*)c+rW+k))); addi(c+sum, c+sum, tmp0); HI In this \ncase, the loop overhead is paid only once, at dynamic compile time. The resulting dynamic code has fewer \ninstructions than the original, no branches, and no loop induction variable. Un- less it is made too \nlarge, and hence acquires poor memory locality and incurs a high code generation cost, it will easily \noutperform its static counterpart. This style of optimization, hard-coded at static compile time and \nthen performed dynamically, helps to produce better code without incurring high dynamic compilation overhead. \nThe code transfor- mations are encoded in the CGF and depend on no run-time data structures. Furthermore, \ndynamic code that is unreachable due to a run-time constant need never be generated, sometimes even result- \ning in faster code generation than in the unoptimized case.   r4 + Dynamic Back Ends The tension \nbetween dynamic code generation speed and code quality has led us to build two dynamic back ends for \ntee: ICODE builds up an intermediate representation at run time before emit- ting executable code, whereas \nVCODE emits code directly, without any form of analysis. The main motivation behind this difference is \ninter-cspec optimization, particularly register allocation. Dynamic register allocation in C is a complex \nproblem, equivalent to effi- cient inter-procedural register allocation when function calls are via pointers. \nWithout an intermediate representation, register allocation lacks any notion of how tick-expressions \nare dynamically composed and so can only use information in a single tick-expression; using an intermediate \nrepresentation, tee is able to perform effective inter- cspec register allocation. These two methods \nare provided because the appropriate level of run-time optimization is application-specific, since it \ndepends on the number of times the code will be used (i.e., it must be used enough to amortize the cost \nof run-time optimization) and on the size and structure of the dynamic code (e.g., loop nesting depth, \nnumber of nested cspecs, etc.). To account for this, tee allows the user to select the dynamic back end. \nThis section explores the implementation details of both back ends. 5.1 VCODE-based code generation When \noptimizing for code generation speed, the code generating functions use VCODE macros to emit code in \none pass. Register allocation in this case is fast and simple. VCODE provides getreg and putreg operations: \nthe former allocates a machine register, the latter frees it. If there are no unallocated registers when \ngetreg is invoked, it returns a spilled location designated by a negative number; VCODE macros recognize \nthis number as a stack offset, and emit the necessary loads and stores. Clients that find these per- \ninstruction if-statements too expensive can disable them: getreg is then guaranteed to return only physical \nregister names and, if it cannot satisfy a request. it terminates the program with a run- time error. \nThis methodology is quite workable in situations where register pressure is not data dependent (i.e., \nit is known in advance), and the improvement in code generation speed (roughly a factor of two) can make \nit worthwhile. tee statically emits getreg and putreg operations together with other VCODE macros in \nthe code-generating functions: this ensures that the register assignments of one cspec do not conflict \nwith those of another cspec dynamically composed with it. As mentioned, however, efficient inter-cspec \nregister allocation is hard, and unsur- prisingly, the placement of these register management operations \ncan greatly affect code quality. Consider the statement { s= '1; }, followed by a loop containing {s \n= (x+9; } (where x is some free or dynamic variable). The code generated by iterating through the loop \nn times corresponds to an expression tree of depth n, as in Figure 2. When compiled statically, the expression \ncan be com- puted using two registers. With a naive dynamic register allocation strategy, however, a \nnew register is allocated every time the code- generating function for the cspec in the loop is called, \nrequiring spilling after only a few iterations. To help improve code quality, tee follows some simple \nheuris- tics. First, expression trees are rearranged so that cspec operands of instructions are evaluated \nbefore non-cspec operands. This min- imizes the number of temporaries which span cspec references, and \nhence the number of registers allocated by the CGF of one A X I Figure 2: Register allocation problem. \n cspec during the execution of the code-generating function of a nested cspec. Secondly no registers \nare allocated for the return value of non-void cspecs: the code-generating function for a refer- enced \ncspec allocates the register for storing its result, and simply returns this register name to the CGF \nfor the enclosing cspec. Obtaining and freeing a register are relatively inexpensive op- erations. Furthermore, \ntee reduces the number of run-time register allocations that occur by reserving a limited number of physical \nregisters. These registers are not allocated by getreg. hut instead are managed at static compile time \nby tee s dynamic back end. They can only be used for values whose live ranges do not span composition \nwith a cspec and are typically employed for expres- sion temporaries. As a result, dynamic register allocation \nusing the VCODE dynamic back end is only slightly slower than in template- based systems, where it can \noccur entirely statically. Since most VCODE macros simply perform bit manipulations (shifts, ors, ands) \non their arguments (constants and physical register names) and write the resulting machine instruction \nto memory, VCODE achieves an amortized code generation cost of ten instructions per generated instruction. \nClearly, however, the emitted code is good only in cases when few variables need to be spilled. If the \ndynamic cede contains large basic blocks with high register pressure, or if cspecs are dynam- ically \ncombined in a way that forces many spills, code quality suffers. The quality of emitted code can be improved \nwithout sacrificing the performance of VCODE very much by extending the code gen- erating functions to \nperform two passes. On the first pass, no code is emitted: each CGF simply returns to its calling CGF \n(if any) the number of registers that it and its children (if any) require to avoid poor spilling. On \nthe second pass, the CGFs and the VCODE macros they contain are executed almost as usual, generating \ncode in one pass. However, if immediately prior to a call to a nested CGF the number of available registers \nis less than that previously requested by the nested CGF,the calling CGF spills and reloads registers \nas necessary. This is a promising technique, since it gives the CGFs a more global view of register allocation \n(e.g., potentially pulling spills out of loop bodies) without incurring much cost (one traversal of the \nCGF call tree). However, at the time of this writing we have not finished implementing and evaluating \nit. 5.2 ICODE-based code generation In cases where dynamically generated code is used frequently or \nruns for a long time, it may be preferable to trade additional dynamic compilation time for improved \ncode quality. In this situation, t&#38;s dynamic back end emits code-generating functions which contain \nICODE (rather than VCODE)macros. ICODE was inspired by VCODE and the difficulty of using the getreg/putreg \nmechanism to effectively allocate registers in the presence of multiple code-generating functions. ICODEprovides \nan interface similar to that of VCODE, with two main extensions: (1) an infinite number of registers, \nand (2) primitives to express changes in estimated usage frequency of code. The first extension allows \nICODEclients to emit code that assumes no spills, leaving the work of global, inter-cspec register allocation \nto ICODE. The second al- lows ICODE to obtain estimates of variable use without expensive analysis: changes \nin expected usage frequency due to conditionals or loops can be expressed explicitly by the ICODEclient. \nFunctionally, ICODE differs from VCODE in that it builds and consumes an intermediate representation \nat run time rather than im- mediately translating instructions to machine code. This intermedi- ate representation \nis designed to be compact (two 4-byte machine words per ICODEinstruction) and easy to parse in order \nto reduce the overhead of subsequent passes. By having access to the entire body of dynamic code resulting \nfrom cspec-composition, ICODE can per- form good register allocation and global optimization. After calling \nthe last code macro, the KODE client can invoke ICODE run-time library functions to perform various forms \nof register allocation and code optimizations prior to generating executable code. When compile is invoked \nin ICODEmode, ICODEbuilds a Row graph, identifies live ranges, employs a linear-time algorithm to perform \nregister allocation, and performs some peephole optimiza- tions. Finally, it translates the intermediate \nrepresentation to the target machine s binary format. We have attempted to minimize the cost of each \nof these operations. We briefly discuss each of these functions in turn. Building a flow graph. ICODE \nbuilds a flow graph in one pass after all CGFs have been invoked, and hence after all the ICODE macros \nhave been executed to lay out the intermediate representa- tion in memory. The flow graph is a single \narray that uses pointers for indexing. In order to allocate all required memory in a single allocation, \nICODEcomputes an upper bound on the number of basic blocks by summing the numbers of labels and jumps \nemitted by ICODE macros. After allocating space for an an array of this size, it traverses the buffer \nof ICODE instructions and adds basic blocks to the array in the same order in which they exist in the \nlist of instruc- tions. Forward references are initially stored in an array of pairs of basic block addresses; \nwhen all the basic blocks are built, the forward references are resolved by traversing this array and \nlinking the pairs of blocks listed in it. ICODE has full information about con- trol flow at indirect \njumps. In addition to constructing control flow information, ICODE collects a minimal amount of local \ndata flow information (def and use sets for each basic block). All memory management occurs through arenas \n[20], ensuring low amortized cost for memory allocation and essentially free deallocation. Finding live \nintervals. In the interest of fast code generation, ICODE does not compute precise live range information, \nbut instead uses a coarse approximation that we call live intervals. An inlend [i, j] of instructions \nis simply all the instructions between the ith and jth instructions in the instruction stream, inclusive. \nThen a five intendofa variables is the interval [m, n], where m is the first in- struction at which 21 \nis ever live, and R. is the last instruction at which it is ever live. This interval information is only \nan approximation of the real live range information (in which ranges may be split): there may be large \nportions of [m, n] in which 2, is not live, but we simply ignore them. In practice this has not been \na problem: the quality of register allocation IS quite good. Importantly, this scheme is quite efficient: \ngiven live variable information, creating a list of live intervals sorted by start or end point is accomplished \nin one pass over the code, and register allocation (described below) simply requires one pass over the \ninterval list. There may also be room for improvement. We currently use a traditional relaxation algorithm \nfor computing exact live variable information; since much of this information is lost when using live \nintervals, it may be possible to perform a much less expensive approximate live variable analysis. We \nare currently studying ways of doing this. Fast Iinear-scan register allocation. Given a set of live \nin- tervals, our global register allocation algorithm is simple and fast. Variants have been considered \nin the literature [22, 24, 271 in the context of local register allocation and for spill-code minimization \nwithin a single basic block [42]. Given R available registers and a list of live intervals, allocating \nregisters so as to minimize the number of spilled intervals involves removing the smallest number of \nlive intervals so that no more than R live intervals overlap any one instruction. Since the number of \noverlapping intervals changes only at the start and end points of intervals, and the intervals appear \nin a list sorted in order of increas- ing end point, the algorithm traverses the list of intervals in \nreverse order, jumping from end point to end point while maintaining a list, active, of intervals live \nat the current point. When the number of these intervals exceeds R, the longest interval (the one with \nthe earliest start point) is spilled. The active list is maintained in or- der of increasing start point. \nAs a result, spilling the longest interval simply means removing the first element, and expiring intervals \nthat are no longer active just involves a short search backwards from the end of the list. The details \nof the algorithm appear in Figure 3. The length of active is bounded by R. As a result, given the live \ninterval information from the previous section, the asymptotic running time of the algorithm is O(I . \nR), where I is the total number of live intervals (in general, one per variable). In addition to this \nregister allocator, we also provide a Chaitin- style graph-coloring register allocator [6]. This register \nallocation technique is not new: it has been studied and optimized exten-sively [5, 8, 25, 341, performs \nwell in many cases, and is simple to implement. As a result, it is a good means of evaluating our simpler \nand faster register allocation algorithm. Emitting code. The final phase of code generation involves \ntrans- lating the register-allocated, optimized ICODE instructions to the host machine s binary format. \nThe code emitter simply makes one pass through the buffer of ICODE instructions. For each ICODEin-struction, \nit invokes the VCODE macro corresponding to the given instruction, prepending and appending spill code \nas necessary, and performing some peephole optimizations and strength reduction. The main problem with \nthis scheme is that the code emitter can be quite large. ICODE has several hundred instructions (the \ncross product of operation kinds and operand types), and the code to translate and peephole-optimize \neach instruction is on the order of 100 instructions, about half of which are executed on a typical run. \nAlways emitting a code generator for the full ICODE instruction set therefore generates unduly large \nexecutables, especially considering that most C programs use a small subset of a11 ICODE instructions. \ntee therefore keeps track of the ICODE instructions used by an ap- plication, and automatically creates \na customized ICODE back end containing code to only translate the required instructions. The com- piler \nencodes the ICODE usage information for a given C source file in dummy symbol names in the corresponding \nobject file. A pre- linking pass then scans all the files about to be linked and emits an additional \nobject file containing an ICODE-to-binary translator tailored specifically to the ICODEmacros present \nin the executable. This simple trick cuts the size of the ICODE library by up to an order of magnitude \nfor most programs, reducing them to approximately the. size of equivalent C programs. GREEDYREGISTERALLOCATION \nactive t {} foreach live interval i, from last to first EXPIREOLDINTERVALS(~) % R is the available number \nof registers if length(ucrive) = R then T t SPZLL,ONGE~TINTERVAL(~) else T t a register from pool of \nfree registers if T is a valid register then register[i] t r add i to active, sorted by start point else \nlocurion[i] t new stack location EXPIREOLDINTERVALS(~) foreach interval j in uctive, from last to first \nif stmtpoint[j] 5 endpoiflt[i] then return remove j from active put registerfj] into pool of free registers \n  SPILLL~NOE~TI~~ERVAL(~) foreach interval j in uctive, from first to last if endpoint[j] > efdpoint[i] \nthen break if stuarrpoiflt[j] < starrpoint[i] then T t regisfer[j] locution[j] t new stack location \nremove j from active  return T else return null Figure 3: Register allocation in one scan.  6 Benchmarks \nThis section evaluates the tee compiler. We outline our exper- imental methodology, describe the benchmarks \nwe have used, and then present and discuss our performance data. 6.1 Experimental Methodology Each of \nour benchmarks was written both in C and in static C. The C programs were compiled both with the VCODE \nand the ICODE-based tee backends. The static C programs were compiled both with the ICC compiler and \nwith the GNU C compiler. The code generating functions used for dynamic code generation are created from \nthe ICC intermediate representation, using that compiler s code generation strategies. As a result, the \nperformance of ICC-generated code should be considered as the baseline to measure the impact of dynamic \ncode generation. Measurements collected using the GNU C compiler serve to compare tee to an optimizing \ncompiler of rea- sonable quality. We are working on improving ICC S static code generation, since optimizing \nthe IR for dynamic code before emit- ting the code-generating functions will clearly result in dynamic \ncode of significantly superior quality. Times were derived by measuring a large number of trials (enough \nto provide several seconds worth of granularity, with negli- gible standard deviations) on a lightly-loaded \nSparcStation 5 using 1 Benchmark 1 VCODE 1 ICODE 1 ] One lame csoec. dvnamic locals 1 96.8 1 1019.7 ] \nOne large cspec; free variables Many small cspecs, dynamic locals 1 Many small cspecs, free variables \n1 260.1 1 1261.9 ] Table 1: Code generation overhead, cycles per generated instruction. the Unix getrusage \nsystem call. These times were then divided by the number of iterations to obtain the average overhead \nof a single run. This form of measurement ignores the effects of cache refill misses, but is representative \nof how these applications would likely be used (ie., in tight inner loops). For the C versions of the \nbenchmarks, we separate the cost of dynamic code generation from the run time of the dynamic code. This \nseparation allows us to calculate the cross-over point at which dynamic code generation becomes profitable. \nWe further break down the cost of dynamic compilation, in units of processor cycles (our test machine \nruns at 70MHz) per generated instruction. In the case of VCODE, this cost consists of manipulating closures \nand other meta-data, and actually generating binary code. For ICODE,we also measure two additional phases: \nbuilding the intermediate rep- resentation, and allocating registers. We present register allocation \ncosts for both the linear scan algorithm described in this paper and for the Chaitin-style register allocator \nwhich we used as a baseline. Several of the benchmarks are data-dependent (usually increas- ing in run \ntime and, sometimes, size of dynamic code, as the size of the input data increases). Due to space constraints, \nwe picked a sin- gle reasonable input size. Specifics about each benchmark appear in Section 6.2. We \nalso compare the cost of our two different dynamic code generation systems (ICODEand VCODE) in two situations \nwhich we consider significant extremes of dynamic code style: a very large tick-expression (approximately \n1000 instructions) compiled alone, and a very small tick-expression (one cspec composition and one addition) \ncomposed many times with other tick-expressions (in our measurements, it is composed 100 times with itself). \nFor both of these cases, we wrote two versions of code, one accessing free variables in the containing \nfunction s scope, and the other making useof dynamic locals. Much cspec composition and many free variables \nboth exacerbate the cost of manipulating closures. The results appear in Table 1. Predictably, ICODE \nis approximately an order of magnitude slower than VCODE, due to the overhead of manipulating an intermediate \nrepresentation and then translating this to binary code. Section 6.3, however, illustrates that this \nextra cost is often amortized by superior dynamic code quality. Our evaluation has not been SPECmark-driven \n: we have not tweaked tee in any way to make individual benchmarks run faster. Complete data from these \nexperiments appears in Section 6.3, be- low. 6.2 Benchmarks This subsection describes the benchmarks \nwe used to evaluate the tee compiler. They have been chosen to highlight different styles of dynamic \ncode generation use. Many of them are fully described (but not measured) in [15]. We also describe modifications \nmade to xv [4], a relatively sophisticated share-ware image manipula- tion package, to exploit dynamic \ncode generation, and the resulting performance benefits. Run-time constants. Dynamic code generation \ncan be used to hardwire infrequently changing values into the instruction stream. This optimization is \nbeneficial because the values need not be loaded from memory, and expensive operations (such as multiplication \nand division) that use these values can be strength-reduced. It is increasingly profitable on modem architectures, \nwhere cache misses are very expensive and division and multiplication are frequently provided only in \nsoftware. An example is a generic hash function, where the table size is determined at run time, and \nwhere the function uses a run-time value to help its hash. Such a hash function can be faster than an \nequivalent C version, since a C compiler can exploit run-time constants to scatter and normalize key \nvalues both by hard-coding them into the instruction stream and by strength-reducing the multiplication \nand division. The hash experiment measures the time to repeatedly look up two values in a hash table; \nthe first value is in the table, the second is not. No bucket has more than one element. If the hash \ntable were rarely modified, C could also be used to dynamically construct a perfect (or near-perfect) \nhash function at run time, possibly further improving performance. A second benchmark we provide for \nthis case is ms, in which we repeatedly scale a 100x100 matrix of integers by a run-time constant. Parameterized \nfunctions. Many library routines are parameter- ized via function pointers. Examples include the standard \nC library quicksort and heapsort routines, and many mathematical library routines. Unfortunately, indirect \nfunction calls eliminate many po- tential optimizations, since the function cannot be integrated with \nthe library code. Since cspecs can be composed with each other arbitrarily, C could be used to parametetize \nlibrary functions with cspecs rather than function pointers, potentially leading to large gains in efficiency. \nWe provide two benchmarks that fit in this class. The first is a simple heapsort function, heap, that \nis parameterized with a code fragment to swap the contents of two memory regions of arbitrary size. It \nconsiderably outperforms static versions by specializing itself with respect to the size of the array \nelements that it sorts. Our experiment measures the time to heapsort a 500-entry array of 1Zbyte structures. \nThe static code copies the structures using memcpy. The second example is a Newton-Raphson root solver, \nntn. The function and its derivative are provided by code fragments that are, again, incorporated into \nthe function at run time. The experiment computes the root of the function f(z) = (Z + 1) to a tolerance \nof lo- . The static code uses Newton s method parameterized via two functions: one to compute f, the \nother to compute f . Function composition. Similarly, C allows modular function composition: composed \ncode specifications can be integrated to- gether by tee into straight-line code. This functionality is \nanalogous to being able to dynamically inline the code referenced by arbitrary function pointers. Networking \ncode is one important application of this type of composition. The networking community has long aimed \nto mod- ularly compose protocol layers [9]. Each protocol layer frequently involves data manipulation \noperations (e.g., checksumming, byte- swapping, etc.). Since performing multiple data manipulation passes \nis expensive, it is desirable to compose the layers so that all the data handling occurs in one phase \n191. This modular composition of data operations is an active research area. The two main limitations \nof current approaches to this problem are that they use specialized lan- guages and, with the exception \nof work using VCODE [ 141, they are static, in that passes cannot be built at run time. A more powerful \nap- proach is to use C to compose functions dynamically; programmers can use a language they are accustomed \nto, and data manipulation steps can be flexibly composed at run time. This benchmark is called cmp. The \nexperiment measures the time to copy a 4096-byte message buffer while computing both a checksum and a \nbyteswap operation. The static code performs these operations using function pointers while the C code \nrepresents checksum and byteswap as code specifications that are dynamically incorporated into the data-copying \nloop. Small language compilation. Many small, primitive languages are both time-critical and amenable \nto dynamic compilation. The query languages used to interrogate data bases are well-known tar-gets for \ndynamic code generation [30]; since databases are large, dynamically compiled queries will be applied \nmany times. We have developed a small query language and benchmarked a dynamic query compiler for it, \nquery. Each query is a boolean expression formed by accessing record fields and comparing them to other \nfields or to constant values. The experiment performs a query on a database with 2000 entries and selects \nthose entries matching a query expression composed of five binary comparisons. The static code interprets \nqueries using a pair of switch statements, while the C version dynamically compiles the query to machine \ncode. Dynamic function call construction. C allows programmers to generate functions and calls with statically \nunknown numbers and types of arguments. This is a powerful feature. For instance, it allows the construction \nof code to marshal and unmarshal arguments stored in a byte vector, operations frequently performed to \nsupport remote procedure call [3]. By generating specialized code for the most active functions it is \npossible to gain substantial performance benefits [44]. Our two benchmarks, mshl and umshl, dynamically \ngenerate marshaling and unmarshaling code, respectively, given a printf-style format string specifying \nthe types of arguments. This ability goes beyond mere performance: ANSI C simply does not provide mechanisms \nfor dynamically constructing function calls with varying numbers of arguments. The mshl experiment measures \nthe time required to construct and run a function that takes five arguments and marshals them into a \nbyte vector. It is not possible to write equivalent C code in ANSI C. If the interface is exposed to \nthe client, it is possible to crudely emulate this functionality using C s varargs facilities, but not \nwithout requiring that the caller always provide information about the number and types of arguments. \nThe umshl experiment measures the time to unmarshal a byte vector and call a function taking five arguments. \nIt is impossible to write code that performs an equivalent function in ANSI C, since doing so requires \nthe ability to generate function calls with varying number of arguments. Therefore, to give some feel \nfor the speed of the generated code, we compare to statically compiled C code that handles the specific \ncase of five arguments. Dynamic partial evaluation. Partial evaluation specializes afunc- tion with respect \nto some number of arguments. C can be used to implement partial evaluation in the context of C. An example \nfrom computer graphics ([ 131) is partial evaluation of the exponentiation function with respect to a \ngiven exponent. This is very useful, be- cause. it reduces the exponentiation algorithm to a minimum \nnumber of multiplication and squaring operations. The benchmark pow dy- namically generates a specialized \nfunction that raises its argument to the power 13. The static version uses a general integer power function. \nCode construction. C can be used to perform unusual code con- struction tasks, such as creating executable \ndata structures. The benchmark binary takes a sorted integer array as input and creates code that implements \na binary search on that array. The values from the array are hardwired into the instruction stream, and \nthe mini- mum number of conditionals and jumps are performed during the search. Thus, lookup into the \narray involves neither memory loads nor looping overhead: the code is a series of nested if statements \nthat compare the value to be found to constants. As a result, the dynamically constructed code is an \norder of magnitude more efli- cient that its static counterpart. The benchmark measures the time to repeatedly \nlook up two entries (one present, one not) in a 16-entry Putting it all together. To validate our system \non a larger exam- ple, we have modified xv, a large and popular image manipulation package. Specifically, \nwe picked one of its image processing algo- rithms (we deemed this sufficient, since most of the algorithms \nare implemented very similarly) and changed it to make use of run-time information. The algorithm, Blur, \napplies a convolution matrix of user-specified size and consisting of all l s to the source image. The \noriginal algorithm was implemented very efficiently: since the values in the convolution matrix are known \nstatically to be all l s, convolution at a point is simply the average of the image values of neighboring \npoints. Nonetheless, the inner loop contains image- boundary checks based on run-time constants, and \nis bounded by a run-time constant, the size of the convolution matrix. By unrolling this loop and exploiting \nthe run-time constant checks, tee produces code that runs in 1.08 seconds (on a 640x480 image and 3x3 \ncon- volution matrix), with a dynamic compilation time of only 0.01 seconds (using our more expensive \ndynamic back end, ICODE). By contrast, code generated hy ICC runs in 1.96 seconds, almost two times more \nslowly. Code emitted by GNU CC with all optimiza- tions turned on runs in 1.04 seconds. All results are \nbest of 5 runs, on an unloaded SparcStation 5. As mentioned earlier, the basis for comparison of the \nperformance of dynamic code should be ICC, since the dynamic back ends are generated by an ICC-style \nback end, without further static optimizations. xv is an example of the profitability of dynamic code \ngeneration in the context of a well- known application program. We are confident that additional work \non static optimization of the code-generating functions will make tee s dynamic code superror even to \nthat of aggressive optimizing compilers, without penalizing dynamic compilation times. Other uses. The \nbenefits of dynamic code generation extend be- yond efficiency. For instance, C-enabled currying can \nbe used to associate functions with state that is not visible to the caller. This technique is implemented \nby dynamically generating a wrapper function that calls the original function with internally bound state, \nthereby providing information hiding while allowing functions to be parameterized with data.  6.3 Results \nThis section discusses the performance of dynamic code versus static code measured for our benchmarks, \nas well as the break down of dynamic compilation costs. In both Figure 4 and Figure 5, the legend indicates \nwhich static and dynamic compilers are being compared. icode-lee compares dynamic code created with ICODE \nto static code compiled with ICC, vcode-gee compares dynamic code created with VCODE to static code compiled \nwith GNU CC, and so forth. Figure 4 illustrates the ratio of run time of static code to run time of dynamic \ncode: a ratio greater than one means that dynamic code generation is profitable. In general, this ratio \nis considerably greater than one: in some cases, dynamically generated code is up to an order of magnitude \nfaster than static code. In three cases, however, dynamic code generation does not pay off. In the case \nof umshl, as mentioned, we are providing dynamically a functionality that does not really exist in C: \nthe static code we created specifically for this example is very well tuned. In the case of hash and \nms, [CODEprovides some advantage over static code (specifically, in the case of ms, we see a six-fold \nspeed-up), but the code generated with VCODE is slower. We attribute this to the fact that VCODE does \nnot perform any significant optimization other than strength-reduction of run-time constants. Figure \n5 gives an indication of the relative costs of dynamic code generation. The cross-over point on the vertical \naxis is the number of times that a piece of dynamic code must be. executed in order for the sum of the \ncost of its invocations and its compilation to be less than or equal to the cost of the same number of \ninvocations of static code. This is a measure of how quickly dynamic code pays for itself. In 3 cases \n(umshl, and hash and ms using VCODE) there are no vertical bars: this is because the dynamic code is \nslower than the static one, so the cross-over point never occurs. Usually, however, the performance benefit \nof dynamic code generation occurs after a few hundred or fewer invocations. In some cases (ms using ICODE, \ncmp, and query) the dynamic code even pays for itself after only one run. These graphs confirm the central \n(and predictable) tradeoff in- herent to the design of tee. Improvements in dynamic code quality come \nat the cost of additional dynamic compilation time. Using VCODEto perform fast, in-place dynamic code \ngeneration is very cheap, and can thus often be effective when the dynamic code is not used very much. \nBut there are some cases when the code quality is not sufficiently good; ICODE then provides a good alternative, \neven though its code-generating costs can be up to an order of magnitude larger than those of VCODE. \nInterestingly, incurring the extra cost of code optimization can sometimes improve code quality sufficiently \nto make dynamic compilation pay off sooner than in the unopti- mized case. This occurs for the ntn benchmark, \nin the icode-gee and vcode-gee cases. Although the VCODE back end generates code six times more quickly \nthan ICODE, the dynamic code generated by ICODE pays for itself in approximately two thirds the number \nof runs required for the VCODE-generated code to pay off (see Figure 5). Figures 6 and 7 analyze these \ncode generation costs in more detail. Figure 6 shows that the VCODE back end generates code at between \n100 and 500 cycles per generated instruction. The cost of manipulating closures and other meta-data is \nnegligible: almost all the time is spent actually emitting binary code. Figure 7 presents similar breakdowns \nin the case of ICODE. For each benchmark, the left column displays code generation costs when using the \nlinear scan register allocation, and the right column displays costs when using graph coloring register \nallocation. The ICODE back end gen- erates code at a speed between approximately 1000 and 2500 cycles \nper generated instruction. The costs of manipulating closures and building the intermediate representation \nare small, as is the time spent translating the ICODE opcodes to machine code. Approxi- mately 70-80% \nof the ICODE code generation cost is due to register allocation and related operations, such as computing \nlive variables and building live ranges. The linear scan register allocation algo- rithm outperforms \nthe graph coloring allocator in all cases but one, sometimes by up to a factor of two (in the case of \ndp). The perfor- mance of the two allocators depends very much on the structure of the code. When the \ncode contains many variables (as is the case, for example with dp), scanning live ranges is superior \nto graph color- ing. By contrast, when there is a lot of code but very few variables (as in binary, the \nonly benchmark where the linear scan performs more poorly than graph coloring), it is cheaper to color \nthe (small) Cvcletiaenerated instruction Ratio (static time / dynamic time) 0 VI 0 m C ....  0 . ,./ \n^> CycleggeneraFd instruzion Cross-over point (number of runs, log scale1 interference graph than to \nset up the live ranges for the linear scan.  7 Conclusion Dynamic code generation is a powerful and \nuseful technique which has not been widely exploited so far because of inadequate language and compiler \nsupport. This paper has described and evaluated tee, the first full imple- mentation of C. C is a superset \nof ANSI C, designed to expose the dynamic code generation process to the programmer at the level of C \nexpressions and statements. Unlike previous systems for dynamic code generation, it gives the programmer \nfull control of the code creation process while remaining expressive and portable. tee is a solid and \nvaluable tool for exploiting dynamic code generation in day-to-day programming and exploring techniques \nand tradeoffs of dynamic code generation itself. A release of the software, which currently runs on MIPS \nand SPARC processors, is available. Measurements on sample code from a variety of application ar-eas \nreveal that an efficient and easy-to-use implementation of a dy- namic code generation system can provide \nsignificant performance improvements. We have reported measurements of running times for both dynamically \ngenerated code and equivalent static C code, and have compared these running times to those of code compiled \nby a widely-used optimizing compiler, GNU CC. Performance gen-erally improved, increasing by up to an \norder of magnitude in the best cases. For several applications, the cost of dynamic code gen-eration \nwas amortized after just one execution of the dynamically generated code. Acknowledgments We thank Vivek \nSarkar and Eddie Kohler for their help and insights regarding register allocation, and Jonathan Litt \nfor his pa- tience in rewriting parts of xv in C, helping us find several compiler bugs along the way. \n References [ll J. Auslander, M. Pbilipose, C. Chambers, S. Eggers,and B. Bershad. Fast, effective dynamic \ncompilation. In Proceedings of the SIGPLAN 96 Conference on Programming Language Design and Itnplementa- \nrion, pages 149-159, Philadelphia, PA, May 1996. [21 B. N. Bershad, S. Savage, P. Pardyak, E. G. Sirer, \nM. Fiuczynski, D. Becker, S. Eggers, and C. Chambers. Extensibility, safety and performance in the SPIN \noperating system. In Proceedings ofthe Fifteenth ACM Symposium on Operating Systems Principles, pages \n267-284, December 1995. [31 A. D. Birrell and B. J. Nelson. Implementing remote procedure calls. ACM \nTransactions on Computer Systems, 2(1):39-59, February 1984. 141 J. Bradley. ~~-3.10. f tp:/ / ftp. cis \n. upenn. edu. r51 D. Callahan and 8. Koblenz. Register allocation via hierarchical graph coloring. SfGPL4N \nNotices, 26(6):192-203, June 1991. (61 G. J. Chaitin. Register allocation and spilling via graph coloring. \nSIGPLAN Notices, 17(6):201-207, June 1982. [71 C. Chambers and D. Ungar. Customization: Optimizing compiler \ntechnology for SELF, a dynamically-typed object-oriented program- ming language. In Proceedings of PLDI \n89, pages 146-160, Portland, OR, June 1989. 181 F. C. Chow and J. L. Hennessy. Registerallocation by \npriority-based coloring. SIGPlANNofices, 19(6):222-232. June 1984. [91 D. D. Clark and D. L. Tennenbouse. \nArchitectural considerations for a new generation of protocols. In ACM Communication Architectures. Protocols, \nand Applications (SIGCOMM) 1990, September 1990. R. F. Cmelik and D. Keppcl. Shade: A fast instruction-set \nsimula- tor for execution profiling. In Proceedings of the 1994 ACM SIG- METRICS Conference on Measurement \nand Modeling of Computer Sysrems, pages 128-137, May 1994. [Ill C. Consel and E Noel. A general approach \nfor run-time specialization and its application to C. In Proceedings of the 23th Annual Sympo- sium on \nPrinciples of Programming Languages, pages 145-156, St. Petersburg. FL. January 1996. [l21 P. Deutsch \nand A.M. Schiffman. Efficient implementation of the Smalltalk-system. In Proceedings of 11th POPL, pages \n297-302. Salt Lake City. UT, January 1984. [l31 S. Draves. Lightweight languages for interactive graphics. \nTechnical Report CMU-CS-95-148, Carnegie Mellon University, May 1995. t141 D. R. Engler. VCODE: aretargetable,extensible, \nvery fast dynamic code generation system. In Proceedings of the SIGPLAN 96 Conference on Programming \nLanguage Design and Implementation. Philadelphia, PA,Mayl996.http://www.pdos.lcs.mit.edu/-engler/ vcode.html. \n1151 D. R. Engler, W. C. Hsieh, and M. E Kaashoek. C: A language for high-level, efficient, and machine-independent \ndynamic code genera- tion. In Proceedings of the 23th Annual Symposium on Principles of Programming Lunguages, \npages 131-144, St. Petersburg, FL, 1995. cl61 D. R. Engler, M. F. Kaashoek, and J. O Toole Jr. Exokemel: \nan op- erating system architecture for application-specific resource manage- ment. In Proceedings of \nthe Fifteenth ACM Symposium on Operating Systems Principles, pages 251-266, Copper Mountain Resort, Col- \norado, December 1995. [l71 D. R. Engler and M. Frans Kaashoek. DPF: Fast, flexible message demultiplexing \nusing dynamic code generation. Proceedings of ACM SIGCOMM 96 Conference on Applications, Technologies, \nArchitec- tures and Protocols for Computer Communication, pages 53-59, Au- gust 19%. V81 D. R. Engler \nand M. Poletto. A C tutorial. Technical Memo MIT- LCS-TM-564, MIT Laboratory for Computer Science, March \n1997. [l91 D.R. Engler and T.A. Proebsting. DCG: An efficient, retargetable dynamic code generation system. \nProceedings of ASPLOS-VI, pages 263-272, October 1994. [201 G. E. Forsythe. Computer Methoak for Mathematical \nComputations. Prentice-Hall, Englewood Cliff... NJ, 1977. 1211C. Fraser. copt. ftp://ftp.cs.princeton.edu/pub/ \nlcc/contrib/copt.shar. [221 C. W. Fraser and D. R. Hanson. A code generation interface for ANSI C. Technical \nReport CS-TR-270-90, Department of Computer Science, Princeton University, 1990. 1231C. W. Fraser and \nD. R. Hanson. A retargetable C compiler: design and implementation. Benjamin/Cummings Publishing Co., \nRedwood City, CA, 1995. [241 R. A. Freiburghouse. Register allocation via usage counts. Commu-nications \nof the ACM, 17( 11):638-642, November 1974. [251 R. Gupta, Mary Lou Soffa, and T. Steele. Register allocation \nvia clique separators. SIGPLAN Notices, 24(7):264-274, June 1989. [261 U. Hijlzle and D. Ungar. Optimizing \ndynamically-dispatched calls with run-time type feedback. In Proceedings of PLDI 94, pages 326 335, Orlando, \nFlorida, June 1994. ~271 W-C. Hsu, Charles N. Fischer, and J. R. Goodman. On tbe minimiza- tion of loads \nand stores in local register allocation. IEEE Transactions on Sofhvore Engineering, 15( IO): 1252-1260. \nOctober 1989. [28] D. Kcppel. A portable interface for on-the-fly instruction space modi- fication. In \nFourth International Conference on Architectural Support for Programming Languages and Operating Systems, \npages 86-95, April 1991. [29] D. Keppel. S.J. Eggers, and R.R. Henry. A case for runtime code generation. \nTR 91-l l-04. Univ. of Washington, 1991. [30] D. Keppel, S.J. Eggers, and R.R. Henry. Evaluating runtime-compiled \nvalue-specific optimizations. TR 93 I I-02, Department of Computer Science and Engineering, University \nof Washington, November 1993. [31] M. Leone and P. Lee. Lightweight run-time code generation. In Proceedings \nof rhe Workrhup on Parrial Evaluation and Semantics-Based Program Manipu/arion, pages 97-106, Copenhagen, \nDenmark, June 1994. [32] M. Leone and P. Lee. Optimizing ML with run-time code generation. In Proceedings \nof the SIGPLAN 96 Conference on Programming Language Design and Implementation, May 1996. [33] P. Cl. \nLowney, S. M. Freudenberger, T. .I. Karzes, W. D. Lichtenstein, R. P Nix, J. S. O Donnell, and J. C. \nRuttenberg. The Multiflow trace scheduling compiler. In The Journal of Supercompuring, volume 7, pages \n51-142, 1993. [34] G. Lueh, T. Gross, and A. Adl-Tabatabai. Global register allocation based on graph \nfusion. Technical Report CMU-CS-96-106, Carnegie Mellon University. March 1996. [35] J.K. Ousterhout. \nTel and the Tk Toolkit. Addison-Wesley Professional Computing Series. Addison-Wesley, Reading, MA, 1994. \n[36] R. Pike, B.N. Locanthi, and J.F. Reiser. Hardware/software trade-offs for bitmap graphics on the \nBlit. Software-Practice and Experience, 15(2):131-151, February 1985. [37] M. Poletto, D. R. Engler, \nand M. F. Kaashcek. tee: A template-based compiler for C. In Workshop on Compiler Supponfor Systems Soft- \nware. Tucson, AZ, February 1996. [38] T. A. Proebsting. Simple and efhcient BURS table generation. SIG- \nPLAhJ Notices, 27(7):33 I-340, June 1992. [39] C. Pu. T. Autry, A. Black, C. Consel, C. Cowan, J. Inouye, \nL. Kethana, J. Walpole, and K. Zhang. Optimistic incremental spe- cialization: streamlining a comtnerical \noperating system. In Proceed-ings of rhe Ffieenth ACM Symposium on Opemting Systems Princi- ples, Copper \nMountain, CO, December 1995. [40] C. Pu, H. Massalin, and J. Iaannidis. The Synthesis kernel. Compur-ing \nSysfems, l(1): 1 l-32, 1988. [41] J. Rees. W. Clinger (editors). et aI. Revised4 report on the algorithmic \nlanguage Scheme. AIM 848b. MIT AI Lab, November 1992. 1421 V. Sarkar. Personal communcation, September \n1996. [43] G.L. Steele Jr. Common Lisp. Digital Press, second edition, 1990. [44] C. A. Thekkathand H. \nM. Levy. Limits to low-latency communication on high-speed networks. ACM Tmnsacfions on Computer Systems. \n11(2):179-203, May 1993. [45] K. Thompson. Regularexpressionsearchalgorithm. Communications ofthe ACM, \n1 l(6). June 1968. 1461 J.E. Veenstra and R.J. Fowler. MINT: a front end for efficient simula- tion of \nshared-memory multiprocessors. In Modeling and Simulation of Computers and Telecommunications Systems, \n1994. [47] L. Wall. The Per1 Programming Language. Prentice Hall Software Series, 1994. [48] E. Witchel \nand M. Rosenblum. Embra: Fast and flexible machine simulation. Proceedings of ACM SIGMETRICS 96 Conference \non Measurement and Modeling of Computer Sysfems. pages 68-79, May 1996. \n\t\t\t", "proc_id": "258915", "abstract": "tcc is a compiler that provides efficient and high-level access to dynamic code generation. It implements the 'C (\"Tick-C\") programming language, an extension of ANSI C that supports dynamic code generation [15]. 'C gives power and flexibility in specifying dynamically generated code: whereas most other systems use annotations to denote run-time invariants. 'C allows the programmer to specify and compose arbitrary expressions and statements at run time. This degree of control is needed to efficiently implement some of the most important applications of dynamic code generation, such as \"just in time\" compilers [17] and efficient simulators [10, 48, 46].The paper focuses on the techniques that allow tcc to provide 'C's flexibility and expressiveness without sacrificing run-time code generation efficiency. These techniques include fast register allocation, efficient creation and composition of dynamic code specifications, and link-time analysis to reduce the size of dynamic code generators. tcc also implements two different dynamic code generation strategies, designed to address the tradeoff of dynamic compilation speed versus generated code quality. To characterize the effects of dynamic compilation, we present performance measurements for eleven programs compiled using tcc. On these applications, we measured performance improvements of up to one order of magnitude.To encourage further experimentation and use of dynamic code generation, we are making the tcc compiler available in the public domain. This is, to our knowledge, the first high-level dynamic compilation system to be made available.", "authors": [{"name": "Massimiliano Poletto", "author_profile_id": "81332521336", "affiliation": "Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA", "person_id": "PP38030750", "email_address": "", "orcid_id": ""}, {"name": "Dawson R. Engler", "author_profile_id": "81100222430", "affiliation": "Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA", "person_id": "P64637", "email_address": "", "orcid_id": ""}, {"name": "M. Frans Kaashoek", "author_profile_id": "81100521650", "affiliation": "Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA", "person_id": "PP14181132", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258915.258926", "year": "1997", "article_id": "258926", "conference": "PLDI", "title": "tcc: a system for fast, flexible, and high-level dynamic code generation", "url": "http://dl.acm.org/citation.cfm?id=258926"}