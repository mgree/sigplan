{"article_publication_date": "05-01-1997", "fulltext": "\n Incremental Analysis of Real Programming Languages* Tim A. Wagner and Susan L. Graham University of \nCalifornia, Berkeley Abstract A major research goal for compilers and environments is the au- tomatic \nderivation of tools from formal specifications. However, the formal model of the language is often inadequate; \nin particu- lar, LNL) gramma ra are unable to describe the natural syntax of many languages, such aa \nC++ and Fortran, which are inherently non-deterministic. Designers ofbatch compilers work around such \nlimitations by combining generated components with ad hoc tech- niques (for instance, performing partial \ntype and acope analysis in tandem with parsing). Unfortunately, the complexity of incremen-tol systems \nprecludes the use of batch solutions. The inability to generate incremental toola for important languages \ninhibits the widespread use of language-rich interactive environments. We addreaa this problem by extending \nthe language model it- self, introducing a program representation baaed on parse dags that is suitable \nfor both batch and incremental analysis. Ambigu-ities unresolved by one stage are retained in this representation \nuntil further stages can complete the analysis, even if the reaolu- tion depends on further actions by \nthe user. Representing ambigu- ity explicitly increases the number and variety of languages that can \nbe analyzed incrementally using existing methods. To create this representation, we have developed sn \nefficient incremental parser for general context-free grammara. Our elgo- rithm combines lhmita s generalized \nLX parser with reuse of en- tire aubtrees via state-matching. Diaambiguation can occur atat- ically, \nduring or after parsing, or during semantic analysis (using existing incremental techniques); program \nerrors that preclude diasmbiguation retsin multiple interpretations indefinitely. Our representation \nand analyses gain efficiency by exploiting the lo- cal nature of ambiguities: for the SPEC% C programs, \nthe explicit representation of ambiguity requires only 0.5% additional apace and leas than 1% additional \ntime during reconstruction. This research has bean sponsored in part by the Defense Advanced Research \nProjecta Agency (DARPA) under Grant MDA972-92-J-1028. The content of this paper does not necessarily \nreflect the position or policy of the U. S. Government. Authors addresses: Tim A Wagner, 673 Soda Hall \nand Susan L. Graham, 771 Soda Hall; Department of EECS, Computer Science Division, University of California, \nBerkeley, CA 94726-1776. email:twagner@cs.berkeley.edu, graham@cs.berkeley.edu U%: http://http.cs.berkeley.edu/-twagner, \nhttp://http.cs.berkeley.edu/-graham. Permission to make digital/hard copy of part or all this work for \npersonal or classroom use IS granted without fee provided that copies are not made or distributed for \nprofit or commercial advan- tage, the copyright notice, the title of the publication and its date appear, \nand notice is given that copying is by permission of ACM, Inc. To copy otherwise, to republish, to post \non servers. or to redistribute to lists, requires prior specific permission and/or a fee. PLDI 97 Las \nVegas, NV, USA 0 1997 ACM 0-B9791-907-6/97/0006....$3.50  1 Introduction Generating compiler and environment \ncomponents from declarative descriptions has a number of well- known advanta es over hand-coded a proaches, \nes- pecially when t i e result is intended Por an increm- ental setting. However, existing formal methods \nuse limited-and unrealistic-language models. In par- ticular, ambiguity, in both syntactic and semantic \nforms, is outside the narrow constraints of LR(1) parsing (the conventional method for syntax analy- \nsis) and is not addressed by attribute grammars (the most common form of formal semantic analysis). Batch \nsystems cope with such language idiosyn- crasies by remaining open; ad hoc code is coupled with generated \ncorn onents to overcome limitations in the lan age mo x el. Those solutions succeed be- cause the Yan \na e document is static and the anal- ysis order is i?tf e . (For example, it can be assumed that necessary \nsymbol table information is available when needed.) The eater complexity of increm- Y ental algorithms \nprec udes simple ad hoc solutions, due to the need to support incomplete documents and partial analyses \nthat depend on the order in which the user modifies the program. The result is a col- lection of standard \nre resent&#38;ions and al orithms unable to directly mo tf el the analysis of C, 5 ++, For- tran, Haskell, \nOberon, and many other languages. Thus many potential applications-compilers, envi-ronments, lan age-based \ntools-fo incremental-Y atch technolo- ity in favor of s ower, less informative T gies. Rather than lament \nthe design of these languag- es, we address the underlying issue by extendin the language model., producing \na framework that aifows existing formahsms to apply to a wider variety of languages. Our solution utilizes \na new intermediate representation (IR) for the early portions of the (pos- sibly incremental) compilation \npipeline: the abstract purse dug allows multiple interpretations to be rep- resented directly and efficiently. \nThe familiar pass- oriented compiler organization is supported, even in incremental settings, by allowing \namby to: resolved at different stages of t e an ysis. antic filters address the feedback problem (syntac- \ntic structure de endent u on semantic information) arising in C an 2 Fortran. F arsing filters 1111 address \nsuch problems as the declaration/expression ambi- int foo 0 ( int i; int j; a lb); c ambiguous--could \nbe c (d); + de&#38; or stmts. i = 1; j = 2; 1 Figure 1: A simple example of ambiguity in C and C++. \nIn this case, type information is necessary for disambiguation: the mid-dle two can declarations function \n lines be either or calls, depend- ing on how a and c have been declared previously in enclosing scopes. \nguity in C++ [3] and the off-side rule in Haskell[71. We describe mechanisms for applying both types \nof resolution using existin formal techniques, such as attribute grammars, will* e also permitting ad \nhoc resolution. Pre-compiled filters such as precedence and associativity declarations in yacc 111 are \nsup-ported in a uniform fashion. In the resence of miss- ing or malformed pro am text, m d tiple interpreta- \ntions may be retaine f indefinitely as a direct expres- sion of the possibilities. We have developed \na novel algorithm for increm- ental, non-deterministic parsing to (re)construct this IR. The parser accepts \nall context-free grammars: generalized LR parsing [20, 221 is used to sup-port non-determinism and ambiguity, \neliminating restrictions on the parsing grammar and the atten- dant need for abstraction services. Shiftin \nof entire subtrees via state-matching [8] provides e k cient in- cremental behavior, and explicit node \nretention 1251 minimizes the work of subsequent analysis passes. (Together they also ensure the preservation \nof user context and program annotations.) Lookahead infor- mation is dynamically tracked and encoded \nin pars- ing states stored in the nodes, eliminating the space overhead of previous ap roaches that require \nper- sistent maintenance oft Re entire graph-structured parse stack 141. As an example of an inherent \ncontext-free syn- tax ambiguity addressed by this representation, con- sider the syntax of C. Figure \n1 illustrates a case where the interpretation of several lines is context- sensitive, i.e., static semantic \nanalysis is needed to resolve the ambiguity.1 A similar roblem arises in C++, Fortran, Oberon, and other \nPan ages. This problem arises whenever the naturr context-free syntax depends on non-local type information \n[281. Ambi ity is discovered during analysis of the context- f? ee syntax, leaving multiple alternatives \nencoded in the parse dag. Early stages of semantic analysis resolve typedef declarations; binding in- \nformation for e names is then used to complete the resolution o p the program s syntax. (In the case \nof a correct program, the parse dag will become a Batch systems typically handle this problem by having \nthe lexer query the symbol table in order to separate identifiers into two distinct categories. Attributetiuenced \nparaing 110,211 ia a combination of IB parsing and a restricted clags of attribute grammam that addresses \nthe same problem in a formal way. Neither of these aolutiona can be applied to an incremental setting \nwhere non-trivial subtrees appear in the parser s input stream. conventional abstract parse tree.) Semantic \nanalysis then continues, using the resolved structure. This approach preserves the familiar compilation \npi eline model, and allows existing formal methods to L -plied to C and other ill-designed languages \nto p%- duce either batch or incremental environments. Encoding alternatives for later resolution is use- \nful in a number of stages in the compilation pipeline. Lexical decisions are often deferred until parsing \nor semantic analysis by having the lexer recognize only equivalence classes of tokens. Visser 1241 makes \nthis integration explicit for a batch system by us- ing a single GLR parser for both lexical and context-free \nanalysis. This approach can be made incremen- tal using the techniques we describe. Code genera- tion \nalso benefits from retaining multiple represen- tations until additional information has been gath- ered. \nGiegerich [51 applies context-sharing in this $ic.nonnto intersperse code selection and register al- \nWe have measured the s ace costs of our repre- sentation and the time over Eead to rebuild it incre- \nmentally using a benchmark suite that includes both C++ programs and the C rograms in SPEC95. Both measurements \nindicate t Rat the significant increase in the flexibility of the language model comes at vir- tually \nno cost. The efficiency results from exploit- ing an inherent property of programming (and nat- ural) \nlanguages: ambiguity is both constrained (the number of interpretations is small) and localized (the \nlength of an ambiguous construct is limited). The remainder of this paper is organized as fol- lows. \nIn Section 2 we describe the basic form of the rogram representation, concentrating on the han cf ling \nof alternative interpretations. Section 2 also summarizes empirical studies demonstrating the highly \nlocalized nature of ambiguity in programs and the minimal space overhead achievable through sharing. \nIn Section 3 we consider in detail the con- struction of our program representation using an in- cremental, \nnon-deterministic parser. We introduce a erformance model and analyze the asymptotic be- Kavior of the \nparser to demonstrate the efficiency of incremental updates. We conclude this section with a return to \nthe issue of sharing in the abstract parse dag, demonstrating optimality and correct-ness properties \nunique to our method. Mechanisms for disambiguation at various points in the anal- ysis phase-particularly \nsemantic disambiguation involving type information-are presented in Sec- tion 4. Implementation details \nand empirical com- parisons between deterministic parsing/parse trees and non-deterministic parsing/abstract \nparse dags are given in Section 5. A discussion of future work and our conclusions end the paper. The \nincremental GLR parsing algorithm is provided in Appendix A. A trace of the parser actions on a small \nC++ example is given in Appendix B.  2 Representing Ambiguity A hase-oriented incremental system can \nsucceed o J y if the intermediate representation explicitly represents unresolved ambiguities. The abstract \n a. Ferro, unambiguous case. b. Rekers, unambiguous case. c. Parse Dag, unambiguous case. d. Ferro, ambiguous \ncase. e. Pekers, ambiguous case. f. Parse Dag, ambiguous case. Figure 2: Comparison of the abstract parse \ndag to other proposed representations. The grammar productions illustrated are X+ABC 1EF.Ferro and Dion \ns approach (a) makes the GSS itself persistent; this requires semantic attributes associated with a production \n(right-hand side) to be attached to a constellation of nodes rather than an individual object. Rekers \nrepresentation (b) is more like a clas- sic parse tree but separates the symbol (phylum, left-hand side) \nand rule (production, right-hand side) into separate nodes. This imposes significant overhead, since \nthe vast majority of the program is deterministic. Our approach represents the deterministic portions \nof the tree in the conventional manner cc), using Rekers-style splitting only where multiple representations \nactually exist (f ). (Not shown are the additional state collections required by the Ferro and Dion approach \nor the problems with under- and over-sharing of epsilon productions eliminated in the abstract parse \ndag.) a(b) i c(d); Figure 3: Representation of ambiguous structure in the ab- stract parse dag. This \nis the result of parsing the example in Fig- ure 1 as a C++ program. Most nodes represent both productions \nand symbols. Choice points, shown as circles, represent only sym- bols; their children comprise the alternative \ninterpretations. In this case the shared subtrees are trivial-they are the terminal symbols in the ambiguous \nregion. The structure shown represents a simplification of the complete grammar. parse dag is similar \nto a parse tree except that a re- gion may have multiple interpretations. This section describes the \nrepresentation itself; subsequent sec-tions describe its construction, via non-deterministic parsing, \nand the resolution of ambiguities expressed through this IR. In the presence of ambiguity, many parse \ntrees po- tentially represent the program. To avoid exponen- tial blowup, this entire forest is collapsed \ninto a sin- gle, corn act data structure. Subtree sharing merges isomorpRl c regions from different trees, \nand requires no special changes-each instance of a production is represented by a single node, just as \nin a parse tree. Merging contexts, 2 however, requires a new type of node to indicate the choices. A \nsymbol node repre-sents a phylum (left-hand side) instead of an entire production; its children represent \nthe possible inter- pretations of their common yield. In the case of a correct program, later stages \nof analysis will disam- biguate the program by selecting exactly one child of each symbol node. Figure \n2 illustrates the distinc- tion between symbol and production nodes and com- pares our representation \nto other proposals. Figure 3 shows the abstract parse dag corresponding to the example in the introduction. \nIf the number of alternate interpretations at a single point is large, the children of a symbol node \ncan be represented as a balanced binary tree to en- sure the performance characteristics described in \nSection 3.4. In practice, however, the number of al- ternatives is effectively bounded and a simple list \nprovides sufficiently fast access. In a typical batch compiler, a grammar from a re- stricted grammar \nclass is used to produce a parser for the concrete syntax. A separate (often implicit) grammar defines \nthe abstract syntax representation Sometimes wferred t.0 a* packing in natural language analysis, Program \nLines Lang %ov compress SC gou Peg m88ksim 1934 205093 29246 31211 19915 c c C C c 0.21 0.10 0.00 0.02 \n0.02 per1 vortex 26871 67202 C C 0.01 0.00 xlisp 7597 c 0.02 emacs 19.3 159921 c 0.47 ensemble 294204 \nc++ 0.26 idl 1.3 29715 c++ 0.10 ghostscript 3.33 tc17.3 128368 26738 C C 0.52 0.31 Table 1: Programs \nused in this study. The first eight are from SPEC95. id1 is the SunSoft IDL front end and ensemble is \nour prototype software development environment. of the parsed program after artifacts of the concrete \nparse have been removed. GLR parsing enables a single grammar to formally define both the repre- sentation \nand the mechanism that builds it: sup-port for multiple syntactic interpretations and non- deterministic \nparsing permit arbitrary CFGs to be used in describing the language. This generality al- lows the grammar \nto serve as a pure definition of the resulting structure, rather than requiring it to conform to the \nrestrictions of some particular pars- ing class.3 Since our parse dag representation inher- its this \nbenefit of GLR parsing, we refer to it as ab- stract . (We will sometimes omit this modifier.) The abstract \nparse dag differs from the ordinary shared forest discovered by a GLR parser: Instances of productions \nare always represented by individual nodes, and sharing of both subtrees and contexts is optimal. We \nreturn to issues of sharing in Section 3.5 after explaining incremental GLR parsing. 2.1 Space Overhead \nfor Ambiguity Cognitive studies suggest that localization of ambi- guity is an inherent property of \nnatural languages, a constraint imposed by limitations on short-term memory 115, 171. Our studies find \nan identical result for programming languages.4 Since an ab- stract parse dag exploits localization of \nambiguity through the sharing of subtrees and contexts, the in- crease in space required relative to \na fully disam- biguated parse tree provides an ideal measure of the amount of ambiguity (as well as the \nspace overhead of adopting our IR). For the suite of C and C++ pro- grams in Table 1, we measured the \nincreased space consumption required to represent the multiple in- terpretations of each syntactically \nambiguous con- 3Even with GLR parsing, some erasing of concrete elements unnecessary for the abstract \nstructure, such as parentheses, is often done. 4This property was indirectly measured by Tomita [221 \nand Rekers 1201, who compared the speed of a batch GLR parser to Earley s algorithm [21 on natural and \nprogramming language grammars, respectively. Both authors concluded that grammars are close to LB(l) \nin practice, and therefore GLR parsing exhibits linear behavior despite ita exponential worst-case asymp \ntatic result. 70 I B 60 1 I 4 8 40- tr E; 30- d m- g 1oJ - 0 i 0 0.1 09 01 0.4 0.5 0.8 0.7 0.8 0.s 1 \n1.1 1.a Space inc- over perae tree (%I Figure 4: Distribution of ambiguities by source file in gee. \nThis histogram groups the source files of gee according to the amount of syntactic ambiguity they possess. \nThe syntax of C++ was used to determine these counta; the percentages would be lower using a C grammar, \ndue to the more restrictive statement syntax of that language. All ambiguities are semantically resolved \n(the typedef problem 1. They consist of two interpretationseach,and share only terminal symbols. struct. \nThe increase is relative to the parse tree pro- duced by a batch compiler (using semantic feedback to \nthe lexer and with the corresponding ambiguity in the grammar resolved through different identi- fier \nnamespaces). The average increase for each pro- gram in the suite is shown in the flnal column of Ta- \nble 1. Figure 4 shows the ambiguity distribution by source file for gee.  3 Constructing the Abstract \nParse Dag We now consider the construction of the abstract parse dag via incremental, non-deterministic \npars- ing. We first review batch GLR parsing and increm- ental parsing, which will jointly form the basis \nfor the incremental GLR (IGLR) parser. We introduce a performance model to analyze the asymptotic behav- \nior of the parser, and conclude the section by proving that sharing in the abstract parse dag is both \nopti- mal and correct. The algorithm itself appears in Ap- pendix A. 3.1 Generalized LR Parsing Batch \nGLR parsing [18, 20, 221 is a technique for arsing arbitrary context-free grammars that uti- Pizes conventional \nLR table construction methods. Unlike deterministic parsers, however, a GLR parser permits these tables \nto contain conflicts: when a state transition is multiply-defined, the GLR parser simply forks multiple \nparsers to follow each possi- bility. In the case of a deterministic parse requir- in additional lookahead, \nall but one of these parsers wlf. 1 eventually terminate by encountering a syntax error. In the case \nof true ambiguity, multiple valid representations will be discovered. In both cases, the graph-structured \nparse stack (GSS) represents the combined parse stacks compactly. This sharing is made possible by having \nthe GLR parse proceed :7 Parser1 ;w42 :u z $ 0,; x 1 23 43 Parser 2 v 2 ;cJ3  Figure 5: Illustration \nof non-determinism in a GLR parser. When the grammar is ambiguous or requires lookahead greater than \nthat of the table construction method (typically a single ter-minal), a GLR parser will split into two \nor more parsers. Here two parsers are being used in a region requiring two terminaIs of look- ahead with \nan LWl) table. (The grammar appears in Figure 7.1 In this case the parse is non-deterministic but unambiguous: \nwhen sufficient lookahead has been scanned dynamically, the GLR au- tomaton will collapse back to a single \nparser. In cases of true am- biguity, multiple interpretations are preserved in the resulting ab- stract \nparse dag. breadth-first: each terminal symbol is shifted simul- taneously by all active parsers in the \ncollection. Fig- ure 5 illustrates a GLR parser processing the non- LR( 1) grammar of Figure 7. As demonstrated \nin batch environments, GLR arsing simplifies the specification of programming Panguages by removing \nrestrictions on the parsing grammar and eliminatin the need for a separate ab- straction mechanism. d \ne ability to use additional lookahead allows a more natural expression of syn- tax and enables the description \nof truly ambiguous languages. 3.2 Incremental Parsing In an incremental parser, the input stream consists \nof both terminal and nonterminal symbols; the non- terminals label the roots of the unmodified subtrees \nfrom the previous version of the parse tree. Two dis- tinct a proaches can be taken: sentential-formpars- \nw R ere the grammar is the basis for incremen- p9 &#38;y and state-matching where the configuration of \nthe pushdown automat&#38; is recorded in the tree and used to skip steps in subsequent analyses. For \nLALR or LR grammars with all conflicts resolved at parse table construction time? sentential-form pars- \ning is the better implementation method, since it re- quires less time and space than a state-matching \nal- gorithm [25]. However, sentential-form parsing can- not be used as the basis for a non-deterministic \nin-cremental parser with conventional table construc- tion: the stronger test of state-matching is needed \nto expose the possibility of non-deterministic splitting when shifting an otherwise valid subtree. In \na state-matching implementation 18,141, each node representing a nonterminal symbol contains a record \nof the configuration of the pushdown automa- ton (the parse state > when the node was shifted onto the \nstack. A subtree can be reused when both its left and right context are unchanged: in an LRU) parser, \nreuse is determined by an equality test be- tween the current parse state and the state recorded Right \n(subtree rouse) Stack LoMparsoWack~~ lyxl IF! Figure 6: Illustration of deterministic incremental parsing. \nHere a change to a token has resulted in a split of the parse tree from the root. to the shaded lookahead \nnode denoting the modi-fied terminal svmbol. (Nodes on the snlit nath are shown dashed.) The shaded region \nto the left is the parse stack, which is instant tiated as a separate data structure since it contains \na mixture of old and new subtrees. The shaded region to the right is the subtree reuse stack, which provides \nthe p%.entially reusable sub- trees of the parser s input stream. This stack is not explicitly materialized-its \ncontents are derived by a traversal of the parse tree as it existed immediately prior to reparsing. in \nthe node, together with a check to ensure that the same termmal symbol follows the subtree as in the \nprevious analysis. If the shift of a subtree is invalid, it is decomposed into its constituent subtrees, \nwhich are pushed back onto the input stack. This process continues until the lookahead symbol is a terminal \nor shifting can resume. The user may apply any number of changes before requesting a reparse. Both textual \nand structural editing are permitted; the structure of the parse dag and the contents of its terminal \nsymbols (tokens) reflects all modifications applied since the revious parse. Once the parser is invoked, \nit splits t K e parse dag at each modification point (interior nodes with structural changes or terminal \nnodes with textual changes). The input stream to the parser consists of both new material, in the form \nof tokens provided by an incremental lexer, and reused subtrees; the lat- ter are conceptually on a stack, \nbut are actually pro- duced by a directed traversal over the version of the tree as it existed immediately \nprior to the start of reparsing 1261. An explicit stack is used to maintain the new version of the tree \nwhile it is being built. Fig- ure 6 illustrates a common case, where a changed token has resulted in \na split from the root to the changed terminal symbol. Shifting a subtree takes O(1) time when state- \nmatching succeeds. However, reductions require ex- tra time since a terminal symbol is needed to index \nthe parse table. (Alternatively, the leftmost termi- nal descendant can be recorded in every node, cost- \ning space.) Often this overhead can be eliminated en- tirely by precomputing nonterminal reductions: \nwe can perform reductions with a nonterminal N if all reduction actions in state s are identical for \nevery ter- minal in FIRST(N), provided that N does not gener- ate E. In the remainin cases, the lookahead \ns struo ture must be traverse % to locate the next terminal. 3.3 Incremental GLR Parsing We now turn \nto the construction of an incremental GLR (IGLR) parser that can parse an arbitrary CFG non-deterministically, \nwhile simultaneously accept- ing non-trivial subtrees in its input stream. The abstract parse dag is \n(re)created during parsing; Section 3.5 explores this process in more detail. Appendix B contains a sample \ntrace of the IGLR parser s actions using our running example and a simplified C++ grammar. The IGLR parser \ncombines subtree reuse in de-terministic regions with GLR methods in areas re- quiring non-deterministic \nparsing. This aggrega- tion of the two algorithms is complicated by the un- constrained lookahead of \nnon-deterministic parsing: even though such regions are limited in practice, lo- cating the boundary \nof such a region is necessary in order to reuse unchanged subtrees. As in previous GLR algorithms, we \nemploy a graph-structured parse stack (GSS) to permit non- deterministic parsing. During parsing, determinis- \ntic behavior is assumed to be the common case. (Sec- tions 2.1 and 5 validate this assumption through \nempirical measurements.) As with a deterministic state-matching parser, each node of the parse dag requires \nan additional word of storage to record the parse state in which it was constructed. LALR(1) ta- bles \nare used to drive the parser: not only are they significantly smaller than LR( 1) tables, but they also \nyield faster parsing speeds in non-deterministic re- gions [13] and improved incremental reuse in deter- \nministic regions (due to the merging of states with like cores).5 Left context checks involve the same \ninteger com- parison used by a deterministic state-matching in- cremental parser. When elements of the \nparse are non-deterministic, however, the right context check is more complicated than its deterministic \ncounter- part, which simply verifies that the terminal sym- bol following a potentially reusable subtree \nis un- changed. For general context-free parsing, there is no fixed bound on right context; an incremental \nGLR parser cannot assume that the amount of lookahead encoded in the parse table (usually one) is sufficient \nto determine when a reduction s right context is un- changed. Instead, the incremental GLR parser must \ntrack lookahead use d.ynamica1l.y; this information is re- corded in the nodes of the abstract parse \ndag, where it is used to influence future parses. The use of ex- tended right context can be encoded \nin the same field normally used to record the parse state. All non-de- terministic states are represented \nas an equivalence class with a unique state value. When any node pos- sessing this state value occurs \nas the lookahead sym- bol in subsequent analyses, the matching test will fail and the parser will decompose \nthe lookahead into its constituent subtrees. Additional (dynamic) lookahead is required only when several \nparsers are simultaneously active. The IGLR parsing algorithm tracks this condition with a boolean flag. \nAfter shifting the lookahead, the flag is set to true if there are multiple active arsers. The flag is \nalso set to true when a parse tabPe inter- In the case where the grammar is LX but not IALR, the IGLR \nparser will try all the conflicting reductions, resolving the uncertainty when it shifts the following \nterminal gymbol. A -+ Bc I De B + Uz D -+ Vz U+X Figure 7: Tracking lookahead information dynamically. \nThis example illustrates a grammar that requires two tokens of looka- head. A GLR parser based on a single-lookahead \ntable will require nondeterminism to parse the sentence XX. Since the grammar is unambiguous, a unique \nparse tree results after c is read. The unsuccessful parser is discarded. Black ellipses indicate nodes \nfor which increased lookahead must be recorded during parsing, note that they coincide with reductions \nperformed while more than one parser was active. Nonterminals representing reductions in a deterministic \nstate (A+BC) require only the implicit (one token) lookahead; they are marked with the (singleton) parser \ns state when they are shifted onto its parse stack. rogation returns multiple actions. Durin a reduc- \ntion, the state value recorded in the new y-created f dag node is the state of the single active parser, \nif the flag is false, and the value representing all non- deterministic states (and thus the use of additional \nlookahead), if the flag is true. Figure 7 shows a sim- le case where dynamic lookahead is used by our \nPGLR parser to analyze an LR(2) grammar using LR(1) tables. When both the previous state (preserved in \nthe root node of the lookahead subtree) and the cur-rent state are deterministic, parsing proceeds as \nin Section 3.2. Shifted subtrees may contain non- deterministic areas as long as they are not ex-posed. \nSubtrees containing modifications (textual and/or structural edits) are decomposed to expose each change \nsite. Subtrees from non-deterministic regions are similarly broken down, triggered by a failure of the \nnormal state matching test. If a conflict is encountered, the parser splits just as in batch GLR parsing, \nand subtrees in the input stream are fully decomposed until a deterministic state is re-established (see \nthe shifter routine in Appendix A). Shifting an unmodified, non-trivial subtree con- denses a sequence \nof transitions by the correspond- ing batch GLR parser. The portion of the abstract parse dag reused \nwhen the incremental algorithm shifts a non-trivial subtree reflect any splitting or merging that would \noccur in the GSS of the batch algorithm as it parsed the subtree s terminal yield. The correctness of \nskipping the intermediate steps is guaranteed in deterministic states by the usual in- cremental context \nchecks, and in non-deterministic states (which are treated as an equivalence class) by the restriction \nto terminal lookaheads. The correct- ness of incremental GLR parsing can then be estab- lished by an \ninduction over the input stream. Our approach differs significantly from the non- deterministic PDA simulator \nof Ferro and Dion [41, which uses the GSS itself as the persistent represen- tation of the program. Their \nrepresentation requires more space than our parse dag, in part because un- successful parses (used to \novercome lookahead limi- tations) must be retained for the sake of future state comparisons. (In Figure \n5, the portion of the GSS constructed by Parser 2 must be kept, even though it represents an unsuccessful \nsearch.) Their algorithm also makes state comparisons and semantic attribu- tion more expensive, since \nboth must refer to a col- lection of nodes. As with deterministic parsing, IGLR parsing can be extended \nto retain eGisting-progrti stru&#38;ure through node reuse [14, 19, 251. Both ambiguous and unambiguous \nreuse models are valid for abstract parse dags, and both bottom-up and top-down reuse mechanisms can \nbe applied. (For on-the-fly bottom- up reuse, we advocate retaining a single, shared list of reused nodes; \nmaintaining separate lists when multiple parsers are active imposes a performance and complexity cost \nfor minimal gain in the number of reused nodes.) 3.4 Asymptotic Analysis The IGLR parsing algorithm \nworks for any context- free grammar and, like GLR parsing, is exponen- tial in the worst-case 191 but \nlinear on actual pro- gramming language grammars. To ensure incremen- tal performance that improves on \nbatch parsing, we need to impose some additional restrictions on both the grammar and the representation \nof the abstract parse dag. Incremental behavior requires that the abstract parse dag support logarithmic \naccess time to each node. This is not the normal case: repetitive struc- ture, such as sequences of statements \nor lists of dec- larations, is typically expressed in grammars and represented in trees in a left- or \nright-recursive man- ner. These parse trees are thus really linked lists, with the concomitant performance \nimplication: any incremental algorithms degenerate to at best linear behavior, and thus represent no \nasymptotic advan- tage over their batch counterparts. There are two types of operators in grammars that \ncreate recursive structure: those that might have semantic significance, such as arithmetic op- erators, \nand those that are truly associative, such as the (possibly implicit) sequencing operators that separate \nstatements. The former do not represent true performance problems because they are natu- rally limited; \nfor instance, we can assume that the size of an expression in C is bounded by a constant in practice. \nThe latter type are problematic, since they are usually quite lengthy in non-trivial programs. To address \nthis problem, we represent associative operators in the abstract parse dag as balanced bi-nary trees. \nAn obvious way to indicate the freedom to choose a balanced representation for associative sequences \nis to describe the syntax of the language using an extended context-free (regular right part> grammar \n1121. We thus use the grammar both to specify the syntax of the language and to describe declaratively \nthe representation of the resulting ab- stract parse dag. Productions in the grammar cor- respond directly \nto nodes in the tree, while regu- lar expressions denoting sequences have an inter- nal representation \nchosen by the system-one that is guaranteed to maintain logarithmic performance. For purposes of analysis, \nwe assume that any un- bounded sequences are expressed in this fashion in the grammar. (Note that changes \nto the grammar are required-the parser generator cannot infer that a given sequence is associative.) \nIn addition, we need to assume that no non-de- terministic region spans a lengthy sequence, since this \nwould naturally require the entire sequence to be reconstructed whenever any part of it was changed. \n(Note that the elements of the sequence can be parsed non-deterministically or even be ambigu- ous, as \nis the case with C++.) Similarly, the interpre- tation of a sequence s yield cannot have more than a \nbounded dependence on its surrounding context, so that changes to adjacent material will not induce a \ncomplete reconstruction of the sequence. Given this assumption regarding the form of the grammar and \nthe representation of the abstract parse dag, we can analyze the time performance of the IGLR parser. \nIn the typical case where the left and right context of a subtree are unchanged, a state- matching algorithm \nwill shift that subtree in 0 1 time. In the event the context has changed, a v au i subtree containing \nM nodes can be shifted in O(lg M) steps by reconstructing its leading or trailing edge. Reductions and \nthe deterministic right context check are oRen accomplished in 0( 1) time using the follow- ing subtree; \nin the worst case the following termi- nal symbol is located in O(lg M) steps. Locally non- deterministic \nregions are reconstructed in their en- tirety, but our assumption that the size of such re- gions is \neffectively bounded (Section 2.1) implies a constant bound on the time to parse them. The result is a \ntypical parsing time of 0 ( t + s lg N) , for t new ter- minal symbols and s modification sites in a \ntree with N nodes, and O(t + s(lg N)2) time in the worst case. (Empirical results are discussed in Section \n5.) 3.5 Correct and Optimal Sharing Our approach treats the GSS as a transient data structure of the \nparser, using it to construct the abstract parse dag in the same way deterministic parsers construct \na concrete parse tree with the help of a parse stack. However, the connection is more complex than in \nthe deterministic case. In this sec- tion we discuss the removal of parsing artifacts from the shared \nparse forest discovered by GLR methods to produce the representation described in Section 2. The parse \nforest produced by GLR parsing re-sults in both over-and under-sharing, complicat-ing (in some cases \nprecluding) the application of ex- isting methods for semantic attribution and similar tools. GLR parsing \nas originally defined [221 results in under-sharing in the shared parse forest when iso- morphic subtrees \nwith the same yield are created in different states (i.e., by different parsers) due to left or right \ncontextual restrictions.6 Rekers corrects This is the same effect that causes incremental deterministic \nparsers based on state-matching to fail to reuse subtrees as aggressively as sentential-form parsers \n[251. under-sharing in his batch GLR parser by merging nodes that have identical yields 1201. Merging \nis per- formed separately for both symbol and rule (produc- tion) nodes. The same approach can be applied \nin our algorithm, since non-deterministic regions are reconstructed atomically. A different problem exhibited \nby GLR algorithms is over-sharing. A GLR parser does not distin-guish non-determinism to acquire additional \nlooka- head information from its use in parsing ambigu- ous phrases. In most cases, non-determinism for \ndy- namic lookahead results in deterministic (and un- shared) structure in the parse tree, since unsuccess- \nful parses eventually terminate. In the GSS, how- ever, sharing needed to handle certain types of gram- \nmars with c-productions results in sharing in the parse tree even for unambiguousgrammars [X31. We consider \nthis a flaw.; among other problems, it pro- hibits semantic attributes or annotations from being uniquely \nassigned to productions with a null yield, since separate instances may not exist in the parse tree. \n(Rekers algorithm exacerbates this problem by merging additional null-yield subtrees, violating left-to-right \nordering.) We correct this problem by adding a post-pass that incrementally duplicates any null-yield \nsubtrees updated by the parser. Since a unique maximal sharing of these subtrees does not necessarily \nexist, this is the only approach that is consistent, correct, and practical. Node reuse strate- gies \ncan be used to prevent unnecessary recreation of these and other subtrees 1251.  4 Resolving Ambiguity \nThe ultimate use of the abstract parse dag is to en- able disambiguation once the needed information \nis available. This filtering of alternatives can be static (decided at language specification time) or \ndynamic (decided at program analysis time). Dynamic filter- ing can involve both syntactic and semantic \ninforma- tion. The abstract parse dag and incremental GLR parser together provide a uniform and flexible \nframe- work for implementing ambiguity resolution at any point in the analysis process. 4.1 Syntactic \nDisambiguation Static syntactic filters, in conjunction with ambigu- ous grammars, are used frequently \nin compiler con- struction. Examples include the operator prece-dence and associativity specifications \nin yacc and bison [l] as well as techniques associated with a particular parse table construction algorithm, \nsuch as prefer shifting . Such methods can be applied at language specification time by selectively removing \nconflicts from the parse table, and therefore do not result in non-deterministic parsing or multiple \nrep- resentations. Since state-matching incrementalizes transitions in the pushdown automaton, any disam- \nbiguation statically encoded in the parse table is sup- ported by the IGLR parser. When the selection \nof a preferred interpretation cannot be determined a priori based on the left con- text and the im licit \n( builtin ) lookahead, a dynamic filter is require x. For example, the syntactic ambigu- ity in C++ expressed \nas prefer a declaration to an ex- pression requires a dynamic filter, since corn eting reductions cannot \nbe delayed until sufficient Pooka-head has been accumulated 131. The abstract parse dag allows ambiguities \nof this form to be encoded using multiple interpretations; an incremental post- pass can then select \nthe preferred structure by di- rectly applying rules such as the one above. Syn-tactic disambiguation \nof this form can also take place on-the-fly, provided it occurs only in a deterministic state to avoid \ncontaminating the dynamic lookahead computation. Unlike Ferro and Dion 141, we do not retain interpretations \neliminated by syntactic filters. In general, disambiguation specifications 16, 111 can be compiled into \na combination of static and dy- namic filters. Encodin as much filtering as pos- sible at language speci \na cation time decreases both the size of the representation and the analysis time. (This contrasts with \nexisting batch GLR environ- ments, which perform all syntactic filtering dynam- ically [20, 22!, and \nthus require quadratic space for each expression, in contrast to the negligible in- creases we report \nin Section 2.1.)  4.2 Semantic Disambiguation Filters for which the selection criteria are not con- \ntext-free are referred to as semantic filters. They may be applied in an ad hoc manner or as part of \na formal semantic attribution process (using attribute grammars or other approaches). Semantic filters \n&#38;e always dynamic; they are typically applied only after incremental narsine and any svntactic filter- \ning passes have &#38;mplecd. This organization pre- serves the familiar pass-oriented framework of batch \ncompilation even though the anal sis techniques are incremental-it thus avoids the Peedback that char- \nacterizes the solution to the typedef problem in ex- isting batch systems. While a complete discussion \nof incremental semantic analysis is beyond the scope of this paper, in this section we briefly outline \nthe sequence of events by which incremental semantic analysis can resolve our running example. Figure \n8 illustrates the sequence of events. Af-ter context-free analysis is complete, the first stage of semantic \nanalysis is applied to process typedef declarations. Type names introduced by such decla- rations are \ngathered into a binding contour, which is then propagated throughout the sco e. (This infor- P mation \nwill be inherited by both chi dren of a sym- bol node, reaching each identifier in an ambiguous region \ntwice.) In a correct rogram, the binding con- tour s contents uniquely L!etermine the namespace for each \nidentifier. With identifier namespaces decided, disambigua- tion per se can take place: parsing is completed \nby propagating the narnespace decision throu hout the ambiguous region. Boolean semantic attri gb utes \nin- dicate nodes filtered out of the parse dag in the un- wanted interpretation. Since all syntactic \nand sem- Contrast this with non-GLR appmaches, such as spawning a separate, hand-coded parser for potentially \nambiguous regions. . . :   FTypeaefs.iint . . a. Processing type definitions. b. Propagating typedef \nbindings. blcck 52 item h,, v. -. . . . . . *. *. *. **. El Tl Filtering semantic ambiguities. d. \nRemaining semantic passes Figure 8: Illustration of semantic disambiguation. This shows our running example \n(using C++, although the situation is similar in both C and Fortran) during the semantic analysis passes. \nIn (a) the basic context-free analysis has been completed, and the first stage of semantic analysis now \nresolves typede f definitions. In (b) this binding information ie propagated to the ambiguous regions, \nallowing the selection of the appropriate namespace for each identifier. In (c) disambiguation per se \noccurs, as the unwanted interpretation is filtered out (it is retained in case future edits reverse the \ndecision). In (d) semantic analysis continues, using the embedded tree discovered by stages a-c. (Note: \nThe right-hand side of production labels are omitted.) antic ambiguities have now been resolved, each \nsym-bol node can be logically identified with its single re-maining child in subsequent passes, allowing \ntools to treat the result as a normal parse tree.8 The order of the passes is the same for both batch \nand incremental scenarios. In the incremental case, each stage ins ects or updates only those portions \nof the pro am tRat have changed or could possibly be affectef by preceding changes [161. An mterestin \ncase occurs when a typedef declaration is removef : Binding information stored in semantic attributes \nallows the former uses of the declaration to be effi-ciently located. At each use site, the interpretation \nof the ambiguous region will change from a variable declaration to a function call as the namespace of \nthe region s initial identifier is altered. Note that the use sites themselves re uire no action from \nthe parser; other attributes oft1 e reinterpreted regions are re-evaluated as semantic analysis progresses. \n8Unlike syntactic disambiguation, semantic diaambiguation requires that the unwanted interpretations \nbe retained in the abetract parse dag. Semantic filtering uses non-local information (such as declarations \nin en-closing scopes) that can change and thus require a diierent resolution with-out a change to the \n.bcal strllcturt?. 4.3 Program Errors When the program is correct with respect to the lan-guage description \n(and the language as a whole is un-ambiguous) a single structural representation will eventually be discovered. \nIn the resence of sem-antic errors, such as missing, mal!armed? or incon-sistent declarations, it may \nnot be possible to de-termine a single inter retation of the entire struc-ture. In such cases tRe abstract \nparse dag main-tains multiple interpretations persistently; future edit/analysis cycles ma eventually \ncorrect the er-rors and allow the reso ution to succeed. These re- r gions are re-evaluated by the parser \nonly when they are modified and by semantic analysis only when the require re-interpretation. L aintaining \nevery potential interpretation in the presence of an error provides tools in the environ-ment with all \nrelevant information. While the pres-ence of persistent ambiguities may preclude some services, such \nas code generation, analyses not de-pendent on the missing information and services that do not require \ncomplete resolution (such as pre-sentation) can continue to operate using the unre-solved parse dag. \nErrors in the context-free syntax may also oc- cur and are detected in the usual fashion: when no parser \ncan successfully shift the (terminal) looka- head symbol. Syntactic error recovery can be sup- ported \nin the same fashion that we have adopted for deterministic parsing: a history-sensitive, non-correcting \nstrategy that reports deviations from cor- rect program components by integrating only those user modifications \nthat result in at least one valid parse tree. Any modifications remaining are flagged as unincorporated \nmaterial [27]. This approach is automated, language-independent, and incremen- tal. The primary change \nneeded to support IGLR parsing is an extension of the isolation boundary test to ensure that each non-deterministic \nregion is treated as an atomic unit: partial update incorpora- tion within such a region is not permitted. \n(This has no practical effect on the efficacy of the recovery, due to the small size of these regions \nin actual programs.) 5 Implementation and Empirical Performance The concepts described in this paper \nhave been implemented as part of the Ensemble incremen-tal software development environment being proto- \ntyped at UC Berkeley. Ensemble supports langua e definition through the off-line compilation of hig fl-level \nspecifications, dynamically loading the com-piled language analysis tools into a running environ- ment. \nExisting language definitions include Java, Modula-2, Fortran, a subset of Lisp, and C (with lim- ited \nreprocessor support). TEe IGLR arser has been implemented in this system as an ap ternative to the sentential-form \npars- er used for deterministic grammars [253. The IGLR implementation, which includes the parse table \nin- terface but not error recovery code, occupies less than 2000 lines of C++ code, including all tracing \nand assertion checking. The actual implementation corresponds closely to the algorithm given in Ap- pendix \nA. Support for abstract parse dags required very little change to Ensemble s low-level represen- tation, \nwhich is based on the self-versioning docu- ment model [26]. Parse table information is pro- duced using \na modified version of bi son that explic- itly records all conflicts in the grammar except for those \narising from the expansion of the associative sequence notation. Despite the slightly less efficient \nstack represen- tation used for GLR parsing relative to determin- istic arsing, the IGLR parser performs \nan initial ( bate R ) parse nearly as fast as its deterministic counterpart. C,g Java, and Modula-2 programs \nwere parsed with both arsers, and yielded an average of 12% overhead dpue to parsing per se for the de- \nterministic parser, compared with 15% for the IGLR parser. Most of the remaining time was spent in constructing \nthe nodes. In incremental tests (self- cancelling modifications to individual tokens, pars- For this \ncomparison, the typedef ambiguity was removed artificially. ing after each such change) the difference \nin running times for the two parsers was undetectable. Compared to sentential-form parsing for deter- \nministic grammars, the space consumption of the ab- stract parse dag is approximately 5% higher, due \nto the need to record explicit states in the nodes. The difference becomes negligible when semantic attributes, \npresentation data structures, and other per-node storage is also considered. The restriction that each \nnon-deterministically parsed region be reconstructed in its entirety when- ever it contains at least \none edit site imposes lit- tle overhead in ractice: since none of these regions s anned more t Ran a \nfew nodes in any of our sam- Pp e rograms, the additional reconstruction time was we1 P under l%, independent \nof the program, source file, or location of the ambiguous region within the file. 6 Extensions and Future \nWork Techniques for expressing both syntactic and seman- tic filtering in a uniform language would both \nsim- plify the language description process and allow op- timized performance by a plying resolutions \nat the earliest possible stage. 9 isser uses priorities and tree patterns to reduce static filters 1231, \nbut fur- ther work is nee If ed. An integrated model of semantic attribution and dynamic (semantic) filters \nremains an open problem. It requires extending scheduling al orithms to dags, balancing the restrictions \nrequired for efficient static scheduling with sufficient expressive power to model disambiguation methods \nthat arise in practice. This would improve language s ecifications and enable verification of the combine \ndpdescription. Incremental, non-deterministic parsing may also find application in rewrite systems and \nin the itera- tive analysis of natural language documents. 7 Conclusion This paper provides a mechanism \nfor applying the open, pass-oriented framework of batch analysis tools to incremental environments. A \nnew IR, the ab- stract parse dag, is introduced to model ambigui in programming language analysis. Circular \nan2 -ysis dependencies as they exist in C, C++, Fortran, and other common languages are eliminated by \nthe ability to apply disambiguation filters at any oint in the analysis process. Arbitrary CFGs may iii \ne used to describe the form of the parse dag, as well as te produce fast incremental parsers based on \nour IGLR algorithm. Optimal and correct subtree and context sharing in the abstract parse da are obtained \nby re- moving parsing artifacts from t Ee shared parse for- est. Empirical measurements demonstrate the \nspace efficiency of our representation and the time effi- ciency of our reconstruction methods, both \nof which exploit an underlying language property: localized non-determinism. 8 Acknowledgments Special \nthanks to William Maddox for discussing parsing theory and semantic analysis techniques and to John Boyland \nfor his tireless I4QX assistance and makebib tool.  References Ul A. V Aho, S. C. Johnson, and J. D. \nUllman. Deterministic parsingof ambiguousgrammars. Commun. ACM, 18@1:441-452, Aug. 1975. RI J. Earley. \nAn efficient context-free parsing algorithm. Com-mun. ACM, 13(2X94-102, Feb. 1970. [31 Margaret A. Ellis \nand B.iame Stroustrup. The Annotated C++ Reference Manual. Addison-Wesley, 1990. Sect. 6.8, 8.1.1. [41 \nM. V. Ferro and B. A. Dion. Efficient incremental parsing for context-free languages. In Pmt. 1994 IEEE \nZntl. Conf Camp. Lang., pages 241-252. IEEE Computer Society Press, May 1994. 61 Robert Giegerich. Considerate \ncode selection. In Robert Giegerich and Susan L. Graham, editors, Code Genemtion -Concepts, Idols, Tkchniques., \nWorkshops in Computing, pages 51-65, Berlin, May 1991. Springer-Verlag. [61 J. Heering, P R. H. Hendriks, \nP Klint, and J. Rekers. The syntax definition formalism SDF -Reference Manual, Dec. 1992. r71 Paul Hudak \net al. Haskell report. SIGPLAN Not., 27(5):R, May 1992. 181 Fahimeh Jalili and Jean H. Gallier. Building \nfriendly parsers. In 9th ACM Symp. Principles of Pmg. Lung., pages 196-206, New York, 1982. ACM Press. \nWI Mark Johnson. The computational complexity of GLR pars- ing. In Masaru Ibmiti, editor, Genemlized \nLR Parsing, pages 35-42. Kluwer Academic Publishers, 1991. WJI Neil D. Jones and Michael Madsen. Attribute-influenced \nLR parsing. In U. D. Jones, editor, Semantics-Directed Compiler Generation, number 94 in LNCS, pages \n393-407, Berlin, 1980. Springer-Verlag. ml Paul Klint and Eelco Visser. Using filters for the disambigu- \nation of context-free grammars. In Proc. ASMICS Workshop on Pursing Theory, Milan, Italy, 1994. WI Wilf \nR. LaLonde. Regular right part grammars and their parsers. Commun. ACM, 20(10):731-740, 1977. t131 Marc \nLankhorst. An empirical comparison of generalized LR tables. In R. Heemels. A. Niiholt, and K. Sikkel, \neditors, l bmita s Algorithm: Extensions and Applications (TWLTl)~ number 91-68 of Memoranda Informatica \nin Twente Work- shops on Language Technology, pages 87-93. Universeit Twente, 1991. [141 J. M. LarchevQue. \nOptimal incremental parsing. ACM 7hm.s. Program. Lang. Syst., 17(11:1-15,1995. [151 Maryellen C. MacDonald, \nMarcel Adam Just, and Patricia A. Carpenter. Working memory constraints on the processing of syntactic \nambiguity. Cog. Psych., 24(l):%%98,1992. [I61 William Maddox. Incremental Static Semantic Analysis. Ph.D. \ndissertation, University of California, Berkeley, 1997. t171 Akira Miyake, Marcel Adam Just, and Patricia \nA. Carpen- ter. Working memory constraints on the resolution of lexical ambiguity: Maintaining multiple \ninterpretations in neutral contexts. J. Memory and Lang., 33(2):175-202, Apr. 1994. r131 R. Nozohoor-Farshi. \nGLR parsing for c-grammars. In Masaru lbmita, editor, Generalized LR Parsing, pages 61- 75. Kluwer Academic \nPublishers, 1991. [I91 Luigi Petrone. Reusing batch parsers as incremental parsers. In Pmt. 15th Conf. \nFoundations Softw. 7&#38;h. and Theor Comput. Sci., number 1026 in LNCS, pages 111-123, Berlin, Dec. \n1995. Springer-Verlag. DO1 Jan Rekers. Parser Genemtion for Zntemctive Environments. Ph.D. dissertation, \nUniversity of Amsterdam, 1992. [211 Masataka Sassa, Harushi Ishizuka, and Ikuo Nakata. Rie, a compiler \ngenerator based on a one-pass-type attribute gram-mar. Software-Practice &#38; Experience, 25(31:229-250, \nMar. 1995. Ku Masaru lbmita. Eficient Parsing for Natural Languages. Kluwer Academic Publishers, 1985. \n[231 Eelco Visser. A case study in optimizing parsing schemata by disambiguation filters. Technical Report \nP9507, Program- ming Research Group, University of Amsterdam, Jul. 1995. L 41 Eelco Visser. Scannerless \ngeneralized-LR parsing, 1997. In preparation. KW Tim A. Wagner and Susan L. Graham. Efficient and flexible \nincremental parsing, 1996. Submitted to ACM duns. Pro-gram. Lang. Syst. 1261 I im A. Wagner and Susan \nL. Graham. Efficient self-versioning documents. In CompCon 97, pages 62-67. IEEE Computer Society Press, \nFeb. 1997. I271 Tim A. Wagner and Susan L. Graham. Isolating errors-a history-based approach, 1997. In \npreparation. I281 David A. Watt. Rule splitting and attribute-directed pars-ing. In U. D. Jones, editor, \nSemantics-Directed Compiler Gen- eration, number 94 in LNCS, pages 363-392, Berlin, 1980. Springer-Verlag. \n Appendix A: IGLR Parsing Algorithm The non-deterministic corn onent of the IGLR parser is based on Rekers \niiatch parser [20]. class NODE Normal parse dog node int type; pmduction or symbol # int state; deterministicparse \nstate or nostate setof NODE kids; rhsofaproduction;interpretations ofa symbol NODE tint type, int state, \nsetof NODE kids) C...) subclass SYMBOL of NODE Symbol (choice) node SYMBOL (NODE node) ( type = symbol(node+type); \nn&#38;.sle~-handside state = nostate; multistate by definition kids = {node); first interpretation I \nadd-choice (NODE node) (kids = kids U node;) class GSS-NODE Node in the GSS int state; state of constructing \nparse* setof LINK links; links to earlier nodes GSSJODE tint state, LINK link) {...I add-link (LINK link) \n(links = links U link;) class LINK Edge in theGSS GSS>ODE head: vrecedina node in the GSS NODE node; \nparse&#38;node Idding this edge LINK (GSS-NODE head, NODE node) {...I boo1 multipleStates; Global variables \nNODE shiftla; lookaheadaymbol (subtree) NODE redla: loohahead for reducing GSS-NODE acceptingparser; \nsetof GSS-NODE activeParsers, forActor. forshifter; setof NODE nodes; production node merge tab&#38; \nsetof SYMBOL symbolnodes; symbo1nodemergetab.k ~ncqarse (NODE root) ( Main routine processJnodifications_to-parse-dag(root); \nredLa = shiftLa = pop-lookahead(root+bos); GSS-NODE gss = new GSS_NODE(O, 8,; activeparsers = (gssl; \nacceptingparser = 0; multipleStates = false: while (acceptingparser == 0) parse-next_symbolO; if (shiftLa \n# eos) recover0; root+kids[ll = first(acceptParser+links)+node; unshare-epsilon-structure(root); delete \ngss; I parse-next-symbol 0 1 redudshifl ecquence forActor = activeparsers; forshifter = nodes = symbolnodes \n= 0; while (forActor # 0) do 1 remove a parser p from forActor: actor(p) ; ProueeaUreductione, ) shifter0; \nthen ship. redLa = shiftLa = pop-lookahead(shiftLa); actor (GSS_NODE P) ( Ilunaition one parser while \n(redLa is an invalid table index) redLa L left-breakdown(redLa); if (Jparse_table[p+state, redLal( > \n1) multipleStates = true; Vaction E parse-table[p+state. redLa1 do switch (action) ( - case ACCEPT: if \n(redLa == eoS) acCeptingParSer = p; else recover () ; break; case REDUCE r: do-reductionscp, r); break; \ncase SHIFT s: forshifter = forshifter U <p,s>; break; case ERROR: if (activeParser == 8) recover(); Recowrfmmapamerm~ \n1 l shifter 0 ship au panwre if (is-terminal(shiftLa) h&#38; shiftLa+has-changes(lastParsedVersion)) \nrelextshiftla); Invohekxerandm~tlmhhade activeParsers = 0; multipleStates = (for-shifter-1 > 1; while \n(!is-term(shiftLa) h&#38; (multipleStates II forShifter+state # shiftLa+state)l shiftLa = left_breakdown(shiftLal; \nVcu,s> E forshifter do if (3~ E activeparsers with p+state == q) p+adb_link(new LINK(q, shiftlal); else \nactiveparsers = activeparser U new GSSJJODE(q, new LINKIs, shiftla)) 1 do-reductions (GSSJODE p, int \nrule) ( Findaupaths GSSJODE q; Vq such that a path of length arity(rule) from p to q exists do ( kids \n= the tree nodes of the links forming the path from q to p; reducertq, GOTO(q+state, symbollrule)1, rule, \nkids); ) Path-reetricted vemion of&#38;we @ction do-limited-reductions (GSS-NODE p, int rule, LINK link) \n( VQ such that a path of length aritytrulel from p to q through link exists do { kids = the tree nodes \nof the links forming the path from q to p; reducercq. GOTO(q-+state. symbol(rule)), rule, kids); reducer \n(GSS-NODE q, int state, Perform a int rule, setof NODE kids) { single reduction NODE node = get-nodetrule, \nkids, q-tstate); if (3~ E activeparsers with p+state == state) if there already exists a direct link \nfrom p to q add-choice(link+head, node); else ( NODE n = get-symbolnode(node); p+add-link(new LINK(q, \nn)); Vm in activeParsers\\forActor do Vtreduce rule) E parse-tablelm-istate, redLa1 do do-limited-reductions(m, \nrule, link); 1 else f GSSJODE p = new GSSJODE(state, new LINK(q. get-symbolnode(node1)); activeparsers \n= activeparsers U p; forActor = forActor U p;  1 l <int,int> cover (setof NODE kids) 1 if (kids == \n0) return <offset(shiftLat,offset(shiftla)>; else return <offset(first(kids)l,offset(last(kids))>; I \n NODE get-node tint rule, setof NODE kids, creabormuse int precedingstate) ( a 'prodrcction'noik if (3n \nE nodes with n-type == rule h6 n-kids == kids) return n; if (multipleStates NODE n = new NODE(rule, \nnoState, kids); else NODE n = new NODEtrule, precedingstate, kids); nodes = nodes U n; return n;  1 \n add-choice (NODE symnode?. NODE node) ( InstMtiate if (symnode? is a symbol node) symbol tknaka kdy \nsymnode+adbchoice(node); else if (symnode? != node) ( replace symnode? with sym E symbolnodes such that \nfirst(sym+kidsl == symnode?; sym-tadd-choice(node); 1 I NODE get-symbolnode (NODE node) { ueeIwlmaJIunke \nif (3sym E symbolnodes with wheneverpoeaibk sym+symbol == symbol(node+type) &#38;&#38; cover(first(s+kids)+kids) \n== cover(node+kids)) sym-+adLchoice(node); else SYMBOL sym . new SYFBOLInodel; symbolnodes = symbolnodes \nU sym; if ((sym-tkidsl == 1) return node; else return sym; \"dIZZ!-  ) The following two routines update \nthe right (input) stack of the incremental parser. One level of structure is removed per invoca- tionof \nleft-breakdown. pop-lookahead advances thelooka-head to the next eubtree for consideration by travereing \nthe pre- vioua structure of the tree. The previouely-pamed version of the programiedenotedby 1astParsedVersion. \nNODE left-breakdown (NODE n) { if (n+arity > 0) ( n = n+first-child(previousVersion); if (n+has-changes(lastParsedVersion)) \n return left-breakdown(n); 1 else return pop-lookahead( 1 NODE pop-lookahead (NODE n) t while (n~right-SiblinglpreviousVersion) \n== 0) S:id I n = n+parent(previousVersion); n = n-+right-sibling(previousVersion): if (n+has-changes(lastParsedVersion)) \n R: funcjd-Bidid IO; return left-breakdown(n); R: type-id->id return n; The function process-modifications-to-parse-dag \n(called by incqarse) is used to invalidate reductions containing a modi-fied terminal in their yield \nor implicit (built-in) lookahead. (Struc-tural modifications can also be accommodated.) Let T denote \nthe set of modified terminals (textual edit sites). Add to T any terminal having lexical lookahead in \nsome t E T. Mark as changed any nonterminal N for which yield( N) U the ter-minal following yield(N) \ncontains any t E T. Appendix B: Sample C++Trace In this example we trace the parser s actions in con-structing \nthe dual interpretations of the typedef problem in C++, using a simplified grammar. Con-sider the input \nstream as it appears in Cl), and sup pose the semicolon has been deleted and then re-inserted. The region \nto the 1eRof the semicolon was an ambiguous it em; the edit to the semicolon causes the parser to discard \nthe non-deterministic structure and read id ( id ) as terminal symbols. Distinguishing between a normal \nidentifier and a type-name identifier is not context-free; the ambigu-ity manifests as a reduce/reduce \nconflict in (21,caus-ing the parser to split. Each of the two parsers now active will create one of the \ntwo possible interpre-tations. A subsequent incremental semantic analy-sis pass will perform the scope \nresolution and name binding needed to distinguish the desired interpreta-tion, based on earlier declarations. \nIn a correct pro-gram, either a typedef or a function declaration will have established the correct namespace \nfor the lead-ing id. (The situation would be similar in C, assum-ing that further input did not yield \na purely syntactic resolution. ) While multiple parsers are active, only terminal symbols can be read \nby the parser. (In this exam-ple the breakdown of the ambiguous subtree has al-ready accomplished this.) \nThe breadth-first nature of GLR parsing means that each terminal symbol is shifted in tandem by all active \nparsers (3,4,7,11>. In (13) context sharing occurs as the two parsers merge into a single parser. The \ni tern node shown on top of the stack is a symbol node; O its two chil-dren represent the two interpretations \nof its termi-nal yield. Now that the state is once again determin-istic, the parser returns to shifting \nentire subtrees. loNot shown is its lazy instantiation. The first item production servea aa a proxy for \nita symbol node; the attempt to add the second item production 88 an alterate interpretation forces the \ninstallation of * real symbol node. The real symbol node replaces the proxy, which becomes its first \nchild. The second item production becomes the second child. s:( 1 ( id ) ; A A N.. type-id jl Q.......................... \n . . . func-id ( i ____________________._..__: . . . . . . . . . . . . . . . S: id id ) ; A A . =* type-id \n( i ______._______.__.... 1  4 . . . . . . . . . . . . . . . . func-id ( id i R: q-Bid ._.._..._.__._..____._.___: \n. . . . . . . . . . . . . . . type-id (id j R: decljd->id 5.. . . . . . . . . . . . . . . . . . . . \n.: 1 R:arglist>q 1);AA.m 8.. .?:!!.( .F.. .:!!. _i1 S:) r ........................... 1 R:funcall->func~idkrglistrglist) \n  hncjd ( arglist 1 i .......................... . ........................... v 9. .*-id ( decl-id \n1 i ...... .. .......... .. . R: decl->typeid(decljd) ........................... R:eXpr->funcau  \nfuncall j .......................... . ........................... I; A A . . decl i 9 .......................... \n. 1 ........................... R:stmbexpr  expr i .......................... . ........................... \n1; A A . . decl : 10 ......................... .: 1 1 ........................... stmt i .......................... \n. ........................... s:; 1; A A . . decl i Il..... ...................... R:item-*kmt ; \n 1AA.m R:item->decl ; s:A A A 0.. item->stmt ; item->dsd;  \n\t\t\t", "proc_id": "258915", "abstract": "A major research goal for compilers and environments is the automatic derivation of tools from formal specifications. However, the formal model of the language is often inadequate; in particular, LR(<i>k</i>) grammars are unable to describe the natural syntax of many languages, such as C<sup>++</sup> and Fortran, which are inherently non-deterministic. Designers of batch compilers work around such limitations by combining generated components with ad hoc techniques (for instance, performing partial type and scope analysis in tandem with parsing). Unfortunately, the complexity of <i>incremental</i> systems precludes the use of batch solutions. The inability to generate incremental tools for important languages inhibits the widespread use of language-rich interactive environments.We address this problem by extending the language model itself, introducing a program representation based on <i>parse dags</i> that is suitable for both batch and incremental analysis. Ambiguities unresolved by one stage are retained in this representation until further stages can complete the analysis, even if the reaolution depends on further actions by the user. Representing ambiguity explicitly increases the number and variety of languages that can be analyzed incrementally using existing methods.To create this representation, we have developed an efficient incremental parser for general context-free grammars. Our algorithm combines Tomita's generalized LR parser with reuse of entire subtrees via state-matching. Disambiguation can occur statically, during or after parsing, or during semantic analysis (using existing incremental techniques); program errors that preclude disambiguation retsin multiple interpretations indefinitely. Our representation and analyses gain efficiency by exploiting the local nature of ambiguities: for the S<sc>PEC</sc>95 C programs, the explicit representation of ambiguity requires only 0.5% additional space and less than 1% additional time during reconstruction.", "authors": [{"name": "Tim A. Wagner", "author_profile_id": "81100167382", "affiliation": "University of California, Berkeley", "person_id": "P282437", "email_address": "", "orcid_id": ""}, {"name": "Susan L. Graham", "author_profile_id": "81452606376", "affiliation": "University of California, Berkeley", "person_id": "PP14173434", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/258915.258920", "year": "1997", "article_id": "258920", "conference": "PLDI", "title": "Incremental analysis of real programming languages", "url": "http://dl.acm.org/citation.cfm?id=258920"}