{"article_publication_date": "09-19-2011", "fulltext": "\n Modular Rollback through Control Logging A Pair of Twin Functional Pearls Olin Shivers Northeastern \nUniversity shivers@ccs.neu.edu Abstract We present a technique, based on the use of .rst-class control \noper\u00adators, enabling programs to maintain and invoke rollback logs for sequences of reversible effects. \nOur technique is modular, in that it provides complete separation between some library of effectful operations, \nand a client, driver program which invokes and rolls back sequences of these operations. In particular, \nthe checkpoint mechanism, which is entirely encapsulated within the effect library, logs not only the \nlibrary s effects, but also the client s control state. Thus, logging and rollback can be almost completely \ntransparent to the client code. This separation of concerns manifests itself nicely when we must implement \nsoftware with sophisticated error handling. We illustrate with two examples that exploit the architecture \nto dis\u00adentangle some core parsing task from its error management. The parser code is completely separate \nfrom the error-correction code, although the two components are deeply intertwined at run time. Categories \nand Subject Descriptors D.1.1 [Applicative (Func\u00adtional) Programming] General Terms Algorithms, Design, \nLanguages Keywords checkpoint, delimited control, error repair Prologue We all make mistakes. What counts \nis how we handle them. There s little less pleasant in programming than watching beautiful code turn \nugly. And nothing causes more contortion than catching and correcting input errors. The problem is that \nerror handling is not naturally modular: it is context-dependent, often relying on the details and current \nstate of input processing. Extricating error checking into a sepa\u00adrate prepass often entails duplicating \nsome of the processing in\u00adtended for correct input. For complicated artifacts like typecheck\u00aders, which \nare hard enough to get right in the .rst place, code to produce friendly error messages can obscure or \neven dwarf the code to check types [9]. When input is provided and processed interac\u00adtively, checking \nand processing must be interleaved. We tell a story in two parts, the moral of which is: error handling \ncan be separable, even beautiful. The hero of our tale is call/cc, for to err is human, but to forgive \nrequires .rst-class control. Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. ICFP 11, September 19 21, 2011, Tokyo, Japan. Copyright &#38;#169; 2011 ACM \n978-1-4503-0865-6/11/09. . . $10.00 Aaron Turon Northeastern University turon@ccs.neu.edu Part one takes \nplace in an eager Scheme REPL, which parses complete s-expressions as the user types a closing parenthesis, \nlong before a carriage return. Yet, despite advancing the state of the parser, the user can interactively \nalter erroneous text by backing up with the delete key and re-entering corrected text. So here the error-handling \nis done, in part, by the user, but done in a way that s invisible to the input-processing code. Part \ntwo retells the tale in ML, using a similar technique to automatically discover and repair the true source \nof a syntax error, perhaps far removed from the location where the parser got stuck. It s the functional \nprogramming equivalent to Burke-Fisher error repair [2]. Again, the key bene.t is the complete separation \nbetween the parsing algorithm and the repair algorithm: you write a parser in any style you like, and \nsend it through our BurkeFisher functor to get a new parser that intelligently repairs errors. We use \n.rst-class control in two crucial ways: First, to provide rollback logging. We layer an interface on \ntop of call/cc, constructed so that the very performance of a re\u00adversible side-effect has an additional \neffect: it logs the appro\u00adpriate reversal. Control effects and other effects smoothly inter\u00adleave, whether \ngoing forward or backward.  Second, to provide modularity: we sneak checkpointing through an unsuspecting \nparser. Although parsing and error correction functionality is interleaved, the code is not. Parsing \nis done via standard recursive descent, with no concern for error correction; likewise, error correction \nneeds only understand the structure of the input to the parser.  We hope that, while savoring the stories \nbelow, you will see that these two techniques transcend them. 1. Prompt reading and effect logging in \nScheme In our .rst example, we show how to recreate, with modern tools, a bit of lost art from classic \nLISP input systems: how to inter\u00adtwine input parsing with terminal-entry text editing without having \nto intertwine the code that carries out these separate tasks. As we do this, we ll discover a general \ntechnique for constructing com\u00admand systems that allows us to transparently log effects in a way that \npermits them to be rolled back on demand, without having to compromise the simplicity of client code \nthat issues sequences of these commands. That s the big picture; let s begin by diving into the speci.cs \nof our example. S-expressions, the standard syntactic form for pro\u00adgrams and data in LISP and Scheme, \nhave an interesting property: they are frequently self-delimiting. For example, we do not need to look \npast the terminating right parenthesis in the string (+ x y) to know that we have reached the end of \nthe form. By way of con\u00adtrast, this is not true of numerals: if an s-expression reader sees the string \n387 , it must look ahead one character to know if this string comprises an entire term, or if it is simply \na pre.x of a larger term. If the following character is a left parenthesis, then the string rep\u00adresents \nthe integer three hundred eighty-seven (which happens to be followed by some list to be read at a later \ndate); if the following character is another digit, then our string is simply the .rst three digits of \nsome longer numeral.  Here is the breakdown for standard Scheme s-expressions, showing which kinds are \nself-terminating, and which aren t: Self-terminating Lists: (), (+ x 3), . . . Vectors: #(), #(-2 7), \n. . . Strings: \"fred\", \"dog\", . . . Booleans: #f, #t Characters: #\\z, #\\q, . . . Not self-terminating \nSymbols: fred, dog, . . . Numerals: 387, 0, . . . Thedetailsvaryacrossdialectsof LISP andScheme,butthegeneral \nproperty remains. Interactive systems that read commands or other structured in\u00adput from a user frequently \ntake their inputs in the form of an s\u00adexpression the classic example is the LISP read-eval-print loop. \nIn such a system, the human user enters some command, expres\u00adsion or de.nition at the terminal; the operating \nsystem passes this text to the LISP process, which parses it into an s-expression, and then computes \nthe command, expression, de.nition, etc. that it de\u00adscribes. It turns out that old, 1970 s-and 1980 s-era \nLISP systems (e.g., Maclisp and Lisp Machine Lisp) took advantage of the self\u00addelimiting property enjoyed \nby their s-expression-based interac\u00adtion languages. When reading s-expressions, these interactive sys\u00adtems \nwould read characters from the terminal eagerly that is, they turned off the operating system s buffering \nmachinery, so that each character was presented to the reader as soon as the user hit the key on the \nkeyboard. Thus, the parse would complete the instant the terminating close-parenthesis was entered, without \nrequiring the user to enter a redundant newline. It s a small but pleasant con\u00advenience that, in the \npost-Lisp-Machine age, has become lost from the text-interaction modality. What makes providing this \ncapability tricky is the task of er\u00adror handling. Human typists make mistakes, which they d like to correct \nas they enter their text. This is usually handled by the so\u00adcalled line discipline code in the operating \nsystem s terminal de\u00advice driver. This code buffers terminal input and provides a simple text editor \nfor operating upon this buffered text: most characters are taken as input from the user, and echoed back \nto the terminal device, to make them visible on entry. A few keys, however, are reserved for this editing \ntask. On a Unix system, for example: The delete key backs up one character: the OS removes the last \ncharacter from the input buffer and outputs a backspace\u00adspace-backspace sequence to the terminal to erase \nit from the screen.  The control-U character typically erases the entire line of text, erasing the entire \nbuffer s worth of input.  The characters control-C and control-Z direct the OS to send an asynchronous \ncontrol signal to the reading process.  Control-V turns off any special treatment of the following char\u00adacter. \n Control-D represents end-of-.le.  The operating system does not release the buffered input to a process \nattempting to read from the terminal device until the user enters a newline character: this commits the \ninput sequence. Now, in order to provide eager reading, we have to turn this OS\u00adprovided machinery off: \nthe user process must now be responsible for echoing input and implementing the interactive editing that \nhu\u00admans use to back up through mistaken input and make corrections. This is not so terrible; we can encapsulate \nthe editing code in a small library and be done with it. What s tricky is that the parsing computation \nis now interleaved with the text-editing computation. Formerly, these things were split into distinct \nphases. First, we enter a string, with no parsing going on at all; during this phase, we can perform \nediting on each line as we enter it. Once we strike the newline key, the .nal version of that line is \nshipped off to the parser phase (i.e., the interpreter), which consumes the text, produces a parse tree \n(that is, an s-expression), and proceeds with the requested task. In our new (well, 1970 s) world, the \napplication is carrying out the parse as text is entered by the user. If we change our minds and wish \nto erase some of the text we ve entered, as we back up through the input text, we also have to rewind \nthe parse com\u00adputation. For example, an s-expression reader is typically a lit\u00adtle recursive-descent \nparser. When it is reading the elements of a nested list and it encounters a close-parenthesis character, \nit returns the accumulated list to its recursive caller. If we were to subse\u00adquently decide to delete \nthat close parenthesis, we d have to back the parse computation back down into that formerly completed \ncall. What we need is the ability to take snapshots of the com\u00adputation at various points as we parse. \nRoughly speaking, every time the parser calls out to the read character routine, that routine should \n.rst checkpoint the parse computation and save the check\u00adpoint away on a list. If the user tries to delete \nsome previously en\u00adtered characters, the input routine can pull the appropriate check\u00adpoint from its \nsaved history and reset the parse computation to that previous character-reading state. By this point, \nit should be clear that the right tool for this job is the Scheme call-with-current-continuation (or, \ncall/cc) procedure: creating computational checkpoints is its raison d \u00eatre. The rubout port and the \nreset protocol In Scheme, we do I/O on ports; our task is to construct a new kind of rubout port for \nreading from a terminal. We ll construct our rubout port using a low-level mechanism in Scheme48 [7]/scsh \n[12] that permits programmers to de.ne their own input ports, which can be passed to the system input \nprocedures like any other input port. To de.ne one of our custom rubout ports, we provide the extended\u00adport \nconstructor two things. The .rst is a .xed suite of port meth\u00adods, described by a record whose .elds \nare procedures the input system will use to read a character, peek at a character, close the port, and \na few other less-important operations. We also provide a data value which encapsulates the port state; \nthis value will be passed to the method procedures when operations are performed on the port. Here is \nthe de.nition of the rubout port s data record: (define-record rubout-port-data ttyin ; input tty port \nttyout ; output tty port, for echoing (prev-tty-info #f) ; tty s original echo state (peek-char #f) ; \n\"lookahead\" peek cache (checkpoint #f)); most recent checkpoint This piece of Scheme code de.nes a procedure \n(make-rubout-port-data ttyin ttyout) which constructs a record from a pair of ports connected to the \nterminal device; the other three .elds of the record are initialised to false, #f. We also get .eld-accessor \nprocedures, such as (rubout-port-data:ttyin rpd) (rubout-port-data:ttyout rpd) and so forth, and some \nanalogous .eld-assignment procedures with names like (set-rubout-port-data:peek-char! rpd char).  Note \nthe checkpoint .eld. Our intention is that every time ap\u00adplication code does a (read-char rp) operation \nthat causes the rubout-port to actually get a character from the terminal, before re\u00adturning the character \nto the caller, the code will also grab a continu\u00adation with call/cc and stow it away in the port s checkpoint \n.eld. If, during a later attempt to read, the rubout-port code reads, say, a delete character and decides \nto undo the previous read, it will be able to do so by fetching this saved value from the checkpoint \n.eld of the rubout-port s data record and invoking it this will reset the entire computation back to \nthe previous read point. The key piece of design we must pin down is the protocol used to invoke the \ncheckpointed continuation. Speci.cally, a checkpoint is a Scheme continuation that must be applied to \na single boolean argument: (checkpoint just-1?). If the just-1? argument is true, we wish to rewind the \ncomputation back just one step that is, to the immediately prior read operation. If the argument is false, \nthen we wish to rewind all the way back to the beginning of the entire read session. The core effects: \nreading and echoing We can now de.ne the pair of low-level procedures that perform our system s two primitive \nside-effects: reading a character from the keyboard, and echoing an input character to the display. Since \neach of these procedures carries out an effect, it must log the effect as it performs it that is, we \nmust update the port s checkpoint to add a rollback handler that will undo the effect if we rewind back \nthrough this point in the computation. Here is the code for echoing: (define (echo c pd) (let* ((oport \n(rubout-port-data:ttyout pd)) (reset (rubout-port-data:checkpoint pd))) (write-char c oport) ; 1: Echo \nthe character. ;; 2: Set a checkpoint to undo the echo. (set-rubout-port-data:checkpoint pd (call/cc \n(. (ret) (let ((just-1? (call/cc ret))) (print-rubout-sequence oport) (reset just-1?))))))) ;;; Output \nbackspace/space/backspace to the port. (define (print-rubout-sequence oport) (write-string \"\\b \\b\" oport)) \nThe rubout-port machinery calls echo whenever it needs to echo a character just read to the terminal. \nThe procedure writes the character out on line 4, and then logs the effect in the last half of the procedure \nby updating the port s checkpoint. This is the .rst piece of serious continuation manipulation we ve \nperformed, so we will trace through its execution carefully. The .rst, outer call/cc creates a return \npoint ret; applying ret to some value cp will cause cp to be installed as the port s new checkpoint. \nThe second, inner call/cc creates the actual checkpoint continuation; call/cc passes this continuation \nto ret, so, just as we described, this continuation gets installed as the current checkpoint. Now, consider \nwhat happens when this checkpoint is invoked at some later time, by fetching it from the rubout port \ns data record and applying it to some boolean argument. We ll reset the com\u00adputation back to now: the \ninner call/cc will return the boolean value, so it will be bound by the let form to the variable just-1?. \nThen we ll proceed into the body of the let, which contains the rollback action: we write out a backspace/space/backspace \nchar\u00adacter sequence to the terminal, which will erase the character we previously echoed back on line \n4 of the code, then we ll pass the just-1? boolean on to our checkpoint. We do this because we are in \nthe process of rewinding back to some prior input the echo ac\u00adtion is an output effect, not an input \neffect, so we need to continue rewinding the computation. Our next procedure (which appears in Figure \n1) is the primitive character-input procedure. When the rubout-port machinery needs to actually read \na character, it applies %read-char to the port s data record. This code is, essentially, our line discipline \ndriver code, written in Scheme. The procedure sits in a loop (the named-let function lp), which does \nan input operation on the actual terminal, binding the variable c to the character entered by the user. \nThen we perform a variety of actions, depending on the character. Inducing rollback is easy: if the character \nis the delete character, we apply the port s current checkpoint continuation rubout to true, which will \nabort what we re doing, and reset to the previous read (and also undo any echoing we might have logged \nin-between). That previous read will then be able to get a new character from the user and return it \nto the parser in place of the original character it had input back when it .rst ran. (We ll see the code \nthat does this the code at the target end of our reset-continuation s non-local jump in just a moment.) \nIf the character is the line-kill character, control-U, then we ap\u00adply the checkpoint to false; by the \nrules of the checkpoint invo\u00adcation protocol, this will induce a rewind all the way back to the beginning \nof the entire parse session, clearing previously echoed characters from the display as we rewind. If \nthe user entered control-C or control-Z, the code sends the current process the appropriate OS signal, \nand then loops by tail\u00adcalling (lp), to continue trying to read a character. (The process signals itself \nin a context that resets the terminal s echoing and buffering state to its original settings, but this \nis a .ne point we can skip.) These .rst few cases describe the text-editing functionality of our device \ndriver, where characters input by the user are not in\u00adtended as data to be passed on to the process, \nbut are rather inter\u00adpreted directly by the input-port system as requesting various ac\u00adtions. The .nal \ncase (the else clause of the cond) is the actual-input case: we ve read an ordinary character c (or we \nve encountered the end of .le, or we ve read the knockdown character, control-V, followed by any character \nat all). Since we can now be considered to have successfully accomplished an input side-effect, before \nwe return c to our caller, we must .rst log the operation by updating the port s checkpoint. Just as \nwith echo, this is done with a nested, double call/cc pattern. The .rst, outer call/cc simply captures \nthe context we ll use to return c and proceed with the parse by re\u00adturning from %read-char. The second, \ninner call/cc creates the checkpoint continuation, naming it ckpt. We then install ckpt into the port \ns data record, and apply ret to the character c, which will lead us to produce c as the return value \nof %read-char. What hap\u00adpens when, at some later time, the checkpoint continuation is in\u00advoked? What \nwe want to accomplish, if this happens, is to rewind the computation back to now, then get a new character \nc' from the terminal and return that instead of the character c we just now pro\u00adduced. That s exactly \nwhat happens. Suppose some future call to %read-char gets a delete character and so fetches the checkpoint \ncontinuation we just now created from the port s data record and applies it to true (i.e., executes line \n7 of the procedure). When the checkpoint continuation is applied to true, we ll rewind to now, and the \nsecond, inner call/cc will return the true value so it will be let-bound to the variable just-1?, and \nwe ll proceed into the body of the let form, whose if conditional will jump back to the top of our original \nloop, lp, continuing our current read. Any character c' we get will be returned to our caller, so the \nnet effect is that, after rewinding the computation to here, we ll proceed with c' instead of our originally-read \ncharacter. In short, we undid the input effect and replaced it with a new one.  (define (%read-char \nport-data) (let ((rubout (rubout-port-data:checkpoint port-data)) (iport (rubout-port-data:ttyin port-data))) \n(let lp () ;; Assert: (rubout-port-data:peek-data port-data) = #F. (let ((c (read-char iport))) ; real \ninput! (cond ((rubout-char? c) (rubout #t)) ; DEL => rubout a char ((linekill-char? c) (rubout #f)) \n; ^U => kill the whole sexp. ((interrupt-char? c) ; ^C => interrupt ;; Undo the tty s raw/no-echo modes \nbefore raising the signal. (with-rubout-port-restored port-data (signal-process 0 signal/int)) (lp)) \n; The process survived the signal => keep reading. ((suspend-char? c) ; ^Z => suspend ;; Undo the tty \ns raw/no-echo modes before raising the signal. (with-rubout-port-restored port-data (signal-process 0 \nsignal/tstp)) (lp))  (else (let ((c (cond ((knockdown-char? c) ; ^V => turn off special handling. (read-char \niport)) ((eof-char? c) *eof-object*) ; ^D => EOF (else c)))) ; Normal char ;; Outstanding! We have read \nan actual character, C. ;; Before returning it to the parser, set a new ;; checkpoint, so that if we \nlater wish to rub C out, ;; we can come back here, get a new character, and resume. (call/cc ; Therein \nlies the rubout. (. (ret) (let ((just-1? (call/cc (. (ckpt) ; Set the checkpoint &#38; return C: (set-rubout-port-data:checkpoint \nport-data ckpt) (ret c))))) ;; On rewind, we ll bind JUST-1? &#38; come here. (if just-1? (lp) ; Either \nre-do the current read, (rubout #f)))))))))))) ; or keep rewinding. Figure 1. The checkpointing character \nreader On the other hand, suppose at some point in the future the user enters the line-kill character, \nControl-U. Then the checkpoint continuation will be applied to false (by line 8 of that future in\u00advocation \nof %read-char). The computation will be reset to now, and the inner call/cc will produce the false value, \nwhich will be let-bound to just-1?. So, instead of looping in our current read, we ll keep rewinding \nby applying our checkpoint to false, in the very last line of the procedure: (rubout #f). In other words, \nwe don t have to keep an explicit stack of checkpoints. The stack is implicit in the environment structure \nof the various checkpoints: each checkpoint continuation has access to the next checkpoint back in the \ntimeline: it is bound to the variable rubout in the current checkpoint s lexical scope. (Similarly, it \nis bound to the variable reset, in the checkpoint created by the echo procedure.) Peeking and reading \nAll the heavy lifting in our system is accomplished by the echo and %read-char primitives. The rubout-port \nsystem calls them from its peek-character and read-character method procedures. Note a policy decision \nencoded in these procedures: a character is not echoed as soon as we get it from the keyboard: peeks \ndon t count. This code doesn t echo a character to the display until the parser actually consumes it \nwith a read-char operation. (define (rubout-peek-char port-data) ;; A \"subsequent\" peek: don t checkpoint \n(or (rubout-port-data:peek-char port-data) ;; A \"first\" peek --checkpoint it (let ((c (%read-char port-data))) \n;; then set the peek cache: (set-rubout-port-data:peek-char port-data c) c))) ; then return the character. \n(define (rubout-read-char port-data) ;; If the peek does input, it will be logged: (let ((c (rubout-peek-char \nport-data))) ;; If we echo, it will be logged: (if (not (eof-object? c)) (echo c port-data)) ;; Clear \nthe peek cache. (set-rubout-port-data:peek-char port-data #f) c)) Note also that these two higher-level \nprocedures do not concern themselves with setting checkpoints or logging effects. One of the nice properties \nof our design is that the effect-logging code is tightly bound to the code that commits the effects. \nThus, doing a side effect and logging its rollback handler are welded together.  Client code, like the \ntwo procedures above, or the application s parser, just commit side-effects at will; it s impossible \nfor them to break the pairing of effects and rollbacks. (This nice property is only extended to the side-effects \nthat we included in our design, of course. Parser clients must be aware that they cannot perform other \nside-effects and expect them to be undone during rollback.) Failure is not an option All that remains \nis to de.ne with-rubout-session*, the proce\u00addure used to delimit a single parse session; it appears in \nFigure 2. We can perform a rubout-enabled parse with something like: (with-rubout-session* rubout-port \n(. () (read rubout-port))) The central body of this procedure executes in a dynamic con\u00adtext, established \nby the R5RS Scheme dynamic-wind procedure, that saves and restores the rubout port s checkpoint if we \nshould throw out and then back into the session s dynamic extent by in\u00advoking saved continuations. It \nalso serves another purpose: the dynamic-wind s exit thunk clears the checkpoint from the rubout port, \nwhich permits the checkpoint to be garbage collected even if the rubout port itself continues to remain \nalive. Note that the rubout-session s thunk executes in an exception\u00adhandler context that treats parser-syntax \nerrors in a clever way: we refuse to accept input from the terminal that triggers a syntax\u00aderror exception. \nIf the user should enter a character that causes the parser to raise this error, the exception handler \nrings the bell (in a visual manner), then discards the bad character by invoking the rubout port s current \ncheckpoint, passing it true for its just-1? parameter. This rewinds the parse computation back to the \nread operation where the user entered the offending character (erasing the character as we rewind, if \nit had been echoed); we then resume the parse by reading an alternate character from the user. For example, \nif the user tries to type in an ill-formed dotted-pair that has two dots, e.g., (a . b . c), the parser \nwill stubbornly refuse to accept the second dot, ringing the bell every time the user attempts to enter \nit to signal that we have departed from the syntac\u00adtic straight and narrow. Note that this facility is \ncompletely inde\u00adpendent of the grammar we are parsing, or the details of the parser: the parser is just \na piece of code that raises an error exception as soon as it encounters an illegal character. The .nal \ntask the rubout-session procedure must perform before invoking the client s parser computation thunk \nis to set the rubout port s initial checkpoint. Again, we see the nested, double call/cc pattern. Tracing \nthrough the restart loop shows that each time we rewind back to the initial checkpoint, we recreate and \nreinstall it into the port, then begin the parse (that is, call thunk) all over again. Thus, invoking \nthe initial checkpoint has the effect of restarting the whole parse. Discussion The big idea The .rst \nthing to note about this rubout-handler system is that the technique is not at all limited to interactive \ntext entry. The general idea here is that we have a library of effectful (but reversible) operations. \nSome client performs a series of effects by issuing a sequence of these operations; as the client computes, \nthe application may decide to rewind the driving computation to some previous operation and do something \ndifferent perhaps (as in our rubout-handler scenario) in response to error conditions. The design pattern \nwe propose here is to instrument the effectful operation library to construct a rollback log for the \noperations it performs. More speci.cally, by constructing this rollback log from continuations, we capture \nnot only the library s effects, but also the client s control state at each operation-invocation point. \nThis is what permits completely transparent rollback of the client computation: it s all due to the power \nof call/cc to package up a general control state. Delimiting our checkpoints Let s motivate our next \npoint by con\u00adsidering an extension to our rubout-handler system. Many text\u00adinput systems have some kind \nof history mechanism: they save previous lines of input, which the user can recall by entering some special \ncontrol key that cycles through previous entries. Suppose we wished to provide this kind of functionality \nand, of course, keep our rubout-handling capability. Unfortunately, the saved con\u00adtinuations that make \nup our checkpoints capture too much control state: they capture not only the parse computation, but also \nthe computational state of the client that called the parser. If we were to reset to one of the checkpoints \nfrom a previous read in, e.g.,a Scheme interpreter s read-eval-print loop, we d reset the entire in\u00adterpreter \nback to that earlier state! This is a problem that is exactly handled by delimited-control operators \nsuch as Felleisen s prompt [4, 13] or Danvy and Filinski s shift [3]. We need only delimit the parse \ncomputation carried out by the thunk passed to with-rubout-session* and we re set. We leave this modi.cation \nto our code as a (fun) exercise for the interested reader. The dark side of Church encodings Scheme provides \ncontinua\u00adtions encoded as procedures: we perform a non-local control trans\u00adfer to a captured continuation \nby applying it to some argument. This has been a long-standing source of subtle problems using Scheme \ns continuations. The central issue is that, if we want to call procedure p, with argument a and continuation \nk, we cannot do the following: (k (p a)). This goes wrong because k s underlying continuation does not \nactually become the current continuation until p returns; the whole time p is executing, the continuation \nis an extension of the one extant when we began evaluating the entire (k (p a)) ex\u00adpression. So if p \nraises an exception, we will resolve it using the ex\u00adception handlers of that continuation, not k s handlers. \nIf we were hoping to reclaim the original continuation s stack by installing k as the current continuation, \nthis won t happen while p is executing if it happens to be some long-running thread (such as a web server), \nthen the original continuation s stack will never become free, lead\u00ading to a subtle space leak. These \nkinds of space leaks aren t just theoretical oddities; they actually occur when programmers build thread \nschedulers based on continuations [1]. The real problem here is that when we Church-encode a kind of \ndata, we can only do one thing with the data: apply it to an argument that is the only operation permitted \non procedures. In the case of continuations, we need to do two things: perform a func\u00adtion call with \nthe given continuation for the call, and compose an a . \u00df function onto the end of a \u00df-accepting continuation, \npro\u00adducing an a-accepting continuation. These two procedures provide the necessary interface: (with-continuation \ncont thunk) (compose-continuation \u00df-cont a->\u00df) Scheme doesn t have this kind of continuation mechanism, \nso we have to code in awkward ways to work around the limitations of call/cc. This problem rears its \nhead in our rubout-handler system. Con\u00adsider the subtle, double-call/cc code that creates the new check\u00adpoint \nwhen we read a character in %read-char. Couldn t we elim\u00adinate the inner call/cc and just use a simple \nprocedure, instead of an exotic continuation, with the following?  (define (with-rubout-session* rubout-port \nthunk) (let ((pd (extensible-input-port-local-data rubout-port)) (suspended-checkpoint #f)) (with-raw-mode-rubout-port \npd ; Turn off tty buffering &#38; echoing. (dynamic-wind ;; Dynamic-wind pre: ;; If we are throwing back \ninto the parse, restore the checkpoint ;; we saved away when we threw out. (. () (set-rubout-port-data:checkpoint \npd suspended-checkpoint)) ;; Dynamic-wind body: (. () (with-syntax-error-handler ;; Here s the error \nhandler. If the parser raises a syntax error, ;; ring the bell, clear the peek-char cache, then trigger \na 1-step ;; rewind to rubout the last char, which triggered the error. (. (c) (visible-bell (rubout-port-data:ttyout \npd)) (set-rubout-port-data:peek-char pd #f) ((rubout-port-data:checkpoint pd) #t)) ;; Set the initial \ncheckpoint, which comes back here and ;; restarts the whole parse. (call/cc (. (go-start-parse) (let \nrestart () (call/cc (. (icp) (set-rubout-port-data:checkpoint pd icp) (go-start-parse))) ;; Come here \nwhen initial checkpoint ICP is invoked: (restart)))) (thunk))) ; Do the parse. ;; Dynamic-wind post: \n;; When we re done, clear out the port s checkpoint, so the port ;; won t keep the checkpoint from being \ngc d. But... we might not be ;; done. We might be throwing out and later throwing back in. So ;; save \naway the current checkpoint in case we later throw back in. (. () (set! suspended-checkpoint (rubout-port-data:checkpoint \npd)) (set-rubout-port-data:checkpoint pd #f)))))) (define (visible-bell oport) ; A simple \"visible bell:\" \n(write-char #\\! oport) ; print out a !, (sleep 1) ; pause one second, then (print-rubout-sequence oport)); \nerase it. Figure 2. Delimiting a rubout-handler session. (call/cc (. (ret) (set-rubout-port-data:checkpoint \nport-data (. (just-1?) (if just-1? (ret (lp)) (rubout #f)))) c)) Unfortunately, no. If some future delete \ncommand applies this checkpoint to true, we will perform the (lp) retry in that future context; we won \nt throw back to the previous control state un\u00adtil the lp call returns to the Scheme-style Church-encoded \ncon\u00adtinuation ret. All the time that (lp) is running, it is running with the wrong exception-handler \ncontext, the wrong dynamic\u00adwind undo/redo handlers, and so forth. Furthermore, the run-time system can \nt reclaim the triggering read s stack and other control context until lp returns; we want to reclaim \nit when lp starts. The double-call/cc pattern establishes the proper context, then captures it with the \ninner call/cc, so things work out properly. It would have been easier and simpler to write this code \nif we d had the alternate continuation functionality described above. Our checkpoint-setting code would \nthen look like this: (call/cc (. (ret) (let ((ckpt (compose-continuation ret (. (just-1?) (if just-1? \n(lp) (rubout #f)))))) (set-rubout-port-data:checkpoint port-data ckpt)) c)) An observant reader might \nsimilarly have wondered why we didn t use a simple procedure as the checkpoint for the echo proce\u00addure. \nThis is why. As a matter of style, checkpoints in our rubout\u00adhandler system that is, things stored in \nthe checkpoint .eld of a rubout port s data record are always and only continuations that is, things \ncreated by call/cc.  This issue matters less in the case of echo s checkpoints. If we d written the \ncheckpoint code for echo with the simpler (set-rubout-port-data:checkpoint pd (. (just-1?) (print-rubout-sequence \noport) (reset just-1?))) then the only code that would run in the wrong context would be the (print-rubout-sequence \noport) call, which is short and presumably terminates with no other control effects such as raising an \nexception. Still, we preferred to work with the discipline of only using continuations for checkpoints. \nBackwards and forwards An observant reader might also be wondering: old LISP systems didn t have call/cc \nor general con\u00adtinuations. So how did these systems provide prompt reading with rubout handling? The \nanswer is rather ingenious [10]. These systems couldn t back up to prior checkpoints by invoking saved \ncontinuations. In\u00adstead, the port machinery would log all the characters read during a session. If the \nuser requested a single-character delete, the rubout handler would raise an exception, which would be \ncaught by an ex\u00adception handler established at the beginning of the rubout-handling session. The exception \nhandler would delete the last character from the log, and then completely restart the entire parse. During \nthe new parse attempt, the port would be in a special replay mode: whenever the parser requested a character \nfrom the port, the port would get the next item from the log, instead of going to the termi\u00adnal to read \na new character. When the log was exhausted, the port would revert to doing actual input from the terminal. \nSo, to delete a character, the rubout handler would simply reread and reparse ev\u00aderything but the deleted \ncharacter. Instead of going one step back, the system would do a complete restart and then go n - 1 steps \nforward. Monads and dependent types The technique of using continua\u00adtions to construct rollback logs \nfor command sequences, where we wish to capture client control state as well, seems nicely suited for \nexpressing in a Haskell monad that uses both continuations and state. We should mention that Conor McBride \nwas able to code up a functional equivalent to our rubout handler in a dependently\u00adtyped extension to \nHaskell. Although McBride was, of course, able to capture many system invariants by means of a rich static \ntype system, we should point out that his implementation required almost sixty lines of code to achieve \nthis feat. Why call/cc? Our .nal point is the following. Many program\u00admers think of call/cc and delimited \ncontrol operators as being the province of effete language theorists. To which we really must reply1: \nAu contraire! Continuations are rather tools for hearty, robust systems programmers: we ve used them \nto write a line\u00addiscipline driver to replace the one provided by the Unix kernel, and we only needed \nabout 200 lines of code. . . and our version pro\u00advides more functionality. 2. The Burke-Fisher functor \nin SML Enough s-expressions. Let s look at some real syntax: (exp) ::= (exp) + (exp) |(num) |(id) | \u00b7\u00b7\u00b7 \n(decl) ::= val (id) = (exp) ; | fun (id) ( (id) )= (exp) ; This is just enough grammar to get us into \nsome interesting trouble. 1 In a hearty, robust manner, that is. Imagine for a moment being a novice \nprogrammer sitting at the REPL. You type > val f(x) = x + 1; expecting to de.ne your .rst function. But, \nof course, you are instead greeted by SYNTAX ERROR: at (1:6), got ( , expected = Being a novice, you \nprobably haven t seen the grammar above, which anyway would be much larger in practice. From the error, \nyou only know that the .rst .ve characters drove the parser into a state from which = is the only way \nout. If you also believe that val declarations are the sole way of creating bindings or have forgotten \nwhether it s fun, fn, proc or function you re in for a long and frustrating REPL session. A more helpful \nparser might instead respond with > val f(x) = x + 1; SYNTAX ERROR: at (1:1), did you mean fun ? Startlingly, \nthe location of the syntax error has changed in this in\u00adteraction. The parser is recommending that val \nbe replaced by fun, even though val is permitted by the grammar. This recommenda\u00adtion seems more helpful \nthan replacing ( with =, but why? There is a general principle at work, one elucidated in a classic paper \nby Burke and Fisher [2]. The principle, loosely stated, is that Syntax errors are usefully explained \nby .nding minimal, nearby edits that allow the parser to substantially progress. Looking at our novice \nREPL session, we see If we replace ( with =, the parser will encounter another syntax error almost immediately: \nthe now-unbalanced closing paren\u00adthesis. To recover from that error, we would probably delete several \ntokens the initial replacement leads us straight into a syntactic quagmire.  If instead we replace val \nby fun, which requires backing up from the location where the error was detected, that single\u00adtoken change \nresults in a grammatically-correct input.  In short, the fun replacement is better because it explains \nmore of the programmer s original input. Burke and Fisher outline two requirements for practicality : \n1. Error handling should not substantially increase the space or time needed to parse correct input. \n 2. Error analysis and recovery should take constant time.  The technique outlined in their paper relies \non the details of explicit-stack LL and LR parsing, and works by maintaining two parser states. The .rst \nparser state represents the real parser, and is used to detect syntax errors. The second parser state \nlags some .xed number k of tokens behind. When the real parser encounters an error, it can be repeatedly \nreverted to the state of the lagging parser as different modi.cations to the input are tried. The win\u00adning \nmodi.cation is, roughly, the smallest one yielding the greatest amount of progress beyond the original \nerror.2 While ingenious, Burke-Fisher error repair is also a vivid exam\u00adple of too-tight coupling between \nerror handling and core logic: the error-handling code relies on complete knowledge of the represen\u00adtation \nand algorithm of the underlying parser. Using similar techniques to the eager REPL, we can liber\u00adate \nBurke-Fisher error repair from its assumptions about parsing, achieving clean separation between processing \nvalid input and han\u00addling erroneous input. 2 To work in constant time, a test of a repair should only \nventure some .xed number of tokens beyond the original error.  Plot summary The basic trick is to slide \nin error correction between a parser and its source of input, a lexer. As with the eager REPL, we do \nthis by feeding the parser an instrumented, checkpointing lexer. To keep things interesting, we switch \nto SML, where we can use the module system to be very clear about the separation of concerns. In the \nend, we write a single functor, BurkeFisher, that can add error repair to any module of signature PARSER. \nWe use two extensions to the language: delimited control and higher-order functors, both of which can \nbe had in SML/NJ [5, 8]. Why? Read on. Setting the scene: the signature of a parser We start with the \nlexer: signature LEXER = sig type tok type tok_stream val lex : tok_stream -> (tok * tok_stream) option \nend The LEXER signature characterizes the source of input to a parser: a stream of tokens (type tok). \nWe know nothing about the internal structure of token streams, but can observe the next token and remaining \nstream, if any, using lex. A PARSER is parameterized by its LEXER: signature PARSER = sig type tok type \nresult functor ForLexer(L : LEXER where type tok = tok): sig exception ParseError of L.tok_stream list \nval parse : L.tok_stream -> result end end Here is our .rst use of SML/NJ s higher-order module system: \na module implementing PARSER must include a functor, ForLexer, which can be applied to token-compatible \nlexers. ForLexer in turn provides a parse function specialized to the token stream of the given lexer. \nOf course, all this could be replaced by an appropriate use of polymorphism, but then, so can SML s module \nsystem [11]. Explicit structuring via signatures, modules and functors allows us to name the separate \nconcepts with which we wish to work. Because result is de.ned outside the ForLexer functor, the result \ntype of a parser cannot depend on its lexer. On the other hand, the ParseError it raises on detecting \na syntax error is parameterized by the token stream in fact, it takes a list of token streams. This is \nthe one concession a parser must make to error repair: it must signal the detection of an error by throwing \nan exception holding the stream just after the error was detected. If the parser performs backtracking \nchoice, but every choice fails, it should throw the exception with a list containing each failure point. \nA simple parser The module DeclRecognizer in Figure 3 implements a recognizer for the (decl) grammar, \nproviding an example realization of the PARSER signature. Being a recognizer, there are only two possible \noutcomes of parse: a unit value if successful, and an exception if not. The implementation of DeclParser \nuses a few parser combi\u00adnators [6], which provide interaction with both the lexer and, ulti\u00admately, error \nrepair. The combinator want simply checks that the given token is the next one on the stream, returning \nan advanced stream if so and raising an exception if not: fun want t = fn s => case L.lex s of NONE => \nraise ParseError [s] | SOME (t , s ) => if t=t then s else raise ParseError [s ] (* stream /after/ the \nerror *) Usually we compose recognizers sequentially, letting errors propa\u00adgate: infix >> fun p >> q \n= fn s => q (p s) To handle nonterminals like (decl), which have multiple produc\u00adtions, we use backtracking \nchoice: infix <|> fun p <|> q = fn s => p s handle ParseError ss => q s handle ParseError ss => raise \nParseError (ss @ ss ) With choice we see concretely the concession the parser must make to error repair: \nit must do a bit of work to bundle together the possible error locations. Checkpointing a lexer Parsers \nare conveniently parameterized over lexers, leaving the per\u00adfect loophole through which to checkpoint \nparser state. Unlike the eager REPL, we will employ delimited continuations for check\u00adpointing. A delimited \ncontinuation captures the evaluation context only up to the most recent delimiter. Delimitation will \nallow us to tentatively run the rest of a parse with various repairs, searching for the best one, without \ngoing on to execute the rest of the program. We use an implementation of delimited control [3], due to \nDavid Herman in an ICFP pearl [5], that is parameterized by a single answer type: signature CONTROL = \nsig type ans val shift : (( a -> ans) -> ans) -> a val reset : (unit -> ans) -> ans end Delimiters are \ninserted using reset, which expects an answer\u00adproducing thunk. On the other hand, shift aborts to the \nnearest delimiter, but rei.es the evaluation context up to the delimiter as a reusable function. Thus, \n> (reset (fn () => shift (fn k => 1) + 1)) * 2; 2 > (reset (fn () => shift (fn k => k (k 1)) + 1)) * \n2; 6 In the .rst case, the captured context [] +1 is simply discarded; the reset is replaced by the \nanswer 1, which is then doubled. In the second case, the captured context [] +1 is applied, as a function, \ntwice; the reset is replaced by the answer 3, which is then doubled. For our purposes, a single delimiter \nsurrounding a parse will suf.ce. The checkpoints captured by the lexer will correspond to the remaining \nexecution of the parser, starting from its request for a token at some point in the stream, and continuing \nto the point  structure DeclRecognizer = struct datatype tok = VAL | FUN | LPAREN | RPAREN | ID | EQ \n| NUM | PLUS | SEMI type result = unit functor ForLexer (L : LEXER where type tok = tok) = struct exception \nParseError of L.tok_stream list  (* ... definition of combinators want, >> and <|> as given in text \n... *) val wantExp = (* ... *) val wantDecl = (want FUN >> want ID >> want LPAREN >> want ID >> want \nRPAREN >> want EQ >> wantExp >> want SEMI) <|> (want VAL >> want ID >> want EQ >> wantExp >> want SEMI) \nfun parse s = let val _ = wantDecl s in () end end end Figure 3. A combinator-style recognizer for (decl) \nfun lex (s, PASSTHRU) = (case L.lex s of NONE => NONE | SOME (t, s ) => SOME (t, (s , PASSTHRU))) | \nlex (s, CHECKPOINT w) = (case L.lex s of NONE => NONE | SOME (t, s ) => SOME (C.shift (fn k => k (t, \n(s , CHECKPOINT (Window.push w (* first time through, yield t *) (fn t => k (t , (s , PASSTHRU))))))))) \n(* on checkpoint invocation, yield t *) Figure 4. The checkpointing lexer where it produces a .nal answer. \nThe type ans will be P.result for a parser P. The checkpointing instrumentation is performed by a LEXER\u00adtransforming \nfunctor. Using SML/NJ s funsig form, we can give it the following signature: funsig LEXER_WRAPPER (C \n: CONTROL) (L : LEXER) = LEXER where type tok = L.tok As the signature indicates, the instrumented lexer \nproduces the same type of tokens as the original one, so it will be compatible with the same parsers. \nWhat changes is the internal representation of token streams, which includes a wrapper component: functor \nWrappedLexer (C : CONTROL) (L : LEXER) = struct type tok = L.tok type checkpoint = L.tok -> C.ans datatype \nwrapper = CHECKPOINT of checkpoint Window.window | PASSTHRU type tok_stream = L.tok_stream * wrapper \nfun lex (* ... see figure ... *) end An instrumented lexer can operate in one of two modes: check\u00adpointing \nor passthrough. Checkpointing is used during initial pars\u00ading, until a syntax error is found. The last \nk checkpoints are main\u00adtained using a window, so that instrumentation imposes only a constant-bounded \nspace overhead: signature WINDOW = sig type a window val empty : a window (* keeps only last k pushes \n*) val push : a window -> a -> a window val list : a window -> a list end Figure 4 shows the implementation \nof instrumented lexing. In passthrough mode, instrumentation has no effect. In checkpointing mode, the \nlexer uses shift to abort while capturing the continua\u00adtion up to the end of parsing. The delimited continuation \nk is imme\u00addiately invoked effectively undoing the abort yielding the same token t that the underlying \nlexer would. However, a checkpoint is pushed that, when invoked, re-runs the parser from the point of \nthe shift, providing an alternative token t and switching to passthrough mode. An instrumented lexer \nprovides wrap to inject an underlying lexer, unwrap to project the underlying lexer, and checkpoints \nto extract the last k checkpoints: fun wrap s = (s, CHECKPOINT Window.empty) fun unwrap (s, _) = s fun \ncheckpoints (_, CHECKPOINT w) = Window.list w | checkpoints (_, PASSTHRU) = []  Putting it together: \nthe Burke-Fisher functor Nearly all the ingredients are now in place. However, to search for repairs, \nwe ll need to know something about the available tokens: signature TOK = sig type tok val toks : tok \nlist val toString : tok -> string end The list toks provides an instance of each token that should be \nused for replacement or insertion during error repair. With that, we can specify the shape of functional \nBurke-Fisher error repair: funsig BURKE_FISHER (T : TOK) (P : PARSER where type tok = T.tok) = PARSER \nwhere type tok = T.tok Figure 5 gives an implementation the BurkeFisher functor. To keep the presentation \nshort, the functor is not quite true to the original algorithm: It only performs a single repair.  \nIt requires the repair to make the entire input valid, rather than choosing a repair that makes maximal \n(but bounded) progress. This means, in particular, that repair is not constant-time.  It only attempts \nrepairs of Hamming distance 1, that is, single\u00adtoken replacements.  These limitations can be easily \naddressed by modifying the functor, without any change to the underlying parser. When applied to a parser \nP, BurkeFisher produces a parser with result type P.result * string option. The string compo\u00adnent is \na description of the single repair (if any) performed. Internally, the functor uses Herman s GreatEscape \nfunctor [5], which provides delimited control by using SML/NJ s call/cc fa\u00adcility. Crucially, this implementation \nof delimited control inter\u00adacts properly with exceptions: delimited continuations captured by shift also \ncapture exception handlers up to the delimiter no more, no less. Thus, as Herman writes, reset (fn _ \n=> (shift (fn k => (k 0) handle Fail _ => 1)) + (raise Fail \"uncaught\")) handle Fail _ => 2 returns 1 \nrather than 2. Since we use exceptions to communicate parse failures, and thus exception handlers to \ninstitute repair, we rely on this behavior. Once BurkeFisher is applied to a particular parser and lexer, \nit instantiates the parser with an instrumented version of the lexer, yielding a module UP (for underlying \nparser ). To parse an under\u00adlying stream us, it wraps the stream and feeds it to the underly\u00ading parser \nwithin a reset, which sets the delimiter for the check\u00adpointing lexer. The result of the parse is paired \nwith NONE, meaning no repair was necessary, which is returned if all goes well. But out\u00adside this pair \n(in particular, outside the reset), there is an exception handler that kicks off the repair process. \nPlacing the handler outside the reset guarantees it won t be captured in the checkpoints. AT LAST when \nthe underlying parser throws a syntax error, BurkeFisher catches it and its list of wrapped streams wss. \nEach wrapped stream represents a possible syntax error within a choice. Concatenating the checkpoints \nfrom each stream, the repairing parse uses tryCPs to attempt a repair at each checkpoint in turn. If \nsuccessful, tryCPs returns a pair of the result from the underlying parser and the replacement token \nit used to get that successful parse. Otherwise tryCPs returns NONE, and parse re-raises the parse error \nusing the underlying lexer streams. Supposing we ve written modules Tok and SimpleLexer (which represents \nstreams as lists of tokens), we can sit down at the REPL and see > structure RP = BurkeFisher(Tok)(DeclRecognizer); \n> structure RPP = RP.ForLexer(SimpleLexer); > RPP.parse [VAL,ID,LPAREN,ID,RPAREN,EQ, NUM,PLUS,NUM,SEMI]; \n((), SOME \"Did you mean fun ?\") A caveat: choice points are commit points There s a subtlety regarding \nchoice: if we factor out = (exp) ; , which is common to both forms of (decl), the repair no longer works. \nThe problem is this: once a choice has been successfully parsed, only the checkpoints of the taken branch \nare retained. The effective result is that repair checkpoints do not always have access to all possible \nbranches. We used exceptions carrying a list of streams to join together the checkpoints of an unsuccessful \nchoice. To deal with suc\u00adcessful choices, we need to maintain all checkpoints even when backtracking \nwe need the backtracking control structure to play nicely with the checkpointing control structure. An \neasy and fairly pleasing way to do this is to parameterize the underlying parser by an implementation \nof backtracking choice which BurkeFisher can then provide which also allows ParseError exceptions to \ncarry just a single stream: fun choose p q = fn (us, w) => p s handle ParseError (us , w ) => q (us, \nw ) Discussion The big idea As with the eager REPL, the key bene.t of control operators is the ability \nto hook into even manipulate the com\u00adputation of a parser, without any understanding of how that compu\u00adtation \nis structured. There are also two signi.cant differences from the eager REPL. First, we assume that parsing \nand lexing are free from observable side effects, so we do not use effect logging (and, in fact, avoid \nstate see below). Thus, we are only logging control state. Second, by having a modicum of knowledge about \nthe structure of input to the parser (via the Tok signature), we are able to intelligently explore the \nspace of input repairs, while keeping the computational structure of the parser abstract. Look Ma, no \nrefs! Contra the eager Scheme REPL, we haven t used mutable state in implementing Burke-Fisher repair. \nWe were able to avoid it because the PARSER signature requires parsers to use their lexers functionally \nin particular, to thread the token stream through the parsing processes. The downside to this approach \nis that checkpointing is sensitive to the way the parser threads the token stream, which as we noted \ncan cause problems when the parser itself backtracks. But, of course, an imperative interface is also \nworkable, and it has the bene.t that every use of the lexer is checkpointed, regard\u00adless of how the token \nstream is threaded. What s more, the token streams can be dropped from the ParseError exception, further \nshrinking the interface between the parser and the repair functor.  functor BurkeFisher (T : TOK) (P \n: PARSER where type tok = T.tok) = struct type tok = T.tok type repair = string type result = P.result \n* string option (* Herman s delimited control from call/cc *) structure C = GreatEscape(type ans = P.result) \nfunctor ForLexer (L : LEXER where type tok = tok) = struct exception ParseError of L.tok_stream list \nstructure WL = WrappedLexer (C) (L) structure UP = P.ForLexer (WL) fun tryReps k [] = NONE | tryReps \nk (t::ts) = SOME (k t, t) handle UP.ParseError _ => tryReps k ts fun tryCPs [] = NONE | tryCPs (k::ks) \n= case tryReps k T.toks of NONE => tryCPs ks | SOME rt => SOME rt fun parse us = (C.reset (fn () => UP.parse \n(WL.wrap us)), NONE) handle UP.ParseError wss => case tryCPs (List.concat (map WL.checkpoints wss)) of \nNONE => raise ParseError (map WL.unwrap wss) | SOME (r, t) => (r, SOME (concat [\"Did you mean \", T.toString \nt, \"?\\n\"])) end end Figure 5. The Burke-Fisher functor To type-checking, and beyond Having generalized \nBurke-Fisher repair to arbitrary parsers, it s natural to wonder if we can go even farther. By encapsulating \nthe notion of input streams and lo\u00adcal repairs in a separate module taken as an extra parameter, the \nBurkeFisher functor could be pared down to handling just the checkpointing and error-catching process. \nWe suspect, for exam\u00adple, that Lerner et al. s SEMINAL tool [9], which attempts to ex\u00adplain type errors \nby searching for repairs, could be restructured to use Burke-Fisher-style local search becoming just \none more in\u00adstantiation of the functor. The real deal The BurkeFisher functor came out of work done building \nnew lexing and parsing infrastructure for SML/NJ; it is in use in production code, and available with \nrecent versions of the compiler.3 The implementation includes the full suite of Burke-Fisher repairs, \nallows for multiple repairs, and judges goodness of repairs using a sophisticated metric. 3 See http://smlnj.org/ \nAcknowledgements This article reports on work supported by the Defense Advanced Research Projects Agency \nunder Air Force Research Laboratory (AFRL/Rome) Contract No. FA8650-10-C-7090 and Cooperative Agreement \nNo. FA8750-10-2-0233. The views expressed are those of the authors and do not re.ect the of.cial policy \nor position of the Department of Defense or the U.S. Government. Turon is currently supported by a Microsoft \nfellowship, and was supported by NSF award CNS-0454136 while writing the ML-ANTLR parser at the University \nof Chicago. John Reppy provided much guidance. Matthias Felleisen pro\u00advided encouragement and insightful \ncomments to Shivers while he was working out the rubout-handler system; Mark Feeley provided Shivers \nan early opportunity to air the design at a Scheme work\u00adshop. The quotation on line 31 of Figure 1 is \ndue to a prince in Denmark. Kent Pitman and Dan Weinreb were fonts of wisdom concerningsophisticateddetailsofclassic \nLISP technology.Thanks go to Vincent St-Amour, Sam Tobin-Hochstadt, and Jesse Tov for feedback on a draft \nof the paper. Shivers would like to dedicate this set of twin pearls to another such set: Olin and Avery. \nReferences [1] E. Biagioni, K. Cline, P. Lee, C. Okasaki, and C. Stone. Safe-for-space threads in Standard \nML. Higher Order and Symbolic Computation, 11: 209 225, Sept. 1998. [2] M. G. Burke and G. A. Fisher. \nA practical method for LR and LL syntactic error diagnosis and recovery. ACM Transactions on Programming \nLanguages and Systems, 9(2):164 197, Mar. 1987. [3] O. Danvy and A. Filinski. Abstracting control. In \nProceedings of the 1990 ACM Conference on LISP and Functional Programming (LFP 90), pages 151 160, 1990. \n[4] M. Felleisen. The theory and practice of .rst-class prompts. In Conference Record of POPL 1988: The \nFifteenth ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 180 190, 1988. [5] \nD. Herman. Functional pearl: The great escape, or how to jump the border without getting caught. In Proceedings \nof the Twelfth ACM SIGPLAN International Conference on Functional Program\u00adming (ICFP 07), 2007. [6] G. \nHutton and E. Meijer. Monadic parsing in Haskell. Journal of Functional Programming, 8(4):437 444, July \n1998. [7] R. Kelsey and J. Rees. The Scheme48 system. http://s48.org. [8] G. Kuan. A true higher-order \nmodule system. PhD thesis, University of Chicago, 2011. [9] B. S. Lerner, M. Flower, D. Grossman, and \nC. Chambers. Searching for type-error messages. In Proceedings of the 2007 ACM SIGPLAN Conference on \nProgramming Language Design and Implementation (PLDI 07), 2007. [10] K. M. Pitman. Ambitious evaluation: \na new reading of an old issue. Lisp Pointers, VIII(2), May 1995. [11] A. Rossberg, C. Russo, and D. Dreyer. \nF-ing modules. In Proceedings of the ACM SIGPLAN Workshop on Types in Language Design and Implementation \n(TLDI 10), 2010. [12] O. Shivers, B. Carlstrom, M. Gasbichler, and M. Sperber. The scsh manual, release \n0.6.6. http://scsh.net, Mar. 2004. [13] D. Sitaram and M. Felleisen. Control delimiters and their hierarchies. \nLisp and Symbolic Computation, 3:67 99, May 1990.  \n\t\t\t", "proc_id": "2034773", "abstract": "<p>We present a technique, based on the use of first-class control operators, enabling programs to maintain and invoke rollback logs for sequences of reversible effects. Our technique is modular, in that it provides complete separation between some library of effectful operations, and a client, \"driver\" program which invokes and rolls back sequences of these operations. In particular, the checkpoint mechanism, which is entirely encapsulated within the effect library, logs not only the library's effects, but also the client's control state. Thus, logging and rollback can be almost completely transparent to the client code.</p> <p>This separation of concerns manifests itself nicely when we must implement software with sophisticated error handling. We illustrate with two examples that exploit the architecture to disentangle some core parsing task from its error management. The parser code is completely separate from the error-correction code, although the two components are deeply intertwined at run time.</p>", "authors": [{"name": "Olin Shivers", "author_profile_id": "81100129912", "affiliation": "Northeastern University, Boston, MA, USA", "person_id": "P2801372", "email_address": "shivers@ccs.neu.edu", "orcid_id": ""}, {"name": "Aaron J. Turon", "author_profile_id": "81418594363", "affiliation": "Northeastern University, Boston, MA, USA", "person_id": "P2801373", "email_address": "turon@ccs.neu.edu", "orcid_id": ""}], "doi_number": "10.1145/2034773.2034783", "year": "2011", "article_id": "2034783", "conference": "ICFP", "title": "Modular rollback through control logging: a pair of twin functional pearls", "url": "http://dl.acm.org/citation.cfm?id=2034783"}