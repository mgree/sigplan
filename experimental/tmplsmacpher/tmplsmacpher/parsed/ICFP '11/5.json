{"article_publication_date": "09-19-2011", "fulltext": "\n A Semantic Model for Graphical User Interfaces Neelakantan R. Krishnaswami Nick Benton Microsoft Research \nMicrosoft Research <neelk@microsoft.com> <nick@microsoft.com> Abstract We give a denotational model \nfor graphical user interface (GUI) programming using the Cartesian closed category of ultrametric spaces. \nThe ultrametric structure enforces causality restrictions on reactive systems and allows well-founded \nrecursive de.nitions by a generalization of guardedness. We capture the arbitrariness of user input (e.g., \na user gets to decide the stream of clicks she sends to a program) by making use of the fact that the \nclosed subsets of an ultrametric space themselves form an ultrametric space, allowing us to interpret \nnondeterminism with a powerspace monad. Algebras for the powerspace monad yield a model of intuition\u00adistic \nlinear logic, which we exploit in the de.nition of a mixed linear/non-linear domain-speci.c language \nfor writing GUI pro\u00adgrams. The non-linear part of the language is used for writing re\u00adactive stream-processing \nfunctions whilst the linear sublanguage naturally captures the generativity and usage constraints on \nthe vari\u00adous linear objects in GUIs, such as the elements of a DOM or scene graph. We have implemented \nthis DSL as an extension to OCaml, and give examples demonstrating that programs in this style can be \nshort and readable. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs \nand Features General Terms Languages, Theory, Design Keywords denotational semantics, ultrametric spaces, \nfunctional reactive programming, guarded recursion, linear logic 1. Introduction Graphical user interfaces \n(GUI) libraries are one of the most widely\u00adused examples of higher-order programming; even languages \nsuch as Javaor C#, in which programmers normally eschew higher\u00adorder style, offer user interface toolkits \nwhich expose higher-order interfaces. Unfortunately, these libraries are a poor advertisement for higher-order \nstyle; they are extremely imperative, dif.cult to extend, and understanding the behavior of client code \nrequires deep familiarity with the internal implementation of the toolkit. Since its introduction, functional \nreactive programming [12] has held great promise for simplifying the speci.cation and interface to graphical \nuser interface libraries. However, a persistent dif.\u00adculty with modeling user interface toolkits with \nfunctional reactive Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. ICFP 11, September 19 21, 2011, Tokyo, Japan. Copyright c &#38;#169; 2011 ACM 978-1-4503-0865-6/11/09. \n. . $10.00 programs is that certain basic abstractions, such as widgets, seem inherently effectful. \nFor example, creating two buttons differs from creating one button and accessing it twice, since creating \ntwo buttons creates two distinct streams of button clicks. That is, since the button abstraction uses \nits access to the outside world to generate a potentially arbitrary stream of clicks indeed, this is \nthe essence of the abstraction it is dif.cult to explain it as a pure value. In this paper, we extend \nour earlier work [17] on the semantics of functional reactive programming to account for this phenomenon. \nIn that work, we used the category of ultrametric spaces to interpret higher-order functional reactive \nprograms, and used Banach s theo\u00adrem to interpret (guarded) feedback. This offers a simple, general semantics \nfor functional reactive programming with an associated language that is essentially the simply-typed \nlambda calculus with a type constructor for streams and a next modality. Our primary observation is that \nthe basic abstraction of reac\u00adtive programming, the event stream, allows us to decouple the state changes \narising from a stream taking on new values as time passes from the effects associated with opening new \nchannels of communi\u00adcation with the user. We can model the creation of a new button, for example, as \na nondeterministic choice over all possible streams of clicks that the user might generate. The powerspace \nmonad we use to interpret the nondeterminism associated with user interaction is rather well-behaved, \nallowing us to design a cleaner term language for GUI-manipulating code than would be possible for general \nimperative code. In particular, algebras for the powerspace monad form a model of intuitionistic linear \nlogic, so we can use a linear lambda calculus syntax for GUI programming. Viewing the monadic effect \nas the composition of the free and forgetful functors, our DSL splits into two parts, a conventional \nnonlinear functional language (with an unconventional treatment of .xed points) in which programmers \ncan write programs to control the behavior of their interface, and a linear one in which they can construct \nand compose widgets and other interactive components. The linear treatment of widgets is a natural .t \nfor interfacing our DSL to existing GUI toolkits. Most of these feature some global piece of state (variously \ncalled the DOM, the scene graph, the canvas, the widget hierarchy, etc.) representing the graphical interface. \nModi.cations to this data structure change the graphical layout of the interface, and the components \nof this data structure typically1 have a strong linearity constraint a given node has a unique path \nfrom the root of the scene graph. By placing widget-manipulating operations in the linear part of our \nAPI, we can conveniently use this global mutable data structure, while still maintaining the relevant \ninvariants and offering a purely functional speci.cation. To summarize, our contributions are: 1 At \nthe implementation level, this is typically a consequence of the fact that most GUI toolkits including \nGTK, Win32, and the HTML/XML DOM require that each node contain a pointer to its (unique) parent. The \ntree-shaped containment hierarchy is used for, amongst other things, routing events ef.ciently. 1. We \nbuild upon our earlier work on semantics of reactive systems to give a simple denotational semantics \nof GUI programs, including strikingly simple semantics for the arbitrariness of user interaction. 2. \nWe give a type theory for this semantics, which integrates our recent work on type systems for guarded \nrecursion with an adjoint calculus [1, 2] for mixed linear/nonlinear logic. Despite the presence of a \n.xed point operator .x x : A. e, this type theory has excellent proof-theoretic properties, including \na simple normalization proof. 3. We illustrate our theoretical work with an implementation, demonstrating \nthat it can lead to clean user code for GUI programs.  2. Programming Language and Model In this section, \nwe will describe the type structure and equational theory of our DSL. Our focus will be on conveying \nintuition about the programming model, as preparation for exploring an extended example. The denotational \nsemantics and proof theory will come after that. In slogan form, we use an intuitionistic lambda calculus \nto give a language for higher-order reactive programming, and combine it with a linear lambda calculus \nto model the stateful nature of the display and user input. Reactive programs are usually interpreted \nas stream transformers. A time-varying value of type X is a stream of Xs, and so a program that takes \na time-varying X and produces a time-varying Y is then a function that takes a stream of Xs and produces \na stream of Y s. In their original paper on functional reactive programming, Elliott and Hudak [12] proposed \nusing general stream-processing functional programs to manipulate these dynamic values. While stream \nprogramming is .exible, it suffers from a major dif.culty: there are de.nable stream-processing programs \nwhich do not correspond to physically realistic stream transformers. If a stream of values represents \na time-varying signal, then it follows that stream processors should be causal: the .rst n outputs of \na program should only depend on the .rst n inputs. But there are common stream functions which are not \ncausal; the simplest example of which is tail xs, whose n-th value is the n +1-st value of xs. There \nhave been several attempts to resolve this dif.culty [18, 20], all of which build on the basic idea of \nusing data abstraction to restrict the de.nable functions to the causal ones. In recent work [17], we \nhave described a new solution to this problem which still blocks non-causal de.nitions, but does not \nsurrender the .exibility of the original FRP model in particular, its support for making free use of \nhigher-order functions for building abstractions. Our basic idea was to work in a lambda calculus with \ntypes not only for data, but also indexed by time. We introduced a type constructor X, pronounced next \nX . If X is a type of values, then X represents X at the next time step. Then, we can type in.nite streams \nas follows: head : S(X) . X tail : S(X) . S(X) cons : X \u00d7 S(X) . S(X) Here, S(X) is the type of streams \nof elements of X. The head operation has the usual type it takes a stream and returns the .rst element, \na value of type X. We diverge from the standard with the type of tail, which returns a value of type \nS(X). So tail does not return a stream right away it only returns a value of stream tomorrow . As a \nresult, it is impossible to take the head of the tail of a stream and perform a non-causal operation \n typing rules out this possibility. Of course, given a value v of type X, and a stream tomorrow vs of \ntype S(X), we can construct a stream today, which will return v today, and then start producing the elements \nof vs tomorrow. In Figure 1, we give the types of a small lambda typed calculus corresponding to this \nidea. The nonlinear types are the types just discussed, and are typed with a judgement G f e :i X. This \ncan be read as saying e is an expression of type X at time i, in context G . The context G also indexes \nall hypotheses with times, which controls when we can use variables the UHYP rule says that a variable \nat time i can only be used at time i or later. The rules for the X type internalize these time indices. \nThe UDELAY rule tells us an expression of type X at time i +1 can be turned into a X at time i, and conversely \nthe UAWAIT rule tells us that a X at time i can be used as an X at time i +1. The last novelty in the \nnonlinear fragment is the UFIX rule. At .rst glance, it seems like an unrestricted .xed point, which \nis surprising in a calculus intended for de.ning well-founded stream programs. However, when we look \nat the time indices, it says that if we can create a value of type X at time i with a hypothesis at time \ni +1, then we can create a value at time i. The underlying intuition is best conveyed at the stream type. \nSuppose that we can build a stream, if only we had one tomorrow. Since we can t look at a stream tomorrow, \nthis means that we can at least produce the head today and so by turning today s output into tomorrow \ns input, we can tie the knot and construct a stream. (However, this works at all types, including functions \nand nested streams.) The nonlinear language is suf.cient for writing pure reactive programs, but cracks \nstart to show if we try to bind it to GUI toolkits. The problem is best illustrated with an example. \nSuppose we had a function button :1 . S(bool), which created a button and returned a stream of booleans \nrepresenting clicks. Now, consider the following two programs: let bs = button() in | let bs = button() \nin let bs = button() in | map xor (zip bs bs) map xor (zip bs bs ) | On the left, we have a program which \ncreates two buttons, and then returns the xor of their click streams. On the right, we have a program \nwhich creates a single button, and then a stream resulting from xor-ing the stream with itself. The program \nin the right will return a constantly-false stream, but there is no reason to expect that the same should \nhappen for two different buttons. Were we to stay within our pure functional language, which satis.es \nall the usual CCC equations, we would have to identify these two programs, which is clearly wrong. We \nwill deal with the side-effects associated with changes to the widget hierarchy by assigning linear types \nto GUI expressions. (Though the behaviour associated with clicks and changes to, for example, the text \ndisplayed in widgets, are still dealt with functionally.) From a purely syntactic point of view, the \nlinearity constraint means we cannot coalesce common subexpressions, and so typing blocks problematic \nexamples like the above. We still need to say precisely what such a syntax should mean a question whose \nanswer we defer to the denotational semantics but for now we keep in mind that any solution will have \nto account for the fact that users are free to click a button arbitrarily, whenever they choose. So we \nadd a linear sub-language, in the style of the LNL calculus [1], also known as the adjoint calculus [2]. \nWe write A, B, C for the linear types, instead of the X, Y, Z we use for nonlinear types. Linear types \ninclude the tensor A . B, the linear function space A -B, and a type Window of GUI windows. We can give \na small but representative set of constants for building GUIs with the following types: label : F (S(string)) \n-Window vstack : Window . Window -Window hstack : Window . Window -Window button : F (S(string)) -Window \n. F (S(bool))  The type constructor F (X) embeds a Functional type into the linear GUI sub-language \n(and dually the type G(A) embeds a GUI type into the functional sub-language), and so the type of label \nsays that if we supply a stream of strings (the time-varying message to display) we will receive a window \nas a return value. The vstack and hstack operations stack two windows vertically or horizontally, with \nthe linearity constraint ensuring that a window cannot be packed on top of itself. The button function \ntakes a stream of label messages, and then returns both a (linear) window, and a (nonlinear) stream of \nbooleans representing the clicks from this button. The typing judgment G; . f t :i A for linear types \nis a little more complicated than for nonlinear ones. There are two contexts, one for nonlinear variables, \nand a second for linear ones. The G; . f t :i A can be read as, t is a term of type A at time i, which \nmay freely use the variables in G, but must use the variables in . exactly once . The presence of the \nlinear variables in . permits us to reason about imperative data structures such as windows in an apparently-functional \nway. The G(A) and F (X) types serve to embed each language in the other. The UG rule says that we can \ntreat a term of type A as a duplicable computation, when it uses no resources from the context. This \nrule is in the nonlinear part of the calculus, but its elimination rule LG lives in the linear sub-language, \nand says that any nonlinear G(A) expression e can be run with the runG(e) expression to produce an A. \nConversely, the LFI rule says that we can embed any nonlinear term t into the linear language F (t), \nwithout using any resources. Its elimination form let F (x)= t in t' takes a term of type F (X), and \nbinds its result to the nonlinear variable x in the scope of t'. Now t' may use the result bound to x \nas often as it likes, even if constructing t originally needed some resources. Finally, in Figure 2, \nwe give the equational theory of our little language. Since our DSL is a total language, it supports \nall the \u00df and . laws of the lambda calculus, for both the linear and nonlinear parts of the DSL. We also \nhave \u00df.-equalities for the adjoint type constructors and the delay type. 3. Example: A Stack-based Calculator \nIn this section, we illustrate our language by developing a small stack-based calculator program. 3.1 \nImplementation Description Conceptually, the calculator consists of two parts. First, we imple\u00adment the \nsemantics of a calculator, making use of all the standard facilities of the host language of our DSL \n(in this case, Objective Caml). In the second part, we will use our DSL to turn the semantics into a \nreactive event processor, and to connect the event processor to a small GUI which lets a user interact \nwith it. 3.1.1 Objective Caml Calculator Interpreter In Figure 3, we give the Objective Caml code which \nimplements the calculator s functionality. An RPN calculator acts on a stack, so on line 1 we de.ne a \ntype of stacks simply as a list of integers. On line 3-4 we de.ne the logical events to which our calculator \nwill react, including receiving a digit, an arithmetic operation, a push or pop instruction, or a no-op. \nOur type of events has no connection to the internal event-loop API of our GUI toolkit it is just an \nordinary Caml datatype representing the semantic events in terms of which we wish to program our calculator. \nOn lines 6-16, we give a step function which takes an event and a stack, and returns a new event. We \nprocess a digit event by adding it as the least signi.cant digit of the topmost element of the stack \n(creating it if necessary). For example, if the topmost element of the stack is 7, then the sequence \nof digit operations Digit 1, Digit 2, Digit 3 will take the stack top from 7 to the number 7123. Nonlinear \nX, Y ::= 1 | X \u00d7 Y | X . Y | S(X) | X | G(A) Linear A, B ::= I | A . B | A -B | Window | F (X) Terms \ne ::= () | (e, e) | fst e | snd e | .x. t | tt' | G(t) | (e) | await(e) | cons(e, e') | head e | tail \ne | .x x : A. e | x t ::= () | let () = t in t' | (t, t) | let (u, v)= t in t' | .x. t | tt' | F (e) \n| let F (x)= t in t' | runG(e) | x Contexts G ::= \u00b7| G,x :i X . ::= \u00b7| .,x :i A Nonlinear Linear G; . \nf t :i AG f e :i X i = jx :i A . G UHYP UUNIT G f x :j A G f () :i 1 G f e :i X G f e ' :i Y G f e :i \nX \u00d7 Y UPAIR UFST G f (e, e '):i X \u00d7 Y G f fst e :i X G f e :i X \u00d7 Y G,x :i A f e :i B USND UFUN G f \nsnd e :i Y G f .x. e :i A . B G f e :i A . B G f e' :i A G f e :i+1 X UAPP UDELAY ' G f tt:i B G f e \n:i X G f e :i X UAWAIT G f await(e):i+1 X G f e :i X G f e' :i+1 S(X) UCONS G f cons(e, e '):i S(X) G \nf e :i S(X)G f e :i S(X) UHEAD UTAIL G f head e :i X G f tail e :i+1 S(X) G,x :i+1 A f e :i A G; \u00b7f \nt :i A UFIX UG G f .x x : A. e :i A G f G(t):i G(A) LHYP LUNIT G; x :i A f x :i A G; \u00b7f () :i I ' G; \n. f t :i I G;.' f t:i A ' LUNITE G; ., .' f let () = t in t:i A ' G; . f t :i A G; .' f t:i B LPAIR G; \n., .' f (t, t'):i A . B ' G; . f t :i A . B G; .',x :i A, y :i B f t:i C LPAIRE G; ., .' f let (x, y)= \nt in t' :i C G; .,x :i A f t :i B LFUN G; . f .x. t :i A -B ' G; . f t :i A -B G; .' f t:i A LAPP G; \n., .' f tt' :i B G f e :i G(A)G f e :i X LG LFI G; \u00b7f runG(e):i A G; \u00b7f F (e):i F (X) ' G; . f t :i F \n(X)G,x :i X;.' f t:i B ' LFE G; ., .' f let F (x)= t in t:i B Figure 1. Types and Syntax  Type A . B \nA -B F (X) 1 X \u00d7 Y X . Y S(X) A G(A) X Equation let () = () in t = \u00df t [t/a]t ' =. let () = t in [()/a]t \n' let (a, b)=(t1,t2) in t ' = \u00df [t1/a][t2/b]t ' [t/c]t ' =. let (a, b)= t in [(a, b)/c]t ' (.a. t ' ) \nt =\u00df [t/a]t ' t = \u00df .a. t a let F (x)= F (e) in t = \u00df [e/x]t [t/a]t ' =. let F (x)= t in [F (x)/a]t ' \n e =. () fst (e, e ' )=\u00df e ' snd (e, e ' )= \u00df e e =. (fst e, snd e) ' (.x. e ' ) e =\u00df [e/x]e e =. .x. \ne x ' head cons(e, e )= \u00df e ' tail cons(e, e ' )= \u00df e e =\u00df cons(head e, tail e) await( e)= \u00df e (await \ne)=. e runG(G(e)) =\u00df e t =. G(runG(t)) .x x : X. e =[.x x : X. e/x]e Figure 2. Equational Theory As in \nother RPN-style calculators, we need a command to mark the end of a numeric input, which the Push event \naccomplishes by pushing 0 onto the top of the stack. Since digit operations only affect the topmost element, \npushing 0 completes the entry of a number by making it the second element of the stack. The Pop operation \ndeletes the topmost element from the stack, discarding it. The Plus, Minus, and Times operations each \ntake the top two elements of the stack, and replace them with the result of performing the appropriate \narithmetic operation on them (reducing the height of the stack by a net of one). The Clear operation \nsimply sets the topmost element of the stack to 0. Finally, we have a catchall clause which does nothing \nto the stack, which handles the Nothing event and also ensures that invalid operations (for instance \nPlus on a stack with 1 or 0 elements) do nothing. On lines 18-22, we de.ne a display function which takes \na stack and returns a string of a comma-separated list of values. On lines 24-27, we de.ne the merge \nfunction, which we will use to multiplex multiple streams of operations into a single stream. Since fair \nmerge is inherently nondeterministic, we implement a simple biased choice operation. If its .rst argument \nis Nothing, then it returns its second argument otherwise it returns its .rst argument. Finally, on \nlines 29-30 we de.ne a function booltoop op b which returns op if b is true, and Nothing otherwise. We \nreiterate that the code in Figure 3 is ordinary Ocaml code. Interpreters and symbolic computation is \nnatural for functional languages, and we do not need any special additional features to implement this \npart. It is only when we need to write interactive code that programs in standard functional languages \n(and for that matter, OO languages) start to lose their appeal.  3.1.2 DSL Code for the User Interface \nIn Figure 4 we give the actual implementation of the user interface, as a program written in our domain-speci.c \nlanguage. The ambient context of the code in this listing is on the functional side of the wall, making \nuse of the G(-) constructor to shift into the linear sublanguage as needed. On lines 1-4, we have a function \nstacks, which takes an initial stack and a stream of operations, and turns it into a stream of stacks. \n It does this by taking the current operation and applies it to the current stack, to get the next stack, \nand recursively calls stacks on the next state and the tail of the stream of operations. Note that as \na recursive de.nition (at a function type), the UFIX rule requires that any recursive calls to stacks \nmust occur at a later time. In this de.nition, the only recursive call we make is inside the tail argument \nto cons, which according to the UCons rule occurs at a later time than the head argument. As a result, \nthis is a safe recursive call which will pass typechecking. Figure 4 contains all of the code we need \nto plug our state ma\u00adchine into the GUI event loop there are no callbacks or anything like that. We \njust do familiar-looking functional programming with streams, with a type system that warns the user \nof any ill-founded de.nitions. On lines 7-51, we actually build a GUI. On line 7, as an abbrevi\u00adation \nwe de.ne the type of input builders input = G(Window . F (S(op))). We can read this type as saying it \nis a GUI command which when executed builds a window yielding a stream of calcu\u00adlator operations. So \nthis is the type we will use for user input GUI widgets in our calculator application. On lines 9-12, \nwe de.ne the calculator button widget. This function takes a string and an event, and returns a button \nlabeled with the string argument, and which returns the event whenever the button is clicked. On line \n11, we create a button, calling the button function with a constant stream of the message argument. This \nreturns a window and a stream of clicks, and we map bool to op over that stream of clicks to generate \na stream of events. (As an aside, we use a nested pattern matching syntax let (w, F(bs)) = ...in ... \nrather than splitting the term into the two bindings let (w, fbs) = ...in let F(bs) = fbs in .... This \nis an easily desugared notational convenience.) On lines 14-16, we use the calculator button function \nto de.ne the numeric function, which is the function we will use to create the number buttons of our \ncalculator. It is just a call to calculator button which converts its numeric argument to a string and \na digit operation before calling calculator button. Despite its simplicity, this function illustrates \na key feature of our library: de.ning new widgets is easy. We construct a new widget for no reason other \nthan to avoid having to write calls like calculator button (string of int 5) (Digit 5). This avoids a \nminiscule amount of redundancy, and yet de.ning new widget operations is lightweight enough that it is \nworth doing. On lines 18-31, we de.ne a function pack, which is a combinator for building new input widgets \nout of old ones. As arguments, it takes a stacking function stack to merge windows (which in this case \nwill be hstack or vstack), and four inputs (g1, g2, g3, g4), which it will coalesce into a new input \nwidget. It does this by executing each of the g s, and merging the returned windows w1, w2, w3, w4 with \nstack, and merging the returned operation streams es1, es2, es3, es4 with the merge operation. The pack \nfunction shows off two strengths and one minor weakness of our DSL. The weakness is simply that we have \nnot yet added lists to the type constructors of our DSL, and so pack is hard-coded to take a 4-tuple. \nThe .rst strength is that pack is a higher-order function, parameterized in the packing order. This is \nsomething that a .rst-order embedded DSL, which did not supply its own interpretation of the function \nspace, could not conveniently do, since the function space in question is a linear function space. The \nsecond strength is the compositionality of functional pro\u00adgramming. We have taken the type G(Window . \nF (S(op))) to be the type of input widgets, and we are at liberty to construct new in\u00adhabitants of this \ntype. Not only are individual buttons input widgets, but entire input panels are also input widgets. \nSo in the de.nition of input panel on lines 33-45, we are able to use the same pack function to lay out \nboth the individual rows of buttons, and the stack 1 type stack = int list 2 3 type op = Push | Pop \n| Digit of int 4 | Plus | Minus | Times 5 | Clear | Delete | Nothing 6 7 val step : op * stack . stack \n8 let step = function 9 | Digit n, m :: s . (10 *m +n)::s 10 | Digit n, [] . [n] 11 | Push, s . 0 :: \ns 12 |Pop, _::s . s 13 |Plus, n::m::s . (n+m) :: s 14 |Minus, n::m::s . (n-m) :: s 15 |Times, n::m::s \n. (n*m) :: s 16 | Clear, n :: s . 0 :: s 17 | Delete, n :: s . s 18 |_, s . s 19 20 val display : stack \n. string 21 let rec display = function 22 | [] . \"0\" 23 | [n] . string_of_int n 24 | n::s . (string_of_int_n) \n^ \", \" ^ (display s) 25 26 val merge:op *op . op 27 let merge = function 28 | Nothing, e . e 29 | e,_ \n. e 30 31 val bool_to_op : op . bool . op 32 let bool_to_op op b = if b then op else Nothing Figure 3. \nRPN Calculator Internals (in OCaml) of rows, simply by varying the stacking parameter. Furthermore, since \npack can do computation, it is able to act as a smart con\u00adstructor which appropriately multiplexes the \ninput signals of all its components. As a result, none of the wiring code is explicit in the code building \nthe input panel the code just follows the tree structure of the visual layout, like an HTML document, \neven though it also produces an output signal.  3.2 Comparison With Traditional Approaches It is dif.cult \nto give a crisp, precise comparison with the traditional approach to GUI programming based on imperative \ncallbacks and event loops, for two reasons. On the one hand, existing GUI libraries have few algebraic \nor equational properties, which makes theoretical comparisons dif.cult, and on the other, we have not \nyet written any large programs in our language, which makes practical comparisons dif.cult. Nevertheless, \nit is still possible to draw distinctions at the architectural level. Traditional GUI toolkits (based \non the model-view-controller pattern [15]) are logically structured as a collection of asynchronous event \nprocessors. Each GUI widget listens to events generated by some other widgets (and the main application/event \nloop), and generates events itself. The primary feature of this design is that widgets can generate events \nat different rates, and there is no guarantee of the order in which events are delivered to other widgets. \n(In practice, the order of delivery depends on the speci.c order in which callbacks were registered with \na widget object.) In contrast, our system is based on a synchronous model of time, such as used in languages \nsuch as Lustre [6] and Lucid Synchrone [21]. There is a global clock, which is respected by every event \nstream in the program every stream generates one event each tick. Our primary motivation was that with \na simpler deterministic semantics, it was possible to interpret higher-order 1 val stacks : stack \u00d7 \nS(op) . S(stack) 2 let rec stacks (stack, ops) = 3 let next_stack = step (head ops, stack) in 4 cons(stack, \nstacks(next_stack, tail ops)) 5 6 7 type input = G(Window . F(S(op))) 8 9 val calculator_button : string \n. op . input 10 let calculator_button msg op = 11 G(let (window, F(bs)) = button F(constant msg) in 12 \n(window, F(map (bool_to_op op) bs)) 13 14 val numeric : int . input 15 let numeric n = 16 calculator_button \n(string_of_int n) (Num n) 17 18 val pack : G(Window . Window -Window) . 19 (input \u00d7 input \u00d7 input \u00d7 input) \n. 20 input 21 let pack stack (g1, g2, g3, g4) = 22 G(let (w1, F(es1)) = runG g1 in 23 let (w2, F(es2)) \n= runG g2 in 24 let (w3, F(es3)) = runG g3 in 25 let (w4, F(es4)) = runG g4 in 26 let w = runG stack \n(runG stack (w1, w2), 27 runG stack (w2, w3)) in 28 let es = F(merge(es1, 29 merge(es2, 30 merge(es3, \nes4)))) in 31 (w, es)) 32 33 val input_panel : input 34 let input_panel = 35 pack G(vstack) 36 (pack \nG(hstack) (numeric 7, numeric 8, numeric 9, 37 calculator_button \"+\" Plus), 38 pack G(hstack) (numeric \n4, numeric 5, numeric 6, 39 calculator_button \"-\" Minus), 40 pack G(hstack) (numeric 1, numeric 2, numeric \n3, 41 calculator_button \"x\" Times), 42 pack G(hstack) (calculator_button \"D\" Delete, 43 numeric 0, 44 \ncalculator_button \",\" Push, 45 calculator_button \"C\" Clear)) 46 47 val calculator : G(Window) 48 let \ncalculator = 49 G(let (input, F(es)) = runG input_panel in 50 let msgs = F(map display (stacks([], es))) \nin 51 vstack(label msgs, input)) Figure 4. Code for Calculator (in embedded GUI DSL) Figure 5. Screenshot \nof the RPN Calculator  constructions such as functions and streams of streams. We think that these constructions \noffer the same simpli.cations of reasoning that the lambda calculus offers over process calculi. Under \na strictly deterministic semantics, it is impossible to write certain programs, such as a fair merge \nof streams. In our calculator example, we have to explicitly write a function to multiplex events, as \ncan be seen in the de.nition of merge on line 26-28 of Figure 3, and in its use in lines 28-31 of Figure \n4. Here, we had to de.ne a biased choice, which favors the left argument over the right. Even though \nfair merges are useful for specifying the behavior of GUIs, we think that it is a bad choice for implementation, \nsince it makes debugging and reasoning about programs much harder than under a deterministic semantics. \nAnother tradeoff comes when trying to correlate events. As can be seen in the de.nition of the op datatype \non line 3-5 of Figure 3, we need to explicitly include a Nothing constructor to indicate that no event \nhappened on this tick. Under an asynchronous event semantics, no-ops do not need to be part of the event \ndatatype, since the event source is never obligated to send a message. However, this advantage is negated \nby the problems that arise when we need to correlate events from multiple sources. Since neither simultaneity \nnor order are guaranteed for event deliveries, clients have to build their own state machines to reconstruct \nevent correlations (such as a view attempting to correlate events generated by the model and the controller). \nBuilding these state machines can get tricky, and programmers are often tempted to exploit details of \nthe subject-observer implementation and register callbacks in a particular order to guarantee a certain \norder of event delivery. These tricks are fragile, and any errors lead to bugs which can be .endishly \ndif.cult to diagnose. 4. Denotational Semantics 4.1 Intuition Reactive programs are typically interpreted \nas stream transformers: functions which take a stream of inputs and generate a stream of outputs. However, \nnot all functions on streams correspond to realistic reactive programs. For example, a stock trading \nprogram accepts a stream of price quotes and emits a sequence of buy and sell orders, but the set-theoretic \nfunction space Price. . Order. contains functions which produces orders that are a function of the future \nstock prices. These functions are, alas, not implementable. The condition governing which stream functions \nare imple\u00admentable is causality: the .rst n outputs may only depend on the .rst n inputs. Writing LxsJn \nfor the n-element pre.x of the stream xs, we can express causality as follows: De.nitition 1. (Causality) \nA stream function f : A. . B. is causal, when for all n and all streams as and as ', we have LasJn =as \n'=.Lf asJn =f as ' nn Causality is a very important idea, but it is de.ned in terms of stream functions, \nand for building programs we will need many more types than just the stream type. So we need to generalize \ncausality to work at other types such as streams of streams, or even higher-order functions. Furthermore, \nit is very common in reactive programming to de.ne streams by feedback and recursion, such as in the \nfollowing de.nition of the increasing sequence of naturals: nats = \u00b5(.xs. 0 :: map succ xs) Intuitively, \nthis .xed point is well-de.ned because the lambda\u00adterm can produce the .rst value of its output (that \nis, 0) before looking at its input. So we can imagine constructing the .xed point via a feedback process, \nin which we take the n-the output and feed it back to as the input at time n +1. So as long as we can \ngenerate more than n outputs from the .rst n inputs, we can .nd a .xed point. De.nitition 2. (Guardedness) \nA function f : A. . B. is guarded, when there exists a k> 0 such that for all n and all streams as and \nas ', we have LasJ=as '=.Lf asJ=f as ' nn+k nn+k Lemma 1. (Fixed Points of Guarded Functions) Every \nguarded endofunction g : A. . A. has a unique .xed point. Just as with causality, the generalization \nto higher types seems both useful and unobvious. For example, we may which to de.ne a recursive function \nto generate the Fibonacci numbers: .b = \u00b5(.f. .(j, k).j :: f(k, j + k)) The above de.nition of .b seems \nintuitively plausible, but goes beyond the stream-based de.nition of guardedness, since it involves taking \na .xed point at function type. To systematically answer these questions, we make use of the mathematics \nof metric spaces. 4.2 1-Bounded Complete Ultrametric Spaces De.nitition 3. (Complete 1-bounded Ultrametric \nSpaces) A com\u00adplete 1-bounded ultrametric space is a pair (X, dX ), where X is a set and dX . X \u00d7 X . \n[0, 1] is a distance function, satisfying the following axioms: dX (x, y)=0 if and only if x = y  dX \n(x, y)= dX (y, x)  dX (x, y) = max(dX (x, z),dX (z, y))  Every Cauchy sequence in X has a limit  \nA sequence (xi) is Cauchy if for any E . [0, 1], there is an n such that for all i>n, j>n, d(xi,xj ) \n= E. A limit is an x such that for all E, there is an n such that for all i>n, d(x, xi) = E. The .rst \nthree conditions axiomatize the properties of 1-bounded distance functions that the distance between \na point and it\u00adself is zero; that distances are symmetric, and the triangle in\u00adequality. Ultrametric \nspaces satisfy a stronger version of the tri\u00adangle inequality than ordinary metric spaces, which only \nask that d(x, y) be less than or equal to dX (x, z)+ dX (z, y), rather than max(dX (x, y),dX (y, x ' \n)). We often just write X for (X, dX ). All the metric spaces we consider are bisected, meaning that \nthe distance between any two points is 2-n for some n . N. We will often simply write X for a metric \nspace, and dX for its corresponding metric (or even d, if the expression is unambiguous). De.nitition \n4. (Nonexpansive maps) A function f : X . Y is nonexpansive when for all a, a ' . X, we have dY (f a,f \na ' ) = dX (a, a ' ). Complete 1-bounded ultrametric spaces and nonexpansive maps form a category (which \nwe will write Ult). The category Ult is bicartesian closed (ie, has sums, products and exponentials), \nand supports a number of other functors on it which we will use in our semantics. (Our semantics will \nonly use nonempty spaces, even though we will perform our semantic constructions in the full category.) \n1. Any set X (such as the natural numbers N) forms a metric space under the discrete metric (i.e., d(x, \ny)=0 if x = y, and 1 otherwise). 2. If (X, dX ) is an object of Ult, we can form causal streams S(X) \nof the elements as follows:  S(X)=({as | as . N . X} ,dS(X)), where dS(X)(xs, ys)=sup2-n \u00d7 dX (xsn, \nysn) | n . N  The intuition behind the stream metric is best conveyed by thinking of S(N), the streams \nof natural numbers (a discrete space). In this case, the distance between two streams xs and ys is 2-n, \nwhere n is the .rst position at which they disagree. So if xs and ys disagree immediately, at time 0, \nthen their distance is 1. If they disagree at time 32, then their distance is 2-32. If they never disagree, \nthen their distance is 2-8 =0 that is, they are the same stream. It is a matter of unwinding de.nitions \nto establish that a non\u00adexpansive map S(X) . S(Y ) (for discrete spaces X and Y ) is equivalent to the \nde.nition of causality that the .rst k outputs are determined by at most the .rst k inputs. In this \nsense, ultrametric spaces give a natural setting in which to interpret higher-order reactive programs \n[17], since we can interpret func\u00adtions with the Cartesian closure and streams of arbitrary type with \nthe stream functor, and nevertheless we can still rule out the de.nition of non-causal functions. 3. \nIf (A, dA) and (B, dB) are objects of Ult, we have a Cartesian product (A, dA) \u00d7 (B, dB) = (A \u00d7 B, dA\u00d7B), \nwhere  dA\u00d7B((a, b), (a ' ,b ' )) = max(dA(a, a ' ),dB(b, b ' ))  The elements of the product space \nare pairs of elements of the two underlying spaces, and the distance between two pairs is the maximum \nof the distances between the individual components. 4. If (A, dA) and (B, dB) are objects of Ult, we \nhave an exponen\u00adtial de.ned as follows: (A, dA) . (B, dB) = (Ult(A, B),dA.B ), where  dA.B(f, g) = \nmax {dB (f a,g a) | a . A}  The set of points for the function space is the set of nonexpansive functions \nfrom A to B (i.e., the hom-set for A and B), and the distance between two functions is the maximum distance \nbetween the results ranging over all arguments a. Intuitively, a function can be thought of as an A-indexed \ntuple of B s, and so the metric for the function space can be seen as a generalization of the metric \nfor tuples. 5. If (A, dA) and (B, dB ) are objects of Ult, we have a coproduct de.ned as follows: (A, \ndA)+(B, dB) = (A + B, dA+B), where . . dA(a, a ' ) if x = inl(a),y = inl(a ' ) dA+B (x, y)= dB(b, b ' \n) if x = inr(b),y = inr(b ' ) . 1 otherwise The presence of coproducts in our semantic model means that \nit is possible to implement FRP-style switching combinators simply by performing a case analysis and \nreturning different stream results, in the ordinary style of functional programming. (For space reasons, \nwe did not include rules for sums in our calculus, though they can be added in the standard way.) 6. \nFor each metric space, there is a contraction (X) (pronounced next-X ) de.ned as follows: (X, d)=(X, \nd ' ), where d ' (X)(a, a ' )= 21 dX (a, a ' ) This functor is Cartesian closed. That is, there are isomorphisms \nzip : X \u00d7 Y . (X \u00d7Y ) and E : (X . Y ) . X . Y . The zip isomorphism says that a delayed pair is the \nsame as a pair of delayed values. A little more surprisingly, the E isomorphism says that a delayed function \nis equivalent to a function which takes a delayed argument and returns a delayed result. These maps are \nall just the identity on points; the real content lies in the fact that these maps are nonexpansive. \nWe will write E for the left-to-right direction of the isomorphism, and write E-1 for the right-to-left \ndirection, and similarly for the other isomorphisms we make use of. We can also iterate these constructions, \nand will write Ei for the isomorphism of type i(X . Y ) . iX . iY (and again, similarly for the other \nisomorphisms). We give the explicit de.nitions of these isomorphisms in Figure 6. In addition, we have \na natural transformation dX : X . X (pronounced delay ) which embeds each space X into X via the identity \non points. Intuitively, this corresponds to taking a value and delaying using it until the tick of the \nclock. Theorem 1. (Banach s Contraction Map Theorem) If A . Ult is a nonempty metric space, and f : A \n. A is a strictly contractive function, then f has a unique .xed point. The utility of the delay functor \nis that it lets us concisely state Banach s contraction map theorem for any nonempty, bisected metric \nspace X: Banach s theorem is equivalent (as our de.nable types are all nonempty) to the assertion that \nthere is a .xed point operator .x :( X . X) . X. 7. If X is an object of M, then we can construct the \npower space PC (X) of its closed, nonempty subsets (a subset S . X is closed if every Cauchy sequence \nof elements in S has a limit also in S): PC (X)= {U . X | U is closed and nonempty} supinfy.V dX (x, \ny), dPC (X)(U, V ) = maxx.U supinfx.U dX (x, y)) y.V The metric dPC X is known as the Hausdorff metric. \nThe functo\u00adrial action of PC (f ): PC (X) .PC (Y ) applies f pointwise to the elements of its argument, \nand takes the metric closure of that image. Explicitly, PC (f)= .X. cl({f(x) | x . X}). The functor \nPC (-) gives rise to a strong, commutative monad [25]. We will write .X : X .PC (X) and \u00b5X : P2 C (X) \n.PC (X) for its unit and multiplication, and sX : X \u00d7PC (Y ) . PC (X \u00d7 Y ) for its strength. Explicitly, \nthe de.nition of the unit is .(x)= {x}, and the multiplication is \u00b5(U)= cl( U). Furthermore, the contraction \nfunctor distributes over the pow\u00aderspace; we have an isomorphism P C : PC (X) .PC ( X). (Again, this \nisomorphism is the identity on points, and fol\u00adlowing the pattern of Figure 6 we can iterate it to construct \nP i C : iPC (X) .PC ( i X).) 8. To interpret the Window type, we .rst take Pic to be the set of trees \ninductively generated from the following grammar (with s ranging over strings): p ::= Button(s) | Label(s) \n| Vert(p, p) | Hor(p, p) We turn this into a space by equipping it with the discrete metric, and then \ntake Window to be streams of Pic.  4.3 The Eilenberg-Moore Category of PC From Ult, we can construct \nits Eilenberg-Moore category UltP , whose objects are algebras (A, a : PC (A) . A), where A is a nonempty \n1-bounded ultrametric space, and a satis.es a.PC (a)= a . \u00b5 and a . . = idA. The morphisms from (A, a) \nto (B, \u00df) are maps A . B in the category of ultrametric spaces which commute with the action (so that \nf . a = \u00df .PC (f)). Identity and composition are inherited from the underlying category Ult. (As a notational \naid to keeping the categories distinct, we will use functional composition f . g zipi : i(X) \u00d7 i(Y \n) . i(X \u00d7 Y ) zip0 = idX\u00d7Y zipn +1 = zip . (zipn ) zipi : i(X) \u00d7 i(Y ) . i(X \u00d7 Y ) zip0 = idX\u00d7Y \nzipn +1 = (zipn ) . zip Ei : i(X . Y ) . i(X) . i(Y ) E0 = idX.Y En+1 = E . (En) E-1 i i :(X) . i(Y \n) . i(X . Y ) E-1 0 = idX.Y E-1 n+1 = (En) . E-1 di : A . i(X) d0 = idA dn+1 = d . dn Figure 6. De.nition \nof Iterated Morphisms when composing maps in Ult, and diagrammatic order f; g when composing maps in \nUltP .) Because PC is a commutative strong monad, Ult has equalizers and coequalizers [22], and UltP \nhas coequalizers of re.exive pairs (since PC preserves coequalizers of re.exive pairs), UltP is symmetric \nmonoidal closed [2, 14, 16]. The tensor product is de.ned using a coequalizer and the exponential by \nan equalizer. We can lift the distribution of the next modality through tensor products zip : A. B (A.B) \nand the monoidal exponential E : (A -B) A - B, as well as the delay operator d : A . A. These operations \nsimply inherit their structure from Ult, but for the operations to respect the algebra structure we need \nthe isomorphism PC : PC (X) PC ( X). This explains why we restricted PC (X) to nonempty closed subsets \nof interpretation X one leg of this isomorphism would fail to be nonexpansive in the presence of the \nempty set, which is distance 1 from any other subset. We also iterate all of these morphisms following \nthe pattern of Figure 6. The free F (X)=(PC (X),\u00b5) and forgetful G(A, a)= A functors give rise to an \nadjunction between Ult and UltP , whose unit and counit we write .X : X . G(F (X)) and eA : F (G(A, a)) \n. A. The action of . as the unit of this adjunction is the same natural transformation as the unit of \nthe monad PC , so no notational confusion can arise. The components of the counit e are the algebra maps \na of (A, a). This is a monoidal adjunction with a natural isomorphism m : F (X) . F (Y ) F (X \u00d7 Y ). \nThis isomorphism lets us duplicate and discard F -typed values; we have maps drop : F (X) . I and dup \n: F (X) . F (X) . F (X).  4.4 Interpretation of the Programming Language In Figure 7, we give the interpretation \nof the syntactic types in terms of metric spaces. The interpretation follows the categorical construc\u00adtions \n in each category, products go to products, exponentials go to exponentials, and the F and G adjunctions \ninterpret the modal operators connecting the Functional and Graphical sub-languages. In Figure 8, we \ngive the semantic interpretation of the syntax of our language. A context G= x :i X, . . . , z :k Z is \ninterpreted as a product i[ X] \u00d7 ... k [ Z] , and a term-in-context G f e :i X is interpreted as a morphism \n[[G]] . i[ X] . A context .= a :i A, . . . , b :j B is interpreted by the tensor product i[ A] . ... \nj [ B] . The pair of contexts G; . is interpreted by F ([[G]]) . [[.]], and a linear term G; . f t :i \nA is interpreted as a morphism F ([[G]]) . [[.]] . i[ A] in UltP . As an abuse of notation, we abbreviate \n[[G f e :i X] as [ e] when G,X and i are clear from context, and similarly we abbreviate [[G; . f t :i \nA] as [ t] . Our semantics combines the interpretation of adjoint logic given in [1] with the guarded \ncalculus given by Krishnaswami and Ben\u00adton [17]. The main technical subtlety arose with the interpreta\u00adtion \nof the time indices. Concretely, consider the interpretation of G f G(t):i G(A), which we expect to be \na map [[G]] . i[ G(A)]], and contrast it with its subderivation G; \u00b7f t :i A, whose interpreta\u00adtion (viewed \nas a map in Ult) is in [[G]] . G( i(A)). To swap these constructors, we use the P PC ( X) isomorphism. \nC : PC (X) For readability, the semantics suppresses the associativity and commutativity maps needed \nto permute the context. Theorem 2. (Soundness of Substitution) Suppose G f e :i X and G; . f t :i A, \nand i = j. Then: '' ' If G,x :j X f e :k Y , then [ e ] .G,dj-i . [ e] = [[[e/x]e ] . X ' If G,x :j \nX;. f tB, then F (G,dj-i . [ e] );[ t] = :kX [[[e/x]t ' ] .  If G; . ' ,a :j A f t ' :k B, then dupF \n(G);(F (G) . . ' . [ t]]); [ t ' ] = [[[t/a]t ' ] .  Proof. The proof is a routine induction. Theorem \n3. (Soundness of Equality Rules) For well-typed terms, the equational rules in Figure 2 are sound with \nrespect to the denotational semantics. Proof. The proof is a routine veri.cation. 4.5 Denotational Semantics \nof GUI Operations We have left out the constructors from the syntax to keep from cluttering the proof \ntheory. We give the semantics of a representative collection of GUI operations (including all of the \nones used in the calculator example) below: label : F (S(string)) . Window label X = {.n. Label(xsn) \n| xs . X} vstack : Window . Window . Window vstack(W, W ' ) = cl({.n. Vert(wn, w ' n) | w . W, w ' . \nW ' }) hstack : Window . Window . Window hstack(W, W ' ) = cl({.n. Hor(wn, w ' n) | w . W, w ' . W ' \n}) button : F (S(string)) . Window . F (S(bool)) button X = ({.n. Button(xsn) | xs . X} , S(bool)) delete \n: Window . I delete W = () Since the free functor F yields sets of possible values, we must de.ne these \nconstants so that they de.ne appropriate outputs for all their possible inputs. The .rst label operation \nessentially just maps an operator over its input, and the two stacking operations take a Cartesian product \nto de.ne the result for each pair of possibilities. On the other hand, the button operation, which is \nan operation representing user input, does something a little more interesting. It returns a set of pairs \nof window values (constructed by mapping its input over the Button constructor), and a set of streams \nof booleans (denoting clicks). We de.ne the windows values by mapping over the input, as with the other \noperations, but we return the full space of boolean streams as its second argument. 1 =1 [ X \u00d7 Y ] =[ \nX] \u00d7 [ Y ] [ X . Y ] =[ X] . [ Y ] [ S(X)]] = S([[A]]) [ (X)]] = [ X] [ G(A)]] = G([[A]]) [ I] =1 \n[ A . B] =[ A] . [ B] [ A -B] =[ A] -[ B] [ F (X)]] = F ([[X]]) [ Window] = F (S(Pic)) F (X) =(PC (X),\u00b5) \nG(A, a)= A Figure 7. Interpretation of Types Therefore, if we receive a .xed stream of string inputs \nxs, we may receive any stream of clicks as a possible return value. So the semantics of button captures \nthe inherent nondeterminism of user actions in a simple way we simply say that the user can click a \nbutton whenever he or she likes, and our semantics has to account for all of these possibilities. Finally, \nthe delete operation simply throws away its argument. Using the semantics of this command, it is possible \nto prove program equalities such as the following: let (F(x), v) = button() in | let (F(y), w) = button() \nlet (F(y), w) = button() in | in w let()=delete v | inw | In this program, we create two buttons and \nthrow the .rst of them away, which is equivalent to not creating it at all. The proof follows as easily \nfrom the semantics of programs as it ought. One fact worth noting is that our semantics does not rule \nout the possibility of two different buttons both yielding a click event (ie, returning true) on the \nsame time step. We see essentially two possibilities for ruling out such behavior, both of which we rejected \nfor this work. If we wish to retain a high-level semantics, where we specify the semantics of the API \nin terms of events like clicks, rather than primitive events such as mouse movements and keystrokes, \nthen positing a collection of constraints (such as two buttons are never simultaneously clicked ) seems \nto require explicitly modeling a store of input channels and maintaining these constraints as an invariant \non the store. This is a bit ugly, and more than a little technically complicated. A better approach, \nin our view, would be to model layout and event synthesis explicitly. In our semantics, we model the \ndisplay as a time-varying tree, much like an HTML document. If the display model actually speci.ed what \nthe graphic layout of a GUI program was, and supplied the primitive mouse movements, keystrokes, and \nclicks as an input, then the semantics could explicitly give the functions explaining how to interpret \nprimitive events as high-level ones for example, we might de.ne a click to occur when the mouse is pressed \ndown inside the button area, and subsequently released, while still inside the button area. We think \nthis level of precision is likely the right approach to take when building new GUI toolkits. However, \nif we wish to bind to existing toolkits, it is better to give a semantics imprecise enough to tolerate \nwide variation in precisely how it is implemented. [[G f e :i A] [[G f cons(e, e ' ):i S(A)]] [[G f \n.x. e :i A . B] [[G f xn :j A] [[G f await(e):i+1 A] [[G f head e :i A] [[G f tail e :i+1 S(A)]] ' \n[[G f ee :i B] [[G f G(t):i G(A)]] [[G f .x x : A. e :i A] [[G; a :i A f a :j A] [[G; \u00b7f () :i I]] \n[[G; ., . ' f let () = t in t ' :i B] [[G; ., . ' f (t, t ' ):i A . B] = = = = = = = = = = = = = = \n[[G; ., . ' f let (a, b)= t in t ' :i C] = [[G; . f .a. t :i A -B] = [[G; ., . ' f tt ' :i B] = [[G; \n\u00b7f runG(e):i A] = [[G; \u00b7f F (e):i F (X)]] = [[G; ., . ' f let F (x)= t in t ' :i C] = [ e] ' i(cons) \n. zipi .([ e] , [ e ] ) Ei . .([[G,x :i A f e :i B]]) j-i d. pn, if xn :i A . G A [ e] i(hd) . [ t] \n i(tl) . [ t]  ' i(eval) . zipi .([ e] , [ e ] ) P i C . G([[t]]) . .G  i(.xA) . Ei . .([[e]]) \n drop; d j-i drop; d i dupF (G) . . . . ' ;[ t]]; [ t ' ] dupF (G) . . . . ' ; ([[t] . [ t ' ]]); zip \ni dupF (G) . . . . ' ; (F (G) . . ' . [ t]]); [ t ' ] .([[G; .,a :i A f t :i B]]); Ei dupF (G) . . . \n. ' ; [ t] . [ t ' ]]; zip i ; eval F (P i C . [[G f e :i G(A)]]); e F ([[e]]) dupF (G) . . . . ' ; F \n(G) . . ' . [ t]]; m . . ' ;[ t ' ] Figure 8. Denotational Interpretation of Terms 5. Proof Theory \nWe have established denotationally that the \u00df and . equalities are valid, but this does not make clear \njust how extraordinarily well\u00adbehaved this calculus is. We can prove a strati.ed normalization result, \ndespite the fact that this language contains a recursion operator of the form .x x : A. e. To state the \nnormalization theorem precisely, we must .rst say what the normal forms are. To see that this is not \nan entirely trivial question, consider the term e . .x xs : S(N). cons(0,x). The term e is equivalent \nto cons(0,e), and to cons(0, cons(0,e)) and so on for in.nitely many unfoldings. So we have to ask, which \nof these unfoldings count as normal forms, and which do not? In Figure 9, we give normal and atomic forms \nof the calculus. The normal and atomic forms are a sub-syntax of the full language with the property \nthat only beta-normal terms are grammatically valid. In this syntax, we count .xed points as atomic forms, \nwhich means we still need to .x a policy for when to allow .xed points, and when not. Next, we introduce \nthe idea of a n-normal form, which are normal forms in which .xed point subterms .x x : A. e only occur \nat times of n or greater. So e . .x xs : S(N). cons(0,x) is itself a 0-normal form, and cons(0,e) is \na 1-normal form, and cons(0, cons(0,e)) is a 2-normal form, and so on. To specify n\u00adnormal forms, we \nuse the judgments G fn e :i X and G; . fn t :i A. These typing rules exactly mirror the existing typing \nrules, with the exception of the UFIX rule (given in Figure 9), where we add a side-condition that a \n.xed point is permitted only when the time index i at which it is typechecked is at least as large as \nn. Hence an n-normal form is a normal form which passes the n-restricted typechecking rule for .xed points. \nSo our example e . .x xs : S(N). cons(0,x) is a 0-normal form but not a 1-normal form, since it has no \nredexes, but does have a .xed point at time 0. However, its unfolding cons(0,e) is a 1-normal form, since \ne occurs in the tail position of a cons, which is checked at a time index 1 greater than the cons expression. \n Now, we can show that every term has a normal form (i.e., a weak normalization result) in the following \nmanner. Given two n\u00adnormal terms, we can de.ne a hereditary substitution [27] which combines substitution \nand computing a normal form. For our type system, an appropriate functions are given in Figures 10, 11, \nand 12. In each of these .gures, we de.ne two of six mutually recursive procedures, one substituting \na normal form into a normal form, and the other substituting a normal form into a atomic term. The normal\u00adnormal \nsubstitution returns a new normal form, and the normal\u00adatomic substitution returns a pair of a term and \noptionally a type. If the result of the substitution is still an atomic term, then no type is returned, \nand if it is a normal form, the type of the substitutand is returned. Below, we write A . X to say that \nthe type A is a subterm of the type X. Theorem 4. (Hereditary Substitution) Suppose G fn e :i X and G; \n. fn t :i A and i = j. Then If G,x :j X fn ' :k Y then G fe/x)e ' e n ( :k Y X ' ' If G,x :j X;. fn :k \nB then G; . f( t t n e/x):k B X ' ' If G; . ' ,a :j A fn t :k B then G; ., . ' fn t/a t :k B A If G,x \n:j X fn g :k Y then either ( g = ( ' ,Y ) and Y . X and G fn e ' e/x)e X :k Y or (e/x )g =(g ' , n/a) \nand G fn g ' :k Y X If G,x :j X;. fn u :k B then either (e/x )u =(t ' ,B) and B . X and G; . fn t ' :k \nB  X or (e/x )u =(u ' , n/a) and G; . fn u ' :k B X If G; . ' ,a :j A fn u :k B then either u =(t fn \n' t/a ' ,B) and B . A and G; ., . ' t :k B A or t/a u =(u ' , n/a) and G; ., . ' fn u ' :k B A Furthermore, \nhereditary substitution is \u00df.-equivalent to ordinary substitution. The statement of the theorem is a \nbit complicated, since we have 6 cases, depending on which judgement and context we are substituting \ninto, and whether we are substituting into a normal or atomic form. Luckily, the induction is straightforward, \nand the algorithm offers no surprises. The induction is lexicographically on the type of the term being \nsubstituted, together with the unordered product of the sizes of the two derivations of the substitutand \nand subtitutee. Note that hereditary substitution never needs to unroll .xed points. By hypothesis, neither \nthe substitutee nor the substitutand contain .xed point terms at an index less than n, and as a result, \nthe process of substitution and normalization will never create a .xed point at the head of a term at \ntime less than n. As a result, we can prove an unrolling lemma separately, without any mutual recursion \nwith the normalization algorithm. In Figure 13, we de.ne an unfolding operation Iel which unrolls all \nthe .xed points in a term by one step, and prove the following theorem: Theorem 5. (Unrolling) If G \nfn e :i X, then G fn+1 Iel :i X  If G; . fn t :i X, then G; . fn+1 Itl :i X  Proof. The result follows \nby a routine induction on the derivation. Now we can combine these two theorems to prove a normaliza\u00adtion \ntheorem. Theorem 6. (Weak Normalization) Suppose G f e :i X. Then for any m, there is an m-normal form \ne ', such that G fm e ' :i X, which is \u00df.-equivalent to e. Normal Nonlinear e ::= () | ( e, e ' ) | .x. \ne | cons( e, e ' ) | G(t ) | ( e) | g Atomic Nonlinear g ::= x | ge | fst g | snd g | await(g) | head \ng | tail g | .x x : X. e Normal Linear t ::= () | (t, t ' ) | .x. t | let () = u in t | let (a, b)= u \nin t | F ( e) | let F (x)= u in t | u Atomic Linear u ::= a | ut | runG(g) G fn e :i X G; . fn t :i A \nG,x :i+1 X fn e :i Xi = n UFIX G fn .x x : A. e :i X (all other rules unchanged except for the appearance \nof n) Figure 9. Normal and Atomic Forms, and Leveled Fixed Points ( () () e/x)X = (e/x )X ( ' , '' )= \ne/x)X e ' e/x)X e '' ee (( , ( ) '' ( .y. = e/x)X e e/x)X e .y. ( ' ( = e/x)X e ' ) e/x)X e (( (e/x \n)X cons( e ' e '' )= cons(( ' , ( '' ) , e/x)X e e/x)X e (e/x )X G(t)= G (( e/x)X t) '' g when ( , \nn/a) e/x)X g =(g ( = e/x)X g ' e e/x)X g = ( ' ,Y ) when ( e (e/x )X x =(x, X) (e/x )X y =(y, n/a) ' \n ( .x y : Y. = e/x)X e ' ),Y ) e/x)X e (.x y : Y. (( ' let e e/x)X e2 in = ( 2 case ( e/x)X g of (e/x \n)X g1 e 2 = ' '' (g, n/a) . ge 2, n/a) ( , ' '' (.y. e ,Y . Z) . e /y e 12Y 1 case ( e/x)X g of '' ( \nhead g =(g, n/a) . (head g, n/a) e/x)X (cons( e1,e 2),S(Y )) . ( e1,Y ) case ( e/x)X g of '' ( tail \ng =(g, n/a) . (tail g, n/a) e/x)X (cons( e1,e 2),S(Y )) . ( e2,S(Y )) case ( e/x)X g of '' ( fst g \n=(g, n/a) . (fst g, n/a) e/x)X (( e1,e 2),Y \u00d7 Z) . ( e2,Y ) case ( e/x)X g of '' ( snd g =(g, n/a) \n. (snd g, n/a) e/x)X (( e1,e 2),Y \u00d7 Z) . ( e2,Z) case ( e/x)X g of ' ( await(g) =(g . (await(g ' ), \nn/a) e/x)X , n/a) ' ( e , Y ) . ( e ' ,Y ) Figure 10. Substituting Nonlinear Terms into Nonlinear Terms \nSuppose G; . f t :i A. Then for any n, there is an n-normal form t ', such that G; . fn t ' :i A, which \nis \u00df.-equivalent to t. To prove this, note than any well-typed term satis.es the UFIX rule for n =0. \nHence we can use the unfolding lemma n times to get a term which has no .xed points at times earlier \nthan n. Then we can .nd a normal form, by inductively walking down the syntax and using hereditary substitution \nto eliminate reducible expressions. ( () () I()l = I()l e/x)X = ( (t ' = e/x)X , ( t '' ) I(e, e ' )l \n=(Iel , Ie 'l) e/x)X ,t '' )(( t ' e/x)X (e/x )X .y. t ' = .y. ( t ' I.x. el = .x. Iel e/x)X ' (e/x \n)X F ( ' )= e/x)X e ' Icons(e, e )l = cons(Iel, Ie 'l) eF (( ) I (e)l = (Iel) e/x)X u of case ( IG(t)l \n= G(Itl) ' ' e/x)X , n/a) let () = u e/x)X e/x)X 'l ( let () = u in t =(u . in ( t Ixl = x ((),I) .( \nt Iee = IelIe 'l Ifst el = fst Iel case ( e/x)X u of Isnd el = snd Iel ' (u, n/a) . Ihead el = head Iel \n' e/x)X ((t1,t2),A . B) .  (e/x )X let (a, b)= u in t = let (x, y)= u in ( t Itail el = tail Iel Iawait(e)l \n= await(Iel) (t2/b)B ((t1/a)A e/x)X (( t)) I.x x : A. el =[.x x : A. Iel/x] Iel case ( e/x)X u of ' \n (u, n/a) . I()l = I()l ' e/x)X I(t, t ' )l (F ( e ' ),F (Y )) .I.a. tl = .a. Itl (e (( IF (e)l = F \n(Iel) (e/x )X let F (x)= u in t = let () = u in ( t =(Itl , It 'l) ' /y)Y e/x)X t) G u ' when ( ' , \nn/a) Ial = a e/x)X u =(u e/x)X u ( = t ' when ( Itt 'l = ItlIt 'l e/x)X u =(t ' ,A) Ilet () = t in t \n'l = let () = Itl in It 'l Ilet (a, b)= t in t 'l = let (a, b)= Itl in It 'l (e/x )X a =(a, n/a) Ilet \nF (x)= t in t 'l = let F (x)= Itl in It 'l case ( IrunG(e)l = runG(Iel) e/x)X g of ' (e/x )X runG(g)= \n(g, n/a) . (runG(g ' ), n/a) (G(t),G(A)) . (t, A) Figure 13. Unfolding let t ' = ( t2 in e/x)X 2 case \n( e/x)X u1 of (e/x )X u1 t2 = ' '' (u1, n/a) . (ue 2, n/a) (1 ,(.a. t ' 1,A -B) . t ' 2/aA t ' 1 6. \nImplementation The basic idea underlying our implementation is to represent a Figure 11. Substituting \nNonlinear Terms into Linear Terms collection of streams with a data.ow graph. An imperative data.ow network \nis rather like a generalized spreadsheet. It has a collection of cells, each containing some code whose \nevaluation may read other (t/a)A () =() cells. When a cell is read, the expression within the cell is \nevaluated, t '' ) (t/a)A (t ' ,t '' ) =((t/a)A t ' , (t/a)A recursively triggering the evaluation of \nother cells as they are read (t/a)A .y. t ' = .y. (t/a)A t ' by the program expression. Furthermore, \neach cell memoizes its (t/a)A F ( e ' )= F ( e ' ) expression, so that repeated reads of the same cell \nwill not trigger case (t/a)A u1 of re-evaluation. (u1, n/a) . (t/a)A let () = u1 in t2 = ' Then, we implement \nreactive programs with a data.ow graph, ' let () = u in (t/a)A 1 t2 which runs inside an event loop. \nInstead of representing streams as ((),I) .(t/a)A t2 lazy sequences of elements, we represent our streams \nwith mutable case (t/a)A u1 of data.ow cells, which enumerate the values of the stream as they ' (u1, \nn/a) . evolve over time. The event loop updates a clock cell to notify the ' (t/a)A let (b, c)= u1 \nin t2 = let (x, y)= u1 in (t/a)A t2 cells in the graph that they may need to recompute themselves, ((t3,t4),B \n. C) . so that each one reads the cells it depends on, doing the minimal (t4/c)C ((t3/b)B ((t/a)A t2)) \n amount of computation needed at each time step. The details of our case (t/a)A u1 of ' implementation \nstrategy are in our earlier paper [17], including a (u1, n/a) . ' correctness proof for the purely functional \nfragment. (t/a)A let F (x)= u1 in t2 = let () = u1 in (t/a)A t2 (F ( e ' ),F (Y )) . In this paper, \nwe content ourselves with a brief informal dis\u00ad(1e ' /y,((t/a)A t2) cussion of how we extended that implementation \nto handle linear G ' 1Y ' types. In our earlier paper, we implemented a family of abstract u when (t/a)A \nu1 = u (t/a)A u1 = t ' 1 when (t/a)A u1 =(t 1 ' ,B) types representing the morphisms of the category \nof ultrametric 11spaces, and then wrote an Ocaml syntax extension which translated (t/a)A a =(t, A) our \nDSL s lambda-calculus into calls to the procedures which called the combinators in question. We extend \nthis implementation strat\u00ad(t/a)A b =(b, n/a) egy continues to the adjoint calculus: now we have two families \nof abstract types, with one each for the nonlinear side and the linear (t/a)A runG(g)=(runG(g), n/a) \n side. let t ' = (t/a)A t2 in We represent the type of windows with widget objects from the case 2 (t/a)A \nu1 of GUI toolkit. As we mentioned in the introduction, we are exploiting (t/a)A u1 t2 = (u ' 1, n/a) \n. (u ' e ' 2, n/a) linearity to double effect. At a low level, we use it to enforce the (1 , (.b. t \n' ,B -C) . t ' /bt ' linear use of widgets in the scene graph, even though the high\u00ad 12B 1 level denotational \nsemantics never mentions state, generativity or mutation at all the semantics of windows is just a pure \nset of Figure 12. Substituting Linear Terms into Linear Terms stream of Pic. We have not yet done a \ncorrectness proof of the implementation, though this is an obvious next step. In our earlier correctness \nproof, we proved the adequacy of our denotational semantics with respect to an imperative implementation, \nby means of a Kripke logical relation which related the state of the data.ow graph to the meaning of \nthe streams in the program. Our implementation was highly imperative to start with, and we expect that \nthe Kripke structure should extend naturally to let us use imperative widget state to model the meanings \nof the widgets. Essentially, since we only ask the equations of the linear lambda calculus to hold, we \nought to be able to realize Window values with mutable state. On the other hand, specifying our contract \nwith the GUI toolkit will be more challenging. The basic issue is to .nd a speci.cation of the behavior \nof the toolkit precise enough to let us prove the correctness of the library, while still being abstract \nenough that we are not forced to verify large parts of the implementation of the underlying toolkit. \nA usable Hoare-style speci.cation for an imperative toolkit API could well be a result of independent \ninterest! It may involve ideas from process calculi, since low-level APIs such as Win32 or GTK are often \ndesigned with logically concurrent and asynchronous abstractions in mind (even though the actual implementations \nare usually sequential). 7. Discussion In our earlier paper [17], we used ultrametric spaces to reinterpret \nthe stream transformers familiar from the semantics of synchronous data.ow. In the special case of functions \nfrom streams to streams, causality and non-expansiveness precisely coincide, but complete ultrametric \nspaces are Cartesian closed, supporting function spaces at all orders, and a general notion of contractiveness \nfor de.ning well-founded .xed points. Metric methods entered semantics in the early 1980s, to simplify \nthe denotational semantics of concurrency [10]. The applications to stream programming were recognized \nearly, but not followed up on: in a surprisingly little-cited 1985 paper [9], de Bakker and Kok proposed \nan ultrametric semantics for a language of .rst-order stream programs over integers and wrote We think \nthere are no problems when we allow functions of higher order[. . . ] . Birkedal et al. [3] have recently \ngiven an ultrametric model of Nakano s [19] calculus for guarded recursion. Nakano s types are very similar \nto ours (though he supports full recursive types), making use of a delay type to guard recursive de.nition. \nHowever, his system includes both subtyping and rules (such as ( )) whose application does not affect \nthe subject term, but which we wished to record for operational reasons. His correctness proof relied \non a logical relation, whereas in this paper we have been able to prove normalization for a language \nincluding the recursion operator .x x : X. e using only ordinary induction as the proof of Banach s \ntheorem hints we ought, since it only uses induction up to . to .nd .xed points. A suggestive paper of \nEscardo s [13] gives a metric model to PCF. He noticed that ultrametric spaces support a version of the \nlift monad from domain theory, and that the extra structure of metrics relative to domains means that \nthe lift monad can be used to interpret timeouts. Since cancels and interrupt operations pervade interactive \nprograms, this suggests a direction of investigation for learning how to support these operations without \ndisturbing the reasoning principles of the language. Recently, Birkedal et al. [4] have given an alternative \nmodel of guarded recursion, based on the topos of trees. Their construction forms a topos, and so many \nof the semantic constructions we performed with metric spaces can be replayed as set-theoretic operations \nwithin the internal language of their topos. In particular, we found the calculations involving powerspaces \nrather dif.cult, and so the possibility of working with ordinary powersets (albeit in a slightly different \nmathematical universe) seems quite attractive. Pouzet and Caspi [5] extended synchronous data.ow program\u00adming \nto higher order with their co-iterative semantics. They il\u00adlustrated how that this generated a Cartesian \nclosed category (of size-preserving functions), which they used to interpret functions. Uustalu and Vene \n[24] subsequently observed that size-preserving functions could be understood more abstractly as the \nco-Kleisli category of streams. However, in both of these works, feedback was handled in a somewhat ad \nhoc fashion. The problem is that these categories contain too few global points (maps S(1) . S(N)) to \ndenote very many streams, including such basic ones such as (1, 2, 3, 6, 24,...).) Still, implicit lifting \nis a very attractive notation for simplifying writing stream programs, and there is an adjunction between \nthe category of ultrametric spaces and the co-Kleisli cate\u00adgory of the stream functor, which would makes \nit easy to return to Ult to take .xed points. The original work on functional reactive programming [12] \nwas based on writing reactive programs as unrestricted stream programs, but due to problems with causality, \nvariations such as arrowized FRP [20] were introduced to give combinators restricting the de.n\u00adable stream \ntransformers to the causal ones. The restriction to arrows is roughly equivalent to .rst-order functional \nprogramming, though Sculthorpe and Nilsson [23] introduced additional combinators to recover higher-order \nand dynamic behavior while using dependent types to retain causality. In contrast, Liu, Cheng and Hudak \n[18] showed how to exploit this .rst-order structure to develop a very ef.cient compilation scheme (reminiscent \nof the Bohm-Jacopini theorem) from arrow programs to single-loop code. A distinctive feature of the original \nFRP work is its focus on continuous time. Though it does not yet do so, we hope our proof framework can \nextend to proving a sampling theorem, as in Wan and Hudak [26]. On the semantic side, we can easily model \ncontinuous behaviors as functions of type R . A, but relating it to an implementation delivering time \ndeltas (instead of ticks, as presently) seems much more challenging. Cooper and Krishnamurthi [7, 8], \ndescribe FrTime, an embed\u00adding of functional reactive programming into the PLT Scheme (now Racket) implementation. \nThey integrate a language with full (i.e., non-commutative) effects, which rules out an adjoint-logic \nstyle as we have done here. However, it might be possible to use Egger et al. s enriched effect calculus \n[11] to support both general effects and strong reasoning principles. References [1] N. Benton. A mixed \nlinear and non-linear logic: Proofs, terms and models. In Computer Science Logic, volume 933 of LNCS, \n1995. [2] P. N. Benton and P. Wadler. Linear logic, monads and the lambda calculus. In LICS, pages 420 \n431, 1996. [3] L. Birkedal, J. Schwinghammer, and K. St\u00f8vring. A metric model of guarded recursion. In \nFICS, 2010. [4] L. Birkedal, R. E. M\u00f8gelberg, J. Schwinghammer, and K. St\u00f8vring. First steps in synthetic \nguarded domain theory: step-indexing in the topos of trees. In LICS, 2011. [5] P. Caspi and M. Pouzet. \nA co-iterative characterization of synchronous stream functions. Electr. Notes Theor. Comput. Sci., 11, \n1998. [6] P. Caspi, D. Pilaud, N. Halbwachs, and J. Plaice. LUSTRE: A declarative language for real-time \nprogramming. In POPL, 1987. [7] G. Cooper. Integrating data.ow evaluation into a practical higher\u00adorder \ncall-by-value language. PhD thesis, Brown University, 2008. [8] G. Cooper and S. Krishnamurthi. Embedding \ndynamic data.ow in a call-by-value language. Programming Languages and Systems, pages 294 308, 2006. \n[9] J. W. de Bakker and J. N. Kok. Towards a uniform topological treatment of streams and functions on \nstreams. In ICALP, 1985.  [10] J. W. de Bakker and J. I. Zucker. Denotational semantics of concurrency. \nIn STOC, pages 153 158. ACM, 1982. [11] J. Egger, R. E. M\u00f8gelberg, and A. Simpson. Enriching an effect \ncalculus with linear types. In E. Gr\u00a8 adel and R. Kahle, editors, CSL, volume 5771 of Lecture Notes in \nComputer Science, pages 240 254. Springer, 2009. ISBN 978-3-642-04026-9. [12] C. Elliott and P. Hudak. \nFunctional reactive animation. In ICFP, 1997. [13] M. Escard\u00b4 o. A metric model of PCF. In Workshop on \nRealizability Semantics and Applications, 1999. [14] M. P. Fiore and G. D. Plotkin. An extension of models \nof axiomatic domain theory to models of synthetic domain theory. In Proceedings of Computer Science Logic \n(CSL), volume 1258 of Lecture Notes in Computer Science. Springer, 1996. [15] E. Gamma, R. Helm, R. Johnson, \nand J. Vlissides. Design patterns: ele\u00adments of reusable object-oriented software. Addison-Wesley Longman \nPublishing Co., Inc. Boston, MA, USA, 1995. [16] A. Kock. Closed categories generated by commutative \nmonads. Journal of the Australian Mathematical Society, 12, 1971. [17] N. Krishnaswami and N. Benton. \nUltrametric semantics of reactive programs. In LICS. IEEE, 2011. [18] H. Liu, E. Cheng, and P. Hudak. \nCausal commutative arrows and their optimization. In ACM International Conference on Functional Programming, \n2009. [19] H. Nakano. A modality for recursion. In LICS, pages 255 266, 2000. [20] H. Nilsson, A. Courtney, \nand J. Peterson. Functional reactive pro\u00adgramming, continued. In ACM Haskell Workshop, page 64. ACM, \n2002. [21] M. Pouzet. Lucid Synchrone, version 3. Tutorial and reference manual. Universit\u00b4 e Paris-Sud, \nLRI, 2006. [22] J. J. M. M. Rutten. Elements of generalized ultrametric domain theory. Theor. Comput. \nSci., 170(1-2):349 381, 1996. [23] N. Sculthorpe and H. Nilsson. Safe functional reactive programming \nthrough dependent types. In ICFP, 2009. [24] T. Uustalu and V. Vene. The essence of data.ow programming. \nIn Central European Functional Programming School, volume 4164 of LNCS, 2006. [25] S. Vickers. Localic \ncompletion of generalized metric spaces II: Powerlocales. Theory and Applications of Categories, 14(15):328 \n356, 2005. ISSN 1201-561X. [26] Z. Wan and P. Hudak. Functional reactive programming from .rst principles. \nIn PLDI, pages 242 252, 2000. [27] K. Watkins, I. Cervesato, F. Pfenning, , and D. Walker. A concurrent \nlogical framework i: Judgments and properties. Technical Report CMU\u00adCS-02-101, Carnegie Mellon University, \n2002.  \n\t\t\t", "proc_id": "2034773", "abstract": "<p>We give a denotational model for graphical user interface (GUI) programming using the Cartesian closed category of ultrametric spaces. The ultrametric structure enforces causality restrictions on reactive systems and allows well-founded recursive definitions by a generalization of guardedness. We capture the arbitrariness of user input (e.g., a user gets to decide the stream of clicks she sends to a program) by making use of the fact that the closed subsets of an ultrametric space themselves form an ultrametric space, allowing us to interpret nondeterminism with a \"powerspace\" monad.</p> <p>Algebras for the powerspace monad yield a model of intuitionistic linear logic, which we exploit in the definition of a mixed linear/non-linear domain-specific language for writing GUI programs. The non-linear part of the language is used for writing reactive stream-processing functions whilst the linear sublanguage naturally captures the generativity and usage constraints on the various linear objects in GUIs, such as the elements of a DOM or scene graph.</p> <p>We have implemented this DSL as an extension to OCaml, and give examples demonstrating that programs in this style can be short and readable.</p>", "authors": [{"name": "Neelakantan R. Krishnaswami", "author_profile_id": "81320491252", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P2801370", "email_address": "neelk@microsoft.com", "orcid_id": ""}, {"name": "Nick Benton", "author_profile_id": "81100165244", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P2801371", "email_address": "nick@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/2034773.2034782", "year": "2011", "article_id": "2034782", "conference": "ICFP", "title": "A semantic model for graphical user interfaces", "url": "http://dl.acm.org/citation.cfm?id=2034782"}