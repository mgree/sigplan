{"article_publication_date": "09-19-2011", "fulltext": "\n An Equivalence-Preserving CPS Translation via Multi-Language Semantics * Amal Ahmed Matthias Blume \nIndiana University Google amal@cs.indiana.edu blume@google.com Abstract Language-based security relies \non the assumption that all poten\u00adtial attacks follow the rules of the language in question. When pro\u00adgrams \nare compiled into a different language, this is true only if the translation process preserves observational \nequivalence. To prove that a translation preserves equivalence, one must show that if two program fragments \ncannot be distinguished by any source context, then their translations cannot be distinguished by any \ntarget context. Informally, target contexts must be no more powerful than source contexts, i.e., for \nevery target context there exists a source context that behaves the same. This seems to amount to being \nable to back-translate arbitrary target terms. However, that is simply not viable for practical compilers \nwhere the target language is lower-level and, thus, contains expressions that have no source equivalent. \nIn this paper, we give a CPS translation from a less expressive source language (STLC) to a more expressive \ntarget language (Sys\u00adtem F) and prove that the translation preserves observational equiv\u00adalence. The \nkey to our equivalence-preserving compilation is the choice of the right type translation: a source type \ns mandates a set of behaviors and we must ensure that its translation s+ mandates semantically equivalent \nbehaviors at the target level. Based on this type translation, we demonstrate how to prove that for every \ntarget term of type s+, there exists an equivalent source term of type s even when sub-terms of the \ntarget term are not necessarily back\u00adtranslatable themselves. A key novelty of our proof, resulting in \na pleasant proof structure, is that it leverages a multi-language se\u00admantics where source and target \nterms may interoperate. Categories and Subject Descriptors D.3.1 [Programming Lan\u00adguages]: Formal De.nitions \nand Theory Semantics General Terms Languages, Reliability, Security, Theory Keywords full abstraction, \nequivalence-preserving compilation, continuation-passing style, multi-language semantics, logical rela\u00adtions, \nback-translation * In electronic versions of this paper, we use blue to typeset our source language and \nred to typeset the target. The paper will be much easier to read if viewed/printed in color. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. 1. Introduction \nAbstraction is a key tool for ensuring the reliability and secu\u00adrity of large, complex systems. We modularize \nsuch systems into components, de.ne interfaces between these components, and let each component s implementation \ndepend only on the interfaces of other components, not their implementation. With the advent of languages \nlike Java and C#, developers increasingly rely on pro\u00adgramming language techniques for enforcing abstraction. \nLanguage-based security relies on an abstraction theorem [40] which effectively states that no user of \na component can observe the difference between two different implementations of that com\u00adponent (i.e., \nthe two implementations are contextually equivalent) if all manifestations of that difference in the \ninterface are masked by an abstract type. If we think of the context as the adversary, the potential \nattacker, it becomes clear that language-based security re\u00adquires that the attacker obey the typing rules \nof the same language. Most programs written in some language S (source) are com\u00adpiled to another language \nT (target) from where they are then exe\u00ad ' cuted. Thus, components eS and eS might be compiled to eT \nand ' eT , which would then interact with a target context CT . But what if there exists some CT that \ncan observe a difference between eT '' and eT , even if eS and eS are contextually equivalent? This is \na question that programmers should care about! It is critical for a programmer writing code in language \nS be able to reason about the properties of her code by thinking in S that is, by only consid\u00adering the \nbehavior of other S components that may interact with her code in a type-safe manner. (In particular, \nto reason about the properties of an S component, she should not have to consider all possible interactions \nwith components written in a different lan\u00adguage, such as the target language T .) This can only be achieved \nif compilation both preserves and re.ects contextual equivalence and is, therefore, fully abstract. If \nthe set of possible contexts in T is restricted to exactly those that can be obtained by translating \nS contexts, then it would be easy to show that no CT can distinguish between code fragments not distinguishable \nby S contexts. However, this is usually not the case. For instance, Microsoft s Common Language Runtime \n(CLR) was speci.cally designed to be the target of compilers for multiple source languages, and most \ntraditional compilers generate machine code that can then be linked with other machine code, possibly \nobtained by compiling code written in other source languages. In these situations, it is possible that \nthe target language contains features that have no source-level equivalent, leading to T contexts that \nare too powerful in the sense that they can make observations that S contexts cannot. In fact, Kennedy \n[26] describes a number of ways in which abstractions were broken in the process of compiling C# to the \nCLR intermediate language. Similar problems with Java have been previously examined by Abadi [1]. ICFP \n11, September 19 21, 2011, Tokyo, Japan. Copyright &#38;#169; 2011 ACM 978-1-4503-0865-6/11/09. . . $10.00 \n c There are three approaches to repairing failures of full abstrac\u00adtion. First, we could add features \nto the source language so that every target-level observation has a source-level counterpart. But this \nis hardly a desirable solution as it amounts to weakening the abstraction facilities of the source language. \nSecond, we could re\u00admove features from the target language until it becomes, in some sense, merely an \nalternative notation for source programs, thereby guaranteeing that the only expressible target contexts \ntrivially cor\u00adrespond to source contexts. This might work in some specialized situations, but it does \nnot apply to foreign-function interfaces, plu\u00adgin architectures, or multi-language frameworks such as \n.NET. (As we discuss in Section 9, much of the existing work on proving full abstraction resorts to one \nof these two approaches.) The third approach is to change the translation. Speci.cally, we advocate engineering \nthe translation so that it uses target-level ab\u00adstraction facilities in a clever enough fashion so that \nwell-typed target contexts have no choice but to respect the original abstrac\u00adtions. Put another way, \ninstead of removing features from the target language, engineer the type translation to use types at \nthe target level to restrict the set of contexts that a compiled source compo\u00adnent can interact (or be \nlinked) with. Of course, this assumes the presence of a rich enough type system at the target language. \nFor\u00adtunately, JVM bytecode, the CLR, and Typed Assembly Language (TAL) [36] may already provide most \nof the necessary features. Assuming that the translation can be engineered in this way, it is still not \nclear how to prove that the result really is fully abstract. Full abstraction for a full-.edged C#-to-CLR \nis currently too hard a problem to tackle. A nontrivial .rst step would be to attempt full abstraction \nfor a more idealized compiler such as that from System F to TAL [36] (which was mentioned in that paper \nas future work). In prior work [4], we proved that typed closure conversion as de.ned by Morrisett et \nal. [36] is fully abstract. For typed closure conversion the key target language feature required was \nexistential types, while the particular way the translation assigns existential types to closure records \nis what makes full abstraction work. An interesting aspect of our earlier proof which, unfortu\u00adnately, \nsigni.cantly limits the situations where that proof strategy may be used is that it takes advantage of \na setup where source lan\u00adguage S and target language T are the same language. Of course, source and target \nlanguages are rarely the same in practice, but we argued there that as long as the real target language \nis less ex\u00adpressive than the source language (i.e., if the compiler compiles away certain high-level \nsource features), there is no loss of gen\u00aderality. Simply speaking, if contexts in the more expressive \ntarget language T (where T = S) cannot distinguish between two tar\u00adget language expressions, then contexts \nin the less expressive real target language cannot make the distinction either. Thus, our earlier proof \nmethodology suf.ces when the source language is at least as expressive as the target, but not when the \nlatter is more expressive. However, there are usually some features in typical target lan\u00adguages that \nhave no source equivalent. A common example for this is control: low-level languages tend to have explicit \nrepresentations of the program counter and the program s control stack. In this set\u00adting the assumption \nof having equally powerful source and target languages does not work. To prove full abstraction when \nit holds, a different proof technique is required. In this paper we investigate the full abstraction \nproblem for CPS translation from a less expressive source language to a more ex\u00adpressive target language. \nSince CPS conversion makes continua\u00adtions explicit, it represents the above-mentioned situation of a \ntarget language with explicit control. Next, we show that the standard typed CPS translation is not fully \nabstract, after which we discuss the speci.c contributions of this paper. Standard CPS Conversion is \nNot Fully Abstract As we have discussed, full abstraction is at least as much a property of the translation \nas it is one of the target language. Therefore, a particular translation scheme can fail to be fully \nabstract even if the source\u00adand target languages are identical. Consider the simply-typed .\u00adcalculus. \nIn this setting, it is easy to see that the following two terms A and B are contextually equivalent: \nA = .(f : int . int,g : int . int).(f 0; g 0; 0) B = .(f : int . int,g : int . int).(g 0; f 0; 0). When \napplied to concrete arguments, the results of calling f and g are ignored in either case, and the overall \nanswer is always 0. Now consider A ' and B ', which are the results of translating A and B using the \nstandard typed CPS-conversion approach (see, e.g., [20]) which makes use of a global abstract answer \ntype ans. (We omit the type annotation int \u00d7 (int . ans) . ans on f, g): A ' = .(f, g, k : int . ans).f(0,. \n.g(0,. .k 0)) B ' = .(f, g, k : int . ans).g(0,. .f(0,. .k 0)) The following context C distinguishes \nbetween A ' and B ' : C = .k. [\u00b7](.( , ).k 1,.( , ).k 2,k) Substituting A ' for the hole applies k to \n1, while plugging in B ' applies k to 2. The problem is that the values given for f and g take advantage \nof the explicit representation of continuations. They do something that our non-CPS functions cannot \ndo: they ignore their own continuation and directly invoke a different one, thereby exposing the previously \ninvisible difference in evaluation order within the bodies of A and B. Thus, this particular CPS-translation \nis not fully abstract. The difference could be observed by source contexts if we added more powerful \ncontrol operators to our source language, such as call/cc or even just exceptions. But we want a fully \nab\u00adstract translation without enriching the source language and weak\u00adening its abstractions to make more \nobservations possible. The key idea is to take advantage of the target language type system in such a \nway that it rules out any target contexts that could make observa\u00adtions that are not possible at the \nsource. One option, that has been studied extensively (e.g., Berdine et al. [10, 11]), is to ascribe \nlin\u00adear types to continuations thus ensuring that they are used exactly once. As we will explain, in \nthis paper, we eschew adding linear (or af.ne) types to the target and instead use polymorphism. Contributions \nOur source language .S is the simply typed .\u00adcalculus, while our target calculus .T is System F. (Section \n3). We prove full abstraction for a CPS translation where each com\u00adputation term is locally polymorphic \nin its answer type (Section 4). This translation has been studied before [48], but we are unaware of \nany work on proving it fully abstract. Although our target type sys\u00adtem itself is not substructural, \nthe locally polymorphic answer type is suf.cient to enforce that continuations be used at least once \nthat is, continuations must be relevant in the terminology of sub\u00adstructural logics. Intuitively, enforcing \nrelevance of continuations suf.ces in our setting because in a purely functional, terminating language \nsuch as .T it is impossible to distinguish between a sin\u00adgle use and multiple uses of a continuation. \nOur proof of full abstraction uses elementary operational tech\u00adniques; there is no use of sophisticated \nmachinery such as domain theory or game semantics. While the proof technique we used in prior work [4] \nrelied on the source and target language being iden\u00adtical, our current proof technique works even if \nthe two languages are different. To illustrate this point, we have picked a target (Sys\u00adtem F) that is \nmore expressive than the source (STLC) e.g., we can encode arithmetic operations in System F but not \nin STLC. In addition, like Morrisett et al. s CPS target language [36], our .T requires terms to be in \nCPS form (in the spirit of compilers like SML/NJ [7, 45], Rabbit [47], Orbit [28], and more recently, \nKennedy s SML.NET compiler [27], though our syntax is not as re\u00adstrictive, e.g., we do not distinguish \nfunctions from continuations.) Thus, neither language is a sub-language of the other. An inter\u00adesting \naspect of our proof technique is that it draws upon work on language interoperability. We de.ne a combined \nlanguage .ST that incorporates both .S , .T, and has two new boundary forms that let us interface terms \nof one language with the other (Section 5). This setup allows us to neatly decompose our proof into three \nparts (Sec\u00adtion 6). We discuss the addition of recursion to both the source and target in Section 8 but \nthe details are beyond the scope of this paper. We have elided most proofs here. Detailed proofs may \nbe found in the online technical appendix [5]. 2. Main Ideas Multi-language scenario and interoperability. \nConsider two source terms eS and e ' and their corresponding translation terms S eT and eT ' . To show \nfull abstraction we need to establish equiva\u00adlence re.ection and equivalence preservation. Re.ection \nis closely related to compiler correctness in the sense that we deem the translation fundamentally broken \nif non-equivalent source terms translate to equivalent target terms. The hard part of the proof, however, \nis to establish preservation: terms that are equivalent at source level should translate to equivalent \ntarget terms. A natural way of proving equivalence preservation is to take an indirect approach: assume \nthat eT and eT ' are not equivalent and derive a contradiction. If eT and eT ' are not contextually equivalent, \nthere has to be a target context CT that exposes the difference: CT [eT ] evaluates to trueT while CT \n[eT ' ] evaluates to falseT . The idea is to show the existence of a source context CS such that CS[eS \n] evaluates to trueS while CS [eS' ] evaluates to falseS. In our previous work [4] we were able to construct \nCS directly from CT with the help of wrapper terms. This technique does not apply directly to the current \nsetting of mutually incompatible source-and target languages. However, it is possible to apply the technique \nat least in an intuitive sense if we take a page out of the work on interoperabil\u00adity [31] and de.ne \na combined language in which S-and T -terms can interoperate in a controlled way. The discriminating \ntarget con\u00adtext CT gives rise to a discriminating context CST for eS and e ' S . What remains to be done \nnow is to show that CST can be converted to a context CS that is equally discriminating. Relevant continuations \nvia parametricity. Our version of typed CPS-conversion differs from the standard account that uses a \nsin\u00adgle, globally abstract answer type. Our answer type is individually abstract at each point where \na continuation argument appears. In essence, each computation term of type (t . ans) . ans be\u00adcomes .a. \n(t . a) . a. The polymorphic type variable a replaces the single answer type ans. As a result, the computation \nhas less freedom in how it can use its continuation. In particular, to produce its own answer of type \na, it has no choice but to invoke its own continuation (which ensures that the continuation is used at \nleast once). It turns out that this typing of CPS code prevents any bad target terms (for example those \nwhose source equivalent is a variant of call/cc) from being well typed. The technical un\u00adderpinnings \nof this intuition is a free theorem [50] that applies to computation terms that are polymorphic in their \nanswer type. Back-translation. The remaining hurdle is to show that CPS\u00adtyped target contexts can be \nback-translated to corresponding source contexts. The dif.culty lies in the fact that the type only governs \nthe interface of a term without preventing the presence of arbitrary subterms, so for a term to have \ntranslation type does not immediately imply that it can be back-translated. However, as we will show, \nwe are always able to eliminate occurrences of inconve\u00adnient subterms by partially reducing them. For \ninstance, whenever Types s ::= bool | s1. s2 Values v ::= x | true | false | .x : s. e Terms e ::= v \n| if e then e1 else e2 | e1 e2 Eval. Contexts E ::= [\u00b7]S | if E then e1 else e2 | E e | v E ' e -. e \n if true then e1 else e2 -. e1 if false then e1 else e2 -. e2 (.x : s. e) v -. e[v/x] ' e -. e E[e] -. \nE[e ' ] Figure 1. .S: Syntax and Dynamic Semantics we have a term of the form v[t]v1 application of a \npolymor\u00adphic function v to type t and then to an argument v1 of transla\u00adtion type s+, either v will have \na translation type (s1. s2)+ (and therefore can be related to a source term of type s1. s2), or it will \nbe a lambda term that can be applied to t and v1, yielding a term e of type s+. The latter term can now \nbe back-translated. This is well-founded because the result term is smaller in that it will re\u00adduce to \na value in fewer steps. The metric for well-foundedness of our back-translation relation is a combination \nof length of reduction sequence, structure of the type of the term being back\u00adtranslated, and the structure \nof the expression. We explain the de\u00adtails in Section 6.2. 3. The Source and Target Languages We typeset \nthe terms, types, and contexts of our source language .S using a blue sans-serif font, and those of our \ntarget language .T using a bold red font with serifs. 3.1 The Source Language (.S) .S Our source language \nis the call-by-value simply-typed .\u00adcalculus with booleans. The syntax and dynamic semantics of .S are \nshown in Figure 1. We de.ne a small-step operational semantics for .S, using evaluation contexts E to \nlift the primitive reductions to a standard left-to-right call-by-value semantics for the language. .S \ntyping judgments have the form G f e : s, where the value environment G tracks the set of free term variables \nin scope, along with their types. The typing rules are entirely standard so we omit them here. (They \nappear later as part of Figure 3 when we de.ne the CPS translation by induction on the structure of G \nf e : s.) .S Contextual Equivalence A .S context C is an expression with a single hole [\u00b7]S in it. Typing \njudgments for contexts have the form f C : (G f s) . (G ' f s ' ), where (G f s) indicates the type of \nthe hole. Essentially, this judgment says that if e is an expression such that G f e : s, then G ' f \nC[e]: s '. The typing rule for a hole is as follows: G . G ' f [\u00b7]S : (G f s) . (G ' f s) The other rules \nare straightforward (see our online appendix [5]). ;ctx We de.ne contextual approximation (G f e1S e2 \n: s) to mean that, for any well-typed program context C with a hole of the type of e1 and e2, and result \ntype bool, if C[e1] evaluates to the boolean value v then so does C[e2]. Contextual equivalence ctx (G \nf e1S e2 : s) is then de.ned as contextual approximation in both directions. Let G f e1 : s and G f \ne2 : s. def G f e1 ctx e2 : s = S .C, v1. f C : (G f s) . (\u00b7f bool) . C[e1] . v1 =. .v2. C[e2] . v2 . \nv1 = v2 def G f e1 ctx G f e1 ctx e2 : s . G f e2 ctx e2 : s = e1 : s S SS .S CIU equivalence Note that \nevaluation contexts E (Figure 1) are a subset of general contexts C. Since only closed terms can be placed \nin an evaluation context, the type of the hole always has the form \u00b7f s. We de.ne the notion of ciu-equivalence \n(uses of closed instantia\u00adtions, .rst introduced by Mason and Talcott [30]) and show that it is a consequence \nof contextual equivalence. Two closed terms of type s are ciu-equivalent if, in any evaluation context \nE with hole type s and result type bool, they evaluate to the same value. This no\u00adtion is often easier \nto work with than contextual equivalence since it cuts down on the number of contexts under consideration. \nThe notion is extended to open terms by closing the terms with a value substitution . that maps variables \nx to values v; we write f . :G when dom(.) = dom(G) and for all x . dom(G), f .(x) : G(x). De.nition \n3.2 (.S CIU Approximation &#38; Equivalence) Let G f e1 : s and G f e2 : s. G f e1 ciu S .E, ., v1. G \nf e1 ciu S def e2 : s = f E :(\u00b7f s) . (\u00b7f bool) .f . :G . E[.(e1)] . v1 =. .v2. E[.(e2)] . v2 . v1 = \nv2 def G f e1 ciu e2 : s . G f e2 ciu e2 : s = SS e1 : s Lemma 3.3 (.S: Contextual Approx Implies CIU \nApprox) If G f e1 ;ctx e2 : s then G f e1 ;ciu e2 : s. S S  3.2 The Target Language (.T) .T booleans \nand pairs. The .T syntax and dynamic semantics are given in Figure 2 (top). Following Morrisett et al. \n[36], our CPS target language syntactically enforces continuation-passing style. .T code is nearly linear \nconsisting of a series of let bindings fol\u00adlowed by a function call with the exception of the if construct \nwhich forms a tree containing two subexpressions. Also following Morrisett et al., we combine the types \n. and . into . [a].t1. t2 and have only one abstraction mechanism (.) which binds both type and term \nvariables. Finally, we have pairs in .T so we can ex\u00adpress CPS conversion without the need to introduce \nmore curried functions. We de.ne a small-step, call-by-value operational semantics. Notice that evaluation \ncontexts in .T are redundant since the syn\u00adtactic restriction to CPS results in a unique order of evaluation; \nwe introduce them primarily to permit a more uniform treatment of .S and .T when they are incorporated \ninto the multi-language seman\u00adtics in Section 5. .T typing judgments have the form .; G f e : t, where \nthe environments . and G are de.ned in Figure 2. The type environ\u00adment . tracks the type variables in \nscope. The value environment G tracks the term variables in scope along with their types t which must \nbe well formed in environment . (written . f t and de.ned as ftv(t) . ., where ftv(t) denotes the set \nof type variables that appear free in type t). The typing rules are standard, so we only show a few rules \nin Figure 2 (middle). Our CPS target language is call-by-value System F with Syntactic Sugar We abbreviate \n. [a].t1. t2 as t1. t2 when a ./(ftv(t1) . ftv(t2)); we similarly abbreviate . [a] (x : t1). e to .(x \n: t1). e, when a does not appear free in t1 or e; and we abbreviate v[t]v1 to vv1 when v has type t1. \nt2. We also use De.nition 3.1 (.S Contextual Approximation &#38; Equivalence) Types t ::= bool | t1 \n\u00d7 t2 | a | . [a].t1.t2 Values v ::= x | true | false | (v1, v2) | . [a] (x : t). e Terms e ::= v | if \nv then e1 else e2 | let x = piv in e | v1 [t] v2 Eval. Ctxts E ::= [\u00b7]T ' e -. e if true then e1 else \ne2if false then e1 else e2let x = pi(v1, v2) in e(. [a] (x : t1). e) [t]v -. e1 -. e2 -. e[vi/x] -. e[t/a][v/x] \n' e -. e E[e] -. E[e ' ] Type Environments . ::= \u00b7| ., a Value Environments G ::= \u00b7| G, x : t .; G f \ne : t x : t . G .;G f v1 : t1 .; G f v2 : t2 ... .; G f x : t .; G f (v1, v2) : t1 \u00d7 t2 .; G f v : t1 \n\u00d7 t2 .; G, x : ti f e : t .; G f let x = piv in e : t ., a;G, x : t1 f e : t2 .; G f . [a] (x : t1). \ne : . [a].t1. t2 .; G f v1 : . [a].t2. t . f t' .; G f v2 : t2[t'/a] .; G f v1 [t']v2 : t[t'/a] Value \nContexts Cv ::= [\u00b7]v | (Cv , v2) | (v1, Cv) | . [a] (x : t). C T Contexts C ::= [\u00b7]T | Cv | if Cv then \ne1 else e2 |if ethenCelsee2 | if ethene1 else C |let x = piCv in e | let x = piv in C |Cv [t]v2 | v1 \n[t]Cv Figure 2. .T: Syntax, Dynamic + Static Semantics, Contexts the following shorthand (and in the \n.rst three cases below, we have analogous shorthand for .S): .x. e = .(x : t). e ; t inferred from context \nlet x = v in e =(.x. e) v id = .x. x let (x1, x2) = z in e = let x1 = p1z in (let x2 = p2z in e) . [a] \n((x1, x2): t1 \u00d7t2). e = . [a] (z : t1 \u00d7 t2). let (x1, x2) = z in e .T Contextual Equivalence and CIU \nEquivalence The syntax of .T contexts is given at the bottom of Figure 2. A .T context C is an expression \nwith a single hole in it, but the hole may be either of the form [\u00b7]v T, a hole that expects a value, \nor of the form [\u00b7]T, a hole that expects any term. We write Cv (respectively, C) for a context that once \n.lled, regardless of the kind of hole in it, yields a value (respectively, a term). Typing rules for \n.T contexts are analogous to those for .S contexts, except that typing judgments have the form f C : \n(.; G f t) . (. ' ;G ' f t'). Hence, if e is a term such that .; G f e : t, then . ' ;G ' f C[e]: t'. \nThe typing rules for holes [\u00b7]v T and [\u00b7]T are identical so we show just one: . . . ' G . G ' f [\u00b7]v \n'' T : (.; G f t) . (. ;G f t) The remaining rules are straightforward (see online appendix [5]). The \nde.nition of contextual approximation and equivalence for .T are analogous to those for .S, except that \nwe now also have to account for the environment .. Also, we must make sure that the terms C[e1] and C[e2] \nare syntactically well formed .T terms. The extra checks are needed because the hole in a context C may \nbe of the form [\u00b7]T or [\u00b7]v T. If it s of the form [\u00b7]T, then any well-typed term e may be placed in \nC. However, if it s of the form [\u00b7]v , then T C[e] will not be a well-formed term unless e is a value. \nDe.nition 3.4 (.T Contextual Approximation &#38; Equivalence) Let .; G f e1 : t and .; G f e2 : t. def \nctx .; G f e1T e2 : t = .C, v1. f C : (.; G f t) . (\u00b7; \u00b7f bool) .\u00b7; \u00b7f C[e1]: bool . \u00b7; \u00b7f C[e2]: bool \n. C[e1] . v1 =. .v2. C[e2] . v2 . v1 = v2 def ctx ctx .; G f e1 ctx e2 : t = .;G f e1 e2 : t . .; G f \ne2 e1 : t T TT .T evaluation contexts are essentially degenerate. Nonetheless we de.ne ciu-equivalence \nfor .T since the notion will later be more convenient to work with than contextual equivalence. As before, \nclosed terms of closed type t are ciu-equivalent if, in any evaluation context E with hole type t and \nresult type bool, they evaluate to the same value. The notion is extended to open terms by closing the \ntype t and the terms with substitutions d and .. The type substitution d is a .nite map from type variables \na to closed types t; we write d |=. whenever dom(d)=.. The value substitution . now maps variables x \nto values v and f . :G means that . maps variables to values that are well-typed according to G. De.nition \n3.5 (.T CIU Approximation &#38; Equivalence) Let .; G f e1 : t and .; G f e2 : t. def .; G f e1 ciu e2 \n: t = T .E, d, ., v1. f E :(\u00b7; \u00b7f d(t)) . (\u00b7; \u00b7f bool) . d |=. .f . : d(G) . E[d(.(e1))] . v1 =. .v2. \nE[d(.(e2))] . v2 . v1 = v2 def ciu ciu .; G f e1 ciu e2 : t = .;G f e1 e2 : t . .; G f e2 e1 : t T TT \nLemma 3.6 (.T: Contextual Approx Implies CIU Approx) If .; G f e1 ;ctx e2 : t then .; G f e1 ;ciu e2 \n: t. T T 4. Typed CPS Translation CPS translation maps source values of type s to target values of type \ns+. The type translation is given in Figure 3 (top). As mentioned earlier, our version of typed CPS-conversion \ndif\u00adfers from the standard account. Instead of using a single, globally abstract answer type, we make \nthe answer type individually abstract at each point where a continuation argument appears. As shown in \nFigure 3 (top left), each function of type s1. s2 acquires a type parameter a and an additional term \nparameter of type s2+. a representing the continuation. The polymorphic type variable a acts as the answer \ntype. The consequence of this is that a function of CPS type has less freedom in how it can use continuations. \nIn particular, to produce its own answer of type a, it has no choice but to invoke its own continuation. \nOf course, the function can invoke its continuation multiple times, but in a purely functional setting \nit is impossible to tell the difference between one use of the contin\u00aduation and multiple uses. As discussed \nearlier, this typing of CPS code prevents any bad target terms from being well typed. The polymorphic \ntype of each continuation lets us take advantage of a free theorem [50] that captures the above intuitions \nand plays a key role in our proof; see discussion of Lemma 6.10 in Section 6.3. Figure 3 (bottom) shows \nthe rules for CPS translation in combi\u00adnation with declarative typing rules for the source language .S. \nTo this end, the typing judgment G f e : s is extended to a translation judgment G f e : s r v, where \nv describes a CPS computa\u00adtion of type . [a].(s+. a). a (which we abbreviate as s\u00f7). A computation is \na suspended term awaiting its continuation. It is polymorphic in the answer type of the continuation \nand, like func- Types . ::= s | t Terms e ::= . . . | sST e e ::= . . . | let x = (TS s e) in e e ::= \ne | e Values v ::= v | v Eval. Contexts E ::= . . . | sST E E ::= . . . | let x = (TS s E) in e E ::= \nE | E ' e -. e boolST true -. true boolST false -. false s1. s2 ST v -. .x : s1. s2 ST (let z = (TS \ns1 x) in (v [s2 +] (z, id))) let y =(TS bool true) in e -. e[true/y] let y =(TS bool false) in e -. \ne[false/y] let y =(TS s1. s2 v) in e -. e[v/y] where v = . [a] ((x, k) : s1+ \u00d7(s2+. a)). let z =(TS s2 \n(v (s1 ST x))) in k z ' e -. e E[e] -. E[e ' ] Type Environments . ::= \u00b7| ., a Value Environments G ::= \n\u00b7| G, x : s | G, x : t .; G f e : . .; G f e : s+ .; G f e : s .; G, x : s+ f e : t ... .; G f sST e \n: s .; G f let x =(TS s e) in e : t Contexts C ::= ... | sST C C ::= ... | let x =(TS s C) in e | let \nx =(TS s e) in C C ::= C | C Figure 4. .ST: Syntax, Dynamic + Static Semantics, Contexts tions, it will \nbe forced to invoke its own continuation to produce its answer of type a. Note that for v to have the \ntype s\u00f7, it has to be considered under the translated environment G+ (de.ned in Figure 3, top right). \nTherefore, notice that variables x in the source term are replaced by variables x in the target term. \nFor instance, in the variable translation rule, the source variable x changes to x in the target. Also, \nin the function rule, note that v in the premise may contain a free occurrence of x : s1+. This x is \ncaptured in the conclusion by a binding occurrence of x. We could parametrize our translation with a \nmapping from source variables to target variables and use that to perform renaming. To avoid this unnecessary \ncomplication, we work with a .xed a-priori mapping and adopt the convention that for each x, y, z, etc., \nthere exists a unique x, y, z, respectively, that we can use in the translated term. The rules are designed \nwith clarity, not optimality, in mind. A translation term v will usually contain many administrative \nredexes that can easily be eliminated with subsequent optimization. 5. Multi-Language Semantics In this \nsection, we present the language .ST designed for interop\u00aderability of terms from the source and target \nlanguages .S and .T and give a de.nition of contextual equivalence (written ctx ST ) for the language. \nThe .ST multi-language system, presented in Figure 4, embeds the source and target languages .S and .T \nso that both languages have natural access to foreign values (i.e., values from the other s+ (bool)+ \n= bool (s1. s2)+ = . [a].(s1+ \u00d7 (s2+. a)).a G+ (\u00b7)+ = \u00b7 (G, x : s)+ =G+ , x : s+ G f e : s v where \u00b7 \n;G+ f v : s\u00f7 and we de.ne s\u00f7 = . [a].(s+. a). a G f true : bool . [a] (k : bool+. a). k true G f false \n: bool . [a] (k : bool+. a). k false G f e : bool v G f e1 : s v1 G f e2 : s v2 G f if ethene1 else e2 \n: s . [a] (k : s+. a). v[a] (.(x : bool). if x then (v1 [a]k) else (v2 [a]k)) x : s . GG, x : s1 f e \n: s2 v + G f x : s . [a] (k : s+. a). kx G f .x : s1. e : s1. s2 . [a] (k : (s1. s2)+. a). k (. [\u00df] \n((x, k ' ): s1 \u00d7 (s2+. \u00df)). (v[\u00df]k ' )) G f e1 : s2. s v1 G f e2 : s2 v2 G f e1 e2 : s . [a] (k : s+. \na). v1 [a] (.(x1 : (s2. s)+). v2 [a] (.(x2 : s2+). x1 [a] (x2, k))) Figure 3. CPS: Type and Environment \nTranslation (top); Term Translation (bottom) language). They receive foreign boolean values as native \nvalues, and can call foreign functions as native functions. The design is in\u00adspired by Matthews and Findler \ns multi-language system for (pared down) ML and Scheme [31], but crafted with the CPS translation in \nmind. To the original core languages, we add new syntax, evaluation contexts, and reduction rules that \nde.ne syntactic boundaries, writ\u00adten sST and TS s to allow cross-language communication. The term sST \ne (target inside, source outside) allows a term e of tar\u00adget type s+ to be used as a term of source type \ns, while TS s e (source inside, target outside) allows a term of source type s to be used as a term of \ntarget type s+. Since code in our CPS target lan\u00adguage is (nearly) linear, we let-bind TS s e instead \nof simply adding TS s e to the grammar for terms. (Here, we do not require e to be a value since, informally, \ne lives on the source side of the boundary and the source language does not mandate the linear code structure \nof the target.) In the interest of brevity, we will often abbreviate let z =(TS s e) in C[z] to just \nC[TS s e] even if C requires a value. We de.ne reduction rules for boundaries annotated bool that convert \nboolean values from one language to the other. To convert functions across languages, we use native proxy \nfunctions. We represent a target function v in the source at type s1. s2 by a new function that takes \nan argument of type s1, converts it to its equivalent in the target, passes that and the identity continuation \nas an argument to the original target function v (instantiated with the result type s2+), and converts \nthe result back to source at type s2. Converting source functions to target functions is a little more \ninvolved. We represent a source function v in the target at type (s1. s2)+ by a new function that takes \ntype parameter a, an argument x : s1+ and a continuation k : s2+. a, converts the argument x to its equivalent \nin the source, passes that to the original source function v, converts the result back to target at type \ns2+, and .nally passes that to the continuation k. In both cases, notice that the direction of the conversion \n(and the boundary used) reverses for function arguments. Typing judgments for .ST have the form .; G \nf e : ., where the environments . and G are de.ned in Figure 4. Note that the environment G now tracks \nboth source variables of type s and target variables of type t. The typing rules include all the .S typing \nrules, but augmented with the additional environment .; all the .T typing rules, unchanged; and rules \nfor the two boundary constructs, shown in Figure 4. .ST Contextual Equivalence and CIU Equivalence The \ngram\u00admar for contexts from .S and .T is augmented to de.ne .ST con\u00adtexts as shown in Figure 4 (bottom). \nThe typing rules for contexts are straightforward (see online appendix [5]), largely following the ideas \ndiscussed before for .T. The de.nition of contextual equiv\u00adalence for .ST is similar to that for .T and \nis given below. In the de.nition below, we could equivalently have chosen the context C s result type \nto be bool instead of bool. As is usually the case for contextual equivalence in a terminating language, \nany base type of the language would suf.ce. De.nition 5.1 (Contextual Approximation &#38; Equivalence) \nLet .; G f e1 : . and .; G f e2 : .. def ctx .; G f e1 ST e2 : . = .C, v1. f C : (.; G f .) . (\u00b7; \u00b7f \nbool) .\u00b7; \u00b7f C[e1]: bool . \u00b7; \u00b7f C[e2]: bool . C[e1] . v1 =. .v2.C[e2] . v2 . v1 = v2 def ctx ctx .; \nG f e1 ctx = .;G f e1 ST e2 : . . .; G f e2 ST e2 : . ST e1 : . We de.ne ciu-equivalence for .ST below. \nIt is analogous to the de.nition of ciu-equivalence for .T. As before, the substitution d maps type variables \na to closed types t. The substitution . now maps both source variables (to values v) and target variables \n(to values v) in G. De.nition 5.2 (.ST CIU Approximation &#38; Equivalence) Let .; G f e1 : . and .; \nG f e2 : .. def ciu .; G f e1 = ST e2 : . .E, d, ., v1. f E :(\u00b7; \u00b7f d(.)) . (\u00b7; \u00b7f bool) . d |=. .f . \n: d(G) . E[d(.(e1))] . v1 =. .v2.E[d(.(e2))] . v2 . v1 = v2 def .; G f e1 ciu = ciu ciu e2 : . .; G \nf e1 e2 : . . .; G f e2 e1 : . ST STST Lemma 5.3 (.ST: Contextual Approx Implies CIU Approx) If .; G \nf e1 ;ctx ST e2 : .. ST e2 : . then .; G f e1 ;ciu 6. Equivalence Preservation Having de.ned .ST for \nsource-language interoperability, the proof of equivalence preservation can be decomposed into three \nparts: 1. if G f e1 ctx S ST e2 : s (Section 6.2); e2 : s then G f e1 ctx ctx ctx 2. if G f e1 ST e2 \n: s then \u00b7;G+ f v1 ST v2 : s\u00f7, where G f e1 : s r v1 and G f e2 : s r v2 (Section 6.3); and  Atom[.1,.2]= \n{ (e1,e2) |\u00b7; \u00b7f e1 : .1 .\u00b7; \u00b7f e2 : .2 } Rel[t1, t2]= { R . P(Atomval[t1, t2]) |.(v1,v2) . R. ' ciu \n'' .v2.v2 v : t2 =. (v1,v ) . R } ST2 2 Shorthand: Atom[.]. = Atom[.1(.),.2(.)] V [bool] . = { (v, v) \n. Atom[bool]. | v = true . v = false } V [s. s '] . = { (.x : s. e1,.x : s. e2) . Atom[s. s ' ]. |.(v1, \nv2) .V [s] .. (e1[v1/x], e2[v2/x]) .E [s '] . } V [a] . = R where .(a)=(t1, t2,R) V [bool] . = { (v, \nv) . Atom[bool]. | v = true . v = false } ' V [t \u00d7 t '] . = { ((v1, v1 ' ), (v2, v2 )) . Atom[t \u00d7t ' \n]. | ' (v1, v2) .V [t] . . (v1 , v2 ' ) .V [t '] . } V [. [a].t. t '] . = { (. [a] (x : .1(t)). e1, . \n[a] (x : .2(t)). e2) . Atom[. [a].t.t ' ]. |.t1, t2,R . Rel[t1, t2]. .(v1, v2) .V [t] .[a . (t1, t2,R)]. \n(e1[t1/a][v1/x], e2[t2/a][v2/x]) .E [t '] .[a . (t1, t2,R)] } E [.] . = { (e1,e2) . Atom[.]. |.v1.e1 \n-.* v1 =. .v2.e2 -.* v2 . (v1,v2) .V [.] . } D [\u00b7] = {\u00d8} D [., a] = { .[a . (t1, t2,R)] | . .D [.] . \nR . Rel[t1, t2] } G [\u00b7] . = { (\u00d8, \u00d8) } G [G,x : .] . = { (.1[x . v1],.2[x . v2]) | (.1,.2) .G [G] . . \n(v1,v2) .V [.] . } log def .; G f e1 ST e2 : . = .;G f e1 : . . .; G f e2 : . . .., .1,.2.. .D [.] . \n(.1,.2) .G [G] . =. (.1(.1(e1)),.2(.2(e2))) .E [.] . log def log log .; G f e1 ST e2 : . = .;G f e1 ST \ne2 : . . .; G f e2 ST e1 : . Figure 5. Combined Language (.ST): Logical Relation ctx ctx 3. if \u00b7;G+ f \nv1 ST v2 : s\u00f7 then \u00b7;G+ f v1T v2 : s\u00f7 (Section 6.4). We shall see that parts (1) and (2) are the nontrivial \nparts of the proof. Informally, part (1) says that embedding .S into .ST pre\u00adserves .S equivalences, \nwhile part (2) says that the translation pre\u00adserves equivalences within .ST. Once we have proved (1), \n(2), and (3), our main result is immediate: Theorem 6.1 (CPS Translation is Equivalence Preserving) If \nG f e1 : s r v1, G f e2 : s r v2, and G f e1 ctx S e2 : s, then \u00b7;G+ f v1 ctx v2 : s\u00f7 . T We start in \nSection 6.1 by setting up some machinery for our proof. We de.ne a logical relation for .ST and prove \nthat it coin\u00adcides with contextual equivalence. Proving contextual equivalence directly can be hard or \neven intractable due to the quanti.cation over all contexts C in the de.nition of ctx ST . The logical \nrelation provides us with a convenient method for carrying out proofs of contextual equivalence. Next, \nin Sections 6.2-6.4, we present the three parts of the proof. 6.1 Logical Relation for .ST and Two Key \nLemmas The basic idea of logical relations is to de.ne an equivalence (or approximation) relation on \nprogram terms by induction on the structure of their types. For instance, we would say that two functions \nare logically related at the type s1. s2 iff, when applied to arguments that are logically related at \ns1, they yield results that are logically related at s2. To take the example of product types, we would \nsay that two pairs are logically related at the type t1 \u00d7 t2 iff their .rst and second components are \npairwise related at the types t1 and t2, respectively. Figure 5 presents the de.nition of the logical \nrelation for .ST . The big picture is that we de.ne a relation V [.] that relates closed values at type \n. and a relation E [.] that relates closed terms at type ., and then generalize the de.nition of relatedness \nto open ;log terms (written .; G f e1 ST e2 : .). So far these relations de.ne logical approximation \nand are intended to capture the notion of contextual approximation; we de.ne logical equivalence (written \n.; G f e1 log ST e2 : .) as logical approximation in both directions. In more detail, the value relation \nV [.] is parametrized by a parameter . that provides relational interpretations R for the free type variables \nin .. We must make sure that these relations R satisfy certain requirements (enforced by requiring that \nR belong to Rel[t1, t2], which we explain momentarily). The .rst requirement is that R should relate \nonly well-typed closed values. To this end, we .rst de.ne Atom[.1,.2] to be the set of all pairs of well-typed \nclosed terms e1 and e2 of types .1 and .2, respectively. We write Atomval to restrict the above set to \npairs of values. The second requirement is that R must be equivalence-respecting. The latter means that \nR must be closed under equivalence (or more precisely under approximation): if (v1,v2) . R (where v2 \n: t2) and v2 ;ciu ST v2 ' : t2, then (v1,v 2' ) . R. Both of these requirements are enforced by Rel[t1, \nt2], which we de.ne as the set of all relations R that contain values of types t1 and t1 with the additional \nrequirement that these relations must be equivalence-respecting. (Note that the equivalence-respecting \nrequirement is needed to prove that our logical relation is complete with respect to contextual equivalence.) \nThe parameter . is a .nite map from type variables a to triples (t1, t2,R), where t1 and t2 are closed \ntypes and R . Rel[t1, t2]. We de.ne abbreviations for projecting the type com\u00adponents of the triple as \nfollows. If .(a)=(t1, t2,R), then .1(a)= t1 and .2(a)= t2. The rest of the de.nition of the logical relation \nis essentially standard. All value relations V [.] . consist of pairs (v1,v2) where \u00b7; \u00b7f v1 : .1(.) \nand \u00b7; \u00b7f v2 : .2(.) (and similarly for term relations E [.] .). Two values are related at the type a \nif they are in the relation R in .(a). Two values are related at the type bool (similarly, bool) if they \nare equal. Two functions are related at s. s ' if, when applied to arguments related at s, they beta \nreduce to terms related at s ' i.e., the latter must be terms that belong to the term relation E [s ']. \nThe term relation E [.] . relates terms e1 and e2 if, when e1 evaluates to v1, then e2 evaluates to some \nv2 such that v1 and v2 are related in V [.] .. Finally, the relation V [. [a].t. t '] ., relates polymorphic \nfunctions. As expected, it considers arbitrary types t1, t2, together with an arbitrary relation R . \nRel[t1, t2], and two arguments v1 and v2 related at t (with . extended to map a to (t1, t2,R), since \na may appear free in t). Then, the two polymorphic functions are considered related at type . [a].t. \nt ' if, when applied, respectively, to the type arguments t1 and t2, and the value arguments v1 and v2, \nthey beta reduce to terms that are related at type t ' (again, with .[a . (t1, t2,R)]). The de.nitions \nof logical approximation and equivalence for open terms (at the bottom of Figure 5) rely on the relational \nse\u00admantics ascribed to the contexts . and G. We say that . belongs to the relational interpretation of \n. if dom(.)=., and whenever .(a)=(t1, t2,R), R is a well-formed relational interpretation (i.e., R . \nRel[t1, t2]). We say the value substitutions .1 and .2 are related at G if they map variables in dom(G) \nto related values. The de.nition of the logical relation for open terms, .; G f ;log e1 ST e2 : . (pronounced \ne1 logically approximates e2 ), is also standard. It says that given a relational interpretation . for \n. and value substitutions .1, .2 related at G, the closed terms .1(.1(e1)) and .2(.2(e2)) are related \nat the type .. Finally, we say that e1 and e2 are logically equivalent, .; G f e1 log ST e2 : ., if they \nlogically approximate each other. Properties of the Logical Relation We prove the fundamental property \nof logical relations, which says that if a term is well typed, then it is related to itself. This follows \nfrom the proofs of a series of compatibility lemmas (e.g., see [38]). The proofs of most of these lemmas \nare standard, exactly as for any logical relation for System F. The two that are interesting are the \ncompatibility lemmas for boundaries, which we state below. These require the following bridge lemma. \n(Further details and proofs are given in the online technical appendix [5].) Lemma 6.2 (Bridge Lemma) \n1. If (e1, e2) .E [s+] \u00d8 then (sST e1, sST e2) .E [s] \u00d8. 2. If (e1, e2) .E [s] \u00d8 '' and (.(x : s+). e1 \n, .(x : s+). e2 ) .V [s+. t] ., then (let x=(TS s e1) in e1 ' , let x=(TS s e2) in e2 ' ) .E [t] .. Lemma \n6.3 (Compatibility ST ) If .; G f e1 ;log ST sST e2 : s. ST e2 : s+ then .; G f sST e1 ;log Lemma 6.4 \n(Compatibility TS) f e1 ;log If .; G f e1 ;log ST e2 : t then ST e2 : s and .; G, x : s+ .; G f let x \n=(TS s e1) in e1 ;log let x =(TS s e2) in e2 : t. ST Theorem 6.5 (.ST Fundamental Property) If .; G f \ne : . then .; G f e ;log ST e : .. Proof By induction on the derivation .; G f e : .. Each case follows \nfrom the corresponding compatibility lemma. Next, we prove that the .ST logical relation is sound and \ncom\u00adplete with respect to contextual equivalence. The key thing here is that the following lemmas (along \nwith the property that ;ctx ST implies ;ciu ST , Lemma 5.3), together establish that logical approxi\u00admation \n;log , ciu-approximation ;ciu STST , and contextual approxima\u00adtion ;ctx all coincide. Therefore, in subsequent \nsections, when ST proving contextual equivalence properties, we are free to switch to whichever de.nition \nis most convenient to work with for proving the property at hand. Theorem 6.6 (.ST: Soundness w.r.t. \nContextual Approx) If .; G f e1 ;log ST e2 : .. ST e2 : . then .; G f e1 ;ctx Lemma 6.7 (.ST: CIU Approx \nImplies Logical Approx) If .; G f e1 ;ciu e2 : . then .; G f e1 ;log ST ST e2 : .. Theorem 6.8 (.ST: \nCompleteness w.r.t. Contextual Approx) If .; G f e1 ;ctx ST e2 : . then .; G f e1 ;log ST e2 : .. Proof \nImmediate from Lemmas 5.3 and 6.7. Two Key Lemmas We use our logical relation to establish two key properties \nthat we will need repeatedly when proving parts (1) and (2). The .rst is boundary cancellation, which \nessentially says that if you embed e into the source using ST , and then embed that into the target using \nTS, the resulting term is contextually equivalent to the original. Analogously, embedding e into the \ntarget via TS and then embedding the latter into the source via ST , also results in a term that is contextually \nequivalent to the original. Lemma 6.9 (Boundary Cancellation) Let .; G f e : s. Then .; G f e log sST \n(TS s e): s. ST Let .; G f e : s+. Then .; G f e log TS s (sST e): s+ . ST Proof By induction on the \nstructure of s. The second key property is a free theorem [50] regarding terms of (computation) type \n. [a].(s+. a). a. (We prove an analo\u00adgous free theorem for terms of type . [a].(s1+ \u00d7 (s2+. a)). a, but \nwe will not show that here.) This free theorem captures the essence of what we gain from switching from \na CPS type trans\u00adlation that makes use of a global answer type, to one that makes each continuation s \nanswer type individually abstract: namely, that a computation (or function) of the above type must invoke \nits con\u00adtinuation at least once, and that it does not matter (in our purely functional setting) if it \ninvokes it more than once. The free theorem can be proved using our logical relation; a similar theorem \nis given in Wadler [50]. We take a notational liberty in the statement of this theorem, which we discuss \nnext. Lemma 6.10 (Free Theorem: Continuation Shuf.ing) Let .; G f vf : . [a].(t. a). a, and .; G f vk \n: t. tk. Then .; G f vf [tk]vk log ST vk (vf [t] id): tk. Notice that vk (vf [t] id) is not a syntactically \nwell-formed term in .ST! We use this essentially as shorthand to avoid a much longer (and less intuitive) \nstatement of the theorem. Strictly speaking, the conclusion of the above lemma should be written as follows: \nThen: .. .D [.] . .(.1,.2) .G [G] .. if .2(.2(vf [t] id)) -.* v then (.1(.1(vf [tk]vk)), (.2(.2(vk))) \nv) .E [tk] . and if .1(.1(vf [t] id)) -.* v then ((.1(.1(vk))) v,.2(.2(vf [tk]vk))) .E [tk] . The intuition \nhere is that we close off the expression vf [t] id with appropriate type and term substitutions and evaluate \nit to get a value v that we then pass to the (appropriately closed) continuation vk. The two clauses \nare required because our underlying relation E [\u00b7]is an approximation while what we want here is equivalence. \n 6.2 Proving Part (1) We start with the top layer of the proof of equivalence preservation. ctx Our \ngoal here is to prove that if G f e1S e2 : s then ctx \u00b7;G f e1 ST e2 : s. As discussed in Section 2, \ngiven an arbitrary .ST context C with a hole of type (\u00b7;G f s), we need to back-translate C to an equivalent \n.S context C. The fact that this can be done at all may seem surprising, since .ST is a more expressive \nlanguage than .S. Speci.cally, .ST includes System F in which we can encode, e.g., Church numerals, and \noperations like addition and multiplication; but natural numbers, addition and multiplication cannot \nbe encoded in our source language .S. As another example, .ST contains pairs (from .T), but pairs cannot \nbe encoded in our source language .S . Thus, we consider this back-translation method and its accompanying \ninsights to be a signi.cant contribution of this work. Back-translating .ST to .S As discussed above, \nwe wish to back-translate an arbitrary .ST context C with a hole of type (\u00b7;G f s). Such a context can \nsimply be treated as an expression .x : s.C[x] which has type s. bool. This type is signi.cant. In\u00adformally, \nthe type represents the interface for this component and, in this case, it tells us that the component \nbehaves like a term of source type (if we have our translation right, that is) and expects to interact \nwith terms that behave similarly (which, technically, will mean terms of some source type s or translation \ntype s+). Thus, we have to be able to back-translate .ST terms of source type.  and where G-is de.ned \nas (\u00b7)-= \u00b7 (G, x : s)-=G-, x : s \u00b7;G f e : s e \u00b7;G f+ e : s+ e where G::= \u00b7| G, x : s | y : s+ (G, y \n: s+)-=G-, y : s and e . .S and G-f e : s '' ' \u00b7;G f e : bool e \u00b7;G f e1 : s e \u00b7;G f e2 : s e 1 2 \u00b7;G \nf true : bool true \u00b7;G f false : bool false \u00b7;G f if ethene1 else e2 : s if e ' then e 1 ' else e ' 2 \n ' '' x : s . G \u00b7;G, x : s1 f e : s2 e \u00b7;G f e1 : s2. s e \u00b7;G f e2 : s2 e \u00b7;G f+ e : s+ e 1 2 ' '' \u00b7;G \nf x : s x \u00b7;G f .x : s1. e : s1. s2 .x : s1. e \u00b7;G f e1 e2 : s e1 e2 \u00b7;G f sST e : s e \u00b7;G f+ v : bool+ \ne \u00b7;G f+ e1 : s+ e1 \u00b7;G f+ e2 : s+ e2 \u00b7;G f+ true : bool+ true \u00b7;G f+ false : bool+ false \u00b7;G f+ if vthene1 \nelse e2 : s+ if ethene1 else e2 + f+ y : s+ . G \u00b7;G, y : s1 e[s2+/a][id/k]: s2+ e + + \u00b7;G f+ y : s+ \ny \u00b7;G f+ . [a] ((y, k) : (s1 \u00d7 (s2+. a))). e : . [a].(s1 \u00d7 (s2+. a)). a .y : s1. e ' + f+ \u00b7;G f e1 : \ns1 e \u00b7;G, x : s1 e : s+ e \u00b7;G f v : t1 \u00d7 t2 v = (v1, v2) \u00b7;G f+ e[vi/x]: s+ e 1 ' \u00b7;G f+ let x =(TS \ns1 e1) in e : s+ let x = e1 in e \u00b7;G f+ let x = piv in e : s+ e \u00b7;G f v1 : . [a].t2.t \u00b7f t ' \u00b7;G f v2 \n: t2[t ' /a] s+ = t[t ' /a] v1 = . [a] (z : t2). e \u00b7;G f+ e[t ' /a][v2/z]: s+ e + (.s1. s1 = . [a].t2.t) \n\u00b7;G f+ v1 [t ' ]v2 : s+ e t ' = s+ v2 = (va, .(z : s2+). ek) \u00b7;G f+ v1 :(s1. s2)+ e1 \u00b7;G f+ va : s1+ \nea \u00b7;G, z : s2+ f+ ek : s+ ek \u00b7;G f+ v1 [t ' ]v2 : s+ let z = e1 ea in ek Figure 6. Back-translation \n: Relating .ST terms to .S terms Translating all the .S terms embedded in .ST is straightforward they \nremain unchanged until we get to a boundary term sST e. At this point, we have to be able to translate \ne which has type s+ . As discussed before, e may contain subterms that are not back\u00adtranslatable . However, \nthe whole term e has type s+ so it should be back-translatable. Intuitively, the idea here is to partially \nevalu\u00adate e till you have a term whose subterms are all back-translatable (of type s or s+). Of course, \nthe result of partial evaluation will be equivalent to the original e. The remaining issue is: can we \nalways partially evaluate till we get to such a point? We will show that this is always the case. With \nthat in mind, we set up two judgments that back\u00adtranslate e to some e . .S (see Figure 6). They have \nthe form \u00b7;G f e : s -e (for translating s terms) and \u00b7;G f+ e : s+ -e (for translating s+ terms). Here \nG may only contain mappings of the form x : s or y : s+ that is, G may only contain variables of source \ntype or translation type. (This is an important restriction as we shall see.) G-denotes the environment \nG with all mappings of the form y : s+ replaced by y : s. G-is the environment used to type-check e. \nThe back-translation rules are given in Figure 6. The rules for translating .ST terms e : s are straightforward, \nde.ned by induction on the structure of the term. The only interesting case is the boundary sST e. This \nis where we switch to the other judgment (f+) which translates terms e that have type s+. We translate \ntarget boolean values by converting them to equivalent source booleans and target if expressions are \neasy to translate because all of the subterms are of translation type. When translating . terms of type \ns1. s2+, which have a type parameter a and two value parameters y : s1+ and k : s2+. a, we can only add \ny : s1+ to the environment G; since k is not of source type or translation type it cannot be added to \nG, and we can never add type variables to the type environment . (it always remains empty). Hence, we \nsubstitute s2+ for a in the body of the function and the identity continuation id for k. As a result, \nour premise has a term of translation type s2+ that we can continue to back-translate. The reason this \nrule is well founded is because the type of the term (s2+) in the premise is smaller than the type of \nthe term in the conclusion. Translating the (let form for) boundary TS s e1 is straightfor\u00adward, since \nthe subterms have either source type or translation type. The term let x= piv in e is more interesting. \nHere v must have type t1 \u00d7 t2. But since the latter is not a source type s or a translation type s+ , \nv cannot be a variable! (This is why the restriction on the codomain of G is critical.) Therefore, v \nmust be a pair, which means partial evaluation is possible. We project the i-th component and substitute \nit for x in the let body e. The resulting term has type s+ so we continue to back-translate. Note that \nthis rule is well founded because e[vi/x] will reduce in fewer steps than let x = piv in e. The two rules \nfor v1 [t ' ]v2 are more involved but follow similar reasoning. In the .rst of these rules the function \nv1 is not of translation type. That means that it cannot be a variable. This permits partial evaluation \n(by applying v1 to t ' and v2, which yields a term that can be back-translated (since it has type s+) \nand will reduce in fewer steps. In the second rule (last rule in Figure 6), v1 is of type (s1. s2)+ (so \nit may be a variable), but that means that v2 must be a pair so it cannot be a variable. Therefore, we \ntake apart the argument va and the continuation in that pair. The continuation also is not of translation \ntype, so it cannot be variable. We then separately back-translate these and reassemble to get the .nal \nback-translation for v1 [t ' ]v2. This rule is well founded since it only requires back-translation of \nsubterms of the original term. Our rules are exhaustive, in the sense that all possible terms of type \ns and s+ have been covered. Next we show that for every term of type s and s+, it is possible to construct \na .nite back-translation derivation, and that the back-translation e is equivalent to the original e. \nNote that for the equivalence statement, on the right-hand side we have to replace all target y variables \nwith TS s y since G -contains y : s in place of y : s+ . Lemma 6.11 (From .ST term : s / s+ to equivalent \n.S term) Let G::= \u00b7| G, x : s | y : s+ 1. If \u00b7;G f e : s then there exists e . .S s.t. \u00b7;G f e : s -e \nand y)/y] log \u00b7;G -f e[(TS G.(y) ST e : s. 2. If \u00b7;G f e : s+ then there exists e . .S s.t. \u00b7;G f+ e \n: s+ -e y)/y]) log and \u00b7;G -f sST (e[(TS G.(y) ST e : s. Proof (1) and (2) are proved by simultaneous \ninduction since the s and s+ translation rules are mutually dependent. We then proceed by induction on \nthe length of the reduction sequence for e, nested induction on the type s, and innermost induction on \nthe structure of the term e. Wrapping Up Proof of Part (1) Our desired lemma, that G f e1 ctx S e2 : \ns implies \u00b7;G f e1 ctx ST e2 : s, follows as a corollary from the lemma below. Lemma 6.12 (Ciu-equiv \nin .S implies ciu-equiv in .ST) Let G be a .S environment, and let e1 and e2 be .S terms. If G f e1 ;ciu \ne2 : s then \u00b7;G f e1 ;ciu e2 : s. S ST Proof Suppose E :(\u00b7; \u00b7f s . (\u00b7; \u00b7f bool), and .st :G and E[.st(e1)] \n. v where v : bool. Show: E[.st(e2)] . v. We back-translate E (or, to be precise, .x : s.E[x]) and .st \nto eE and .s. By Lemma 6.11 these are equivalent to the original E and .st. Hence, E[.st(e1)] ctx ST \neE (.s(e1)) : bool. Hence, the latter evaluates to v. Now, we instantate the premise with eE (after morphing \nit into a valid evaluation context), and .s. Hence, (e2)) ctx eE (.s(e2)) evaluates to v. Since eE (.sST \nE[.st(e2)] : bool, the latter evaluates to v.  6.3 Proving Part (2) We now tackle the middle layer of \nthe proof of equivalence preser\u00advation. Our goal in this section is to prove that if e1 and e2 translate \nto v1 and v2, then e1 ctx ST v2 at ST e2 at type s implies that v1 ctx type s\u00f7 . Below, we prove that \nour CPS translation is both semantics pre\u00adserving (typically referred to as compiler correctness) and \nseman\u00adtics re.ecting. We use the logical relation for our multi-language system to do these proofs. Our \nstatements of semantics preserva\u00adtion and re.ection are novel in that they rely on our multi-language \nsemantics. As we discuss in Section 8, as compared to work on semantics-preserving compilation that uses \ncross-language logical relations [8, 9, 17] (which relate source terms to target terms), it seems simpler \nto understand how to set up the de.nitions and ma\u00adchinery for such proofs using a multi-language system \nand logical relation. Finally, we wrap up by showing that the main result of this section (Lemma 6.17), \nnamely the proof that translation preserves equivalence (within .ST), which follows easily from the fact \nthat CPS translation preserves and re.ects semantics. Translation Preserves and Re.ects Semantics With \nthe bound\u00adary cancellation and continuation-shuf.ing lemmas in hand, we can prove that our CPS translation \npreserves and re.ects semantics. In the statement of these lemmas, we will have a .S term e on one side \nand its translation, a .T term v, on the other side. Wherever e contains a variable x : s, v will have \nthe variable x : s+. There\u00adfore, we will need related (source and target) substitutions .S and .T to \nobtain closed terms. De.nition 6.13 (Related Source-Target Substitutions) Let G be a .nite map from variables \nx to types s. Let .S be a .nite map from variables x to (closed) values v. Let .T be a .nite map from \nvariables x to (closed) values v. We de.ne G f .S ; .T as follows: \u00b7f\u00d8 ; \u00d8 i. (unconditionally) G, x \n: s f .S, x . v ; .T, x . v i. G f .S ; .T log .f v ST sST v : s We de.ne G f .S 2 .T as follows: \u00b7f\u00d8 \n2 \u00d8 i. (unconditionally) G, x : s f .S, x . v 2 .T, x . v i. G f .S 2 .T log .f sST v ST v : s We de.ne \nG f .S c .T as follows: G f .S c .T i. G f .S ; .T . G f .S 2 .T Notice that in the de.nition of G f \n.S 2 .T, we require log f sST v ST v : s. Using boundary cancellation and the com\u00adpatibility lemmas for \nboundaries, we can conclude that this is log equivalent to f v ST TS s v : s+. (This observation might \nmake it slightly easier to understand the statement of Lemma 6.15.) Informally, the following lemma says \nthat if e evaluates to some value v1, then its CPS translation, when applied to the identity continuation \nwill evaluate to some v2 : s+ that can be converted to a source value v2 such that v1 and v2 are related \nat s. Lemma 6.14 (CPS is semantics preserving) If G f e : s r v and G f .S ; .T `\u00b4 then f .S(e) ;log \nsST .T (v) [s+] id : s. ST Proof By induction on the structure of e. The statement that CPS translation \nis semantics re.ecting is a bit more involved. Informally, the following lemma says that suppose that \nthe computation v (which is the CPS translation of e), when applied to a type ta and some continuation \nvk : s+. ta, evaluates to the value v1 : ta. Then if we convert e to a target value v ' : s+, and then \ninvoke the continuation vk (or to be precise, a continuation that s related to vk) with v ', this will \nresult in a value v2 such that v1 and v2 are related at the type ta. Lemma 6.15 (CPS is semantics re.ecting) \nIf G f e : s r v and G f .S 2 .T then f .T(v) ;log ST . [a] (k : s+. a). let z =(TS s .S(e)) in k z : \ns\u00f7 . Proof By induction on the structure of e. The following is a corollary of semantics preservation \nand re\u00ad.ection. Notice that by boundary cancellation, the conclusion is `\u00b4 (.S(e)) log equivalent to \nf TS s ST .T (v) [s+] id : s+. (This explains why we call it translation is equivalent to embedding. \n) Corollary 6.16 (Translation is Equivalent to Embedding) Let G f e : s r v and G f .S . .T. `\u00b4 f .S(e) \nlog Then ST sST .T (v) [s+] id : s. Lemma 6.17 (Translation Preserves Equivalence in .ST) Let e1 and \ne2 be .S terms. If G f e1 : s r v1, G f e2 : s r v2, and \u00b7;G f e1 ;log ST v2 : s\u00f7 . ST e2 : s, then \n\u00b7;G f v1 ;log Proof Follows from Lemmas 6.14 and 6.15 and the transitivity of ;log ST. 6.4 Proving Part \n(3) For the .nal (bottom) layer of our proof of equivalence preser\u00ad ctx vation, we must show that if \n\u00b7;G+ f v1 ST v2 : s\u00f7 then ctx \u00b7;G+ f v1T v2 : s\u00f7. The latter is immediate from the fol\u00adlowing more general \nlemma. Lemma 6.18 (Equivalence in .ST implies equivalence in .T) Let e1 and e2 be .T terms. If .; G f \ne1 ;ctx T e2 : t. ST e2 : t then .; G f e1 ;ctx The proof is straightforward, intuitively, because \n.T contexts are a subset of .ST contexts. Given an arbitrary .T context C of the appropriate type, we \nmust show that if C[e1] evaluates to v (which will be of type bool) then so does C[e1]. We can instantiate \nthe premise with the context boolST [C[\u00b7]]. The rest easily follows from the fact that there is a one-to-one \ncorrespondence between the evaluation of a .T expression in .ST and in .T, and from noting that the reduction \nrule for boolST \u00b7 simply converts true to true and false to false. 7. Equivalence Re.ection Equivalence \nre.ection is a direct consequence of semantics preser\u00advation. Semantics preservation states that source \nprograms (closed .S terms of base type, i.e., bool) and their translations in .T behave analogously: \nLemma 7.1 (Semantics preservation) Let \u00b7f e : bool r v. If e -. * true then v [bool] id -. * true and \nif e -. * false then v [bool] id -. * false. Proof Immediate from Lemma 6.16. The next observation we \nneed concerns the structural behavior of the CPS translation: Lemma 7.2 (Context translation) Let G f \nC[e1]: s and G f C[e2]: s. Then there exist C, v1, v2 such that G f C[e1]: s r C[v1] and G f C[e2]: s \nr C[v2]. Proof By induction on the structure of C, using the de.nition of the CPS translation relation. \nEquivalence re.ection now follows almost immediately from Lemmas 7.1 and 7.2: Theorem 7.3 (Equivalence \nre.ection) ctx Let G f e1 : s r v1 and G f e2 : s r v2. If \u00b7;G+ f v1T v2 : s\u00f7 then G f e1 ctx S e2 : \ns. Proof Indirect: Suppose the conclusion does not hold, which means there exists some C such that \u00b7f \nC[e1]: bool and \u00b7f C[e2]: bool where (w.l.o.g.) C[e1] -. * true while C[e2] -. * false. By Lemma 7.2 \nthere must exist a C such that \u00b7f C[e1]: bool r C[v1] and \u00b7f C[e2]: bool r C[v2]. At this point Lemma \n7.1 tells us that (C[v1]) [bool] id -. * true while (C[v2])[bool]id -. * false. Thus, (C[\u00b7])[bool]id \nis a context that discriminates between v1 and v2, which is a contradiction. 8. Discussion and Future \nWork Supporting Additional Language Features For this paper, we chose simply-typed .-calculus and System \nF as our source and tar\u00adget languages so that we could highlight the main ideas underlying our proof \ntechnique, in particular, the use of multi-language seman\u00adtics and how back-translation can leverage \npartial evaluation given the right type translation. We now sketch how to extend our the\u00adorem and its \nproof to source and target langauges with more ad\u00advanced features. If the source and target language \nhave non-terminating terms, then we are faced with two dif.culties: ensuring well-foundedness of the \nback-translation (which affects Lemma 6.11) and proving the continuation-shuf.ing lemma (Lemma 6.10). \nTo address the .rst problem, ensuring well-foundedness of the back-translation relation, we add a new \ncase wherever back\u00adtranslation performs computation steps: if the term to be partially evaluated is non-terminating \n(i.e., contextually equivalent to a term that diverges), simply make its translation a non-terminating \nsource term of appropriate type. Notice that this de.nition does not yield an algorithm for back-translation \nbut merely a relation. However, since back-translation is merely a proof device, it does not need to \nbe an algorithm. We explain this is greater detail in the technical appendix [5] (see \u00a71.1): we add divergent \nterms to both .S and .T and present the changes required to the back-translation rules. The second problem, \nproving the continuation-shuf.ing lemma, is more dif.cult to deal with: in the presence of non-termination, \nLemma 6.10 cannot be proved by parametricity alone; parametric\u00adity only gives us an approximation relation \nand not an equivalence relation. However, there is an alternative, syntactic proof for the continuation-shuf.ing \nlemma in this case. The details are beyond the scope of the current work; we will present that result \nin a future paper. Recursive types give rise to non-termination, so everything said above applies here \nas well. In particular, though, recursive types make it somewhat trickier to de.ne the semantics of our \nmulti\u00adlanguage boundary terms. However, the technique for de.ning wrapper terms in our full abstraction \nproof for closure conver\u00adsion [4] can be adapted to deal with this issue. Also, in the presence of recursive \ntypes we will need to switch to a step-indexed logical relation [3] for .ST to ensure well-foundedness \nof the logical rela\u00adtion. Thus, all parts of the proof that make use of the .ST logical relation will \nbecome more involved. Again, we plan to report on this result in a future paper. Adding polymorphism \nto the source language is not dif.cult to deal with. The main idea is for boundary terms to not peek \nunder abstraction barriers but to simply leave abstract things abstract. We have successfully applied \nthis idea before in our work on fully abstract closure conversion [4] and do not foresee any dif.culties \nwhen adapting it to the case of CPS translation. Our longer-term goal is to show that a compiler from \nSystem F (with recursion, and later, with state) to typed assembly language is equivalence preserving. \nThus far we have considered two phases of compilation, namely CPS (this paper) and typed closure con\u00adversion \n[4], where the type translations were precisely the key to ensuring that the target terms that compiled \ncode interacts with are suf.ciently well behaved. Thus, the type translations were the key to proving \nthat the translations were equivalence preserving. To formulate an equivalence-preserving translation \nfrom CPS-and\u00adclosure-converted code down to assembly, we will need a target\u00adlevel type system rich enough \nto be able to express invariants about local state, separation of state, and so on. We believe that an \nas\u00adsembly language based on Hoare Type Theory [37] can provide the features needed for imposing the necessary \nwell-behavedness con\u00adstraints on target contexts. Finally, the reader may have wondered if we can prove \nthat our CPS translation is fully abstract when the target language is Sys\u00adtem F without the syntactic \nrestriction that enforces continuation\u00adpassing style. In the online technical appendix (see \u00a71.3) we \nshow that this is, in fact, the case. The main change to the proof is that the back-translation from \nthis unrestricted System F to STLC becomes more complicated, intuitively, since a target language without \nthe CPS restriction contains many more terms than .T . Compiler Correctness Proofs Let us compare the \nstatement of CPS is Semantics Preserving (Lemma 6.14) to roughly what one would expect in a semantics-preservation \n(compiler correctness) proof that uses a cross-language logical relation (e.g., [8, 9, 17]) relating \nsource terms of type s to target terms of type s+ (though, relating to s\u00f7 is a valid choice as well). \nIn the absence of a com\u00adbined language, the statement there cannot mention ST . Instead it says that \nv1 must be related to v1 in the cross-language relation at the type s (which would mean that v1 would \nhave type s+). That means that to understand the de.nition of relatedness at each type, one would have \nto have a precise understanding of the cross-language relation. In the presence of features like recur\u00adsive \ntypes (and eventually state), these logical relations get rather complicated, for instance using step-indexing \nand/or biorthogonal\u00adity (e.g., [8, 9]), or advanced denotational models. Thus, it can be dif.cult for \nsomeone who simply wants to understand the statement of the semantics-preservation theorem, and not the \nmathematical machinery underlying the logical relation, to decipher exactly what that statement says. \nOn the other hand, with the multi-language ap\u00adproach, to understand the statement of the theorem, one \nsimply has to examine the reduction rules for boundaries. The details of the .ST logical relation are \nnot important at this level; all one needs to know is that it is sound with respect to contextual equivalence. \n Finally, de.ning the multi-language logical relation seems more straightforward than the cross-language \nlogical relation. The multi\u00adlanguage logical relation is simply a combination of the logical relations \nfor source and target; the desired relationship between source and target semantics is speci.ed separately \nby de.ning the dynamic semantics for boundaries. The cross-language logical relation, meanwhile, must \nsimultaneously provide a proof method and specify the desired relationship between source and target \nterms. 9. Related Work Fully Abstract Denotational Models The earliest work on full abstraction was done \nin the context of denotational models of languages (e.g., [2, 16, 25, 33]). The denotation function can \nbe thought of as a translation from a syntactic/operational calculus into a mathematical domain. The \ngoal there is to ensure that the deno\u00adtational semantics does not expose differences that are not opera\u00adtionally \nobservable [35]. As typi.ed by parallel OR in PCF [39], in a lot of this work, full abstraction is achieved \nby adding certain be\u00adhaviors that are possible in the denotational semantics (target) to the operational \nsemantics of the language being modeled (source). Our work differs somewhat from that on denotational \nmodels in that we are interested in proving full abstraction of translations (mostly compilers); here \nthe target language also comes with an opera\u00adtional semantics. In particular, we focus on type-directed \nand type\u00adpreserving compilation and critically require a suf.ciently clever type translation such that \nthe types of compiled terms can impose well-behavedness constraints on any target-level term that might \ninteract with the result of the translation, thus ensuring that target contexts cannot violate source-level \nabstractions. Translation to Continuation-Passing Style CPS has been studied extensively in the literature. \nHere we only discuss work that seems most closely related to ours. A number of papers have investigated \nfull abstraction for CPS translation, but there is no prior full abstraction result for a CPS translation \nthat uses a locally polymorphic answer type. Meyer and Riecke [32] pointed out that standard (untyped) \nCPS translation does not preserve observational equivalence and conjectured as to how this could be repaired. \nSeveral papers have looked at the use of linear types to en\u00adsure that a function calls its continuation \nexactly once. Zdancewic and Myers [51] present a security-typed CPS target language with higher-order, \nimperative features where linear continuations are needed to ensure noninterference. They also give a \ntranslation from a security-typed, direct-style language into the afore-mentioned target language using \nlinear typing of CPS and prove that the translation preserves well-typedness. Berdine et al. [10, 11] \nshow that continuations are used linearly in a variety of situations, in\u00adcluding procedure call/return, \nexception raising/handling, labelled jumps (goto statements) and process switching (coroutines). Nei\u00adther \nZdancewic and Myers [51] nor Berdine et al. [10, 11] present any full abstraction results for their CPS \ntranslation. Berdine, O Hearn, and Thielecke [12] use af.ne typing of CPS to extract the range of CPS \nfor a call-by-value .-calculus. Speci.\u00adcally, they restrict the grammar of types in the target to only \nthose forms exercised by the CPS translation. They then de.ne the gram\u00admar for target terms so that there \nis one syntactic category for terms of each type. This allows them to give a precise characterization \nof the range of CPS by showing that all terms in the target come from some term in the source that is, \nthey prove a no junk lemma (also known as full completeness) that states that for each term M in the \ntarget, there exists a term N in the source such that M is \u00df.\u00adequivalent to the CPS translation of N. \nThe proof of this no junk lemma requires back-translating M to get N. The critical differ\u00adence between \nBerdine et al. s work [12] and ours that their target language is exactly as expressive as the source \n(i.e., every target term can be back-translated), while our target language is more ex\u00adpressive than \nthe source (i.e., there exist well-typed target terms that cannot be back-translated, speci.cally, terms \nof type t where t is not a translation type.) Consequently, our proof framework allows for one target \nlanguage to serve as the target for different source languages and compilers, and allows components written \nin these different source languages to interoperate at the target level (assum\u00ading the compilation strategies \nrely on similar representation invari\u00adants at the target level). As a concrete example, we could de.ne \na CPS translation from a second source language, System F, to our target langauge .T. Now source code \nwritten in .S can interoperate with source code written in System F after CPS translation to .T , as \nlong as we have a well-typed program after linking the two compiled components in .T. This would not \nbe possible if we had resorted to a strategy like Berdine et al. s where back-translation requires that \nthe target language be no more expressive than the source. Sabry and Felleisen [43] study equational \ncompleteness of CPS based on \u00df.-equality rather than observational equivalence. They present a CPS transformation \nand an inverse mapping (or back\u00adtranslation ). From the CPS transformation, they extract the pre\u00adcise \nlanguage of CPS terms closed under \u00df.-equality, arriving at almost exactly the same syntax (modulo administrative \nredexes) as Berdine et al. [12]. Sabry and Felleisen analyze the syntax of the output of CPS while Berdine \net al. analyze the types of the output of CPS to arrive as almost exactly the same target language syntax. \nHence, Berdine et al. s back-translation is essentially Sabry and Felleisen s inverse mapping (from CPS \nto direct style). Hasegawa [21] has proved a full completeness result for the lin\u00adear CPS transformation \nin the setting of a simply typed .-calculus using syntactic methods based on long \u00df.-normal forms. Like \nSabry and Felleisen [43], he considers only \u00df.-equivalence, not observational equivalence. Using categorical \ngame semantics, Laird [29] showed that for call-by-value PCF one can recover full abstraction of CPS \ntransla\u00adtion by imposing an af.ne typing discipline on continuations, es\u00adsentially employing the idea \nof linearly-used continuations pre\u00adsented by Berdine et al. [11]. We feel that with proofs based on game \nsemantics, it is hard for non-experts to understand even the statements of the main lemmas required for \nthe proof. Therefore, a primary objective of our work has been to come up with an op\u00aderational proof \ntechnique that s simpler to understand and could (plausibly) be used throughout all the stages of a compiler. \nThe proof techniques described in this paper, combined with recent ad\u00advances in step-indexed logical \nrelations [3, 6] seem like they would scale when applied to richer languages and successive compilation \nphases. Thielecke [48] seems to have been the .rst to study CPS trans\u00adformation with a locally polymorphic \nanswer type, though his work focuses on the role of answer type polymorphism in a language with control \neffects. He uses parametricity reasoning to observe the connection between linear typing of CPS and answer \ntype polymor\u00adphism in a pure call-by-value setting, showing that functions with\u00adout control effects do \nnot impose any constraints on the answer type and so can have a locally polymorphic answer type. He essen\u00adtially \nproves the equivalent of our continuation-shuf.ing lemma, a property that he calls naturality. He has \nalso studied answer type polymorphism for the call-by-name CPS transform and used it to show that the \nlatter satis.es the eta-law [49]. He does not, however, discuss full abstraction of CPS translations. \n Danvy [18] presents a translation from CPS programs into direct-style (DS) programs in an untyped setting. \nHis technique relies on syntactically characterizing CPS terms that can be trans\u00adlated back to DS. Speci.cally, \nto be back-translatable, a CPS term must satisfy certain occurrence conditions (see Danvy [18], Fig. \n2) that ensure that the CPS term encodes a call-by-value left-to-right evaluation order, checked essentially \nby parsing the CPS term us\u00ading a stack that holds the formal parameters of continuations. We, on the \nother hand, use types to semantically characterize terms that can be translated back to our direct-style \n.S, without requiring that all of their subterms also have back-translatable types. As a re\u00adsult, we \ncan back-translate more terms. Finally, our CPS grammar does not distinguish between ordinary . s and \ncontinuation . s as Danvy s does, while he does not make use of partial evaluation as we do, i.e., to \ndeal with subterms that are not, on their own, back-translatable. Several researchers have investigated \nback-and-forth transla\u00adtions between direct-style and CPS semantics following Meyer and Wand s [34] work \non retractions. An embedding-retraction pair (i, j) is a pair of functions such that j . i is the identity \nfunction. Meyer and Wand work with the typed .-calculus and use the stan\u00addard type translation for CPS \nthat we showed is not fully abstract in Section 1. They write s ' to denote their type translation of \ns; let s * =(s ' . ans) . ans. They show that there exist embedding\u00adretraction pairs (is,js) and (Is,Js) \nde.nable in call-by-name .-calculus (CBN) where is : s . s ' , js : s ' . s, Is : s ' . s *, and Js : \ns * . s '. Their main result is the Retraction The\u00adorem which says that (js . Js) is the inverse of the \nCPS trans\u00adform, i.e., M =CBN js(Js(M)), where M is the CPS transform of M. The boundary terms TS s and \nsST in our multi-language semantics are similar in spirit to is and js, respectively; the prop\u00aderty that \n(js . is)= id is analogous to (part 1) of our boundary cancellation property (Lemma 6.9); and their Retraction \nTheorem, which says that the retraction of a translation is equivalent to the original term, is analogous \nto our translation is equivalent to em\u00adbedding lemma (Corollary 6.16). 1 But there are also important \ntechnical differences since our target language (System F) is more expressive than theirs (STLC), and \ndue to the fact that we make use of a multi-language semantics. In particular, our boundary terms are \nbuilt-in with an appropriate operational semantics; thus our embedding-retraction pairs do not have to \nbe de.nable in the target language as is the case with retractions, and this makes our multi\u00adlanguage \ntechnique more general. With retractions, the source lan\u00adguage is generally assumed to be a strict subset \nof the target and the Retraction Theorem proves equivalence with respect to the (larger) target language. \nNote that our .S is not a strict subset of .T since the latter syntactically enforces continuation-passing \nstyle. Meyer and Wand s Retraction Theorem is essentially analogous to our proof of Part (2). There is \nno analog to our Part (1) and no proof of full abstraction. In particular, Meyer and Riecke [32] subsequently \nshowed that if we replace CBN \u00df.-equational reasoning with call\u00adby-value observational equivalence, then \nthe embedding-retraction pairs de.ned in Meyer-Wand no longer suf.ce. In fact, Meyer and Riecke failed \nto prove a Retraction Theorem in this setting. 1 In technical terms, our previous work on typed closure \nconversion seems closer to the work on retractions since there we do not use a multi-language semantics; \ninstead the source and target are the same language and in this language we de.ne wrapper functions W+ \nand W- that are analogous to i and j, respectively, and we prove a theorem similar to Meyer and Wand \ns (except that it s for closure conversion, not CPS conversion). Later Riecke [41] and Riecke and Viswanathan \n[41] investigated a semantic variation of the retraction approach with the goal of iso\u00adlating side-effects \nin sequential programs. Also, Filinski [19] gen\u00aderalized Meyer and Wand s Retraction Theorem to a CPS \ntransform for the monadic metalanguage. Like Meyer-Wand, Filinski s tech\u00adnique does not generalize to \na language with divergence. Berger, Honda, and Yoshida have studied fully abstract trans\u00adlations from \nvarious languages (with recursion [13], polymor\u00adphism [14, 15], control [23], state [22], and concurrency \n[22]) to linear or af.nely typed and in some cases polymorphic [14, 15] p-calculus. They prove their \ntranslations fully abstract in the case of recursion (with source language PCF) [13], polymorphism (with \nsource language System F) [14, 15], and control [23], but only speculate about full abstraction in the \ncase of state and concur\u00adrency [22]. Since the usual translation of the .-calculus into the p-calculus \ncan be seen as a form of CPS translation, it may be useful to further investigate the connections between \ntranslations into the p-calculus and translations to continuation-passing style. Like us, Berger et al. \nrely on typing in the p-calculus to ensure that the translations are fully abstract. Unlike us, they \nrely on game semantics to prove their translations fully abstract. In this paper, we have shown that \nterms of translation type are back-translatable. Analogously, Berger et al. show that terms of translation \ntype are de.nable. De.nability says that for every p-calculus term P of translation type s , there exists \na well-typed source term M : s (where they write s to denote the translation of a source type s). Like \nus, they note that one reason de.nability is dif.cult to estab\u00adlish is because subterms of P may not \nbe of translation type, which means that the proof cannot be carried out simply by induction on typing \nderivations. Our strategy for dealing with subterms that are not of translation type was to show that \nit is always possible to perform some partial evaluation that gets rid of the problematic subterm, leaving \nonly subterms that are of translation type. Their strategy is to show that every .nite target term P \nof translation type can be represented by a .nite innocent function that can be turned into a .nite canonical \nform, which in turn is easily transformed into some source term M such that P is equivalent to the translation \nof M. Thus, they use the notion of innocence [24] from game seman\u00adtics to establish, in essence, that \ntranslation types at the target level are inhabited by only well-behaved computations. They are, thus, \nable to perform induction on the size of the corresponding innocent functions. This approach is similar \nto that of Laird s [29] whose proof of full abstraction also relies on game semantics. Our proof method \nis more elementary as it relies on operational/syntactic techniques (coupled with typing) for back-translatability; \nexpertise in game semantics is not required to follow the details. Full Abstraction of Other Translations \nMost work on prov\u00ading that translations preserve equivalence has typically resorted to adding precisely \nthose target behaviors that are problematic to the source language. For instance, Riecke [42] investigates \nfully ab\u00adstract translations between CBN, CBV, and lazy PCF, using denota\u00adtional models of the languages \nthat include the parallel conditional. This is needed to make the models fully abstract. Also, Sanjabi \nand Ong [44] investigate a translation from a core calculus of additive aspects to a target language \nwith higher-order store in the style of ML references. After showing that their original translation \nis not fully abstract, they weaken the source language by endowing it with the power to construct bad \nlabels the analogue of the bad references at the target that were responsible for the failure of full \nabstraction. Shikuma and Igarashi [46] prove full abstraction of a translation from STLC with seal and \nunseal operators to STLC with base types for each sealing authority. They use a syntactic proof method, \nbut their back-translation is only applicable to terms all of whose sub\u00adterms are of translation type. \nOur back-translation is more general precisely because it does not impose this restriction. Acknowledgments \nThe .rst author would like to thank Greg Morrisett for suggesting the problem of fully abstract compilation \nto her in Spring 2005. We thank Kyle Ross who helped us with this work in Spring 2010. We are also grateful \nto Amr Sabry and several anonymous reviewers for their many helpful suggestions on earlier versions of \nthis paper. References [1] M. Abadi. Protection in programming-language translations. In ICALP, 1998. \n [2] S. Abramsky, R. Jagadeesan, and P. Malacaria. Full abstraction for PCF. Inf. Comput., 163(2):409 \n470, 2000. [3] A. Ahmed. Step-indexed syntactic logical relations for recursive and quanti.ed types. \nIn ESOP, 2006. [4] A. Ahmed and M. Blume. Typed closure conversion preserves observational equivalence. \nIn ICFP, 2008. [5] A. Ahmed and M. Blume. An equivalence-preserving CPS translation via multi-language \nsemantics (technical appendix). Available at http://www.cs.indiana.edu/~amal/papers/epc/, July 2011. \n[6] A. Ahmed, D. Dreyer, and A. Rossberg. State-dependent representa\u00adtion independence. In POPL, 2009. \n[7] A. W. Appel. Compiling with Continuations. Cambridge University Press, 1992. [8] N. Benton and C.-K. \nHur. Biorthogonality, step-indexing and compiler correctness. In ICFP, 2009. [9] N. Benton and C.-K. \nHur. Realizability and compositional compiler correctness for a polymorphic language. Technical Report \nMSR-TR\u00ad2010-62, Microsoft Research, Apr. 2010. [10] J. Berdine. Linear and af.ne typing of continuation-passing \nstyle. Technical Report RR-04-04, Queen Mary, Univ. of London, Jan. 2004. [11] J. Berdine, P. O Hearn, \nU. Reddy, and H. Thielecke. Linear continuation-passing. Higher Order Symbol. Comput., 15(2-3):181 208, \n2002. [12] J. Berdine, P. O Hearn, and H. Thielecke. Extracting the range of cps from af.ne typing: Extended \nabstract. In Workshop on Linear Logic, 2002. [13] M. Berger, K. Honda, and N. Yoshida. Sequentiality \nand the p\u00adcalculus. In TLCA, 2001. [14] M. Berger, K. Honda, and N. Yoshida. Genericity and the p-calculus. \nIn FOSSACS, 2003. [15] M. Berger, K. Honda, and N. Yoshida. Genericity and the p-calculus. Acta Informatica, \n42:83 141, November 2005. [16] R. Cartwright and M. Felleisen. Observable sequentiality and full abstraction. \nIn POPL, 1992. [17] A. Chlipala. A certi.ed type-preserving compiler from lambda calculus to assembly \nlanguage. In PLDI, 2007. [18] O. Danvy. Back to direct style. Science of Computer Programming, 22(3):183 \n195, 1994. [19] A. Filinski. Representing monads. In POPL, 1994. [20] R. Harper and M. Lillibridge. Explicit \npolymorphism and CPS conversion. In POPL, 1993. [21] M. Hasegawa. Linearly used effects: Monadic and \nCPS transforma\u00adtions into the linear lambda calculus. In FLOPS, 2002. [22] K. Honda and N. Yoshida. A \nuniform type structure for secure information .ow. In POPL, 2002. [23] K. Honda, N. Yoshida, and M. Berger. \nControl in the p-calculus. In Fourth ACM-SIGPLAN Continuations Workshop (CW 04), Jan. 2004. [24] J. M. \nE. Hyland and C. H. L. Ong. On full abstraction for PCF: I, II, and III. Information and Computation, \n163(2):285 408, 2000. [25] A. Jeffrey. A fully abstract semantics for a concurrent functional language \nwith monadic types. In LICS, 1995. [26] A. Kennedy. Securing the .NET programming model. Theoretical \nComputer Science, 364(3):311 317, 2006. [27] A. Kennedy. Compiling with continuations, continued. In \nICFP, 2007. [28] D. A. Kranz, R. A. Kelsey, J. A. Rees, P. Hudak, and J. Philbin. ORBIT: an optimizing \ncompiler for Scheme. In Proceedings of the ACM Symposium on Compiler Construction, June 1986. [29] J. \nLaird. Game semantics and linear CPS interpretation. Theor. Comput. Sci., 333(1-2):199 224, 2005. [30] \nI. A. Mason and C. L. Talcott. Equivalence in functional languages with effects. J. Functional Programming, \n1(3):287 327, 1991. [31] J. Matthews and R. B. Findler. Operational semantics for multi\u00adlanguage programs. \nIn POPL, Nice, France, pages 3 10, Jan. 2007. [32] A. Meyer and J. G. Riecke. Continuations may be unreasonable. \nIn Conf. on LISP and functional programming, LFP, 1988. [33] A. R. Meyer and K. Sieber. Towards fully \nabstract semantics for local variables. In POPL, 1988. [34] A. R. Meyer and M. Wand. Continuation semantics \nin typed lambda\u00adcalculi. In R. Parikh, editor, Logics of Programs (Brooklyn, June, 1985), volume 193 \nof LNCS, pages 219 224. Springer-Verlag, 1985. [35] R. Milner. Fully abstract models of typed lambda \ncalculi. Theoretical Computer Science, 4(1), 1977. [36] G. Morrisett, D. Walker, K. Crary, and N. Glew. \nFrom System F to typed assembly language. Transactions on Programming Languages and Systems, 21(3):527 \n568, May 1999. [37] A. Nanevski, A. Ahmed, G. Morrisett, and L. Birkedal. Abstract predicates and mutable \nadts in hoare type theory. In ESOP, 2007. [38] A. M. Pitts. Typed operational reasoning. In B. C. Pierce, \neditor, Advanced Topics in Types and Programming Languages. MIT Press, 2005. [39] G. D. Plotkin. LCF \nconsidered as a programming language. Theoretical Computer Science, 5:223 255, 1977. [40] J. C. Reynolds. \nTypes, abstraction, and parametric polymorphism. Information Processing, pages 513 523, 1983. [41] J. \nRiecke and R. Viswanathan. Isolating side effects in sequential languages. In POPL, 1995. [42] J. G. \nRiecke. Fully abstract translations between functional languages. In POPL, 1991. [43] A. Sabry and M. \nFelleisen. Reasoning about programs in continuation\u00adpassing style. In Conf. on LISP and functional programming, \nLFP, 1992. [44] S. B. Sanjabi and C.-H. L. Ong. Fully abstract semantics of additive aspects by translation. \nIn Proceedings of the 6th international conference on Aspect-oriented software development (AOSD), 2007. \n[45] Z. Shao and A. W. Appel. A type-based compiler for Standard ML. In PLDI, 1995. [46] N. Shikuma and \nA. Igarashi. Proving noninterference by a fully complete translation to the simply typed lambda-calculus. \nLogical Methods in Computer Science, 4(3:10):1 31, 2008. [47] G. L. Steele. RABBIT: A compiler for SCHEME. \nTechnical Report AI-TR-474, MIT, May 1978. [48] H. Thielecke. From control effects to typed continuation \npassing. In POPL, 2003. [49] H. Thielecke. Answer type polymorphism in call-by-name continua\u00adtion passing. \nIn ESOP, 2004. [50] P. Wadler. Theorems for free! In ACM Symposium on Functional Programming Languages \nand Computer Architecture (FPCA), 1989. [51] S. Zdancewic and A. C. Myers. Secure information .ow and \nCPS. In ESOP, 2001.   \n\t\t\t", "proc_id": "2034773", "abstract": "<p>Language-based security relies on the assumption that all potential attacks follow the rules of the language in question. When programs are compiled into a different language, this is true only if the translation process preserves observational equivalence.</p> <p>To prove that a translation preserves equivalence, one must show that if two program fragments cannot be distinguished by any source context, then their translations cannot be distinguished by any target context. Informally, target contexts must be no more powerful than source contexts, i.e., for every target context there exists a source context that \"behaves the same.\" This seems to amount to being able to \"back-translate\" arbitrary target terms. However, that is simply not viable for practical compilers where the target language is lower-level and, thus, contains expressions that have no source equivalent.</p> <p>In this paper, we give a CPS translation from a less expressive source language (STLC) to a more expressive target language (System F) and prove that the translation preserves observational equivalence. The key to our equivalence-preserving compilation is the choice of the right type translation: a source type &#963; mandates a set of behaviors and we must ensure that its translation &#963;<sup>+</sup> mandates semantically equivalent behaviors at the target level. Based on this type translation, we demonstrate how to prove that for every target term of type &#963;<sup>+</sup>, there exists an equivalent source term of type &#963;- even when sub-terms of the target term are not necessarily \"back-translatable\" themselves. A key novelty of our proof, resulting in a pleasant proof structure, is that it leverages a multi-language semantics where source and target terms may interoperate.</p>", "authors": [{"name": "Amal Ahmed", "author_profile_id": "81100287263", "affiliation": "Indiana University, Bloomington, IN, USA", "person_id": "P2801456", "email_address": "amal@cs.indiana.edu", "orcid_id": ""}, {"name": "Matthias Blume", "author_profile_id": "81100215091", "affiliation": "Google, Chicago, IL, USA", "person_id": "P2801457", "email_address": "blume@google.com", "orcid_id": ""}], "doi_number": "10.1145/2034773.2034830", "year": "2011", "article_id": "2034830", "conference": "ICFP", "title": "An equivalence-preserving CPS translation via multi-language semantics", "url": "http://dl.acm.org/citation.cfm?id=2034830"}