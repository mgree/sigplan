{"article_publication_date": "09-19-2011", "fulltext": "\n How to Make Ad Hoc Proof Automation Less Ad Hoc Georges Gonthier Beta Ziliani Aleksandar Nanevski Derek \nDreyer Microsoft Research MPI-SWS IMDEA Software Institute MPI-SWS gonthier@microsoft.com beta@mpi-sws.org \naleks.nanevski@imdea.org dreyer@mpi-sws.org Abstract Most interactive theorem provers provide support \nfor some form of user-customizable proof automation. In a number of popular sys\u00adtems, such as Coq and \nIsabelle, this automation is achieved primar\u00adily through tactics, which are programmed in a separate \nlanguage from that of the prover s base logic. While tactics are clearly useful in practice, they can \nbe dif.cult to maintain and compose because, unlike lemmas, their behavior cannot be speci.ed within \nthe ex\u00adpressive type system of the prover itself. We propose a novel approach to proof automation in \nCoq that al\u00adlows the user to specify the behavior of custom automated routines in terms of Coq s own \ntype system. Our approach involves a sophis\u00adticated application of Coq s canonical structures, which \ngeneralize Haskell type classes and facilitate a .exible style of dependently\u00adtyped logic programming. \nSpeci.cally, just as Haskell type classes are used to infer the canonical implementation of an overloaded \nterm at a given type, canonical structures can be used to infer the canonical proof of an overloaded \nlemma for a given instantiation of its parameters. We present a series of design patterns for canonical \nstructure programming that enable one to carefully and predictably coax Coq s type inference engine into \ntriggering the execution of user-supplied algorithms during uni.cation, and we illustrate these patterns \nthrough several realistic examples drawn from Hoare Type Theory. We assume no prior knowledge of Coq \nand describe the relevant aspects of Coq type inference from .rst principles. Categories and Subject \nDescriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs and Features Data types and struc\u00adtures; \nF.3.1 [Logics and Meanings of Programs]: Specifying and Verifying and Reasoning about Programs Mechanical \nveri.ca\u00adtion; F.4.1 [Mathematical Logic and Formal Languages]: Math\u00adematical Logic Logic and constraint \nprogramming General Terms Languages, Design, Theory, Veri.cation Keywords Interactive theorem proving, \ncustom proof automation, Coq, canonical structures, type classes, tactics, Hoare Type Theory This research \nhas been partially supported by Spanish MICINN Project TIN2010-20639 Paran10; AMAROUT grant PCOFUND-GA\u00ad2008-229599; \nand Ramon y Cajal grant RYC-2010-0743. Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 11, September 19 21, 2011, Tokyo, Japan. Copyright &#38;#169; 2011 \nACM 978-1-4503-0865-6/11/09. . . $10.00 1. Introduction In recent years, interactive theorem proving \nhas been successfully applied to the veri.cation of important mathematical theorems and substantial software \ncode bases. Some of the most signi.cant exam\u00adples are the proof of the Four Color Theorem [8] (in Coq), \nthe ver\u00adi.cation of the optimizing compiler CompCert [17] (also in Coq), and the veri.cation of the operating \nsystem microkernel seL4 [16] (in Isabelle). The abovementioned proof assistants employ higher\u00adorder logics \nand type systems in order to maximize expressiveness and generality, but also to facilitate modularity \nand reuse of veri.\u00adcation effort. However, despite the expressiveness of these theorem provers, effective \nsolutions to some veri.cation problems can often only be achieved by going outside of the provers base \nlogics. To illustrate, consider the following Coq lemma, which natu\u00adrally arises when reasoning about \nheaps and pointer aliasing: noalias : .h:heap. .x1x2:ptr. .v1:A1. .v2:A2. def (x1 . v1 x2 . v2 h) . \nx1 != x2 Here, the type heap classi.es .nite maps from pointers of type ptr to values, h1 h2 is the \ndisjoint union of h1 and h2, and x . v is a singleton heap consisting solely of the pointer x, storing \nthe value v. The disjoint union may be unde.ned if h1 and h2 overlap, so we need a predicate def h, declaring \nthat h is not unde.ned. Consequently, def (h1 h2) holds iff h1 and h2 are disjoint heaps. Finally, the \nconclusion x1 != x2 is in fact a term of type bool, which Coq implicitly coerces to the proposition (x1 \n!= x2)= true. The noalias lemma states that x1 and x2 are not aliased, if they are known to belong to \ndisjoint singleton heaps. Now suppose we want to prove a goal consisting of a number of no-aliasing facts, \ne.g., (x1 != x2) &#38;&#38; (x2 != x3) &#38;&#38; (x3 != x1), under the following hypothesis: D : def \n(i1 (x1 . v1 x2 . v2) (i2 x3 . v3)). Before noalias can be applied to prove, say, x2 != x3, the disjoint \nunion in D will have to be rearranged, so that the pointers x2 and x3 appear at the top of the union, \nas in: ' D: def (x2 . v2 x3 . v3 i1 i2 x1 . v1) Otherwise, the noalias lemma will not apply. Because \n is commu\u00adtative and associative, the rearrangement is sound, but it is tedious to perform by hand, and \nit is not very robust under adaptation. In\u00addeed, if the user goes back and changes the input heap in \nD, a new rearrangement is necessary. Furthermore, the tedium is exacerbated by the need for different \nrearrangements in proving x1 != x2 and x3 != x1. The most effective solution would be for the type checker \nto somehow automatically recognize that the heap expression from D is in fact equivalent to some form \nrequired by noalias. Unfortu\u00adnately, none of the proof assistants that we are aware of provide such automatic \nreasoning primitively. Instead, they typically pro\u00advide a separate language for writing tactics, which \nare customized procedures for solving a class of proof obligations. For example, one can write an auto \nnoalias tactic to solve a goal like x2 != x3 by automatically converting the assumption D into D ' and \nthen applying the noalias lemma. However, while tactics have been de\u00adployed successfully (and with impressive \ndexterity) in a variety of scenarios [6, 7], they are beset by certain fundamental limitations.  The \nprimary drawback of tactics is that they lack the precise typing of the theorem prover s base logic (and \nin the case of Coq, they are essentially untyped). This can make them much more dif.cult to maintain \nthan lemmas, as changes in basic de.nitions do not necessarily raise type errors in the code of the tactics \naffected by the changes. Rather, type checking is performed on the goals obtained during tactic execution, \nresulting in potentially obscure error messages and unpredictable proof states in the case of failure. \nMoreover, the behavior of a tactic typically cannot be speci.ed, nor can it be veri.ed against a speci.cation. \nDue to their lack of precise typing, tactics suffer a second-class status, in the sense that they may \nnot be used as .exibly as lemmas. For example, suppose the pointer (in-)equalities we want to resolve \nare embedded in a larger context, e.g., G : if (x2 == x3) &#38;&#38; (x1 != x2) then E1 else E2 In this \nsituation, we cannot apply the auto noalias tactic directly to reduce (x2 == x3) and (x1 != x2) to false \nand true, respectively, since those (in-)equalities are not the top-level goal. Coq s rewrite primitive \nis designed precisely for this situation it enables one to reduce all (in-)equalities within G that match \nthe conclusion of a particular lemma but it is not applicable to tactics (like auto noalias). Thus, with \nthe auto noalias tactic, we are left with essentially two options: (1) use it to prove a bespoke lemma \nabout one speci.c inequality (say, x1 != x2), perform a rewrite using that lemma, and repeat for other \n(in-)equalities of interest, or (2) implement another custom tactic that crawls over the goal G searching \nfor any and all (in-)equalities that auto noalias might resolve. The former option sacri.ces the bene.ts \nof automation, while the latter option redundantly duplicates the functionality of rewrite. Ideally, \nwe would prefer instead to have a way of writing auto noalias as a lemma rather than a tactic. Had we \nsuch a lemma, we could give it a precisely typed speci.cation, we could rewrite the goal G with it directly, \nand we could also compose it with other lemmas. For instance, we could use ordinary function composition \nto compose it with the standard lemma negbTE : .b:bool. !b = true . b = false, thus transforming auto \nnoalias into a rewrite rule for positive facts of the form (x2 == x3)= false. Consequently, we could \napply rewrite (negbTE (auto noalias D)) to the goal G, thereby reduc\u00ading it to E2. The question of how \nto support automation, while remaining within the .rst-class world of lemmas, is the subject of this \npaper. 1.1 Contributions We propose a novel and powerful approach to proof automation in Coq, which \navoids the aforementioned problems with tactics by allowing one to program custom automated routines \nwithin the ex\u00adpressive dependent type system of Coq itself. In particular, we will be able to rephrase \nthe noalias lemma so that it can automatically analyze its heap-de.nedness hypothesis D in order to derive \nwhat\u00adever valid pointer inequalities are needed, without any manual in\u00adtervention from the user. Our \nproposal is much more general, how\u00adever, and we will illustrate it on a variety of different and signi.\u00adcantly \nmore involved examples than just noalias. Our approach involves a sophisticated application of Coq s \ncanonical structures, which have existed in Coq for quite some time [23], but with sparse documentation \nand (perhaps as a con\u00adsequence) relatively little use. At a high level, canonical structures may be viewed \nas a generalization of Haskell s type classes [28, 13], in the sense that they provide a principled way \nto construct default dictionaries of values and methods and hence support overloading and implicit program \nconstruction as part of the type inference process. However, unlike in Haskell, where the construction \nof canonical instances is keyed solely on the type belonging to a certain type class, instance construction \nin Coq may be keyed on terms as well. This, together with Coq s support for backtracking during type \ninference, enables a very .exible style of dependently-typed logic programming.1 Furthermore, since canonical \nstructures can embed proofs of interesting invariants about the instance .elds being computed, one can \nuse them to implement custom algorithms (in logic-programming style) together with proofs of their (partial) \ncorrectness. Thus, just as Haskell type classes are used to infer the canonical implementation of an \noverloaded term at a given type, canonical structures can be used to infer the canonical proof of an \noverloaded lemma for a given instantiation of its parameters. We feel this constitutes a beautiful application \nof the Curry-Howard correspondence between proofs and programs in Coq. Intuitively, our approach works \nas follows. Suppose we want to write a lemma whose application may need to trigger an auto\u00admated solution \nto some subproblem (e.g., in the case of noalias, the problem of testing whether two pointers x1 and \nx2 appear in dis\u00adjoint subheaps of the heap characterized by the heap-de.nedness hypothesis D). In this \ncase, we de.ne a structure (like a type class) to encapsulate the problem whose solution we wish to automate, \nand we encode the algorithm for solving that problem along with its proof of correctness in the canonical \ninstances of the structure. Then, when the lemma is applied to a particular goal, uni.cation of the goal \nwith the conclusion of the lemma will trigger the construc\u00adtion of a canonical instance of our structure \nthat solves the automa\u00adtion problem for that goal. For example, if auto noalias is the over\u00adloaded version \nof noalias, and we try to apply (auto noalias D) to the goal of proving x2 != x3, type inference will \ntrigger con\u00adstruction of a canonical instance proving that the heap character\u00adized by D contains bindings \nfor x2 and x3 in two disjoint sub\u00adheaps. (This is analogous to how the application of an overloaded function \nin Haskell triggers the construction of a canonical dictio\u00adnary that solves the appropriate instantiation \nof its type class con\u00adstraints.) Although we have described the approach here in terms of backward reasoning, \none may also apply overloaded lemmas using forward reasoning, as we will see in Section 5. Key to the \nsuccess of our whole approach is the Coq type in\u00adference engine s use of syntactic pattern-matching in \ndetermining which canonical instances to apply when solving automation prob\u00adlems. Distinguishing between \nsyntactically distinct (yet semanti\u00adcally equivalent) terms and types is essential if one wishes to sim\u00adulate \nthe automation power of tactics. However, it is also an aspect of our approach that Coq s type system \ncannot account for because it does not observe such syntactic distinctions. Fortunately, our re\u00adliance \non Coq s uni.cation algorithm for analysis of syntax is the only aspect of our approach that resides \noutside of Coq s type sys\u00adtem, unlike tactics, which are wholly extra-linguistic. Perhaps the greatest \nchallenge in making our approach .y is in developing effective and reliable ways of circumventing certain \n1 It is folklore that one can simulate logic programming to some extent using Haskell s multi-parameter \nclasses with functional dependencies [15] or with associated types [5], but Haskell s lack of support \nfor backtracking during type inference limits what kinds of logic programming idioms are possible.  \ninherent restrictions of Coq s canonical structures, which were not designed with our ambitious application \nin mind. In particular, in order to implement various useful forms of automation using canonical structures, \nit is critically important to be able to write overlapping instances, but also to control the order in \nwhich they are considered and the order in which uni.cation subproblems are solved. None of these features \nare supported primitively, but they are encodable using a series of simple design patterns , which form \nthe core technical contribution of this paper. We illustrate these patterns through several realistic \nexamples involving reasoning about heaps, pointers and aliasing. All of these examples have been implemented \nand tested in the context of Hoare Type Theory (HTT) [19], where they have replaced often-used tactics. \nThe code in this paper and HTT itself is built on top of Ssre.ect [10], which is a recent extension of \nCoq providing a very robust language of proofs, as well as libraries for re.ection\u00adbased reasoning. However, \nin the current paper, we assume no prior knowledge of Coq, Ssre.ect, or canonical structures them\u00adselves. \nWe will remain close, but not adhere strictly, to the Coq notation and syntax. All of our sources are \navailable on the web at http://www.mpi-sws.org/~beta/lessadhoc. 2. Basics of Canonical Structures In \nthis section, we provide a quick introduction to the basics of canonical structure programming, leading \nup to our .rst important design pattern tagging which is critical for supporting order\u00ading of overlapping \ninstance declarations. 2.1 Type Class Programming In the literature and everyday use of Coq, the word \nstructure is used interchangeably (and confusingly) to mean both dependent records and the types they \ninhabit. To disambiguate, in this paper we use structure for the type, instance for the value, and canonical \ninstance for a canonical value of a certain type. We will use the term canonical structures only when \nreferring generally to the use of all of these mechanisms in tandem. The following de.nition is a simpli.ed \nexample from a struc\u00adture (i.e., type) taken from the standard Ssre.ect library [10]: structure eqType \n:= EqType {sort : Type; equal : sort . sort . bool; : .xy : sort. equal xy . x = y} The de.nition makes \neqType a record type, with EqType as its constructor, taking three arguments: a type sort, a boolean \nbinary operation equal on sort, and a proof that equal decides the equality on sort. For example, one \npossible eqType instance for the type bool, may be eqType bool := EqType bool eq bool pf bool where eq \nbool xy := (x &#38;&#38; y) || (!x &#38;&#38; !y), and pf bool is a proof, omitted here, that .xy : bool. \neq bool xy . x = y. The labels for the record .elds serve as projections out of the record, so the de.nition \nof eqType also introduces the constants: sort : eqType . Type equal : .T :eqType. sort T . sort T . bool \nWe do not care to project out the proof component of the record, so we declare it anonymous by naming \nit with an underscore. Notational Convention 1. We will usually omit the argument T of equal, and write \nequal xy instead of equal T xy, as T can be inferred from the types of x and y. We use the same convention \nfor other functions as well, and make implicit such arguments that can be inferred from the types of \nother arguments. This is a standard notational convention in Coq. It is also very useful to de.ne generic \ninstances. For example, consider the eqType instance for the pair type A \u00d7 B, where A and B are themselves \ninstances of eqType: eqType pair (AB : eqType) := EqType (sort A \u00d7 sort B)(eq pair AB)(pf pair AB) where \neq pair (AB : eqType)(uv : sort A \u00d7 sort B) := equal (p1 u)(p1 v) &#38;&#38; equal (p2 u)(p2 v) and pf \npair is omitted as before. Declaring both eqType bool and eqType pair now as canoni\u00adcal instances using \nCoq s canonical keyword will have the fol\u00adlowing effect: whenever the type checker is asked to type a \nterm like equal (b1,b2)(c1,c2), where b1,b2,c1 and c2 are of type bool, it will generate a uni.cation \nproblem of the form sort ?T .bool \u00d7 bool = for some uni.cation variable ?T , generated implicitly at \nthe ap\u00adplication of equal. It will then try to solve this problem using the canonical instance eqType \npair, resulting in two new uni.cation subproblems, for fresh uni.cation variables ?A and ?B: sort ?A \n.bool sort ?B .bool == Next, it will choose ?A =.eqType bool and ?B = .eqType bool, with the .nal result \nthat equal (b1,b2)(c1,c2) reduces implicitly to eq bool b1 c1 &#38;&#38; eq bool b2 c2, as one would \nexpect. In this manner, canonical instances can be used for overloading, similar to the way type classes \nare used in Haskell [28, 13].2 We can declare a number of canonical eqType instances, for various prim\u00aditive \ntypes, as well as generic instances for type constructors (like the pair example above). Then we can \nuniformly write equal xy, and the typechecker will compute the canonical implementation of equality at \nthe types of x and y by solving for equal s implicit ar\u00adgument T . Generalizing from eqType to arbitrary \nstructures S, the declara\u00adtion of an instance V : S as canonical instructs the typechecker that for each \nprojection proj of the structure S, and c the head symbol of proj V , the unknown X in the uni.cation \nequation proj X .cx1 ...xn = (*) should by default be solved by unifying X .V . For instance, in = the \ncase of eqType pair, the projector proj is sort, the head constant c is (\u00b7\u00d7\u00b7), and the head constant \narguments x1 ...xn are bool and bool. We emphasize that: (1) to control the number of such default facts, \nwe will frequently anonymize the projections if they are not important for the application, as in the \ncase of the proof in eqType above; and (2) there can only be one speci.ed default solution for any given \nproj and c (i.e., overlapping canonical instances are not permitted). As we will see shortly, however, \nthere is a simple design pattern that will allow us to circumvent this limitation.  2.2 Logic Programming \nAlthough the eqType example is typical of how canonical struc\u00adtures are used in much existing Coq code, \nit is not actually repre\u00adsentative of the style of canonical structure programming that we explore in \nthis paper. Our idiomatic style is closer in .avor to logic programming and relies on the fact that, \nunlike in Haskell, the con\u00adstruction of canonical instances in Coq can be guided not only by the structure \nof types (such as the sort projection of eqType) but by the structure of terms as well. 2 It is worth \nnoting that Coq also provides a built-in type class mechanism, but this feature is independent of canonical \nstructures. We discuss Coq type classes more in Section 7.  To make matters concrete, let s consider \na simple automation task, one which we will employ gainfully in Section 3 when we present our .rst overloaded \nlemma . We will .rst present a na\u00a8ive approach to solving the task, which almost works; the manner in \nwhich it fails will motivate our .rst design pattern (Section 2.3). The task is as follows: search for \na pointer x in a heap h. If the search is successful, that is, if h is of the form \u00b7\u00b7\u00b7 (\u00b7\u00b7\u00b7 x . v \u00b7 \u00b7\u00b7 \n) \u00b7 \u00b7\u00b7 , then return a proof that x . dom h. To solve this task using canonical structures, we will .rst \nde.ne a structure .nd: structure .nd x := Find {heap of : heap; : invariant x heap of} where invariant \nis de.ned as invariant xh := def h . x . dom h The .rst thing to note here is that the structure .nd \nis parameterized by the pointer x (causing the constructor Find to be implicitly parameterized by x as \nwell). This is a common idiom in canonical structure programming and we will see that structure parameters \ncan be used for various different purposes but here x may be viewed simply as an input to the automation \ntask. The second thing to note here is that the structure has no type component, only a heap of projection, \ntogether with a proof that x . dom heap of (under the assumption that heap of is well-de.ned). The search \ntask will commence when some input heap h gets uni.ed with heap of X for an unknown X : .nd x, at which \npoint Coq s uni.cation algorithm will recursively deconstruct h in order to search for a canonical implementation \nof X such that heap of X = h. If that search is successful, the last .eld of X will be a proof of invariant \nxh, which we can apply to a proof of def h to obtain a proof of x . dom h, as desired. (By way of analogy, \nthis is similar to what we previously used for eqType pair. The construction of a canonical equality \noperator at a given type A will commence when A is uni.ed with sort T for an unknown T : eqType, and \nthe uni.cation algorithm will proceed to solve for T by recursively deconstructing A and composing the \nrelevant canonical instances.) The structure .nd provides a formal speci.cation of what a successful \ncompletion of the search task will produce, but now we need to actually implement the search. We do that \nby de.ning several canonical instances of .nd corresponding to the different cases of the recursive search, \nand relying on Coq s uni.cation algorithm to actually implement the recursion: canonical found struct \nAx (v : A) := Find x (x . v)(found pf Axv) canonical left struct xh (f : .nd x) := Find x ((heap of f) \n h)(left pf xhf) canonical right struct xh (f : .nd x) := Find x (h (heap of f)) (right pf xhf) Note \nthat the .rst argument to the constructor Find in these in\u00adstances is the parameter x of the .nd structure. \nThe .rst instance, found struct, corresponds to the case where the heap of projection is a singleton \nheap whose domain contains precisely the x we re searching for. (If the heap is y . v for y = x, then \nuni.cation fails.) The second and third instances, left struct and right struct, handle the cases where \nthe heap of projection is of the form h1 h2, and x is in the domain of h1 or h2, respectively. Note that \nthe recursive nature of the search is implicit in the fact that the latter two instances are parameterized \nby instances f : .nd x whose heap of projections are uni.ed with the subheaps h1 or h2 of the original \nheap of projection. Notational Convention 2. In the declarations above, found pf, left pf and right pf \nare proofs, witnessing that invariant relates x and the appropriate heap expression. We omit the proofs \nhere, but they are available in our source .les. From now on, we omit writing such explicit proofs in \ninstances, and simply replace them with ... , as in: Find x ((heap of f) h) ... Unfortunately, this \nset of canonical instances does not quite work. The trouble is that left struct and right struct are \nover\u00adlapping instances since both match against the same head symbol (namely, ), and overlapping instances \nare not permitted in Coq. Moreover, even if overlapping instances were permitted, we would still need \nsome way to tell Coq that it should try one instance .rst and then, if that fails, to backtrack and try \nanother. Consequently, we need some way to deterministically specify the order in which overlapping instances \nare to be considered. For this, we introduce our .rst design pattern.  2.3 Tagging: A Technique for \nOrdering Canonical Instances Our approach to ordering canonical instances is, in programming terms, remarkably \nsimple. However, understanding why it actually works is quite tricky because its success relies critically \non an aspect of Coq s uni.cation algorithm that diverges signi.cantly from how uni.cation works in, say, \nHaskell. We will thus .rst illustrate the pattern concretely in terms of our .nd example, and then explain \nafterwards how it solves the problem. The Pattern First, we de.ne a tagged version of the type of thing \nwe re recursively analyzing in this case, the heap type: structure tagged heap := Tag {untag : heap} \nThis structure declaration also introduces two functions witnessing the isomorphism between heap and \ntagged heap: Tag : heap . tagged heap untag : tagged heap . heap Then, we modify the .nd structure to \ncarry a tagged heap instead of a plain heap, i.e., we declare invariant x (h : tagged heap) := def (untag \nh) . x . dom (untag h) structure .nd x := Find {heap of : tagged heap; : invariant x heap of} Next, \nwe de.ne a sequence of synonyms for Tag, one for each canonical instance of .nd. Importantly, we de.ne \nthe tag synonyms in the reverse order in which we want the canonical instances to be considered during \nuni.cation, and we make the last tag synonym in the sequence be the canonical instance of the tagged \nheap struc\u00adture itself. (The order doesn t matter much in this particular exam\u00adple, but it does in other \nexamples in the paper.) right tag h := Tag h left tag h := right tag h canonical found tag h := left \ntag h Finally, we modify each canonical instance so that its heap of projection is wrapped with the corresponding \ntag synonym. canonical found struct Ax (v : A) := Find x (found tag (x . v)) ... canonical left struct \nxh (f : .nd x) := Find x (left tag ((untag (heap of f)) h)) ... canonical right struct xh (f : .nd x) \n:= Find x (right tag (h (untag (heap of f)))) ...  The Explanation The key to the tagging pattern is \nthat, by em\u00adploying different tags for each of the canonical instance declara\u00adtions, we are able to syntactically \ndifferentiate the head constants of the heap of projections, thereby circumventing the need for over\u00adlapping \ninstances. But the reader is probably wondering: (1) how can semantically equivalent tag synonyms differentiate \nanything? and (2) what s the deal with de.ning them in the reverse order? The answer to (1) is that Coq \ndoes not unfold all de.nitions automatically during uni.cation it only unfolds the de.nition of a term \nlike found tag h automatically if that term is uni.ed with something else and the uni.cation fails (see \nthe next paragraph). This stands in contrast to Haskell type inference, which implic\u00aditly expands all \n(type) synonyms right away. Thus, even though found tag, left tag, and right tag are all semantically \nequivalent to Tag, the uni.cation algorithm can distinguish between them, rendering the three canonical \ninstances of .nd non-overlapping. The answer to (2) is as follows. By making the last tag syn\u00adonym found \ntag the sole canonical instance of tagged heap, we guarantee that uni.cation always pattern-matches against \nthe found struct case of the search algorithm .rst before any other. To see this, observe that the execution \nof the search for x in h will get triggered when a uni.cation problem arises of the form untag (heap \nof ?f)= h, for some unknown ?f : .nd x. Since found tag is canonical, the problem will be reduced to \nunifying heap of ?f = found tag h. As found struct is the only canonical instance of .nd whose heap of \nprojection has found tag as its head constant, Coq will .rst attempt to unify ?f with some instantiation \nof found struct. If h is a singleton heap containing x, then the uni.cation will succeed. Otherwise, \nCoq will backtrack and try unfolding the de.nition of found tag h instead, resulting in the new uni.cation \nproblem heap of ?f = left tag h, which will in turn cause Coq to try unifying ?f with some instantia\u00adtion \nof left struct. Again, if that fails, left tag h will be unfolded to right tag h and Coq will try right \nstruct. If in the end that fails as well, then it means that the search has failed to .nd x in h, and \nCoq will correctly .ag the original uni.cation problem as unsolvable. 3. A Simple Overloaded Lemma Let \nus now attempt our .rst example of lemma overloading, which makes immediate use of the .nd structure \nthat we developed in the previous section. First, here is the un-overloaded version: indom : .x:ptr. \n.v:A. .h:heap. def (x . v h) . x . dom (x . v h) The indom lemma is somewhat simpler than noalias from \nSec\u00adtion 1, but the problems in applying them are the same neither lemma is applicable unless its heap \nexpressions are of a special syntactic form, with the relevant pointer(s) at the top of the heap. To \nlift this restriction, we will rephrase the lemma into the following form: indomR : .x:ptr. .f:.nd x. \ndef (untag (heap of f)) . x . dom (untag (heap of f)) The lemma is now parameterized over an instance \nf of structure .nd x, which we know just according to the de.nition of .nd alone contains within it a \nheap h = untag (heap of f), together with a proof of def h . x . dom h. Based on this, it should come \nas no surprise that the proof of indomR is trivial (it s a half-line long in Ssre.ect). In fact, the \nlemma is really just the projection function corresponding to the unnamed invariant component from the \n.nd structure, much as the overloaded equal function from Section 2.1 is a projection function from the \neqType structure. To demonstrate the automated nature of indomR on a concrete example, we will walk in \ndetail through the trace of Coq type inference when indomR is applied to prove the goal z . dom h in \na context where xyz : ptr, uvw : A, h : heap := x . u y . v z . w, and D : def h. When indomR is applied, \nits formal pa\u00adrameters are turned into uni.cation variables ?x and ?f : .nd ?x, which will be constrained \nby the uni.cation process. (Hereafter, we will use ? to denote uni.cation variables, with previously \nunused ?x s denoting fresh uni.cation variables.) As a .rst step, the system tries to unify ?x . dom \n(untag (heap of ?f )) = z . dom h getting ?x = z, and, then untag (heap of ?f)= h By canonicity of found \ntag, we need to solve heap of ?f = found tag h Uni.cation tries to instantiate ?f with found struct, \nbut for that it must unify the entire heap h with z .?v, which fails. Before giving up, the system realizes \nit can unfold the de.nitions of h and of found tag, yielding, as is left-associative, heap of ?f = left \ntag ((x . u y . v) z . w) (1) Now, left struct can be used for ?f , and the following uni.cation problems \neventually arise: untag (heap of ?f2)= x . u y . v ?h = z . w ?f = left struct z ?h ?f2 Attempting to \nsolve the .rst equation, the system again applies found tag and found struct. As before, it fails, unfolds \nfound tag to get left tag, then attempts left struct to get untag (heap of ?f3)= x . u, It can now apply \nfound tag and found struct to .nally fail, be\u00adcause z does not match x. Rolling back, it unfolds left \ntag to right tag, matches z with y, fails again, and rolls back to the equa\u00adtion (1). At this point it \nunfolds left tag to right tag, resulting in heap of ?f = right tag (x . u y . v z . w), then chooses \nright struct to eventually obtain ?h ' = x . u y . v untag (heap of ?f2' )= z . w ?f = right struct \nz ?h ' ?f2 ' The .rst equation uni.es immediately, after which the second one is solved by applying found \ntag and choosing found struct for ?f2' . After that, the third equation also uni.es right away. 4. Re.ection: \nTurning Semantics into Syntax As canonical structures are closely coupled with the type checker, it is \npossible to fruitfully combine the logic-programming idiom afforded by canonical structures together \nwith ordinary functional programming in Coq. In this section, we illustrate the combina\u00adtion by developing \na thoroughly worked example of an overloaded lemma for performing cancellation on heap equations. In \nour im\u00adplementation of Hoare Type Theory, this lemma is designed to re\u00adplace an often used, but rather \ncomplicated and brittle, tactic.  Mathematically, cancellation merely involves removing com\u00admon terms \nfrom disjoint unions on the two sides of a heap equation. For example, if we are given an equation x \n. v1 (h3 h4)= h4 x . v2 and we know that the heaps are disjoint (i.e., the unions are de\u00ad.ned), then \nwe can extract the implied equations v1 = v2 . h3 = empty We will implement the lemma in two stages. \nThe .rst stage is a canonical structure program, which re.ects the equation, that is, turns the equation \non heap expressions into an abstract syntax tree (or abstract syntax list, as it will turn out). Then \nthe second stage is a functional program, which cancels common terms from the syntax tree. Notice that \nthe functional program from the second stage cannot work directly on the heap equation for two reasons: \n(1) it needs to compare heap and pointer variable names, and (2) it needs to pattern match on function \nnames, since in HTT heaps are really partial maps from locations to values, and . and are merely convenient \nfunctions for constructing them. As neither of these is possible within Coq s base logic, the equation \nhas to be re.ected into syntax in the .rst stage. The main challenge then is in implementing re.ection, \nso that the various occurrences of one and the same heap variable or pointer variable in the equation \nare ascribed the same syntactic representation. Cancellation Since the second stage is simpler, we explain \nit .rst. For the purposes of presentation, we restrict our pointers to only store values of some predetermined \ntype T (although the actual implementation in our source .les is more general). The data type that we \nuse for syntactic representation of heap expressions is then the following: elem := Var of nat | Pts \nof nat &#38; T term := seq elem An element of type elem identi.es a heap component as being either a \nheap variable or a points-to clause x . v. In the .rst case, the component is represented as Var n, where \nn is a number identifying the heap variable in the style of de Bruijn indices; that is, as an index into \nsome environment (to be explained below). In the second case, the component is represented as Pts mv, \nwhere m is a number identifying the pointer variable in an environment. We do not perform any re.ection \non v, as it is not necessary for the cancellation algorithm. A heap expression is then represented via \nterm as a list (seq) of elements. We could have represented the original heap expression more faithfully \nas a tree, but since is commutative and associative, lists suf.ce for our purposes. We will require \ntwo kinds of environments, which we package into the type of contexts: ctx := seq heap \u00d7 seq ptr The \n.rst component of a context is a list of heaps. In a term re.ecting a heap expression, the element Var \nn stands for the n\u00adth element of this list. Similarly, the second component is a list of pointers, and \nin the element Pts mv, the number m stands for the m-th pointer in the list. Because we will need to \nverify that our syntactic manipulation preserves the semantics of heap operations, we need a function \nthat interprets syntax back into semantics. Assuming lookup functions hlook and plook which search for \nan index in a context of a heap or pointer, respectively, the interpretation function crawls over the \nsyntactic term, replacing each number index with its value from the context (and returning an unde.ned \nheap, if the index is out of cancel (i : ctx)(t1 t2 r : term): Prop := match t1 with nil . interp ir \n= interp it2 ' | Pts mv :: t1 . if premove mt2 is Some (v ' ,t 2' ) then cancel it ' 1 t2 ' r . v = v \n' else cancel it ' 1 t2 (Pts mv :: r) ' | Var n :: t1 . if hremove nt2 is Some t2 ' then cancel it ' \n1 t2 ' r else cancel it ' 1 t2 (Var n :: r) end Figure 1. Heap cancellation algorithm. bounds). The function \nis implemented as follows: interp (i : ctx)(t : term): heap := match t with Var n :: t ' . if hlook in \nis Some h then h interp it ' else Undef | Pts mv :: t ' . if plook im is Some x then x . v interp it \n' else Undef | nil . empty end For example, if the context i is ([h3,h4], [x]), then interp i [Pts 0 \nv1, Var 0, Var 1] = x . v1 (h3 (h4 empty)) interp i [Var 1, Pts 0 v2]= h4 (x . v2 empty) Given this \nde.nition of term, we can now encode the cancel\u00adlation algorithm as a predicate (i.e., a function into \nProp) in Coq (Figure 1). The predicate essentially constructs a conjunction of the residual equations \nobtained as a consequence of cancellation. Referring to Figure 1, the algorithm works as follows. It \nlooks at the head element of the left term t1, and tries to .nd it in the right term t2 (keying on the \ndeBruijn index of the element). If the el\u00adement is found, it is removed from both sides, before recursing \nover the rest of t1. When removing a Pts element keyed on a pointer x, the values v and v ' stored into \nx in t1 and t2 must be equal. Thus, the proposition computed by cancel should contain an equation between \nthese values as a conjunct. If the element is not found in t2, it is shuf.ed to the accumulator r, before \nrecurs\u00ading. When the term t1 is exhausted, i.e., it becomes the empty list, then the accumulator stores \nthe elements from t1 that were not can\u00adcelled by anything in t2. The equation between the interpretations \nof r and t2 is a semantic consequence of the original equation, so cancel immediately returns it (our \nactual implementation performs some additional optimization before returning). The helper func\u00adtion premove \nmt2 searches for the occurrences of the pointer in\u00addex m in the term t2, and if found, returns the value \nstored into the pointer, as well as the term t ' 2 obtained after removing m from t2. Similarly, hremove \nnt2 searches for Var n in t2 and if found, returns t2 ' obtained from t2 after removal of n. Soundness \nof cancel is established by the following lemma which shows that the facts computed by cancel indeed \ndo follow from the input equation between heaps, when cancel is started with the empty accumulator. cancel \nsound : .i : ctx. .t1 t2 : term. def (interp it1) . interp it1 = interp it2 . cancel it1 t2 nil. The \nproof of cancel sound is rather involved so we omit it here, but it can be found in our source .les. \nWe could have proved the converse direction as well, to obtain a completeness result, but this was not \nnecessary for our purposes.  The related work on proofs by re.ection usually implements the cancellation \nphase in a manner similar to above (see for example the work of Gr\u00b4 egoire et al. [12]). Where we differ \nfrom the related work is the implementation of the re.ection phase. This phase is usually implemented \nby a tactic, but here we show that it can be implemented with canonical structures instead. Re.ection \nvia Canonical Structures Intuitively, the re.ection al\u00adgorithm traverses a heap expression, and produces \nthe correspond\u00ading syntactic term. In our overloaded lemma, presented further be\u00adlow, we will invoke \nthis algorithm twice, to re.ect both sides of the equation. To facilitate cancellation, we need to ensure \nthat identical variables on the two equation sides, call them E1 and E2, are repre\u00adsented by identical \nsyntactic elements. Therefore, re.ection of E1 has to produce a context of newly encountered elements \nand their syntactic equivalents, which is then fed as an input to the re.ection of E2. If re.ection of \nE2 encounters an expression which is already in the context, the expression is re.ected with the syntactic \nelement provided by the context. Notational Convention 3. Hereafter, projections out of an in\u00adstance \nare considered implicit coercions, and we will typically omit them from our syntax. For example, in Figure \n2 (described below), the canonical instance union struct says union tag(f1 f2) instead of union tag((untag \n(heap of f1)) (untag (heap of f2))), which is signi.cantly more verbose. This is a standard technique \nin Coq. The re.ection algorithm is encoded using the structure ast from Figure 2. The inputs to each \ntraversal are the initial context i of ast, and the initial heap in the heap of projection. The output \nis the (potentially extended) context j and the syntactic term t that re.ects the initial heap. One invariant \nof the structure is precisely that the term t, when interpreted under the output heap j, re.ects the \ninput heap: interp jt = heap of There are additional invariants too, which are necessary to carry out \nthe proofs, but we omit them here for brevity; they can be found in our source .les. There are several \ncases to consider during a traversal, as shown by the canonical instances in Figure 2. We .rst check \nif the in\u00adput heap is a union, as can be seen from the (as usual, reverse) ordering of tag synonyms. \nIn this case, the canonical instance is union struct. The instance speci.es that we recurse over both \nsub\u00adheaps, by unifying the left subheap with f1 and the right subheap with f2. The types of f1 and f2 \nshow that the two recursive calls work as follows. First the call to f1 starts with the input context \ni and computes the output context j and term t1. Then the call to f2 proceeds with input context j, and \ncomputes outputs k and t2. The output context of the whole union is k, and the output re.ected term is \nthe list-concatenation of t1 and t2. When re.ecting the empty heap, the instance is empty struct. In \nthis case, the input context i is simply passed as output, and the re.ected term is the empty list. When \nre.ecting a singleton heap x . v, the corresponding instance is ptr struct. In this case, we .rst have \nto check if x is a pointer that already appears in the pointer part xs1 of the input context. If so, \nwe should obtain the index m at which x appears in xs1. This is the number representing x, and the returned \nre.ected elem is Pts mv. On the other hand, if x does not appear in xs1, we need to add it. We compute \na new context xs2 which appends x at the end of xs1, and this is the output pointer context for ptr struct. \nThe number m representing x in xs2 now equals the size of xs2, and returned re.ected elem is again Pts \nmv. Similar var tag h := Tag h pts tag h := var tag h empty tag h := pts tag h canonical union tag h \n:= empty tag h structure ast (ij : ctx)(t : term) := Ast {heap of : tagged heap; : interp jt = heap of \n. ...} canonical union struct (ijk : ctx)(t1 t2 : term) (f1 : ast ijt1)(f2 : ast jkt2) := Ast ik (append \nt1 t2)(union tag (f1 f2)) ... canonical empty struct (i : ctx) := Ast ii nil (empty tag empty) ... canonical \npts struct (hs : seq heap)(xs1 xs2 : seq ptr) (m : nat)(v : A)(f : x.nd xs1 xs2 m) := Ast (hs, xs1)(hs, \nxs2)[Pts mv](pts tag (f . v)) ... canonical var struct (hs1 hs2 : seq heap)(xs : seq ptr) (n : nat)(f \n: x.nd hs1 hs2 n) := Ast (hs1, xs)(hs2, xs)[Var n](var tag f) ... Figure 2. Structure ast for re.ecting \na heap. structure xtagged A := XTag {xuntag : A} extend tag A (x : A) := XTag x recurse tag A (x : A) \n:= extend tag x canonical found tag A (x : A) := recurse tag x structure x.nd A (sr : seq A)(i : nat) \n:= XFind {elem of : xtagged A; : index ri = elem of . ...} canonical found struct A (x : A)(s : seq A) \n:= XFind (x :: s)(x :: s)0(found tag x) ... canonical recurse struct (i : nat)(y : A)(sr : seq A) (f \n: x.nd sri) := XFind (y :: s)(y :: r)(i +1) (recurse tag f) ... canonical extend struct A (x : A) := \nXFind nil [x]0(extend tag x) ... Figure 3. Structure x.nd for searching for an element in a list; appending \nthe element at the end if not found. considerations apply in the case when we are re.ecting a heap variable \nh. The instance is then var struct and we search in the heap portion of the context hs1, producing a \nnew heap portion hs2. In both cases, the task of searching and extending the context is performed by \nthe polymorphic structure x.nd (Figure 3), which re\u00adcurses over the context lists in search of an element, \nrelying on uni\u00ad.cation to make syntactic comparisons between expressions. The inputs to the structure \nare the parameter s which is the sequence to search in, and the .eld elem of, which is the (tagged) element \nto search for. The output sequence r equals s if elem of is not in s, or extends s with elem of otherwise. \nThe output parameter i is the position at which the elem of is found in r.  If the searched element \nx appears at the head of the list, the selected instance is found struct and the index i =0. Otherwise, \nwe recurse using recurse struct. Ultimately, if s is empty, the returned r is the singleton [x], via \nthe instance extend struct. It may be interesting to notice here that while x.nd is in prin\u00adciple similar \nto .nd from Section 2.3, it is keyed on the element being searched for, rather than on the list (or in \nthe case of .nd, the heap) in which the search is being performed. This exempli.es that there are many \nways in which canonical structures of similar func\u00adtionality can be organized. In particular, which term \none keys on (i.e., which term one uni.es with the projection from the structure) may in general depend \non when a certain computation needs to be triggered. If we reorganized x.nd to match .nd in this respect, \nthen the structure ast would have to be reorganized too. Speci.cally, ast would have to recursively invoke \nx.nd by unifying it against the contexts xs1 and hs1 in the instances pts struct and var struct, respectively. \nAs we will argue in Section 6, such uni.cation leads to incorrect results, if done directly, but we will \nbe able to perform it indirectly, using a new design pattern. Now we can present the overloaded lemma \ncancelR. cancelR : .jk : ctx. .t1 t2 : term. .f1 : ast nil jt1. .f2 : ast jkt2. def (untag (heap of f1)) \n. untag (heap of f1)= untag (heap of f2) . cancel kt1 t2 nil Assuming we have a hypothesis h1 h2 . . \n H : x . v1 (h3 h4)= h4 x . v2 and a hypothesis D : def h1, we can apply move/(cancelR D): H. This \nwill make Coq .re the following uni.cation problems: 1. def (untag (heap of ?f1)) = def h1 2. untag \n(heap of ?f1)) = h1 3. untag (heap of ?f2)) = h2  Because f1 and f2 are variable instances of the structure \nast, Coq will construct canonical values for them, thus re.ecting the heaps into terms t1 and t2, respectively. \nThe re.ection of h1 will start with the empty context, while the re.ection of h2 will start with the \noutput context of f1, which in this case is ([h3,h4], [x]). Finally, the lemma will perform cancel on \nt1 and t2 to produce v1 = v2 . h3 = empty . empty = empty. The trailing empty = empty can ultimately \nbe removed with a few simple optimizations of cancel, which we omitted to simplify the presentation. \n5. Solving for Functional Instances Previous sections described examples that search for a pointer in \na heap expression or for an element in a list. The pattern we show in this section requires a more complicated \nsearch and replace functionality, and we describe it in the context of our higher-order implementation \nof separation logic [22] in Coq. Interestingly, this search-and-replace pattern can also be described \nas higher-order, as it crucially relies on the typechecker s ability to manipulate .rst\u00adclass functions \nand solve uni.cation problems involving functions. To set the stage, the formalization of separation \nlogic that we use centers on the predicate verify : prog A . heap . (A . heap . Prop) . Prop. The exact \nde.nition of verify is not important for our purposes here, but it suf.ces to say that it encodes a form \nof Hoare-style triples. Given a program e : prog A returning values of type A, an input heap i : heap, \nand a postcondition q : A . heap . Prop over A-values and heaps, the predicate verify eiq holds if executing \ne in heap i is memory-safe, and either diverges or terminates with a value y and heap m, such that qym \nholds. Programs can perform the basic heap operations: reading and writing a heap location, allocation, \nand deallocation. In this section, we focus on the writing primitive; given x : ptr and v : A, the program \nwrite xv : prog unit stores v into x and terminates. We also require the operation for sequential composition, \nwhich takes the form of monadic bind: bind : prog A . (A . prog B) . prog B. We next consider the following \nprovable lemma, which serves as a Floyd-style rule for symbolic evaluation of write. bnd write : verify \n(e ()) (x . v h) q . verify (bind (write xv) e)(x . w h) q To verify write xv in a heap x . w h, it \nsuf.ces to change the contents of x to v, and proceed to verify the continuation e. In practice, bnd \nwrite suffers from the same problem as indom and noalias, as each application requires bringing the pointer \nx to the top of the heap. We would like to devise an automated version bnd writeR, but, unlike indomR, \napplication of bnd writeR cannot merely check if a pointer x is in the heap. It needs to remember the \nheap from the goal, and reproduce it in the premise, only with the contents of x changed from w to v. \nFor example, applying bnd writeR to the goal G1 : verify (bind (write x2 4) e) (i1 (x1 . 1 x2 . 2) \n (i2 x3 . 3)) q should return a subgoal which changes x2 in place, as in: G2 : verify (e ()) (i1 (x1 \n. 1 x2 . 4) (i2 x3 . 3)) q. The Pattern Here is where functions come in. The bnd writeR lemma should \nattempt to infer a function f which represents a heap with a hole , so that .lling the hole with x . \nw (i.e., computing f (x . w)), obtains the heap from the goal. Then replacing w with v is computed as \nf (x . v). For example, in G1 we want to .ll the hole with x . 2, while in G2, we want to .ll it with \nx . 4. Hence, in this case, the inferred function f should, intuitively, be: fun k. i1 (x1 . 1 k) \n(i2 x3 . 3). The function f therefore takes an input heap k, but it should not merely produce an output \nheap. Instead, we want f s range to be a structure, called here partition kr (Figure 4). A projection \nheap of out of this structure will be used to trigger the search for the subheap that should be replaced \nwith a hole. For technical reasons, partition has an additional heap param\u00adeter r, whose role will be \nexplained later. Because the range of f depends on the input k, f must have a dependent function type, \nand the bnd writeR lemma looks as below. For clarity, we use . to dis\u00adtinguish a function, even when \nCoq does not make that distinction. bnd writeR : .r : heap. .f : (.k : heap. partition kr). verify (e \n()) (f (x . v)) q . verify (bind (write xv) e)(f (x . w)) q We have omitted the projections and written \nf (x . w) instead of untag (heap of (f (x . w))), and similarly in the case of x . v. When the bnd writeR \nlemma is applied to a verify goal with a heap h, the type checker attempts to unify untag (heap of (?f \n(x . w))) = h.  structure tagged heap := Tag {untag : heap} right tag (h : heap) := Tag h left tag h \n:= right tag h canonical found tag h := left tag h structure partition (kr : heap) := Partition {heap \nof : tagged heap; : heap of = k r} canonical found struct k := Partition k empty (found tag k) ... canonical \nleft struct hr (f :.k. partition kr) k := Partition k (r h)(left tag (fk h)) ... canonical right struct \nhr (f :.k. partition kr) k := Partition k (h r)(right tag (h fk)) ... Figure 4. Structure partition \nfor partitioning a heap into two parts: the part matching k, and the rest (r). The instances in Figure \n4 are designed so that the canonical solution f will have the property that the heap component of f (x \n. w) syntactically equals h, matching exactly the order and the paren\u00adthesization of the summands in \nh. We have three instance selectors: one for the case where we found the heap we are looking for, and \ntwo to recurse over each side of the . The reader may wonder why all the instances of partition take \nthe k parameter last, thus forcing the f parameter in the latter two instances to be itself abstracted \nover k as well. The reason is simple. The last step in solving the above uni.cation goal will be to unify \n?f (x . w) with whatever canonical structure is ultimately computed. For example, if h = h0 x . w, then \nthe last step of uni.cation will resolve the following goal: ?f (x . w)= right struct h0 empty found \nstruct (x . w). Coq s uni.cation will reduce to subgoals involving the structural components of the applications: \n?f = right struct h0 empty found struct and x . w = x . w, which are solved immediately. However, this \nonly works because the k parameter of right struct comes last, thus making it possible to structurally \nmatch the occurrences of x . w on the two sides of the equation. If k came earlier, the uni.cation would \nsimply fail. We have described how to construct the canonical solution f, but the mere construction is \nnot suf.cient to carry out the proof of bnd writeR. For the proof, we further require an explicit invariant \nthat f (x . v) produces a heap in which the contents of x is changed to v, but everything else is unchanged \nwhen compared to f (x . w). This is the role of the parameter r, which is constrained by the invariant \nin the de.nition of partition to equal the rest of the heap , that is h = k r. With this invariant in \nplace, we can vary the parameter k from x . w in the conclusion of bnd writeR to x . v in the premise. \nHowever, r remains .xed by the type of f, providing the guarantee that the only change to the heap was \nin the contents of x. It may be interesting to note that, while our code computes an f that syntactically \nmatches the parentheses and the order of sum\u00ad mands in h (as this is important for using the lemma in \npractice), the above invariant on h, k and r is in fact a semantic, not a syntactic, equality. In particular, \nit doesn t guarantee that h and k r are con\u00adstructed from the same exact applications of . and , since \nin HTT those are de.ned functions, not primitive constructors. Rather, it captures only equality up to \ncommutativity, associativity and other semantic properties of heaps as partial maps. This suf.ces to \nprove bnd writeR, but more to the point: the syntactic property, while true, cannot even be expressed \nin Coq s logic, precisely because it concerns the syntax and not the semantics of heap expressions. To \nconclude the section, notice that the premise and conclusion of bnd writeR both contain projections out \nof f. Therefore, the lemma may be used both in forward reasoning (out of hypotheses) and in backward \nreasoning (for discharging a given goal). For example, we can prove the goal verify (bind (write x2 4) \ne)(i1 (x1 . 1 x2 . 2)) q under hypothesis H : verify (e ()) (i1 (x1 . 1 x2 . 4)) q in two ways: \nBackward: By applying bnd writeR to the goal. The goal will therefore be changed to exactly match H. \n Forward: By applying bnd writeR (x := x2)(w := 2) to the hypothesis H, thus obtaining the goal. Note \nhow in this case we need to explicitly provide the instantiations of the parameters x and w because they \ncannot be gleaned just from looking at H.  This kind of versatility is yet another advantage that lemmas \nbased on canonical instances exhibit when compared to tactics. The latter, it seems, must be specialized \nto either forward or backward mode, and we have not managed to encode a tactic equivalent of bnd writeR \nthat is usable in both directions. 6. Reordering Uni.cation Subproblems In this section we design an \noverloaded version of our original noalias lemma from Section 1. The main challenge, as it turns out, \nis ensuring that the uni.cation constraints generated during canonical structure inference are resolved \nin the intended order. This is important because the postponing of a certain constraint may underspecify \ncertain variables, leading the system to choose a wrong intermediate value that will eventually fail \nto satisfy the postponed constraint. In the case of noalias, the problem is that a na\u00a8ive implementation \nwill result in the triggering of a search for a pointer in a heap before we know what pointer we re searching \nfor. Fortunately, it is possible to handle this problem very easily using an extremely simple design \npattern we call hoisting. Before we come to explain the details of the problem and the pattern, let us \n.rst present the search structures that form the core of the automation for noalias and are shown in \nFigures 5 7. Given a heap h, and two pointers x and y, the algorithm for noalias proceeds in three steps: \n(1) scan h to compute the list of pointers s appearing in it, which must by well-de.nedness of h be a \nlist of distinct pointers; (2) search through s until we .nd either x or y; (3) once we .nd one of the \npointers, continue searching through the remainder of s for the other one. Step (1) is implemented by \nthe scan structure in Figure 5. Like the ast structure from Section 4, scan returns its output using \nits parameter (here, s). It also outputs a proof that the pointers in s are all distinct (i.e., uniq \ns) and that they are all in the domain of the input heap, assuming it was well-de.ned. Step (2) is implemented \nby the search2 structure (named so be\u00adcause it is searches for two pointers, both taken as parameters \nto the structure). It produces a proof that x and y are both distinct mem\u00adbers of the input list s, which \nwill be passed in through uni.cation  structure tagged heap := Tag {untag : heap}default tag (h : heap) \n:= Tag h ptr tag h := default tag h canonical union tag h := ptr tag h structure scan (s : seq ptr) := \nScan {heap of : tagged heap; : def heap of . uniq s ..x. x . s . x . dom heap of} canonical union struct \ns1 s2 (f1 : scan s1)(f2 : scan s2) := Scan (append s1 s2)(union tag (f1 f2)) ... canonical ptr struct \nAx (v : A) := Scan (x :: nil)(ptr tag (x . v)) ... canonical default struct h := Scan nil (default tag \nh) ... Figure 5. Structure scan for computing a list of pointers syntacti\u00adcally appearing in a heap. \nstructure tagged seq2 := Tag2 {untag2 : seq ptr}foundz (s : seq ptr) := Tag2 s foundy s := foundz s canonical \nfoundx s := foundy s structure search2 (xy : ptr) := Search2 {seq2 of : tagged seq2; : x . seq2 of . \ny . seq2 of .(uniq seq2 of . x != y)} canonical x struct xy (s1 : search1 y) := Search2 xy (foundx (x \n:: s1)) ... canonical y struct xy (s1 : search1 x) := Search2 xy (foundy (y :: s1)) ... canonical z \nstruct xyz (s2 : search2 xy) := Search2 xy (foundz (z :: s2)) ... Figure 6. Structure search2 for .nding \ntwo pointers in a list. structure tagged seq1 := Tag1 {untag1 : seq ptr}recurse tag (s : seq ptr) := \nTag1 s canonical found tag s := recurse tag s structure search1 (x : ptr) := Search1 {seq1 of : tagged \nseq1; : x . seq1 of} canonical found struct (x : ptr)(s : seq ptr) := Search1 x (found tag (x :: s)) \n... canonical recurse struct (xy : ptr)(f : search1 x) := Seach1 x (recurse tag (y :: f )) ... Figure \n7. Structure search1 for .nding a pointer in a list. with the seq2 of projection. The search proceeds \nuntil either x or y is found, at which point the search1 structure (next paragraph) is invoked with the \nother pointer. Step (3) is implemented by the search1 structure, which searches for a single pointer \nx in the remaining piece of s, returning a proof of x s membership in s if it succeeds. Its implementation \nis quite similar to that of the .nd structure from Section 2.3. With our core automated machinery in \nhand, we are ready for our .rst (failed) attempt at an overloaded version of noalias: noaliasR wrong \n: .x : ptr. .s : seq ptr. .f : scan s. .g : check x s. def (untag (heap of f)) . x != unpack (y of g) \nThe intuition behind the reformulation can be explained in pro\u00adgramming terms. When the lemma is applied \nto a hypothesis D of type def h, the heap h will be uni.ed with the projection untag (heap of f). This \nwill trigger an inference problem in which the system solves for the canonical implementation of f by \nexecut\u00ading the scan algorithm, thus producing as output the pointer list s. For example, if h = i1 (x1 \n. v1 x2 . v2) (i2 x3 . v3), then s will get uni.ed with [x1,x2,x3], so it can serve as a well\u00adde.ned \ninput to the search steps that follow. When the lemma is subsequently applied in order to solve a goal \nof the form x ' != y ', we need some way to get the uni.cation with the conclusion of the lemma to trigger \nthe automated search for x ' and y ' in the list s. Toward this end, we can use the uni.cation with either \nx ' or y ' as the trigger for the search, and here we choose the latter. Speci.cally, we de.ne a structure \ncheck, whose construction ' :3 is keyed on a projection y of that will be uni.ed with y structure packed \nptr := Pack {unpack : ptr} canonical pack (z : ptr) := Pack z structure check (x : ptr)(s : seq ptr) \n:= Check {y of : packed ptr; : uniq s . x != unpack y of} canonical start xy (s2 : search2 xy) := Check \nx (untag2 (seq2 of s2)) (pack y) ... The sole purpose of the canonical instance start for the check structure \nis to take x ' and s, passed in as parameters, and y ', passed in through uni.cation with the y of projection, \nand repackage them appropriately in the form that the search2 structure expects. In particular, recall \nthat search2 expects the two pointers to be passed in as parameters, and s to be uni.ed with its seq2 \nof projection. Unfortunately, the linking structure we ve de.ned here doesn t quite work. The trouble \nhas to do with the way in which Coq or\u00adders the subproblems that arise during canonical instance uni.ca\u00adtion. \nAlthough a fully detailed presentation of the Coq uni.cation algorithm is beyond the scope of this paper, \nthe rule of thumb is that when matching against a canonical instance, Coq solves the uni.\u00adcation subproblems \nin a left-to-right order that is, it .rst solves the uni.cation subproblems corresponding to each of \nthe structure parameters (in the case of check, the x and s parameters) and only then uni.es the structure \nprojections (like y of in this case). Thus, when matching against the start instance, what happens is \nthe following. First, fresh uni.cation variables are generated for the instance parameters ?x, ?y and \n?s2. Then, three new uni.ca\u00adtion subproblems are generated and solved in the following order, 3 The astute \nreader may notice that it is not actually necessary to tag (or in this case, pack) the y of projection \nof the check structure since we are only de.ning one canonical instance for the structure. We tag y of \nsimply to minimize the delta required when we describe the hoisting pattern below.  corresponding to \nthe arguments of Check: ?x = x ' untag2(seq2 of ?s2)= s ?y = y ' The problem is that the solution to \nthe second equation will .re the search for a canonical solution for ?s2 of type search2 x ' ?y thus \ntriggering the search for x ' and ?y in s before the third equation has uni.ed ?y with y '. So we will \nend up searching s for an unknown ?y, leading to the wrong behavior in most cases. The Pattern In order \nto .x our check structure, we need a way to arrange for ?y to be uni.ed with y ' before the search algorithm \ngets triggered on the pointer list s. The trick to doing this is to give check an extra parameter y, \nwhich will appear earlier than (i.e., to the left of) s in the parameter list, thus ensuring higher priority \nin the uni.cation order. But we will also constrain that parameter y to be equal to the y of projection \nfrom the structure by (effectively) giving the projection a singleton type. We call this hoisting. To \nillustrate, here is how to change the packed ptr and check structures (and their instances) according \nto the hoisting pattern: structure equals ptr (z : ptr) := Pack {unpack : ptr} canonical equate (z : \nptr) := Pack zz structure check (xy : ptr)(s : seq ptr) := Check {y of : equals ptr y; : uniq s . x != \nunpack y of} canonical start xy (s2 : search2 xy) := Check xy (untag2 (seq2 of s2)) (equate y) ... The \nkey here is the new version of packed ptr, which (for clarity) we call equals ptr, and which is now explicitly \nparameterized over a pointer z. The instance equate guarantees that the canonical value of type equals \nptr z is a package containing z itself. We rely on this guarantee in the check structure, whose y of \nprojection now has type equals ptr y, thus constraining it to be equal to check s new parameter y. We \ncan now revise our statement of the overloaded noaliasR lemma ever so slightly to mention the new parameter \ny: noaliasR : .xy : ptr. .s : seq ptr. .f : scan s. .g : check xy s. def (untag (heap of f)) . x != unpack \n(y of g) As above, suppose that noaliasR has already been applied to a hypothesis D of type def h, so \nthat the lemma s parameter s has already been solved for. Then, when noaliasR is applied to a goal x \n' != y ', the uni.cation engine will unify x ' with the argument ?x of noaliasR, and proceed to unify \nunpack (y of ?g)= y ' in a context where ?g : check x ' ?ys. Note that, although we have elided it, unpack \nhere really takes as its .rst (implicit) argument the unknown pointer ?y that is implied by equals ptr \n?y (the type of y of ?g). Thus, by canonicity, the equation will be resolved with equate, and two new \nequations will be generated (in this order): ?y = y ' y of ?g = equate y ' The .rst uni.cation is the \nessential one that needs to happen prior to triggering of the search procedure, so that all inputs to \nthe search are known; the rest of uni.cation then works as expected. Intuitively, the reason the equation \nbetween ?y and y ' is gen\u00aderated .rst is because it arises from unifying the types of y of ?g and equate \ny ', which is necessary before one can unify the terms themselves. For a more formal explanation of canonical \ninstance resolution, we refer the reader to our online appendix [11]. Finally, note the y that is shared \nbetween the parameter (y) and the projection (equate y) of the start instance. By hoisting y so that \nit appears before s in the argument list of Check, we have ensured that it will be uni.ed with the y \n' from the goal before the search through s begins. Applying the Lemma The overloaded noaliasR lemma \nsupports a number of modes of use: it can be applied, used as a rewrite rule, or composed with other \nlemmas. For example, assume that we have a hypothesis specifying a disjointness of a number of heaps \nin a union: D : def (i1 (x1 . v1 x2 . v2) (i2 x3 . v3)). Assume further that the arguments x, y, \ns, f and g of noaliasR are implicit, so that we can write simply (noaliasR D) when we want to partially \ninstantiate the lemma with the hypothesis D. Then the following are some example goals, and proofs to \ndischarge them, illustrating the .exibility of use. As can be seen, no tedious reordering of heap expressions \nby commutativity and associativity is needed. 1. The lemma can be used in backward reasoning. The type \nchecker picks up x1 and x2 from the goal, and con.rms they appear in D. Goal : x1 != x2 Proof : by apply \n:(noaliasR D). 2. The lemma can be used in iterated rewriting (notice the modi.er ! ). The lemma is \npartially instantiated with D. It performs the initial scan of D once, but is then used three times to \nreduce each conjunct to true. There is no need in the proof to specify the input pointers to be checked \nfor aliasing. The type checker can pick them up from the goal, in the order in which they appear in the \nconjunction. Goal :(x1 != x2) &#38;&#38; (x2 != x3) &#38;&#38; (x3 != x1) Proof : by rewrite !(noaliasR \nD). 3. The lemma can be composed with other lemmas, to form new rewrite rules. Again, there is no need \nto provide the input pointers in the proofs. For example, given the standard library lemma negbTE : .b:bool. \n!b = true . b = false, we have: Goal : if (x2 == x3) &#38;&#38; (x1 != x2) then false else true Proof \n: by rewrite (negbTE (noaliasR D)). 4. That said, we can provide the input pointers in several ways, \nif we wanted to, which would correspond to forward reasoning. We can use the term selection feature of \nrewrite to reduce only the speci.ed conjunct in the goal. Goal : ((x1 != x2) &#38;&#38; (x2 != x3)) = \n(x1 != x2) Proof : by rewrite [x2 != x3](noaliasR D) andbT. Here a rewrite by andbT : .b. b &#38;&#38; \ntrue = b is used to remove the true left in the goal after rewriting by noaliasR. 5. Or, we can supply \none (or both) of the pointer arguments di\u00adrectly to noaliasR. Goal : ((x1 != x2) &#38;&#38; (x2 != x3)) \n= (x1 != x2) Proof : by rewrite (noaliasR (x := x2) D) andbT. Goal : ((x1 != x2) &#38;&#38; (x2 != x3)) \n= (x1 != x2) Proof : by rewrite (noaliasR (y := x3) D) andbT.  7. Related Work Expressive Type Systems \nfor Proof Automation A number of recent languages consider specifying tactics via very expressive dependent \ntypes. Examples include VeriML [26] for automat\u00ading proofs in Coq, and Delphin [21] and Beluga [20] for \nproofs in Twelf. Their starting point is the higher-order abstract syntax (HOAS) style of term representation; \nconsequently, one of their main concerns is using types to track the variable contexts of sub\u00adgoals generated \nduring tactic execution. In contrast, we do not build a separate language on top of Coq, but rather customize \nCoq s uni\u00ad.cation algorithm. This is much more lightweight, as we do not need to track variable contexts \nin types, but it also comes with lim\u00aditations. For example, our automations are pure logic programs, \nwhereas the other proposals may freely use imperative features. On the other hand, as we have demonstrated, \ncanonical structures can bene.t from freely mixing with Coq s primitives for higher-order computation. \nThe mixing would not have been possible had the automation and the base language been kept separated, \nas is the case in other proposals. Another bene.t of the tight integration is that canonical structures \ncan be used to automate not only proofs, but also more general aspects of type inference (e.g., overloading). \nIn this paper, we have not considered HOAS representations, but we have successfully made .rst steps \nin that direction. The interested reader can .nd in our source .les an implementation of the motivating \nexample from VeriML, which considers a simple automation tactic for a logic with quanti.ers. Canonical \nStructures One important application of canonical structures is described by Bertot et al. [3], where \nthe ability to key on terms, rather than just types, is used for encoding iterated versions of classes \nof algebraic operators. Gonthier [9] describes a library for matrix algebra in Coq, which introduces \na variant of the tagging pattern, but brie.y, and as a relatively small part of a larger mathematical \ndevelopment. In contrast, in the current paper, we give a more abstract and detailed presentation of \nthe general tagging pattern and explain its operation with a careful trace. We also present several other \nnovel design patterns for canonical structures, and explore their use in reasoning about heap-manipulating \nprograms. Asperti et al. [1] present uni.cation hints, which generalize Coq s canonical structures by \nallowing that a canonical solution be declared for any class of uni.cation equations, not only for equa\u00adtions \ninvolving a projection out of a structure. Hints are shown to support applications similar to our re.ection \npattern from Sec\u00adtion 4. However, they come with limitations; for example, the au\u00adthors comment that \nhints cannot support backtracking. Thus, we believe that the design patterns that we have developed in \nthe cur\u00adrent paper are not obviated by the additional generality of hints, and would be useful in that \nframework as well. Type Classes Sozeau and Oury [24] present type classes for Coq, which are similar \nto canonical structures, but differ in a few im\u00adportant respects. The most salient difference is that \ninference for type class instances is not performed by uni.cation, but by gen\u00aderal proof search. This \nproof search is triggered after uni.cation, and it is possible to give a weight to each instance to prioritize \nthe search. This leads to somewhat simpler code, since no tagging nor hoisting is needed, but, on the \nother hand, it seems less expressive. For instance, we were not able to implement the search-and-replace \npattern of Section 5 using Coq type classes, due to the lack of con\u00adnection between proof search and \nuni.cation. We were able to de\u00adrive a different solution for bnd writeR using type classes, but the solution \nwas more involved (requiring two specialized classes to differentiate the operations such as write which \nperform updates to speci.c heaps, from the operations which merely inspect pointers without performing \nupdates). More importantly, we were not able to scale this solution to more advanced lemmas from our \nimple\u00admentation of higher-order separation logic. In contrast, canonical structures did scale, and we \nprovide the overloaded code for these lemmas in our source .les [11]. In the end, we managed to implement \nall the examples in this paper using Coq type classes, demonstrating that lemma overload\u00ading is a useful \nhigh-level concept and is not tied speci.cally to canonical structures. (The implementations using type \nclasses are included in our source .les as well [11].) Nevertheless, unlike for canonical structures, \nwe have not yet arrived at a full understand\u00ading of how Coq type classes perform instance resolution. \nIn ad\u00addition, the preliminary performance results are mixed, with type classes sometimes beating canonical \nstructures (in terms of speed) and sometimes vice versa. Ultimately, it may turn out that the two formalisms \nare interchangeable in practice, but we need more ex\u00adperience with type classes to con.rm this. Spitters \nand van der Weegen [25] present a re.ection algorithm using Coq type classes based on the example of \nAsperti et al. dis\u00adcussed above. In addition, they consider the use of type classes for overloading and \ninheritance when de.ning abstract mathematical structures such as rings and .elds. They do not, however, \nconsider lemma overloading more generally as a means of proof automation, as we have presented here. \nFinally, in the context of Haskell, Morris and Jones [18] propose an alternative design for a type class \nsystem, called ilab, which is based on the concept of instance chains. Essentially, instance chains avoid \nthe need for overlapping instances by allowing the programmer to control the order in which instances \nare considered during constraint resolution and to place conditions on when they may be considered. Our \ntagging pattern (Section 2.3) can be seen as a way of coding up a restricted form of instance chains \ndirectly in existing Coq, instead of as a language extension, by relying on knowledge of how the Coq \nuni.cation algorithm works. ilab also supports failure clauses, which enable one to write instances that \ncan only be applied if some constraint fails to hold. Our approach does not support anything directly \nanalogous, although (as Morris and Jones mention) failure clauses can be encoded to some extent in terms \nof more heavyweight type class machinery. Dependent Types Modulo Theories Several recent works have considered \nenriching the term equality of a dependently typed sys\u00adtem to natively admit inference modulo theories. \nOne example is Strub et al. s CoqMT [27, 2], which extends Coq s typechecker with = .rst-order equational \ntheories. Another is Jia et al. s language . ~(pronounced lambda-eek ) [14], which can be instantiated \nwith various abstract term-equivalence relations, with the goal of study\u00ading how the theoretical properties \n(e.g., the theory of contextual equivalence) vary with instantiations. Also related are Braibant et al. \ns AAC tactics for rewriting modulo associativity and commuta\u00adtivity in Coq [4]. In our paper, we do not \nchange the term equality of Coq. Instead, we allow user-supplied algorithms to be executed when desired, \nrather than by default whenever two terms have to be checked for equality. Moreover, these algorithms \ndo not have to be only deci\u00adsion procedures, but can implement general-purpose computations. 8. Conclusions \nand Future Work The most common approach to proof automation in interactive provers is via tactics, which \nare powerful but suffer from several practical and theoretical limitations. In this paper, we propose \nan alternative, speci.cally for Coq, which we believe puts the problem of interactive proof automation \non a stronger foundational footing. The approach is rooted in the recognition that the type checker and \ninference engines are already automation tools, and can be co\u00aderced via Coq s canonical structures into \nexecuting user-supplied code. Automating proofs in this style is analogous to program over\u00adloading via \ntype classes in Haskell. In analogy with the Curry-Howard isomorphism, the automated lemmas are nothing \nbut over\u00adloaded programs. In the course of resolving the overloading, the type checker performs the proof \nautomation.  We have illustrated the .exibility and generality of the approach by applying it to a diverse \nset of lemmas about heaps and pointer aliasing, which naturally arise in veri.cation of stateful programs. \nOverloading these lemmas required developing a number of design patterns which we used to guide the different \naspects of Coq s uni.cation towards automatically inferring the requisite proofs. Of course, beyond this, \nmuch remains to be done, regarding both the theoretical and pragmatic aspects of our approach. From the \ntheoretical standpoint, we believe it is very important that Coq s uni.cation algorithm, as well as the \nalgorithm for inference of canonical structures, be presented in a formal, declarative fashion, which \nis currently not the case. To somewhat remedy the situation, and help the reader interested in developing \ntheir own overloaded lemmas, we include in our online appendix [11] a brief description of the order \nin which canonical instances are resolved in Coq. This is essentially a speci.cation of the operational \nsemantics of canonical instance resolution, and we have found it invaluable, but it has been obtained \nby a diligent study of the source code of Coq s uni.cation algorithm. The study of the uni.cation algorithm \nis also important from the pragmatic standpoint, as in our experience, the current implemen\u00adtation suffers \nfrom a number of peculiar performance problems. For example, we have observed that the time to perform \na simple assignment to a uni.cation variable is quadratic in the number of variables in the context, \nand linear in the size of the term being as\u00adsigned. In contrast, in Ltac, or in type classes, variable \nassignment is essentially constant-time. Thus, even though the proof terms produced by application of \nour overloaded lemmas are usually much shorter than the proofs generated by corresponding tactics, they \noften take somewhat longer to generate and type check, and scale much worse. This complexity has so far \nnot been too problematic in practice, as inter\u00adactive proofs tend to keep variable contexts short, for \nreadability. However, it is a serious concern, and one which is not inherent to overloading or to canonical \nstructures; if addressed by an optimiza\u00adtion of Coq s kernel functionality, it will likely improve many \nother aspects of the system. Acknowledgments We would like to thank Cyril Cohen and Matthieu Sozeau for \nvery helpful discussions. References [1] Andrea Asperti, Wilmer Ricciotti, Claudio Sacerdoti Coen, and \nEn\u00adrico Tassi. Hints in uni.cation. In TPHOLs, volume 5674 of LNCS, pages 84 98, 2009. [2] Bruno Barras, \nJean-Pierre Jouannaud, Pierre-Yves Strub, and Qian Wang. CoqMTU: a higher-order type theory with a predicative \nhier\u00adarchy of universes parametrized by a decidable .rst-order theory. In LICS, pages 143 151, 2011. \n[3] Yves Bertot, Georges Gonthier, Sidi Ould Biha, and Ioana Pasca. Canonical big operators. In TPHOLs, \nvolume 5170 of LNCS, pages 86 101, 2008. [4] Thomas Braibant and Damien Pous. Rewriting modulo associativity \nand commutativity in Coq. In Second Coq workshop, 2010. [5] Manuel M. T. Chakravarty, Gabriele Keller, \nand Simon Peyton Jones. Associated type synonyms. In ICFP, pages 241 253, 2005. [6] Adam Chlipala. Certi.ed \nprogramming with dependent types. URL: http://adam.chlipala.net/cpdt, 2008. [7] Adam Chlipala. Mostly-automated \nveri.cation of low-level programs in computational separation logic. In PLDI, 2011. [8] Georges Gonthier. \nFormal proof the four-color theorem. Notices of the AMS, 55(11):1382 93, 2008. [9] Georges Gonthier. \nPoint-free, set-free concrete linear algebra. In ITP, 2011. [10] Georges Gonthier and Assia Mahboubi. \nAn introduction to small scale re.ection in Coq. Journal of Formalized Reasoning, 3(2):95 152, 2010. \n[11] Georges Gonthier, Beta Ziliani, Aleksandar Nanevski, and Derek Dreyer. How to make ad hoc proof \nautomation less ad hoc, 2011. Code + appendix: http://www.mpi-sws.org/~beta/lessadhoc. [12] Benjamin \nGr\u00b4egoire and Assia Mahboubi. Proving equalities in a commutative ring done right in Coq. In TPHOLs, \npages 98 113, 2005. [13] Cordelia Hall, Kevin Hammond, Simon Peyton Jones, and Philip Wadler. Type classes \nin Haskell. TOPLAS, 18:241 256, 1996. [14] Limin Jia, Jianzhou Zhao, Vilhelm Sj\u00a8oberg, and Stephanie \nWeirich. Dependent types and program equivalence. In POPL, pages 275 286, 2010. [15] Mark P. Jones. Type \nclasses with functional dependencies. In ESOP, pages 230 244, 2000. [16] Gerwin Klein, June Andronick, \nKevin Elphinstone, Gernot Heiser, David Cock, Philip Derrin, Dhammika Elkaduwe, Kai Engelhardt, Rafal \nKolanski, Michael Norrish, Thomas Sewell, Harvey Tuch, and Simon Winwood. seL4: formal veri.cation of \nan operating-system kernel. CACM, 53(6):107 115, 2010. [17] Xavier Leroy. Formal veri.cation of a realistic \ncompiler. CACM, 52:107 115, July 2009. [18] J. Garrett Morris and Mark P. Jones. Instance chains: Type \nclass programming without overlapping instances. In ICFP, pages 375 386, 2010. [19] Aleksandar Nanevski, \nViktor Vafeiadis, and Josh Berdine. Structuring the veri.cation of heap-manipulating programs. In POPL, \npages 261 274, 2010. [20] Brigitte Pientka and Joshua Dun.eld. Programming with proofs and explicit contexts. \nIn PPDP, pages 163 173, 2008. [21] Adam Poswolsky and Carsten Sch\u00a8urmann. System description: Del\u00adphin \n a functional programming language for deductive systems. ENTCS, 228:113 120, 2009. [22] John C. Reynolds. \nSeparation logic: a logic for shared mutable data structures. In LICS, 2002. [23] Amokrane Sa\u00a8ibi. Typing \nalgorithm in type theory with inheritance. In POPL, pages 292 301, 1997. [24] Matthieu Sozeau and Nicolas \nOury. First-class type classes. In TPHOLs, volume 5170 of LNCS, pages 278 293, 2008. [25] Bas Spitters \nand Eelis van der Weegen. Type classes for mathematics in type theory. MSCS, Special issue on Interactive \ntheorem proving and the formalization of mathematics , 21:1 31, 2011. [26] Antonis Stampoulis and Zhong \nShao. VeriML: Typed computation of logical terms inside a language with effects. In ICFP, pages 333 344, \n2010. [27] Pierre-Yves Strub. Coq modulo theory. In CSL, pages 529 543, 2010. [28] Philip Wadler and \nStephen Blott. How to make ad-hoc polymorphism less ad hoc. In POPL, pages 60 76, 1989.   \n\t\t\t", "proc_id": "2034773", "abstract": "<p>Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through <i>tactics</i>, which are programmed in a separate language from that of the prover's base logic. While tactics are clearly useful in practice, they can be difficult to maintain and compose because, unlike lemmas, their behavior cannot be specified within the expressive type system of the prover itself.</p> <p>We propose a novel approach to proof automation in Coq that allows the user to specify the behavior of custom automated routines in terms of Coq's own type system. Our approach involves a sophisticated application of Coq's <i>canonical structures</i>, which generalize Haskell type classes and facilitate a flexible style of dependently-typed logic programming. Specifically, just as Haskell type classes are used to infer the canonical implementation of an overloaded term at a given type, canonical structures can be used to infer the canonical <i>proof</i> of an overloaded <i>lemma</i> for a given instantiation of its parameters. We present a series of design patterns for canonical structure programming that enable one to carefully and predictably coax Coq's type inference engine into triggering the execution of user-supplied algorithms during unification, and we illustrate these patterns through several realistic examples drawn from Hoare Type Theory. We assume no prior knowledge of Coq and describe the relevant aspects of Coq type inference from first principles.</p>", "authors": [{"name": "Georges Gonthier", "author_profile_id": "82658771157", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P2801394", "email_address": "gonthier@microsoft.com", "orcid_id": ""}, {"name": "Beta Ziliani", "author_profile_id": "81488670714", "affiliation": "MPI-SWS, Saarbruecken, Germany", "person_id": "P2801395", "email_address": "beta@mpi-sws.org", "orcid_id": ""}, {"name": "Aleksandar Nanevski", "author_profile_id": "81100503327", "affiliation": "IMDEA Software Institute, Madrid, Spain", "person_id": "P2801396", "email_address": "aleks.nanevski@imdea.org", "orcid_id": ""}, {"name": "Derek Dreyer", "author_profile_id": "81100381796", "affiliation": "MPI-SWS, Saarbruecken, Germany", "person_id": "P2801397", "email_address": "dreyer@mpi-sws.org", "orcid_id": ""}], "doi_number": "10.1145/2034773.2034798", "year": "2011", "article_id": "2034798", "conference": "ICFP", "title": "How to make ad hoc proof automation less ad hoc", "url": "http://dl.acm.org/citation.cfm?id=2034798"}