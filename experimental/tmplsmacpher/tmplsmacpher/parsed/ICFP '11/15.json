{"article_publication_date": "09-19-2011", "fulltext": "\n Functional Modelling of Musical Harmony An experience report Jos\u00b4e Pedro Magalh aes W. Bas de Haas Department \nof Information and Computing Sciences, Utrecht University, P.O. Box 80.089, 3508 TB Utrecht, The Netherlands \n {jpm,bash}@cs.uu.nl Abstract Music theory has been essential in composing and performing music for centuries. \nWithin Western tonal music, from the early Baroque on to modern-day jazz and pop music, the function \nof chords within a chord sequence can be explained by harmony theory. Although Western tonal harmony \ntheory is a thoroughly studied area, formalising this theory is a hard problem. We present a formalisation \nof the rules of tonal harmony as a Haskell (generalized) algebraic datatype. Given a sequence of chord \nlabels, the harmonic function of a chord in its tonal context is automatically derived. For this, we \nuse several advanced func\u00adtional programming techniques, such as type-level computations, datatype-generic \nprogramming, and error-correcting parsers. As a detailed example, we show how our model can be used to \nimprove content-based retrieval of jazz songs. We explain why Haskell is the perfect match for these \ntasks, and compare our implementation to an earlier solution in Java. We also point out shortcomings \nof the language and libraries that limit our work, and discuss future developments which may ameliorate \nour solution. Categories and Subject Descriptors D.1.1 [Programming Tech\u00adniques]: Functional Programming; \nH.5.5 [Information Interfaces and Presentation]: Sound and Music Computing Modelling General Terms Experimentation, \nLanguages 1. Introduction [Tonality is] the art of combining tones in such succes\u00ad sions and such harmonies \nor successions of harmonies, that the relation of all events to a fundamental tone is made pos\u00ad sible. \nArnold Schoenberg, in Problems of Harmony The deep connection between mathematics and music has been \nknown at least since the times of Plato (Mountford 1923). In the realm of tonal harmony in particular, \nwhen studying the relation\u00adships between sequential chords, we notice order and regularity; some combinations \nsound pleasing while others sound peculiar. These observations led music theorists to develop ways to \nanalyse the function of a chord in its tonal context (e.g. Riemann 1893). Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 11, September 19 21, 2011, Tokyo, Japan. \nCopyright c &#38;#169; 2011 ACM 978-1-4503-0865-6/11/09. . . $10.00 Among the .rst to formalize these \ntheories were Lerdahl and Jack\u00ad endoff (1983), who gave an encompasing account on how experi\u00ad enced listeners \nhierarchically organise tonal music. More formally, Steedman (1984) proposes a generative grammar for \ntwelve-bar blues chord progressions, and Rohrmeier (2007, 2011) describes the core of tonal harmony as \na formal grammar. This grammar was implemented by De Haas et al. (2009) and used for modelling har\u00ad monic \nsimilarity. Models of tonal harmony are useful because they explain the role or function that a musical \nchord has within a piece of music. For instance, the same musical chord often has different functions \ndepending on the context in which it occurs. We present HARMTRACE (Harmony Analysis and Retrieval of \nMusic with Type-level Representations of Abstract Chords Enti\u00adties), an adaptation and extension of the \nJava approach of De Haas et al. to a functional setting. Exploring the connection between a context-free \ngrammar and an algebraic datatype, we represent dif\u00adferent musical harmonies as values of a datatype. \nUnlike in previ\u00adous work, we encode all the musical restrictions in the type itself; strong static typing \nguarantees that well-typed values represent har\u00admonical sequences. Furthermore, a strongly-typed model \ngives us higher expressiveness and results in simpler code: through tech\u00adniques such as datatype-generic \nprogramming and type-level com\u00adputation, most of the code is automatically derived from the types. In \na way, the types are the code: most of the code (that would other\u00adwise have to be written manually) follows \ndirectly from the types. A formal model of musical harmony can be used to improve many other typical \nmusic processing tasks. Content-based Mu\u00adsic Information Retrieval (MIR, Downie 2003), for instance, \nis a rapidly expanding area within multimedia research which aims at keeping large repositories of digital \nmusic maintainable and acces\u00adsible. Within MIR the notion of similarity is crucial: songs that are similar \nin one or more features to a given relevant song are likely to be relevant as well. The majority of approaches \nto notation-based music retrieval focus on melodic similarity. Using our harmony model, we present a \nmethod that allows the retrieval of music based on harmonic similarity. We compare harmonic analyses \nin a tree form (which explains the functions of chords within a sequence) using a generic edit-distance \nfunction, and show that this compar\u00adison predicts harmonic similarity better than an edit-distance be\u00adtween \nthe original textual sequences of chords. Chord labels which do not .t in our model are automatically \ncorrected at the parsing stage, allowing comparison to proceed. Contribution In this paper we present \na new functional model of Western tonal harmony and explain why Haskell is particularly well-suited for \nmodelling harmony. We show how our model can be used to perform automatic harmony analysis of sequences \nof textual chord labels, and that such an analysis improves the task of retrieving harmonically similar \npieces. Along the way, we explain how several features of Haskell, such as type-level computations, Figure \n1. On the left: the C major scale with the names of the notes at the bottom and three example intervals \nabove the notes. On the right: a schematic piano keyboard containing note names and highlighting the \nsemitone interval.  error-correcting parsers, and generic programming, are essential to our approach. \nAll the code of HARMTRACE is available on Hackage (package HarmTrace-0.4). The rest of this report is \nstructured as follows: we .rst introduce basic concepts of harmony in Section 2, and then explain how \nwe encode them in Haskell in Section 3. In Section 4 we show applications of our model, which we evaluate \nin Section 5. We conclude in Section 6, discussing the limitations of our system and pointing out directions \nfor future development. 2. Harmony The French-American composer Edgard Var` ese once de.ned music as \norganised sound . In this section we present a very brief intro\u00adduction of how tonal harmony organises \nsound in Western music; for a thorough approach, we refer the reader to Piston and DeVoto (1991). We \nstart with the most basic element in music: a tone. A tone is a sound with a .xed frequency or pitch \nwhich can be described in musical notation with a note. All notes have a name, e.g. C, D, E, etc., and \nrepresent tones of a speci.c pitch (Figure 1 on the left). The distance between two notes is called an \ninterval and is measured in semitones, which is the smallest interval in Western tonal music. A semitone \nis also the distance between a black and a white key (or two adjacent white keys) on a piano (Figure \n1 on the right). Harmony arises when two or more tones sound at the same time. Simultaneously sounding \nnotes form chords, which can in turn be used to form chord sequences. A chord is a group of tones sounding \nat the same time, and separated by intervals of roughly the same size. The two most important factors \nthat characterize a chord are its structure, which determined by the intervals between the notes of the \nchord, and the chord root. The root is the note on which the chord is built. Chords can be labelled by \ndescribing their root and the relative interval structure of the tones in the chord. Figure 2 displays \na frequently occurring chord sequence, in the C major key. The key of a piece of music is the tonal center \nof the piece. It speci.es the tonic, which is perceived as the most stable tone in that piece. Often \npieces begin and end with chords rooted on the tonic of the key. Moreover, the key speci.es the scale, \nwhich is the set of pitches that occur most frequently in the piece and that sound reasonably well together. \nFor instance, the key of C major only contains the white keys of a piano keyboard. The same chord sounds \ndifferently in pieces of different keys. On the other hand, a chord sequence that is transposed to a \ndifferent key, by moving all notes up or down by a .xed interval, sounds very similar to the original \nsequence. Scale degrees are used to abstract from key and absolute pitch. A scale degree represents the \nrelative interval between a tone and the tonic of the piece. They are typically denoted with Roman numerals, \nas seen in Figure 2. In music, building up and releasing tension is crucial. In the de\u00advelopment of harmonic \ntension, three functional roles can generally be discerned: tonic, dominant, and subdominant. The dominant \nin\u00adduces maximal tension, the subdominant prepares a dominant by Figure 2. An often occurring chord sequence. \nThe chord labels are printed below the score, and the scale degrees and functional analysis above the \nscore. building up tension, and the tonic releases tension. Hence, every scale degree can be categorized \nby having a dominant, subdom\u00adinant, or tonic role. Similarly to the preparation of a tonic by a dominant, \nor a dominant by a subdominant, any scale degree can be recursively preceded by the scale degree seven \nsemitones (or a .fth) up, e.g. the D7 preceding G7 in Figure 2. This allow the cre\u00ad ation of chains of \nscale degrees, so-called secondary dominants. We have presented an extremely condensed view on harmony \ntheory. Nevertheless, it is clear that within a sequence not ev\u00adery chord is equally important. Some \nchords can easily be re\u00admoved leaving the global structure of the piece intact, whereas other chords \ncannot be removed without altering the way the piece is perceived. For instance, the D7 in Figure 2 can \nbe removed leav\u00ad ing the general harmony structure intact, while removing the G7 or the C at the end \nwould change the harmony structure. This sug\u00adgests that the rules of tonal harmony can be formalized \nhierarchi\u00adcally, analogically to linguistics. This is what we do in the next sec\u00adtion, building on ideas \nof Rohrmeier (2007, 2011) and the previous formalisation as a context-free grammar by De Haas et al. \n(2009). However, it is important to stress that formal modelling of tonal harmony is a dif.cult task, \nsince the rules of harmony are highly ambiguous and often formulated imprecisely. 3. Encoding harmony \nas a datatype We now discuss how we formalize general harmony theory as a datatype. Throughout the rest \nof the paper we elide most of the musical details and concentrate on a small but representative subset \nof the rules. The general idea is that we convert an input sequence of chord labels, such as \"C:maj F:maj \nD:7 G:7 C:maj\" (also shown in Figure 2), into a value of a Haskell datatype which captures the function \nof chords within the sequence. Since we want to abstract from speci.c keys, we .rst translate every chord \nlabel into a scale degree. For this to be possible, we assume we know the key of every input song. For \ninstance, our previous example is in C major, so it translates to \"I:maj IV:maj II:7 V:7 I:maj\". 3.1 \nNaive approach Using standard algebraic datatypes, we can encode alternatives as constructors, sequences \nas arguments to a constructor, and repeti\u00adtions as lists. A .rst (and very simpli.ed) approach could \nbe the following: data Piece = Piece [Phrase] data Phrase = PT Ton | PD Dom data Ton = TIMaj Degree data \nDom = DVMaj Degree | DSD,D SDom Dom data SDom = SIVMaj Degree We see a piece as a list of phrases. A \nphrase is either a tonic or a dominant. A tonic is simply the .rst scale degree, while a dominant might \nbranch into a subdominant and a dominant, or simply be the .fth degree.  The leaves of our tree are \nthe input labelled scale degrees, which consist of a root degree (an integer between 1 and 7) together \nwith a chord class: data Degree = Deg Int Class data Class = Maj | Min | Dom7 |... The chord class is \nused to group chords into a small number of cat\u00adegories based on their internal interval structure. All \nmajor chords, which tend to be perceived as sounding joyfully, are grouped under Maj. Similarly, Min \ngroups all minor chords, which are generally perceived as sounding darker than major chords, and Dom7 \ngroups chords that have an interval structure that induces tension. We can now encode harmonic sequences \nas values of type Piece: goodPiece,badPiece :: Piece goodPiece = Piece [PT (TIMaj (Deg 1 Maj))] badPiece \n= Piece [PT (TIMaj (Deg 2 Maj))] The problem with this representation is evident: non-sensical se\u00adquences \nsuch as badPiece are allowed by the type-checker. We know that a Tonic can never be the second scale \ndegree: it must be the .rst degree. However, since we do not constrain the Degree argument in TIMaj, \nwe have to make sure at the value-level that we only accept Deg 1 Maj as an argument. To guarantee that \nthe model never deals with invalid sequences we would need a separate proof of code correctness.  3.2 \nMore type information Fortunately, we can make our model more typed simply by using phantom types to \nencode degrees and chord classes at the type level: data Ton = TIMaj (Degree I Maj) data Dom = DVMaj \n(Degree V Maj) | DSD,D SDom Dom data SDom = SIVMaj (Degree IV Maj) data Degree d. = Deg Int Class Now \nwe detail precisely the root and class of the scale degree expected by each of the constructors. We need \ntype-level scale degrees and classes to use as arguments to the new Degree type: data I;data II;data \nIII;data IV;data V;data VI;data VII; data Maj;data Dom7;... It only remains to guarantee that Degrees \nare built correctly. An easy way to achieve this is to have a type class mediating type-to\u00advalue conversions, \nand a function to build degrees: class ToRoot d where toRoot :: d . Int instance ToRoot I where toRoot \n= 1 ... class ToClass . where toClass :: . . Class instance ToClass Maj where toClass = Maj ... deg :: \n(ToRoot d , ToClass .) . d . . . Degree d. degr c = Deg (toRoot r)(toClass c) If we also make sure that \nthe constructor Deg is not exported, we can be certain that our value-level Degrees correctly re.ect \ntheir type. Sequences like badPiece above are no longer possible, since the term TIMaj (deg (. :: II)(. \n:: Maj)) is not well-typed. 3.3 Secondary dominants So far we have seen how to encode simple harmonic \nrules and guar\u00adanteed that well-typed pieces make sense . However, we also need to encode harmonic rules \nthat account for secondary dominants. According to harmony theory, every scale degree can be preceded \nby the scale degree of the dominant class a .fth interval (seven semitones) up. To encode this notion \nwe need to compute transpo\u00adsitions on scale degrees. Since we encode the degree at the type\u00adlevel this \nmeans we need type-level computations. For this we use GADTs (Peyton Jones et al. 2006) and type families \n(Schrijvers et al. 2008). GADTs allow us to conveniently restrict the chord root and class for certain \nconstructors, while type families perform the necessary transpositions for relative degrees. To support \nchains of secondary dominants we change the Degree type as follows: data Degreen d.. where BaseDeg :: \nDegreeFinal d. . Degreen d. (Su .) ConsV :: Degreen (V/ d ) Dom7 . . DegreeFinal d. . Degreen d. (Su \n.) data DegreeFinal d. = Deg Int Class We now have two constructors for Degreen: BaseDeg is the base \ncase, which stores a Root and a Class as before. In ConsV we encode the relative dominants. Its type \nsays we can produce a Degreen for any root d and class . by having a DegreeFinal for that root and class \npreceded by a Degreen of root V/ d of the dominant class. The type family V/ transposes its argument \ndegree a .fth up: type family V/ d type instance V/ I = V type instance V/ V = II ... To avoid in.nite \nrecursion in the parser (Section 4.1) we use a type-level natural number in Degreen. This parameter also \nserves to control the number of allowed secondary dominants: data Su . data Ze type Degree d. = Degreen \nd. (Su (Su (Su (Su Ze)))) Typically we use values between 4 and 7 for .. Its value greatly affects compilation \ntime; see the discussion in Section 6.1.  3.4 Examples We have shown a very simpli.ed description of \nour model of musical harmony as a Haskell datatype. In reality, our model is larger and more detailed, \nalbeit still far simpler than the hundreds of pages of Piston and DeVoto (1991), for instance. To provide \nan idea of the kind of structure our datatype models, we show the chord sequence of Figure 2 as a pretty-printed \ntree in Figure 3. Every chord is classi.ed as being part of a dominant, subdominant, or tonic structure, \nand the D:7 is classi.ed as a secondary dominant of the G:7 (V/V). Piece PTPD PT TD T ISD I C:maj IV \nV/V C:maj F:maj II7 V7 D:7 G:7 Figure 3. The parse tree for the chord sequence shown in Figure 2. PT \nand PD represent phrase nodes. T, D, and S denote tonic, dom\u00adinant, and subdominant, respectively, and \nthe secondary dominant is denoted by V/V.  Another example piece is displayed in Figure 4. Within this \nshort piece, the IV:maj and G:7 are preceded by their secondary dominants. Because the model expects \nthe .rst C:7 to resolve to an F:maj, the parser inserts the expected scale degree IV (see Section 4.1.2). \nNote that although C:7 sounds similar to C:maj, their harmonic functions in Figure 4 are distinct. Piece \nPD PT D T S D I V/IV IV S D C:maj V/I I7 ins V/IV IV V/V V7 Vmin C:7 V/I I7 F:maj II7 G:7 G:min Vmin \nC:7 D:7 G:min Figure 4. The pretty-printed parse tree generated for the chord sequence \"G:min C:7 G:min \nC:7 F:maj D:7 G:7 C:maj\". 4. From chord labels to harmonic structure We have seen how to put Haskell \ns advanced type system features to good use in the de.nition of a model of tonal harmony. In this section \nwe further exploit the advantages of a well-typed model while de.ning a generic parser from labelled \nscale degrees (e.g. \"I:maj IV:maj II:7 V:7 I:maj\") to our datatype. We also show other operations on \nthe model, like pretty-printing and dif.ng. 4.1 Parsing From the high-level musical structure (e.g. \nthe Ton and Dom datatypes of Section 3.2) we can easily build a parser in applicative style mimicking \nthe structure of the types: data Parser a --abstract class Parse a where parse :: Parser a instance Parse \nTon where parse = TIMaj <$> parse instance Parse Dom where parse = DVMaj <$> parse <|> DSD,D <$> parse \n<*> parse For the purposes of this paper we keep Parser abstract; in our implementation we use the uu-parsinglib \npackage (Swierstra 2009). We prefer uu-parsinglib over, say, parsec because our grammar is highly ambiguous \nand we can put error correction to good use, as we explain in Section 4.1.2. The instances of Parse for \nTon and Dom are trivial because they follow directly from the structure of the datatypes. They can even \nbe obtained by syntactic manipulation of the datatype declaration: replace | by <|>, add <$> after the \nconstructor name, separate constructor arguments by <*> and replace each argument by parse. The code \nis tedious to write, and since we have several similar datatypes it becomes repetitive and long. To compound \nthe problem, the rules of harmony are naturally ambiguous, and we often change the model in search of \nthe best solution. Even more importantly, different musical styles can have signi.cantly different harmony \nrules (e.g. baroque harmony versus jazz), so our solution should support multiple models. We solve all \nthese problems by not writing instances like the one above. In\u00adstead, we use datatype-generic programming \nto derive a parser au\u00adtomatically in a type-safe way. We use the instant-generics package, which implements \na library similar to that initially de\u00adscribed by Chakravarty et al. (2009). Due to length considerations \nwe cannot explain how generic programming works in this paper, but our generic parser is entirely trivial. \nThe order of the construc\u00adtors and their arguments determines the order of the alternatives and sequences; \nin particular, we avoid left-recursion in our datatypes, since we do not implement a grammar analysis \nlike Devriese and Piessens (2011). 4.1.1 Adhoc parsers The only truly non-generic parser is that for \nDegreeFinal, which is also the only parser that consumes any input. It uses the type classes ToRoot and \nToClass as described in Section 3.2. Unfortunately, we are also forced to write the parser instances \nfor GADTs such as Degreen, since instant-generics does not support GADTs. Although the code remains entirely \ntrivial, the instance heads become more complicated, since they have to re.ect the type equalities introduced \nby the GADT. As an example, we show the parser code for Degreen: instance ( Parse (DegreeFinal d.) , \nParse (Degreen (V/ d ) Dom7 . )) . Parse (Degreen d. (Su .)) where parse = BaseDeg <$> parse <|> ConsV \n<$> parse <*> parse The context of the instance re.ects the type of the constructors of Degreen: BaseDeg \nintroduces the Parse (DegreeFinal d.) con\u00adstraint, whereas ConsV requires Parse (Degreen (V/ d ) Dom7 \n.)) too. The need for type-level natural numbers becomes evident here; the instance above is undecidable \nfor GHC, meaning that the rules for instance contexts become relaxed. Normally there are con\u00adstraints \non what can be written in the context to guarantee termi\u00adnation of type-checking. Undecidable instances \nlift these restric\u00adtions, with the side-effect that type-checking becomes undecidable in general. However, \nwe are certain that type-checking will always terminate since we recursively decrease the type-level \nnatural num\u00adber .. This means we also need a base case instance where we use the empty parser which always \nfails; this is acceptable because it is never used. instance Parse (Degreen d. Ze) where parse = empty \nNote how useful the type class resolution mechanism becomes: it recursively builds a parser for all possible \nalternatives, driven by the type argument .. This also means potentially long type\u00adchecking times; fortunately \nour current implementation remains compilable under a minute. We discuss parser performance issues in \nmore detail in Section 6.2.  4.1.2 Error correction We cannot hope to be able to model all valid harmonic \nrelations in our datatype. Furthermore, songs often contain mistakes or mistyped chords, or sequences \nof dubious harmonic validity. How\u00adever, these things are often a localized problem, and most of the song \nstill makes sense. In our solution we rely on error correction while parsing: chords that do not .t the \nstructure are automatically deleted or preceded by inserted chords, according to heuristics computed \nfrom the grammar structure. We keep track of the num\u00adber of corrections, since the ratio of corrections \nto number of input chords provides a measure of meaningfulness of the parse tree. For most songs, parsing \nproceeds with none or very few corrections. Songs with a very high error ratio denote bad input or wrong \nkey assignment, which results in meaningless scale degrees.   4.2 Visualising harmonic relations In \na way similar to the generic parser of Section 4.1, we also have a generic pretty-printer, which produces \noutput suitable for generation of graphical representations such as that of Figure 4. Similar issues \nwith adhoc instances for GADTs arise, which we solve in the exact same way as described in Section 4.1.1. \n 4.3 Generic diff A practical application of our tonal harmony model is estimating the harmonic similarity \nof two songs. An easy way to obtain a measure of similarity between two Pieces is to use a generic diff \nalgorithm. Just like the parser and the pretty-printer, our generic diff is derived from the structure \nof the datatypes, and adapts automatically to any change. We have implemented it in the style of Lempsink \net al. (2009) for the instant-generics library. This diff is based on four primitive generic functions: \nchildren, which returns a (heterogenously-typed) list of all children of a term, build, which rebuilds \na term given a list of new children, eqCon, which computes equality of terms based only on their top-level \nconstructor, and typeOf , which returns a unique representation for the type of a term. For performance \nreasons we use typeOf from the standard Data.Typeable library, while the other functions are easily implemented \nin instant-generics. However, the generic diff is rather slow; we discuss this problem in detail in Section \n6.3. 5. Evaluation In this section we evaluate the parsing results of our system and compare the retrieval \nperformance of the gdiff similarity measure with a simple baseline diff on the input tokens. 5.1 Datasets \nWe have performed our experiment with two datasets: the dataset of De Haas et al. (2009, which we call \nsmall) and a larger dataset (large). Both datasets consist of textual chord sequences extracted from \nuser-generated Band-in-a-Box .les that were collected from the Internet. Band-in-a-Box is a software \npackage that generates accompaniment given a chord sequence provided by the user. The small dataset contains \na selection of pieces that harmonically make sense , while the large dataset includes many songs that \nare harmonically atypical. This is because the .les are user-generated, and contain peculiar and un.nished \npieces, wrong key assignments and other errors; it can therefore be considered real life data. Within \nboth datasets there are different chord sequences that de\u00adscribe the same piece in different ways; these \ncan be used to do a retrieval experiment. We summarize the statistics of each dataset in Table 1. The \nlast column shows the average number of chord labels per song on the dataset, and the clusters are the \nnumber of songs that are similar. For instance, in the small dataset, 35 songs have no similar songs, \n11 songs have one other similar song, and 5 songs have two other similar songs (for a total of 35 + 11 \n* 2 + 5 * 3 = 72 songs). The large dataset contains about 11 times more songs than small (854 songs), \nand the songs are also longer on average. Note also that songs with no similar songs are akin to noise \nfor the retrieval task (see Section 5.3). Dataset Clusters Avg. labels/song small 35 11 5 41.70 large \n485 71 27 21 7 2 1 1 54.73 Table 1. Cluster size distribution and average number of chord labels per \nsong. The small dataset has cluster sizes ranging from 1 to 3, and the large dataset has cluster sizes \nranging from 1 to 8. 5.2 Parsing results The parsing results are shown in Table 2. For each dataset, \nwe show the average time taken to parse a song and the average error ratio. The error ratio is a measure \nof how many corrections the parser performed. We de.ne it as a ratio between the number of correction \nsteps and the number of chord labels, but we remove sequences of duplicate chord labels from the input \n.rst. A ratio of 0.2, for instance, means that 20% of the signi.cant labels of the sequence have been \naltered. Note that a single chord that doesn t match the speci.cation might cause multiple corrections, \ne.g. one deletion followed by one insertion. Lower ratios indicate that the song .ts our harmony model \nbetter. Dataset Error ratio Time taken (ms) small 0.067 23.833 large 0.200 381.837 Table 2. Error ratio \nand parsing runtime averaged over all songs On the small dataset, which consists of harmonically cor\u00adrect \nchord sequences, our model performs very well. The songs are parsed quickly and with average error ratio \nbelow 0.07. The large dataset is more problematic. The parsing time increases con\u00adsiderably, mostly because \nthe ambiguity of our model can make the error-correction process rather expensive. The error ratio also \nin\u00adcreases considerably, but in no way does the parser crash or refuse to produce a valid output. A higher \nerror ratio is also expected, since this dataset has many noisy or meaningless songs.  5.3 Matching \nresults To test gdiff as a similarity measure for musical harmony, we have performed a retrieval experiment. \nIn this experiment, the task is to retrieve the similar (but not identical) songs based on the edit dis\u00adtance \nof the gdiff algorithm. The distance between all pairs of songs is calculated, and for every song a ranking \nis constructed by sorting all other songs on the basis of their distance. To place the performance of \nthe gdiff algorithm and the dif.culty of the task in perspective, we compare with a baseline algorithm. \nThis method uses no harmony information whatsoever; we simply tokenize the input string into a list of \nDegrees and perform a standard diff on that list (using the diff package). We use this method to provide \na baseline case; the generic diff, having all the harmony infor\u00admation available, has to perform better \nthan this. We call this sim\u00adple algorithm baseline, while the generic diff of Section 4.3 is named gdiff. \nFor our datasets we know all the clusters of similar songs. We can therefore analyse the rankings by \ncalculating the Mean Average Precision (MAP). The MAP is a single-.gure measure between 0 and 1 quantifying \nthe precision of the retrieved results at all recall levels (Manning et al. 2008, Chap. 8, p. 160); a \nhigher MAP value indicates a better ranking. For the small dataset, gdiff has a MAP of 0.853, while baseline \nscores 0.475. In the large dataset the difference is smaller, but gdiff still outperforms baseline with \na score of 0.510 against 0.395, respectively. We tested whether the difference in MAP is signi.cant by \nper\u00adforming a Wilcoxon Signed-rank test1. We chose the Wilcoxon Signed-rank test because the underlying \ndistribution of the aver\u00adage precision over the queries is unknown, and this Signed-ranks test does not \nrequire the distribution to be normally distributed. The differences between baseline and gdiff were \nstatistically signif\u00adicant, with W = 1058.5, p < 0.0001 on the small dataset, and also on the large dataset, \nwith W = 80352, p < 0.0001. 1 All statistical tests were performed with the R language.  5.4 Comparison \nwith previous work There are considerable differences between our HARMTRACE sys\u00adtem and the context-free \ngrammar approach of De Haas et al. (2009, hereafter referred to as ISMIR09). 5.4.1 Error-correcting parsers \nOne of the drawbacks of ISMIR09 is that a sequence of chords that does not match the context-free speci.cation \nprecisely will be rejected. For instance, appending one nonsensical chord to an otherwise grammatically \ncorrect sequence of symbols will still force the parser to reject the complete sequence, not returning \nany partial information about what it has parsed. HARMTRACE solves this rejection problem by using error \ncorrecting parsers (Swierstra 2009). This allows us to formalize the rules of tonal harmony that we are \ncertain of, and leave the borderline cases to the parser. 5.4.2 Ambiguity control Music, and harmony \nin particular, is intrinsically ambiguous. Hence, certain chords can have multiple meanings within a \ntonal context. This is re.ected in both ISMIR09 and HARMTRACE. A major drawback of ISMIR09 is that it \nis very limited in ways of controlling the ambiguity of the grammar. ISMIR09 uses weighting to order \nthe grammar rules by adding low weights to rules that ex\u00adplain rare phenomena. However, controlling conditional \nexecution would require some form of high-level grammar generation system, since all rules are replicated \nfor each scale degree and chord class. On the other hand, HARMTRACE supports more .exible condi\u00adtional \nexecution, through the use of GADTs and type families. An example is the restriction of secondary dominants \nto chords of the Dom7 class (Section 3.3). 5.4.3 Parsing performance There are considerable differences \nin the parsing performance of HARMTRACE compared to ISMIR09 on both datasets. HARM-TRACE takes 1.65s \nto parse the small dataset, while ISMIR09 takes more than 9m. When we compare parsing performance on \nthe large dataset the differences become even more prominent: ISMIR09 rejects 89.7% of the 854 pieces \nand 3.9% of the dataset had to be excluded because the parsing process would not terminate (due to unconstrained \nambiguities). The remaining pieces parse in 84m13s, while HARMTRACE parses the entire dataset in 5m14s. \nAll measurements were done on the same Intel Core 2 duo E6600, 2.4 GHz machine using GHC 7.0.2 and Java \nSE 1.6.0 17. 5.4.4 Retrieval effectiveness Both HARMTRACE as well as ISMIR09 have been evaluated on \nthe small dataset. When we compare the retrieval effectiveness of the gdiff approach with the best performing \nvariant of ISMIR09 (MAP of 0.859), we conclude that there is no statistically signi.\u00adcant difference \n(W = 685, p = 1.00, using the same test procedure as in Section 5.3). Because ISMIR09 rejects 89.7 percent \nof the pieces, no sensible comparison between the two approaches on the large data set can be performed. \n 5.4.5 Grammar simplicity In ISMIR09 all context-free rules were written by hand, which is not only a \ntedious and error-prone enterprise, but can also result in very large grammars. By using Haskell s GADTs \nto represent the rules of tonal harmony, we gain more expressive power, and the grammar becomes shorter \nand easier to maintain. For instance, GADTs allow us to write rules that hold for every Maj chord. In \nISMIR09 this is expressed by having one rule for major I, II, III, etc.  5.4.6 Code repetition Our Haskell \nsystem is more concise than the Java implementation of ISMIR09. An analysis of the number of signi.cant \nsource lines of code2 reveals that ISMIR09 has 5545 lines, while HARMTRACE has 1311, less than one quarter. \n6. Discussion and conclusion We have shown how Haskell can be used to implement a model of musical harmony. \nOur solution outperforms a previous Java approach in terms of speed, functionality, and elegance. However, \nthe current implementation has a number of limitations, which we now describe in detail. 6.1 Type-checker \nperformance As mentioned in Section 4.1.1, it is easy to make the type-checker take very long to compile \nour code. We managed to keep the type\u00adchecking time acceptably low, but this is only because we are help\u00ading \nit. We minimized the number of type families used (four in total, all similar to V/), and we (automatically) \nplace each instance declaration in a separate module, since this speeds up compilation considerably. \nFurthermore, we represent each scale degree as an in\u00addependent type; type-level computations, such as \ntransposition, are then indexed over each type. A more concise way of representing scale degrees would \nbe to use type-level naturals. Transposition is then simply summing modulo the total number of scale \ndegrees. Unfortunately this makes the compilation time unacceptably high. We hope that native type-level \nnaturals are added to GHC soon3 so that we can simplify our type-level computations without a perfor\u00admance \npenalty. 6.2 Parser performance The higher average parsing time per song on the large dataset shown \nin Table 2 is caused mostly by a few songs taking very long. In this dataset, only about 6% of the songs \ntake longer than one second to parse. The three slowest songs take 41s, 24s, and 15s to parse. They are \nlong songs, and either contain chord sequences which our model does not account for or are harmonically \natypical. In these pathological cases the parser combinators take very long to compute the possible corrections. \nThis is somewhat understand\u00adable, since our grammar is highly ambiguous and there are mul\u00adtiple non-trivial \npossible corrections. However, such long parsing times are undesirable; perhaps the number of steps to \nlookahead in the parser could be dynamically adjusted based on the number of possible alternatives. This \nwould hopefully lead to shorter parsing times, albeit at the cost of potentially worse corrections. \n 6.3 Matching performance The generic diff is a powerful tool that solves the matching prob\u00adlem almost \nfor free (Section 5.3). However, to use it we need new generic functions to be derived for every datatype. \nThis means longer compilation times, but also more adhoc instances, since there is no suitable generic \nprogramming library supporting GADTs. These instances amount to over 200 lines of repetitive and error-prone \ncode. Worse, this code runs very slowly; our imple\u00admentation uses type-safe runtime casts, which prevents \nfusion of the generic representations (Magalh aes et al. 2010). This prevents us from using the generic \ndiff on datasets with thousands of songs. Besides addressing the limitations pointed out above, we also \nplan to add new functionality to our system. 2 Using http://cloc.sourceforge.net/. 3 http://hackage.haskell.org/trac/ghc/ticket/4385 \n  6.4 Mode and key In Section 3 we only discussed the rules for pieces in a major key. However, many \nsongs are written in a minor key; this affects the expected scale degrees at the leaves, invalidates \nsome alternatives, and creates others. Nevertheless, a large number of rules hold for both pieces in \na major and a minor key. Currently we handle this using a similar model for pieces in a minor key: data \nPiece = PieceMaj [PhraseMaj ] | PieceMin [PhraseMin ] However, this leads to unnecessary code duplication, \nsince most of the harmony rules are independent of mode. A better alternative would be to index pieces \nby their mode: data MajMode;data MinMode; data Piece \u00b5 = Piece [Phrase \u00b5 ] The type variable \u00b5 would \nthen be indexed with either MajMode or MinMode, similarly to d for degrees and . for chord classes. We \nthink this would be an elegant way of expressing mode in the model. Additionally, we currently restrict \nourselves to songs in a single key, but often songs change the key throughout their development. This \nmeans that scale degree I no longer maps to chord C, but to F, for instance. Indexing the model over \nthe key, and introducing rules for modulation which would change this key, would be a good way of encoding \nkey changes. Such changes would make the entire model indexed over one or more type variables. We plan \nto see if the extensions to instant-generics reported by Magalh aes and Jeuring (2011) allow us to continue \nusing generic programming for our model. 6.5 Other applications We show how to use our model for improving \nmusic retrieval, but we believe other tasks can be improved similarly. For instance, al\u00adgorithms for \ncomputing chord labels from audio or images (scores) often recognize a set of possible chords at each \nstep, with differ\u00adent probabilities. Our model could be used to check which chords are harmonically valid \nat each step, therefore introducing harmony knowledge into the algorithm. Another interesting development \nwould be to implement a (generic) enumerator over our datatypes; this would correspond to a generator \nof harmonically valid se\u00adquences of chords.  6.6 Dependently-typed implementation It would be interesting \nto see if we could easily port our system to a dependently-typed setting. We plan to use Agda (Norell \n2009), due to its proximity to Haskell, or Idris (Brady 2011), since it has ef.cient type-level naturals. \nWe expect that deriving the parser au\u00adtomatically will not be as easy, since generic programming support \nin dependently-typed languages is more primitive than in Haskell. However, we believe the model can bene.t \nfrom a more expressive type language. Having no barriers between values and types would reduce code duplication \nand simplify the model. At the same time, we expect that the increased expressiveness can be used to \nmodel more complex harmonic relations. Overall, we are convinced that strong static typing and generic \nprogramming are essential tools in modelling musical harmony. We hope that our approach paves the way \nfor future functional approaches to musical modelling and processing. Acknowledgments This work has been \npartially funded by the Portuguese Foundation for Science and Technology (FCT) via the SFRH/BD/35999/2007 \ngrant, and by the Dutch ICES/KIS III Bsik project MultimediaN. We thank Jurriaan Hage, Johan Jeuring, \nAndres L\u00a8 oh, Frans Wier\u00ading, and the anonymous reviewers for their helpful comments, and Doaitse Swierstra \nfor his exhaustive technical support in using his parser combinators. References E. Brady. Idris systems \nprogramming meets full dependent yypes. In PLPV 11, pages 43 54, 2011. M. M. T. Chakravarty, G. C. Ditu, \nand R. Leshchinskiy. Instant generics: Fast and easy, 2009. Draft version. D. Devriese and F. Piessens. \nExplicitly recursive grammar combinators a better model for shallow parser DSLs. In PADL 11, pages 84 \n98. Springer, 2011. J. Stephen Downie. Music information retrieval. Annual Review of Infor\u00admation Science \nand Technology, 37(1):295 340, 2003. W. B. de Haas, M. Rohrmeier, R. C. Veltkamp, and F. Wiering. Modeling \nharmonic similarity using a generative grammar of tonal harmony. In Proceedings of the Tenth International \nConference on Music Information Retrieval (ISMIR 09), pages 549 554, 2009. E. Lempsink, S. Leather, and \nA. L\u00a8Type-safe diff for families of oh. datatypes. In WGP 09, pages 61 72. ACM, 2009. F. Lerdahl and \nR. Jackendoff. A Generative Theory of Tonal Music. The MIT Press, 1983. ISBN 0-262-62107-X. J. P. Magalh \naes and J. Jeuring. Generic programming for indexed datatypes. Technical Report UU-CS-2011-021, Department \nof Information and Computing Sciences, Utrecht University, 2011. J. P. Magalh aes,S. Holdermans, J. Jeuring, \nandA. L\u00a8oh. Optimizing generics is easy! In PEPM 10, pages 33 42. ACM, 2010. C. D. Manning, P. Raghavan, \nand H. Sch\u00a8 utze. Introduction to Information Retrieval. Cambridge University Press, 2008. J. F. Mountford. \nThe musical scales of Plato s Republic. The Classical Quarterly, 17(3/4):125 136, 1923. U. Norell. Dependently \ntyped programming in agda. In AFP 08, volume 5832 of LNCS, pages 230 266. Springer, 2009. S. Peyton Jones, \nD. Vytiniotis, S. Weirich, and G. Washburn. Simple uni.cation-based type inference for GADTs. In ICFP \n06, pages 50 61. ACM, 2006. W. Piston and M. DeVoto. Harmony. Victor Gollancz, 1991. H. Riemann. Vereinfachte \nHarmonielehre; oder, die Lehre von den tonalen Funktionen der Akkorde. Augener, 1893. M. Rohrmeier. A \ngenerative grammar approach to diatonic harmonic struc\u00adture. In Proceedings of the 4th Sound and Music \nComputing Conference, pages 97 100, 2007. M. Rohrmeier. Towards a generative syntax of tonal harmony. \nJournal of Mathematics and Music, 5(1):35 53, 2011. R. Schrijvers, S. Peyton Jones, M. M. T. Chakravarty, \nand M. Sulzmann. Type checking with open type functions. In ICFP 08, pages 51 62. ACM, 2008. M. J. Steedman. \nA generative grammar for jazz chord sequences. Music Perception, 2(1):52 77, 1984. S. Doaitse Swierstra. \nCombinator Parsing: A Short Tutorial, pages 252 300. Springer-Verlag, 2009.     \n\t\t\t", "proc_id": "2034773", "abstract": "<p>Music theory has been essential in composing and performing music for centuries. Within Western tonal music, from the early Baroque on to modern-day jazz and pop music, the function of chords within a chord sequence can be explained by harmony theory. Although Western tonal harmony theory is a thoroughly studied area, formalising this theory is a hard problem.</p> <p>We present a formalisation of the rules of tonal harmony as a Haskell (generalized) algebraic datatype. Given a sequence of chord labels, the harmonic function of a chord in its tonal context is automatically derived. For this, we use several advanced functional programming techniques, such as type-level computations, datatype-generic programming, and error-correcting parsers. As a detailed example, we show how our model can be used to improve content-based retrieval of jazz songs.</p> <p>We explain why Haskell is the perfect match for these tasks, and compare our implementation to an earlier solution in Java. We also point out shortcomings of the language and libraries that limit our work, and discuss future developments which may ameliorate our solution.</p>", "authors": [{"name": "Jos&#233; Pedro Magalh&#227;es", "author_profile_id": "81453643564", "affiliation": "Utrecht University, Utrecht, Netherlands", "person_id": "P2801392", "email_address": "jpm@cs.uu.nl", "orcid_id": ""}, {"name": "W. Bas de Haas", "author_profile_id": "81488672189", "affiliation": "Utrecht University, Utrecht, Netherlands", "person_id": "P2801393", "email_address": "bash@cs.uu.nl", "orcid_id": ""}], "doi_number": "10.1145/2034773.2034797", "year": "2011", "article_id": "2034797", "conference": "ICFP", "title": "Functional modelling of musical harmony: an experience report", "url": "http://dl.acm.org/citation.cfm?id=2034797"}