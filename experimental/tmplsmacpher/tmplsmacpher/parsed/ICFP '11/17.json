{"article_publication_date": "09-19-2011", "fulltext": "\n Temporal Higher-Order Contracts Tim Disney Cormac Flanagan Jay McCarthy University of California, Santa \nCruz University of California, Santa Cruz Brigham Young University Abstract Behavioral contracts are \nembraced by software engineers because they document module interfaces, detect interface violations, \nand help identify faulty modules (packages, classes, functions, etc). This paper extends prior higher-order \ncontract systems to also ex\u00adpress and enforce temporal properties, which are common in soft\u00adware systems \nwith imperative state, but which are mostly left im\u00adplicit or are at best informally speci.ed. The paper \npresents both a programmatic contract API as well as a temporal contract lan\u00adguage, and reports on experience \nand performance results from im\u00adplementing these contracts in Racket. Our development formalizes module \nbehavior as a trace of events such as function calls and returns. Our contract system pro\u00advides both \nnon-interference (where contracts cannot in.uence cor\u00adrect executions) and also a notion of completeness \n(where contracts can enforce any decidable, pre.x-closed predicate on event traces). Categories and Subject \nDescriptors D.3.1 [Formal De.nitions and Theory]: Semantics; D.3.3 [Language Constructs and Fea\u00adtures]: \nConstraints General Terms Languages, Reliability, Security, Veri.cation. Keywords Higher-order Programming, \nTemporal Contracts 1. Contract Expressiveness Large software systems typically consist of many modules \n(e.g., packages, classes, functions) produced by different development teams. When the system fails, \nan initial dif.culty is fault localiza\u00adtion: identifying the module that failed to perform as expected. \nUn\u00addocumented module interfaces are problematic for various reasons, not least because they lead to disagreements \nabout which module is considered at fault and should be .xed. Software engineers embrace behavioral contracts \nbecause they address many of these problems. In particular, behavioral con\u00adtracts provide a mechanism \nto explicitly document each mod\u00adule s assumptions and guarantees; to dynamically detect contract violations; \nand to identify faulty modules. Behavioral contracts are widely used in procedural, object-oriented, \nand functional languages, including Eiffel [36], C [42], C# [32], Haskell [26], Java [28], Python [44], \nScheme [19, 15, 22], and Smalltalk [10]. Existing contract systems can express a range of interface spec\u00adi.cations. \nBelow, we consider a range of possible speci.cations for Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to \nlists, requires prior speci.c permission and/or a fee. ICFP 11, September 19 21, 2011, Tokyo, Japan. \nCopyright c &#38;#169; 2011 ACM 978-1-4503-0865-6/11/09. . . $5.00 a sort routine, not all of which are \nsupported by existing contract systems. 1. The sort function takes two arguments, an array of positive \nintegers and a comparison function cmp. This standard, .rst-order precondition constrains how sort should \nbe called, that is, what arguments are valid. These kinds of basic .rst-order contracts are supported \nby most contract systems, for example, Eiffel [36]. 2. The argument function cmp in turn requires two \narguments, both positive integers. This higher-order precondition constrains how the sort module can \ncall the function argument cmp, and so is a guarantee pro\u00advided by sort rather than an obligation on \nthe client. Higher\u00adorder contract systems [19, 15, 22, 24, 45] support such precon\u00additions by wrapping \nthe cmp argument to enforce this property dynamically. 3. The sort function is not re-entrant it can \nonly be called after all previous sort invocations have completed. Unlike the previous contracts that \nconstrain how functions may be called, this temporal contract constrains when sort can be called [12, \n13]. This constraint implies that sort must be used carefully in a multithreaded setting. Moreover, it \nalso imposes restrictions in a sequential setting, since for example, cmp is not allowed to call sort. \nA variety of prior systems support such .rst-order temporal contracts: for example, MOP [33], Tracematches \n[39], PathExplorer [25], Eagle [6], RuleR [7], and others. 4. sort is granted a capability to call the \ncmp function only until sort returns. This last contract is a higher-order temporal contract in that \nit combines both higher-order and temporal aspects. It expresses a temporal constraint, not on sort itself, \nbut on its higher-order interaction with the cmp argument it was passed. To enforce this contract, it \nis not suf.cient to instrument all cmp functions passed to sort, since these may legally be called from \nother call sites after sort returns. It is also insuf.cient to instrument only calls to cmp within sort, \nsince sort might pass a reference to cmp to a third party, who in turn could call cmp after sort returns. \nOur study of a widely-used standard library (see Section 8) indi\u00adcates that higher-order temporal constraints \nare common in soft\u00adware systems with imperative state, but are mostly left implicit or are at best informally \nspeci.ed. In this paper, we study how to ex\u00adpress and enforce such higher-order temporal contracts. Our \ndevel\u00adopment leverages and combines techniques from prior higher-order contract systems [19, 15, 22] \nand from .rst-order temporal contract systems [33, 39, 25, 6, 7]. We also address blame assignment in \na temporal setting. For the example considered above where sort passes cmp to a third party that later \ncalls cmp, our temporal con\u00adtract system immediately detects the error, halts execution, and cor\u00adrectly \nblames the sort module, even though it is neither the caller (the third party) nor the callee (cmp) of \nthe erroneous function call.  In a very general sense, contracts provide a means to specify and restrict \nthe behavior of a module. In a higher-order imperative setting, this notion of a module s behavior is \nquite complex, as it can involve higher-order callbacks, mutual recursion, and sharing of imperative \nstate between modules. Understanding the temporal and higher-order aspects of module behavior is a prerequisite \nto developing expressive contracts for constraining this behavior. The .rst step in our investigation \nis to formalize the behavior of each module as a sequence of events, namely remote procedure calls to \nother modules and matching returns, etc. We start with an operational abstract machine that extends a \ncontrol-store ma\u00adchine [16, 17] with a remote procedure call mechanism. This ab\u00adstract machine then generates \nstructural and scoping constraints on event sequences, and so bootstraps the game semantics. Module linking \ninvolves running abstract machines in parallel and appro\u00adpriately routing events between them. In this \nsetting, the observable behavior of a module is cap\u00adtured by the set of possible event sequences it can \ngenerate. Con\u00adsequently, the most general notion of a contract is a predicate de\u00adscribing permitted event \nsequences (that is, permitted observable behaviors of the module). We require that the set of event sequences \npermitted by a contract is pre.x-closed, so that errors are detected as soon as they occur. We also require \nthat contracts are computable predicates. Based on this formalism, we provide a monitor interface whereby \nprogrammers can express arbitrary contracts as predicates over event sequences. This monitor interface \nprovides: 1. non-interference, since the monitor code does not gain refer\u00adences (a.k.a. capabilities \n[37]) to mutable data or to functions, and so the monitor cannot perturb correct program executions, \nbut can only halt erroneous executions;1 and 2. a notion of completeness that we call trace completeness, \nmean\u00ading that a monitor can impose any computable pre.x-closed predicate on a module s event trace (i.e., \non its observable be\u00adhavior).  It is straightforward to achieve one of non-interference or trace completeness; \nachieving both simultaneously requires a more sub\u00adtle design since we need to provide monitors with all \ninformation about the observed trace (to achieve trace completeness) without giving it access to function \nreferences or to mutable state (in order to ensure non-interference). In addition to this programmatic \nmonitor interface, we also pro\u00advide a declarative contract language for expressing both structural and \ntemporal speci.cations of a module s behavior. The structural speci.cations expresses constraints on \nfunction arguments and re\u00adsults, and also names each function (including function arguments such as cmp \nabove). The temporal speci.cations is a regular gram\u00admar2 over calls and returns of functions named in \nthe structural component, and includes dependent sequences to express, for ex\u00adample, that a call to release(x) \nmust be preceded by a call to acquire(x), for any resource x. Each constraint in this language is compiled \ninto a monitor, and thus leverages the monitor interface to provide non-interference and blame assignment. \n1 Earlier work on higher-order contracts [20] also proposed non-interference as a design goal, but did \nnot achieve a notion of completeness. 2 We focus on checking safety but not liveness properties, and \nso do not need the additional expressiveness of temporal logics such as LTL [40]. Contributions The \nmain contributions of this paper are: We formalize the behavior of imperative higher-order modules as \nevent sequences, using an operational semantics (section 3).  We formalize a contract as a computable, \npre.x-closed predi\u00adcate on event sequences (section 4).  We present a monitor interface that satis.es \nthe twin design goals of non-interference and trace completeness (section 5).  We show how to track \nand assign blame for complex temporal contracts (section 6).  We present a declarative contract language \nfor expressing mixed structural and temporal contracts (section 7).  We describe a Racket [22]3 implementation \nof both the monitor interface and the contract language, and include preliminary performance and usability \nresults (section 8).4  2. Motivating Examples We .rst illustrate how our proposed contract language \nsuccinctly captures important structural and temporal constraints of software interfaces. To start, the \nfollowing formal contract captures all four of the desired constraints for sort informally outlined above: \nSortContract = sort : (List Pos) // 1 (cmp : Pos . Pos . Bool) // 2 . (List Pos) where not ... call(sort,_) \n!ret(sort,_)* call(sort,_) // 3 and not ... ret(sort,_) ... call(cmp,_) // 4 By convention, we use Initial \nCapitals to denote contract names such as Bool and Pos (for positive numbers) and SortContract. The notation \nname : Dom . Rng describes a function contract where the argument and result values should satisfy contracts \nDom and Rng respectively. The optional name : pre.x associates a name with each function, which can then \nbe referenced in the where clause. This clause expresses a regular constraint over the sequence of events \n(calls and returns of these named functions). The pattern ... matches any sequence of events, and the \nnot operator has low precedence, so its argument extends to the end of the where clause. The pattern \n matches any argument in a call or any return value in a ret. The pre.x ! denotes the negation of a \nsingle event (unlike not , which negates a pattern), and the post.x * denotes a sequence matching the \npreceding pattern. Thus, !ret(sort, )* denotes any sequence of events that does not include a return \nfrom sort. Whereas, not ret(sort, )* matches any traces that are not only returns from sort, such as \ntraces that start with a return from sort, a call to something else, then any other events. Constraint \n(3) declares sort to be non-reentrant; it cannot be called a second time before the .rst call returns. \nConstraint (4) is a little more complex in that it is a higher-order temporal contract. Each call of \nsort introduces a binding for cmp in the above con\u00adtract, and so cmp denotes not just one function, but \nany comparison function ever passed to sort. Each such comparison function has an associated sort invocation, \nand constraint (4) explicates that the comparison function cannot be called after the associated sort \ninvocation returns. 3 Formerly known as PLT Scheme. 4 The implementation is available in the core Racket \ndistribution as of July 2011 in the unstable collection.  As a simpler example, an implicit property \nof many library functions is that they are expected to return immediately after being called, with no \nintervening callbacks to client code. We document this atomicity property with the following contract, \nwhich detects an error if a call to f is not immediately followed by a matching return. AtomicContract \n= f : Any . Any where not ... call(f,_) !ret(f,_) Since internal calls within f are not externally visible, \nthis contract still permits arbitrary internal computation, but forbids callbacks to outside code. Note \nthat this atomicity guarantee is useful even in a sequential setting. The following interface describes \na .le system whose open method returns a File object corresponding to the given .le name. Each File object \ncontains methods for reading, writing, and clos\u00ading that .le, with the temporal constraint that once \nthe .le is closed these methods should not be called. Note that this temporal con\u00adstraint is scoped to \nits enclosing File object: calling close on one .le does not in.uence the ability to access other open \n.les. Put differently, the alphabet of close events is unbounded. FileSystemContract = open : String \n. FileContract FileContract = Record read : Unit . String write : String . Unit close : Unit . Unit where \nnot ... ret(close,_) ... (call(close,_) | call(read,_) | call(write,_)) Finally, consider the following \ncontract that documents a stan\u00addard alloc/free interface on some resource, where each resource instance \nhas an associated integer handle z. After a resource handle z has been freed, it should not be freed \nagain until after it has been re-allocated. The pattern ?z binds a variable z to an argument/re\u00adsult, \nallowing z to be referenced later in the grammar. AllocFreeContract = Record alloc : Unit . Int free \n: Int . Unit where not ... call(free,?z) !ret(alloc,z)* call(free,z) We now proceed to investigate a \ncontract system that can express these kinds of mixed structural and temporal constraints. 3. A Model \nof Module Interactions The starting point for our investigation of contract expressiveness is an imperative \nhigher-order language, namely the untyped impera\u00adtive lambda calculus with constants (c) and mutable \nreference cells. e ::= x | .x. e | ee | c | ref e To simplify our presentation, we use standard lambda-calculus \nen\u00adcodings of let expressions, sequencing, n-ary function de.nitions and calls, pairs (with accessors \nfst and snd), n-ary records, sums, booleans, conditionals, recursive de.nitions, and assertions. Thus, \ndespite its simplicity, this language is suf.cient to model many as\u00adpects of modern languages, including \nencapsulated behavior (via .-expressions) and both encapsulated and shared imperative state (via ref).5 \n5 The language does not support concurrency, whose interaction with tem\u00adporal higher-order contracts \nremains an important topic for future work. To facilitate our technical development, we take an interface\u00adoriented \nview to reference cells, as proposed by Reynolds [41], whereby ref e returns a pair of getter and setter \nfunctions for read\u00ading and updating the newly created reference cell. This representa\u00adtion allows calls \nto getter/setter functions to also model operations on shared mutable data, and so all inter-module interaction \nis mod\u00adeled by function calls and returns. A module generally denotes a syntactic construct such as a \npackage, class, function, etc. In the setting of the .-calculus, we take a module to simply mean a closed \nexpression e. Two modules e1 and e2 can be linked via function application (e1 e2). As an example, consider \nthe following module twice with an associated test harness H: def twice =(.f. .x. f (fx)) def H =(.t. \nt (.x. x+1) 4) The linked program (H twice) passes the result of twice into H, which then calls twice \nwith appropriate arguments (.x. x+1) and 4. The module twice in turn calls back into the (.x. x+1) function \nprovided by H. Thus, despite its simplicity, the imperative lambda calculus permits rich patterns of \nmodule interaction and callbacks. The goal of this paper is to formalize (and subsequently constrain, \nvia contracts) these interactions. 3.1 Semantics of Modules We formalize the semantics of a module using \nthe operational ab\u00adstract machine called the CSI machine de.ned in Figure 1. This machine includes both \ncode (C) and a store (S), and so in part func\u00adtions much like Felleisen s (C, S) machine [16, 17]. The \n[CALL] rule performs standard \u00df-reduction within an evaluation context E. The rule [PRIM] leverages an \nauxiliary d function to de.ne the se\u00admantics of primitives. For example, d(constant?, 4) = true. The \nrule [REF] for (ref v) creates a new reference cell by extending the store S with a triple (x, y) . v \n, where v is the initial value of the cell, and x and y are binding occurrences for functions that read \nand write the value of this cell via the [GET] and [SET] rules, respec\u00adtively. The last four rules of \nthe CSI machine add inter-module inter\u00adactions, in a manner analogous to remote procedure calls. Speci.\u00adcally, \nthe code term C may contain free variables not bound in the store S; these free variables are external \nreferences to functions de\u00ad.ned by other modules. The CSI machine communicates with these other modules \nvia an event stream. The CSI machine does not transmit .-expressions themselves; instead, each transmitted \nvalue is .rst translated into a handle, which is either a constant or a fresh variable. The following \nopera\u00adtion I[hC v] performs the appropriate translation of a value v into a handle h, and returns an \nappropriately updated interface compo\u00adnent. Constants c are transmitted by-value, and functions (.y. \ne) and imported variables y are transmitted by exporting a fresh vari\u00adable z that is bound by I to that \nvalue. As usual, I[z . v] denotes a function that is identical to I except that it maps z to v. def I[cC \nc]= I def I[zC (.y. e)] = I[z . .y. e] z fresh def I[zC y]= I[z . y] z fresh In a function application \nE[xv] where x is externally de.ned, the rule [SEND-CALL] .rst translates the argument value v into an \nexternal handle h via the operation I[hC v], and then transmits the event send.call(x, h). After transmitting \nthe event send.call(x, h), the module be\u00adcomes inactive or quiescent, with code E[send.callx .] indicat\u00ading \nthat the module is waiting for a matching return rcv.ret(x, hl), after which evaluation continues with \nE[hl]: see [RCV-RET].  Figure 1: CSI Machine Domains State CSI . Code \u00d7 Store \u00d7 Interface Evaluation \ncontext E ::= E[ e] |E[v ] |E[ref ] |Q[rcv.callx ] Quiescent context Q ::= |E[send.callx ] Code C ::= \nE[e] |Q[.] Value v ::= c | x | .y. e Store S .P(Var \u00d7 Var \u00d7 Value) Handle h ::= c | x Interface I . Var \n. Value Event a ::= ..ret(x, h) | ..call(x, h) Direction . ::= send | rcv Trace t ::= aa Transition \nrelation (.) . State \u00d7 Event. \u00d7 State (E[(.x. e) v], S, I ). (E[e[x := v]], S, I ) [CALL] l (E[cv], \nS, I ). (E[vl], S, I ) v= d(c, v) [PRIM] (E[ref v], S, I ). (E[pair xy],S[(x, y) . v],I ) x, y fresh \n[REF] (E[xv],S[(x, y) . vl],I ). (E[vl],S[(x, y) . vl],I ) [GET] (E[yv],S[(x, y) . vl],I ). (E[v],S[(x, \ny) . v],I ) [SET] .send.call(x,h) (E[xv], S, I) (E[send.callx .], S, I[ht v]) x . BV(S) [SEND-CALL] \n.rcv.ret(x,h) (E[send.callx .], S, I) (E[h], S, I ) [RCV-RET] .rcv.call(x,h) (Q[.], S, I) (Q[rcv.callx \n(vh)],S, I ) I(x)= v [RCV-CALL] .send.ret(x,h) (Q[rcv.callx v], S, I) (Q[.], S, I[ht v]) [SEND-RET] \nFigure 2: Example of Linking and Running Two CSI Machines Concurrently The two CSI machines shown below \ncooperate to evaluate linkRun([[H] , [ twice]]). After the initial bootstrapping, send events of one \nmachine match rcv events of the other and vice-versa. The .nal send.ret(y, 6) event reports the result \nof the execution is 6. Evaluation of H =(.t. t (.x. x+1) 4) I1 =[y . (.t. t (.x. x+1) 4)] J1 =[y . (.t. \nt (.x. x+1) 4),f . (.x. x+1)] ( rcv.callstart (.t. t (.x. x+1) 4), (., ( rcv.cally ((.t. t (.x. x+1) \n4) t), ( rcv.cally ((t (.x. x+1)) 4), ( rcv.cally (send.callt .) 4), ( rcv.cally (g 4), ( rcv.cally \n(send.callg .),  ).send.ret(start,y) \u00d8, \u00d8 \u00d8,I1 ).rcv.call(y,t) \u00d8,I1 ). \u00d8,I1 ).send.call(t,f) \u00d8,J1 ) \n .rcv.ret(t,g) \u00d8,J1 ).send.call(g,4) \u00d8,J1 ) .rcv.call(f,4) ( rcv.cally (send.callg (rcv.callf ((.x. x+1) \n4))), \u00d8,J1 ).2 \u00d8,J1 ).send.ret(f,5) ( rcv.cally (send.callg (rcv.callf 5)), \u00d8,J1 ).rcv.call(f,5) ( rcv.cally \n(send.callg .), ( rcv.cally (send.callg (rcv.callf ((.x. x+1) 5))), \u00d8,J1 ).2 \u00d8,J1 ).send.ret(f,6) ( rcv.cally \n(send.callg (rcv.callf 6)), ( rcv.cally (send.callg .), \u00d8,J1 ).rcv.ret(g,6) \u00d8,J1 ).send.ret(y,6) ( rcv.cally \n6, (., \u00d8,J1 ) Evaluation of twice =(.f. .x. f (fx)) I2 =[t . (.f. .x. f (fx))] J2 =[t . (.f. .x. f (fx)),g \n. (.x. f (fx))] ( rcv.callstart (.f. .x. f (fx)), \u00d8, \u00d8) .send.ret(start,t) (., \u00d8,I2 ) .rcv.call(t,f) \n( rcv.callt ((.f. .x. f (f x)) f), \u00d8, I2 ) . ( rcv.callt (.x. f (f x)), \u00d8, I2 ) .send.ret(t,g) ( ., \u00d8, \nJ2 ) .rcv.call(g,4) ( rcv.callg ((.x. f (f x)) 4), \u00d8, J2 ) . ( rcv.callg (f (f 4)), \u00d8, J2 ) .send.call(f,4) \n( rcv.callg (send.callf (f .)), \u00d8, J2 ) .rcv.ret(f,5) ( rcv.callg (f 5), \u00d8, J2 ) .send.call(f,5) ( rcv.callg \n(send.callf .), \u00d8, J2 ) .rcv.ret(f,6) ( rcv.callg 6, \u00d8, J2 ) .send.ret(g,6) ( ., \u00d8, J2 )  Since the \ncode component encodes both active and quiescent states, we de.ne both standard evaluation contexts E \nand quiescent contexts Q. A code component of Q[.] means that control is ex\u00adternal to the module, but \nthe module can still receive external calls via a rcv.call(x, h) event. Here, x should be some previously \nex\u00adported function whose de.nition v is de.ned by I, and evaluation continues with Q[rcv.callx (vh)], \nas described by [RCV-CALL]. Once (vh) reduces to a value v l, the rcv.callx marker indicates that control \nshould return to the caller module via [SEND-RET]. For a module e, we initialize its execution with the \ncode (rcv.callstart e), where start is an arti.cial variable name de\u00adnoting the initial evaluation of \na module. Once the evaluation of e terminates, it will return send.ret(start,h) and wait for incoming \nevents. The meaning of a module e is then the set of all possible event sequences Ia that e can generate \nunder the CSI machine: [ -] : Module .P(Trace) a [ e] = {Ia |(rcv.callstart e, \u00d8, \u00d8) .iCSI } We use t \nto range over traces or .nite event sequences Ia; we use T to range over sets of traces; and t \u00b7 tl to \ndenote trace concatena\u00adtion. The exported variables (EV ) and imported variables (IV ) in a CSI machine \nstate, and the bound variables (BV ) of a store S, are: EV ( C, S, I ) def = dom(I) IV ( C, S, I ) def \n= (F V (C) . F V (rng(S)) . F V (rng(I))) \\ BV (S) BV (S) def = {x, y | S contains (x, y) . v} Thus, \nthe initial state (rcv.callstart e, \u00d8, \u00d8) of a module s compu\u00adtation has no imported variables or capabilities \n[37]; they must be passed explicitly as arguments to functions de.ned by the module.  3.2 Running a \nSingle Module Suppose a program consists of a single module e, which performs some computation and then \nreturns a .nal result, with no subse\u00adquent interactions. We assume that the result is .rst-order data \n(i.e., a constant) since a function result would be opaque and thus mean\u00adingless. The following function \nrun(T ) extracts from the trace set T =[ e] the result of running the program e, which is simply the \nconstant it returns. def run(T )= {c | send.ret(start,c) . T } Thus, we run a program e by starting the \nCSI machine in state (rcv.callstart e, \u00d8, \u00d8) and run its computation until it emits a send.ret(start,c) \nevent containing the result of that computa\u00adtion.  3.3 Linking Two Modules More generally, a program \nmay consist of multiple (reactive) mod\u00adules that must be linked before running. For simplicity, we consider \nthe case where the program consists of just two modules e1 and e2, where the module e1 is a function \nthat expects the result of e2 as an argument. Subsequently, the two modules may continue to interact \nby communicating events, where every send event of e2 becomes a rcv event by e1, and vice versa. More \ngenerally, every event a of e2 must match a dual event a of e1, where the dual operation . on directions \nswaps sends and receives, and this dual operation extends in a compatible manner to events and to event \nsequences: def def send = rcv rcv = send Based on this dual operation, we formalize the notion of linking \nand running two trace sets T1 and T2 (where Ti =[ ei] ) as follows: def linkRun(T1,T2)= {c | send.ret(start,h) \n\u00b7 t2 . T2 send.ret(start,x) \u00b7 rcv.call(x, h) \u00b7 t2 \u00b7 send.ret(x, c) . T1} Here, trace set T2 (for the \nfunction argument) starts by returning a handle h. Trace set T1 returns a function x that is then immediately \napplied to handle h from T2. Subsequent events from the two trace sets must then correspond, with each \nsend event from T1 matching a receive event from T2, and vice versa. Eventually, after the function x \ncompletes its computation and its interaction with its argument h, trace set T1 .nally returns a result \nc. We assume that this result is .rst-order data (i.e., a constant) since a function result would be \nopaque and thus meaningless.  3.4 Example To illustrate module linking, Figure 2 revisits the (H twice) \nexam\u00adple to show how each module can run on a separate CSI machine, using the function linkRun to link \nup the event traces from these two machines. In particular, the handle t returned by the evaluation of \ntwice is passed as the argument to the function y produced by the evaluation of H. Subsequent events \nfrom the two modules must match exactly, with each send event from one module matching a corresponding \nrcv event from the other module. Finally, the H module returns the constant 6 as the result of applying \ny to twice; thus 6 is the .nal result of running this program. For this test harness, the module twice \nproduces the trace shown in the right column of Figure 2. However, twice can gener\u00adate many additional \ntraces if linked with other modules. The trace set [ twice] captures the set of all possible traces generated \nby the CSI machine when executing twice. 3.5 Semantic Equivalence We now have two notions of module \nlinking. We can link two modules e1 and e2 via function application, and run the resulting expression \n(e1 e2) on a single CSI machine according to run. Alternatively, we can run e1 and e2 on separate CSI \nmachines that communicate according to linkRun. The following theorem proves that these two notions coincide, \nwhich implies that linkRun correctly captures our notion of module composition as function application: \nTHEOREM 1 (Module Transparency). For any closed expressions e1 and e2, linkRun([[e1] , [ e2]]) = run([[e1 \ne2]]). PROOF: By proving a bisimulation relation between the CSI ma\u00adchine state of run and the CSI state \npairs of linkRun. D  3.6 Well-Formed Traces An inspection of the CSI machine reveals that it generates \ntraces satisfying the following structural and scoping properties; we refer to such traces as being well-formed. \n1. Traces consist of alternating send events, which produce a qui\u00adescent state, and receive events, which \nre-initiate computation.  2. Every send.ret(x, h) matches a preceding rcv.call(x, hl), and every rcv.ret(x, \nh) matches a preceding send.call(x, hl), so these events form balanced bracket pairs , with the excep\u00adtion \nof the initial send.ret(start,h) that starts each trace.  3. Exporting a variable x via send.call(y, \nx) or send.ret(y, x) adds x to the interface I, where it is in scope for subsequent rcv.call(x, h) events. \n   4. Importing a variable x via rcv.call(y, x) or rcv.ret(y, x) means that x occurs free in the CSI \nmachine and can be used in subsequent send.call(x, h) events. Properties 3 and 4 provide an implicit \nnotion of variable scop\u00ading, where the second variable in each event is a binding occur\u00adrence, and the \n.rst argument must be a bound occurrence. We con\u00adsider two traces to be a-equivalent if they are identical \nmodulo con\u00adsistent renaming of bound variables, and we implicitly perform a\u00adconversion to avoid name \ncollisions. The set T of traces generated by the CSI machine also satis.es the following properties: \n1. It is pre.x-closed. 2. Itis input-enabled, in that whenever it can receive one event it is willing \nto receive any well-formed event: if t.a . T , a and a l are both receive events, and t.al is well-formed \nthen t.al . T.  3.It is output-deterministic, in that at most one send event is possible at any point. \nThus, if t.a . T , t.al . T , and a and a l are both send events, then a = a l . 4. Contracts as Trace \nPredicates The CSI machine semantics exposes each module s behavior as a trace set. We now use this formalism \nto study contract enforcement. Consider a module e whose behavior is the set of traces [ e] . Each trace \nrepresents a behavior that could be observed on a par\u00adticular execution. A contract is a mechanism for \nrestricting the set of observable behaviors to those satisfying some safety predicate. Formally, a contract \nis a set of traces K . Trace that is pre.x\u00adclosed, computable, and that contains only well-formed traces. \nThe execution of e under contract K should only generate traces in the intersection K n [ e] . Since \nK restricts both rcv and send events, it explicates e s assumptions and guarantees. For a contract K, \nwe want to implement a function eK that takes as argument the module e. The function eK then observes \nall of e s behaviors and halts program execution if any of those behaviors violate K. Thus, eK should \nsatisfy a requirement like [ eK e] = K n [ e] . However, [ eK e] must be input-enabled but K (and hence \nK n [ e] ) may not be input-enabled, so more precisely [ eK e] should be the input-enabled closure of \nK n [ e] , that is, the smallest superset of K n [ e] that is input-enabled. Intuitively, [ eK e] has \nto receive bad events from its enclosing context but can block them from being sent on to e. 4.1 The \nUniversal Contract The identity function (.x. x) behaves like a universal contract, in that ((.x. x) \ne) exposes all the behaviors of module e. We start by studying the semantics [ .x. x] of this universal \ncontract. Consider the possible executions of the CSI machine starting from the initial state S0 = (rcv.callstart \n(.x. x), \u00d8, \u00d8). When\u00adever the machine imports a variable y via [RCV-CALL] or [RCV-RET], it immediately \nexports a fresh name, say yh, for that variable, via [SEND-CALL] or [SEND-RET]. Here, the hat (h\u00b7 ) operator \nmaps be\u00adtween imported and exported variable names, and is an involution (its own inverse). We extend \nthis hat operator to handles by de.n\u00ading c = c. The set of identity function traces [ .x. x] is then \nthe well-formed subset of the pre.x-closure of the following regular grammar. Note that the last two \nproductions essentially copy events from one side of the identity function to the other, renaming vari\u00adables \nappropriately. Tid ::= send.ret(start,f) | Tid \u00b7 rcv.call(f, h)\u00b7send.ret (f, h ) | Tid y, h ) \u00b7 rcv.call(y, \nh)\u00b7send.call(h| Tid \u00b7 rcv.ret (h (y, h)\u00b7send.ret y, h )  4.2 Copycat Traces We next consider contracts \nthat are more restrictive than the identity function. Suppose the target module e generates the trace: \nt = send.ret(start,h) \u00b7 a1 \u00b7 ... \u00b7 an If the contract K permits this trace then [ eK ] should include: \ndef copycat(t)= send.ret(start,f) \u00b7 rcv.call(f, h) \u00b7 send.ret(f, h )\u00b7 copy(a1) \u00b7 ... \u00b7 copy(an) This \ntrace returns a function f that is applied to the handle h produced by t. It then returns a renamed handle \nh , and subsequently copies every event ai from one side of eK to the other via the following event copying \nfunction copy(a): copy(send.call(y, h)) = y, h ) rcv.call(y, h)\u00b7send.call(h copy(send.ret (y, h)) = rcv.ret \n(y, h)\u00b7send.ret (h y, h ) copy(rcv.call(y, h)) = y, h )\u00b7send.call(y, h) rcv.call(h copy(rcv.ret (y, \nh)) = rcv.ret y, h )\u00b7send.ret (h(y, h) We extend copycat from traces to trace sets in a pointwise fashion: \ndef copycat(K)= {copycat(t) | t . K} This copycat function allows us to formalize the relationship be\u00adtween \nthe permissible traces K and the contract implementation eK . We require that eK copies only K-traces: \n[ eK ] is the pre.x and input-enabled closure of copycat(K) 5. The Programmatic Monitor Interface Based \non the above speci.cation, it is possible to hand-code an implementation eK for each contract K, but \nthese implementations are dif.cult to read and write, and can violate non-interference. Instead, we propose \nto express eK as a pair of a guard and a monitor. The prede.ned guard function performs the nec\u00adessary \ncopycat behavior on event streams and guarantees non\u00adinterference. It also encodes the observed event \nstream and com\u00admunicates it to the monitor M, which detects errors and reports them to the guard, which \nthen halts execution. Thus, we implement eK as: def eK =(guard M) Traces contain scope and binding information, \nwhich is tricky to communicate to the monitor M. Our chosen encoding is that, when an event such as rcv.call(\u00b7,x) \nintroduces a new variable x, the monitor M creates two new sub-monitors, say Mcall and Mret, which handle \nevents ..call(x, ) and ..ret(x, ), respec\u00adtively. This encoding avoids passing function references (or \nget\u00adters/setters for mutable reference cells) to M, which helps ensure non-interference. We also require \nthat the monitor M is closed, so that it does not gain accesses to function references through its en\u00advironment. \nBased on this discussion, the type t of the monitor M is: t =(Constant . Bool) \u00d7 (Unit . (False +(t \u00d7 \nt ))) When an event transmits a constant, the .rst component of M is called to decide if that event is \npermitted. That function can use mutable internal state to track and enforce temporal properties. Thus, \ntemporal properties of the contracts are implemented via imperative state in the monitor. When an event \ntransmits a function x, the second component of M is called, which again has the opportunity to halt \nexecution by retuning false. Otherwise, the function should return a pair of monitors for handling call \nand ret events on the function x.  The function guard below then converts its monitor argument M into \nan appropriate contract implementation that queries M to verify that each transmitted event is permitted: \n 1 guard M = 2 .x. if (constant? x) then 3 assert ((fst M) x) != false 4 x 5 else 6 let MM = (snd M)() \n7 assert MM != false 8 .y. (guard (snd MM) (x (guard (fst MM) y))) 5.1 Example Monitors Using the monitor \ninterface, it is straightforward to implement a universal monitor Any that permits all communication: \nrec Any = pair (.x. true) (.. pair Any Any) As a more interesting example, the following code shows how \nto implement revokable membranes [37]. In this code, ref true returns a pair of get and set methods. \nAs long as get() returns true, the monitor M behaves like the universal contract. Calling revoke puts \nfalse into the reference cell, after which all further communication is prohibited. The top-level membrane \nfunction returns a pair of the membrane monitor and its revoke function. 1 membrane = 2 .. let (get,set) \n= ref true 3 let revoke = .. set false 4 letrec M = pair (.x. get()) 5 (. . if (get()) 6 then (pair M \nM) 7 else false) 8 in pair M revoke Note that M is not strictly speaking a monitor, since it calls a \nfree variable get, which could (in theory, but not in this case) interfere with the enclosing program. \n 5.2 Deep Tracing A particularly interesting monitor is deepTrace, which performs deep or higher-order \ntracing. The code ((guard deepTrace) g) prints all calls and returns of g. Additionally, if g takes or \nreturns functions, then those functions are also traced. Thus, deep tracing reports both .rst-order and \nhigher-order interactions between the module g and the rest of the program. Revisiting the example twice \nfrom Section 3.4, the program (H ((guard deepTrace) twice)) prints out the event sequence shown in the \nright half of Figure 2 (modulo naming of bound variables). Alternatively, the program (((guard deepTrace) \nH) twice) prints out the event sequence shown in the left half of that .gure. In this manner, deep tracing \nallows the programmer to observe the trace semantics of a module as explored during a particular run. \nThe implementation of deepTrace uses an auxiliary function helper to generate the appropriate monitor. \nThe helper function takes four arguments: the .rst two indicate whether this monitor is observing send \nor receive events; the third whether it is receiving ret or call events; and the fourth argument is a \nfunction name. Every function that passes through the guard is assigned a new name via gensym, and the \ngenerated monitor then prints each event. 1 deepTrace = (helper \"send\" \"rcv\" \"ret\" \"start\") 2 3 helper \nsend rcv op fn = 4 pair (.x. print (send+\".\"+op+\"(\"+fn+\",\"+x+\")\") 5 true) 6 (.. let name = gensym() 7 \nprint (send+\".\"+op+\"(\"+fn+\",\"+name+\")\") 8 pair (helper rcv send \"call\" name) 9 (helper send rcv \"ret\" \nname))  5.3 Non-Interference and Trace Completeness We now revisit the design goals of non-interference \nand trace com\u00adpleteness, to show how they are achieved by the guard/monitor ar\u00adchitecture. First, for \nany monitor M, the function (guard M) satis.es non\u00adinterference, in that it behaves like the identity \nfunction except that it may abruptly halt certain (erroneous) executions. Thus, guard behaves like an \ninformation diode , in that information can .ow into the monitor M but can never .ow back out to the \nprogram. In a richer language with exceptions, guard would need to appropri\u00adately catch any thrown exceptions \nto ensure that they do not con\u00adstitute an additional information channel between the monitor and the \nenclosing program. THEOREM 2 (Non-Interference). For any closed expression M, [ guard M ] . [ .x. x] \n PROOF: By showing that the trace set [ .x. x] from section 4.1 is a superset of [ guard M ] . The behavior \nof M is irrelevant, since non-interference is guaranteed entirely by guard. D Our argument for trace \ncompleteness is based on showing that the monitor observes all events that cross the contract boundary. \nSpeci.cally, consider the semantics of an arbitrary module e under the deepTrace monitor, i.e., [[(guard \ndeepTrace) e] An investigation of the reachable states of the corresponding CSI machine shows that this \nmodule prints each send event before transmitting it, and prints each rcv event right after receiving \nit. In\u00adstead of printing these events, deepTrace could feed them into an algorithm that decides a computable \ncontract K over event traces, and could halt execution once that algorithm detects a trace that vio\u00adlates \nK. Consequently, any computable predicate over traces could be implemented using the monitor interface. \n 5.4 Dependent Contracts Dependent contracts allow a function s range contract R to depend on the function \ns argument x. If the argument x is itself a function, then R could violate non-interference by calling \nx. Our guard/monitor architecture avoids this dif.culty by only allowing dependency when the argument \nx is a .rst-order value (that is, a constant). Essentially, the argument x is saved on a stack by the \ndomain contract, and is then popped by the matching range contract. The following monitor illustrates \nhow to implement such dependent contracts. It speci.es a function contract where the integer result should \nbe greater than the integer argument. The monitor accepts only functions, where the function s argument \nx must be an integer constant that is pushed on a stack that records the arguments of currently active \ncalls, and the function s result y must be an integer that is greater than the argument.  1 increasingMonitor \n= 2 let (push,pop) = newStack() 3 pair (.x. false) // no constants allowed 4 (.. pair (pair (.x. (push \nx); (integer? x)) 5 (.. false)) 6 (pair (.y. (integer? y) &#38;&#38; y > pop()) 7 (.. false))) This \nexplicit stack design also avoids subtle dif.culties with blame assignment in traditional dependent contracts \n[15]. 6. Blame Assignment The discussion so far has focused on detecting contract violations; we next \naddress how to assign blame for these violations. In partic\u00adular, we show that blame assignment, previously \nstudied in higher\u00adorder contract systems [19], extends in a consistent fashion to the more general setting \nof temporal higher-order contracts. Suppose the program consists of two modules e1 and e2, with corresponding \ntrace sets Ti =[ ei] for i . 1, 2, and suppose that K is a contract on e2. The semantics of correct executions \nis de.ned as: linkRun(T1,K n T2) This formula links together the modules e1 and e2, with the re\u00adquirement \nthat all interaction between the two modules must be permitted by K. We now extend that semantics to \nassign blame, via the function linkMonitorRun(T1, K, T2) shown below. The .rst case in this de.nition \nis analogous to the function linkRun de.ned earlier, with the additional requirement that the trace send.ret(start,h) \n\u00b7 t2 in T2 must be permitted by K. The second case deals with assigning blame, where T1 and T2 want to \nexchange a message a that is not permitted by K, but where the pre.x of a is accepted by all parties. \nIn this situation, the module i sending that message is blamed. def linkMonitorRun(T1, K, T2)= {c | \nsend.ret(start,h) \u00b7 t2 . K n T2 send.ret(start,x) \u00b7 rcv.call(x, h) \u00b7 t2 \u00b7 send.ret(x, c) . T1} .{blamei \n| send.ret(start,h) \u00b7 t2 \u00b7 a . T2 send.ret(start,x) \u00b7 rcv.call(x, h) \u00b7 t2 \u00b7 a . T1 send.ret(start,h) \n\u00b7 t2 . K send.ret(start,h) \u00b7 t2 \u00b7 a . K if |t2| odd then i =1 else i =2 } Thus linkMonitorRun(T1, K, \nT2) extends linkRun(T1,K n T2) to return a blame label in situations where linkRun would fail silently. \n To incorporate blame assignment into the guard implementa\u00adtion, we introduce additional arguments to \ntrack the module and enclosing context of each monitor, where these two arguments are swapped for contravariant \ndomain checks (as in [19]). We assume a primitive blame for reporting blame, and an appropriate represen\u00adtation \nfor module labels (e.g., strings).  1 guard module context M = 2 .x. if (constant? x) then 3 if ((fst \nM) x) == false then blame module 4 x 5 else 6 let MM = (snd M)() 7 if MM == false then blame module 8 \n.y. (guard module context (snd MM) 9 (x (guard context module (fst MM) y))) Figure 3: Declarative HOT \nContracts M ::= S where R HOT contract S ::= .at(e) | n : S1 . S2 Structural contract R ::= A | !A | \nRR | R * | not R | R . R Temporal contract | ... | call(n, ?x) R | ret(n, ?x) R A ::= call(n, p) | ret(n, \np) Event patterns p ::= | x | c Value patterns n . Name Function names 7. The Declarative Contract Language \nThe programmatic monitor interface provides trace completeness, non-interference, and blame assignment. \nWe now leverage that in\u00adterface to develop a declarative contract language for writing mixed higher-order \ntemporal (HOT) contracts. Our declarative language sacri.ces trace completeness for ease-of-expression, \nbut still inter\u00adoperates with the monitor interface for situations where additional expressiveness is \nrequired. Figure 3 summarizes the contract syntax. A HOT contract S where R contains both a structural \ncomponent (S) that binds function names (n), and a temporal component (R) that imposes constraints on \nwhen those functions can be called or return. The .at structural contract .at(e) describes the set of \nconstants c that satisfy the predicate e. The higher-order structural contract (n : S1 . S2) describes \nfunctions where S1 and S2 specify the function s domain and range contracts, respectively, and n provides \na name for this function that can be referenced in the temporal component. In the temporal component, \nevent patterns call(n, p) and ret(n, p) denote calls and returns of the function named n, where the argument \nor result matches pattern p. Patterns include con\u00adstants, variables x, and , which matches any argument. \nTemporal contracts (R) include events (A), negated events (!A), concatentation (RR), Kleene closure (R \n*), negation of trace sets (not R), union (R . R), and the universal temporal contract ( ... ), which \nmatches any trace. Temporal contracts also include dependent sequencing patterns such as call(n, ?x) \nR, where the argument from the .rst event is bound to x, and can be referred to from within R. Dependent \nsequencing captures common con\u00adstraints on function arguments and returns, for example, that the argument \npassed to free must previously have been returned from alloc. 7.1 Semantics of HOT Contracts To formalize \nthe semantics of a structural contract S, we de.ne an abstract machine called the EF machine that describes \nwhat traces S permits. This EF machine contains an environment E and a stack F . The environment E associates \neach variable x with a direction . (describing whether x was sent or received) and a structural contract \nS (describing permitted uses of x). The stack F contains the variable names of inter-module calls (or \nstack frames). E ::= E | E,x : .S F ::= Variable * The EF machine generates traces according to the following \ntransition relation EF EF l. The stack length |F | indicates .a whether the contracted module is active \nor quescient, so if |F | is odd we require that . = send, and otherwise that . = rcv, in both of these \nrules.  ...call(x,h) (E, F )(E . (h : .S1), F.x) [S-CALL] where E(x)= .(n : S1 . S2) ...ret(x,h) (E, \nF.x)(E . (h : .S2),F ) [S-RET] where E(x)= .(n : S1 . S2) Assuming . = send, the rule [S-CALL] generates \na call event send.call(x, h), provided x was previously received and has a function contract. (If . = \nrcv then the dual situation applies.) The [S-RET] rule generates a return event that must return to the \ntop variable on the stack F . The operation E . (h : .S1) checks if a sent handle h is com\u00adpatible with \nthe argument contract S1, and extends the environment E appropriately. Note that the check run([[ec]]) \n= true ensures that the constant c satis.es the structural contract .at(e). E . (c : . .at(e)) = E provided \nrun([[ec]]) = true E . (x : .S)= E,x : .S The meaning of a structural contract S is then de.ned as the \nset of all traces that .rst return a handle satisfying S, and where subsequent interactions satisfy the \nrequirements of the EF machine: [ S] = { send.ret(start,h).t |(E0, start).t (E, F )} where E0 = \u00d8. (h \n: send S) The meaning of a temporal contract R is de.ned with respect to the environment E that is produced \nby the EF machine, where E is used to map each variable x in the trace to a name n that is referenced \nin the temporal contract. The relation p ~ h de.nes when a pattern p matches a handle h. Constants match \nconstants (c ~ c), and the pattern  matches any handle ( ~ h). [ ] : R \u00d7 E .P(Trace) [ call(n, p)]]E \n= {..call(y, h) | E(y)= n : ... and p ~ h} [ ret(n, p)]]E = {..ret(y, h) | E(y)= n : ... and p ~ h} [[!A] \nE = Event \\ [ A] E [ R1R2] E =[ R1] E \u00b7 [ R2] E [ R * ] E =[ R] * E [ not R] E = any trace \\ [ R] E \n[ R1 . R2] E =[ R1] E . [ R2] E [ ... ] E = any trace [ call(n, ?x) R] E = {..call(y, c) \u00b7 t | E(y)= \nn:.., t . [ R[x := c]]]E}[ ret(n, ?x) R] E = {..ret(y, c) \u00b7 t | E(y)= n:.., t . [ R[x := c]]]E} Finally, \nthe meaning of a contract (S where R) is de.ned as any trace that satis.es S, providing a resulting environment \nE, and where the trace also satis.es R with respect to E. The function pre.xes performs pre.x-closure \non a set of traces. [ S where R] def = { (send.ret(start,h) \u00b7 t) . pre.xes([[R] E ) |(E0, start).t (E, \nF ) and E0 = \u00d8. (h : send S) } Thus, a module e under contract S where R yields the trace set: [ e] n \n[ S where R]  7.2 Compiling HOT Contracts We enforce each contract (S where R) by compiling it into \nan appropriate monitor. We convert the temporal component R into a .nite state automaton, where s ranges \nover the state space of the automaton, s0 denotes the initial state, and the handlers calln and retn \nfor each function name n imperatively update s appropriately and return true if the automaton is in an \naccepting state and false otherwise. The code is roughly: let s = s0 calln = .i. \u00b7 \u00b7 \u00b7 check and update \ns appropriately \u00b7 \u00b7 \u00b7 . . . . . . retn = .o. \u00b7 \u00b7 \u00b7 check and update s appropriately \u00b7 \u00b7 \u00b7 . . . . . . \n in compile(.x.true,S) The function compile(f, S) generates a monitor that ensures that the trace satis.es \nS, and which is parameterized over a number of calln and retn functions that communicate to the temporal \ncode above. The additional argument f :(Constant .{.x.x} . Bool) is an observer function that is called \nand can signal an error whenever a value passes through this S boundary; it is used in the following \nrecursive de.nition of compile. compile :(Constant .{.x.x} . Bool) \u00d7 S . Monitor def compile(f, .at(e)) \n= pair (.x. (e x) &#38;&#38;(f x)) (.. false) def compile(f, n:S1 . S2)= pair (.x. false) (..(f (.x.x)) \n&#38;&#38; (pair compile(calln,S1) compile(retn,S2)))) def compile(f, y)= let (chkconst,chkfn) = y pair \n(.x. (f x) &#38;&#38; (chkconst x)) (..(f (.x.x)) &#38;&#38; (chkfn())) For the contract .at(e), the \ngenerated monitor accepts only constants; it checks that the constant satis.es both the observer function \nf and the predicate e. For the function contract n : S1 . S2, the generated monitor accepts only functions. \nIt immediately noti.es the observer that a function is passing through this contract, and then returns \na pair of monitors that monitor calls and returns of this function, in each case notifying calln or retn \nand enforcing the sub-contracts S1 or S2, as appropriate. Our implementation extends the structural contract \nlanguage to include variable references (y) for referring to prede.ned monitors such as the Any monitor \nde.ned in section 5.1. The compilation of such monitor references extends the referenced monitor to call \nthe observer function f appropriately. Compilation Correctness The compile function compiles a structural \ncontract S into a monitor in a manner than respects the intended meaning [ S] of the structural contract. \nTHEOREM 3 (Compilation Correctness). For any structural con\u00adtract S, [ S] = [ guard compile(.x.true,S)]]. \nPROOF SKETCH: We proceed by structural induction on S. In the case that S = .at(e): we substitute into \nthe theorem, then focus on the right-hand side. We expand the de.nition of compile and do beta reduction. \nThe application of (f x) in the de.nition reduces to true with the given f, so we remove it and the and-expression. \nThis and an application of eta produces the right-hand side: [ guard (pair e (..false))]]. If we expand \nthis application of guard, it only succeeds if the value sent to the contract is a constant, c, such \nthat (ec) evaluates to true. We now focus on the left-hand side. By expanding the de.nition of [ S] and \n., we get the condition that run([[ec]]) = true where c is the constant sent to the contract. Clearly \nthese two constraints are the same, so this case is completed.  In the case that S = n : S1 . S2, we \nuse the inductive hypothesis twice. However, getting to that point requires a few subtle steps. First, \nwe assume that calln and retn are .x.true for all n, since we are only considering structural contracts, \nso there are no temporal properties to enforce. Next, we consider the behavior of both sides after it \nhas been applied. Only the case where it is actually a function is relevant, because if it is a constant, \nboth trivially reject any subsequent events. After assuming we ve received a function, we then assume \nthat the function is called and returns. The contracts S1 and S2 protect the call and return through \nthe S-CALL and S-RET rules on the left and through the recursive calls to guard on the right and the \ninductive hypothesis ensures that these have identical semantics. D Compiling Dependent Sequences For \ndependent sequences, we follow the same general approach, except we cannot compile to a .nite state automaton. \nFor example, the constraint not ... call(free,?z) !ret(alloc,z)* call(free,z) requires unbound storage \nto record all freed locations z. Instead, we compile to a lazily constructed in.nite automaton. Each \nautomaton is a function from an event (call or return) to a next automaton as well as a boolean to encode \nacceptance. Event patterns are functions that return the epsilon automaton on matching and a null (rejecting) \nautomaton otherwise. In contrast, dependent sequences return a new automaton representing the rest of \nthe trace, and which includes an appropriate binding for the dependent variable z. Each of the regular \ngrammar operators (sequencing, comple\u00adment, etc) is implemented as an explicit automaton that simulates \nthe operator using the automaton functions representing its pieces. These implementations correspond \nprecisely to the intuitive expla\u00adnations of regular operator closure properties found in any textbook \non automata theory. Since Kleene star and sequencing may invoke their arguments multiple times, dependent \nsequences embedded in them will be duplicated for each successful match of the pattern. This approach \nis similar to regular expression derivatives [9, 38].  7.3 Examples Section 2 presented a variety of \nexamples of structural/temporal contracts, whose meaning and compilation can now be understood based \non the formalism of this section. In particular, the contract combinator Pair S1 S2 abbreviates the \ncontract for Church\u00adencoded pairs (S1 . S2 . Any) . Any , and generalizes to a Record combinator that \nsupports n-ary tuples. The speci.cation of temporal properties involves some sub\u00adtleties, which we illustrate \nby considering various contracts for a lock object with acquire and release methods. Our initial con\u00adtract \nstates that acquire and release are atomic, and calls must alternate between these functions, with acquire \nbeing called .rst. LockContract = Record acquire : Unit . Unit release : Unit . Unit where ( call(acquire,_) \nret(acquire,_) call(release,_) ret(release,_) )* This contract states the good behavior of this module. \nThis kind of speci.cation is not stable under extension, since adding and calling other methods from \nthis module would violate this contract. It is often safer to enumerate bad behavior, so that all unmen\u00adtioned \ngood behavior is allowed including good behavior not yet implemented. The following contract reads, Do \nnot call acquire twice without an interleaving release, and do not call release twice without an interleaving \nacquire. where not ... call(acquire,_) !call(release,_)* call(acquire,_) and not ... call(release,_) \n!call(acquire,_)* call(release,_) We must include the initial ... in the negations, because other\u00adwise \nwe are only disallowing traces that start with the illegal se\u00adquence. Unfortunately, this contract does \nnot specify that acquire must be called .rst. We rephrase the property as After calling acquire, you \nmay not call it again until you call release, after which you may not call release and so on. : where \n( call(acquire,_) !call(acquire,_)* call(release,_) !call(release,_)* )* This version is extensible, \nbecause our use of event negation matches functions that have yet to be written. Unfortunately, it constrains \nfuture versions of the module so that acquire must be the .rst call. If we simply rotate the sequence, \nwe avoid that problem: where ( !call(release,_)* call(acquire,_) !call(acquire,_)* call(release,_) )* \n This version reads, It is illegal to call release until you acquire, and you may not call acquire twice \nbefore calling release. Note that this speci.cation constrains only the client, not the lock object itself. \nWe conjoin the following atomicity requirement to complete our speci.cation. and not ... call(acquire,_) \n!ret(acquire,_) and not ... call(release,_) !ret(release,_) 8. Implementation Our presentation so far \naddresses an idealized language. To evalu\u00adate this approach in practice, we have extended and implemented \nthis design for the Racket programing language [22]. Our imple\u00admentation includes both the programmatic \nmonitor interface from Section 5 and the declarative HOT contract language of Section 7. Guard/Monitor \nImplementation Racket already provide a higher\u00adorder contract system with a variety of contract combinators \nthat have been widely used to document Racket s libraries, but which do not support temporal properties \ndirectly. Racket also provides a programmatic make-contract in\u00adterface, which creates a contract from \na user-provided projec\u00adtion function eproj that is expected to satisfy the requirement [ eproj ] . [ \n.x. x] (ignoring blame issues for simplicity). Since make-contract does not check that eproj is actually \na projection, it cannot guarantee non-interference. Our implementation uses this make-contract interface \nas a foundation on which to implement our guard/monitor architecture. This design allows monitors to \ninteroperate with the Racket lan\u00adguage and to annotate module boundaries, while also guaranteeing non-interference. \nOur implementation addresses a number of additional issues not considered in the .-caculus model. For \nexample, the presence of .rst-class continuations allows functions to return multiple times, or never \nreturn, and so the resulting event traces do not satisfy the well-bracketed property. In order to properly \nmatch calls and re\u00adturns, call events include a unique label, which is then repeated in each matching \nreturn event. The implementation works seamlessly with mutation, allowing monitors to interpose between \naccesses and updates to mutable structures which are just differently\u00adlabeled events in the trace grammar. \nThe implementation s mon\u00aditors are safe with respect to concurrent interaction via a kill-safe manager \nthread [21].  Declarative Contract Implementation Our HOT contract lan\u00adguage and implementation are \nalmost exactly as described in sec\u00adtion 7.2, although the implementation is more general. In particular, \nas well as the structural contract forms of section 7.2, it also ac\u00adcepts Racket s previous non-temporal \ncontract language (where these contracts do not produce events for the temporal portion). We also provide \na facility for de.ning macros to abbreviate common temporal constraints, such as the following atomic \nand transient macros. A function is atomic if it returns immediately af\u00adter it is called, with no intermediate \ninteractions that are visible to the contract; meaning no interactions to explicitly labeled func\u00adtions, \nsince we do not do deep-tracing by default: def atomic(f) = not ... call(f,_) !ret(f,_) A higher-order \nargument g is transient when passed to a function f if g can only be called before f returns that is, \nf does not get a permanent capability to call g, but only a transient capability. def transient(g,f) \n= not ... ret(f,_) ... call(g,_) The syntax R1 n R2 is introduced via a macro that expands to not (not \nR1).(not R2). Other macros including optional events, bounded-length sequences, etc. Performance Evaluation \nThe performance overhead of contracts depends critically on the amount of work performed by the appli\u00adcation \nwithin a contract boundary. To avoid this application de\u00adpendence, we compared the performance of temporal \ncontracts with Racket s current contract system using the following micro\u00adbenchmark. We applied a contract \nto the identity function that checks for integer arguments and results. The following results measure \nthe time to call the resulting function 106 times, under three different contract implementations: 870ms \nfor Racket s current contract system.  877ms for the new monitor interface.  854ms for the HOT contract \nlanguage.  The results demonstrate that, when the additional expressiveness of temporal contracts is \nnot used, our proposed contract system provides equivalent performance to Racket s current non-temporal \ncontract implementation. Furthermore, both the programmatic monitor interface and the HOT contract language \nprovide equiv\u00adalent performance. We investigated the overhead of temporal constraints by extend\u00ading the \ncontract to check that the called function is atomic. The resulting performance numbers are: 931ms for \nthe new monitor interface when enforcing atomicity.  1435ms for the HOT contract language when enforcing \natom\u00adicity, using an optimized implementation that does not support dependent sequencing.  2371ms for \nthe HOT contract language when enforcing atomic\u00adity, using a more general implementation that supports \ndepen\u00addent sequencing.  These results indicate that the monitor architecture provides an ef.cient mechanism \nfor enforcing simple temporal properties with little additional overhead. Our current implementation \nof temporal automata for the HOT contract language is quite general and so a little slow. Restricting \ntemporal constraints to disallow dependent sequences improves performance signi.cantly, and we conjecture \nthat other plausi\u00adble optimizations could achieve performance comparable to the monitor-based implementation. \nIn theory, it should be possible to optimize HOT contract patterns to the equivalent hand-coded mon\u00aditor, \nat least for common speci.cations such as atomicity, but this remains for future work. Monitoring Filesystem \nAccesses Experience with Racket s cur\u00adrent contract system indicate its overhead is quite adequate for \nmonitoring the vast majority of APIs, where the work inside the contract boundary dominates the contract \noverhead, and so con\u00adtracts have little impact on performance. We conjecture that many temporal contracts \nwould similarly have no performance impact. To evaluate this hypothesis, we modi.ed a GUI text editor \nto use a temporal contract to monitor its .lesystem accesses. As expected, we found no change in the \nuser experience in particular, the dif\u00adference in overall application runtime was unmeasurable in bench\u00admarking \nruns. Temporal Contracts for the Standard Library We conducted a study of 600 functions in the Racket \nstandard library to determine how many of these function could bene.t from temporal contracts. We found \nthat: 519 functions in the standard library are intended to be atomic. For example, the number? predicate \nmay be passed a function argument, but it is not permitted to call this argument; instead it should immediately \nreturn a boolean result.  51 library function are passed transient function arguments that the library \nmay call, but only before the library function returns. Examples include map, build-list, filter. None \nof these library functions are allowed to retain a reference to the argument function after the library \nfunction returns.  17 library function exhibit the opposite behavior, where they are passed function \narguments that should not be called until the library function returns. These are in-port, in-producer, \nstop-before, stop-after, make-do-sequence, make-custom-hash, make-immutable-custom-hash, make-weak-custom-hash, \ncompose, procedure-rename, procedure->method, procedure-reduce-arity, make-keyword-procedure, procedure-reduce-keyword-arity, \nnegate, curry, curryr.  The remaining 13 library functions have quite unconstrained behavior. Examples \ninclude apply, keyword-apply, and 11 sequence functions that may cause additional function calls (because \ninspecting a sequence can cause lazy code evaluation across a module boundary.)  Note that the issue \nof when a function is called, that is addressed in these temporal speci.cations, is much more critical \nin a language with imperative state and reactive behavior than in a purely function language, and our \nwork proposes a means to specify and enforce these temporal aspects of behavior. Adversarial Defense \nThe contract examples presented so far are useful for identifying and localizing defects in well-intentioned \nbut perhaps buggy code. Contracts are also valuable for enforcing properties at trust boundaries between \nmodules written by different principals. As an example, we developed an implementation of Tic-tac-toe \nwith adversarial players, where each player provides a function turn : Board . Board Here, Board is an \nabstract data type that provides board-get and board-set methods, and each player s turn function is \nsupposed to update the Board by placing an additional mark. The core of the game places complete con.dence \nin the players to follow the rules namely that they must only take one move and they cannot place their \nmark over the other player s mark and this assumption greatly simpli.es the implementation of the game \ncore.  Of course, this con.dence in each player s code may be mis\u00adplaced, due to unintentional bugs \nas well as intentional violations of the game rules. To make each untrusted turn function trustworthy, \nit is monitored by a temporal contract. For example, the following contract states that a turn may not \ncontain two calls to board-set. not ... call(board-set,_,_,_,_) !ret(turn,_,_,_)* call(board-set,_,_,_,_) \nAdditionally, the board should not observe the same row and col\u00adumn of the board being set twice (by \neither player) during a game.6 not ... call(board-set,_,?r,?c,_) !ret(game,_)* call(board-set,_, r, c,_) \nTo evaluate this architecture, we wrote a collection of player functions, including textual and graphical \ninteractive players, non\u00adcheating AI players, and cheating AI players. In all cases, the contracts behave \nas expected they catch all cheaters, both human and AI. Note that the game core consists entirely of \ncalls to contracted functions. To evaluate the performance overhead, we measured the time to play a 7 \nmove game between two deterministic non\u00adcheating AI players, both with and without the temporal contracts. \nThe average running time of 100 runs is: 247ms for the version without contracts, and  255ms for the \nversion with contracts.  This example demonstrates a key software engineering bene.t of HOT contracts: \nthe game model can be decoupled from the security policy, simplifying both in the process, while imposing \nminimal performance overhead in this case study. 9. Related Work Temporal Constraints Temporal constraints \nare widely under\u00adstood to be important aspects on a module s behavior, and prior work has eloquently \nargued for modeling software modules as players in a formal game [12, 13]. Our event sequences are anal\u00adogous \nto the interface automata of prior work, and extend those ideas to handle higher-order languages by introducing \nthe notions of variable binding and scope in event sequences. It also addresses dynamic enforcement rather \nthan static veri.cation. Runtime Veri.cation Much prior work has addressed runtime monitoring of system \nbehaviors. The MOP Framework [33] pro\u00advides a general runtime monitoring framework that supports multi\u00adple \nlanguages and logics. Aspect-Oriented Programming [29] is a technique for weaving into an existing program \nadditional func\u00adtionality, including contract checks on module boundaries. AOP has been used in tools \nthat enforce temporal properties speci.ed in LTL, such as Tracematches [39] and J-LO [8]. In other approaches, \nruntime monitors are synthesized from formal speci.cations, for example in PathExplorer [25], Eagle [6], \nand RuleR [7]. Program Trace Query Language (PTQL) [23] expresses temporal properties as SQL-like queries \nover program traces. Generally speaking, these approaches focus on temporal properties and do not provide \nex\u00adplicit support for higher-order functions. 6 Alternatively, this property could be enforced by a contract \nthat calls board-get instead of keeping history information, but that speci.cation does not guarantee \nnon-interference. Behavioral Contracts Meyer [34, 35, 36] introduced contracts with Eiffel and its contract-oriented \ndesign approach. Since then contracts have been used to extend static checking [14, 5] and for runtime \nmonitoring of higher-order programs [18]. These investi\u00adgations have progressed towards more expressive \ndependent con\u00adtracts [18, 31, 24, 15]. In contrast, our work moves contract ex\u00adpressiveness in a different \northogonal direction where contracts enforce temporal properties. Our work explicitly enforces that contracts \ncan only observe, but not in.uence, execution (apart from stopping execution on con\u00adtract violations). \nPrior work on dependent contracts has been more lax in this regard, including allowing dependent function \ncontracts to observe the argument value, and even call that value in cases where it is a function [18, \n31]. This interpretation of contracts as code eventually requires that each contract is considered an \naddi\u00adtional module in the system, with its own blame label [15]. Our usage of the .exibility of Racket \ncontracts to enforce temporal constraints is unique7, except in one case: Tov and Pu\u00adcella [43] implement \na contract for af.ne functions. Of course, af.ne-ness allowing at most a single call is a temporal property \nthat is trivially encoded in our DSL. Their implementation ap\u00adproach is neceassarily similar to ours, \nalthough it is clearly limited to a single temporal property. Game Semantics Much prior work has studied \nthe denotational semantics of higher-order languages, often with the goal of de\u00adveloping fully abstract \ndenotational semantics in which observable equivalence implies denotational equivalence. Game semantics \nhas emerged as an appealing foundation for developing fully abstract denotational models. For example, \nfully abstract game semantics have been developed for PCF [3, 27] or for languages with fea\u00adtures such \nas call-by-value [4], general references [2], and excep\u00adtions [11, 30], to name just a few. Compositional \ngame seman\u00adtics also facilitate compositional veri.cation [1]. Our work draws deeply on game semantics \nas a tool to study contract systems and module behavior, but follows a different development that starts \nwith the CSI machine, which provides a connection between oper\u00adational semantics and game semantics. \n10. Discussion and Future Work We have presented a programmatic monitor architecture for con\u00adtracts that \nsatis.es the twin goals of trace completeness (all computable, pre.x-closed contracts are expressible) \nand non\u00adinterference (contracts cannot in.uence correct executions). The architecture also provides precise \nblame assignment, even for com\u00adplex temporal properties. Additionally, we presented a declarative contract \nlanguage that can express a variety of temporal constraints on module behavior that are common in software \nsystems with imperative state, but they are often left undocumented. Our contract language provides a \nconvenient declarative means for explicating these temporal aspects of library interfaces. We have formalized \nour ideas in the context of an untyped lan\u00adguage that supports rich interactions between modules, including \nmutual recursion, higher-order functions and callbacks, and both encapsulated and shared imperative state. \nExtending these ideas to additional language features is an important topic for future work. For compound \ndata structures such as lists or arrays, con\u00adtracts could be enforced eagerly (as with constants) or \nlazily (as with functions). In this work, compound data structures are Church\u00adencoded as functions and \nso checked lazily, but eager checking is an interesting alternative. Other topics for future work include \nthe de\u00ad 7 Based on a search on the publically available Racket code: the core distribution and an online \npackage repository.  velopment of temporal contracts for typed languages and the study of temporal higher-order \ncontracts in a concurrent setting. Acknowledgements We thank Shriram Krishnamurthi and Michael Greenberg \nfor valuable comments on an earlier draft of this paper, Robby Findler for helpful discussions on temporal \ncontracts, and Matthias Felleisen for exploring temporal contracts for game policy enforcement. We are \nalso grateful to the anonymous reviewers of ICFP 2011 for their constructive feedback. This material \nis based upon work supported by the National Science Foundation under Grants 1016334 and 0905650. References \n[1] Samson Abramsky, Dan R. Ghica, Andrzej S. Murawski, and C.- H. Luke Ong. Applying game semantics \nto compositional software modeling and veri.cation. In TACAS, pages 421 435, 2004. [2] Samson Abramsky, \nKohei Honda, and Guy McCusker. A fully abstract game semantics for general references. In LICS, pages \n334 344, 1998. [3] Samson Abramsky, Radha Jagadeesan, and Pasquale Malacaria. Full abstraction for PCF. \nInformation and Computation, 163:409 470, 1996. [4] Samson Abramsky and Guy McCusker. Call-by-value games. \nIn CSL, pages 1 17, 1997. [5] Mike Barnett, K. Rustan M. Leino, and Wolfram Schulte. The Spec# programming \nsystem: An overview. In Construction and Analysis of Safe, Secure and Interoperable Smart Devices, pages \n49 69, 2004. [6] Howard Barringer, Allen Goldberg, Klaus Havelund, and Koushik Sen. Rule-based runtime \nveri.cation. In VMCAI, pages 44 57, 2004. [7] Howard Barringer, David Rydeheard, and Klaus Havelund. \nRule Systems for Run-time Monitoring: from EAGLE to RULER. J Logic Computation, November 2008. [8] Eric \nBodden. J-LO -A tool for runtime-checking temporal assertions. Diploma thesis, RWTH Aachen University, \nNovember 2005. [9] Janusz A. Brzozowski. Derivatives of regular expressions. J. ACM, 11:481 494, October \n1964. [10] Manuela Carrillo-Castellon, Jes\u00b4us Garc\u00b4ia Molina, Ernesto Pimentel, and Israel Repiso. Design \nby contract in smalltalk. JOOP, 9(7):23 28, 1996. [11] Robert Cartwright, Pierre-Louis Curien, and Matthias \nFelleisen. Fully abstract semantics for observably sequential languages. Inf. Comput., 111(2):297 401, \n1994. [12] Luca de Alfaro and Thomas A. Henzinger. Interface automata. In Foundations of Software Engineering, \npages 109 120, 2001. [13] Luca de Alfaro and Mari\u00a8elle Stoelinga. Interfaces: A game-theoretic framework \nfor reasoning about component-based systems. Electr. Notes Theor. Comput. Sci., 97:3 23, 2004. [14] David \nL. Detlefs, K. Rustan M. Leino, Greg Nelson, and James B. Saxe. Extended static checking. Research Report \n159, Compaq Systems Research Center, December 1998. [15] C. Dimoulas, R. Findler, C. Flanagan, and M. \nFelleisen. Correct blame for contracts: No more scapegoating. In POPL, 2011. [16] Matthias Felleisen, \nRobert Bruce Findler, and Matthew Flatt. Semantics Engineering with PLT Redex. The MIT Press, 1st edition, \n2009. [17] Matthias Felleisen and Daniel P. Friedman. A calculus for assignments in higher-order languages. \nIn POPL, pages 314 325, 1987. [18] R. Findler and M. Felleisen. Contracts for higher-order functions. \nIn ICFP, 2002. [19] Robert Findler and Matthias Blume. Contracts as pairs of projections. Functional \nand Logic Programming, pages 226 241, 2006. [20] Robert Bruce Findler, Matthias Blume, and Matthias Felleisen. \nAn investigation of contracts as projections. Technical report, University of Chicago, 2004. [21] Matthew \nFlatt and Robert Bruce Findler. Kill-safe synchronization abstractions. In Programming Language Design \nand Implementation, pages 47 58, 2004. [22] Matthew Flatt and PLT. Reference: Racket. Technical Report \nPLT\u00adTR-2010-1, PLT Inc., 2010. http://racket-lang.org/tr1/. [23] Simon F. Goldsmith, Robert O Callahan, \nand Alex Aiken. Relational queries over program traces. OOPSLA, pages 385 402, 2005. [24] Michael Greenberg, \nBenjamin C. Pierce, and Stephanie Weirich. Contracts made manifest. In POPL, 2010. [25] Klaus Havelund \nand Grigore Rosu. An overview of the runtime veri.cation tool Java PathExplorer. In Formal Methods in \nSystem Design, 2003. [26] Ralf Hinze, Johan Jeuring, and Andres L\u00a8oh. Typed contracts for functional \nprogramming. In Functional and Logic Programming (FLOPS), pages 208 225. Springer-Verlag, 2006. [27] \nJ. M. E. Hyland and C.-H. Luke Ong. On full abstraction for PCF: I, II, and III. Inf. Comput., 163(2):285 \n408, 2000. [28] Murat Karaorman, Urs H\u00a8olzle, and John Bruno. jContractor: A re.ective Java library to \nsupport design by contract, 1998. [29] Gregor Kiczales, John Lamping, Anurag Mendhekar, Chris Maeda, \nCristina Lopes, Jean-Marc Loingtier, and John Irwin. Aspect-oriented programming. In ECOOP, chapter 10, \npages 220 242. 1997. [30] J. Laird. A fully abstract game semantics of local exceptions. In Logic in \nComputer Science, Washington, DC, USA, 2001. [31] Blume Matthias and David McAllester. Sound and complete \nmodels of contracts. J. Funct. Program., 16:375 414, July 2006. [32] K McFarlane. Design by contract \nframework. [33] Patrick O Neil Meredith, Dongyun Jin, Dennis Grif.th, Feng Chen, and Grigore Ros\u00b8u. An \noverview of the MOP runtime veri.cation framework. International Journal on Software Techniques for Technology \nTransfer, 2011. to appear. [34] B. Meyer. Object-oriented Software Construction. Prentice-Hall, 1988. \n[35] B. Meyer. Design by contract. In Advances in Object-Oriented Software Engineering, pages 1 50. Prentice-Hall, \n1991. [36] B. Meyer. Eiffel: The Language. Prentice-Hall, 1992. [37] Mark Samuel Miller. Robust composition: \ntowards a uni.ed approach to access control and concurrency control. PhD thesis, Johns Hopkins University, \nBaltimore, MD, USA, 2006. [38] Scott Owens, John Reppy, and Aaron Turon. Regular-expression derivatives \nre-examined. J. Funct. Program., 19:173 190, March 2009. [39] Chris Allan Pavel, Chris Allan, Pavel Avgustinov, \nAske Simon Christensen, Laurie Hendren, Sascha Kuzins, Oege De Moor, Damien Sereni, Ganesh Sittampalam, \nand Julian Tibble. Adding trace matching with free variables to AspectJ. In OOPSLA, pages 345 364. ACM \nPress, 2005. [40] Amir Pnueli. The temporal logic of programs. In Foundations of Computer Science, pages \n46 57, 1977. [41] John C. Reynolds. The essence of ALGOL, pages 67 88. Birkhauser Boston Inc., Cambridge, \nMA, USA, 1997. [42] David S. Rosenblum. A practical approach to programming with assertions. IEEE Transactions \non Software Engineering, 21, 1995. [43] Jesse Tov and Riccardo Pucella. Stateful contracts for af.ne \ntypes. Programming Languages and Systems, pages 550 569, 2010. [44] T. Tuglular, C. A. Muftuoglu, F. \nBelli, and M. Linschulte. Event\u00adbased input validation using design-by-contract patterns. In Software \nReliability Engineering, pages 195 204, 2009. [45] Dana N. Xu, Simon L. Peyton Jones, and Koen Claessen. \nStatic contract checking for Haskell. In POPL, pages 41 52, 2009.    \n\t\t\t", "proc_id": "2034773", "abstract": "<p>Behavioral contracts are embraced by software engineers because they document module interfaces, detect interface violations, and help identify faulty modules (packages, classes, functions, etc). This paper extends prior higher-order contract systems to also express and enforce temporal properties, which are common in software systems with imperative state, but which are mostly left implicit or are at best informally specified. The paper presents both a programmatic contract API as well as a temporal contract language, and reports on experience and performance results from implementing these contracts in Racket.</p> <p>Our development formalizes module behavior as a trace of events such as function calls and returns. Our contract system provides both non-interference (where contracts cannot influence correct executions) and also a notion of completeness (where contracts can enforce any decidable, prefix-closed predicate on event traces).</p>", "authors": [{"name": "Tim Disney", "author_profile_id": "81488668581", "affiliation": "University of California, Santa Cruz, Santa Cruz, CA, USA", "person_id": "P2801398", "email_address": "tdisney@ucsc.edu", "orcid_id": ""}, {"name": "Cormac Flanagan", "author_profile_id": "81100538763", "affiliation": "University of California, Santa Cruz, Santa Cruz, CA, USA", "person_id": "P2801399", "email_address": "cormac@ucsc.edu", "orcid_id": ""}, {"name": "Jay McCarthy", "author_profile_id": "81329490606", "affiliation": "Brigham Young University, Provo, UT, USA", "person_id": "P2801400", "email_address": "jay@cs.byu.edu", "orcid_id": ""}], "doi_number": "10.1145/2034773.2034800", "year": "2011", "article_id": "2034800", "conference": "ICFP", "title": "Temporal higher-order contracts", "url": "http://dl.acm.org/citation.cfm?id=2034800"}