{"article_publication_date": "09-19-2011", "fulltext": "\n Modular Veri.cation of Preemptive OS Kernels Alexey Gotsman IMDEA Software Institute Alexey.Gotsman@imdea.org \nAbstract Most major OS kernels today run on multiprocessor systems and are preemptive: it is possible \nfor a process running in the kernel mode to get descheduled. Existing modular techniques for verify\u00ading \nconcurrent code are not directly applicable in this setting: they rely on scheduling being implemented \ncorrectly, and in a preemp\u00adtive kernel, the correctness of the scheduler is interdependent with the correctness \nof the code it schedules. This interdependency is even stronger in mainstream kernels, such as Linux, \nFreeBSD or XNU, where the scheduler and processes interact in complex ways. We propose the .rst logic \nthat is able to decompose the veri.\u00adcation of preemptive multiprocessor kernel code into verifying the \nscheduler and the rest of the kernel separately, even in the pres\u00adence of complex interdependencies between \nthe two components. The logic hides the manipulation of control by the scheduler when reasoning about \npreemptable code and soundly inherits proof rules from concurrent separation logic to verify it thread-modularly. \nThis is achieved by establishing a novel form of re.nement between an operational semantics of the real \nmachine and an axiomatic seman\u00adtics of OS processes, where the latter assumes an abstract machine with \neach process executing on a separate virtual CPU. The re.ne\u00adment is local in the sense that the logic \nfocuses only on the relevant state of the kernel while verifying the scheduler. We illustrate the power \nof our logic by verifying an example scheduler, modelled on the one from Linux 2.6.11. Categories and \nSubject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; F.3.1 [Logics and Meanings \nof Programs]: Specifying and Verifying and Reasoning about Pro\u00adgrams; D.4.1 [Operating Systems]: Process \nManagement General Terms Languages, Theory, Veri.cation Keywords Veri.cation, Concurrency, Scheduling, \nModularity 1. Introduction Developments in formal veri.cation now allow us to consider the full veri.cation \nof an operating system (OS) kernel, one of the most crucial components in any system today. Several recent \nprojects have demonstrated that formal veri.cation can tackle real\u00adistic OS kernels, such as a variant \nof the L4 microkernel [17] and Microsoft s Hyper-V hypervisor [3]. Having dealt with relatively small \nmicrokernels, these projects nevertheless give us hope that in Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 11, September 19 21, 2011, Tokyo, Japan. \nCopyright c &#38;#169; 2011 ACM 978-1-4503-0865-6/11/09. . . $10.00 Hongseok Yang University of Oxford \nHongseok.Yang@cs.ox.ac.uk the future we will be able to verify the likes of kernels from today s mainstream \noperating systems, such as Windows and Linux. In this paper, we tackle one of the main challenges in \nrealising this hope handling kernel preemption in a multiprocessor system. Most major OS kernels are \ndesigned to run with multiple CPUs and are preemptive: it is possible for a process running in the kernel \nmode to get descheduled. Reasoning about such kernels is dif.cult for the following reasons. First of \nall, in a multiprocessor system several invocations of a system call may be running concurrently in a \nshared address space, so reasoning about the call needs to consider all possible interac\u00adtions among \nthem. This is a notoriously dif.cult problem; how\u00adever, we now have a number of logics [3 5, 13, 20, \n23] that can reason about concurrent code. The way the logics make veri.ca\u00adtion tractable is by using \nthread-modular reasoning principles that consider every thread of computation in isolation under some \nas\u00adsumptions about its environment and thus avoid direct reasoning about all possible interactions. The \nproblem is that all these logics can verify code only un\u00adder so-called interleaving semantics, expressed \nby the well-known operation semantics rule: Ck -. Ck q q C1 I ... I Ck I ... I Cn -. C1 I ... I Ck I \n... I Cn This rule effectively assumes an abstract machine where every process Ck has its own CPU, whereas \nin reality, the processes are multiplexed onto available CPUs by a scheduler. Furthermore, in a preemptive \nkernel, the scheduler is part of the kernel being veri.ed and its correctness is interdependent with \nthe correctness of the rest of the kernel (which, in the following, we refer to as just the kernel). \nThus, what you see in a C implementation of OS system calls and what most logics reason about is not \nwhat you execute in such a kernel. When reasoning about a system call implementation in reality, we have \nto consider the possibility of context-switch code getting executed at almost every program point. Upon \na context switch, the state of the system call will be stored in kernel data structures and subsequently \nloaded for execution again, possibly on a different CPU. A bug in the scheduling code can load an incorrect \nstate of the system call implementation upon a context switch, and a bug in the system call can corrupt \nthe scheduler s data structures. It is, of course, possible to reason about the kernel together with \nthe scheduler as a whole, using one of the available logics. However, in a mainstream kernel, where kernel \npreemption is enabled most of the time, such reasoning would quickly become intractable. In this paper \nwe propose a logic that is able to decompose the veri.cation of safety properties of preemptive OS code \ninto ver\u00adifying the scheduler and preemptable code separately. This is the .rst logic that can handle \ninterdependencies between the scheduler and the kernel present in mainstream OS kernels, such as Linux, \nFreeBSD and XNU. Our logic consists of two proof systems, which we call high-level and low-level. The \nhigh-level system veri.es preemptable code assuming that the scheduler is implemented cor\u00adrectly (Section \n4.3). It hides the complex manipulation of control by the scheduler, which stores program counters of \nprocesses (de\u00adscribing their continuations) and jumps to one of them during a context switch. In this \nway, the high-level proof system provides the illusion that every process has its own virtual CPU the \ncon\u00adtrol moves from one program point in the process code to the next without changing its state. This \nillusion is justi.ed by verifying the scheduler code separately from the kernel in the low-level proof \nsystem (Section 4.4).  A common way to simplify reasoning about program compo\u00adnents sharing an address \nspace, such as the scheduler and the ker\u00adnel, is to introduce the notion of ownership of memory areas: \nonly the component owning an area of memory has the right to access it. The main dif.culty of decomposing \nthe veri.cation of the main\u00adstream OS kernels mentioned above lies in the fact that in such kernels there \nis no static address space separation between data structures owned by the scheduler and the rest of \nthe kernel: the boundary between these changes according to a protocol for trans\u00adferring the ownership \nof memory cells and permissions to access them in a certain way. For example, when an implementation \nof the fork system call asks the scheduler to make a new process runnable, the scheduler usually gains \nthe ownership of the process descriptor provided by the system call implementation. This leads to several \ntechnical challenges our logic has to deal with. First, this setting introduces an obligation to prove \nthat the scheduler and the kernel do not corrupt each other s data structures. To this end, we base our \nproof systems on concurrent separation logic [20], which allows us to track the dynamic memory partition\u00ading \nbetween the scheduler and the rest of the kernel and prohibit memory accesses that cross the partitioning \nboundary. For exam\u00adple, assertions in the high-level proof system talk only about the memory belonging \nto the kernel and completely hide the memory belonging to the scheduler. A frame property, validated \nby concur\u00adrent separation logic, implies that in this case any memory not men\u00adtioned in the assertions, \ne.g., the memory belonging to the sched\u00aduler, is guaranteed not to be changed by the kernel. A realistic \nin\u00adterface between the scheduler and the kernel is supported by proof rules for ownership transfer of \nlogical assertions between the two components describing permissions to access memory cells. Second, \nin reasoning about mainstream operating systems, the ownership transfer between the scheduler and the \nkernel can in\u00advolve not only .xed memory cells, but arbitrary logical facts de\u00adscribing them (Section \n4.3). Such ownership transfers make even formalising the notion of scheduler correctness non-trivial, \nas they are dif.cult to accommodate in an operational semantics of the ab\u00adstract machine with one CPU \nper process the scheduler is supposed to implement. In this paper we resolve this problem by introduc\u00ading \na concept of logical re.nement between an operational seman\u00adtics of the real machine and an axiomatic \n(as opposed to opera\u00adtional) semantics of the abstract machine, de.ned in our logic by the high-level \nproof system. Namely, desired properties of OS code are proved with respect to the abstract machine using \nthe high-level proof system; the low-level system then relates the concrete and the abstract machines. \nHowever, proofs in neither of the two systems are interpreted with respect to any semantics alone, as \nwould be the case in the usual semantic re.nement. Instead, our soundness state\u00adment (Section 6) interprets \na proof of the kernel in the high-level system and a proof of the scheduler in the low-level one together \nwith respect to the semantics of the concrete machine. Finally, while we would like to hide the scheduler \nstate com\u00adpletely when reasoning about the kernel, the converse is not true: the scheduler has to be \nable to access at least some of the local state of every process, such as its register values. For this \nreason, the low-level proof system (Section 4.4) includes special assertions to describe the state of \nthe OS processes the scheduler manages. These assertions are also interpreted as exclusive permissions \nto schedule the corresponding processes, which allows us to reason about scheduling on multiprocessors. \nA novel feature of the low\u00adlevel proof system that allows verifying schedulers separately from the rest \nof the kernel is its locality: proofs about the scheduler focus only on a small relevant part of the \nstate of processes. Even though all of the OS veri.cation projects carried out so far had to deal with \na scheduler (see Section 7 for a discussion), to our knowledge they have not produced methods for handling \npractical multiprocessor schedulers with a complicated scheduler/kernel in\u00adterface. We illustrate the \npower of our logic by verifying an exam\u00adple scheduler, modelled on the one from Linux 2.6.11 (Sections \n2.2 and 5), which exhibits the issues mentioned above. 2. Informal development We .rst explain our results \ninformally, sketching the machine we use for formalising them (Section 2.1), illustrating the challenges \nof reasoning about schedulers by an example (Section 2.2) and describing the approach we take in our \nprogram logic (Section 2.3). 2.1 Example machine To keep the presentation tractable, we formalise our \nresults for a simple machine, de.ned in Section 3. Here we present it informally to the extent needed \nfor understanding the rest of this section. We consider a machine with multiple CPUs, identi.ed by in\u00adtegers \nfrom 1 to NCPUS, communicating via the shared memory. We assume that the program the machine executes \nis stored sepa\u00adrately from the heap and may not be modi.ed; its commands are identi.ed by labels. For \nsimplicity we also assume that programs can synchronise using a set of built-in locks (in reality they \nwould be implemented as spin-locks). Every CPU has a single interrupt, with its handler located at a \ndistinguished label schedule, which a scheduler can use to trigger a context switch. There are four special\u00adpurpose \nregisters, ip, if, ss and sp, and m general-purpose ones, gr1,..., grm . The ip register is the instruction \npointer. The if register controls interrupts: they are disabled on the corresponding CPU when it is zero \nand enabled otherwise. As if affects only one CPU, we might have several instances of the scheduler code \nexecut\u00ading in parallel on different CPUs. Upon an interrupt, the CPU sets if to 0, which prevents nested \ninterrupts. The ss register keeps the starting address of the stack, and sp points to the top of the \nstack, i.e., its .rst free slot. The stack grows upwards, so we always have ss<sp. Since we are primarily \ninterested in interactions of components within an OS kernel, our machine does not make a distinction \nbetween the user mode and the kernel mode all processes can potentially access all available memory and \nexecute all commands. The machine executes programs in a minimalistic assembly-like programming language. \nIt is described in full in Section 3; for now it suf.ces to say that the language includes standard commands \nfor accessing registers and memory, and the following special ones: lock(e) and unlock(e) acquire and \nrelease the lock e.  savecpuid(e) stores the identi.er of the CPU executing it at the address e.  call(l) \nis a call to the function that starts at the label l. It pushes the label of the next instruction in \nthe program and the values of the general-purpose registers onto the stack, and jumps to the label l. \nicall(l) behaves the same as call(l), except that it also disables interrupts by modifying the if register. \n ret is the return command. It pops the return label and the saved general-purpose registers off the \nstack, updates the registers with the new values, and jumps to the return label. iret is a variant of \nret that additionally enables interrupts.   2.2 Motivating example Figure 1 presents an implementation \nof the scheduler we use as a running example. We would like to be able to verify safety proper\u00adties of \nOS processes managed by this scheduler using off-the-shelf concurrency logics, i.e., as though every \nprocess has its own vir\u00adtual CPU. The scheduler uses data structures and an interface with the rest of \nthe kernel similar to the ones in Linux 2.6.11 [2]1. To concentrate on key issues of scheduler veri.cation, \nwe make some simplifying assumptions: we do not consider virtual memory and assume that processes are \nnever removed and never go to sleep. We have also omitted the code for data structure initialisation. \nThe scheduler s interface consists of two functions: schedule and create. The former is called as the \ninterrupt handler or directly by a process and is responsible for switching the process running on the \nCPU and migrating processes between CPUs. The latter can be called by the kernel implementation of the \nfork system call and is responsible for inserting a newly created process into the scheduler s data structures, \nthereby making it runnable. Both functions are called by processes using the icall command that disables \ninterrupts, thus, the scheduler routines always execute with interrupts disabled. Programming language. \nEven though we formalise our results for a machine executing a minimalistic programming language, we \npresent the example in C. We now explain how a C program, such as the one in Figure 1, is mapped to our \nmachine. We assume that global variables are allocated at .xed addresses in memory. Local variable declarations \nallocate local variables on the stack in the activation records of the corresponding procedures; these \nvariables are then addressed via the sp register. When the variables go out of scope, they are removed \nfrom the stack by decrementing the sp register. The general-purpose registers are used to store intermediate \nvalues while computing complex ex\u00adpressions. We allow the ss and sp registers to be accessed di\u00adrectly \nas _ss and _sp. Function calls and returns are implemented using the call and ret commands of the machine. \nBy default, parameters and return values are passed via the stack; in partic\u00adular, a zero-.lled slot \nfor a return value is allocated on the stack before calling a function. Parameters of functions annotated \nwith _regparam (such as create) are passed via registers. We assume macros lock, unlock, savecpuid and \niret for the correspond\u00ading machine commands. We also use some library functions: e.g., remove node deletes \na node from the doubly-linked list it belongs to, and insert node after inserts the node given as its \nsecond argument after the list node given as its .rst argument. Data structures. Every process is associated \nwith a process de\u00adscriptor of type Process. Its prev and next .elds are used by the scheduler to connect \ndescriptors into doubly-linked lists of processes it manages (runqueues). The scheduler uses per-CPU \nrunqueues with dummy head nodes pointed to by the en\u00adtries in the runqueue array. These are protected \nby the locks in the runqueue_lock array, meaning that a runqueue can only be accessed with the corresponding \nlock held. The entries in the current array point to the descriptors of the processes running on the \ncorresponding CPUs; these descriptors are not members of any runqueue. Thus, every process descriptor \nis either in the current array or in some runqueue. Note that every CPU always has at least one process \nto run the one in the corresponding slot of the current array. Every process has its own kernel stack \nof a .xed size StackSize, represented by the kernel_stack .eld of its de\u00ad 1 We modelled our scheduler \non an older version of the Linux kernel (from 2005) because it uses simpler data structures. Newer versions \nuse more ef\u00ad.cient data structures [18] that would only complicate our running example without adding \nanything interesting. #define FORK_FRAME sizeof(Process*) #define SCHED_FRAME sizeof(Process*)+sizeof(int) \nstruct Process { Process *prev, *next; word kernel_stack[StackSize]; word *saved_sp; int timeslice; \n}; Lock *runqueue_lock[NCPUS]; Process *runqueue[NCPUS]; Process *current[NCPUS]; void schedule() { int \ncpu; Process *old_process; savecpuid(&#38;cpu); load_balance(cpu); old_process = current[cpu]; if (--old_process->timeslice) \niret(); old_process->timeslice = SCHED_QUANTUM; lock(runqueue_lock[cpu]); insert_node_after(runqueue[cpu]->prev, \nold_process); current[cpu] = runqueue[cpu]->next; remove_node(current[cpu]); old_process->saved_sp = \n_sp; _sp = current[cpu]->saved_sp; savecpuid(&#38;cpu); _ss = &#38;(current[cpu]->kernel_stack[0]); unlock(runqueue_lock[cpu]); \niret(); } void load_balance(int cpu) { int cpu2; Process *proc; if (random(0, 1)) return; do { cpu2 = \nrandom(0, NCPUS-1); } while (cpu == cpu2); if (cpu < cpu2) { lock(runqueue_lock[cpu]); lock(runqueue_lock[cpu2]); \n} else { lock(runqueue_lock[cpu2]); lock(runqueue_lock[cpu]); } if (runqueue[cpu2]->next != runqueue[cpu2]) \n{ proc = runqueue[cpu2]->next; remove_node(proc); insert_node_after(runqueue[cpu], proc); } unlock(runqueue_lock[cpu]); \nunlock(runqueue_lock[cpu2]); } _regparam void create(Process *new_process) { int cpu; savecpuid(&#38;cpu); \nnew_process->timeslice = SCHED_QUANTUM; lock(runqueue_lock[cpu]); insert_node_after(runqueue[cpu], new_process); \nunlock(runqueue_lock[cpu]); iret(); } int fork() { Process *new_process; new_process = malloc(sizeof(Process)); \nmemcpy(new_process->kernel_stack, _ss, StackSize); new_process->saved_sp = new_process->kernel_stack+ \n_sp-_ss-FORK_FRAME+SCHED_FRAME; _icall create(new_process); return 1; } Figure 1. The example scheduler \n  ... . saved sp Figure 2. The invariant of the stack of a preempted process scriptor. When a process \nis preempted, the saved_sp .eld is used to save the value of the stack pointer register sp. Finally, \nwhile a process is running, the timeslice .eld gives the remaining time from its scheduling time quantum \nand is periodically updated by the scheduler. Apart from the data structures described above, a realistic \nkernel would contain many others not related to scheduling, including additional .elds in process descriptors. \nThe kernel data structures reside in the same address space as the ones belonging to the scheduler, thus, \nwhile verifying the OS, we have to prove that the two components do not corrupt each other s data structures. \nThe schedule function. According to the semantics of our ma\u00adchine, when schedule starts executing, interrupts \nare disabled and the previous values of ip and the general-purpose registers are saved on the top of \nthe stack. The scheduler uses the empty slots on the stack of the process it has preempted to store activation \nrecords of its procedures and thus expects the kernel to leave enough of these. Intuitively, while a \nprocess is running, only this process has the right to access its stack, i.e., owns it. When the scheduler \npre\u00adempts the process, the right to access the empty slots on the stack (their ownership) is transferred \nto the scheduler. When the sched\u00aduler returns the control to this process, it transfers the ownership \nof the stack slots back. This is one example of ownership transfer we have to reason about. The schedule \nfunction .rst calls load_balance, which mi\u00adgrates processes between CPUs to balance the load; we describe \nit below. The function then decrements the timeslice of the cur\u00adrently running process, and if it becomes \nzero, schedules another one. The processes are scheduled in a round-robin fashion, thus, the function \ninserts the current process at the end of the local runqueue and dequeues the process at the front of \nthe runqueue, making it current. The function also re.lls the scheduling quantum of the process being \ndescheduled. The runqueue manipulations are done with the corresponding lock held. Note that in a realistic \nOS choos\u00ading a process to run would be more complicated, but still based on scheduler-private data structures \nprotected by runqueue locks. To save the state of the process being preempted, schedule copies sp into \nthe saved_sp .eld of the process descriptor. This .eld, together with the kernel stack of the process \nforms its saved state. The stack of a preempted process contains the activa\u00adtion records of functions \ncalled before the process was preempted, the label of the instruction to resume the process from, the \nvalues of general-purpose registers saved upon the interrupt, and the ac\u00adtivation record of schedule, \nas shown in Figure 2. This invariant holds for descriptors of all preempted processes. The actual context \nswitch is performed by the assignment to sp, which switches the current stack to another one satisfying \nthe invariant in Figure 2. Since this changes the activation record of schedule, the function has to \nupdate the cpu variable, which lets it then retrieve and load the new value of ss. The iret command at \nthe end of schedule loads the values of the registers stored on the stack and enables interrupts, thus \ncompleting the context switch. The load balance function checks if the CPU given as its pa\u00adrameter is \nunderloaded and, if it is the case, tries to migrate a pro\u00adcess from another CPU to this one. The particular \nway the function performs the check and chooses the process is irrelevant for our purposes, and is thus \nabstracted by a random choice. To migrate a process, the function chooses a runqueue to steal a process \nfrom and locks it together with the current runqueue in the order deter\u00admined by the corresponding CPU \nidenti.ers, to avoid deadlocks. The function then removes one process from the victim runqueue, if it \nis non-empty, and inserts it into the current one. Note that two concurrent scheduler invocations executing \nload balance on dif\u00adferent CPUs may access the same runqueue. While verifying the OS, we have to ensure \nthey synchronise their accesses correctly. The create function inserts the descriptor of a newly created \npro\u00adcess with the address given as its parameter into the runqueue of the current CPU. We pass the parameter \nvia a register, as this simpli.es the following treatment of the example. The descriptor must be ini\u00adtialised \nlike that of a preempted process, hence, its stack must sat\u00adisfy the invariant in Figure 2. To prevent \ndeadlocks, create must be called using icall, which disables interrupts. Upon a call to create, the ownership \nof the descriptor is transferred from the ker\u00adnel to the scheduler. The fork function is not part of \nthe scheduler. It illustrates how the rest of the kernel can use create to implement a common system \ncall that creates a clone of the current process. This function allocates a new descriptor, copies the \nstack of the current process to it and initialises the stack as expected by create (Figure 2). This amounts \nto discarding the topmost activation record of fork and pushing a fake activation record of schedule \n(note that the values of registers the new process should start from have been saved on the stack upon \nthe call to fork). Since stack slots for return values are initialised with zeros, this is what fork \nin the child process will return; we return 1 in the parent process. The need for modularity. We could \ntry to verify the scheduler and the rest of the kernel as a whole, modelling every CPU as a process in \none of the existing program logics for concurrency [3 5, 13, 20, 23]. However, in this case our proofs \nwould have to consider the possibility of the control-.ow going from any statement in a process to the \nschedule function, and from there to any other process. Thus, in reasoning about a system call implementation \nwe would end up having to reason explicitly about invariants and actions of both schedule and all other \nprocesses, making the reasoning unintuitive and, most likely, intractable. In the rest of the paper we \npropose a logic that avoids this pitfall.  2.3 Approach Before presenting our logic in detail, we give \nan informal overview of the reasoning principles behind it. Modular reasoning via memory partitioning. \nThe .rst issue we have to deal with while designing the logic is how to verify the scheduler and the \nkernel separately, despite the fact that they share the same address space. To this end, our logic partitions \nthe mem\u00adory into two disjoint parts. The memory cells in each of the parts are owned by the corresponding \ncomponent, meaning that only this component can access them. It is important to note that this parti\u00adtioning \ndoes not exist in the semantics, but is enforced by proofs in the logic to enable modular reasoning about \nthe system. Mod\u00adular reasoning becomes possible because, while reasoning about one component, one does \nnot have to consider the memory par\u00adtition owned by the other, since it cannot in.uence the behaviour \nof the component. An important feature of our logic, required for handling schedulers from mainstream \nkernels, is that the memory partitioning is not required to be static: the logic permits ownership transfer \nof memory cells between the areas owned by the scheduler and the kernel according to an axiomatically \nde.ned interface. For example, in reasoning about the scheduler of Section 2.2, the logic permits the \ntransfer of the descriptor for a new process from the kernel to the scheduler at a call to create. As \nwe have noted before, our logic consists of two proof sys\u00adtems: the high-level system (Section 4.3) for \nverifying the ker\u00adnel and the low-level one for the scheduler (Section 4.4). These proof systems implement \na form of assume-guarantee reasoning between the two components, where one component assumes that the \nother does not touch its memory partition and provides well\u00adformed pieces of memory at ownership transfer \npoints.  Concurrent separation logic. We use concurrent separation logic [20] as a basis for modular \nreasoning within a given com\u00adponent, i.e., either among concurrent OS processes or concurrent scheduler \ninvocations on different CPUs. This choice was guided by the convenience of presentation; see Section \n8 for a discussion of how more advanced logics can be integrated. However, the use of a version of separation \nlogic is crucial, because we inherently rely on the frame property validated by the logic: the memory \nthat is not mentioned in the assertions in a proof of a command is guar\u00adanteed not to be changed by it. \nWhile reasoning about a component, we consider only the memory partition belonging to it. Hence, we automatically \nknow that the component cannot modify the others. Concurrent separation logic achieves modular reasoning \nby fur\u00adther partitioning the memory owned by the component under con\u00adsideration into disjoint process-local \nparts (one for each process or scheduler invocation on a given CPU) and protected parts (one for each \nfree lock). A process-local part can only be accessed by the corresponding process or scheduler invocation, \nand a lock\u00adprotected part only when the process holds the lock. The resulting partitioning of the system \nstate is illustrated in Figure 3. The frame property guarantees that a process cannot access the partition \nof the heap belonging to another one. To reason modularly about parts of the state protected by locks, \nthe logic associates with every lock an assertion its lock invariant that describes the part of the state \nit protects. Resource invariants restrict how processes can change the protected state, and hence, allow \nreasoning about them in isolation. Scheduler-agnostic veri.cation of kernel code. The high-level proof \nsystem (Section 4.3) reasons about preemptable code assum\u00ading an abstract machine where every process \nhas its own virtual CPU. It relies on the partitioned view of memory described above to hide the state \nof the scheduler, with all the remaining state split among processes and locks accessible to them, as \nillustrated in Fig\u00adure 4. We have primed process identi.ers in the .gure to emphasise that the virtual \nstate of the process can be represented differently in the abstract and physical machines: for example, \nif a process is not running, the values of its local registers can be stored in scheduler\u00adprivate data \nstructures, rather than in CPU registers. Apart from hiding the state of the scheduler, the high-level \nsystem also hides the complex manipulation of the control-.ow performed by it: the proof system assumes \nthat the control moves from one point in the process code to the next without changing its state, ignoring \nthe possibility of the scheduler getting executed upon an interrupt. Explicit calls to the scheduler \nare treated as if they were executed atomically. Technically, the proof system is a straightforward adaptation \nof concurrent separation logic, which is augmented with proof rules axiomatising the effect of scheduler \nroutines explicitly called by processes. The novelty here is that we can use such a scheduler\u00adagnostic \nlogic in this context at all. Proving schedulers correct via logical re.nement. The use of the high-level \nproof system is justi.ed by verifying the scheduler implementation using a low-level proof system (Section \n4.4). What does it mean for a scheduler to be functionally correct? Intuitively, a scheduler must provide \nan illusion of a system where every process has its own virtual CPU with a dedicated set of registers. \nTo formalise this, we could de.ne a semantics of such an abstract system and prove that any behaviour \nof the concrete system is reproducible in the abstract one, thus establishing a re.nement between the \ntwo systems. The main technical challenge we have to Figure 3. The partitioning of the system state enforced \nby the logic. The memory is partitioned into two parts, owned by the scheduler and the kernel, respectively. \nThe memory of each compo\u00adnent is further partitioned into parts local to processes or scheduler invocations \non a given CPU, and parts protected by locks. Figure 4. The state of the abstract system with one virtual \nCPU per process. Process identi.ers are primed to emphasise that the virtual state of the process can \nbe represented differently in the abstract and physical machines (cf. Figure 3). Dark regions illustrate \nthe parts of process state that are tracked by a scheduler invocation running on a particular physical \nCPU. deal with in this paper is that for realistic OS schedulers, de.ning a semantics for the abstract \nsystem a scheduler implements is dif.cult. This is because, in reasoning about mainstream operating systems, \nthe ownership transfer between the scheduler and the kernel can involve not only .xed memory cells, but \narbitrary logical facts describing them, which is dif.cult to describe operationally (see the treatment \nof the desc predicate in Section 4.3). In this paper we resolve this problem in a novel way. Instead \nof de.ning the semantics of the abstract machine operationally, we de.ne it only axiomatically as the \nhigh-level proof system described above. As expected, the low-level proof system is used to reason about \nthe correspondence between the concrete and the abstract system, with its assertions relating their states. \nHowever, proofs in neither of the two systems are interpreted with respect to any semantics alone: our \nsoundness statement (Section 6) interprets a proof of the kernel in the high-level system and a proof \nof the scheduler in the low-level one together with respect to the semantics of the concrete machine. \nThus, instead of relating sets of executions of the two systems, the soundness statement relates logical \nstatements about the abstract system (given by high-level proofs) to logical statements about the concrete \none (given by a constraint on concrete states). We call this form of establishing a correspondence between \nthe two systems a logical re.nement. Note that in this case the soundness statement for the logic does \nnot yield a semantic statement of correctness for the scheduler being considered. Rather, its correctness \nis established indirectly by the fact that reasoning in the high-level proof system, which assumes  \nReg = {ip, if, ss, sp, gr1,..., gr} Loc . Val m Context = Reg .Val CPUid = {1,..., NCPUS} GContext = \nCPUid -Context Heap = Loc -Val Lock = {e1,e2,...,en} Lockset = P(Lock) Con.g = GContext \u00d7 Heap \u00d7 Lockset \nFigure 5. The set of machine con.gurations Con.g. We assume sets Loc of valid memory addresses and Val \nof values, respectively. the abstract one-CPU-per-process machine, is sound with respect to the concrete \nmachine. To verify the scheduler separately from the processes it man\u00adages, low-level assertions focus \nonly on a small relevant part of the state of the kernel, which we call scheduler-visible. Namely, the \nassertions relate the state local to a scheduler invocation on a par\u00adticular CPU in the concrete system \n(e.g., the region marked CPU1 in Figure 3) to parts of abstract states of some of the OS processes (e.g., \nthe dark regions in Figure 4). The latter parts can include, e.g., the values of registers of the virtual \nCPU of the process, but not the process-local memory. They are used in the low-level proof system to \nverify that the operations performed by the scheduler in the concrete machine correctly implement the \nrequired actions in the abstract machine. These parts also function as permissions to schedule the corresponding \nprocesses, i.e., a given part can be owned by at most one scheduler invocation at a time. For example, \na scheduler invocation owning the parts of process states marked in Figure 4 has a permission to schedule \nprocesses 1 and 2, but not 3. Such a permission reading is crucial for handling scheduling on multiprocessors, \nas it ensures that a process may not be scheduled at two CPUs at the same time. Summary. In the following \nwe formalise the above approach for a particular class of schedulers. Despite the formalisaton being \nperformed for this class, the technical methods we develop here can be reused in other settings (see \nSection 8 for a discussion). In particular, we propose the following novel ideas: exploiting a logic \nvalidating the frame property to hide the state of the scheduler while verifying the kernel and vice \nversa;  using a logical re.nement in a context where de.ning an abstract semantics re.ned by the concrete \none is dif.cult; and  focusing on relevant parts of the two systems related in the re.nement and giving \na permission interpretation to them.  3. Preliminaries In this section, we give a formal semantics to \nthe example machine informally presented in Section 2.1. 3.1 Storage model Figure 5 gives a model for \nthe set of con.gurations Con.g that can arise during an execution of the machine. A machine con.guration \nis a triple with the components describing the values of registers of the CPUs in the machine, the state \nof the heap and the set of locks taken by some CPU. The con.gurations in which the heap or the global \ncontext is a partial function are not encountered in the semantics we de.ne in this section. They come \nin handy in Sections 4 and 6 to give a semantics to the assertion language and express the soundness \nof our logic. In this paper, we use the following notation for partial functions: f[x : y] is the function \nthat has the same value as f everywhere, except for x, where it has the value y; [] is a nowhere-de.ned \nfunction; f lg is the union of the disjoint partial functions f and g. 3.2 Commands Programs for our \nmachine consist of primitive commands c: r . Reg -{ip} e . Lock l . Label = N e ::= r | 0 | 1 | 2 | ... \n| e + e | e - e b ::= e = e | e = e | b . b | b . b |\u00acb c ::= skip | r := e | r := [e] | [e] := e | assume(b) \n| lock(e) | unlock(e) | savecpuid(e) | call(l) | icall(l) | ret | iret In addition to the primitive commands \nlisted in Section 2, we have the following ones: skip and r := e have the standard meaning; r := [e] \nreads the contents of a heap cell e and assigns the value read to r; [e] := eq updates the contents of \ncell e by eq; assume(b) acts as a .lter on the state space of programs, choosing those satisfying b. \nWe write PComm for the set of primitive commands. Note that the commands cannot access the ip register \ndirectly. Commands C are partial maps from Label to PComm \u00d7 P(Label). Intuitively, if C(l)=(c, X), then \nc is labelled with l in C and is followed by commands with labels in X. In this case we let comm(C, l)= \nc and next(C, l)= X. We denote the domain of C with labels(C) and the set of all commands with Comm. \nThe language constructs used in the example scheduler of Sec\u00adtion 2, such as loops and conditionals, \ncan be expressed as com\u00admands in a standard way, with conditions translated using assume.  3.3 Semantics \nWe now give a standard operational semantics to our programming language. We interpret primitive commands \nc using a transition relation .c of the following type: State = Context \u00d7 Heap \u00d7 Lockset .c .CPUid \u00d7 \nState \u00d7 Label2\u00d7State \u00d7 Label . {T}) The input to .c consists of four components. The .rst is the identi\u00ad.er \nof the CPU executing the command, and the next the con.gura\u00adtion of the system projected to this CPU, \nwhich we call a state. The latter includes the context of the CPU and the information about the shared \nresources the heap and locks. The last two components of the input are the labels of the command c and \na primitive command following it in the program. Given this input, the transition relation .c for c nondeterministically \ncomputes the next state of the CPU after running c, together with the label of the primitive command \nto run next. The former may be a special T state signalling a machine crash. The latter may be different \nfrom the label given as the last component of the input, when c is a call or a return. The relation .c \nappears in Figure 6. In the .gure and in the rest of the paper, we write for an expression whose value \nis irrelevant and implicitly existentially quanti.ed. The relation follows the informal meaning of primitive \ncommands given in Sections 2.1 and 3.2. Note that .c may yield no post-state for a given pre-state. Unlike \na transition to the T state, this represents the divergence of the command. For example, according to \nFigure 6, acquiring the same lock twice leads to a deadlock, and releasing a lock that is not held crashes \nthe system. Note that we do not prevent a held lock from being released by a CPU that did not acquire \nit, so locks behave like binary semaphores. The program our machine executes is given by a command C \nthat includes a primitive command labelled schedule, serving as the entry point of the interrupt handler. \nFor such a command C, we give its meaning using a small-step operational semantics, for\u00admalised by the \ntransition relation .C . Con.g\u00d7(Con.g.{T}) in Figure 7. The .rst rule in the .gure describes a normal \nexecu\u00adtion, where the ip register of CPU k is used to choose the primitive command c to run. After choosing \nc, the machine picks the label lq of a following command, runs c according to the semantics .c,  (k, \n(r, h[[[e] r : u],L), l, lq) r:=[e] ((r[r : u],h[[[e] r : u],L),lq) (k, (r, h, L), l, lq) assume(b) ((r, \nh, L),lq), if [ b] r = true (k, (r, h, L), l, lq) Passume(b) if [ b] r = false (k, (r, h, L), l, lq) \nlock(\u00a3) ((r, h, L .{U}),lq), ifU P. L (k, (r, h, L), l, lq) PifU . L lock(\u00a3) (k, (r, h, L), l, lq) unlock(\u00a3) \n((r, h, L -{U}),lq), ifU . L (k, (r, h[[[e] r :],L), l, lq) savecpuid(e) ((r, h[[[e] r : k],L),lq) (k, \n(r, h[r(sp): ,...,r(sp)+m :],L), l, lq) call(lll) ((r[sp : r(sp)+m+1], h[r(sp): lq,r(sp)+1 : r(gr1),...,r(sp)+m \n: r(gr)],L),lqq) m (k, (r, h[r(sp)-m-1: lqq,r(sp)-m : g1,...,r(sp)-1: gm],L), l, lq) ret ((r[sp : r(sp)-m-1, \ngr1 : g1,..., gr: gm], m h[r(sp)-m-1: lqq,r(sp)-m : g1,...,r(sp)-1: gm],L),lqq) (k, (r, h, L), l, lq) \nc T, otherwise Figure 6. Semantics of primitive commands. We have omitted standard de.nitions for skip \nand most of assignments (see [21]). We have also omitted them for icall and iret: the de.nitions are \nthe same as for call and ret, but additionally modify if. In the .gure cT indicates that the command \nc crashes, and pc means that it does not crash, but diverges. The function [ \u00b7] r evaluates expressions \nwith respect to the context r. r(ip)= l . labels(C) lq . next(C, l) (k, (r, h, L), l, lq) comm(C,l) ((rq,hq,Lq),lqq) \n(R[k : r], h, L) .C (R[k : rq[ip : lqq]],hq,Lq) r(ip)= l . labels(C) r(if)=1 q (k, (r, h, L), l, l) icall(schedule) \n((r,hq,Lq),lqq) q[ip : lqq (R[k : r], h, L) .C (R[k : r]],hq,Lq) r(ip)= l . labels(C) lq . next(C, l)(k, \n(r, h, L), l, lq) comm(C,l) T (R[k : r], h, L) .C T r(ip) p. labels(C) (R[k : r], h, L) .C T r(if)=1 \n{r(sp),...,r(sp)+m} p. dom(h) (R[k : r], h, L) .C T Figure 7. Operational semantics of the machine and \nuses the result of this run to update the registers of CPU k and the heap and the lockset of the machine. \nThe next rule concerns interrupts. Upon an interrupt, the interrupt handler label schedule is loaded \ninto ip, and the label of the command to execute after the handler returns is pushed onto the stack together \nwith the val\u00adues of the general-purpose registers. The remaining rules deal with crashes arising from \nerroneous execution of primitive commands, unde.ned command labels and a stack over.ow upon an interrupt. \n4. The logic In this paper we consider schedulers whose interface consists of two routines: create and \nschedule. Like in our example sched\u00aduler (Section 2.2), create makes a new process runnable, and schedule \nperforms a context-switch. (Our results can be extended when new scheduler routines are introduced; see \nSection 8 for a discussion.) Our logic thus reasons about programs of the form: C l [lc :(iret, {lc+1})] \nl S l [ls :(iret, {ls+1})] l K (OS) where C and S are pieces of code implementing the create and schedule \nroutines of the scheduler and K is the rest of the kernel code. Our high-level proof system is designed \nfor proving K, and the low-level system for proving C and S. We place several restrictions on programs. \nFirst, we require that C and S de.ne primitive commands labelled create and schedule, which are meant \nto be the entry points for the corre\u00adsponding scheduler routines. The create routine expects the ad\u00address \nof the descriptor of the new process to be stored in the regis\u00adter gr1. By our convention schedule also \nmarks the entry point of the interrupt handler. Thus, schedule may be called both directly by a process \nor by an interrupt. For simplicity, we assume that the scheduler data structures are properly initialised \nwhen the program starts executing. To ensure that the scheduler routines execute with interrupts disabled, \nwe require that C and S may not contain icall, iret and assignments accessing the if register. We also \nneed to ensure that the kernel may not affect the status of interrupts, become aware of the particular \nCPU it is executing on, or change the stack address. Thus, K may not contain savecpuid, icall and iret \n(except calls to the scheduler routines schedule and create), assignments accessing if or writing to \nss. In reality, a kernel might need to disable interrupts. We discuss how our results can be extended \nto handle this in Section 8. Finally, we require that the kernel K and the scheduler C and S access disjoint \nsets of locks. This condition simpli.es the soundness statement in Section 6 and can be lifted. The core \npart of our logic is the low-level proof system for ver\u00adifying scheduler code, which we present in Section \n4.4. It extends the high-level proof system used for verifying kernel code, which, in turn, adapts concurrent \nseparation logic to our setting. For this reason, we present the high-level system .rst. 4.1 Assertion \nlanguage We now present the assertion language of the high-level proof system. Assertions describe properties \nof a single process, as if it were running on a separate virtual CPU. The state of the pro\u00adcess thus \nconsists of the values of the CPU registers (its context), the heap local to the process and the locks \nthe process has a per\u00admission to release (its lockset). Mathematically, states of a pro\u00adcess are just \nelements of State de.ned in Section 3.3: State = Context \u00d7 Heap \u00d7 Lockset. However, unlike in the semantics \nof Section 3.3, a heap here can be a partial function, with its domain de.ning the part of the heap owned \nby the process. A lockset is now meant to contain only the set of locks that the process has a permis\u00adsion \nto release (in our logic such permissions can be transferred between processes). To denote sets of process \nstates in our logic, we use a minor extension of the assertion language of separation logic [21]. Let \nNVar and CVar be disjoint sets containing logical variables for values and contexts, respectively. Assertions \nare de.ned as follows: x, y . NVar . . CVar r . Reg -{ip} r .{ip, if, ss, sp, gr1,..., gr} m E ::= x \n| r | 0 | 1 | ... | E+E | E-E | G(r) G ::= . | [ip : E, if : E, ss : E, sp : E, E gr : E ] S ::= e | \nE | SS B ::= E=E | S=S | G=G | E=E | B . B | B . B |\u00acB P ::= B | true | P . P |\u00acP |.x. P |... P | emp \n| E . E | E..E . S | P * P | dll.(E, E, E, E) | locked(e) Expressions E and Booleans B are similar to \nthose in programs, except that they allow logical variables to appear and include the lookup G(r) of \nthe value of the register r in the context G.A context G is either a logical variable or a .nite map \nfrom register  (r, h, L) |=. B iff [ B] .r = true (r, h, L) |=. P1 . P2 iff (r, h, L) |=. P1 and (r, \nh, L) |=. P2 (r, h, L) |= . emp iff h = [] and L = \u00d8 (r, h, L) |=. E0 . E1 iff h = [[[E0] .r :[ E1] .r] \nand L = \u00d8 (r, h, L) |=. E0..E1 . S iff .j = 0. .v1,...,vj . Val. L = \u00d8,j =[ E1] .r-[ E0] .r+1,v1v2 ...vj \n= [[S]].r and h = [[[E0] .r : v1,..., [ E1] .r : vj ] (r, h, L) |= . locked(e) iff h = [] and L = {e}(r, \nh, L) |=. P1 * P2 iff .h1,h2,L1,L2.h = h1 l h2, L = L1 l L2, (r, h1,L1) |=. P1 and (r, h2,L2) |=. P2 \nPredicate dll. is the least one satisfying the equivalence below: dll.(Eh,Ep,En,Et) ..x. (Eh = En . Ep \n= Et . emp) . Eh.prev.Ep * Eh.next.x * .(Eh) * dll.(x, Eh,En,Et) Figure 8. Semantics of high-level assertions. \nWe have omitted the standard clauses for most of the .rst-order connectives. The function [ \u00b7] .r evaluates \nexpressions with respect to the context r and the logical variable environment .. labels r to expressions. \nWe denote the set of assertions de.ned here with AssertK. Let a logical variable environment . be a mapping \nfrom NVar . CVar to Val . Context that respects the types of variables. Assertions denote sets of states \nfrom State as de.ned by the satisfaction relation |=. in Figure 8. For an environment . and an assertion \nP , we denote with [ P ] . the set of states satisfying P . The assertions in the .rst line of the de.nition \nof P except emp are connectives from the .rst-order logic with the standard semantics. We can de.ne the \nmissing connectives from the given ones. The following assertions from emp up to the dll. predicate are \nstandard assertions of separation logic [21]. Informally, emp describes the empty heap, and E . Eq the \nheap with only one cell at the address E containing Eq. The assertion E..Eq . S is the generalisation \nof the latter to several consecutive cells at the addresses from E to Eq inclusive containing the sequence \nof values S. For a value u of a C type t taking several cells, we shorten E..(E+sizeof(t)-1) . u to just \nE . u. For a .eld f of a C structure, we use E.f . Eq as a shortcut for E + off . Eq, where off is the \noffset of f in the structure. The separating conjunction P1 * P2 talks about the splitting of the local \nstate, which consists of the heap and the lockset of the process. It says that a pair (h, L) can be split \ninto two disjoint parts, such that one part (h1,L1) satis.es P1 and the other (h2,L2) satis.es P2. The \nassertion dll.(Eh,Ep,En,Et) is an inductive predicate describing a segment of a doubly-linked list. It \nassumes a C struc\u00adture de.nition with .elds prev and next. Here Eh is the address of the head of the \nlist, Et the address of its tail, Ep the pointer in the prev .eld of the head node, and En the pointer \nin the next .eld of the tail node. The . parameter is a formula with one free logi\u00adcal variable describing \nthe shape of each node in the list, excluding the prev and next .elds; the logical variable de.nes the \naddress of the node. For instance, a simple doubly-linked list can be expressed using .(x)= emp. We included \ndll. to describe the runqueues of the scheduler in our example. Predicates for other data structures \ncan be added straightforwardly [21]. Finally, the assertion locked(e) is speci.c to reasoning about concurrent \nprograms and denotes states with an empty local heap and the lockset consisting of e, i.e., it denotes \na permission to release the lock e. Note that locked(e) * locked(e) is inconsistent: acquiring the same \nlock twice leads to a deadlock. To summarise, our assertion language extends that of concurrent separation \nlogic with expressions to denote contexts and locked assertions to keep track of permissions to release \nlocks.  4.2 Interface parameters As we noted in Section 2.3, our logic can be viewed as imple\u00admenting \na form of assume-guarantee reasoning between the sched\u00aduler and the kernel. In particular, interactions \nbetween them in\u00advolve ownership transfer of memory cells at points where the con\u00adtrol crosses the boundary \nbetween the two components. Hence, the high-and low-level proof systems have to agree on the description \nof the memory areas being transferred and the properties they have to satisfy. These descriptions form \nthe speci.cation of the inter\u00adface between the scheduler and the kernel, and, correspondingly, between \nthe two proof systems. Here we describe parameters used to formulate it. We note that the interface parameters \nwe present here are tied to a particular class of schedulers for which we present our logic. As we argue \nin Section 8, our results can be carried over to schedulers with more elaborate interfaces. Ownership \ntransfer happens at calls to and returns from the scheduler routines create and schedule. When the kernel \ncalls the create routine of the scheduler, the latter should get the own\u00adership of the process descriptor \nsupplied as the parameter. In the two proof systems, we specify this descriptor using an assertion desc(d, \n.) . AssertK with two free logical variables and no regis\u00adter occurrences. Our intention is that it describes \nthe descriptor of a process with the context ., allocated at the address d. However, the user of our \nlogic is free to choose any assertion, depending on a particular scheduler implementation being veri.ed. \nAs the sched\u00aduler and the kernel access disjoint sets of locks, we require that all states in [ desc(d, \n.)]]. have an empty lockset. We .x the piece of state transferred from the kernel to the schedule routine \nupon an interrupt to be the free part of the stack of the process being preempted. The parameters determining \nits size are the size of the stack StackSize . N and the upper bound StackBound . N on the stack usage \nby the kernel (excluding the scheduler). To ensure that the stack does not over.ow while calling an interrupt \nhander, we require that StackSize-StackBound = m+1, where m is the number of general-purpose registers. \n 4.3 High-level proof system The high-level proof system reasons about the kernel code K. It is obtained \nby adapting concurrent separation logic to our setting and adding proof rules axiomatising the effect \nof scheduler routines. The judgements of the high-level proof system are of the form I, . f C, where \nI : Lock -AssertK is a partial mapping from locks accessible in the kernel code to their invariants (see \nSection 2.3) and .: Label . AssertK is a total mapping from code labels to preconditions. The parameter \n. in our judgement speci.es local states of the process at various program points, which induce pre-and \npost-conditions for all primitive commands in C. When considering a complete system in Section 4.5, we \nrestrict . so that it is false everywhere except at labels in the kernel code. An example of a lock invariant \nis .x, y. 10.prev . y * 10.next . x * dll.(x, 10, 10,y), where .(x)= emp. It states that the lock protects \na non-empty cyclic doubly-linked list with the head node at address 10. We forbid lock invariants to \ncontain registers or free occurrences of logical variables. We consider a version of concurrent separation \nlogic where resource invariants are allowed to be imprecise [20] at the expense of excluding the conjunction \nrule from the proof system [12]. The rule PROG-H for deriving the judgements is given in Fig\u00adure 9. The \n.rst premise of the rule says that all assertions in . have to satisfy some restrictions regarding stack \nusage, formulated using parameters StackSize and StackBound introduced in Sec\u00adtion 4.2. These ensure \nthat the interrupt handler can safely execute on the stack of the process it preempts:  .l . Label(C). \n.P . AssertK. .(l) . (0 = sp-ss = StackBound . P * sp..(ss+StackSize-1) . ) .l . labels(C). .lq . next(C, \nl). (I, . 1ll {.(l)} comm(C, l) {.(lq)}) PROG-H I, . f C P . P q I, . 1l {P q} c {Qq} Qq . Q I, . 1l \n{P } c {Q} notCallRet(c) CONSEQ EXISTS I, . 1l {P } c {Q} I, . 1l {.x. P } c {.x. Q} I, . 1l {P1} c {Q1} \nI, . 1l {P2} c {Q2} I, . 1l {P } c {Q} mod(c) n free(F )= \u00d8 notCallRet(c) DISJ FRAME I, . 1l {P1 . P2} \nc {Q1 . Q2} I, . 1l {P * F } c {Q * F } ASSUME STORE I, . 1l {P } assume(b) {P . b} I, . 1l {e .} [e]:=eq \n{e . eq} LOCK UNLOCK I, . 1l {emp} lock(e) {I(e) * locked(e)} I, . 1l {I(e) * locked(e)} unlock(e) {emp} \n(P * (sp..(sp+m) . l gr1 ... grm)) . (.(lq)[sp+m+1/sp]) CALL SCHED I, . 1l {P * (sp..(sp+m) . )} call(lq) \n{Q} I, . 1l {P } icall (schedule) {P } .lq . Label. (P * ((sp-m-1)..(sp-1) . EqEE) . Eq = lq) . (.(lq)[sp-m-1/sp][ \nEgr]) E/ E RET I, . 1l {P * ((sp-m-1)..(sp-1) . EqEE)} ret {Q} free(P ) n Reg = \u00d8.lq . Label. (... id \n= . . .(ip)= lq . sp..(ss+StackSize-1) .* P ) . .(lq) CREATE I, . 1l {....(if)=1 . desc(gr1,.) * P \n* Q} icall(create) {... Q} Figure 9. High-level proof system. Here mod(c) is the set of registers modi.ed \nby c, free(F ) is the set of registers appearing in F , and notCallRet(c) means that c is not one of \ncall, icall, ret and iret. Finally, id =[ip : , if : if, ss : ss, sp : sp,Egr]. gr : E the free part \nof the stack of the process must always be in its local state so that it can be transferred to the handler \nat any time;  this part must always be large enough for the handler to run without a stack over.ow; \nand  the assertions should be independent of any changes to the empty slots of the stack, which may \nbe modi.ed by the handler.  The other condition in the PROG-H rule is that for every primitive command \nc in C and the label lq of a command following c, we have to prove I, . 1ll {.(l)} c {.(lq)}. This informally \nmeans that, if c is run from an initial state satisfying .(l), then it accesses only the memory speci.ed \nby .(l) and either terminates normally and ends up in a state satisfying .(lq), or jumps to a label lqq \nwhose assertion .(lqq) holds in the current state. Note that the italicised clause enforces the frame \nproperty (Section 2.3). The proof rules for such judgements are also given in Figure 9. The rules CONSEQ, \nDISJ and EXISTS are standard rules of Hoare logic. The FRAME rule is inherited from separation logic; \nit states that executing a command in a bigger local state does not change its behaviour. The rule is \nuseful to restrict the reasoning about primitive commands to the memory they actually access. To keep \nthe logic sound we have to forbid EXISTS and FRAME to be applied to calls or returns. The logic also \nprovides standard separation logic axioms for primitive commands. In Figure 9 we show two of them, ASSUME \nand STORE, and omit the others to save space; see [21]. The LOCK and UNLOCK axioms are inherited from \nconcurrent separation logic and provide tools for modular reasoning about con\u00adcurrent processes. The \nLOCK axiom says that, upon acquiring a lock, the process gets the ownership of its invariant and a permis\u00adsion \nto release it. According to UNLOCK, before releasing the lock, the process must have the corresponding \npermission and must re\u00adestablish the lock invariant. When the lock is released, the process gives up \nthe ownership of the permission and the invariant. The CALL and RET axioms mirror the operational semantics \nof call and ret (see Section 2.1 and Figure 6). CALL requires us to provide enough space on the stack \nto store the values of registers before a call. The precondition together with the modi.ed stack then \nhas to establish the assertion given by . at the target label. RET similarly requires the precondition \nto establish the assertion at the target label after the values of general-purpose registers and ip (denoted \nwith EEand Eq) have been loaded from the stack. The axioms CALL and RET provide only a very rudimentary \ntreatment of procedures. In particular, our logic does not have analogues of the usual modular Hoare \nproof rules for procedures and does not allow applying the FRAME rule over a procedure call. This is \nbecause soundly formulating such proof rules in the setting where the stack is visible to procedure code \nand can potentially be modi.ed by it is non-trivial. This issue is orthogonal to the problem of scheduler \nveri.cation we are concerned with, thus, in this paper we chose the simplest high-level logic possible. \nSee Section 8 for pointers to more expressive logics for procedures. What we have presented so far is \njust an adaptation of concur\u00adrent separation logic to our setting. We now provide axioms for calling \nthe scheduler routines schedule and create, which are speci.c to our logic. As the high-level proof system \nhides the im\u00adplementation of scheduler routines, the corresponding axioms are signi.cantly different \nfrom CALL. In particular, the axioms are for\u00admulated as if after these icall commands the control just \npro\u00adceeded to the next statement in the program instead of jumping to the implementation of the routines. \nThis is despite the fact that after a call to schedule, the process may be preempted and the control-.ow \ngiven to any other process in the system. In this way, the axioms abstract from the scheduler implementation. \nThe SCHED axiom states that invoking schedule has no effect from the point of view of the process if \nit is preempted, the scheduler resumes it in the same context, and no other process can touch its local \nheap. The axiom does not place any requirements on the process, as the preconditions necessary for the \nexecution of schedule, which anyway can be invoked at any time as the interrupt handler, are established \nby the .rst condition in PROG-H. The CREATE axiom is more complicated. First, it requires the caller \nof create to provide a new descriptor desc(gr1,.) for the process being created with the context .. We \npass the parameter via the register gr1 and not via the stack, as this simpli.es the following technical \npresentation. The context is required to have if set, since after the context switch is .nished, the \nprocess starts executing with interrupts enabled. Note that the descriptor is not present in the postcondition: \nit gets transferred to the scheduler and reappears in the precondition of the implementation of create \n(Section 4.5). The axiom also allows us to transfer the ownership of the part of the heap given by P \nto the newly created process, thus providing it with an initial local state. This is a typical idiom \nfor high-level reasoning about processes in separation logics [13]. The premise of the rule correspondingly \nrequires that, after the registers and the stack are properly initialised, the state P we are transferring \nshould establish the assertion at the label the process starts executing from. The effect of loading \nregisters from . is formulated using the context id.  For the example scheduler in Section 2.2, desc(d, \n.) should describe a process descriptor with the stack initialised accord\u00ading to the invariant of a preempted \nprocess pictured in Figure 2: desc(d, .)= d.prev .* d.next .* desc0(d, .), where desc0(d, .) . .(if)=1 \n. .(ss)=d.kernel stack . 0 = .(sp)-.(ss) = StackBound . d.timeslice .* d.saved sp . (.(sp)+m+1+SCHED \nFRAME) * .(sp)..(.(sp)+m) . .(ip).( E gr) * (.(sp)+m+1)..(.(ss)+StackSize-1) . and SCHED FRAME is the \nsize of the activation record of schedule (Figure 1). The descriptor does not include .lled stack slots; \nthey can be passed to the process directly in the precondition P . As we have noted before, desc(d, .) \ncan be an arbitrary log\u00adical predicate. In some cases, e.g., when it is imprecise [20], its transfer \nfrom the kernel to the scheduler is hard to express oper\u00adationally when de.ning a semantics of the kernel \nseparately from the implementation of the scheduler; see [12] for a discussion. The situation would be \nworse had we based our logic on one of ad\u00advanced modular concurrency logics, such as deny-guarantee [4], \nwhich are needed to handle real OS code. This is because proofs of soudness for such logics do not give \nan operational semantics to separate components of a program. The above dif.culties with an operational \nde.nition of ownership transfer are a prime reason for using logical re.nement in this paper. The high-level \nproof system provides modern tools for modular reasoning about concurrent processes using proof rules \nof concur\u00adrent separation logic. The PROG-H rule of the system subsumes the usual sequential composition \nrule of Hoare logic, which assumes that the control-.ow follows the structure of the process code and \nignores the possibility of scheduler code getting executed at an in\u00adterrupt. The axioms SCHED and CREATE \nabstract the implementa\u00adtion of scheduler routines by treating them like atomic commands. Thus, the state \nand the control-.ow of the scheduler is completely hidden by the proof system. The soundness of such \nan illusion is established by verifying the scheduler code using a low-level proof system, which we describe \nnext.  4.4 Low-level proof system We now present the core of our logic the low-level proof sys\u00adtem, \nwhich is used to prove that the commands C and S of the OS program implement scheduling correctly. As \nwe explained in Section 2.3, assertions of the proof system relate the states of the concrete machine \nand an abstract one, where every process has its own virtual CPU. The state of the concrete machine can \nbe de\u00adscribed using separation logic assertions introduced in Section 4.1. To describe states of the \nabstract machine, we extend the assertion language of Section 4.3 with an additional predicate: P ::= \n... |Process(G), where G ranges over context expressions. We denote the set of such assertions with AssertS. \nThe Process(G) predicate (r, h, L),M |=. Process(G) iff h = [],L = \u00d8,M = {[ G] .r} (r, h, L),M |=. P \n* Q iff .h1,h2,L1,L2,M1,M2. h = h1 l h2,L = L1 l L2,M = M1 l M2, (r, h1,L1),M1 |=. P and (r, h2,L2),M2 \n|=. Q (r, h, L),M |=. emp iff h = [],L = \u00d8 and M = \u00d8 (r, h, L),M |=. P . Q iff (r, h, L),M |= . P and \n(r, h, L),M |= . Q Figure 10. Semantics of low-level assertions. The l operation on multisets adds up \nthe number of occurrences of each element in its operands. describes a process with the values of registers \nof its virtual CPU given by the context G. The addition of the Process predicate changes objects described \nby assertions: they now denote relations de.ned by subsets of RelState = State \u00d7M(Context), where M(A) \nis the set of all .nite multisets with elements from A. Relations in RelState connect the states of the \nconcrete machine and the abstract machine with one CPU per process. As we have noted before, these relations \ndo not describe the full state of the machines. The .rst component in a relation describes the local \nstate of a scheduler invocation running on a CPU, including its context and the heap and the lockset \nlocal to it (e.g., the region marked CPU1 in Figure 3). The multiset in the second part records the scheduler-visible \nstates of processes described by Process predicates in the assertion, i.e., parts of their local states \nthat may be referred to by proofs about the scheduler (cf. the dark regions in Figure 4). These include \nthe context of a process, but exclude its local heap and lockset: the latter are irrelevant for the schedulers \nwe consider here and are therefore invisible to them. The low-level logic we present in this section \nis based on separation logic, hence, the invisibility of parts of process state to the scheduler automatically \nguarantees that it cannot access them. Apart from keeping track of the state of a process, a Process \npredicate serves in the logic as an exclusive permission for the scheduler invocation owning it to schedule \nthe corresponding pro\u00adcess. To enforce this, the semantics of assertions de.ned below forbids the duplication \nof Process predicates: Process(G) p.Process(G) * Process(G). Furthermore, the proof obligations for the \nscheduler we de.ne in Section 4.5 state that it needs a Process predicate to schedule a process. Such \na permission interpretation of Process is a key feature of our logic that allows us to reason about schedulers \nfor multiprocessors: it ensures that, at a given time, only one scheduler invocation can own a Process \npredicate for a pro\u00adcess, and hence, it can be scheduled only on one CPU at a time. We give the formal \nsemantics of assertions using the satisfac\u00adtion relation |= . in Figure 10, parameterised by environments \n.. The .rst two cases in the .gure are the most interesting ones. Process(G) relates a scheduler invocation \nhaving the empty heap and the empty lockset to a single process with the register values G. To be related \nby the separating conjunction P * Q, all parts of the state-multiset pair except the context should be \nsplit such that the .rst part is related by P and the second by Q. The semantic de.nitions of the remaining \nassertions are obtained from the corre\u00adsponding cases in our high-level proof system (Figure 8) either \nby requiring the multiset component M to be empty, like in the case of emp, or by propagating M to their \nsub-assertions, like in the case of P . Q. We denote with [ P ] . the set of states satisfying P . The \njudgements of the low-level proof system have the form I, . fk C, where k . CPUid, I : Lock -AssertS \nis a vector of resource invariants for locks accessible to the scheduler, and .: Label . AssertS is a \nmapping from program positions to low-level assertions. When considering a complete system in Section \n4.5,  we restrict . so that it is false everywhere except at labels in the scheduler code. The intuitive \nmeaning of the judgements is the same as in the high-level system (Section 4.3), with the component describing \nscheduler-visible process states unchanged during the execution of scheduler commands. The judgements \nthus express how the scheduler code changes the relationship between the state of the scheduler on the \nCPU k and those of processes running on the machine. The proof rule for deriving our judgements is: .l \n. labels(C). .lq . next(C, l). I, . 1kll {.(l)} comm(C, l) {.(lq)} PROG-L I, . fk C Note that the syntactic \nstructure of the OS program (see the be\u00adginning of Section 4) ensures that the scheduler always executes \nwith interrupts disabled. Thus, in the rule we are able to follow the control .ow of C. The low-level \nsystem inherits the proof rules for deriving judgements for primitive commands I, . 1l {P } c {Q}in Figure \n9, adding the superscript k to 1l and ignoring the rules for icall(schedule) and icall(create). It also \nhas a rule for savecpuid, which makes use of the index k: CPUID I, . 1k {e .} savecpuid(e) {e . k} l \n 4.5 Putting the two proof systems together The proof systems presented in Sections 4.3 and 4.4 allow \nus to reason about the kernel and the scheduler code. We now describe a rule for combining judgements \nfrom the two systems, which de.nes proof obligations for the OS components. This allows us to prove the \nOS program de.ned at the beginning of Section 4. As can be seen from the example of Section 2.2, a scheduler \nmight need to maintain some data structures related to every CPU, which can be accessed by a scheduler \ninvocation on it. A data structure of this kind in our example scheduler is the element of the current \narray corresponding to the current CPU. Let Jk be an invariant of such data structures for CPU k, which \nis meant to be maintained when the scheduler is not running on it. Similarly to lock invariants, we forbid \nJk to contain free logical variables or registers, except ss. In this case we can allow ss because we \nhave previously required that the kernel cannot modify it. We denote with J the vector of invariants \nJk. Consider assertions IK, .K and IS, .k S for all k . CPUid, such that: dom(IK) n dom(IS)= \u00d8;  .l. \nl p. dom(K) . .K(l)= false;  .l. l p. dom(S) l dom(C) l{ls,lc}. .k S (l)= false.  The proof rule for \nthe program OS is as follows: IK, .K f K .k . CPUid.IS, .k S fk S,IS, .k S fk C .k . CPUid. .k S (schedule)=.S \nk(ls)=.S k(lc)= SchedStatek .k . CPUid. .k S (create)=(....(if)=1 . SchedStatek * desc(gr1,.) * Process(.)) \nIK, .K | IS, {.k S }k.CPUid | J f (S, C, K) where SchedStatek = .l, Eg. if=0 . 0 = sp-ss-m-1 = StackBound \n. (sp-m-1)..(sp-1) . lEg * sp..(ss+StackSize-1) .* Jk * Process([ip : l, if :1, ss : ss, sp : sp-m-1,Eg]) \ngr : E The .rst three premises require us to prove the kernel and the scheduler code in their respective \nproof systems. The rest de.ne pre-and postconditions for schedule and create by .xing the assertions \nat the corresponding labels. This is done using the predi\u00adcate SchedStatek, which describes the state \nof a scheduler invoca\u00adtion at CPU k right after it is called using icall or before it returns by executing \niret. When schedule is called, the stack satis.es the bound on stack usage and interrupts are disabled. \nThe scheduler gets the ownership of the per-CPU data structure Jk, a part of the stack of the process \nbeing preempted (which contains the values of registers saved upon the call together with the empty slots), \nand a Process predicate consistent with the registers saved on the stack. The predicate certi.es that, \nwhen the scheduler starts executing, the state of the preempted process in the machine corresponds to \nits state in the abstract machine. The schedule routine has to re\u00adestablish the same assertion before \nreturning. In the case when it schedules a different process, this will be done using a different Process \npredicate. However, since the scheduler can only get a Process predicate in the precondition of schedule \n(and when a new process is created; see below), its postcondition guarantees that the process being scheduled \nhas the same register values it had last time it was preempted. Note that the precondition of schedule \nmirrors the .rst premise of the PROG-H rule. Thus, the assumptions it makes about the kernel are justi.ed \nby the proof of the latter in the high-level system. The precondition of create is similar to that of \nschedule, but additionally assumes a process descriptor for a new process with the address in gr1, and \na corresponding Process assertion ini\u00adtialised according to the information in the descriptor. This descrip\u00adtor \nis guaranteed to be provided by the kernel by the precondition of the CREATE rule. Adding the new Process \nassertion can be under\u00adstood intuitively as creating a fresh virtual CPU for the new process in the abstract \nmachine. 5. Verifying the example scheduler We have used the logic to manually construct a proof of the \nex\u00adample scheduler of Section 2.2, establishing the judgements about schedule and create required by \nthe proof rule in Section 4.5. By the soundness theorem for our logic (presented in Section 6), this \nimplies that any property of a piece of high-level code proved in concurrent separation logic, including \nmemory safety and func\u00adtional correctness, holds of the code when it is managed by the example scheduler. \nThe detailed proof is given in [14, Appendix A]. Here we present only lock and per-CPU scheduler invariants \ntogether with some informal explanations. The invariants of runqueue locks are as follows: I(runqueue \nlock[k]) = .x, y, z. runqueue[k] . z * desc0(z, ) * z.prev . y * z.next . x * dll.(x, z, z, y) where \n.(d)= ... desc0(d, .) * Process(.) and desc0 is de.ned in Section 4.3. The per-CPU scheduler invariants \nare: Jk = .d. (d.kernel stack=ss) . current[k] . d * d.prev .* d.next .* d.timeslice .* d.saved sp . \nAccording to these de.nitions, a runqueue for a CPU k contains a list of descriptors of preempted processes \ntogether with Process predicates matching the state stored in them. When an invocation of schedule acquires \nthe runqueue lock and removes a node from the list, it gets the ownership of the corresponding Process \npredicate, which lets it schedule the process by establishing the postcondition SchedStatek of schedule \n(see Section 4.5). The descriptor of the process just scheduled, pointed to by an entry in the current \narray, forms the scheduler s per-CPU state and is described by Jk. When the process is preempted again, \nschedule receives the Process predicate in its precondition SchedStatek. This predicate and the state \nin Jk let the scheduler insert the descriptor back into the runqueue while maintaining its invariant. \n 6. Soundness In this section, we explain the guarantees about the entire kernel that follow from proofs \nin our logic. Consider a program OS of the form introduced in Section 4. We formulate a theorem, proved \nin [14, Appendix B], which describes how proofs of a scheduler and the kernel in our logic can be combined \nto construct an induc\u00adtive invariant of the entire system. To aid understanding, we .rst state the theorem \nand explain the components used to formulate it informally. Only after this do we provide formal de.nitions. \nTHEOREM 1. If IK, .K | IS, {.k S }k.CPUid | J f (S, C, K), then for all environments ., the following \nset of con.gurations Rk is preserved by .OS: compose( heldS(L) n (lowinv. *S lowlockLl ), LlLl=dom(IS) \n heldK(L) n (highinv. *K highlockLl )) LlLl=dom(IK) Informal explanation. The invariant R is constructed \nin several steps by conjoining the descriptions of pieces of program state owned by different OS components. \nFirst, from assertions .k S and J in the proof of the scheduler, we construct a predicate def lowinv. \n. RelCon.g = Con.g \u00d7M(Context) Consider ((R, h, L),M) . lowinv.. For register values of the CPUs in the \nmachine given by R, the components h and L describe the part of the machine state belonging to the scheduler, \nand M the contexts of the processes it has a permission to schedule. Similarly, from assertions .K in \nthe proof of the kernel, we construct a predicate def highinv. . HighCon.g = M(Context) \u00d7 Heap \u00d7 Lockset \nConsider (M, h, L) . highinv.. For any set of processes with the contexts given by M , the components \nh and L describe the part of the machine state belonging to these processes. To construct the complete \nmachine state, we also have to take into account the parts of the heap protected by free locks. Thus, \nfor any set of free locks Lq accessible to the scheduler, from resource invariants IS we construct a \npredicate lowlockLl . RelCon.g describing the state protected by the locks. A similar predicate highlockLl \n. HighCon.g, constructed from IK, describes the state protected by a set of free locks Lq accessible \nto the kernel. The predicates lowlockLl and highlockLl are then combined with lowinv. and highinv. using \noperations *S : P(RelCon.g) \u00d7P(RelCon.g) .P(RelCon.g) *K : P(HighCon.g) \u00d7P(HighCon.g) .P(HighCon.g) To \nensure that Lq is indeed the set of all free locks, we require that the rest of the locks L are held \nby intersecting the result with heldS(L) .P(RelCon.g) or heldK(L) .P(HighCon.g). Finally, we connect \nthe resulting predicates describing the states of the scheduler and the kernel using a form of relational \ncomposi\u00adtion, implemented by compose : P(RelCon.g) \u00d7P(HighCon.g) .P(Con.g) The operation conjoins the \nheaps and locksets described by the predicates and makes sure that the scheduler-visible states of pro\u00adcesses \nthey describe match. The result is an invariant of the entire machine maintained by each step of the \nkernel or the scheduler. We now formally de.ne the above operations and predicates. Composition operations. \nEach of the operations *S, *K and compose is obtained by lifting a partial function in A \u00d7 B-C to a function \nin P(A) \u00d7P(B) .P(C) pointwise. To de.ne *K we lift the operation K on HighCon.g that combines the information \nabout processes, heaps and locksets: (M1,h1,L1) K (M2,h2,L2)=(M1 l M2,h1 l h2,L1 l L2) (Recall that the \nl operation on multisets adds up the number of occurrences of each element in its operands.) To de.ne \n*S we similarly lift S on RelCon.g that combines the information about contexts, heaps, locksets and \nprocesses: ((R1,h1,L1),M1) S ((R2,h2,L2),M2) = ((R1 l R2,h1 l h2,L1 l L2),M1 l M2) Finally, we lift compose \n: RelCon.g \u00d7 HighCon.g -Con.g that combines heaps and locksets provided the scheduler-visible states \nof processes in both arguments match: ((R, h1,L1),M1) compose (M2,h2,L2)=(R, h1 l h2,L1 l L2) if both \nunions are de.ned and M1 = M2; unde.ned otherwise. It is this operation that carries over statements \nproved in the high-level proof system about the abstract machine with one virtual CPU per process to \nthe concrete machine: the second operand (M2,h2,L2) represents the state owned by the processes running \non the abstract machine, and the .rst ((R, h1,L1),M1) relates the scheduler state in the concrete machine \nto the processes it has permissions to schedule. The components M1 and M2 are used to ensure that the \ntwo operands describe the same set of processes. Predicate de.nitions. Consider p . RelState and q . \nState. Given k . CPUid and r . Context, we de.ne the following embedding operations converting states \nto con.gurations: LpJk = {(([k : r], h, L),M) . RelCon.g | ((r, h, L),M) . p}LqJr = {({r}, h, L) . HighCon.g \n| (r, h l [r(sp)..(r(ss)+StackSize-1): ],L) . q}LpJ = {(([ ], h, L),M) . RelCon.g | ((r, h, L),M) . p}LqJ \n= {(\u00d8, h, L) . HighCon.g | (r, h, L) . q} The .rst one tags states with CPU identi.ers and is used to \ncon\u00adstruct lowinv.. The second selects the states with a given context r and is used for highinv.. For \ntechnical reasons it removes the empty slots of the process stack, which are accounted for in the scheduler \nstate (see the de.nition of SchedSleepk below). The remaining two operations are used for lowlockLl and \nhighlockLl . As resource in\u00advariants do not restrict registers, they ignore contexts. We also need predicates \nde.ning states where the CPU is at a particular label l, or con.gurations with a particular lockset L: \natS(l)= {((r, h, L),M) . RelState | r(ip)= l}heldS(L)= {((R, h, L),M) . RelCon.g}heldK(L)= {(M, h, L) \n. HighCon.g} The following predicate describes the state of the scheduler on CPU k, when a process is \nrunning on this CPU and is at label l: SchedSleepk(l)= Jk * sp..(ss+StackSize-1) .* Process([ip : l, \nif :1, ss : ss, sp : sp,EE gr : gr]) Finally, let *S Kbe the iterated versions of *S and *K. and *Using \nthe above notation, we can de.ne the predicates from the theorem. For LS . dom(IS) and LK . dom(IK), \nwe have: lowinv. = *( L[ SchedSleepk(l)]]. n atS(l)Jk. S l.labels(K) k.CPUid l.(labels(SlC)l{ls,lc})L[[.k \nS (l)]]. n atS(l)Jk) highinv. = K *L[[.K(r(ip))]].Jr M.M(Context) r.M lowlockLS = S *L[ IS(e)]]J \u00a3.LS \nhighlockLK = *L[ IK(e)]]J K \u00a3.LK  The de.nitions follow the informal explanation given at the be\u00adginning \nof this section. To determine the state of the scheduler on a given CPU when de.ning lowinv., we branch \nover all possible program positions l of that CPU. Depending on whether l is in the scheduler or the \nkernel code, we use either the assertion in the scheduler proof or the invariant SchedSleepk, describing \nthe state of the scheduler when it is not running. Since assertions do not re\u00adstrict the value of the \nip register, we have to do this explicitly using atS. Note that, although assertions in the high-level \nproof system mention the empty slots of the process stack, the slots in fact be\u00adlong to the scheduler \nwhen the process is preempted. For simplicity we choose always to count them in the scheduler state (the \nassertion in .k S or the scheduler invariant SchedSleepk). To de.ne highinv. we branch over all possible \n.nite multisets of contexts M, representing processes that may run on the machine. For every context \nr in M, the local state of the corresponding process is then determined by the assertion in the proof \nof the kernel at the program point r(ip), restricted to the states with the context r. Note that the \ncomprehension r . M over a multiset M considers every duplicate of an element in the multiset separately. \nFinally, lowlockLS and highlockLK are straightforward combi\u00adnations of resource invariants for the given \nsets of locks. Ownership transfer. It is instructive to analyse how ownership transfer between the scheduler \nand the kernel is handled by our soundness statement. For example, consider a transfer of a new pro\u00adcess \ndescriptor desc(d, .) from the kernel to the scheduler at a call to create. Since the CREATE axiom requires \nthe descriptor in its precondition, before the kernel calls create, the state partitioning de.ned by \nR counts the descriptor as part of highinv.. Since the implementation of create receives the descriptor \nin its precondi\u00adtion, in the con.guration immediately after the call to create, R de.nes it to be part \nof lowinv.. Thus, ownership transfer reparti\u00adtions program state among the parts de.ned in Theorem 1. \nConsequences. Theorem 1 allows us to check invariance properties of preemptable code. For example, assume \nthat the initial con.g\u00aduration satis.es R. Then the soundness statement ensures that the machine cannot \nreach an error label le on any CPU, provided the as\u00adsertion at this program point in all high-level proofs \nis false. Indeed, in this case the invariant R does not contain any states where one of the CPUs is at \nle. Note that the functional correctness of an OS ker\u00adnel is usually formulated as a simulation between \nthe kernel and its speci.cation. As an OS kernel does not usually make any assump\u00adtions about user processes, \nproving the simulation can be reduced to proving an invariance property relating the two (e.g., [10, \n17]). Thus, Theorem 1 can be also used to justify such proofs. 7. Related work There have been a number \nof OS veri.cation projects; see [16] for a survey. To our knowledge, none of these has included the veri.cation \nof a scheduler in a preemptive kernel with the realistic features we consider. A representative example \nis the L4.veri.ed project [17], which veri.ed the L4 microkernel as a whole, together with the scheduler. \nThere, proofs about kernel components other than the scheduler had to ensure the preservation of its \ninvariants, e.g., the preservation of its runqueue. The proof was still tractable because the kernel \nwas running on a uniprocessor and preemption was disabled most of the time. However, such architecture \nis not used by mainstream operating systems. The closest work to ours is the one by Feng et al. [6 8], \nwho veri.ed an idealised scheduler without dynamic process creation. Their logic considers a uniprocessor \nand does not handle ownership transfer between the scheduler and processes. Like us, they have separate \nproof systems for the scheduler and preemptable code. However, their high-level system is non-modular \nin that it does not have a notion of a process-local state. Their approach to low-level reasoning and \nproving the soundness of the logic is also different from ours. Because Feng et al. consider a restricted \nscheduler and high-level proof system, they are able to avoid designing a special relational low-level \nlogic. Instead, they view calls to and returns from the scheduler as jumps and compile proofs of the \nscheduler and the rest of the system into OCAP [6], a logic supporting .rst\u00adclass code pointers. According \nto our understanding, extending this approach to handle multiprocessing, ownership transfer and a modular \nhigh-level proof system would be non-trivial. Maeda and Yonezawa have proved a simple context-switch \nrou\u00adtine using an extension of alias types [19]. Their proof expresses the disjointness of data structures \nbelonging to the scheduler and the rest of the kernel using the tensor operator of alias types, which \ncorresponds to our separating conjunction. However, their type sys\u00adtem does not hide the internal data \nstructures of the scheduler while proving the rest of the kernel, and is thus non-modular. Yang and Hawblitzel \n[24] have recently proposed a kernel where most of the codebase is typechecked and therefore cannot directly \naccess data structures belonging to the core part of the ker\u00adnel, including the scheduler. However, the \nguarantees established by the type system do not take into account the contents of data structures, so \nthe kernel can still subvert the scheduler by leaving them in an inconsistent state. The OS resorts to \nruntime checks in such cases, introducing a performance penalty. The relationship to this work is that \nof a trade-off: type safety guarantees are easier to get, but are not as strong as those provided by \na program logic. Re.nement is a well-known approach in veri.cation of both operating systems and general \nconcurrent programs [1, 10, 15, 17, 22]. We advance it further by proposing its novel form where the \ntarget of the re.nement is de.ned axiomatically and re.nement relations focus only on the relevant state \nof the systems related. This allows us to handle systems with complex ownership transfers. 8. Discussion \nIn this paper we have neither veri.ed a complete operating system nor built an automatic tool. Instead, \nwe have proposed a proof rule that allows decomposing the veri.cation of a preemptive OS kernel into \ntwo simpler tasks verifying the scheduler and preemptable code separately. Such a result is relevant \nno matter what type of formal analysis of OS code one is performing: manual or automatic veri.cation, \nor even bug-.nding. Moreover, as we argued in Sec\u00adtion 2.2, the straightforward approach of verifying \nthe scheduler to\u00adgether with the rest of the kernel makes reasoning intractable; thus, a result such \nas ours is in fact indispensable for verifying realistic OS kernels. The only way we could communicate \nthe proposed reasoning principles understandably is by presenting our results in a simpli\u00ad.ed setting. \nBesides, we could not cover all the interesting features of mainstream OS kernels, even in regards to \nscheduling, in one paper. Below we list some of the limitations of our results and pos\u00adsible ways to \nlift them, which also provide avenues for future work: We based our logic for preemptable code on concurrent \nsep\u00adaration logic, which would not be able to handle complicated concurrency mechanisms employed in modern \nOS kernels. The proof of soundness of our logic follows an approach that has been applied extensively \nto various concurrent derivatives of separa\u00adtion logic [11, 12]. This leads us to believe that we can \nintegrate more advanced logics from this class [4, 5, 23] without problems.  Our treatment of procedure \ncalls is naive in that it does not allow us to reason about procedures modularly. We consider this problem \northogonal to our goal and believe that our logic can be combined with more powerful logics for procedures \nin low-level code, such as [9].   We have considered schedulers with only two procedures in their \ninterface, and .xed the piece of state transferred between the scheduler and the kernel at schedule to \nbe the empty slots of the process stack. It is straightforward to add new procedures and de\u00ad.ne their \npre-and postconditions abstractly, like desc in the pre\u00adcondition of create. The real issue is how to \nrestrict the ways the scheduler is allowed to change the state it receives before giv\u00ading the state back \nto the kernel. For example, in some operating systems (e.g., XNU), schedule can receive the ownership \nof the whole stack of the process being preempted and may reallocate the stack when it schedules the \nprocess again, while preserving its contents. Such an interference is routinely described in com\u00adbinations \nof separation logic and rely-guarantee [4, 5, 23] and can be integrated into our logic.  Modern OS kernels \nhave a number of features that break through the abstraction of a virtual CPU implemented by the scheduler. \nFor example, they allow preemptable code to disable interrupts, e.g., to access data structures local \nto a particular CPU. The effects of such features can be axiomatised in the high-level logic in much \nthe same way as we axiomatise the effect of the create routine of the scheduler. We plan to report on \nextensions of our logic to such features in future papers.  Our logic is designed for proving safety \nproperties only. Proof methods for liveness properties or the absence of deadlocks usu\u00adally rely on modular \nmethods for safety properties. Thus, our logic is a prerequisite for attacking liveness in the future. \n Despite the above limitations, our logic is the .rst to handle patterns of interaction between the \nscheduler and the kernel that are present in mainstream operating systems. Even though the logic has \nbeen formalised in a particular setting, its key technical ideas the use of proof systems validating \nthe frame property, logical re.nement and a local way of establishing it are transferable and can be \nreused in OS veri.cation projects. Acknowledgements We would like to thank Anindya Banerjee, Xinyu Feng, \nBoris Koepf, Mark Marron, Peter O Hearn, Matthew Parkinson, Noam Rinetzky, Zhong Shao, Viktor Vafeiadis \nand Jules Villard for com\u00adments and discussions that helped improve the paper. Yang was supported by \nEPSRC. References [1] R.-J. Back. On correct re.nement of programs. Journal of Computer and System Sciences, \n23:49 68, 1981. [2] D. Bovet and M. Cesati. Understanding the Linux Kernel, 3rd ed. O Reilly, 2005. [3] \nE. Cohen, W. Schulte, and S. Tobies. Local veri.cation of global invariants in concurrent programs. In \nCAV 10: Conference on Computer-Aided Veri.cation, volume 6174 of LNCS, pages 480 494. Springer, 2010. \n[4] T. Dinsdale-Young, M. Dodds, P. Gardner, M. Parkinson, and V. Vafeiadis. Concurrent abstract predicates. \nIn ECOOP 10: Euro\u00adpean Conference on Object-Oriented Programming, pages 504 528. Springer, 2010. [5] \nX. Feng, R. Ferreira, and Z. Shao. On the relationship between concur\u00adrent separation logic and assume-guarantee \nreasoning. In ESOP 07: European Conference on Programming, volume 4421 of LNCS, pages 173 188. Springer, \n2007. [6] X. Feng, Z. Ni, Z. Shao, and Y. Guo. An open framework for founda\u00adtional proof-carrying code. \nIn TLDI 07: Workshop on Types in Lan\u00adguage Design and Implementation, pages 67 78. ACM, 2007. [7] X. \nFeng, Z. Shao, Y. Dong, and Y. Guo. Certifying low-level pro\u00adgrams with hardware interrupts and preemptive \nthreads. In PLDI 08: Conference on Programming Language Design and Implementation, pages 170 182. ACM, \n2008. [8] X. Feng, Z. Shao, Y. Guo, and Y. Dong. Combining domain-speci.c and foundational logics to \nverify complete software systems. In VSTTE 08: Conference on Veri.ed Software: Theories, Tools, Experi\u00adments, \nvolume 5295 of LNCS, pages 54 69. Springer, 2008. [9] X. Feng, Z. Shao, A. Vaynberg, S. Xiang, and Z. \nNi. Modular ver\u00adi.cation of assembly code with stack-based control abstractions. In PLDI 06: Conference \non Programming Language Design and Imple\u00admentation, pages 401 414. ACM, 2006. [10] M. Gargano, M. Hillebrand, \nD. Leinenbach, and W. Paul. On the correctness of operating system kernels. In TPHOLs: Conference on \nTheorem Proving in Higher Order Logics, volume 3603 of LNCS, pages 1 16. Springer, 2005. [11] A. Gotsman. \nLogics and analyses for concurrent heap-manipulating programs. PhD Thesis, University of Cambridge, 2009. \n[12] A. Gotsman, J. Berdine, and B. Cook. Precision and the conjunction rule in concurrent separation \nlogic. In MFPS 11: Conference on Mathematical Foundations of Programming Semantics, 2011. To appear. \n[13] A. Gotsman, J. Berdine, B. Cook, N. Rinetzky, and M. Sagiv. Local reasoning for storable locks and \nthreads. In APLAS 07: Asian Sympo\u00adsium on Programming Languages and Systems, volume 4807 of LNCS, pages \n19 37. Springer, 2007. [14] A. Gotsman and H. Yang. Modular veri.cation of preemptive OS kernels (extended \nversion). Available from www.software.imdea.org/~gotsman. [15] C. Jones. Splitting atoms safely. Theoretical \nComputer Science, 375:109 119, 2007. [16] G. Klein. Operating system veri.cation an overview. S\u00afadhan\u00afa, \n34:26 69, 2009. [17] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin, D. Elkaduwe, \nK. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and S. Winwood. seL4: Formal veri.cation \nof an OS kernel. In SOSP 09: Symposium on Operating Systems Principles, pages 207 220. ACM, 2009. [18] \nR. Love. Linux Kernel Development, 3rd ed. Addison Wesley, 2010. [19] T. Maeda and A. Yonezawa. Writing \nan OS kernel in a strictly and statically typed language. In Formal to Practical Security, volume 5458 \nof LNCS, pages 181 197. Springer, 2009. [20] P. W. O Hearn. Resources, concurrency and local reasoning. \nTheoret\u00adical Computer Science, 375:271 307, 2007. [21] J. Reynolds. Separation logic: A logic for shared \nmutable data struc\u00adtures. In LICS 02: Symposium on Logic in Computer Science, pages 55 74. IEEE, 2002. \n[22] A. Turon and M. Wand. A separation logic for re.ning concurrent objects. In POPL 11: Symposium on \nPrinciples of Programming Languages, pages 247 258. ACM, 2011. [23] V. Vafeiadis and M. J. Parkinson. \nA marriage of rely/guarantee and separation logic. In CONCUR 07: Conference on Concurrency The\u00adory, volume \n4703 of LNCS, pages 256 271. Springer, 2007. [24] J. Yang and C. Hawblitzel. Safe to the last instruction: \nautomated veri.cation of a type-safe operating system. In PLDI 10: Conference on Programming Language \nDesign and Implementation, pages 99 110. ACM, 2010.   \n\t\t\t", "proc_id": "2034773", "abstract": "<p>Most major OS kernels today run on multiprocessor systems and are preemptive: it is possible for a process running in the kernel mode to get descheduled. Existing modular techniques for verifying concurrent code are not directly applicable in this setting: they rely on scheduling being implemented correctly, and in a preemptive kernel, the correctness of the scheduler is interdependent with the correctness of the code it schedules. This interdependency is even stronger in mainstream kernels, such as Linux, FreeBSD or XNU, where the scheduler and processes interact in complex ways.</p> <p>We propose the first logic that is able to decompose the verification of preemptive multiprocessor kernel code into verifying the scheduler and the rest of the kernel separately, even in the presence of complex interdependencies between the two components. The logic hides the manipulation of control by the scheduler when reasoning about preemptable code and soundly inherits proof rules from concurrent separation logic to verify it thread-modularly. This is achieved by establishing a novel form of refinement between an operational semantics of the real machine and an axiomatic semantics of OS processes, where the latter assumes an abstract machine with each process executing on a separate virtual CPU. The refinement is local in the sense that the logic focuses only on the relevant state of the kernel while verifying the scheduler. We illustrate the power of our logic by verifying an example scheduler, modelled on the one from Linux 2.6.11.</p>", "authors": [{"name": "Alexey Gotsman", "author_profile_id": "81322494535", "affiliation": "IMDEA Software Institute, Madrid, Spain", "person_id": "P2801453", "email_address": "Alexey.Gotsman@imdea.org", "orcid_id": ""}, {"name": "Hongseok Yang", "author_profile_id": "81100355747", "affiliation": "University of Oxford, Oxford, United Kingdom", "person_id": "P2801454", "email_address": "Hongseok.Yang@cs.ox.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2034773.2034827", "year": "2011", "article_id": "2034827", "conference": "ICFP", "title": "Modular verification of preemptive OS kernels", "url": "http://dl.acm.org/citation.cfm?id=2034827"}