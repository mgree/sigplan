{"article_publication_date": "09-19-2011", "fulltext": "\n An Ef.cient Non-Moving Garbage Collector for Functional Languages Katsuhiro Ueno Atsushi Ohori Toshiaki \nOtomo* Research Institute of Electrical Communication Tohoku University {katsu, ohori, o-toshi}@riec.tohoku.ac.jp \nAbstract Motivated by developing a memory management system that al\u00adlows functional languages to seamlessly \ninter-operate with C, we propose an ef.cient non-movinggarbage collection algorithm based on bitmap marking \nand report its implementation and perfor\u00admance evaluation. In our method, the heap consists of sub-heaps \n{Hi | c = i = B} ofexponentially increasing allocation sizes(Hi for 2i bytes) andaspecial sub-heap forexceptionally \nlarge objects. Actual space for each sub-heap is dynamically allocated and reclaimed from a pool of .xed \nsize allocation segments. In each allocation segment, the algorithm maintains a bitmap representing the \nset of live ob\u00adjects. Allocation is done by searching for the next free bit in the bitmap.By adding meta-level \nbitmaps that summarize the contents of bitmaps hierarchically and maintaining the current bit position \nin the bitmap hierarchy, the next free bit can be found in a small constant time for most cases, and \nin log32(segmentSize) time in the worst case on a 32-bit architecture. The collection is done by clearing \nthe bitmaps and tracing live objects. The algorithm can be extended to generational GC by maintaining \nmultiple bitmaps for the same heap space. The proposed method does not require com\u00adpaction and objects \nare not moved at all. This property is signi.cant fora functional languageto inter-operatewithC,andit \nshouldalso be bene.cial in supporting multiple native threads. The proposed method has been implemented \nin a full-scale Standard ML compiler. Our benchmark tests show that our non\u00admoving collector performs \nas ef.ciently as a generational copying collector designed for functional languages. Categories and Subject \nDescriptors D.3.4[Programming Lan\u00adguages]: Processors memory management (garbage collection) General \nTerms Algorithms, Languages, Performance Keywords Non-moving Garbage Collection, Bitmap Marking, Generational \nCollectors, SML# * The third author s current af.liation: Hitachi Advanced Digital, Inc. Permission to \nmake digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page.To copyotherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 11, September 19 21, \n2011,Tokyo, Japan. Copyright c . 2011ACM 978-1-4503-0865-6/11/09... $10.00 1. Introduction The general \nmotivation of this research is to develop a mem\u00adory management system for a functional language that \nsupports seamless interoperability with the C language. We have partially achieved this goal through \ntype-directed compilation for natural data representations in ML [25]. Under this scheme, ML records \nand arrays as well as atomic types such as int and real have the same representation as inCand are therefore \ndirectly read or updated by a C program without any data representation conver\u00adsion. This has been embodied \nin our SML# compiler [33]. In this implementation, one can directly import a C function and call it with \ndata structures such as records, mutable arrays, and function closures (for call-backs) created in SML#. \nThe following code is a fragment of a demo program distributed with SML#. val glNormal3dv = dlsym (libgl, \n\"glNormal3dv\") : _import (real * real * real) -> unit ... map (fn (vec, ...) => (glNormal3dv vec; ...)) \n[((1.0, 0.0, 0.0), ...), ...] This code dynamically links glNormal3dv function in the OpenGL library \nas an ML function of type real * real * real -> unit and uses it with other SML# code. SML# compiles \n(1.0, 0.0, 0.0) toa pointertoaheap block containing3double preci\u00adsion .oating point numbers. Since this \nrecord has the same repre\u00adsentation as a double array of C, glNormal3dv works correctly. In addition \nto this natural data representation, each SML# heap object has a header containing object layout information \nindicat\u00ading whether each .eld is a pointer or not. This information is used bytheSML#garbage collector(GC)toexactly \ntracelive objects. By adopting the strategy that the SML# GC only traces and col\u00adlects SML# objects and \nleaves management ofCallocated objects toCcode, we should be able to achieve seamless interoperability \nbetween SML# and C. The solution so far is however only partial in that data struc\u00adtures that are passed \nto foreign functions must be allocated in a special non-moving area. SML# compiler, as well as most other \nfunctional language compilers, has used copying garbage collec\u00adtion (GC) based on the commonly accepted \nbelief being that, for functional programs requiring large amount of short-lived data, the Cheney scopying \ncollector[8]wouldbethe mostef.cientfor their minor collection. However, any(precise) copying GC requires \nthat the runtime system must be able to locate and update all the point\u00aders to each heap allocated data. \nThis prohibits functional programs from inter-operating with foreign functions or any programs that use \nlocal memory space not accessible from thegarbage collector. To side-step this problem, the programmer \nmust explicitly request GC not to move those data that are passed to external code. This objectpinning \napproachisnotonly cumbersomebutalsodanger\u00adous. This problem should be painfullyfamiliar to anyone who \nhas tried to write a functional program that interacts with a foreign li\u00adbrary that requires callbacks \nor locally stores object pointers passed from the caller.Fora language with rather limited interoperability, \nobject pinning mightbe performed automatically,butforanML\u00adstyle language that provides seamless interoperability, \nautomatic object pinning is dif.cult,if not impossible.To see the problem, supposeaCfunctionis called \nwithan arrayanda call-back func\u00adtion. Since both theCfunction and the call-back function can freely mutate \nthe array, the runtime system can only safely estimate that thesetof reachableobjectsfromthearraypassedtotheCfunction \ntobethesetofallthelive objectsinthe entireheap, includingeven those that may be created later by the \ncall-back function.  To solve this problem, we would like to develop anon-moving garbage collection \nalgorithm suitable for functional languages. Since functional programs rely heavily on ef.cient allocation \nand collection, a new non-moving GC algorithm should ideally be as ef.cient as currently widely used \ncopying GC with generational extension [21, 35]. The purpose of this paper is to develop such a garbage \ncollection algorithm, to implement it for a full-scale ML compiler, and toevaluate its performance throughextensive \nbench\u00admarks to verify the feasibility of the algorithm. An obvious non-moving candidate is mark and sweep \nGC [24]. Compared with copying GC, however, simple mark and sweep GC tends to exhibit the following general \nweaknesses. Fragmentation and slow allocation. Functional programs re\u00adquire objects of various sizes \nwith various life time. Due to this property, the heap space becomes fragmented very quickly, re\u00adsultinginslow \nallocationand reclamation.Toavoid this prob\u00adlem, practical variant of mark-and-sweep GC algorithms some\u00adtimes \nperform costly compaction at sweep phase. In contrast, copying GC automatically performs compaction and \nyields a veryfast allocator, which has only to check the heap boundary and to advance the allocation \npointer.  High sweep cost. Mark and sweep GC requires to sweep the heap, which takes time proportional \nto the size of the heap. Again this is in contrast with copying GC whose collection cost is proportional \nto the amount of live data.  Dif.culty in developing ef.cientgenerational GC. While it is straightforward \nto combine mark and sweep GC with other GC to form a generational GC, developing generational mark and \nsweep GC requires certain amount of additional machinery, which would result in slower GC time [10]. \n Perhaps due to these problems, mark and sweep GC seems to be considered not suitable for primary GC \n(e.g. minor GC in gener\u00adational GC) of functional programs, which produces large amount of short-lived \ndata of varied size very rapidly. The main new technical contribution of this paper is to develop a variant \nof mark and sweep GC that is as ef.cient as Cheney s copying GC and its generational extensions, and \nto demonstrate its feasibility for functional languages thorough implementation and evaluation. Our basic \nstrategy is well known bitmap marking (see [37] and [17] fora survey.)We associatea heap with bitmaps \nthat represent the setoflive objects. Thisstructurealonedoes notyield anef.cient allocationand collection.Wehavedevelopedaseriesof \nnew data structures and algorithms that overcome the weakness of markand sweepGC mentionedabove.The followingisasummary \nof the features of our GC algorithm. 1. Afragmentation-avoided and compaction-free heap.Fragmen\u00adtation \noccurs when objects have varied sizes; if all the objects were of the same size, then the heap could \nbe a .xed size array that can be managed by a bitmap without incurring fragmen\u00adtation. An extreme idea \nis to set up a separate heap for each object size. Of course we cannot prepare suf.ciently large sep\u00adarate \nheaps for all possible object sizes, so we prepare a series of sub-heaps {Hi | c = i} of exponentially \nincreasing alloca\u00adtion block sizes, i.e. each Hi consists of allocation blocks of 2i bytes. Actual allocation \nspace of Hi is dynamically maintained as a list of .xed-size segments. Each segment contains an array \nof 2i-byte blocks. 2c is the minimum allocation block size in bytes. In SML#, the minimum size of non-empty \nobjects is8 (23)byte, so we .xc tobe3in this paper. These structures eliminate the fragmentation problem \nassoci\u00adatedwithmarkandsweep collection.Sinceasegmentisa.xed sizearray,itisef.ciently maintainedbyabitmapwhereeachbit \ncorresponds to one block. Moreover, size of each Hi is dynam\u00adically adjusted through allocation and reclamation \nof segments. In our scheme, an allocation block in Hi in general contains an object smaller than 2i bytes, \nand some amount of memory is unused.Ourobservationisthat,wecanavoidcostly compaction attheexpenseoflocallywastingspaceineach \nallocationblock, and that this cost is quite acceptable in practice. Our evaluation shows that the space \nusage is better than that of copying GC in most cases. Since we cannot prepare Hi for unbounded i, we \nseta boundB of i and allocate exceptionally large objects of size more than 2B to a special sub-heap \nM. B can be as large as the size of one segment. According to our experimentation, B = 12 (i.e. at most \n4096 bytes) appears to be suf.cient for functional programs (e.g. covers most of allocation requests.) \nHence, in our system, the heap consists of 10 sub-heaps, H3,...H12. Since the special sub-heap M occupies \na very small portion of the entire heap and can be managed by anynon-copying GC method, we do not consider \nthis further. 2. Ef.cient allocation. Abitmap can be used not only for marking but also for allocation \nby searching for a free bit in a bitmap. Simple search for a free bit in a bitmap takes, in the worst \ncase, the time proportional to the number ofbusy bits. Perhaps due to this problem, most of bitmap based \nGC algorithms use some formoffreelistfor allocation.Wesolvethisproblembyadding meta-level bitmaps that \nsummarize the contents of bitmaps. The set of all bitmaps form a hierarchically organized tree. The sequence \nof bits at the leaf level in the tree is the ordinary bitmap representing liveness of the set of allocation \nblocks, and the sequence of bits at an intermediate level summarizes the bitmap one level below. On this \nbitmap tree, we maintain a data structure representing both the next bit position to be examined and \nthe corresponding block address. This structure corresponds to the allocation pointer of copying GC, \nso we call it an allocation pointer. The whole organization is depicted in Figure 2 whose details will \nbe explained in Section 2. By constructing a series of optimized searching algorithms on this data structure, \nthe next free bit can be found in a small constant time for most cases, and in log32(segmentSize) time \nin the worst case. 3. Small GC cost. Sweepingisdoneby clearing bitmaps.Thetotal collection cost of a \nbitmap making GC is the sum of the costs for clearing bitmaps, tracing live objects, and setting the \nbits in the bitmaps. Among them, the bitmap clearing requires N/32 steps where N is the total number \nof allocation blocks. Our extensive evaluation shows that bitmap clear time is negligible (about 1% of \nthe GC time), and therefore, in practice, the total cost of our GC is dominated by the tracing and marking \ncost. So in practice our GC algorithm behaves similarly to that of copying GC. In most of the benchmark \ntests we performed, the   totalGCcostwas smallerthanthoseofsimplecopying collector and generational \ncopying collector. 4. Non-movinggenerational GC. By adapting the idea of partial collection proposed \nby Demers et.al. [10], our bitmap marking GC scales up to generational GC without moving objects. This \nis based on our observation that a bitmap represents a subset of the set of objects in a heap. Generational \nGC can be real\u00adized by maintaining a separate bitmap for each generation. The partial collection with \nstickybit technique presented in [10] coincides witha special case where tenuring thresholdis1and the \nnumber of generations is 2. Pointers to younger generations from older generations are tracked using \na write barrier and a remembered set. In the above special case, the remembered set can be allocated \nin the collector strace stack due to the property that the remembered set can be .ushed after minor collection. \nThe resulting implementation of the special case does not re\u00adquire anyadditional memory space other than \nthose used in the non-generational version. We have implemented the data structures and algorithms in \na Standard ML compiler, and have done extensive benchmark tests. We have evaluated and compared them \nagainst a simple Cheney s copying GC, and a generational copying GC for functional lan\u00adguages described \nin [29], and have obtained the following results: (i) segment-based dynamic sub-heap size adjustment \nautomatically achieves optimal hand-tuned sub-heap size assignment, (ii) the bitmap marking GC is as \nef.cient as Cheney s copying GC, and (iii) the generational extension outperforms the non-generational \nbitmap GC, and shows comparable or better performance results compared to generational copying GC. These \nresults demonstrate that our development have achieved the goal of developing a non\u00admoving GC method \nfor functional language. The proposed method has additional advantage of supporting multiple native threads \nwithout much additional machinery. Our segment-basedheap organization allows each concurrent thread to \nallocate objects in a shared global heap without anylocking. The detailed implementation and evaluation \nfor multithread extension is outof the scopeof the present paper,but our preliminary imple\u00admentation \nof multithread extension shows promising result. All the implementation is done in our SML# compiler, \nwhich compiles the full set of Standard ML language (with the (mostly) seamless interoperability with \nC) into x86 native code. SML# ver\u00adsion 0.40 or later includes the GC algorithms reported in this paper, \nand they are available and enabled by default in x86 native compi\u00adlation mode. The restofthe paperisorganizedas \nfollows. Section2presents the bitmap marking GC algorithm. Section 3 extends the GC method to generational \nGC. Section4reports implementation and performanceevaluation. Section5compares the contribution with \nrelatedworks. Section6concludes the paper. 2. The bitmap marking GC This section describes the details \nof the data structures and algo\u00adrithms for the bitmap marking GC. This description involves low\u00adlevelbit \nmanipulation.Toachieveef.cient allocationwith bitmaps, we found it essential to design data structures \nand algorithms in detail. Accurately reporting them requires us to present them in de\u00adtails, sometimes \nreferringto bit-level manipulation.For this reason, we useClike syntaxin describing the algorithms. 2.1 \nThe GC-mutator interface Our GC is an exact tracing GC for functional languages. It can be used with \nanycompiler that produces objects with their layout information and maintains an exact root set. In order \nto make accurate comparison with other GC algorithms, we design our GC algorithm witha uniforminterfacetoa \ncompiler.For this purpose, the implementation of our GC provides a function for the mutator to register \na root set enumerator, which takes a function on a heap object pointer of the following type void trace \nfn(void **); and applies this function to each object in a root set. At the beginning of each GC, the \ncollector calls all the registered root set enumerators with an appropriate trace fn function. In the \ncase of Cheney collector, for example, this would be a function to move an object from one semi-space \nto the other; in our GC, this is a function that marks the bit corresponding to an object. An allocation \noperation is designed as a function which takes a request size in bytes and returns a pointer to a newly \nallocated object. This is the most general style of allocator required for natu\u00adral data representation. \nSince the size of natural data representation is different according to their types, the size of some \nrecords in a polymorphic function canonlybe determinedatruntime.Forex\u00adample, consider a function of type \na-> a* a. This function returnsa8byte record for an int argumentanda16byte recordfor an real argument. \nOf course, for monomorphic cases, where sizes are statically known, we can inline-expand the allocation \nfunction to mutator code to produce an optimized allocation code.For the inline-expansion, however, compiler \nrequires detailed knowledge of the allocation function, which may vary according to GC algo\u00adrithms.To \nmake the compiler independent of GC methods, in this paper, we turn offthe inlining.  2.2 The structure \nof the heap space and allocation strategy In what follows, we assume that one machine word is 32-bit \nlong. This is not a restriction; anyother word size can equally be used. Weuseagiven allocationspaceasapoolof.xedsize \nallocation areas, called segments, and set up the entire heap as follows. heap =(M, S, (H3,...,H12)) \nM is a special sub-heap for large objects explained earlier. S is a free segment pool, i.e. set of unused \nsegments. Each Hi is a sub\u00adheap for 2i byte allocation blocks. Each sub-heap has the following structure. \nHi =(SegListi,Pi) SegListi is a list of segments currently belonging to Hi. Pi is an allocation pointer \nfor sub-heap Hi whose structure is de.ned in subsection 2.4. Asegment Si initialized for Hi has the following \nstructure. Si =(Counti, Blksi, BitMapi, Tworki) where Counti is the number of already allocated blocks \nin this segment, Blksi is an array of 2i byte allocation blocks, BitMapi is a bitmap tree, and Tworki \nis the working area used for tracing live objects. The number of allocation blocks in a segment is derived \nfrom the segment size, which is statically .xed. We write Sizei for the number of allocation blocks in \nSi.We assume that every segmentis alignedtopower-of-2 boundaryforfast bit-level address computation. \nWe write Blksi(k) for the k-th block in Blksi. Let Li = .log32(Sizei).. This determines the height of \nthe bitmap tree in a segment Si. The bitmap tree has the following structure Li-1 BitMapi =(BM 0 i ,..., \nBM i ) where BM ji is the j-th level bitmap which is a sequence of bits organized as an arrayof32 bitwords.We \nwrite BM ji (k) to denote the k-th bit and BM ji [k] the k-thwordin the j-th level bitmap. The least \nsigni.cant bit in BM ji [k] is the bit BM ji (32 \u00d7 k + 0) and its most signi.cant bit is BM ij (32 \u00d7 \nk + 31). The leaf-level bitmap  Figure 1. Heap structure BM 0 i represents the liveness of Blksi, namely, \n{ 0 1 Blksi(k) is live, BM i (k)= 0 Blksi(k) is free. As we shall explain below, meanings of 1 and 0 \nare chosen in such away that free bit search can be implemented ef.ciently. Thej +1\u00ad j+1 j th level bitmap \nBM i represents whether each word in BM i has free entry or not, namely, { j+1 1 all bits in BM ji [k] \nare1, BM (k)= i 0 otherwise. So for example if all the bits of the top-level bitmap BM Li i-1 is1 then \nall the blocks in Blksi are live, and there is no space left.  2.3 The allocation strategy With the \nabove structure, SegListi in Hi forms a single alloca\u00adtion area managed by one (virtual) hierarchically \norganized tree of bitmaps. The list itself is regarded as the root bitmap of the entire bitmap tree where \neach bit indicates whether each segment is full or not, and each segment in the list is regarded as an \nimmediate sub-tree ofthe root bitmap. This structure guarantees that the next free block in Hi can be \nfound in log32(Sizei) time in the worst case. In addition, we need to make average allocation as ef.cient \nas possible so that it can be comparable to bump allocation in Cheney GC. To this end, we observe that \nin most cases the block array Blksi is very sparsely used after GC. So we adopt the following strategy. \n1. We sequentially allocate the next free block in Hi. 2. To make the typical case of allocation fast, \nwe maintain a position information of the next candidate of allocation block. If this block is free then \nthe allocator simply returns this next block and advances the position information.  Figure 2. Segment \nstructure 3. If the next block is live, then the allocator searches for the next freebitusingthebitmap \ntree.Toperformthis searchef.ciently, we maintain the next bit position information for higher-level bitmaps. \nThe allocation pointer Pi in Hi introduced in the previous subsec\u00adtion is for this purpose, whose structure \nis given below. Pi =(Si, BitPtrsi, BlkPtri) 0 Li-1 BitPtrsi =(BitPtri ,..., BitPtri ) Si isapointertothe \nactive segment in Hi,i.e. the segment in which blocks are being allocated. BitPtrsi are bit pointers \nindicating the next bit positions in Si to be examined. BitPtr0 i indicates the next bit position to \nbe tested in the leaf-level bitmap BM 0 i . For each 0 = j = Li - 2, BitPtrji +1 points to the parent \nbit representing the bitmapword that includes the bit pointedby BitPtrji . BlkPtri isa blockpointer indicating \nthe block address corresponding to the bit pointed by BitPtr0 i . Using these pointers, allocation is \ndone as fast as bump allocation when the next block is free. Figure1and2shows the structuresof the setof \nsub-heaps and a segment, respectively.  2.4 The allocation algorithm In writing algorithms below, we \nsimply write SegListi instead of a more verbose notation such as Hi.SegList, to indicate that this is \nthe segment list belonging to Hi. Similar notations are used for all the other elements including BitMapi, \nBM ji etc. The structure of the allocation algorithm is given in Figure 3. alloc(n) .rst locates the \nsub-heap Hi by findSubHeapBySize function.IfthetargetCPUhasanativeinstruction counting trailing 0bits \nof an integer (such asBSR instruction of x86 machine), this function canbe implementedbyasequenceofafewinstructions.In \ngeneral cases, thisis implemented througha decision tree designed according to allocation ratio of blocks \nof various sizes. Our bench\u00admark tests show the following average allocation ratio (in number of requests)of \n.rst4sizes.  alloc(n) {Hi = findSubHeapBySize(n); temp = tryAlloc(Hi); if (temp == Fail) { bitmapMarkingGC(); \ntemp = tryAlloc(Hi); } return temp; } tryAlloc(Hi) {if (isMarked(Pi)) {if (findNextFreeBlock(Pi) == \nFail) {if (nextSegment(SegListi,Pi) == Fail) {if (newSegment(Hi) == Fail) {return Fail; }} findNextFreeBlock(Pi); \n}} temp = BlkPtri; inc(Pi); return temp; } newSegment(Hi) {S = allocSegment(i); if (S == Fail) return \nFail; append S to SegListi; Pi = firstBlockOfLastSegment(SegListi); return Success; } inc(Pi) {incBlkPtr(BlkPtri); \nincBitPtr(BitPtr0 i ); } Figure 3. Allocation algorithm (top-level) Hi H0 H1 H2 H3 alloc % 11.6 51.3 \n31.4 4.5 From them, we coded findSubHeapBySize(n) so that it de\u00adtermines Hi for about 93% of allocation \nrequests by 2 compar\u00adisons. The algorithm then tries to allocate a block in Hi using tryAlloc(Hi). If \nit fails then it invokes the bitmap marking garbage collector. tryAlloc(Hi) .rst checks whether the block \npointed by Pi is marked. If not, then it simply returns the block address stored in Pi and increment \nPi by inc function. If the next block is already marked, then it searches for the next free bit in the \nactive segment. If the search fails then it advances Pi to the .rst block of the next segment in the \nSegListi. If there is no next segment then it tries to dynamically allocate a new segment from the free \nsegment pool by newSegment function. Then it tries to search a free bit in the next or new segment. The \ncollection al\u00adgorithm described later organizes SegListi so that the search in the next segment never \nfails. We note that under our strategy of sequentially allocating blocks in Hi, it is not needed to set \nany bit at allocation. The auxiliary functions used in Figure3such as nextSegment should be clear from \ntheir names. The remaining thing is to de.ne findNextFreeBlock as ef.\u00adcientas possible.For this purpose,wehaveexaminedandexperi\u00admented \na number of algorithms in detail. The following is the one that we found thefastest. We implementBlkPtri \nas a machine address of a block, simi\u00adlar to the allocation pointer in copying GC. So incBlkPtr just \nin\u00adcrements the address. BitPtrij is an abstract data structure whose implementation is the following \ntwo word data j jj BitPtri =(Idxi , Maski ) where Idxij is an index into the bitmap array BM ij , and \n Maskji is a 32 bit word in which only one bit is set, indicating the bit position.  For example, if \nBitPtr0 i = (1, 8) (in decimal notation) then it denotes the 3rd bit in the second bitmap word, and corresponds \nto the 35th block.For bit pointers, we de.ne the following primitives. incBitPtr(BitPtrji ) increments \nBitPtrij .  indexToBitptr(x) converts a bit index x to a bit pointer.  bitptrToIndex(BitPtrji ) convertsabit \npointertoabitindex.  j jj isMarked(BitPtr) tests whether the bit in BM at BitPtr i ii is 1. blockAddress(BitPtr0 \ni ) converts a bit pointer to the corre\u00adsponding block address. The last two are used in the context \nof some particular Si. These primitives can be implemented through ef.cient bit manipulation (e.g. see \n[36] for bit manipulation techniques.) Similar primitives are de.ned for Pi,which containsBitPtr0 i .In \nFigure3and the fol\u00adlowing, we also use these primitives for Pi as well as for BitPtrji . We implementfindNextFreeBlock \nby using the bit pointers and their primitives. This function .nds the next free bit in the bitmap tree \nof a segment and adjust BitPtrsi by performing the following steps. 1. Search for a 0 bit in the current \nbitmap word after BitPtr0 i . If one is found then advance BitPtr0 i by setting its Maski 0 accordingly, \nand return. Otherwise, perform the following two steps. 2. Compute the next free bitmap word index k \nafter Idx0 i at level 0 by traversing the bitmap trees at level 1 and above. Set Idx0 i to k and Mask0 \ni to 1. 3. Set Mask0 i to the positionof the .rst0bitin BM 0 i [Idxi 0]. This always succeeds and yields \nthe new mask.  The second step may in turn require to compute the free bitmap word indexes and the masks \nat level 1 and above. So we de.ne the aboveoperation asaprocedure forwardBitPtr(j)that recursively computes \nthe bit pointer of level j using the bitmaps of level j +1 and above. Then the step2above canbe implemented \nas follows. 2.1 Calculate the j +1 level bit pointer BitPtrji +1 that points to the bit corresponding \nto the Idxij -th word in the j level bitmap BM ji . 2.2 Call forwardBitPtr(j +1)to advanceBitPtrji +1 \nto the next free bit position. 2.3 Set BitPtrji tothe .rst0bitinthe bitmapword BM ji [k] where k = bitptrToIndex(BitPtrji \n+1). Figure4showsthe structureofthebit search algorithm, which uses the following operation. nextMask(BitPtrji \n)returns a bit mask Mask such that a bit pointer(Idxji , Mask)points to the next free bit ofBitPtrji \nin the same word. If no free bit is found, it returns Fail. This operation is used in the context of \nsome particular Si. This operation can be implemented ef.ciently through bit manipu\u00adlations as well as \nbit pointer primitives de.ned earlier.  findNextFreeBlock(Pi) { Mask0 i = nextMask(BitPtr0 i ); if (Mask0 \n== Fail) { i if (forwardBitPtr(Pi, 0) == Fail) { return Fail; }} BlkPtri = blockAddress(Si, BitPtri \n0); return Success; } forwardBitPtr(Pi,j) { if (j +1 = Li) return Fail; j+1 j BitPtri = indexToBitptr(Idxi \n); j+1 j+1 Maski = nextMask(BitPtri ); if (Maskj+1 == Fail) { i if (forwardBitPtr(Pi,j +1) == Fail) \n{return Fail; }} j j+1 Idxi = bitptrToIndex(BitPtri ); j Maski = 1; Maskji = nextMask(BitPtrji ); return \nSuccess; } Figure 4. Free bit search algorithm  2.5 The bitmap marking GC algorithm When tryAlloc failsto \nallocatea blockin certainHi, thegarbage collector is invoked. In addition to standard marking collection, \nafter marking phase, the collector rearranges the newly marked SegListi in suchaway thatevery segment \nafter the position Pi has at least one free block. This operation ensures that searching a free block \nin successive segments of the allocation pointer never fail. This arrangement also effectively performs \ncompacting the bitmap treeinverylowcostbymovingallthe .lled sub-treestotheleftof the allocation pointer. \nFigure 5 shows the bitmap marking collection algorithm. It performs the following. 1. For each Hi,clearallthe \nbitmapsinallthesegmentsby writing 0 to each word of in their bitmap trees. This corresponds to sweeping \nthe entire heap area. 2. For each object in the root set, mark the object, increment the live object \ncount Counti, and record it to the trace stack. The trace stack is implemented as a linked list using \nTwork work areas. 3. Whilethetracestackisnotempty,popthetracestack.Foreach object referencestoredina.eldofthepoppedobject,markand \npush the referenced object to the trace stack, and increment the count. 4. When the marking is complete, \nthen the algorithm reclaims empty segments, and reconstructs SegList by rearranging the remaining non-empty \nsegment. The allocation pointer is put at the beginning of the .rst segment which has at least one free \nblock.  Marking an object involves the following operations. 1. Find the bit position corresponding \nto the object. 2. Check whether the bit has already been set. If not, set the bit and propagate this \nchange to upper levels in the bitmap tree.  It uses the following auxiliary function. findBitptr(O).nds \nthe segmentSi in which O is allocated and the bit pointer corresponding to O as follows. Let addr(X) \nbe the starting address of X. First, it computes addr(Si) by bitmapMarkingGC() {for each Hi { clearAllBitmapsAndCount(Hi); \n}traceLiveObjects(); for each Hi { rearrangeSegList(Hi); } } traceLiveObjects() { for each O in rootSet \n{ markAndPush(O); } while (stackIsNotEmpty()) { O = pop(); for each O ' in PointerFields(O) { markAndPush(O \n' ); }} } markAndPush(O) { Si, BitPtr0 i = findBitptr(O); if (not isMarked(BitPtr0 i )) { setBit(Pi, \n0); incrementSegmentCount(Si); push(O); } } rearrangeSegList(Hi) { empty = {Sij | Sij . SegListi, Countji \n=0} filled = {Sj | Sj . SegListi, Countj = Sizei} ii i jj j unfilled = {S| S. SegListi, 0 < Count< Sizei} \nii i reclaim all segments in empty; SegListi = concatSegList(filled, unfilled); set Pi to the .rst Sij \nin SegListi such that Countji < Sizei; } setBit(Pi,j) { BM j [Idxj ]= BM j [Idxj ]| Maskj ; i iii i \nif (j +1 <Li and BM j [Idxj ] == 0xFFFFFFFF) { ii j+1 j BitPtri = indexToBitptr(Idxi ); setBit(Pi,j +1); \n} } Figure 5. Bitmap marking GC algorithm bit-level computation from addr(O). Since every segment is \naligned to power-of-2 boundary, this is done by masking lower bits of addr(O) to 0. Second, it computes \nthe block index k of O in the block array Blksi of Si by address arithmetic. indexToBitptr(k) is the \ndesired bit pointer. Anyother auxiliary functions usedin Figure5shouldbe clear from their names. 3. Generational \nextension In order for our non-moving bitmap marking GC to become a practical and truly better alternative \nto copying GC, we would like to extend it to generational GC. It is of course straightforward to combine \nour bitmap marking GC with any other GC to form a generational GC by moving objects between two heaps \nmanaged by two separate GC,but the resulting system loses the non-moving property. Our goal is to develop \na new method that achieves the desired effect of generational GC without actually moving objects. This \nsection presents one such general method. 3.1 General strategy Demers et.al. [10] observed that generational \nGC is a partial GC that collects some subset of objects, and presented two variants of generational mark \nand sweep GC. This general idea can be adapted todevelopagenerationalextensionof our bitmap markingGC.Our \nstrategy is to maintain multiple bitmap trees for the same sub-heap: one for each generation.  In an \nabstract view, generational GC manages the set of live objects in Hi as n disjoint sets Gi 1 ,..., Gin \n, called generations.We note that a bitmap tree BitMapi of Hi can represent anysubset of the set of all \nblocks in Hi, and therefore that each generation Gik canbe representedbyaseparate bitmap tree BitMapki \nof Hi. These observations yield the following strategy. We use n bitmap trees BitMap1 i , BitMap2 i ,..., \nBitMapni for the same sub-heap Hi. Let [ BitMapki ] bethesetof objects representedby BitMapki . The GC \nalgorithm maintains the following invariant for each k: [ BitMapik] = Gik .Gik+1 .\u00b7 \u00b7\u00b7.Gin or equivalently, \nGik =[ BitMapki ] \\ [ BitMapki +1] . The genera\u00adtional GC algorithm can then be realized as follows. \n1. Every object is assigned a generation number k and a tenure counter indicating the number of minor \ncollections it survived. 2. The mutator allocates an object in Gi 1 with its tenure counter initialized \nto 0. 3. Reclamation of Gik is done by performing the following steps. If k = n, then the algorithm \nclears all the bitmap trees for Hi. If k<n then it overrides BitMapki with BitMapki +1 . This corresponds \nto sweeping Gik by clearing the bits of objects in Gik . The algorithm then traces the set of live objects. \nIf it .nds an unmarked live object, it marks the object in BitMapki and increments its tenure counter. \nIf the tenure counter reaches the tenuring threshold, tenureAge, then the algorithm also marks it in \nBitMapki +1 . This corresponds to promoting the object to Gik+1 . When the tracing completes, the algorithm \nresets BitMapji to BitMapki for all j smaller than k. 4. Reclamation of Gi 1 (minor GC) is invoked at \nsome interval determined by a GC policy. When Gi 1 is .lled up to some prede.ned level, the algorithm \nestimates the oldest generation Gik that needs to be collected, and invokes the collection of Gik . \n  3.2 The GC algorithm In this paper we restrict the number of generations to 2. Then GC is either minor \ncollection of Gi 1 or major collection of Gi 2 .For this simple case, the major tuning parameters are \nthe effective size of minor heap and the frequencyof minor collections. In our segment based bitmapGC, \nthesetwo canbe controlledbythe followingtwo parameters. minorSize: the number of segments which can \nbe allocated before the minor collection.  .llLimit:the percentage limit to which each segment can con\u00adtinue \nto be .lled after minor GC. Segments that are .lled be\u00adyond this limit are regarded as full and will \nnot be used for further allocation.  Each segment Si is extended with oldBitMapi corresponding to BitMap2 \ni .AgenerationalGC algorithmis obtainedbyextending the tryAlloc function and de.ning a new procedure \nminorGC for minor collection. Figure6 de.nes these functions. The algorithm for the major collection \nis the same as bitmapMarkingGC de.ned before. The allocation function alloc is also the same as before, \nexcept that it uses the new tryAlloc. The traceLiveObjects is also the same, except that it uses the \nnew markAndPush that manages the tenure counter and promotion. The underlined part in the .gure6is required \nre.nementtothe non-generationalversion. The setBit is extended so that it can mark bits in oldBitMapi. \ntryAlloc(Hi) { if (isMarked(Pi)) { if (findNextFreeBlock(Pi) == Fail) {increment the minor GC counter; \nif (minor GC counter = minorSizei) minorGC(); if (findNextFreeBlock(Pi) == Fail) { if (nextSegment(SegListi,Pi) \n== Fail) {if (newSegment(Hi) == Fail) {return Fail; }} findNextFreeBlock(Pi); }}} temp = BlkPtri; inc(Pi); \nreturn temp; } minorGC() {for each Hi {for each Sj in Sub(SegListi,Pi, minorSize) { i overwrite BitMapj \nwith oldBitMapj ; }} ii traceLiveObjects(); for each Hi { rearrangeSegListMinor(Hi); } reset the minor \nGC counter; } markAndPush(O) { Si, BitPtr0 i = findBitptr(O); if (not isMarked(BitPtr0 i )) { setBit(Pi); \nincrementSegmentCount(Pi); push(O); increment the tenure counter of O; if (the tenure counter of O = \ntenureAge) { reset the tenure counter of O; setBit(Pi)inoldBitMapi; }} } rearrangeSegListMinor(Hi) \n{ filled = {Sj | Sj . Sub(SegListi,Pi, minorSize), ii Countj = .llLimit \u00d7 Sizei} i unfilled = {Sj | \nSj . Sub(SegListi,Pi, minorSize), ii Countj < .llLimit \u00d7 Sizei} i list = concatSegList(filled, unfilled); \nreplace Sub(SegListi,Pi, minorSize)withlist; set Pi to the .rst Sij in SegListi such that Countji < \n.llLimit \u00d7 Sizei; } Figure 6. Generational bitmap marking GC algorithm Sub(SegListi,Pi,n) is a reference \nto the sub-list of SegListi consisting of n segments immediately preceding Pi in the list. If we further \nrestrict tenureAge to 1,a particularly simple vari\u00adant exists. As we noted earlier, allocation only advances \nthe bit pointer without setting the bits corresponding to newly allocated blocks. This means that BitMapi \nis unchanged during allocation. Since tenureAge is 1, BitMapi after minor GC is the new con\u00adtents of \noldBitMapi. So we do not actually need oldBitMapi. The simplevariantis obtained from the algorithmin \nFigure6by elim\u00adinating the bitmap overriding operation in minorGC, and using the same markAndPush function \nas non-generational GC de.ned in Section 2.5. The resulting algorithm coincides with the collection algorithm \nusing stickymark bits described in [10]. This simpli\u00ad.ed generational GC algorithm can be implemented \nwith the same data structure and the support functions as the non-generational version.  4. Implementation \nand Evaluation We have implemented the bitmap marking GC algorithm presented in Section2andits generationalextension \npresentedin Section3. For comparison purpose,wehavealso implementedaplainCheney copying collector, and \na generational copying GC algorithm for Standard ML described in [29]. In this section, we outline our \nimplementation and show the detailed evaluation results. 4.1 Implementation Our implementation of non-generational \nGC takes the segment size and the total usable memory size as parameters, allocates the speci.ed memory \nusing mmap system call, and sets up the free segment pool and the 10 sub-heaps. The special sub-heap \nM for large objects is implemented as a mark and sweep GC, whose allocation area is dynamically obtained \nand freed usingC library functions malloc and free. Since the usage of this special heap is very low \nin our benchmark tests, this special heap does not affect much on performance results. So we will not \ninclude performance data of this heap. The free segment pool S is implemented as a free list of seg\u00adments. \nIn addition to the above standard implementation, we have also implementedaspecialversionof non-generational \nbitmap-marking GC. In this special version, instead of managing the allocation space as a collection \nof segments, each sub-heap Hi consists of a single large segment whose size is statically determined. \nThis special implementation .rst reads an environment variable that holds 10 numbers R3,...,R12 representing \npercentage ratio of the sizes of sub-heaps H3,...,H12, and sets up the single segment for each Hi. As \nwe shall report in the next subsection, this version is used to evaluate performance of sub-heap size \nadjustment through segment-based dynamic allocation and reclamation. In what follows, we refer to the \nstandard implementation of our non-generational bitmap marking GC as bitmap (or bm), and the special \nversion as bitmap(static). Wehaveimplementedthe simpli.edversionof generationalGC with2generations and \ntenureAge =1, described in Section 3.2, by extending the standard implementation bitmap. The only ma\u00adjor \naddition is a mechanism for a write barrier and a remembered set tokeep track of pointers to young objects \nfrom outside. Since tenureAge is1andanyobject surviveda minor collectionis pro\u00admoted to the old generation, \nthe remembered set can be .ushed after minor GC. Taking advantage of this fact, we allocate a re\u00admembered \nset in the collector s trace stack. As mentioned before, our trace stack is implemented as a linked list \nusing Twork work areas. This is done by assigning a unique pointer slot in Twork to each object. This \nimplementation allows us to determine whether a given object is already in the list or not by checking \nwhether the pointer is non-null. This automatically eliminates duplication in the remembered set. A write \nbarrier can then be incorporated in the generational collector as follows.Awrite barrier codetakes a \nyoung object that is to be referred from the old generation due to mutation, and marks it and pushes \nit to the trace stack. Minor collector simply traces objects using the trace stack whose initial contents \nis the remembered set. In what follows this implementa\u00adtion is referred to as bitmap(gen) (or bm(gen)). \nOur implementation of Cheney collector uses the given mem\u00adory as their two semi-spaces. In addition, \nwe modi.ed the standard Cheneyalgorithm so that it also uses the special sub-heap M for large objects, \njust the same way as in bitmap, bitmap(static) and bitmap(gen). We have carefully tuned and optimized \nthe alloca\u00adtion and collection functions of the Cheney collector, consulting the generated x86 assembly \ncode, to make the Cheney collector performs the best as itself for x86 machine.Wenote that our change \nof including a special sub-heap for large objects makes the Cheney GC slightlyfasterin most cases, especially \nfor those programs that uselargeobjects.SothischangeisinfavoroftheCheneycollector. We also note that \nthis change adds two x86 machine instructions to the optimized Cheneyallocator, which should have increased \nallo\u00adcationoverheadbyvery small amount. Accordingto ourevaluation, thisoverheadis below marginof error.We \nreferto this implemen\u00adtation as cheney (or cp). Our implementation of a generational copying GC for Standard \nML mostly follows [29], which is one of standard generational GC algorithm for functional languages, \nexcept that it uses a .xed heap layout instead of dynamically allocating to-spaces, and that our implementation \nuses exact remembered set instead of card\u00admarking. As in [29], the tenuring threshold is .xed to 1. The \nnumberof generations canbe settoa numbergiven asa parameter. The default number of generations used in \nStandard ML of New Jerseycompileris5, and ourGC onlyhave2generations.So we have compared ourGCagainst \nthiscopyingGC with2generations and5 generations.We refer to them as copy(2g) (or cp(2g))and copy(5g) \n(or cp(5g))respectively.  4.2 Performance Evaluation Weevaluate performanceof our algorithms using publiclyavailable \nbenchmark programs for Standard ML, omitting benchmarks such as fib, tak, ntakl whose memory usage is \nvery small. The evaluation has been done on an Intel Xeon 5150 2.66GHz processor with 8GB memory running \nSUSE Linux Enterprise Server 10. Execution timeis measuredby the system timer. We organize our performance \nevaluation using the following general parameters and measures. Heap size. The entire heap size allocatedby \nthe runtime system except for special sub-heapM. This size includes the allocation area as well as all \nthe administrative data for GC. For the Cheneycollector, this is the size of the sum of to and from spaces. \nFor our GC, this is the size of the sum of allocation blocks, bitmap trees, and a trace stack combined. \n Live object ratio. The average percentage ratio of the total size of live objects after GC against \nthe heap size.  Memory occupancy ratio. The average percentage ratio of the amount of memory actually \nused for objects just before GC against the entire heap size. In the case of the CheneyGC, this is 50% \nat best. Since the allocator aligns each objects to double word boundary, the actual occupancyratio is \nlower than 50%. The ratio of our GC depends on the sub-heap con.guration.  Total time. The user time \n(in seconds) spent for the program to run.  GC time. The time (in seconds) spent in GC.  In our method, \nsweeping is done by clearing bitmaps, which is proportional to the heap size with very small constant \nfactor. According to all the results, the bitmap clear time is in the range of 2.4% 0.06% of the GC \ntime, and in most cases they are less than 1% of the GC time. So we can safely conclude that bitmap clear \ntimeis negligible.We omit the detailed data. Through preliminary evaluations and comparisons, we found \nthat performance depends on the live object ratio, and that the set of benchmarks can be roughly grouped \ninto the following three categories. GroupIof those that only producevery short-lived data, and show \nvery low live object ratio.  Figure 7. Performance of bitmap(gen) on typical benchmarks Group III of \nthose that require some amount of memory and show high live object ratio.  GroupIIisin between GroupIand \nGroup III.  We sometimes use these groups in evaluation and comparison. Our .rst evaluation is the performance \nof automatic sub-heap size adjustment through dynamic segment allocation and reclama\u00adtion. Our claim \nof fragmentation-avoided heap depends on this per\u00adformance. If sub-heap size adjustment is not optimal \nin our GC then large amountof memorywouldhavebeenwasted.Toevaluate this, we have .rst estimated the best \npossible sub-heap size con.gura\u00adtion for each benchmark using our bitmap(static) implementation; we have \nrun each benchmark test on bitmap(static) a number of times (30 80 times) with different sub-heap size \ncon.gurations by changing the environment variable we mentioned above. For each benchmark, we have selected \nthe sub-heap size con.guration that shows the best performance as our estimate of the optimal sub\u00adheap \nsize con.guration for bitmap(static).Wehavethen compared performance of this hand-tuned bitmap(static) \nagainst bitmap and cheney.Weomitthe detailsofthe resultandonlyshowa summary of overall performance of \ntwo typical benchmarks in each group inTable 1.We witnessed that all the others show similar behavior. \nThe results show the following. The hand-tuned bitmap(static) performs better than cheney in most cases. \nThe GC time is always shorter, and the total time is slightly better in most cases.  The hand-tuned \nbitmap(static) shows signi.cantly better mem\u00adory usage for almost all the cases.  Performance of the \nstandard bitmap is as good as the best hand-tuned bitmap(static) in memory usage, GC time and the execution \ntime.   These results verify that the dynamic segment allocation mecha\u00adnism we have developed and implemented \nperforms as ef.ciently as the best possible sub-heap size assignment obtained through hand-tuning. We \nthus conclude that this mechanism achieves al\u00admost optimal heap size adjustment automatically and dynamically. \nPrior to overall performance evaluation, we searched for op\u00adtimal values of the tuning parameters for \nthe standard version bitmap and the generational version bitmap(gen). The segment size is a tuning parameter \ncommon to bitmap and bitmap(gen).We have evaluated the performance of bitmap with various segment sizes \nfrom 32KB to 512KB. The results show that GC performance is not sensitive to segment size except for \nthe cases where the total heap size is rather small compared to segment size.We omit the detailed data, \nand only state our conclusion that the segment size of 128KB is generally acceptable for all the benchmarks \nwe used. All the data of bitmap and bitmap(gen) in this section are taken with 128KB segments. Forbitmap(gen), \nwe need to set its tuning parameters.llLimit and minorSize.To determine the optimal values for .llLimit, \nwe have evaluated the benchmarks against values of 0.2, 0.3,..., 0.9. According to the results, which \nwe omit here, both the GC time and the total time of the most of benchmarks are not sensitive to this \nparameter, and 0.5 is reasonable for all the cases. So we set .llLimit to 0.5.To determine the optimalvalueof \nminorSize, we have evaluated the benchmarks with different minorSize values from 1 to the total number \nof segments. The benchmark test results, which we omit, indicate that larger minorSize value is generally \nfavorable. So we setminorSize to be unlimited. With these parameters, we have evaluated our generational \nGC bitmap(gen) and compared the results with those of the copying collectors copy(2g) and copy(5g).For \nthis purpose, we have run each of the benchmark programs with various heap sizes, ranging from the minimum \nrunnable size to suf.ciently large size. Figure7showsthe resultsofa typical benchmarkofeachofthe three \ngroups. It shows the total execution time(exec), the GC time (gc), and the mutator time(mutator)i.e. \nthe difference of exec and gc against various heap sizes. From these sample results, we observe the following \nproperties. For both generational and non-generational versions, the GC time of bitmap marking GC methods \nis shorter than that of copying GC methods. In particular,the GC time of bitmap(gen) is the shortest \nin most cases. Among the copying GC methods, copy(2g) is the shortest in GC time.  The mutator time \nof bitmap GCs is longer than that of copying GCs, as expected. This difference should be due to the over\u00adhead \nof bitmap searching againstbump pointer allocation. The difference of mutator time between non-generational \nand gen\u00aderational versions is very small.  The total execution time of bitmap(gen) is shorter than that \nof bitmap. This shows that our generational GC scheme has the expected advantage for mark and sweep GC. \nAmong copying GC methods, copy(2g) is the shortest in the total time.  We cannot draw anyde.nite conclusion \non the relative strength of bitmap(gen) against copy(2g);sometimesbitmap(gen) out\u00adperforms copy(2g) and \nconversely depending on benchmarks and heap size.  In additionto those3benchmarksshownin Figure7,weeval\u00aduated \nthe other benchmarks against varying heap sizes. We ana\u00adlyze these evaluation results and try to extract \ngeneral property of our bitmap GC method, in particular, the relative strength of bitmap(gen) against \ncopy(2g). Tomakea proper analysisofthe benchmarkdata,we normalize them according to the relative heap \nsize against the minimum Group benchmark min bm bm(gen) cp cp(2g) cp(5g) I barnes hut 1 1.24 1.17 1.20 \n1.13 1.29 count graphs 1 13.75 12.60 13.32 12.40 14.25 cpstak 1 1.09 0.89 1.06 0.92 1.16 diviter 1 3.40 \n3.15 3.36 3.22 3.53 divrec 1 4.03 3.75 3.80 3.64 3.94 fft 2 1.61 1.52 1.55 1.49 1.57 life 1 0.59 0.57 \n0.56 0.55 0.58 logic 1 2.26 2.09 2.22 2.16 2.65 mandelbrot 1 1.05 0.97 1.00 0.97 1.03 nucleic 1 0.13 \n0.12 0.13 0.12 0.14 puzzle 2 27.40 24.99 26.62 24.04 25.08 ray 1 0.95 0.84 0.91 0.84 0.95 simple 2 1.82 \n1.69 1.73 1.64 1.76 II boyer 5 0.09 0.09 0.10 0.09 0.10 knuth bendix 6 0.65 0.55 0.62 0.51 0.52 lexgen \n8 1.21 1.12 1.06 0.99 1.01 mlyacc 9 0.20 0.19 0.18 0.17 0.17 ratio regions 13 35.47 38.16 33.60 33.05 \n36.55 smlboyer 5 0.75 0.73 0.77 0.80 0.85 tsp 7 0.51 0.52 0.51 0.61 0.66 vliw 2 1.81 1.37 1.52 1.30 1.54 \nIII gcbench 35 3.25 2.98 3.23 3.03 3.33 perm9 95 2.95 2.99 3.07 3.58 4.29 (min: minimum heap size in \nMB for bm(gen). bm, bm(gen), cp, and cp(ng):average total execution time with each GC method in seconds.) \nTable 2. Performance summary runnable heap size.For mostof the benchmarks, the minimal heap size of a \nbitmap marking GC is smaller than the corresponding copying GCs in both simple and general version. So \nwe take the minimal heap size of each benchmark as the minimal heap with which bitmap(gen) can run. To \neliminate anomalous or singular results due to too small or large heap, we sample the benchmark results \nwith heap sizes from 2 to 6 times of this minimum heap sizeunit.Table2showsthe summaryoftheaverageexecutiontime \nover varying heap sizes for each benchmark. This table shows the following. bitmap(gen) outperform bitmap \nin almost all cases, as ex\u00adpected.  copy(2g) shows the best performance among the copying GC methods \nin most cases.  Figure 8 shows the ratio of total execution time of bitmap(gen) against that of copy(2g) \n(smalleris better) under2,4,and6times of the minimum heap size. These results showthat, for smaller heap \nsize, bitmap(gen) outperforms copy(2g). While the performance of bitmap(gen) is getting slightlyworse \nthan thatof copy(2g) when the heap size increases, the ratios are around1in most of bench\u00admarks. From \nthese data, we can conclude that the performance of bitmap(gen) is comparable to that of copy(2g). These \nresults are quite satisfactory; they show that our non\u00admoving generational GC is a viable alternative \nto generational copying GC for functional languages. 5. Related works This section compares our approach \nwith some more relatedworks that are not mentioned in Section 1. Supporting ef.cient GC is essential \nfor any optimizing func\u00adtional language compilers. The current state-of-the-art in this .eld appears \nto be a generational GC whose minor (younger) collector is a variant of Cheneycopying collector. OCaml, \nMLton, and old versionof Haskell useahybridofcopyingGC with mark-compact GC [7, 31]. SML/NJ [29], Chez \nScheme [14], and the latest Glas\u00adgow Haskell Compiler [23] use generational copying GC. In all  2 \u00d7 \nminimum heap 4 \u00d7 minimum heap 6 \u00d7 minimum heap average execution time Figure 8. bitmap(gen) vs. copy(2g) \nthese systems, the Cheney scopying collector is used for minor GC and object-moving is inevitable, which \nmakes inter-operation with other languages cumbersome and error-prone.A new contribution of ourworkisto \npresenta non-moving alternative. Our benchmark tests including those that generate large amount of short-lived \ndata such as cpstak show the feasibility of our approach. Mark and sweep GC has also been extensively \nstudied. Major issues havebeen ef.cient data structure for liveobjects, ef.cient al\u00adlocation, avoiding \nfragmentation through compaction, and ef.cient sweeping. The idea of using separate bitmaps to represent \nlive objects is well known. Examples include bitwise sweep [12], bitmapped .ts [37], and mark-and-deferred-sweep \n[38] based on lazy sweeping [16]. The main focuses of these works and others are on reducing theGCtimeandthecostforfreelist \nconstructionbyavoiding scan\u00adning the entire heap. In contrast, our GC method uses bitmaps not onlyfor \nrepresentinglive objectsbutalsofor allocation. Allocation is done using bitmaps without anyother data \nstructure. Reducing sweep cost has been one of central issue, and a num\u00adber of approaches have been proposed \nand implemented. Exam\u00adples include mark during sweep [28], Treadmill [1], lazy sweep\u00ading [5, 16, 38], \nand selective sweeping [9]. Mark and split [30] eliminates subsequent sweep operations. In the context \nof sweep\u00ading, we can say that our approach eliminates the need of complex algorithms and data structures \nfor sweeping and compaction, and yet achievesveryfast sweeping; sweepis done simplyby clearing bitmaps, \nwhose cost is shown to be negligible in our benchmark tests. One approach for ef.cient allocation, widely \nused in manyGC methods[4,6,11,15,22,29,34],istodividetheheapinto multiple areas of different size and \nmanage those areas as a pool of Big Bag ofPages (BiBoP) [18] and some form of segregated free list such \nas [20]. In general perspective, our method of dividing the heap into sub-heaps of .xed size segment \nshares the same motivation with these previous works. In particular, obtaining a bit pointer from an \nobject address mentioned in Subsection 2.5 can be regarded as an instance of encoding object meta-data \nin BiBoP. Our major new contribution is to prepare a sequence of sub-heaps of exponentially increasing \nblock sizes. With this con.guration, we avoid costly compaction at a reasonable expense of locally wasting \nspace in each allocation block. The problem of fragmentation and ef.cient compaction have also been extensively \ninvestigated. Example of recent works in\u00adclude [2, 4, 19, 26]. However, in most of the proposed approaches, \npossibility of fragmentation remains and for long running pro\u00adgram, object-moving compaction is inevitable. \nSCHISM/CMR [27] attempts to eliminate fragmentation by .xing the size of an allo\u00adcation unit, and decomposing \nobjects into multiple units. Although this eliminates fragmentation in the main heap, it needs to intro\u00adduceaseparatecopyingheapfor \nmeta-leveldatato representobject structures. In contrast, our GC does not require anyother structure \nthan the heap itself, and still does not create fragmentation. So com\u00adpaction is not needed by construction. \nOur observation is that our sub-heap organization achieves satisfactory compaction-free heaps at the \nacceptable expense of locally wasting allocation space. Our goal is to develop an ef.cient non-moving \ncollector. A pioneeringworkonthis areais Boehm-Weiser conservativeGC[6] developed for C. Since it is \nnot possible to locate all the pointers of objects allocatedbyCprograms, object-movingGCis impossible. \nOur non-moving constraint has the same origin: to inter-operate withC, we cannot moveobjects that are \naccessed fromCprograms. The problem domain is however rather different. Our aim is not to collect objects \nallocated in theCheap,but to collect only objects that are allocated in the functional-language heap. \nWe hope that thisopensupanewpossibilityofusingGC technologiesdeveloped for functional languages to develop \na new method satisfying non\u00admoving constraint. Precise relationship between our GC method and those of \nconservative GC and its variants including mostly\u00adcopying GC [3, 32] is a topic for further investigation. \n 6. Conclusions and further development Motivated by developing a memory management system that al\u00adlows \nfunctional languages to seamlessly inter-operate with C, we haveproposeda newgarbage collection algorithm \nbased on bitmap marking and have reported its implementation and performance evaluation. The proposed \nmethod realizes a fragmentation-avoided heap throughafamilyof sub-heaps for objectsof 2i bytes (3 = i \n= 12), and ef.cient allocation through hierarchically organized bitmaps. This method can be extended \nto non-moving generational GC by maintaining separate bitmaps for the same allocation seg\u00adments.In ourextensive \nbenchmark tests, our methodis comparable to simple and generational copying GC in most cases. These results \nachieves our goal of developing a non-moving GC method that is as ef.cient as copying GC currently used \nin functional languages. This is our .rst step towards a satisfactory memory manage\u00adment system suitable \nfor functional languages that support various practical features including interoperability with C.A \nnumber of further issues remain to be investigated, including: 1. complete implementation and evaluation \nof generational GC, 2. further ef.cient allocation techniques such asbunched alloca\u00adtions, and 3. ef.cient \nmultithreading support for modern shared memory multi-core processors.  The .rst and second one can \nbe implemented without much dif.\u00adculty. The last one is more challenging and requires newdata struc\u00adturesand \nalgorithms.Wehavealreadydone preliminarydesignand implementation of multithreading extension of our GC \nmethod. Its detailed development and evaluation is outside of the scope of the present paper. In what \nfollows, we brie.y described the extension, focusing on the advantage offered by our new GC method. There \nare a number of issues in developing ef.cient allocation and GC method that support multithreading on \na modern shared memory multi-core architecture. Here we focus on the reduction of synchronizations overhead \nat allocation time. Obtaining a lock at each allocation time would be prohibitively expensive. An existing \nproposalfora functional language[13]isto use thread-local heaps. However, introduction of thread local \nheaps in an ML-style im\u00adperative functionallanguage complicates the algorithms andwould incur overhead \nin both allocation and collection due to the need of maintaining the invariant that there should be no \npointer from a globalheaptoalocalheap.In contrast,ourGC methodallowseach threadto allocateablockinaglobalheap \ndirectly withoutanylock\u00ading for most of the cases. As described in section 2, our allocation algorithm \nsearches for a free block within the current active seg\u00adment using an allocation pointer anda bitmap \nfor that segment.A multithread extension can then be obtained simply by giving each thread its own active \nsegment. Since the allocation pointer and the bitmap in each segment is local to that segment, each thread \ncan al\u00adlocate objects without any locking at all until the active segment becomes full. When the current \nactive segment for a thread be\u00adcomes full, the thread acquires exclusive lock on the sub-heap and attempts \nto obtain a new segment for the active allocation segment of the thread. If the free segment pool is \nempty, GC is invoked. The simple strategy to extend our GC to support multithreading is stop-the-world: \nsuspending all threads before starting the bitmap markingGC.Wehavealreadyexperimentally implementedthisap\u00adproach \nand obtained preliminary evaluation result showing that it achieves expected ef.cient allocation in a \nmultithreaded program running on a multi-core processor. Weexpect that non-moving property should alsobe \nbene.cialin developing concurrent GC, and that the combination of the above approach with concurrent \nand parallel GC mechanisms (see [17] for survey) would yield a satisfactory non-moving concurrent GC \nfor functional languages, which can work with native threads. References [1] H. G. Baker. The treadmill: \nreal-time garbage collection without motion sickness. SIGPLAN Notices, 27(3):66 70, 1992. [2] K. Barabash, \nO. B.-Yitzhak, I. Goft, E. K.Kolodner,V. Leikehman, Y. Ossia, A. Owshanko, and E. Petrank. A parallel, \nincremental, mostly concurrentgarbage collector for servers. ACMTransactions on Programming Languages \nand Systems, 27:1097 1146, 2005. [3] J.F. Bartlett. Compactinggarbage collection with ambiguous roots. \nSIGPLAN LispPointers, 1(6):3 12, 1988. [4]S.M. BlackburnandK.S. McKinley. Immix:a mark-regiongarbage \ncollector with space ef.ciency, fast collection, and mutator perfor\u00admance. In Proceedings of the ACM \nSIGPLAN Conference on Pro\u00adgramming Language Design and Implementation, pages 22 32, 2008. [5] H.-J. Boehm. \nReducinggarbage collector cache misses. In Proceed\u00adings of the International Symposium on Memory management, \npages 59 64, 2000. [6] H.-J. Boehm and M. Weiser. Garbage collection in an uncoopera\u00adtive environment. \nSoftware Practice and Experience, 18(9):807 820, 1988. [7] E. Chailloux, P. Manoury, and B. Pagano. Developing \napplications with Objective Caml. O Reilly, April 2000. French version. [8] C.J. Cheney.Anonrecursive \nlist compacting algorithm. Communica\u00adtionsof theACM, 13(11), 1970. [9] Y. C. Chung, S.-M. Moon, K. Ebcio.glu, \nand D. Sahlin. Selective sweeping. Software Practice and Experience, 35(1):15 26, 2005. [10] A. Demers, \nM. Weiser, B. Hayes, H. Boehm, D. Bobrow, and S. Shenker. Combining generational and conservative garbage \ncol\u00adlection: framework and implementations. In Proceedings of theACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Lan\u00adguages, pages 261 269, 1990. [11]D. Detlefs,C. Flood,S. Heller,andT. Printezis. Garbage-.rstgarbage \ncollection. In Proceedings of the International Symposium on Memory Management, pages 37 48, 2004. [12] \nR. Dimpsey, R. Arora, and K. Kuiper. Java server performance: a case study ofbuilding ef.cient, scalable \nJvms. IBM SystemsJournal, 39(1):151 174, 2000. [13]D. DoligezandX.Leroy.Aconcurrent, generationalgarbage \ncollector for a multithreaded implementation of ML. In Proceedings of the ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Languages, pages 113 123, 1993. [14] R. K. Dybvig. The development of Chez \nScheme. In Proceedings of the ACM International Conference on Functional Programming, pages 1 12, 2006. \n[15] R. K. Dybvig, D. Eby, and C. Bruggeman. Don t stop the BIBOP: Flexible and ef.cient storage management \nfor dynamically-typed lan\u00adguages.Technical report, Indiana University, 1994. [16] R. J. M. Hughes. A \nsemi-incrementalgarbage collection algorithm. Software Practice and Experience, 12(11):1081 1082, 1982. \n[17] R. Jones and R. Lins. Garbage collection: algorithms for automatic dynamic memory management. JohnWiley&#38;Sons, \nInc., 1996. [18] G. L. Steele Jr. Data representation in PDP-10 MACLISP. MIT AI Memo 421, September 1977. \n[19] H.Kermanyand E. Petrank. The Compressor: concurrent, incremen\u00adtal, and parallel compaction. In Proceedings \nof theACM SIGPLAN Conference on Programming Language Design and Implementation, pages 354 363, 2006. \n [20] D. Lea. A memory allocator. http://gee.cs.oswego.edu/dl/html/ malloc.html. [21]H. LiebermanandC.Hewitt.Areal-timegarbage \ncollector basedon the lifetimes of objects. Communicationsof theACM, 26(6):419 429, 1983. [22] S. Marlow, \nT. Harris, R. P. James, and S. P. Jones. Parallel generational-copyinggarbage collection witha block-structured \nheap. In Proceedings of the International Symposium on Memory Manage\u00adment, pages 11 20, 2008. [23] S. \nMarlow, S.P. Jones, and S. Singh. Runtime support for multicore Haskell. In Proceedings of theACM SIGPLAN \nInternational Confer\u00adence on Functional Programming, pages 65 78, 2009. [24] J. McCarthy. Recursive functions \nof symbolic expressions and their computation by machine, Part I. Communications of the ACM, 3(4):184 \n195, April 1960. [25] H.-D. Nguyen and A. Ohori. Compiling ML polymporphism with explicit layout bitmap. \nIn Proceedings of theACM SIGPLAN Inter\u00adnational Conference on Principles and Practice of Declarative \nPro\u00adgramming, pages 237 248, 2006. [26] F. Pizlo, D. Frampton, E. Petrank, and B. Steensgaard. Stopless: \na real-timegarbage collector for multiprocessors. In Proceedings of the International Symposium on Memory \nmanagement, pages 159 172, 2007. [27]F. Pizlo,L. Ziarek,P. Maj,A.L. Hosking,E. Blanton, andJ.Vitek. Schism: \nfragmentation-tolerant real-timegarbage collection. In Pro\u00adceedings of the ACM SIGPLAN Conference on \nProgramming Lan\u00adguage Design and Implementation, pages 146 159, 2010. [28] C. Queinnec, B. Beaudoing, \nand J.-P. Queille. Mark during sweep rather than mark then sweep. In Proceedingsof theParallelArchitec\u00adtures \nand Languages Europe,Volume I:Parallel Architectures, pages 224 237, 1989. [29] J.H. Reppy.Ahigh-performancegarbage \ncollector for Standard ML. Technical report,AT&#38;T Bell LaboratoriesTechnical Memo, 1994. [30] K. Sagonas \nand J.Wilhelmsson. Mark and split. In Proceedings of the International Symposium on Memory Management, \npages 29 39, 2006. [31]P.M. SansomandS.L.P. Jones. Generationalgarbage collectionfor Haskell. In Proceedings \nof the Conference on Functional Program\u00adming Languages and Computer Architecture, pages 106 116, 1993. \n[32] F. Smith and G. Morrisett. Comparing mostly-copying and mark\u00adsweep conservative collection. In Proceedings \nof the International Symposium on Memory Management, pages 68 78, 1998. [33] SML# compiler. http://www.pllab.riec.tohoku.ac.jp/smlsharp/. \n[34] D. Spoonhower, G. Blelloch, and R. Harper. Using page residency to balance tradeoffs in tracing \ngarbage collection. In Proceedings of theACM/USENIX International Conference onVirtual Execution Environments, \npages 57 67, 2005. [35]D.Ungar. Generationscavenging:Anon-disruptivehigh performance storage reclamation \nalgorithm. In Proceedings of the ACM SIG-SOFT/SIGPLAN Software Engineering Symposium on Practical Soft\u00adware \nDevelopment Environments, pages 157 167, 1984. [36] H. S.Warren. Hacker s Delight. Addison-WesleyLongman \nPublish\u00ading Co., Inc., 2002. [37] P. R. Wilson, M. S. Johnstone, M. Neely, and D. Boles. Dynamic storage \nallocation:A surveyand critical review. In Proceedings of the InternationalWorkshop on Memory Management, \npages 1 116, 1995. [38] B. Zorn. Comparing mark-and-sweep and stop-and-copy garbage collection. In Proceedings \nof the ACM Conference on LISP and Functional Programming, pages 87 98, 1990.   \n\t\t\t", "proc_id": "2034773", "abstract": "<p>Motivated by developing a memory management system that allows functional languages to seamlessly inter-operate with C, we propose an efficient non-moving garbage collection algorithm based on bitmap marking and report its implementation and performance evaluation.</p> <p>In our method, the heap consists of sub-heaps <i>H<sub>i</sub></i> | <i>c</i> &#8804; <i>i</i> &#8804; <i>B</i> of exponentially increasing allocation sizes (<i>H<sub>i</sub></i> for 2<i><sup>i</sup></i> bytes) and a special sub-heap for exceptionally large objects. Actual space for each sub-heap is dynamically allocated and reclaimed from a pool of fixed size allocation segments. In each allocation segment, the algorithm maintains a bitmap representing the set of live objects. Allocation is done by searching for the next free bit in the bitmap. By adding meta-level bitmaps that summarize the contents of bitmaps hierarchically and maintaining the current bit position in the bitmap hierarchy, the next free bit can be found in a small constant time for most cases, and in log<sub>32</sub>(<i>segmentSize</i>) time in the worst case on a 32-bit architecture. The collection is done by clearing the bitmaps and tracing live objects. The algorithm can be extended to generational GC by maintaining multiple bitmaps for the same heap space. The proposed method does not require compaction and objects are not moved at all. This property is significant for a functional language to inter-operate with C, and it should also be beneficial in supporting multiple native threads.</p> <p>The proposed method has been implemented in a full-scale Standard ML compiler. Our benchmark tests show that our non-moving collector performs as efficiently as a generational copying collector designed for functional languages.</p>", "authors": [{"name": "Katsuhiro Ueno", "author_profile_id": "81488652229", "affiliation": "Tohoku University, Sendai, Japan", "person_id": "P2801404", "email_address": "katsu@riec.tohoku.ac.jp", "orcid_id": ""}, {"name": "Atsushi Ohori", "author_profile_id": "81100168829", "affiliation": "Tohoku University, Sendai, Japan", "person_id": "P2801405", "email_address": "ohori@riec.tohoku.ac.jp", "orcid_id": ""}, {"name": "Toshiaki Otomo", "author_profile_id": "81488673360", "affiliation": "Tohoku University, Sendai, Japan", "person_id": "P2801406", "email_address": "o-toshi@riec.tohoku.ac.jp", "orcid_id": ""}], "doi_number": "10.1145/2034773.2034802", "year": "2011", "article_id": "2034802", "conference": "ICFP", "title": "An efficient non-moving garbage collector for functional languages", "url": "http://dl.acm.org/citation.cfm?id=2034802"}