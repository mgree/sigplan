{"article_publication_date": "01-12-2005", "fulltext": "\n Region-Based Shape Analysis with Tracked Locations Brian Hackett and Radu Rugina Computer Science Department \nCornell University Ithaca, NY 14853 {bwh6,rugina}@cs.cornell.edu ABSTRACT This paper proposes a novel \napproach to shape analysis: using local reasoning about individual heap locations instead of global reason\u00ading \nabout entire heap abstractions. We present an inter-procedural shape analysis algorithm for languages \nwith destructive updates. The key feature is a novel memory abstraction that differs from traditional \nabstractions in two ways. First, we build the shape ab\u00adstraction and analysis on top of a pointer analysis. \nSecond, we decompose the shape abstraction into a set of independent con.gu\u00adrations, each of which characterizes \none single heap location. Our approach: 1) leads to simpler algorithm speci.cations, because of local \nreasoning about the single location; 2) leads to ef.cient algo\u00adrithms, because of the smaller granularity \nof the abstraction; and 3) makes it easier to develop context-sensitive, demand-driven, and incremental \nshape analyses. We also show that the analysis can be used to enable the static detection of memory errors \nin programs with explicit deallocation. We have built a prototype tool that detects memory leaks and \nac\u00adcesses through dangling pointers in C programs. The experiments indicate that the analysis is suf.ciently \nprecise to detect errors with low false positive rates; and is suf.ciently lightweight to scale to larger \nprograms. For a set of three popular C programs, the tool has analyzed about 70K lines of code in less \nthan 2 minutes and has produced 97 warnings, 38 of which were actual errors. Categories and Subject Descriptors \nF.3.2 [Logics and Meanings of Programs]: Semantics of Pro\u00adgramming Languages Program Analysis; D.2.4 \n[Software En\u00adgineering]: Software/Program Veri.cation; D.3.4 [Programming Languages]: Compilers Memory \nManagement General Terms Algorithms, Languages, Veri.cation  Keywords Shape analysis, static error \ndetection, memory leaks, memory man\u00adagement Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 05, January 12 14, 2005, Long Beach, California, USA. Copyright \n2005 ACM 1-58113-830-X/05/0001 ...$5.00. 1. INTRODUCTION Dynamic data structures are fundamental to \nvirtually all pro\u00adgramming languages. To check or enforce the correctness of pro\u00adgrams that manipulate \nsuch structures, the compiler must automat\u00adically extract invariants that describe their shapes; for \ninstance, that heap cells are not shared, i.e., not referenced by more than one other memory location. \nThis invariant provides critical information to check high-level properties, for instance that a program \nbuilds a tree or an acyclic list; or to check low-level safety properties, for instance that there are \nno accesses through dangling pointers. For imperative programs with destructive updates, the task of \nidentify\u00ading shape invariants is dif.cult because destructive operations tem\u00adporarily invalidate them. \nExamples include even simple operations, such as inserting or removing elements from a list. The challenge \nis to show that the invariants are restored as the operations .nish. There has been signi.cant research \nin the area of shape analysis in the past decades, and numerous shape analysis algorithms have been proposed \n[34]. At the heart of each algorithm stands a sophis\u00adticated heap abstraction that captures enough information \nto show that invariants are being preserved. Examples of heap abstractions include matrices of path expressions \nand other reachability matri\u00adces [18, 17, 11], shape graphs [29, 21], and, more recently, three\u00advalued \nlogic structures [31]; all of these characterize the entire heap at once. Although shape analyses have \nbeen successful at verify\u00ading complex heap manipulations, they have had limited success at being practical \nfor larger programs. We believe that their mono\u00adlithic, heavyweight abstraction is the main reason for \ntheir lack of scalability. This paper presents an inter-procedural shape analysis algorithm based on \na novel memory abstraction. The main idea of this paper is to break down the entire shape abstraction \ninto smaller components and analyze those components separately. As shown in Figure 1, we propose a decomposition \nof the memory abstraction along two directions: Vertical decomposition: First, we build the .ne-grained \nshape abstraction and analysis on top of a points-to analysis that pro\u00advides a coarse-grained partition \nof the memory (both heap and stack) into regions, and identi.es points-to relations between re\u00adgions; \n Horizontal decomposition: Second, we decompose the shape abstraction itself into individual con.gurations; \neach con.gura\u00adtion characterizes the state of one single heap location, called the tracked location. \nA con.guration includes reference counts from each region, and indicates whether certain program expres\u00adsions \nreference the tracked location or not. The set of all con.g\u00adurations provides the entire shape abstraction; \nhowever, con.g\u00adurations are independent and can be analyzed separately. This is the key property that \nenables local reasoning.  Horizontal Decomposition Theoretical Framework: It presents the analysis \nalgorithm in a formal setting and shows that the key parts of the algorithm are independent configurations \nsound; Experimental Results: It presents experimental results col\u00ad lected from a prototype implementation \nof the proposed analysis Vertical decomposition Config. 1 Config. 2 . . . Config. n Shape Abstraction \nfor C programs. The rest of the paper is organized as follows. Section 2 presents an example. Section \n3 introduces a simple language, and Sections 4 and 5 describe the algorithm in the context of this simple \nlanguage. Next, Section 6 presents extensions to the algorithm. Section 7 Region Abstraction Points-to \nInformation discusses limitations. We present experimental results in Section 8, discuss related work \nin Section 9, and conclude in Section 10.  2. EXAMPLE Figure 1: Decomposition of the memory abstraction \nThe vertical decomposition frees the shape analysis of the burden of reasoning about aliases in unrelated \nprogram structures. Fur\u00adther, the horizontal decomposition into independent con.gurations provides a \nrange of advantages. First, it enables local reasoning about the single tracked location, as opposed \nto global reasoning about the entire heap. This makes the analysis simpler and more modular. Second, \nthe .ner level of abstraction granularity reduces the amount of work required by the analysis: ef.cient \nworklist al\u00adgorithms can process individual con.gurations rather than entire abstractions. Third, it \ndoes not require keeping multiple abstrac\u00adtions of the entire heap at each point [30], nor any complex \nmech\u00adanisms to merge entire abstractions for a more compact represen\u00adtation [29]. The decomposition into \ncon.gurations automatically yields a compact representation that is able to model many con\u00adcrete heaps. \nFourth, it makes it easier to formulate inter-procedural context-sensitive analyses where procedure contexts \nare individual con.gurations. Fifth, it makes it easy to build on-demand and in\u00adcremental shape analysis \nalgorithms. Minor modi.cations allow the algorithm to explore from only a few selected allocation sites, \ngiving a complete shape abstraction for all cells created at those sites, and to reuse previous results \nwhen new allocation sites are being explored. We also present extensions of the analysis that enable \nthe static detection of memory errors in languages with explicit deallocation. Our algorithm can identify \nmemory leaks and accesses to deallo\u00adcated data through dangling pointers. We have built a prototype system \nfor C programs that implements the ideas in this paper and is aimed at detecting memory errors. Our experiments \nshow that local reasoning leads to scalable implementations; that it can cor\u00adrectly model shape for standard \nlist manipulations; and that it can enable the detection of memory errors with low false positive rates. \nThis paper makes the following contributions: Memory Abstraction: It proposes a novel memory abstrac\u00adtion \nthat builds the precise shape abstraction on top of a re\u00adgion points-to abstraction; it further decomposes \nthe shape ab\u00adstraction into independent con.gurations that describe individ\u00adual heap locations;  Analysis \nAlgorithm and Applications: It gives a precise spec\u00adi.cation of an inter-procedural, context-sensitive \nanalysis algo\u00adrithm for this abstraction; and shows how to use the analysis results to detect memory \nerrors;  On-demand and Incremental Shape Analysis: It shows that our approach can be applied to the \ndemand-driven and incremen\u00adtal computation of shapes;  We use the example from Figure 2 to illustrate \nthe key features of our analysis. This example is written in C and shows a procedure splice that takes \ntwo argument lists x and y, splices x into y, and returns the resulting list. The code assumes that input \nlist x is not longer than y. The goal of shape analysis is to statically verify that, if the input lists \nx and y are disjoint and acyclic, then the list returned by spliceis acyclic. The execution of splice \nworks as follows. First, it stores a pointer to the second list into a local variable z. Then, the program \nuses a loop to traverse the two lists with parameters x and y. At each iteration, it sets a pointer from \nthe .rst list into the second, and vice\u00adversa, using a temporary variable t. When the traversal reaches \nthe end of list x, it terminates and the procedure returns the list pointed to by z. 2.1 Memory Abstraction \nFigure 3 shows two possible concrete stores that can occur dur\u00ading the execution of splice. The one on \nthe left is a possible concrete store at the beginning of the procedure, where x and y point to acyclic \nlists; and the store on the right is the corresponding memory state when the loop terminates. Boxes labeled \nwith x, y, z, and trepresent the memory locations of those variables. The re\u00admaining unlabeled boxes \nare heap cells and represent list elements. Figure 4 presents the memory abstraction that our analysis \nuses for these two concrete stores. The left part of this .gure shows the region component of the abstraction, \nwhich consists of a points\u00adto graph of regions. Each region models a set of memory loca\u00adtions; and different \nregions model disjoint sets of locations. For this program, our analysis uses a separate region to model \nthe lo\u00adcation of each variable1: X, Y, Z, and T are the regions containing variables x, y, z, and t, \nrespectively. Region L models all list el\u00adements. The points-to graph Figure 4 shows the points-to relations \nbetween abstract regions for the whole procedure, as given by a .ow-insensitive pointer analysis. Hence, \nthis graph applies to both the input and output abstractions discussed here. The right part of Figure \n4 shows the shape component for each of the concrete stores. Each abstraction consists of a set of con\u00ad.gurations: \nthe input abstraction has 3 con.gurations and the out\u00adput abstraction has 4. Each con.guration characterizes \nthe state of the tracked location and consist of: a) reference counts from each region to the tracked \nlocation, shown in superscripts; b) program expressions that de.nitely reference the tracked location \n(hit ex\u00adpressions); and c) program expressions that de.nitely do not (miss expressions). For instance, \ncon.guration (T1 L1 , {t}, \u00d8) shows that the tracked location has one incoming reference from region \nT, 1Although not the case in this example, it may happen that multiple variables get placed into the \nsame region. 1: typedef struct list { 2: struct list *n; 3: int data; 4: } List; 5: 6: List *splice(List \n*x, List *y) { 7: List *t = NULL; 8: List*z=y; 9: while(x != NULL) { 10: t=x; 11: x = t->n; 12: \nt->n = y->n; 13: y->n = t; 14: y = y->n->n; 15: } 16: return z; 17: } Figure 2: Example program: \nsplicing lists one incoming reference from region L, and is referenced by t,but any expression originating \nfrom L (i.e., next pointers) may either reference it or fail to reference it. Although we could have \nused richer sets of miss expressions, these abstractions are suf.cient for our algorithm to prove the \nshape property. These abstractions are complete: the set of all con.gurations in each abstraction provides \na characterization of the entire heap. In\u00addeed, if the tracked location is any of the .ve heap cells, \nthere is a con.guration that characterizes it. But although their sum collec\u00adtively describes the entire \nheap, con.gurations are independent: the state described by any particular con.guration is not related \nto the other con.gurations; it characterizes one heap location and has no knowledge about the state of \nthe rest of the heap (beyond what is given by the points-to graph). This is the key property that enables \nlocal reasoning. 2.2 Analysis of Splice Figure 5 shows the analysis result that our algorithm computes \nat each point in the program. This shape abstraction builds on the region points-to abstraction from \nthe previous section. Boxes in the .gure represent individual con.gurations; each row represents the \nentire heap abstraction at a program point; and edges correlate the state of the tracked location before \nand after each statement. There\u00adfore, each path shows how the state of the tracked location changes during \nprogram execution. For readability, we omit wrap-around edges that connect con.gurations from the end \nto the beginning of the loop. Also, we omit individual variables from hit and miss sets, and show just \nthe .eld accesses expressions. We use the abbrevia\u00adtions: tn= t->nand yn= y->n, and indicate miss expressions \nus\u00ading overlines. Our algorithm ef.ciently computes this result using a worklist algorithm that processes \nindividual con.gurations (i.e., individual nodes), rather full heap abstractions (i.e., entire rows). \nThe top row shows three con.gurations, Y1,L1, and X1, that describe the memory for any input where x \nand y point to acyclic lists. The bottom row consists of con.gurations Z1 and L1, and shows that at the \nend of the procedure the returned value zpoints to an acyclic list. Hence, the analysis successfully \nveri.es the desired shape property. We discuss the analysis of several con.gurations to illustrate how \nthe analysis performs local reasoning. Consider the con.gura\u00adtion Y1Z1 before the statement at line 11, \nx=t->n. The compiler inspects this assignment and tries to determine whether or not the expressions in \nthe left-and right-hand side reference the tracked lo-Example concrete input Corresponding output t t \nx  x z  z   Figure 3: Example concrete memories Region Shape Component Points-to Con.gurations \nCon.gurations Component for input memory for output memory T n (X1 , {x}, \u00d8) (Z1 , {z}, \u00d8) X (Y1 , {y}, \n\u00d8) (T1 L1 , {t}, \u00d8) L (L1 , \u00d8, \u00d8) (Y1 L1 , {y}, \u00d8) Z (L1 , \u00d8, \u00d8) Y  Figure 4: Memory abstraction cation: \nif the right side references the location, the assignment may add a new reference to it; and if the left \nside points to the tracked lo\u00adcation, the assignment may remove a reference to it. For x=t->n, the analysis \ndetermines that xrepresents a location in region X, and t->nis a location in region L, as indicated by \nthe points-to graph. But the reference counts in the current con.guration show that the tracked location \nhas no references from regions X or L; hence, it concludes that neither x, nor t->n reference the tracked \nlocation and this assignment doesn t affect its reference counts. Consider now the con.guration L1 at \nthe same program point, before line 11. The compiler can use the same judgment as above to determine \nthat xdoes not reference the tracked location. However, it is not able to determine whether or not t->n \nreferences it. At this point, the compiler bifurcates the current con.guration into two con.gurations \nwhere this fact is precisely known: one where t->n references the location and one where it doesn t. \nIn each case, it adds t->n to the corresponding hit or miss set, and analyzes the assignment. The resulting \ntwo con.gurations L1 and X1L1 after line 11 are the successors of the analyzed con.guration L1 . Keeping \ntrack of hit and miss sets provides invaluable informa\u00adtion to the analysis. Consider con.guration L1 \nbefore statement t->n=y->n. The analysis of this statement yields a con.guration L2, where the tracked \nlocation has two incoming references from L and violates the desired shape property. However, the analysis \nidenti.es that the reference y->nis being copied, so it adds y->n to the hit set of con.guration L2. \nAt the next assignment, y->n=t, the analysis identi.es that the same expression y->nis being over\u00adwritten. \nThe presence of y->nin the hit set enables the analysis to accurately decrease the reference count from \nL back to 1.  2.3 Cyclic and Shared Inputs Analyzing the behavior of splice for cyclic or shared input \nlists provides key insights about why the local reasoning about the single location works. The left part \nof Figure 6 shows an input store where the list pointed to by y contains a cycle; the right part shows \nthe resulting memory after running splicewith this input. 8:z=y; 9: while (x != NULL) 10: t=x; 11: \nx = t->n; 12: t->n = y->n; 13: y->n = t;    Loop Z1 14: y = y->n->n;  T1 L1 Y1T1L1 L1 Y1L1 X1 \n16: return z;  Z1 L1 Figure 5: Shape analysis results for splice. Boxes represent con.gurations and \nedges show how the state of the tracked location changes during the execution. We only show .eld access \nexpressions in the hit and miss sets. We use the abbreviations: tn= t->n and yn= y->n, and we indicate \nmiss expressions using overlines. For readability, back edges from con.gurations at the end of the loop \nto the corresponding con.gurations at the beginning of the loop are omitted. A closer look at the input \nstructure reveals that the cycle is caused by the presence of one shared cell with two incoming references, \nthe shaded cell. If we inspect the output structure we see that it is also a cyclic list. The interesting \nfact is not that spliceyields a cyclic output given a cyclic input; but rather that the shaded cell that \ncauses the input cycle is exactly the same cell that causes the cycle in the output. Therefore, reasoning \nabout cycles requires reasoning just about this particular cell. All of the other cells in this structure \nbehave as in the acyclic case. To build the abstraction for the cyclic input from Figure 6, we can use \nthe previous abstraction, and augment it with one additional con.guration L2 to describe the cell in \nquestion. The analysis of the abstraction for the cyclic input will yield a con.guration graph similar \nto the one from Figure 5, but augmented with additional paths that originate at the L2 con.guration. \nThese paths describe the state of the shared cell through the program. One can examine the input-output \nrelationships in the result graph, and identify that the shared cell in the input (L2) may remain shared, \nbut all of the non-shared cells in the input (X1,Y1, and L1) will remain non\u00adshared in the output. In \nfact, the analysis of the cyclic case can reuse all of the analysis result from the acyclic case. This \nis possible because the analysis of each con.guration in Figure 5 reasons only about one location, and \nmakes no assumption about the presence or absence of cycles in the rest of the structure. Hence, those \nresults directly apply to cyclic inputs; they characterize the acyclic portion of the cyclic input. Similar \nsituations arise for inputs that have shared sublists, or inputs where one list is a sublist of the other. \nThis discussion brings us to the inter-procedural analysis, the main obstacle in building scalable analyses. \nThe example shows that our abstraction allows us to ef.ciently build an inter-procedural context-sensitive \nanalysis, where the analysis of each calling con\u00adtext can reuse results from other contexts. In our example, \nthe anal- Corresponding output Cyclic input z t  Figure 6: Example cyclic memory ysis of splice for \na cyclic context can reuse the result from an acyclic context, and do little additional work. And if \nthe cyclic context is being analyzed .rst, the result for the acyclic one is al\u00adready available. This \nis possible because we can break down the entire heap context into .ner-grain contexts that are just \nindividual con.gurations.  3. A SIMPLE LANGUAGE To formalize the description of the algorithm, we use \nthe simple language shown in Figure 7. This is a typeless C-like imperative language with procedures, \ndynamic allocation, and explicit deallo\u00adcation. A program prog maps each procedure to a pair containing \nits formal parameters and its body. The only possible values are pointers to memory locations and null \npointers. Dynamic alloca\u00adtions create structures that contain one memory location for each .eld. There \nis a distinguished .rst .eld f1 in each structure; dy\u00adnamic allocations return a pointer to the .rst \n.eld in the newly al\u00adlocated structure. The language supports pointers to variables and pointers into \nthe middle of structures. An expression e.f requires e to be an l-value representing the .rst .eld of \na structure; then e.f is the f .eld of that structure. A dereference expression *e al\u00adprograms: prog \n.Prog = P .(Vn \u00d7S) procedures: p .P statements: s.S, s::= e0 .e1 |e.malloc |free(e) |call p(e1,..,en) \n|s0 ; s1 |if (e) s0 else s1 |while (e) s expressions: e.E, e::= null |x |&#38;e |*e |e.f variables: x \n.V .elds: f .F = {f1,...,fm} Figure 7: Source language ways represents the memory location pointed to \nby e(not the whole structure when e points to a structure). C expressions of the form e->f are represented \nin our language as (*e).f. Deallocation statements free all of the locations in a structure and yield \ndangling pointers. We formally model concrete stores that can arise during program execution using a \nset of memory locations Lthat contains the stack locations for variables, and all of the heap locations \ncreated during program execution. Let V be the set of variables in the program. A concrete store is a \ntriple s =(sv,sl,sf ), consisting of: Variable map: sv : V .L Location map: sl : L-(L+ {null}) Field \nmap: sf :(L\u00d7F) -L The map sv assigns a location to each variable. The partial map sl models points-to \nrelations between locations. We require that range(sv) .dom(sl). The set range(sv) represents stack-allocated \nmemory locations. The set Ls = dom(sl) -range(sv) represents the currently allocated heap locations. \nA stack or heap location l contains a dangling pointer if sl(l) .dom(sl) .{null}. Finally, the partial \nmap sf captures the organization of .elds in allocated structures. For a location l .L that represents \nthe .rst .eld in a heap structure, sl(l,f) represents the f .eld of that structure. We require that all \nlocations in the domain and range of sf be allocated. The Appendix describes the formal semantics of \nthe language us\u00ading a relation (e,s).l lthat evaluates expression eto its l-value; a relation (e,s).v \nv that evaluates e to its r-value; a relation (s,s).s s' for statements. In this paper, we refer to the \nl-value of an expression eas the location of e, and to the r-value of eas the value of e. We formulate \nthe proposed analysis algorithm in the context of this language. The overall algorithm .rst performs \na region anal\u00adysis, and then runs the shape analysis. The following two sections describe each of these \nanalyses in turn. 4. REGION ANALYSIS The goal of region analysis is to provide a partitioning of the \nmemory into disjoint regions, and to identify points-to relations be\u00adtween regions. In general, this \ncan be achieved using any pointer analysis algorithm; our shape analysis is independent of the partic\u00adular \npointer analysis being used. However, we use a .ow-insensitive and context-sensitive pointer analysis \nsimilar to [24] and [10]. Such algorithms seem a good match for our problem because of two rea\u00adsons. \nFirst, they are ef.cient in practice, due to .ow-insensitivity. Second, they are precise enough to distinguish \nbetween different heap structures allocated at the same site, due to context-sensitivity. Using such \nan algorithm, the analysis result is a points-to graph for each procedure; nodes in these graphs represent \nmemory regions, and edges model points-to relations between regions. Most impor\u00adtant in our system is \nto characterize the computed region result, thus describing the interface between region and shape analysis. \nGiven a program, a region abstraction consists of the following: for each procedure p, a set of regions \nRp that models the loca\u00adtions that pmay access;  for each procedure f, a region abstract store: .p =(.pv,.pr \n,.fp ), where .pv : V .Rp maps variables to their regions; the partial map .pr : Rp -Rp models points-to \nrelations between regions; and .pf :(Rp \u00d7F) -Rp maps pairs of base regions and .elds to .eld regions; \n for each call site cs, with caller p and callee q, a one-to-one mapping \u00b5cs : Rq .Rp that maps all \n(parameter) regions in q to actual regions in p.  A region abstraction is sound if regions describe \ndisjoint sets of memory locations, and points-to relations in the abstraction accu\u00adrately describe points-to \nrelations in the concrete heap. We give a formal de.nition of soundness in Section 5.3. Key to the algorithm \nis that regions are disjoint, so the subsequent shape analysis can safely conclude that an update in \none region will not change the values of locations in other regions. We brie.y sketch the .ow-insensitive \nand context-sensitive anal\u00adysis that computes the region points-to abstraction. First, the algo\u00adrithm \nperforms an intra-procedural, uni.cation-based analysis [32] to build a points-to graph for each function. \nThen, it performs an inter-procedural analysis and propagates the aliasing information between different \nfunctions at each call site. The algorithm uses a two-phase approach similar to [24]: a bottom-up pass \nthrough the functions in the call graph propagates the aliasing information from callees to callers; \nand, a top-down phase propagates the information from callers to callees. Note that the region partitioning \nthat other kinds of pointer anal\u00adyses produce could be modeled in a similar way. For a context\u00adinsensitive \npointer analysis, each call site mapping \u00b5cs is the iden\u00adtity function. And in the case of a .ow-sensitive \napproach, the analysis result is not just one abstract store .per function, but a set of abstract stores, \none for each program point. 5. SHAPE ANALYSIS This section presents the shape analysis algorithm in \ndetail. We .rst present the shape abstraction and then give the intra-and inter\u00adprocedural algorithms. \n5.1 Shape Abstraction The role of the shape abstraction is to make the points-to infor\u00admation more accurate. \nRoughly speaking, the region abstraction provides may points-to relations between memory locations, and \nthe shape abstraction augments it with must points-to informa\u00adtion about each heap cell. The shape abstraction \nis based on the notion of con.gurations. Each con.guration abstracts the state of one individual memory \nlocation, the tracked location. The full heap abstraction consists of a .nite set of con.gurations, such \nthat each concrete memory location can be modeled by one con.guration in the set. Each con\u00ad.guration \nkeeps track of: reference counts from each region to the tracked location; expressions that de.nitely \nreference the tracked location (hit expressions); and expressions that de.nitely don t ref\u00aderence the \nlocation (miss expressions). Formally, we describe con.gurations using an index domain I for counting \nreferences, and a secondary domain Hfor hit and miss expressions. A con.guration is then a pair of an \nindex and a sec\u00adondary value. If R is the set of regions in the currently analyzed function and Ep is \nthe .nite set of program expressions, then the domains are: Index values: i .I = R .{0,...,k,8} Secondary \nvalues: h .H = P(Ep) \u00d7P(Ep) Con.gurations: c .C = I \u00d7H Each index value igives the reference counts for \neach region. We bound the reference counts to a .xed value k, to ensure that the abstraction is .nite. \nFor each region r .dom(i), the number i(r) is the number of references to the tracked location from region \nr: if i(r) . 0..k, then the reference count is exactly i(r); otherwise, if i(r)= 8, the reference count \nis k +1 or greater. In practice, we found a low value k =2 to be precise enough for all of the programs \nthat we experimented with. We emphasize that k is the maximum reference count from each region; however, \nthere can be many more references to the tracked object, as long as they come from different regions. \nFinally, each secondary value h . H is a pair h =(e + ,e -), where e + is the hit set and e - is the \nmiss set. The full shape abstraction consists of a set of con.gurations, with at most one con.guration \nfor each index value. In other words, the abstraction is a partial map from index values to secondary \nvalues. We represent it as a total function that maps the unde.ned indices to a bottom value .: Shape \nabstraction: a.A = I .(H .{.}) We de.ne a lattice domain over the abstract domain, as follows. The bottom \nelement is a. = .i.., meaning that no con.guration is possible. The top element is aT = .i.(\u00d8,\u00d8), meaning \nthat any index is feasible and, for each index, any expression can either ref\u00aderence or fail to reference \nthe tracked location. Given a1,a2 .A, their join a1 Ua2 is: 8 < a1(i) if i.dom(a2) (a1 U a2)(i)= a2(i) \nif i.dom(a1) : a1(i) Ua2(i) if i.dom(a1) ndom(a2) + - + - ++ -- where (e1 ,e ) U(e2 ,e )=(e ne2 ,e ne \n) 1 21 12 + -+ -+ - and .U(e ,e )=(e ,e ) U.=(e ,e ) The merge operator Uis overloaded and applies to \nboth Aand H. {.}; one can infer which operator is being used from its context. We denote by .the partial \norder that corresponds to U. 5.2 Intra-Procedural Analysis We present the data.ow equations, the transfer \nfunctions for as\u00adsignments, malloc, and free, and then give formal results. 5.2.1 Data.ow Equations We \nformulate the analysis of each function in the program as a data.ow analysis that computes a shape abstraction \na .Aat each program point in the function. The algorithm differs from standard approaches in two ways. \nFirst, it uses a system of data.ow equa\u00adtions and a corresponding worklist algorithm that operate at \nthe granularity of individual con.gurations, rather than entire heap ab\u00adstractions (i.e., sets of con.gurations). \nSecond, the data.ow infor\u00admation is being initialized not only at the entry point in the control\u00ad.ow, \nbut also at each allocation site, where the analysis produces a new con.guration for the newly created \nmemory location. Let Sasgn be the set of assignments in the program, and Salloc . Sasgn the set of allocation \nassignments. For each assignment s . Sasgn, we de.ne two program points: sis the program point be\u00adfore \nsand s is the program point after s. Let Sentry .Sasgn be the set of assignments that occur at the beginning \nof the currently analyzed function (i.e., assignments reachable from the function For all s .Sasgn,sa \n.Salloc,se .Sentry ,i.I : F [JOIN] Res( s) i= Res(s ' ) i s'.pred(s) F '' [TRANSF] Res(s ) i= i'.I ([[s]](.,(i,Res( \ns) i ))) i a]]gen [ALLOC] Res(sa ) ia ha, where [[s(.)=(ia,ha) [ENTRY] Res( se) i ao i Figure 8: Intra-procedural \ndata.ow equations. entry point without going through other assignments), and let pred and succ map assignments \nto their predecessor or successor assign\u00adments in the control .ow (these can be easily computed from \nthe syntactic structure of control statements). We model the analysis of individual assignments using \ntransfer functions that operate at the level of individual con.gurations. The transfer function [[s]] \nof a statement s . Sasgn takes the current region abstract store .and a con.guration c .C before the \nstate\u00adment to produce the set of possible con.gurations after the state\u00adment: [[s]](.,c) .A. Furthermore, \nfor each allocation s .Salloc, there is a new con.guration [[s]]gen(.) .C being generated. The result \nof the analysis is a function Res that maps each pro\u00adgram point to the shape abstraction at that point. \nFigure 8 shows the data.ow equations that describe Res. In this .gure, .is the re\u00adgion store for the \ncurrently analyzed function and a0 . A is the boundary data.ow information at the function entry point. \nEqua\u00adtions [JOIN], [TRANSF], and [ENTRY] are standard data.ow equa\u00adtions, but are being expressed such \nthat they expose individual con\u00ad.gurations and their dependencies. Equation [ALLOC] indicates that the \nanalysis always generates a con.guration for the new loca\u00adtion, regardless of the abstraction before \nthe allocation statement. This formulation allows us to build an ef.cient worklist algo\u00adrithm for solving \nthe data.ow equations. Instead of computing transfer functions for entire heap abstractions when the \ninforma\u00adtion at a program point has changed, we only need to recompute it for those indices whose secondary \nvalues have changed. Rather than being entire program statements, worklist elements are state\u00adments paired \nwith indices. Using a worklist with this .ner level of granularity serves to decrease the amount of work \nrequired to .nd the least .xed point. The worklist algorithm is shown in Figure 9. Lines 1-14 perform \nthe initialization: they set the value of Res at entry points (lines 4-7) and at allocation sites (lines \n8-14), and initialize it to a. at all other program points (lines 2-3). The algorithm also initializes \nthe work\u00adlist, at lines 1, 7, and 14. Then, it processes the worklist using the loop between lines 16-22. \nAt each iteration, it removes a statement and an index from the worklist, and applies the transfer function \nof the statement for that particular index. Finally, the algorithm updates the information for all successors, \nbut only for the indices whose secondary values have changed (lines 19-21). Then, it adds the corresponding \npair of successor statement and index value to the worklist, at line 22. 5.2.2 Decision and Stability \nFunctions To simplify the formal de.nition of transfer functions, we in\u00adtroduce several evaluation functions \nfor expressions. First, we use a location evaluation function L[[e]] that evaluates an expression e to \nthe region that holds the location of e. The function is not de\u00ad.ned for expressions that do not represent \nl-values (&#38;e and null). WORKLIST( Data.owInfo a0) 1 W = \u00d8 2 for each s .Sasgn 3 Res( s)= Res( s )= \na. 4 for each se .Sentry 5 Res( se) U= a0 6 for each i such that Res( se) i has changed 7 W = W .{( s, \ni) } 8 for each sa .Salloc 9 let ( ia,ha)=[[ sa]] gen( .) 10 Res( sa ) ia U= ha 11 for each i such that \nRes( sa ) ia has changed 12 for each s .succ( sa) 13 Res( s) i U= Res( sa ) i 14 W = W .{( s, i) } 15 \n16 while ( W is not empty) 17 remove some ( s, i) from W 18 Res( s ) U=[[ s]]( ., ( i, Res( s) i)) 19 \nfor each i ' such that Res( s ) i ' has changed 20 for each s ' .succ( s) ' ) i ' 21 Res( s U= Res( \ns ) i ' 22 W = W .{( s ' ,i ' ) } Figure 9: Intra-procedural worklist algorithm. If . =( .v,.r,.f ) , \nthen: L[[ x]] . = .v( x) L[[ *e]] . = .r( L[[ e]] .) L[[ e.f]] . = .f ( L[[ e]] ., f) Second, we de.ne \na decision evaluation function D[[ e]] that takes a store . and a con.guration c, uses this information \nto deter\u00admine whether e references the location that c tracks: D[[ e]]( ., c) . {+ , -, ? }. The evaluation \nreturns + is e references the tracked location, - if it doesn t, and ? if there is insuf.cient informa\u00adtion \nto make a decision: 8 > - if e .e - .i( L[[ e]] .)=0 > < + -. e = null . e = &#38;x D[[ e]]( ., ( i, \n( e ,e ))) = + > + if e .e > : ? otherwise (the condition i( L[[ e]] .)=0 in the miss case is a shorthand \nfor e = null . e = &#38;e ' . i( L[[ e]] .)=0 ) Finally, we de.ne two stability evaluation functions \nto determine if writing into a region affects the location or the value of an expres\u00adsion. The location \nstability function S[[ e]] l takes an abstract store and a region, and determines whether the location \nof e is stable with respect to updates in that region: S[[ e]]l( ., r) .{true, false}: S[[ x]] l( ., \nr)= true S[[ *e]] l( ., r)= S[[ e]] l( ., r) .L[[ e]] . = r S[[ e.f]] l( ., r)= S[[ e]] l( ., r) The \nvalue stability function S[[ e]] v indicates whether the value of e is stable with respect to updates \nin r. Value stability implies loca\u00adtion stability, but not vice-versa: S[[ null]] v( ., r)= true S[[ \nx]] v( ., r)= .( x)= r S[[ &#38;e]] v( ., r)= S[[ e]] l( ., r) S[[ *e]] v( ., r)= S[[ e]] v( ., r) .L[[ \n*e]] . = r S[[ e.f]] v ( ., r)= S[[ e]] l( ., r) .L[[ e.f]] . = r PROPERTY 1(STABILITY). Given a sound \nabstract store ., an assignment e0 .e1 such that L[[ e0]]( .)= r, a concrete state s before the assignment \nand a concrete state s ' after the assignment, then: for any expression e,if S[[ e]] v( ., r) then e \nevaluates to the same value in stores s and s ' ;  if S[[ e0]] l( ., r) then e0 evaluates in store s \n' to the value that e1 evaluates in store s;  if S[[ e1]] l( ., r) then e1 evaluates to the same value \nin stores s and s ' .  We illustrate the importance of stability with an example. Con\u00adsider two variables: \nx in region rx and y in region ry. Assume that the tracked location is being referenced by y, that the \ntracked location does not have a self reference, and that the program exe\u00adcutes the statements x = &#38;x; \n*x = y. Although we assign y to *x and y is a hit expression, *x will not hit the tracked location after \nthis code fragment. The reason is that *x does not represent the same memory location before and after \nthe statement; the update has caused *x to have different l-values. Our analysis captures this fact by \nidentifying that expression *x is not location-stable with re\u00adspect to updates in region rx. In general, \nif the left-hand side of an assignment is not location-stable, it is not safe to add it to the hit (or \nmiss) set, even if the right-hand side hits (or misses) the tracked location. 5.2.3 Analysis of Assignments: \ne0 .e1 The analysis of assignments plays the central role in the intra\u00adprocedural analysis. Given a con.guration \nc =( i, h) before the assignment, the goal is to compute all of the resulting con.gura\u00adtions after the \nassignment. Given our language syntax, this form of assignment models many particular cases, such as \nnulli.cations (x = null), copy assignments (x = y), load assignments (x = *y or x = y.d), store assignments \n(*x = y or x.d = y), address\u00adof assignments (x = &#38;y), as well as assignments that involve more complex \nexpressions. Our formulation compactly expresses the analysis of all these statements in a single, uni.ed \nframework. Figure 10 shows the algorithm. The analysis must determine whether or not the expressions \ne0 and e1 reference the tracked lo\u00adcation. For this, it invokes the decision function D[[ \u00b7]] on e0 and \ne1. For each of the two expressions, if the decision function can\u00adnot precisely determine if they hit \nor miss the tracked location, it bifurcates the analysis in two directions: one where the expression \nde.nitely references the tracked location, and one where it de.\u00adnitely doesn t. The algorithm adds e0 \nand e1 to the corresponding hit or miss set and analyzes each case using the auxiliary function assign; \nit then merges the outcomes of these cases. The function assign is shown Figure 11 and represents the \ncore of the algorithm. It computes the result con.gurations when the referencing relations of e0 and \ne1 to the tracked location are pre\u00adcisely known, and are given by the boolean parameters b0 and b1, respectively. \nThe algorithm works as follows. First, it evaluates the region r that holds the location being updated, \nusing L[[ e0]] . Then, it updates the reference count from r, between lines 2-8. If e0 references the \nlocation, but e1 doesn t, it decrements the count; if e1 references the location, but e0 doesn t, it \nincrements it; and if none or both reference it, the count remains unchanged. Special care must be taken \nto handle in.nite reference counts; in particular, decrementing in.nite counts yields two possible values, \n8and k. The result is a set Si that contains either one or two indices with the updated reference count(s) \nfor r. Note that the analysis can safely preserve reference counts from all regions other than r, because \nregions model disjoint sets of memory locations. [[eo .e1]](.,(i,(e + ,e -))) : + -+ - case (D[[e0]](.,(i,(e \n,e ))),D[[e1]](.,(i,(e ,e )))) of (v0 .{-,+},v1 .{-,+}) . assign(e0,e1,.,i,e+ ,e - ,v0 =+,v1 =+) (?,v1 \n.{+,-}) . assign(e0,e1,.,i,e+ .{e0},e - ,true,v1 =+) U assign(e0,e1,.,i,e+ ,e - .{e0},false,v1 =+) (v0 \n.{-,+}, ?) . assign(e0,e1,.,i,e+ .{e1},e - ,v0 =+,true) U assign(e0,e1,.,i,e+ ,e - .{e1},v0 =+,false) \n (?, ?) . assign(e0,e1,.,i,e+ .{e0,e1},e - ,true,true) U assign(e0,e1,.,i,e+ .{e0},e - .{e1},true,false) \nU assign(e0,e1,.,i,e+ .{e1},e - .{e0},false,true) U assign(e0,e1,.,i,e+ ,e - .{e0,e1},false,false) Figure \n10: Transfer function for assignments [[e0 .e1]]. Next, the analysis derives new hit and miss sets, using \nthe com\u00adputation between lines 10-20. First, at lines 10 and 11, the analysis .lters out expressions \nwhose referencing relations to the tracked location no longer hold after the update. For instance, the \n.ltered set e - includes from e - only those expressions ethat meet one of n the following two conditions: \n S[[e]]v(.,r): the value of eis stable with respect to the updated region r. In that case, ehas the same \nvalue before and after the assignment, so it remains in e -;  S[[e]]l(.,r) .\u00acb1: the location of e is \nstable with respect to r and the assigned value misses the tracked location (i.e., b1 = false). Hence, \nthe location of e is the same before and after the assignment, but its value may or may not change. If \nthe value doesn t change, e will not reference the tracked location after the assignment because it didn \nt before (e . e -). If the value changes, the location gets overwritten with a value that still doesn \nt reference the tracked location (as indicated by b1 = false). Hence, the analysis can conclude that \nin either case ewill  - not reference the tracked location and can safely keep ein en . At lines 13 \nand 14, the analysis tries to add the left-hand side expression e0 to the hit or miss set. It uses a \nsimilar reasoning as above to determines that e0 is a hit (or miss) expression only if it is location-stable \nand the written value hits (or misses) the tracked location. At lines 16-18, the analysis derives new \nexpressions in e + and e - by substituting occurrences of *e1 with *e0 in expres\u00ad nn sions that do not \ncontain address-of subexpressions. The set Ep ' in this .gure represents all program expression that \ndon t contain the address-of operator. Once again, substitutions are safe only when certain stability \nconditions are met, in this case that e0 and e1 are both location-stable. At line 20, the analysis discards \nfrom the miss set all those ex\u00adpressions whose referencing relations can be inferred by the deci\u00adsion \nfunction using region information alone. This allows the anal\u00adysis to keep smaller miss sets without \nlosing precision. At the end, assign produces one con.guration for each index in Si. We use the following \nnotation: if S is a set of indices and ha secondary value, then (S,h)= .i.I.if (i.S) then helse .. assign(e0,e1,.,i,e+ \n,e -,b0,b1): 1 r = L[[e0]](.) 2 if (b0 .\u00acb1) then 3 if (i(r) =k) then Si . = {i[r .i(r) -1] } 4 else \nSi .. = {i[r .k],i[r .8] }5 else if (\u00acb0 .b1) then 6 if (i(r) <k) then Si . = {i[r .i(r)+1] } 7 else \nSi . = {i[r .8] } 8 else Si = {i} 9 10 e + = {e .e + |S[[e]]v(.,r) . (S[[e]]l(.,r) .b1)} n 11 e - = \n{e.e - |S[[e]]v(.,r) . (S[[e]]l(.,r) .\u00acb1)} n 12 + 13 if (S[[e0]]l(.,r) . b1) then en .= {e0} 14 if (S[[e0]]l(.,r) \n.\u00acb1) then e - .= {e0} n 15 16 if (S[[e0]]l(.,r) .S[[e1]]l(.,r)) then ++ ' 17 e .=( e [*e0/*e1] n E ) \nnn p -- ' 18 en .=( en [*e0/*e1] n Ep ) 19 - -'' 20 e = {e.en |.i .Si .i (L[[e]].)=0} n 21 + - 22 return \n(Si,(en ,en )) Figure 11: Helper function assign. Note that bifurcation can produce up to four cases \nand each case may yield up to two con.gurations. However, there can be at most three resulting con.gurations \nafter each assignment, since we merge con.gurations with the same index, and the reference count from \nthe updated region can only increase by one, decrease by one, or remain unchanged. In the example from \nSection 2 the analy\u00adsis of each statement and con.guration produces either one or two con.gurations. \nFinally, transfer functions map con.gurations with a secondary value of .to bottom abstractions a.. The \nsame is true for all of the other transfer functions in the algorithm. 5.2.4 Analysis of Malloc and \nFree Figure 12 shows the analysis of dynamic allocation and deallo\u00adcation statements. The transfer function \n[[e . malloc]] works as follows. First, the effect of the allocation is equivalent to that of a nulli.cation \n[[e .null]] because the tracked location is guaranteed to be distinct from the fresh location returned \nby malloc (even if it happens to be allocated at the same site). Second, since the con\u00adtents of the fresh \nlocation are not initialized, its .elds become miss expressions provided that eis location-stable. The \ngenerating function [[e .malloc]]gen yields a con.guration (i,c) for the newly created location such \nthat the index i records a reference count of 1 from the region of e and 0 from all other regions. The \nsecondary value h records e as a hit expression, and adds .eld expressions to the miss set if eis stable. \nFinally, the analysis models the transfer function for deallocation statements [[free(e)]] as a sequence \nof assignments that nullify each .eld of the deallocated structure. This ensures that the analysis counts \nreferences only from valid, allocated locations. 5.2.5 Conditional Branches The analysis extracts useful \ninformation from test conditions in if and while statements. On the branch where the tested expression \n[[e .malloc]](., c): a =[[e .null]](., c) if (S[[e]]l(., L[[e]](.))) then e - = {(*e).f |f .F }nEp n \n+ - + - a = {(i, (e ,e - .e )) |ai =(e ,e )} n return a [[e .malloc]]gen(.): r = L[[e]](.) i = .r ' . \nif (r ' = r) then 1 else 0 e - = {(*e).f |f .F }nEp if (S[[e]]l(., r)) then h = {{e},e -} else h = {\u00d8, \n\u00d8}return (i, h) [[free(e)]](., c): a =[[t .*e]](., c)(t fresh) a = U{i.I|ai. =.}[[t.f1 .null]](., (i, \nai)) ... a = U{i.I|ai..null]](., (i, ai)) =.}[[t.fm =.}[[t .null]](., (i, ai)) return a a = U{i.I|ai. \nFigure 12: Analysis of malloc and free. e is null, the analysis determines that e misses the tracked \nlocation. To take advantage of this information, the analysis invokes the de\u00adcision function D[[e]](., \nc). If the returned value is ? , then the analysis adds e to the miss set e -; if the returned value \nis + , then the con.guration is inconsistent with the actual state of the program and the analysis reduces \nthe secondary value to .. The latter case occurs in the example from Section 2, where the condition x \n!= nullallows the analysis to .lter out the con.g\u00aduration X1 after the while loop.  5.3 Formal Framework \nThis section summarizes the formal results for the intra-procedural analysis. The proofs for all of the \ntheorems below are available in a companion technical report [12]. The .rst two theorems provide correctness \nand termination guarantees for the worklist algorithm. THEOREM 1(WORKLIST CORRECTNESS). If transfer func\u00adtions \nmap each con.guration with .secondary value to a., then the worklist algorithm from Figure 9 yields the \nleast .xed point of the system of data.ow equations from Figure 8. THEOREM 2(MONOTONICITY). The transfer \nfunctions [[s]] for assignments, malloc, and free are monotonic in the secondary value: if hh ' , then \n[[s]](., (i, h)) [[s]](., (i, h ' )) for all s, i, .. COROLLARY 1(TERMINATION). The worklist algorithm \nfrom Figure 9 is guaranteed to terminate. We next give soundness conditions and results. Given an abstract \nstore . =(.v,.r,.f ) and a concrete store s =(sv,sl,sf ),we say that a region partial map a : L-R is \n(s, .)-consistent if: range(a) .dom(.r); a(sv(x)) = .v(x), .x .V ; .r(a(l)) = a(sl(l)); and .f (a(l),f)= \na(sf (l, f)) for all the locations l and .elds f where a and s are de.ned. The de.nitions below give \nsoundness conditions for our abstractions. We denote by |S|k the cardinality of a set S if it is less \nor equal to k, and 8otherwise. DEFINITION 1(REGION ABSTRACTION SOUNDNESS). Are\u00adgion abstraction, consisting \nof abstract stores for procedures and mappings for call sites, is sound if for each activation of each \npro\u00adcedure p there exists a region mapping ap : L-Rp such that: p accesses only locations in dom(ap); \n for each concrete store s that occurs during the execution of p, ap is (s, .p)-consistent;  for each \ncall site cs in p that invokes q,if sp is the store before (or after) the call and sq is the store at \nthe entry (or exit) of q, then ap(l)= \u00b5cs(aq (l)), .l .Lsq ndom(aq ).  DEFINITION 2(SHAPE ABSTRACTION \nSOUNDNESS). Let . be a sound region store for an activation of procedure p, and let a be the corresponding \nregion mapping for that activation of p. Let R be the regions of p, and s a concrete store during the \nexecution of p. Denote by Lv = {l|(l, f) .domf (s)}ndom(a) the set of of valid .rst-.eld locations. Then \nc =(i, (e + ,e -)) safely approximates l .Lv, written c s,. l, if: .r .R.i(r)= |{l ' |a(l ' )= r . s(l \n' )= l}|k  .e .e + . (e, s).v v . v = l  .e .e - . (e, s).v v . v = l  A shape abstraction a .A safely \napproximates s, written a . s, if : .l .Lv . .i .I. (i, ai) s,. l. The soundness theorem states that \nshape analysis is sound as long as the underlying region abstraction is sound. THEOREM 3(ANALYSIS SOUNDNESS). \nLet s be a statement in procedure p. Consider two concrete stores s and s ' , a sound region store . \nfor p, and a shape abstraction a .A.If (s, s).s ' and a . s, then: F i.I [[s]](., (i, ai)) . s ' ,if \ns is not a malloc; and F ([[s]]gen(.) U i.I [[s]](., (i, ai))) . s ' ,if s is a malloc. 5.4 Inter-Procedural \nAnalysis We formulate the inter-procedural algorithm as a context-sensitive analysis that distinguishes \nbetween different calling contexts of the same procedure. Again, we take advantage of our abstraction \nand de.ne procedure contexts to be individual con.gurations, not entire heap abstractions. The result \nfor an input con.guration context is a set of corre\u00adsponding output con.gurations at the end of the procedure. \nIf we consider a graph model (such as the one in Figure 5) that describes how the state of the tracked \nlocation changes during execution, we can express the input-ouput relationships for procedure contexts \nas reachability relations: the outputs are those exit con.gurations that are reachable from the input \ncon.guration (the input context). However, we do not need to build the con.guration graph explic\u00aditly; \ninstead, we tag con.gurations with the entry index that they originated from. This separates out con.gurations \nthat originated from different entries, allowing the analysis to quickly determine both the output con.gurations \nfor a given input, and the input con\u00ad.guration for a given output. Formally, we extend the index domain \nin the analysis with the index at entry: Index values: (ic,ie) .Ip = I \u00d7I The entry index ie has no bearing \non the intra-procedural trans\u00adfer functions they simply preserve this value, and operate on the current \nindex ic . The analysis at procedure calls must account for the assignment of actuals to formals and \nfor the change of analysis domain be\u00adtween the caller and the callee. For this, the analysis uses two \nFor all se .Sentry,sc .Scall,i .Ip : [IN]: F Res( se)i ([[sc]]in(., \u00b5sc , (i ' , Res( sc)i ' )))i i ' \n. Ip tgt(sc)=fn(se) [OUT] F Res(sc )i = ([[sc]]out(., \u00b5sc ,(i ' , Res( sc)i ' ), i ' ,i '' .Ip (i '' \n, Res(sx )i '' )))i where sx = exit(tgt(sc)) Figure 13: Additional inter-procedural data.ow equations. \nWORKLIST(Data.owInfo a0) 15 ... 16 while (W is not empty) 17 remove some (s, i) from W 18 if s .Scall \nthen 19 let se = entry(tgt(s)),sx = exit(tgt(s)) 20 Res( se) U=[[s]]in(., \u00b5s, Res( s, i)) 21 for each \ni ' s.th. Res( se)i ' has changed 22 W .= {(se,i ' )} 23 for each i ' s.th. Res(sx )i ' = . 24 Res(s \n) U= [[s]]out 25 (., \u00b5s, Res( s, i), Res( sx,i ' )) 26 else if s .Sexit then 27 for sc,i ' s.th. tgt(sc)= \nfn(s), Res( sc)i ' = . 28 Res(sc ) U= 29 [[sc]]out(., \u00b5sc , Res( sc,i ' ), Res( s, i)) 30 else 31 Res(s \n) U=[[s]](., Res( s, i)) 32 33 for each s ' ,i ' s.th. Res(s ' )i ' has changed 34 for s '' .succ(s ' \n) '' )i ' 35 Res( s U= Res(s ' )i ' 36 W .= {(s '' ,i ' )} Figure 14: Inter-procedural worklist algorithm \ntransfer functions: an input function [[s]]in(., \u00b5s,c) . A which takes a caller con.guration c (before \nthe call) and produces the set of con.gurations at the entry point in the callee; and an output func\u00adtion \n[[s]]out(., \u00b5s,c,c ' ) .A which takes an exit con.guration c ' at the end of the procedure, along with \nthe caller con.guration c that identi.es the calling context, to produce a set of caller con.gura\u00adtions \nafter the call. Both functions require the region store . for the current procedure and the region mapping \n\u00b5s at the call site where the information must be propagated. We express the inter-procedural analysis \nusing a set of data.ow equations that augments the intra-procedural equations from Fig\u00adure 8 with the \ntwo additional equations from Figure 13. We use the following notations: fn(s) . P is the procedure that \nstate\u00adment s belongs to; tgt(sc) . P is the target procedure of a call statement sc; Scall is the set \nof call sites in the program; and entry(p) . Sentry and exit(p) . Sexit are the entry and exit statements \nof procedure p, respectively. Equation [IN] performs the transfer from the caller to the callee; and \n[OUT] transfers the analysis back to the caller. Figure 14 shows the main loop of the inter-procedural \nworklist algorithm; the remainder of the algorithm is unchanged. The algorithm propagates output con.gurations \nto the callers when it encounters new exit con.gurations in the callee, or when it discovers new input \ncontexts in the caller. [[call q(e1, .., en)]]in(., \u00b5, (i, h)) : a =[[p1 .e1]] ... [[pn .en]](., {(i, \nh)}) F return Sin(., \u00b5, (i,a i)) {i | ai.=.} where Sin(., \u00b5, ((ic,ie), (e + ,e -))) : e + = {e .e + |.r \n.range(\u00b5) . S[[e]]v(., r))} q - eq = {e .e - |.r .range(\u00b5) . S[[e]]v(., r))} ieq = .r .Rq .ic(\u00b5r) return \n((ie,ie), (e + -e + ,e - -e -)) qqqq [[call q(e1, .., en)]]out(., \u00b5, ((ic,ie),h), ((icx,iex),hx)) : let \nsc = call q(e1, .., en) if [[sc]]in(., \u00b5, ((ic,ie),h))(iex,iex)= .then return .i.. let (e + ,e -)= h \n + - let (ex ,ex )= hx + eq = {e .e + |.r .range(\u00b5) . S[[e]]v (., r))} e - = {e .e - |.r .range(\u00b5) . \nS[[e]]v (., r))} q icq = .r .Rq . if (r .range(\u00b5)) then ic(r) else icx(\u00b5 -1(r)) ++ -- return ((icq,ie), \n(ex .eq ,ex .eq )) Figure 15: Inter-procedural transfer functions. Figure 15 shows the input and output \ntransfer functions. The entry transfer function accomplishes two things. First, it performs the assignments \nof actual to formal arguments, which may gener\u00adate new references to the tracked location. Second, it \nadjusts the regions of existing references according to the call site map \u00b5. Ref\u00aderences whose regions \nare not in the range of \u00b5 are not visible by the callee and are discarded by the slicing function Sin. \nThe exit transfer function performs the reversed tasks. First, it accounts for context-sensitivity using \nthe if statement at the beginning: it checks if the exit con.guration in the caller originates from the \ninput con\u00adtext ((ic,ie),h) before the call. If so, it restores the hit and miss expressions discarded \nat entry and adjusts the region counts.  6. EXTENSIONS We present two extensions: incremental computation \nof shapes, and detection of memory errors. 6.1 On-Demand and Incremental Analyses The goal of a demand-driven \nanalysis is to analyze a selected set of dynamic structures in the program, created at a one or a few \nallocation sites. In our framework, this can be achieved with mini\u00admal effort: we just apply the data.ow \nequation [ALLOC] from Fig\u00adure 8 to the selected allocation sites. The effect is that the data.ow information \ngets seeded just at those sites, and the worklist algo\u00adrithm will automatically propagate that information \nthrough the program. In particular, the inter-procedural analysis will propagate shape information from \nprocedures that contain these allocations out to their callers. Our analysis framework also enables the \nincremental compu\u00adtation of shapes. To explore new allocation sites, we seed the data.ow information \nat the new sites, initialize the worklist to con\u00adtain successors of those allocations, and then run the \nworklist algo\u00adrithm. Key to the incremental computation is that our abstraction based on con.gurations \nallows the analysis to reuse results from previously analyzed allocation sites. This is possible both \nat the intra-procedural level, when the new con.gurations match exist\u00ading con.gurations at particular \nprogram points; and at the inter\u00adprocedural level, when new calling contexts match existing con\u00adtexts. \n 6.2 Memory Error Detection We extend our analysis algorithm to enable the static detection of memory \nerrors such as memory accessed through dangling point\u00aders, memory leaks, or multiple frees. To detect \nsuch errors, we enrich the index with a .ag indicating whether the tracked cell has been freed: Index \nvalues: if .If = {true,false}\u00d7I Since this information is in the index, for any con.guration we know \nprecisely whether or not the cell has been freed. Most of the transfer functions leave this .ag unchanged; \nand since merging con.gurations does not combine different index values (as before), there is no merging \nof .ags. Only two more changes are required in the analysis. First, after the initial allocation this \n.ag is false: [[e .malloc]]gen f (.)=((false,ia),ha) Second, we must change the transfer function for \nfree statements, since the allocation state of the tracked cell may change at these points. We express \nthe modi.ed transfer function for free using the original one, which preserves the allocation .ag, and \nusing the decision function to determine whether the freed location is the one being tracked or not: \n[[free(e)]]f (.,((f,i),h)) = case (D[[e]](.,c)) of - . [[free(e)]] (.,((f,i),h)) + . [[free(e)]] (.,((true,i),h)) \n? . [[free(e)]] (.,((f,i),h)) U [[free(e)]] (.,((true,i),h)) With these additions, the analysis can \nproceed to detect errors. To identify memory leaks, it checks if there are no incoming refer\u00adences to \na cell, but the cell was never freed. While a con.guration with no incoming references means there are \nno pointers to the cell from regions that are in scope, this does not mean that functions further up \nthe call stack do not still have pointers to the cell. To be sure that none of these functions have pointers \nto the tracked cell, the cell must not have been allocated at entry to the function. We classify memory \nleaks as con.gurations ((false,.r.0),h) that are not reachable from the boundary con.gurations in a0.How\u00adever, \nleak detection suffers from the standard problem of reference counting, that it cannot detect leaked \ncycles. To detect double frees, the analysis performs the following check. For any statement s = free(e),if \n((true,i),h) . Res( s) and D[[e]](.,(i,h)) = - , a possible double free has occurred. And to identify \naccesses to deallocated memory the analysis checks the following. For any statement s, de.ne Es as the \nset of expressions that are dereferenced by s: {e|*eappears in s}.If ((true,i),h) . Res( s) and D[[e]](.,(i,h)) \n= - for any e.Es, a possible ref\u00aderence to deallocated memory has occurred.  7. LIMITATIONS The analysis \nalgorithm presented in this paper has the following limitations: Spurious con.gurations. The analysis \nmay generate spurious con.gurations, but still determine the correct .nal shape in spite of this imprecision. \nIn the example from Figure 5, con\u00ad.gurations Y1T1L1 and X1Y1L1 are spurious. Ruling such cases requires \nmore complex decision functions D[[\u00b7]]. Complex structural invariants. For manipulations of linked structures \nwith complex invariants, our algorithm may not identify the correct shape. For example, our algorithm \ncan\u00adnot determine that shapes are preserved for operations on doubly-linked lists, because our con.gurations \ncannot record the doubly-linked list invariant.  Robustness. The analysis may not identify the correct \nshape when the same program is written in a different manner. In the example program from Section 2, \nif we replace state\u00adment x=t->n with x=x->n, the algorithm will not verify the shape property. This is \nbecause the analysis does not know that x=tat that point, and cannot add t->nto the hit or miss set. \nTo address this issue, the analysis needs expres\u00adsion equality information.  Worst-case exponential \nblowup. Similar to most of the exist\u00ading shape abstractions, the size of our abstraction is exponen\u00adtial \nin the worst case. In practice, we have seen cases where a blowup in the number of con.guration occurs, \nbut only be\u00adcause of the imprecision in the analysis, e.g., for traversals of doubly-linked lists with \nmultiple pointers.  However, we believe that these are limitations of the current al\u00adgorithm, but not \nof the framework with local reasoning. We antici\u00adpate these issues can be addressed by extending the \nabstraction and the algorithm, while still reasoning about one single location. For instance, the decision \nfunction could be improved to rule out spuri\u00adous con.gurations; an expression equality analysis could \nbe added as an underlying analysis in the vertical decomposition to address the robustness issue; and \ncon.gurations could be extended with reachability information and structural invariants about the tracked \nlocation. We chose to keep the algorithm in this paper simpler and cleaner to emphasize the concept and \nto make it amenable to for\u00admal presentation. These issues will be the subject of future work. 8. RESULTS \nWe have implemented all of the algorithms presented in the pa\u00adper, including the points-to analysis, \nshape analysis, and extensions for detecting memory errors, using the SUIF Compiler infrastruc\u00adture [1]. \nWe have extended the analysis to handle various C con\u00adstructs, such as arrays, pointer arithmetic, casts, \nunions, and others. The points-to analysis makes the usual assumptions, e.g., that array accesses and \npointer arithmetic do not violate the array or structure bounds. Our shape analysis is guaranteed to \nbe sound as long as the underlying region abstraction computed by the points-to analysis is sound. We \nhave tested our prototype implementation on several small examples and on a few larger C programs. To \nexperiment with the demand-driven and incremental approach, our system an\u00adalyzes one allocation site \nat a time, reusing existing results as new sites are explored. The experiments were conducted on a 1.2GHz \nAthlon machine with 256MB of memory, running Linux RedHat 9. 8.1 Core List Manipulations We have tested \nthe analysis on the following programs that ma\u00adnipulate singly-linked lists: insert: inserts an element \ninto a list;  delete: deletes an element from a list;  splice: list splicing program from Section 2; \n reverse: iterative list reversal program from [8];  quicksort: recursive quicksort program from [5]; \n insertion sort: iterative insertion sort.  The analysis has successfully determined that all of these \npro\u00adgrams preserve acyclic list shape. It has also determined that none of the programs leak memory or \naccess deallocated memory. The analysis took less than 1 second for these programs altogether. 8.2 Experience \non Larger Programs We have also used the analysis to detect memory leaks in por\u00adtions of three popular \nC programs: OpenSSH, OpenSSL, and BinU\u00adtils. The results of these experiments are shown in Figure 16. \nIn total, we analyzed 184 dynamic allocation sites in about 70 KLOC, taking less than two minutes. This \nproduced 97 warnings, 38 of which were actual memory leaks (a few warnings were for double frees and \naccesses to deallocated memory, all of which were false). Hence, more than one warning out of three was \nan actual error. Given that the tool uses sound analysis techniques, we view this as a low rate of false \npositives. The error reporting is based on error traces. An error trace repre\u00adsents an execution trace \nthrough the program that leads to an error. The tool produces these traces by following the program execution \nbackwards through the con.guration graph, from the error point to the allocation site; we .nd the traces \nto be extremely helpful in identifying whether a warning is legitimate. Furthermore, the tool clusters \nerror traces on a per-region basis: all of traces in one clus\u00adter refer to errors about locations in \nthe same region. The tool then reports one warning per cluster. We .nd this clustering technique very \nuseful in identifying distinct bugs, since all of the errors in one cluster essentially refer to the \nsame programming error. For our programs, the majority of clusters have a single trace; a few clusters \nhave less than 10 traces; and one cluster has more than 100 error traces. As mentioned above, all of \nthe detected errors were memory leaks. Most of them were caused as functions failed to clean up local \nresources on abnormal return paths. For instance, some func\u00adtions in SSH do not reclaim memory when a \nconnection fails. In a few cases, however, functions failed to release resources on all return paths. \nThe examination of false warnings indicated that they were due to several sources of imprecision. Many \nof the errors were due to lack of path information that could have been used to rule out the error trace. \nFor instance, we are unable to track the correla\u00adtion between the references to the tracked cell and \nthe values of various error codes in the program. False warnings were also due to the context-insensitive \ntreatment of global variables in pointer analysis. For instance, one of the programs stores references \nto several buffers (stdin, stout, and stderr) into global variables. Since these references are being \npassed as the same argument to a func\u00adtion, pointer analysis merges them together. This imprecision in \nthe pointer analysis then impacts the precision of shape analysis. The above-mentioned cluster with more \nthan 100 error traces was due to this kind of imprecision. The tool was most affected when the analysis \ncould not accu\u00adrately identify shapes, as in the case of doubly-linked lists or for heap manipulations \nwhere it lacked variable equality information, as mentioned in Section 7. This lead to a blowup in the \nnumber of feasible con.gurations and the analysis failed to complete in such cases. However, we are able \nto isolate these situations using in\u00adcremental analysis: we explored one allocation site at a time and \nintroduced a cutoff for the amount of exploration to be performed from any given allocation site (by \nlimiting the size of the work\u00adlist). Figure 16 indicates that the analysis did not complete for 3 allocation \nsites in SSL and 10 sites in Binutils due to this kind of imprecision. They represent about 10% of the \nallocation sites in these programs. Program OpenSSH OpenSSL BinUtils Size (LOC) 18.6 K 25.6 K 24.4 K \nAlloc. Sites 41 31 125 Analyzed 41 28 115 Total Time (sec) 45s 22s 44s Region Analysis 16s 13s 6s Shape \nAnalysis 29s 9s 38s Reported 26 13 58 Real bugs 10 4 24 Figure 16: Results for Larger Programs Overall, \nwe consider that these results are encouraging. They suggest that the local reasoning approach to shape \nanalysis is both suf.ciently lightweight to scale to larger programs, and suf.ciently precise to yield \na low rate of false warnings. 9. RELATED WORK There has been signi.cant work in the past decade in the \narea of shape analysis [34]. Early approaches to shape analysis have proposed the use of path matrices \nand other matrices that capture heap reachability information [18, 17, 11]. In particular, Ghiya and \nHendren [11] present an inter-procedural shape analysis that uses boolean matrices to identify trees, \ndags, or cyclic graphs. Their implemented system has been successful at analyzing programs of up to 3 \nKLOC. Sagiv et. al. present an abstract interpretation that uses shape graphs to model heap structures \n[29]. They introduce materializa\u00adtion and summarization as key techniques for the precise compu\u00adtation \nof shapes. Role analysis [21] uses shape graph abstractions to check program speci.cations for heap shapes \nand heap effects. Experiments have not been presented for these analyses. In subsequent work, Sagiv et. \nal. have proposed a parametric shape analysis framework based on 3-valued logic [31]. They en\u00adcode shape \ngraphs as 3-valued structures and use a focus opera\u00adtion to accurately compute shapes when the analysis \nencounters unknown (1/2) logic values. Our bifurcation technique is similar to their focus operation, \nbut applies to a different analysis abstrac\u00adtion. The 3-valued logic approach has been implemented in \nthe TVLA system [23] and has been successful at verifying correctness and safety properties for complex \nheap manipulations [22, 8, 35]. Work on inter-procedural analysis in TVLA has explored modeling the program \nstack using 3-valued structures [28] and expressing the function input-output relations for individual \nheap cells [20]. These analyses seem expensive in practice; for instance, the analysis of a recursive \nprocedure that deletes an element from a list takes more than 200 seconds [20]. Yahav and Ramalingam \n[36] have proposed heterogeneous heap abstractions as a means of speeding up analyses in TVLA. Their \nframework constructs a heap abstraction that models different parts of the heap with different degrees \nof precision, and keeps precise information just for the relevant portion of the heap. In contrast, our \napproach is homogeneous, precisely abstracts the entire heap, but models each heap location separately. \nTheir approach enabled TVLA to analyze programs of up to 1.3 KLOC. Reynolds, O Hearn, and others propose \nSeparation logic [27, 26] and BI (the logic of Bunched Implications) [19] as extensions of Hoare logic \nthat permit reasoning about mutable linked struc\u00adtures. They provide features (such as the separating \nconjunction and implication, or the frame rule) that make it easier to express correctness proofs for \npointer-based programs. Compared to static analyses, these logics provide techniques for verifying program \ncor\u00adrectness; analyses, on the other hand, provide techniques for auto\u00admatically inferring points-to \nproperties. A signi.cant challenge for static analysis is the automatic synthesis of loop invariants. \nGen\u00aderally speaking, inferring points-to properties is more dif.cult than verifying them. Therefore, \nalthough separation logic works well for correctness proofs with local reasoning, it is not clear whether \nan analysis can use local reasoning alone. In our system, we push global reasoning down to the pointer \nanalysis component; and that enables us to use local reasoning at the shape analysis level. Fur\u00adthermore, \nwe use a .nite shape abstraction that localizes the rea\u00adsoning to one single heap location. Demand-driven \nand incremental algorithm have been proposed in the area of pointer analysis. Heintze and Tardieu [16] \ndescribe a technique to answer aliasing queries by exploring the minimal set of points-to constraints \nthat yields the desired answer. Vivien and Rinard [33] present an incremental points-to analysis that \ngradually explores more code to re.ne the points-to information. Our notion of demand-driven and incremental \nanalysis is different it refers to the number of explored allocation sites. Heine and Lam present Clouseau \n[15], a static leak detector tool for C and C++ programs. They use a notion of pointer ownership to describe \nthe references responsible for freeing heap cells, and formulate the analysis as an ownership constraint \nsystem. Their approach is able to detect leaks and double frees, but cannot de\u00adtect accesses through \ndangling pointers. Intuitively, that is because their system tracks owning pointers (and doesn t have \ninformation about targets of non-owning pointers), while ours tracks memory locations and their allocation \nstate. The experiments indicate that our shape analysis approach yields more precise results than the \npointer ownership approach. In particular, Clouseau reports a large number of warnings when the program \nplaces pointers in aggregate structures, or when it manipulates multi-level pointers. Das et. al. present \nESP [6], a path-sensitive tool for verifying state machine properties. ESP uses property simulation, \na tech\u00adnique that captures path information but avoids the exponential cost of a full path-sensitive \nanalysis. We borrow from ESP the notion of index values in the abstraction to model critical information \nthat the analysis must not merge at join points. However, ESP is de\u00adsigned to analyze temporal properties \nfor non-recursive structures, not shapes in recursive heap structures. DeLine and Fahndrich pro\u00adpose \nVault [7], an extension of C where programmers can specify resource management protocols that a compiler \ncan enforce. The system can ensure, for instance, that the program doesn t leak re\u00adsources. But it cannot \nprecisely track unbounded numbers of re\u00adsources such as those that arise in recursive structures. The \nSLAM Project [2, 3] uses predicate abstraction re.nement along with model checking techniques to check \ntemporal safety properties of C programs. Necula et al. propose CCured [25], a an analysis and transformation \nsystem for C programs that uses type inference to identify type-safe pointers, and instrument the re\u00admaining \npointers with run-time checks. However, CCured does not address the memory deallocation problem and uses \na garbage col\u00adlector instead. Other existing error-detection tools, such as Metal [9] and Pre\u00ad.x[4], \nuse unsound techniques to limit the number of false positives or to avoid .xed-point computations. Finally, \ndynamic memory error detection tools such as Purify [13] or SWAT [14] instrument the program to detect \nerrors at run-time. They test only one run of the program and may miss errors that are not exposed in \nthat run; in particular, they may miss errors in rarely executed code fragments. 10. CONCLUSIONS We have \npresented a new approach to shape analysis where the compiler uses local reasoning about the state of \none single heap location, as opposed to global reasoning about entire heap abstrac\u00adtions. We have showed \nthat this approach makes it easier to develop ef.cient intra-procedural analysis algorithms, context-sensitive \ninter\u00adprocedural algorithms, demand-driven and incremental analyses, and can enable the detection of \nmemory errors with low false pos\u00aditive rates. We believe that the proposed approach brings shape analysis \na step closer to being successful for real-world programs. 11. REFERENCES [1] S. Amarasinghe, J. Anderson, \nM. Lam, and C. Tseng. The SUIF compiler for scalable parallel machines. In Proceedings of the Eighth \nSIAM Conference on Parallel Processing for Scienti.c Computing, San Francisco, CA, February 1995. [2] \nT. Ball, R. Majumdar, T. Millstein, and S. Rajamani. Automatic predicate abstraction of C programs. In \nProceedings of the SIGPLAN 01 Conference on Program Language Design and Implementation, Snowbird, UT, \nJune 2001. [3] T. Ball and S. Rajamani. The SLAM project: Debugging system software via static analysis. \nIn Proceedings of the 29th Annual ACM Symposium on the Principles of Programming Languages, Portland, \nOR, January 2002. [4] W. Bush, J. Pincus, and D. Sielaff. A static analyzer for .nding dynamic programming \nerrors. Software Practice and Experience, 30(7):775 802, August 2000. [5] S. Chong and R. Rugina. Static \nanalysis of accessed regions in recursive data structures. In Proceedings of the 10th International Static \nAnalysis Symposium, San Diego, CA, June 2003. [6] M. Das, S. Lerner, and M. Seigle. ESP: Path-sensitive \nprogram veri.cation in polynomial time. In Proceedings of the SIGPLAN 02 Conference on Program Language \nDesign and Implementation, Berlin, Germany, June 2002. [7] R. DeLine and M. Fahndrich. Enforcing high-level \nprotocols in low-level software. In Proceedings of the SIGPLAN 01 Conference on Program Language Design \nand Implementation, Snowbird, UT, June 2001. [8] N. Dor, M. Rodeh, and M. Sagiv. Checking cleanness \nin linked lists. In Proceedings of the 7th International Static Analysis Symposium, Santa Barbara, CA, \nJuly 2000. [9] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking system rules using system-speci.c, \nprogrammer-written compiler extensions. In Proceedings of the SIGPLAN 02 Conference on Program Language \nDesign and Implementation, Berlin, Germany, June 2002. [10] M. Fahndrich, J. Rehof, and M. Das. Scalable \ncontext-sensitive .ow analysis using instantiation constraints. In Proceedings of the SIGPLAN 00 Conference \non Program Language Design and Implementation, Vancouver, Canada, June 2000. [11] R. Ghiya and L. Hendren. \nIs is a tree, a DAG or a cyclic graph? a shape analysis for heap-directed pointers in C. In Proceedings \nof the 23rd Annual ACM Symposium on the Principles of Programming Languages, St. Petersburg Beach, FL, \nJanuary 1996. [12] B. Hackett and R. Rugina. Region-based shape analysis with tracked locations. Technical \nReport TR2004-1968, Cornell University, October 2004. [13] R. Hastings and B. Joyce. Purify: Fast detection \nof memory leaks and access errors. In Proceedings of the 1992 Winter Usenix Conference, January 1992. \n[14] M. Hauswirth and T. Chilimbi. Low-overhead memory leak detection using adaptive statistical pro.ling. \nIn Proceedings of the 11th International Conference on Architectural Support for Programming Languages \nand Operating Systems, Boston, MA, October 2004. [15] D. Heine and M. Lam. A practical .ow-sensitive \nand context-sensitive C and C++ memory leak detector. In Proceedings of the SIGPLAN 03 Conference on \nProgram Language Design and Implementation, San Diego, CA, June 2003. [16] N. Heintze and O. Tardieu. \nDemand-driven pointer analysis. In Proceedings of the SIGPLAN 01 Conference on Program Language Design \nand Implementation, Snowbird, UT, June 2001. [17] L. Hendren, J. Hummel, and A. Nicolau. A general data \ndependence test for dynamic, pointer-based data structures. In Proceedings of the SIGPLAN 94 Conference \non Program Language Design and Implementation, Orlando, FL, June 1994. [18] L. Hendren and A. Nicolau. \nParallelizing programs with recursive data structures. IEEE Transactions on Parallel and Distributed \nSystems, 1(1):35 47, January 1990. [19] S. Ishtiaq and P. O Hearn. BI as an assertion language for mutable \ndata structures. In Proceedings of the 28th Annual ACM Symposium on the Principles of Programming Languages, \nLondon, UK, January 2001. [20] B. Jeannet, A. Loginov, T. Reps, and M. Sagiv. A relational approach to \ninterprocedural shape analysis. In Proceedings of the 11th International Static Analysis Symposium, Verona, \nItaly, August 2004. [21] V. Kuncak, P. Lam, and M. Rinard. Role analysis. In Proceedings of the 29th \nAnnual ACM Symposium on the Principles of Programming Languages, Portland, OR, January 2002. [22] T. \nLev-ami, T. Reps, M. Sagiv, and R. Wilhelm. Putting static analysis to work for veri.cation: A case study. \nIn 2000 International Symposium on Software Testing and Analysis, August 2000. [23] T. Lev-Ami and M. \nSagiv. TVLA: A system for implementing static analyses. In Proceedings of the 7th International Static \nAnalysis Symposium, Santa Barbara, CA, July 2000. [24] D. Liang and M.J. Harrold. Ef.cient points-to \nanalysis for whole-program analysis. In Proceedings of the ACM SIGSOFT 99 Symposium on the Foundations \nof Software Engineering, Toulouse,France, September 1999. [25] G. Necula, S. McPeak, and W. Weimer. CCured: \ntype-safe retro.tting of legacy code. In Proceedings of the 29th Annual ACM Symposium on the Principles \nof Programming Languages, Portland, OR, January 2002. [26] P. O Hearn, H. Yang, and J. Reynolds. Separation \nand information hiding. In Proceedings of the 31th Annual ACM Symposium on the Principles of Programming \nLanguages, Venice, Italy, January 2004. [27] J. Reynolds. Separation logic: A logic for shared mutable \ndata structures. In Proceedings of the Seventeenth Annual IEEE Symposium on Logic in Computer Science, \nCopenhagen, Denmark, July 2002. [28] N. Rinetzky and M. Sagiv. Interprocedural shape analysis for recursive \nprograms. In Proceedings of the 2001 International Conference on Compiler Construction, Genova, Italy, \nApril 2001. [29] M. Sagiv, T. Reps, and R. Wilhelm. Solving shape-analysis problems in languages with \ndestructive updating. ACM Transactions on Programming Languages and Systems, 20(1):1 50, January 1998. \n[30] M. Sagiv, T. Reps, and R. Wilhelm. Parametric shape analysis via 3-valued logic. In Proceedings \nof the 26th Annual ACM Symposium on the Principles of Programming Languages, San Antonio, TX, January \n1999. [31] M. Sagiv, T. Reps, and R. Wilhelm. Parametric shape analysis via 3-valued logic. ACM Transactions \non Programming Languages and Systems, 24(3), May 2002. [32] Bjarne Steensgaard. Points-to analysis in \nalmost linear time. In Proceedings of the 23rd Annual ACM Symposium on the Principles of Programming \nLanguages, St. Petersburg Beach, FL, January 1996. [33] F. Vivien and M. Rinard. Incrementalized pointer \nand escape analysis. In Proceedings of the SIGPLAN 01 Conference on Program Language Design and Implementation, \nSnowbird, UT, June 2001. [34] R. Wilhelm, M. Sagiv, and T. Reps. Shape analysis. In Proceedings of the \n2000 International Conference on Compiler Construction, Berlin, Germany, April 2000. [35] E. Yahav. Verifying \nsafety properties of concurrent Java programs using 3-valued logic. In Proceedings of the 28th Annual \nACM Symposium on the Principles of Programming Languages, London, UK, January 2001. [36] E. Yahav and \nG. Ramalingam. Verifying safety properties using separation and heterogeneous abstractions. In Proceedings \nof the SIGPLAN 04 Conference on Program Language Design and Implementation, Washington, DC, June 2004. \nAPPENDIX  A. LANGUAGE SEMANTICS The operational semantics of the simple language from Figure 7 uses \nthe following semantic domains: locations: l .L values: stores: v .L .{null}s =(sv,sl,sf ).(V .L)\u00d7 (L-(L \n.{null}))\u00d7 ((L \u00d7F )-L) The following rules describe the evaluation of expressions. Re\u00adlation (e, s).l \nl evaluates e in store s to the location l of e; and relation (e, s).v v evaluates e in store s to the \nvalue v of e. Given a concrete store s =(sv,sl,sf ), we use the nota\u00adtions: domv(s)=dom(sv), doml(s)=dom(sl), \nand domf (s)= dom(sf ). The evaluation rules are as follows. x .domv(s) (e, s).l l .doml(s) s(l)=l ' \n(x, s).l s(x) (*e, s).l l ' (e, s).l l (l, f).domf (s) (e, s).l l .doml(s) (e.f, s).l s(l, f) (e, s).v \ns(l) (e, s).l l (&#38;e, s).v l (null,s).v null The evaluation relation for statements (s, s).s s ' indicates \nthat the execution of statement s in input store s produces the store s ' . The evaluation rules are \nas follows: (e, s).l l .doml(s) {lf }f.F fresh s ' =s[l ..f.F [(lf1 ,f).lf ] .lf1 ][lf .null].f.F (e \n.malloc,s).s s ' (e, s).v l .f .F :(l, f).domf (s) s ' =(s -{(l, f). .}f.F )-{. s(l, f).}f.F (free(e),s).s \ns ' (e0,s).l l .doml(s) (e1,s).v v (e0 .e1,s).. s s[l .u] prog(f)=((x1, .., xn),s) .i =1..n : (ei,s).v \nvi (s, s[s(xi)..vi]i=1..n).s s ' (call p(e1, .., en),s).s s ' (s0,s).s s '' (s1,s '' ).s s ' (s0 ;s1,s).s \ns ' (e, s).v v =null (s0,s).s s ' (if (e)s0 else s1,s).s s ' (e, s).v v =null (s1,s).s s ' (if (e)s0 \nelse s1,s).s s ' (e, s).v v =null s s '' (s, s).(e, s).v v =null (while (e)s, s '' ).s s ' (while (e)s, \ns).s s (while (e)s, s).s s '    \n\t\t\t", "proc_id": "1040305", "abstract": "This paper proposes a novel approach to shape analysis: using local reasoning about individual heap locations instead of global reasoning about entire heap abstractions. We present an inter-procedural shape analysis algorithm for languages with destructive updates. The key feature is a novel memory abstraction that differs from traditional abstractions in two ways. First, we build the shape abstraction and analysis on top of a pointer analysis. Second, we decompose the shape abstraction into a set of independent configurations, each of which characterizes one single heap location. Our approach: 1) leads to simpler algorithm specifications, because of local reasoning about the single location; 2) leads to efficient algorithms, because of the smaller granularity of the abstraction; and 3) makes it easier to develop context-sensitive, demand-driven, and incremental shape analyses.We also show that the analysis can be used to enable the static detection of memory errors in programs with explicit deallocation. We have built a prototype tool that detects memory leaks and accesses through dangling pointers in C programs. The experiments indicate that the analysis is sufficiently precise to detect errors with low false positive rates; and is sufficiently lightweight to scale to larger programs. For a set of three popular C programs, the tool has analyzed about 70K lines of code in less than 2 minutes and has produced 97 warnings, 38 of which were actual errors.", "authors": [{"name": "Brian Hackett", "author_profile_id": "81320490544", "affiliation": "Cornell University, Ithaca, NY", "person_id": "PP14013402", "email_address": "", "orcid_id": ""}, {"name": "Radu Rugina", "author_profile_id": "81100094619", "affiliation": "Cornell University, Ithaca, NY", "person_id": "P237448", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1040305.1040331", "year": "2005", "article_id": "1040331", "conference": "POPL", "title": "Region-based shape analysis with tracked locations", "url": "http://dl.acm.org/citation.cfm?id=1040331"}