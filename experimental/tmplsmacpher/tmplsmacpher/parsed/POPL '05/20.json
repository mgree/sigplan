{"article_publication_date": "01-12-2005", "fulltext": "\n Separation Logic and Abstraction Matthew Parkinson University of Cambridge Computer Laboratory Cambridge \nCB3 0FD, UK mjp41@cl.cam.ac.uk ABSTRACT In this paper we address the problem of writing speci.cations \nfor programs that use various forms of modularity, including proce\u00addures and Java-like classes. We build \non the formalism of sepa\u00adration logic and introduce the new notion of an abstract predicate and, more \ngenerally, abstract predicate families. This provides a .exible mechanism for reasoning about the different \nforms of ab\u00adstraction found in modern programming languages, such as abstract datatypes and objects. \nAs well as demonstrating the soundness of our proof system, we illustrate its utility with a series of \nexamples. Categories and Subject Descriptors D.2.4 [Software Engineering]: Program Veri.cation class \nin\u00advariants; D.3.3 [Programming Languages]: Language Constructs and Features Modules, packages; D.3.3 \n[Programming Langua\u00adges]: Language Constructs and Features Classes and inheritance General Terms Languages, \nTheory, Veri.cation  Keywords Separation Logic, Modularity, Resources, Abstract data types, Class\u00ades \n1. INTRODUCTION In order to assist programmers in building complex software sys\u00adtems, programming languages \noffer various forms of abstraction. In this paper we focus on those that provide some form of modular\u00adity. \nThese range from simple procedures with local state, through abstract datatypes (ADTs), to the complexities \nof Java-like class hi\u00aderarchies with method overriding and runtime resolution of method invocation. Our \naim is to provide intuitive ways for programmers to specify the behaviour of their modular code. Previous \nsolutions to handling modularity are either too weak, in that certain natural speci.cations can not be \nexpressed; or too strong, in that the programmer is forced to accept an unreasonable proof or annotation \nburden. Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n05, January 12 14, 2005, Long Beach, California, USA. Copyright 2005 ACM 1-58113-830-X/05/0001 ...$5.00. \nGavin Bierman Microsoft Research 7 J J Thomson Ave Cambridge CB3 0FB, UK gmb@microsoft.com We choose \nto build upon the recent formalism of separation logic, which facilitates local reasoning about code \n[23]. This local reason\u00ading approach has proved successful when considering many real world algorithms, \nincluding the Schorr-Waite graph marking al\u00adrithm [31] and a copying garbage collector [4]. Until recently, \nthe work on separation logic has focused exclu\u00adsively on low-level C-like languages with no support for \nabstrac\u00adtion. O Hearn, Reynolds and Yang [22] have recently added static modularity to separation logic. \nThey hide the internal resources of a module from its clients using the so called hypothetical frame \nrule. This partitioning of resources between the client and the module allows them to model ownership \ntransfer , where state can safely be transferred between the module and the client without fear of dereferencing \ndangling pointers. This allows them to reason about examples such as a simple memory manager, which allocates \n.xed size blocks of memory, and a queue. Though this is a signi.cant advance, their work is severely \nlim\u00adited as it only models static modularity. Their modules are based on Parnas work on information hiding \n[25], which deals with single instances of the hidden data structure. Hence, it can not be used for many \ncommon forms of abstraction, including ADTs and classes, where we require multiple instances of the hidden \nresource. For example, one would expect, given a list module, to use multiple lists in an application; \nand one frequently creates new objects in object-oriented applications. Let us review the problem: take \na piece of code that we wish to consider abstract (this could be because the code is a procedure, a module \nor a method). A speci.cation is then a contract between the code and its callers. It includes a precondition \nthat expresses what a caller must establish before the code may be executed. The implementation of the \nmodule can assume the precondition on en\u00adtry. A speci.cation also contains a postcondition that records \nwhat must hold upon exit of the module. Consequently the caller can assume the postcondition upon return \nfrom the module. When rea\u00adsoning about the module and the calls, only the contract given by the speci.cation \nis used: that is, we expect the appropriate form of information hiding. Various researchers have proposed \nenriching the logic to view the data abstractly (as in data groups [14]), or the methods/proce\u00addures \nabstractly (as in method groups [30, 13]). In contrast, we propose to add the abstraction to the logical \nframework itself, by introducing the notion of an abstract predicate. An abstract pred\u00adicate has a name, \na de.nition, and a scope. Within the scope one can freely swap between using the abstract predicate s \nname and its de.nition, but outside its scope it must be handled atomically, i.e. by its name. Thus the \nscope de.nes the abstraction boundary for the abstract predicate. In various work on separation logic \n(e.g. [29]) it is common to use inductively de.ned predicates to represent data types. In essence we \nallow predicates to additionally encapsulate state and not just represent it. This gives us two key advantages: \n(1) the impact of changing a predicate is easy to de.ne; and (2) by encap\u00adsulating state we are able \nto reason about ownership transfer. Whilst the notion of abstract predicates is suf.cient to reason about \nmodules and simple ADTs, we should like to reason about object-oriented forms of abstractions; more precisely \nJava-like class\u00ades and inheritance. This adds an additional complication: not only do we have to reason \nabout encapsulation but also inheritance. Rath\u00ader pleasingly this again can be provided by re.ecting \nthe abstrac\u00adtion in the logical framework itself. Here the key observation is that an object can exist \nat multiple types through the class hierar\u00adchy. We re.ect this in the logic by generalising abstract \npredicates to families of abstract predicates that are indexed by class. The rest of the paper is structured \nas follows. In \u00a72we givea brief overview of separation logic, detailing the features that we use in this \npaper. In \u00a73 we present more formally the notion of an abstract predicate, giving proof rules and outlining \na soundness proof. We also give a number of worked examples. In \u00a74weex\u00adtend these reasoning principles \nto a core subset of Java. Again we outline a soundness proof and give examples. We conclude in \u00a75 with \na comparison to related work and propose some future work. 2. SEPARATION LOGIC PRIMER In this section \nwe give some brief details of the fragment of sepa\u00adration logic that we shall use. Space prevents us \ngiving a complete description or explanation of the signi.cant advantages of using separation logic. \nThe interested reader can read further details and references in a survey paper by Reynolds [29]. Separation \nlogic is an extension to Hoare logic that permits rea\u00adsoning about shared mutable state. It extends Hoare \nlogic by adding spatial connectives to the assertion language, which allow asser\u00adtions to de.ne separation \nbetween parts of the heap. This sepa\u00adration provides the key feature of separation logic local reason\u00ading \nspeci.cations need only mention the state they access [23]. We use the standard model of state from separation \nlogic. A heap, H, is a partial function from locations to values (for simplicity we take Values to be \nthe integers and Locations to be the positive integers). def H= Locations fin Values This has a partial \ncommutative monoid for disjoint function com\u00adposition: ( def H1(l) l .dom(H1) H1 *H2 = .l. H2(l) l .dom(H2) \nwhich is de.ned iff dom(H1) n dom(H2)= \u00d8. A stack, S,is a function from (program) variables to values. \nUnlike other presen\u00adtations [22], we do not interpret auxiliary variables1 using the stack but we de.ne \nan auxiliary stack, I, that is a function from auxiliary variable names to values.2 def S = Vars .Values \ndef I = AuxVars .Values We de.ne a state as a triple consisting of a stack, a heap and an auxiliary stack. \nA predicate is just a set of states, and formulae are given by the following grammar where B and E range \nover boolean-and integer-valued expressions respectively (these are de\u00ad.ned formally in the \u00a73.1). 1Sometimes \ncalled ghost or logical variables. 2We add this as we make heavy use of local variables, and do not have \nglobal variables. P, Q ::= B |\u00acP |P .Q |P .Q |P .Q | empty |P *Q |P -*Q |E .E' The usual classical connectives \n(\u00ac, ., ., .) are interpreted using the boolean algebra structure induced on the powerset of states. In \naddition to the boolean connectives we have the new spatial con\u00adnectives * and -*, along with the predicates \nempty and. . Taking these in reverse order: the predicate E . E' consists of all the triples (S, H, I) \nwhere the heap, H, consists of the single mapping from the location given by the meaning of E to the \nvalue given by the meaning of E'. .E' def S, H, I |= E = dom(H)= {[E]S,I}.H([E]S,I)= [E']S,I We use the \nshorthand E . E1,E2 to mean E. E1 * E +1. E2. The spatial conjunction P * Q means the heap can be split \ninto two disjoint parts in which P and Q hold respectively. def S, H, I |= P *Q = .H1, H2. H1 *H2 = H \n.S, H1, I |= P .S, H2, I |= Q Heaps of more than one element are speci.ed by using the * to join smaller \nheaps. The * has a unit empty that consists of all states (S, H, I) where H is the empty heap. The adjunct \nto *, written -*, is not used in this paper so we shall suppress its (routine) de.nition. The essence \nof local reasoning is that to understand how a piece of code works it should only be necessary to reason \nabout the memory the code actually accesses (its so-called footprint ). Ordinarily aliasing precludes \nsuch a principle but the separation enforced by the * connective allows this intuition to be captured \nformally by the following rule. FRAME RULE f{P }C{Q} f{P *R}C{Q *R} where C does not modify the free \nvariables of R, i.e. modi.es(C)n FV (R)= \u00d8. The side-condition is required because * only describes the \nsep\u00adaration of heap locations and not variables; see [5] for more details. Note: modi.es(C) denotes the \nset of stack variables assigned by a given command, C, e.g. modi.es(x=3) = {x}. However assign\u00adment through \na stack variable to the heap is not counted: modi.es([x]=3) = \u00d8. See [31] for full de.nition. By using \nthis rule, a local speci.cation concerning only the vari\u00adables and parts of the heap that are used by \nC can be arbitrarily extended as long as the extension s free variables are not modi.ed by C. Thus, from \na local speci.cation we can infer a global spec\u00adi.cation that is appropriate to the larger footprint \nof an enclosing program.  3. A LANGUAGE WITH MODULES In this section we consider reasoning about a simple \nimperative language with .rst-order functions/procedures, which is essentially the same as that considered \nby Reynolds [29]. To simplify the pre\u00adsentation we delay using Java to \u00a74. We introduce our novel con\u00adcept \nof an abstract predicate, and state some rules for its use. (These rules are proved sound in \u00a73.4.) We \ndemonstrate the power and el\u00adegance of abstract predicates in reasoning about modular code by considering \ntwo detailed examples: a connection pool and a mem\u00adory manager. 3.1 Syntax The syntax for the programming \nlanguage considered in this sec\u00adtion is given by the grammar in Figure 1. We use x to range over C := \nlet k1 x1 =C1, ..., kn xn =Cn in C | return E |x= k(E) |newvarx;C |x=E | x=[E] |[E] =E |x=cons(E) |dispose(E) \n| if B then C else C |while BC |C;C E := x|E+E |E -E |E *E |n|null B := E ==E |E =E |true|false Figure \n1: Module language syntax program variable names, and k ranges over function names. We have a distinguished \nprogram variable ret that is not modi.able except with the return command. We restrict our considera\u00adtion \nto well-formed programs: e.g. a well-formed program only has returns as the last command of a function; \nand de.nes a function name at most once in a let. In the examples of \u00a73.3 we will use syntactic sugar \nfor procedures: procedure de.nitions are functions that return null, and procedure calls are functions \ncalls assigned to an unused variable. The command newvar x;C de.nes a new local variable for the command \nC, we use a shorthand newvar x,...,y;C for introduc\u00ading multiple variables; x =cons(E) allocates |E| \nconsecutive heap locations with the values of E. The location E is disposed using dispose; updated to \nE ' with [E] = E ' ; and stored in x with x = [E]. 3.2 Proof rules For the assertion language we take \nthe language given in \u00a72 and extend it with predicates. Naturally we restrict our consideration to well-formed \nformulae, and again we elide the obvious de.ni\u00adtion. We write a to range over predicate names and use \na function arity() from predicate names to their arity. A judgement in our assertion language is written \nas follows: .; G f{P}C{Q} This is read: the command, C, satis.es the speci.cation {P } {Q}, given the \nfunction hypotheses, G, and predicate de.nitions, .. The hypotheses and de.nitions are given by the following \ngrammar: G:= . |{P}k(x){Q},G def .:= . |a(x)= P,. However, when it simpli.es the presentation, we will \ntreat . as a partial function from predicate names to formulae, and G as a partial function from function \nnames to speci.cations. We de.ne def .(a)[E] as P [E/x] where . contains a(x)= P . For the hypotheses, \nG, to be well-formed each function, k, can appear at most once; and the speci.cation s free program variables \nare contained in its arguments and ret. For the predicate de.ni\u00adtions, ., to be well-formed we require \nthat each predicate, a,is contained at most once; the free variables of the body, P , are con\u00adtained \nin the arguments, x; and P is a positive formula.3 We will only consider well-formed G and .. Intuitively, \nthe predicates are used like abstract data types. Ab\u00adstract data types have a name, a scope and a concrete \nrepresen\u00adtation. Within this scope the name and the representation can be freely exchanged, but outside \nonly the name can be used. Simi\u00adlarly abstract predicates have a name and a formula. The formula is scoped: \ninside the scope the name and the body can be exchanged, 3A positive formula is one where predicate names \nappear only un\u00adder an even number of negations. This ensures that a .xed point can be found; this is \nexplained in further detail in \u00a73.4.2 and outside the predicate must be treated atomically. Hence our \n.rst rule: ABSTRACT FUNCTION DEFINITION .,. ' ;G f{P1}C1{Q1} . . . .,. ' ;G f{Pn}Cn{Qn} .; G,{P1}k1(x1){Q1},...{Pn}kn(x1){Qn}f{P}C{Q} \n.; G f{P}letk1 x1 =C1,...,kn xn =Cn inC{Q} where P , Q, G and . do not contain the predicate names in \ndom(. ' ); dom(.) and dom(. ' ) are disjoint; and  the functions only modify local variables: modi.es(Ci)= \n\u00d8(1 = i = n) .  This rule allows a module writer to use the de.nition of an abstract predicate, yet \nthe client can only use the abstract predicate name. The functions k1,...,kn are within the scope of \nthe predicates de\u00ad.ned in . ' hence verifying the function bodies C1...Cn can use the predicate de.nitions. \nThe client code, C,is not in the scope of the predicates, so it can only use the predicates atomically \nand through the speci.cations of k1, ..., kn. The predicate names can not occur in the conclusions speci.cation, \nP and Q. The side-conditions for this rule prevent both the predicates es\u00adcaping the scope of the module, \nand repeated de.nitions of a predi\u00adcate. The .nal restriction is not required but reduces the complexity \nof the modi.es clauses for the frame rule. In fact, the previous function de.nition rule is a derived \nrule in our system. It is derived from the standard function de.nition rule and two new rules for manipulating \nabstractions: ABSTRACT WEAKENING .; G f{P}C{Q} .,. ' ;G f{P}C{Q} where dom(. ' ) and dom(.) are disjoint \nABSTRACT ELIMINATION .,. ' ;G f{P}C{Q} .; G f{P}C{Q} where the predicate names in P , Q, G and . are \nnot in dom(. ' ). The.rst, ABSTRACT WEAKENING,allowstheintroductionofnew de.nitions; and the second, \nABSTRACT ELIMINATION allows any unused predicate to be removed. We derive the abstraction function de.nition \nrule by taking the standard function de.nition rule, and using ABSTRACT WEAKEN-ING on the client code \npremise and ABSTRACT ELIMINATION on the conclusion to remove the new predicate de.nitions. We can ap\u00adply \nthe same technique to the recursive function de.nition, however we do not require this for our examples. \nNext we give one of the standard Hoare logic rules: the rule of consequence. (Of course, we use the other \nstandard rules; space prevents us from listing them here.) CONSEQUENCE '' . |= P .P ' .; G f{P ' }C{Q \n} . |= Q .Q .; G f{P}C{Q} This rule is key to actual use of abstract predicate de.nitions. We provide \nthe following two axioms concerning abstract predicates: def OPEN (a(x)= P),. |= a(E) .P[E/x] def CLOSE \n(a(x)= P),. |= P[E/x] .a(E) These axioms embody our intuition that if (and only if) an ab\u00adstract predicate \nis in scope then we can freely move between its name and its de.nition. Next we present the rules for \nfunction call and return. .; G f{P [y/x]}y=k(y) {Q[y, y/x, ret]} where {P }k(x){Q}.G .; G f{P [x/ret]}returnx \n{P } These rules use the distinguished variable ret to match the return value with its destination variable. \nFinally we give the small axioms of separation logic .; G f{E .}[E]=E' {E .E' }.; G f{E .n .x = m}x=[E] \n{E[m/x] .n .x = n}.; G f{E .}dispose(E) {empty} .\u00af .; G f{empty .x = m}x=cons(E) x .E[m/x] These refer \nonly to the state that is accessed by the commands. They can typically be extended using the FRAME RULE \nto refer to a larger state, e.g. .; G f{E .*E1 .E2}dispose(E) {E1 .E2}. 3.3 Examples 3.3.1 Connection \npool Our .rst example is a database connection pool. Constructing a database connection is generally \nan expensive operation, so this cost is reduced by pooling connections using the object pool design pattern \n[9]. Programs regularly access several different databases, hence we require multiple connection pools \nand dynamic instantia\u00adtion (hence this could not be modelled in the framework of O Hearn et al. [22]). \nThe connection pool must prevent the connections be\u00ading used after they are returned: ownership must \nbe transferred be\u00adtween the client and the pool. We assume a library routine, consConn, to construct \na database connection. This routine takes a single parameter that speci.es the database,4 and returns \na handle to a connection. The speci.cation uses a predicate conn to represent the state of the connection. \n{empty} consConn(s) {conn(ret, s)} We de.ne two abstract predicates for the connection pool mod\u00adule: \ncpool and clist. The cpool predicate is used to represent a connection pool; and the clist predicate \nis used inside the cpool to represent a list of connection predicates. def cpool(x, s)= .i.x .i, s *clist(i, \ns) def . clist(x, s)= x = null .(.ij.x .i, j *conn(i, s) *clist(j, s)) . where E = E ' is a shorthand \nfor E = E ' . empty. The connection pool has three operations: construct a pool, con\u00adsPool; get a connection, \ngetConn; and free a connection, free-Conn. These are speci.ed as follows. {empty}consPool(s){cpool(ret, \ns)} {cpool(x, s)}getConn(x){cpool(x, s) *conn(ret, s)} {cpool(x, s) *conn(y, s)}freeConn(x,y){cpool(x, \ns)} We give the implementation of these operations in Figure 2. We present the proof that the freeConnimplementation \nsatisi\u00ad.es its speci.cation, which illustrates the use of abstract predicates: {cpool(x, s) *conn(y, \ns)} {.i.x .i, s *clist(i, s) *conn(y, s)} t=[x]; 4In a more realistic implementation, such as JDBC \n[8], several ar\u00adguments would be used to specify how to access a database. let consPool s = (newvar p; \np=cons(null,s); return p) getConn x =(newvar n,c,l,p; l=[x]; if (l == null) then p=[x+1]; c=consConn(p) \nelse (c=[l]; n=[l+1]; dispose(l); dispose(l+1); [x]=n); return c) freeConn x y = (newvar t,n; t=[x]; \nn=cons(y,t); [x]=n) in C Figure 2: Source code for the connection pool {x .t, s *clist(t, s) *conn(y, \ns)} n=cons(y,t); {x .t, s *n .y, t *clist(t, s) *conn(y, s)} [x]=n {x .n, s *n .y, t *clist(t, s) *conn(y, \ns)}{x .n, s *clist(n, s)}{cpool(x, s)} In this proof the de.nitions of both cpool and clist are used \nwith OPEN and CLOSE to give the following three implications cpool(x, s) ..i.x .i, s *clist(i, s) n .y, \nt *clist(t, s) *conn(y, s) .clist(n, s) x .n, s *clist(n, s) .cpool(x, s) These are used with the rule \nof CONSEQUENCE to complete the proof. Next we present, and attempt to verify, a fragment of client code \nusing the connection pool. It demonstrates both correct and incor\u00adrect usage, which causes the veri.cation \nto fail. The example calls a function, useConn, that uses a connection. {cpool(x, s)} y = getConn(x); \n {cpool(x, s) *conn(y, s)}{conn(y, s)} useConn(y); {conn(y, s)}{cpool(x, s) *conn(y, s)} freeConn(x,y); \n {cpool(x, s)} useConn(y) {???} The client gets a connection from the pool, uses it and then returns \nit. However, after returning it, the client tries to use the connection. This command cannot be validated \nas the precondition does not contain the conn predicate. Even though this predicate is contained in cpool, \nthe client is unable to expand the de.nition because it is out of scope. This illustrates how abstract \npredicates capture own\u00adership transfer . The connection passes from the client into the connection pool \nstopping the client from accessing it, even though the client has a pointer to the connection. A connection \npool library wants many instances; generally one per database. This can be easily handled by calling \nconsPoolthe required number of times. Assume we have two different databases, s1and s2. {empty} y = consPool(s1); \n {conP ool(y, s1)} z = consPool(s2); {conP ool(y, s1) *conP ool(z, s2)} This code creates two connection \npools. The parameter prevents us returning the connection to the incorrect pool. {conP ool(y, s1) * conP \nool(z, s2)} x = getConn(z); {conP ool(y, s1) * conP ool(z, s2) * conn(x, s2)} freeConn(y,x) {???} The \nfreeConncall can only be validated if s1= s2.5 This example has illustrated that abstract predicates \ncapture the notion of ownership transfer , .rst presented with the hypotheti\u00adcal frame rule. Abstract \npredicates additionally deal with dynamic instantiation of a module, which the hypothetical frame rule \ncan\u00adnot. Note: To complete this example we should include a dispose pool function. As it presents no \nadditional interesting dif.cults we omit it from our exposition. 3.3.2 Malloc and free The next example \nis a simple memory manager that allocates variable sized blocks of memory. We use a couple of additional \nfeatures for handling arrays, described by Reynolds [29]: the it\u00aderated separating conjunctions, 8Ex2 \n=E1 .P; and a system routine allocate that allocates variable sized blocks. Intuitively the it\u00aderated \nseparating conjunction, 8Ex2 =E1 .P, is the expansion P [E1/x] * ... * P [E2/x] where x ranges from E1 \nto E2.IfE2 is less than E1, it is equivalent to empty. More formally its semantics are: E2 def S, H, \nI |=. 8.P =([E1]S,I = n1 . [E2]S,I = n2) . x=E1 ((n1 = n2 . S, H, I |=. P [n1/x] *8n2 .P ) x=n1+1 . (n1 \n>n2 . S, H, I |=. empty)) Returning to the example, consider the following na\u00a8ive speci.\u00adcations, which \ndemonstrate the dif.culties in reasoning about the memory manager: {empty}malloc(n){8n-1.ret + i . } \ni=0 {8n-1 i=0 .x + i . }free(x){empty} The problem is with the speci.cation of free: it does not specify \nhow much memory is returned as n is a free variable. The standard speci.cation [12] of freeonly requires \nit to deal\u00adlocate blocks provided by malloc. Using abstract predicates we are able to provide an adequate \nspeci.cation. {empty}malloc(n){8n-1.ret + i . * Block(ret, n)} i=0 {8n-1 * Block(x, n)}free(x){empty} \ni=0 .x + i . The Block predicate is used as a modular certi.cate that malloc actually produced the block. \nThe client can not construct a Block predicate as its de.nition is not in scope. Standard implementations \nof mallocand freestore the block s size in the cell before the allocated block [12]. This can be speci.ed \nby de.ning the Block predicate as follows. def Block(x, n)= x - 1 . n This allows freeto determine the \nquantity of memory returned.6 We can give a simple implementations of these routines that call system \nroutines to construct (allocate) and dispose (dispose) the blocks.7 5Given the speci.cation it is always \nvalid to return a connection to a pool if it is to the correct database. A tighter speci.cation could \nbe given to restrict returning to the allocating pool. 6More complicated speci.cations can be used which \naccount for padding and other book keeping. 7One could extend the speci.cations to have an additional \nmemory manager predicate as in the connection pool example. malloc n =(newvar x; x=allocate(n+1); [x]=n; \nreturn x+1) free x =(newvar n; n=[x-1]; while(n=0) (n=n-1; dispose(x+n)) Both of their implementations \ncan be veri.ed; here we present the proof of malloc: {empty} x=allocate(n+1); {8ni=0.x + i .}{x . *8ni=1.x \n+ i .} [x]=n; {x . n *8ni=1.x + i . } return x+1 {ret - 1 . n *8n .ret - 1+ i .} i=1 {ret - 1 . n *8n-1.ret \n+ i .} i=0 {8n-1.ret + i . * Block(ret, n)} i=0 The .nal implication in this proof abstracts the cell \ncontaining the block s length, hence the client cannot directly access it. The fol\u00adlowing code fragment \nattempts to break this abstraction: {empty} x=malloc(30); {829 * Block(x, 30)}i=0.x + i . [x-1]=15; \n {???} free(x); The client attempts to modify the information about the block s size. This would be \na clear failure in modularity as the client is dependent on the implementation of Block. Fortunately, \nwe are unable to validate the assignment as the pre-condition does not con\u00adtain x - 1 . . Although, the \nBlock contains the cell, the client does not have the de.nition in scope and hence cannot use it. O Hearn, \nReynolds and Yang s [22] idealization of a memory manager does not support variable sized blocks. Their \nspeci.ca\u00adtions can not be extended to cover this without exposing the rep\u00adresentation of the block. Additionally, \nit is impossible for them to enforce that malloc must provide the blocks that free deallo\u00adcates without \nextending the logic. 3.3.3 Permissions reading O Hearn [21] has recently given separation logic an ownership, \nor permissions, interpretation: E . E ' is the permission to read, write and dispose the cell at location \nE. Bornat et al. [5] extend this to allow read sharing. Essentially they annotate the . relation to express \nthe type of permission it represents: read or total. In the previous example, the Block predicate is \nthe permission to dis\u00adpose the memory using free. Using this permissions reading of separation logic, \nabstract predicates allow modules to de.ne their own permissions. The concept of ownership transfer can \nbe seen as transferring permission to and from the client. Consider a ticket machine: {empty}getTicket(){Ticket(ret)}{Ticket \n(x)}useTicket(x){empty} To call useTicketyou must have called getTicket; each us\u00adage consumes a ticket. \nTrying to use a ticket twice fails: {empty} x = getTicket(); {Ticket (x)} useTicket(x); {empty} useTicket(x); \n {???} The second call to useTicket fails, because the .rst call re\u00admoved the Ticket.    Any client \nthat is validated against this speci.cation must use the ticket discipline correctly. In fact the module \nis free to de.ne the def ticket in any way, e.g. Ticket(x)= true. Although this ticket would be logically \nvalid to duplicate, true *true . true, the client does not know this, and hence cannot.  3.4 Semantics \nIn the previous section we have informally introduced the notion of abstract predicates and detailed \na couple of examples to high\u00adlight their use and demonstrate their usefulness. In this section we formalize \nthem precisely and show that the two abstract predicate rules are sound. 3.4.1 Programming language We \nassume the usual semantics of separation logic [31] and ex\u00adtend it to handle the functions. A semantic \nfunction environment, ., is a .nite partial function from function names, k, to a pair of a vector of \nvariable names and a command for the body (.: k\u00ad(x, C)). An environment is well-formed, . ok, if it only \nmodi.es local variables, .x, C .cod(.).modi.es(C)= \u00d8. A con.guration is de.ned as a quadruple of a function \nenviron\u00adment, a command, a stack, and a heap. A terminal con.guration is a stack, heap pair or Fault. \nThe semantics are given by a recur\u00adsively de.ned relation between con.gurations and terminal con.g\u00adurations \npresented in Figure 3. We provide additional failure rules for each heap command accessing unde.ned state: \n9 (., [E]=E ' , S, H) .Fault > = where (.,x=[E], S, H) .Fault > [E]S ./dom(H) ; (., dispose(E), S, H) \n.Fault and add rules to propagate the Fault states in the obvious way. DEFINITION 3.1 (SAFETY). def (.,C, \nS, H): safe = \u00ac((.,C, S, H) .Fault) Note: As we only consider partial correctness, we consider non\u00adtermination \nas safe. We have the standard properties required for the soundness of the frame rule [31]. LEMMA 3.2 \n(SAFETY MONOTONICITY). (.,C, S, H): safe .H ' .H .(.,C, S, H .H ' ): safe LEMMA 3.3 (HEAP LOCALITY). \n(.,C, S, H1): safe .(.,C, S, H1 *H) .(S ' , H ' ) . .H2.H ' = H *H2 .(.,C, S, H1) .(S ' , H2)  3.4.2 \nAbstract predicates Next we de.ne the semantics of an abstract predicate. First we de.ne semantic predicate \nenvironments, ., as follows: a .: A (Nn .P(H)) n.N where Ais the set of predicate names. We restrict \nour consideration to well-formed environments: each predicate name is mapped to a Narity(a) function \nof the correct arity, .(a): .P(H). The reader might have expected the use of P(H\u00d7S\u00d7I), but this breaks \nsubstitution as the predicate can depend on variables that are not syntactically free. The semantics \nof a predicate is as follows: S, H, I |=. a(E) . a .dom(.) . H .(.a)[[E]S,I] The rest of the semantics \nare from the standard de.nition, sketched in \u00a72, with the predicate environment added in the obvious \nway. We de.ne the following ordering on semantic predicate environ\u00adments def . r. ' = n : Narity(a) .a.. \n..(a)= ...(a)(n) .. ' (a)(n) The least upper bound of this order is written U. LEMMA 3.4. Well-formed \nsemantic predicate environments form a complete lattice with respect to .. LEMMA 3.5. Formulae only depend \non the predicate names they mention, i.e. if . de.nes all the predicate names in P, and . and . ' are \ndisjoint, then .S, H, I. S, H, I |=. P .S, H, I |= .U.' P LEMMA 3.6. Positive formulae are monotonic \nwith respect to semantic predicate environments, i.e. if P is a positive formula, . r. ' . S, H, I |=. \nP . S, H, I |= .' P Now let us consider the construction of a semantic predicate en\u00advironment from an \nabstract one, .. The abstract predicate environ\u00adment does not, necessarily, de.ne every predicate, so \nconstructing a solution requires additional semantic de.nitions, ., to .ll the holes. We use the following \nfunction to generate a .xed point: def .a .dom(.)..n .Narity(a) step(.,.)(.n)= . {H|S, H, I |=.nU. .(a)[n]} \nwhere . are the de.nitions we want to solve; . are the predicates not de.ned in .; and .n is an approximation \nto the solution. step is monotonic on predicate environments, because of Lemma 3.6 and that all the de.nitions \nare positive. Hence by Tarski s theorem and Lemma 3.4 we know a least .xed point always exists. We write \n[.]. for the least .xed point of step.,.. Note: step is not Scott-continuous. This does not cause any \nprob\u00adlems because we only need consider the properties of the least .xed point, rather than its construction. \nConsider the set of all solutions of . of the form . U[.].: def close(.) = {. U[.].| dom(.) = A\\dom(.)} \nThis function has two properties. LEMMA 3.7. Adding new predicate de.nitions re.nes the set of possible \nsemantic predicate environments, i.e. close(.) .close(., . ' ) LEMMA 3.8. The removal of predicate de.nitions \ndoes not af\u00ad fect predicates that do not use them. Given . which is disjoint from . ' and does not mention \npredicate names in its domain; we have .. .close(.)... ' .close(., . ' ). . r dom(. ' )=. ' r dom(. ' \n) where f I S is {a .b|a .b .f .a/.dom(S)} We de.ne validity wrt an abstract predicate environment, written \n. |= P , as follows: .S, H, I, . .close(.). S, H, I |=. P THEOREM 3.9. OPEN and CLOSE, i.e. def a(x)= \nP, . |= a(E) .P [E/x] def a(x)= P, . |= P [E/x] .a(E), are valid. Function de.nition New variable (.[k1 \n.(x1,C1),...,kn .(xn,Cn)],C, S, H) .(S ' , H' ) (.,C, S[x .nil],H) .(S1, H1) (., letk1 x1=C1,...,kn xn \n=Cn inC), S, H) .(S ' , H' ) (., newvarx; C, S, H) .(S1[x .S(x)], H1) While1 While2 Function call [B]S \n= false [B]S = true (.,C; whileBC, S1, H1) .(S2, H2) (.,C, x .[y]S, H) .(S ' , H' ).(k)= x, C (., whileBC, \nS1, H1) .(S1, H1) (., whileBC, S1, H1) .(S2, H2) (.,x=k(y), S, H) .(S[x .[ret]S' ], H ' ) Sequence (.,C1, \nS1, H1) .(S2, H2) If1 If2 (.,C2, S2, H2) .(S3, H3) [B]S = true (.,C1, S, H) .(S1, H1) [B]S = false (.,C2, \nS, H) .(S1, H1) (.,C1; C2, S1, H1) .(S3, H3) (., ifB thenC1 elseC2, S, H) .(S1, H1) (., ifB thenC1 elseC2, \nS, H) .(S1, H1) Read (.,x=[E],S,H).(S[x . n],H) where H([E]S)= n Write (.,[E]=E ' ,S,H).(S,H[n . n ' \n]) where [E]S = n, n . dom(H) and [E ' ]S = n ' Cons (.,x=cons(E),S,H).(S[x . n],H[n . n]) where |E| \n= n ' , {n,...,n+ n ' }.dom(H) and [E]S = n Dispose (.,dispose(E),S,H).(S,H ' ) where [E]S = n, H ' [n \n. n ' ]= H and n/. dom(H ' ) Assign (.,x=E,S,H).(S[x . n],H) where [E]S = n Return (.,returnE; ,S,H).(S[ret. \n[E]S],H) Figure 3: Operational semantics 3.4.3 Judgements We are now in a position to de.ne a semantics \nfor our reasoning system. We write .; G |= {P}C{Q} to mean that, if every spec\u00adi.cation in G is true \nof a function environment, and every abstract predicate de.nition in . is true of a predicate environment, \nthen so is {P}C{Q}: def .; G |= {P}C{Q}= .. .close(.), .. . ok . (. |=. G) . . |=. {P}C{Q} where def \n. |=. G= .{P}k{Q}.G..(k)=(x, C) .. |=. {P}C{Q} def . |=. {P}C{Q}= .S, H, I. S, H, I |=. P . ((.,C, S, \nH): safe .((.,C, S, H) .(S ' , H ' ) .S ' , H ' , I |=. Q)) Given this de.nition we can show that the \ntwo new rules for abstract predicates are sound. THEOREM 3.10. Abstract weakening is sound. PROOF. Directconsequenceofde.nitionofjudgementsandLem\u00adma \n3.7. THEOREM 3.11. Abstract elimination is sound. PROOF. Follows from Lemmas 3.5 and 3.8.  4. A JAVA-LIKE \nLANGUAGE In the previous section we have shown how abstract predicates can be used with separation logic \nto provide a powerful but intuitive framework to reason about a language with .rst-order functions or \nprocedures. We now turn our attention to another form of modular\u00adity: class-based objects. More precisely \nwe shall consider the problems of reasoning about a fragment of Java. We will consider a simple subset \nof Java based on Middleweight Java (MJ) [3]. We restrict MJ s expressions to be Program prog ::= cldef1 \n... cldef;s n Class de.nition cldef ::= class C extends D {fdef mdef} Method de.nition mdef ::= C m(C1 \nx1, ..., Cn xn) {s return x;} Field de.nition fdef ::= C f; Expressions E ::= x |null  Statements s \n::= x =y.f; | x =(C)y; | x =new C(); | x.f =E; | x =y.m(E); | Cx; |{s}| ; | if (E ==E) {s}else {s} Figure \n4: Syntax of MJ subset stack variables and null,8 and remove constructors. We present the full syntax \nin Figure 4. We write f and m to range over .eld and method names respectively. We use C, D to range \nover class names, and x, y to range over variable names. Consider giving a separation logic to this language: \nclearly we require the points to relation to describe .elds.9 The new asser\u00adtion .eld points to , written \nx.f . y, means the .eld f of the object x contains the value y. We also use the predicate x : C to mean \nthat xpoints to an object of class C: it is actually a C not just a subtype of C. Now consider a motivational \nexample [1] of a Cell class and a subclass that has backup, Recell, presented in Figure 5. The speci.cations \nof the setmethods are: {this.cnts .} {this.cnts .X *this.bak .} Cell.set(n) Recell.set(n) {this.cnts \n.n}{this.cnts .n *this.bak .X} These speci.cations have two problems: (a) they have no encapsu\u00adlation; \nand (b) they do not respect behavioural subtyping. (a) From the speci.cation the client knows which .eld \nis used to 8This restriction is required as separation logic requires expres\u00adsions to be pure: they cannot \naccess the heap, i.e. x.f1.f2 is not allowed. 9An alternative approach would be to use the heap primitive \nas a whole object [18]. However, being able to split an object allows for more .exible reasoning.  \n  class Cell { Object cnts; void set(Object n) {this.cnts = n;} Object get() {Object t; t = this.cnts; \nreturn t;}} class Recell extends Cell { Object bak; void set(Object n) { Object t; t = this.cnts; \n this.bak = t; this.cnts = n;}} Figure 5: Source code for Cell and Recell classes store the contents. \nClearly we need a greater level of abstraction. Using an abstract predicate allows us to encapsulate \nthe object s state. We can write the Cell s setspeci.cation as: {Val Cell(this, )} Cell.set(n) {Val Cell(this,n)} \nand de.ne the abstract predicate as def Val Cell(this,x)= this.cnts .x and scope it to the Cellclass. \nThis stops the Cell s client using the .eld directly as it is hidden in the abstract predicate. (b) Using \nstandard behavioural subtyping [17], to allow dynamic dispatch, the Recell s speci.cation needs to be \ncompatible with the Cell s, i.e. we require the following two implications to hold pre(Cell, set) .pre(Recell, \nset) (1) post (Recell, set) .post (Cell, set) (2) where pre(C, m) denotes the pre-condition for the method \nm in class C, and post denotes the post-condition. Given the earlier speci.cations, these implications \ncan never hold as they require a one element heap to be the same size as a two el\u00adement heap. What about \nabstract predicates? The speci.cation for Recellmust use a different abstract predicate to Cellas it \nhas a different body, i.e. {Val Recell(this,X, )}Recell.set(n){Val Recell(this,n, X)} with the obvious \nde.nition for ValRecell. Unfortunately the predi\u00ad cates are treated parametrically; no implications hold \nbetween them. As it stands, abstract predicates do not, by themselves, help with behavioural subtyping. \nThey provide support for encapsulation but not inheritance. In an object-oriented setting we require \npredicates to have multiple de.nitions, hence we introduce abstract predicate families where the families \nare sets of de.nitions indexed by class. Abstract predicate family instances10 are written a(x; .v) to \nindicate that the object x satis.es one de.nition from the abstract predicate family a with arguments \n.v. The particular de.nition satis.ed de\u00ad pends on the dynamic type of x. In object-oriented programming \nan object could be from one of many classes; abstract predicate families provide a similar choice of \npredicate de.nitions when con\u00ad sidering their behaviour. We de.ne abstract predicate family de.nitions, \n.f , with the fol\u00ad lowing syntax. def .f := . |aC = .(x; x)P, .f .f is well-formed if it has at most \none entry for each predicate and class name pair, and the free variables of the body, P , are in its \nargument list, x; x. We treat .f as a function from predicate 10In the module system the concept of \nabstract predicate instance, and the abstract predicate are con.ated, but here as we have multi\u00ad ple \nde.nitions the distinction must be kept. and class name pairs to formulae. Each entry corresponds to \nthe de.nition of an abstract predicate family for a particular class. Our example shows the need to alter \nthe arity of the predicate to re.ect casting; the Recell s predicate has three arguments while the Cell \ns only has two. Hence we provide the following pair of implications: WIDEN .f |= a(x; x) ..y.a(x; x, \ny) NARROW .f |= .y.a(x; x, y) . a(x; x) If we give a predicate more variables than its de.nition requires, \nit ignores them, and if too few, it treats the missing arguments as existentially quanti.ed. This leads \nto our de.nition of substitution onto a predicate de.nition, def (.(x; x).P )[E; E]= ( P [E/x, E1/x] \n|E1|= |x|and E = E1, E2 .y.P [E/x, (E,y)/x] |E,y|= |x| This de.nition of substitution can then be used \nto give the families version of OPEN and CLOSE. OPEN .f |=(x : C .a(x; x)) ..f (a, C)[x; x] CLOSE .f \n|=(x : C ..f (a, C)[x; x]) .a(x; x) where a, C . dom(.f ). To OPEN or CLOSE a predicate we must know \nwhich class con\u00adtains the de.nition, and must have that version of the predicate in scope. Note: We can \nOPEN predicates at incorrect arities as the substi\u00adtution will correctly manipulate the arguments. An \nalternative ap\u00adproach would be to restrict opening to the correct arity, and use WIDEN and NARROW to \nget the correct arity. However, this ap\u00adproach complicates the semantics. 4.1 Proof rules In this section \nwe de.ne a set of Hoare-style proof rules for rea\u00adsoning about MJ programs. The judgements take the following \nform: .f ;G f{P }s {Q} where G is a set of assertions about methods. They have the fol\u00adlowing form: G:= \n. |{P }C.m(x){Q}, G A well-formed method environment, . G wf, de.nes each method and class name pair \nonly once and has the following three proper\u00adties: 1. The pre-and post-conditions can only contain free \nprogram variables in the argument list, thisand ret; i.e. .{P }C.m(x){Q}.G.FPV(P ) .({this}.x) . FPV(Q) \n.({this,ret}.x) 2. A method can only modify local variables; there are no global variables and arguments \ncannot be modi.ed, i.e. .{P }C.m(x){Q}.G.modi.es(mbody(C, m)) = \u00d8 where mbody(C, m) returns the body \nof method m in class C. 3. Subtypes must have compatible speci.cations with their su\u00adpertypes, i.e. .{PC \n}C.m(x){QC }.G.D .C .{PD}D.m{QD}.G . (f{PC } {QC }.{PD} {QD}) DEFINITION 4.1 (SPECIFICATION COMPATIBILITY). \nWe de\u00ad.ne speci.cation compatiblity, .{PC }{QC }.{PD}{QD}, as .s. if .; G .{PD}s{QD}is derivable from \n.; G .{PC }s{QC }using only the structural rules: CONSEQUENCE, AUXILIARY VARI\u00ad 11 ABLE ELIMINATION and \nVARIABLE SUBSTITUTION. This is more general than the behavioural subtyping rules as it allows manipulation \nof auxiliary variables. In fact, if the derivation only uses the rule of CONSEQUENCE, speci.cation compatibilty \ndegenerates to behavioural subtyping. Now let us consider the method call rule: METHOD CALL . . P [x, \ny/this,x] .;Gf y=x.m(y){Q[x, y, y/this,ret, x]} .x !=null where x has static type C and {P }C.m(x){Q}.G \nThe method call rule only needs to consider the static type of the receiver, because we have restricted \nourselves to methods that are speci.cation compatible.12 The rules for checking the whole program deserve \nsome atten\u00adtion. CLASS .f ;Gf{Pn .this :C}mbody(C, mn){Qn} . . . .f ;Gf{P1 .this : C}mbody(C, m1){Q1} \n.f ;Gf{P1}C.m1(x1){Q1},..., {Pn}C.mn(xn){Qn} PROGRAM .f 1;GfG1 ... .fn;GfGn \u00d8, G f{P }s{Q} f{P }cldef1 \n... cldef; s{Q} n where G1 is the method speci.cations of the methods de.ned in and inherited into cldef1; \n...; Gn is induced by cldef n; G= G1,..., Gn; and .f 1,..., .fn have disjoint domains. These two rules \ncorrespond to the abstract function de.nition from the previous section. They enforce that each method \nis checked with the predicate de.nitions associated to its class.13 Inherited methods must be rechecked \nwith the new predicate de.nitions for the class that inherits them. This is because when we check the \nmethod bodies in the class rule, we add to the pre-condition this : C. Without this we would not be able \nto open or close the abstract predicate families. Again we have the two rules for introducing and eliminating \nab\u00ad stract predicate families. ABSTRACT WEAKENING .f ;Gf{P }C{Q} ' .f , .f ;Gf{P }C{Q} where dom(. ' \nf ) and dom(.) are disjoint. ABSTRACT ELIMINATION ' .f , . ;Gf{P }C{Q} f .f ;Gf{P }C{Q} where the predicates \nnames in P , Q, G and . are not in doma(. ' f ) and de.ne doma(.f ) as {a|(a, C) .dom(.f )}. 11The frame \nrule could be included in this list if s is restricted to terms that modify no variables. 12We could \npresent additional rules that do not rely on the subtyping constraint, but they would only serve to complicate \nthe presentation and wouldn t illustrate anything interesting. 13We assume these de.nitions will be \nprovided during the proof, and provide no explicit syntax for them. Abstract predicate families are less \nsymmetric than abstract pred\u00adicates: weakening allows the introduction for a particular class and predicate, \nwhile elimination requires the entire family of de.ni\u00adtions to be removed, i.e. must remove all the classes \nde.nitions for a predicate. This is because it is not possible to give a simple syntactic check for which \nparts, i.e. classes, of a family will be used. Finally we give the rules for .eld access, .eld write, \nand object construction, which are similar to their equivalents in the module system: .f ;Gf{x.f .}x.f=E' \n{x.f .E' } . .. . y.f .ny[m/x].f .n .f ;Gf x=y.f . x =m . x = n .f ;Gf{empty}x=new C(){x.f1 .*... * x.fn \n..x :C}where C has .elds f1... fn 4.2 Example: Cell/Recell Let us return to our original motivating example. \nWe de.ne an abstract predicate family, Val , with the de.nitions for Cell and Recellgiven earlier. We \nhave to validate four methods: Cell.set, Cell.get, Recell.set and Recell.get. Even though the bodies \nof Cell.get and Recell.get are the same, we must validate both, because they have different predicate \nde.nitions. We give the proof for Recell.set. {Val (this;X, ).this :Recell} {this.cnts .X *this.bak ..this \n:Recell} t = this.cnts; {this.cnts .X *this.bak ..this :Recell .X =t} this.bak = t; {this.cnts .X *this.bak \n.t .this : Recell .X = t} this.cnts = n; {this.cnts .n *this.bak .t .this :Recell .X =t}{this.cnts .n \n*this.bak .X .this :Recell}{Val (this;n, X)} The other method bodies are all easily veri.able. Additionally, \nwe must prove the method speci.cations are com\u00adpatible. The compatiblity of the setmethod follows from \nthe rule of CONSEQUENCE and AUXILIARY VARIABLE ELIMINATION. f{Val (this;X, )}{Val (this;n, X)}f{Val (this; \n, )}{Val (this;n, )}f{Val (this;)}{Val (this;n)} The get methods have the same speci.cation, so are obviously \ncompatible. A client that uses this code does not need to worry about dy\u00adnamic dispatch, because of the \nbehavioural subtyping constraints. Consider the following method: m(Cell c) { c.set(c); } This code \nsimply sets the Cell to point to itself. The code is speci\u00ad.ed as {Val (c;)} m(Cell c) ... {Val (c;c)} \nNow consider calling mwith a Recellargument. {empty} Recell r = new Recell(x); {Val (r;x, )}{Val (r;)} \nm(r); {Val (r;r)}{Val (r;r, )} Weuse CONSEQUENCE tocastthe Val predicate to have the correct arity. \nWe need not consider dynamic dispatch at all because of behavioural subtyping. Note: The speci.cation \nof method mis weaker than we might like. Based on the implementation we might expect the post-condition \n{Val (r; r, x)}. However, there are several bodies that satisfy m s speci.cation: for example c.set(x);c.set(c);. \nWe can set the Cellto have any value, as long as the last value we set is the Cell itself. This body \nacts identically on a Cellto the previous body, however on a Recellacts differently. Hence only using \nthe speci.cation we can not infer the tighter post-condition. This could be deduced if mwas speci.ed \nfor a Recellas well. 4.3 Semantics In this section we consider the extensions to the semantics of \u00a73.4 \nsuf.cient to model abstract predicate families. MJ has been de.ned formally elsewhere [3]. First we shall \nmake some small changes to the basics of the separation logic setting: DEFINITION 4.2. A heap, H, is \ncomposed of two functions, H = (Hv, Ht): the .rst, Hv, maps pairs of object identi.ers and .eld names, \n(oid, f), to values, val; and the second, Ht, maps object identi.ers to class names, C. We use H(oid, \nf) to refer to the value given by the .rst function, Hv(oid, f), and H(oid) to refer to the value given \nby the second function, Ht(oid). (We make the obvious alterations to the semantics to deal with the new \nheap de.nition.) This de.nition allows a heap to contain only some .elds of an object. This new de.nition \nalso separates the type information from the value information in the heap. We use the following two \nde.nitions to give the partial commu\u00adtative heap composition monoid def ) *(H '' , H '' .H '' (H ' , \nH ' )=(H ' , H ' ) vtvt vvt H '' and is de.ned iff dom(H ' vvt = t ).dom(H '' ) and H ' where . is composition \nof disjoint partial functions. The semantic predicate environment as de.ned in \u00a73.4 has to be extended \nto handle the arity changes that predicate families require. We de.ne a semantic predicate family environment \nas `\u00b4 .f : A\u00d7CN+ .P(H) This is a partial function from pairs of predicate and class name to semantic \nde.nition. An abstract predicate family is de.ned for all arities, so the semantic de.nition must be \na function from all tuples of non-zero arity. This semantically supports the change in arity required \nby WIDEN and NARROW. We can now give the semantics of the new assertions as follows S, H, I |=.f E.f \n.E' .H([E]S,I,f)= [E' ]S,I .dom(H)= {[E]S,I,f} S, H, I |=.f E : C . H([E]S,I)= C S, H, I |=.f a(E; E) \n.H .(.f (a, C))[[E; E]S,I] . H([E]S,I)= C The .eld points to relation, E.f . E ' , holds if the heap \ncon\u00adsists of a single .eld, f, of the object [E]S,I and has the value [E ' ]S,I.E : C is true if the \nheap types [E]S,I as class C. a(E; E) holds for some heap H, where [E]S,I has class C,iff H satis.es \nthe predicate de.nition for C, given arguments [E, E]S,I, in the predi\u00adcate family a. To ensure that \nWIDEN and NARROW hold we restrict our atten\u00adtion to argument re.neable environments. DEFINITION 4.3 (ARGUMENT \nREFINEABLE). A semantic pred\u00adicate family environment is said to be argument re.neable if adding an argument \ncan not increase, or decrease , the set of accepting states, i.e. [ AR(.f ) ..a, n, n. .f (a)[n; n]= \n.f (a)[n; n, n ' ] n ' PROPOSITION 4.4. Argument re.nement coincides precisely with WIDEN and NARROW: \n.S, H, I,a,n, n. AR(.f ) ..(S, H, I |=.f a(n; n) ..n ' .a(n; n, n ' )) We can de.ne an order on semantic \npredicate families environ\u00adments, i.e def r. ' = .a, C, n, n..f (a, C)[n; n] ..f (a, C)[n; n] .ff Again, \nthe least upper bound of the order is written U. Lemmas 3.4 and 3.6 can be extended to semantic predicate \nfamily environments as follows: LEMMA 4.5. Argument re.neable predicate family environments form a complete \nlattice with respect to . LEMMA 4.6. Positive formulae are monotonic with respect to semantic predicate \nfamily environments .f r.f ' . S, H, I |=.f P . S, H, I |= . ' P f However extending Lemma 3.5 is less \nstraight forward, as it is not possible to tell which predicate name, class name pairs are used in a \nformula. LEMMA 4.7. Formulae only depend on the abstractions they mention. If .f contains all the abstractions \nin P, and doma(.f )n doma(. ' f )= \u00d8, then .S, H, I. S, H, I |=.f P .S, H, I |= .f U. ' P f Now let us \nconsider the construction of semantic predicate fam\u00adily environments from their abstract syntactic counterparts. \nWe de\u00ad.ne a new function, stepf, that accounts for the .rst argument s type and uses the special substitution, \ndef stepf(.f ,.f )(. ' f )(a, C)[n; n]= {H|H(n)= C .S, H, I |= .f .. ' .f (a, C)[n; n]} f This function \nis monotonic on predicate family environments, be\u00adcause of Lemma 4.6 and that all the predicate de.nitions \nare posi\u00adtive. Hence by Lemma 4.5 and Tarski s theorem we know a .xed point must always exist. We write \n[.f ].f as the least .xed point of stepf(.f ,.f ). LEMMA 4.8. stepf produces argument re.neable results. \nConsider the following set of solutions: {[.f ].f U.f |(A\u00d7C) \\dom(.f )= dom(.f ) .AR(.f )} This satis.es \nthe analogues of Lemmas 3.7 and 3.8. LEMMA 4.9. Adding new predicate de.nitions re.nes the set of possible \nsemantic predicate environments. close(.f ) .close(.f , . ' ) f LEMMA 4.10. The removal of predicate \nde.nitions does not af\u00adfect predicates that do not use them, i.e. given .f which is disjoint from . ' \nf and does not mention predicates in its domain; we have .. .close(.f )... ' .close(.f , . ' ). ff .f \nr dom(. ' )=. ' f r dom(. ' ) ff where f I S is {a . b|a . b . f . a/. dom(S)} Validity is de.ned identically \nto the previous section, i.e. def .f |= P = .S, H, I, .f .close(.f ).S, H, I |=.f P THEOREM 4.11. OPEN \nand CLOSE, i.e. .f |= a(E; E) .E : C ..f (a, C)[E, E/x, x] .f |=.f (a, C)[E, E/x, x] .E : C .a(E; E) \nwhere (a, C) . dom(.f ), are valid. THEOREM 4.12. WIDEN and NARROW, i.e. .f |= a(E; E) ..X.a(E; E,X) \n.f |= a(E; E, E ' ) .a(E; E), are valid. 4.3.1 Judgements We are now in a position to de.ne the semantics \nfor our reason\u00ading system. We write .f ;G |= {P }C{Q} to mean if every spec\u00adi.cation in G is true of \na method environment, and every abstract predicate family in .f is true of a predicate family environment, \nthen so is {P }C{Q}, i.e. def .f ;G |= {P }C{Q}= ..f .close(.f ). (.f |=G) . .f |= {P }C{Q} where def \n.f |=G = .{P }C.m{Q}.G..f |= {P }mbody(C, m){Q} def .f |= {P }s {Q}= .S, H, I.S, H, I |=.f P . ((S, H, \ns, []) : safe .((S, H, s, []) . * (S ' , H ' ,v, []) .S ' , H ' , I |=.f Q)) Given this de.nition we \ncan show that the two new rules for abstract predicate families are sound. THEOREM 4.13. Abstract weakening \nis sound. PROOF. Direct consequence of the de.nition of judgements and Lemma 4.9. THEOREM 4.14. Abstract \nelimination is sound. PROOF. Follows from Lemmas 4.7 and 4.10  5. RELATED AND FUTURE WORK In this paper \nwe have considered the problem of writing spec\u00adi.cations for programs that use various forms of abstraction. \nWe have focused here on modules and Java-like classes. We have built on the formalism of separation logic \nand presented rules for rea\u00adsoning about ADTs and Java-like classes. We have demonstrated the utility \nof these rules with a series of examples. The principles of abstraction this paper builds on have been \naround since the Seventies. Parnas [25] .rst described the principles of information hiding and showed \nthat without it seemingly indepen\u00addent components of a program could become tied together. Hoare provided \na logic for data abstraction [11] that allowed internal im\u00adplementation details to be hidden from the \nclient. These ideas were developed further by Liskov [16] and Guttag [10] to provide what we now know \nas abstract datatypes. In Hoare s [11] presentation of data abstraction, he used an ab\u00adstraction function \nthat maps values from a concrete domain to an abstract one. This abstraction function has been used in \nbehavioural subtyping [17] to make classes with different implementations meet the same speci.cation. \nWhen reasoning with framing, Leino ob\u00ad served that, in addition to abstraction functions, datagroups \n[14] are needed to abstract modi.es14 clauses. Abstract predicates, and fam\u00ad ilies, combine the concept \nof both datagroups and the abstraction function into a single de.nition: separation logic formulae repre\u00ad \nsent both the amount of state and its possible values. There have been several attempts to reason about \nJava using a Hoare logic, including those by Oheimb and Nipkow [24], Poetzsch- Heffter and M\u00a8uller [27], \nPierik and de Boer [26]. However these logics do not have the framing properties of separation logic; \nmethod bodies must be veri.ed at each call site. Also they do not at\u00ad tempt to express abstraction. In \nthis sense Leino s work with data\u00ad groups [14] and data abstraction [15] are more closely related. This \nwork uses the concept of modular soundness to determine when state can be exposed to a client. Another \nrelated approach by Bar\u00ad net et al. [2] uses a private invariant to encapsulate the objects state. This \ninvariant can be packed and unpacked to access its con\u00ad tents. These pack and unpack operations can be \nseen as correspond\u00ad ing to the open and close implications of abstract predicates. Reddy [28] takes a \ndifferent approach to adding abstraction to the logic. He extends speci.cation logic to provide the ability \nto existentially quantify a predicate. This quanti.ed predicate behaves in a similar way to an abstract \npredicate. Middelkoop et al. [18] have similar aims to us and give a sepa\u00ad ration logic for a class-based \nlanguage. Their approach considers an object as the primitive element of the heap, rather than a .eld. \nThis restricts their use of the frame rule by preventing them from considering splitting an object. Their \nwork does not consider ab\u00ad straction or inheritance and so can not handle any of the examples presented \nin this paper. A different approach to adding abstraction to separation logic has been taken by O Hearn \net al. [22]. They use the hypothetical frame rule to reason about static modularity. They are not able \nto reason about ADTs or classes, and cannot verify the examples we present. All the examples they present \ncan by expressed using ab\u00ad stract predicates, however the proofs are less compact: predicates must be \nthreaded through the proof to represent the internal invari\u00ad ant. This leads to two open questions: (1) \ncan abstract predicates express all the proofs of the hypothetical frame rule?; and (2) can the concepts \nbe soundly combined into a single logic? We believe the answer to both of these questions to be yes, \nbut more work re\u00ad mains. Building on the principles of the hypothetical frame rule, Mija\u00ad jlovi\u00b4c and \nTorp-Smith [19] have built a semantic model of re.ne\u00ad ment in a setting similar to separation logic. \nThis allows them to semantically show one module could be used in place of another. They do not provide \nany logical rules for this reasoning, and they do not deal with ADTs. It would be interesting to see \nif their mod\u00ad els could be adapted to abstract predicates. A different approach to separation logic to \ndealing with the prob\u00ad lem of aliasing is to impose some form of restriction using a type system. Ownership \ntypes [6] have been used to restrict aliasing in object-oriented languages. They prevent pointers into \nan object s representation, which helps reasoning about encapsulation. Smith and Drossopoulou [7] exploit \nthis encapsulation to extend a Hoare logic with framing properties. Separation logic is more .exible \nthan ownership types as it prevents dereferencing of a pointer rather than its existence. Many researchers \nhave pointed to similarities between separation logic and ownership types. However close comparison has \nbeen hampered by the fact that separation logic research has dealt with 14A modi.es clause is an annotation \nthat speci.es all the possible changes made by a method/function body. low-level pointer manipulation; \nwhereas ownership types has dealt with high-level object languages. We hope that the work detailed in \nthis paper may provide a stepping-stone for a more indepth analysis of these two approaches. In this \npaper we have built a logic for reasoning about abstract types. It is well-known that abstract types \ncorrespond via the Curry-Howard correspondence to existential types [20]. Abstract predi\u00adcates appear \nto be analogous, but at the level of the propositions themselves. We should also like to explore this \nanalogy further, perhaps using higher-order logic to provide a logical semantics for abstract predicates. \nThe types analogy leads to another direction to pursue: para\u00admetric polymorpism. In this paper functions \nand methods can be de.ned to manipulate a datatype or class without knowing its repre\u00adsentation: e.g. \nthe connection pool did not know how a connection was stored. This is related to O Hearn s comment that \nOwnership is in the eye of the asserter . Abstract predicates may provide a suitable setting for studying \nparametric datatypes; we are currently working on a set of proof rules. Finally, in this paper we have \nonly considered sequential lan\u00adguages. Recently, O Hearn has shown how to extend separation logic with \nrules to reason about concurrency primitives [21]. These rules use the same information hiding principles \nof the hypotheti\u00adcal frame rule [22]. They allow state to be stored in a semaphore, and by manipulating \nthis semaphore the state can be transfered be\u00adtween threads. Unfortunately the semaphore is statically \nscoped, which prevents reasoning about heap allocated semaphores includ\u00ading, for example Java s synchronised \nprimitive. We are cur\u00adrently consider the combination of the information hiding provided by abstract \npredicates with O Hearn s system for concurrency to allow for reasoning about semaphores in the heap, \nand hence Java with threads. Acknowledgements We should like to thank Peter O Hearn for insightful comments \non earlier versions of this work and proposing the malloc and free example; and Andrew Pitts, Alisdair \nWren and the anonymous ref\u00aderees for comments on this paper. We acknowledge funding from EPSRC (Parkinson) \nand APPSEM II (Bierman and Parkinson).  6. REFERENCES [1] M. Abadi and L. Cardelli. A theory of objects. \nSpringer, 1996. [2] M. Barnett, R. DeLine, M. F\u00a8ahndrich, K.R.M. Leino, and W. Schulte. Veri.cation \nof object-oriented programs with invariants. Journal of Object Technology, 2004. [3] G.M. Bierman and \nM.J. Parkinson. Effects and effect inference for a core Java calculus. In Proceedings of WOOD, volume \n82 of ENTCS, 2004. [4] L. Birkedal, N. Torp-Smith, and J.C. Reynolds. Local reasoning about a copying \ngarbage collector. In Proceedings of POPL, 2004. [5] R. Bornat, C. Calcagno, P. O Hearn, and M. Parkinson. \nPermissions accounting in separation logic. Proceedings of POPL, 2005. [6] D. Clarke and S. Drossopolou. \nOwnership, encapsulation and the disjointness of type and effect. In Proceedings of OOPSLA, 2002. [7] \nS. Drossopoulou and M. Smith. Cheaper reasoning with ownership types. In Proceedings of IWACO, 2003. \n [8] J. Ellis and L. Ho. JDBC 3.0 speci.cation, 2001. http://java.sun.com/products/jdbc/download.html. \n [9] M. Grand. Patterns in Java, volume 1. Wiley, second edition, 2002. [10] J. Guttag. The Speci.cation \nand Applications to Programming of Abstract Data Types. PhD thesis, Dept. of Computer Science, University \nof Toronto, 1975. [11] C. A. R. Hoare. Proof of correctness of data representations. Acta Informatica, \n1(4):271 281, 1972. [12] B. W. Kernighan and D. M. Ritchie. The C Programming Language, Second Edition. \nPrentice-Hall, 1988. [13] J. Lamping. Typing the specialization interface. In Proceedings of OOPSLA, \n1993. [14] K.R.M. Leino. Data groups: Specifying the modi.cation of extended state. In Proceedings of \nOOPSLA, 1998. [15] K.R.M. Leino and G. Nelson. Data abstraction and information hiding. ACM Transactions \non Programming Languages and Systems, 24:491 553, September 2002. [16] B. Liskov and S.N. Zilles. Programming \nwith abstract data types. In Proceedings of Symposium on Very High Level Programming Languages, 1974. \n[17] B.H. Liskov and J.M. Wing. A behavioral notion of subtyping. ACM TOPLAS, 16(6):1811 1841, 1994. \n[18] R. Middelkoop, K. Huizing, and R. Kuiper. A Separation Logic Proof System for a Class-based Language. \nIn Proceedings of LRPP, 2004. [19] I. Mijajlovi\u00b4c and N. Torp-Smith. Re.nement in a separation context. \nIn Proceedings of FSTTCS, 2004. [20] J.C. Mitchell and G.D. Plotkin. Abstract types have existential \ntype. ACM Trans. Program. Lang. Syst., 10(3):470 502, 1988. [21] P.W. O Hearn. Resources, concurrency \nand local reasoning. Invited paper, in Proceedings of CONCUR, 2004. [22] P.W. O Hearn, H.Yang, and J.C. \nReynolds. Separation and information hiding. In Proceedings of POPL, 2004. [23] P.W. O Hearn, J.C. Reynolds, \nand H. Yang. Local reasoning about programs that alter data structures. In Proceedings of CSL, 2001. \n[24] D. Oheimb and T. Nipkow. Hoare logic for NanoJava: Auxiliary variables, side effects and virtual \nmethods revisited. In Formal Methods Europe, 2002. [25] D.L. Parnas. The secret history of information \nhiding. In Software Pioneers: Contributions to Software Engineering. Springer, 2002. [26] C. Pierik and \nF.S. de Boer. A syntax-directed Hoare logic for object-oriented programming concepts. In Formal Methods \nfor Open Object-Based Distributed Systems, 2003. [27] A. Poetzsch-Heffter and P. M\u00a8uller. A programming \nlogic for sequential Java. In Proceedings of ESOP, 1999. [28] U.S. Reddy. Objects and classes in Algol-like \nlanguages. Information and Computation, 2002. [29] J.C. Reynolds. Separation logic: A logic for shared \nmutable data structures. In Proceedings of LICS, 2002. [30] R. Stata. Modularity in the presence of subclassing. \nTechnical Report 145, Digital Equipment Corporation Systems Research Center, April 1997. [31] H. Yang. \nLocal reasoning for stateful programs. PhD thesis, University of Illinois, July 2001.  \n\t\t\t", "proc_id": "1040305", "abstract": "In this paper we address the problem of writing specifications for programs that use various forms of modularity, including procedures and Java-like classes. We build on the formalism of separation logic and introduce the new notion of an <i>abstract predicate</i> and, more generally, abstract predicate families. This provides a flexible mechanism for reasoning about the different forms of abstraction found in modern programming languages, such as abstract datatypes and objects. As well as demonstrating the soundness of our proof system, we illustrate its utility with a series of examples.", "authors": [{"name": "Matthew Parkinson", "author_profile_id": "81406598777", "affiliation": "University of Cambridge, Cambridge, UK", "person_id": "P707743", "email_address": "", "orcid_id": ""}, {"name": "Gavin Bierman", "author_profile_id": "81100249578", "affiliation": "Microsoft Research, Cambridge, UK", "person_id": "PP39034558", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1040305.1040326", "year": "2005", "article_id": "1040326", "conference": "POPL", "title": "Separation logic and abstraction", "url": "http://dl.acm.org/citation.cfm?id=1040326"}