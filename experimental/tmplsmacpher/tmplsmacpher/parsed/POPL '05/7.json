{"article_publication_date": "01-12-2005", "fulltext": "\n Slot Games A quantitative model of computation Dan R. Ghica Oxford University Computing Laboratory \n ABSTRACT We present a games-based denotational semantics for a quan\u00adtitative analysis of programming \nlanguages. We de.ne a Hyland-Ong-style games framework called slot games, which consists of HO games \naugmented with a new action called token. We develop a slot-game model for the language Ide\u00adalised Concurrent \nAlgol by instrumenting the strategies in its HO game model with token actions. We show that the slot-game \nmodel is a denotational semantics induced by a notion of observation formalised in the operational theory \nof improvement of Sands, and we give a full abstraction re\u00adsult. A quantitative analysis of programs \nhas many poten\u00adtial applications, from compiler optimisations to resource\u00adconstrained execution and static \nperformance pro.ling. We illustrate several such applications with putative examples that would be nevertheless \ndi.cult, if not impossible, to handle using known operational techniques. Categories and Subject Descriptors: \nF.3.2 [Semantics of Programming Languages]: Denotational semantics; C.4 [Performance of Systems]: Modeling \ntechniques. General Terms: Languages, Performance, Theory, Veri.\u00adcation Keywords: Game semantics, quantitative \nanalysis, Algol 1. INTRODUCTION 1.1 Intension and extension in programmingsemantics One of the essential \nrequirements of a Tarski-style seman\u00adtics is that two phrases should have the same denotation if and \nonly if they can be replaced in any context without changing the overall meaning of the resulting phrase \n[34]. In programming languages this requirement is called full ab\u00adstraction, and is interpreted as follows: \ntwo terms should have the same denotation if and only if they are observa\u00adtionally equivalent. The notion \nof observational equivalence is de.ned with Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 05, January 12 14, 2005, Long Beach, California, USA. Copyright \n2005 ACM 1-58113-830-X/05/0001 ...$5.00. respect to a set of term-rewriting rules which are called an \nevaluation relation or an operational semantics, and which represent a de.nition of the language. Observational \nequiva\u00adlence is de.ned as follows: for any program with a hole C[-], C[M1] terminates if and only if \nC[M2] also terminates. By program we understand a command-type closed term and by termination we understand \nthe existence of a reduction path to the (unique) command-type constant. The pioneering work of Scott \n[32], Plotkin [26], Milner [20] and others on de.ning and studying the full abstraction problem for the \nprogramming language PCF is an impor\u00adtant milestone in the history of theoretical computer science. This \nproblem turned out to be hard, remaining unsolved un\u00adtil recently [22, 13, 2, 24]. The full-abstraction \nproblem, as originally formulated, is relative to a particular de.nition of observability: the con\u00adtexts \nin which observations are to be made are programming language contexts, and the property being observed \nis ter\u00admination. Although observation in such contexts induces an important notion of equivalence, it \nis by no means a de.nitive one. For example, equivalence in programming language contexts does not entail \nequivalence in all logi\u00adcal contexts, as de.ned by some speci.cation or veri.cation logic. The reason \nis that programming logics, as opposed to languages, can be more .ne-grained in what they can dis\u00adtinguish. \nFor example, Reynolds s speci.cation logic of Ide\u00adalised Algol [27] involves a predicate called non-interference \nwhich distinguishes between terms otherwise observation\u00adally indistinguishable in the language [7]. In \nthe separation logic developed by O Hearn, Reynolds and others [23] to reason about programs with dynamically \nallocated linked structures, there exist garbage-sensitive formulations of the logic, although the existence \nof garbage is not observable in programming language contexts. It is obvious that the denotational model \ninduced by a programming logic can be substantially di.erent from that induced by the programming language \nalone. However, most of the semantic study has been focused on denotational mod\u00adels relative to programming-language \ncontexts only. But it is equally interesting to .nd correspondences between var\u00adious observational contexts \nand the denotational semantics they induce. For instance, much of the study of the process calculus CSP \nhas been undertaken along these lines. An entire hierarchy of denotations has been developed, depend\u00ading \non the speci.cation languages one uses to analyse CSP processes. [28] It is customary to think of a denotational \nsemantics as an extensional model of the language. However, the consid\u00aderations above suggest that the \nline between extension and intension in programming is quite blurry. In other words, the issue of what \na program does is sometimes essentially related to how it does it, depending on the context in which \nthe question is asked. The subtle interplay between extension and intension in programming languages, \nrelative to programming language contexts, was studied by Berry and Curien [4, etc.] and by Brookes and \nGeva [6]. The ideas of Berry and Curien had signi.cant impact on the subsequent development of Game Semantics. \n 1.2 Quantitative modeling The distinction between intension and extension becomes even more di.cult \nwhen the context of the analysis involves a quantitative assessment of resource usage, such as time, \nmemory, or power. There exist important situations where such an analysis is required: compiler optimisation, \nreal\u00adtime computation, embedded devices. In such situations a meaningful notion of equivalence must re.ect, \nin some well-de.ned way, the e.ciency of a program (or program fragment) because resource-usage becomes \nobservable. For a quantitative analysis of computational phenomena, the appropriate notion of observation \nis formally described in Sands s operational theory of improvement [30, 31, 21], which was motivated \nby the need to study program transfor\u00admations in various .-calculi. In a program transformation two properties \nare important to prove: that the transformed version of a program is more e.cient and that, otherwise, \nthere are no behavioural di.erences between the two pro\u00adgrams. In higher-order functional programs using \ncall-by\u00adname (or call-by-need) these two tasks are not trivial. In this paper we will examine a cost-sensitive \ndenotational semantics induced by the operational theory of improvement in the same way that a standard \ndenotational semantics is induced by an operational semantics. To formulate the semantic model we use \nslot games, a version of Hyland-Ong\u00adstyle game semantics [13], augmented with a novel type of action \ncalled token. The game model will be shown to be fully-abstract relative to operational improvement. \nIncorporating highly intensional concepts such as costs in a denotational semantics is quite di.cult \n(see Sec. 1.3 be\u00adlow). However, adding costs to a game model requires little revision of the game-theoretic \napparatus. The game model will be also seen to be .exible and robust in the following sense: for any \ngiven programming language there is practi\u00adcally an endless variety of quantitative analyses, depending \non the usage of what resource one needs to observe and on how the various operations of the language \nconsume that re\u00adsource. This also depends on the concrete execution model of the architecture on which \na program is run. It would be utterly impractical to have a model which is not uniformly parameterised \nby such factors. The motivation for having a denotational counterpart for the theory of improvement is \nthe standard one. Operational theories are good tools for de.ning languages or proper\u00adties of languages, \nbut they can be awkward in reasoning about them. Using operational techniques it is especially di.cult \nto reason about open terms, i.e. programs that use non-locally de.ned identi.ers. Moreover, a denotational \nse\u00admantics is compositional, allowing analyses about program fragments to be combined directly into an \nanalysis of a larger program. In order to apply operational techniques to open terms the language must \nsatisfy so-called context lemmas. The .-calculi studied by Sands satisfy such context lemmas, be\u00adcause \nthey are functionally pure. However, languages with imperative constructs are known in general not to \nsatisfy strong context lemmas. We emphasise the advantage of having a denotational the\u00adory of improvement \nby analysing a language which combines higher-order procedures (call-by-name), local state and con\u00adcurrency: \nIdealised Concurrent Algol (ICA). We do not know if the language has contextual properties strong enough \nto allow a meaningful operational theory of improvement. However, using the denotational model we can \nproduce such analyses. We conclude by showing some applications of slot games, including automated quantitative \nanalyses of resource-usage using model checking. Except for function in\u00adlining the examples we consider \nwould be di.cult, if not im\u00adpossible, to prove using any known operational approaches because they involve \nopen programs that are structurally very di.erent. However, semantic reasoning o.ers rather straightforward \nanswers. 1.3 Related work Some of the earliest work on quantitative analysis using semantics was that \nof Bjerner, Holmstr\u00a8om [5] and Wadler [36], for analysing .rst-order lazy languages. David Sands s doc\u00adtoral \ndissertation [29] extended the techniques to languages with higher-order functions. This approach was \nimproved and extended to lazy data structures by Van Stone in her dissertation [33]. A semantic-based \nanalysis of complexity (rather than costs) was undertaken by Doug Gurr in his dissertation [11], but \nhis work has a di.erent emphasis. Gurr proposes a category\u00adtheoretical framework based on monadic constructions \nin or\u00adder to allow comparison of complexity of programs even if they are written in di.erent programming \nlanguages. Pro\u00adgrams and complexity properties are interpreted in di.erent categories, with a functor \nassigning complexity to meanings of programs. A monadic calculus for costing programs with concurrency \nand arrays is also used by [14]. Our work is innovative in de.ning a notion of full abstrac\u00adtion for \nquantitative analyses through a connection with Sands s notion of improvement. Using game semantics we \nthen give a denotational model that is fully abstract.1  2. ICA AND ITS GAME MODEL Idealised Concurrent \nAlgol (ICA) is Idealised Algol ex\u00adtended with parallel composition ( || ) and binary semaphores. Semaphores \ncan be manipulated using two (blocking) prim\u00aditives, grb(-) and rls(-), which grab and respectively re\u00adlease \na semaphore. The combination of call-by-name and .ne-grained concur\u00adrency forms a programming idiom in \nwhich programming e.ciently is a nontrivial exercise. This justi.es the need for a denotational framework \nthat can support a quantitative analysis of computation. The semantics is de.ned using a (small-step) \ntransition relation S f M, s -. M. ,s . . S is a set of names of vari\u00adables denoting memory cells and \nsemaphores denoting locks; 1One of the referees pointed out recent (unpublished) inde\u00adpendent work of \nBenjamin Leperchey [18] which studies a similar game model and the categorical structures that arise \nfrom it. S f skip || skip,s -. skip,s S f skip; c, s -. c, s S f newvar x := n in c, s -. c, s S f newsem \nx := n in c, s -. c, s S f{ n1 } *n2,s -. n, s, where n = { n1 } *n2 S f if 0 then M1 else M2,s -. M1,s \nS f if n then M1 else M2,s -. M2, s, where n =0 S f !v, s . (v . n) -. n, s . (v . n) '' S f v := n,s \n. (v . n) -. skip,s . (v . n) S f grb(v),s . (v . 0) -. skip,s . (v . 1) S f rls(v),s . (v . n) -. skip,s \n. (v . 0), where n =0 '' S f (.x.M)M,s -. M[M /x],s S f .x M, s -. M(.x M),s Figure 1: Basic reduction \nrules for ICA '' s, sare states, i.e. functions s, s:S . t, and M, M' are terms. c stands for any language \nconstant (n or skip) and * for any binary operator (arithmetic-logic or sequential com\u00adposition). The \nbasic rules are given in Fig. 1. The rules for local variable and semaphore are: S,v f C[v/x],s . (v \n. n) -. C',s' . (v . n') ' S f newvar x := n in C, s -. newvar x := n' in C'[x/v],sS,v f C[v/x],s . (v \n. n) -. C',s' . (v . n') ' S f newsem x := n in C, s -. newsem x := n' in C'[x/v],s The in-context reduction \nrules are given by ' S f M, s -. M',s , S fE[M],s -. E[M'],s' where the evaluation contexts are de.ned \nby the grammar E ::= [-] | C ||E |E|| C |E *M | c* E | if E then M else N | !E|EM |E := n | V := E | \ngrb(E) | rls(E). Other constructs (while, for, let, or etc.) can be easily introduced as syntactic sugar. \nWe consider an angelic notion of termination: we say that a term M terminates in state s, written M, \ns ., if there ex\u00ad ' ists a terminating evaluation at start state s: .s, M,s -. * c, s', with c . t .{skip}. \nIf M is closed and M, \u00d8. we write M .. We de.ne the observational approximation re\u00adlation contextually: \nG f M1 ~ M2 by .C[-]: com, C[M1] . implies C[M2] ., where C[Mi] are closed programs of com ~ type. Observational \nmay-equivalence (G f M1 = M2) is de.ned as G f M1 ~ M2 and G f M2 ~ M1. In [10] we have given a game \nmodel which is fully abstract for .and ~Below we give a sketch of the model. =. An arena A is a triple \n(MA,.A, fA) where MA is a set of moves, .A : MA .{ O, P }\u00d7{ Q, A } is a function determin\u00ading for each \nm . MA whether it is an Opponent or a Propo\u00adnent move, and a question or an answer. We write .OP ,.QA \n~ AA for the composite of .A with respectively the .rst and sec\u00adond projections. fA is a binary relation \non MA, called en\u00adabling, satisfying: if m fA n for no m then .A(n)=(O, Q), .OP if mn then .OP A (n), \nand if fA fAA (m)= mn then .QA A (m)= Q. If m fA n we say that m enables n. We shall write IA for the \nset of all moves of A which have no enabler; such moves are called initial. Note that an initial move \nmust be an Opponent question. The product (A \u00d7 B) and arrow (A . B) arenas are de.ned by: MA\u00d7B =MA + \nMB .A\u00d7B =[.A,.B] fA\u00d7B = fA + fB MA.B =MA + MB PO QA .A.B =[(.A ,.A ),.B ] fA.B = fA + fB + { (b, a) \n| b . IB and a . IA } where .PO (m)= O i. .OP (m)= P . AA An arena is called .at if its questions are \nall initial (con\u00adsequently the P-moves can only be answers). In arenas used to interpret base types all \nquestions are initial and P-moves answer them as detailed in the table below. Arena O-question P-answers \n[com] run ok [exp] q n [var] read write(n) n ok [sem] grb rls ok ok  A justi.ed sequence in arena A \nis a .nite sequence of moves of A equipped with pointers. The .rst move is initial and has no pointer, \nbut each subsequent move n must have a unique pointer to an earlier occurrence of a move m such that \nm fA n. We say that n is (explicitly) justi.ed by m or, when n is an answer, that n answers m. Note that \ninterleavings of several justi.ed sequences may not be justi.ed sequences; instead we shall call them \nshu.ed sequences. If a question does not have an answer in a justi.ed sequence, we say that it is pending \n(or open) in that sequence. In what follows we use the letters q and a to refer to question-and answer\u00admoves \nrespectively, m denotes arbitrary moves and mA a move from MA. In order to constitute a legal play, a \njusti.ed sequence must satisfy a well-formedness condition which re.ects the static style of concurrency \nof our programming language: any process starting sub-processes must wait for the chil\u00addren to terminate \nin order to continue. In game terms, if a question is answered then that question and all questions justi.ed \nby it must have been answered (exactly once). Formally, the de.nition is: Definition 1. The set PA of \npositions (or plays) over A consists of the justi.ed sequences s over A which satisfy the two conditions \nbelow.  FORK : In any pre.x s= \u00b7\u00b7\u00b7 q \u00b7\u00b7\u00b7 m of s, the ques\u00adtion q must be pending before m is played. \n WAIT : In any pre.x s= \u00b7\u00b7\u00b7 q \u00b7\u00b7\u00b7 a of s, all ques\u00adtions justi.ed by q must be answered. For two shu.ed \nsequences s1 and s2, s1 I s2 denotes the set of all interleavings of s1 and s2. For two sets of shu.ed \nX sequences S1 and S2, S1 I S2 = s1 I s2. Given s1.S1,s2.S2 X, Xi+1 a set X of shu.ed sequences, we de.ne \nX0 == Xi I X. Then X@, called iterated shu.e of X, is de.ned X to be i.N Xi . We denote O-moves by o. \nA strategy s is O-complete if s . s and so . PA imply so . s. Definition 2. A strategy s on A (written \ns : A) is a pre.x-closed O-complete subset of PA. Strategies s : A . B and t : B . C are composed in \nthe standard way, by considering all possible interactions of positions from t with shu.ed sequences \nof s@ in the shared arena B then hiding the B moves. More formally, let u be a sequence of moves from \narenas A, B and C with justi.cation pointers from all moves except those initial in C such that pointers \nfrom moves in C cannot point to moves in A and vice versa. De.ne u IB, C to be the subsequence of u consisting \nof all moves from B and C (pointers between A-moves and B-moves are ignored). u IA, B is de.ned analogously \n(pointers between B and C are then ignored). We say that u is an interaction sequence @ of A, B and C \nif u IA, B . PA.B and u IB, C . PB.C . The set of all such sequences is written as int(A, B, C). Then \nthe interaction sequence s i t of s and t is de.ned by s i t = { u . int(A, B, C) | u IA, B . s@,u IB, \nC . t } Suppose u . int(A, B, C). De.ne u IA, C to be the sub\u00adsequence of u consisting of all moves from \nA and C only together with new pointers from all moves mA . MA to any (initial) moves mC . MC such that \nthere exist (initial) moves mB . MB with pointers from mA to mB and from mB to mC : \u00b7\u00b7\u00b7 mA \u00b7\u00b7\u00b7 mB \u00b7\u00b7\u00b7 \nmC \u00b7\u00b7\u00b7 IA, C = \u00b7\u00b7\u00b7 mA \u00b7\u00b7\u00b7 mC \u00b7\u00b7\u00b7 Then the composite strategy s; t is de.ned to be s; t = { u IA, C | \nu . s i t }. The model consists of saturated strategies only: the sat\u00aduration condition stipulates that \nall possible (sequential) observations of (parallel) interactions must be present in a strategy: actions \nof the environment can always be observed earlier if possible, actions of the program can always be ob\u00adserved \nlater. To formalise this, for any arena A a preorder . on PA is de.ned as the least transitive relation \n. satisfying s0 \u00b7 o \u00b7 s1 \u00b7 s2 . s0 \u00b7 s1 \u00b7 o \u00b7 s2 and s0 \u00b7 s1 \u00b7 p \u00b7 s2 . s0 \u00b7 p \u00b7 s1 \u00b7 s2 for all s0,s1,s2 \nwhere o is an O-move and p is a P-move. In the above pairs of positions moves on the lhs of . have the \nsame justi.er as on the rhs. The two saturation conditions, in various formulations, have a long pedigree \nin the semantics of concurrency. For example, they have been used by Udding to describe propa\u00adgation \nof signals across wires in delay-insensitive circuits [35] and by Josephs et al to specify the relationship \nbetween in\u00adput and output in asynchronous systems with channels [15]. Laird has been the .rst to adopt \nthem in game semantics, in his model of Idealised CSP [17]. Definition 3. A strategy s is saturated i. \ns . s and s ' . s imply s ' . s. Arenas and saturated strategies form a Cartesian closed cat\u00adegory Gsat \nin which Gsat(A, B) consists of saturated strate\u00adgies on A . B. The identity strategy is de.ned by sat\u00adurating \nthe alternating positions s . PA1.A2 such that . t .even s, t IA1 = t IA2, which gives rise to the be\u00adhaviour \nof an unbounded bu.er. Let us denote by strat(P ) the least saturated strategy gen\u00aderated by a set of \nplays P , i.e. its saturated set of O-complete pre.xes. The constants of ICA are interpreted by: [-; \n- : com . .0 . .1] = op; = strat(q1 run ok q0 a0 a1) [- || - : com0 . com1 . com2] = op || = strat(run2 \nrun0 run1 ok0 ok1 ok2) [- := - : var . exp . com] = op := = strat(run qn write(n) ok ok) !- : var . exp] \n= op! = strat(q read nn) [ grb : sem . com] = strat(run grb ok ok) = opgrb [rls : sem . com] = strat(run \nrls ok ok) = oprls Stateful behaviour is induced by local variable and semaphore binding: [newvar x \n:= n] = celln N N * ** = stratqq (read n)( (write(i) ok (read i) )) aa i=0 [newsem x := 0] = lock0 = \nstratqq (grb ok rls ok) * (grb ok + E) aa [newsem x := 1] = lock1 = stratqq (rls ok grb ok) * (rls ok \n+ E) aa. This is the standard way of introducing stateful behaviour in game models [3]. Free variables \nof type var are in general not constrained to stateful behaviour, i.e. the last variable written is not \nnecessarily the next one read. Only when a variable of this type is bound to new is such behaviour enforced, \nthrough composition with a strategy that behaves like a memory cell. For semaphores, the proper locking \nbehaviour consists of strictly alternating grab and release operations. As shown in [10], Gsat is fully \nabstract for ~in the sense = mentioned below. Let comp(s) be the set of non-empty complete plays of \na strategy s. Theorem 1 (Full abstraction). G f M1 ~ M2 .. comp([G f M1]) . comp([G f M2]). 3. SLOT \nGAMES The game model presented in the previous section is fully abstract relative to a notion of observability \nde.ned by (an\u00adgelic) termination in programming-language contexts. All other behaviour is abstracted \naway. For example, there exist only two identi.able behaviours for closed terms of command type: the \nterminating command and the non\u00adterminating command. As a consequence, all sorting pro\u00adgrams have exactly \nthe same semantic model (insofar as they are correct), irrespective of how e.cient or ine.cient they \nare. For a quantitative account of the behaviour we must in\u00adtroduce a new observable in the model, with \nthe property that, unlike moves, this new observable cannot be hidden through composition or otherwise. \nThis is essential if we wish to model the consumption of a resource which is not re-usable, such as time \nor power, and suggests that resource consumption should not be modeled by moves. Moves can always be \nhidden through composition and they should be used only to model the input-output interactive behaviour \nof the program. We therefore expand the game paradigm by introducing a new kind of action, called token-action, \nand denoted by the \u00ae@ reserved symbol $ . It represents the intuition that, in order to continue playing, \none of the protagonists needs to make a payment. The analogy is borrowed from slot machines: at various \npoints in the game one is required to insert to\u00adkens in order to be allowed to continue playing. We denote \n\u00ae@ sequences of n token-actions by n . The game apparatus introduced so far does not have to change too \nmuch in order to accommodate token-actions. We only need to introduce the new concept of strategy-with\u00adcosts: \nDefinition 4. A strategy-with-costs s on an arena A is a pre.x-closed O-complete set of sequences such \nthat there exists an A-strategy s such that .s . s, s IMA . s . To wit, a strategy-with-costs is simply \na strategy instru\u00ad @ mented with the distinguished token actions \u00ae $. We call s the underlying strategy \nof s; we also call s = s I MA the underlying position (or play) of s. We call @ \u00ae@ |s| = n, where s \nI\u00ae = the cost of s. $ n Sequences in strategies-with-costs, which we shall call plays\u00ad s I \u00ae with-costs, \ntherefore are interleavings of the form @n , where s is a play, and are interpreted as play s has cost \nn . Note that plays-with-costs give information not only about what the overall costs are, but also about \nthe moments when costs are incurred, relative to moves. Strategies-with-costs s : A . B and t : B . C \nare composed in the standard way, by considering all possible interactions of plays-with-costs from t \nwith shu.ed plays\u00ad @ with-costs of sin the shared arena B then hiding the B moves. Notice that token \nactions, not being moves, do not participate in the composition. Also, notice that although the B moves \nare hidden, no tokens are ever hidden. There\u00adfore tokens can only accumulate through composition. Example \n1. Consider strategies-with-costs s : com1 . (exp2 . exp3) and t :(exp2 . exp3) . (exp4 . exp5): \u00ae \u00ae@ \ns = strat(q3 run1 @2 ok1 q2 512 33) \u00ae \u00ae@ t = strat(q5 q3 q2 q4 14 @6 12 33 235) Such plays may occur \nfor example in computing terms which approximate p : com f .x.p; x +2 : exp . exp and f : exp . exp,x \n: exp f f(x): exp, respectively. The cost of @\u00ae 2 in s can be interpreted as a cost incurred by the non-local \ncommand p, and so on. The interaction sequence of the two strategies has the fol\u00adlowing complete play-with-costs \n\u00ae \u00ae@ @ \u00ae@ @ \u00ae q5 q3 run1 2 ok1 q2 5 q4 14 612 33 235 After hiding the moves from the shared component \nexp2 . exp3 we are left with \u00ae \u00ae@ @ \u00ae@ @ \u00ae s; t = strat(q5 run1 2 ok1 5 q4 14 6 235) \u00ae@ \u00ae@ @ \u00ae = strat(q5 \nrun1 2 ok1 5 q4 14 835) 3.1 A case study In this section we informally present a particular cost\u00adanalysis \nof ICA, in order to illustrate the model of the pre\u00advious section. As mentioned in the introduction, \nfor any given language there are many quantitative analyses that make sense. They are relative to the \nresource we wish to track and the op\u00aderational speci.cs of the architecture on which a program is executed. \nSuppose we wish to analyse ICA in an envi\u00adronment where there is signi.cant overhead in the follow\u00ading \noperations: assignment and dereferencing (because of memory access), parallel composition (because of \nprocess management) and semaphore manipulation (because of lock management). We do this by modeling these \noperations using strategies-with-costs with the sets of complete plays\u00adwith-costs of the following shapes. \nWe use [ - ] to denote interpretation in the slot-game model. \u00ae@ [ := ] = strat(run2 $ q1 n1 write(n)0 \nok0 ok2) \u00ae@ [!] = strat(q $ read nn) [ || ] = strat(run2 \u00ae@4 run0 run1 ok0 ok1 ok2) \u00ae@ [grb] = strat(run1 \n2 grb0 ok0 ok1) \u00ae@ [rls] = strat(run1 2 rls0 ok0 ok1). For all other constructs, [ - ] = [-]. In our \nparticular cost model, the overhead of memory ac\u00adcess is the unit, that of parallel composition is 4 \nunits and that of semaphore manipulation is 2 units. Using this cost model we can achieve precise quantitative \ncomparisons of programs. Consider for example the two programs: M1 = test : exp1, proc : exp2 . com3 \nf new x := 0 in while test do x := 1; proc(!x): com4 and M2 = test : exp1, proc : exp2 . com3 f while \ntest do proc(1) : com4. Using the ICA game model we can show they are obser\u00advationally equivalent. Using \nthe cost model we can (infor\u00admally) see that the former is less e.cient that the latter. The .rst program \nis modeled by: @ [M1] = strat{run4 (q1 n1 \u00ae run3 q l \u00ae@ l 1l 2 ok3)k q1 01 ok4 $ 2 | k, l, n . t,n =0}, \n The second program is modeled by: ll k [M2] = strat{run4 (q1 n1 run3 q2 12 ok3)q1 01 ok4 | k, l, n . \nt,n =0}. This means that for any .xed k and l, the second program will save k\u00d7(l+1) units. Informally, \nk represents the number of iterations of the while-loop and l the number of times the procedure uses \nits argument, and both are controlled by the S f skip || skip,s -.kpar skip,s S f skip; c, s -.kseq c, \ns S f newvar x := n in c, s -.kvar c, s S f newsem x := n in c, s -.ksem c, s S f{ n1 } *n2,s -.k* n, \ns, where n = { n1 } *n2 S f if 0 then M1 else M2,s -.kif M1,s S f if n then M1 else M2,s -.kif M2, s, \nwhere n =0 S f !v, s . (v . n) -.kasg n, s . (v . n) ' ,s . (v . n) -.kder ' S f v := n skip,s . (v . \nn ) S f grb(v),s . (v . 0) -.kgrb skip,s . (v . 1) S f rls(v),s . (v . n) -.krel skip,s . (v . 0), where \nn =0 S f (.x.M)M ' ,s -.kapp M [M ' /x],s S f .x M, s -.kapp M (.x M),s Figure 2: Basic reduction rules \nwith costs for ICA environment (O), hence unknown. So the second program saves k assignments and k \u00d7 \nl dereferencings. Any play of the .rst program can be found in the second program, but with no costs. \nWe can (informally) conclude that the latter is an improvement of the former if this was the result \nof a compiler optimisation, such as constant prop\u00adagation, then we can also conclude that the optimisation \nwas successful. We will make the notion of improvement precise, operationally and denotationally, in \nthe following section, and will show that the two notions coincide through a full abstraction result. \n  4. AN OPERATIONAL THEORY OF IMPROVEMENT FOR ICA Sands [30, 31] and Moran and Sands [21] have introduced \nan operational theory of improvement to analyse quantita\u00adtively and qualitatively the e.ect of program \ntransforma\u00adtions in various purely functional languages. We will adapt the theory of improvement to ICA. \nSands assigns a unitary cost to each reduction step. As argued previously, it makes sense to assign di.erent \n(non\u00adnegative) costs to each reduction rule. We decorate the re\u00adduction rules in Fig. 1 with costs, as \nin Fig. 2. Assigning the same cost kapp to application and each iteration of the .x-point operator is \nnot essential but it makes sense in most execution models. Rules for local variables, semaphores and \nrecursion do not incur additional costs. The in-context reduction rules prop\u00adagate the costs: S f M, \ns -.n M ' ,s ' , S fE[M ],s -.n E[M ' ],s ' where the evaluation contexts E[-] are as before. We take \nthe transitive closure of the reduction relation by adding the costs along the derivation: S f M, s \n-.n M ' ,s ' '' S f M, s .n M,s ' '' '' .n'' '' S f M, s .n M,s S f M,s M,s ' . S f M, s .n+nM'' ,s '' \n We introduce costs in the notion of termination. We write M, s .n if there exists a constant c and state \ns ' such that ' S f M, s .n c, s . If M is closed and M, \u00d8.n we write ' M .n . If M .n , n = n ' we \nwrite M .=n. Definition 5 (Improvement). We say M may be im\u00adproved by N, written M . N if .C[-], if C[M] \n.n then C[N] .=n . Note that the de.nition of improvement is angelic, just like the de.nition of termination. \nThe de.nition above entails that N is both more e.cient and terminates more often than M . An operational \ntheory of improvement relies crucially on the existence of a strong enough context lemma. Indeed, the \nvarieties of .-calculi analysed by Sands satisfy the following context lemma: Lemma 1 (Context [21]). \nFor all terms M, N, of the lazy lambda calculus, if E[M ] .E[N] for all evaluation con\u00adtexts E[-], then \nM .N. That means that only con.guration contexts of a certain form, with the hole [-] occurring exactly \nonce need be con\u00adsidered. This reduces the number of contexts to be consid\u00adered in proofs requiring induction \non contexts. In general it is known that purely functional program\u00adming languages satisfy strong context \nlemmas. However, formulating context lemmas for imperative programming languages is more di.cult (see \n[25] or [19]). It is not known whether the language ICA satis.es a strong enough context lemma to allow \nfor a usable theory of improvement to be developed along operational lines. We will pursue an alter\u00adnative, \nsemantic, approach. 5. A SLOT-GAME SEMANTICS OF IMPROVEMENT FOR ICA To create a slot-game model we add \nquantitative informa\u00adtion to the game-semantic model, in a way that is consistent with the operational \nsemantics with costs of the previous section. If s, t are sequences and m a move, let ms. t = mts, i.e. \ninsert t into ms just after the .rst move m. If s is a strategy, we de.ne s.t = {s.t | s . s}. The slot \ngame model is de.ned by instrumenting strate\u00adgies with tokens representing costs incurred during execu\u00adtion. \nSome of the strategies-with-costs are shown in Fig. 3. The operator * ranges over the binary and unary \noperators of the language, and op* is its game-semantic interpreta\u00adtion. The strategy ev is the evaluation \nmorphism in Gsat . . is a relabelling of moves which also represents the curry\u00ading isomorphism in Gsat \n. Finally, cell and lock are the Gsat strategies used to interpret stateful behaviour. The interpretation \nof the .x-point operator is a little more complicated. Let [.x. :(.1 . .2) . .3] be the game-semantic \ng [G f MN : .] =[G f M : . ' . .]; [G f N : . ' ];(ev kapp ) ' ' [G f .x.M : . . .] =.[G,x : . f M : \n.] [G f M1 *M2 : .] =[G f M1 : .1], [G f M2 : .2];(op* @k* ) @ [G f *M : .] = [G f M : . ' ];(op* k* \n) [G f newvar x := n in N] =. [G,x : var f M : .] ;(cell. g ) n kvar g [G f newsem x := n in N] =.[G,x \n: sem f M : .];(lock. ksem ) n Figure 3: Slot-game valuations interpretation of .x-point at type .. \nThe strategy-with-costs g [.x.] is obtained by inserting kapp before each opening question in type component \n.2. For constants and free variables the interpretations are the same as in the game model: [n] = [n] \n= strat(qn) [skip] = skip] = strat(run ok) [x : . f x : .] = [ x : . f x : .] = idl.]. Note that we attach \nthe costs of a strategy just after the initial question, with the exception of .x-point, which incurs \nthe cost at each iteration. This is only a matter of conven\u00adtion. For our analysis, it is not relevant \nat what point in time costs are incurred. In fact, because strategies for ICA are characterised by their \nsets of complete plays, our model could be presented by assigning global costs to plays rather than interleaving \ntokens into plays. However, this presenta\u00adtion would be cumbersome for several reasons. The de.ni\u00adtion \nof composition would become more complicated. Also, identifying languages or fragments of languages admitting \n.nitary representations would become more di.cult. Fi\u00adnally, such a presentation of the model would not \nscale at all to models where strategies are not characterised by com\u00adplete plays or to more re.ned analyses \nthat may exploit the possibility of recognising the temporal signi.cance of occur\u00adrences of costs. In \nthe following, we relate slot games to the operational notion of improvement. For the purpose of relating \nour model with the operational semantics we need to recover explicit state. We represent a state s :S \n. t by a strategy. [s]\u00df :[.1] . \u00b7\u00b7\u00b7 . [.m] . [\u00df]. [\u00df] . [s]\u00df .rst copies the initial O-question q to \nthe other [\u00df] sub\u00adgame. Then it behaves in each .i component like suitably initialised cell. and lock. \nstrategies. Finally, when the copy of the initial question is answered by O, [s]answers ni ni \u00df the initial \nquestion with the same answer. This strategy does not incur any costs. The strategy with costs [S f M \n: .]; [s]\u00df will be the interpretation of S f M : \u00df at state s. If clear from the context we omit the \n\u00df superscript. Lemma 2. If S f M, s -.n M ' ,s ' is a basic reduction then [S f M]; [s] = [S f M ' ]; \n[s ' ] \u00ae@n. Proof: Immediate, for each basic reduction rule with costs, from the de.nitions. 0 Lemma \n3. If S f M, s -.n M ' ,s ' is a reduction then @ there exists a strategy with costs s . [S f M ]; [s] \nI \u00aen such ' ]; [s ' that s . [S f M ]. Proof: If S f M, s -.n M ' ,s ' then there must be an evaluation \ncontext E such that M = E[M0], M ' = E[M0' ], and S f M0,s -.n M0' ,s ' a basic reduction rule. The argument \nis by induction on evaluation contexts E. Lem. 2 gives the base case; the inductive cases require an \nanalysis of the interaction sequences in [S f M]; [s] similar to that in the analogous lemma of [10]. \n0 n '' Lemma 4. If S f M, s . M,s then there exists a @ strategy with costs s . [S f M]; [s] I \u00aen such \nthat s . [S f M ' ]; [s ' ]. Proof: By induction on the derivation of S f M, s . n M ' ,s ' . The base \ncase is Lem. 3, and the induction is imme\u00addiate. 0 An immediate corollary of Lem 4 is a soundness result: \n Lemma 5 (Soundness). If M, s .n then .t . comp[S f  M]; [s]such that |t| = n. To wit, if a term M in \nstate s may be evaluated at cost n then the slot-game model of the term contains a play which uses precisely \nn tokens. Using logical relations, along the same lines as in [9], we can also show the converse: Lemma \n6 (Computability). If .t . comp[S f M]; [s] such that |t| = n then M, s .n . Soundness and computability \nimmediately entail: Lemma 7 (Computational adequacy). M, s .n if and  only if .t . comp[S f M]; [s]such \nthat |t| = n. We can now relate a semantic notion of improvement to the operational one. Let S be the \ngame with a single question q and answer a, such that q fS a. We consider the strategies-with-costs T \nfor S such that comp(T) has only complete plays of the @ form q \u00aena. If the shortest complete play in \na strategy\u00adwith-costs uses n tokens we say |s| = n. For two strategies T, T ' , if |T| = |T ' | we say \nT . We denote by . the T ' strategies-with-costs without complete plays. We also have .. and for any \nT, .T. The strategy . is the least de.ned strategy therefore any other strategy represents an improvement \nof it. Definition 6 (Semantics of improvement). Given two strategies-with-costs s, t on arena A we say \nthat s is im\u00adproved by t, denoted by st , if for any strategy-with-costs a on A . S we have s; at ; a. \nNote that improvement is de.ned quite similarly to the in\u00adtrinsic preorder on games. It is straightforward \nto show that improvement represents a partial order on strategies, and that composition of strate\u00adgies \nis monotonic relative to it. For our language we can also give a more e.ective char\u00adacterisation of improvement: \nt improves s if it contains all its plays but with smaller costs. Lemma 8 (Characterisation). st , if \n.s . comp(s), .t . comp(t ) such that s = t and |s|=|t|. Theorem 2 (Soundness of improvement). For any \nterms G f M, N : ., if [M][N ] then MN. Proof: Suppose that for some context C[-] we have C[M] .n . By \nadequacy, .s . comp [C[M]] such that |s| = n. From [M][N], using the monotonicity of the semantics, it \nfollows that [C[M]][C[N]]. Together these imply that .t . comp [C[N]] such that |t| = m = n. Using adequacy \nit follows C[N] .m, which implies MN . 0 For full abstraction we can rely on de.nability in the cost\u00adfree \nmodel: Theorem 3 (Gsat definability [10]). For any type . and play in s . Pthere exists a term M : . \nsuch that [M] = strat(s). l.] There is no similar de.nability result for slot-games, i.e. we cannot always \n.nd terms that use an arbitrary number of tokens in an arbitrary fashion. This is because we cannot always \nconstruct terms which are arbitrarily e.cient. There is a minimum amount of tokens that must be spent \nin order to produce any given trace, but no more than the amount of tokens used by the terms produced \nby the de.nability algorithm for Gsat (as given in [10]). Also note that we do not insist on a particular \nscheduling of costs relative to moves, as long as we control the overall cost of a play. However, de.nability \nfor underlying strategies is enough to prove the following: Theorem 4 (Full abstraction of improvement). \nFor any terms G f M, N : ., [M ][N] i. MN. Proof: The left-to-right direction is soundness of improve\u00adment. \nFor the right-to-left direction we prove by contradic\u00adtion. Assume [M][N]. There are two cases: 1. [M] \n. [N] , i.e. the underlying strategy interpreted M is not included into that for N. Using full abstrac\u00adtion \nfor may-termination for ICA it follows immedi\u00adately that M ./N , hence MN, which contradicts ~ the hypothesis. \n2. .s . [M],t . [N] such that s = t = u and |s| < |t|. Let us consider a strategy (without costs) in \nGsat , s = strat(v) where v is a play in [.] . S such that strat(u); s = strat(qa). From the de.nability \ntheo\u00adrem for ICA (Thm. 3) we know that there exists a term M : . . com, which can be written also as \nx : . f C[x]: com, such that [C[x]] = s . Let s = [C[x]]. By de.nition of semantic improvement and by \nmonotonic\u00adity of composition, [M]; s [N]; s. But [M]; s = [M]; [C[x]] = [C[M]] and [N]; s = [N]; [C[x]] \n= [C[N]]. This implies [C[M]][C[N]]. By adequacy of im\u00adprovement (Lem. 7) this implies C[M] C[N] there\u00adfore, \nby de.nition, MN which contradicts the hy\u00adpothesis. 0 This result shows that the operational and denotational \ntheories of improvement are identical. Both theories are parameterised by the costs of the basic operations \nof the language in a .exible and uniform way. 5.1 Strong improvement In practice it is also useful to \nwork with a stronger notion of improvement which compares the costs of programs which are otherwise equivalent. \nDefinition 7 (Strong improvement). We say that M is strongly improved by N, written M . N, if MN and \nM ~ = N. Definition 8 (Semantics of strong improvement). We say that strategy s is strongly improved \nby t , written s . t , if st and s = t . It is straightforward to see that the semantics of strong im\u00adprovement \nis also fully abstract. Theorem 5 (Full abstr. of strong improvement). For any terms G f M, N : ., [M] \n. [N] i. M . N. Proof: We use the full abstraction of improvement and the full abstraction of the game \nmodel, along with the observa\u00adtion that [M ] 0 = [M].  6. APPLICATIONS AND EXAMPLES In Sec. 3.1 we \nlooked at a concrete example of improve\u00adment. In this section we will consider several more general examples \nof improvement for programs (or program frag\u00adments). We will not attempt to develop a full-blown general \nsyntactic theory of improvement akin to Moran and Sands tick algebra because the equational theory of \na language such as ICA, which combines higher order procedures with local state, semaphores and concurrency \nis not known and likely hard to de.ne. However, we can .nd interesting, albeit ad hoc, improvement schemata \nand prove their soundness se\u00admantically (cf. [16]). 6.1 Simple general laws ICA has few simple general \nschemata for improvement. Two of them are function inlining and dead variable elimi\u00adnation. Function \ninlining (strong) improvement is: (.x.F )(M) . F [x/M]. Proof: [(.x.F )(M)] = [(.x.F )(M)] = [F [x/M]] \n= [F [x/M]] . [(.x.F )(M)] = ([.x.F ], [M]);(ev kg app ), but [F [M/x]] = ([.x.F ], [M]); ev. This means \nthat .s . [(.x.F )(M )] s.t. |s| = k, .t . [F [M/x]] such that |t| = k + kapp. As ex\u00adpected, for any \nplay we save the cost of one application. So [(.x.F )(M)].[F [x/M ]] and we can use the full abstraction \nresult. 0 The result above is tied to our particular cost assignment scheme for application, which assigns \nthe same overhead cost to a function notwithstanding its strictness properties. For example, the same \noverhead is incurred by function .x.0 and .x.x + x. If this is considered unrealistic for a par\u00adticular \nexecution (or compilation) model we can give the evaluation strategy ev at type .1 . (.1 ' . .2) . .2 \n' a di.er\u00ad g ent cost assignment, for example adding a cost kapp after each opening move in .1. This \nwould make functions in\u00adcur costs proportional to the number of times they use the argument. To preserve \nthe full abstraction property of the model a similar change to the cost scheme must be applied to the \noperational semantics as well. Dead variable elimination (strong) improvement is: newvar x in C I C, \nx . freevar(C). gkvar Proof: [newvar x in C] = [C];(cell ). However, since variable x does not occur \nfree in C, [C]; cell = [C]. It gkvar follows that [newvar x in C] = [C] , so obviously [newvar x in C] \nI [C], and we can use full abstraction. 0  6.2 Local variable manipulation This transformation re.ects \nthe intuition that operations only involving a local variable may be ignored: newvar x in F (X; n) F \n(n),n . t if x . freevar(F ) and freevar(X)= {x}. Note that in this situation the relation is not one \nof strong improvement, be\u00adcause the removed operation X may cause divergence. Proof: freevar(X)= {x} \nimplies that comp([X; n]) has only sequences of the form qsn where s consists only of \u00ae moves in [var] \nand @$ . Composition with cell will therefore @produce a strategy with complete plays of the form q \u00aekn \nonly. [G f newvar x in F (X; n): com] = [G,x : var f F (X; n): com]; cell ' x = ([G,x : var f F : exp \n. com], [G,x : var f X; n : exp]); ev ' ; cell ' x. gkvar ' g where cell ' x = cell and evx = ef kapp \nEvery play in [G,x : var f F (X; n): com] is an inter\u00adleaving of a play from [F ] and several plays from \n[X; n]. Since freevar(V ) f x, composition with cell ' x has no e.ect over these plays. On the other \nhand freevar(X; n)= {x}, so composition with cell ' x will hide all actions on variable x, @ leaving \nonly plays of the form q \u00aekn or incomplete plays. [G f newvar x in F (X; n): com] ' .([G f F : exp . \ncom], strat(q \u00ae@kn)); ev I ([G f F : exp . com], strat(qn)); ev ' = [G f F (n): com]. Which implies: \n[G f newvar x in F (X; n): com][G f F (n): com]. Then we use the full abstraction result. 0  6.3 Forced \nevaluation In call-by-name languages one major source of ine.ciency is the fact that an argument is unnecessarily \nre-evaluated several times. If an argument computes a value and it has no side-e.ects then we can improve \na program by storing its value in a local variable: f (E) I newvar x in x := E; f(!x). This is subject \nto the following assumptions: f is strict: fO ~=O @ E has no side-e.ects: [E] = strat(q \u00aekn) for some \nk, n . t  the overhead of local variable manipulation and deref\u00aderencing are (relatively) negligible: \nkvar = kder = 0.  Proof: We use qf ,nf to indicate moves in the argument of function f. Using the semantic \nde.nitions, and the fact that f must be strict, N \u00ae@ [f(E)] = strat run (qf knf ) ok . i>01=j=i On the \nother hand, [x := E; f (!x)] = @ strat run \u00aek write(n)x okx N (qf readx (ni,j )x (ni,j )f ) ok , i>01=j=i \n since the cost of ! is deemed negligible. Upon composition with cell we have: [newvar x in x := E; f(!x)] \n= @ N strat run \u00aek (qf nf ) ok . i>01=j=i It is obvious that [f (E)].[newvar x in x := E; f(!x)], since \n@ the cost \u00aek is only incurred exactly once in the rhs. Note that the strictness of f is important: \nif the function does not evaluate the argument then f(E) does not incur the cost of E at all, whereas \nnewvar x := E in f(!v) does; moreover, if E diverges the former term does not diverge, but the latter \ndoes. 0 Since f : exp . com is a free identi.er, the condition f is strict must be interpreted as f must \nbe bound only to a strict function F . We have chosen to work with an identi\u00ad.er (rather than a term \nF , as in the previous example) for presentational reasons, because the proof is clearer. Since we are \nin a call-by-name language, it is indi.erent whether we are working with a term or an identi.er, and \nwe will choose whatever is more convenient. This should not cause any confusions. 6.4 Loop unrolling \nA common compiler optimisation is to unroll for-loops. newvar x := 0 in while(x<n) do C; x := !x +1 I \nC; \u00b7\u00b7\u00b7 ; C, x . freevar(C)   ' \u00b7\u00b7 C n times The proof of this is immediate from the semantic de.nitions. \n6.5 Sequentialisation In our cost model parallel execution may incur additional costs. Therefore, it \nis an improvement wherever possible to execute a program sequentially rather than concurrently. For example: \nnewsem s := 0 in (grb(s); C1; rls(s)) || (grb(s); C2; rls(s)) C1; C2 or C2; C1,s . freevar(C1,C2) where \n[or : com1 . com2 . com] = strat{run run1 ok1 ok, run run2 ok2 ok} is nondeterministic choice. Introducing \nthis does not a.ect in any way the full abstraction result. Proof: Let us assume for simplicity the only \nrelevant costs are those associated with semaphore manipulation. Then we have: [(grb(s); C1; rls(s)) \n|| (grb(s); C2; rls(s))] = strat{run (grb \u00ae@ $ ok c1 rls \u00ae@$ ok ok I grb \u00ae@$ ok c2 rls \u00ae@$ ok) ok | run \nci ok . strat([Ci])} Upon composition with lock we get [LHS] = strat{run \u00ae@$ c1 @\u00ae2 c2 @\u00ae$ ok, run \u00ae@$ \nc2 @\u00ae2 c1 @\u00ae $ ok | run ci ok . strat([Ci])}, whereas [RHS] = strat{run c1 c2 ok, run c2 c1 ok | run \nci ok . strat([Ci])}. 0  6.6 Abstract data types One of the advantages of a semantic model is that it \nallows us to reason about open programs. A particularly interest\u00ading kind of open programs are abstract \ndata types (ADT). In this case, the missing part of the program is the context in which the ADT is used. \nIn [1] we have examined how games-based techniques can be used to model-check safety properties of ADTs. \nWe can use a similar approach to rea\u00adson about improvement of ADTs. Let us consider the following toy \nADT implementing a switch, which has two methods in its interface: on evaluate the state of the switch, \nwhich is initially o. .ick change the state of the switch to on. Let us look at two possible implementations \nof this switch ADT: Method Implementation (1) Implementation (2) on grb s;!x> 0; rls s grb s;!x> 0; rls \ns .ick grb s; x := !x + 1; rls s grb s; x := 1; rls s, where v is a global variable and s is a global \nsemaphore. It is clear that the second implementation is an improvement, since it changes the state using \nonly one assignment as op\u00adposed to an assignment, an addition and a dereferencing. This can be formalised \nas: context : exp . com . com f newvar x := 0 in newvar x := 0 in newsem s := 0 in newsem s := 0 in \nlet on be let on be grb s;!x> 0; rls s in grb s;!x> 0; rls s in let .ick be let .ick be grb s; x := !x \n+ 1; rls s in grb s; x := 1; rls s in context(on)(.ick) context(on)(.ick). This is proved directly from \nthe semantic de.nitions, like in the previous examples. More complicated examples can be dealt with similarly \nand, subject to several assumptions, even veri.ed automatically, as in [1]. 6.7 Sorting algorithms Finally, \nwe use improvement to illustrate how we can com\u00adpare programs for e.ciency. Consider two implementation \nof sorting, bubble-sort (Fig. 4) and insert-sort (Fig. 5). The %k annotation means that the variable \ntakes on values in the range {-k +1,...,k - 1}. We can use (semantic) improvement to show that insert\u00adsort \nis indeed an improvement over bubble-sort. The complete plays for the strategies of the two programs \nare regular languages, so they can be represented as .nite\u00adstate automata. Moreover, let us assume that \nwe are only interested in comparing the e.ciency of the two programs relative to the number of swap operations. \nThis is quite standard in comparing sorting algorithms. Let us add an operation swap : var . var . com \nto our language, with the obvious semantics for swapping the @ values of 2 variables, and with cost \n\u00ae2: [swap : var1 . var2 . com] = strat {run \u00ae@2 read1 m1 read2 n2 write(n)1 ok1 write(m)2 ok2 ok | m, \nn . t} We have adapted the model-checker used in [1] to generate the .nite-state model of the two programs. \nWe show the models for insert-sort and bubble-sort for a small array (3 elements, storing ternary data) \nin Fig. 6. We choose a small array in order to have a model which can be displayed and analysed informally, \nbut we can also automatically analyse much larger arrays using the methods from [1]. The models contain \nonly the read and write moves on the free variable v : var, used to initialise then read the ar\u00adray, \nand the token actions. These models can be seen as statically generated pro.ling information. Transitions \ncor\u00adresponding to token actions appear as a thicker line. The models above are .nite-state and improvement \ncan be eas\u00adily encoded as a regular-language property, which gives a decision method for checking it. \nInformally, one can see that the worst and the best paths in the two mod\u00adels have equal costs (6 and \n0 tokens, respectively) but the bubble-sort model has otherwise more costly computation paths than the \ninsert-sort. So even though the best-case and worst-case costs are the same, insert-sort always repre\u00adsents \nan improvement over bubble-sort. v:var%2 |\u00ad array%2 a[4] in let nbe 4in new var%5i:=0in while!i<n do \na[!i] := v; i :=!i+1 od; new var%2 flag := 1 in while !flag do new var%5i:=0in flag := 0; while !i < \nn -1 do if !a[!i] > !a[!i + 1] then flag := 1; swap(a[!i], !a[!i+1]); else skip fi; i:= !i+1 od od; new \nvar%5i:=0in while!i<n do v := !a[!i]; i :=!i+1 od; : com. Figure 4: Bubble-sort 7. FURTHER WORK In this \npaper we have seen how game semantics can be adapted relatively easily to give a quantitative analysis \nof programming languages, using a new action called token. We have also seen that the resulting semantics \nis exactly that induced by the operational theory of improvement, and made this correspondence rigorous \nthrough a full abstraction result. A quantitative analysis of programs has many poten\u00adtial applications, \nfrom compiler optimisations to resource\u00adconstrained execution and static performance pro.ling. Our analysis \nused the ICA programming language in order to stay focused, but it is quite clear that a similar approach \ncan be extended in a straightforward manner to any lan\u00adguage for which a fully abstract game semantics \nexists, by adding costs consistently to the reduction rules in the oper\u00adational semantics and to the \nstrategies in the game model. However, formalising the way in which a cost model can be in general derived \nfrom a game model is a topic for further research. The cost model we focused on was a linear one, and \nit is suitable to modeling resources that are consumed linearly and cannot be reused, such as time or \npower. More so\u00adphisticated cost models must be created for resources that can be reused (e.g. memory) \nusing a suitable notion of ob\u00adservation [12]. Our analysis also assumes a sequential op\u00aderational model; \nexecution in a concurrent multi-processor environment requires yet a di.erent analysis. However, in the \ninstances above the di.culties are technical rather than conceptual. In our model we have also abstracted \nthe temporal sig\u00adni.cance of costs. This was possible because our language does not contain control operators. \nConsider the two cost v:var%2 |\u00adarray%2 a[4] in let n be 4 in newvar%5 i:= 0in while!i<n do a[!i] := \n!v; i:=!i +1 od; newvar%5 i:= nin while !i > 0 do i:=!i -1; new var%5 max := 0 in newvar%5j:=0 in while \n!j < !i do if !a[!max] < !a[!j] then max := !j else skip fi; j:=!j+ 1 od; if !a[!max] > !a[!i] then \nswap(a[!max],!a[!i]) else skip fi od; newvar%5 i:= 0in while!i<n do  v := !a[!i]; i:=!i +1 od; : com. \nFigure 5: Insert-sort schemes for assignment below. For our purposes they are indistinguishable, although \nthe cost is incurred at di.erent moments in time: \u00ae@ \u00ae@ run qn write(n) ok $ ok vs. run $ qn write(n) \nok ok However, in a language with control where the arguments may interrupt execution the two are distinguishable. \nIf a non-local jump occurs, in the former the cost will not have been incurred whereas in the latter \nit will have. We also do not assign polarities to tokens; we do not dis\u00adtinguish whether it is P or O \nincurring the cost. Assign\u00ading polarities to costs can help give semantics to assume\u00adguarantee type systems \nwhich control resource usage, along the lines of [8]. In contrast, our polarity-free semantics can only \nanalyse resource usage. Finally, our semantic model is helpful in assigning costs to computations and \nthus compares programs for e.ciency. However, it is not clear how this approach can be used to give a \ncomplexity-theoretical characterisation to programs, i.e. relating asymptotically the costs to the size \nof the in\u00adputs. But the concrete nature of the game model could be useful in handling this problem as \nwell. Acknowledgements The author is indebted to Jakob Re\u00adhof for his helpful suggestions. 8. REFERENCES \n[1] Abramsky, S., Ghica, D. R., Murawski, A. S., and Ong, C.-H. L. Applying game semantics to  Figure \n6: Models for insert-sort and bubble-sort compositional software modeling and veri.cation. In TACAS (Barcelona, \n2004), LNCS 2988. [2] Abramsky, S., Jagadeesan, R., and Malacaria, P. Full abstraction for PCF. Information \nand Computation 163 (2000). [3] Abramsky, S., and McCusker, G. Linearity, sharing and state: a fully \nabstract game semantics for Idealized Algol with active expressions (extended abstract). ENTCS 3, (1996). \n[4] Berry, G., and Curien, P.-L. Sequential algorithms on concrete data structures. TCS 20 (1982), 265 \n321. [5] Bjerner, B., and Holmstr\u00a8 om, S. A compositional approach to time analysis of .rst order lazy \nfunctional programs. In Fourth International Conference on Functional Programming Languages and Computer \nArchitecture (1989). [6] Brookes, S., and Geva, S. Computational comonads and intensional semantics. \nIn Applications of Categories in Computer Science: Proceedings LMS Symposium (Durham, UK, 1991). [7] \nGhica, D. R. Semantical analysis of speci.cation logic, 3: An operational approach. In ESOP (Barcelona, \n2004), LNCS 2986. [8] Ghica, D. R., Murawski, A., and Ong, C.-H. L. Syntactic control of concurrency. \nIn ICALP (Turku, Finland, 2004), LNCS 3142. [9] Ghica, D. R., and Murawski, A. S. Angelic semantics of \n.ne-grained concurrency. Tech. Rep. PRG-RR-03-20, Oxford University Computing Laboratory, 2003. http: \n//users.ox.ac.uk/~coml0074/papers/asfgc.pdf. [10] Ghica, D. R., and Murawski, A. S. Angelic semantics \nof .ne-grained concurrency. In FOSSACS (Barcelona, 2004), LNCS 2987. [11] Gurr, D. J. Semantic frameworks \nfor complexity. PhD thesis, University of Edinburgh, 1991. [12] Gustavsson, J., and Sands, D. A foundation \nfor space-safe transformations of call-by-need programs. In Higher Order Operational Techniques (Paris, \nFrance, 1999), ENTCS 26. [13] Hyland, J. M. E., and Ong, C.-H. L. On full abstraction for PCF: I, II \nand III. Information and Computation 163, 8 (Dec. 2000). [14] Jay, C. B., Cole, M. I., Sekanina, M., \nand Steckler, P. A monadic calculus for parallel costing of a functional language of arrays. LNCS 1300 \n(1990), 650 665. [15] Jifeng, H., Josephs, M. B., and Hoare, C. A. R. A theory of synchrony and asynchrony. \nIn Programming Concepts and Methods. Elsevier, 1990, pp. 459 473. [16] Lacey, D., Jones, N. D., Wyk, \nE. V., and Frederiksen, C. C. Proving correctness of compiler optimizations by temporal logic. In 29th \nPOPL (Portland, OR, USA, 2002) [17] Laird, J. A games semantics for idealized CSP. In MFPS 17 (Aarhus, \nDenmark, 2001), ENTCS 45. [18] Leperchey, B. Time and games. http: //www.pps.jussieu.fr/~leperche/pub/time.ps.gz. \n[19] Mason, I. A., and Talcott, C. L. Equivalence in functional languages with e.ects. Journal of Functional \nProgramming 1 (1991), 287 327. [20] Milner, R. Processes: a mathematical model of computing agents. \nIn Logic Colloquium 73 (1975), H. E. Rose and J. C. Shepherdson, Eds., North-Holland, Amsterdam, pp. \n157 174.  [21] Moran, A., and Sands, D. Improvement in a lazy context: An operational theory for call-by-need. \nIn 26th POPL (San Antonio, Texas, 1999). [22] Nickau, H. Hereditarily sequential functionals. LNCS 813 \n(1994). [23] O Hearn, P., Reynolds, J., and Yang, H. Local reasoning about programs that alter data structures. \nIn Proceedings of the Annual Conference of the European Association for Computer Science Logic (2001), \nLNCS 2142. [24] O Hearn, P. W., and Riecke, J. G. Kripke logical relations and PCF. Information and Computation \n120, 1 (July 1995), 107 116. [25] Pitts, A. M. Reasoning about local variables with operationally-based \nlogical relations. In 11th LICS (1996), Washington, USA. [26] Plotkin, G. D. Lcf considered as a programming \nlanguage. TCS 5 (1977), 223 255. [27] Reynolds, J. C. Idealized Algol and its speci.cation logic. In \nTools and Notions for Program Construction (Nice, France, 1981), D. N\u00b4eel, Ed., Cambridge University \nPress, Cambridge, 1982, [28] Roscoe, W. A. Theory and Practice of Concurrency. Prentice-Hall, 1998. [29] \nSands, D. Calculi for Time Analysis of Functional Programs. PhD thesis, Unversity of London, 1990. [30] \nSands, D. Operational theories of improvement in functional languages (extended abstract). In Proceedings \nof the Fourth Glasgow Workshop on Functional Programming (Skye, August 1991), Workshops in Computing \nSeries. [31] Sands, D. Improvement theory and its applications. In Higher Order Operational Techniques \nin Semantics, A. D. Gordon and A. M. Pitts, Eds., Publications of the Newton Institute. Cambridge University \nPress, 1998. [32] Scott, D. S. A type-theoretical alternative to Cuch, Iswim, Owhy. Privately circulated \nmemo, Oxford University, Oct. 1969. Published in Theoretical Computer Science, 121(1/2):411 440, 1993. \n[33] van Stone, K. A denotational approach to measuring complexity in functional programs. PhD thesis, \nCarnegie Mellon University, 2003. [34] Tarski, A. Logic, Semantics, and Meta-Mathematics. Oxford University \nPress, Oxford, 1956. [35] Udding, J. T. A formal model for de.ning and classifying delay-insensitive \ncircuits and systems. Distributed Computing 1(4) (1986), 197 204. [36] Wadler, P. Strictness analysis \naids time analysis. In 15th POPL (January 1988).  \n\t\t\t", "proc_id": "1040305", "abstract": "We present a games-based denotational semantics for a quantitative analysis of programming languages. We define a Hyland-Ong-style games framework called <i>slot games</i>, which consists of HO games augmented with a new action called token. We develop a slot-game model for the language Idealised Concurrent Algol by instrumenting the strategies in its HO game model with token actions. We show that the slot-game model is a denotational semantics induced by a notion of observation formalised in the operational theory of improvement of Sands, and we give a full abstraction result. A quantitative analysis of programs has many potential applications, from compiler optimisations to resource-constrained execution and static performance profiling. We illustrate several such applications with putative examples that would be nevertheless difficult, if not impossible, to handle using known operational techniques.", "authors": [{"name": "Dan R. Ghica", "author_profile_id": "81100060125", "affiliation": "Oxford University Computing Laboratory", "person_id": "P58037", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1040305.1040313", "year": "2005", "article_id": "1040313", "conference": "POPL", "title": "Slot games: a quantitative model of computation", "url": "http://dl.acm.org/citation.cfm?id=1040313"}