{"article_publication_date": "01-12-2005", "fulltext": "\n Theoretical Foundations for Compensations in Flow Composition Languages * Roberto Bruni Hern\u00b4an Melgratti \nUgo Montanari Dipartimento di Informatica Dipartimento di Informatica Dipartimento di Informatica Universit`a \ndi Pisa, Italia Universit`a di Pisa, Italia Universit`a di Pisa, Italia bruni@di.unipi.it melgratt@di.unipi.it \nugo@di.unipi.it ABSTRACT A key aspect when aggregating business processes and web services is to assure \ntransactional properties of process ex\u00adecutions. Since transactions in this context may require long \nperiods of time to complete, traditional mechanisms for guaranteeing atomicity are not always appropriate. \nGen\u00aderally the concept of long running transactions relies on a weaker notion of atomicity based on compensations. \nFor this reason, programming languages for service composition cannotleave outtwo key aspects: compensations, \ni.e. ad hoc activities that can undo the e.ects of a process that fails to complete, and transactional \nboundaries to delimit the scope of a transactional .ow. This paper presents a hierarchy of transactional \ncalculi with increasing expressiveness. We start from a very small language in which activities can only \nbe composed sequentially. Then, we progressively introduce parallel composition, nesting, programmable \ncompensations and exception handling. A running example illustrates the main features of each calculus \nin the hierarchy. Categories and Subject Descriptors D.1.3 [Programming Techniques]:Concurrent program\u00adming \nDistributed programming; D.3.1 [Programming Languages]:Formal De.nitions and Theory; D.3.3 [Pro\u00adgramming \nLanguages]:Language Constructs and Fea\u00adtures Concurrent programming structures; F.3.2 [Logics and Meanings \nof Programs]:Semantics of Programming Languages Operational semantics General Terms Languages, Theory \n* Research supported by the FET-GC Project IST-2001\u00ad32747 Agile, by the MIUR Project COFIN 2001013518 \nCoMeta, and by the MURST-CNR 1999 Project Software Architectures on Cooperative WAN. Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 05, January 12 14, \n2005, Long Beach, California, USA. Copyright 2005 ACM 1-58113-830-X/05/0001 ...$5.00.  Keywords Transactions, \ncompensations, process description languages 1. INTRODUCTION The ultimate goal of web services technologies \nis to allow the distribution, delivery and interoperability of heteroge\u00adneous components over the Internet. \nApplications achieve interoperability by adhering to standard protocols that pro\u00advide uniform ways to \ndescribe services (namely wsdl), to look for particular services (i.e., uddi), and to access ser\u00advices \n(i.e., soap). In this way standards facilitate the inter\u00adaction of di.erent services, not only within \nan organization but also across organization boundaries. Nevertheless, these standards do not provide \nyet any support to describe com\u00adplex interactions between several applications. Recently, many proposals \nhave addressed the problem of aggregat\u00ading services, giving birth to a family of xml-based compo\u00adsition \nlanguages (also known as choreography or orchestra\u00adtion languages), such as bpml [6], xlang [21], wsfl \n[16], bpel4ws [5] and wsci [24]. Choreography languages allow the de.nition of complex services in terms \nof the interactions among simpler services. In general, composition can be speci.ed in one of the fol\u00adlowing \nstyles [16]:(i) .ow composition (also known as hi\u00aderarchical patterns) and (ii) interaction based composition \n(also known as conversational patterns or global models). Flow composition is reminiscent of work.ow \nsystems [13], where composed services are described by a process that states precisely the .ow of both \ncontrol and data between the component parts. Instead, conversational based lan\u00adguages are aimed at describing \nthe interaction protocols or patterns that services should follow in order to achieve a speci.c goal. \nIn this case, any service declares the ways in which it can be engaged in a larger process. Usually .ow \ncomposition is associated with a centralized coordination mechanism (the .ow engine) that monitors the \norder in which activities are run, while interaction models are related to distributed orchestration, \nin which partici\u00adpants are responsible for adhering to a speci.c protocol. Most proposals for orchestration \nlanguages contain a large amount of primitives, allowing for both styles of composi\u00adtion. (For a discussion \nabout the several patterns or prim\u00aditives they provide we refer to [2]). Since the o.cial spec\u00adi.cations \nof composition languages for web services mainly consist in an informal textual description of their \nconstruc\u00adtors, many recent e.orts have attempted to formalize dif\u00adferent subsets of such proposals (see \nfor instance [7, 3, 22]). At the same time, foundational models for concurrency has been proposed also \nas foundational models for web services orchestration ([18, 1]). Nevertheless, there are several funda\u00admental \naspects when describing composed services, in par\u00adticular the transactional properties of .ows, that \nhave re\u00adceived little attention in the area of process description lan\u00adguages (pdls) like the p-calculus \nor ccs. These properties are somehow orthogonal to usual pdl s operators, and al\u00adthough they could be \npossibly encoded into standard oper\u00adators, the extension of pdlswith thiskindof abstractions are desirable \n(at least) for the following reasons:(i) to lay the foundations for the formal de.nition of orchestration \nlanguages; (ii) to facilitate the comparison of di.erent se\u00admantics; (iii) to reason about the relation \namong operators; (iv) as the starting point for comparing the expressive power of newly proposed primitives \n(i.e., whether they can be con\u00adveniently de.ned in term of usual operators or not) and for studying the \nproperties preserved by di.erent encodings; and (v) to give insights about implementation details. In \nthis paper, we study primitives for long running trans\u00adactions in .ow composition languages, and in particular \nin structured control .ows, i.e. .ows de.ned in terms of a .xed set of primitives, like sequencing and \nbranching. We provide a formal semantics for a hierarchy of transactional languages with increasing expressiveness \nand we prove that the semantics is adequate to the modelled features. Transactional aspects in composed \nweb services have been mainly inherited from work.ow languages. The key idea is that valid executions \nof a transactional business process (or of a part of it) are those that complete all involved activ\u00adities. \nNevertheless, since the execution of a business process may require a very long period of time in order \nto complete (perhaps some hours or days), traditional mechanisms for as\u00adsuring atomicity, such as locking \nof resources, are regarded as not suitable. Since the seminal work of Sagas [12], the key mechanism for \ndealing with long running transactions is that of compensating activities . Instead of relying on locking \nand roll-back mechanisms to perfectly undo incom\u00adplete executions and avoid interference among transactions, \na more relaxed form of atomicity is granted by associating processes with activities that can recover \npartial executions. Although compensations can be regarded as an exception handling mechanism [17], the \ndistinctive feature is that com\u00adpensation handlers are dynamically built during the execu\u00adtion of processes. \nConsider the saga given in Figure 1, where the transactional process P consists in the sequential exe\u00adcution \nof the activities A1, A2 and A3,that can be com\u00adpensated respectively by B1, B2 and B3. Suppose now that \nactivity A1 completes successfully while activity A2 fails. In this case, after A2 fails, the compensation \nB1 (correspond\u00ading to the successfully completed activities) is run to undo as much as possible the e.ects \nof A1, because the transac\u00adtion failed as a whole. Note that B2 is not executed, because A2 has not completed. \nInstead, if both A1 and A2 succeed while A3 fails, then the compensations will be executed in the reverse \norder, i.e. .rst B2 and then B1. After Sagas, several work.ow models have been proposed in literature \nfor equipping processes with di.erent (compen\u00adsation-based) transactional capabilities, such as nesting \nand forward recovery (for a general overview see [20]). Contrast\u00adingly, the study of pdls with compensations \nhave been less numerous. An extension of the asynchronous p-calculus, called pt-calculus, with transactional \ncontexts has been in\u00ad        A1 B1  A2 B2  A3 B3  Figure 1: A sequential saga. troduced \nin [4]. The pt-calculus formalizes the close relation between exception handling and compensations. Neverthe\u00adless, \nthis approach is not aimed at capturing the order in which compensations should be activated, i.e. there \nis not a strong relation between compensations and the control .ow of the original processes. For instance, \nif activity A3 fails during the execution of .ow depicted in Figure 1, compen\u00adsations B1 and B2 are activated \nconcurrently. A di.erent approach is taken by StAC [9], where compen\u00adsations are installed to be executed \nin the reverse order w.r.t. that of completion of original activities. StAC is a language in the spirit \nof process algebras like csp or ccs with excep\u00adtion handling mechanisms and compensations inspired by \nBPBeans, a framework for modelling business processes inte\u00adgrated to WebSphere [23]. Although being (to \nthe best of our knowledge) the .rst process calculus where compensations are closely related to the control \n.ow of the executed pro\u00adcess 1, there are several aspects in StAC that deserve further investigation. \nFor instance, compensations in StAC should be explicitly activated through special primitives, i.e. they \nare not related to the failure or success of the activities of processes, as usually expected in work.ows \nand composition languages, e.g. bpel4ws. Moreover, to reason about StAC processes, it is necessary to \nknow the low level description of activities. In fact, there is an interplay between data structures \nused by activities and the control .ow of pro\u00adcesses. Finally, StAC provides a large number of operators \nincluding the imperative fragment of a programming lan\u00adguage, whose operational semantics has been given \nin terms of an even richer intermediate language, called StACi [10]. In this way, operators in StAC can \nonly be understood by analyzing their encodings into StACi operators. Due to the complex de.nition of \nthe operational semantics of StACi,it is di.cult to reason about the interplay among exception handling, \ncompensations, nesting and parallel composition in StAC. Moreover, some usual behaviors of compensations \n(for instance, the failure of a branch in a parallel composi\u00adtion requiring the compensation of both \nbranches) are only achieved by combining several operators, making the seman\u00adtics in [10] not entirely \nsatisfactory. (Recent ongoing work by Butler, Ferreira and Hoare aims to de.ne a clean trace semantics \nfor a subset of StAC.) In this work we intend to give a more compact description of StAC-like languages:in \nthe spirit of pdls, we are aimed at providing a minimal set of operators with orthogonal mean\u00ading and, \nin particular, we are interested on marking the distinction between compensations and exception handling \nmechanisms. Moreover we attempt to provide our opera\u00adtors with the meaning most frequently used in composition \nlanguages. Additionally, we relate the behavior of whole processes with the success or failure of atomic \nactivities. 1We are aware of previous formal approaches to de.ne com\u00adpensations, such as acta [11] in \nthe context of database transactions and the work done by C.A.R Hoare [14], but they are not process \ncalculi  In order to achieve these goals, we start from a very small language formalizing Sagas. First, \nwe show a language cor\u00adresponding to its sequential version (i.e., allowing only the sequential composition \nof activities inside a saga). Then we introduce the parallel composition and discuss di.erent al\u00adternatives \nin de.ning the semantics for the compensation of parallel activities. After that, we add the possibility \nof de.ning nested transactions. Finally, we present some ex\u00adtensions, such as programmable compensations, \nexception handling and forward recovery. Each language in the result\u00ading hierarchy comes with a clean \nbig-step semantics and an adequacy result for such semantics. As a running example, we select a business \nprocess for ordering goods. It is simple enough to require a process that .ts in one line, yet it is \nexpressive enough to show how the primitives can enhance business process design. Structure of the paper. \nIn Section 2 we present the core language for sequential sagas, which has primitives for compensated \nactivities A \u00f7 B, sequential composition P ; Q and saga scope {[P ]} . In Section 3 we extend the core \nlan\u00adguage with parallel composition P | Q, and in Section 4 we extend parallel sagas with nesting {[S]} \n.In Section 5 we discuss how the language for nested sagas can be further extended with additional features \nlike programmable com\u00adpensations, exception handling, choices, and dependencies. Concluding remarks and \nfuture work are in Section 6.  2. SEQUENTIAL SAGAS As mentioned before, Sagas [12] is one of the .rst \npropos\u00adals for dealing with long running transactions in database applications. A sequential saga (i.e., \na long lived trans\u00adaction) is a sequence of atomic activities (called subtrans\u00adactions, activities or \nsteps) that should be executed com\u00adpletely. The parallel execution of several sagas can inter\u00adleave steps \nin any way, but any single step is guaranteed to be atomic. Subtransactions are atomic in the sense that \nei\u00adther they are successfully executed (committed)orno e.ect is observed when the execution fails (aborted). \nIn addition, no intermediate states computed by an activity are visible to other activities. Activities \nare transactions with short dura\u00adtion, and therefore they can rely on traditional mechanisms to assure \nthe usual acid properties (i.e., Atomicity, Consis\u00adtency, Isolation and Durability). Additionally, any \nactivity Ai in a saga has a compensating activity Bi that can be ac\u00adtivated to undo the e.ects of a successful \nexecution of Ai upon a later failure. (We remind that, in this context, the term undo does not mean to \nexactly reverse the e.ects by restoring the original state, but just to perform an ad hoc activity that \nmoves the system to a sound state). Any partial execution of a saga is undesirable, and if it occurs, \nit must be compensated for. A saga involving A1, ..., An (where each Ai has a compensation Bi)is guar\u00adanteed \nto execute either the entire series A1; ...; An or the compensated sequence A1; ...; Aj; Bj; ...; B1 \nfor some j<n. The .rst case stands for the successful execution of the whole saga, i.e., when all activities \nin the sequence complete. In the second case, the activity Aj+1 fails, and all activities al\u00adready completed \n(A1; ...; Aj) are recovered by executing the corresponding compensations, in reverse order (Bj; ...; \nB1). In this section we introduce a compensation language for sequential sagas. The semantics is intended \nto describe the behavior of top-level processes but not the low-level compu\u00adtations performed by atomic \nactivities. The only assumption made on subtransactions is that their executions end either successfully \nor with a failure. We rely on an in.nite set A of names for atomic activities, ranged over by A, B,.... \nMoreover, we will consider a special nil activity 0 .A that always completes and has no e.ect. Definition \n1 (Sequential Sagas). The set of all se\u00adquential sagas is given by the following grammar: (step) X ::= \n0 | A | A \u00f7 B (process) P ::= X | P ; P (saga) S ::= {[P ]} A sequential saga S consists in a sequential \nprocess P . Each step in P corresponds either to an activity A or a compensated activity A \u00f7 B,where \nA is the activity of the normal .ow and B its compensation. The term 0 repre\u00adsents the inert process, \nand P ; P stands for the sequential composition of processes. We de.ne the semantics of sagas up-to structural \ncongru\u00adence over processes and steps given by the following axioms: A \u00f7 0 = A (Null compensation) 0; \nP = P ;0 = P (Null process) (P ; Q); R = P ;(Q; R)(Assoc. of Seq. Comp.) For simplicity we will consider \nall (instances of) activities in a saga named di.erently. This does not mean we do not allow the same \nactivity to be executed more than once in a saga, but we consider any execution as a di.erent instance \nof it and, hence distinguishable from all other instances. Definition 2 (Activities of a saga). The set \nof ac\u00adtivities of a saga S is de.ned as A (S)= { A | A occurs in S} . 2.1 Big Step Semantics As described \nabove, the execution of a saga S either com\u00admits i.e., every activity executes successfully or it aborts \nand all completed steps are compensated for. This model implicitly assumes that compensations always \nsuc\u00adceed. In order to relax this assumption, we allow also com\u00adpensations to fail. In this case, a saga \nS has an abnormal termination. Abnormal termination could be managed by suitable exception handling mechanisms. \n(We informally discuss exception handling in Section 5.2). Thus, the set of possible results for the \nexecution of a saga is R = { C, ., .} , where Cstands for commit, .for (compensated) abort,and .for abnormal \ntermination.We let .range over R . The execution of a sequential saga is described in terms of the results \nobtained by performing their constituent activi\u00adties. As we are not interested on the low-level behavior \nof individual tasks, we rely on the abstract description of their executions, stating whether they complete \nsuccessfully or abort. This information is given by a context G. Formally, G is a partial function over \nA that maps any activity to the result obtained with its execution, i.e., G : A -{ ., C} . Note that \nactivities can only commit or abort (they do not terminate abnormally). We denote a particular function \nG as A1 .1,...,An. .n,where Ai Aj for all i= j . = (i.e., , stands for the disjoint union of partial \nfunctions). The semantics of a sequential saga S is given by the rela\u00ad a tion G f S -. .de.ned by the \ninference rules in Figure 2. a The notation G f S -. .denotes that the execution of S produces .when \nthe atomic activities behave like G. The observation a describes the actual .ow of control occurring \nwhen executing S under the context G. The .ow a is a process whose activities have no compensations. \n (zero) G f(0,\u00df) 0-.(0,\u00df) (s-act) A .0, G f(A \u00f7B, \u00df) A-.(0,B; \u00df) (s-cmp) G f(\u00df, 0) a-.(0, 0) A ..,G f(A \n\u00f7B, \u00df) a-.(.,0) (f-cmp) G f(\u00df, 0) a-.(., 0) A ..,G f(A \u00f7B, \u00df) a-.(., 0) (s-step) G f(P,\u00df) a-.(0,\u00df'') \nG f(Q,\u00df'') a.-.(.,\u00df') G f(P; Q,\u00df)a;a.-.(.,\u00df') (a-step) G f(P, \u00df) a-.(s, 0) G f(P; Q,\u00df) a-.(s, 0) s .{.,.} \n(saga) G f(P, 0) a-.(.,\u00df) G f{[P]} a-.. Figure 2: Semantics of sequential sagas. a The auxiliary relation \nG f( P,\u00df) -. ( .,\u00df') describes the behavior of a process P within a saga that already installed the compensation \n\u00df (\u00df stands for a process without compen\u00adsations). G and a are analogous to the previous case. When P \nis executed inside a saga, it can either commit, abort, or fail, but additionally, it can change the \ncompensations, for instance by installing new activities, like in rule (s-act). Rule (zero) states that \n0 always commits without chang\u00ading the installed compensation. Rule (s-act) stands for the successful \nexecution of the compensated activity A\u00f7 B when A commits. In this case, the observation is A (i.e., \nthe only executed activity), the obtained result is C, while the com\u00adpensation is updated by installing \nB in front of \u00df.Note that A is the last executed activity, hence the .rst to be compensated for if the \nnext activity in the saga fails. Rules (s-cmp)and (f-cmp) describe the execution of A\u00f7 B when A fails \nin a saga that has already installed \u00df.Both rules activate the compensation procedure by executing \u00df \n(premises of the rules). Note that neither A nor B are re\u00adally executed. In fact, since A is an atomic \nactivity that aborts, A has no e.ects and hence, it is not compensated for. For this reason the observation \na is just the .ow ob\u00adserved by executing \u00df.In particular, (s-cmp) describes the case in which the compensation \nprocedure completes suc\u00adcessfully. Rule (f-cmp) stands for the case in which the compensation procedure \nfails. In this case, the process .n\u00adishes abnormally (the corresponding result is ). Since all steps \nin \u00df have trivial nil compensations, the execution of \u00df cannot produce . For the same reason, the execution \nof \u00df installs no signi.cant compensations, and hence any execu\u00adtion that ends with .or must have 0 as \ncompensation. Rule (s-step) describes the behavior of a process P; Q when the step P commits. In such \ncase the remaining pro\u00adcess Q is executed by taking into account the compensation produced after the \nexecution of P. The observation for the whole process P; Q corresponds to the sequential composi\u00adtion \nof a, i.e. the observation of executing P,and a', i.e. the .ow corresponding to the execution of Q. The \n.nal result is that obtained when executing Q. Rule (a-step) handles the case in which P; Q is stopped \nbecause P ends with abort or abnormal termination. Note that the compensation is activated when P reaches \nthe abort. Last rule (saga) states that the execution of a saga {[P]}is the activation of P with no installed \ncompensations. Although a more concise set of rules could be used to describe the semantics, we choose \nthis presentation for con\u00advenience when extending the language in the next sections. Accept Order Refuse \nOrder  Update Credit Refund Order  Prepare Order Update Stock  Figure 3: A sequential saga for handling \norders. Example 1 (Sequential Sagas). Figure 3 shows a se\u00adquential saga for dealing with purchase orders. \nIt consists on three activities composed sequentially. The .rst activ\u00adity (Accept order) handles a request \nfrom a client and it is compensated by Refuse order, which will contact the client to notify her/him \nthat the order was canceled. The second step (Update Credit) charge the amount of the order to the balance \nof the client. This activity could fail, for instance when the client has not enough credit to proceed, \nactivating the compensation, i.e., executing Refuse order. Instead, if it succeeds, then the compensation \nRefund order is also in\u00adstalled. Refund order is responsible for updating the balance with the amount \ndetracted previously. Last activity (Prepare Order) handles the packaging of the order and update the \nstock. Its compensation (Update Stock) will increment the stock with the proper values. The following \nresult states that the execution of a saga corresponds to the intuitive notion we gave initially. Theorem \n1 (Adequacy). Let S ={[A1\u00f7 B1; ...; An\u00f7 Bn]} be a saga. Then: a (Completion) G f S -. Ci. . i = n : Ai \n. C. G and a = A1; ...; An; a (Successful Compensation) G f S -. .i. . k,1 = k = n . Ak . .. G .. i<k \n:(Ai . C,Bi . C. G) and a = A1; ...; Ak-1; Bk-1; ...; B1. a (Failed Compensation) G f S -. i. . j,k, \n1 = k = n . 1 = j<k s.t. Ak . .. G . Bj . .. G . (. i< k : Ai . C. G) . (. h . [j +1,k- 1] : Bh . C. \nG) and a= A1; ...; Ak-1; Bk-1; ...; Bj+1. It is clear from the above theorem that the last compensa\u00adtion \nBn is never activated. Nevertheless we allow such kind of de.nitions because they can be useful when \nspecifying more complex sagas in the following sections.  3. PARALLEL SAGAS In order to allow several \nactivities to be executed concur\u00adrently, the language of sequential sagas is extended with the operator \n| , denoting the parallel composition of processes. (s-par) aa G f(P, 0)-.(C,\u00df ' ) G f(Q, 0)-.(C,\u00df '' \n) a|a C,\u00df ' |\u00df '' G f(P |Q, \u00df)-.(; \u00df) (f-par-na\u00a8ive-1) aaa. .if .1 = C G f(P, 0)-.(., 0) G f(Q, 0)-.(., \n0) G f(\u00df, 0)-.(.1,\u00df '' ) .2 = otherwise (a|a );a G f(P |Q, \u00df)-. (.2, 0) (f-par-na\u00a8ive-2) aaa G f(P, \n0)-.( , 0) G f(Q, 0)-.(C,\u00df ' ) G f(\u00df ' , 0)-.(., 0) (a|a );a G f(P |Q, \u00df)-. ( , 0) (f-par-na\u00a8ive-3) \naa G f(P, 0)-.( , 0) G f(Q, 0)-.(s, 0) with s .{., } (a|a ) G f(P |Q, \u00df)-. ( , 0) (f-par-na\u00a8ive-4) \naaa. .if .1 = C G f(P, 0)-.(., 0) G f(Q, 0)-.(C,\u00df ' ) G f(\u00df ' ; \u00df, 0)-.(.1, 0) .2 = otherwise (a|a );a \n G f(P |Q, \u00df)-. (.2, 0) Figure 4: Na\u00a8ive semantics of parallel composition. Definition 3 (Parallel Sagas). \nThe set of all par-the form .|. ' ,where . and . ' are uncompensated processes. allel sagas is de.ned \nby the grammar: In this way we quotient out all possible interleaving exe\u00adcutions of .|. ' . We recall \nthat activities are atomic steps, (step) X ::= 0 | A | A \u00f7B and therefore there is no interaction among \nthem. For this (process) P ::= X | P ; P | P |P reason any interleaving of .|. ' is a valid execution \nof the (saga) S ::= {[P ]} process. Hence, the parallel branches of P |Q are executed independently, \ni.e. each branch performs until completion In addition to the structural axioms for sequential sagas, \n '' in its own thread, which has no initial compensation. we require | to be associative and commutative \nwith unit The.rst rule(s-par) handles the successful execution of 0. We let sequential composition have \nhigher priority than P |Q, i.e. every activity commits and both P and Q pro\u00ad parallel, i.e. P ; Q|R; \nS stands for (P ; Q)|(R; S). duce Cas result. The compensation for the whole process is Note that the \ndependencies among activities are described updated by installing the parallel composition of \u00df ' and \n\u00df '' by a structured .ow, and in particular synchronizations be\u00ad at the top, i.e. the compensation of \nparallel processes cor\u00ad tween processes take place only when composing sequen\u00ad responds to the parallel \ncompensation of its branches. The tially. We will not consider descriptions based on links de\u00ad observed \n.ow is the parallel composition of the .ows for P pendencies like those allowed in wsfl until Section \n5.5. and Q. As for sequential sagas, a computation of a parallel saga The remaining four rules handle \nthe cases where at least is successful only when all its activities commit, while the one activity aborts. \nIf both branches fail during the normal whole saga should be compensated for when an activity fails. \n.ow but their compensation completes, then the execution Also we like compensations to be performed in \nthe reverse ends by activating the original compensation \u00df (rule f-par\u00ad order of the normal .ow. Composition \nlanguages usually na\u00a8ive-1). The result is .when \u00df .nishes without problems. express this requirement \nby stating that all compensation On the contrary, if \u00df aborts, then the whole process termi\u00ad handlers \nfor completed activities run in the reverse order of nates abnormally (producing ). completion. In our \napproach the compensations of concur- Rules (f-par-na\u00a8ive-2)and (f-par-na\u00a8ive-3) stand for the rent activities \nare concurrent, because we want a semantics cases in which P terminates abnormally, i.e. some activity \nwhere compensations do not depend on the particular inter\u00ad in the normal .ow of P aborts activating its \ncompensation leaving of executed concurrent activities. procedure, which also fails. In such cases, the \noriginal com- We .rst give a semantics where parallel branches are com\u00ad pensation \u00df is not executed, \nbecause it should follow the pletely independent (Section 3.1). This semantics is simple compensation \nof P that has failed. The behavior is similar but not entirely satisfactory when modelling real problems, \nto the sequential case, where the compensation procedure because it does not allow to force the failure \nin one branch stops when some activity aborts. In particular, rule (f-par\u00ad as soon as a failure is detected \nin the other branch. A more na\u00a8ive-2) handles the situation in which the remaining pro\u00ad complex semantics \nis then given in Section 3.2, which can cess Q has completed successfully and it is compensated for. \ndeal properly with this kind of optimization. For this reason the compensation \u00df ' installed by Q is \nacti\u00advated. The .nal result is in any case , and the observed 3.1 Na\u00a8ive de.nition for the semantics \nof | .ow corresponds to the parallel execution of both branches In a .rst attempt at de.ning the semantics \nof the par\u00ad followed by the execution of the compensation \u00df ' .Instead allel composition we add the rules \nin Figure 4 to those of (f-par-na\u00a8ive-3) describes the cases in which Q has already sequential sagas. \nNote that transition labels a can now take been compensated for (i.e., the result is .or ), and there\u00adfore \nno further compensation is activated. Also, in this case the process P|Q terminates abnormally.  Last \nrule (f-par-na\u00a8ive-4) describes the behavior when one of the branches .nishes successfully and the other \nhas been aborted and properly compensated for. Hence. the execution done by the successful branch needs \nto be reversed (by running \u00df ' ) before activating the original compensation \u00df. If the whole compensation \n(i.e., the execution of \u00df ' ; \u00df) .nishes with success, then the .nal result is .,otherwise the whole \nprocess terminates abnormally. Example 2 (Parallel Sagas). The second and third activities in Example \n1 could be performed in parallel as shown in Figure 5. Nevertheless, in case some activity aborts, we \nwould like all completed steps to be compensated for. Although given rules allow a failed branch to start \nits compensation as soon as it aborts, the successful branch is forced to execute until completion, even \nwhen it will be compensated for. Consider the following parallel saga: S ={[A1 \u00f7B1; A2 \u00f7B2 | C1 \u00f7D1]} \nand the context in which all activities but C1 commit, i.e. G= A1 . C,A2 . C,C1 . .,B1 . C,B2 . C,the \nonly possible computation for S produces as result .with observation (A1; A2|0); B2; B1. In a real execution \nof S where C1 fails while A1 is still ex\u00adecuting, it would be desirable to avoid the execution of both \nA2 and its compensation B2 by starting the compensation procedure as soon as A1 .nishes. (We remind that \nactivities are atomic and hence their execution cannot be stopped once they have started). In general, \nwhen several processes exe\u00adcute concurrently and some activity aborts, then the whole saga aborts and \nevery completed activity should be compen\u00adsated for. Hence, it would be desirable to stop all processes \nbefore completion and to start the compensation procedure of partially executed branches as soon as a \nconcurrent ac\u00adtivity aborts. The following section presents a semantics for parallel sagas that allows \nsuch kind of behaviors.  3.2 Parallel Sagas Revised To handle partial executions of successful branches \ndur\u00ading an aborted execution of a saga, we introduce two new kinds of results for a process running in \na saga:(i) .de\u00adnoting that the process has been forced to compensate and then it has been compensated \nfor successfully, and (ii) denoting that the process has been forced to compensate but the compensation \nprocedure has failed. Let .,s1,s2 range over R= R.{., }. Moreover, we use the binary operator .over Rto \nexpress the result obtained by combin\u00ading the execution of two parallel branches. The associative and \ncommutative operator .is de.ned in the following table (because of commutativity we omit half of the \ntable). Note that . is not de.ned when one operand is Cand the other not. In fact, it is not possible \nfor a branch to commit when the other aborts or fails:in the process P|Q, when P commits but Qdoes not, \nP is forced to compensate. The other interesting cases are the two last rows on the table, in which one \nof the branches is forced to compensate (producing either .or ). If the remaining branch really fails \n(i.e., it reduces to a con.guration with result .or ) then the parallel composition actually fails. Otherwise \nif it is also forced to compensate then the whole process has been forced to compensate. The semantics \nfor parallel sagas is given in Figure 6. All rules for sequential sagas remain unchanged but a-step, \nwhose side condition considers also the new kinds of results for s, and four new rules are added. Rules \n(s-par), (f-par)and (c-par)specify the behavior of parallel composition. As for the na\u00a8ive semantics, \nparallel branches are run in parallel without initial compensations. If both branches commit (rule (s-par)), \nthen the original compensation \u00df is updated with the compensations \u00df ' and \u00df '' installed by both branches. \nIn particular, if the whole process P|Q has to be compensated, then \u00df ' and \u00df '' are activated in parallel \nand \u00df is started only when they .nish. If some branch has activated its compensation procedure, then \nalso the other branch is required to be compensated for. If one of the branches fails during the compensation \nproce\u00addure (rule (f-par)), then the .nal result for P|Q will be a (possibly forced) abnormal termination \n(i.e., or ). In this case the compensation \u00df installed before the execution of P|Q is not even activated. \nFinally, rule (c-par) handles the case in which both P and Q are successfully compensated for. In such \ncase, also the previously installed compensation \u00df is run. The new rule (forced-abt) handles the forced \ncompen\u00adsation of a process P, i.e. P can activate the compensation procedure before starting its execution \nthat will produce a forced termination .or . Nevertheless, by rule (saga), the execution of a saga ends \nonly when P produces C, .or . Hence, a valid execution forces a process to compensate only when it is \na branch of a parallel composition. Moreover, in order to remove the tag of forced termination, the other \nbranch is required to actually abort or .nish abnormally. This is achieved by rules (f-par)and (c-par)thatuse \nthe operator .to combine the results of concurrent executions. As done for sequential sagas, we state \nthe correspondence between the proposed semantics and the intended meaning of parallel sagas. We start \nby de.ning some notions that are needed to formalize the correspondence. Definition 4 (Forward flow). \nThe forward .ow |S|of a parallel saga S is obtained by removing all compensa\u00adtions from S, i.e. terms \nA\u00f7B are replaced by A. In de.ning the order of a saga, we assume all activities to have a compensation \n(A=A\u00f70). Since activities in a saga (zero) 0 G f(0,\u00df)-.(0,\u00df) (f-cmp) a G f(\u00df, 0)-.(., 0) a A ..,G f(A \n\u00f7B, \u00df)-.( , 0) (s-par) a G f(P, 0)-.(0,\u00df ' ) G f(Q,0) (s-cmp) (s-act) a A G f(\u00df, 0)-.(0, 0) A .0, \nG f(A \u00f7B, \u00df)-.(0,B; \u00df) a A .., G f(A \u00f7B, \u00df)-.(., 0) (s-step) (a-step) aa a G f(P, \u00df)-.(0,\u00df '' ) G f(Q,\u00df \n'' )-.(.,\u00df ' ) G f(P,\u00df)-.(s, 0) s .{.,, ., } aa;a G f(P; Q,\u00df)-.(.,\u00df ' ) G f(P; Q,\u00df)-.(s, 0) (f-par) \n. a a a -.(0,\u00df '' ) G f(P, 0)-.(s1,0) G f(Q,0)-.(s2,0) s1 .{ , }s2 .{.,, ., } a|a a|a G f(P|Q,\u00df)-.(0,\u00df \n' |\u00df '' ; \u00df) G f(P|Q,\u00df)-.(s1 .s2, 0) (c-par) aa . G f(P, 0)-.(s1,0) G f(Q,0)-.(s2, 0) G f(\u00df, 0)-.(.1,0) \ns1,s2 .{., .} and = . .if .1 = 0 .2 otherwise (a|a );. G f(P|Q,\u00df)-. (s1 .s2 ..2,0) (forced-abt) (saga) \na a G f(\u00df, 0)-.(.1, 0) .2 = . .if .1 = 0 G f(P,0)-.(s, \u00df) s .{0, ., }otherwise a a G f(P, \u00df)-.(.2, 0) \nG f{[P]}-.s Figure 6: Semantics of parallel sagas. are named di.erently, we univocally identify the compensa\u00adtion \nof an activity A\u00f7B with A-1 = B. Definition 5 (Orderof a saga). Let S be a parallel saga, the order of \na saga S is the least transitive relation .S on A(S) s.t.: 1. if A\u00f7B occurs in S then A.S B; 2. if P; \nQ then A.S B .A.A(|P|) and .B .A(|Q|); 3. if A,B .A(S) and A.S B then B-1 .S A-1 .  Given A .A(S), \nwe write .S|A for the order .S restricted to the elements of A. We will use A .S {A1,...,An}(and {A1,...,An}.S \nA)if .i s.t. A.S Ai (resp. Ai .S A). The adequacy is now expressed by three theorems. Theorem 2 (Completion). \nGiven a parallel saga S, a G fS -.Ci. .A.A(|S|): A.C.G and a=|S|. Theorem 3 (Successful compensation). \nLet S be a a parallel saga. G fS -..i. there exists a non empty set FA .A(|S|) of failed activities (i.e., \n.A.FA,A ...G) s.t. .A,B .FA: A.S B and the following conditions hold: 1. .a=.S|A(a), i.e. the observed \n.ow respects the .ow given by S; 2. if A .A(a) then A .C.G, i.e. all observed activi\u00adties commit; 3. \nif A.FA then A.A(a), i.e. failed activities are not observed; 4. if A .A(|S|) and A .S FA then A .A(a), \ni.e. all activities that precede FA are executed successfully; 5. if A .A(|S|) and FA .S A then A .A(a), \ni.e. all activities after FA in the forward .ow are not run; 6. if A.A(|S|) and A.A(a) then A-1 .A(a), \ni.e. all executed activities are compensated successfully.  Theorem 4 (Abnormal termination). Given \na par\u00ad a allel saga S.Then G fS -. i. there exist a non empty set of failed activities FA .A(|S|) s.t. \n.A1,A2 .FA: A1 .S A2, and a non empty set of failed compensations FC .A(S) s.t. FC nA(|S|)= \u00d8 and .B1,B2 \n.FC: B1 .S B2, and the following conditions hold: 1 5 as in Theorem 3 and 6 . if A .A(|S|) and A .A(a) \nand A-1 .S FC then A-1 .A(a), i.e. activities whose compensations pre\u00adcede FC are compensated successfully; \n7. if A-1 .FC then A-1 .A(a), i.e. failed compensa\u00adtions are not executed; 8. if A .A(|S|) and A .A(a) \nand FC .S A-1 then A-1  .A(a), i.e. activities whose compensations fol\u00adlows FC are not compensated. \nAbove results are a generalization of Theorem 1. In fact, the order of a sequential saga is a total order, \nand constraints in Theorems 2 4 reduce to conditions in Theorem 1.  4. ADDING NESTING TO SAGAS Nesting \nhas been introduced in database transactions to localize failures within a transaction and to allow partial \nroll\u00adbacks [19]. Basically, a nested transaction is decomposed into a hierarchy of activities called \nsubtransactions.The root of the hierarchy is usually referred to as the top-level transaction. In this \nscheme, any subtransaction executes independently and concurrently with respect to its parent and siblings, \ndeciding autonomously to commit or abort. When a transaction aborts all its subtransactions should abort \nand consequently all committed subtransactions must be rolled back. Nevertheless, a top-level transaction \ncan commit even though some subtransactions have aborted. Definition 6 (Nested Sagas). Nested sagas are \nde\u00ad.ned by the following grammar: (step) X ::= 0 | A | A\u00f7B (process) P ::= X | P; P | P|P | S (saga) \nS ::= {[P]} (sub-cmt) G f(P,0) a-.(0,\u00df ' ) G f({[P]},\u00df) a-.(0,\u00df ' ; \u00df) (sub-forced-1) G f(P,0) a-.( \n,0) G f({[P]},\u00df) a-.( ,0) (sub-abt) G f(P,0) a-.(.,0) G f({[P]},\u00df) a-.(0,\u00df) (sub-fail) G f(P,0) a-.( \n,0) G f({[P]},\u00df) a-.( ,0) (sub-forced-2) G f(P,0) a-.(.,0) G f(\u00df,0) . -.(.1,0) G f({[P]},\u00df) a;. -.(.2,0) \n.2 = . . if .1 = 0 if .1 .{., } Figure 7: Semantics of nested Sagas The additional rules for nested \nsagas are in Figure 7. The main idea is that a subtransaction {[P]} executes P in an independent thread \nwithout initial compensation. The suc\u00adcessful completion of {[P]} (rule sub-cmt) is analogous to the \ncase of a successful activity (rule s-act). When the subtransaction commits, the compensation \u00df ' computed \nby P is installed on top of the compensations. Rule (sub-abt) describes the silent abortion of a sub\u00adtransaction. \nAs aforementioned, nesting is intended to allow the commit of a transaction even when some activities \nfail. That is, if an activity in P fails while running {[P]},and the executed activities of P are successfully \ncompensated for, then the abort is hidden to the parent. For this reason the result associated with {[P]}is \nCeven though P aborts. (We discuss another possibility for handling this situation in Sec\u00adtion 5.3). \nThe observed .ow corresponds to the execution of P and the original compensation \u00df is not modi.ed. Instead, \n{[P]}ends abnormally when P has an abnormal termination (sub-fail). This result is propagated until the \ntop-level transaction, which will .nish abnormally. (Sec\u00adtion 5.2 introduces local handlers for abnormal \ntermination). The three rules described above do not allow a subtransac\u00adtion to be stopped and compensated \nfor when a concurrent activity aborts. Consider the saga S ={[ {[P]}| A \u00f7B]} and a con\u00ad a textG = A . \n.,G ' such that G f(P,0)-.(C,\u00df) and a G f(\u00df,0)-.(.,0), the whole saga S should abort because A aborts. \nWith the rules seen until now we can build only the two derivations shown in Figure 8. The branch {[P]}is \nforced to abort either before (Figure 8(a)) or after (Fig\u00adure 8(b)) the whole execution of P. Nevertheless, \nif P is a composed process, for instance a sequence, it is not pos\u00adsible to stop the execution of P once \nit starts. To allow the activation of the compensation procedure in subtrans\u00adactions as soon as possible, \nwe add the last two rules in Fig\u00adure 7, which handle the interruption and compensation of a subtransaction. \nRule (sub-forced-1) handles the failure of the forced compensation. In this case the compensation \u00df previously \ninstalled is not activated since the compensa\u00adtion procedure fails. On the contrary, rule (sub-forced-2) \nactivates \u00df when P is compensated successfully. Example 3 (Nested sagas). The organization has a reward \nprogram in which users accumulate points when they purchase. The activity Add points updates the reward \nbalance of a user. This activity aborts when the buyer is not part of the reward program. Clearly, we \ndo not like the whole process to abort when the user is not registered, for this reason we model this \nactivity as a nested transaction (see Figure 9). The compensation Subtract points undoes the step Add \npoints when some activity in the top level .ow fails. To formalize the adequacy theorems we need some \npre\u00adliminary de.nitions. Definition 7 (Subtransactions). The set of all sub\u00adtransactions of S are S(S)= \n{{[P]}|{[P]} is a proper sub\u00adterm of S}while the top-level subtransactions are Stop(S)= ' ' '' ''' {S \n|S .S(S) ..S .S(S): S .S(S )}.The set of all top-level activities of S is Atop(S)= {A |A .A(|S|) and \nAdoes not occur in a subterm {[P]}}. The de.nition of order of a saga considers only top activ\u00adities \nand subtransactions (i.e., A and B range over top ac\u00adtivities and subtransactions, and A-1 denotes also \ncompen\u00adsations of subtransactions seen as symbolic atoms). Again, we break the adequacy results in three \ntheorems. Theorem 5 (Completion). Let S be a nested saga. a Then G fS -.Ci. 1. if A.Atop(|S|) then A.C.G; \na 2. if S ' .Stop(S) then G f(S ' ,0) -. (C,\u00df) for some a ' ,\u00df. Theorem 6 (Successful compensation). \nLet S be a a nested saga. Then G fS -..i. there exists a non empty set of failed activities FA .Atop(|S|) \ns.t. .A,B .FA: A.S B, and the following conditions hold: 1. if A.A(a) then A.C.G; 2. if A.FA then A.A(a); \n 3. if A.Atop(|S|) and A.S FA then A.A(a), i.e. all top activities that precede FA are executed successfully; \n a '' ' 4. if S .Stop(S) and S .S FA then G f(S,0)-. . (C,\u00df),and G f(\u00df,0) -. (C,0) for some a ' ,\u00df and \n., i.e. all top subtransactions before FA (and their compensations) are successful; 5. if A.Atop(|S|) \nand FA .S A then A.A(a), i.e. all activities in the forward .ow after FA are not executed; ' '' 6. if \nS .Stop(S) and FA .S S then .A .A(S ): A .A(a), i.e. activities of subtransactions following FA are not \nexecuted; 7. if A.A(|S|) and A.A(a) then A-1 .A(a), i.e. all executed activities are compensated successfully. \n Theorem 7 (Abnormal termination). Let S be a a nested saga. Then G fS -. i. there exist: (i) a set \nof ' failed activities FA .A(|S|) and (ii) a set of abnormal ter\u00ad ' minated subtransactions FS .Stop(S) \ns.t.: FA = FA .FS zero zero 00 Gf(0,0)-.(0,0) Gf(0,0)-.(0,0) forced-abt s-cmp zero 000 ' G f({[P]},0)-.(.,0) \nA..,G f(A\u00f7B,0)-.(.,0) G f(0,0)-.(0,0) c-par 0 Gf( {[P]}|A\u00f7B,0)-.(.,0) sub-abt 0 G f({[ {[P]}|A\u00f7B ]},0)-.(0,0) \n(a) {[P]}is not activated . . . . . . .G f(\u00df,0)-.(.,0) forced-abt zero a. 0 Gf({[P]},0)-.(0,\u00df) G f(0,\u00df)-.( \n,0) G f(0,0)-.(0,0) s-step s-cmp a;. 0 ' G f({[P]};0,0)-.( ,0) A..,G f(A\u00f7B,0)-.(.,0) f-par a;.|0 G \nf( {[P]}|A\u00f7B,0) -. ( ,0) sub-fail a;.|0 G f({[ {[P]}|A\u00f7B ]},0)-. ( ,0) (b) P is completely executed \nFigure 8: Possible executions of S ={[ {[P]}| A\u00f7B]}when G= A..,G ' . is not empty and .A1,A2 .FA: A1 \n.S A2, (iii) a set of failed compensations F ' .Atop(S) s.t FC' nA(|S|)= \u00d8, C (iv) a set of precommitted \nsubtransactions with failed com\u00adpensations FP .Stop(S) s.t. FC = FC' .FS-1 .FP-1 is not empty and .A1,A2 \n.FC: A1 .S A2, and the following conditions hold: conditions 1,3,5,6 as in Theorem 6 and ' 2 . if A.FA \nthen A.A(a) 4 . if S ' .Stop(S), S ' .S FA,and S'-1 .S FC then a. G f(S ' ,0)-.(C,\u00df)and G f(\u00df,0)-.(C,0) \n7 . if A .Atop(|S|) and A .A(a) and A-1 .S FC then A-1 .A(a), i.e. activities whose compensations pre\u00adcede \nFC are compensated successfully. a 8. if S ' .FS then G f(S ' ,0)-.(s,0)with s .{ , }, i.e. failed subtransactions \nterminate abnormaly; a '' ' 9. if S .FP then S .S FA, G f(S,0)-.(C,\u00df)and . G f(\u00df,0) -. (.,0), i.e. failed \nprecommitted sub\u00adtransactions complete successfully but their installed compensations fail. ' S'-1 ' \n10. if(S .Stop(S) and FC .S and A .A(S ))or (A .Atop(S) and FC .S A-1)then A-1 .A(a), i.e. compensations \nafter FC are skipped. Previous results do not characterize precisely the order of the observation a (as \nin previous sections). Instead they state the set of executed steps and the result they produce.  5. \nADDITIONAL FEATURES This section presents further extensions of nested sagas. 5.1 Programmable compensations \nThe compensation mechanism described until now is usu\u00adally referred to as implicit or default compensation. \nIn addi\u00adtion, some composition languages (such as bpel4ws) allow Figure 9: A nested saga for handling \norders. the programmer to explicitly de.ne the compensation pro\u00adcedure associated with a completed subtransaction. \nIn our case, the syntax of steps should include terms with the fol\u00adlowing form: S\u00f7P. Consider the long \nrunning transaction S ={[ {[A1 \u00f7B1; A2\u00f7B2]}\u00f7P ; A3]}, which should behave as follows:when A1 commits \nand A2 aborts, the default mech\u00adanism should compensate A1 by activating B1.Instead, if A1 and A2 commit \nwhile A3 aborts, the programmed com\u00adpensation P (and not the default B2; B1) should be run. The di.erence \nbetween default and programmable com\u00adpensations is that the former are always .at processes with\u00adout \ncompensations whose executions always produce results like (.,0), while the latter can produce (.,\u00df).Let \nP = C1 \u00f7D1; {[Q]}\u00f7Q ' ; C2 \u00f7D2 in S above. Clearly, if A3 fails, then P is activated and it can commit, \nabort or terminate abnormally, but it may also generate compensations. In particular, if P commits, then \nit produces (C,D2; Q ' ; D1)but the rules used in previous sections, which assume com\u00adpensations not \nto generate new compensations (i.e. s-cmp, f-cmp, c-par, forced-abt and sub-forced-2), will not handle \nthis expected behavior. One alternative for dealing with programmable compensa\u00adtions is to restrict their \nsyntax to allow only basic activities or processes without compensations. Similarly, without im\u00adposing \na syntactical restriction, to make compensations to behave as their forward .ow, as follow. (pgm-cmp) \na G f(P, 0)-.(0,\u00df ' ) a G f({[P]}\u00f7Q, \u00df)-.(0, |Q|; \u00df) This rule is similar to (sub-cmt) in Figure 7 that \ninstalls the default compensation \u00df ' . Di.erently, rule (pgm-cmp) discards \u00df ' and replaces it by the \nforward .ow |Q| of Q. We recall that the forward .ow of a process is obtained by replacing in P each \nterm Q \u00f7Q-1 by Q. This will assure that the execution of a compensation never generates new compensations \nneither terminates abnormally. On the contrary, it could be possible to take into ac\u00adcount compensations \nproduced by compensations (as done in StAC) and to install and use them to repeatedly compen\u00adsate a process. \nFor instance by adding the following rule (repeated-comp) aa G f(P, \u00df)-.(.,\u00df '' ) G f(\u00df '' , 0)-.(.,\u00df \n' ) \u00df '' =0 a;a G f(P, \u00df)-.(.,\u00df ' ) Consider the process {[ {[P ]}\u00f7A0 ; A1 \u00f7(B1 \u00f7C1); R ]}and an execution \nin which {[P ]}commits and installs A0 as a compensation. Then, A1 commits and installs B1 \u00f7C1 on top. \nSuppose now that R fails and starts the compensation procedure by executing B1 \u00f7C1.If B1 commits, C1 \nwill be installed and could be activated later on, for instance when A0 aborts. Note that this kind of \nde.nitions generates an upward .ow of control when a compensation fails, i.e. the failure of A0 activates \nC1. In our approach, where com\u00adpensations are used to undo committed steps, the meaning of such a construction \nis quite obscure. Basically, it would mean that a successful execution of A1 can be undone by running \nB1, which can be in turn compensated with C1. In particular if they are perfect compensations, i.e. they \nremove all the e.ects, the term A1 \u00f7(B1 \u00f7C1)leaves all the e.ects of A1 when the compensation procedure \nfails. Moreover it is di.cult to .gure out real cases in which re\u00adpeated compensation is really necessary. \nIn our opinion the failure of a compensation can be modelled more naturally by exploiting an exception \nhandling mechanism like the one presented in Section 5.2. For this reason, we prefer rule (pgm-cmp) instead \nof (repeated-comp) for handling pro\u00adgrammable compensations. 5.2 Exception handling A basic exception \nhandling mechanism can be added to the presented languages by interpreting the result ( ,\u00df)as a process \nthat raises an exception. At the syntactic level, we can consider exception handlers introduced by steps \nlike try S with P ,where S is a saga and P a generic process. The behavior for such processes is de.ned \nin Figure 10. The .rst rule handles the case in which S1 .nishes with\u00adout raising an exception. As usual, \nthe exception handler P2 is discarded, and the compensation created by S1 is in\u00adstalled on top of the \nstack. The second rule describes the activation of the handler P2 when S1 raises an exception. Note that \nP2 starts with the original compensation \u00df.The last rule handles the activation of the compensation handler \nwhen the abnormal termination is reached during a forced compensation. The handler is also run in this \ncase because it is intended to .nish the compensation procedure. Note that the .nal result is always \na forced termination. (no-excp) a G f(S, 0)-.(.,\u00df ' ) with .{C, ., .} . a G f(try S with P, \u00df)-.(.,\u00df \n' ; \u00df) (excp) aa G f(S, 0)-.( , 0) G f(P, \u00df)-.(.,\u00df ' ) a;a G f(try S with P, \u00df)-.(.,\u00df ' ) (forced-excp) \naa G f(S, 0)-.( , 0) G f(P, \u00df)-.(.1,\u00df ' ) a;a G f(try S with P, \u00df)-.(.2,\u00df ' ) . if .1 = with .2 = .otherwise \nFigure 10: Semantics of exception handling Although the described mechanism is na\u00a8ive, it illustrates \nthe interplay between both concepts:compensations undo partial executions of transactions, while exception \nhandling deals with incomplete compensations. 5.3 Alternatives to aborted subtransactions In the nested \nmodel we presented in Section 4, the be\u00adhavior of a parent transaction does not depend on the com\u00adpletion/abortion \nof its subtransactions. In fact, rule sub\u00adabt hides to the parent transaction the fact that one (or more) \nof its subtransactions have not been executed (i.e., compensated). Nevertheless, work.ow systems usually \nal\u00adlow the possibility of specifying forward recovery strategies for a process that fails to commit, \nsuch as the retry of the activity or the execution of an alternative process. These aspects can be modelled \nby extending the language with new primitive steps try S or P whose behavior can be described with the \nfollowing rules (s-alt) a G f(S, 0)-.(C,\u00df ' ) a G f(try S or P, \u00df)-.(C,\u00df ' ; \u00df) (f-alt) a G f(S, 0)-.(., \n0) with ..{ , ., } a G f(try S or P, \u00df)-.(., 0) (t-alt) aa G f(P, 0)-.(., 0) G f(P, \u00df)-.(.,\u00df ' ) a;a \nG f(try S or P, \u00df)-.(.,\u00df ' ) This mechanism is similar to the exception handling de\u00adscribed above. Nevertheless, \nwhile exception handling is used during backward computation (for failed compensa\u00adtions) alternative \nprocedures are used as a forward recovery mechanism. For this reason, an alternative is activated only \nwhen the subtransaction aborts. Moreover, by rule (f-alt), which shift the forced abortion .to the parent \nlevel, alterna\u00adtives are not executed during a forced termination. In fact, alternatives are intended \nto be used while executing towards a completion not during the compensation procedure.  5.4 Choices \nThe recovery capability introduced above allows the se\u00adquential search of one process that executes successfully. \nSome composition languages (like bpml [6]) allow alterna\u00adtives to be explored in parallel (this kind \nof choice is known as discriminator). Once one branch .nishes successfully all the remaining alternatives \nare stopped and compensated for. We will write these processes as P .Q, and we assume .as\u00adsociative and \ncommutative. Inference rules are in Figure 11. The last two rules (i.e., abnormal termination (f-choice) \nand abort ((c-choice)) are analogous to those for paral\u00adlel composition. Di.erently, a choice P .Q succeeds \nonly when one branch commits and the other has been success\u00adfully (possible forced) compensated for (rule \ns-choice). A computation cannot go forward when one branch terminates abnormally because the state of \nthe system is inconsistent. Hence, the successful branch is forced to compensate and the whole process \nP .Q ends abnormally (f-choice). (s-choice) G f(P, 0) a-.(C,\u00df ' ) G f(Q, 0) a-.(., 0) G f(P .Q, \u00df) a|a \n-.(C,\u00df ' ; \u00df) with ..{., .} (f-choice) G f(P, 0) a-.(s1, 0) G f(Q, 0) a-.(s2, 0) G f(P .Q, \u00df) a|a -.(s1 \n.s2, 0) {s1 .{ , }s2 .{., , ., } (c-choice) G f(P, 0) a-.(s1, 0) G f(Q, 0) a-.(s2, 0) G f(\u00df, 0) . -.(.1, \n0) G f(P .Q, \u00df)(a|a );. -. (s1 .s2 ..2, 0) s1,s2 .{., .} and .2 = { . if .1 = C otherwise Figure 11: \nSemantics for the choice of a successful branch: P .Q These kind of choices, where the selection takes \nplace once one of the branches has completed successfully, are quite dif\u00adferent to usual internal or \nexternal choices. Internal choices P nQ can be de.ned straightforwardly by de.ning a unique rule and \nrequiring nto be associative and commutative. (int-choice) a G f(P, \u00df)-.(.,\u00df ' ) a G f(P nQ, \u00df)-.(.,\u00df \n' ) External choices are related to the notion of synchroniza\u00adtion of events that make the description \nof .ows not struc\u00adtured. We analyze more in detailed the synchronization be\u00adtween .ows in the following \nsection.  5.5 Link dependencies This section discusses the synchronization of concurrent .ows. Consider \nthe .ow depicted in Figure 12, and let P =A1 \u00f7B1;(A2 \u00f7B2; A4 \u00f7B4|A3 \u00f7B3; A5 \u00f7B5); A6 \u00f7B6 with the additional \nconstraint stating that A4 must be exe\u00adcuted after A3, written link(A3 , A4 ). Hence, any valid execu\u00adtion \na of P must hold both the order given by P and the ad\u00additional constraints A3 .a A4. Although all languages \nagree on this meaning for links (or synchronization) while com\u00adputing forward, it is less clear which \nis the desired behavior when compensating. For instance, StAC (which provides an operator for parallel \ncomposition with synchronization over a name set) ignores all synchronizations when computing backward. \nFor instance, if A6 fails during the execution of P , then, according to the compensation policy of StAC,the \ncompensation procedure could activate B3 before the ter\u00admination of B4. In our opinion this semantics \nhas a main drawback in that the encoding of sequential composition as a synchronization between parallel \n.ows has a di.erent meaning when compensating. Consider the sequential pro\u00adcess P =A1 \u00f7B1; A2 \u00f7B2; Q,and \nP ' =A1 \u00f7B1 |A2 \u00f7B2; Q with link(A1 , A2 ). It is clear that requiring A1 .a A2 does not make any execution \na of P a valid execution of P ' :we also need B2 .a B1. The following de.nitions formalize the notion \nof valid ex\u00adecution for a structured .ow process with links. Definition 8 (Order of a saga with links). \nLet S be a parallel saga and L = {link(Ai,Aj)|Ai,Aj .A(S)}be a set of links. The order .S,L is the least \ntransitive and antisymmetric relation (if de.ned) satisfying: (i) .S..S,L, and (ii) .link(Ai,Aj) .L, \nAi .j S,L A-1 . S,L Aj and A-1 .i Clearly, when L introduces cycles in the control .ow the order is not \nde.ned. The following de.nition singles out those executions that satisfy a set of well-de.ned links. \nDefinition 9 (Valid execution with links). Let S be a parallel saga and L aset of linkss.t. .S,L is de.ned. \nAn a order a is a valid execution of S with links L i. G fS -.. and a =. a ,L. The de.nition above simply \nstates that a valid execution of a process with links is an execution of the process that also satis.es \nthe dependency constraints.  6. CONCLUSION AND FUTURE WORKS We have presented several primitives and \nmechanisms for the speci.cation and execution of long running transactions in .ow composition languages. \nIn this context, the key issue is the backward compensation of completed activities upon abortion at \na later stage of the transaction:compensations must be programmable and installable. Starting from the \nformalization of sequential sagas with a minimal set of primitives, we have progressively enriched the \nlanguage with primitives for dealing with parallelism, nest\u00ading, exception handling and choices. In particular, \nparallel composition and nesting requires a careful analysis of the mechanisms used for notifying failures \nto siblings and forc\u00ading their abortion. We have given to each language a neat big step semantics and \nproved its adequacy with respect to the informal requirements of each di.erent kind of sagas. This work \nfollows a thread (started not earlier than four years ago) concerning the formalization of transactions \nvia   A1\u00f7B1    A2\u00f7B2A3\u00f7B3   A4\u00f7B4A5\u00f7B5  A6\u00f7B6 Figure 12: A .ow with links. process description \nlanguages. Works in the literature rough\u00adly fall into one of the categories below: Extensions of well-known \ncalculi that exploits the original characteristics of the calculus to describe .ow or interaction based \ncomposition.(Like dialects of the p-calculus [4], of the Join [8], and of the object calculus [15]). \nLanguages for the description of business processes.They are generally graphical or xml-based languages \nthat do not provide a formal / unambiguous de.nition of their seman\u00adtics. All well-known (proposed) standards \nfall into this cat\u00adegory, for instance xlang [21], wsfl [16], bpel4ws [5]. Formal de.nition of compensations \nfor .ow composition languages. To the best of our knowledge StAC is the only proposal in this category. \nNevertheless, since the use of operators and transaction scopes are not well-disciplined in StAC, it \nallows writing processes with obscure meaning. This work is a next step in the line initiated by StAC.Our \ngoal is to formalize the relation of compensation with ordi\u00adnary primitives in .ow languages and to highlight \nalternative meanings for them (such as forced termination of concur\u00adrent processes vs. independent completion \nof threads, silent abort of subtransactions vs. forward recovery). Neverthe\u00adless, there are several aspects \nin this work that still require investigation. For instance, we do not include usual impera\u00adtive features, \nsuch as state (or variables), control structures like branching or iteration, neither data communication \nbe\u00adtween activities (i.e. parameter passing). We abstract away from the fact that compensations usually \nrequire appropri\u00adate data when activated. Dependency links are .rst step to\u00adwards this direction, but \nundoubtedly, more work is needed to formally explain the state seen by compensations. We leave these \nissues as future work. Acknowledgments. We thank Michael Butler and Carla Ferreira for the discussions \nabout StAC semantics that mo\u00adtivated this work, and Dan Hirsch for helpful comments. 7. REFERENCES [1] \nW.Aalst,M. Dumas,and A. Hofstede. Web service composition languages:Old wine in new bottles? Proc. of \nEUROMICRO 03, pp. 298 307. IEEE Computer Society, 2003. [2] W. Aalst, M. Dumas, and A. Hofstede, and \nP. Wohed, Analysis of web services composition languages:The case of bpel4ws. Proc. of ER 03, vol. 2813 \nof LNCS, pp. 200 215. Springer, 2003. [3] B. Benatallah and R. Hamadi. A Petri net-based model for web \nservice composition. Proc.ofADC 03, pp. 191 200. Australian Computer Society, 2003. [4] L. Bocchi, C. \nLaneve, and G. Zavattaro. A calculus for long-running transactions. Proc. of FMOODS 03,vol. 2884 of LNCS, \npp. 124 138. Springer, 2003. [5] bpel Speci.cation. Version 1.1. Available at http: //www.ibm.com/developerworks/library/ws-bpel. \n [6] Business process modelling language (bpml). http://www.bpmi.org. [7] A. Brogi, C. Canal, E. Pimentel, \nand A. Vallecillo. Formalizing web services choreographies. Proc. of WS-FM 04. To appear as ENTCS. [8] \nR. Bruni, H. Melgratti, and U. Montanari. Nested commits for mobile calculi:extending Join. Proc. of \nIFIP-TCS 04, pp. 569 582. Kluwer, 2004. [9] M. Butler, M. Chessell, C. Ferreira, C. Gri.n, P. Henderson, \nand D. Vines. Extending the concept of transaction compensation. IBM Systems Journal, 41(4):743 758, \n2002. [10] M. Butler and C. Ferreira. An operational semantics for StAC, a language for modelling long-running \nbusiness transactions. Proc. of Coordination 04,vol. 2949 of LNCS, pp. 87 104. Springer, 2004. [11] P. \nChrysanthis and K. Ramamritham. Transaction Models for Advanced Applications, acta:The saga Continues, \npp. 349 397. Morgan Kaufmann, 1992. [12] H. Garcia-Molina and K. Salem. Sagas. Proc. of ACM SIGMOD 87, \npp. 249 259. ACM Press, 1987. [13] D. Georgakopoulos, M. Hornick, and A. Sheth. An overview of work.ow \nmanagement:From process modeling to work.ow automation infrastructure. Distributed and Parallel Databases, \n3(2):119 153, 1995. [14] C. Hoare. Long-running transactions. Slides for the Second Microsoft .NET Crash \nCourse 2002. http://research.microsoft.com/Collaboration/ University/Europe/Events/dotnetcc/Version2. \n[15] A. Hosking, S. Jagannathan, J. Vitek, and A. Welc. A semantic framework for designer transactions. \nProc. of ESOP 04, vol. 2986 of LNCS, pp. 249 263. Springer, 2004. [16] F. Leymann. The wsfl Guide. Available \nat http://www.ibm.com/software/solutions/ webservices/documentation.html. [17] M. Mazzara and R. Lucchi. \nA framework for generic error handling in business processes. Proc. WS-FM 04. To appear as ENTCS. [18] \nL. G. Meredith and S. Bjorg. Contracts and types. Commun. ACM, 46(10):41 47, 2003. [19] J. Moss. Nested \nTransactions: An Approach to Reliable Distributed Computing.PhD thesis,Dept. of Electrical Eng. and Computer \nSci., MIT, 1981. [20] A. Sheth and D. Worah. Transactions in transactional work.ows. Advanced Transaction \nModels and Architectures, pp. 3 34. Kluwer, 1997. [21] S. Thatte. xlang:Web Services for Business Process \nDesign. Available at http: //www.gotdotnet.com/team/xml_wsspecs/xlang-c. [22] M. Viroli. Towards a formal \nfoundation to orchestration languages. Proc. of WS-FM 04.To appear as ENTCS. [23] WebSphere Software \nPlatform. IBM. Available at http://www.ibm.com/software/websphere. [24] wsci Speci.cation. Version 1.0. \nAvailable at http://www.w3.org/TR/wsci.  \n\t\t\t", "proc_id": "1040305", "abstract": "A key aspect when aggregating business processes and web services is to assure transactional properties of process executions. Since transactions in this context may require long periods of time to complete, traditional mechanisms for guaranteeing atomicity are not always appropriate. Generally the concept of long running transactions relies on a weaker notion of atomicity based on compensations. For this reason, programming languages for service composition cannot leave out two key aspects: <i>compensations</i>, i.e. ad hoc activities that can undo the effects of a process that fails to complete, and <i>transactional boundaries</i> to delimit the scope of a transactional flow. This paper presents a hierarchy of transactional calculi with increasing expressiveness. We start from a very small language in which activities can only be composed sequentially. Then, we progressively introduce parallel composition, nesting, programmable compensations and exception handling. A running example illustrates the main features of each calculus in the hierarchy.", "authors": [{"name": "Roberto Bruni", "author_profile_id": "81100368636", "affiliation": "Universit&#224; di Pisa, Italia", "person_id": "PP14131137", "email_address": "", "orcid_id": ""}, {"name": "Hern&#225;n Melgratti", "author_profile_id": "81100647244", "affiliation": "Universit&#224; di Pisa, Italia", "person_id": "PP14221788", "email_address": "", "orcid_id": ""}, {"name": "Ugo Montanari", "author_profile_id": "81100532297", "affiliation": "Universit&#224; di Pisa, Italia", "person_id": "PP15035334", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1040305.1040323", "year": "2005", "article_id": "1040323", "conference": "POPL", "title": "Theoretical foundations for compensations in flow composition languages", "url": "http://dl.acm.org/citation.cfm?id=1040323"}