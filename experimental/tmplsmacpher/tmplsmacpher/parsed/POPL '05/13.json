{"article_publication_date": "01-12-2005", "fulltext": "\n Downgrading Policies and Relaxed Noninterference Peng Li Steve Zdancewic University of Pennsylvania \nUniversity of Pennsylvania lipeng@cis.upenn.edu stevez@cis.upenn.edu ABSTRACT In traditional information-.ow \ntype systems, the security policy is often formalized as noninterference properties. How\u00adever, noninterference \nalone is too strong to express security properties useful in practice. If we allow downgrading in such \nsystems, it is challenging to formalize the security pol\u00adicy as an extensional property of the system. \nThis paper presents a generalized framework of downgrad\u00ading policies. Such policies can be speci.ed in \na simple and tractable language and can be statically enforced by mecha\u00adnisms such as type systems. The \nsecurity guarantee is then formalized as a concise extensional property using program equivalences. This \nrelaxed noninterference generalizes tradi\u00adtional pure noninterference and precisely characterizes the \ninformation released due to downgrading.  Categories and Subject Descriptors D.3.3 [Programming Languages]: \nLanguage Constructs and Features Constraints, Data types and structures, Frame\u00adworks; F.3.1 [Logics and \nMeanings of Programs]: Spec\u00adifying and Verifying and Reasoning about Programs Speci\u00ad.cation Techniques, \nInvariants, Mechanical veri.cation; K.6.5 [Management of Computing and Information Sys\u00adtems]: Security \nand Protection. General Terms Languages, Design, Security, Theory.  Keywords Downgrading policies, \ninformation .ow, language-based se\u00adcurity, relaxed noninterference, program equivalence. 1. INTRODUCTION \nThe Challenge of Downgrading In this paper we focus on a speci.c area of computer secu\u00adrity research, \nnamely, language-based information-.ow secu\u00adrity [17], where the target systems are computer programs. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n05, January 12 14, 2005, Long Beach, California, USA. Copyright 2005 ACM 1-58113-830-X/05/0001 ...$5.00. \nThe security properties we care about are con.dentiality and integrity, speci.ed by information-.ow policies, \nwhich are usually formalized as noninterference [4] [8], a global extensional property of the program \nthat requires that con\u00ad.dential data not a.ect the publicly visible behavior. Such information .ow policies \ncan be enforced by mechanisms like type systems and static program analysis [19] [13] [14] [1]. In information-.ow \ncontrol, each piece of data is anno\u00adtated by a label that describes the security level of the data. Such \nlabels usually form a partially ordered set. Pure non\u00adinterference policies only allow data .ow from \nlow security places to high security places. As a program runs, the la\u00adbel of data can only become higher. \nThis restriction is not practical in most applications. Take the example of a login process, the password \nis a secret and it has a higher secu\u00adrity level than the user-level data. By comparing the user input \nwith the password and sending the result back to the user, data .ows from high to low, thus the noninterference \nproperty is violated. We use the word downgrading to specify information .ow from a high security level \nto low security level. It is also called declassi.cation for con.dentiality and endorsement for integrity. \nAs we allow downgrading in the system, pure noninterference no longer holds and the security policy of \nthe whole system becomes much more complex. Instead of using an elegant extensional property such as \nnoninterfer\u00adence, most downgrading policies are intensional, specifying exactly what circumstances information \ncan .ow in which order. To formally specify such policies, we may require an accurate description of \nthese intensional properties in a complex piece of software, which can be very complicated. Such security \npolicies can be hard to specify, understand and enforce. It is also di.cult to prove the soundness of \nthe corresponding enforcement mechanism. Our Contribution We approach the downgrading problem by allowing \nthe user to specify downgrading policies. Weuse a typesystemto enforce such policies, and formalize the \nsecurity goal as an extensional property called relaxed noninterference,which generalizes pure noninterference \nand accurately describes the e.ects due to downgrading. Our research is based on the observation that \na noninterfering program f(h, l)can usually be factored to a high security part fH(h, l)and a low security \npart fL(l) that does not use any of the high\u00adlevel inputs h. As a result, noninterference can be proved \nby transforming the program into a special form that does not depend on the high-level input. Relaxed \nnoninterference can then be formalized by factoring the program into the composition of such a special \nform and some functions that depend on the high-level inputs, which we treat as down\u00adgrading policies. \n 2. BACKGROUND AND RELATED WORK Before presenting our results in detail, it is useful to de\u00adscribe some \nprior approaches to the problem of downgrading. DLM and Robust Declassi.cation The decentralized label \nmodel (DLM) invented by Myers and Liskov [10] puts access control information in the security labels \nto specify the downgrading policy for the annotated data. Di.erent mutually-distrusting principals can \nspecify their own access control rules in the same label. Such labels are well-structured and can be \nused to express both con\u00ad.dentiality and integrity. Downgrading is controlled based on the code authority \nand the access control information in the label of data to be downgraded: each principle can only weaken \nits own access control rules. Practical languages such Jif [9] have been built based on the DLM. The \ndowngrading policy speci.ed by the DLM is highly intensional and it is di.cult to formalize as an extensional \nproperty of the program. Once downgrading happens in the program, the noninterference property is broken \nand the user cannot reason about the e.ects of downgrading. Trusted code can downgrade its data in arbitrary \nways, whereas untrusted code cannot downgrade any data that does not belong to it. Robust declassi.cation \n[20] improves the DLM by impos\u00ading a stronger policy on downgrading that requires the de\u00adcision to perform \ndowngrading operations only depend on trustworthy (high-integrity, untainted) data. Such a policy can \nbe formalized and the security guarantee can be ex\u00adpressed as an extensional property of the system [11]. \nNev\u00adertheless, it only addresses one particular useful policy for downgrading. It cannot provide detailed \nguarantees on how the data is downgraded, and downgrading is still forbidden for untrusted code. Our \nwork borrows some philosophy from robust declassi.\u00adcation. Although we are concerned with con.dentiality \nand the process of declassi.cation, the policies for downgrad\u00ading can be thought of as integrity properties \nof the system: they require the downgrading operation to be trustworthy and correct with respect to some \nspeci.cation. Complexity Analysis and Relative Secrecy To look for a system-wide extensional guarantee \nwith the existence of downgrading, Volpano and Smith proposed the relative secrecy [18] approach as a \nremedy for noninterfer\u00adence. They designed a type system that contains a match primitive, where the secret \ncan only be leaked by comparing it to untrusted data via this primitive. The security goal is then formalized \nas a computational complexity bound of the attack. However, this approach lacks some .exibility in practical \napplications. It assumes that there is a single secret in the system and the attack model for the system \nis .xed, thus it only enforces one particular useful downgrading policy using a particular mechanism. \nTo express and enforce other downgrading policies like the parity of the secret integer n can be leaked \n, we need completely di.erent frameworks and mechanisms. Abstract Noninterference Giacobazzi and Mastroeni \nused abstract interpretations to generalize the notion of noninterference by making it para\u00admetric to \nwhat the attacker can analyze about the informa\u00adtion .ow [3]. Many downgrading scenarios can be formally \ncharacterized in this framework, and the security guarantee is formalized in a weakened form of noninterference. \nHow\u00adever, this framework is mainly theoretical. To practically apply this theory in building program \nanalysis tools, we need to design ways to express the security policies and mecha\u00adnisms to enforce such \npolicies. Intransitive Noninterference Our work has a close relationship to intransitive noninter\u00adference \n[15] [7], where special downgrading paths exist in the security lattice. During downgrading, data can \n.ow in\u00addirectly through these paths, although there is no direct lattice ordering between the source \nand the destination. We improve this idea of intransitive noninterference by param\u00adeterizing the downgrading \npaths with actions, and globally reasoning about the e.ects due to downgrading. Quantifying Information \nFlow Some interesting work has been done using quantitative ap\u00adproaches [5] [6] [12] to precisely estimate \nthe amount of in\u00adformation leakage when downgrading is available. Drawing on this research, we order \nthe security levels by comparing their abilities to leak information. Programs leaking more information \nare considered less secure. However, comparing the quantity of information leakage does not have directly \nsensible meanings in many situations. Instead of using real numbers as metrics for information leakage, \nwe use program fragments; the information order is de.ned among these pro\u00adgrams. Delimited Information \nRelease Sabelfeld and Myers [16] proposed an end-to-end security guarantee called delimited release that \ngeneralizes nonin\u00adterference by explicitly characterizing the computation re\u00adquired for information release. \nOur work generalizes delim\u00adited release in two ways. First, we treat the computation re\u00adquired for declassi.cation \nas security policies and use these policies to represent security levels for each piece of data in the \nsystem. Second, downgrading can be .ne-grained and implicit in our framework. We formalize the security \nguar\u00adantee by transforming a safe program to the form of delim\u00adited release, where all the downgrading \nexpressions explicitly match the downgrading policies. 3. A FRAMEWORK OF DOWNGRADING POLICIES 3.1 The \nMotivation The focus of our research is studying downgrading policies. Instead of studying who can downgrade \nthe data as the decentralized label model did, we take an orthogonal direc\u00adtion and study how the data \ncan be downgraded .Instead of having various mechanisms that provides vastly di.erent kinds of security \nguarantees, we would like to have a more general framework where the user can specify downgrading policies \nthat accurately describes their security requirement, and have the enforcement mechanism carry out such \npoli\u00adcies. We have the following goals for downgrading policies: Expressiveness: The programmers should \nbe able to spec\u00adify a rich set of downgrading policies depending on their highly-customized security \nrequirement. Such policies are .ne-grained and describes security requirements for each piece of data \nin the system. For example: some data is a top secret and we do not allow any information to leak from \nit; some secrets can be downgraded by encrypting them; for some secret data we can safely reveal the \nlowest several bits; root passwords can only be leaked by comparing them to public data; etc. Representability: \nThe downgrading policies should be for\u00admally speci.ed in representable forms. It should be easy for the \nprogrammer to write down their policies and such policies are meant to be understood by both human and \nmachines. In this paper, we use a simple programming lan\u00adguage to express downgrading policies and treat \nthese poli\u00adcies as security levels so that the programmer can use them as type annotations. Tractability: \nSuch policies must be enforceable by some mechanisms such as type systems or model checking. Since we \nare extending the traditional language-based information\u00ad.ow security, it is desirable to use similar \nstatic approaches, where the policies are enforced at compilation time rather than at run time. Extensional \nGuarantee: This is the main challenge we face: if the policies are enforced by some mechanism, what are \nthe security guarantees they bring to the user? The policies are .ne-grained and the enforcement mechanisms \nare usually intensional, yet we would like to have a formal, system-wide, extensional security guarantee \nthat looks sim\u00adple, elegant, understandable and trustworthy. We also want to formally prove the soundness \nof the enforcement mecha\u00adnism with respect to this security guarantee. In this paper, we express such \nguarantees in a form of relaxed noninter\u00adference, where the e.ects of downgrading policies can be accurately \ncharacterized by program equivalences. 3.2 Downgrading Policies as Security Levels The main idea of \nour framework is to treat downgrading policies as security levels in traditional information .ow sys\u00adtems. \nInstead of having only H and L in the security lattice, we have a much richer lattice of security levels \nwhere each point in the lattice corresponds to some downgrading pol\u00adicy, describing how the data can \nbe downgraded from this level. For example, the policy corresponding to H is that the information cannot \nbe leaked to public places by any means, whereas the policy implied by L is that the data can be freely \nleaked to the public places. In our policy language, we express H using constant functions and express \nL using identity functions. The security levels in the middle of the lattice are more interesting. We \ntake the following program as an example, where the security policy for secret is that the secret can \nonly be leaked by comparing the lowest 64 bits of its hashed value to some public data , and input,output \nhave security level L. Example 3.2.1 (Downgrading). 01 x := hash(secret); 02 y:= x%2^64; 03 if (y=input) \nthen output:=1 else output:=0; 04 z:=x %3; Downgrading happens when the secrets are involved in some \ncomputation. In the .rst statement, we computed the hash of the secret, so the downgrading policy for \nx should be that x can only be leaked by comparing its lowest 64 bits to some public data . After the \nsecond statement, the policy for y should be that y can only be leaked by comparing it to some public \ndata . In the branching statement, the policy for the conditional (y=input) should be L because y is \ncompared to input. Therefore, the information leak from secret to output is safe with respect to the \ndowngrading policy of secret. However, in the last statement, we cannot .nd a way to downgrade z while \nsatisfying the policy for x and secret. To be safe, the security level for z can only be H: it cannot \nbe downgraded by any means. With the existence of downgrading, the ordering among these security levels \nis more complicated than in the tradi\u00adtional security lattice. Brie.y speaking, there are two kinds of \nordering here. Subtyping order. We can extend the traditional L . H lattice with something in the middle: \nL . ls . H where ls denotes the security level of secret.We can see that it is always safe for information \nto .ow from lower levels to higher levels, because it is equivalent to making the downgrading policy \nmore restrictive. How\u00adever, the security level lx for x has no such ordering with ls because it does \nnot make sense to give x the same downgrading policy as secret doing so will violate the downgrading \npolicy for secret.  Downgrading order. Although we do not have lx . ls, it is true that ls can be downgraded \nto lx via certain computation, which we call an action. Weuse theno\u00ad  a tation ls . lx to specify the \ndowngrading relation via action a. This is similar to the approach of intran\u00adsitive noninterference, \nbut the key di.erence is that, the downgrading relation is determined by the seman\u00adtics of the security \nlevels and the action a performed, and this information is crucial for reasoning about the global e.ects \nof downgrading. 3.3 The Road Map Our framework consists of three parts: policy speci.cation, enforcement \nmechanism and the security guarantee.The basis of our theory is a well-studied, security-typed language \n.sec as shown in Figures 3, 4 and 6, where security levels from the simplest security lattice LLH = {L, \nH} are used as type annotations. A noninterference theorem can be proved for languages like .sec. The \nrest of this paper is organized in a step-by-step fash\u00adion. We .rst set out to de.ne a lattice of local \ndowngrading policies called Llocal in Section 4, where each policy describes how the secret can be downgraded \nby interacting with con\u00adstants and low-level public information. Correspondingly, we extend the language \n.sec to .. in Section 5 with typing local rules for downgrading. We formalize the security guarantee \nas a relaxed form of noninterference using program equiv\u00adalences and prove the soundness of our type \nsystem. In Section 6 and 7, we extend Llocal to Lglobal with global down\u00adgrading policies that describes \nhow secrets can be leaked by composing multiple secrets together, and patch the type sys\u00adtem to .. with \na similar relaxed noninterference theorem. global We discusses the application of this framework in Section \n8 and conclude in Section 9.  4. LOCAL DOWNGRADING POLICIES 4.1 Label De.nition De.nition 4.1.1 (The \npolicy language). In Figure 1. Types t ::= int | t . t Constants c ::= ci Operators . ::= +,-,=,... Terms \nm::= .x:t. m | mm | x | c | m. m Policies n ::= .x:int.m Labels l ::= {n1,...,nk} (k = 1) Figure 1: Llocal \nLabel Syntax The core of the policy language is a variant of the simply\u00adtyped .-calculus with a base \ntype, binary operators and con\u00adstants. A downgrading policy is a .-term that speci.es how an integer \ncan be downgraded: when this .-term is ap\u00adplied to the annotated integer, the result becomes public. \nA label is a non-empty set of downgrading policies, specifying all possible ways to downgrade the data. \nA label can be an in.nite set. Each label represents a security level and can be used as type annotations. \nFor example, if we have x : int{m1} where m1 is de.ned as .y : int.y%4, then the result of the application \n(m1 x) = x%4 is considered a pub\u00adlic value. Take the password checking example, we can let p: int{m2} \nwhere m2 is .x: int..y: int.x = y, so that the application (m2 p) = .y: int.p = y is considered as a \npub\u00adlic closure, assuring that the only way to leak information about p is to use this closure and perform \nthe comparison with p. De.nition 4.1.2 (Label well-formedness). 1. A policy language term m is well-typed, \ni. f m: t in the simply-typed .-calculus. 2. A label l is well-formed, i. .n . l, n is well-typed. \n3. Let Llocal be the set of all well-formed labels (both .nite and in.nite).  Note. In the rest of the \npaper, we implicitly assume that all the labels are well-formed in our discussion. De.nition 4.1.3 (Term \nequivalence). We use conven\u00adtional \u00df- . equivalences for .-calculus, as de.ned in Figure 2. We write \nm1 = m2 as an abbreviation for f m1 = m2 : t. We write G f m1 = m2 as an abbreviation for G f m1 = m2 \n: t. The rules in Figure 2 are call-by-name equivalences, which may not preserve the termination behavior \nin a call-by-value semantics. It is important that our policy language has no .xpoints and programs never \ndiverge. De.nition 4.1.4 (Term composition). If f m1 : t1 . t3, f m2 : t2 . t1, then the composition \nof m1 and m2 is de.ned as: m1 . m2 = .x:t2.m1 (m2 x). 4.2 Label Interpretation Each label is syntactically \nrepresented as a set of down\u00adgrading policies, but the semantics of the label includes more than the \nspeci.ed policies. Generally speaking, if n . l and n' = m.n,then n' is also a valid downgrading policy \nimplied G f m:t Q-Refl G f m= m: t G f m1 = m2 : t Q-Symm G f m2 = m1 : t G f m1 = m2 : t G f m2 = m3 \n: t Q-Trans G f m1 = m3 : t G,x:t1 f m1 = m2 : t2 Q-Abs G f .x:t1.m1 = .x:t1.m2 : t1 . t2 G f m1 = m2 \n: t1 . t2 G f m3 = m4 : t1 Q-App G f m1 m3 = m2 m4 : t2 G f m1 = m2 : int G f m3 = m4 : int Q-BinOp \nG f m1 . m3 = m2 . m4 : int G,x:t1 f m1 :t2 G f m2 :t1 Q-Beta G f (.x:t1.m1) m2 = m1{m2/x} : t2 \u00acfree(x,m)G \nf m:t1 . t2 Q-Eta G f m= .x:t1.mx : t1 . t2 Figure 2: Term Equivalences G f m1 = m2 : t ' by l, because \neach time we apply nto the data x annotated by l, it is equivalent to .rst applying n to x to get a public \nresult (nx), then applying m to the public result, so that m (nx) = n' x can also be considered as public. \nThere\u00adfore, a .nite label implies in.nite number of downgrading policies and we need to de.ne the interpretation \nof a label l to represent all downgrading policies such that, when the policy term is applied to the \ndata annotated by l,the result is considered public. De.nition 4.2.1 (Label interpretation). Let S(l) \ndenote the semantic interpretation of the label l: S(l)= {n' | n' = m. n, n . l} This label semantics \nenjoys the following properties: Lemma 4.2.1 (Properties of S(l)). 1. l . S(l)= S(S(l)). 2. n . S(l) \ni. .n' . l,.m, n= m. n'. 3. l1 . S(l2) i. .n1 . l1, .n2 . l2,.m, n1 = m. n2. 4. l1 . S(l2) i. S(l1) \n. S(l2).  We can now reason about the equivalence of labels with respect to the label semantics. Two \nlabels are considered as structurally equivalent if they denote the same set of down\u00adgrading policies: \nDe.nition 4.2.2 (Structural equivalence of labels). We de.ne the structural equivalence =l on Llocal: \nl1 =l l2 i. S(l1)= S(l2) Corollary 4.2.1 (Properties of =l). 1. l =l S(l) 2. l1 =l l2 i. l1 .S(l2) and \nl2 .S(l1)  4.3 Label Ordering To organize Llocal as a lattice, we need to introduce partial ordering \namong the labels and to de.ne joins and meets. De.nition 4.3.1 (Label ordering). Let .be a binary relation \non Llocal such that l1 .l2 i. S(l2) .S(l1) This de.nition relies on the set inclusion relation of label \ninterpretations. If l2 has fewer downgrading policies than l1 has, then l2 denotes a higher security \nlevel. We can al\u00adlow information to .ow from l1 to l2 without changing its content. If we use labels \nas type annotations, the ordering of labels determines the subtyping relation: if l1 .l2,then intl1 =intl2 \n. Corollary 4.3.1. .is a partial order on Llocal. Corollary 4.3.2. l1 .l2 i. l2 .S(l1). De.nition 4.3.2 \n(Joins and meets). The upper bound for a set of labels X is a label l such that x .X implies x .l.The \njoin or the least upper bound for X is an upper bound l such that for any other upper bound z of X, it \nis the case that l .z.  The lower bound for a set of labels X is a label l such that x .X implies l \n.x.The meet or the greatest lower bound for X is a lower bound l such that for any other lower bound \nz of X, it is the case that z .l.  The notation UX and nX denote the join and the meet of X. The notation \nl1 Ul2 and l1 nl2 denote the join and the meet of {l1,l2}. Because we de.ned the partial ordering using \nsubset rela\u00adtion, the joins and meets of labels share the same structure as sets: Corollary 4.3.3 (Interpreting \njoins and meets). 1. .X,.l1,.l2 such that l1 =l UX and l2 =l nX 2. S(UX)= n(S(X)), S(l1 Ul2)= S(l1) \nnS(l2) 3. S(nX)= .(S(X)), S(l1 nl2)= S(l1) .S(l2)  It is inconvenient to use in.nite interpretations \nto rep\u00adresent the result of join and meets. The following lemma shows how to compute joins and meets \ndirectly. Lemma 4.3.1 (Computing joins and meets). 1. l1 nl2 =l l1 .l2. 2. l1 Ul2 =l {n |.m1,.m2,.n1 \n.l1,.n2 .l2, n =m1 .n1 =m2 .n2}.  De.nition 4.3.3 (Highest and lowest labels). H = ULlocal, L = nLlocal \nThe following lemma shows the beauty of this lattice. H corresponds to the most restrictive downgrading \npolicy, where the secret cannot be leaked by any means. To ex\u00adpress such a policy in our policy language, \nwe can use a constant function .x: int.c as the only policy in the label. The intuition is that this \nfunction is completely noninterfer\u00ading, i.e. we can learn nothing about its input x by studying its output \nc. On the other hand, L corresponds to the least restrictive policy, where the data itself is already \nconsidered as public. The simplest way to express this fact is to use the identity function .x: int.x \nas the policy, meaning that we can leak all information about this piece of data. Lemma 4.3.2. H =l {.x:int.c}, \nL =l {.x:int.x} Proof: For any well-formed label l, we can prove that (.x: int.c) . S(l): .n . l, suppose \nf n : int . t,we construct the term .x: t. c so that (.x: t. c) .n =l .x:int.c, which implies (.x:int.c) \n.S(l). Therefore, (.x : int.c) . S(H), {.x : int.c}. S(H) and H .{.x: int.c}. By de.nition of H we also \nhave {.x:int.c}.H,so that H =l {.x:int.c}. .n .L, n =n.(.x: int.x), so L .S({.x: int.x}) and {.x: int.x}.L. \nBy de.nition of L,wealso have L .{.x:int.x}, therefore L =l {.x:int.x} . We can further show that all \nthe noninterfering functions are in the interpretation of H. In this particular scenario, con\u00adstant functions \nand noninterfering functions have the same meaning. We can also show that all the policy functions, both \ninterfering and noninterfering, are in the interpreta\u00adtion of L. For a label l between H and L, the policy \nterms precisely de.ne a set of permitted interfering functions. Theorem 4.3.1 (Lattice completeness). \nThe pair (Llocal,.)is a complete lattice.  4.4 Label Downgrading Downgrading happens when data is involved \nin some com\u00adputation. The security level of data changes depending on the computation performed. We describe \nsuch computation as an action and formalize downgrading as a ternary rela\u00ad a tion: l1 . l2. De.nition \n4.4.1 (Multi-composition). Suppose fm1 :int .t, fm2 :t1 .t2 .....tk .int, the multi-composition of m1 \nand m2 is de.ned as: m1 8m2 = .y1 :t1. ....yk :tk.m1(m2 y1 ...yk) De.nition 4.4.2 (Actions). We use the \nmetavariable a to range over actions. An action is a .-term that has the same syntax as a downgrading \npolicy function. That is, the metavariable a and n range over the same set of terms. De.nition 4.4.3 \n(Downgrading relation). We use the a notation l1 . l2 to denote that l1 can be downgraded to l2 a via \nthe action a. Given a well-typed action a, . is a binary relation on Llocal: a l1 . l2 i. .n2 .S(l2),n2 \n8a.S(l1) Example 4.4.1 (Downgrading). Suppose we have an integer u at security level l1,where l1 is de.ned \nas: l1 = {n1},n1 = .x :int..y :int..z :int. (x%y)= z Suppose we have another integer v at security level \nL. What is the security level for (u%v)? We can de.ne an action that describes this computation step: \na = .x :int..y :int.x%y The result has a security level l2: l2 = {n2},n2 = .x :int..z :int.x = z a Labeled \ns ::= tl types t ::= int | (s . s) Programs e ::= (.x :s. e)l | ee | x | c | s | . | e . e | if e then \ne else e | .xl r(x)= e | r Secret inputs s ::= si Public inputs . ::= .i Figure 3: .sec, .. Syntax local \nDe.nition 5.1.1 (Local Downgrading Policies). Let S(si) denote the security label for si. It is easy \nto verify that l1 . l2, because n2 8 a = n1. In this system, we aim for an end-to-end style security \nguarantee. For each secret input si of the program, the Lemma 4.4.1. user speci.es a label S(si) as its \ndowngrading policy. For example, the policy for the password may be: a a 1. If l1 . l2 and l2 l3 then \nl1 . l3. S(spwd)= {(.x :int..y :int.x = y} a a 2. If l1 . l2 and l3 l1 then l3 . l2. which only allows \ndowngrading by comparing the password The above lemma shows very useful properties of down-to a value \nat security level L. The policy for the variable aa grading. It implies that if l1 . l2,then l1 . H, \nbut it is not secret in Example 3.2.1 can be written as: very useful to use H as the result because it \nsimply forbids any further downgrading. We can see that downgrading is not deterministic: given l1 and \na, there are many targets l1 that can be downgraded to via a. The questions are: which label is the most \nuseful result, and how to .nd it? De.nition 4.4.4 (Lowest downgrading). Let . (l, a) be the greatest \nlower bound of all possible labels that l can be downgraded to via a: ' a ' S(ssecret)= {(.x :int..y \n:int. (hash(x)%264)= y} where the hash function is a function provided by the ex\u00adternal library and it \ncan be modeled as an operator in our system.  5.2 The Type System De.nition 5.2.1 (Type stamping). tl1 \nU l2 = t(l1l2). Most common typing rules are in Figure 4 and we call . (l, a)= n{l | l l } them .sec \nrules, because they are standard typing rules in traditional security-typed languages. The downgrading \nrule . Lemma 4.4.2. is in Figure 5. We only listed the DLocal-Left rule, and a . (l, a) . omitted it \nsymmetrical case, the DLocal-Right rule. The 1. l subtyping rules are listed in Figure 6. a l ' then \n. (l, a) l ' For simplicity, we require that all the .xpoint functions 2. If l . have type (intl . intl)l. \nAs a design choice, we do not Theabovelemma shows that . (l, a) is the most accurate allow loop variables \nhave security levels other than L and (lowest) label that l can be downgraded to via a.In fact, H. The \nreason is that a loop variable changes its own values a given l and a,all the labels l ' l ' that satisfy \nl . form a sub-during recursive calls. In our security lattice, the security lattice of Llocal, where \nthe bottom of the lattice is . (l, a) and the top is H. Lemma 4.4.3 (Computing downgrading results). \n. (l, a) =l {n |.n1 . l, .m, n 8 a = m . n1} This lemma shows exactly what is inside . (l, a).  5. \nA TYPE SYSTEM FOR LOCAL DOWNGRADING 5.1 The Language In this section we present a security-typed programming \nlanguage .. that supports downgrading. The language local syntax is presented in Figure 3. Compared to \nthe policy language we presented in the last section, we introduce con\u00additionals and .xpoints. Security \nlabels are used as type annotations. Furthermore, the inputs to the program are explicitly written as \nvariables: s denotes a secret input and . denotes a public input. level of data downgrades during computation \nunless it is L or H. Since all the policy terms are terminating programs, the security level of data \nalways becomes L or H after .nite steps of nontrivial computation. 5.3 The Security Goal If we erase \nthe type annotations, the unlabeled programs in Figure 7 is a superset of our policy language in Figure \n1, so that we can use terms in our policy language to represent fragments of unlabeled programs. De.nition \n5.3.1 (Label erasure). E(e) erases all the la\u00adbel annotations in e andreturns asimply-typed .-term, as \nde.ned in Figure 7. De.nition 5.3.2 (Term sanity). The predicate clean(f) holds if and only if f syntactically \ncontains no secret variable s. De.nition 5.3.3 (Program equivalences). All the rules in Figure 2 are \nalso used for program equivalences by sub\u00adstituting all metavariables m with f. Furthermore, we have \nsome new rules de.ned in Figure 8. G fci : intL G f.i : intL G fsi : intS(si) G(x)= s G fx: s G(r)= s \nG fr : s G,x : s1 fe: s2 x/.dom(G) G f(.x:s1.e)l :(s1 .s2)l G fe1 :(s1 .s3)l G fe2 : s2 s2 =s1 s3 Ul \n=s G fe1 e2 : s l .{L,H} s=intl G,r :(intl .intl)l,x : intl fe: s G f.xl r(x)= e:(intl .intl)l G fe: \nintl G fe1 : s1 G fe2 : s2 s1 =ss2 =s G fif e then e1 else e2 : sUH G fe: intL G fe1 : s1 G fe2 : s2 \ns1 =ss2 =s G fif e then e1 else e2 : s G fe1 : intl1 G fe2 : intl2 G fe1 .e2 : intH G fe1 : intL G fe2 \n: intL G fe1 .e2 : intL Figure 4: .sec Typing Rules: TConst TPublic TSecret TVar TRecVar TFun TApp \nTFix TCond-H TCond-L TOp-H TOp-L G fe: s G fe1 : intl1 G fe2 : intL a a= .x:int..y:int.x.yl1 . l3 DLocal-L(R) \nG fe1 .e2 : intl3 Figure 5: .. Typing Rules: local G fe: s l1 l2 SLab ftl1 =tl2 ft =t SRefl ft1 =t2 ft1 \nft2 ==t3 t3 STrans fs1 =s2 fs3 = s4 SFun fs2 .s3 =s1 .s4 Figure 6: .sec, .. Subtyping Rules: local fs=s \nft=t Unlabeled Programs f ::= .x:t. f |ff |x |c |. |s |f .f |if f then f else f |.x r(x)= f |r E: e.f \nE(tl)= E(t) E(int)= int E(s.s)= E(s) .E(s) E(G)(x)= E(G(x)) E((.x:s. e)l)= .x:E(s). E(e) E(e1 e2)= E(e1) \nE(e2) E(x |c |s |. |r)= x |c |s |. |r E(e1 .e2)= E(e1) .E(e2) E(if e1 then e2 else e3)= if E(e1) then \nE(e2) else E(e3) E(.xl r(x)= e)= .x r(x)= E(e) Figure 7: Label Erasure We formalize the security guarantee \nof our type system using program equivalences. The following is the main the\u00adorem of this paper. Theorem \n5.3.1 (Relaxed noninterference). If fe: intL,then E(e) =f (n1si1 ) ...(nksik ) where clean(f) and .j.nj \n.S(sij ). The proof of this theorem is in Subsection 5.5. This the\u00adorem shows that a type-safe program \ncan only leak secret information in controlled ways, i.e. only through the spec\u00adi.ed downgrading functions. \nTake the password example again, if we know that E(e) =f ((.x:int..y:int.x = y) spwd) and clean(f), then \nthe only way through which f can leak information about spwd is to use its argument, the closure (.y: \nint.spwd = y), which intuitively enforces the security policy speci.ed by the user in an end-to-end fashion. \nNote that this policy still allows the full password be leaked by the following program: f = .g: int \n.int. (.x r(x)= if g(x) then x else r(x+1)) 0 Nevertheless, such an attack takes exponentially long time \nto .nish. We will discuss such programs more in Section 8. We call this security guarantee relaxed noninterference, \nbecause it generalizes traditional noninterference as shown in the following corollary. All the G fm1 \n=m2 : t rules become G ff1 =f2 : t,plus the following rules: G ff1 =f2 : int G ff3 =f4 : t G ff5 =f6 \n: t Q-If G fif f1 then f3 else f5 =if f2 then f4 else f6 : t G,x :int,r :int .int ff1 =f2 : int Q-Fix \nG f.x r(x)= f1 =.x r(x)= f2 : int G fif f1 then f2 else f3 :t1 .t2 G ff4 :t1 Q-EtaIf-App G f(if f1 then \nf2 else f3) f4 =if f1 then f2 f4 else f3 f4 : t2 G fif f1 then f2 else f3 :int G ff4 :int Q-EtaIf-Op-L(R) \nG f(if f1 then f2 else f3) .f4 =if f1 then f2 .f4 else f3 .f4 : int Figure 8: Program Equivalences: \nG ff1 =f2 : t Corollary 5.3.1 (Pure noninterference). If f e : intL and .j.S(sj )= H,then E(e) = f where \nclean(f). Obviously, when no downgrading policy is available, a type-safe program is noninterfering because \nit is equivalent to another program that contains no secret variable at all, which implies that the program \ndoes not leak any informa\u00adtion about the secret variables. It is important to understand the meaning \nof the equiva\u00adlence rules. We treat these rules as the static semantics of the program. Rather than evaluating \nthe program in a call\u00adby-value semantics, we transform the program statically in a call-by-name fashion \nand formalize our security goal. In a call-by-value setting, the Q-Beta and Q-Eta rules a.ect the termination \nbehavior of the program. The Q-EtaIf rules al\u00adlow us to statically reason about di.erent execution paths \nwithout changing the termination behavior of the program. If f1 =f2 and both programs terminate in a \ncall-by-value semantics, they must evaluate to the same value. With such equivalence rules, our relaxed \nnoninterference theorem gives us a notion of weak noninterference,where secrets can be leaked by observing \nthe termination behavior of program. 5.4 Making Typechecking Practical During typechecking, we need \ntractable ways to work with the security labels. The major label operations in the typ\u00ading rules are: \norder testing, computing joins and computing downgrading results. There are two challenges here. First, \nsome label operations involve higher-order uni.cation prob\u00adlems that require searching and such problems \nare undecid\u00adable. Second, labels with in.nite size are hard to deal with. Although higher-order uni.cation \nis generally undecid\u00adable, most such problems in typechecking are either trivial or easily solvable. \nTake the label ordering as an example, we can use the following corollary to test whether l1 l2: Corollary \n5.4.1 (Label order testing). 1. If l1 .l2 then l2 l1. 2. l2 l1 i. .n1 .l1, .n2 .l2, .m, n1 =m .n2 In \ntypechecking, it is often the case that one of l1 and l2 are either H or L,or l1 .l2. It is rarely the \ncase that we need to search for the uni.er m, and if we need to do so, the size of m is usually no larger \nthan n1,because the computation of n1 is being decomposed into two steps, and each piece is likely to \nhave fewer computation than n1 does. If no uni.er is found within the length of n1,the typechecker could \nconservatively report that the label ordering cannot be established, as doing so does not break type \nsoundness. We solve the .nite representation problem by approximat\u00ading intractable labels. Suppose we \ndo not know how to rep\u00adresent l .nitely and for some policies we cannot even decide whether they are \nin S(l). But, if we can compute a .nite label l ' such that we know l ' .S(l), then we have ll ' and \nl ' canbe usedas anapproximationfor l.To make such approximations useful, l ' should be as close to l \nas possible. The following shows how to approximate joins and down\u00adgrading results for .nite labels. \nLemma 5.4.1 (Approximating joins). l1 Ul2 l where l = {.x : int.c}.{n |n .l1 and n . S(l2)}.{n |n .l2 \nand n .S(l1)} In most cases, we have either l1 l2 or l2 l1 and the computation of joins can be short-circuited. \nIn some rare cases, the join of l1 and l2 can be approximated by using the above lemma: for each policy \nn .l1, test whether it is implied by l2 and vice versa. The member test n .S(l2) uses Lemma 4.2.1 and \nuni.cation can be handled as we just did for label ordering. The TApp and the TCond rules do not require \nthe exact join to be computed, so this approximation can always be used. Lemma 5.4.2 (Approximating downgrading \nresults). .(l, a) .{n |.n1 .l, n 8a =n1} This lemma can be used to optimize the searching in Lemma 4.4.3. \nThe intuition is that, a is usually a minimal step of computation in our type system and n1 is usually \na long sequence of computation that can be decomposed into smaller steps. Therefore, we have a practical \nprocedure for .nding the approximation of .(l, a): for each n1 .l,we search for n such that n 8a =n1.Since \ng is usually a policy shorter than n1, most sensible answers can be found by searching for terms no larger \nthan n1. By Lemma 4.4.1, the approximated result can be safely used in typechecking.  5.5 Proof of Theorem \n5.3.1 This proof involves two stages. First, we transform the program into a normal form de.ned in De.nition \n5.5.1. The transformation takes .nite steps and preserves program equiv\u00adalences. Then, we use induction \nto prove the theorem for normalized programs. De.nition 5.5.1 (Normal forms). In Figure 9. v ::= x |c \n|s |. |v.v |if v then v else v |(.xl r(x)= v) v |rv Figure 9: Normal forms The key idea about normal \nforms is that the metavari\u00adable v always ranges over terms of the int type. To trans\u00adform a program into \na normal form, we would like to use \u00df-reductions to get rid of all the .-abstractions. The excep\u00adtion \nis that the left side of an application node may not be a .-abstraction: it can be a .xpoint, a variable \nor a branch. In De.nition 5.5.2, we also de.ned .if -reduction. Lemma 5.5.2, Lemma 5.5.3 and Lemma 5.5.4 \ntell us that these two reduction rules are su.cient to normalize a well-typed pro\u00adgram. De.nition 5.5.2 \n(\u00df,.if reductions). In Figure 10. Lemma 5.5.1 (Equivalence preservation). * ' ' If e. e ,then E(e) =E(e). \nLemma 5.5.2 (Progress under \u00df,.if reductions). If fe: intl, e is stuck under \u00df,.if reduction, then e= \nv as in the normal form de.ned in Figure 9. Lemma 5.5.3 (Preservation under \u00df,.if reductions). ' ''' \nIf fe: s, e.e ,then fe : s where s =s. Lemma 5.5.4 (Normalization under \u00df,.if reductions). If fe: intl,then \n.v such that e. * v. E ::= [] |E e |v E |E .e |v.E |if E then e else e |if v then E else e |if v then \nv else E |.xl r(x)= E .\u00df,.if : e.e E[(.x:s. e1) e2] .\u00df E[e1{e2/x}] E[(if e1 then e2 else e3) e4] .E[if \ne1 then e2 e4 else e3 e4] .if Figure 10: \u00df and .if reduction rules branch(FC,F) ::= (fi .F, fcj .FC) \nfi |if fthen branch(FC,F) else branch(FC,F) cj Figure 11: Short hand notion for nested branches De.nition \n5.5.3 (Branches). In Figure 11. De.nition 5.5.3 a short hand notion for representing nested branching \nstatements. It is easy to show that G fbranch(FC,F) .f =branch(FC,F .f) and vice versa. The proof of \nour main lemma proceeds with induction on the typing derivation of a normalized program. Lemma 5.5.5 \n(Main lemma). Suppose G only contains variables introduced by the TFix rule. That is, G f r : (intl .intl), \nG fx: intl, l .{L,H}for all r and x in G. 1. If G fv : intL, then E(G) fE(v) =f (n1si1 ) ...(nksik ) \nwhere clean(f) and .j.nj .S(sij ). 2. If G fv : intl, l .. = H, l = L,then (a) E(G) fE(v) =branch(FC,F) \nwhere FC = {E(v01),...,E(v0k)}, F = {(a1 sa1 ) E(v11) ...E(v1k1 ), ......... (aj s) E(vj1) ...E(vjkj \n)} aj (b) G fvij : intL, and the typing derivation is smaller than G fv : intl ai (c) S(sai ) . l for \nall i. Proof: By induction on G fv : intl. Case TConst, TPublic : The type must be intL.Sim\u00adply let \nf be v.  Case TSecret : Choose the secret variable itself si, let a1 = .x:int.x.  Case TFun,TRecVar \n: Cannot happen.  Case TVar : By our assumption on G, x must have type intL.Same as the TConst case. \n Case TApp : v is either (.xl r(x)= v1) v2 or rv2. For the .x subcase, we must have l = L,otherwise \nv will have type intH.For the r subcase, we know from our assumption about G that r have type intL .intL. \nBy inversion we know that the type of v2 must be a subtype of intL, which implies that v2 must have type \nintL in the premises of TApp. So we can use IH(1) on v2 and get E(G) fE(v2) =f2.... For the .x subcase, \nwe can extend G with r and x and use our IH(1) to go into v1 and get E(G,r,x) fE(v1) = f1....Use the \nQFix Rule, we have E(G) fE(.xl r(x)= v1) =.x r(x)= f1... Then we can compose f1 and f2 to prove (1). \nThe other subcase rv2 is similar.  Case TFix, TOp-H, TCond-H : Cannot happen.  Case TOp-L : Use IH(1) \nand equivalence rules.  Case TCond-L : First we can use IH(1) on e.Then we assert that both branches \nhave int type.  If s= intL, then we know that both s1 and s2 are intL, so that we can use IH(1) and \nsimple equivalence rules to prove this case. If s. = intL,then we use IH(2) on e1 and e2 respectively, \nthen compose the result. The downgrading condition in (2)(c) is preserved by some property of the down\u00adgrading \nrelation. Case DLocal-Left :If l1 is H then we can show that it is impossible. If l1 = L and l3 = L then \nwe can use IH(1) to prove (1). If l1 = L and l3 .= L then we can create a vacuous secret and put a constant \nfunction to prove (2). Consider the subcase when l1 .L and l1 = H.Use IH(2) to prove (2a),(2b),(2c) ... \nand do a case analysis on the resulting label l3.If l3 . = L then we proved (2), otherwise use IH again \nto prove (1). Case DLocal-Right : Similar. . Finally, we can easily compose Lemma 5.5.4, Lemma 5.5.1 \nand Lemma 5.5.5 to prove Theorem 5.3.1.  6. GLOBAL DOWNGRADING POLICIES 6.1 Motivation In the last \ntwo sections we presented a system with local downgrading, where each secret is assigned a security label \nand secrets can be downgraded by interacting with public inputs and constants. In practice, this framework \nis ca\u00adpable of expressing many useful downgrading policies, but there are some important policies it \ncannot express. For example, we may want to specify the policy data must be encrypted before sending \nit to the network . Naively we can use the policy .x : int. encrypt(x)and treat encrypt as an operator \nin our framework. However, an encryption algorithm usually requires a key as its input, so we may try \nthe policy .x : int..y : int. encrypt(x, y) for the data and .x : int..y : int. encrypt(y, x) for the \nkey. Unfortunately, this does not work because the downgrading rule requires the secrets interact with \nan intL type. Furthermore, these policies allow the attacker to use its own key to downgrade the secret: \nencrypt(x, fakekey). Another interesting example is: we have two secrets s1 and s2 and we want to specify \nthe policy both s1 and s2 are secrets, but their sum is considered as public . Such policies not only \ndescribe the computation required for downgrading, but also speci.es how multiple secrets should be composed \nin order to downgrade. We solve this problem by introducing the idea of global downgrading policies. \nWe identify all the secret inputs of the system, and refer to these secrets in our policy language. In \nthis section we present Lglobal , a lattice of global downgrading policies, and in the next section we \ncorrespondingly extend the type system to support global downgrading. 6.2 Label De.nition The only thing \nwe need to change in the policy language is to allow secret variables to appear in the policy language, \nas shown in Figure 12. For example, s1 may have a down\u00adgrading policy {.x : int.x + s2}, and when we \napply this policy term to s1, the resulting term s1 + s2 is considered public. Similarly, s2 can have \nthe policy {.x : int.s1 + x}. We use Lglobal to denote the set of all well-formed labels. Policy Terms \nm ::= ... | s Figure 12: Lglobal Label Syntax 6.3 Label Interpretation The label interpretation is slightly \ndi.erent from Llocal. The general idea remains the same. If n . l,then m . n is implied by n. However, \nwe must assure that m does not con\u00adtain other secrets, otherwise by applying m . n to the data, we may \nleak arbitrary secrets by deliberately choosing some m. Therefore, we need to make a patch to our de.nition. \nDe.nition 6.3.1 (Label Interpretation). Let S(l) denote the semantic interpretation of the label l: S(l)= \n{n ' | n ' = m . n, n . l, clean(m)} Lemma 4.2.1 requires a similar patch. Others parts re\u00adquire no change \nin Subsection 4.2. 6.4 Label Ordering The de.nition of label ordering in Subsection 4.3 requires no \nchange. Lemma 4.3.1 requires a similar patch as above. The interesting thing is that Lemma 4.3.2, which \nasserts that the identity function is the bottom of the lattice, be\u00adcomes broken. For backward compatibility, \nwe change our de.nition for the rest of the paper: De.nition 6.4.1. H = {.x :int.c}, L = {.x :int.x} \nIt is easy to verify that H =l ULglobal still holds, but nLglobal is no longer structurally equivalent \nto L.The in\u00adtuition is that a constant function is still the most restric\u00adtive policy because it leaks \nno information. The identity function is no longer the least restrictive policy: it can only leak information \nabout the data it annotates. But there are plenty of policies that allow leakage of information besides \nthe annotated data itself. Take this policy as an example: .x : int..y : int.x * (y =0)+ s1 * (y = 1), \nit is capable of leaking the annotated data as well as another secret s1. Intuitively, we can try to \nquantify the information leakage of policies: constant functions leak 0 unit of information, iden\u00adtity \nfunctions leak 1 unit, all policies in Llocal leak between 0 and 1, and some policies in Lglobal leak \nmuch more than 1. It turns out that if we add tuples and projections in our policy language and enrich \nthe equivalence rules, we can easily give a simple .nite representation of nLglobal ,which we call Bottom. \nAssuming the secret variables in the system are s1, ..., sk,then Bottom = nLglobal =l {.x :int. (x, s1, \n..., sk)} Such a function is capable of leaking all possible secrets be\u00adsides the annotated data itself. \nAlthough adding Bottom helps us understand the struc\u00adture of Lglobal , we do not need it in practice. \nThe security level L still has important practical meaning: if x is anno\u00adtated with a label l and we \nhave l L,then x can still be considered as public. It is only di.erent when x has the ability to interact \nwith other secrets and downgrade them. 6.5 Downgrading All the de.nitions in Subsection 4.4 require \nno modi.\u00adcation, except that we need the uni.ers m to be clean in Lemma 4.4.3. The actions now can contain \nsecret variables. For example, we have a {.x :int. (x + s2)%4} . {.x :int.x%4} where a = .y : int.y + \ns2. In fact, the secret variables are handled just like constants.  7. A TYPE SYSTEM FOR GLOBAL DOWNGRADING \n7.1 Integrity Labels In this section, we extend the Llocal language in order to support global downgrading \npolicies. As we add the secret variables in the downgrading policy, there are some new is\u00adsues to solve. \nConsider the simplest case where we are going to typecheck a term a + b. Suppose we already know that \na has a security level {.x : int.x + s2}. We de.ne an action .y :int.y + b and attempt to downgrade a \nvia this action so that the result can have security level L. In order to do that, it is necessary to \nestablish that the term b must be equal to s2. More generally speaking, we need some integrity reason\u00ading \nabout the data, and it is the dual of the con.dentiality analysis we have done. The downgrading policies \nmainly express con.dentiality requirements: where the data can go to and what kind of computation we \nmust do before releas\u00ading it to the public. To enforce such policies, we also need integrity analysis \nof data: where the data comes from and what computation has been done with them. Since integrity and \ncon.dentiality are duals, it is natu\u00adral to use a dual mechanism to reason about integrity. We introduce \nan optional type annotation, called an integrity label in our language. Such labels can be attached to \nthe base type in the form of int(m) as in Figure 13, where m tracks the interesting computations that \nhappened to this term. For example, a term of type int(s1)l must be equiva\u00adlent to s1 itself and this \nis just a singleton type; a term of type int(.x:int.x *s2)l must be equivalent to y *s2 where y is another \nterm of type intL. The integrity labels are essen\u00adtially the dual of our con.dentiality labels. The di.erence \nis that the integrity label is optional and it has exactly one policy term in it. Labeled Types s ::= \ntl t ::= int |int(m)|(s .s) Global Policies S ::= {mi}.{H} Figure 13: .. Syntax global 7.2 Policy Splitting \nIf we directly specify the downgrading policy for each se\u00adcret input just as we did for .. we are likely \nto have local, some inconsistencies among these policies. Take the exam\u00adple of s1 + s2 again. If the \ndowngrading policy for s1 is {.x : int.x + s2} and the policy for s2 is just H,can we downgrade s1 + \ns2 to L? The policy of s1 says yes and the policy of s2 says no. To be safe, we have to compute With \nthese global policies, we can automatically generate the security policy for each individual secret in \nthe following way: De.nition 7.2.1 (Label generation). S(si)= {.x:int.mj[x/si] | mj .S} Take the example \nabove, we have S(s1)= {.x:int.x%2,.x :int. (x + s2)%8} S(s2)= {.y :int..x :int.y = x, .x:int. (s1 + x)%8}Thus \nwhen we typecheck s1 + s2, we can downgrade from either s1 or s2, and the results are consistent: .x:int.x%8. \nThis policy speci.cation method not only simpli.es the user s program annotation work but also make the \nformalization of our security guarantee more concise.  7.3 The Type System The type system is shown \nin Figure 14. Compared to .. ,the DLocal-L(R) rule remains unchanged. Global local downgrading is supported \nby the DGlob-L(R) rule, which exactly shows how the labels are computed for global down\u00adgrading using \ninformation from the integrity label. All other downgrading rules are used to keep track of the integrity \nla\u00adbels. The DTLocal and DTGlob rules are essentially the same as DLocal and DGlob, except that we compute \nthe integrity label for the result. Integrity labels are introduced bythe TSecret rule. The SIntLabel \nrule patches the subtyping relation. Since our typing rules are mostly algorithmic and we do not have \nsubsumption rules, we can make the language more con\u00advenient by changing the TCond and TOp rules to ignore \nintegrity labels in their premises. We omitted them in this paper because they do not a.ect the expressiveness \nof the language. . fint(m)=int SIntLabel G fsi : int(si)S(si) TSecret G fe1 : intl1 G fe2 : intL l1 l3 \na the downgrading result from both sides, and take the up\u00ad per bound of them. Doing so will produce a \nresult of H, which is absolutely safe but inconvenient. If the user actu\u00adally wants such downgrading \nto be successful, he or she has a = .x:int..y :int.x .y G fe1 .e2 : intl3 DLocal-L(R) G fe1 : int(m1)G \nfe2 : intL l1 .l2 a = .x:int..y :int.x .yl1 l3 error-prone when the policies become complicated. G fe1 \n.e2 : int(a 8m1) l3 To guarantee the consistency of such policies, we change the method of policy speci.cation. \nInstead of writing poli-G fe1 : intl1 G fe2 : int(m2)cies for individual secrets, the user simply writes \na set S of a = .x:int.((.y :int.x .y) 8m2) policy terms as shown in Figure 13. Each of these terms a \na to write a symmetric policy for s2. Such work is tedious and DTLocal-L(R) in S denotes a way of downgrading \nsecrets to public. For l1 . l3 example, we can have S = {m1,m2,m3, H}where G fe1 .e2 : intl3 m1 =(s1%2), \nmeaning that s1 can be downgraded to G fe1 :int(m1)l1 G fe2 :int(m2)l2 public by exposing its parity; \na = .x:int. ((.y :int.x .y) 8m2) a DGlob-L(R) l1 . m2 =(.x : int.s2 = x), meaning that s2 can only be \nG fe1 .e2 : int(a 8m1) l3 downgraded by comparing it to some data at security level L. l3 DTGlob-L(R) \nFigure 14: .. Typing Rules global m3 =((s1 + s2)%8), meaning that we can downgrade the last three bits \nof the sum of s1 and s2.  7.4 The Security Goal The security guarantee of .. is similar to .. .The global \nlocal major di.erence is that we changed our way of policy spec\u00adi.cation. In .. , the policies are globally \nspeci.ed by the global user: S is just a set of policy terms. During typechecking, S is split into local \npolicies for each secret variable. Therefore, we would like to express our security goal in terms of \nthe global policy S. Theorem 7.4.1 (Relaxed Noninterference). If f e: intL,then E(e) = fm1 ...mk where \nclean(f) and .j.mj . S. Corollary 7.4.1 (Pure Noninterference). If f e: intL and S= {H} then E(e) = f \nwhere clean(f). These security guarantees are similar to the ones in .. local. They look even more intuitive: \na safe program can only leak secrets in permitted ways, and these permissions are directly characterized \nby the global downgrading policy. The proof of Theorem 7.4.1 is similar to the proof of The\u00adorem 5.3.1. \nThe only major di.erence is the reasoning about integrity labels. Lemma 7.4.1 shows the exact meaning \nof these integrity labels. With the help this lemma, we can go through the cases for additional downgrading \nrules. Lemma 7.4.1 (Integrity guarantee). If G f v : int(m)l,then E(G) fE(v) = branch(FC ,F) where FC \n= {E(v01),...,E(v0i)}, F = {m E(v11) ...E(v1k), ......... m E(vj1) ...E(vjk)}and for each vxy, G f vxy \n: intL for a smaller derivation. Typechecking for .. is not fundamentally harder. Han\u00ad global dling integrity \nlabels is algorithmic and requires no search\u00ading. The only subtle point is that the label ordering is \nchanged in Lglobal, so we must be careful that L is not used as the lowest label in comparing labels \nand computing joins.  8. EVALUATION AND FUTURE WORK Strengths and Limitations We have presented an end-to-end \nstyle framework for down\u00adgrading policies. On one end, it provides a policy speci.ca\u00adtion language expressive \nenough to represent a wide variety of downgrading policies useful in practice. On the other end, it formally \ndescribes a global security goal determined by the user s downgrading policy. To guarantee that a program \nsat\u00adis.es the security goal, i.e. the program is safe with respect to the downgrading policies, we only \nneed a proof showing that the program is equivalent to a speci.c form, by using program equivalence rules. \nWe also presented type systems as enforcement mecha\u00adnisms. The soundness theorem of the type system ensures \nthat, if a program is well-typed, then there exists a proof of the security goal for the program. Thus, \nwe reduced the problem of proof searching to the problem of typechecking, which is a syntax-directed \nprocess. The programmer can explicitly write down the types as security proofs, or we can use type inference \nto search for proofs automatically. It is necessary to point out that a type system is not the only possible \nenforcement mechanism for our framework. Type systems typically have limitations that prevent them from \nenforcing some kinds of downgrading policies. For ex\u00adample, consider the policy .x: int..p : int. (x+ \np) * p:it cannot be enforced by our type system because typecheck\u00ading is not syntax-directed. At each \nstep, all the information is locally synthesized from adjacent nodes. For the program (x+ y) * y where \nx has the policy above, we cannot down\u00adgrade the syntax node (x+ y), therefore (x+ y) cannot have a downgradable \ntype annotation. To reason about such poli\u00adcies, we need more powerful mechanisms that involve more global \ndata-.ow analysis. Nevertheless, many useful policies are not in these forms and are easily enforceable \nby our type system. Understanding the Policies The security guarantee in our framework only assures that \nthe program respects the user s security policies, but it does not verify anything about the policies \nthemselves. It is im\u00adportant to study how to evaluate the e.ects of these down\u00adgrading policies, especially \nwhen the program is not trusted. Both informal and formal reasoning can be used. For exam\u00adple, given \nthe policy {s1%2}, it is apparently true that only the parity of s1 can be leaked to public. Given the \npolicy for the password: {.y: int.spwd = y},wecan usethe same reasoning technique in relative secrecy \n[18] and assure that any program satisfying this policy must take exponentially long expected time to \ncrack the password. Our framework has the ability to minimize the scope of security analysis: in\u00adstead \nof analyzing the whole program, we need to examine only the security policies for these programs, and \nsuch poli\u00adcies are usually several orders of magnitudes smaller than the program. Understanding the Equivalence \nRelation The equivalence rules are crucial in the de.nition of relaxed noninterference. Extending these \nrules can make the frame\u00adwork more expressive. For example, if we have a policy stating that x%4 is safe \nand the equivalence relation can es\u00adtablish that x%2 = (x%4)%2, then x%2 is also safe with respect to \nour policy. However, the equivalence relation must provide a useful notion of security guarantee. Take \nthe password example again: if we use the usual de.nition of observational equivalence to de.ne relaxed \nnoninterfer\u00adence, it would make the following two terms equivalent: spwd = (.x r(x)= if (spwd=x) then \nx else r(x+1)) 0 The consequence would be that any single occurence of the variable spwd can be considered \nas a public value of type intL because it satis.es the de.nition of relaxed noninter\u00adference. This is \napparently not a good security guarantee. Therefore, it is interesting to explore what equivalance rela\u00adtions \nare good for our purposes and how to formalize such criteria. Practical Application Our framework can \nbe practically adapted into existing security-typed languages such as Jif. In our policy language, some \nrun-time library calls and API interfaces can be mod\u00adeled as operators and constants, such as encryption, \npri\u00admality testing and hash functions. The program annotation work mainly involves marking secret and \npublic variables; the downgrading policies can be globally speci.ed outside the program. In ideal cases, \nmost type annotations can be automatically inferred during typechecking and the pro\u00adgrammers do not need \nto write the downgrading policies for each piece of data in the program. To achieve this goal, more work \nneeds to be done on type inference algorithms in our framework. Integrating with DLM The decentralized \nlabel model (DLM) expresses policies like who can downgrade the data and it is orthogonal to our work. \nSince our security policies are also formalized as a lat\u00adtice of security levels, it is tempting to integrate \nour frame\u00adwork with the decentralized label model so that we can ex\u00adpress policies like who can downgrade \nthe data in which ways and achieve a better integration of access control and information .ow. There \nhas been work on combining secu\u00adrity policies with owner information [2] in the style of DLM. This is \na promising research direction we are planning to pursue in the future. Proof Carrying Code and Information \nFlow Our framework also facilitates the use of proof-carrying code for information-.ow security. The \ndowngrading policies can be speci.ed as interfaces for untrusted software modules. The untrusted code \nmust come with a proof showing that it respects our interfaces in our framework, such a proof even needs \nnot to be a typing derivation; it is su.cient to give a proof using program equivalence rules because \nour security goal is expressed in this way. The trusted comput\u00ading base is very small: we need not trust \nthe soundness of any type system; the correctness of our equivalence rules is almost indubitable; the \nproof checker is easy to implement correctly. Even without downgrading, our framework can still be very \nvaluable in this aspect. Since we are not re\u00adstricted to the use of type systems, the programmer could \nuse more expensive proof searching techniques so that more expressive downgrading policies can be enforced. \n 9. CONCLUSION In this paper, we studied the challenges of downgrading in language-based information-.ow \nsecurity and presented a generalized framework of downgrading policies. Such poli\u00adcies are treated as \nsecurity levels for information .ow con\u00adtrol, speci.ed in a simple, expressive, tractable and exten\u00adsible \npolicy language, and enforced by a type system. The security guarantee is then formalized as a concise \nand exten\u00adsional property called relaxed noninterference using program equivalences, which generalizes \ntraditional noninterference properties and accurately describes the e.ects of downgrad\u00ading. Alternative \nenforcement mechanisms can also be used. Our framework now enables untrusted code to safely declas\u00adsify \nsecrets and we can guarantee that information is only leaked in permitted ways.  Acknowledgements We \nwould like to thank Stephen Chong, Stephen Tse, Ge\u00ado.rey Washburn and the POPL reviewers for their valuable \nfeedbacks and extensive proofreading of the original draft. References [1] Anindya Banerjee and David \nA. Naumann. Secure information .ow and pointer con.nement in a java-like language. In Proc. of the 15th \nIEEE Computer Security Foundations Workshop, 2002. [2] Hubie Chen and Stephen Chong. Owned policies \nfor information security. In Proc. of the IEEE Computer Security Foundations Workshop, 2004. [3] R. \nGiacobazzi and I. Mastroeni. Abstract non-interference: Parameterizingnon-interference by abstract interpretation. \nIn Proc. 31st ACM Symp. on Principles of Programming Languages (POPL), pages 186 197, January 2004. [4] \nJ. A. Goguen and J. Meseguer. Security policies and security models. In Proc. IEEE Symposium on Security \nand Privacy, pages 11 20. IEEE Computer Society Press, April 1982. [5] James W. Gray, III. Towards a \nmathematical foundation for information .ow security. In Proc. IEEE Symposium on Security and Privacy, \npages 21 34. IEEE Computer Society Press, 1991. [6] Gavin Lowe. Quantifyinginformation .ow. In Proc.ofthe \nIEEE Computer Security Foundations Workshop,pages 18 31. IEEE Computer Society Press, 2002. [7] Heiko \nMantel and David Sands. Controlled declassi.cation based on intransitive noninterference. In Proceedings \nof The Second Asian Symposium on Programming Languages and Systems, volume 3302 of LNCS. Springer, 2004. \n[8] John McLean. Security models and information .ow. In Proc. IEEE Symposium on Security and Privacy,pages \n180 187. IEEE Computer Society Press, 1990. [9] Andrew C. Myers. JFlow: Practical mostly-static information \n.ow control. In Proc. 26th ACM Symp. on Principles of Programming Languages (POPL),pages 228 241, San \nAntonio, TX, January 1999. [10] Andrew C. Myers and Barbara Liskov. Protectingprivacy usingthe decentralized \nlabel model. ACM Transactions on Software Engineering and Methodology, 9(4):410 442, 2000. [11] Andrew \nC Myers, Andrei Sabelfeld, and Steve Zdancewic. Enforcingrobust declassi.cation. In Proc. of the 17th \nIEEE Computer Security Foundations Workshop, pages 172 186. IEEE Computer Society Press, June 2004. [12] \nAlessandra Di Pierro, Chris Hankin, and Herbert Wiklicky. Approximate non-interference. In Proc. of the \nIEEE Computer Security Foundations Workshop, pages 1 17. IEEE Computer Society Press, 2002. [13] Fran\u00b8cois \nPottier and Sylvain Conchon. Information .ow inference for free. In Proc. 5th ACM SIGPLAN International \nConference on Functional Programming (ICFP), pages 46 57, September 2000. [14] Fran\u00b8cois Pottier and \nVincent Simonet. Information .ow inference for ML. In Proc. 29th ACM Symp. on Principles of Programming \nLanguages (POPL), Portland, Oregon, January 2002. [15] A. W. Roscoe and M. H. Goldsmith. What is intransitive \nnoninterference? In Proc. of the 12th IEEE Computer Security Foundations Workshop, 1999. [16] Andrei \nSabelfeld and Andrew Myers. A model for delimited information release. In Proceedings of the International \nSymposium on Software Security (ISSS 03), 2004. [17] Andrei Sabelfeld and Andrew C. Myers. Language-based \ninformation-.ow security. IEEE Journal on Selected Areas in Communications, 21(1):5 19, January 2003. \n[18] Dennis Volpano and Geo.rey Smith. Verifyingsecrets and relative secrecy. In Proc. 27th ACM Symp. \non Principles of Programming Languages (POPL), pages 268 276. ACM Press, January 2000. [19] Dennis Volpano, \nGeo.rey Smith, and Cynthia Irvine. A sound type system for secure .ow analysis. Journal of Computer Security, \n4(3):167 187, 1996. [20] Steve Zdancewic and Andrew C. Myers. Robust declassi.cation. In Proc. of 14th \nIEEE Computer Security Foundations Workshop, Cape Breton, Canada, June 2001. IEEE Computer Society Press. \n \n\t\t\t", "proc_id": "1040305", "abstract": "In traditional information-flow type systems, the security policy is often formalized as noninterference properties. However, noninterference alone is too strong to express security properties useful in practice. If we allow downgrading in such systems, it is challenging to formalize the security policy as an extensional property of the system.This paper presents a generalized framework of downgrading policies. Such policies can be specified in a simple and tractable language and can be statically enforced by mechanisms such as type systems. The security guarantee is then formalized as a concise extensional property using program equivalences. This <i>relaxed noninterference</i> generalizes traditional pure noninterference and precisely characterizes the information released due to downgrading.", "authors": [{"name": "Peng Li", "author_profile_id": "81100475426", "affiliation": "University of Pennsylvania", "person_id": "PP45026117", "email_address": "", "orcid_id": ""}, {"name": "Steve Zdancewic", "author_profile_id": "81384616728", "affiliation": "University of Pennsylvania", "person_id": "PP14144604", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1040305.1040319", "year": "2005", "article_id": "1040319", "conference": "POPL", "title": "Downgrading policies and relaxed noninterference", "url": "http://dl.acm.org/citation.cfm?id=1040319"}