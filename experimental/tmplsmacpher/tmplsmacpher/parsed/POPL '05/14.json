{"article_publication_date": "01-12-2005", "fulltext": "\n A Probabilistic Language based upon Sampling Functions Sungwoo Park Frank Pfenning Computer Science \nDepartment Carnegie Mellon University {gla,fp}@cs.cmu.com ABSTRACT As probabilistic computations play \nan increasing role in solv\u00ading various problems, researchers have designed probabilis\u00adtic languages that \ntreat probability distributions as primi\u00adtive datatypes. Most probabilistic languages, however, focus \nonly on discrete distributions and have limited expressive power. In this paper, we present a probabilistic \nlanguage, called .O, which uniformly supports all kinds of probability distributions discrete distributions, \ncontinuous distribu\u00adtions, and even those belonging to neither group. Its math\u00adematical basis is sampling \nfunctions, i.e., mappings from the unit interval (0.0, 1.0] to probability domains. We also brie.y describe \nthe implementation of .. as an extension of Objective CAML and demonstrate its practi\u00adcality with three \napplications in robotics: robot localization, people tracking, and robotic mapping. All experiments have \nbeen carried out with real robots. Categories and Subject Descriptors D.3.2 [Language Classi.cations]: \nSpecialized application languages General Terms Languages, Experimentation Keywords Probabilistic language, \nProbability distribution, Sampling function, Robotics 1. INTRODUCTION As probabilistic computations play \nan increasing role in solving various problems, researchers have designed proba\u00adbilistic languages to \nfacilitate their modeling [11, 7, 30, 23, 26, 15, 21]. A probabilistic language treats probability dis\u00adtributions \nas primitive datatypes and abstracts from their representation schemes. As a result, it enables programmers \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n05, January 12 14, 2005, Long Beach, California, USA. Copyright 2005 ACM 1-58113-830-X/05/0001 ...$5.00. \nSebastian Thrun Computer Science Department Stanford University thrun@stanford.edu to concentrate on \nhow to formulate probabilistic computa\u00adtions at the level of probability distributions rather than representation \nschemes. The translation of such a formu\u00adlation in a probabilistic language usually produces concise \nand elegant code. A typical probabilistic language supports at least discrete distributions, for which \nthere exists a representation scheme su.cient for all practical purposes: a set of pairs consist\u00ading \nof a value in the probability domain and its probabil\u00adity. We can use such a probabilistic language for \nproblems involving only discrete distributions. For those involving non-discrete distributions, however, \nwe usually use a conven\u00adtional language for the sake of e.ciency, assuming a speci.c kind of probability \ndistributions (e.g., Gaussian distribu\u00adtions) or choosing a speci.c representation scheme (e.g.,a set \nof weighted samples). For this reason, there has been lit\u00adtle e.ort to develop probabilistic languages \nwhose expressive power is beyond discrete distributions. Our work aims to develop a probabilistic language \nsup\u00adporting all kinds of probability distributions discrete dis\u00adtributions, continuous distributions, \nand even those belong\u00ading to neither group. Furthermore we want to draw no distinction between di.erent \nkinds of probability distribu\u00adtions, both syntactically and semantically, so that we can achieve a uniform \nframework for probabilistic computation. Such a probabilistic language can have a signi.cant practi\u00adcal \nimpact, since once formulated at the level of probability distributions, any probabilistic computation \ncan be directly translated into code. The main idea in our work is that we can specify any probability \ndistribution by answering How can we generate samples from it? , or equivalently, by providing a sampling \nfunction for it. A sampling function is de.ned as a map\u00adping from the unit interval (0.0, 1.0] to a probability \ndomain D. Given a random number drawn from a uniform distri\u00adbution over (0.0, 1.0], it returns a sample \nin D, and thus speci.es a unique probability distribution. For our purpose, we use a generalized notion \nof sampling function which maps (0.0, 1.0]8 to D\u00d7(0.0, 1.0]8 where (0.0, 1.0]8 denotes an in\u00ad.nite product \nof (0.0, 1.0]. Operationally it takes as input an in.nite sequence of random numbers drawn independently \nfrom a uniform distribution over (0.0, 1.0], consumes zero or more random numbers, and returns a sample \nwith the remaining sequence. We present a probabilistic language, called .O,whose mathematical basis \nis sampling functions. We exploit the fact that sampling functions form a state monad, and base the syntax \nof .. upon the monadic metalanguage [17] in the formulation of Pfenning and Davies [24]. A syntactic \ndis\u00adtinction is drawn between regular values and probabilistic computations through the use of two syntactic \ncategories: terms for regular values and expressions for probabilistic computations. It enables us to \ntreat probability distribu\u00adtions as .rst-class values, and .O arises as a conservative extension of a \nconventional language. Examples show that .O provides a uni.ed representation scheme for probabil\u00adity \ndistributions, enjoys rich expressiveness, and allows high versatility in encoding probability distributions. \nAn important aspect of our work is to demonstrate the practicality of .O by applying it to real problems. \nAs the main testbed, we choose robotics [29]. It o.ers a variety of real problems that necessitate probabilistic \ncomputations over continuous distributions. We implement .O as an ex\u00adtension of Objective CAML and use \nit for three applications in robotics: robot localization [29], people tracking [20], and robotic mapping \n[31]. We use real robots for all experiments. .O does not support precise reasoning about probability \ndistributions in that it does not permit a precise implemen\u00adtation of queries on probability distributions \n(such as expec\u00adtation). This is in fact a feature of probability distributions that precise reasoning \nis impossible in general. In other words, lack of support for precise reasoning is the price we pay for \nrich expressiveness of .O. As a practical solution, we use the Monte Carlo method to support approximate \nreasoning. As such, .O is a good choice for those problems in which all kinds of probability distributions \nare used or precise reasoning is unnecessary or impossible. This paper is organized as follows. Section \n2 gives a mo\u00adtivating example for .O. Section 3 presents the type system and the operational semantics \nof .O. Section 4 shows how to encode various probability distributions in .O, and Section 5 shows how \nto formally prove the correctness of encodings, based upon the operational semantics. Section 6 demon\u00adstrates \nthe use of the Monte Carlo method for approximate reasoning and brie.y describes our implementation of \n.O. Section 7 presents three applications of .O in robotics. Sec\u00adtion 8 discusses related work and Section \n9 concludes. We refer readers to [22] for .gures from experiments in Section 7. Notation If a variable \nx ranges over the domain of a probability dis\u00adtribution P,then P(x) means, depending on the context, \neither the probability distribution itself (as in probability distribution P(x) ) or the probability \nof a particular value x (as in probability P(x) ). If we do not need a speci.c name for a probability \ndistribution, we use Prob. Similarly P(x|y) means either the conditional probability P itself or the \nprob\u00adability of x conditioned on y.We write Py or P(\u00b7|y)for the probability distribution conditioned \non y. U(0.0, 1.0]de\u00adnotes a uniform distribution over the unit interval (0.0, 1.0]. 2. A MOTIVATING \nEXAMPLE A Bayes .lter [9] is a popular solution to a wide range of state estimation problems. It estimates \nthe state s of a system from a sequence of actions and measurements, where an action a makes a change \nto the state and a measurement m gives information on the state. At its core, a Bayes .l\u00adter computes \na probability distribution Bel(s)of the state according to the following update equations: Bel(s) .A(s|a,s')Bel(s')ds' \n(1) Bel(s) . .P(m|s)Bel(s) (2) A(s|a,s') is the probability that the system transitions to state s after \ntaking action a in another state s', P(m|s)the probability of measurement m in state s,and . a normalizing \n constant ensuringBel(s)ds =1.0. The update equations are formulated at the level of probability distributions \nin the sense that they do not assume a particular representation scheme. Unfortunately the update equations \nare di.cult to imple\u00adment for arbitrary probability distributions. When it comes to implementation, therefore, \nwe usually simplify the update equations by making additional assumptions on the system or choosing a \nspeci.c representation scheme. For instance, with the assumption that Bel is a Gaussian distribution, \nwe obtain a variant of the Bayes .lter called a Kalman .l\u00adter [32]. If we approximate Bel with a set \nof samples, we obtain another variant called a particle .lter [3]. Even these variants of the Bayes .lter \nare, however, not trivial to implement in conventional languages, not to men\u00adtion the di.culty of understanding \nthe code. For instance, a Kalman .lter requires various matrix operations includ\u00ading matrix inversion. \nA particle .lter needs to manipulate weights associated with individual samples, which often re\u00adsults \nin complicated code. An alternative approach is to use an existing probabilis\u00adtic language after discretizing \nall probability distributions. This idea is appealing in theory but impractical for two rea\u00adsons. First, \ngiven a probability distribution, we cannot eas\u00adily choose an appropriate subset of its support upon \nwhich we perform discretization. Even when such a subset is .xed in advance, the process of discretization \nmay require a con\u00adsiderable amount of programming; see [4] for an example. Second there are some probability \ndistributions that cannot be discretized in any meaningful way. An example is proba\u00adbility distributions \nover probability distributions, which do occur in real applications (see Section 7). Another example \nis probability distributions over function spaces. If we had a probabilistic language that supports all \nkinds of probability distributions without drawing a syntactic or semantic distinction, we could implement \nthe update equa\u00adtions with much less e.ort. We present such a probabilistic language .O in the next section. \n3. PROBABILISTIC LANGUAGE .O In this section, we develop our probabilistic language .O. We begin by explaining \nwhy we choose sampling functions as the mathematical basis of .O. 3.1 Mathematical basis The expressive \npower of a probabilistic language is de\u00adtermined to a large extent by its mathematical basis, i.e., which \nmathematical objects are used to specify probability distributions. Since we intend to support all kinds \nof proba\u00adbility distributions without drawing a syntactic or semantic distinction, we cannot choose what \nis applicable only to a speci.c kind of probability distributions (e.g., probability mass functions, \nprobability density functions, or cumulative distribution functions). Probability measures are a possibil\u00adity \nbecause they are synonymous with probability distribu\u00adtions. They are, however, not a practical choice: \na proba\u00adbility measure on a domain D maps not D but the set of events on D to [0.0, 1.0], and may be \ndi.cult to represent if D is an in.nite domain. Sampling functions overcome the problem with probabil\u00adity \nmeasures: they are applicable to all kinds of probability distributions, and are also easy to represent \nbecause a global random number generator supplants the use of in.nite se\u00adquences of random numbers. For \nthis reason, we choose sampling functions as the mathematical basis of .O. 1 It is noteworthy that sampling \nfunctions form a state monad [16, 17] whose set of states is (0.0, 1.0]8.Moreover sampling functions \nare operationally equivalent to proba\u00adbilistic computations because they describe procedures for generating \nsamples. These two observations imply that if we use a monadic syntax for probabilistic computations, \nit becomes straightforward to interpret probabilistic com\u00adputations in terms of sampling functions. Hence \nwe use a monadic syntax for probabilistic computations in .O. 3.2 Syntax and type system As the linguistic \nframework of .O, we use the monadic metalanguage of Pfenning and Davies [24]. It is a reformu\u00adlation \nof Moggi s monadic metalanguage .ml [17], following Martin-L\u00a8of s methodology of distinguishing judgments \nfrom propositions [14]. It augments the lambda calculus, consist\u00ading of terms, with a separate syntactic \ncategory, consisting of expressions in a monadic syntax. In the case of .O,terms denote regular values \nand expressions denote probabilistic computations. We say that a term evaluates to a value and an expression \ncomputes to a sample. The abstract syntax for .O is as follows: type A, B ::= A .A | A \u00d7A | oA | real \nterm M, N ::= x | .x: A. M | MM | (M, M) | fst M | snd M | .x x: A. M | prob E | r expression E, F ::= \nM | sample x from M in E |S value/sample V, W ::= .x: A. M | (V, V ) | prob E | r real number r sampling \nsequence s ::= r1r2 \u00b7\u00b7\u00b7ri \u00b7\u00b7\u00b7 where ri .(0.0, 1.0] typing context G ::= \u00b7| G,x : A We use x as variables. \n.x : A. M is a lambda abstraction, and MM is an application term. (M, M) is a product term, and fst M \nand snd M are projection terms; we include these terms in order to support joint distributions. .x x \n: A. M is a .xed point construct for recursive terms. A probability term prob E encapsulates an expression \nE; it is a .rst-class value denoting a probability distribution. Real numbers r are implemented as .oating \npoint numbers, since the over\u00adhead of exact real arithmetic is not justi.ed in the domain where we work \nwith samples and approximations anyway. There are three kinds of expressions: terms M, bindex\u00adpressions \nsample x from M in E,and sampling expressions S. As an expression, M denotes a probabilistic computation \nthat returns the result of evaluating M. sample x from M in E sequences two probabilistic computations \n(if M evaluates to a probability term). S consumes a random number from a sampling sequence, which is \nan in.nite sequence of random numbers drawn independently from U(0.0, 1.0]. The type system employs a \nterm typing judgment G fM : A and an expression typing judgment G f E \u00f7A (Figure 1). G f M : A means \nthat M evaluates to a value of type A under typing context G, and G f E \u00f7A that E computes to 1Note, \nhowever, that not every sampling function speci.es a probability distribution. For instance, no probability \ndistri\u00adbution is speci.ed by a sampling function mapping rational numbers to 0and irrational numbers \nto 1. Thus we restrict ourselves to those sampling functions that determine prob\u00adability distributions \n(i.e., measurable sampling functions). x : A .GG,x : A f M : B Var Lam G f x : A G f .x: A. M : A .B \nG f M1 : A .B G f M2 : A App G f M1 M2 : B G f M1 : A1 G f M2 : A2 G f M : A1 \u00d7A2 Prod Fst G f (M1,M2): \nA1 \u00d7A2 G f fst M : A1 G f M : A1 \u00d7A2 G,x : A f M : A Snd Fix G f snd M : A2 G f .x x: A.M : A G f E \u00f7A \nProb Real G f prob E : oA G f r : real G f M : A G f M : oA G,x : A f E \u00f7B Term Bind G f M \u00f7A G f sample \nx from M in E \u00f7B Sampling G fS\u00f7real Figure 1: Typing rules of .O asample of type A under typing context \nG. The rule Prob is the introduction rule for the type constructor o;it shows that type oA denotes probability \ndistributions over type A. The rule Bind is the elimination rule for the type construc\u00adtor o.The rule \nTerm means that every term converts into a probabilistic computation that involves no probabilistic choice. \nAll the remaining rules are standard. 3.3 Operational semantics Since .O draws a syntactic distinction \nbetween regular values and probabilistic computations, its operational se\u00admantics needs two judgments: \none for term evaluations and another for expression computations. A term evaluation is always deterministic \nand the corresponding judgment in\u00advolves only terms. In contrast, an expression computation may consume \nrandom numbers and the corresponding judg\u00adment involves not only expressions but also sampling se\u00adquences. \nSince an expression computation may invoke term evaluations (e.g.,toevaluate M in sample x from M in \nE), we .rst present the judgment for term evaluations and then use it for the judgment for expression \ncomputations. Both judgments use capture-avoiding substitutions [N/x]M and [N/x]E de.ned in a standard \nway. For term evaluations, we introduce a judgment M .N in a call-by-value discipline. We could have \nequally chosen call\u00adby-name or call-by-need, but .O is intended to be embedded in Objective CAML and \nhence we choose call-by-value for pragmatic reasons. We use evaluation contexts which are terms with \na hole [] indicating where a term reduction may occur. We use M. R N for term reductions: evaluation \ncontext . ::= [] | .M | (.x: A.M) . |(., M) | (V, .) | fst . | snd . (.x: A. M) V [V/x]M .R M .R N fst \n(V1,V2) V1 .R .[M] ..[N]snd (V1,V2) V2 .R .x x: A. M [.x x: A. M/x]M .R We use M * V for a term evaluation \nwhere * denotes .. the re.exive and transitive closure of . .A term evaluation is always deterministic. \nFor expression computations, we introduce a judgment E @ s . F @ s ' which means that the computation \nof E with sampling sequence s reduces to the computation of F with sampling sequence s ' .It uses computation \ncontexts which are expressions with either a term hole []term or an expression hole []exp.[]term expects \na term and []exp expects an expression. We use E @ s .R F @ s ' for expression reductions: computation \ncontext . ::= []exp |[]term |sample x from []term in E |sample x from prob . in E sample x from prob \nV in E @ s .R [V/x]E @ s S@ rs .R r @ s M .NE @ s .R F @ s ' .[M]@ s ..[N]@ s.[E]@ s ..[F ]@ s ' term \nterm exp exp We use E @ s . * V @ s ' for an expression computation where . * denotes the re.exive and \ntransitive closure of .. Note that an expression computation itself is deterministic; it is only when \nwe vary sampling sequences that an expres\u00adsion exhibits probabilistic behavior. An expression computation \nE @ s . * V @ s ' means that E takes a sampling sequence s, consumes a .nite pre.x of s in order, and \nreturns a sample V with the remaining sequence s ' : Proposition 3.1. If E @ s . * V @ s ' ,then s = \nr1r2 \u00b7\u00b7\u00b7rns ' (n =0)where * '** '* ' E @ s . E1 @ r2 \u00b7\u00b7\u00b7rns . \u00b7\u00b7\u00b7. En-1 @ rns . V @ s for a sequence \nof expressions E1, \u00b7\u00b7\u00b7,En-1. Thus an expression computation coincides with the opera\u00adtional description \nof a sampling function when applied to a sampling sequence, which implies that an expression repre\u00adsents \na sampling function. The type safety of .O consists of two properties: type preservation and progress. \nThe proof of type preservation requires a substitution lemma, and the proof of progress requires a canonical \nforms lemma. Theorem 3.2 (Type preservation). If M .N and \u00b7fM : A,then \u00b7fN : A. If E @ s .F @ s ' and \n\u00b7fE \u00f7A,then \u00b7fF \u00f7A. Theorem 3.3 (Progress). If \u00b7fM : A, then either M is a value ( i.e., M = V ), or \nthere exists N such that M .N. If \u00b7fE \u00f7A, then either E is a sample ( i.e., E = V ), or for any sampling \nsequence s,there exist F and s ' such that E @ s .F @ s ' . The syntactic distinction between terms and \nexpressions in .O is optional in the sense that the grammar does not need to distinguish expressions \nas a separate non-terminal. On the other hand, the semantic distinction, both statically (in the form \nof two typing judgments) and dynamically (in the form of evaluation and computation judgments) appears \nto be essential for a clean formulation of our probabilistic language. .O is a conservative extension \nof a conventional language because terms constitute a conventional language of their own. In essence, \nterm evaluations are always determinis\u00adtic and we need only terms when writing deterministic pro\u00adgrams. \nAs a separate syntactic category, expressions also provide a framework for probabilistic computation \nthat ab\u00adstracts from the de.nition of terms. For instance, the ad\u00addition of a new term construct does \nnot change the de.\u00adnition of expression computations. When programming in .O, therefore, the syntactic \ndistinction between terms and expressions aids us in deciding which of deterministic eval\u00aduations and \nprobabilistic computations we should focus on. In the next section, we show how to encode various proba\u00adbility \ndistributions and further investigate properties of .O.  4. EXAMPLES When encoding a probability distribution \nin .O,we natu\u00adrally concentrate on a method of generating samples, rather than trying to calculate the \nprobability assigned to each event. If the probability distribution itself is de.ned in terms of a process \nof generating samples, we simply translate the de.nition. If, however, the probability distribution is \nde\u00ad.ned in terms of a probability measure or an equivalent, we may not always derive a sampling function \nin a mechanical manner. Instead we have to exploit its unique properties to devise a sampling function. \nBelow we show examples of encoding various probabil\u00adity distributions in .O. These examples demonstrate \nthree properties of .O: a uni.ed representation scheme for proba\u00adbility distributions, rich expressiveness, \nand high versatility in encoding probability distributions. The sampling meth\u00adods used in the examples \nare all found in simulation the\u00adory [2]. We assume primitive types int and bool, arithmetic and comparison \noperators, and a conditional term construct if M then N1 else N2. We also assume standard let-binding, \nrecursive let rec-binding, and pattern matching when it is convenient for the examples. While we do not \ndiscuss here type inference or polymorphism, the implementation han\u00addles these in the manner familiar \nfrom ML. We use the following syntactic sugar for expressions: unprob M = sample x from M in x eif M \nthen E1 else E2 = unprob (if M then prob E1 else prob E2) unprob M chooses a sample from the probability \ndistribution denoted by M and returns it. eif M then E1 else E2 branches to either E1 or E2 depending \non the result of evaluating M.  Uni.ed representation scheme .O provides a uni.ed representation scheme \nfor probability distributions. While its type system distinguishes between di.erent probability domains, \nits operational semantics does not distinguish between di.erent kinds of probability distri\u00adbutions, \nsuch as discrete, continuous, or neither. We show an example for each case. We encode a Bernoulli distribution \nover type bool with parameter p as follows: let bernoulli = .p: real. prob sample x from prob Sin x =p \nbernoulli can be thought of as a binary choice construct. It is expressive enough to specify any discrete \ndistribution with .nite support. In fact, bernoulli 0.5su.ces tospec\u00adify all such probability distributions, \nsince it is capable of simulating a binary choice construct [5]. As an example of continuous distribution, \nwe encode a uniform distribution over a real interval (a, b] by exploiting the de.nition of the sampling \nexpression: let uniform = .a: real..b: real. prob sample x from prob Sin a + x *(b -a) We also encode \na combination of a point-mass distribution and a uniform distribution over the same domain, which is \nneither a discrete distribution nor a continuous distribution: let point uniform = prob sample x from \nprob S in if x< 0.5 then 0.0 else x Rich expressiveness We now demonstrate the expressive power of .O \nwith a num\u00adber of examples. We encode a binomial distribution with parameters p and n0 by exploiting \nprobability terms: let binomial = .p : real..n0 : int. let bernoulli p = bernoulli p in let rec binomialp \n= .n: int. if n =0 then prob 0 else prob sample x from binomialp (n - 1) in sample b from bernoulli \np in if b then 1+ x else x in binomialp n0 Here binomialp takes an integer n as input and returns a binomial \ndistribution with parameters p and n. If a probability distribution is de.ned in terms of a re\u00adcursive \nprocess of generating samples, we can translate the de.nition into a recursive term. For instance, we \nencode a geometric distribution with parameter p as follows: let geometric rec = .p : real. let bernoullip \n= bernoulli p in let rec geometric = prob sample b from bernoullip in eif b then 0 else sample x from \ngeometric in 1+ x in geometric Note that a geometric distribution has in.nite support. We encode an exponential \ndistribution by using the in\u00adverse of its cumulative distribution function as a sampling function, which \nis known as the inverse transform method: let exponential 1.0 = prob sample x from S in -log x The rejection \nmethod, which generates a sample from a probability distribution by repeatedly generating samples from \nother probability distributions until they satisfy a cer\u00adtain condition, can be implemented with a recursive \nterm. For instance, we encode a Gaussian distribution with mean m and variance s2 by the rejection method \nwith respect to exponential distributions: let bernoulli 0.5 = bernoulli 0.5 let gaussian rejection = \n.m : real..s : real. let rec gaussian = prob sample y1 from exponential 1.0 in sample y2 from exponential \n1.0 in eif y2 = (y1 - 1.0)2/2.0 then sample b from bernoulli 0.5 in if b then m + s * y1 else m - s * \ny1 else unprob gaussian in gaussian We encode the joint distribution between two indepen\u00addent probability \ndistributions using a product term. If MP denotes P (x)and MQ denotes Q(y), the following term de\u00adnotes \nthe joint distribution Prob(x, y) . P (x)Q(y): prob sample x from MP in sample y from MQ in (x, y) For \nthe joint distribution between two interdependent prob\u00adability distributions, we use a conditional probability, \nwhich we represent as a lambda abstraction taking a regular value and returning a probability distribution. \nIf MP denotes P (x)and MQ denotes a conditional probability Q(y|x), the following term denotes the joint \ndistribution Prob(x, y) . P (x)Q(y|x): prob sample x from MP in sample y from MQ x in (x, y) We compute \nthe integration Prob(y)= Q(y|x)P (x)dx in a similar way: prob sample x from MP in sample y from MQ|P \nx in y Due to lack of semantic constraints on sampling functions, we can specify probability distributions \nover unusual do\u00admains such as in.nite data structures (e.g., trees), function spaces, cyclic spaces (e.g., \nangular values), and even prob\u00adability distributions themselves. For instance, we add two probability \ndistributions over angular values in a straight\u00adforward way: let add angle = .a1 : oreal..a2 : oreal. \nprob sample s1 from a1 in sample s2 from a2 in (s1 + s2) mod (2.0 * p) With the modulo operation mod, \nwe take into account the fact that an angle . is identi.ed with . +2p. As a simple application, we implement \na belief network [27]:  We assume that Palarm|burglary denotes the probability dis\u00adtribution that the \nalarm goes o. when a burglary happens; other variables of the form P\u00b7|\u00b7 are interpreted in a similar \nway. let alarm = .(burglary, earthquake ): bool \u00d7 bool. if burglary then Palarm|burglary else if earthquake \nthen Palarm|\u00acburglary.earthquake else Palarm|\u00acburglary.\u00acearthquake let john calls = .alarm : bool. if \nalarm then PJohn calls|alarm else PJohn calls|\u00acalarm let mary calls = .alarm : bool. if alarm then PMary \ncalls|alarm else PMary calls|\u00acalarm The conditional probabilities alarm, john calls,and mary calls do \nnot answer any query on the belief network; they only describe its structure. In order to answer a speci.c \nquery, we have to implement a corresponding probability distribution. For instance, in order to answer \nwhat is the probability pMary calls|John calls that Mary calls when John calls? , we use QMary calls|John \ncalls below, which essentially implements logic sampling [8]:     let rec QMary calls|John calls \n= prob sample b from Pburglary in sample e from Pearthquake in sample a from alarm (b,e) in sample j \nfrom john calls a in sample m from mary calls a in eif j then m else unprob QMary calls|John calls in \nQburglary|John calls Pburglary denotes the probability distribution that a bur\u00adglary happens, and Pearthquake \ndenotes the probability dis\u00adtribution that an earthquake happens. Then the mean of QMary calls|John calls \ngives pMary calls|John calls . We will see how to calculate pMary calls|John calls in Section 6. We can \nalso implement most of the common operations on probability distributions. An exception is the Bayes \nopera\u00adtion . (the second update equation of the Bayes .lter uses it). P.Q results in a probability distribution \nR such that R(x)= .P(x)Q(x)where . is a normalization constant en\u00adsuring R(x)dx=1.0;if P(x)Q(x) is zero \nfor every x,then P.Q is unde.ned. Since it is di.cult to achieve a general implementation of P.Q, we \nusually make an additional assumption on P and Q to achieve a specialized implemen\u00adtation. For instance, \nif we have a function p and a constant c such that p(x)= kP(x) = c for a certain constant k,we can implement \nP.Q by the rejection method: let bayes rejection = .p: A.real..c: real..Q: oA. let rec bayes = prob sample \nx from Q in sample u from prob S in eif u< (px)/c then x else unprob bayes in bayes We will see another \nimplementation in Section 6.  High versatility .O allows high versatility in encoding probability distribu\u00adtions: \ngiven a probability distribution, we can exploit its unique properties and encode it in many di.erent \nways. For instance, exponential 1.0 uses a logarithm function to encode an exponential distribution, \nbut there is also an ingenious method (due to von Neumann) that requires only addition andsubtractionoperations: \nlet exponential von Neumann1.0 = let rec search = .k: real..u: real..u1 : real. prob sample u ' from \nprob S in eif u<u ' then k+ u1 else sample u from prob S in eif u =u ' then unprob (search kuu1) else \nsample u from prob S in unprob (search (k+1.0) uu) in prob sample u from prob S in unprob (search 0.0 \nuu) The recursive term in gaussian rejection consumes at least three random numbers. We can encode a \nGaussian distri\u00adbution with only two random numbers: let gaussian Box Muller = .m: real..s: real. prob \nsample u from prob S in sample v from prob S in v m+ s*-2.0 *log u*cos (2.0 *p*v) We can also approximate \na Gaussian distribution by exploit\u00ading the central limit theorem: let gaussian central = .m: real..s: \nreal. prob sample x1 from prob S in sample x2 from prob S in \u00b7\u00b7\u00b7 sample x12 from prob S in m+ s*(x1 + \nx2 + \u00b7\u00b7\u00b7+ x12 -6.0) The three examples above serve as evidence of high ver\u00adsatility of .O: the more we \nknow about a probability distri\u00adbution, the better we can encode it. All the examples in this section \njust rely on our intuition on sampling functions and do not actually prove the cor\u00adrectness of encodings. \nFor instance, we still do not know if bernoulli indeed encodes a Bernoulli distribution, or equiva\u00adlently, \nif the expression in it generates True with probability p. In the next section, we investigate how to \nformally prove the correctness of encodings. 5. PROVING THE CORRECTNESS OF EN-CODINGS When programming \nin .O,weoften ask What probabil\u00adity distribution characterizes outcomes of computing a given expression? \nThe operational semantics of .O does not di\u00adrectly answer this question because an expression compu\u00adtation \nreturns only a single sample from a certain, yet un\u00adknown, probability distribution. Therefore we need \na dif\u00adferent methodology for interpreting expressions directly in terms of probability distributions. \nWe take a simple approach that appeals to our intuition on the meaning of expressions. We write E ~ Prob \nif out\u00adcomes of computing E are distributed according to Prob. To determine Prob from E, we supply an \nin.nite sequence of independent random variables from U(0.0,1.0] and an\u00adalyze the result of computing \nE in terms of these random variables. If E ~Prob,then E denotes a probabilistic com\u00adputation of generating \nsamples from Prob and we regard Prob as the denotation of prob E. We illustrate the above approach with \na few examples. In each example, Ri means the i-th random variable and Ri 8 means the in.nite sequence \nof random variables beginning from Ri (i.e., RiRi+1 \u00b7\u00b7\u00b7). A random variable is regarded as a value because \nit represents real numbers in (0.0,1.0]. As a trivial example, consider prob S. The computation of S \nproceeds as follows: S @ R8 1 .R1 @ R2 8 Since the outcome is a random variable from U(0.0,1.0], we have \nS~U(0.0,1.0]. As an example of discrete distribution, consider bernoulli p. The expression in it computes \nas follows: sample x from prob S in x=p @ R1 8 . sample x from prob R1 in x=p @ R2 8 . R1 =p @ R2 8 \n . True @ R2 8 if R1 =p; False @ R2 8 otherwise.  Since R1 is a random variable from U(0.0,1.0], the \nprobabil\u00adity of R1 =pis p. Thus the outcome is True with probability p and False with probability 1.0 \n-p,and bernoulli p denotes a Bernoulli distribution with parameter p. As an example of continuous distribution, \nconsider uniform ab. The expression in it computes as follows: sample x from prob S in a+ x*(b-a)@ R1 \n8 . * a+ R1 *(b-a) @ R8 2 Since we have a+ R1 *(b-a) .(a0,b0] i. R1 .( a0 -a b-a , b0 -a b-a ], the \nprobability that the outcome lies in (a0,b0]is b0 -aa0 -ab0 -a0 - = .b0 -a0 b-ab-ab-a whereweassume (a0,b0] \n.(a,b]. Thus uniform ab denotes a uniform distribution over (a,b]. The following proposition shows that \nbinomial pn de\u00adnotes a binomial distribution with parameters pand n,which we write as Binomialp,n: Proposition \n5.1. If binomialp n . * prob Ep,n,then Ep,n ~Binomialp,n. Proof. By induction on n. Base case n =0. Wehave \nEp,n =0. Since Binomialp,n is a point-mass distribution centered on 0, we have Ep,n ~ Binomialp,n. Inductive \ncase n> 0. The computation of Ep,n proceeds as follows: sample x from binomialp (n-1) in sample b from \nbernoullip in if b then 1+ x else x @ R1 8 . * sample x from prob xp,n-1 in sample b from bernoullip \nin if b then 1+ x else x @ Ri 8 . * sample b from prob bp in if b then 1+ xp,n-1 else xp,n-1 @ R8 i+1 \n. * 1+ xp,n-1 @ R8 if bp = True; i+1 xp,n-1 i+1 otherwise. @ R8 By induction hypothesis, binomialp (n-1) \ngenerates a sam\u00adple xp,n-1 from Binomialp,n-1 after consuming R1 \u00b7\u00b7\u00b7Ri-1 for some i (which is actually \nn). Since Ri is an independent random variable, bernoullip generates a sample bp that is independent \nof xp,n-1. Then we obtain an outcome k with the probability of bp = True and xp,n-1 = k-1or bp = False \nand xp,n-1 = k, which is equal to p*Binomialp,n-1(k-1) + (1.0 -p) *Binomialp,n-1(k) = Binomialp,n(k). \nThus we have Ep,n ~Binomialp,n. As a .nal example, we show that geometric rec p de\u00adnotes a geometric \ndistribution with parameter p. Suppose geometric . * prob E and E ~ Prob. The computation of E proceedsasfollows: \nE @ R1 8 . * sample b from prob bp in eif b then 0 else sample x from geometric in @ R2 8 1+ x . * 0@ \nR2 8 if bp = True; sample x from prob E in 1+ x @ R2 8 otherwise. The .rst case happens with probability \npand we get Prob(0) = p. In the second case, we compute the same expression E with sampling sequence \nR2 8 . Since all random variables are independent, R2 8 can be thought of as a fresh sequence of random \nvariables. Therefore the computation of E with sampling sequence R2 8 returns samples from the same prob\u00adability \ndistribution Prob and we get Prob(1 + k)= (1.0 - p) *Prob(k). Solving the two equations, we get Prob(k)= \np*(1.0 -p)k-1, which is the probability mass function for a geometric distribution with parameter p. \nThe above approach can be thought of as an adaption of the method established in simulation theory [2]. \nAn alter\u00adnative approach would be to develop a denotational seman\u00adtics. For instance, if we ignore .xed \npoint constructs, it is straightforward to translate expressions into probability measures because probability \nmeasures form a monad [6, 26] and expressions already follow a monadic syntax.2 In prac\u00adtice, however, \nthe translation does not immediately reveal the probability measure corresponding to a given expression \nand we have to go through essentially the same analysis as in the above approach. Ultimately we have \nto invert a sam\u00adpling function represented by a given expression (because an event is assigned a probability \nproportional to the size of its inverse image under the sampling function), but this is di.cult to do \nin a mechanical way in the presence of various operators. Therefore it seems to be reasonable to analyze \neach expression individually as demonstrated in this section. 6. APPROXIMATE COMPUTATION IN .O We have \nexplored both how to encode probability distri\u00adbutions in .O and how to interpret .O in terms of proba\u00adbility \ndistributions. In this section, we discuss another im\u00adportant aspect of probabilistic languages: reasoning \nabout probability distributions. The expressive power of a probabilistic language is an im\u00adportant factor \na.ecting its practicality. Another important factor is its support for reasoning about probability distri\u00adbutions \nto determine their properties. In other words, it is important not only to be able to encode various \nprobability distributions but also to be able to determine their prop\u00aderties such as means, variances, \nand probabilities of speci.c events. Unfortunately .O does not support precise reasoning about probability \ndistributions. That is, it does not permit a precise implementation of queries on probability distribu\u00adtions. \nIntuitively we must be able to calculate probabilities of speci.c events, but this is essentially inverting \nsampling functions. Given that we cannot hope for precise reasoning in .O, we choose to support approximate \nreasoning by the Monte Carlo method [13]. It approximately answers a query on a probability distribution \nby generating a large number of samples and then analyzing them. For instance, in the belief network \nexample in Section 4, we can approximate pMary calls|John calls by generating a large number of samples \nand counting the number of True s. Although the Monte Carlo method gives only an approximate answer, \nits accu\u00adracy improves with the number of samples. Moreover it can be applied to all kinds of probability \ndistributions and is therefore particularly suitable for .O. 2In the presence of .xed point constructs, \nexpressions should be translated into a domain-theoretic structure because of recursive equations. While \nthe work by Jones [10] suggests that such a structure could be constructed from a domain\u00adtheoretic model \nof real numbers, we have not investigated in this direction.  In this section, we apply the Monte Carlo \nmethod to an implementation of the expectation query. We also show how to exploit the Monte Carlo method \nin implementing the Bayes operation. Then we brie.y describe our implemen\u00adtation of .O. 6.1 Expectation \nquery Among common queries on probability distributions, the most important is the expectation query. \nThe expectation of a function f with respect to a probability distribution P is the mean of f over P,which \nwe writeas fdP.Other queries may be derived as special cases of the expectation query. For instance, \nthe mean of a probability distribution over real numbers is the expectation of an identity function. \nThe Monte Carlo method states that we can approximate fdP with a set of samples V1,\u00b7\u00b7\u00b7 ,Vn from P: f(V1)+ \n\u00b7\u00b7\u00b7+ f(Vn) lim = fdP n.8 n We introduce a term construct expectation which exploits the above equation: \nterm M ::= \u00b7\u00b7\u00b7 | expectation Mf MP G f Mf : A.real G f MP : oA ExpG f expectation Mf MP : real Mf . * \nfMP . * prob EP *' * EP @ si . Vi @ si fVi . vi 1 =i =n . ExpR expectation Mf i vi MP .R n The rule ExpR \nsays that if Mf evaluatestoalambdaab\u00adstraction denoting f and MP evaluates to a probability term denoting \nP,then expectation Mf MP reduces to an approxi\u00admation of fdP. A runtime variable nspeci.es the number \nof samples to be generated from P.The runtime system initializes sampling sequence si to generate sample \nVi. A problem with the above de.nition is that although expectation is a term construct, its reduction \nis probabilis\u00adtic because of sampling sequence si in the rule ExpR.This violates the principle that a \nterm evaluation is always de\u00adterministic, and now the same term may evaluate to di.er\u00adentvalues if itcontains \nexpectation. In practice, however, this is acceptable because .O is intended to be embedded in Objective \nCAML in which side-e.ects are already allowed for terms. Besides, mathematically the expectation of a \nfunction with respect to a probability distribution is always unique (if it exists).3 Now we can calculate \npMary calls|John calls as expectation (.x: bool.if x then 1.0 else 0.0) QMary calls|John calls . 6.2 \nBayes operation The previous implementation of the Bayes operation P.Q assumes that we have a function \np and a constant c such that p(x)= kP(x) = c for a certain constant k.It is, how\u00adever, often di.cult \nto .nd the optimal value of c (i.e.,the maximum value of p(x)) and we have to take a conserva\u00adtive estimate \nof c. The Monte Carlo method, in conjunction with importance sampling [13], allows us to dispense with \nc by approximating Q with a set of samples and P.Q with a set of weighted samples. We introduce a term \nconstruct 3We de.ne expectation as a term construct only for prag\u00admatic reasons. For instance, examples \nin Section 7 become much more complicated if expectation is de.ned as an ex\u00adpression construct. bayes \nfor the Bayes operation and an expression construct importance for importance sampling: term M ::= \u00b7\u00b7\u00b7 \n| bayes Mp MQ expression E ::= \u00b7\u00b7\u00b7 | importance {(Vi,wi)|1 =i =n} In the spirit of data abstraction, \nimportance represents only an internal data structure and is not directly available to the programmer. \n G f Mp : A.real G f MQ : oA Bayes G f bayes Mp MQ : oA G f Vi : A G f wi : real 1 =i =n G f importance \n{(Vi,wi)|1 =i=n}\u00f7A Imp Mp . * pMQ . * prob EQ *' * EQ @ si . Vi @ si pVi . wi 1 =i =n BayesR bayes Mp \nMQ .R prob importance {(Vi,wi)|1 =i =n} . k-1 . k i=1 i=1 wi wi . n <r = where S = wi SS i=1 importance \n{(Vi,wi)|1 =i =n}@ rs.R Vk @ s ImpR The rule BayesR approximates Qwith n samples V1,\u00b7\u00b7\u00b7 ,Vn, where n \nis a runtime variable as in the rule ExpR.Then it applies p to each sample Vi to calculates its weight \nwi and creates a set {(Vi,wi)|1 = i = n} of weighted samples as an argument to importance.The rule ImpR \nimplements importance sampling: we use a random number r to prob\u00adabilistically select a sample Vk by \ntaking into account the weights associated with all the samples. As with expectation, we decide to de.ne \nbayes as a term construct despite the fact that its reduction is probabilis\u00adtic. The decision also conforms \nto our intuition that math\u00adematically the result of the Bayes operation between two probability distributions \nis always unique. 6.3 Implementation of . O We have implemented .O by extending the syntax of Ob\u00adjective \nCAML. The runtime system uses a global random number generator for all sampling sequences. Hence it gen\u00aderates \nfresh random numbers whenever it needs to compute sampling expressions, without explicitly initializing \nsampling sequences. The runtime system also allows the program\u00admer to change the runtime variable n in \nthe rules ExpR and BayesR, both of which invoke expression computations dur\u00ading term evaluations. Thus \nthe programmer can control the accuracy in approximating probability distributions.  7. APPLICATIONS \nIn this section, we present three applications of .O in robotics: robot localization, people tracking, \nand robotic mapping. The goal is to estimate the state of a robot from sensor readings, where the de.nition \nof state di.ers in each case. In order to cope with uncertainty in sensor readings (due to limitations \nof sensors and noises from the environ\u00adment), we estimate the state with a probability distribution. \nWe use a Bayes .lter as a framework for updating the prob\u00adability distribution. There are two kinds of \nsensor readings: action and mea\u00adsurement. As in a Bayes .lter, an action induces a state change whereas \na measurement gives information on the state. An action is represented as an odometry reading which returns \nthe pose (i.e., position and orientation) of the robot relative to its initial pose. A measurement includes \nrange readings which return distances to objects at certain angles. We .rst consider robot localization, \nsince it directly im\u00adplements update equations (1) and (2) in Section 2. 7.1 Robot localization Robot \nlocalization [29] is the problem of estimating the pose of a robot when a map of the environment is available. \nIf the initial pose is given, the problem becomes pose track\u00ading which keeps track of the robot pose \nby compensating errors in sensor readings. If the initial pose is not given, the problem becomes global \nlocalization which begins with mul\u00adtiple hypotheses on the robot pose (and is therefore more di.cult \nthan pose tracking). We consider robot localization under the assumption that the environment is static. \nThis assumption allows us to use a Bayes .lter over the robot pose. Speci.cally the state in the Bayes \n.lter is the robot pose s =(x, y, .), and we estimate s with a probability distribution Bel(s) over three\u00addimensional \nreal space. We compute Bel(s) according to update equations (1) and (2) with the following interpreta\u00adtion: \n A(s|a, s ' ) is the probability that the robot moves to pose s after taking action a in another pose \ns ' . Ais called an action model.  P(m|s) is the probability that measurement m is taken at pose s. \nPis called a perception model.  Givenanaction a and a pose s ' , we can generate a new pose s from A(\u00b7|a, \ns ' ) by adding a noise to a and applying it to s ' . Given a measurement m and a pose s, we can also \ncompute .P(m|s)where . is an unknown constant: the map determines a unique measurement ms for the pose \ns,and the di.erence between m and ms is proportional to P(m|s). Then, if MA denotes conditional probability \nAand MP m returns a function f(s)= .P(m|s), we can implement up\u00addate equations (1) and (2) as follows: \n. let Belnew = prob sample s ' from Bel in . sample s from MA (a, s ' ) in (1) . s let Belnew = bayes \n(MP m) Bel }(2) Now we can implement pose tracking or global localiza\u00adtion by specifying an initial probability \ndistribution of robot pose. In the case of pose tracking, it is usually a point-mass distribution or \na Gaussian distribution; in the case of global localization, it is usually a uniform distribution over \nthe open space in the map. 7.2 People tracking People tracking [20] is an extension of robot localization \nin that it estimates not only the robot pose but also the positions of people (or unmapped objects). \nAs in robot lo\u00adcalization, the robot can take an action to change its pose. Unlike in robot localization, \nhowever, the robot must catego\u00adrize sensor readings in a measurement by deciding whether they are caused \nby objects in the map or by people. Those sensor readings that correspond with objects in the map are \nused to update the robot pose; the rest of sensor readings are used to update the positions of people. \nA simple approach is to maintain a probability distribu\u00adtion Bel(s, u ) of robot pose s and positions \nuu of people. While it works well for pose tracking, this approach is not a general solution for global \nlocalization. The reason is that sensor readings from people are correctly interpreted only with a correct \nhypothesis on the robot pose, but during global localization, there may be multiple incorrect hypothe\u00adses \nthat lead to incorrect interpretation of those sensor read\u00adings. This means that during global localization, \nthere exists a dependence between the robot pose and the positions of people, which is not captured by \nBel(s, uu). Hence we maintain a probability distribution Bel(s, Ps(u )) of robot pose s and probability \ndistribution Ps(u ) of positions u of people conditioned on robot pose s. Ps(uu)captures the dependence \nbetween the robot pose and the positions of peo\u00adple. Bel(s, Ps(u )) can be thought of as a probability \ndistri\u00adbution over probability distributions. As in robot localization, we update Bel(s, Ps(u )) with \na Bayes .lter. The di.erence from robot localization is that the state is a pair of s and Ps(uu) and \nthat the action model takes as input both an action a and a measurement m.We use update equations (3) \nand (4) in Figure 2 (which are obtained by replacing s by s, Ps(u )and a by a, m in update equations \n(1) and (2)). The action model A(s, Ps(u )|a, m, s ' ,PsI (uu')) requires us ' to generate s, Ps(uu)from \ns ,PsI (uu' ) utilizing action a and measurement m. We generate .rst s and next Ps(u ) accord\u00ading to \nequation (5) in Figure 2. We write the .rst Prob in ' equation (5) as Arobot (s|a,m,s ,PsI (uu')). The \nsecond Prob in equation (5) indicates that we have to generate Ps(uu) ' from PsI (uu) utilizing action \na and measurement m,which is exactly a situation where we can use another Bayes .l\u00adter. For this inner \nBayes .lter, we use update equations (6) and (7) in Figure 2. We write Prob in equation (6) as Apeople(u \n|a, uu' ,s,s ' ); we simplify Prob in equation (7) into Prob(m|uu, s)because m does not depend on s ' \ngiven s,and write it as Ppeople(m|uu, s). Figure 3 shows the implementation of people tracking in .O. \ndenote conditional probabili- MArobot and MApeople ties Arobot and Apeople, respectively. ms returns \na MPpeople function f(uu)= .Ppeople(m|uu, s) for a constant ..In im\u00adplementing update equation (4), we \nexploit the fact that P(m|s, Ps(uu)) is the expectation of a function g(uu)= Ppeople(m|uu, s)with respect \nto Ps(uu): P(m|s, Ps(uu)) = Ppeople(m|uu, s)Ps(uu)duu We can further simplify the models used in the \nupdate equations. For instance, we can use Arobot (s|a, s ' )instead of Arobot (s|a, m, s ' ,PsI (uu')) \nas in robot localization. In our ' implementation, we use Apeople(uu|uu) on the assumption that the positions \nof people are not a.ected by the robot pose.  7.3 Robotic mapping Robotic mapping [31] is the problem \nof building a map (or a spatial model) of the environment from sensor read\u00adings. Since measurements are \na sequence of inaccurate local snapshots of the environment, a robot must simultaneously localize itself \nas it explores the environment so that it can correct and align the local snapshots to construct a global \nmap. For this reason, robotic mapping is also referred to as simultaneous localization and mapping (or \nSLAM). It is one of the most di.cult problems in robotics, and is under active research. We assume that \nthe environment consists of an unknown number of stationary landmarks. Then the goal is to esti\u00admate \nthe positions of landmarks as well as the robot pose. ' '' Bel(s, Ps(u )) .A(s, Ps(u )|a,m,s ,PsI (uu' \n))Bel(s ,PsI (uu' ))d(s ,PsI (uu' )) (3) Bel(s, Ps(u )) . .P(m|s, Ps(u ))Bel(s, Ps(u )) (4) ' '' A(s, \nPs(u )|a,m,s ,PsI (uu')) = Prob(s|a,m,s ,PsI (uu')) Prob(Ps(u )|a,m,s ,PsI (uu'),s) (5) = Arobot (s|a, \nm, s ' ,PsI (uu' )) Prob(Ps(u )|a, m, s ' ,PsI (uu' ),s) Ps(u ) . Prob(u |a, uu' ,s,s ' )PsI (uu' )duu' \n= Apeople (u |a, uu' ,s,s ' )PsI (uu' )duu' (6) . '' Ps(u ) . Prob(m|uu, s, s )Ps(u )= . ' Ppeople(m|uu, \ns)Ps(u ) (7) Figure 2: Equations used in people tracking. (3) and (4) for the Bayes .lter computing Bel(s, \nPs(u )).(5) for decomposing the action model. (6) and (7) for the inner Bayes .lter computing Ps(u ). \n. let Belnew = prob sample (s ' ,PsI (uu' )) from Bel in . .. . . sample s from MArobot (a, m, s ' \n,PsI (uu' )) in .. .. . .. u' .. let Ps(u )= prob sample u from PsI (uu' ) in .. .. . . ' .. sample \nu from MApeople (a, uu' ,s,s ) in (6) . (3) . (5) . u . .. .. .. in . . .. .. ms) Ps(u ) in } (7) \n.. let Ps(u )= bayes (MPpeople .. .. (s, Ps(u )) let Belnew = bayes .(s, Ps(u )): . (expectation (MPpeople \nms) Ps(u )) Bel } (4) Figure 3: Implementation of people tracking in .O. equations in Figure 2. The key \nobservation is that we can think of landmarks as people who never move in an empty environment. It means \nthat the problem is a special case of people tracking and we can use all the equations in Figure 2. Below \nwe use subscript landmark instead of people for the sake of clarity. As in people tracking, we maintain \na probability distribu\u00adtion Bel(s, Ps(u )) of robot pose s and probability distribu\u00adtion Ps(u ) of positions \nu of landmarks conditioned on robot pose s. Since landmarks are stationary and Alandmark(u |a, uu' ,s,s \n' ) is non-zero if and only if u = uu' ,we can skip update equation (6) in implementing update equa\u00ad \ntion (3). Arobot in equation (5) can use Plandmark(m|uu' ,s)to test the likelihood of each new robot \npose s with respect to old positions u ' of landmarks, as in FastSLAM 2.0[19]: u Arobot (s|a, m, s ' \n,PsI (uu')) (8) = Prob(s|a, m, s ' ,u ' )PsI (uu' )duu' Prob(s|a, uu')Prob(m, s ' |s, a, uu') = PsI (uu')duu' \nProb(m, s '|a, uu') ' = . '' Prob(m, s ' |s, a, uu' )PsI (uu' )duu . '' Prob(s|a, uu') where = Prob(m, \ns '|a, uu') = . '' Prob(s ' |s, a, uu' ,m)Prob(m|s, a, uu' )PsI (uu' )duu' = . '' Prob(s ' |s, a)Prob(m|s, \nuu')PsI (uu')duu' . '' ' = Arobot (s|a, s ) Plandmark(m|uu' ,s)PsI (uu')duu' Given a and s ' , we implement \nthe above equation with a Bayes operation on Arobot (\u00b7|a, s ' ). Figure 4 shows the implementation of \nrobotic mapping in .O. are interpreted in the same way MArobot and MPlandmark as in people tracking. \nSince landmarks are stationary, we no longer need MAlandmark . Numbers on the right-hand side show corresponding \n 7.4 Experimental results We have implemented the above three systems in .O.To test the robot localizer \nand the people tracker, we use a mo\u00adbile robot Nomad XR4000 in Wean Hall at Carnegie Mellon University. \nWe use CARMEN [18] for controlling the robot and collecting sensor readings. To test the mapper, we use \nthe a data set collected with an outdoor vehicle in Victo\u00adria Park, Sydney [1]. All the systems run on \nPentium III 500Mhz with 384 MBytes memory. We test the robot localizer for global localization with 8 \nruns in Wean Hall (each run takes a di.erent path). For an initial probability distribution of robot \npose, we use a uniform distribution over the open space in the map. In a test experiment, it succeeds \nto localize the robot on 5 runs and fails on 3 runs. As a comparison, the CARMEN robot localizer, which \nuses particle .lters, succeeds on 3 runs and fails on 5 runs. The people tracker uses the implementation \nin Figure 3 during global localization, but once it succeeds to localize the robot and starts pose tracking, \nit maintains an indepen\u00addent probability distribution for each person in sight (be\u00adcause there is no \nlonger a dependence between the robot pose and the positions of people). We test the mapper with a data \nset in which the vehicle moves approximately 323.42 meters (according to the odom\u00adetry readings) in 128.8 \nseconds. Since the vehicle is driving over uneven terrain, raw odometry readings are noisy and do not \nre.ect the true path of the vehicle, in particular when the vehicle follows a loop. The mapper successfully \ncloses the loop, building a map of the landmarks around the path. The experiment takes 145.89 seconds. \nOur .nding is that the bene.t of implementing probabilis\u00adtic computations in .O, such as readability \nand conciseness of code, outweighs its disadvantage in speed. As a com\u00adparison (although not particularly \nmeaningful), our robot . let Belnew = prob sample (s ' ,PsI (uu ')) from Bel in ' . . . . . . sample \ns from bayes .s: . (expectation (MPlandmark let Ps(u )= bayes (MPlandmark ms) Ps(u ) in (s,Ps(u )) ms) \nPsI (uu ')) (MArobot (a,s )) in } (8) } (7) . . (5) . . . . . (3) let Belnew = bayes .(s,Ps(u )): . \n(expectation (MPlandmark ms) Ps(u )) Bel } (4) Figure 4: Implementation of robotic mapping in .O. Compared \nwith the implementation in Figure 3, it omits equation (6) and uses equation (8). localizer is 1349 lines \nlong (868 lines of Objective CAML code and 481 lines of C code), and the CARMEN robot lo\u00adcalizer, written \nin C, is 3397 lines long. The speed loss is also not signi.cant. For instance, while the CARMEN robot \nlocalizer processes 100.0sensor readings, our robot localizer processes on average 54.6 sensor readings \n(and nevertheless shows comparable accuracy).  8. RELATED WORK There are a number of probabilistic \nlanguages that focus on discrete distributions. Such a language usually provides a probabilistic construct \nthat is equivalent to a binary choice construct. Saheb-Djahromi [28] presents a probabilistic lan\u00adguage \nwith a binary choice construct (p1 . e1,p2 . e2) where p1 + p2 =1.0. Koller, McAllester, and Pfe.er [11] \npresent a .rst order functional language with a coin toss construct .ip(p). Pfe.er [23] generalizes the \ncoin toss con\u00adstruct to a multiple choice construct dist [p1 : e1, \u00b7\u00b7\u00b7 ,pn : en] where i pi =1.0. Gupta, \nJagadeesan, and Panangaden [7] present a stochastic concurrent constraint language with a probabilistic \nchoice construct choose x from Dom in e where Dom is a .nite set of real numbers. All these constructs, \nal\u00adthough in di.erent forms, are equivalent to a binary choice construct and have the same expressive \npower. An easy way to compute a binary choice construct (or an equivalent) is to generate a sample from \nthe probability distribution it denotes, as in the above probabilistic lan\u00adguages. Another way is to \nreturn an accurate representa\u00adtion of the probability distribution itself, by enumerating all elements \nin its support along with their probabilities. Pless and Luger [25] present an extended lambda calculus \nwhich uses a probabilistic construct of the form i ei : pi where pi =1.0. An expression denoting a probability \ni . distribution computes to a normal form i vi : pi,which is an accurate representation of the probability \ndistribution. Jones [10] presents a metalanguage with a binary choice con\u00adstruct e1 orp e2. Its operational \nsemantics uses a judgment e . pivi. Mogensen [15] presents a language for speci\u00adfying die-rolls. Its \ndenotation semantics (called probability semantics) is formulated in a similar style, directly in terms \nof probability measures. Jones and Mogensen also provide an equivalent of a .xed point construct which \nenables programmers to specify dis\u00adcrete distributions with in.nite support (e.g.,geometric dis\u00adtribution). \nSuch a probability distribution is, however, dif\u00ad.cult to represent accurately because of an in.nite \nnumber of elements in its support. For this reason, Jones assumes pi =1.0in the judgment e . pivi and \nMogensen uses partial probability distributions in which the sum of proba\u00adbilities may be less than 1.0. \nThe intuition is that we allow only a .nite recursion depth so that we can omit some ele\u00adments in the \nenumeration. There are a few probabilistic languages supporting con\u00adtinuous distributions. Kozen [12] \ninvestigates the seman\u00adtics of probabilistic while programs. A random assignment x := random assigns \na random number to variable x.Since it does not assume a speci.c probability distribution for the random \nnumber generator, the language serves only as a framework for probabilistic languages. The third author \n[30] extends C++ with probabilistic data types which are cre\u00adated from a template prob <type>. Although \nthe language supports common continuous distributions, its semantics is not formally de.ned. The .rst \nauthor [21] presents a proba\u00adbilistic calculus whose mathematical basis is sampling func\u00adtions. In order \nto encode sampling functions directly, the calculus uses a sampling construct ..e where . is a formal \nargument and e denotes the body of a sampling function. As in .O, the computation of ..e proceeds by \ngenerating a random number from U(0.0, 1.0] and substituting it for . in e. The idea of using a monadic \nsyntax in .O was inspired by Ramsey and Pfe.er [26]. They present a stochastic lambda calculus (with \na binary choice construct choose pe1 e2) whose denotational semantics is based upon the monad of probability \nmeasures, or the probability monad [6]. In im\u00adplementing a query for generating samples from probabil\u00adity \ndistributions, they note that the probability monad can also be interpreted in terms of sampling functions, \nboth de\u00adnotationally and operationally. In designing .O,we take the opposite approach: .rst we use a \nmonadic syntax for probabilistic computations and relate it directly to sampling functions; then we interpret \nit in terms of probability distri\u00adbutions. 9. CONCLUSION AND FUTURE WORK We have presented a probabilistic \nlanguage .O whose math\u00adematical basis is sampling functions. .O supports all kinds of probability distributions \nwithout drawing a syntactic or semantic distinction. We have demonstrated the practical\u00adity of .O with \nthree applications in robotics. To the best of our knowledge, .O is the only probabilistic language with \na formal semantics that has been applied to real problems involving continuous distributions. There are \na few other probabilistic languages that are capable of simulating con\u00adtinuous distributions (by combining \nan in.nite number of discrete distributions), but they require a special treatment such as the lazy evaluation \nstrategy in [11, 23] and the lim\u00aditing process in [7]. .O does not support precise reasoning about probability \ndistributions. Note, however, that this is not an inherent weakness of .O due to its use of sampling \nfunctions as the mathematical basis; rather this is a necessary feature of .O because precise reasoning \nabout probability distributions is impossible in general. In other words, if .O supported pre\u00adcise reasoning, \nit could support only a small number of prob\u00adability distributions and operations on them. The utility \nof a probabilistic language depends on each problem to which it is applied. .O is a good choice for those \nproblems in which all kinds of probability distribu\u00adtions are used or precise reasoning is unnecessary. \nRobotics is a good example, since all kinds of probability distribu\u00adtions are used (even those probability \ndistributions similar to point uniform in Section 4 are used in modeling laser range .nders) and also \nprecise reasoning is unnecessary (sen\u00adsor readings are inaccurate at any rate). On the other hand, .O \nmay not be the best choice for those problems involv\u00ading only discrete distributions, since its rich \nexpressiveness is not fully exploited and approximate reasoning may be too weak for discrete distributions. \nWe are investigating how to generate a large number of samples quickly, which is important for improving \naccuracy of approximate reasoning in .O. For instance, instead of computing a given expression repeatedly \n(as in the current implementation of .O), we could run through it only once by performing multiple, either \nindependent or correlated, computations simultaneously. Acknowledgment We are grateful to anonymous reviewers \nfor their helpful comments. 10. REFERENCES [1] http://www.acfr.usyd.edu.au/homepages/academic/ enebot/dataset.htm. \nAustralian Centre for Field Robotics, The University of Sydney. [2] P.Bratley, B.Fox,and L. Schrage. \nA guide to simula\u00adtion. Springer Verlag, 2nd edition, 1996. [3] A. Doucet, N. de Freitas, and N. Gordon. \nSequential Monte Carlo Methods in Practice. Springer Verlag, New York, 2001. [4] D. Fox, W. Burgard, \nand S. Thrun. Markov localization for mobile robots in dynamic environments. Journal of Arti.cial Intelligence \nResearch, 11:391 427, 1999. [5] J. Gill. Computational complexity of probabilistic Tur\u00ading machines. \nSIAM Journal on Computing, 6(4):675 695, Dec. 1977. [6] M. Giry. A categorical approach to probability \nthe\u00adory. In B. Banaschewski, editor, Categorical Aspects of Topology andAnalysis, pages 68 85. Springer \nVerlag, 1981. [7] V. Gupta, R. Jagadeesan, and P. Panangaden. Stochas\u00adtic processes as concurrent constraint \nprograms. In 26th ACM POPL, pages 189 202. ACM Press, 1999. [8] M. Henrion. Propagation of uncertainty \nin Bayesian networks by probabilistic logic sampling. In J. F. Lem\u00admer and L. N. Kanal, editors, Uncertainty \nin Arti.cial Intelligence 2, pages 149 163. Elsevier/North-Holland, 1988. [9] A.H.Jazwinski. Stochastic \nProcesses andFiltering Theory. Academic Press, New York, 1970. [10] C. Jones. Probabilistic Non-Determinism.PhD \nthesis, Department of Computer Science, University of Edin\u00adburgh, 1990. [11] D. Koller, D. McAllester, \nand A. Pfe.er. E.ective Bayesian inference for stochastic programs. In AAAI\u00ad97/IAAI-97, pages 740 747. \nAAAI Press, 1997. [12] D. Kozen. Semantics of probabilistic programs. Journal of Computer andSystem Sciences, \n22(3):328 350, 1981. [13] D. J. C. MacKay. Introduction to Monte Carlo meth\u00adods. In M. I. Jordan, editor, \nLearning in Graphical Models, NATO Science Series, pages 175 204. Kluwer Academic Press, 1998. [14] P. \nMartin-L\u00a8of. On the meanings of the logical constants and the justi.cations of the logical laws. Nordic \nJournal of Philosophical Logic, 1(1):11 60, 1996. [15] T. Mogensen. Roll: A language for specifying die-rolls. \nIn V. Dahl and P. Wadler, editors, PADL 03,volume 2562 of LNCS, pages 145 159. Springer, 2002. [16] E. \nMoggi. Computational lambda-calculus and mon\u00adads. In LICS-89, pages 14 23. IEEE Computer Society Press, \n1989. [17] E. Moggi. Notions of computation and monads. Infor\u00admation andComputation, 93:55 92, 1991. \n[18] M. Montemerlo, N. Roy, and S. Thrun. CAR-MEN: Carnegie mellon robot navigation toolkit. http://www.cs.cmu.edu/~carmen/. \n[19] M. Montemerlo, S. Thrun, D. Koller, and B. Wegbreit. FastSLAM 2.0: An improved particle .ltering \nalgo\u00adrithm for simultaneous localization and mapping that provably converges. In IJCAI-03. Morgan Kaufmann \nPublishers, Inc., 2003. [20] M. Montemerlo, W. Whittaker, and S. Thrun. Condi\u00adtional particle .lters \nfor simultaneous mobile robot lo\u00adcalization and people-tracking. In IEEE International Conference on \nRobotics andAutomation (ICRA), 2002. [21] S. Park. A calculus for probabilistic languages. In TLDI 03, \npages 38 49. ACM Press, 2003. [22] S. Park, F. Pfenning, and S. Thrun. A probabilistic language based \nupon sampling functions. Technical Report CMU-CS-04-173, School of Computer Science, Carnegie Mellon \nUniversity, 2004. [23] A. Pfe.er. IBAL: A probabilistic rational programming language. In IJCAI-01, pages \n733 740. Morgan Kauf\u00admann Publishers, 2001. [24] F. Pfenning and R. Davies. A judgmental reconstruc\u00adtion \nof modal logic. Mathematical Structures in Com\u00adputer Science, 11(4):511 540, 2001. [25] D. Pless and \nG. Luger. Toward general analysis of re\u00adcursive probability models. In UAI-01, pages 429 436. Morgan \nKaufmann Publishers, 2001. [26] N. Ramsey and A. Pfe.er. Stochastic lambda calculus and monads of probability \ndistributions. In 29th ACM POPL, pages 154 165. ACM Press, 2002. [27] S. Russell and P. Norvig. Arti.cial \nIntelligence: A Mod\u00adern Approach. Prentice Hall, 1995. [28] N. Saheb-Djahromi. Probabilistic LCF. In \nProceedings of the 7th Symposium on Mathematical Foundations of Computer Science,volume 64 of LNCS, pages \n442 451. Springer, 1978. [29] S. Thrun. Probabilistic algorithms in robotics. AI Mag\u00adazine, 21(4):93 \n109, 2000. [30] S. Thrun. Towards programming tools for robots that integrate probabilistic computation \nand learning. In ICRA-00. IEEE, 2000. [31] S. Thrun. Robotic mapping: A survey. In G. Lakemeyer and B. \nNebel, editors, Exploring Arti.cial Intelligence in the New Millenium. Morgan Kaufmann, 2002. [32] G. \nWelch and G. Bishop. An introduction to the kalman .lter. Technical Report TR95-041, Department of Com\u00adputer \nScience, University of North Carolina -Chapel Hill, 1995.   \n\t\t\t", "proc_id": "1040305", "abstract": "As probabilistic computations play an increasing role in solving various problems, researchers have designed probabilistic languages that treat probability distributions as primitive datatypes. Most probabilistic languages, however, focus only on discrete distributions and have limited expressive power. In this paper, we present a probabilistic language, called &#955;&#959;, which uniformly supports all kinds of probability distributions -- discrete distributions, continuous distributions, and even those belonging to neither group. Its mathematical basis is sampling functions, <i>i.e.</i>, mappings from the unit interval (0.0,1.0] to probability domains.We also briefly describe the implementation of &#955;&#959; as an extension of Objective CAML and demonstrate its practicality with three applications in robotics: robot localization, people tracking, and robotic mapping. All experiments have been carried out with real robots.", "authors": [{"name": "Sungwoo Park", "author_profile_id": "81100161164", "affiliation": "Carnegie Mellon University", "person_id": "PP14066560", "email_address": "", "orcid_id": ""}, {"name": "Frank Pfenning", "author_profile_id": "81100157780", "affiliation": "Carnegie Mellon University", "person_id": "PP39030152", "email_address": "", "orcid_id": ""}, {"name": "Sebastian Thrun", "author_profile_id": "81100590972", "affiliation": "Stanford University", "person_id": "PP39049906", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1040305.1040320", "year": "2005", "article_id": "1040320", "conference": "POPL", "title": "A probabilistic language based upon sampling functions", "url": "http://dl.acm.org/citation.cfm?id=1040320"}