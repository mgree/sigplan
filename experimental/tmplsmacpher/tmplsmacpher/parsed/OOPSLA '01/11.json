{"article_publication_date": "10-01-2001", "fulltext": "\n Incremental Computation of Complex Object Queries Hiroaki Nakamura IBM Research, Tokyo Research Laboratory \n1623-14 Shimotsuruma, Yamato-shi, Kanagawa-ken 242-8502 Japan hnakamur@jp.ibm.com ABSTRACT The need \nfor incremental algorithms for evaluating database queries is well known, but constructing algorithms \nthat work on object-oriented databases (OODBs) has been di.cult. The reason is that OODB query languages \ninvolve complex data types including composite objects and nested collec\u00adtions. As a result, existing \nalgorithms have limitations in that the kinds of database updates are restricted, the oper\u00adations found \nin many query languages are not supported, or the algorithms are too complex to be described precisely. \nWe present an incremental computation algorithm that can handle any kind of database updates, can accept \nany ex\u00adpressions in complex query languages such as OQL, and can be described precisely. By translating \nprimitive values and records into collections, we can reduce all query expressions into ones composed \nof only one kind of operation, namely comprehension. This makes the problems with incremental computation \nless complicated and thus allows us to describe the algorithm precisely. Our incremental algorithm consists \nof two parts: one is to maintain the consistency in each com\u00adprehension occurrence and the other is to \nupdate the value of an entire expression. The algorithm is so .exible that we can use strict updates, \nlazy updates, and their combina\u00adtions. By comparing the performance of applications built with our mechanism \nand that of equivalent hand written update programs, we show that our incremental algorithm can be implemented \ne.ciently. 1. INTRODUCTION Incremental computation has been studied in many .elds [19]. The underlying \nidea is that we can improve the performance of a function by computing an output using the result of \na previous computation whose input is slightly di.erent from the current one. Incremental computation \nis also receiving attention in the database community [11]. It is normally cheaper to compute the changes \nto a query answer in re- Permission to make digital or hard copies of part or all of this work or personal \nor classroom use is granted without fee provided that copies are not made or distributed for profit or \ncommercial advantage and that copies bear this notice and the full citation on the first page. To copy \notherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission \nand/or a fee. OOPSLA 01 Tampa Florida USA Copyright ACM 2001 1-58113-335-9/01/10 $5.00 sponse to changes \nto the database than to compute the en\u00adtire answer from scratch. Although many incremental algorithms \nhave been proposed for relational databases (RDBs) [12], we cannot directly apply them to object-oriented \ndatabases. The reason is OODBs must be able to handle complex data structures in\u00adcluding composite objects \nand nested collections while RDBs handle only .at tables. Queries of OODBs are also di.erent from those \nof RDBs in that they are recursively composed of sub-queries so that they can traverse the complex data \nstructures. Since OODBs must support complex data types and oper\u00adations, which can be composed recursively, \nincremental al\u00adgorithms for OODB queries are inherently complicated. A straightforward implementation \nwould produce in.nite com\u00adbinations of cases. Thus existing incremental algorithms suf\u00adfer from the following \nde.ciencies: (1) the kinds of database updates are restricted, (2) the operations found in many query \nlanguages are not supported, and (3) the algorithms are presented so informally that we cannot check \ntheir cor\u00adrectness or completeness. In this paper we will present an incremental computation al\u00adgorithm \nfor OODB queries in which (1) any kinds of database updates can be handled, (2) any expressions in complex \nquery languages such as ODMG OQL [4] can be accepted, and (3) the algorithm can be precisely represented. \nThe contributions of this paper are: (1) the technique for trans\u00adlating various types of operations in \nOODB query languages into single operation, (2) the algorithm that computes dif\u00adferential elements for \ncollection expressions correctly and ef\u00ad.ciently, (3) the .exible incremental evaluation method in which \nwe can use strict updates, lazy updates, and their combinations, and (4) the demonstration that the combina\u00adtion \nof the above can be implemented e.ciently. 2. COMPREHENSION QUERY NOTATION A clear distinction between \na query language and a program\u00adming language is that the former must allow us to describe operations \non collections concisely. A literature review [21] covers a wide range of languages for collection types. \nWe use a query notation based on comprehensions [22, 3] as the basis of our algorithm. In particular \nwe will employ the monoid comprehension calculus [6], in which multiple col\u00adlection types and aggregate \noperations can be treated uni\u00adformly. A set comprehension {x * x|x . S . x> 0} describes the set of squares \nof all the positive numbers in a set S. The resulting set is obtained by evaluating x * x for each x \n. S where x> 0 holds. This notation leads us to a collection query language that takes the form: e ::= \n... |{e1,...,en} (n = 0) |{e|q1,...,qn} (n = 0) in which e is an expression and qi is a quali.er. A quali.er \nis either a generator of the form v . e ', where v is a variable that ranges over the elements of e \n. , or  a .lter, which is a boolean valued expression.  A comprehension is de.ned by the following \nequations: {e|} = {e} {e|v . e . ,q1,...,qn} = if e . = {} then {} else C(a1) . ... . C(am) where C(v)= \n{e|q1,...,qn}, e . = {a1,...,am}{e|filter, q1,...,qn} = if filter then {e|q1,...,qn} else {} The following \nare examples of comprehension expressions: select(f, e)= {x|x . e, f (x)} project(f, e)= {f(x)|x . e} \nflatten(e)= {x|s . e, x . s} A comprehension with multiple generators is equivalent to a nested loop \nin an imperative programming language. Thus flatten({{1, 3}, {5}}) iterates over {1, 3} and {5}, which \nre\u00adsults in the set {1, 3, 5}. We can treat other types of collection such as bag in the same framework. \nIn addition, aggregate operations such as sum, and, and or can also be captured by comprehensions. Each \nof the data types can be understood as a monoid, an algebraic structure that is a pair of an associative \nmerge operator and the left and right identity of the operator. Ta\u00adble 1 shows the monoids we use in \nthis paper. A monoid is idempotent when .x.x . x = x. The de.nition of comprehension above can easily \nbe ex\u00adtended so that it can handle other monoids by replacing M merge identity idempotent v collection \nset union empty set monoid bag additive union empty bag primitive sum + 0 v monoid and . true v or . \nfalse Table 1: Monoid Examples . and {} with their merge operators and identities. To dis\u00adtinguish \nthe monoids we describe them with pre.xes that specify collection types or aggregate operations. For \nexam\u00adple, sum{x|x . bag{1, 2}} computes the integer value 3. When no confusion results, we will use {...} \nfor set{...}. Other examples are: length(e)= sum{1|x . e} includes(e, a)= or{a = x|x . e} intersect(e1,e2)= \n{x1|x1 . e1, or{x2 = x1|x2 . e2}} A comprehension language can capture most features of OODB query languages \nwhen it is equipped with primitive values and records in addition to collections. The language must also \nsupport operations on such data types. The lan\u00adguage now takes the form: e ::= ... | c constant | v variable \n| e1 + e2 also for *, =, <, \u00b7\u00b7\u00b7 | <l1 = e1,...,ln = en> record construction | e.l record projection | \nM{e1,...,en} monoid | M{e|q1,...,qn} monoid comprehension M.{set, bag, sum, and, or} This can serve \nas an intermediate language for other query languages such as OQL, a standardized OODB query lan\u00adguage. \nThe query select the employees whose family in\u00adcomes are higher than $50,000 is represented in OQL as \nfollows: select e from e in Employees where sum(select m.salary from m in e.family) + e.salary > 50000 \n This OQL query is translated into the following comprehen\u00adsion expression: bag{e| e . Employees, sum{m.salary|m \n. e.family} + e.salary > 50000} Most OQL expressions have a direct translation into com\u00adprehension expressions \n[6, 10]. Relational algebra is a special case of comprehensions in which the values are restricted to \nsets of records of primitives.  3. PROBLEMS WITH INCREMENTAL COMPUTATION A comprehension language can \nserve as a foundation for incremental computation of expressions that involve collec\u00adtions. Assume we \nhave f(E)= {x * x|x . E} When the new elements .E are added to E, we can obtain the new value of f(Enew), \nwhere Enew = E . .E, by com\u00adbining the previous result f(E) and the value of f(.E) as follows: f(Enew)= \nf(E) . f(.E) This implies that we can reuse the value of f(E) to compute f(Enew). However, we cannot \napply the idea to all the cases for two major reasons. One reason is that we have to handle prim\u00aditives \nand records as well as collections, which prevents us from using the same idea for incremental computation. \nThe other reason is that we cannot handle deletion of el\u00adements with the same approach. For example, \nassume we have E = {-4, 1, 4} and .E = {4}. Then f(E)= {16, 1}and f(.E)= {16}, thus f (E) - f(.E)= {1}. \nHowever f(Enew), where Enew = E - .E, is {16, 1}, which does not satisfy f(Enew)= f(E) - f(.E). Even \nif we use a bag, which satis.es the equation above, computing f(.E) from scratch is often too expensive \nbecause the elements of f(.E) will not be used in f(Enew). We will address the .rst problem in Section \n4 and the second problem in Section 5.  4. TRANSLATION INTO COLLECTIONS Primitive Values ' When a primitive \nvalue a is changed into ain an expression ' g(a), we can obtain the new value g(a) by .rst cancelling \nthe e.ect caused by the old value a and then introducing the ' e.ect caused by the new value a. For example, \nwhen a = 2, the expression bag{x * 2|x . bag{1,a}} yields bag{2, 4}. When the value of a is changed to \n3, the new value of the expression can be computed by .rst removing 4, which is the e.ect of the old \nvalue of a, and then adding 6, which is the e.ect of the new value. The result is bag{2, 6}. This observation \nleads us to represent a primitive value as a set whose only element is the primitive value. A change \nof the value is realized in two steps: (1) remove the old value from the set and (2) add the new value \nto the set. Given the value representation as a set S, the .rst step is realized by: S1 = S -{eold} The \nsecond step is S2 = S1 .{enew} We also have to modify the operations on primitive values so that they \ntake and produce sets. The modi.ed operator ' that corresponds to '+has to be: {} if X1 = {}  {} \nif X2 = {}add(X1,X2)={x1 + x2} otherwise where {x1} = X1,  {x2} = X2 This can be represented by the \nfollowing comprehension: {x1 + x2|x1 . X1,x2 . X2} Note that since X1 and X2 are singletons or empty \nsets, the result has one element at most. The .rst example in this section is expressed as follows: bag{{x1 \n* x2|x1 . x, x2 .{2}}|x . bag{{1}, {a}}} This yields bag{{2}, {4}} when a = 2, which becomes bag{{2}, \n{}} in the intermediate state, and .nally becomes bag{{2}, {6}} when a =3 Records We can also encode \nrecords into collections. The basic idea is to represent a record as a set of pairs, each of which consists \nof a .eld name and its value1 . For example, the record < name = John , age = 32 > can be represented \nby r = {(name, { John }), (age, {32})}. The value of age can be obtained by a comprehension as follows: \n{x|(l, a) . r, l = age, x . a} Figure 1 shows the entire encoding algorithm in terms of the function \nE[ .]]. Although the sets for representing primitive values and records are nothing special in that they \nobey all the axioms of sets, we denote them by setp and setr so that the inverse function D[ .] in Figure \n2 can uniquely decode values. Booleans For the translated language in Figure 1, since the booleans are \nnow represented by {true} and {false}, the de.nition of a .lter should be changed as follows: {e|filter, \nq1,...,qn} = if filter = {true} then {e|q1,...,qn} else {} 1A pair (a,b) can be represented by a set \n{{a},{a,b}} (Ku\u00adratowski s ordered pair). This makes pairs unnecessary, but we use them for readability. \nE[ c] E[ v] E[ e1 + e2] E[ <l1 = e1,...,ln = en > ] E[ e.l] E[ M{e1,...,en}] E[ M{e|q1,...,qn}] Q[ \nv . e] Q[ e]  = setp{c} = v = setp{x1 + x2|x1 .E[ e1] ,x2 .E[ e2] } also for *, =, <, \u00b7\u00b7\u00b7 = setr{(l1, \nE[ e1]]),..., (ln, E[ en]])} = E[ M{x|(l ' ,a) .E[ e] ,l = l ' ,x . a}] . M{E[ e1] ,..., E[ en] }= \nsetp{M{E[ e1] ,..., E[ en] }} . M{e|Q[ q1] ,..., Q[ qn] } = setp{M{e|Q[ q1] ,..., Q[ qn] }} = v .E[ \ne] = E[ e]  Figure 1: Encoder M is the type of a for collection types for aggregate operations for collection \ntypes for aggregate operations D[ setp{c}] = c = D[ setr{(l1,v1),..., (ln,vn)}] <l1 = D[ v1] ,...,ln \n= D[ vn] > D[ M{v1,...,vn}] = M{D[ v1] ,..., D[ vn] } (M.= setp or setr) Figure 2: Decoder If we replace \n{false} with {}, the de.nition becomes: {e|filter, q1,...,qn} = if filter = {} then {} else {e|q1,...,qn} \n= if filter = {} then {} else C(a) where C(v)= {e|q1,...,qn}, {a} = filter = {e|v . filter, q1,...,qn} \nIn this way we can implement .lters as generators, which makes the equation for .lters unnecessary in \nthe de.nition of comprehensions. Note that the iteration variable v (or the value of a) is never used \nin qi. 5. INCREMENTAL COMPUTATION OF COMPREHENSION INSTANCES Comprehension Instances We will introduce \nthe notion of a comprehension instance for separating an expression from its value. A comprehension instance \nC is an occurrence of a comprehension expression in an environment, an association of values with variables. \nSo far we have not clearly distinguished between an expres\u00adsion and the value it denotes. However, since \nexpressions can have free variables, their values vary depending on the environments in which they are \nevaluated. We describe the value of C as C.value and the environment of C as C.env. Let C be a comprehension \ninstance for {e|v . e ' ,q1,...,qn}, E be that for e ' , and Si be that for {e|q1,...,qn}. Then the following \nequations hold: C.value = if E.value = {} then {} else S1.value . ... . Sm.value E.env = C.env Si.env \n= C.env .{(v, ai)} where E.value = {a1,...,am} Therefore we can keep the value of C.value up to date \nby modifying it in response to the changes in E.value and Si.value.  Bag Comprehensions We .rst look \ninto the method for computing a bag compre\u00adhension incrementally. The discussion can be generalized to \nany comprehensions whose underlying monoids are anti\u00adidempotent. As we have mentioned in Section 3, the \nincre\u00admental computation of a bag comprehension is easier than that of a set comprehension because a \nbag allows elements to be duplicated but a set does not. The problem in maintaining a bag comprehension \nis when we remove ak from E.value, creating a comprehension instance Sk for ak to compute C.valuenew \n= C.value - Sk.value is often too expensive because Sk is discarded just after Sk.value is used. We solve \nthis problem by retaining the mapping between ai and Si, and reusing Si when ai is removed. For that \npurpose we use an auxiliary data structure C.map such that C.map = bag{(a, S such that (v, a) . S.env)|a \n. E.value} Then C.value can be obtained as C.value = bag{x|(a, S) . C.map, x . S.value} When ak is removed \nfrom E.value, the elements to be re\u00admoved from C.value can be obtained as . - (C.value)= lookup(C.map, \nak).value where lookup(m, x) selects from m one element (a, b) such that x = a, and gives b. By de.ning \nC.value and its dif\u00adferential elements . - (C.value) in terms of C.map, we can avoid computing Sk multiple \ntimes. We also maintain the following relationships so that we can propagate changes among comprehension \ninstances and can ensure the consistency of entire expressions. E . C.components Si . C.components C \n. E.dependents C . Si.dependents  Set Comprehensions For a set comprehension, we also use the auxiliary \ndata structure C.map so that we can avoid unnecessary compu\u00adtation in deleting elements. Since the value \nof a set compre\u00adhension is a set, C.value is obtained as C.value = set{x|(a, S) . C.map, x . S.value} \nUnlike a bag comprehension, a set comprehension requires us to manage the input elements that yield the \nsame value. In the example in Section 3, since both -4 and 4 yielded the same value 16, we could not \nexclude 16 from the result when deleting the input element 4. However, if we delete both -4 and 4, we \nhave to exclude 16 from the result. To handle those situations correctly, we use another auxil\u00adiary data \nstructure C.counts such that C.counts = set{(x, count(C.map, x))|x . C.value} The function count(m, x) \nis de.ned as follows: count(m, x)= sum{1|(a, S) . m, y . S.value, x = y} C.counts maintains the mapping \nbetween an element in the result C.value and the number of duplicates that yielded the element. When \nak is removed from E.value, the elements to be re\u00admoved from C.value can be obtained as . - (C.value)= \nset{x| x . lookup(C.map, ak).value, lookup(C.counts, x)= count(lookup(C.map, ak).value, x)} The expression \nchecks if an element to be removed satis\u00ad.es the condition that the number of duplicates in C.value is \nsame as the number of duplicates in S.value. The tech\u00adnique here can be generalized to any comprehensions \nwhose underlying monoids are idempotent. 6. UPDATE PROPAGATIONS Strict Updates Given the incremental \nevaluator update(c) for a compre\u00adhension instance c, we can update the value of an entire expression \nby propagating changes among comprehension instances. When the value of a comprehension instance c is \nchanged, the value of another comprehension instance c ' that depends on c should also be updated. Figure \n3 shows the algorithm that directly implements this idea. The al\u00adgorithm updates the value of a comprehension \ninstance and propagates the update along the edges of the dependency graph. This algorithm is strict \nin that the algorithm up\u00addates the value of an entire expression whenever the value of a piece of the \nexpression is changed. Since comprehen\u00adsion instances that are not involved in the change are not evaluated, \nthis algorithm is incremental.  Lazy Updates Although StrictUpdate(c) correctly updates the values of \nexpressions, it has two problems. One is that because a single comprehension instance can depend on multiple \nother instances, it may be evaluated more than once for a single change. This makes the update propagation \nine.cient. The other problem is that the algorithm always computes the latest value even if the value \nwill not be used. When the value is overwritten, the previous value becomes useless. The two problems \ncan be solved by delaying updates until the value is actually required. To avoid traversing the entire \ngraph when the value is required, we use an algorithm that consists of two phases (Figure 4). The .rst \nphase propa\u00adgates the invalid marker along the dependency graph. The second phase makes all of the components \nof a comprehen\u00adsion instance valid, then evaluates the instance itself. The .rst phase visits an edge \nof the dependency graph at most once, and the second phase computes the new value of an instance at most \nonce. Thus the algorithm does not do the same work multiple times. This algorithm computes the lat\u00adest \nvalue only when the second phase is invoked. The idea behind this algorithm is presented as the Adaptive \nPropa\u00adgator in Feiler and Tichy [7]. Hybrid Updates Unfortunately, the lazy update algorithm makes the \nresponse time worse when collections are dominant in an expression. The second phase updates all the \ninvalid comprehensions at once. If we have many unprocessed elements in collec\u00adtions, this phase takes \nlong time, which lessens the e.ect of incremental computation. StrictUpdate(c: comprehension instance) \n{ update(c); for each c ' . c.dependents StrictUpdate(c ' ); } Figure 3: Strict Update LazyUpdatePhase1(c: \ncomprehension instance) { if c.valid = true { c.valid := false; for each c ' . c.dependents LazyUpdatePhase1(c \n' ); }} LazyUpdatePhase2(c: comprehension instance) { for each c ' . c.components if c ' .valid = false \n{ LazyUpdatePhase2(c ' ); c ' .valid := true; } update(c); } Figure 4: Lazy Update One solution is to \ndelay changes of primitive values only; ad\u00addition and deletion of elements are processed immediately. \nSince the e.ect of updates in primitive values is always over\u00adwritten when the value is changed, it is \nclear that delaying computation of primitive values is e.ective to improve the performance. The resulting \nalgorithm is a combination of the strict updates and the lazy updates shown in Figure 5. For primitive \nvalues, the lazy algorithm is applied; otherwise the strict algorithm is used. Note that the hybrid update \nalgorithm is not always the best solution because it has the same problem as the strict updates. 7. \nIMPLEMENTATION We implemented an experimental system using Cincom Vi\u00adsualWorks 3.1, a Smalltalk development \nenvironment. We use OQL instead of a comprehension language as a surface language. The system takes OQL \nqueries as an input and translates them into byte codes that will generate the ab\u00adstract syntax trees \n(ASTs) whose nodes are comprehensions. When a query, which is now a compiled Smalltalk method, is invoked, \nthe generated AST constructs comprehension in\u00adstances, each of which holds its initial value as well \nas de\u00adpendency relationships. Maintenance of dependencies between objects, change no\u00adti.cations, and \nautomatic updates are well represented by the Observer pattern [8] in an object oriented system. Vi\u00adsualWorks \nprovides a framework for the Observer pattern, namely the dependency mechanism, but we implemented our \nown mechanism because we wanted to separate change noti.cations from value updates. When they are synchronous, \nthe computation is strict. When they are asynchronous, the HybridUpdatePhase1(c: comprehension instance) \n{ if c.type = setp { LazyUpdatePhase1(c); } else { update(c); for each c ' . c.dependents HybridUpdatePhase1(c \n' ); }} HybridUpdatePhase2(c: comprehension instance) {LazyUpdatePhase2(c); } Figure 5: Hybrid Update \n computation is lazy. Although we have only one kind of operation, which is com\u00adprehensions, we implemented \nthem in multiple ways so that we can take advantage of the features of underlying data and operations. \nFor example, since a set that represents a constant never changes, we can implement it in terms of a \nconstant itself. We made constants behave as if they were sets by adding a method whose meaning is to \naccess a set element but whose implementation is to return the constant object itself. Another example \nis the implementation of a primitive value. Since a set that represents a primitive value contains one \nelement at most, we can implement it as an object whose only instance variable is to hold a value. This \nobject is much lighter than general sets, which can hold any number of objects. We can also make a set \nfor a record ef\u00ad.cient by adding to the object indexes that make access to .eld values fast. We also \noptimized our implementation by taking OQL-speci.c features into account. For example, the group by clause, \nwhich converts a bag into a set of bags, can be implemented e.ciently using the knowledge that any two \nconverted bags are disjoint. 8. EVALUATION Evaluation Method We evaluated the performance of our system \nby compar\u00ading (a) applications built on our incremental computation mechanism and (b) equivalent programs \nhand written in Smalltalk. A hand written Smalltalk program updates its results using procedural logic. \nNote that the hand writ\u00adten programs were implemented in a straightforward way; they were not optimized. \nTo investigate the e.ect of lazy updates, we executed applications built on our mechanism in two modes: \n(a1) using only strict updates, and (a2) us\u00ading both strict and lazy updates (hybrid updates). Since \nin our applications, collections are dominant, we excluded lazy only updates. All the applications share \nthe same underlying database. The data model is shown as a UML class diagram in Fig\u00adure 6. In the data \nmodel, Order, Sale, and CashReceipt are primary transactions while OrderLineItem, SaleLineItem, Figure \n6: Benchmark Data Model and Payment are transactions subsequent to Order, Sale and CashReceipt. Transaction \nobjects are being inserted into the database while the benchmark is running but the other ob\u00adjects are \n.xed. We insert Orders, Sales, and CashReceipts in the same ratio 1:1:1. For each primary transaction, \n.ve subsequent transactions are generated. We used the OQL queries shown in Figure 7. Note that although \nthe only change to the underlying database is the addition of elements, the queries cause other types \nof change by means of the sum operator, the group by clause, and the binary operators on primitive values. \nResults The performance evaluation was conducted on a 300 MHz Pentium-II PC with 128MB memory under Windows \nNT 4.0. Table 2 shows the ratio of the processing time of our incremental framework to that of the hand \nwritten Smalltalk programs. The Order Statistics and Unpaid Sales queries achieve performance comparable \nto hand written programs. However, the General Ledger application is slow compared with the other queries. \nThe reason is that the hand written General Ledger program uses few expensive operations such as table \nsearches or collection iterations. Lazy updates are e.ective only in the Unpaid Sales application because \nit uses a complex condition in the where clause. Figures 8, 9, and 10 indicate how the ratio changes \nwith the amount of data inserted. The ratio is almost stable in the General Ledger and Order Statistics \nqueries. For the Un\u00adpaid Sales application, the performance of our framework becomes closer to that of \nthe hand written program as the amount of data increases. This is because VisualWorks does not handle \nlarge collections e.ciently and thus the perfor\u00admance of the hand written program is dominated by the \ncollection operations, which our framework also depends on.  9. RELATED WORK Database View Maintenance \nThe algorithms for computing queries incrementally are known as incremental view maintenance techniques. \nTechniques for relational models have been studied extensively [11]. Re\u00adcently incremental algorithms \nfor nested collections have been attracting attention. Examples are: Gluche et al. [9], Baekgaard and \nMark [2], Kawaguchi et al. [16], and Liu et al. [18]. However they addressed problems that arise only \nwhen elements are added or deleted; modi.cation of record attributes were out of their scope. Kuno and \nRundensteiner [17] considered modi.cation of at\u00adtribute values, but this can be treated independently \nof ad\u00addition or deletion of elements because in their language col\u00adlections and the other types do not \ninteract. Fegaras [5] suggested that by extending the monoid calculus with ob\u00adject identities, we can \nhandle the modi.cation of attributes as well as addition and deletion of collection elements in a single \nframework. However, he left constructing an actual algorithm to future research. To our knowledge, Ali \net al. [1] is the only work that pre\u00adsented an incremental algorithm that can handle modi.ca\u00adtions, additions, \nand deletions in a complex object-oriented query language like OQL. However, although their algorithm \nis very complicated, they did not formally show the ratio\u00adnale behind the algorithm, which prevents us \nfrom checking the correctness or completeness of their algorithm. Application Hand Written Incremental \nFramework Time (Tb) Strict Updates Time (Ta1) Ratio (Ta1/Tb) Strict &#38; Lazy Updates Time (Ta2) Ratio \n(Ta2/Tb) General Ledger 0.65 s 5.14 s 7.9 4.94 s 7.6 Order Statistics 3.56 s 7.62 s 2.2 7.67 s 2.2 Unpaid \nSales 10.81 s 17.28 s 1.6 13.79 s 1.3 (Number of primary transactions = 8K) Table 2: Performance Comparison \nQuery: General Ledger struct( accountsReceivable: (sum(select i.price * i.quantity from s in sales, i \nin s.saleLineItems) -sum(select r.checkAmount from r in cashReceipts)), cash: sum(select r.checkAmount \nfrom r in cashReceipts), costOfGoodsSold: sum(select i.product.cost * i.quantity from s in sales, i in \ns.saleLineItems)) Query: Statistics on Product Orders select struct( product: product.name, month: month, \ntotal: sum(select p.i.quantity from p in partition)) from order in orders, i in order.orderLineItems \ngroup by product: i.product, month: order.date.monthIndex  Query: Unpaid Sales select struct( name: \ns.order.customer.name, no: s.no) from s in sales where (sum(select i.price * i.quantity  from i in \ns.saleLineItems) Figure 8: Performance Comparison (General -sum(select p.amount Ledger) from p in s.payments)) \n> 0 Figure 7: Benchmark Queries   Incremental Attribute Evaluation An attribute grammar supplies its \naccompanying semantics in terms of the equations that de.ne attribute values associ\u00adated with the grammar \nsymbols. By dynamically maintain\u00ading the equations in response to changes to the attribute val\u00adues, we \ncan preserve the semantic correctness of a program in the language. This idea was explored extensively \nin the context of language-aware programming environments [20]. Hudson [14] presented an algorithm in \nwhich attribute eval\u00aduation can be deferred until the values are actually needed. He then applied the \nlazy evaluation algorithm to an object\u00adoriented language [15]. Zanden et al. [25] also gave both a strict \nand a lazy incremental algorithms for manipulating data structures with pointer variables. Our work is \nactually an extension of their approaches, but applied to a language equipped with collections as a .rst-class \ndata type. Yellin and Strom [24] designed a functional language that can be evaluated incrementally. \nThe language can handle bags as well as records, and thus their approach is similar to ours. One di.erence \nis that their notion of change is re\u00adstricted to addition and deletion of bag elements, while our framework \naccepts any types of data updates. Another dif\u00adference is that they attached independent incremental \npro\u00adcedures to 15 operators, which makes analyzing the entire algorithm very hard, while our algorithm \nhas to handle only one operator. 10. CONCLUDING REMARKS We have presented an incremental query evaluation \nalgo\u00adrithm that can handle any kinds of database updates and can accept any expressions in complex query \nlanguages by translating diverse OODB queries into uniform comprehen\u00adsion expressions. Since we have \nto consider only one opera\u00adtion, the problems with incremental computation of OODB queries are manageable. \nWe have also shown that the al\u00adgorithm can be implemented e.ciently. It achieves perfor\u00admance comparable \nto hand written update programs. Since our work is essentially an application of incremental attribute \nevaluation techniques to collection languages, we can use the ideas developed in those two areas to improve \nour algorithm. For example, the algorithm shown in this pa\u00adper does not use any sophisticated techniques \nin managing dependencies, but we can achieve faster incremental com\u00adputation by handling non-local dependencies \ndirectly [13]. Another technique we can use is the meaning-preserving transformation between two collection \nexpressions [6, 23]. Although their transformation rules are designed to increase the performance of \nqueries in a non-incremental setting, we believe we can use them to improve the performance of our incremental \nalgorithm. 11. ACKNOWLEDGEMENTS The author would like to thank Ralph E. Johnson for his helpful comments \nand advice. Figure 10: Performance Comparison (Unpaid Sales)  12. REFERENCES [1] M. A. Ali, A. A. A. \nFernandes, and N. W. Paton. Incremental maintenance of materialized OQL views. In International Workshop \non Data Warehousing and OLAP, 2000. [2] L. Baekgaard and L. Mark. Incremental computation of nested relational \nquery expressions. ACM Transactions on Database Systems, 20(2), 1995. [3] P. Buneman, L. Libkin, D. Suciu, \nV. Tannen, and L. Wong. Comprehension syntax. SIGMOD Record, 23(1), 1994. [4] R. G. G. Cattell and D. \nK. Barry, editors. The Object Database Standard: ODMG 3.0. Morgan Kaufmann Publishers, Inc., 2000. [5] \nL. Fegaras. Optimizing queries with object updates. Journal of Intelligent Information Systems, 12, 1999. \n[6] L. Fegaras and D. Maier. Optimizing object queries using an e.ective calculus. ACM Transactions on \nDatabase Systems, December 2000. [7] P. H. Feiler and W. F. Tichy. Propagator: A family of patterns. \nIn Proceedings of Technology of Object-Oriented Languages and Systems, 1997. [8] E. Gamma, R. Helm, R. \nJohnson, and J. Vlissides. Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley, \n1994. [9] D. Gluche, T. Grust, C. Mainberger, and M. H. Scholl. Incremental updates for materialized \nviews with user-de.ned functions. In Proceedings of the 5th International Conference on Deductive and \nObject Oriented Databases (DOOD 97), 1997. [10] T. Grust and M. H. Scholl. Translating OQL into monoid \ncomprehensions -stuck with nested loops ? Technical Report 1430-3558, Universit\u00a8at Konstanz, 1996. [11] \nA. Gupta and I. S. Mumick. Maintenance of materialized views: Problems, techniques and applications. \nIEEE Quarterly Bulletin on Data Engineering; Special Issue on Materialized Views and Data Warehousing, \n18(2), 1995. [12] A. Gupta and I. S. Mumick, editors. Materialized Views Techniques, Implementations, \nand Applications. MIT Press, 1999. [13] R. Hoover. Dynamically bypassing copy rule chains in attribute \ngrammars. In Proceedings of Symposium on Principles of Programming Languages, 1986. [14] S. E. Hudson. \nIncremental attribute evaluation: A .exible algorithm for lazy updates. ACM Transactions on Programming \nLanguages and Systems, 13(3), 1991. [15] S. E. Hudson. A system for e.cient and .exible one-way constraint \nevaluation in C++. Technical Report 93-15, College of Computing, Georgia Institute of Technology, 1997. \n[16] A. Kawaguchi, D. F. Lieuwen, I. S. Mumick, and K. A. Ross. Implementing incremental view maintenance \nin nested data models. In Proceedings of the International Workshop on Database Programming Languages, \n1997. [17] H. A. Kuno and E. A. Rundensteiner. Incremental maintenance of materialized object-oriented \nviews in multiview: Strategies and performance evaluation. IEEE Transactions on Knowledge and Data Engineering, \n10(5), 1998. [18] J. Liu, M. Vincent, and M. Mohania. Incremental evaluation of nest and unnest operators \nin nested relations. In Proceedings of 1999 CODAS Conference, 1999. [19] G. Ramalingam and T. Reps. A \ncategorized bibliography on incremental computation. In Proceedings of the Symposium on Principles of \nProgramming Languages, 1993. [20] T. Reps and T. Teitelbaum. The Synthesizer Generator: A System for \nConstructing Language-Based Editors. Springer-Verlag, 1988. [21] V. Tannen. Tutorial: Languages for collection \ntypes. In Proceedings of Symposium on Principles of Database Systems, 1994. [22] P. Trinder. a query \nnotation for DBPLs. In Proceedings of the Third International Workshop on Database Programming Languages, \n1991. [23] L. Wong. Normal forms and conservative extension properties for query languages over collection \ntypes. Journal of Computer and System Sciences, 52(3), 1996. [24] D. M. Yellin and R. E. Strom. INC: \nA language for incremental computations. ACM Transactions on Programming Languages and Systems, 13(2), \n1991. [25] B. T. V. Zanden, B. Myers, D. Giuse, and P. Szekely. Integrating pointer variables into one-way \nconstraint models. ACM Transactions on Computer Human Interaction, June, 1994.  \n\t\t\t", "proc_id": "504282", "abstract": "The need for incremental algorithms for evaluating database queries is well known, but constructing algorithms that work on object-oriented databases (OODBs) has been difficult. The reason is that OODB query languages involve complex data types including composite objects and nested collections. As a result, existing algorithms have limitations in that the kinds of database updates are restricted, the operations found in many query languages are not supported, or the algorithms are too complex to be described precisely. We present an incremental computation algorithm that can handle any kind of database updates, can accept any expressions in complex query languages such as OQL, and can be described precisely. By translating primitive values and records into collections, we can reduce all query expressions comprehension. This makes the problems with incremental computation less complicated and thus allows us to decribe of two parts: one is to maintain the consistency in each comprehension occurrence and the other is to update the value of an entire expression. The algorithm is so flexible that we can use strict updates, lazy updates, and their combinations. By comparing the performance of applications built with our mechanism and that of equivalent hand written update programs, we show that our incremental algorithm can be iplemented efficiently.", "authors": [{"name": "Hiroaki Nakamura", "author_profile_id": "81543296656", "affiliation": "IBM Research, Tokyo Research Laboratory, 1623-14 Shimotsuruma, Yamato-shi, Kanagawa-ken 242-8502 Japan", "person_id": "PP309664300", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/504282.504294", "year": "2001", "article_id": "504294", "conference": "OOPSLA", "title": "Incremental computation of complex object queries", "url": "http://dl.acm.org/citation.cfm?id=504294"}