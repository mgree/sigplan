{"article_publication_date": "10-01-2001", "fulltext": "\n Pretenuring for Java Stephen M. Blackburn Sharad Singhai Matthew Hertz Kathryn S. McKinley J. Eliot \nB. Moss Architecture and Language Implementation Laboratory, Department of Computer Science University \nof Massachusetts, Amherst, MA 01003-4610 ABSTRACT Pretenuring can reduce copying costs in garbage collectors \nby allo\u00adcating long-lived objects into regions that the garbage collector will rarely, if ever, collect. \nWe extend previous work on pretenuring as follows. (1) We produce pretenuring advice that is neutral \nwith re\u00adspect to the garbage collector algorithm and con.guration. We thus can and do combine advice \nfrom different applications. We .nd that predictions using object lifetimes at each allocation site in \nJava programs are accurate, which simpli.es the pretenuring implemen\u00adtation. (2) We gather and apply \nadvice to applications and the Jala\u00adpe no JVM, a compiler and run-time system for Java written in Java. \nOur results demonstrate that building combined advice into Jala\u00adpe no from different application executions \nimproves performance regardless of the application Jalape no is compiling and executing. This build-time \nadvice thus gives user applications some bene.ts of pretenuring without any application pro.ling. No \nprevious work pretenures in the run-time system. (3) We .nd that application\u00adonly advice also improves \nperformance, but that the combination of build-time and application-speci.c advice is almost always no\u00adticeably \nbetter. (4) Our same advice improves the performance of generational and Older First collection, illustrating \nthat it is collec\u00adtor neutral. General Terms Garbage collection, pretenuring, lifetime prediction, pro.ling \n1. Introduction Garbage collection (GC) is a technique for storage management that automatically reclaims \nunreachable program data. In addition to sparing the programmer the effort of explicit storage manage\u00adment, \ngarbage collection removes two sources of programming er\u00adrors: memory leaks due to missing or deferred \nreclamation; and . This work is supported by NSF ITR grant CCR-0085792, NSF grant ACI-9982028, NSF grant \nEIA-9726401, NSF Infrastructure grant CDA\u00ad9502639, DARPA grant 5-21425, and IBM. Any opinions, .ndings, \ncon\u00adclusions, or recommendations expressed in this material are the authors and do not necessarily re.ect \nthose of the sponsors. Permission to make digital or hard copies of part or all of this work or personal \nor classroom use is granted without fee provided that copies are not made or distributed for profit or \ncommercial advantage and that copies bear this notice and the full citation on the first page. To copy \notherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission \nand/or a fee. OOPSLA 01 Tampa Florida USA Copyright ACM 2001 1-58113-335-9/01/10 $5.00 memory corruption \nthrough dangling pointers because of prema\u00adture reclamation. The growing use and popularity of Java, \nin which garbage collection is a required element, makes attaining good col\u00adlector performance key to \ngood overall performance. Here our goal is to improve collector performance by reducing GC costs for \nlong\u00adlived objects. We focus on generational copying collection [17] and demonstrate the generality of \nour approach with the Older First collector [15]. Generational copying GC partitions the heap into age-based \ngener\u00adations of objects, where age is measured in the amount of alloca\u00adtion (the accepted practice in \nthe GC literature). Newly allocated objects go into the youngest generation, the nursery. Collection \nconsists of three phases: (1) identifying roots for collection; (2) identifying and copying into a new \nspace any objects transitively reachable from those roots (called live objects); and (3) reclaim\u00ading \nthe space vacated by the live objects. Rather than collecting the entire heap and incurring the cost \nof copying all live objects, gen\u00aderational collectors collect the nursery, place survivors in the next \nolder generation, and only collect successively older generations if necessary. Pretenuring allocates \nsome objects directly into older generations. If pretenured objects are indeed long-lived, then the pretenuring \navoids copying the objects from the nursery into the generation where they are allocated. An ideal pretenuring \nalgorithm would inform the allocator of the exact lifespan of a new object, and then the allocator would \nselect the ideal generation in which to place the object. The collector would thus consider an object \nonly after it has suf.cient time to die, avoiding ever copying it. If an object will die before the next \nnursery collection, then the allocator would place it in the nursery (the default), whereas if the object \nlives until the termination of the program, then the allocator would place it into a permanent region. \nWithout an oracle, pretenuring advice can be gleaned from applica\u00adtion pro.ling on a per allocation-site \n[8] or call-chain [4, 14] basis. For our suite of Java programs, we show that allocation-site advice \nresults in accurate predictions, and these predictions are robust over different input data. ML programs \nare similar [8], whereas C pro\u00adgrams need the additional context of a call-chain [4, 14]. We use two \nobject lifetime statistics (measured in bytes allocated): lifetime and time of death. Object lifetime \nis how long an object lives (in bytes of allocation), and time of death is the point in the allocation \nhistory of the program at which the object becomes un\u00adreachable. Our advice classi.es each object as \nimmortal its time of death was close to the end of the program, short lived its life\u00adtime was less than \na threshold value, or long lived everything else. Cheng, Harper, and Lee (CHL) instead classify objects \n(allocated at a particular allocation site) that usually survive a nursery collec\u00adtion in a generational \ncollector as long lived, and those that do not as short lived [8]. CHL pro.le a given application and \ngenerational collector con.guration to generate pretenuring advice. We instead use frequent full-heap \ncollections to generate the lifetime statistics from which we derive our advice, a more costly process. \nBecause our statistics are collector-and con.guration-neutral, they are more general. The generality \nof our pretenuring advice results in two key advan\u00adtages over previous work. (1) Since we normalize advice \nwith re\u00adspect to total allocation for a speci.c execution, we can and do combine advice from different \napplications that share allocation sites (e.g., classes internal to the JVM, and libraries). (2) We can \nand do use the advice to improve two distinct collectors, an Appel\u00adstyle generational collector [3] and \nan Older First collector [15], on .ve benchmarks, three from SPEC JVM98. In our experiments, we use the \nJalape no JVM [2, 1], a compiler and run-time system for Java written in Java, extended with an Appel\u00adstyle \ngenerational collector. We pro.le all our benchmarks, and then combine their pretenuring advice to improve \nthe performance of Jalape no itself; we call this system build-time pretenuring. Be\u00adcause CHL pro.le \nadvice is speci.c to both the application and collector con.guration, they cannot readily combine advice \nfor this purpose. When measuring the effectiveness of our build-time pre\u00adtenuring, we omit information \nfrom the application to be measured from the combined advice. Such advice is called true advice [4]. \nWe show that build-time pretenuring improves the performance of Jalape no running our benchmarks an average \nof 8% for tight heaps without any application-speci.c pretenuring. As the heap size grows, the impact \nof garbage collection time and pretenuring on total execution time decreases, but pretenuring still improves \ncollector performance. Building pretenuring into the JVM before distribution means users will bene.t \nfrom pretenuring without pro\u00ad.ling their applications. Just using our application-speci.c pro.le advice \nalways improves performance, too: up to 3.5% on average for tight heaps. Our advice is also on average \ncomparable to us\u00ading CHL advice, and is signi.cantly better for tight heaps. Com\u00adbining our build-time \nand application-speci.c advice always yields the best performance: it decreases garbage collection time \non aver\u00adage by 20% to 32% for most heap con.gurations. It improves total execution time on average by \n7% for a tight heap. The remainder of this paper is organized as follows. Section 3 dis\u00adcusses our approach \nto pretenuring and the collection and genera\u00adtion of pretenuring advice. It also analyzes the lifetime \nbehaviors of objects in our Java applications. We then describe our experimen\u00adtal methodology and setting \nin Section 4. Section 5 presents execu\u00adtion time results for pretenuring with generational collection \nfor the Jalape no JVM at build-time, application-speci.c pretenuring with CHL and our advice, and the \ncombination of application-speci.c and build-time advice. We further demonstrate the generality of our \nadvice by showing the same advice improves an Older First collector. We then compare related work with \nour approach, and conclude. 2. Background For this paper we built an Appel style generational collector \n[3] that partitions the heap into a nursery and a second, older, generation. It also has a separate, \npermanent space that is never collected. The total heap size is .xed. The nursery size is .exible: it \nis the space not used by the older generation and the permanent space. Some heap space is always reserved \nfor copying (this space must be at least as large as sum of the nursery and the older generation in order \nto guarantee that collecting the nursery and then the older generation will not fail). When all but the \nreserved heap space is consumed, it collects the nursery, promotes surviving objects into the older generation, \nand makes the freed space the new nursery. After a nursery collection, if the old generation s size is \nclose to that of the reserved space, it triggers collection of the older generation. 3. Pretenuring \nAdvice Two objectives are central to our approach: producing robust and general pretenuring advice, and \nunderstanding and testing the premise of per-site lifetime homogeneity on which the success of pro.le-driven \npretenuring rests. 3.1 Gathering and Generating Pretenuring Advice Any algorithm for generating pretenuring \nadvice must consider the two major cost components: copying and space rental. The copy\u00ading cost includes \nscanning and copying an object when it survives a collection. The space rental cost is the space in memory \noccu\u00adpied by objects over time. On the two extremes, pretenuring ad\u00advice that recommends pretenuring \nall objects into permanent space minimizes copying costs but incurs a high space rental cost; and advice \nthat recommends pretenuring no objects minimizes space rental cost at the expense of higher copying costs. \nOne of our goals is to generate advice that is neutral with respect to any particular collection algorithm \nor con.guration. This goal precludes the use of the metric used by CHL [8], which pretenures if the collector \nusually copies objects allocated at a particular site in the context of a speci.c generational collector \ncon.guration. Our approach is instead based on two fundamental object lifetime statis\u00adtics: age and time \nof death. Object age indicates how long an object lives, and time of death indicates the point in the \nallocation history of the program at which the object becomes unreachable. Following the garbage collection \nconvention of equating time to bytes allocated, we normalize age with respect to max live size. Max live \nsize refers to the maximum amount of live objects in a pro\u00adgram execution, which indicates the theoretical \nminimum memory requirement of a program. We normalize time of death with respect to total allocation.1 \nFor example, consider an object allocated to\u00adward the end of the program that dies after the last allocation. \nIt has a normalized time of death of 1.00. Object age is a fraction or multiple of the max live size. \nFor example, an age of 0.25 means e that during the lifetime of the object, 0 25 max live size bytes \nof allocation occurs. The relationships between object age, time of death, max live size, and total allocation \nare illustrated in Figure 1 for a Java version of health running a small input set, where one point is \nplotted for each object s age and time of death. The top and left axes nor\u00admalize time with respect to \ntotal bytes allocated for that program, while the bottom and right axes show time with respect to the \npro\u00adgram s max live size, which relates to a heap full of allocation. This .gure shows that a large number \nof objects have short life\u00adtimes, and the vertical lines of points indicate that throughout the life \nof the program objects are most likely to die when they reach one of a small number of ages (for example \nabout 0.2 and e 0 6max live size). 1The relationship between max live size and total allocation is a \nfunction of allocation behavior. In our Java programs, total alloca\u00adtion ranges from 11 to 113 times \nmax live size.  Allocation Site Classi.cation Object age relative to total allocation Using the bins, \nwe then classify a site. Given an allocation site 0 0.2 0.4 0.6 0.8 1 that allocates a fraction Sf of \nshort-lived objects, Lf of long-lived 1 Object time of death relative to total allocation n Object time \nof death realtive to max live size objects, and If of immortal objects, we classify it using a homo\u00ad \n7 geneity threshold Hf as follows: 0.8 1. If Sf +Hf >Lf + 6 If we classify the site short. 2. Otherwise, \nif Sf +Lf +Hf >If , we classify the site long. 5 0.6  immortal 3. In all other cases, we classify the \nsite immortal. 4 Thus we make a conservative classi.cation (short) for the site if that 0.4 is the most \ncommon case, and the less conservative classi.cations 3 (long or immortal) when they are suf.ciently \nmore common than the other choices. For example, given fractions of 0.1 short, 0.35 long, and 0.55 immortal, \nwe classify the site long if Hf >o(g1, but if Hf 2 long w 0.2 55 35g01)=0 Hf = 1 01, we classify it \nimmortal. We use 33 in our experiments. We .nd our binning and classi.cation 0 0 fairly insensitive \nto reasonable choices of Ta and Hf . 1234567  short 0 Combining Classi.cations from Different Program \nExecutions Object age relative to max live size We are also able to combine data from different program \nexecu\u00adtions to generate pretenuring advice. Our trace combining algo- Figure 1: Object Age and Death \nDistributions for health (3\u00ad rithm works as follows. For each site, we generate new combined 128) bins \nsc lc ic. For each trace t, we .rst compute a weight wt for each site: wt =vs /vt , where vs is the volume \nallocated at the site, and vt is the total volume of allocation in the trace. We then compute the following \ncombined bins for all sites with trace information. Let Object Lifetime Pro.ling .n wc =tL1 wt . We \nanalyze age and lifetime statistics using an execution pro.le ) n =/* . (tL1 mutation trace, which records \nall object allocations, pointer muta\u00ad sc st wt wc for each application. The pro.le takes the form of \nan object graph ) n =/( lt * tions, and object deaths. We log all allocations, all heap pointer . 1 tL \nlc wt wc mutations, and when the collector frees an object. To obtain accu\u00ad rate object death information, \nwe trigger a (non-generational) full heap collection frequently (once every 64KB of allocation). We ic \ngather age and time of death statistics for each object, as well as the max live size and total allocation \nfor the application. Binning For each object allocated at a given site, we categorize it into one of \nthree bins: short, long, or immortal. We use the following algo\u00adrithm. 1. If an object dies more than \nhalfway between its time of birth and the end of the program, we bin it as immortal. e 2. Otherwise, \nif an object s age is less than Ta max live size bytes, then it is binned as short. 3. In all other \ncases, an object is binned long.  We use Ta =02 in our experiments below. Our immortal classi\u00ad.cation \ncriterion is based on the observation that objects that will never be copied have a lower space requirement \nthan objects that may be copied. The latter must have space reserved into which to copy them. Because \nin an Appel-style generational collector, the reserved space overhead is 100% (half the heap), an object \nshould w be classi.ed as immortal if dead time/lifetime 1 for that object, where dead time is the time \nfrom when the object dies to the end of the program. Figure 1 illustrates this categorization. )=/ it \n* ( . tL1 With these bins, we then use the same classi.cation algorithm as above but with a different \nhomogeneity factor, which we call the combining homogeneity factor, Hc f . We found that it was impor\u00adtant \nto be particularly conservative when combining traces, so we used Hc f =09. 3.2 Testing the Homogeneity \nPremise Pro.le-driven pretenuring is premised on homogeneous object life\u00adtimes at each allocation site. \nPrevious work shows that ML pro\u00adgrams are amenable to a classi.cation of sites as short and long, where \nlong means usually survives one nursery collection [8]. C programs are not homogeneous at each call site, \nbut require the dy\u00adnamic call chain to predict similar classes of lifetimes [4, 14]. We show in this \nsection that the allocation sites in our set of Java pro\u00adgrams have homogeneous lifetimes with respect \nto our new classi\u00ad.cation scheme. We use 3 benchmarks from the SPEC JVM98 suite: 202 jess, 213 javac, \nand 228 jack, plus IBM s pBOB [6], on which SPEC JBB 2000 is based, and health, an object-oriented Java \nversion of the Olden C program that models a health care system [13]. We choose these programs because \nthey exercise the garbage collec\u00adtor. We explicitly exclude other SPEC JVM98 benchmarks such as 201 compress \nbecause they have a low ratio of total heap size to wt wc max live size and thus do not exercise garbage \ncollection. Table 1 contains the total allocation in bytes, maximum live size in bytes, and the ratio \nbetween the two, for each benchmark. Benchmark Live Alloc Alloc/Live jess 4,340,224 493,363,764 113 javac \n12,450,043 651,452,676 52 jack 7,216,975 517,214,752 72 pBOB 36,272,138 678,600,124 18 health (6-128) \n3,503,011 39,679,440 11 Table 1: Benchmark Characteristics: (Live) is maximum live size in bytes, (Alloc) \nis total allocation in bytes. We present two types of results in the remainder of this section. For javac \nand for our combined advice, we illustrate our binning and classi.cations for a number of call sites \nin each. We then present aggregate advice summaries for each benchmark and the actual be\u00adhavior of the \nsite to demonstrate the quality of our advice. Binning and Classi.cation Table 2 shows our per-site bins \nand object classi.cation for javac and our combined advice for the Jalape no build-time system. We include \nthe top 14 sites ranked by their space rental costs, where e space rental is the size lifetime product \nfor each of the objects al\u00adlocated at that site as a percentage of total space rental, and present a \ncumulative total of space rental costs. Clearly, we exclude many sites in this presentation. The low \ncumulative total for space rental demonstrates that there are very many sites contributing to the total \nallocation. We include the number and volume of objects the site allocates, and show the percentage of \nobjects that are binned as short, long, or immortal. Using Ta =02 Hf =0 33 and Hc f =0 9, we show our \nresulting classi.cation. Notice that many allocation sites are homogeneous: the majority of objects at \na site are in a single bin. For some sites, especially in the combined trace, objects are well distributed \namong bins. For javac, we classify many sites as long (l), and in the combined trace, several sites as \nimmortal (i). Thus, we .nd sites to pretenure into the long lived and immortal space. Table 3 summarizes \nthe level of classi.cation accuracy for each of our benchmarks. We classify objects as (short (s), long \n(l), and immortal (i)) on both a per-object and per-site basis. We examine the per-object (exact, indicated \nwith subscript o) and per-site (rep\u00adresentative, indicated with subscript s) decisions for each object \nto establish the level of error in the per site decisions. The nine decision pairs fall into three categories: \nneutral, bad, and good with respect to the non-pretenured status quo. Neutral pre\u00adtenuring advice allocates \nobjects into the nursery (.so ss., .lo ss ., and .io ss.). Bad pretenuring advice allocates objects into \na longer lived region than appropriate (.so ls., .lo is ., and .so is.). Fol\u00adlowing bad advice tends \nto waste space. Good pretenuring advice allocates objects into longer lived regions, but not too long \nlived (.io is ., .lo ls., and .io ls.). Following good advice reduces copy\u00ading without wasting space. \nTable 3 indicates that on average, 44.3% of our advice is good , 52.3% is neutral , and only about 3.4% \nis bad . 4. Methodology This section begins by describing how we use pretenuring advice, then it overviews \nthe Jalape no JVM and the GC toolkit we built for this exploration. We then discuss how we measure and \ncon.gure our system. 4.1 Using Pretenuring Advice Both the generational and Older First collectors have \nthree object insertion points: a primary allocation point (the nursery), a primary copy point (the second \ngeneration and copy zone, respectively), and an allocation point in permanent (immortal) object space. \nOur advice classi.cations map allocations to these insertion points in the obvious way. We have modi.ed \nthe Jalape no compiler to generate an appropri\u00adate allocation sequence when compiling each new bytecode \nif the compiler has pretenuring advice for that bytecode. We provide ad\u00advice to the compiler as a .le \nof .site string advice.pairs, where the site string identi.es a particular bytecode within a class. By \nprovid\u00ading advice to the compiler at build time (when building the Jalape no boot image [1]), allocation \nsites compiled into the boot image, in\u00adcluding the Jalape no run-time system, can pretenure. If advice \nis provided to the compiler at run-time, allocation sites compiled at run-time, including those in the \napplication, can pretenure. The advice part of a pair indicates which of the three insertion points to \nuse. Since the nursery is the default, one needs to pro\u00advide advice only for long-lived and immortal \nsites. In application-speci.c pretenuring, we use self advice [4], i.e., the benchmark executions use \nthe same input when generating and us\u00ading advice. In build-time pretenuring, we use combined advice, \nomitting information from the application to be measured, which is called true advice. Using an advice \n.le is not the only way one might communicate pretenuring advice to a JVM; bytecode rewriting is another \npossi\u00adbility when one does not have access to the JVM internals. BIT is a bytecode modi.cation tool that \nfacilitates annotation of arbi\u00adtrary bytecodes [12]. Similarly, IBM s Jikes Bytecode Toolkit2 al\u00adlows \nbytecode manipulation. Since our pretenuring advice is im\u00adplemented inside Jalape no, we manipulate the \nintermediate repre\u00adsentation directly. Also, for build-time pretenuring, we avoid modi\u00adfying a large \nnumber of Jalape no class .les by using just one simple text .le for all pretenuring advice. 4.2 The \nJalape   no JVM and the GC Toolkit We use the Jalape no JVM for our implementation study [1]. Jala\u00adpe \nno is a high performance JVM written in Java. Because Jalape no uses its own compiler to build itself, \na simple change to the com\u00adpiler gave us pretenuring capability with respect to both the JVM run-timeanduserapplications. \nThecleandesignofJalape nomeans that the addition of pretenuring to Jalape no (beyond the garbage collectors \nand allocators themselves) is limited to writing a sim\u00adple advice .le parser and making the above minor \nchange to the compiler. These changes totaled only a few hundred lines of code. We have developed GCTk, \na new GC toolkit for Jalape no. It is an ef.cient and .exible platform for GC experimentation, that ex\u00adploits \nthe object-orientation of Java and JVM-in-Java property of 2Available at http://www.alphaworks.ibm.com/tech/jikesbt \n javac site 137 3301 objects 465394 145636 volume 9307880 4077808 % space site 13.082 8.727 rental % \ntotal 13.082 21.809 short 55.74 2.64 % bin % long 35.22 77.13 immortal 9.04 20.23 classi.cation s l 3364 \n148676 2378816 5.556 27.365 38.10 51.28 10.62 s 3361 96696 1547136 5.553 32.918 4.85 78.83 16.32 l 3308 \n48328 1159872 3.783 36.701 0.56 54.70 44.74 l 3310 49812 1793232 3.501 40.202 1.33 64.43 34.24 l 3331 \n46924 791408 3.198 43.400 1.10 64.47 34.44 l 3330 40156 1766864 2.734 46.134 1.10 65.09 33.81 l 29 435580 \n14588780 2.256 48.390 93.53 3.61 2.86 s 3327 382616 7652320 2.046 50.436 93.00 4.11 29.0 s 3340 32956 \n763504 1.843 52.279 3.39 81.67 14.94 l 3303 22684 635152 1.670 53.949 4.37 52.81 42.81 l 3339 23980 575520 \n1.519 55.468 1.84 73.91 24.25 l 103 4787 114888 1.491 56.959 5.31 16.94 77.75 i  combined 1992 725186 \n14503720 4.801 4.801 77.79 15.15 7.06 s 1862 106212 1699392 3.595 8.396 65.62 23.03 11.35 s 2442 45537 \n1466549 3.367 11.763 56.74 18.86 24.39 s 2893 515773 19759078 3.358 15.122 51.86 15.62 32.52 s 3266 \n1663676 53687928 3.214 18.336 72.42 26.03 1.55 s 3111 127833 7877744 2.953 21.289 20.15 25.76 54.09 \ns 2333 1191535 38129120 2.398 23.687 69.86 28.38 1.76 s 1727 9813 235512 1.796 25.483 8.75 11.54 79.71 \ns 1377 5461 89956 1.667 27.150 0.09 0.00 99.91 i 3583 5453 567112 1.667 28.818 0.00 0.00 1.00 i 424 \n15489 309780 1.633 30.451 47.22 15.75 37.03 s 2934 38758 775160 1.628 32.079 40.06 32.54 27.40 s 1499 \n5294 460012 1.620 33.699 0.00 0.00 1.00 i 2182 5273 84368 1.610 35.309 0.00 0.00 1.00 i      \n Table 2: Per-site Object Binning and Classi.cation % good % % neutral % % bad% benchmark <io is ><lo \nls ><io ls ><so ss ><lo ss ><io ss ><so ls ><lo is ><so is > jess 41.6 0.1 0.0 47.3 3.9 5.8 0.0 0.4 0.7 \njavac 10.6 37.0 15.5 23.7 8.1 3.1 1.6 0.3 0.2 jack 29.6 7.6 0.8 46.2 7.8 5.6 1.3 0.2 0.9 health 25.5 \n3.5 1.7 42.0 19.5 5.8 1.4 0.3 0.3 pBOB 37.7 3.3 6.8 33.9 4.9 4.0 2.5 6.0 0.9 average 29.0 10.3 5.0 38.6 \n8.9 4.8 1.4 1.4 0.6 Table 3: Per-program Pretenuring Decision Accuracy (weighted by space rental cost) \nJalape no. We have implemented a number of GC algorithms using GCTk and found their performance to be \nsimilar to that of the ex\u00adisting Jalape no GC implementations. Our Appel-style generational collector \nis well tuned and uses a fast address-order write barrier [15]. We extend the algorithm in a straightforward \nway to include an uncollected region (for immortal objects). We recently imple\u00admented the Older First \nGC algorithm [15] using the GCTk, and added an uncollected region to it as well. 4.3 Experimental Setting \nand GC Con.guration We performed our experimental timing runs on a Macintosh Power Mac G4, with two 533 \nMHz processors, 32KB on-chip L1 data and instruction caches, 256KB uni.ed L2 cache, 1MB L3 off-chip cache, \nand 384MB of memory, running PPC Linux 2.4.3. (We used only one processor for our experiments.) As indicated \nin Section 3.1, a time-space trade-off is at the heart of each pretenuring decision. In order to better \nunderstand how that trade-off is played out and to make fair comparisons, we conduct all of our experiments \nwith .xed heap sizes. We express heap size as a function of the minimum heap size for the benchmark in \nques\u00adtion. We de.ne the minimum heap size for a benchmark to be the smallest heap in which the benchmark \ncan run when using a Appel\u00adstyle generational collector without pretenuring. This amount is at least \ntwice the max live size, we determine it experimentally. For the generational algorithm, we collect when \nthe sum of the space consumed by the three allocation regions (nursery, older generation, and permanent \nobject space) and the reserved region reaches the heap size. We collect the older generation, as per \nthe Appel algorithm, when it approaches the size of the reserved re\u00adgion. 5. Results This section presents \nexecution time and other results using gen\u00aderational collection for build-time pretenuring, application-speci.c \npretenuring with our advice and CHL advice, and the combina\u00adtion of build-time and application-speci.c \npretenuring. Finally, we Build time pretenuring Application pretenuring: geometric mean for all benchmarks \n110 % 105 %  Normalized execution time 100 % 95 % 90 % 85 % 80 % Normalized execution time 102 % 101 \n% 100 % 99 % 98 % 75 % 97 % 70 % Heap size relative to minimum heap size (log) Figure 2: Relative Execution \nTime for Build-Time Pre\u00ad tenuring demonstrate that our advice is collector-neutral by showing that it \nimproves a very different collector as well, the Older First collector. In all of the experiments, we \nuse the pretenuring advice parameters Ta =0 2, Hf =0 33, and Hc f =0 9 as described in Section 3.1. We \nuse the times reported by the SPEC JVM98 benchmarks them\u00adselves; health similarly reports its execution \ntime. The pBOB benchmark runs for a .xed period and reports transactions per sec\u00adond, which we invert, \ngiving time per transaction as our measure of time. We always report times normalized with respect to \nthe non-pretenured case. 5.1 Build-Time Pretenuring Build-time advice is true advice; in these experiments \nwe acquired it by combining advice (Section 3.1) from each of the other bench\u00admarks. Because pretenuring \nwill only occur at sites pre-compiled into the Jalape no boot image, build-time advice does not result \nin pretenuring of allocation sites within an application. However, be\u00adcause considerable allocation occurs \nfrom those sites compiled into the boot image (quite notably from the Jalape no optimizing com\u00adpiler), \nbuild-time advice has the distinct advantage of delivering pretenuring bene.ts without requiring the \nuser to pro.le the appli\u00adcation. Figure 2 shows for each benchmark the total performance improve\u00adment \nusing build-time pretenuring normalized with respect to the generational collector without pretenuring. \nIt plots on the x-axis the heap size in multiples of the minimum heap size for 32 points between 1 and \n3.25 on a log scale versus relative execution time. All our results use the same x-axis. Notice that \nthere is a lot of jitter for each benchmark in these graphs. This jitter is present in our raw performance \nresults for each speci.c allocator as well as in the normalized improvement graphs we show. The jitter \nis mostly due to variations in the num\u00adber of collections at a given heap size. Small changes in the \nheap size can trigger collections either right before or after signi.cant object death, which affects \nboth the effectiveness of a given col\u00adlection and the number of collections. This effect illustrates \nthat GC evaluation should, as we do, use many heap con.gurations, not just two or three. Pretenuring \nneither dampens nor exaggerates this behavior, but is subject to it. 96 % Heap size relative to minimum \nheap size (log) Figure 3: Relative Execution Time for Application- Speci.c Pretenuring In some cases, \nbuild-time pretenuring degrades total performance by a few percent, but for most con.gurations, programs \nimprove, sometimes signi.cantly. Improvements tend to decline as the heap size gets larger because the \ncontribution of garbage collection time to total time declines as the heap gets bigger, simply because \nthere are fewer collections. Pretenuring thus has fewer opportunities to improve performance, but pretenuring \nstill achieves an improve\u00adment on average of around 2.5% even for large heaps. All programs improve on \naverage, and for javac and health, with a number a con.gurations improvements are more than 15%. These \nimprove\u00adments are a result of reducing copying in the garbage collector, and the sign.cant decrease in \nGC time improves overall execution time. Section 5.3 presents these measurements as well. 5.2 Application-Speci.c \nPretenuring In this section, we compare our classi.cation scheme to the CHL scheme [8] using application-speci.c \n(self) advice. Given an ap\u00adplication running with a generational collector with a .xed nursery size, \nCHL advice generation .rst measures the proportion of ob\u00adject instances that survive at least one minor \ncollection on a per\u00adallocation site basis. CHL classi.es as long-lived those allocation sites for which \na high proportion survive (we implemented their approach with the same 80% threshold they used). CHL \nthen pre\u00adtenures (allocates) objects created at these sites into the older gen\u00aderation, and allocates \nobjects from all the other allocation sites into the nursery in the usual way. Because of allocation-site \nhomogene\u00adity in ML (which we also observed in Section 3.2 for our Java pro\u00adgrams), their approach is \nfairly robust to the threshold. The biggest difference between the two classi.cation schemes is that \nwe include an immortal category and our collector puts im\u00admortal objects into a region that it never \ncollects. With respect to space rental cost, pretenuring allocates on average 29% of objects into the \nimmortal space (see Table 3), and these decisions are over\u00adwhelmingly correct (because our decisions \nto pretenure to immortal space are so conservative). Since both schemes get the same total heap size \nin our experiments, allocation into the immortal region reduces the portion of the heap the generational \ncollector manages in our scheme (see .gure 5). Figure 3 compares CHL and UMass application-speci.c pretenur\u00ading, \nusing the generational collector, which has a .exible nursery Figure 4: Comparing UMass Application-Speci.c, \nBuild-Time, and Combined Pretenuring  100 % Geometric mean for all benchmarks 95 % 90 % PT non\u00ad 85 \n%e to 80 %elativ 75 % 70 % 65 %Mark/cons ratio r 60 % 55 % 1 1.25 1.5 2 2.5 Heap size relative \nto minimum heap size (log) 3 (a) Relative Mark/Cons Ratios 110 % Geometric mean for all benchmarks 100 \n%  90 %  80 % C time lized G  70 %Norma  60 %  50 % 1 1.25 1.5 2 2.5 Heap size relative to minimum \nheap size (log) 3 (b) Relative Garbage Collection Time 91 % 92 % 93 % 94 % 95 % 96 % 97 % 98 % 99 % 100 \n% 101 % 102 % Normalized execution time 1 1.25 1.5 2 2.5 Heap size relative to live size (log) Geometric \nmean for all benchmarks 3 (c) Relative Execution Time size. The .gure shows the average relative execution \ntime using a geometric mean of our benchmark programs. On average our ad\u00advice performs about as well \nas CHL, except in a tight heap where the impact of immortal objects is highest and our advice performs \nsigni.cantly better. With UMass pretenuring, immortal objects are never copied, and because they do not \nrequire reserved copy space they are twice as space ef.cient as regular heap objects. With CHL these \nobjects typically go into the second generation. Given a tight heap and a .exible nursery size, the amount \nof space available to the nursery is thus reduced, which triggers more full heap collec\u00adtions for CHL. \nThis cost is greater than the savings of avoiding one copy out of the nursery. Our scheme is sometimes \nsubject to the same behavior, but clearly less frequently. With a larger heap, both schemes avoid these \nadditional full heap collections. Because CHL advice generation is speci.c to program, collector, and \ncollector con.guration, it cannot be combined for build-time pretenuring without signi.cant change to \nthe algorithm. We make no further comparisons with CHL because of this drawback and because, as we have \njust illustrated, our three-way classi.cation offers similar performance to the CHL two-way scheme on \naverage and much better performance than CHL for tight heaps.  5.3 Combining Build-Time and Application-Speci.c \nPretenuring This section shows that combining build-time and application\u00adspeci.c pretenuring results \nin better performance than either one alone. For these three pretenuring schemes, we present results \nus\u00ading the geometric mean of the 5 benchmarks for relative mark/cons ratio in Figure 4(a), the geometric \nmean of the relative garbage collection time in Figure 4(b), the geometric mean of the relative execution \ntime in Figure 4(c), and the relative execution time for each benchmark in Figure 6. Figure 4(a) shows \nthe mark/cons ratio for each pretenuring scheme, relative to non-pretenuring. The mark/cons ratio is \nthe ratio of bytes copied ( marked ) to bytes allocated ( cons ). The .gure explains why pretenuring \nworks: it reduces copying. In all cases, pretenur\u00ading reduces the number of objects the collector copies. \nReductions range from 1% to 33%, which is quite signi.cant when minimum heap sizes can be as large 150MB \n(pBOB). Figure 5 offers additional insights. Figure 5(a) shows heap usage over time for a run of the \njavac benchmark without pretenuring, and Figure 5(b) shows it with pretenuring. The top line in each \ngraph shows the total heap consumption immediately before each GC. The second line shows the space consumed \nby the older gen\u00aderation immediately before each GC (both nursery and full heap collections). Finally, \nthe bottom line shows the immortal space consumption (always zero in Figure 5(a)). Note that in pretenuring, \nallocation to immortal space effectively increases the size of the heap because it does not need to reserve \nspace to copy immortals. (Of course the total space available is the same in both cases.) Thus the pretenuring \ngraph s total occupied heap size is larger. This makes the nursery effectively larger. A larger nursery \ndelays the growth of the older generation and defers older generation collections. The lowest points \nin the second line are very similar in both graphs, which shows that pretenuring does not allocate many \nimmortal objects inappropriately (if it does, the second line would be higher for pretenuring). Also \nnote that the shapes of the four troughs in the second lines towards the right side _213_javac, 30MB \nheap, no pretenuring _213_javac, 30MB heap, build &#38; application pretenuring 16 MB  14 MB 14 MB 12 \nMB 12 MB 10 MB 8 MB 6 MB 4 MB 10 MB 8 MB 6 MB 4 MB 2 MB 0 MB Time (allocation) (a) Heap Pro.le Without \nPretenuring 2 MB 0 MB Time (allocation) (b) Heap Pro.le with Build-Time and Application-Spec\u00adi.c Pretenuring \n Figure 5: Heap Usage Over Time By Region for a Run of javac of the .gures. When not pretenuring, the \nbottoms of the troughs are .at, showing that there is no direct allocation to the older gen\u00aderation. \nWith pretenuring, they show an upward slope to the right, indicating direct allocation to the older generation. \nIn summary, pretenuring performs better because it does less copy\u00ading. It reduces copying in two ways: \ndirect allocation into the older spaces avoids copying to promote longer lived objects; and the im\u00admortal \nspace effectively increases the size of the heap, thus reduc\u00ading the number of GCs and the amount of \ncopying. Figure 4(b) shows that the reduction in copying cost signi.cantly and consistently reduces GC \ntime, especially considering the ad\u00advice is true rather than self advice for build-time pretenuring. \nIn particular, combined application and build-time pretenuring im\u00adproves GC time between 20% and 30% \nfor most heap sizes. App\u00adlication-speci.c pretenuring is on average usually the least effec\u00adtive of the \nthree, but it occasionally improves over build-time pre\u00adtenuring, mirroring the mark/cons results. Combined \npretenuring is virtually always the best of the three schemes. Collector time is of course a fraction \nof total execution time and that fraction ranges from around 10% on large heaps to 45% on very small \nheaps for our programs. Figure 4(c) shows that all the pretenuring schemes improve performance. Average \nimprovements are usually between 1% and 4%, but as shown in Figure 6, individ\u00adual programs improve by \nas much as 29%. Figure 6 compares the three schemes with respect to each of our benchmark programs. Notice \nagain that pretenuring improves per\u00adformance more in tighter heaps. For application-speci.c pretenur\u00ading \nand a tight heap, jess, javac, and jack exhibit degradations due to the phenomenon described in Section \n5.2. We get our best im\u00adprovements on javac and health. Tables 1 and 3 show that these programs have \nvery different lifetime characteristics and receive very different pretenuring advice. For javac, pretenuring \nallocates objects with 11% of the space rental cost into the immortal space and 54% into the long-lived \nspace. For health, 26% go into im\u00admortal and 5% into the long-lived space. These differences further \nemphasize the value of a three-way classi.cation.  5.4 Improving Older First Collection Using an Older \nFirst (OF) collector [15], we show the same ad\u00advice can improve this collector as well. The OF collector \norganizes the heap in allocation order. View the heap as a queue; the oldest objects are at the tail \nand the OF allocator inserts newly allocated objects at the head of the queue. OF begins by positioning \nthe win\u00addow of collection at the end of the queue, which contains the oldest objects. During a collection, \nit copies and compacts the survivors in place, returns free blocks to the head of the queue, and then \npo\u00adsitions the window closer to the front of the queue, just past the survivors of the current collection. \nWhen it bumps into the allo\u00adcation point for the youngest objects, it resets the window to the oldest \nobjects. See Stefanovi\u00b4c, et al., for more details [15]. With pretenuring advice, OF puts immortal objects \nin a reserved space that is never collected. OF allocates long-lived objects at the copy point for the \nprevious collection, which gives them the longest possible time before OF will consider them for collection. \nOF continues to put short-lived objects at the head of the queue. As with the generational collector, \nwe use a .xed sized heap, reduced by the space allocated to immortal objects. We set the collection e \nwindow size, g, to 0 3 heap size. Figure 7 shows the geometric mean of the relative performance for all \nour benchmarks, normalized with respect to the OF collector without pretenuring, for build-time, application-speci.c, \nand com\u00adbined pretenuring. Application-speci.c OF pretenuring is almost always a win, except for a number \nof heap sizes around 1.5 where javac sees a degredation of 20% for one heap size and some bench\u00admarks \nsee ocassional degredations as high as 10%. These degreda\u00adtions lead to degradations in the geometric \nmean at around 1.5 and 1.7. In these cases, the degradations are caused by a signi.cant in\u00adcrease in \nthe number of collections, most likely due to overzealous pretenuring. Again, build-time pretenuring \nimproves performance, and additional improvements from combined pretenuring are con\u00adsistent and signi.cant, \nranging from 2% to 23%. SPEC _202_jess SPEC _213_javac 102 % 120 % 115 % 100 %  Normalized execution \ntime Normalized execution time Normalized execution time Normalized execution time 110 % 105 % 100 % \n95 % 90 % 85 % 80 % 75 % 98 % 96 % 94 % 92 % 90 % 88 % 70 % Heap size relative to minimum heap size \n(log) Heap size relative to minimum heap size (log) (a) jess (b) javac SPEC _228_jack Olden health (6, \n128) 106 % 105 % 104 %  100 % 95 % 90 % 85 % 102 % 100 % 98 % 96 % 94 % 92 % 80 % Heap size relative \nto minimum heap size (log) Heap size relative to minimum heap size (log) (c) jack (d) health IBM pBOB \n1.2B4 110 % 108 %  Normalized execution time 106 % 104 % 102 % 100 % 98 % 96 % 94 % 92 % Heap size \nrelative to minimum heap size (log) (e) pBOB   Figure 6: Comparing UMass Application-Speci.c, Build-Time, \nand Combined Pretenuring Execution Time Relative to Non-Pretenuring Older-first pretenuring: geometric \nmean for all benchmarks 105 % 100 % 95 % 90 % 85 % 80 % 75 % Heap size relative to minimum heap size \n(log) Figure 7: Relative Execution Time for Pretenuring with OF Collection Since the OF collector visits \nolder objects more regularly than the generational collector, there is potential for better improvements, \nand it is realized in these results. However, our implementation of the OF collector is currently not \nwell tuned, and does not in\u00adclude key details such as an address order write barrier [15]. These drawbacks \nprevent direct comparisons between the performance of the OF and generational collectors with or without \npretenuring. Indeed, these comparisons are not pertinent to the subject of this work. The key point of \nthis section is that we can use the same ad\u00advice in this vastly different collector and it improves performance \nas well. 6. Related Work We .rst compare our work to previous research on generational garbage collectors, \nobject lifetime prediction, and pretenuring. We then relate it to work on prediction and object segregation \nfor C programs with explicit allocation and freeing. Ungar pioneered the use of generational copying \ngarbage collec\u00adtion to effect quick reclamation of the many short-lived objects in Smalltalk programs \n[17]. Performance studies with a variety of lan\u00adguages demonstrate well tuned generational collector \nperformance ranges from 10% to 40% of the total execution time [18, 20, 19, 5, 16, 8]. Ungar and Jackson \nuse pro.ling to identify what we call long-lived objects in a two generation collector for Smalltalk \n[18, 19]. The older generation in their system is the tenured, permanent space and is never collected. \nThey do not allocate directly into this re\u00adgion, but copy into it objects that survive a given number \nof nurs\u00adery collections. Their system keeps long-lived objects in the nurs\u00adery, repeatedly collecting \nthem to keep from tenuring them, which would result in tenured garbage. They outline a multi-generational \napproach that would copy the long-lived objects fewer times. They notice immortal objects, but since \nthose were insigni.cant in their system, they take no special action. We allocate immortal objects directly \ninto a permanent space. We thus never copy immortal ob\u00adjects. We have the potential never to copy long-lived \nobjects, but we may. Normalized execution time Cheng, et al. (CHL), evaluate pretenuring and lifetime \nprediction for ML programs in the context of a generational collector [8]. Sim\u00adilar to Ungar and Jackson, \nthey divide the heap into two regions: a .xed size nursery and an older generation. They collect the \nnursery on every collection, and both spaces when the entire heap .lls up. They generate pretenuring \nadvice based on pro.les of this collec\u00adtor, and classify call sites as short-lived or long-lived. Most \nobjects are short-lived, and allocation sites are bimodal: either almost all objects are short-lived, \nor all are long lived. Their advice is depen\u00addent on their collection algorithm and the speci.c con.guration, \nwhereas our pretenuring advice is based on two collector-neutral statistics: age and time of death. We \ntherefore can and do use it with different con.gurations of a generational collector, and with an altogether \ndifferent collector, the Older First collector. CHL statically modify those allocation sites where 80% \nor more of objects are long-lived to allocate directly into the older generation, which is collected \nless frequently than the nursery. We allocate instead into three areas: the nursery, the older generation, \nor the permanent space. We never collect our permanent space. At col\u00adlection time, their system must \nscan all pretenured objects because they believed that the write barrier cost for storing pointers from \nthe pretenured objects into the nursery would be prohibitive. We instead perform the write barrier as \nneeded; this cost is very small in our case. The cost of scanning is signi.cant [8, 15], and as they \npoint out, it reduces the effectiveness of pretenuring in their system. We never collect or scan immortal \nobjects, and only collect long\u00adlived objects later when they have had time to die. In summary, our pretenuring \nclassi.cation is more general, and our collectors more fully realize the potential of pretenuring. Most \nimportantly, the more general mechanism we use to gather statistics and generate advice enables our system \nto combine advice from different execu\u00adtions and perform build-time pretenuring, which is not possible \nin their framework. Harris makes dynamic pretenuring decisions for Java programs in the context of a \ntwo generation collector and shows improvements by detecting long-lived objects [10]. This technique \nuses sampling based on over.ow, and thus tends to sample more large objects, and can react to phase changes. \nOur scheme for build-time pretenuring is most similar to this work, and it achieves better performance \nim\u00adprovements due to lower overhead. Pro.ling enables us to achieve even better performance. Our advice \nis neutral with respect to the collector, and we show that we can predict object lifetime based on the \nallocation site whereas Harris work does not investigate how much context is needed to perform prediction. \nFor explicit allocation and deallocation in C programs, Hanson per\u00adforms object segregation of short-lived \nand all other objects on a per allocation site basis with user speci.ed object lifetimes [9]. Barrett \nand Zorn extend Hanson s algorithm by using pro.le data to predict short-lived objects automatically \n[4]. To achieve accu\u00adrate results, their predictor uses the dynamic call chain and object size, whereas \nwe show Java prediction does well with only the al\u00adlocation site. Subsequent work by Siedl and Zorn predicts \nshort\u00adlived objects with only the call chain [14]. In these three studies, a majority of objects are \nshort-lived, and the goal is to group them together to improve locality and thus performance by reusing \nthe same memory quickly. Barrett and Zorn s allocator dynamically chooses between a special area for \nthe short-lived objects, and the default heap. Because we attain accurate prediction for an allo\u00adcation \nsite, we statically indicate where to place each object in the heap, which is cheaper than dynamically \nexamining and hashing on the call chain at each allocation. Since in their context long-lived is the \nconservative assumption, Barrett and Zorn predict short-lived only for call chains where 100% of the \nallocations pro.le to short lived. In a garbage collected system, our conservative prediction is instead \nshort-lived. We also differentiate between long-lived and immortal objects, which they do not. A technique \nsomewhat complementary to pretenuring is large ob\u00adject space (LOS) [7, 19, 11]. One allocates large objects \n(one ex\u00adceeding a chosen size threshold) directly into a non-copying space, effectively applying mark-sweep \ntechniques to them. This avoids copying these objects, and can noticeably improve performance. Our GCTk \ndoes not (yet) support LOS, so we cannot compare here the relative bene.ts of LOS and pretenuring. Some \nJVMs allo\u00adcate large objects directly into older spaces; i.e., they use size as a criterion for pretenuring. \n(These older spaces may also be mark\u00adsweep, so they are effectively implementing pretenuring and LOS.) \nWhile pretenuring large obejcts may be generally helpful in a two\u00adway classi.cation system (a point that \nrequires further analysis), it could be disastrous to pretenure into our immortal space using size as \na criterion. The compress benchmark is an example of this: it allocates and discards large arrays. 7. \nConclusions This paper makes several unique contributions. It offers a new mechanism for collecting and \ncombining pretenuring advice, and a novel and generalizable classi.cation scheme. We show app\u00adlication-speci.c \npretenuring using pro.ling works well for Java. Our per-site classi.cation scheme for Java .nds many \nopportuni\u00adties to pretenure objects and reduces copying, garbage collection time, and total time, sometimes \nsigni.cantly. We are the .rst to demonstrate the effectiveness of build-time pretenuring, and we do so \nusing true advice. Because Jalape no is written in Java for Java, we pro.le it and any libraries we choose \nto include, combine the advice, then build the JVM and libraries with that advice, and ship. User applications \nthus can bene.t from pretenuring without any pro.ling. We further show that the combination of build-time \nand application-speci.c pretenuring offers the best improvements. Acknowledgements We thank Sara Smolensky \nwho did the .rst studies that inspired this work. We also thank John Cavazos, Asjad Khan, and Narendran \nSachindran for their contributions to various incarnations of this work, and our anonymous reviewers \nfor their helpful comments. Finally, we thank the members of the Jalape no team at IBM T.J. Watson Research \nCenter who helped facilitate this research. 8. REFERENCES [1] B. Alpern, D. Attanasio, J. J. Barton, \nM. G. Burke, P.Cheng, J.-D. Choi, A. Cocchi, S. J. Fink, D. Grove, M. Hind, S. F. Hummel, D. Lieber, \nV. Litvinov, M. Mergen, T. Ngo, J. R. Russell, V. Sarkar, M. J. Serrano, J. Shepherd, S. Smith, V. C. \nSreedhar, H. Srinivasan, and J. Whaley. The Jalape no virtual machine. IBM System Journal, 39(1), Feb. \n2000. [2] B. Alpern, D. Attanasio, J. J. Barton, A. Cocchi, S. F. Hummel, D. Lieber, M. Mergen, T. Ngo, \nJ. Shepherd, and S. Smith. Implementing Jalape no in java. In ACM Conference Proceedings on Object Oriented \nProgramming Systems, Languages, and Applications, Denver, CO, Nov. 1999. [3] A. W. Appel. Simple generational \ngarbage collection and fast allocation. Software Practice and Experience, 19(2):171 183, 1989. [4] D. \nA. Barrett and B. Zorn. Using lifetime predictors to improve memory allocation performance. In Proceedings \nof the ACM SIGPLAN 93 Conference on Programming Language Design and Implementation (PLDI), Albuquerque, \nNew Mexico, June 23-25, 1993, pages 187 196, June 1993. [5] D. A. Barrett and B. Zorn. Garbage collection \nusing a dynamic threatening boundary. In Proceedings of the ACM SIGPLAN 95 Conference on Programming \nLanguage Design and Implementation (PLDI), La Jolla, California, June 18-21, 1995, pages 301 314, June \n1995. [6] S. J. Baylor, M. Devarakonda, S. J. Fink, E. Gluzberg, M. Kalantar, P. Muttineni, E. Barsness, \nR. Arora, R. Dimpsey, and S. J. Munroe. Java server benchmarks. IBM System Journal, 39(1), Feb. 2000. \n[7] P. J. Caudill and A. Wirfs-Brock. A third-generation Smalltalk-80 implementation. In OOPSLA 86 ACM \nConference on Object-Oriented Programming Systems, Languages, and Applications, pages 119 130, 1986. \n [8] P. Cheng, R. Harper, and P. Lee. Generational stack collection and pro.le-driven pretenuring. In \nProceedings of the ACM SIGPLAN 98 Conference on Programming Language Design and Implementation (PLDI), \nMontreal, Canada, 17-19 June 1998, pages 162 173, May 1998. [9] D. R. Hanson. Fast allocation and deallocation \nof memory based on object liftimes. Software Practice and Experience, 20(1):5 12, Jan. 1990. [10] T. \nL. Harris. Dynamic adaptive pre-tenuring. In Proceedings of the International Symposium On Memory Management \n(ISMM), Minneapolis, MN U.S.A, 15-16 October, 2000, pages 127 136. ACM, 2000. [11] M. Hicks, L. Hornof, \nJ. T. Moore, and S. Nettles. A study of Large Object Spaces. In ISMM 98 Proceedings of the First International \nSymposium on Memory Management, pages 138 145. ACM, 1998. [12] H. B. Lee and B. G. Zorn. BIT: A tool \nfor instrumenting java bytecodes. In USENIX Symposium on Internet Technologies and Systems, 1997. [13] \nA. Rogers, M. C. Carlisle, J. H. Reppy, and L. J. Hendren. Supporting dynamic data structures on distributed-memory \nmachines. ACM Transactions on Programming Languages and Systems (TOPLAS), 17(2):233 263, Mar. 1995. [14] \nM. L. Seidl and B. G. Zorn. Segregating heap objects by reference behavior and lifetime. In ASPLOS-VIII \nProceedings of the 8th International Conference on Architectural Support for Programming Languages and \nOperating Systems, San Jose, California, October 3-7, 1998, pages 12 23, Nov. 1998. [15] D. Stefanovi\u00b4c, \nK. S. McKinley, and J. E. B. Moss. Age-based garbage collection. In Proceedings of the 1999 ACM SIGPLAN \nConference on Object-Oriented Programming Systems, Languages &#38; Applications (OOPSLA 99), Denver, \nColorado, November 1-5, 1999, pages 379 381, Nov. 1999. [16] D. Tarditi and A. Diwan. Measuring the cost \nof storage management. Lisp and Symbolic Computation, 9(4), Dec. 1996. [17] D. Ungar. Generation scavenging: \nA non-disruptive high performance storage reclamation algorithm. In Proceedings of the ACM SIGSOFT/SIGPLAN \nSoftware Engineering Symposium on Practical Software Development Environments, Pittsburgh, Pennsylvania, \nApril 23-25, 1984., pages 157 167, May 1984. [18] D. Ungar and F. Jackson. Tenuring policies for generation-based \nstorage reclamation. In N. K. Meyrowitz, editor, Conference on Object-Oriented Programming Systems, Languages, \nand Applications (OOPSLA 88), September 25-30, 1988, San Diego, California, Proceedings, pages 1 17, \nNov. 1988. [19] D. Ungar and F. Jackson. An adaptive tenuring policy for generation scavengers. ACM Transactions \non Programming Languages and Systems (TOPLAS), 14(1):1 27, 1992. [20] B. Zorn. Comparative Performance \nEvaluation of Garbage Collection Algorithms. PhD thesis, Computer Science Dept., University of California, \nBerkeley, Dec. 1989. Available as Technical Report UCB/CSD 89/544.   \n\t\t\t", "proc_id": "504282", "abstract": "Pretenuring can reduce copying costs in garbage collectors by allocating long-lived objects into regions that the garbage collector with rarely, if ever, collect. We extend previous work on pretenuring as follows. (1) We produce pretenuring advice that is neutral with respect to the garbage collector algorithm and configuration. We thus can and do combine advice from different applications. We find that predictions using object lifetimes at each allocation site in Java prgroams are accurate, which simplifies the pretenuring implementation. (2) We gather and apply advice to applications and the Jalape&#241;o JVM, a compiler and run-time system for Java written in Java. Our results demonstrate that building combined advice into Jalape&#241;o from different application executions improves performance regardless of the application Jalape&#241;o is compiling and executing. This <i>build-time</i> advice thus gives user applications some benefits of pretenuring without any application profiling. No previous work pretenures in the run-time system. (3) We find that application-only advice also improves performance, but that the combination of build-time and application-specific advice is almost always noticeably better. (4) Our same advice improves the performance of generational and Older First colleciton, illustrating that it is <i>collector neutral</i>.", "authors": [{"name": "Stephen M. Blackburn", "author_profile_id": "81100547435", "affiliation": "Arthitecture and Language Implementation Laboratory, Department of Computer Science, University of Massachusetts, Amherst, MA", "person_id": "P268028", "email_address": "", "orcid_id": ""}, {"name": "Sharad Singhai", "author_profile_id": "81100424832", "affiliation": "Arthitecture and Language Implementation Laboratory, Department of Computer Science, University of Massachusetts, Amherst, MA", "person_id": "PP39042175", "email_address": "", "orcid_id": ""}, {"name": "Matthew Hertz", "author_profile_id": "81100478720", "affiliation": "Arthitecture and Language Implementation Laboratory, Department of Computer Science, University of Massachusetts, Amherst, MA", "person_id": "PP48024764", "email_address": "", "orcid_id": ""}, {"name": "Kathryn S. McKinely", "author_profile_id": "81100402805", "affiliation": "Arthitecture and Language Implementation Laboratory, Department of Computer Science, University of Massachusetts, Amherst, MA", "person_id": "P344302", "email_address": "", "orcid_id": ""}, {"name": "J. Eliot B. Moss", "author_profile_id": "81406593781", "affiliation": "Arthitecture and Language Implementation Laboratory, Department of Computer Science, University of Massachusetts, Amherst, MA", "person_id": "PP39023945", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/504282.504307", "year": "2001", "article_id": "504307", "conference": "OOPSLA", "title": "Pretenuring for Java", "url": "http://dl.acm.org/citation.cfm?id=504307"}