{"article_publication_date": "10-01-2001", "fulltext": "\n Points-to Analysis for Java Using Annotated Constraints Atanas Rountev Ana Milanova Barbara G. Ryder \nDepartment of Computer Science Rutgers University New Brunswick, NJ 08901  {rountev,milanova,ryder}@cs.rutgers.edu \nABSTRACT The goal of points-to analysis for Java is to determine the set of objects pointed to by a reference \nvariable or a reference object .eld. This information has a wide variety of client ap\u00ad plications in \noptimizing compilers and software engineering tools. In this paper we present a points-to analysis for \nJava based on Andersen s points-to analysis for C [5]. We im\u00ad plement the analysis by using a constraint-based \napproach which employs annotated inclusion constraints.Constraint annotations allow us to model precisely \nand e.ciently the semantics of virtual calls and the .ow of values through ob\u00ad ject .elds. By solving \nsystems of annotated inclusion con\u00ad straints, we have been able to perform practical and precise points-to \nanalysis for Java. We evaluate the performance of the analysis on a large set of Java programs. Our experiments \nshow that the anal\u00ad ysis runs in practical time and space. We also show that the points-to solution has \nsigni.cant impact on clients such as object read-write information, call graph construction, virtual \ncall resolution, synchronization removal, and stack\u00ad based object allocation. Our results demonstrate \nthat the analysis is a realistic candidate for a relatively precise, prac\u00ad tical, general-purpose points-to \nanalysis for Java. 1. INTRODUCTION Performance improvement through the use of compiler technology is \nimportant for making Java a viable choice for production-strength software. In addition, the develop\u00adment \nof large Java software systems requires strong support from software engineering tools for program understanding, \nmaintenance, and testing. Both optimizing compilers and software engineering tools employ various static \nanalyses to determine properties of run-time program behavior. One fundamental static analysis is points-to \nanalysis.For Java, points-to analysis determines the set of objects whose ad\u00addresses may be stored in \na given reference variable or refer- Permission to make digital or hard copies of part or all of this \nwork or personal or classroom use is granted without fee provided that copies are not made or distributed \nfor profit or commercial advantage and that copies bear this notice and the full citation on the first \npage. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior \nspecific permission and/or a fee. OOPSLA 01 Tampa Florida USA Copyright ACM 2001 1-58113-335-9/01/10 \n$5.00 ence object .eld. By computing such points-to sets for vari\u00adables and .elds, the analysis constructs \nan abstraction of the run-time memory states of the analyzed program. This abstraction is typically represented \nby one or more points\u00adto graphs. (An example of a points-to graph is shown in Figure 1, which is discussed \nlater.) Points-to analysis enables a variety of other analyses for example, side-e.ect analysis, which \ndetermines the memory locations that may be modi.ed by the execution of a state\u00adment, and def-use analysis, \nwhich identi.es pairs of state\u00adments that set the value of a memory location and subse\u00adquently use that \nvalue. Such analyses are needed by compil\u00aders to perform well-known optimizations such as code mo\u00adtion \nand partial redundancy elimination. These analyses are also important in the context of software engineering \ntools: for example, def-use analysis is needed for program slicing and data-.ow-based testing. Points-to \nanalysis is a crucial prerequisite for employing these analyses and optimizations. In addition to enabling \nother analyses, points-to anal\u00adysis can be used directly in optimizing Java compilers to perform a variety \nof popular optimizations such as virtual call resolution, removal of unnecessary synchronization, and \nstack-based object allocation. Typically, each of these op\u00adtimizations is based on a specialized analysis \ndesigned for the purpose of this speci.c optimization. Thus, compil\u00aders that employ multiple optimizations \nneed to implement many di.erent analyses. In contrast, using a single general\u00adpurpose points-to analysis \ncan enable several di.erent op\u00adtimizations. Furthermore, the cost of the analysis can be amortized across \nmany client optimizations, and the devel\u00adopment e.ort to implement the optimizations can be signif\u00adicantly \nreduced. Because of the many applications of points-to analysis, it is important to investigate approaches \nfor precise and e.\u00adcient computation of points-to information. In this paper we de.ne and evaluate a \npoints-to analysis for Java which is based on Andersen s points-to analysis for C [5], with all extensions \nnecessary to handle object-oriented features. Andersen s analysis is a relatively precise .ow-and con\u00adtext-insensitive \nanalysis1 with cubic worst-case complexity. Despite this complexity, previous work has shown that cer\u00adtain \nconstraint-based techniques allow e.cient implementa\u00adtions of this analysis [14, 31]. We have developed \na constraint\u00ad 1A .ow-insensitive analysis ignores the .ow of control be\u00adtween program points. A context-insensitive \nanalysis does not distinguish between di.erent invocations of a procedure. based approach that extends \nthe previous work with features necessary for points-to analysis for Java. We introduce con\u00adstraint annotations, \nand show how to implement the analysis using annotated inclusion constraints of the form L .a R, where \na is a constraint annotation, and L and R are ex\u00adpressions representing points-to sets. The annotations \nplay two roles in our analysis. Method annotations are used to model precisely and e.ciently the semantics \nof virtual calls, by representing the relationships between a virtual call, its receiver objects, and \nits target methods. Field annotations allow separate tracking of the .ow of values through the dif\u00adferent \n.elds of an object. By using techniques for e.cient representation and resolution of systems of annotated \ninclu\u00adsion constraints, we have been able to perform practical and precise points-to analysis for Java. \nOne disadvantage of Andersen s analysis is the implicit assumption that all code in the program is executable. \nJava programs contain large portions of unused library code; in\u00adcluding such dead code can have negative \ne.ects on analysis cost and precision. In our analysis, we keep track of all methods potentially reachable \nfrom the entry points of the program, and we only analyze such reachable methods. We have implemented \nour analysis and evaluated its per\u00adformance on a large set of Java programs. On 16 out of the 23 data \nprograms, analysis time is less than a minute. Even on large programs, the analysis runs in a few minutes \nand uses less than 180Mb of memory. Our results show that the analysis runs in practical time and space, \nwhich makes it a realistic candidate for a relatively precise general-purpose points-to analysis for \nJava. We have evaluated the impact of the analysis on several of its possible client applications. Our \nresults show very good analysis precision in determining which objects may be read or written by program \nstatements; this object read\u00adwrite information is a prerequisite for clients such as side\u00ade.ect analysis, \ndef-use analysis and dependence analysis. In addition, our measurements show signi.cant improvement in \nthe precision of the program call graph. Through pro.ling experiments, we observe that in many cases \nour analysis allows resolution of the majority of run-time virtual calls. Our experiments also show that \nthe points-to solution can be used to detect a large number of objects that do not need synchronization \nor can be stack-allocated instead of heap\u00adallocated. Contributions. The contributions of our work are \nthe following: We de.ne a general-purpose points-to analysis for Java based on Andersen s points-to \nanalysis for C. We show how to implement the analysis using a constraint-based approach that employs \nannotated inclusion constraints. The implementation models virtual calls and object .elds precisely and \ne.ciently, and only analyzes reach\u00adable methods.  We evaluate the analysis on a large set of Java pro\u00adgrams. \nOur results show that the analysis runs in practical time and space, and has signi.cant impact on object \nread-write information, call graph construc\u00adtion, virtual call resolution, synchronization removal, and \nstack-based object allocation.  class Y {..} p class X {Yf; void set (Y r) this { this.f = r; } static \nvoid main() { s1: Xp=newX(); q s2: Y q = new Y(); p.set(q); } r } Figure 1: Sample program and its points-to \ngraph. Outline. The rest of the paper is organized as follows. Section 2 de.nes the semantics of our \npoints-to analysis. Section 3 discusses the applications of points-to analysis for Java. Section 4 describes \nthe general structure of our an\u00adnotated inclusion constraints, and Section 5 contains the details of \nour constraint-based points-to analysis. The ex\u00adperimental results are presented in Section 6. Section \n7 dis\u00adcusses related work, and Section 8 presents conclusions and future work.  2. SEMANTICS OF POINTS-TO \nANALYSIS FOR JAVA In this section we de.ne the semantics of our points-to analysis for Java; Section \n5 describes the implementation of the analysis with annotated inclusion constraints. The analysis is \nde.ned in terms of three sets. Set R contains all reference variables in the analyzed program (including \nstatic variables). Set O contains names for all objects created at object allocation sites; for each \nallocation site si,we use a separate object name oi . O.Set F contains all instance .elds in program \nclasses. Analysis semantics is expressed as manipulations of points-to graphs containing two kinds of \nedges. Edge (r,oi) . R \u00d7 O shows that reference variable r points to object oi.Edge (.oi,f.,oj) . (O \n\u00d7 F) \u00d7 O shows that .eld f of object oi points to object oj.A sample program and its points-to graph \nare shown in Figure 1. To simplify the presentation, we only discuss the kinds of statements listed below; \nour actual implementation (de\u00adscribed in Section 5) handles the entire language. Direct assignment: \nl=r  Instance .eld write: l.f= r  Instance .eld read: l = r.f  Object creation: l = new C  Virtual \ninvocation: l=r0.m(r1,...,rk)  At a virtual call, name m uniquely identi.es a method in the program. \nThis method is the compile-time target of the call, and is determined based on the declared type of r0 \n[18, Section 15.11.3]. At run time, the invoked method is determined by examining the class of the receiver \nobject and all of its superclasses, and .nding the .rst method that matches the signature and the return \ntype of m [18, Section 15.11.4]. HHj* HHj* H H o1 f o2 f(G,l = new C)= GU{(l,oi)} f(G,l = r)= GU{(l,oi) \n|oi .Pt(G,r)} f(G,l.f = r)= GU{(.oi,f.,oj) |oi .Pt(G,l) =oj .Pt(G,r)} f(G,l = r.f)= GU{(l,oi) |oj .Pt(G,r) \n=oi .Pt(G,.oj,f.)} f(G,l = r0.m(r1,... ,rn)) = GU{resolve(G,m,oi,r1,... ,rn,l) |oi .Pt(G,r0)} resolve(G,m,oi,r1,... \n,rn,l)= let mj(p0,p1,... ,pn,retj )= dispatch(oi,m) in {(p0,oi)}Uf(G,p1 = r1) U... Uf(G,l = retj) Figure \n2: Points-to e.ects of program statements. Analysis semantics is de.ned in terms of rules for adding \nnew edges to points-to graphs. Each rule represents the semantics of a program statement. Figure 2 shows \nthe rules as functions of the form f : PtGraph \u00d7Stmt -PtGraph. The points-to set (i.e., the set of all \nsuccessors) of x in graph G is denoted by Pt(G,x). The solution computed by the analysis is a points-to \ngraph that is the closure of the empty graph under the edge-addition rules. For most statements, the \ne.ects on the points-to graph are straightforward; for example, statement l = r creates new points-to \nedges from l to all objects pointed to by r.For virtual call sites, resolution is performed for every \nreceiver object pointed to by r0. Function dispatch uses the class of the object and the compile-time \ntarget of the call to deter\u00admine the actual method mj invoked at run time. Variables p0,... ,pn are the \nformal parameters of the method; variable p0 corresponds to the implicit parameter this.Variable retj \ncontains the return value of mj. 3. APPLICATIONS OF POINTS-TO ANALYSIS FOR JAVA Using points-to analysis \nin optimizing compilers and soft\u00adware engineering tools has several advantages. A single points-to analysis \ncan enable a wide variety of client ap\u00adplications. The cost of the analysis can be amortized across many \nclients. Once implemented, the analysis can be reused by various clients at no additional development \ncost; such reusability is an important practical advantage. In this sec\u00adtion we brie.y discuss several \nspeci.c applications of points\u00adto analysis for Java. In our experiments, we have evaluated the impact \nof our analysis on some of these applications; the results from these experiments are presented in Section \n6. 3.1 Object Read-Write Information Points-to analysis can be used to determine which objects are read \nand/or written by every program statement. This information is a necessary prerequisite for a variety \nof other analyses. For example, for the purposes of side-e.ect anal\u00adysis, points-to information can be \nused to answer questions like Can statement p.f=x modify the f .eld of any object pointed to by q? . \nPoints-to information is also needed to answer questions like Can statement z=q.f read any mem\u00adory locations \nthat were written by statement p.f=x? ,which are necessary for def-use analysis and dependence analysis. \nAnalyses that require read-write information are used in compilers to perform various optimizations such \nas code mo\u00adtion and partial redundancy elimination. In addition, such analyses play an important role \nin a variety of software engi\u00adneering tools (e.g., in the context of program slicing or data\u00ad.ow-based \ntesting). Practical and precise points-to analysis is crucial for enabling the use of these analyses \nand opti\u00admizations. 3.2 Call Graph Construction and Virtual Call Resolution The points-to solution can \nbe used to determine the tar\u00adget methods of a virtual call by examining the classes of all possible receiver \nobjects. The set of target methods is needed to construct the call graph for the analyzed program; this \ngraph is a prerequisite for all interprocedural analyses and optimizations used in Java compilers and \ntools. If the call has only one target method, it can be resolved by re\u00adplacing the virtual call with \na direct call; this optimization eliminates the run-time overhead of virtual dispatch. In ad\u00addition, \nvirtual call resolution allows subsequent inlining of the target method, potentially enabling additional \noptimiza\u00adtions within the caller. 3.3 Synchronization Removal Synchronization in Java allows safe access \nto shared ob\u00adjects in multi-threaded programs. Each object has an asso\u00adciated lock which is used to ensure \nmutual exclusion. Syn\u00adchronization operations on locks can have considerable run\u00adtime overhead; this \noverhead occurs even in single-threaded programs, because the standard Java libraries are written in \nthread-safe manner. Static analysis can be used to detect properties that al\u00adlow the removal of unnecessary \nsynchronization. For ex\u00adample, no synchronization is necessary for an object that cannot escape its creating \nthread and therefore cannot be accessed by any other thread (i.e., a thread-local object).2 Some escape \nanalyses [10, 7, 8, 36] have been used to iden\u00adtify thread-local objects and to remove the synchronization \nconstructs associated with such objects. Points-to analysis can be used as an alternative to escape analysis \nin detecting thread-local objects. Consider an ob\u00adject oi and suppose that in the points-to graph computed \nby the analysis, oi is not reachable from (i) static (i.e., global) reference variables, or (ii) objects \nof classes that implement interface java.lang.Runnable3 . It can be proven that in this case oi is not \naccessible outside the thread that created it. We can identify such thread-local objects by perform\u00ading \na reachability computation on the points-to graph; this approach is similar to the multithreaded object \nanalysis pro\u00adposed by Aldrich et al. [4]. 2If synchronization operations are removed for objects re\u00adceiving \nwait, notify,or notifyAll messages, the modi\u00ad.ed program may throw IllegalMonitorStateException. This \nproblem can be avoided by maintaining the informa\u00adtion needed by the noti.cation methods without performing \nactual synchronization [28]. 3The run methods of such objects are the starting points of new threads. \n 3.4 Stack Allocation In some cases, an object can be allocated on a method s stack frame rather than \non the heap. This transformation reduces garbage collection overhead and enables additional optimizations \nsuch as object reduction [17]. Similarly to synchronization removal, static analysis can be used to de\u00adtect \nproperties that allow stack-based allocation. For exam\u00adple, stack allocation is possible for an object \nthat may never escape the lifetime of its creating method and therefore can only be accessed during that \nlifetime (i.e., a method\u00adlocal object). Some escape analyses [10, 7, 36] can detect method-local objects; \nclearly, such objects can be allocated on the stack frames of their creating methods. Points-to analysis \ncan be used as an alternative to escape analysis in identifying method-local objects. Suppose that object \noi has been classi.ed as thread-local according to the points-to solution (i.e., oi is not reachable \nfrom static vari\u00adables or from objects implementing Runnable). Also, sup\u00adpose that in the computed points-to \ngraph, oi is not reach\u00adable from the formal parameters or the return variable of the method that created \noi.In this case, it can be proven that oi is method-local; we can identify such method-local objects \nby traversing the points-to graph.  4. SYSTEMS OF ANNOTATED INCLUSION CONSTRAINTS This section describes \nthe general structure of the anno\u00adtated inclusion constraints used in our points-to analysis for Java. \nThe details about the speci.c kinds of constraints and annotations are discussed in Section 5. Previous \nconstraint-based implementations of Andersen s analysis for C [14, 31] employ non-annotated inclusion \ncon\u00adstraints. We have developed a constraint-based approach that extends this previous work by introducing \nconstraint annotations. In our analysis, the annotations are used to model the .ow of values between \na virtual call site and the run-time target methods of the call. In addition, the an\u00adnotations allow \nseparate tracking of di.erent object .elds, which is not possible with the constraints from [14, 31]. \n4.1 Constraint Language We consider annotated set-inclusion constraints of the form L .a R,where a is \nchosen from a given set of annotations. We assume that one element of this set is designated as the empty \nannotation E, and we use L .R to denote constraints labeled with it. L and R are expressions representing \nsets, de.ned by the following grammar: L, R -v |c(v1,... ,vn) |proj (c, i, v) |0 |1 Here v and vi are \nset variables, c(... ) are constructed terms and proj (... ) are projection terms. Each constructed term \nis built from an n-ary constructor c. A constructor is either covariant or contravariant in each of its \narguments; the role of this variance in constraint resolution will be explained shortly. Constructed \nterms may appear on both sides of inclusion relations. 0 and 1 represent the empty set and the universal \nset; they are treated as nullary constructors. Projections of the form proj (c, i, v) are terms used \nto select the i-th argument of any constructed term c(.., vi,..), as de\u00adscribed shortly. Projection terms \nmay appear only on the c(v1, ..., vn) .a c(v1, ..., vn) .  vi .a vi if c is covariant in i for i =1 \n...n vi .a vi if c is contravariant in i for i =1 ...n c(v1, ..., vn) .a proj(c,i, v) . vi .a v if \nc is covariant in i v .a vi if c is contravariant in i Figure 3: Resolution rules for non-atomic con\u00adstraints. \nright-hand side of an inclusion. 4.2 Annotated Constraint Graphs Systems of constraints from the above \nlanguage can be represented as directed multi-graphs. Constraint L .a R is represented by an edge from \nthe node for L to the node for R; the edge is labeled with the annotation a. There could be multiple \nedges between the same pair of nodes, each with a di.erent annotation. The nodes in the graph can be \nclassi.ed as variables, sources, and sinks. Sources are constructed terms that oc\u00adcur on the left-hand \nside of inclusions. Sinks are constructed terms or projections that occur on the right-hand side of inclusions. \nThe graph only contains edges that represent atomic constraints of the following forms: Source .a Var, \nVar .a Var,or Var .a Sink. If the constraint system con\u00adtains a non-atomic constraint, the resolution \nrules from Fig\u00adure 3 are used to generate new atomic constraints, as de\u00adscribed in Section 4.3. We use \nannotated constraint graphs based on the induc\u00adtive form representation [3]. Inductive form is an e.cient \nsparse representation that does not explicitly represent the transitive closure of the constraint graph. \nThe graphs are represented with adjacency lists pred(n)and succ(n) stored at each node n.Edge (n1,n2,a), \nwhere a is an annota\u00adtion, is represented either as a predecessor edge by hav\u00ading .n1,a.. pred(n2), or \nas a successor edge by having .n2,a..succ(n1), but not both. Source .a Var is always a predecessor edge \nand Var .a Sink is always a successor edge. Var .a Var is either a predecessor or a successor edge, basedona.xed \ntotal order T : Vars -N.Edge (v1,v2,a) is a predecessor edge if and only if T(v1) <T(v2). The order function \nis typically based on the order in which variables are created as part of building the constraint system \n[31]. 4.3 Solving Systems of Annotated Constraints Every system of annotated inclusion constraints can \nbe represented by an annotated constraint graph in inductive form. The system is solved by computing \nthe closure of the graph under the following transitive closure rule: 9 . L, a..pred(v) } . R, b..succ(v) \n.L .aob R (Trans)  ; Match(a, b) The closure rule can be applied locally, by examining pred(v)and succ(v). \nThe new transitive constraint is cre\u00adated only if the annotations of the two existing constraints match \nthat is, only if Match(a,b) holds, where Match is a binary predicate on the set of annotations. Intuitively, \nthe Trans rule uses the annotations to .lter out some .ow of values in the constraint system. The Match \npredicate is de.ned as follows: 8 {true if a or b is the empty annotation E Match(a,b)= true if a= b \n: false otherwise The annotation of the new constraint is 8 {a if b= E a0b= b if a= E : E otherwise Intuitively, \nan annotation is propagated until it is matched with another instance of itself, after which the two \ninstances cancel out. If the new constraint generated by the Trans rule is atomic, a new edge is added \nto the graph. Otherwise, the resolution rules from Figure 3 are used to transform the constraint into \nseveral atomic constraints and their corre\u00adsponding edges are added to the graph. The closure of a constraint \ngraph under the Trans rule is the solved inductive form of the corresponding constraint system. The least \nsolution of the system is not explicit in the solved inductive form [3], but is easy to compute by examining \nall predecessors of each variable. For constraint graphs without annotations, the least solution LS(v)for \na variable v is LS(v)= {c(...) |c(...) .pred(v)}ULS(u) u*pred(v) In this case, LS(v) can be computed \nby transitive acyclic traversal of all predecessor edges [14]. For an annotated constraint graph, the \ntraversal is done similarly, but the annotations are used as in rule Trans: LS(v)= {.c(...),a.|.c(...),a..pred(v)}U \n{.c(...),x0y.|.u,x..pred(v) =.c(...),y..LS(u) =Match(x,y)}  5. POINTS-TO ANALYSIS FOR JAVA USING ANNOTATED \nCONSTRAINTS In this section we show how to implement the points\u00adto analysis from Section 2 using annotated \ninclusion con\u00adstraints. Recall that the analysis is de.ned in terms of the set R of all reference variables \nand the set O of names for all objects created at object allocation sites. Every element of RUO is essentially \nan abstract memory location repre\u00adsenting a set of run-time memory locations. To implement our analysis \nwith annotated inclusion con\u00adstraints, we generalize an approach for modeling Andersen s analysis for \nC with non-annotated constraints [14, 31]. For each abstract location x,a set variable vx represents \nthe set of abstract locations pointed to by x. The representation of each location is through a ternary \nconstructor ref which is used to build constructed terms of the form ref (x,vx,vx). The last two arguments \nare the same variable, but with dif\u00adferent variance the overline notation is used to denote a contravariant \nargument. Intuitively, the second argument is .l = r..{vr .vl} -HHj ..{.}.ref ()lo,vvv= new oiil,ooii \n...{..}l.f proj(ref 3)fresh = rv,u,vu,ulf,r ...{..}lr.fproj (ref 2)fresh = v,u,uv,ufl,r Figure4:Constraintsforassignmentstatements. \nH s1: p = new X(); s2: q = new Y(); f p.f=q; r = p.f; r Figure 5: Accessing object .elds. used to read \nthe values of locations pointed to by x, while the last argument is used to update the values of locations \npointed to by x. Given a reference variable r.R and an object variable o.O,constraint ref (o,vo,vo) .vr \nshows that r points to o. We use .eld annotations to model the .ow of values through .elds of objects. \nField annotations are unique identi.ers for all instance .elds de.ned in program classes. For any two \nobject variables o1 and o2,constraint ref (o2,vo2 ,vo2 ) .f vo1 shows that .eld f in object o1 points \nto object o2. 5.1 Constraints for Assignment Statements For every program statement, our analysis generates \nan\u00adnotated inclusion constraints representing the semantics of the statement. Figure 4 shows the constraints \ngenerated for assignment statements. The .rst two generation rules are straightforward. The rule for \nl.f = ruses the .rst constraint to access the points-to set of l, and the second constraint to update \nthe values of .eld f in all objects pointed to by l. Similarly, the last rule uses two constraints to \nread the val\u00adues of .eld f in all objects pointed to by r. 5.1.1 Example Consider the statements in Figure \n5 and their correspond\u00ading points-to graph. After processing the statements, our analysis creates the \nfollowing constraints: ref (o1,vo1 ,vo1 ) .vp ref (o2,vo2 ,vo2 ) .vq vp .proj (ref ,3,u) vq .f u vp .proj \n(ref ,2,w) w .f vr where u and w are fresh variables. For the purpose of this example we assume that \nthe variable order T (de.ned in Section 4.2) is T(vp) <T(vq) <T(vr) <T(vo1 ) <T(vo2 ) < T(u) <T(w). Consider \nthe indirect write in p.f= q.Since we have we can use the Trans rule and the resolution rules from Figure \n3 to generate a new constraint u .vo1 .Thus, vq .f u .vo1 and using rule Trans we generate vq .f vo1 \n. Intuitively, this new constraint shows that some of the values of .eld f in object o1 come from variable \nq.Now we have ref (o2,vo2 ,vo2 ) .vq .f vo1 Since both constraint edges are predecessor edges, we can\u00adnot \napply rule Trans. Still, in the least solution of the constraint system (as de.ned in Section 4.3), we \nhave the constraint ref (o2,vo2 ,vo2 ) .f vo1 , which shows that .eld f of o1 points to o2. To model \nindirect reads, we use the second argument of the ref constructor. For example, for the constraints above \nwe have ref (o1,vo1 ,vo1 ) .vp .proj(ref ,2,w) and therefore vo1 .w .f vr, which through Trans gener\u00adates \nvo1 .f vr. This new constraint shows that the value of r comes from .eld f of object o1.Now we have vq \n.f vo1 .f vr Since the annotations of the two constraints match that is, they represent accesses to the \nsame .eld we generate vq .vr to represent the .ow of values from q to r.Thus, in the least solution of \nthe system we have ref (o2,vo2 ,vo2 ) .vr which shows that reference variable r points to o2.This example \nillustrates how .eld annotations allow us to model the .ow of values through object .elds.  5.2 Handling \nof Virtual Calls For every virtual call in the program, our analysis gener\u00adates a constraint according \nto the following rule: .l= r0.m(r1,... ,rk).. {vr0 .m lam(0,vr1 ,... ,vrk ,vl)} Theruleis based on a \nlam (lambda) constructor. The con\u00adstructor is used to build a term that encapsulates the actual arguments \nand the left-hand-side variable of the call. The annotation on the constraint is a unique identi.er of \nthe compile-time target method of the call. This annotation is used during the analysis to .nd all appropriate \nrun-time target methods. To model the semantics of virtual calls as de.ned in Sec\u00adtion 2, we separately \nperform virtual dispatch for every re\u00adceiver object pointed to by r0. In order to do this e.ciently, \nwe use a precomputed lookup table. For a given receiver object at a virtual call site, the lookup table \nis used to de\u00adtermine the corresponding run-time target method, based on the class of the receiver object.4 \nSuch a table is straight\u00adforward to precompute by analyzing the class hierarchy; the 4Every object is \ntagged with its class; this tag is used when performing lookups. table is essentially a representation \nof the dispatch function from Section 2. Given the class of the receiver object and the unique iden\u00adti.er \nfor the compile-time target of the virtual call, the lookup table returns a lambda term of the form lam(vp0 \n,vp1 ,... ,vpk ,vret) Here pi are the formal parameters of the run-time target method; p0 corresponds \nto the implicit parameter this.We assume that each method has a unique variable ret that is assigned \nthe value returned by the method (this can be achieved by inserting auxiliary assignments in the program \nrepresentation). At the beginning of the analysis, lambda terms of the above form are created for all \nnon-abstract methods in the program and are stored in the lookup table. To model the e.ects of virtual \ncalls, we de.ne an addi\u00adtional closure rule Virtual. This rule encodes the semantics of virtual calls \ndescribed in Section 2 and is used together with the Trans rule to obtain the solved form of the con\u00adstraint \nsystem. Virtual is applied whenever we have two constraints of the form ref (o,vo,vo) .vv .m lam(0,vr1 \n,... ,vrk ,vl) As described in Section 4.2, the edge from the ref term is a predecessor edge, and the \nedge to the lam term is a successor edge. Thus, the Virtual closure rule can be applied locally, by examining \nsets pred(v)and succ(v). Whenever two such constraints are detected, the lookup table is used to .nd \nthe lambda term for the run-time method corresponding to object o and compile-time target method m.The \nresult of applying Virtual are two new constraints: ref (o,vo,vo) . vp0 lam(vp0 ,vp1 ,... ,vpk ,vret \n) . lam(0,vr1 ,... ,vrk ,vl) The .rst constraint creates the association between param\u00adeter this of the \ninvoked method and the receiver object. The second constraint immediately resolves to vri . vpi (for \ni .1) and vret .vl, plus the trivial constraint 0 .vp0 . These new atomic constraints model the .ow of \nvalues from actuals to formals, as well as the .ow of return values to the left-hand side variable l \nused at the call site. 5.2.1 Example Consider the set of statements in Figure 6. For the pur\u00adpose of \nthis example, assume that T(va) <T(vb) <T(vc). Since the declared type of b is B,at call site c1 the \ncompile\u00adtime target method is B.n;thus, we have vb .B.n lam(0,vx) When rule Virtual is applied as shown \nin (1), the lookup for receiver object o2 and compile-time target B.n produces run-time target B.n. The \nresolution with the lam term for B.n creates the two new constraints shown in (1). The declared type \nof c is A,and for callsite c2 we have vc .A.n lam(0,vy). Thus, ref (o2,vo2 ,vo2 ) .vb vb .A.n lam(0,vy) \nwhere the second constraint is obtained through the Trans class A {X n() {... return rA; }} class B extends \nA {X n() {... return rB; }} s1: A a = new A(); s2: B b = new B(); Ac=b; c1: X x = b.n(); c2: X y = c.n(); \nif(...) a=b; c3: X z = a.n(); (1) ref (o2,vo2 ,vo2 ) .vb .B.n lam(0,vx) . {ref (o2,vo2 ,vo2 ) .vB.n.this \n,vrB .vx} (2) ref (o2,vo2 ,vo2 ) .vb .A.n lam(0,vy) . {ref (o2,vo2 ,vo2 ) .vB.n.this ,vrB .vy} (3) ref \n(o1,vo1 ,vo1 ) .va .A.n lam(0,vz) . {ref (o1,vo1 ,vo1 ) .vA.n.this ,vrA .vz} (4) ref (o2,vo2 ,vo2 ) .va \n.A.n lam(0,vz) . {ref (o2,vo2 ,vo2 ) .vB.n.this ,vrB .vz} Figure 6: Example of virtual call resolution. \nrule.5 When applying rule Virtual as shown in (2), the lookup for receiver object o2 and compile-time \ntarget A.n leads to run-time target B.n. The two new constraints which result from the resolution are \nshown in (2). For call site c3, the receiver object can be either o1 or o2.As shown in (3) and (4), separate \nlookup and resolution is performed for each receiver.  5.3 Correctness For every program statement, \nour analysis generates con\u00adstraints representing the semantics of the statement. This initial constraint \nsystem is solved by closing the correspond\u00ading constraint graph under closure rules Trans and Vir\u00adtual.Let \nA. be the solved inductive form of the constraint system. Recall that the least solution of the system \nis not ex\u00adplicit in A. and can be obtained through additional traversal of predecessor edges, as described \nin Section 4.3. Let G. be the points-to graph computed by the algorithm in Section 2. Consider a reference \nvariable r and an object variable o such that (r,o) .G. . It can be proven that the least solution constructed \nfrom A. contains the constraint ref (o,vo,vo) .vr. Similarly, consider two object variables oi and oj \nsuch that (.oi,f.,oj) .G.; it can be proven that the least solution contains ref (oj,voj ,voj ) .f voi \n. The proof of the these claims depends on the following restriction on the variable order T: all variables \nvr,where r.R, should have lower order than the rest of the constraint variables. We enforce this restriction \nas part of building the constraint system. Given this restriction, it can be proven 5Note that if T(vc) \n<T(vb), instead of propagating the lam term to vb we would propagate the ref term to vc. that the least \nsolution of the constraint system represents all points-to pairs from G. [26]. 5.4 Cycle Elimination \nand Projection Merging Cycle elimination [14] and projection merging [31] are two techniques that can \nbe used to reduce the cost of Andersen s analysis for C. We have adapted these techniques to allow us \nto reduce the cost of our points-to analysis for Java. The idea behind cycle elimination is to detect \na set of variables that form a cycle in the constraint graph: v1 .v2 .....vk .v1 Clearly, all such variables \nhave equal solutions and can be replaced with a single variable. Whenever a cycle is detected during \nthe resolution process, one variable from the cycle is chosen as a witness variable, and the rest of \nthe variables are redirected to the witness. This transformation has no e.ect on the computed solution, \nbut can signi.cantly reduce the cost of the analysis. Cycle detection is performed every time a new edge \nis added between two variables vi and vj. The detection algo\u00adrithm essentially performs depth-.rst traversal \nof the con\u00adstraint graph and tries to determine whether vi is reach\u00adable from vj. Cycle detection is \npartial and does not detect all cycles. Nevertheless, for Andersen s analysis for C this technique has \nsigni.cant impact on the running time of the analysis [14]. Cycle elimination cannot be used directly \nfor the anno\u00adtated constraint systems presented in this paper. If we per\u00adformed the standard cycle detection, \nwe would discover cy\u00adcles in which some edges have .eld annotations; however, the variables in such cycles \ndo not have the same solution, and cannot be replaced by a single witness variable. To guarantee the \ncorrectness of our analysis for Java, we use a restricted form of cycle elimination. The cycle detection \nalgorithm is invoked only when a new edge is added be\u00adtween two reference variables that is, when the \nnew edge is (vri ,vrj ), where ri,rj .R. It can be proven that in this case, the detected cycle contains \nonly reference vari\u00adables, and all edges in the cycle have empty annotations. This guarantees that all \nvariables on the cycle have identi\u00adcal points-to sets, and therefore replacing the cycle with a single \nvariable preserves the points-to solution. Projection merging is a technique for reducing redundant edge \nadditions in constraint systems [31]. It combines mul\u00adtiple projection constraints for the same variable \ninto a sin\u00adgle projection constraint. For example, constraints v . proj (c,i,u1)and v .proj (c,i,u2) \nare replaced by v .proj (c,i,w) w .u1 w .u2 where w is a special projection variable. For points-to anal\u00adysis \nfor C, constraints of the form w .ui are represented only as successor edges; this restriction guarantees \na bound on the number of projection variables w. The analysis en\u00adsures the restriction by assigning to \nw a high index in the variable order T [31]. In this case, projection merging is bene.cial because it \nis coupled with cycle elimination. In our annotated constraint systems, projection merging does not interact \nwith cycle elimination. In our case, the high indices from [31] (which necessitate the interaction) are \nnot required. The high indices become unnecessary because the bound on the number of special projection \nvariables is ensured by the variable ordering restriction from Section 5.3. Thus, the special projection \nvariables can be treated simi\u00adlarly to the rest of the variables in the constraint system. This decoupled \nform of projection merging has signi.cant impact on the running time of the analysis for Java. 5.5 Tracking \nReachable Methods Andersen s analysis implicitly assumes that all code in the program is executable. \nSince Java programs heavily use libraries that contain many unused methods, we have aug\u00admented our analysis \nto keep track of reachable methods, in order to avoid analyzing dead code. Thus, we take into ac\u00adcount \nthe e.ects of statements in a method body only if the method has been shown to be reachable from one \nof the entry methods of the program. The set of entry methods contains (i) the main method of the starting \nclass, (ii) the methods in\u00advoked at JVM startup (e.g., initializeSystemClass), and (iii) the class initialization \nmethods <clinit> containing the initializers for static .elds [22, Section 3.9]. During the analysis, \nwe maintain a list of reachable meth\u00adods; whenever a method becomes reachable, all statements in its \nbody are processed and the appropriate constraints are introduced in the constraint system. Any call \nto a construc\u00adtor also generates a corresponding call to the appropriate finalize method. For multi-threaded \nprograms, a call to Thread.start is treated as a call to the corresponding run method. 5.6 Analysis \nImplementation We use the Soot framework (www.sable.mcgill.ca), ver\u00adsion 1.0.0, to process Java bytecode \nand to build a typed intermediate representation [35]. The constraint-based anal\u00adysis uses Bane (Berkeley \nANalysis Engine) [2]. Bane is a toolkit for constructing constraint-based program analyses. The public \ndistribution of Bane (bane.cs.berkeley.edu) contains a constraint-solving engine for non-annotated con\u00adstraints \nthat employs inductive form, cycle elimination, and projection merging. We modi.ed the constraint engine \nto represent and solve systems of annotated constraints. The analysis works on top of the constraint \nengine, by processing newly discovered reachable methods and generating the ap\u00adpropriate constraints. \nThe points-to e.ects of JVM startup code and native methods (for JDK 1.1.8) are encoded in stubs included \nin the analysis input. Dynamic class load\u00ading (e.g., through Class.forName) and re.ection (e.g., calls \nto Class.newInstance) are resolved manually; similar ap\u00adproaches are typical for static whole-program \ncompilers and tools [20, 16, 33, 34].  6. EMPIRICAL RESULTS All experiments were performed on a 360MHz \nSun Ultra\u00ad60 machine with 512Mb physical memory. The reported times are the median values out of three \nruns. We used 23 publicly available data programs, ranging in size from 56Kb to about 1Mb of bytecode. \nWe used programs from the SPEC JVM98 suite, other benchmarks used in previous work on analysis for Java, \nas well as programs from an In\u00adternet archive (www.jars.com) of popular publicly available Java applications. \nTable 1 shows some characteristics of the data programs. Program User Size Whole-program Class (Kb) \nClass Method Stmt proxy 18 56.6 565 3283 58837 compress 22 76.7 568 3316 60010 db 14 70.7 565 3339 60747 \njb-6.1 21 55.6 574 3393 60898 echo 17 66.7 577 3544 62646 raytrace 35 115.9 582 3451 62755 mtrt 35 115.9 \n582 3451 62760 jtar-1.21 64 185.2 618 3583 65112 jlex-1.2.5 25 95.1 578 3381 65437 javacup-0.10 33 127.3 \n581 3564 66463 rabbit-2 52 157.4 615 3770 68277 jack 67 191.5 613 3573 69249 j.ex-1.2.2 54 198.2 608 \n3692 71198 jess 160 454.2 715 3973 71207 mpegaudio 62 176.8 608 3531 71712 jjtree-1.0 72 272.0 620 4078 \n79587 sablecc-2.9 312 532.4 864 5151 82418 javac 182 614.7 730 4470 82947 creature 65 259.7 626 3881 \n83454 mindterm1.1.5 120 461.1 686 4420 90451 soot-1.beta.4 677 1070.4 1214 5669 92521 mu.n-0.9.2 245 \n655.2 824 5253 94030  javacc-1.0 63 502.6 615 4198 Table 1: Characteristics of the data programs. First \ntwo columns show the number and bytecode size of user classes. Last three columns include library classes. \nThe .rst two columns show the number of user (i.e., non\u00adlibrary) classes and their bytecode size. The \nnext three columns show the size of the program, including library classes, after using class hierarchy \nanalysis (CHA) [11] to .lter out irrelevant classes and methods.6 The number of methods is essentially \nthe number of nodes in the call graph computed by CHA. The last column shows the number of statements \nin Soot s intermediate representation. 6.1 Analysis Cost Our .rst set of experiments measured the cost \nof the anal\u00adysis, as shown in Table 2. The .rst two columns show the running time of the analysis and \nthe amount of memory used. For 16 out of the 23 programs, the analysis runs in less than a minute. For \nall programs, the running time is less than six minutes and the memory usage is less than 180Mb. These \nresults show that our analysis is practical in terms of running time and memory usage, as evidenced on \na large set of Java programs. This practicality means that the analysis can be used as a relatively precise \ngeneral-purpose points-to analysis for advanced static compilers and software engineering tools for Java. \nAnalysis cost can be reduced further if the library code is analyzed in advance. This would allow certain \npartial analy\u00adsis information about the Java libraries to be computed once and subsequently used multiple \ntimes for di.erent client pro\u00adgrams. We intend to investigate this approach in our future work. We also \ninvestigated a version of our analysis in which no 6CHA is an inexpensive analysis that determines the \npossi\u00adble targets of a virtual call by examining the class hierarchy of the program. Program Time Memory \nTime-nf Memory-nf (sec) (Mb) (sec) (Mb) proxy 6.5 38.9 29.8 45.1 compress 22.2 45.3 68.4 77.2 db 23.2 \n46.8 63.2 80.7 jb 13.3 40.7 28.1 45.6 echo 41.5 61.8 231.6 184.3 raytrace 26.1 51.2 99.6 100.4 mtrt 26.1 \n49.0 89.7 100.2 jtar 44.7 58.8 125.8 113.3 jlex 17.7 45.7 137.7 83.6 javacup 32.0 54.1 80.5 83.8 rabbit \n27.9 53.3 74.3 82.7 jack 48.7 63.1 5871.4 134.8 j.ex 56.1 73.1 208.6 191.8 jess 41.8 64.9 202.7 207.7 \nmpegaudio 28.1 51.8 227.1 226.3 jjtree 24.6 52.5 57.4 76.0 sablecc 287.2 151.9 815.4 280.9 javac 350.0 \n151.5 396.8 334.1 creature 176.4 101.0 821.4 319.7 mindterm 94.6 95.4 407.7 341.0 soot 239.5 176.4 401.8 \n308.5 mu.n 243.7 163.8 javacc 190.5 125.5 167.8 167.7  Table 2: Running time and memory usage of the \nanalysis (with and without .eld annotations). .eld annotations are used, and therefore individual object \n.elds are not distinguished. The last two columns in Table 2 show the cost of this no-.elds version. \nThe running time is between 88% and 12056% (average 892%, median 384%) of the running time of the original \nanalysis; the memory usage is between 112% and 437% (215% on average). Typically, the no-.elds version \nis signi.cantly more expensive; for one of the larger programs, it even ran out of memory. These re\u00adsults \nshow the importance of distinguishing object .elds: the improved precision produces smaller points-to \nsets, which in turn reduces analysis cost. By using .eld annotations, we have been able to distinguish \nobject .elds in a simple and e.cient manner. 6.2 Object Read-Write Information We performed measurements \nto estimate the potential im\u00adpact of our analysis on clients of object read-write infor\u00admation (e.g., \nside-e.ect analysis and def-use analysis). In particular, we considered all expressions of the form p.f \noc\u00adcuring in statements in reachable methods. For each such indirect access expression,the points-to \nset of p contains all objects that may be read or written by the corresponding statement. More precise \npoints-to analyses produce smaller numbers of accessed objects; this improves the precision and reduces \nthe cost of the clients of the read-write information. Thus, to estimate the potential impact of our \nanalysis, we measured the number of accessed objects for each indirect access expression; similar metrics \nhave been traditionally used for points-to analysis for C. Table 3 shows the distribution of the number \nof accessed objects; each column corresponds to a speci.c range of num\u00adbers. For example, the .rst column \ncorresponds to expres\u00adsions that may only access a single object, while the last column corresponds to \nexpressions that may access 10 or Program proxy compress db jb echo raytrace mtrt jtart jlex javacup \nrabbit jack j.ex jess mpegaudio jjtree sablecc javac creature mindterm soot mu.n javacc 1 53% 57% 56% \n59% 54% 51% 51% 47% 89% 68% 48% 58% 61% 48% 56% 54% 69% 49% 36% 69% 69% 60% 73% 2 18% 12% 12% 20% 15% \n13% 13% 13% 4% 11% 24% 10% 12% 14% 15% 20% 13% 13% 50% 6% 12% 16% 9% 12% 6% 10% 8% 3 4 5 6 9 .10 8% 7% \n8% 6% 12% 6% 5% 8% 14% 7% 6% 5% 7% 4% 5% 5% 9% 8% 4% 10% 12% 6% 10% 8% 8% 10% 9% 13% 2% 2% 2% 1% 5% \n3% 7% 6% 11%5% 6% 6% 8% 5% 4%15% 10% 4% 2% 11% 14% 13% 5% 6% 14%6% 4% 5% 8% 3%10%5% 3% 3% 2%10% 9% 9% \n4%16% 1% 1% 2%10% 8% 7% 2% 8% 2%10%3% 4% 5% 5% 4%10% 4% 3% 7% 4% Table 3: Number of accessed objects \nfor indirect ac\u00adcess expressions. Each column shows the percentage of indirect accesses with a given \nnumber of objects. more objects. Each column shows what percentage of all in\u00addirect access expressions \ncorresponds to the particular range of numbers of accessed objects. The measurements in Table 3 indicate \nthat our analysis produces precise read-write information. Typically, more than half of the indirect \naccesses are resolved to a single object (which is the lower bound for this metric), and on average 81% \nof the accesses are resolved to at most three objects. These results show that the analysis is a promis\u00ading \ncandidate for producing useful read-write information for clients such as (i) aggressive optimizing compilers, \nin which optimizations require precise read-write information, and (ii) software engineering tools, in \nwhich analysis pre\u00adcision is important for reducing the human e.ort spent on program understanding, restructuring, \nand testing. 6.3 Call Graph Construction and Virtual Call Resolution To measure the precision with respect \nto call graph con\u00adstruction and virtual call resolution, we compared our points\u00adto analysis with Rapid \nType Analysis (RTA) [6]. RTA is an inexpensive and widely used analysis for call graph construc\u00adtion. \nIt performs a reachability computation on the call graph generated by CHA; by keeping track of the classes \nthat have been instantiated, RTA computes a more precise call graph than CHA. Both our analysis and RTA \nimprove the call graph com\u00adputed by CHA by identifying sets of methods reachable from the entry points \nof the program; this reachability com\u00adputation reduces the number of nodes in the call graph. For brevity, \nwe summarize this reduction without explicitly showing the number of nodes for each program. The aver\u00adage \nreduction in the number of nodes is 54% for our analysis and 47% for RTA. On average, the call graph \ncomputed by Program (a) Num (b) Resolved (c) Run-time Calls RTA Points-to Monomorphic compress 0 db 10550782 \n0% 100% 100% mtrt 2833913 0% 0% 0% jlex 1336 11.0% 99.9% 100% jack 2663305 5.9% 98.6% 98.6% jess 1511933 \n0.03% 0.3% 50.2% mpegaudio 6528736 0% 0% 0.5% sablecc 1005390 0.1% 36.5% 46.7% javac 20198864 0% 19.2% \n71.0% javacc 44322 0.02% 85.8% 85.9% Table 5: Execution counts for virtual call sites. (a) Total count \nfor CHA-unresolved call sites. (b) Per\u00adcentage due to resolved sites. (c) Percentage due to sites with \na single run-time target. umn (a) in Table 5 shows the total number of invocations of CHA-unresolved \ncall sites. This number is an indicator of the run-time overhead of virtual dispatch, as well as the \nmissed opportunities for performance improvement through inlining. We also measured what percentage of \nthis total number was contributed by call sites that are uniquely re\u00adsolved by RTA and by our analysis. \nThese percentages are shown in column (b) in Table 5; higher percentages indicate higher potential for \nperformance improvement. The results from this pro.ling experiment indicate that RTA has little potential \nfor improving the run-time perfor\u00admance over CHA. Our analysis shows signi.cantly higher potential, and \nfor several programs it allows the resolution of the majority of run-time virtual calls. In addition, \nwe used the pro.le to determine what CHA-unresolved call sites had only one run-time target. Column (c) \nshows the con\u00adtribution of such sites to the total count from column (a). This number is an upper bound \non the number of invoca\u00adtions that could be resolved by a static analysis. By com\u00adparing columns (b) \nand (c), it is clear that in many cases our analysis achieves performance close to the best possible \nperformance.  6.4 Synchronization Removal and Stack Allocation Points-to analysis has a wide variety \nof client applications, including optimizations for removal of unnecessary synchro\u00adnization and for stack-based \nobject allocation. To investi\u00adgate the impact of our analysis on synchronization removal and stack allocation, \nwe identi.ed all object allocation sites that correspond to thread-local and method-local objects, as \ndescribed in Section 3. Figure 7(a) shows what percentage of all allocation sites in reachable methods \nwere identi.ed as thread-local or method-local. Across all programs, the analysis detects a signi.cant \nnum\u00adber of allocation sites for thread-local objects on average, about 48% of all allocation sites. These \nresults indicate that the points-to information can be useful in detecting and eliminating unnecessary \nsynchronization in Java programs. The analysis also discovers a signi.cant number of sites for method-local \nobjects on average, about 29% of all sites. These results suggest that there are many opportunities for \nstack-based object allocation that can be detected with our analysis. Program (a) Removed Targets Points-to \nRTA proxy 8.7 5.8 compress 6.4 2.4 db 6.0 2.2 jb 8.5 5.8 echo 3.4 1.4 raytrace 6.0 2.3 mtrt 6.0 2.3 jtar \n5.3 3.2 jlex 9.3 6.2 javacup 6.3 3.9 rabbit 8.6 4.1 jack 3.0 0.9 j.ex 6.5 3.5 jess 5.7 2.0 mpegaudio \n7.1 2.2 jjtree 8.4 5.9 sablecc 7.1 1.5 javac 2.8 1.1 creature 3.8 2.3 mindterm 2.5 1.3 soot 4.5 1.0 mu.n \n5.7 2.0 javacc 5.0 2.8 Average 5.9 2.9 Table 4: Improvements for CHA-unresolved virtual call sites. (a) \nAverage reduction in the number of target methods per call site. (b) Percentage of uniquely resolved \ncall sites. our analysis has 14% less nodes than the call graph com\u00adputed by RTA. This reduction allows \nsubsequent analyses and optimizations to safely ignore portions of the program. To determine the improvement \nfor call graph edges, we considered call sites that could not be resolved to a sin\u00adgle target method \nby CHA. Let V be the set of all CHA\u00adunresolved call sites that occur in methods identi.ed by our analysis \nas reachable. For our data programs, the size of V is between 7% and 44% (22% on average) of all virtual \ncall sites in reachable methods. For each site from V ,we com\u00adputed the di.erence between the number \nof target methods according to CHA and the number of target methods ac\u00adcording to RTA and our analysis. \nThe average di.erences are shown in the .rst section of Table 4. On average, our analysis removes more \nthan twice as many targets as RTA; this improved precision is bene.cial for reducing the cost and improving \nthe precision of subsequent interprocedural analyses. The second section of Table 4 shows the percentage \nof call sites from V that were resolved to a single target method. Our points-to analysis performs signi.cantly \nbetter than RTA on average, 53% versus 15% of the virtual call sites are resolved. The increased precision \nallows better removal of run-time virtual dispatch and additional method inlining. We performed additional \nexperiments to estimate the po\u00adtential performance impact of analysis precision on virtual call resolution. \nThese experiments used a subset of our data programs for which we had representative input data. For \neach program, we instrumented the user classes (i.e., non\u00adlibrary classes) and measured the number of \ntimes each call site was executed during a pro.le run of the program. Col\u00ad (b) Resolved Call Sites Points-to \n50% 58% 61% 56% 45% 58% 58% 39% 63% 63% 54% 83% 45% 57% 53% 54% 32% 32% 50% 43% 41% 48% 79% 53% RTA 13% \n19% 21% 21% 17% 12% 14% 14% 12% 12% 15% 17% 14% 7% 15% 25% 24% 1% 17% 10% 15% (a) Object allocation sites \n % Thread-local % Method-local 70 60 50 40 30 20 10 0  (b) Run-time objects Program Objects Thread-local \nMethod-local  compress 456 99.3% 39.0% db 154325 0.03% 0.01% mtrt 6457298 99.9% 85.0% jlex 7350 50.9% \n31.6% jack 1340919 86.7% 77.0% jess 7902221 17.9% 17.9% mpegaudio 2025 12.4% 12.4% sablecc 420494 24.9% \n13.7% javac 3738777 27.6% 21.2% javacc 43265 65.7% 45.8%  proxycompressdbjbraytracemtrtjtarjlexjavacuprabbitechojackjflexjessmpegaudiojjtreesableccjavaccreaturemindtermsootmuffinjavacc \nFigure 7: (a) Thread-local and method-local allocation sites. (b) Number of objects created at run time: \ntotal number, percentage of thread-local objects, and percentage of method-local objects. As with virtual \ncall resolution, we performed additional pro.ling experiments to obtain better estimates of the po\u00adtential \nimpact on run-time performance. Using the same set of programs with instrumented user classes and the \nsame data input sets, we measured the number of run-time ob\u00adjects created at each object allocation site. \nThe total num\u00adber of created objects is shown in the .rst column of Fig\u00adure 7(b); the other two columns \nshow what percentage of these objects were identi.ed by our analysis as thread-local or method-local. \nThe results from this experiment indicate that our anal\u00adysis has good potential for improving the run-time \nperfor\u00admance through synchronization removal and stack-based ob\u00adject allocation. The results in Figure \n7(b) are similar to the results obtained through more expensive .ow-and context\u00adsensitive escape analyses \n[10, 36]. Even though direct com\u00adparison with this previous work is not possible (due to dif\u00adferences \nin the infrastructure and the data programs), the results suggest that our analysis may be a viable alternative \nto these more expensive analyses.  7. RELATED WORK Points-to analysis for object references in Java \nis clearly related to pointer analysis for imperative languages such as C. There are various pointer \nanalyses for C with di.erent tradeo.s between cost and precision. The closest related work from this \ncategory are the constraint-based implemen\u00adtations of Andersen s analysis from [14, 31], in which non\u00adannotated \nconstraints are used together with inductive form, cycle elimination, and projection merging. We extend \nthis work by introducing constraint annotations and by changing the constraint representation and the \nresolution procedure to allow points-to analysis for Java. Field annotations are used to track object \n.elds separately; this is not possible with the constraints from [14, 31]. Method annotations al\u00adlow \nus to model the semantics of virtual calls. In addition, we avoid analyzing dead library code by including \na reach\u00adability computation in the analysis. Constraint indices and constraint polarities [15] have been \nused to introduce context-sensitivity in uni.cation-based .ow analysis. This work has similar .avor to \nour use of an\u00adnotations for tracking .ow of values through object .elds. Conceptually, in both cases \nthe goal is to restrict the .ow of values in constraint systems either for uni.cation-based constraints \nin [15], or for inclusion constraints in our case. Recent work [30], which postdates our initial report \n[27], describes a points-to analysis for Java based on Andersen s analysis for C. Analysis cost is higher \nthan ours, which is most likely due to the di.erent kind of constraints employed by this approach. Another \nrecent points-to analysis for Java based on Andersen s analysis is presented in [21], together with several \nanalysis variations. Direct comparison with this work is not possible because it handles the library \ncode in a di.erent manner; based on the size of the analyzed code, our analysis appears to be faster. \nAnother example of points\u00adto analysis for object-oriented languages is due to Chatter\u00adjee et al. [9]. \nThis .ow-and context-sensitive analysis is more precise and more expensive than ours. Points-to anal\u00adyses \nwith di.erent degrees of precision have been proposed in the context of a framework for call graph construction \nin object-oriented languages [19]. The closest to our work is the 1-1-CFA algorithm, which incorporates \na .ow-and context-sensitive points-to analysis. The scalability of the analyses from [19, 9] remains \nunclear; our approach may be a practical alternative to these more expensive analyses. Other related \nanalyses, based on uni.cation techniques, are a context-sensitive alias analysis for synchronization \nremoval due to Ruf [28], and points-to analyses for Java [25, 30, 21] derived from Steensgaard s points-to \nanalysis for C [29]. Class analysis for object-oriented languages computes a set of classes for each \nprogram variable; this set approxi\u00admates the classes of all run-time values for this variable. The traditional \nclient applications of class analysis are call graph construction and virtual call resolution. DeFouw \net al. [12] present a family of practical interprocedural class analyses, ranging from linear to cubic \ncomplexity; the closest to our analysis are the classic 0-CFA and the linear-edge 0-CFA al\u00adgorithms. \nOther work in this area considers more expensive analyses with some degree of context-or .ow-sensitivity \n[23, 1, 24, 13, 19], as well as less precise but inexpensive analyses such as RTA [6, 34, 32]. Comparison \nwith the results from this work is di.cult due to di.erences in language, infras\u00adtructure, and analysis \nparameters (e.g., handling of libraries, dynamic class loading, etc.). There is a large body of work \non synchronization removal and stack-based object allocation [4, 10, 7, 8, 36, 17, 28]. Gay and Steensgaard \n[17] present a uni.cation-based analy\u00adsis for stack allocation. Ruf [28] describes an uni.cation\u00adbased \nalgorithm for synchronization removal. Aldrich et al. [4] propose several approaches for synchronization \nre\u00admoval. Our approach for identifying thread-local objects is similar to the multithreaded object analysis \nfrom [4] (which is based on 1-1-CFA). Previous work on escape analysis for Java [10, 7, 8, 36] also investigates \nsynchronization removal and stack allocation; the scalability of these approaches re\u00admains unclear. In \ncontrast to these specialized analyses, we propose a points-to analysis that can also be used for a va\u00adriety \nof other client applications. 8. CONCLUSIONS AND FUTURE WORK Designing precise and practical points-to \nanalyses is im\u00adportant for enabling a wide variety of popular analyses and optimizations. We de.ne a \npoints-to analysis for Java based on Andersen s points-to analysis for C. We implement the analysis by \nusing a constraint-based approach which em\u00adploys constraint annotations. Method annotations are used \nto model precisely and e.ciently the semantics of virtual calls. Field annotations allow us to distinguish \nbetween dif\u00adferent .elds of an object. On a large set of Java programs, our experiments show that the \ncost of the analysis is practi\u00adcal. We also show that the points-to solution has signi.cant impact on \nobject read-write information, call graph con\u00adstruction, virtual call resolution, synchronization removal, \nand stack-based object allocation. Our results demonstrate that the analysis is a realistic candidate \nfor a relatively precise, practical, general-purpose points-to analysis for ad\u00advanced optimizing compilers \nand software engineering tools for Java. One direction of future work is to investigate techniques for \nfurther reduction of analysis cost. For example, the cost can be reduced if the library code is analyzed \nin advance. This would allow partial analysis information about the Java libraries to be computed once \nand subsequently used for di.erent client programs. Another direction of future work is to investigate \nthe im\u00adpact of the analysis solution on traditional client analyses such as def-use analysis, side-e.ect \nanalysis, and dependence analysis, which in turn are necessary for various optimiza\u00adtions. Such analyses \nand optimizations have been exten\u00adsively investigated in other languages, and will play an in\u00adcreasingly \nimportant role in aggressive optimizing compilers for Java. Finally, it would be interesting to investigate \napplications of points-to analysis in the context of software engineer\u00ading tools for program checking, \nunderstanding, maintenance, and testing. The functionality provided by such tools will be necessary for \nthe development of production-strength Java software systems. 9. ACKNOWLEDGMENTS We would like to thank \nMatthew Arnold, Michael Hind, and the anonymous reviewers for their suggestions for im\u00adproving the content \nand the presentation of this work. This research was supported by NSF grant CCR-9900988. 10. REFERENCES \n[1] O. Agesen. Constraint-based type inference and parametric polymorphism. In Static Analysis Symposium, \nLNCS 864, pages 78 100, 1994. [2] A. Aiken, M. F\u00a8ahndrich, J. Foster, and Z. Su. A toolkit for constructing \ntype-and constraint-based program analyses. In International Workshop on Types in Compilation, 1998. \n [3] A. Aiken and E. Wimmers. Type inclusion constraints and type inference. In Conference on Functional \nProgramming Languages and Computer Architecture, pages 31 41, June 1993. [4] J. Aldrich, C. Chambers, \nE. G. Sirer, and S. Eggers. Static analyses for eliminating unnecessary synchronization from Java programs. \nIn Static Analysis Symposium, LNCS 1694, pages 19 38, 1999. [5] L. Andersen. Program Analysis and Specialization \nfor the C Programming Language.PhD thesis, DIKU, University of Copenhagen, 1994. [6] D. Bacon and P. \nSweeney. Fast static analysis of C++ virtual function calls. In Conference on Object-Oriented Programming \nSystems, Languages, and Applications, pages 324 341, 1996. [7] B. Blanchet. Escape analysis for object-oriented \nlanguages. Applications to Java. In Conference on Object-Oriented Programming Systems, Languages, and \nApplications, pages 20 34, 1999. [8] J. Bogda and U. H\u00a8olzle. Removing unnecessary synchronization in \nJava. In Conference on Object-Oriented Programming Systems, Languages, and Applications, pages 35 46, \n1999. [9] R. Chatterjee, B. G. Ryder, and W. Landi. Relevant context inference. In Symposium on Principles \nof Programming Languages, pages 133 146, 1999. [10] J. Choi, M. Gupta, M. Serrano, V. Sreedhar, and S. \nMidki.. Escape analysis for Java. In Conference on Object-Oriented Programming Systems, Languages, and \nApplications, pages 1 19, 1999. [11] J. Dean, D. Grove, and C. Chambers. Optimizations of object-oriented \nprograms using static class hierarchy analysis. In European Conference on Object-Oriented Programming, \npages 77 101, 1995. [12] G. DeFouw, D. Grove, and C. Chambers. Fast interprocedural class analysis. In \nSymposium on Principles of Programming Languages, pages 222 236, 1998. [13] A. Diwan, J. B. Moss, and \nK. McKinley. Simple and e.ective analysis of statically-typed object-oriented programs. In Conference \non Object-Oriented Programming Systems, Languages, and Applications, pages 292 305, 1996. [14] M. F\u00a8ahndrich, \nJ. Foster, Z. Su, and A. Aiken. Partial online cycle elimination in inclusion constraint graphs. In Conference \non Programming Language Design and Implementation, pages 85 96, 1998. [15] M. F\u00a8ahndrich, J. Rehof, and \nM. Das. Scalable context-sensitive .ow analysis using instantiation constraints. In Conference on Programming \nLanguage Design and Implementation, pages 253 263, 2000. [16] R. Fitzgerald, T. B. Knoblock, E. Ruf, \nB. Steensgaard, and D. Tarditi. Marmot: An optimizing compiler for Java. Software: Practice and Experientce, \n30(3):199 232, Mar. 2000. [17] D. Gay and B. Steensgaard. Fast escape analysis and stack allocation for \nobject-based programs. In International Conference on Compiler Construction, LNCS 1781, 2000. [18] J. \nGosling, B. Joy, and G. Steele. The Java Language Speci.cation. Addison-Wesley, 1996. [19] D. Grove, \nG. DeFouw, J. Dean, and C. Chambers. Call graph construction in object-oriented languages. In Conference \non Object-Oriented Programming Systems, Languages, and Applications, pages 108 124, 1997. [20] IBM Corporation. \nHigh Performance Compiler for Java, 1997. www.alphaWorks.ibm.com/formula. [21] D. Liang, M. Pennings, \nand M. J. Harrold. Extending and evaluating .ow-insensitive and context-insensitive points-to analyses \nfor Java. In Workshop on Program Analysis for Software Tools and Engineering, pages 73 79, 2001. [22] \nT. Lindholm and F. Yellin. The Java Virtual Machine Speci.cation. Addison-Wesley, 1999. [23] J. Palsberg \nand M. Schwartzbach. Object-oriented type inference. In Conference on Object-Oriented Programming Systems, \nLanguages, and Applications, pages 146 161, 1991. [24] J. Plevyak and A. Chien. Precise concrete type \ninference for object-oriented languages. In Conference on Object-Oriented Programming Systems, Languages, \nand Applications, pages 324 340, 1994. [25] C. Raza.mahefa. A study of side-e.ect analyses for Java. \nMaster s thesis, McGill University, Dec. 1999. [26] A. Rountev, A. Milanova, and B. G. Ryder. Points-to \nanalysis for Java based on annotated constraints. Technical Report DCS-TR-428, Rutgers University, Nov. \n2000. [27] A. Rountev, A. Milanova, and B. G. Ryder. Points-to analysis for Java using annotated inclusion \nconstraints. Technical Report DCS-TR-417, Rutgers University, July 2000. (Initial report superseded by \nDCS-TR-428). [28] E. Ruf. E.ective synchronization removal for Java. In Conference on Programming Language \nDesign and Implementation, pages 208 218, 2000. [29] B. Steensgaard. Points-to analysis in almost linear \ntime. In Symposium on Principles of Programming Languages, pages 32 41, 1996. [30] M. Streckenbach and \nG. Snelting. Points-to for Java: A general framework and an emprirical comparison. Technical report, \nU. Passau, Sept. 2000. [31] Z. Su, M. F\u00a8ahndrich, and A. Aiken. Projection merging: Reducing redundancies \nin inclusion constraint graphs. In Symposium on Principles of Programming Languages, pages 81 95, 2000. \n[32] V. Sundaresan, L. Hendren, C. Raza.mahefa, R. Vallee-Rai, P. Lam, E. Gagnon, and C. Godin. Practical \nvirtual method call resolution for Java. In Conference on Object-Oriented Programming Systems, Languages, \nand Applications, pages 264 280, 2000. [33] F. Tip, C. La.ra, P. Sweeney, and D. Streeter. Practical \nexperience with an application extractor for Java. In Conference on Object-Oriented Programming Systems, \nLanguages, and Applications, pages 292 305, 1999. [34] F. Tip and J. Palsberg. Scalable propagation-based \ncall graph construction algorithms. In Conference on Object-Oriented Programming Systems, Languages, \nand Applications, pages 281 293, 2000. [35] R. Vall\u00b4ee-Rai, E. Gagnon, L. Hendren, P. Lam, P. Pominville, \nand V. Sundaresan. Optimizing Java bytecode using the Soot framework: Is it feasible? In International \nConference on Compiler Construction, LNCS 1781, 2000. [36] J. Whaley and M. Rinard. Compositional pointer \nand escape analysis for Java programs. In Conference on Object-Oriented Programming Systems, Languages, \nand Applications, pages 187 206, 1999.   \n\t\t\t", "proc_id": "504282", "abstract": "The goal of point-to analysis for Java is to determine the set of objects pointed by a reference variable or a reference object field. This information has a wide variety of client applications in optimizing compilers and software engineering tools. In this paper we present a point-to analysis for Java based on Andersen's point-to analysis for C [5]. We implement the analysis by using a constraint-based approach which employs <i>annotated inclusion constraints.</i> Constraint annotations allow us model precisely and efficiently the semantics of virtual calls and the flow of values through object fields. By solving systems of annotated inclusion constraints, we have been albe to perform practical and precies points-to analysis for Java", "authors": [{"name": "Atanas Rountev", "author_profile_id": "81100162864", "affiliation": "Department of Computer Science, Rutgers University, New Brunswick, NJ", "person_id": "PP14067180", "email_address": "", "orcid_id": ""}, {"name": "Ana Milanova", "author_profile_id": "81100481541", "affiliation": "Department of Computer Science, Rutgers University, New Brunswick, NJ", "person_id": "PP14168576", "email_address": "", "orcid_id": ""}, {"name": "Barbara G. Ryder", "author_profile_id": "81100632248", "affiliation": "Department of Computer Science, Rutgers University, New Brunswick, NJ", "person_id": "PP14217204", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/504282.504286", "year": "2001", "article_id": "504286", "conference": "OOPSLA", "title": "Points-to analysis for Java using annotated constraints", "url": "http://dl.acm.org/citation.cfm?id=504286"}