{"article_publication_date": "10-01-2001", "fulltext": "\n Ef.cient Subtyping Tests with PQ-Encoding . YOAV ZIBIN JOSEPH (YOSSI) GIL Department of Computer Science \nTechnion Israel Institute of Technology Technion City, Haifa 32000, Israel zyoav tyogi @ cs.technion.ac.il \n Abstract Subtyping tests, i.e., determining whether one type is a subtype of another, are a frequent \noperation during the execution of object\u00adoriented programs. The challenge is in encoding the hierarchy \nin a small space, while simultaneously making sure that subtyping tests have ef.cient implementation. \nWe present a new scheme for encod\u00ading multiple and single inheritance hierarchies, which, in the stan\u00addardized \nhierarchies, reduces the footprint of all previously pub\u00adlished schemes. The scheme is called PQ-encoding \nafter PQ-trees, a data structure previously used in graph theory for .nding the or\u00adderings that satisfy \na collection of constraints. In particular, we show that in the traditional object layout model, the \nextra mem\u00adory requirements for single inheritance hierarchies is zero. In the PQ-encoding subtyping tests \nare constant time, and use only two comparisons. Other than PQ-trees, PQ-encoding uses several novel \noptimization techniques. These techniques are applicable also in improving the performance of other, \npreviously published, encod\u00ading schemes. 1. Introduction One of the basic operations in the run time \nenvironment of object\u00adoriented (OO) programs is a subtype test. Given an object 0and a type b, a subtype \ntest is to determine whetheren=neab(0eu, the type of 0, is a subtype of b, i.e., eis a descendant ofbin \nthe inheri\u00adtance hierarchy. Such tests (also known as type inclusion tests), oc\u00adcur either implicitly \nin type cast operations, e.g., dynamic cast in C++ [32], ?= in EIFFEL [29], or explicitly in the execution \nof dedicated lingual constructs such as JAVA s [2] instanceof, and SMALLTALK s [18] isKindOf: method. \nSubtyping tests are more frequent than one might think. Covari\u00adant overriding of arguments in EIFFEL \nmakes it necessary to make subtyping test in conjunction with calls to procedures which use s Contact \nauthor Contact the authors for patent information Permission to make digital or hard copies of part \nor all of this work or personal or classroom use is granted without fee provided that copies are not \nmade or distributed for profit or commercial advantage and that copies bear this notice and the full \ncitation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to \nlists, requires prior specific permission and/or a fee. OOPSLA 01 Tampa Florida USA Copyright ACM 2001 \n1-58113-335-9/01/10 $5.00  this feature1. The covariance nature of arrays in JAVA renders sub\u00adtyping \ntests necessary in assignments to elements of arrays whose dynamic type is unknown. Consider the following \ncode fragment void f(Object x[]) { x[1] = new A();  f(new B[3]);  It may be a bit surprising that the \nassignment to x[1]in frequires a subtyping test. To understand why, consider the call to function f, \nin which the argument x receives a value of type B[3] (an array of three elements of type B). The function \ncall is legal since type B[3] is a subtype of Object[] (an array of objects). However, the assignment \nx[1] = new A();  is legal only if type Ais a subtype of type B. Otherwise, the runtime environment raises \nan ArrayStoreExceptionexception. Formally, a hierarchy is a partially ordered set (T,h) where Tis a set \nof types2 and his a re.exive, transitive and anti-symmetric subtype relation. If eb,are types, anderhnbholds, \nwe say that they are comparable, that eis a subtype of band that bis a supertype ofe. Given a hierarchy \nbsTa ,hsu, tTptI=f , the subtyping problem is to build a data structure supporting queries of the sorteprhob. \nThe generation of this data structure is called encoding of the hierarchy. The subtyping problem has \nenjoyed considerable attention recently (see e.g., [21, 1, 9, 20, 7, 15, 16, 26, 25, 28, 33, 30]), the \nchallenge being in simultaneously optimizing its four complexity measures: Space Encoding methods associate \ncertain data with each type. We measure the average number of bits per type, also called the encoding \nlength. Instruction count This is the number of machine instructions in the test code, on a certain \nhardware architecture. There are indications [25] that the space consumed by the test code, which can \nappear many times in a program, can dominate  Various mechanisms of static analysis have been proposed \nto elim\u00adinate this requirement, but none of these have been implemented. i The distinction between type, \nclass, interface, signature, etc., as it may occur in various languages does not concern us here. We \nshall refer to all these collectively as types. the encoding length. An encoding is said to be uniform3 \nif there exists an implementation of the test code in which the instruction count does not depend on \nthe size of the hierarchy. Only uniform encodings will interest us. Test time The time complexity of \nthe test code is of major inter\u00adest. Since the test code might contain loops, the time com\u00adplexity may \nnot be constant even in uniform encodings. Our main concern here are constant time encodings (which are \nalways uniform). To improve timing performance, loops of non-constant time encodings may be unrolled, \ngiving rise to non-constant instruction count, without violating the unifor\u00admity condition. (Bit-vector \nencoding, presented in Section 4, is an example of a uniform encoding which is non-constant time.) In \nmost uses of the subtyping lingual constructs, the super\u00adtype b, is known at compile time. The test code \ncan then be specialized, by precomputing values depending on bonly (henceforth denoted by a # pre.x), \nand emitting them as part of the test code. Specialization thus bene.ts both instruc\u00adtion count and test \ntime, and may even reduce the encoding length. Encoding creation time Another important complexity measure \nis the time for generating the actual encoding. This task is usually computationally dif.cult, so different \ncreation algo\u00adrithms have been proposed to the same encoding scheme. These algorithms differ in their \nrunning time and encoding length. The most obvious (uniform) representation as a binary matrix (BM) gives \nconstant subtyping tests, but the encoding length is . This method is useful for small hierarchies and \nis used e.g., for encoding the JAVA interfaces hierarchy4 in CACAO 64-bit JIT compiler [19, 24]. However, \nfor a hierarchy containing 5500 types the total size of the binary matrix is 3.8MB. The BM can be (non-uniformly) \nimplemented using a zero encoding length and Olb( puinstruction count: relying on specialization, the \ntest code for earhnbthen checks whether eis among the possibly Olb( pudescendants of b. More generally, \na non-uniform encoding is tantamount to representing the encoding data structure as part of the test \ncode, and therefore will not interest us. The observation that stands behind the work on subtyping tests \nis that the BM representation is in practice very sparse, and therefore susceptible to massive optimization. \nNevertheless, the number of partially ordered sets (posets) with elements is 2t8hC ne2,), so the representation \nof some posets requires fsb(iubits5. Thus, the en\u00adcoding length isfsb( ou. In other words, for arbitrary \nhierarchies the performance of binary matrix is asymptotically optimal. Let the relation haabe the transitive \nreduction of h, i.e., a minimal relation whose transitive closure is h. More precisely, relation ha is \nde.ned by the condition that eohabif and only if erhaba deoy=-b, and there is nohbcoTsuch that eahnhbhnbt \ndedy=ohly=ob.a The term is borrowed from circuit complexity. A family of circuits for the size dependent \nincarnations of a certain problem is called uniform, if this family can be generated by a single Turing \nmachine. u Krall, personal communication, Feb. 2001 The number of bipartite graphs with elements is clearly \n2e88C ne2 ), and every bipartite graph is also a poset. Then, another obvious solution to the subtyping \nproblem is DAG\u00adencoding that is based on the directed acyclic graph (DAG) de.ned by types as nodes and \nedges from ha. Figure 1 depicts a DAG topology representation of a hierarchy which will serve as the \nrun\u00adning example of this paper. We employ the usual convention that edges are directed from the subtype \nto the supertype, and that types drawn higher in the diagram are considered greater in the subtype relationship. \nThus, G haC and H hA. Figure 1: A small example of a multiple subtyping hierarchy In DAG-encoding, \na list of parents is stored with each type, result\u00ading in total space of b( o+othatuertlbotgs atbits6. \nThe DAG encoding length is therefore bf g++that// pugrsl oegg 1t. Take note that the aver\u00adage number \nof parents, that//, is small. We will see that in the standard benchmark hierarchies, it is always less \nthan 2. Unfortu\u00adnately, a subtyping test in DAG-encoding is Olb( putime. The Closure-encoding presents \nanother obvious point of tradeoff between space and test time. In this encoding, with each type we store \na sorted array of all of its ancestors. Thus, a subtyping test is then implemented using a binary search \nin time Olb(lbotgy pu. The encoding length is bdthut/a pugrsl otgy at. BM-, DAG-and Closure-encoding \nare not very appealing tech\u00adniques. Previous contributions in this .eld included many sophis\u00adticated \nencoding schemes which come close to DAG-encoding in space, while keeping the test time constant or almost \nconstant. An important special case of the problem is single inheritance (SI), which occurs when the \nhierarchy DAG takes a tree or forest topol\u00adogyasmandatedbytherulesoflanguagessuchas SMALLTALK [18] and \nOBJECTIVE-C [12]. The general case of multiple-inheritance (MI), is more dif.cult, and will be our main \nconcern here. Based on PQ-trees [6], a technique for searching an ordering satisfying prescribed constraints, \nour PQ-encoding (PQE) algorithm improves the encoding length of all previous results, in the de facto \nstan\u00addard benchmark hierarchies. Thanks to specialization and other op\u00adtimization techniques, PQE achieves, \nin a standard object layout model, an encoding length of zero for all SI hierarchies and even in some \nMI hierarchies. Yet another demanding constraint is the time for computing the en\u00adcoding. It is essential \nthat a compiler with whole program informa\u00adtion will be able to .nish its computation in a reasonable \ntime. PQE compares favorably to previous results in this respect as well. Outline The remainder of this \narticle is organized as follows. Sec- O Here and henceforth, all logarithms are based two. Hierarchy \na/a hut/a b c Tsolt/a IDL 66 0.98 3.83 8 6 7 15% Laure 295 1.07 8.13 16 11 9 18% Unidraw 613 0.78 3.02 \n9 8 10 4% JDK 1.1 225 1.04 3.17 7 6 8 15% Self 1801 1.02 29.89 40 16 11 9% Ed 434 1.66 7.99 23 10 9 61% \nLOV 436 1.71 8.50 24 9 9 62% Eiffel4 1999 1.28 8.78 39 17 11 46% Geode 1318 1.89 13.99 50 13 11 75% JDK \n1.18 1704 1.10 4.35 16 9 11 18% JDK 1.22 4339 1.19 4.37 17 9 13 22% JDK 1.30 5438 1.17 4.37 19 9 13 21% \nCecil 932 1.21 6.47 23 12 10 33% tion 2 makes some pertinent de.nitions. The data set of the 13 hierarchies \nused in our benchmarking is presented in Section 3. A survey of prior research is the subject of Section \n4. This section de\u00adscribes the slicing technique of partitioning a hierarchy for the pur\u00adpose of subtyping \ntests. The technique is common to many previous algorithms for the problem; it also stands as the basis \nof the PQE algorithm which is described in Section 5. Section 6 presents our new optimization techniques, \nimproving instruction count, test time and encoding length. The penultimate Section 7 presents the results \nof running these algorithms on our benchmark. Finally, some open problems and directions for future research \nare mentioned in Sec\u00adtion 8.  2. De.nitions Given a type ercrT, we de.ne the following sets: dde,sdc,e,n \nd aan{t s{b(eauandatnac,e,sft otr s/b(eau(which are the subtypes and supertypes of e, re\u00adspectively), \nas well as cchaiblbd{r e,nob(eauand p a/r e,nIt s{b(e u(the sets of all immediate subtypes and supertypes \nof e). More precisely, dae sdc,e,n daatnIt s{b(eau)=f{{bbcETot/bsh-e atn c e,sft otr s/b(eau)=f{{bbcETot/erhnb \n(1) c h i lbddr e nob(eau)=f{{bbcETot/bshae p aar e,nIt s{b(eau)=f{{bbcETot/erhab Also for e+cfT, the \nvalue l e,v e,llb(eauis the length in nodes of the longest directed (upgoing) path starting from e. The \nheight of the th hierarchy is the maximal level among all types in T. The k-level of the hierarchy is \nthe set of all types efor which lbe v e,llb(eaue=-k. lbe v e,llb(e u)=o g++maaax {{l e,v e,llb(b{u)tabbcEp \naar e,nIt s{b(eau (2) h e ibgthIt/bsTsu)=omaaax){al e,v e llb(eau)tteacrT (In the above de.nition of \nl e,v e llb(eau, the maximum over an empty set, is de.ned as zero. In other words, nodes without any \nparents are de.ned as being in level 1.) In Figure 1 we have that dae sdc,e,n daatnIt s{bAu)=={ACDFGH \natnac,e,sft oar stbFu)=={ABCF c h i lbddr e nobAu)=={CD p aar e,nIt s{bFu)=={C l e,v e llbFu)=- This \nhierarchy has three levels: with two, three, and four types. The following de.nitions will also become \npertinent: r oIott s/bsTbuh=={/eocrTot)p aar e,nIt s,b(eau)=-0 (3) l e{a{v e,s/bsTbuh=={/eocrTot)c h \ni lbddr e npb(eau)=-0 In our running example we have r oIott s/bsTbu)=={AB l e{a{v e,s{bsTbu)=={FGHI \n 3. Data Set To benchmark the algorithms, we use the 9 multiple inheritance hierarchies used by Eckel \nand Gil [14] in their benchmark of ob\u00adject layout techniques. Three new JAVA hierarchies, and the Cecil \ncompiler hierarchy [10], were added to this benchmark. This data set represents an array of large hierarchies \ndrawn from various OO languages. In particular, the set includes all multiple-inheritance hierarchies \nused in previous studies of encoding schemes [28, 30, 26, 25]. The reader is referred to [14] for the \ndetailed description of these hierarchies. One of the .ndings in [14] is that many topo\u00adlogical properties \nof typical hierarchies are similar to those of bal\u00adanced trees. This makes it possible to .nd more ef.cient \nencoding for hierarchies used in practice. Comparison of different encoding schemes is done over these \n13 hierarchies which have now become a de facto standard benchmark. Some statistical information on our \ndata sets can be found in Ta\u00adble 1. The number of types ranges between 66 and 5,438. In total the 13 \nhierarchies represent over 19,500 types. t httaat  amaaax {{tatn c e,sft otr sab(eau,tataercrT h e \nibgthItrsl oegg at Table 1: Topological properties of hierarchies in our data set We see in that table \nthat the average number of parents, that//, is always less than 2. On the other hand, the average number \nof an\u00adcestors, thut/a , is large. In the Self hierarchy a type has in average almost 30 ancestors! The \nmaximal number of ancestors plays an important factor in the complexity of some of the algorithms. We \nsee that there exists a type in the Geode hierarchy which has 50 an\u00adcestors in total. In comparing the \nheight of the hierarchy with l oeggwe see that the hierarchies are shallow; their height is similar to \nthat of a balanced binary tree. Finally, we can learn a bit more on the topology of inheritance hi\u00aderarchy \nby considering the set To, which can be thought as the MI core of the hierarchy. Formally, a type is \nin the core if it has a de\u00adscendant with more than one parent. Conversely, the set TthhTsois a collection \nof maximal subtrees discovered in a bottom-up search of the hierarchy. It was previously noticed [25] \nthat encoding is easier if the core is considered .rst, and the bottom trees of T+hsToare added to the \nencoding later. In Table 1 we see that in most hierar\u00adchies the core is rather small, typically less \nthan half the number of types. Treating the core and the bottom trees separately will reduce the run \ntime of PQE. 4. Previous Work This section gives an overview of various encoding methods pro\u00adposed in \nthe literature. We describe the data structure used in each such encoding, and how it is deciphered to \nimplement subtyping tests. Little if any attention is devoted to describing the actual gen\u00aderation of \nthe data structure and the theory behind it. Perhaps the most elegant algorithm for encoding is relative \nnumber\u00ading [31] (also called Schubert s numbering) which guarantees both optimal encoding length of rsl \notgy atbits and constant time subtyp\u00ading tests. However, these achievements are only possible in a SI \nhierarchy. For a type bEcaT, let radenote its ordinal (i.e., an in\u00adteger in the range t ,b,b,b{ f) in \na postorder traversal of T. A basic property of postorder traversal is that a r=omaa/x {/rt/erhnbb (4) \nLet aabe de.ned by a a=ommibn {/rtteah-bb (5) Combining (4), (5) with the fact that in postorder traversal \nthe de\u00adscendants of any type are assigned consecutively, we .nd that eahnb iff pp aa r rab (6) Thus, \nin relative numbering, each type eis encoded by an inter\u00adval radrt]as exempli.ed by Figure 2. We argue \nthat since bis known at compile time, the subtyping test code (6) can be special\u00adized by eliminating \nthe memory fetch of constants aaand ra . In doing so, we .nd that the values aaneed not be stored. The \nto\u00adtal encoding length in our improved version of relative numbering is rsl oegy at. Figure 2: Relative \nnumbering in a tree hierarchy Relative numbering is used in CACAO [19, 24] for representing the JAVA \nclass inheritance hierarchy7. (Recall that BM is used in CACAO for the interfaces hierarchy.) Range-compression \n[1], de\u00adscribed below, is a generalization of relative numbering for MI. Cohen s algorithm [11], which \ncan be thought of as a variant of Dijkstra s displays [13], is yet another algorithm initially designed \nfor SI hierarchies, and later generalized by Packed Encoding to f Krall, personal communication, Feb. \n2001 MI. The algorithm, which is implemented as part of the DEC SRC MODULA-3 system [8], relies on hierarchies \nbeing relatively shal\u00adlow, and more so, on types having a small number of ancestors. As Table 1 shows, \nthis is indeed the case even in our MI hierarchies. A type eis allocated with an array rof size l e,v \ne,llb(eau taan c,e,sft oar stb(eau,t (in SI, l e,vee,llb(eau)==tatn c e,sft otr s/b(eau,t), with entries \nfor each bbc aan c,e sft otr s/b(eaucb Speci.cally, bbsoeis stored in location l e,vee,llb(b{uin array \nr. Thus, checking whetherbas+ecan be carried out by checking whether b indeed occurs in location l e,vee,llb(b,uof \narray r. The encoding is optimized by not storing bitself in this location, but rather an id, which is \nunique among all types in its level. Since different levels come in different sizes, some ibd s may require \nfewer bits than others. Typically, an ibdis stored in either a single byte or in a 16 bits word. It is \neven possible to pack several ibd s into a single byte. As a result of this compression the entries of \nr, which are not of equal size, cannot be referenced using ordinary array access operations. We say thatris \na pseudo array, and use the notation r@iinstead ofrari]for denoting array access. Note that if the index \niis known at compile time, then a pseudo-array access is the same as record member selection, and is \nno slower than a non-pseudo array access. Pseudo-arrays are only used, if in all of their indexing operations, \nthe index is known at compile time. Cohen s encoding stores with each type eits level, a==l e,v e,llb(eau, \nits unique id within this level ied, as well as the pseudo array r, such that for each pbbcEatn c e,sft \notr sab(eau, r@aa=ibdab p(7) The test earh=bis carried out by checking that a .aaand then that (7) holds. \nNote thataais known at compile time. An example of the actual encoding is given in Figure 3.  Figure \n3: Cohen s encoding of the tree hierarchy of Figure 2 p The array boundary check ao.aais not elegant. \nWe found that it can be eliminated in the price of allocating globally unique ibd s. Then, it is possible \nto concatenate the arrays, making sure that the largest array is at the end. Even if there is an over.ow \nin the array access rraa], the location found will not contain ibda . Cohen s algorithm was generalized \nto MI by Vitek, Horspool and Krall [25] into what is called Packed Encoding (PE) and Bit-Packed Encoding \n(BPE), which are both constant time methods. A com\u00admon theme to Cohen s algorithm, PE, BPE and our algorithm \nis slicing, in which the set Tis partitioned into disjoint slices (some\u00adtimes called buckets) 8,b,b b,81a. \nFor each slice 81Twe store the en\u00adtire information required to answer queries of the sort earhnb, eacoT \nand blco81T, i.e., queries in which the supertype is drawn from81T. Type ehas a pseudo array rof length \nk, where r@iholds infor\u00admation for slice81T. In essence, we store, in a very compressed for\u00admat, the \nset of descendants of each element in 8aT. The compression is possible since there is a great deal of \nsharing in the descendants set of different members of8aT. PE associates with each type eEcETa unique \ninteger ibdwithin its slicew, so that eis identi.ed by the pairulwibde. Also associ\u00adated with eis a byte \narray r, such that for all bmcoatnac,e,sft otr sab(eau, indexwastores ibdpa, i.e., rrwa]=iedab (8) A \nnecessary and suf.cient condition for erhnbto hold is then (8). It should be clear that no two ancestors \nof ecan be on the same slice. Thus, the number of slices is at least the size of the largest ancestors \nset, which is described in Table 1. Comparing (8) with (7), we see that slices play a role similar to \nthat of levels in Cohen s algorithm. In fact, Cohen s algorithm partitions the hierarchy into h e,i gehIt/bsTbuanti-chains8, \nwhile PE partitions the hierarchy into anti-chains where no two elements in an anti-chain have a common \ndescendant. Fall [15], who observed that this tech\u00adnique might be used for subtyping tests, noted that \nit is NP-hard to .nd a minimal such partition, and stopped short of .nding a con\u00adstant time subtyping \ntest. The heuristic suggested in [25] along with the constant time subtype test made PE viable. PE constrains \neach slice to a maximum of 255 types, so that ied can always be represented by a single byte. The encoding \nlength is thenwek, where kis the number of slices. The inventors of PE observed that kis usually the \nmaximal number of ancestors unless MI is heavily used. Figure 4: PE representation of the hierarchy \nof Figure 1 Consider Figure 4 for an example of PE representation of the hierar\u00adchy of Figure 1. The \ntypes of the hierarchy are partitioned into .ve different slices: 8=h{A , 8i=h{B , 8a=h{D , 8u=n{CE , \nand 84=s{FGHI . This is the smallest possible number of slices, since type F (for example) has .ve ancestors. \n An anti-chain is a set of types, where no two types are comparable. Clearly, each level is an anti-chain. \n The only difference between BPE and PE is that BPE permits two slices or more to be represented within \na single byte. Thus, in BPE ris a pseudo array, and the array access in (8) becomes a pseudo array access: \np r@wa=iedab (9) Starting from Figure 4 we can represent slices 8, 8iand 8ausing a single bit,8uusing \ntwo bits, and 84in three bits, for a total of seven bits, which can .t into a single byte. Bit-vector \nencoding is one of the most explored directions in prior art. In this scheme, each type eis encoded as \na vector v e,cof k bits. If vee,cri]=ethen we say that ehas gene i. Let \u00a2hb(eaube the set of genes of \ne. Relation eahybholds iff \u00a2hb(eaumLn\u00a2)b(b,u, which can be easily checked by masking v e,caagainst v \ne,c, speci.cally, applying the test: a v e,caa v e,c=-v e,cb (10) Figure 5 gives an example of bit-vector \nencoding of the hierarchy of Figure 1.  Figure 5: Bit-vector encoding of the hierarchy of Figure 1. \n(In each type we only write the genes it adds to its parents.) Bit-vector encoding effectively embeds \nthe hierarchy in the lattice of subsets of {e {b,b b,k. It is always possible to do so by set\u00adting k \n=oand in letting vee,cbe the row of the BM which corre\u00adsponds to e. A simple counting argument shows \nthat kmust depend on the size of the hierarchy. Hence, bit-vector encoding is non\u00adconstant time, but \nit is uniform. For ef.ciency reasons, the implicit loop in (10) is unrolled, giving rise to a non-constant \ninstruction count. The challenge is in .nding the minimal kfor which such an em\u00adbedding of the hierarchy \nin a lattice is possible. The problem is NP-hard [20], but several good heuristics were proposed, including \nKaci, Boyer, Lincoln, and Nasr [21] work, Caseau s Compact Hier\u00adarchical Encoding [9], later improved \nby Habib, Caseau, Nourine and Raynaud [28]. Currently, Near Optimal Hierarchical Encoding (NHE) due to \nKrall, Vitek and Hoorspool [26], is the best bit vector encoding. It is only natural to ask then whether \nit is possible to promise con\u00adstant encoding length, while maintaining uniformity and almost constant \ntime. An af.rmative answer to this question was given by Agrawal, Borgida and Jagadish [1] in their range-compression \nencoding which generalizes relative numbering. Range compres\u00adsion encodes each type bas an integer ibda, \nwith its ordinal in a postorder scan of a certain spanning forest of the hierarchy. Then, the set ibb(b{uof \nibd s of the descendants of b, ibb(b{ue=={/ibdtteacEdae,sdc,e n d aanIt s{b(b{u(11) is represented by \nan array of consecutive disjoint intervals raa@e dra@ ]/raa@2{ra@2]{b b,b, {raa@kab(b{uc dra@kab(b{u]b \nThus, eah-bpiff paa@iibdra@i (12) holds for some i, ikab(b{u. In SI, all descendants of a type are assigned \nconsecutive numbering in a postorder traversal, and therefore the set (11) can be represented using a \nsingle interval. The encoding then degenerates to relative numbering. Figure 6 gives a range-compression \nencoding of the hierarchy of Figure 1. We have for example ibbBu)=f{e c2Id c5Id7Iwd9 which can be represented \nas two intervals rt]and r5I9]. Thus, aB = {e c5rB =={/ d9and k1bBue=+2.  for each type ewe store an \ninterval radrt]and a pseudo array ibd, such that eahnbiff pp aaibd@warab (13) Since bis known at compile \ntime, testing (13) requires exactly the same number of RISC instructions as relative numbering (6). Also, \nsince (13) is similar to boundaries check in an array access, it may be further optimized on architecture \nwith dedicated instructions for this kind of check. Figure 7 describes a PQE representation of our running \nexample. Note that the encoding uses only one slice. Figure 7: PQ-encoding of the hierarchy of Figure \n1 A slice 8+.oTin PQE is a set of types, maximal with respect to the property that there is an ordering \nTof Tsuch that all descendants of any efca8occur consecutively in T. This property makes is possible \nto represent the set of all descendants of eusing merely two integers, as required by (13). Figure 6: \nRange-compression encoding of the hierarchy of Fig\u00adure 1. (Edges of the spanning forest are in bold.) \nExamining (12) we see that only iedhas to be stored for a type e, since everything else is specialized \ninto the subtyping test site. The specialization reduces the encoding length to rtlbotgy at, but at a \nprice of increasing the instruction count from constant to k1b(b,u, which can be in the order of . In \nall of our hierarchies however, the average kab(b{uwas always less than 2. The maximal kab(b{uy=o5e5was \nfound in the Geode hierarchy. The usual straightforward implementation of range compression re\u00adquires \nOlblkab(b{udutime. If k1b(b,uis large then a binary search on (12) reduces the time to Olb(lbotgskab(b{udu. \nNote that this faster implementa\u00adtion does nothing to improve the instruction count in the specialized \nimplementation which remains fsblkab(b{udu. Other non-constant encoding techniques were used in large \ndata\u00adand knowledge-bases, e.g., modulation techniques [21, 15], sparse terms encoding [16], and representation \nusing union of interval or\u00adders [7]. The common objective is a small average, rather than worst-case, \ntime for testing, which may be considered unsuitable for object oriented applications.  5. PQ-Encoding \nThis section describes PQE, an encoding scheme which achieves the smallest space requirements among all \npreviously published al\u00adgorithms. PQE combines the ideas of relative numbering with slic\u00ading as used \nin PE and BPE. Each type ebelongs in a slice w. Also, The name PQ-encoding is derived from the main tool \nused in .nd\u00ading these maximal slices: PQ-trees. This data structure is the inven\u00adtion of Booth and Leuker \n[6] who used it to test for the consecutive 1 s property in binary matrices of size reiswand in time \nO(k8+lr +rw) where kis the number of 1 s in the matrix. Their result gave rise to the .rst linear time \nalgorithm for recognizing interval graphs. Later, PQ-trees were used for other graph-theoretical problems, \nsuch as on-line planarity testing [3, 4] and maximum planar embeddings [5, 22, 23]. There are three \nkinds of a nodes in a PQ-tree: a leaf which rep\u00adresents a member of a given set U,a Q-node which represents \nthe constraint that all of its children must occur in the order they occur in the tree or in reverse \norder, and a P-node which speci\u00ad.es that its children must occur together, but in any order. As a whole, \na PQ-treeprepresents a subset of the orderings of U, de\u00adnoted by c oen sdi sft e,nItab(puu. The ordering \nof Uobtained by a DFS traversal ofp, is denoted ftr otn{t i e rab(puu. Two transformations ofp preserve \nc,otn sdi sft e,nIt/b(puu: swapping any two children of a P-node, and reversing the order of the children \nof a Q-node. PQ-trees p and piare equivalent (p=opi) if pican be reached frompiby a series of these transformations. \nThus, c,otn sdi sft e,nIt/b(puu)=={efer oenIt i e rab(pou)tapo=opa}(14) The universal PQ-tree, denoted \npu , has a P-node as a root and a leaf for every member of U. Let bbe a collection of subsets of a set \nU, i.e., b<. 2Iu, and lettablbhube the collection (which might be empty) of all orderingsT of Usuch that \nthe members of each imcdboccur consecutively in T. THEOREM 5.1 (BOOTH-LEUKER (1976)). For every collec\u00adtion \nof constraints bthere exists a PQ-tree p, and for every tree pthere exists a collection of constraints \nbsuch that tablbhu)=oc,oenasdi sft e,nIttb(puucb Constructively, the tree pcan be generated from bby \nletting pf+ p and making the procedure call reduce(p,i) for each iocEb. Procedure reduce(p,i) .rst checks \nwhether there is apIo, pIoh=op, such that the elements of iappear consecutively in ftr otn{t i e rab(pou. \nThe procedure aborts if no such pois found. Pro\u00adcedure reduce then conducts a bottom up traversal of \nthe nodes of p. At each step, one of standard eleven PQ-tree transformations is applied, until all elements \nof iappear consecutively in all con\u00adsistent orderings. The time complexity is Olb tiatu. Algorithm 1 \nshows how the actual construction of the encoding is carried out. At the termination of the .rst outer \nloop (lines 3 9), the PQ-treesd)r] {b,b{b, cder\u00a3gu+ ]represent the\u00a3gu+slices generated by the algorithm. \nThen, all that remains is to assign unique ibd s within each slice, and to compute the ibd s of the right-most \nand left-most ibd s among the descendants of each type within each slice. The time complexity is Oabfbs\u00a3sun \n/u,thutu. The order at which types are inserted into PQ-trees in line 3 is un\u00adspeci.ed. This line is \nthe main source of non-determinism in our algorithm. After having tried several traversal orders, including \na random one, we concluded that the differences in the encoding length is small. It appears however that \nthe best results are obtained by a reverse topological-order in which the leaves with the largest number \nof ancestors are visited .rst. 1: der]+ pu // dis an array of the slices (represented as PQ-trees) // \ncreated so far. 2: \u00a3a+=// The index of the .rst unused PQ-tree in d. 3: For all ercrTdo // Find a PQ-tree \nconsistent with type e. 4: For w =o e {b,b b, f\u00a3do 5: reduce(derw],dae,sdc e,n daatnIt s b(eau)  6: \nexit loop if reduce succeeded 7: w+xw 8: If s= \u00a3then // Start a new universal PQ-tree 9: \u00a3a+<\u00a3e+o; der\u00a3]+(p \n10: For w =o e {b,b,bf\u00a3sundo // Assign unique ied s 11: ibdm+=// The .rst unused iedin the slicederw]. \n12: For all ercoftr otn{t i e rablderw]udo 13: ibd@w + ibd; ibdm+(ibds+p 14: For all ercrTado // Assign \nan interval to each type e 15: Dh+l{{ibd@wtabbc dde,sdc,e,n d aan{t s{b(eau; 16: a+(mmi npblDEu; r+ maa/xablDEu \nAlgorithm 1: PQE algorithm for a hierarchy bsTa {hsu We next describe several optimizations techniques \ntargeted at im\u00adproving various complexity measures of the encoding. The .rst such optimization reduces \nthe encoding length as gener\u00adated by Algorithm 1. Let h=={{bIt :{ercE8s. bshneh be the set of descendants \nof a slice 8. Then, t8attt. For h some of the smaller slices we might even have that ttis close to .The \nlength optimization relies on the observation that in these h cases it is possible to reuse ibd s while \nnumbering the types in . The critical point to note is that two types bdbichneed to be assigned distinct \nidenti.ers only if there is a type eecn8, such that bc-dde,sdc,e,n d aan{t s{b(eau, while bicodae,sdc,e \nn d aanIt s{b(e u y(or vice versa). Phrased differently, 8partitions Tinto equivalence classes, such \nthat types band biare in the same equivalence class if atnac,e,sft oar sab(bu ny8n=-atn c e,sft otr s/b(biu \nns88b(15)h We call this the 8-partitioning of T. Note that Esod= T=his a single equivalence class, which \ncan be assigned the special ied0, which is not contained in any interval. The minimal range (number of \ndifferent ibd s) needed to encode a slice 8is exactly the number of equivalence classes in 8-partitioning \nof T. We next show that the minimal range is always lower than twice the size of a slice. Now, PQE ensures \nthat for every eacE8there is an interval iwhich consists of dde,sdc,e,n d atnIt s{b(eau. These t8)tintervals \npartition the types in hinto at most 2dt8)t ut segments, such that all types in the same segment can \nreceive the same ibd. h Consider for example Figure 8 in which the types in were ini\u00adtially numbered \n{ ,b,b{b, , {5. Intervals i, iiand iadrawn in the .gure partitionhinto 5I=+2sI)unsegments. This is the \nmaximal h possible number of segments, since every type inmust belong to at least one interval. D. \nFigure 8: Reducing the range needed for PQE We have then THEOREM 5.2. Let 8+.oTbe a slice obtained by \nPQE. Then, the integral range required for numbering Tis at most mmi npbl2dt8)t atTptucb Every equivalence \nclass, except Eo, is a collection of segments, which proved Theorem 5.2. For example, E ob=a{I e c2I \n{ {,E= G , Ei=Gi, Ea=Gag5G4, and Eu=Gu . In all hierarchies in the data set, we found that all slices, \nexcept the .rst, were of size 128 or less. Thus, thanks to Theorem 5.2, ied can be represented as a byte \narray, with each slice adding a single byte to the encoding length. The .rst slice receives some special \nhandling as will be described below in Section 6. It is possible to modify the PQE algorithm to ensure \nthat all but one slice has their range bounded by 255. An application of reduce (line 5 in Algorithm \n1) to a PQ-tree (other than the .rst) is simply revoked if the range required for numbering exceeds 255.9 \nStoring the current required numbering range of a PQ-tree, and updating it with each reduce is straightforward. \nOne can also manage the equivalence classes of all slices incrementally in Olb thututotal time. The second \noptimization reduces the time of running Algorithm 1 by pruning in a preprocessing stage all bottom-trees \n(see Section 3); a lighter machinery is then used to produce the encoding of those. After the PQ-encoding \nof the core is generated, relative numbering of each bottom-tree is inserted into the interval of its \nroot, after an appropriate expansion of this interval. (See Figure 9 for an illustra\u00adtion of this process.). \n lx rx II ly ry idx lz rz  lw rw ln rn Figure 9: Inserting a bottom-tree into an existing PQ-encoding \nThe third optimization, heterogeneous encoding, is an encoding\u00adlength optimization technique. Recall \nthat in BM-encoding each type adds exactly one bit to the encoding of all other types. The PQ-encoding \nof a small slice with k+<=wtypes adds a byte to the array ibdof each other type e, which is less ef.cient \nthan using BM-encoding for types in this slice. In heterogeneous encoding, subtyping tests e-rhnb, where \nbbelongs in such a small slice, are im\u00adplemented using BM-encoding. Since bis known at compile time, \nthe compiler can choose the appropriate code to plant at the sub\u00adtyping test. We found that heterogeneous \nencoding may give rise to signi.cant improvement to the encoding length. On the other hand, the total \nnumber of types in small slices is negligible, and therefore we do not expect a noticeable impact on \nthe instruction count and test time.  6. Inlining and Coalescing Optimizations So far it was tacitly \nassumed that in the test earhnbthat the type eis given at run time. In reality, however the type emust \nbe computed from a certain object 0. The traditional object model [17] stores with each object 0a pointerpto \na memory block with run time representation of the type eof 0. The various encoding schemes store their \nauxiliary information in this area, called RTTI (run time type information) in the C++ jargon. The object-oriented \nparadigm mandates other uses to the RTTI records, including dispatching, downcasting, and garbage collection. \nInlining optimization makes use of the degree of freedom in that the compiler has in placing these records \nin memory. The simplest application of inlining is in relative numbering: The RTTI records are placed \nin memory in the same order as postorder traversal. In doing so,pcan play the same role as r. As a result, \nthe encoding length is reduced to zero and one load instruction in the subtyping test is saved. t Note \nthat this does not necessarily happen when the slice size hits 128. Similarly, in range-compression \n(12), we can use pinstead of the global ied. If specialization is used then we obtain an encoding scheme \nwith zero encoding length, but non-constant test time or instruction count. In PQE, inlining is used \nto represent the ibd s of types with respect to the .rst slice, speci.cally, ibd@ for all types e. In \nother words, the .rst entry in the pseudo array ibd, is encoded as p. The saving is signi.cant since \nthe .rst slice occupies the largest number of bits. Inlining also saves one load instruction in the case \nthat type bbe\u00adlongs in the .rst slice. Since the .rst slice constitutes around 90% of the types, we expect \nthis saving to lead to a noticeable saving in the average test time. Thus, in PQE, there are three kinds \nof slices. The .rst slice is in\u00adlined. Heterogeneous encoding based on binary matrix representa\u00adtion \nis used for the small slices (with fewer than 8 types). Each of the remaining slices occupies a single \nbyte in the array ibd. We could think of no straightforward way for applying inlining nei\u00adther for bit-vector \nencodings nor for Cohen s algorithm and its gen\u00aderalizations, PE and BPE. Another intricacy which is \noften overlooked in subtyping tests is that even fetching the pointer pfrom the object 0, may not be \ntriv\u00adial. In the presence of multiple inheritance, traditional object layout schemes are inclined to \nstore several pointers in an object to various RTTI records. The reason is a phenomenon sometimes called \nthis adjustment occurring in upcasts in a multiple inheritance hierarchy. After such a cast, a pointer \nto an object does not necessarily point to its start. For the sake of concreteness, let us use the object \nlayout model of C++. In this model, there are various pointers, called VPTRs to the dispatching tables, \ncalled VTBLs. No matter what this\u00adadjustment took place, it is always possible to fetch a VPTR from an \nobject. The dif.culty in applying inlining in this model, is that there is no unique valuepfor a type \ne. Observe that the subtype tests of relative numbering (6), range com\u00adpression (12), and PQE (13), check \nfor inequality rather than equal\u00adity. Thus, inlining can be done even ifpis not unique by allocating \na range of memory addresses, rather than a single address, as the value r(as in (6)) or the ied(as in \n(12) and (13)). Yet another intricacy posed by C++ is the location in memory of the subtype data as generated \nby the encoding algorithm. If there are several VTBLs, then an implementer faces the dilemma of ei\u00adther \nduplicating this data in each VTBL, or using another level of indirection from all the VTBLs of a certain \nclass to a shared sub\u00adtyping encoding. Not only sharing incurs a run time penalty, it also increases \nthe memory overhead by a pointer for each VTBL of each class. With the reduction in encoding length, \nas offered by algorithms such as PQE, the alternative of duplication seems more appealing. In considering \nthe tradeoff, it should be remembered that the number of VTBLs may be in the order of the number of an\u00adcestors \n[17]. Empirical data on the number of VTBLs can be found in [14]. If the sharing alternative is chosen, \nthen another reduction in the en\u00adcoding length can be achieved by coalescing the ibdarrays of PQE. We \nnow turn to describing Coalesced PQ-Encoding (CPQE). Recall that the .rst entry of the pseudo array ibdhas \nan implicit representation due to inlining. Let ibdodenote the array ibdafter truncating its .rst entry, \nand let p odenote the pointer to ieddo(which is stored in all VTBLs of type e). If several ibdoarrays \nbelonging to different types are identical, they can be stored only once. All the distinct arrays ibdoare \nstored in one large array denotedZ. We also note that if the number of different ibdoarrays is small, \nthen pocan be replaced by the index of ieddoin the large array Z. o.2 o.4 An example of the memory layout \nin CPQE is in Figure 10. In the .gure, we see two instances 0and 0iof type A. Each of these objects has \ntwo pointers to the two VTBLs of class A. Each of these VTBLs stores p oA which points to the array ibddoA. \nSince the total number of different ibdoarrays is small, instead of storing a pointer to ibdAo, the VTBLs \nstore the index of ibdAoin the larger array Z. Object 0aof type B has a single VPTR to the VTBL of B. \nAr\u00adrays ibdBoand ibdAoare identical, and hence the VTBLs of both types store a reference to the same \nentry of array Z, i.e., pAo==pBo. Fi\u00adnally, object 0uof type C has three VPTRs. The VTBL of C stores \nthe index of the array ibdCoin Z. We also see that 0iand 0uhave undergone thisadjustment. In the same \nfashion we inlined the .rst slice by using pinstead of ibd@ , we can now inline the second slice by using \npoinstead of ibd@2. The second inlining is possible since there is again a degree of freedom in the order \nin which arrays iedoare stored inZ. In the test errh(b, if it is found that bbelongs in slice 8i, then \ninstead of using ied@2in the test (13), the compiler emits code aa for comparing powith the values aand \nr, which are, as usual, specialized into the test code. The entries in arrayZare then the arrays ibdooproduced \nby truncating the .rst two entries of array ibd. Figure 11 depicts CPQE after the second inlining. Note \nthat the arrays iedooare not necessarily distinct. The entries in array Zwhere reordered, so Slice 2 \ncould be inlined into the VTBLs. For example, the .rst entry in Figure 10 is now in position 3. Finding \nall coalescing opportunities among the arrays ibdocan be done using bucket sort (in time linear in the \ntotal size of all ar\u00adrays). We can also show that the number of distinct arrays iedois exactly the number \nof equivalence classes in G-partitioning of T, whereG==-T+h 8. Furthermore, this number is always smaller \nor equal to the size of the core. A  Slice 3 Slice 4 A B C C Z. Figure 11: An example of CPQE of \nFigure 10 after the second inlining We .nally note that CPQE is not limited to C++, nor to the VTBLs \nimplementation. It is possible to store the encoding of each type using this two levels scheme. In doing \nso, we presume, just as in all previously published algorithms, that the unique pointer pcan be produced \ndeus ex machina from the object 0. Then ppoints to p owhich points to array iedoo. This two levels scheme \nis similar to the one depicted in Figure 11, only each type has a single VTBL. It should be stressed \nthat the two-level structure makes CPQE slower than PQE. The slowdown is justi.ed in the C++ sharing \nalternative. In other object layout models, the time penalty of the extra indi\u00adrection has to be weighed \nagainst the potential saving in encoding length of CPQE. 7. Results Table 2 compares the encoding length \nin bits of PQE and CPQE with that of other algorithms. PQE, and its variant CPQE, are pre\u00adsented with \nall optimizations, including length-optimization, het\u00aderogeneous encoding and the newly suggested inlining \noptimiza\u00adtion. We see that PQE encoding length improves on all previously pub\u00adlished algorithms. As explained \nabove, the memory requirements of PQE is zero for all SI hierarchies. As can be seen in the table, zero \nmemory footprint occurs even in IDL, which is MI. The me\u00addian improvement with the next best algorithm, \nNHE, is by 37%, while the average improvement is 50%. In addition, PQE test time is constant, whereas \nNHE, which is based on bit-vector encoding, is non-constant. In the Eiffel4 hierarchy the constant BPE \nhas a total space requirements of 39KB, compared to 16KB in PQE. These differences are signi.cant since \nsubtyping tests are frequent, so the encoding data should be cached. If PQE is not optimized by inlining, \nthen its encoding length will increase by 16 bits. Without this optimization, PQE is better than NHE \nin 8 out of the 13 hierarchies. In two hierarchies (LOV and Geode), the encoding length of NHE is 1 bit \nshorter than PQE, in two hierarchy (Self and JDK 1.18) it is 2 bits shorter, and in one hierarchy (Eiffel4) \nit is 9 bits shorter. We see that in the .rst four hierarchies CPQE is not as ef.cient as PQE. The reason \nis that its two-level structure imposes an encoding length of 8 bits even in very degenerate hierarchies. \nLet mdenote the number of distinct arrays ibdoin CPQE. Then, we found that with the exception of Eiffel4, \nGeode, and JDK 1.30, m was less than 256. Thus, in all these hierarchies, p ocan be repre\u00adsented as a \nsingle byte. We see that CPQE improves the encoding VTBL3 VTBL3 3 VTBL 5 VTBL 5 5VTBL VTBL 6 7 8 9 6 \n7 ... Hierarchy m IDL 1 100.0% 0.0% 0 0 0 Laure 2 98.0% 2.0% 6 7 0 Unidraw 2 99.7% 0.3% 2 2 0 JDK 1.1 \n2 99.6% 0.4% 1 1 0 Self 13 97.2% 1.7% 31 63 1 Ed 10 87.8% 4.6% 20 145 2 LOV 12 86.2% 6.0% 26 164 2 Eiffel4 \n11 89.1% 0.5% 9 376 7 Geode 16 86.0% 1.8% 24 419 7 JDK 1.18 6 97.5% 0.5% 9 74 2 JDK 1.22 8 97.6% 0.3% \n12 235 3 JDK 1.30 8 97.7% 0.3% 17 286 3  Hierarchy CPQE PQE NHE BPE PE DAGa Closureb BM IDL 8 0 17 32 \n96 7 27 66 Laure 8 6 23 63 128 10 74 295 Unidraw 8 2 30 63 96 8 31 613 JDK 1.1 8 1 19 32 64 9 26 225 \nSelf 9 39 53 126 344 12 329 1801 Ed 17 36 54 94 216 15 72 434 LOV 21 42 57 94 216 16 77 436 Eiffel4 27 \n65 72 157 312 15 97 1999 Geode 39 80 95 157 408 21 154 1318 JDK 1.18 9 25 39 94 128 13 48 1704 JDK 1.22 \n10 36 62 157 184 16 57 4339 JDK 1.30 18 41 65 188 216 16 57 5438 Cecil 10 22 58 94 192 13 65 932 b that(rsl \notgy at/ud/aab thutlrtlbotgy at/ud// Table 2: The encoding length of different algorithms length of \nPQE by factors ranging between 2 and 4.3. Table 3 compares the encoding creation time of CPQE with that \nof NHE and BPE. The creation time of PQE and PE is the same as CPQE and BPE, respectively. Hierarchy \n(C)PQE a NHE b (B)PE c IDL 1 - 5 Laure 4 21 9 Unidraw 1 93 10 JDK 1.1 1 19 10 Self 122 1367 22 Ed 77 \n136 12 LOV 95 168 10 Eiffel4 299 - 29 Geode 668 1902 28 JDK 1.18 29 - 26 JDK 1.22 140 - 77 JDK 1.30 187 \n- 90 Cecil 50 - 13 266 Mhz Pentium II a 500 Mhz 21164 Alpha 750 Mhz Pentium III, user time in Linux \nTable 3: Encoding creation time in milliseconds of different al\u00adgorithms The comparison is not easy, \nsince the algorithms were run on dif\u00adferent machines. Algorithm 1 was written in C++ based on the PQ-tree \nimplementation of Leipert [27]. More experimentation is required before a faithful and fair comparison \nis possible. It ap\u00adpears as if PQE, which is based on a linear algorithm, outperforms the quadratic NHE-algorithm. \nPE and BPE, which use a fast im\u00adplementation of set unions and intersections using bit-vector oper\u00adations, \nseem to be the fastest. The Geode hierarchy is toughest for PQE and NHE. In this hierarchy, the average \ntime for processing a type is less than one millisecond in PQE. In all benchmarks the time for computing \nthe PQ-encoding is less than a second. Table 4 presents values of some internal parameters in the execu\u00adtion \nof PQE and CPQE. The total number of distinct slices is k. The number of types in the .rst slice is \ndenoted by , while i is the number of types in slices whose size is smaller than 8. The value ko<=kis \nthe number of slices not which do not fall in these two categories. k//i//ikdo Table 4: Internal parameters \nof PQE and CPQE We see in the table that a very signi.cant portion of all types fall in the .rst slice; \nvery small fraction of types fall into the small slices. The encoding length of PQE is weko+ti. In CPQE \nthe total size of array Zis blwdblkdodun {ua+oiuyi.m(recall that a second inlining was performed), and \nthe encoding length is therefore blwablkoua /u/+liu i.mE/a y++rtlbotg.moteb  8. Conclusions and Future \nResearch The PQE algorithm improves the encoding length, creation time, test time and instruction count \nof NHE, the most space ef.cient previously published encoding algorithm. The CPQE variant, es\u00adpecially \ntailored for object layout like the one in C++, reduces the encoding length even further. The main problem \nwhich this paper leaves open is an incremental algorithm for the subtyping problem, as required by languages \nsuch as JAVA, in which types may be added as leaves at run time. It turns out that the PQ-data structure \nis not susceptible to ef.cient updates of this sort. On the theoretical side, it would be very interesting \nto see any non\u00adtrivial lower bound for the encoding length. Acknowledgements We are truly indebted to \nJan Vitek for his help in making the initial data set available to us, for contributing the three additional \nJAVA hierarchies, for help in running the experi\u00adments, and for many stimulating discussions!  9. References \n[1] R. Agrawal, A. Borgida, and H. V. Jagadish. Ef.cient management of transitive relationships in large \ndata and knowledge bases. In J. Clifford, B. G. Lindsay, and D. Maier, editors, Proceedings of the 1989 \nACM SIGMOD International Conference on Management of Data, pages 253 262, Portland, Oregon, 31 May 2 \nJune 1989. [2] K. Arnold and J. Gosling. The Java Programming Language. The Java Series. Addison-Wesley, \n1996. [3] G. D. Battista and R. Tamassia. On-line planarity testing. Technical Report CS-89-31, Brown \nUniversity -Department of Computer Science, May 1989. [4] G. D. Battista and R. Tamassia. On-line graph \nalgorithms with SPQR-trees. In M. S. Paterson, editor, Automata, Languages and Programming, 17t hInternational \nColloquium, volume 443 of Lecture Notes in Computer Science, pages 598 611, Warwick University, England, \n16 20 July 1990. Springer-Verlag. [5] G. D. Battista and R. Tamassia. On-line maintenance of triconnected \ncomponents with SPQR-trees. Algorithmica, 15(4):302 318, Apr. 1996. [6] K. S. Booth and G. S. Leuker. \nTesting for the consecutive ones property, interval graphs, and graph planarity using PQ-tree algorithms. \nJ. Comput. Sys. Sci., 13(3):335 379, Dec. 1976. [7] C. Capelle. Representation of an order as union \nof interval orders. In ORDAL 94 (Orders, Algorithms and Applications), LNCS 831, pages 143 162. Springer, \n1994. [8] L. Cardelli, J. Donahue, M. Jordan, B. Kalsow, and G. Nelson. The Modula-3 type system. In \n16t hSimposium on Principles of Programming Languages, POPL 89, pages 202 212, Austin, Texas, Jan. 1989. \nACM SIGPLAN SIGACT, ACM Press. [9] Y. Caseau. Ef.cient handling of multiple inheritance hierarchies. \nIn A. Paepcke, editor, Proceedings of the 8t h Annual Conference on Object-Oriented Programming Systems, \nLanguages, and Applications, pages 271 287, Washington, DC, USA, Sept. 26 -Oct. 1 1993. OOPSLA 93, ACM \nSIGPLAN Notices 28(10) Oct. 1993. [10] C. Chambers. The Cecil language, speci.cation and rationale. Technical \nreport, University of Washington, Seattle, 1993. [11] N. H. Cohen. Type-extension tests can be performed \nin constant time. ACM Transactions on Programming Languages and Systems, 13:626 629, 1991. [12] B. J. \nCox. Object-Oriented Programming -An Evolutionary Approach. Addison-Wesley, 1986. [13] E. W. Dijkstra. \nRecursive programming. Numerische Mathematik, 2:312 318, 1960. [14] N. Eckel and J. Y. Gil. Empirical \nstudy of object-layout strategies and optimization techniques. In E. Bertino, editor, Proceedings of \nthe 14t hEuropean Conference on Object-Oriented Programming, number 1850 in Lecture Notes in Computer \nScience, pages 394 421, Sophia Antipolis and Cannes, France, June 12 16 2000. ECOOP 2000, Springer Verlag. \n[15] A. Fall. Heterogeneous encoding. In Proceedings of International KRUSE 95 Conference : Knowledge \nUse, Retrieval and Storage for Ef.ciency, pages 162 167, Aug. 1995. [16] A. Fall. Sparse term encoding \nfor dynamic taxonomies. In P. W. Eklund, G. Ellis, and G. Mann, editors, Proceedings of the Fourth International \nConference on Conceptual Structures (ICCS-96): Knowlegde Representation as Interlingua, volume 1115 of \nLNAI, pages 277 292, Berlin, Aug. 19 22 1996. Springer. [17] J. Y. Gil and P. Sweeney. Space-and time-ef.cient \nmemory layout for multiple inheritance. In Proceedings of the 14t h Annual Conference on Object-Oriented \nProgramming Systems, Languages, and Applications, pages 256 275, Denver, Colorado, Nov.1 5 1999. OOPSLA \n99, ACM SIGPLAN Notices 34(10) Nov. 1999. [18] A. Goldberg. Smalltalk-80: The Interactive Programming \nEnvironment. Addison-Wesley, 1984. [19] R. Gra.. CACAO: Ein 64bit JavaVM just-in-time compiler. Master \ns thesis, University of Vienna, 1996. [20] M. Habib and L. Nourine. Bit-vector encoding for partially \nordered sets. In ORDAL 94 (Orders, Algorithms and Applications), LNCS 831, pages 1 12. Springer, 1994. \n[21] P. L. Hassan Kaci, Robert Boyer and R. Nasr. Ef.cient implementation of lattice operation. ACM Transactions \non Programming Languages and Systems, 11:115 146, 1989. [22] M. Junger, S. Leipert, and P. Mutzel. On \ncomputing a maximal planar subgraph using PQ-trees. Technical report, Informatik, Universit\u00a8at zu K\u00a8oln, \n1996. [23] M. Junger, S. Leipert, and P. Mutzel. A note on computing a maximal planar subgraph using \nPQ-trees. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 17(7), 1998. \n[24] A. Krall and R. Gra.. CACAO a 64 bit JavaVM just-in-time compiler. In G. C. Fox and W. Li, editors, \nPPoPP 97 Workshop on Java for Science and Engineering Computation, Las Vegas, June 1997. [25] A. Krall, \nJ. Vitek, and R. N. Horspool. Ef.cient type inclusion tests. In Proceedings of the 12t hAnnual Conference \non Object-Oriented Programming Systems, Languages, and Applications, pages 142 157, Atlanta, Georgia, \nOct. 5-9 1997. OOPSLA 97, ACM SIGPLAN Notices 32(10) Oct. 1997. [26] A. Krall, J. Vitek, and R. N. Horspool. \nNear optimal hierarchical encoding of types. In M. Aks\u00b8it and S. Matsuoka, editors, Proceedings of the \n11t hEuropean Conference on Object-Oriented Programming, number 1241 in Lecture Notes in Computer Science, \npages 128 145, Jyv\u00a8askyl\u00a8a, Finland, June 9-13 1997. ECOOP 97, Springer Verlag. [27] S. Leipert. PQ-trees, \nan implementation as template class in C++. Technical report, Informatik, Universit\u00a8at zu K\u00a8oln, 1997. \n[28] L. N. M. Habib, Y. Caseau and O. Raynaud. Encoding of multiple inheritance hierarchie and partial \norders. In Computational Intelligence, volume 15, pages 50 62, 1999. [29] B. Meyer. EIFFEL the Language. \nObject-Oriented Series. Prentice-Hall, 1992. [30] O. Raynaud and E. Thierry. A quasi optimal bit-vector \nencoding of tree hierarchies. application to ef.cient type inclusion tests. In Proceedings of the 15t \nhEuropean Conference on Object-Oriented Programming, Lecture Notes in Computer Science, Budapest, Hungary, \nJune18 22 2001. ECOOP 2001, Springer Verlag. [31] M. A. Schubert, P. L.K., and J. Taugher. Determining \ntype, part, colour, and time relationships. Computer, 16 (special issue on Knowledge Representation):53 \n60, Oct. 1983. [32] B. Stroustrup. The C++ Programming Language. Addison-Wesley, 3rd edition, 1997. [33] \nM. F. van Bommel and T. J. Beck. Incremental encoding of multiple inheritance hierarchies. In Proceedings \nof the 8t h International Conference on Information Knowledgement (CIKM-99), pages 507 513, N.Y., Nov. \n2 6 2000. ACM Press.  \n\t\t\t", "proc_id": "504282", "abstract": "<i>Subtyping test</i>, i.e., determining whether one type is a subtype of another, are a frequent operation during the execution of object-oriented programs. The challenge is in encoding the hierarchy in a small space, while simulataneously making sure that subtyping tests have efficient implmentation. We present a new scheme for encoding multiple and single inheritance hierarchies, which, in the standardized hierarchies, reduces the footprint of all previsously published schemes. The scheme is called <i>PQ-encoding</i> after <i>PQ-trees</i>, a data structure previously used in graph theory for finding the orderings that satisfy a collection of constraints. In particular, we show that in the traditional object layout model, the extra memory requirement for single inheritance hierarchies is zero. In the PQ-encoding subtyping tests are constant time, and use only two comparisons. Other than PQ-trees, PQ-encoding uses several novel optimization techniques. These techniques are applicable also in improving the performance of otehr, previously published, encoding schemes.", "authors": [{"name": "Yoav Zibin", "author_profile_id": "81100037778", "affiliation": "Department of Computer Science, Technion-Israel Institute of Technology, Technion City, Haifa 32000, Israel", "person_id": "PP36023074", "email_address": "", "orcid_id": ""}, {"name": "Joseph Yossi Gil", "author_profile_id": "81100349003", "affiliation": "Department of Computer Science, Technion-Israel Institute of Technology, Technion City, Haifa 32000, Israel", "person_id": "P344301", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/504282.504290", "year": "2001", "article_id": "504290", "conference": "OOPSLA", "title": "Efficient subtyping tests with PQ-encoding", "url": "http://dl.acm.org/citation.cfm?id=504290"}