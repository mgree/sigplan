{"article_publication_date": "01-01-2004", "fulltext": "\n Atomizer: A Dynamic Atomicity Checker For Multithreaded Programs Cormac Flanagan Stephen N. Freund \nDepartment of Computer Science Department of Computer Science University of California at Santa Cruz \nWilliams College Santa Cruz, CA 95064 Williamstown, MA 01267 Abstract Ensuring the correctness of multithreaded \nprograms is dif.cult, due to the potential for unexpected interactions between concurrent threads. Much \nprevious work has focused on detecting race condi\u00adtions, but the absence of race conditions does not \nby itself prevent undesired thread interactions. We focus on the more fundamental non-interference property \nof atomicity; a method is atomic if its ex\u00adecution is not affected by and does not interfere with concurrently\u00adexecuting \nthreads. Atomic methods can be understood according to their sequential semantics, which signi.cantly \nsimpli.es (formal and informal) correctness arguments. This paper presents a dynamic analysis for detecting \natomicity vi\u00adolations. This analysis combines ideas from both Lipton s theory of reduction and earlier \ndynamic race detectors. Experience with a prototype checker for multithreaded Java code demonstrates \nthat this approach is effective for detecting errors due to unintended in\u00adteractions between threads. \nIn particular, our atomicity checker de\u00adtects errors that would be missed by standard race detectors, \nand it produces fewer false alarms on benign races that do not cause atomicity violations. Our experimental \nresults also indicate that the majority of methods in our benchmarks are atomic, supporting our hypothesis \nthat atomicity is a standard methodology in multi\u00adthreaded programming. Categories and Subject Descriptors: \nD.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation reliability; D.2.5 [Software Engineering]: \nTesting and Debugging monitors, testing tools; F.3.1 [Logics and Meanings of Programs]: Specifying and \nVerifying and Reasoning about Programs. General Terms: Languages, Algorithms, Veri.cation. Keywords: \nAtomicity, dynamic analysis, reduction. Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 04, January 14 16, 2004, Venice, Italy. Copyright 2004 ACM 1-58113-729-X/04/0001 \n...$5.00 1 Reliable Threads Multiple threads of control are widely used in software develop\u00adment because \nthey help reduce latency, increase throughput, and provide better utilization of multiprocessor machines. \nHowever, reasoning about the behavior and correctness of multithreaded code is dif.cult, due to the need \nto consider all possible interleavings of the executions of the various threads. Thus, methods for specifying \nand controlling the interference between threads are crucial to the cost-effective development of reliable \nmultithreaded software. Much previous work on controlling thread interference has focused on race conditions. \nA race condition occurs when two threads si\u00admultaneously access the same data variable, and at least \none of the accesses is a write [47]. In practice, race conditions are commonly avoided by protecting \neach data structure with a lock [6]. This lock\u00adbased synchronization discipline is supported by a variety \nof type systems [21, 20, 19, 22, 8, 7, 28] and other static [49, 23, 10, 13] and dynamic [47, 11, 51, \n42, 45] analyses. Unfortunately, the absence of race conditions is not suf.cient to ensure the absence \nof errors due to unexpected interference between threads. As a concrete illustration of this limitation, \nconsider the following excerpt from the class java.lang.StringBuffer. All .elds of a StringBuffer object \nare protected by the implicit lock associated with the object, and all StringBuffer methods should be \nsafe for concurrent use by multiple threads. Excerpt from java.lang.StringBuffer public final class StringBuffer \n{ public synchronized StringBuffer append(StringBuffer sb) { int len = sb.length(); ... // other threads \nmay change sb.length(), ... // so len does not reflect the length of sb sb.getChars(0, len, value, count); \n... } public synchronized int length() { ... }public synchronized void getChars(...) { ... }... } The \nappend method shown above .rst calls sb.length(), which acquires the lock sb, retrieves the length of \nsb, and releases the lock. The length of sb is stored in the variable len. At this point, a second thread \ncould remove characters from sb. In this situation, len is now stale [9] and no longer re.ects the current \nlength of sb, and so the getChars method is called with an invalid len argu\u00adment, and may throw an exception. \nThus, StringBuffer objects cannot be safely used by multiple threads, even though the imple\u00admentation \nis free of race conditions. Recent results have shown that subtle defects of a similar nature are common, \neven in well-tested libraries [24]. Havelund reports .nding similar errors in NASA s Remote Agent spacecraft \ncon\u00adtroller [1], and Burrows and Leino [9] and von Praun and Gross [51] have detected comparable defects \nin Java applications. Clearly, the construction of reliable multithreaded software requires the devel\u00adopment \nand application of more systematic methods for controlling the interference between concurrent threads. \nThis paper focuses on a strong yet widely-applicable non\u00adinterference property called atomicity. A method \n(or in general a code block) is atomic if for every (arbitrarily interleaved) program execution, there \nis an equivalent execution with the same overall behavior where the atomic method is executed serially, \nthat is, the method s execution is not interleaved with actions of other threads. Atomicity corresponds \nto a natural programming methodology, es\u00adsentially dating back to Hoare s monitors1 [32]. Many existing \nclasses and library interfaces already follow this methodology, our experimental results indicate that \nthe vast majority of methods in our benchmarks are atomic. In addition, atomicity provides a strong, \nindeed maximal, guaran\u00adtee of non-interference between threads. This guarantee reduces the challenging \nproblem of reasoning about an atomic method s behav\u00adior in a multithreaded context to the simpler problem \nof reasoning about the method s sequential behavior. The latter problem is sig\u00adni.cantly more amenable \nto standard techniques such as manual code inspection, dynamic testing, and static analysis. In summary, \natomicity is a widely-applicable and fundamental cor\u00adrectness property of multithreaded code. However, \ntraditional test\u00ading techniques are inadequate to verify atomicity. While testing may discover a particular \ninterleaving on which an atomicity viola\u00adtion results in erroneous behavior, the exponentially-large \nnumber of possible interleavings makes obtaining adequate test coverage essentially impossible. This \npaper presents a dynamic analysis for detecting atomicity vio\u00adlations. For each code block annotated \nas being atomic, our analy\u00adsis veri.es that every execution of that code block is not affected by and \ndoes not interfere with other threads. Intuitively, this approach increases the coverage of traditional \ndynamic testing. Instead of waiting for a particular interleaving on which an atomicity violation causes \nerroneous behavior, such as a program crash, the checker actively looks for evidence of atomicity violations \nthat may cause errors under other interleavings. Our approach synthesizes ideas from dynamic race detectors \n(such as Eraser s Lockset algorithm) and Lipton s theory of reduction (described in Section 3.1). For \nthe StringBuffer class described above, our technique detects that append contains a window of vulnerability \nbetween where the lock sb is released inside length and then re-acquired inside getChars, and produces \nthe following warning, even on executions where this window of vulnerability is not exploited by concurrent \nthreads. 1Monitors are less general in that they rely on syntactic scope restrictions and do not support \ndynamically-allocated shared data. Atomizer error report  StringBuffer.append is not atomic: Atomic \nblock entered at StringBuffer.append(StringBuffer.java:445) at BreakStringBuffer.main(BreakStringBuffer.java:21) \nAtomic block commits at lock release: at StringBuffer.length(StringBuffer.java:144) at StringBuffer.append(StringBuffer.java:451) \nat BreakStringBuffer.main(BreakStringBuffer.java:21) Atomicity violation at lock acquire: at StringBuffer.getChars(StringBuffer.java:326) \nat StringBuffer.append(StringBuffer.java:455) at BreakStringBuffer.main(BreakStringBuffer.java:21)  \nWe have implemented this dynamic analysis in an automatic check\u00ading tool called the Atomizer. The application \nof this tool to over 100,000 lines of Java code demonstrates that it provides an effective approach for \ndetecting defects in multithreaded programs, includ\u00ading some defects that would be missed by existing \nrace-detection tools. In addition, the Atomizer produces fewer false alarms on be\u00adnign races that do \nnot cause atomicity violations. Finally, our results suggest that a large majority of the exported methods \nin our bench\u00admarks are atomic, which validates our hypothesis that atomicity is a widely-used programming \nmethodology. We propose that the application of this technique during the devel\u00adopment, validation, and \nevolution of multithreaded programs will provide multiple bene.ts, including: detecting atomicity violations \nthat are resistant to both tradi\u00adtional testing and existing race detection tools,  facilitating safe \ncode re-use in multithreaded settings by vali\u00addating atomicity properties of interfaces,  simplifying \ncode inspection and debugging, since atomic methods can be understood according to their sequential se\u00admantics, \nand  improving concurrent programming methodology by encour\u00adaging programmers to document the atomicity \nguarantees pro\u00advided by their code.  Dynamic atomicity checking complements existing static tech\u00adniques, \nsuch as the type system for atomicity developed by Flana\u00adgan and Qadeer [24], since most software is \ncurrently validated us\u00ading a combination of static type checking and dynamic testing. For large programs, \na bene.t of the dynamic approach is that it avoids the overhead of type annotations or type inference, \nparticularly for legacy code. Combining dynamic atomicity checking with other static checkers for multithreaded \ncode, such as the Calvin-R tool developed by Freund and Qadeer [26], would yield similar bene.ts. The \npresentation of our results proceeds as follows. Section 2 in\u00adtroduces a model of concurrent programs \nthat we use as the basis for our development. Section 3 describes our dynamic analysis for atomicity. \nSection 4 describes how the Atomizer implements this analysis, and Section 5 presents our experimental \nresults. Section 6 discusses related work, and we conclude with Section 7.  2 Multithreaded Programs \nTo provide a formal basis for reasoning about interference between threads, we start by formalizing an \nexecution semantics for multi\u00adthreaded programs. In this semantics, a multithreaded program con\u00adsists \nof a number of concurrently executing threads, each of which has an associated thread identi.er t . Tid. \nThe threads communi\u00adcate through a global store s, which is shared by all threads. The global store maps \nprogram variables x to values v. The global store also records the state of each lock variable m . Lock \n.If s(m)= t, then the lock m is held by thread t;if s(m)= ., then that lock is not held by any thread. \nIn addition to operating on the shared global store, each thread also has its own local store p containing \ndata not manipulated by other threads, such as the program counter of that thread. A state S= (s, .) \nof the multithreaded system consists of a global store s and a mapping . from thread identi.ers t to \nthe local store .(t) of each thread. Program execution starts in an initial state S0 =(s0, .0). Domains \nu, t . Tid x . Var v . Value m . Lock s .GlobalStore p . LocalStore = (Var .Value) .(Lock .(Tid .{.})) \n. .LocalStores = Tid .LocalStore S . State = GlobalStore \u00d7LocalStores 2.1 Standard semantics We model \nthe behavior of each thread in a multithreaded program as the transition relation T : T . Tid \u00d7 LocalStore \n\u00d7 Operation \u00d7 LocalStore The relation T (t, p, a, p') holds if the thread t can take a step from a state \nwith local store p, performing the operation a . Operation on the global store, yielding a new local \nstore p'. The set of possible operations on the global store includes: rd(x, v), which reads a value \nv from a variable x; wr(x, v), which writes a value v to a variable x; acq(m) and rel(m), which acquire \nand release a lock m, respectively; begin and end, which mark the beginning and end of an atomic block; \nand E, the empty operation. a . Operation ::= rd(x, v) | wr(x, v) | acq(m) | rel(m) | begin | end | E \nThe following transition relation S . S' performs a single step of an arbitrarily chosen thread. We use \n. * to denote the re.exive\u00adtransitive closure of .. A transition sequence S0 . * S models the arbitrary \ninterleaving of the various threads of a multithreaded program, starting from the initial state S0. Although \ndynamic thread creation is not explicitly supported by the semantics, it can be modeled within the semantics \nin a straightforward way. Standard semantics: S . S' [STD STEP] a s' T (t, .(t),a,p') s . t (s, .) .(s', \n.[t := p'])  2.2 Serialized semantics We assume the function A : LocalStore . Nat indicates the num\u00adber \nof atomic blocks that are currently active, perhaps by exam\u00adining the program counter and thread stack \nrecorded in the local store. This count should be zero in the initial state, and should only change when \nentering or leaving an atomic block. We formalize these requirements as follows: A(.0(t)) = 0 for all \nt . Tid;  if T (t, p, begin, p') then A(p')= A(p)+1;  if T (t, p, end, p'), then A(p) > 0 and A(p')= \nA(p) - 1;  if T (t, p, a, p') for a .{begin, end}, then A(p)= A(p').  The relation A(.) holds if any \nthread is inside an atomic block: def .t . Tid.A(.(t))=0 A(.) = The following serialized transition relation \n. is similar to the stan\u00addard relation ., except that a thread cannot perform a step if an\u00adother thread \nis inside an atomic block. Thus, the serialized relation . does not interleave the execution of an atomic \nblock with in\u00adstructions of concurrent threads. . S' Serialized semantics: S [SERIAL STEP] a s' T (t, \n.(t),a,p') s ..u= t. A(.(u)) = 0 t .(s' (s, .) , .[t := p']) Reasoning about program behavior and correctness \nis much easier under the serialized semantics ( .) than under the standard seman\u00ad s' models the effect \nof an operation at The following relation s .a by thread t on the global store s. The global store s[x \n:= v] is tics (.), since each atomic block can be understood sequentially, without the need to consider \nall possible interleaved actions of con\u00adidentical to s except that it maps the variable x to the value \nv.  Effect of operations: s . at s' current threads. However, standard language implementations only \nprovide the standard semantics (.), which admits additional transi\u00adtion sequences and behaviors. In particular, \na program that behaves correctly according to the serialized semantics may still behave er\u00ad [ACT READ] \n[ACT WRITE] [ACT OTHER] roneously under the standard semantics. Thus, in addition to being s(x)= va .{begin, \nend, E} a s . correct with respect to the serialized semantics, the program should rd(x,v) wr(x,v) s \n. ss . s s[x := v] t also use suf.cient synchronization to ensure the atomicity of each t t block of \ncode that is intended to be atomic. Thus, for any program [ACT ACQUIRE] [ACT RELEASE] execution (s0, \n.0) . * (s, .) where \u00acA(.), there should exist an s(m)= . s(m)= t equivalent serialized execution (s0, \n.0) (s, .). We call this . * acq(m) rel(m) the atomicity requirement on program executions, and any \nexecu\u00adtt tion of a correctly synchronized program should satisfy this require\u00ad s .s[m := t] s .s[m := \n.] ment. (The restriction \u00acA(.) avoids consideration of partially-Reduced execution sequence executed \natomic blocks.)  3 Dynamic Atomicity Checking b1 b2 b3 acq(m) rd(x,0) wr(x,1) rel(m) 5 6 S0 SSSSSSS7 \n1 2 3 4 In this section, we present an instrumented semantics that dynam\u00adically detects violations of \nthe above atomicity requirement. We start by reviewing Lipton s theory of reduction [38], which forms \n More generally, suppose a path through a code block contains a the basis of our approach. sequence \nof right-movers, followed by at most one non-mover ac\u00adtion and then a sequence of left-movers. Then this \npath can be reduced to an equivalent serial execution, with the same resulting state, where the path \nis executed without any interleaved actions by 3.1 Reduction other threads. The theory of reduction is \nbased on the notion of right-mover and left-mover actions. An action b is a right-mover if, for any execution \nwhere the action b performed by one thread is immediately followed by an action c of a concurrent thread, \nthe actions b and c can be swapped without changing the resulting state, as shown below: Commuting actions \n For example, if the operation b is a lock acquire, then the action c of the second thread neither acquires \nnor releases the lock, and so cannot affect the state of that lock. Hence the acquire operation can be \nmoved to the right of c without changing the resulting state, and we classify each lock acquire operation \nas a right-mover. Conversely, an action c is a left-mover if whenever c immediately follows an action \nb of a different thread, the actions b and c can be swapped, again without changing the resulting state. \nSuppose the operation c by the second thread is a lock release. During b, the second thread holds the \nlock, and b can neither acquire nor release the lock. Hence the lock release operation can be moved to \nthe left of b without changing the resulting state, and we classify each lock release operation as a \nleft-mover. Next, consider an access (read or write) to a variable that is shared by multiple threads. \nIf the variable is protected by some lock that is held whenever the variable is accessed, then two threads \ncan never access the variable at the same time, and we classify each access to that variable as a both-mover, \nwhich means that it is both a right\u00admover and a left-mover. If the variable is not consistently protected \nby some lock, we classify the variable access as a non-mover. To illustrate how the classi.cation of \nactions as various kinds of movers enables us to verify atomicity, consider the .rst execution trace \nin the diagram below. In this trace, a thread (1) acquires a lock m, (2) reads a variable x protected \nby that lock, (3) updates x, and then (4) releases m. The execution path of this thread is inter\u00adleaved \nwith arbitrary actions b1, b2, b3 of other threads. Because the acquire operation is a right-mover and \nthe write and release op\u00aderations are left-movers, there exists an equivalent serial execution in which \nthe operations of this path are not interleaved with opera\u00adtions of other threads, as illustrated by \nthe following diagram. Thus the execution path is atomic.  3.2 Checking atomicity via reduction We next \nleverage the theory of reduction to verify atomicity dy\u00adnamically. In an initial presentation of our \napproach, we assume the programmer provides a partial function P : Var -.Lock . that maps protected shared \nvariables to associated locks; if P (x) is unde.ned, then x is not protected by any lock. We develop \nan instrumented semantics that only admits code paths that are reducible, and which goes wrong on irreducible \npaths. To record whether each thread is in the right-mover or left-mover part of an atomic block, we \nextend the state space with an instrumenta\u00adtion store: f : Tid .{InRight, InLeft} Each state is now a \ntriple (s, f, .).If A(.(t))=0, then thread t is inside an atomic block, and f(t) indicates whether the \nthread is in the right-mover or left-mover part of that atomic block. The initial instrumentation store \nf0 is given by f0(t)= InRight for all t . Tid. The following relation S .a f ' updates the instrumentation \nstore t whenever thread t performs operation a. The rule [INS ACCESS PROT] deals with an access to a \nprotected variable while holding the appropriate lock. This action is a both-mover and so the instrumen\u00adtation \nstore f does not change. Accesses to unprotected variables are non-movers, and they can occur outside \natomic blocks: see [INS ACCESS OUTSIDE]. Unprotected accesses are also allowed inside an atomic block, \nand they cause a transition from the right-mover to the left-mover part of the atomic block: see [INS \nACCESS COM-MIT]. Acquire operations are right-movers, and they can occur out\u00adside or in the right-mover \npart of an atomic block, and conversely for release operations. The relation S .a wrong holds if the \noperation a by thread t t would go wrong by accessing a protected variable without hold\u00ading the correct \nlock [WRONG RACE], or by performing a non-left\u00admover action in the left-mover part of an atomic block. \nNon-left\u00admover actions include accessing an unprotected variable [WRONG UNPROTECT] or acquiring a lock \n[WRONG ACQUIRE]. Instrumented operations: S .f ' and S .  wrong THEOREM 2(INSTRUMENTED REDUCTION). If \n(s0,f0, .0) . * (s, f, .) and \u00acA(.) then (s0, .0) . * [INS ACCESS PROT] [INS ACCESS COMMIT] (s, .). a \n.{rd(x, v),wr(x, v)} a .{rd(x, v),wr(x, v)}P (x) de.ned P (x) unde.ned aa tt PROOF: See Appendix. [INS \nACCESS OUTSIDE] [INS ACQUIRE] a .{rd(x, v),wr(x, v)} f(t)= InRight P (x) unde.ned A(.(t)) = 0 or A(.(t)) \n= 0 (s, f, .) .a f acq(m) t (s, f, .) .f t [INS RELEASE] rel(m) (s, f, .) .f[t := InLeft] t [INS ENTER] \n[INS OTHER] a .{end, E} a (s, f, .) .begin f[t := InRight](s, f, .) .t f t [WRONG RACE] [WRONG UNPROTECT] \na .{rd(x, v),wr(x, v)} a .{rd(x, v),wr(x, v)}P (x) de.ned P (x) unde.ned s(P (x)) = tA(.(t)) =0 f(t)= \nInLeft aa (s, f, .) .wrong (s, f, .) .wrong tt [WRONG ACQUIRE] A(.(t)) =0 f(t)= InLeft acq(m) (s, f, \n.) .wrong t The instrumented transition relation S . S ' performs an instru- If the instrumented semantics \nadmits a particular execution, then not only is that execution reducible, but many similar executions \nare also reducible. In particular, when an atomic block is being executed, the only scheduling decision \nthat affects program behav\u00adior is when the commit operation (the transition from InRight to InLeft) is \nscheduled. Scheduling decisions regarding when other operations in the atomic block are scheduled are \nirrelevant, in that they do not affect program behavior or reducibility. Hence, one test run under our \ninstrumented semantics can simultaneously verify the reducibility of many executions of the standard \nsemantics.  3.3 Inferring protecting locks The instrumented semantics of the previous section relies \non the programmer to specify protecting locks for shared variables. To avoid burdening the programmer, \nwe next extend the instrumented semantics to infer protecting locks, using a variant of Eraser s Lock\u00adset \nalgorithm [47]. We extend the instrumentation store f to map each variable x to a set of candidate locks \nfor x, such that these candidate locks have all been held on every access to x seen so far: Lock f :(Tid \n.{InRight, InLeft}) . (Var . 2) The initial candidate lock set for each variable is the set of all locks, \nthat is, f0(x)= Lock for all x . Var . mented step of an arbitrary thread; and S . wrong holds if a step \nfrom S could violate the synchronization discipline or the atomicity The relation S . at f ' updates \nthe extended instrumentation store whenever thread t performs operation a on the global store. The requirement. \nInstrumented semantics: S . S ' and S . wrong rule [INS2 ACCESS] for a variable access removes from the \nvari\u00adable s candidate lock set all locks not held by the current thread. We use H(t, s) to denote the \nset of locks held by thread t in state s: [INS STEP] [INS WRONG] T (t, .(t),a, p ' ) T (t, .(t),a, p \n' ) aa s .s ' s .s ' tt a f ' a (s, f, .) .(s, f, .) .wrong tt H(t, s)= {m . Lock | s(m)= t} If the \ncandidate lock set for a variable becomes empty, then all ac\u00ad (s, f, .) .(s ' ,f ' , .[t := p ' ]) (s, \nf, .) .wrong cesses to that variable should be treated as non-movers, but previ\u00adous accesses may already \nhave been incorrectly classi.ed as both- The following theorems state that the instrumented semantics \nis identical to the standard semantics, except that the instrumented semantics records additional information \nand may go wrong. In ad\u00addition, any instrumented execution that does not go wrong satis.es the atomicity \nrequirement. THEOREM 1(EQUIVALENCE OF SEMANTICS). 1. If (s, f, .) . * (s ' ,f ' , . ' ), then (s, .) \n. * (s ' , . ' ). 2. If (s, .) . * (s ' , . ' ) then .f either (a) (s, f, .) . * wrong,or (b) .f ' \nsuch that (s, f, .) . * (s ' ,f ' , . ' ).   PROOF: By induction over derivations. movers. For example, \nif f(x)= {m} when thread t enters the following function double, then the .rst access to x by thread \nt will be classi.ed as a both-mover. If, at that point, an action of a concurrent thread causes f(x) \nto become empty, the analysis will classify the second access to x by t as a non-mover, but will not \nre\u00adclassify the .rst access, and thus the analysis will fail to recognize that double may not be reducible. \n/*# atomic */ void double() { synchronized (m) { intt= x; x=2*t; } } Thus, to ensure soundness, the \nlock inference semantics does not support unprotected variables, and instead requires every variable \nto have a protecting lock. If the candidate lock set becomes empty, then that state goes wrong, via [WRONG2 \nRACE]. Instrumented operations 2: S .f ' and S .   wrong program to include additional instrumentation \ncode. This instru\u00admentation code calls appropriate methods of the Atomizer run\u00ad [INS2 ACCESS] [INS2 \nACQUIRE] a .{rd(x, v),wr(x, v)} f(t)= InRight f(x) nH(t, s)= \u00d8 or A(.(t)) = 0 (s, f, .) a f[x := f(x) \nnH(t, s)] t (s, f, .) acq(m) f t [INS2 ENTER] [INS2 OTHER] a .{end, E} (s, f, .) begin f[t := InRight](s, \nf, .) at f t [INS2 RELEASE] (s, f, .) rel(m) f[t := InLeft] t [WRONG2 RACE] [WRONG2 ACQUIRE] a .{rd(x, \nv),wr(x, v)} A(.(t)) =0 f(x) nH(t, s)= \u00d8 f(t)= InLeft (s, f, .) at wrong (s, f, .) tacq(m) wrong  The \nrelation S . S ' performs an instrumented step (with lock inference) of an arbitrarily chosen thread; \nthe relation S . wrong describes states that go wrong.  Instrumented semantics 2: S . S ' and S . wrong \n [INS2 STEP] [INS2 WRONG] T (t, .(t),a, p ' ) T (t, .(t),a, p ' ) a s ' a s ' s .t s .t (s, f, .) a \nf ' (s, f, .) a wrong tt (s, f, .) (s ' ,f ' , .[t := p ' ]) (s, f, .) wrong  Like the previous instrumented \nsemantics (.), the lock-inference semantics (.) is equivalent to the standard semantics (.) except that \nit only admits execution sequences that satisfy the atomicity requirement. The following two theorems \nformalize these correct\u00adness properties. Their proofs are analogous to those of Theorems 1 and 2. THEOREM \n3(EQUIVALENCE OF SEMANTICS 2). 1. If (s, f, .) .* (s ' ,f ' , . ' ), then (s, .) . * (s ' , . ' ). 2. \nIf (s, .) . * (s ' , . ' ) then .f either (a) (s, f, .) .* wrong,or (b) .f ' such that (s, f, .) .* \n(s ' ,f ' , . ' ).   THEOREM 4(INSTRUMENTED REDUCTION 2). If (s0,f0, .0) .* (s, f, .) and \u00acA(.) then \n(s0, .0) . * (s, .). Again, if the instrumented semantics admits a particular execution, then all executions \nthat are equivalent to that execution modulo ir\u00adtime that implement the Lockset and reduction algorithms \nand issue warning messages when atomicity violations are detected. The Atomizer performs the instrumentation \non Java source code. This approach has a number of advantages: it supports programmer-supplied annotations; \nit works at the high level of ab\u00adstraction of the Java language; and it is portable across all Java vir\u00adtual \nmachines. This approach does require source code, but the instrumentation could also be performed at \nthe bytecode level. The target program can include annotations in comments to indicate that a method \nis atomic, as in: /*# atomic */ void getChars() {...} The Atomizer supports additional annotations to \nspecify that a code block is atomic, to suppress spurious warnings, to ignore races on speci.c .elds, \nand so on. Alternatively, the Atomizer can apply heuristics to decide which blocks should be checked \nfor atomicity. These heuristics are that (1) all methods exported by classes should be atomic, and (2) \nall synchronized blocks and synchronized meth\u00adods should be atomic. Exported methods are those that are \npublic or package protected. However, these heuristics are not used for main and the run methods of Runnable \nobjects, because these methods typically are not atomic. Although these heuristic are quite simple, they \nprovide a reasonable starting point for identifying atomicity errors in unannotated code. In the rest \nof this section, we describe our Lockset and reduction implementation, demonstrate how the tool identi.es \nand reports er\u00adrors, and present several improvements to the basic algorithm. 4.1 Lockset algorithm For \neach .eld of each allocated object, the Atomizer tracks a state that re.ects the degree to which the \n.eld has been shared among multiple threads. Lockset algorithm states for each allocated .eld The following \npossible states of our algorithm are similar to the relevant scheduling decisions are reducible.  4 \nImplementation We have developed an implementation, called the Atomizer, of the dynamic analysis outlined \nin the previous section. The Atomizer takes as input a multithreaded Java [27] program and rewrites the \nstates in earlier race detectors [47, 50]: Thread-Local: The .eld has only been accessed by the object \ns creating thread. Thread-Local (2): Ownership has transferred to a second thread, and the .eld is no \nlonger accessed by the creating thread. This state supports common initialization patterns in Java [50]. \nRead-Shared: The .eld has been read, but not written, by multi\u00adple threads. Shared-Modi.ed: The .eld \nhas been read and written by multiple threads, and a candidate lock set records which locks have been \nconsistently held when accessing this .eld. When entering this state, the candidate set is initialized \nwith all locks held by the current thread. When a thread accesses a .eld, the Atomizer run-time updates \nits state according to the following transition diagram. (The Atomizer does not instrument array accesses.) \n4.2 Reduction algorithm The instrumented semantics for lock inference in Section 3.3 goes wrong on any \nrace condition. Since programs frequently have be\u00adnign races, the Atomizer implements a relaxed version \nof this se\u00admantics that accommodates such benign race conditions. If the candidate lock set for a variable \nbecomes empty, then subsequent accesses to that variable are considered non-movers. Note that previous \naccesses to that variable, which were earlier classi.ed as movers, will not be re-classi.ed as non-movers, \nsince storing a his\u00adtory of all variable accesses would be expensive. Thus, as men\u00adtioned in Section \n3.3, these relaxed rules introduce a degree of un\u00adsoundness. We believe this unsoundness rarely causes \nthe Atom\u00adizer to miss atomicity violations in practice because it requires an unlucky scheduling of operations \nand because the Atomizer will report the problem on the next execution of the non-atomic code f ' and \nat /*# atomic */ void inc() fragment. The following rules adapt the relations S S Re-entrant locks. Lock \nacquires are in general only right-movers and not left-movers. However, Java provides re-entrant locks, \nand a re-entrant lock acquire is a both-mover, because this operation cannot interact with other threads. \nSimilarly, a re-entrant release is also a both-mover. Thread-local locks. If a lock is used by only a \nsingle thread, ac\u00adquires and releases of that lock are both-movers. Thread-local (2) locks. Adding another \nThread-local state, as in our Lockset algorithm, eliminates false alarms caused by initializa\u00adtion patterns \nin which one thread creates and initializes a protected object, and then transfers ownership of both \nthe object and its pro\u00adtecting lock to another thread. Protected locks. Suppose each thread always holds \nsome lock m1 before acquiring lock m2. In this case, two threads cannot attempt to acquire m2 simultaneously, \nand so operations on the lock m2 are also both-movers. Write-protected data. Consider the following two \nmethods, in which the variable x is protected by a lock for all writes, but not protected for reads. \n/*# atomic */ int read() { return x; } at wrong to express this relaxed semantics. {synchronized (lock) \n{ x=x+1; }} Relaxed instrumentation: S at f ' and S at wrong If x is a 32-bit variable, then the read() \nmethod is atomic on a  [INS2 RACE] sequentially-consistent machine, even though no protecting lock \nis a .{rd(x, v),wr(x, v)} held. Despite the presence of such unprotected reads, the inc() f(x) nH(t, \ns)= \u00d8 method is also atomic. In particular, when the lock is held, a read f(t)= InRight or \u00acA(.(t)) of \nx is a both-mover, since no other thread can write to x without (s, f, .) at [WRONG2 RACE] f[t := InLeft,x \n:= \u00d8] holding the lock. To handle examples like this one, we use a variant of the Lock\u00ad a .{rd(x, v),wr(x, \nv)} set algorithm. For each .eld, this algorithm infers a lock set pair, f(x) nH(t, s)= \u00d8 consisting \nof: A(.(t)) f(t)= InLeft (s, f, .) at wrong 1. an access-protecting lock set, which contains locks held \non  To produce clear error messages like that in Section 1, the Atom\u00adizer can optionally capture stack \ntraces (in the form of Exception objects) at the entry and commit points of each atomic block, and include \nthese stack traces in error messages. Since the Atomizer supports nested atomic blocks, a single operation \ncould result in multiple atomicity violations. 4.3 Extensions The Atomizer may produce false alarms due \nto imprecisions in the Lockset and reduction algorithms. We next present several im\u00adprovements that eliminate \nmany of these false alarms. We start by revisiting the treatment of synchronization operations during \nreduction. The classi.cation of lock acquires and releases as right-movers and left-movers, respectively, \nis correct but overly\u00adconservative in some cases. In particular, modular programs typ\u00adically include \nredundant synchronization operations that we can more precisely characterize as both-movers. every access \n(read or write) to that .eld, and 2. a write-protecting lock set, which contains locks held on every \nwrite to that .eld. The access-protecting lock set is always a subset of the write\u00adprotecting lock set. \nA .eld read is a both-mover if the current thread holds at least one of the write-protecting locks; otherwise \nthe read is a non-mover. In contrast, a .eld write is a both-mover only if the access-protecting lock \nset is non-empty; otherwise the write is a non-mover. Using these lock set pairs, the Atomizer can infer \nthat inc() is atomic, since it consists of a right-mover (the lock acquire); a both\u00admover (the read of \nx); an atomic action (since the write of x does not commute with concurrent reads of other threads); \nand a left\u00admover (the lock release). In comparison, existing race-detection tools would produce a false \nwarning about the race condition in read(), even though this race condition is benign and does not affect \nthe atomicity of either method. Benchmark Lines Num. Threads Num. Locks Max. Locks Held Num. Lock Set \nPairs Base Time (s) Atomizer Slowdown Atomicity Warnings Errors elevator 529 5 8 1 17 11.14  2 0 hedc \n29,948 26 385 3 728 8.36  4 1 tsp 706 10 2 1 5 0.94 48.2 7 0 sor 17,690 4 1 1 2 0.70 7.3 0 0 moldyn \n1,291 5 1 1 2 3.62 11.8 0 0 montecarlo 3,557 5 1 1 2 7.94 2.2 1 0 raytracer 1,859 5 5 1 7 5.96 36.6 1 \n1 mtrt 11,315 6 7 2 7 2.33 46.4 6 0 jigsaw 90,100 53 706 31 4,531 13.49 4.7 34 1 specJBB 30,490 10 262,000 \n6 340,088 18.01 11.2 4 0 webl 22,284 5 402,445 3 452,685 60.35  19 0 lib-java 75,305 39 816,617 6 986,855 \n96.5  19 4 Figure 1. Summary of test programs and performance. 5 Evaluation This section summarizes \nour experience applying the Atomizer to twelve benchmark programs. These programs include elevator, a \ndiscrete event simulator for elevators [51]; hedc, a tool to access astrophysics data from Web sources \n[51]; tsp, a Traveling Sales\u00adman Problem solver [51]; sor, a scienti.c computing program [51]; mtrt, \na multithreaded ray-tracing program from the SPEC JVM98 benchmark suite [48]; jigsaw, an open source \nweb server [54] con\u00ad.gured to serve a .xed number of pages to a crawler; specJBB, the SPEC JBB2000 business \nobject simulator [48] con.gured to pro\u00adcess a .xed number of transactions; moldyn, montecarlo, and raytracer \nfrom the Java Grande benchmark suite [33]; webl,a scripting language interpreter for processing web pages, \ncon.gured to execute a simple web crawler [34]; and lib-java. This last pro\u00adgram is an uninstrumented \ntest harness (comprised of webl, jbb, and hedc) that tests an instrumented version of the standard Java \nlibraries java.lang, java.io, java.net, and java.util. All programs other than lib-java use uninstrumented \nlibraries. The Atomizer instrumented these programs using the heuristics de\u00adscribed in Section 4 (exported \nmethods and synchronized blocks are annotated as atomic). To ensure that our measurements would ac\u00adcurately \nre.ect the cost of the underlying analysis, the Atomizer did not record stack histories for atomic block \nentry and commit points for these tests. We performed the experiments on a Red Hat Linux 8.0 computer \nwith dual 3.06GHz Pentium 4 Xeon processors and 2GB of memory. We used the Sun JDK 1.4.2 compiler and \nvirtual machine for all benchmarks except lib-java, for which we used the Sun JDK 1.3.1 virtual machine \ndue to compatibility problems. Figure 1 presents statistics for the test programs using all the exten\u00adsions \nfrom Section 4.3. The number of locks and distinct lock set pairs were relatively small for most programs, \nalthough the larger programs used many objects as locks, in some cases several orders of magnitude more \nthan in comparably-sized C programs [47]. The slowdown incurred by the instrumentation varied from 2.2x \nto roughly 50x. We only report slowdowns for compute-bound pro\u00adgrams. Those programs with very little \nslowdown, such as sor and montecarlo, spent most of the time in uninstrumented library code. We believe \nthat slowdowns of 20x 40x are representative for most programs. However, we did not focus on ef.ciency \nin this prototype, and there is much room for improvement. In particular, static analyses have reduced \nthe overhead of dynamic race detection to under 50% [51], which suggests that similar performance could \nbe achieved when checking atomicity. The Atomicity Warnings column in Figure 1 reports the number of \natomic blocks and methods that failed the Atomizer s atomic\u00adity requirements during test runs. Figure \n2 shows the cumulative bene.t of the extensions from Section 4.3. The Basic column in\u00addicates the number \nof warnings reported for each program using the basic Lockset and reduction algorithms. The succeeding \ncolumns show the number of warnings as each re.nement from Section 4.3 is added. Cumulatively, these \n.ve re.nements are quite effective: they reduce the number of warnings by roughly 70% (from 341 to 97). \nThe last column in Figure 1 reports the number of atomicity vio\u00adlations that we consider errors, either \nbecause they could lead to undesirable program behavior or because they violate documented atomicity \nproperties. Despite checking only mature software, the Atomizer identi.ed a number of potentially damaging \nerrors. Half of the errors were reported for atomic blocks with multiple data races or a single data \nrace followed by a lock acquire. The remain\u00adder contained a lock acquire operation after a lock release. \nWhen testing the instrumented libraries, the Atomizer warned of an atomicity violation in the synchronized \nmethod PrintStream.println(String s), which uses two calls to write the string s and the following new-line \ncharacter to a stream stored in the instance variable out. However, a different thread in the system \nalso wrote to out, potentially at the same time, which could cause the output stream to be corrupted. \nA comparable error in PrintWriter had been previously identi.ed by a static type system [24], but the \nAtomizer caught this defect with no programmer intervention and pinpointed an exact location in the program \nwhere the bug could manifest itself. The Atomizer reported an error in jigsaw that was also found stat\u00adically \nusing a view consistency analysis [51]. In this case, a speci.c interleaving could allow an entry to \nbe added to a resource store af\u00adter the store had been closed as part of the shutdown process. Other \nerrors included a known problem with Hashtable iterators in the presence of concurrent modi.cations, \nand a case where multiple threads updated a Calendar object through non-atomic methods. In most programs, \nthe warnings that did not indicate defects could be suppressed by inserting a handful of annotations. \nA signi.cant number of false alarms were due to the overly-optimistic heuristics employed by the Atomizer \nto identify atomic blocks. Fewer false alarms would be produced when checking code with programmer\u00adinserted \n/*# atomic */ declarations. For example, atomicity vi\u00adolations were often reported on methods called \nnear the top-level  Extensions Figure 2. Warnings reported by the Atomizer under different con.gurations. \nentry points of the program (the main and run methods), but many such methods are not intended to be \natomic and would not be la\u00adbeled as atomic by a programmer. Other common sources of false alarms include \ndouble-checked locking patterns, lazy initialization patterns, and various caching idioms. These programming \nidioms are notoriously problematic for analysis tools based on race detec\u00adtion and are discussed in more \ndetail in [42]. Although some of these practices, such as double-checked locking, are incompatible with \nthe Java memory model speci.cation, we classify them as false alarms since they do not cause problems \nin most current Java envi\u00adronments [42]. During these tests, the Atomizer also recognized .ve .elds with \nbenign race conditions that did not lead to atomicity violations. In these cases, the Atomizer did not \nreport spurious warnings to the user, as would have been the case for race condition checkers. Overall, \nthe Atomizer found no potential atomicity violations in over 90% of the methods annotated as atomic that \nwere exercised during our test runs. These statistics suggest that atomicity is a fundamental design \nprinciple in many multithreaded systems, espe\u00adcially library classes and reusable application components. \n 6 Related Work Lipton [38] .rst proposed reduction as a way to reason about con\u00adcurrent programs without \nconsidering all possible interleavings. He focused primarily on checking deadlock freedom. Doeppner [15], \nBack [4], and Lamport and Schneider [37] extended this work to allow proofs of general safety properties. \nCohen and Lam\u00adport [12] extended reduction to allow proofs of liveness properties. Misra [41] has proposed \na reduction theorem for programs built with monitors [32] communicating via procedure calls. Eraser [47] \nintroduced the Lockset algorithm for dynamic race detection. This approach has been extended to object-oriented \nlanguages [50] and has been improved for precision and perfor\u00admance [11, 45]. O Callahan and Choi [42] \nrecently combined the Lockset algorithm with a happens-before analysis to reduce false alarms in a dynamic \nrace detector for Java programs. A number of static race detectors have also been developed. Warlock \n[49] is a static race detection system for C programs. ESC/Java [23] statically catches a variety of \nsoftware defects, in\u00adcluding race conditions. Other approaches for static race and dead\u00adlock prevention \nare discussed in earlier papers [20, 19, 21]; these in\u00adclude model-checking [10, 13, 18], data.ow analysis \n[16], abstract interpretation [44], and type systems for process calculi [35, 36]. In previous work, \nwe produced a type system [21] that prevents vi\u00adolations of the lock-based synchronization discipline. \nSince then, similar type systems have been developed that include a notion of object ownership [8], and \nthat target other languages such as Cy\u00adclone [28], a type-safe variant of C. Compared to dynamic tech\u00adniques, \nthese static type systems provide stronger soundness guar\u00adantees and detect errors earlier in the development \ncycle, but require more effort from programmer. While some of these race detection tools have been quite \neffec\u00adtive, they may fail to detect atomicity violations and may yield false alarms on benign race conditions \nthat do not violate atomicity. Bacon et al developed Guava [5], an extension to the Java language with \na form of monitor capable of sharing object state in a way that prevents race conditions. The Atomizer \nwould work very well for languages like Guava, since language-enforced race freedom would eliminate several \ncommon sources of false alarms observed while checking programs written in languages that permit races. \nIn recent work, Flanagan and Qadeer developed a static type system to verify atomicity in Java programs \n[25, 24]. In comparison to the Atomizer, the type system provides better coverage and soundness guarantees, \nbut is less expressive (for example, it does not support redundant locking). The type system also requires \nprogrammer\u00adinserted annotations that specify properties such as the locking dis\u00adcipline followed by the \nprogram. This type system for atomicity was inspired by the Calvin-R [26] static checking tool for multithreaded \nprograms. Calvin-R supports modular veri.cation of multithreaded programs by annotating each procedure \nwith a speci.cation; this speci.cation is related to the procedure implementation via abstraction relation \nthat combines the notions of simulation and reduction. In ongoing work, the no\u00adtions of reduction and \natomicity are used by Qadeer et al [46] to infer concise procedure summaries in an analysis for multithreaded \nprograms. An alternative approach for verifying atomicity using model\u00adchecking is being explored by Hatcliff \net al [30]. In addition to us\u00ading Lipton s theory of reduction, they also investigate an approach based \non partial order reductions. Their experimental results sug\u00adgest that the model-checking approach for \nverifying atomicity is feasible for unit-testing, where the reachable state space is smaller than in \nintegration-testing. Atomicity is a semantic correctness condition for multithreaded software. In this \nrespect, it is similar to strict serializability [43], a correctness condition for database transactions, \nand linearizabil\u00adity [31], a correctness condition for concurrent objects. Verifying that an object is \nlinearizable requires full program veri.cation. We hope that our analysis for atomicity can be leveraged \nto develop lightweight checking tools for related correctness conditions. Artho et al [1] have developed \na dynamic analysis tool to identify one class of higher-level races . The analysis is based on the no\u00adtion \nof view consistency. Intuitively, a view is the set of variables accessed within a synchronized block. \nThread A is view consis\u00adtent with B if all views from the execution of A, intersected with the maximal \nview of B, are ordered by subset inclusion. Viola\u00adtions of view consistency can indicate that a program \nmay be using shared variables in a problematic way. View consistency violations can also be detected \nstatically [52]. ESC/Java has been extended to catch a different notion of higher-level races, where \na stale value from one synchronized block is used in a subsequent synchronized block [9]. In recent work, \nWang and Stoller [53] developed several algorithms for checking atomicity dynamically, including the \nbasic algorithm described in Section 3.3. Their work focuses primarily on more ex\u00adpressive algorithms \nthat can verify additional execution sequences as serializable. They have not yet applied their algorithms \nto large programs. Our experiments on large programs motivated the de\u00advelopment of several crucial improvements \nto the basic algorithm, such as our support for redundant synchronization operations and write-protected \ndata, and has allowed us to validate the ef.ciency and effectiveness of our approach. While our tool \nchecks atomicity, other researchers have proposed using atomicity as a language primitive, essentially \nimplementing the serialized semantics .. Lomet [40] .rst proposed the use of atomic blocks for synchronization. \nThe Argus [39] and Avalon [17] projects developed language support for implementing atomic ob\u00adjects. \nPersistent languages [2, 3] are attempting to augment atomic\u00adity with data persistence in order to introduce \ntransactions into pro\u00adgramming languages. A more recent approach to supporting atom\u00adicity uses lightweight \ntransactions implemented in the run-time sys\u00adtem [29]. An alternative is to generate synchronization \ncode auto\u00admatically from high-level speci.cations [14]. 7 Conclusions Developing reliable multithreaded \nsoftware is notoriously dif.cult, because concurrent threads often interact in unexpected and erro\u00adneous \nways. Programmers try to avoid unintended interactions by designing methods and interfaces that are atomic, \nbut traditional testing techniques are inadequate for verifying atomicity. This paper presents a dynamic \nanalysis designed to catch atomic\u00adity violations would be missed by traditional testing or (static or \ndynamic) race-detection techniques. This analysis has been imple\u00admented and applied to a range of benchmark \nprograms, and has successfully detected atomicity violations in these programs. In ad\u00addition, our experimental \nresults suggest that over 90% of the meth\u00adods in our benchmarks are atomic, which validates our hypothesis \nthat atomicity is a fundamental design principle in multithreaded programs. For future work, we hope \nto study hybrid atomicity checkers based on a synthesis of the dynamic and static approaches. In one \ncom\u00adbination, a static type-based analysis may verify many expected race-freedom and atomicity properties, \nand the dynamic atomicity checker could then focus on the unveri.ed residue. For race detec\u00adtion, this \nhybrid approach has reduced the instrumentation overhead by an order of magnitude [51, 42]; we expect \ncomparable improve\u00adments when checking atomicity. Acknowledgments. We thank Mart\u00b4in Abadi, Shaz Qadeer, \nRob O Callahan, and Scott Stoller for valuable comments on this work. We also thank Christof von Praun \nfor his assistance in collecting test programs. This work was partly supported by the National Sci\u00adence \nFoundation under Grants CCR-0341179 and CCR-0341387, and by faculty research funds granted by the University \nof Califor\u00adnia at Santa Cruz and by Williams College. 8 References [1] C. Artho, K. Havelund, and A. \nBiere. High-level data races. In The First International Workshop on Veri.cation and Validation of Enter\u00adprise \nInformation Systems, 2003. [2] M. P. Atkinson, K. J. Chisholm, and W. P. Cockshott. PS-Algol: an Algol \nwith a persistent heap. ACM SIGPLAN Notices, 17(7):24 31, 1981. [3] M. P. Atkinson and D. Morrison. Procedures \nas persistent data ob\u00adjects. ACM Transactions on Programming Languages and Systems, 7(4):539 559, 1985. \n[4] R.-J. Back. A method for re.ning atomicity in parallel algorithms. In PARLE 89: Parallel Architectures \nand Languages Europe, volume 366 of Lecture Notes in Computer Science, pages 199 216. Springer-Verlag, \n1989. [5] D. F. Bacon, R. E. Strom, and A. Tarafdar. Guava: A dialect of Java without data races. In \nProceedings of the ACM Conference on Object-Oriented Programming, Systems, Languages and Applications, \npages 382 400, 2001. [6] A. D. Birrell. An introduction to programming with threads. Research Report \n35, Digital Equipment Corporation Systems Research Center, 1989. [7] C. Boyapati, R. Lee, and M. Rinard. \nA type system for preventing data races and deadlocks in Java programs. In Proceedings of the ACM Conference \non Object-Oriented Programming, Systems, Languages and Applications, pages 211 230, 2002. [8] C. Boyapati \nand M. Rinard. A parameterized type system for race-free Java programs. In Proceedings of the ACM Conference \non Object\u00ad Oriented Programming, Systems, Languages and Applications, pages 56 69, 2001. [9] M. Burrows \nand K. R. M. Leino. Finding stale-value errors in concur\u00adrent programs. Technical Note 2002-004, Compaq \nSystems Research Center, 2002. [10] A. T. Chamillard, L. A. Clarke, and G. S. Avrunin. An empirical comparison \nof static concurrency analysis techniques. Technical Re\u00adport 96-084, Department of Computer Science, \nUniversity of Mas\u00adsachusetts at Amherst, 1996. [11] J.-D. Choi, K. Lee, A. Loginov, R. O Callahan, V. \nSarkar, and M. Srid\u00adhara. Ef.cient and precise datarace detection for multithreaded object\u00adoriented programs. \nIn Proceedings of the ACM Conference on Pro\u00adgramming Language Design and Implementation, pages 258 269, \n2002. [12] E. Cohen and L. Lamport. Reduction in TLA. In Proceedings of the International Conference \non Concurrency Theory, volume 1466 of Lecture Notes in Computer Science, pages 317 331. Springer-Verlag, \n1998. [13] J. C. Corbett. Evaluating deadlock detection methods for concurrent software. IEEE Transactions \non Software Engineering, 22(3):161 180, 1996. [14] X. Deng, M. Dwyer, J. Hatcliff, and M. Mizuno. Invariant-based \nspeci.cation, synthesis, and veri.cation of synchronization in concur\u00adrent programs. In International \nConference on Software Engineering, pages 442 452, 2002. [15] T. W. Doeppner, Jr. Parallel program correctness \nthrough re.nement. In Proceedings of the ACM Symposium on the Principles of Program\u00adming Languages, pages \n155 169, 1977. [16] M. B. Dwyer and L. A. Clarke. Data .ow analysis for verifying prop\u00aderties of concurrent \nprograms. Technical Report 94-045, Department of Computer Science, University of Massachusetts at Amherst, \n1994. [17] J. L. Eppinger, L. B. Mummert, and A. Z. Spector. Camelot and Avalon: A Distributed Transaction \nFacility. Morgan Kaufmann, 1991. [18] L. Fajstrup, E. Goubault, and M. Raussen. Detecting deadlocks in \ncon\u00adcurrent systems. In D. Sangiorgi and R. de Simone, editors, Proceed\u00adings of the International Conference \non Concurrency Theory, volume 1466 of Lecture Notes in Computer Science, pages 332 347. Springer-Verlag, \n1998. [19] C. Flanagan and M. Abadi. Object types against races. In J. C. M. Baeten and S. Mauw, editors, \nProceedings of the International Confer\u00adence on Concurrency Theory, volume 1664 of Lecture Notes in Com\u00adputer \nScience, pages 288 303. Springer-Verlag, 1999. [20] C. Flanagan and M. Abadi. Types for safe locking. \nIn S. D. Swier\u00adstra, editor, Proceedings of European Symposium on Programming, volume 1576 of Lecture \nNotes in Computer Science, pages 91 108. Springer-Verlag, 1999. [21] C. Flanagan and S. N. Freund. Type-based \nrace detection for Java. In Proceedings of the ACM Conference on Programming Language Design and Implementation, \npages 219 232, 2000. [22] C. Flanagan and S. N. Freund. Detecting Race Conditions in Large Programs. \nIn Workshop on Program Analysis for Software Tools and Engineering, pages 90 96, 2001. [23] C. Flanagan, \nK. R. M. Leino, M. Lillibridge, G. Nelson, J. B. Saxe, and R. Stata. Extended static checking for Java. \nIn Proceedings of the ACM Conference on Programming Language Design and Implemen\u00adtation, pages 234 245, \n2002. [24] C. Flanagan and S. Qadeer. A type and effect system for atomicity. In Proceedings of the ACM \nConference on Programming Language Design and Implementation, pages 338 349, 2003. [25] C. Flanagan and \nS. Qadeer. Types for atomicity. In Proceedings of the ACM Workshop on Types in Language Design and Implementation, \npages 1 12, 2003. [26] S. N. Freund and S. Qadeer. Checking concise speci.cations for mul\u00ad tithreaded \nsoftware. In Workshop on Formal Techniques for Java-like Programs, 2003. [27] J. Gosling, B. Joy, and \nG. Steele. The Java Language Speci.cation. Addison-Wesley, 1996. [28] D. Grossman. Type-safe multithreading \nin Cyclone. In Proceedings of the ACM Workshop on Types in Language Design and Implementa\u00adtion, pages \n13 25, 2003. [29] T. L. Harris and K. Fraser. Language support for lightweight trans\u00adactions. In Proceedings \nof the ACM Conference on Object-Oriented Programming, Systems, Languages and Applications, pages 388 \n402, 2003. [30] J. Hatcliff, Robby, and M. B. Dwyer. Verifying atomicity speci.ca\u00adtions for concurrent \nobject-oriented software using model-checking. In Proceedings of the International Conference on Veri.cation, \nModel Checking and Abstract Interpretation, 2004. [31] M. P. Herlihy and J. M. Wing. Linearizability: \nA correctness con\u00addition for concurrent objects. ACM Transactions on Programming Languages and Systems, \n12(3):463 492, 1990. [32] C. Hoare. Monitors: an operating systems structuring concept. Com\u00admunications \nof the ACM, 17(10):549 557, 1974. [33] Java Grande Forum. Java Grande benchmark suite. Available from \nhttp://www.javagrande.org/, 2003. [34] T. Kistler and J. Marais. WebL a programming language for the \nweb. In Proceedings of the International World Wide Web Conference, volume 30 of Computer Networks and \nISDN Systems, pages 259 270. Elsevier, 1998. [35] N. Kobayashi. A partially deadlock-free typed process \ncalculus. ACM Transactions on Programming Languages and Systems, 20(2):436 482, 1998. [36] N. Kobayashi, \nS. Saito, and E. Sumii. An implicitly-typed deadlock\u00adfree process calculus. In C. Palamidessi, editor, \nProceedings of the International Conference on Concurrency Theory, volume 1877 of Lecture Notes in Computer \nScience, pages 489 503. Springer-Verlag, 2000. [37] L. Lamport and F. B. Schneider. Pretending atomicity. \nResearch Re\u00adport 44, DEC Systems Research Center, 1989. [38] R. J. Lipton. Reduction: A method of proving \nproperties of parallel programs. Communications of the ACM, 18(12):717 721, 1975. [39] B. Liskov, D. \nCurtis, P. Johnson, and R. Schei.er. Implementation of Argus. In Proceedings of the Symposium on Operating \nSystems Principles, pages 111 122, 1987. [40] D. B. Lomet. Process structuring, synchronization, and \nrecovery using atomic actions. Language Design for Reliable Software, pages 128 137, 1977. [41] J. Misra. \nA Discipline of Multiprogramming: Programming Theory for Distributed Applications. Springer-Verlag, 2001. \n[42] R. O Callahan and J.-D. Choi. Hybrid dynamic data race detection. In ACM SIGPLAN Symposium on Principles \nand Practice of Parallel Programming, pages 167 178, 2003. [43] C. Papadimitriou. The theory of database \nconcurrency control. Com\u00adputer Science Press, 1986. [44] Polyspace technologies, 2003. Available at http://www.poly\u00adspace.com. \n[45] E. Pozniansky and A. Schuster. Ef.cient on-the-.y data race detection in multithreaded C++ programs. \nIn Proceedings of the ACM Sym\u00adposium on Principles and Practice of Parallel Programming, pages 179 190, \n2003. [46] S. Qadeer, S. K. Rajamani, and J. Rehof. Summarizing procedures in concurrent programs. In \nProceedings of the ACM Symposium on the Principles of Programming Languages, 2004. [47] S. Savage, M. \nBurrows, G. Nelson, P. Sobalvarro, and T. E. Anderson. Eraser: A dynamic data race detector for multi-threaded \nprograms. ACM Transactions on Computer Systems, 15(4):391 411, 1997. [48] Standard Performance Evaluation \nCorporation. SPEC benchmarks. Available from http://www.spec.org/, 2003. [49] N. Sterling. Warlock: A \nstatic data race analysis tool. In Proceedings of the USENIX Winter Technical Conference, pages 97 106, \n1993. [50] C. von Praun and T. Gross. Object race detection. In Proceedings of the ACM Conference on \nObject-Oriented Programming, Systems, Languages and Applications, pages 70 82, 2001. [51] C. von Praun \nand T. Gross. Static con.ict analysis for multi-threaded object-oriented programs. In Proceedings of \nthe ACM Conference on Programming Language Design and Implementation, pages 115 128, 2003. [52] C. von \nPraun and T. Gross. Static detection of atomicity violations in object-oriented programs. In Workshop \non Formal Techniques for Java-like Programs, 2003. [53] L. Wang and S. D. Stoller. Run-time analysis \nfor atomicity. In Pro\u00adceedings of the Workshop on Runtime Veri.cation, volume 89(2) of Electronic Notes \nin Computer Science. Elsevier, 2003. [54] World Wide Web Consortium. Jigsaw. Available from http://www.w3c.org, \n2001. A Proof of Theorem 2 We start by de.ning two additional transition relations: S .t S ' , which \nperforms an instrumented step of thread t, and S |. S ' , which is a serialized variant of the instrumented \nsemantics .. Additional relations: S .t S ' and S |. S ' [INS STEP T] [INS SERIAL STEP] T (t, .(t),a, \np ' ) s . a s ' (s, f, .) . t (s ' ,f ' , . ' ) t (s, f, .) . a f ' . u = t. A(.(u)) = 0 t (s, f, .) \n. t (s ' ,f ' , .[t := p ' ]) (s, f, .) |. (s ' ,f ' , . ' ) We introduce three state predicates N(t), \nR(t), and L(t), where N(t) means that thread t is not in an atomic block, and R(t) and L(t) mean that \nthread t is in the right-mover and left-mover parts of an atomic block, respectively. The following Reduction \nTheo\u00adrem formalizes .ve conditions that are suf.cient to conclude that all atomic blocks are reducible. \nThe statement of this theorem uses some additional notation. For two actions b, c . State\u00d7State, we say \nthat b right-commutes with c if for all S1, S2, S3, whenever (S1, S2) . b and (S2, S3) . c, then there \nexists S ' 2 such that (S1, S ' 2) . c and (S2' , S3) . b. The action b left-commutes with the action \nc if c right-commutes with b. We also de.ne the left restriction . \u00b7 b and the right restriction b \u00b7 \n. of an action b with respect to a set of states . . State. def ' . \u00b7 b = {(S, S) . b | S . .} def '' \nb \u00b7 . = {(S, S) . b | S . .} THEOREM 5(REDUCTION). Suppose that for all t, u . Tid with t = u: A1. R(t), \nL(t), and N(t) form a partition of State. A2. (L(t) \u00b7.t \u00b7 R(t)) is empty. A3. (.t \u00b7 R(t)) right-commutes \nwith .u. A4. (L(t) \u00b7.t) left-commutes with .u. A5. if S .t S ' , then S . R(u) . S ' . R(u), and S . \nL(u) . S ' . L(u). Suppose further that S0 . * S and S0 and S are in N(t) for all t . Tid. Then S0 |. \n* S. PROOF: See [25]. We now leverage this theorem to show that every instrumented ex\u00adecution trace is \nreducible. RESTATEMENT OF THEOREM 2(INSTRUMENTED REDUCTION) If (s0,f0, .0) . * (s, f, .) and \u00acA(.) then \n(s0, .0) . * (s, .). PROOF: We de.ne the predicates N(t), R(t), and L(t) necessary to apply Theorem 5 \n(Reduction) as follows: def N(t)= {(s, f, .) | A(.(t)) = 0} def R(t)= {(s, f, .) | A(.(t)) =0 . f(t)= \nInRight} def L(t)= {(s, f, .) | A(.(t)) =0 . f(t)= InLeft} These predicates satisfy the following .ve \nrequirements of Theo\u00adrem 5, for t, u . Tid with t = u: A1. They clearly partition State. A2. (L(t) \u00b7.t \n\u00b7 R(t)) is empty, since f(t) is never set to InRight while within an atomic block. A3. (.t \u00b7 R(t)) right-commutes \nwith .u, since if R(t) holds af\u00adter an action of thread t, then that action is either an E-action, a \nlock acquire, or a variable access while holding the protecting lock, all of which right-commute with \n.u. A4. (L(t) \u00b7.t) left-commutes with .u, since if L(t) holds be\u00adfore an action of thread t, then that \naction is either an E-action, a lock release, or a variable access while holding the protect\u00ading lock, \nall of which left-commute with .u. A5.if S .t S ' , then S . R(u) . S ' . R(u) and S . L(u) . S ' . L(u), \nsince a step by thread t does not change f(u) or .(u). Hence by Theorem 5 (Reduction), (s0,f0, .0) |. \n* (s, f, .), and therefore (s0, .0) . * (s, .).   \n\t\t\t", "proc_id": "964001", "abstract": "Ensuring the correctness of multithreaded programs is difficult, due to the potential for unexpected interactions between concurrent threads. Much previous work has focused on detecting race conditions, but the absence of race conditions does not by itself prevent undesired thread interactions. We focus on the more fundamental non-interference property of <i>atomicity</i>; a method is atomic if its execution is not affected by and does not interfere with concurrently-executing threads. Atomic methods can be understood according to their sequential semantics, which significantly simplifies (formal and informal) correctness arguments.This paper presents a dynamic analysis for detecting atomicity violations. This analysis combines ideas from both Lipton's theory of reduction and earlier dynamic race detectors. Experience with a prototype checker for multithreaded Java code demonstrates that this approach is effective for detecting errors due to unintended interactions between threads. In particular, our atomicity checker detects errors that would be missed by standard race detectors, and it produces fewer false alarms on benign races that do not cause atomicity violations. Our experimental results also indicate that the majority of methods in our benchmarks are atomic, supporting our hypothesis that atomicity is a standard methodology in multithreaded programming.", "authors": [{"name": "Cormac Flanagan", "author_profile_id": "81100538763", "affiliation": "University of California at Santa Cruz, Santa Cruz, CA", "person_id": "PP14187273", "email_address": "", "orcid_id": ""}, {"name": "Stephen N Freund", "author_profile_id": "81100165065", "affiliation": "Williams College, Williamstown, MA", "person_id": "P653516", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/964001.964023", "year": "2004", "article_id": "964023", "conference": "POPL", "title": "Atomizer: a dynamic atomicity checker for multithreaded programs", "url": "http://dl.acm.org/citation.cfm?id=964023"}